Alright, hello and welcome. It's May 24th, 2024. We're in ACTIMF livestream number 57.0,
doing background and context video for the active data selection and information seeking
paper and series. So welcome to the ACTIMF Institute. We're a participatory online institute
that is communicating, learning and practicing applied active inference. This is a recorded
and archived livestream. Please provide feedback so we can improve our work. All backgrounds
perspectives are welcome. And we'll follow video etiquette for live streams. Head over
to active inference.org to learn more about any of the projects, including the live streams.
Today, we're going to do together a background first pass on a very interesting paper from
Thomas Parr, Carl Friston and Peter Seidman, active data selection and information seeking
from 2024. In this video, we're going to introduce ourselves, talk about big questions, go through
the keywords of the paper, then most of the sections, section by section. And as always,
with the dot zero, it's just like a first pass. And we'll look forward to speaking with
hopefully some of the authors in the coming weeks, and also looking what people ask about. So
Christopher, let us introduce ourselves and go from there. Thanks a lot also for helping in
the dot zero preparation. Happily. Yeah, so I'm Christopher Bennett. I'm a bioinformatics
scientist. I do a lot of data mangling data analysis and that sort of thing. This paper was
of great interest to me as we kind of go into this more data driven era in making sure that with
such large data sets that we have, making sure that we can actually select relevant data for any of
our applications going forward, be it machine learning or whatever we're trying to do.
And I'm Daniel. I'm a researcher in California and also was drawn to this on one hand on the
applied side, the idea of more efficient and effective data sampling. And then on the more
theory side, the connection with epistemic value information gain.
So here are some of the big questions. Why don't you add some detail to this?
Absolutely. So there's five major big questions that I had after reading this.
For the most part, it boils down to
doing our sampling. You can do sampling over time and sampling of different data sets in different
ways. Is there a way that we can intelligently select the data that we're going for the time
the time that we're trying to select? Is there a way that we can understand how the
time aspect helps sample through time instead of just doing a dynamic or more dynamic instead of
doing a static like we're going to do time zero, time seven, time 14, time 21. Can we say, hey,
the differences between time one and time two are very 10.1, time point two are very interesting.
It's a lot of data in there alone. So we'll sample one and two and then maybe sample 10. Is
there a way that we can intelligently select the time points that we are sampling from
when we get into the time series aspect? The Piper mentioned a number of different
time dimension models that you can add to the four model that they're utilizing,
one of which was a hidden Markov model, another was they mentioned a differential equation in the
actual model itself, in the equation itself. Is there one, are there situations that one
performs better over than the other? Or is what they have selected to use in the paper the optimal
solution in most cases, if not all cases? When it comes to clinical trials, that was a
section in this that they discussed. There's a lot of FDA regulations of the clinical trials and
it's very heavy red tape right now. Is there a way that there's minimum ends that you need in
many clinical trials to actually be considered passing? Is there a way that you can bound this
model that they've developed into something that you can guarantee a minimum number,
a minimum sampling that the FDA requires or any regulatory body?
Another point is the next step of how are we going to integrate this in with other machine
learning models or any downstream applications that you're going with? Is there a selection method
that we can, or how do you see these, this method kind of pre, kind of before machine learning?
How are we going to attach these things together so that we feed the right data into machine learning?
Being an LLM. And then scalability and computation demands. That's going to be a big one if this
is going to be something that is used routinely in industry. We need to make sure that this is
something that is as scalable as you can get. Go from small scale, which is a lot of what they
show in this paper and then all the way up to the very large scale data sets that we
use to train LLMs and other models. Those are kind of the five major points that I have.
Thank you. Those are very insightful. Here were some of the big questions that I was excited about.
So first, from a more general information gain, epistemic foraging perspective,
how do we model the implicit and explicit constraints or trade-offs or dynamics of
information seeking? Which is often addressing a question that is left unaddressed in data science
of where the data comes from. It's just about doing analysis with the data that's there.
But even there, as this paper will kind of get into, there's still sub-sampling and all these
other factors to consider. The clinical trial example brings a very serious and very real plot
twist into the paper, which moves through several levels of adding theoretical generalization and
incorporating like the time dimension and other features. And then the plot twist is when the
preferences for certain kinds of observations is specified, then there's all this interesting
behavior and decisions that come into play. So I'm sure that'll be a great discussion.
And then also in section four, they mentioned the streetlight effect, which is, quote,
the tendency to search where data are generated in a minimally ambiguous way,
i.e. under a street lamp compared to searching elsewhere on a darkened street. And so there it's
an interesting scenario and there'll be some fun art coming up and also how they distinguish the
sampling method with the full information seeking from the maximum entropy sampling
is a very subtle but very important point that I look forward to hearing more from the authors about.
Okay, so just to summarize, the paper is Active Data Selection and Information Seeking,
2024, Thomas Parr, Carl Friston, Peter Seidman, and just a few of the aims and claims of the paper,
and then Christopher will read the abstract. This paper aims to unpack the principles of
active sampling of data by drawing from neurobiological research on animal exploration
and from the theory of optimal experimental design. Our overall aim is to provide an intuitive
overview of the principles that underwrite active data selection and to illustrate this with some
simple examples. Our interest is in the selection of data, either through sampling subsets of data
from a large data set or through optimizing experimental design based upon the models we have
of how those data are generated. Optimizing data selection ensures we can achieve good
inference with fewer data, saving on computational and experimental costs. So if you could read the
abstracts. Absolutely, so the main points in the abstract are the Bayesian inference is typically
focused on two major issues. The first one is that you have to estimate the parameters of the model
of the data, and the second is that you need to quantify the evidence for alternative hypotheses
and formulate an alternative model. But this paper is actually looking at a third issue,
which is in how you're going to select the data for your models. And either through sampling
subsets of large data is typically used or optimizing experiments of design.
Based upon the models we have these of how these data are generated. Optimizing data selection,
what's going into the models can achieve a very good inference with fewer data points. So you're
saving on computational time costs, that sort of thing by actually reducing the amount of
information that you're putting into a model. So what we're doing here is trying to unpack
how you're going to actively select data, and I mean actively select data through a machine
optimization protocol by drawing from some of these neurobiology concepts and trying to optimize
the maximum information that the information can provide, maximum information gain. So they offer
overview of some basic points from the field and illustrates the application in some of the toy
examples that they have will go through, ranging from different approximations with basis sets
to inference about how the process can evolve over time. And finally they'll go through and
consider how the approach to the data selection could be applied to design of clinical trials in
this case, and specifically Bayes adapted clinical trial, something that is more and more
seeing headlines and it's more and more used today now that we have the technology to do it.
Great. Okay. For the roadmap, the paper begins with introduction section,
goes into Bayesian inference, generative models and expected information gain.
They go through a simplest worked example, and then consider a few more ways to level up that model
with function approximation, consideration of the time dimension with dynamic processes,
and then bring in the preference for certain observations in the clinical trials.
Then there's a discussion and conclusion, and they also have a paragraph explaining their
kind of logic there. The keywords for the paper were experimental design, active sampling,
information gain, and Bayesian inference. So the next slides are going to go into those
four background topics. After the four background topics, we'll speed through the sections and
just plant a few seeds for what we want to explore more. So first, experimental design.
Here's two kind of classical views of experimental design in the active inference and free energy
principle eras. So on the left is the statistical parametric mapping, textbook, toolbox, documentation,
et cetera, has multiple chapters and kinds of analyses included in the package to specify
and simulate and also to recognize data according to different experimental designs.
And one very hallmark or common visualization of these kinds of patterns of experimental design
are these design matrices. And it's just represented in this black to white gray scale,
and it summarizes different kinds of measurements across different experimental settings. Like here
might be six settings in the larger white blocks. And then there was variability within each of those
trials. And those are the smaller row levels. So that's like where the data are collected.
And a lot of this has to do with the linear operations that can occur on this kind of
matrix in a general linear modeling framework. And then on the right is the experimental design
experimenters perspective, where the experimental stimuli they output as actions are the
observations going into the subjective model, like of the rat in the team is, and then the action
output of the rat is the observations of the experiment of the experiment. So kind of two
different perspectives, SPM with more of a matrix multiplication, f m r i optimal design, and then
active inference with the more general graphical Bayesian modeling, starting to broaden the
consideration of what optimal foraging and what information gain epistemic value mean.
These are kind of the experimental design themes and how they connect a little bit with
other experimental design factors. Want to add anything? Yeah, keep in mind that a lot of these
experiments, experimental design is a very big and very important consideration when you're
actually running any sort of science or analytics of any variety. And these experiments can actually
get very large with huge, huge amounts of data. And all of that data is relevant for every
application that you want. So you want to be able to design your experiment in a way that you can
collect information in a intelligent way rather than trying to go through and just collect every
data point that you can because humans in many cases are running some of these experiments and
they are have limited time. I certainly do when I'm running these things. So I have to be very
intelligent in how I set things up and how I actually collect data and what did I collect,
because you only get in many of these cases, you only get one shot to collect the data,
you miss it, it's over. You won't have that data point. So it's very critical that you actually
take the experimental design seriously when you're setting these things up.
Great. So connecting that kind of experimental design, experimenter on a budget perspective
with a more statistical and biologically statistical based perspective, active sampling.
So they wrote, when we look at the world around us, we are implicitly engaging in a form of active
data sampling, also known as active sensing or active inference. So this is referencing the
visual saccades. And just to kind of highlight how extreme the relative acuity difference is
between the center of the eye where the gaze is focused on and the off center,
among other visual changes. And vision is just being taken as one sensory example here.
It could also be thought of as like looking for books within a library or any other kind of
selection of what data are going to come in, even if it seems like all of it is going to
all of it is coming in, that still is going to be perhaps addressed with different sensors that
have different variability profiles, or like there's different RNA sequencing kits that you
could buy. And so how do you balance the kind of more samples or which samples, especially as
those spaces grow massive. And then just to contrast that, whereas digit recognition in a
saccade based paradigm would focus on the motor patterns and the small centrally focused
visual acuity and then the motor patterns that relate to circuiting around a digit. Whereas
in the kind of machine learning taken all at once approach, a matrix corresponding to like the
pixels in the MNIST dataset are simply taken in all at equivariance level. So that's just kind
of taking in the data. There's still another higher order data selection question of like,
which digits do you take? If there was a large number of digits in that library. So this is
active data sampling on multiple scales, which records you pull at all, and then how the resolution
and all the tradeoffs that are associated with using the data processing or making the experiment.
Yeah, add more though. And, you know, keep in mind that when you're talking about something
like the visual system, you know, our visual system has access to untold amounts of information,
but our brain can't take advantage of all of that at once. So there's low energy usage of the brain
that needs to optimize the relevant information. Think, you know, your nose is right at the end
of your face. Your eyes are always seeing your nose, but your brain is filtering it out. And this
is happening all the time at all points in time. There are literal blind spots in what you are
actually capable of intaking and processing all at once. And then additionally, when you're
moving away from something like your eye or biological systems and into the experiment
design itself, you know, you oftentimes can't run a full factorial design. And there are other
methods like a fractional factorial design. But those are random base. And this is trying to
actually talk about actively selecting how you're going to set up that design. So it's kind of a,
you can think of it multiple different ways. Awesome. The factor that's going to come into
play as driving the active sampling is going to be the information gain. And there's some quotes
here. And equation two is shown. They write, we have conditioned our model upon the variable
pi, which represents a choice we can make in selecting our data. So data recognition,
interpretation, analysis, and so on. It's often framed as kind of like an observation type or
sense making type activity. Here, pi for policy, as with usual, is being framed as a control or
an active data selection policy, we're applying to some data set. So it adds a action element
into this sequential epistemic foraging, rather than just taking a large data set,
and just munching it like all at once, it brings in this sequential question of where to sample,
and potentially updating where is informative to sample through time. And that I of pi is the
functional on that policy distribution or specific choice that can be decomposed,
all these interesting ways that we can explore more in the coming discussions.
What else would you add, though, about information gain?
I think this is one of the biggest points in this whole paper is you're measuring how much
information you are gaining in your model by adding these different variables in here and
selecting different variables. You're effectively automatically taking out or trying to remove
things that have high mutual information that don't add as much. So if you have parameter A
and parameter B that are effectively just transformations of the same data, then you
can easily remove one of those and still have all the information that you need.
So it's a really, really powerful way of saying I'm trying to optimize and maximize the amount
of information that I'm adding into the model by selecting data that actually has the information
that is going to improve them. Awesome. One other interesting angle here is often in the control
literature, utility, reinforcement learning, etc. The epistemic value component is added in,
whereas in the structure of this paper, they start with the pure information gain perspective.
And then in the clinical trial, they bring the preference in. So the pragmatic value
comes in secondary to the information gain in how they build it up step by step.
Bayesian inference is the last keyword. A lot of places to go. Here's what they showed
for equation one. And they wrote Bayesian inference is the process of inverting
a model of how data, why, are generated to obtain two things, the marginal likelihood
and the posterior probability. So anything you want to say about Bayesian inference or
do you want to say something about Bayesian networks and graphs? I think that you've kind of
covered it here. It's, I think, barely textbook on this part. Yeah. How about graphs?
On the Bayesian graphs side of it, there's multiple different ways that these Bayesian
statistics is done nowadays. And the Bayesian networks and graphs is a really powerful method
going forward. I know that right now in the Institute, we have an Rx and Fur group working
right now, which is a Julia package for actually just building these network graphs, these Bayesian
graphs and doing message passing between the different factors and the different nodes of
the graph. So this is a very big up and coming area right now. It's very early in the time frame
that this is going to become big. It's kind of on the upswing right now. And it's kind of,
at least I would predict, going to be kind of the next big thing going forward in the next five
years or so. Yeah. We've been having a great epistemic time and Livestream 55 explores some of
this in more detail. Okay. That was the background now on to the paper. So first, just to get the
last part of the paper out of the way, they have a GitHub, Thomas Parr's GitHub with the
active data selection repo. And maybe in one of the upcoming discussions or somebody in the time
between can explore and transform and play with the code. And also all these different
ways that we have fun discussions around the language of the active inference model
and how building it in different languages or using different styles like is there isn't plausible.
These have been very fun discussions that help us get at what the core of the math really is
and how that's independent of whether it's written in MATLAB or any other language.
And then also as it is simulated, it's written here in MATLAB. And so that's kind of interesting.
Any thoughts on that or just like coding in Rx and fur or or
Yeah, I think that with Rx and fur being, I think, relatively new on the scene, you have some of
these other traditional approaches with MATLAB and high MD and that sort of thing. It'll be very
interesting to see how these techniques evolve over time with packages like Rx and fur really,
I think, changing how we approach building these models and designing them. I think that it's going
to be even more critical now in this current environment to select the data intelligently
going in so that you're not muddying up your models or having to build two big of models that might
have information that's not as useful to the application at hand. Yeah, great. All right,
section one introduction. So we'll try to hit on some of the key points. I'll say something briefly
and then feel free to add something if you want. Section one situates that inference and action
cycle or loop or partition in terms of a statistician's job or process in modeling
observations data as sampled and latent variables as models and the process by which there's
kind of snapshot or bulk summarization or generativity or and how it's possible to have a
continuous resampling of informative data or how you even evaluate how data are informative in which
way. Want to add anything? I think you've captured that very well. I'm going to actually pull out my
notes so that I can actually remember all the symbols. Why are going to be used for data and
data for the latent variables? So distributions of data, distributions of latent variables
conditioned upon data coming in. So that could be seen as just one data point sequentially or a big
bulk vector coming in like all at once. Just continuing to move through this section, they wrote
careful data selection is especially important when we consider the problems associated with
very large data sets of the sort that are now ubiquitous in machine learning and artificial
intelligence settings. So just to summarize a little bit or add a few notes that came up in
the paper. So other than this topic being very fascinating and very integrative in terms of a
unifying approach for information and behavior etc. Also this is definitely one of the active
inference questions that has a lot of pragmatic relevance as dealing with with data sets of
different kind is totally day to day. And especially the way that even the examples specify
important settings is very clear, very direct. Though also the mathematics are very general
about epistemics and this motivation that they lay out in the first section about how if this
challenge could be addressed, then there will be all these kinds of benefits that could be realized
with current systems and data sets. And then they provide the approach to at least getting
there or towards it to optimize data selection. We first need to identify an appropriate optimality
criterion. And so they're going to kind of go through several stages of with different
generative models how that optimality criterion is defined. Anything else that
And keep in mind that this is the expected information gain that they're talking about.
It's effectively how much do we think we're going to gain by adding this information in there.
And then you can of course train your model by looking at the actual information gain if necessary
and go through kind of a learning cycle. But we're basing this all off of what do we expect
to gain from this information. All right, section two, basing inference generative models and
expected information gain. In this equation three, I won't read it all. It models the Markov blanket
formalism in terms of upstream and downstream causal relationships in terms of messages that are
passed along edges of a factor graph. They introduce in this paper the lambda operator
to indicate either summation or integration. So this is across continuous variables or discrete
variables. And we'll explore this more with the authors, hopefully anything you want to add on
equation three. More that you know the information gain is a function of the data that you sample.
So depending on how you sample that data, you're going to get different information gain out of
it as you would expect. And then you start to get into the message passing, which is that base graph
and factor graph, I guess, challenge going forward that that construct when you build
it in a factor graph model, you have to be able to pass the messages between the nodes effectively.
Yeah, and to kind of ground that in the data science situation, if you have a latent
state estimate and you're generating data, generative AI, synthetic data, then the latent
variable is upstream, causally, statistically from the data pseudo observation. But that might be
the actual real observation if you're interested in the computer model. Whereas the data recognition
case where the data are upstream of the estimate of a parameter, like a risk score or something like
that, then the parents of the latent state estimate is the data. So that's the recognition
direction. So this kind of covers the whole Bayesian update possibility spectrum in this
essentially Markov blanket, but it could be in face space or time or a few other situations
they explore. All right, three, a worked example. This section lays out the overall pipeline for
how you get from the graphical notation of the Bayesian network, whether it's viewed visually
graphically, like with a variable dependency structure, or whether it's just written out
in terms of the plain text with the analytical, the Bayesian network is transformed into a factor
graph, probably constrained factor graph, discussion for another day. On that graph,
certain messages are passed at inference runtime. conditional and predictive entropies are calculated
as part of the way that this system outputs or is described by different probability distributions
understand in a kind of statistical mechanical way in terms of entropy. And then that is going
to come together into calculation of the objective function, which is the expected information gain,
which is basically conditioned upon the cognitive model of the sampler. So just because the sampling
is active data sampling, doesn't mean that it's going to lead to like an adaptive behavior.
It just means that where the learning rate is perceived to be highest informationally,
iteratively, there is a ranking by which those can be, which this the space of experiments
can be ranked by and it can connect to pragmatic value in terms of epistemic and pragmatic coming
together for the full expected free energy like in the clinical trial. Anything else?
And you'll notice in this story example, they are discussing here, the factors that they have in
their graph in each of their nodes is actually a cosine. So that's why you get that kind of
oscillation in that bottom plot there. So you'll have areas of maximal information and then areas
of minimal information just based on the toy example they have. And this doesn't always have
to be cosine, but in this example it is. And so it just kind of gives you a really good graphical
understanding of how your information gain can be viewed over a sinusoidal sort of oscillation.
Yeah, just to kind of double down on that, if you sample right here on the number line,
or right here, the lines are indistinguishable. So the information gain is expected to be low
under understanding the parameter family that is being generated and sampled from,
which in this first example is the same, same type of equations. Whereas where the functions are
maximally distinct, the information gain associated with reducing uncertainty about which one of those
five the data point is coming from, those are the informative points at the zero on the number line
and far out. That's where just perceiving one point uncolored would give you the most ability to
even perfectly resolve which one of the five situations it was.
So they're right. In effect, this model amplifies or attenuates the amplitude of the predicted
data, depending upon a periodic function of our data sampling policy pi. So here the policy
distribution is like that kind of around the clock direction, which is not a common setting,
but the general idea of sampling amongst a finite set of alternatives, where a control
variable is going to result in the most informative data point, is a theme that is going to be
expanded upon, and also one interesting mathematical move. Once all terms that are constant with
respect to pi are eliminated, we are left with equation six. So equation five comes down to
equation six, or maybe not exactly only five to six, but six has removed all the variables
that don't change as policy changes. So if the question of policy selection is taken alone,
like gradients on policy updating, then everything that's constant with respect to it
doesn't come into like the delta pi, delta something. So it just simplifies it down to
only a function of policy, and that just kind of reflects how like the sense making and belief
updating component is partitioned off from the policy selection component here.
Yeah, you're looking for change in your belief based on the observations that you're gained.
So if it's not changing, it's not as informative in your information model.
Yeah, continuing on equation six there, which is modeling the policy dependent
components of information gain as an objective function that ranks decisions about where to
sample. Equation six is a special case of the third row of table one, which highlights analytical
expressions for expected information gain for a few common model structures. As we might intuit,
the most informative place is to sample data aligned with those in which differences in data
lead to large differences in the predicted data, in which our choice of pi maximizes the sensitivity
with which y depends on data. So here are the categorical, the Dirichlet, and other functions
in terms of how they'd be written out in the probabilistic, like specifying a distribution
way, and then how there's this relationship analytically to a related distribution, which is
an objective function that ranks the information content of sampling the likelihood distribution
in a certain way. And that's closed form in certain situations. And then also they explore
where it's intractable formally. And so then that's where the variational approximation comes into
play. Anything to add? No, I think that summarizes this slide. Okay, section four, function approximation.
We next turn to a generic supervised learning problem, that of trying to approximate some
function based upon known inputs and the observable outcomes they stochastically
cause. Pretty general neural network or latent state observation setup.
That information is composed and concatenated. So that there's a common variable with that's
describing the statistical object that's going to be describing the inputs and the relationship
with the observable outcomes. And then that function approximation from sequential data
in figure three is simulated with random but potentially you could call all of them random.
But this one is a flatter or a less informed and iterated model of data sampling,
just going to show that samples of random data with even this minimal
non information gain driven model has a certain baseline prediction that's associated with
certain choices about sampling sequentially from this generative model. Want to add anything?
Yeah, it's just I like that they highlighted in this that choice diagram there that you can
actually get the inefficient sampling just by random that you start to you can randomly select
two things very close together and you've effectively maybe not wasted a choice but
you know not gotten the maximum gain from that choice that you could have.
Yeah, they write a little bit more about figure three. Figure three illustrates a depiction of
this model as a Bayesian network and a visual representation of the data generating process.
Now they're going to bring in information gain. So they write this is where information gain
becomes relevant into designing a more informed way to sample data than from a flat or a non
updating prior data sampling distribution. It's like equivalent to having a policy prior that's
fixed which might be a heuristic in certain space. They write substituting equation seven into
equation three. So here's that Markov blanket parent child concept and here equation three is
describing the policy dependence on the joint distribution of the observed and unobserved
and this is combined into equation 10. To show what equation 10 does in terms of now that we're
sampling from this distribution or like statistical distributions that this describes they'll
differentiate figure three from figure four kind of like bring in this model change between those
two figures. Now samples are drawn from a distribution whose log is proportional to the
information gain in equation 10. So it takes the flat policy prior and in a fixed way has remapped it
to be proportional to the information gain. So here's three on the right and then four on the right
and the figure uses the same format as figure three but now each choice is sampled to maximize
anticipated information gain and they point to some specific quantitative patterns but also
like qualitative patterns. So want to add anything on figure four? Just that now if you focus on those
choices because that I really did I think like that choice plot there you can see that the walks
around kind of choices around your data space are a little bit more distributed evenly distributed
a little bit less random but you start to get I think a more cohesive sampling of the data
without entire randomness putting things too close together putting selections too close together.
Yeah okay continuing on well they set up the question as this raises the question as to how
many samples should we collect. So within a foraging bout where should one look and then at the kind
of like pulling a layer back in the strategy when should you halt look it like if you have already
sampled all three records from a data set then unless you had some other reason you could fully
stop sampling there but you also might want to have a softer stopping criterion that would relate to
how much information you're gaining from continuing to sample in that way before like halting and so
they include that by having like an exit policy in the state space of foraging possibilities.
So how do you resolve that and answer this question can be drawn from behavioral neuroscience in the
so-called exploitation exploration dilemma and they introduced the notion of sampling costs
to help decide that. So this method is still going to require parameterization and situation
specific modeling of the relative costs versus the relative information gain however at least
there's an accounting that includes costs into the sampling equation to give any possibility of
exiting because if no costs are provided for sampling then the model might just converge
and continue to eke out very small amounts of variance explained if it doesn't explicitly
have that stop option so they take the policy vector the list of locations that can be sampled
from and adds a zero element which reflects the information gained if we were to stop sampling
and then there's a preference over those observations expressed in the c vector preferences
and this brings in the information seeking and the cost averse of imperatives into the same
objective function in 11. Anything to add on 11? Yeah eventually the idea is that it just gets to
a point where you're no longer whatever you set you're kind of stopping like energy to be
kind of breaking energy eventually it's just gonna get to a point where the model just says
hey I've reached what I can you've set this you're not gaining any anything beyond this point
we can just stop at this point which is nice since in the random selection case there's not
necessarily a stopping parameter as Daniel mentioned you could continue to get eke out
very very small marginal changes but you're not going to gain anything else and so you're just
spinning your wheels for no reason so this is a very elegant way of saying hey I've reached kind
of an inflection point of data gain I'm done. So figure five they're continuing in this genre of
three four five and now they've added in to the policy decision which which has an upstream
dependency on the data that's the active policy edge they add in this
cost to sampling so we can explore more however it now includes not just the information gain
driven choices within a trial but it includes a specific probabilistic but decisive stopping point
for that trial as parameterized by how sensitive it is to information gain and preference
so this is one of the most interesting parts and and discussions in the paper
they they ask it out loud a reasonable question to ask at this stage is why bother
with the full information seeking objective and basically how does this differ from maximum
entropy sampling and um let's look forward to the authors or other guests but here's just a
few notes on this because I think it'll be a great place to explore what it really means to do
statistical and physical modeling on cognitive systems they directly contrast maximum entropy
sampling and their whole information gain family against each other and then the rebuttal is in
figure six so just to show figure six for a second the measurement noise increases in variance from
the center of the function domain so the the variability profile of the function is non-uniform
this means this means the amount of unresolvable uncertainty is heterogeneous through the domain
of potential sampler so I in some kind of ways of thinking about what they're really getting at
and just putting this out as a speculation or starting point for for this key technical point
so if there were a case where the latent states were equivariants they had iid variability
profiles then sampling the most variable sensory data is the most informative like if
you're taking a picture of a solid black image then sampling from the noisy pixels is going to
potentially provide more information gain you're reducing uncertainty more about something
it might be overfitting but you can select as a heuristic wanting to sample from where variability
is high at just kind of a first pass layer however as we start to think about richer or
more specified statistical patterns generative models there become dependencies that are sparse
but important amongst all different kinds of things so things that are variable from a sensory
perspective provide high information gain potentially to one part of a generative model
like a screen and static but then other events might be less variable from a sensory perspective
but smaller differences even in that variable relate to some other component of uncertainty
resolution from some other component of the the model like those are going to be the cases where
cognitive modeling does differ from just dispersed decision-making however they're
both going to result in dispersed decision-making profiles like looking at the choices in the
figures but the choices to sample from the less ambiguous parts of the actual distribution
that leads to a much narrower policy path in this cognitive control setting versus in a variability
sampling where it would go for the areas that were just more variable but not necessarily
providing more information question mark
and you can add on this with the maximum entropy or anything
and I would even highlight kind of on the next slide it effectively what it is doing is accepting
that you're not going to gain a lot of resolution in these highly variable regions and so you don't
really have to sample into those deeply because you've accepted that it is variable it is not
something it is inherently variable in the data we're not going to gain a lot of information
from these regions and it's highlighted in blue down there and I think that's one of the big highlight
notes of this figure is this less information gain available in these highly available regions
and that's something that makes this method more robust and powerful when you're dealing with some
of these non-uniform variable data yeah awesome and then the the um streetlight effect is brought in
there so the avoidance of sampling in ambiguous locations is sometime referred to as a streetlight
effect the tendency to search where data are generated in a minimally ambiguous way i.e.
under streetlamp compared to searching elsewhere on a darkened street so I made some GPT-40 images
some fun streetlight and on one hand there's kind of this sense of like is it constraining to look
under only the streetlight isn't that kind of absurd and then there's the joke about how what
the person's looking for is elsewhere but they're still searching under the streetlight
but they're looking for something they they know is elsewhere so that's the kind of
tragic element of it then there's this limited element however there's also this realistic element
which is like well are you supposed to search where you can't sense or outside of where you
are at that moment so how could you you know say that that wasn't just and then this paper is more
framing it as just a general condition of perception like you're in your tactile streetlight
that is the part you can see at all you can have latent modeling of any and other things
but if it's not grounded in some way to a measurement made in a streetlight under the
metaphor where the light allows for observation then you're not connected to data unless you're
connected to that streetlight so that's just a very interesting kind of topic and and reference
that the authors use what do you think absolutely I mean it kind of boils down to you can't
know what you don't know what you can't observe you know if you can only observe what's underneath
the streetlight then you can't really know what else is outside of there and so your inference
necessarily should be constrained to what you're able to actually observe you can't observe the
unknown and so not necessarily in this case um because you don't even know if it even exists
you have no data to confirm or to refute it all right section five dynamic processes so
in that previous example there was a data selection challenge whether it was approached
from the flat fixed prior or all these other kind of subsequent variants with the adaptivity
and or with the cost now there's going to be a time element brought into the underlying
generative model we'll just go quickly here because that's the big point they take the static
distribution that was sampled from and now give the underlying process also variability
through time so this is like a very SPM brain latent state causal modeling type set yeah anything
you want to say on that before we go in oh no go ahead okay okay so they consider processes that
evolve in time equation 12 can be interpreted similarly to equation eight in which the expectation
of the data is treated as a function approximation which now includes a time argument so here was eight
expectation of the data given latent state parameterization and policy equals so on
and then here there is data also being a function of parameterization and policy
and then also bringing in an element with a subscript tau for time uh then you mentioned in
your big questions the different approaches that they raise here with the three ways to
bring temporalities into a model so let's definitely talk about that but just to show
their images seven and eight are the pair for this dynamical section so figure seven shows a
graphical representation of the matrices involved in generating our data and the inferences obtained
after sampling so here it is sampling from a time variance function and then figure eight goes into
more detail and notes predictions based upon current data can be used to inform predictions
about nearby spatial locations and to predict and post it the values of the function at different
points in time so just like you could have a 2d plane grayscale and infer the location of the
streetlight by pursuing like a gradient up the light and then there would be this optimal
sampling like if you just got one observation you would want to sample on a line that was
orthogonal to the one that you couldn't resolve lots of ways to think about this sequential
prediction but now the underlying landscape also changes so there's some
temporal dynamics and then that can be fit with all these different time series models and
autocorrelation and so on however that's specified statistically in the generative model
but this section just shows however you do make a statistical model for time
it's basically going to be the same thing where information is going to be drawn from a distribution
and now time is a variable in that distribution uh they write in this in the previous section we
have demonstrated the way in which smarter optimal sampling may be used to select data
in a manner that balances the cost of sampling or performing further experiments against the
information gained from those samples or experiments each of these examples has relied
upon relatively simple and analytically comfortable linear Gaussian systems next we address active
sampling in a situation where analytical solutions are no longer possible so to highlight the key
formalisms that they're working with in that kind of background section uh or setup section
they kept one thing constant which was that the the generative model the generative process or
however it's considered with the family of equations that the agent is inferring and tracking hidden
states with and that being the same as the actual family of equations that's generating
the function of observations and here that is relaxed so that opens it up to all empirical
settings where you can just say right off the bat we do not have access to the generative model of
those data so we're making a map statistical map with all the associated trade-offs and
statuses of like that genetic data or that transcriptomic data all those different kinds
of data sets starting from a position where it's going to have to be statistically approximated
and it isn't going to be based unless explicitly otherwise on actual knowledge about the causal
elements of the system any any thoughts on that well in something else that they noted in the paper
by adding this time element when they're actually going through the time series the model itself will
preferentially select different data beyond what it just recently selected so time point one it
selects x and y data time point two it might select l and m data so it actually will go through and
select different types of data and it'll take a little bit of time um what the time is variable
but it'll take a little bit of time before it revisits some of that previous data um at a
previous time so by this you kind of have a sliding window of data that you're selecting
over different time periods yeah all right that's all going to come to play in this clinical trial
which is the big final contribution section of the paper in our final example we demonstrate the
potential utility of the ideas outlined above in the context of a more concrete example so
they model the statistical setting here as an adaptive Bayesian clinical intervention methodology
experiment for example the kind that was done during the 2014 West African Ebola outbreak
the active sampling approach advocated in this paper offers two main opportunities to augment
adaptive trial designs first it allows us to adapt the design to maximize the information we obtain
about treatment efficacy so that's the pure sense making information gain learning sampling from
where it's informative not from where like we habitually or prefer to look and then second
to balance and bring together that information gain with costs and that was brought in with
the cost of the sampling section which was done in this paper by adding the stop policy option
which can be probabilistically selected and then as other sampling locations become less
informative or if somebody was just sampled and you know that there's a slow decay through time
then on that subject the stop policy cost would outweigh the information gain from an experiment
and this is also I think will be a very interesting discussion this blows the line between clinical
trial and public health intervention and can be seen as analogous to animal behavior that is never
fully exploitive or explorative but is a balance between the two so how do we think about that
in terms of biomedical and health security and all these different topics and any thoughts on this
before we go into the formalism of the clinical trial just like about clinical trials or anything
yeah and I think that that's going to be like that last point there is going to be a big one
going forward of like how do you balance benefits to the patient benefits to your trial benefits to
essentially the company like there's a lot of different benefits and costs that you have to
weigh into this and so these models are going to get very complicated when you start to distill
this into something especially with health related so it'll be very interesting to see how this evolves
okay so here's how they do it our setup is as follows for each new cohort of participants
we decide upon the randomization ratio to adopt that's the orange subscript r of policy so this
is policy on a randomization ratio there's three options so this is a discrete but linearly ranked
not fully categorical policy decision where one half would be the 50-50 sampling between the two
groups whereas you know a priori that sampling in a skewed ratio is going to be less informative
like if you sampled only from one you would obviously be maximally uninformed about the other
however what's going to end up being reflected in the policy decision to shift to a one-third or
a two-third which is focusing observations on one branch of the study more than the other
is going to focus on the explicit quantitative preference for observations of survival
so that's going to be very interesting to see how the time variable which relates to the
experimental design but by way of modeling the death curves of the participants and how different
preferences for complementary processes of reducing uncertainty about the treatment specific
death curves and not preferring to see death observations because that would introduce the
pragmatic imperative to measure low survival experiments so there's a lot of complexity
in there from the public health side also in this very simple and interpretable way that like this
is like a Bayesian light switch with 50-50 information seeking mode or tilt it one way or
the other to bias observations whereas if no information had to be resolved then the policy
selection would orient towards observing long survival whereas if that was somehow changed
then it would have to be adaptively sampled on the fly and changing these ratios and all that
what do you what do you think about this yeah and what we're going to kind of get into is
especially with these sorts of health decisions you want people to survive like that's your
that's your primary goal in a lot of these you want to see an effect you want to see a positive
effect of your treatment one way or the other you know if it's the placebo that's the positive or
it's the actual treatment that's the positive you want people to survive so this is kind of
getting into that ethics of making sure that when you design these things that you're doing the
maximum good to your participants who you know may not have you know much hope to stand on
doing some of these crises or epidemics or whatever they are experiencing at the time
so you want to design this in such a way that you know you keep them the patients in mind
that is the whole point of this and so by having a Bayesian kind of preference and bias to keeping
the patient alive and the best outcome you're maximizing how the patient's outcome in the
patient's life thanks for adding that another point to make this is from figure nine that's
gonna come up but it really highlights how sparse and few and interpretable the Bayesian
graphical formalism is and message passing which a lot of the equations describe and
the discussion about rx and fur touched upon message passing gives procedural ways to implement this
in computational systems because it's sometimes hard to go from the simplicity of like this
graphical model to fitting it iteratively on complex data sets but it's pretty clear to see
how different variables are upstream or downstream of other variables and also how the time
sampling can be shown to be which is the upstream of data sampled as these other factors are
but it has a separable interpretable calculable epistemic value that doesn't have a certain kind
of connection to randomization ratio for example so being able to have explicit statistical
calculations and directnesses where the follow-up time doesn't influence the treatment group ratio
or the randomization ratio or other processes gives a type of interpretability that the
generative model gives us the equations for and then the pragmatic challenges are about actually
implementing that and then even if the computational component were totally addressed and abstracted
away that would basically center these broader questions which i think the health example is
a great like jumping off point four yeah and uh you have probably recalled from all the other
different uh figures despite how simple this figure is the other figures the the plots were very
basic the models themselves like you just had the three nodes you know converging on the y so
despite how simple this looks you are adding more complexity to these um to these systems and the more
complexity that you add the harder it is the more computationally intensive it is and so this is
that question of how big can you go you know how how many nodes can you add how many parameters
can you add how much complexity can you add to the system before it starts to break down
or not perform as well as you would hope yeah so other than bringing in that randomization ratio
kind of expression of preference this model differs from the prior one in that it's defined
that the kind of cognitive map is not the territory they're different families so that's
what motivates this um approximation approach so this is a simple displacement where still it's a
trackable problem as they'll unfold however the simulation family chosen for the for like the
approximation basically the approximation could apply to any data set but it might be woefully
inadequate like it might fit only one component of it so that's again part of the interesting
question is like how similar does the statistical model have to be or what information does it really
bring in and how to to model or work with an empirical side um but just on a more general
statistical level equations 15 16 17 describe some of the technical details of the incremental
optimization gradient scheme the newton optimization variational plus we'll talk to
thomas et al figure nine is displaying the kind of before picture for the randomized control
trial so here's where that graphical model is that was shown earlier and then here are these two
groups and their survival through time and different sampling uh choices that are made
then just to to jump to figure 10 has the same layout as figure nine but now using the expected
information gain from equation 18 to guide sampling of data so this is just to show the
impact of that active data sampling and it will drop back to the equation uh there are some notable
differences between the choices made in figure 10 compared with nine nine choices 10 uh the most
obvious of these is that the follow-up time selected have been moved later once optimal sampling is
employed this makes intuitive sense as a later follow-up time is informative about the survival
probabilities at all prior times whereas an earlier follow-up time is not informative about
survival probabilities at later time um where it gets in the final uh simulation brings in the
random sampling plus the preference element here's where the symmetry is broken to also want the
measurement of survival as more likely than death which is how the preferences are specified
in active inference um and then the policy switch is reflected in this like um part where
the observations are shifted later because there's there's less than a threshold of information to
gain by having them earlier and then they uh even if there is equal variance i'm not exactly sure we
can ask between the two branches there is uh an over sampling for the group with the higher
survival which in this case was the placebo group so anything to add on this preference element
this is the the like the crux of the whole making sure that you optimize you know the patient's
outcome on this because the treatments in this scenario were not um were not beneficial they're
actually harmful and so throughout the course of the study this by utilizing this model you
actually randomized more people into the placebo group which caused a greater survival of these
uh individuals and so you're you can already see the effect that this sort of methodology has on
clinical trials because you're optimizing the outcome and i think that is exactly what you want
to do in these health decisions in these trials in these things that impact human health uh or
humanity in general you want to optimize the outcome uh and you know in this way you're actually
reducing the overall harm to patients yeah interesting um here's the specification for the
information gain so uh bringing in the the form of the message is required for equation three now
with all these extra components that have been added in with time variability demographic and the
sampling they write out some of the technical details for the approximations in the variational
Laplace and then some aspects about those models which we can ask about but figure 11 basically
shows the big change which is that uh as you go from having a a flat sampling distribution
across time and across treatment groups you can actually do better than that basically by choosing
a sampling regime that makes sense given the costs of sampling so that's just very interesting
because it it really does look like given the the possibility for these two lines to diverge
their divergence would be largest later on whereas if you could only schedule like one
check for every person if it was something that was expected to happen later in life
then sampling all the young wouldn't even make sense so then one approach is like flat
sampling but that is kind of sometimes erroneously called uh like unbiased or or uninformative but
it is very informative and then this is pointing towards how there can be better sampling than
just trying to go flat across the entire latent state estimate if there are priors relating to
something they can be leveraged as part of the probabilistic sampling and adapted to the
data set at the in the end however for picking prior families for the active data selection
that's a big question about how much it will change how the algorithms work so I guess that kind of takes us to the
discussion the paper's focus has been on illustrating how we might make use of
information seeking objectives augmented with costs which gave kind of the exit criterion or
preferences which gives the biased pragmatic part of data selection to choose the best data to
optimize our inferences and they highlight that the maximum entropy would yield identical results
in several of our examples so that'll be interesting like what were the examples where
maximum entropy and the information gain are identical and then what are the real world
or the statistical settings when the variance around predicted outcomes is in homogeneous
how does the full cognitive epistemic model based objective do differently than the max and
distribution dispersal kind of null hypothesis any thoughts on this
no I think you've captured it very well okay then there are several technical points worth
considering for how we might advance the concepts reviewed in this paper so let's talk about each
of these one refinement of the active selection process two empirical evaluation of active versus
alternative sampling methods and three identifying the appropriate cost functions so we'll talk about
those coming up conclusion here's the entire conclusion the key ideas involved in appeal
to foveal like sampling of small portions of the total available data to minimize computational cost
that's a very cool way to put it and it highlights that kind of like sequential scanning but also
opens up some very exciting directions about how efficient that could be for some but not
other kinds of problems and how those problems could be identified or those patterns could be
filtered for to where different kinds of succating models would be adaptive or not so like these are
all fun discussions we'll have and then they kind of brought all the theoretical components together
at the end with the Bayes adaptive clinical trial with the cost of sampling constraints on
sampling and also the preference for survival so what are your overall thoughts or what are you
excited about for the ones to come I'm excited to kind of see me I mean this is a fairly recent
paper I'm excited to see kind of where they have gone since this paper was published you know they
had a number of kind of next directions I would love to see what of those directions have they've
taken what they've compared it to other other sampling techniques this show shows a lot of promise
going forward for very complex and you know ethical situations or situations where ethics
are going to be a huge component so kind of where that is what they're going into and kind of where
they see you know further improvements I still kind of want to know what would happen or what
of these other time metrics or what are the situations these time metrics would or alternative
time models would be applicable to or if this really is like the de facto just the way it needs
to be done totally totally fair I think that could very well be the case I would just love to hear
exactly you know if you did a hidden Markov model how would that look you know is is there a benefit
of that over the selection that they have is there does it provide more or less versatility in the
models these are things that are going to be I think very interesting going forward and then
you know how do we like the like you noted in the discussion how do you optimize those cost
functions what's what's a cost you know you're dealing with clinical trials it's a human life
that's a cost time it's a cost there's also just computer time how much you can actually get
how much compute you can get and give them all the time some of these machine learning models
that you might want to apply this to or you know select data going into sometimes takes a long
time to train how are you going to sample data that's going into those models how are you going
to continually feed those models appropriate data going forward so this is a huge broad category of
um directions that you can go clinical trials was a very wonderful example of a complex situation
that is you know right there applicable to human life um but then you also have just data science
in general like how are you going to utilize this to you know going more broad how are you
going to utilize this just going forward in any data sense data is growing it'll continue to grow
it will never really stop growing so it's going to be more and more important going forward to
have these methods more broadly used and random's nice random's really really good but this holds
a lot of promise to being I would love to just hear their thoughts on where that's going where
they see that yeah a lot of a lot of interesting directions a few things that made me think of
one was about search and about relational search concepts page rank and everything
syntactic semantic new kinds of search algorithms and personalization for search and learning and
updating and to what extent like explicit cognitive modeling would change the way that
different recommendation algorithms or different kinds of computer systems would work I'll read
a question um and then any any other questions otherwise this is our our last slide so thank
you Christopher um okay glia maximalist wrote interesting point about biased and unbiased
sampling schemes perhaps this points out the fact that unbiased approaches are the wrong
thing to strive for in research study design what do you think about that unbiased research
in study design um I think there's a time and place for unbiased and I think there's a time
and place for bias I think that but you when you accept a bias into your model or refute
take bias out of your model you need to understand why you're doing certain bias you don't want to
have you know researcher bias is something that's a huge bias that you want to not have for example
but in certain cases um like in this paper where you actually do want to have a bias
you want to make an intelligent decision know why you're making that decision call it out and then
build it into your model that would be my problem yeah that's interesting like there are certain
statistical distributions the bias or the constraints on which to find the research study
whereas other ones that can have an explicitly strictly negative like data loss or something
but then the trade-offs of how that distribution actually interacts with others can enter into
this more complex experimental calculus that relates to like well all these different
experimental factors and so the optimal experiment for for different labs or different
moments for the lab could look extremely different and that's going to be the case
there's going to be just first behavior out of the way but then the question is how is that actually
driven in a way that is doing better than drawing from distributions however even that does interestingly
well for the right variables and you can mind bias all over the place I bias in data design
in experiments is can be very useful so it'll just be interesting I think it'll be case by case
it's the way I see it
okay well do you have any last comments I think that the main thing here is I'm just very excited
to see this paper come out I would love to see how this is going to evolve over time
see if this can be applied to different technologies different areas I'm really excited
just to see where this is going because I think this is just right on the cusp of what's needed
awesome thank you okay we will look forward to it thank you see you all right thanks guys
you
