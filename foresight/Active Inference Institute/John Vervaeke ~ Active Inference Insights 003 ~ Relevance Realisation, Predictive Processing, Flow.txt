Okay, and we're away. Welcome, everybody, to the third episode of Active Inference Insights,
brought to you by the Active Inference Institute. I'm your host, Darius Parveezy-Wayne, and
today I am absolutely thrilled to be able to speak to John Viveke. John is an award-winning
professor of psychology, cognitive science, and Buddhist philosophy at the University
of Toronto. He is also the presenter of the renowned YouTube series Awakening from the
Meaning Crisis, as well as the newer After Socrates. His work focuses on 4e cognitive
science, which holds that cognition is embodied, embedded, enacted, and extended beyond the
brain. In particular, John explores relevance realisation, our adaptive ability to zero
in on salient information in a world of near-infinite complexity. Last year, he, Mark Miller, and
Brett Anderson wrote the paper Predictive Processing and Relevance Realisation, exploring
convergent solutions to the frame problem, which proposes that trade-offs in precision
weighting, a key second order dynamic in predictive processing hierarchies, are at the heart of
our ability to be intelligently ignorant. And that alignment of predictive processing
and relevance realisation is exactly what we're going to be talking about today. John,
welcome to the show. Thank you so much for joining us. It's an absolute treat.
Thank you, there is a great pleasure. I'm hoping that Mark does make it on in December.
That'll be great. Yeah, absolutely. But in his absence, because Mark was meant to be
here today, but it's unfortunate, he's not unfortunately able to make it. Perhaps, so
this podcast is acting as a kind of primer and introduction for our audience to the critical
themes in cognitive science and psychology and biology, as well as maths and physics,
as they are right now. So I think it would be a worthwhile place to start if you could
just unpick what relevance realisation is, and then we'll come to how it aligns with
predictive processing. Sure. So relevance realisation is sort of inverts the way common
sense works. Common sense is there's a lot that is obvious to us. And you know what it's
obvious what you should pay attention to. We're sometimes mistaken. But it's obvious
what we should be remembering and what we should be doing. And that's all obvious. And
we just run from that. Our job as cognitive scientists is to explain how the brain generates
that obviousness, that salience landscapes that makes the right things stand out as relevant
to us so that we can do what is astonishing, solve a wide variety of problems and a wide
variety of domains. You're a general problem solver, which is just astonishing. I mean,
you can learn Albanian history, you could learn about swimming or rock climbing, you
can take up the study of dinosaurs in the Jurassic period. Like it's just, you know,
it's just amazing and astonishing. And there's good empirical evidence you have something
like a general intelligence. There seems to be a general capacity. There's individual
variation in talent. Some people are better at learning this domain than other domains.
But they're way back from Spearman. We know there's some sort of general ability. I'm
going to propose that the general ability are two interlocking things, the anticipation
and relevance realisation. What I mean by a general ability is these are kind of meta
problems. These are the two big problems you have to solve when you're doing any other
specific problem solving. And what makes relevance realisation so hard, generating that obviousness
so mysterious, actually. And that's what Scott Atrin says. He says that what science does
is it makes what's common sense to take, takes to be obvious, mysterious. Here's a table
in front of me, but physics says, well, what is that really? And they're mysterious and
it's made out of quarks and all this sort of stuff. It's the same sort of thing here.
Because when you think about it outside of common sense, you realise that there's just
an overwhelming amount of information that's constantly, as you said, dynamically changing
in the environment. There's an overwhelming amount of information in your long-term memory
that's constantly changing and being readjusted to the reconstructive nature of memory. There
is an overwhelming number of combinations of actions you can perform, sequences of action.
And yet, you ignore that overwhelming, almost all of that overwhelming information
and zero in on the relevant information so that you are oriented right in the world,
finding things obvious, salient, standing out. And it's not just a single thing. There's
like a salient's landscape. Some things stand out more than others. Some things are more
foreground, background. You have all this happening so that you are capable of solving
so many problems in a messy, complex world in which there's constant novelty because of an
emergent phenomena. And trying to give this ability to machines has been overwhelmingly
difficult and one of the hard, hard problems. We're actually bumping up right into it now
as we finally taken up the AGI project, the project of trying to create artificial general
intelligence. Excellent. It may be worth digging a little bit deeper into that
exposition because people might be thinking, well, don't we just have a module for relevance
or salience? Don't we just kind of, we're born and we know, oh, I should not fall off cliffs and I
should, but actually what happened yesterday might be quite irrelevant. You have a wonderful
explanation in your sort of keynote paper, Explicating Relevance Realization, where you say
that leads to an infinite regress. Perhaps you could explain that argument.
So the magic module, not to be confused with predictive processing's
reported problem of the magic modulators. So let's keep those two distinct from each other.
But the magic module is, well, I have a relevance realization thing in my head that just does it.
And then that just, and then I can just say, well, how does it do it? Then the mistake people can
make is, well, evolution made it. And that's right. Evolution tells me how it got here.
That's not telling me how it functions. Evolution tells me how my eye got here and
how my ear got here. And that's not telling me how my eye and my ear function. I'm trying to
take what's called the design stance. How could, tell me what I need to do to give that module
the ability to realize relevance? All you've done is said it has that ability,
but it faces the problem of, okay, now it has to know what to pay attention to,
and so on and so forth. Now, what you might say is, well, evolution totally prepared us for it.
The problem with that is that doesn't work. Evolution can only pick up on things that are
long-term invariant and that make an ongoing continuous difference to your reproductive
status. And that's not how relevance works. Relevance is really fast and changing. If I say
left big toe, it suddenly becomes relevant to you, and it wasn't relevant a minute ago,
and what's the Darwinian difference there? And there's nothing that's intrinsically relevant.
Well, my own life is intrinsically relevant, is it? You'll sacrifice your life for your kids.
Well, my life and my kids, under all circumstances, saving your kid
means that 10 million people, oh, well, and so on, and we get into all these philosophical
arguments because we realize, no, no, there isn't any hard, fast thing that is always relevant.
Relevance is not something for which we can generate a scientific theory. It's not stable.
It's not intrinsic to the phenomenon. And there's nothing, other than being relevant,
there's nothing that all the events or objects or feelings have in common. What is it that,
what do they all have that makes them, other than saying, well, you'll give me synonyms,
they're important to me, or they help me solve my problems? Yes, that's exactly it. But how?
Exactly. Perfect. And it's so nice to see how the apparently disparate strands of cognitive
science, so Gibsonian affordances for a cognitive science, predictive processing and
processing and active inference, align at this path, which is that everything is dynamical.
Everything is about this mutual unfolding. There is no rarefied static
existence. It's what's relevant to you might not be relevant to me, and there are these dynamic
relationships which govern that. Yeah, so that's a great place to start. I think
let's now go into the solution, if there is such a solution. And let's start with
opponent processing. So this is a term that you use frequently. To a layman audience,
it's not clear exactly what it means. So what is opponent processing, and how does it help
shed light on this complex problem? Sure. And maybe along the way, I can point out how
relevance realization really gives some specific teeth to claims of embodiment from 4-Ecox-I.
Because I'd like the point you made, and maybe we don't have to do it right now,
but I'd like to come back to it, how relevance realization is kind of a glue,
they glue together predictive processing and 4-Ecox-I in a powerful way and makes them all,
including itself, mutually stronger from that integration. But yeah, the opponent processing,
so let's just note something. At many different levels of analysis in your biology,
you will find opponent processing at work. I'll take one that's very easy to explain,
and people have a ready experience of it. So we are all constantly, mostly unconsciously,
although it's affected by conscious factors, we're constantly recalibrating and adjusting,
dare I say it, we're even evolving our level of metabolic arousal. I don't mean just sexual
arousal, don't be Freud here, I mean arousal. How much, how much, how sort of activated are you,
how sort of energized are you? And the problem is there isn't, there isn't some state,
homeostatic state you're looking for with that, because if there's a tiger in the room, I need to
maximal arousal. And if I'm going to sleep, I need to go to minimal arousal, and I can't just be
sort of Canadian and keep sort of average arousal at all times, because then I don't fall asleep
and I get killed by tigers. And so it constantly has to be, like we're talking about, it has to
constantly be adjusting. So what has evolved in your biology is your autonomic, meaning
self-governing, it's a self-organizing system. Like you said, it's a dynamical entity.
Your autonomic nervous system, and what it does is it couples together two subsystems that are,
have opposite biases from each other. So your sympathetic system is biased to, I'll speak
anthropomorphically, just because it speeds things up. Your sympathetic system is biased to seeing
as much of it can of the world as threat or opportunity and arousing you as much as it can.
And your parasympathetic system is biased the opposite way. It's biased to seeing
as much of the world as secure, safe, a place where you can rest and recover. And then these
subsystems are not independent from each other. They're locked together, and they're also, they're
continually trying to shut each other off. And they're constantly competing that way,
but they're cooperatively competing. It's not adversarial, they're cooperatively competing.
And what happens is the constant trade-off between those processes, between those processes,
constantly, right, in very dynamic manner, constantly recalibrate to your level of arousal
to the world. And that's opponent processing. And what you find is you got that, you know,
there's other, there's opponent processing between your focal vision and your peripheral vision.
There's opponent processing plausibly between your left and right hemispheres. The number of these
things, right, it is huge. And I say at many different levels of analysis. And so
I think opponent processing is a clue to how relevance realization is actually undertaken
by your embodied cognition. Wonderful. And immediately to anyone interested in active
inference or its manifestation in continuous state spaces as predictive processing,
what will be screaming out is this notion of an attractor set or our homeostatic equilibrium,
which Karl has spoken about at length, obviously, and has had many other researchers. But this idea
that what this, we are, we suffer, but we also embody in a kind of positive way this itinerancy.
We never, we're never stuck in a single mode. We are endowed with the capacity to
go beyond our homeostasis and return back to it. But we're always, in a sense, being drawn
without ever residing, without ever having stopped at that homeostatic set point.
So let's now fold in active inference to the picture. What does it provide relevance realization
and the formulation of relevance realization that couldn't be done purely with Fourier cognitive
science? So, I mean, I'm going to talk about it in terms of predictive processing, because that's
the one, that's the formulation of it, that lines up most cleanly with the theoretical
integration. As you said, there's there's clear derivation relations between active inference
and predictive processing, and also between them and the Bayesian math, but the Bayesian math, if
you were to actually strictly apply it would be computationally intractable. So we're doing some
approximation function. So I'm just going to take it that everybody sort of shall knows that I'm
playing fair with this, right? I'm not, I'm not trying to be dodgy. And so, relevance realization
is grounded in the idea of problem solving. And problem solving actually assumes a fundamental
thing, which again is so obvious to us, which is the states you're in and the states you want to
be in are not the same state. That's the defining feature of a problem. If I'm in a state I want
to be in, I want to be sitting in this chair. I am. I don't have a problem, right? And now,
what that means is you're all, you're immediately into something very interesting. The organism is
trying to actually predict a possible state in the world and prepare itself, so it's an agent.
It doesn't just behave. It alters its behavior to alter the states in the world, right? And so it is
trying to, I would say, predictively prepare for the world. It's trying to predict the world, but
prepare itself for that world, but also prepare the world so it's more likely to come out in the
prediction that it seeks, right? And so I put those two together, and I talk about anticipation.
And so whenever you're problem solving, you're anticipating a goal, meaning that prediction
and preparation. Now, Fourier coincide doesn't directly talk about that as clear as it needs to.
It talks about coupling, and it talks about affordances, and I think there's a deep connection
between opponent processing, optimal gripping, and affordances, and maybe we can exploit that
at some point. But typically, one of the things where Fourier coincide has some challenges
is in more distal relations to the environment, because it tends to rely primarily on coupling.
And this is a long-standing critique that one of my colleagues, Brian Cantwell Smith,
at the University of Toronto, because that is where all knowledge is flowing from,
right, has made. He said, you know, you can be predictably coupled to things that you're in
direct causal contact with, but, you know, sorry, dynamically coupled, not predictably coupled,
my apologies. But how do you do things that are much more distal? And for me, that is key.
And here's why I do this. I think when we evaluate, even intuitively, so I'm not using that as an
authority, I'm just showing how readily this works for us. When we evaluate an organism for
its intelligence, we tend to do it in two interlocking ways. We do it in terms of, I think,
how well does it zero in on relevant information? How well does it pay attention to what it needs?
We look at an animal and go, wow, that's really good. Notice how it's noting subtle differences.
But we also evaluate the intelligence of an organism, and Michael Levin talks about this
with his cognitive light cone idea, is how deeply into the world they can anticipate. And I don't
mean just spatio-temporally, I also mean it modally, possibility. Like when I talk to my cat and I say,
you know, where's your toy? The cat looks at me and I go, no, well, I say to my puppy,
where's your ball? And she goes into the other room, looks for the ball, finds it under the
couch and brings it all the way back to me. I go, wow, you're really smart, right? And so we get
this because we know how just moment by moment that adaptive ability is built on how distally
can we pursue goals? We tend to evaluate people, wow, you pursued a long-term goal and you brought
it up. So that's what's missing. And I think that's what's really afforded. Now, I want to make one
more point, and then I'll shut up so you can ask me another question, which is these two issues,
anticipating more deeply, and remember, I don't just mean spatio-temporally, I mean modally,
and relevance realisation are deeply interconnected. The more you anticipate, the more the problem of
relevance realisation goes up exponentially. And so these two things, right, they, I would argue,
because they're interlocking, they have to be solved together. And I think that's why we use
both of them as evaluations of the intelligence of an organism.
Okay, I'd like to backtrack to that second argument after this, after what I say here.
Yeah, it strikes me that what predictive processing can give, perhaps where 4e Cognitive
Science doesn't, but I'm happy to be schooled on this. And I know Varela and Autoporesis in some
sense pre-shadowed and prefigured what I'm about to say, is that it kind of gives a ground to
our action and to our perception, which is that we have to have a model of the world and a model
of ourselves, which is not only descriptively viable, but also normatively viable. In so far as,
it's all like, it's very important for me to be able to predict the world. But as you said,
we aren't just at the behest of the world's dynamics, we can change the world according
to our preferences. Exactly. And I think what predictive processing gives us is, although to
be fair, I think Carl might say that this is a bit of an overshoot, is a telos, is a fundamental
attractor set to which our perception of action is governed. So I think that's kind of the way that
I see the added benefit of this convergence between predictive processing and relevance
realization. What I was also going to say there is that it's, fantastically, you're mentioning
this kind of deep temporal modeling. Because from my eyes, that's really where a lot of the work
is being done right now, which is that selfhood consciousness, even perhaps space itself is
downstream on the fact that we can downstream on the degree to which we can model the slower
dynamics and the faster dynamics in a generative hierarchy. So that's, I think that's it. I mean,
complete agreement with that. I think that's an extension of the argument I made.
And so what I wanted to pick up there is you said, if I heard correctly, that the more,
the deeper your temporal model, the more you can model slower fluctuations in the environment,
the more critical relevance realization becomes, the higher the stakes in some sense.
I'm interested in unpicking that argument, because from my eyes, there are plenty of
things out there that don't have deep temporal models. So a virus, for example, you're just
reacting to very coarse-grained features of the environment. But for them, relevance realization,
at least to my eyes, appears as critical as it would for a human.
It is. It is. And so I think it's how I'm going to put it, I think it's always the
demanding problem. So I'm not denying that even the paramecium has to do salience landscaping.
It has to, I'm going to use a word very neutrally here. I'm not connoting anything about consciousness,
but it has to recognize this molecule is food and that molecule is poison and swim reliably
towards the one and away from the other. So I think the problem is always there,
as I was trying to indicate, as soon as you have problems, as soon as your goal states are
distinct. And I think the space opens up very quickly exponentially. I just meant that it
exponentially gets worse. This is why you see across species, hyperbolic discounting,
temporal discounting, because that's a huge relevance realization machine. It's about
salience discounting. And the point of that is, is because as you opened into the future,
the number of possibilities goes up exponentially. And so you need to have this attenuation function,
so you don't get overwhelmed by the possibilities as you extend your cognition into the future.
That's why we have hyperbolic discounting. And we pay a huge price for it. It makes us procrastinate.
It makes us difficult to give up, to pursue our long-term goals. So there's even a trade-off
relationship in there, but I won't get into it. But that's an example. There's a good reason why we
must have something like temporal discounting across species. That's what Angelie showed,
is because the relevance realization issue just, it gets even worse. It starts out bad and gets even
worse. Right. Wonderful. And yeah, I mean, a lot of your work will come to affordances now because
a lot of your work is centered on the notion of affordances. So affordances are the possibilities
for action afforded, actually circular, possibilities for action granted by the environment. I mean,
afforded was a verb and then Gibson made it now. How much has the predictive processing
framework supplemented your understanding of affordances? And perhaps the way that
what we perceive in the world is not necessarily a feature list of objects, but they are fundamentally
affordances. I see my glass of water as grippable rather than being glass this dimension. And I
only ask that because, as I said, as conscious, animate cognizers, we are blessed with the
capacity to change the world in accordance with our priors, which makes action really the fundamental
currency for auto poesis, for self-organization. So does it has predicted processing ramped up
the importance that you give to Gibsonian affordances? I don't have it ramped up because I
always thought I literally learned this stuff from John Kennedy when it gives his greatest
protease. So very early on, I was very much impressed by this. And it occurred to me that
relevance realization, the realization of relevance, and I mean realization in both senses,
actualizing a possibility and becoming aware of it, or at least detecting it in some fashion,
that it's a prototypical kind of affordance. The thing about affordances is they're not found
in the object or in the organism. The grippability of the glass is not in the glass, can't be gripped
by a peramecium. And it's not in my hand. My hand can't grasp Africa or the sun. It's in a fitted
relation between them. And that's exactly what relevance is. It's a fitted relationship between.
So I always, before I came into a deep dialogue with predictive processing, I already saw a deep
relationship between relevance, realization, and affordances. And I think part of my work has been
to really explore the deep ontological significance of that, that we have a category that sort of
falls outside. This was Gibson's intent, too. This is what Forde Cogside is really talking about.
Falls outside are our belief that we have a complete exhaustive dichotomy between the subjective
and the objective, between the inner world and the outer world. And so there's this other important,
why call it the transjective, this betweenness, this connectedness, that you see in
adeptivity, you see in relevance, but you also see it, like you said. Now, what do I think
the predictive processing did? If you'll allow me, I want to talk back and forth symmetrical,
not just linear. So I think what the predictive processing does is emphasize the need to try
and explain, rather than just... I don't want to be cruel. So I'm being a little bit oversimplistic.
I'm doing that just for speed. But generally, it's like, yeah, but how do affordances get actualized
in the Ford E-caller? Like, there's a lot of affordances all the time. And what I'm interested
is, how do those affordances become, well, salient and obvious to me, so they become
binding on my sensory motor behavior. And that was always something of, not that there's Redfield
and others who are doing some work on it, but typically they start to invoke predictive processing
to try and explain that mechanism of, okay, there's a huge affordance network, but I'm not...
Here we go again. How do I select and actualize the ones that actually go into my salience
landscaping? And I think predictive processing, especially with the notion of precision waiting,
is a good job of that. And what I think relevance realization helps to do to predictive processing,
a bunch of other things. But one thing is, predictive processing, basically, there's subtlety
to this, and I know there's lots of mouth, but just to keep going, right, that, you know, well,
what attention is, is the precision waiting? It's this meta function. And I think that's a
very good argument, but there's a conceptual analysis that's been needed, but it's like,
but what is salience? And one of the arguments I can make is, well, what the precision waiting is
doing is relevance realization. And relevance realization, when relevance realization does
a higher order finding relevant of an affordance that has been generated by lower order relevance
realization, that's when something becomes salient to us. And so we can actually give a
conceptual explanation that goes with the theoretical identity claim in predictive processing,
the precision waiting is attention, and what it gives you is salience. So they can, they can
unpack each other. I think what another thing that happens is, relevance realization is deeply
connected to foreecogside, because relevance is grounded, I would argue, in auto-polisis.
Relevance, relevance is always relevant to an organism, right? And so that means,
relevance realization is a cold calculation. It's how the organism cares about some more
information rather than all the other information, because it is constantly taking care of itself.
There are literally, and I mean this physically, things that matter to it, and things that it
must import into itself, important things. And some of that's also information. And so
why that, if you, if you can, if you can glue foreecogside and predictive processing together,
I think you can answer some of the questions, maybe even challenges, that some people in
foreecogside are making of predictive processing and saying, well it's not really connected to
embodiment. I think, no, no, if you show a deep theoretical integration of predictive processing
and relevance realization, and then relevance realization and auto-polisis, then you've really
strongly glued predictive processing and foreecogside together. So that's some of the
important theoretical work that you've done. Yeah, absolutely. I would love to jump into
the critiques that certain foree cognitive research, cognition researchers have leveraged
at predictive processing, but let's leave that for a second. This is exactly what I was talking
about in terms of telos, which is that exactly this notion of care. And when I spoke to Mara
Albaras in an active inference researcher last week, we kind of actually ended up concluding
that this is almost the Heideggerian sense of care that we take from our existence.
Can I, can I just interrupt there? Yeah. Right. Heideggerian sense of care was exactly what I
was invoking. And I, right, and I was deeply influenced by Dreyfus and the frame problem,
got this from Heidegger. Yeah. So the connection you just drew is very, I, I, yeah, I explicitly
argue for that. Excellent. So yeah, I mean, I personally think that the Heidegger, Heideggerian,
Dreyfus, Merleau Ponty lineage needs to be integrated more into active inference. And I'm
speaking to Dr. Marilyn Stendera, who has done work on Heidegger and auto-poesis. So that will be
really, that will be really fun in the upcoming weeks. This is exactly what I was talking about
in terms of telos, which is that taking a stance on your own existence can be computationally
modeled as having these kind of high precision priors. So our homeostatic set point will be
different from a snake's. And that actually gives a really solid explication of why we act
differently in certain contexts than snakes. And so that was my kind. But then that said,
I will have to make clear that Carl is in himself, although he has spoken about existential imperative
says that there actually is no imperative. All that you're really saying is if a thing like us
is to persist over time, this is what it needs to do. And it's just a, it's just cast as a
minimization of free energy. So I think there's an interesting question there that maybe you
could have a go at, which is to what degree do you see this as a genuine imperative versus
just what things do to self-organize over time? Yeah. And so I mean, and Carl's no
slope, so he's welcome. I sometimes don't like it when people who, you know, are physicists or
something start commenting on philosophical normative questions with an authority they
don't properly possess. But I know Carl's a great theorist. And I know he's philosophically educated.
I have not yet to talk to him, but I hope I do get to do so.
We can do ahead. So yeah, I mean, so I'm going to argue later if I get a chance that what
relevance realization doing is strongly analogous, obviously a very different timescale to what
evolution does about constantly redesigning the adapted fittedness of the, of organisms to the
environment and allowing organisms to fit their environments to them. Because as you keep emphasizing
and I keep agreeing with, it's not passive. It's not right. The organism is shaping the
environment as the environment is shaping the organism, niche construction and all that sort
of thing. And I think that's all right. And then there again, that's a very clear connection to
40 cogside again. But this deeper question, I do want to do it. I want to pause and I want to
slow down because it is a really important question. Because it gets us beyond what we might call
scientific explanations of how and into properly, but not useless, philosophical reflection of sort
of why. And why does this matter to me? Because as you've mentioned, I'm deeply concerned with,
you know, issues of meaning in life. This, this, this largely metaphorical, nebulous notion that
humans seek meaningful lives, lives that are worth living, even given all of our failures and our
faults and our flaws and our foolishness and our frustration, right? And pretty clear empirical
evidence that it's not reducible to just subjective well-being or pleasure and pretty good conceptual
philosophical argument, because that's where it's relevant, that it's not reducible to just living
a moral existence. You could live a very moral existence in which you're sort of experiencing
the pleasure of food and other things. And, and, and you've got, you know, certain stability in
your environment that you could be very, very lonely. You could be very lonely. So, and what,
what that loneliness points to, I'm just making an intuitive gesture. That's not a tight argument.
I have tight arguments, but the gesture is people are seeking a kind of connectedness. And now you
see where I'm getting to relevance realization and what we're talking about this niche construction,
the fittedness, the belonging togetherness, this mutually shaping, like this is this,
I argue that that's exactly the connectedness human beings are seeking the meaning in life.
Now, you can then ask the question and people, and I'm going to play with two
terms of phrase here to play with that. I think we clearly seek meaning in life.
I think the evidence for that is growing and it converges with the psychological work on
meaning in life and on what Karen Allen calls belongingness. If you don't feel that you belong,
you're in trouble and you're in trouble across all these measures, cognitive, emotional, social,
financial, blah, you're in trouble, physiologically you're in trouble. That's why solitary confinement
is such a punishment, right? So, is there a meaning of life to the meaning in life?
The meaning of life is that is there some sort of cosmic destiny, cosmic order to which we are
which we are ultimately trying to find. And here's the thing, I don't think I have enough evidence
for that. I think that there's lots of evidence for meaning in life and if I'm right that it's
relevance realization and if that's something very much like evolution, right? Evolution is
constantly redesigning adeptivity, but there isn't a final thing that evolution is aiming towards.
There isn't a final form of life. There isn't some like what we're doing is
like the sculptor, we're constantly refining and then finally one day we will have the final
form of life. And I think this is fundamentally flawed and I think this matters philosophically.
I don't think previous forms of life were in some in any kind of moral sense superior to us.
So, I don't believe in any nostalgias. Some of the previous things that people found important
and relevant and sacred, those were the true ones and we just have to get back there. Nope.
And I don't believe the utopia. We are working towards the final ultimate thing that will all
agree for all time is the most relevant, most salient. I don't believe that's how this works.
So, I reject nostalgias. I reject utopias. The idea that there's a telos can either mean
there's a telos to meaning in life, which is it's like Carl says, it's necessary,
it's constitutive necessary for living things to have this. But does that mean there's any
metaphysical necessity to their being living things? That's a different question. Now, here's my
weak answer at that one. Sorry. Long question, but you asked like this is like almost up there
with like God. Yeah. Right. Right. I note that I'm in a very difficult situation. I can't see any
evidence for and I'm not attacking God here. And as you know, I'm very respectful and even
appreciative of religious frameworks and religious lives. But I can't see any evidence for that.
However, if you were to ask me, which is a better universe, one with life in it and one without
life in it, even if you couldn't exist in either one, I would say the one with life in it. There's
some primordial judgment going on there that has some kind of metaphysical import. Now, it's weak.
I admitted that ahead of time. And so I'm giving you a very, I'm sorry, very long but wishy-washy
answer. I don't really think I believe in anything like the meaning of life, but I do think there's
a metaphysical import to being connected to reality. We find reality being connected to reality
inherently valuable for its own sake. And we find worlds in which things can realize reality
better worlds than ones that don't have that in it. That's my answer. No, it's a wonderful answer.
And it, it's really helped me and hopefully our audience clarify exactly what I mean by
an existential imperative, which is that the free energy principle doesn't tell you
what you're here for. No, it tells you if you're here, what are you doing? Like I've given your
phenotype and given your culture and etc, etc. So that's a really useful sort of explanation
of exactly what I was going for there. And actually, it points to something I said to
Carl right at the end of our podcast, which at the time of recording this came out yesterday. So
people should definitely check it out because he's, for sure, for sure, he's on top form,
which is that I asked him, I mentioned Thomas Nagel. So Thomas Nagel has this very romantic
philosophical notion that life is deaf is bad because life is fundamentally good. And it points
to kind of your thought experiment. If we had two worlds, one with life and one without life,
I think we would all intuitively say the one with life is better. Whether that has any
metaphysical input, as you say, is up for grabs. I was going to ask sort of jumping on the back
of the initial thing you said, which was about connectedness and belongingness. So if we take
this from a theoretical or computational stance and active inference, what this looks like to me
is we embody a model of the world which we can so we can make fundamentally sound predictions
about how the world will unfold and how about we will and how we will act to make that world more
compatible with our preferences. Now, when that was formalized initially in the active inference
literature, immediately a response to this came in the form of what's called the dark room problem.
So this is sort of papers in 2011, 2012, and they've been rebutted in multiple ways. But the
basic idea is why don't humans just seek out dark rooms where maybe they have access to food and
water, but they don't really seek out, but in a state where they don't go and explore and they're
not curious. Because what you're saying there is actually a perfect coupling between your predictions
of the world and the way the world is unfolding to your eyes. So I was wondering whether you had
pondered the dark room problem and where you see exploration and epistemic affordances coming into
play here. Yeah, I think that the dark room problem, I'm not, I'm happy with all the other
rebuttals. And I don't know, I don't know, I don't know them all, so I may be stepping on somebody
else's toes. So if I am, whoever you are, I apologize. I think this is a lock-in individualist
model of cognition and how we work. And I think it is therefore the presupposition, well, is that no,
that's actually, I don't agree with that presupposition, that our cognition is fundamentally
individualistic in that way. I think we are, you know, we are socio-social cultural mammals.
And let me point to one thing, you know, yes, measures of G are very robustly predictive,
but you know, it's also really a very powerful way of predicting your behavior,
your attachment style. This is also very robust. Now, that means, think about what that actually
means. And this, you know, and this goes into the heart of religious traditions, like agopic love,
right? When you have a child, you have to invert your relevance arrow. It's not how
that being is relevant to you. You invert everything around. This is agopic love,
and it's how it's different from erotic love or philea love. You invert everything around,
right? And so that it's, how am I relevant to this being? How am I relevant to this being? And
how can I be relevant in a way that turns it into a person, turns it into an intelligent,
rational, self-reflective, relevance-realizer, predictive processor, meaning maker, right?
And so, well, first of all, where are my attachment relationships in the dark room? Well,
there's other people in the dark room. As soon as there's other people in the dark room, all the
problems that you thought you got away from by putting me in a dark room return. Other people
have different goals than me. They have different needs. They're going to move around differently,
right? That we're going to have to decide about when and where and how we gain access,
blah, blah, blah, blah, blah, blah. All of that immediately unfolds. Secondly, and this is part
of 4E CogSight, I think the evidence for extended cognition, distributed cognition,
that we evolve to work in groups, and the collective intelligence of that is actually
our superpower, and other people are making this argument. I think that's clear. The standard thing,
take the Waste and Selection Task, put it an individual person, highly educated, highly
intelligent, second-year psychology and top-tier university. From the 1960s on, you put them
in the Waste and Selection Task, and only 10% get it right, right? You replace that same task
with four people who are allowed to talk to each other, and their success rate goes from 10% to
82% reliably. Why? Because we do opponent processing between each other. You have biases
different from mine, and if we work in opponent processing, not adversarial, but if I say,
you're probably a good source for correcting my bias, and I'm probably a good source for correcting
yours, we get the best dynamical self-correction possible. When you add in the fact of the reality,
and there's actually evidence, empirical and formal, for the power of collective intelligence,
the reality of attachment, well, then the dark room becomes filled with other people
who are trying to band together to solve problems that they can't solve individually, and then,
to me, everything that the dark room thought it had as an absurdity, like a reductioid absurdum,
disappears. That would be my response. Yeah, I think eventually the dark room just becomes the
world once you start asking the things you need, eventually it becomes a civilization.
Yeah, I love all this stuff on distributed cognition. I spent the first six months of this
year working at UCL on finding experimental ground for what's called social baseline theory.
Social baseline theory is this idea that humans, like to study a human being in a lab by itself is
to study a human being at deficit. Yes. Actually, it's physiological arousal to take one factor
is at its baseline when it's with other people, and it will fluctuate according to stuff like
attachment style or the relationship that one has with that person, which is really beautiful,
but inverts our kind of, well, maybe not common sense, but our institutionalized notion of what
it is to be a person, which is kind of alone. Yeah, wonderful. Well, I'm going to take this
argument a little bit further if you let me, because this is something that we spoke about a
couple of months ago, and I think Mark might have a different opinion, so it'd be cool to
unpickle this. I have this slightly fuzzy, wishy-washy idea that the notion that, okay,
so I always think about a climber climbing a rock face or a climbing wall. The climbing wall is a
kind of beautiful canonical example of an affordance based landscape. It's rich for the affordances.
It's got the toe holes, the finger holes. So in many ways, what the rock, in terms of active
inference, what it allows the rock climber to do is to self-evidence or find evidence for its own
model about itself as a successful rock climber. Now, that's relatively well established in the
literature. What isn't established is my kind of, again, slightly wishy-washy idea, which is that
the rock climber is offering affordances to the wall. And so this is why, right at the beginning
of our conversation, I spoke about mutual coupling. So what dynamical systems theory gives us,
what auto-polysis gives us, what active inference gives us, is this idea that to exist is not to
be this kind of reified self that takes a objective stance on the world. And actually, what it is,
is this really the fundamental unit of analysis should be this dynamic mutual coupling between
agent and arena to use your terminology. I've spoken to Mark about this, and he
said it's something like an overextension of the term affordances, to say that the human being is
offering affordances to the climbing wall. I know Mark isn't here to defend himself, so again, I'm
not going to put one... But I will definitely raise this with him again. But just to your own
ears, how does that argument sound to you? I like the argument, and yeah, I don't want to speak
to you, but Mark, I'll only speak to the propositions that you spoke on his behalf. And I'm very happy
to... I mean, Mark and I work close together. Mark is one of the best people I know.
Mark's a former student of mine. I'm very proud of Mark, so... But I actually agree with you. Now,
that goes to another connection I make in my work that would probably be a little bit stranger
to the ears of many of your listeners. They might say, oh, I get why he wants to connect
to process inter-relevance realization and the 40-card side. But now what you're doing,
and this is where I do a lot of what I call my deeper ontological work, and this is where the
Heideggerian stuff really comes to bear, is this is all the work I do on neoplatonism,
which may sound like something very arcane. But again, here's the proposal that once we
really profoundly accept affordances, and once we accept that they are reciprocally realizing,
I agree with you, that affordance not only discloses things about me, it discloses things
about the world. And that's a way in which things, like Heidegger's notion of truth is alifea,
as an event, as the disclosure, rather than a static property of our propositions.
I think that, bang on, now, as Filler argues, and I've been arguing for a while, and John Russen,
Filler's book is called Neoplatonism, Heidegger and the History of Being, Relation as Ontological
Ground, that relationality is actually the ultimate nature of reality. Heidegger is actually turning
back towards this, because what does that give you? If you have that, and I think this is a fair
way to put it, if you have that alethetic notion of affordance, then you are getting back to the
neoplatonic theory of knowing by conformity, knowing by participation, and the deeper argument
goes something like this, that if the fundamental grammar of your cognition, I don't mean the content,
your content can go wrong, but if the fundamental grammar, the bottom up, top down, all this stuff
we're talking about, if it's not picking up on something fundamental about how reality is structured,
right, then you face the kind of profound solipsism, a profound kind of skepticism.
And I think that is ultimately leads you into all kinds of performative contradictions that I
and I agree with Whitehead, there is devastating as propositional contradiction.
There's a longer argument there, and I could point to, please check out some of my talks
on YouTube about this longer argument, like Pickstock's Aspects of Truth, where she said,
all the things we use to decodemize this, we had the analytic synthetic distinction,
that is broken down under philosophical criticism. We had the theory fact distinction,
that is broken down. We had the, like, is, ought, that has broken down.
Like, think about the relevance, it is or not, well, blah, right, it's sort of both, right?
And so her point is all the things that were used to cleave, and then what we tried to do
is we tried to make the logical world, the thing that sort of stuck the two worlds together,
and that collapsed under Godel and other people. And so we're back to the idea that we either go
into the Lockean cabinet, in which we're locked inside of our heads, we're somehow getting postcards
sent to us, we think they might be from an outside world that we think might be out there,
and we're trying to build it from the postcards, and we're doomed, that's never going to get us there.
And so I think if you have an allothetic notion of affordance, you start to make the argument
that how reality is realizing, and how we are doing relevance realization, are fundamentally
participating in the same principles in a profound way. And I think, yeah, I have no doubt that Mark
might not want to do this. I think Mark would be, I would agree with Mark that this is not a direct
derivation from sort of classic Christonian presentations of active inference and predicted
processing, Bayesian brain, we should settle on a name. But I think if you make the connections
through deeper into Gibson, deeper into Foricog side, deeper into Heidegger, you get back to this
notion that with the prevalent notion of knowing, that when we know something, what we're doing is
our structural functional organization is identifying with the structural functional
organization of the thing. And we are both participating in that same form, that same
principle, that same grammar. And that has all kinds of metaphysical and ontological consequences,
even ethical consequences. It means talking about the truth of good and the beautiful becomes
something very relevant again. Yeah, yeah, no, this is exactly where I wanted to go and exactly
aligns with the way I'm thinking about the free energy principle at the moment,
which is I have a skepticism between the internal and the external distinction.
Yes, it's something I spoke about with so a classic problem when one starts reading active
inference, as I spoke about with Carl, is whether one would consider the the agent or the internal
dynamics is having having a model of the external world or instantiating a model of the external
world. Yes, excellent, excellent. And since it's come back to sort of cybernetic formulations
of what it is to be a good regulator. So Colin Ashby and all of that stuff from the 50s and 60s.
So I have an inherent skepticism because I would I kind of take the stance that actually all that
the internal dynamics are doing is instantiating a particularized form of the external dynamics.
And this is very easy once you take out the picture of a homunculized ego. Just if you look at it in
terms of just the particle physics, we're just a instantiation of some of the physics that defines
everything else. But we just we just actually seem to have a kind of complexified Markov blanket or
Markov blanket form of that. But there's nothing particularly distinct about that. And we'll come
to consciousness because maybe there is. And that I guess is the big elephant in the room here.
But it's funny that you mentioned Heidegger because Heidegger to my to my eyes, and in my
opinion, and then obviously Dreyfus and Merleau Ponty and the phenomenologists followed Heidegger,
really, he's the one who strikes at this established distinction between a subject and an object.
So the Cartesian distinction. And then this is where his kind of gripes with Sartre came in.
Now, my question is, is that, yes, if you read Heidegger, Dasein, the ground of Dasein is this
kind of interrelationality. Alpha is the disclosure of truth in an interrelational relationship,
so to speak. But there still seems to be some kind of subject who, you know, the the hammerer who
is hammering away at the nail. Now, from the perspective of the hammerer, he's not some
reified ego who is objectifying the nail that all that is really being witnessed there from the
level of consciousness is the disclosure of activity. But still, we can give a description of a hammerer
and a nail. So to what degree in your thinking, do you completely eradicate the subject object
distinction? And is there anything that you think predictive processing has to say about that?
I think, well, the second question.
I'm happy to think about it with you. I have put a lot of thought into the first question.
And so, I mean, I think Filler is right in his book that our subjective objective divide is our
version of the appearance reality distinction. And it's just our version. In the ancient world,
they had a different version. So ours is an in out metaphor. How is the inner and the outer
connected? And the ancient world is the problem of the one in the midi. How is the lower and the
upper connected? And once you see that, you realize that there's a deeper structural problem that
isn't bound to the inner outer or the emergence and the emanation. It's the connectivity issue.
And what Filler argues, and there's a lot of other people converging on this, is if you try to,
if you go with an Aristotelian metaphysics, or that what's most real are substances in the
Aristotelian sense, which are things that can independently exist, then this becomes a big
problem for you. And that kind of ontology, I would argue, and I can make the argument,
drives you towards a nominalistic epistemology. And then you get, you know, Occam's version of it,
or Kant's version of it, where all of the patterns and all the information are just in the mind,
which means the mind is radically other, because it is the only place that the information
intelligibility actually exists. And the world is profoundly absurd in a deep, deep way. And I
think that leads you into, well, first of all, it makes science impossible. And it leads you into
all kinds of existential and moral dilemmas. And if you then take a look at the logic of trying to
get, you can't actually, and this is what Filler does very carefully, you can't actually get relations
out of properties that belong to the Relata. The relation has to precede the Relata in a very
important way. So I think there's a deep, at a very deep level, I do want to call it into question.
I do want to challenge that. First of all, it's historical. It's cultural. We pretend as if
that is the only way in which human beings have related to the world. Like I said, even in the
West, that's not their problem in the ancient world. Their problem is the problem of the one in
the many. It's not the problem of being in the world. Now, what does this all ground in? I think
this grounds in the common problem of the relationship between appearance and reality. And
here's where I could now say something that aligns with my previous argument about relationality.
See, so, and I'm going to borrow a term from rapport here, the hermeneutics of suspicion. The
hermeneutics of suspicion is that a parent, and we got it because of Freud and Nietzsche and
blah, blah, blah. There's historical reasons. And those are valuable critiques, by the way.
But the hermeneutics of suspicion says that appearances are distorting. They're deceptive.
They're destructive, right? They're disruptive. And what we should do is always question whether
or not they are leading us into reality. Now, Marlo Ponte has a great argument against that,
that he gets from, maybe he doesn't get, but it's in Plato, which is, wait, you're treating real like
red. Like, you could just say, if you could look at an isolated thing and say that's real.
But real is a comparative term. So, of course, is illusion. To say this is an illusion is to say
this is an illusion in comparison, in relation to something that is more real. And that thing
is in relation, so on and so forth, right? And what that means is, first of all, you have to see
that those judgments are inherently relational. And secondly, you have to call into question
the independence of the hermeneutics of suspicion. The hermeneutics of suspicion is actually
parasitic on the hermeneutics of beauty. It depends on there being things that we agree on
by saying that's where appearance discloses reality rather than distorting it, right?
And then as soon as you do that, that undercuts the deep divide, because you ultimately make these
divisions between the one and the many, or the subject and the object, by getting a hermeneutics
of suspicion into the appearance reality distinction. That's at least the argument I would make.
Interesting. Yeah, I like the suspicion of binary-ness inherent in all of this. It speaks
to me, and I think it speaks to people who are interested in active inference, and the notion
of sort of philosophical vagueness as well. At what point is something real? It's fundamentally
a comparative term in the web of things that could be considered real. Yeah. That's right.
Yeah. I'm trying to do this without invoking a binary, but you mentioned earlier that four
E cognitive scientists do have their critiques of active inference and predictive processing.
I will stick with active inference actually for now, and I will explain why later. It's not that
interesting. So this is people like Tony Camaro or Ed Bags who are radical inactivists, and what
they're critiquing, in a sense, is an interdelist picture of active inference. Again, I'm not putting
words into people's mouths, but if you read Jacob Howey's 2016 paper about self-evidencing,
some of the language may to some people imply that there is a homunculus that has a representational
picture of the world. This, to the ears of an inactivist, is deeply worrying. I would love to,
as a four E cognitive scientist with obviously a vested interest in predictive processing as well,
I'd love to just hear your take on that debate and, again, without striking up binaries,
and whether you think those critiques are legitimate.
Well, I mean, it depends what you mean by legitimate. I mean, there's also the ones
that Evan Thompson made, and I hold Evan in a very high regard. I mean, they're legitimate in that
they are well-made arguments in peer-reviewed journals, and so we have no right to be dismissive
of them. Well, if I was to say that let's take as an axiom of active inference. This isn't your case,
but let's just say, for sake of argument, that you have some interdelist representations of a
statistical model. So you are, in a sense, you're not just embodying a model. You actually have a
model. So again, it comes back to that distinction we're talking about. Would an inactivist critique
of that internalism be justified?
So the reason I'm hesitating is this is landing on the swamp of what do we mean by representation,
which, I mean, so does the thermostat represent the temperature in the environment?
And everything I'm going to say is controversial because of the swamp. So I want that understood,
please. I would say no, because what's needed is there might be some, there might be co-variation,
but what I think the critiques of the co-variation model of representation locks ultimately model.
So we had the idea that representations have to be similar to what they represent. That's how they
represent. And then you have all the problems with similarity and Aristotle even could bring that down.
And then lock replaced it with the co-variation model. To have a representation is I have something
in my head that reliably co-varies with something in the world, and that's how it represents it.
And then the problem with the co-variations is they don't give you the specificity, for example,
of thought. So this is co-varying with a bottle, with a tool, with a man-made object. Which is it?
Those are not the same things. Those are not the same ideas, but this is co-varying causally with
all of that. And you have the problem then of aspectualization. And the Lockian answer, of
course, is we get aspects by doing representation. But I agree with Searle that that's the wrong
way around, that any representation is inherently aspectual. When I represent this as a bottle,
I'm only picking up on some of its properties insofar as they are relevant to each other,
insofar as they are relevant to me. So representation depends on aspectualization,
which depends on relevance realization. And this is not what you do with relevance
realization. You do not represent all the facts, judge them to be irrelevant, and then zero in.
So it's ultimately non-representational. So what I would say is, I don't know that some level,
there's something like representations. But if I agree with many arguments that representations
are more than co-variation, but there's this kind of caretness and aspectualization through them,
then they depend on relevance realization, which grounds an autopolicist and is deeply
intertwined with predictive processing. That would be my response.
Splendid. And I guess what intuitively supports a more representationist picture is consciousness.
I think consciousness is going to become a recurring theme in this podcast.
Well, it's the Holy Grail, right? It is the Holy Grail. And so I guess my question here is,
is that if one was to adopt a radically inactivist view, there's nothing in that picture which
needs consciousness. So why couldn't my mutual coupling with the world just happen with the
lights off? So this is an argument, I guess, that's rooted in Chalmers 1995 paper, which is,
you can give me the function, but you can't give me the why, why are the lights on? And so I guess,
in other words, my question too is, yes, that we may have relevance realization,
preceding perception or grounding perception. Then why do we have perception in the first place?
So again, I'm going to give a gist of an argument that I've spoken about at length elsewhere,
and I'm trying to get published on and presented at conferences and so forth. So
I don't think you can separate the function and the nature questions, which is what
Chalmers Hard Problem relies on. Yeah, you've given me the function, but you've told me nothing
about the nature. I don't think function works ontologically like that. I think function has
to be plugged into the ontology. And I think as soon as we're talking about the ontology of
anything within a living organism, we're talking about something functional. So I think the questions
have to be answered interconnected. So let's go back. Let's say that you give me
that any cognitive agent has to be doing anticipatory relevance realization, or it's
not going to be a general problem solver. And then when it's doing that, it has to be
aspectualizing its world. It's not doing all of this, but this as a bottle or the molecule
as food, the molecule. And then if you then start to pay attention to,
let's look at the continuum of consciousness. Let's look at the possibility, which I have
experienced. That's not even the right sentence. Many people have, and this is Foreman's idea,
of something like the pure consciousness event. And the pure consciousness event doesn't have,
well, actually, I need a distinction here. I'm going to claim it doesn't have one type of
qualia, but it has another type of qualia in it. It doesn't have adjectival qualia. There's no red,
there's no blue, there's no cap, there's no dot. You're not even conscious of consciousness,
you're just conscious. But what it still has, is it still has the adverbial qualia.
It still has a sense of here-ness, noun, and the here-ness is profound presence. That's the language
with you. The now-ness, eternity, the integration, right, the together-ness, it's everything is one.
So all the adverbial qualia are still there, and you still have consciousness. That shows
that the adjectival qualia are not necessary to consciousness. Now, I have the other arguments
to show they're probably not sufficient, because if I give you sort of atomic blips of blue-ness
and green-ness, and they're not bound together, and there's not a here-ness and a noun-ness,
so you can anyway orient on them, I don't think you have consciousness either. So I'm not saying that
adjectival qualia don't exist. I'm saying that we've held consciousness hostage to them. And
what I'm proposing to you is that what consciousness is doing is these adverbial qualia,
which are just salience, which is just relevance realization, which is, as far as we can tell,
tied to the best evidence we have, it's all controversial, about the function of consciousness.
It's tied up with working memory and attention, which are both doing higher order relevance
realization. We seem to need consciousness for situations of complexity, novelty, or ill-defined
in this, ones that are really demanding on relevance realization. So you can make a pretty,
and there's a lot of convergence, actually, on what the function of consciousness is,
relevance realization. And I think if you plug in relevance realization, you can at least get
all the adverbial qualia. And that, I think, gives you a lot of what consciousness actually is.
Cool. Yeah, let's stay on that adverbial qualia, because I'd like to integrate what you've just
said with a more active inference account of consciousness, which there are, and then they're
also diverse. But one, well, I have to ask a question before, does Foreman say that mind-ness,
so feeling that this experience is mine, does he, is that one of his adverbial qualia that
persists in the pure consciousness event? So that has another thicket, because the debate about,
this is a raging debate. Evan Thompson actually has a good anthology on this, on the self-no-self
debate. Right. And I think it's reasonable and complies with most of the evidence, which
of course is self-report after the fact, which is problematic, blah, blah, blah, blah. I agree
with all of that. I'm not dismissing that. But that's what we basically have to go on right now,
that the ego narrative sense of mine and me and I goes away. Whether or not that is a complete loss
of the self as where relevance realization is happening or something like that. I'm not convinced
that that second thing is the case. I think, so if you would allow me, and this is a torture
distinction, a distinction between the ego and the self, I think these experiences very much,
the ego goes away. I'm very suspicious of the claim that the self goes away, because people are
readily able to recall these experiences. This is what Forman does report, and I would report to you
and seamlessly integrate them into their auto-noenic autobiographical memory. There isn't any weird
disjarring or where was I during that? Yeah, yeah, yeah, yeah. Okay, excellent. The reason I asked
that is because a lot of self-modeling in active inference is based on the work of Thomas Metzinga.
So, Thomas Metzinga is such a wonderful addition to this conversation. I had a wonderful conversation
with him not that long ago. Oh, really? I love it. But on my show. Amazing. I think he's such an
underrated and important philosopher. Oh, I totally agree. Yeah, yeah. So, he's got this notion of,
so he makes a distinction between phenomenal self-modeling and an ontological self. So,
people intuitively, even everyone listening to this podcast, even the way we act on a day-to-day
basis is in lieu of an ontological self. So, we can't help but really think of ourselves as being
this soul, this Cartesian soul. But anyway, Metzinga invokes this notion of phenomenal
self-modeling, how the system appears to itself. And he's got this minimal phenomenal self, which
has been unpicked in other ways, but he normally speaks generally of presentness,
minus, and perspectivalness. Exactly what I've been talking about. Yep, exactly. And he gets
fleshed out in some of the active inference work. People like Jakob Howie, Carl, and Jakob
Limonowski have used Metzinga's work for several papers. And then, on the other end of that, we
have what Carl turned an epistemic agent model, which is the system that sees itself as epistemic
in the sense that it can retrieve past memories to inform future decisions, and agentive in the
fact that it can conduct allostatic action, i.e., action to retain some homeostatic equilibrium,
given what it knows about the future. So, me putting on a jumper before I go outside,
because I know it's going to be colder outside than it is inside. The reason why I invoke the
minimal phenomenal selfhood is because, and Carl actually outlines this in the podcast we did
together, that consciousness may be downstream, in a sense, on one, a deep temporal model,
and from that, the sense of agency. And he has an argument from referring to dimensions,
not in terms of sort of millimeter size, but in terms of the degree to which you have embedded
markup blankets, that when we're distant from our actuators, what we end up doing is we have to have
a way of distinguishing what's my action from what's your action or from what the world is,
how the world has acted on us. And in doing that, we come up with a self other distinction, but
also the notion of an agentive self, the idea that I can change the world in accordance to my
preferences, as I mentioned beforehand. So, to paraphrase Carl, what that seems to be
suggesting is that consciousness is actually rooted in selfhood. And I know there's this whole
argument in Metzinger about whether that's the case. That's why I asked whether mindness
is also part of these pure consciousness events, or whether it's kind of a post hoc inference.
Just wondering whether you had any ideas about that notion, and whether we can truly have
consciousness without at least the sense of self. Right. Okay. So,
let me try a few things. First of all, I don't think it's inevitable that human beings model
themselves as souls. I think that's a Western post Cartesian way of, and that's even, and then the
soul as a monadic single substance, I can put it that way. That's not even the case in the ancient
world of the West, certainly not the case in other parts of the world, etc. So, I hesitate that
that's the claim that's part of how the machinery must unfold. And then secondly, I worry about
saying that because it isn't a soul, there isn't a self. This is a weird notion, again, of a substance
ontology being just presupposed in an unquestioned manner. I mean, look, we've discovered most things
aren't substances. This table, which would be a classic Aristotelian substance, is not a substance.
It's a dynamical system of atoms and quarks, and we don't go, oh, well, because tables aren't
substances, they aren't real. Like that, we don't do that. And so, I want to just
note that I'm worried that there's a substance ontology creeping in here and leading to certain
conclusions. Now, that idea about this, I can't remember the name of the people,
and I apologize for that. There is a fairly recent theory of consciousness that trying to
respond to all the lipid experiments and things like that, arguing that, well,
consciousness is sort of after the fact, but consciousness is actually for the future. So,
the idea here is, consciousness emerges out of the evolution of episodic memory. And so,
the function of consciousness is to allow us to create an episodic memory of something we have
already done. And the point about the episodic memory is, as soon as you get into episodic
memory, you get into perspectival knowing. That's what an episode is. You have a perspective
on a situation, what you found salient and relevant, how your actions and the arena
coupled or didn't couple, the affect, all of that, all of that that's so bound up
with consciousness. And the point they make, and I totally agree with this, is as soon as you agree
that there are multiple kinds of knowing, not just propositional and procedural, but also
perspectival and participatory, you get the argument that episodic memory affords
perspectival knowing, which allows you to solve problems that you can't solve without
perspectival knowing. You can pick up on the world, the world discloses itself in ways that it is not
otherwise disposable to you. And then consciousness emerges as an optimization on the formation of
episodic memory. So it is optimally transfer appropriate for the future. And then you get,
it is a sense of agency, but it's not a billiard ball agency. It's this kind of longitudinal agency.
And to tell you the truth, given the human critiques, that's actually the kind of agency
the cell has. It has this kind of longitudinal agency around episodes. It doesn't have this,
I'm an sort of uncaused cause, a moved mover within myself, which I think is
both a ridiculous proposal ontologically and an ethically undesired. Why would I want such a thing?
It's completely arbitrary. I think my life is being lived. I'm trying to change myself so that
I am, my thoughts are as determined by what is true, my action as determined by what is good,
and my perception is determined by what is beautiful as I possibly can. I would like to lose
all my freedom in that sense. And so I think if we move to the right level of analysis, and Gallagher
makes a convergent argument about this, that when we're talking about agency and selfhood,
we're not talking at that limit scale. We're not talking at where's the first movement of the
billiard ball chain. We're talking more about, no, no, no, how are we building this long-term
virtual engine that enhances our predictive agency in the world? Yeah, absolutely. And Gallagher's
work is very convergent with Thomas Metzinger's, of course. And so this, just for our audience,
this, these arguments, and this notion of the narrativized self is well fleshed out in active
inference literature. So I could point you, yeah, I would probably start with the Fristlin and
Limonalski papers. There are two wonderful papers about self-construction under active inference.
And then I have a convergent argument coming out of Daniel Huda, who is also in the 4U,
the Narrative Practice Hypothesis. And he argues that any mindsight ability, any ability to see
in other people's mental states, you know, attributing beliefs and desires to them,
requires, well, for example, if I'm going to attribute a belief and desire, I need to know
something about your character. Are you lying or not? I need to know something about the context,
the setting. What's going on in this situation? Are you tired? Is that a small child? So you're
not really lying. And when you tell them at Christmas time that there's a Santa Claus,
right? Right. And I need to know what the conflict is, what the problem. Notice what I'm
talking about here. I need to know all the elements of narrative. Daniel Huda points out,
we practice narrative incessantly. And unlike many of the other things, including language,
which we scaffold for children, we scaffold narrative for our kids. I had to sit through the
teletubbies twice, in which you have to sit through these really impoverished narratives,
because we're scaffolding this up because narrative ability gives us the right, gives us the set of
skills, the sets of states of mind with the perspectives taking therein, and the traits
of character that allow us to pick up on other people's mental states. And I think that is also
a function of the self, the function of selves is to make us agentically predictive to each other.
Right. Exactly. Exactly. And there's another, there's another convergent argument in active
inference, which is that only in the context of other people like you, would you ever come to
the inference that there is something that is like to be you? Yeah. If you were low,
that converges with the Vagatsky approach to the development of metacognition and self-awareness,
which I think is right. Right. And of course, your colleague at just pointing people in
different directions, your colleague at Toronto, former colleague Jordan Peterson,
as a whole literature on literature and narrative. And he has a conversation with Carl
on his podcast, which is deeply intriguing about these kind of alignments of the free energy
principle and narrative. John, I wanted to also speak about flow states. You've written about flow
as the sort of locus of implicit learning. As you know, I've just been writing up a paper on flow
for an active inference perspective. So I'd love to be able to sort of see maybe where we align,
where we don't align and try and sort of unpick that. Just as forewarning my paper, the paper that
I've written with my wonderful co-authors is not out yet, but it should be coming out soon. So
I want to, I have not yet read your paper because you suggest waiting.
Yes. The paper has gone through modifications as papers are want to do.
It's in the final stages. So you have access to it. So please feel free to read it.
I will read it then. I will read it. I can give a very brief overview. So to not disadvantage you.
My, the basic thesis of the basic perspective that we take on the paper is about self-modeling
under flow states. So that's the main thing that we're looking at and the attenuation of an epistemic
agent model. Because what we're arguing is that certain precision waiting mechanisms are lending,
leading the organism to undertake pragmatic actions, seeking out pragmatic affordances,
rather than engaging in what Carl or other authors would call epistemic foraging.
Now, I think where we might have a point of difference here is that I have a section on flow
states and learning. And I think this is a really interesting point because your paper speaks about
implicit learning. Whereas I'm, and this, and just to make it transparent, this is there,
I've had different perspectives on this, but my current opinion is that in flow states,
what you're getting is a reinforcement of the skills that you actually picked up through epistemic
work. So I have the example of a violinist. The violinist must undergo a certain period of exploration,
of epistemic foraging, which comes with this kind of self-talk, this real prominence of
myself as a knowing thing. And then what it does is over time through learning, you get high
precision over the beliefs about that action in terms of the technical detail. And then that
becomes kind of the foundation on which you can then go and do more epistemic work. And then that
expertise development is stepwise, in a sense. I mean, you can picture it either way. But critically,
where we differ is that I'm arguing that actually in the moment of flow itself,
you're just garnering more evidence for the capacities and the policies that you already have.
So I'd like to start there and see what you think of that claim.
So we, as you point out, Leo Ferraro in Herobenidae, we argue something different,
which is why you're bringing it up. We argue that learning is inevitably occurring even in
the flow situation. And so there's improvement. And that's why if the environment doesn't have
the capacity to renew its challenges on you, you will very quickly fall out of the flow state.
So the argument is, well, why don't you just stay in the flow state? Well, the argument is,
because eventually you get a mastery over the environment, which means your skills start to
exceed the demands. And so phenomenologically, when I'm in the flow state, like inspiring or
lecturing, I'm finding tremendous amount of insight and innovation coming out.
Now, this is where it might get tricky, because is procedural innovation a restructuring of,
especially, is that a restructuring of your information and therefore have new capacities
in it, new emergent abilities? Or is it just a reinforcement? And I don't, we might get into
the thesis of ship here, which is problematic. But the one of the defining phenomenological
features of the flow state, and I want to be clear, I'm not pinning you down on this,
but I do think it's relevant evidence is the ongoing sense of discovery. There's a sense of
discovery there. There's a sense of coming to know things you did not know before. And of course,
when the flow state is in much more comprehensive expertise, not like the plain tennis or maybe
like just your optimal gripping on the world, people come to think they have learned something
deeply profound about reality. So I tend to think that there's evidence for transformative learning
happening up and beyond just reinforcement learning. Okay. Yeah, I like the return to the
phenomena. You know, Dreyfus has this phrase, which I will definitely use over and over again
in this podcast, which is when in doubt return to the phenomena. The way that we have cast it
is that there's this idea in the literature about a hyper prior that the world is changing. So that
we have a prior that the world is changing. And that is adapted for us because we don't get stuck
in the same free energy minima. Now, if that prior is always at play, what ends up happening
downstream on that is that my inference about my own abilities deteriorates over time. And we
experience that, I guess, I mean, like if I play tennis today, and then I play tennis in a week's
time, I'm probably going to have less fidelity in my own capacities in the week's time. And I do,
if I play tomorrow, having followed today. And so our argument is that the positive affect
that's part of the flow state is downstream on the surprise that's generated when you actually
violate that hyper prior that the world is changing. Because what you're getting evidence for is that
your policy still work in the world that you would have been for, you would have thought
didn't lend itself to your policies working. And there's this idea, Casper Hesp's paper and his
co-authors in 2021 that affect inactive inference is about basically your model doing better than
you thought it would do. And this actually comes a lot into what Mark talks about in terms of
aerodynamics. So I'm wondering, I don't know. Well, see, I think that's right. And the problem,
of course, is you can get an infinite regress. So well, I'll say, well, the things here, and you'll
say, well, there needs to be something a hyper prior behind that. And then we can, that's what I
mean about thesis is shit. So again, I would say, well, what are you getting better at? And what
you're getting better at, I would argue, is not stand like so expertise is generally built around
giving you a well, like a specific domain. We can talk about the possibility of sort of meta
expertise if you want. But what I mean by that is, once you've got expertise, you've gotten really
good at within a certain domain at formulating the problems you're fronting as for you, well
defined problems. That's one way in which an expert is sort of reliably different from a novice.
A novice goes in, this is no defined problem, the expert goes, it goes in, it's a, no, it's this
problem. And this is the right way to do this and this and this and this. Okay, so we agree with
that. But I think what's happening, right? And maybe this is the gray area between your position
in mind. I think what's happening is we're discovering new ways in which we can turn
well defined problem, sorry, ill defined states into well defined problems. But something's like,
I didn't realize I could adapt to that situation, but I can. And that sounds similar. But for me,
that's an insight experience. And that's what, like it's an insight flow, because you're getting
an extension of your cognitive capacity, because you have restructured what you take to be
like your, your problem formulation of the world. That's, that's,
yeah, I mean, to supplement that, I actually, I don't disagree on that note, but the way I would
formulate that, and this actually isn't in the paper. It's in the paper in some sense,
but it's not a fully fleshed out argument, because it wasn't hyper relevant.
I'm glad there's another really quality paper on flow. There's really nothing.
When we published the paper, we were literally the only paper talking about the cognitive
processes that work in flow. It's a bizarre one. There's very little on skillful coping,
generally, within cognitive science. But as I said, I think that's why I said there should be
more phenomenology active or cognitive science convergence. What we kind of mentioned in brief
is that flow, if we take the sort of macro perspective on what flow is, it can also be
this kind of humming between the pragmatic and the epistemic boundary. So maybe when you're
realizing, oh, I can reframe this kind of perplexing problem and actually something manageable,
what you're doing there is maybe just slightly x-ting the flow, doing some epistemic foraging,
returning, because something I want to make really clear to everyone listening as well.
When we talk about epistemic action and pragmatic action in terms of expected free energy or active
inference, it's not like the agent goes, I'm doing pragmatic action right now. It's part
of the actual maths. If you look at the maths, firstly, you can do a bit of both at the same
time. That's a thing. But it's also like the action policies that we're talking about here,
John and I, these are not protracted seven hours of just like pragmatic action. No,
these have to be very temporally thin because the world is volatile. The world is constantly
changing. And so you have to be able to not just pin all your hopes or pull your eggs in one basket
in terms of an action policy. And so actually fundamentally, our divergence might well be
a semantic thing, which is that I'm talking very much about the synchronic nature of being in flow
right now. And for simplicity, I have that boundary between pragmatic and epistemic,
whereas if you take a more macro perspective, as that flow state, as the concerto unfolds,
you could be humming at that boundary and doing learning as well.
Yeah, I really look forward to your paper because I think that sounds like actually
a powerful way in which the theories could be integrated together. I'm also interested in
the question that's emerging out of this, well, I've already been interested in the question,
but it emerges out of what we're talking about. Because I'm interested because I think there's,
there might be an additional thing. Because there's, you can flow in a situation and it
doesn't transfer, it doesn't transfer to other domains, video game addiction is the classic
model, you can flow in the game, you can't flow in the world. So you get depressed in the world,
you can flow in the game and so you want to stay in the game more and more and more.
That's very different than how I flow in Tai Chi Chuan. Tai Chi Chuan, in fact,
other people pointed this out in me, the flow states that I cultivate in Tai Chi Chuan,
I can, they are cultivated in such a way that they transfer broadly and deeply to many other
domains. And I'm interested in this sort of ritual framework, because what you get is this
ritual and this philosophical framework, Taoism and other, other practices and ecology of practices
around so that it broadens, like it transfers in powerful ways. And I'm wondering what the
differences are. And also if, how does that show up? Is there a phenomenological difference?
I mean, so now really, really, really weakly, anecdotally, right, in terms of phenomenological
practice, I do get a sense of a difference between what I'm just flowing and what I'm flowing in a
ritual context. So if I enter into a violin hall, and let's say I'm an expert in playing the violin,
and I see a crowd and I see my violin and I see the whole stage, what I end up getting is this,
so habits are quite well codified within active inference, you get this kind of contextual cue
that like in layman's touch, although this isn't, we're saying this isn't happening propositionally,
it's time for me to play the violin. And this can look like precision over beliefs about your own
action. So what, this is again, not something I've thought about necessarily with any depth,
because this is just something that you've brought up. I'm wondering whether that contextual cue,
what you're happening when you're doing Tai Chi and then maybe what you're doing when you're
lecturing is that your system is seeing similarities in the context and doing similar precision
weighting in a separate domain. Yeah, I think that's right. And I think what philosophical
frameworks do is they reverse engineer that. They try to find out what might be similar,
or maybe even invariant across many contexts, and then build that back into the specific context
in which you are doing the practice to exactly afford that transfer appropriate processing.
I think that's right. I think there's something else also going on with the cueing, and this goes
into Aptur's metamotivational theory. We can be broadly speaking, we frame our arousal in two
different ways. When we're in italic mode and we're working towards, where the reward is found
in the external goal, then increased effort is experienced as frustration and then it increases
too much of getting anxiety. But if I'm doing something where the goal is the behavior itself,
like making love or doing poetry, then the increased, not infinitely obviously, but the
increased arousal is framed as positive, as excitement. And so I think also, and so Aptur
talks about safety framing. Let's call the first italic mode work and the peritolic mode
a play. I think ritual has to do with serious play, and I've got a whole argument about that.
But I think also what you're doing in the context is you're trying to cue people into the play mode
because the play mode allows them to model themselves, their arousal, as positive,
rather than as negative. And that allows them, and I think there's a deep connection between
this peritolic framing and Csikszentmihais, I think accurate claim that flow is autotelic,
doing it for its own sake. Right. Yeah, cool. Yeah, I like the notion of effort here.
Recognize that one of the fundamental factors or fundamental characteristics of flow is
perceived effortlessness. Yes, even though you can, even though you can have sort of very
peripheral cues that you might be expending a lot of metabolic energy. Exactly. And just for the,
given this is the Active Inference Institute's podcast, just for those interested in the
computational framing of that within Active Inference, Thomas Parr has got a paper out this
year on cognitive effort and Active Inference. So that gives a kind of nice computational
modeling picture of that, which actually leads me to a much broader question because I know we're,
we haven't got too much more time, which is I've noticed in myself to be totally candid that I've
started, like I learned about flow and Csikszentmihais through you and through other people,
but mainly as a philosophical notion. And now I'm viewing it as a computational notion.
Yes. Do you worry about that? Do you worry that if we rely too much on computation, not just
computational models, but maths, physics, we in some ways reduce the phenomena in a way that's
detrimental, not just because it's not romantic or that it's, but like that we're missing something
fundamentally? Well, it depends. I mean, that's a really important question. We could do two hours
on just that question. But if you think that a leveled ontology is actually the way ontology is,
that the level at which we do science is as ontologically real as the quantum level we
discover when we're doing science. And I think you have to come to that conclusion.
Right. And I have extended arguments for that elsewhere. Then you can make a clean philosophical
distinction between explaining a way in a reductive fashion and explaining that actually
enriches your appreciation for the phenomena. Now, if the computational stuff, the computational
stuff to my mind, well, let's say what the argument we were just exploring has merit,
then notice what we were saying. We're saying, well, what the computational modeling actually does
is actually shows why this sometimes very obscure philosophical framework is really important.
It's actually doing some really important work. And you can't get rid of it. You can't dispense with
it. And that would mean that some of the stuff we're doing, where we're trying to commodify flow
and take it out of those frameworks and do the thing we do and sell books.
It's actually misrepresenting the phenomena in a way that we can philosophically and scientifically
critique. It's like, wait, wait, this phenomena has the power it has, because Chick-Mat St.
said it's an evolutionary market for adaptivity. And then, well, making it adaptive is how broadly
and deeply is it transferring out of the situation. And then the philosophical framework really
matters to what it is and how it functions. And so if you can make a distinction and you need
an ontological distinction to make this distinction, but if you can make a distinction
between explaining and explaining a way, then I think it's possible to say, no, no,
when I do these things. And to be fair to me, there's, I got a lot of people who, you know,
from various religious and spiritual backgrounds, and they come in and they say, thank you so much
for your work. I now, I much better appreciate this, this experience or that experience or the
flow state or this mystical state, because you didn't try and tell me it's nothing. But you
tried to say, this is what it's doing. And this is why you like it and value it so much.
But do you think your work, to kind of, yeah, to look at that personal vantage point, do you
think you've managed to keep, like, because if I, without being sort of embarrassingly lording,
people should watch Awakening from the Meaning Crisis, not only for the content, but also just
the way you present it, which is just so magical. So thanks. I mean, it's really inspired a lot of
the way that I think science should be done and philosophy should be done. What, what is it about,
I think, you know, anyone who watches that recognizes there's something kind of special
going on there. The ideas are living through you, you're, they're breathing through you,
you're breathing through them, there's this really beautiful coupling. Again, we'll come back to that
between you and the ideas. What, what is it about that kind of synthesis of the philosophy and the
sort of more hard cognitive science? Do you think made that project so successful?
I suppose it's a view of the role of cognitive science, what cognitive science is doing.
I think what cognitive science does is it's,
well, I'll try and do it sort of narratively. And I do this in the series. I think, you know,
even the notion of mind that we've been invoking mind and cognition is equivocal,
because it means one thing to the neuroscientists who study the brain and looking at neurons and
anatomical networks and perhaps functional networks. It means a different thing to the
artificial intelligence person who's building algorithms and heuristics and doing reinforcement
learning and blah, blah. It means a different thing to the psychologists who study human behavior
with experiments and running stats. And they talk about working memory. They don't talk so much
right. And it means a different thing to the linguists and a different thing to the cultural
anthropologists. By the way, I include them because they were the people that have been
studying distributed cognition and collective intelligence. They matter. Yeah. If you think
about it on this analogy, it's like they're different countries speaking different languages.
And here's the thing that has great value. Specialization has great value. I'm not dismissing
that. I am not dismissing that. But each one of these is talking about a different level. And
here's what I think I would state as a very plausible claim. I think it's unlikely that these
levels in reality, the brain information processing, behavioral, linguistic, sociocultural levels
are independent from each other. I think they causal influence and constrain each other.
So we are missing something important about the mind by not getting clear about the relationship
between these levels. We can be equivocating and we have a fragmented notion if we don't capture
the relations of constraint and causation between these different levels of cognition and mind.
And so I think the proper function of cognitive science is to use philosophy's skills of
creating bridging discourses, creating bridging conceptual vocabulary, theoretical grammar,
so that these different disciplines can talk to each other in reciprocally reconstructive ways
as a way of converging on the causal and constraint relationships between the levels,
rather than trying to compete or say the bottom level is the only real level. So that for me,
they all live together. They are doing, and I'm sorry to evoke it again, they're doing
opponent processing between each other. And that's what inhabits me when I'm doing cognitive
science, that vision. I call it synoptic integration. Yeah, it's, well, it's wonderful to see.
So, I mean, like, I think we, I mean, that's the cognitive scientists that I'm aspiring to be.
I think you've called it a big picture cognitive scientist as well. Yes. And one of the things,
one of the, and I felt very lonely for a while, you know, I was doing relevance realization,
which is a big picture. And then, to my great delight, another big picture for ecocide down
the road. And then to my even greater happiness, another big picture came down the road,
which is, you know, the predictive processing framework. And I think they are more convergent
than adversarial. And I, well, you've heard me arguing about how we can integrate them together.
Excellent. Yeah, I would say maybe it's just bias. Active inferences or physics processing is a
big picture cognitive scientist from the physics and the maths, all the way, well, what we're
trying to do to the phenomena, to what it is like to be a, to be a human being, to have conversations
like this. John, it's, it was, you know, I can't say it was better than I expected,
because I knew it was going to be wonderful, but you're full of just thrilling insights and
speaking to you, listening to you is always such a wonderful learning experience.
Where that happens in flow or without flow. But I just wanted to thank you so very much for,
I know you're extremely busy, but for giving us your time. Where can people find you? What have
you got coming up? I'm sure people are curious. So the most immediate thing for this conversation
is the talk I gave at Leiden on the predictive processing symposium. It's up on my channel.
I think it's the second most recent video on my channel on YouTube.
We can put it in the video. Yeah. Where I try to go into the nuts and bolts of how you could
integrate predictive processing and relevance realisation theory together. So people might find
that. And I've got a lot of good feedback on that for being sort of clear and a good argument.
So I would recommend that when people are interested in the broader implications of this
awakening for the meeting crisis and then after Socrates also after Socrates is where I take all
of this and all of this stuff and how do you turn it into practices in order to overcome
self deception and enhance relevance realisation become more wise and virtuous. And so they can
take a look there. The arguments around neoplatonism. There are several videos around that. I try to
connect neoplatonism to foreecogsci and relevance realisation and predictive processing as we
saw in this podcast. But in the neoplatonism I'm working on my third big series. Walking the
philosophical Silk Road which will be on Zen neoplatonism. Trying to see if we can bring
an integration, an opponent processing, not an adversarial one, an opponent processing between
Zen and neoplatonism to give us a rich philosophical framework by which like the philosophical road
we can trade ideas and move between worlds without having to descend into well tribalism
and other such things. Wonderful, wonderful. Well, again, it was absolutely my pleasure.
I apologise. I've got a slight cold. So if I've been a little sniffly or nasal,
we can blame it on the London weather. But I'd love to have you back on. At some point
your work is truly inspiring. So thank you so much, John, for me and the Institute.
Thank you, Doris. I'm happy to come back on. If it turns out that Mark and I come on together,
that would be thrilling as well. Great. We will definitely get that sorted. All right, thank you.
Thank you.
