to copy or not to copy. That is the question from chimpanzees to the foundation of human
technological culture, recently appeared in physics of life reviews. Let me see if this works. Yeah,
sorry. So it all starts with a jigsaw puzzle. And the puzzle is why a highly innovative species
like chimpanzees do not live in a complex technological world. So we know chimpanzees are
very inventive. They are very creative. They are insightful. They can learn socially.
But what we don't see in the same extent or similar extent we see in humans is the accumulation
of complexity across generations. So you can see here in these images, we have one of the more
complex and demanding tasks that chimpanzees perform, cracking nuts open, and they can combine
different tools. They can use it in the appropriate order. So this means they are very insightful.
And yet, if we compare it with a rocket that can bring civilization to Mars,
it is clear that the accumulation of technology across generation works very differently in humans
and other non-human species. So the basic question or the one million dollar question is why does
innovation fail to translate into technological cumulative complexity in chimpanzees?
Does it owe to a limited capacity to copy with fidelity? Or what we referred
as true imitation, which means reproducing not only the end result that would be emulating
or emulation, but also the steps that lead to that end result. So according to this view,
further to copy innovation with faithful accuracy, hampers their intra and intergenerational spread,
and any ensuing ratcheting up effects. So possibly when copying with fidelity is impeded,
innovative performances are unlikely to lift their protagonist. And this brings us back to the
discussion we had the other day in The Snakes and Others paper where we said that after two
million years ago, Iriomo produced these almond-shamed bifacili flaked stones. But these
kind of artifacts that we don't even dare to call them tools were not copied by
conspecific observers because perhaps they were not attributing to them any kind of functional
use. So perhaps they were not seen as tools and were the result of manual inactions.
So to ratchet up complexity, it is important that inventions, that is tools, are copied with
sufficient fidelity so that they retain the fundamental features or attributes that make
them functional. So following the steps of demonstrated tool manufactured by an expert
model to the letter is the simplest, fastest and cheapest way to make sure that copies of the
original artifact are accurate. And here cheapest we refer to in terms of expenditure of energy.
So if the copies are functional, hence useful, they keep circulating in the group community
longer. And these skills increase the opportunities for one or more individuals different from the
original inventor to add in complexity. So for example, one individual invents a wooden spur
and 100 years later the smelting of copper is discovered and another individual adds to it
to this spur a sharp copper point and so on.
So here is an interesting concept of ratchet effect that would explain in part why humans
have built such complex cultural and technological work. So the idea of the ratchet effect is that
no generation starts from scratch. Instead, inventions and cultural products created by
one generation are kept in mind and transmitted to the next generation. This way, every generation
is better off supposedly than the one that preceded it. So here we can think of books,
books are a wonderful way of keeping information, sharing it across generations and among the same
generation also. So thus technological complexity and success in humans is not dependent solely
on the geniality of one or few individuals. It is a joint endeavor where many individuals
contributed specific expertise and skills to produce increasingly complex artifacts.
And again, we can think in establishing a colony in Mars, no single human alive could achieve that
alone or we have the required expertise to achieve that alone, but all together we can
perhaps manage that. So we need this kind of shared knowledge and accumulated accretion of course.
So why it is some behaviors or innovation are copied or not can be explained at the level of
social dynamics but also at the level of the brain or giving a more mechanistic explanation.
So explanation of why coping of certain behavior in chimpanzees does not occur with frequency
have been often kept at the level of social dynamics where factors such as social prestige,
dominance, etc. are said to be key to explaining whether or not an invention is adopted by observers.
And this is a problem against the brain to a subsidiary role. Here, Michael and I will
be attempting to identify what the minimum cognitive requirements are that can give rise
to innovations and their horizontal and vertical transmission. And we also attempted to differentiate
the cognitive ingredients necessary for innovation from those that need to be in place for the adoption
of an innovation. So we wanted to establish a clear demarcation between the brains of the
ones that innovate and the brains of those who observe an innovation because we think this
is important to be analyzed separately. So in order to see which are the mechanisms
at the level of the brain that would allow for one innovation to be copied, we invoked
the lens of the free energy principle. According to active inference under the free energy principle,
it is through there being limited to a certain number of states that is the attracting set
that organisms minimize the variational free energy of the internal states and resist entropic
dissipation. Minimizing variation of free energy reduces prediction sensation discrepancies,
prediction errors that can be corrected by active sampling of predicted sensory inputs
and perceptive modification of predictions. This is sometimes expressed in terms of perceptual
inference that is changing predictions to mad sensations and active inference reactively
changing sensations to match predictions. So innovation in a way might represent a potential
misfireings from a Darwinian perspective. So minimizing variational free energy can be achieved
through action, sending creatures can act, active inference in order to fulfill their predictions
and thereby reduce discrepancy between the latter and sample reality.
Being limited to a certain number of states, what we could refer to as the attracting set,
is therefore synonymous with minimizing variational free energy and hence maximizing adaptive fitness.
Here innovation represents an anomaly and innovators are unorthodox actors or protagonists
who entertain new courses of action or plans. New phenotypical responses that have not been
previously entertained and according to this interpretation of the free energy principle,
it is at the level of policy selection where innovators stand apart from the crowd.
Their policy selection is in a sense faulty insofar as their ensuing behavioral outcomes are
in more contrast to those of their fellow actors who deploy orthodox responses that reduce discrepancies
between predictions and sensations thereby reducing the prediction error. Here when we talk
of misfireings, we don't do it in a kind of negative sense, it's just to express that
these new behaviors, these innovations necessarily will produce more surprise.
Okay, seeing surprising things, with this phrase I am kind of paraphrasing Andy Clark
in a paper in Behavioral and Brain Sciences. He referred to seeing surprising things to being
able to lend credibility to the sensory information that is not in accordance to prior beliefs.
So the family of priority density is entertained by an individual irrestricted to the systems,
the brains prior by some beliefs. Equivalent, roughly speaking, to its phenotypical repertoire.
This means by definition that innovative behaviors both are likely to be missed in any given phenotype
and, crucially, difficult to recognize when observed by another.
Should an innovator's behavior diverge markedly from the repertoire of plausible policies used
usually by an observer to predict another's behavior, it may be beyond the capacity of
the latter's generative model to recognize it, that is, to make sense of it. So large discrepancies
pose a threat to the brain, because one, updating involves making energetic demands, and two,
risk-reducing adaptive fitness by inappropriately changing the generative models. And here we
need to think that the generative model has been selected also in a specific economy, so changing
it might have risks. Okay. So what is required for a brain to entertain generative models that
involve unusual or bizarre behaviors? The hierarchical predictive interpretation of the brain,
or hierarchically mechanistic mind, an amphibious inference machine, sorry, implies that each level
of the hierarchy of cerebral neuronal circuits conveys predictions or conditional expectations
that suppress errors at the level below, while concurrently conveying errors that permit the
revision of the expectations at the level above. Possibly, dynamical precision weighting enables
the system, that is, the brain, to readjust the confidence afforded to top-down expectations
as opposed to bottom-up prediction errors. In other words, in order to entertain a prior
data and likely hypothesis might explain best some behavior within us, it is first necessary to
relax the precision or commitment to prior beliefs, thus enabling new or implausible
hypotheses to explain novel behavior. And here I introduce some things we discussed the other day,
Professor Freiston talk of attenuation of sensory information in relation to
saccades, which is kind of switching off the sensory information we are being aware of,
and that would be the opposite as being impressionable. So I'm quoting Professor Freiston here.
If I can copy, that means I am impressionable. I will accumulate new evidence very quickly.
I have the capacity to assign greater evidence or precision to sensory evidence and suspend
the precision to my prior beliefs. This is something he mentioned in the last
active inference recording, 53.1. And to end this introduction,
one concept we introduced in our paper, which is central to our discussion, is that of zones
of bandwidth surprise. So this is a new concept we introduced to refer to the levels of mismatch
between prior beliefs or top-down predictions and sensory information that species can tolerate.
So first and foremost, the focus of the ZBS concept is on the observers and their ability
to make sense of unobserved innovation. Encoding and subsequent copying of innovation depends
on the degree of disparity or surprise between predictable behaviors, namely,
those typical of the species, and the perceptual incoming information about novel behaviors.
If the ZBS is right, it means that the species can give credit to the information received
through its senses that challenges the prior beliefs. In short, as species can register and
code and potentially reproduce innovative behavior of certain code specifics that
deviate markedly from customary prototypical behaviors. The species is highly impressionable
if we use the words that Professor Friston used the other day. So if the ZBS is narrow,
then a species' ability to change prior beliefs to accommodate new evidence regarding
innovative practices of serving code specifics is compromised. I just want to end up and avoid
any kind of misunderstanding. I want to make clear that our zone of bandwidth surprises have
nothing to do with the zone of Latin solutions by Tenie, albeit we are discussing similar topics.
So the zone of Latin solutions that was introduced by Tenie Kai and Tomo Aselo refers to solutions
to a problem, for instance, extractive foraging that can be achieved by an individual in isolation
during his or her lifetime and hence is not likely to be the product of cumulative culture
involving social learning when observed in the wild. And for those readers interested in this
concept, they can go to the original paper I'm showing here. And also there is a recent paper
by Andrew Whiten, who is Professor in St. Andrews, that discusses this concept and that has replication
by other authors. So it might be a good update for those interested also. And with that, I
finish this short presentation and we can enter this question. Let me stop sharing the screen. Okay, now.
Thank you, Hector. I will bring up the notes again and to Michael, Carl or Dean,
whomever would like to provide a first response, please.
Well, I don't really have a great deal more to add. I think
Hello. Yes, please continue. What's happened here? You're all good, Michael.
We're here, Michael. Hello. Can you hear me? Yes, we hear you continue. Yes, we can. I'm not quite
sure what's happened here. We seem to have snakes and ladders up on the screen. As I said, I don't
think I can add much more to what Hector has just said. I think it makes a very succinct
summary of our paper. And I would like to certainly congratulate Hector for making
what seems to me a very original and perceptive observation that it is the observers whom we
have to thank for the copying and therefore for the handing down of technological achievements by
early humans. Whereas too often the emphasis has been made on the personal responsible for making
a technological innovation. But of course, unless somebody copies that, or at least unless it registers
in the mind of somebody else, it is unlikely ever to get copied. And although this seems to be a fairly
obvious observation, it seems to have escaped most of those who have published on the matter
either too. And I think this is a very original contribution on Hector's part, which deserves
to be complimented. And really, that's all I wish to say. I think I'd like to throw this open to
other people. And if I can illuminate or elucidate any matters, I'm happy to do so. But I think
this is really very much to put it mildly Hector's brainchild. And congratulations.
Thanks, Michael. You're very kind, but this is our child. And you know a lot. You have a lot to
contribute. So I mean, I can only learn school. But thank you anyway.
Awesome. Carl or Dean?
Go ahead, Carl.
Right. So I just wanted to reiterate Michael's admiration for both the idea, but also the very
fluent and clear articulation of it. It was nice for me to see that presented so succinctly,
because the clarity of the idea is really very evident. It struck me there are sort of two
themes that we could discuss, which is the emergence of more complicated solutions to
accurately engaging with and modeling our world. I think that was sort of a generic theme in the
first part of the presentation. But then very quickly, we moved to this kernel idea, this core
idea that the dissemination and the transgenerational propagation that could be read as some kind of
cultural niche construction in a sort of evo-devo context depends upon being able to recognize
a particular behavior and thereby copy and imitate. I think that was the key thing. And for me,
just understanding the mechanics of that from the point of view of belief updating and active
inference was, I think, a really useful thing. And as Hector beautifully articulated, the ability
to recognize something new and update one's generative model or posterior beliefs depends
very sensitively on the confidence or the precision that you've described, the sense of evidence,
in relation to the precision with which you hold your prior belief. And I think that's
absolutely crucial. And I sort of highlight that issue because it is exactly the same issue
that you will find when applying active inference and the free energy principle to
psychiatry and the different ways in which we can... I can't remember, Hector, what was your
word, misfire, in neither a good nor a bad sense, but certainly there are certain psychiatric
syndromes that could be regarded as misfiring. And of course, there's a very close association
with innovation and creativity and manic depressive psychosis, famed in terms of various
historical figures in the arts. And that, I think, again, brings us back to this key notion
of getting that balance, the balance of the precision of our prior constructs,
what we have accrued through experience-dependent learning, and the precision-afforded evidence
that this is how the world is actually working and how I am actually working, getting that balance
right. And that's a really difficult job. And sometimes in computational psychiatry,
we try to explain this in terms of a statistician. In order to get the balance right, you have to
be able to estimate these precisions in exactly the same spirit that a statistician, when making
an inference doing a t-test, has to estimate not just the difference in the group means,
but also the standard error. And it's often much more difficult to estimate the standard error
than it is to estimate the difference in the group means. And that standard error is the
inverse precision. It's the weight that you afford, the meaning, the significance of some
quantitative difference, say, a prediction error. So you see this theme that there are two parts to
inference. The first order part is just the prediction error or the surprise. But then
you have to assign how newsworthy is that. You have to actually modulate that
with its precision. So you can multiply by the precision or divide by the standard error
to get the actual thing that matters that's going to change your mind. And there's a whole
literature on different kinds of people in the context of neurodiversity that have an impairment
in being able or possibly have an impairment in being able to estimate that precision. And
I'm thinking here of the poster child of this kind of formulation, which is autism. And the idea
being that there is an early developmental failure to attenuate sensory precision. So they are
early and continually during their early development, severe autism, unable to ignore
any of their sensations. And as a consequence, everything is surprising. Everything's arousing.
Everything is in danger of revising any beliefs very, very quickly. So they're highly impressionable
to the extent they can't build deeply coherent models of their lived world or indeed the other
artifacts such as mum that constitutes their world. So I'm just wondering whether a species
that has the same kind of latitude in terms of either biasing attention or precision
to sensory evidence versus accumulated prior beliefs would display the same kind of misfiring.
So you can go from one end and autistic species will be overly impressionable.
It'll be too evolvable. It will be able to remember anything from generation to generation.
The converse is somebody who you can imagine from a psychiatric perspective
has committed unduly to very precise prior beliefs about the world works. And you can think of this
in terms of compulsive obsessional disorder or perhaps even depression. The world is an awful
place. That is true. Therefore, there's no point in going out and challenging the evidence that the
world is an awful place. So I'm just going to stay inside and feel isolated and not move or say very
much. So that would be an example of who somebody is not very impressionable. In fact,
their pathology, their misfiring prevents them from acquiring any evidence to revise those beliefs.
So if you imagine a species that had that same kind of second order misfiring,
this is not the misfiring of the innovative soul. This is a failure to infer the second
order cystics, the reliability, the precision, the variance, the entropy of the content of the
things they try to innovate or make sense of. You're left with this notion of a species that
just cannot respond to selective pressures for selectability. They can't respond by adjusting
their evolvability simply because they're fixed in their way. So for the environmental,
economic changes in any fundamental way, they're not going to be able to respond to that.
So I think there are many examples of this key. I think it would be called a pathology in the
sense that in a volatile environment, you would need to optimize the precision afforded sensory
evidence in order to make the best sense and understand and engage with that environment.
And if you get that wrong, there will be a pathology. And I think basically Hector's
formulation really drills down and really focuses on the actual mechanism of this kind of pathology.
It's all about the transcultural spread of generative models and sense making
in terms of engaging either with artifacts or indeed with conspecifics.
I repeat, it's such an easy thing to get wrong as evinced in psychiatry. There are so many instances
of neurodiversity expressed clinically that I think reflects this singular dimension in terms
of the ability to get that balance right. I remember we discussed last time again in terms of
impressionability and selection for selectability and the like, the same kind of mechanism unfolding
in terms of evolutionary mechanics. But at the level that I think we're talking about today
in terms of pursuing plans and novel ways of doing things that may or may not be
recognized due to a failure or not of being able to suspend the precision of your priorities.
I think that was a central theme. I'll just close with an interesting comment that
in terms of the kind of misfiring that Hector was implying, basically a novel way of doing things,
being the unique province of those kinds of creatures that can plan possibly deeper into the
future. There's a really interesting sort of link back to this precision notion
in the sense that if you try to simulate the depth of planning of any sentient artifact,
then the degree to which they are able to look into the future depends upon the precision
of their beliefs about the succession of contingencies. What will happen if this happens
and then what will happen if that happens? It's technically the precision of the transitions
amongst worldly states of affairs as you roll out into the future. Again, you have to estimate
that precision. There's another point at which precision gets into the game, but in this instance,
it's not the precision of the sensory evidence, but the prior precision about the ways things
unfold and what will happen if I do that. If you have a low precision there, then you don't
hang very far into the future because you lose certainty and confidence very, very quickly
after just a few moves. Whereas if you have very precise beliefs about the state transitions and
the consequences of various actions or sequential policies, then you can roll out confidently much
further into the future and perhaps find that innovative solution. Again, you come back mechanistically
to phenotypes that have differing degrees of precision. In this instance, get into the game
in terms of bounding the depth of the planning or the temple horizons that you can entertain
when scoring different plans in order to actually select the best action at the moment.
For me, that insight is really useful because I can see how one could simulate that quite easily
in toy situations. Those are my thoughts inspired by Hector's excellent presentation.
Thank you, Carl. Dean, what say you?
Well, if it's okay, I'd like to step back for a second. Because we were privileged to be able
to look at the two papers almost simultaneously, I know chronologically we've split it up into
weeks, but as readers we were able to kind of look at both papers side by each. I kind of want
to take a bit of a Hofstetter strange loop, two-sided condition, Mobius. We've got all those
representations in a lot of our live stream introductions. So if we were to assume that
because Carl pointed out not everybody can accommodate a two things at once perspective,
if we can assume that that doesn't overwhelm, my question to the authors is, do they see their
own journey as a one paper or artifact morphing into the next, or as we were pulled out and taken
up by this relationship between epistemic and pragmatic values when uptaking an active inference
perspective? That's part one of the question. Part two is the former is kind of a sequential
mechanical technical side of things. The latter is the combinatorial plus meaning entailed and
entangled. So more where am I relative? So combined, that's a relative depth of field
as setting, as establishing, morphing, we want to call it that. As active inference strategy
is applied, how do the authors see or potentially see this perspective combining, meaning the
sequential end of the combinatorial affecting, not effecting, but affecting what we believe?
Because I'm a big believer that we can't just sort of strip the feelings part of this out. I think
that's whether we're talking chimpanzees or whether we're talking the emotions of sliding down a snake,
those are part of this thing that we're looking at.
I'll just give one short note on that. In the paper, Sophisticated Affective Inference,
they simulated counterfactual futures, projections about futures, which are in active inference,
action oriented. All futures are analyzed and inferred about with respect to policy selection
by the agent. And one of the patterns already apparent in even the simple simulations were that
even if a very small fraction of counterfactuals have like death as an outcome or highly negative
outcomes, it can increase the variance estimator on possible futures greatly,
leading to essentially ruminative behavior and affective anxiety around the legitimately warranted
variance in possible outcomes. So I see a key piece of this puzzle to be entertaining
progressively wider time cones of possible futures in a prospective capacity,
and entertaining progressively wider time cones in the past of causal mechanisms
and somehow negotiating that affect barometer in the moment as the eye of the needle.
Hector and Michael, where do you see affect coming into the snakes and ladders to copy
or not to copy set? Well, may I make one or two comments? First of all, in addition to
what Professor Fiston has told us about autism and so on, I think it's worth mentioning
in the connection of the question that Daniel has just raised to say that there is clearly a
difference in the evolution during the life cycle of early humans on the one hand and great apes
and probably most human forerunners on the other, the extension of the human life cycle,
the extension beyond childhood, and in particular, as I mentioned last time,
the adolescent growth spur to which we have, but which may not have existed in early hormone
even one and a half million years ago, I'm sure is relevant to making the evolutionary
step between, let us say, the surprise that perhaps a chimpanzee has if she
observes a dead bird and then regards this as counterintuitive because birds ought not
to be lying on the ground, throws it up into the air, but this is an individual spontaneous
reaction which is not handed on as part of a behavioral repertoire of the species.
And on the other hand, when we begin to see the reproduction of, as it were, counterintuitive
behavioral sequences such as taking a lot of flakes repetitively by hand from a piece of stone
using another stone to produce an almond-shaped hand axe fairly regularly flaked on both sides,
something which is not found before Homo appears in the archaeological and paleoantribological
record, but which is not something that seems to be a regular part of human behavior. It is almost
as if the individual who made that was doing it as a kind of spontaneous thought of what might
happen if I was to do this, part of the deep generation of the hierarchically mechanistic
mind which Professor Fiston has told us about, a deep generation that, however, may have been
a misfiring, it may have been simply a personal spontaneous event which is not easily
recognized by others, particularly if their, shall we say to put it mildly, their mental
development is stunted due to the early adulthood and the lack of any adolescence.
Adolescence in particular, which and of course the development of the neuronal
architecture of the brain which in modern people continues until our mid-20s, if this was not to
have occurred, as it does not of course in evening gray tapes, then there would have been perhaps
a problem here about the deep generative potential of an individual ever being
recognized such that it isn't just what might happen if I was to do this with a piece of stone,
but what might happen if I was to copy what that other individual is doing with a piece of stone.
And this I think is the stumbling block, this is what has led to the snakes and ladders picture,
it is what I think has led to the very slow adaptation of technological, cumulative technological
handing down from between generations or between individuals of a generation and between
generations and it may well have been the case that it was not until demographical
as well of course as paleobiological changes had evolved in the Guinness Homo that there was
sufficient intercourse, not merely sexual but social such that these questions continue to be
asked ever more frequently and with the appearance of better and ever more fluent communication
would allow what we now regard as human culture specifically human nature which
I think has differentiated us ever more from the gray tapes. I just, those are my thoughts on the
matter. Thank you Michael, Tari or anyone else please.
When I just speak to the question about affect and what Michael has just treated us to,
so one way of conceiving of affect and valence and the emotional aspects of
choosing different plans or making sense of my own bodily sensations is to think a bit in terms of
precision estimation. So one way of carving, one way of a very generic way of thinking about some
negatively effectively charged states of mind would be those states of mind in which there is
irreducible or unresolvable uncertainty. So you know to put simply to be uncertain about what is
going to happen to me or what I should do is to be in a state of angst and that can be linked to
notions such as anxiety and you know with some extra nuances other feelings such as you know
a low affect and indeed if that is pervasive a low mood or or depression but I think the key
thing here and indeed many people have developed a calculus of emotion based upon whether your
average level of uncertainty is increasing or decreasing or is high and low and adding these
things together to get an ontology of emotional states or a purely sort of inference perspective
there's another body of thought and literature which links emotions to the literally gut
feelings, interception. So that certain emotional states are just hypotheses about the way that I
am feeling now that best explain the myriad of extraceptive, intraceptive sensations. So I think
there is a mechanics of affect in certainly intraceptive inference and possibly more generally
in terms of active inference. However there is another aspect of things that we
the feelings that we might associate when we feel compelled to do things and I'm thinking here
not about the irreducible or irresolvable uncertainty but about uncertainty that can
be resolved. I'm thinking here when Hector mentioned Andy Clark's treatment of surprise
there is also the truism that we expect to be surprised and technically that lens that can
be explained in terms of the imperatives for choosing those actions that will resolve uncertainty
about the way the world works. So this is just an expression of novelty. So if we anticipate
that we are going to be surprised by some outcome what we are saying is that that outcome is going
to be informative and that it will reduce some uncertainty. Technically it has a high expected
information gain. So I'm speaking here as a statistician and using terms that would underlie
the Bayesian principles of experimental design that we do these experiments specifically
in order to get surprising outcomes that are by definition going to resolve my uncertainty
about my different hypotheses. So if we think about the misfires that are innovations
these are effectively by definition novel behaviors and there are the fact that people
or certain people in certain regions engage in novelty seeking is entirely sensible from
the point of view of the free energy principle because novelty seeking just is an expression
of curiosity it is just an expression of choosing those outcomes that are going to yield rich
information that has technically a high self-information or an expected information gain.
So this is another view of the if you like the effective aspect that we do we are compelled
and expect ourselves and will possibly explain ourselves as being excited in a positive way
at the opportunity to resolve uncertainty because we see an opportunity to do something novel what
is behind that door you know what is inside this present you know what would happen if I did that
and that's an entirely natural and by natural I mean something that is easily naturalized under
the physics of self-organization of any system that has or entails an implicit generative model
the consequences of its own action. So I thought it was a lovely link between that kind of
affect written into the imperative to seek novelty to seek surprises in the future
and what Michael was saying about well yes in order to do that you still have you still have
you have to suspend your your prior convictions because if you a priori think you know everything
there is no novelty there is no imperative for expiration and you just do the same thing time
and time again but if you're in a if you can recognize that there is reducible uncertainty
and choose those actions that have the greatest expected expected information gain then you
will necessarily succumb to novelty seeking behavior and thereby discover those misfire
innovations so and it may be that you know there is well the story that Michael was telling was
that we are built to be curious creatures for much longer we are built to you know to be able
to respond to novelty and to find those innovative novel ways of behaving and you know so that we
remain we were we retain that childlike curiosity as part of our epigenetic neurodevelopmental
programming for much longer than other species so I I think that matches very nicely with
the sort of the basic thesis that Hector was proposing during the presentation it all comes
back to getting the precision of your prior beliefs right and suspending very precise
prior beliefs in order to explore hypotheses and that exploration just is in terms of engaging
in novel innovative behaviors that moves um that you know will resolve your uncertainty
so I if that's right it's sort of engender the question why is there an evolutionary pressure
for this kind of eternal childhood so I want to ask Michael and Hector
because Michael certainly brought in language and cultural niche construction
my guess would be that there will be a circular causality between the
the cultural eco niche and the phenotypes that are trying to adapt to that cultural eco niche
such that they are required or the phenotypes that have the greatest adaptive fitness are those
that retain a greater curiosity in the context of the culture in which they find themselves
and part of that will be necessary to actually understand the communication and the signs and
the semiotics afforded by their conspecifics which could be read just as language so my question is
did this innovative uh does innovative tool use does it emerge um um stochastically or um
sort you know um at certain points along with communication and language um or um are they
or are they not correlated and if they are correlated in terms of you know um you know
historically um what are their thinking about the direction of causality does the fact that you
um um remain curious and innovative for much longer um lead to language that we can you know
engage in novel communicative behaviors or is it that we need to um remain curious and open-minded
in terms of um thinking about or entertaining novel plans and innovative plans simply because we
have to make sense of a world that is rich in information because there is language that is
that has been culturally inherited or is it both is there is a both top down and bottom up causation
so so two questions language tool use and copying and the um the coupling between the
sort of evolutionary um phylogetic um sorry the phylogetic on the um the um sort of phenotypic
levels when it comes to things like language well um I wonder if I could come in here
Daniel is it okay if I address uh calls questions yes in whatever order you like
thank you um well in the first place there is a voluminous literature on the relationship between
language and the origins of toolmaking and tool use uh really and there's a lot of
unresolved argument about whether the two came together very early in human evolution
let's say between one million and two million and one and a half million years ago
as I originally thought some years ago or whether in fact languages we know it or shall we say
fluent communication at least uh only developed much later as I'm coming around to believe now
and as Noam Chomsky has said for many many years uh I don't want to get involved in that because
really we would need two or three programs and a lot of literature to compare and contrast
rather I would query whether we have an eternal childhood
on the contrary I think that physiological childhood
is slowed down and when the adolescent growth spurt arises after about the age of let's say
nine years old uh at sometimes or perhaps somewhat later at others
is when we see a major change uh in behavior which is no longer childish but is neither is it
adult um of course we needn't go into that we all know that adolescents can be very impetuous
but they can also be extremely anxious and this brings us to the angst that uh Carl has mentioned
and which I certainly felt uh as an adolescent uh facing the weekly viva voce examinations in human
anatomy in the dissecting room which in those days we all had to undergo uh at least in the United
Kingdom uh as I can show uh Carl remembers and which always that put me into a state of extreme
nervousness and has given me a lifelong worry about the lack of accuracy uh let alone precision
in anatomical description and identification uh and a concern um with the statistical
variability in uh uh in human anatomy or aspects of it or anatomy in general necessarily human
and its relation to uh uh process in other words to physiology and I feel myself much more
despite having lectured in human anatomy much more uh aligned to physiology uh and I spent
some time doing your physiological stuff you know many many years ago you know I talked to
him in GÃ¶ttingen um then uh in the uh classification this has to be that way uh and as we were taught
as medical students all was linked back to about the most obvious rather than the most obscure
but we have to have the whole range before us and this brings in the whole um the whole problem of
do we think in terms of very uh right or wrong concrete uh facts about stuff in general
or do we think in terms of the statistical range of variability whether uh this is uh in terms of
occurrences uh let's say related to um Poisson type distributions or to uh uh continuous
variants which can be let's say related to um Gaussian type distributions and unfortunately it
was only much later in life that I discovered that in fact uh modern statistics allows these two
approaches to be uh compared and contrasted in a uniform manner I didn't know that um
50 years ago alas uh which shows my my my my ignorance still uh I would come back to the
whole business of the growth um curve of of humans that this clearly has altered when we
look at chimpanzees and other great apes basically they don't have much of anything approaching
our adolescents they don't have this slowing down of growth and then a recuperation of the
velocity of growth combined with uh most important not merely anatomical and physiological changes
but also uh those of the mind uh the ability to uh innovate the ability to have lateral thinking
or the ability um which I have noticed in some um uh young people I've met with an
asperger syndrome to be able to concentrate in much great in great detail on particular matters
which are extraordinarily arcane such as Sanskrit literature uh in uh people that are not of a
South Asian heritage uh whereas uh in dealing with uh other people uh their other colleagues uh
they appear to be uh shall we say gauche uh and this is of course well known however and indicates the
range of variability but it is the change which we all undergo uh in not merely physical but also
intellectual uh ability and inquisitiveness uh which could get us into trouble uh when we are
in our adolescence and as young men and women uh given the uh continual and continuous changes in our
urinal architecture at least until our mid-20s these days which I think distinguishes and has
distinguished the evolution of uh homo sapiens well homo in general and homo sapiens in particular
but I wouldn't rule out Neanderthals or even homo erectus and which I think has been cumulative
and undoubtedly although we have no idea undoubtedly
enhanced by uh increased excuse me and ever ever more complicated uh communication
during the the past probably half a million and certainly quarter of a million years
this curiosity what would happen if we did this what would happen if we did that um but
even so things are not rapidly uh grasped and we see that in different parts of the world
particularly in modern populations even that have been long separated from each other
not everything is developed at the same rate a couple of well-known examples
are for example uh the wheel which first appears probably on the Eurasian steps about 5000 years
ago and was used for traction and then appears quite independently in pre-Columbian Mesoamerica
um about 2000 years ago and was not used even that would have been very useful
but even anything as simple as a wheelbarrow but simply to move around in your images
whether they were dolls or toys or gods with no idea and another one taken from the same
two areas of the world uh is the metallurgy of copper which appears about well perhaps over
6000 years ago in Eurasia and possibly 2000 years ago independently in the new world
and yet other things happen too for example in Australia we find modern people were making
hand axes when these had long ceased to be made by anybody outside your uh Australia
some of them may even be um only a few thousand years old so this
appearance and disappearance and reappearance is something which has not gone away and must
be related somehow to our ability to to this deep generation of our inquisitiveness our curiosity
and indeed our ability um to not to see the most obvious thing around us the desire to see
only one simple solution uh this uh which so irritated me when my teachers in the
in has a department when I was a medical student believed that there was only one
right answer asked how many heads this muscle had or which um how many how many
vertebrae there were and this and all that part of the vertebral column
that alone in the skull and we know how very variable these matters can be so
there is this tension between the desire for things to be seen in one light only
in a one-dimensional way and our natural inquisitiveness this deep deeply generated
desire to say what would happen if it was like this how is it how has it come to be like that
why is everything different and not the same I can't put it any other way with that I've said
of course you know thank you Michael Dean
thanks Daniel um so again this is for the authors this this has been really helpful to me
as observers because that's that's highlighted um very clearly in the papers I see both papers um
speaking to something that I would describe as condition set meaning
in the papers examples limit the game to the game metaphor at least to this type where there's
a limited number of tiles and a and a clear continuation until a conclusion or recognize
the limit of the species to not cracking so there there's a there's a real clear idea and Michael's
and Hector both spoken to so what was the what was the growth limit of the of the
brain's capacity etc well I'm curious about and I and I don't know if there's a Michael or Hector
have a a real clear answer to this but I'm wondering what and when was the
the was maybe the range of time that we see the unlocking or or or sort of combinatorial
explosion or not but what I guess what I'm asking is is is there a move that we can
clearly see as being something that differentiates playing which we know happens in a lot of species
and gaming because as I said at the end of 53.1 I wondered if it was going to be game on
and so I'm I'm curious what the authors think about that is there a difference between playing
and gaming meaning that there's now an actual introduction of strategy in this um so maybe
another way of asking it is there a moment when you guys can point to it and say this was kind of
when we saw a a reducing or maybe a relaxing of a of a limit forward world
I wonder whether in fact this difference is really quite as great as Dean suggests
and whether it may be have something to do with the ability in working memory and other aspects
of memory in dealing with or in developing a logical mathematical ability to plan or in planning
and in communicating disability such that the planning is no longer at an on an individual
level but is participatory and therefore again in other words and perhaps Hector can answer
this question but I would suggest that this developed slowly gradually and by no means
in a continual let alone a continuous manner in Homo but not in earlier in a way it did not in
earlier and other hominid species do we see and this I would ask Hector do we really see
um let's just say uh well chimpanzees or other great apes developing the kind of
logical math ability to make very very simple combinatorial
associations between objects or behavioral activities and developing this into a communal game
which involves other individuals in the group because as Hector has remarked on various occasions
and informed me when we see things like nut fat in small groups of chimpanzees by no means
is copied by all of them let alone copied or emulated by all of them but and by no means
even when it is with faithful accuracy and precision in the manual operations that are
required so that I would ask Hector do we see these associations being transformed into games
okay that's a tricky question um
I mean what we know with chimpanzees is that they have promised to do these second organ
relationships which is like hierarchical um ordering of for instance if I have a set of
objects I can classify them attending to the color for instance chimps could do that okay if
only color is involved but I can classify them by color and shape so this is another order of
of hierarchy so I can pick things that are square and red and put them together so this ability to
abstract um a kind of ordering category so that I have relations of relations like in
analogical reasoning when I I can focus on one dimension or in another simultaneously so I can
shift my focus from one dimension to another in order to classify things this I think it's
quite human like for instance the Wisconsin card sorting test so I can shift from one dimension
to another to classify objects or cards and this is something that chimps would have more
problems to do so they might classify in a first order categories like I put things that have a
same color they could learn to do that that wouldn't be a big problem but I guess they have to use
two dimensions together to classify objects that we have more problems because this involves
considering more one that more than one dimension simultaneously I'm not sure I'm making sense here
this is the the Jonas Langer work that he did with with kids and that's a remarkable work that
Jonas Langer did and then there were these people in Rome I think it was Poti at the lab of
um Biopark and Rome that replicated that with um with chimpanzees uh I think it was a spinosci
who replicated it and found that chimpanzees were more compromised in order to have this kind of
classificatory relations of relations so and I think that's a very very remarkable ability that
that uh that we develop so I don't know if I answered your question Michael
perhaps that comparison of two dimensions color and shape and then the snakes and
ladders overlay that lets us take the hypotenuse is that abductive jump enabled developmentally
and neuro epigenetically by all of these different features which happen over much slower
timescales especially considering the actual millisecond timescale associated with recognition
those other changes are so much slower but the ability to move diagonally on the grid
through the rows and the columns and turn that into movement on a manifold
is the ability looked at from the either row or column perspective to move in both at once
but by condensing those two dimensions into one there can be new kinds of cognitive movements
and then applying that cognitivist lens also evolutionary transitions even without the complex
cumulative feedback with the eco-cultural niche merely in the um abductive moment
and just one other piece I wanted to return to is that every variable can have a precision
estimator or not in the generative models and active inference every variable can be fixed
and so the model can just be persistently surprised with no updating or one can have any
kind of prior or hyper prior and so on and that enables learning and that's what enables not just
estimation of the mean or the center of gravity the expectation of but also the variance the whole
distribution and then it's um by applying that kind of precision on everything view which as
Michael brought up is exactly what modern statistics does you can't do
inference with a t-test unless you have the mean and the variance
we won't go into any more details on the statistics but every variable has the
center of gravity mean estimator and the variance estimator and so we talked about precision on
sensory information the mapping between observations and hidden state estimates
and then also there's this action oriented precision on how things will unfold
and you might be able to update your precision on sensory evidence by seeing something different
but updating your precision on how things will unfold is oriented around taking actions
and
Daniel you must have some questions I can't be the only one floating questions and having my
zone of bound and surprise of being expanded here
I I have um questions I can ask you a question or Michael or Hector or Carl please feel free
if you're only I would like to pick up with something that professor please don't mention
before and that was kind of it was intriguing because it is true that some great artists like
Van Gogh and others were very creative and also I don't know if it's appropriate to say
that they were in the verge of psychosis I don't know if it's appropriate because I
don't have any statistics but I'm thinking if being innovative is this again is misfiring so I
would like to separate two things one is how innovative you are and I'm thinking in the
economy if you are well adapted to an environment it's not a good idea that you try different
things all the time because imagine that you have some place where there are nice berries
you have discovered a safe path to that place and if you keep to that path you go to the berries
you get there you feed so that's good for you imagine you want to try something new so you
are very innovative and one day you decide to try another path to the berries a shortcut so you have
one risk that you can face new dangers because this path is new you don't know what is waiting for
you there the other is you face it that you can get lost and then you could spend the energy you
need to survive so in a way I don't think that being innovative is good in itself but we have
the risk if we are too conservative that the environment changes and if the environment changes
significantly we are not well adapted because we don't have alternative behaviors that are
adaptive to the new environment so I guess with this happens like psychological traits
nobody has extremes so we don't have people with extreme psychological personalities I mean
we have pathologies but the selection has favored kind of intermediate levels so I guess
and Professor Friston can correct me on this he knows more about psychopathology
but I guess it happens with innovation that we need some kind of balance and
what this is doing for me is how humans escape that balance in terms of how they
manage to be creative and innovative at times because we are very good we repeat many routines
so but still we can be very creative and we have selected so we have been successful in
up to our recognition and I'm just thinking in this counterfactual idea so I think this
might have played a major role the ability to have counterfactuals because perhaps
instead of risking my life every time I innovate I can rehearse what will happen and as Professor
Friston mentioned before if I have a good precision I can imagine things that will unfold
if the genetic model is very deep I can think ahead many steps and see how I will fare in the
future so I can kind of rehearse things in my head before I put them into practice in the real
world and this might help me to be innovative but with a kind of bounded risk or controlled risk
I don't know if this makes sense but I think it must be some kind of balance between
if I can rehearse things in my head I'm very good and predicting things that will
evolve or unfold many steps ahead I can see how I will fare and then I can risk to be
innovative I don't know I mean I'm very I'm being very speculative here okay so I just want to
make clear that I'm being very speculative
please Cara yeah no I'd like to speak to that yeah I don't yes you may be speculating but I think
those those observations are very very little and very and very useful I mean you've brought a
number of fundamental issues to the table first of all the importance of being able to plan
to have a generative model of the consequences of actions is not the gift of all species and
and in some instances in your words when the environment doesn't change you that would be
an undue complexity cost to carry around a brain with a generative model of the consequences of
my actions if I don't need it if I was a virus or an insect I wouldn't I wouldn't need that it would
be it would be very inefficient and so that sort of lens brings you to a picture that our world
is sufficiently complex and changing at pace the committing to very simple underly expressive
generative models is not an option and one really important way of making the more expressive is to
increase that temporal horizon or temporal depth so that we can you know in accord with things like
simulation theory roll out into the future and and now become the kind of phenotypes that can
select among a number of plausible policies and you know I think that would be one bright line
between lots of you know different genres and different species you know that could be just
drawn on a dimension which is just the depth of planning that my generative model will support
and we've talked previously about that being constrained by the precision afforded in a given
context my beliefs about how I would roll out into the future so I think that's just you know
from the from my perspective at least that's a really important observation that the depth of
planning is a very important functional characteristic of the generative models
that are implicit in phenotypic behavior and possibly in terms of what what kinds of models
are subject to selective pressure at an evolutionary or indeed at you know an eva diva at an eva diva
level and the other the other I think key insight that you bring to the table here
relates to what affords the right balance between novelty seeking exploratory behavior
and the risks that that would entail and I think you know that from a purely sort of mathematical
point of view is a really important observation just to sort of join the dots with other ways
of understanding how the universe works that particular question is very
usefully framed in terms of constraints so the free energy principle that from which active
inference inherits is one way of or is dual to something called the maximum entropy principle
under constraints so this was brought to physics in the 20th century by a foundational thinker
et james who basically rewrote physics in terms of probability theory and said that basically
everything of interest at least or physically conforms to a constrained maximum entropy principle
so that actually is just an expression or form
for 10s the free energy principle in the sense that the constraints
in from the point of view of free energy principle are just what is brought to the table by a
generative model and the entropy pertains to the entropy of belief so you've got this
this dialectic simply at the level of the physics of measurement and inference
which means that I'm always trying to explain any measurement
in such that my predictions are as accurate as possible but at the same time
leaving having the maximum of the attitude so that I don't over commit in accord with
Occam's principle so mathematically what that means is the entropy of my beliefs has to be as
big as possible provided I provide provided I have an accurate given the constraint that my
account on my measurement has to be an accurate measurement so that that may sound if you like
completely unconnected to whether I choose to wander away from the very path and but in fact
exactly the same maths applies to these quantities either the constrained entropy
or the variational free energy in the future and what happens is you get exactly the same dialectic
you have two pressures on one hand to comply with Occam's principle or Occam's razor
and on the other hand to
to keep all your options open which in a sense is exactly do I comply with the constraints
that I know I'm going to get my barriers and I'm not going to be eating my myself by a predator
or do I keep my options open and try that other path so this this so dialectic is just baited
into the physics of any self-organizing system and practically you know it emerges in a number
of ways one way of writing down the free energy or the constrained entropy from James's point of
view expected given a particular policy do I go down this path or that path is in terms of ambiguity
and risk to you're using exactly your words you know so the risk is just the relative entropy on
the divergence or discrepancy between what I think will happen and what I expect to happen to me
so I expect not to be eaten and that's the key constraint at hand here there's not about rewards
anymore we're throwing away the notion of rewards and we're now replacing it with a multi-dimensional
construct which is all the constraints in the ways of being like having a certain temperature or not
being very cold or very hot not being eaten not being dead just keeping within my characteristic
states so you write down those characteristics states in terms of constraints and those constraints
basically preclude certain states of being and then I just compare well what will my states be
if I do this and how far away from how far away is that anticipation from my prior constraints
and that literally is called risk it's the KL divergence between your policy dependent
predictive posterior and your prior preferences that have the constraints
the other thing is the ambiguity and that simply reduces to making sure that you make moves in a
way that underwrites an unambiguous precise mapping between what you see and what caused your
sensation so you avoid dark rooms basically you avoid the dark you avoid dark alleys you don't go
where you can't see what's happening so that's the ambiguity so together the expected free
energy is equal to risk plus ambiguity and when read like that then the balance between
the risk and the ambiguity or another way of carving this up is in terms of expected information
gain and expected cost or its complement expected value where the value is just how to what degree
am I complying with my constraints is enables you to to now write down the balance that resolves
to a certain extent dissolves that dialectic by the precision of your prior preferences your
constraints so if you're the kind of creature or child or insect that has very precise beliefs
about the kinds of outcomes I expect to anticipate and I may have very precise beliefs about my body
temperature for example but I may have very less precise beliefs about where I am in terms of latitude
I could be in Alabama I could be in Newcastle London I can still be me but I can't be minus
your minus two degrees centigrade and still be me so some constraints are very precisely
specified and other constraints are less precisely specified so the risk is you know
is determined by the precision of your prior beliefs about your characteristic states the
precision of the constraints you bring to the table as a phenotype and some people will be innate
and completely sub-personal it's wired into your home ostensis and some will be learnable some may
even be sort of oppositional you know we can talk about them but whatever they have to be that
because they define basically what kind of thing you think you are and how you act accordingly
so the balance between the you know whether to go down another path as opposed to the berry path
is going to depend upon this particular creature of phenotype and specifically the precision of
their prior preferences in terms of what outcomes they would a priori entertain and if they have very
very precise preferences of not being eaten and there's even a marginal small probability of being
eaten if they stray from the current path then they won't explore if on the other hand they
have a slightly more liberal expectation about being about the encounters with the predator for
example and then there will be more there will be more likely to engage in novelty seeking and
exploratory behavior so you know perhaps put this even more simply you know that this is the
exploration exploitation dilemma written in terms of the physics of self-organization under
planning and you know and it all reduces again to precision and in this instance it's the precision
of the constraints that are articulated as the your prior preferences your characteristic states
your the kinds of states that you know you are you believe characterize you that if you stray from
you cease to be you cease to exist basically so I thought I was I thought you know that's I don't
think what you said was speculation I think they're all fundamentals of behavior and actually
um from an ecological perspective you know they speak to the heart of the of choice behavior
and you know why we do the things we do and why it is always in the background the game
of saying do I explore or do I play it safe awesome thank you Carl Dean
I think you'd muted Daniel oh thank you thank you Carl go ahead Dean
I just like to run with what Carl was saying
this is mostly for Hector and Michael um
here's a here's a here's a case in point all the collective wisdom on the side of a volcano
can suddenly be arrested and yet there is still a Pompeii today I wonder what you gentlemen think
that says about certain species zone of founded surprise
Dean does this refer to the material the fixed materiality alone of the ruins of Pompeii
of which no more will ever exist in the
archaeological context being able to be unpacked into this collective wisdom
I'm just curious because we are talking about regular irregularities and regular irregularities
these these seismic events occur in the timeline and I'm just curious what we think then as we
reflect on that and still adopt that kind of risk mindset as I said I just want to run with what
Carl was was suggesting and I don't know that I don't know that there's an equivalent I don't
know if I if I if chimpanzees would do what humans have done like see the evidence and still
you know park themselves right in the path of of danger I'm just curious what they think about that
in terms of the timeline aspect of this
Hector or Michael go ahead
I don't think you're muted now Hector
sorry my microsoft
so it's a kind of difficult question Dean I'm not sure if I understood correctly
but as you're referring to the zone of founded surprise and linking what what Professor Christon
said before if I'm to take any road which is I don't know what awaits for me there okay
but if I'm very good at making guesses or inferring what might happen based on information I have
gathered before so I'm good at anticipating what might unfold okay because I have this complex
machinery let's call it working memory which is a construct I have a powerful working memories
for I have entertained many possibilities and there is something that kind of
ring bell when Professor Christon was talking of precision which is the concept of metacognition
so metacognition refers to thinking about my own thinking right so I and you have to clear
to clear aspects one is how sure am I about my knowledge for instance I'm sure I know
something even when I cannot remember this is the tip of the tongue effect so I can be
or I can give you an answer and be 100% sure this answer is correct I can be 80% sure 50%
sure so I can evaluate how much sure I am about something okay so this I think it looks a bit
like precision so if I make some expect plans and I think one might unfold I can be very sure
this will happen or not and this probably has to do with my metacognition so how sure I am
about what will happen and that might help me to decide whether I go or not
and coming back to your son of under surprise I'm not sure if I'm digressing but perhaps I can
preempt the surprise if I have a good precision or good metacognition so if I'm sure that I can
rehearse things in my head and see how they will unfold they won't be that surprising later
so I'm just speculating perhaps this ability to have counterfactuals to have this kind of
rehearsing in my head and this depth of generative models can be empty surprise and here I'm
speculating clearly so I don't know if I answer your question about Pompeii because I'm not sure
they understood but just bring some some ideas that might be useful but again they are speculative
it'd be nice just to link that notion of metacognition and having beliefs about beliefs
you know the precision of a belief about the likelihood of being eaten by a predator
I think that's what Daniel was speaking to before when he was talking about the hierarchical depth
of models and their increasing complexification one really important way of making a model more
expressive and context sensitive is to induce a hierarchy of exactly the sort that Hector was
talking about in terms of this metacognitive aspect but not just content but crucially again
coming back to the confidence and the precision I think that's a really central concept and I
was just thinking you know if you had to commit to what kinds of epigenetically specified constraints
you would associate with the genome what in what space would they live
and my guess is that most of it is about the constraints and within that it's going to be
the constraints on the precisions that there are certain sort of innate ranges of outcomes that I
will entertain and in in principle at least you can actually just write down an entire
generative model in terms of constraints and in terms of precisions in the sense that if the
generative model is universally expressive and everything goes then you can sort of carve out
an apt structural form for that generative model despite shrinking some of or 99.9% of this overly
expressive generative model to zero with very very precise constraints so well perhaps I'll
turn this into a question if you were trying to simulate artificial life in its most generic sense
if you're trying to simulate tool use for example the emergence of tool use in a synthetic
population and you had to actually write down what could be asked via genetically or epigenetically
to each subsequent generation what what kinds of things would you specify
that's kind of my question in the same in the same sense how do we
where where do we draw those arbitrary lines I mean it's this it's the thing that comes up again
and again as we continue to sort of see the next the next sedimentary layer of papers discussing
this right but the but the fact that it can be moving and the fact that it it isn't there is
a rate constant that you mentioned in the last live stream that has to be
working functioning and effective and then there's still this question of so
so what is our our but what are we attending to and what are we still available to all at once
and how do we organize that in a way that it most closely as you say precisely if that that's
the best way to describing it what's really going on and that that's that that seems to me at least
to be a moving target just one quick speculative mapping as well first the um instead of just
stacking bricks with content on content on content intercalating layers of content estimation
with metacognitive estimation is what allows the extendability of the multi-layer predictive
processing type architectures it's actually like the back and forth or the interplay between
the content estimators and the variance estimators that allows that model to
not just be described in terms of its center of gravity but also in terms of its full distribution
and then to Carl's question about what is being passed down genetically and epigenetically
and thinking about those terms even generically like in the context of perhaps source code
and a configuration file or some other mapping of like what is inscribed from a classical information
genetic perspective and then what is contextually and more rapidly transmitted there's an interesting
angle I could see it this way or potentially the opposite but there's a shorter term epigenetic
firing rate and then a slower updating of neuromodulatory like genetic possibilities
kind of opening and closing valves over a slower timescale and then of course these are nested
within another one so what is what is neuromodulatory this can also itself be a firing rate in other
ways but just focusing on this direction the inscribed constraints are like the width of the
aperture and then the actual flow of the photons through the lens is an instantaneous firing rate
that's happening way faster than the aperture can be dilated or not and so merely the fact that there
are multiple concurrent timescales and the associated interplay of their rate constants
tells us a lot about this kind of learning architecture what we do without understanding
is the action question and related to our preferences and precision however it seems
pretty key that to alternate estimates about content with metacognitive type estimates
and to package that set of two belief distributions mean and variance to package those also as one
so it can be handled as a composite one
and just to point out that learning rates are the manifestation of that second order
specification that precision so they are the same thing at every timescale
so you could articulate the developmental stages for example the
rejuvenation but certainly the changes say in late adolescent
as a programmed learning rate or learnability that can be read at some level as a precision
because the precision is just the rate constants that link the state to the rate of change of the
state and that basically is just a learning rate at many many different levels so I think it was a
sort of uniform way of putting together these different notions some useful notions here
from machine learning are sort of the notion of learning to infer you know so I was just
thinking about my an answer to my own question and clearly you can't write down a generative model
that's going to be able to get up and go to school in the morning all you can do is to
create a self-organizing blob that has exactly the right learning rates so that it is has exactly
the right learnability so that it can acquire a generative model and learn through experience
dependent plasticity that model of its little lived world of course that little lived world
has been constructed by other grown-up babies so you know we get back to this circular
causality that evolution is trying to provide you with the right ability learning rates,
precisions and structural constraints on your generative model but your generative models
from the evolutionist point of view are actually creating the environment that has to be learned
so there's to my mind isn't there's you know a very beautiful circular causality here
that you know as fast as you're learning you're actually creating new worlds in which to learn
you know I guess we're seeing that at the moment with the advances in technology and the like
which brings me back to my question about the sort of the top-down versus bottom-up causation
about you know what is a good model of this world what is a good phenotype?
in our final 15 minutes or so here how do we move beyond the 53.2 either to the authors
their directions and excitements about the work or anyone's exhortations or
raising of possibilities for other ways it can be developed
I wonder if it's worth bearing in mind that
increasing technological not necessarily complexity but at least variability
may well have permitted a reduction in selection pressure on the
phenotype and evidently affecting both the genotype and epigenetic
variability I see this because I would like to draw attention to the the graph which I
presented last week which was taken from Professor Philip Tabars's work on early humans
showing an increasing range of variation in the cranial capacity of
bipedal hominids from the osteopathy signs through to homo sapiens suggesting a reduction
in selection pressure for particular well for the size of the brain basically
I find it hard not to relate this to the advantages that slowly accrued to
tool use and thereby of course the variability and variation of tool making
thereby reducing the risk or some of the risks existential risks
that otherwise plague or have plagued other hominins whether extant whether the ancestors
of extant great apes or indeed the earlier forms of bipedal hominin and osteopathy signs
palanthropus canianthopus etc well who knows but it's perhaps
um not totally irrelevant that this variability has grown over the past couple of million years
and is now very wide as I mentioned last week
this I think is in contradiction to the the way in which
selection pressures have been highly discriminatory in for example producing let's say the wide range
of Darwin's famous Galapagos finches yeah just to give a well-known example
thank you Carl can I ask um coming back to this theme of um selection for selectability
um and the notion of precision or learning rates cast in terms of mutation rates so
you're my favorite example of and I'm sure there are better ones nowadays when I was reading around
this subject my favorite example was um the story told by Ernst Merer about Drosophila fruit flies
being reared in volatile versus non-volatile environments so you're rearing generation after
generation at a fairly fixed temperature and then an equivalent set of generations where they've
varied the temperature um you're a few degrees plus and minus um and what they showed was that the
mutation rate of the Drosophila in the volatile changing environment
was greater than the mutation rate the genetic mutation rate in the less volatile population or
transgenerational populations which I thought was a beautiful example of selection for selectability
itself that you know that increased variation um certainly or it's you know a phenotypic
expression of implicit increased genomic variability was itself an adaptive response to
the rate of change of the environment so my question is is there a similar sort of picture
or view of um variation in um either phenotypic or genetic um characteristics in um over a longer
time scale in in sort of um human evolution uh and if there is is there any evidence um
that there's go that there is in the past century or so um
perhaps this is a bit of an ambitious uh ask but uh is there any evidence that the
there has been a sort of phase transition in the variability and the evolvability and the
associated um phenotypic variation the empirical or an empirical research agenda would be to make
a hierarchical active inference model and perform dynamic causal modeling on different
variability characters across levels of phenotypic and genotypic integration and have that model
in use but a very provocative and interesting question Carl
and to what extent is it happening with our cellular architecture and to what
extents are these processes happening with our niche given these unique cumulative cultural
generative model generative process thinking through other minds increasingly the production
of artifacts that enable not just offloading but outsourcing these do represent unique cognitive
niches and so it will be quite interesting to investigate perhaps if we each want to have
some closing round thoughts perhaps dean with the first word thank you because you know I hate
having the last one I'm just curious gentlemen thank you first again for for your generosity
I'm just curious now that you've dipped your toes in this this active inference institute
live stream world what are your what are your impressions is was it was it it was it helpful at
all who is next you okay so I think that's been very useful and mostly very I mean I've enjoyed
a lot to have this discussion with all of you so it's been very enjoyable and just for the future
I'm just wondering if there is such a thing like preempting surprise based on these counterfactuals
I guess maybe it's already written and discussed and it's all clear but I wonder that this might be
an interesting idea to explore if I can preempt to surprise before I act I mean for even acting but
that's kind of maybe that's resolved already anyway it has been fun thank you all honestly
thank you that makes me think about saying I don't mean to surprise you but that's actually
going to increase it's like oh boy has someone been injured but what is the show not tell
of preempting surprise so that with a linear string in time there is the path from the old
berry patch to the new berry patch such that it appears to be within a nested hierarchical model
the path of least action to follow though in a less nested model it would be quite surprising
Michael or Carl your kind of closing thoughts or questions as we bring this set of 53 to a close
well I'll let Michael have the last word and
what you just said in Hector's comment I think there's a lot of interest in that in that notion
you know sort of trying to preempt surprise I mean a simple reading of risk minimization
you're just basically not engaging in policies that are going to result in surprising outcomes
where surprise is just the violation of prior preferences and so at that level I think that's
that sort of almost a truism but there is an interesting there's an interesting sort of
implication of that which leads to notions of the way that we choose to behave epistemically
in terms of avoiding information that would be very surprising sometimes articulate in terms of
optimism bias sometimes in terms of wishful thinking but the kind of paradox that you get
when we are Bayes optimal creatures and yet we don't want to open the letter from the GP giving
us our most recent cancer results or we don't want to open that letter whether we fail to get
that job or pass that exam or indeed the anatomy dissection survivor and there are certain things
that we avoid there are certain surprises that we avoid or split another way there are certain ways
of preempting surprise by avoiding knowing stuff that we might find surprising and that's an emerging
literature now which takes you a little bit outside your comfort zone but it's a fascinating
literature because you'll find things like trends in cognitive science and and the like
in answer to Dean's question about these sessions because this is not my first session so but
but this does exemplify it yeah it's for fun and we're amongst friends and indulging ourselves
and those people who care to listen to us so I think the next thing to do is the next horizon
although I do think dynamic calls the modeling of evolutionary trajectories is an excellent idea
I suspect the heavy lifting now is to get the ideas that we've been talking about out there
I think that's what Michael and Hector have to do basically it's just keep keep on telling the story
and in my experience usually takes about five to ten years before people start listening
thank you Carl Michael with the last word
well there have been these sessions have been fun and most illuminating there is a lot to be done on
the matter of whether there have been phased transitions in the evolution of what we might
call evolvability in again as Homer over the past two million years there are big
arguments amongst human evolution specialists between whether there was a unitary evolutionary
whether a unitary evolutionary model is acceptable or as lumpers like myself would like to believe
or whether in fact there was a big bush with a lot of dead end separate unsuccessful
species like homo flori ciensis, homo allelusoniensis, homo allelidae or even perhaps Neanderthals
with whom I've had a lot of contact have excavated about 15 of them
and these arguments are highly relevant to the matter of cognitive evolution and indeed
as to whether the record of artifacts and tools can indeed inform us as I believe it can about
just how and how slowly I would say evolution proceeds proceeded and of course the splitters
believe it happened in leaps jumps and leaps I'm rather convinced Darwinist I believe that things
happen very very slowly and that we have to concentrate and with this I conclude on
the especially the neuro epigenetic modification of genetic expression as affecting not merely
morphology and physiology but also I would say cognition and the matter in hand of course
the ability or not to let our surprises affect one lookers and other people
permitting let's say modification of behavior in a very wide in a far wider with far wider results
than those that occur in many other species including some of those of our closest
closest primate relatives and thank you very much for organizing this session Daniel and Dean
it's been a pleasure to take part I'm sorry that I have this terrible appearance but I
I really can't do much about that at the moment I had well lost a few days
thank you all Michael at least you have an excuse I have no excuse
all right till next time long live the mean long live the variants thank you
you bye everybody
You
