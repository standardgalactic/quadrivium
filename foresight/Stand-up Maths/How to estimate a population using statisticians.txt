It can be difficult to calculate the size of a wild population,
but thankfully, there are statistical techniques available
to estimate how big populations are.
And today, I'm going to put one of those to test in the real world.
So, I have come to the Royal Statistical Society's annual conference.
This is the biggest statistics conference in the UK.
There are a lot of statisticians here.
But how many are there, right? That's exactly what we're going to do.
We're going to try and estimate the current population size of statisticians
by sampling them in their natural habitat.
I've found quite a large group of statisticians.
They're currently feeding.
Unfortunately, this is not all of them.
And statisticians don't all come together to feed or sunbathe or nest.
So, unlike some animals,
where you can just wait until they're all together and count them all,
for statisticians, we're going to have to do something a bit more clever.
We're going to have to do a classic capture, recapture estimation.
To help me with the experiment,
I'm joined by stand-up masses resident statistician, Jen Rogers,
who is also one of the vice presidents of the Royal Statistical Society.
So, she is technically working right now.
OK. Very quickly, how would you explain capture-recapture?
So, you take a sample of people.
You mark them in some way.
Then you release them back into the wild.
You leave a little bit of time for them to get mingled back in again.
And then you recapture them and you count how many are actually marked.
OK. And to mark our statisticians, we've brought some stickers.
And the plan is just to take these and put them on the back of the conference badge.
Stick it. Easy.
We're going to go around.
Behind us is the poster session at the conference,
where people are presenting their statistical findings in poster form.
We're going to label every single person here.
Let's do it.
So, why have we picked the poster session?
Well, if we'd gone through one of the talks,
we would have only had a particular type of statistician.
So, it might be medical or environmental.
By choosing the poster session,
we're hoping that we're going to get a random mix
across all of the different statisticians that are here.
And there are a couple of other assumptions that we need to make
when doing this capture-recapture.
We're going to assume that no one leaves the conference
in the time that it takes for us to recapture.
And we're going to assume as well that nobody else comes in.
So, we need to make sure that the numbers are staying around constant,
which is a pretty reasonable assumption at this conference.
And when we do our resampling,
we need to make sure that we also do that randomly.
We're going to be doing that later on in the day.
There are other options than just capture, mark, release, recapture.
You can do it several times for a more accurate result.
Here, I have a population of confectionary children.
I don't know how many are in here. There's just over a kilogram of them.
I'm going to sample them several times
to try and estimate this population.
So, my first sampling is going to be this many.
That is... You know what? I'm going to label them and chuck them back in.
Five and 15, 17.
OK, so I know my first capture was 17.
They've all been marked, except I've numbered them from one to 17.
So, when I recapture them, I will know exactly which one is,
and I can actually keep track over several recapturings
which ones have been captured how many times.
So, I'll have the recapture frequency. So, here's my next sample.
Here we go. And I've got one again.
So, there's one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve,
thirteen, fourteen, seventeen again.
Wow, that is a consistent scoop.
And I'm going to number... That one's now 18.
Thirty.
OK, so, I've just relabeled all the ones that came out a second ago,
and there are two new ones.
So, I've got a... That's a 14.
Wow, that is not very clear.
I've got a 14. That's come out a second time.
And number one has come out a second time.
So, I'm going to increase both of those.
14 now goes up to two captures.
One goes up to two captures.
So, I've now had an additional 15 that I found for the first time.
And so, that brings us up to 32,
which have been uniquely labelled.
And so, I'm going to add all of those into my tally.
I'm now going to do this for as many times as I can be bothered.
We're going to go for 10. So, we've done two so far.
We've got a frequency table for how often each one has been captured.
Now, I've got all of my stats.
We're going to crunch them and see if we can calculate
how many confectionary offspring are in that bowl.
OK, I think I've put most of the data together.
So, we've got the 10 times we sampled.
And it was an average of 16.9.
So, 17 suites per sample.
And then, 48 of them were only picked out once.
42 were picked twice.
10 were picked three times.
Two were picked four times.
And then, none.
Zero were picked five or more times.
I've put that into a bar chart.
Here are the ones that were picked once, twice, three times, four times.
And then, that's it.
And there's a missing column here
for the ones that were picked zero times.
That's what we don't know.
We've got to try and extend this distribution somehow
to work out how big zero is.
We could do something clever, like a Frisson distribution
or a geometric thing.
Like everything in statistics, it gets very complicated very quickly
and I am dangerously underqualified.
So, I have just approximated using probability
now that I know the average sample size,
what distributions I would get for different population sizes.
I'm just going to guess.
I'm going to scroll through a bunch,
find the one that's the closest match to this,
and assume that's it.
So, we know there's at least 102.
So, if I set my population to 102,
that's the distribution I would expect.
As you can see, it's way smaller here.
So, obviously, there's more than 102
because there's some that we didn't pick at all.
So, it's got up to 150.
Let's see how that looks.
Yeah, that's a bit.
What if I go up to 180?
Oops, too many. 140.
Well, that's closer.
They're a little off, they're a little off.
These are quite close together,
so I might bring it down this measure.
130. Ooh!
That's not bad.
120.
No, too small.
125.
126.
140.
138.
138.
My official prediction is 138.
We're now going to count these to see how close we were.
A Jen is still here,
so it's going to be...
She's dangerously overqualified
for counting confectionary children.
OK, so I figured...
Not like I had anything better to be doing.
It's like you've got a conference to run.
OK, here we go.
So, I reckon we put them in piles of 10.
OK.
Oh, we can put piles of 10 in the squares.
Oh, we could.
Let's do 20 per square. OK, here you go.
OK. So, you're on.
One, two,
three, four.
Oh, wow, you're being a lot.
You know it.
It's still neat.
Not yet, not yet.
Sorry, I'm 10.
Do you have a minute?
Yes, yes, please.
Sorry. Wait, do you want us to bring them afterwards?
We can...
I can't do it.
OK.
How many is that?
Ooh, that's got to be two.
That's a two. That's a two.
I'm going to put them there.
One, two, three, four.
Seven.
They're ones that are, like, trap-shy.
Like, they're less likely to get caught.
That's true. You know, that's an important feat.
I mean, you can exclude it
as a... No.
No, it's the real world.
These confectionary children.
I'm just assuming I'm going to be right,
so I want to do it in a dramatic...
I mean... ...reveal.
One, two, three, four, five, six, seven, eight, nine, ten.
Uh-oh. Uh-oh.
Oh, no.
No!
11, 12, 13, 14, 15.
160.
160.
One, two, three, four,
five, six, seven, eight, nine.
169.
That's not 130.
No, I'm checking my bar chart.
Population of 169, you'd expect.
Oh, come on!
We should have trusted the tale.
Yeah. Didn't trust the tale.
We should have gone, this is wrong.
Oh.
This has not bowed well for our estimation
of the number of statisticians.
Uncertainty. You would always put...
Exactly. We've got the error bars.
We're in the room with a final closing.
Plenary sessions about to take place.
People are just coming in to take their seats.
And we're quite happy that if we take every person
on the end of each of the aisles,
that that should be a pretty good random mix
of all the different statisticians.
Let's do it.
Give a green sticker.
Is that OK?
OK.
David Spiegelholt has started talking,
so we have to get out because he gets very angry.
He doesn't, he's lovely.
So I had eight people with stickers
and 22 without stickers.
OK, I had 13 with stickers.
And 21 with stickers.
24 without.
OK, and then there's 21 with stickers.
So we had a total population...
I'm going to add going up of 67.
Yeah.
That's surprisingly close to last time.
Is that good? I don't know.
The way the equation works out is
we assume that what we just did now
is work out the proportion of the population
we previously stickered.
And so the number of people in the first sample,
we stickered all of them,
divided by the total population,
and the second sample, who were stickered,
divided by the size of the second sample.
Yep.
So if we multiply the first sample size
by the second sample size,
divided by the number of stickers,
which I'm going to put here,
so it's 64 times 67,
divided by 21,
that is our estimate.
So I'm going to work that out.
Jen actually knows the correct answer.
I do.
Because she's on the organising team.
So I will...
Do I have to round to the nearest whole statistician?
Yeah, we don't have many half statisticians here.
Well, if there's anywhere you're going to have
a fraction of a person, it's here.
OK, so...
OK, so we're going to do, like, a 1, 2, 3 reveal.
Yep, sounds good.
OK, ready? 1, 2, 3,
204.
475.
So no.
Get home!
I must have done that wrong.
Did I do the maths wrong?
That's horrific.
So...
Hang on, I'm going to do it logically from the top.
So we're saying that 21 divided by
67,
we labelled about a third before.
Yep.
Yeah, at times about 60 is about 200.
Yep.
And what is it, everyone who's here today?
475 are here today.
So in conclusion, statistics doesn't work.
In conclusion, statistics is difficult.
So we got nowhere near it.
204.
I mean, there are several reasons what could have gone wrong there.
This is the very end of the conference.
Loads of people have left.
There are not 475 people still in there.
I mean, people are leaving right now, see?
So 475 was more of an upper bound.
That's the maximum number.
So if we'd gotten more than that, we'd been worried.
Under that is fine.
And frankly, it's the correct order of magnitude.
I refuse to accept there are 475 people in there.
And I guess more importantly,
as I was sampling statisticians at the end, they're like,
oh yes, but actually there's going to be a lot of overlap
between the sorts of people who will go to the poster session
and go to the general plenary.
They're the ones who are interested in a wide range of things
and being engaged in the community.
And obviously some people will just come in for their seminars
or their subsection and go.
And I mean, we could have done a better random sample.
We could have done a bigger sample.
We should have done more samples.
So basically, in conclusion, we didn't put the effort in.
And when I did do more samples with the confectionary children,
I shouldn't have just eyeballed it.
I shouldn't have done a proper thing.
And that would have revealed that the tail was the bit
I should have been matching, not the lead to cause.
Anyway, it's been great fun.
Thanks to the Royal Statistical Society for getting me along.
I'm now doing the after dinner like entertainment
at the closing conference dinner.
That'll be fun.
And thanks to all the Patreon people who fund these things.
So when I get invited to a conference,
I can, you know, bring a camera, make a video, put it online.
Thank you so much for your statistically significant support.
