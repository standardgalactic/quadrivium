Hello, Lionel. It's already seven o'clock.
Wake up. It's twenty twenty seven.
Don't wake up. You have a meeting at nine o'clock this morning.
In twenty twenty seven, Sarah takes care of everything.
For breakfast, what do I make for you?
A glass of chocolate.
Looking at your health data, I advise you to use soy milk instead of avocados.
Sarah is a virtual assistant who knows exactly what's best for you.
For your part of Squash, I selected Emmanuelle.
I crossed your data. This time, you're sure to take it.
For your dinner party tonight, I reserved this restaurant.
It's new and very well-noted.
It's perfect. Thank you.
Everywhere you go, artificial intelligence, like Sarah, predicts your needs and does the work for you.
Hello, Lionel. We're going to start. I've prepared a contract for our last meeting.
With all of these machines working for you, isn't life wonderful in twenty twenty seven?
But let's not get carried away.
Before Sarah changes your life forever, there's another story to tell, one with less special effects.
This story takes place behind the scenes of those businesses who are working to invent our future.
For now, it's hardly this wonderful world where machines are working entirely for mankind.
In fact, you could say it's exactly the opposite.
Humans are involved in every step of the process.
When you're using anything online, but we're sold as this miracle of automation.
Google, Facebook, Amazon, Uber, these digital giants are using a completely invisible workforce to keep their applications running.
There we are.
With technology, you can actually find them, pay them the tiny amount of money, and then get rid of them when you don't need them anymore.
A workforce that is disposable and underpaid.
On a very good day, I could do five dollars an hour. On a really bad day, I could do ten cents an hour.
Is it possible for you to pay less than the American minimum wage?
I'm not sure we want to go in this direction, yeah.
Whilst millions of men and women are training artificial intelligence for next to nothing,
others are being hired and hidden out of sight to clean up social networks.
You must have been told by the recruiting team that you cannot mention that you are working for this project.
We went undercover as one of these web cleaners, working as a content moderator for Facebook.
There are a few things that I saw. Those things are going to stay with me because I remember them as it was yesterday.
To meet the workers hiding behind your screen, we're taking you to the factory of the future, the digital economy's best kept secret.
You know, it's just like a sausage factory. They don't want people to come in to see how the sausage is made.
I mean, I think it's just that simple.
To delve into the mysteries of artificial intelligence, we're heading to the west coast of the U.S.
Here in San Francisco and the Silicon Valley, the world of tomorrow is being developed.
It's the high-tech hub of giants, like Apple, Facebook, YouTube, Uber, Netflix, and Google.
We have a meeting of figure eight, a business specializing in artificial intelligence that primarily works with Google.
The founder, Lucas Biewald, agreed to spend the morning with us.
Hello, Lucas. Nice to meet you. Thank you very much for your time. I know you have a busy schedule. Thank you.
At 38 years old, this Stanford graduate has already worked for the likes of Microsoft and Yahoo before founding his own company.
Once his microphone is on, a quick tour of their startup-style Californian office space.
This is our best dressed in play.
Cool and relaxed.
This is probably our worst dressed in play.
Do you play babyfoot? I think I'm pretty good. I don't know, maybe.
This is kind of our eating area. This is actually where I like to work.
My coffee got cold.
And in the reception area, an impressive display.
These are some of our customers and the different things that they did with our products.
Here's Twitter. We help them remove a lot of people that were kind of bullying on their website.
You know, American Express. Is that in France? Yeah.
You know, I feel especially proud of, you know, something like Tesco, right?
Is able to use us to improve their online website to show better search results so people can find the items that they're looking for.
And I don't see Google.
No, I don't know. Do you know why some of these get up here?
Frankly, we just stopped because it was getting out of hand.
This is Mr. Brown, head of PR.
This is a good scene.
After our visit, the founder explains the enigmatic name, Figure 8.
We call our company Figure 8 because we think of it as a loop.
And the loop really has these two parts, right? There's the humans that do the labeling.
And then the machine learning that learns from the humans.
And then it goes back to the humans for more labeling, right?
So we think of this kind of like beautiful loop, right?
Where humans do the best things that humans can do and the algorithms, the artificial intelligence, does the best things that the algorithms can do.
And we put that together. And that's why we call it Figure 8.
To get a better understanding of why AI needs humans to function, we stop joking around and get out the computer.
So here's an example.
You know, a lot of people these days are trying to build cars that automatically drive.
Like, for example, Tesla has a system where you can drive around in a car.
But of course, it's incredibly important that these cars don't run into pedestrians.
So the car camera just sees something like this.
So it's really important that they build reliable systems that can identify people.
And the way that they learn to identify people is looking at lots of pictures of what the car is seeing from the camera.
And then actually literally labeling where the people are.
Here's a real example of how it works.
If you want to teach a self-driving car to recognize a pedestrian, a human like you or I,
it first has to identify pedestrians from photos and then feed this information to the AI.
And this process has to be done over a thousand, even a million times over, which can be very time-consuming.
This is where Figure 8 gets involved, using real people who are paid to do this work.
So the task here is to look at this picture and then label where the people are.
And so you get paid for this?
You get paid to draw boxes around the people.
How much?
I'm not sure this task, but maybe it would be like ten cents per person that you draw a box around.
Who do this job? Do you have employees doing these jobs and labeling people?
Yes, so it's contractors in our network that log in and do these jobs.
What do you mean by contractors on your network? What kind of people?
So it's like people that log into this and then want to work on these tasks.
How many people work for Figure 8?
In this capacity as labellers?
Yeah.
So again, people can kind of come and go if they want to.
So there's maybe around 100,000 people that kind of consistently work every day for certain use cases that we have.
But then there's also millions of people that log in from time to time and work on tasks.
And where do those people live?
They live all over the world actually.
So they live all over America and then they live all over the world.
So who are these millions of people who are being paid to train AI technology?
In order to meet these contractors, as Figure 8 calls them,
we leave Silicon Valley and head 500 miles north of San Francisco in Oregon.
There we are.
Ah, success.
Jared Mansfield signed up to Figure 8 three years ago.
He now spends several hours a week working for them.
Every day, the company offers a list of tasks that he can complete for money.
For example, training search engines.
For this first one, it's showing examples of how to do it.
The query is mac and cheese pierogies.
And the two results are Annie's homegrown organic mac and cheese
and Annie's really cheddar microwavable macaroni and cheese, which are neither of them are pierogies.
So it's saying that one would be equally bad matches.
What's the use of doing that?
A lot of it, I think, is to train search algorithms.
So like when someone sits at their computer and types a product,
the algorithm will be able to determine with more accuracy
what product it is that that person is looking for.
For every ten answers, Jared earns less than one cent.
To get an idea of how much money he can make, we leave him to work for 30 minutes.
He's answered 180 questions over the course of half an hour.
How much have you earned?
15 cents.
For how long?
A half hour.
Which would be 30 cents per hour?
Yeah, which are pretty definitely not a livable wage, that's for sure.
Do they have the right to do this?
I mean, they have the right to do whatever they want.
I'm the one coming to them for little tiny bits of coins on this website.
And there's no contract between me and them.
No contract, no salary, no guaranteed minimum wage.
These ghost workers are paid to train software and robots
using only one rule, supply and demand.
It definitely feels like I'm part of this invisible workforce
that is kind of made up of just random people throughout the world.
And together we're kind of training what's going to replace the workforce as a whole eventually.
Jared is very philosophical about the idea.
Still, he can afford to be.
To earn a real living, he has another job selling chicken in the supermarket
for a little more than $1,500 a month.
Figure 8 is just what he does on the side to earn a little extra cash.
After leaving Oregon, we decided to take advantage of what we'd learned in America
and sign ourselves up to Figure 8 to train artificial intelligence.
On the site's welcome page, small tasks are proposed at 1, 2, or 12 cents.
We chose this as our first task, drawing boxes around objects in images.
Following the instructions, it took us a couple of minutes
to draw around 10 objects and earn 2 cents.
On the list of tasks, Figure 8 also offers evaluations of search engine answers,
Jared's task of choice.
We could also listen to conversations and confirm if the recording
features a man or a woman's voice, and if they are speaking English.
Hi, is James there, please?
We work for our team,
we work for hours without ever earning more than 30 cents an hour.
It's difficult to imagine that there are people who work on these tasks on a full-time basis.
We're in Maine, on the east coast of the United States, close to the Canadian border.
We've arranged to meet with one of the NET's ghost workers,
the human side of the Figure 8 loop.
Her name is Don Carbone, she is 46 years old.
Bonjour.
Hello.
Hello.
Nice to meet you.
Thank you so much for your welcome.
Beautiful.
Oh, we had a blizzard not that long ago, and then we got more.
And it's also, I think, negative seven out there.
Don is a single mother.
She lives here with three of her children.
This is what subsidized housing looks like up here.
I mean, it's not bad for public housing.
She lives and works here, working on the Figure 8 site all day.
I'll turn it on, like I said, right before seven o'clock.
Get the initial stuff done.
I'll turn this off at three o'clock in the afternoon and then turn it back on at nine o'clock at night.
So, I'll say eight hours minimum.
I bust my butt though.
Like this would be the dashboard.
And you can see I've done 6,445 tasks.
Since when?
Three years.
See these different badges?
Yeah.
You start off, you have no badge.
And you have to do so many questions and get so many right.
And then you get your first level badge.
And then when you get to level three, you have access to virtually all the tasks that are put up.
What is your level right now?
Right now, oh, I'm on level three.
I've been level three.
I've been level three for quite a while.
Don is considered a high performing worker.
Figure 8 therefore offers her more work than a beginner.
But it isn't necessarily more interesting.
I have to put bounding boxes around people.
I'm not really keen on this job.
The biggest problem is trying to find jobs that are viable.
And right now, I don't have many.
And it's definitely not better paid.
On a very good day, I could do $5 an hour.
On a really bad day, I could do $0.10 an hour.
I mean, I have had some really, really good days until February.
Yeah.
Do you think this is a fair payment for what you're doing?
No, no, no, no.
Not at all.
But I live in Northern Maine.
We get a lot of snow.
There's a very low job market.
And it helps me as a stay-at-home mom.
It helps with added income.
Don prefers to work from home because her youngest daughter,
Jane, has autism.
Here you go.
What happened?
Don wants to be there to take care of her
when she gets home from school at 3 p.m.
So how was school?
Good day or bad day?
Really a good day?
With her autism, I always have to be ready to jump in my car
and go get her from school.
I mean, it could happen one day out of the week,
or not at all, or three days out of the week.
And the school is very understanding.
So I mean, I have to take out the whole week
if I was working out of the home.
Don receives $750 in government aid every month,
which isn't enough to cover all of her bills.
This is why she signed up to Figure 8.
By working eight hours a day and five days a week,
she says she earns, on average, $250 a month on the site.
On Figure 8, the pay is non-negotiable.
If you refuse the work,
there will always be someone else to take it.
There is an unlimited supply of these ghost workers,
coming from all over the world.
It's probably why Lucas B. Wald is so happy.
But he isn't the only one to take advantage of this phenomenon.
Various other businesses propose these sorts of repetitive
and underpaid online tasks,
the biggest amongst them being ClickWorker and Amazon Mechanical Turk,
a platform provided by Amazon and its boss, Jeff Bezos,
who invented the concept in 2005.
Micro-working is a growing concern for the ILO,
the International Labour Organization,
a UN agency in charge of protecting workers' rights across the globe.
Jeanine Berg is the resident expert on this subject at the ILO,
who speaks to us through Skype.
And the technology has facilitated this, and it's cheap.
That's us, the main advantage.
Jeanine Berg wrote a report,
calculating that micro-workers earn, on average, $3.31 an hour,
without any rights in return.
Workers' extreme vulnerability is the key to Lucas B. Wald's business model.
After months of investigations,
we found this video from 2010 that sums up his view of the labour force.
Before the internet, it would be really difficult to find someone,
sit them down for 10 minutes and get them to work for you,
and then fire them after those 10 minutes.
But with technology, you can actually find them,
pay them a tiny amount of money,
and then get rid of them when you don't need them anymore.
While we were interviewing him,
we wanted to ask him if he still shared the same opinion.
But when we start talking about work conditions,
the figure-eight founder seemed to lose his sense of humour.
Do you have an idea of the average revenue per hour of your contributor?
You know, I'm not sure.
It's totally dependent on the task that someone puts in,
and it's hard to track time on the internet
because people can walk away from their computer and come back,
so I don't know how much people don't really make.
There was a report on ILO saying that on average,
the people working on crowdsourcing were paid $3.31 an hour.
Would that be consistent with what you pay?
Again, I'm not sure.
Is it possible for you to pay less than the American minimum wage?
It could be possible.
So this is legal?
I'm not sure we want to go in this direction.
Can we take this a different direction?
I'd rather this focus on more AI than anything.
Yeah, but this is the whole thing.
This is about crowdsourcing as well,
so I have to ask questions on crowdsourcing.
I prepped him for more of an AI conversation
than a crowdsourcing conversation.
No, I don't really want to do this.
Yeah, we can find someone else to talk about this stuff.
Okay, so you're not comfortable with this part of the discussion?
No, no, no.
You're right, it is an important part of the conversation,
but I think it's just, you know,
it's not the AI conversation.
We don't have time to pull up the video.
Lucas B. Wald makes a heasty exit without saying goodbye
and leaves us alone with his head of PR.
One last chance to ask how the business treats these contractors,
as they call them here.
When I was working on this,
I found many people complaining, being disconnected.
I actually have to go now, too.
So it's 11 o'clock.
So you don't want to speak about human in the...
That's not my role here.
All right, I think we're done.
So only artificial intelligence, no human?
Well, that's what we were prepared for, so, sorry.
Okay, it's a pity.
To get some answers to our questions about Lucas B. Wald
and his views on his workers,
we thought we'd try a different tactic.
On the day the Figure 8 founder made his statement
on disposable workers,
there were other entrepreneurs amongst him,
as well as a researcher, Lily Irani, just on the right.
Ten years after the conference,
we find Lily living south of Los Angeles, California.
Lily Irani teaches at the University of San Diego,
and one of her specialist subjects
is the working culture of high-tech business.
We're lucky she has a good memory.
Do you remember if somebody reacted after this sentence,
which is very brutal in a certain way?
To be honest, the reaction was nothing.
I remember that panel, everyone went up to him to talk to him,
and two or three people came up to me
to talk about the ethics of this form of labor.
This is a room full of highly educated people in San Francisco,
and nobody batted an eyelash.
How do you explain that?
The kinds of people who have access to these spaces
are the kinds of people who never worked in a situation
where they wondered if they could make rent,
or they never worked in a situation where somebody gets sick
and they can't pay someone to go take care of them,
so they have to kind of take a really bad job at home.
And they have no connection to the kinds of situations
of the people that are willing to do this work.
It's what happens when you go to schools
like Stanford and Harvard and Princeton
that tell you you're the smartest person
and you're going to be a future leader
and you've been chosen because you're special,
and that you have the power to change the world.
A Silicon Valley elite who is out of touch
with the rest of the world.
This is the key to understanding Lucas B. Wald's logic,
although it's not the only part.
These workers are invisible by design.
You can write code and send your work out,
never talk to anyone.
It's designed so you can get the work back on a spreadsheet.
If you need to, you just see these, you know,
letters and numbers identifying the worker.
You don't see a name. You don't see where they live.
You don't see what their situation is.
You don't see, unless you keep track of it yourself,
have they worked for you before or not?
Do these ghost workers really know who they work for?
Have they ever heard of Lucas B. Wald?
We showed them the footage of the figure eight founder
talking about their work.
With technology, you can actually find them,
pay them a tiny amount of money,
and then get rid of them when you don't need them anymore.
You're giggling over and paying people pennies and,
yeah, bye-bye.
Okay.
Now I'm going to start arguing what I do about the AIs
when they get me agitated.
It's kind of surprising, I guess, a little bit
to see there's so openly,
openly talking about that view that they have of the workforce.
I guess it doesn't really surprise me that much,
but, yeah, it definitely kind of sucks,
I guess, when they could be paying them a lot more,
or at least showing some appreciation,
or maybe even some discretion.
Basically, saying in person, you know,
you hide somebody for 10 minutes and fire them.
This way, you don't have to look at the person
and you just, goodbye.
So that's kind of just, it is kind of,
the fact that the head of the company is,
people are that disposable,
that really isn't right.
I don't like that.
So I like what I do when I have something to say,
and I will say it.
So I'm not disposable.
Amongst this invisible workforce hiding behind your screen,
there are those who feed algorithms for next to nothing.
It's the people in charge of tidying up the web,
the social media cleaners,
who work on sites like Facebook or Instagram.
These workers are never mentioned
in the slick presentations of the Silicon Valley CEOs.
I started building a service to do that,
to put people first,
and at the center of our experience with technology,
because our relationships are what matters most to us.
That's how we find meaning
and how we make sense of our place in the world.
Today, with 2 billion users,
Facebook no longer has anything to do with Mark Zuckerberg's
initial vision of the site.
With violent videos, hate speech, and pornographic images,
more and more content has to be deleted.
And it isn't always robots doing this job.
There are, once again, humans hidden behind the screen.
Determining if something is hate speech
is very linguistically nuanced.
I am optimistic that over a five to ten year period,
we will have AI tools that can get into some of the nuances,
the linguistic nuances of different types of content
to be more accurate in flagging things for our systems,
but today we're just not there on that.
So a lot of this is still reactive, people flag at us.
We have people look at it.
These people are in charge of sorting and managing content
on the network.
Facebook call them content reviewers.
According to their site,
Facebook has 15,000 workers doing this job across the world,
in Ireland, Portugal, the Philippines, and the U.S.
We contacted Facebook,
but the company refused our request for an interview.
So in order to meet these moderators and understand their role,
we identified Facebook's main subcontractors,
multinationals such as Majoral, Cognizant, or Accenture.
We found this job offer for a content reviewer
for the French market in Portugal.
Gregoire is one of the journalists in our team.
He responded to the ad and was offered the job.
Before taking off, he received his contract,
which included his monthly salary, 800 euros,
a little over the minimum wage in Portugal,
with a food allowance of 7 euros 63 cents a day.
Facebook isn't mentioned once in the document.
Even when directly asked, Accenture refused to give the client's name.
I was just wondering, now that I took the job,
I'm going there, I'm doing it.
I was just wondering if I could know the name of the company
I'm going to work for.
No, we cannot reveal the name yet.
It's for a wonderful customer,
but we are not allowed to say the name.
This is where Gregoire will be working at the Accenture offices in Lisbon.
Before getting started, our journalist was sent to a welcome meeting.
The footage is a little shaky, as Gregoire is filming with a hidden camera.
Hello, I'm having a meeting with Accenture on 9.30.
Gregoire isn't the only new employee.
12 other people are starting the role at the same time.
Another French person along with some Italians and Spaniards.
An HR representative is running the welcome meeting.
Welcome, you all.
My job as career advisor is to help you
in all the relationships with Accenture.
After the vacation documents and social security paperwork,
the small group finally find out which company they are working for.
But it's top secret.
You must have been told by the recruiting team
that you cannot mention that you are working for this project.
The client is really very demanding.
You cannot mention anyone that you are working for at the Accenture.
If someone asks you where you work, you work for Accenture.
We still have this code name, they seal.
So if I'm talking to some colleague from Accenture, not from this project,
and he asks me where do I work,
I cannot tell that I work for Facebook.
This is not allowed.
It's completely confidential that Facebook is working here at this facility.
Codenames, confidentiality clauses, and a complete ban on cell phones.
Facebook gives you the life of a secret agent for $800 a month.
And if you're the chatty type,
the following argument should shut you up pretty quickly.
You have an agreement and you cannot break that agreement
because by law we can punish you by law.
It's confidential.
Cleaning up social media is a bit like doing your family's dirty laundry.
It has to be done, but nobody talks about it.
Why so careful? What does the job involve?
We continue discreetly with Gregoire.
Before becoming a moderator,
Gregoire has to follow a three-week training program.
Moderating Facebook's content doesn't only involve
deleting violent videos or racist jokes.
It's a lot more complicated.
At the moment, the algorithms can't handle everything.
Every decision must be justified using very strict rules.
This is what we learn during the training.
Every day is dedicated to a different theme during the program.
For example, nudity, violent images, or hate speech.
On the agenda today, dark humor and jokes and bad taste.
We will remove a violation if the person that you see in the image
we need to have a real person is visibly affected.
If you are making fun of the event,
then it's going to be in the market score.
What do we do when there's a knock on the event?
Here's an example of an inappropriate joke about 9-11.
It may seem over the top,
but there are dozens of rules like this for each category,
which can be difficult to get your head around.
Take nudity, for example.
Depending on what part of the body you see, or their position,
the moderator can't always make the same decision.
Here's an example from the exercises to better explain.
Gregoire decided to delete this particular photo.
But according to Facebook's rules, he was wrong to do so.
In the feedback session, the trainer offers this explanation.
If we cannot see...
If his head is not here, then it's ignored.
It's in between her boobs.
So if I don't see directly the contact with the nipple, it's nothing.
You know, that's exactly why I am having so much trouble to understand things.
You have an artistic picture of a photograph of a woman
and you show a tiny nipple on it.
On one hand, this is a delete because we have 100% uncovered nipples.
On the other hand, you have this almost porn photo.
And you don't delete because it doesn't feed the world.
That's exactly why I...
Yes, but you have a small problem because you're still going from what you think
in your decisions.
And we're in school to learn rules.
Applying Facebook's rules without questioning them is the number one rule.
A principle that will be drilled into you all day, every day.
There has to be a line and they drill it around that.
We just need to respect it and we just need to apply it to do our jobs.
Sometimes we'll find disagreements, but I mean, this is the good job
because this is not my social network experience.
A training program with the end goal of turning you into a machine.
Pedro worked for six months as a content reviewer for Facebook at Accenture.
He agreed to respond to our questions, but only if he remained anonymous.
Two years after leaving the company, he still remembers the numbing side of the rule.
You have to play by their game or else you won't have a job at the end of the month.
And it's got two points where I just felt I was a robot
and just doing as many pictures and videos as much as possible
just because that's the only thing I can do.
You're just there with numbers and clicking enter.
Numbers, enter, numbers, enter.
The hardest thing for Pedro is trying to forget everything that he saw on that screen over six months.
We're not prepared for it. We're not mentally prepared for it.
All these stuff, they don't really give us the input before
and it just comes to you as a shock.
It just comes to you as like a wave here, have this in front of you
and you can't really say yes or no to it.
If you give me a million euros, a billion euros, I wouldn't go.
It's not for me.
What Pedro described to us, the wave of shock that washes over you unexpectedly
is exactly what happened to Grégoire.
It started around the fifth day of training during the practical exercises.
A stream of horrific images
and unbearable videos that must be watched closely in order to make the right decision
according to Facebook's criteria.
The same horrific scenes are unfolding on his neighbor's screen too.
I'm going to open the window.
Excuse me.
I'll take a glass on the other side.
I'm not far from Vominier.
I just took a break because I saw the bodies of the members,
but the people who threw themselves from the top of the tower,
they were crushed by the ground.
The nose, the body that trembled, the hands that trembled,
it was really close to today.
It's like this on a daily basis for Grégoire and his group.
Luckily, they can always rely on the useful advice of the trainers to feel better.
If the macarena isn't quite enough to cheer you up,
the business also has psychologists available for the most traumatized moderators.
On this day, a video lasting several minutes
brought the violence to another level for Grégoire.
During the break, everyone tries to shake off the shock
by discussing the grim video they've just witnessed.
Grégoire realizes the extent of the damage this job can cause
when talking with a former moderator who is now a trainer.
I know that I have to be like this.
I can't watch people running across the street.
Anyone.
You're still doing this while you have PTSD?
There is a purpose.
I do feel every day like I'm cleaning the trash.
Right.
Okay, I will watch it, but at least I know that I'm going to watch it.
Someone who's 14 years old is going to quit that and not know.
Even two years after quitting the post,
Pedro still has very vivid memories of certain videos.
There's a few things that I saw.
Those things are going to stay with me
because I remember them as if it was yesterday,
it's very emotional sometimes.
I remember sometimes people used to like,
they were working, being productive,
and suddenly they just stand up and run out of the room.
That's okay.
Trauma built up.
And for Pedro, left him feeling helpless.
But if you see someone getting murdered,
the only action you take is the lead, for example.
You just erase it out of the platform.
You don't really go into depth of like calling the police, for example.
It's like, you never really feel content with what you're doing.
You're just going round and round in circles
and just like bombard with all this stuff.
It's like a mixture of emotions that you go through in one day,
eight hours for it.
How many were you when you started?
We were 30 when we started, 30.
From that 30, it started just decreasing month by month
until now there's only like three people.
Pedro claims that a lot of people struggle to deal with the role
and end up quitting.
To understand what Pedro went through
and what Grégoix and his colleagues are currently experiencing,
we met up with a psychiatrist.
Professor Thierry Boubet is a specialist
in post-traumatic stress disorder.
For example, he works with police officers
who have been involved in terrorist attacks.
We show him the footage we filmed.
Some potentially traumatic images,
like the ones described here,
can have several effects.
For some people, it's just anxiety effects.
It can make you anxious for a while,
sometimes in an important way,
with panic attacks or something like that.
But in some cases,
there can be what we call a traumatic infraction,
i.e. one of these images
or some of these images
will go deeper into us
and come back to us without any stress.
What's special about post-traumatic stress disorder
is that when these images come back without any stress,
they produce without any stress the same stress.
So it's a stress that lasts
and it doesn't disappear, if you like.
We also talk to him about the famous
confidentiality classes imposed by Facebook.
The secret culture and the interdiction
that is made in talking to third parties
is a process that belongs to the records
of what we call mental imprisonment.
Mental imprisonment is something
that is used by different movements,
like, for example, sector movements,
and it makes it even more vulnerable
to traumatic impacts.
Anxiety, trauma, stress.
Cleaning up social media comes at a great cost.
Grégoire decides to quit only two weeks later,
still in his training period.
He received his paycheck just before leaving,
his hourly pay written at the top,
four euros, 62 cents gross.
This is a tough pill to swallow for his colleague.
I was earning more in the ice cream shop.
In the ice cream shop?
Man, that's bad, right?
After our experience there, we contacted Accenture.
Their response was a brief email
that didn't once reference Facebook.
It did, however, contain this phrase,
the well-being of our employees is our priority.
To finish our tour of the Internet's trash cleaners,
the invisible workforce behind your Facebook
or Instagram feed, we had one last meeting.
Sarah Roberts is the leading researcher
specializing in those who work as moderators.
She is a key figure in this field.
We met her at the university where she teaches in California.
She presented us with an analysis of the rise
and development of content moderation over the past year.
We are talking about a scope and a scale of magnitude
that has not been seen before.
Billions of things shared per day on Facebook.
Hundreds of hours of video uploaded to YouTube
per minute per day and so on.
The response has continued to be,
we'll put more content moderators on it,
which means that that continues to exponentially grow.
It has gone from a next to nothing kind of line item
in the budget to being a massive, massive cost center,
meaning it doesn't actually return revenue.
It's not like a new product.
It's just seen as an economic drain.
And the way we manage that problem
is by pushing it onto some low-wage workers
to do it as cheaply as possible,
because, again, that stacks up
when you double your workforce in two years
that it does not come for free.
This is why companies like Facebook use subcontractors.
But according to this researcher,
this isn't the only reason.
It's about labor costs,
but it's also about creating layers
of lessening responsibility
between those who solicit this kind of work
and need it and those who do it and where they do it.
They remove themselves,
they put themselves at a distance
from the workers and their conditions,
and it's not just a geographic distance,
but sort of a moral distance.
So when that content moderator some years later alleges harm
or, you know, is having trouble psychologically
or emotionally because of the work that they did,
then it may be possible for that company
to disclaim responsibility for that,
even though ultimately they really are responsible
because they asked them to do that work in the first place.
Despite these precautions,
three former moderators filed lawsuits
against Facebook in the U.S. a few months ago.
All three were working under subcontractors,
all claimed to be victims of post-traumatic stress disorder.
The American company refused every request
we made for an interview.
They did, however, send us an email to explain
how Facebook, with its partners,
pays great attention to the well-being of content moderators
working on its platform,
which is an absolute priority.
To finish off, here's some of the latest news from the sector.
While these ghost workers are left in the shadows,
it's business as usual for the companies
working in this new sector.
A few weeks after filming,
Figure 8's founder sold his company for $300 million.
Well, at least now, he has good reason to be happy.
Thank you.
