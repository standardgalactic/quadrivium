Dear Fellow Scholars, this is Two Minute Papers with Dr. Károly Zsolnai-Fehér.
With the nimble progress we are seeing in computer graphics research,
it is now not only possible to perform beautiful fluid simulations,
but we can also simulate more advanced effects such as honey coiling,
ferrofluids climbing up on other objects, and a variety of similar advanced effects.
However, due to the complexity of these techniques,
we often have to wait for several seconds or even minutes for every single one of these images,
which often means that we have to leave our computer crunching these scenes overnight,
or even wait several days for the results to appear.
But what about real-time applications?
Can we perform these fluid simulations in a more reasonable time frame?
Well, this technique offers detailed fluid simulations like the one here and is blazing fast.
The reason for this is that, one, it uses a sparse volume representation,
and two, it supports parallel computation and runs on your graphics card.
So, what do these terms really mean?
Let's start with the sparse part.
With classical fluid simulation techniques, the simulation domain has to be declared in advance,
and is typically confined to a cube.
This comes with several disadvantages.
For instance, if we wish to have a piece of fluid or smoke coming out of this cube,
we are out of luck.
The simulation domain stays, so we would have to know in advance how the simulation pans out,
which we don't.
Now, the first thing you're probably thinking about, well, of course, make the simulation domain bigger.
Yes, but, unless special measures are taken, the bigger the domain, the more we have to compute.
Even the empty parts take some computation.
Ouch.
This means that we have to confine the simulation to as small a domain as we can.
So, this is where this technique comes into play.
The sparse representation that it uses means that the simulation domain can take any form.
As you see here, it just starts altering the shape of the simulation domain
as the fluid splashes out of it.
Furthermore, we are not only not doing work in the empty parts of the domain,
which is a huge efficiency increase, but we don't need to allocate too much
additional memory for these regions, which, you will see in a minute,
will be a key part of the value proposition of this technique.
We noted that it supports parallel computation and runs on your graphics card.
The graphics card part is key because otherwise, it would run on your processor,
like most of the techniques that require minutes per frame.
The more complex the technique is, typically, the more likely that it runs on your processor,
which has a few cores, two, a few tens, of course.
However, your graphics card, comparably, is almost a supercomputer, as it has up to a few hundred,
or even a few thousand cores to compute on.
So, why not use that?
Well, it's not that simple.
And here is where the word parallel is key.
If the problem can be decomposed into smaller, independent problems,
they can be allocated to many, many cores that can work independently and much more efficiently.
This is exactly what this paper does with the fluid simulation.
It runs it on your graphics card, and hence, it is typically 10 to 20 times faster
than the equivalent techniques running on your processor.
Let me try to demonstrate this with an example.
Let's talk about coffee.
You see, making coffee is not a very parallel task.
If you ask a person to make coffee, it can typically be done in a few seconds.
However, if you suddenly put 30 people in the kitchen and ask them to make coffee,
it will not only not be a faster process, but may even be slower than one person,
because of two reasons.
One, it is hard to coordinate 30 people, and there will be miscommunication,
and two, there are very few tools and lots of people, so they won't be able to help each other,
or much worse, will just hold each other up.
If we could formulate the coffee making problem such that we need 30 units of coffee,
and we have 30 kitchens, we could just place one person into each kitchen,
and then they could work efficiently and independently.
At the risk of oversimplifying the situation, this is an intuition of what this technique does,
and hence, it runs on your graphics card and is incredibly fast.
Also, note that your graphics card typically has a limited amount of memory,
and remember, we noted that the sparse representation makes it very gentle on memory usage,
making this the perfect algorithm for creating detailed, large-scale fluid simulations quickly.
Excellent design.
I plan to post slowed-down versions of some of the footage that you see here to our Instagram page
if you feel that it is something you would enjoy, make sure to follow us there.
Just search for two-minute papers on Instagram to find it,
or also, as always, the link is in the video description.
And, finally, hold on to your papers because if you look here,
you see that the damn break scene can be simulated with about 5 frames per second,
not seconds per frame, while the water drop scene can run about 7 frames per second
with a few million particles.
We can, of course, scale up the simulation, and then, we are back at seconds per frame land,
but it is still blazing fast.
If you look here, we can go up to 27 times faster, so, in one all-nighter simulation,
I can simulate what I could simulate in nearly a month.
Sign me up.
What a time to be alive.
Now, note that in the early days of two-minute papers, about 300-400 episodes ago,
I covered plenty of papers on fluid simulations, however, nearly no one really showed up to watch them.
Before publishing any of these videos, I was like, here we go again,
I knew that almost nobody would watch it, but this is a series where I set out to share the love
for these papers.
I believe we can learn a lot from these works, and if no one watches them, so be it.
I still love doing this.
But, I was surprised to find out that over the years, something has changed.
You fellow scholars, somehow, started to love the fluids, and I am delighted to see that.
So, thank you so much for trusting the process, showing up, and watching these videos.
I hope you are enjoying watching these as much as I enjoyed making them.
This episode has been supported by weights and biases.
Here, they show you how to make it to the top of Kaggle leaderboards,
by using weights and biases to find the best model faster than everyone else.
Weights and biases provides tools to track your experiments in your deep learning projects.
Their system is designed to save you a ton of time and money, and it is actively used
in projects at prestigious labs such as OpenAI, Toyota Research, GitHub, and more.
And the best part is that if you are an academic or have an open source project,
you can use their tools for free.
It really is as good as it gets.
Make sure to visit them through wnb.com slash papers,
or just click the link in the video description, and you can get a free demo today.
Our thanks to weights and biases for their longstanding support,
and for helping us make better videos for you.
Thanks for watching and for your generous support, and I'll see you next time!
