I think a key question to this is like, you know, people say hallucinations.
I was like, what does that mean? Well, I mean, it doesn't get every single fact completely right.
Challenge E.P.T. is probably like 100 gigabytes down from like 10 trillion words.
The fact you can get anything right is an absolute technical marvel that
no one's really sure exactly how that happens. What if you had an AI tutor for every child?
What does that look like? What if you had 100 AI tutors for every child?
For the first time, every single person can have hundreds of characters that like and
support them all the time. Basically, you log into social media or whatever, and you're like,
hey, I'm Sam, and he's like, cool, what type of people, instead of who do you want to follow?
It's like, who do you want to follow you? For example, there aren't enough therapists in the
world, you know, and it is a regulated industry. But at the same time, there is a gap for therapists,
just like you have the meditation apps kind of step in, and they created calm and they
created these other things that were huge. Hello, and welcome to the Cognitive Revolution,
where we interview visionary researchers, entrepreneurs, and builders working on the
frontier of artificial intelligence. Each week, we'll explore their revolutionary ideas,
and together we'll build a picture of how AI technology will transform work,
life, and society in the coming years. I'm Nathan LaBenz, joined by my co-host, Eric Tornberg.
Hello, and welcome back to the Cognitive Revolution. Today's episode is a super
interesting one on a number of levels, as we're hosting a discussion between two
super influential technology thinkers. Sam Lesson, former VP of product at Facebook,
now early stage technology investor and writer, Andy Modmostock, founder and CEO of Stability AI,
whose work at Stability, highlighted of course by Stable Diffusion, has already been incredibly
influential, but has also come under intense scrutiny in the months since he raised $100
million at a $1 billion valuation. This conversation started on Twitter with a short essay that Sam
wrote, arguing that AI is mostly a bad investment for VC. Imad responded and suggested a podcast on
the topic, and Eric and I were naturally happy to volunteer to host. Both Sam and Imad talk fast.
This is a 1.5x speed episode for me, down from the usual 2x, and both had a lot to say,
so we mostly let them speak directly to each other before I jumped in at the end,
to ask some concrete question. I think regular listeners to the show will know that I definitely
share Sam's point of view around investing in AI. AI may well disrupt society at large,
but it doesn't seem likely to disrupt many existing SaaS markets between now and then.
There will, as Sam says, always be exception, but for someone whose focus is on looking for
those early-stage companies with 100x potential investment returns, I think he's quite right
that there'll be few and far between, at least at the model and application layers.
For what it's worth, though, I do think Sam is quite wrong to limit his thinking about LLM
function to the no-real-intelligence-just-association-between-words paradigm. There is now ample
mechanistic interpretability work that shows quite conclusively that AI models are indeed
groping much more than statistical correlation, but that's a topic for another episode.
For today, the subtext of the conversation seemed to be this question. Will stability AI
prove to be one of those exceptional, highly successful startups deserving of its
unicorn status and valuation? From my standpoint, the answer may depend on your definition of
success. Stability is as much a movement as a company and has already left an indelible mark
on AI open-source culture. Their impact goes beyond the groundbreaking stable diffusion,
including major dataset releases such as the Lyon 5 billion image dataset, various language models
and accompanying open-source RLHF libraries, which enable further downstream training and
customization, and many, many other projects across a wide range of modalities.
They've also established themselves as tremendous identifiers of and supporters of talent,
including another upcoming guest, 19-year-old PhD Tanishk Matthew Abraham, who just published a
literal mind-reading paper that converts fMRI data into reconstructed images of what the person saw,
truly mind-blowing work. But perhaps more important than any of that has been
a mod's unique ability to articulate an inspiring vision for the future of AI.
While the positive vision of AI that we tend to hear when we hear one at all often centers
around the possibility of large and powerful AGI's, of which there might only be a few,
presumably built and owned by leading technology firms. A mod has not only signed the AGI pause
letter and the extinction risk statement, but has articulated a very different positive vision
for a panoply of smaller AI models, mostly presumably derived from the open-source standards
that he and the team at Stability are creating, but all highly specialized for specific purposes
and localized to specific contexts and culture. This is an extremely appealing notion to billions
of people around the world who don't want to be beholden to American or, for that matter,
Chinese corporations or their access to AI. A mod has been criticized recently for allegedly
exaggerating certain claims and affiliations, and for some operational problems at stability
that resulted in people sometimes being paid late. And while some of that may well have happened,
I will say that I've followed a mod quite closely now for at least a year,
and have generally found him to be very reasonable. He has, for example, always recognized the reality
of open AI in Google's modes, and has projected that open-source models will continue to lag
leading closed-source models by a year or more. All of this seems quite right and reasonable
to me. Given a mod's comments about the centrality of stories, I think it's safe to say he understands
the task of developing a positive vision for AI, a vision that others can really buy into
as a core part of his role and strategy. This is quite different from other AI CEOs who often
seem to be sharing their plans more for your information than for your input, and it really
does seem to be working. I've joined the discords of many stability-affiliated projects,
and have been very impressed with the quality of people and conversations that they contain.
So, whether stability will ultimately deliver a great return for the investors who bought in at
that $1 billion dollar valuation is, for me, not the most interesting question about the company.
I'd be very surprised if they failed outright given the quality of talent that they have,
and so the question that matters more to me is simply, what impact will they have?
Will their push toward decentralization prove democratizing, destabilizing, or both? If you
fear centralization of power and you want to see a rich ecology of AI's develop around the world,
you might expect their contribution to be extremely positive. If, on the other hand, you fear chaos
and see AI's as invasive species colonizing niche after niche and ultimately perhaps competing with
humans, you might feel quite the opposite indeed. For my part, as you can probably guess,
I expect the outcome will ultimately be a bit of both. Throughout this conversation,
you'll hear just how much change both Sam and Imad take for granted as they think about the future.
Culture, entertainment, and relationships, they agree, are in for a shock.
The global south may well have leapfrog moments in education and even medicine.
Online communities may come to contain AI characters that we can't even identify as non-human.
Given the magnitude of all these changes and the resources and talent that Imad has amassed,
the inspiration he's provided, and the tremendous global need that AI seems so well suited to fill,
I think stability has a real chance not only to become a great company,
but to help shape a global universal basic intelligence standard, a potentially historic
development. How humans ultimately wield the new power that Imad and others unlock,
and whether we can control AI long-term at all, is much harder to predict,
but can ultimately only go one way or the other. Now, I hope you enjoy this fast-paced
conversation with Imad Mostak and Sam Lesson. I think that large language models and a lot of
the AI stuff that we're seeing kind of start to get consumerized right now and become real,
it's super cool. There's no question about that. There are absolutely going to be
great product experiences improved by it and opportunities to create more efficiency,
create better interfaces. I am not negative on how some of the stuff will find its way
into consumer product experiences and make things better. My wife's company,
the publication information, we've already deployed a bunch of AI stuff that makes
search for the information go from absolutely terrible to pretty good, and there's a bunch
more stuff coming that will get better. I'm not against that. I do think the things that I keep
in mind, one as an investor, is I think the case about why a bunch of this technology is going to
make meta, and Amazon, and Google, and a bunch of big players, an assload of money are clear.
I think the idea that it is a wedge or an angle that's going to allow a bunch of companies from
zero to come out of nowhere and then become wildly profitable or compete with those guys,
types of big players, I think is much more sus, as they would say. It's because I mean,
to really take advantage of the stuff, you need a ton of distribution, you need a ton of data,
and I really see a lot of what I've seen is opportunities to extend innovation that already
exists versus completely reshuffled the deck. That's my big thing. I am very bullish on crypto
long-term. Crypto is undeniably whatever you think of it, a deck reshuffled. AI, and what we're
seeing is not a deck reshuffled from my perspective as an extender. People come pitch me, we're going
to be the Adobe of AI. Adobe is going to be the Adobe of AI, from my deployment. I think
it's a very tough one to see. Will there be exceptions? Of course there will be exceptions.
There will be exceptions, but I think it's a seen thing. I think it's hard. I'd also say as an investor,
a seed investor, which is how I earn my daily bread. I'd say that the opportunities to deploy
a few million dollars, turn over a card and have an experience like, oh my god, there's something
here, now let's have a series A investor put a ton more money in and see it scale up, I think are
few and far between. And because everyone's so excited, everything's way mispriced. And so for
me as an investor, I think it's an extremely hard market to get excited about. What else can I say?
I mean, look, I do think that the elephant in the room, which I'm sure we can discuss or not, is
for the companies that have gone out so far, talk about chat, GPT, I think there's huge regulatory
problems which are becoming clearer. And it's not about the machine is going to eat us all.
I think that's a load of crap. And it's been in the record for quite some time,
being very, very negative and cynical about kind of a lot of those narratives. I mean,
at the end of the day, token guessing, guess the next token is not a fundamentally dangerous
piece of technology. I do think that the copyright issues are deeply real
and complicated. And there's a bunch of other challenges that these guys are going to face
that, you know, again, because the world has a general viewpoint of like,
fool me once, shame on you, fool me twice, shame on me is, you know, the era of from social media
to Uber to whatever, like, I think people are going to be way more quick reactive to like what's
going on from regulatory environment here, I hope, then that historically. But I don't know,
that's a ton of ground. And I don't know, where do you want to go?
Yeah, no, there's a ton of ground. I think, you know, there's this question of, is this a
disruptive or sustaining innovation? And the question of what this is, you know, you have
the classical big data and then you extrapolate it to sell you ads. And that was good old internet.
And it created these kind of behemoths in matter and Google in particular. But then you have the
application of computer vision and these other things largely to the incumbents. So value was
captured there. I was at your mobile and mobile's a great example of like, just double down, right?
Yeah. And that's why kind of Facebook's first shift, my while was good. Next shift to matter.
And maybe they'll rename themselves spatial or something. But, you know, this becomes very
interesting. Because like, these models are something a bit different. So I would stable
the fusion to 100,000 gigs of images and the app was a two gig file. And it was four of the top
10 absolutely app store in December. We're having that as the entire backend. You put words in and
images pop out and it makes pretty pictures in your face, right? But then they all dropped off and
they disappeared. Because there are more features than apps, they're cool features. But they weren't
kind of product experiences. That is exactly what happened when the apps were launched, right? You
had like fart apps as number one for $599. There's a brief moment where it's cool and you're experimenting
with it and you have these kind of poops, right? But they're not. Yeah, I think like poops. Yeah,
you're right. Exactly. Literally. It's not real because you have to have the user experience
and build products like normal. But where I feel right now is that we're at the primitive stage
and very boring in terms of one to one interaction is very boring. I think it is again, very surface
level without any memory. And it's ephemeral and fleeting. My thing is that probably iPhone 2G,
iPhone 3G bit, we're just getting copy paste. Because what's happened is you've got technology
that's gone from research and it's now starting to go into engineering. What are the design patterns
for this? How is it implemented? Was it good for? I think a key question to this is like, you know,
people say hallucinations. I was like, what does that mean? Well, I mean, it doesn't get every
single fact completely right. Charge GPT is probably like 100 gigabytes down from like 10 trillion
words. The fact you can get anything right is an absolute technical marvel that no one's really
sure exactly how that happens. You know, it's like in a pipe pipe from Silicon Valley. Like,
that Weisman stool would be even more intensive, even repress all that knowledge.
Because what these really are, they're reasoning machines. They're not facts,
because we've got two parts of our brain. Are they reasoning machines? Aren't they
guess the next token machines? Like, that's the I think I think that's a really fundamental thing.
Like, I think that my model and the easiest way for most consumers to think about this,
basically accurate, right, is like, there's no actual intelligence to be system. So right,
all they're doing is saying, okay, based on all the words I've seen in the graph of language that
I've been able to observe, here's the most likely next token. And that's really cool to be clear.
That's like super useful. But calling that intelligence is a real stretch in my mind.
Well, I think it depends on your definition of intelligence, like you're applying the free
energy principles of Carl Friston, and where everything just intelligence from energy kind
of dropping to its last date or different definition of intelligence. I think what I
look at it is like this. One to one is getting the next token for language models for image
models that diffusion based and now generate all sorts of other architectures. But it's about output
and what can it do? So one on one, it's a bit dumb, it doesn't have memory. You have the meta
paper by Cicero, whereby they had eight language models interacting with each other, and it out
performed humans in the game of diplomacy. You know, you just like all that good old Alpha
Go type stuff, which he's reinforcement learning. Is that intelligence? Probably still not,
but it can augment intelligence. That's something that we've been focusing on a lot because
you can use it for actual intelligence augmenting things, you can use it for reasoning things.
Give it a PDF and say, well, on Earth, this is PDF talking about, you can do that right now.
And that's a useful thing that reduces frustration. I used to invest in video games. I used to look
at time to fund flow and frustration. I look at things like, you know, this podcast we're doing
any year, it'll be automatically transcribed and edited and added to our knowledge base through
next token prediction. Does that require AGI? No. Yeah. Although interesting, let's talk about
this podcast. It's a really interesting case. You know, in the early days of Clubhouse, when
Clubhouse was ripping, I used to like go after Paul all the time. And I wrote about this being like,
you are so stupid for not recording this stuff. I was like, look, here's the reality. These
conversations in Clubhouse are dribble, right? Like 99% of them is crap. And I don't want to
listen to it. However, if you've created a magical pump that says the internet is full of SEO,
shit, and Wikipedia, we have a magic pump of people wanting to talk to each other live.
Here's the thing, people want to talk, no one wants to listen. But if you transcribe and record it all,
and you can create an index out of it, and then all of a sudden you have this meta, this next
generation search engine, but that's fucking interesting, right? Here's the problem. We're
Paul's side of the time, which I think turns out to be totally wrong, given where AI is coming.
He's like, yes, Sam, but like, there's no way to index it and blah, blah, blah. There will be,
like, there's clearly going to be, right? And it turns out, I'd like to, you know,
because I like seeing, I told you so, like, I told you so, like, they're definitely a way to do that
now, right? And like, that would have been super sweet. I think we're great. Here's the problem,
though, is with a lot of these visions of like, oh, we'll just like take all the recorded podcasts,
right? And then kind of put a front end and tie to them and like, compress them down and be done,
is there's no economic model to that. And maybe we can get into business models for a second.
That's going to make sense for anyone to publicly share anything, right? Like the way, the reason
that like, people put things on the web was because they were getting paid for it in one form or
another, because the whole ecosystem of Google, where it created was a trade, it was, okay,
like you get to index this shit, but you're going to send me traffic and I can monetize. And like,
you know, the publishers got snowed by that for a while, right? And like almost lost, almost went
away until they figured out paywalls, right? We're doing this now because it's kind of fun and
bullshit and we'll learn, right? But we're also kind of doing it, at least I'll do it. I'll post it,
maybe someone will follow me out of it, it's a fun hour to spend with interesting people, right?
But there's an economics to it in some form, social or financial capital. This model, I actually
think that the interesting thing about AI, if you take that view, whatever you would think is
interesting, is like, it's already going to crush the information economy of the web, right?
I think that if you roll it forward, like this conversation will not be in the public domain,
right? Going forward, because there'll be no, there'll be no social economics to it,
just be a compression on top of it. And if anything AI, again, if you take the model of,
oh, it'll take a bunch of podcasts and compress them down into tweets, right, will end up kind of
collapsing on itself, if you need people, what you do, right, to ultimately be the source of truth
and information about the world. And so that's that point of view, but I'm not sure I entirely
agree, because you know, it's fun to shoot the shit. And Tony, you do have a podcast thing,
they've got their ads, which is about that. But I think the attention economy is a very
interesting element to this, particularly because these models are based on attention.
So the differential of these models versus previous is that you have the attention of all
you need, Peko, where it's like, from an information theory perspective, information is
valuable in as much it changes the state. So you take this whole podcast and compare this down
to a few tweets, that's all you need to see. But sometimes people want to see the full kind of
thing. No one really wants the whole thing. Oh, no, they do. They do. Sometimes it's quite fun to
kind of do it because I mean, let's say the Christianson thing of a job to be done, right?
You have a functional component, a social component and an emotional component.
You know, why does everyone want to go to a concert? You know, why do people want to have
collectors items things? Products have different aspects and different elements to it. People
still read full books. They don't kind of read the summaries of the book. They don't read the
simulacrums of it. I mean, like, look, to me, there's there's there's two different, again,
this gets into some old Facebook stuff. But like, I think we can talk about let's take
financial economy out of it and just talk about like informational and social economy.
There's the entertainment economy, right? For sure, AI is going to crush the entertainment
economy, right? Like, there's no question about that, right? Like, you start with porn and go on
through. And the reality is, is that, you know, we went from, you know, people magazine to your
friends and your friends are more interesting than people magazine. And that's what's more
impressing your friends is professional friends who are like hotter and funnier. And guess who's
more interesting than hot, funny, professional friends, it's going to end up being actually,
I said, there's a more tick tock was it turns out algorithmically, find the best person from the
universe, you'll find some niche that's better. What's better than that? Synthetic, right? We will
get to the point where we say, Hey, like, there will be like a hotter, funnier, more interesting,
more personalized AI thing, which is derived, like, I totally buy that, right? And I think that's
why actually some it's been funny to watch some pretty interesting influencers who are smart,
be like, Oh, my God, this is the end of the world for us, right? I agree with that. Information is a
very, very different beast, right? And entertainment, though, right, because the value is not like
engagement. That is, that is actually the, in the broad sense, the attention is everything,
where it's totally raw, right? Which is like, that is for sure true, if you're trying to optimize
for entertainment. And it's not true, right? If you actually know what needs to know what's going
on in the world, right? Or you need to like, you're dealing with a real world. And that interface
between the real world, the digital world, where the systems have no knowledge of what actually is
truth is to your, the point where I think is probably that already even falls down the most.
Well, I mean, maybe this is why, you know, if you say that kind of hallucinations are kind of core
and it's the creativity machine, media is where it's more impactful, where the truth is in the
element there, right? What happened a little bit to date is a few of the AI companies wanted to
talk about themselves as information machines. And they realized, right? And so they'll be like,
you're like, we're not instead of we're creative, don't trust us for facts is like,
fine. And I agree, they'll be useful entertainment machines. But I do, I think that goes into the
whole like, what are we actually talking about here? What are the actual value is? And like,
how scoped it is, which is not it's not zero. It's just not like every social societies are
based on stories. You know, like, all of my view on finance, pretty much all of finance is
securitization and leverage telling stories. And then how did you tell them? Like, and we can
see the power of stories as they move around. So Silicon Valley Bank was a story that was true.
And led to an $18 billion outflow like that. All of us are kind of familiar with that.
Probably listen to this podcast. I think it's pretty cynical to say it's all in the stories.
I mean, it's like, I think there are there's reality in the world, like the economy is not
based just on storytelling. No, I mean, the dollar is a story. The economy is based on the dollar.
And so you have the Fed confidence, you have confidence in the stock markets,
it's kind of layers of these things. And then you have this technology, you need trust, that's
for sure true. And trust, I mean, ultimately goes all the way down to like, is there a military
behind it, which is somewhat of a story. And that I agree with. But I think that's like,
a pretty abstract view, right? Like companies earn cash flows, they're real or not real,
they release products, they do work, it's real or not real. It's not just storytelling.
What is the multiple? Maybe it's because I'm a former hedge fund manager. So I always looked at
what was the incremental story for a stock that adjusted the multiples and other things.
Sure, I agree that if you look at the world of multiples, you say, why do you multiple expansion
or compression, right? And that's based on people's feelings about the world in future cash flows,
right? And in theory that that is a lot of storytelling. I don't think that's actually the
vast majority of the economy, right? That's the stock market. So I think that separating out what
is the stock market from what's the economy is pretty important. Hey, we'll continue our interview
in a moment after a word from our sponsors. Omnike uses generative AI to enable you to launch
hundreds of thousands of ad iterations that actually work, customized across all platforms
with a click of a button. I believe in Omnike so much that I invested in it. And I recommend
you use it too. Use CogGrav to get a 10% discount. And I think this is the important thing. We
separate it out and we see where does this technology affect? And when does it go to the
incumbents versus startups? All of these things kind of fundable, right? And so we have one area
of media. We can discuss that very concretely. I think it will have a massive impact on media
at stability. We have leading media team, right? And so we haven't agreed with that, but we can
dig into that. The other area is a lot of these things are language models right now that chat
bots and it's like, it's nice. But Bing is not the top search engine. It's not even top 20
on the app store, right? Because it's still a terrible experience, rather to be speaking.
Yeah. So even though some people like why use it for all the things, you don't really, you know,
chat GPT rows really fast. And it's useful for things like doing your own work. But do you
really use it that much? So where I find it interesting is really looking at where companies
are trying to go beyond the basic search patterns and have the classical kind of feedback loops
with engaging content and see how that grows. So I think mid journey is a good example of that,
whereby David delivery built a community, took it to like 14 million people and is making money
hand over fist because he built even though discord is fricking weird, a good experience on
existing infrastructure, Facebook, App Store. But how many of those have you seen looking across
the entire AI space? Most of this stuff right now is terrible. But again, the other question is who
gets the value, right? And I think like, let's talk about the internet because we actually agree
on the entertainment thing. Like, you know, world of closed loop, it's all about what's the most
engaging thing and attention is everything, right? Yes, like, these systems are like quite
assuming that you don't end up getting into hell, which I do think is a really big problem around
human creativity and copyright and a bunch of other points of legal leverage on these things.
I agree that you can make really compelling cases and it's going to hurt a lot of the human
entertainment industry, right? That that I agree with. But the question is, who's going to win it?
Is it going to be the Hollywood studios? Is it going to be, you know, is it going to be the
existing publishers who just start adding incrementally more of this stuff in, etc. Or is it going to
be new startups or new people? You know, look, there's always exceptions to the rule. But I think
almost the entire pie is going to be the people who have the distribution, they have the IP,
they have all the pieces they need to just plug this shit in.
Well, but I mean, maybe we can look at it in terms of the consumption of content went to zero
with streaming and kind of all these things that led to some winners coming
because you have Netflix, you have Spotify, etc. The creation of content basically goes to zero
with this technology as well. And basically, I believe in a few years who will feature films
using this. Yeah, but I guess I own and distribute those, right? And the reality is,
I think I'll be the Hollywood studios, because they have the distribution, right? Like,
if you believe that's kind of the distribution mechanism, but there's a whole ecosystem that
can build around that. Things like D-Nag, things like industrial light and magnitude,
do you need that when you have rendering, you know, at scale?
To be clear, I think the thing I think you could totally see changing or evolving is going to be
the factory, right? So like, you know, meaning like, yes, are there capital investments that
people have made that will become less relevant because of AI? Absolutely. There's no question.
Will you almost certainly still have human writer rooms for the foreseeable future?
For sure, right? Like, is whatever it is. So there's going to be hybrids. I just,
I think saying that, but my basic point is that IP matters, distribution matters,
like there are things that matter. I agree with you that the factory plumbing in some of these
places gets a lot less valuable if you have better AI tooling. I just don't mind matters.
Well, I think it's a bit of a disruptive innovation for that side of things,
increasing the pace of output. So Pixar can do six movies a year rather than two.
And so the question around the industry, so a few weeks ago I was at Cannondale gave a talk,
so I used to be a video game investor and player. And I was like, the video game industry over the
last 10 years has gone from 70 billion to 170 billion. The average score has gone from 69% to 74%.
Movies are 40 billion to 50 billion. The score is 6.4 on IMDB. Are you going to be able to make
better movies and have a bigger market then, in which case there's more rooms for people to make
money? Or is it going to be a case of, it cannibalizes itself? There's some key questions
around kind of media, right? And media consumption. In the end of the day, the media consumption
thing, though, again, depending on like how you want to factor it and look at it, it really just
comes back. There's 24 human hours in a day, right? Like, and the reality is, is like, where
time spends, it shifts, right? As a result of this stuff, like for sure, time spent dramatically
into social, right? Off of other things, right? When that thing. Will social get more compelling,
right? With AI? Absolutely, right? And so will more attention shift into Instagram because of it?
Absolutely. Do I believe there's going to be another platform that comes out of nowhere
and swipes Instagram because the cost of production goes down? Nah, right? Like, do I believe that,
like, some new studio is going to come out and take out Pixar? Nah, Pixel will just make a few
more films, right? And like, that's cool. Like, I'm not against that happening. I think that's
completely fine. And like, people will make money on that in some places. The cost of production
and therefore the war of content gets more intense, for sure. You'll get to a point where like,
if you don't use this stuff, you're going to get fucked. But like, just because the competition
level rises, doesn't necessarily change the scorecard very much through that, how these things
go. So believe this question of do you use legacy systems or do you use systems such as runway
MLs, such as one of the dynamics, and some of these other ones that are engineered differently?
I think there's a lot of kind of legacy stuff where you used to Photoshop and you used to continue
to use Photoshop. And now they're introducing features like infill. But is there room for a
ground up kind of interface? And we see that sometimes kind of a character. And my assertion is
broadly no, but there will be exceptions. And the broadly no is going to be it's just it's
not to your point about innovate about is it a sustaining or is it disruptive? It's like,
Photoshop will get 95% right. They already have everyone's payment on file. They already have
the infrastructure. This is not like the internet. People like in the internet, there was a bunch
of companies that were fundamentally unprepared for this, right? I do not think that most of the
incumbents are fundamentally unprepared for this. Yeah. And you know, there's a question of do you
create brand new markets? So I was an early investment via the Chinese kind of Twitch. And
there was two hours a day on average per user. Now on character AI, I think it's still number
two on the app store. We're seeing two hours a day on average of usage, where she has some insane
kind of engagement metrics. It's quite nice to have a chat with it. But there's a question,
can that become then a product or a network? I think that we may be looking at some of the wrong
areas here because what you have is you have the consumer experience, the media experience and
enterprise experience. I think one of the things that's most interesting for me in terms of where
money could potentially be made is actually the regulated experience. So at stability, we make
open models, open source, but actually what we do is open auditable models for enterprise,
private data, governments, et cetera. So we've got a whole bunch of stuff that doesn't have any
web crawls, et cetera, employed via Bedrock and others. Then that's valuable data. So one of the
things we do is kind of education. And that's where I look at some of these areas and they've
been the main contributors to US inflation and CPI education and healthcare. And unlike you
could do something different there. And maybe that's where a significant amount of value will be.
I mean, I think it's sad from the Silicon Valley story if the answer is like, well, the money's
all going to be made for regulation. I don't disagree with you for what it's worth. Disrupting
regulated industries, which is different. I do believe that someone's going to make a lot of
money on AI regulatory points, right? There's no question. AI insurance. There we go.
Like, you know, there's a bunch of things that are like really sad things that you have to do and
like, you know, people will make money on. There's no question that people will find niche markets.
They're super boring. And not the type of thing I want to be involved in. But like, yes, like some
enterprise investors will have will make bank on like, you know, the whatever Europe comes up with
certifying your models are compliant and GDPR 8.0 to like deal with fucking data request removals.
Like that will happen as kind of the stuff happens. I'm like pretty uninspired by that,
right? Like, I think that's like, pretty sad that that's if that's if the net income of like,
new opportunities in AI is just going to be like, opportunities to like interface with government
and reign it in will be sad. Yeah, but like said, regulated industries. So the example that I have
there is education and healthcare. So like, one of the things you work with a range of charities
and multinational is deploying tablets into entire countries in Africa with AI that teaches
and learns. You give every kid a tablet, the young ladies illustrated primer, what does that do to
an entire nation? You know, the only thing that's been provably to work in education is the bloom
effect, the two segment effect. Right now, our kind of sister charity Imagine Worldwide has
been deploying the global XPRIZE for learning adaptive learning. And we're teaching 76% of kids
literacy and numeracy in 13 months and one hour a day with older kids teaching younger kids.
I look at this technology and I'm like, there are certain areas where there's a gap that nothing
could fill before. What if you had an AI tutor for every child? What does that look like? What if
you had 100 AI tutors for every child? I get it. And like, I do think that we can always go back to
the industries that tech has been trying to disrupt for a million years and like for lots of structural
reasons has not and say, ah, but now with this new tech will disrupt it, you know, I look forward to
the, to the years of debate in the, we'll talk about the US between the teachers unions and people
trying to deploy tablets for AI. We can say, Oh, no, no, no, no, we're going to do it in Africa,
skip the regulator, like the teachers, but I'm just saying it's like, yes, there's always hope
that the next wave of technology will somehow unstick a bunch of problems technologists hate
because of the regulatory or the structural issues with them. But I have no confidence that this
one is meaningfully different. But I mean, this is the question structural issues, right? Regulation
is one thing. You look at kind of BG use some of the other Indian kind of education companies,
you look at the Chinese ones across emerging markets, maybe it'll be the case here. I mean,
this is what I believe that much of the productivity enhancements, aside from maybe coding and things
like that, which we can get on to. And the biggest leaps will happen in the global south, because
they left a mobile and there's a whole mobile economy and massive companies created from that.
What if they make a leap to intelligence augmentation with this technology? Because right now they
can't service that. Now they could potentially service it, given the decreased cost of creativity
of engagement and other things from education to healthcare to other things.
I think if your argument is that there's a bunch of countries outside of the US that have lagged
in a bunch of infrastructure effectively or ability to like execute certain things in education,
et cetera, it will be able to allow the cell phone have like a leap frog moment and move forward.
Yeah, I don't object to that. I think that's like basically true. Again, I goes back to the thing
where like, I'm excited about kind of like the US, I think lives in the future relatively speaking
to most other people in countries. And like, I think the thing most people are excited about
is how like we can how AI changes like the top of the top. I agree with that. So I think if your
argument is it doesn't change the top of the top, but it does kind of catch up a bunch of the third
world, like I do think that there are places that will be true.
Well, so let's look at the top of the top then. So I think Microsoft put out that 50% of all code
is AI generated on GitHub now from code products, et cetera, and there's 40% improvement in
efficiency. I mean, my top coders really enjoy it because they train them in models. We have code
models too, and they are showing more and better code. What do you think about it with respect
to that industry? Because that's obviously a large industry, which is technology disrupted.
The only thing that I actually think is fucking awesome for chat GPT effectively is, I'll call it
Stack Overflow 2.0. It's fucking great for that. And like, if you think about it, why is it great
for that? Like, why? I think it is the perfect problem for the existing technology we have.
You have a shitload of open source code that these models can look at. Plus, you scrape all of Stack
Overflow, which Cyanar is Stack Overflow, and that goes back to the whole copyright issue,
as well as the issue of where some of the inputs come from, but most of the copyright issue.
Plus, the nice part about computer code is that it's test driven in a lot of cases. You either
pass it to the fucking test or it doesn't pass the test. So you have the perfect dataset of digital
only self-contained reality, which I totally agree chat GPT is great at. And frankly, I'm
the type of person who, like, I told, but I would never consider myself an engineer. It makes coding
for me so much more fun because all this shit I don't want to deal with, like, what the fuck is
this random error? What package do I have to install that manages this? It's all great. Now,
it does lie, and it does make up wrong answers, and it's not perfect. But I fully agree that the
co-pilot as thing is very powerful and like a really great specific use case. And I do agree that
talking about business models or what happens is like, like Stack Overflow is the poster. Stack
Overflow is the Yelp of this generation, right? You know how Yelp had this huge lawsuit with
Google that's gone on forever because Google basically just sold their results, right? Stack
Overflow is going to be that of this because they are screwed, right? And like, it is a great example
of a place where the tech is better because it was basically lifted. Yeah. And you know, it becomes
very interesting as well because now what you have is regulatory arbitrage, like the good old
double Irish with the Dutch sandwich on taxation, whereby Israel and Japan have said you can scrape
anything for any reason, which is kind of crazy, commercial or otherwise. So you maybe scrape in
one area, trade in another, and you serve it up in a different country. So I think this technology
is kind of inevitable. But then what is the implication of that? Like, my take is that as we
move through the next kind of five years or something like that, the nature of coding will
change. Like I started coding what 22 years ago, we had like assembler and subversion and stuff
like that. And kids these days have it so easy with get up, you know, and all these libraries.
What does it look like in a few years when you've got these technologies that you can describe
something and start building apps? You know, what does the whole ecosystem look like again when
the creation of these cells? It will just make them like much less valuable, right? Like is what
I basically come down to. And what ends up remaining valuable is distribution and data,
right? Because like right now you can be a great engineer or solve a problem, whatever, and there's
like a value. You can create a product that's actually worth something. If everyone can make
products, theoretically, that are like cost nothing, right, or really easily, then like there's
just no leverage in that anymore. And again, this goes back to who wins, who wins with people with
distribution data, right? That's the answer, like it from existing now to your point of
a regulatory arbitrage and data, I think this is really, I think the sad part about a lot of
this AI stuff, everything is going right, right? Like that's what the net of this is going to be
is like any, anything that has historically been an open data set, or people are able to say like,
okay, well, like I'll share this, but in return, I get traffic or notoriety, and that's like a
fair economics rate over, right? And so what's going to end up happening is walls are going to go
up everywhere, everything's going to go private. And that's going to be the interesting question
about where you end up from all this stuff from an economics perspective in the next few years.
But what is where this has happened many times before, right? Like this is not the first time in
human history, this happens that you know, people, you know, if you look at news industry,
you know, people are like, Oh, like the news industry used to be so great, and then whatever,
it's like bullshit. It's like the number of times in the history of news, basically, you had
growth and distribution, right? Things get super scammy. The elites retreat to private newsletters,
like in its cycles, it's happened like six or seven times. And like, I think this is going to be a
hard pin. In some ways, I think the biggest thing is that I'm very confident of is that AI will be
the death of the public web, and will be the death of a lot of open information, specifically
because of what you said, right? Which is that just will not that it's me too valuable and too,
and too, too important. But the reality is AI doesn't need any more information,
because of your short letter. But it does, it doesn't for entertainment. And that's why I think
entertainment is screwed. I think it absolutely the the oracle problem in crypto, where how you
keep a system, a digital system in sync with reality and be meaningful is exactly the same
problem that AI has, which is it can go in any direction it wants, as long as the data is self
contained. The second it's not, and it's trying to be synced to reality or a real world, it does
need more data. It does need to be continuously updated or addressed in whatever direction,
you know, cars attention. But then, you know, you have public broadcasting data, you have some
of these other things as well, whereby the oracle problem comes a lot easier to do when you can
do retrieval augmented models and other things like that. I mean, there are sources of verifiable
data for leasing. Maybe it comes down to the use case. My main point is that they're going to be
increasingly cut off, right, if there's no economic model for supporting them, and they're all getting
abstract and scraped by model. I would disagree with this. So you know, like, I made it deliberately
open so that we could highlight how that shapes that I think they're unsafe as well. And we're
the only company to offer octab, but we work with multiple governments on national data sets and
national models, using broadcasts of data and other things like that that are continuously updated
as national infrastructure. Because I think these models are a form of infrastructure, they're a
weird type of primitive, they're like a mega codec type thing, where stuff goes in stuff comes out,
but people do want to have relevance and updates. So I think you will have an open version that is
updated continuously. But then maybe again, that's where value is. Which parts of information go
private and are served up through models and who is providing them? Is this financial data? Is it
this? Is it that? And what is the quality of these fine-tuned models? Because what you just described
as well is a bit of a Armageddon for consumer apps in a way, right? Because it goes down to zero.
So then what becomes useful is that then the Apple takes a massively forward because they've got
this identity structure, and they have all the data there, and they can do apps quicker than
anything else. Yeah, except for the fact that Apple's entire shtick about encryption and privacy
is going to make it literally impossible for them to play in this. I actually think Apple's role
in the future of this stuff is going to be one of the most interesting big tech questions,
because they have positioned themselves so hardcore against all the things you would need to get
leveraged right from AI, that it's going to be very interesting to see how they navigate. Google,
fine, meta, fine. But despite the fact, I am very skeptical of what Apple's AI approach is going
to be, or I will say on the flip side, they're incredible at government relations and PR. So
if they see you have to figure out a way to totally recant on all their encryption and their
approaches to this type of stuff and have a new model where they somehow are the privacy heroes,
but also doing AI, I'm very curious how that's going to work.
They can keep a perfection and they can keep a customized rule. Because again,
you don't need to take everyone's days to the trainer. You have a generalized model. I think
local model, mini models on your local device, like a general model behind it. Exactly. I think
in practice, we'll see how it plays out. I'm skeptical. It works with an embedding layer
potentially, but it is kind of very interesting because, again, the technology doesn't matter.
It's the use that matters. What use can you get out of it? So yesterday, they had the thing
whereby they said, oh, it learns automatically with a little ML model in there. It learned
through a small embedding layer. They don't talk about the technology that much because Apple
always just talks about what the use actually is. I think the question is, what is disruptive?
What can engage more? What could attract more? And so I think that you've got apps coming down
there, which is why the bar generally rises. I think we see this with technology as it goes. The
bar generally rises, and so attention becomes even more difficult, where it does come down to
distribution. I think about that. What's your take on the nature of virality in this type of age?
Because these things are good at optimizing for virality, potentially, right? Like, again,
you can build better content. You can build better engagement once you get the puddles down.
And that is the start of many of these apps. Yeah, I just think virality is a war in a lot of
ways. So look, I think in the end of the day, will newsfeeds get more compelling for people?
Absolutely. Will ads get more compelling for people individually? Absolutely. There's no
question if these things are true and the existing players will get the vast majority of the pie of
that type of stuff. I do think you'll tend towards more and more niche interests. So let's talk about
porn for a second. Porn is always fascinating. You can go on Reddit and find the weirdest
fucking porn in the world of all these sub communities that have filtered into these weird
things that they're interested in. AI will make this 10 times weirder. Or if 100 times weirder.
And people are just going to keep filtering. Now, why does this weird filtering happen?
There's a bunch of reasons and different things. I think part of it, moving away from
porn for a second in the broader ecosystem is people are desperate for a sense of purpose and
place. And the reality is the internet makes you feel very small. There's millions of people just
like you. And that encourages people to seek out right sized communities that are smaller and smaller.
With AI, I think the interesting thing will be when it comes to attention and things like that is,
look, for the first time, every single person can have hundreds of characters that like and
support them all the time. The math of it all used to be, okay, you're trying to find a community
that's the right size and knows you have a price and you're valued in. But it's hard to, you're
not necessarily the hero. So you go find out a smaller niche or a different niche where you're
more of a hero or you create a spit of it and try to lead that. I think a future where basically
you log into social media or whatever and you're like, hey, I'm Sam. And it's like, cool. What
type of people, instead of who do you want to follow? It's like, who do you want to follow you?
And like you end up with like hundreds of AI characters or frankly, I think what's more likely
is it's a mix of humans, AI's and you're not really sure which is which. But they're caught,
they're the ones commenting on your posting, like, you're fucking great. Or like, here's a cool question
or whatever. Like, I think that's the world we're gonna end up on is like more and more segmented
niches, right? Where the ultimate end would be the her model where it's like, you just have one AI
girlfriend. I'm not sure we'll go there. I think that's really hard to pull off. And I think like
that's a tough thing. But if you told me that like, in the future, you know, on Twitter, good
example, you know, everyone has 100,000 followers, right? You're not exactly sure who's a person and
who's a robot, right? And they all fucking love you and it makes it super compelling and you feel
great. Like that's a very plausible future. Come on, birth rates are gonna do that. Have you seen
that child of young male virginity under 13 the US for the Washington Post? They went from 8% in
2008 to 27% in 2018. That do you see what happened with replica on Valentine's Day this year? So
replica was originally about that was designed to be your mental health buddy, right? Until they
did realize you could charge $300 a year for a lot of roleplay until the 13th of February 2023,
when they get a message from Apple saying shut this off. So on Valentine's Day, they shut that
off. And then 68,000 people joined the Reddit the day after and said, why'd you do the boss of mine
with my girlfriend? You know, like, it was quite a massacre. That's where we're going. And look,
there's a whole history. I mean, again, like, we'll go back to porn for a second. Like, the whole
it's always fascinating. It's such an interesting base human thing. But it's like, look, it's like
the whole dynamic of like, you know, you know, how Tinder has affected sexuality and equality,
right? It's like, fascinating. Like, there's all these really interesting studies on this,
like technology has a deep impact on this type of stuff, right? But if people ultimately want
care about validation, titillation, whatever it's going to be, there's no question that
plays one place you, you and I will agree is that AI does dramatically shift the power on these
things, they will end up with weird or sub communities. And he says, here's my question to
you, though, we talk about power dynamics, I still think, and in this, I might be wrong about, I
will admit, because it's a little bit of a niche, weird industry. But my bet is that porn hub is
still the winner. I actually, I assume they're the biggest porn company, like I, or whatever Reddit
is, it was like, the place porn is doesn't shift, the platforms don't shift. It's just going to be
like, weirder, weirder stuff, and more and more AI generated. I don't know. I mean, this porn
hub isn't that big. So Mind Geek is the company behind it. They were just bought by ethical
capital partners. Because, you know, life is weird. Reddit could be a big winner of this. But I think,
you know, I've been already, like Reddit is already just full of porn, right? So it's like,
I just assume you are more full of porn. I'm sure they're going to be very smart about this,
you know, and engaging porn. But really, what you're saying is go along AI voices, you know,
like this kind of loneliness that they fill in, that could be a good investment team. Because
again, you have the whole whole life stuff that then emerges to these engaging people.
I think it's going to happen, but I don't think it's a good investment. And like, let me just go
back to like, just because it's going to happen doesn't make it a good thing to invest in. And
like, to me, it's really unclear where the leverage is in that, right? Like, it's like,
you're, you'd have to believe that somehow you're going to have dramatically more compelling
characters than like the next company also provide, right? Or you'd have to use it like,
I just don't use any lock in, I think, and I don't think there's any like other and so it's
really unclear just because it's going to happen doesn't make it an investment.
Well, I think there is kind of, if you kind of look at hook dynamics, there's kind of that trigger
reward kind of dopamine rush and lots of stuff that you invest into each character. So there's
probably going to be a lot of first mood and advantage here. On the other side, you have the
licenses, you have the IPs that can be brought to this, like not on the form side, but as a whole
gamut from board to your mental health buddy, right? I mean, I think ultimately, if you're
basically saying, is there a solution to loneliness and solution to making you feel good,
there's a whole gamut of different things that can happen here, where you've got IP,
wait for these other things. Again, the example I think that comes from that is
the hollow life influences that going up like that.
Not to push you with it. I mean, it sounds like you're agreeing with me, which is like the leverages
in IP, right? Or the leverages in distribution, right? For this type of stuff, because the pure
tech stuff to it, it's like, yes, there'll be good jillions of, you know, virtual girlfriendy,
whatever things, but it's not, those are not platforms you can invest in. And they're like,
they're not really valuable, even if there's a lot. I think bringing it all together is something
that will take time. So I think there will be a lot of first-degree advantage. So like with stability,
again, data distribution are key, right? So my thing is, take the best of open, which we stimulate
and we fund lots of, build the stable series of models already without any data and distribution
to it. So open data, commonsense data, national data, and then we take it through cloud system
integrators on-prem and I take a share of all that revenue. So I agree, that's kind of cool to a good
business. But what I'm saying is, I don't believe in this particular area, going from port at one
end to mental health buddies at the other end, there are established distribution networks.
I think there'll be a lot of opportunity there for first mover advantage.
In the history of investing, first mover advantage has generally turned out to be a pretty bad
investment. Okay, maybe not first mover advantage, just say first proper entity advantage that takes
advantage of classical good company dynamics. There aren't big companies there yet.
Yeah, maybe. Again, I think it's a little hard to know exactly. There's a huge spectrum here,
it's hard to like, exactly react. But I would say, like, look, I think we're agreeing that like,
entertainment's going to get more entertaining, right, and cheaper to produce, right?
I think we're agreeing that IP is very valuable and maybe it's more valuable. Like, so maybe the
answer is buy Disney stock. Because Elsa is going to be a way cooler character when like,
that's kind of obvious, kind of obvious, right? And like, I think we can all agree on that. I think
what is not clear to me is outside of the IP plays, outside of the distribution,
existing distribution plays, like what IP, what AI really unlocks is a new disruptive
vector for this type of stuff. Because I don't, I do think that there are some pure AI type things
you can do. Again, we'll talk about the AI girlfriend thing is just unclear what the payoff
is there, right? Because they don't have any modes. Well, I think if you look kind of, you can scale
a certain type of human endeavours, shall we say, for example, the origin of therapists in the world,
you know, and it is a regulated industry. But at the same time, there is a gap for therapists,
just like you have the meditation apps kind of step in, and they created calm, and they
created these other things that were huge. Now this is more engaging. So I think one of the areas
to look at is where can you not find enough people that can fill in some of these things and then
build good experiences around that if you're looking at companies that can come to the fore,
because there isn't an existing solution. This is why, like I said, for me, I look at the global
south, I'm like, there's lots of gaps. I look at kind of here, and there's again gaps, where are
the gaps that you want to go because you can basically create a market need to fulfill a key
customer need. And so again, I looked at mental health in particular, and that goes again from
the porn AI waifens all the way through to proper mental health, kind of therapists. There's a huge
gap in that particular market, and there's a huge chasm of loneliness, and a lot of products that
could be built that are generally useful. And that can go quite fast enabled by this technology,
where they were not enabled before. I think this has been fascinating. I have kind of a handful
of concrete prediction questions that I kind of want to get you guys on record with if you're
up for it, and see if you have similar concrete predictions are different. And then we can obviously
check back in on in the future. How does the market for inference shape up? And for a jumping off point,
how do you think it might look different from the current cloud infrastructure market?
I think inference will be the vast majority, but I think it's like GPUs to assets with Bitcoin
mining. Because these are big research artifacts that are pie torches, but the output is a little
tiny part of binaries. And that's not a complicated thing to run inference on.
You see in Forensia 2 on Amazon Cloud, you see kind of the TPU v5s and others. I think there'll
be more and more customized solutions as you move from that research to engineering bit. And then
the cost competition goes massive in a few years time. Over the next few years, I think there'll
be a shortage because everyone will try to use this technology. There won't be enough. And then
eventually it'll move towards the edge because I think there's just all this magnitude optimization
that we can do from here. Yeah, I mean, this is a little bit beyond my
direct wheelhouse. But I think in the end of the day, what I'd say is like, I highly suspect
because the distribution is indifferent, right? And the patterns aren't different in any of this
stuff that we're going to see is everything from chipsets all the way through to cloud providers.
Things look basically the same as they do today. Everyone's just making more money.
Yeah, I think inference is also interesting because in the cloud, you just move to wherever
the cheapest inference is for these models. And so it's quite a mobile thing. So you've
got NVIDIA coming forward for that reason. Question two, what happens to the price
of primary care medicine in the United States over the next 10 years?
Unfortunately, given the issues, I think it's correct. It should go down. The regulatory capture
is far too strong. Unless something major, major happens. Question three, you guys both
have kind of said there's a ton of junk out there. It seems like broadly, we're not expecting
that many major incumbents to be disrupted. What would you guess would be the most likely
incumbents to be disrupted if you had to pick some? Stack overflow. I think it's 4.1.6 billion
by process, right? Whoever. I mean, I think the process is probably fine. You've seen disruption
in CHEG and other things. We didn't really get into this, but I do think that some SaaS companies
with low switching costs will be at risk from some of these higher context window companies
where you can put 10,000 words of instructions in. Because some of them are relatively basic
in that way. Actually, for words, I think we once again mostly agree. The only thing I think is
at risk for things like Zapier, right? Or some of these like kind of like, and it's kind of a 50-50
because they also get way more powerful. But I think there's a bunch of SaaS tools that
probably end up looking more like features where they used to look maybe like companies
because of the AI. But real incumbents, like public big multi-billion-dollar companies,
I mean, I don't think any of them are really at risk in disruption. I think they're all just going
to get stronger. I think a bunch of startups or series A companies are going to get swiped out
or all of a sudden not going to be able to grow, right? Because I think the big guys will just get
better faster. Will the big tech companies that are currently open sourcing,
for example, Meta, Salesforce, will they continue to do so? Or will they stop?
Well, I think Meta has moved to non-commercial open source for all their open source.
Now, I think Salesforce has kind of continued to do full open source. I think it's just very
difficult because the regulatory environment become tougher and tougher. And it's not called to their
business to open source. I think that it would be 100% driven by business models, right? So like
Meta, if you think about it, is incredibly well positioned should generally the level of AI continue
to grow in the world, right? If you think about it, it's like the way they're going to monetize that
is having dramatically better ads, right? And like dramatically better content in a bunch of ways.
And so I think they have a heavy incentive to think about it, to like keep up and sourcing
it, they want the talent, they want, you know, the reason companies also open source is like,
there's like a real internal external interplay, right? In terms of how you build an ecosystem,
they attract great talent. So I think they'll still keep happening. But I think you'll, I think
the list of people who are supporting open source stuff will shrink, right? If that makes
sense, as people get super competitive about this stuff, and the battle lines are drawn.
If you had a billion dollar company, you know, of any, of any kind, could you come up with a story?
Could you identify a type of company that should not, you know, where it wouldn't make sense, or
let's even frame it more decisively, where it would be defensible to not be investing, say,
at least a million dollars in figuring generative AI out today? In other words, is there anywhere
where this is not relevant? I mean, I'm sure there is, but nowhere I can think of offhand.
I think it's relevant just about everywhere, just because you always get a level of productivity
increase. But, you know, as Sam said, for a lot of industries, is this sustaining innovation? It's
just the next stage, as opposed to massively well changing, shall we say? What happens to
the marriage rate and the birth rate in, say, the United States as AI companions of all sorts
become available? It clearly goes down everywhere. I mean, like, look at South Korea, they're at
0.8 now on their fertility rate thanks to video games and a few other factors.
There are negative and positive ways to spin this, actually. Like, I think I personally, I
have the negative take on this, like, I think that's the future and a bunch of other things,
but here's the reality. It's just a simple economics thing, which is like, if the world was
more entertaining, then like, that makes doing un-entertaining, hard, long things like having
kids and raising them like less appealing, right? It's like, Tinder, Tinder is going to hurt the
birth rate. Like, AI is going to hurt, again, it's just sustaining innovation, which is technology
generally is going to hurt the birth rate. Yeah, and then you see places like Japan where you've
got declining birth rates, really embracing this because they want the productivity increase,
which is the other flip side of this. See, if you're more productive, you less people.
Yeah, I mean, that's the irony that you talk about the long-lived and the diamond age you
referenced earlier, like a really long-term sci-fi story is pretty simple, which is like,
a highest, highest, highest level, like technology will drive there to be fewer people. And then
because there are fewer people, we need more technology, right? And like, it becomes a symbiotic
thing. That's the really sad part. I mean, like, it's all sort of people thinking about like, oh,
shit, like the entire human population is going to fall off a cliff, right? It's because we're
like entertaining ourselves to death. Do you think any AI leader, you know, open AI right now or
somebody who takes, you know, the leading position from them in terms of having the best model,
can sustain super high gross margins for a few years into the future?
Based purely on the AI, no. It needs to be distribution data.
I think the proprietary side, it's just unless it's super data unique, you're going to zero.
I think that you have Google and open AI as uneconomic actors. And that's incredibly difficult.
You know, so just to unpack that, you mean that basically they won't allow,
they don't intend to make a ton of money on this and they won't allow any models to either because
they're going to provide it at cost. They don't care about, yeah, they're probably under cost to
get the data. You know, again, they have different business models, Google cost shifts all the time,
right? This is why I went to the other side for open models to private data and standardizing that.
No one's making money on open models alone. Well, I mean, there is a way, there is a way.
So what basically what I do with my business model is standardizing it.
And then providing all the services around it as a blueprint for my partners to take forward.
Yeah, I mean, they're the consulting nexus version of this, like that you can probably pull off.
Again, consulting models, I think, again, obviously saying you're pursuing, but very difficult.
I build the models, I give it to my consulting partners and they take it forward.
That's why this is my theory of stability has been a partial theory. It's obviously a lot of
facets to the organization. But I kind of view stability as the the provider for like the non
aligned countries, if you will, like those that are like, we definitely don't want to buy from
corporate America. We want to own our own. We want control. Those folks seem like they have
nowhere close to the resources domestically to build their own systems. But they do have kind of
a point of pride and also just practicality, right? Like if you're an African government
and you want to get your own legal system into a language model, you know, who's going to do that
for you? That feels like a real sweet spot for stability. How much of the future do you think
is kind of serving that kind of third set of countries? No, I mean, look, we're carrying
subsidiaries and dozens of countries bringing all the top family offices with data and distribution.
And national models and national data sets based on broadcast data, we take a subset of that make
that open. And we've got the rest of that for our commercial side. So I think the global south
is the focus for us. Plus, there were these big multinational companies building dedicated teams
with them. Because we're the only company in the world that can build you a model of any
single majority or type. Is that sustaining? Who knows, but it's a decent business. And so my
thing was build a decent business doing decent stuff, doing something different to other people.
I'm sure there'll be more competitors. But again, let's see how it goes.
Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually
work customized across all platforms with a click of a button. I believe in Omniki so much
that I invested in it. And I recommend you use it too. Use Kogrev to get a 10% discount.
