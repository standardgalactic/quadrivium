So here's my first question for you. Very, very simple question. What makes you human?
Me? Both of you. You both have to answer what makes you human. Oh, and one word. You get one word.
Humor. Humor?
Emotion. Okay.
To confirm you're both human, I'm gonna need you to confirm which of these boxes have a traffic light.
I
Think I think I can do that too now. Okay. All right. Well, Sam, you are actually here
nine years ago at our first tech live and actually want to roll the clip of what you said, okay?
Certainly the fear with with AI or machine intelligence in general is that it replaces drivers or doctors or whatever
but
the optimistic view on this and certainly what backs up what we're seeing is that
Computers and humans are very good at very different things
So a computer doctor will out crunch the numbers and do a better job than a human on looking at a massive amount of data and saying this
But on cases that require judgment or creativity or empathy. We are nowhere near any computer system that is any good at this
Okay, does
2023 say I'll partially right and partially wrong. Okay. Yeah worse. Could have been worse. What's your outlook now?
People I
Think the prevailing wisdom back then was that AI was gonna
Do the kind of like robotic jobs really well first so it would have been a great robotic surgeon something like that
and then maybe eventually it was gonna do the
the sort of like higher judgment tasks and then you know, then it would kind of do the empathy and then maybe
never it was gonna be like a really great creative thinker and
Creativity has been in some sense and at this point the definition of the word creativity is up for debate
But creativity and in some sense has been easier for AI than people thought you can, you know, see dolly three generate these like amazing images
or
Write these creative stories with GPT-4 or whatever
so that part of the answer maybe was not perfect and
GP I certainly would not have predicted GPT-4 nine years ago
Quite how it turned out, but a lot of the other parts about people still really want a human doctor
That's definitely very true
And I want to quickly shift to AGI
What is AGI here after you could just define it for everybody in the audience? I
will say it's a system that can
generalize across many domains that
You know would be equivalent to human work
They would produce a lot of
productivity and economic value and but you know
We're talking about one system that can generalize across a lot of digital domains of human work and
Sam why is AGI the goal?
The the two things that I think will matter most over the next decade or few decades
To improving the human condition the most giving us sort of just more of what we want our
Abundant and inexpensive
intelligence
The more powerful the more general the smarter the better
I think that is AGI and then and then abundant and cheap energy
And if we can get these two things done in the world then it's almost like
Difficult to imagine how much else we could do
We're big believers that you give people better tools and they do things that astonish you and I think AGI will be
the best tool
Humanity has yet created with it. We will be able to solve all sorts of problems
We'll be able to express ourselves in new creative ways. We'll make just incredible things
for each other for ourselves for the world for for kind of this unfolding human story and
You know, it's new and anything new comes with change and changes
not always all easy, but I think this will be just absolutely tremendous upside and
Gonna you know, we're gonna
Nine more years if you're nice enough to invite me back. You'll roll this question and people will say like
How could we have thought we didn't want this?
How I guess two parts to that my next question
When will it be here and how will we know it's here?
From here
But either one of you, I mean you can both predict how long I think we'll call you in ten years and we'll tell you you're wrong
That's done. That's done that. Yeah, I probably in the next decade, but I would say it's a bit tricky because we
You know, when will it be here, right?
And I just kind of give you a definition
But then often we talk about intelligence and you know, how intelligent is it or whether it's conscious and sentient and all of these terms and
You know, they're not quite right because they sort of define our
Our own intelligence and we're building something so it different and you can kind of see how the definition of intelligence
Evolves from, you know machines that were really great at chess and
Off-a-go and now the GPT series and then what's next they continues to evolve and it pushes what how we define intelligence
We we kind of define
AGI is like the thing we don't have quite yet
So we've moved I mean there were a lot of people who would have ten years ago
So that art if you could make something like GPT for GPT five maybe that would have been an AGI
And now people are like well, you know, it's like a nice little chatbot or whatever and I think that's wonderful
I think it's great that the goalposts keep getting moved. It makes us work harder
but I
Think we're getting close enough to whatever that AGI threshold is gonna be that we no longer get to hand wave at it and the definition is gonna
Matter so less than a decade for some definition
Okay, all right
The goalpost is moving
Sam you've used the word and and previously when describing AGI the term
Median human. Can you explain what that is?
I
Think there are experts in areas that are gonna be
Better than AI systems for a long period of time
And so like, you know, you could come to like some area where I'm like really an expert at some task
And I'll be like alright, you know GPT four is doing a horrible job there GPT five six
Whatever doing a horrible job there, but you can come to other tasks where I'm okay, but certainly not an expert
I'm kind of like maybe like an average of what different people in the world could do it something and for that
Then I might look at and say oh, this is actually doing pretty well
so
What we mean by that is that the in any given area expert humans may
Like experts in any area can like just do extraordinary things and that may take us a while to be able to do with these these systems
But for kind of the more average case performance
So, you know me doing something that I'm like not very good at anyway. Maybe our future versions can help me with that a lot
So am I a median human?
It's some tasks, I'm sure and it's some clearly at this year a very expert human and no GPT is taking your job anytime soon
Okay, that makes me feel that makes me feel a little better
Mira, how's that GPT five going?
We're not there yet, but it's kind of need to know basis. I'll let you know that's such a diplomatic answer
I'm gonna make mirror to all
I would have no I would have just said oh, yeah
We're not sending you back here. There are these two who paired whose idea was this
You're working on it. You're training it. We're always working on the next thing
Just do it staring contest that's what makes us human
All of these steps though with GPT right is it or GPT three
3.5 for our steps towards AGI with each of them. Are you looking for a benchmark?
Are you looking for this is what we want to get to? Yeah, so
You know before we had the product we were sort of looking at academic benchmarks
and how well these models were doing on academic benchmarks and you know open AI is
Known for betting on scaling, you know throwing a ton of compute and data on this neural networks and
Seeing how they get better and better at predicting the next token
But it's not that we really care about the prediction of the next token
We care about the tasks in the real world to which this correlates too
And so that's actually what we started seeing once we put out
research in the real world and
We we build out products through the API eventually through a child GPT as well. And so now we actually have
real-world examples we can see how our customers do in
Specific domains how it moves the needle for specific businesses
and of course with GPT for we saw that it did really well in
exams like SAT and ELSAT and so on so it kind of goes to our earlier point that we're you know
Continually evolving our definition of what it means for these models to be more capable
but
You know as we increase the the capability vector what we really look for is reliability and
Safety these are very interweaved and it's very important to make systems that of course are increasingly
Capable, but that you can truly rely on and they are robust and
That you can trust the output of the system. So we're kind of pushing in both of these vectors at the same time and
You know as we build the next model the next set of technologies
We're both betting continuing to bet on scaling, but we're also looking at you know this other
Elemental of multi modality
Because we want these models to kind of perceive the world in a similar way to how we do and
You know we perceive the world not just in text but images and sounds and so on
So we want to have robust representations of the world
in these models
Well
GPT-5 solve the hallucination problem
Well, I mean
Actually, maybe like let's see
We've made a ton of progress on the hallucination issue
With GPT-4, but we're still quite
We're not where we need to be but you know, we're sort of on the right track and it's it's unknown
It's research. It could be that
Continuing in this path of reinforcement learning with human feedback
We can get all the way to really reliable
Outputs and we're also adding other elements like retrieval and search so you can
You have the ability to to provide more factual answers or to get more factual outputs
From the model so there's a combination of technologies that we're putting together to kind of reduce the hallucination issue
Sam I'll ask you about the data the training data
Obviously, there's there's been maybe maybe some people in this audience who may not be
Thrilled about some of the data that you guys have used to train some of your models not too far from here and in Hollywood people have
Not been thrilled
Publishers when you're when you're considering now as you're as you're walking through and turning going to work towards this these next models
What are the conversations you're having around? Yeah, so a
Few thoughts in different directions here one we obviously
Only want to use data that people are excited about us using like we don't
We want the model of this new world to work for
Everyone and we want to find ways to make people say like you know what I see why this is great
I see why this is like gonna be a new it may be a new way that we think about some of these issues around
data ownership and
Like how economic flows work?
But we want to get to something that everybody feels really excited about but one of the challenges has been people
You know different kinds of data owners have very different pictures. So we're just experimenting a lot of things
We're doing partnerships of different shapes
And we think that like with any new field will find something that sort of just becomes a new standard
also, I
Think as these models get smarter and more capable
We will need less training data. So I think there's this view right now, which is that we're just gonna like
You know models are gonna have to like train on every word humanity has ever produced or whatever and I
Technically speaking, I don't think that's what's gonna be the long-term path here
Like we have existential proof with humans that that's that's not the only way to become intelligent
And so I think the conversation gets a little bit
Let us stray by this because what what really will matter in the future is like
Particularly valuable data, you know people want people trust the Wall Street Journal
And they want to see content from that and the Wall Street Journal wants that too and we find new models to make that work
But I think the the conversation about data and the shape of all of this
Because of the technological progress we're making it's about to it's about to shift
Well publishers like my mine might be out there somewhere they want money for that data
Is the future of this entire race about who can pay the most for the best data?
Um
No, that was sort of the point. I was trying to make I guess you know
The but you still needs
Some you will need some but the core like the thing that is the thing that people really like about a GPT model
Ah is not fundamentally that it has that it knows particular knowledge. There's better ways to find that
It's that it has this
Larval reasoning capacity and that's gonna get better and better
But that's that's really what this is gonna be about and then there will be ways that you can set up all sorts of economic
Arrangements as a user or as a company making the model or whatever to say all right now
You know I I understand that you would like me to go get this data from the Wall Street Journal
I can do that but here's the deal that's in place
So there'll be things like that but but the fundamental thing about these models is not that they memorize a lot of data
So sort of like the model we're also right now. You've got being integrated it goes out looks for some of that data
And can bring back yeah, and that's you know on the internet. We decided
Again back in the early days in it
There were a lot of conversations about the different models could be and we all kind of decided on you know
Here's the the core framework and there's different pieces in there, of course
And we're all gonna have to figure that out for AI well speaking of Bing
You and Satya Nadella your ten billion dollar friends or frenemies friends. Yeah, yeah
I won't pretend that it's like a perfect relationship, but nowhere near the frenemy category. It's really good
Like we have our squabbles
You know, we just seems like recently as you guys are releasing more and more products that they seem to compete in some places
um
I mean, I think that that's that there's something
Core about this language interface that is a big deal and so there's gonna be a lot of people doing things for that and
And then there's other places like you know, we offer a version of API they offer a version of the API
But like that just that's like a very
Friendly thing and we all like we work it out so that we all benefit and we're all happy and and we just want like we jointly want as much
Usage of our models of our as possible. So we're super aligned there
But yeah, it's like
Makes sense
Friends friends that's text. We do a lot. Okay. All right. All right
Mira you you over the last number of months have started to roll out a lot more personalization to the model
Right, you can put in custom instructions
You get a you can get the voice now and we're gonna bring out one of the bring down the screen to hear one of these clips
But I wanted to play one of these conversations. I had with chat GPT just yesterday
It's a slow screen
Chachi BT responds quicker
We're gonna get that better though. Yeah, we're gonna work on that. We'll get it faster. Yeah, that I can't help you
No, I'm saying chat to BT is faster than this. Yeah. Yeah, and I'm saying that's like it's not
I've got a big interview with open AI executives and I'm nervous any advice
Absolutely given your background as a technology columnist, you're well equipped for this
Just be yourself do your homework on open AI's latest developments and trust in your expertise
Remember, they'll likely appreciate thoughtful and well researched questions. And hey, everyone gets nervous
Take a deep breath and rock it
Am I rocking it definitely I'm rocking it. All right, are we rocking it up here?
But what's so striking about that first of all, I want every that's that's the voice of chat GPT
They have one of five. Yeah. Yeah, I mean that is the voice. It is it sounds so human
It sounds so natural
It knows about me because I've already put into custom instructions. I'm a tech journalist
It also knows I'm allergic to avocado. It's always putting that in there. Don't eat avocado. I'm like, I'm not asking about avocado
We got some work to do is there is there a future and this is what you're maybe trying to build here where we have
Deep relationships with this type of thought
It's going to be a significant relationship, right because you know
We're we're building the systems that are going to be everywhere in your home in your educational environment in your work environments
and maybe you know when you're having fun and so that's why it's actually so important to get it right and
We have to be so careful about how we design this interaction so that ultimately it's you know
Elevating and it's fun and it's it makes productivity better and it enhances creativity
And you know, this is ultimately where we're trying to go and as we increase the capabilities of the technology
We also want to make sure that you know on on the product side
we feel in
control of
This these systems in the sense that we can steer them to do the things that we want them to do and the output is
Reliable that's very important and of course we want it to be personalized
Right and as it has more information about your preferences the things you like the things you do
And the capabilities of the models increase and other features like memory and so on it has of course
it will become more personalized and
That's that's a goal it will become more useful and it's going to become
More fun and more creative and it's not just one system, right?
Like you can have many such systems personalized for specific domains and tasks
That's a big responsibility though, and you guys will be in sort of control of
People's friends. Maybe people gets to being people's lovers. How do you how do you guys think about that control?
First of all, I think there's
We're not gonna be the only player here like there's gonna be many people
So we have we have we get to put like our nudge on the trajectory of this technological development
And we've got some opinions
But a we really think that the decisions belong to sort of humanity society's a whole whatever you want to call it and be
We will be one of many actors building sophisticated systems here. So
It's gonna be a society wide discussion. It's and there's gonna be all the normal forces
there'll be competing products that offer different things there will be different kind of like
Societal embraces and pushbacks. There'll be regulatory stuff
It's gonna be like the same complicated mess that any new technological
birthing process goes through and then we pretty soon will turn around and we'll all feel like we had smart AI in our lives forever and
You know, that's just that's that's the way of progress, and I think that's awesome. Um, I
Personally have deep misgivings about this vision of the future where everyone is like super close to AI friends and not like more so than human
Friends or whatever. I personally don't want that. I
accept that other people are gonna want that
and
You know, some people are gonna build that and if that's what the world wants and what we decide makes sense of work
We're gonna get that I
Personally think that personalization is great
Personality is great, but it's important that it's not like
person this
And at least that you know when you're talking to AI and when you're not, you know, we named it chat gbt and not
It's a long story behind that but we need a chat gbt and not a person's name
Very intentionally and we do a bunch of subtle things in the way you use it to like make it clear that you're not talking to a person
um, and
I think what's gonna happen is that in the same way that people
Have a lot of relationships with people they're gonna keep doing that and then there also be these like AI's in the world
But you kind of know they're just a different thing
When you're saying this is another question for you, what is the ideal device that we'll interact with these on and I'm wondering if you
I hear you and Johnny. I've been talking
You bring something to show us
I
Think I think there is something great to do, but I don't know what it is yet
You must have some idea a lot of ideas. Yeah, I'm interested in this topic
I think it is possible. I think most of the current thinking out there in the world is
quite
Bad about what we can do with this new technology in terms of a new computing platform
And I do think every sufficiently big new technology
Enables some new computing platform
But lots of ideas but like in the very
Mason stage so it doesn't I
guess the question for me is
There's something about a smartphone or earbuds or a laptop or a speaker that doesn't quite work right now
Yeah, of course
Smartphones are great. Like I have no interest in trying to go compete with a smartphone
like it's a phenomenal thing at what it does, but I
Think the way what AI enables is so fundamentally new
That it is possible to and maybe we won't like you know
Maybe maybe just like for a bunch of reasons doesn't happen
But I think it's like well worth the effort of talking about or thinking about you know
What can we make now that before we had computers that could think was?
our computers that could understand whatever you want to call it was not possible and
If the answer is nothing it would be like a little bit disappointing
What sounds like doesn't look like a humanoid robot, which is good
Definitely
I don't think that quite works. Okay, speaking of hardware and making your own chips
You want answer no
Directed here
Are we making our own chips?
We are trying to figure out what it is going to take to scale to deliver
At the scale that we think the world will demand and at the model scale that we think that the research can support
That might not require
Any custom hardware?
And we have like wonderful partnerships right now with people who are doing amazing work
So the default
Path would certainly be not to but I wouldn't I would like I would never rule it out
Are there any good alternatives to Nvidia out there?
Nvidia certainly has something amazing amazing, but you know, I think like
The magic of capitalism is doing its thing and a lot of other people are trying and we'll see where it all shakes out
We had Renee Haas here from arms. It is great here. You guys have been talking
We said hello. Yeah, oh you said hello
Not as close as that you're not you're not as close as I'm not as the plug. I got it got it
Um
This is the really hard. This is we're good. Yeah, we're getting to the heart
I'm about to get to the hard hitting. So
My colleagues recently reported you guys are are are actually looking at the valuation is 80 to 90 billion
And that you're expected to reach a billion in revenue
Are you raising money?
No, well, I mean always but not like this minute not right now
There's people here with money. All right, let's talk
We will need huge amounts of capital to complete our mission and we have been extremely up front about that
There has got to be something more interesting to talk about in our limited time here together then our
Future capital raising plans, but we will need a lot more money. We don't know exactly how much we don't know exactly how
It's gonna be structured what we're gonna do, but
You know it like shouldn't
Come as a surprise because we have said this all the way through like it's just a tremendously expensive endeavor
Where which part of the business though right now is growing the most
Mira you can also jump in definitely in the product side
Yeah, with with the research team is very important to have you know density of talent
Small teams that innovate quickly the product side, you know, we're doing a lot of things
We're trying to push great uses of AI out there both on platform side and first party and work with customers
So that's the delay and the revenue is coming mostly from that API
The the revenue for the company revenue, oh, I'd say both sides both sides
Yeah, so my my subscription to chat GBT plus is appreciate that. Yeah. Yeah
How many people here actually are subscribers to chat GBT plus? Thank you all very much
You guys make a family plan
I'm spending on you. We'll talk about it. Yeah, okay. This is what we're really here for tonight
Moving out a little bit into policy and and some of the fears
It's not like super cheap to run if we had a way to like yeah say like hey, you know, you can have this for like
You can give you like way more for the 20 bucks or whatever
We would like to do that and as we make the models more efficient will be able to offer more
But it's not for like lack of us wanting more people to use it that we don't do things like family
Family plan for like thirty five dollars for two people
That's the kind we'll work on
Well, I gave you the sweatshirt
How do we go from the chatbot we just heard that told me to rock it to one that I don't know can rock the world and end the world
Well, I don't think we're gonna have like a chat about that ends the world
We've got simple chatbots. They're not simple. They're advanced what you guys are doing
But how do we go from that idea to this fear that is now pervading?
everywhere
if
if we are right about the trajectory things are going to stand and if we are right about not only the kind of like scaling at the
GPT's but new techniques that were interested in that could help generate new knowledge and
Someone with access to a system like this can say like
Help me hack into this computer system or help me design
You know like a new biological pathogen. It's much worse than COVID or any number of other things
It seems to us like it doesn't take much imagination to think about scenarios that deserve great caution and
And again, we all come and do this because we're so excited about the tremendous upside in
That the incredibly positive impact and I think it would be like a moral failing not to go pursue that for humanity
But we've got to address and this happens with like many other technologies
We've got to address the downsides that come along
With this and it doesn't mean you don't do it
It doesn't mean you just say like this eight day. I think we're gonna like
You know, we're gonna like go like full dune and like blow up, you know have not have computers or whatever
But it means that you like are thoughtful about the risks you try to measure what the capabilities are and you try to
build your own technology in a way and
That mitigates those risks and then when you say like hey, here's a new safety technique you make that available to others and
As you guys are thinking about
Building in in in this direction. What are some of those specific safety risks you're looking to put in?
I mean like Sam said
You've got the capabilities and then there is always a downside whenever you have such immense and great capability
There's always a downside. So
We've got a fierce task ahead of us to figure out what are these downsides discover understand them
Build the tools to mitigate them and it's not, you know, like a single fix
You usually have to intervene everywhere from the data to the model to
the tools in the product and of course policy and then thinking about the entire regulatory and
Societal infrastructure that can kind of keep up with these technologies that we're building because ultimately what we want is to
Slowly roll out these capabilities in a way that makes sense and allow society to adapt
because you know the
Progress is incredibly rapid and we want to
Allow for adaptation and for the whole infrastructure that's needed for these technologies to actually be absorbed
Productively to exist and be there. So, you know, when you think about what are sort of the concrete
safety
Measures along the way, I'd say number one is actually rolling out the technology
And slowly making contact with reality understanding how it affects
Certain use cases and industries and actually dealing with implications of that whether it's regulatory copyrights
You know, whatever the impact is actually absorbing that and dealing with that and moving on to more and more capabilities
I don't think that building the technology in a lab in a vacuum without contact with the real world and
With the friction that you see with reality is
Good way to actually deploy it safely and this might be where you're going, but it seems like right now
You're also policing yourself, right? You're setting this bad and Sam
That's where I was going to ask you
I mean you seem to spend more time in Washington than Joe Biden's dogs right now and I've only been twice this year really
That's I think those dogs like three days or so anyway
But what is it specifically that you would rather the government and our regulators do versus you have to do first?
The point you're always making I think is really important that that it's very difficult to make a technology safe in
the lab
Society uses things in different ways and adapts in different ways
And I think the more we deploy AI the more I is used in the world the safer AI gets and the more we kind of like
Collectively decide hey, here's a thing that is not an acceptable risk tolerance and this other thing that people are worried about that's that's totally okay
and
you know like
We see this with many other technologies airplanes have gotten unbelievably safe
even though they didn't start that way and it was
it was like careful thoughtful engineering and
Understanding why when something went wrong it went wrong and how to address it and you know the shared best practices there I
Think we're gonna see in all sorts of ways that the things that we worry about with AI in theory don't quite play out in practice
You just like a ton of talk right now about deep fakes and you know that the
Impact that's gonna have on
Society in all these different ways
I think that's an example of where we were thinking about the last generation too much and
AI will disrupt society in all of these ways, but you know we all kind of are like
They're like oh, that's a deepfaker. Oh, it might be a deepfaker. Oh that picture video or audio like we learn quickly
But but maybe the real problem. This is like speculation. This is hard to know in advance is not the deep fake ability
But the sort of customized one-on-one persuasion and that's where the influence happens. It's not it's not like the fake image
It's that this thing has a subtle ability these things have a subtle ability to influence people and then we learn that that's the problem and we
adapt
so
In terms of what we'd like to see from governments. I think we've been like very mischaracterized here. We do think that international
Regulation is gonna be important for the most powerful models nothing that exists today
Nothing that will exist next year, but as we get towards a real super intelligence as we get towards a system that is like
More capable than like any humans
I think it's very reasonable to say we need to treat that with like caution and
And a coordinated approach, but like we think what's happening with open source is great
We think startups need to be able to train their own models and deploy them into the world and a regulatory response on that would be a
disastrous mistake for this country or others
So the message we're trying to get across is you got to embrace what's happening here
You got to like make sure that we get the economic benefits and the societal benefits of it, but
Let's like look forward at where this where we believe this might go and let's not be caught flat-footed if that happens
You mentioned deep fakes, and I want to talk about AI generated content. That's all over the internet now
Who do you guys think is responsible or or should be?
Responsible for policing some of this or not policing but detection of some of this is this on the social media companies
Is this on open AI and all the other AI companies?
We're definitely responsible for the technologies that we develop and put out there and you know
misinformation and
That's that's clearly a big issue as we create more and more capable
Models and we've been developing technologies to deal with
the provenance of an image or a text and
Detect output, but it's a bit complicated because you know you want to give the user sort of
Flexibility and they you also don't want them to feel monitored
And so you have to consider the user and you also have to consider people that are impacted by the system that are not users and so
These are quite nuanced issues that require a lot of interaction and input from not just your users of the product
but also of society more broadly and
Figuring out, you know also with partners that that bring on this technology and integrate it
What are the best ways to to deal with these issues because right now?
There's no way or no tool from open AI at least that I that I can put in an image or
Some of the text and ask is this AI generated? Correct for image. We have actually technology that's
Really good almost, you know 99% reliable, but we're still testing it
It's early and we want to be sure that it's going to work and even then it's not just a technology problem
This information is such a nuanced and broad problem
So you still have to be careful about how you roll it out where you integrate it
But we're certainly working on the research side and for for image at least we have a very reliable tool in in the early stages
yeah, and
Say it's work. When might you release this?
You said you said you're you're working on this right now. Is this something you plan to release? Oh, yes
Yes, for both images and text for text. We're trying to figure out what actually makes sense
For for images. It's a bit more straight straightforward problem
But in either case we definitely test it out because we don't have all the answers right like we're building these technologies first
We don't have all the answers. So often we will experiment. We will put out something
We will get feedback, but we want to do it in a controlled way, right?
and
Sometimes we'll take it back and we'll make it better and roll it out again
I'll also add that I think this idea of watermarking content is not something that
Everybody has the same opinion about what is good and what is bad
There's a lot of people who really don't want their generated content watermarked and that's understandable in many cases
Also, it's not it's not going to be super robust to everything like maybe you could do it for images
Maybe for longer text, maybe not for short text, but over time there will be systems that don't put the watermarks in and also
there will be people who really like
You know, this is like a tool and up to the human user how you use the tool and I don't like
This is why we want to engage in the conversation like we are willing to sort of like follow the
the collective wishes of society on this point and I
Don't think it's a black-and-white issue
I think people are still evolving as they understand all the different ways
We're gonna use these tools. They're still evolving the thoughts about what they're gonna want here
Also to Sam's earlier point, it's not, you know
It's not just about truthfulness, right?
And what's what's real and what's not real actually?
I think in the world that we're going towards marching towards the bigger risk is really this individualized
Persuasion and and how to deal that and that's going to be a very tricky problem to deal with I
Realize I have five minutes left and we we're going to do some audience questions
So we can get to one audience or two audience questions. I'm gonna finish one one one last thought here
I can actually not see a thing out there. So I will ask one last question. Then we'll hopefully have time for one or two
So ten years you were here ten years ago
What we touched on this as we were starting here, but what is your biggest fear about the future?
And what is your biggest hope with this technology?
I think the future is gonna be be like amazingly great. We wouldn't come work so hard on this if we didn't
I think this is gonna be like I think this is one of the most significant inventions humanity has
yet done
So I'm super excited to see it all play out. I think like things can get so much better
for people than
Then they are right now, and I'm I feel very hopeful about that
We covered a lot of the fears it like again, we're clearly dealing with something very powerful
That's gonna impact all of us in ways. We we can't
Perfectly foresee it
But like what a time to be alive and get to witness this
You're not so fearful, but I was gonna actually ask this but I'll ask it now. You have a bunker
This is the heart this is this is better than the audience questions not better than I'm gonna let that walk run
I'm not gonna pay attention that but I was we're thinking about fears
I just I'm wondering why if you have a bunker and I would say you know you have that you'd say no
I have like structures, but I wouldn't say like a bunker
structures
None of this is gonna help if age goes wrong. This is really it's a ridiculous question
Okay, okay good good good
Mira with your hope and fear. I
Mean the hope is definitely to push our
civilization ahead with
augmenting our collective intelligence and
The fears we talked a lot about the fears, but you know, we've got this opportunity right now
And you've got summers and winters in AI and so on but you know when we look back ten years from now
I hope that
we get this right and I think there are many ways to to mess it up and
We've seen that with many technologies. So I hope we get it right
All right, we've got time right here. Hi, I'm Pam Dylan preferably
Sensory consumer products AI my question has to do with the inflection point
we are where we are with respect to AI and
AGI what is the inflection point?
How do you define that moment where we go from where we are now to however you would choose to define?
What is AGI?
I think it's
It's gonna be much more continuous than that
We're just on this beautiful exponential curve
Whenever you're on a curve like that you look for it looks vertical you look back. It looks horizontal
That's true at any point on there
So a year from now will be in dramatically more impressive place than a year ago
We were in a dramatically less impressive place, but it'll be hard to point people will try and say oh it was
Alpha go there did it was GPT-3 that did it was GPT-4 that did it
But it's just brick by brick one foot in front of the other up climbing this exponential curve
Right here in the front
Thank you, my name is Nyariana Maiko. I'm the chief information officer at the Port of Long Beach
But I'm also computer scientist by training a few decades ago. I'm older than you
I remember working with some of the early AI people. I have a general question. I agree with you
This is one of the most significant innovations to happen
One of the things I've struggled with over the last 20 years and thinking about this we're about to change the nature of work
This is that
Significant and I feel that people are not talking about it. There will be a significant
There'll be a transition time period for a significant population in the world and in this country
Will not have had the types of discussion understand that we have so they can like you mentioned society needs to be a part of it
There's a large portion of society. That's not even in this discussion
So the nature of work will change it used to be that things that were just gonna be automated
There will be a time where people who define themselves by work
Since thousands of years will not have that and we're hurtling towards it
What can we do to make sure that we take that into account because when we talk about society?
It's not like they're all together ready to discuss this
Some of the effects of some of the technologies that we brought into the world have actually made people separate from each other
How do we get some of those not regulations, but how do we?
Come up with some of those frameworks and voluntarily bring things about that will actually result in a better world
That doesn't leave everybody else behind. Thank you
I
I'll give you my perspective. I think I
Completely agree with you that it's one of it's the ultimate technology that could really increase inequality and make
make things so much worse for us as
human beings and civilization or it could be you know really amazing and it could bring along a lot of
creativity and productivity and
Enhance us and you know, maybe a lot of people don't want to work
Eight hours or a hundred hours a week. Maybe they want to work four hours a day and do a bunch of other things and
you know, I
think it's certainly going to lead to a lot of disruption in the workforce and
We don't know exactly the scale of that
Or or the trajectory along the way, but that's that's for sure and
one of the things that I
In retrospect, it's not that we specifically planned it by in retrospect
I'm happy about is that with the release of charge of beauty. We sort of brought AI into the
You know collective consciousness and people are kind of paying attention because they're not reading about it in the press
People are not just telling them about it, but they can play with it
They can interact with it and get the sense for the capabilities
And so I think it's actually really important to bring these technologies into the world and make them as
Widely accessible as possible
You know Sam mentioned earlier like we're working really hard to make these models cheaper and faster
So they're accessible very broadly, but I think that's key for people themselves to actually
interact with the technology and experience it
and sort of visualize how it might change their way of life their way of being and
participate as you know as
Improving product feedback, but also, you know
Institutions need to actually prepare for these changes in the workforce and economy
Can I give you the last word? Yes, absolutely. I think it's a super important question
every technological revolution
affects the job market and
Over human history, you know every maybe 100 years you feel different numbers for this 150 years half the kind of jobs go away
Totally change whatever
I'm not afraid of that at all. In fact, I think that's good
I think that's the way of progress and we'll find new and better jobs the thing that I think we do need to confront as a society
Is the speed at which this is going to happen?
It seems like over, you know to maximum three probably two generations
We can adapt society can adapt to almost any amount of job market change, but a
Lot of people like their jobs or they dislike change and going to someone and saying hey the future will be better
I promise you and society is gonna win, but you're gonna lose here that that doesn't work
That's not a that's not cool like that's that's not a nice. That's not an easy message to get across and
although I tremendously believe that we're not gonna run out of things to do people that want to work less fine
they'll be able to work less but you know probably many people here don't need to keep working and and we all do like we
There's like great satisfaction in expressing yourselves in in being useful and sort of contributing back to society
That's not going away. That that is such an innate human desire like evolution doesn't work that fast
Also the sort of ability to creatively express yourself and to sort of leave something to to add something back to
the trajectory of the species is
That that's that's like a wonderful part of the human experience
so we're gonna keep finding things to do and
The people in the future will probably think some of the things
We'll think some of the things those people do a very silly and not real work in a way that like a hunter-gatherer
Probably wouldn't think this is real work either, you know, we're just trying to like entertain ourselves with some silly status game
That's fine with me. That's how it goes
the
But we are gonna have to really do something about this transition
It is not enough to just give people a universal basic income
people need to have
Agency the ability to influence this they need we need to sort of jointly be architects of the future and one of the reasons
that we feel so strongly about
Deploying this technology as we do as you said not everybody's in these discussions
But more and more are every year and by putting this out in people's hands and making this super widely available and getting billions of people to use
chat GBT
not only do people
have
The opportunity to think about what's coming and participate in that conversation
But people use the tool to push the future forward and that's really important to us
