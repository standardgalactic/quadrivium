So our closing event is a special lecture given by Mike Jordan who almost I think does
not need an introduction but I'll still give one.
So he's a Pei Hong Chen Distinguished Professor at UC Berkeley and Mike has been a leader
in the computational and mathematical study of learning for a long time and he's achieved
such prominence that I think in 2016 he's been named one of the most influential computer
scientists on Earth and so I'm just looking at his computer right now or the most influential
computer scientist.
He's been recognized for his work by many contributions, many awards as a member of
the National Academy of Science, of the National Academy of Engineering, of the Royal Society.
He was the inaugural winner of the World Laureates Award last year in 2022 and he receives
a John von Neumann Medal from IEEE in 2020.
If I were to list all these awards I think we would be here for a long, long time.
But I would say that personally there are three things that amaze me about Mike Jordan.
The first is his range of interest.
They span an enormous array of fields that goes all the way from computer scientists
to statistics to control theory, signal processing, mathematics, information theory, cognitive
science and now economics and maybe we'll hear about a bit about this today.
And I think the range and the breadth of his interest is just very unique.
There's another thing that is unique about Mike.
He's his track record of training the next generation of students.
I think if you look at, I think he has a very impressive CV, but I think if you look at
the CV the thing that impresses me the most is the name of his grad students because your
students, and we have one right behind you, Lee-Wa, we have another one right there so
we have already a lot of various, they are actually, they make up the who's who in machine
learning today.
And so if you open who's who in machine learning and ask the question, is this one of Mike's
student?
The likelihood of a yes is very high and so, and I think he's done this by fostering an
environment of inclusivity and curiosity that has really moved the entire field.
And so I think the whole field is grateful for this.
The third observation is more personal.
I think Mike's age is public information, at least if Wikipedia is correct.
So you've been at the top of your game for a long, long time and this is really unique.
And the way I think about Mike in the evening is I think it's a kind of the Roger Federer
of science, someone who has been dominating the circuit for a very, very long time with
no signs of slowing down.
Mike, welcome to Stanford.
All right, thank you, that was perhaps the most fun introduction I've had ever.
When I next time introduce Emmanuel, which will happen, I'm sure I'm gonna have to think
about the right metaphor.
Maybe someone has an idea helped me out there.
I gotta get my mind off that because it's a fun thing to think about.
So I'm a pleasure to be here.
I am a data scientist and in fact this kind of quote that I was like an influential computer
scientist is kind of funny to me because I'm trained as a control theory statistician and
I was never a computer scientist.
I embrace it because of the entrepreneurial spirit in computer science and just let's
try everything.
I love that.
And I found less of that in control theory and statistics, so that's great.
But intellectually I'm a data scientist.
I really want to think about how data and inference can inform real world decision making and
I think that's where it's at.
I think that it's in the first time in my career that sort of all of campus agrees.
It's sort of a, it's just not the truth.
Technologist inside of a computer scientist or statistician wasn't enough.
This is much more fun.
And indeed it's economics, which is the most thrilling to me right now, the connections
to economics.
That's really what I want to mostly convey tonight is why I think that's thrilling
and important and so on.
The elephant in the room is this thing called AI and I've never thought of myself as an
AI researcher.
I've never aspired to the Frankenstein-like thing of create some thing.
And I kind of want to say why.
Not only didn't aspire to it, I don't think it's right, but it is what everyone's talking
about.
So I want to say a few things about it.
So first of all, the thing that triggered all of this was back propagation, gradient
descent in layered neural networks.
There's all these other ideas along the way, unsupervised this and that, which didn't really
quite pan out, but back propagation had this huge impact.
Dave Rummelhardt was my advisor at UCSD and he developed that.
It's just gradient descent, so you can't say he invented it, but he invented the idea
of doing it in layered neural networks and applying it to all kinds of problems.
And he took about a year to do that.
It was not trivial for him.
He was not trying to be an AI person.
He was just trying to understand learning.
I think he'd be somewhat shocked that suddenly that becomes AI to this era.
So what I think is happening really is not that we have a new technology, this new brilliant
idea, AI, and then we start applying it everywhere.
I don't think that's the right way to think about it.
And so I think you need to go back in history a little bit and think about engineering fields
that have emerged.
So like in the 40s and 50s, chemical engineering became a thing.
The name was actually used, I kind of looked into it a little bit more.
Already by 1890, I think there was a department of chemical engineering at MIT.
But chemical engineering really was a very simple chemistry, kind of done its bigger
scale than before.
But polymers and all the kind of things that have triggered the revolution that we're all
living in, that happened in the 40s and 50s.
Before that, there was quantum chemistry and there was fluid dynamics and there was thermodynamics
and also there was a lot of deep understanding of the phenomenon.
And people then were able to start to envisage, what if I take the laboratory test tube experiment
of how you put molecules together, which I do understand because of the quantum chemistry,
and I do that at a huge scale in a field somewhere, will that work?
And of course, it didn't really work.
Often those things would explode, often they just wouldn't deliver a product and so on
so forth.
But over a 20-year period in the 40s and 50s, it kind of started to get worked out.
And an engineering field emerged that had huge impact on all of our lives.
Electrical engineering, I know less about the history, but obviously there was Maxwell's
equations before there was electrical engineering, so it was a full understanding of the phenomenon
at some level.
But it wasn't clear how to bring electricity into homes, how to make it safe, how to do
communication on top of the waves, and so on and so forth.
So a whole field emerged, which we now call electrical engineering, that did all that
in the early part of the past century.
It took a couple of decades again.
So I think that's what's happening right now.
We have a new engineering field emerging.
I wouldn't call it AI, but it's a field that's based on flows of data, networks, flows, inferential
ideas, large-scale decision-making, cooperative endeavor, building transportation systems,
commerce systems, healthcare systems, it's all part of this engineering field.
That's really what's happening.
And so it's the first engineering field that has got, as its objects of study, not just
bits and information and atoms and laws of physics, it has humans involved, critically.
So utilities and aspirations and so on.
And so economics has minimally got to be involved, but the rest of the social sciences as well.
And the implications are vast.
So actually, that's the phenomenon, and it's going to take 20 or so years.
The difference, though, with these others is that there was a deep understanding of some
underlying phenomenon there.
We don't have that now.
We do not understand intelligence, I can assure you.
So we're calling it AI as if we got this understanding and then it leads to technology, and I think
that's kind of backwards.
So let's just say, why did this happen?
Well, first of all, there was McCarthy and so on in the 50s who invented this terminology,
and for good reason.
There was a philosophical aspiration, almost.
There had been discussions of mind and body, and now we have a computer, it has software
and hardware, it looks like mind and body, and it looks like we can now make headway
on that.
And let's talk about putting thought in a computer.
That's a really interesting thing to talk about.
And of course, people got excited about that notion and worked on it.
We don't have thought in a computer to this day, and it's not clear why we really care
in some sense.
It'll somehow emerge and we'll call it thought, but it's not clear what that means.
And in the meantime, that's not what happened.
What computers started to do was aid humans.
They became complementary.
Search engines and translation systems and all that aided our own intelligence and expanded
it and networks expanded a planetary scale.
So let's not call it McCarthy's version of intelligence for sure, but that aspiration
still exists.
And people who study psychology and neuroscience and core AI, whatever that is, they are working
on that.
It's a worthy thing.
But we should be waiting for that because in the meantime, all these systems are being
built in the real world that are having this huge impact.
We should understand the phenomenon.
All right.
Now, the other part that happened, it wasn't really so much McCarthy, but others, it had
to be autonomous.
Why did the AI have to be autonomous?
Well, if it's not autonomous, if it's tethered to me, it doesn't seem so intelligent.
It's tethered to me.
And if it's developed by vast numbers of humans, it's engineers who built something
and it doesn't seem so intelligent.
So it had to kind of be built by small numbers of people and it had to be all on its own.
Now, that's a okay kind of science fiction-y kind of aspiration, but it's a bad idea for
technology.
You don't develop technology that way.
You don't want self-driving cars to be autonomous.
They should be highly networked so you think about the overall traffic system so you don't
ever have an accident, just like air traffic control.
You don't want autonomous airplanes.
So there'll be a lot of cartoons in this talk.
I don't mean it's never a good idea.
So a burning building, I want an autonomous robot.
Up on Mars, I want some double autonomy, but for most applications, I don't want the intelligence
to be autonomous.
I want it to be federated, linked in, transparent, cooperative, all those things.
So I think this was a big mistake to add that to the list.
I think it became kind of about bragging rights, look at my autonomous AI, how great
it is and it's better than your autonomous AI.
And again, this is all kind of fun and games for like 40 years, but it's no longer fun
and games.
It's actually going to hurt the planet.
All right, so here's a counterpoint, which is that first of all, this is kind of maybe
an obvious statement, but if we want to talk about intelligence, there's not one kind of
intelligence.
It's not just human intelligence.
It's as much about the collective as it is about the individual.
And an economist thinks this way all the time.
They recognize that a market is composed of many small decisions by entities that don't
have to be intelligent themselves.
They just have to kind of know a demand curve and follow some of their nose.
And you're not using huge intelligence within it, but the overall market becomes really
intelligent.
It could do things like bring food into cities, bring or shine at any scale for hundreds
of years, and it can create all kinds of opportunities.
And then there's like ant swarms that we talk a lot about, not an individual ant might
not be so smart, but the swarm could do amazing things.
So we're all aware of that, but too dimly.
I don't think we understand that we could be creating new kinds of collectives that are
really exciting, that do new things as human beings.
That's what's opening up to me in the era.
Not the super intelligence replacing a human, look at how great that is.
All right, so in particular, if you're going to be a little less exuberant, but you're
going to say, what are the goals for this emerging field?
It's not make a super intelligence at a computer, and you're done.
It's rather what is the overall object, like the factory in the field?
Is it a transportation system?
Is it a logistics chain?
Is it a healthcare system?
Is it a communication system designed for that level?
And then think about what the components need to be and what data is needed and all that.
It sounds more boring than a typical AI person's talk, which is, we'll solve intelligence
and then the intelligence will solve climate change.
That's a typical Silicon Valley thing to say.
It sounds great and you get rid of it in the New York Times, but really to me, logistics
chains and supply chains are much more exciting and interesting and important for human life
and healthcare.
And it's not that the AI is going to solve healthcare.
It's us designing really good systems with good data science principles and economic
principles.
So I think I've said all this, mimicry is just not a good way to think about the implications
of collectives.
Autonomy is also maybe a losery.
And so there might be new forms of collectives.
Okay.
So if you want to read a little bit more about this kind of philosophical ruminations, I
wrote an article, our official that the Revlon hasn't happened yet, three years ago, and
I still very much stand behind everything in there, even though we've had this kind of
upswing and surprising chat GBT abilities, this was like about where's the data come
from?
What's the provenance?
What is the bigger scope?
And all that.
And so if you want to read about that, and then there was a bunch of commentary by including
Emmanuel Candace by some luminaries and it was quite a lot of fun.
So and there was my response to those luminaries.
And then with some colleagues, mostly social scientists all down here, we wrote a paper
about two years ago called How AI Fails Is.
And it's less about the kind of economics perspective that I was pushing up above and
more about what are the implications for technology if you've got like autonomous systems being
designed by small numbers of people.
That kind of incentivizes entities like open AI, that they get vast amounts of money for
a small number of people, they build this thing, and it's not for everybody.
They control it.
And it was supposed to be open, it's no longer open.
And so this idea that AI is the future, it just has a natural tendency towards making
it be in the hands of small numbers of people.
And again, I think this article kind of gets into some of the social science reasons why
that's just really a bad idea.
And people pretend that it's not happening.
It's all open and all that, but that's a pretense, it's just not true.
So if we stop thinking about AI this way, I think it'll actually liberate us from that.
All right, so again, I've already sort of said this, but just to lean in a little bit
more, McCarthy had this imitative perspective.
It was a great aspiration and still remains one.
It's just not what's happened.
What really happened was more like IA, that's Doug Engelbart there who kind of talked about
technology, augment our intelligence.
And for certain, it has.
The search engine has augmented my intelligence more than just about any other piece of technology
that I can think of, in addition to everybody's intelligence.
And then this third bullet is kind of what I think is a better description of what's
really emerging.
It looks kind of like Internet of Things.
They've got all these little devices around, they all send data around, and decisions are
being made.
It's all delocalized and everything.
But Internet of Things was a little too computer sciencey.
It wasn't thinking about the data and the inferences and the predictions and the people.
It was just about put things on the Internet.
But anyway, that is still the right spirit, and I think this is really what's happened.
Even like the pandemic response of the planet.
That was a engineering system that sort of didn't work okay, but we could do better.
Now, if you go to an ML person or an AI person and say, okay, aren't you guys thinking about
this?
Is it all this classical AI stuff?
And they say, no, no, no.
We work on this.
Here's, for example, federated learning.
It's decentralized learning.
So you have a server up there, and they're collecting data from a bunch of edge devices,
and then they're analyzing the data centrally, and we're worried about privacy and all that.
So we got the social stuff.
This is our, we handled all the social stuff.
All right.
Now, I'm being a little bit, again, cartoonish here.
But at terminology of federated learning, a number of groups were working on it, but
it's a Google patented, and not patented, but it's a Google terminology, because Google
wanted to collect a lot of data for their speech engines.
And so everybody has cell phones and is talking on their phones.
Let's just collect a lot of data from that.
Let's worry about the compression.
Let's get the gradients back cheaply.
Let's also do some differential privacy, and that's the technical problem.
If we solve that, wow.
But what's missing in this picture?
All right.
Well, I'm going to give some examples of what's missing to make it more clear.
But what's missing is that these are actual humans here, and they have their own values
and goals and aspirations, and they want to join this collective for some reason.
They don't want to just be assumed that they are in the collective because they want Google
to build a bitter speech model.
Okay.
So the nodes are often people, and they value their data.
And by data, I don't just mean where I went today and what was around me and all that.
I mean, things I created, works of art, things I wrote, songs I wrote, et cetera, et cetera.
That's my data.
Stuff that's on the internet now that's being exploited by other companies, and I've lost
all value.
That's wrong.
All right.
So we need to talk about cost and benefits of these decentralized paradigms where learning
is involved.
So we need learning to wear mechanisms, and mechanisms that we're learning.
Mechanism is an economics terminology, and I want to get into that.
So I'm going to give some more kind of industrially, real-world examples, but as an academic, I
needed to kind of think a little bit about what's happening academically.
Are we kind of a set up for this emerging discipline, whatever you want to call it.
And I'm not sort of sure we are.
So the three disciplines, and it's not really the disciplines, it's the styles of thinking
that I think are most important here, and I don't want to exclude anybody, but computer
science certainly, the algorithms, the networks, and so on, statistics, and economics.
Just to say there are pair-wise interactions among these fields for quite some time.
Computer science meets statistics, that is machine learning.
In fact, I would argue machine learning is just statistics with kind of a computer science
way of thinking.
Every time I see a new idea in machine learning, I know that it already exists in statistics,
and I tell people that.
They get mad at me, but eventually it kind of...
And there's lots of ideas and statistics they don't yet know about, too.
I could give lots of examples, but I won't.
Statistics meets economics, that's econometrics, and I've got Hito and others in the audience
who are masters of that.
Well it's great, but it's kind of about measuring the economy.
That's what the main goal has been, doing the causal inference to measure the economy.
And it's less about algorithms and mechanisms and engineering kind of thing, artifacts.
So it's had its important role, but it's missing that third leg.
In economics meets computer science, that's called algorithmic game theory.
That emerged 15, 20 years ago.
It's very important field, study of auctions and combinatorial auctions and how they behave
and incentives and all that.
What's missing there is they have no statistics.
They don't worry about gathering data and changing the preferences and learning them
from as part of the auction and all that.
So all three of these pairwise things exist, but they're critically missing the third leg.
Now the interesting thing is if you go into an industry, and I spend a day a week at Amazon,
and you look at any real world problem they are studying, like how do we provision, how
do we interface with third party sellers, blah, blah, blah, there's always all three
disciplines around the table.
And just to add, there are always operations research people who already have kind of ingested
all three disciplines, just to say, and control theorists and mathematicians and so on.
So I don't mean to exclude anybody, but it's never one of those perspectives alone.
That kills you if you just have one of those perspectives.
You need all three.
All right, here's a real world example that I've been involved in.
So I'm a musician, I just end up being an academic.
And I met up, I have a friend, Steve Stout.
Someone introduced me at some point.
Steve is a legendary producer, entrepreneur, well known in the hip hop and the Latin world
and so on.
And he and I kind of came together on this idea of modern data, modern systems, platforms
should not just be about taking streaming bits.
Music shouldn't just be about streaming.
It should be about creating two and three-way markets.
And so the idea that we originally sat down and talked about, and Steve is the CEO of
now a company that has taken this and made it real.
It's called UnitedMasters.com, or United Masters is the company.
Basically provides a three-way market.
So if you make music and now you can sign up with United Masters, they give you a record
company in your pocket, you're able to kind of produce songs on your cell phone and upload
them to United Masters and then they connect that to a market on the other side.
So in particular, Steve has gone to the NBA.
The NBA used to be streaming music from the record companies and they would pay the record
companies a royalty and they might give some money back to Beyonce or whatever.
But most musicians are not the big famous ones.
In fact, if you look at the data, if you do some actual data science, today 95% of the
songs being listened to in the United States played by people you've never heard of and
they're probably between 16 and 20 years old and the song was probably recorded in the
last six months.
So everybody thinks we're all listening to the Beatles and Madonna or whatever.
It's just not true.
All right, so you think, wow, there's this wonderful market that's been created because
of the ability to stream music and you'd be wrong because it's not a market.
No one's making money.
All the 16 to 20 year olds are not making any money off of this.
They do it for a few years and then they disappear.
So well, what Steve has done is by creating our masters is that a musician signs up and
now there's 3 million young musicians signed up on the platform.
And if you now go to the NBA website and you watch a video, there'll be some music behind
it, that music is streamed from United Masters.
And when every time it's streamed, the musician gets paid.
It's their actual two-way market.
And it's in fact a three-way market because it's got the NBA, it's got the listener,
which is you and me, and it's got the person who made the music.
And now all kinds of, I could give a longer talk about that, but all kinds of other market
sort of forces are starting to come to play.
People are reaching out to musicians and partnering with them.
Shows are being made.
People are playing at weddings.
There's 3 million people who now have access to a steady income stream.
So this is a sense in which AI can create jobs.
3 million people have access now to a possible job.
And these are 16 to 20-year-olds in the inner city, just to say, this is quite important.
And that's just in the US.
This can be done in every country around the world.
And entrepreneurs thinking about a new company, instead of thinking about how do I steal some
bits from somebody and then sell them, should think about how do I create a two-way market.
And I just help the market get going.
You could do this for art.
You could do this for works of, you know, scholarly works.
You could do this for travel information, all kinds of things.
You can start to think more about markets.
Okay, so that was the first half of my talk.
That was kind of why do I work on what I'm working on, okay?
And so hopefully you get a little bit more of the picture.
It really is, in some sense, economics and mechanisms and, you know, networks and all
that.
But, you know, with all due respect, those fields didn't have enough of a statistics
and learning perspective.
They assumed a lot of things were already known and you get certain curves that cross.
But they didn't kind of just adapt the market as you went and use large data sets to inform
it and have recommendator systems.
You don't see economics talking about recommender systems.
Recommender systems are the way that social knowledge gets used and exploited among groups
of people.
So anyway, when you start thinking about what are the new problems that are going to emerge
if you put these three axes together, it's really quite exciting.
So in machine learning and statistics, we're really good about talking about optima.
We can find optima in hundreds of thousands of dimensions even if they're saddle points
and we can guarantee a rate and prove theorems about it and we're really, you know, we're
really good at that.
But in economics, you don't often find optima.
You find equilibria.
And moreover, the equilibria are rarely just stationary.
They're moving around and you need to follow them.
And so you need to talk about the dynamics.
And so now there's topological issues and dynamical systems issues and stochastic process
issues all merged together.
And so there are algorithms, you know, gradient descent does not work for finding equilibria,
but extra gradient does work and so on.
There's a whole emerging, it's fixed point theory.
So most of these ideas go back to the 30s and 40s, but they have been forgotten.
But fixed point theory in hundreds of thousands of dimensions with stochastics, that's something
we can start talking about and do and prove rates and, you know, get really new algorithms.
And there are people doing that now.
Exploration, exploitation, incentives in multi-way markets.
Those are words that usually don't come into the market perspective.
How do I exploit?
How do I explore?
And how do I put that together with incentives?
I'm going to talk about some of the rest of these, but let me just sort of highlight.
These are mostly words you will not see on a machine learning person's talk or AI person's
talk.
They will talk about trust maybe or fairness or privacy, that's all good.
Those are social concepts.
But they don't embed it in a fuller, what are the underlying foundational principles
that make it fair or make it private or make it valuable to people.
They just want to kind of stamp privacy or, you know, or fairness on it and that's enough.
So let's try to think about what are these underlying concepts.
And let me just say that I've loved learning all this economics.
I had learned a lot of statistics and I've eventually learned some computer science.
And that was fun, but learning economics has been particularly fun.
And it's maybe because I already knew the math and I could just kind of go through the
books really fast.
But you know, this notion of incentives and really thinking about asymmetries and decentralized,
I really get that out of economics in ways I never got from any other field.
So I'm having a lot of fun here and I'm realizing that if I'd gone back to the 1950s and I'd
hung out with David Blackwell and Von Neumann and others that they were doing all this.
This was kind of the spirit of the era.
And operations research emerged in that era, kind of bringing it all together.
And somehow that all got kind of forgotten.
We got all buried into building certain kind of systems or doing certain kind of data analysis
or, you know, measuring certain kind of linear models and we forgot about the overall picture.
Okay, so these blue ones are the ones I'm going to kind of use now as vignettes and
the rest of my talk.
And so this is, given this is an evening talk, I don't want to make this a highly technical
academic talk.
There are archive papers on all this with theorems and so on and so forth.
But I do want to give the sense of what's the problem and what is the theorem, all right,
and what is the consequence of that.
Okay, so I'm going to give enough of that to highlight some of these issues.
So I picked these three to talk about in some order.
I forget which order.
Okay, so here's perhaps my favorite one.
I get to recognize two Stanford people.
Stephen was a student with Emanuel and joined my group two years ago, three maybe.
You know, fabulous intellect.
Michael, I actually don't, we've only, because of the pandemic, met online, but
he is a Stanford person.
And then Jake was a student with me.
He's now a postdoc with one of Emanuel's ex-students, Serena Fogelbarber.
So a lot of nice connectivity there.
Okay, with all due apology to the economists in the room,
I'm going to say a little bit about incentives.
There's a kind of general theory of incentives.
There's books on it.
And roughly speaking, there's kind of three branches to it.
There's auction theory that you all know about.
There's matching markets, and there's contract theory.
So contract theory is maybe the less well-known outside of economics, but
you all know about it because you experience it daily.
It's where agents provide, possess private information, and
there's a principal who wants to incentivize to do something with that
private information.
So why does this happen?
Well, you know, the boss wants to get the employees to do something.
And it's not just because the boss would do it themselves, but
you know, they have to get the employees to do it.
The boss would know how to do it.
The employees have local information.
They're smarter.
They may, if they're incentivized, they'll do even better work and so on.
And now the boss has got to kind of offer them incentives so
that they'll actually do the labor.
So this came up in economics, sort of after General Equilibrium Theory,
which was very symmetric, Nash Equilibria and everything is very symmetric.
This recognized that real life is full of asymmetries.
There's someone trying to get someone else to do something and
that person has power because they know something that it's not known upstairs.
All right, so you know about it because you've all, for example, you travel.
And you probably have wondered why aren't there, why is this so complicated?
Why is there not one fare for every seat on the airplane?
Like there is for a movie theater.
All right, and you all know the answer kind of, right?
Because there's different willingness to pay in the population.
So a business class traveler or a business traveler, not a business,
traveler, maybe the company's paying so they could care less what the fare is.
Or maybe they're really urgently needing to get from one place to another.
They have high willingness to pay.
And there's a lot of other people who don't have high willingness to pay.
They could wait till tomorrow, you know, and so on.
So the airlines really in the 80s realized that they could start to price discriminate.
They could try to figure out who had higher wills to pay and
charge them higher and who had lower wills to pay and charge them less.
And fill the airplane and get a blend of both kinds.
And you've got to be clever to do this, right?
And so what you do, if you set a single price, that's not going to work.
And if you try to screen for people, like, you know,
look at somebody wearing a suit and tie, you say, I'm going to charge you more.
Well, that person's going to the next time show up in jeans.
All right, so people are doing this all the time.
They're aware.
They're gaming the system.
And you've got to think this through.
All right, so you know the answer.
What you do is you provide a menu of options.
You provide a service and you provide a price.
And a service and a price.
And everybody gets the same menu, right?
Now what is this menu for the airline?
Well, there's this class called business class and the students don't know about
this yet, but eventually they'll learn about it.
Where you get a little glass of red wine and you get to be first in line and
be all proud of yourself and you get a little bit bigger chair.
And people will pay $1,000 more for that.
It's amazing, right?
Now, only class that actually makes money, right?
But the marginal cost of putting people on airplanes is sort of zero, all right?
So you want to fill the rest of the airplane, all right?
So amazingly, there are people in the back who don't want to spend $1,000 for
a little glass of red wine.
And they feel very good about themselves because they didn't spend all that money
and they're still on the airplane.
So everybody's happy.
That's what's called social welfare.
And the plane is full.
That's what's called revenue.
Okay, so you can make mathematics out of all that.
So you get the usual crossing curves and all that.
They're just not the same crossing curves as in general equilibrium theory.
They're a different set of things.
But every one of those texts says we have missing information.
We're going to assume there's some probability distribution and
we're going to call the whole thing Bayesian.
Now, as a statistician, I look at it and say, wow, Bayesian, it's not Bayesian.
There's a distribution on unknown quantities.
That's all.
There's no updating, there's no learning, there's none of the above, okay?
All right, so wow, wonderful opportunity.
We should work on this.
And we have.
Okay, so you all know about clinical trials.
Costs tens of millions of dollars a year to run clinical trials in any particular
therapeutic area.
You all know about it for vaccines.
It's amazingly expensive and it's amazingly important.
And if you don't do it at the right scale, you'll make big mistakes.
You all know this.
All right, so you would imagine that the FDA does a great job of this.
And in some level they do.
They're very good statisticians.
But they're not good at being the economics.
All right, so this really should be thought as a contract theory problem.
The FDA is a principle and they're trying to decide what drugs go to market.
But they only have partial knowledge about the drug candidates, okay?
Where do the drug candidates come from?
They come from the pharmaceutical companies.
Pharmaceutical companies know something internally about some candidate.
They're about ready to send up to the FDA.
Maybe they know they put their best engineers on it.
Maybe they've had experience with it.
Maybe a little internal testing, so on and so forth, all right?
The FDA is now getting all these candidates and
they would like to say, pharmaceutical company,
that candidate you just sent me, how good is that candidate?
Well, the pharmaceutical company does not want to reveal.
Because the FDA, if they're told it's not a good candidate,
they'll put yet more, they'll ensure there's no false positive.
They'll put yet more clinical trial money into it.
Where if they think it's a really good candidate, they won't.
And also the license they will get will be titrated to risk.
All right, so the companies are incentivized to not say.
All right, but that's a problem.
All right, so now let's think about the actual paradigm.
What is the FDA doing?
Well, they're being statisticians, a frequentist statistician.
So here's a little Naaman Pearson kind of setup.
A bad drug, theta equals zero, doesn't mean that it hurts people,
because they definitely screen for that.
It just means it has no effect, all right?
And there are tons of drugs on the market that have no effect,
for better or for worse.
And they have a type one error of say 0.05, it's actually more like 0.01,
but they set up a classifier that achieves that.
And then for the good drugs that are actually having an effect,
they want a high power, so 0.8 is a kind of a standard number for that.
Is that a good protocol?
Well, it's optimal, it's the Naaman Pearson test.
So yeah, of course, it's great.
But is it a good protocol?
And the answer is no.
So let's do a little thought experiment here.
In situations where there's a small profit to be made,
it costs $20 million to run the trial.
But if you're approved, let's suppose you would make 200 million.
So this would be for a niche drug of some kind.
And so the CEO can do a little calculation, as can the FDA,
conditioning on theta equals zero.
Now no one knows if theta is zero or not, so this is a counterfactual.
But thinking conceptually, theta equals zero, what's my expected profit?
Well, you can put all those numbers together and you get minus 10 million.
All right, so the CEO looks at that number and they say,
only send candidates up to the FDA if you're really pretty sure it's a good drug.
That it's going to get passed because it's a good drug.
Don't hope for a false positive.
We'll go out of business.
That's great.
Now the FDA is mostly getting good drugs and they have a good screening procedure.
So everything that's getting through is looking good.
If that were real life, that'd be great, but here's more like real life.
So you have $20 million to run the trial and if you're approved,
you could make 2 billion.
So this would be like ibuprofen or something.
So this is more common.
And now the CEO could do the same exact calculation.
If it was the case that theta is equal to zero,
my expected profit would be 80 million.
So now the CEO is very incentivized to send as many candidates as they can to the FDA.
And the FDA will get flooded and they do get flooded.
And they will do these tests and there will be some false positives.
And these things will go to market.
They don't hurt anybody, but they just don't have any effect.
And people will make money and then eventually that changes.
So this is broken.
And it's just broken because it's not being thought of as a contract theory problem.
All right, so we have now lured on this.
We have a paper and we have an idea we call Statistical Contract Theory.
And so here is the protocol.
There are four steps to it.
It's only step three, which is new.
The other three are standard contract theory.
So an agent comes to this contract and they opt in or they just decide to walk away.
So the drug company comes and they just looked at it and say, no, I'm not interested.
Or if they opt in, they have to pay a reservation price R, say 20 million.
And then they get to select a payout function from a menu.
And I'm going to say more about what that means here in a moment.
But it's going to be a function from observed the clinical trial to the amount you get to licensed for.
And we're going to design the menu.
That's going to be our goal as economical statisticians.
Then we do a statistical trial, which yields a random variable, Z, coming from P of theta.
Theta is the true theta in nature because we're getting data from the real world.
No one knows theta, but we get data from P of theta.
And then there's the payoff.
So agent gets payoff F of Z.
They were the ones who selected the payout function, so they get paid that amount they selected.
And the principal receives a utility, which is a function of F of Z because they have to pay that.
And theta, because the FDA, if they make lots of approvals of not so good drugs,
they'll eventually look bad, and so their utility should reflect that.
Agents in this setting need to maximize their payoff.
Their best response is simply to take the arg max of the expectation under this data of the payoff.
That's what they want to maximize.
So that's pretty clear what an agent should be doing in this paradigm.
All right, now if you're going to do economics together with statistics,
the key thing you have to think about is incentive alignment.
Am I doing a situation where the incentives or what I want to achieve is aligned with people's interest?
All right, so here's a way to set that up.
For the null agents, those who have the null candidates,
it should be the case that the utility of the principal is decreasing in F of Z, okay?
Whereas for the non-null agents, for a good drug, the utility should be increasing in F of Z, okay?
So it's kind of obvious.
So, you know, in English, the principal wants to attract as transact as much as possible with the good agents,
the ones that have a good drug.
All right, so now the definition is that a menu of these options is incentive aligned.
If it is the case for all of the null drugs, the expectation under the null of the difference
of the payout and the reservation price is less than or equal to zero.
If that weren't true, then these companies just make money for free, okay?
So you need to have that be the case, so the principal would be happy with this.
The P less than or equal to 0.05 protocol that we're used to from statistics is not incentive aligned.
That's simple to see.
Okay. All right, so now we have a theorem, which is right down at the bottom there,
which is that it turns out that a contract is incentive aligned if and only if,
this is a characterization, all of the payout functions are E values, right?
So what's an E value?
Well, it's like a P value kind of.
It's a statistical measure of evidence, but
whereas a P value is a tail probability under the null,
the probability of under the null hypothesis being more extreme than the observed data.
That's a P value.
And E value is under the null hypothesis.
The expectation of this E value is less than or equal to 1, okay?
It looks a little bit like a martingale, a super martingale, and in fact is the more general story is these are non-negative super martingales.
And because they're martingales, they kind of compose nicely.
You can stop them because of stopping theorems.
They just are a nicer measure of statistical evidence.
Whereas P values don't compose.
You can't stop them.
They just have all these troubles.
So this is a neat result, which is that this concept from theory of contracts
is exactly the same concept as E values in statistics.
And moreover, we have a result, which I don't think I have a slide on it.
Nope.
That if we now want to do, how do you actually design a menu and get,
say, a maxi min menu, the maximal overall theta of the minimum risk.
It turns out to be characterized by taking all possible E values.
That's your menu.
So if a computational regime might want to do that, or for interpretability reasons,
but that's another if and only of theorem.
Okay, so I'm going to move on.
We're now rolling this out in various domains of actually designing menus and
contracts, but we have this guide.
We now know how to design the optimal contract.
We know what, we use E values, and we know lots of E values.
There's a lot of literature on non-negative super martingales or E values and so on.
So we'll be doing that.
And I'll just say we've done this in particular in the federated learning
domain.
This is now just, again, the picture of federated learning, but
now with an incentive structure.
So we're able to design an incentive compatible mechanism that incentivizes
agents at the edge to contribute data.
And in particular, this handles a problem that has been recognized in
literature, which is a free writing problem.
If I have some data to send up, but sitting next to me there is a manual, and
he has data to send, and I know that his data is pretty much the same as mine.
I'm going to watch him send the data, and I know I don't have to.
Pre-writing.
This paradigm incentivizes against free writing.
Professor, just one small clarification.
Yeah.
Is this based on the assumption that we're talking about home economics in terms
of very rational and certain things?
It's a good question.
I was hoping that was going to come up later about, it's all this rational
economic stuff.
No, and sort of the behavioral economics here is kind of coming in the fact that
we're gathering data.
So all these distributions are informed by data.
And if we just write down the utility, that's only the assumption we have to
make, is that we agree that you want to maximize that.
And that's usually not so strange.
And then the data informs it.
We don't make a distributional assumption about the data.
So I can get into that a little bit longer, but
behavioral economics is very much part of this agenda.
But it's not just that it's broken and we think about the psychology of it.
Well, no, we collect data, and data is coming from real people.
So we already have a little bit of a help there.
So hopefully that partially answers your question.
Anyway, if you're interested in this application, we have a paper on that and
we're continuing on with that.
I got two more vignettes, I think, and I'm just going to go a little more quickly on
these. I just want to give you a flavor of these.
Classification is the big killer app in machine learning.
Classify, yes or no, good or bad, blah, blah, blah.
But if you do this in domains where there are strategic agents,
you get something called strategic classification.
So this is a work with Tiana Zernich, who's still a student with me and
will be joining Emmanuel's group as a postdoc.
He and I shuttle these superstar people back and forth.
And then Eric is now a professor at Caltech.
All right, so here's a little picture to suggest this.
Health insurance, the health insurance company has got to do a classification
problem. I fill out a form, they have to decide whether to give me insurance or not.
They're going to ask me, how much do you exercise?
I'm going to say a lot.
How much do you drink of wine?
Very little, so on and so forth.
Now if it's implausible, they'll kind of see that.
But you make it plausible.
They know that, however, so they're not going to make it so easy for you.
So they're going to ask questions like, would you be willing to have us look at
your cell phone accelerometer for one day?
Just opt in, you don't have to, but are you willing to do that?
You say, sure.
And now if my cell phone moves around a lot during that, it shows I'm very active.
If it sits in one place all day, I'm not so active.
They would use that as data.
So someone went out to build a device,
then you put your cell phone on the device and it moves around all day.
So this is the kind of problem that arises.
An economist are very much aware of this.
They call this Goodhart's Law.
If you set up a poverty index score at some year, this was in Columbia in 1994.
It looks very good, very Gaussian and all that.
By 2003, people have discovered that if they move just a little bit left of there,
they get more better housing.
So everyone cheated a little bit so they could move over.
And so the poverty index score has now been ruined.
But this is real life.
This is what people really will do, and they should.
Why not?
It's not an ethical issue.
Ethics is sometimes used a little bit too easily here.
So the real problem is that when you do learning,
you rarely have just collected data set and analyze it.
In the real world, you have to say, where's the data come from?
If it's people supplying the data, are they aware of what the outcome is?
Do they have some bets that's interested in it?
Probably they do, because if not, why would they really be engaged in this whole exercise?
All right, so now we have a Stackelberg game.
It's a game theory setting, which is sequential.
I send some data up, and the central decision maker, say the bank,
is trying to decide about loans, collects a lot of data.
They build a model that predicts whether I should get a loan or not.
And then that starts to make some decisions.
People start to realize what's happening.
Maybe the bank has got to reveal by regulatory reasons,
I'm using logistic regression or something.
People realize that, and they say, okay, the next time they send the data,
they're going to alter their data.
And that goes back and forth, and you want to ask what equilibria rise here.
We're not trying to optimize any likelihood, it's an equilibrium problem.
Okay, so we have studied this as a Stackelberg game,
which is the appropriate concept in game theory.
Classically, in a Stackelberg game, you have a leader and you have a follower.
Classically, the decision maker would be thought of as the leader here.
They run the whole show, and agents are the follower.
You can show in that situation, in this setup,
that the leader gets high utility and the followers get low utility, just to say.
So it seems reasonable.
But if that's an analysis you could do in a synchronous situation,
where there's a model built, data's gathered.
Model built, data gathered, all synchronized.
The real world is no synchronization.
Why should people wait till, there's no synchronization between the central model
and me sending up data?
Okay, so you could start to think about analyzing different scenarios,
where there's different kinds of timescales.
So here's one where the modeler goes slowly, only updating every once in a while,
and the streets you gain doesn't send data much more rapidly.
So does this arise in real life?
Sure, this is, for example, like college admissions.
The college is gathering all these applicants, and they have all this data.
They're not gonna adjust their policy after every applicant.
They'll do it every couple of years or so, and
they'll publish it and all, for obvious social reasons.
So that's a real scenario.
What about the other way around?
Where the central agent updates very, very rapidly, and agents are much more slow?
Well, that happens all the time too, that's like YouTube.
Every time someone clicks, they update a model in principle, okay?
So these are different scenarios, and so what happens here?
So you can analyze this as now you do the game theory.
So we were able to prove a theorem that shows, first of all,
that in either order of play, you get an equilibrium.
It's not so hard to see that and analyze that.
Much more surprisingly, is that in these statistical settings,
where it's a data analysis problem, not just an arbitrary Stackelberg game,
it turns out that when the decision maker is a follower, and
the strategic agents are the leader, the kind of flipped around version,
the strategic agents have higher utility than before.
That makes some sense.
But also, the decision maker has higher utility.
It's a rare example in game theory of a win-win.
Going in the order where the strategic agent is a one's going fast,
that leads to higher utility for both parties.
So that's not a true fact about game theory in general, but
it's a true fact about statistical game theory.
These statistical modeling exercises for
generalized linear models, just to say.
I'm gonna skip this little part here,
just I like to show pictures of my students.
So there's Lydia and Horia, and just say this,
I'm gonna show you really quick the slides.
But it's a cute little paper where you bring together bandits from machine
learning and matching markets from economics.
And let me just show you a picture.
Here's a learner in a bandit problem.
They're trying to find out which of the set of options is the best,
gives the highest reward.
And they're algorithms like upper confidence bound,
that help you guide you towards diminishing your uncertainty and
also picking the optimal arm.
So we asked the question about, what if you put this in a market setting?
So I don't just have one decision maker, I've got a two sided market.
And so in particular, I might have two decision makers who are selecting
actions from the other side of the market.
And there's preferences on both sides.
And so you ask questions like, what if both of the agents select the same action?
And so we model this as congestion that one of them gets the reward,
the other gets no reward at all.
And who gets the reward?
Well, that depends on the preferences on the right side of the market.
So both sides are learning about each other.
And so again, you can do the mathematics here, and
it turns out to be pretty interesting.
What you're really asking is, if there's competition in a bandit situation,
does that make the regret higher or better?
What does competition do for
the learning process of a person trying to learn the best action?
Okay, and long story short, we did a, here's a theory.
Here's a regret bound, and so this is more for the experts.
But the regret is as a function of time, which is n, logarithmic and n.
So that's an optimal result from classical bandit theory.
So that is still true.
Competition does not hurt your rate of learning.
There's a denominator term though, which is a constant,
which is a gap between the preferences of nearby agents.
So if there's competition and you have a small gap between me and
somebody else, we start to compete more.
And that gives us a higher regret, but it's only a constant.
All right, so I put that up there just to sort of show you that it's kind of
really fun things to do with simple learning algorithms,
explore exploit type, and simple matching market kind of ideas.
And this was motivated by this kind of restaurant setting where
100,000 of us are out looking for a restaurant in Shanghai.
There's 100,000 restaurants, and we're all trying things out as we go and
getting rewards or not, and both sides of the market have some preferences.
And how does that market clear?
That was our question.
All right, so last two weeks ago, I talked about this in this very room.
So I'm going to kind of go quickly, but
this is a very exciting project here that I want to spend five minutes on.
Similar collection of students, but also again, Stephen, who's a postdoc.
Anastasia, Stephen, Clara, and Tiana.
So this is really more about the statistics.
There's little economics here, but less.
This is more about how do we do things like use neural nets to do science,
just roughly speaking, okay?
So you all know about things like Alpha-fold, they will make huge numbers
of predictions of, say, these tertiary structure proteins.
Hundreds of millions of structures, whereas the hand labeled ones,
there's only hundreds of thousands of such sequences, all right?
So that was a problem that's now being revolutionized in biology.
So here's an example of someone in 2004 wrote a very important paper in nature,
studying the relationship between intrinsic disorder of proteins,
where things don't fold, they kind of are more strand-like.
And that turns out to be very important for, like, grid-like things.
And phosphorylation, which is an important part of it, and many pathways.
So they wanted to ask, is there an association between those two notions?
With the parts of the protein in its order, they tend to be more phosphorylated or not.
But they really couldn't test it, and now you go forward to 2022.
Instead of this small amount of data we had back in 2004,
now you have vast amounts of Alpha-fold labeled data.
It's not really data, it's predictions, but they're good predictions.
So why not throw them in as if they were data, all right?
So someone wrote a paper, 2022, doing that.
And so they wanted to quantify this odds ratio,
probability of intrinsically disordered given phosphorylation.
And kind of amazingly, they didn't even use any of the hand label,
the gold standard data, because they had so much of this other stuff,
they just threw it all in, because it's such a good predictor, why not?
But as a statistician, you know better, right?
Even if it's very, very accurate at making predictions,
that doesn't mean the inferences you make are any good.
All right, so I think this one picture I'm about to show, so there's the mayors.
This picture is probably the end of my talk, really,
and I'll just kind of scroll through a couple more.
So let me take a moment on this one.
Our statistic here is this odds ratio.
We'd like to know if there's an association or not.
You've all taken elementary statistics.
We have to find whether it's significantly different from one.
One would be no association, bigger is an association.
We did a Monte Carlo version of this where we, in the set of label data,
we actually got the true odds ratio, that's the dotted line there.
And then we redid the entire experiment with alpha fold output using the predictions.
Okay, so what are we doing here?
That gold region right there is a confidence interval.
And it's based on taking all of the alpha fold predictions and treating them as real, okay?
And from those, you form a confidence interval on this odds ratio.
And that's an elementary statistics exercise to do that, all right?
That confidence interval is tiny.
That looks really good, because you have all this data.
It's not real data, but it looks really good.
You're very, very confident.
You're just dead wrong, all right?
The statisticians in the room, Art, will say, why'd you do that?
Just we know how to do confidence intervals.
Just use the gold standard data.
Don't trust these wild machine learning predictions.
And Art, I would do that too.
That's what my first thought would be.
That gives you the gray region, so it covers the truth, as it was asserted to be, all right?
But it also covers one.
So it doesn't allow you to include, there's an actual association, all right?
So the new method gets the best of both worlds, this prediction powered inference.
It forms a confidence interval, which is guaranteed to cover the truth, with 95% probability.
But it's also much smaller than the, it uses the predictions, but it corrects them, all right?
And I think the most fun thing to show you, I'm going to skip that slide,
is just the examples that we've been applying this to, and we have a paper that does these.
Here's voting, here's a ballot, here's a messed up ballot.
So this was a San Francisco election.
People use computer vision to look at all the ballots and make a prediction,
whether it was yes or no, all right?
And now you can feed that in and do an eight analysis on that.
And you can see the little gold region there, it's a little small confidence interval,
it's just missing the truth.
And again, I don't know why some things are not coming out here.
Our new interval is the green one, and then there's a missing, a classical one there that's much
larger, but again, covers the truth.
This is counting spiral galaxies, you know, there's some hand labeled,
here's the spiral galaxy, here's not.
And again, you can see the small confidence interval,
if you use the computer vision algorithm, but it's not covering the truth.
And again, we cover the truth.
And I think this was the last one I wanted to show.
Yeah, here's a California census.
The estimate is a logistic regression coefficient of income when predicting
whether a person has private health insurance.
And there was a machine learning algorithm run on that.
You can see the tiny little confidence interval, it's very, very sure and dead wrong.
Okay, I hope this conveys, you all kind of knew this, that, you know,
very accurate machine learning models can still lead to completely wrong inferences.
Okay, I just don't think my machine learning colleagues get that, but it definitely can.
And so, but you can get the best of both worlds.
And I think I'm going to skip all the way to this last slide here and
just show you roughly how this happens.
It's kind of like a bias correction procedure, but it's not quite that.
All right, so there is a bias between the predicted parameter using all the predictive data
and the true parameter, theta star.
That bias is a population level quantity.
If you had the whole population, you could just write it down as a number, right?
There are ways to estimate bias, like the bootstrap.
And you could take that estimate and correct your estimate.
That's done a lot.
We have a different idea, which is that we take that quantity, that bias,
or we call it in general rectifier.
And we don't just estimate it, we'd put a confidence interval on it.
We get all the possible values of that correction.
Now we take the original predictive quantity, which is wrong, and
we correct it with all the possible corrections.
That leads to that green region there, which is a confidence interval on the
corrected predictions.
All right, and then our theorem at the very bottom of the page shows that we
were good statisticians.
The probability that this new confidence interval covers the truth is bigger than
or equal to 1 minus alpha.
And it's much, much smaller than if you've forgotten all the predictions altogether.
Okay, so I put that up there just at the end of an economics talk.
There's more statistics, but I just think many people in the room are already
thinking about this and working on it.
It is one of the critical issues.
If you're going to do science with machine learning, you've got to face this.
You've got to be a good statistician while exploiting the advantages of the
machine learning paradigm.
And I think this is a step towards doing that.
All right, so that's my last slide, and that's the slide I had up earlier.
I just wanted to kind of remind you of the big picture of the more provocative
issues.
This to me has kind of been a no-brainer.
I just, what's happening this era?
Well, it's just statistics and computer science and econ and all.
And we're being good engineers.
We're trying to deliver artifacts that will help humans and how to do that well,
like previous generations of engineers.
And this kind of Silicon Valley hype thing of, we've discovered this great
thing called AI, and it suddenly, we've got to worry about all the things that's
going to happen because of that.
It just, to me, wrong.
Thank you.
I hope, yeah, I knew.
I shouldn't have picked on you, Art.
You have a better idea?
Well, I have a paper where there's an island of really high quality gold
standard data and an ocean of data where you're not quite sure of the quality.
And then we sort of do a shrinkage of one onto the other.
But we just got point estimates so we didn't get a confidence interval.
Yeah.
I mean, so this is a little bit like the semi-supervised paradigm.
So we have an ocean of labeled data and, sorry, an ocean.
We have a small pool of labeled data and an ocean of unlabeled data.
The machine learning person says, oh, yeah, that's similar to supervised.
No.
We're using the unlabeled data to find a confidence interval to correct the, sorry,
we're using the, got it wrong.
The labeled data to find a confidence interval to correct the unlabeled data and
get a confidence interval out of the whole thing.
But yes, I think I was aware of that work of yours.
And let me just say this is not, none of this is ever new.
Statisticians in kind of small data census work did things like this.
And semi-parametric statisticians did some too.
So this is, again, there's always somebody who did it probably in the 1950s in
statistics, or Art, or Brad Efron or what, it's always, any other?
Yes, there's two over here.
As you pointed out, there's been a lot of attention around uncertainty,
quantification, and similar, you know, similar moves in that direction lately in
the machine learning space, which is great.
What does that mean for the future of applied Bayesian statistics and, you know,
MCMC, that sort of thing?
Given that it's computationally less tractable than a lot of modern machine
learning training techniques, is there still a place for it?
Okay, yeah, good, thank you for asking.
Yeah, no, I tend to be a Bayesian, as with most statisticians, sometimes I'm a
Bayesian, sometimes I'm not.
And I'm a Bayesian when I'm working with a scientist over two or three years.
Because I'm trying to kind of get out the knowledge that they have and use it.
All right, and that's a prior.
And so why would I not do that if I'm going to work with them a long time?
I'm a frequentist when I'm trying to produce a piece of software that
people all over the world will use.
Because I'm not going to work with them and get the prior.
I'm just going to put it out there and I want to put a stamp certificate that 99%
of the time they're going to work for whoever uses it.
That's the two perspectives I have.
Now, a little more nuance to that.
Bayesian way to structure models is very nice.
You get hierarchies, you get sharing of shrinkage, social network kind of things
or naturally Bayesian.
I think that Brad Efron, who has been the luminary in statistics here at
Stanford but worldwide, had it right.
Which is that you often will go into a problem, you think Bayesian.
You start to structure the model, think about what I could know,
what would be together with what, and then you become frequentist.
You say, I'm going to do empirical Bayes.
I'm not going to just run the Bayesian MCMC paradigm.
I'm going to at some point just say, okay, there's some things I can estimate.
I can plug them in at the Bayesian procedure and
then I'll get the benefit of both worlds.
Now, I totally agree.
So a lot of the things you saw here have a kind of an empirical Bayes interpretation.
And a lot of the, but it's true, the conformal things in the uncertainty
you're talking about don't necessarily, maybe a manual could correct me there.
But those are kind of pure hardcore frequentist at some level.
But I tend to, when I would use those in practice, I would probably have not just
one conformal predictor over here, I'd have another one over here, another one over
here, I would want to shrink them towards each other, I want to have them related.
Because in real domains, if you really start to scale,
the Bayesian way of thinking helps you immensely.
So that's funny, Bayesian frequentists do conflict, but
it's like wave particle duality.
It's kind of my metaphor, right?
Waves and particles are both correct, and they conflict a little bit.
But if you throw out one and just use the other one,
you're gonna do bad physics.
And same thing with statistics, yeah.
Professor, you were emphasizing the importance of forming collectives in solving
the problems.
And I'm very curious to know how you think about how those
collectives can actually be formed to pursue a goal.
Especially because, I mean, I don't know if a principle or
a platform is required to kind of create the market where agents can actually trust
that and cooperate.
Or do you actually feel like a decentralized kind of a network is possible?
That's a fantastic question, I'm delighted to have it.
And just for the young people in the room, I hope you see the questions like that
are kind of the thing of the era, and they're hard.
I don't have an answer to your question, it's gonna be the short answer.
The colleagues I had on that paper, the social science colleagues,
they talk a lot about new models for democracy.
And they emphasize that democracies tend to arise when you have multiple layers of
like bring 200 people together, get some consensus, take 200 people here,
get some consensus, and put the consensus together.
And form cities and countries and all that.
That's what humans have done throughout history.
And we've had this experiment now that we have this thing called Twitter.
And we're assuming that it's all good that all of us talk all the time.
Or that we all listen to one person.
And those are terrible ways to do democracy.
So there are experiments that have been underway for
quite some time for people like that.
Like those famous examples in Taiwan where they have a legislator,
which is using lots of data analysis together with kind of structured assemblies
of ways to kind of come to coherent decisions and to get consensus.
And Ireland has used this, and their latest this,
they kind of legalized abortion at some point, that's very hard to do in Ireland.
They did it partly because of these new assemblies, new structures.
So I love this, people thinking about out of the box of new mechanisms that
bring together visibility of, but it's still among relatively small numbers of
people, that's really critical.
And I think that the technologists who just built the YouTubes and
the Facebooks and all that, were trying to do this experiment on human beings.
So it was just destined to fail.
The big broadcast channels were terrible.
We want communities and we got to think about a structure of those.
So I don't have much more to say about that other than how do you form collectives
and support them and make them healthy and all that is hugely interesting and
important, and there are social scientists who spend their life doing this.
This is definitely not just a technology issue.
We need to both cooperate and listen and
have a dialogue with those kind of social scientists.
There's many others we should cooperate with, but
I think that's a particularly pregnant one.
Economics certainly talks about collaborative things.
There's cooperative game theory and how do coalitions form.
But it's a little bit dry, and maybe Hido can help me a little bit with kind of,
maybe there's more to it.
But it's a little bit about how do I do negotiation and
get the most money out of the deal I can and so on.
You need to line the incentives.
Yeah, or line with incentives and so on.
But that just means that we just haven't thought about it enough.
And for the young people in the room, wow, that's a great topic to think about.
How do I start to structure collaborative efforts in data-oriented ways?
So I think economists didn't have enough kind of,
they talk about communication signaling, but
they didn't really have enough data to kind of really signal interesting things,
and do it in adaptive interesting ways.
So let me just lean in again to this, there's a lot of young people in the room.
This is the most exciting era to be in.
The previous eras kind of gave us greaty to send and
gave us networks and all that and all these tools.
And now they threw them out there in the world and they kind of work and
they kind of don't.
We got better commerce, we got better transmission.
And we can sort of fix all those.
We can also think a lot more about, wow, new things, good things could happen if
we start to think in the right way.
And what problems are needed to do that?
Don't just work on self-driving cars and whatever, or
make Facebook advertisements better, work on problems that you believe
in, and there are plenty of them, but bring these two fields together though.
Don't just think of yourself as a system builder.
What up guy?
I don't know,
I don't know,
I think my qury just made a living.
Okay, thank you, bye.
I will just let you guys go and get off the car.
Bye.
