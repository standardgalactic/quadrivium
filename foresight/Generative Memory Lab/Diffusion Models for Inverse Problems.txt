Great. Yeah, so hi, I'm Hyunjin Chung. I'm a PhD student at bio-imaging and signal
processing and learning lab at KAIST Korea. I'm honored to give a talk in such a prestigious
group in Netherlands. And so thank you very much for having me here. So today I'll give a talk
mostly about diffusion models and how to use them to solve inverse problems in imaging,
focusing on a few recent papers that I wrote. So specifically it will be focused on base and
inference in the context of inverse problem solving. So I believe it will be of quite a
relevance to you. And I'm pretty sure that most of you are already familiar with diffusion models,
but some of you may not be familiar with inverse problems. So and since we have a rather small
group, I feel free to speak up with your microphone. I'm very sure that I'm going to miss
some chats. So I hope the talk will be as interactive as possible.
Yeah, so the talk will be structured in a bit of an odd way because we're going to first talk about
two closely related work in a reverse order. So the first part of the talk will be about a paper
named DPS, accepted to iClear recently. Then we will move backwards and talk about MCG,
which was supposed to be the main content of the talk today. And finally, if time allows,
I would also like to briefly touch the most recent work that applies these methods to more
advanced problems called blind inverse problems. So I'll just briefly cover the basic concepts
of diffusion models. I don't want to bore you too much, but I'll just speak in a briefly in
a score perspective. So what we do in diffusion models is we try to estimate the gradient of
the lock density with the neural network S of theta, which points to the high density most of the
distribution. In order to circumvent the intractable explicit score matching, you train your network
with denoising score matching, which boils down to essentially training a residual denoiser.
Once that is done, you can use the train score functions to sample from the distribution p of x
with, for example, Langevin MCMC. And another interesting view is that one can view the data
noising process as some linear forward SE, and the data generating process as the corresponding
reverse stochastic differential equation, where the drift function is governed by the score function.
Hence, when we want to sample data, you can discretize the reverse SDE and numerically
solve it using the pre-trained score function. On the other hand, here we are interested in
solving inverse problems. In the inverse problem setting, our aim is to recover the ground truth
x from the noisy measurements y obtained through some integral imaging system A.
And there will be some pollution of noise, and here, A, sorry, and the problem is naturally
opposed, which means that there exist infinitely many solutions to this problem,
meaning that given this noisy image, noisy blurred image of the leopard, there could exist
a lot of different feasible answers to the actual clean image. So in order to correctly specify
which one of the solutions is the one that we want, we need to specify the prior of the data
distribution, and in other words, how the images would actually look like in real world.
Examples of such inverse problems include in-painting and deep learning in the context
of low-level vision. They're also called image restoration problems. And in the context of
biomedical imaging, there could be compressing MRI, sparsive CT, and so on.
So we'll go over how we can solve such inverse problems with diffusion models.
So let's first consider the following measurements model. Now, given y, what we want is to sample
from the posterior distribution p of x given y. And using Bayes' rule, it's straightforward to see
that the gradient of the log posterior is the sum of gradient of the log likelihood
plus the score function. Here, gradient of the log likelihood in red gives us the information
about the measurement process. And the score function is what we've already estimated with
the neural network. So one should note that the likelihood function p of y given x is in most cases
known. And in 95% of the cases, it can be modeled relatively well with the Gaussian.
And among the rest of the 5%, 4% is Poisson, meaning that the likelihood function is often known
a priority. So hence, in the perspective of Bayesian reconstruction, all we have to do when
posterior sampling is desirable is to specify the correct prior distribution. Then the measurement
process is hand wavy, it's known so we can sample from the posterior. So let's consider the case
where we modeled the data distribution with the diffusion model. From the score or the SDE perspective,
recall that the generative process is defined by this general form of reverse SDE. So in order
to do unconditional sampling from the prior distribution, we can use the following discretization
steps of the reverse SDE. So for simplicity, I denoted Euler-Maruyama discretization here,
but other forms of sampling can of course be used, such as ancestral sampling of DDPMs
or hybrid methods that incorporate MCMC chains within the numerical integration solvers.
They're called predictor-corrector solvers in score SDE paper.
Moreover, when we want to do posterior sampling, we can use what we've derived from the Bayes rule
and incorporate the gradient of the walk likelihood. So here comes the problem.
Can I ask a question? I'm sorry, I'm decently new to the diffusion model, so maybe there is
something I didn't understand. I don't understand the sign, why there is a minus sign in front of
the even the original paper, why there is a minus sign in front of the gradient of the
score. Oh, so you're asking, how did the reverse SDE come along here, right?
Well, I'm saying that with that minus sign, it will do the opposite of going to the high
probability regions. It will go away from it. So am I missing something?
Oh, yeah. So intuitively, if you want to sample from the high density modes of the
distribution, you would kind of do gradient ascent with it. And yeah, there's a caveat here,
because the differential dt here is a time running backwards. So you have to show the minus sign.
Yeah. But then the sign of f is wrong, because the sign of f should have the same
sign of g, doesn't it? Actually, no. So the derivation process of this reverse SDE comes from
the thing called Anderson's theorem. So if you plug in this general form of forward SDE,
then there's a theorem that states that this reverse SDE is the correct form.
I understand. But so if there isn't, let's say that there is no score, so there is no goal,
then if you have a, let's say, a Oldston-Ulenbach process, the forward and reverse dynamics are the
same. So you're saying that f dt is running backwards, then f should be negative. If you
have a stationary process like an Oldston-Ulenbach, regardless whether you run it forward or
backward, you have the same dynamics. Therefore, you are not going to flip the sign of f if you
change the time. Let's say, in an Oldston-Ulenbach process, f induces the mean reversion. So if
you actually flip the sign, you will have the process going away from the mean, which is not
the reverse time process. The reverse time process wants to go back to the mean exactly like the
forward process. Right, right. I'm also a bit confused myself.
Because everything works, I think, I don't know. So again, I could be misinterpreting something.
Because I do see this in papers, but I just,
it's, again, if it's an Oldston-Ulenbach process, the forward and reverse dynamics,
assuming score zero, should be the same. So you cannot flip the sign. Otherwise,
you get the opposite, you get the diverging process. And if you assume the generative
direction to be forward, then the sign of the score should be plus, not minus. But of course,
it would become minus if you are actually considering that going backward. But okay,
but maybe we can discuss this offline. And also, I mean, again, it could be that I'm missing some
details of the notation that for which things will match up. I'm not sure if, especially in the case
of Ornstein-Ulenbach process, is there, is the score function zero there? Well, so the,
well, so the, if the forward process is Oldston-Ulenbach, then f of x of t is just minus alpha x.
Right. And that would be true both in the forward and in the backward,
because again, it's time invariant. If you flip, you don't change anything.
The score happened in order to enforce the terminal condition that the process has to fit the data.
So it, in this sense, it's nothing to do with the Ornstein-Ulenbach process. It's just a
starting point of the process, which if then, if you want to reverse, it will actually go back to
there. Yeah, I think we should come back to this later. I think it's better to discuss
So coming back to where we were, I think it was right here. So I was talking about how we could
switch from prior sampling to posterior sampling by, by just plugging, plugging in this base rule.
And here I said that care must be taken here because the gradient of the log likelihood
is in fact intractable. And note that this is different from my claim earlier that the
likelihood function is in most cases known. And this is, this arises from the fact that
there are noisy x i's here rather than x zero. So let us dive into closely examine what I mean by this.
To see why this is the case, I'm sorry that I'm switching notations with i and t. For i's,
I'm denoting discretized things and t. I'm just pointing at some general continuous time.
and instantiations. So here, consider the following probabilistic graph in the context of diffusion
models. So we know two conditional distributions p of y given x zero and p of x t given x zero.
And for now, let's assume that the first one is the measurement distribution is given as typically
Gaussian. So, and the second word, the four distribution of the diffusion is also Gaussian.
However, the reverse distribution p of x zero given x t shown with blue dotted line is intractable
in general. So hence p of y given x t is intractable because we have no information about this blue
dotted line. So in our work, we aim to approximate the intractable distribution.
The first key comes from the factorization. Since x zero is conditionally independent on y
and x t, we can factor the integrand as follows. Where the former term is what we know and the
latter term is what we partially know. And by partially known, I mean that we know how to obtain
the posterior mean of the distribution, which is given by the 3ds formula. Note that 3ds formula
is used widely in diffusion model context, as it states that the posterior mean, or the denoised
estimate, can always be achieved when we know the so-called blurred score function. That is,
the score function of the intermediate noisy variables x t.
Here we see that we can plug in 3d denoising to achieve some posterior mean of the
distribution in the context of the dpms. And to fully enjoy the effectiveness of 3ds formula,
and because leaving the expectation outside is intractable, let us push the expectation inside
for now. When we do that, by the 3ds formula proposition, we have a fully tractable distribution
where the condition is now given by x zero hat, the denoised estimate from x t.
Now, since we proposed an approximation here, it is important that we quantify the approximation
bound. And for that, we have a theorem that states the approximation error,
or the so-called Jensen gap, and used by pushing the expectation inside the function.
And we show that this approximation error is upper bounded by this constant with 3 constituents.
So, the latter two parts are usually bounded in most practical situation.
And the interesting part here is the first one, where we see that when sigma goes to zero,
the entire constant goes to zero. This is useful because it states that in cases where we have
negligible measurement noise, the approximation will be tight. However, in practice, even when
we have high measurement noise, the method also works very well. So, just summing everything up,
thanks to theorem one, we can achieve what we call diffusion posterior sampling,
or DPS in short. We start with standard Bayes rule in the context of diffusion models.
We can apply theorem one to get the approximation.
I lost him. I don't hear anything anymore. Do you hear me now?
Yeah. Yeah. Yeah. Sorry. Where did the...
I don't have any sound anymore.
Yeah, now we're here. Yeah, now it's back. But we cannot see the screen.
Can you try to share the screen again? I can see a screen. I can see the screen,
the Gaussian and Poisson. Yeah, me too. Yeah. Can you try to just stop sharing again?
We'll share it again. Yeah, sure. Thanks.
So, is this where the connection was disconnected?
Yeah, you were just starting about the Gaussian and Poisson. Yeah.
So, I was saying that these gradients can be analytically computed because these
functional forms are already known. So, we see that for Gaussian, we're essentially
performing gradient descent that minimizes the squared L2 norm of the residual.
I cannot see the slides, but I cannot see the screen. Yeah, neither. No.
They just dropped away in the halfway through your sentence.
Okay. So, let's try to reshare...
Yeah, now I can see them. Yeah, me too. Thanks. So, does this work?
Yes. It seems like... Yeah. So, yeah, I was saying that for Gaussian measurement models,
we're trying to do gradient descent that minimizes the squared L2 norm of the residual,
and for Poisson measurements, we're minimizing the squared weighted norm of the residual.
So, incorporating ancestral sampling for DDPMs, we have our algorithm of DPS where we can derive
separate algorithms according to the measurement model in hand. Note that line seven is where DPS
takes place. If we were to remove line seven, we would simply be sampling from the prior distribution,
the usual diffusion models, what they do. And hence, our algorithm is just very simple
modification of the usual DDPM sampling. When we do that, we achieve these results.
So, since our method is not dependent on the measurement model, we can apply the same score
function to various problems. For example, this is the result of applying our method to super
resolution that are contaminated with Gaussian noise. We can also apply our method to noisy in
painting, and this is the case where 92% of the pixels are blocked out in a 256x256 image.
This is noisy Gaussian deep blurring. We can do noisy motion deep blurring.
And what's even more, since we're not restricted to the choice of the forward operator A,
for the first time in the context of inverse problem solving with diffusion models,
we show that we can also solve nonlinear inverse problems, such as phase retrieval presented here.
And for those of you who do not know what phase retrieval is, it's a problem that tries to estimate
the phase and the Fourier domain, and this is a notoriously hard problem because most of the
information of the image is actually concentrated on the Fourier phase rather than the Fourier
magnitude of an image. And we can also solve problems like non-uniform deep blurring, which
is another nonlinear inverse problem, given that the forward measurement model is actually
differentiable. This is one application that I want to highlight because we actually used
a complex neural network that emulates the nonlinear blurring here. And neural network is one
of the most nonlinear forward models that you can imagine. So even when the forward operator is
highly nonlinear, we can see that DPS is capable of recovering the image with high fidelity.
So that was it for DPS. I think we can briefly stop to see if any of you have any questions.
I have a question. So basically, did you also show, because you can have, due to the stochasticity,
you can have posterior distribution of the denoid samples, right? So do you notice a difference
compared for the one you, the blur, for example, this image, do you get some deviations that are
meaningful in one sense? Yeah, so I'm sorry that I don't have examples here, but
yeah, you do see quite a bit of stochasticity, especially when the degradation is heavy as,
for example, the example here, blurring is heavy. So the posterior samples have high
standard deviation in terms of reconstructions. Yeah, that's another question. I don't know if
you're going to explain it and maybe let me study that, but you also mentioned that reconstruction
is possible if you have a prior, right? Right. But how do you choose the prior? Do you learn
it or is it something that you'd have to? Oh yeah. So the thing that we're proposing here is that
we're using the diffusion prior, right? So we're using this generative prior,
and the prior is learned through the usual training process of diffusion models. So
whether it be score matching or epsilon matching or whatever, we only, what we only need in the
sampling process is the pre-trained score function s theta here. So all the examples that I show you
here are generated by pre-trained models available online. So specifically, we use the
open AI model, and we don't need any fine-tuning for any of these problems. We can just plug it
into the solver and that will act as the prior of the distribution. Okay, so the prior is trained
on the data that you use it on. So you use the simulation of the model pre-trained on different
data. Yeah. Thanks. So how this method would differ from the paper also from song et al for
inverse problems in medical imaging? So is there a likely difference? They are different and that
will be covered more in detail in the second section where I explain the nearest paper.
Yeah. So if you could summarize, for example, in a few words, because the main paper from song et al,
you can also do inverse problems straightforward. I mean, you can do the painting. What would be
like the main contribution is this non-linear approach to inverse problems, or what would
be the main difference? So it's two things. I guess I'll try to explain it later. So you're
mentioning the original paper of song et al at iClear 2021 and there was a paper that you mentioned
that tackled medical imaging in the next year of the same author. They solved inverse problems by
using a so-called projection approach, which means that you're directly replacing what you have as
the measurements and you're keeping only the rest of it. So this is the visualization of such
projection process. And this projection process works for certain inverse problems, for example,
in painting. And for in painting, when you have a small degradation, for example, the mask is small
or the blocked out pixels are not dominant. In those cases, projection approaches work fine.
But for example, when you have a large mask, for example, a 128 by 128 mask cure, when you
apply song's method, projection type approaches tend to fail dramatically. This is also relevant
to the case of medical imaging, where you have high degradations. These projection-based approaches
will typically fail. Whereas DPS that I proposed in the last section and the MCG that I will explain
soon after does not have this property. And the methodological main difference is that
you song and all use projection type approaches, whereas MCG or DPS uses gradient type approaches.
So it's a smoother transition towards the that adapts to the measurement process.
Yeah, that's pretty nice. Yeah, that's pretty clear. Thanks.
Yeah. Okay. Should I move on to the next section?
Yeah, thanks. Yeah, so the next paper that I'm going to talk about is actually a paper that came
before DPS. But I explained DPS first because it really uses the same gradient, I would say
similar, but almost the same gradient method with DPS. But at the time of development of MCG paper,
we did not really understand how mathematically the solvers would be derived. So here in this
paper, we focused more on the explanation in the geometric context of diffusion models. So I hope
that this also helps the understanding of the underlying intuitive
things about these gradients based methods.
So in order to understand the paper, let us review some of the important properties of
high dimensional Gaussian random variables. And specifically for very high dimensional Gaussian
random variables, while the mode of the PDF may be near the main of the distribution,
the measure is actually concentrated in the annulus that is distant from the center.
This is the reason why when we add fixed variance Gaussian noise to an image,
you never really see a clean image, even when the highest probability of a Gaussian noise would be
zero noise. We always get images with very similar noise levels. Now extending that,
let us think of a random variable Y that is corrupted with Gaussian noise
by adding some noise. Sorry, can you maybe rephrase that? I mean, I think that's interesting,
the slides before. So the concentration of Gaussian measure, right? Yeah, so this is a
Gaussian annulus theorem, right? And then the effect that we see, what you said is that we
don't see like, so we see the same effect, right? Or what do you mean? Definitely. So
because of the Gaussian annulus theorem, what we see when we add Gaussian noise to images with,
let's say, fixed variance Gaussian noise to an image, I guess the highest probability
instantiation of this Gaussian distribution would be no noise, right? Zeroes. But that never happens.
So if you add some random Gaussian noise to an image, you will always see some
very similar noise level images that are corrupted in a very similar way. So that was what I was
talking about. Yeah, okay. Yeah. So it's also due to the convolution, right? You can observe this
as a convolution. Yeah. So this is kind of related to what I was talking about before.
So let's say you have like a linear space of X. And what you would do is you add some Gaussian
noise to that random variable X. Because this is a convolution, we can show that the marginal
distribution P of Y is actually a, the measure actually concentrates on the hypercylinder
that is distant from the center of PX. So this is kind of intuitive reason why
the noisy images with the fixed variance have similar looking structure.
So in this work, we propose to interpret diffusion models using some assumptions about the data
manifold. So the usual manifold hypothesis states that the data lives in a low dimensional manifold
with much smaller dimensionality than the ambient space. And in this work, we add an
additional strong assumption that the manifold, the central data manifold is locally linear.
And in order to leverage, and this is because we want to leverage the results from the concentration
of Gaussian measure. And specifically, when we assume that our data manifold is locally linear,
what we can show is that the geometry of diffusion model is given by the successive manifolds
where there exists a clean data manifold in the center. And there are continuously many
noisy manifolds where the noisy samples reside. So these are the manifolds of the noisy images.
Extending that to a continuous limit, we propose that diffusion model is an onion because
where when we push T to infinity, the distribution actually becomes a pure Gaussian.
And since the measure of a high dimensional Gaussian resides in a Gaussian hypersphere,
the intermediate manifolds are covers of the central manifolds that interpolates between these
two. Therefore, this diffusion process would correspond to these red arrows, and the reverse
diffusion would correspond to the blue arrows. And furthermore, when we are considering the case
where we are trying to solve inverse problems with diffusion, we are left with the figure on
the right. Here, we are not only trying to find points in the central manifold M,
but we're trying to find the intersection between the manifold M and the line Y equals HX.
So I've already said this earlier, but let's examine some of the representative methods that
solve inverse problems using diffusion. These methods, Song at L and Choi at L,
are a type of projection-based approach, since they directly replace the part that is known
and keep only the unknown part. Another way to impose data consistency in the Bayesian framework
is to incorporate likelihood. In other words, try to minimize the residual by gradient descent.
However, with diffusion models, if we were to use naive gradient descent with a noisy residual,
we will acquire no meaningful gradient, as the residual between HXI and Y
will only be focused on the Gaussian noise part of the residual.
Now, as we saw in diffusion posterior sampling, one can actually approximate the correct likelihood
by switching to 2D denoised estimate X0 hat here. Here, visually and intuitively,
we see why this may help. This is because after denoising, the residual is more likely to focus
on the structural differences between HX0 hats and Y. In practice, using this gradient step over
the projections work much, much better. And you can see the kind of the resulting differences
when we use projection type approach and the gradient approaches.
So in the paper, we properly analyze why this would be the case, leveraging the geometric
understanding of diffusion models. So first, under our assumptions, we show that 2D denoising
corresponds to an orthogonal projection to the data manifold. However, note that we have to consider
two components of the data manifold, the orthogonal one that is related to the noise components,
and the tangential one that is related to the data fidelity.
So score function alone cannot handle the data fidelity. And here comes our theorem,
which states that the proposed manifold constraint gradient term points to a direction that is
tangential to the central data manifold. And therefore, our solution will move closer to Y
equals HX every time we apply this MCG step. Another important aspect of this is that since MCG
lets the sample move on the data manifold, whereas projections move the sample off the data manifold
because projections are hard constraints that try to make Y minus HX equals 0.
Note that MCG will not do that. It will move on the data manifolds in the direction tangential
to the manifold. So those falling off the manifold will not happen.
So here, note that the score functions that are pre-trained were not trained with
samples that are off the data manifold. So they were trained with the samples that were on the
noisy data manifolds. So it will not be able to properly denoise samples that are off the data
manifolds. So by using projections, the intermediate error will probably accumulate,
and we conjecture that this is the reason why projection-based approaches often fail to produce
a good sample. But however, as I said, in the time we wrote MCG, there was a gap between
theory and practice because even with the MCG steps, we had a hard time trying to solve inverse
problems. So we had to resort to some projections within the denoising and the gradient steps.
But in DPS, we managed to achieve a general solver that only uses these gradient steps.
Now, for the Gaussian case, the only difference between MCG and DPS is that we do not use projections
for DPS. Leveraging the geometric viewpoint of diffusion models, we can think that DPS is
superior to MCG specifically because we avoid such projections. As projections here can potentially
throw samples off the data manifold. Hence, DPS will typically be more stable by avoiding such
throw-offs. And by the way, this is just an illustration. It doesn't really guarantee anything
that our solver will always stay on the noisy data manifolds.
Yeah, so that was about it for MCG. Any questions up until now?
I just have a question, but maybe a very simple question. At the beginning of this slide,
when you were explaining the, I think it's, no, the next one, two after this one.
But yeah, this one, the previous one. How do you define this k? So n, what is n and what is k?
I would have to look for the definition of n and k here.
From my memory, n is the dimension of the ambient space, in case the dimension of the
locally linear, low-dimensional dimensionality of the data manifold.
I guess you're assuming that this, so the brown, the mean is basically used, the mean of each
intermediate distribution. So it's the mean of the diffuse or denoise distribution.
And then this, I'm just wondering, shouldn't you start going from a big
standard deviation to a small standard deviation? Because basically when you do the denoising,
you start with a high variance and then you start denoising and the variance slowly decreases.
That's just something I was thinking that if that's not the case, so I'm missing out something.
Can you repeat the question again? I'm not sure if I understood it correctly.
Yeah, so the point of this is to interpret what's going on, like how the denoising samples
behave in the data manifold through the trajectory. So when you do the denoising,
so you start with the isotropic Gaussian, which is the highest entropy you can have. So you start
with the maximum variance that you have and then slowly you start removing the noise and by doing
that interactively the variance at each intermediate step goes down. So what I was expecting is to have
this behavior when you have the mean and then the variance is large at the beginning and then
starts decreasing. Because ideally you would reduce the variance, but I don't know if I'm missing
something there. Oh, but I think it's what you're saying is kind of different from what
this slide is saying. So I'm not really stating anything about denoising anything because the
flow here is that we're first assuming that there exists a central data manifold M here.
And then we're trying to visualize how the manifold of the noisy images would look like
if there exists the central data manifold M. And I'm claiming that these noisy data manifolds will
be covers of the central data manifold, where the distance between from the central data manifold
will be defined by this constant value. So it's really not about starting from high variance
Gaussian noise and reducing it to anything. We're starting from a clean image and then we're defining
the manifolds of these of these noisy images. Okay, so I will have to look at that for I guess also
more too. Yeah, thanks. Yeah. So I guess we just tell me if
if I'm
it's gonna get it's a good cliffhanger.
It's first again.
Um, do you hear me okay?
Yeah, yes. Yeah, so I think it's about 48 minutes. So I don't think we have to go over the final
section. So yeah. So I'll just try to we just we cannot see you or the slides anymore if you
can do the same thing as before to stop sharing and start again. Yeah. Well, the talk is basically
done. So okay, that was the last slide if we if we don't cover the last section.
I'm not sure if this is the correct way of saying thank you very much in in Dutch.
Maybe you should put it in Italian.
Yeah, so yeah, that is the right way to say thank you. Thank you too.
