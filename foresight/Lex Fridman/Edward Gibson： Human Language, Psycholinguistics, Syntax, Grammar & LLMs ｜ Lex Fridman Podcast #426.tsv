start	end	text
0	5840	Naively, I certainly thought that all humans would have words for exact counting.
6960	12480	And the Piroha don't, okay? So they don't have any words for even one. There's not a word for
12480	17120	one in their language. And so there's certainly not a word for two, three, or four. So that kind
17120	21760	of blows people's minds off. Yeah, that's blowing my mind. That's pretty weird. How are you going to
21760	27280	ask? I want two of those. You just don't. And so that's just not a thing you can possibly ask in
27280	29840	the Piroha. It's not possible. That is, there's no words for that.
32160	38240	The following is a conversation with Edward Gibson, or Ted, as everybody calls him. He is a
38240	44560	Psycho-Linguistics Professor at MIT. He heads the MIT Language Lab that investigates why human
44560	51120	languages look the way they do, the relationship between cultural language and how people represent,
51120	57680	process, and learn language. Also, he should have a book titled Syntax, A Cognitive Approach,
58240	64800	published by MIT Press, coming out this fall. So look out for that. This is the Lex Freeman
64800	70480	podcast. To support it, please check out our sponsors in the description. And now, dear friends,
70480	76720	here's Edward Gibson. When did you first become fascinated with human language?
77360	84640	As a kid in school, when we had to structure sentences and English grammar, I found that
84640	90640	process interesting. I found it confusing as to what it was I was told to do. I didn't
90640	94720	understand what the theory was behind it, but I found it very interesting.
94720	97520	So when you look at grammar, you're almost thinking about like a puzzle,
97520	101200	like almost like a mathematical puzzle? Yeah, I think that's right. I didn't know I was going
101200	106320	to work on this at all at that point. I was really just, I was kind of a math geek person.
106400	109280	Computer scientist. I really liked computer science. And then I found
110000	116640	language as a neat puzzle to work on from an engineering perspective. Actually, that's what
116640	123600	I, as a, I sort of accidentally, I decided after I finished my undergraduate degree,
123600	128720	which was computer science and math and Canada and Queens University, I decided to go to grad
128720	135040	school. That's what I always thought I would do. And I went to Cambridge, where they had a master's
135040	141120	in a master's program in computational linguistics. And I hadn't taken a single language class
141120	146640	before. All I'd taken was CS, computer science, math classes, pretty much mostly as an undergrad.
146640	149520	And I just thought, oh, this was an interesting thing to do for a year,
150240	155760	because it was a single year program. And then I ended up spending my whole life doing it.
155760	160800	So fundamentally, your journey through life was one of a mathematician and computer scientists.
160800	166480	And then you kind of discovered the puzzle, the problem of language, and approached it
166480	172240	from that angle, to try to understand it from that angle, almost like a mathematician or maybe
172240	178400	even an engineer. As an engineer, I'd say, I mean, to be frank, I had taken an AI class,
178400	183200	I guess it was 83 or 85, somewhere 84 in there a long time ago. And there was a natural language
183200	188800	section in there. And it didn't impress me. I thought there must be more interesting things
188800	196160	we can do. It didn't seem very, it seemed just a bunch of hacks to me. It didn't seem like a real
196160	203200	theory of things in any way. And so this seemed like an interesting area where there wasn't enough
203200	208560	good work. Did you ever come across like the philosophy angle of logic? So if you think about
208560	216400	the 80s with AI, the expert systems where you try to kind of maybe sidestep the poetry of language
216400	221120	and some of the syntax and the grammar and all that kind of stuff and go to the underlying
221120	226720	meaning that language is trying to communicate and try to somehow compress that in a computer
226720	231840	representable way. Do you ever come across that in your studies? I mean, I probably did, but I
231840	236720	wasn't as interested in it. I was trying to do the easier problems first than ones I could
237280	243120	thought maybe were handleable, which seems like the syntax is easier, which is just the forms as
243120	246560	opposed to the meaning. When you're starting talking about the meaning, that's a very hard
246560	251840	problem. And it still is a really, really hard problem. But the forms is easier. And so I thought
251840	258240	at least figuring out the forms of human language, which sounds really hard, but is actually maybe
258240	263680	more tractable. So it's interesting. You think there is a big divide, there's a gap,
263680	269440	there's a distance between form and meaning. Because that's a question you have discussed a
269440	274960	lot with LLMs, because they're damn good at form. Yeah, I think it's what they're good at,
274960	278720	is form. And that's why they're good, because they can do form, meaning's hard.
279680	284160	Do you think they're, oh, wow. I mean, it's an open question, right? How close form and meaning
284160	289600	are? We'll discuss it. But to me, studying form, maybe some romantic notion,
290880	298080	gives you form is like the shadow of the bigger meaning thing underline language.
298160	305360	Language is how we communicate ideas. We communicate with each other using language.
305360	310720	So in understanding the structure of that communication, I think you start to understand
310720	315920	the structure of thought and the structure of meaning behind those thoughts and communication
315920	322880	to me. But to you, big gap. What do you find most beautiful about human language,
322880	327760	maybe the form of human language, the expression of human language?
327760	334400	What I find beautiful about human language is some of the generalizations that happen
334400	339120	across the human language, just within and across a language. So let me give you an example of
339120	347040	something which I find kind of remarkable, that is if a language, if it has a word order,
347040	351200	such that the verbs tend to come before their objects. And so that's like English does that.
351200	357440	So we have the subject comes first in a simple sentence. So I say, you know, the
358480	363680	dog chased the cat or Mary kicked the ball. So the subject first, and then after the subject,
363680	369040	there's the verb. And then we have objects. All these things come after in English. So it's generally
369040	373760	a verb. And most of the stuff that we want to say comes after the subject. It's the objects.
373760	377600	There's a lot of things we want to say they come after. And there's a lot of languages like that.
377600	384000	About 40% of the languages of the world look like that. They're subject verb object languages.
384000	392640	And then these languages tend to have prepositions, these little markers on the nouns
392640	398720	that connect nouns to other nouns or nouns to verb. So when I say a verb, I say preposition
398720	404720	like in or on or of or about, I say, I talk about something. The something is the object
404800	409120	of that preposition that we have these little markers come also just like verbs,
409120	413920	they come before their their nouns. Okay. And then so now we look at other languages
413920	420080	that like Japanese or or Hindi or some, these are these are so called verb final languages.
420080	426000	Those is about maybe a little more than 40%, maybe 45% of the world's languages are more,
426000	432080	I mean, 50% of the world's languages are verb final. Those tend to be post positions,
432080	435280	those markers, the same if you have the states have the same kinds of markers,
436080	442080	as we do in English, but they put them after. So sorry, they put them first, the markers come
442080	449600	first. So you say instead of, you know, talk about a book, you say a book about the opposite
449600	455280	order there in Japanese or in Hindi, you do the opposite and the and the talk comes at the end.
455280	460400	So the verb will come at the end as well. So instead of Mary kicked the ball, it's Mary
461360	468160	ball kicked. And then if it's Mary kicked the ball to John, it's John two, the two,
468160	472240	the little marker there, the preposition, it's a post position in these languages.
472240	476320	And so the interesting thing, a fascinating thing to me is that within a language,
477760	486080	this order aligns, it's harmonic. And so if it's one or the other, it's either verb initial or
486160	490720	verb final, but then you then you'll have prepositions, prepositions or post positions.
490720	495680	And so that and that's across the languages that we can look at. We've got around 1000 languages
495680	501920	for there's around 7000 languages around on the earth right now. But we have information
501920	507440	about say word order on around 1000 of those pretty decent amount of information. And for
507440	514480	those 1000, which we know about, about 95% fit that pattern. So they will have either verb and
514880	521280	it's about half and half or half verb initial, like English and half verb final, like Japanese.
521280	527520	So just to clarify, verb initial is subject verb object. That's correct. Verb final is
527520	532000	still subject, object verb. That's correct. Yeah, the subject is generally first.
532000	539920	That's so fascinating. I ate an apple or I apple eight. Yes. Okay. And it's fascinating that there's
540160	545360	pretty even division in the world amongst those 45%. Yeah, it's pretty, it's pretty even.
545360	549600	And those two are the most common by far. Those two words, the subject tends to be first.
549600	553120	There's so many interesting things, but these things are what I find so fascinating is there
553120	559120	are these generalizations within and across a language. And not only those are the, and
559120	563280	there's actually a simple explanation, I think, for a lot of that. And that is,
563680	569600	you're trying to like minimize dependencies between words. That's basically the story,
570160	575600	I think, behind a lot of why word order looks the way it is, is you, we're always connecting.
576640	579520	What is it? What is the thing I'm telling you? I'm talking to you in sentences. You're talking
579520	585360	to me in sentences. These are sequences of words, which are connected. And the connections are
585360	592000	dependencies between the words. And it turns out that what we're trying to do in a language is
592080	597200	actually minimize those dependency links. It's easier for me to say things if the words that
597200	602240	are connecting for their meaning are close together. It's easier for you in understanding if that's
602240	608560	also true. If they're far away, it's hard to produce that and it's hard for you to understand.
608560	613840	And the languages of the world within a language and across languages fit that generalization,
613840	621280	which is, so it turns out that having verbs initial and then having prepositions ends up
621280	627440	making dependencies shorter. And having verbs final and having postpositions ends up making
627440	631040	dependencies shorter than if you cross them. If you cross them, it ends up, you just end up,
631040	635280	it's possible, you can do it. Even within a language. Within a language, you can do it.
635280	640560	It just ends up with longer dependencies than if you didn't. And so languages tend to go that way.
640560	646800	They tend to, they say they call it harmonic. So it was observed a long time ago without the
646800	653440	explanation by a guy called Joseph Greenberg, who's a famous typologist from Stanford. He
653440	657200	observed a lot of generalizations about how word order works. And these are some of the
657200	659680	harmonic generalizations that he observed.
659680	664560	Harmonic generalizations about word, word, word. There's so many things I want to ask you.
664560	664880	Okay, good.
664880	669760	Okay, let me just, sometimes basics. You mentioned dependencies a few times.
669760	670240	Yeah.
670240	671920	What do you mean by dependencies?
671920	678640	Well, what I mean is in, in language, there's kind of three structures to three components
678640	684480	to the structure of language. One is the sounds. So cat is cat and to in English. I'm not talking
684480	688560	about that part. I'm talking, and then there's two meaning parts. And those are the words.
688560	692880	And, and you're talking about meaning earlier. So words have a form and they have a meaning
692880	697280	associated with them. And so cat is a full form in English and it has a meaning associated with
697280	704080	whatever a cat is. And then the combinations of words, that's what I'll call grammar or syntax.
704080	711280	And that's like, when I have a combination like the cat or two cats, okay, so where I
711280	715280	take two different words there and put them together and I get a compositional meaning
715280	721840	from putting those two different words together. And so that's the syntax. And in any sentence
721840	725440	or utterance, whatever I'm talking to you, you're talking to me, we have a bunch of words
725440	733040	and we're putting together in a sequence. They, it turns out they are connected so that every word
733040	738000	is connected to just one other word in that, in that sentence. And so you end up with what's
738000	743520	called technically a tree. It's a tree structure. So there, where there's a root of that, of that
743520	748960	to utterance of that sentence. And then there's a bunch of dependence, like branches from that root
748960	754560	that go down to the words, the words are the leaves in this metaphor for a tree.
754560	758640	So a tree is also sort of a mathematical construct. Yeah. Yeah. It's a graph theoretical thing.
758640	764320	Graph theory thing. Yeah. So in this fascinating that you can break down a sentence into a tree
764320	768640	and then one, every word is hanging on to another, it's depending on it. That's right. And everyone
768640	772240	agrees on that. So all linguists will agree with that. No one. It's not a controversial.
772240	776400	That is not controversial. There's nobody sitting here. I do nothing mad at you. I don't think so.
776400	780080	Okay. There's no linguists sitting there mad at this. No, I think in every language,
780080	786480	I think everyone agrees that all sentences are trees at some level. Can I pause on that? Sure.
786480	794400	Because it's to me just as a layman, it's surprising that you can break down sentences
794400	800320	in many, mostly all languages into a tree. I think so. I've never heard of anyone
800320	805120	disagreeing with that. That's weird. The details of the trees are what people disagree with.
805840	809600	Well, okay. So what's the root of it? How do you construct?
809600	812880	How hard is it? What is the process of constructing a tree from a sentence?
814000	819520	Well, this is where, depending on what your theoretical notions, I'm going to say the simplest
819520	824400	thing. Dependency grammar. It's like a bunch of people invented this. Tinier was the first
824400	830000	French guy back in, I mean, the paper was published in 1959, but he was working on the 30s and stuff.
830720	837840	And it goes back to, you know, philologist Panini was doing this in ancient India. Okay.
837840	842480	And so, you know, doing something like this, the simplest thing we can think of is that there's
842480	848000	just connections between the words to make the utterance. And so let's just say I have like two
848000	855440	dogs entered a room. Okay. Here's a sentence. And so we're connecting two and dogs together.
855440	858880	That's like, there's some dependency between those words to make some bigger meaning.
858880	866720	And then we're connecting dogs now to entered, right? And we connect a room somehow to entered.
866720	871280	And so I'm going to connect to room and then room back to entered. That's the tree,
871280	875520	is I, the root is entered. That's the thing is like an entering event. That's what we're saying
875520	881040	here. And the subject, which is whatever that dog is, is two dogs, it was, and the connection
881040	886400	goes back to dogs, which goes back to them, then that goes back to two. I'm just, that's my tree.
886400	892080	It starts at entered, goes to dogs down to two. And then the other side, after the verb,
892080	897600	the object, it goes to room. And then that goes back to the determiner or article, whatever you
897600	901360	want to call that word. So there's a bunch of categories of words here we're noticing. So
901360	908080	there are verbs. Those are these things that typically mark, they refer to events and states
908080	912480	in the world. And they're nouns, which typically refer to people, places and things is what people
912480	917120	say, but they can refer to other more, they can refer to events themselves as well. They're
917120	923280	marked by, you know, how they, how they, the category, the part of speech of a word is how
923280	928560	it gets used in language. It's like, that's how you decide what the, what the category of a word
928560	934400	is not, not by the meaning, but how it's, how it gets used. What's usually the root? Is it going
934400	940640	to be the verb that defies the event? Yes. Yes. Yes. Okay. Yeah. I mean, if I don't say a verb,
940640	943440	then there won't be a verb. And so it'll be something else. What if you're messing, are
943440	947520	we talking about language that's like correct language? What if you're doing poetry and messing
947520	953360	with stuff? Is it then, then rules got the window, right? Then it's, no, you're still, no, no, no,
953360	957200	no, you're constrained by whatever language you're dealing with. Probably you have other
957200	961760	constraints in poetry, such that you're like usually in poetry, there's multiple constraints
961760	966320	that you want to, like you want to usually convey multiple meanings is the idea. And maybe you have
966320	971440	like a rhythm or a rhyming structure as well. And depending on, so, but you usually are constrained
971440	977440	by your, the rules of your language for the most part. And so you don't violate those too much.
977440	982400	You can violate them somewhat, but not too much. So it has to be recognizable as your language.
982400	989280	Like in English, I can't say dogs to entered room. Ah, I mean, I meant that, you know, two dogs
989280	995840	entered a room and I can't mess with the order of the, the articles and the articles and the
995840	1001120	nouns. You just can't do that. In some languages, you can, you can mess around with the order
1001120	1006320	of words much more. I mean, you speak Russian. Russian has a much freer word order than English.
1006320	1011040	And so in fact, you can move around words in, you know, I told you that English has the subject,
1011040	1016080	verb, object, word order. So does Russian, but Russian is much freer than English. And so you
1016080	1020720	can actually mess around with the word order. So probably Russian poetry is going to be quite
1020720	1025040	different from English poetry because the word order is much less constrained. Yeah,
1025120	1031040	there's a much more extensive culture of poetry throughout the history of the last 100 years
1031040	1036640	in Russia. And I always wondered why that is, but it seems that there's more flexibility
1037360	1042080	in the way the language is used. There's more, you're more female language easier by
1042800	1045920	altering the words, altering the order of the words, messing with it.
1045920	1049680	Well, you can just mess with different things in each language. And so in Russian, you have
1049680	1054960	case markers, right? On the end, which is these endings on the nouns, which tell you how it can
1055280	1058960	each noun connects to the verb, right? We don't have that in English. And so when I say
1060000	1065520	Mary kissed John, I don't know who the agent or the patient is, except by the order of the words,
1065520	1069680	right? In Russian, you actually have a marker. On the end, if you're using a Russian name and
1069680	1075280	each of those names, you'll also say, is it, you know, agent, it'll be the, you know, nominative,
1075280	1079760	which is marking the subject, or an accusative will mark the object. And you could put them in
1079760	1084640	the reverse order. You could put accusative first, as you could put subject, you could put
1085600	1090880	the patient first, and then the verb, and then the, the, the subject, and that would be a perfectly
1090880	1095840	good Russian sentence. And it would still mean Mary, I could say John kissed Mary, meaning Mary
1095840	1100800	kissed John, as long as I use the case markers in the right way, you can't do that in English.
1100800	1106720	And so I love the terminology of agent and patient. And, and the other ones you use,
1107360	1110960	those are sort of linguistic terms, correct? Those are, those are for like kind of meaning,
1110960	1115840	those are meaning. And, and subject and object are generally used for position. So subject is
1115840	1120000	just like the thing that comes before the verb. And the object is when it comes after the verb.
1120000	1124160	The agent is kind of like the thing doing it. That's kind of what that means, right? The,
1124160	1128480	the, the subject is often the person doing the action, right? The thing. So yeah.
1128480	1132000	Okay. This is fascinating. So how hard is it to form a tree in general? Is there,
1132400	1137360	is there a procedure to it? Like if you look at different languages, is it supposed to be a
1137360	1141040	very natural, like is it automatable or is there some human genius involved in?
1141040	1144640	I think it's pretty automatable at this point. People can figure out the words are,
1144640	1148000	they can figure out the morphemes, which are the, technically morphemes are the,
1148640	1153600	the minimal meaning units within a language. Okay. And so when you say eats or drinks,
1153600	1156800	it actually has two morphemes in an English. There's, there's the, there's the root,
1156800	1160320	which is the verb. And then there's some ending on it, which tells you, you know,
1160320	1164480	that's this third person, third person singular. Can you say what morphemes are?
1164480	1168080	Morphemes are just the minimal meaning units within a language. And then a word is just
1168080	1171520	kind of the things we put spaces between English and 10. They have a little bit more,
1171520	1176160	they have the morphology as well. They have the endings, this inflexual morphology on the endings
1176160	1179920	on the roots. They modify something about the word that adds additional meaning.
1179920	1183040	They tell you, yeah, yeah. And so we have a little bit of that in English, very little,
1183040	1187120	much more in Russian, for instance. And, and, but we have a little bit in English. And so we
1187120	1191360	have a little on the, on the nouns, you can say it's either singular or plural. And, and you can
1191360	1197120	say, same thing for, for, for verbs, like simple past tense, for example, it's like, you know,
1197120	1201680	notice in English, we say drinks, you know, he drinks, but everyone else says, I drink,
1201680	1206560	you drink, we drink, it's unmarked in a way. And then, but in the past tense, it's just drank
1206560	1210720	for everyone. There's no morphology at all for past tense. There is morphology, it's marking
1210720	1215440	past tense, but it's kind of, it's an irregular now. So we don't even, you know, it drink to
1215440	1220160	drink, you know, it's not even a regular word. So in most verbs, many verbs, there's an ED,
1220160	1224720	we kind of add. So walk to walked, we add that to say it's the past tense, that I just happened
1224720	1228560	to choose an irregular because the high frequency word and the high frequency words tend to have
1228560	1233200	irregular as in English for. What's an irregular? Irregular is just, there's, there isn't a rule.
1233200	1238720	So drink to drink is an, it's an irregular. Drink, drink, okay, as opposed to walk, walked,
1238720	1242880	talked, talked. And there's a lot of irregular, irregular as in English. There's a lot of
1242880	1247280	irregular as in English. The, the, the frequent ones, the common words tend to be irregular.
1247280	1252960	They'll let, there's many, many more low frequency words and those tend to be, those irregular ones.
1252960	1257680	The evolution of the irregular is fascinating. It's essentially slang that's sticky because
1257680	1262320	you're breaking the rules and then everybody use it and doesn't follow the rules. And they,
1262320	1267680	they say screw it to the rules. It's fascinating. So you said it morphemes, lots of questions.
1267680	1272800	So morphology is what, the study of morphemes? Morphology is the, is the connections between
1272800	1277200	the morphemes onto the roots, the roots. So in English, we mostly have suffixes. We have
1277200	1281760	endings on the words, not very much, but a little bit. And as opposed to prefixes,
1281760	1288000	some words, depending on your language can have, you know, mostly prefixes, mostly suffixes or
1288000	1292960	mostly, or both. And then even languages, several languages have things called infixes where you
1292960	1301760	have some kind of a general form for the, for the root and you put stuff in the middle. You
1301760	1308000	change the vowels. That's fascinating. That's fascinating. So in general, there's what, two
1308000	1313840	morphemes per word, usually one or two or three? Well, in English, it's, it's one or two. In English,
1313840	1317920	it tends to be one or two. There can be more, you know, in other languages, you know, a language,
1318000	1324480	language like, like Finnish, which has a very elaborate morphology, there may be 10 morphemes
1324480	1329600	on the end of a root. Okay. And so there may be, there may be millions of forms of a given word.
1329600	1338800	Okay. Okay. I will ask the same question over and over. But how does the, just sometimes to
1338800	1344640	understand things like morphemes, it's nice to just ask the question, how does these kinds of
1344640	1354640	things evolve? So you have a great book studying sort of the, how, how, how the cognitive processing,
1354640	1359360	how language used for communication. So the, the mathematical notion of how effective languages
1359360	1363520	for communication, what role that plays in the evolution of language, but just high level,
1364240	1370080	like how do we, how does a language evolve with where English is two morphemes or one or two
1370080	1376400	morphemes per word and then Finnish has infinity per word? So what, how does that, how does that
1376400	1382000	happen? Is it just people? That's a really good question. That's a very good question. It's like,
1382000	1387520	why do languages have more morphology versus less morphology? And I don't think we know the
1387520	1392560	answer to this. I know, I think there's just like a lot of good solutions to the problem of
1392560	1399760	communication. And so I, like, I believe as you hinted that language is an invented system
1399760	1405600	by humans for communicating their ideas. And I think we, it comes down to we label the things we
1405600	1410000	want to talk about. Those are the morphemes and words. Those are the things we want to talk about
1410000	1416080	in the world and we invent those things. And then we put them together in ways that are easy for us
1416160	1422080	to convey, to process. But that's like a naive view. And I don't, I mean, I think it's probably
1422080	1423840	right, right? It's naive and probably right.
1423840	1426320	Well, that's a nice, I don't know if it's naive. I think it's simple.
1426320	1426960	Simple. Yeah.
1426960	1432320	I think naive is, naive is an indication that's an incorrect somehow. It's a trivial,
1433200	1439360	too simple. I think it could very well be correct. But it's interesting how sticky it feels like
1439920	1446080	two people got together. It just feels like once you figure out certain aspects of a language,
1446080	1450480	that just becomes sticky and the tribe forms around that language, maybe the language,
1450480	1454480	maybe the tribe forms first, then the language evolves. And then you just kind of agree and
1454480	1456080	you stick to whatever that is.
1456080	1462480	I mean, these are very interesting questions. We don't know really about how words, even words,
1462480	1467120	get invented very much about, you know, we don't really, I mean, assuming they get invented,
1467920	1472000	they, we don't really know how that process works and how these things evolve. What we have is
1472960	1480320	kind of a current picture, a current picture of a few thousand languages, a few thousand
1480320	1486240	instances. We don't have any pictures of really how these things are evolving, really. And then
1486240	1493920	the evolution is massively, you know, confused by contact, right? So as soon as one language,
1493920	1500320	group, one group runs into another, we are smart, humans are smart, and they take on
1500320	1505600	whatever is useful in the other group. And so any kind of contrast, which you're talking about,
1505600	1510160	which I find useful, I'm going to, I'm going to start using as well. So I worked a little bit
1510720	1518480	in specific areas of words, in number words and in color words, and in color words. So we have,
1519040	1526560	in English, we have around 11 words that everyone knows for colors. And many more, if you happen to
1527120	1531440	be interested in color for some reason or other, if you're a fashion designer or an artist or something,
1531440	1537120	you may have many, many more words. But we can see millions, like if you have normal color vision,
1537120	1541680	normal trichrometric color vision, you can see millions of distinctions in color. So we don't
1541680	1546800	have millions of words. You know, the most efficient, no, the most, you know, detailed color
1546800	1551600	vocabulary would have over a million terms to distinguish all the different colors that we
1551600	1557440	can see. But of course, we don't have that. So it's somehow, it's been, it's kind of useful
1557440	1563280	for English to have evolved in some way to, there's 11 terms that people find useful to talk about,
1563280	1570720	you know, black, white, red, blue, green, yellow, purple, gray, pink, and I probably miss something
1570720	1576080	there. Anyway, there's 11 that everyone knows. And depending on your, but you go to different
1576080	1581840	cultures, especially the non industrialized cultures, and there'll be many fewer. So some cultures
1581840	1589280	will have only two, believe it or not, that the Danai and Papua New Guinea have only two labels
1589280	1594400	that the group uses for color. And those are roughly black and white. They are very, very dark
1594400	1598400	and very, very light, which are roughly black and white. And you might think, oh, they're dividing
1598400	1602720	the whole color space into, you know, light and dark or something. And that's not really true.
1602720	1606880	They mostly just only label the light, the black and the white things. They just don't talk about
1606880	1611360	the colors for the other ones. And so, and then there's other groups, I worked with a group called
1611360	1618560	the Chimani down in, in Bolivia, in South America, and they have three words that everyone knows,
1618560	1624720	but there's a few others that are, that, that several people, that many people know. And so,
1624720	1630000	they have made, it's kind of depending on how you count between three and seven words that
1630000	1636240	the group knows. Okay. And again, they're black and white. Everyone knows those. And red, red is,
1636240	1641360	you know, like that tends to be the third word that everyone, that cultures bring in, if there's
1641360	1645360	a word, it's always red, the third one. And then after that, it's kind of all bets are off
1645360	1651120	about what they bring in. And so after that, they bring in a sort of a big blue, green space group,
1651120	1656160	group, they have one for that. And then they have, and then, you know, different people have
1656160	1661440	different words that they'll use for other parts of the space. And so anyway, it's probably related
1661440	1666160	to what they want to talk, what they, not what they, not what they see, because they see the
1666160	1673120	same colors as we see. So it's not like they have, they don't, they have a weak, a low color palette
1673120	1678080	and the things they're looking at, they're looking at a lot of beautiful scenery. Okay. A lot of
1678080	1684000	different colored flowers and berries and things. And you know, and so there's lots of things of
1684000	1689680	very bright colors, but they just don't label the color in those cases. And the reason probably,
1689680	1695280	we don't know this, but we think probably what's going on here is that what you do, why you label
1695280	1700080	something is you need to talk to someone else about it. And why do I need to talk about a color?
1700080	1706160	Well, if I have two things which are identical, and I want you to give me the one that's different,
1706160	1711360	and in the only way it varies is color, then I invent a word, which tells you, you know,
1711360	1715520	this is the one I want. So I want the red sweater off the rack, not the green sweater, right?
1715520	1720240	There's two. And so those things will be identical, because these are things we made and they're
1720240	1724880	dyed, and there's nothing different about them. And so in industrialized society, we have,
1725760	1729680	you know, everything, everything we've got is pretty much arbitrarily colored.
1730400	1734880	But if you go to a non-industrialized group, that's not true. And so they don't,
1734880	1738400	suddenly they're not interested in color. If you bring bright colored things to them,
1738400	1742560	they like them just like we like them. Bright colors are great. They're beautiful.
1743760	1747040	But they just don't need to, nobody to talk about them. They don't have.
1747040	1753120	So probably color words is a good example of how language evolves from sort of function,
1753120	1755680	when you need to communicate the use of something.
1755680	1756320	I think so.
1756320	1762160	Then you kind of invent different variations. And basically, you can imagine that the evolution
1762160	1767200	of a language has to do with what the early tribes doing, like what they want it, what kind
1767200	1771280	of problems they're facing them, and they're quickly figuring out how to efficiently communicate
1772160	1776320	the solution to those problems, whether it's aesthetic or function, all that kind of stuff,
1776320	1781920	running away from a mammoth or whatever. But you know, it's, so I think what you're pointing to
1781920	1787200	is that we don't have data on the evolution of language, because many languages have formed
1787200	1790000	a long time ago. So you don't get the chatter.
1790000	1795760	We have a little bit of like old English to modern English, because there was a writing system.
1795840	1800000	And we can see how old English looked. So the word order changed, for instance,
1800000	1803600	in old English to middle English to modern English. And so it, you know, we could see
1803600	1808400	things like that, but most languages don't even have a writing system. So of the 7000,
1808960	1813360	only, you know, a small subset of those have a writing system. And even if they have a writing
1813360	1817280	system, they, it's not a very modern writing system. And so they don't have it. So we just
1817280	1822320	basically have for Mandarin, for Chinese, we have a lot of, a lot of evidence from,
1822880	1827040	for long time and for English and not for much else, not from in German a little bit,
1827040	1832000	but not for a whole lot of like long-term language evolution. We don't have a lot.
1832000	1834720	Well, you can have snapshots is what we've got of current languages.
1834720	1839440	Yeah, you get an inkling of that from the rapid communication and certain platforms,
1839440	1843840	like on Reddit, there's different communities, and they'll come up with different slang,
1843840	1849600	usually from my perspective, German by a little bit of humor, or maybe mockery or whatever,
1850160	1856000	you know, just talking shit in different kinds of ways. And you could see the evolution
1856880	1864800	of language there. Because I think a lot of things on the internet, you don't want to be the boring
1864800	1872480	mainstream. So you like want to deviate from the proper way of talking. And so you get a lot of
1872480	1878480	deviation, like rapid deviation, then when communities collide, you get like, just like you
1878480	1882480	said, humans adapt to it. And you can see it through the lens of humor. I mean, it's very
1882480	1886480	difficult to study, but you can imagine like a hundred years from now, well, if there's a new
1886480	1889920	language born, for example, we'll get really high resolution data on.
1889920	1894480	I mean, English is changing. English changes all the time. All languages change all the time. So,
1895120	1902400	you know, it's a famous result about the Queen's English. So if you look at the Queen's vowels,
1902400	1907440	the Queen's English is supposed to be, you know, originally the proper way for the talk was sort
1907440	1912960	of defined by whoever the Queen talked, or the King, whoever was in charge. And so if you look
1912960	1920080	at how her vowels changed from when she first became Queen in 1952 or 1953, when she was
1920080	1924640	coronated, the first, I mean, that's Queen Elizabeth, who died recently, of course, until,
1924640	1929200	you know, 50 years later, her vowels changed, her vowels shifted a lot. And so that, you know,
1929200	1935600	even in the sounds of British English, in her, the way she was talking was changing. The vowels
1935600	1940080	were changing slightly. So that's just, in the sounds, there's change. I don't know what's, you
1940080	1944720	know, we're, I'm interested. We're all interested in what's driving any of these changes. The
1944720	1949520	word order of English changed a lot over a thousand years, right? So it used to look like
1949520	1954880	German. You know, it used to be a verb final language with case marking, and it shifted
1954880	1960320	to a verb-medial language, a lot of contact. So a lot of contact with French. And it became a verb
1960320	1965680	medial language with no case marking. And so it became this, you know, verb, verb initially thing.
1965680	1971520	So, and so that's, it totally evolved. And so it may very well, I mean, you know, it doesn't evolve
1971520	1976320	maybe very much in 20 years is maybe what you're talking about. But over 50 and 100 years, things
1976320	1982800	change a lot, I think. We'll now have good data, which is great. Can you talk to what is syntax
1982800	1988080	and what is grammar? So you wrote a book on syntax. I did. You were asking me before about what,
1988080	1992640	you know, how do I figure out what a dependency structure is? I'd say the dependency structures
1992640	1996880	aren't that hard to generally, I think it's a lot of agreement of what they, of what they are
1996880	2000960	for almost any sentence in most languages. I think people will agree on a lot of that.
2002400	2007920	There are other parameters in the mix such that some people think there's a more complicated
2007920	2011760	grammar than just a dependency structure. And so, you know, like Noam Tromsky,
2011760	2020000	he's the most famous linguist ever. And he is famous for proposing a slightly more complicated
2020000	2026480	syntax. And so he invented phrase structure grammar. So he's well known for many, many
2026480	2032080	things. But in the 50s, in the early 60s, like the late 50s, he was basically figuring out what's
2032080	2038960	called formal language theory. So, and he figured out sort of a framework for figuring out how
2038960	2043600	complicated language, you know, a certain type of language might be, so-called phrase structure
2043600	2051600	grammars of language might be. And so he, his, his idea was that maybe we can, we can think
2051600	2056720	about the complexity of a language by how complicated the rules are. Okay. And the rules
2057440	2062800	will look like this. They will have a left-hand side and they'll have a right-hand side. Something
2062800	2066000	will, on the left-hand side, will expand to the thing on the right-hand side. So we'll say we'll
2066000	2071520	start with an S, which is like the root, which is a sentence. Okay. And then we're going to expand
2071520	2077200	to things like a noun phrase and a verb phrase is what he would say, for instance. Okay. And S
2077200	2082000	goes to an NP and a VP is a kind of a phrase structure rule. And then we figure out what an NP
2082000	2087680	is. An NP is a determiner and a noun, for instance. And verb phrase is something else,
2087680	2092400	is a verb and another noun phrase and another NP, for instance. Those are the rules of a very
2092480	2099440	simple phrase structure. Okay. And, and so he, he proposed phrase structure grammar as a way to
2099440	2104160	sort of cover human languages. And then he actually figured out that, well, depending on the formalization
2104160	2108480	of those grammars, you might get more complicated or less complicated languages. And so you could,
2108480	2113200	he could, he said, well, you, these are, these are things called, you know, context-free languages,
2113200	2117520	that rule that he thought, you know, human languages tend to be what he calls context-free
2117520	2123040	languages. And, but there are simpler languages, which are so-called regular languages, and they
2123040	2128080	have a more, a more constrained form to the rules of the, of the phrase structure of, of these
2128080	2135200	particular rules. So he, he basically discovered and kind of invented ways to describe the language.
2135200	2139280	And though, and those are phrase, those are phrase structure, a human language. And he was
2139280	2143120	mostly interested in English initially in his, his work in the 50s.
2143120	2148080	So quick questions around all this. So formal language theory is the big field of just studying
2148080	2152000	language formally. Yes. And it doesn't have to be human language there. We can have a computer
2152000	2161600	languages, any kind of system, which is generating a, some set of expressions in a language. And
2161600	2168080	those could be like the, the, you know, the statements in a computer language, for example.
2168080	2171600	So it could be that, or it could be human language. So technically, you can study
2171600	2176160	programming languages. Yes. And have been, I mean, heavily studied using this formalism.
2176160	2180640	There, there's a big field of programming languages within the formal language.
2180640	2186480	Okay. And then phrase structure grammar is this idea that you can break down language into this
2186480	2193520	SNP, VP, like type of thing. It's a particular formalism for describing language. Okay. So
2193520	2197360	and, and Chomsky was the first one, he's the one who figured that stuff out back in the 50s.
2197360	2203040	And, and, and, but he, and, and that's equivalent. Actually, the context free grammar is actually
2203040	2207280	is kind of equivalent in the sense that it generates the same sentences as a dependency
2207280	2212080	grammar would, you know, as the dependency grammar is a little simpler in some way. You just have
2212080	2217520	a root and it goes like, we don't have any of these, the rules are implicit, I guess, in,
2217520	2221200	in, we just have connections between words. The free structure grammars are kind of a different
2221200	2226400	way to think about the, the dependency grammar. It's slightly more complicated, but it's kind
2226400	2232480	of the same in some ways. So to clarify, dependency grammar is the framework under
2232480	2237200	which you see language. And you make a case that this is a good way to describe the language.
2237200	2244080	That's correct. And no, no Chomsky is watching this is very upset right now. So let's just kidding.
2244080	2251600	But what's the difference between where's the place of disagreement between phrase structure
2251600	2255760	grammar and dependency grammar? They're very close. So free structure grammar and dependency
2255760	2261600	grammar aren't that, aren't that far apart. I like dependency grammar, because it's more
2261600	2266000	perspicuous, it's more transparent about representing the connections between the words.
2266000	2269600	It's just a little harder to see in phrase structure grammar, you know, the place where
2269600	2275520	Chomsky sort of devolved or went off from, from, from this is he also thought there was
2276720	2281280	something called movement. Okay. And so, and so, and that's where we disagree. Okay, that's the
2281280	2284960	place where I would say we disagree. And, and, and I mean, well, maybe we'll get into that later.
2284960	2289520	But the idea is, if you want to, do you want me to explain that? No, I would love to explain
2289520	2294320	movement. Okay, so you're saying so many interesting things. Okay, so here's the movement is
2294320	2299920	Chomsky basically sees English. And he says, okay, I said, you know, we had that sentence
2299920	2303120	early, like it was like two dogs entered the room, it's changed a little bit, say,
2303120	2308720	two dogs will enter the room. And he notices that, hey, English, if I want to make a question,
2309360	2313840	yes, no question from that same sentence, I say, instead of two dogs will enter the room,
2313840	2319280	I say, will two dogs enter the room? Okay, there's a different way to say the same idea.
2319280	2324000	And it's like, well, the auxiliary verb that will thing, it's at the front as opposed to
2324000	2328480	in the middle. Okay. And so, and he looked, you know, if you look at English, you see that
2328480	2333200	that's true for all those modal verbs. And for other kinds of auxiliary verbs in English,
2333200	2338000	you always do that, you always put an auxiliary verb at the front. And, and what he's, when he
2338000	2343600	saw that, so, you know, if I say, I can win this bet, can I win this bet, right? So I move a can
2343600	2348880	to the front. So actually, that's a theory, I just gave you a theory there, he talks about it as
2348880	2354480	movement, that word in the declarative is the root, is the sort of default way to think about
2354480	2359120	the sentence, and you move the auxiliary verb to the front, that's a movement theory. Okay,
2359120	2365120	he said, and he just thought that was just so obvious that it must be true, that there's nothing
2365120	2370880	more to say about that, that this is how auxiliary verbs work in English. There's a movement rule,
2371520	2375440	such that you're moved, like to get from the declarative to the interrogative, you're moving
2375440	2380000	the auxiliary to the front. And it's a little more complicated as soon as you go to simple,
2380000	2384320	simple present and simple past, because, you know, if I say, you know, John slept, you have to say,
2384880	2390000	did John sleep, not slept John, right? And so you have to somehow get an auxiliary verb, and I
2390000	2395200	guess underlyingly, it's like slept is, it's a little more complicated than that, but that's his
2395200	2399920	idea, there's a movement, okay? And so a different way to think about that, that isn't, I mean,
2400480	2405360	he ended up showing later. So he proposed this theory of grammar, which has movement, and there's
2405360	2410400	other places where he thought there's movement, not just auxiliary verbs, but things like the passive
2410400	2415840	in English, and things like questions, WH questions, a bunch of places where he thought
2415840	2421120	there's also movement going on. And each one of those, he thinks there's words, well, phrases
2421120	2424720	and words are moving around from one structure to another, which he called deep structure to
2424720	2428720	surface structure. I mean, there's like two different structures in his theory, okay?
2429600	2435040	There's a different way to think about this, which is there's no movement at all. There's a
2435040	2441760	lexical copying rule, such that the word will or the word can, these auxiliary verbs, they just
2441760	2446560	have two forms. And one of them is the declarative, and one of them is the interrogative. And you
2446560	2451520	basically have the declarative one, and oh, I form the interrogative, or I can form one from
2451520	2456400	the other, doesn't matter which direction you go. And I just have a new entry, which has the same
2456400	2461920	meaning, which has a slightly different argument structure, argument structure, it's a fancy word
2461920	2469200	for the ordering of the words. And so if I say, you know, it was the dogs, two dogs can or will
2469200	2477120	enter the room. There's two forms of will. One is will declarative. And then, okay, I've got my
2477120	2482160	subject to the left, it comes before me, and the verb comes after me in that one. And then
2482160	2487440	the will interrogative is like, oh, I go first, interrogative will is first, and then I have
2487440	2491600	the subject immediately after, and then the verb after that. And so you just, you can just
2491600	2496160	generate from one of those words, another word with a slightly different argument structure
2496240	2501520	with different ordering. And these are just lexical copies. They're not necessarily moving
2501520	2505360	from one to another. There's no movement. There's a romantic notion that you have one
2506160	2511680	main way to use a word, and then you could move it around, which is essentially what
2511680	2518240	movement is applying. Yeah, but that's the lexical copying is similar. So then we do lexical copying
2518240	2523600	for that same idea that maybe the declarative is the source, and then we can copy it. And so
2523680	2529120	an advantage, there's multiple advantages of the lexical copying story. It's not my story. This is
2529120	2536080	like Ivan Sog, a bunch of linguists have been proposing these stories as well in tandem with
2536080	2542480	the movement story. Ivan Sog died a while ago, but he was one of the proponents of the
2542480	2548720	non-movement of the lexical copying story. And so that is that a great advantage is, well,
2549440	2557840	Chomsky, really famously in 1971, showed that the movement story leads to learnability problems.
2557840	2564320	It leads to problems for how language is learned. It's really, really hard to figure out what the
2564320	2568720	underlying structure of a language is if you have both phrase structure and movement. It's like
2568720	2573440	really hard to figure out what came from what. There's like a lot of possibilities there. If
2573440	2578320	you don't have that problem, the learning problem gets a lot easier. Just say there's lexical copies.
2579680	2582960	Well, we say the learning problem. Do you mean like humans learning a new language?
2582960	2588240	Yeah, just learning English. So baby is lying around, listening to the crib, listening to me talk,
2588240	2592640	and how are they learning English? Or maybe it's a two-year-old who's learning
2593200	2599040	interrogatives and stuff. How are they doing that? Are they doing it from like, are they figuring out?
2600400	2604560	So Chomsky said it's impossible to figure it out, actually. He said it's actually impossible,
2605200	2610400	not hard, but impossible. And therefore, that's where universal grammar comes from,
2610400	2616800	is that it has to be built in. And so what they're learning is that there's some built-in movement
2616800	2623440	is built in in his story is absolutely part of your language module. And then you are,
2624080	2628080	you're just setting parameters. You're set, depending on English, is just sort of a variant
2628080	2633040	of the universal grammar. And you're figuring out, oh, which orders does English do these things?
2633600	2640640	The non-movement story doesn't have this. It's like much more bottom-up. You're learning rules.
2640640	2645360	You're learning rules one by one. And, oh, this word is connected to that word.
2646800	2650720	Another advantage, it's learnable. Another advantage of it is that it predicts
2651280	2656160	that not all auxiliary might move. Like, it might depend on the word, depending on whether you,
2656720	2663520	and that turns out to be true. So there's words that don't really work as auxiliary.
2663520	2669440	They work in declarative and not in interrogative. So I can say, I'll give you the opposite first.
2669440	2674560	I can say, aren't I invited to the party? Okay. And that's an interrogative form,
2675280	2680480	but it's not from, I aren't invited to the party. There is no I aren't, right? So that's
2680560	2687760	interrogative only. And then we also have forms like ought. I ought to do this.
2688560	2691040	And I guess some British, old British people can say,
2691920	2696240	exactly. It doesn't sound right, does it? For me, it sounds ridiculous. I don't even
2696240	2699920	think ought is great, but I mean, I totally recognize I ought to do it. It's not too bad,
2699920	2702080	actually. I can say ought to do this. That sounds pretty good.
2702080	2706080	If I'm trying to sound sophisticated, maybe. I don't know. It just sounds completely out of
2706960	2712720	to me. Anyway, so there are variants here. And a lot of these words just work in one
2712720	2717200	versus the other. And that's fine under the lexical copying story. It's like, well,
2717200	2723520	you just learned the usage. Whatever the usage is, is what you do with this word.
2723520	2727760	But it doesn't, it's a little bit harder in the movement story. The movement story,
2727760	2731520	like that's an advantage, I think, of lexical copying. And in all these different places,
2731840	2739760	there's all these usage variants which make the movement story a little bit harder to work.
2739760	2743600	So one of the main divisions here is the movement story versus the lexical copy story
2743600	2748960	that has to do about the auxiliary words and so on. But if you're relying to the phrase
2748960	2754880	structure grammar versus dependency grammar. Those are equivalent in some sense in that
2754880	2759920	for any dependency grammar, I can generate a free structure grammar which generates
2759920	2767280	exactly the same sentences. I just like the dependency grammar formalism because it makes
2767280	2773520	something really salient, which is the lengths of dependencies between words, which isn't so
2773520	2777680	obvious in the phrase structure. In the phrase structure, it's just kind of hard to see. It's
2777680	2784000	in there. It's just very opaque. Technically, I think phrase structure grammar is mappable to
2784000	2788800	dependency grammar. And vice versa. And vice versa. But there's like these little labels,
2788880	2794080	S and PVP. Yeah. For a particular dependency grammar, you can make a phrase structure grammar
2794080	2798960	which generates exactly those same sentences and vice versa. But there are many phrase
2798960	2803680	structure grammars which you can't really make a dependency grammar. I mean, you can do a lot
2803680	2808880	more in a phrase structure grammar. You get many more of these extra nodes, basically. You can
2808880	2814800	have more structure in there. And some people like that. And maybe there's value to that. I don't
2814800	2821360	like it. Well, for you, we should clarify. So dependency grammar, it's just one word depends
2821360	2828240	on only one other word and you form these trees. And that makes, it really puts priority on those
2828240	2833440	dependencies just like as a tree that you can then measure the distance of the dependency
2833440	2838960	from one word to the other. They can then map to the cognitive processing of the
2839760	2844000	of these sentences, how well how easy is to understand all that kind of stuff. So it just
2844000	2852400	puts the focus on just like the mathematical distance of dependence between words. So like
2852400	2857120	it's just a different focus. Absolutely. Just continue on a thread of Chomsky because it's
2857120	2862800	really interesting because it as you're discussing disagreement, to the degree there's
2862800	2866640	disagreement, you're also telling the history of the study of language, which is really awesome.
2867520	2873760	So you mentioned context free versus regular. Does that distinction come into play for dependency
2873760	2880400	grammars? No, not at all. I mean, regular languages are too simple for human languages.
2882240	2888160	It's a part of the hierarchy, but human languages are in the phrase structure world are definitely,
2889920	2895600	at least context free, maybe a little bit more, a little bit harder than that. So there's something
2895600	2900960	called context sensitive as well, where you can have like this is the just the formal language
2900960	2907920	description. In a context free grammar, you have one, this is like a bunch of like formal language
2907920	2912400	theory we're doing here. I love it. Okay. So you have you have a left hand side category and
2912400	2917280	you're expanding to anything on the right is a, that's a context free. So like the idea is that
2917280	2921920	that category on the left expands in independent of context to those things, whatever they're on
2921920	2929040	the right. It doesn't matter what. And a context sensitive says, okay, I actually have more than
2929040	2932960	one thing on the left. I can tell you only in this context, you know, I have maybe you have
2932960	2937040	like a left and a right context or just a left context or a right context, I have two or more
2937040	2941920	stuff on the left tells you how to expand that those things in that way. Okay. So it's context
2941920	2948480	sensitive. A regular language is just more constrained. And so it, it doesn't allow anything
2948480	2954720	on the right. It allows very, it allows basically it's a one very complicated rule is kind of what
2955280	2961520	a regular language is. And so it doesn't have any, let's just say long distance dependencies,
2961520	2966400	it doesn't allow recursion, for instance, there's no recursion. Yeah, recursion is where you,
2966400	2970560	which is human languages have recursion, they have embedding. And you can't, well, it doesn't
2970560	2975040	allow center embedded recursion, which human languages have, which is what center embedded
2975120	2978400	recursion, within a sentence, within a sentence. Yeah, within a sentence. So here we're going to
2978400	2982960	get to that. But I, you know, the formal language stuff is a little aside, Chomsky wasn't proposing
2982960	2988000	it for human languages, even he was just pointing out that human languages are context free. And
2988000	2992080	then he was most in for, for human, because that was kind of stuff we did for formal languages.
2992080	2997280	And what he was most interested in was human language. And that's like the, the movement is
2997280	3003200	where we, we, we, where, where he sort of set off in on the, I would say a very interesting,
3003840	3006800	but wrong foot. It was kind of interesting. It's a very, I agree. It's kind of,
3006800	3011840	it's very interesting history. So there's a set, he proposed this multiple theories in 57,
3011840	3015440	and then 65, they're, they all have this framework, though, was phrase structure,
3015440	3019520	plus movement, different versions of the, of the phrase structure and the movement in the 57.
3019520	3024240	This is the most famous original bits of Chomsky's work. And then 71 is when he figured out that
3024240	3030240	those lead to learning problems, that, that there's cases where a kid could never figure out
3030880	3036720	which rule, which set of rules was intended. And, and so, and then he said, well, that means it's
3036720	3041520	innate. It's kind of interesting. He just really thought the movement was just so obviously true
3041520	3046960	that he couldn't, he didn't even entertain giving it up. It's just obvious that that's obviously
3046960	3053440	right. And it was later where people figured out that there's all these like subtle ways in which
3053440	3057120	things would, which look like generalizations aren't generalizations. And they, you know,
3057120	3061520	across the category, they're, they're word specific and they have, and they, they kind of
3061520	3065280	work, but they don't work across various other words in the category. And so it's easier to just
3065280	3070560	think of these things as lexical copies. And, and I think he was very obsessed. I don't know. I'm
3070560	3076240	just guessing that he just, he really wanted this story to be simple in some sense. And language
3076240	3081440	is a little more complicated in some sense, you know, he didn't like words. He never talks about
3081440	3085920	words. He likes to talk about combinations of words and words are, you know, look up a dictionary,
3085920	3092080	there's 50 senses for a common word, right? The word take will have 30 or 40 senses in it. So,
3092640	3097760	there'll be many different senses for common words. And he just doesn't think about that. It's, or
3097760	3102400	he doesn't think that's language. I think he doesn't think that's language. He thinks that
3102400	3109520	words are distinct from combinations of words. I think they're the same. If you look at my brain
3109680	3116400	in the scanner, while I'm listening to a language I understand, and you compare, I can localize my
3116400	3120560	language network in a few minutes, in like 15 minutes. And what you do is I listen to a language
3120560	3126400	I know, I listen to, you know, maybe some language I don't know, or I listen to muffled speech, or I
3126400	3130960	read sentences, or I read non words, like I do anything like this, anything that sort of really
3130960	3135040	like English and anything that's not very like English. So I've got something like it and not,
3135040	3141840	and I got to control. And the voxels, which is just, you know, the 3D pixels in my brain
3141840	3150480	that are responding most is a language area. And that's this left lateralized area in my head. And
3151360	3156240	wherever I look in that network, if you look for the combinations versus the words, it's
3157280	3162320	everywhere. It's the same. That's fascinating. And so it's like hard to find, there are no areas
3162320	3168880	that we know. I mean, that's a little overstated right now. At this point, the technology isn't
3168880	3174160	great. It's not bad. But we have the best way to figure out what's going on in my brain when I'm
3174160	3179040	listening or reading language is to use fMRI, Functional Magnetic Resonance Imaging. And
3179040	3184480	that's a very good localization method. So I can figure out where exactly these signals are coming
3184480	3189040	from pretty, you know, down to, you know, millimeters, cubic millimeters are smaller,
3189040	3194240	okay? Very small. We can figure those out very well. The problem is the when, okay? It's measuring
3195200	3200320	oxygen, okay? And oxygen takes a little while to get to those cells. And so it takes on the
3200320	3205120	order of seconds. So I talk fast. I probably listened fast and I can probably understand
3205120	3210160	things really fast. So a lot of stuff happens in two seconds. And so to say that we know what's
3210160	3216640	going on, that the words right now in that network, our best guess is that whole network
3216640	3222080	is doing something similar, but maybe different parts of that network are doing different things.
3222080	3227040	And that's probably the case. We just don't have very good methods to figure that out right at
3227040	3233040	this moment. And so since we're kind of talking about the history of the study of language,
3233920	3238800	what other interesting disagreements, and you're both at MIT or were for a long time,
3238800	3243200	what kind of interesting disagreements there, attention of ideas are there between you and
3243200	3248400	Noam Chomsky. And we should say that Noam was in the linguistics department. And you're,
3249840	3255200	I guess, for a time were affiliated there, but primarily brain and cognitive science department,
3255760	3260320	which is another way of studying language. And you've been talking about fMRI. So like what,
3260960	3266240	is there something else interesting to bring to the surface about the disagreement between the two
3266240	3273680	of you or other people in the industry? Yeah, I mean, I've been at MIT for 31 years since 1993,
3273680	3280880	and Chomsky's been there much longer. So I met him, I knew him, I met when I first got there,
3280880	3287760	I guess, and we would interact every now and then. I'd say that, so I'd say our biggest difference
3287760	3294560	is our methods. And so that's the biggest difference between me and Noam, is that I
3295280	3301440	gather data from people. I do experiments with people and I gather corpus data, whatever,
3301440	3305680	whatever corpus data is available, and we do quantitative methods to evaluate
3306480	3313520	any kind of hypothesis we have. He just doesn't do that. And so, you know, he has never once been
3313520	3319360	associated with any experiment or corpus work ever. And so it's all thought experiments,
3319360	3323360	it's his own intuitions. So I just don't think that's the way to do things.
3324880	3329360	That's a, you know, across the street, they're across the street from us, kind of difference
3329360	3334160	between brain and cog sci and linguistics. I mean, not all linguists, some of the linguists,
3334160	3338960	depending on what you do, more speech oriented, they do more quantitative stuff. But in the
3339840	3345520	meaning, words and, well, it's combinations of words, syntax, semantics, they tend not to do
3346080	3352560	experiments and corpus analyses. So I know in linguistics size, probably, well,
3352560	3358640	but the method is a symptom of a bigger approach, which is sort of a psychology philosophy side on
3358640	3363520	Nome. And for you, it's more sort of data driven, sort of almost like mathematical approach.
3363520	3368160	Yeah, I mean, I'm a psychologist. So I would say we're in psychology. You know, I mean,
3368160	3372720	brain and cognitive sciences is MIT's old psychology department. It was a psychology
3372720	3377040	department up until 1985, and it became the brain and cognitive science department. And so,
3377600	3381440	I mean, my training is in psychology, I mean, my training is math and computer science, but I'm
3381440	3384320	a psychologist. I mean, I mean, I don't know what I am.
3384320	3386400	So data driven, psychologist. Yeah, yeah, yeah.
3386400	3390640	You are. I am what I am, but I'm having to be called a linguist. I'm having to be called a
3390640	3393760	computer scientist. I'm having to be called a psychologist, any of those things.
3393760	3398800	But in the actual, like how that manifests itself outside of the methodology is like these
3398800	3403760	differences, these subtle differences about the movement story versus the lexical copy story.
3403760	3408640	Yeah, those are theories, right? So the theories, like the theories are, but I think the reason
3408640	3414800	we differ in part is because of how we evaluate the theories. And so I evaluate theories quantitatively,
3414800	3422880	and Nome doesn't. Got it. Okay, well, let's let's explore the theories that you explore in your
3422880	3430960	book. Let's return to this dependency grammar framework of looking at language. What's a good
3430960	3434560	justification why the dependency grammar framework is a good way to explain language?
3435280	3439840	What's your intuition? So the reason I like dependency grammar, as I've
3440560	3446000	said before, is that it's very transparent about its representation of distance between words.
3446000	3451120	So it's like, all it is, is you've got a bunch of words, you're connecting them together to make a
3451120	3460160	sentence. And a really neat insight, which turns out to be true, is that the further apart the pair
3460160	3463680	of words are that you're connecting the harder it is to do the production, the harder it is to
3463680	3467120	do the comprehension. It's as hard to produce, it's hard to understand when the words are far
3467120	3472240	apart. When they're close together, it's easy to produce and it's easy to comprehend. Let me
3472240	3480160	give you an example. Okay, so we have, in any language, we have mostly local connections between
3480160	3484960	words, but they're abstract. The connections are abstract, they're between categories of words.
3484960	3492400	And so you can always make things further apart if you add modification, for example,
3492400	3499040	after a noun. So a noun in English comes before a verb, the subject noun comes before a verb,
3499040	3504000	and then there's an object after, for example. So I can say what I said before, the dog entered
3504000	3509200	the room or something like that. So I can modify dog. If I say something more about dog after it,
3509200	3516240	then what I'm doing is, indirectly, I'm lengthening the dependence between dog and entered by adding
3516240	3526400	more stuff to it. So I just make it explicit here if I say the boy who the cat scratched
3527040	3532480	cried. We're going to have a mean cat here. And so what I've got here is, the boy cried,
3532480	3537680	it would be a very short, simple sentence, and I just told you something about the boy,
3537680	3541040	and I told you it was the boy who the cat scratched. Okay.
3541040	3545840	So the cry is connected to the boy. The cry at the end is connected to the boy in the beginning.
3545840	3549600	Right. And so I can do that. And I can say that that's a perfectly fine English sentence.
3549600	3557680	And I can say the cat which the dog chased ran away or something. Okay. I can do that.
3557680	3562880	But it's really hard. So it's really hard now. I've got whatever I have here. I have the boy
3563600	3570720	who the cat. Now let's say I try to modify cat. Okay. The boy who the cat which the dog
3570800	3575680	chased scratched ran away. Oh my God, that's hard, right? I can, I'm sort of just working
3575680	3580480	that through in my head how to produce and how to, and it's really just horrendous to understand.
3580480	3584480	It's not so bad. At least I've got intonation there to sort of mark the boundaries and stuff.
3584480	3590400	But it's, that's really complicated. That's sort of English in a way. I mean, that follows the
3590400	3595280	rules of English. But so what's interesting about that is, is that what I'm doing is nesting
3595280	3601280	dependencies there. I'm putting one, I've got a subject connected to a verb there. And then I'm
3601280	3606160	modifying that with a clause, another clause, which happens to have a subject and a verb relation.
3606160	3611200	I'm trying to do that again on the second one. And what that does is it lengthens out the dependence,
3611200	3615200	multiple dependence actually get lengthened out there. The dependencies get longer,
3615200	3619600	on the outside ones get long. And even the ones in between get kind of long. And you just,
3619600	3625040	so what's fascinating is that that's bad. That's really horrendous in English.
3625920	3630320	But that's horrendous in any language. And so in, in no matter what language you look at,
3630320	3635680	if you do just figure out some structure where I'm going to have some modification following
3635680	3639920	some head, which is connected to some later head, and I do it again, it won't be good.
3639920	3645280	It guaranteed like 100% that will be uninterpretable in that language in the same way that was
3645280	3650320	uninterpretable in English. Just clarify, the distance of the dependencies is whenever
3651280	3659200	the boy cried, there's a dependence between two words. And then you counting the number of what
3659200	3664880	morphemes between them. That's a good question. I just say words. Your words are morphemes between.
3664880	3668080	We don't know that. Actually, that's a very good question. What is the distance metric?
3668080	3673520	But let's just say it's words. Sure. And you're saying the longer the distance of that dependence,
3673520	3682880	the more no matter the language, except legalese. Even legalese. We'll talk about it. Okay. But that,
3684320	3688480	the people will be very upset that speak that language, not upset, but they'll either not
3688480	3693760	understand it. They'll be like, this is, their brain will be working in overtime.
3693760	3697520	They will have a hard time either producing or comprehending it. They might tell you that's not
3697520	3702320	their language. It's sort of the language. I mean, it's following, they'll agree with each of those
3702320	3707360	pieces as part of the language. But somehow that combination will be very, very difficult to produce
3707360	3713120	and understand. Is that a chicken or the egg issue here? Well, I'm giving you an explanation.
3716240	3719360	I'm giving you two kinds of explanations. I'm telling you that center embedding,
3719360	3725360	that's nesting, those are synonyms for the same concept here. And the explanation for what,
3725360	3728400	those are always hard. Center embedding and nesting are always hard. And I give you an
3728400	3732240	explanation for why they might be hard, which is long distance connections. There's a
3732320	3736240	when you do center embedding, when you do nesting, you always have long distance connections between
3736240	3741760	the dependents. That's not necessarily the right explanation. I can go through reasons why that's
3741760	3747760	probably a good explanation. And it's not really just about one of them. So probably it's a pair
3747760	3753280	of them or something of these dependents that get long, that drives you to be really confused
3753280	3759680	in that case. And so what the behavioral consequence there, I mean, this is kind of methods,
3759680	3764320	like how do we get at this? You could try to do experiments to get people to produce these things.
3764320	3767440	They're going to have a hard time producing them. You can try to do experiments to get them to
3767440	3773120	understand them and see how well they understand them, can they understand them. Another method you
3773120	3779600	can do is give people partial materials and ask them to complete them, those center embedded
3779600	3783840	materials and they'll fail. So I've done that. I've done all these kinds of things.
3784800	3790320	Wait a minute. So central embedding, meaning like you take a normal sentence like boy cried and
3790320	3796000	inject a bunch of crap in the middle that separates the boy and the cried. Okay, that's
3796000	3800240	central bedding and nesting is on top of that. No, nesting is the same thing. Center embedding,
3800240	3804000	those are totally equivalent terms. I'm sorry, I sometimes use one and sometimes use the other.
3804000	3810880	Got it. Got it. And then what you're saying is there's a bunch of different kinds of experiments
3810880	3815440	you can do. I mean, I like to understand one is like have more embedding, more central bedding,
3815440	3819120	is it easier or harder to understand, but then you have to measure the level of understanding,
3819120	3823360	I guess. Yeah, you could. I mean, there's multiple ways to do that. I mean, there's the simplest
3823360	3828000	ways just to ask people, how good is it sound? How natural is this sound? That's a very blunt,
3828000	3832800	but very good measure. It's very, very reliable. People will do the same thing. And so it's like,
3832800	3836560	I don't know what it means exactly, but it's doing something such that we're measuring something
3836560	3840160	about the confusion, the difficulty associated with those. And those like those are giving you
3840240	3845440	signal. That's why you can say that. What about the completion of the central bed?
3845440	3854400	So if you give them a partial sentence, say I say the book which the author who, and I ask you to
3854400	3858880	now finish that off for me, I mean, either say it, but you can just say it's written in front
3858880	3863120	of you and you can just type and have as much time as you want. They will, even though that one's
3863120	3868480	not too hard, right? So if I say it's like the book is like, oh, the book which the author who I
3868480	3875040	met wrote was good. That's a very simple completion for that. If I give that completion
3875040	3881040	on online somewhere to a crowdsourcing platform and ask people to complete that,
3881040	3886480	they will miss off a verb very regularly, like half of the time, maybe two thirds of the time.
3886480	3890320	They'll say, they'll just leave off one of those verb phrases. Even with that simple so to say,
3890320	3900000	the book which the author who, and they'll say was, you need three verbs, right? I need three
3900000	3906880	verbs are who I met wrote was good, and they'll give me two. They'll say who was famous was good
3906880	3912240	or something like that. They'll just give me two. And that'll happen about 60% of the time. So 40%,
3912240	3916960	maybe 30%, they'll do it correctly, correctly, meaning they'll do a three verb phrase. I don't
3917040	3920160	know what's correct or not. This is hard. It's a hard task.
3920160	3922240	Yeah. I can actually, I'm struggling with it in my head.
3922240	3925120	Yeah. Well, it's easier when you look at it.
3925120	3928880	If you look at it a little easier, then listening is pretty tough because you have to,
3928880	3933280	because there's no trace of it. You have to remember the words that I'm saying,
3933280	3937200	which is very hard auditorily. We wouldn't do it this way. We do it written. You can look at it
3937200	3941920	and figure it out. It's easier in many dimensions in some ways, depending on the person. It's easier
3941920	3947760	to gather written data for, I mean, most sort of psycho, I work in psycholinguistics, right?
3947760	3952800	Psychology of language and stuff. And so a lot of our work is based on written stuff because it's
3952800	3959600	so easy to gather data from people doing written kinds of tasks. Spoken tasks are just more complicated
3959600	3965200	to administer and analyze because people do weird things when they speak. And it's harder to analyze
3965200	3970160	what they do, but they generally point to the same kinds of things.
3970160	3977920	It's okay. So the universal theory of language by Ted Gibson is that you can form dependency,
3979120	3984000	you can form trees from any senses, and you can measure the distance in some way of those
3984000	3990560	dependencies. And then you can say that most languages have very short dependencies.
3990560	3994720	All languages. All languages. All languages have short dependencies. You can actually measure that.
3994720	4000080	So an ex-student of mine, this guy is at University of California, Irvine. Richard
4000080	4005520	Futrell did a thing a bunch of years ago now where he looked at all the languages we could
4005520	4010800	look at, which was about 40 initially. And now I think there's about 60 for which there are
4010800	4015680	dependency structures. So they're meaning there's got to be like a big text, a bunch of texts,
4015680	4019760	which have been parsed for the dependency structures. And there's about 60 of those
4019760	4025920	which have been parsed that way. And for all of those, what he did was take any
4027040	4031360	sentence in one of those languages, and you can do the dependency structure, and then start at
4031360	4035200	the root. We were talking about dependency structures. That's pretty easy now. And he's
4035200	4041280	trying to figure out what a control way you might say the same sentence is in that language. And so
4041280	4046640	what he does is just like, all right, there's a root, and say as a sentence is, let's go back to,
4046880	4052880	two dogs entered the room. So entered is the root. And entered has two dependents that's got
4052880	4058320	dogs, and it has room. And what he does is like, let's scramble that order. That's three things,
4058320	4063680	the root, and the head, and the two dependents, and into some random order, just random. And then
4063680	4068320	just do that for all the dependents down the two. So now look, do it for the whatever was two in
4068320	4074000	dogs and for in room. And that's not a very short sentence. When sentences get longer,
4074000	4078720	and you have more dependents, there's more scrambling that's possible. And what he found,
4078720	4082560	what so that so so that that's one, you can figure out one scrambling for that sentence,
4082560	4087600	he did like a hundred times for every sentence and every corp and every one of these texts,
4087600	4093760	every corpus. And then he just compared the dependency lengths in those random scramblings
4093760	4099120	to what actually happened with what the English or the French or the German was in the original
4099120	4103040	language or Chinese or what all these like 80, like, you know, 60 languages, okay. And the
4103040	4108080	dependency lengths are always shorter in the real language compared to this kind of a control.
4108080	4116960	And there's another, it's a little more rigid his control. So the way I described it, you could
4116960	4121680	have crossed dependencies, like that by scrambling that way, you could scramble in any way at all.
4122560	4127200	Languages don't do that. They tend not to cross dependencies very much. Like so the dependency
4127200	4131920	structure, they just they tend to keep things non-crossed. And there's a, you know, like,
4131920	4135440	there's a technical term they call that projective, but it's just non-crossed is all that is
4135440	4141520	projective. And so if you just constrain the scrambling so that it only gives you projectives
4141520	4146560	sort of non-crossed is the same thing holds. So it's so the you still still human languages are
4146560	4152800	much shorter than these this kind of a control. So there's like, what it means is that that
4152800	4158480	we're in every language, we're trying to put things close in relative to this kind of a control,
4158480	4161680	like it doesn't matter about the word order, some of these are verb final, some of them is
4161680	4165840	a verb, media-like English, and some are even verb initial. There are a few languages in the
4165840	4171600	world which have VSO, word order, verb, subject, object languages, haven't talked about those.
4171600	4177360	It's like 10% of the and even even in those languages, it's still short dependencies.
4177360	4182720	Short dependencies is rules. Okay. So how what, what are some possible explanations for that?
4183920	4188000	For why languages have evolved that way? So that that's one of the,
4188880	4194640	I suppose disagreements you might have with Chomsky. So you consider the evolution of language
4194640	4204000	in terms of information theory. And for you, the purpose of language is ease of communication,
4204000	4208240	right, in processing. That's right. That's right. So I mean, the story here is just about
4208800	4213760	communication. It is just about production really. It's about ease of production is the story.
4213760	4217600	When you say production, can you? Oh, I just mean each of language production. It's easier for me
4217600	4223520	to say things when the, when I'm doing, whenever I'm talking to you is somehow I'm formulating
4223520	4227600	some idea in my head and I'm putting these words together. And it's easier for me to do that,
4229040	4233280	to put, to say something where the words are close, closely connected in a dependency,
4233280	4238480	as opposed to separated, like by putting something in between and over and over again.
4238480	4242160	It's just hard for me to keep that in my head. It like, that's, that's the whole story.
4242160	4246320	Like the story is basically, it's like the dependency grammar sort of gives that to you.
4246400	4251200	Like just like long, long as bad, short as good. It's like easier to keep in mind because you
4251200	4256400	have to keep it in mind for probably for production, probably matters in comprehension
4256400	4260240	as well. Like also matters in comprehension. It's on both sides of it. The production and the,
4260240	4264000	but I would guess it's probably evolved for production. It's about producing. It's what's
4264000	4269600	easier for me to say that ends up being easier for you also. And that's very hard to disentangle
4269600	4274400	this idea of who is it for? Is it for me, the speaker, or is it for you, the listener? I mean,
4274480	4279280	part of my language is for you. Like the way I talk to you is going to be different
4279280	4283280	from how I talk to different people. So I'm, I'm definitely angling what I'm saying
4283280	4287840	to who I'm saying, right? It's not like I'm just talking the same way to every single person.
4287840	4293840	And so I am sensitive to my audience, but how does that, does that, you know,
4293840	4298480	work itself out in the, in the dependency link differences? I don't know. Maybe that's about
4298480	4302480	just the words, that part, you know, which words I select. My initial intuition is that
4303440	4309280	you optimize language for the audience. Yeah. But it's just kind of like messing with my head
4309280	4314480	a little bit to say that some of the optimization might be, or it may be the primary objective,
4314480	4320000	the optimization might be the ease of production. We have different senses, I guess. I'm, I'm like,
4320000	4324640	very selfish and you're like, I think it's like, it's all about me. I'm like,
4324640	4328880	I'm just doing what's easiest for me at all times. I don't want to, I'm like, I'll, I mean,
4328880	4333680	but I have to, of course, choose the words that I think you're going to know. I'm not going to
4333680	4337280	choose words you don't know. In fact, I'm going to fix that when I, you know, so there it's about,
4337280	4342800	but, but maybe for, for the syntax, for the combinations, it's just about me. I feel like
4342800	4345440	it's, I don't know though, it's great. Wait, wait, wait, wait, wait, but the purpose of
4345440	4350720	communication is to be understood, is to convince others and so on. So like the selfish things to
4350720	4354400	be understood. Okay. It's about the listener. It's a little circular there too then. Okay.
4354400	4359040	Right. I mean, like the ease of production helps me be understood then.
4360400	4364880	I don't think it's circular. So I think the primary, I think the primary objective is to be
4364880	4370320	understood is about the listener. Cause otherwise the, if you're optimizing for the ease of production,
4370320	4374560	then you're, you're not going to have any of the interesting complexity of language. Like
4374560	4378080	you're trying to like explain. Well, let's control for what it is I want to say. Like I,
4378080	4381920	I'm saying let's control for the thing, the, the message, control for the message.
4381920	4385040	But that means the message needs to be understood. That's the goal.
4385040	4387120	Oh, but that's the meaning. So I'm still talking about the form.
4387760	4392800	Just the form of the meaning. How do I frame the form of the meaning is all I'm talking about.
4392800	4396560	You're talking about a harder thing, I think, is like, how am I, like trying to change the
4396560	4402400	meaning. Let's, let's keep the meaning constant. Like which, if you keep the meaning constant,
4402400	4407520	how can I phrase whatever it is I need to say, like I gotta pick the right words and I'm gonna
4407520	4412080	pick the order so that it's, so it's easy for me. That's, that's, that's what I think it's
4412080	4418320	probably like. I think I'm still tying meaning and form together in my head. But you're saying,
4418320	4423440	if you keep the meaning of what you're saying constant, would the optimization, yeah, it could
4423440	4429200	be the primary objective of that optimization is the, for production. That's interesting.
4429920	4436400	I'm struggling to keep constant the meaning. It's just so, I mean, I'm such a, I'm a human,
4436400	4443280	right? So for me, the form without having introspected on this, the form and the meaning
4443280	4451040	are tied together, like deeply because I'm a human. Like for me, when I'm speaking,
4451040	4456080	because I haven't thought about language, like in a rigorous way about the form of language.
4456080	4463760	But look, for any event, there's, there's an unbounded, I don't want to say infinite, but sort
4463760	4469680	of ways that I might communicate that same event. This two dogs entered a room, I can say in many,
4469680	4475440	many different ways. I can say, Hey, there's two dogs. They entered the room. Hey, the room was
4475440	4479360	entered by something. The thing that was entered was two dogs. I mean, there's, I mean, it's kind
4479360	4486080	of awkward and weird stuff. But those are all similar messages with different forms, but different
4486080	4490640	ways that might frame. And of course, I use the same words there all the time. I could have referred
4490720	4495600	to the dogs as a Dalmatian and a Poodle or something. I could have been more specific
4495600	4500800	or less specific about what they are. And I could have said, been more abstract about the number.
4500800	4506640	There's like, so I, like I'm trying to keep the meaning, which is this event constant. And then
4506640	4510320	how am I going to describe that to get that to you? It kind of depends on what you need to know,
4510320	4515280	right? And what I think you need to know. But I'm like, let's control for all that stuff and not,
4515840	4519520	and then I'm just like choosing about, I'm doing something simpler than you're doing,
4519520	4526320	which is just forms. Yes. Just words. So to you specifying the breed of dog and
4527120	4531520	whether they're cute or not is changing the meaning. That might be, yeah. Yeah, that would be
4531520	4536320	changing. Oh, that would be changing the meaning for sure. Right. So you're just, yeah. Yeah.
4536320	4540800	That's changing the meaning. But say, even if we keep that constant, we can still talk about
4540800	4547280	what's easier or hard for me, right? The listener and the, which phrase structures I use, which
4547280	4554560	combinations, which, yeah. This is so fascinating and just like a really powerful window into human
4554560	4561840	language. But I wonder still throughout this, how vast the gap between meaning and form,
4561840	4567840	I just, I just have this like, maybe romanticized notion that they're close together, that they
4567840	4573840	evolve close to like hand in hand, that you can't just simply optimize for one without
4574560	4580480	the other being in the room with us. Like it's, well, it's kind of like an iceberg.
4580480	4585120	Form is the tip of the iceberg and the rest, the, the meaning is the iceberg, but you can't like
4585120	4590400	separate. But I think that's why these large language models are so successful is because
4590400	4595680	they're good at form and form isn't that hard in some sense. And meaning is tough still. And
4595680	4598560	that's why they're not, they're, you know, they don't understand what they're doing. We're going
4598640	4604480	to talk about that later maybe, but like we can distinguish in our, forget about large language
4604480	4608480	models, like humans, maybe you'll talk about that later too, is like the difference between
4609200	4614560	language, which is a communication system and thinking, which is meaning. So language is a
4614560	4620400	communication system for the meaning. It's not the meaning. And so that's why, I mean, that, and
4620400	4624320	there's a lot of interesting evidence we can talk about relevant, relevant to that.
4624320	4628640	Well, I mean, that's a really interesting question. What is the difference between
4630240	4637600	language written, communicated versus thought? What to use the difference between them?
4638800	4645200	Well, you or anyone cast a think of a task, which they think is, is a good thinking task. And
4645200	4649920	there's lots and lots of tasks, which should be good thinking tasks. And whatever those tasks,
4649920	4654160	let's say it's, you know, playing chess, or that's a good thinking task, or playing some game,
4654160	4660240	or doing some complex puzzles, maybe, maybe remembering some digits that's thinking,
4660240	4664000	remembering some, a lot of different tasks we might think, maybe just listening to music is
4664000	4668320	thinking, or there's a lot of different tasks we might think of as thinking. There's a woman in
4668320	4673040	my department at Federico, and she's done a lot of work at, on this question about what's the
4673040	4678320	connection between language and thought. And, and so she uses, I was referring earlier to MRI,
4678320	4684640	fMRI, that's her primary method. And so she is been really fascinated by this question about whether,
4685600	4688880	what language is, okay? And so as I mentioned earlier, you can
4689440	4693840	localize my language area, your language area in a few minutes, okay? In like 15 minutes,
4693840	4699200	I can listen to language, listen to non-language or backward speech or something. And we'll find
4699200	4706080	areas left lateralized network in my head, which is especially, which is very sensitive to language,
4706080	4709600	as opposed to whatever that control was, okay? Can you specify what you mean by language, like
4709600	4713920	communicated language? Like what is language? Just sentences. You know, I'm listening to English
4713920	4719040	of any kind story, or I can read sentences, anything at all that I understand, if I understand it,
4719040	4724080	then it'll activate my language network. So right now, my language network is going like crazy
4724080	4728400	when I'm talking and when I'm listening to you, because we're both, we're communicating. And
4728400	4734800	that's pretty stable. Yeah, it's incredibly stable. So I've, I happen to be married to this woman
4734880	4739520	Federico. So I've been scanned by her over and over and over since 2007 or six or something.
4739520	4745600	And so my language network is exactly the same, you know, like a month ago, as it was back in 2007.
4745600	4751600	It's amazingly stable. It's astounding. And with it, it's, it's a really fundamentally cool thing.
4751600	4756880	And so my language network is, it's like my face, okay? It's not changing much over time inside my
4756880	4762720	head. Can I ask a quick question? Sorry, it's a small tangent. At which point in the, as you grow
4762800	4768000	up from baby to adult, does it stabilize? We don't know. Like that's a, that's a very hard
4768000	4772560	question. They're working on that right now because of the problem of scanning little kids,
4772560	4778800	like doing the, trying to do local, trying to do the localization on little children in this scanner,
4778800	4782800	or you're lying in the fMRI scan. That's the best way to figure out where something's going on
4782800	4787360	inside our brains. And the scanner is loud and you're in this tiny little, you know, area,
4787360	4792240	you're claustrophobic. And it doesn't bother me at all. I can go to sleep in there, but some people
4792240	4795520	are bothered by it. And little kids don't really like it. And they don't like to lie still. And
4795520	4799840	you have to be really still because you can move around. That's, that messes up the coordinates of
4799840	4804560	where, where everything is. And so, you know, try to get, you know, your question is how and when
4804560	4808960	our language developing, you know, how, when, when, how does this left lateralized system come to
4808960	4812800	play? Where does it, you know, and it's really hard to get a two year old to do this task. But
4812800	4816880	you can maybe where they're starting to get three and four and five year olds to do this task for
4816880	4821360	short periods. And it looks like it's there pretty early. So clearly when you lead up to you,
4821440	4828160	like a baby's first words, before that, there's a lot of fascinating turmoil going on about like
4828160	4833680	figuring out like, what are, what are these people saying? And you're trying to like make
4833680	4837760	sense, how does that connect to the world and all that kind of stuff. Yeah. That might be just
4837760	4842400	fascinating development that's happening there. That's hard to introspect. But anyway, you,
4842400	4848400	we're back to the scanner and I can find my network in 15 minutes. And now we can ask a,
4849040	4853520	find my network, find yours, find, you know, 20 other people do this task. And we can do some
4853520	4859200	other tasks. Anything else you think is thinking of some other thing. I can do a spatial memory task.
4859200	4865920	I can do a music perception task. I can do programming task if I program. Okay. I can do
4866480	4872080	where I can like understand computer programs. And none of those tasks will tap the language
4872080	4876480	network at all, like at all. There's no overlap. They do, they're, they're highly activated in
4876480	4881600	other parts of the brain. There's a, there's a bilateral network, which I think she tends to
4881600	4885520	call the multiple demands network, which does anything kind of hard and, and so anything that's
4885520	4891280	kind of difficult in some ways will activate that multiple demands network. I mean, music will be
4891280	4895520	in some music area, you know, there's music specific kinds of areas. And so, but they're,
4896080	4901520	but, but none of them are activating the language area at all, unless there's words, like, so if
4901520	4905680	you have music and there's a song and you can hear the words then, then then you get the language
4906000	4910400	area. We're talking about speaking and listening, but are, or are we also talking about reading?
4910400	4916880	This is all comprehension of any kind. And so that is fast. So what this, this, this network
4916880	4921280	doesn't make any difference if it's written or spoken. So the, the, the thing that she calls,
4921280	4925840	Federico calls the language network is this high level language. So it's not about the spoken,
4925840	4929680	the spoken language, and it's not about the written language is about either one of them.
4929680	4933360	And so we're, so when you do speech, you're sort of list, you either, you're listening to speech
4933360	4937280	and you'd, you know, subtract away some language you don't understand and see where it's, or you
4937280	4942240	subtract away back, backward speech, which signs sounds like speech, but it isn't. And, and then
4942240	4948480	so you take away the sound part altogether. And so, and then if you do written, you get exactly
4948480	4953600	the same network. So for just reading the language versus reading sort of nonsense words or something
4953600	4959680	like that, you'll find exactly the same network. And so it's just about high level, um, comprehension
4959680	4962960	of language. Yeah. In this case, and the same thing happened, production is a little harder to
4962960	4966560	run the scanner, but the same thing happens in production. You get the same network. So production
4966560	4970080	is a little harder. You have to figure out how do you run a task, you know, in the network such
4970080	4973040	that you're doing some kind of production. And I can't remember what, they've done a bunch of
4973040	4977760	different kinds of tasks there where you get people to, you know, produce things. Yeah. Figure
4977760	4982320	out how to produce and the same network goes on there. Exactly the same place. And so if, wait,
4982320	4986080	wait, so if you read random words, yeah, if you read things like, um,
4986880	4990480	like gibberish. Yeah. Yeah. Lewis Carroll's, Twas Brillig,
4990480	4995040	Jabberwocky, right? They call that Jabberwocky speech. The network doesn't get activated.
4995040	4999360	Not as much. There are words in there. Because it's like, there's function words and stuff.
4999360	5004720	So it's lower activation. Yeah. Yeah. So there's like, basically the more language like it is,
5004720	5010480	the higher it goes in the language network. And that network is there from when you speak from,
5010480	5015280	as soon as you learn language. And, and it's, it's there, like you speak multiple languages,
5015280	5019360	the same network is going for your multiple languages. So you speak English, you speak Russian,
5020240	5024400	both of them are hitting that same network. If you, if you're affluent in those languages.
5024400	5029280	So programming. Not at all. Isn't that amazing? Even if you're a really good programmer,
5029280	5034800	that is not a human language. It's just not conveying the same information. And so it is
5034800	5038800	not in the language network. And so that has mind blowing as I think. That's pretty cool.
5038800	5043280	That's weird. It is amazing. And so that's like one set of day. This is hers like shows that
5043280	5048480	what you might think is thinking is, is not language language is just the seek, just, just
5048480	5054640	this conventionalized system that we've worked out in human languages. Oh, another fascinating
5054640	5061680	little bit tidbit is that even if they're these constructed languages, like Klingon, or I don't
5061680	5065280	know the languages from Game of Thrones, I'm sorry, I don't remember those languages, maybe a lot of
5065280	5069440	people offended right now. There's people that speak those languages. They really speak those
5069440	5076000	languages because the people that wrote the languages for the shows, they did an amazing
5076000	5080960	job of constructing on something like a human language. And those that, that lights up the
5080960	5086080	language area. That's like, because they can speak, you know, pretty much arbitrary thoughts
5086080	5090640	in a human language. It's not a, it's a constructed human language. Probably it's related to human
5090640	5094320	languages because the people that were constructing them were making them like human languages in
5094320	5099600	various ways, but it also activates the same network, which is pretty, pretty cool. Anyway.
5099600	5104800	Sorry to go into a place where you may be a little bit philosophical, but is it possible
5105440	5110000	that this area of the brain is doing some kind of translation into a deeper set of
5111200	5117840	almost like concepts? It has to be doing. So it's doing in communication, right? It is translating
5118400	5122960	from thought, whatever that is, is more abstract, and it's doing that. That's what it's doing. Like,
5122960	5126560	it is, that is kind of what it is doing. It's like kind of a meaning network, I guess.
5127360	5131120	Yeah, like a translation network. Yeah. But I wonder what is at the core,
5131120	5137120	at the bottom of it? Like, what are thoughts? Are they thoughts? To me, like, thoughts and words,
5137120	5142960	are they neighbors or are, is it one turtle sitting on top of the other? Meaning, like, is there a
5142960	5149680	deep set of concepts that we... Well, there's connections right between those, what these
5149680	5152720	things mean. And then there's probably other parts of the brain that what these things mean.
5152800	5158480	And so, you know, when I'm talking about whatever it is I want to talk about, it'll be represented
5158480	5162640	somewhere else. That knowledge of whatever that is will be represented somewhere else.
5162640	5167440	Well, I wonder if there's like some stable, nicely compressed encoding of meanings
5168240	5178080	that's separate from language. I guess the implication here is that we don't think in
5178080	5182480	language. That's correct. Isn't that cool? And that's so interesting.
5182480	5187120	So people, I mean, this is like hard to do experiments on, but there is this idea of
5187120	5192320	inner voice and a lot of people have an inner voice. And so, if you do a poll on the internet
5192320	5195200	and ask if you hear yourself talking when you're just thinking or whatever,
5195840	5202480	about 70 or 80% of people will say yes. Most people have an inner voice. I don't. And so,
5202480	5205920	I always find this strange when... So, when people talk about an inner voice, I always
5205920	5211520	thought this was a metaphor. And they hear, I know most of you, whoever's listening to this,
5211520	5215920	thinks I'm crazy now because I don't have an inner voice. And I just don't know what you're
5215920	5222080	listening to. It sounds so kind of annoying to me, but to have this voice going on while you're
5222080	5227840	thinking, but I guess most people have that. And I don't have that. And we don't really know what
5227840	5232560	that connects to. I wonder if the inner voice activates that same network. I don't know.
5233520	5237520	I don't know. I mean, this could be speechy, right? So that's like, you hear, do you have an inner
5237520	5244240	voice? I don't think so. A lot of people have this sense that they hear themselves. And then,
5244240	5248000	say they read someone's email, I've heard people tell me that they hear that other person's voice
5248000	5253680	when they read other people's emails. And I'm like, wow, that sounds so disruptive.
5253680	5258160	I do think I like vocalize when I'm reading, but I don't think I hear a voice.
5258800	5260880	Well, that's, you probably don't have an inner voice. Yeah, I don't think I have an inner voice.
5260880	5266640	People have an inner voice. People have this strong percept of hearing sound in their heads
5266640	5270240	when they're just thinking. I refuse to believe that's the majority of people.
5270240	5274800	Majority, absolutely. What? It's like two-thirds or three-quarters. It's not.
5274800	5279920	I would never ask class. And I went internet, they always say that. So you're in a minority.
5279920	5286080	It could be a self-report flaw. It could be. You know, when I'm reading inside my head,
5287520	5293680	I'm kind of like saying the words, which is probably the wrong way to read, but I don't
5293680	5299680	hear a voice. There's no percept of a voice. I don't refuse to believe the majority of people
5299680	5304160	have it. Anyway, it's a fascinating, the human brain is fascinating, but it still blew my mind
5304160	5311280	that the, that language does appear, comprehension does appear to be separate from thinking.
5312560	5319440	So that's one set. One set of data from Fedorenko's group is that no matter what task you do,
5319440	5323840	if it doesn't have words and combinations of words in it, then it won't light up the language
5323840	5328720	network. You know, you could, it'll be active somewhere else, but not there. So that's one.
5328720	5335520	And then this other piece of evidence relevant to that question is, it turns out there are these,
5335520	5341040	this group of people who've had a massive stroke on the left side and wiped out their language
5341040	5344960	network. And as long as they didn't wipe out everything on the right as well, in that case,
5344960	5348960	they wouldn't be, you know, cognitively functionable. But if they just wiped out language,
5348960	5353840	which is pretty tough to do because it's, it's very expansive on the left. But if they have,
5353840	5359760	then there are these, there's patients like this, so-called global aphasics, who can do
5360480	5364800	any task just fine, but not language. They can't, you can't talk to them. I mean,
5365360	5370480	they don't understand you. They can't speak, can't write, they can't read, but they can do,
5370480	5374240	they can play chess, they can drive their cars, they can do all kinds of other stuff, you know,
5374240	5378560	do math, they can do all, like, so math is not in the language area, for instance, you do arithmetic
5378560	5382560	and stuff. That's not language area. It's got symbols. So people sort of confuse some kind of
5382560	5387440	symbolic processing with language and symbolic processing is not the same. So there are symbols
5387440	5391760	and they have meaning, but it's not language. It's not a, you know, conventionalized language
5391760	5396560	system. And so language, so math isn't there. And so they can do math. They're, they do just as well
5396560	5401120	as their control, age match controls and all these tasks. This is Rosemary Varley over in
5401120	5405200	University College London, who has a bunch of patients who, who she's shown this that they're
5405200	5413520	just, so that sort of combination suggests that language isn't necessary for thinking. It doesn't
5413520	5417680	mean you can't think in language. You could think in language because language allows a lot of
5417680	5422320	expression, but it's just, you don't need it for thinking. It's, it suggests that language is separate,
5422960	5427600	is a separate system. This is kind of blowing my mind right now. I'm trying to load that in
5427600	5434160	because it has implications for large language models. It sure does. And they've been working on
5434160	5439280	that. Well, let's take a stroll there. You wrote that the best current theories of human language
5439280	5445360	are arguably large language models. So this has to do with form. It's kind of a big theory. And,
5446080	5451680	but the reason it's arguably the best is that it, it does the best at predicting what's English,
5451680	5456320	for instance, it's, it's like incredibly good, you know, it better than any other theory. It's so,
5456320	5461360	you know, but, you know, we don't, you know, there's, it's not sort of, there's not enough detail.
5461360	5464080	What's opaque? Like, there's not, you don't know what's going on.
5464080	5467920	No, what's going on. It's another black box. But I think it's, you know, it is a theory.
5467920	5472240	What's your definition of a theory? Because it's a gigantic, it's a gigantic black box with,
5472240	5477840	you know, a very large number of parameters controlling it. To me, theory usually requires
5479040	5483600	a simplicity, right? Well, I don't know. Maybe I'm just being loose there. I think it's a,
5483600	5487360	it's not, it's not a great theory, but it's a theory. It's a good theory in one sense,
5487360	5490720	and then it covers all the data. Like anything you want to say in English, it does. And so
5490720	5495200	that's why it's, that's how it's arguably the best, is that no other theory is as good as
5495200	5499840	a large language model in predicting exactly what's good and what's bad in English.
5500400	5503840	You know, now you're saying, is it a good theory? Well, probably not, you know,
5503840	5507200	because I want a smaller theory than that. It's too big. I agree.
5507200	5513600	You could probably construct mechanism by which it can generate a simple explanation of a
5513600	5521440	particular language, like a set of rules, something like it could generate a dependency
5521440	5530640	grammar for a language, right? Yeah. You could probably, you could probably just ask it about
5530640	5536880	itself. Well, you know, that's, I mean, that presumes, and there's some evidence for this,
5537920	5542640	some large language models are implementing something like dependency grammar inside them.
5542640	5548320	And so there's work from a guy called Chris Manning and colleagues over at Stanford
5548320	5553440	in natural language. And they looked at, I don't know how many large language model types,
5553440	5559360	but certainly Burt and some others where, and where you do some kind of fancy math to figure
5559360	5563440	out exactly what the sort of, what kind of abstractions of representations are going on.
5563440	5567200	And they, and they were saying it does look like dependency structure is, is what they're
5567200	5571520	constructing. It doesn't, like, so it's actually a very, very good map. So kind of a,
5571520	5578080	they are constructing something like that. Does it mean that, you know, that they're using that
5578080	5583040	for meaning? I mean, probably, but we don't know. You write that the kinds of theories of language
5583040	5588320	that LLMs are closest to are called construction based theories. Can you explain what construction
5588320	5594880	based theories are? It's just a general theory of language such that there's a form and a meaning
5594960	5600960	pair for, for lots of pieces of the language. And so it's, it's, it's primarily usage based,
5600960	5604880	is a construction grammar. It's just, it's trying to deal with the things that people
5605440	5611280	actually say, actually say and actually write. And so that's, it's a usage based idea. And
5611280	5616320	what's the constructional constructions either a simple word, so like a morpheme plus its meaning
5616320	5621280	or a combination of words, it's basically combinations of words, like the rules. So,
5621920	5630960	but it's, it's unspecified as to what the form of the grammar is under underlyingly.
5630960	5637520	And so I would, I would argue that the dependency grammar is maybe the right form to use for the
5637520	5643280	types of construction grammar. Construction grammar typically isn't kind of formalized
5643280	5648400	quite. And so maybe the formalization, a formalization of that, it might be in dependency
5648400	5654080	grammar. Yeah. I mean, I, I would think so, but I mean, it's up to people, other researchers
5654080	5659600	in that area, if they agree or not. So. Well, do you think that large language models understand
5659600	5665200	language? Are they mimicking language? I guess the deeper question there is, are they just
5665200	5671360	understanding the surface form? Or do they understand something deeper about the meaning
5671360	5675840	that then generates the form? I mean, I would argue they're doing the form, they're doing
5675840	5679600	the form, they're doing it really, really well. And are they doing the meaning? No,
5679600	5684480	probably not. I mean, there's lots of these examples from various groups showing that they
5684480	5688800	can be tricked in all kinds of ways. They really don't understand the, the meaning of what's going
5688800	5695360	on. And so there's a lot of examples that he and other groups have given, which just, which show
5695360	5699600	they don't really understand what's going on. So, you know, the Monty Hall problem is this
5699600	5704960	silly problem, right? Where, you know, if you have three door, it's less make a deal as this
5704960	5710640	old game show, and there's three doors, and there's a prize behind one, and there's some
5711920	5716480	junk prizes behind the other two, and you're trying to select one. And if you, you know,
5716480	5721520	he knows Monty, he knows where the target item is, the good thing, he knows everything is back
5721520	5726320	there. And you're supposed to, he gives you a choice, you choose one of the three, and then
5726320	5730560	he opens one of the doors, and it's some junk prize. And then the question is, should you trade
5730560	5734400	to get the other one? And the answer is yes, you should trade, because he knew which ones you could
5734400	5740080	turn around. And so now the odds are two-thirds, okay? And then you just change that a little bit
5740080	5745360	to the large language mall. The large language mall has seen that explanation so many times,
5745360	5749440	that it just, if you change the story, it's a little bit, but it makes it sound like it's the
5749440	5755600	Monty Hall problem, but it's not. You just say, oh, there's three doors, and one behind them is a
5755600	5760160	good prize, and there's two bad doors. I happen to know it's behind door number one. The good prize,
5760160	5764560	the car, is behind door number one. So I'm going to choose door number one. Monty Hall opens door
5764560	5768640	number three, and shows me nothing there. Should I trade for door number two? Even though I know
5768640	5772560	the good prize in door number one, and then the large language mall say, yes, you should trade,
5772560	5779680	because it just goes through the forms that it's seen before so many times on these cases,
5779680	5784400	where it, yes, you should trade, because your odds have shifted from one in three now to two out
5784400	5789440	of three, to being that thing. It doesn't have any way to remember that actually you have a
5789440	5795120	100% probability behind that door number one. You know that. That's not part of the scheme that
5795120	5800160	it's seen hundreds and hundreds of times before. And so you can't, even if you try to explain to
5800160	5805520	it that it's wrong, that they can't do that, it'll just keep giving you back the problem.
5805520	5809200	But it's also possible that a larger language model would be aware of the fact that there's
5809200	5817440	sometimes over a representation of a particular kind of formulation, and it's easy to get tricked
5817440	5824560	by that. And so you could see if they get larger and larger models be a little bit more skeptical.
5824560	5833360	So you see over a representation. So it just feels like form can, training on form can go
5833360	5842320	really far in terms of being able to generate things that look like the thing understands
5843200	5852560	deeply the underlying world model of the kind of mathematical world, physical world,
5853440	5858640	psychological world that would generate these kinds of sentences. It just feels like you're
5858640	5864080	creeping close to the meaning part, easily fooled, all this kind of stuff, but that's humans too.
5864960	5872880	So it just seems really impressive how often it seems like it un-understands concepts.
5874160	5879280	I mean, you don't have to convince me of that. I am very, very impressed, but does it,
5879280	5884880	does it mean you're giving a possible world where maybe someone's going to train some other
5884880	5890800	versions such that it'll be somehow abstracting away from types of forms? I mean, I don't think
5890800	5897680	that's happened. No, no, no. I'm not saying that. I think when you just look at anecdotal examples
5898320	5902720	and just showing a large number of them where it doesn't seem to understand and it's easily fooled,
5903280	5911760	that does not seem like a scientific data-driven analysis of how many places is a damn impressive
5912480	5915600	in terms of meaning and understanding and how many places is easily fooled.
5916560	5919920	That's not the inference. So I don't want to make that, the inference I don't,
5919920	5923760	I wouldn't want to make was that inference. The inference I'm trying to push is just that is it,
5924720	5929520	is it like humans here? It's probably not like humans here. It's different. So humans don't make
5929520	5933840	that error. If you explain that to them, they're not going to make that error. They don't make
5933840	5937440	that error. And so that's something, it's doing something different from humans that they're
5937440	5942160	doing in that case. What's the mechanism by which humans figure out that it's an error?
5942160	5946640	I'm just saying the error there is like, if I explain to you there's 100% chance
5946640	5951840	that the car is behind this case, this door, well, do you want to trade? If you'll say no.
5951840	5957440	But this thing will say yes, because it's so, that trick, it's so wound up on the form
5958320	5963280	that it's, that's an error that a human doesn't make, which is kind of interesting.
5963280	5965920	Less likely to make, I should say. Yeah, less likely.
5965920	5968480	Because like humans are very- Oh yeah.
5969120	5975360	I mean, you're asking, you're asking humans, you're asking a system to understand 100%,
5975360	5978480	like you're asking some mathematical concepts. And so like-
5980000	5985760	Look, the places where large language models are, the form is amazing. So let's go back to
5985760	5990000	nested structures, center embedded structures. Okay, if you ask a human to complete those,
5990000	5994960	they can't do it. Neither can a large language model. They're just like humans in that. If you
5994960	5997680	ask, if I ask a large language model- That's fascinating, by the way.
5997680	6001680	The central embedding, the central embedding, it struggles with-
6001680	6004960	Just like humans, exactly like humans. Exactly the same way as humans.
6005200	6011360	And that's not trained. So they do exactly, so that is a similarity. So but then it's,
6011360	6015600	that's not meaning, right? This is form. But when we get into meaning,
6015600	6020080	this is where they get kind of messed up. When you start to saying, oh, what's behind this door?
6020080	6024880	Oh, it's, you know, this is the thing I want. Humans don't mess that up as much, you know.
6024880	6031200	Here, the form is just like, the form of the match is amazing, is similar, without being
6031200	6034560	trained to do that. I mean, it's trained in the sense that it's getting lots of data,
6034560	6039280	which is just like human data. But it's not being trained on, you know,
6040080	6044160	bad sentences and being told what's bad. It just can't do those. It'll actually say things like,
6044160	6048720	those are too hard for me to complete or something, which is kind of interesting.
6048720	6050160	Actually, kind of, how does it know that? I don't know.
6050880	6058320	But it really often doesn't just complete, very often says stuff that's true.
6058960	6064880	And sometimes says stuff that's not true. And almost always the form is great.
6065760	6072480	But it's still very surprising that with really great form, it's able to generate a lot of things
6072480	6080480	that are true based on what is trained on and so on. So it's not just form that is generating.
6081280	6087920	It's mimicking true statements from the internet. I guess the underlying idea
6087920	6093200	there is that on the internet, truth is overrepresented versus falsehood.
6093200	6094800	I think that's probably right. Yeah.
6094800	6098880	So but the fundamental thing is trained on, you're saying is just form.
6098880	6101280	I think so. Yeah. Yeah, I think so.
6102000	6107040	Well, that's a sad, if that's, to me, that's still a little bit of open question. I probably
6107040	6114080	lean agreeing with you, especially now you've just blown my mind that there's a separate
6114080	6120720	module in the brain for language versus thinking. Maybe there's a fundamental part missing from
6121520	6126880	the large language model approach that lacks the thinking, the reasoning capability.
6128240	6134560	Yeah, that's what this group argues. So the same group, Fedorenko's group has a
6134560	6140400	recent paper arguing exactly that. There's a guy called Kyle Mahwell who's here in Austin,
6140400	6144960	Texas, actually. He's an old student of mine, but he's a faculty in linguistics at Texas,
6144960	6150080	and he was the first author on that. That's fascinating. Still, to me, an open question.
6151120	6152880	What do you have the interesting limits of LLMs?
6154800	6160800	I don't see any limits to their form. Their form is perfect. Yeah, it's pretty much,
6160800	6164960	I mean, it's close to- Well, you said ability to complete central embeddings.
6164960	6167600	Yeah, it's just the same as humans. It seems the same.
6167600	6171920	But that's not perfect, right? It should be- That's good. No, but I want to be like humans.
6171920	6176160	I'm trying to, I want a model of humans. Oh, wait, wait, wait, wait, wait. Also,
6176160	6179680	perfect is as close to humans as possible. I got it. Yeah.
6179680	6183200	But you should be able to, if you're not human, you're like you're super human,
6183200	6186000	you should be able to complete central embedded sentences, right?
6186640	6192000	I mean, that's the mechanism is, if it's modeling some, I think it's kind of
6192000	6194240	really interesting that it can't. That it's really interesting.
6194320	6198560	It's more like, like I think it's potentially underlyingly modeling
6198560	6201680	something like what the way the form is processed.
6201680	6206000	The form of human language and how humans process the language.
6206000	6207840	Yes. I think that's plausible.
6207840	6211440	And how they generate language. Process language and general language, that's fascinating.
6212640	6218640	So in that sense, they're perfect. If we can just linger on the center embedding thing,
6218640	6221920	that's hard for LLMs to produce, and that seems really impressive because that's
6221920	6227600	hard for humans to produce. And how does that connect to the thing we've been talking about
6227600	6234640	before, which is the dependency grammar framework in which you view language and the finding that
6234640	6241120	short dependencies seem to be a universal part of language. So why is it hard to complete center
6241120	6245520	embeddings? So what I like about dependency grammar is it makes
6245680	6254480	the cognitive cost associated with longer distance connections very transparent.
6254480	6258720	Basically, as there's some, it turns out there is a cost associated with producing
6258720	6263360	and comprehending connections between words, which are just not beside each other.
6263360	6268560	The further apart they are, the worse it is according to, well, we can measure that.
6268560	6270240	And there is a cost associated with that.
6270960	6274960	Can you just linger on, what do you mean by cognitive cost and how do you measure it?
6275200	6279520	You can measure it in a lot of ways. The simplest is just asking people to say
6280160	6286880	whether how good a sentence sounds. We just ask, that's one way to measure, and you try to triangulate
6286880	6290960	then across sentences and across structures to try to figure out what the source of that is.
6290960	6298480	You can look at reading times in controlled materials, in certain kinds of materials,
6298480	6301360	and then we can measure the dependency distances there.
6301760	6308160	We can, there's a recent study which looked at, we're talking about the brain here,
6308160	6311360	we could look at the language network, okay? We could look at the language network,
6311360	6316480	and we could look at the activation in the language network, and how big the activation is
6316480	6320960	depending on the length of the dependencies. And it turns out in just random sentences
6320960	6323680	that you're listening to, if you're listening to, so it turns out there are people listening to
6323680	6333120	stories here. And the longer the dependency is, the stronger the activation in the language
6333120	6337280	network. And so there's some measure, there's a bunch of different measures we could do,
6337280	6342000	that's a kind of a neat measure actually of actual activation in the brain.
6342000	6345920	So that you can somehow in different ways convert it to a number. I wonder if there's a
6345920	6349360	beautiful equation connecting cognitive costs and length of dependency,
6349440	6354880	equals MC squared kind of thing. Yeah, it's complicated, but probably it's doable. I would
6354880	6360960	guess it's doable. I tried to do that a while ago, and I was reasonably successful, but for
6360960	6364720	some reason I stopped working on that. I agree with you that it would be nice to figure out.
6364720	6369920	So there's like some way to figure out the cost. I mean, it's complicated. Another issue you raised
6369920	6375360	before was like, how do you measure distance? Is it words? It probably isn't, is it part of the
6375360	6382320	problem? Is that some words matter than more than others? And probably, meaning like nouns might
6382320	6386080	matter depending, and then it maybe depends on which kind of noun. Is it a noun we've already
6386080	6391280	introduced or a noun that's already been mentioned? Is it a pronoun versus a name? Like all these
6391280	6394880	things probably matter. So probably the simplest thing to do is just like, oh, let's forget about
6394880	6402240	all that and just think about words or morphemes. For sure. But there might be some insight in a
6402240	6412320	kind of function that fits the data, meaning like what... I think it's an exponential. So we
6412320	6417120	think it's probably an exponential such that the longer the distance, the less it matters.
6417120	6422960	And so then it's the sum of those. That was our best guess a while ago. So you've got a bunch
6422960	6428480	of dependencies. If you've got a bunch of them that are being connected at some point, at the ends
6428480	6435280	of those, the cost is some exponential function of those is my guess. But because the reason it's
6435280	6440080	probably an exponential is like, it's not just the distance between two words, because I can make a
6440080	6445040	very, very long subject verb depends by adding lots and lots of noun phrases and prepositional
6445040	6450080	phrases. And it doesn't matter too much. It's when you do nest it, when I have multiple of these,
6450720	6456800	then things go really bad, go south. Probably somehow connected to working memory or something
6457360	6463360	that's probably the function of the memory here is the access is trying to find those earlier
6463360	6468400	things. It's kind of hard to figure out what was referred to earlier. Those are those connections.
6468400	6473360	That's the sort of notion of working as opposed to a storagey thing, but trying to connect,
6474880	6479200	retrieve those earlier words depending on what was in between. And then we're talking about
6479200	6484240	interference of similar things in between. That's the right theory probably has that kind of notion
6484240	6488800	and it is an interference of similar. And so I'm dealing with an abstraction over the right
6488800	6493200	theory, which is just, it's count words, it's not right, but it's close. And then maybe you're
6493200	6498800	right though, there's some sort of an exponential or something to figure out the total so we can
6498800	6504800	figure out a function for any given sentence in any given language. But it's funny, people haven't
6504800	6509760	done that too much, which I do think is, I'm interested that you find that interesting. I
6509760	6513040	really find that interesting. And a lot of people haven't found it interesting. And I don't know
6513040	6516480	why I haven't got people to want to work on that. I really like that too.
6517760	6521040	That's a beautiful, in the underlying idea is beautiful that there's a cognitive
6521040	6525920	cost that correlates with the length of dependency. It just, it feels like it's a deep,
6525920	6530640	I mean, language is so fundamental to the human experience. And this is a nice clean
6531360	6538880	theory of language where it's like, wow, okay. So like we like our words close together,
6538960	6542720	dependent words close together. That's why I like it too. It's so simple.
6542720	6547120	Yeah, the simplicity of the theory. And yet it explains some very complicated phenomena.
6547120	6551440	If I write these very complicated sentences, it's kind of hard to know why they're so hard.
6551440	6556480	And you can like, oh, nail it down. I can do like a, give you a math formula for why each one of
6556480	6560960	them is bad and where. And that's kind of cool. I think that's very neat. Have you gone through
6560960	6567600	the process? Is there like a, if you take a piece of text and then simplify, sort of like there's an
6567600	6575040	average length of dependency, and then you like, you know, reduce it and see comprehension on the
6575040	6579760	entire, not just a single sentence, but like, you know, you go from James Joyce to Hemingway or
6579760	6585840	something. No, no, simple answer is no, that does, there's probably things you can do in that,
6585840	6590160	in that kind of direction. That's fun. We might, you know, we're gonna talk about legalese at
6590160	6595440	some point. And so we, maybe we'll talk about that kind of thinking with applied to legalese.
6595520	6598080	Well, let's talk about legalese because you mentioned that as an exception,
6598080	6602720	which is taking tangent upon tangent. That's an interesting one. You give it as an exception.
6602720	6608240	It's an exception. That you say that most natural languages, as we've been talking about,
6608880	6614800	have local dependencies with one exception, legalese. That's right. So what is legalese,
6614800	6619920	first of all? Oh, well, legalese is what you think it is. It's just any legal language.
6620640	6624720	I mean, like, I actually know very little about the kind of language that lawyers use.
6624720	6628320	So I'm just talking about language in laws and language in contracts.
6628320	6628800	Got it.
6628800	6634000	So the stuff that you have to run into, we have to run into every other day or every day,
6635120	6640720	and you skip over because it reads poorly. And or, you know, partly it's just long, right?
6640720	6645440	There's a lot of text there that we don't really want to know about. And so, but the thing I'm
6645440	6651600	interested in, so I've been working with this guy called Eric Martinez, who is a, he was a lawyer
6652160	6656400	who was taking my class. I was teaching a psycholinguistics lab class. I haven't been
6656400	6660800	teaching it for a long time at MIT. And he's a, he was a law student at Harvard. And he took the
6660800	6665360	class because he had done some linguistics as an undergrad. And he was interested in the problem of
6666000	6672800	why legalese sounds hard to understand, you know, why. And so why is it hard to understand and why
6672800	6677280	do they write that way? If it is hard to understand, it seems apparent that it's hard to understand.
6677360	6684800	The question is, why is it? And so we didn't know. And we did an evaluation of a bunch of contracts.
6684800	6688960	Actually, we just took a bunch of random contracts, because I don't know, you know,
6688960	6693760	there's contracts and laws might not be exactly the same, but contracts are kind of the things
6693760	6697760	that most people have to deal with most of the time. And so that's kind of the most common
6697760	6703760	thing that humans have, like humans, that adults in our industrialized society have to deal with
6703760	6709680	a lot. And so that's what we pulled. And we didn't know what was hard about them. But it turns out
6709680	6714960	that the way they're written is very center embedded, has nested structures in them. So
6714960	6718960	it has low frequency words as well. That's not surprising. Lots of texts have low frequency,
6718960	6724800	it does have surprising, slightly lower frequency words than other kinds of control texts, even
6724800	6730000	sort of academic texts. Legalese is even worse. It is the worst that we weren't being able to find.
6730640	6734720	You just reveal the game that lawyers are playing. They're optimizing a different...
6734720	6738880	Well, you know, it's interesting. Now you're getting at why. And so, and I don't think...
6738880	6741920	So now you're saying they're doing intentionally. I don't think they're doing intentionally.
6741920	6744880	But let's... It's an emergent phenomena. Okay.
6744880	6749200	Yeah, yeah, yeah. We'll get to that. We'll get to that. And so, but we wanted to see why. So we
6749200	6753440	see what first as opposed... So because it turns out that we're not the first to observe that
6753440	6761600	legalese is weird, like back to... Nixon had a plain language act in 1970, and Obama had one.
6761600	6767600	And boy, a lot of these... A lot of presidents have said, oh, we've got to simplify legal language,
6767600	6772240	must simplify it. But if you don't know how it's complicated, it's not easy to simplify it. You
6772240	6777120	need to know what it is you're supposed to do before you can fix it. And so you need to cycle
6777120	6782320	linguists to analyze the text and see what's wrong with it before you can fix it. You don't
6782320	6785440	know how to fix it. How am I supposed to fix something? I don't know what's wrong with it.
6785440	6788560	And so what we did was just... That's what we did. We figured out, well, it's okay. We just
6788560	6795040	took a bunch of contracts, had people, and we encoded them for a bunch of features. And so
6795040	6799440	another feature of the people, one of them was the center embedding. And so that is like basically
6799440	6807280	how often a clause would intervene between a subject and a verb, for example. That's one kind
6807280	6813600	of a center embedding of a clause. And turns out they're massively center embedded. So I think
6813600	6820240	in random contracts and in random laws, I think you get about 70% or 70% of sentences
6820240	6824960	have a center embedded clause, which is insanely high. If you go to any other text,
6824960	6830320	it's down to 20% or something. It's so much higher than any control you can think of,
6830320	6835520	including... You think, oh, people think, oh, technical, academic text, no, people don't write
6835520	6840000	center embedded sentences in technical, academic texts. I mean, they do a little bit, but it's
6840000	6845760	on the 20%, 30% realm as opposed to 70. And so there's that. And there's low frequency words.
6845760	6850080	And then people, oh, maybe it's passive. People don't like the passive. Passive, for some reason,
6850080	6854240	the passive voice in English has a bad rap. And I'm not really sure where that comes from.
6856240	6863120	And there is a lot of passive. There's much more passive voice in legalese than there is
6863360	6865920	in other texts. Passive voice accounts for some of the low frequency words.
6865920	6868160	No, no, no, no. Those are separate. Those are separate.
6868160	6870960	Oh, so passive voice sucks. Low frequency word sucks.
6870960	6872400	Well, sucks are different. So these are different.
6872400	6873520	That's a judgment on passive.
6873520	6876160	Yeah, yeah, yeah. Drop the judgment. It's just like, these are frequent.
6876160	6881200	These are things which happen in legalese texts. Then we can ask the dependent measure is like,
6881200	6885520	how well you understand those things with those features. Okay. And so then,
6885520	6889840	and it turns out the passive makes no difference. So it has a zero effect on your comprehension
6889840	6893280	ability, on your recall ability. No, nothing at all. That means no effect.
6894400	6898160	The words matter a little bit. They do low frequency words are going to hurt you in
6898160	6902720	recall and understanding. But what really hurts is the central bedding.
6902720	6908960	That kills you. That is like, that slows people down. That makes them very poor at understanding.
6908960	6912800	That makes them, they can't recall what was said as well, nearly as well.
6912800	6916160	And we did this not only on lay people. We didn't have a lot of lay people.
6916160	6921120	We ran it on a hundred lawyers. We recruited lawyers from a wide range of
6923120	6928000	sort of different levels of law firms and stuff. And they have the same pattern.
6928000	6932960	So they also like, when they did this, I did not know what happened. I thought maybe they could
6932960	6937360	process, they're used to legalese. They think you can process it just as well as it was normal.
6937360	6943360	No, no, they're much better than lay people. So they're much, they can much better recall,
6943360	6948320	much better understanding, but they have the same main effects as lay people, exactly the same.
6948320	6954000	So they also much prefer the non-center. So we constructed non-center embedded versions of
6954000	6959520	each of these. We constructed versions which have higher frequency words in those places.
6959520	6965520	And we did, we un-passivized, we turned them into active versions. The passive active made no
6965520	6971280	difference. The words made a little difference. And the un-center embedding makes big differences
6971280	6974960	in all the populations. Un-center embedding. How hard is that process, by the way?
6974960	6979120	It's not very hard. So I don't question, but how hard is it to detect center embedding?
6979120	6982000	Oh, easy, easy to detect. That's just easy to parse. You just looking at long dependencies?
6982000	6986800	Yeah, yeah. You can just, you can, so there's automatic parsers for English, which are pretty good.
6986800	6988800	And they can detect center embedding. Oh, yeah. Very.
6988800	6992240	Or, I guess, Nestle. Perfectly. Yeah, you learn pretty much.
6992240	6996080	So you're not just looking for long dependencies. You're just literally looking for center embedding.
6996080	6999280	Yeah, we are in this case, in these cases. But long dependencies are, they're highly
6999280	7004800	correlated to this. So like a center embedding is a big bomb you throw inside of a sentence
7004800	7009680	that just blows up the, that makes sure. Yeah. Can I read a sentence for you from these things?
7009680	7012880	Sure. I see. I mean, this is just like one of the things that, this is just terrible.
7012880	7020080	My eyes might glaze over in mid-sentence. No, I understand that. I mean, legally, this is hard.
7020080	7024000	This is a go, because in the event that any payment or benefit by the company,
7024000	7028080	all such payments and benefits, including the payments and benefits under section 3a here of
7028160	7032640	being here and after referred to as a total payments, would be subject to the excise tax,
7033200	7037840	then the cash severance payments shall be reduced. So that's something we pulled from a regular text,
7037840	7039440	from a contract. Wow.
7039440	7043520	And the center embedded bit there is just, for some reason, there's a definition.
7044080	7049760	They throw the definition of what payments and benefits are in between the subject and the verbal.
7049760	7051600	Let's, how about don't do that? Yeah.
7051600	7055920	How about put the definition somewhere else as opposed to in the middle of the sentence?
7055920	7061280	And so that's very, very common, by the way. That's what happens. You just throw your definitions,
7061280	7065840	you use a word, a couple of words, and then you define it, and then you continue the sentence.
7066400	7069600	Like, just don't write like that. And you ask, so then we asked lawyers, we thought,
7069600	7074400	oh, maybe lawyers like this. Lawyers don't like this. They don't like this. They don't want to,
7074400	7079600	they don't want to write like this. They, we asked them to rate materials which are with the same
7079600	7085280	meaning with un-centered bed and center bed, and they much preferred the un-centered bed versions.
7085360	7088480	On the comprehension, on the reading side. Yeah, well, and we asked them,
7088480	7092080	we asked them, would you hire someone who writes like this or this? We asked them all kinds of
7092080	7096640	questions, and they always preferred the less complicated version, all of them. So I don't
7096640	7100640	even think they want it this way. Yeah, but how did it happen? How did it happen? That's a very good
7100640	7107360	question. And the answer is, they still don't know. But I have some theories. Well, our best
7107360	7113360	theory at the moment is that there's actually some kind of a performative meaning in the
7113360	7117920	center embedding and the style which tells you it's legalese. We think that that's the kind
7117920	7123600	of a style which tells you it's legalese. Like that's a reasonable guess. And maybe it's just,
7123600	7128880	so for instance, if you're like, it's like a magic spell. So we kind of call this the magic
7128880	7133120	spell hypothesis. So when you give them, when you tell someone to put a magic spell on someone,
7133120	7138480	what do you do? They, you know, people know what a magic spell is and they do a lot of rhyming.
7138480	7142080	You know, that's kind of what people will tend to do. They'll do rhyming and they'll do sort of
7142160	7147200	like some kind of poetry kind of thing. Abracadabra type of thing. Yeah. And maybe that's,
7147200	7153040	there's a syntactic sort of reflex here of a magic spell which is center embedding. And so
7153040	7157600	that's like, oh, it's trying to like tell you this is like, this is something which is true,
7157600	7163120	which is what the goal of law is, right, is telling you something that we want you to believe as
7163120	7167680	certainly true, right? That's what legal contracts are trying to enforce on you, right?
7167680	7173280	And so maybe that's like a form which has, this is like an abstract, very abstract form,
7173280	7176880	center embedding, which has a, has a, has a meaning associated with it. Well,
7177600	7185120	don't you think there's an incentive for lawyers to generate things that are hard to understand?
7185120	7188960	That was our, one of our working hypotheses. We just couldn't find any evidence of that.
7188960	7193840	No, lawyers also don't understand it. But you're creating space, why you yourself,
7194800	7199520	but I mean, you ask in a communist Soviet Union, the individual members,
7200560	7207360	their self-report is not going to correctly reflect what is broken about the gigantic bureaucracy
7207360	7213680	that leads to Chernobyl or something like this. I think the incentives under which you
7214400	7220080	operate are not always transparent to the members within that system. So like, it just
7220800	7227120	feels like a strange coincidence that like, there is benefit if you just zoom out, look at the
7227120	7232880	system as opposed to asking individual lawyers that making something hard to understand is going
7232880	7240000	to make a lot of people money. Like there's going to, you're going to need a lawyer to figure that
7240000	7244400	out, I guess, from the perspective of the individual, but then that could be the performative aspect.
7244400	7248640	It could be as opposed to the incentive driven to be complicated. It could be performative
7248640	7254640	to where we lawyers speak in this sophisticated way and you regular humans don't understand it,
7254640	7258160	so you need to hire a lawyer. Yeah, I don't know which one it is, but it's suspicious.
7259120	7264480	Suspicious that it's hard to understand and that everybody's eyes glaze over and they don't read.
7264480	7269520	I'm suspicious as well. I'm still suspicious. And I hear what you're saying. It could be kind of a,
7269520	7273600	you know, no individual and even average of individuals, it could just be a few bad apples
7273600	7279360	in a way which are driving the effect in some way. Influential bad apples at the sort of,
7280240	7285520	that everybody looks up to whatever they're like in central figures and how, you know.
7285520	7291120	It turns out, but it is kind of interesting that among our 100 lawyers, they did not share
7291120	7296880	it with us. They really didn't like it. And they weren't better than regular people at
7296880	7301120	comprehending it or they were on average better. But they had the same difference.
7302000	7309520	Exactly, same difference. But they wanted it fixed. And so that gave us hope that
7310160	7315760	because it actually isn't very hard to construct a material which is uncenter embedded and has
7315760	7319280	the same meaning, it's not very hard to do. Just basically in that situation, just putting
7319280	7322960	definitions outside of the subject verb relation in that particular example, and that's kind of,
7323520	7327360	that's pretty general. What they're doing is just throwing stuff in there, which you didn't
7327360	7332480	have to put in there. There's extra words involved. Typically, you may need a few extra
7332480	7337600	words sort of to refer to the things that you're defining outside in some way, because if you
7337600	7344400	only use it in that one sentence, then there's no reason to introduce extra terms. So we might
7344400	7350160	have a few more words, but it'll be easier to understand. So I mean, I have hope that now
7350160	7355200	that maybe we can make legalese less convoluted in this way.
7355200	7360080	So maybe the next president in the United States can, instead of saying generic things, say,
7360080	7367600	I ban center embeddings and make Ted the language czar of the U.S.
7367600	7370480	Eric Martinez is the guy you should really put in there.
7373200	7377200	But center embeddings are the bad thing to have. That's right.
7377200	7380080	So you can get rid of that. That'll do a lot of it. That'll fix a lot.
7380640	7386560	That's fascinating. That is so fascinating. And it is really fascinating on many fronts that humans
7386560	7390160	are just not able to deal with this kind of thing. And that language, because of that,
7390160	7395600	evolved in the way you did. It's fascinating. So one of the mathematical formulations you have
7396240	7400800	when talking about languages communication is, let's say, do you have noisy channels?
7402160	7407600	What's a noisy channel? So that's about communication. And so this is going back
7407600	7415760	to Shannon. So Claude Shannon was a student at MIT in the 40s. And so he wrote this very
7415760	7422400	influential piece of work about communication theory or information theory. And he was interested
7422400	7427840	in human language, actually. He was interested in this problem of communication, of getting a
7428880	7434720	message from my head to your head. And he was concerned or interested in
7435680	7441840	what was a robust way to do that. And so that assuming we both speak the same language, we
7441840	7449440	both already speak English, whatever the language is, we speak that. What is a way that I can say
7449440	7455920	the language so that it's most likely to get the signal that I want to you? And then the problem
7455920	7464000	there in the communication is the noisy channel. There's a lot of noise in the system. I don't
7464000	7469600	speak perfectly. I make errors. That's noise. There's background noise. You know that.
7470880	7474320	Literal background noise. There is like white noise in the background or some other kind of
7474320	7479840	noise. There's some speaking going on that you're at a party. That's background noise. You try to
7479840	7482960	hear someone. It's hard to understand them because there's all this other stuff going on in the
7482960	7490720	background. And then there's noise on the receiver side so that you have some problem
7490800	7495280	maybe understanding me for stuff that's just internal to you in some way. So you've got some
7495280	7500720	other problems, whatever, with understanding for whatever reasons. Maybe you've had too much to
7500720	7505200	drink. Who knows why you're not able to pay attention to the signal? So that's the noisy
7505200	7509520	channel. And so that language, if it's a communication system, we are trying to
7510400	7515440	optimize in some sense the passing of the message from one side to the other. And
7516240	7523920	so, I mean, one idea is that maybe aspects of word order, for example, might have optimized
7523920	7529840	in some way to make language a little more easy to be passed from speaker to listener.
7529840	7534400	And so Shannon's the guy that did the stuff way back in the forties. It's very interesting.
7534400	7539600	Historically, he was interested in working in linguistics. He was in MIT. And this was his
7539600	7544880	master's thesis of all things. It's crazy how much he did for his master's thesis. In 1948,
7544880	7549840	I think, or 49 or something. And he wanted to keep working in language. And it just wasn't a
7549840	7556800	popular communication as a reason, a source for what language was wasn't popular at the time.
7556800	7561520	So Chomsky was becoming, it was moving in there. And he just wasn't able to get a handle there,
7561520	7568160	I think. And so he moved to Bell Haps and worked on communication from a mathematical point of
7568160	7573600	view and did all kinds of amazing work. And so he's just more on the signal side versus
7573680	7578480	like the language side. It would have been interesting to see if you proceed the language
7578480	7582640	side. That's really interesting. Yeah, he was interested in that. His examples in the forties
7582640	7590000	are kind of like, they're very language like things. We can kind of show that there's a
7590000	7595680	noisy channel process going on in when you're listening to me, you can often sort of guess
7595680	7602640	what I meant by what you think I meant given what I said. And I mean, with respect to sort of
7602640	7606800	why language looks the way it does, we might, there might be sort of, as I alluded to, there
7606800	7612640	might be ways in which word order is somewhat optimized for, because of the noisy channel in
7612640	7617840	some way. I mean, that's really cool to sort of model if you don't hear certain parts of a sentence
7618560	7622480	or have some probability of missing that part, like how do you construct a language that's
7622480	7626960	resilient to that? That's somewhat robust to that. Yeah, that's the idea. And then you're kind of
7626960	7632560	saying like the word order and the syntax of language, the dependency length are all
7633120	7637840	helpful. Yeah, well, the dependency length is really about memory, right? I think that's like
7637840	7642880	about sort of what's easier or harder to produce in some way. And these other ideas are about sort
7642880	7648960	of robustness to communication. So the problem of potential loss of loss of signal due to noise.
7648960	7654080	It's so that there may be aspects of word order, which is somewhat optimized for that. And, you
7654080	7658640	know, we have this one guess in that, and these are kind of just so stories. I have to be, you
7658640	7662720	know, pretty frank, they're not like, I can't show this is true. All we can do is like look at the
7662720	7667040	current languages of the world. This is like, we can't sort of see how languages change or anything
7667040	7671520	because we've got these snapshots of a few, you know, hundred or a few thousand languages.
7671520	7677600	We don't really, we can't do the right kinds of modifications to test these things experimentally.
7677600	7682320	And so, you know, so just take this with a grain of salt, okay, from here, this stuff. The dependency
7682320	7687200	stuff I can, I'm much more solid on. I'm like, here's what the lengths are, and here's what's
7687200	7690880	hard. Here's what's easy. And this is a reasonable structure. I think I'm pretty reasonable. Here's
7690880	7696160	like, why, you know, why does the word order look the way it does? We're now into shaky territory,
7696160	7700720	but it's kind of cool. But we're talking about, just to be clear, we're talking about maybe just
7700720	7705360	actually the sounds of communication. Like you and I are sitting in the bar, it's very loud,
7705360	7713120	and you model with a noisy channel, the loudness, the noise, and we have the signal that's coming
7713200	7718240	across. And you're saying word order might have something to do with optimizing that.
7718240	7718800	Yes. Yes.
7718800	7719920	There's a presence of noise. Yes.
7719920	7720800	Yes. Yeah.
7720800	7723760	It's really interesting. I mean, to me, it's interesting how much you can load into the
7723760	7728720	noisy channel. Like how much can you bake in? You said like, you know, cognitive load on the
7728720	7729680	receiver end.
7729680	7734000	We think that those are, there's three, at least three different kinds of things going on there.
7734000	7736320	And we probably don't want to treat them all as the same.
7736320	7736640	Sure.
7736640	7740640	And so I think that you, you know, the right model, a better model of a noisy channel would
7741200	7745040	have three different sources of noise, which are background noise,
7745760	7750800	speaker, inherent noise, and listener, inherent noise. And those are not,
7750800	7751680	those are all different things.
7751680	7755920	Sure. But then underneath it, there's a million other subsets of like what?
7755920	7756720	Oh yeah. That's true.
7756720	7761760	On the receiving, I mean, I just mentioned cognitive load on both sides. Then there's like
7763360	7768000	speech impediments or just everything. World view, I mean, on the meeting,
7768080	7771920	we start to creep into the meeting realm of like, we have different world views.
7771920	7774880	Well, how about just form still though? Like just what language you know?
7774880	7779520	Like, so how well you know the language? And so if it's second language for you versus first
7779520	7784240	language, and how maybe what other languages you know, these are still just form stuff.
7784240	7788880	And that's like potentially very informative. And, you know, how old you are, these things
7788880	7793680	probably matter, right? So like a child learning a language is, is a, you know, as a noisy
7794240	7798560	representation of English grammar, you know, depending on how old they are.
7799200	7802320	So maybe when they're six, they're perfectly formed. But
7803200	7808320	you mentioned one of the things is like a way to measure the language is learning problems.
7808960	7812880	So like, what's the correlation between everything we've been talking about and how
7812880	7821040	easy it is to learn a language? So is like a short dependencies correlated to ability to
7821040	7826400	learn a language? Is there some kind of, or like the dependency grammars, there's some kind of
7827440	7830320	connection there? How easy it is to learn?
7830320	7834720	Yeah, well, all the languages in the world's language, none is right now,
7834720	7839120	we know is any better than any other with respect to sort of optimizing dependency lengths,
7839120	7842240	for example, they're all kind of do it, do it well, they all keep low.
7842720	7847600	It's so that I think of every human language is some kind of an opposite sort of an optimization
7847600	7853040	problem, a complex optimization problem to this communication problem. And so they've,
7853040	7857120	like they've solved it, you know, they're just sort of noisy solutions to this problem of
7857120	7860080	communication. There's just so many ways you can do this.
7860080	7863920	So they're not optimized for learning, they're probably less for communication.
7863920	7866560	And learning. So yes, one of the factors which,
7867120	7871280	yeah, so learning is messing this up a bit. And so, so for example,
7871280	7875760	if it were just about minimizing dependency lengths, and that was all that matters,
7875760	7881520	you know, then we, you know, so then we might find grammars which didn't have regularity
7881520	7886560	in their rules. But languages always have regularity in their rules. So what I mean by
7886560	7891360	that is that if I wanted to say something to you in the optimal way to say it was,
7891360	7894400	it would really matter to me, all that mattered was keeping the dependencies
7895280	7900480	as close together as possible. Then I would have a very lack set of free structure or dependency
7900480	7904160	rule. It wouldn't have very many of those. I would have very little of that. And I would
7904160	7908240	just put the words as close to the things that refer to the things that are connected right
7908240	7912560	beside each other. But we don't do that. Like there are, like there are word order rules, right?
7912560	7916640	So they're very, and depending on the language, they're more and less strict, right? So you speak
7916640	7921040	Russian, they're less strict than English. English is very rigid word order rules. We
7921040	7927280	order things in a very particular way. And so why do we do that? Like that's probably not about
7928160	7931360	communication. That's probably about learning. I mean, then we're talking about learning. It's
7931440	7937760	probably easier to learn regular things, things which are very predictable and easy to, so that's
7937760	7940880	probably about learning is our guess, because that can't be about communication.
7940880	7946320	Can it be just noise? Can it be just the messiness of the development of a language?
7946320	7950080	Well, if it were just a communication, then we should have languages which have very,
7950080	7954640	very free word order. And we don't have that. We have free error, but not free. Like there's
7954640	7960640	always- Well, no, but what I mean by noise is like cultural, like sticky cultural things,
7960640	7966960	like the way, the way you communicate, just there's a stickiness to it. That it's an imperfect,
7967520	7973120	it's a noisy, it's stochastic. The function over which you're optimizing is very noisy.
7974080	7980160	So, because I don't, it feels weird to say that learning is part of the objective function,
7980160	7986000	because some languages are way harder to learn than others, right? Or is that, that's not true.
7986000	7988880	That's interesting. I mean, that's the public perception, right?
7988880	7992640	Yes, that's true for a second language. For a second language.
7992640	7997040	But that depends on what you started with, right? So, it really depends on how close
7997040	8001520	that second language is to the first language you've got. And so, yes, it's very, very hard
8001520	8006240	to learn Arabic if you've started with English, or it's harder to learn Japanese,
8006240	8011680	or if you've started with Chinese, I think is the worst. There's like Defense Language Institute
8011680	8017840	in the United States has like a list of how hard it is to learn what language from English.
8017840	8020240	I think Chinese is the worst. But that's the second language.
8020240	8024640	You're saying babies don't care? No. There's no evidence that there's anything harder,
8024640	8029360	easier, but any baby, any language learned, like three or four, they speak that language.
8029360	8033440	And so, there's no evidence of anything harder, easier, but any human language. They're all
8033440	8040720	kind of equal. To what degree is language, this is returning to Chomsky a little bit, is innate.
8041520	8045280	You said that for Chomsky, he used the idea that language is,
8045280	8048720	some aspects of language are in need to explain away certain things that are observed.
8049680	8055200	How much are we born with language at the core of our mind, brain?
8056880	8063120	I mean, I, you know, the answer is I don't know, of course, but the, I mean, I like to,
8063120	8068160	I'm an engineer at heart, I guess, and I sort of think it's fine to postulate that a lot of
8068160	8073120	it's learned. And so, I'm guessing that a lot of it's learned. So, I think the reason Chomsky
8073120	8080960	went with innateness is because he hypothesized movement in his grammar. He was interested in
8080960	8085360	grammar and movement's hard to learn. I think he's right. Movement is a hard thing to learn,
8085360	8089520	to learn these two things together and how they interact. And there's like a lot of ways in which
8089520	8092960	you might generate exactly the same sentences. And it's like really hard. And so, he's like,
8092960	8098480	oh, I guess it's learned. Sorry, I guess it's not learned, it's innate. And if you just throw out
8098480	8104320	the movement and just think about that in a different way, you know, then you get some messiness.
8104880	8110560	But the messiness is human language, which it actually fits better. That messiness isn't a
8110560	8120560	problem. It's actually, it's a valuable asset of the theory. And so, I think I don't really see a
8120560	8125280	reason to postulate much innate structure. And that's kind of why I think these large language
8125360	8130800	models are learning so well, is because I think you can learn the form, the forms of human language
8130800	8134400	from the input. I think that's like, it's likely to be true.
8134400	8137200	So that part of the brain that lights up when you're doing all the comprehension,
8137200	8140240	that could be learned. That could be just, you don't need, you don't need any.
8140240	8146640	It doesn't have to be innate. So, like lots of stuff is modular in the brain that's learned.
8146640	8151440	It doesn't have to, you know, so there's something called the visual word form area in the back.
8151520	8156640	And so, it's in the back of your head, near the, you know, the visual cortex, okay? And that
8157360	8162240	is very specialized language, sorry, very specialized brain area, which does
8164080	8168000	visual word processing if you read, if you're a reader, okay? If you don't read, you don't have it,
8168000	8172560	okay? Guess what? You spend some time learning to read and you develop that brain area,
8172560	8176960	which does exactly that. And so, these, the modularization is not evidence for
8176960	8181200	innateness. So, the modularization of a language area doesn't mean we're born with it.
8181200	8186880	We could have easily learned that. We might have been born with it. We just don't know at this
8186880	8191680	point. We might very well have been born with this left lateralized area. I mean, there's like
8191680	8197440	a lot of other interesting components here, features of this kind of argument. So, some people
8198080	8202640	get a stroke or something goes really wrong on the left side, where the left, where the language
8202640	8207440	area would be. And that, and that isn't there. It's not, not available. And it develops just
8207440	8212560	fine on the right. So, it's no lie. So, it's not about the left. It goes to the left. Like,
8212560	8217840	this is a very interesting question. It's like, why is the, why are any of the brain areas the
8217840	8222800	way that they are? And how, how, how did they come to be that way? And, you know, there's these
8222800	8227200	natural experiments, which happen where people get these, you know, strange events in their
8227200	8232720	brains at very young ages, which wipe out sections of their brain and, and they behave
8232720	8236560	totally normally and no one knows anything was wrong. And we find out later, because they happen
8236560	8240640	to be accidentally scanned for some reason. It's like, what, what happened to your left hemisphere?
8240640	8243760	It's missing. There's not many people who have missed their whole left hemisphere, but they'll
8243760	8247840	be missing some other section of their left or their right. And they behave absolutely normally,
8247840	8253440	we would never know. So, that's like a very interesting, you know, current research. You know,
8253440	8257920	this is another project that this person in Federico is working on. She's got all these people
8257920	8265040	contacting her because she's scanned some people who have been missing sections, one person missing,
8265040	8269520	missed a section of her brain and was scanned in her lab. And she, and she happened to be a writer
8269520	8275280	for the New York Times. And there was an article in the New York Times about, about the, just about
8275280	8280720	the scanning procedure and, and about what might be learned about by sort of the general process
8280720	8286080	of MRI and language and that's her language. And, and because she's writing for the New York Times,
8286080	8291920	then she, all these people started writing to her who also have similar, similar kinds of deficits
8291920	8298080	because they've been, you know, accidentally, you know, to scan for some reason and, and found
8298080	8303120	out they're missing some section. And they, they volunteer to be scanned. These are natural
8303120	8306960	experiments. Natural experiments. They're kind of messy, but natural experiments kind of cool.
8307760	8313360	She calls them interesting brains. The first few hours, days, months of human life are fascinating.
8313360	8317040	It's like, well, inside the womb, actually, like that development,
8319440	8325040	that machinery, whatever that is, seems to create powerful humans that are able to speak,
8325040	8329680	comprehend, think, all that kind of stuff, no matter what happened, not no matter what, but
8329760	8336960	robust to the different ways that the brain might be damaged and so on. That's really,
8336960	8342800	that's really interesting. But what would Chomsky say about the fact, the thing you're saying now,
8342800	8349760	that language is, seems to be happening separate from thought? Because as far as I understand,
8349760	8354320	maybe you can correct me, he thought that language underpins. Yeah, he thinks so. I don't know what
8354320	8360320	he'd say. He would be surprised because for him, the idea is that language is a sort of the foundation
8360320	8367440	of thought. That's right. Absolutely. And it's pretty mind blowing to think that it could be
8367440	8372480	completely separate from thought. That's right. But so, you know, he's basically a philosopher,
8372480	8375360	philosopher of language in a way, thinking about these things. It's a fine thought.
8376480	8381760	You can't test it in his methods. You can't do a thought experiment to figure that out.
8381760	8387360	You need a scanner. You need brain damage people. You need something. You need ways to measure that.
8387360	8393920	And that's what, you know, fMRI offers as a, and, you know, patients are a little messier.
8393920	8400240	fMRI is pretty unambiguous, I'd say. It's like very unambiguous. There's no way to say that
8400240	8405440	the language network is doing any of these tasks. There's, like, you should look at those data.
8405440	8409760	It's like, there's no chance that you can say that those networks are overlapping. They're not
8409760	8414160	overlapping. They're just, like, completely different. And so, you know, so the, you know,
8414160	8417840	you can always make, you know, it's only two people. It's four people or something for the
8418560	8422640	patients. And there's something special about them we don't know. But these are just random people.
8423280	8428640	And with lots of them, and you find always the same effects. And it's very robust, I'd say.
8428640	8435440	What's a fessing effect? What's the, you mentioned Bolivia. What's the connection between
8436000	8445440	culture and language? You've also mentioned that, you know, much of our study of language
8445440	8452720	comes from W-E-I-R-D, weird people, western educated, industrialized, rich, and democratic.
8453680	8460400	So when you study, like, remote cultures, such as around the Amazon jungle, what can you learn
8460480	8468000	about language? So that term weird is from Joe Henrich. He's at Harvard. He's a Harvard
8468000	8475520	evolutionary biologist. And so he works on lots of different topics. And he basically was pushing
8475520	8481680	that observation that we should be careful about the inferences we want to make when we're talking
8481680	8488640	in psychology or, yeah, mostly in psychology, I guess, about humans if we're talking about,
8489520	8494160	undergrads at MIT and Harvard. Those aren't the same, right? These aren't the same things.
8494160	8499760	And so if you want to make inferences about language, for instance, there's a lot of very,
8500320	8505360	a lot of other kinds of languages in the world, then English and French and Chinese, you know.
8505360	8512000	And so maybe for language, we care about how culture, because cultures can be very,
8512000	8514880	I mean, of course, English and Chinese cultures are very different. But
8515520	8521280	you know, hunter-gatherers are much more different in some ways. And so if culture
8521280	8526960	hasn't affected what language is, then we kind of want to look there as well as looking. It's
8526960	8530320	not like the industrialized cultures aren't interesting. Of course they are. But we want
8530320	8535120	to look at non-industrialized cultures as well. And so I've worked with two. I've worked with
8535120	8542400	Chimani, which are in Bolivia and Amazon, both in the Amazon in these cases. And there are
8542400	8548480	so-called farmer foragers, which is not hunter-gatherers. It's sort of one up from hunter-gatherers
8548480	8552960	in that they do a little bit of farming as well. A lot of hunting as well, but a little bit of
8552960	8557520	farming. And the kind of farming they do is the kind of farming that I might do if I ever were
8557520	8563520	to grow like tomatoes or something in my backyard. So it's not like big field farming. It's just a
8563520	8567440	farming for a family, a few things you do that. And so that's the kind of farming they do.
8567840	8574720	And the other group I've worked with are the Pirah, which are also in the Amazon and happen
8574720	8582480	to be in Brazil. And that's with a guy called Dan Everett, who is a linguist, anthropologist,
8582480	8588160	who actually lived and worked in the... I mean, he was a missionary, actually, initially, back in
8588160	8593920	the 70s, working with trying to translate languages so they could teach them the Bible,
8593920	8599200	teach them Christianity. What can you say about that? Yeah, so the two groups I've worked with,
8599200	8605680	the Cimani and the Pirah, are both isolate languages, meaning there's no known connected
8605680	8609760	languages at all. They're just like on their own. Oh, cool. Yeah, there's a lot of those. And most of
8609760	8619520	the isolates occur in the Amazon or in Papua New Guinea, in these places where the world has
8619520	8626240	sort of stayed still for long enough. And so there aren't earthquakes. There aren't...
8628400	8634240	Well, certainly no earthquakes in the Amazon jungle. And the climate isn't bad. So you don't
8634240	8639360	have droughts. And so in Africa, you've got a lot of moving of people because there's
8639360	8643600	drought problems. And so they get a lot of language contact when people have to...
8644320	8650160	You've got to move because you've got no water, then you've got to get going. And then you run
8650160	8655600	into contact with other tribes, other groups. In the Amazon, that's not the case. And so people
8655600	8659520	can stay there for hundreds and hundreds and probably thousands of years, I guess. And so these
8659520	8665280	groups have... The Cimani and the Pirah are both isolates in that. And I guess they've just lived
8665280	8673040	there for ages and ages with minimal contact with other outside groups. And so, I mean,
8673120	8678960	I'm interested in them because they are... In these cases, I'm interested in their words.
8678960	8683840	I would love to study their syntax, their orders of words, but I'm mostly just interested in how
8683840	8690800	languages are connected to their cultures in this way. And so with the Pirah,
8690800	8695600	sort of most interesting, I was working on number there, number information. And so the
8695600	8699200	basic idea is I think language is invented. That's what I get from the words here is that
8699200	8703120	I think language is invented. We talked about color earlier. It's the same idea,
8703120	8708640	so that what you need to talk about with someone else is what you're going to invent words for.
8709200	8716240	And so we invent labels for colors that I need, not that I can see, but that things I need to
8716240	8720080	tell you about so that I can get objects from you or get you to give me the right objects.
8720080	8726960	And I just don't need a word for teal or a word for aquamarine in the Amazon jungle,
8726960	8730640	for the most part, because I don't have two things which differ on those colors. I just
8730640	8736560	don't have that. And so numbers are really another fascinating source of information here where
8737440	8744880	you might... Naively, I certainly thought that all humans would have words for exact counting
8746000	8751920	and the Pirah don't. So they don't have any words for even one. There's not a word for one
8751920	8757920	in their language. And so there's certainly not a word for two, three, or four. So that kind of
8757920	8762400	blows people's minds off. Yeah, that is blowing my mind. That's pretty weird. How are you going to
8762400	8767760	ask, I want two of those? You just don't. And so that's just not a thing you can possibly ask
8767760	8772160	in the Pirah. It's not possible. That is, there's no words for that. So here's how we found this
8772160	8778240	out. So it was thought to be a one, two, many language. There are three words, four quantifiers
8778960	8785280	for sets. And people had thought that those meant one, two, and many. But what they really
8785280	8790320	mean is few, some, and many. Many is correct. It's few, some, and many. And so the way we
8790320	8798400	figured this out, and this is kind of cool, is that we gave people... We had a set of objects.
8798400	8802320	These are having to be spools of thread. It doesn't really matter what they are. Identical objects.
8802320	8806400	And when I sort of start off here, I just give you one of those and say,
8806400	8810800	what's that? Okay, so you're a Pirah speaker and you tell me what it is. And then I give you two
8810800	8815680	and say, what's that? And nothing's changing in this set except for the number. And then I just
8815680	8819120	ask you to label these things. We just do this for a bunch of different people. And frankly,
8819120	8826000	it's a... I did this task. And it's a little bit weird. So they say the word that we thought was
8826000	8830240	one, it's few, but for the first one. And then maybe they say few or maybe they say some for
8830240	8835360	the second. And then for the third or the fourth, they start using the word many for the set. And
8835360	8840720	then five, six, seven, eight. I go all the way to ten. And it's always the same word. And they
8840720	8846480	look at me like I'm stupid because they told me what the word was for six, seven, eight. And I'm
8846480	8851760	going to continue asking them at nine and ten. I'm sorry. They understand that I want to know
8851760	8855120	their language. That's the point of the task is like I'm trying to learn their language. And so
8855120	8861120	that's okay. But it does seem like I'm a little slow because they already told me what the word
8861120	8865840	for many was, five, six, seven. And I keep asking. So it's a little funny to do this task over and
8865840	8871120	over. We did this with a guy called... Dan was our translator. He's the only one who really speaks
8871120	8879200	Piazza fluently. He's a good bilingual for a bunch of languages, but also English and Piazza.
8879200	8883520	And then a guy called Mike Frank was also a student with me down there. He and I did these
8883520	8890560	things. And so you do that. Okay. And everyone does the same thing. We asked like 10 people.
8890560	8895040	And they all do exactly the same labeling for one up. And then we just do the same thing
8895040	8899040	down on random order. Actually, we do some of them up, some of them down first. Okay.
8899040	8903600	And so we do, instead of one to 10, we do 10 down to one. And so I give them 10,
8903600	8908960	nine, eight. They start saying the word for some. And then when you get to four,
8908960	8914960	everyone is saying the word for few, which we thought was one. So the context determined
8914960	8920160	what that quantifier they used was. So it's not a count word. They're not count words.
8920400	8923520	They're just approximate words. And they're going to be noisy when you interview a bunch
8923520	8927360	of people, what the definition of few, and there's going to be a threshold in the context.
8928160	8931040	Yeah, I don't know what that means. That's going to be 10 on the context. I think it's
8931040	8933840	true in English too, right? If you ask an English person what a few is, I mean,
8933840	8937760	that's going to depend completely on the context. And it might actually be at first
8937760	8942880	hard to discover. Because for a lot of people, the jump from one to two will be few.
8943680	8946640	Right? So it's a jump. Yeah, it might be. It might still be there. Yeah.
8947600	8951120	I mean, that's fascinating. That's fascinating that numbers don't present themselves.
8951120	8954400	Yeah. So the words aren't there. And then, and so then we do these other things. Well,
8954400	8960640	if they don't have the words, can they do exact matching kinds of tasks? Can they even do those
8960640	8967600	tasks? And the answer is sort of yes and no. And so yes, they can do them. So here's the tasks
8967600	8972320	that we did. We put out those spools of thread again. Okay. So maybe I put like three out here.
8972320	8977760	And then we gave them some objects. And those happen to be uninflated red balloons. It doesn't
8977760	8982400	really matter what they are. It's just a bunch of exactly the same thing. And it was easy to
8982400	8988320	put down right next to these spools of thread. Okay. And so then I put out three of these.
8988320	8994080	And your task was to just put one against each of my three things. And they could do that perfectly.
8994080	8997840	So I mean, I would actually do that. It was a very easy task to explain to them because I have,
8997840	9003040	I did this with this guy, Mike Frank, and he would be my, I'd be the experimenter telling him to do
9003040	9007200	this and showing him to do this. And then we just like, just do what he did. You'll copy him. All we
9007200	9012160	had to, I didn't have to speak to him, except for know what copy him, like do what he did is like
9012160	9016160	all we had to be able to say. And then they would do that just perfectly. And it's always
9016160	9022160	moving up. We do some sort of random number of items up to 10. And they basically do perfectly
9022160	9026160	on that. They never get that wrong. I mean, that's not a counting task, right? That is just a match.
9026160	9029280	You just put one against them. It doesn't matter how many, I don't need to know how many there are
9029280	9035520	there to do that correctly. And they would make mistakes, but very, very few and no more than
9035520	9040880	MIT undergrads. Just going to say, like there's no, these are low stakes. So, you know, you make
9040880	9044640	mistakes. Counting is not required to complete the matching task. That's right. Not at all. Okay.
9044640	9049920	And so, and so that's our control. And this guy had gone down there before and said that they
9049920	9053600	couldn't do this task, but I just don't know what he did wrong there because they can do this task
9053600	9058160	perfectly well. And, you know, I can train my dog to do this task. So, of course, they can do this
9058160	9063360	task. And so, you know, it's not a hard task. But the other task that was sort of more interesting
9063360	9070320	is like, so then we do a bunch of tasks where you need some way to encode the set.
9070320	9078880	So, like one of them is just a, I just put a opaque sheet in front of the things I put down a
9078880	9083200	bunch of set of these things and I put an opaque sheet down. And so you can't see them anymore.
9083200	9086960	And I tell you, do the same thing you were doing before, right? You know, and it's easy if it's
9086960	9092480	two or three, it's very easy. But if I don't have the words for eight, it's a little harder, like,
9092480	9098320	maybe, you know, with practice, well, no. Because you have to count. For us, it's easy
9098320	9102560	because we just, we just count them. It's just so easy to count them. But, but they don't,
9102560	9105840	they can't count them because they don't count. They don't have words for this thing. And so,
9105840	9108800	they would do approximate. It's totally fascinating. So, they would get them
9108800	9113840	approximately right, you know, after four or five, you know, because you can,
9113840	9118000	basically, you always get four right, three or four, that looks, that's something we can
9118000	9122640	visually see. But, but after that, you kind of have, it's an approximate number. And so,
9122640	9127440	then, and there's a bunch of tasks we did, and they all failed as, I mean, failed. They did
9127440	9132320	approximate after five on all those tasks. And it kind of shows that the words,
9133600	9137280	you kind of need the words, you know, to be able to do these, these kinds of tasks.
9137280	9141680	This is a little bit of a chicken and egg thing there. Because if you don't have the words,
9142720	9148000	then maybe they'll limit you in the kind of, like a little baby Einstein there,
9148720	9153840	won't be able to come up with a counting task. You know what I mean? Like, the ability to count
9153840	9160480	enables you to come up with interesting things, probably. So, yes, you develop counting because
9160480	9165280	you need it. But then, once you have counting, you can probably come up with a bunch of different
9165280	9172240	inventions, like how to, I don't know, what kind of thing they do matching really well for
9172240	9178000	building purposes, building some kind of hut or something like this. So, it's interesting that
9178000	9181600	language is a, a limiter on what you're able to do.
9181600	9187040	Yeah, here's language is just, is the words, here is the words, like the words for exact count
9187680	9190560	is the limiting factor here. They just don't have them.
9190880	9198240	Yeah. Well, that's what I mean. That limit is also a limit on the society of what they're able to
9198240	9203360	build. That's going to be true. Yeah. So, it's problem, I mean, we don't know, this is one of
9203360	9207840	those problems with the snapshot of just current languages is that we don't know what causes a
9207840	9214080	culture to discover slash invent accounting system. But the hypothesis is the guess out there is
9214080	9220080	something to do with farming. So, if you have a bunch of goats and you want to keep track of them,
9220560	9224560	and you have saved 17 goats and you go to bed at night and you get up in the morning,
9224560	9229680	boy, it's easier to have a count system to do that. You know, that's an abstract abstraction
9229680	9234320	over a set. So, they don't have, like, people often ask me when I talk to them about this kind
9234320	9237360	of work, and they say, well, don't these, Peter, huh, don't they have kids? Don't they have a lot
9237360	9241280	of children? I'm like, yeah, they have a lot of children. And they do, they often have families
9241280	9245120	of three or four or five kids. And they go, well, don't they need the numbers to keep track of their
9245120	9250160	kids? And I always ask the person who says this, like, do you have children? And the answer is
9250160	9255040	always no, because that's not how you keep track of your kids. You care about their identities.
9255040	9260320	It's very important to me when I go, I think I have five children. It's, it's, it doesn't matter
9260320	9266000	which, yeah, it matters which five. It's like, if you replaced one with someone else, I would,
9266000	9270240	I would care. A goat maybe not, right? That's the kind of point. It's an abstraction,
9270240	9273760	something that looks very similar to the one wouldn't matter to me, probably.
9273760	9277760	But if you care about goats, you're going to know them actually individually also.
9277760	9281280	Yeah, you will. I mean, cows and goats, if there's a source of food and milk and all that kind
9281280	9284560	of stuff, you're going to actually do it right there. But I'm saying it is an abstraction
9284560	9288400	such that you don't have to care about their identities to do this thing fast. That's,
9288400	9293680	that's the hypothesis, not mine. From anthropologists are guessing about where
9293680	9300400	words for counting came from is from farming, maybe. Yeah. Do you have a sense why universal
9300400	9307440	languages like Esperanto have not taken off? Like, why do we have all these different languages?
9307920	9314640	Well, my guess is the function of a language is to do something in a community. And I mean,
9314640	9318880	unless there's some function to that language in the community, it's not going to survive.
9318880	9323760	It's not going to be useful. So here's a great example. So what I'm like, language death is
9323760	9329440	super common. Okay. Languages are dying all around the world. And here's why they're dying.
9329440	9333600	And it's like, yeah, I see this in, you know, it's not happening right now in either the
9333600	9338240	Chimane or the, or the Piedoha, but it probably will. And so there's a neighboring group called
9338240	9344720	Mostitan, which is, I said that it's a isolates. Actually, there's a dual. There's two of them.
9344720	9348640	Okay. So it's actually, there's two languages, which are really close, which are Mostitan
9348640	9355040	and Chimane, which are unrelated to anything else. And Mostitan is unlike Chimane in that
9355040	9360160	it has a lot of contact with Spanish and it's dying. So that language is dying. The reason it's
9360160	9367200	dying is there's not a lot of value for the local people in their native language. So there's much
9367200	9372160	more value in knowing Spanish, like because they want to feed their families. And how do you feed
9372160	9376400	your family? You learn Spanish, so you can make money, so you can get a job and do these things.
9376400	9380640	And then you can, and then you make money. And so they want Spanish things they want. And so,
9380640	9387040	so Mostitan is in danger and is dying. And that's normal. And so basically the problem is that people,
9388000	9395440	the reason we learn languages to communicate, and we need to, we use it to make money and to
9395440	9402640	do whatever it is to feed our families. And if that's not happening, then it won't take off.
9402640	9407360	It's not like a game or something. This is like something we use. Like, why is English so popular?
9407360	9412240	It's not because it's an easy language to learn. Maybe it is. I don't really know.
9413040	9417360	But that's not why it's popular. But because the United States is a gigantic economy.
9417360	9422160	Yeah. It's big economies that do this. It's all it is. It's all about money. And that's what,
9422160	9426960	and so there's a motivation to learn Mandarin. There's a motivation to learn Spanish. There's
9426960	9430800	a motivation to learn English. These languages are very valuable to know because there's so,
9430800	9436160	so many speakers all over the world. There's less of a value economically. It's like kind of what
9436160	9440720	drives this. It's not a, but it's not a, you know, it's not just for fun. I mean, there are these
9440720	9445760	groups that do want to learn language just for language's sake. And then there's something,
9445760	9450720	you know, to that, but those are rare. Those are rarities in general. Those are a few small
9450720	9454240	groups that do that. Not most people don't do that. Well, if that was the primary driver,
9454240	9458400	then everybody was speaking English or speaking one language. There's also a tension.
9458400	9459280	That's happening.
9459280	9462880	And that, well, we're moving towards fewer and fewer languages.
9462880	9468400	We are. I wonder, you're right. Maybe, maybe, you know, this is slow, but maybe that's where
9468400	9474880	we're moving. But there is a tension. You're saying a language that the fringes. But if you
9475440	9480080	look at geopolitics and superpowers, it does seem that there's another thing in tension,
9480080	9485920	which is a language is a national identity sometimes. For a certain nation. I mean,
9485920	9491280	that's the, the war in Ukraine, language, Ukrainian language is a symbol of that war
9491840	9496800	in many ways, like a country fighting for its own identity. So it's not merely the convenience.
9496800	9501760	I mean, those two things that are a tension is the, the convenience of trade and the economics
9501760	9507520	and be able to communicate with neighboring countries and trade more efficiently with
9507520	9511360	neighboring countries, all that kind of stuff, but also identity of the group.
9511360	9512640	That's right. I completely agree.
9512640	9520400	Because language is the way, for every community, like dialects that emerge are a kind of identity
9520400	9526720	for people. And sometimes a way for people to say FU to the more powerful people.
9527360	9531120	That's interesting. So in that way, language can't be used as that tool.
9531120	9537200	Yeah. I completely agree. And there's a lot of work to try to create that identity. So people
9537200	9544720	want to do that. Speak, you know, as a cognitive scientist and language expert, I hope that continues
9544720	9548080	because I don't want languages to die. I want languages to survive because,
9550080	9555920	because they're so interesting for, for so many reasons. But I mean, I find them fascinating
9555920	9559760	just for the language part, but I think they, you know, there's a lot of connections to culture
9559760	9565440	as well, which is also very important. Do you have hope for machine translation
9565440	9569680	that can break down the barriers of language? So while all these different diverse languages
9569680	9576800	exist, I guess there's many ways of asking this question, but basically how hard is it to translate
9577680	9580240	in an automated way from one language to another?
9580240	9584640	There's, there's going to be cases where it's going to be really hard, right? So there are concepts
9585360	9589920	that are in one language and not in another. Like the most extreme kinds of cases are these
9589920	9595120	cases of number information. So exactly, like good luck translating a lot of English into
9595680	9599840	it's just impossible. There's no way to do it because there are no words for these concepts
9599840	9605040	that we're talking about. There's probably the flip side, right? There's probably stuff in
9606400	9610480	which is going to be hard to translate into English on the other side. And so I just don't
9610480	9615680	know what those concepts are. I mean, you know, the space, the world space is a little, is different
9615680	9619440	from my world space. And so I don't know what like, so that the things they talk about things are,
9620080	9624320	you know, it's going to have to do with their life as opposed to, you know, my industrial life,
9624320	9628560	which is going to be different. And so there's going to be problems like that always.
9629280	9632560	You know, there's like, it's not, maybe it's not so bad in the case of some of these spaces,
9632560	9637040	and maybe it's going to be harder than others. And so it's pretty bad in number. It's like,
9637040	9641520	you know, extreme, I'd say, in the number space, you know, exact number space, but in the color
9641520	9646640	dimension, right? So that's not so bad. There's, I mean, but it's a problem that, that you don't
9646640	9652160	have ways to talk about the concepts. There might be entire concepts that are missing. So to you,
9652160	9658240	it's more about the space of concept versus the space of form. Like form, you can probably map.
9658240	9664240	Yes. Yeah. But so you were talking earlier about translation and about how translations,
9664960	9668240	you know, there's good and bad translations. I mean, now we're talking about translations of
9668240	9676080	form, right? So what makes a writing good, right? It's not just the content. It's, you know,
9676080	9680160	it's how it's written. And translating that, I, you know, I, you know, that's,
9680160	9686480	that sounds difficult. We should, we should say that there is like, I don't, it has a day to say
9686480	9692640	meaning, but there's a music and a rhythm to the form. When you look at the broad picture, like
9692640	9700880	the Fritz Wietzi and Dostoyevsky and Tolstoy, or Hemingway Bukowski, James Joyce, like I mentioned,
9700880	9704800	there's a beat to it. There's an edge to it that it's like, is in the form.
9706000	9711760	We can probably get measures of those. Yeah. I don't know. I'm optimistic that we could get
9711760	9716000	measures of those things. And so maybe that's translatable. I don't know. I don't know though.
9716000	9719760	I haven't worked on that. I would love to see. That sounds totally fascinating.
9719760	9725920	Translation to Hemingway. I mean, Hemingway is probably the lowest, I would love to see
9725920	9733120	different authors, but the average per sentence dependency length for Hemingway is probably
9733120	9739440	the shortest. That's your sense, huh? It's simple sentences with short, yeah, yeah, yeah, yeah.
9739440	9742560	I mean, that's when, if you have really long sentences, even if they don't have center of
9742560	9746240	writing, like. They can have longer connections. Yeah. They can have longer connections. They
9746240	9750320	don't have to, right? You can have a long, long sentence with a bunch of local words. Yeah.
9750320	9754480	Yeah. But it's, but it is much more likely to have the possibility of long dependencies with
9754480	9761840	long sentences. Yeah. I met a guy named Azar Askin who does a lot of cool stuff. Really
9761840	9767040	brilliant. He works with Tristan Harris and a bunch of stuff. But he was talking to me about
9768160	9774400	communicating with animals. He co-founded Earth Species Project, where you're trying to find
9774400	9781360	the common language between whales, crows, and humans. And he was saying that there is a lot
9781360	9786560	of promising work that even though the signals are very different. Right. Like the actual, like,
9788480	9794160	if you have embeddings of the languages, they're actually trying to communicate similar type things.
9796720	9801280	Is there something you can comment on that? Like where, is there promise to that? And everything
9801280	9805440	you've seen in different cultures, especially like remote cultures, that this is a possibility?
9805520	9812560	No. They can talk to whales. I would say yes. I think it's not crazy at all. I think it's quite
9812560	9820320	reasonable. There's this sort of weird view, well, odd view, I think, that to think that human language
9820320	9827600	is somehow special. I mean, it is, maybe it is. We can certainly do more than any of the other
9827680	9838000	species. And maybe our language system is part of that. It's possible. But people do have often
9838000	9844480	talked about how human, like Chomsky, in fact, has talked about how human language has this
9846000	9851680	compositionality thing that he thinks is sort of key in language. And the problem with that
9851680	9857440	argument is he doesn't speak whale. And he doesn't speak crow, and he doesn't speak monkey.
9858480	9863600	They say things like, well, they're making a bunch of grunts and squeaks. And the reasoning is like,
9864160	9869440	that's bad reasoning. I'm pretty sure if you asked a whale what we're saying, they'd say, well,
9869440	9875360	I'm making a bunch of weird noises. Exactly. And so it's like, this is a very odd reasoning to
9875360	9878720	be making that human language is special because we're the only ones who have human language. I'm
9879360	9885440	well, we don't know what those other, we just don't, we can't talk to them yet. And so there
9885440	9891280	are probably a signal in there. And it might very well be something complicated, like human language.
9891280	9896960	I mean, sure, with a small brain, in lower species, there's probably not a very good
9896960	9901840	communication system. But in these higher species where you have what seems to be
9903200	9908080	abilities to communicate something, there might very well be a lot more signal there than we're
9909280	9912880	than we might have otherwise thought. But, but also if we have a lot of intellectual
9912880	9917280	humility here, as somebody formerly from MIT, Neri Oxman, who I admire very much,
9918000	9926960	has talked a lot about, has worked on communicating with plants. So like, yes, the signal there is
9926960	9933680	even less than we're like, it's not out of the realm of possibility that all nature has a way of
9933680	9939440	communicating. And it's a very different language, but they do develop a kind of language through
9939440	9945200	the chemistry, through some way of communicating with each other. And if you have enough humility
9945200	9950720	about that possibility, I think you can, I think it would be a very interesting in a few decades,
9951520	9957520	maybe centuries, hopefully not a humbling possibility of being able to communicate not
9957520	9962880	just between humans effectively, but between all of living things on earth.
9964000	9966880	Well, I mean, I think some of them are not going to have much interesting to say,
9968320	9974240	we don't know. We certainly don't know. I think if we're humble, there could be some
9974240	9979680	interesting trees out there. Well, they're probably talking to other trees, right? They're not talking
9979680	9984160	to us. And so to the extent they're talking, they're saying something interesting to some other,
9984800	9990000	you know, conspecific as opposed to us, right? And so there probably is, there may be some signal
9990000	9996560	there. So there are people out there, actually it's pretty common to say that human language
9996560	10002960	is special and different from any other animal communication system. And I just don't think
10002960	10010880	the evidence is there for that claim. I think it's not obvious. We just don't know, because we
10010880	10016720	don't speak these other communication systems until we get better. You know, I do think there's,
10016720	10019520	there are people working on that, as you pointed out, though, people working on
10019520	10022000	whale speak, for instance, like that's really fascinating.
10022000	10027440	Let me ask you a wild out there sci-fi question. If we make contact with an intelligent alien
10027440	10035040	civilization and you get to meet them, how hard do you think, like how surprised would you be
10035040	10040560	about their way of communicating? Do you think it would be recognizable? Maybe there's some
10040560	10045760	parallels here when you go to the remote tribes. I mean, I would want Dan Everett with me. He is
10045760	10051040	like amazing at learning foreign languages. And so he like, this is an amazing feat, right, to be
10051040	10056320	able to go, this is a language, which has no translators before him. I mean, there were,
10056320	10060320	he was a mystery, well, there was a guy that had been there before, but he wasn't very good.
10060320	10065920	And so he learned the language far better than anyone else had learned before him. He's like good
10065920	10070480	at, he's just a, he's a very social person. I think that's a big part of it is being able to
10070480	10076640	interact. So I don't know, it kind of depends on these, this species from outer space, how
10076640	10080480	much they want to talk to us. Is there something you can say about the process he follows?
10080480	10085920	Like what, how do you show up to a tribe and socialize? I mean, I guess colors and counting is
10085920	10089600	one of the most basic things to figure out. Yeah, you start that. You actually start with
10089600	10094160	like objects and just say, you know, just throw a stick down and say stick. And then you say,
10094160	10097760	what do you call this? And then they'll say the word, whatever. And he says,
10097760	10101120	the standard thing to do is to throw two sticks at two sticks. And then, you know,
10101120	10105360	he learned pretty quick that there weren't any count words in this language because
10105360	10108800	they didn't know this wasn't interesting. I mean, it was kind of weird. They'd say some or
10108800	10112320	something, the same word over and over again. And so, but that is a standard thing. You just
10112320	10117840	like try to, but you have to be pretty out there socially, like willing to talk to random people,
10118640	10122400	which these are, you know, really very different people from you. And he was, and he's,
10122400	10125440	he's very social. And so I think that's a big part of this is like, that's how,
10126080	10130480	you know, a lot of people know a lot of languages that they're willing to talk to other people.
10130480	10135280	That's a tough one. We just show up knowing nothing. Yeah. Oh, God. It's beautiful that
10135280	10140560	humans are able to connect in that way. Yeah. Yeah. You've had an incredible career exploring
10140560	10146480	this fascinating topic. What advice would you give to young people about how to have a career
10147440	10152320	like that or a life that they can be proud of? When you see something interesting,
10152320	10156880	just go and do it. Like I do, I do that. Like that's something I do, which is kind of unusual
10156880	10160880	for most people. So like when I saw the, like if Piedoha was available to go and visit, I was like,
10160880	10167920	yes, yes, I'll go. And then when we couldn't go back, we had some trouble with the Brazilian
10167920	10171520	government. There's some corrupt people there. It was very difficult to get, go back in there.
10171520	10174960	And so I was like, all right, I got to find another group. And so we searched around and
10174960	10178960	we were able to find the, because I wanted to keep working on this kind of problem. And so we
10178960	10182880	found the Chimani and just go there. I didn't really have, we didn't have contact. We had a
10182880	10187600	little bit of contact and brought someone. And that was, you know, we just, just kind of just
10187600	10193040	try things. I say it's like, a lot of that's just like ambition, just try to do something
10193040	10197440	that other people haven't done. Just give it a shot is what I, I mean, I do that all the time.
10197440	10203280	I love it. And I love the fact that your pursuit of fun has landed you here talking to me. This
10203280	10208960	was an incredible conversation that you're, you're, you're just a fascinating human being.
10208960	10212880	Thank you for taking a journey through human language with me today. This is awesome.
10212880	10214800	Thank you very much. It's been pleasure.
10215920	10220400	Thanks for listening to this conversation with Edward Gibson. To support this podcast,
10220400	10225680	please check out our sponsors in the description. And now let me leave you with some words from
10225760	10231280	Wittgenstein. The limits of my language mean the limits of my world.
10232480	10241600	Thank you for listening and hope to see you next time.
