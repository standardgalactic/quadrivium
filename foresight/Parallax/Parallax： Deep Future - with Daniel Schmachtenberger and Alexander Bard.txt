All right. Welcome to Parallax. I'm your host, Thomas Mark. With me today are Daniel Schmachtenberger
and Alexander Bart. Daniel Schmachtenberger is a social philosopher and founding member
of the Concilions Project aimed at providing public sense making and improving public sense
making and dialogue. Alexander Bart is amongst many other things, the philosopher, author
and futurologist. I'm very happy to bring you both together for the first time. So welcome
both of you. The goal and the idea of this conversation isn't short to kind of generate
a snapshot of where we are 2022, ideologically, politically, economically and technologically,
and where we are headed to the end of the decade. So where are we now in this time between
worlds and what are the possible and probable outcomes of our current trajectories? We are
facing a crisis while at the same time our institutions do not seem to fit or able to
solve these problems. It appears that the climate crisis unfolding right now and the
war is brewing, the cultural divide and the western hemisphere, the culture war is getting
more intense. And at the same time our myths and narratives don't work anymore. The postmodern
policies of deconstructions have for better or worse negated our way of reducing complexity.
So where are we now? Is the west going to fall as Oswald Sprengler once put it? Is the
chaos going to increase till we find a new way of life? Or is it as it ever was, men
struggling to find meaning in a complex world? Can digital providers with the means to reconstruct
the myth and narrative? And maybe more on the point, at what point does it become wiser
to acknowledge that it's too late to stop anything and turn our efforts to surviving
it? So Daniel, if you had to start to paint this broad painting, where we are right now,
where are we now when you were to take up a systemic bird's-eye view of things?
I tried to paint a brief, hopefully useful starting place picture. You were saying, you
know, we're in a global crisis and you gave a few examples. I often use a term metacrisis
that is not just looking at the fact that we have climate change and biodiversity loss
and extinction of species in dead zones and oceans and topsoil loss and all those environmental
issues, or that we have increasing fragility in supply chains or the problem of exponential
growth on the financial system and linear materials economy, hitting fragility on planetary
boundaries, or the AI risk, bio risk, cyber risk issues that new exponential technologies
create, like all of these are possibly catastrophic risks. And we're in this interesting situation
where the total number of catastrophic risks is increasing and the probability of them is
increasing. And so rather than just see each of those as different separate ones, there are
certain underlying drivers that we can look at that they had in common. Talk about the
generator functions of catastrophic risk. And so we would say that we are at a unique point in
history, something where Alexander and I definitely agree is that it's not just processes of the
same thing always under the sun. Being able to extinct species at scale and genetically
engineered new species and synthetic biology is a different thing than was true 2000 or 20,000
years ago. And so the first truly existential tech we had in terms of technology enough that we
could make choices that damage the habitability of the world was the nuclear bomb. And that was so
recent in historical time, we built an entire world system to prevent using tech, that tech,
and we had never done that before. Every tech we had, we always made an arms race to use as
fast as we could. Now we built a whole world system that involved mutually assured destruction and
the Bretton Woods monetary system and the UN IGO systems to ensure not doing that. While that
succeeded in a way, it also drove all the catastrophic risks we're facing now and to more
likely like let's have a monetary system that increases exponential GDP so everybody can have
more without taking each other's stuff on linear supply chains that externalize cost to the
environment pushing all the planetary boundary issues. And you can make mutually assured
destruction on two superpowers with one catastrophe weapon, but you can't on lots and
lots of non state actors all having access to different kinds of catastrophe weapons. So how
do you deal with that? So we're in a situation where the post World War Two world is over,
there's a lot more catastrophic risks. And those types of solutions don't work and we need new
ones. What we'd say is that there's, so like whether we're talking about the risk from a
particular kind of AI or bio or nuclear or climate change refugees leading to nuclear or
whatever it is, there's the increasing catastrophe attractor, right? There's like an
attractive basin defined by we can't manage our power well coordination failures creating
increasing catastrophes. There's a thousand scenarios, but they're all kind of the catastrophe
attractor. Then there's this other tractor that says, in order to manage those, we must be able
to monitor and control adequately. And that looks like pretty powerful centralized control
mechanisms, which mostly turn pretty dystopic. So we can make sure that nobody builds catastrophe
weapons in their basement using tabletop crisper. If we have ubiquitous surveillance and extremely
powerful control mechanisms, then that becomes pretty dystopic. So there's like catastrophes and
dystopias as these two different attractors and exponential tech makes both more likely, you
can run much more powerful top down systems using AI and IoT. You can also create a lot worse
catastrophic dynamics with exponential tech. So we want a third attractor that is neither dystopic
nor catastrophic. And that means that it has to have the capacity to check all of the power that
could cause catastrophe on purpose or accident, but where that system that checks it must also have
checks and balances and be oriented in a life that is somehow desirable. And so how do we make it
through the metacrisis means make it through the catastrophes and the dystopias to some kind of
third attractor? What are the criteria of that attractor? That would be a fine starting point of
kind of where I see that we're at in the arc of history. And that the quote in the book of Roman
something like the path to hell is wide and many of the path to heaven is narrow and steep. It's
easy to come up with dystopian sci-fi because humans have been pretty nasty stewards of power
historically and the idea of us having decentralized exponential power like there's just a lot of bad
scenarios. The idea of exponential power AI and genetic engineering and whatever, going well with
people like us running it requires some pretty significantly new thought. And so how do we come
up with a positive future narrative that is not a naive silly one? I think this is the topic would
be fun to have us explore today. That's my kind of initial frame.
I can then add to that that the reason why I got really interested in Daniel's brain a few years
ago was that I was very alone being a philosopher of technology for quite a long time. And it was
really required. Obviously, we live in the middle of a technological revolution. Here was a guy who
was even more a philosopher of technology than I was, which is great. So it's kind of shocking that
this is actually probably the first recording of conversation between us because we've been friends
for many years now and I highly respect Daniel's work. And I'm very excited about this conversation.
So I just want to say that first. What I add to this is that I'm a narratologist. Well, here's a
new word, right? Please recall that the 20th century was mostly used for deconstruction. You
know, after the atomic bomb, August the 6th, 1945, the most important date in recent history for all
of us on the planet. I agree completely here with Daniel. Let's use that date. There's a certain date
there, August 6th, 1945. It helps us to locate ourselves historically. And after that date,
deconstruction became the natural norm. It's just like we have to deconstruct all of history. We
only begun that process. We have to deconstruct Western history of the world right now. That's
happening. We have people over the world who realize that there's a myth about Asia that is
completely incorrect. There's a myth about Africa that's completely incorrect. And also America
is finally shifting. America is not European any longer. America is now the meeting place of the
world populated by people from all over the world. And America needs just a new standard
language of the world that we all use to communicate. So even America is shifting in the
sense that America is becoming truly a global meeting place today. And that's what's really
interesting here. So I do narratology. Narratology is more than deconstruction. It's also
reconstruction. It's basically the philosophical search for the narratives that human beings tell
about themselves. We are storytelling animals. We're storytelling flock animals. So we tell
stories about ourselves all the time. And fundamentally, these stories have to be split
into three different types of stories. So let me follow you into this one. The first one is
precisely the one we're down here as an expert. It's what we call the logos. This is how reality
actually operates and how we symbolically try to understand how the world operates. For example,
mathematics, you know, when language tries to be exact, that's when we go into the logos.
The second one is pathos. You know, every time somebody tells you do it once more,
we would feeling like add the pathos, please, you're a human being, right? You're not a machine,
you do, you do, you need to add the pathos to what you do. So pathos is the storytelling
that's usually banned, banned from children's use. Just like I said that pornography, violence,
all of that is located in the pathos. And the third one is the mythos. And the mythos is the
only way for the other two to be combined. So our predicament as both Hegel and Nietzsche pointed
out in the 19th century is that the only way for us to have some kind of narrative that we can share
is to create a mythos. Not myth, but a mythos here. So these are the three basic stories and
they are dialectically intertwined. You cannot focus on one of them rather than the other one.
And then if you look at power and domination, it goes to say that power and domination goes
into these three realms. So the logos is the symbolic order and the symbolic, it's more of
the masculine side of things, if you allow us to say that, but it's more of the masculine side of
things. And the logos, how the world actually operates, zeros and ones today, more than anything
is the logos. And then that is logos is presented as knowledge, the power through knowledge,
whoever has access to knowledge today would say data and data processing, whoever has control
over the knowledge or dominates in the knowledge field has enormous power and influence. And that's
of course, we need to start today. The other one is violence itself, who has the monocular violence
of a specific territory, that state turn things like that. And that is the pathos. So that's
the second realm. And the pathos we call the real order, the real order of things. So ultimately,
the physical world out there, if you walk straight into a wall and hit your head,
you just encounter the pathical world out there. We can fantasize all we like and we human beings
fantasize individually and collectively all the time. But at the end of the day, our fantasies
will be crushed and they will be crushed by what's called the pathos. So that's the second realm,
the real one. The third one, the only one that can unite the other two is the imaginary order.
Imaginary order is tied to the mythos. So we imagine the world. And this way it gets important.
We have to have an imaginary that makes sense to us. We have to have a shared imagine if you're
going to share your society. And that's where the crisis at. So what's happening right now,
our proposal is that this is a paradigm shift in the sense that we're moving into the online world
and the internet is taking over the world. And we're globalized because the internet itself
goes towards globalization, whereas we human beings are very local in our attitude towards the world.
So this does a paradigm shift. Why there's a metacrisis tied to the paradigm shift
is that all these three narratives are in crisis at the same time. Daniel is the perfect guy in
the world right now to list the reason why logos is in crisis. That's exactly what he's talking about.
After 1945, we discovered that we're exploiting the world towards our own extinction. And that's
not a small thing to say. That's exactly what we're doing. We could blow ourselves up with the
bomb. We could also blow ourselves up in many other ways to just take more time. That's what
the logos crisis at. The problem is the other two aspects are in crisis too. The pathos,
the pathos is in crisis. The mythos is in crisis. The mythos is in crisis in a very particular way.
It's a crisis in the religious or the spiritual and therefore also political manner. Death has
become the absolute. We now have an elite in the world today who believe they really will die when
they die. That has never happened before in history. We have always excused ourselves
with an afterlife or at least with a reincarnation. The reincarnation of the east of the afterlife of
the west. We have always had those myths before. Now we can no longer have a myth and therefore we
cannot have a myth that it's utopian or dystopian either. We have to accept that we die when we die
and the only thing that can transcend us is children who inherit the earth after we're gone.
We're into that mode now. We have an elite in the world that have come to accept that
and they're dealing with it massively and it's not a small thing at all when it's dealt with
collectively. This is like Nietzsche's The Last Man. That's where we're located right now. So there's
a crisis in the mythos too. There's a crisis in storytelling. We can deconstruct as much as we
like but if we don't reconstruct something valuable to us and have a new story, we're done.
And the third one is the crisis in the pathos. This is the crisis of violence. This is the
crisis of sexuality but this is also the crisis of nature itself that's now catching up with us.
This is the crisis of the bomb. It's literally physical. This is the crisis of the climate.
It's literally physical. Therefore, there's a crisis in the pathos too. So all the three
different narratives are in crisis. All the three different narratives simultaneously have to be
retold as a new shared narratology that makes sense to us. That's why there's a mental crisis.
May I ask you to just clarify a bit for what has to happen in logos, in pathos, and mythos?
Like is there something like what you would think of as necessary and sufficient criteria of the
new logos, the new mythos, and the new pathos that converges towards the third attractor?
Yeah, absolutely. The third attractor we call protopianism and I think it was Kelly Over at
Wired who invented the term or maybe it's been around because it sounds a bit generic. But
protopianism, when I came to East Asia and you travel there too down in a lot, like when I talk
to the Japanese, the Korean, and the Chinese, it doesn't make sense to say anything today that
they don't get or they don't subscribe to. And it certainly makes a lot of sense to listen to them
and their history, because we share a world with them now. Protopianism makes sense to anybody in
East Asia. The utopian dystopian dichotomy was always Western and we got it from Abrahamic
religion. It doesn't make sense in India, it doesn't make sense in China or Japan, but the
protopian perspective which is the incremental improvement and work towards optimization or
processes makes sense. That makes sense globally. So I would start with saying that all these
different narratives now have to be protopian. We need to get rid of the utopian, the drive towards
the utopian and the dystopian, which is what you call the third attractor, which I think is brilliant.
The third attractor is now required because it's the only credible global narrative we can have.
And it goes for both the logos and the mythos and the pathos. They all have to be protopian.
And you and I in one of our little night sessions over in California came up with the term that I
love called symbiotic intelligence. AI is what the machines will do, but as long as we human
beings are involved in a collaboration with the machines, I think it makes more sense to speak
of an SI. An SI is an AI ultimately controlled by humans serving our interests, but that takes a lot
of maturity from us as well to work with the symbiotic intelligence. But symbiotic intelligence
is an intelligence that works towards optimization or process at all times. And of course,
this is not an optimization of a process that's ultimately exploitative.
That's what we use to term exploitation in our work all the time. We talk about resilience,
sustainability, these things. The exploitative aspect has to be implemented within a protopian
process, meaning that you have to give back what you just used. In that sense, you cannot exploit
the world any longer because it's the end of the story. To employative means closed loop or real
closed. Exactly. Employative is opposite to exploitative. So it's easy to understand. It's
the opposite of that. We used the word for the past 20 years. And what's important here is that
protopian ideals, meaning that if you're an artist, you go protopian. If you're an engineer, you go
protopian. If you start a company, you should have a protopian company from day one. So the way to
make incremental improvements on the world through your work, which is how you do technology,
essentially. Once we've created the technology, it's there. And technology in itself is a pharma
con. It can be good or bad. It can be Hiroshima. It can also be fusion. A pharma con. A pharma con
means that a technology in itself is neutral. It depends on what we human beings deal with it.
And in this sense, of course, atomic power is the perfect sample of a pharma con.
So that's what technology itself should be neutral to us. And then we ask ourselves the
question, how do we use that technology to the benefit of mankind longer?
It was actually a funny point of intersection. And I wish that my schedule over the last week
had been different. And I've got to read more of your recent work and share some things with you.
We actually just published a paper with a conciliance project called Tech Is Not Values Neutral
like a few days ago. So it's just funny to come to this point. It's maybe an interesting
topic for us to discuss because it doesn't map to the logos, pathos, mythos perfectly,
but the infrastructure, social structure, superstructure way of looking at the domains
of civilization and the fact that psyches and cultures are directly affected by tech.
And it's not just what values we bring to it determines if it has a good or bad use. It's that
every technology is an extension of human choice making. It catches on because it confers power.
And thus whoever uses it and gets more power usually ends up driving the beginning of a
new arms race of some type that obligates other people to use it. That codes a pattern of human
behavior to use the tech as opposed to not coding that pattern of human behavior affects human
psyches, value systems, belief systems, everything. And then the distribution of that affects
cultures and societies. So we call this psychosocial externalities rather than physical
externalities. And so physical externalities, we know the pollution and the harm in the supply
chain and whatever that occurs. So we have to go physically closed loop, meaning we're not using
unrenewable physical resources or turning them into trash or pollution. We have to go psychosocial
closed loop too. And it's not going to be closed loop in the same way, but it does mean forecast
the psychosocial effects and internalize them into the design process. Because obviously
something like the nature of the algorithm that optimizes for engagement, which in
optimizes for outrage, which ends up polarizing a society or shortening attention spans like
these are very real effects on psyches and society. So it's not fair to say tech is values
neutral. Tech was built to advance certain values like ease and brevity and comfort and
whatever, it advances those that affects other values and it does so at scale. And so if you
don't actually think about what are the values that are worth valuing? And how do we build tech
that enhances those? Then because the tech is so powerful, it will end up damaging them. And so
you actually can't think about the evolution of culture independently from the techplex that
ends up determining what wins behaviorally. I agree. So the point here is that engineers
have no clue what they're doing historically. So like if you would have asked Gutenberg about
the printing press in 1415, it was quite an event where the printing press arrived. I mean,
they started printing Bibles quite quickly to start with. And that was his point. The point
was that you should translate the Bible to local dialects around Europe so that Europeans could
read the Bible and become all the good Catholics that he wanted them to be. Actually, he created
the end of the Catholic Church. It's been growing gradually, but the whole question of the Catholic
Church, and now it's just basically diminishing into nothing, started with Gutenberg. He was the
killer of the Catholic Church. He just didn't know. So the problem is that engineers are usually
historically speaking very unaware. So I just want to remove the guilt applied to them afterwards,
like you don't even know what people do with you. I mean, Nietzsche couldn't know that Hitler would
come along and Marx couldn't know that Stalin would come along. You can't blame people afterwards
what people later are doing in the sense that we usually do. So my point is this, though, that
there's a social responsibility for creating an environment where technology is created in the
first place. The one thing we have learned is that we hardly change at all. Human beings are
basically the same worthy five or 10,000 years ago in the very short span of the created civilization.
What we do create is technology. The way I frame it is that I said, women give birth to children.
Men envy women for giving birth to children. Men therefore give birth to technology.
The problem is that if technology develops quicker than children do, which tends to do,
it's only a question of time before technology kills the child unless you intervene. So that's
essentially the history of civilization in five sentences in a very Freudian sense. So my point
being calling technology value neutral is, of course, nothing is value neutral in the formal
sense, but it is to point out that technologies are pharmaconic, usually by historical necessity,
and then we can look at them. Today we know more, and today the loops of technological innovation
are so tight and involve so many people that the pathos of the mythos are obviously now involved
in the loop of the logos itself. We are really beginning to look at the word dialectically.
We're really beginning to look at the word. These three narratives are now colliding one
another. We cannot trust any one of them because as human beings we have to operate all three,
and we have to reform all three at the same time, which is exactly why this is a meta crisis to solve.
Yeah, we have to do all three at the same time, you and I totally agree on. We're not looking at a
theory of change. We're looking at an ecosystem of theories of change, an ecosystem of projects that
have a pro-topic direction to them, have a third attractor, attractive basin to them, and the desire
for what is the comprehensive solution set or roadmap for humanity is based on the fallacy
that a centralizing intelligence could do that thing. I think we think very much the same way
about that. It's interesting. I want to try to tie a couple things together that you said.
We're mentioning that Marx can't really be blamed first all and then etc. because people can't really
forecast what's going to happen afterwards. Einstein and the Baum, great example. I think it's true that
I was talking with a friend the other day about all of the hopeful projects that were going to make
the world better that didn't happen that he was kind of traumatized by and where their hope in how
good they would be was false. And I said, yeah, but you also need to equally factor all of the
devastatingly bad things that people forecasted during that time that didn't happen as well,
that the Cuban Missile Crisis didn't become World War III and Y2K didn't in the world and 2012 didn't
and on and on. And that if you factor them both, people just suck at forecasting the future because
it makes sense that we would. We can't get the weather right 10 days out like
multiply embedded complex systems are hard, we're just not going to do that.
So we have to get recursive intelligence processes that can do a little bit and increase the
collective intelligence that can keep doing that. That said, I think there are some things we can do
to forecast externalities much, much, much better than we ever have that are kind of low hanging
and it's really worthwhile. And so one thing as you're mentioning that the engineers, I mean,
I think the engineers have been profoundly competent in the domain that they were trained,
but as soon as you understand that technology codes patterns of behavior that end up coding
minds that then in mass code societies, of course, technologies have to be trained in social sciences
and axiological design, what are the value sets that will emerge from the use of these technologies
has to be a consideration doesn't mean you'll get it all right, but we need to work at it and then
recursively work at it and improve the process as we go. So I think when you have bigger frameworks
like that are superstructure and our collective definition of the good life and values, whatever
our social structure or economics governance law and agreement fields and our infrastructure or
techplex co influence each other so that you don't try to do sense making within what you do
sense making across them. Just basic shit like that really helps, right? It really helps the
forecasting. But one other thing I wanted to say is there's a very interesting thing right now where
the arguments that we can't possibly forecast the future well enough ends up being a source of plausible
deniability for people not even trying where it's in their vested interest not to. And the less
wrong community had this blog post on is it mistake theory or conflict theory that's a very
deal meaning the mistake theory or the problem is the result of shit we just couldn't have possibly
known and the externalities are too complex or is it conflict theory meaning we actually wanted
to cause that problem or we wanted to benefit and we didn't really care if we caused that problem.
And of course it's some of both. But some of the argument in there is Michael Vassar and others
commented is that the existence of the possibility of mistake theory serves as a plausible
deniability cover for a bunch of conflict theory to hide itself and say oh we couldn't have possibly
known. Oh bullshit you didn't try because it wasn't in your interest. Yeah I'm just thinking of like
Instagram wouldn't they have known that they would cause like a massive psychiatric health
crisis among teenage girls. It was quite obvious. You and I pointed that out from the very beginning
like just like they couldn't know but they didn't want to hear it right because they were
there was telling everybody at the time Facebook was starting or whatever it's going to do these
things they're like shut up hippie and no it's not there's no possible way but of course the
motivated reasoning is a problem right. Motivated reasoning is tricky. So here's the piece that I
wanted to add which is there's a very perverse piece of kind of game theory at a consentive here
that has to be bound which is that it is very disadvantageous and a market type dynamic for
any individual or group to focus on what the possible risks might be and it's very of the
thing that they would develop and it's very advantageous to just focus on the opportunities
and benefits because if I do protracted risk assessment somebody else hits first mover advantage
faster and if my protracted risk assessment says actually the field is too dangerous we
shouldn't do it it's not going to stop the fucking thing the market is going to move
the people who move fastest will privatize the benefits and then socialize the losses
and so there's a focus to move fast break things socialize the losses nobody takes responsibility
that perverse game theory keeps people from even trying to think well and when the worst
harm you could do was add lead to gasoline which was pretty fucking bad right it it decreased
the IQ of the planet by like a billion points and made people four times more violent it's like
Jesus Christ that's a huge deal when you say humans have been about the same for 5000 years I'm
like no man fucking just let it gasoline alone made us a billion IQ points stupider and four times
more violent like that's a big deal and that was one of 50 million chemicals in the in the chemical
database that it made but but when it comes to synthetic biology and general artificial intelligence
by the time we're dealing with those types of externalities it is it's totalizing
and so we actually have to do some fundamentally different types of coordination
around how to think through the long term better using models like attractive basins and things
where you don't have to get every detail of complex systems right but you can get general
principles and where you disincentivize move fast and break things and this is actually
things like to open up a new category of tech you actually have to open up these you have to get
regulatory approval to open it up as opposed to regulate after the harms have already happened
that's of course that bothers everyone because they don't trust states to regulate so we have
to also restructure the state from scratch because the power to check the catastrophes creates
dystopias unless you also have strong bindings on it but you have to face these things together
yeah and that's where it gets interesting here with the narcology you just said the state here
the state is in the imaginary realm it's not a logical rose in the imaginary realm so so we
did inherit from religion and the gods and the forefathers and all that we know this idea of the
state and that would be the king or you know with the priest and eventually that becomes the state
we have today and the state is so far behind and the problem here of course is the other one
is that if you have if you create a monopoly it will instantly go corrupt and become dysfunctional
and we created states so far that are not competing one another at all they're local monopolies
and this is of course the problem you got the market the market is incredibly efficient i can
give an example of my team we just studied construction sites in east africa east africa is
like wide open right now it wants to expand quickly it looks at china and india it doesn't care too
much about regulation so this is the perfect place for a chinese construction company to
be the shed of a french construction company with a bid for a construction in iroby because the
french come there with a european attitude they've learned you know the hard way that we need to make
an assessment a risk assessment before you start building and by the time they start the risk
assessment the chinese are ready up and building the construction anyway because they don't care
about the risk assessment so we still have this sort of this blatant aggressive form of capitalism
running around the world and they know that we have exactly what you said we need to create
a functioning container within which the market can operate with some certain rules and then people
scream oh that's socialism and we need a bigger state and we know states can function any longer
and the states are going incredibly corrupt slow and they no longer work this is again this is part
of the imaginary order of crisis so it's in the imaginary order it's a crisis of religion and politics
in a fundamental one now i like then to go back to what actually worked and i know you also you
you tend to quote the silk group try it you tend to quote daoism buddhism is orastrism i do too i
find very very little solace in christianity and islam when it comes to try to understand
we're at right now i prefer these religions that have been around for thousands of years
and they've been created along the trade routes so i go to the metaphor of the bazaar now how does
a bazaar work well a bazaar has to be exploitative because it's going to be around for thousands
of years it's probably in some kind of an oasis town along the trade route you put an old smart
wise woman at the door you know you put that bitch at the door nobody gets in without her permission
so you have a membrane and containers start with functioning membranes so there are rules
how you conduct the trade in the bazaar otherwise the bazaar will not work it's not a free market
it's not a free for all you can do whatever you like because then the bazaar falls apart so if
you think of the system we're looking at as a kind of a bazaar that we need to create for the digital
age it starts to make sense then we can have different bazaars that compete in one another
but we have to have a central framework for all the bazaars of the world which is how we
exploitatively use the world in that sense so that we don't completely go into collapse so the
problem here is that we both on a global level have to have a network of bazaars and another
local ever there are the bazaars but what I'm then proposing is that the bazaar looks to its own
self-interest long time see it keeps itself alive as a container within which you can put the content
and this is why the market will not work unless the market is regulated it has to start there
so the markets themselves have to look at their own regulation otherwise we should just boycott
the market not be part of it just say that I don't want to be in the bazaar at all unless it works
unless unless it has a functioning membrane unless it takes responsibility for itself in
relation to other bazaars it's not a trading place for me to be involved with it has to be
something like that because we have a major a metacrisis of politics right now we know the
states that we construct and no longer work and the only alternative out that seems to work right
now interesting enough imitates egyptian dictatorship and it's called communist china
they at least seem to have a sense of what we call a sensocracy where they're going how they
will control everything to a central computer we also know that that won't work either so the
question is how do we open a society that's free and open enough to stay creative and to stay open
to bad news which dictatorships never do which exactly why they go extinct eventually and this
is of course the central question ideologically speaking and it's a question of imaginary narrative
it's in imaginary order that's the crisis there the reason that you're saying it's fundamentally
imaginary and why the bazaar worked in the market didn't is the bazaar had a long-term
survival interest in the market doesn't and that the long-term interest is in the imaginary realm
there was some narrative that everyone the bazaar was a part of that was self-transcending so they
wouldn't fuck the future to benefit themselves for some reason and that that's what's missing
currently that's the mythos is what is it that has us not maximize short-term personal gain
because there is some higher order transcendental narrative that we will have be a basis to find
our behavior is that right yeah so if you're looking around the bazaar on a map this would
you find interesting every bazaar it had the hospice it had the restaurant and the hotel
it had the bath house in a clique which is also a social place it had a gym there was always a
gym around the bazaar they called sarkhani the persians invented the gym 3 000 years ago
where you go work out and make your body fit and then it has the bazaar and you need to probably
go to the whorehouse which is another word for nightclub to socialize with people and see strangers
and make friends with strangers and there's no better place than a nightclub or even a whorehouse
if we're honest about it to make friends with a stranger they'd be absolutely naked in front
of somebody which you are at a whorehouse and therefore you can make a trade the next day
so the matriarch sitting at the front of the bazaar will make sure that she checks you done all
these things now here's the most important thing though it wasn't my team in london that they
discovered that every bazaar after you leave the bazaar you leave the town and go to the next
town to trade you have to go up to a costog the costog is the origin of the monastery
you literally have after you've done your traded bazaar you need to go to spiritual center and
fix your mind this is where you go into what the Tao is called Tao or the Zoroastrian is called the
Asha of the world you go into a relationship where you actually you go back into the logos you go back
into reality as much as you possibly can including yourself and you readjust yourself your own
thinking oh you did a bad deal in the bazaar get rid of it get over it move on come back with a
constructive mindset and all these trade group religions are basically they bowled down the
ethics to in what way are you constructively participating in the world in what way are you
constructing or representing your tribe when you're out here traveling doing the trades
in what way are constructed be supporting the community that just embraced you and welcomed
just you could do your trade and what we are constructively moving on to the next community
you're gonna enter so you can go into that bazaar and make more trade so the question here is that
why do we miss out on the costog we separated religion from the rest of side and made it a
private thing something you do on Sundays you go to church and show off yourself and of course that
eventually ended up with us being cynical about religion like well I only go to church on Sunday
it's only worth investment if it looks good so I can make more money on the Monday while
exploiting the world so the costog is fundamental to interactions especially when it comes to
larger populations than our own tribe as soon as you move into a larger public zone tribe
we need to start containing ourselves in our behavior relationship to other people the costog
eventually leads to the monastery traditions of all of Eurasia especially buddhism's are
asked in the dullest monasteries and I think it really pays off for most people today to go and
spend some time a year or two in the monastery and try to figure out what it means to meditate
and contemplate every morning of your day to have a constructive mindset towards the world
it has to it has to be his personal spiritual journey involved here and it was required at the
bazaars it was required it was the first thing they would ask you the next time you come to
oh did you go to the costog after did the train of bazaar the last stop you made otherwise you're
not welcome otherwise you haven't done your work this became such an industry you even had to build
costogs in mountains you know god hello tibetan buddhism you had to build in mountain where the
monks themselves and the nuns themselves prepare themselves for all the heaven load that they had
to go through with the traders and the costogs in the trading towns so it became like a spiritual
industry but that's fine and we need one today as well so did the next bazaar require some kind of
ticket or proof that you've been in the costog or they took your word for it
no absolutely and again this is this is how you get your credibility you get your credibility
because you've done the trade many times and yeah we can trust this god the way we do grading
today this is the 5.0 okay and it also represents a community that is underrepresented inside the
bazaar meaning it's got to sell us stuff we haven't seen it before oh that's quite exotic and interesting
let him go in he will do fine but if he doesn't do fine if he's out competed about it he needs to
go to the costog more than ever the next day to not take that looser mentality with him into the
next trade it's very interesting i i not heard that story told that way um so there's a way that i
think about that relative to the world today where it uh it seems like something has changed in scale
in a way that crossed a threshold that changed in type or the same thing even in network wouldn't
apply i'd like to ask this question and get your thought on it so you went to the market
after talking about the state and then you said okay in the market there was something like law
the woman at the front um had some kind of wisdom to be able to assess who you are some
record of if you went to the costog or not some you know some indicators about you and then obviously
she's probably connected to a network of people who are reporting on what people are doing inside
and there's probably something like police and whatever right so uh if someone is stealing or
doing false advertising or whatever it would be that would go against the um written or unwritten
law of the thing then they get kicked out or something like that so there's something like
rules and there's something like enforcement which is what defines the membrane and so acting on the
inside requires participation with the rules one of the things that makes that work without
being tyrannical is the smallness of scale yes and so unlike a massive police state um if the
police in that thing started to get corrupt enough of the people could overthrow the police and
there's no such thing as a person at a bazaar who can use personalized data micro targeted
split tested advertising on me like they can just say I got the best shit and I can say what about
these guys over here their shoes are cheaper and I can go touch them by myself right so there's not
a radical asymmetry between billion dollar corporations and the purchaser it's like a dude on
one side of the table selling stuff and a dude on the other side buying stuff there's not that much
asymmetry between the police and the non-police and so the symmetry is part of what makes something
like caveat and tour by or be where be reasonable or what makes something like the second amendment
hey if we need to throw over the police we can deal with it a reasonable idea when you start to get
to much more radical when you get to much more size if you want to have something like rule of
law across that whole size a very big membrane then you get pretty radical asymmetries of power
in a radical asymmetry of power you don't even have things like the ability to check the corruption
on it or even consent as a valid idea because of things like a new influence what does consent mean
if I don't have capacity to consent because the other agent is so much smarter than I am that they
can manipulate me to do shit which is like cold dynamics but a cold dynamic is nothing compared
to ai's on social media or whatever else doing stochastic terrorism and population centric warfare
so I don't even need a monopoly of violence anymore I just need a monopoly of influence
and the monopoly of influence can make people commit the violence I want or whatever it is
so when you start dealing with those who control ai's and those who don't
when you start to deal with that level of um asymmetry of information processing capacity
voluntarism doesn't mean anything anymore the ability to uh because you cannot voluntarily consent
in or not consent when you can't check all the stuff what does it mean for the people to be able
to check the state if there's no way to process all the information because the state's using ai to
process all the shit right um and how do the people deal with the if there is a policing force at all
the levels of asymmetry of power so if you say okay fuck nation states we're just doing city
states let's keep them smaller and let's always make sure that if anybody has an ai there's a
competing ai so you at least have something of some metrical size that can compete with it
well now we get this issue that let's just even take nation states we can go to city states but
let's take something less than global governance anything less than global governance you still
get global multicoller traps meaning a situation where if they're going to do the fucked up thing
then we have to raise to do the fucked up thing or they be best right they're going to develop nukes
we have to develop nukes they're going to develop ai weapons we have to develop ai weapons they're
going to overfish the ocean well how do we stop them from overfishing the ocean if they have nukes
and then they really need the fish for their population growth so if we don't overfish the
ocean the fish are still going to go so we might as well race to overfish the ocean so those race
to the bottom coordination failures are because you don't have a monopoly of violence to be able
to enact rule of law which is why you want a global government that you don't want a global
government because a monopoly of violence with no checks and balances become totally corrupt
catastrophes dystopias so you want a global government that is not corrupt well that requires
some magic right or really good design and i think that's where you and i are going to get so
what i see is that the principles that we're operating at the bazaar were scale dependent
and that as the scale gets larger you get fundamental breakdowns in some of those things
when the scale gets large enough for instance that supply and demand have a radical asymmetry
because even though in aggregate the total amount of demand total amount of supply is
the same flow of dollars the supply is not coordinated the demand is not coordinated and
the supply is coordinated right i don't have a labor union of all google users who work together
and use ai to coordinate how they want to use google but google is the centralized corporation
that actually has long perm planning and in org chart and again chart whatever so it's really
google half a trillion dollar organization whatever using ai's against a single user or facebook or
nike or whatever it is and they can employ radical behavior mod techniques so there's no
longer authentic demand driving supply there's supply manufacturing bullshit demand based on one
marshmallow stuff rather than two marshmallow and then say oh but the people want it after driving
addiction and so when you have those types of asymmetries it's asymmetric warfare you don't
have like the same principles that apply when there's symmetry like buyer beware like second
amendment like what they just don't hold in the same way so you need a fundamentally different
way of thinking how do we deal when there are competing interests across types of asymmetries
of power that are totally unprecedented absolutely i agree totally here and i think you're not
working on the same thing you're doing it on the technological level i'm doing it on the
narratological level i'm writing a book and you can do the technical level without the narrative
level no exactly exactly that's the point yeah so the the um the narratology i'm doing at the moment
the reason why i got into this thing with the bazaar is of course the the whole the entire
history of eurasia is being rewritten at the moment by asian historians many of them asian
americans like chinese american indian american persian american historians and i have discovered
that the entire history of asia is just a european 19th century fantasy it's completely incorrect it's
just read the wrong way so that's exactly what we see these patterns and and the reason what we're
doing is because asia's history is much older than europe's and that's the asset here we need we need
deep history we need long history to to look at what systems work and what stories work over
long periods of time and which stories failed and here's the interesting thing the it is that
we're looking at units like empire which is older by the way than nation and look at these systems so
what is an empire what is a nation what could it possibly be in what we would technology subscribe
to an empire in what way can human beings subscribe to certain empire and in terms of the
empire that were very loose they were full of dialectical conflicts and economies everywhere
they were allowed they were certainly encouraged they didn't worry too much about a diversity of
looks like we do today there were much more about diversity of talents and a diversity of opinions
because the strengthens the system's long term so you want to have these sort of competitive
environments we want to have them within certain containers that work and you discover when you
do these formats that you don't need the police unless the size is big that's exactly my scale
here is incredibly important we take to the tribal size somewhere between 1200 and 1500
people quite naturally and anything smaller than that we're perfectly comfortable with
we don't need a police force to be loyal to and even live and die for a community of say 1500
people once it gets bigger than that that gets more problematic and that's why you need these
sort of social systems and eventually even states or at least city states nations whatever
for those things to work and they are required the question is on what level can people you know
align this in what on what level can they for example vote for a politician that they would
know and they say hi to industry well that's only to a certain level but that's absolutely
minimum level you must work with because otherwise people don't trust people around them they don't
trust the leaders their elders or whatever then you have to go all the way up to global that's
the challenge here it's unavoidable there has to be some kind of least loose global you know
collaboration here and some certain global rules we have to have a membrane for planet earth itself
and at least after the atomic bomb in 1945 in the late 1950s we got the first pictures of
planet earth from outer space we tend to forget how young these pictures are there's only like
a little more than 50 years ago we finally saw this beautiful green blue planet where we live
and we saw this huge cold dark space out there that we cannot relate to so at least we know we
have the dia we have we have that narrative it's there and it's unavoidable I would even say that
I challenge my students these days and say that the one thing I will take care of probably is to
conquer outer space and you will not be involved and maybe that's a good place to start because the
hubris we suffered from should have some kind of a price we need to pay so you remind the students
that if we don't fix this planet which is the only place we know we can actually live in the
universe then we're done so the planet has to be fixed it has to be fixed it's unavoidable as a question
and this is the largest size I think we should allow ourselves to think to forget about our
space but think of the satellites at least a space surrounding the planet creating the internet
and what we then come to is of course the complexity has increased to higher levels than ever
which are there for expect people to go absolutely bananas over the next 50 years that's our book
digital libido by the way it's a very dark book because the first thing that will happen now so
people will go absolutely bananas they will go for all kinds of conspiracy theories that will create
the weirdest sects and cults you've ever seen they will lose themselves completely in these
environments it will not be safe to be outside anybody can kill you for whatever reasons you don't
know you know if anybody can order your murder you don't know who's going to kill you uh she
says abe was killed in japan because somebody started making homemade guns in japan so japan
has the same gun control problem that was america for that very reason so it becoming a very unsafe
world very quickly now that's quite obvious so the question then is we then have to move quicker
towards the global order it has to be very very loose it has to be very loose then the question
the next question is what would its insocracy be like we need algorithms algorithms have bad
reputation today because they're so bad today but they could be much much much better they could
much better reflect the world how the world actually operates i call it the free and open
algorithm to give it a positive spin is to get rid of those sort of manipulated algorithms
corrupted algorithms and conformist algorithms that we have today we need to get rid of the
manipulation the conformation and the corruption of current algorithms we need proper algorithms
because algorithms is the only help we have with increased complexity try to understand the world
better and leadership has to be based on proper algorithms that give you a fair view what the
world looks like again back to the logos the conspiracy theories they want to avoid the logos
as much as they can so jump between the pathos and the mythos which is incredibly dangerous to
put a lot of people in that realm we need to go back to the logos and the algorithms are there to
help us do that can you explain for me what you mean by the good algorithms that we need for leadership
to work okay so if it's a new paradigm it will be chaotic at first now allow for chaos say an
anarchy to establish itself first which is what the internet has been so far the old institutions
that used to be powerful the old logos the old pathos and the old mythos and the institutions
built on those old narratives will try to defend themselves all they can although they're done
I call this the the the Versailles versus Paris uh dichotomy this is like 1789 in Paris so Versailles
today is politics politics tries to manipulate the algorithms in political directions so the
algorithms are not free and open they don't reflect you and don't reflect the kind of world you want
to live in and need to live in then we got the corruption of money they used to put the ads
on the side with the percent of the algorithms for you when you did your search now the ads are at
the very top of the ads are increasing the infill trading the algorithm itself it becomes a corrupt
algorithm because money is corrupting it and money should not be involved in creation of the
algorithm at least for you personally we try to search the internet the third one is the conformation
and that means the old established institutions hate the fact the world is splitting up in so
many different directions and it's becoming so chaotic so the old institutions like academia
like mass media you know television stations you know the old institutions they will all say that
you must be more alike you must be more conformed and therefore conform it in itself as a value
precisely we need more people to you know to be more creative about solving these problems we try
to conform everybody into the same pattern so these are the three fourths of the old institutions
the way Versailles would attack the streets of Paris in 1789 by telling the streets of Paris off
not realizing the people in the streets of Paris could read write or count which nobody in the
nobility of Versailles could any longer therefore the streets of Paris finally came to the conclusion
let's go to Versailles chop their heads off because the old institutions are useless to us these days
because we can create the new institutions that could work of course that led to a bloodbath
would you want to avoid what have a slow gradual decrease of the old institutions and want the
new institutions to come into place and the new institutions to come into place must represent
the logos the pathos and the mythos they must incredibly do that the different expertise
that's why you and I are very very careful to not ever speak like in a sort of general sense
we speak as the specialists we are even if we're considered to be generalists so I'm a
narratologist I do storytelling uh John Seticfist and I have worked with this for the past 25 years
you know he was a former scriptwriter I was a former music producer it makes sense to be
become philosophers of narrative and narratology and we now want to move the whole the construction
revolution of the 20th century into a reconstruction revolution of the 21st century which is fiendishly
hard we call it narrative you call it culture in your work where is the digital culture
digital is still a tale digital is hardly even happened yet we just know it's going to happen
and digital is going to remember absolutely everything the way it's been programmed at least
it's going to remember absolutely everything that happens so thankfully we have a data revolution
in parallel with increased complexity and that data revolution should be the free and open algorithms
that can help us to guide ourselves so we get a fair view how the world actually operates
it's required and if that's how we're going to solve climate change at the end of the day
you're not this working any longer you're actually providing proper data no climate change is
happening here is the data the satellites provide the data this is the actual temperature in
500 different places around the planet right now this temperature should be in July this temperature
that's in July so you know the data at the end of the day convinces people finally to give up the
resistance and realize the climate change is really happening and now it has to be worked on
and that's sort of logical argument the logos once the logos comes into the picture it becomes
a lot easier to convince more people this is actually happening you cannot escape this and
along with this must be done before that we just did the guesswork we just did the storytelling
just had fairy tales suddenly is real and this when the real on the logos when the real from
the pathos to the logos comes into the picture when the undeniable facts are there we have more
hope of getting things done than we did right before so I I generally agree that important
deconstruction happened an important reconstruction of a different type a different dimensionality
is needed when you identify rightly that all of the narratives had embedded power plays in them
and you kind of deconstruct that you look at all the motivated reasoning that was involved
in a way you actually heighten power to be the only game there is because there is no
unifying basis of ability to form shared basis for choice making and so the ability to have
epistemologies of is science and epistemologies of all ethics that work together better
that are never adequate but we're continuously improving that identify their own perverse incentives
and where the perverse incentives affect the nature of the motivated reasoning itself
gives you something like whether you call it metamodern or whatever some capacity for
shared choice making that is not just the game of power so I would very much like to go there
I'd very much like to go into the relationship between what has to happen in culture or narrative
or superstructure or like our shared values or shared meaning making to inform choice making
and how that relates to tech but I think because you said a lot in there I think the place I'd like
to start is when you said what happened between Paris and Versailles we want to do a slow version
now so it's not so bloody and that the previous institutions are kind of holding on
there's this story that like looks like the sovereign individual put forward
that said changes in tech change social structures we know that changes in info tech
specifically do right so Marvin Harris said the first argument McLuhan really went deep
with the second argument and that you get a printing press and in feudalism and usher's in
democracy and in Catholicism and usher's in you know Lutheranism and other things
because the nature of everybody can have a newspaper and everybody can have a textbook is
really different so you it's a democratizing force but it was tech affecting the social system so then
the idea that the next we we got modern democracies based out of that
the idea that the next major change in the information technology is the internet computation
and then shared distributed computation and so now we can share value online by moving bits around
in uh net space as opposed to just atoms around in physical space and we can find networks of
affinity that are stronger than just the networks of geography so the nation state that was a
geographically based thing to move atoms around will be progressively less useful than the net
based move bits around thing and so you'll get these new emergent systems that kind of debase
the old ones i think this is a good and partial insight i think there's a heap wrong with it
and i want to hear your thoughts on one part of it because one specific part there's quite a lot
the fact that we can move bits around and have that correspond to value doesn't mean we don't
also still have to move atoms around or that the virtual world doesn't completely depend upon the
physical world and if the virtual world depending upon the physical world is debasing the integrity
of the foundational thing it depends upon there's a problem in that thing um so there's a bunch of
things i have there a problem with it but one in particular we talked about how to have it be less
bloody in the old institutions there was bloody overthrow of feudalism right the american revolutionary
war is one of many there was a thing where the symmetry of power was such that the uprising
army could deal with another army sometimes right within a standing army pitch forks could deal with
swords sometimes um i don't see how the focus of how the old nation state institutional thing falls
works very well with those who hold the nukes because there is no other force that overthrows
that thing unless you talk about ai's i can capture it that's fine um outside of that we can see the
ussr go through a complete economic socioeconomic collapse a collapse of the political economy
and stay a world superpower and turn itself into something else because we got fucking nukes so
back off like it's a so i'm curious how you think about that when you think about the transition
of power and uh how hard it is to deal with that particular part of it well the old structure stays
it doesn't go away you know food was still incredibly important even when capitalism arrived
it just as food production wasn't the center of the economy any longer it became a marginal
part of the economy and so the same thing here uh the nukes are perfect cases but so far at least
they're not owned owned by corporate corporations corporations don't have the nukes yet so they're
stuck with like large nation states hopefully not too many of them too quickly because otherwise
the bomb is more of an acute problem the climate olivism so that served me an existential problem
right there and and i would say the institutions are still there and what you want to do is you
want to keep those institutions that says that okay if you those institutions still have the
problem the nuclear bomb so it's locked up for good and then we can see if we use nuclear energy
something better um in and again that means that let's not give google the bomb you know
that's that's the problem there whether that could still happen or not we don't know yet
and there's this is where it comes into we know from hegel that triads are stable and we need to
try it the problem with with digital the problem we call the nectocracy the problem with this new
sort of this sort of global power lead that rides on digital and happen to be the people
with the right talents the right motivation to be powerful and influential during digital
is that it's an entire new paradigm all together and obviously big tech is the first one of the
three nectocracies and it's the first one in the sense that the the the asset here is no longer
land or capital the asset here is data and because collecting and processing data is so
fundamentally different from collecting and processing money it requires a whole new set of
talents the money goes to those who have the data anyway meaning they can concentrate on the data
and the data processing and that's exactly big tech has done and then taught the rest of world
this is what we do so that is just the first of three necessary uh structures and it represents
the real in the sense that the data is the real here but that requires also symbolic order and
imaginary order to complement that and we don't have those yet the chinese have probably called
you the way they call me they're interested in guys like us at the moment but they have their
very definite plan what they want to do next which is to create what we called a sonsocracy
and the chinese idea of the sonsocrates is that increased complexity but also the possibility
of algorithms to control data flows and have an oversight over the increased complexity
requires at least for china and china's history to have one guy at the top so they go they don't
go for the persian model which i strongly propose which actually the us constitution was built on
which is that you install power sharing from day one into the system before the system kicks in
like in any bazaar you you you make sure that the power is split between three which none can
dominate the other two because if one dominates the other two will stand up against the third
therefore you have a split and this is the beauty of the us constitution and what has
kept the united states together since the 1700s precisely the constitution the constitution itself
is in an imperial order of persian origin and here's the difference the reason why the persians
didn't spend their entire fortune building pyramids and finally just killing their whole
civilization building pyramids was the persians knew dutching from egypt they didn't want that
they didn't want the pyramid constructions they didn't want the entire culture being obsessed
but feeding the dead which were the egyptians did right they wanted to feed the living so when
sorastical structures or asterism one of the trade group religions by the way it's very close to
buddhism and dalism when he did that 1700 before christ he said let's not do animal or human sacrifice
any longer it's just a waste of resources he was in the logos completely there are no gods
who pay any attention to sacrificing humans or animals this is ridiculous let's get over it
let's die when we die and let's transcend ourselves by having children who take over
the world from us when we die and therefore he enabled the very thought that there could be
civilization this is the first time in human history somebody thinks what a civilization
could possibly be we could improve on the world everything doesn't have to be an eternal return
of the same as it is in paganism it is an eternal return of the same the seasons come and go the
world come and goes people live and die and they breathe and live and die but there can be an event
that's why our book is called pros and they could be an event and the event can change history forever
the event can be for good or bad depending on us humans it can be Hiroshima it can also be
future nuclear power that might save the world with you know affordable and and exploitative
energy forever you know it could be any of those things it depends on where we put our imagination
or put our efforts or work that's so raster's insight and therefore he constructs that even
event is possible and the fact that event is possible is what we take with us the problem
with our culture was that we started believing the event so strongly forgot about the process
this is the essential problem of western culture if eastern culture got too stuck in the process
didn't think the event properly then the problem with western culture is that we inherited from
the persians was the belief in the event that the persians always tied to the process we ignore
the process altogether and therefore we created religions that says if we exploit the world until
extinction comes god will come and save us and give us a new Jerusalem that's literally what
Christianity and Islam have been preaching for thousands of years and that is of course not
sustainable at all we're now discovering that we need both the process eternal return of the same
circular time and we need the event which is linear time we need to think the world both ways
and this is the beauty of power sharing power sharing reinforces that it says that there must
be split power from day one before you put the button on the ai it must understand the power
must display the chinese don't want that the chinese are terrified of it they go for the
egyptian model it says no we're just gonna have one fair at the very top and build a huge pyramid
and off we go and then we know what we're gonna do with the data and increasing and now when data
solutions become incredibly complex and incredibly expensive the chinese are going to excel at that
because it's exactly what they're doing at the moment they're creating a modern day egypt the
question is then can we especially america then create an alternative which is more like the persian
imperial model and i think building on the u's constitution is the beginning because the logos
the pathos and the mythos the three narratives are split the logos is the congress the pathos is the
precedent and of course the matriarchal bitch at the opening of the bazaar is the supreme court at
least it should be where the mythos is located so the you you have a narrative here that is balanced
dialectical it never arrives in one truth because the three different truths that can be spoken at
any given time depending on which of the three positions you take now we know that for a fact
it's a pragmatic solution to the overall problem of power and the narratives must be there from
all three angles therefore we must have a system that implements all three so my suggestion that
whenever you do with ai make sure it splits itself dialectically into these three posts
before it does anything else whereas the chinese are going for now we've got a one guy at the top
we're going to marry the aabic cmp and off we go and we have the pharaoh again
okay if i might ask a question because i was uh listening to this fascinating conversation
and one question arose and maybe daniel you can answer to this because we were talking about
you know conscious design of technologies and you know outcomes that we didn't expect
kind of ways we were talking about you know a third attractor in ecology you know of of new
narratives but at the same time um we know that we are uh storytelling beings you know we can't
really live without narratives and myths and stories except we go maybe in meditation and try to
get rid of that um but then at the same time we also know that events are way more random than
we think you know so we see that you know in the policies let's say how europe dealt with russia
nobody could foresee what is happening right now and so the the question really is like if you
have uh our urge to live with narratives and the randomness of future events so the it's it's
kind of a creator paradox or creator parallax so how do we create a better future and more functional
narratives if we know that the events are way more random than we think and that we can't really
foresee what kind of uh affects our decisions might have and so that that question is kind of
boggling me sure um it's funny because um a lot of people think about religion in terms of narrative
and there's probably a distinction that alexander would make between narrative and mythos but um
roughly i'll just say in terms of narrative and you're talking about the ability to forecast the
future of a certain kind of certainty about the future um and i i think one of the things
like religions that smith mixed bag because there was like good philosophy and then political
power plays that got mixed together because of course memes don't spread for no reason they
spread because someone's invested in spreading them and they so you you get like good kind of
gnostic and the scene and whatever thinking but then you get the council and i say i'm making the
bible and the crusades and they change the stuff to be supportive so like the throw the
religions out completely or believe them completely they are both silly right you've got a kind of look
at um which memes are true good and beautiful and which one's one war and coordinated people well
and the difference between those and um but if i think about the meaningful part of religion a
big part of it is how do we actually deal with the radical uncertainty of the world
and knowing that uh all the choices we make are going to be consequential not making choices
is still making a choice is consequential and i'm making every choice under partial information
and there is some stuff that is quite possibly affecting the situation that exists in the unknown
unknown set i don't even know that i'm not factoring it so how do i make progressively
competent rational decisions while holding the profound amount of uncertainty that we have to
have um so there's like a mature relationship to both certainty and uncertainty or anything
able to hold those together where you both get way more epistemic humility and way more epistemic
rigor at the same time um okay so that was just one thing so i don't think you get anything like
perfected prediction and i don't think it's even a good impulse like i don't think it arises from
a healthy place in people this is why so often when i start conversations with friends like
what happened earlier today about ethics i end up starting with heisenberg and gordel and tarski
and like the upper limits of no ability because what it means is i'm not going to get an ethical
system that's computable um that as gordel said my mathematics can be consistent or complete but
not both which means bound to incompleteness forever or what heisenberg showed about measurement
which is deeper than science upon which science rests is i get um i get indeterminism forever
right like a fundamental thing so that doesn't just mean throw up your hands and believe in
whatever god you want but it does mean that the impulse to certainty is an immature one
and the the unknowable set is larger it's a larger infinity than the knowable set is
and so like a healthy relationship with unknowability is part of spiritual maturity or cognitive
maturity or emotional maturity or probably all of those um and so then how do we make choices
in the presence of that um i don't want my narrative to tell me how it's all going to go
with high certainty i wanted to like help me orient to how to make good choices in the presence of
the uncertainty as well i think you guys had a conversation with mark uh the rabbi on here not
that long ago and he said something to me that i think might have been the best formalization of
ethics i have had ever heard he said that all fears of ethics are feathers of intimacy
because if you're in real intimate contact with any reality whether it's a tree or a forest or a
person the intimacy of the contact meaning you're you're not modeling them in some trolley problem
way you're actually really in contact with their sentience informs you everything you need to to
not harm it both the motivation and the sentiment the sensocracy in an embodied sense of it um so
the narrative that actually takes us into way more intimacy with the world um uh how we come to
progressively better knowing but we never think that the knowing is more true than it is which
becomes a false idol right um these are the things i i want a narrative a good a good religion to do
but just very pragmatically i think there's a lot of things we say we couldn't possibly predict that
are really fucking predictable and we're we're not trying or we're lying um or we're just applying
silly models there's places where we're applying silly models like engineers not factoring psychosocial
effects if they're not being trained in social sciences like that's just silly like we should
just do a better job of that but there are plenty of places where it's like oh we had no idea putin
and such and such really like nato aggresses on his border in every fucking way possible and he's
like dude fucking just don't just commit to not take ukraine and tornado and they're like no we're
not going to do it and they're like how much did we like the cuban missile crisis the idea of
russian bases that close it's like oh we had no idea who's going to do that really like just
what would you do in his position play the game theory a little bit so there's a bunch of places
where the unpredictability is bullshit um for things that are actually decently predictable um
and then there are places where it's like okay there's a radically complex thing i don't know
what's going to happen well that's where you have to do safe to fail probes is there some way
to be able to run an experiment here that is not consequential depending upon how it goes and if
there is no safe to fail probe they just don't do the thing yet right um so with a lot of ai and
biotech and i think those are the answers and then a lot of it just has to do with processes of
recursion so let's say i want to forecast how my new technology is going to affect people
so i think about what are the things this is going to enable that will actually be really
desirable as a result what behaviors are those people are going to do as a result how does that
affect their minds and psyches is it there's some super simple principles like if it's engaging their
attention it should make their attention spend better if it has an effect just there's some base
reality that it's engaging with it should enhance the base reality it engages with if it has choice
architectures that are designed to affect the choices people make i affect their intention it
should support their net intentionality and their sovereignty of local control like there are some
things like that that should be ubiquitous and they're just not um that could help to even have
sense making frameworks to think through oh we couldn't have guessed it would have done did you
even think about what it would do to attention or intention or polarization or anything like that
so we can just do a better job but there will be still be some stuff you don't predict right
so then you run an experiment and then you say oh wow i did this shit we didn't know so now you
turn that into the design process then you do a beta release and then you're watching for a bunch
of stuff including some shit that you don't know right you're watching for some stuff but you're
also just seeing let's just watch the people using it and the people around them and just see if
there's any weird new stuff that happens because that's how we deal with the unknown unknowns is that
we don't formalize what metrics too closely we just watch for weird stuff right and we didn't expect
that there'd be less time at the family dinner table that's worth noting so one of the things is
if i don't even know what to look for just do kind of broader spectrum observation and then say okay
let's see if we can find out why do some research on it and then internalize that into the design
and fix it again but that means that when you observe the thing and then you come up with a
new design whoever comes up with a new design has to have the authority to implement it not just oh
sorry that goes against our business model and we have a fiduciary responsibility to maximize profit
so you have to create a business that has a collect or a corporation or whatever it is that has a
collective intelligence uh i mean excuse me that has a a type of intelligence that is oriented
to be able to forecast as much as it can and to recursively upgrade itself where mistakes were made
i think this ties nicely into our idea of the bazaar so there has to be some kind of new container
here that works and it's an alternative to the sort of the chinese fantasy of the sonocracy
that's more free and more open and therefore more sustainable more resilient and will last longer
the argument for the persian empire is not a moral one the argument is that the persian empire
lasted for 2200 years the gypsum empire repeatedly imploded and with a knot and only lasted for six
years it was over and done with so style then is it doesn't last that's the argument against
our lesson here resilient systems actually are pragmatic and and they realize that splitting
narrowcase and splitting power from the very beginning makes the system much more resilient
over time and and therefore it can work in the kind of environments moving into right now
this is something you said about splitting power and that you program that into the ai and this
seems extraordinarily problematic because um checks and balances on power yes we like that idea
so one you know as well as i do that ai is not being set up that way and it's moving really
fucking past so there's a reality to tend to here the other thing is that making uh similarly
powered ai is divided in an adversarial network is how you make both of them crazy fucking smart
right and so the reason that alpha go was able to defeat stockfish like it was standing still
was because you never programmed a single human game in it you made two computers
play each other a trillion times in three hours and so what that then does is say okay well this
system can check this system vice versa the two of those systems now in a or either of them in
combined capacity is so asymmetric to every human system true but but the the computer is
still only doing the logos at least i want to believe that so the pathos of the methods are
two realms left and if at least the computers are interesting in interacting with human beings
they don't go off into outer space and do their own thing as a technological intelligence
which probably should lead them to do is basically say you can have Mars on your own right please don't
kill us on earth right or something like that but if you think about at least at least so far
history has been about human beings and has been a human society we're talking about here
and natural logically speaking the computer cannot do the methods and the computer cannot
do the pathos it can only do the logos but it does the logos with incredible efficiency
anything credible you seen have you seen dolly yet yeah the visual gpt3 visual audio gpt3 yeah um
so it's early right but uh will it be able to generate methods that are compelling for people
at a Turing test passing level totally will it be able to generate art that is evocative enough
that people experience catharsis i.e pathos sure so is it experiencing pathos or methods no
but can it do a thing that evokes it in fact maybe even split test for its ability to do that
progressively better on an asymptote sure now this is really fucked up and interesting right
yeah and considering how terrible the latest star wars script is if that was written by humans
then humans don't deserve to survive to be honest about it you know we need better artists than that
it's just so fucking crap so yeah um i think i think though we're moving to the other we're
moving into the third nautocracy the second one is the sense of cracks or whatever is collaborating
with the satellites and the data flows around the world to create the container so if you isolate
the container and think of the container what we usually call politics is separate from say
perverse in business and enterprise which is what we call it indeed so that those two are separated
we have the informational lists or the informationism which is which is essentially data and and
that's big tech today the second one is in socracy whatever places politics we know it has to be
sense of critic and if we don't save the planet to begin with since socracy will never even happen
so the socracy has a self interest in at least saving the planet to begin with the chinese
other model we need to catch up with them quickly and create a different model that i call more
personal the third one though is the third nautocracy is the artistic one this is the imaginary one
no this is the real one it's tied to the path so this is the artistic one because art like sex
and violence are actually tied to pathos so this is intensely human this is the intense this is
where sexuality violence is located this is where we're as far away from the machines themselves
as possible and this is where the symbiotic intelligence comes in for example if you're
going to write a really fantastic eight hour series that's going to spell spell by in the world
what you would do today is that you will collaborate with the ai you will do symbiotic
intelligence and practices as an artist and i think at the end of the day the machine on its
own doing it will be vastly inferior to what a human being can do with a machine i think for the
foreseeable future we're saved by the fact the symbiotic intelligence will be better than artificial
intelligence in all of these three narratives that i'm talking about and if that is the case which
otherwise why would you must be around you know but if that is the case then the the artistic
aspect is the really protopian one so the protopian it's not so much that in art it's not so much
that you're productive you incremental improve on something one step at a time like you do
for an engineer but protopiness and for an artist is just the the unbound exploration of the darkest
shadows and the most fascinating storytelling we could possibly have and you're telling it to
grown-ups you're not telling it to children in a fundamental sense like real art is challenging
you it's challenging you in a transformative way and it has to be the third aspect of an autocracy
and we will give away the third power to the people who with their machines are capable of doing that
this is where art is heading and i think again our term the unideveloped symbiotic intelligence
fits better here than artificial intelligence when it comes to doing these things i've wrote pop songs
for 25 years and i've heard machines writing pop songs and yes they sound generic and professional
but they sound like german pop songs like they sound like i just copied last week's number one
record and i make it a new record now we can hear what you copy it it's just too similar to what we
heard it's eerily boring right and so far at least the machines have not been able to come up with
anything else because machines always work in the past the curse of logos is that logos can only
work with data that already exists they can only write things that are similar to what we already
have but the idea to imagine a future that's radically different from anything we've ever seen
is still a very very human capacity only because one of the reasons that GPT-3 is passing the
Turing test now is because for many audiences and if you have GPT-3 created text in areas of subject
matter expertise and subject matter experts are looking at it they know it doesn't pass the Turing
test but for general chatbot functions it does but it's not because the AI has gotten that good
it's because most people's ability to be able to vet theory of mind or have deep conversation
has gotten so bad that there's like this like it's kind of funny that's like reclaim the quality of
the Turing tests by increasing human intelligence to be deserving of the term of general intelligence
that we can make the test a little harder the reason i bring it up is because so let's say we
have a symbiotic intelligence where we have a human using a transformer AI to generate stuff
and people like it well in the classic adversarial network type style i could then train another AI
on the output of that symbiotic intelligence and whatever the metric of win is pop chart
hips or whatever that is going to be judged by the demand consumption of by other humans
i just say beat it and of course now what it's trained to do is be able to identify the things
to do more of that and so of course it will like it'll be able to beat that if we can define it in
any narrow metrics because it's the same as beating us at starcraft or chess or go as soon as it can
define it as a finite game i don't think it can win at the infinite game but i also don't think
most humans are oriented to infinite games right now nor our economic systems or anything else
and so it's like i think the symbiotic intelligence would produce more meaningful things
if the depth of what it means to be human in the depth of the experience the depth of the pathos
and the methods that are not the logos is fully brought to both the creation of it and fully brought
to the appreciation of it by others which is now why this work in in culture and narrative is so
important because anything less than that if it's if it's consumers who want one marshmallow
hypernormal stimuli and producers who want to supply that know the AI will be the symbiotic
intelligence yeah and this is this goes for popular culture certainly and we're very dark in
digital libido so it gets not right that the vast majority of people will be sedated by popular
cultures probably manufactured machines because it's more efficient to do it that way but there
was something eerie about it the thing is that you might be fooled once but you're not fooled
several times over until you discover this eerie feeling that this is increasingly predictable
and it's increasingly flattering like the culture's fighting and this is the problem of popular
culture it might work for kids stories it might work for disney right but that's not art at all
and i think this is why we so strongly philosophically defend the concept of art
and we put that put it in the pathical narrative the mythical narrative yes can be mass produced
they can be manufactured by technological intelligence it's just you put the button on
the and it produces disney culture that's exactly the new star wars series that's why it's crap
because the script is so bad it's so predictably bad right because it just tries to flatter you
tries to fly it doesn't it doesn't challenge you it's not going to transform you at all real art
therefore has to be located next to sex and violence and we call the tantric realm in the
really grown up adult realm it challenges you fiercely otherwise it isn't art at all and it
challenged you to transform you the truly artistic experience is not just to kill time that's what
silicon valley and hollywood are trying to do they just try to kill time no real art is that you go
through transformative experience like a spiritual experience that transforms you you're a totally
different person when you come out of experience compared to who you were before in either direction
doesn't matter you changed you have gone through an event your life is no longer the repetition of
the same i don't see any machine being able to do anything remotely like that yet that's why art has
to get out of popular culture return to its own realm and go spiritual and that's why we put art
in the pathical narrative that's what's important in their ecology mythical narrative can be mass
produced yes that's popular culture but pathical narrative is an entirely different thing and i
would know because i was in the mythical narrative production when i was a pop song writer and pop song
producer i never tried to do jazz or opera i went to the opera and i enjoyed jazz because i didn't do it
i didn't do anything pathical i did mythical things but to then go into the pathical narrative
where i tried to be as a philosopher is fiendishly more challenging but it's absolutely required
and this is probably of all the three narratives the hardest one to nail because at the end of the
day we now live in the world where death is the absolute i am adamant i'm with a lot of thinkers
today to say that the problem with the west is that we banned everything that was out of our comfort
zone and we basically called it sin and at least in the east they realized that no sin is not going
to disappear so instead of creating pressure cookers that blow over all the time and cause
huge warfare and misery instead it's better to have it around but to have it around inside a container
and only those who can handle it can go there and handle that container they're the ones who
can have access to it that's the concept of tantra this is interesting sutra is the message the
narrative that makes people love their children so they want to survive that is the ultimate truth
of sutra sutra has a direction must be exactly that the opposite of the sutra is the tantra it's like
okay we don't know where this is going therefore we're containing it we're keeping it in some kind
of a laboratory and we can only access by people who can really go through it and that's where sex
and art and violence must be located that we must realize that these are factors of human life
and that's what we're working with as philosophers at the moment so i think it's important here to
make that distinction i don't see any machine even being remotely close to creating a credible
pathological narrative in the foreseeable future it's funny that you say that the elites now believe
in death because in so many important ways i don't see that like the extreme life extension
movement radical life extension movement for radical biological extension is totally a holy
grail pursuit and then the biggest one of course and and the brain computer interface
pursued all the way up to the full digital consciousness singletarian we can all be
ai gods in a universe that we can fork infinitely remember how i told you daniel that engineers
don't know what they're doing because the engineers haven't talked to the priests this is the perfect
example to give exactly that they're going to create things that are not at all what they thought
they're going to create and so and whatever they're all going to be disappointed when they're dying
finally learn to die with some fucking grace and i think but i think the death escape has arrived
it has existed all along buddhist thoracists and Taoists always knew they would die when they die
and the question is what transcends you they always had that question that question around for
thousands of years we just need to get rid of these childish religious that promises the afterlife
of the reincarnation because it was too hard to tell children that their parents had died right
it's just it's just death as the absolute has arrived i think it's a dominant story today
and i think these people who try to escape try to escape precisely because they find it hard to die
one of the things i really like about the invisible afterlife um i like the reincarnation
version better than heaven and hell version but i like that you can get narcissistic and even
sadistic people to do the right things for the wrong reasons um meaning if i don't want to reincarnate
badly and i can't hide the karma from god or from uh universal accounting system then even though
if i could hide it from the humans i'd fuck everybody over and get ahead and if death was
the end that'd be fine the fact that i can't hide it from the day of judgment or whatever it is
means now i have to do the right thing for my own prevention of suffering i think that was actually
brilliant and i think there were places where that obviously didn't work all that well in many
places but there were places where it did um how you create a system where even if someone uh if
someone's focus of self is too personal right too much narcissistic trait not enough empathy etc
they still are oriented to a system of ethics i think that's one of the things the system has
to do as a failsafe while it works to condition people who all have authentic intimacy where
emergent ethics can arise um i know it is time for us to wrap up and it's late one thing i was
going to say we should do next time that would be fun we opened a lot more threads and we closed
but that's good you started talking about um uh what ai won't get and will get in the future and
what the three different types of uh natocracies will be and i i think if we were to just kind of
give a vision like what is a positive vision for the not too distant future like you know 50 years
out or so that we can see that involves uh getting mythos pathos logos all meaningfully better right
that my terms might be getting some of the critical things that have to happen in infrastructure and
social structure and superstructure whatever um what is a vision that could happen that would be
a fun that'd be a fun place to go i totally agree uh so i just want to add that we also need a new
sutra a new story about how we're going to love our children therefore we want our children to
survive we need a new one so we can't go back to the old ones and and when it comes to the
belief in the afterlife that also ruined ancient egypt that's why ever since then we sort of suspected
that we will not live after we're dead so the afterlife was a very very destructive thought
in that sense when it was taken all the way through the ancient egyptians at least in the
first kingdom seriously believed that life after death was more important than life right here and
now ever since then well at least we've doubted it so uh i think those those i think once the gene
is out of the bottle historically in this sense that a certain tantra is now leaked into the sutra
and we can no longer pretend it's not there that's what i mean we cannot construct the system of
believing the afterlife we believe in reincarnation and longer we cannot even believe that we're
going to conquer outer space and live another planet because we're way too late to that race
ai will certainly beat us to it so ai will take bacteria away and go to other planets and we
won't even be part of the game that's more likely so we can look into that we can look into what
could possibly the new sutra be what could be the new story we could actually tell each other and
agree on and then at least the tantra itself we know it's around but it's hidden in containers
for the people who can actually absorb it and understand it and thankfully because it's tantra
so tied to complexity that we can only specialize on certain complexities like you and i honorably
do we're supposed to be generalists but nobody can be a generalist any longer that's impossible
we can only understand that that's impossible therefore we're more hegellian in the sense that
our absolute knowing is not that we know everything is that we know the limits of our own
knowledge and we thrive within that limit and that's exactly what we're promoting very pragmatic
ideas constantly we will learn from history like and it's moving quicker than ever it's more
important than ever to be pragmatic about history and to make due process before we make decisions
and start building things that's where you're an absolute the adamant anything else is completely
responsible from now on historically speaking so i would love to be more into that yes absolutely
all right this is fun alexander daniel thank you so much for taking the time i think it's
very late at your end daniel what is it two o'clock in the morning already yes thank you again
fascinating conversation i would love to do a second part where we have a look at the future
in 50 years it sounds super interesting um yeah thank you guys thank you tom for making the space
and having us here and uh and alex for uh having the dialogue i it's funny because you and i think
about things that are so related and i think both try to um bring deep frameworks and they're such
different frameworks it was like such different schools of study that um uh i really enjoy it
because i get different insights and learn every time we talk thank you so much i'm on i'm over here
in europe and we have hegel and itcha you have the fantastic american pragmatists and our shared
friends layman pascal and saxstein are big fans of pers and james and these guys that is the other
tradition that i really really really think is fantastic and for anybody's interest in philosophy
you need to do your hegel and your nature and certainly your pho like you certainly need to do
the american pragmatist so that's the tradition you come from and i hear it in the way you speak
and the way you address issues that there's so much of american pragmatism coming through to you
and i should say this last thing i'm off to the borderland next week which is northern europe's
burning man so of course another thing that dad and i've been coming with both good old burners
we'll have a blast there i have some friends that are going to be going there and maybe i'll
connect you all and you can meet up there exactly speaking speaking of the pathical narrative
participatory culture is where it's at
