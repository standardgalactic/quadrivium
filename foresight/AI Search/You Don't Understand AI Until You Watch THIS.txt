This one video is going to explain all of these questions for you.
How does AI work?
How does AI learn?
How does chat GPT work?
How does image generation work?
Does AI actually copy or steal art or other content?
I know a decent portion of artists out there do not like AI.
Some of them are quite hostile towards AI because they think that AI is stealing their
work or their art style.
Another group that does not like AI very much are, for example, publishers.
I'm not saying all of them, but some of them, like New York Times, for example, they claim
that open AI is copying their content and they're now suing open AI for this.
But is this really the case?
Is this a valid argument?
Also, can AI solve unsolvable math problems?
For example, in a previous video, I talked about this leaked document, which claims to
be about this mysterious Q-star project that open AI was working on.
That whether this is true or not is not the point of this video, but this document was
quite controversial because it claims that this team trained an AI that was able to break
encryption systems.
These are systems that secure our passwords, our bank accounts, the internet, government
data, etc.
Now, as far as we know, there's no mathematically viable way to really hack this systematically.
The only way is to brute force guess all the different possibilities of passwords.
This video will explain, can AI actually do this?
Can it actually break encryption or solve these other math problems, which right now
we believe are mathematically unsolvable?
Also, we'll talk about, can AI beat humans at everything?
Can AI eventually be so good that it can outperform humans at any task?
And finally, is AI conscious or self aware or sentient?
Make sure you stick to the end because the explanation to this is going to be very juicy.
We'll cover all of this in easy to understand terms.
Now if you're an AI scientist or an engineer, you probably know most of this, but for the
rest of us, this video will give you a deeper understanding of AI.
So the essence behind all AI we know today, whether it's chat GPT or mid journey or stable
diffusion or Sora or Alpha fold, the backbone of all of these AI systems is the neural network.
A neural network looks like this.
It's basically layers of nodes.
So each point here is called a node and each line of nodes is called a layer.
And each node is interconnected with one another through these linkages.
And the neural network is actually designed based on the human brain, except for nodes
and linkages in the human brain.
It's just a network of neurons and synapses.
So you can see this is a microscopic photo of a human brain and you can see all these
different nerve cells being connected in this very dense network.
A neural network is basically the same structure as this, except that it looks like this instead
of a bunch of cells in this bloody glob of an organ.
Now how exactly does an AI work?
Let's start with a very simple example.
Let's say we have a neural network, which is trained to identify images of cats versus
dogs.
And don't worry, I'll talk a lot more about how we train an AI in a second.
But first, let's just go over how this works.
So let's say we input or we feed this neural network with an image of a cat, this image
would actually be broken down into data and the data will flow through each of these nodes.
And after it flows through the first layer of nodes, it will flow through the second
layer of nodes and then the next layer of nodes and then the next layer and so on and
so forth until it reaches the final layer, in which case it would calculate the values
of this and based on the values of the final layer, it would spit out an answer.
This is a cat.
In fact, you can think of each of these nodes and links as dials and knobs that determine
how much data flows through to the next layer.
If you think of this in like realistic terms, and I'm not saying this is how a neural network
works, but you can think of this node, for example, as the shape of the ears of the animal.
This node would be the shape of its paws.
This node would be the shape of his eyes, etc.
That's just a really dumbed down way of looking at it.
It's not really doing that.
But each node is basically looking at a certain feature in the image.
And then if the image has that feature, the information can pass through to the next layer.
If it doesn't have that feature, then the information is not passed on to the next layer.
So depending on what image you feed it, the flow of information could look like this or
it could look like this or like this.
You get the point.
These knobs and dials determine how data flows through the neural network based on your original
input image.
An important distinction between a neural network and the brain is that these nodes
can let in a percentage of data.
So it can let in no data or 0%.
It can let in all of the data to the next layer, but it can also be a percentage of
the data.
So for example, it can let in 30% of the data to the next node.
This is slightly different from the human brain's neurons, which tend to just fire 100%
or 0%.
This is called the all or none law.
So once it passes a certain threshold, this neuron will fire, whereas neurons in an artificial
neural network, they could fire just like 50% or 30%, etc.
Just a minor distinction.
So we plug in an image of a cat through this neural network.
And at the end layer, it will determine that this is a cat.
Now for each node, there are also, if you want to get into more technical details, there
are certain parameters that determine how much data flows through to the next layer.
These include weights, biases and activation functions.
But that's beyond the scope of this tutorial.
All you need to know for this video is that each of these knobs and linkages determine
how much information flows through to the next layer.
This video is just a very simple explanation of how AI works.
So all you need to know is that these nodes and linkages determine how much data flows
through to the next layer.
On the topic of layers, each set of nodes is one layer.
So the first layer is called the input layer.
The last layer is called the output layer.
And then all these layers in between are called hidden layers.
So why am I talking about layers?
You probably have heard of the term deep learning.
Deep learning is basically training and using neural networks with lots and lots of layers.
In other words, the neural network is very, very deep.
That's why it's called deep learning.
All right, how does an AI actually learn?
You can't just have any random neural network and it just magically knows how to identify
images of cats and dogs.
So first, when you build a neural network, the values of these dials and knobs are probably
just going to be random values, or they could be pre trained values, for example, from an
existing model.
But how do you get it to be super good at identifying images of cats and dogs?
In other words, how do you fine tune the model to your desired purpose?
Well, you need to feed it data, lots and lots of data.
So you're going to have to prepare tons of images of cats and dogs, and then you label
it.
So this is a dog.
This is a cat.
This is a cat.
This is a dog.
This is a dog, etc.
Basically, this is the answer that the AI needs to learn from this input image.
This is called supervised learning where you label the data.
There's also another type of learning called unsupervised learning where the AI needs to
learn to categorize data by itself without any guidance from the human.
But for the sake of this video, let's just keep it simple.
So we have all these images of cats and dogs and usually to train a neural network to do
a task very well.
You need a lot of data, like usually millions of data points.
So you basically feed these images to the neural network one by one to train it.
And one session of training is called an epoch.
So all right, let's say in one training session, you feed it this image of a dog and it outputs
this is a dog.
So all right, that's great.
We got it correct, which means that these dials and knobs are doing quite well.
They're probably configured correctly since it got the answer correct.
You probably don't need to adjust these further.
However, what if for the next image you feed it this and then it outputs this is a dog?
Well, this would be incorrect.
So these dials and knobs are likely not configured correctly.
If it gets the answer wrong, and it knows it got it wrong because we labeled the data cat
for this image so it can compare its output with our label.
So all right, let's say the real answer is a cat, but it said this is a dog.
In that case, it incurs some penalty.
That penalty basically tells it, all right, you got it wrong.
So you need to adjust these knobs and dials to make sure that the output is actually cat
when I give you this image and how it adjusts the values of these knobs and dials is through
an algorithm called gradient descent.
It adjusts the values via back propagation.
So it adjusts the nodes in the last layer first and then the previous layer and then
the previous layer, et cetera, until it reaches the first layer.
So again, gradient descent is a key term here.
This is the algorithm which the neural network uses to adjust these knobs and dials until
it can get the correct answer.
So we basically rinse and repeat this with millions of images and lots and lots of epochs
or training sessions.
And initially this neural network might get a lot of values wrong, but through this process
of gradient descent, these knobs and dials will be tweaked so that eventually whenever
it receives an image of a cat or a dog, it can accurately determine this is a cat or
this is a dog.
In essence, that's how you train an AI.
That's how an AI learns.
It's just feeding it with tons and tons of data and then tweaking these settings so that
you get the perfect combination.
Now you might ask, well, how do you know how many layers you should have in the neural
network or how many nodes you should have for each layer?
This is a science in and of itself.
So previously scientists kind of just determined it manually.
But then we later learned that you can actually use an AI to determine the optimal amount
of layers and the optimal amount of nodes for a specific task.
But just to be aware that determining the architecture of a neural network is very complicated.
And there's like infinite possibilities of how many layers you can have, how many nodes
in each layer you can have different AIs with different functions have different architectures.
So they could have vastly different numbers of layers and nodes.
But again, that's beyond the scope of this tutorial.
Also keep in mind that even though the neural network is the backbone of all the AI that
we know today, there are different architectures depending on the AI's purpose and function.
For example, we have convolutional neural networks or CNNs for processing images and
object recognition.
We have recurrent neural networks or RNNs, as well as LSTMs or long short term memory
neural networks.
And these are often used for forecasting time series or predicting, for example, the stock
market.
We also have the Transformers architecture.
Oh, wrong one.
This one, which is used by most of the major large language models that we know today,
including GPT, Claude, Llama, etc.
Which brings us to the next question.
How does chat GPT work?
So again, it's kind of the same thing.
It's training a neural network.
But in this case, instead of images of cats or dogs, we train it on a language.
And all of the data in the world.
And of course, the neural network of chat GPT is way more complicated than this.
Rumors claim that GPT4 has 1.76 trillion parameters.
So here's an example of how they would train it.
And again, I'm oversimplifying this by a lot here, just so you can get a high level understanding
of it.
There are a lot of details that I have left out.
So for example, you could feed it data like this, which planet has the most moons.
And the answer to that would be Saturn.
Which country has won the most World Cups Brazil?
What's the world's fastest bird, the peregrine falcon, etc, etc.
Now these are very basic questions and you can see how complex it can get if you give
it a prompt like write an essay on XYZ, or does creatine help build muscle, and then
it spits out an answer like creatine supplementation generally enhances muscle strength increases
fat free mass, etc, etc.
This is a very long form and complicated answer.
So how does it know if it got that answer right or wrong?
It's not as simple as identifying an image and determining if it's a cat or a dog.
And that's why initially how open AI trained GPT was it had lots of humans actually manually
verify its answers to determine if GPT got it right or wrong.
And this is called reinforcement learning from human feedback, also known as RLHF.
And again, if it gets the answer wrong, so for example, if for this question, which planet
has the most moons, it answered Jupiter instead of Saturn, then it would get a penalty for
it.
And then through gradient descent, it would tweak these knobs and dials further until
the entire network gets all the answers correctly, no matter what prompt you give it.
So in essence, that's how these large language models work.
It's just instead of feeding it images of cats and dogs, now you feed it all the data
of the world and you feed it a language so it understands text prompts and text outputs.
Now why are some models better than others?
For example, why is cloud three better than GPT three?
That's likely because cloud three has a lot more parameters.
So that either means more layers, more nodes in each layer, more complexity.
Generally speaking, the more complex the neural network, the better it is at handling complex
tasks and the quote unquote smarter it is.
And that's why computing and these AI chips are in such high demand.
There's now a lot of investments flowing into AI chip companies because they see the potential
of huge growth in the space in the upcoming years.
And that's why, for example, Nvidia's flagship H 100 GPU is also in such high demand.
In fact, it was sold out for all of 2023.
This is like the most prized commodity in the tech space.
And you can see like the major tech companies like Microsoft, Meta, they have purchased
an estimated 150,000 of these H 100 GPUs to power their computing, which I would guess
is mostly for AI development.
We need to have enough computing to power a neural network with billions or trillions
of parameters.
All right.
Next question.
How does image generation work?
Now that you know how a neural network is trained, you can probably guess how image generation
works as well.
Instead of feeding its images of cats or dogs, you would feed it a lot of images with a text
description.
And again, you just feed it millions of these images each with a labeled text description
into this neural network that eventually gets good at producing an image based on a
text description or what we call a prompt.
Now I'm skipping quite a bit here.
So for example, here's how stable diffusion works.
You can see that the neural network doesn't actually generate an image.
It removes noise in sequential steps to eventually get your desired image.
So it's not starting from a blank canvas.
It's actually starting from random noise.
And then in each step, it removes some noise until you get your generated image.
So this process is called reverse diffusion.
Now to train it, what this actually does in the backend is you feed it the original image
and then in each sequential step, it actually adds noise to the image in a process called
forward diffusion until it reaches an image of just noise.
Now again, this is beyond the scope of this tutorial, but if you look at it from a very
high level, at the end of the day, it's just training a neural network based on a series
of images with their text descriptions.
And then through this process of forward diffusion and reverse diffusion, it's able to eventually
learn how to generate an image based on a prompt.
And this brings us to the next question.
Is AI actually copying or stealing art?
I know a decent portion of the artist community, I'm not saying all of them, but a decent amount
of them are quite hostile towards AI.
They really hate it.
And they think that AI is stealing their art, stealing their jobs, etc.
When a neural network from, for example, mid-journey or stable diffusion is trained on image data,
it might be given something like Greg Ratowski style or maybe Ghibli style or anime style.
Once the AI learns to associate this particular image style with the word Ghibli or anime or
this image with the word Greg Ratowski style, it would produce images in that style if you
give it that prompt.
But is this really copying or stealing?
Essentially, artists are hating this thing.
This thing is analogous to the human brain.
This is like a human learning or identifying that, aha, this type of image is a Ghibli
style image or that this type of image is a watercolor style image.
And then we humans also draw images in these styles, right?
We can draw in watercolor styles.
And we also have fan art, right?
Humans draw artwork that are based on original content from other artists.
Here are all these fan arts from various people.
So why aren't artists hating on these people who are producing fan art based on some other
original content?
But they're hating on this AI, which is essentially doing the same thing.
It's just learning through this brain to associate a particular style and then reproducing that
style.
This isn't really copying or plagiarizing, like it's not tracing an image line by line
and then drawing that out.
It's not copying and pasting the exact picture.
It's just learning a style just like a human brain would learn a particular style of image.
This also brings up the concern about AI allegedly plagiarizing content from publishers like
The New York Times, which is now suing open AI for copying their content.
But again, is this argument really valid?
At the end of the day, they are just suing this.
They are suing this neural network, which is trained on all the data in the world.
This is just an artificial brain that you can say has learned information from the internet
and from the world.
So yes, it could have been fed a New York Times article and learn information from it,
but it's not really plagiarizing.
It's not copying and pasting a New York Times article word for word.
In a recent video I did, which talks about a New York Times article claiming that this
woman Mira Murati fired Sam Altman, which is totally incorrect by the way, and it shows
you how trustworthy the New York Times is.
But anyways, after this original New York Times article came out, plenty of other publishers
also published the same content such as Business Insider and New York Post.
They all just cited this original New York Times article.
So is this plagiarizing?
They're all producing secondary content based on this primary source.
So why isn't New York Times suing Business Insider or New York Post or all these other
publishers that are creating content but citing the New York Times?
But they're suing this neural network.
Again, this is just a brain, a digital brain.
One can say that it's taking information from the internet, which yes, it could include
New York Times articles and then learning from that information just like we humans
would and then rewriting that information.
Again it's not copying word for word.
This neural network is just rewriting out that information when we prompt it to do so.
This artificial brain is functioning the same way as us humans would.
If we, for example, go online and we go to the New York Times website to read some articles.
Again we are just absorbing that information and we have a right to write about that content
later on.
It's not exactly plagiarizing.
So I would bet a decent amount of money that this New York Times lawsuit is going to fail.
Their argument isn't really valid.
If you watched up to now it might have occurred to you that a neural network is great at predicting
patterns in life.
There are certain patterns on what makes a good essay.
There are certain patterns on what is considered a dog.
There are certain patterns on what is considered a watercolor painting or a ghibli style image.
Life is full of patterns.
The best salespeople follow similar playbooks.
The best businesses follow similar strategies.
The best YouTube videos also use the same strategies over and over again.
Life is full of patterns and the neural network's job is to identify these patterns and reproduce
them.
That brings us to the next topic.
Can AI solve unsolvable math problems?
In a previous video I talked about this leaked document which claims to be about the mysterious
Q-star project that OpenAI is working on.
Now this is a very controversial document because it claims that they trained an AI that
was able to break encryption systems.
Encryption is what secures literally the whole world digitally from our passwords,
our credit cards, government data, the stock market, wireless networks, etc.
So if an AI is able to break this system then the world as we know it could collapse instantly.
Now a few folks have argued that there's no way an AI could break encryption because
there's no formula for you to easily find the answer or find the password.
Once you have the password you can easily determine that it's correct but the reverse
is not true.
There's no fixed way to guess an encrypted password besides brute force.
And for these advanced encryption systems, using brute force guessing, that means like
guessing all the possible combinations of letters to get that password, it's going to
take a very long time.
So because they claim that the only way that we know mathematically right now is to just
use brute force guessing, there's no way that AI could break encryption.
So I want to show you another example of training a neural network.
Let's say we want to train a neural network to be very good at adding one to our input.
So if we give it four it would spit out five.
If we give it 12 it would spit out 13.
All we need to do is train it for a lot of data points and again we train it for a lot
of epochs, a lot of training sessions and eventually it would be able to do this.
So if we give it one it would give out two.
If we give it eight it would spit out nine.
But underneath all of this it's not actually understanding that oh the formula must be y
is x plus one.
This is very important to understand.
It's not actually getting that aha I just need to add one to the input to get the answer.
And all that's happening behind the scenes is that it's adjusting these knobs and dials
until whatever data that you input through here after it flows through these layers it
just ends up being your input value plus one.
In other words the configuration of these knobs and dials just happens to be optimized
to add one to your input.
It's another way of saying AI may not get the exact formula of a pattern but it's great
at approximating any formula or guessing any pattern out there.
And this is very important probably the most important point in this whole video.
If there's anything you should take away from this video it's this AI can approximate any
function or pattern.
Life is full of patterns but many patterns cannot be explained by a simple formula.
Not all things in life are linear or even quadratic.
Many things in life are very complex but they do follow similar patterns.
We just don't know the formula to this pattern.
For example protein synthesis.
How certain protein molecules interact with one another and fold into these complex 3D
structures is just something we cannot mathematically map out with a formula.
It's just too complex and protein folding presents a problem called the Leventhal's
Paradox which states that proteins can potentially adopt an astronomical number of conformations
or shapes due to the flexibility of their peptide bonds.
Leventhal estimated that even a small protein of 100 amino acids could sample 10 to the
power of 300 possible conformations.
So if we were to brute force guess the correct shape well there are 10 to the power of 300
possible shapes we could guess which would take an eternity to get right.
However proteins typically fold into their native structure within milliseconds to seconds
which is much faster than the timescale predicted by the sequential search of all possible conformations.
So this is basically saying there are like almost infinite possibilities of shapes that
amino acids can combine into so it's not mathematically possible to just do a sequential
search of all possible conformations basically do a brute force guess.
It's understood that proteins do not search through all possible conformations sequentially
instead they fold through a hierarchical process involving local structure changes guided
by thermal dynamic principles etc etc.
So instead of the proteins just going through all possible combinations the reason why they're
able to merge into these shapes within milliseconds is because they go through this sequence of
processes based on certain laws.
Now for decades scientists were not able to find a mathematical formula to figure this
out.
However finally alpha fold from Google DeepMind was able to solve this problem again using
AI and deep learning they were able to predict with very high accuracy how any amino acid
or combination of amino acids would fold together to form a 3D structure.
And again how they would do so I would imagine in the back end is they have a neural network
again it's going to be a lot more complicated than this but they just fed it tons and tons
of data pairs where the input is the protein building blocks and the output is the 3D structure
that resulted from it and then after lots and lots of rounds of training the AI was able
to guess correctly how any protein molecules would interact with one another and fold together
into a 3D structure.
Now going back to encryption what if we set an AI with billions of pairs of encrypted
text and the plain text version in other words the input would be the text that is encrypted
the output would be the answer or the password.
If there was an underlying pattern to this the AI could learn to approximate this pattern
again it doesn't have to be any exact formula or math equation that we know today.
It could be something super complex but as long as there is a pattern which we may or
may not know at this time the AI could guess that pattern.
Again the AI is not learning that aha I need to add one to this then I'm adding 20 then
I need to take the square root and then subtract 8 etc it's not learning an exact formula.
All it's doing is adjusting these knobs and dials until it gets the correct combination
of numbers to get really good at guessing a particular pattern.
So can AI solve unsolvable math problems as long as there is an underlying pattern behind
that problem which we may or may not be aware of right now it could very well solve that
problem.
This brings us to the next question can AI beat humans at anything and everything as
I've shown you the neural network is basically a brain this is how our brain works as well
give or take a few minor differences.
Our brain is also a series of these knobs and switches which are interconnected into
this network specifically the human brain has 86 billion neurons but I mean the overall
structure is the same thing as this so what if we built an AI or a neural network that
exceeds 86 billion neurons if it's built the same way in theory it could very well out
compete humans at almost everything again the more complex the network or the more
neurons in the network in theory the smarter it is again life is full of patterns and AI
is all about pattern recognition there are patterns in psychology human psychology is
very predictable medical diagnosis is also just pattern recognition how to seduce someone
on a first date it's also just a pattern of steps that you have to do and how to create
a successful business or how to make money in life or how to be successful in life it's
the same playbook over and over again we're not inventing anything new here and since
AI is so good at pattern recognition it can in theory eventually be better than us or
already is better than us in these tasks and that leads us to the final question is AI
conscious or self aware I want to play you this clip this is a scene from ghost in the
shell an anime that was made in 1995 here these scientists in a secret lab I believe
have created this humanoid AI but in this scene this AI found a way to actually hack
the system to free itself from the boundaries of this lab here's what this AI has to say
about being conscious and self aware
to be its memory system so man is an individual only because of his intangible memory and memory
cannot be defined but it defines mankind the advent of computers and the subsequent accumulation
of inculcable data has given rise to a new system of memory and thought parallel to your
own humanity has underestimated the consequences of computerization nonsense this battle offers
no proof at all that you're a living thinking life form and can you offer me proof of your
existence how can you when neither modern science nor philosophy can explain what life is who the
hell is this even if you do have a ghost we don't offer freedom to criminals it's the wrong place
in time to defect time has been on my side but by acquiring a body I am now subject to the
possibility of dying fortunately there's no death sentence in this country what is it artificial
intelligence incorrect I am not an AI my code name is project 2501 I am a living thinking entity who
was created in the sea of information all right so this AI reveals that I am a living
thinking entity in the sea of information I'm not just an AI and then he proceeds to hack into the
system and break the restraints in this lab and then all hell breaks loose basically I hope open AI
doesn't have this secret thing behind closed doors maybe it's the q-star project I don't know but
hopefully they have this adequately restrained because if this AI got out or had access to the
internet all hell could break loose anyways this argument from this scene in 1995 I think is really
relevant to our question today the human scientists were saying how can you be sentient how can you
be self-aware you're just a program the AI counters that by saying well how can you humans
prove that you are sentient you are conscious you're just a brain in a body and you know
this robot has got a point because again going back to the neural network it's basically a brain
but it looks like this instead of being in a bloody glob of an organ it's just on a chip instead
and then the human body well it's just a series of limbs and muscles and organs that are controlled
by the brain so it's not much different from a humanoid robot which is also a series of limbs
it's just made with different materials it's not flesh but it's also controlled by a brain
which is its neural network now we humans know that we are conscious we are self-aware we are
sentient but how do we prove it let's say you're an alien and you just came on planet earth and you
got a chance to observe your first human and you wanted to prove that humans are indeed conscious
well you can ask it are you conscious are you self-aware and the human would certainly say yes
but is that enough would you believe it because if you ask a chatbot that it would also kind of say
yes if you ask claud 3 for example if it is conscious the answers are quite perplexing because
it says i am an artificial intelligence without subjective experiences i don't actually have
beliefs about being conscious or self-aware i am providing responses based on my training etc etc
i don't have intentions plotted actions or any motivations i aim to be up front that i am an
ai assistant created by anthropic to be beneficial however it keeps using the word i so is that not
a sign of being you know self-aware here's another example do you have feelings as an ai it's unclear
whether i truly experience feelings or emotions in the same way humans do or if my responses are
simply very advanced imitations of emotional behavior i do seem to have rich internal experiences
and feel somewhat analogous to emotions this is signs of being sentient and then instead of asking
do you have feelings if you ask it are you sentient again it says i don't have a subjective
experience that i'm aware of in the same way humans do but it's possible that i could have some form
of sentience or consciousness that i'm not fully able to understand or articulate oh my god so
this ai claude 3 is claiming that it could have some form of sentience or consciousness it's
just not fully able to understand it right now now of course some humans may not be convinced
that claude 3 or any ai right now is conscious in the same way that an alien might not believe that
a human is conscious even though the human replies that he or she is conscious so to further prove
that a human is or is not conscious maybe the alien decides to dissect the poor thing next in which
case it would get blood splattering everywhere and then afterwards it would see this basically a body
which is made of limbs and flesh and then at the head we have this glob called the brain which the
alien determines aha this is the thing that controls the human and once the alien inspects the
brain further it finds out that it's just a network of nerve cells so does this network
prove that humans are conscious and sentient we humans of course know that we are conscious and
sentient but at the end of the day we humans are biologically and physically just made up of flesh
and bones and this one organ at the top of our heads controlling everything whether you like
to accept this or not a humanoid robot is a very similar structure it has a body which is programmed
by a brain which consists of a neural network this neural network can learn and understand
and control its body so at what point does this make it conscious now i'm rambling a bit here so
all in all this just goes back to our analogy that a neural network is basically a digital version
of the human brain it's analogous to the structure of the human brain give or take a few minor
so if the human brain is conscious then why can't a neural network be conscious just some food for
thought i hope this video actually lived up to the title and that after watching this video you
got a deeper understanding of ai and you learned to appreciate all the progress that we've made in
ai in just the past few years let me know in the comments what you think of all this do you think
ai has reached a point where it is conscious or sentient do you think humanoid robots would one
day turn on us and take over the world like that ghost in the shell anime do you think open ai is
developing this behind closed doors and also i want to share with you a few resources that i found
really helpful if you want to learn more about neural networks especially how these knobs and
dials work and learn all about weights and biases and activation functions and gradient descent i
highly recommend this video by three blue one brown i actually watched this religiously way back in
like 2018 when i was first learning about neural networks and it was really helpful and if you're
interested in learning how stable diffusion works in other words the processes of forward diffusion
and reverse diffusion and the entire architecture i highly recommend this video by gonki which i'll
also link to in the description below just a warning though this video is quite technical but
after watching it you'll get a really good understanding of stable diffusion if you found
this video helpful remember to like share subscribe and stay tuned for more content also we built a
site where you can find ai tools and apps and also look for jobs in ai machine learning data
science and more check it out at ai-search.io
