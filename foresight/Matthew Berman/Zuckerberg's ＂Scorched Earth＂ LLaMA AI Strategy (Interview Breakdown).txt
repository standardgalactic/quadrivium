So I think we're going to live in a world where there are going to be hundreds of millions
and billions of different AI agents, eventually probably more AI agents than there are people
in the world.
All right.
So Lama 3.1 was just released today.
And along with that, there has been a ton of additional information released from meta
about how they think about open source.
Mark Zuckerberg wrote a letter, which I will also be covering, but he also did a 30 plus
minute interview with Rowan Chang.
And so today we're going to watch the video together and I'm going to give you my thoughts
on it.
Can I also just say I am absolutely loving Mark Zuckerberg's current vibes.
His transformation is going to be studied in business school for decades to come.
So let's keep watching.
Okay.
In this first section, he is going to introduce the Lama 3.1 launch and it'll be in his
own words and what he thinks about it.
So let's watch.
I mean, the big release today, first of all, happy to be doing this big fan of what you
do.
The big release today is Lama 3.1 and we're releasing three models.
The first time we're releasing a 405 billion parameter model.
So it's by far the most sophisticated open source model that I think anyone has put out.
And it really kind of is competitive with some of the leading close models and in some
areas is even ahead.
So I'm really excited to see what people do with that, especially now that we're making
it so that the community policies around Lama allow people to use it as a teacher model
to distill and fine tune and basically create whatever other models they want with it.
I already have to pause it.
So he said a lot just in those few words.
First of all, the 405 billion parameter model is outstanding.
It is leaps and bounds more sophisticated than any other open source model out there.
It is directly competitive with closed source frontier models and it is really the first
open source model that can be considered frontier.
Also all of this is a direct shot at open AI and other closed source companies.
And he is taking a tried and true playbook.
Microsoft did this for years.
Basically when you're behind in a technology race, the strategy that you employ is called
scorched earth.
Essentially invest a ton of money into replicating whatever that technology is and then release
it for free.
Because at that point it becomes ubiquitous, it becomes a commodity and why would anybody
go and pay premium prices for a closed source frontier model when you can have full control
over the model and pay fractions of the price.
Plus you are increasing competition greatly.
And so you have companies like grok, GROQ who are able to take this large model and
run it at inference speeds that are absolutely incredible orders of magnitude greater than
what open AI can run at.
And by the way, I don't think open AI is down for the count by any means.
Sam Altman is a brilliant operator.
And this is likely why they just released GPT-40 mini, a model that is as performant
as GPT-40 but for a fraction of the price and it's much faster.
So they're getting the message.
They see the writing on the wall.
Models are becoming commodities and I just read an article and I'm going to talk about
this in another video that open AI is building their own AI chips.
And again, that's really where a lot of the differentiation comes from.
That is why GROQ is so special because of their unique chip design that allows them
to run inference at blazing fast speeds.
And open AI wants to accomplish the same thing because especially after this release, models
are a commodity.
Let's keep watching.
In addition to that, we've distilled the 405 billion parameter model down to make newer
and updated and now leading for their size 70 billion and 8 billion parameter models.
So that's actually one thing I didn't quite realize even after reading the announcement,
they took the 405 billion parameter model and distilled it down into the 3.1 versions of
the 8 billion and 70 billion parameter models.
I didn't know that.
Does that mean that the 8 billion and 70 billion parameter models that first came out the three
version were standalone models and now these are completely new models?
I'm not actually sure.
So if you know, let me know in the comments.
Yeah, I mean, taking a step back, I think this is a pretty big moment for open source AI.
Yeah, I've been reflecting on this and I kind of think it's, you know, I thought for a while
that open source AI was going to become the industry standard.
And I thought that it would basically follow the path that Linux did, where, you know,
if you just go back to before Linux was popular, there, you know, there were all these companies
that had their own closed versions of Unix and at the time, you know, there's nothing
that was sort of that sophisticated that had ever been done as an open source project.
And people thought, hey, no, this is like the closed model of development is the only
way to do something that's this advanced.
And at first Linux kind of got its foothold because it was cheaper because developers
could customize it in different ways.
And then over time as the ecosystem built out, it, you know, got more scrutiny.
So it actually became the more secure one.
It became the more advanced one.
There were more partners that basically built more capabilities in the case of Linux, more
developers, and things like that, that basically ended up making it have more capabilities as
well than any closed source Unix.
So I think that this moment with Lama 3.1 is kind of like that inflection point where
I think Lama has the opportunity to become the open source AI standard for open source
to become the standard, the industry standard for AI.
And even in the places where it's not yet ahead on performance, it leads on, on kind
of cost and on, on customized ability and on the ability to take the model and fine tune
it and do all the things that you want with it.
So he also mentioned, and I forgot to mention this in my last comments, but he also mentioned
that they changed the license and now with the 405 billion perimeter model, they allow
you to create synthetic data from that model to train smaller models.
So that is a huge change and extremely valuable for the ecosystem.
This is what NVIDIA did with their Nemetron model.
They trained a massive model that generates data and has the permission to do so to train
smaller models.
And this is going to allow a lot of companies, a lot of AI model companies as well to make
their own versions of these models, dependent on the use case.
And that is a really cool strategy and something again, I really appreciate from meta.
I think that those are just huge advantages that that we're going to see developers take
and we're focusing on building out this partner ecosystem and there are going to be all these
different capabilities that get built out around it.
So yeah, and that's another thing.
He's not doing this just to screw over the closed source companies.
He actually believes in this as a true business strategy.
If you build out the foundation for other companies to come build on top of you, then
of course you get to set the standards and then you'll figure out ways to monetize over
time.
That's essentially what they did with Facebook.
They built out a platform, other developers came and built on top of it.
Now the counter example to that is Apple with the App Store.
They built a completely closed system and then other developers because it was so popular
came and built on top of it.
And there's the alternative Android, which is the open version of the smartphone operating
system.
So we needed a strong open source player in AI and now we have it.
All right.
Next is something you all ask me about all the time whenever I put out a tutorial, whenever
I put out some kind of news, you always ask me, okay, but what's the real world use case
and that's something that I've been trying to include more and more in my videos.
So now what Mark is going to talk about in this segment is what he sees as the real world
use cases.
He's probably going to start with the things that we all know are pretty obvious and are
the basic intro use cases for AI.
But I'm hoping he's also going to talk about the more sophisticated use cases and there's
probably a ton of use cases we haven't even thought of yet or that the capabilities aren't
quite there yet until today.
So let's watch.
The thing that I'm most excited about is seeing people use it to distill and fine tune their
own models.
Right.
It's, I mean, like you're saying, I mean, this is the first open source frontier level
model, but it's not the first frontier level model.
So there have been other models that sort of have that capacity and yeah, people are going
to want to do inference directly on the four or five because it's, you know, by our estimates,
it's going to be at 50% cheaper, I think, than the GPT four or to do that directly.
And so I think that that obviously makes a difference to a lot of people.
But the thing that I think is really new in the world with this is the, because it's
open weights, the ability to take the model.
And by the way, it was rumored that Meta was not going to release the weights for the 405
billion parameter model, but Mark Zuckerberg corrected them.
And it seems like he held true to his promise.
They did release it.
It is completely open source.
And I can truly say that completely open source and distill it down to whatever size
that you want to use it for synthetic data generation, to use it as a teacher model.
You know, so our vision for the future, it's not just, okay, it was never that there's
going to be one singular thing.
I think this is like open AI sort of as this vision that they're going to build kind of
one big AI, Anthropic does to Google does to it's never been our vision.
Our vision is that there should be lots of different models.
I think every startup out there, every enterprise governments, they all kind of want to have
their own custom models.
And yeah, when the closed ecosystem was so much better than open source, it was just
better to take the vanilla closed thing off the shelf, because even though you could
customize open source, there was still some gap between the performance that you could
get, but now we don't see that anymore.
So this is actually something that I believe in really strongly.
And if you've watched my videos as of the last few weeks and months, you've heard me
say it, I truly believe that small vertical narrow use case models
are going to be the future, especially, and again, something else I've talked about as
AI compute continues to get pushed towards edge devices.
The only way we're going to be able to have capable AI is by running small models, multiple
small models on a device like this.
And when we also have algorithmic innovations like route LLM and mixture of agents, all
of a sudden, these small models become so much better and know when to offload to these
giant kind of world knowledge models, if they have to.
And funny, that is the approach that Apple intelligence took, but they just took the
completely closed ecosystem approach, which is very Apple to do as open source basically
closes the gap.
I think you're just going to see this wide proliferation of models where people now have
the incentive to basically customize and build and train exactly the right size model for
what they're doing, train their data into it, they're going to have the tools to do it
because of a lot of the partner integrations that the companies like Amazon are doing with
AWS or Databricks or different folks like that, who are building these whole suites
of services for distilling and fine tuning open models.
So I think that that's going to be the thing that's new here.
And that's really exciting is how far can that get pushed?
And and that's a completely new capability in the world because there hasn't been an
open source or open weight model of kind of this sophistication that's ever been released
before.
Yeah.
And that's a really important point.
The battle for unique and diverse data is really going to be the front lines of artificial
intelligence.
That is why, as I mentioned in a recent previous video, open AI has been building partnerships
with numerous content companies like Time Magazine and so on.
And so if you're a company and you have this very unique, very proprietary data set, you can
now take these large frontier open source models and train them on your particular use case for
your business, whether you want to use it internally or resell it to your industry.
And I think that's a really interesting approach.
All right.
In this next section, Rowan asks Mark Zuckerberg about how they're going to teach the world
how to use these AI models and specifically about open source and its benefits.
So let's watch what he has to say.
Yeah.
So I'd say before a 3.1 hour approach, I mean, the reason that Meta fundamentally is
investing in this is we basically want to know that we have access to, to a leading
model, you know, because of some of our, our history of kind of how mobile worked and
things like that, we didn't want to be in a position where we had to rely on some competitor.
All right.
So he kind of revealed why he's employing this strategy.
During the mobile revolution, Facebook got caught flat footed.
They basically were completely platform dependent on Apple or Android.
And they even tried to make their own phone at a certain point, although it was a failed
project.
So he is obviously not wanting to make that same mistake again.
We built it for ourselves.
And before a 3.1, you know, we, we kind of had this instinct that if we made it open
source, there would be a community that would grow around it and that would actually extend
the capabilities and make it more valuable for everyone, including us.
Because at the end of the day, this isn't just a technology.
It's an ecosystem, right?
That, that, that you're developing.
So in order for this to end up being a useful thing for us, there also needs to be a broad
ecosystem.
One of the big changes that I think we see with llama 3.1 is instead of just building
it for ourselves and throwing it over the wall and letting developers use it, this time
we're really taking a much more proactive stance on building partnerships and making
sure that there's this whole ecosystem of companies that can do interesting things with
the model and conserve developers in ways that we're not going to.
Okay, really, what that translates into is they want control of the ecosystem.
They want to be able to define the standards.
They want to build up the ecosystem.
So there's obviously a financial motive for meta and it's not just purely out of the
goodness of their heart that they release this model for free, but that's okay.
Everybody can still win.
And quickly, I want to show Mark Zuckerberg talking about GROC, which is, as you know,
one of my favorite companies out there right now in the world of AI.
The time I think that there are also going to be folks like GROC, right, who are doing
really interesting work on really kind of ultra low latency inference.
And I'm really excited to get this in their hands.
And they're building something for launch that basically.
Okay, so obviously this was filmed a few days before launch, if not more.
And GROC on day one already has it available.
I haven't been able to use it because there's been so many people trying.
It basically says they're bandwidth limited.
But as soon as I can, I'm definitely going to try it out.
Next, Rowan asks Mark Zuckerberg what the implications are of open source AI.
And this has been a fierce debate amongst obviously close source companies like
open AI and open source companies like Meta AI, Mark Zuckerberg, Yann LeCun.
And what I really appreciate about the open source approach is that it hopefully puts
a stop to any regulatory capture that might be happening and likely is happening
from the likes of Google and open AI.
They want regulation.
They want the hurdle to start a new AI company, a new innovative frontier AI model
to be as high as possible because they're already on that side of the fence.
They don't want anybody else at their party.
My view is that open source is a really important ingredient to having a positive AI future.
And that there are all these awesome things that AI is going to bring in terms
of productivity gains and creativity enhancements for people.
And hopefully it'll help us with research and things like that.
But I think open source is an important part of how we make sure that this benefits
everyone and is accessible to everyone.
It isn't something that's just locked into a handful of big companies.
At the same time, I actually think that open source is going to end up being the
safer and more secure way to develop AI.
I know that there's sort of a debate today about is open source safe?
And I actually take the different position on it.
It's not only do I think it's safe.
I think it's safer than the alternative of closed development.
And yeah, so I'm going to cut him off for a second because I kind of already know
where he's going, something I've already talked about in previous videos.
And he actually talked about it a little bit earlier in this video.
Basically, when you open source something and everybody with diverse skills,
diverse perspectives and a much larger pool of talent can look and examine
every single line of code, every single piece of data, how it's behaving,
why it's doing certain things, you're going to harden the system.
Much more so than closed source systems.
Now, there's some examples where that's not the case.
There's some examples where that is the case, but I think generally speaking,
open source tends to be more secure than closed source systems.
If you agree, let me know in the comments.
I'm not sure if that's even a controversial statement or not.
You know, I sort of break it down into, you know, there are lots of different
kinds of harm, so you can't just talk about one type of thing.
But on this, I think that there's unintentional harms.
So the system goes off the rails in some way that people didn't intend.
And then there's intentional harms where you have like some bad actors
trying to use the system to do something bad when it comes to unintentional harms,
which I think, by the way, it's worth noting that like most of the sci-fi
scenarios that people worry about of AI just going rogue are kind of unintentional.
I actually think that open source should be safer on that because it's
it will have more scrutiny, they'll have more transparency.
And I think all the developers who use it with all the Lama Guard
and the safety tools that it comes with,
there's going to be so much scrutiny and testing and pressure on those
that my guess is that it will have kind of just like traditional open
source software, any kind of issues with it, I think will be ironed out
and fixed a lot quicker than with the closed models.
So I think you've got you've got that on kind of unintentional harm,
which is why I think most of the discussion around safety for open
source revolves around intentional harm. It's OK, it's open.
It's out there. How are you going to stop bad actors from doing it?
Doing bad things with it?
There, I think you basically want to probably divide the problem
into kind of smaller actors like an individual or
or some kind of smaller group that's trying to create some some some mayhem
and the larger actors who are more sophisticated and have huge amounts
of resources like big nation states.
I think it's kind of a different mix for the two of those.
This reminds me of something that Jan LeCun talked about in his interview
with Lex Friedman. I'm actually forgetting the name he called this,
but he essentially said that if everybody has open source frontier models
that are incredibly capable, as capable as closed source,
then it's basically a battle of AI versus AI.
If there's a bad actor and a good actor with AI, whoever has the better AI
is going to win. And if both sides have equal AI, or if they're just off
by, let's say, 5% in terms of capabilities, then it's pretty much null.
And one AI is going to protect the good actors from the bad actors.
AI. Now, the instance that we're not talking about,
which I actually don't think is possible is if bad actors with huge resources
suddenly get a massive jump in capabilities in AI
that nobody else even thought was possible.
So imagine all of a sudden a bad actors AI is 100% better than the good actors AI.
At that point, we'd probably be in trouble.
But as I said, I don't even believe that's possible just because of the iterative
nature of artificial intelligence innovation.
There just aren't these huge step functions in capability gain.
You know, for the smaller actors, my view on this is that, you know,
the way that we've, I think that having a balance of power on this is super important.
You know, what we've done in managing our social networks is we have all these
kind of bad actors who are trying to do kind of bad stuff on our networks.
And a lot of times they deploy AI systems to do that.
And the way that we stop them and identify them is by having more
sophisticated AI systems that have more compute to go find what they're doing.
So I think that this is actually pretty similar to the governments and law
enforcement essentially maintain order in society.
It's like, yeah, you have a bunch of rogue people who might be committing crimes.
But, you know, generally the police forces and the militaries are much
better funded, have more resources.
And I think that that's basically going to be true here.
As a matter of fact, I think what you want is for open source to be widely deployed,
which I think that there's sort of a risk if it's closed, that that's not the case.
But when it's open, you're going to have all these big institutions
that have a ton of resources that they can basically deploy these systems
in a way that I think will check bad actors.
Then you get to the question of basically, you know, folks like
China or like large, sophisticated actors.
And one of the questions that you sometimes hear debated is like, OK,
if you're open sourcing the really advanced models, how do you make it so
that that it doesn't get to to China or they're not going to use that against us?
And that's sometimes an argument that people have for, hey, you should lock down development.
But I think that that's sort of missing a few things.
One is that in order for this all to work, the US has to have an advantage
in the first place or the West.
And in kind of our advantage is basically open and decentralized innovation,
where it's not just a small number of big companies or labs at startups
and universities and individuals hacking on things who are in parts of companies.
And that's a big part of it.
And you don't want to shut that down.
And I think if you do, you increase the chance that we don't even lead in the first place.
But then I think you get to the the issue, which is, OK, China or not even China,
any government, you know, there are all the risks of kind of stealing the models
and an espionage, I mean, a lot of the models fit on, you know, a hard drive
that you can quickly put in your backpack or whatever.
And it's I just think we need to be realistic about how likely it is that we can secure
and not just not us, but like any of the tech companies can secure any of these
models long term against very sophisticated efforts to do that.
So if you remember my video about the situational awareness paper by Leopold
Aschenbrenner, he specifically calls out China, but let's just use any large state
actor, the chances of being able to protect a closed source model, the weights
indefinitely is essentially zero in my mind.
How many times have US companies been hacked specifically by China and their IP stolen?
And here's the thing, it only needs to happen once.
You only need to have one minor lapse in security and then you lose the model weights.
So with the likelihood of a private company like open AI getting hacked, having their
model weights stolen, then let's just assume state actors are going to have these AI models.
So let's just make sure everybody has them.
Let's make sure all of the good guys, quote unquote, good guys, quote unquote, bad guys,
they all have the same capabilities.
And thus we're back to the original statement of it's one AI versus another AI.
My own fear is that if we lock down development, we end up in a world where basically you have
a small number of companies, plus all the adversaries who can steal the model are the
only ones who have access.
But all the startups, all the universities, all the individual hackers are kind of just
left out and don't have the ability to do this.
So my own view is that a realistic aim that we should hope for is that we use open
source to basically develop the leading and most robust ecosystem in the world, in
that we have an expectation that our companies work closely with our government and allied
governments on national security so that way our governments can persistently just be
integrating the latest technology and have, you know, whatever it is, a six month advantage,
eight month advantage on our adversaries.
And I think that that's, you know, I don't know that that in this world, you get a 10
year permanent advantage, but I think a kind of perpetual lead actually will make us more
safe in one where we're leading, then the model that others are advocating, which is,
okay, you have a small number of closed labs, they lock down development, we probably risk
being in the lead at all, like probably the other governments are getting access to it.
It's that that's my view.
I actually think on both these things, spreading prosperity for more evenly around the world,
making it so that there can be more progress and on safety, I think we're basically just
going to find over time that open source leads.
Look, there are going to be issues, right?
It's like, well, to mitigate the issues.
We're going to test everything rigorously.
We do, we work with governments and all the stuff.
We'll continue doing that.
Um, but that's my view of kind of where the equilibrium, I think we'll settle out, given
what I know today.
So next, Mark Zuckerberg is going to start talking about economic possibilities with
the use of AI.
And this is something that I'm extremely curious and excited about.
I tend to be an optimist.
I can also see the pessimist point of view here and open AI just came out with a bunch of
research talking about UBI and economic effects of AI.
And I'm going to be reading and covering that in a subsequent video.
But for now, let's see what Mark Zuckerberg has to say about it.
There's a version of this, which AI will do no matter how it's developed.
Um, and then there's a version of this that I think benefits from open source specifically.
So I think that AI has more potential than any other single technology that's
being developed right now to increase productivity, accelerate the economy, um,
make it set kind of every person has the ability to be more creative and, and,
and produce more interesting things.
And I think that that's all going to be great.
I also think I hope that it'll help out with science and, um, medical research
and things like that.
There are a lot of folks today, though, who don't necessarily have access to the
ability to fine tune or build their own state of the art models.
So they're sort of limited to what these large labs do.
Um, and like I just said, I think, um, you know, one of the defining
aspects of our culture and innovation as a sort of a country or, or society is
like, it's not just big companies that do it, right?
There's all these startups and hackers and academics and people in university.
And I think you want to give all of those folks access to state of the art models
that they can build on top of, not just that they can run, which is what they have
today with, with the closed vendors, but that they can build on top of and tweak
and distill down to smaller models that they can run on their laptop or their
phone or whatever other device they're building.
And I think that that's just going to unlock a ton of progress.
There's also a version of this where there are, you can look at it by, you know,
nation too.
Um, you know, so it's not just that startups might not have the resources
or universities might not have the resources to go train their own, um,
they know, large scale foundation models now or in the future.
But, um, but there were a lot of countries that aren't going to have
the ability to do that because I mean, you know, pretty soon these things
are going to cost many billions of dollars to train.
And I think that having the ability for different countries and entrepreneurs
and different countries and businesses to use it to serve people better and just
do better work is going to be something that, that basically like lifts all boats
around the world and, um, which just has a massive kind of equalizing effect.
So I know that that's really positive.
Here, Rowan asked Mark about specifically in his letter, which I'll
cover in another video, but he directly called out Apple in their closed approach
and Rowan asked him to elaborate on it and what are his thoughts.
So let's listen.
I mean, my point in there is more, it's a little more philosophical on how
it's affected my own kind of approach towards things and, and psychologically
sort of affected how I think about building stuff.
Um, I actually don't know how they're going to approach AI.
Um, you know, they do some open development.
I do some closed development.
Um, you know, by the way, I think it's worth noting, like, I don't actually
consider myself to be an open source as Ellen.
I just think that in this case, um, I think that open models are going to be
the standard and I think that that's going to be good for the world, but we
do open development, we do close development.
So I get it, right?
And I'm not saying that Apple is necessarily going to be on the wrong place
on this for AI, but if you look back over the last 10 or 15 years, it has
been a formative experience for us is building our services on top of platforms
that are controlled by our competitors and for a number of different incentives.
Oh, I can just sense, I can just sense the anger here.
And I can tell he's being very diplomatic about the way he's saying all of this.
But I know he got burned and, and burned for years on the fact that he had to
build his platforms during the mobile revolution, which really took over everything.
He had to build Facebook and the rest of his app portfolio on top of his competitors.
And he doesn't want to make that mistake again.
That is also likely why they invested and he invested so much in the metaverse
because he really foresaw the VR revolution as being the next computing platform.
And so he wanted to be way ahead of that.
And he was.
And although it didn't come to fruition either as quickly or at all, the way he
thought it would, AI seemingly is heading in that same direction.
And he wants to be the platform.
Meta wants to be the platform.
They absolutely, from my perspective, apply different rules to kind of limit what we can do.
And, and yeah, they have all these taxes.
And, you know, at some point we did, we've done some analysis that we think we'd be
way more profitable if it weren't for some of these arbitrary rules.
And I think a lot of other businesses would be too.
But, you know, honestly, the money part, I think it's annoying.
But for me, it's not the biggest thing.
It's, I think it's a little bit soul crushing when you go build features that are what you
believe is good for your community.
And then you're told that you can't ship them because some company wants to put you in a box
so that they can better compete with you.
Don't mess with the Zuck.
He thinks in 4D chess.
My concern for AI at this point isn't actually Apple.
It's more the other companies and how that would evolve.
And I think to some degree, it's not even that.
I'm not even saying that they're like bad people.
It's, it's, I think that there's just a physics and incentive structure to the system where,
you know, if you build a closed system, then eventually there are all these forces on you
that sort of kind of push you to, to kind of clamp down on things.
And I think that it will be a healthier ecosystem if it's developed more like the web,
but more capable.
And I think that, you know, because of how mobile developed where the closed model won,
right?
And it's like Apple, I think, has really reaped most of the benefits in terms of,
you know, they, there might be more Android phones out there, but like Apple gets like
almost all the profits of, for mobile phones.
I think there's a bit of recency bias because these are, these are long cycles.
Right? I mean, the iPhone, I think it came out in 2007, right?
So we're almost 20 years into this thing.
It's a long cycle, but it's easy to forget the fact that the closed model doesn't always win.
If you go back to PCs, now I know a lot of people have, especially if you're using the
Linux analogy, people don't necessarily consider windows to be maximally open, but compared to
the, the Apple approach of kind of coupling your operating system with, with the device,
the windows approach was a more open ecosystem and it won.
And part of my hope for the next generation of platforms, which includes both AI and the
work that we're doing and augmented in virtual reality is to, you know, meta wants to be on the
side of building the open ecosystems.
And it's not just that we want to build something that's an alternative to the closed
ecosystem. I want to restore the industry to the state where the open ecosystem is actually
the one that is leading.
As I said earlier, his motivations for doing this are clearly because he got burned.
That is why he is trying to change the way that this ecosystem is going to be developed
and play out in the long run.
And I kind of love it. I love this approach.
This is also why Elon Musk decided to open source grok because he was bitter at open AI
being closed AI, taking a bunch of his money and then eventually converting into a for-profit
company. And so there is nothing like a burned entrepreneur with a chip on their shoulder
and a little bit of spite to really drive them to innovate.
And let me tell you, I am here for it. I love it.
All right. So Rowan now asks Mark Zuckerberg about Lama 4.
And I'm sure he's already planning Lama 4, but he just released Lama 3.5.
He just released the 405B model.
And so I think all of their efforts, probably for the foreseeable future,
are going to be on iterating and innovating on Lama 3, Lama 3.1, Lama 3.2.
And they'll probably have Lama 4 cooking in the background,
but it's going to be a while before we see that.
And I'm going to guess that's probably going to come out a little bit after GPT-5 comes out.
Oh man. I mean, it's, you know, we're just doing 3.1 for Lama now.
I think it might be a little early to talk about Lama 4, but we've got the compute cluster set up.
All right. I think that was hilarious.
He's like, oh, it's probably a little bit too early to be thinking about Lama 4,
but we have all the compute necessary to do it. I absolutely love this new version of Zuck.
The data setup, we kind of have a sense of what the architecture is going to be,
and have run a bunch of research experiments to kind of max that out.
So I do think that Lama 4 is going to be another big leap on top of Lama 3.
I think we have a bunch more progress that we can make.
I mean, this is the first dot release for Lama.
There's more that I'd like to do, including launching the multimodal models, which we...
Yes. I can't wait for that. That is the one biggest missing capability between Lama 3,
4.0.5.B, and GPT-4.0. GPT-4.0 can take many different file formats, interpret them,
including images, and really that one feature I use all the time.
Unfortunately, we have not had a Lama model that is really truly multimodal,
and there have been a few fine-tuned versions that allow for multimodality,
but they don't work super well if I'm being honest. You've seen me test them on this channel,
so I can't wait for a native multimodal Lama 3.1.
We kind of had an unfortunate setback on that,
but I think we're going to be launching them probably everywhere outside of the EU.
For those who are wondering what he's talking about, just recently it was reported that they
are not going to be releasing multimodal AI in the EU strictly because of their regulations,
and that is the setback that he's talking about. I can't wait till they release it here in the US
and other countries that allow it, but not going to be in the EU, and that is one reason why they
need to ease up on the regulation in the EU, and hopefully we don't over-regulate in the US,
and from where I'm from, California. Yeah, probably a little early to talk about Lama 4,
but it is going to be awesome, and it has been one of the interesting things in running the
company is basically planning out the compute clusters and data trajectories for not just
Lama 4, but the next probably four or five versions of Lama, because these are long lead
time investments to build out these data centers and the power around them and the chip architectures
and the networking architectures, so all this stuff. So yeah, I realize that's a bit of a non-answer
for now other than just some general excitement, but I don't know, I think Lama 3 deserves at
least a week of kind of just processing what we've put out there before we get into talking
about the future. All right, I'm going to put this out into the world. I want to interview
Mark Zuckerberg, and if I'm the one who gets to interview him or one of the ones who gets to
interview him as part of the Lama 4 launch, I would love that. So if anybody from META is watching
this, please consider me. I would love to do that. All right, next, he's going to be talking about AGI
and agents, something that I've seen little bits of in the Lama 3.1 launch. They are defining their
own agent architecture, it seems, or its own language. I still haven't dug into it too deeply
yet, but I plan to, but let's see what Mark has to say about AGI and specifically agents.
I'm happy to talk about it both from a technical perspective and a product perspective, but since
we've mostly talked about the models so far, maybe I'll start with the products. So our vision
is that there should be a lot of different AIs out there in AI services, not just kind of one
singular AI. And that really informs the open source approach. It's, you know, it also informs
the product roadmap. So yeah, we have META AI. META AI is doing quite well. My goal was for it
to be the most used AI assistant in the world by the end of the year. I think we're well on track
for that. We'll probably hit it, hit that milestone, you know, a few months before the end of the year.
That's a huge statement, if true. That means that META AI has more usage than chat GPT,
which would be surprising to me because anybody who knows about AI knows about chat GPT, but they
don't necessarily know about Anthropics Clawd or other models. And many people have never even heard
of Lama before. Obviously, META has the billions of built-in user base. So it's exciting to see
that. But he's specifically talking about the META.AI product. And I believe when he's saying META AI,
it's not just META.AI, which is kind of the chat GPT competitor, but it is also each of the
implementations of META AI in each of their products, WhatsApp, Instagram, Facebook, etc.
A lot of what we're focused on is giving every creator and every small business the ability to
create AI agents for themselves, making it so that every person on our platforms can create their own
AI agents that they want to interact with. And if you think about it, these are just
huge spaces, right? So there are hundreds of millions of small businesses in the world.
And one of the things I think is really important is basically making it
so with a relatively small amount of work, a business can basically, you know, few taps,
stand up an AI agent for themselves that can do customer support, sales, communicate with all
their people, all their customers. That's going to be hundreds of millions, maybe billions of
what kind of small business agents. Similar deal for creators. There are more than,
there's more than 200 million people on our platforms who consider themselves creators,
who basically use our platform in a way that is primarily for, you know, building a community,
you know, putting out content feel like it's kind of like a part of their job is doing that.
And they all have this basic issue, which is that there aren't enough hours in the day to engage
with their community as much as they'd like. And likewise, I think that their communities would
generally want more of their time, but, but again, not enough hours in the day. So I just think it's
there's going to be a huge unlock where basically every creator can pull in all their information
from social media, can train these systems to reflect their values and their business objectives
and what they're trying to do. And then people can interact with that. It'll be almost like this,
almost artistic artifact that creators create that people can kind of interact with in different
ways. And then, and that's not even getting into all the different ways that I think people are
going to be able to create, you know, different AI agents for themselves to do different things.
So I think we're going to live in a world where there are going to be hundreds of millions and
billions of different AI agents, eventually probably more AI agents than there are people in
the world, and that people are just going to interact with them in all these different ways.
So that's part of, you know, that's the product vision. Obviously, there's a lot of business
opportunity in that. That's where we want to go make money. So we don't want to, we're not going
to make money from selling access to the model itself. Because again, we're not a public cloud
company. We will make money by building the best products. An important ingredient to the best
products is building, is having the best models. So this is echoing exactly what Jan Lacoon told
Lex Freeman a few months ago, where he said, they're not going to make money by developing and
deploying open source models, but as being the company who can define the standards and thus
make the best products around that AI, that's going to be meta. And that's how they're going
to make money. All right, in this last section, he talks about fear of AI, why people worry about
AI, why they should, why they shouldn't. So let's take a look. I mean, financially, one thing that
I'm quite aware of is the internet had a big bubble burst before it succeeded. And it's all
the people who were very long on the internet were eventually right. But sometimes things take
a little longer to develop than you think. And you just need to have the commitment to see that
through. And that's something that I'm aware of. Because yeah, I mean, I'm really excited about,
you know, all the unlocks that we're going to get from llama three, and then llama four,
and then llama five, and I think that's going to translate into better products. But
realistically, it's hard to know in advance when something is good enough that you're going to
have a product that billions of people use. And then when it's ready to kind of be a large business.
And I mean, look, we're all spending, you know, a lot of capital and on basically training these
models. So I think that people are going to be probably losing money for quite a while.
Yeah. And that's what I've been hearing generally from the industry. Every single big tech company,
even a lot of VC dollars going into startups, they're all spending their money buying the silicon.
They are mostly buying it from Nvidia. That is why Nvidia stock price has skyrocketed over the last
couple of years. However, all of that initial investment has not necessarily translated into
revenue. In fact, I think the number is only like 30 billion in revenue, even though there's been a
trillion dollars in spend. So that's not sustainable in the long term. There is likely a mini bubble
that is going to burst eventually. But obviously I'm bullish on AI. And that's what I'm dedicating
all of my time to right now. So I believe in it in the long run. And as he said,
people who were early on the web and long on the web eventually were right. Now there was a bubble
in between that we do have to think about and consider and worry about when it comes to AI.
The other part of this that I think you are more getting at is people's concern about what it means
for their livelihoods. And on that, this is one of the reasons why I think the open source approach,
the approach of lots of different models out there that are kind of personalized and customized to
every business and every creator and every person. I think that's important because if this develops
in a way where it's just a small number of companies that build the products and benefit
and people use the products and maybe they like talking to an AI assistant and that's valuable
for them. But if this doesn't in some way help lift all boats, then I think you end up eventually
getting a backlash. And part of what I've spent some time thinking about after just looking at how
the kind of Web 2.0 stuff developed is in the next generation of technologies around AI,
around AR and VR. How do we create not just a thriving set of products and economic productivity
gains, but how do we have a better and more sustainable political economy around it where
there's just way more people who feel like they're kind of bought in or benefiting from this
in support of the system? And I thought we did that reasonably well with social media,
but just looking at some of the feedback and some of the response from the world,
I think that it's going to be important to do that even better with AI and some of the new
technologies in order to mitigate some of the concerns that people are going to have about
what this is going to mean for their livelihoods and jobs and their lives.
So we're going to end it there. I think that is a great place to end it. Something for us to think
about over the coming weeks, months and years, incredibly important stuff. I'm so excited to see
all the different innovations that come from Lama 3.1, whether we're talking about an extremely
capable model that can fit on your phone or on your laptop, or the massive 405B model that is
as capable as any closed source frontier model. If you enjoyed this video, please consider giving
a like and subscribe, and I'll see you in the next one.
