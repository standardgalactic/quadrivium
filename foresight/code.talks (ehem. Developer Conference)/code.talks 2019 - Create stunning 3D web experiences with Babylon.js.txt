Hi, everyone. I'm very glad to be here, even though I am fighting against a jet lag. There
is none our difference between here and Seattle. So back with me. I'm going to try to not sleep
on stage. Yeah, we're going to I'm going to present Babylon.js. It's an engine I created
six years ago. And it's an engine that I am pretty proud of because now it's very it's
used in a lot of important places. For instance, that's PowerPoint. But this little guy here
is a 3D object animated by Babylon.js inside PowerPoint. And actually, at Microsoft, every
time you're going to see 3D, it's probably a 99% sure that it's actually based on Babylon.js.
It's something that I'm going to present right now. It's an open source framework. It's
entirely free. It's based on Apache 2 or do the heck you want with the code. There is
no license, no nothing. It's brand new at Microsoft. We are using our own technology
here, but this technology is entirely free for you to use in any place you want. It's
based on any in a lot of web open standard and web open frameworks like WebGL 1 and 2,
WebGPU. So WebGPU, are you aware of what WebGPU is? Who knows? Okay, quite a few. It's
the evolution of WebGL actually. It's metal slash Vulkan slash DirectX 12 for the web.
It's a new technology that we are working on with Apple and Google to support. The interesting
point here of using Babylon.js is that if you want to use 3D today, you do not have to worry
about that. We will take care of all the underlying frameworks like WebGL 1, 2, or WebGPU. We also
support WebXR. I'm going to do a quick demo later. It's a full-fledged game engine and rendering
engine. So we support physics and VR particles. I don't like this image, but that's the best I
can have. It's kind of the unity for the web, if I may. We're going to provide you tools to create
3D on the web without the burden of understanding shaders and math and stuff like that. We also
support physically-based rendering. It's an advanced technique created by Disney starting with, I
don't know, Untangle, the name of the movie. I am not sure it's the right translation anyway. The
lady with the long hairs, they created PBR for this cartoon. And this PBR, and thanks to the power of
our computer now, can be now rendered in real-time on the web. I'm going to get back to that later
as well. We have principles, and I'm very glad to have my talk after John's one because we have
exactly the same principle. I like bug first. We create tools before the engine and stuff like
that. And we are also backward compatible. That's something that just pissed me off a lot when I
have to update to a new version of a framework and I have to rewrite everything. That's something I
do not want for Babylon. So if you're using Babylon.js, you will be able to run it up until the next
version without having to change anything on your code. We do not break backward compatibility. And
we are also supporting GLTF. Who is aware of what GLTF is? Okay. So GLTF stands for Graphic Library
Transport Format, and that's the JPEG of 3D. You think about JPEG. If I give you a JPEG image, you
will be able to display it on your computer, right? Because everyone understands JPEG or PNG. For
3D objects, like the file format itself, it was a mess up until now because there were like 10,000
different file formats, all in code printable, obviously, and all proprietary. So we sit down with
the Kronos group, the group who is standardizing WebGL, and we define all together, and by all, I
mean Google, Facebook, Microsoft, NVIDIA, et cetera, et cetera, we define a file format. And this
file format is GLTF here. So if you want to render 3D objects like the dinosaur I was rendering
before, it's a GLTF file format. And so by supporting this file format, we ensure that your
object will be displayed and compatible. It's an open source project. Since the very beginning, it was
started as an open source project. It's still an open source project. We have around like 100,000
posts on the forum. It's a very active forum. Most of the users, when they come to us, the number one
reason they come to use Babylon.js is because of the forum. We have a very lovely community. It's
very helpful. There is no shame. It's definitely a place where you can ask any question and you will
get a response in a matter of a few days. We also have a pretty large number of active supporters,
like people contributing to the forum and to the engine itself. So it's used in a very, it's funny
because I started it six years ago, and I was the only developer, and it was only for me. And now
it's used across the web. Adobe is using it for their product. Being Microsoft apps, obviously, I
mentioned SharePoint, PowerPoint, et cetera, but it's also used by Dolby, by Minecraft. If you go to
Minecraft.net, classic.minecraft.net, you're going to play the Minecraft game, and it's using
Babylon.js to do the rendering, et cetera. We work with a lot of small, high, very large companies,
and my favorites are probably the enthusiasts, like students of people that just do that because
they want to learn how to create a game or to create 3D. And that's why we created the engine. And so
also, I want to underline and second what John said just before, we created the engine, but we also
created a lot of tools. And I'm going to get back and demonstrate these tools. Just name-dropping here,
I'm going to get back to that later. The goal for me is to mention that it's not just an engine,
it's actually engine is a small portion of it. The tools that let you create what you want to
create in 3D are really the important point here. Okay. So I have a quick video because I wanted to
capture what the community was creating with Babylon.js. So instead of going through a demo
manually, I created a quick video for you to see.
Right. It was an example of in real time,
in real time, obviously, running on any computer
what can be done with the framework itself.
So instead of spending too much time just talking,
I would like to show you in action
what you can do with Babylon.js.
I'm going to start with a first presentation of one
of the tools that I have.
Nope, it's not here.
The Playground.
So Babylon.js-playground.com is a place
where you can go to learn the engine.
So I spend a lot of time writing documentation,
and that's a pity because no one's read it, right?
You don't read documentation.
No one's read them.
So I decided to take the problem the other way,
like, how do I learn?
I learned by trying, right?
And so that's why we created the Babylon Playground.
Here, you have on the left a full-fledged editor,
and on the right, you have the real-time rendering of what
you just typed on the left.
The editor comes with IntelliSense.
So if you type here, you can get help while you type.
So instead of reading documentation,
again, you can just experiment, OK?
And I'm going to just show you what
can be done in a matter of a few seconds here.
So here, I have a scene that I created.
I create a camera, which is the point of view
that I can manipulate with touch or with my mouse.
I set the target of my camera, and I attach it to the events.
By calling Attach Control, I attach to the mouse event,
the pointer event, and stuff like that.
So I can play with my finger here or just with my mouse
if I want to, or the keyboard.
That's all coming from this line.
Then I create a light, like in real world, you have a light.
I set the intensity of that light and the sphere.
So if I run that, I just have my sphere
in the center of my screen, OK?
As a user, now what you can do is to experiment.
And we use the playground for experimentation,
but also for bug fixing.
When a user comes to us and say, hey, I have a bug,
most of the time, we ask them to reproduce the bug here,
because it's then easier to discuss.
So I'm going to create, actually, a material.
The material here will be a PBR, sorry,
Babylon, dot PBR Metallic Roughness Material.
It's a specific kind of material that simulates metal, OK?
I'm going to give it a name.
And as you can see, there is a while I type help
on the parameters.
So for instance, I want the name here, like foo,
and the scene where I want to have my material.
Then I set my sphere.material to that material, OK?
And I'm going to just quickly set some values, like metallic.
It will be fully metallic between 0 and 1.
And is that a little bit too small, maybe, right?
Let me change the font size to something bigger.
OK, sorry about that.
And I want also to set my material
to be the roughness of it, like brushed metal, if you prefer,
will be 0.5, again, between 0 and 1.
If I run it, you have a sense of something change,
like it's a bit metallic, but the power of a metal,
like in your car, is because you see the reflection
of the environment, right?
A car by itself with no reflection looks rough.
So what I'm going to do here, I'm
going to just ask the scene to create a default environment
for me.
And by doing that, now here, I have a sphere, which
is like brushed metal, OK?
So I can play with the parameters,
but I told you it's all about tools.
So here I have the playground, but we also
have a second tool that I would like to show you,
which is the inspector.
Here I can invoke the inspector by calling
deburglayer.show, show.
And if I do that, zoop, I'm going to have an additional UI
that will be on top of my scene here,
where I can see the tree view.
So I have my glide, my camera, my sphere,
and the background that was generated
by the created environment.
And I can take my material here, and I
have all the properties of that material.
And for instance, I can play with the levels here
and change the opacity or the roughness.
So fully metallic, fully rough, OK?
Let me just get closer.
So that's the Chinese theater in Los Angeles.
And you can play with the parameter here.
Also, we introduce a lot of options that you can change,
like I want to render in wireframe and stuff like that.
You can play with it here, OK?
That's the inspector.
The inspector is extremely useful to debug or just
develop your scene.
So you can, visually, instead of just typing the code
in the playground or in your application,
you can just visually debug the scene itself.
Right.
Another tool I wanted to show you is the documentation itself.
Yes, I know.
People won't go there, but still, I
would like to show them the documentation for one reason.
Here, we have a regular documentation
with code practice, example, regular documentation
you should be looking for.
But we also have the playground here.
And the playground is actually a tool
that's going to search through all the examples that were created
in the playground here.
Because in the playground, if I hit Save,
it will generate, for me, a unique URL
that I can share with my friend with this code running, OK?
And that is stored in our database.
And if I want to learn something,
I could just search for the documentation
or I could just search for examples showing me
how to do something, like I want to do shadows.
And I can search for shadows inside our database.
And here, you're going to see, like, I just lost my mouse, OK?
Thank you.
I can find any example here where people just
do something with shadows.
And I can click on the Playground button here.
It's completely random.
I have no idea what's inside this playground.
Hopefully, it's not something stupid.
OK, there is shadows.
Cool.
Someone was doing that with shadows, OK?
And so I can look the code here and say, OK,
what did you do with this code?
And maybe that's going to help me learn or understand
how the shadows works.
Right.
Among new features that are going to be available soon,
there is the Node Material Editor.
I created here a material, but this material is actually
me setting some parameters to an existing material.
We have a couple of materials.
We have what we call the standard material, which
is the fastest and the simpler one.
And we have the pretty advanced physically based
renderer, which is used here, the PBR.
But if you want to do something different,
you have to use what we call the shader material.
The shader material is up to you to code using shader
languages, your own material, OK?
That's a friction point, definitely.
A lot of people say, I would love to create my own material,
but I don't want to learn how to create shaders.
So we introduce with the very new version here
the Node Material Editor.
The Node Material Editor is a way for you
to create your material.
So who is aware of what a shader is?
Quite a few, OK.
A shader is made actually of a C-like language
that's going to explain to the GPU how
to create your own rendering, OK, here.
Here I have a pretty simple one, and I will just
focus on the second part here.
A shader is made of a vertex shader and a fragment shader.
The vertex shader explains how the geometry is drawn
on the screen, and the fragment shader
explains how to compute the color.
And here my color is just, I want
to set a color to the output, OK?
This tool will let me actually create my own shader
without having to develop them.
For instance, here I'm going to open and look for the light.
I want to add lightning support.
Here my object is just flat, just gray, OK?
To support lightning, I need to add light support here.
And the light supports here will expect
me to provide a few parameters that you
can see on the left here.
I'm going to just quickly connect them.
So the world position, which is the position of my mesh
in the world, and the world normal, which is the normal,
is a perpendicular vector defining the surface
of every object, OK?
If I just plug them here and do that, then boom,
I have support for light.
A shader was developed for me by the system.
I can export the shader here.
So instead of coding the shader, which is quite big,
if you look at it, all of that is
required to do a lightning shader.
You just have to wire some stuff, right?
And that can go even better than that.
Instead of having just plain color,
I want to have a texture.
So think about your game, you have your character,
and you want to have lightning, OK, done.
And I want also to have a texture, OK?
So let me just load the texture here.
The texture will require me to give it a texture, perfect,
like a crate.
And what I want to do is actually take the light color,
the texture color, merge them.
And to merge them, I will remove this link here.
Just multiply them, boom, taking the light output,
multiply it by the texture output,
plug that into the output here, and boom,
I have a crate with light.
Isn't that cool?
Again, you can save your wonderful shader,
and it will generate for you a unique URL here.
And let me just fast forward to a complicated shader
that I created for you.
This one is pretty advanced.
It's not that good looking, but it's just me as a developer
trying to play the designer.
So I have a shader, and you can see here,
there is what we call bump or normal.
You feel like there is not a smooth surface.
We feel like there is something defining a bump here,
and actually just coming from a texture.
And also at some places here, there are reflections.
So it's a complex shader because the reflection is
defined by a second texture here.
We are using reflection texture to do the reflection here.
We have a perturbed normal object
that will change the normal.
And by the way, Doom 3, created by John Carmich, by the way,
introduced this notion of bump.
Bump is using a texture to simulate the volume.
Anyway, we don't care.
Here, it's just that I want to use that code.
So the shader here will generate for me
a code, like literal code that I can save here.
I'm going to open the file.
And this code is regular TypeScript code
that you can use directly in your own environment.
So let me remove all of that.
Dump here.
What was generated for me by the node generator?
So the node generator, it's actually a node model
where you create a node material, and then you have blocks,
transform block, whatever block, texture block, et cetera.
You connect all of them, like you connect the output
with the input.
So this code is just literally what I did visually.
And then it gives you a node material object
that you can plug with your sphere here.
That material is equal to node material object.
Let me close this guy here, close that, run that again,
and boom.
In my code, I have my wonderful reflection bump,
whatever scene.
Yes, it's ugly, but it's about technical and development, right?
It's not the designer track.
All right, so all of that, it's pretty cool.
I can save it again, so I can save that.
And it will generate for me a new version of my unique URL
here soon.
It's a big one because we dumped the entire texture.
So we just need to wait for the server
to come back without an error, hopefully.
In the meantime, oh yeah, it's fine, it's on.
OK, in the meantime here, let me show you a third tool.
So Babylon.js is developed to be easy to use.
You do not have to understand shader, math, whatever.
You just drop object.
You create a light, a scene, a camera, an object.
You load the GLTF file, and you're done.
But if you want to, there is no problem for you
to just look under the hood and see how it works.
And for that, we have a third object,
which is used by even our competitors.
The name of this object is a browser extension.
The name is Spector.js.
Spector.js is a tool that will let me inspect WebGL,
like a profiler for WebGL.
So at the first thought, you could
think that it should be a tool developed by the browser vendor.
But unfortunately, the browser vendor
are not investing a lot into WebGL.
So we did it.
So yeah, when I click here, I have a record button.
And the record button will just analyze the current frame
and generate for me here a simple view of the orders that
were sent directly to WebGL.
So you can see here directly the bind, vertex array,
the viewport, all this command, our WebGL command.
And every time you can see, here I am clearing the screen.
And here I am using this shader that I can edit live here
to send the data.
So you can see precisely what's happening in your code.
And you can even edit the code here.
And it will dynamically change the rendering.
So this one is pretty advanced.
Not a lot of people use it.
But you should know that from the very beginning up to the end,
like directly to WebGL, you have the control.
All right.
Then let me get back to my other demo.
So that's a new feature that we are adding
with the upcoming release for one.
And this one is one that I love.
I am part of the W3C and Kronos working groups.
And what I try to do with JavaScript
is to make it equivalent to what you can do with native.
And one of the main problem of JavaScript
is that it's running on one unique thread.
There is a notion of web workers.
But web workers are like process.
To communicate between the main thread and the web worker,
you have to send string or share just a ray of memory.
We recently had a victory by having the validation
of the off-screen canvas here.
And let me show you the code.
It's going to be even easier to understand.
If I look at my code, which is here,
trying to make it bigger enough for you guys to see it.
Can I zoom here?
Yes.
So I actually have here two scripts.
If I find the off-screen canvas API in the Windows object,
I will get a canvas.
So there is two canvases, one on the left, one on the right.
The one on the left is just initialized by Babylon.js.
So here you can see.
I create the canvas.
I create my engine, my scene.
I say, execute the code, render the scene.
Done.
And so it just load this object and rotate it.
It's done on the main UI.
The second one, it's exactly the same thing,
but using not a canvas, but an off-screen canvas.
And so when there is off-screen canvas support
on your browser, so far only Chromium-based browser,
meaning Edge, Opera, and Chrome, then
you can call a new API called Transfer Control to Offscreen,
meaning that I will let a second thread control the canvas
and render to it.
And that's utterly cool.
Why?
Because now here it's a worker that runs this one,
meaning that if I slow things down when
I'm going to click on this button,
I will do something stupid like computing this random scene
of course 10 million times, just to simulate
that you are doing something easy on the main thread.
And we do that, for instance, when
you are on SharePoint or on PowerPoint,
let's say PowerPoint, when you display the current slide,
PowerPoint is using the main thread
to prepare the next slide.
So the main thread, the main UI, is already pretty
easily occupied to do something.
So by using off-screen canvas, we
can have stuff that definitely are slowing down
the main thread, but still, because a second thread is
running and doing all your 3D rendering,
the experience for the user is pretty good.
Before, it was only that.
And now, we have access to the worker render.
Yes, I know.
I'm excited, but for a good reason.
Other stuff we are working on, I wanted to show you,
like, GLTF support.
Here, I have my halion head.
And if you look at my code, loading GLTF files,
it's just one line of code here.
Sorry, I forgot to zoom it again.
And we have options to load it once and then duplicate it.
If you are familiar with Unity, I just
can't remember now the name of that feature,
but you can load an object, an asset,
and then introduce it multiple times in your scene.
They are replicated, and it's a clone.
So it's a smart clone.
The geometry and all the shader are reused.
So here, the entire code to run these three guys
with, just for the sake of it, skeletal animation,
meaning that the head is moving with the neck.
And also, there is morph target.
So the halion is smiling and closing the move.
All of that is loaded from the GLTF and then duplicated.
And it's what?
It's 20 line of code.
This one, we don't care.
Let's go.
Next one, WebXR.
So this demo, you know it?
Yes.
We are in Hill Valley about to go back in time.
And it's running in the browser.
Yes, I know.
That's very cool.
I like that.
And there is a little button here.
I don't have a headset connected.
So when I'm going to click on this button,
Babylon.js will automatically consider
that you want to use some cardboard stuff,
like running on your phone and setting that in a cardboard.
It will switch to cardboard mode,
just to give you the experience here.
So if you have Oculus Quest, a Oculus VR, a Microsoft Mixed
Reality headset, thanks to WebXR, we just click on this button
and we will take care of everything for you.
And it's literally one line of code.
There is one line of code to switch.
We have an object named the VR Experience Helper.
You just need to instantiate it, and it will automatically
detect everything for you, provide the button.
And the scene that was not VR before, then become a VR scene.
Up to a point where you can, I need to reload.
Sadly, it should be fine.
We also support collision.
I mentioned that.
Here, it's a kind of a doom in a museum.
And I walk like in a game, meaning
that I can't go through the wall, but I can go upstairs
by just walking like in doom or quake, exactly the same
the way I play it with my keyboard and my mouse.
And that's running in your browser, obviously.
And at some point, you want to switch into VR.
Just click the button, and then you
can teleport with the controller.
Right.
Last but not least, I wanted also to mention this guy.
You saw the video.
That's physics, real-time physics using WebAssembly.
Here, you have a complicated mesh, this marble tower.
And we have a code here on the left that just drops
marbles at the top of the tower.
And then we let the physics engine deal with that.
And to just drop a marble, let me show you.
Where is that?
When we call create marble here,
let me zoom again.
The only thing you have to do is to say, OK,
my marble has a physics and post-or.
So there is an imposter representing in the physics
engine my marble here.
And it's going to be a sphere with a mass of two
and a friction of whatever.
And just with that, you let the system drop,
and it will control for you the entire emulation up
to a point where we have a complicated scene here
with this object, this scale.
Also, when they reach this point,
I should have a smaller window.
Here, they go into the wheel.
And that's also a physics engine just
applying a real-time constraint on it.
Right.
Let me get back to my slide.
So you should try it.
Everything is entirely free.
There is no hidden line or whatever.
You have all the links here, BabylonJS.com,
doc.babillon, et cetera, the forum, the playground, enemy,
the dot-material editor if you want to play with shaders.
That's it.
Right on time.
[? Applause ?]
Super cool, right?
OK.
Thanks for the talk.
My pleasure.
And we have some questions.
So what's the advantage of BabylonJS over 3JS?
What's the advantage?
First, we are a team of 10 people paid by Microsoft
to maintain it.
We have a 24-hour bug turned around.
So you declare a bug.
It's fixed in less than 24 hours.
We do not have backward compatibility issues,
like I know 3JS for that.
And we have tools.
3JS is a good tool.
I don't want to say it's a bad tool.
We just have a different philosophy.
BabylonJS is more aimed for professional products
in the sense that there is support.
And there is this turnaround for the bugs.
Like, we fix bugs very, very fast.
Like, definitely, when I saw John Romero mentioning
that you should fix bugs first, that's exactly us.
We stop everything we are working on to just fix bugs.
We do not have bugs.
And we have a link on our GitHub.
If you go to the GitHub, there is a mention.
The average time to fix a bug on our repo.
And so far, it's less than 24 hours.
I guess it's 20 hours.
OK.
Just from my side, I've used 3JS before.
And it usually took me quite a few hours
to get started with any project.
And with BabylonJS, I started using it.
And maybe because I came from 3JS,
and the basics are almost the same.
But I developed something like a VR, just a shooter,
where you can shoot balls just into empty space
or something within one hour and headed
to running on my Oculus Quest in the browser,
which was super cool.
So I think just getting started this way easier,
at least for me it was.
That's why we have a documentation.
No, I'm kidding.
No one's here about documentation.
What's in it?
What's in for it for Microsoft?
You mean why the reason of Microsoft to support the product?
I guess, yes.
I created BabylonJS on my spare time.
And Microsoft was interested to use it.
So we use it in SharePoint, Dynamics, and other products.
We have 12 products in Microsoft using it.
And I was also working for Microsoft.
It was not correlated at the beginning.
And they asked me if I wanted to keep working on BabylonJS.
And I asked them, I will provide you support
for all the 12 products that you have.
But as a compensation, you give me a team,
and we keep it open source, and people can use it.
So it was a win-win situation where Microsoft
get a fully fledged team supporting the product.
Whereas I wanted it to be open and for everyone.
So it was a win-win situation.
I have a question.
So you told me earlier that you developed another game engine
before you came to Microsoft.
Can you tell us about that a little bit?
And actually, I was almost emotional when I saw John Romero
because I was a big fan of him and John Carmack.
And I created my own engine when I was 17.
It was a C using an engine developed with C on DOS,
using Whatcom.
And I imported it back to DirectX.
And then I joined Microsoft.
And so I stopped.
And I sold the company I created because it
was a 3D engine for architecture.
And I sold my company, I moved to Microsoft.
And when I was a Microsoft, I was like, oh my gosh,
I still want to do 3D, right?
So at that specific time, six years ago, we shipped IE10.
And IE10 came with the very first version of WebGL
for Microsoft.
It was here since ages for Chrome.
But Microsoft entered a 3D game on the browser
like six years ago.
And so I was like, OK, I want to do 3D stuff.
There is this WebGL support now everywhere, thanks to IE.
OK, let's create a port of my old engine, which
was now BabillionGS.
That's really cool.
I was 17.
OK, I have another fun question at the end.
How do you pass data between other JS code and the 3D
application?
Are there any restrictions?
So your 3D application will be JavaScript as well.
So there is no restriction at all.
Like literally, BabillionGS is like jQuery or any other framework
or React or whatever.
You're going to use it the same way.
We have ES6 version of it and ES5,
depending on if you want to use it with module or without module.
And there is no restriction.
Like literally, all the application using BabillionGS
just communicate through JavaScript.
OK, there is one on performance.
What about performance and compatibility with mobile
devices?
Another good reason to use BabillionGS.
One of our motto is to make sure that it works everywhere.
So we have a full list of devices that we test on.
And I would say like 20% of BabillionGS core code
is about compatibility.
So we know that on specific version of iOS or Safari
of IE or Firefox or whatever, we have hack.
Because WebGL is a spec.
And human implementing a spec, you know it works, right?
So everyone understands things a little bit differently.
So we make sure that it works everywhere.
And then we have thousands of countermeasures
for performance.
So we support WebGL 2 by default.
If you don't have WebGL 2, we have a fallback for WebGL 1.
If you are supporting WebGL 1 with extension,
we're going to use the extension for you.
So it's transparent in a sense that we try to reach out
the best performance.
We know that in mobile, the CPU is the problem.
So we try to move everything to the GPUs.
Even collision should be done by the GPU if you can.
So we run on Chromebooks, for instance.
Flipgrid, if you know it, is an application
Microsoft acquired recently.
They were just using JavaScript.
But they were not able to run on Chromebooks
because it's an application that do screen capture
for students.
The way they did screen capture was very easy on the CPU.
And by using BabillionGS, they were
able to move a bit of this code onto the GPU.
And they were able to reach out a user using Chromebooks.
So that's a very important focus for us.
So you have full support already for WebGPU?
We are the only engine that I know of supporting WebGPU.
Yeah, that's also what my last step was.
OK, what are the next steps for BabillionGS?
Features, etc.
Number one is we're going to ship for one in February.
February will be about what I show you today,
like finishing the node material editor.
It's number one key feature.
And number two is supporting WebGPU.
WebGPU is not even a draft spec so far.
It's an evolving version.
So every week, I have one of my engineers just changing
all the code we had to adapt to the new spec.
Like, oh, yeah, they reversed the viewport.
Or it's now up or down anyway.
So that's going to also be the main portion of 4.1.
And WebXR just hit the draft spec standard recently.
So we plan to make sure that everything works for 4.1
as well.
And WebXR, which is an evolution of WebVR,
is complicated because it's not just about VR.
It's also about AR.
So we are also working with the HoloLens team
to make sure that you can do AR with the web.
So it's WebXR on the AR context, supporting fingers
instead of controllers, stuff like that.
So that's the third big bucket of 4.1.
And then you still need the 3,000 euros for the HoloLens.
Yes, but I'm not responsible for that.
I would have given that to everyone else.
I'd like this one.
Would you recommend BabylonJS for 2D or 2.5D development?
Honestly, if you compare to Pixi or other 2D framework,
it depends on what you want to do.
For 2.5, yes, definitely.
And we have a lot of people using it.
We recently came across a company
creating games for Las Vegas.
What's the name?
You know the?
Yes, slot machines, exactly.
It's purely 2D, but they are using 3D
to move the card and stuff like that.
So if there is a sense of at least layers,
yes, BabylonJS is a good example.
Else, you should stick with pure 2D framework tools.
Unless you're interested by the backward compatibility issue
and the turnaround of bug, then we also
have a 2D version of BabylonJS, so it could be useful.
OK, I have another question.
Did you actually have to support Internet Explorer
with BabylonJS when you're working for Microsoft?
Yes, we still support it.
You should take my demos.
They run on Internet Explorer.
The PlayGrant won't work because I am in love with the arrow
function.
You know the new arrow function of JavaScript?
That sucks.
But I was like, OK, the PlayGrant will not work on IE.
That's not a big deal.
But every rendering stuff will work because, yeah,
it's important for us.
One more?
OK.
One more question, and I'm just going to look through here.
I saw one that I can quickly support.
Which browser do we support all?
Can you import models, maps, materials you
build in other software, if so, what formats are supported?
So yes, part of the BabylonJS tools I did not share today.
We have exporters for 3DS Max, Maya, Unity, Blender 3D,
a few others.
And we also developed transcoders.
And the goal is to have everything in GLTF file format.
So as long as your tool that you are using
is exporting into GLTF, then we will be able to load it.
And we are also supporting tools that generate GLTF
into the tools I mentioned before, like Maya, Autodesk, Maya,
3DS Max, Blender, and stuff.
OK.
Let me see if I find one more.
There's some over AI.
I don't get the AI.
How accessible is Babylon to designers?
We have users that are purely designers.
They use another tool that I did not demonstrate here.
It's the sandbox.
The sandbox is a place where you drag and drop a GLTF model
and the inspector pops.
And you can edit everything just visually.
And they use that a lot to create.
We have a viewer as well.
It's a tool that you can plug in a page.
And just one line of HTML, you say display this object.
And there is no code, just a HTML tag.
So they use that to display controls and 3D objects,
for instance.
OK.
Last one.
Is it possible to stream 3D geometry
between server and client for an open world level?
Yes.
We have users doing that.
Super cool.
We just do the client huntering, to be honest.
We don't do the backend, for instance.
And the streaming, you have to stream something compatible
with Babylon.js.
But yes, we are doing that.
OK.
If you have any other question, feel free.
I'm going to stay here, trying not to sleep.
So it should be fine.
If someone talked to me, it's going to be fine.
First, you can have lunch now.
There's going to be lunch.
So everyone, have a good lunch.
And yeah, see you after the break.
