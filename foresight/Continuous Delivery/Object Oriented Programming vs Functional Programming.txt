OO is better than functional. Or is it the other way around? Maybe the next big thing
will be better than both of them. This is one of those arguments that exercises developers,
and they tend to fall into one camp or the other. Either you think that functional programming
is the only sane answer, or OO is the defining approach for complex systems. So what are
the differences, and do they matter? What advantages does language paradigm have to offer?
And have we found all of the paradigms that there are to find?
Hi, I'm Dave Farley of Continuous Delivery. Welcome to my channel. If you haven't already,
please do hit subscribe. And if you enjoyed the video, hit like as well. I'd like to begin by
thanking my sponsors, Harness, Equal Experts, Octopus, and Speckflow. They're all helping us to
grow this channel. So please do check out their links in the description below. Whatever programming
paradigm or technology you pick, a deployment pipeline will improve your workflow. Check out
my new Continuous Delivery Pipelines book on LeanPub, which will help you to get started
building and to build better deployment pipelines. Links in the description again.
In this episode, I want to explore programming paradigms. There's an argument made by Bob
Martin that we've identified all of the paradigms that there are to find. I think that he might be
wrong, but we'll cover that later on. I do, though, like his analysis of the language
paradigms that we currently have. He argues that a programming paradigm works by removing a
freedom of some kind. It constrains us in some way, limiting our options, in ways that tend to help
us to reduce or even avoid some kinds of mistakes. I quite like that description. A good place to
start is how these paradigms arose in the first place. The first languages were unstructured,
paradigm-free. They were general-purpose languages, but this first generation were pretty
unconstrained. They were really like high-level assembler languages in some sense. You could do
anything. The usual way to describe the history of programming languages is as some kind of linear
progression. We started with unstructured languages, invented structure, and then OO came along,
and finally, functional, is the new kid on the block. This is rubbish and completely wrong. In
reality, it was quite a lot messier than that. Grace Hopper wrote the first compiler of any kind
in the early 1950s. Fortran was the first high-level language written in 1957, which is quickly
followed by Lisp in 1958. So languages began with an unstructured language, Fortran, but then the
second language invented was functional, kind of. Fortran was intentionally mathematical. Fortran
was named for formula translator. It was unstructured, but was built on some core concepts
that are common in programming today. Concepts like variable assignment, conditionals, and loops.
COBOL was the next big language written in 1959. It was trying to make programming language more
like natural language and so easier to learn, which I think that most people these days would
consider a mistake for a general purpose language. Lisp was written for researching artificial
intelligence at the time. We'll come back to the functional paradigm that Lisp gave birth to
shortly. So people built most systems in Fortran or COBOL for a while. Lisp was a bit of an outlier
even then, but systems were getting bigger and more complex, so the lack of constraints
meant that there were lots of balls of mud being produced. Dijkstra came along in 1968. He wanted
systems to be mathematically provable, so he said go-to statements are considered harmful
and gave birth to structured programming in 68. Structured programming works by constraining
the flow of transfer of control. You can't just jump to any point in a program as you could in
COBOL or Fortran or Assembler. You are forced to jump to fixed points that are defined, jump to
points in the language, if you like, that we these days call functions or methods. This allows us to
be a bit more cautious at these points. We're forced to assemble arguments and we can check them
for validity if we want to when a call is received. As I said earlier, it's a mistake to see this as
some kind of linear progression of language goodness. While all of this was going on elsewhere in
parallel, OO was being invented. The term OO was invented by Allen Kay in 1966, but the ideas that
led to it were around for a few years before that, even as early as 1961. The first real
OO language was similar, which was created in 1965, but there were earlier attempts.
The radical OO step, though, was small talk in 1972. The OO paradigm is not really what most
people think, though. It's not really about inheritance and why it is about putting data
and behavior together. I think that most OO programmers would say it is much more about
polymorphism. Later, Allen Kay said this, I'm sorry that I long ago coined the term objects for this
topic, because it gets many people to focus on the lesser idea. The big idea is messaging.
I think that what Kay means here is that the real value is that we can send a message to something
and it figures out how to process that message. We can send the same message to two different things
and each of them deals with that same message, but in different ways, ways that make sense to them.
This is polymorphism, really. This is the real power of OO, not inheritance. In fact,
the 1972 version of small talk didn't support inheritance at all. In Bob Martin's model,
this is called dependency management through polymorphism. That's how he characterizes the
OO paradigm. The real value of OO is our ability to modularize our systems and deal
from the outside with different modules in consistent ways. This is polymorphism.
Structured OO and functional aren't the only paradigms.
Logic programming constrains programs to follow the rules of formal logic, for example.
You could argue that machine learning in its current incarnation is a different paradigm
that constrains programmers by allowing them to pick good examples and only define fitness
functions. But let's get back to our topic for today, though. Remember, on the timeline,
kind of weirdly structured programming is historically the last of these paradigms to
turn up. But let's loop back to the current on-point fashion leader, the functional paradigm.
The defining characteristic of functional programming is really that it constrains assignment.
We write code with no side effects. Each function translates its inputs into a new
output, and that's all it does, without changing these inputs in any way, and without relying
on anything but its inputs to achieve its goals. Sometimes functional programmers talk
about this as separating data and function. But if I'm honest, I think that this is probably
so that they can argue with OO programmers who talk about combining data and behavior.
In reality, I like the idea of the constraints. I think that we talk a lot of rubbish about
languages and paradigms. I am probably primarily an OO programmer. That's where I spent most of my
career. But a lot of my thinking was informed by my early programming in assembler languages of
different kinds. An unstructured programming approach, if ever there was one. By shooting
myself in the foot many times when writing assembler programs, I adopted some defensive
habits that I later learned were part functional, part OO, part structured. So that when I learned
more about these ideas, they kind of fit together. And that is what I like about this model of
constraints, because that's exactly how and why I learned these things. I wanted to constrain
the freedom with which I made designs so that I screwed up less often. I adopt programming habits
that limit the degree to which I screw up when I write code. I don't really think of myself as a
language or even a paradigm focused developer. But I like to pick the tools that make sense to me at
the time. Modern languages are mostly a combination of these constraints, rarely pure in concept,
although there are some. I laugh when functional programmers rubbish OO, for example, and then
go on to use collections to implement folds. The degree to which the collections like these make
sense is really applying polymorphism to me and OO idea. The degree to which the data is external
in a list is an implementation detail in this case, as long as we don't change that data.
If I write immutable code in Java or C sharp or any other OO programming language, then I can
justifiably be seen to be writing in a functional style. I used to write C. I used to use ideas
that I now I'd call OO and functional in the design of my code. My language didn't help me much in
those days, in the same way that Java doesn't enforce no assignment when I'm using it. But
it doesn't take a lot of self-discipline to achieve the same results if I want to.
So at the technical level, I think that your choice of paradigm is just that. It's a choice,
and it can be fluid and contextual. Let's be clear, though, you can write crap code in any paradigm,
and you can write great code in any paradigm too. There's no functional good OO bad here.
There's a fashion for each side to rubbish the other. And if I'm honest, I think that that is a
little naive. There are advantages to different paradigms, different advantages for each. As I've
said, I am more of an OO than a functional programmer, so probably somewhat biased. The problem
with this kind of religious war is that people get over emotional. So if I do trample on any of
your sacred cows during the course of this, please do forgive me. There is a social
dimension to all of this, though, and we tend to be too tribal in software development. Broadly,
I think that we could oversimplify the tribes like this. Functional programmers tend to think of
programming as maths. OO programmers tend to think of coding as a problem of modeling. Neither of
these are completely true, but may be a reasonable approximation. So the benefits of a functional
approach are that we can abstract ideas into functions that are always correct. In every
circumstance and so write less code. By excluding or at least constraining assignment, we can create
more stable systems and maybe even prove more provable systems. The benefits of a model based
approach are that we can be guided in our analysis by the problem. I think that this is one of the
advantages that OO has over functional programming. It's that when done well, the code is more
navigable because it's closer to the problem. It allows us to explore the relationships more
clearly and understand the problem in small pieces in a way that is closely related to how we think
about the problem. Human beings are naturally classifiers. This gets us to what seems to me
like an important point. I think OO is more closely aligned with how humans brains work.
I can certainly buy the claim that the more mathematical functional approach is a more
rigorous way to capture an idea. But much as I love maths, it's famously difficult and in
essence an unnatural way of thinking for human brains. We value mathematical thinkers highly
because their skills are so rare. This is so obvious. If I throw a ball to you,
is it easier to catch it or to work out the physics of its flight and predict where it will
land so that you can move to the right place? We don't do the maths when we catch a ball.
If we did, we'd certainly miss the ball. So there's something to be said for ease of
comprehension, clarity of expression, which is clearer, this or this. Even if you are a functional
programmer, I think that you would agree that the second version was easier to read. Sure,
we can argue about the flexibility of folds versus loops and because of the immutability of
functional style, our potential to parallelize the computation of our programs, an argument which I
confess as a developer of high performance systems I'm a bit skeptical about, but the
readability, the comprehensibility of our code matters a lot. Here is a function written in
imperative style, in this case in Java. We're just going to look at a collection of numbers
and form some kind of total. Here is the same function written in Haskell.
In this case, we're going to define the function as a recursive function. The first seems to be a
lot easier to explain to somebody that has never written any code because of this alignment with
the way in which people think about things. You have to access some reasonably complex ideas
like recursion to even start to understand the second example. Yes, the code is shorter,
but that compromises its readability somewhat too. The first is a bit more like catching the ball
than doing the maths. In reality, in Haskell, this sum function is a library function, which
I'm told is apparently implemented like this. I rest my case. I think that the functional
paradigm has a lot to offer. In particular, the idea of limiting side effects is an excellent one,
however you choose to write your programs. I've adopted that style of thinking in my OO code
for a long time now, not eliminating assignment, but certainly limiting it and reducing the side
effects. I confess that I've never tried to write a whole functional system as a pure functional
system, and I'm sure that I would learn a lot if I did, but I think that one of the reasons that
everyone doesn't do functional programming is that it's more difficult to transpose these
ISDs into the kinds of functions in a way that keeps the code readable and navigable.
I said at the beginning that I disagreed somewhat with Bob Martin about whether we have found all of
the programming paradigms. There is another aspect of programs and programming that we can
usefully constrain that has some very interesting properties. That is synchronicity. What if we
constrained our programs to disallow synchronous calls between modules of code? Each component of
each component of the system only communicated with any other by sending a message.
Response is sent in a different message some time later. I'm not talking about
asynchro weights here, which I dislike. More like this. A sends an add item message to B
some time later. B sends an item added message back, saying and confirming the receipt.
Concurrency only allowed at these module boundaries,
no creating threads inside a module. Each module is internally single threaded and so naturally
concurrent. Each module is allowed to be state for or stateless as need arises.
This approach is significantly higher performance than any other approach that I am familiar with,
certainly higher performance than a functional design. Functional systems copy a lot of stuff
to achieve immutability. The best that they can do is clever tricks to pretend that they're copying
things, but actually not moving the bytes around in memory. However clever these tricks are though,
it's still going to add CPU cycles. This is less tightly coupled than OO systems,
this approach of limiting synchronicity that I've described, but it has some properties of
both functional and OO design. It also sounds to me quite a lot closer to the vision that
Alan Kay had back in the 1960s. I wrote about some of these ideas in a thing called the
reactive manifesto. There's a link in the description. If you'd like to hear more about
these kinds of ideas in a future video, do let me know in the comments. Thank you very much for
watching.
