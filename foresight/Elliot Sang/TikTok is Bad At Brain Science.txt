At the age of 25, Phineas P. Gage was fairly accomplished in his profession.
A railroad foreman in 1848, he was in charge of leading construction gangs, blasting away
rock to make way for roads that would be pivotal for expanding US civilization less than a
century after its formation.
Physician John Martin Harlow knew him to be a most efficient and capable foreman, a shrewd,
smart businessman, very energetic and persistent in executing all his plans of operation.
He was tall, smart, and driven toward his goals, the very ideal of young American masculinity.
In those times, blasters used tamping irons which were basically like long, smooth crowbars
in order to tamp a hole which you drilled into a rock and filled with explosive material.
When you tamp the hole, you pour sand and ore clay in it, some type of material to contain
the explosion so that it doesn't explode at you, but rather within the rock formation
so you can collapse it.
The iron is used to firmly pat down all the material into the hole.
But one day, a problem occurred.
Phineas' assistant had not put nearly enough sand in the hole before Phineas, looking over
at his men, put his tamping iron into the hole and made direct contact with the explosive
material.
The result?
Phineas' custom-made tamping iron shot directly upward out of the hole, like a cannon, into
his lower jaw, shooting behind his left eye, through the left side of the front of his
brain, and then right out of the top of his skull.
Now, despite the gruesome, life-altering injury, Phineas survived.
He was taken to a hospital and told a physician of his situation, insisting against disbelief
that his 43-inch tamping iron had indeed shot through his head.
He did this, of course, in between throwing up and coughing up blood.
Harlow went to work, cleaning, treating, and closing the injury.
Over the next few days, Phineas' mental condition went up and down.
He was optimistic at first that he'd be back to work.
At points, he was able to recognize family members and communicate.
Two weeks later, comatose and suffering infection, Harlow had to act to save Phineas' life.
So he did.
He cleared out fungi and cerebral abscess, sprouting from Phineas' dome, applying silver
nitrate.
Phineas continued to survive.
After a month, he was able to walk again, and after two and a half, he was back home,
helping out on the family farm.
He was never, however, able to work in his old job again.
As far as we know, this is because he changed as a person after his injury.
Harlow, the main biographer of Phineas' ordeal, as well as his life-saving surgeon, described
him as becoming impulsive and vulgar.
A child in his intellectual capacity and manifestations, he has the animal passions of a strong man.
His mind was radically changed, so decidedly that his friends and acquaintances said he
was no longer gage.
The thing is, we don't know exactly how much he was affected by this injury.
Malcolm McMillan chronicles the situation and its impact on the world of neuroscience
in the book An Odd Kind of Fame, wherein he details the types of debates taking place
within the medical community surrounding Phineas' case, as well as the overall science of the
mind.
In it, he writes that the kind of knowledge that we would like to have about the damage
done to Phineas' gage's brain still seems beyond our reach.
John Martin Harlow was the only person with extensive recorded observations of Phineas'
gage, and we can draw a lot from them.
We can see from these recordings that his personality changed and that he went through
a lot of things in his life afterwards to varying reports, but we don't have scans of
his brain.
We don't have full-on data.
We don't even have much record from those close to him.
And the science of the time was so limited that we have to approach it with a degree
of caution.
Mainly, Phineas' case became central in the middle of a debate in the early 1800s about
the localization of the brain, that being whether or not the brain had different compartments
which were allocated different functions and basically, frankly, what the brain even was
capable of doing at all.
Even the understanding that the brain was focal in decision-making and morality and logic
was something that was fairly new in science at that point, as opposed to understandings
from old philosophy about these things coming down to the heart and the soul.
With the case of Phineas, there was debate as to whether or not the injury, the one where
a giant bar rammed through his head and shot through the top of his skull, even affected
him that much.
A common narrative was that he was basically fine.
After the thing flew through his head, he got up, dusted himself off, took himself to
the doctor, got wrapped up, and was good as new.
Phineas' documentation proved that this was false, but because anti-localization narratives
had become popular within the medical community at that time, its narratives spread with much
more popularity.
And that's the thing about science.
There's so much we know and so much we don't, and thus, tons of things that we assume based
on how we see the world.
But why does it matter?
Why should we care about the case of Jack Harlow and Phineas Flynn?
Well, the brain and debates over its functions remain a huge part of our social understanding
to this day.
For example, one of the most trendy terms these days, it seems, on social media, is the
prefrontal cortex.
Okay, so follow me here.
Rumor has it that Sidney Sweeney of Euphoria fame cheated on her fiance with Glenn Powell
of Top Gun fame, who was also cheating on his girlfriend, model Gigi Paris, who basically
announced a breakup with him shadily over Instagram.
This was a story or non-story because nothing is really confirmed that was significant enough
to be a part of online discourse for about a day and a half in late April before everyone
decided to move on to whatever we moved on to.
Now, I'm not particularly interested in taking a side in the case of Glidney.
Cheating is bad.
We don't know if they're cheating.
We don't know them personally.
I don't know.
I don't know.
I don't know what's going on.
What I'm interested in is a particular hit tweet by a prevalent Stan Twitter user, which
had tons of likes that read as follows.
Glenn Powell is a nasty cheater, and Sidney Sweeney is just a 25-year-old teenage girl
trying to navigate this crazy thing we call life.
This tweet is almost certainly satirical, although many of the people in the replies
don't seem to pick up on the hyperbole.
But what it satirizes is an important linkage with our topic.
Powell is a 34-year-old man.
Sidney is a 25-year-old woman.
And I can't account for the amount of people that have serious takes mirroring that of
the satire I just read to you.
But I do know that age gap discourse and discourse surrounding young women's choices and their
situations in general tend to run into the kind of walls that this tweet jokes about.
So there's this commonly held idea that the prefrontal cortex, which is a part of your
brain sort of towards the front that does a lot of things with regards to your attention
and your decision-making, doesn't finish developing fully until you reach the age of
like 25.
Sometimes people make this statement on social media to talk about celebrities or talk about
people they know in a way to defend them or abdicate them of as much responsibility because
since they were before the age of 25, their brain didn't fully develop yet, and they thusly
cannot be held as accountable for those actions.
We can't tell whether or not people are being fully serious about these takes because who
knows?
Everything is dry humor at this point.
We've all memed ourselves out of seriousness.
Everything is ironic and also kind of real.
Some people dryly celebrate their birthday on Twitter by announcing that their prefrontal
cortex has finished cooking.
And then others seem to all out declare that people should not get married before that
age because of that brain thing.
In other words, the prefrontal cortex development is like a new, memed way of saying a coming
of age, a time in which a person becomes fully mature and also simultaneously some people
take that age and that dynamic a lot more seriously than others.
The problem with earnestly saying this idea that the brain finishes developing at 25 and
before then it's not finished cooking, it's still cooking, is that it leads to some troubling,
sleeping assumptions about the differences between people and thus some questionable
social views.
When you say someone's brain isn't fully developed, what image do you conjure other
than that of a person who isn't fully smart, isn't fully mature, is childish, thus cannot
have full agency, has to depend on other people, struggles to know left from wrong, left from
wrong, struggles to know left from right, right from wrong.
When you point to a particular age and say, before you reach this age, your brain is not
finished cooking, it's still kind of raw.
You give a poor reading of science that dismisses human beings as agencies, their capacity for
maturity and intellect before reaching a certain age and you end up a hop and a skip away from
outright ableism.
Although it is important to understand that people's brains are developing at younger
ages, it is far from this simplistic idea.
Someone's brain works a little differently, first of all but generally, brain development
is affected by heredity in an environment, prenatal and postnatal insults, nutritional
status, sleep patterns, pharmacotherapy and surgical interventions during early childhood.
Furthermore, physical, mental, economical and psychological stress, drug abuse, caffeine,
nicotine and alcohol and sex hormones including estrogen, progesterone and testosterone can
influence the development and maturation of the adolescent's brain.
The brain does develop rapidly and somewhat vulnerably in certain ways during adolescence
but it is shaped by the same thing that adult brains, which continue developing basically
until death, do as well, external and internal factors combining in a variety of ways.
And there's no concrete way to determine what a brain will look like or be capable of by
a certain age.
In a Slate article by Jane See-Hoo, neurologists who are seen as titans of the field don't
even know where this idea of the 25 year old timeline even comes from.
Psychologist Larry Sternberg, a giant of the adolescence development field, says I honestly
don't know why people picked 25, it's a nice sounding number, it's divisible by
5.
The article details how brain scanning allowed for numerous significant advancements in studying
the brain but also became a field for toxic generalizations that have become prominent
in culture, assuming an indisputable nature to the field of neuroscience that simply does
not measure up to reality.
There's a huge amount of variability between individual brains, just as you might stop
growing taller at 23 or 17, or if you're like me 12, sick burn on yourself but it's
okay to be short, short people are cool.
The age that corresponds with brain plateaus can differ greatly from person to person.
In one study, participants ranged from 7 to 30 years old and researchers tried to predict
each person's brain age by mapping the connections in each person's brain.
Their age predictions accounted for about 55% of the variance among the participants
but far from all of it.
Some 8 year old brains exhibited a greater maturation index than some 25 year old brains,
Somerville wrote in her neuron review.
But the most disturbing part of these cultural assumptions is not the bad science itself
but the cultural implications and impacts that they have.
Mills told me she's heard from middle and high school students that their teachers often
point to brain science as justification for their bad decisions.
As people continue to cite this factoid, it has the power to create serious societal change.
In some cases the result might literally save lives, for instance keeping dangerous weapons
out of the hands of young people or preventing instances of capital punishment.
In other cases it could cost lives.
Anti-trans activists cite this as evidence that young people should not be allowed to
access life saving, gender-affirming care.
The ultimate trajectory of this growing belief and the profound effect it could have on young
lives is impossible to know but it's clear that neuroscience has and will be deployed
to shape policy.
In other words, making these assumptions that your brain simply is not ready or good enough
to make big decisions before it reaches a certain age has huge impacts on young people
and the amount of agency they can have on sometimes life saving decisions.
Life changing choices that are extremely important to them.
And it shouldn't take some sort of fake neuroscientific explanation to showcase why age gaps can be
very problematic in predatory or to showcase why certain people shouldn't have guns.
We don't need to cite bad facts about the brain in order to make good decisions in society.
Now here's the question, what do we know about the prefrontal cortex and what kind of reasonable
ideas can we draw from that knowledge?
For one, we can identify the prefrontal cortex as the key part of the frontal lobe that is
essential in regulating emotional behaviors, executive function, and fear extinction.
Those are the kinds of things that neurodivergent people often struggle with.
Something like stimulant medication, which ColorMind has done a great video essay on,
has been found to reduce usage of the prefrontal cortex, essentially taxing that part of the
brain less as users report an easier time focusing and maintaining energy.
Your prefrontal cortex is important but we're not sure still how exactly it works to the
detail other than a few basics.
We know that physical trauma to the prefrontal cortex like, I don't know, a giant rod ramming
through it and shooting out of the top of your head can have an impact on your brain
and your livelihood, but the brain is so complicated that any attempts to oversimplify its workings
should be questioned.
Before we conclude, let's talk about studying and learning.
The processes of the brain and stories like Phineas Gages are complicated for me to discuss,
especially since I don't have any real science background training and I have serious attention
issues.
That's why it's helpful for me to use an app like Milanote.
Milanote is a tool for organizing your creative projects.
It allows you to collect notes, images, videos, tasks, and more.
The layout is super clean and cool and the projects are shareable, which was ideal for
my editor Denai and I to put images and notes together.
Serious note taking is hard, so Denai ended up putting a bunch of Monsters Inc and high
school musical stuff together, had a bunch of fun with it.
For me, having cool software to play around with to help with inspiration and keeping
memory of things helped my prefrontal cortex feel warm and fuzzy inside.
And I like how downloading the app on mobile allows me to access my boards on the go as
well.
If you pick up Milanote, you can get started on projects pretty easily.
Over 100 built in templates are available for every type of creative project.
Which ones look coolest to you?
I think the creative brief one looks pretty cool to me because it's going to help me
for some group projects I want to work on in the future.
You can download Milanote with the link in the description to get started for free with
no time limit.
And if you enjoy using Milanote, feel free to share in the comments.
Thanks to Milanote for sponsoring this video and let's get back to it.
John Martin Harlow's 1868 report on Phineas Gage is probably to this day the most important
text on this case.
It details the behavioral changes and difficulties Phineas experienced and how he ultimately got
his things together, worked some horse carriage jobs, and eventually died of a seizure in 1860.
The rest of his life was as far as we know a mix of success and struggles.
It's true that he recovered his brain to some extraordinary degrees and picked himself
up by his bootstraps, but only to a certain extent before the ailments that he suffered
at least in great part because of his injuries affected his life and eventually ended it.
Now, 1868 is 8 years after his death.
Harlow had to wait many years after his initial reporting on Gage and 8 years after his death
in order to come out with this report which eventually had a seismic impact on the medical
community.
This was a huge deal because it revealed the extent of Phineas' behavioral changes from
the injury, at least in that moment, which is something that for years had been downplayed.
Henry James Bigelow, who was another person who had seen Gage in the earlier times after
his injury and became this kind of widely quoted scientific reporter on him, was an
anti-localizationist who said the man was still able to walk off and talked with composure
and equanimity of the hole in his head.
And this became a focal point of anti-localization arguments which trotted this case out as an
example of how the brain could be injured in many ways, especially in this particular
part of the brain, and human beings could essentially recover from it good is new, which
pointed to the fact that certain parts of the brain simply aren't that important and
that maybe the brain doesn't have that many roles or functions.
On the other side, Harlow's report and his viewpoint argued the opposite, something much
more modern, which is the idea that this part of Phineas' brain had certain aspects,
it had certain roles, and when it was damaged in such a severe way, it had certain effects
on his personality.
Ways that we can kind of understand to this day as mirroring what we would think would
happen to somebody who injures their prefrontal cortex in such a way.
Similar to people who have neural atypical brains that have difficulties in the prefrontal
cortex, somebody could injure it and have difficulties with memory retention, like Phineas did,
have issues counting and have issues keeping a schedule or keeping their temperament calm.
The thing is, Harlow and the localizationists of that time had an understanding that was
still pretty far from what we know now.
You see, on the other side of Bigelow and the anti-localizationists were the phrenologists.
Phrenology was an extremely popular scientific trend of the early 1800s.
Today we know it to be pseudoscience.
The idea was that different parts of your brain had different functions, which people
mapped out with all these different terms, and that this is where it gets especially
goofy.
The shape of your head could determine which parts of your brain were more pronounced,
and thus which personality aspects and brain strengths you had, and which parts were weaker.
So if your brain was big on this side, then that meant you had, I don't know, better memory.
Stuff like that.
Via email, Mark Dingman from the YouTube channel NeuroscientificallyChallenged explained to
me that although phrenology was pseudoscientific, Franz Gaul, who developed it, was an accomplished
neuroscientist and his ideas that different parts of the brain might be involved in different
functions was sound.
So although phrenology eventually was dismissed, it helped generate ideas about localization
that would persist.
Gaul invented phrenology through a curiosity that people may act and think differently
based on how they looked.
In one of his early experiments, Gaul collected together a number of individuals of the lower
classes of society, such as coachmen, servants, etc., and after gaining their confidence in
giving them beer, wine, and money, encouraged them to talk about each other's good and
bad qualities, in short, their striking characteristics.
Their discussions soon narrowed to identifying those who were peaceable and those who provoked
quarrels.
Gaul then tried to identify the features of the heads that differentiated the two groups.
I ranged the quarrel some on one side and the peaceable on the other and examined carefully
the heads of both.
I found that in all the former, the head, immediately behind and on a level with the
top of the ears, was much broader than in the latter.
Ah-ha!
Cracked the case!
John Martin Harlow was, if not a phrenologist himself, a phrenology sympathizer to say the
least.
The term Nervo Billius, which Harlow used to describe Phineas Gage's new personality
post-injury, was lifted directly from a phrenological doctrine.
His account of Phineas being unable to value money properly linked with the idea that the
injury had pierced his organ of veneration.
Phrenology was hugely popular, like I said in the early 1800s, for a time.
You could make substantial money as a medical professional or not even, going around to
people and giving them advice on what they should do in big situations by looking at
the shape of their head and saying, well, you might want to avoid this because your
brain is like this and you might want to do this instead or you might want to work on
this particular part of your brain.
And as all popular sciences go, it was formed through and shaped by political motivations.
Most infamously, phrenology was used to describe the inferiority of other races.
A shocking twist for a practice based on judging how somebody thinks and acts based on how they look.
At the same time, phrenology was actually practiced by people across political lines
and across class lines.
And it set a foundation for our understanding of the brain today, which I still don't know
how to feel about that.
It was phrenologists like Harlow who were basically right about how Gage was affected
by his injury.
Understanding that the prefrontal cortex is an important part of the brain, although
they didn't have that terminology necessarily and not as the anti-localizationist might
have felt some sort of like neutral, non-active part of the brain that you could basically
just like chop off if you needed to.
We now know that the prefrontal cortex, as Dingman describes, is best known for its
role in complex cognition and executive functions.
But on both sides of this debate over the brain and on all the sides of these debates
these days about our brain, we see a lot of dogma.
When we talk about our prefrontal cortex and how they need to reach a certain age in order
to finish cooking, we participate in pushing dogma.
We resemble the anti-localizationists who think you can chop off a piece of your brain
and basically be fine, or the phrenologists who think that the organ of veneration must
enlarge in order for you to be better at counting money.
And not only does this make us ignorant, it is, by and large, and as such, a process
of trying to be determinative and naturalist, declaring the world to be dictated by obvious,
simple, natural rules, and basically telling people who oppose us with facts and reason
that they should argue with the science, because the science backs us up.
But science doesn't work that way.
It is hard enough to make scientific discoveries and find new scientific truths, which makes
it all the more satisfying when we do find those, and all the more frustrating when our
society seems to refuse to open itself up to these new knowledges.
But maybe that's the point.
Phrenology became popular not because of empirical evidence, but because of how it could offer
a simple, compelling roadmap for people.
If your head was a certain shape that didn't favor a certain trait, you could train it
to make parts of your brain stronger.
America Janic writes for The Atlantic that,
One reason phrenology attracted so many followers was that it seemed to provide the toolbox
for the American dream.
All classes of society found much to admire in phrenology.
The upper classes liked it because it reassured them, but the social hierarchy that placed
them on top was natural.
The emerging middle class and working classes liked it because its meritocratic message
confirmed their hope of advancement through personal striving and self-improvement.
Science has so much to offer us, but we only pay attention to it when it tells us what
we want to hear.
In today's day and age, we talk about the prefrontal cortex like it's some obvious
natural explanation of our issues.
If we're under 25 and struggling to get life together, maybe it's just because our brain
isn't fully developed.
It's easier to say that than to look at all the complicated confluences of culture,
biology, politics, earth science and everything else and get a detailed understanding of our
lives.
What really fascinates me though is why this is so popular in the first place.
Wouldn't it be more pleasant to cling to simplistic neuroscience saying that young people are
actually really smart?
Wouldn't it be more inspiring to cling to stories of people healing their own brains
even after injuring them severely?
Why do we instead seem excited to call ourselves underdeveloped?
Why do we seem so obsessed with the powerlessness of youth to be continued?
