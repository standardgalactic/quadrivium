And I think one of the reasons that chat GPT and stuff have been so hyped recently is because most people don't know what it is.
And so when you see it doing what it does, you think this thing must basically be a person, right?
Because it's acting like one.
And I should carry out this by saying I'm not selling short these incredible technologies.
I'm just saying that it would be very silly to just completely use them blind and never check what they do, right?
Because we know they just make stuff up a lot of the time.
I'm glad you mentioned computer science.
Do you think it's time for more of us to learn computer science-type stuff because of AI, like maths and all these computer science stuff and not really?
I've been saying that you need to learn artificial intelligence or AI.
Question that a lot of you have been asking me is, OK, so how do I learn that?
So let's ask another friend.
David.
Yes.
You've mentioned this before, but remind me which place do you recommend that I learn and others learn AI?
I really like Brilliant.
It's one of those places where you can go and a visual gamified way to learn concepts and mathematics behind AI and machine learning.
You've recommended this a few times to me.
The way you said it was, David, if you want to learn AI, I need to learn like statistics and stuff like that, right?
Yes, they've got these roadmaps that actually helps you with calculus and learning statistics and linear algebra, all the stuff that you need to know for AI.
I'll say this.
David is on my team, really glad that he is.
David has strengths that I don't have, and I think that's what's really important in life.
You need to learn from others.
David, well, tell us, you've done a lot of maths.
You've done a lot of computer science.
You've actually worked with AI stuff, right?
I worked in the medical field for data science stuff.
I really think you need to know all the statistics and calculus and linear algebra and the discrete mathematics that you need to learn, which actually makes a lot of coding a lot easier for you.
That's brilliant.
So I'm looking on their website now.
The one that you've recommended that I go through is the Data Science Foundations, right?
That's like probability, applied probability, statistics, fundamentals, and then an introduction to neural networks.
And obviously, me being me, I just skipped all of that.
They went straight to learning neural networks.
But as David said, what I really like about this website is it's gamified, as he said.
So really great way to get started.
Really want to thank Brilliant for sponsoring this video.
Brilliant, as they say in the UK.
Thanks.
Everyone, it's David Bombal back with Dr. Mike Pound.
Mike, welcome.
Thanks for having me back again.
Mike, it feels like the sky's falling again.
You know, we had this interview previously and it was all this hype about AI, but it seems to just be getting hotter and hotter.
So tell me, is the sky falling?
Am I going to lose my job?
Is the future bleak?
I think I think it'll be all right.
Just relax.
Relax.
Um, just bring me into calm everything down a bit.
That's, that's, you know, I think that the last six months particularly have been, you know, both unbelievable in terms of genuine hype,
like things that are really exciting appearing and also obviously totally overboard hype that's just getting really quite silly and everyone needs to calm down.
Right.
So I think there's a bit of everything going on.
Chat and GPT is an incredibly impressive tool that works very, very well.
I've done some really fun tests of it where I push to see what it will do.
And some of the things it will do are quite amazing, right?
On the other hand, there are lots of things it doesn't do very well.
And one of the big problems we have at the moment is it won't always tell you it's one of those things.
And that's, I think, where we have something that needs addressing.
I've done some tests and I mean, a lot of people I know have done tests.
And it's amazing what it seems to be able to produce.
I think the concern a lot of people have is like, Mike, I'm 18 years old or let's say I'm older.
I want to switch careers to become a programmer or I want to get into cybersecurity or I want to be a network engineer, whatever, some technical role.
And it feels like I'm just going to waste my time because Chat GPT is just going to obliterate jobs.
The first thing I would observe is that it's very nice for some of these big tech companies, if that's the perception, because it makes them look very, very impressive, right?
And so I think that the cynic in me a little bit is like, this is, you know, no PR is bad PR kind of a situation.
They like to drop, you know, these tools get dropped as incredibly impressive tech demos and I'm not selling them short, right?
Very impressive, but maybe not quite as impressive as they first appear on a service when you start to dig in.
And I think that's what's really important.
You know, in science, we spend a lot of time checking things and rechecking them, at least that's what we're supposed to do, right?
So I, you know, a PhD student comes to my office with some results and they say, oh, we've got 95% accuracy on some task.
And I think, OK, let's talk about which data you used and whether that's really true and whether when you use it on this new data, you're going to get that same result.
And we spend ages going over and over the data again to make sure that when we actually publish it, it's really as accurate as possible.
Large language models are maybe not operating in quite that same way.
Yes, they release papers from time to time, but mostly they release these big websites where you can try them out and they do incredibly impressive stuff.
And then and they lie very impressively as well, right?
And I think that's the thing that we haven't quite got around.
So, you know, suppose you're a programmer and you've been using co-pilot and you've been using chat.
GPT also does code and you're a bit worried because it's just producing pretty decent code.
Maybe you don't see it replacing you right now, but you could see in 10 years, maybe that's going to be a problem.
I think the problem is at the moment is it's very difficult to know where it's going.
I think a lot of researchers are suspicious of the idea that we can just make it continually bigger and bigger and more impressive and it will just get better and better.
You know, when we talked about how these models work, they don't really have an internal model of what it is they're trying to do or anything, really.
They just map text to other texts.
You know, when I write a piece of computer code, what I'm really hoping to do is in my mind come up with an idea of the problem that needs to be solved
and what the variables and things that I'm going to need start to get them down on paper and then start thinking about how would I manipulate those variables using code to produce the result that I want.
Chat GPT doesn't really work that way.
It just spits out code and it happens a lot of the time to look pretty good.
At the moment, it's a tool to be used quite carefully, particularly with code.
I wouldn't push anything chat GPT has written straight into production without, you know, quite a few tests because at the moment there's no grounding in reality.
The reality is for training data, but once it's finished training, it's kind of random what it gets.
And these things actually, I don't know if you've noticed this, David, but when you run it, it can produce different answers each time.
And that's because it uses something called temperature to somewhat randomize its output.
So instead of saying, OK, the next word in my output is going to be there, it will say, I think there's an 80% chance that it's there, but it's a 20% chance that it's so.
And then what what the machine will do is say, well, OK, 20% of the time, then we'll pick a different word.
And that way you can go in slightly different directions because if you didn't do that, it will just produce a save output every time.
It's not it's not a random object, so it's not a random network in that sense.
And so you can imagine a situation where there is a really good version of this program that it could write, but it randomly didn't and produce one below the bugs.
So, you know, I mean, that's what I've experienced.
Yeah. And you know, I suppose there's a question in my mind about how is there an efficiency saving if you have to order everything you're reading, right?
Is reading code as fast as writing code or slower or faster?
I'm I don't know, right?
I'm undecided. I think sometimes for boilerplate code, probably pretty effective.
If it's a sort of code, you know, write me a for loop to do X, Y and Z, probably works pretty well, as long as you're capable of quickly checking that.
But then it didn't take me very long to write a for loop anyway.
I'm undecided, I suppose, as to how much of a game change that will be.
This said, I know there are developers that use it, and I know that the developers who claim, or at least they think they're much more efficient.
I don't spend as much time coding as I'd like, because I'm I see, you know, as a professor in a university, I spend a lot of time teaching, a lot of time mentoring others and teaching people.
So they do the coding and I sit there and look at it.
I haven't had as much experience as some.
Yeah, I mean, I think the concern is always, you know, younger young people are people trying to switch careers is, you know, I want to have a job for more than a year or five years.
Is it worth putting all the effort in to learn this stuff if AI is just going to take it away?
My gut tells me that AI isn't going to take it away anytime soon, because I think that I would argue that you need something more fundamental to understanding some of these problems.
If you're going to write code to solve them than just a text production mechanism, that isn't to say that what it doesn't do, it's very impressive what it does.
But I think that as you start to build up, you know, it's very, it's all very well saying like me a for loop to do this.
But if you want to write your class structure and they and a really complicated system, that's such a more difficult, you know, it's like the difference between lane assist and self driving, right?
And that's why we can we see lane assist exist, but self driving seems to be so hard to get to because of how much harder that is as a problem.
And I think that it's very easy to fit a straight line upwards to these things.
You say, well, they didn't do anything and now they're doing this, which means they're going to be doing this.
It may get a lot harder and plateau out, right?
We, you know, it's difficult to say for sure.
I think that there's going to be a very strong need for people in the loop for a long time further.
I mean, as an example, outside of programming in medical science, AI is obviously used quite a lot to help with diagnosis and things, but almost no AI systems are used just on their own with no human oversight.
Because for a start, because we don't trust them yet.
And also because patients don't trust them.
Patients don't want an AI, even if it's good, making their health decisions, right?
Like not yet, you know.
And so I think also culturally, we're not quite ready.
And I know a few companies that are not using co-pilot because they're not absolutely sure of the copyright on the code and think, you know, there's questions that haven't been answered.
I think if you're looking for it to be a software developer or you're looking for a career in security or career in AI, there's still plenty of things to do.
So I wouldn't personally worry about that.
I think we mentioned this last time, and I want to give people firstly, you know, a way to make themselves more valuable and then a path to get there.
You mentioned that, you know, if you attach AI to any skill that you've got, it's going to make you more valuable.
I assume that's still the case.
And then I want to ask you, Mike, how do I get there?
And it also makes you more experienced at dealing with things like this.
When something comes along, you can sit back and you can say, OK, how impressive is this?
Let's think about what it's doing and how it works.
And, you know, some understanding of how these things work, you don't have to understand deep down transformer networks if you want to understand roughly what they're doing and how they've been trained.
Yeah, I would say some knowledge of statistical analysis and data, data processing in general is really, really important, right?
People mock Excel.
Excel is, I think, one of the best products ever written.
It's totally ubiquitous.
It's very powerful and it underpins the huge amounts of, you know, financial systems and other systems.
I use it all the time for student marks, right?
So, you know, you get a table of data that comes in and it doesn't make any sense what we're going to look at, how we're going to deal with this, right?
And how we're going to make decisions based on this data.
And things like data science and machine learning will help you deal with some of these problems.
People who want to become experts in AI obviously need to delve a bit deeper.
But I think for a lot of people, AI can just solve small problems in your pipeline that might make things a little bit easier.
Having that extra string in your bow is not a terrible idea.
So, in the previous videos, I told people you need to learn AI and it's something that I want to really focus on this year.
And this is why I'm talking to you, you know, right in the beginning of the year.
Have you got, like, courses, places that I can go to, books that I can read?
Any recommendations of how do I go from, like, where I am now, zero knowledge to at least, you know, getting down that path to be able to put it on my resume?
There are loads, there's loads of books and resources in Python to learn machine learning and data science.
And that would be a great place to start.
You know, I've said it before, many times, I have a love-hate relationship with Python.
I like it sometimes and I don't like it other times.
At the end of the day, there are libraries in Python that do quite incredible machine learning and make your life a lot easier.
Right, so we've got things like scikit-learn, we've got TensorFlow and PyTorch, of course.
But there are tutorials and books written around these things and they take you from, I don't know what this network is,
to I can actually get one of these networks running on a machine.
And it's often not that much code because of these libraries do a lot of heavy lifting for you.
Often it becomes more plug-in building books together than it does writing your network layers from scratch,
which we don't do anymore.
You know, so you can start by just plugging some things together and I've got a rudimentary network
that I don't really understand that's doing this classification.
And before long, you've made your classification problem a little bit more complicated
and you've got multi-class classification.
I mean, you've got a slightly different data set and then you've solved a data augmentation problem
and you can add these things in and slowly work towards a bit more experience.
You know, I have a number of undergraduate project students every year.
So in university, in the third year, you often do a dissertation, which is like a focused project over a whole year.
Often most of my dissertation projects are going to be on AI and something like this.
And, you know, these are students who've done some, you know, machine learning, maybe a little bit in their modules
throughout their undergraduate and they know how to code.
But a lot of it's new, you know, we pick it up and we run with it and we do some great stuff.
I've got some students in the second year solving Rubik's cubes,
using machine learning to detect where the colors are and things like this.
And this is from scratch, right?
So this is people who haven't done machine learning before and I can point them in the right direction.
I think it is very doable and I think it's, you know, it's fun as well, right?
There's nothing more satisfying to me than you've trained a network
and it's just classifying really accurately whatever it was you wanted to do.
Basically, my job is looking at numbers go up and I like when they go up.
So Mike, I mean, I'd love to come to Nottingham University and attend your courses,
but obviously I can't and so can, you know, most of us can't.
Do you have any like resources or ideas that things, places I can go to to learn?
Often the first course I recommend for everyone is to take Andrew Ung's Coursera course, right?
Very popular.
I mean, I don't know how many times it's been taken now, millions of times.
It's Andrew Ung's course, a course on machine learning.
There is a deep learning follow up to it, which I haven't I haven't done
because probably I actually already know deep learning.
But the machine learning course is really good.
It's a good understanding of some of the key concepts in machine learning
and not specifically about it.
Yes, a little bit about how neural networks work and things like this.
And it can be a little bit mathematical is my experience of it.
But if you if you watch it anyway, you're going to pick up a lot of tips and tricks.
So things like watching your network train over time
and reacting to how that works and doesn't work and making decisions based on this.
These are the things really I think that people who want to do machine learning
in an applied way in a in a in a in a in a business or in an industry.
That's what they need to be able to do.
A lot of them are not going to be writing neural networks from scratch
or designing the number of layers in your network.
They're going to take a network that we know works and run it on some new data.
And if that works great the first time, then that's fabulous.
But if it doesn't, what do you do then?
And these are things that you're going to learn and start learning that Coursera course.
Joshua Bengio and others have written a book just called Deep Learning,
which is very popular.
Again, obviously, it can go into a little bit of heavy math detail,
but it's very popular.
I would say don't read it end to end.
It's one to dip into while you're doing some tutorials
to understand a bit more about the theory.
And after that, personally, I would get I would do the PyTorch tutorials
or the psychic learn tutorials.
They can be directed at your own pace and they will include
they'll give you experience in all those different things, right?
There's there's tutorials on things like reinforcement learning,
but also just standard CNNs and transformers and things like this.
You know, and don't don't worry about you don't have to do all of those on day one.
On day one, we're talking about what is classification?
What is regression?
Maybe get something little going, right?
Really, you know, start yourself off
size and slow and build up the complexity as we go, right?
It's the same with any subject in computer science.
You can't learn everything on the first day.
So you just have to take it a little bit at a time.
I'm glad you mentioned computer science.
Do you think it's time to for more of us to learn computer science type stuff
because of AI like maths and all these computer science stuff and not really?
I think that it's it wouldn't it's not necessary for everyone to do that.
I think that, you know, I would encourage everyone to do computer science,
because I would, but I think that sometimes both computer science
and industry have a sort of reverse snobbery about each other, right?
Which I don't like very much.
So, for example, computer scientists might say, well, if someone didn't do a degree,
you know, what do we know about computers, right?
Which is not true.
And someone who's who got on fine without a degree might go,
why will I go and get student loans and do a degree?
And different paths are all valid.
I don't know why we're having this conversation.
And I think there are there are elements of maths in machine learning,
which help, I suppose, me to understand it a bit better
when someone comes with a particularly weird problem that doesn't, you know,
they've added another layer and it's not training. Why is that?
They also help me sometimes when I'm reading papers,
because papers, they can have a lot of mathematical notation in.
And sometimes that's not necessary and they've just added it in.
But often it's just it's just to be absolutely clear about what they've done.
And often the mathematical notation is necessary to achieve that
rather than writing it in sort of flavourful text.
But to begin with machine learning, you don't necessarily need to know those things.
You know, you can train a network in PyTorch with a knowledge,
a rudimentary knowledge of Python and following some tutorials,
and you'll pick up the rest as you go.
The really complicated maths like back propagation, which is how we train it,
that's all taken care of under the hood. You don't see that.
It's not something unless you're really interested.
It's not something to concern yourself with.
But I mean, the great thing is if I'm in industry, or I'm into cyber,
or dev or whatever, I can really enhance my career prospects
and the future by just adding this on to my skills.
Yeah, but I also think that, and I mentioned it before,
I think the other thing is it makes you much more resistant to hype
and to concerns over things.
And also when someone comes to you and says, oh, yeah, I've trained a neural network
to do X, Y and Z, you can start to think,
doesn't sound very likely, right?
That sounds like the sort of thing that maybe is a bit fanciful, right?
Let's deal with, let's look at their data and see if that's actually true,
what they've done.
And I think one of the reasons that chat GPT and stuff have been so hyped recently
is because most people don't know what it is.
And so when you see it doing what it does,
you think this thing must basically be a person, right?
Because it's acting like one.
But actually, it's only acting like one in a very narrow thing.
And we know how it's trained and how it's trained
doesn't imply necessarily that it's got any human qualities, right?
It might, but I don't, gut tells me not quite, right?
But the point is that I can, I'm sort of more resistant to that in some sense,
because I know how it works underneath.
And I sort of think I've trained all these networks
and this is a bigger version of networks that I've trained myself.
I don't see what's different about,
but so different about that that it would suddenly be
unbelievable, be intelligent compared to anything else, if that makes sense.
Some knowledge of how what some of these technologies are,
just like knowledge of, you know, some companies trying to sell you a new firewall
with next generation antivirus on it that has all kinds of machine learning.
Well, if you understand a bit about machine learning,
you'll know what it will and won't do, right?
And that will allow you to make a better informed purchase decision.
And the answer is it'll work pretty well, right?
But nothing's perfect and machine learning is only as good as a training day to and so on.
So there's lots of things you can ask.
And you can ask really difficult questions
instead of people that come and try and sell it to you.
Especially with things like Twitter and the news,
it's very easy to get carried away in this hype cycle, right?
Lots of technologies have this.
It's in the interest of these companies to make these massive models
of incredibly impressive performance.
I think we're a long way from full automation of a lot of these tasks,
even if it might appear that way at a sort of superficial level.
But on the other hand, they're really promising in some other ways, right?
So one of the things that I found that chat GPT is really good at
is paraphrasing text and vice versa.
So you have a text that you don't quite understand,
say, please can you read this and tell me what it means?
Or please can you summarize these bullet points in an email or something like this?
You know, these kind of functions, I think, are actually working really well, right?
Because those are functions that rely on their text to text.
They're meant for text to text, right?
They are, that's kind of what they're for.
And I think that those are ones that are really, really good.
I think co-completion is useful when you're asking limited things
that you can carefully check quite quickly.
Don't ask it to produce a thousand lines of code
that you expect them to all be perfect, because that's not what it will do, right?
And you'll end up with a lot of weird bugs.
Or, I mean, there was this paper that was released just the other day, actually,
from Stanford that said that they audited code from about 30 to 35 researchers
who some of them were using AI to produce some of the code
and some of them weren't.
And the AI produced code had more vulnerabilities in it.
And that's because when the AI produces code that works,
but let's say it uses ECB mode in AS,
or it uses a slightly weak key derivation or something, I don't know,
something subtle, if they don't know about that subject already,
they might accept that change, if that makes sense, right?
And actually, so this is why you need to still be an expert in your field,
because you can't just rely on it to do it for you yet.
You've got to be there saying,
I think that's okay, or I don't think that's okay,
and make those decisions for yourself.
Yeah, I mean, it's a limited study, but it's not that limited,
and it makes a very valid point.
I think the real danger is people who...
And I should carry out this by saying,
I'm not selling short these incredible technologies.
I'm just saying that it would be very silly
to just completely use them blind and never check what they do, right?
Because we know they just make stuff up a lot of the time.
I think a bit of domain knowledge is always going to help.
Yeah, I mean, it's interesting, because I did some tests with Cisco devices,
and it's amazing.
Like, first time it got it perfect, then I wanted to do it for a video,
and then it wasn't good, and I did like five or six attempts,
and none of them were perfect.
Yeah, I think...
And if I didn't know what it was doing, I would have accepted it.
Sorry, go on.
Yeah, and the other thing is that, you know,
if you think about the data that it's trained on,
it's got some 40 plus billion tokens, right?
It's just internet text, we'll just leave it at that, right?
Loads and loads of text.
Cisco-related text is only going to form a very, very small fraction of that.
There is very little evidence, because it's not got a world model,
because it's not got an understanding of the world,
where it can bring Cisco in and add it to its model.
It's just doing text completion.
And so, when something is underrepresented in the training set,
it's going to probably be worse performing
when it comes to actually running it later, right?
So when you say, write me something in the style of Shakespeare,
it's going to do really well,
because there's Shakespeare all over the internet, right?
Some tasks are going to be very solvable,
because they're just...
They're hugely represented in the training set,
they work really well.
And some tasks are really niche,
and you probably don't know which ones are niche,
because you haven't seen the training set.
I say, write me a link expression, and it does it really well.
And when I say, write me a link expression using some other thing,
and that isn't in the training set, and it produces me a wrong answer.
And I don't know until I run it whether that's the case.
So I have to understand and be able to read that code,
because otherwise I can't possibly put it into my system.
And it goes back to the exact same problem with medicine, right?
It might be that we're absolutely confident that this AI
will look at this image and make the correct decision,
but we're not absolutely sure.
And while we're not absolutely sure,
do we want to completely take a human out of a loop there?
There's questions that we have to think about.
So do you think it'll become like the AI might do a lot of the low-level donkey...
I think that's much closer to what will happen.
So I think there's a phrase in medicine called CAD, or computer-aided diagnosis.
And the idea is that instead of the doctor not making a decision,
the doctor will be guided into a decision by the AI saying,
we've noticed these spots over here in this image, is that relevant to you?
And it will speed them up, right?
And if we can make doctors or medics 50% more efficient, that's a huge boost.
Rather than try and put it all on the AI.
And similarly, it works in code.
If you can produce boilerplate code,
if you can get it to bootstrap, spring boot, configuration files for you,
fabulous, do that, right?
And then that saves you half an hour to an hour of doing some actual code
or making sure that it works.
But what I would avoid doing is trying to have it write everything for you
and replace yourself because I don't think it'll work.
I think you'll end up really frustrated that your code doesn't get past any of your reviews
because it doesn't work, right?
I was going to say, I love what you said, though,
because with that example at Stanford,
if people had just accepted the code,
there's hidden vulnerabilities in the code that wouldn't have been picked up.
Yeah, and then there's a combination of issues, right?
Is it that the developer needs to know more about these subjects
or is it that there's someone that would normally be on that team
that wasn't auditing that code,
that would have been auditing that code at that time, you know?
Because you have security teams sometimes who are specialists in this.
But I think it's that same argument.
In some ways, if someone has a small amount of knowledge of computer security,
that might allow them to be more resistant when code appears that does this.
And that's the same thing with the AI.
If you know a little bit about AI, maybe you can better deal with it when something comes along.
So I think a little bit of knowledge in lots of these things is often useful for that reason.
Mike, so how has this affected like university life?
Because I've heard people talk about how students can just get chat GPT to write their essays and stuff like that.
And you can't see the difference between a student and a human, sorry, and a chat GPT.
Yeah, I think it's very subject dependent.
I think that's one thing.
So what we've done is we've actually been running some tests, right?
Because so, you know, it was very kind of open,
they had to drop this tool just before exams.
Yeah, exactly.
Yeah, we've run some tests and I think it depends on it.
If I show, I suppose we're doing a computer security exam, which actually I teach.
So, you know, and I ask a very simple question,
a question like what's a good encryption algorithm to use?
Chat GPT can answer that.
So it would be unwise of me to ask that question in an exam, I suppose, what we say.
In some sense, I think it's another variant of a search engine.
So if a student could, you know, we call it academic misconduct, right?
If a student was going to use a search engine to do that,
they could also have a go at using chat GPT.
It has the advantage for that student that it's generating very plausible looking answers.
Sometimes they're completely wrong, right?
And those answers are going to get marked very far down when they come in front of a convenience.
So I think your mileage may vary
if you think you can get through a university degree using just AI tools.
It's something we have to consider, right?
Now, some of our exams are face-to-face.
They aren't really affected, right?
You know, we're talking about coursework essays,
and I don't know, I haven't spoken too much to other schools in university and other subject areas,
but obviously there are lots of essay-based subjects,
but they require very well-written essays.
Chat GPT has a habit of producing general answers to things,
which are sometimes very detailed, but sometimes not quite so detailed.
Again, I think that your mileage would vary if you tried this.
I suspect that it is possible to tell that they're written by Chat GPT to an extent
because it has a way of phrasing things that's quite common.
I've noticed as I produce answers,
but that isn't necessarily all the time, but that's going to be a problem.
It's something that every university on earth is now looking at.
Well, yeah, it's had a big impact.
And you know, when you consider that this is just version one,
and you know, there's going to be a Chat GPT 2 probably,
and Microsoft might release one, and Google release one, and so on and so forth,
there's always going to be one of these tools floating about.
That we have to just be prepared and think about how that's going to work.
I think, I mean, the examples I've seen which have worked really well is like,
if I'm asked to write an essay about something,
I can get it to write something that gives me a lot of ideas,
and then I can just rephrase it in my own voice.
But it helps you a lot from a study point of view, I suppose.
Yeah, and I think it actually does.
And I think, so anyway, that's a big positive, right?
And there are some academics in this school, for example,
and across the world, who operate in a kind of human computer interaction area,
who are very interested in, could you end up writing a better essay
if you worked with a computer to help you out, right?
And in a way, is that not a win for the lecturers as well, if that's the case?
Now, I agree with that to an extent.
I think that's absolutely right.
I think that maybe we can't solve that whole discussion in a month,
right, which is how long it is until our exams.
So, you know, the clock is ticking in somewhat,
it's somewhat in the short term for these issues.
But in the longer term, I think they're going to be really transformative in helping.
You know, there are students who have, who are very, very intelligent,
and they know all the subject area, but they're just not good at exams,
they really struggle to get their thoughts down on paper.
Maybe those students could really be helped by something like this,
because if you give really specific prompts to chat GPT,
you get much better answers.
If a student knows what they're doing and can work with the AI,
I think that's going to be much better.
I mean, I suppose you could have said the same thing for Google,
or, you know, using search engines for...
Yeah, yeah, that's the point that's been made.
I mean, in some ways, I see on Twitter a lot people compare these things to Google.
I would not, because they're very different,
and they don't have no source of actual data.
That's a really important thing to remember.
But they are a complementary tool in many ways,
and they operate in a similar way.
If you were going to try and answer an exam,
you know, you would put the question in, you'd rephrase it,
you'd see what came out, you'd see,
does that look plausible, I'm going to try again, I'm going to edit it, and so on.
In the same way that you would if you were using a search engine to write an essay as well.
And using a search engine to write an essay,
and I don't want to speak for every academic on the planet, right,
but it's not necessarily plagiarism or misconduct,
it depends on how you use it, right.
You know, looking up sources online is absolutely to be encouraged.
It depends on how you're doing this.
I think in the long term we will get a nice balance, actually,
between using it too much and not using it enough.
And I think actually there's another thing, there's another aspect,
which is I think this is plays into your,
this is relevant to your channel's viewers,
is that you shouldn't think of doing a degree or writing a coursework
as just about getting a mark, right.
That's very easy to think about that,
but actually it's about learning something that you can then take and use in your career,
or something like that, right.
We don't teach people to programme, so they pass the exams.
We teach them the programme so that they can go off and be software developers.
If you used AI to write all your work for you,
then you'd get out and you wouldn't be able to get a job
and you wouldn't be able to work in that job
because you wouldn't be able to do any of the computer science.
Actually, I think that if you've got a lot,
because I have quite a lot of learning
and I love to learn about new topics,
particularly, you know, about computer science,
I would never use chat GPT to cheat
because I wouldn't know any of it then, right.
And you know, and I like to learn about these things.
Now, if you want to become an expert in something,
then you're going to need to learn it.
You can't read what chat GPT wrote.
A lot of it comes down to hoping that students
and trying to encourage students to think
that it's about the process of learning
and where they get to at the end,
rather than specifically about a series of kind of barriers
of exams that they have to get through,
which I think is not a good way to look at a degree or any course, really.
You know, it's much better to think about where you'll be at the end, right,
and you'll be in that much better position to do what you want to do next.
That's exactly right. I mean, it's like certification exams.
Same thing, you know, you can go and get all the answers
or the cheater sites or you can actually learn something.
And you haven't done yourself any favours if you get it off,
because you might get a job based on that.
It's not going to go well, right?
Because you don't have any of the knowledge.
You'll always feel like you don't have any of the knowledge as well, right?
You know, actually, you don't take that long to learn these things
if you really put yourself to it,
and you'll be in such a much better position afterwards.
Mike, as always, I really want to thank you for, you know, sharing your knowledge
and, you know, separating the hype from, like, the worries about people's futures.
Thanks so much for making a drill.
Yeah, it's no problem. I'm glad to be on again.
It's been really, really, really good.
Brilliant. Thanks, Mike. Thanks.
