you
you
you
you
you
good afternoon I still have to wait for a sign since we
the livestream determines the program are we ready I guess we are ready good
afternoon dear ladies and gentlemen the president of the Bavarian Academy of
Science I would like to welcome you all to our talk focusing on current
developments of advanced computing technologies we are very proud to host
this event in the rural residents in the center of Munich which houses the main
office of the Bavarian Academy of Science founded in 1759 the Academy
functions today as a community of scholars a non-university research
institution and a communication interface between the Bavarian
scientific community society and policymakers with the scholars the
Academy provides a powerful internet disciplinary network of very
established scientists this network of excellence interacts very closely with
all Bavarian research institutions and political decision makers and represents
an important part of the science communication with the public research
activities range from the composer Richard Strauss to the study of climate
change in their alps from baroque ceiling paintings to quantum physics the
longer-term basic research spans from natural science to technology to
humanities and social studies the Academy research project actively
leverage the latest digital technologies the Leibniz supercomputer center also
part of our Academy serves as an important infrastructural support for
digital activities at Bavarian universities today we will hear an
important contribution to the rapidly growing discussions about artificial
intelligence from Jan Lecun who is according to the Time magazine one of
the hundred worldwide leading AI pioneers his professor of NYU on chief
I scientists at Metta not in California in New York I just learned the title of
his talk from machine learning to autonomous intelligence artificial
intelligence as you all know is the key topic of our time not only in research
and industry but also in the broader society this becomes evident as a large
interest and thank you for all coming to this meeting on sharing this
experience we're very pleased as Bavarian Academy to gather with the AI agency to
be part of biosphere biosphere is the official network of all AI activities
in Bavaria we partner in this important task to advance AI science in Bavaria in
close cooperation with the Center for Advanced Studies at LMU the Bavarian
Research Institute for Digital Transformation the Munich Center for
Machine Learning and the Konrad Susie School of Excellence in Reliable AI the
event today is part of this successful cooperation and we're looking very
broadly forward to learn more about recent progress from advanced computing to
autonomous intelligence I hereby hand over to professor Thomas Seidel member
of the Bavarian AI Council chair of database systems and data mining
director of Munich Center for Machine Learning to all of you I wish a very
insightful and informative afternoon the Seidel
yeah thank you President Schweiger for this nice introduction and very warm
welcome also from my side to all of you particularly to Jan Leckardt to be here
today I wear two hats today one is I'm a member of the Bavarian AI Council we
are 20 members appointed by the Bavarian state government as part of their high
tech agenda from universities research institutions and also companies in the
field to advise the government on AI strategies and actions particularly in
steering the Bavarian AI agency so the representative is also Dr. Klimke which
promotes the Bavarian network which we call biosphere so the logo is there as
well so the biosphere comprises a variety of strong AI players in Bavaria
also universities research institutes from all over Bavaria as well as a lot
of the global companies we have here including Google, Microsoft, IBM but
also the locally sitting global players Siemens, BMWs, every insurances Munich
three Alliance and so on but also many original small and medium enterprises
and startups in the field of AI so the second hat I am aware today's I'm one
of the four directors of the Munich Center for Machine Learning one of the
co-directors Daniel Gremmels also here and we this is a consortium of LMU and
Tom funded by the BNBF in the Bavarian high-tech agenda with around 50 PIs in
machine learning in the I3 junior research groups recently established
around 200 doctoral students and our focus is on foundations of machine
learning where we have several players including Gitta Kottiniok from the
mathematical part and statistics and computer science is there then perception
we are particularly strong in computer vision here and in Munich and in natural
language processing the two big things where humans and computers interact
and a lot of domain specific things it's not on research but also on transfer
activities fostering the collaboration network together with the biosphere
outreach to the general public things like that if you're interested also
openings of course so this is that part so I'm sure we get fully inspired by
your presentation and between your presentation is now the next is Dr. Mayer
from TASS, you're on stage, thank you ladies and gentlemen may I also welcome
you warmly on behalf of the Center for Advanced Studies at LMU and let me
briefly say a few words about this institution and how it comes into play
the Center for Advanced Studies at LMU was founded 15 years ago to provide a
forum for precisely those research questions that cannot be tackled by
only one discipline this was intended to take account of an increasingly
diversifying but also specializing body of research that is becoming more and
more disparate not only in terms of content but also in terms of space in
Munich you can just think of the campus in Ober-Schleishheim, Ober-Guy-Ching,
Nordeid in the far south so the Center for Advanced Studies offers the place
where these centrifugal forces can be bundled and for what topic does this
task play a more important role than for artificial intelligence which is
spread across most faculties of LMU and other universities it was therefore a
great pleasure for us when Gitta Kutinyok freshly appointed at our
university approached us and asked whether a form it could be found that
would network research on AI at LMU and unable to discuss overarching issues
together it wasn't long before a so-called interdisciplinary CAS
research focused entitled next generation AI was born bringing together
researchers from 14 faculties working on the topic of artificial intelligence
over the course of two years a wide variety of lectures workshops and
conferences was organized and held and we were thrilled by the spirit that
emerged of that group that's why we look forward to Professor LeCun's lecture
today with both a smile and a tear as it marks the formal conclusion of the
research focus we are honored and grateful that Professor LeCun is going
to give the lecture in this framework today yeah also a warm welcome from my
side to everyone here on site and also to everyone who participates via
live stream it is wonderful to have so many people with us here this afternoon
and a great thanks to all of our cooperation partners for actually
making this lecture possible and here I would like to particularly thank Dr
Anette Meyer and the Center for Advanced Studies of the Ludwig Maximilians
University MÃ¼nchen Professor Dr. Markus Schweiger and the Bavarian Academy of
Sciences and Humanities that this event can take place here in the academy in
these really beautiful rooms Professor Dr. Thomas Seidel and Dr. Michael
Klimker from the biosphere the Bavarian Eye Network which made the live stream
for the event possible and also Dr. Christoph Egle from the Bavarian
Research Institute for Digital Transformation and now it's my great
pleasure and honor to welcome Professor Jan LeCun thank you very much for
accepting our invitation and for coming to Munich for this lecture today
Professor LeCun is chief AI scientist at Meta and the silver professor of
computer science at New York University he started his career with a PhD in
computer science at Sorbonne University in Paris and then moved to the US where
he became the head of the image processing research department at the
famous Bell Labs the AT&T Bell Laboratories then after intermediate
stations he joined New York University in 2003 and he also became there the
founding director of the NYU Center for Data Science in 2012. His groundbreaking
work includes among many others the development of convolutional neural
networks which are the state-of-the-art for basically any problem in particular
imaging sciences and computer vision and a particularly particular convolutional
network architecture is also named by him the so-called LeNet which in
sense also promoted the impressive development of deep learning and AI as
we experience it today. His contributions are honored by numerous awards many more
than I could name here let me just mention that he's a member of the US
National Academy of Sciences and the National Academy of Engineering he
received various honorary degrees for instance from EPFL, received the IEEE
neural network pioneer award and in 2019 the Turing Award which is typically
referred to as the Nobel Prize of Computing and just a few weeks ago we
already heard at the Time Magazine and congratulations to that has selected him
as one of the 100 most influential people in AI worldwide and he also
repeatedly contributes to the public debate about AI with also controversial
proclamations for example on the current craze around large language models. How
could machines to learn as efficiently as humans and animals? How could machines
learn to reason and plan? In his lecture Professor Jan LeKang will now talk about
a possible path towards an autonomous intelligent agents based on a new
modular cognitive architecture. Where come Jan? The floor is yours.
Thank you very much for the introduction and thank you very much for
inviting me for coming here so so numerous. I have to correct one thing
though I did not call convolutional net solonet this was my lab director at Bell
Labs who gave it that name I would never done this but it's a good name okay it's
a long title and a long subtitle objective-driven AI this is what I call
this I used to give this talk with the title autonomous machine intelligence
and and it scares people you know they say do you mean machines that will be
autonomous we're not going to be able to control them so I changed the name to
objective-driven AI because that's really more accurate and they're really kind
of systems it's an aspiration it's not something that we've done it's something
that we should do and there are systems that could of course learn remember
reason plan have common sense be steerable controllable safe and have the
same kind of learning abilities and intelligence that we observe in animals
and humans so let me start by a little bit of the state of the art okay because
there's a lot of debates today about about AI and a lot of people are afraid
of AI it's understandable whenever there is technological revolution people are
afraid of the unknown and AI is promising to be a big revolution so people
are afraid so let's first talk about the benefits before we talk about the risks
and the benefits are of AI are numerous already today and there is you know even
more coming in medicine particularly in imaging diagnosis assistant treatment
protocol drug design things like this very promising research transportation
every car sold in the European Union today has to come with what's called a
automatic emergency braking system a system that will automatically stop the
car there is an obstacle in front of it and the driver does not react this
saves lives it reduces frontal collision by 40% so AI saves lives and that uses
convolutional nets by the way and in all the systems that I know in fact Germany
was kind of a and and a very in particular was a pioneer in this some of
the early systems of this type was the word developed by them events so driving
assistance autonomous driving energy storage and management things like that
environmental environmental monitoring and protection I'm going to say a few
words about this content information and management this is probably the biggest
use of AI today and of course in industry manufacturing information systems
quality control etc a lot of applications are expected also in things like
education for personalized education connecting people with each other with
translation today presence augmented reality virtual reality and then
enormous applications in science biology and genomics neuroscience physics
particularly physics of disordered systems complex systems very large-scale
simulations chemistry material science very promising area for AI so this well
really and of course you know we've been talking a lot about creation like
creating art AI is essentially enabling a lot more people to be creative people
who don't necessarily have the technique the underlying technique for
producing art so I will affect every aspect of human activity and let me give
you a couple examples so this is a video that was put together by my colleagues
at meta a couple years ago this is already sort of aging if you want and we
chose the capability of computer vision system as of about two years ago so we
can have systems that detect objects and put frames around them give them a name
they can track human bodies and figure out in what what pose they are densely
actually so that's actually very useful for all kinds of applications and more
interestingly we can have systems that perform what's called semantic
segmentation which means isolating every object marking them with kind of a mask
and then giving them a name for a category and this works for a very
fine-grained category for example the species of a bird or or plant or
something of that type so it's pretty amazing it's not like computer vision is
completely solved in fact if it was solved we wouldn't have the large
conference that takes place in Paris next week called ICCV so there's still a
lot of work to do but but there's been a huge amount of advances there and a lot
of advances in AI but no advances in my slides for some reason okay my
presentation refuses to advance hang on just one minute one second
okay I mentioned medicine so certainly medical imaging is an area where a lot
of work is going on there's too many to cite really this is some work by some of
my colleagues at NYU that use 3d image recognition not just 2d in some cases
this is actually 2d but that use various techniques to detect for example tumors
in mammograms or particular things in MRI and other types of images and
almost a lot of progress there some product project that took place a few
years ago which was a collaboration between the NYU radiology department and
people at fair Meta's fundamental research lab which essentially allows to
accelerate the data collection for an MRI by a factor of 4 without degrading the
image quality so instead of having to lie down in a MRI machine for 40 minutes
or something you can reduce this to 10 minutes and have the same quality of
images and that's thanks to deep learning essentially a lot of applications in
science what's interesting today is that the favorite model that neuroscientists
use to explain how the brain works use artificial neural nets so the best
explanation for what we observe using functional MRI data in the visual
cortex of humans and animals are actually models that are essentially
convolutional net models and that's kind of a closing the circle because the
architectural convolutional net is actually inspired by the architecture of
the visual cortex classic work in neuroscience from the 1960s the similar
work also in language understanding this is a recent paper in science by some
colleagues from from from it actually and they try to figure out if the
current large language models that everybody is playing with explain the
what we observe in the brain when people are asked to kind of remember or
understand a story and the answer is sort of but not really it doesn't work nearly
as well as a convolutional net models for vision so what that means is that
we're missing something that those models probably are not sufficient to
explain what the brain does when when we understand language I mentioned some
applications in science in particle physics in particular high energy physics
to kind of make models of particle collisions and things of that type image
processing to discover exoplanets some estimate says that about 12 percent of
all physics papers today actually mention AI as a tool that he used which is
astonishing in just a relatively short time and in the large-scale simulation
sort of universe scale simulation that could sort of validate or invalidate
certain theories about dark matter and things I guess so very fascinating work
and applications this is a very interesting project that was started by
some of my colleagues at fair by Larry Zittnick in particular called the open
catalyst project and you can actually participate if you want the website is
open-catalyst.org and and that project the idea of that project is that we
could solve climate change if we had a good efficient scalable way of storing
energy if we had a good way of storing energy we could cover a small desert
with solar panels and produce enough energy to power Europe or the entire
planet the problem is you have to have a way of storing energy which is why
renewables today despite the decisions of the German government to go all out on
it renewables are not drivable you can't control whenever there is wind or sun
and so you need another source of energy when there is no no sun or or no no
wind and and for that you need to be able to store energy and ship it wherever
it's needed the best way to store energy is in the form of hydrogen or maybe
methane and the best way to do this is by separating hydrogen from oxygen from
water right so take some water put two electrodes and then separate hydrogen
from oxygen problem with this is that it's either scalable if you use catalyst
to do this like platinum sorry it's either efficient if you use catalyst like
platinum or it's scalable but not efficient and so the big question is
could we design compounds new catalyst that would facilitate this reaction so
that is efficient but does not require exotic materials like like platinum so
that is scalable and the idea there is that you do a lot of chemical
simulation that's called DFT simulation of various of water on two various
compounds and then you generate that data using simulation and also using
experiments you put that data you make it available and then you ask people can
you train machine learning system to figure out what the underlying rule is
so that we can use it to design new materials that might have the same
effect but be cheap so fascinating program it may not work but it's worth
a shot okay now what's important to realize is that the progress we've seen
over the last few years in AI and machine learning are due to a set of
techniques that we call self-supervised running which I'm sure many of you here
in the room have heard about and essentially self-supervised running
would be a set of techniques that allows a system to be trained to represent the
data the world without requiring labeled data okay without requiring sort of
manual human intervention to produce the data so perhaps the best success of
this idea which I've been advocating for a long time is in the context of natural
language understanding so the way all NLP systems are trained today whether
there are LLMs of the types that we play with or others is the following you
take a piece of text a sequence of words and you remove some of the words you
you mask you mask them you blank them out you replace them by a blank marker okay
you corrupt essentially the input and you put it at the input of a large neural
net you train this very large neural net usually usually a transformer
architecture to predict the words that are missing in the process of doing so
the system has to extract representations of the text that contain the
semantics the syntax the you know grammar everything I sort of lied slightly
here these are not words that are input they are what's called tokens which are
essentially subword units so in most languages words have a prefix and a
root and a suffix and you need to kind of separate those for those systems to
work properly otherwise your dictionary of words would be gigantic and then in
German you have to do it because you can have words that are long like this
they are you know by so so there is no choice you have to break up words into
subword units you know in tokens and so you train that you train the system and
and this is the so-called BERT model if you want or idea and that's me
incredibly successful it's completely self-supervised you don't need any other
data than the text and once you've pre-trained that system you can use the
internal representation produced by the system as input to a subsequent task a
downstream task like let's say translation hate speech detection you
know summarization whatever so that's the general idea of self-supervised
running fill in the blanks have a big piece of data corrupt it in some way
and then train some big neural net to fill in the blanks or or recover the
original data a particularly stunning example of this which I'm not going to
go into the technical details of but I will later is a system they came out of
my colleagues that in Paris that fair Paris called Dino v2 you can think of it
as a foundation model for vision so it's a system that is trained to extract
features from images such that those features can be used for anything you
want whether it's classification fine-grained classification depth
estimation semantic segmentation instance retrieval so the same kind of
application that I showed in the video but basically with very little
supervision this is then it's pre-trained and it basically because it's
pre-trained on enormous amounts of data just training a very shadow head to
solve any particular one of those problems actually beats the state of the
art for that's estimation or classification or whatever you can
actually play with it interactively that's the URL that you see here and
these are some examples of visualization of what the features that are
extracted are it's kind of a you know colorful representation of the like
different feature vectors are represented by different colors this is
actually kind of each color is like a principal component if you know what
that is so those are you know examples on sort of typical typical images and
people I've started to use this for all kinds of stuff for biological image
analysis for astronomy for for environmental protection so that's the
next example I'm going to show you so this is a project by someone on the team
Camille Coupri and a large collection collection of collaborators and what she
did was use the Dino V2 features and trained relatively small system on top
of it to tell what the height of the trees are from a satellite image so we
have lots of satellite images on the entire world at half meter resolution
you can get this from a satellite imaging companies and for some areas
there is LiDAR data which tells you how tall the trees are so you use that to
train the system and then you can apply it to the entire world and what it tells
you is how much how much carbon is captured by the trees if you know
roughly what the height of the tree is you know roughly how much carbon is
captured in the tree that's super important to know like you know should
we protect forests of course we should should we plant more trees where things
like that so very interesting this publications on this where you know
everything is detailed and everything another success of self supervised
running of the type that I showed for natural language processing where you
remove some other words is in biology proteomics particularly so you can the
protein is a sequence of amino acids and we know hundreds of millions of them so
you take a sequence of amino acids you remove some of the amino acids and you
train some gigantic neural net to predict the amino acids that are missing
the system kind of learns to represent sequences of amino acids that
constitute proteins and then you use that representation as input to a system
that predicts the conformation of that protein how it folds well they can stick
to another protein a particular location so there's a famous work by our
colleagues at DeepMind at Fairfold but the this idea of using pre-trained
transformers for protein was actually first published by my colleagues at fair
they're actually no longer at fair now they have left Fairf to create a startup
around this around this idea but it's incredibly successful thousands of
research groups around the world are using this kind of data is actually a
atlas of folded protein contains 600 million proteins or something like that
with the structure that is predicted it's called the ESM metagenomic atlas and
ESM atlas.com a very big tool for biologists that really may change
completely the way we do drug design and understand the mechanisms of life
another very impressive project here that required a lot of effort is a project
called no language left behind again from fair collection of people from the
various sites of fair and this is a system that can translate 200 languages
from in any direction and when you look at what those languages are it's a lot
of languages most of them we never heard of in you know square corners of the
world but it's important for people to be able to preserve that culture that you
know they can speak their language and basically be understood using automatic
translation so what's interesting about this is that there are four thousand
directions for translation but the data only covers 2400 of those pairs
among the 40,000 despite that because we train a giant transformer to represent
language regardless of the language the system takes advantage of the
similarities between between the language families to actually kind of
extract a multilingual language independent representation of language
which allows the system to do translation in any direction including
four directions has never been trained on that's pretty amazing pretty small
model but today standard only 54 billion parameters I mean sizable the same team
now as another project called seamless which was was announced a few weeks ago
they can do speech to speech speech to text text to speech and text to text
translation as well as speech recognition speech synthesis etc speech to
speech is interesting because it can do translation for languages that are not
written directly from speech to speech that system can handle a thousand
languages which is really impressive okay so applications of deep learning that
are less visible perhaps is that deep learning or AI connects people to
knowledge and they connect people to each other the biggest deployment of
machine learning today is probably in social networks and online services like
like search engines and if you take deep learning out of Google or Meta or
Microsoft companies crumble they literally are built around it so deep
learning helps us deal with the information deluge for doing things
like search and retrieval ranking question answering things like this but
and that requires machine to understand content of course for
translation which is very useful for people who are not literate for example
or people are blind or visually impaired so there's three billion people in the
world today who can't use technology because they basically can't read more
or less so here's the biggest use of AI today filtering out illegal and
dangerous content and this is something that's very hard to do it's impossible to
do perfectly but to tell you to give you an idea of how much progress AI has made
those idea of pre-training transformers and stuff like that the
proportion of hate speech that Facebook was able to take down automatically five
years ago was about 20 to 25 percent okay it was using sort of fairly simple
machine learning techniques NLP methods of the types that were common five years
ago and then self-supervised pre-trained transformers happened and that number
went to 95% last year and it's just progress in AI so a lot of people that
we hear talk about AI who generally don't know much about AI actually tell you
about all the dangers of AI that then you know AI is going to destroy I don't
know democracy because of disinformation and things like that what they
don't understand is that AI is actually the solution to those problems it's not
actually the problem it's the solution to those problems and it's already the
case that doing content moderation on social networks makes massive use of the
latest advancements in AI and the people who try to corrupt that system are not
sophisticated in terms of their AI so something that needs to be known okay
but everybody is excited about generative AI and autoregressive large
language models and things of that type right so many of you certainly I'm sure
have played with those image generation things where you type a text and
outcomes image and this is the state of the art about a year and a half ago from
either a meta and make a scene system or a penny I dali to or Google's image and
as of yesterday this is what you get out of meta so this is actually from a
paper and you can get the paper from archive it's there but there's a product
attached to that paper called emu it's an acronym but actually don't remember
what it means and what the system can do is in it can generate images from a
text prompt and it was rolled out as a product yesterday as well as the paper
right so it's one of the things where like the science the research the
technology and the product come out to the same day pretty crazy and this is
available in Facebook Messenger if you use Facebook Messenger you can you can
ask to talk to meta AI that is the name of the intelligent virtual assistant
at meta the generic ones and then if in a font you type backslash sorry forward
slash imaging and type a text then the system will produce an image in five
seconds this used to take minutes the results are pretty amazing the same team
is is working on synthesizing video this is actually some work from about a year
ago they're making progress on sort of practical things of this type okay but
how do those LLMs those large language models you know that you can talk to how
do they work they are autoregressive right so what that means is they are of
the type that I talked about before you take a text and you remove some other
words and then you turn train assistant to predict the words except it's a
special case where you only train the system to predict the last word okay to
take a long piece of text remove the last word and train this gigantic neural
net to predict that last word and if you train the system this way you can do
what's called autoregressive prediction which means give a text predict the last
word or the next word then inject that into the input and then predict the next
next word and then shift that into an input produce the third word etc.
Autoregressive prediction and it's amazing how it works there's a whole
bunch of those models around actually I typed that list a few a couple months
ago and now there's a whole bunch more but Blunderbot Galactica Lama Lama 2
from from meta which is actually a open source code Lama that came out in July
which is basically Lama specialized for generating code Alpaca Lambda Chinchilla
chai GPT the various incarnations of chai GPT and then there is one that came
out just a few days ago called mistral via a French startup in Paris formed by
people who used to be at fair and deep end actually that's interesting so
performance is amazing for those systems right we've all been surprised by it but
they do make really really stupid mistakes they don't really understand the
world they they're trained to produce the most likely sequence of words that
follow a particular prompt and then they're kind of fine-tuned to sort of
work well for particular types of questions but they make factual errors
logical errors they are inconsistent they don't really have reasoning abilities
it's very easy to kind of chorus them into producing toxic content they really
do have a limited knowledge of the underlying reality because they're
purely trained from text they don't have common sense like a cat can have common
sense and they can't plan their answer so you can you can play with Lama so
basically the chatbot I just mentioned meta AI is sort of a productized
version of Lama too if you want and it has various incarnations actually various
personas that you can call and there's three models the production model is a
different one but it's open source you can download it if you're a big enough GPU
you can read it on your GPU there's a lot of people working towards running those
models on mobile devices and laptops and things like that and they they can
generate text this is a funny one so in the early days of Lama my colleagues
kind of interrogated that so they typed into Lama did you know that Yanlok
dropped a rap album last year we listened to it and here is what we thought
and this and the system writes a critique of my alleged rap album so they
showed this to me and they say is it okay if we put this in the paper and say
yeah sure no problem but I said like could you do this with jazz because you
know I'm like I'm rap is okay but like I prefer jazz really and they told me yeah
yeah we tried and it didn't work because there's not enough training data for
jazz so I cried so as I was saying you can fine-tune the system to sort of play
different roles and what Mita announced yesterday is that is 28 different
chatbots that are specialized for different applications so think for
example you can have Snoop Dogg a rapper be a dungeon master if you are into
dungeon and dragon or text adventure games others that are like advisors for
traveling others that are cooks or or sous chefs or whatever so different
but those things really suck I mean they really not that great because they
don't understand the world they just manipulate language because they
manipulate language fluently we're fooled into thinking that they are
intelligent but they're not intelligent in certain ways but they're not
intelligent in sort of what we think as as human intelligence so you will see if
you go to X from a Twitter or any kind of social networks people who make
posts say oh there is a latest LLM from so-and-so company and you type this and
it's mind-blowing you know we are this far away from human level intelligence
what I call a GI I hate the term and you know it's for tomorrow like you know all
the naysayers are wrong blah blah blah it's just happening tomorrow they are
wrong okay this those things do not have anything close to human intelligence
they appear to do to have to have it because they're trained on so much data
that they've accumulated an enormous amount of background knowledge
approximately that they can regurgitate approximately so whenever they seem
intelligent it's usually because they can do information retrieval in an
approximate way that sort of looks reasonable but they cannot possibly
understand how the world works because their only training data is text and
most of human knowledge this may surprise you but most of human knowledge has
nothing to do with language it has to do with our experience with the world
every day physics another limitation that people have been pointing out
increasingly with various papers is the inability of those LLMs to plan so an
LLM produces those tokens autoregressively as I explained earlier right they
don't plan their answer they just produce one token after the other and
whatever token they produce will determine which token they produce next
because it's autoregressive there is a process by which the system is basically
an exponentially divergent process the system makes one mistake that takes it
out of the kind of correct set of answers it cannot recover and so this
entire architecture of autoregressive prediction in my opinion is is inherently
flawed and my prediction is that within a few years nobody in their right mind
would use autoregressive LLMs okay everybody is working towards something
better because those things are major flaws now what's the issue though is
that there's a lot of people who are scared about future AI systems that may
have the may attain attain human intelligence or or be more intelligent
than humans and if you extrapolate from what LLMs currently do you might think
well it's gonna be very dangerous because those systems cannot really be
controlled they can spew complete nonsense they can be jail broken blah
blah if they are smart they might be dangerous that's a big mistake future
AI systems will not be using this particular blueprint they're not going
to be autoregressive LLMs okay and I'm going to tell you what I think it will
be okay so autoregressive LLMs suck I just said all that no reasoning no
planning essentially right the amount of computation devoted to producing a
single token by an LLM autoregressive LLM is constant there's a constant amount
of computation per token produced so there's no possibility for the system
to for example think about something for a long time before saying something it's
cannot do that by construction so machines do not of this type do not
learn how the world works unlike animal and animals and humans they will not be
able to approach human intelligence okay so whatever I don't know the CEO of some
company that thinks they have the best LLM in the world tells you a GI is just
around the corner don't believe that we're still missing some major advances
but there is absolutely no question that eventually machines will surpass human
intelligence in all domains okay it's basically no doubt about that and it's
going to happen during the lifetime of most people here maybe not me you know I
might take a few decades there's no question it's going to happen so these
are I think the biggest challenges for AI going forward learning representations
and predictive models of the world and I'll tell you why in a minute and that's
what's addressed by self-supervised learning so we have good handle on this
at least for text not so much for video learning to reason so if some of you know
about Daniel Kahneman's theory of system one system two sort of subconscious
things that we do without thinking and then conscious things that we have to
focus our attention on LLMs currently can do system one but not system two we
need to build AI systems that are capable of reasoning of the type that Daniel
Kahneman calls system two is a Nobel Prize winning well he won the Nobel Prize
in economics but is a psychologist and one possible path towards a solution
that I've been proposing for about a year now you're gonna have is what I call
this objective driven AI so this paper I put on open review it's not on archive
it's an open review because on open review you can make comments and and this
is a working document more than a kind of finished paper if you want it's long
though you can also listen to technical talks I've given about this are a
little more technical than the current one and it's based on this idea of a
modular cognitive architecture where you have a system composed of multiple
modules first module be the perception so it's represented overlaid over the
back of the brain because in the human brain perception is in the back so
perception basically perceives the world and then constructs an estimate of the
state of the world right so it produces an estimate of the state of the world
perhaps it needs to combine this with the content of a memory that contains you
know other information about the state of the world that is not currently
perceptible and then that goes into a world model and the role of the world
model is to imagine the outcome of a sequence of actions okay so the system
can imagine a sequence of actions that's the role of the actor the yellow
module so the actor imagines a sequence of actions fits that to the world model
the world model knows the current state of the world and what the world model
predicts is the future state of the world that will result from that sequence
of actions now that cannot be a perfectly exact prediction because the
world is not entirely predictable but that's the the the role of the world
model and then the entire purpose of the system is to figure out a particular
sequence of actions that will predict a state of the world that satisfies a
certain number of constraints that are implemented by the cost module so the
red module that you see this cost module that that's the drive of the system
that's the the current goal of the system if you want and the entire purpose of
the system so imagine this module as getting the predictions from the world
model and then computing a cost for it right so basically it computes the degree
of in comfort of the system discomfort and what the system does is that it
figures out internally a sequence of actions so the actor does that it figures
out a sequence of actions that will minimize its cost according to the
predictions of the world model okay and this is very much system 2 type it's
very similar to what you know people do classically in optimal control it's
called model predictive control and it's really like this right observe the state
of the world get an initial world state representation combine that with what
you think about the state of the world from your memory feed a sequence of
actions to your world model and ask the world model to predict where the final
state will be then feed that to your objectives the objectives might
implement the goal that the system has set for itself or that you set it for
it but also you can have a number of guardrails so might be a guardrails if
we have a domestic robot that is cooking has a knife in its hand because it's
cutting onions or whatever you might have a cost that says if you have a knife
in your hand and there are people around you don't move your hand too fast okay
don't flail your arms right so maybe dangerous so you can imagine all kinds
of guardrails of this type to basically ensure the safety of the of the system and
the system has no choice but satisfy those because they are satisfied at
inference time they're not it's not like RLHF for LLMs reinforcement learning
through human feedback where it's a it's a training time fine-tuning to make
sure the system produces only safe behavior the system can always produce
unsafe behavior by you know being prompted something that the the people
training it didn't think of it didn't think about here that's impossible the
system cannot produce a sequence of actions that will not satisfy the
guardrails according to the world model so those systems would be intrinsically
safe provided two things provided that the guardrail objectives guarantee the
safety and that's complicated also provided that the world model is accurate
and that's also complicated so you can imagine something like this that works
over time so that you know you can have a sequence for example in this case
sequence of two actions you can have and again this is very similar to what
control theory is called model predictive control except here we're
learning the world model and possibly learning the cost as well you might want
to imagine the system like this that does hierarchical planning humans animals
do hierarchical planning all the time it's a essential characteristic of what
we can do and we don't know how to do this at the moment we have some ideas
working on it but it really doesn't work like if there is like a really good
opportunity for young scientists or aspiring scientists to really solve a
problem like try to see if you can do something about hierarchical planning
because it's really hard but the payoff if you can do it I think is enormous so
a good example of this is let's say I'm at NYU in my office at NYU and I want to
go to Paris okay so my objective is my distance to Paris I want to minimize my
distance to Paris at a high level I can say well first thing I need to do is go
to the airport and then catch a plane and there is a latent variable that may
indicate like which airport I'm choosing depending on traffic or whatever or what
airline flights at what time okay now how do I go to the airport well I have
to go down in the street and catch a taxi you can do this in New York you can
just tell the taxi in the street how do I go down in the street I need to stand up
for my chair open the door go to the stair staircase of the elevator how do I
get out from my chair I need to kind of push with my arms or something or or
turn my chair and then you know you imagine you can imagine decomposing this
all the way down to millisecond by millisecond muscle control I'm not going
to plan my entire trajectory from my NYU office to Paris in terms of millisecond
by millisecond muscle control that would be classical planning it has to be
hierarchical and people can do this today I mean engineers do this in control
but those various levels in a hierarchy are designed by hand the question is can
we train a machine to automatically learn what the proper hierarchical
representation of the action plan is and that's the answer problem yeah you're
looking to do a phd or something or two or three that's a good problem
we could use techniques like this for LLMs so LLMs that would be non-auto
aggressive instead of producing one token after the other they would basically
infer a sequence of tokens that would satisfy a number of objectives on a
guardrail an objective that measures to what extent you're answering the
question and an objective that measures to what extent the answer is non-toxic
or toxic or whatever right that would make LLMs controllable nothing like
this works today right again if you are looking for a good topic for a phd that's
a good one ultimately we need machine to learn to understand the world that's the
purpose of that world model the essential central piece of that architecture
I just talked about is this world model given the state of the world at time t
given an action I might take or a sequence of actions what is going to be
the state of the world at time t plus one or t plus whatever and humans and
animals are amazingly good at this babies learn how the world works in the first
few months of life at an amazing speed and they learn an incredible amount of
background knowledge about the world first thing you learn is that the world
is three-dimensional then you learn that something like object permanence the
fact that when an object is hidden behind another one it still exists okay
five
and babies learn things like basic notions like gravity in the around the age of
nine months takes a long time to learn intuitive physics like like inertia
gravity things like that okay but it's mostly just by observation a little bit
by experimentation and we don't know how to reproduce this kind of learning with
machines and that's why although we have fluid systems that can pass the bar
exam or medical exams we don't have robots that can clear up the dinner table
and fill up the dishwasher something that any 10 year old can learn in one
shot in a few minutes we don't even have completely autonomous level five cell
driving cars even though any 17 year old can learn to do this within 20 hours
and then drive at 300 kilometers an hour on the Autobahn you know obviously we're
missing something really big with machines that humans and animals can can do
in terms of learning that learning efficiency that we don't we don't know
how to reproduce so we need this ability to learn world models to get machines to
learn world models from video essentially from natural signals and so
this is idea of self-supervised learning but now apply to video not text and it
turns out text is easy text is easy because text is discrete and finite it's
only a finite number of possible tokens in every language on the order of 30
thousand or something and so it's easy to predict a distribution a probability
distribution over the next token you can represent it by a long list of numbers
between 0 and 1 that's on to 1 but if you want to predict video you can't do
that because we don't know how to represent probability distributions over
all possible videos at least not in a good way so if you train a neural net to
predict what happens in a very simple video this is over overhead video from a
highway you get this kind of prediction very very blurry prediction because the
system can only predict the average of all the possible things that can happen
and it can't make make up its mind so the solution I'm proposing to this is
something I call joint embedded joint embedding architecture okay or joint
embedding predictive architecture JEPA and this is a non generative
architecture so everybody is talking about generative AI what I'm telling you
here is abandoned generative models okay so not only am I telling you AI is not
gonna kill us but LLM suck machine learning sucks and generative models
suck right all the popular things at the moment okay so a generative model
predicts you know if you have an observation x you're trying to predict
y just predict y from x using an encoder and some predictor right but what
problem with this is that you have to predict every single details of y and in
video that's just too much in text it's okay it's just like you know what word
okay you don't know exactly what word but it's okay in video it's just not
possible so what you should do instead is what's on the right here the joint
embedding architecture where you run both x and y through encoders the
encoders eliminate all the irrelevant details about the input and the
prediction takes place in representation space okay so joint
embedding predictive architecture JPA there's several incarnations of this
I'm not gonna go to the details because I don't have time and you can read the
details in this long paper I can't read what's on it but I can imagine and that's
kind of the basic JPA architecture so let me skip ahead a little bit there's
two ways to train those JPAs basically two major techniques to train
those JPAs that cannot be understood within the context of probabilistic
methods but only within the context of what I called energy based models and I
was going to explain what this was but I skipped that section but you don't need
to know about energy based model to understand what I'm gonna say so there's
several methods to train those JPAs and this is a particularly interesting one
this is a paper that was published at CVPR just a few months ago it's called
image JPA and it's using this masking idea so you take an image you mask
regions of that image okay and you feed that partially masked image to an
encoder the encoder produces a representation and with that representation
you try to predict using another neural net predictor you try to predict the
representation for use from the full image okay and they both they run
through essentially identical encoders so not identical one of them uses
something called exponential moving average weights but but but they're
almost identical and and that works amazingly well so you you train the
system this way pre-train it with images that you corrupt by masking them
partially and you get amazing result on using the features that are produced by
that system you get amazing results for classification for segmentation for all
kinds of stuff and the Dino method I told you about before is very similar to
this it uses kind of a slightly different way of encoding the outputs but
it's it's in spirit it's very much the same idea and it gives really good
performance on image recognition on transfer tasks on all kinds of stuff
that I don't have time to tell you about okay but things we're working on today
that we need to work on because we don't know how to do it perfectly is self
supervised running from video so basically a version of this image JEPA
that would work for video and learn good representations of videos by
observing the world basically the same thing that babies can do right so we
have a project along those lines V JEPA and we have a paper that we're just
submitting to a conference that some of you probably know what it is because the
deadline is today well actually if you know what it is you're probably not here
you're working on your paper I think the deadline is passed by two hours so maybe
maybe you're here so then you would be able to use those JEPA as world models
right because you know you have an input and you can feed it maybe a set of
actions that an agent might take and it will predict a representation abstract
representation of the state of the world at the next time step and so this could
be used perhaps as a world model as one of the components of the big
architecture I introduced earlier okay okay I said that already all right so
there's quite a question that we need to answer with AI and this is my second
last slide how long is it going to be before we reach human level AI years to
decades probably decades it's probably harder than we think it's certainly much
harder than what the most boasting people believe there's many problems to solve
along the way and before we get to human level AI we're going to get to
something like cat level AI okay so people who are scared that you know
one day someone is going to discover the secret of human level AI is going to
turn on this gigantic computer and that gigantic computer is going to take over
the world and kill everyone that's just ridiculously stupid just cannot possibly
happen we're gonna start small we're gonna you know start with something that
has all the right components but it's small it's not gonna be very smart it's
gonna be like a rat or a cat right and then we're gonna work our way up and you
know change the objectives to make sure it's safe and test it in all kinds of
sandboxes and blah blah blah so this idea somehow that you know the discovery of
AI is going to be an event and that machines are going to escape for control
that's Hollywood movies it's not the real world there is no such thing as a
GI anyway because intelligence is really a multi-dimensional thing humans are
only good at certain things and terrible at many things in fact our minds are
extremely specialized we don't realize this but we're incredibly specialized and
we know this because computers are much better than us at many tasks for example
chess go poker pretty much every video game I mean not today but eventually
recognizing a species of a bird by just listening to the song recognizing an
individual whale or marine mammal by the shape of the tail like AI systems can do
this a very small number of humans can do all of this I mean we just we totally
suck at chess as humans machines are much better than we are and so we don't
have general intelligence ourselves so this word a GI makes no sense human
level yes a GI no there's no question as I said before that machines will
eventually surpass human intelligence and so people are scared by this but
really is a interesting question to ask ourselves imagine a future maybe 20 years
from now or maybe longer where every single one of our interactions with the
digital world is mediated by an AI system okay and it might happen faster
actually okay if some of the startups are being created today and some of the
big company plans product plans actually fulfilled this may happen fairly
quickly that essentially every time that we want to connect to the digital
world that will be through the intermediary of an AI system then those
systems will become the repository of all human knowledge right and it's very
important for that at least the base for a foundation of this to be open source
every infrastructure the internet is open source runs on open source software
and the reason is because it's too important for one company to control it
right so it's the same for AI systems they will have to be open source because
it's too important for any single company or small number of Californian
company to control AI systems if all of our information of all the citizens are
basically filtered through those AI systems the way those systems will be
trained will need to be quite sourced kind of like Wikipedia to collect
culture and information and knowledge from the entire world not just from the
view of the world in parallel to us in place right so that's why I'm a huge
advocate of open source base models for AI and a number of my colleagues at
Meta and his company policy at Meta to open source those base models because it
makes them safer more powerful they progress faster they're more culturally
diverse if more people can train them and it creates an entire ecosystem of
startups and research projects that can build on top of it so it's a very
important political questions at the moment because a lot of companies are
pressuring governments around the world including the German government to
basically keep AI under lock and key to say AI is too dangerous it needs to be
controlled and licensed and and not put into the hands of everyone I think it's
the exact opposite I think it's too dangerous to actually keep in the hands
of just a few a few people okay so I became a little philosophical political
here those people have convinced the UK government the Prime Minister that
AI should be regulated under lock and key apparently the EU Commission also is
convinced this is very bad and I think if we do it right AI will make everybody
smarter it's like we all have those intelligent assistant with us all the
time it's like having a staff of intelligent people working for you okay
every person who is leading anything including me only works with people who
are smarter than them right I only hire people who are smarter than me because
that's the way to be successful so that everybody is gonna be like that we'll
have AI assistant that are smarter than us we shouldn't feel threatened by them
because we'll be controlling them they will be designed to be subservient to us
so this may have an effect on society similar to what the printing press had
probably 500 years ago not too far from here of basically causing a new
renaissance because intelligence is really the commodity that we lack the
most this will make humanity smarter thank you very much
yeah thank you so very much Jan for an amazing lecture we have about 10 minutes
for questions and I'm sure there are several so much for the great talk
customer from a minute you alluded to the fact that we should keep code open
which is great however as you know right many of the recent developments not
just rely on the code but also on the hardware so many of the things are
developed at companies because they have access to a large GPU resources now not
only Germany I guess we are limited by that so and what's your take on that
also being in an academic and an meta environment right how do you deal
yourself with it do you do some things only at universities and others only at
meta or how I mean how do you see that in the future okay should have used an
automatic speech recognizer because there is an awful echo and it's very hard to
understand it's not your fault but anyway I mean hardware is a big limitation so
currently the only entities they can train large language models that are
good are people who have access to large amounts of computation either in-house
which is the case for Google and meta and Microsoft or through cloud services
which is the case for open AI and entropy can others they have access to
Microsoft Azure and you know some of them use AWS some of them use other
other tools so but that costs a huge amount of money so training a sort of
top-of-the-line language model today you know costs tens of millions of euros
right it depends how many tens depends on how you do it possibly more if you
want to buy an infrastructure that is sufficient power today you have to buy
basically stuff from Nvidia and is going to cost you a number with with 10
digits it's in the billions it's insane so what that tells you is that it's like
it's like an autobahn you don't want 10 parallel autobahn going from one city to
another city you just want one and that has to be sort of accessible to everyone
so that's the idea behind open source base model foundation model they need to
be open source because it's a common infrastructure they can be customized
and there's no point having 50 of them because they cost so much to train that's
another argument for open source
hello yes hi thank you for the great lecture there was a slide that had
challenges of AI and machine learning and there were three points in there it
went by really fast and I couldn't catch if ethical fairness responsible AI was a
challenge that you're facing with and if so what are you doing about it okay so I
think that point was wrapped into the the second point but sort of not
mentioned directly it was more can I mention in the other thing so this idea
of objective driven AI the fact that a system can only produce answers that
satisfy a number of objectives including some guardrails the answer to your
question is how do you design those guardrails essentially we don't have an
answer to this and the reason we don't have an answer to this is because we
haven't really began to build systems of this type and so it's as if someone in
1925 asked aviators how are you going to make sure that transatlantic
transatlantic flight at near the speed of sound will be safe nobody could be
possibly answering this nobody across the Atlantic on a plane in 1925 at least
not in there not without any stuff nobody knew what a turbojet was like the
idea of you know speaking at near the speed of sound was completely
unthinkable so we're a bit in the same situation we don't know how exactly how
to make those things safe because we haven't built them yet but I think it's
an engineering problem like any other problem and there is a there's a fallacy
also which is that to design those objectives a lot of people say oh we've
never done this before so we're not going to know how to do it but in fact we are
doing this all the time we've been doing it for millenia designing objectives so
that intelligent entities behave properly that's called laws lawmaking is
designing objectives for humans to behave properly and it's even designing
objectives for superhuman entities to behave properly superhuman entities
like corporations for example right corporate law basically is a way to make
sure that whatever a corporation does is aligned more or less with the common
good of society right of course you know they can be corruption and everything
but that's the that's a big idea so we're very familiar with this with this
this concept it's not it's not new
and thank you Jan for the really great talk I want to follow up on the question
we had earlier about GPU resources what I see is that in machine learning and AI
the biggest breakthroughs in the last years were achieved with huge amount of
GPU resources the amount that academic institutions typically do not have do
you see a future for academic research in the field of AI so I'm gonna can make
myself I have two hats okay let me tell you something many of the best ideas come
from academia okay the whole idea of generating images from text and things
like this those actually came out of a German university right and then you
know people picked it up and made products out of it but originally this
was done not too far from here in the university the whole idea of using
attention mechanisms which is the basis of transformers they came out of
university Montreal so that was an interesting story they this was Dimitri
Bada now Kim Jong-chul who is now a colleague at NYU and Joshua Benjo and
they came up with this idea that when you build a translation system the system
should be able to decide which word to look at to translate you know English
into let's say German in fact German was the main issue because you know the
verb is at the end so it screws up all the translation system so so that was
actually the solution to that problem and and they came up with this idea of
this kind of learn attention mechanism and then there was a paper that that by
Chris Manning at Stanford that sort of picked up this architecture and made it
work at scale so they won the WNT competition a few months later and then
the entire industry jumped on it right and then you know as much people at
Google said oh you can build an entire neural net based on just this idea and
the title of the paper was attention is all you need and that was the
transformer and you know so the root of some of those good ideas are very often
in academia then the problems that I talked about you know how you do
hierarchical planning how you're done world models from video that kind of
stuff these are things you don't need enormous amounts of computation to
demonstrate the principle you may not be able to you know beat some benchmark
results or whatever but it doesn't matter if you show that a principle can
work and it's convincing enough then there'll be other people who pick it up
and actually build something real out of it it's okay that's the way you have
intellectual impact so if you think about your career and what drove you would
you say that more the dreams you had about what could be possible or you're
so interested in the topic let yeah just all the work you contributed to and how
that maybe change also over time yeah so interesting question I think at the
root of it is really a scientific question what is intelligence how does
the brain work you know it's a very sort of front and center big big scientific
question over time so right there's three big scientific questions is what you
know what's the universe made of what's life all about and how does the brain
work right three questions but then I'm kind of an engineer as well so for a
complex system like the brain the only way to really understand how it works is
that you build one yourself and you verify that like all the hypothesis that
you built into your system actually kind of correspond to what happened and it's
really the inspiration behind convolutional nets and multilayer learning
and the whole idea of neural nets in the first place right getting inspiration
from the brain but not copying it because you copied blindly you're not
gonna get anywhere you need to understand the underlying principles so
underlying the understanding the underlying principles of intelligence is
really what kind of drives me and then it's great if you have like multiple
applications whether they are useful or entertaining I mostly don't do this
myself but but I'm really happy with people do it
hello LeCun I want to ask you a question what's your opinion on the field of
embodied AI and robot learning I think it's very interesting because it's
deployed artificial intelligence techniques to change the real world yes
I completely agree so in fact in fact that's kind of one of the point that I
perhaps didn't make clear enough that this idea of world model as I said is
easy to do in the context of language which is why we have language models
that are so impressive but it's very hard to do in the context of the real
world data video things like that property of sensitive data from a robot
and so the good news about the good thing the good aspect of embodied AI of
like working with with robots whether they are real or simulated is that you
can't cheat you can't take shortcuts like representing everything as a word or
something although some people are trying to do that but so I think
focusing on this kind of type of problem I think makes people honest so I
think the most interesting advances in in AI over the last several years are
not in LLMs they are in people who do robotics and try to do control and sort
of make robots basically learn efficiently without having to be trained
by you know for hours in simulation this teams there's a colleague at NYU
Lera Alpinto who's working on this there is I mean I've grouped a colleague
Emelon and his colleagues and then probably the biggest group working on
this is at Berkeley Peter Abiel, Segelle Yvine and Chelsea Finn who is a former
student of theirs at Stanford those are really kind of interesting approaches
there this whole idea of planning objective-driven kind of planning you
have to do that in the context of robots so in that sense is very interesting
there's a whole division at fair that actually is called embodied AI for that
reason thank you yeah thank you so much Jan I mean this amazing lecture and I
think you're all very grateful that you shared your thoughts and perspectives on
future AI with us and I think we all got a lot of impulses from this today so we
have a small gift for you as well
thank you
yeah so let me also again I mean thank all cooperation partners who contributed
to this event so the Center for Advanced Studies biosphere the Varian Academy of
Sciences Humanities Munich Center for Machine Learning the Varian Research
Institute for Digital Transformation and the Konrad Susi School of Excellence in
Reliable AI and sorry I would like to have a special thanks to Dr. Ursula
Olinger who is science manager at my chair and who headed actually the
organization of the entire event so I think she deserves a small applause
yeah thanks also everyone for coming here and also for those who joined us
via live stream we now have we I would now like to invite you to a little
reception in this Sitzung Sal 1 and 2 which is here right around the corner
so thank you so much
you
