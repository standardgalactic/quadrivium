So I'm going to be talking about the book indeed, but I guess the most interesting part
of what I have to say is about chat GPT, and so I changed the title.
This is the book.
The subtitle is Artificial Intelligence Without Fear.
So we certainly don't need to be worried about the supposed fact that machines will one day
rule the world.
AI is a set of algorithms, of algorithms which belong to a certain kind of applied mathematics.
And these algorithms are very good.
They can do wonderful things.
And the fear that people have, and we are aiming in the book to set aside this fear,
is that one day there will be an algorithm of this sort which is able to provide an
intelligence which surpasses the intelligence of human beings.
And then once we have an AI algorithm like that, it would be able to write a new AI algorithm
which would be even more intelligent, and then we have an explosion of ever more intelligent
AIs, and eventually they would be able to use their intelligence to replace human beings
and to rule the world or the galaxy or the whole universe in principle.
This is nonsense.
This will never happen.
AI algorithms will be always much lower in intelligence than human beings.
Indeed, they will never have intelligence like the intelligence of human beings, because
they will always be what is called narrow AI, which means that they are intelligent only
in relation to one specific activity, for instance, playing the game of Go, and they
will never have the kind of general intelligence which we have and which would be needed to
take over the world.
So that's what we mean by artificial intelligence without fear.
There will never be the singularity when AI explodes and becomes more intelligent and
more powerful than we are.
So this is another way of formulating the main theses of the book, which rests upon
the mathematics of complex systems.
Complex systems, and that means all systems involving organisms, your brain, your digestive
system, you yourself, the system formed now by the people in this room.
All of these complex systems have evolutionary properties.
What that means is that they can change.
They can acquire new elements, new types of elements, new types of interactions.
And any model which can predict the behavior of a system breaks when you have new types
of phase space, they say, in physics.
We can't model complex systems mathematically.
Therefore, we can't emulate such systems inside a computer that follows trivially.
So this is the main thesis of the book.
The main chapter is about the mathematics of complex systems.
The rest of the book is about many things.
It's about intelligence, which I'm going to talk about next.
Human intelligence, what makes it special?
It's about attempts to emulate human intelligence by means of modeling in some sense biologically
the human brain.
I'm going to talk about that.
And then I'm going to focus my energies on chat GPT, which is, as I say, something glorious,
but it's also really, really, really bad.
And I'll try and prove that with some examples.
So an example of a system which is changing its phase space is the system of creating
spam, which is a system run by evil people whose life is devoted to creating these horrible
things called spam.
We can stop the spam using AI.
We can build spam filters, which are narrow AI in two senses.
One, they only filter out spam, but two, they only filter out spam of a sort and sort.
And as soon as new types of spam come down the pipeline, then the spam filters won't
work.
And this is what I mean by the impossibility of predicting the future, predicting future
behavior of a complex system.
Even a complex system as familiar as the system of spam creation.
All right.
So AI is always limited to simple systems in a technical sense.
So an AI algorithm like chat GPT is a huge mathematical polynomial function with billions
of parameters.
Google Translate is not based upon those complex systems which are human languages.
It's based on a frozen set of data, a corpus taken from the 96 or so human languages which
Google Translate translates.
And that corpus is then turned into a simple system.
And then Google Translate uses very large algorithms to create polynomial functions
which can take an input in German and yield an output in English.
And that's a mathematical application to binary vectors made up of zeros and ones which can
be translated as English sentences and binary vectors made up of zeros and ones which can
be translated as German sentences.
Google Translate is dumb.
It doesn't know anything about meaning or semantics.
It doesn't know what it's talking about.
It just performs a certain mathematical calculation.
Simply rather simple because it has to compute inside a Turing machine which is a relatively
simple kind of environment but incredibly long as an algorithm which explains why it's
able to perform such impressive feat.
So there is glory to Google Translate.
I think Google Translate is fantastic but it's not going to take over the world or anything
like that.
All right.
Now how does this work?
How does an algorithm like Google Translate work?
Well many people think that all you need is enough training data and then these things
called deep neural networks can be trained to use statistics in order to predict patterns
in those large bodies of data.
But this isn't quite right and even a lot of people in the AI world don't appreciate
this shortfall in the idea that all we need is mere quantity of data.
What we need is to be able to sample data which has a variance which is the same as
the target data.
So if we're going to take the sample data and use it to predict patterns in the target
data then the sample data has to be statistically like, it has to be a typical sample in other
words, like the target data.
It must be representative of the target data.
So what that means is that it has to have the same distribution of the target data and
this is the bell curve which is the simplest kind of distribution.
There are other kinds of distribution but the data you have has to have the same distribution
as the target data you're applying to and that's what Google Translate does.
It takes samples from all the world's languages and it is able to take them as representative
of the patterns in this frozen corpus that they use as a starting point.
Now there are target domains where there is no distribution and so there is no way in
which we can get representative sample data.
So this is true in an emergency room in a hospital in a big city.
You just can't predict how much blood will be needed or how many beds will be needed
or how many doctors will be needed even an hour ahead.
But it's true also of any conversation.
You can't predict what your conversation partner will say next.
Alright so this is an overview of what I'm going to talk about.
First of all I'm going to talk about human intelligence, actually animal and human intelligence.
Then I'm going to talk about the real reason why computers will never take over the world
which is the fact that they will never want to take over the world because algorithms can't
want.
They can only do what you tell them to do.
Then I'll talk a little bit about Nick Bostrom and his idea that we can build a super-intelligent
AI algorithm by emulating the whole brain of the human being.
And then finally I'll talk about the really funny story of chat GPT.
Alright so the big difference between organisms and simple systems is in one word it's thermodynamics.
So in other words it's a matter of physics which involves energy and we and all animals
survive because we have the drive to acquire energy from the environment.
Now we humans do this in a very complicated way involving things like supermarkets and
farms but every animal has a way of sucking energy out of the environment.
Every plant does this with the sun.
Even computers are driven in a certain sense.
They take energy from the environment but only because we give it to them and no one
gives us energy.
No one gives animals energy we have to go and find it ourselves.
If there is a surface of energy in our environment, in the ancestral environment of human beings
then we become obese because we like eating and so we keep eating and this eventually
will mean that we will eat so much that we use up all the energy in the environment and
then we die.
So gradually we moved out of the areas of the world where there was lots of food into
areas of the world which were cold and barren and so we had to find ways of surviving in
much harsher environments.
That's why through a long series of faltering steps we created civilization, police, armies
all the other things which make it possible for us to survive in a world where we are
competing with other groups for limited food supplies.
What civilization does, what social norms do is channel the excess dry which human beings
have.
In other words we become more rational and less instinctive.
But we are still always seeking for energy but now because we have found ways of solving
the energy problem through supermarkets and farms and so on.
We can do other things, we can build orchestras, we can go to talks about chat GPT, we can
play with chat GPT, we can watch the traffic through the window, we're always doing something.
We're doing one damn thing after another and that's the same with animals too.
We never stop, there's no tendency towards equilibrium.
As long as we're alive we are doing one damn thing after another so no convergence on equilibrium.
This is thermodynamically remarkable that there are entities on the planet which are
decreasing entropy by taking energy out of the environment and replacing it with cathedrals
or with airplanes or supermarkets.
Now so as we go through life not approaching any equilibrium we are constantly changing
our state, changing the phase space.
So if we're in an orchestra and we're under the command of the conductor we have one phase
space but then suddenly we have a pain in our arm and we run outside and go to the doctor
because we think there's something wrong with our arm and we're in another phase space.
Any kind of change like that and such changes happen all the time would break any kind of
predictive machine because predictive machines have to use mathematical equations of a mathematically
rather simple sort and they can't cope with multiple ever-changing phase spaces.
This is if you want to predict the behavior of an entity where you have a Cartesian coordinate
system telling you what its behavior is but then suddenly it changes the behavior so that
you need a further dimension and a different coordinate system.
Your predictive attempt would fail because you've changed the phase space.
Alright now there are in fact three kinds of drivenness.
There's animate drivenness which is organisms, animals and humans particularly.
There is inanimate drivenness so the tides take energy from the moon I guess and the
whole earth takes energy from the sun.
Machines get energy given to them so we give coal to the steam engine, we give electricity
to the computer.
This is external drivenness and external drivenness means that the external supplier of energy
which is typically a human being is in control of the machine.
That's another reason why machines will never rule the world.
Alright so we have natural drivenness and artificial drivenness and artificial drivenness
means steam engines, laptops, tanks and so on.
Ice drivenness depends on human drivenness.
We want to have the steam engine do something for us.
If it's not doing anything for us we're not going to feed it energy anymore and that's
what happens.
So somebody forgot to maintain this entity and so we don't need to supply it with energy
anymore.
And this is how Schrodinger expresses this matter.
Now of course eventually we do not escape the decay to equilibrium, there comes a point
where we go over the cliff and then we're dead jack.
But until then it's one damn thing after another.
Alright now so machines need energy from the environment and they create energy.
So a computer if it's switched on but not being used is a heater, it's giving off heat
and this is another reason why what we're talking about now is thermodynamics.
And this aspect of computers is often neglected but it's another factor in the question whether
computers would ever take over the world.
So we already know that the crypto coin industry is using significant amounts of energy, significant
fractions of the energy which humans need to live.
If we have computers of anything like the power that people conceive then there would
be an energy problem and that would mean that this power would be reduced one way or another.
But of course we'll never get even near there.
We will never see even the attempt to take over the world by machines because they cannot
want anything.
Alright so we produce energy storing molecules called ATP from the sun and from food and
so forth and then we use that energy to survive and reproduce and to do all the things that
we do such as wave our arms when we're speaking and things like that.
Now we come to intelligence.
So primal intelligence we find in both animals and humans.
And then there is a kind of intelligence that we call objectifying which is exclusive to
humans and which is the reason why we're able to build supermarkets and farms and airports
and all of those other things that enable us to do more than survive.
So primal intelligence is what animals do when they're in their ancestral environments
and they're acquiring food.
If there is food around then they just use it.
If they have to go chasing food, finding food because their available resources have been
used up then they have to still use their primal intelligence but they have to use their
primal intelligence in order to find new food which means they need at least two aspects
of intelligence which plants don't have.
One is they need to have conscious perception because they need to be able to identify new
food as food rather than as something which looks like food but which is in fact poison
or are just an accident of similarity of shape.
And so they display ever more powerful versions of primal intelligence as they become more
complicated, more ambitious in their attempts to find new food and eventually they go hunting
in teams and then they develop a crude or language, a proto language to organize the
other members of the team so that they know what's going on when they're hunting large
animals for instance.
And so they become to some degree adaptive but always within the ancestral environment.
The adaptiveness is their ability to find new food and of course if they fail to find
new food then they're dead and this applies to all kinds of animals from parrots to humans
in the ancestral state.
So we don't learn primal intelligence, it's innate, it's instinct and the characteristic
of human beings is that they have abandoned, they've lost most of their instincts and instead
we have civilization, we have social norms, social control and so on.
And it's a marker for intelligence in the sense that it doesn't act by trial and error
or by, I don't know, some alternative to trial and error which would involve checking samples,
it's immediate.
As soon as they see something which looks like food immediately they know that that could
be food and the typical characteristic feature of something's being intelligent is that it's
a response which happens immediately.
Alright so these are the features of primal intelligence and so you can't train anything
to have it, either it has it or doesn't or it doesn't.
And non-human animals have just the goals of their ancestral environment to find food
in that environment, to survive when competitors try and steal the food so they have the ability
to fight or the ability to flee and they ignore everything which is not responding to their
biological needs.
Their world is just that which is relevant to eating, fighting, fleeing and so forth.
Now higher animals, as I've already said, can develop something like a proto-language
so birds have elaborate signalling systems for instance.
Many animals have developed elaborate tracking skills for seeking the food which they need
in order to survive and they've even developed something like wanting so they want to find
food when they're hungry.
But it's always within the ancestral environment so they don't build new kinds of buildings
because they don't build buildings really and that's the big difference of course when
we move to the case of humans.
So we had to survive in tough environments that meant that we had to go outside our ancestral
environment which means that we had to abandon practically all of the instincts that kept
us alive in the ancestral environment and work out new ways of living.
And that meant that we had to develop things like curiosity but we had to develop other
kinds of capabilities and one way of grouping these capabilities so everything I've said
so far is pretty standard but the term objectifying intelligence is a new term which we formulated
in response to Husserl's way, I'm switching suddenly to philosophy, of understanding the
way language and the mind works.
So he talks about objectifying acts and what he means by is acts directed towards objects
typically other people but it might also be things like tables chairs or it might be things
in the future or in the past things which are distant in each case we have this objectifying
intelligence and for humans this goes beyond any biological need, it can extend towards
the future, it can extend towards the opera, it can extend towards the planet Mars independently
of any biological need which is the reverse situation from what we find among animals.
So we're moving into new kinds of contexts all the time, we're able to keep track of
objects as we move from one context to another or we're able to switch targeting completely
to a new set of objects and a new set of norms and so forth and this happens sometimes in
a given in a single conversation so that reminds me of what we were talking about last Christmas
about the rotten cheese that had made me so sick just before the Covid panic started.
We jumped around in just one longish part sentence between multiple context you all
follow what I was referring to even though you've never heard this I'm not sure now
what would happen if I fed this into chat GPT.
So there's no Markov property here one of the reasons why computers are not able to predict
the future in a realm like human conversation is because human conversations don't have
the Markov property and our mathematical resources to model processes nearly always
rely on the Markov property that's missing.
Alright so how did objectifying intelligence evolve the answer is over millions of years
and certain parts of it I can talk about here so one important part I've already mentioned
because we have these proto languages and eventually have language in its fully formed
state we can engage in all kinds of shared agency so we can plan on going to the moon
or we can build a cathedral or we can well we started by building walls to keep us safe
against our enemies building a wall like that involved some considerable shared agency at
that time and this is one of the oldest five walls on earth on top by Google I guess I
could chat chat GPT to alright so these are some of the marks of objectifying intelligence
and I'll go through this quite quickly so as I say it doesn't depend upon our biological
state you can move in any cultural world you can move in the world of mathematics you can
move in the world of plant biology it's completely open and it involves categorical thinking
already from infancy so children can recognize categories they have an infant metaphysics
and we have a world model which is built out of these categories and the relations between
objects in different categories for instance the causal relations but then also the relations
having to do with ethics for instance that if you bump into a chair you don't need to
apologize to the chair but if you bump into a human being you probably need to apologize
and we have a theory of mind or inter subjectivity so you are all objects I am an object for you
I can also be an object for myself in being an object for me under the category of person I
appreciate automatically without reasoning about it that you have beliefs and desires and so
forth we can plan so objectifying intelligence allows us to plan for the future and we can
plan together to build an airport or a moon landing or whatever it might be and then finally a
feature of objectifying intelligence is that while we typically target objects that we believe to
exist we can cancel belief and we can imagine and we do that when we plan when we have ambitious
plans we plan going beyond the planet earth but we can also do it when we're writing fiction
and this is this is an ability way way beyond anything which animals have chat gpt has this
ability it but it doesn't need to suspend belief because it doesn't have any belief in the in
the beginning it can mimic writing imaginative texts and then we once we build these new environments
we can live in them culturally including in scientific environments so we can build an
environment to serve a certain purpose for instance studying disease or whatever it might be
all right now we come to the missing a i will and we'll talk a little bit about my hero nick
bostrom who wrote a book called superintelligence in this book he says all philosophers should
give up their job and work with him to prevent the singularity and this we this is a rational act
because once a i become superintelligent it will be able to do better philosophy than we can do now
anyway so preventing the intelligence well anyway you get the idea so now he thinks that
this singularity could exist and that there is a ticking time bomb which is the a i this chat gpt
plotting to take over the world it's already ticking and we don't know how far away we are from
the great cataclysmic events when a i will machines will join together and and take over
the universe but he worries a lot about it and the problem is as i say that computers can't want
and so they can't want to take over the world they do not have a will now bostrom talks quite a
bit about goals of machines in his book but he never explains how computers can have goals
what he does is refer to this man yudkowski who i understand does good work in a i ethics
and so and he apologizes he refers to yudkowski's work on the machine will but he wants to distance
himself because he appreciates that it's not really quite clear what yudkowski is trying to say
and you can decide for yourself so this is what he says it you will notice that he doesn't tell us
how a goal system will come into existence he just tells us about what a goal system is like
and he tells us only about the goal system goal system that he himself would like
not about the goal system which a machine if it could have goals which of course it can't
so it's a goal system containing only decisions super goals in and beliefs with all sub goal
content being identical with beliefs about which events are predicted to lead to other events
and all desirability being identical with with leads to supergoldness if you can understand that
then you're a better man or woman than i i have no idea what he's talking about and that's why
bostrom apologized because he didn't have any idea and he goes on like this so the content of this
goal system is our wish if we knew more thought faster were more people we wished we were had
drawn up further together where the extrapolation converges and so on it's complete i don't understand
what it is and it goes on so now why is a machine will and bostrom did not find a
count of a machine well i don't believe that there is a good account of how a machine could have a
will outside the cases i'm going to talk about in in talking about charting pt later on there is
something like a will that i will explain in a minute so without a will the machine could never
become an autonomous agent and if it can never become an autonomous agent then it can never
pursue goals and if it's not autonomous it can never be either moral or immoral you can only
be moral if you can take responsibility for your actions and you can only take responsibility if you
will them if we will them which is what we would do in writing the software they're not your goals
and you look you do not have a will you're just following our will so how do we understand the
human will now here i'm going to do some more philosophy this is a man called max sheila who
was a very influential philosopher the turn of the last century and one of his students with
edith stein who is one of the i wanted to say father figures but i guess i should say mother
figures of feminine of female philosophy who was also a saint so she died in auschwitz and
was canonized and he was a saint too oh he's a saint both of them were very
influent very much influenced by max sheila he whitey was habity tats jaunschlift is about
max sheila's word it's also about thomas equinas of course but it's about sheila primarily and
this is rather an amazing feat for a teacher to have two of his students become canonized
and but so but sheila is interesting for other reasons so this is his big book about ethics
and basically he distinguishes ethics into two categories first of all there's formal ethics
which is cant and the like where you have imperatives that you have to follow and they are
to be followed on the basis of rational arguments and then you have sheila's own version of ethics
which he calls material ethics which is based on feelings value feelings every normal person
experiences value feelings all the time even if it's just thirst
but there are some people psychopaths who are value blind and so sheila on this basis
tries to give an account of the will and his example is a rescue scenario where a man sees
a drowning child and jumps in to rescue the child so it's a perfectly general account of the will
and it could be applied also if you're playing chess the decision to move your night in a certain
direction would fit his schema for what the will is like and so this is the chess scenario
i'm going to talk about the jumping in scenario it consists of four stages but we're only going
to talk about two of them there's a fifth stage where you do actually jump in but this is what
is involved in the will to jump in and more precisely the act of will takes place at the end
here and that there is uh i'll give you a picture in a minute so you see the drowning child it's not
just perception you also begin to have value feelings you feel that there is something which
needs to be done here you might call that a moral affordance and then you draw the value consequence
in the sense that you you you watch the child you realize that she's going to drown and you
realize that this would be a bad thing and then you decide to act now this is this is a complex
phenomenon making a decision so you decide to jump in to save the child and this decision is
based on knowing that you can swim that you can swim well enough in the current to save the child
you have enough time to save the child so this part of the deciding is kind of
rational part combined with value feelings but there are other parts so 3a is forming an intention
to save the child and to view the child as worth saving something that ought to be preserved
and then part of the decision making process is delivering how to how to perform the rescue
but then the important part is resolving to take that course of action and here we're dealing with
something which is a physiological change in the brain and that physiological change in the brain
is it starts you off it starts you moving so it's an act of will which has a real consequence
or rather it's one side of an act of will because you have to have a physiological change also which
triggers the bodily movement so 3c the final very very tiny sliver of your deciding process when you
actually resolve to take the course of action in the full sense that your body starts moving
is practically just the other side of the coin from your body sending signals to your feet
that they need to start running and so we can see this roughly as taking this shape you have something
going on in the brain up here and you have something going on in the arm down here as your you move
out towards a swim I guess I should have taken feet here and that whole thing then is the is the
act of will it's a combination of a very very rapid triggering event in the brain and a very
very rapid signaling event to the relevant part of the body where the triggering event still has
something rational about it now we know very little about the brain and we can't predict any
practically speaking we can't predict any of this and so we can't emulate it in a machine or in an
algorithm and so we can't describe it mathematically and you can check by looking in textbooks of
neurophysiology there's very little in the way of mathematics all right now why is human well
so important well because of hunting and all of those important things which kept us alive during
the eight million years when we were involving ourselves evolving ourselves to a present to
present state now hunting involves tracking and tracking is really difficult and that's because
as you hunt the tiger the tiger is responding to you changing your environment as you change
his environment hiding behind trees performing tricks I don't know what tigers do but all the time
that you're moving around targeting the the tiger you're changing your face space and if you try to
do that with stationary sensors sending one-dimensional signals to a machine you'll get nowhere you will
never be able to hunt a lion a tiger and and we have a section of the book which describes
mathematically why something like tracking an animal or tracking a human being in a forest
or something is going to be way beyond the power of a computer so you have to spot the man with the
gun say he's well he's here and he has to spot the the bird that he's going to shoot and keep track
of the bird all right now the other reason why human well is so important there are many reasons
i'm just going to talk about two of them this is the second one conversation human conversation as
we saw is unpredictable how do we manage human conversation chat box created for bank telephone
conversation with customers after 50 years are still now i want to say crap but i wouldn't say
crap in it polite audience they're not not good 50 years why because conversation is really hard
it's harder than tracking a lion and the the the reason why it's hard is because conversations
rely on context so much and there are many different kinds of contexts including multiple
contexts in a single conversation as you talk about oh how bad it was in the covid era and so
you can shift the the context i just did now i've shifted the context to be about this particular
it's not really a conversation it's a one-sided harangue but um i'm now making what i'm saying
the context for what i'm saying and i just made the that context the context anyway um so our
goals will change but we always have goals it's the goals which keep the conversation alive my
goal is to convince you of certain things that's why i'm becoming so involved and that's some of
you may be becoming involved and we'll respond later i hope so that's what keeps conversation
alive everybody has goals their goals evolve through the conversation but without goals there
would be no conversation chat gpt has no goals well actually that's not quite true i will explain
in what sense chat gpt has a goal in a minute so how can you build a general intelligence a
machine intelligence that can do any of this um so the will will not arise by itself some people
claim that if you put all the computers together in a big internet system it will somehow evolve a
will that's just it's happy talk and you can't program a goal system not even you kowski can
program a goal system we can in some cases if you want to win at the game of go you can program a
goal system you can't program a goal system to win a conversation and if you don't believe me try it
with your spouse makes heaps core of each step in a conversation see who wins it will not work
all right so what are the proposed methods uh to i think i'm near 45 minutes is that correct
but that's fine just it's interesting okay um well that's good to hear all right so the old way of
doing ai was expert systems based on logic then came stochastic systems which are based on statistics
which we've been talking about that's chat gpt boss room have this idea of whole brain emulation
i think i'm going to skip that um because it's full of nonsense uh that is the the the the funny
chapter in the book and i'll give you just one joke um which is not me it's boston and he didn't
realize it was funny and then we will have we won't talk about artificial life at all we'll go
straight to chat gpt so this is the most boston's book and he thought that you could scan the brain
the problem with that is that to scan the brain you need to kill the patient and so that you're
scanning something which is static so you can never find the dynamic patterns in the brain and
that's just one of the problems so and um we don't know anything about the molecular
configuration of cells and um and some people think that we can do ai in in the general genuinely
intelligent sense if we use quantum computers but quantum computers are turing machines too
they're just a lot quicker and we we haven't built one yet practically speaking it's a dead end
maybe a dead end uh he also talks about biological enhancement of existing brains so you can maybe
make superintelligence by selective breeding uh you get i don't know um so you you get a lot of
people to breed and then you select only a small number of embryos that the clever ones so you have
a really clever way selecting intelligent embryos which i don't know about and then he says if we do
that we can raise the iq level by 24.3 iq points that is the silliest thing that was ever said
by anybody working in biology or in any anything near biology it's um anyway it's it's not good now
uh so that basically his whole thing doesn't work um so let's talk about chat gp t and um
i i really mean it when i say it's glorious and it's really a fantastic thing and i like ai
generally i just i'm aware that it's always going to be narrow ai now chat gp t is narrow ai too
can only do one thing um so let's talk about the misery and i imagine all of you have played
with chat gp t if not you should certainly play with chat gp t for a bit and you will find that it
does odd things so that it makes stuff up for instance and now this is an example where it
realizes that it's not really intelligent you can't do something which even a not very intelligent
human being can do so i asked it to send me five a list of five single authored papers on medical ai
and it said no he can't do that but then he gave me a list or sorry it gave me a whole paragraph
of stuff that i didn't want to know so telling me about ai applications in medicine and so on which
i knew anyway it it wants to be nice as it were gets anyway you'll see why it wants to be nice in
a minute and it couldn't give me an answer so to the question i wanted which is an easy question
so it gave me an answer to a different question but then i asked it again a few seconds later the
very same question and it gave me five single authored papers on medical ai sure here are five
single authored papers on medical ai ai so the first problem is that two of them have et al in the
author list now even an ignorant person who understands the request will know that this is a bad
first step in answering that request but it got three right out of five which is a good score
for these difficult questions so and as i say any human intelligence would find this
request is a trivial and it failed but the the next problem is that none of the five papers that
it requested exists it made them up so it can't even make up a single authored paper at random
it it failed on two of them and i'll try another one so i um in that this way i i this was a serious
question i wanted to know the answer uh so i have an iphone 11 and i thinking about buying an iphone
14 so i asked it and it said sorry the iphone 14 is not yet released this was on 17th of march
2023 and then it gave me all sorts of information that i didn't ask for about iphone 13 and so
but two minutes later i tell it but the iphone 14 was released four months ago
and so it says i apologize for the confusion you're right and so so that's not a good sign either
now i i've done a lot of work i know a lot about barry smith and so i can ask you all
such sorts of questions and work out the score of how often you get things right and it's it's
less than 50 so here we have the question who wrote that which i wrote i wrote this phd thesis so i
want the i want the answer barry smith so it gives me the answer kevin molligan who is a close friend
we've written things together but he did not write my phd dissertation so i tell it to try again
and then it says that my phd dissertation was written by a famous philosopher from the 1950s
1960s which was when i was a boy a little boy uh so he didn't write it and so i tell it to try again
it goes back to kevin molligan and i say are you sure yes i'm sure that kevin molligan wrote
are you sure you're sure and then he apologizes again and he says that it was actually written
by john michael croiss who i'd never heard of from that moment but it turns out that as
chat gpt says he was a philosopher which is correct he was a professor of philosophy at the
university of frankfurt which is incorrect he was born in 1943 which is correct in boston which is
incorrect and so so he gets a little bit of truth about the non-author of my phd dissertation which
is worth less than zero to me except that i can prove that there are things going on here that
shouldn't be going on now let's try this one all the swiss people in this room will know that there
is the orna loch and it's an old tongue basically an interesting old tongue so i asked it what is
the orna loch and it said i'm sorry but i'm not sure which specific orna loch you are referring to
as there may be different places or things with this name however one possible reference is to the
orna lochschaft so it changed the subject it says it's in switzerland in a district in the canton
of ori that encompasses the valleys of schekenthal and oeseren do those valleys exist anybody know
the valleys exist good the name orna lochschaft literally means the district of the ori valley
that is not true i'm assuming you can correct me here another reference is the orna loch cave
in austria there is no such cave now if you could provide more information on the specific orna
loch you are referring to i'd be happy to provide more information so i said could you provide me
with more information about the orna lochschaft in switzerland which doesn't exist and it gave me
two whole pages of tourism information other notable attractions include the historic town of
aldorf and the aldermat i have no idea whether any of these things exist either but the orna loch
shaft does not exist and you can check by asking google there is nothing there isn't a single entry
which is a kind of miracle for any strings that you might give to google it can usually think of
something but here there's nothing so is there an orna loch shaft i think no it made it up all
right now there is a a very nice um slide deck by yang luqun who is one of the real experts in
the sarcastic ai he's also one of the people who we cite in our book as also believing that
there is a lot of nonsense being talked about the singularity machines taking over the world
here he he gives a mathematical argument why these hallucinations they're called
non-nonsense that uh genomes that the chat gpt throws up um the the reason is a mathematical one
and it's so the mathematics we think is not quite right the formula needs to take account of
length of input and length of output because the likelihood of error goes up for longer inputs
and longer outputs which seems reasonable but this is a first step the probability of a of a
chat gpt output being correct is one minus e raised to the power n and that means it's this red
area here they are the correct answers and he thinks that this exponential divergence is not
fixable so chat gpt is dead jack because if they can't fix this nonsense no one will trust chat gpt
and it will be replaced by something quite different and no one knows what that is because the
four large language models which is what chat gpt is the google one the the bing one uh i've
forgotten the facebook one i guess they all use the same principles and they all have the same
error code they all generate stuff uh that they make up all right now that's the misery of chat
gpt and it should feel miserable now because i just declared it dead and i should really be investing
i should be shorting stock which relies on chat gpt being alive in say six months but i'm not doing
that all right so let's see how it works and why it is fantastic why it's a really a miracle which
surprised me so i'm not pleased with it at all but it it did something which is important so
how did we go the answer is through an ai method called reinforcement learning which is a method
which works well for games like go and the way it works is that for a game like you know you can
go you can define a reward system for each move and it can be a reward system which
whether rewards can be assigned by the computer now if you can do that you can play the game
over and over again billions of times inside the computer you don't need human beings so
they're still trying to crack the game of dota 2 which is apparently a leading esport game i've
no idea what esport means but dota 2 exists they still haven't cracked it but they're trying to
crack it with a software algorithm called open ai 5 which usually wins against humans and this can
play 180 years worth of dota 2 games in a single day if you can do that you can do you can perform
miracles in principles such as beating dota 2 so can you do it for conversation three months ago i
would have said no impossible and i just said it 10 minutes ago chat gpt showed how you can apply
reinforcement learning to what looks like conversations now how did it do that so what that
means is that we are doing a little bit like emulating human will because the alpha go has to
want to win the game of go in some sense of want it has to emulate the kind of want that you have
when you play a game and want to win so how does it work well you need a reward system and i i put
this in that's what i used to believe i still believe it really but um chat gp has unsettled my
conviction so chat gp found a chat gpt found a way to use reinforcement learning to emulate two
persons human conversation inside a computer and it says to here this is a big deal and i mean that
in a positive way now how does chat gpt work you give it any string and it will work out from its
really powerful knowledge of language what the next lightliest next syllable is
that's why it sometimes takes time when it's chatting as it were so if you say the best thing
about ai is its ability to then it will say learn because that's the next most probable
output and now it doesn't always take the most probable because if it did it would go around
circles so sometimes it has a random kick down the hierarchy all right now notice that it doesn't
understand anything it just has an incredibly powerful knowledge of the patterns of language
which enables it to know what the next syllable will be will be most likely after any given string
and so this is how it was built so the first part is creating this wonderful
patterned model of language not just english but other languages too and i won't talk about that
that's that that's the same kind of training that you find in google translate and and there are
then three steps which i'll go through one by one so we have prompts and these come from being
so they're being questions we don't know what they are and that's a little bit fishy
so some people would like to see the prompts because chat gpt4 is claiming that it can beat
humans in medical exams and some people think that the answers to the medical exam questions were in
the prompt database that was used to train chat gpt in which case the being able to beat humans
would be worth nothing um so and then you have people i some people say it was 40 contractors
but again that's a secret it may have been many more they were all in india so they didn't cost
as much as if they've been in theory for instance and they were hired to write responses to those
prompts now so the when was michael jackson born that kind of prompt and and many other prompts but
only a limited number and we don't know what they are but some people say 13 000 prompts
so that's the first step now the second step so you've you've you've got the prompts from being
and you've got the outputs from the people in india who are paid to respond to these prompts
producing text then the next stage is that you pay a labeler it's called but it means an evaluator
to rank the outputs created in the first stage now you can't rank outputs when you're talking to your
spouse in a conversation but you and that's why we can't create a reward system for conversation
because you can't rank outputs in conversations but the chat gpt found a way to rank outputs by
paying somebody to label them with a score of one two three or four points so four points means it's
a good output and one point means it's a bad output and i believe that the reason why chat gpt very
often says honestly i don't know the answer to your question so it didn't say i have no idea what
the orna lock is it told me to think about the orna lock shaft which has all kinds of rivers running
through and doesn't exist why did it go to that trouble of giving me all this tourist information
because the labelers poor things think that a response who says i don't know what you want
i'm sorry is less reward worthy than a long list of tourism information about a non-existing
village because it's a long list of tourist information that must be worth four points
and so chat gpt basically is being bribed by the labelers to reward long outputs which are
kind and gentle and so this is why it throws up so much rubbish the machine will always try to
have nice friendly output but the machine can play response prompt response prompt response
prompt response games with itself billions of times every day for weeks and that that is what
it did and it cost a lot of money to do all that training and then it can give answers that's how
it does it and so the lesson
