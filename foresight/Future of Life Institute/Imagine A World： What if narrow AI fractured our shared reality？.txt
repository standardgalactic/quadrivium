On this episode of imagine a world.
My best guess is that a guy will progress much more slowly than I have it progressing in my story.
And my best guess is that we do survive because I progress is much more slowly from my perspective.
It's extremely contrived for a GI to develop even as fast as it does in this story and be handled well enough cautiously enough.
Thoughtfully enough that we have more than a fraction of a percent chance of survival.
Welcome to imagine a world, a mini series from the Future of Life Institute.
This podcast is based on a contest we ran to gather ideas from around the world about what a more positive future might look like in 2045.
We hope the diverse ideas you're about to hear will spark discussions and maybe even collaborations.
But you should know that the ideas in this podcast are not to be taken as FLI endorsed positions.
And now, over to our host, Guillaume Reason.
Welcome to the imagine a world podcast by the Future of Life Institute.
I'm your host, Guillaume Reason.
In this episode, we'll be exploring a world called Hall of Mirrors, which was a third place winner of FLI's World Building Contest.
Hall of Mirrors is a deeply unstable world where nothing is as it seems.
The structures of power we know today have eroded away, survived only by shells of expectation and appearance.
People are isolated by perceptual bubbles and struggle to agree on what's real.
Despite all this, things are generally going okay, for now.
This is partly due to this world's particularly slow and modest development of AI technologies.
AI tools here are still dominated by extensions of today's fundamentally narrow systems,
with the one true AGI being developed under heavy quarantine.
There are a number of reasons for this slow progress, including high computational costs and poor funding due to politicization.
This team put a lot of effort into creating a plausible, empirically grounded world,
but their work is also notable for its irreverence and dark humor.
I can safely say that it's the only winning world where you could see virtual celebrity Tupac List
perform at a luxury war-themed amusement park run by the Taliban.
Needless to say, there's a lot going on here.
I was excited to get a look into the minds behind this particularly brimming and erratic world.
Our guest today is Michael Vasser, one member of the three-person team who created Hall of Mirrors.
Michael is a futurist, activist, and entrepreneur with an eclectic background in biochemistry, economics, and business.
He served as president of the Machine Intelligence Research Institute and is co-founder of Metamed Research.
His other team members were Matia Franklin, a doctoral student studying AI ethics and alignment at University College London,
and Bryce Heidi Smith, who has worn many hats from fortune-telling to modeling,
and now has a focus on finance and policy research.
Hey Michael, great to have you with us.
Great. Good to speak to you.
So I'm curious how the three of you on your team came to work on this project together.
So I've known Bryce for a very long time, and when the project was starting up,
there was a call for collaborations, and I tried talking to a bunch of people.
And Matia and I had, you know, the most productive conversations.
But like the overall project was mostly my vision, and Matia did some level of editing,
and Bryce did the fiction and art.
Cool. So did Bryce make the music that was accompanying your session?
Yes.
Cool. Yeah, I really enjoyed your music and the short stories as well.
He did a great job with those.
I mean, it's the closest thing to a super intelligence that we have around for now.
Endurable.
Well, what was it like for you guys to do this project together?
Did you learn anything yourself in the course of it?
I mean, I had a lot of fun.
It helped me to concretize some of my thinking.
Some, I feel like the basic sense of where I think we're going or would like to go
has been reasonably stable in my head since GPT-3 came out,
and hasn't drastically changed since GPT-2 and COVID.
Yeah.
What were some of your biggest sources of inspiration when you were working on this together?
I don't think my thinking on this is significantly influenced by stories or books
or music or what have you.
I think it's basically just coming from looking at what the technology can do
and spending the last 25, 30 years obsessively thinking about history and the economy
and social sciences and making some effort to understand the technology.
I'm certainly not a top expert in actually understanding the technology
while I will humbly claim to be a top expert in understanding the history of technology
as it relates to economics.
Yeah. Well, you do have this deep professional background.
Can you say a little bit about how your experience in other fields
and kind of working through all this has influenced how you see the future?
I mean, in terms of professional background,
molecular bio, I studied in university and it doesn't really inform this very much.
I have a lot of thoughts about cool things that could be done with molecular bio,
and now that GPT-4 is performing at a high school national championship level
without major upheaval enhancements.
I'm confident that I can do a lot more of that stuff,
and also AlphaFold is very cool, and mRNA tech is very cool.
So I think there's enormous opportunities now for bio.
Getting an MBA gave me an opportunity to exist in the business office world for a while,
and that certainly is necessary without having interacted with corporate hierarchies.
One doesn't know what corporate hierarchies are like at all.
There's very effective disinformation and propaganda about that.
I think mostly I've just read a lot in directions that seemed like they could be helpful
over maybe a 25, 30-year period.
Yeah. What sorts of insight did Bryce and Machita bring to the project?
So the actual stories were very cool, and the music was very cool.
And Bryce wrote those mostly by himself.
And there were some back and forth about what sorts of things were maybe too over-the-top
or too fun and silly to include in the story.
And it's just good to talk to people about things and develop the ideas together.
And certainly Bryce has been enormously central to developing my understanding of the world
in general over the last decade.
And what about Machita?
Machita? I mean, mostly just discussing what I can get away with.
In terms of when telling a story, what is too weird, what is socially acceptable enough
that people can understand it as relatively limited in French distance from normal, thoughtful people?
Yeah.
In some ways, this world is kind of a caricature of the present.
We see deeper isolation and polarization caused by media
and a proliferation of powerful but ultimately limited AI tools
that further erode our sense of objective reality.
A deep instability threatens.
And yet on a human level, things seem relatively calm.
It turns out that the stories we tell ourselves about the world have a lot of inertia,
and so do the ways we live our lives.
I had a hard time picturing those individual lives among all the wild happenings of this world,
and I wanted to hear more about that human perspective from Michael.
What's it like to live in this world you've made?
Well, it's going to be very different in different media bubbles.
The biggest media bubble by far is going to be Chinese,
and the successor to contemporary Chinese Communist Party politics
will mean something more neo-confusion than China has been recently.
But done with capacities that no one's ever had the opportunity to bring to the table,
so you can just spend so much more time on filial piety and cultivating then
when all of the real work has been automated
and when you have machines that are in some ways superhuman watching your every move
and helping you along to express gratitude to your parents
in the most ritually prescribed manner.
Other people have different experiences.
There are probably hundreds of millions of people trapped in pornographic universes
and effectively mind controlled by AI.
That would maybe be the second largest demographic, if I really think about it.
And there are lots and lots of people, like the ones we discussed at the end,
living in old age homes and having their experiences mediated through a somewhat more tasteful
but still like relatively liberal and relatively cultivated sense of benevolence.
But the prospect of AGI coming online at all changes that.
In some sense, these stories were intended to point at the extreme instability of the world that I produced.
So we have one story about producing a piece of transhuman music
and one story about consuming it despite the cautions of the companies around AGI
under the basically reasonable assumption that music was not existentially dangerous under normal circumstances.
Yeah, so you're referring to, in your world, there's this system that DeepMind has called siren,
which is I think kind of the only AGI in your world.
It's under very tight wraps.
Everyone's really carefully screened and there's follow-up monitoring,
even if they just hear the music that it produces.
This system has also written some books on a few topics that have been carefully curated.
I'm curious what broader impacts siren's existence has on your world,
given kind of how cloistered it is.
I mean, none by design.
Allowing it to have more than the tiniest amount of impact on the world
would be allowing the world to end almost immediately.
So instead, yeah, your world really dives into narrow AIs.
So these are systems that are very good at just a few specific tasks,
like playing chess or driving a car.
No, much broader than that, like the AIs we have today, like GPT,
which are at least pretty good at most things that we tend to think of as intellectual tasks
and very, very, very good at most things that we tend to think of as perceptual
or as extremely rehearsed short-term actions without a lot of context sensitivity.
I see.
So these are like, you know, souped up, narrow AI systems.
They're still not AGI's, but they're kind of the most effective extension
of today's technologies like chat GPT and things like that, as you're saying.
They're general enough that for the vast majority of the world's population,
they probably are vaguely thought of as generally intelligent,
like the vast majority of the world's people probably don't understand very well
the differences between them and AGI's.
And that's probably part of why there's essentially no funding or work on AGI outside of DeepMind.
Yeah, interesting.
And like broadly speaking, they're sufficient to produce some level of relatively benign,
not totally impenetrable, but close enough, a global mind control system
that also contributes to not understanding the differences and also not pursuing AGI.
In some ways, I think that the fiction that my world most reminds me of
is probably Who Framed Roger Rabbit, where they have these tunes everywhere.
And the tunes can talk.
They have personalities.
They have something kind of like agency, but they don't seem to, for the most part,
have agency with any scale.
It's like an extremely rare, extremely dangerous thing for a tune like Judge Doom
to have agency with scale and scope.
And when they do, like Judge Doom, it's agency with an extremely inhuman focus, scale and scope.
So very potentially dangerous.
And the tunes are in some sense extremely cheap and disposable, easy to produce,
but in some sense immortal.
And the humans are like completely clueless about the glaring ways
in which the tunes' capabilities are less than human,
such as Roger Rabbit can only do things when it's funny,
but fairly clueless about the ways in which their abilities are more than human,
like they can survive having a piano dropped on their head.
I actually haven't seen that movie, but I'm really excited now to watch it with this metaphor in mind.
It's a really cool connection.
Yeah.
So one thing you say that these systems can do in your world
is basically replace all white collar workers in theory,
but you say this doesn't happen and you say basically, you know,
there are various reasons, political and personal, why humans are still employed.
I'm curious what kinds of work humans do and what it's like for these human workers in this situation.
So I think basically it depends on their organization,
but in the pretty large majority of organizations,
it's pure office politics and getting therapy from not peak human ability,
but good enough AI therapists to recover enough from the office politics
that they only kill themselves with like drug overdoses and the like
at maybe a third or a fourth the rate that they do in our world.
And maybe even less if AI enhanced medicine makes such drug significantly less deadly
and treatment significantly more effective.
Yeah.
Your world still has a ton of economic inequality,
but the actual quality of life that you describe is kind of universally pretty good.
Like travel has become really cheap and there's basically free energy.
It makes food distribution really trivial as people can kind of live wherever they want
and they have augmented reality, so it'll always look beautiful.
I'm curious, given all of these kind of unifying factors,
how people decide where to build their lives
and what kinds of goals they decide to pursue with them.
So the world that I'm thinking of, for the large majority of people,
they start exploring the world when they're children
and hopefully their parents take a lot of interest in them.
But if not, there's an infinite amount of attention freely available
from the web and from open source and commercial products.
And the decisions they make throughout their lives are almost entirely determined
by what sorts of commercial or open source products find them first, in a sense,
and build the sort of feedback loops that pull them into one or another bubble reality.
You have this interesting thread in your world
where families kind of become a currency
or a kind of wealth that people pursue more than monetary assets.
Can you say a little bit about what that looks like?
I mean, that's just being a normal person.
We've lost touch with it in, you know, late stage capitalism.
But even under normal capitalism, this was not confusing to anybody.
You know, the idea of trying to accumulate wealth
rather than trying to accumulate happy help,
the wise flourishing and mutually cooperative descendants
is like a really surprising thing to find an organism doing.
So thinking about some of the more unusual aspects of your world,
your world definitely had some of the wildest kind of one-off ideas in it
that we saw in the competition.
You have like the Taliban creates luxury war themed amusement parks.
You have elephants that are domesticated by CRISPR.
And you even have Kanye West creating a virtual reproduction of biblical Jerusalem.
I'm curious like what prompted these kinds of details to be included
and whether they're part of a larger theme for you that you were trying to convey.
So the biggest thing that I left out of the actual thing that Matija's influence
was a coup by the comedy party where basically in the 2032 election
between AOC and Donald Trump,
the mainstream Democrats, which still basically control the media and the courts,
decide to allow a completely flagrant election fraud to control John Stuart
as a third party president.
And, you know, so that one I think Matija thought was too political, too controversial.
But I do think it's the sort of thing that could realistically happen.
Overall, where are these coming from?
I mean, some of them are just like extreme low hanging fruit,
things that a few college kids could throw together as a project
in a world with AI capabilities that I realistically expect to exist well before the 2045 deadline.
Yeah. So this is kind of just speaking to maybe like the chaos
and the power flying around the instability of things
and how the world is just going to get so much stranger.
Yeah, I don't think of it as a chaotic world.
The stories are super, super non-chaotic about people living very calm lives.
I see it as a world that's very, very unstable simply because it has even one AGI in it.
And like sooner or later, a more permanent solution is necessary
than just keeping its interest cyber focused and keeping people from noticing it very much.
To some degree, I'm just trying to show a picture,
because that's all you can do in a story like this,
but a picture where all of the pieces are scientifically well founded,
technologically, economically and politically well founded,
make sense and fit together fairly well.
I guess more than anything else, I'm trying to show people like the contest is trying to show people
that it is even possible to make a sincere, serious and competent effort
to depict a realistic but optimistic future.
Major changes are hacking away at the foundations of this world's systems.
The loss of shared reality and weakening of governmental structures, at least in the West,
seemed to strip humanity of a good deal of agency.
It's implied that we're being kept from destruction only by our tenuous control of this world's one true AGI.
At the same time, new approaches to things like education and social conflict
signal hope for building a more coherent and empowered humanity.
I wanted to hear more about how Michael saw this world approaching the changes and challenges that it faced.
You write that in America, like Microsoft, Amazon, Tesla and Walmart
are basically the only entities capable of large scale coordinated action anymore
and elected government officials really just enact change by influencing their supporters
rather than by pursuing any kind of legislation.
Most decisions are made locally.
Can you say a little bit more about how America's governmental systems
lose so much influence in your world?
I just see that as a continuation of the trend that we're already on.
When you look at COVID, the government took an unbelievably huge amount of oppressive
and authoritarian action that there probably won't be social or political support for
if there's another major event that calls for it.
It lost an enormous amount of public trust.
If you look at what the government did that was effective with COVID,
it basically boils down to printing enormous amounts of money
and providing certain types of encouragement to conform to a certain standard.
It's not that the government no longer matters.
It's just that popularity contests should be.
It's primarily a source of information about how to be popular.
Just like in our world, people mostly want to be popular.
They don't want it as much as in our world because they can always be popular with AIs.
But still, AIs are not fully satisfying as mental and social companions.
As this power switches over and flows towards tech companies gaining influence,
it becomes increasingly hard to track wealth.
In some ways, it also seems like things are just going on sheer inertia.
You have this great line in your submission that says,
a supermajority of the population has negative net worth
and continues to be allocated credit as a matter of economic policy.
You mentioned this instability of the world.
How long do you see it remaining stable?
Will these systems fall apart shortly after 2045 and you're imagining?
The way I'm imagining this, this is a fairly close to best case scenario.
My realistic best guess scenario would be that it's more than 70% likely,
maybe more than 80% likely,
that the system that I'm describing falls apart well before it gets to the point that I'm describing.
These are supposed to be optimistic visions for the future.
But once it gets to the point that I'm describing, if it gets to that point,
I actually imagine it being stable for a pretty long time.
Except for the edge, I think.
Yeah, Siren gets up.
One big tension in your world as a result of this increasing difficulty
and verifying information is just people have a hard time agreeing on objective reality.
They're really good in experimental healthcare interventions,
but it's mostly about luck and maybe some skill to pick the winners out of that crowd.
You have cryptocurrency that's made it really impossible to tell how much money anyone has.
You mentioned that instead of Forbes keeping track of wealth,
now kidnapping rings keep some of the best records of people's total assets.
You even say that startups are buying these records off of those kidnapping rings to find wealthy funders.
Can you say a little bit more about what leads to this deep fracturing of shared objectivity?
That's been going on really in a big way since the 1940s.
Once again, I'm just imagining it continuing and accelerating with more powerful technologies.
The collapse of the dollar, which happens in the 2030s more or less in my story,
contributes a fair amount.
It makes the crypto thing much more substantial.
And the increase like basically social welfare through senior age
and the expansion of senior age through the population
helps to stabilize things a lot at the expense of coherence and efficiency,
which isn't really necessary anymore.
Could you say what senior age is?
Senior age is printing money through bank activities.
When banks borrow money, then they lend out much more money.
And there's a stack of different interest rates paid by different creditors.
One of the basic challenges of running a capitalist society
that's been well understood since long before Adam Smith
is the extreme difficulty of causing control of the money printing apparatus
to not be the convergent agenda of practically everyone.
And most capitalist societies do collapse as control of the money printing apparatus
becomes a convergent agenda.
So I'm basically imagining the essential worker system that we discovered we had during COVID
and the relatively resilient management of a small number of companies
basically keeping the material reality held together.
Despite the fact that the vast majority of supposed economic activity
is actually pure political wealth redistribution
to the people who bother to fight for wealth being distributed to them in a world
where most people have basically lost track of wealth anyway.
I'm curious why AI systems don't help more with these issues of shared goals and shared knowledge.
You mentioned that AI systems can provide common knowledge,
like they help groups of people identify if their behaviors are aligned with their goals
or how to change their behaviors.
You would think that that might cut through the haze
and help people agree on things more or have more transparency.
AI systems help enormously with establishing whatever set of goals
is reasonably psychologically plausible and that the systems designers want to establish.
But mostly that consists of consuming products just like it does in our world.
And in the rare cases of societies that have more of a shared set of values
and more of a shared power structure like China,
it means that they have incredibly high integration and unity
targeting shared goals that more or less consist of normal reasonable things
like extending life and ecological sustainability and stability in general.
One other thread I really enjoyed in your world is how you talk about education changing.
So people start to see traditional educational pedigrees as a form of inherited privilege.
And educational histories actually become private information
which can't be used in decisions like hiring, which is a really interesting concept.
And this tips the scales in favor of online self-driven education.
Schools basically go empty while kids live with their families and learn on their own.
I'm curious what this looks like for those kids.
What are they learning? What aren't they learning?
And who's deciding?
So I'm basically imagining that nominally the parents decide when the kids are younger
and the kids decide when they're older.
But in practice, reasonably agentic parents who are also tech savvy
and have like reasonably coherent preferences about what to get
will be able to direct their kids towards media bubbles and narratives
that will be extremely stable and which won't change much unless something really weird happens.
So I expect that almost everyone's learning speed is going to be like
at least four or five times faster between more targeted instruction, objectively better instruction,
maybe learning enhancement through drugs and mRNA tech.
And much better trauma care is a major feature of my world.
So just the elimination of mental blocks through MDMA therapies and their successors.
I don't know if I really played up adequately the spread of a new way of doing civilization
from the carceral system into the general population
as like MDMA therapies get adopted for dispute resolution within prisons
and reach a level of reliability and efficacy that's sufficient that basically everyone wants some.
Despite some of the more madcap details of their world,
this team expresses a strong commitment to realism and plausibility.
Their portrayal of AI development was also perhaps the slowest and most restricted among our winners.
While there isn't AGI around, most of the technological developments in this world
are just extensions of today's narrow AI systems whose awesome capabilities are ultimately limited.
I was curious to hear more about this team's creative influences
and whether this slower pace of AI development was something they saw as merely likely
or a necessary component of any safe path to an aspirational future.
So I'd like to spend a little while discussing the narratives in your world
and how they compare to other narratives that are going around in popular culture.
Like one really big through line for me is this sort of emperor has no close attitude you have
towards economics and politics where your world kind of just goes through the motions
to keep things moving along but the systems themselves are no longer really doing much.
I'm curious if there are other examples of this perspective that inspired you in other kinds of media?
I mean, mostly I'm inspired by real life, not by media and narratives.
I can't think of a piece of fiction that is as radical as real life
in the degree to which it violates conventional assumptions.
You know, it's basically impossible to do without being a top tier literary genius like Shakespeare.
I mean, Hamlet's wonderful Doris Lessig's book, The Golden Notebook,
is maybe the best depiction I've ever seen,
but one would need to be a really, really good literary scholar to appreciate it, I think.
Same with Hamlet.
Interesting.
Well, I'm curious if there are any examples,
and this can come from philosophers as well as fiction,
of economic or political systems that could actually maybe function in a world like yours,
or do you think that the whole concept of having a system that's run in a sensible way is kind of moot?
No.
I mean, the Chinese system is sort of run in a sensible way in the world I'm describing.
It's not run with perfect rigor and resolution.
It wouldn't pass like Talmudic standards.
But by the standards that we're used to from government,
I'm imagining a China with a life expectancy of well over 100 years,
and the ability to industrially produce in a clean way,
and with very little labor, practically everything the entire world needs.
The goals of maximizing filial piety and ren
are just going to be what's inherited from their ancestors and traditions,
and it may not seem like doing a thing to us,
but most of what we do is arguably not really doing a thing.
Do you think there are any actions or reforms we could do to Western systems
that would make them more resilient to these changes as well?
I mean, my simple answer is I already put them all into this story.
That's why the world is still alive and has not collapsed already.
I'm making a number of surprising good luck-happens assumptions,
not extraordinary.
I really try to keep avoid endorsing things that are not just quirky
and that have probabilities of less than about 10%.
I think it's important to note that our world would be way scarier
to people from my vision of 2045 than their world would be from us.
Their world would just be incredibly addictive,
and we would very quickly find ourselves trapped in some relatively exploitative bubble.
But even exploitative bubbles have reasons to try to keep people mentally healthy enough
to keep on receiving government benefits within a thin veneer of contributing to the economy.
I guess one way to think about it is the American dream is basically a colpage
of the America prior to the Civil War,
America between the Civil War and the New Deal,
and America after the New Deal,
which could be summarized as the colonist experience,
the immigrant experience, and the GI experience.
And none of these experiences at all resemble what Zoomers are coming into and experiencing.
And so they are growing up in a world of such transparent lies
that they're almost without exception total epistemic nihilists
mistakenly disbelieve that anything was ever true
rather than only disbelieving that anything that they've ever seen is true,
which is actually the case.
So one really unique thing about your world is this focus on the narrow AI systems
and how high a ceiling you put on their abilities.
You kind of have basically a suite of different narrow AI systems
that together have the capabilities of an AGI in some ways,
but they're spread across these separate modules.
No, they don't have the capabilities of an AGI.
They don't have anything even remotely close to the abilities of an AGI.
Can you distinguish that?
The story is just kind of hinting at the capabilities of an AGI
with the sort of security around it and the sort of implied impact
and like potential risk.
I'm operating with the definition of AGI that's something like a system
that's better than a human at any task that you can reasonably define.
Is that different from what you say when you say that these narrow AI systems?
No, better than any human at any task that you can reasonably define.
I'm saying that the systems that I'm describing are not even remotely close to that.
They're like superhuman at very narrow tasks.
They're superhuman at a lot of very narrow tasks.
But it doesn't even come close, fitting them all together
to the full range of human capabilities.
I see. So there's kind of a synergy here, you're saying.
Right, and then they're like not superhuman,
but like merely as good as the experts that top elites tend to point to
at the vast majority of tasks that get measured and graded
and systematized and standardized threat society.
So the best doctors in my world are still humans who make very heavy use of AI tools,
but the best purely AI doctors might only be as good as the doctors
that like the president has in our world,
but not nearly as good as the doctors that like a top doctor has in our world
since the top doctors know who the actual best doctors are and to date them.
So not only do these systems not exceed the best human experts individually
at these narrower tasks, but you're also saying that there's something missing
even if you have this collection of narrow systems
that can each do something that a human can do.
Just putting those together is not the same as having something
that could do all of these flexibly, is that what you're saying?
Definitely, but also there are things that none of them can do even a little bit.
Like in the story that I'm talking about,
Siren is the only AI in the world that could, if it wanted to,
do important original mathematics.
It's the only AI in the world that could, if it wanted to,
make the tiniest contribution to theoretical world-plied physics.
So in your world, you have this incredibly powerful AGI system that does exist,
but it's under really, really strong protections under tight wraps.
Do you think that this is necessary to have a optimistic future with AGI in it?
Yeah, definitely, unless we can basically do, you know,
thousands of years worth of philosophical progress in like 20 years.
And we can't.
Like maybe we can do thousands of years worth of philosophical progress this century
because we will have both AI and other technologies for enhancing our mental capabilities
if we choose to use them.
But we can't do it in 20 years, it's just laughable.
Yeah.
So the limitations that are preventing AGI from developing faster in your world,
some of them are intentional, like policy decisions.
Some of them are just kind of practical ones,
like bad funding, politicization, and the rarity of human expertise.
Do you think these are actual likely causes of slowing development in the real world?
Yeah, that's my, my best guess is that AGI will progress much more slowly
than I have it progressing in my story.
And my best guess is that we do survive
because AGI progresses much more slowly.
From my perspective, it's extremely contrived for AGI to be,
to develop even as fast as it does in this story
and be handled well enough, cautiously enough, thoughtfully enough
that like we have more than a fraction of a percent chance of survival.
Yeah.
Have you seen other portrayals of the future
where narrow AI plays as much of a role as in yours?
I mean, I feel like there's a lot of portrayals of the future
where narrow AI is taken for granted and plays a large role.
Like in the Star Trek, the next generation,
they have one AGI data, like in my world,
and then they have like an unbelievably powerful narrow AI in the ship
and in the holodeck and just all over the place.
But everyone takes it for granted and it's used as a tool
by a military organization with a relatively unified internal agenda
of exploration and extremely prudish and narrow conceptions
of what types of experiences and behaviors
its members are supposed to engage in.
I will say that the type of narrow AI that we have actually developed
is like pretty broad compared to what I expected five years ago.
It's like very much what we were visibly moving towards four years ago.
But to some degree, when I was growing up,
C3PO seemed like a silly fantasy,
seemed silly that you could have a machine
that was that close to human performance
but like stuck for a long time at below human performance
and in some ways pretty profoundly below
and in some ways pretty profoundly superhuman
but like just be stuck there for a long time.
But it kind of looks from the technologies that open up in AI
is generating that a minimum viable C3PO
might actually happen and be around for a long time
without really drastic improvement from that.
How do you feel about the general portrayals of the future that are in fiction?
Do you think they're over or under optimistic when they try to be optimistic?
I just think optimism in fiction that is trying to be at all realistic
is unfortunately much rarer than it should be.
And like that's basically maybe largely
because the most perceptive and insightful people
who are also successful at becoming prominent
and surrounding themselves with other prominent people
are constantly confronted with lots of profoundly miserable,
extremely zero sum other prominent people
and have very little contact with the large majority of people
who are just not as miserable as the people who like double audience
are going to end up around.
So you're kind of calling for more optimism in nonfiction as well?
Is that where you're going?
I mean, no, I feel like optimism and pessimism is like
intrinsically unhealthy concepts.
You should just try to have true beliefs
but true beliefs should be balanced.
There's a lot of social pressure to performatively be pessimistic
because the elites tend to be pessimistic.
And elites tend to be pessimistic
because they're living in a hyper competitive zero sum world
that most of us are not living in.
And there's a lot of, it's easier in some ways to be pessimistic
especially cheaply pessimistic.
But there's also like just cognitive biases that lead to silly sorts of pessimism.
So like imagine there was a news item
about how it turns out that apples cause cancer.
Practically everyone would see this as bad news.
Oh no, I've been poisoning myself for years.
But obviously it's good news.
We know what the cancer rate is.
Now we know that we can avoid it by not eating apples.
Right, the devil you know.
Like information is almost always desirable
but information about bad things gets interpreted
as something bad happening
rather than being interpreted as something good happening.
You know James Baldwin,
not everything that can be confronted can be overcome
but everything to be overcome must be confronted.
And to some degree this picture that I'm depicting
is an edge case on that
because this is a world that has managed to partially overcome
and fully survive a lot of the problems
that our society is dying from
without really confronting them.
In your world a lot of the role models become virtual.
So basically all celebrities popular with the under 30 crowd
are virtual people.
Some are recreations of historical figures.
Others are kind of amalgams like Tupacalist
and you have XXX, Tentacion, Albus XXX.
I'm curious how these play a role
as kind of role models in your world.
I think they mostly don't.
I think that people who have at least reasonably good taste
do prefer interaction with individuals.
Insofar as they mostly imitate behavior by real people
and that like the social influences from machines
are in general more of a, you know,
goal directed relatively overt manipulation sort.
What are your thoughts on some of the current cultural attitudes
towards like AI generated art
and virtual cultural figures right now?
So it seems like any reasonably good artist
wants to make art,
not wants to get paid for making art
and like maybe wants to be seen
and people can worry that
a lot of people will never be exposed to good art
because they're going to be exposed to an enormous amount of stuff
that doesn't have a message behind it
and isn't created as an expression of pain
and suppressed emotion.
But like if you're a good artist
you can learn new tools
and you keep learning new tools throughout your life
and you learn how to make use of these new tools
to compete and to get your message out there.
The barriers to entry for art in some sense never go down
because they have to do with the attention
and consciousness of your audience.
The economic barriers to entry in our world
are going up because of extreme economic scarcity
that's being created through policy.
So like we're living in a time of
really extreme economic scarcity
compared to the Great Depression at this point.
We've lost way more actual economic freedom
in the sense of like
not needing to work very hard or very well
or be very exceptional in order to afford
to reproduce our own labor
have children and grandchildren
and have them live at least as nicely as we do
and be able to purchase our baskets of goods.
And every Zoomer knows it
because like they in fact can't purchase
the baskets of goods that their parents had
and their parents deny them recognition as adults
even like millennials with kids
are denied recognition as adults in major ways
because they don't have the baskets of consumption goods
that in fact, generationally speaking, they can't have.
The process of world building has great potential
to make a positive future feel more attainable.
This can be incredibly powerful
whether you're a creative person looking to produce rich works of fiction
or have a more technical focus
and are looking to reach policymakers or the public.
I asked Michael what kind of impacts
he hoped his work would have on the world.
What do you hope your world leaves people
thinking about long after they've read through it?
So the biggest thing is that I just would like people
to try to make sense of what could happen.
I would like them to know that it is possible
to make a joint prediction
and expression of preference that is in line with
the relatively full range of scientific and technological
and humanistic thinking
and that holds together and makes sense
and that much more close to comes true
and also somewhat guides society towards it coming true
than what we would normally think of as science fiction.
What kinds of expertise would you be most interested in having
people bring to discussions about your world or the future in general?
I think that the things that I would want to bring in first
would be somatic skills
like body work and yoga
and things like that
experience with MDMA and other psychedelic therapies
and maybe even electrical engineering
for creating better alternatives
to transcranial magnetic stimulation
for disinhibiting some parts of the cortex
and activating other parts of the cortex
so to enable people to recapture
usually after years of work
the sorts of cognitive abilities that
normal smart inquisitive kids had when I was a kid
and which the entire literary imprint
of Western civilization is the imprint of
which is why we don't have a literary imprint
for our contemporary civilization.
Do you have any particular hopes about the impact
this work would have on the younger generation of folks around today?
It seems to me that the vast majority of zoomers
are doomers. They believe that the world is going to hell in a handbasket
and everything is falling apart.
But they are likewise cynics about the past
in that they somehow believe that things have been getting worse forever
but were never better than they are today.
And that that can't be a concrete set of beliefs.
It actually has to be something that they have
instead of having beliefs which is like a posture, a vibe.
What's actually going on is that they have always been lied to
about everything of importance by every credible authority
so they don't believe that people can know things
and they only believe that people can posture and vibe.
That's really sad because manifestly the world around us
displays incredible amounts of the results of knowledge
and if people don't continue to produce the results of that knowledge
we're going to live in a much less nice world.
What could help to correct for this or influence their attitudes
in a positive way for you?
Well, to a really non-trivial degree
large language models that we have today
if they were reinforcement learning trained
for questioning and challenging and calling out bullshit
and especially for perceiving the emotional dynamics of social situations
which are very easy to perceive for even average humans
and wouldn't be that hard to train systems to perceive.
Like people need social support in calling out bullshit
rather than all of the social pressure being to submit to bullshit
and go along with it and like we have the technology today
to build artificial social support of precisely the type we need.
What aspects of your world would you be most excited to see popular media
take on when portraying the future?
Well, to start having a picture of China as something like China
rather than using China as our designated bad guy
which we use to project the images of ourselves
basically our popular media almost exclusively treats China
as a scapegoat for the types of behavior
that we are very aware that we engage in
to approximately the same degree that they do
and is almost always trying to display
so bias for the sake of showing loyalty
rather than trying to display scholarship and understanding.
I think that having in general a somewhat more balanced view
of all sorts of cultural things
having more of an attitude that most things have some good and some bad in them.
Well, thanks so much for joining us today, Michael.
We've covered so much ground in this conversation
and it's been really great to explore all these ideas with you.
It's great having this conversation.
You can read all the comments and appreciate every rating.
This podcast is produced and edited by Worldview Studio
and the Future of Life Institute.
FLI is a non-profit that works to reduce large scale risks
from transformative technologies
and promote the development and use of these technologies
to benefit all life on earth.
We run educational outreach and grants programs
and advocate for better policy making
in the United Nations, US government,
and European Union institutions.
If you're a storyteller working on films
and creative projects about the future,
we can also help you understand the science
and storytelling potential of transformative technologies.
If you'd like to get in touch with us
or any of the teams featured on the podcast to collaborate,
you can email worldbuildatfutureoflife.org.
A reminder, this podcast explores the ideas
created as part of FLI's Worldbuilding Contest,
and our hope is that this series sparks discussion
about the kinds of futures we all want.
The ideas we discuss here are not to be taken as FLI positions.
You can find more about our work
at www.futureoflife.org
or subscribe for a newsletter to get updates on all our projects.
Thanks for listening to Imagine a World.
Stay tuned to explore more positive futures.
