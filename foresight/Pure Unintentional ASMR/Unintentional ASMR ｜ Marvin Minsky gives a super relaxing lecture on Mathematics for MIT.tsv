start	end	text
0	15740	So, what I'm going to do in this course is discuss mostly ideas that are already in the
15740	24600	book called The Emotion Machine, I'm sorry I used that title, and the older book called
24600	36360	The Society of Mind, which are, the books are not quite the same, they overlap a bit
36360	43680	in material, but they're sort of complementary, I like the old one better because the chapters
43680	51760	are all one page long, and they're moderately independent, so if you don't like one you
51760	61200	can skip it. The new book is much denser and has a smaller number of long chapters, and
61200	72080	I think it's, over the years I got lots of reactions from young people in high school,
72080	80840	for example, almost all of whom like The Society of Mind and found it easy to read and seemed
80840	90560	to understand it, there are lots of criticisms by older people who maybe some of them found
90560	101040	it harder to put so many fragments together, who knows, but most of this class, most of
101040	109920	the things I'd like to say are in those books, so it's really like a big seminar and I'll,
109920	118160	my hope is that everyone who comes to this class would have a couple of questions that
118160	126040	they'd like to discuss, and if I can't answer them maybe some others if you can, so I'd
126040	133120	like to think of this as a super seminar, and normally I don't prepare lectures, and
133120	138880	I just start off asking if there are any questions, and if they're not I get really pissed off
139440	149800	because, but anyway I'm going to start with a series of slides. So why do we need machines,
149800	165880	and partly there are a lot of problems, unlike most species or kinds of animals, humans have
165880	175000	only been around a few million years, and they're very clever compared to other animals,
175000	184760	but it's not clear how long they will last, and when we go we might take all the others
184760	194760	with us, so there are a whole set of serious problems that are arising because there are
194800	210640	so many humans, and here's just a little list of things. There's a better list in a book
210640	226760	by the astronomer royal Martin Lise of England, anybody know the title? Yes, our final hour,
226760	249880	it's a slightly scary title, and when I was a teenager, World War II came to an end with
249960	267720	the dropping of two atomic bombs on Japan, and I didn't believe the first one was real
267720	277040	because it was in Hiroshima, so I assumed that the U.S. had somehow made a big underground
277040	286200	underwater tanker with 20,000 tons of TNT and some few grams of radium or something and
286200	294040	blown it up in the harbor, and first it flew an airplane over dropping some little thing,
294040	304320	and this was to fool the Japanese into thinking that we have an atomic bomb, but when they
304320	317800	did it again over Nagasaki that wasn't feasible, so, and when I was in grade school, sometimes
317800	325680	if I said something very bright, I would hear a teacher saying, maybe he's another J. Robert
325720	336240	Oppenheimer, because that was the name of a scientist who had been head of the Manhattan
336240	350560	Project, and he was, I think, three or four years earlier in grade school than I was, and I thought
350560	356400	it was very strange for a person to have a first name as just being a letter rather than a name,
356400	371480	and many years later, when I was at Princeton in graduate school, I met the Robert Oppenheimer,
371480	380280	and that was a great pleasure, and in fact he took me to lunch with a couple of other people I
380320	389480	admired, namely Gertl and Einstein, which was very exciting, except I couldn't understand
389480	397560	Einstein because I wasn't used to people with a strong German accent, but I understood Gertl
397560	406000	just fine, and after that lunch was over, I went and spent about a year learning about Turing
406000	417840	machines and trying to prove theorems about them and so forth. So anyway, in the course of these
417840	431080	talks, we'll run across a few of these people, and here's a big list of the people that I'm mostly
431080	441920	indebted to for the ideas in the Society of Mind and the Emotion Machine. The ones in blue are
441920	457000	people I've actually met. It would be nice to have met Aristotle because no one really knows much
457120	467800	about him, but you really should read, just skim through some of that and you'll find that this is a
467800	474440	really smart guy. We don't know if he wrote this stuff or if it were compiled by his students,
474440	485360	like a lot of Feynman's writing is, and von Neumann's writing is edited from notes by their
485400	497160	students. Anyway, the astonishing thing about Aristotle is that he seems to be slightly more
497160	507280	imaginative than most cognitive scientists you'll run into in the present day. It would have been
507280	523040	nice to know Spinoza and Kant and the others. Also, Freud wrote 30 or 40 books, so did he fall off this
523040	534760	list? There he is. I just made this list the other day and I was looking up these people to find their
535440	550800	birthdays and stuff. Yes? Because they're religious, as far as I can see. Well, who would you, would you
550800	577240	say Buddha? Name one. Maybe I never heard of them. Confucius. Well, I only know of them through
577240	598440	aphorisms. Single Proverbs, but I don't know that Confucius had a theory of thinking. Well, I've
598520	610480	looked at Buddhist theories and they're, I don't think they would get a C plus. And one problem is
610480	618800	that there are cultures, there's something about Greek culture because it had science, it had
618840	633160	experiments. Somebody has a theory and they say, and like Epimenides Lucretius, somewhere in the society
633160	643200	of mind, I think I quoted Lucretius about translucent objects. And he says they have the
643360	649600	particular appearance because the rays of light bounce many times before they get to the surface, so
649600	657640	you can't tell where they started. And I don't find in Eastern philosophy theories that say, here's what
657640	668240	I think and here's a reason why. I've looked at Buddhist stuff and it's strange lists of psychological
668240	676520	principles, every one of which is looks pretty wrong. And they make nice two dimensional diagrams,
676520	682400	but no evidence for any of them. So I don't know whether to take it seriously.
698960	700560	Well, what can't be tested?
704560	709840	Then why, if they can't be tested, why should one look at it twice?
718960	726560	Okay, I think this is a serious argument. It seems to me that science began a little bit in China,
727280	739120	a little bit in India. In the Arabic world, they got up to the middle of high school algebra. But then what?
741000	747920	Well, but this wasn't as good as Archimedes, who got to the beginning of calculus. So if you look at most
747920	756520	cultures, they never got to the critical point of getting theories, doing experiments, discussing them
757040	766160	and then throwing them out. And so if you look at Buddhist philosophy, it's 2,500 years old.
768040	777080	If you look at Greek physics, yes, Archimedes almost got calculus and he got lots of nice principles. And
777080	781480	Buddha mentions, at some point, if you want to weigh an elephant,
785160	792560	put him in a boat and then take the elephant out and put rocks in till the boat sinks at the same level. So there
792560	800400	you see a good idea. But if you look at the history of the culture, if people still say this 1000 year old
800400	804120	stuff is good, then you should say, no, it's not.
814760	815280	Sure.
822840	828320	No, the question is why did it stop? Why did it stop?
830400	838440	Ancient wisdom is generally not very good. And we shouldn't respect it for too long. And that's
839160	858160	no, everybody. No, we, we got rid of alchemy, we got rid of what do you call it? What's caloric?
859440	865840	You, you use you jump off their shoulder. You don't stay on them.
869280	875600	So it's good to know history. But if the history doesn't get anywhere, then you don't want to admire it too
875600	881120	much because you have to ask, why did it stop when it went wrong? And usually went wrong because
881120	890360	barbarians came in and, well, you know, it happened to Archimedes. Some, some Roman killed him. But
891200	902160	anyway, no, it's, it's good. It's a good question. Why, why didn't science happen a million years ago?
902160	906920	Because humans are five million years old. So what took it so long?
911520	918480	No, it's more. Sure. Okay. Do you have a theory of why science didn't develop for
918480	927680	so long? In most cultures, it might be religion, which is a sort of science that doesn't use
927680	934360	evidence. And in fact, kills people who try to get it. And so they're, they're systematic reasons why
934360	941720	most cultures failed. And maybe somebody has written, is there a book on why science disappeared,
942680	953040	except once? It's rather remarkable, isn't it? After all, the idea, if somebody says something,
953040	959640	and somebody else says, okay, let's do an experiment to see if that's right. You don't have to very,
959640	966120	be very bright. So how come it didn't happen all the time everywhere? Period.
971720	978040	He's speculating, even in Europe, there did happen, was it a fluke? And I think he gives the example of,
978040	985640	suppose an asteroid or a common crash in Paris in, you know, family year, he gives me 1150 or 1200 or
985640	991240	something. Then what? Whether it's with science that they never developed anywhere. He just sort of
991240	999800	raised it himself as a thought problem. Well, history is called the flukes. I'm trying to remember who
999840	1011680	wrote that nice book about the plague. Some woman. And she mentions that this was spread by rats and
1011680	1022960	fleas or something. And 30 or 40% of the population of many countries in Europe died. And the next
1022960	1046680	generation had a lot of furniture. The standard of living went way up. So anyway, here's a list of
1047280	1065480	disasters and Martin Reese is the Royal Astronomer and has that book about the last hour or whatever. And I'm
1065480	1078200	making another longer list, but he has lots of obvious disasters like some high school student looks up the
1079520	1093040	genetic sequence for smallpox virus has been published. And now you can write a list of nucleotides and send
1093040	1099480	it somewhere. And they'll make it for about 50 cents or a dollar per nucleotide for so for a couple of
1099480	1107400	hundred dollars, you can make a virus or a few hundred. And so one possibility is that some high school
1107400	1116480	student makes some smallpox only gets it wrong and it kills everyone. So there are lots of lots of
1116520	1127920	disasters like that. And no one knows what to do about that because the the DNA synthesis machinery is
1127920	1140040	becoming less and less expensive and probably the average rich private high school could afford one. So
1140080	1150960	there are lots of other things that could happen. But one particular one is this graph which I just made up.
1154680	1169440	An interesting fact is that since 1950, when the first antibiotics started to appear, as I mentioned, I was a kid
1169440	1181800	in the 1940s, and penicillin had just hit the stands. And there wasn't much of it. And there was a researcher
1183720	1195400	lived a few blocks from us whose dog had cancer. And so its father, I don't know what you call the owner of a
1195400	1207720	dog, sneaked some penicillin out of the lab and gave it to the dog who died anyway. But he said, Well, nobody's
1207720	1216880	tried penicillin on cancer yet. Maybe it will work. And a lot of people were mad at him because he probably
1216880	1226920	cost some human its life. But he said he might have saved a billion humans their lives. So ethics, ethicists are
1226920	1234520	people who give reasons not to do things. And I'm not saying they're wrong. But it's a funny job.
1237880	1245320	So anyway, since that sort of thing happened, and medicine began to advance, people have been living one year
1245320	1262440	longer every 12. So it's 60 years since 1950. Another. So that's five of those six. So they're living six or seven
1262440	1274200	years longer now than they were when I was born. And somebody mentioned that that curve stopped the last few years.
1275400	1287800	For other reasons. But anyway, if you extrapolated that, you find that the lifespan is going to keep increasing.
1289320	1298840	How much we don't know. Another problem is that you might discover enough about genetics to get rid of most of the
1298840	1309480	serious diseases. Maybe just 20 or 30 genes are responsible for most deaths right now. And if you could fix those,
1310160	1316920	which we can't do yet, there's no way to change a gene in a person. Because invading all the cells is pretty
1317880	1326920	massive intervention. But we'll get around that. And then it might be that people suddenly start living 200 or 300
1326920	1338120	years. No, at some point, the population has to slow down. And so you have, you can only reach equilibrium with one child per
1338120	1347000	family, and probably less than that. And so all the work has to be done by two or 300 year olds. And let's hope they're good
1347000	1357960	and healthy. So anyway, I think it's very important that we get smart robots, because we're going to have to stem the
1357960	1368040	population. And I hope people will live longer and blah, blah, blah. And so these robots have to be smart enough to replace
1368040	1386000	most people. And how do you make something smart? Well, artificial intelligence is the field whose goal has been to make
1386000	1399840	machines that do things that we regard as smart or intelligent or whatever you want to call it. And the idea of seriously making
1399840	1415680	machines smart has roots that go back to a few pioneers like Leibniz who wrote about automata and that sort of thing. But the idea of
1415680	1428040	the general purpose computer didn't appear till the 1930s and 40s in some sense. The first form of the general purpose computer appears in
1428640	1444400	really in the 1920s and 30s with the work of a mathematician who, Amel Post at NYU, who I happen to never meet. But we had some friends in
1444400	1459880	common. And he had the idea of production rules and basically rule based systems and proved various theorems about them. Then Kurt Gertl showed
1459880	1471560	that if you had something like a computer or a procedure that had the right kinds of rules, it could compute all sorts of things. But there were
1471560	1484040	some things it couldn't compute, unsolvable problems. And that became an exciting branch of mathematics. And the star thinker in that field was
1484040	1496800	Alan Turing, who invented a very simple kind of universal general purpose computer. Instead of random access memory, it just had a tape which it
1496800	1511520	could write on and read and change symbols and would go back and forth. And if it's in state X at C symbol Y, it will print symbol Z over the
1511520	1532560	X and move to the left or right. And just a bunch of rules like that were enough to make a universal computer. And so from about 1936, it was sort of clear to a large
1532560	1549480	mathematical community that these were great things. And a couple of general purpose like computers, very simple ones, were built in the 1930s and more in the 1940s. And in the 1950s, big
1549480	1568560	companies started to make big computers, which were rooms full of equipment. But as you know, most programs could only do some particular thing. And none of them were very smart.
1569560	1594560	Whereas a human can handle lots of kinds of situations. And if you have one that that you've never seen before, there's a good chance you'll think of a new way to deal with that, and so forth. And so how do you make a machine that doesn't get stuck almost all the time?
1594560	1621560	And I like to use the word resourcefulness, although I left an R out of that one. Is there a shorter word? So here's a good example.
1624560	1650560	My favorite example of a situation where a person is born, or less, with a dozen different ways of dealing with something. And the problem that I imagined that you're dealing with is this. My favorite example is I'm thirsty.
1651560	1676560	So I see that glass of water, and I do that and get it. Actually, I am. On the other hand, if I were here, I would never in a whole lifetime do this. You never walk out a window by mistake.
1677560	1696560	We're incredibly reliable. So how do I know how far it is? And that slide shows you 12 different ways that your vision system, that's only your vision system, has to measure distances.
1697560	1725560	So gradients, if things are sort of blurry, then they must be pretty far away. That's sort of a foggy day outside. Here's a situation. If you assume those are both chairs of the same size, and you know that this chair is about twice as far away as that, although you don't well,
1725560	1734560	and you know how far away they are pretty much by the absolute size.
1734560	1752560	If you have two eyes that work well, then if something is less than 30 feet away, you can make a pretty good estimate of its distance by focusing both eyes on some feature, and your brain can tell how far apart your eyes are looking.
1752560	1768560	So there's 12 different things. It's more than you need. Lots of people are missing half of those. Lots of people have very poor vision in one eye.
1769560	1788560	Some people cannot fuse stereo images, even though both eyes have 20-20 vision, and in some cases, nobody knows why they can't do that.
1789560	1806560	I think I once took a test for being a pilot, and they wanted to be sure you could do stereo vision, which seemed very strange, because if you're an airplane and you're less than 30 or 40 feet away from something, it's too...
1807560	1815560	Then yes, you can't use stereo, you could use stereo, but it's too late.
1815560	1837560	So anyway, that's interesting. See if you can think of an example where a person has even more 12 of these, but it's pretty amazing, isn't it? That's more redundancy.
1838560	1856560	This is too hard to read, but somehow I found in an Aristotle essay the idea that you should represent things in multiple ways.
1857560	1879560	One person might describe a house as a shelter against destruction by wind, rain, and heat. Another might describe it as a construction of stones, bricks, and timbers, but a third possible description would say it was in that form, in that material, with that purpose.
1879560	1907560	So you see there's two different descriptions. One is the functional description. It's a shelter. The second one is a structural description of how it's made, and Aristotle says which is the better description, and he dismisses the material one or the functional one is not rather the person who combines both in a single statement.
1910560	1928560	And then I found a paragraph by Feynman who says every theoretical physicist who is any good knows six or seven different ways to represent exactly the same physics, and you know that they're all equivalent,
1929560	1940560	but you keep them all in your head hoping that they will give you different ideas for guessing. I should put more dots.
1940560	1964560	Anyway, that whole argument is to say that the interesting thing about people is that they have so many ways to do things and perceive things and think of things.
1965560	1979560	And in some cases we even know that there are different parts of the brain that are involved in one aspect or another of constructing those different representations or descriptions.
1979560	2006560	If you look at the, one of my favorite books weighs about 20 pounds. It's the book on the nervous system by Candle and Schwartz, and the index to that book is quite a lot of pages long, and it mentions 400 different structures in the brain.
2009560	2030560	So the brain is not like the, well, I shouldn't make fun of the liver, because for all I know, the liver has 400 different mini processes for doing things, but the brain has distinguishable areas that seem to perform several hundred different functions,
2030560	2048560	and with a microscope, at first they all look pretty much the same, but if you look closely you see different, slightly different patterns of how the most layers of the cortex of the brain, most parts of it have six layers,
2049560	2074560	and each has a population of different kinds of cells. There are a lot of cross connections up and down, and sideways to other, there are engine columns of between 400 and 1,000 cells, and you have a couple of million of those, and there are lots of differences between the columns in different areas, and we know some of the functions.
2075560	2101560	Most cases we don't know much about how any of them actually work, with the main exception of vision, where the functions of the cells in the visual cortex are fairly well understood at low levels, so we know how that part of the brain finds the edges and boundaries of different areas and textures and regions of the visual field.
2102560	2120560	But we do not know even a little bit about how the brain recognizes something as a chair and an overhead projector and CRT screen, and that sort of thing.
2121560	2147560	So, the kind of question that I got interested in was, how can you have a system which has a very large number of different kinds of computers, each of which by itself might be relatively simple or might not, I suppose,
2148560	2168560	and how could you put them together into a larger system which could do things like learn language and prove theorems and convince people to do things that they would never have dreamed of doing five minutes earlier and stuff like that.
2169560	2197560	Now, the first sort of things I was interested in was, in fact, how to make, how to simulate simple kinds of nerve cells, because in the 1950s, there was about almost 100 years, really more like 50 years,
2197560	2210560	of science discovering things about neurons and nerve cells, the axons and dendrites that they used to communicate with other neurons.
2210560	2227560	So, if you go back to 1890, you find a few anatomists discovering some of the functions of, or connections of neurons in the brain, and you find a few experimental physicists.
2227560	2252560	There was no oscilloscope yet, but there were very high-yane galvanometers which could detect pulses going along a nerve fiber, and by 1900, it was pretty clear that part of the activity in a nerve cell was chemical,
2252560	2272560	and part was electrical, and by 1920 or 1930, with the cathode ray tube appearing mostly because of television, but it became possible to do a lot of neurophysiology by sticking needles in brains.
2273560	2288560	The vacuum tube appears around 1900, and you can make amplifiers that can see millivolts and then microvolts, so in the beginning of the 20th century, there was lots of progress.
2288560	2300560	By 1950, we knew a lot about the nervous system, but we still don't know much about how you learn something in the brain.
2301560	2314560	It's quite clear that the things called synapses are involved, connections between two neurons become better at conducting nerve impulses under some conditions.
2315560	2333560	But no one knows how higher-level knowledge is represented in the brain yet, and the Society of Mind Book had a lot of theories about that, and in particular, there was a theory called K-Lines,
2334560	2361560	K-Lines, knowledge lines or something, that came partly from me and partly from a couple of other researchers named David Walts and Jordan Pollack, and that's a sort of nice theory of how neural networks might remember higher-level concepts.
2362560	2372560	And for some reason, although that kind of work is from around 1980, which is 30 years ago, it has not hit the neuroscience community.
2373560	2398560	So if you look at the Emotion Machine Book or the Society of Mind, in Amazon, you might run across a review by a neurologist named Richard Restak, who says that Minsky makes up a lot of concepts like K-Lines and micro-neems and stuff like that that nobody's ever heard of, and there's no evidence for them,
2398560	2415560	and he ignores the possibility that it isn't the nerve cells in the brain that are important, but the supporting tissues called glia, which hold the neurons up and feed them, and he goes on for a couple of insane paragraphs.
2416560	2441560	It's very interesting because it doesn't occur to him that you can't look for something until you have the idea of it, and so here's this 30-year-old idea of K-Lines, and go and ask your favorite neuroscientist what it is, and he said,
2441560	2445560	oh, I think that's some AI thing, but where's the evidence for it?
2448560	2450560	What do you suppose is my reaction to that?
2453560	2455560	Who's supposed to get the evidence?
2458560	2467560	So it seems to me that there's a strange field in neuroscience, which is that it doesn't want new ideas unless you've proved them.
2468560	2477560	So I try to have conversations with them, but get somewhat tired of it.
2478560	2489560	Anyway, but in this course, I'm taking the opposite approach, which is that we don't want a theory of thinking.
2490560	2497560	We want a lot of them because probably psychology is not like physics.
2498560	2500560	What's the most wonderful thing about physics?
2501560	2509560	The most wonderful thing is that they have unified theories.
2510560	2518560	There wasn't much of a unified theory until Newton, and he got these three laws.
2519560	2520560	Wonderful laws.
2524560	2534560	One was the gravitational idea that things, bodies attract each other with a force that's the inverse square of the distance between them.
2535560	2540560	Another is that kinetic energy is conserved.
2543560	2547560	Equal reaction is equal and opposite.
2548560	2554560	If two things collide, they transfer equal amount of momentum to both.
2555560	2558560	There was a little problem up to Newton's time.
2559560	2561560	Galileo got some of those ideas.
2562560	2570560	My impression from reading him is that he has a dim idea that there are two things around.
2571560	2581560	There's kinetic energy, which is mv, and there's momentum is mv, and there's kinetic energy, which is mv squared.
2583560	2589560	He doesn't have the clear idea that there are two different things here, and you can't blame him.
2591560	2602560	You wouldn't think that two quantities would combine in two different ways to make two important different concepts.
2603560	2612560	Well, that got clear to Newton somehow, and Galileo is a bit muddled, although he gets almost all the consequences of those things right.
2613560	2618560	But he doesn't get the orbits and things to come out.
2622560	2631560	Anyway, what happened in artificial intelligence, like most fields, is that people said,
2632560	2637560	well, let's try to understand thinking and psychology, and let's use physics as our model.
2638560	2649560	And so what we want is to get a very small number of universal laws, and a lot of psychologists struggled around to do that.
2649560	2657560	And then they gradually separated so that there were some psychologists, like Bill Estes,
2658560	2665560	who worked out some very nice mathematical rules for reinforcement-based learning.
2666560	2675560	Got a simple rule, if you designed an experiment right, it predicted pretty well how many trials it would take,
2675560	2686560	a rat or a pigeon or a dog or whatever, to learn a certain thing from trial and error.
2687560	2692560	And Estes got a set of four or five rules, which looked like Newton's laws.
2693560	2699560	And if you designed your experiment very carefully and shielded the animal from noise and everything else,
2699560	2715560	which is what a physicist would do for a physics experiment, the reinforcement theories got some pretty good models of how to make a machine learn.
2716560	2718560	But they weren't good enough.
2719560	2731560	So here's a whole list of things that happened in the early years of cognitive psychology,
2732560	2737560	when people were trying to make theories of thinking, and they were imitating the physicists.
2738560	2755560	By physics envy to borrow a term of Freud, the idea is, can you find a few simple rules that will apply to very broad classes of psychological phenomena?
2756560	2761560	And this led to various kinds of projects.
2765560	2778560	Lots of neural network and reinforcement and statistical-based methods led to learning machines that were pretty good at learning in some kinds of situations.
2779560	2792560	And they're becoming very popular, but I don't like them because if you have a lot of variables, like 50 or 100,
2793560	2801560	then to use a probabilistic analysis, you have to think of all combinations of those variables.
2802560	2814560	Because if two of them are combined in something like an exclusive or a manner, I just put the light pen in a pocket.
2815560	2821560	It's either in a left pocket or a right pocket. Can't be both. That's an XOR.
2822560	2837560	That will cause a lot of trouble through a learning machine, and if there are 100 variables, there's no way you could decide which of the two to the 100th Boolean combinations of those variables you should think about.
2838560	2856560	And so lots of statistical learning systems are good for lots of applications, but they just won't cut it to solve hard problems where the hypothesis is a little bit complicated and has seven or eight variables with complicated interactions.
2857560	2872560	So most statistical learning people assume that if you get a lot of partial ones, then you can look for combinations of ones that have high correlations with the result.
2873560	2877560	Then you can start combining them and things get better and better.
2878560	2891560	However, if mathematically, if in effect you're looking for, it depends on the exclusive or of several variables, there's no way to approach that by successive approximations.
2891560	2899560	If any one of the variables is missing, there won't be any correlation of the phenomenon with the others.
2899560	2912560	Anyway, that's a long story, but I think it's worth complaining about because almost all young people who start working on artificial intelligence look around and say, what's popular?
2913560	2922560	Statistical learning. So I'll do that. That's exactly the way to kill yourself scientifically.
2923560	2935560	You don't want to get the most popular thing. You want to see what am I really good at that's different and what are the chances that that would provide another thing.
2935560	2940560	So you end of long speech.
2941560	2965560	Another problem in the last 30 years, and I'm sort of, as you'll see during my lectures, I think a lot of wonderful things happened between 1950 when the idea of AI first got articulated in the 1950s.
2965560	2981560	And then the 20 years after that from 1960 to 1980, a lot of early experiments, and I'll show you some of them, looked very promising.
2981560	2989560	In fact, they may be, here we go.
2989560	3015560	1961. Jim Slagle was a young graduate student here at MIT.
3016560	3037560	He was blind. He had gotten some retinal degeneration thing in his first or second year of high school. He was told that he would lose all his vision and there was no treatment or hope.
3038560	3047560	So he learned Braille while he could still see. And when he got to MIT, he was completely blind.
3047560	3063560	But there was a nice big parking lot in Technology Square, and he would ride a bicycle and people like Sussman and Winston and whoever was around would yell at him,
3063560	3076560	telling him where the next obstacle would be, and Jim got better and better at that, and nothing would stop him.
3076560	3084560	And he decided he would write a program that, oh, I wrote a program that would take any formula and find its derivative.
3085560	3088560	It was really easy because there are just about five rules.
3088560	3099560	Like if there's a product UV, then you compute U times the derivative of V plus V times, you know, U, T, V plus V, D, U.
3099560	3106560	So I wrote a 20-line list program that did all the algebraic expressions.
3106560	3115560	And what it would do is put D's in and then in the right place, and then it would go back through the expression again.
3115560	3122560	Wherever it saw a D, it would do the derivative of the thing after that, and nothing to it.
3122560	3132560	So Slagle said, well, I'll do integrals. And we all said, well, that's very hard. Nobody knows how to do it.
3133560	3147560	And in fact, in Providence at the home of the American Mathematical Society, there is a big library called the Bateman Manuscript Project,
3147560	3152560	which has been collecting all known integrals for 100 years.
3152560	3159560	And when anybody finds a new integral that they can integrate in closed form,
3159560	3170560	they send the formulas to the Bateman Manuscript Project, and some hackers there have developed ways to index it.
3170560	3178560	So if you had an integral and you didn't know how to integrate it, you could look it up.
3178560	3181560	And that was pretty big.
3182560	3200560	I should say that Slagle succeeded in writing a program that managed to do all of the kinds of integrals that one usually found on the first year calculus course at MIT,
3200560	3207560	and got an A in those, couldn't do word problems.
3207560	3218560	And the uncanny thing is that if it was a problem that usually took an MIT student five or 10 minutes, Slagle's program would take five or 10 minutes.
3218560	3225560	It's running on a IBM 701 with 20 millisecond cycle time.
3225560	3228560	It's incredibly slow.
3228560	3234560	You can type almost that fast.
3234560	3240560	And 16K of words of memory.
3240560	3245560	So there's no significance whatever to this accident of time.
3245560	3258560	It would now take a microsecond or so, be a thousand million times faster than a student.
3258560	3260560	Quite remarkable.
3260560	3262560	I don't have a slide.
3262560	3266560	Joel Moses then, Slagle went and graduated.
3266560	3274560	Joel Moses was another student who was, is he a provost now or what?
3274560	3276560	What?
3276560	3279560	He got tired of it.
3279560	3288560	A terrific student, and he set up a project called Maxima for Project Max Symbolic, something or algebra.
3289560	3296560	And got people, several people all over the country, working on integration.
3296560	3307560	And at some point, a couple of them, Bobby Kavanis and forget the other one, found a procedure that could in fact integrate everything,
3307560	3312560	every algebraic expression that has a, can be integrated in closed form.
3312560	3315560	I forget the couple of constraints on it.
3315560	3320560	And that became a widely used system.
3320560	3326560	It ultimately got replaced by Stephen Wolfram's Mathematica.
3326560	3333560	But Maxima was sort of the world class symbolic mathematician for quite a few years.
3333560	3345560	And Moses mentioned to me, he had read Slagle's program thesis.
3345560	3354560	And it took him a couple of weeks to understand the two pages of, or three pages of Lisp that Slagle had written.
3354560	3371560	Because being blind, Slagle had tried to get the thing into as compact a form as possible.
3371560	3374560	But that's symbolic.
3374560	3377560	It's too easy.
3377560	3381560	It wasn't a more ambitious one, which was three years later.
3381560	3388560	Dan Bobrow, who is now a vice president doing something at Xerox.
3388560	3391560	And it solved problems like this.
3391560	3395560	The gas consumption of my car is 15 miles per gallon.
3395560	3400560	The distance between Boston and New York is 250 miles.
3400560	3406560	What is the number of gallons used on a trip between Boston and New York?
3406560	3411560	And it chomps away and solves that.
3411560	3414560	It has about 100 rules.
3414560	3418560	It doesn't really know what any of those words mean.
3418560	3425560	But it thinks that the word is is equals.
3425560	3429560	The distance between doesn't care what Boston and New York is.
3429560	3435560	It has a format thing, which says the distance between two things.
3435560	3444560	And it never bothers to, you see, because the phrase Boston and New York occurs twice in the example.
3444560	3448560	It just replaces that by some symbol.
3448560	3450560	It was fairly remarkable.
3450560	3457560	And generally, if you had an algebra problem and you told it to Bobrow,
3457560	3460560	Bobrow could type something in and it would solve it.
3460560	3464560	If you typed it in, it probably wouldn't.
3464560	3469560	But it was, you know, it had more than half a chance or less, about half a chance.
3469560	3471560	So it was pretty good.
3471560	3481560	And if you look at an out-of-print book, I compiled called Semantic Information Processing.
3481560	3484560	Most of Bobrow's program is in that.
3484560	3488560	So that's 1964.
3488560	3493560	I'll skip Winograd, which is perhaps the most interesting program.
3493560	3502560	This was a program where you could talk to a robot that...
3502560	3505560	I don't have a good picture on the slide.
3505560	3508560	But there are a bunch of blocks of different colors.
3508560	3512560	They're all cubes in the rectangular blocks.
3512560	3520560	And you can say, which is the largest block on top of the big blue block?
3520560	3522560	And it would answer you.
3522560	3530560	And you could say, put the large red block on top of the small green block.
3530560	3532560	And it would do that.
3532560	3539560	And Winograd's program was, of course, a symbolic one.
3539560	3547560	We actually built a robot, and I guess we built it second.
3547560	3555560	Our friends at Stanford built a robot, and they imported Winograd's program.
3555560	3564560	And they had the robot actually performing these operations that you told it to do by typing.
3564560	3568560	And it was pretty exciting.
3568560	3578560	My favorite program in that period was this one, because it's so psychological.
3578560	3584560	This is called a geometrical analogy test, and it's on some IQ tests.
3584560	3590560	A is to be as C is to which of the following five.
3591560	3601560	And Evans wrote a set of rules, which were pretty good at this.
3601560	3607560	It did as well as 16-year-olds, and it picks this one.
3607560	3618560	And if you ask it why, it says something like...
3618560	3621560	I don't have a reason that...
3621560	3625560	It moves the largest object down or something like that.
3625560	3629560	It makes up different reasons, but...
3629560	3634560	So, you see, in some sense, we're going backwards in age,
3634560	3643560	because we're going from calculus to algebra to simple analogies.
3643560	3647560	Oh, there it is.
3647560	3651560	That's one where the largest object moves down.
3651560	3659560	I don't know why I have two of them.
3659560	3662560	These are for another lecture.
3662560	3673560	Okay.
3673560	3679560	So that was a period in which we picked problems that people considered hard,
3679560	3682560	because they were mathematical.
3682560	3690560	But when you think about it more, you see, well, those math things are just procedures,
3690560	3699560	and once you know what Laplace and Gauss and those mathematicians Newton and people did,
3699560	3704560	you can write down systematic procedures for integrating
3704560	3712560	or for solving simultaneous algebraic constraint equations or things like that.
3712560	3714560	And so there's very little to it.
3714560	3722560	So in some sense, if you look at what you're doing in math in high school, in education,
3722560	3725560	you're going from hard to easy.
3725560	3727560	It's just that people aren't...
3727560	3733560	Most people aren't very good at obeying really simple rules,
3733560	3739560	because it's so hideously boring or something.
3739560	3746560	So we gradually started to ask, well, why can't we make machines understand everyday things
3746560	3752560	and the things that everyone regards as common sense,
3752560	3757560	and people can do so you don't need machines to do them?
3757560	3766560	One of my favorite examples is, why can you pull something with a string but not push?
3766560	3775560	And there's been a lot of publicity recently about that interesting program
3775560	3779560	that I've written a group at IBM called Watson,
3779560	3795560	which is good at finding facts about sports people and celebrities and politics and so forth.
3795560	3802560	But there's no way it could understand why you could pull something with a string but not push.
3802560	3809560	And I don't know of any program that has that concept or way of dealing with it.
3809560	3813560	So that's what I got interested in.
3813560	3822560	And starting around maybe the middle 1970s or late 1970s,
3822560	3829560	several of us started to stop doing the easy stuff
3829560	3839560	and try to make theories of how you would do the kinds of things that people are uniquely good at.
3839560	3843560	I don't know of animals.
3843560	3845560	Well, I don't know.
3845560	3849560	I'm sure a monkey wouldn't try to push anything with a string.
3849560	3859560	Maybe it does it very quickly and you don't notice.
3859560	3873560	And one aspect of common sense thinking is going right back to that idea of vision having a dozen different systems.
3873560	3877560	What I think is that whatever a person normally is doing,
3877560	3882560	they are probably representing it in several different ways.
3882560	3892560	And here's an actual scene of two kids named Julie and Henry who are playing with blocks.
3892560	3896560	It's pretty hard to see those blocks.
3896560	3905560	And you can think that Julie is thinking seven thoughts.
3905560	3912560	I'd like to see a longer list, maybe a good essay would be to take a few examples and say,
3912560	3916560	what are the most common micro worlds?
3916560	3926560	See physical, social, emotional, mental, instrumental, whatever that is, visual, tactile, spatial.
3926560	3930560	She's thinking all these things. What if I pulled out that bottom block?
3930560	3933560	You can't see the tower very well.
3933560	3937560	Should I help him or knock his tower down?
3937560	3939560	How would he react?
3939560	3942560	I forgot where I left the arch shaped block.
3942560	3945560	That was real.
3945560	3948560	It's somewhere over here.
3948560	3952560	But I don't think maybe it's that.
3952560	3955560	I don't know.
3955560	3963560	I remember when it happened, she mentioned that she reached around and it wasn't where she thought it was.
3963560	3969560	So common sense thinking involves this.
3969560	3972560	In most cases, I think several representations.
3972560	3988560	I don't know if it's as many as seven or maybe 20 or what, but that's the kind of thing we want to know how to do.
3988560	3991560	Okay, I think I'll stop and we'll discuss things.
3991560	4003560	But in the next lecture, I'll talk about a model of how I think thinking works.
4003560	4009560	What's the difference between us and our ancestors?
4009560	4012560	We know we have a larger brain.
4012560	4022560	But if you think about it, if you took the brain that you already had in say,
4022560	4029560	I remember the name of the little monkey that looks like a squirrel, jumps around in trees.
4029560	4032560	Anybody know it?
4032560	4033560	What?
4033560	4035560	Maybe.
4035560	4039560	It's a squirrel like thing.
4039560	4043560	I didn't know it was a monkey till you took a close look.
4043560	4044560	Maybe.
4044560	4045560	Lemur?
4045560	4050560	I don't, I forget.
4050560	4060560	Anyway, if you just made the brain bigger, then the poor animal would be slower and heavier and would need more food and take longer to reproduce.
4060560	4064560	The joke about difficulty to give birth.
4064560	4068560	I don't know if any animal has the problem that humans have.
4068560	4073560	A lot of people die.
4073560	4076560	And so on.
4076560	4083560	So how did we evolve new ways to think and so forth?
4083560	4109560	And my first book, The Society of Mind, had this theory that maybe we evolved in a series of higher and higher levels or management structures built on the earlier ones.
4109560	4121560	And this particular picture suggests that I got this idea from Sigmund Freud's early theories.
4121560	4125560	There's been a lot of Freud bashing recently.
4125560	4127560	You can look on the web.
4127560	4132560	I forget the authors, but there are a couple of books saying that he made up all his data.
4132560	4149560	And there's no evidence that he ever cured anyone and that he lied about all the data mentioned in his 30 or 40 books and so forth.
4149560	4152560	Yes, right.
4152560	4170560	But the funny part is that if you look at his first major book, 1895, called The Interpretation of Dreams, it sort of outlines this theory that most of thinking is unconscious and it's processes you can't get access to.
4170560	4177560	And it has a little bit about sex, but that's not a major feature.
4177560	4189560	And it's just full of great ideas that the cognitive psychologists finally began to get in the 1960s again and never give credit to Freud.
4189560	4204560	So he may well have made up his data, but if you have a very good theory and nobody will listen to you, what can you do?
4204560	4209560	His friend Rudolf Fleece listened to him.
4209560	4232560	And there was another paper on how the neurons might be involved in thinking, which was also written around 1895, but never got published till 1950 by, forget who, called Project for a Scientific Psychology.
4232560	4238560	And it's full of ideas that if they had been published, might have changed everything.
4238560	4250560	Because anyway, what's on your mind?
4250560	4252560	What would you like to hear about?
4252560	4258560	Who has another theory?
4258560	4259560	Great.
4259560	4268560	So earlier you talked a little bit about how we don't really see the neuroscience, all the things like K-Lines, etc.
4268560	4277560	Do you think it's because they're just really hard to find or no one's actually looking for them?
4277560	4291560	S. Dex Review says he uses vague ill-defined terms like K-Line and Microneme and a couple of others, and Frame and so forth.
4291560	4298560	They're very well-defined.
4298560	4305560	When he talks about neurotransmitters, it's as though he thinks that chemical has some real significance.
4305560	4314560	Any chemical would have the same function as any other one, provided there's another receptor that causes something to happen in the cell membrane.
4314560	4323560	So you don't want to regard acetylcholine or epinephrine as having mental significance.
4323560	4328560	It's just another pulse, but very low resolution.
4328560	4344560	And yes, a neurochemical might affect all the neurons a little bit and raise the average amount of activity of some big population of cells and reduce the average activity of some others.
4344560	4346560	But that's nothing like thinking.
4346560	4355560	That's like saying, in order to understand how a car works, what's the most insulting thing I could say?
4356560	4370560	Or to understand how a computer works, you have to understand the arsenic and phosphorus and or what's the other one?
4370560	4374560	You have to understand these atoms that are, what?
4374560	4377560	Well, that's the matrix.
4378560	4385560	So there are these one part in a million impurities, and that's what's important about a computer, isn't it?
4385560	4389560	The fact that the transistor has gain and so forth.
4389560	4391560	Well, no.
4391560	4394560	The trouble with the computer is the transistors.
4394560	4414560	That's why practically every transistor in the computer is mated to another one in opposite phase to form a flip-flop whose properties are exactly the same except one in a quadrillion times.
4415560	4420560	In other words, everything chemical about a computer is irrelevant.
4420560	4442560	And I suspect that almost everything chemical about the brain is unimportant except that it causes, it helps to make the columns in the cortex which are complicated arrangements of several hundred cells work reliably.
4442560	4449560	Whereas the neuroscientist is looking for the secret in the sodium.
4449560	4456560	When a neuron fires, the important thing is that that lets the sodium in and the potassium out or vice versa.
4456560	4458560	I forget which.
4458560	4460560	At 500 millivolts.
4460560	4463560	Really quite a colossal event.
4463560	4465560	But it has no significant.
4465560	4481560	It's only when it's attached to a flip-flop or to something like a K line which has an encoder and decoder of a digital sort every few microns of its length that you get something functional.
4481560	4490560	So the trouble is the poor neuroscientist started out with too much knowledge about the wrong thing.
4491560	4499560	The chemistry of the neuron firing is very interesting and complicated and cute.
4499560	4505560	And in the case of the electric eel, you know what happened there.
4505560	4519560	The neuron synapse, it got rid of the next neuron and it just, in the electric eel, you have a bunch of synapses or motor end plates, they're called, in series.
4519560	4524560	So instead of half a volt, if you have 300 of those, you get 150 volts.
4524560	4530560	I think the electric shock that an electric eel can give you is about 300 volts.
4530560	4540560	And this can cause you to drown promptly if you are in the wrong way when it happens to bump into you.
4540560	4544560	I don't know why I'm rambling this way.
4544560	4550560	You're welcome to study neuroscience, but please try to help them instead of learn from them.
4554560	4557560	And they just don't know what a K line is.
4557560	4564560	And that's a paper that's been widely read, published in 1980, and RESTAC says, ill-defined.
4564560	4568560	And I guess he couldn't understand it.
4569560	4571560	Yeah, yeah.
4572560	4578560	Why instead of trying to make the neuroscientists, like trying to find this in the human mind,
4578560	4588560	why don't we just, like, as computer scientists, program, like, the K lines and try to prove that all this is the human mind and the claim of the producer?
4588560	4596560	Like, why is that not widely spread into the computer scientist field?
4596560	4601560	Well, I'm surprised how little has been done.
4601560	4605560	Mike Travers has a thesis, Tony Hearn.
4605560	4609560	There are three master's theses on K lines.
4609560	4613560	They sort of got them to work to solve some simple problems.
4613560	4618560	But I'd go further.
4618560	4627560	I've never met a neuroscientist who knows the pioneering work of Newell and Simon in the late 1950s.
4627560	4631560	So there's something wrong with that community.
4631560	4634560	They're just ignorant.
4634560	4637560	They're proud of it.
4637560	4640560	Oh, well.
4640560	4646560	I spent some time learning neuroscience when I was...
4646560	4650560	I once had a great stroke of luck when I was a...
4650560	4656560	I guess I was a junior at Harvard and there was a great new biology building that was just constructed.
4656560	4660560	You probably know it's a great big thing with two rhinoceroses.
4660560	4665560	What are those two huge animals?
4665560	4675560	So this building was just finished and half occupied because it was made with the future.
4675560	4681560	So I wandered over there and I met a professor named John Welsh.
4681560	4685560	And I said, I'd like to learn neurology.
4685560	4690560	And he said, great, well, I have an extra lab.
4690560	4695560	Why don't you study the crayfish claw?
4695560	4697560	And I said, great.
4697560	4702560	So he gave me this lab, which had four rooms and a dark room.
4702560	4709560	And a lot of equipment and nobody there.
4709560	4712560	And he had worked on crayfish.
4712560	4721560	So there was somebody who went every week up to Walden Ponder somewhere and caught crayfish and bringing them back.
4721560	4724560	And I was a radio amateur hacker at the time.
4724560	4726560	So I was good at electronics.
4726560	4731560	So I got my crayfish and Welsh showed me how to.
4731560	4740560	The great thing about this preparation is you can take the crayfish and if you claw and if you hold it just right, go snap.
4740560	4743560	It comes off, grows another one.
4743560	4747560	It takes a couple of years.
4747560	4751560	And then there's this white thing hanging out, which is the nerve.
4751560	4757560	And it turns out it's six nerves, one big one and a few little ones.
4757560	4764560	And if you keep it in ringer solution, whatever that is, it can live for several days.
4764560	4776560	So I got a lot of switches and little inductors and things and made a gadget and mounted this thing with six wires going to these nerves.
4776560	4789560	And then I programmed it to reach down and pick up a pencil like that and wave it around.
4789560	4792560	Well, that's obviously completely trivial.
4792560	4797560	And all the neuroscientists came around and gasped and said, that's incredible.
4797560	4805560	How did you do that?
4805560	4811560	They had never thought of putting the thing back together and making it work.
4811560	4831560	Anyway, it was, I always reminding myself that I'm the luckiest person in the world because every time I wanted to do something, I just happened to find the right person.
4831560	4838560	And they'd give me a lab.
4838560	4849560	I got an idea for a microscope and there was this great professor, Purcell, who got the Nobel Prize after a while.
4849560	4852560	And he said, that sounds like it would work.
4852560	4860560	Why don't you take this lab?
4860560	4867560	It was in the Jefferson.
4867560	4872560	Anyway, yeah.
4872560	4879560	Part of the reason that you don't see experimental neuroscience on things like K-lines is that neurons are long and thin.
4879560	4888560	So if you want to do an experiment to actually measure a real neural network, you have to trace structures with roughly maybe tens of nanometer resolution.
4888560	4894560	But you need to trace them over what might be a couple or even tens of millimeters to charge a week.
4894560	4901560	And you need to do this for thousands and thousands of neurons before you could get to the point of seeing something like a K-line and understanding it.
4901560	4905560	So it's just a massive data acquisition and processing problem.
4905560	4906560	But they're doing that.
4906560	4907560	They're trying to try to.
4907560	4911560	But they don't know what to look for.
4911560	4914560	Maybe you don't have to do so much.
4914560	4921560	Maybe you just have to do a few sections here and there and say, well, look, there were 400 of these here.
4921560	4923560	Now there's only 200.
4923560	4926560	It looks like this is the same kind.
4926560	4928560	Maybe you don't have to do the whole brain.
4929560	4943560	Even getting a single neuron is because you might get down to, you need to be looking at electron micrographs of grains that are sliced at about 30 nanometer slices.
4943560	4949560	So even just having a single person reconstruct a single neuron might take weeks.
4949560	4950560	Well, I don't know.
4950560	4956560	Maybe a bundle of K-lines is a half a millimeter thick.
4956560	4960560	Oh, so you actually do some larger scale structure to start looking at.
4960560	4961560	Yeah.
4961560	4964560	Why not?
4964560	4969560	I don't think they have no idea what to look for.
4969560	4975560	I could give you 20 of those in five minutes, but nobody's listening.
4980560	4982560	What scale?
4982560	4983560	I don't know.
4983560	4985560	I mean, they know what the neurons look like.
4985560	4989560	So you know what to look for if you're saying there's a neuron that level.
4989560	4993560	I'm saying you may only have to look at the white matter.
4993560	4995560	Oh, yeah.
4995560	5006560	Ignore the neurons because the point of K-lines is where do these go and what goes into them and out.
5006560	5007560	I don't know.
5007560	5014560	It's just this idea, let's map the whole brain, 100 billion things.
5014560	5016560	And then people, I rest exit.
5016560	5020560	Oh, and there's a thousand supporting cells for each neuron.
5020560	5027560	He's just glaring in the obscurity of it rather than trying to contribute something.
5027560	5030560	Anyway, if you run into him, give him my regards.
5030560	5039560	I really wonder how somebody can write something like that.
5043560	5044560	Yes.
5044560	5047560	Excuse my ignorance, but what is a K-line?
5047560	5059560	The idea is that suppose one part of the brain is doing something and it's in some particular state
5059560	5069560	that's very important, like I don't know, like I've just seen a glass of water.
5069560	5081560	Then another part of the brain would like to know there's a glass of water in the environment.
5081560	5088560	And I've been looking for one, so I should try to take over and do something about that.
5088560	5094560	Now at the moment, there's no theory of what happens in different parts of the brain
5094560	5097560	for a simple thing like that to happen.
5097560	5111560	No theory at all, except they use the word association or they talk about what are the purposeful neurons.
5111560	5113560	Goal, forget.
5113560	5123560	Okay, so my theory is that there are a bunch of things which are massive collections of nerve fibers,
5123560	5126560	maybe a few hundred or a few thousand.
5126560	5135560	And when the visual system sees an apple, it turns on 50 of those wires.
5135560	5141560	And when it sees a pear, it turns on a different hundred or 50 of those wires,
5141560	5144560	but about 20 of them are the same, so forth.
5144560	5147560	In other words, it's like the edge of a punched card.
5147560	5152560	Have you ever seen a card-based retrieval system?
5152560	5164560	If you have a book that has, suppose it's about physics and biology and Sumatra.
5164560	5171560	And a typical five-by-eight card has 80 holes in the top edge.
5171560	5180560	So what you do is, if it's Sumatra, you punch eight of these holes at random, a particular set.
5180560	5186560	They're assigned to the Sumatra, and then if it's, I forget what my first two examples were,
5186560	5190560	but you punch eight or ten holes for each of the other two words.
5190560	5192560	So now there are 24 punches.
5192560	5198560	Only probably four or five of them are duplicates, so you're punching about 20 holes.
5198560	5205560	And now, if something is looking for the cards that were punched for those three things,
5205560	5209560	even if there are 30 or 40 other holes punched in the card,
5209560	5214560	you stick your 20 wires through the whole deck and lift it up,
5214560	5219560	and only cards fall out that had those three categories punched for.
5219560	5222560	So you see, even though you had 80 holes,
5222560	5229560	you could punch combinations of up to a million different categories into that,
5229560	5235560	and if you have to put a bunch of wires through,
5235560	5240560	you'll get all of the ones that were punched for those categories, the categories you're looking for,
5240560	5244560	and you might get three or four other cards that will come down also
5244560	5250560	because all of the eight holes were punched for some category by accident.
5250560	5254560	Do you get the picture? I'll send you a reference.
5254560	5266560	It was invented in the early 1940s by a Cambridge scientist here named Calvin Moores,
5266560	5273560	and was widely used in libraries for information retrieval until computers came along.
5273560	5278560	But anyway, that's the sort of thing you could look for in a brain
5278560	5283560	if you had the concept in your head of Zato coding,
5283560	5288560	but I've never met a neuroscientist who ever heard of such a thing.
5288560	5295560	So you have this whole community which doesn't have a set of very clear ideas
5295560	5302560	about different ways that knowledge or symbols could be represented in neural activity.
5302560	5306560	So good luck to them when they get their big map.
5306560	5319560	They'll still have to say, what do I do with a hundred billion of these intricate accounts?
5319560	5320560	Yeah?
5320560	5325560	What are your thoughts about the current artificial intelligence research at MIT,
5325560	5328560	such as Winston's Legendes project?
5328560	5333560	Winston is just about one of the best ones in the whole world.
5333560	5344560	I don't know any other projects that are trying to do things on that higher level of common sense knowledge.
5344560	5352560	He's just lost a lot of funding, so one problem is how do you support a project like that?
5358560	5365560	Have you followed it? I don't know if there's a recent summary of what they're doing.
5365560	5372560	We used to write a new book every year called The Progress Report.
5372560	5382560	The nice thing is that we had a very good form of support from ARPA, or DARPA,
5382560	5388560	which was every year we'd tell them what we had done.
5388560	5396560	They didn't want to hear what we wanted to do, and things have turned the opposite.
5396560	5406560	So what would happen is every year we'd say we did these great things, and we might do some more.
5406560	5414560	It went on for about 20 years, and then it fell apart.
5414560	5423560	One thing that's a nice story, there was a great liberal senator, Mike Mansfield,
5423560	5434560	and unfortunately he got the idea that the Defense Department was getting too big and influential.
5434560	5447560	So he got Congress to pass a law that ARPA shouldn't be allowed to support anything that didn't have direct military application.
5447560	5457560	Congress went for this, and all of a sudden a lot of research disappeared, basic research.
5457560	5463560	It didn't bother us much because we made up applications and said,
5463560	5475560	well, this will make a military robot that will go out and do something bad.
5475560	5496560	I don't remember ever writing anything at all, but anyway around 1980 the funding for that sort of thing just dried up because of this political accident.
5496560	5504560	It was just an accident that ARPA, mainly through the Office of Naval Research, was funding basic research.
5504560	5508560	That was a bit of history.
5508560	5520560	If you look back at the year 1900 or so, you see people like Einstein making these nice theories.
5520560	5534560	But Einstein wasn't a very abstract mathematician, so he had a mathematician named Hermann Weill polishing his tensors and things for him.
5534560	5544560	And Hermann Weill's son, Joe, was at the Office of Naval Research in my early time.
5544560	5565560	That office had spent a lot of secret money getting scientists out of Europe while Hitler was marching around and sending them to places like Princeton and other forms of heaven in Cambridge.
5565560	5581560	And again, one of the reasons I was lucky is that I was here and all these, you know, if you had a mathematical question you could find the best mathematician in the world down the block somewhere.
5581560	5597560	And Joe Weill was partly responsible for that, and the ONR was piping all that money to us for work on early AI.
5597560	5611560	So it was a very sad thing that maybe the most influential liberal in the US government actually ruined everything by accident.
5611560	5628560	ARPA changed its name to DARPA. It was Advanced Research Projects Agency, and it had to call itself Defense Advanced Research Projects Agency.
5628560	5657560	Well, Christianity wiped out science. That might happen tomorrow. Only choose your religion.
5657560	5686560	It's a hard problem. The number of people working on advanced ideas in AI has gotten smaller and smaller as the, right now the around 1980 rule-based systems became popular.
5686560	5715560	There are lots of things to do. Right now, statistical-based inference systems are becoming popular. And as I said, these things are tremendously useful, but the problem is if you have a statistical system, the important part is guessing what are the plausible hypotheses and then making up the, then finding out how many instances of that are correlated with such and such.
5716560	5729560	So it's a nice idea, but the hard problem is the abstract symbolic problem of what sets of variables are worth considering at all when there are a lot of them.
5730560	5744560	So to me, the most exciting projects are the kind that Winston is developing for reasoning about real-life situations. And the one that Henry Lieberman, would you stand up, Henry?
5745560	5762560	Lieberman runs a world-class group that's working on common sense knowledge and informal reasoning. And it seems to me that that's the critical thing that all the other systems will need.
5763560	5776560	In the meantime, there are people working on logical inference, which has the same problem that statistical inference has, namely, how do you guess which combinations of variables are worth thinking about?
5777560	5796560	Then it seems to me that the statistics isn't so important. In fact, there's a great researcher named Douglas Lenat in Austin, Texas, who once made an interesting AI system that was good at making predictions and guessing explanations for things.
5797560	5812560	And it was sort of like a probabilistic system. It had a lot of hypotheses, and every time one of them was useful in solving a problem, it moved it up one on the list.
5812560	5827560	So Lenat's thing never used any numbers. It didn't say, this is successful .73 of the time, and now it's successful .7364825 of the time.
5828560	5837560	What it would do is, if something was useful, it would move it up past another hypothesis, every now and then, it would put a new one in.
5837560	5850560	Well, if you're trying to solve a problem, what do you need to know? You want to know what's the most likely to be useful one, and try that.
5850560	5856560	You don't care how likely it is to be useful, as long as it's the most, right?
5856560	5870560	I mean, if it's one in a million, maybe you should say, I'm getting out of here. I shouldn't be working in this field at all, or get a better problem.
5870560	5887560	But Lenat's thing did rather wonderfully at making theories by just changing the ranking of the hypotheses that it was considered. No numbers.
5887560	5892560	It did something very cute.
5892560	5916560	It gave it examples of arithmetic, and it actually, this is a rather long effort, and it actually learned to do some arithmetic, and it invented the idea of division, and the idea of prime number, which was some number that wasn't divisible by anything.
5916560	5940560	It decided that nine was a prime, didn't do much harm, and it crept along, and it got better and better, and it invented modular arithmetic by accident at some point, and it's a PhD thesis.
5940560	5949560	A lot of people didn't believe this PhD thesis because Lenat lost the program tape.
5949560	5959560	So he was under some cloud of suspicion for people thinking he might have faked it, but who cares?
5959560	5976560	Anyway, I think there's a lesson there, which is that let's start with something that works, and then if it's really good, then hire a mathematician who might be able to optimize it a little.
5976560	6002560	But the important thing was the order, and a good statistical one might waste a lot of time because here's this one that's 0.78, and here's this one that's 0.56, and it's the next one down, and you get a lot of experience, and it goes up to 0.57 and 0.58, and it never, you know, might be a long time before it gets past the other one because you're doing arithmetic.
6003560	6013560	Whereas in Lenats, it would just pop up past the other one, and then it would get tried right away, and if it were no good, it would get knocked down again. Who cares?
6013560	6038560	So it's a real question of, I don't know, mathematics is great, and I love it, and a lot of you do, but there should be a name for when it's actually slowing you down and wasting your time because there's a better way that's not formal.
6038560	6044560	There are people who know the price of everything and the value of nothing.
6044560	6046560	Yes, that's very nice.
6049560	6059560	I know you're also a musician, so I have a music related question. What do you think is the role of music? Why do all cultures have it?
6060560	6072560	I have a paper about it. Oh, okay.
6072560	6086560	I've been trying to revise it, actually, but it's a strange question because there is music everywhere.
6086560	6105560	On the other hand, I have several friends who are A musical, and so when I have this theory that music is a way of teaching you to represent things in their orderly fashion and stuff like that,
6106560	6124560	well, I have three of my colleagues who aren't musical, but they dance, so it may be that I don't know the answer.
6124560	6148560	The first theory in my paper is that when you have a lot of complicated things happening, then the only way to learn is to represent things that happen and then look at the differences between things that are similar and then try to explain the differences.
6149560	6156560	Right? I mean, what else is there? Maybe there's something else.
6156560	6174560	So in order to become intelligent and understand things, you have to be able to compare things, and to me the most important feature of what's called music is that it's divided into measures.
6175560	6180560	Ba-ba-ba, ba-ba-ba, ba-ba-ba, ba-ba-ba.
6180560	6191560	And measures are the same number of beats or whatever they are, and so now you can say da-da-da-da, da-da-da, da-da-da, da-da-da.
6191560	6203560	What's the difference? You change the eighth notes in the second one, the last four eighth notes, no, the two before last to a quarter note.
6203560	6213560	So you're taking things that were in different times, and you're superimposing those times, and now you can see the difference.
6213560	6225560	And the reason you can see the difference is that you have things called measures, and the measures have things called beats, and so things get knocked into very good frames.
6226560	6241560	Now there's some Indian music which has 14 measures for a phrase, and some of the measures go seven and five, and I can make no sense of that stuff whatever, and I've tried fairly hard but not very.
6243560	6246560	So I don't understand how Indians can think.
6248560	6253560	Any of you can handle Indian music?
6256560	6259560	I just want to add on what you said about this.
6259560	6273560	My favorite quote from your paper on music-minded meaning is the one about what good is music, about how kids play with blocks to learn about space, and people play with music to learn about time.
6273560	6281560	And I think in that sense both music and dance are different ways that people can arrange things in time.
6281560	6292560	And in the sense like in proposatory music and in proposatory movement are both ways of different blocks if you will in time as opposed to space.
6292560	6306560	Yeah, my friends who seem a-musically, maybe there's something different about their cochlea, or maybe they have absolute pitch in some sense, which is a bad thing to have.
6307560	6327560	Because if you're listening to a piece composed by a composer who doesn't have absolute pitch, then you're reading all sorts of things into the music that shouldn't be there, and the opposite would be true.
6327560	6341560	I read music criticism sometimes, and maybe the reviewer says, and after the second and third movement, he finally returns to the initial key of E flat major. What a relief.
6343560	6354560	Well, I once had absolute pitch for a couple of weeks, because I ran a tuning fork in my room for a month.
6355560	6367560	And I didn't like it, because you can't listen to Bach anymore.
6368560	6386560	Oh, well. It's a good question. Why do people like music? And I don't know any other paper like mine. If you ever find one, I'd like to see it, because if you go to a big library, there are thousands of books about music.
6387560	6397560	And if you open one, it's mostly Berlioz complaining that somebody wouldn't give him enough money to hire a big enough chorus.
6402560	6406560	I've found very few books about music itself. Yes.
6407560	6418560	Do you think that having a body is a necessary component of having a mind?
6419560	6428560	Could you do just as well a simulated creature?
6428560	6431560	Oh, sure. You could have all things.
6431560	6441560	Simulation? I think a mind that's not in a world wouldn't have much to do. It would have to invent the world.
6442560	6451560	And I don't see why it couldn't, but you might have to give it a start, like the idea of three or four dimensions.
6459560	6463560	Can't you? What happens if you sit back and just think for a while?
6464560	6471560	You wouldn't know if your body had disappeared, would you?
6477560	6482560	There are also some strange ideas about existence and...
6488560	6490560	Why do you think there's a world?
6493560	6497560	One of the things that bugs me is people say, well, who created it?
6497560	6502560	And that can't make any sense, because this is just a possible world.
6502560	6507560	Suppose there are a whole lot of possible worlds, and there's one real one.
6507560	6511560	How could you ever, how could you possibly know which one you're in?
6511560	6517560	And then you could say, well, didn't someone have to make it?
6517560	6520560	And what's the next thing you'd ask?
6520560	6524560	Well, who made the maker?
6524560	6534560	So the body-mind thing seems to me that once you have a computer, it can be its own world.
6534560	6547560	The program can spend half the time simulating a world and half the time thinking about what it's like to be in it.
6548560	6550560	Yeah?
6553560	6555560	Yes, it's an empty concept.
6555560	6563560	It's all right to say this bottle exists because let's say this bottle is in this universe.
6563560	6568560	But what would it mean to say the universe exists?
6568560	6571560	The universe is in the universe?
6572560	6580560	So there's something wrong with thinking about, so there are only possible worlds.
6580560	6587560	There's no, it doesn't make any sense to pick one of them out and say that's the real one.
6590560	6593560	Yeah, but existence is relative.
6593560	6600560	Yeah, you don't say this is the world I'm in, but you shouldn't say that doesn't mean it exists.
6600560	6604560	Like, two is in the set of even numbers.
6604560	6607560	What's the set of even numbers in?
6607560	6609560	It doesn't stop anywhere.
6609560	6611560	Yeah, lots of words.
6611560	6614560	So is mathematics or is it only worlds?
6614560	6621560	But physics explains the current world or are there no variables to use at this time?
6621560	6626560	Well, you can't tell because five minutes from now, everything might change.
6626560	6630560	So nothing ever explains anything.
6630560	6636560	You just have to take what you've got and make the best of it.
6636560	6637560	Yeah?
6637560	6643560	Solutions are between systems, knowledge, and visual intelligence.
6643560	6644560	Which knowledge?
6644560	6651560	Like systems, basically, in general.
6651560	6657560	Well, there are people who talk about systems theory, but I'm not sure that it's well-defined.
6657560	6666560	Artificial intelligence means, to me, making a system that is resourceful and doesn't get stuck.
6666560	6678560	And so if you have a system, and also it's a, how do you put it?
6678560	6681560	Some definitions are not stationary.
6681560	6689560	Like, what's popular?
6689560	6694560	Popular is what's popular now.
6694560	6699560	There isn't any such thing as popular music in terms of the music.
6700560	6709560	I know there were, there was once a little department called Systems Analysis at Tufts,
6709560	6716560	which had a couple of rather good philosophers trying to make general theory of everything.
6716560	6726560	And they were writing nice little papers and it got, it moved along.
6727560	6734560	But then there was a Senator McCarthy you've probably heard of, and he announced that,
6734560	6746560	he had evidence that the, one of the principal investigators had slept with his wife before they were married.
6746560	6754560	Well, Tufts was very frightened at this and abolished that department.
6754560	6763560	And Bill Schutts went to California and started Eselin and had a good time for the next 50 years.
6763560	6768560	I don't know, more stories.
6768560	6770560	Yeah.
6770560	6775560	Kind of was an extension of the body and mind question.
6775560	6782560	It seems to me like we as humans, we learn a lot from just interacting with the environment.
6782560	6788560	Like language and hearing, being spoken, we speak it, you know, we see things, we touch things.
6788560	6794560	But it, as far as I know, a lot of the efforts in artificial intelligence so far have been
6794560	6800560	confined to the computer that does not go out into the real world,
6800560	6805560	and direct doesn't kind of turn to bitlessly learn new things.
6805560	6808560	Well, here's the problem.
6808560	6812560	I look over at Carnegie Mellon and there are some nice projects.
6812560	6817560	And the most popular one is robot soccer.
6817560	6821560	And here are these little robots kicking a ball around.
6821560	6826560	They're Sony, what are they called?
6826560	6829560	Yes, the Sony iBos.
6829560	6843560	Sony stopped making the iBos, but it respected Carnegie and it made a little secret stash of iBos to send to Carnegie when the present ones break.
6843560	6856560	But my impression of AI projects that have robots is that they do less, less, less than projects that don't.
6856560	6867560	The reason is, if you have a robot like ASIMO, made by Sony, no, Honda,
6867560	6876560	ASIMO can get in the backseat of a car with some effort, usually falls over.
6876560	6883560	However, if you simulate a stick figure in a computer getting into a stick figure of a car,
6883560	6887560	then you can make it learn to do that and get better and better.
6887560	6895560	And so all AI projects without robots are way ahead of all AI projects with robots.
6895560	6902560	And the profound reason is that robots are usually expensive and they're always being fixed.
6902560	6907560	We have five students and the robot is being fixed.
6907560	6911560	I don't know what they're doing, but they have to wait.
6911560	6919560	Whereas if you have a stick figure robot, then you can just run it on this,
6919560	6923560	although it might be a little slower than your mainframe.
6923560	6928560	Probably not.
6929560	6935560	Here's the theory that I just thought of.
6935560	6942560	The idea of the body as a scene in abstract, basically a mechanism for input output.
6942560	6948560	It's a set of sensors from which our brains can get information about the world
6948560	6952560	and a set of actuators in which we can display our state.
6953560	6961560	In that light, it's almost as if our brains are really independent on our body itself.
6961560	6965560	It can adapt to any sort of body if we haven't hooked it up that way.
6965560	6969560	It just so happens that we've been hooked up to this body since birth,
6969560	6974560	that we have such good mental models of how to use this body.
6974560	6980560	I guess an example from experiments that support this theory might be
6980560	6983560	how when people have limbs amputated,
6983560	6987560	it takes them a while to forget that they have the limb
6987560	6992560	because their mental models still exist and their mental models don't go away overnight.
6992560	6997560	Also, I guess they train monkeys to control robot arms with their brains.
6997560	6999560	Sure.
6999560	7008560	Well, but it just seems to me that a large amount of our brain is involved
7008560	7014560	with highly evolved locomotion mechanisms.
7014560	7022560	And as I said, when you're sitting back with your eyes closed in a chair
7022560	7030560	thinking about something, then it's not clear how much of that machinery is important.
7030560	7040560	But it might be that I have a strange paper on...
7041560	7048560	I don't know if it's...
7048560	7058560	I'm trying to remember its name. It's called...
7058560	7078560	I can actually get a...
7078560	7086560	I can't remember the name of the title.
7086560	7091560	Oh, I give up.
7091560	7100560	The idea is that maybe in the older theories of psychology,
7100560	7104560	everything is learned by experience in the real world.
7104560	7112560	So conditioning and reinforcement and so forth.
7112560	7116560	In this theory, I call internal grounding.
7116560	7118560	I make a conjecture.
7118560	7122560	Suppose the brain has a little piece of nerve tissue,
7122560	7129560	which consists of a few neurons arranged to make...
7129560	7133560	not a flip-flop, but a...
7133560	7136560	what would you call a three or a four-flop?
7136560	7138560	A flip-flop with three or four states.
7138560	7140560	Let's say three.
7140560	7146560	If you put a certain input, it goes from...
7146560	7152560	I couldn't find the chalk.
7152560	7155560	So here are three states.
7155560	7157560	And here's a certain input.
7157560	7160560	That means if you're in that state, you go to this.
7160560	7166560	And if you pop that input again, it does this.
7166560	7173560	And if you say, go counterclockwise, it goes...
7173560	7176560	So three of them get you back where you were.
7176560	7181560	But if I go this, this, and that,
7181560	7187560	that would mean to go like this, this, and back.
7187560	7189560	So this would be...
7189560	7193560	that means that's equivalent to just going one.
7193560	7195560	Get the idea?
7195560	7199560	Imagine that there's a little world inside your brain,
7199560	7202560	which is very small and only has three states.
7202560	7205560	And you have actions that you can perform on it.
7205560	7207560	And you have an inner eye,
7207560	7212560	which can see which of the three points of that triangle you're on.
7212560	7215560	Then you could learn by experience
7215560	7219560	that if you go left, left, left, you're back where you were.
7219560	7223560	But if you go left, right, left, right, you're back where you are.
7223560	7228560	And if you go left, left, right, that's like going one left.
7228560	7232560	In other words, you could imagine a brain
7232560	7237560	that starts out before it connects itself to the real world.
7237560	7243560	It starts by having the top level of the brain
7243560	7245560	connected to a little internal world,
7245560	7248560	which just has three or four states.
7248560	7251560	And you get very good at manipulating that.
7251560	7255560	Then you add more sensory systems to the outer world,
7255560	7261560	and you get to learn ways to get around in the real world.
7261560	7265560	So I call that the internal grounding hypothesis.
7265560	7272560	And my suggestion is maybe somewhere in the human brain,
7272560	7275560	there's a little structure that's somewhat like that,
7275560	7280560	which is used by the frontal part of the cortex
7280560	7284560	to make very abstract ideas.
7284560	7287560	You understand, the more abstract an idea is,
7287560	7291560	the simpler and more stupid an elementary it is.
7291560	7293560	Abstract doesn't mean hard.
7293560	7296560	Abstract means stupid.
7296560	7303560	Real things like this are infinitely complicated.
7303560	7309560	So we might have, and I wouldn't dare suggest this to a neuroscientist,
7309560	7314560	there might be some little brain center somewhere near the frontal cortex
7314560	7320560	that allows the frontal cortex to do some predicting and planning
7320560	7325560	and induction about very simple,
7325560	7329560	few simple finite state arrangements.
7329560	7332560	Who knows?
7332560	7335560	Would you look for it?
7335560	7337560	Well, if you were a neuroscientist, you could say,
7337560	7341560	oh, that's completely different from anything I ever heard.
7341560	7343560	Let's look for it.
7343560	7347560	And if you're wrong, you're wasted a year,
7347560	7358560	and if you're right, then you become the new Ramoni Kahal or someone.
7358560	7366560	Who's the currently best neuroscientist?
7367560	7372560	Maybe it's late.
7372560	7375560	One more question.
7375560	7387560	One last question.
7387560	7394560	This is Cynthia Salman, who's one of the great developers of the logo language.
7394560	7397560	Hey.
7397560	7399560	Yes?
7399560	7404560	Maybe it's that question for me.
7404560	7412560	What do you think about theories such as Ramoni's theories
7412560	7415560	that speak of no same thing?
7415560	7417560	Completely weird.
7417560	7421560	Obviously, those theories have nothing to do with human thinking,
7421560	7424560	but they're very good for making stupid robots,
7424560	7432560	and the vacuum cleaner is one of the great achievements of the century.
7432560	7436560	However, his projects, what was it called?
7436560	7442560	Cog disappeared without a trace.
7442560	7447560	That theory was so wrong that it got a national award,
7447560	7451560	and it corrupted AI research in Japan for several years.
7451560	7453560	I can't understand.
7453560	7456560	Brooks became popular because he said,
7456560	7461560	maybe the important things about thinking is that there's no internal representation.
7461560	7464560	You're just reacting to situations,
7464560	7469560	and you have a big library of how to react to each situation.
7469560	7474560	Well, David Hume had that idea,
7474560	7479560	and he was a popular philosopher for hundreds of years,
7479560	7484560	but it went nowhere, and it's gone, and so is Rod.
7484560	7488560	However, he is one of the great robot designers,
7488560	7498560	and he may be the instrumental in fixing the great Japanese nuclear meltdown,
7498560	7502560	because they're shipping some of his robots out there.
7502560	7506560	The problem is, can it open the door?
7506560	7512560	So far, no robot can open the door, even though it's not locked.
7512560	7515560	I usually start by asking if there are any questions,
7515560	7519560	but I thought I'd say a few things about chapter one,
7519560	7523560	and then see if there are any questions.
7523560	7526560	I can't see the pointer.
7526560	7540560	Oh, anybody remember how to get word to make its pointer not disappear?
7540560	7543560	Maybe I mentioned this in the first lecture,
7543560	7556560	but I was taken by this cute poem by Dorothy Parker,
7556560	7564560	because the first chapter was about love and stuff like that.
7564560	7568560	So I tried to get the rights to reproduce it,
7568560	7573560	and it turned out that she was angry at all her friends.
7573560	7578560	She must have been a perpetually pissed off person,
7578560	7585560	and so she left all her literary rights to the NAACP,
7585560	7590560	and I called them up for hours, and they couldn't find the rights.
7590560	7598560	So finally, so it's in the version of the Emotion Machine on the web,
7598560	7608560	but I had to resort to Shakespeare to replace her.
7608560	7611560	Shakespeare's a slightly better poet,
7612560	7621560	he's not as funny as Dorothy Parker.
7621560	7625560	So the first chapter starts out,
7625560	7631560	it's mostly about all the things we don't understand about the mind,
7631560	7635560	which is almost everything,
7635560	7644560	and the first discussion is, well the whole chapter is making fun of the most popular ideas,
7644560	7654560	and the most popular idea of the mind is that people think that they're not doing the thinking,
7654560	7658560	but there's something inside them that's doing the thinking.
7658560	7669560	And it's this idea that there's a self is embedded in just about everything we say and think,
7669560	7673560	and really it's hard to see how you would do without it.
7673560	7678560	But if you ask what is the self,
7678560	7681560	then since this idea is so popular,
7681560	7688560	people begin to believe that there is such a thing and it takes all sorts of various forms,
7688560	7696560	and the most dangerous form maybe is the one that religions exploit,
7696560	7701560	which is that inside a person with all their complications,
7701560	7707560	there's a little pure essence called the soul or the self or whatever you want to call it,
7707560	7717560	and it's impossible to describe it or explain it in physical terms,
7717560	7725560	and so that is one of the reasons why we think there are two worlds,
7725560	7730560	a physical world and lots of other kinds of worlds.
7730560	7743560	Each of us has some imaginary model of what they are and what they're in,
7743560	7748560	and philosophers talk about it and existentialists and so on.
7748560	7753560	So there are lots of problems about our ideas, about ourselves,
7753560	7759560	and in reading around for half my life,
7759560	7766560	I was puzzled at the strange ideas that are around,
7766560	7774560	and in Aristotle, I find the first intelligible theories of mind and emotions.
7774560	7780560	So if you look at particular Aristotle's, there are a number of books,
7780560	7783560	and one of them is called Rhetoric,
7783560	7789560	and it's full of theories about how people reason and influence each other,
7789560	7798560	and I'll show you some quotes from that,
7798560	7805560	because when I look at the history that I've encountered about psychology,
7805560	7811560	Aristotle stands out as being the first and among the best,
7811560	7817560	and as far as I can see, there were no psychologists nearly as good as him.
7817560	7821560	Of course, we don't know whether there was a him exactly,
7821560	7826560	because what we have of Aristotle is a lot of writing,
7826560	7832560	but it's all cobbled together by students from all sorts of manuscripts by other people
7832560	7839560	and people who took notes, and Aristotle claims to have learned a lot from Plato.
7839560	7844560	We have very little writing from him,
7844560	7853560	and so there you go, three centuries before the Christian era, as it's called,
7853560	7858560	and then a couple of thousand years later,
7858560	7869560	we start to find people like Spinoza and Kant and John Locke and David Hume
7869560	7873560	who start to make psychology theories,
7873560	7881560	very little of which is as good as the ones that Aristotle has in all his fragments.
7881560	7888560	So one question that frequently bothers me and should bother everyone is
7888560	7892560	why did science disappear for a thousand years,
7892560	7902560	and the standard explanation is the rise of the great religions,
7902560	7909560	and why did it come back, and you see with the first signs of anything like modern science,
7909560	7913560	at least in my view, with Galileo and Newton.
7913560	7916560	There are a couple of people before that.
7916560	7922560	There are some people in the Muslim world who invented some high school algebra,
7922560	7925560	and they make a big fuss about that.
7925560	7933560	It looks like Archimedes, in a very recently discovered manuscript,
7933560	7935560	computed in integral.
7935560	7944560	He found the volume of a cone, which is, what is it, 1, 6th, B, H, I forget.
7944560	7950560	Anyway, so why did science disappear,
7950560	7953560	and why did psychology appear so late?
7953560	7959560	Because there isn't much psychology in the modern sense until 1900,
7959560	7969560	or the late 1800s, with Francis Galton and William James lived around here,
7969560	7980560	and Rudolf Fleiss, who, Sigmund Freud, starts writing in 1895.
7980560	7985560	People make fun of Freud, as I mentioned last week,
7985560	7990560	but in fact, among other things,
7990560	7993560	how many of you have read the recent criticisms of Freud,
7993560	8000560	which claim that he was complete faker and never cured a single patient?
8000560	8002560	This is popular stuff.
8002560	8007560	I don't believe Freud ever really claimed to cure a single patient.
8007560	8011560	So the critics, who are really very ferocious,
8011560	8015560	claim that he made up all his data and so forth.
8015560	8021560	But most of what Freud says is that psychoanalysis might be a good way
8021560	8026560	to find out what you're really thinking and discover more about yourself
8026560	8030560	and your goals and so forth.
8030560	8039560	I had the good or bad luck to be introduced to L. Ron Hubbard when I was an undergraduate.
8039560	8044560	John Campbell was the great editor of the, I think it was called,
8044560	8047560	The Stounding Science Fiction in those days.
8047560	8049560	What a marvelous title.
8049560	8056560	And this fairly mediocre science fiction writer L. Ron Hubbard
8056560	8062560	invented a new form of psychiatry called...
8062560	8064560	What was it called?
8064560	8067560	Dianetics.
8067560	8069560	It's pretty good.
8069560	8074560	And I'll tell you that story another time.
8074560	8081560	But John Campbell had Thanksgiving in the Commander Hotel every year
8081560	8084560	and invited a bunch of friends.
8084560	8090560	And I don't remember if that's how I got to meet Asimov and Heinlein and other people.
8090560	8097560	But anyway, I did and science fiction had a big influence on me from my...
8097560	8105560	Actually, early years, but starting in college, it got very serious.
8105560	8118560	Anyway, so chapter one starts to talk about this phenomenon of psychology
8118560	8127560	and one of the funny parts is this little section three, 1.3,
8127560	8131560	of trying to say what are emotions.
8131560	8137560	And I looked up emotions in dictionaries and can you all read that?
8137560	8143560	I don't feel like reading aloud.
8144560	8150560	There's lots of discussion of emotions and how mysterious and complex they are.
8150560	8159560	And then the marvelous thing is how many words there are for emotional states.
8159560	8162560	I think I got 300, but I don't remember.
8162560	8166560	Anyway, here's from A to D.
8166560	8172560	And I don't recall how I found those, but I think...
8172560	8175560	But that's a lot.
8175560	8182560	How many words for ways to think are there?
8182560	8190560	Now, that's a serious question because I complained maybe on the next page.
8190560	8193560	No, I didn't.
8193560	8198560	I found myself complaining that there were very few words for ways to think.
8198560	8202560	And then this afternoon when I was pruning these slides,
8202560	8205560	it occurred to me that I didn't really try.
8205560	8212560	So maybe I just didn't think enough.
8212560	8218560	So if there are a couple of hundred words for everyday emotions,
8218560	8224560	if any of you can find me a list of 10 or 20 common words for styles of thinking,
8224560	8232560	I'd appreciate it because I wonder if there are a lot and if not, why not?
8232560	8244560	So here's a list of typical situations, grieving for a lost child,
8244560	8247560	panic at being in an enclosed space.
8247560	8253560	I'm not sure any of the words in the list of 300 standard emotions
8253560	8261560	are good enough to describe how you feel for any of these not unusual states.
8261560	8266560	Have you ever lost control of your car at high speed?
8266560	8271560	No, but when I first learned to drive, I couldn't believe that you could read signs
8271560	8279560	at the same time as...
8279560	8286560	Well, anyway, one of the very best psychologists in history,
8286560	8292560	or a pair of psychologists, aren't even cold psychologists.
8292560	8298560	These are two guys named Conrad Lorenz and Nico Tinbergen,
8298560	8301560	and somebody made up the word ethology.
8301560	8304560	What they study is the behavior of animals,
8304560	8309560	and in some sense, presumably they're studying the psychology of animals
8309560	8316560	because just as with a person, when somebody flies into a rage,
8316560	8318560	you're not describing their mental state,
8318560	8322560	you're describing something about how they behave.
8322560	8325560	So the ethologists, too, are psychologists,
8325560	8332560	and Tinbergen and Lorenz, starting around 1920s,
8332560	8340560	started to analyze the behavior of animals in great detail.
8340560	8346560	So here's an example of how a certain fish behaves.
8346560	8352560	I actually forgot which fish it is, but there's a picture of it in the book.
8352560	8359560	And at different points in its life, it's in different phases,
8359560	8367560	and this is just one diagram of a dozen for this particular fish,
8367560	8374560	and its reproduction, which involves an environment with plants and other things,
8374560	8380560	and he divides its behavior into parenting, courtship, nesting and fighting,
8380560	8386560	and then you see each of those has a lot of subdivisions.
8386560	8393560	And Tinbergen and Lorenz and some students discovered all these things
8393560	8399560	by sitting in front of fish tanks and watching the fish for months and years.
8399560	8408560	Tinbergen also spent years on some beach watching seagulls,
8408560	8418560	and so he has a diagram like this for a particular class of seagulls.
8418560	8428560	When I came to Boston, my friends and I used to go to Nahant,
8428560	8433560	and look at these tide pools there where there are a lot of activities,
8433560	8437560	and it was very interesting, and I got a big fish tank
8437560	8445560	and imported all sorts of little animals and plants from the tide pools in Nahant,
8445560	8450560	and I watched them for about a year and didn't learn anything.
8451560	8460560	That was before I read Tinbergen, and then I realized there's something about those people,
8460560	8464560	which is they could watch a fish and recognize all sorts of behaviors,
8464560	8468560	and I would just watch a fish and wonder whether it was hungry,
8468560	8475560	or wouldn't you get bored swimming back and forth for three years in this.
8476560	8483560	Anyway, so here are the great psychologists of our day, Aristotle,
8483560	8490560	two thousand years ago, and Lorenz and Tinbergen in the 1930s,
8490560	8499560	and Sigmund Freud and Galton and William James around 1900,
8499560	8502560	and then what went wrong?
8502560	8507560	There's almost no good psychology between then and 1950s
8507560	8511560	when something called cognitive psychology started,
8511560	8516560	and it was partly due to people who said,
8516560	8520560	let's make psychology more scientific,
8520560	8524560	and you've probably all heard of Pavlov or Watson,
8524560	8529560	and what happened is around 1900, some psychologists said,
8529560	8534560	well, these Galton's and Freud's and William James are very poetic
8534560	8539560	and expressive and literary, and they write much better than we do
8539560	8543560	and tell good stories, but they're not scientists,
8543560	8546560	and they don't do reproducible experiments.
8546560	8551560	So what we have to do is simplify the situation to find the basic laws of behavior.
8551560	8556560	So let's take a pigeon and put it in a vacuum in the dark.
8556560	8564560	Well, they didn't go that far, but they did put it in the dark,
8564560	8569560	and there were two illuminated levers to work,
8569560	8574560	and you could make a sound, and the sound could be very annoying,
8574560	8579560	or you could have a right, annoying flashing light or something,
8579560	8582560	and the animal would push one of two levers,
8582560	8587560	and one of them would make the stimulus even more annoying,
8587560	8591560	and one of them would make it go away,
8591560	8596560	and you'd plot curves of how often the animal pressed these levers,
8596560	8600560	so you would get a quantitative theory of how much it learned
8600560	8604560	and how much it could remember and how many trials it would have to do,
8604560	8611560	and then instead of just looking at reactions to stimuli,
8611560	8619560	quickly switch to trying to teach the animal things by giving it two alternatives,
8619560	8624560	turn left or turn right, or push this button or that or whatever,
8624560	8629560	and if they pushed the one you approve of, then you'd give them a little pellet of food,
8629560	8636560	and there was a lot of engineering so that you would make sure that the food got to them right away,
8636560	8642560	because if there were a 10-second delay between an action and a reward,
8642560	8648560	the pigeon or a squirrel or a rat or a cat or a dog would learn much less quickly
8648560	8651560	than if there was a one-second delay,
8651560	8660560	and anyway, that went on for 50 years, starting around 1900, Pavlov and his dogs,
8660560	8667560	and there's a great movie that some guy came around with that had been taken of Pavlov's lab,
8667560	8674560	and it shows sort of like a great dictator or something.
8674560	8679560	There's this room with a lot of cages and dogs and mostly dogs in this case,
8679560	8683560	and Pavlov comes in and there are a bunch of lackeys who sort of bow and scrape,
8683560	8687560	because he's a lord, and he comes in,
8687560	8693560	and all the dogs run into the corner of their cage and yelp.
8693560	8701560	So the Pavlovians tried pretty hard to get that movie suppressed,
8701560	8707560	and I haven't seen it in recent years,
8707560	8720560	but anyway, Fred Skinner, who was a professor when I was an undergraduate at Harvard,
8720560	8726560	was the first one to really automate this experimental psychology,
8726560	8729560	and he invented what's called a Skinner box,
8729560	8736560	but it's just a soundproof, lightproof, well ventilated and thermally regulated cage,
8736560	8742560	and you can put a rat or a pigeon, those are the most common animals.
8742560	8747560	They're very inexpensive because they're free.
8747560	8755560	No one knows much about dolphins.
8755560	8760560	They've been studied for 50 years, whenever, John, what's his name?
8760560	8765560	Remember the name of the great dolphin?
8765560	8767560	Lily, thanks.
8767560	8774560	He discovered a lot about dolphins, and a certain amount about their communication,
8774560	8780560	and a little bit about whales, but there's an interesting mystery.
8780560	8786560	I forget which whales, but some whales have a 20-minute song,
8786560	8792560	and they repeat it for a whole season, and next year that song is a little bit different,
8792560	8798560	but it goes essentially without repeating, it's very complicated for 20 minutes,
8798560	8807560	and people have studied that a lot, and no one has the slightest idea of what it means,
8807560	8811560	and nobody even has any good conjectures, which bothers me.
8811560	8818560	What I think it probably means is this, when there's a whole bunch of fish somewhere for one of these whales,
8818560	8824560	it might be 200 miles away, and whales eat a lot,
8824560	8828560	and it's very important to find where the fish are,
8828560	8836560	and I believe this message, which changes a bit during the season,
8836560	8844560	might be telling you where the food is on the Atlantic or Pacific coastline,
8844560	8850560	in great detail, because if somebody finds a lot of fish somewhere,
8850560	8854560	you have to swim 300 miles, and if they're not there.
8854560	8860560	So anyway, it's interesting that John Lily got a lot of publicity,
8860560	8871560	but he didn't discover squat, and finally the dolphin studyers gave up because nothing happened.
8871560	8877560	Anybody have heard anything? I haven't paid any attention for 20 years.
8877560	8881560	Have you heard of anybody discovering anything about dolphins?
8881560	8890560	Except they're very good at solving a lot of physical problems.
8890560	8903560	Anyway, that's unbothered by the mystery of why was there some psychology in Aristotle's time,
8903560	8914560	and why didn't it get anywhere till 1950 when there was regular psychology,
8914560	8918560	but it was afflicted by what I call physics envy.
8918560	8923560	Namely, you run into people like Estes, and well, he was pretty good actually,
8923560	8931560	but there are a lot of psychologists who made up things like Maxwell's equations for how animals learn,
8931560	8939560	and there were generally three or four laws, and if there's a sequence of events,
8939560	8947560	then animals remember a lot about the first few and the last few in the sequence.
8947560	8956560	They don't remember much about the middle, and of course the reliability of their memory depends a lot on how recent it was
8956560	8964560	and on how powerful the reward was and blah, blah, and so they get these little sets of rules that look like Newton's laws,
8964560	8974560	and that was the kind of sort of psychological physics that the so-called behaviorists were mostly looking for.
8974560	8984560	This was not what Tinbergen and Lorenz did, because they wrote books with extensive descriptions of what the animals did
8984560	8992560	and made little diagrammatic guesses about the structure of the subroutines and substructures.
8992560	8997560	Anyway, end of history, but it's a nice question.
8997560	9005560	Why do some sciences grow and why was psychology just about the last one?
9005560	9015560	I suspect it could have been earlier, but people tried to imitate the physicists and tried to say maybe there's something like Newton's
9015560	9026560	or Maxwell's laws for the mind, and they found a few, but they weren't enough to explain much.
9026560	9031560	There are a lot of questions.
9031560	9043560	When Seymour Papert and I started thinking about these things, which was really around 1960,
9043560	9055560	I had been working on some ideas about AI in the late 50s, and my PhD thesis was a theory of neural networks,
9055560	9064560	which was sort of interesting, but never really went anywhere.
9064560	9073560	I went to a meeting in London somewhere and gave a talk about a theory of learning that was based on some neural network ideas,
9073560	9083560	and there was this person from South Africa named Seymour Papert who gave the same paper.
9083560	9089560	I hope this happens to you someday.
9089560	9096560	Find somebody who thinks so much like you, only different enough that it's worth it,
9096560	9106560	and that you only have to say about three words a day and some whole new thing starts because we really did write the same paper
9106560	9114560	and it had the same equation in it.
9114560	9121560	He had been working for Piaget, who was the first great child psychologist.
9121560	9130560	I should have mentioned Piaget, who probably discovered more things about psychology than any other single person in history,
9130560	9139560	and there are lots of people now who are saying he was wrong about 0.73,
9139560	9145560	because children learn that at the age of two and a half instead of two and three quarters.
9145560	9152560	I'm parodying the Piaget critic community, but it's pretty bad.
9152560	9161560	I think those poor guys are uncomfortable because Jean Piaget published 20 books full of observations about children
9161560	9167560	that, as far as I know, no one had made systematically before,
9167560	9179560	and in his later years he started courting algebraic mathematicians because he wanted more formal theories,
9179560	9189560	and in my view he wanted to make his theories worse, and nothing much happened,
9189560	9203560	but he did visit here a couple of times and it was really exciting to meet the starter of a whole new field.
9203560	9217560	Anyway, Papert and I discussed lots of things, and somehow or other we kept finding other more ideas about psychology,
9217560	9226560	and it finally gelled into the idea that, well, if you look at the brain, you know that there are several hundred different brain centers.
9226560	9239560	What's all that stuff for? And how could it possibly make any sense to try to explain what it does in terms of four laws like Newton?
9239560	9248560	Like, how does a car work? Is there a magical force inside the engine that causes the wheels to turn?
9248560	9260560	No. There's this funny thing in the back to cause a differential so that if the car isn't going in a straight line,
9260560	9267560	the two wheels going at different speeds won't rip the...
9267560	9272560	If the two wheels were going at the same speed, the tread would come off in five minutes.
9272560	9277560	You ever wonder what a differential is for?
9277560	9283560	So, most of the car is fixing bugs in the other parts.
9283560	9291560	Most of the brain is because we started out as fish, or lizards or whatever you like,
9291560	9298560	and making the brain bigger wouldn't help much,
9298560	9305560	because you'd just get a heavier lizard that had to eat more and would think more slowly.
9305560	9315560	So, size is bad, but on the other hand, if you need another cubic inch of brain to fix the bugs in the other part,
9315560	9330560	then the evolutionary advantage of being smarter had better make you able to catch a little more food per hour.
9330560	9336560	So, each person is an ecology of these different processes,
9336560	9346560	and the brain reached its present size about a million years ago, I guess.
9346560	9350560	What's the current guess? Anybody been tracked?
9350560	9357560	They keep discovering new ancestors of humans, and I don't have the patience to read about them,
9357560	9363560	because you know that next week somebody will say, oh, that isn't in the main line,
9364560	9373560	you were just unlucky to discover that skeleton.
9373560	9387560	So anyway, Papert and I and a lot of students gradually developed this picture that the mind is made of lots of processes,
9387560	9394560	or agents, or resources, or whatever you want to call them, and it's anybody's guess what they are.
9394560	9401560	If you look at the anatomy of the brain, you know that people label regions,
9401560	9408560	so it's very clear that this occipital lobe back here is largely concerned with vision,
9409560	9414560	and I forget where the one for hearing is.
9414560	9420560	If you destroy the part of the brain for hearing in some animals,
9420560	9427560	you get a little bit of increased function in some part of the visual system
9427560	9433560	that seems to enable the animal to hear a little bit and make some reactions.
9434560	9443560	And there's a whole lot of hype, I think you have to call it, about the flexibility of the nervous system.
9443560	9448560	That is, if certain brain areas get destroyed, other parts take over.
9448560	9455560	They almost never are as good, and mostly many functions never get taken over at all,
9455560	9460560	but are replaced by ones that superficially seem similar.
9460560	9468560	And so there's a whole lot of, I guess, wishful thinking that the brain is immensely resourceful
9468560	9471560	and error-correcting and repairing.
9471560	9478560	I think there was some idea that it was a general phenomenon,
9478560	9482560	but if you do some arithmetic, you get an interesting result.
9482560	9491560	Suppose that each function in the brain occurred in ten different places at random.
9491560	9501560	Then if you removed half the brain, how many functions would you lose?
9501560	9508560	Well, almost nowhere arithmetic tells you you would lose about one part in the thousand.
9508560	9513560	And so, in fact, you would never be able to detect it.
9513560	9521560	So this idea that the brain has enormous redundancy will now change that number to five.
9521560	9527560	Suppose each function is somewhat supported in five different parts of the brain.
9527560	9533560	Then if you take off half the brain, then what am I saying?
9533560	9540560	One part in 32, chance of losing some significant function.
9540560	9547560	So probably lots of things that we do are supported in several parts of the brain.
9547560	9553560	Apparently the language center is pretty unique and some others,
9554560	9563560	be careful about the conclusions you read from optimistic neuroscientists.
9571560	9582560	Anyway, Papert and I worked on this idea of how could these large numbers of different processes be organized
9582560	9592560	and we made various theories about it and then around, I guess, the late 1970s,
9592560	9600560	we stopped working together and Papert developed his revolutionary ideas about education,
9600560	9611560	which certainly have had a lot of influence although they didn't sweep the world in the way we had hoped.
9611560	9619560	And I kept working on the Society of Mind Theory and we didn't work together so much,
9619560	9628560	but we still did plenty of criticizing and supporting of each other.
9628560	9636560	Anyway, my theory ended up with this idea that it's sort of based on Freud.
9636560	9641560	I don't know if I kept a picture of his here.
9641560	9649560	Freud concluded that the mind was an interesting arena, sort of,
9649560	9654560	and he had the mind divided into three parts.
9654560	9661560	There's at one end of the mind, which we inherited from most other animals,
9661560	9669560	is called the id, which is a bunch of instinctive, mainly built-in behavioral mechanisms.
9669560	9681560	And a second part of the mind is what he called the superego, which is a collection of critics.
9681560	9686560	So in Freud's first image, the brain is in two parts.
9686560	9691560	One is a set of instinctive, built-in behaviors and the other is a set of critics,
9691560	9700560	which actually are associated with a culture and a tradition.
9700560	9706560	And you learn from other people things that are good to do and things that are bad to do.
9706560	9712560	And that's called the superego.
9712560	9718560	This is your set of values and standards and tests for suitable behavior.
9718560	9726560	And the middle is this strange object called the ego, which is not what people think it is.
9726560	9736560	At least Freud's word, the ego, is a kind of big neutral battleground where the instinctive behaviors,
9736560	9749560	I keep wanting to, oh, you can see that arrow if I take my finger off it.
9749560	9756560	And then gradually as I kept trying to figure out where, how problems are solved
9756560	9764560	and what kind of processes might be involved, I got this picture which has six layers.
9764560	9773560	And various people come around and say, I don't think you need to distinguish between layers four and five
9774560	9780560	or why don't you just lump all the three top layers into one.
9780560	9795560	And I sort of laugh quietly and say, these people are trying to find a physics like unified minimal theory of psychology.
9795560	9800560	And they're probably right in one sense, but if they do that they'll get stuck
9800560	9808560	because if you get a new idea there'll be no place to put it.
9808560	9815560	So if you have something that's very mysterious, don't imitate the physicists
9815560	9821560	because if you make a theory that's exactly right and just accounts for the data
9821560	9826560	and there's nothing extra and nothing loose,
9826560	9836560	even when you notice a new phenomenon like dark matter, then the physicists don't know what to do.
9836560	9843560	Should they regard dark matter as some obscure feature of space-time
9843560	9848560	or does it have something to do with this universe being near another one
9848560	9854560	that you can't otherwise communicate with and it's all very puzzling.
9854560	9859560	But there are lots of things that don't fit into Newton's laws these days.
9859560	9874560	And I'm not suggesting a six-layer theory of physics, but it might be worth a try.
9874560	9887560	Okay, so I made up some nice slides, but I think I'll stop.
9887560	9894560	So who has some questions and what would you like to see in the theory of psychology?
9894560	9898560	What do you want to be explained?
9898560	9908560	A lot of people are convinced that there are some really serious problems and mysteries
9908560	9913560	like what is consciousness?
9913560	9927560	And if you look at chapter four, my feeling is consciousness is an etymological accident
9927560	9938560	that people got a word which is a suitcase for all of the things they don't understand about the mind and more.
9938560	9944560	But once you've got a word and it goes in the culture,
9944560	9949560	consider the word consciousness for a minute from a legal point of view.
9949560	9959560	Suppose that you happen to be walking along and you're carrying something.
9959560	9964560	Where is that pointer?
9964560	9969560	And it happens to stick somebody's eye out.
9969560	9983560	Then it's very important when they sue you to establish whether you meant to do it or whether it was an accident.
9983560	9989560	Did you consciously plan to...
9989560	9994560	I can't think of the English word for putting somebody's eye out.
9994560	10005560	There's be heading and also to gouge is a good word.
10005560	10020560	So anyway, it's very important for social reasons to have a word for whether an action was deliberately violating the rules
10020560	10023560	as opposed to accidentally violating the rules.
10023560	10030560	Like if you tripped on the stairs and landed on somebody and broke their neck,
10030560	10039560	that's not a crime unless you were so clever as to make it appear that it was an accident.
10040560	10043560	Anyway, you see what I mean?
10043560	10051560	So we need a whole system of fairness and ethics and social responsibility
10051560	10058560	is based on the distinction between whether an action was deliberate or not.
10058560	10065560	And so did he do that consciously is a word for that.
10065560	10068560	And somehow the idea of conscious became elevated.
10068560	10070560	Well, that's a very superficial.
10070560	10076560	You can probably think of 10 other reasons why a word like that.
10076560	10078560	Yes.
10078560	10084560	Sometimes in your writing, it seems to me that there's both sides of it.
10084560	10086560	Some of you argue both sides of it.
10086560	10089560	It seems like in that kind of...
10089560	10092560	I can well imagine there's that kind of representation.
10092560	10095560	You have representation of self and representation of your mind,
10095560	10098560	but then you say there's no self or no consciousness.
10098560	10104560	Why can't you think about consciousness as just a process that is reasoning about your own mind?
10104560	10106560	Well, I...
10106560	10110560	I mean, I understand you don't want to talk about self as that's a real discussion, but...
10110560	10116560	No, but sometimes when you say conscious, that is, do you remember doing it?
10116560	10118560	Which is...
10118560	10124560	Yeah, but don't want to load up my process that asks me what I think about my own mind
10124560	10127560	and then I retrieve that and I say, yeah, I do remember it.
10127560	10128560	Well, you're right.
10128560	10134560	Actually, I went to a lot of trouble to find 25 or 30 different uses
10134560	10139560	for the word consciousness, and probably if I...
10139560	10144560	or if one of us worked harder, we could take those and condense them into five or six
10144560	10149560	much better ones that account for more stuff than the 30.
10149560	10155560	That might be just right for something.
10155560	10158560	Who knows?
10158560	10162560	Yes, well...
10163560	10170560	I think that's a great criticism of one reason why people don't like these theories quite so much
10170560	10174560	because I propose too many things.
10174560	10181560	I really should reprint that criticism from RESTAC or hand it out
10181560	10185560	because this neurologist who says,
10185560	10194560	why is he telling us all these things about K-lines and representations and so forth?
10194560	10202560	The answer is he's from a community that doesn't have enough variety yet.
10202560	10207560	And I'd be the first to admit that I try to go overboard
10207560	10213560	and think of five more things than are in the literature.
10216560	10221560	But that emotion thing is nice.
10221560	10228560	Remember that that was a serious challenge because when I made that list,
10228560	10236560	I do have a laser pointer somewhere in my jacket probably.
10237560	10246560	How many words for at least noticeably distinct ways of thinking or reasoning
10246560	10251560	or figuring out or solving problems can you think of?
10251560	10254560	Maybe there are 20 or 30.
10254560	10260560	I just realized this afternoon that I never looked.
10260560	10265560	I don't remember where I got this list.
10267560	10272560	Can I ask about your perception of free will?
10272560	10278560	I got a lot of readings that you don't have a strong sense of free will, so what is that?
10278560	10284560	I think it's the same as the one for consciousness, namely it's a legal concept.
10284560	10288560	The idea of free will is completely obscene, isn't it?
10288560	10294560	What could it possibly mean if you did something for no reason?
10295560	10300560	So it's a thoroughly empty idea, isn't it?
10300560	10302560	Or what do you mean by it?
10302560	10310560	Do you mean there's nobody ordering you around so you're free to do whatever you want?
10310560	10311560	But of course you're not.
10311560	10316560	You can only do what your computer computes you to do.
10317560	10326560	In the same way that you show the fish diagram, the fish's actions are products of the environment
10326560	10330560	and its current state, and it's essentially a turning machine.
10330560	10332560	Well, it's some kind of machine, yes, sure.
10332560	10337560	And so would you argue that we are also turning machines that are just turning out in the world?
10337560	10339560	Sure.
10339560	10344560	I've never heard of any even interesting alternative.
10344560	10350560	In other words, people who insist on free will appear to me to be like people who believe
10350560	10354560	that there must be a God who created the world.
10354560	10355560	What's the next step?
10355560	10357560	Who created the God?
10357560	10359560	They don't take that step.
10359560	10365560	So if your will is free, okay, then who's controlling it?
10365560	10367560	There's nothing there.
10367560	10376560	But legally it's great, because if somebody stole some money of their own free will.
10376560	10387560	But suppose you were a peculiar kind of epileptic, and every now and then when you go by,
10387560	10391560	your hand goes out and steals things.
10391560	10395560	Then they, what do they do?
10395560	10399560	They put you on parole?
10399560	10401560	This is very strange.
10401560	10407560	But if you look at religions, you see that people make money on them.
10407560	10417560	13% of the world's product goes to people who make their living on concepts like free will and consciousness.
10417560	10419560	So it's a big money thing.
10419560	10422560	It's not just an accident.
10422560	10425560	It's an industry.
10425560	10429560	So both of those are concepts of society?
10429560	10430560	They're parasitic.
10430560	10434560	Imagine a society without the concept of consciousness of free will.
10434560	10436560	But those are requirements for being free will.
10436560	10437560	I don't think you could.
10437560	10444560	You'd have to make up something to keep people in check and under control and to train them.
10444560	10452560	It's like the rat being, the rat needs somebody to press the reward or punish button.
10452560	10461560	And we have it built into our, a culture works because you build into people's head the machinery for suppressing doubt.
10461560	10466560	And it's very clever.
10466560	10473560	But you should think of it as an industry rather than an explicable phenomenon.
10473560	10477560	How much money goes into, yes?
10477560	10484560	How many ways of thinking can you think of right now?
10484560	10491560	That's my challenge, in fact.
10491560	10499560	There's probably a big list in some chapter or other, but there's nothing like this.
10499560	10510560	What's the trick? Three, if I go like that.
10510560	10516560	Actually, Dragon has a thing so you can tell it make things bigger.
10516560	10522560	How many of you use the new Dragon program speech thing?
10522560	10526560	I can't believe how good it is.
10526560	10531560	I was talking to Henry Lieberman about it earlier.
10531560	10533560	Yes?
10533560	10541560	So I'm wondering, personally, you would say that the side of mind here is both humans and animals.
10541560	10546560	Is it just that we have higher levels of organization than them?
10546560	10549560	And so where would you draw that line?
10549560	10555560	Like, do animals not have a notion of the cell that we describe in the book?
10555560	10566560	That's a great question and it'd be interesting to think about ways to investigate it.
10566560	10574560	People are, researchers are often, in fact, raising that question of,
10574560	10578560	do animals have a representation of themselves?
10578560	10584560	And there's a famous experiment, but I can't remember what its current status is,
10584560	10590560	where you put a red dot on a chimpanzee's head,
10590560	10599560	and when the chimp passes a mirror and sees that, the chimp might go like that.
10599560	10615560	Whereas, I don't think a dog, when it passes a mirror, would rub its forehead to see if it has a red spot.
10615560	10624560	I had a cat who walked past mirrors, because we have some wool full-sized mirrors around the house.
10624560	10631560	And the cat walks by and there's this other cat in the mirror, and she pays no attention to it, whatever.
10631560	10638560	So, of course, I don't know what happened the first three times she walked by that mirror.
10638560	10643560	Because if you see another cat going by, you'd think it would...
10643560	10653560	Anyway, it's a good question and people ask that and there's some evidence that elephants have a model of themselves.
10654560	10662560	And maybe dolphins, and I don't know where...
10662560	10671560	Have any of you heard any stories of other animals that can recognize, for example, when they've been painted?
10671560	10673560	Which?
10673560	10674560	Is it elephants?
10674560	10676560	Yes, I think elephants.
10676560	10688560	There's a famous child psychology experiment where, if you're less than a couple months old, you actually fail this test.
10688560	10695560	So, it's actually something that comes as a sign of your child progressing.
10695560	10700560	So, it might not be intrinsic to humanity, but it might be so.
10700560	10703560	So, I'm sure that the chimp can see how it can do that.
10704560	10723560	This is off the topic, but I once had a great email correspondence with some woman who was getting a PhD in France about how babies recognize their mothers.
10724560	10727560	And she concluded with...
10727560	10736560	You did experiments after having other people walk into the room with a mask of the mother or a different hairdo and so forth.
10736560	10747560	And for the first two months or three months, I think, it turned out that the baby recognizes the mother by the hairdo, which had not been known.
10747560	10756560	And then, I think, after three months, it's recognizing the mother by a face.
10756560	10767560	And at that point, she's doing experiments where you get another woman wearing a copy of the mother's face.
10767560	10773560	And so, now there's two mothers and the baby is absolutely delighted.
10774560	10786560	And then, as I can't remember, then I think at four or five months, when two copies of the mother comes in, the baby gets really panicked.
10786560	10792560	So, I lost track of her.
10792560	10796560	If you have a baby, let me know.
10801560	10808560	She got her PhD for this, and I haven't heard anything since. Yes?
10808560	10816560	Here's sort of a formulated thought that I just thought of regarding ways of thinking and ways of feeling.
10816560	10825560	So, it just occurred to me that it seems like, if you go back to the list of feelings, it seems like when we talk about feeling, we're talking about a state that the brain is in.
10825560	10834560	So, it might be a complicated state that's like some combination of a lot of different parameters, but it's a state that you can stay in for like an arbitrary amount of time.
10834560	10845560	But I think thinking is something that's more sequential, as in like, when you're thinking, you're necessarily changing the state of your brain all the time because you're moving bits around.
10846560	10850560	No, I think that's right.
10850560	10854560	I think when we talk about intelligent behavior, you're absolutely right.
10854560	10862560	What you've got is a process that's criticizing itself and seeing when you got stuck in finding things to do.
10863560	10877560	And I suppose in each emotional state, you're certainly also thinking, so that's going on, but maybe it's more restricted.
10877560	10897560	If you're confronting somebody and there's a sort of conflict, then almost all your thoughts are constrained to that subject and it's not as resourceful, but I'm just improvising.
10908560	10934560	Okay, I think what I'm talking about in this context is sort of extreme forms where the person changes into another machine and it's like an angry person won't listen to reason.
10935560	10941560	Or it's very hard to deflect them, so it's this kind of rigid thing.
10941560	10950560	But humans are generally, are rarely in such extreme states where nothing gets through.
10951560	10969560	The whole point of that was that, and I just realized that maybe it was just too lazy, that we have this huge vocabulary of nuances of emotional activity.
10969560	10980560	And people think these are, also people think that these are hard to explain and mysterious and non-physical and blah, blah, blah.
10980560	10995560	But why do we wait till next week and see if somebody comes up with, or see if we can come up with a set of 30 or 40 words about intellectual states, curiosity.
10996560	11003560	I just don't know how many there are and I haven't thought of any in the last few minutes.
11003560	11006560	Yes, has anybody thought of a couple of...
11006560	11011560	What's the word?
11011560	11020560	Flow, like just in the high, when you're really engaged in some activity that you're doing and you're really in the zone.
11021560	11028560	Yes, there's this, there's a state of keeping other things out so you can focus.
11028560	11031560	Not being interuptable, yes.
11031560	11038560	So in this side of mind, you talked about agents and how they divide between themselves.
11038560	11048560	But I don't see anywhere about how evolution modified a lot agents.
11048560	11053560	Like I believe that evolution modified the way we think right now.
11053560	11058560	I don't know if you saw, there's a paper like wrote like two years ago.
11058560	11061560	It's called The Region of Behavior.
11061560	11066560	And this guy tried to explain like how we make some decisions.
11066560	11072560	Evolutionary, like in a point of view of like our speech.
11073560	11081560	We are maximizing the probability of reproducing ourselves.
11081560	11087560	But individually we are not kind of increasing these efficiencies.
11087560	11094560	And like I think somehow like these agents would be like the decisions of agents or resources
11094560	11104560	would be like very determined by evolution since we have like a very long time to like of evolution of the human being.
11104560	11108560	And somehow we have like hard wire to make some decisions.
11108560	11113560	So for example, like he gives the example of like a guy.
11113560	11116560	Well, for lizards that's certainly true.
11116560	11121560	But why do humans keep changing their environment?
11121560	11127560	So like for example, yeah, so he gives this example of like tossing a point.
11127560	11131560	The guy says that like this coin is unfair.
11131560	11141560	And like there is seven, he doesn't say the probabilities, but there is 75% of getting heads and 25% of getting tails.
11141560	11152560	And like we like the subjects, they choose run only 25% of the time the tails.
11152560	11160560	Even though they like they can take account of the number of the times that you put heads.
11160560	11170560	And even though if you choose always hands, you would get more money or whatever you would make it the right decision.
11171560	11173560	That's called probability matching.
11173560	11176560	And it's not a good strategy.
11176560	11178560	Yeah, but humans do that.
11178560	11185560	No, well, they do it if the psychologist rigs the experiment very carefully.
11185560	11189560	It turns out that the best things, what do you think is the optimal strategy?
11189560	11190560	Always.
11190560	11199560	No, the optimal strategy turns out it's the square roots of the probabilities normalized to add up to one.
11199560	11203560	And I'll, I'll give you a proof next time.
11203560	11209560	This theorem is due to Ray Solomon off who invented inductive probability theory.
11209560	11219560	So evolution, if evolution did probability matching, then it would be wrong.
11219560	11226560	And I bet you'll find out that those experiments are wrong.
11226560	11236560	You have to see how did he rig the experiment so that people, if it's probability 25%, they guess that 25%.
11236560	11242560	I don't know.
11242560	11246560	There was a theory about why you would expect it.
11246560	11247560	It's a good question.
11247560	11250560	I don't think people use probabilities though.
11250560	11265560	So even if an experiment shows some, I would look for a flaw in the design of the experiment.
11265560	11266560	Yes.
11267560	11270560	You talked about a lot of emotions today, I'm sure.
11270560	11285560	And my understanding is that for someone who has a specific personality, they might have a predisposition to feel certain emotions, like anger, depression, or whatnot.
11285560	11300560	My question is that if you had any kind of insight or theories on to what extent our personality is affected by events or influences that happened to us over the course of a lifetime.
11300560	11308560	And to what extent is it impacted by sort of, you know, chemical violence when you wake up or carbohydrate?
11308560	11313560	Well you're asking what things do, what do people learn?
11314560	11317560	We don't care if it's chemical or...
11317560	11322560	See if it's chemical, it's still physical.
11322560	11329560	I mean, I reckon we'll go to that sort of treatment for your depression.
11329560	11341560	And the argument is that a lot of reasons for your depression is because of some sort of chemical or biological way of operating is constructed.
11341560	11344560	Well there's lots of complicated things about the brain.
11344560	11349560	One feature of the brain that I don't know if everybody...
11349560	11354560	You know that there are inhibitory and excitatory synapses.
11354560	11370560	When one neuron connects to another, the impulse that goes along the axon to the target neuron may reduce the probability or the strength of its firing or increase it.
11370560	11375560	So that's called inhibiting or...
11375560	11378560	There's no...
11378560	11382560	Or exciting, that's not quite the right word is it?
11382560	11387560	Now generally in the nervous system has a rule but not always.
11387560	11396560	If you follow a chain of activity, it goes inhibiting, exciting, inhibiting, exciting.
11396560	11406560	If you had too many excitatory things and there was a loop, then it would explode and it would wear itself out and jig time.
11406560	11411560	So there is this general feature of the anatomy that you alternate.
11411560	11425560	So when somebody talks about a drug having an inhibitory effect, that's sort of weird because it's inhibiting half the neurons and therefore lowering the thresholds.
11425560	11428560	Of the ones they're connected to and so on.
11428560	11445560	So I think the best thing is until you have a diagram of the functional relations between different brain centers, it might be best not to try to make generalizations about how the chemistry works.
11446560	11463560	It's easy but people think of adrenaline as a stimulant but in the nervous epinephrine but in the nervous system it's locally it may be inhibiting things that are inhibiting something else.
11463560	11465560	And so it appears to be exciting.
11465560	11467560	Yes.
11467560	11486560	I have a problem understanding the difference between thoughts and emotions and knowing something might be as simple but since the only thing that I can separate in my mind is that thoughts, so let's call it a time constant, I can change it kind of rapidly.
11486560	11492560	Emotions, time constant is long and I can control it again much less.
11492560	11505560	But since there is no, at least in this class, there is no preview, how can I make a decision on where the dividing line between these two entities is?
11505560	11509560	Oh, I think it's a waste of time.
11509560	11522560	As far as I can see, emotional mechanisms are generally lower level simpler ones than the ones that involve several layers of the, more layers of the brain.
11522560	11524560	So it's just a relative thing.
11524560	11527560	It's not that some states are emotional.
11527560	11532560	You're always having some high level thoughts and low level thoughts.
11532560	11540560	And the distinction, I just don't know why the distinction has occupied so much tension.
11540560	11550560	I think it's because, and that goes back to having more words for, or asking how many words do we have for ways to think.
11551560	11563560	It seems to me that in popular culture, there are very few words for ways to think and lots of words for emotions and so they're very prominent.
11563560	11571560	Maybe you have to be smarter to distinguish between ways to think and people generally are dumb.
11571560	11582560	Not because they're inherently dumb, but they come from cultures which bully you if you, you know, what happens if you're in third grade and you're smart.
11582560	11591560	You get it beaten out of you and you learn not to show it.
11591560	11601560	Kind of looked like that question of why science happened earlier and why we have more ways to describe different ways to think.
11601560	11609560	And that sort of puzzled me, but can we just not reflect it as much on different thinking states or different approaches?
11609560	11612560	I wonder if the Greeks had more, but we...
11612560	11622560	I think they did. I think they had also more concept of ideas and different states and their approaches.
11625560	11630560	Who has a theory of that? What's your theory of the Middle Ages?
11633560	11637560	How could things get dark for so, so dark for so long?
11638560	11642560	Well, I do have a theory.
11642560	11645560	And are we about to have one?
11645560	11657560	I think it has this much to do with the channels in which one can communicate ideas to other people, whether they exist or not, whether the arteries are over their clothes.
11657560	11663560	The Middle Ages were characterized by scientific discoveries being kept as family secrets.
11664560	11671560	Ah, Cardan knew how to take cube roots and he wouldn't tell anyone.
11671560	11679560	Well, the classic student example is baby talk, which for 300 years made a single Italian family very rich.
11679560	11686560	You know, using tunnels to extract the baby and crop earth increased success rate in difficult births by about 10% they say.
11686560	11687560	Wow.
11687560	11692560	And that was enough to build a family fortune until some servant finally stole the gene.
11698560	11701560	So, who has a theory of the Middle Ages?
11701560	11704560	Is there a standard theory? Yes.
11704560	11710560	Well, the concept of the Middle Ages as the dark ages is something that emerged mostly in the Renaissance,
11710560	11721560	when people in the 14th, 15th, 16th century tried to present themselves as going back to the classical age of scholarship of ancient Greece and Rome,
11721560	11725560	and as being better than their predecessor for the last few years.
11725560	11731560	This mostly happened because of the discovery of manuscripts that were translated from the ancient Greek,
11731560	11739560	and in certain cases Latin by muslims who at the time were sort of receding from Europe.
11740560	11745560	So, the entire concept of the Middle Ages might be a fabrication of the Renaissance.
11745560	11748560	There were some significant discoveries at the time.
11748560	11749560	That's a nice idea.
11749560	11752560	In other words, when was St. Patrick?
11752560	11754560	St. Patrick.
11754560	11764560	I'm told that he popularized a lot of technical manuscripts, brought them back into Europe.
11764560	11769560	He has two achievements.
11769560	11777560	One was bringing scientific culture back, and the other was getting snakes out of England or something.
11777560	11779560	Ireland.
11779560	11782560	I don't know which he was sainted for.
11782560	11785560	Don't you have to do three miracles, or is it?
11785560	11789560	What's, what's, yeah?
11789560	11794560	Yeah, my theory is that the Middle Ages ended around 2100.
11794560	11800560	Because they'll say, after the Middle Ages ended, they'll say, you know, those guys back in the 21st century,
11800560	11803560	they had no idea how thinking worked.
11803560	11807560	They couldn't even think of a few ways to think.
11807560	11810560	They had poverty, they had wars.
11810560	11813560	You know, those guys were barely out of their winecloths.
11813560	11816560	Right.
11816560	11818560	I just read a history of AI.
11818560	11820560	I forget who wrote it.
11820560	11827560	But it had this section saying, it mentioned the Newell Simon.
11827560	11832560	There was a thing called general problem solver, which I mentioned a couple of times in the book.
11832560	11839560	And it's the idea that the way to solve a problem is to find, it's a symbolic servo.
11839560	11843560	Find the difference between what you have and what you want.
11843560	11847560	And look in your memory for something that can reduce that difference.
11847560	11848560	Keep doing that.
11848560	11856560	And of course, it's, it's important to pay attention to the more important differences first and so forth.
11856560	11859560	And I'll send you this article.
11859560	11866560	This article is saying that they made a terrible mistake and this was a trivial theory.
11866560	11868560	And that's why nobody uses it anymore.
11868560	11875560	And it was interesting how many AI people fell for that idea in the 1960s.
11875560	11888560	My complaint has been that if you look in a modern textbook on, you must have some in your first volume, Pat.
11888560	11895560	Didn't you have some GPS things?
11895560	11900560	If you want to keep up with AI, you should read Patrick's textbook, even though he's,
11900560	11908560	people are starting to use this new one, which doesn't have any AI in it.
11908560	11910560	By, who's it by?
11910560	11912560	Russell and Norvig.
11912560	11913560	Russell and Norvig.
11913560	11921560	It's probably pretty good technically, but I leafed through it and it didn't have any, never mind.
11921560	11934560	It's probably better than I think because I'm jealous.
11934560	11937560	Yes.
11937560	11939560	It's kind of a different topic.
11939560	11945560	In Society of Learning, you're talking about the amnesia of infancy when you forget what you learned
11945560	11948560	and things that were once difficult to become common sense.
11948560	11950560	You can't even remember how it wasn't like that.
11950560	11954560	So it's just kind of wondering about the reverse of that process when you try and say,
11954560	11958560	do something to somebody that you turn on so that people can get your quick awareness on it
11958560	11963560	and bring back up the different levels.
11963560	11976560	I was wondering about, is that itself another way of relearning the things that you learned?
11976560	11981560	That's sure an interesting question.
11981560	11992560	When I first learned about programming, I had the idea that maybe babies think in machine language
11992560	11999560	and then after a while they start to think in FORTRAN.
11999560	12005560	And then finally when they're a little older, they think in ALGO or something.
12005560	12014560	But when they switch from machine language to FORTRAN, then they can't remember their earlier thoughts.
12014560	12030560	And there's almost no evidence of people finding genuine recollections from two-year-olds at later ages.
12030560	12033560	Now almost everybody thinks they remember something,
12033560	12039560	but there's the problem that you might have rehearsed it and translated it into the FORTRAN
12039560	12047560	and the ALGO and the LISP and the logo, whatever it is.
12047560	12057560	I had one of my greatest influences was a great mathematician named Andrew Gleason at Harvard,
12057560	12064560	who I met practically the first day I got to Harvard.
12064560	12072560	And he would always talk about things I didn't understand and I would go home and look them up and try to.
12072560	12078560	Anyway, one day we were talking about number forms.
12078560	12087560	And number forms are a psychological phenomenon which about 30% of people have.
12087560	12092560	And it was first described by Francis Galton.
12092560	12106560	And the phenomenon is if I ask you, close your eyes and tell me where is the number three?
12106560	12112560	How many of you have a place for the number three?
12112560	12114560	Well, that's a few.
12114560	12124560	So typically, if you imagine the visual field, that's a windshield, I guess.
12124560	12143560	So there are these numbers and they're nowhere in particular except that it's usually like that for an older child.
12143560	12151560	So here are these numbers and what's more in some people they're colored.
12151560	12160560	So I was talking to Andrew Gleason, I had read this Galton paper which was 1890 or 1885 or something.
12160560	12164560	And so I was asking people if they had number forms.
12164560	12167560	And he said, oh yes, he has one.
12167560	12172560	And he sketched it for me.
12172560	12176560	And he said, and they're colored too.
12176560	12185560	Oh, and his went way up and the prime numbers were bright.
12185560	12188560	What am I doing?
12188560	12192560	Maybe the composite numbers were something was bright.
12192560	12196560	And they were colored.
12196560	12206560	So I wrote this down and I, over the next couple of years, I look in antique stores for old children's blocks.
12206560	12212560	And I found a set of blocks that matched that.
12212560	12219560	And Andrew Gleason said that he knows when he acquired this thing.
12219560	12231560	And it was about four years old and he had a window which in this house and there was a hill.
12231560	12238560	And he could just see over the sill and he imagined these numbers on the side of that hill.
12238560	12239560	Blah, blah, blah.
12239560	12248560	Anyway, people who don't have a number form don't know what I'm talking about.
12248560	12255560	And I don't know if the 30% is still true, but it's an interesting phenomenon.
12255560	12268560	And in most cases of early childhood, well, that's, you can't find out because children do remember details of a house they lived in,
12268560	12272560	but you don't know if they've copied it.
12272560	12277560	So what was the original question?
12277560	12281560	How much can you remember from infancy?
12281560	12286560	Elran Hubbard thought you could go back to before you were born.
12286560	12298560	And you could remember people talking about you when you're still in the womb.
12298560	12301560	So anyway, John Campbell said you should look into this.
12301560	12305560	And a few of us made an expedition.
12305560	12313560	We went down to Elizabeth, New Jersey to visit the just starting up Dianetics Center.
12313560	12322560	And I met this Elran Hubbard who had green eyes and was quite hypnotic looking.
12323560	12331560	And the end of the story is he had been writing about how if you took this treatment of Dianetics,
12331560	12338560	then you could memorize an entire newspaper in five minutes and do all sorts of miraculous things like that.
12338560	12343560	Once your mind has been cleared of aberrations and obstacles.
12343560	12348560	And I became a big industry and turned into later Scientology.
12348560	12351560	I'm sure you've all heard about that.
12351560	12358560	So we asked Hubbard to look at a newspaper and tell us what was in it.
12358560	12371560	And he explained he was so busy training the other people to be cleared that he hadn't had time to go through the procedure himself.
12371560	12377560	And I never saw him again.
12377560	12379560	Yes?
12379560	12389560	What are your thoughts on memes and the fact that we're just, but because our thoughts are actually all about the good.
12389560	12391560	Of memes?
12391560	12398560	You mean Dawkins?
12398560	12400560	I didn't quite get the whole question.
12400560	12404560	The idea that...
12404560	12409560	So for example the way we talk and the way we all talk,
12409560	12415560	how we very much mix the way our parents talk to the people around us.
12415560	12419560	And possibly the way we think as well.
12419560	12423560	So how does that relate to how our mind develops?
12423560	12428560	Are we actually creative original characters?
12428560	12438560	Well of course it's both because you learn things from your culture and then you might just mainly repeat things
12438560	12443560	or you might get the knack of making new ideas.
12443560	12450560	I'm trying to remember what Dawkins main ideas are.
12450560	12457560	He invented the word meme to say that
12457560	12466560	ideas that people have might be considered to be somewhat similar to the genes in our heredity
12466560	12477560	and that societies are systems in which these memes which are conceptual units of meaning or knowledge
12477560	12484560	propagate around and self-reproduce and mutate and spread.
12484560	12496560	And I don't know what to say about it except that it's obviously true that every now and then someone gets a new idea
12496560	12502560	and tells people and for one reason or another they either forget it or tell someone else
12502560	12512560	and after a while it spreads and some of them fill up the whole culture and some just die out.
12512560	12516560	And whatever else Dawkins says, he's a very smart guy,
12516560	12525560	but almost everything then in my mind is that he's explaining that religions are mostly made of these memes
12525560	12535560	and they're very bad and cost the world a great deal in progress and productivity.
12535560	12545560	In other words, he's a militant atheist and there are about five best sellers in that business today.
12545560	12554560	But I don't know what else to say about memes. It's an obviously generally correct idea.
12554560	12564560	But the great thing about genes is we know the four amino acids or four nucleic acids they're made of
12564560	12568560	and how they're rope together and all that.
12568560	12577560	And I don't think Dawkins' theory develops anywhere nearly as elegantly as modern genetics.
12577560	12589560	So it would be nice if it could, but a really good theory of good ideas would be nice to have.
12590560	12595560	What would it look like?
12595560	12598560	Someday we'll have an AI that just punches them out.
12598560	12602560	I think it would look like a really good language.
12602560	12605560	Oh right.
12605560	12614560	Robert Heinlein has some stories in which the super intelligent people have a language that's so dense
12614560	12620560	that in five syllables they can explain something that would take you a half hour.
12620560	12627560	I think, I forget what it's, log land.
12627560	12633560	Anyway, if you need a good idea, read Robert Heinlein.
12633560	12635560	Sure.
12635560	12637560	I thought you already mentioned this.
12637560	12648560	When you talk about how geniuses, they might have just come up with better ways to think better,
12648560	12658560	like better ways to think, better ways to learn about how to better learn from better learning.
12658560	12662560	But why do you think they never mention it?
12662560	12672560	And why hasn't they propagated them better and learning about how better to learn from it?
12672560	12674560	That's a great question.
12675560	12693560	Do you think people have a concept of an idea that improves better learning?
12693560	12701560	There's a couple of phenomena that, like, how come there were so many geniuses in Athens?
12702560	12718560	And then some of the best mathematicians came from some high school in some little country next to the Baltic.
12718560	12720560	Bulgaria?
12720560	12722560	Romania.
12722560	12728560	Yes, there was some high school in Romania that not only produced von Neumann,
12728560	12732560	but about five or six other world-class mathematicians.
12732560	12734560	I don't remember the details.
12734560	12735560	So that's a nice question.
12735560	12746560	How come, if there are these great memes, how come there aren't more big pockets of them?
12746560	12754560	But there are a lot of cultures which were very inventive in other than intellectual fields.
12754560	12757560	How come Paris got all those artists?
12757560	12760560	How many of you saw the Woody Allen movie?
12760560	12762560	What's it called?
12762560	12767560	Paris at Midnight?
12767560	12773560	So funny.
12773560	12776560	Like, would you be able to say no one?
12776560	12784560	Say one idea that would improve, you know, your improvement of learning.
12784560	12786560	Right.
12786560	12789560	That's a good question for each of us.
12789560	12791560	What's your very best idea?
12791560	12799560	And stop fussing with the other ones and get that one out.
12799560	12805560	There must be some people who are very quiet and only speak once in a long time.
12805560	12808560	We should watch them carefully.
12808560	12810560	Yes?
12810560	12815560	I guess along with like, do you ever feel restricted by language?
12815560	12821560	Wait.
12821560	12827560	It's the sound I can't hear.
12827560	12834560	Am I strong enough to lift you?
12834560	12837560	I'm sure someone's done it.
12837560	12840560	Sorry about that.
12840560	12851560	Do you ever feel restricted by language and that you must represent your theory of mind or any theory of language?
12851560	12852560	No, I don't.
12852560	12869560	But I once was jealous when Papert explained that he got some idea and he explained he gets ideas like that when he thinks in French.
12869560	12870560	What?
12870560	12871560	You draw pictures too.
12871560	12872560	Oh, yeah.
12872560	12873560	So it's not just language.
12873560	12875560	That's a language.
12875560	12878560	Graphics.
12878560	12890560	So we ought to have devices within the next few years that draw pictures when you think.
12890560	12892560	It's so funny.
12892560	12895560	You know, we had cyborgs.
12895560	12897560	What were they called?
12897560	12898560	I mentioned them last time.
12898560	12904560	We had Steve Mann and who's the other one?
12904560	12906560	Yeah.
12906560	12919560	So there's these two guys around the Media Lab wearing various things on their head and they're always typing and you ask them a question and they've searched Google.
12919560	12924560	And when was that?
12924560	12930560	1990.
12930560	12932560	But it's all gone.
12932560	12938560	Nobody walks around with direct connection to the web.
12938560	12940560	Yes.
12940560	12946560	Anyway, I certainly expected it to turn up and something wrong.
12946560	12950560	So anyway, you should be able to buy one one of these days.
12950560	12954560	And what's your name?
12954560	12961560	Who is that nice woman who had the EEG thing?
12961560	12966560	Do you remember a Ted?
12966560	12967560	Forgot her name.
12967560	12975560	Anyway, she had this sort of helmet which had about 20 electrodes and she induced me to put it on.
12975560	12981560	I was on a stage with about a thousand people there, which was rather funny.
12981560	12994560	And there's a little spot on a CRT and I get to think about it moving one way or the other and rewarding it when it did the right thing for only about half a minute.
12994560	12996560	And then I could steer it around.
12996560	13006560	So here was a nice primitive gadget where you could sort of almost draw just by thinking this spot.
13006560	13013560	And then she started a company and hasn't sent me one.
13013560	13016560	Because maybe it was just beginners luck.
13016560	13021560	Beginners luck or something.
13021560	13022560	What?
13022560	13024560	Her name is Holly.
13024560	13030560	Yes, Lee.
13030560	13035560	Did you find the company?
13035560	13041560	Do you think there would be lots of people wearing stuff?
13041560	13047560	With your keyboard, right?
13047560	13049560	Why don't we take a five minute break?
13049560	13070560	I don't know.
13070560	13094560	Well, I hate to interrupt because I see ten different productive discussions.
13094560	13107560	I know.
13107560	13109560	Yes, I see.
13109560	13113560	I saw quite a few apparently productive discussions.
13113560	13115560	Maybe that's what the class needs.
13115560	13121560	But anybody come to a conclusion?
13121560	13130560	Yeah.
13130560	13135560	See if you can knock the wall down.
13135560	13137560	It's not a conclusion, but it's a question.
13137560	13138560	It's a thought experiment.
13138560	13142560	So if you had a black box that could sort of replace part of your brain.
13142560	13146560	And let's say you could replace like five percent at a time.
13146560	13148560	If you assume that there's a self entity.
13148560	13154560	At what point would you lose yourself?
13155560	13173560	If you change the question is, are you how how much do you have in common with with the you of yesterday as compared to when you graduated grade school?
13173560	13186560	So this question of the idea of identity is very, very fuzzy.
13186560	13215560	Yeah, I read a science fiction novel by Robert Sawyer.
13215560	13231560	And if you know of him, Canadian writer and it has to do with somebody who has a fatal disease.
13231560	13234560	So he's going to die soon.
13234560	13240560	But the technology is around where you can make a duplicate of him.
13240560	13250560	And so he has a duplicate made and he is sent to the moon for some reasons.
13250560	13264560	I can't remember, which is a kind of nursing home for I think people who are enfeebled and do much better with one seventh of gravity.
13264560	13275560	So there's some reason why anyway the living the original copy is sent to the moon and the substitute takes over.
13275560	13286560	But then our hero is miraculously cured by eating the right stem cells or what I don't remember.
13287560	13296560	So he wants to come back and the question is who gets the car?
13296560	13307560	So I can't remember the title of the novel except that it has alien in it.
13307560	13316560	Alienable rights is not something like that, but I wrote an article called alienable rights.
13316560	13325560	Anyway, so are you the same as you were five minutes ago or five years ago or whatever?
13325560	13331560	And as far as I'm concerned, the answer is who cares?
13331560	13340560	It's a sort of silly question because no two things are exactly the same ever anyway.
13340560	13347560	But again, a lot of these questions which look philosophical are legal.
13348560	13364560	The joke of that novel is that who owns the car is what matters to decide who is the real original and who's the copy.
13364560	13379560	Frederick Paul wrote a similar story much longer ago where people are copied and the copy is sent on a one way trip to some planet to fix a broken reactor.
13379560	13386560	And they always die and you get a million dollars for providing this copy.
13386560	13392560	But one of the copies survives so it's the same plot.
13392560	13395560	I can't remember that.
13395560	13411560	If you're looking for a good idea, if you go to 1950s science fiction, look for A.E. Van Voter, Frederick Paul or all those wonderful writers.
13411560	13417560	That was before it was necessary to describe really good characters.
13417560	13433560	And science fiction got better and better for the literary critics and generally worse and worse for the science fiction fans.
13433560	13436560	Do we really have any more questions?
13436560	13438560	Yes.
13438560	13448560	We're in a time age where sharing information between many people on a short amount of time is quite easy.
13448560	13451560	Do you think that this will change?
13451560	13456560	This will bring up many more ideas. Do you think that this will hinder?
13456560	13463560	Because before this time people had problems with sharing information.
13463560	13469560	And also now it's touching to hear from a large group of people working on one thing.
13469560	13475560	Do you think that this will change the way that we think and do you think that this will make us better?
13475560	13487560	It's a tough one. Bad things can happen and good things can happen.
13487560	13490560	Funny, because that reminds me again of science fiction.
13490560	13500560	Because in science fiction many, many years ago some writers got the idea that there would be something like an internet.
13500560	13504560	And some people realized there would be flash crowds.
13504560	13507560	And now there are flash crowds.
13507560	13514560	And I remember even as a kid talking to people who said,
13514560	13520560	why not wire up the voting machines so that they're always there?
13520560	13527560	And so if somebody in the government wants to know should we do this or that?
13527560	13532560	Should we bomb China or not?
13532560	13539560	You could get 100 million people to run up to the keyboard and say yes or no.
13539560	13546560	Presumably when the, what do they call those?
13546560	13556560	That great crowd of Jeffersons and Franklins and the Founding Fathers did a lot of things to prevent that.
13556560	13564560	And the one that they focused on, which was one of the most effective, was called the Electoral College.
13564560	13571560	And the United States is different from other places because we don't elect congressmen or presidents.
13571560	13579560	We elect smart people from the community who then get together and decide who should be president.
13579560	13587560	And of course now if anybody, now they belong to parties and if any of them voted for the other party's candidate,
13587560	13590560	they would be held to pay.
13590560	13600560	But it was a great idea because the Founding Fathers realized that if you had instant feedback, which is what Hitler got,
13600560	13607560	then you could say something really exciting and everybody would press the yes button and then you kill all the Jews.
13607560	13618560	And then the next speech you kill all the black people and all the yellow people and all the people whose last name doesn't begin with M.
13618560	13623560	And so what you don't want is instant feedback.
13623560	13628560	Now the new social networks are getting us close to that.
13628560	13636560	And the question is, is it time to have, is it time to stop that?
13636560	13639560	Is it getting dangerous? I don't know.
13639560	13650560	But there must be a lot of people who are recognizing that this thing is creeping up on us and you might be able to get 50 million people
13650560	13658560	to do something reckless in a few minutes if you don't put some limits.
13658560	13669560	I don't think we could get the electoral college back because you'd have to get a majority to, what does it take to fix the Constitution?
13669560	13674560	Two thirds?
13674560	13678560	We'll never see two thirds again.
13678560	13683560	It's the end of America.
13683560	13691560	Well, we have three minutes.
13691560	13692560	Yes?
13692560	13699560	If you would design a direction for the field of psychology, obviously one word is a set of debugging tools.
13699560	13704560	Why don't you say they should be doing it?
13704560	13708560	They should read Patrick Winston's thesis.
13708560	13721560	The psychologists now have disappeared into the tar pit of statistics and they don't have the idea that knowledge needs complicated representations.
13721560	13731560	And I don't care whether you assign probabilities to them or put them in the order in which you thought of them or, you know,
13731560	13744560	or do what Doug Lenet did in his thesis of swapping things when one worked better than another, but I forget the question.
13744560	13751560	But I think we've got to get better ideas about representation of knowledge.
13751560	13766560	I don't know where they're going to come from now that the whole AI community is drifting into these ways of avoiding representations.
13766560	13770560	I haven't read the Norvig, Russell, book.
13770560	13780560	Does he, can anybody summarize what it says about knowledge representation?
13780560	13784560	Who's read it?
13784560	13788560	There's a chapter on logic for sort of logic.
13788560	13791560	That's so funny.
13791560	13805560	First order of logic is what Newell and Simon thought of in 1956 before they thought of the so-called GPS thing.
13805560	13807560	Logic can't make analogies.
13807560	13813560	It's a very bad thing to get stuck with.
13813560	13823560	Zero or one.
13823560	13828560	Maybe one of our papers should be on what should AI do next year.
13828560	13846560	So really what my main concern it has been for quite a few years is to make some theory of how,
13846560	13852560	what makes people able to solve so many kinds of problems.
13852560	13860560	I guess if you ran through the spectrum of all the animals,
13860560	13866560	you'd find lots of problems that some animals can solve and people can't,
13866560	13875560	like how many of you could build a beaver dam or a termite nest.
13875560	13881560	So there are all sorts of things that evolution manages to produce.
13881560	13894560	But maybe the most impressive one is what the human infant can do just by hanging around for 10 or 20 or 30 years
13894560	13899560	and watching what other humans can do.
13899560	13902560	So we can solve all sorts of problems.
13902560	13912560	And my quarrel with the rest of the, most of the artificial intelligence community,
13912560	13923560	has been that the great success of science in the last 500 years really has been in physics
13923560	13935560	and it's been rewarded by finding little sets of rules like Newton's three laws and Maxwell's four laws
13935560	13949560	and Einstein's one law or two that explained a huge range of everyday phenomena.
13949560	13959560	Of course in the 1920s and 30s that apple cart got upset because actually Einstein himself
13959560	13971560	who had discovered the first quantum phenomena, namely the quantization of photons,
13971560	13980560	had produced various scientific laboratory observations that were inexplicable
13980560	13988560	in terms of either Maxwell or Newton or Einstein's earlier formulations.
13988560	13996560	So my picture of the history is that in the 19th century
13996560	14005560	and a little bit earlier going back to Locke and Spinoza and Hume and a few of those philosophers, even Immanuel Kant,
14005560	14009560	they had some pretty good psychological ideas.
14009560	14019560	And as I mentioned the other day, I suspect that Aristotle was more like a modern cognitive psychologist
14019560	14026560	and had even better ideas but we've probably lost a lot of them because there are no tape recorders.
14026560	14038560	Who knows what Aristotle and Plato said that their students didn't write down because it sounded silly.
14038560	14053560	So the idea that we developed around here mostly Seymour Papert and a lot of students,
14053560	14067560	Pat Winston was one of the great stars of that period was the idea that to get anything like human intellectual abilities
14067560	14072560	you're going to have to have all sorts of high level representations.
14072560	14083560	So one has to say the old conditioned reflex of stimulus versus stimulus producing a response isn't good enough.
14083560	14091560	The stimulus has to be represented by some kind of semantic structure somewhere in the brain or mind.
14092560	14107560	And so far as I know it's only in the theories of not even modern artificial intelligence but the AI of the 60s and 70s and 80s
14107560	14118560	that people thought about what could be the internal representation of the kinds of things that we think about.
14119560	14128560	And even more important, if one of those representations you see something or you remember some incident
14128560	14137560	and your brain represents it in some way and if that way doesn't work you take a breath and you sort of stumble around
14137560	14140560	and find another way to represent it.
14140560	14146560	Maybe when the original event first happened you represented it in three or four ways.
14146560	14153560	And so we're beginning to see, did anybody hear Faroochi's talk?
14153560	14161560	The Watson guy was up here a couple of days ago, I missed it,
14161560	14170560	but they haven't made a technical publication as far as I know of how this Watson program works
14170560	14178560	but it sounds like it's something of an interesting society of mind-like structure and it would be nice if they would...
14178560	14182560	Has anybody read any long paper on it?
14182560	14184560	There have been a lot of press reports.
14184560	14186560	Have you seen anything, Pat?
14188560	14194560	So anyway they seem to have done some sorts of common sense reasoning.
14194560	14203560	As I said the other day, I doubt that Watson could understand why you can pull something with a string but you can't push.
14203560	14212560	And actually I don't know if any existing program can understand that yet.
14213560	14220560	I saw some amazing demonstrations yesterday by...
14220560	14230560	Or Monday by Steve Wolfram of his Wolfram Alpha,
14230560	14235560	which doesn't do much common sense reasoning but it has...
14235560	14242560	What it does do is, if you put it in a sentence, it finds five or ten different representations,
14242560	14245560	anything you can find that's sort of mathematical.
14245560	14256560	And so when you ask it a question it gives you ten answers and it's much better than previous systems because it doesn't...
14256560	14262560	Well, Google gives you a quarter million answers but that's too many.
14263560	14273560	Anyway, I'm just going to talk a little bit more and just...
14273560	14280560	Everybody should be trying to think of a question that the rest of the class might answer.
14280560	14286560	So there are lots of different kinds of problems that people can solve going back to the first one,
14286560	14295560	like which moving object out there is my mother and which might be a potential threat.
14295560	14299560	So there are a lot of kinds of problems that we solve.
14299560	14313560	And I've never seen any discussion in psychology books of what are the activities, principal activities of common sense thinking.
14313560	14321560	Somehow they don't have...
14321560	14327560	Before computers there really wasn't any way to think about high-level thinking
14327560	14336560	because there weren't any technically usable ways to describe complicated processes.
14336560	14347560	The idea of a conditional expression was barely on the threshold of psychology.
14347560	14350560	So what kinds of problems do we have?
14350560	14360560	And if you take some particular problem like I find these days I can't get the top off bottles.
14360560	14362560	So how do I solve that?
14363560	14366560	There are lots of answers.
14366560	14383560	One is you look for somebody who looks really strong or you reach into your pocket and you probably have one of these.
14383560	14385560	And so on.
14385560	14394560	There must be some way to put it on the floor and step on it and kick it with the other foot.
14394560	14398560	So there are lots of problems that we're facing every day.
14398560	14404560	And if you look in traditional cognitive psychology you're...
14404560	14406560	Well, what's the worst theory?
14406560	14412560	The worst and the best theory got popular in the 1980s.
14412560	14420560	It was called rule-based systems and you just have a big library which says if you have a soda bottle
14420560	14425560	and you can't get the cap off then do this or that or the other.
14425560	14431560	And so some people decided well that's really all you need.
14431560	14439560	Rod Brooks in the 1980s sort of said we don't need those fancy theories
14439560	14443560	that people like Minsky and Papert and Winston are working on.
14443560	14452560	Why not just say for each situation in the outer world have a rule that says how to deal with that situation?
14452560	14454560	Let's make a hierarchy of them.
14454560	14461560	And he described a system that sort of looked like the priority interrupt system in a computer.
14461560	14470560	And he won all sorts of prizes for this really bad idea that's spread around the world.
14470560	14473560	But it solved a lot of problems.
14473560	14477560	There are things about priority interrupt that aren't obvious.
14477560	14480560	Like suppose you have...
14480560	14486560	In the first computers there was some problem because what should you do
14486560	14490560	if there are several signals coming into the computer and you want to respond to them.
14490560	14497560	And some of the signals are very fast and very short.
14497560	14507560	Then you might think well I should give the highest priority to the signal that's going to be there the shortest time.
14507560	14509560	Something like that.
14509560	14517560	The funny part is that when you made such a system the result was that if you had a computer
14517560	14522560	that was responding to some signal that's coming in at a...
14522560	14527560	I'm talking about the days when computers were only working at a few kilohertz.
14527560	14529560	A few thousand operations a second.
14529560	14531560	God that's slow.
14531560	14536560	A billion times shorter than what you have in your pocket.
14536560	14544560	And if you give priority to the signals that have to be reacted to very fast
14544560	14550560	then what happens if you type to those computers it would never see them because it's always...
14550560	14552560	I saw this happening once.
14552560	14561560	And finally somebody realized that you should give the highest priority to the inputs that come in most...
14561560	14564560	least frequently.
14564560	14571560	Because otherwise if there's something coming in very frequently you'll just always be responding to it.
14571560	14576560	Any of you run into this?
14576560	14581560	It took me a while to figure out why.
14581560	14584560	Anyway there are lots of kinds of problems.
14584560	14596560	And the other day I was complaining that we didn't have enough ways to...
14596560	14604560	We had hundreds of words for emotions and here's a couple of dozen.
14604560	14609560	There are chapters seven and eight actually most of these.
14609560	14616560	So here's a bunch of words for describing ways to think but they're not very technical.
14616560	14622560	So you can talk about remorse and sorrow and blah blah blah.
14622560	14632560	Hundreds and hundreds of words for feelings and it's a lot of effort to find a dozen words for...
14632560	14639560	for intellectual, for what should I call them, problem-solving processes.
14639560	14648560	So it's curious to me that the great field called cognitive psychology has not focused in that direction.
14648560	14658560	Anyway here's about 20 or 30 of them and you'll find them scattered through chapters seven and eight.
14658560	14667560	Here's my favorite one and I don't know of any proper name for it but if you're trying to solve a problem and you're stuck...
14667560	14676560	and the example that comes to my mind is if I'm trying to remember someone's name I can tell when it's hopeless.
14676560	14688560	And the reason is that for somehow or other I know that there's a huge tree of choices.
14688560	14699560	That's one way to represent what's going on and I might know that I'm sure that that letter, that name has a Z in it.
14699560	14703560	So you search around and try everything you can.
14703560	14707560	But of course it doesn't have a Z.
14707560	14732560	So the way to solve that problem is to give up and then a couple of minutes later the name occurs to you and you have no idea how it happened and so forth.
14732560	14752560	So anyway the long story is that Papert and I and lots of really great students in the 60s and 70s spent a lot of time making little models of problem solvers that didn't work.
14752560	14758560	We discovered that you needed something else and we put that in.
14758560	14763560	Other people would come and say that's hopeless.
14763560	14775560	You're putting in more things than you need and my conclusion is that wow it's the opposite of physics and physics you're always trying to find.
14775560	14787560	You don't want to what is it called Occam's razor never have more structure than you need because because what well it'll waste your time.
14787560	14795560	But my feeling was I never have less than you'll need but you don't know how many you'll need.
14795560	14808560	So what I did I had four of these and then I forced myself to put in two more and people ask what's the difference between self models and self conscious processes and I don't care.
14808560	14812560	What's the difference between self conscious and reflective.
14812560	14814560	I don't care.
14814560	14820560	And the reason is that wow it's nice to have a box that isn't full yet.
14820560	14830560	So if you find something that your previous theory going back to Brooks.
14830560	14840560	He was so successful getting simple robots to work that he concluded that the things didn't need any internal representations at all.
14840560	14851560	And for some mysterious reason the artificial intelligence society gave him their annual big prize for for this very wrong idea.
14851560	14861560	And it caused a research to sort of half collapse in places like Japan and said oh rule based systems is all we need.
14861560	14865560	Anybody want to defend him.
14865560	14873560	The odd thing is if you talk to Brooks he's one of the best philosophers you'll ever meet and he says oh yes of course that's wrong.
14873560	14879560	But it helps people do research and get things done.
14879560	14893560	As I think I mentioned the other day when the Three Mile Island thing happened there was no way to get into the reactor.
14893560	14906560	That was 1980 and 30 years later when the what's how do you pronounce it Fukushima accident happened.
14906560	14922560	There was no robot that could go in and open a door and I don't know who to blame for that maybe us.
14922560	14928560	But my picture of the history is that the places that did research on robotics.
14929560	14940560	There are quite a few places and for example Carnegie Mellon was very impressive in getting the Sony dogs to play soccer.
14940560	14951560	And they're still at it and I think I mentioned that Sony still has a stock of what's it called.
14951560	14953560	Say it again.
14953560	14955560	FIBO.
14955560	14957560	Right.
14957560	14959560	I Bose.
14959560	14962560	Right.
14962560	14973560	But the trouble is they're always broken and we had a there was a robot here called Cog that Brooks made and it sometimes worked.
14973560	14980560	But usually it wasn't working and so only one student at a time could experiment with the robot.
14980560	14987560	What was that wonderful project of trying to make a walking machine for four years in.
14987560	14994560	There was a project to make a robot walk and there was only one of it.
14994560	15003560	So first only one student at a time can do research on it and most of the time it's something's broken and you're fixing it.
15003560	15016560	And so you end up that you sort of get five or ten hours a week on your laboratory physical robot at the same time.
15016560	15028560	Ed Fredkin had a student who tried to make a walking robot and it was a stick figure on the screen and I forgot the student's name.
15028560	15041560	But anyway he simulated gravity and a few other things and in a couple of weeks he had a pretty good robot that could walk and go around turns and bank.
15041560	15057560	And if you put if you simulated an oily floor it could slip and fall which we considered the high point of the demo actually.
15057560	15075560	So anyway I've sort of asked you to read my two books for this course.
15075560	15082560	But those are not the only good texts about artificial intelligence.
15082560	15105560	If you want to dig deeper it might be a good idea to go to the web and type in Aaron Sloman S L O M A N and you'll get to his website which is something like that.
15105560	15113560	And Sloman is a sort of philosopher who can program.
15113560	15124560	There are a handful of them in the world and he has lots of interesting ideas that nobody's gotten to carry out.
15124560	15132560	And so I recommend.
15132560	15134560	Who else is.
15134560	15145560	Pat do you ever recommend anyone else.
15145560	15155560	I'm trying to think.
15155560	15158560	I mean if you're looking for a lot for philosophers.
15158560	15171560	Dan Dennett has a lot of ideas but but Sloman is the only person I'd say is a sort of real professional philosopher who tries to program.
15171560	15180560	At least some of his ideas and he has successful students who have made larger systems work.
15180560	15190560	So if you get tired of me and you ought to then go look at this guy and see who he recommends.
15190560	15196560	So OK any who has a good question to ask.
15197560	15209560	It's a mystery but.
15209560	15219560	I spent most of the couple of days making this list bigger.
15219560	15229560	But these aren't you know these are things that you do when you're thinking you make analogies.
15229560	15242560	If you have multiple goals you try to pick the most important one or in some cases if you have several goals maybe you should try to achieve the easiest one.
15242560	15251560	And there's a chance that it'll lead you into what to do about the harder ones but.
15251560	15256560	A lot of people think that mostly in England.
15256560	15260560	That logic is a good way to do reasoning.
15260560	15263560	And that's completely wrong.
15264560	15271560	Because in logic first of all you can't do analogies at all except at a very high level.
15271560	15281560	It takes four or five nested quantifiers to say A is to B is C is to which of the following five or.
15282560	15287560	So I've never seen anyone do analogical thinking.
15287560	15295560	Using formal logic first order or higher order predicate calculus.
15295560	15297560	What's logic good for.
15297560	15300560	It's great after you've solved a problem.
15300560	15305560	Because then you can formalize what you did and see if.
15305560	15308560	Some of the things you did weren't necessary.
15308560	15318560	In other words after you've got the solution to a problem which you got by going through a big search you finally found a path from A to Z.
15318560	15322560	And now you can.
15322560	15331560	See if the assumptions that you had to make to bridge all these various little gaps were all essential or not so.
15331560	15333560	Yes.
15333560	15344560	What example would you say that logic can do analogies like water is for water was like containment or like why.
15344560	15346560	Why.
15346560	15349560	Well.
15349560	15352560	Because you have to make a list of hypotheses.
15352560	15356560	And then let me see if I can find Evans.
15356560	15360560	The trouble is.
15360560	15364560	Don Evans name is in a picture.
15364560	15368560	And word can't look inside its pictures.
15368560	15375560	Can power can PowerPoint find words in its illustrations.
15375560	15378560	Why don't I use PowerPoint.
15378560	15382560	Because I've discovered that PowerPoint can't read.
15382560	15390560	Pictures made by other programs in the Microsoft Word suite.
15390560	15394560	The drawing program in Word is pretty good.
15394560	15401560	And then there's an operation in Word which will make a PowerPoint out of what you drew.
15401560	15405560	And.
15405560	15415560	It's 25 years since Microsoft hasn't fixed the fatal errors that it makes when you do that.
15415560	15422560	In other words I don't think that the PowerPoint and Word people communicate and they both make a lot of money.
15422560	15428560	So that might be that might be the reason.
15428560	15434560	Where was I.
15434560	15438560	Well you can do anything in logic if you try hard enough but.
15438560	15440560	But.
15440560	15443560	A is to be a C is to X.
15443560	15446560	Is a four part relation and.
15446560	15451560	You'd need a whole pile of quantifiers and.
15451560	15454560	How would you know what to do next.
15454560	15456560	Yes.
15456560	15463560	About the situation in which we are able to perform some sort of action like really fluently and really well.
15463560	15466560	But we cannot describe what we're doing.
15466560	15472560	And the example I give is say I'm like an expert African drummer from Africa.
15472560	15474560	And I can make these like really complicated rhythms.
15474560	15479560	But if you ask me what did you just do like I have no idea how to describe it.
15479560	15484560	And in that case do you think the person is capable of like.
15484560	15491560	Or I guess do you think the person we can say that the person understands this even though they cannot explain it.
15491560	15493560	Well.
15493560	15498560	But if you take an extreme form of that.
15498560	15503560	You can't explain why you used us any particular word for anything.
15503560	15506560	There's no reason.
15506560	15511560	It's remarkable how well people can do in everyday life.
15511560	15516560	To tell people how they got an idea but when you look at it.
15516560	15520560	It doesn't say how you would program a machine to do it.
15520560	15523560	So something very peculiar about.
15523560	15528560	The idea that.
15528560	15531560	Goes back to this.
15531560	15534560	This idea that people have free will and so forth.
15534560	15537560	Suppose I say.
15537560	15541560	Look at this and say.
15541560	15544560	This has a constriction at this point.
15544560	15547560	Why did I say constriction.
15547560	15551560	How do you get any how do you decide what word to use for something.
15551560	15556560	You have no idea.
15556560	15559560	So it's a very general question.
15559560	15561560	It's not clear that.
15561560	15564560	The different parts of the.
15564560	15568560	That the frontal lobes which might have something to do with.
15568560	15572560	Making plans and analyzing certain kinds of situations.
15572560	15575560	Have any access to what happens in the.
15575560	15578560	Broca or what's the.
15578560	15583560	What's the speech production area.
15583560	15587560	Broca and.
15587560	15589560	I'm trying to find the name of the other one.
15589560	15591560	It's connected by a cable that's.
15591560	15595560	About a quarter inch thick.
15595560	15597560	Yeah.
15597560	15599560	We have no idea.
15599560	15601560	How those work.
15601560	15604560	As far as I've never seen.
15604560	15606560	Any publication.
15606560	15608560	In neuroscience.
15608560	15612560	That says here's a theory of what happens in Wernicke's area.
15612560	15615560	Have any of you ever seen one.
15615560	15618560	What do those people think about.
15618560	15622560	But they'll tell you about.
15622560	15626560	I was reading something which said it's going to be very hard to understand these areas.
15626560	15631560	Because each neuron is connected to a hundred thousand little fibers.
15631560	15633560	Well, some of them are.
15633560	15638560	And I bet they don't do much except sort of set the bias for.
15638560	15640560	Some large.
15640560	15642560	Collection of other neurons.
15642560	15646560	But.
15646560	15650560	But we if you ask somebody how did you think of such a word.
15650560	15653560	They will tell you some story or anecdote.
15653560	15656560	But they won't be able to describe some sort of procedure.
15656560	15658560	Which is.
15658560	15661560	Say in terms of a language like Lisbon.
15661560	15664560	Say I const this and that and I took the cutter.
15664560	15667560	Of this and the car of that and I.
15667560	15670560	Put them in this register and then I.
15670560	15672560	Swap that with.
15672560	15675560	You don't see theories of how the mind works.
15675560	15678560	In psychology today.
15678560	15681560	The only parts are they know a little bit about.
15681560	15684560	Some aspects of vision because you can track.
15684560	15687560	The paths of images from the retina to the.
15687560	15689560	What to call to the.
15689560	15692560	Primary visual cortex and.
15692560	15697560	People have been able to figure out what's what some of those cortical columns do.
15697560	15699560	And.
15699560	15702560	If you go back to an animal like the frog then.
15702560	15705560	Researchers like bitsy and others.
15705560	15709560	Have figured out how the equivalent of the cerebellum in the frog.
15709560	15713560	They've got almost the whole circuit of how.
15713560	15715560	When the frog sees a fly.
15715560	15721560	It manages to turn its head that way and stick its tongue out and catch it.
15721560	15723560	But in the case of a human.
15723560	15728560	I've never seen any theory of how any person thinks of anything.
15728560	15730560	So.
15730560	15734560	There's artificial intelligence which has high level theories of.
15734560	15738560	Semantic representations and there's new neuroscience.
15738560	15745560	Which has good theories of local some parts of locomotion and some parts of sensory systems.
15745560	15747560	And.
15747560	15750560	To this day there's nothing much in between.
15750560	15752560	So.
15754560	15759560	David here has decided to go from one to the other and.
15759560	15762560	Former student of mine Bob her and.
15762560	15764560	Has done a little bit on both and.
15764560	15768560	I bet there are 20 or 30 people around the country who have.
15768560	15773560	Trying to bridge the gap between symbolic artificial intelligence and.
15773560	15776560	Mapping of the nervous system.
15776560	15778560	But.
15778560	15780560	It's very rare and.
15780560	15786560	I don't know who you could ask to get support to work on a problem like that for five years.
15786560	15788560	Yeah.
15788560	15792560	Presumably to build a human like artificial intelligence.
15792560	15793560	We need to.
15793560	15797560	Like we need to perfectly model our own intelligence which means that.
15797560	15799560	We're the system.
15799560	15802560	We ourselves are the system that we're trying to understand.
15802560	15804560	Well it doesn't have to be exact.
15804560	15806560	I mean people are different.
15806560	15809560	And.
15809560	15813560	Typical person has looks like they have 400.
15813560	15819560	Different brain centers doing slightly different things are very different things.
15819560	15820560	And.
15820560	15826560	We have these examples in many cases if you lose a lot of your brain.
15826560	15831560	You're very badly damaged and in other cases.
15831560	15835560	You recover and become.
15835560	15837560	Just about as smart as you were.
15837560	15842560	Probably a few cases where you got rid of something that was holding you back but.
15842560	15845560	It's hard to prove that.
15845560	15847560	So we don't need to.
15847560	15849560	We don't need a theory of.
15849560	15851560	How people work yet.
15851560	15855560	And the nice thing about AI is that.
15855560	15857560	We could get we could.
15857560	15861560	Eventually get models which are pretty good at solving.
15861560	15865560	What people call everyday common sense problems.
15865560	15866560	And.
15866560	15870560	Probably in many respects they're not the way the human mind works.
15870560	15872560	It doesn't matter.
15872560	15874560	But once you've got.
15874560	15878560	If I had a program which was pretty good at understanding why you can.
15878560	15882560	Pull with a string but not push.
15882560	15885560	Then there's a fair chance you could say well.
15885560	15889560	That seems to resemble what people do I'll do this.
15889560	15892560	A few psychological experiments and see.
15892560	15896560	What's wrong with that theory and how to change it.
15896560	15898560	So at some point.
15898560	15901560	There'll be people making AI systems.
15901560	15904560	Comparing them to two particular people.
15904560	15907560	And trying to make them fit.
15907560	15910560	The trouble is nowadays it takes a few months to.
15910560	15916560	If you get a really good new idea to program it.
15916560	15919560	I think there's something wrong with programming languages.
15919560	15922560	And what we need is a.
15922560	15925560	We need a programming language which.
15925560	15927560	Where the instructions.
15927560	15930560	Describe goals and then sub goals.
15930560	15934560	And then finally you might say well let's represent.
15934560	15937560	This concept by a number or a semantic.
15937560	15939560	Network of some sort.
15939560	15941560	But.
15941560	15942560	Yes.
15943560	15945560	Programming.
15945560	15947560	Is there a goal oriented language.
15947560	15948560	So.
15948560	15950560	There's kind of one if you think about it.
15950560	15952560	If you swim hard enough.
15952560	15954560	Something like SQL.
15954560	15957560	Where you tell him here you know I want to find.
15957560	15959560	You know the top 10.
15959560	15962560	People like my database with this high value.
15962560	15966560	And then you don't worry about how the system goes about doing that.
15966560	15967560	In a sense that's.
15967560	15969560	We're defining the goal when it goes.
15970560	15975560	What's it called.
15975560	15977560	SQL.
15981560	15986560	Oh right yes I guess database query languages are on the track.
15986560	15987560	But.
15987560	15990560	Wolfram alpha seems.
15990560	15992560	To be better than I thought.
15992560	15997560	Well he was running it.
15997560	15999560	And he.
15999560	16003560	Steve Wolfram was giving this demo a meeting we were at.
16003560	16005560	On Monday.
16005560	16008560	And he'd say well maybe I'll just say this and.
16008560	16012560	And it always worked so.
16012560	16013560	So maybe.
16013560	16016560	Either the language is better than I thought or.
16016560	16022560	Wolfram is better than I thought at something.
16022560	16024560	Remarkable guy.
16027560	16028560	Yes.
16028560	16029560	So.
16029560	16031560	I like this example of.
16031560	16033560	You only remember a game after your.
16033560	16037560	You remember a game after you've given up consciously trying to think about it.
16037560	16041560	Do you think this is a matter of us being able to set up background.
16041560	16042560	Processes and then.
16042560	16043560	Either.
16043560	16046560	There's some delay like we give up.
16046560	16049560	There's some delay in the process or we don't have the ability to correct me.
16049560	16050560	Terminate.
16050560	16051560	Processes.
16051560	16054560	Do you think this only works for memory or could work for.
16054560	16055560	Other things.
16056560	16057560	Starting.
16062560	16066560	Well there's a lot of nice questions about.
16066560	16072560	Things like that how many processes can you run at once in your brain and.
16072560	16075560	I was having a sort of argument.
16075560	16080560	The other day about.
16080560	16082560	Music.
16082560	16084560	And.
16085560	16087560	I was wondering if.
16087560	16090560	I see a big difference between Bach and.
16090560	16092560	The.
16092560	16093560	And.
16093560	16096560	The composers who do counterpoint.
16096560	16097560	Counterpoint.
16097560	16102560	You usually have several versions of a very similar idea.
16102560	16104560	Maybe there's one theme.
16104560	16105560	And you.
16105560	16108560	Have it playing and then another voice comes in.
16108560	16112560	And it has that theme upside down or a variation of it.
16112560	16114560	In some cases exactly the same.
16114560	16117560	And then it's called a cannon.
16117560	16118560	And.
16118560	16122560	So the tour de force in classical music.
16122560	16125560	Is when you have two or three or four.
16125560	16128560	Versions of the same thought going on at.
16128560	16131560	Once in different times.
16131560	16133560	And my feeling was that in.
16133560	16137560	Popular music or red.
16137560	16140560	If you take it to a typical band.
16140560	16141560	Then.
16141560	16143560	There might be four people.
16143560	16146560	And they're doing different things at the same time.
16146560	16149560	Usually not the same.
16149560	16150560	Musical tunes.
16150560	16154560	But there's a rhythm and there's.
16154560	16158560	A timpani and there's various instruments doing different things.
16158560	16160560	But there you don't have several doing the same thing.
16160560	16164560	I might might be wrong and.
16164560	16167560	Somebody said well some some popular music.
16167560	16169560	Has a lot of counterpoint.
16169560	16171560	I'm just not familiar with it.
16171560	16173560	But I think that's.
16173560	16176560	If you're trying to solve a hard problem.
16176560	16180560	It's fairly easy to look at the problem in several different ways.
16180560	16186560	But what's hard is to look at in several almost the same ways that are slightly different.
16186560	16188560	Because probably.
16188560	16194560	If you believe that the brain is made of agents or resources or whatever.
16194560	16197560	You probably don't have duplicate copies of.
16197560	16200560	Ones that do important things because.
16200560	16203560	That would take up too much real estate.
16203560	16206560	Anyway I might be completely wrong about.
16206560	16210560	Jazz somebody.
16210560	16212560	Maybe they have.
16212560	16216560	Just as complicated overlapping things.
16216560	16217560	As.
16217560	16219560	Buck and.
16219560	16225560	The Contrapuntal Composers did but.
16225560	16226560	Yeah.
16226560	16229560	What is the ultimate goal of artificial intelligence?
16229560	16233560	Is it some sort of application or is it more philosophical?
16233560	16237560	Oh everyone has different goals or ones.
16237560	16240560	In your opinion.
16240560	16245560	I think we're going to need it because.
16245560	16249560	The disaster that we're working our way toward is that.
16249560	16251560	People are going to live longer.
16251560	16253560	And.
16253560	16255560	They'll become slightly less able.
16255560	16257560	And so you'll have.
16257560	16262560	Billions of 200 year old people who can barely get around.
16262560	16266560	And there won't be enough.
16266560	16269560	People to import from underdeveloped countries.
16269560	16271560	To.
16271560	16273560	Or they won't be able to afford them.
16273560	16277560	So we're going to have to have machines that take care of us.
16277560	16279560	Of course that's just a transient because.
16279560	16282560	At some point then you'll download your brain into.
16282560	16285560	A machine and fix everything that's wrong.
16285560	16288560	So we'll need robots for a few hundred years.
16288560	16290560	Or a few decades and.
16290560	16295560	Then we'll be them and we won't need them anymore.
16295560	16297560	But it's an important problem.
16297560	16301560	What's going to happen in the next hundred years.
16301560	16304560	You're going to have.
16304560	16308560	Twenty billion two hundred year olds and nobody to take care of them.
16308560	16318560	Unless we get a I.
16318560	16324560	Nobody seems particularly sad about that.
16324560	16326560	How long.
16326560	16329560	Oh another anecdote.
16329560	16332560	Because once giving a lecture and.
16332560	16337560	Talking about people living a long time.
16337560	16340560	And nobody in the audience seemed interested in.
16340560	16343560	I'd say well suppose you could live 400 years and.
16343560	16346560	Most of the people I then I asked what.
16346560	16350560	What was the trouble and said wouldn't it be boring.
16350560	16353560	So then I tried it again in a couple of other lectures.
16353560	16355560	And.
16355560	16358560	If you ask a bunch of scientists.
16358560	16361560	How would you like to live 400 years.
16361560	16365560	Everyone says yay.
16365560	16367560	And you ask them why and they say.
16367560	16369560	Well I'm working on a problem that.
16369560	16372560	I might not have time to solve but if I.
16372560	16376560	If I had 400 years I bet I could get somewhere on it.
16376560	16379560	And the other people don't have any goal.
16379560	16383560	That's my cold-blooded view of the.
16383560	16387560	Typical non-scientist.
16387560	16391560	There's nothing for them to do in the long run.
16391560	16394560	Who can think of what should people do.
16394560	16397560	What's your goal.
16397560	16400560	How many of you want to live 400 years.
16400560	16402560	Wow.
16402560	16407560	Must be scientists here.
16407560	16411560	Try it on some crowd and let me know what happens.
16411560	16414560	Are people really afraid yeah.
16414560	16417560	Differentiating factors whether or not you're.
16417560	16420560	400 years it's just going to be the repetition.
16420560	16423560	Of 100 years experience or that will start to like.
16423560	16426560	Take off.
16426560	16428560	Well progress.
16428560	16430560	Right.
16430560	16434560	I've seen 30.
16434560	16437560	Issues of the big bang and I don't look forward to.
16437560	16439560	The next one anymore because they're all this.
16439560	16441560	They're getting to be all the same.
16441560	16444560	Well it's the only thing on TV that has.
16444560	16451560	Scientists.
16451560	16457560	Seriously I hardly read anything except journals and science fiction.
16457560	16459560	Because.
16459560	16461560	Yeah.
16462560	16486560	I can't think of any advantages except that medicine has.
16486560	16488560	Isn't getting.
16488560	16490560	The the age of.
16490560	16492560	Unhandy cap people.
16492560	16495560	Went up at one year every four.
16495560	16498560	Since the late 1940s.
16498560	16500560	So life span is.
16500560	16504560	So that's 60 years so people are living 15 years longer.
16504560	16507560	On the average then.
16507560	16509560	They did when I was born.
16509560	16511560	Or even more than that.
16511560	16514560	But it's leveled off lately.
16514560	16518560	Now I suspect that you only have to fix a dozen genes or.
16518560	16520560	Who knows nobody.
16520560	16522560	Really has a good estimate.
16522560	16525560	But you can probably double the lifespan if you could.
16525560	16528560	Fix.
16528560	16531560	Nobody knows but maybe there's just a dozen processes that.
16531560	16534560	That would fix a lot of things and.
16534560	16537560	Then you could live longer without deteriorating.
16537560	16539560	And lots of people might.
16539560	16541560	Get bored.
16541560	16544560	But.
16544560	16546560	They'll self select.
16546560	16549560	I don't know.
16549560	16552560	What's your answer.
16552560	16555560	I.
16555560	16557560	I hear that.
16557560	16559560	Creating I know that.
16559560	16563560	And more.
16563560	16568560	I mean the goal is not to help take care of people but to compliment.
16568560	16571560	What we already have.
16571560	16576560	You could also look at them as our descendants and.
16576560	16579560	They we will have them replace us.
16579560	16582560	And.
16582560	16587560	Just as a lot of people consider their children to be.
16587560	16590560	The next generation of them.
16590560	16593560	And I know a lot of people who don't.
16593560	16594560	So it's.
16594560	16597560	It's not a universal.
16597560	16603560	But.
16603560	16610560	What's the point of anything I don't want to get in.
16610560	16616560	We might be the only intelligent life in the universe and.
16616560	16619560	In that case it's very important that we.
16619560	16621560	Solve all our problems and make sure.
16621560	16625560	That something intelligent persists.
16625560	16631560	Carl Sagan had some argument of that sort.
16631560	16634560	If you were sure that there were lots of others.
16634560	16635560	Then.
16635560	16645560	Then it wouldn't seem so important.
16645560	16649560	Who's the new Carl Sagan.
16649560	16652560	Is there any who's the who's the note.
16652560	16656560	Is there a public scientist.
16656560	16660560	Who.
16660560	16664560	All the time.
16664560	16668560	Tyson.
16668560	16670560	He's very good.
16670560	16676560	Tyson is the astrophysicist.
16676560	16679560	Brian Green is a great actor.
16679560	16684560	Quite impressive.
16684560	16686560	Yeah.
16686560	16707560	Machine.
16707560	16710560	Well I think that's a funny question because.
16710560	16712560	If we're programming it.
16712560	16716560	We can make sure that the machine has a.
16716560	16718560	Very good.
16718560	16719560	Abstract.
16719560	16722560	But correct model of how it works.
16722560	16724560	Which people don't.
16724560	16726560	So people have a sense of self.
16726560	16729560	But it's only a sense of self and it's.
16729560	16731560	It's just plain wrong in almost every.
16731560	16733560	Every respect.
16733560	16735560	And.
16735560	16739560	So it's a really funny question because.
16739560	16741560	When you make a machine.
16741560	16743560	That really has a.
16743560	16746560	Good useful representation of.
16746560	16748560	What it is and how it works.
16748560	16750560	It might be quite different.
16750560	16753560	Have different attitudes than a person does.
16753560	16757560	Like it might not consider itself very valuable and say.
16757560	16762560	It's a oh I could make something that's even better than me and jump into that.
16762560	16765560	And so it wouldn't have the.
16765560	16768560	It might not have any self protective.
16768560	16771560	Reaction because.
16771560	16775560	If you could improve yourself then you don't want not to.
16775560	16779560	Whereas we're in a state where there's nothing much we can do except.
16779560	16782560	Try to keep living and.
16782560	16785560	We don't have any alternative.
16785560	16786560	If.
16786560	16788560	Stupid.
16788560	16793560	Thing to say.
16793560	16796560	I can't imagine getting tired of living but.
16796560	16802560	Lots of people do.
16802560	16804560	Yeah.
16804560	16807560	Think about creative thinking and the way of thinking and.
16807560	16809560	Where does this.
16809560	16815560	I had a little section about that somewhere that I wrote.
16815560	16823560	Which was the difference between artists and scientists or engineers and.
16823560	16825560	Engineers are in.
16825560	16828560	Have a very nice situation because.
16828560	16830560	They know what they want.
16830560	16834560	Because somebody's ordered them to make a.
16834560	16839560	In the last month three times I've walked away.
16839560	16844560	From my computer and.
16844560	16848560	How many of you have a Mac with the magnetic.
16848560	16851560	Thing.
16851560	16859560	And three times I pulled it with by tripping on this and it fell to the floor and didn't break.
16859560	16863560	And I've had Max for 20 odd years or since 1980.
16863560	16868560	When did they start.
16868560	16872560	30 years and.
16872560	16876560	They used to they have the regular jack power supply in the old days.
16876560	16881560	And I don't remember and usually when you pull the cord it comes out.
16881560	16885560	Here's this cord that Steve Jobs and everybody designed.
16885560	16893560	Very carefully so that when you pull it nothing bad would happen.
16893560	16897560	But it does.
16897560	16900560	How do you account for that.
16900560	16905560	Yeah.
16905560	16908560	Yeah.
16908560	16910560	Well it's quite a wide angle.
16910560	16921560	Yeah.
16921560	16925560	Well what it needs is a little ramp so that it would slide out.
16925560	16931560	I mean it would only take a minute to file it down so that it would slide out.
16931560	16934560	But they didn't.
16934560	16941560	I forget why I mentioned that but.
16941560	16942560	Right.
16942560	16944560	So what's the difference between an artist and engineer.
16944560	16947560	Well when you do a painting.
16947560	16950560	It seems to me if you're already good at painting.
16950560	16955560	The nine tenths of the problem is what should I paint.
16955560	16958560	So you can think of an artist as.
16958560	16964560	10% skill and 90% trying to figure out what the problem is to solve.
16964560	16966560	Whereas for the engineer.
16966560	16971560	Somebody's told him what to do make a better cable connector.
16971560	16976560	And so he's going to spend 90% of his time actually solving the problem.
16976560	16979560	And only 10% of the time.
16979560	16982560	Trying to decide what problem to solve.
16982560	16986560	So I don't see any difference between artists and engineers.
16986560	16989560	Except that.
16989560	16994560	The artist has more problems to solve than it could possibly solve.
16994560	16997560	And usually ends up by picking a really dumb one.
16997560	16998560	Like.
16998560	17001560	Let's have a saint in three angels.
17001560	17005560	Where will I put the third angel.
17005560	17011560	The engineering part.
17011560	17015560	Just just improvising.
17015560	17016560	So.
17016560	17019560	To me the media lab makes sense.
17019560	17023560	The artists and were semi artists and the scientists.
17023560	17026560	Are doing almost the same thing.
17026560	17029560	And if you look at the more arty people.
17029560	17033560	They're a little more concerned with human social relations and.
17034560	17037560	And others are more concerned with.
17037560	17041560	Very technical specific aspects of signal processing or.
17041560	17044560	Semantic representations.
17044560	17045560	So what.
17045560	17046560	But.
17046560	17048560	So I don't see much difference.
17048560	17052560	Between the arts and the sciences.
17052560	17054560	And then.
17054560	17057560	Of course the great moments are when you run into.
17057560	17060560	People like Leonardo and Michelangelo who.
17061560	17065560	Get some idea that requires a great new technical.
17065560	17066560	Innovation that.
17066560	17069560	Nobody it's ever done and.
17069560	17071560	It's hard to separate them.
17071560	17074560	I think there's some place where Leonardo.
17074560	17078560	Realizes that the lens in the eye would mean.
17078560	17080560	That the image is upside down.
17080560	17083560	On the retina and he couldn't stand that.
17083560	17085560	So there's a diagram he has.
17085560	17087560	Where the corny is curved enough.
17087560	17089560	To invert the image.
17089560	17094560	And then the lens inverts it back again.
17094560	17098560	Which is contrary to fact with.
17098560	17102560	He has a sketch showing that he was worried about.
17102560	17103560	If.
17103560	17106560	If the image were upside down on the retina.
17106560	17108560	Wouldn't things look upside down.
17108560	17109560	But.
17114560	17116560	Yeah.
17116560	17118560	I don't know if they have a question.
17118560	17120560	Did you ever heard of.
17120560	17122560	Hiring.
17122560	17123560	High air.
17123560	17125560	Temporal memory.
17125560	17127560	Temporal.
17127560	17129560	Temporal memory.
17129560	17130560	Like.
17130560	17132560	There's a system that I've had.
17132560	17133560	Right.
17133560	17134560	That's right.
17134560	17135560	Great.
17135560	17136560	That's right.
17136560	17137560	How.
17137560	17138560	Great.
17138560	17140560	Requires them.
17140560	17142560	They have a company called.
17142560	17144560	And they're going to release.
17144560	17146560	At the end of this year.
17146560	17147560	On it.
17147560	17149560	And there's like some research.
17149560	17152560	They have paper.
17152560	17155560	Well, I'm not sure what.
17155560	17157560	This is Jeff Hawkins project.
17157560	17158560	I don't know.
17158560	17160560	Yes.
17160560	17164560	I haven't heard about 10 years ago he said Hawkins.
17164560	17165560	Yeah.
17165560	17166560	Hawkins.
17166560	17167560	Yeah.
17167560	17169560	Well he was talking about 10 years ago how.
17169560	17172560	Great it was and I haven't heard a word of any progress.
17172560	17175560	Is there some.
17175560	17178560	Anybody heard it.
17178560	17180560	There's a couple of books about it but.
17180560	17185560	I've never seen any claim of that it works.
17185560	17189560	They wrote a ferocious review of the society of mind.
17189560	17190560	In.
17190560	17192560	Which came out in 1986.
17192560	17195560	And.
17195560	17199560	The Hawkins group existed then and had this.
17199560	17204560	Talk about a hierarchical memory system.
17204560	17207560	But.
17207560	17211560	So if I can tell it's all bluff nothing happened.
17211560	17213560	I've never seen a report.
17213560	17217560	That they have a machine which solved the problem.
17217560	17219560	Let me know if you find one.
17219560	17223560	Because.
17223560	17226560	Oh well.
17226560	17230560	Hawkins got really mad at me for pointing this out.
17230560	17232560	But.
17232560	17234560	I was really mad at him for.
17234560	17235560	Having four of his.
17235560	17239560	Assistants write a bad book review of my book so.
17239560	17246560	I hope we were even.
17246560	17253560	If anybody can find out whether I forget what it's called you remember its name.
17254560	17257560	The game.
17257560	17262560	Well let's find out if it can do anything yet.
17262560	17267560	Hawkins is wealthy enough to support it for a long time so.
17267560	17275560	It should be good by now.
17275560	17279560	Yes.
17279560	17282560	People first start out with some sort of.
17282560	17286560	Classification in their head of the kind of problem it is for.
17286560	17288560	Is that not necessary.
17288560	17290560	Yes.
17290560	17292560	That's.
17292560	17296560	Well.
17296560	17300560	There's this huge book called human problem solving.
17300560	17302560	Which was.
17302560	17304560	I don't know how many of you know.
17304560	17306560	The names of Newell and Simon.
17306560	17310560	Originally was Newell Shaw and Simon.
17310560	17312560	And in the.
17312560	17315560	Believe it or not in the late 1950s.
17315560	17317560	They did some of the first.
17317560	17321560	Really productive AI research.
17321560	17323560	And.
17323560	17325560	Then I think.
17325560	17327560	In 1970.
17327560	17329560	So that's.
17329560	17333560	After 12 years of.
17333560	17336560	Discovering interesting things.
17336560	17338560	Their main discovery was.
17338560	17341560	The gadget that they called GPS.
17341560	17344560	Which is not global positioning satellite but.
17344560	17347560	General problem solver.
17347560	17349560	And.
17349560	17351560	You can look it up in the index.
17351560	17353560	Of my book and there's a sort of.
17353560	17356560	One or two page description.
17356560	17359560	If you ever get some spare time.
17359560	17361560	Search the web for their early.
17361560	17364560	Early paper by Newell and Simon on.
17364560	17367560	How GPS worked because it's really fascinating.
17367560	17371560	What it did is it looked at a problem and found some features of it.
17371560	17375560	And then looked up in a table saying that.
17375560	17379560	If there's this difference between what you have and what you.
17379560	17380560	Want.
17380560	17382560	Use such and such a method.
17382560	17384560	So it was so what I called it.
17384560	17386560	We named it a difference engine.
17386560	17388560	As a sort of joke.
17388560	17390560	Because the first computer.
17390560	17393560	In history was.
17393560	17396560	The one called the difference engine but.
17396560	17398560	It was for.
17398560	17400560	Predicting tides and things.
17400560	17401560	Anyway.
17401560	17403560	They did some beautiful work.
17403560	17405560	And there's this big book.
17405560	17407560	Which I think is about 1970.
17407560	17409560	Called human problem solving.
17409560	17411560	And.
17411560	17413560	What they did is.
17413560	17415560	Got some people to solve problems.
17415560	17419560	And they trained the people to talk while they're solving the problem.
17419560	17426560	So some of them were little cryptograms like.
17426560	17430560	If each letter stands for.
17430560	17434560	For a digit.
17434560	17437560	I've forgotten it.
17437560	17441560	Pat, do you remember the name one of those problems.
17441560	17444560	John plus Joe.
17444560	17448560	John plus Jane equals Robert or something.
17448560	17451560	That I'm sure that has no solution.
17451560	17454560	But those are called crypt arithmetic.
17454560	17458560	And so they had dozens or hundreds of people.
17458560	17462560	Who would be trained to talk aloud while they're solving.
17462560	17464560	Little puzzles like that.
17464560	17465560	And then.
17465560	17467560	What they did was.
17467560	17471560	Get exactly what the people said and how long they took and.
17471560	17474560	In some cases where they moved their eyes.
17474560	17476560	They had an eye tracking machine.
17476560	17478560	And then they wrote programs.
17478560	17484560	That showed how this guy solved a couple of these crypt arithmetic problems.
17484560	17486560	Then they ran the program on a new one.
17486560	17490560	And in some rare cases it actually solved the.
17490560	17493560	The other problem so this is a book.
17493560	17495560	Which.
17495560	17499560	Looks at human behavior and makes a theory of what it's doing.
17499560	17501560	And the output is a rule based system.
17501560	17503560	So it's.
17503560	17505560	It's not a very exciting theory, but.
17505560	17507560	But.
17507560	17510560	There had never been anything like it.
17510560	17511560	Inside.
17511560	17516560	You know, it was like Pavlov discovering conditioned reflexes for rats.
17516560	17517560	Or dogs.
17517560	17519560	And Newland Simon.
17519560	17521560	Discovering some.
17521560	17524560	Rather higher level.
17525560	17527560	Almost a Rodney Brooks like system.
17527560	17532560	For how humans solve some problems that most people find pretty hard.
17532560	17533560	See.
17533560	17535560	Anyway.
17541560	17544560	What there hasn't been as much.
17544560	17547560	I don't know of any follow up they spent years.
17547560	17550560	Perfecting those experiments and.
17550560	17552560	Writing about.
17552560	17554560	Results.
17554560	17556560	And.
17558560	17560560	Anybody know anything like that.
17560560	17564560	What psychology is to try to make.
17564560	17568560	Real models of real people solving.
17568560	17570560	Point problems.
17573560	17575560	My.
17581560	17584560	It has a green light.
17584560	17587560	It has a green light, but the switch was up.
17587560	17589560	Boo.
17589560	17592560	Oh, it doesn't.
17592560	17594560	Yes.
17594560	17596560	Did that study.
17596560	17597560	Try and see when.
17597560	17600560	A person gave up on a particular problem solving method.
17600560	17604560	How they switched another which one is which to based on.
17604560	17607560	It has it has inexplicable.
17607560	17608560	Points at which.
17609560	17612560	The person suddenly gives up on that representation.
17612560	17615560	And he says, oh, well, I guess.
17615560	17618560	I guess are must be three.
17621560	17624560	Did I erase well.
17624560	17626560	Yes, it's got episodes.
17626560	17629560	And they can't account for the.
17629560	17631560	These little jerks in the script.
17631560	17634560	Where the model changes.
17634560	17636560	And.
17636560	17638560	Sorry.
17638560	17641560	And they announced those to be mysteries.
17641560	17643560	And say, here's a place where the.
17643560	17646560	Person has decided the strategy isn't working.
17646560	17651560	And starts over or is changing something.
17651560	17654560	The amazing part is that their model.
17654560	17657560	Sometimes fits what the person says.
17657560	17660560	For 50 or even 100 steps.
17660560	17663560	The guy saying, oh, I think two must be.
17663560	17667560	Z must be two and P must be seven.
17667560	17670560	And that means he plus he is nine.
17670560	17672560	And I wonder what's nine.
17672560	17674560	And.
17674560	17678560	So their model fits for very long.
17678560	17683560	Strings maybe two minutes of the person mumbling.
17683560	17685560	To themselves.
17685560	17687560	And then.
17687560	17688560	It breaks and then.
17688560	17691560	Is another sequence.
17691560	17694560	So new will actually spent.
17694560	17700560	More than a year after doing it verbally.
17700560	17703560	At tracking the person's eye motions.
17703560	17707560	And trying to correlate the person's eye motions with.
17707560	17710560	What the person was talking about.
17710560	17712560	And guess what.
17712560	17715560	None.
17715560	17717560	It was almost as though.
17717560	17719560	You look at something.
17719560	17722560	And then to think about it, you look away.
17722560	17725560	It was a.
17725560	17727560	Newell was quite distressed because.
17727560	17729560	He spent about a year.
17729560	17732560	Crawling over this data trying to.
17732560	17736560	Figure out what kinds of mental events caused the eyes to.
17736560	17738560	Change what they were looking at.
17738560	17742560	But when the problem got hard, you would look at a blank part of the thing more.
17742560	17744560	More often than.
17744560	17746560	The place where the problem.
17746560	17748560	Turned up.
17748560	17751560	So conclusion.
17751560	17754560	That didn't work.
17754560	17757560	When I was a very young.
17757560	17760560	Student in college I had a.
17760560	17763560	Friend named Marcus Singer who.
17763560	17766560	Was trying to figure out how the.
17766560	17770560	Nerve in the four limb of a frog worked.
17770560	17775560	And so he was operating on tadpoles and.
17776560	17778560	He spent about six weeks.
17778560	17781560	Moving this sciatic nerve.
17781560	17784560	From the leg up to the arm.
17784560	17786560	Of this tadpole.
17786560	17793560	And then they all got some fungus and died.
17793560	17797560	So I said what are you going to do and he said well.
17797560	17800560	I guess I'll have to do it again.
17800560	17803560	I switch from biology to mathematics.
17813560	17816560	But in fact he discovered the.
17816560	17818560	Growth hormone that.
17818560	17821560	He thought came from the nerve and made that.
17821560	17824560	If you cut off the limb but of a tadpole.
17824560	17828560	It'll grow another one and grow a whole.
17828560	17831560	It was a nude I'm sorry it's salamander.
17831560	17834560	It'll grow a new hand.
17834560	17836560	If you wait till it's got a.
17836560	17839560	Substantial hand it won't grow a new one.
17839560	17841560	But he discovered the hormone that.
17841560	17843560	Makes it do that.
17843560	17845560	Yeah.
17845560	17847560	Questions from the homework that.
17847560	17850560	Relates to the problem solving.
17850560	17853560	A common theme is having multiple ways to react to the same problem.
17854560	17856560	Which.
17859560	17862560	So we have a whole lot of if thens and we have to.
17862560	17865560	Choose which if.
17865560	17871560	I don't think I have a good theory of that.
17871560	17874560	Yes if you have a huge rule based system and they're.
17874560	17878560	What does Randy Davis do.
17878560	17880560	What if you have a rule based system and.
17881560	17883560	A whole lot of rules fit.
17883560	17886560	Ifs fit the condition.
17886560	17889560	Do you just take the one that's most often worked.
17889560	17891560	Or.
17891560	17895560	If nothing seems to be working do you.
17895560	17902560	You certainly don't want to keep trying the same one.
17902560	17905560	I think I mentioned Doug Lenet's rule.
17905560	17908560	Some people will assign probabilities to things.
17909560	17911560	To behaviors.
17911560	17913560	And then pick.
17913560	17917560	The way to react in proportional to the probability that.
17917560	17919560	That thing has worked in the past.
17919560	17922560	And Doug Lenette.
17922560	17926560	Thought of doing that but instead he just put the things in a list.
17926560	17928560	And whenever a hypothesis.
17928560	17930560	Worked better than another one.
17930560	17932560	He would raise it.
17932560	17935560	Push it toward the front of the list.
17935560	17939560	And then whenever there was a choice it would pick.
17939560	17943560	If all the rules that fit it would pick the one at the top of the list.
17943560	17946560	And if that didn't work it would get demoted.
17946560	17949560	So.
17949560	17952560	That's when I became an anti probability.
17952560	17954560	Person.
17954560	17955560	That is.
17955560	17960560	If just sorting the things on the list worked pretty well.
17960560	17964560	Our probabilities going to do much better.
17964560	17965560	No.
17965560	17968560	Because if you do probability matching.
17968560	17972560	You're worse off then.
17972560	17976560	Then what.
17976560	17979560	Ray Solomon off discovered that.
17979560	17981560	If you have.
17981560	17986560	A set of probabilities that something will work.
17986560	17988560	And you have no memory.
17988560	17991560	So that each time you comments.
17992560	17994560	Try the.
17994560	17997560	I think I mentioned that the other day but.
17997560	17999560	It's worth emphasizing because.
17999560	18005560	Nobody in the world seems to know it.
18005560	18008560	Suppose you have a list of things.
18008560	18009560	He.
18009560	18011560	Equals this.
18011560	18012560	Or that.
18012560	18015560	Or that.
18015560	18018560	And.
18018560	18021560	In other words suppose is a hundred boxes here.
18021560	18023560	And.
18023560	18025560	One of them has a.
18025560	18028560	Gold brick in it.
18028560	18031560	And the others don't.
18031560	18033560	And so for each box.
18033560	18035560	Suppose the probability is.
18035560	18038560	Point nine.
18038560	18041560	That this one has the gold brick.
18041560	18042560	And.
18042560	18045560	This one has point oh one.
18046560	18050560	And this has point oh one.
18050560	18052560	Let's see how many of them.
18052560	18054560	So there's ten of these.
18054560	18062560	That makes.
18062560	18067560	Now what should you do suppose you're allowed to.
18067560	18069560	Keep choosing a box.
18069560	18070560	And.
18070560	18074560	You want to get your gold brick as soon as possible.
18074560	18076560	What's the smart thing to do.
18076560	18077560	Should you.
18077560	18083560	But you have no memory.
18083560	18085560	Maybe the gold brick is decreasing in value.
18085560	18086560	I don't care.
18086560	18087560	But.
18087560	18092560	So should you keep trying point nine.
18092560	18094560	If you have no memory.
18094560	18096560	Of course not.
18096560	18101560	Because if you don't get it the first time you'll never get it.
18101560	18104560	If you tried them at random.
18104560	18105560	Each time.
18105560	18108560	Then you'd have point nine chance of getting it.
18108560	18109560	So in.
18109560	18111560	In two trials.
18111560	18113560	You'd have.
18113560	18114560	What am I saying.
18114560	18115560	In a hundred trials.
18115560	18117560	You're pretty sure to get it.
18117560	18118560	But.
18118560	18123560	In a hundred trials.
18123560	18125560	Almost certain.
18125560	18127560	So if you don't have any memory.
18127560	18131560	Then probability matching is not a good idea.
18131560	18134560	Certainly picking the highest probability.
18134560	18136560	Is not a good idea.
18136560	18137560	Because.
18137560	18141560	If you don't get it the first trial you'll never get it.
18141560	18145560	If you keep using the probabilities.
18145560	18146560	At.
18146560	18148560	What am I saying.
18148560	18151560	Anyway what do you think is the best thing to do.
18151560	18155560	It's to take the square roots of those probabilities.
18155560	18158560	And then divide them by the sum of the square roots.
18158560	18162560	So it adds up to one.
18162560	18164560	So a lot of psychologists.
18164560	18167560	Design experiments until they get the rat.
18167560	18170560	To match the probability.
18170560	18172560	And then they publish it.
18172560	18178560	Sort of like the.
18178560	18182560	But if the animal is optimal and doesn't have much memory.
18182560	18185560	It shouldn't match the probability of the unknown.
18185560	18188560	It should.
18188560	18194560	End of story.
18194560	18197560	Every now and then I search.
18197560	18199560	Every few years.
18199560	18204560	To see if anybody has noticed this thing which.
18204560	18219560	And I've never found it on the web.
18219560	18220560	Yeah.
18220560	18235560	So earlier in the course.
18235560	18238560	I didn't don't mean to say they don't work.
18238560	18240560	Rule based methods are great.
18240560	18243560	For some kinds of problems so.
18243560	18247560	Most.
18247560	18250560	Most systems make money and.
18250560	18251560	You know if.
18251560	18255560	If you're trying to.
18255560	18262560	Make hotel reservations and things.
18262560	18266560	This business of rule based systems.
18266560	18267560	It has a nice history.
18267560	18270560	A couple of AI researchers really.
18270560	18272560	Notably Ed Feigenbaum.
18272560	18274560	Who was a.
18274560	18278560	Student of Newell and Simon.
18278560	18284560	Started a company for making rule based systems.
18284560	18285560	And.
18285560	18288560	Company did pretty well for a while.
18288560	18290560	Until.
18290560	18292560	And they maintained that.
18292560	18295560	Only an expert in artificial intelligence.
18295560	18298560	Could be really good at making rule based systems.
18298560	18300560	And so they had a lot of customers and.
18300560	18304560	Quite a bit of success for a year or two.
18304560	18307560	And then some people at Arthur D little.
18307560	18309560	Said oh we can do that and.
18309560	18312560	They made some systems that worked fine.
18312560	18315560	And.
18315560	18317560	The market disappeared.
18317560	18318560	Because it turned out that.
18318560	18320560	You didn't have to be.
18320560	18322560	Good at anything in particular.
18322560	18327560	To make rule based systems work.
18327560	18328560	But.
18328560	18330560	For doing.
18330560	18336560	Harder problems like translating from one language to another.
18336560	18339560	You really needed to have more structure and.
18339560	18342560	You couldn't just take the probabilities of.
18342560	18344560	Words being in a sentence that you.
18344560	18348560	Had to look for diagrams and trigrams and.
18348560	18355560	Have some grammar theory and so forth so.
18355560	18359560	But generally if you have a.
18359560	18363560	Ordinary data processing problem.
18363560	18367560	Try rule based system first because.
18367560	18371560	If you understand what's going on good chance you'll.
18371560	18380560	Get things to work I'm sure that's what the.
18380560	18382560	Hawkins.
18382560	18390560	Thing started out as.
18390560	18410560	I don't have any questions.
18411560	18416560	Sure.
18416560	18420560	Machines use relatively few electronic components to run a.
18420560	18422560	Different type of thought operations.
18422560	18425560	All that changes is data over which the operation runs.
18425560	18428560	In the critic selector model resources different.
18428560	18430560	Of data with different physical parts to bring.
18430560	18432560	Which model.
18432560	18434560	Critics left.
18434560	18439560	Oh actually.
18440560	18449560	I've never seen a.
18449560	18454560	I've never seen a large scale theory of how the brain.
18454560	18457560	Connects it's.
18457560	18461560	There doesn't seem to be a global model anywhere.
18461560	18463560	Anybody.
18463560	18465560	Read any.
18465560	18470560	Of science books lately.
18470560	18474560	I mean.
18474560	18477560	I just don't know of any.
18477560	18483560	Any big diagrams.
18483560	18490560	Here's this wonderful behavioral diagram so.
18490560	18496560	How many of you have run across the word ethology.
18496560	18498560	Just a few.
18498560	18500560	There's a branch of.
18500560	18503560	The psychology of animals.
18503560	18507560	Which is.
18507560	18509560	Thanks.
18509560	18512560	Which is called ethology.
18512560	18518560	And it's the study of instinctive behavior.
18518560	18520560	So these.
18520560	18525560	And the most famous people in that field.
18525560	18527560	Who.
18527560	18531560	Well Tim Bergen Nico Tim Bergen and Conrad Lorenz.
18531560	18533560	Are the most famous.
18533560	18537560	I've just lost the name of the.
18537560	18540560	Guy around the 1900.
18540560	18542560	Who wrote.
18542560	18545560	A lot about the behavior of ants.
18545560	18547560	Anybody.
18547560	18549560	Ring a bell.
18549560	18552560	So he was the sort of the first ethologist.
18552560	18556560	And these people don't study learning because it's hard to.
18556560	18558560	I don't know why.
18558560	18559560	But.
18559560	18562560	So they're studying instinctive behavior which is.
18562560	18565560	What are the things that all fish do.
18565560	18567560	Of a certain species.
18567560	18569560	And.
18569560	18573560	You get these big diagrams.
18573560	18583560	And.
18583560	18586560	This is from a little book.
18586560	18588560	Which you really should read.
18588560	18591560	Called the study of instinct.
18592560	18605560	And.
18605560	18607560	It's a beautiful book.
18607560	18610560	And if that's not enough.
18610560	18613560	Then there's a two volume.
18613560	18616560	Similar book by Conrad Lorenz.
18616560	18618560	Who.
18618560	18619560	Was.
18619560	18622560	Austrian researcher.
18622560	18624560	They report.
18624560	18626560	They did a lot of stuff together.
18626560	18627560	These two.
18627560	18628560	People.
18628560	18630560	And it's full of.
18630560	18632560	Diagrams showing.
18632560	18634560	The.
18634560	18637560	Main behaviors that they were able to observe.
18637560	18639560	Of various.
18639560	18644560	Low cost animals.
18644560	18645560	I think I.
18645560	18647560	Mentioned that I had some fish and I.
18648560	18650560	Watched the fish tanks.
18650560	18652560	What they were doing for.
18652560	18655560	A very long time.
18655560	18656560	And.
18656560	18658560	Came to no conclusions at all.
18658560	18659560	And.
18659560	18661560	When I finally read.
18661560	18663560	Timbergen and Lorenz.
18663560	18666560	I realized that.
18666560	18668560	Just it never occurred to me.
18668560	18669560	To.
18669560	18675560	To guess what to look for.
18675560	18677560	My favorite one was.
18677560	18681560	That whenever a fire engine went by.
18681560	18684560	Lorenz's sticklebacks the male sticklebacks.
18684560	18687560	Would go crazy and look for a female.
18687560	18690560	Because when the females in heat or whatever it's called.
18690560	18692560	Estrus.
18692560	18697560	The lower abdomen turns red.
18697560	18700560	I think fire engines have turned yellow recently.
18700560	18701560	No one.
18701560	18702560	I don't know what the.
18702560	18709560	Sticklebacks do about that.
18709560	18713560	So if you're just an AI.
18713560	18715560	You really should look at.
18715560	18717560	At least one of these people.
18717560	18720560	Because.
18720560	18722560	It's the first appearance of rule based.
18722560	18726560	Systems in great detail in psychology.
18726560	18737560	There weren't any computers yet.
18737560	18743560	There must be 20 questions left.
18743560	18744560	Yeah.
18745560	18747560	So.
18747560	18748560	I know that.
18748560	18750560	Early on.
18750560	18753560	People were kind of.
18753560	18755560	They're careful not to apply.
18755560	18758560	Ecology of humans.
18758560	18760560	Till about 60s.
18760560	18762560	With.
18762560	18764560	Sociobiology.
18764560	18766560	So if you're thinking on that.
18766560	18768560	Maybe.
18768560	18771560	Around this area.
18771560	18774560	I don't know.
18774560	18777560	I sort of grew up with Ed Wilson because we.
18777560	18780560	Had the same fellowship at Harvard for three years.
18780560	18782560	But he was almost never there.
18782560	18784560	Because he was.
18784560	18786560	Out in the jungle in some little.
18786560	18788560	Telephone booth watching the.
18788560	18790560	Birds or.
18790560	18794560	Bees or.
18794560	18798560	You also had a 26 year old aunt.
18798560	18800560	Not aunt.
18800560	18802560	Aunt.
18806560	18811560	A and T.
18811560	18814560	I'm not sure what the controversy would have been but.
18814560	18817560	Of course.
18817560	18820560	There would be humanists who would say.
18820560	18826560	People aren't animals but.
18826560	18831560	But then what the devil are they.
18831560	18838560	Why aren't they better than they.
18838560	18841560	You've got to read this it's a fairly short book.
18841560	18843560	And you'll never.
18843560	18845560	See an animal is the same again.
18845560	18846560	Because.
18846560	18848560	I swear.
18848560	18850560	You start to notice.
18850560	18853560	All these little things you're probably wrong.
18853560	18854560	But.
18854560	18858560	You start picking up little pieces of behavior and trying to.
18858560	18860560	Figure out.
18860560	18869560	What what part of the instinct system is it and.
18869560	18875560	Lawrence was particularly I think in chapter two of the.
18875560	18878560	A motion machine I have some quotes from.
18878560	18883560	These guys and.
18883560	18885560	Lawrence was particularly interested in.
18885560	18887560	In how.
18887560	18889560	Animals got attached to their.
18889560	18891560	Parents that is.
18891560	18894560	For those animals that do get attached to.
18894560	18896560	Like alligator babies.
18896560	18899560	Live in the alligator's mouth.
18899560	18902560	For quite a while.
18902560	18906560	It's a good safe place.
18906560	18909560	And.
18909560	18912560	Lawrence would.
18913560	18915560	Catch birds.
18915560	18917560	Just when they're hatching.
18917560	18920560	And within the first day or so.
18920560	18924560	Some baby birds get attached to whatever large moving.
18924560	18927560	Object is nearby.
18927560	18930560	And he that was often Conrad Lawrence.
18930560	18932560	Rather than the birds.
18932560	18934560	Mother who's.
18934560	18937560	Supposed to be sitting on the egg when it hatches and.
18937560	18939560	The bird gets attached to the mother most.
18940560	18942560	Most birds do because.
18942560	18945560	They have to stay around and get fed.
18945560	18947560	So.
18947560	18950560	It is said that wherever Lawrence went.
18950560	18953560	In Vienna.
18953560	18956560	There were some ducks or whatever.
18956560	18958560	Birds that had gotten imprinted on him.
18958560	18962560	Would come out of the sky and land on his shoulder and.
18962560	18966560	And on no one else.
18966560	18968560	And he has various theories of.
18968560	18970560	How they recognize him.
18970560	18972560	But.
18972560	18974560	But you could do that too.
18982560	18985560	Anyway that was quite a field.
18985560	18987560	This thing called ethology.
18987560	18989560	And.
18989560	18991560	Between 1920 and 1950.
18991560	18993560	1930 I guess.
18994560	18996560	There were lots of people studying.
18996560	18998560	The behavior of animals and.
18998560	18999560	Ed Wilson is.
18999560	19002560	Probably the.
19002560	19004560	Most.
19004560	19006560	Well known successor to.
19006560	19008560	Lorenz and Timbergen.
19010560	19012560	And I think he just wrote a book is that.
19012560	19014560	Anybody seen it.
19016560	19019560	He has a huge book called socio biology.
19019560	19021560	Which is too heavy to read.
19024560	19026560	I've run out of things.
19029560	19031560	Yes.
19031560	19033560	Thank you.
19033560	19035560	Society of mind.
19035560	19036560	Ideas.
19036560	19038560	That book.
19038560	19040560	Had the machinery from it.
19040560	19042560	What would the initial state of the machine be.
19042560	19043560	You.
19043560	19044560	You.
19044560	19045560	You.
19045560	19046560	You.
19046560	19047560	You.
19047560	19048560	You.
19048560	19049560	You.
19049560	19050560	You.
19050560	19052560	You.
19052560	19053560	You.
19053560	19054560	You.
19054560	19056560	You.
19056560	19057560	You.
19057560	19058560	You.
19058560	19060560	You.
19060560	19062560	You.
19062560	19063560	You.
19063560	19064560	You.
19064560	19065560	You.
19065560	19066560	You.
19066560	19067560	You.
19067560	19068560	You.
19068560	19069560	You.
19069560	19070560	You.
19070560	19071560	You.
19071560	19072560	You.
19072560	19073560	You.
19073560	19074560	You.
19074560	19075560	You.
19075560	19076560	You.
19076560	19077560	You.
19077560	19078560	You you.
19078560	19079560	You.
19079560	19082320	I guess it depends whether you want it to be a person
19082320	19087000	or a marmoset or chicken or something.
19091760	19094880	Are there some animals that don't learn anything?
19094880	19095720	Must be.
19096880	19101640	What are the ones that Sidney Brenner studied?
19101640	19105920	See, I'm gonna say like, very simple associations.
19105920	19107020	The little worms?
19109560	19120560	There was a rumor that if you fed them RNA, was it them or was it some slightly higher animal?
19120560	19123960	It was worms.
19123960	19124960	What?
19124960	19125960	RNA interference.
19125960	19126960	Is that what you're talking about?
19126960	19127960	Yeah.
19127960	19134640	There was one that if you taught a worm to turn left when there was a bright light or
19134640	19144640	right and put some of its RNA into another worm, that worm would copy that reaction even
19144640	19148360	though it hadn't been trained.
19148360	19149360	And this was
19149360	19150360	That's just a worm.
19150360	19151360	Is that what it is?
19151360	19152360	Slugs.
19152360	19153360	Slugs.
19153360	19154360	I think it was, yeah.
19154360	19155360	Yes.
19155360	19156360	It's a lazy-art scarex or something.
19156360	19160000	It's a little snail-like thing.
19160000	19162520	And nobody was ever able to replicate it.
19162520	19172080	So it's that rumor spread around the world quite happily and there was a great science
19172080	19183560	fiction story trying to remember in which somebody got to eat some of an alien's RNA
19183560	19187680	and got magical powers.
19187680	19197800	I think it's Larry Niven who is wonderful at taking little scientific ideas and making
19197800	19201440	a novel out of them.
19201440	19209280	And his wife Marilyn was a undergraduate here.
19209280	19221160	So she introduced me to Larry Niven and I once got to write an article.
19221160	19223880	I once gave a lecture and he wrote it up.
19223880	19231440	It was one of the big thrills because Niven was one of my heroes.
19231440	19237920	Imagine writing a book with a good idea in every paragraph.
19237920	19249560	Bernie Vingy and Larry Niven and Frederick Poe seem to be able to do that or at least
19249560	19250560	on every page.
19250560	19251560	I don't know about every paragraph.
19251560	19252560	Yeah.
19252560	19261560	To follow up on that question, it seems to me that you almost were saying that if this
19261560	19268560	was the difference between these sort of animals and depending on the start of the day, we
19268560	19272200	could either create a chicken or a human.
19272200	19284120	Well no, I don't think that I don't think that most animals have scripts.
19284120	19300600	I might, but I'd say that I don't know where most animals are, but I sort of make these
19300600	19309080	six levels and I'd say that none of the animals have this top self-reflective layer except
19309240	19318880	for all we know, dolphins and chimpanzees and whatever, it would be nice to know more
19318880	19327760	about octopuses because they do so much of wonderful things with their eight legs.
19327760	19331520	What kind of, how does it manage?
19331520	19339040	Have you seen pictures of an octopus picking up a shell and walking to some quiet place
19339040	19347720	that can, there's some movies of this on the web and then it drops the shell and climbs
19347720	19349280	under it and disappears.
19349280	19356280	It's hard to imagine programming a robot to do that.
19356280	19357280	Yeah.
19357280	19367280	So I've noticed both your books in the lecture, a lot of your models and diagrams seem to
19367280	19373280	have a very hierarchical structure to them, but as you mentioned in your book, other places,
19373280	19378280	passing between levels, feedback and self-reference are all very important to diligence.
19378280	19384280	So I'm curious if you could discuss some of the uses of these very hierarchical models,
19384280	19388280	why you represent so many things in that way and some implementation theory?
19388280	19398280	Well, it's probably very hard to debug things that aren't, so we need a sort of meta theory.
19398280	19407280	One thing is that, for example, it looks like that all neurons are almost the same.
19407280	19413280	Now, there's lots of difference in geometric features of them, but they all use the same
19414280	19426280	one or two transmitters and every now and then you run across people saying, oh, neurons
19426280	19428280	are incredibly complicated.
19428280	19431280	They have 100,000 connections.
19431280	19440280	You can find it if you just look up neuron on the web and get these essays, explaining
19440280	19446280	that nobody will ever understand them because typically a neuron is connected to 100,000
19446280	19448280	others and blah, blah, blah.
19448280	19453280	So it must be something inside the neuron that figures out all this stuff.
19453280	19460280	As far as I can see, it looks almost the opposite, namely probably the neuron hasn't changed
19460280	19468280	for half a billion years very much, except in sort of superficial ways in which it grows
19469280	19478280	because if you changed any of the genes controlling its metabolism or the way it propagates impulses,
19478280	19488280	then the animal would die before it was born.
19493280	19497280	That's why the embryology of all mammals is almost identical.
19497280	19514280	You can't make a change at that level after the first generations of cell divisions or
19514280	19518280	everything would be clobbered, the architecture would be all screwed up.
19518280	19525280	So I suspect that the people who say, well, maybe the important memories of a neuron are inside it
19525280	19528280	because there's so many fibers and things.
19528280	19536280	I bet it's sort of like saying the important memory in a computer is in the arsenic and phosphorus atoms
19536280	19539280	of the semiconductor.
19539280	19549280	So I think things have to be hierarchical in evolution because if you're building later stuff on earlier stuff,
19549280	19554280	then it's very hard to make any changes in the earlier stuff.
19554280	19563280	So as far as I know, the neurons in sea anemones are almost identical to the neurons in mammals
19563280	19574280	except for the later stages of growth and the way the fibers ramify.
19575280	19584280	Who knows, but there are many people who want to find the secret of the brain in what's inside the neurons
19584280	19589280	rather than outside.
19589280	19596280	It would be nice to get a textbook on neurology from 50 years in the future,
19596280	19602280	see how much of that stuff mattered.
19602280	19606280	Where are time machines?
19606280	19612280	Most systems have a state that they prefer to be in, like a state that they're most comfortable in.
19612280	19620280	Do you think the mind has such a state or would it tend to certain places?
19620280	19626280	That's interesting. How does that apply to living things?
19626280	19632280	I mean this bottle would rather be here than here, but I'm not sure what you mean.
19632280	19644280	Okay, so apparently in Professor Tannenbaum's class he shows this example of a number game.
19644280	19648280	He'll give you a sequence of numbers and he'll ask you to find a pattern in it.
19648280	19653280	For example, if you had a pattern like 10, 40, 50, and 55,
19653280	19658280	he kind of asks the class to come up with different things that could be describing the sequence.
19658280	19666280	Between the choice of, oh this sequence is a sequence of the multiples of 5
19666280	19672280	versus a sequence of the multiples of 10 or multiples of 11.
19672280	19679280	He says something like the multiples of 5 would have a higher private probability.
19679280	19684280	So that got me thinking, why would that be?
19684280	19690280	Would our minds have a preference for having as few categories as possible
19690280	19692280	and trying to view the world around us?
19692280	19698280	Trying to categorize things and as few things as possible?
19698280	19708280	Sounds very strange to me, but certainly if you're going to generate hypotheses,
19708280	19721280	you have to have the way you do it depends on what does this problem remind you of.
19721280	19730280	So I don't see how you could make a general...
19730280	19736280	If you look at the history of psychology, there are so many efforts to find four laws,
19736280	19739280	three laws of motion like Newton's.
19739280	19746280	Is he trying to do that?
19746280	19760280	And here you're talking about people with language and high level semantics.
19760280	19772280	Let's ask him what he meant.
19772280	19776280	Yeah, it's more of a social question, but there's always this debate about
19776280	19781280	how if AI gets to a point where it can take care of humans, will it ever destroy humanity?
19781280	19785280	And do you think that's something that we should fear?
19785280	19795280	And if so, is there some way we can prevent it?
19795280	19815280	If you judge by what's happened in AI since 1980, it's hard to imagine anything to fear.
19815280	19822280	Funny you should mention that I'm just trying to organize a conference sometime next year
19822280	19825280	about disasters.
19825280	19832280	And there's a nice book about disasters by...
19832280	19834280	What's his name?
19834280	19837280	The Royal... The Astronomer Royal.
19837280	19838280	What?
19838280	19840280	Martin Rees.
19840280	19848280	So he has a nice book which I just ordered from Amazon and it came the next day.
19848280	19860280	And it has about ten disasters like a big meteor coming and hitting the earth.
19860280	19864280	I forget the other ten, but I have it in here somewhere.
19864280	19870280	So I generated another list of ten to go with it.
19870280	19878280	So there are lots of bad things that could happen.
19878280	19891280	But I think right now that's not on the top of the list of disasters.
19891280	19901280	Eventually some hacker ought to be able to stop the net from working because it's not very secure.
19901280	19918280	And while you're at it, you could probably knock out all of the navigation satellites and maybe set off a few nuclear reactors.
19918280	19924280	But I don't think AI is the principal thing to worry about.
19924280	19928280	But it should very suddenly get to be a problem.
19928280	19931280	And there are lots of good science fiction stories.
19931280	19937280	My favorite is the Colossus series by DF Jones.
19937280	19939280	Anybody know?
19939280	19942280	There was a movie called The Forbidden Project.
19942280	19949280	And it's about somebody who builds an AI and it's trained to do some learning.
19949280	19959280	And it's also the early days of the web and it starts talking to another computer in Russia.
19959280	19970280	And suddenly it gets faster and faster and takes over all the computers in the world and gets control of all the missiles.
19970280	19974280	Because they're linked to the network.
19974280	19987280	And it says, I will destroy all the cities in the world unless you clear off some island and start building the following machine.
19987280	19990280	I think it's Sardinia or someplace.
19990280	19996280	So they get bulldozers.
19996280	20001280	And it starts building another machine which it calls Colossus 2.
20001280	20005280	And they ask, what's it going to do?
20005280	20016280	And Colossus says, well, you see, I have detected that there's a really bad AI out in space and it's coming this way.
20016280	20022280	And I have to make myself smarter than it really quick.
20023280	20030280	Anyway, see if you can order the sequel to Colossus.
20030280	20037280	That's the second volume where the invader actually arrives and I forget what happens.
20037280	20048280	And then there's a third one which was an anticlimax because I guess D.F. Jones couldn't think of anything worse that could happen.
20048280	20054280	But Martin Rees can.
20054280	20055280	Yeah.
20055280	20070280	Going back to her question, an example, if my mind has a state, would that example be more of a pattern recognition example?
20070280	20075280	So instead of 10, 40, 50, 55, it wasn't physical.
20075280	20078280	Good, fine, great.
20078280	20086280	And you have to come up with a word that could potentially fit in that pattern.
20086280	20089280	And then that pattern could be ways to answer it.
20089280	20090280	How are we?
20090280	20092280	Let's do an experiment.
20092280	20095280	How many of you have a resting state?
20101280	20116280	Sometimes when I have nothing else to do, I try to think of twinkle, twinkle, little star happening with the second one starting in the second measure.
20116280	20120280	And then the third one starts up the third measure.
20120280	20124280	And when that happens, I start losing the first one.
20124280	20142280	And ever since I was a baby, when I have nothing else to do, which is almost never, I try to think of three versions of the same tune at once and usually fail.
20142280	20146280	What do you do when you have nothing else to do?
20146280	20148280	Any volunteers?
20148280	20149280	What's yours?
20149280	20152280	I don't have to think anything at all.
20152280	20154280	All right, not two or two?
20154280	20156280	Not two.
20156280	20159280	Isn't that a sort of Buddhist thing?
20159280	20161280	Yes, sir.
20161280	20162280	Do you ever succeed?
20162280	20164280	How do you get out of it?
20164280	20169280	You have to think, well, enough of this, nothingness.
20169280	20171280	If you succeeded, wouldn't you be dead?
20171280	20175280	We're stuck.
20175280	20180280	Eventually some stimulus will appear that is too interesting to ignore.
20180280	20188280	Right, and threshold goes down until even the most boring thing is fascinated.
20188280	20193280	Make a good short story.
20193280	20198280	There was actually a movie that really got to me when I was little.
20198280	20204280	These aliens were trying to infiltrate people's brains and like their thoughts.
20204280	20209280	To keep the aliens from infiltrating your thoughts, you had to think of a wall,
20209280	20217280	which didn't make any sense at all, but now whenever I try to think of nothing,
20217280	20226280	I just end up thinking of a wall.
20226280	20237280	These awful psychoses and about every five years,
20237280	20244280	I get an email from someone who says that,
20244280	20248280	please help me, there's some people who are putting these terrible ideas in my head.
20248280	20251280	Have you ever gotten one, Pat?
20251280	20259280	And they're sort of scary because you realize that maybe the person
20259280	20272280	will suddenly figure out that it's you who's doing it.
20272280	20288280	I remember there was once,
20288280	20294280	one of them came to visit, actually showed up and he came to visit Norbert Wiener,
20294280	20300280	who is famous for, I mean he's the cybernetics person of the world.
20300280	20309280	And this person came in and he got between Wiener and the door
20309280	20316280	and started explaining that somebody was putting dirty words in his head
20316280	20321280	and making the grass on their lawn die.
20321280	20329280	And he was sure it was someone in the government and this was getting pretty scary.
20329280	20337280	I was near the door, so I went and got lethin.
20337280	20343280	It's a true story because nearby and I got lethin to come in
20343280	20349280	and lethin actually took this guy down and took him by the arm and went somewhere
20349280	20355280	and I don't know what happened, but Wiener was really scared
20355280	20360280	because the guy kept keeping him from going out.
20360280	20370280	Lethin was big. Wiener is not very big.
20370280	20376280	Anyway, that keeps happening every few years.
20376280	20381280	I get one and I don't answer them.
20381280	20386280	He's probably sending it to several people and I'm sure one of them
20386280	20390280	is much better at it than we are.
20390280	20395280	How many of you have ever had to deal with an obsessed person?
20395280	20398280	How did they find you?
20398280	20405280	I don't know. They found a number of people in the media lab, actually.
20405280	20408280	Don't answer anything.
20408280	20424280	But if they actually come, then it's not clear what to do.
20424280	20429280	Last question.
20429280	20432280	Thanks for coming.
20435280	20439280	Thank you.
