Computer graphics is the driving force of NVIDIA.
It is one of the world's most computationally intensive applications.
It has been for decades, and it will continue to be for decades to come.
Forty years ago, one of NVIDIA's researchers wrote a seminal paper on a technique to simulate
light we call ray tracing.
To trace a light beam through an environment bouncing off surfaces, reflecting, refracting
or illuminating that surface ultimately generate what is a photorealistic image.
Two years ago, at 2018 SIGGRAPH in Vancouver, BC, we announced one of our most ambitious
endeavors.
We call it the NVIDIA RTX.
NVIDIA RTX fuses two groundbreaking technologies.
The first is accelerated ray tracing, and the second breakthrough is deep learning.
Ray tracing is so computationally intensive, even with the amazing accelerator that we've
created, it just simply wasn't fast enough.
And then the breakthrough of artificial intelligence happened.
And over the last three years, we've been piling onto this technology to solve the
last missing piece of the puzzle.
We use ray tracing in our programmable shaders, and the fastest possible GPUs we could make
to generate a relatively low resolution image.
And in this particular case, 540p, not even anti-aliased.
It also generates, along with it, a motion vector.
Where the pixel is and where it's traveling, that goes into an artificial intelligence
network which tries to synthesize a higher resolution image.
We teach this artificial intelligence network what extremely high resolution and high quality
images look like.
In this particular case, we use a supercomputer to render 16K anti-aliased resolution images.
We then compare what comes out of the neural network with this ground truth.
The difference propagates back into the network through a supercomputer, and it corrects the
weights of the neurons as to improve its ability to guess the next time.
We go through this trillions of times.
Eventually, this neural network could take just a few pixels, 540p in this case, and
synthesize what otherwise would be a beautiful image.
Incredible.
Then we take this neural network, we download it into your GeForce computers, particularly
the ones with Turing, are now ready to receive this neural network and process it on the
tensor core processor in the Turing GPU.
We call this technology DLSS, Deep Learning Super Sampling.
What you're looking at here is the image generated by the supercomputer.
Its 16K resolution is completely anti-aliased.
This is a scene from an Unreal Engine demo that Epic did called Infiltrator.
It's really a beautiful demo.
They did this several years ago.
Here, what I'm showing you is 16K ground truth.
The next scene is rendered, and it's 720p.
Notice how blurry it is.
Let me just go back one more time so you can see it.
This is ground truth, 16K, look at the small lights.
We like to look at the leaves on the trees, the clouds from afar, that is so crisp.
The detail is incredible.
This is rendered at 720p, and here what I'm showing you is our first try, and we call
it DLSS 1.0.
Notice it improves the resolution that appears, but only by a little bit.
Most people felt that the artificial intelligence technology was not going to work, but we believed
in it and we didn't give up.
This is, ladies and gentlemen, DLSS 2.0, scaling from 720p, generating the pixels necessary
to create a 1080p anti-aliased image.
Look at that, first generation, a little blurry, second generation.
Look at all the lights.
It's much, much more than sharpening.
Look at all the lights that all of a sudden appear that didn't appear before.
How do you create content where content did not exist?
Well, partly because the neural network has learned what the image should look like, and
secondarily, because we have motion vectors and the pixels by observing across a few scenes,
the neural network can predict what each scene should look like.
Now, if you were to render this with native 1080p, using the GPU to render each and every
pixel anti-aliased, this is what it looks like.
This is native 1080p, and look, artificial intelligence actually does a better job going
back to DLSS 2.0.
Look at that, AI does a better job than 1080p native.
That is a complete breakthrough.
Suppose we started from 540p, and because there are so few pixels, most of the pixels
are blurry when we scale it up to this image.
Now imagine if we were to take this 540p image and put it into a artificial intelligence
network, DLSS 2.0, and this neural network had learned from beautiful images that were
generated by a supercomputer, and it's now asked to recreate that image.
Look at that.
This is the input, 540p, and this is the output, DLSS 2.0, 540p to 1080p.
What an amazing breakthrough.
Let's take a look at the combination of RTX and DLSS on the most popular game in the
world, Minecraft.
Because each one of the worlds are created by the gamer, it is not possible to pre-bake
a lot of the shadows and lighting effects that you see in very big blockbuster games.
This is created by the users themselves, and so the lighting effects can't be cheated,
and it has to be generated by the program, which is the reason why we chose to work with
the team at Minecraft to bring RTX to it.
Now with this particular scene, you can see that when we render Minecraft without DLSS
with just ray tracing, the frame rate was only 35 frames per second.
With DLSS, we can render this beautiful image and then use DLSS to scale that low resolution
image and still maintain the speed.
So now you get beautiful image with ray tracing, high resolution, and high speed all at the
same time, and that is the requirement for modern computer graphics.
Let me show you now a video that we just made of Minecraft.
The reception has been incredible all over the world.
You're going to love this video.
Oh my goodness, this looks insane.
Look at the shiny floor.
I feel like I'm going to slip and fall down.
It hurt myself.
Look at that.
Look at that.
Look at that.
Look at that.
Look at that.
Out.
Boom.
Look at the way the light comes through the wall.
It really adds just this level of depth.
Is that mirrors?
It's mirrors.
Ladies and gentlemen, RTX on, ray tracing, DLSS.
We've made possible real-time ray tracing 10 years earlier than anybody thought was
possible.
When we launched it, people were skeptical, but now it is very, very clear that ray tracing
is here and it's the next big thing.
Creating 3D content is hard.
It takes so many different types of disciplines from artists to designers to software programmers.
Uses all kinds of different tools from MyEd, 3D Studio Max, to Photoshop, and they're creating
these worlds that take enormous databases.
That's one of the reasons why it's so expensive and so hard to create world-class 3D content.
We have a solution for that.
We call it the NVIDIA Omniverse and it leverages all of NVIDIA's technology over the last
10 years.
On the foundation is our RTX server, our latest generation GPUs, then it's built on top of
a virtual application server.
Each one of the GPUs could be shared by many different designers using virtual quadro or
many GPUs could gang up to accelerate one application.
The networking is accelerated and offloaded by Melanox Nix, the smart Nix that we were
talking about earlier.
And then one of the virtual machines is the Omniverse Nucleus.
This nucleus has created a shared space, a shared world, and this shared world has portals.
The output of that portal is visualized and streamed to any device you like.
Multiple designers could work on one design at the same time and reviewers could ask for
changes in real time.
The ultimate design collaboration platform.
Let me show you a demo that's created by NVIDIA engineers.
What I'm about to show you is really amazing.
This was done over the course of the last couple of months.
Artist designers from different locations and it's never been seen before.
It is completely ray traced.
None of the lights are baked, none of the shadows are baked, everything is completely
lit and shadowed in real time.
And one of the most important things is everything obeys the laws of physics.
Let's roll it.
Isn't that amazing?
Real time ray tracing, physically based materials, obeys the laws of physics.
It was created by just a few designers and engineers on top of Omniverse working remotely
from different states.
Incredible achievement.
Just so beautiful.
I love it.
And so ladies and gentlemen, this is the NVIDIA Omniverse.
It starts with a server with a whole bunch of RTX 8000s.
These are the most powerful ray tracing GPUs in the world, tensor core processing to do
AI so that we can both have beautiful images and high resolution and high performance at
the same time.
The servers are available from Box, Dell, HP and Supermicro.
And it's been preconfigured with all the hypervisors necessary, the networking stack
and the virtual quadros so that you can remotely run applications so that you could create
portals into the shared space.
It's really, really an amazing thing.
In today's world where you have to work remotely and share and collaborate with large numbers
of people, this couldn't have come at a better time.
The NVIDIA Omniverse.
