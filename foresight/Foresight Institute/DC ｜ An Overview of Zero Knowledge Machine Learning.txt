Hi, Vern. Welcome to FOSAT's Intelligent Cooperation Group.
We're really excited about this seminar.
We have DC here from Welkheim.
Thank you so much for joining us to give an overview of ZKML,
which is a topic that has come up so much,
especially, I guess, data coming up already a few years ago
in this group, and then much, much more
to have really ramping up in the last year.
And so I'm really excited for you to share a little bit more
about it because we have not had a dedicated seminar
to this topic yet.
So thanks a lot for joining.
We're really excited about you guys' work.
Without further ado, please take it away.
I'll be in the chat monitoring questions,
and we're off to the races.
Awesome. Thank you for having me.
So today, I'll be talking about the zero-knowledge machine
learning.
I'll be giving a very brief introduction.
But first, maybe let me start by saying a little bit about myself.
I'm a research engineer at the World Coin Foundation,
and World Coin is this project that
is trying to build the largest identity and financial network.
And there is an interplay of various technologies
in the products and things that we're building at World Coin,
and some of which are AI, and some of which are cryptography.
So we've had expertise in both realms
from different teams internally.
And there have been some essentially experimentation
that naturally occurred.
We have some AI parts of the stack,
and there are some reasons why cryptography might
be useful in the AI sector of the stack.
And so this prompted us to think about this topic
about two years ago in August.
Almost two years ago, August of 2022.
One of my teammates was just playing around with cryptography
and trying to prove machine learning models.
But so this is a little bit of a background.
I mostly run our grants program, where
we give grants to people to help decentralize World
Coin and solve some more problems,
and also help with a bunch of different R&D efforts
as an individual contribute.
So without further ado, let me start with the presentation.
Usually, the way that I like to start with this presentation
is that I like to decompose the statement into its constituents
so that people have an understanding of which elements
or what is zero-knowledge machine learning?
What is the zero-knowledge part?
What is the machine learning part?
I like to decompose it into its fundamental compositions,
so competition.
And the first one that I want to talk about
is zero-knowledge cryptography, or called zero-knowledge.
I don't know if many of you understand the reference that
or get the reference that I put here, which is Waldo,
finding Waldo.
Waldo essentially is a character or one specific analogy,
which is very simple, very easy, very friendly
to explain what zero-knowledge cryptography is
to people who have never heard about it.
Because there is this essentially like poster
that many people know where there's just lots of characters
which are in the city, and there's one Waldo.
And it takes some amount of time to essentially find the Waldo,
and that's like the challenge of these specific games.
And so there is one specific analogy
which allows people to explain what zero-knowledge is,
which is that if I put a bigger like white paper
on top of the poster, defining Waldo game,
and if I create a little tiny cutout for the head of Waldo,
and I place the cutout just on top of Waldo's head,
but covering the entire game itself, or the poster itself,
then I'm able to prove to anyone that I know where Waldo is
without revealing his location within the poster.
So this is like the good analogy
for explaining what zero-knowledge cryptography is,
because I'm able to prove things that I know
to someone else, to an outside observer,
without them learning everything
about the things I'm making a proof of.
I can selectively prove specific statements
because I have information,
but I don't have to reveal everything
in order to be able to prove that statement.
So this is like a good analogy to explain DK.
So some of the properties that zero-knowledge cryptography has.
So the first one, which I think is the most important one,
especially in the context of blockchain,
I saw that many of you were like in previous presentations
of this specific group.
I saw that there's a few crypto people
that were talking about different things.
I'm sure that came along a few times.
So succinct list essentially just means
that in order to verify a proof of a statement,
it's a lot less computationally expensive
or a lot less expensive
than to actually prove the computation
or to just perform the computation yourself, right?
So essentially verifying that I know where Waldo is,
as an outside observer,
it's a lot easier than me finding Waldo myself.
So this is really important in the context of blockchains
because for example, for scalability solutions,
instead of everyone having to re-execute
the same transactions in a block,
I can just verify a proof
and I can just update my state
without having to secure it myself, for example.
So this property is important for the kid
because it allows us to very easily,
computationally easily verify things
without having to do computation ourselves.
This is a really important property.
The second one, arguably the one that is most known for,
is correctness.
So correctness essentially means
that I can have almost 100% certainty
that this statement that I'm proving is correct, right?
That I cannot lie.
There is no way that I as a prover
can lie to a verifier
unless if the cryptography is sound in this case.
There's two specific properties
that constitute correctness.
One is soundness.
So soundness means that I, if I'm a prover,
someone making this claim, someone making a statement,
I'm not able to fool a verifier with invalid proof
and completeness is another property
where I'm not essentially able to create a valid proof
unless I know the truth.
If I don't know the truth,
I cannot make a valid proof as a prover.
And the third one, which is name after, zero knowledge,
is this property where I can hide parts of the statement.
For example, let's say that I have,
I don't know, this is a good example.
Let's say I have my passport.
So I have my name, my nationality, my date of birth,
where I'm from, which country I was born in,
for example, the place of birth.
So something that would be useful
or like something that would constitute a zero knowledge proof
is that I can make the statement
that my age is over 18 years old
without revealing to anyone my age,
but anyone can just verify that I'm actually over 18.
The way that this is actually implemented
is that within a zero knowledge proof,
I can verify a signature from some issuing body
like the government.
And then I can make a statement that like A,
this age, which was attested to
or essentially committed to by a government is over 18
and you don't learn my age.
So this is the zero knowledge part
where I'm able to hide parts of the state
that I'm making a statement about or proof about
according to some constraint or some statement, right?
Like I can say greater than, less than,
equal to a bunch of other properties
that I think can put.
So the second part of the statement
of zero knowledge machine learning,
this machine learning, right?
I think that one is much more familiar to most of you
since it's been generating such a buzz everywhere,
like machine learning through a generative AI,
like in things like ChagYPT or Dali
or a lot of generative AI models
or natural language processing, categorizing models
like robots, the machine learning essentially,
the way that I think about it is that it's a tool
that allows us to give us not the non-deterministic solutions
or just estimates for short for problems
that don't really have a concrete solution, right?
There's usually there's some problems
which we can solve algorithmically
and we can just have a set of steps
that we can just execute in order to solve it
and we will have a perfect solution every time.
In the case of machine learning, however,
most of the problems that are being solved
by machine learning are not such problems.
Therefore, we need to,
because maybe like the space of solutions is too big
or the space of the steps that we can take is too big,
so it's really hard to navigate deterministically,
then we just have this sort of juristic.
A juristic essentially is a good enough approximation
to the real solution which we can work with
and which has some form of accuracy, right?
So in the context of machine learning,
we have some sort of juristic for some problem.
So let's say I want to categorize
whether an image that I see is the image of a dog or a cat.
This I can train a machine learning model
to essentially solve this task,
but the machine learning model will never be 100% correct.
It will have some accuracy, right?
It will have some that will fail on,
it will have, most of them it will get correct.
But essentially the way that the machine learning model works
is that it trains on some data.
So I feed some data to some model
or to some machine learning algorithm and it gets better.
And this juristic keep getting better and better
for things that it hasn't seen before.
It generalizes over the data
and it's able to make essentially like predictions
or classifications or all sorts of things.
So in the case, for example,
of foundational models for large language models,
they get better at creating like cohesive explanations
or at reasoning or at mathematics
or at all sorts of different things.
And we can have these benchmarks
and with more data, they get better at these benchmarks,
which essentially provide better juristic problems
that we're grading them on.
So another concept that I want to explain here
is that there's two specific parts within machine learning
or two specific things you can do usually,
is that when you have a model, you can train a model.
The act of training a model is the act of creating a function
which gets actually better and better
at giving you the juristics,
the more data you feed into it, right?
So I'm able to update the parameters of this function
by learning, this is what learning is, right?
I'm updating parameters of a function
in order to get a better jurist.
And this process is really expensive, right?
It's really hard, you have to co-locate a data center,
it's running lots of graphics cards in a big place
and consuming lots of electricity for months on end
in order to be able to create something useful
or meaningful, this is really expensive.
But the end product is very easy to run.
So once I've trained this function,
once I have my set of parameters,
evaluating this function at some input,
is usually inexpensive or very inexpensive
compared to actually training it,
several orders of magnitude less.
So these are like the,
how I usually explain machine learning just very briefly.
And so now I want to get,
what is zero knowledge machine learning, right?
We have some intuitions from the ZK side,
some intuitions from the machine learning side.
Now we can discuss what ZK machine learning can be
or is within the modern understanding of it.
So essentially what ZKML is,
is the creation of zero knowledge proofs
of machine learning algorithms, right?
So zero knowledge cryptography allows you
to create proofs of arbitrary computations.
It can be a proof that I've computed some specific thing.
It can be a proof that some variable is bigger than another.
Essentially it's making proofs about computation
and you know the person who's verifying that proof
knows that someone has executed that computation
on some inputs and has produced some output.
So in the context of machine learning,
usually you have some input, a function or a model,
and then some output, right?
So if it's let's say like charge EPT,
I have a prompt which I feed into the model.
The model just takes that prompt and evaluates its model
and it gives you an output,
which is the thing that you then read in the end,
which is the result, right?
So zero knowledge machine learning would be the art
or act of creating a proof that I have fed an input
to a model and I've produced some output.
And I can verify that this output came from a model
without essentially having to evaluate this myself personally.
I just know that this comes from a model
because I have a cryptographic proof that this indeed happened.
So something that many people in the space
actually use as a good analogy that accountable AI, right?
Usually AI or machine learning models,
you don't know that they're actually correct
unless you run them yourself, right?
If you run it yourself on your own local machine
or your own data center which you have privileged access to,
then you know that you've run the right thing.
But let's say that you're using some form of server or API, right?
If I go to chat GPT, like the website,
how do I know that OpenAI is actually serving me
the right model?
They claim, like in the UI, in the front end,
they claim that I am using GPT-4, but how do I know that?
There's no way of me of actually verifying that this is GPT-4.
They might be serving me a worse model,
which is cheaper to run
and just pocketing the difference, for example, right?
I don't know.
So one good thing that ZKML provides
is this form of accountability
where I, as the consumer of some API or some model,
I know that this actually came from something
because I can verify a cryptographic proof
that this indeed happened.
So we can make AIs accountable.
We can make anyone using AI accountable
because we can make proofs of computation.
Many of the framing for ZKML in the modern way
is that they want to essentially bring machine learning on-chain
or onto the blockchain in this case, right?
Like we have the blockchains where we have
very interconnected networks of low-end hardware, mostly.
It's like consumer hardware, which is available everywhere,
to run these decentralized networks.
And the problem with this is that every single computer
on this network needs to re-execute everything
that the network sees in order to validate
that the network is progressing correctly.
And this is a big problem
because now everything is really expensive.
If it's already expensive running it on your own machine,
if you have to run it on 1,000 machines
or 10,000 or 100,000 machines,
it's as many times more expensive.
So it's unfeasible to essentially do machine learning
on-chain right now because it's just too expensive.
And the computational environment
that these usually like blockchains have,
like virtual machines, let's say if they're about the EVM,
Solana has SVM, the Solana virtual machine,
that every single blockchain or most blockchains
do have some form of execution capabilities
or computing capabilities.
And these are very constrained.
So some of the things that blockchains are good at
is cryptography because they're usually subsidized
within the cost of execution in blockchain.
So I can verify a zero-knowledge proof on a blockchain
and I can bring something that I run off-chain
on-chain by providing a proof, right?
So for example, if I'm evaluating a model locally,
I'm able to create a zero-knowledge proof
that I've evaluated a model on some input
and I can just send the output to the chain
and verify a proof.
And then the chain or the smart contract
can know that I've actually run a model on some inputs
and I don't have to run that within the environment,
the computing environment, the blockchain,
so I can save a lot of cost.
And if I make ML more accessible on-chain,
I can actually bring it and I can build application
that leverage machine learning for lots of different things
which I'll get into a little bit later.
And the last one is the zero-knowledge part of things
where I'm able to hide specific parts of the computation
or specific parts of the data that I'm making proofs about
and therefore I can make machine learning private.
In order to make machine learning private,
there's other techniques as well
which is like fully homomorphic encryption
and multi-party computation.
Each of these other types of cryptography
or types of distributed systems engineering and compute it
usually have different trade-offs.
So for example, fully homomorphic encryption
does not give you this correctness assumption
or like probability.
I cannot verify that something happened correctly,
but I can, for example, make computations on Cyphertex.
So if I encrypt some data,
I'm able to perform computations on encrypted data.
And when I decrypt, I have the computation performed
on the original input, on the original plaintext
which is something that is quite fascinating.
However, I do lose this property of ZK
where I cannot verify that something happened correctly.
Multi-party computation is like the better of both worlds
but for example, these protocols require multiple parties
to work in unison
and this is really hard to manage, for example.
So yeah, so I want to talk a bit
about who is actually building
Zeronautic Machine Learning nowadays.
Like which startups, which teams,
what are they're focusing on?
So full disclosure, I am an investor in Giza and Modulus
so I don't want to put that out there, just so you know.
So essentially there's different avenues
on what is there to build on within the ZKML domain
in order to make these systems better
or to make this more interesting
or faster and all sorts of different things.
So the three main companies that usually go around
are Giza, Modulus and Ezekio.
On Giza, for example, they're building
on top of the StarkNet ecosystem
which is like one specific scalability solution
in the Ethereum space
and they're implemented a bunch of machine learning models
within this computational environment
that this blockchain had, which is called Cairo.
The computational environment is called Cairo,
the blockchain is called Tarkin
and they're building products, right?
So they're building, for example,
tooling so that financial products
that are deployed on StarkNet
can leverage machine learning within their,
for example, prediction models for financial services
so they can predict where the highest yield is
to routes my money into
so I can get the highest yield on my collateral
or my assets so I can use machine learning off-chain
or machine learning on-chain
within this computational environment,
I can prove it, et cetera, et cetera.
So essentially Giza is building
a lot of the product side of things,
like different abstraction, different SDKs,
different representations of models, on-chain, et cetera.
Modulus is mostly working on the foundational side of things
and by foundation, I mean the primordial science
of doing cryptography and doing engineering.
So they're essentially building their own,
the thing so-called like approving system
which is how do you implement a zero-knowledge scheme?
Like zero-knowledge, it boiled down to mathematics
and working with polynomials and finite fields
and mostly like linear algebra and abstract algebra
and modular arithmetic and bunch of things of this sort.
So essentially they're trying to build
better cryptographic models and better cryptographic systems
in order for zero-knowledge machine learning
to be more efficient within the actual representation of it
in the computing sense, right?
So this is what they're working on.
I'm happy to then after this presentation
or in the FAQ, I'm happy to share more if anyone wants.
Like there's plenty of resources to learn more
and Ithiko is mostly building, tooling
and also some of the products type of things
and infrastructure, a lot of infrastructure as well.
So Ithiko, for example, is building an abstraction layer
that allows developers that are,
they come from the machine learning world.
So people who usually know Python
or right now in this context is just Python.
So people who know Python and know the standard tools
for building machine learning models,
whether it's TensorFlow or Pycorg
or I could learn or any other library for machine learning,
they even have a standardized representation
of a model which can be exported
to this model representation called ONIX, ONIX,
open your network exchange format.
And this format essentially is something
that represents what the model looks like
in the computational sense.
It's a computational graph of different operations
that you need to perform.
And Ithiko allows you to convert whatever you are building
within Python to something that can be ZK proven,
that you can make a proof of in a very easy way.
So you just import a Python library,
you will create your model
and then you just do model that ZK proved
and you are able to ZK prove that
without you as a Python engineer,
as a machine learning engineer,
you don't need to know how ZK works.
You just create a proof of it
because Ithiko has built a tool that helped convert
the way that you work with ML
to something that cryptography can,
the cryptography tooling can create proofs of.
And of course, academia, academia
has been a crucial element of all of this.
There's lots of cryptography,
new cryptography coming out every week almost.
There's new proving systems,
there's new types of final field arithmetic,
there's new discoveries in different field.
There's different optimizations
like computing optimization from representation,
better models on the machine learning side.
There's also improvements
and since usually ZK ML,
you need both things to become more performant.
If academia comes up with better models
and better quantization schemes and whatnot,
all of these improvements, compounds, right?
It's usually the worst of both,
the thing that becomes the worst for the aggregate.
So the worst of KML, or sorry,
the worst of ZK and the worst of ML
become the worst of ZK ML, like the bottlenecks.
So academia is working a lot of the foundational bottlenecks
when it comes to cryptography
and all these other things that I mentioned.
So some of the use cases,
I do wanna talk about use cases
because I've seen a lot of people
who are really deeply interested in the technology,
but the only way that I've seen technology
actually progress forward is if there's funding
and people actually are interested and excited about it.
For example, in the case of zero knowledge cryptography,
because I mostly spend most of my time
in the blockchain space,
zero knowledge cryptography has become really popular
in the last two to three years,
mostly because there's been products that actually use it,
whether it's scalability solutions,
whether it's privacy solutions,
whether it's digital identity solutions,
there's been product market fit for this technology
and so new companies have been created
and a lot of capital has been poured in
and this capital was reinvested
into the actual development of better cryptography,
better tooling, better hardware,
and also there's a lot of network effects, right?
So if there's lots of people using something,
other vendors like hardware vendors
might want to create hardware for these people,
so it will even speed it up even further.
So I do believe that, for example,
ZKML needs a lot of product market fit
or products or catalysts and use cases,
which would improve the state of the art
just by the fact that there's many people looking at it,
there's a lot of mind share, there's high excitement.
So of course there's negative parts to this as well,
but mostly I think it's good.
So some of the use cases that I've seen around,
so I personally work at WorldQuake
and that's like the way that I got exposed to it.
I'll explain our specific youth case towards the end.
So provable inference is one,
so I mentioned earlier on that I do not know
if I'm using chat GPT,
that someone is actually serving me
the model that they claim they are.
So provable inference is just this concept
where I can know that whomever who used a model
to infer some output, I know where it came from.
I know which model it came from.
If it's public, of course,
the APIs can choose to keep the model private,
but at least they can, for example, commit to it.
Something that I can do if, let's say,
GPT-Force Quilt Force, right?
Open source is not open source.
OpenAI did not open source GPT-Force, as of now.
And so if, for example,
I cannot know that someone used GPT-Force
because I don't have the weights, right?
It's not a public thing.
But something that OpenAI could do or anyone else
with a private model could do
is that they can commit to a specific model,
let's say a hash.
And for example, I know that for the entire user base,
they're using the same model.
So they cannot fool any single user
that they're using specific different models
for anyone else.
At least they can commit to it
with a cryptographic hash, so I can just hash.
I know that there is one deterministic output
for this model.
And I know every single user knows
that they're using the same model
because within the zero-knowledge group,
they have a commitment to some specific set of weights,
but they do not reveal the weight.
They're just committed.
And maybe later, they open source the model,
they can reveal the weights,
and you can see that the commitment
does indeed match the weight.
So you actually learn that you did indeed learn about that.
That they did actually use the model they claimed they were.
In this case, GPT-4,
they managed to open source the weights.
So that's provable inference.
It can be used for APIs.
So I mentioned like chat GPT,
but there's many others, like video games.
If I'm playing an on-chain game
and there's some form of ML,
how do I know that the game is not cheating?
How do I know that I have fair rules on there?
The second one is bringing AI on chain.
So there's lots of smart contracts,
lots of applications that people are building
within the blockchain domain.
And within the blockchain domain right now,
it's very limited in terms of things it can do.
And machine learning can provide lots of cool solutions
to a lot of different problems, right?
At the end of the day, machine learning is able to provide
good enough approximations to problems that people have.
And so if we're able to bring that on chain,
we might be able to bring some interesting
opportunity to the table.
I mentioned the financial ones,
where for example, I have a yield protocol on chain
where I deposit assets to this protocol
and it tries to optimize the yield
that I get on those assets.
But it can, it has to use a strategy.
Usually these strategies are called source and hidden,
but at least I can commit to a strategy.
And this strategy can now leverage machine learning
and I can take proof to the protocol
that we're using a machine learning strategy fairly
and we're not updating the weights.
And we can also, for example,
prove that it was trained on some historical data
with some accuracy, right?
I can make a proof that my model is accurate
on some historical data in terms of yield routing
with some accuracy and it's routed
the most performant way, for example.
There's also another one which is agents or intents
in the context of blockchain.
So agents is a word that comes from the ML lingo,
which is like a program that has the ability
to do actions on their own, right?
They're a player, some system,
like game theoretical system in this case.
So if we have some system, let's say that, I don't know,
like we have a program and we allow
this machine learning algorithm, let's say robotics.
Robotic agents are, is a good analogy, right?
So I have a robot and the robot is able
to interact with the real world
because it has limbs, it has different tools
like cameras, et cetera.
And it's able to interact with the real world.
The robot in this case is an agent, right?
It's a program which is able to perform actions
in the real world.
It doesn't have to be a real world agent.
It can be a digital agent.
It can interact with a website.
It can browse the web.
It can watch a video and give me some information about it.
But essentially on-chain agent could, for example,
interact with a blockchain
if they have maybe some knowledge, right?
So if it's a smart agent, it sees that,
okay, something happened here.
So maybe I see that there's a liquidation happening.
So let me do this, let me buy this, let me sell that.
There's different agents that can learn based on information
and if they have a set of steps that they can do,
they can maybe try and optimize for some goal
and then they become agents in the system.
Blockchain people like to call this intense, yeah?
And another one is attestations, for example.
So I can make attestations about things, right?
I can prove to a smart contract that I'm over 18.
I can prove that all sorts of different things, right?
Essentially, I'm just able to use machine learning off-chain
and I can prove that and bring it on-chain.
Private and machine learning cruise.
So this one is a cool one.
So for example, in the context of medicine,
let's say that there's a cancer diagnosis model
and I as the patient, I do not wanna reveal to anyone
like my personal health records.
But for example, there's a doctor
or some health institution
which signs some form of report
or some form of certificates
to some personal health records or data.
And then there's a machine learning model
which uses this data to essentially evaluate it
and tells you whether you're likely to have cancer
or whether you have cancer and with what's uncertainty.
So something that you can hear
is that if you want to prove to, for example,
let's say that an insurance or a payout
had a condition that you've been insured against
or something like that,
you'd be able to prove to them
that there's some health institution
or a specific health institution if you want
that has concluded that I am indeed this
or have been diagnosed with a specific thing
without revealing the model, without revealing the weight,
but you at least know that there's some specific thing
that you can make a proof about.
The possibilities here are early big
in the sense that there is generally programmable.
So this is like just one concrete example,
but people can essentially make proofs about anything,
any data that they have and computations that they did
when they're machine learning base or not
without revealing the data itself, right?
The only person who learns about the data
in the context of ZK is the person making the proof.
I mentioned earlier that this property called completeness.
So in order to make a valid proof,
I do need to have the data.
So the problem is that there's always a prover,
always learns the data,
but if the prover is controlled by myself,
then only it's the same thing as me learning data.
So it's something that is a worthy trade-off.
So if I'm making a proof on my own computer,
that makes sense.
And I can prove to anyone else anything
without revealing my data.
But if I am, for example, delegating it to a server,
the server doesn't need to learn my information,
so I need to be careful.
And digital identity.
So I do want to explain very briefly,
like how did we come to this at WorldCoding?
So we have this hardware device, it's called an org.
I do have it with me.
Maybe if you guys want, I can just go grab it.
And one second in the FAQs, I can show it.
But essentially the WorldCoding org is a piece of hardware
that verifies two things.
It proves that there's a real person
in front of this hardware device.
It does this bunch of phenomenally detection like methods,
and some other like statistical-based methods,
some sensors that it has like infrared sensors,
and it has like field of depth sensors,
it has high-resolution cameras, et cetera.
And it's able to determine that there's a real person
in front of the hardware device, the org,
with like a shiny ball, I'll show it in a bit.
And it can also prove the person in front of it is unique.
And the way that it does that is that it takes
a high-resolution image of the person's IRC's,
and it's able to compute a unique representation of them
called an IRS code.
And this IRS code, the good thing about it,
is that it's not deemed personally
that if I put information, it's just the representation
of the uniqueness or of the randomness of a person's IRS,
and I can use that to measure how unique they are.
And if the distance between two different IRS codes
is big enough, I can prove that this user is unique.
And then once I prove that the person is unique,
I'm able to essentially put them in a set of verified users.
And then what we do is we have a protocol called WorldID,
which allows you to prove that you're a member
of this set of verified users
without revealing which member you are,
using zoological photography as well,
but not ZKML, just traditional zero-knowledge cryptography.
You're able to prove that I am a unique verified human being
without revealing who you are,
and the data that we collect, which is just this IRS code,
is not personally data-fibre information.
We don't collect the raw biometric images, which is cool,
because you're able to essentially leverage modern cryptography,
modern biometric literature, and the modern tools,
like modern hardware like GPUs and everything.
Everything happens client-side,
like within this actual hardware device, right?
So the hardware device does this computation,
nothing leaves the actual orb,
and then the orb deletes everything within its secure enclave
and computational environment.
Within this model of how work can work,
very simplistic model, there's one specific problem,
which in our biometrics pipeline,
if you change the pipeline in any significant way,
you change the outputs of this uniqueness representation,
you change the output space of the IRS codes,
you can think of them as vectors, right?
So you essentially take this vector space,
and you convert it to a different one.
So the same user will have a different representation
in this new space,
therefore you will not be able to measure uniqueness anymore.
So if you ever update the model,
you have to re-sign up all users.
And since you have this physical hardware device
that people have to go to,
it means that all the users that have signed up to date
to WorldID have to go in person again to this hardware device
and get re-signed up.
And this is terrible,
because it's already been really hard enough
for us to get 5 million plus users
and to have to force our users to re-sign up
every single time that we update the biometrics pipeline,
it would be really bad.
And it has like really terrible user experience.
And so this is where one of my coworkers,
his name is Remco, at the WorldCon Foundation,
he came across with a solution or an idea,
which was what if users self-custody their own biometrics,
meaning that the orb,
which has essentially a secure enclave
and a trusted execution environment.
So essentially these two pieces of chips
or these two chips allow you to sign things.
So I'm able to cryptograph a big sign,
something that the orb sees.
So whenever the user gets verified
that they're a real and unique person,
the orb can sign their raw biometric,
which it has in its memory for a given lifetime,
and it can give it to the user,
and the user can store their own biometrics
in their phone and they can encrypt them, of course,
store them safely in an encrypted fashion
on their own phone or cloud or whatever they prefer.
And they would be able to then have a signature
from the orb on the actual biometric, right?
You know that this image was seen at one point by the orb
and it said that this is a unique human being
and this is a real human being,
most importantly is the real part.
Whenever we want to update the model,
what the user could do is they would be able
to download the new model, the weights of the model,
and they seek the approving library for that specific model
and they would be able to create a group
that created this iris code within a zero-knowledge environment.
So they would be able to create a zero-knowledge proof
that they've created a valid iris code
from an input image, which was attested to by the orb.
So essentially the pipeline of trust here is not broke, right?
I know that I've created an iris code
from an original biometric,
which was verified by the orb to be unique.
And with this, I'm able to permissionlessly
or out of my own accord,
I'm able to permissionlessly insert myself
into the set of verified users
without having to go to the orb again
because I have the entire set of steps that I need
in order to prove to the world ID protocol
that I'm a unique user without revealing who I am again.
I just proved to you that, hey, the orb saw me at one point in time,
the orb did indeed sign this my image, I store my images,
and then I make a proof
that I've created this derived representation of uniqueness
for my biometrics,
and I can prove to them I'm a unique human
in this new representation and this new model
without revealing who I am again, right?
So this is like perfect things,
like a perfect solution for us.
It's actually quite crazy that this problem didn't exist,
at least that's what I felt when I first covered it through Remco.
And so right now, for example,
we're working with one of the companies
which I mentioned earlier,
Modulus to essentially do this client-side
zero-knowledge machine learning proving
inside of a user's phone, right?
So that people can self-cassellate the biometrics
and permissionlessly insert themselves.
It's like very early stages,
R&D is not yet in production,
but there's been a lot of good progress here.
And two years ago, it seemed like sci-fi,
now there's already like concrete proof concepts
and implementation and there's benchmarks
and things that are improving.
But yeah, this is like one of the things that I saw.
One last thing that I do want to mention
before I leave you to ask me questions
and for me to go grab my orb as well
is technical bottlenecks.
Zero-knowledge machine learning, right?
We've seen some use cases,
we've seen what people are working on,
what people are doing, what it is,
some of the things that we are doing,
but where do we go now, right?
If you're someone who is interested in this topic,
where could you contribute if you want to,
if you end up learning more?
How do you contribute to these?
Or what are the problems that are hard
and that would help us improve in the front?
So one is better cryptography, right?
Because it's better ZK.
As I mentioned, the worst in ZK and the worst of ML
create a joint bottleneck.
So if you improve ZK or if you improve ML,
you improve the KML.
But there is also an intersection
where if you just focus on the ZK parts
that would make ML better
and on the ML parts that would make ZK better
or simpler, that's the most focused effort
that you can make to essentially improve everything.
The one is better cryptography.
So remainder, for example,
the thing that I mentioned here,
remainder is a proving library
that is built by modulus labs or modulus,
which essentially uses a type of cryptography
which better models the structured nature
of machine learning computing.
Where like machine learning usually have
matrix multiplication.
They have some non-linearities.
So like functions that are non-linear, in this case,
there's like activation functions
or like a good example of this.
So there's things like ReLU,
which is one of the most popular ones,
defined linear unit, something like that.
Like tanh, there's a bunch of activation functions,
non-linear function.
So they built a cryptographic system
which is able to represent the structured computation
in a much more efficient way.
So when it comes to proving these structured computations,
it takes a lot less computational power to do so
because the representation is much more succinct
and much more efficient.
And so it makes it a lot faster
and a lot more performant
and less computationally intensive.
So this would potentially make it feasible
to run a DK machine learning prover
on a personal phone, for example.
Another one is better hardware.
So hardware and specialized hardware
is one of the things that modern science
has benefited from most.
We've seen the transistor consistently shrinking
and shrinking.
We fit more transistors on a chip,
almost like 2X every 18 months, right?
There's Moore's Law, which goes exponentially.
And now we're at like the two nanometer scale
where we have transistors that are two nanometers wide
and we're able to pack trillions of them on modern GPUs.
And for example, in the context of machine learning,
machine learning was really terrible
on traditional computers like CPUs back in the day,
like in the 60s and 70s and 90s.
So no one actually did machine learning back then.
But when these people were playing video game for some reason,
people started building chips
that represent graphical interfaces a lot better.
And it happens that there's an overlap of the mathematics
that are used to represent graphics and graphics card
and the machine learning, right?
Machine learning is the matrix multiplication
and the way that you represent pictures is matrices, right?
It's just zeros and one that represent the RGB values
of every single pixel on the screen
and transformations between them.
And so you have to do these operations
between pixels really fast.
And it just happened that it's the same thing
as doing machine learning like neural network
fast multiplication across multiple connected layers.
It's like very similar structure.
And so people start using GPUs to speed up machine learning
and machine learning became feasible all of a sudden in 2012
with convolutional neural networks
and all these new like booms that we've been writing
until now with modern LLMs.
Like LLMs and all these new generative AI models
are only possible because of this specialized hardware
that come from NVIDIA, DCMC, AMD, ASML,
like all these like transistor manufacturers,
graphic car manufacturers, specialized hardware manufacturers.
These ones are for machine learning,
GPUs and tensor processing unit,
GPUs, cryptography on the other hand,
they work with a different type of math.
Instead of working with floating points or arithmetic,
they work with finite fields and sixth point arithmetic.
And so you need to design fundamentally different hardware.
And so we need to build better hardware
to improve the computational capabilities
of zero knowledge machine learning
or just zero knowledge cryptography in this then.
So there's lots of things to be done here.
So I'm, for example, I'm also an investor in Fabric,
I'm sorry for that,
but Fabric is one of the ZK hardware company.
In GoNyama, not size thick, it's size thick,
sorry about that, some misspelling without the T.
And irreducible,
there's some of the biggest ZK hardware companies.
And yeah, so these are trying to essentially model
the software in hardware so that it's faster
and there's less overhead.
Another one is better tooling.
So I mentioned Ezekiel and Giza.
They're building tooling that makes it easier
for developers to use ZK.
And if I'm a machine learning engineer,
there's no way in hell I'm gonna spend six years
learning cryptography and learning the state of the art
and trying to contribute there
so that I can prove my machine learning model.
As a machine learning engineer,
I just care about something that ZK can bring to me.
And vice versa, if I'm a ZK guy,
I just care about something that ML can bring to me
to get better or like somehow make it on chain.
So whenever we've brought down the cost of barriers,
like barriers that the cost barriers
that prevent us from doing something,
people start experimenting, right?
Like same thing happened with the web.
Like anyone can build a website nowadays
and you can build a business,
you can just be Shopify.
And if I'm a business guy,
I don't need to know web development.
Shopify and I have my store
and I can process millions of dollars of payment.
I can have a truly user and everything.
And otherwise I would have to learn web development,
servers, everything.
I don't have to care about that.
I just do my business
and I use web technology without having to know how it works.
So the same thing applies to KML of course.
More robust than secure implementation.
That one is a bit like self-explanatory
but essentially like the more security
the less prevent like if we can prevent hacks and exploit
then if it's more robust,
it can sustain more users, et cetera.
And the other one is like what I mentioned before
pretty much at the same point,
like better tooling and easier interfaces
is pretty much the same thing
because the easier it is to use,
the more experimentation there for the more products,
the more product market fits,
the more businesses can build
and the more technology can accelerate
towards the direction of growth.
So yeah, that's everything about my presentation
and I would love to answer any of your questions.
I don't know how long we have.
I think it's 14 minutes for FAQ.
I can also go run, get the orb if you guys wanna see it.
And thank you for having me.
This was fantastic.
Thank you so much.
What a world.
And we have a few questions already here
from people in the chat
and then maybe after a few we give you some time to breathe
and get the orb, that would be great.
Okay, so first one, Shadi,
if you wanna unmute your first.
Hi, yeah, thanks for the great presentation.
Very informative.
I had a question about the personally identifying information
from the hash from the iris biometrics.
Isn't a hash or iris still uniquely identifying
if you know the hashing function to produce that digest?
Or did you mean that make the function is kept secret
and nobody can easily take like a photograph of someone
and then produce the same hash and that look on chain,
for example, I don't think you posted on chain
but look on chain, for example, to try to match that.
Yeah, there's one unfortunate naming collision here.
So in biometric literature,
people use a hash in a non-urgorous way.
And so what we mean here,
or what we used to mean,
we've changed the way that we explain these things.
We no longer use the terminology of hash
because we work in the intersection of AI and cryptography
and if you use a term that means a different thing in both,
it's like ambiguous and it can cause problems
like this one right now.
Actually, the way the biometrics pipeline works
is that there's this essentially convolution-like algorithm.
It's called the GABER wavelet or GABER filter,
which essentially applies convolutions
into original biometrics many times over
and it's able to compute like a randomness representation.
And this one essentially compresses the image so much,
like after performing all these operations,
you end up with a pretty much a small representation
of a few bits, like I think it's 200,
something that, so the vector in the end,
like the embedding in the end is like a few bit.
And this one is not able to be reconstructed
to its original, at least like a lossy function, right?
If I go from a compressed representation
to a fully, try to expand it back,
I lose information in the process
of converting it to this compressed representation.
Therefore, I'm not able to reconstruct the same one.
And the good part of this is that I'm able to,
I'm able to reconstruct something similar,
but it's not personalized identifiable,
at least not considered so in modern literature, right?
This may change and this is why we've been working
on a lot of other things within world economy,
like more of the party computation solutions and whatnot.
We're gonna be publishing a lot about this
in the coming month, but if you're interested
in like follow this, the biometrics pipeline works
and have the definition of it and how it works
and what is actually going on,
I recommend going to the link I just said in the chat,
my paper that work in the org.
Also, one of my teammates is in the,
actually one of the former teammates,
he's at Tool for Humanity,
which is the labs entity.
I'm at the foundation of different legal entities,
but they're both contributing to the world team project.
His name is Daniel Gershiewicz.
He is in the cause law.
So he's also able to explain a bit more.
He's on the org software team.
So he works a lot more with the biometrics pipeline than I do.
I'm more still in the cryptography
protocol side of thing.
But yeah, within the white paper,
white paper.worldcoin.org,
you have a biometric action
and you have the third definition
of what it is that we're doing
and how we preserve privacy.
So to answer your question in a specific way,
it's not a hash, it's not a cryptographic hash.
There's no digest, there's no plaintext.
It's essentially a convolutional like operation
which happens many times
and it leaves the input unrecognizable
and you compress certain information
of the randomness that you get.
You cannot use that to reconstruct the original thing
that you put into this function
because it's a very lofty function.
And this is good enough to prevent
like getting the raw biometric out again.
Got it.
So the idea is even if I had access
to the kernels that you used to train,
then I wouldn't be able to deconvolute the output.
I see.
Ideally to try and break our own assumptions
and try to reverse engineer
and actually get the original image.
And now we've gone ahead a step further
because if it was possible,
we've gone a step further
and we're now storing everything in ciphertext
and the uniqueness check,
it's happening on ciphertext with multi-party computation.
So yeah, that's like cool, cool new research stuff.
Love it.
Dan also shared, I think the white paper
that you referenced directly here in the chat
already a little further up.
Thanks for that, Dan.
Next one up we have Richard and then we have Micah.
Yeah, I think the previous discussion
answered my question there.
Thank you.
Awesome.
Wonderful.
Micah, you go.
Micah, we can't hear you.
Feel free if you can't unmute to put your chat,
your question in the chat.
Okay, he's going to rejoin.
This could be a great opportunity for you to get the orb.
I also have a few questions, but God, you go.
Can you hear me?
Yes, Dan, we can hear you.
I want to go back, there was this question about
and things being personally identifiable
or uniquely identifying information.
And then the question turned into ashes
versus wavelet encodings.
I don't know.
I think the question actually got lots of discussions.
And the interesting thing is that even if you've had
either a hash or an encoding,
and you somehow broke this and could reverse that image,
actually the privacy comes from
what was briefly mentioned in the talk,
which is that when you prove your ownership of such,
you're proving ownership of a key
that was linked to this biometric encoding.
So when you prove ownership of that key,
you're not pointing to which encoding is yours.
So you're a member of the set
without revealing which member.
And that means that these encodings
are cryptographically delinked from anything else,
your transactions, your accounts.
Nothing can be linked back.
So if you did reverse those codes, you wouldn't know.
Also, one additional thing is that
these encodings are not public.
They're hidden in a database that we have.
The thing that is public is the public key
associated with the user that has undergone a unique question.
So if I have this unique coding,
and I prove that I'm a unique within the coding set,
which is kept not on any public sphere,
it's now kept in this multi-party computation
encrypted environment in a database
that is run by three different parties
in an MPC setting, again, multi-party.
And when the user is verified to be unique,
we take the user's public key,
which was generated by the World app,
which is the way that you interface with World ID
and the wallet and a bunch of other things that we're building.
Essentially, the public key that was generated
by the World app, by the user,
which is a unique person that's been just verified
by the World, gets inserted into the set of verified users,
and then I'm able to make a knowledge proof
that I own a private key to a public key
and the set of verified users.
So even then, there's one more step
that removed from your biometric completely,
because a public key is just random,
cryptographical, gibberish that I can make proofs about,
and I'm able to prove to you that I'm a unique member
of the set because I own a private key
to a public key in the set, but I don't know which one.
And there's another cool part,
which is the nullifier scheme that we have,
which allows you to represent unique actions.
For example, one is like unique governance,
like one person, one vote, digital governance,
or voting protocol.
Currently, there's no way to prove
that you're not a bot online.
So if you, for example, let's say, I don't know,
Elon Musk puts a poll on Twitter or on X
that, hey, is this doc cute or no?
I can create a bajillion X accounts and vote for no, right?
There's no way for me to prove
that this is a one person, one vote.
So whomever who posts a poll on whatever thing
doesn't matter, like the opinion doesn't matter,
the result of the poll doesn't matter.
There's million bots that have incentives
and both, like presidential elections,
if Elon says, is this candidate a good guy?
People can vote yes, but it can be like a third,
like external nation state actor trying to just
civil attack, which means like attack a protocol
where you need unique members in a way
that just make the protocol broken
completely beyond repair.
So this is where we step in,
where we create a unit of account of uniqueness
for humans in a digital environment,
whether it's on chain or it's off chain doesn't matter.
As long as you're able to make these cryptographic
at the station that I am a unique person
and I've not done an action before,
so I'm able to prove that I'm a unique actor.
I'm a unique member of this protocol
and I only voted once.
So I can say that this dog was cute only once.
And if I want to weigh the outcome,
the only way to weigh the outcome is that I need
to convince a thousand other members
to vote for the same thing,
but I'm not able to just create a million accounts
and vote for a same thing to weigh the outcome.
Yeah.
Awesome.
Yeah, I think Bramco talked a little bit about that,
especially like with possible future applications
also that you also listed very briefly,
including in medicine and so forth
that I think these groups are just like really incredible for
because it can't for medicine, for financial risk,
for insurance and stuff,
you just can't really access the data any other way.
Or you just can't do too much anyways with the information.
Okay, we have another question,
but you also have the orb now or?
It's right here, my lap.
Wonderful.
By the call, the battery,
at least.
All right, sorry.
I'm gonna unbler my background.
I do have a, I just moved into a new apartment,
so forgive me for,
but yeah, the battery right here.
Yeah, that is able to say a lot more about the orb than I can.
If you work on the orb software team,
you've been working on this for three years plus.
Yeah.
Yeah, I've come in multiple close contacts with the orb already
and I think in 50 years you even have it like taken apart,
you know, and it's different components,
which is really fun to see.
So yeah, thanks.
The orb hardware specs are publicly available
on GitHub as well.
So people can see the PCB design,
they can see like what components it's made out of.
There's also an hour paper,
there's like an annotated set of every single component
and like what it does, how it works, et cetera.
Yeah, I've been following like
just how many people are signing up
and like the very, very long lines.
Sign up stations, which has been really interesting.
Okay, Micah, you rejoined and you raised your hand.
Do you want to ask you a final question?
Testing, can you hear me?
Yep.
Quick comment and then a question after that.
The, I believe that while the transactions,
your transactions made using your unique ID
can't be linked back to you.
You can be linked back to your transaction.
Someone has an orb or the algorithm in the orb
and they can get a picture of you, so to speak.
They can then regenerate your unique ID
and this is an unnecessary piece.
You can't get rid of it because in order to have
a unique human, you need to be able to verify.
There needs to be only one outcome.
You can't introduce randomness here, right?
And so if your goal is to not have someone be able
to tell which transactions you did,
that is not possible here.
But someone can't tell just by looking at the transactions
that they were yours.
It's a one-way thing.
This one held you down and put an orb in front of your eye,
they can then figure out all your transactions,
but they couldn't look at your transaction
and figure out which eye they belong to, so to speak.
Yes and no, there's one step that helps us mitigate this,
which is the separation of the public key, right?
Like your transactions are not being done
by your iris code or whatever.
The transactions are being done by a public key
which was owned by a user,
which just happened to verify at the orb, right?
You would have to get the user's private key
to learn what they did on the game.
And then you would also have to get their bandwidth forked
to try and interlink too, right?
You'd have to get their bandwidth forked,
you'd generate the iris code,
and then get somehow steal from them their private key.
And then with a private key,
you're able to de-anonymize the on-chain state
that they performed in a DK way
because you're not able to just get the live iris.
You know you can generate them.
And so there's two things that you need to compromise there.
I'll just, my actual question,
I'll try to keep it,
I know I've got one minute left.
Last I checked, DK proof of an execution takes
on the order of a thousand times or so,
executing the same thing without a DK proof.
Even though inference is significantly cheaper
than training, execution costs is still very non-trivial.
That's why you need giant GPUs and whatnot,
just to do inference.
The use cases you're thinking of,
are they all things that are like become useful
once we can get the DK proofing costs down by a hundred times?
Or do you think there's some things that are usable
even with that thousand increase in execution costs?
Right now there's already like DK use cases on-chain, right?
And there's equally expensive in the ML lens,
like already proved a hundred million like parameter models
in an inexpensive way, right?
In a usable way, right?
Let's say you have a small convolutional neural network
classifier with 200 million like weights,
like flowing point,
or in this case for a ZKML with field elements,
but you're able to make proofs in reasonable time,
one to two minutes for inference, right?
Where the evaluation of it in the normal world
is a thousand nights less,
two millisecond, 20 millisecond, like point two second,
or 200 million, my bad.
So yeah, like this is like the costly incur,
but it makes sense for some things.
And right now, as I mentioned,
like the things that we're doing could prove the thing,
like cryptography, better implementation,
better hardware, specialized hardware, et cetera,
they're gonna bring down this cost significantly,
it's gonna make more things feasible.
Like now we can maybe prove an LLM,
it may take 10 minutes,
but maybe proving that LLM once
for something that's really important enables a new thing.
And it's always happened like this,
that like the use case and the demand for it
and bring the proving time down,
the overhead down, the performance up,
and we're still like have a bunch of things to do.
So it should work out eventually.
Love it.
Any final words?
How can people find out more?
I know that you said, for example,
there's an announcement coming on soon,
but if people are really excited about this
or they just wanna learn more,
what are any possible action items that people can take?
So action items.
So if you have a specific question about this presentation,
you wanna ask me, I think my Twitter or my Telegram,
or like my ex and my Telegram are the best.
So my handle is DC build 3R.
So DC builder, but with the 3 instead of an E at the end.
So that is for asking me questions.
If you were interested in ZKML itself,
I do have a resource aggregator for ZKML things.
It's on my, or one of my GitHub's,
which is github.com slash ZKML dash community slash
awesome dash ZKML.
I'm able to leave the link in the chat real quick,
but I think like the spelling makes sense.
Besides that, there's a bunch of startups working in ZKML,
mostly like what I mentioned, like Modulus, Giza, and Ezekio.
And these three keep coming out with new developments,
new things, new announcements, et cetera.
There's cryptographic papers coming out on ZKML,
which I also try and keep up to date on my resource.
So yeah, those are like the best ones, I think.
Love it.
And I just saw from Dan that he's bringing
up to our upcoming May workshop though.
If you're going to that one, you may be able to try it.
Hey, thank you so much.
This was really fantastic.
Thanks for staying on three minutes longer.
I really appreciated it.
Thanks for all of your great questions, everyone,
and I hope to see you guys soon.
Bye-bye.
