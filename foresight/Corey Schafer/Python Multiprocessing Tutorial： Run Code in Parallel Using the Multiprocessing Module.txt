Hey there, how's it going everybody? In this video, we're going to be learning how to run
code in parallel using the multi-processing module. Now, if you'd also like to learn about
running code concurrently using the threading module, then I did recently put out a video on
that as well, so I'll be sure to leave a link to that video in the description section below. Now,
if you don't know the difference between threading and multi-processing, then you should have a grasp
on the difference between those once we're finished. Now, I would like to mention that we
do have a sponsor for this video, and that is Brilliant.org. So, I really want to thank Brilliant
for sponsoring the video, and it would be great if you all could go and check them out using the
link in the description section below and support the sponsors, and I'll talk more about their
services in just a bit. So, with that said, let's go ahead and get started. Okay, so first, why would
we want to use multi-processing? So, basically, we want to use multi-processing whenever it's going
to significantly speed up our program. Now, the speed up comes from different tasks running in
parallel. Now, in this video, we're going to start off with a basic example of where we learn how to
run some simple sleep methods in parallel, but then we'll finish up with a real-world example
where we do some image processing on a directory of high-resolution images. I want to show that
real-world example because, personally, when I watch tutorials that only show how it works on
basic examples, then I always feel like I don't really walk away with any useful knowledge. So,
we'll use the sleep method to get a good idea of how to use multi-processing, and then we'll
be sure to go over the more complicated real-world example of image processing. So, let's go ahead
and get started. So, I have a starting script open here, and if you'd like to follow along, then
I'll be sure to have a link to this code in the description section below. And, like I said, we'll
start with a very simple example to see how this works and then build up with more realistic examples.
So, let me go over the script that I currently have open here. So, first, I'm importing time,
and I'm just using time to measure how long it takes the script to run. That's also what this
is here. This is just a start time for our script, and then we have a function here called
doSomething, and all this is doing is printing that we are sleeping for one second, then we actually
sleep a second using that time module, and then we are printing out that we are done sleeping,
and then we are actually executing that function. So, it should do all of this,
and then we are calculating the finish time and printing out that our script is finished.
Okay, so, if I run the code that we have right now, we can see that it said that it was sleeping
for one second, done sleeping, and that we finished in about one second. And that sounds
about right since we were running our doSomething function one time, and that sleeps for one second.
And if we were to run that function twice, then our program will likely take two seconds. So,
let's go ahead and see that. So, right below doSomething here, I'm going to run this again,
and if I run that, then we can see that now that it printed out that it was sleeping for one second
twice, and that it took about two seconds. So, we can see that each time we run this doSomething
function, it's adding about one second to our script. So, our script is just waiting around
sleeping for a second, and once that's done, it moves on to run that next function,
and sits around waiting for another second. And then at that point, we're basically done,
and our script finishes. Now, I created a quick graphic to try to represent what this looks like.
So, let me bring that up here in my browser real quick. And this is actually the second
graphic. We'll go over that in just a second. Okay. So, this is basically what it looks like
for our script to be executed right now. So, we are running a function. In this case, it's that
doSomething function. And then this is just coming up here and waiting and executing for one second.
And once that one second is over, then we come back and we execute this another function,
and it's that same function again. So, then it comes up here and executes this sleep for one
second again. And when that one second is done, then we can come down here and print that our
script is done. And running everything in order like this is called running it synchronously.
Now, if you have some tasks that don't need to be run synchronously, then we can use the
multi-processing module to split these tasks up onto other CPUs and run them at the same time.
Now, if you watched my last video on threading, then I mentioned that tasks were going to either
be IO bound or CPU bound. So, CPU bound tasks are things that are crunching a lot of numbers and
using the CPU. And IO bound tasks are things that are waiting for input and output operations
to be completed. And they're not really using the CPU all that much. So, some other examples of
IO bound tasks include file system operations and network operations like downloading stuff online.
Now, in that threading video, I mentioned that we wouldn't get much of a speed up when using
threading on CPU bound tasks because those threads are still only running one process. But with
multi-processing, we're going to actually spread the work out onto multiple processors on our machine
and run those tasks at the same time. So, we can use this with both IO bound tasks and CPU bound
tasks. So, it really just depends on what we're doing and your computer's hardware that will
determine if it's better to use threading or multi-processing. But with that said,
let's look at what it looks like to run something in parallel using multi-processing.
And I've got another graphic put together of what this would look like. So, in this example,
we can see that we still have our two tasks. But now we're just breaking these up onto two
different processes. And unlike with threading, where we were running these concurrently, and I
said that running concurrently doesn't necessarily mean that they're running at the same time,
with multi-processes, these actually are running at the same time on different processes. So,
we can see here that once we kick off our multiple processes and we spread out our tasks onto those
processes, then we can just run each of these functions one time. And then both of these will
sleep for a second. And then once they're both done, we'll come down here and print that they're
done. Okay, so now that we've talked about multi-processing and what it looks like to run code
in parallel, now let's see how to actually do this with our current script. So, first,
let's import the multi-processing module. So, this is in the standard library, so we don't need to
install anything. So, up here at the top, I'm just going to say import multi-processing. Now,
I'm going to show an older way of how to do multi-processing first so that we can get a good
idea of what's going on. But if it seems confusing at first, then definitely stick around, because
I'm also going to show some newer ways of doing multi-processing using pools that allow us to
add this to our program with just a few lines of code. Okay, so first, instead of running the
do something function twice in a row like we have here, let's instead turn both of these into
processes. So, to do this, I'm just going to create two processes. And for both of these,
we can just say p1 is equal to multi-processing.process. And now, we are going to pass in a
target. And the target is the function that we want to run. So, if I want to run this do something
function, then I can pass in do something. Now, we want to pass in the actual function and not
the return value of the function. So, we don't want to execute the function with parentheses
like this. We just want to pass it in with no parentheses. Okay, so now that will be one process.
And now, if I do a p2 is equal to multi-processing.process with a target of do something, then
that will be our second process. Okay, so at this point, we've created two process objects,
but we're not actually running that code. So, if I run this right now, then we can see that it says
that it finished immediately, but nothing from our function printed out. So, our functions didn't
actually run. So, in order to get our processes to run, we need to use the start method on each one.
So, down here below our p2, I'm going to say p1.start to start that first process,
and p2.start to start that second process. Okay, so now that will actually run our processes,
but it might not do exactly what we think it'll do. So, if we run this, then we can see that now
it runs the functions, but it said that our script was finished in zero seconds, and then it said
that we were sleeping for one second twice because we ran that function twice, and then it said that
it was done sleeping. Now, our entire script didn't actually complete in zero seconds. It actually
took around one second, but the reason that it says that it completed in zero seconds is because
after it started both of these processes here, while those processes were sleeping, our script
continued running and came down here and calculated out the finish time and printed out that our
script was finished in zero seconds, and then it kicked off these processes. Now, actually, I think
that I just said that it started sleeping first before it printed out that we were finished,
but these processes take a little bit longer to spin up than threads, so it actually didn't even
start our processes first. It actually came down here and printed that we were finished before
these sleep statements even first got executed. So, it printed that before it said we were sleeping,
and then after a second we were done. So, basically what this is doing is it's kicking off our processes,
but then it's going down here and running the rest of our script before our process is finished.
Now, what if we wanted our processes to finish before we calculated the finish time and before
we printed out that our script is finished? So, in order to do this, we can use the join method.
So, to do this right below start, I'm going to say p1.join and p2.join. So, when we run that join
method, it means that the process will finish before moving on in the script. So, now, if we
run this, then we can see that both processes started at almost the same time, and then they
both printed that they were done sleeping after one second, and then our script continued on to
print that our script had finished in about one second. Now, if using multi-processing seems a
bit complicated right now, then definitely stick around until the end of the video, because we're
going to see an easier way of how to do what we're doing here, but I think it's important to understand
what this is doing so far, even if we use other methods where we don't actually manually call
these start methods and join methods. Okay, so, right now, we're not really getting that big of a
speedup. Now, so, our code ran in two seconds before, and now it's running in one second,
but that's because our function doesn't take too long, and we're only running it twice,
but what if we wanted to run our function 10 times? Well, if we were to run our code synchronously,
then we can take a guess that it would take 10 seconds since one would have to finish before
the other, and we'd be running 10 in a row. But if we ran this with multiple processes,
then it should be significantly faster. So, let's see an example of this. Now, instead of manually
creating 10 different processes, let's instead create and start these in a loop. So, to do this,
I can come up here, and I'm going to copy this whole part here, and now I'm just going to
overwrite all the code that we have here so far, and I'm going to say 4 underscore in range of 10,
and we'll say p is equal to multi-processing dot process with a target set to the do something
function. And now, let's also start that process here within our loop. Now, if you're unfamiliar with
the underscore in Python, basically, that's just a throwaway variable name. It's just saying that
we're not actually using the integer from this range in the loop. So, we just have something as
a throwaway variable there. So, we're starting all these processes here within our loop, but we can't
do a p dot join within the loop, because it would run join on the process before looping through
and creating and starting the next process in the loop. So, it would basically be the same
as running it synchronously. So, we need a way that we can start all of these processes in one loop,
and then loop through those processes again, and run the join method on them
so that they all finish before the end of our script. So, to do this, let's just append each
process to a list. So, above our for loop here, I'm just going to create a list called processes
and set that to an empty list. And then below p dot start, I'm going to say processes dot append,
and I will append each process to our processes list. And now, here below our for loop, I'm going
to say for process in processes, let's do a process dot join. Okay, so just one more time here. We are
looping over a range of 10. So, we're going to do this loop 10 times here. And each time through
the loop, we are creating a new process with this target of do something. And we are starting that
process. And then we are appending that process to a processes list. So, then after that loop is
complete, and all of our processes have been started, we're coming through and looping over all
those processes, and we are joining them. And again, when we join a process, when we run the join
method, it means that it is going to wait until that finishes before continuing on to the rest
of the script. So, it'll finish before it comes down here and calculates the finish time and
prints that our script is finished. So, we're running this do something function 10 times,
and it sleeps for one second every time. But since we're using multiple processes, it'll just run
all of these in parallel at the same time. So, instead of it taking 10 seconds, let's save this
and run this and see how long it actually takes. So, we can see that even running the function 10
times, we're still finishing this in about one second. Now, that might seem a little strange,
because I don't actually have 10 cores on this machine. But your computer has ways of switching
off between cores when one of them isn't too busy. So, even though we had more processes than we do
cores, it's still finished in about a second. So, that's pretty good. Okay, so now let's look at
how we can pass in arguments into our function. So, right now, we're running a function that
doesn't accept any arguments. But let's add a couple of arguments real quick. So, right now,
we're just sleeping for one second. So, let's add an argument that specifies how long to sleep.
So, up here, we will accept an argument. And I'm just going to pass in an argument of seconds.
And let's also change that we are going to sleep for that number of seconds. And let me also put
a parentheses s there as well. Now, this needs to be an f string, since we're now using this
variable here within our string. Now, I want to sleep for that number of seconds. Okay, so with
that small change, our do something function now accepts an argument of seconds. And then it'll
print out that we're sleeping for that number of seconds. And then it will actually sleep for that
number of seconds. So, let's pass in seconds as an argument to this function. And we need to pass
that in as a list of arguments to our process. So, I'll say, down here, where we are saying that
our target is that do something function, we can also pass in an argument of arcs. And we'll pass
that in as a list of arguments. So, I'll do 1.5. So, now, instead of sleeping for one second
for 10 different times, now it's going to sleep for 1.5 seconds for 10 different times. Now,
unlike with threads, in order to pass arguments to a multi processing process, the arguments must
be able to be serialized using pickle. Now, if you don't know what that means, basically serializing
something with pickle means that we're converting Python objects into a format that can be deconstructed
and reconstructed in another Python script. So, now we should expect our function to take
1.5 seconds instead. So, if I save this and run it, then we can see that now our script is finishing
in about 1.5 seconds. Okay, so, I said before that I was going to show you the older way of doing
multi processing, and then I'd show you what I believe is a faster, easier way of doing this.
And I still wanted to show you the manual way of creating these processes, because I think this can
still be useful depending on what you're doing. And also, I think it's better to learn this manual
first to understand a bit better what's going on in the background. But in Python 3.2, they added
something called a process pull executor. And in a lot of cases, this will be an easier and more
efficient way to run multiple processes. And it also allows us to easily switch over to using
multiple threads instead of processes as well, depending on the problem that we're trying to
solve. So, let's replace what we currently have and instead use this process pull executor.
Now, this actually isn't in the multi processing module. It's in the concurrent futures module
instead. So, up here at the top, let's instead import concurrent futures. And I actually don't
think I need multi processing anymore. So, I'm just going to say import concurrent futures.
Now, I'm going to leave everything else that I have here for now, so that we can see the
difference between these. Now, when we use this process pull executor, it's usually best to use
this with a context manager. So, above our processes list here, I'm going to do the same thing that
we already have. But just with our concurrent futures module instead. So, I'm going to say with
concurrent dot futures dot process pull executor, and make sure you get those capitalizations in
the right place. And then, we will say, whoops, we'll say as executor. And now, within our or
with our executor here, there are a couple of different methods that we can use. Now, if we
want to execute the function once at a time, then we can use the submit method. So, the submit method
schedules a function to be executed and returns a future object. So, let's add this in and then
I'll explain this a bit more. So, I'm going to say f one is equal to executor dot submit. And I will
submit that do something function. And let's also pass in an argument of one. So, again, the submit
method schedules a function to be executed and returns a future object. So, a future object
basically encapsulates the execution of our function and allows us to check on it after it's
been scheduled. So, we can check that it's running or if it's done, and also check the result. So,
if we grab the result, then it'll give us the return value of the function. Now, right now,
we're just printing out values. But let me add in a return value so that we can grab that. So,
instead of just printing that we are done sleeping up here, instead, I'm going to return that string.
So, I'm going to say return done sleeping instead of just printing that out. Okay, so now that's
returning that string. So, if we still want to print that out, then we'll need to print that return
value. So, let's grab that by using the result method on that future object. So, I'm going to say
print and we will print out F1 dot result. Now, if we run the return method, then this will wait
until the function completes. Okay, so let's comment out what we had before and run our code. So,
I'm going to comment out this processes list here and our previous starts and joins. And instead,
we're just going to use this process pull executor. Okay, so if I run this, then we can see that
that still works. And that's a lot less code than we had down here that's commented out. But we're
still not running this multiple times yet like we were down here. So, if we wanted to run this
multiple times, then we could just run submit multiple times. So, I could say let me go above
our result here. I'm going to add in another execution of this do something function. So,
I'm going to call this F2 is equal to executor dot submit do something with one second. And then,
I will also print out the F2 result. So, if I run this, then we can see that it's the same thing.
It kicks both of these off at the same time. And we finished in about one second. And if we wanted
to run this 10 times like we did below, then we likely wouldn't want to run submit 10 different
times. So, we could use a loop like we did before. So, instead of running one at a time,
I'm going to use a loop. And we could use a regular loop like we did below. But I'm going
to go ahead and use a list comprehension to create these instead. So, we could say, I'm just going
to copy this executor dot submit part. And I'm just going to overwrite all of this other stuff
right now. And I'm going to say results are equal to, then I will start a list comprehension here
and say executor dot submit do something for one second for underscore range 10. Now, if you're
not familiar with list comprehensions like we have here, then I do have a separate video on that
as well. So, I'll put a link to that in the description section below if you've never seen
this type of code before. And if you're not comfortable using list comprehensions, then
you can always use a regular loop like we did down here below. Okay, so now we've created a list
comprehension that's running our submit method with this do something function, and an argument of
one second, 10 different times. Now, in order to get these results, we can actually use another
function from the concurrent futures module called as completed. And this will give us an
iterator that we can loop over that will yield the results of our processes as they're completed.
So, I think this is really useful. And it's one of the good things about using these processing
pull executors. So to use this, we can say just for f in concurrent, oops, sorry about my typing
there, concurrent dot futures dot as underscore completed. And now we want to pass in this list
of results, which is a list of futures objects. And now within this list, let's print out f dot
result. So if we run this, oops, and it looks like I have some invalid syntax here. Oh,
I forgot to say, I should have said for underscore in range of 10. Some of you probably saw that
as I was typing it out. Okay, so now if I run this, then we can see that we slept for one second.
Now it's still ran 10 different times. But if we scroll down to the bottom, then we can see
how much time it took. So we can see here that it actually took three seconds this time. Now,
the reason behind that is that our poll may have made a decision based on our hardware,
not to a lot as many processes. So that's why it might take longer. But even though it took longer
in our simple little example here, I still you like to use these processing pull executors most
of the time, because I trust it to a lot the processes a lot more than I trust myself. So
I passed that off to the process pull executor to do and to make that decision for me. Now to
prove that these results are actually coming in as they're completed, let me actually pass in a
different range of seconds for our processes to sleep. And those should print out in the order
that they complete. So I'm going to create a list of seconds to sleep. And I'll make that sleep
from five seconds all the way down to one second. So above our results here, I'm going to make a list
of seconds. And I will just make a list of five, four, three, two, one. And I'll also print out
the seconds in the return statement of our do something function, so that we can tell which
ones are finishing and in what order. So again, I'm going to make this an f string by putting an f
right there. And I'm just going to pass that in to so we can see which seconds is actually done
sleeping. So now, let me also change our list comprehension here, so that we are running our
do something function with each of these seconds in this seconds list. So I'm going to say executor
dot submit, do something. And I want to do that for whatever second. So four sec in our seconds
list. Okay, so now if I run this, then we can see that it actually started our five second
process first, and then our four, then our three, then our two, then our one. But it finished these
in the order that they came in. And the lower number seconds are towards the top. Now I'm not
sure why the one second process took so much longer than the two and the three second processes. I
guess it just got hung up on something. But the four and the five second processes were down here
at the bottom. Actually, let me run that one more time. And Oh, okay, so that's why it's because
our one second process was down here. And since I have four cores on my machine,
it started these four processes here first. And it didn't start the one second process until
this two was finished right here. So that's why that took a little bit longer. But since we are
using this as completed method, this actually did print our result out our results in the order
that they completed. So this two second one finished first, and then this three, then one,
then four, then five. And we can see here down at the bottom that our script is still finishing
in about five seconds. So that's pretty good. Okay, so with this submit method right now,
it's submitting each function once at a time. But in order to run submit on an entire list,
then we need to do a loop or a comprehension like we did here. But if you're familiar with the built
in map method, then there is actually something similar that we can do with processes, where we
can use the map method to run our function over a list of values. So if you're familiar with the
built in map method, then this is very similar, except it uses processes instead. So it runs the
function every time or with every item of the interval that we pass in. So let's say that I
want to map our function to our list of seconds. So to do this, I am just going to overwrite our
list comprehension here. And I'm not going to be using this as completed anymore either. So I'm
also going to get rid of that. So now in order to do this, we can simply say executor dot map.
And now we will map our do something function. And we will map our list of seconds. So again,
what this map method does, if you're not familiar with the built in Python map method and what it
does, basically map will run this do something function with every item of this list with every
item of whatever iterable you pass in. So that is what map does. Now, when we were using the submit
method, it returned future objects. But when we use map, it just returns the results. Now, it is
going to run those processes in parallel. But instead of returning the results as they're completed,
like we saw before, map is going to return the results in the in the order that they were started.
So to loop over these results, we can simply just do a for loop. So I'm going to say for
result in results. And then I will just print out our result, whoop, make sure that I'm printing
out the result and not that results list. Okay, so now if I run this, then we can see that all of
our processes kicked off at pretty much the same time, except for that one second when it looked
like it got outside of the pool like it did before. But they actually didn't all complete at the same
time. But when you loop over your results using map like we did here, then it returns the results
in the order that they were started. So since we slept for five seconds first, then we waited for
that one to finish before printing out the other results. But it still didn't slow us down, we can
see that our entire script still finished in five seconds here. But it looks like our five
seconds was done sleeping first, and then our four, then three, then two, then one, it actually didn't
finish in that order. But it printed out in that order, because again, it prints out the ones that
in the order that they were started and not in the order that they were finished. Now another
thing to point out here is that if our function raises an exception, it won't actually raise that
exception while running the process. The exception will be raised when its value is retrieved from
the results iterator. So if you need to handle any exceptions, then you can do that here within the
iterator if you'd like. And if you'd like to learn more about handling exceptions, then I do have a
more in depth video. If you'd like to learn more about that. So I'll be sure to leave a link to
that video in the description section below for anyone who's interested. Now even if we don't
grab our results within the context manager, it's still going to automatically join all of those
processes and let them finish after the context manager ends. So if I comment out where we are
printing out our results, let me also get rid of our old way of doing this here so that we can
see our code below our processes here. So now I'm commenting out where we're printing those results.
And if I run this, then we can see that it still didn't move on to our finish time here
until it returned the results from our processes. So anytime you're using a context manager like
this, it's going to automatically join those processes. And they're going to complete before
that context manager finishes. Okay, so now that we've looked at a basic example of using sleep,
now let's take a look at a more real world example of where using multiple processes
would be useful. So I've got another script open here where I'm not using multiple processes at
the moment. So let me open this up and let's go over what this is doing. And again, I'll have a
link to this code in the description section below for anyone who wants to follow along. So in our
last video on threading, I showed how we could use threads to go out and download some high resolution
photos from unsplash. Now if you don't know what unsplash is, it's a website that has some really
nice photos available for anyone to use. Now downloading images is something that is IO bound
since we're waiting for the images to download. So for this multi processing example, we want
something that is more CPU bound. So in this script, I'm doing some image processing on the
images that we downloaded in the threading video. And I'll have these images available in the
description section below as well, in case anyone didn't follow along with that threading video.
So let me go over the script to show you how someone might do this image processing normally.
So I'm using the pillow library here, which if you don't know what the pillow library is, it's a
image library for Python that makes it makes image processing easy. I also have a video on pillow if
you'd like to learn more about image processing. But I have a list here of image names. And these
are all of the images or all of the image names that we downloaded in the last video using threading.
So I am starting a counter here so that we can measure how long our script took.
I am setting a size of 1200 pixels. And that is what we are going to resize these high resolution
photos to. Okay, and now what I am doing is I am looping over all of those image names.
So with one image at a time, I am opening that image. And then I am running running this image
filter. And we're just doing a Gaussian blur on that image. And then I am doing an image thumbnail
and setting it to this 1200 pixel size. And then we are saving that image into a processed folder
with that the image name. And then we are printing out that that image was processed.
Now I do have a processed folder here within my directory. If you don't, you'll probably get an
error. And I also have all of these photos here within my directory. If you don't have those,
then you're also going to get an error. So you want to have all of those photos in order for
this code to work. Then after that's done, I am printing out the time that it took. And then
I am printing out that our script is finished. Okay, so this is processing 15 high resolution photos.
So if I run this now, then let's see how long this takes. So I'm running this, we can see that
it is just going through synchronously and running these one at a time. And then we will print out
the final time once this is done. Now, I think that my processing here, I think that this still
might be more IO bound than CPU bound. Because opening the image and saving this here is going
to be more of an IO bound thing. I don't know how much is actually getting CPU bound here using
this filter. But if we were doing some more computations, then this would be more CPU bound.
And we can even test this in a second. But anyways, we can see that our script finished in 22
seconds. So that's how long it took to do this image processing here on 15 of these high resolution
photos. Now, when we're processing a lot of items like this, this is actually a great candidate to
use multi processing, because this can be one of those CPU bound operations that's spending a lot
of time processing each image. And it's not moving on to the next image until the previous one
finishes. And if we use multiple processes, then it can actually go ahead and move on to the to
process another image while the previous one is finishing. And even if this is IO bound, unlike
threading, CP or multi processing is actually going to be beneficial for IO bound processes as
well. So now let's see how we can change this code so that it's using multiple processes instead.
So first, let's think about what we're doing here. So we're looping over our list of images
and processing each one at a time. So if we remember from our previous examples, then this
would probably be a good candidate for the processing pull map method, where we can pass in a function
and a list and have that function run with every value in that list. But first we'll have to create
a function that will process a single image. So to do that, if we think about this, we can basically
just replace our for loop, because our for loop is processing a single image from our images list.
So instead, we can just change this one line here and just turn this into a process image function.
And we will just accept this image name as the argument. And now that we have that function,
that process is a single image, then we can create a process pull and map our list of images using
that function. So first let's import the concurrent futures module so that we can use that. So up here
at the top, I'm going to import concurrent dot futures. And now down here below our function,
we can do this by saying with concurrent dot futures dot process pull executor as executor.
And now within our context manager, we can just say executor dot map. And we want to map this
process image function. And we want to pass in the list of these image names. Now, just in case
that was confusing, let me go over exactly what we did again, in order to change our previous
script in order to use multiprocessing. So we were using a for loop here. But instead,
we changed this to a function that processes one image at a time. And now we're using our
processing pull executor like we saw before within a context manager, we're running executor dot map.
And we are passing in that function that we created. And then we're passing in our list of
image names. And again, what map does is it runs this process image function with every item in
this image names list. And just with those small changes, this will actually use multiple processes
to process those images and run these in parallel, instead of running these synchronously. So if I
run this, whoops, and I made another mistake here, you guys probably saw that one also. But I needed
to put a colon there. Okay, hopefully that's my only mistake. Okay, so if I run this, then we can
see now these are processing faster. And I'm going to open up my activity monitor here, and scroll
down to the P's. And we can see here that we have multiple Python processes running here. So we can
actually see these in our activity monitor. And now that this script is finished, then we can see
most of those go away. The only one that's still here is probably just one that is open here in
my sublime text. So we could see all of those kick off in our activity monitor. And we could see that
they were all returning faster. That's because they were running in parallel. And now instead of
taking 22 seconds, like it did before, now it finished in seven seconds, so more than a third
of the time. So that's a pretty significant speed up there. And this would be even more
significant if we were processing even more images. So the speed ups can be pretty drastic,
depending on what you're doing. Now, again, you might want to experiment when using multiple
threads or processes for specific tasks, depending on what you're doing and what kind of hardware
you're running. One might be drastically different than the other. And it's hard to tell exactly what
you should be using without some benchmarks. But again, a good rule of thumb is that you want to use
threads for things that are IO bound. And you'll want to use processes for things that are CPU bound.
But you may actually see significant speed ups using threads with this example, since this is
reading and writing to disk, which is an IO bound operation. Now, one nice thing about using the
concurrent futures library like this is that switching between threads and processes is just
as simple as changing this process pull executor, and just using a thread pull executor instead.
And you can do that vice versa to change from threads to processes with your programs. So
if I change this to a thread pull executor, let me see if I'm right about a lot of this
being IO bound here. If I run this, then we'll see how long this takes us to finish this script
using threads instead of multiple processes. And that was actually faster. So that was 7.2 seconds.
So even though I tried to put together an example that was doing a lot of processing on the CPU,
it looks like most of this is IO bound from opening and saving these files and not CPU bound, but from
doing some image processing here with these Gaussian blurs and these resizes and things like that.
But that's okay. That's why you want to always experiment. And, you know, if you try it with
a process pulled, and maybe try it once with threads and see if you get a better execution. And
also, whenever you add in even more items, maybe processes will start to become
more performant than threads. So it really just depends on what you're doing. Now,
before we finish up here, I'd like to mention the sponsor of this video. And that is brilliant.org.
So when we're talking about threading and multi processing, these topics are especially useful
in the field of data science. And the data science field is growing at a very rapid pace.
If you'd like to learn more about programming and data science, then I would definitely recommend
checking out brilliant.org. So brilliant is a problem solving website that helps you understand
underlying concepts by actively working through guided lessons. And they've recently added some
brand new interactive content that makes solving puzzles and challenges even more fun and hands
on. And if you'd like to learn more about data science and programming with Python, then I would
recommend checking out their new probability course that covers everything from the basics
to real world applications and also fun things like casino games. They even use Python in their
statistics courses and will quiz you on how to correctly analyze the data within the language.
So their guided lessons will challenge you, but you also have the ability to get hints or even
solutions if you need them. It's really tailored towards understanding the material. They even
have a coding environment built into their website so that you can run code directly in the browser.
And that is a great compliment to watching my tutorials, because you can apply what you've
learned in their active problem solving environment. And that helps to solidify that knowledge.
So to support my channel and learn more about brilliant, you can go to brilliant.org forward slash
CMS to sign up for free. And also the first 200 people that go to that link will get 20% off the
annual premium subscription. And you can find that link in the description section below. And
again, that is brilliant.org forward slash CMS. Okay, so I think that's going to do it for this
video. I hope you feel like you got a good idea of how to use the multiprocessing module and how
we can use these to speed up our scripts. Now, I hope you also feel like you got a good overview
of threads and processes. And when you should use those. But like I said, if you're unsure,
then there's no hurt in simply trying both on a subset of your data to see what gives you the
most speed up. Now, there are some more advanced topics that we could cover in future videos,
such as race conditions, locks and things like that. But we'll save that for a future video if
anyone is interested. But if anyone has any questions about what we covered in this video,
then feel free to ask in the comment section below and I'll do my best to answer those. And if you
enjoy these tutorials and would like to support them, then there are several ways you can do that.
The easiest way is to simply like the video and give it a thumbs up. And also it's a huge help
to share these videos with anyone who you think would find them useful. And if you have the means
you can contribute to Patreon and there's a link to that page in the description section below.
Be sure to subscribe for future videos and thank you all for watching.
