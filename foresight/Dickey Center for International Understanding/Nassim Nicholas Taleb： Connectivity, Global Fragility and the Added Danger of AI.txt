It's a great pleasure for us to host Nassim Talib to Dartmouth, Nassim as you probably
know by now has been a pretty influential thinker for the last three decades, but particularly
since he published the Black Swan, which I looked it up, Nassim is cited by a hundred
thousand people in various publications.
I looked in Google Scholar, you should know this.
It's good for you.
It's good for your career.
What career?
What career?
When Nassim came of age in Lebanon during the Civil War, that only in retrospect seemed
predictable, little wonder he spent his remarkable career teaching us about how to manage risk.
His profession he once told me is probability, but his vocation is showing how the unpredictable
is increasingly probable.
He taught us to be irritated by economists, officials, journalists, and executives who
take averages from empirical data and suppose that our tomorrows are likely to be pretty
much the same as our yesterdays.
He taught us about fat tales, fat tales there, fat tales, events that seem statistically
remote but contribute most to outcomes by precipitating chain reactions, say, viruses
that spread software that goes viral.
He taught us about the dangers of connectivity that enable exponential growth.
He taught us about the dangers of connectivity that expose us to malicious or compromised
nodes in the network whose threats once could be isolated but now move and spread instantaneously.
He taught us about how fragile connected systems are and how seriously we have to take anti-fragile
measures that make us more robust, even at the cost of some illusory notion of efficiency,
about the importance of storerooms and cash reserves and many supply chains and circuit
breakers and separation of powers.
He taught us, a former options trader that he was, about how to hedge against even profit
from our inevitable reversals.
He taught us about how in an uncertain world our choices actually become easier because
they focus us on doing what we must avoid, which is reckless behavior while increasing
our flexibility.
He taught us finally about how to contain our incipient recklessness, how we need to
insist that all have skin in the game, face moral hazards, suffer the consequence of our
action.
He taught us, as only he can, about Hammurabi code.
Now we are confronting a world in which network effects are being put on steroids.
Nodes are able to process unimaginable amounts of data and turn them into what can seem like
human creations.
AIs, large language models may not be as capable as humans but we seem nevertheless to be meeting
them halfway.
Nassim has made clear to me that he does not consider himself an expert on AI, yet I can't
think of anyone who is better qualified to talk with us about the dangers we may face
from technologies we just barely understand in networks that we do understand largely
thanks to him.
It's great pleasure, Nassim Taler.
I'm very honored, but he gave me, Professor Abishai gave me way too much credit, but
I think that it's been shorter because what I think I contributed to mostly is fragility,
is mapping fragility to accelerate a non-linear response, why they must be come together.
Something else is pretty much other people's ideas largely my grandmother, but this mapping,
so that's sort of, but I'm very honored also to be here because I've read him before he
read me, all right?
And also you guys have a wonderful setup here, wonderful campus, very well positioned, shielded
from New Yorkers and stuff like that, valley, entry points are scarce, so this is a wonderful
campus and I'm honored to be the first time in that great institution.
Nassim, let's start with some of the basics.
I feel like most of us intuitively understand the dangers of connectivity, but I think that
you've given it a kind of precision, you've given that danger a kind of precision and
I'd like to hear you talk about it because before we talk about AI, I think it makes
sense for everyone to understand what you considered to be the dangers of networks before
AI became a serious problem.
So let me give a very simple metaphor, a story I gave to the Black Swan, so I'll be repeating
myself with that story that illustrates both fat tails and connectivity.
Let's assume that you're in the 19th century and you're an opera singer, okay?
You're an opera singer in Boston or in Naples, you're protected, you have a job because the
great opera singers in Milan at the Scala, which essentially is very small, and the great
opera singers at the Metropolitan, they can't compete with you because they're over there
and you're here, so you have some kind of protection.
Therefore the income of opera singers is going to be similar to that of dentist.
Some dentists make a lot of money, some make less money, but the greatest dentist doesn't
make much, much more than the average because of course you can't scale it, you can fill
up the Scala, you know, you can do more than that.
And then from Carrion, okay, discovered that there's such a thing as television and such
a thing as Deutsche Grammophon where you can store your voice.
What happened?
A hundred years later, a few opera singers, about ten of them made 90% of the money and
the remaining opera singers worked, Starbucks was not the same at the time, but most of
the occupation was Starbucks, so that gives you an idea about connectivity, what did it
do in the economic world, okay, is that someone dead, like Pavarotti, can compete, okay, or
as a state can actually get the income away from a young opera singer in Boston.
So this is pretty much, so this is connectivity for you and then you can generalize to biological
things like COVID and in the Black Swan I say that the pandemic would not be a Black
Swan because of connectivity, now connectivity is a very good thing, but it has side effects
and if you don't know the side effects, alright, don't get too much into something.
So these are the side effects of connectivity is that you have a winner take all effect.
So if you take income of athletes, 1950, the top athlete versus the average, two, three
times which people found excessive at the time, top athletes, today it's 50 million
euros versus say 35,000 euros, I'm very bad at numbers, so I can do algebra, but I can
do division, so divide 50 million by 35,000 and then you get an idea of the inequalities
that we have in that field, okay, so the current environment produces these things, the Harry
Potter effect that 100 authors worldwide can live off, this was numbers as of four or five
years ago, can live off of their income as authors and then the rest, again now they
have Starbucks, there are other things, there are university programs where they teach people
to write or end up teaching other people to write or stuff like that.
So the rare event actually accounts for the greatest impact on the entire thing, if you
average it out, you miss that, you miss that.
You miss that because it's driven by the tails, by the rare event, by the extreme, there are
two environments, one I call mediocrity, if I take the weight of the people here, we put
them on a scale, I'm sure in darkness, the engineering department know how to build robust
scales, you know, and then we add to our sample the largest person you can find on a planet,
the largest human being, it's not going to change the average much, all of us here, I
don't know how many we have here, but say a couple of hundred, nothing, it's not going
to make an impact on the average.
But if you take the net worth and add Elon Musk, some 200 billion dollars, so you realize
that there are some domains Elon Musk would change the average and it would be a high
percentage of the total.
So this is the effect of fat tails and you got to figure out which domains produce fat
tails and which domains don't.
So we have a tableau, in the black swan I did that years ago, saying this is the domain
socioeconomic life, it's driven by fat tails, your weight is not driven by fat tails, like
there's no meal you can have that will represent 98% of your annual consumption.
You can try, I mean you die I think very after the first 2% or something like that, you die
after the first 5,000 calories, so you can't reach, so, but you can lose all your money
in a minute.
This is, so we have this domain and the other domain.
Right, so go back to the epidemic, because that's interesting.
You said the epidemic was actually not a black swan event, even though the particular
virus might be considered a rare fat tail event.
Yeah, not having an epidemic is actually the rare event, not having had an epidemic.
Let's look at connectivity and the reasoning, I had the black swan event as follows.
If I have an island, an island will have many more species per square meter than a continent.
So what does it tell you?
It tells you the continent has more inequality, a few species dominate the numbers.
And if you'd open up all the islands to one another, you're going to have that.
So we're going to have a winner take all in the biological field.
So whatever virus you have would travel.
So the reasoning of the black swan was that there's such thing, I don't know if you've
heard of Air France.
Air France, they fly, they do New York, Paris.
And at the time they rotated because they were not stopping Gabon during Ebola.
There are other things like Air France, the British Air, the American Airlines, everybody
has those, okay.
So the Great Plague, I don't want to call it great, but it was the plague, all right.
It was a bad plague.
It took, I think there's some villages in the Lake District, in England, that was reached
340 years after Constantinople, okay.
And they never reached the Americas and Oceania, okay.
So you realize now you can have the same effect with a meeting like this one or you have people
from many countries, particularly if you have conventions and people fly in and they
can distribute to the Philippine, Mongolia, Southwestern, China, Argentina.
Within a week you have a worldwide pandemic.
So that was the reasoning in the black swan and no pandemic was taking place.
And we haven't had anything of significance since the Spanish flu.
So I mean, we had many bad things, but so the black swan for me was the absence of such
a thing as COVID.
Right.
So the irony here is that most people will think of the existence of this virus as a rare
statistical event, but because of connectivity and the way in which you describe connectivity,
the ability of that virus to spread is so baked into the network.
And there's no place to hide.
And there's no place to hide that we should not think of pandemics as rare events.
We should assume that they're going to be predictable, they're rare, improbable, but
the probability of their spread is very predictable.
And I was enraged during the pandemic at practically every single group of different political
groups.
In the beginning, when we were waiting, we were a group of people in a nearby arm, myself,
complex waiting for the pandemic to emerge to go back people to reduce connectivity.
You don't need all these things, all you need is reduced connectivity.
And the Ottomans know how to do it.
The Ottomans and Habsburg had something called lasaretos, quarantines.
I grew up in Beirut, there's a quarantine, the Quarantina, had an Italian name, that's
where people, vessels would come in and put you for 40 days.
Actually, quarantine was about seven to 11 days, depending on where you came from.
They had formulas.
And the minute they hear a rumor of a quarantine, of a pandemic, or the Quarantina, all right,
so you had quarantines, we don't eat quarantines if you have testing.
So it took us 13 months from the inception of the COVID, right, to have testing at the
U.S. border.
And I don't know if you've been to JFK during, you know, when planes come from all these
places.
And it looks like, I mean, being in a subway car, everybody's contaminating everybody.
So for 13 months, people didn't get the simple measure.
So in the beginning, we started fighting for, what we called exactly, decoupling systems,
by putting fences around the system.
So instead of lock-in, lock-in in your house, we locked out.
So the second thing is we had to fight people in psychology departments, finding it irrational
for us to worry about a pandemic that killed 5,000 people worldwide.
When cancer was killing 5,000 people every day or something, right?
So you couldn't explain to them the following reasoning.
There's a fellow called Dr. Phil who went on television saying, oh, we don't, at the
time COVID had killed 3,000 Americans.
He said, 3,000 Americans have drowned in a swimming pool.
So, you know, why don't, we don't shut down swimming pools because people drown in them.
Why do we shut down because of COVID?
So, you know, the response is, if I drowned in my swimming pool, also I was at a neighbor
who was going to drown in her swimming pool, and that probably increased, whereas the five,
sorry, that probably have not increased, right?
Whereas if I die of COVID, the odds that my neighbor is going to die of COVID has increased.
So you got to look at the multiplicative effect of these things and forget about standard statistics.
Again, mediocre standard is what people learn in business pool and statistics through classes.
You're completely useless on a bell curve.
The bell curve works very, very well if you do astronomy, right?
If you do astronomy, if you do medicine, it works, but it doesn't work in socioeconomic
things.
It doesn't work for pandemics.
So we had to fight, and nobody was taking us seriously until we started producing papers
in like nature physics, because physicists understood the mass immediately, and then
people start taking us seriously.
And then you interviewed us, and about a few words.
I remember also when we talked about it, I read that paper at the time, and one of the
things you said in the paper as a kind of decoupling or quarantine was, if everybody
just wore a mask immediately.
Exactly.
Even if you don't understand how it works, wear a mask.
And the masks for masks also, they didn't get the non-linearity, is that the first part
of the non-linearity, it's complicated for us really to explain the following.
If I reduce viral load by 10%, I may reduce infection probably by 90%, you see, or risk
of death by more than that.
And the second thing, they couldn't figure out that if I wear a mask, and I reduce my
viral load by 10%, and you were wearing a mask, that you're looking at the joint effect
of both masks, not just one.
So there have been a lot of papers on masks that, we actually debunked a lot of them.
But besides that, you don't need a paper, I mean, just understand that what you've got
to lose wearing a mask while you're going to have a little CO2 or something, it's not
a big deal.
People are not going to see your teeth, so it's okay, it's fine, draw a smile on your
mask.
So we had to fight for masks.
The problem is that in the beginning, the establishment, intellectual establishment,
using pseudo-statistics, what I call the Pinker statistics, named after Stephen Pinker
in my books.
So bad statistics are called na√Øve empiricism.
They were against measures to fight COVID.
And then it switched, okay, the Trumpist became against the measures.
The other one is because the Trumpists were against the measures.
The other one said, okay, let's take measures.
But in the beginning, it's not like the polarization flipped at some point during that story.
So let's talk about fragility in this context, because that seems to me a critical insight
that you've advanced.
If you have networks that are susceptible to the catastrophic network effects that ensue
and that you have exponential spread, you then have a kind of fragile system which considers
itself safe as long as it's just doing averaging, but is not at all safe if you take into account
the catastrophic effects of tail events.
And also the acceleration effects.
And the acceleration effects.
So let me explain sort of like what happens in a system.
So let me go back to non-linearity.
I can talk about it, it's not too complicated.
Yeah, go ahead.
So non-linearity.
As long as you don't talk about convex and concave.
Okay, so if you jump, say you jump four meters, you're going to be harmed a lot more than
four times if you jump one meter.
You agree?
All right.
And if you definitely, if you jump 10 meters a lot more than 10 times one meter, because
if you jump 10 meters, definitely there's a bituary in the darkness.
So there's what we call acceleration.
I notice that in finance, as a trader, if the market is down 1%, say you make 100,000,
the market is down 10%, you make 20 million from acceleration payoff.
So that's what we call, let me use the word, negative convexity.
Convexity.
Concavity, whatever, or positive convexity in some cases.
So there must be, then I notice that everything in nature has to have those accelerated, those
response, okay?
And there's an argument which is complicated, but let's say, so in other words, if you jump
four times one meter, okay, it's a lot better than jumping 0000 than four meters, you agree?
All right.
So let's apply that to demand, okay, a fragile system in demand.
And there was a part of our conversation way before people were aware of the supply chain.
If you consume 100 one year, say toilet paper, whatever it is, okay, and then 100 the next
year, the average is 100, it's not going to stress the system in the same way that if
you produce zero one year, or demand zero one year, and then 200 the next year, what
happens if demand, you have hyperinflation, then hyperinflation, all right?
So that's exactly what happened with demand for anything, for bicycle parts to whatever,
so demand went to zero, and then jumped, okay.
And of course, also there's stuff like Peloton, demand 1200, and then 100, so it was a lot
worse than 50 and 50, so the unevenly distributed stuff, if you're fragile, you want a distribution
to be steady when you're fragile, when you're out here, you want the market to go down 1%
one day, and then 1% the other day, it's a lot better than zero, and then 2%.
The effect is it squares or whatever, so it's the same thing actually in price impact
in the markets.
If you want to buy 10 units, say $10 billion of whatever, the stocks, if you buy them all
now, you're definitely going to have financial problems, you're going to move prices, but
if you buy over 10 days, no impact, okay, because 10 times, you know, it's 100 times
the price change, because it's in squares, okay, 10 times is a lot, like 100 times 1.
So that's the example of non-linearity that had to be present, and I think that's the
only idea I've ever had, everything else is, you know, comes from reading a lot of books
talking to grandmothers and grandparents and uncles and stuff, so this is the idea that
our world, you've got to realize where the fragilities are, and it's very simple once
you understand where the vulnerabilities are based on non-linearity, so this is it, and
then the idea is-
So for business school students, I just want to be, for business school students, the clearest
example of this are the efficiencies of just-in-time manufacturing and stuff like that.
So fragility is, in a way, a function of an illusory understanding of efficiency, right?
Yeah, the word efficiencies actually makes no sense, okay, because I'm okay, so let me
give you a little bit of my background, okay, I was a, you know, a regular MBA person, then
became a trader, then after being a trader, I decided to become a mathematician, right?
People do things backwards, and then after that, so I did practice, and then I did theory,
usually people do the reverse, they study, then they, okay, so to me a lot of things
that make sense because I was a trader, trading complex instruments, so, and then, so I did
things backwards in the reverse sequence, going from practice to theory, theory to practice,
you see people do it differently, and so that was the thing, they realized that a lot of
the stuff we teach in some departments is excellent, you know, there's a lot of stuff
that's very bad because it doesn't match the nuances of reality, okay, like mediocre
standard, extreme standard, you can't talk about probability in the same way with a
multiplicative process, and the process like drowning in a swimming pool or falling from
a ladder or having a heart attack, okay, so there are different classes of risk, so this
is sort of like my background, so come into it, so, so if you have, so we actually talked
about this, because I was, for my sins, technology editor at the Harvard Business Review back
in 1986, 87, when just in time manufacturing, we felt we had to compete with Japan at the
time, and you know, just in time manufacturing entailed our, you know, doing away with store
rooms and having good relationships with one supplier who would deliver just in time to
your factory, so you wouldn't need a store room, and why have a lot of cash reserves
because you want the money to be working for you, and it was all under the rubric of lean
manufacturing, and it was a kind of efficiency idea which was great and terrifically cost-effective
as long as there was no disruption, and now we learned in COVID, what did we learn?
Yeah, but actually even before that, the notion of efficiency to me was it's something that exists
in textbooks, but doesn't exist in research, let's take a very simple example, mergers,
they say okay, we're going to have a bigger firm, it's going to be more efficient
on ground that you will have fewer people in personnel department and smaller number of
cafeteria people per capita, whatever it is, and a fewer number of trucks or whatever, okay, so
they look at the numbers, they say it's going to be more efficient, but obviously it doesn't work
because companies, you know, large companies don't survive, okay, and here in instant, you know,
thought experiment, two companies come together, okay, they should have huge advantage that they
don't have, and papers have been since 1978 documenting the absence of gains from mergers,
they say something is leaking somewhere, till I figure it out when I started doing modeling on
acceleration, I realized that, you know, there's such a thing as an animal called an elephant,
no, a mammal, very cute and so on, there's an equivalent animal built almost the same way,
called what? A mouse, okay, now why is it that we have eight million mice in New York
that more than we ever had elephants, why? Because a mouse, I don't know, I'm not suggesting,
please don't accuse me of whatever, but if you throw a mouse out of the window, it will laugh at
you, but if an elephant falls by one meter, breaks a leg, it's gone, okay, and one meter is tiny for
for an elephant, okay, so you realize the same thing applies to corporations, because if they're
squeezed into needing something, so we look at a few case studies of corporations that had a squeeze
that cost them a lot more than if they were small, and effectively that explains the first
efficiency coming from size called economies of scale, it turns out to be completely S,
they're this stochastic, this economy of scale, right, so there's an optimal size, okay, so
and then we look at other, you know, stuff like efficiency of supply chain, right, visibly if
you're going to be squeezing to pay it up, you got to count that in your model, all right, eventually
you're going to pay up, everything's efficient, but let's say you have no chips, you're going to go
begging for chips, no, because your whole process has stopped, you have all these employees, you've
got to feed, okay, you have all these things, you have all these things to deliver, every day
costs you a lot, so you're going to pay up for whatever you don't have, and guess what,
you know, it's going to be taken out of, so there's an equilibrium, and the equilibrium is probably
some economy of scale, not too much, some supply chain optimization, not too much, there's constraints
as high, and then when I started looking mathematically at optimization models, I realized that they
only made sense under a set of assumptions that completely get destroyed if you vary one variable,
okay, so I mean, and I looked at, first thing I looked at is Ricardian model of
comparative advantage, that if you assume, you know, the original Ricardian model,
Ricardian model that one country produced cloth, the other one produced wine, but let's,
but it assumed that the price of both is constant, but what if the price is not constant, so yeah,
you know, so what if you have a problem with, with Phylloxera that happened after Ricardo,
destroying your wine crop, okay, so all these are not part of the model, so I think the analogy I
gave you is that if I drive 500 miles an hour in New York City, I say at 2am, it's not going to be
faster than 20 miles per hour, actually it's not going to be faster than one mile per hour, because
you're guaranteed to die at 500 miles per hour, you're pretty much guaranteed to die, so there
exists, so, and then the other thing I discussed in the black swan is why is it that nature, if it
was efficient to have, you know, less, less, use of stuff like, you know, why does nature
give us two kidneys, and I'm sure students at Dartmouth tend to have in general two kidneys,
but you don't need two kidneys, you need only one, one kidney, and an economist would say
not even one, you just go to dialysis, you're carrying all this weight for nothing,
but there's no storm and you're pressed out of the, you exist out of the gene pool, right, so.
So that's a perfect segue to, to talk about what steps you can take to be antifragile,
that is to say what things that you do to be robust, because I think that's really the
entree into the question of AI, like we, we are able to counter the dangers of fragility, how.
Okay, let me not be very gloomy by saying that number one, I like AI.
No, we're not in with AI yet, I'm just talking in, in, in, in the current situation.
Yeah, okay, the current situation of connectivity actually is doing good things,
let me put a good thing, a good word for connectivity.
Yeah, okay.
Let me move before, all right, in 1973, for those of you who were driving a large car,
you know, this, you, you, you know what happened, 1973, there was an Arab oil embargo.
Oh, yes.
You remember that, of course, all right.
And then the American cars in 1973, I don't have seen pictures,
they could pretty much have this conference in a, in a car, all right, they were very large,
we've had, okay, so it was, so they were like gas guzzlers, nobody can, I mean gas was free,
and, and cars got bigger, and then, and then there's such a thing as Las Vegas where cars were,
so, so you had room, so cars were huge, okay.
And 1973 came, now what happened after 1973, compact cars started to show up everywhere,
okay, and the cars, and the demand for oil dropped to the point that the state of Texas
was nearly bankrupt, but definitely the Soviet war bankrupt, okay, so it took like
from 1973 to the early 80s for the adaptation to take place, okay, so that's in the 70s.
Now there is, I think the Nobel Prize of, I don't know if there's no such thing yet for
the Nobel Prize for environmental studies, it should be given to Vladimir Putin, because by cutting
the gas, it took Germany six months to adapt, okay, so he helped the cause of environmentalism
because what took, what took six or seven years of, you know, reduction in demand and adaptation
and stuff like that happened in six months, because of the, the Russians, he thought that it's
going to be, you know, like the Arab embargo and everybody's going to suffer and the Germans are
going to come to their knees to beg for mercy, give us natural gas, we need you, you know,
so God save Russia, but it didn't work because they adapt it very quickly, so our world can adapt
much faster than you think, and I remember posting something on Twitter, right before I bought a
Tesla, all right, I made a mistake in my life, so I posted that, that how, you know, this is great,
because we have like convexity, there's also some energy, free energy, you know, and stuff,
the electricity is free, and I got all these insulting things, including the letter from
the chief investment officer of the major firm, how I should be ashamed of saying something like
that, and sure enough, we have much more, many more electric vehicles, and much more solar power,
and it's growing. Right, so, so you're coming at this on a slant, I mean, what you're saying,
I, I hear, what I hear you saying is that by stressing the system, you're proving the adaptability
of people within these networks, and that there are certain stresses. But that's happening
faster than in the past. Yeah, I, I, I agree, you know, got good things, got bad things,
and now we got good things as well. I agree, but I'm trying to set up your own insights with regard
to how you create a more robust system in advance of this kind of stress, in other words, you, you
spoke about breakers, and, and storerooms, and cash reserves, and the things, I mean, even,
I mean, one way to understand it is like the separation of powers in the United States,
the biggest danger that the founders understood was that of a tyrant. And somehow, they made
something that appears less efficient, they made it like the, the American government
operates less efficiently than you imagine it being able to. But the reason for doing that is
because of all the breakers in a way that they've put in to avoid the big catastrophe, which would
be a tyrant. So there are ways in which you can create a more robust system, a more robust system
when you, when you take the all in cost of putting in these breakers, rather than just looking at the
immediate inefficiency. Yeah, yeah, I mean, they are, they are definitely, I mean,
I gave a metaphor, it's very easy, years ago, they say you have two twin sisters,
and they have an identical business, same revenue base, but one of them makes $4 share,
the other one makes $1 share. The one that makes $4 share doesn't pay for insurance,
doesn't have any stuff like that. And the stock market is going to love her,
but she's going to go bankrupt, who's probably won eventually. If you look at mortality rate,
which is like medicine, right? So you have an average expected life expectancy of maybe six
or seven years, right, for these firms, right? But security analysts won't pick it up. The other
sister makes $1 share, but she can survive, provided that her board or something doesn't
try to fire her, you know, to hire someone like the other sister. So the thing is, we don't have to
go through time series and data to figure it out, you can just look at inventory of the firms.
Okay. You just, you know what can blow up the firm.
Right. You pretty much know what is it, that operational leverage, central thing, we figured
out on this, each firm has its vulnerability. You don't do that. Why? Because it costs money.
Real owners of companies, this is why we have a survival of family owned companies,
intergenerational, for hundreds of years in Japan and Europe, even here, because they have skin in
the game. Whereas an employee has this asymmetry, you see, you want to accumulate as many bonuses
and then send a postcard, say, I'm enjoying my retirement on a golf course, by the way, you know,
I'm sorry about your bankruptcy, right? So that's the Jack Welch trade. I was going after Jack
Welch when he was like a sacrosanct, was like, you know, so it's like going after Aquinas or
someone going after Jack Welch, you know, in circles. The guy is stuffing the company with
what I call short optionality, these things that explode. And incidentally, let me confess one
thing, I made my money to retire from it, you know, betting on blowups of companies that have
hidden risk. Okay. Like Fannie Mae, and I wrote in the Black Swan, Fannie Mae is sitting on a barrel
of dynamite. And everybody laughed at me, but I had the last laugh because we made tons of money
from the bankruptcy, but from the, from its insolvency, and then of course later on, it's
funding. So, so I don't hide that we, that that have skin in the game in the sense that we bet
on tail events. But you're implying that the people who ran Fannie Mae didn't, I mean, they
were, they had no idea, they were making their bonuses, and they didn't necessarily lose anything.
No, they said they had 15, they counted the New York Times. I said the New York Times that they're
sitting on dynamite. When I saw their PNL, accelerating losses, providing things, I said,
they're going to go bankrupt. I told the New York Times, I told the fellow who turned to be COVID
denier, Berencind, who ended with me, he showed me secret reports, I told him they're going to go
bankrupt. He said, he said, probably he'll say, of course, shout it. You know, I can tell the
doorman, I'm going to tell people in the street, they're going to go bust. All right. They eventually
went bust, but they countered. This is nonsense. This guy doesn't know what he's talking about.
We have 15 mathematicians. Of course, I countered, but they didn't publish the New York Times,
that you can have 15 mathematicians, 150 mathematicians, 1500 mathematicians, 15 billion
mathematicians. It won't make a difference, right? You're still going to go bankrupt. And sure enough,
they almost went bust without the tax payer, without the generosity of you and us tax payers.
So we have a, it's not just Tany May. Tany May was, to me, a model of firms like that that are going
to blow up. So we can express the bank with other firms. That was that. And that was the banking
crisis 2007. And that's what people noticed me. But the black swan was written right then.
Okay. So now let's look at the same analysis and apply it to who's going to blow up.
So it's very simple. You take a firm, you see how many suppliers they have. What odds are that in
2003, they had 18 suppliers for a product. But the accountants over time made them get one supplier
Newhawn converge. All right. Like a very large firm that I know had 15 suppliers and now one in
Newhawn. Okay. But of course they deserve what happened to them. Okay. But because it was cheaper.
But things are not cheap. But there's a middle way. What's the halfway is if you need supplies,
make sure that all your suppliers are not in the same basket. Okay. Right. All right.
Diversify this one on one diversification. Okay. So and skin in the game. And skin in the game. Of
course, if you lose the other, you know, so there's a lot of things you can do. But then as a society,
as a whole, I think the job of the government is to protect us from tail events. That's my
definition of government that sort of some people think the government like in the EU
should meddle with how much energy your vacuum cleaner uses. I think that otherwise the things
of government is there for pandemics and things like that. Okay. That we have, we have a reserve for
oil, but we didn't have one for chips. Right. Right. We have a, so we have to identify vaccines.
We didn't have a reserve for vaccines. We didn't have, we weren't planning for this event. That's
right. And the only place, the only intelligent person, because from 2013 on, Yannay Baryam and I
went talking to people, tell them, listen, the pandemic is coming. Are you ready? The person,
the only place where these people had a game plan that was very precise, Singapore. And guess what?
And the person retired. So it wasn't as good as when he was there.
Phil, something, right? He was head of civil service in Singapore. And he had, he knew, he said,
yes. And then this is what we're doing for this. And he taught us basically,
you know, we learned more from him than, than, than our argument. So, so they are some places,
but not, not the job of the government is to have contingency plan in case of pandemic. And we
know we're going to get that big one. I mean, COVID was very bad. But it was more like a dress
rehearsal for the real one. Think about it. The antibiotic resistant strain that once it's out,
you know, plus for the aging of the population, they will transmit. So, so they are things that
will, you know, that, that, that, that you've got to consider. The problem is epidemiologists,
I hope I'm not offending too many people, but epidemiologists, their models were using Gaussians
who was not using, you know, power law tales. Right. When you wrote that, the nature of physics,
the physicists got it right away. They say, how come they're not using it? They say, yes,
there's a published article and people were shocked. It's a completely different culture.
Well, now that, now that you've frightened me with the idea of a universal pandemic of
antibiotic resistant bacteria, I feel like I'm somehow scanting the problem by turning to AI,
which seems by comparison, by comparison, rather hypothetical event. But I do, before we get to
questions, which I hope to in like within five minutes, I just want you to try to apply what
you mean by anti fragility to a network where nodes in the network suddenly are on steroids because
of AI. Like, how can we apply this? Let me, let me go back to COVID in a way, in a way we were
lucky. COVID was a bad thing. It killed 20, some million people were very bad. But it's sort of
like it was, it taught us, right? So just assume that the big one came before COVID. Okay. So,
and the internet saved us with COVID. Just assume if we didn't have as a sequence, we had COVID,
then the internet versus internet and COVID. Okay. So, so we were, but now we're more prepared for
the next one. So we don't have a lot of selling to do, say, okay, you test at the border, you close
the border, you do this, you do this, we know the game plan. And probably for generations,
it's going to hold. The, and, and the zoom, you know, which I mean, I'm sure you fed up with it.
Okay, I am fed up with it. He made me teach a class on zoom. For me, going to a dentist is better
than teaching class on zoom. But nevertheless, I mean, it allows us to function. So the,
the, so we have things. So antifragile, there's the systems that have this property that without
stressors, they get weaker. That's what I noticed. Doctors call it hermesis. And I figured out the
modeling of it comes from convexity. Once you define fragility, you have the reverse of fragility.
And it's the same equation. It's a minus sign. Because the minus one is concave, the other's
convex. So something, so you tell yourself it's a system is antifragile, then it needs to be stressed.
Okay. Otherwise, it dies. And natural systems don't get information via the New York Times.
How do they get via stressors? So if you go, if you have a Mediterranean skin, I think you
qualify as Mediterranean skin, you go in the sun. All right. What happens? You tan. Okay.
Why do you tan? Your body gets a signal that this is the intensity. So it's protection
for 10% more intensity. I'm sure you have a gym here. You know, you have a gym in darkness.
There's a gym. You go to the gym, you lift the 100 pounds. What happens to your body?
It prepares for 110 pounds. It up regulates. So there are a lot of things. And now if you
tell us what is the converse of it, the bad news is that if something needs stressors and doesn't
get stressors, what happened to it? It weakens. You see? So just assume that if you spend six months
in bed, no stressors, no germs, nothing, no classes, no Starbucks, no bad coffee, nothing.
All right. You're in bed for six months. And then you get out of bed. What have, first of all,
your bones, you know, would be weaker. And, and of course, you're going to the first germ. And,
and if you're in a completely germ free room, you know, what's going to happen to you,
probably not going to survive. Right. So, so there is this idea that, you know,
you need stressors up to a point. You need some stressors. And things up regulate. And I learned
that. Why I don't, one thing is maybe sort of I'm trying to explain why I'm not a good speaker.
I don't want to be a good speaker. Because if you speak like this, you have to make an effort
to understand me. You'll remember more what I'm talking about. So the, now this sort of like,
okay, but I still want to make it easier on them just a second. So apply this, apply this to AI. I
mean, we, we normally think, I mean, people have talked about this, you wouldn't be in the room,
I suppose, unless you were concerned to some extent with AI. Well, no, you'd be in the room to see
nothing anyway. But if, if with AI, we have these nodes in networks that have these capabilities,
you spoke about the various capabilities of AI at lunch today, which I want you to share.
Okay. But what, what can we do if government, if government's responsibility is to protect us
from tail events? Yeah, I'm not worried about AI. And let me start more. Good. So let me tell you why
I'm not, I'm more worried about the pandemic. And I'm vastly more worried on my list about debt.
And I don't know if you own real estate, but the, the, the, we had because of bad policy for the
reserve zero interest rates, we have a bubble. And, and they're not able to manage it, keep raising
a lot of debt in the system. So we have that to me, these are the big problems. AI is not a
problem for several reasons. Number one, I happen to have my, my big job is happened to do statistical
modeling. And we've been doing neural net forever. Okay. Neural net and finance and always failed.
And, and, and also with people, what do you mean by AI, the difference thing, the machine learning,
the LLM, which strategy PT is, and we'll focus on that in a minute. And then we have robotics,
robotics, do you have a thermostat in your car? As you put 68 degrees, if it's higher, it shuts off.
So we've had that forever for a long time. I mean, okay, so it's not like we're just, you know,
making it more advanced, but, but, but people were not afraid of thermostat. And now suddenly
the single robots are going to take over the world. Right. So we got other things to worry about
before, but let me talk about chat, GPT as, as a trader. I learned one thing as an option trader.
And I had a saying, if you have any reason to buy a stock or an option to buy an option, don't buy it.
Why? This was already in the price. Okay. Now the, let me explain what chat GPT does,
basically. It does is that it takes all the conversation and gives you the most likely,
maybe not that precise conversation, but the most likely one that resembles it.
And, and the first thing I did is try to trick it because, you know,
during the day, I do nothing except bicycling now and a little bit of math in the morning,
and then the rest of the time, I get time to kill. So, let's strip chat GPT. Okay.
So you go to the obvious point is that what, what does chat GPT? It's, it takes just,
it's just verbalistic. It takes words. So you can trip it by either making it say
two things that are contradictory because of the verbalism, but that's complicated.
So I did that, of course, and say, oh, I got a homerun. So let's see why chat GPT
cannot run anything. Let me tell you why. It's a great clerk, right?
It cannot run. The clerk doesn't run. It assists. Let me explain the thing. The first thing is
there was a, at the Congress of Berlin, there's been a war between, on one part in Greece and
Western power. The other one, the Ottoman Empire. And there was a fellow called
Constantine Karateodoris, okay, who was representing one power. So I asked chat GPT,
what was the function of Constantine Karateodoris at the Congress of Berlin, where they had to
sign a peace agreement to the treaty between Greece and Western countries versus the Ottoman Empire?
Of course, it saw it because his name was Greek, and he was an ethnic Greek, that he represented
Greece. Who did he represent? The Ottoman Empire. Karateodori Pasha. So you knew immediately,
what does it do? It doesn't know the answer, but it gives you the most likely answer,
okay, and that's exactly what's going to bankrupt you because that's already in the price.
I tripped it. Another one was my village, the Battle of Amun. My village is a Byzantine
village in Lebanon. So there was a battle that happened, according to the record,
some a century after the Arab invasion. So there was a battle between the Byzantine army and the
Maronite, some Christian sect that was pushed up the mountain. So we asked chat GPT, you know,
what happened at the Battle of Amun? And it told you it's between the Islamic invaders and the
thing because it's most likely there's a battle. So when you take the corners, how are you going
to make money? You're not going to make money with an existing idea, but it makes sense, you're not
going to make money because it made sense. A lot of people tried, they failed, and you don't hear
about it, okay, because people don't talk a lot about their failure, right? So that was the idea.
If you look at chat GPT, it cannot come up with a theory of relativity because it's not part of
this course. It would actually dismiss it. You see? So that's why I'm not worried about it.
And you can't run anything, you're just an assistant. It's excellent if you want to write
a condolences letter. It's always very complicated. I have friends who are Muslims,
friends who are Jewish, friends who are Catholic, and then they have to make sure
they use the right wording, you know, like you don't say ad-vitam eternam to the eternal life,
to a Jewish condolence letter. I learned from chat GPT, so you write one, you see, let his memory
be eternal. Okay, so for example, chat GPT is great for that because it gives you the most likely
thing that people say. But if you want to progress, you don't progress by saying the obvious. You
don't progress, you progress only with the corner. So this is where, yeah.
So I can't resist asking you, is it possible then that the great, even call it black swan danger
of chat GPT is, if what you're saying is true, that it's always sort of giving you sort of the
most likely average response. Exactly. The mediocre, the most mediocre.
The most mediocre assistant you can ever have. Right.
So think about it. That's how it's by design, because it reflects.
But if we become more and more and more pleased to have this assistant,
is the difficulty and maybe the danger that we are going to meet them halfway and ourselves
become mediocre. I mean, that's the thing that kind of bothers me. I think, okay, so we are
become, I agree with this, this is our argument about that launch, but let me come in with one
word. Have you heard of, there's a Flaubert's Dictionary of Received Ideas? Yeah.
Well, as a parody, what people would say, you know, that's a received idea, usually, you know,
and you know the crowd is wrong. So it's pretty much like the dictionary received idea. So,
but let me, what happened is that I am, I have a problem. I didn't know I was good in math
because I have a, I can't count as a track very well. I can't divide. So I have, I have, I had a
12C, luckily, and I became a trader with a 12C, I became adapted. So what happened is that I'm
still my 12C calculator, which incidentally, I have now my iPhone 12C. So I can't compute a tip
in a restaurant without it. All right. So the, but it frees you up to do other things. So become
more mediocre at driving. I used to get lost driving home now, definitely without Google Maps,
I get lost, you know, going around the corner. All right. So I have a worse driver than in the past.
Sailors are worse navigators than they were in the town of Columbus, when you have three ships and
how you can follow one another, especially at night, all right, and communicate, all right.
So there were much better sailors than today, but you free up that time, I become very mediocre,
all right, in, in saying that I'm mediocre in what I use that machine, and I'm going to be better
than other things. Okay. So, so this is, this is where technology can free you up to do other
things. And, but people think that chat GPT will replace people. I think what it will do is what
I learned from, from my translators. You know, the translators lie. All right. One of the lies is,
I don't, I don't use Google translate. Never heard of it. I don't know what it is. So
I know some translators used to translate two, three books a year in 2000, when I had my first
book translated. And now the same translators translate seven or eight books. How this is.
So, so Google translate is not replacing translators, but translators are using it
for efficiency. So, you know, for the first cut and stuff like that. And then of course,
they make sure that your text doesn't look like Google translate by, by changing words here and
there or so. But the, so this is pretty much what will happen with when people say that in imaging,
we're going to change GPT, not change GPT, that, that pattern recognition will replace
radiologists. It probably will have fewer radiologists. Okay. Because they can process maybe
a hundred, you know, x-rays a day versus 10. Okay. And, and this is where it's very useful.
Or there are parts of the world that don't have radiologists at all. And that will,
you know, it's part of the world. Yeah, because you'd have one radiologist service a lot more.
So we'll bring down the cost of medicine or make it more efficient, but it will free up medicine
to the other things, you know, like focus on headaches, for example, or maybe curing bad
humor, right? That's to me, whatever, I'll think that are more important, I mean, very important,
but, but completely neglected. So you freeze you up like driving Google Maps, freed me up
to compose maybe, you know, other things and became worse now at composing a spontaneously
condolences letter. But I know now I have a format for, you know, what's Sunni, this is
for the optimal format. This is for Shiite. This is for Maronite. This is for Greek Orthodox.
This is for religious Jew. This is for secular Jew. So I have the format. So you see what, what,
so I'm worse writer for condolences letter, but probably I have more time to write aphorism on
Twitter. All right, so she's I'll have to remember this when I write my thank you letter to you.
We should, we should actually go to audience for questions. Yes, sir, just wait for the
microphone. Someone is going to deliver a microphone to you.
I'm curious if you would comment on how you perceive the possible outcomes given the increasing
US debt and our inability to service it. We have, I think that we're conscious of it.
I mean, this country is very adaptable. Nobody would have thought that would have
5% interest rates, 7.7% mortgages today. And then we went from 2% to 7.7% mortgages.
So some countries are very adaptable. That's the most adaptable probably country on the planet.
So there's one thing about debt that happened. We have had some inflation
that reduced debt in a way. All right. And then also what there's a Lebanese expression.
It got a bit big before it gets smaller. You got to get bigger before it gets smaller. So in
other words, now we realize what's going on with each problem of Congress. And some, some people
are realizing that the thing cannot last long and you can't keep borrowing.
The government has to have some kind of model for to reduce that. But there's a positive thing I
would say is that the government has, because of the zero interest rate policy, has accumulated debt.
But there's a lot of, you know, that, that swelling of assets. That's a lot of profits for
the government because you know, there's such a thing as income tax, capital gains tax.
So government has accumulated assets that people are not noticing during the bubble.
So overall, I'd say that people are conscious of the problem now. And, and I'm glad people are
fighting in Congress. Because on one hand, you have a tension between, it's like optimization
under no constraint. So you optimize social justice. You'd like to, but you need to have
constraints. Like you have a wallet, you know, you have a watch in your wallet. And, and you can't
borrow forever. And so people are conscious of it. And once you have the solution, it would be
probably easier. Plus, we got, I think AI would do something, which is increase productivity in
some domains, as we are noticing, the Google scholar translator productivity. So a lot of
things will come that, but, but so it's not, we're not Japan yet. And other countries will suffer
more before we suffer. I had a question about AI and regulation. A number of AI innovators are
going to Congress and asking for regulation, which looks a lot like Stigler's insight that
firms demand regulation to raise barriers to entry. And of course, highly regulated firms are the
most profitable firms. Would you agree that what's happening is a Stiglerian thing where they're
trying to raise barriers to entry or is there some noble intent? Those clamoring for regulation are
those the most threatened by AI. I mean, I, I was an arbitrage trader. And you know what regulation
means because you give me a country where they have a lot of regulations. You hire three lawyers.
Okay. One lawyer in Japan. Japan was the most regulated financial market. So you hire a lawyer
in Japan, one in London and one in New York. Okay. And then you, the regulation, what does it do?
It causes arbitrage because there's some, you can't short stocks in Japan. So you can make tons
of money, whatever you have regulation, if you love tons of money, finding ways to reproduce the
same product built in another way. Like for example, you can't go short stocks in Japan. So you buy
the index. Okay. You buy all the stocks, but you could short the index. So you have a flat book
and someone wants to short a stock. You said, you short the stock as a huge fee, you know, you
remove one stock from your long. So you have net, a synthetic short, for example. So this is an
elementary trade, but they're more complicated trades. So, so regulations are, I'm for skin in
the game, not regulations. I'm for tort because you can't gain tort. You, you, you, you cause a
problem. You pay for it. Regulations usually allow, I had a fight with this guy. He's at Princeton.
He was last chair of the Fed. Trying to sell. No, no, no, no, another fellow. There's a fellow.
I was in Davos the only time. Sorry. I'm blind. I was in Davos. And, and the fellow say, Oh,
it's incredible. This, how can we protect ourselves? You know, the world I'm talking about.
An American citizen said, you make me go bust. How can I get cash? I'm in Switzerland,
stuff like that. Oh, no, I got protection. What is it? So, you know, FDIC insurance,
they insure you for, for, for per account, not per individual. So you give them $20 million
and then they open up, I don't know, 25 accounts, 50 accounts, something for you.
And then therefore I told them that this is unethical, you know, because basically
rich people can benefit. He said, no, we got a lot of former regulators in our staff.
Then I started the crusade against regulation because I realized that, that regulation allow
regulators to later on sell their services because they know the inside. I mean, some
regulations are necessary, but, but it's like speed limits. Some are necessary, but torts,
all right, are vastly more powerful because it can't be gained. And torts, and that's a left-wing
concept that started with Ralph Nader with, and so you're actually dedicated the book to Ralph
Nader. Torts are vastly more robust than regulations. So I think with AI could be, you can use a
torts system. You say you're responsible, but, but people to regulate, the basic is the regulations,
people calling for regulation with AI either don't understand anything or they are afraid of it
because it hurts their business. But, but think about it. If we slow down AI grows in this country
and the Chinese develop AI, what happens? We're going to have to learn Mandarin now as first
language because basically you're invaded, all right? So you have to realize that there is a,
you know, you can't really stop research on grounds that, that it hurts Elon Musk's business.
Okay. Oh, it's helping Elon Musk. Sorry. It's helping Elon Musk, but he's got,
he wanted, he wanted to regulate it first. He wanted to scare them. Maybe he woke up one day
thought it was bad for him. Right. But he also has one of the most robust AI networks going
with the self-driving cars and the neural net. Yeah, but this is, this is not working. Self-driving
is not working. They are probably, this is, this is where they are, they are some mathematical
thing that is, even if every individual car is self-driving, you see the, the problem is you
have to make them all, all cars on the road got to follow the same protocol. Right. You know,
when you see flocks of birds, they all follow the same protocol. Right. So, so you got it,
instead of doing it bottom up, you got to do it top down for the, for the cars. So this is why I
doubt that it's going to go very far, except for using some things, you know, you know,
temporarily, you know, you can't have a self-driving car as easily as you think. If, if all the cars
were self-driving, okay, you need to have one unified protocol. Right. And, and to get that,
I think maybe your great, great, great, great grandchildren may hear something similar of the
sort. So we have to get rid of human beings to have self-driving cars. Yes.
Wait for the mic. Thanks. First off, thanks so much for, for coming up to, to hand over.
One thing that you've spoken out against before is like reading newspapers. I'd love to hear you
expand a little bit on that. And, and I guess there's a follow-up like how you
suggest staying informed. Okay. So the, the problem that information is that the anecdote is very
salient. The what? The anecdote is very salient. Yeah. So when you read newspapers, you're focusing
on anecdotes and, and early on as it relies as a trader that all these people are talking about
things that don't connect to the importance of the events. You see, like all these analysis that
make no sense. All right. So the, the, so I realized also that the newspaper should be a
thousand page long on some days and one page long on other days, right? In accordance to
statistical significance of what happened, right? Yeah. The same length. So I stopped reading papers
when I became a trader and it's very easy because it freed up time to do other things. And other
people reading the papers or were out of business anyway. So, so that's the idea of the anecdote.
You see anecdotes, you don't see them in context. Okay. And the same thing with the news, but you
develop tricks to only read about large deviations. Large deviations are more, more explainable.
That's something, but the, the market, and they tell you, oh, the market went up 10 points
tiny based on conversations with this and this. And as I showed in the black swan, they said,
bond market up on September capture. And then this one, the afternoon went down,
bond market down on sundown capture. I mean, they look at, so pretty much wasting your time. And
I had this algorithm, if you only cure the newspapers, spend some time reading the previous
year's newspapers. And then you realize how silly it was to read that newspaper.
You know, so, so how much, how much time you wasted. And then you can free up your time to
read other stuff like articles in my professor, I'll be shy, for example. Even in New York,
I said, at that time, I said, don't read the, if you're going to read the newspaper, read the
weekly one. And now I think you should really just yearly newspaper. So the, but the news get to
you organically, if there's something going on, then you know to look for the news, you're not
supplies. Yes, sorry. Hi. So the first thing you said about AI is that you speak in the mic. Oh,
yeah. The first thing you said about AI is that you're not worried because we've had these sorts
of things for a long time, like the thermostat automatically adjusts. But it sort of reminds
me of Dr. Phil's anecdote of the swimming pool. And the thing which worries me about AI is the
possibility of recursive self improvement. And I think that this is a good example of an accelerating
tail event, where for a long time, things seem stable and normal. But once you pass a threshold,
where AI's can recursively self improve, things can get out of hand very quickly. And they are
something worth worrying about, even though, you know, we've had swimming pools for a long time.
We can worry about, we can, I mean, there are things to worry about, like recursive self improvement,
start learning from itself. And then the size, you know, you need to have a lot of things going
wrong for it to start learning from itself and then spontaneously and then
running the world. I think the reverse actually is happening with AI,
language model, that progressively it's actually the reverse is that this progressive self degradation.
And let me tell you how it happens, that you know, when you use chat GDP, it's calibrated to some
information up, say, 2021. And now you use it and you populate the web with information based
on what you got from chat GDP. And then guess what? Chat GDP is learning from itself. So it's more
likely. So the counter to that is I'm more worried about a self-licking lollipop. But basically,
it is recursive in the opposite direction, it's self degradation. So this is what I'd be worried
about was a lot of AI models. So you put that so much better than I did. Does that satisfy you?
I'm not sure. I mean, it's definitely a concern AI is training on their own data. But I think that
within these labs, like open AI, the thing that they understand the most is AI engineering. The
very first thing that they're testing these models trying to get them to do is to help them with their
work. So I do think that there is still a capacity for a recursive self-improvement data.
Yeah. So you'd have evolution. You'd have some system of self-improve at the expense of others
and stuff like that. But I mean, we have bigger problems ahead of time, namely a pandemic. We have
things, how to handle a pandemic like that. We have the fact that zero interest rates destroyed
financial knowledge for half a generation, 15 years, 16 years, generation of trainees and finance.
So we have some sort of lady has a question. Yeah, kids on TikTok too. Yes, go ahead.
I usually, you know, when you allocate, of course you have ladies, but then also if you're going to
take people who don't have hair.
Hi. Thanks for coming here to Dartmouth. During the Arab Spring, I kind of realized that that was
maybe the last time we could ever trust video footage from a scene where things were really
happening. And now it's really, really here. AI can create videos, not only pictures, but live
videos from a single photograph. I think it's going to make everybody a lot more skeptical,
which may be a good thing. But what do you think about that? Okay. So this is a great thing because
I wanted to discuss it today. And at lunch, I told you what I do. So the people have the
feeling that this information is something new that came from social media. Okay. But
you got to realize the French Revolution, you know, the story of the stories of Marie Antoinette,
they were a complete campaign with all fake news and they're produced in London and called
Libels. Well, actually the word libel, I think it's generated from that where people would be,
and they could cancel out of London because they had freedom in London.
And the harming the French was a good thing. Of course, so they were printed in London,
these pamphlets, and crossing, crossed on Fisherman's boats, right, and then supplying
all kinds of fake news. So we have a long history of fake news and how we handle fake news in the
past. And of course, there's a counter to fake news, which is the fact that I, for example,
like to bust stuff. And we have a mechanism to bust stuff. Even Twitter has it. It tells you
that this is not true. And during COVID, people are producing all kinds of fake statistical tricks
that it's easier to bust now than in the past. And you know the Protocol of Sages of Science,
that's the fake news, the producer at the time, that the Protocol of Sages of Science
was a pamphlet produced during the Tsarist era. Actually, the Russians were expert at it. They
had the produced en masse. They produced the Protocol of Sages of Science, say that the Jews
wanted to take over the world. Exactly the same language you hear now about sorrows and a bunch
of people, the World Economic Forum, trying to program you with vaccines so they can, you know,
own the world. Well, for us, fake news is the book of Luke, you know.
So anyway, so we have had fake news about historically. I mean, there's even fake news in
the Talmud, you know, about Jesus being the son of a Roman soldier called Pantera.
Oh, yes, yes, that's right. So Yahushua been Pantera. So there's a lot of fake news. So
historically, so thanks for your question. It's a great question. Can we trust stuff on a web?
And I think that we have an antidote we didn't have in the past.
You cannot believe how many people in Egypt believe in today in the Protocol of Sages of Science.
Whereas if you put the fake news on Twitter, you're going to have people countering it. And
these people develop authority naturally because they spent their time countering it.
I never expected that thanks to COVID, I reached millions of subscribers on Twitter.
And during COVID, the fellow called me up and said, Listen, I'm going to tell you one thing.
I don't like your style. I think you're arrogant and rude. Okay, but I'm going to tell you one thing.
The New York Times, they're boring for life, boring and so on. And people know
that the few attack the fake news, okay, will have more impact. I still, she said, I don't like your
style. I've confirmed, but I need you. So he likes my style visibly. So I play a role, for example,
against fake news. And I tell you, there's this nonsense that you need against PS, you need a
thousand times more effort to remove the SN to put it in. It's not true. I don't believe
the things correct themselves very quickly. Last question. Yes, sir.
How do you get more skin in the game for civil servants, politicians and CEOs?
Do you want to add to that?
Because there's no stock options or things like that. Okay, the first thing,
skin in the game, okay, for politicians, but first of all, you should have limited,
you should have decentralization. That's some of the problem, because if you give more municipal
power, people live in a community. So they may, they already have that more naturalistic skin in
the game. That's how Switzerland works. And then term limits. Okay, so term limits, definitely.
So nobody, you know, they, they also remove some wedge between people become professional
politicians versus normal human being. And so this is how, how it works. And also, I think
polarization, it's not popular to believe that polarization is good because I like politicians
to hate one another. Because then they cast, they can't become a cast that runs us by having
fake, like in Lebanon. In Lebanon, they, they, they love one another secretly. So they have,
so they became a cast, you know, and then they, they start like in Congress, they give themselves
perks, for example. But if they hate one another, they, you know, they, these things become more
difficult. That we're talking about, about the idea of collaboration doesn't work, as well as
competition and adversarial collaboration. So, so, so this is where, you know, I think polarization
is helping. But, but for politicians, the only thing to do is term limit. And then the second
question for educational universities, I think we have a problem with student debt. Okay. And,
and basically, you know, I'm in, I'm a professor, and, and I say openly, you know, in the institution
that there are a lot of real estate developers made a lot of money. Okay. So student debt should be
not be the responsibility of society, but those who made money from it. So institution, if you
make them accountable for student debt, after a while, somehow, then they would probably make,
there'd be a chain, the real culprits are, you know, the culprits are real estate developers.
Okay. That's, that's where the money, the large money went there. And the large money went on
a fat administration with multiplication of administrative positions, like someone responsible
for winter entertainment, one's responsible for improving your life. Like I get this email from
the well being program at NYU. What the hell do I need the well being program from NYU,
buy it from market. So, so you realize when there's money, they spend it. So, so we'll make it more
efficient because the cost of education, when you look at Germany, the cost of education is
something like one or the magnitude less proves the same than the United States. You want the
word of the difference. The difference is partly real estate, partly administration, not so much
faculty. By the way, if you're afraid of faculty liking each other, don't worry. Thank you, Nassim.
It's always such a pleasure to hear you, to think about what you think about. And
such a pleasure that you drove all the way up to Dartmouth. I mean, the leaves are great, but
still, I mean, I'm, I'm really very grateful. We're all very grateful that you came.
This is a great campus. And don't tell anybody it was a great retirement place.
I know, I know. Thank you.
So thanks.
