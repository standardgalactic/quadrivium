I'm about to say something that you would never expect to hear from more perfect union.
Elon Musk is right about something.
Elon Musk is suing the maker of chat, GPT,
suing open AI, suing open AI for breach of contract
by putting profit ahead of benefiting humanity.
Elon's lawsuit against open AI, the most recognizable developer of artificial intelligence,
was big news. But when I heard it, I was a bit confused.
When has Elon ever been against profit?
So I dug it. I read and I watched far too much of these guys talking about AI.
I think that AI will be a technological revolution on the scale of the agricultural,
the industrial, the computer revolution.
AI is about to revolutionize digital biology and genomics and transportation and retail.
Artificial intelligence, this is, it is a renaissance.
This is a world-changing set of advances.
By the time these lawsuits are decided, we'll have digital god, so digital god.
I noticed three things. That the rise of AI is inevitable.
That it will change everything about our lives.
And that there's a war brewing between a handful of billionaires to seize control of it.
Nvidia became one of the most valuable stocks of all time producing chips for AI.
Microsoft reached an over $3 trillion valuation based on its AI work.
And open AI tripled in value in just 10 months.
But where do we, you, and I, and everyone other than the dozen or so billionaires duking it out
for control fit in? We're already seeing plans to replace human nurses with AI.
Media magnates killing jobs to focus on cost cutting with AI.
AI written drivel filling the internet. And AI that does karaoke for you.
But let's look at the possible AI future through the rise of Sam Altman, CEO of OpenAI.
And just one contender in the billionaire battle for the future.
Sam Altman is the ruler of Silicon Valley startups. And that's not me saying that. He thinks that.
I think the president of YC is sort of the unofficial leader of the startup movement.
YC is Y Combinator, a significant venture capital firm and tech incubator that Altman
ran from 2014 to 2019. He'd originally connected with YC in 2008.
When the firm funded his app, Looped, when he was 19 years old and wore two popped collars.
Looped was a common Silicon Valley story. They raised a ton of money, gathered a bunch of data,
and got in trouble for texting everyone on your phone when you downloaded the app.
Altman sold the company and it all but disappeared.
Altman landed at Y Combinator where he rose to president in two years.
Under Altman's leadership, Y Combinator invested in massive companies most people have heard of,
like Reddit, Airbnb, Coinbase, Dropbox, Stripe, Twitch, DoorDash, and Instacart.
In a lecture to Stanford computer science students on startups,
Altman quoted Peter Thiel's advice.
As Peter Thiel is going to discuss in the fifth class, you want an idea that turns into a monopoly.
But you can't get a monopoly in a big market right away. You have to find a small market
in which you can get a monopoly and then quickly expand.
Quick expansion is an inherent part of the way venture capital funded tech runs today.
This is Tim O'Reilly. He's been in tech forever.
And if you know phrases like open source or WEM 2.0, it's because he popularized them.
One of the big problems with today's Silicon Valley is that it no longer really supports
remarket competition. Early days of VCD, you were really talking about funding
insurgent companies that had an experimental idea.
Most companies didn't actually raise massive amounts of capital.
But at some point that changed.
But then you fast forward to 2010 in the wake of the look super low interest rates is all this
cheap capital and companies are just buying market share. And I call this the Uber problem.
We didn't see real competition with different business models, different pricing.
We saw two heavily capitalized companies driving everybody else out of business.
By growing rapidly with a bunch of capital, Uber created an ecosystem where if you want
a cab, you need to use Uber. The old system of car services was pretty much pushed out of existence.
Uber is not an Altman company, but DoorDash, Airbnb and other companies that used similar
strategies totally are. In 2015, we get our first hint of open AI.
I actually just agreed to fund a company that is not even really a company,
sort of a semi company, semi nonprofit doing AI safety research.
Open AI is announced as not a company, but a nonprofit focused on AI safety,
funded and supported by Y Combinator, Elon Musk, Reed Hoffman, the LinkedIn guy,
Peter Thiel, Amazon and Infosys. Basically a who's who of the people who built
the broken tech infrastructure of today. The stated goal of open AI was to advance digital
intelligence in the way that is most likely to benefit humanity as a whole, with no shareholders
to be beholden to. We wanted to build this with humanity's best interest at heart.
That doesn't sound too bad, right? A groundbreaking new technology,
its power available to all without any responsibility to shareholders?
But let's dig a little deeper. They say they want to make the world
better and do it safely, but what does that mean to them? Most of what Altman talks about
in regards to what open AI's products can do seems to center on productivity, efficiency
and margin boosting. Our ability to have amazing ideas
for our children to like teach themselves more than ever before for people to be more productive.
How does that make life better for the rest of us? Well, Altman claims to have the answer.
In his essay, Moore's Law for Everything, he explains it would require simply changing the
entire economic system. Altman claims AI would drive down labor costs so everything would get
cheaper. And the lost jobs would be offset by a universal basic income coming from corporate
and property tax rates, with no other taxes. Which sounds great, maybe, but how true is that?
Would corporations see falling labor costs and reduced prices or just keep the profits for themselves?
Would a flat tax and UBI mean more money for working people or more tax cheating by the rich
and social service cuts for everyone else? And there's a running theme through all of what Altman
says, the inevitability and the danger of artificial intelligence. Listen to this clip.
You know, I think AI will probably like most likely sort of lead to the end of the world.
People like Altman benefit from the narrative that AI is this big scary thing,
even as they're the ones trying to build and profit from it. Here's Tim O'Reilly again.
It feels a little bit like a kind of misdirection. They're basically calling for a kind of regulation
of an extreme risk to avoid the regulation of the many proximate harms we can see today.
If they were really afraid of it, they would stop doing their research. Instead,
they're racing to accelerate it so they can get a monopoly. It's a lot like the famous
lion from the Wizard of Oz. It paid no attention to the man behind the curtain.
And a lot of what I spent my time in talking about AI regulation is this. There is a man behind
the curtain or a series of men who are making decisions for their business advantage. And
those are the things that we need to be regulating. Why are they moving fast to break things?
I mean, in the Altman clip from before where he says the world ending thing,
he literally says this right after. You know, I think AI will probably like most likely sort of
lead to the end of the world. But in the meantime, there will be great companies created with
serious machine learning companies. See, it's right back to profit. But hold on, isn't open AI
a nonprofit? Not anymore.
Just three years after the founding of open AI, they transitioned to something they're calling
mixed profit. To do what we needed to go do, we had tried and failed enough to raise the money as
a nonprofit. We didn't see a path forward there. So we needed some of the benefits of capitalism,
but not too much. And the new board of open AI is rife with the profiteers who've been extracting
value from working people for decades. They're also not open. None of this stuff is just simply
available. Sure, an old version of chat DBT is free and kind of fun sometimes. But open AI's real
product is enterprise software doing partnerships with other giant tech companies and loads of
stuff we don't even know about. Defense contracts included. Open AI has a product to sell a product
they see as having inevitable near universal proliferation, which is a pretty damn good business
plan. But it's dangerous for the rest of us. You know what Tim O'Reilly said about the Uber
problem. Here's how it applies to AI. All of the smaller AI firms are already starting to fold
because there are a couple in the form of open AI and Anthropic that are incredibly heavily funded
that have tens of billions of dollars of capital. And we don't know that they're the best companies.
We just know that they're the ones that big investors picked up early. And so we have a
defective kind of market where if you really believe in the wisdom of millions of people
making independent decisions based on optimal information to kind of do work this re-magic
market, we don't have that. We have a central committee of deep-pocketed investors. It all
illuminates Elon's lawsuit against open AI when he and Altman had once been such good friends.
I'm looking for a new video gameplay. Can you give me a recommendation?
Overwatch. After Overwatch. Yes, go else.
I named it open AI after open source. It is in fact closed source. It should be renamed
super closed source for maximum profit AI. But he has his own for sale for profit AI that he
wants to be predominant. He made it open source in a seemingly empty gesture. But
meanwhile, Nvidia, Microsoft, and Google all want to take control of the tech
that will change our future and destroy our jobs. It doesn't matter that these guys say
they're doing it for good. It matters what they are actually doing. Look at the DOM of the Internet
itself. Or web 2.0. That's social media and user generated content. All of that seemed great.
And yeah, the modern Internet has obviously had a lot of clear benefits. But it was also
pretty quickly ruined by giant corporations and profit motive. We're already starting to see
effects of the AI power grab. Nvidia, the main producer of the chips used for AI, is partnering
with a company that wants to replace nurses with an AI that costs $9 an hour. Look at anything from
the history of the American medicine industry. Will a new low cost tool actually help patients
or just pad investor pockets? Companies are using AI to do job interviews and it's shutting out
applicants unfairly. And on a simply annoying level, they're spitting out content that's making
the Internet even more unusable than it already was. AI generated LinkedIn comments? Why don't you
just not post anything if you don't have anything to say? So what are we going to do about this?
Well, let's turn to Sam Altman for advice. He has what he calls the more good guys than bad guys
approach. He wrote in that Moore's Law essay, There are bad humans, but all humans are within a
magnitude are as powerful as one another. And the good humans, and together to stop the bad humans.
It's been that way through all of history so far. What if the bad humans are actually the people
building the system? One built entirely on fast profits and monopoly, advancing as quickly as
possible. Then we need more good guys and we've got them. They're like 12 people. What if we all
stand up and say no? When electricity was first becoming widespread, it was still dangerous for
the low paid workers who were setting up the systems. But those workers stood together and formed
the International Brotherhood of Electrical Workers, that's the Electricians Union,
to demand safer jobs and better wages. It worked and it didn't hamper progress. We clearly have
electricity today, right? That same concept applies to AI too. Remember the writer's strike?
The screenwriter's guild stood up and said no to AI taking their jobs. Senator Bernie Sanders
just introduced legislation for a shorter work week. Do we continue the trend that technology
only benefits the people on top? Or do we demand that these transformational changes benefit working
people? And one of the benefits must be a lower work week. If AI is going to make workers more
productive and labor cheaper, workers should be able to take advantage of it. AI cannot exist
without being trained on all that humanity has done before. That's literally how chat GPT,
the way most people interact with AI, was built by reading a bunch of stuff online and then
synthesizing it so it can talk. If all of this is built on the labor of all of humanity, then
it should be all of humanity that benefits. Thank you so much for watching. If you want to
support more human-written, human-edited, human-shot videos like this, please don't forget to like and
subscribe.
