The main focus, I'll put links to the 2017 paper on the hard problem of consciousness,
but for the most part, that would be nice. Yeah. Yeah. I put a direct link to that in
the paper because I mean, in the video, because I think people should read this. It's very
long, very, very in depth. And I like that. I mean, that's when someone has a lot to say
about something so complicated. I think you can't really summarize it. It's something
that does require that level of detail. So to all those who are going to read this paper,
just bear that in mind. It probably takes repeat readings for most people to really
understand and grasp most of the concepts, but you do a great job at putting the imagery.
And I mean, it's a wonderful paper overall. Well, thank you. Two things come to mind.
One is that it's a long paper, but it compresses a huge amount of knowledge. So if you can
get through that, you've saved an enormous amount of time. And that's one thing that
my students always came to realize. It was a way that they could get an entree into so
much psychological, neurobiological knowledge and start organizing it for themselves. Whereas,
if all you did was you gave them 200 articles, which may be explained or an explanation often
in this one article of mine, they wouldn't know where to begin. And they wouldn't, they
would have to build up a model in their mind. And that's what I'm giving them. Not to say
it's the final model, but it's been validated, each of the models in multiple ways. And it
gives them a way to start organizing all this information. Because ultimately, the model,
as a thing in itself, isn't what we're interested in. We're interested in understanding what the
hell is going on. And if models help us to create stories about what's going on in those
stories, make sense and help us to clarify what we're learning, well, that's what they're for.
So I was going to say something else, but split my mind. I should write notes.
Now anyway, the huge chunk of this conversation will be about the heart problem of consciousness
in your paper on that topic. And I think the best place for us to start, I've got a list of
questions from from the general fans, audience listeners and viewers. And I'll just go through
those later on in the conversation. But at the beginning, I think let's start with,
what is the heart problem to you? And if you could tell me your philosophical history of the heart
problem and your perception of it, what would that story be? Well, I don't have my 2017 paper in
front of me, but it was David Chalmers who described what he considered the heart problem.
And my comment about it was the following.
Let's go back to the orbits of the planets. If we can predict the orbits of the planets
with great precision, we don't have to necessarily visit them. We don't have to touch
easily them. It's a description that's predictively effective. And so my comment at the beginning
of my magnum opus, and I think I made a very similar comment in my 2017 paper is,
let's say you have a neural network model, which describes identified brain cells and
identified regions of the brain interacting in a way that's validated by neurobiological data,
anatomical and physiological, in some cases, biochemical. And let's say the emergent properties
map quantitatively onto lots of behaviors that interest you, including parametric properties
of conscious experiences like seeing, hearing, feeling, knowing things. That's all equations
can do for you. And if you expect an equation to see color or to hear musical tone, that will
never happen. And it doesn't happen in mind brain science, but it doesn't happen in physics or
chemistry. And people have come to understand that if you get predictive insight based on
harmonious laws that make things seem clear, that's enough. To think you would get more,
which is implicit in the definition of the hard problem, is asking for something that equations
can never give you in any science and only look to sciences that are better developed to realize
you don't really need it to feel quite satisfied that you've understood something.
So that's my response. It's sufficient. Of course, it is a mystery. And as I point out, let's say
right down to the photons. And for example, Gail Carpenter and I, among other colleagues,
did very detailed models of the transduction of color signals in vertebrate cones.
And we were able to quantitatively simulate very hard data using designs that you could see had
been using many other parts of our brains. But the model doesn't see color. It just describes how we
see color. And there is that explanatory gap. And I, for one, don't see how equations can ever
bridge the gap, but we don't need equations to do it because we have our conscious minds.
So one of your quotes in the paper was, as in quantum theory,
there are measurement limitations in understanding our brains. We can no more personally ride an
electron than we can enter a neuron that is participating in a conscious experience.
That's pretty much along the lines of what you're trying to say.
Yeah, it is what I'm trying to say. And of course, there are superb
nurses now who do enter neurons. In fact, a colleague or a miller at MIT might put an array of
a hundred or more electrodes in three different parts of the brain and do experiments with the
way behaving monkeys to try to correlate what the monkeys are seeing and doing with the recordings.
And it's very insightful. And if you have a strong enough theory to explain what these patterns
mean for emergent properties to link brain to mind, to link brain to the perception of the action,
but that is extremely useful. But in itself, without a theory,
it's not satisfying enough. You need more. You know, where's the spice?
Yeah, so what are your thoughts on Thomas Nagels? What is it like that that specific component
of consciousness, what is it like? And the fact that we'll never really be able to say what it's
like to be a bad slow... Well, to the extent to which what it's like is that having an equation
that is the qualia, you can't do that. That's what I just said. But there are cases already,
many cases, where we've developed models, principled models that you can understand are using
principles that are parsimoniously used in many processes that can tell you a lot about
different percepts. And where the end, like what's the difference between vision and auditions, say?
Well, even though the circuits, even though the equations, I mean the local neuronal processes
and the modules, as I talked about last time, a certain number of conserved microcircuits that
are used for many things, may be shared in vision and auditions, if you look at how they're specialized
in order to be sensitive to environmental invariance of those signals in the world,
photons and phonons, and how they're organized by sound sources. Then you can begin to understand,
wow, this is really fascinating, because here is a universal computational substrate that can be
specialized to resonate with the invariance of different environmental experiences.
And that is the power of how evolution has crafted our brains in order to be able to do that.
And we know that there are a variety of species that are resonating on things that
we can't do, like consider honey bees or consider the vision of birds. Certain birds
from hundreds of feet in the air can detect the movement of a fish under the water and
dive straight down to it, but we can't do that. But that doesn't mean that their neurons, their
fundamental components are something totally unfamiliar. That's not true. And that's why,
for quite a while, people studied invertebrate circuitries like crayfish, swimmerettes, etc., etc.
And one of my colleagues many years ago, Al Silverstein out in California, I hope he's still
alive, a wonderful scientist. He had, I guess, studied the stomatogastric ganglion of, I think
it was the lobster, and he had characterized, on multiple levels of physiology, anatomy,
all the parts. And when it was all in said and done, he still didn't know how it worked.
And he said that. And that was because it's an emergent property of all those parts,
interacting in a highly nonlinear feedback manner. And I'll acknowledge that he did what you could do
with brilliant experiments. And then you need a level of description, notably a sufficiently
powerful model, that can show how those components interact to generate the emergent properties
that are the adaptive behavior of the stomatogastric ganglion, or whatever else
we're considering. So it's that speculative leap we talked about a little last time,
you know, how you discover that it's not, we don't have an algorithm for it. In fact,
my colleague Rudy Kalman, I don't know if you studied the Kalman filter, which is used in
many problems in prediction and engineering. And he was trying to characterize,
in a very rigorous way, linear controllers. But at least at the time, he said, when he got the
multi-linear controllers, he couldn't even do that. You know, the methods he had just weren't
powerful enough. So the miracle is that somehow the methods that I've been lucky enough to discover
have not hit that brick wall yet. And lots of other people use them in one form or another,
including in technology. And as I may have mentioned last time, one of the reasons why
Gail Carpenter and I, and a number of our PhD students and post-docs, were eager to
specialize our model discoveries into applications in engineering technology and AI
was to show they work in the real world. And, you know, one way you can show they work in a way
that people who don't really care at all about mind and brain is by doing a technological
application that they do care about and frankly can make a lot of money for them.
Yeah. Steve, the approach that the science of the brain and the approach of philosophy of mind
are very different. As a scientist fundamentally involved in this interface of mind and body,
what are your thoughts on philosophy as a whole regarding their approach to this topic or
philosophy's engagement in this field? Because definitions play a big role and there's often
arguments. I mean, within philosophy, even merely starting with the brain as the source of consciousness
seems to be problematic for many philosophers. You have philosophers who claim that consciousness
is fundamental to reality. You have others that claim that consciousness is a fundamental feature
of reality, so panpsychism, which integrated information theory is pretty much a form of
that. Are you able as a scientist to even have a conversation with those people with such
different views from your own? Well,
I always ask, what can you explain with your concepts? And by explain, I mean facts, data.
If you can't explain anything, then you're not even in the ballpark yet.
Now, one of the things that's fascinated me personally is, I don't know if you looked at
a later chapter in my book, it's about really simple evolutionary precursors of
brains. I talk about a universal developmental code and show how
mathematical laws and primitive circuits that are controlling the development of
non-neural single cell or multicellular organisms have many of the
features that the laws have that I might use to explain mammalian and human data.
You know, I talked about hydra's heads and slime old aggregation and stuff like that.
And to me, it wasn't an accident that I published an article in 1978
called Communication Memory and Development, where I described these things theoretically.
And in the same year, I published, you know, an early magnum opus called the theory of human memory,
colon and then more stuff about what was in it. In fact, together they were book length and I
originally planned to publish it as a book, but I was young and foolish. I didn't know what I was
doing. And so, Robert Rosen, Bob Rosen, who was a very sweet and, you know, significant
mathematical biologist, also was an editor of a book series called Progress in Theoretical
Biology and he was eager to publish the two articles as articles, but by putting it in
something called Progress in Theoretical Biology, it buried it from the viewpoint of marketing. So
that was one of many naive things I've done in my life that I could kick myself for, but
I'm just a naive guy, basically. And I welcome it because having a naive approach to stuff
really helps you to be creative. You don't come in with, you know, too many preconceived ideas.
There's a cost for it and so far the cost has been worth it. But I should have published a major
book in 78 on mind and brain. As it is, I wised up a little and by 82, I published a book that
brought together my articles, but, you know, and that I think a lot of people were influenced by.
It was called Studies of Mind and Brain. I think it's still in print in some form.
Anyway, so you have people like Edelman and Tanoni. I order information theories and
integrated information theory. At some point, this is quite a lengthy quote, so bear with me.
This is your words. I mean, they used the word information as a critical component of their
hypothesis. But what is information? The scientific concept of information in the
mathematical sense of information theory by Shannon requires that a set of states exist
whose information can be computed and that fixed probabilities exist for transitions between these
states. In contrast, the brain is a self-organizing system that continually creates new states
through development and learning and whose probability structure is continually changing
along with them. Without a theory that explains how these states arise and how their transition
probabilities may change through time in response to changing environmental statistics and internal
representations thereof, the classical concept of information is useless. You want to unpack that a
bit for us. Well, I think you just did. I mean, I'm not sure what else. I mean,
yeah, well, Jerry Edelman was a very brilliant man and a Nobel laureate. There are a lot of Jerry
Edelman stories I won't go into, but he was a faculty member at the Rockefeller University
when I was a graduate student there. And one of the more favorable descriptions of Jerry was
the Black Knight. And I won't go beyond that in this public forum, but he made very
many useful contributions. And then as many Nobel laureates decided, hey,
you know, the next great frontier is brain, I'm going to get my next Nobel laureate in brain. But
the problem was Jerry didn't know any data. You know, and I was lucky to grow up
daved in data, which is where I comfortably live. And you can't go very far if you don't know the
data. And to know me initially, although I haven't kept track of his work, he's a clever person,
try to give a scalar to discuss, you know, whether I don't remember the details in such a long time,
whether the system was complex enough to, you know,
I think, do consciousness or something. My remark was, hey, you can't do anything with a scalar,
you know, I mean, we have a brain after all for a reason. But to the extent to which
everyone's contribution is useful.
Hey, do it. I only view problems if work is useful, and it's not just hype,
of which we know today there's a huge amount of hype. And
if it's done in a solipsistic environment,
I always taught my students and it was a policy about apartment. Whenever we were studying models
to do it in a comparative setting, what are all the models out there? What are their strengths
and weaknesses? If we have models we favor, do they have weaknesses that are the models have
overcome? And if they have, how can our models be refined and further developed to also do that?
So that's a certain attitude. And if everyone's making their proposal in the context of a
comparative analysis, then hey, go for it, it's good. But if it's solipsistic and if it's aimed
at selling any idea in a, I'll push it to the limit here, a cult-like setting,
we know that's bad news. And to me, the worst part of it is students go into
courses with famous professors or any professor who they like as a teacher.
And they're going to try to absorb everything the teacher says
at the time of life when you can learn better than at any other time in your life,
if only to get a good grade. And it's really not proper, I would almost go so far to say it's not
ethical to give kids a misleading view of the world that they're about to have to live in.
If you know better, if you don't know something's out there, hey, you do the best you can, that's
all any of us can do. But if you know something's out there and you try to shield your kids from it
because, hey, your work isn't as good and you want your kids to do what you do so you can
publish more papers or whatever, that's unethical in my mind. That's the strongest I put it. Usually
I'd say it's just in a weak character, opportunism, marketing, those words are dead enough.
The last, so the last time we went very in-depth on an adaptive residence theory in most of your
work, obviously it's just scratching the surface of what is very complex. And as a scientist,
I mean, huge respect for your work and everybody seems to have a consensus regarding that. So
I've tried to frame this conversation slightly more philosophically so that people can get a deeper
understanding of the science behind the work and what its implications on the heart problem as a whole
are. And with that in mind, the understanding of other theories of consciousness are important
because with yours you can highlight flaws within theirs, just the same way you did with the information
aspect of this one. Along those lines of Nobel laureates doing that, you've got others like
Francis Crick, Penrose, very different types of theories of consciousness. You've got someone who
is approaching it from a pan-psychist perspective who's claiming that consciousness is that fundamental
feature. And then you've got someone like Penrose who claims that consciousness is almost quantum
in a sense and beyond what classical physics can interpret. And therefore the data in this case
would not be as easily applicable. What do you think about that? Sorry, that was a very long question.
Well, I don't want to sound like a broken record, but it's always, you know, what theories have the
broadest and most principled explanatory range and how many of their predictions have been
supported by subsequent data. And in terms of quantum brain, you know, there's an obvious sense in
which our brain's a quantum, hey, well, matter comes out of quantum mechanics or some kind of
quantum reality, even if quantum mechanics is not yet a complete theory as some people think and,
you know, string theory and all that. So obviously, you know, the structure of matter would embody
ourselves in a world that has a quantum substrate. But I take the kind of work I've done as an
existence proof. And there have been many times in my life when I've been dying to use some kind of
concepts to explain the kinds of phenomena that I'm really yearning to understand.
And the existence proof here is that if you look at all the things that I,
my colleagues have explained, which I think has the broadest and deepest,
interdisciplinary explanatory range, linking brain to mind of any existing theory,
I've never needed quantum theory, except, except for example, at the sensory level.
So, for example, I mentioned briefly Gil Carpenter and I did some work on
photoreceptor transduction and vertebrate cones. And what that means is photons come in,
photons to the quantum constituents of light, you know, the whole thing with Einstein and
Wake particle dualism and all those profound things. But photons come in. And the question is,
how does a photo detector, which is at the front end of registering that there's something
going on in the visual world, how does it generate a signal through the retina to the optic nerve?
And one of the things we realized is that the brain, our brains in many species,
I think we were doing turtle, I think with turtle photoreceptors because, oh gosh,
you know, it's been so long ago. Some really wonderful experimentalists that worked up
turtle phototransduction. And it was a parametric database, really challenging. And
there were some really bizarre, at the first lush properties of the data curves. And what we
showed is that if you had a temporal averaging of the photons, just so you're computing a photon
density, and you know, it would rise and then it would fall when a little event occurred,
we showed with simple ideas like that, you'd be quantitatively explaining all those data. So we
faced the problem that you have to
transduce from individual photons, which is on the quantum level, into a classical description
of neuronal dynamics. We needed some stuff you don't use everywhere. And that
is a simple version that goes way back in phylogeny. And I've talked about
with some of my graduate students, we looked at multiple species that have these precursors,
what ultimately, a discovery I may call spectral timing, which is
both in space and in time. Our brains face the problem of going from,
you know, you could respond to a single photon, but that's too short to register any
microscopic event. Or in space, you could have a cell that's selective to just a very little region,
but that's not going to influence your navigational behavior. So one of the things I
talked about in my book, I like to sort of say it in a cute way, how do little nerve cells
generate spatial and temporal representations that can influence adaptive behaviors. And
a key ingredient in that turns out are called grid cells and time cells. And one of the things I
loved about this modeling, much of which I did with Praveen Pilli, a brilliant
PhD student of mine who then worked with me in much more senior positions before he got,
I think, I think he's got quite an important job at Intel now.
They obeyed basically the same laws, and they're in two parallel streams
in the entorhinal to hippocampal cortex. And because of this
homology between the spatial and temporal laws, I love to say, you know, give me a break here,
space and time are one. And I called it neural relativity, because space and time are one.
But the parsimony of it was breathtaking. Now, you know, the evolutionary precursors of that,
someone else is going to have to look at, but I'm condensed. They'll love the answer,
you know, and it'll be well worth their time. But to be able to say space and time are one and to
show, you know, and we're talking about entorhinal cortex, I didn't know from entorhinal cortex when
I was young, it's an acquired taste, you get forced into it by conceptual questions that you then get
stuck on, you get hung up on until you've got to get an answer, not the final answer, there's no
final answer, but a computationally effective and experimentally remarkably successful pair of
models. They, Praveen and I didn't mainly the space part of it, but we were able to simulate
quantitatively very challenging parametric data about grid cell dynamics. And then the time stuff
I did with a series of other PhD students, Nestosh Mayak and John Merrill, among others.
So I had called it spectral timing because there's a spectrum of cells.
If you want to go from little nerve cells to temporal delays, you could bridge. So let's say,
to give a simple example, let's say I'm a human or a pigeon or a rat, or let's say that I have to wait
two or three seconds after a stimulus to make a response in order to get my reward,
and if I prematurely make the response I might get punished.
Not so different like a student in a classroom, you have to know when it's okay to raise your hand.
And so spectral timing, you have lots of nerve cells, each with its own local
firing delay because they all have different rates of firing. So one cell might fire a bump,
another cell might fire a bump, another cell might fire a bump, bump, bump. And if the stimulus
activates the whole spectrum, it turns out that each of those cells has an adaptive weight assigned
to it. And the correlation between the stimulus and when the action is trained to occur is going
to strengthen some cells in the spectrum better than others. So for example, you could train,
I'm not sure if I can show you this. Steve, do you mind bringing more to your left?
I'm going to jiggle. I didn't do it. Bringing more to your left, Steve, the other way. Yes.
Can you see? Oh, there they are. They're the curves. So you know, it's in an
time is plotted against activity. And for example, you can get spectral cells to fire
selectively at two distinct times. And if you notice the bump at the earlier time is narrower
than the bump at the later time, that is a signature of spectral timing. And you find it
in the cerebellum, you find it in the basal ganglia.
I'm blocking the several other parts of the brain, you find it and I can't
pull it all up fast enough. It is a conserved mechanism. And you also find evolutionary
precursors of it in very primitive organisms where it isn't even neural. It is a way of
doing a kind of blocks law, a trade off between time and energy. That's what's behind it.
But that kind of spectral time that I just showed you, you can record from in cerebellum
parallel fiber, pecensio cell synapses.
So Steve, I'm sorry, you finished that first? No, I was forgetting why I was telling you
this. What triggered this reply? It's fine. Maybe if I ask the next question, it'll come back to you.
On that note, you're talking about the fact that it's also not just in neural cells.
There's work being done by people like Michael Levin. He's at Tufts University,
where they started to show this blurry nature of what intelligence seems to be. Now,
fair enough, some people might argue that defining the word intelligence here plays a big role. But
in a nutshell, what he's trying to say is there's bio-electrical communication occurring
between cells that goes beyond what our hardwired DNA is producing to communicate between cells.
Because of that, they're able to actually do some incredible work at this lab. It's called Levin
Lab. I don't know if you want to check this out afterwards, but they're able to create...
I've interacted with Michael Levin at Tufts in the past, but you're not giving me a
good focus and a prime need to remember what we were interacting about. Because there was
something he was doing that I thought some of my work clarified, but I'm just talking about
intelligence. I can't remember. In essence, he's work starting to almost confirm panpsychism as a
theory of consciousness in the sense that panpsychism basically means that consciousness
is a fundamental feature of reality, not in the sense that consciousness is just everywhere.
A lot of people, technically, that is what they mean. But for the most part...
Let me interrupt you there just because that reminded me of why I was telling you a lot of this
stuff. The reason why I was telling you about some of these primitive and not even neural
mechanisms is because, for example, there are very primitive processes which have
properties of resonance, in fact, adaptive resonance. One of the ones that I talked about
in my communication memory and development paper way back in 78, and then I review it in
chapter 15 or 16, I forget, in my 17. And my magnum opus has to do with the process whereby a
blastula during when you have a single cell, very early embryo, becomes a gastrula.
You know, you start with a spherically symmetric set of cells after the first few stages of
mitosis, and then some of the cells get selectively active and they start
sending pseudopodia to the other side of the
blastula. And on the other side, certain cells develop adhesiveness,
and when some of those pseudopodia hit the adhesive cells, they stick. And then this
accumulates until enough of these. It's an autocatalytic interaction until enough of these
pseudopodes connect. Now, why is that going to do something? It's because the pseudopodes have
contractal properties. You know, if they go up and they don't hit, they might come down and go up.
If enough of them stick, it becomes like a primitive muscle,
and they contract, and then they pull the cells on the two sides together,
and that starts to create a gastrula. It's gastrulation. It's the next step
in cellular development. And in my communication memory and development paper, way, way back,
I began to realize that these morphogenetic processes already embodied primitive versions
of things like adaptive resonance, because when the connections occur,
the prediction is they get more and more tuned, which strengthens the sensation. And as I recall,
there were some later data that were at least partially consistent, but very hard experiment
to do directly. But my prediction would be it's a simple form of adaptive resonance
in an early stage of morphogenesis, multiple species. And there are a number of examples of these.
Remember, I talked about complementary computing, a kind of yin-yang fitting together. And that goes
in multiple parts of biology, too. And although I'm going to make a statement now that,
it's the rankest form of speculation that doesn't give you any predictive ability beyond what
wonderful scientists have already done, I think an example of that complementary computing is
the double helix, the DNA and RNA double helixes. It's a way of bringing complementary stuff together
and into a more complete representation of the information you need to do stuff.
I would love to see Barbara McClintock did wonderful work on dancing
genes. I don't think that was quite it. But trying to get at the dynamics of how
the double helix, which usually you see in a static form and some wonderful
chemical architecture, but it's very dynamic. It's always doing stuff.
So I think there's resonance and complementarity everywhere. And remember, last time I talked
about the fact that in many parts of my work there are principles of complementarity,
uncertainty and resonance. And we know, coming back to quantum theory, those are principles at
the core of quantum theory. That doesn't mean that we are operating on the quantum level.
It just means these are kind of universal principles of nature. And we, through evolutionary
adaptation over the eons, have been built embodying them in a form that could support
animal intelligence. So if you ask about anti-psychism and stuff, well, you're never going to get
into that system just like you're not going to write an electron. But hey, they're built on very
similar principles as we are. And I feel I've understood more by commenting about these three
general principles that are conserved over phylogeny and evolutionary time than just saying the word
pence, psychism, which I want to know exactly what are you talking about? Because it's a lovely
phrase and it's important to have a lovely phrase, but I need to know where's the beef here?
Where is the beef? Where is it? What's the beef? So just to define it a little bit,
Mike once wrote a paper with Daniel Dennett. I think this would be a nice way to reel it in.
It's called cognition all the way down. And the reason why I bring that paper up is because
at some point I was going to mention it, you do mention it in your paper. And Dennett doesn't
have a panpsychist view. So panpsychism is pretty much the, it pretty much means consciousness is
everywhere, not always in the very mystical sense that a lot of people seem to think of it. They're
pretty much trying to come across by saying that cognition or proto-cognition or even proto-consciousness
can be found within smaller layers of reality in terms of a human. So you can go down into like,
let's say tissues and cells and within those biological processes, you can find forms of
proto-consciousness. Well, I don't necessarily agree with it. Wait, let me, you really have
to be clear about what you mean by consciousness. Yes, I agree with that completely. I've already
given you examples with guest relation and with talking about complementarity and resonance
and uncertainty going all through the natural world that these things go all the way down.
Now, the question is, what's the definition of cognition that you're using here and what's the
definition of consciousness? There are these shared processes. As I remarked in our last discussion,
I'm happy to believe that every species that solves the stability plus disability dilemma
has some form of consciousness because, you know, my own work, I showed that to do that,
at least in everything I've seen in experiments and models, you need a combination
of learning expectation, attention, resonance, and synchrony. And when you have all those things,
if you're exposed to an external world that has stable enough events
for you to actually learn something with spatial and temporal stability, then
the process will also give you form of consciousness, either of recognition or of perception.
But that was a big if, too. You know, what is the stable world that
resonant events are interacting with? And is it what we would call consciousness or cognition?
So I think that until I hear their definitions and how they've used to explain something
interesting, I would be more comfortable just saying stuff like I said, giving examples of
shared mechanisms like adaptive resonance and
gastrulation and this complementarity all over the place. But cognizant all the way down, it's cute.
In your paper, you mentioned. But as I pointed out in my book, Dan, who is a very bright
leading philosopher of mind, also wrote things about neon color spreading that are just wrong.
And then he became sarcastic about all the fools who actually believe it's a phenomenon.
And it really sarcasm in science is that hominem and gratuitous. And he was especially embarrassing
when he was wrong. And at a meeting where I invited him to speak because I don't only invite people
who agree with. He said to the audience that he was wrong. But I'm not sure if after he left
the meeting, he still said he would just surround it by good psychosis and neuroscientists and
modelers and what exactly did he say? What exactly he well, I think part of my talk was,
I think, you know, it's so long ago explaining a lot of data about how we consciously see,
you know, brightness, perception, form, the end color spreading. You know,
general surface filling in the complementarity of perceptual boundaries and surfaces.
And he was one of two philosophers of mind I invited. Anyway, he just got up and started
his talk with that retraction. Because what, you know, if he had claimed it again, people would
say, but Steve just explained data about it. It exists. You can see it, you know, with your own
mind. So I don't know where he stands on it now. He's very bright and very creative.
But he went too far there and he was wrong. And what made what annoyed me was it's my
current understanding that he first heard about neon color spreading. When he came kindly,
I don't take it to granted, people come to my lecture, he came to a talk I gave on vision in
which one of the kinds of data I was explaining was neon color spreading data. And, you know,
as part of a more integrated view of a lot of visual processes, like neon color spreading is,
you know, the reason it got popular. Well, one reason it got popular is because we
pulled it out of anonymity, because I could see that it gave really good visible evidence
of our predicted laws of how boundaries and surfaces interact, because there were colors
where there shouldn't have been colors. And I actually
emphasized it. And then Ken Akiyama and Mike Paradiso and other people picked up on it
and started doing more experimental work on it. But it was lying, unnoticed, until the theory
clarified how remarkable the interactions were and gave compelling evidence of surface filling in,
which is precisely what Dan was saying doesn't exist.
Yes, that is something you hear. And it's not the only one, you know, Mike,
my very gifted colleague, Ben Jo Pina, has what he calls a watercolor effect, which is all about
surface filling in. And, you know, you could say this is due to the first competitive state doing
interacting with it. I mean, we can explain it, and you can see it.
Are there any philosophers of mine who's working familiar with who you feel does
represent your form of emergentism in a great way, or your view on consciousness in a similar way?
Well, people don't have to do what I do in any way. I'm blocking on his name. The other philosopher
of mine, who I invited to that meeting long ago, is a Canadian guy. And I forget his name.
It's, I shouldn't to get it, but I, you know, I'd have to prime my stuff, my mind's else for now.
And he gave a lovely talk. I really thought it was a useful, interesting talk.
Is it Paul Churchland?
No, it's not Paul. No, Paul also did serious work.
I'm not sure.
Anyway, but my advice to anyone who wants to talk scientifically about mind and brain is,
read the data, and then read the state of the modeling community,
because you don't want to make a fool of yourself.
No, okay, so with that in mind, so we've discussed the people who have...
Let me, let me make a remark about that. You know,
I forget who said it, but I'm a very distinguished guy who I very much admired.
And, and he gave a keynote lecture. And, and he said, you know,
everybody thinks they can have a theory about how our minds work, we have a mind.
But by extension, we also have electrons and photons and atomic nuclei.
Do we feel we're immediately physicists, you know?
I mean, it's people think introspective evidence will explain their mind, but
remember the main point of cognitive and penetrability is that you and I can see each
other, hear each other, have feelings about each other, learn from each other.
Because we have no cognitive penetrability, we don't know what's up here.
We don't know that even the brain is the seat of intelligence from our daily experience.
And as, you know, anyone who studied the history of neuroscience knows, people originally thought
that other organs were the seat of intelligence, the heart or the pancreas even.
You know, so, yeah.
So, so to you, I mean, fundamentally, the, that phenomenological first person
subject of quality, a qualitative feel is explainable via scientific theory.
I'm just, obviously, I'm just playing devil's advocate. I know what your view pretty much is,
but I want people to understand this as much as possible, that intentionality that people
that intentionality, the aboutness of, of reality for you, that's nothing
and special about this.
Well, again, you have to be very clear about how you use the word intentionality.
I mean, for example, an adaptive resonance theory, there are top-down expectations,
which were a form of intentionality.
There are predictions of what's going to happen next, which are a form of intentionality.
I'd have to know an example that would be different from that to realize that someone's
talking about something else.
So you're using the nice word.
Some words are better as chapter headings.
And then you write what you mean by the word in and of themselves.
They don't tell you, do you know what, what meaning of intentionality
is being expressed here?
Can you articulate it better?
I think I say something irrelevant.
What would be, I think maybe the best way for me to do that,
let me define it from the Stanford X-cycle video philosophy is to make it easier.
In philosophy, intentionality is the power of minds and mental states to be about,
to represent or to stand for things, properties and states of affairs.
Now, I know in your theory, obviously you address these,
but to a philosopher of mind, this is considered almost a very special property, a qualitative,
it's difficult for me to actually explain it, to be honest.
That's what all my work is about.
Yeah, I know that's the tip.
But that's what the work does.
But when you're talking about what it's about, there are multi-dimensional aspects of that
knowing, including the perceptual, the cognitive, the recollective,
the emotional, the action, the appetitive, so it's too vague.
The issue is explanatory power.
As people have written about time and again in physics, people were doing natural philosophy,
until they could explain stuff and then it was called physics.
I think that's true of philosophy of mind too.
I mean, I took philosophy courses in college and what they were good at was opposing questions,
articulating questions, but if you wanted the answers, you have to turn to science.
But also what I found is by getting to a deep principled understanding of something,
it helps me to articulate new questions that I couldn't have done just based on intuition alone.
Intuition is limited.
It is so important that because we can't consciously see, because we can't consciously feel and so on,
that helps us to know at least, well, what are we trying to explain?
I want to explain how I see, how I see color and brightness and texture and
shading and objects and motion and all this stuff.
So it gives us a whole series of chapter headings, but to actually explain it,
you have to think in a totally different way.
And finding that way I have found requires an immersion into large databases that probe the
different aspects of the properties that you're trying to explain.
You can't just, hey, hey, I bet it's like this and you were right.
The chances are as close to zero as you can imagine.
Hunches are good.
Don't get me wrong.
I mean, hunches help theorists think about, oh, I should have been thinking about that,
but the hunch you'll have after you know a lot will be very different from the hunch you have
when you know very little.
Steve, you mentioned you know Paul Churchland.
He was a very prominent...
No, I don't know Paul.
Okay, but you know off Paul.
I just knew, yeah, I knew that he did some good work, but I haven't looked at it for many years.
Okay, so there was Paul and Patricia Churchland and they were the theory known as
Eliminative Materialism and what that was was it was it's a very radical claim basically
ordinary common sense terms.
So common sense understandings of the mind.
They claim to be deeply incorrect.
They felt that folk psychological terms that we use.
So even saying things like learning or thought, etc.
Don't technically work in the physical world because when you take
materialism to be true, you have to realize that reality is just neurons firing.
It's actually got there is no secondary reality in psychology where we could say things like,
okay, that's thought, that's memory, that's conscious experiences because in reality,
that's just neurons firing.
That's just blood circulating, etc. etc.
So, yeah, well, what are you?
Well, well, well, first words like learning and thought are more chapter headings.
You know, they're not theories, they're not principles, they're chapter headings.
Then you've got to if you're going to continue using those words at all,
you've got to say what you mean.
So for example, I invented the phrase adaptive resonance in order to describe
a brain process for which there was a great deal of evidence that I could explain.
The word wasn't there before and I've done that.
We've talked about spectral timing.
I invented the word spectral timing.
We talked about neural relativity.
I invented the word neural relativity.
You know, I mean, all these words come out of an analysis of lots of data.
But, you know, again, we're just getting back to the problem of emergent properties.
It's not just neurons, it's neuronal interactions that generate emergent properties
that often cause actions that lead to feedback that create a cycle of perception, cognition,
emotion, action over and over and over as you evolve in the world.
And through that cycle, if there are statistically repeatable enough or stable enough
properties of that interaction, you will learn about them as appropriate to the circuits
that are resonating with those particular invariants.
And as I mentioned last time, you know, we talked briefly about cognitive emotional
interactions. To me, it was very satisfying that cognitive and emotional circuits share
many properties. But one thing they don't share is their inputs and their outputs.
Like with emotion, you have a lot of inter-receptive inputs of hunger, satiety,
pain, you know, whatever, belief, happiness.
And with cognition, usually, there's a perceptual front end,
envision, audition, you know, tactile that drives those. And then there's an interface
that resonates. So a lot of the circuitry can be shared but specialized in order to
be able to resonate with particular invariants of the environments that they are trying to
understand. That's a bad word, it's a loaded word. To the environments for which they have adapted.
Yeah, so emergent properties, emergent properties, emergent properties, which you
cannot understand without a sufficiently powerful and principled, computational,
mathematically rigorous theory. And there is that explanatory gap without theory.
And in your work, I mean, you refer to this as establishing a linking hypothesis.
Between brain and mind, yeah. Well, it's a familiar phrase, linking hypothesis.
Yeah, and I don't want us to go in circles, but if you don't have a way to generate the
emergent properties linking to behavior, then you really can't mechanistically explain behavior.
Okay, so I've got a lot of questions from fans and audience members in general, but
tell that some of them are going to take us in circles. Well, that's okay. You know,
I don't think it's bad to say the same thing more than once. I think I might have mentioned I
would sometimes give the same keynote at two different conferences, assuming that because
they were in different continents or whatever, a lot of the people hadn't heard it. And then I
see in the audience, some of the same people and they said, you know, it's good to hear more than
once. Oh, by the way, I forgot to mention, you know, there are, when it comes to my
2017 paper on the hard problem, I do have keynote lectures about that on my webpage,
my webpage, your relegation is sites, s-i-t-e-s dot b-u for Boston University,
dot e-d-u for education, slash Steve G, that's s-t-e-v-e-g,
sites dot b-u dot d-d-u slash Steve G. So for people who want to hear that lecture given,
I might have given that one in more than one form, I forget, and sometimes I will
have both of them put on my webpage. But there are a number of
keynotes that I try to make self-contained for interdisciplinary audiences. But, you know,
as we were joking before, self-contained depends on where you're coming from.
No, exactly. But they keep inviting me back. So I assume I couldn't have been that bad. I keep
getting invited back. So. Well, here as well, we'll help to solidify some of these concepts for
people, because I think it does require repeat reading, repeat watching, and repeat listening,
just to get all of these, well, in your way, see, feel, and experience this a lot more, resonate
with it a bit. Well, I would recommend, you know, a discussion such as ours, I think,
for me is successful if it motivates someone to want to learn more. And then I would recommend
someone go to one of the videos on my webpage or YouTube or wherever,
and listen to the lecture. Yes. And maybe listen more than once and stop it and repeat if
what is he talking about. And after you've done that, until you feel I know a little better,
then go to some of the articles. And some of the articles are heuristic, like my 2017 paper is in
a way, even though it breaks new ground in a way, it's a review paper, because a lot of the
foundational mathematical work is earlier, or I wouldn't have had the nerve to write that paper,
because I knew everything I was writing is supported by mathematical models and computer
simulations of challenging data. So, you know, there were levels from an S, you know, our chat to
videos of self-contained lectures to reading, hopefully non-technical review papers to
technical ones. But really, the best resource I can recommend is my magnum opus,
conscious mind, resonant brain, colon, how each brain makes a mind. Because there I work really
hard to write a self-contained and non-technical synthesis and overview of my work in many different
areas, as well as to bring together and try to clarify the meaning of the work of
really hundreds of other scientists. So, but as we might have mentioned last time, you know,
we are talking about this, and this is one of the hard things to understand in the world. So,
nothing that I would write about it, I hope, would be
trivial, but I hope it's, you could see, oh, he's writing clearly. I just have to stop and
think about what he just wrote. And one reason I have over 600 color figures is to help people to
visualize the concepts that the words are trying to express. Because until you can get a picture in
your mind, it's often hard to know what the hell someone's talking about. It's not only me, it's
anything. So, yeah. Steve, talk to me about one of the one of the other very leading theories of
consciousness, which is global neuronal workspace. What are your views on that theory of consciousness?
Well, I'm not going to give a professional review like you would for a journal article.
I'm blocking on who's, I know the very nice fellow who promotes it. What is his name?
Bernard Bos. Yeah, I know Bernie Bos. He's a very nice guy, and he's very dedicated and sincere.
Just check what his predictive and explanatory range is. That's all I could say.
I mean, it's not for me to try to give a review of Bernie's work. You should ask Bernie to review
his work. I think it's always intriguing to see where, I mean, you guys either align or disagree.
It's fascinating, particularly for the audience, to kind of get a grasp of where you guys diverge
or intersect. Well, I could discuss it. Bernie had an explanation of a certain fact,
and I thought it was correct. I'd say, yeah, I agree. But if I thought it was incorrect,
I'd say, well, I would explain it as well as that I can do, but to give some holistic way
and waving evaluation of Bernie's hard work. No, I won't play that game.
I don't think it's constructive. If people find value in reading Bernie's work, they should
read it. If there are still questions they'd like answered, and they can find some of those
questions given more complete answers in my work, they should read my book.
There is a section within the book where you do discuss it, and the fact that that theory sort of
does provide a little bit more information when you compare it to the other ones that we briefly
discussed. Oh, yeah, Bernie is more serious, I think. Okay. Okay, let's let you know.
I'd like to leave it at that. Was that one of the questions someone wanted to comment on?
I haven't gotten to those. Well, you better get to that, because it's an hour and a half in,
I can go up the two hours or so, but let's go. So one of my friends actually asked this question.
This question, this first question, one of my friends asked us, he wants to remain unnamed,
but he wants to know at what, so let me just read this.
At what point would Professor Grossberg delineate between zero conscious experience
and conscious experience? Are all conscious experiences considered to be resonant states
in that regard? Well, you know, later in my book, I talk about quite a few mental disorders.
And for example, without talking about parametric properties of behavioral symptoms
and the mechanisms that cause them and what has gone wrong there in altering consciousness, you
know, if you don't have a sufficiently sustained and energetic adaptive resonance
that is resonating with either external stimuli or internal memory representations,
it won't get to consciousness. You know, what I'm blocking on his name now. Oh, he did very nice work.
You know, I talk about it a little in my book where, you know, usually
the stimulation our senses get by the time we're consciously aware of it can be 150 to
300 milliseconds later. And that's partly because in addition to the
all the pre processing stages, you then have to activate resonating circuits that have to
resonate for a sufficiently sustained energetic interval before it becomes conscious.
So anything that prevents that will not become conscious. And there are many ways that can be
prevented. Yeah, your work, I mean, clearly, in your work, you also you address the fact that not
not all resonance states are conscious states, but conscious states are always resonance states.
Yes, not all resonance states are conscious. And I give example to that.
For example, I mentioned grid cells and play cells will enter Rhino hippocampal resonances,
which support the stable learning stable and coordinated learning of grid and play cell
receptive fields are not conscious. They are not linked to internal or external sources of
sensory experience. Not directly, you know, for example, grid cells are sensitive to
linear motions and rotational motions. But those sensors aren't designed to support qualia.
And so, you know, there's just no nothing like a conscious awareness there. There are inputs,
but the inputs are very low level. Now it's another matter entirely if you try to link the
spatial representations that are learned in grid and play cells with information like optic flow,
visual cues that are being synthesized when you navigate. So you use combinations of visual
and motor information to know where you are. And then if you suddenly in the dark,
you use path integration information, that's what the information about the linear and angular
movement is all about path integration or integrating how far these senses think you've
gone. That's your ground truth. And my PhD student, Bill Gnat and I developed a rather
comprehensive animat model of how, for example, how an animat would under visual guidance learn
to efficiently acquire a food reward, say that's in a maze, you know, how you would, first, you
would just be randomly exploring the maze, you know, that would be endogenous exploratory behavior.
And then how that, as you explore it, how that is transformed into an efficient goal oriented
series of actions to efficiently acquire the goal in some distal part of the maze.
And there we do combine the visual and the path integration information to help
learn how to solve that problem. I forget what we call the model, it was, oh, the sovereign model,
sovereign for self organizing visual expectation, you know, let me wait sovereign, maybe I can
sovereign. And I think that Bill thought of this when I thought, hey, that's not that
self organizing vision expectation resonance. And on and on, I can't even remember what the other
letters stand for, but it is an acronym that captures the essence of what the architecture's
doing. And I say architecture, because not just a model, it's a very, you know,
you know, sparse version of a full animat, it doesn't have higher cognition, but it has working
memory, you know, it can learn sequential actions, etc, etc. And there, you know, the
designer working memory, I don't think you talked much about that, but, you know, you can derive
all working memories from a couple of simple postulates, both having to do with stable learning.
It's not surprisingly, but this is stable learning of sequences. So even though in a working memory,
it would be like, you know, to have remember the following series of letters five to eight, eight,
nine, five, three. And, you know, you can repeat it back to me five to eight, eight, nine, five, three.
But if I distract you and say, hey, repeat it back to me, you can't, because it's in a short-term
temporary working memory buffer, you know, in computer science algorithms, you sometimes call it
a blackboard, but this is more than a blackboard, this is a suborganizing blackboard. And one of the
key issues here is how do you know which subsequence of all the sequences you've just experienced is
predicted in a given context? And, you know, the theory gives a solution to that problem.
You want me to... And what? Oh, sorry, you were, you, sorry, continue. Well, well, and, you know,
you can see immediately there are, there are issues. Let's say I have already learned the word
my, and I've learned the word self. And in particular, I've learned recognition categories
of my and self. But now for the first time in working memory, I represent myself a new word
with a new meaning. First problem, why doesn't adding self after my, undermine the previously
learned inputs to the my and self category? But the second problem is how do you learn a new category
for myself, given you have two perfectly good categories, my and self, that are already learned?
How do you overcome the salience of the known to self-organize a larger grouping that's unknown?
And of course, if you couldn't do this, you couldn't learn language or dance or
navigational sequential skills. Because we're talking here about short words, my and self.
The same problem arises with individual phonemes grouped into words. And so,
you know, my theory of working memories off is a computational solution to that, you know,
based on very simple principle. Remarkably, that also was first published in my human
memory paper in 78 when communication memory and development came out. It was a good year. And,
and one of the reasons I got into it was because it often fails.
You know, you might not know, but there was a, let me give you a simple example of it. I was
interested more in verbal learning from when I was a boy. But, but did you over here, George Mill is
the magical number seven plus or minus two? Well, George Miller was the person who introduced
the notion of a chunk. And he basically showed that most people, if you tell them a series of
numbers or letters or whatever, they can't repeat it right back to you without learning,
well, without actively trying to learn if the sequence is more than five to maybe nine, depending
on the person, units. But then what he showed about chunks is that, you know, you could do that
for much higher level chunks. You know, like, let's say you're controlling the movements of a
dance. And you know, each movement, you're, you know, professional ballet dancer. And you can do
all of the individual movements. And now, you know, George Ball and Shane is teaching the new dance.
Well, you have to be able to put that sequence of movements into working memory where each of the
items in working memory is a chunk of a familiar dance gesture. And so that he realized you could
have, you know, sequences of chunks, creating another chunk. And you could get higher and higher.
And that's how we learned so many of the higher order things, because we chunked all the lower
order stuff and automated it. So we don't have to pay focal attention to things that are already
chunked. They more or less can be done under very much less oversight. Anyway, so that's what this
theory is about. How you get this chunking, really, by solving the myself problem by,
in a stable way, it's sort of like the stability plasticity, the limit solve to sequence learning.
But that was too far afield, maybe. But it did get a new, it got a new information.
Yes, at least. And it was in, oh, I was talking about sovereign, you need that
to learn sequences of turns in sovereign. Yeah. Okay, so the next question is from YouTube.
It's by ecstasy. Different functional modalities have been proposed to explain the emergence
of quality from physical properties. Under the given art framework, how would residents,
even in principle, explain the perception of a qualitative state?
I'm not sure what a qualitative state is. I don't mean to be perverse. I mean, the first thing that
comes to my mind, of course, is that we have to ask ourselves what flavor of what we're talking about.
The category learning stuff, as I had briefly reviewed last time, is about feature category
resonances. But if you're talking about experiences from the external world, let's say a visual experience,
what you're often conscious of is a surface shroud resonance, which is a conscious seeing.
And if you synchronize surface shroud and feature category resonances, you know and see about the
object or event, and then the surface shroud resonance via posterior parietal cortex can
control actions, which we've learned in response to that combination of events.
But now I didn't understand the last two words there. I don't know what they mean.
Yeah, I think this is basically referring to qualia, that qualia like state.
Well, I just commented on that. You have surface shroud resonance. You have stream
shroud resonances. They're not the same as basic category learning. And when I hear and see
and know things about you, they're coordinated synchronizations of surface shroud, stream
shroud, feature category, and to the extent of which you're processing sequences, you know,
they're item list resonances responding to all this, because that's where you get understanding
of speech and language. So there are all these resonances that are being coordinated quite
wonderfully. And, you know, you have resonance and reset, resonance and reset. So as our visual
representations of a momentary visual experience is reset by your movement, to what have you,
and I have another frame, and so I have a sequence of these, you know, likewise we're
updating all our working memories, because the sequential information that's forming the context
of them is changing. One of my articles, you know, I try to bring together a lot of
a lot of these ways of thinking in an article that I think that I published it in 2019, 2020.
It's an article that starts, well, I think it's one of the latest, maybe it's
it's one of the latest chapters in my book. Let me do you have the chapter names in front of you
by chance? Let me let me try to search for it. It's important that I make this comment.
Okay, I'll go to my, okay. Let me see.
Oh, I have to turn off airplane mode. That was to stop me from getting bothered.
Airplane mode. Okay. I'll be there in a minute. I have no fear.
It's fine. I'm just going to ask other questions.
Okay, I think this is it. As a list of the chapter titles on the Oxford listing.
Oops, I hit the wrong thing. Damn. Okay.
Okay. Let me see. Okay. Okay. Yeah, yeah, yeah.
Yeah, it was chapter 14. How prefrontal cortex works.
Um, colon cognitive working memory planning in emotion can jointly achieve valued goals.
And um,
Yeah. Sorry, Steve, my, my copy of the book isn't in this office.
No, it's fine. I'm looking at it, but, but um, yeah, and I'm, it's not, I have the abstract and the
keywords here. But it's, let me get the book one second. I'll get it. I have a copy in the next
room. Anyway, for people who haven't seen the cover, this is the cover and the background around
the brain is neon color spreading. If you look carefully at it, you'll see the red or the blue
spreading out of their crosses. Because I thought of that, you know, as such an important example of
the complementarity of boundaries and surfaces.
And let me go here. Okay.
Except for that aspect.
What is that?
The artwork. Well, what, how did you come up with that? That is the idea for the artwork.
Oh, well, um, I wanted to cover that.
So I said what the book is about. So, you know, the title is on a brain and, um,
uh, the brain is into Hemifield and I fiddled with trying to indicate the complementarity of
the Hemifields cause the water and wet streams and stuff like that. Other parts of the brain
are complemented, made it too complicated. But so that said, it's just brain, but neon color
spreading, the spreading is an emergent property that happens in our mind. It's a property of our
conscious visual awareness. And I thought it would be nice to emphasize on the cover.
It's about emergent properties. And I'm trying, I thought I, oh yes. Yeah, yeah.
Um, I, Betsy Murray stimulated me to write, to make some of these discoveries cause Betsy told
me that they had all this wonderful data in prefrontal cortex that no one could explain.
And so she sent me the paper and I realized that not only could I explain it, but I predicted
some of it and, you know, and they have, you know, words like desirability and availability
stuff like that, which are good words for the phenomena they were talking about. But, you know,
a macro circuit in complete one of, of the predicted adaptive resonance theory I needed for
this. I don't know if you could see that, but I couldn't put in the basal gaggle or a number of
other things. And those different colors, the red, green, what have you, are systems. And so it
just showed that like for prefrontal cortex, I needed and, and explained data from seven
interacting parts of the prefrontal cortex. It's not a unitary thing. It's a complex organ. And,
and then I also, in red, I had some of the main reinforcement learning kind of things that,
and then I'm just black and white. I had some of the main vision and spatial
kind of things. Anyway,
Roy, you want me to move? I think the point, I would, the point was I was trying to clarify
that, you know, the prefrontal cortical work really is a synthesis of a lot of work.
And I think, I think that
things really came together in a nice way.
You know, with a number of points in my book, I point out, you shouldn't take for granted
that the next step could be taken. And this happened to me over and over again, how the previous work
sort of thrust me into a new area where I knew they were interacting with. And the same things with
the prefrontal cortical work, so many parts of the brain are interacting there to explain really
challenging quantitative data, physiological data mostly. But, you know, it's all an accumulation
of evidence. And if you're a really good theorist, you can weigh the amount of evidence for this
part or that part or the other part. You know where the weaknesses are, where you might have
variations on a theme that don't undermine any of the principles as you would expect
for species specific variations of the design. And you also know what you can't explain.
And, and that keeps you up night until you can. So this is not, this is not finished. But I think
if someone wanted to get into an overview of some of my work after this discussion, and maybe looking
at a lecture of mine on my web, you might look at my magnum opens, and I want to emphasize one thing.
It's a long book. After you read the preface and introductory chapter one, I wrote it so that you
could jump directly to any chapter that's topic interested. You don't have to read at all. I don't
expect even interested people have the time or interest to read at all. The chapters are written
independently of each other. And so, you know, if you wanted to read more about art in the
sense of future category resonance, jump to chapter five. But if you wanted to read about
prefrontal cortex, you'd go to chapter 13. If you wanted to know about spatial navigation,
I think it was chapter 16. Yes. If you wanted to know about visual perception,
go to the first few chapters, and so on. Yeah, I really enjoyed that aspect. I said this the last
time. It's that easily accessible nature of the book, the way you can just jump from chapter to
chapter without having a preconceived idea of the previous chapter makes it very accessible.
Steve, one last question, and this one's from Facebook.
This is a funny one. Francina, who resonates most in the Grossberg-Karperter household?
Whoa, now this is getting very personal. Who resonates most with why?
I have no idea. That's just the question. That's where the question ends.
Well, all I could say is that Gail Carpenter is the love of my life. We've been together for a
half century. She has strict instructions that she can't pre-desease me, because she's younger
than I am. We already spoke on the phone earlier today. I'm in Truro on Cape Cod, and she's back
in Newton, where we have our main residence. I'll be talking to at least two, three more times today.
She's a brilliant neural network modeler. She's done foundational work, as well as really doing
some of the best work on large-scale applications, like she did really important work on remote sensing
on medical database prediction. One of the things she did that I think
should be studied more, and I think she'd agree,
is in a remote sensing context, where you can have multiple observers. They're each looking at
different pieces of a remotely sensed terrain, maybe with different combinations of sensors.
They will create their own personal labels for what they're trying to describe.
One person might say water. One person might say pond. Another person might say lake for the very
same object, and they only do this for a subset, usually a pretty small subset, of the remotely
sensed terrain, because it's expensive to get ground through. Someone has to be running around
down there. How do you input this kind of information, which may be
incomplete, probabilistic, sometimes self-contradictory, and out of it,
automatically learn a cognitive hierarchy of rules, including the confidence you have
of the links in the hierarchy, whereas you get higher and higher and higher in the rules,
they get more and more abstract. I think that is a foundational contribution, a really quite
wonderful one. That needs a lot more work. Gail and I are both no longer teaching, we're both
emeritus, and it doesn't mean we're brain dead. I just published my last paper, I think a few
weeks ago, and I'm writing another book, but Gail is not going to work on that project again,
and that project could really be very interesting, especially if you're in some kind of a technology
AI lab. That's the kind of project that Google could really sink its teeth into,
because you could do it for the whole world. Part of it, we got into it because
many years ago, I gave a lecture at the Optical Society meeting about some of the vision modeling
work, and there were several program managers from MIT, Lincoln lab there, which is one of the
great sensor houses in the world. They have laid on multispectral IOS and tetic aperture radar and
so on, and very much pixelated data with very intense pixels and dropout pixels and
a lot of noise, and they realized that the kind of work even then that we were doing in vision
modeling could help them process their sensor data. In fact, there was a very active project at
Lincoln lab for a while doing that. They also designed a robot based on some of our ideas
and sensor remote control course, some of the models I developed with my students and platform
independent, they work with wheels or legs or what have you. Yeah, so what more should I say
about my wife? My best friend, the love in my life, the mother of a wonderful daughter, and we
have wonderful grandchildren. We feel super lucky, super lucky. I love the way your face lights up
when you talk about us, Steve. Sorry for the personal question, but I thought it's quite cool
that you bought such great pioneers in this field, and I thought it would be a nice question to ask
from Mo while it wasn't mine, but I chose it. Well, to sum it up, we've been a real mom and
pop show where I have many projects without Gail, she many without me, and we've done, I think at
least 20 projects together, and you know, they're sort of like our scientific children.
Well, I think it's absolutely beautiful, and keep up the great work. Steve, thank you again for
joining me. So I really appreciate your round two. And you've also written a paper on illusions
enough that I find very fascinating. And I hope at some point we can also dissect one of those.
And with that one, it will be far less philosophical and a lot more scientific. So
I think you'll enjoy it a lot more as well. Yeah, well, I love studying, especially visual illusions,
of course. You know, it's sort of like how very young people can get
excited by mathematics, some of the hardest problems in number theory, you can say to any child,
and then it takes firm math to solve it. But visual illusions, it's right there,
it's in your face. And immediacy raises questions of how do you see anything?
Well, thanks, Ted, for having me on. So this would be part, this would be part two of this series.
Yes, definitely. Thanks so much. I enjoyed this.
Thank you so much, Steve. I appreciate it.
