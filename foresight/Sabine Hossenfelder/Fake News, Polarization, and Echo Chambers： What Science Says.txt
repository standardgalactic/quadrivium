What should you do if you're spending too much time on social media, asking for a friend?
Well, you try to convince yourself that social media is actually good for, well,
something. It's gotta be good for something, right? But they say that social media increases
polarization and gets you stuck in echo chambers full of fake news and so on.
How bad is social media? That's what we'll talk about today.
Social media has changed society profoundly. About 60% of the world's population now uses
social media. It has made it vastly easier to find people all over the globe to connect with them
and to get insulted by them. What does that do to society? It's complicated. American social
psychologists Jonathan Haidt and sociologist Chris Bayer have compiled a public Google doc
in which they collect references on questions such as, does social media make people angrier?
And does social media create political echo chambers? The most relevant thing you learn
from this document is that whatever your opinion, you can find a paper that supports it.
Honestly, I began working on this video thinking it'll end up being one big shrug,
because that's how sociology generally looks like to a physicist. But it turns out it isn't
quite as bad. You just have to be really careful with phrasing the question. For example, you may
remember the headlines claiming that fake news spreads faster than the truth. Then again,
there were headlines saying that those headlines about fake news were themselves fake news.
What is going on? Well, the original headlines were based on a 2018
paper published in Science by researchers at MIT. The authors compared how true and false
news stories spread on Twitter. They had a sample of about 126,000 news items from 2006 to 2017,
tweeted by about 3 million people over 4.5 million times. So not a small study.
These news items were classified as true or false according to certain fact-tracking
organizations. The conclusion of the study was, in the authors' own words, that
falsehood diffused significantly farther, faster, deeper and more broadly than the truth
in all categories. The facts were most pronounced for false political news. And it wasn't a small
difference. They found that it took two stories approximately six times as long as false stories
to reach 1,500 people. But in 2021, other researchers pointed out that the 2018 paper
looked at news that had been fact-checked by certain organizations, but that those organizations pay
more attention to news that have already spread quite successfully. An article in Science then
claimed that this means the original study had been debunked. This is why you've seen the
headline saying news about fake news is fake news. That wasn't the end of the story. Because the
authors of the original study then said they'd never claimed their study applies to all fake news,
it had just been misreported. And the authors of the new study said they had never claimed the
earlier study was wrong because they knew it had been misreported. Then the author of the Science
News article who had claimed that the misreported fake news study was fake news
apologized that his article had misreported this story. I hope that clarifies it. But wait,
what does all of that mean now? Do fake news spread better or do they not? The answer is they do,
but it turns out that the major difference between true news and fake news is that fake news spread
to a larger audience. And since they appeal to a larger audience, they also spread faster.
But if you compare true and false stories that have reached an audience of the same size,
then the sharing pattern looks the same. This was the point of the 2021 paper. It's not like fake
news networks have a different connectivity. The size of the audience that they attract is the
major difference. And yes, that was strictly speaking only demonstrated for fake news stories
that were fact-checked by certain organizations. One of the authors made this diagram to show
the difference between what they said they did and what the headlines said they did. But the
authors also say they're reasonably confident their finding will carry over to false news more
generally, but that remains to be seen. I'm guessing there are people working on this as we speak.
But the 2018 science paper made an interesting point that didn't spread widely. They found
that bots accelerated the spread of true and false news equally. This means that if false news
spreads better than the truth, that's because humans are more likely to spread false news.
We can't blame it on the bots. The authors conjecture that the reason may be that people
like novelty and it's easier to be original with something that's made up.
Anecdotal evidence. I had my first encounter with fake news on Facebook in 2016 when Trump
ran for president. It was a quote attributed to Trump from some anti-Republican Facebook page
shared by an American friend. Several people pointed out that there was no evidence Trump
actually said that. The guy who shared it reacted by saying it's funny even if it isn't true.
And that's why false news spreads. We share it for reasons other than accuracy,
because it's funny or upsetting or because it allows us to express our own opinion.
Whether it's true doesn't really matter for that. The problem is that the next person who
comes across shared fake news believes that the person who shared it believed it to be true
and is therefore more likely to also believe it to be true. What can be done about it?
It's easier than you think. Because most people agree that fake news is bad and they're actually
quite good at spotting it. You just have to occasionally remind them to think before sharing.
At least this was the conclusion of a paper published in Nature last year.
The authors recruited about a thousand Americans and presented them with 36 actual news stories
taken from social media. Half of the headlines were false and half were correct.
Half favorable to Democrats and the other half favorable to Republicans.
The participants were then asked to evaluate the accuracy of the news items.
They quite reliably rated correct headlines as correct and false ones as false.
And while they did rate headlines in favor of their own political orientation as correct more often
than those in favor of the other camp, the partisan influence was much smaller than that of the
actual accuracy of the headline. So the problem is not that we're just bad at spotting bad news.
But the authors also found that whether the headlines were right or wrong had little effect
on whether people intended to share a news item. They then encouraged people to consider the accuracy
of the news item and afterwards asked again how likely they'd share it. This simple tactic led
to a big reduction of the intention to share false news but didn't affect the intention to share real
news. According to the paper, accuracy often has little effect on sharing because the social
media context focuses users' attention on other factors such as the desire to attract and please
followers and friends or to signal one's group membership. According to another paper that just
appeared two months ago, the misinformation problem is particularly pronounced in the United States.
The authors of the paper found that while people from the UK, Canada, Australia and New Zealand
are exposed to misinformation on social media at about the same rate, Americans are three times
more likely to share it. Earlier this year a review paper in the journal Nature Medicine
looked at the spread of misinformation about public health in particular by reviewing one
and a 23 papers. The two major conclusions that the author draws from his literature survey is that
A. people are sometimes duped by misinformation just because they are distracted or not paying
attention and B. some people believe in and share misinformation because it reinforces their beliefs.
So that's consistent with what the other papers had found. As to what to do about it,
one thing he suggests is also just reminding people to think about accuracy before sharing.
Another interesting suggestion he has is to give people information about the tactics of
misinformation spreaders with browser games. There are two of those games, one is called
Go Viral and the other one Get Bad News. Studies have found that people who played these games
were much better at spotting health-related misinformation. You can try them out yourself,
links are in the info below. I think this is a really good idea and I'd like to have a game
like this about physics please. So yes, social media spreads a lot of misinformation. The good
side of social media is that it also seems to generally benefit information literacy. In 2018,
a team of American researchers recruited almost 3,000 Americans. They offered half of them $20
to deactivate their Facebook accounts for four weeks just prior to the 2018 midterm elections.
Four weeks later, those who disconnected from Facebook were less able to correctly answer
factual questions about recent news events. But they also reported increased well-being
and less political polarization. Let's therefore look at what we know about polarization and
echo chambers. If you watched a few of my videos on quantum mechanics, soon all your recommended
videos will be about quantum mechanics. Suddenly, the whole world is quantum mechanics. Such an
echo chamber seems to be an inevitable side effect of algorithms that want to help you find what
you're interested in. And as a result, you get more of the same. This leads to the dreaded
conspiracy rabbit holes that you fall into on YouTube as it happened to me when I was working
on my video on flat earthers, though YouTube seems to have tweaked their algorithm since to prevent
that from happening quite as easily. These more of the same algorithms help you make contact with
people who think like yourself. So the idea that we live in echo chambers sounds plausible.
But plausible ideas are the ones you should be most skeptical about. What does the data say?
According to a 2021 paper by a group from the University of Oxford, echo chamber issues are
real, but the problem has been hugely overstated. They looked at surveys from seven different
countries in which people reported what news they typically consumed. Turns out, only about
five percent of social media users are properly stuck in a political echo chamber in which they
almost exclusively consume news from one political side. Though the numbers differ somewhat by country,
the overall largest fraction of people in echo chambers is that of the American left.
The previously mentioned Chris Bale is lead author of a 2018 paper about an experiment
in which they try to get people out of their echo chambers. They surveyed about 1,500 Americans,
about half Democrats and the other half Republicans, who visited Twitter at least three times each
week. After one week of tracking, a randomly selected group of those people was offered
$11 to follow a Twitter bot for one month, but they were not informed about the purpose of the study.
The bot initially just tweeted landscape pictures, but then began tweeting opinions
that promoted the participants' opposing political ideology. At the end of the month,
the participants were surveyed again. Turned out that Republicans who followed a liberal Twitter bot
became even more conservative. The more they were exposed, the larger the effect. For Democrats,
the change was not statistically significant. By the way, Chris Bale is the director of an
institute called the Polarization Lab that lets you check how deeply stuck in an echo chamber
you are on Twitter. Turns out, rather unsurprisingly, I'm deeply stuck in a liberal camp. That's what
you get when you mostly follow people with PhDs. The question whether social media increases
polarization in society has been extensively studied, especially in the United States.
The risk, sociologists say, is that social media makes it easier to find people whose
opinions we like and we get encouraged by like-minded people to distance ourselves from the perceived
enemy. Indeed, in 2018, a leaked internal presentation at Facebook warned senior executives
that Facebook algorithms exploit the human brain's attraction to divisiveness and that,
if left unchecked, the algorithm would feed users more and more divisive content
in an effort to gain user attention and increase time on the platform.
Now, it's quite well established among sociologists already that increased levels
of polarization in society are associated with an erosion of constructive political debate,
social trust and inter-party cooperation. The question we're interested in here is whether
social media increases this polarization. In 2021, researchers from the UK and the US
set out to answer the question whether out-group animosity drives engagement on social media.
They analyzed almost 3 million Twitter posts by news media accounts and US congressional members.
They found that posts about the political out-group were shared or retweeted about twice as often
as posts about the in-group. And almost all of the posts about the other political camp were
negative, leading to more negative engagement. Again, though, you have to be really careful
to keep in mind what question a study was asking in the first place, because this finding doesn't
necessarily mean that the negative engagement cost polarization to increase. It might just mean
that social media is a good platform to live out your feelings. Just which way the causation goes
is at the moment rather unclear. For one thing, a study from 2017 found that self-reported
polarization is higher among elderly Americans who are less likely to be online to begin with.
Another thing to keep in mind is that the USA isn't the only country in the world.
A team of American researchers pointed out last year that while social media usage has increased
worldwide, polarization has not. It has increased in the US, but in many other countries,
polarization has in fact decreased. Indeed, a 2021 study among more than 3,000 Dutch citizens
found that self-reported polarization correlates with social media use, but the causation goes from
polarization to social media use and it depends on the platform you're using. At least in the
Dutch sample, people who became politically more polarized spent more time on Facebook,
but less time on Twitter. It's hard to interpret what this means, because God knows what's up
with Dutch Twitter. But I think what we can take away from this is that the idea that more social
media use increases polarization is almost certainly too simple to be correct. What happens
depends both on cultural context and on platform design. So what do we learn from all this?
Most obviously, we learn that this is a very active research area. I certainly hope that the
results will eventually lead to better algorithms for social media. While we wait for that to happen,
I think the best we can do is focus on the part that's in our hands, which is to decide what we
pay attention to and what we share. What I have taken away from all those papers is that we have
to be especially careful with headlines that upset us. Yes, they might get a lot of comments,
but they might also spread misinformation and hate. So be careful out there.
How has Sabina talking about nuclear power one day and about social media the other day?
Is she omniscient? I'm afraid the answer is no. I work with several other people who help me
sort through the scientific literature to bring the information to you. And the only reason this
works is thanks to our sponsors. Today's episode was made possible by MelScience,
which is a subscription service for science experiments. And I have to say, my family's
having a lot of fun with their products. MelScience has experiments for children in
different age categories and different scientific disciplines. And not only this,
their experiments come together with AR in VR lessons and live online classes.
The experiment I got this week is a gyroscope labelled for children aged five and up. It's
a great opportunity to talk about color perception and the preservation of angular momentum and the
solar system and why we always see the same side of the moon and why the length of the day depends
on which way the wind blows. And well, I guess I got a little carried away there. I found the
MelScience experiment extremely well designed and also high quality products. This is not
cheap stuff that breaks when you touch it. It works like you expect it to work. And of course,
we do have a special offer for viewers of this channel. You can get 50% off the first month
for any MelScience subscription if you use our link in the info below or scan the QR code. So
go check it out. Thanks for watching. See you next week.
