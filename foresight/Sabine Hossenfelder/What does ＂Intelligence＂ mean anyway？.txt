artificial intelligence. It seems like lately everyone talks about it everywhere all at once.
But is artificial intelligence really intelligent? What do we even mean by intelligent? And if it's
not yet intelligent, how would we find out if it were to become intelligent? That's what we'll talk
about today. Paul Graham, computer scientist, writer and investor, recently wrote that what
worries him about artificial intelligence is that few things are harder to predict than the
ways in which someone much smarter than you might outsmart you. Sabina Hossenfelder, theoretical
physicist, writer and involuntary comedian knows from personal experience that you don't have to
be smart to appear smart and that worries her much more. When it comes to AI, the question of
consciousness receives all the attention, but intelligence is much more difficult to define.
For example, few of my colleagues would doubt I'm conscious, but opinions on my intelligence
diverge. While there's no agreed upon definition for intelligence, there are two
ingredients that I believe most of us would agree are aspects of intelligence. First,
there's the ability to solve a large variety of problems, especially new ones. This requires
knowledge transfer, creativity and the ability to learn from mistakes. Second, there's the ability
to think abstractly, to understand concepts and their relations and deduce new properties.
This relies heavily on the use of logic and reasoning. The relation between knowledge
and intelligence is especially difficult to untangle. This is well illustrated by a 1980
thought experiment from the philosopher John Searle, known as the Chinese Room.
Searle asks us to imagine we're in a room with a book that contains instructions for responding to
Chinese text. From outside the room, people send in pieces of paper with Chinese characters,
because that's totally a thing people do. We use our book to figure out how to respond to these
messages and return an answer. The person outside might get away thinking there's someone in the
room who understands Chinese, even though that isn't so. Searle used this thought experiment
to argue that a piece of software doesn't really understand what it's doing. I explained in my
earlier video why that's a bad analogy for artificial intelligence, but why the Chinese
Room doesn't tell us much about understanding, it illustrates nicely the difference between
knowledge and intelligence. In the Chinese Room, we and our instruction book undoubtedly have
knowledge, but we're not intelligent. We can't solve any new problems, we can't transfer knowledge,
we have no capacity for abstract thought or logical reasoning, we're just following instructions.
But as long as the person outside is just asking for knowledge, they won't be able to tell whether
we're intelligent. Okay, so we have a vague intuitive idea for what it means to be intelligent,
but can we make this more precise? If you can't measure it, does it even exist?
Trying to measure intelligence is not a new idea. The first attempt has been attributed to Sir
Francis Galton, a British polymath and cousin of Charles Darwin. But Galton's work on intelligence
focused on sensory and perceptual tasks. He developed tests for skills such as reaction
time and visual acuity. A good start, I guess, but it conflates cognitive with physical abilities.
The next step was taken by Charles Spearman at the beginning of the 20th century. He introduced the
g-factor, a measure for what he called general intelligence as opposed to specific factors
that might be a talent in a particular domain. Spearman wasn't trying to say you're done if
you don't know everything. It was rather that he thought everyone is a genius in some area,
but it takes suitable tests to figure out just what that area is.
Briefly after that, but unrelated to Spearman's work, psychologist Alfa Benet and Th√©odore
Seymour took on the task of developing a test to quantify intellectual ability in children.
It was an assignment by the French government with the aim of identifying children who needed
special support. The Benet-Seymour test came out first in 1905. It includes questions of
comprehension, for example about the content of short stories, the meaning of words,
counting backwards, memorizing images and stuff like that. Similar tests are still used in some
places to assess whether children are old enough to start primary school. In a story that my mum
never tires of telling, I failed my primary school assessment because I refused to hop on one leg.
So please forgive me if I'm somewhat cynical about assessment tests.
The idea of the intelligence quotient IQ for short goes back to these early ideas from Spearman,
Benet and Seymour. If you want to take an IQ test today, you could try to assemble a piece
of furniture from a certain Swedish retailer. But the standard way to do it is to see a psychologist
and have them walk you through a certified test. There are several institutions who regularly
update these tests and who sell the most recent version to licensed practitioners.
These tests are not meant to be taken on your own, though you find some similar versions online.
The most commonly used IQ test might be the Wexler Intelligence Scale that comes in a version
for children and one for adults. It measures intellectual ability with several subtests that
assess verbal comprehension, perceptual reasoning, working memory, mathematical ability and processing
speed. One big disadvantage of this test is, however, that verbal comprehension strongly
depends on what language you've grown up with and what education you've gone through. In most
cases, it's a good proxy for general intelligence, but some people fall through the cracks because of
their social and cultural background. A popular alternative is therefore Raven's Progressive
Matrices, a non-verbal test for abstract reasoning skills that works by completing patterns.
There's also the Cato Cultural Fair Test, which also relies on abstract patterns
and that was specifically designed to minimize cultural bias. The scores for these tests are
calculated by recruiting a sample group, setting their average score to 100 points
and one standard deviation to 15 points. That means that about 68% of people will score between
85 and 115 points. One tricky point is that since the IQ is defined relative to that sample group,
the average IQ of the entire population that the sample is supposedly representative for
will generically not be exactly 100. Generally, the IQ of any group will depend on the comparative
sample. This is why in an international comparison, the average IQ of people in different countries
can noticeably diverge from 100. It's because the score 100 was based on a global average sample,
so nations can come out higher or lower. In a recent global comparison, the highest scoring
country was Japan with an average IQ of 106, closely followed by Taiwan. Germany came in 10th
with almost exactly 100 on average. The UK came in 20th with 99 and the United States 28th with 99.5.
At the bottom of the list, you find countries where malnutrition is rampant and illiteracy is
common, such as Nicaragua and Nepal. This brings up the question just what these IQ tests measure.
Studies have shown that the IQ changes with education, health, environment and age.
We also know that it has a strong heritable component, but it can fluctuate wildly.
According to a study by researchers from University College London in 2011, IQ and
teenagers changed by as much as 21 points over four years, and that was only on the days when
the teenagers could find their brain to begin with. There's also some evidence that cognitive
training can improve parts of the performance on IQ tests, such as working memory and verbal abilities.
So in the end, what does the IQ test tell us? As the psychologist Edwin Boring put it already
in 1923, intelligence is what the tests test. Basically, the psychologist's version of
shut up and calculate. And this is fine if what you want is just a number to find out what it's
correlated with. But in the end, we don't just want a number. We want to know what someone or
something can do with this supposed intelligence. We want to know what we can expect from them.
We want to know how far we can trust them not to be stupid. And while measuring things is all
well and fine, the idea that intelligence can be reduced to a single number is itself problematic.
Of course, we're not the first to point that out, which is why some smart people have thought of
more intelligent ways of measuring intelligence. One popular alternative to the IQ is the theory
of multiple intelligences proposed in 1983 by the developmental psychologist Howard Gardner.
According to Gardner, the IQ is too narrow a measure for intelligence. Gardner argued that
intelligence is not just a singular entity, but rather a collection of eight different ones.
That's linguistic, logical, mathematical, musical, spatial, bodily kinesthetic, interpersonal,
interpersonal, and naturalistic intelligence. While Gardner's theory of multiple intelligences
offers an appealingly inclusive view of intelligence, it's been criticized for being
subjective, lacking empirical evidence, and being in practice too difficult to use.
You see, it's a nice idea in principle to say there's no easy way to measure intelligence,
but in reality, it's rather useless. If you feel that eight types of intelligence are a little excessive,
maybe Robert Sternberg's triarchic theory of intelligence is more to your liking. In his 1985
book Beyond IQ, Sternberg proposed that intelligence is not solely based on cognitive abilities,
but also on practical intelligence and creative intelligence. By practical intelligence, he means
the ability to adapt to real-life situations, and creative intelligence is the capacity to
generate novel and valuable ideas. But Sternberg's triarchic theory has the same basic problem as
Gardner's eight levels. The definition is vague and in practice, it's difficult to assess,
so it's never been widely used. Okay, now that we have some idea of what we mean by
intelligence in humans, let's talk about intelligent software. Computer scientists
distinguish three different types of artificial intelligence. First, there's narrow AI, also
known as weak AI. It's designed to perform specific tasks with high proficiency. This includes AI
systems that can recognize speech, play games, or identify objects and images. Every AI you've
met so far was a narrow AI. Second, there's the idea of general artificial intelligence,
also referred to as strong AI. It's supposed to have an intelligence comparable to that of humans,
useful across a wide range of tasks and domains, except understanding English spelling, which is
something humans weren't meant to understand. Finally, there could be super-intelligent AI,
which is one that surpasses human intelligence in most, if not all, tasks. This brings up the
interesting question whether we'd notice if a super-intelligent AI pretends to be dumb
so as to not scare us into shutting it down. So how could we find out whether an AI is intelligent?
Well, the most obvious thing you can do is give it an IQ test. There are a few problems with this,
though. The first problem is that the current IQ test for humans tests things such as working speed
and memory, and even a dumb computer will easily outperform humans on these measures,
which makes me wonder whether these tasks should ever have been part of an intelligence test.
They arguably matter for cognitive function and are therefore correlated with intelligence,
but are a good memory and processing speed really a sign of intelligence on their own?
The second problem is that IQ tests for humans use different types of verbal and visual
input, and at the moment, fewer AIs are good at all of these tasks. But leaving aside memory and
speed tests and focusing only on the tasks chat GPT can do, Ika Rovainen, an assessment psychologist
in Finland, gave everybody's favorite AI the verbal part of the previously mentioned vexler test.
This includes questions about the meaning of words or the similarity between words or phrases.
It also includes questions of general knowledge, like who elects the president or what's the capital
of Iceland. Chat GPT scored 155. But as we've all learned in the past couple of months, chat GPT's
knowledge is extremely narrow, even when it comes to verbal intelligence. A sunny example is that
while it's been trained on text, it doesn't understand the idea of letters. If you ask
it to write a paragraph on a particular topic, say animals, that doesn't contain say the letter
in, it has no idea what to do, but doesn't know that it doesn't know what to do. It also can't
count the number of letters in a sentence, though it'll still answer the question if you ask it to.
This tells us three things. First, the issue isn't that an AI doesn't know some things,
but rather that it doesn't know what it doesn't know. Second, in practice, we often measure
dumbness rather than intelligence. We look for negatives. We want to know where someone or
something fails and use that to assess its intelligence. Third, we use our own intelligence
to search for these failures, which is an approach that will inevitably eventually fail.
The Turing test is based on this idea that we can use our own intelligence to judge that of an AI.
The Turing test is named after the British mathematician and computer scientist Ellen
Turing, who proposed it in 1950. It relies on an operator asking questions to an artificial
intelligence and a human to try to figure out which is which. If the human evaluator can't
distinguish the machine's response from the human's, the machine passes the test.
There have been a few claims in the past 10 years or so that a chatbot has passed the Turing test,
but they didn't have the best scientific standards. I suspect that someone's going
to stage a Turing test later this year just to make a point and will see AI pass it.
However, the Turing test doesn't so much prove that the machine is intelligent,
but rather that it has the ability to pretend to be intelligent.
Another problem with the Turing test is that, well, it depends on how smart the person is
who asks the questions. To take at least this issue out of the picture, Terry Winograd,
a professor of computer science at Stanford University, came up with the Winograd Schema
Challenge for AI. The challenge involves a series of questions that are designed to be
easy for humans to answer but hard for computers. Each question is based on a sentence that
contains an ambiguity, and the correct interpretation of the sentence requires
common sense reasoning about the context. Here is an example.
The city councilman refused the demonstrators a permit because they feared violence.
The challenge is to determine who they refers to in this sentence, the city councilman or the
demonstrators. Or maybe I should say that's what the challenge was because several AIs have
passed the test already in 2019 with more than 90% accuracy. But this test only looks for verbal
ability. You can also test AIs based on the IQ tests used for human intelligence that we discussed
earlier. For example, Raven's progressive matrices have been proposed for testing the
visual abilities of AIs. In 2020, two German scientists developed an AI that was able to
generate a fitting image from scratch. It solved an AI-adapted variant of the test with 98% accuracy.
More recently, in March 2023, another group developed an AI that scored 87% accuracy on
the regular test. There are further tests that are specifically designed for AIs,
such as variants of the Bongad problems. This is a software-generated data set of abstract
sketches, some of which match a pattern and some that don't. The AI must decide if new
sketches match the pattern. In a 2020 study, researchers found that AIs reach 60-70% accuracy,
whereas humans tend to reach more than 90%. So this one's still somewhat of a challenge for AIs.
Good news for our egos, I guess. In summary, researchers are using a number of ways to measure
how intelligent artificial intelligence is and how it progresses. AIs have always been ahead of
humans in terms of memory and processing speed and have recently rapidly caught up on verbal
and visual tasks. While there's still nowhere near humans in terms of general reasoning skills,
I think it's only a matter of time until they get there. And I agree with Paul Graham, we should
worry less about consciousness and more about intelligence, because of the two, intelligence
is much more dangerous. How will we know when an AI becomes intelligent? Probably because it'll
start arguing with us about what we mean by intelligence. If you want to boost your intelligence,
just sitting there and watching a video isn't going to help much. But if you want to exercise
your brain in general or learn more about artificial intelligence in particular, I know
just the place for you. Brilliant.org. Brilliant offers courses on a large variety of topics in
science and mathematics with interactive visualizations and follow-up questions. To learn
more about artificial intelligence, have a look, for example, at their course on computer science
fundamentals, their introduction to neural networks, and their course on artificial neural
networks. I found Brilliant to be a highly effective way to understand and also to remember
material. And they're adding new content each month. I like looking things up on Brilliant,
and I now even have my own course there. It's an introduction to quantum mechanics that covers
topics such as interference, superpositions and entanglement, the uncertainty principle,
and Bell's theorem. It's a beginner's course that you can take without prior knowledge.
And afterwards, maybe you want to continue learning more about quantum computing or
special relativity or wherever your interest takes you. If you want to try Brilliant out,
use our link brilliant.org slash Sabine and sign up for free. You'll get access to everything
Brilliant has to offer for 30 days, and the first 200 subscribers using this link will get 20%
off the annual premium subscription. Thanks for watching. See you next week.
