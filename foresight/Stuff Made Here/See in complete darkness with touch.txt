Imagine if your phone could see for you. This could be really useful in low visibility situations,
but more than anything, it should be useful for people who are blind. This should be possible
because smartphones and tablets have some pretty incredible sensors in them. They know where they
are in space and what's around them. If you could somehow communicate what the phone is seeing
with an interface that doesn't require a screen, something you can touch or hear,
it could actually be a pretty good replacement set of eyes. I've been thinking if I could do that,
it might actually be useful invention in contrast to a lot of the stuff I make.
It took me a few tries, but I did eventually get a system working. This iPad is running an app
that I wrote, which is talking to a kind of unusual case for it. And what it does is it's
communicating what it sees into my hand through a tactile interface right here. This allows me to
walk around blindfolded and not hit things. I think if I refined it a little bit more,
it could be a Braille display. It doesn't have enough resolution to do that right now, but
there's no reason it couldn't, I don't think. So inside of this, there's a pretty cool mechanism,
which I'll show you. I also spent way too much engineering time trying to prank my wife. She's
kind of on red alert now, so I had to come up with a complicated scheme to get her right where I
wanted her. So as usual, this project was a lot harder than I was thinking that it was going to
be. Yeah, because you did it the hard way. If you just would have used a bunch of motors,
like I said, it would have been a whole lot easier that way. No, what we should have done
is made an entirely new actuator from scratch. I'm telling you, night and all is the future.
All right, all right. So I did have a lot of internal debate on the best way to build this thing.
There's actually several different, all good ways to build this. I went with this approach
because I thought it was the most interesting. There's a really cool mechanism inside of here.
I also want to thank San Juan Steve for nerd sniping me with this idea and the comments
from my last video. Also, thank you for having a name that is WorkSafe San Juan Steve. This totally
distracted me from the project I was working on, which is making myself better at playing this violin
with the help of some robotics. It may still be on hold because I have a couple of other really
interesting projects that are competing for my attention. So I've been thinking a lot about
guided missiles and if there might be any kind of constructive uses for them. And I finally think
I have it. So imagine building the Iron Man gauntlet that flies like a rocket onto Tony Stark's hand.
I've been thinking about this problem. Definitely is dangerous, but I think it might be borderline
possible. That would be really cool. I'm also really interested in the idea of a baseball bat
that doubles or triples the power of my swing with the assistance of a very modest explosive
charge. I think I have a legal and interesting way to do that as well. If any of those things sound
cool, you should subscribe. I give you my word that I will build some all or none of those things.
I promise. Oh yeah. And I did finally set up a Patreon. If you want to help support me making
more awesome things and videos, this is a great way to do that. These videos do typically take
more than a hundred hours each and also quite a bit of money and material and tooling and other
things. In exchange, I'll be giving more behind the scenes info and in-depth project stuff. So
if that's interesting, there's a link in the description. All right, back to the project.
I calculate that this thing gives me roughly 20-1200 vision. Not the best, but it's better than
nothing. What 20-1200 vision means is that if I look at something with this, that's 20 feet away,
it will look as clear as it would look to someone if I took that thing and moved it 1200 feet away.
Going into this project, I really wasn't sure how I was going to do the sensing.
I was looking at using sonar sensors and off-the-shelf lidar unit. I was strongly
considering using the Kinect, but seriously, where are you going to put this thing? Are you
going to ask someone to just wear this on their head? You look like a complete idiot. Think about
how people would treat you if you walked down the street with this on your head. The goal of this
project is maybe something that could help humanity not hurt it. And I then remembered that the new
iPad has a lidar in it, which is awesome. The only problem is that it's only the latest iPad that
has the lidar in it, and I don't have one. And if you really think about it, I don't have a choice
here. I have to get this. It's to help humanity. Really? Humanity? It's going to help blind people.
Let's think about it. Fine.
Lidar is one of those things that if it didn't exist and you proposed it to me as an engineer,
I would laugh you out of the room. It just does not seem like it should exist. It's kind of like
ball screws where if you look at how they work, it still seems like magic. Lidar is crazy because
it measures the time that it takes light to travel from the iPad to an object, reflect off it, and
then come back. And this is crazy because light is mind-bogglingly fast. It's going around 670
million miles per hour. Unless it's light in the EU or Canada, in which case it's going about a
billion kilometers per hour. So the time that it takes to go from the iPad to a wall is on the
order of 5 nanoseconds. And to actually measure distance, you have to measure much more precisely
than this. The Lidar is actually sending out beams of light in all directions. It gives you a bunch
of measurements on the surface of everything that it sees and how far away it is from the iPad.
So this is an incredibly powerful technique for perceiving the world. It's how most self-driving
cars actually figure out what's around them. The other big architectural question I had to figure
out is how do I communicate what the thing is seeing using touch? The proposal in the comments
was to use some kind of vest, but my limited experience with nerves and humans is that
your torso isn't actually very good at sensing. So we're going to do a two-point discrimination
test. Tell me if you feel one or two touches. One. It's just so funny. I'm like jabbing you with two
screwdrivers. I know it's just how your body works, but it's really kind of funny. All right,
now turn around so I can test the front. That's probably not such a good idea, is it?
Your back isn't so great for tactile input, but your hands are incredible.
Not only do they have good resolutions, they can distinguish lots of touches.
They also are extremely sensitive. If this device could be a phone case,
I think that's legitimately more useful. A vest, you have to wear it and have all
these sensors, whereas your phone, you just have your phone and it helps you see.
So let's imagine that the iPad is seeing this. It's a room with a door and a chair.
What I do is I convert this into the simplest representation possible for navigating the space.
Right here, there's something that you don't want to hit. That's very close. That's the chair.
I have some stuff that's further. That's the walls. And then everywhere else is clear.
I can actually communicate this into your hand because there's not so much information.
If something is really close, I push really hard on your fingers at those corresponding
locations. If something is there but not as close, I can push not as hard. Where it's clear,
I don't push at all. This gives me basically a course map of what's going on in the world
on my hand. So I also made a couple different views. So if you want to zoom in and get more
detail, I have the ability to zoom. I also have an experimental top-down view. So this is the chair,
this is the wall, looking down from above. I can say that this is no go. This is open.
And these areas are unknown because I can't see through the walls with the lidar.
Remember, I'm looking from this perspective so I can only see what I can see through the doorway.
I can communicate this to the hand the same way I do the other view. It's just a different view
of the room. This view is kind of like the little mini-map in a first-person shooter in the bottom
of the screen, if you know what I'm talking about. I think this could be a pretty nice view with more
improvement. But this problem of things blocking other things happens a lot in practice. And so
it can be really difficult to interpret what you're looking at. To make this work, I had to find a way
to poke all of my fingers simultaneously with a controllable amount of poke. And that's hard
because I would like this to be an iPhone case. And that means I really, this is about as big as I
can go, kind of a grip shape. So if I just try to do the simple thing and cram a bunch of servo
motors in here, attach to each pin, there's just no way that's going to fit. Especially if I try to
scale it up so that it can be a Braille display, which I think is important and very useful. So
the big challenge for this project was finding a way to move all those pins with a compact and
ideally simple system. So what I wanted to do is make something that had a little metal pin that
I could push into every joint of every finger. And the way that I did this, imagine that I have one
of the pins that I want to move pressed against a cylinder that I can rotate. If I attach a little
wedge to this cylinder, when it goes underneath this pin, it's going to force it up. Then if I make
an even bigger wedge and I move my cylinder over, I can spin the cylinder and then push this pin
up even higher. All that I have to be able to do is can is rotate the cylinder and shift it left
and right to control how high up this pin goes. And then because it's a cylinder, I can pack
lots of ramps and lots of pins into it very compactly. Here's what some well-used ramps look
like IRL. That big bump next to them is used to trigger the pin locking and unlocking mechanism.
It's basically another ramp. And this keeps the pins in place when they're not under a ramp. And
then you can see that I can control where the cylinder goes with two opposing motors. By driving
them together, it rotates. And by driving only one of them, I can move it left and right. Planning
the motor moves for this system is a lot harder than I expected. Mostly because I wanted to move
one motor at a continuous speed and then have the other one keeping pace. It was a lot of quadratic
equations. And now the pain and joy of making this in 60 seconds or less.
Ah, why?
Ah.
This is the electronics. And the only thing that really mattered for proving the system is that
they work. So I made zero attempts at miniaturizing them. And they're very simple. They're just a
microcontroller Bluetooth communication module and then two big fat stepper motor drivers. If I
was trying to make this a real product, I'd be trying to fit it onto a little circuit board, which
there's no reason it couldn't. This is just what I had on hand. I should also point out that these
motors are massively overkill for the application. It doesn't take much power to raise a little pin.
I went with these partially because they're what I had on hand and also because
it's convenient to have a lot of extra power when you're prototyping. Now we don't worry about
stalling and other stuff. It's been almost a decade since I last wrote an iPad app.
And it's gotten a lot easier. And this is the app. It's really quite simple. I have all the
controls on the side for the different views and for zooming. And these are all accessible when
you're holding the grip on the side. There's a little preview of the depth data. And this just
helps me see what's going on. Ideally this would be running on a phone, but the LiDAR is only in
the iPad. If Apple puts the LiDAR on the iPhone, you could imagine it could just be a phone with
a little case on it, which would be really cool. That's pretty much all there is to this app.
Apple makes it really easy to work with LiDAR data. I spent a lot more time on the embedded system
trying to get the motor profiles working. And it was kind of wasted time, but I spent probably more
time trying to get wife mode working than anything else in this app. I really wanted to see my wife
walk into something. So I set it up to initially tell her correct data. Then after a bit start giving
her bad data. Probably just a bug. It's a complicated system. This thing is really weird to use.
It's a lot less intuitive than I was thinking it would be. You can feel all the pokes, but
I think about every finger and what it's feeling to try to create a mental image of what's in front
of me. Although I do think that if you used it a lot, it might become second nature. I remember
learning the type was pretty similar to this. It also lets you see things like overhead obstructions.
So you can get under them. Although it's since it's only giving two levels of depth, it was hard
for me to figure out where the obstruction actually was. So and you can see me pointing the iPad up
to see if there's anything above me. I would really like to see more touch points and more control
of those touch points because you really can feel the difference between these different pin
pressures. I think you could get a much nicer picture of what's around you if they could push
with more granularity. If I was doing another revision or trying to make this as a product,
I would be trying to find some little tiny actuator that I could buy that would allow me to
directly control every pin. I think it's a cool proof of concept and hopefully you'll like it as
well. So a lot of people have pointed out that I have a lot of tools and that I may in fact even
have a problem, which is probably true, but I would have an even bigger problem if all my tools got
stolen. Though I do spend a lot less time worrying thanks to this video sponsor Simply Safe. I spent
most of my adult life and my adult dollars building out this shop and the idea of someone
busting in and stealing my tools makes me want to curl up and die. Although let's be real, if
someone manages to steal this, they can have it. I'm only joking. That is not a challenge. Please
don't rob me. Although if you do try to rob me, you're busted because Simply Safe detects basically
every possible intrusion and calls the police immediately. You're going to kick down my door.
You just triggered my entry sensor. You're going to break my window. You just triggered my glass
brake sensor. You're going to cut a hole through my wall. Say hello to my motion sensor. Then wave
to me and the police dispatch on my HD security camera. You're going to try to break in when the
system is disarmed. Boom. Got a panic button. Simply Safe protects against outsiders, but it also
protects against me. And honestly, with all the stuff I get up to, I'm probably the biggest danger
here. I've got a fire alarm. If I accidentally leave a smoldering heap in the basement that
catches fire once I'm gone, I'm going to get notified. Got a carbon monoxide sensor. If I
leave my jet engine running and it makes a bunch of carbon monoxide, it's going to let me know
before it kills me. The number one thing for me though is the automatic deadbolt. The number of
times I've come back to see if the shop is actually locked is way too high. You get notified if you
forget to lock the door. You can lock it remotely. You can check it. Super handy. So if I was going
to rob your house, the first thing I'd do is I'd cut your power and your telephone. Although if
you had Simply Safe, I'd be a fool because it has a battery backup and uses cell service. It's super
reliable. It's usually ordered online or over the phone and they ship it straight to your house.
You stick the sensors wherever you want them and hit a few buttons and that's about it. It doesn't
even take an hour. And it's only 50 cents a day with no contract. That's cheaper than my previous
security system which had a contract. So have a lot more peace of mind with Simply Safe, knowing
that you're protected around the clock from basically anything you can think of. Visit
SimplySafe.com slash stuff made here to learn more or click the link in the description.
