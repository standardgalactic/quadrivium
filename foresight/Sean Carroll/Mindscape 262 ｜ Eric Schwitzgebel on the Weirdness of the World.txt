Hello, everyone, and welcome to the Mindscape Podcast. I'm your host, Sean Carroll.
If any of you out there own a copy of my book, Something Deeply Hidden,
you can go to the copyright page, the page right after the title page,
where there's the copyright information, et cetera, printed in the United States of America, or whatever.
There is a little notation on that page that gives the version number.
And the version number is not your copy of the book personally.
All of you and your friends and I and everyone else that we know has the same version number.
And the version number is 756 trillion, 132 billion, 390 million, 815,553.
If you know the story about what that version number is, when I wrote the book,
I generated a quantum random number between one and a quadrillion, an integer.
And that's what this version number is.
If you believe or if you, for the moment, imagine that the world is described
by the many worlds interpretation of quantum mechanics, which I explain and defend in the book,
then there are different branches of the wave function with almost exactly the same book written in them,
but different version numbers.
Every different integer of that size is represented somewhere on the branches of the wave function of the universe,
somewhere it's all zeros or all threes or whatever, and there's got to be some comment in that version of the book.
Well, wow, I guess we got really unlucky about that.
But this idea, this little joke that we sneaked into the book was supposed to be a way of really making you face up
to the claims involved in the many worlds formulation of quantum mechanics.
And those claims, I am very quick to admit, are weird.
They are bizarre.
The implications of the many worlds interpretation of quantum mechanics are very, very far away from our intuitive,
everyday experience of the world.
And some people will say, you know what, they're too far away.
I'm just not going to go there.
I do not believe there are a quadrillion different versions of something deeply hidden out there
and some quantum multiverse with different version numbers in them.
So what are we to do about that objection that this idea that many worlds interpretation of quantum mechanics is just too weird?
Because quantum mechanics is not the only place where this issue arises.
There are other attempts to make sense of the world, in other words, understand it even better than we do,
that like it or not lead us to some place that seems bizarre and weird to us.
That is the theme of Eric Schwitzgabel's new book.
Eric is a philosopher at University of California Riverside,
and he has a new book that is going to come out tomorrow by the day that this podcast gets released.
And it is literally called The Weirdness of the World.
And in this book, he basically faces up to the fact that some of our best attempts to make sense of the world end up looking pretty weird.
In fact, he argues that in some cases, they're going to have to look pretty weird.
There is no version of the correct theory that doesn't look weird to us.
Now, weird is an interesting thing.
Weird in his definition of it is a little bit different from bizarre.
He defines bizarre to mean contrary to our common sense, and weird is a little bit stronger than that.
It's contrary to our common sense in kind of an irrevocable way.
It's not going to go away just because we understand it better.
We're going to have to buy into it.
So he talks about not only quantum mechanics, but consciousness is a big theme.
All the different versions of consciousness theory, just like all the different versions of the foundations of quantum mechanics,
Eric will argue, involve a certain degree of weirdness.
And there's other weird things that may just be false, like maybe we live in a simulation or maybe we're brain in a vat or whatever.
Maybe those you can dismiss, but what about when you can't dismiss it?
What do you do when you need to balance different levels of weirdness of different kinds of theories?
Should we just ignore the weird possibilities?
Should we give substantial credence to them?
Should we be more cautious when all the options on the table are pretty weird?
So I like it as a work of philosophy that faces up to the real challenges that come along with taking seriously our best ways of understanding the world.
So over the course of all our different podcasts here, we've gone to some pretty weird places we might as well celebrate it.
Let's go.
Eric Schwitzkable, welcome to the Mindscape podcast.
Thanks for having me.
So you've written a book about the weirdness of the world, which is just a great provocative title that I'm sure will give us a lot to talk about.
But before we do that, I have to bring up a couple of things that you've also been involved with that are really interesting, but not on that topic.
But I have to get them out of the way a little bit.
One is virtual Dan Dennett.
You know, we had Dan Dennett as a previous Mindscape guest.
I think that's his claim to fame these days.
But those are before the days when we had large language models and could just program up a Dan Dennett to interview.
So you did that and did a little experiment.
So tell us about that.
Yeah, we sure did.
So we did this, I should say, this is collaborative with Anna Strasser and my son, David Schwitzkable.
And Matthew Crosby was a collaborator earlier on, but he had to leave to work for DeepMind.
That happens, yeah.
So we couldn't publish something using open AI technology.
I'm sure he's handsomely compensated for his problems.
He was involved early on and actually did some of the fine tuning.
So people know chat GPT, probably most of your listeners know where this is a large language model.
It can produce texts.
It's very human-like.
A precursor to that that came out, I think, in 2020 was GPT-3.
And one of the things that you could do with GPT-3 was you could fine tune it on a corpus of text.
So it's basically, it consumes large portions of the internet.
And from this, it can predict the next word when you input likely text.
So when you fine tune it, what you do is you add some more corpus.
And then it readjusts its weights so that its outputs look like a compromise between what it is in its original state
and the corpus that you've input, you fine-tuned it on.
So what we did was we took GPT-3 and we fine-tuned it on the corpus of Dan Dennett, about 2 million words.
Most of his, I don't know how many books he has, in the teens, in articles, we just pumped them into GPT.
And then what we did was we asked the actual Dan Dennett 10 philosophical questions
and we asked our fine-tuned model, we called DigiDan, the same 10 questions.
We did it four times.
We got four answers from each of the DigiDans.
We didn't do any cherry picking of those answers to see for quality.
We did make sure that they were sufficient length.
So we excluded short answers.
We wanted length similar to Dennett's own answers.
And then what we did was we took experts in Dennett's work and we said,
hey, could you guess which is Dennett's real answer and which has come from the model?
So chance would have been 20%.
The experts got it about 50%, right?
So they did better than chance, but still half the time they chose the model's answer over Dennett's answers.
And on two of the questions, the plurality of experts actually chose one of the model's answers over Dennett's answer.
And on one of the questions, Dennett said, you know what?
I kind of see why the experts chose that answer over my own answer.
If I'd thought about it more, I should have said something different.
Arguably, on one question, the model actually outperformed Dan himself.
So anyway, that was our experiment.
We wrote it up, we published it, and it was a lot of fun.
And when you did it, it was only a short while ago, but probably it was much more surprising at the time.
It wasn't quite as public the whole excitement these days about Lore's language models.
That's right.
We actually ran the experiment before ChatGPT was released.
And so people were getting the wind about the power of GPT-3, but it wasn't quite the phenomenon that it has since become.
And just as a technical matter, when you download this corpus, does that mean you had to have electronic copies of all of Dan's writings?
Did he help you with that, or did you just pirate a book or get a Kindle edition?
He helped us with this, and he collaborated with us on the project throughout.
And Anna Strosser did a huge amount of work converting these old PDFs and junky files into clean text that could be uploaded into the model.
But you've written things.
You have a blog.
Have you been tempted to do this for yourself, too?
Does that save you time?
Yes.
Actually, the first thing we did was we uploaded my blog into this.
So this didn't become a publication, but we uploaded my blog into GPT-3 kind of lower power version of it.
Actually, not the Da Vinci model, but the Curie model, which is a slightly lower powered version.
And then we had it produce blog posts in the style.
And so readers can go if they want, look on my blog, the Splintered Mind, and they can see the GPT-generated blog posts, which were actually pretty interesting.
I think I write blog posts better, but it was kind of cool.
Yeah.
And at the time that we did this, it was not generally well known that GPT could create well-structured answers over long strings of text.
I mean, if you're thinking, it essentially does next word prediction.
So you would kind of think it would lose the thread of ideas over time and wouldn't be able to create a well-structured argument that runs for paragraphs.
Anyway, that's kind of what we thought, but it was surprising.
One of the blog posts was, I think, not a convincing argument, but at least it had a kind of philosophical argumentative structure over the course of several paragraphs, which we found really interesting and surprising, given the basic structure of these models.
Clearly, GPT does have some memory of what it's recently said, right?
It's not literally going from one word to another.
Right.
It's got a window of, I forget how, something like a thousand tokens, and a token's like three-quarters of a word, something in that ballpark.
So yes.
So did you give it topics for those blog posts, or did you just say write another blog post that would fit in here?
We gave it titles, and then it wrote the post given the title, yeah.
This is very scary.
Do you think that the world is going to change dramatically because of this technology?
Yes.
Yeah.
Okay.
It's hard to know exactly how it's going to change.
Hard to know how.
Right.
Yeah.
Okay.
But for sure, it's going to change.
So that was one thing I wanted to get out of the way.
The other one, which I only found when I saw your Wikipedia page, is that you were one of the people involved in asking the questions, are ethicists, especially ethical, or does studying moral philosophy make you a more moral person?
Is that right?
Yeah.
Arguably, I'm the world's foremost expert on the moral behavior of ethics professors.
And what are your conclusions about this?
Well, I've done a fair number of empirical studies on this, and what I found over and over again, almost without exception, is that they behave about the same as comparison groups of other professors.
So sometimes we do the comparison group would be other philosophers who don't specialize in ethics.
Sometimes the comparison group is other professors at the same university in different departments.
There have been a couple studies where we found a little bit worse or a little bit better behavior in some respects for ethicists.
But generally speaking, it's a big null result.
Well, okay.
You just find they behave the same as other people, which I think is kind of interesting because you might have thought that ethicists would reflect on ethics and then behave differently as a result of their reflections.
And mostly that seems not to be the case.
One particularly interesting example of this is with respect to vegetarianism because ethicists on some issues will embrace more demanding moral standards.
So for example, ethicists are much more likely than professors in departments other than philosophy, where they were in 2009 when we collected these data.
To say that it's bad to eat meat, bad to eat the meat of mammals in particular is what we asked about.
And yet in our research, we found them just as likely to report having eaten meat at their previous evening meal.
Now, is that correlated?
I mean, are the people who say it is bad to eat meat also eating the meat?
Right.
It had the correlation, they would think.
So the people who, we gave them a nine point scale from very morally bad to very morally good.
And the people who ticked one or two very morally bad or one tick toward good from that, few of them reported having eaten meat at their previous evening meal.
But the ones who ticked three or four on our nine point scale, which was a lot of ethicists, seemed basically just as likely to have reported eating meat.
So there was a individual, there was a kind of correlation between the strength of the opinion and the self reported eating.
But there wasn't the group difference that we expected.
Right.
So ethicists as a group said the majority, 60% said it was morally bad.
But I don't know, 30 some percent of them reported having done at their previous evening meal nonetheless compared to I think was 38% of ethicists.
And 37% of ethicists and 38% of respondents overall.
So if this is a surprising result, which I'll entertain the possibility that it is, what's your theoretical understanding of what's going on?
Is it just that ethicists are better at arguing about ethics, but not actually better at being ethical?
Is there a different kind of study that would make you better at ethics?
Is it like coaching versus playing a sport?
Yeah, I think coaching versus playing is an interesting comparison.
We don't hire ethicists to be saints, just like we don't hire coaches to be football stars.
Yeah.
And yet you would expect if you took a coach and a random member of the population of the same age and gender and put them on a football field together,
you would expect the coach would still outperform, even if the coach is not a superstar.
Right.
So I think that's an interesting comparison that reveals partly why you might think it's still a little surprising,
even if we don't hold ethicists to saint-like standards.
I mean, in the vegetarianism results again, I think that strikes people as somewhat surprising.
Yeah.
So one of the things that I draw from this is it fits with a view I have about moral psychology.
I suspect that real answer is complex and multi-causal.
But one of the things I think it fits pretty well with is the idea that people in general aim to be morally mediocre.
Okay.
So my inclination is to think, and this is grounded both in personal experience and in reading social and moral psychology,
that people don't generally aim to be good or bad by absolute standards.
Instead, they aim to be about as morally good as their peers.
They don't want to make the sacrifices that would be involved in being very morally better.
But they also don't want to be the worst in the bunch.
Interesting.
So people aim for peer-relative moral standards.
So if you think about that from the point of view of thinking philosophically about ethics,
maybe what you do when you think about ethics is you discover moral truths,
like maybe you discover it's bad to eat the meat of mammals.
But if you're aiming just for peer-relative goodness, your peers are still eating meat.
So what happens is your opinion about your peers' moral behavior and your own moral behavior goes down,
but your behavior doesn't change.
That's actually very nicely consonant with other podcasts I've done recently about other aspects of things like psychology or even epistemology,
having much more of a social slant than we would expect.
Brian Lowry explained to us how our sense of selves serves mostly as social function.
Hugo Mercier explained how our use of reasons serves largely as social function.
And you're saying that there's a very big social function that is served by our ethical practice at any rate.
Yeah, right. Absolutely.
Social animals. There we are.
But I guess this does segue even more smoothly than I thought it would into the weirdness of the world,
because when you say the world is weird and now we're going to get into the topic of your book,
immediately part of me wants to say, come on, the world can't be weird.
It's the world.
What we're seeing is a mismatch between our expectations and the world,
and maybe those can be colored somehow.
So what is the title of your book mean?
Right.
So, yeah, you're right.
It's not that the world is intrinsically weird.
I'm not sure what that would mean.
The idea of weirdness or bizarreness, which is a closely related idea in my book,
involves violating our expectations or our standards or a sense of what's normal or violating a common sense.
So when I say that the world is weird, I mean something like our common sense understandings of how the world is
are going to be sharply violated by how the world actually is.
That's the bizarreness element.
And then there's also an element which I call dubiety, which is that, and all of our answers to this are dubious.
It's not like, oh, well, it violates common sense, but we perfectly well understand it.
It's also a dimension of weirdness is that it kind of exceeds our ability to fully comprehend.
Right.
The example you gave in the book is special relativity, which tells us various things that happen at the speed of light
might seem bizarre to us.
It's anti-common sensical, but it's not weird in the same sense.
We can fully understand it once we learn what's going on.
Correct.
So special relativity is a nice example of something that's highly bizarre.
It violates common sense, but it's not dubious.
The full weirdness thesis also involves this dubiety claim.
Yeah.
You use the word dubiety in your book much more often than I've ever seen it used before.
So just to let people know, it's the existence of, or I guess, the claim that you should be dubious about something.
Right.
That doubt is justified.
Doubt is justified.
Good.
So the name, the URL of my personal website is preposterousuniverse.com for exactly the same reason.
It came out of thinking about naturalness and cosmology and the cosmological constant and the fact that the universe is surprising to us.
And it's funny because I get critics, you know, the usual crackpot on the street with opinions about cosmology saying,
No, Sean Carroll thinks the universe is preposterous.
He doesn't realize that it's just our ideas that are wrong.
But I'm trying to say, like, no, that's the point.
I don't think the universe is making a mistake.
It's definitely we are making a mistake.
That's the whole message that is trying to get across.
Exactly.
And I like the word preposterous too.
I was flirting with just borrowing that word from you, but I decided I liked weirdness a little bit better.
Weirdness works, especially weirdness of the world, the alliteration, etc.
OK, so is then let's take the universe's point of view here.
You know, why is it our fault that the universe looks weird to us?
Is there something about us that is, despite the fact that we're part of the world that kind of doesn't quite match on to what we see out there in principle?
Right.
Well, I'm inclined to think that our theories and our common sense.
Well, especially our common sense.
Let's start with that.
Our common sense is trained upon, built upon a very limited range of experiences.
Yeah.
Right.
So with respect to big picture cosmology, right, it's relatively low energy, middle sized, slow moving moving stuff on Earth.
Right.
And that's what we're good at.
That's what we evolve to be good at.
That's what the social pressures and learning environment is.
Makes us good at you take something at a very different scale, much larger, much smaller, much more energetic.
And those aren't the kinds of things that there's any particularly good evolutionary or developmental or social reason to think we would have well tuned common sense judgments about.
So in other words, the way that I've said similar things in some cases, we have, we only experience a tiny fraction of what the world is.
And but we make efforts to experience more and more of it.
And guess what?
It looks different and surprising to us.
Yes.
I completely agree with that.
So I think the same is true for our understanding of consciousness, although less, less obviously so.
Right.
So the thesis of the weirdness of the world is partly about large big picture cosmological issues.
It's also equally or even more about consciousness.
Yeah.
Right.
So again, with respect to issues of consciousness, we're familiar with the human case and with, you know, certain familiar vertebrates we like.
And that's about what we know about consciousness.
And we have not had experience, for example, with sophisticated AI systems.
Yeah.
So we shouldn't expect particularly to have well tuned common sensical intuitions about such things.
Good.
And so in some sense, I don't want to put words in your mouth, but it seems to me that the model of your book should be that you're asking us to be courageous.
To say, you know, we should expect that as we learn more and more about the world, we'll find that what we're learning seems weird to us and we need to develop tools and techniques to deal with that and handle it.
Yeah, absolutely.
And yeah, I guess that's in a sense courageous, although I'm not sure that's the word I would use.
I like the word wonderful instead.
Okay.
Because it's got this, it's got to the idea of wonderful, it's got two dimensions to it, right?
So it's got the root sense of wonder, right, that we live in a world that promotes wonder in us.
And wonderful, of course, is also something like a synonym for one for good.
So I think that's a good thing about the world that it's going to defies our understanding.
So you have lessons and nostrums that we should get from contemplating the weirdness of the world, but I thought that maybe we could just go through some examples, really think about them in depth, and that will help us extract what these lessons are.
And as you said, consciousness is a big one, but I first wanted to just talk about the existence of the external world, you know, these radically skeptical scenarios.
Like you talk a lot about, are we sure that we're awake, for example.
So give us the general lay of the land here.
Like how do you think about these skeptical possibilities and what are your favorite ones?
Right.
So you have a few different chapters where I tangle with these skeptical possibilities in different ways.
The dream argument, of course, is a famous one.
That's the one that you started with.
But I'm also interested in the simulation hypothesis, the idea that we might be living in a simulation.
The Boltzmann brain idea, which you, of course, talked about in your work very wonderfully.
And, you know, just the idea that even the idea that the universe might consist wholly of my own mind and nothing else.
Right.
So I talk about all of those possibilities in the book.
But we could start with the dream one, which is maybe the most familiar one.
Sure.
So this goes back in philosophy all the way at least to the ancient Chinese philosopher Zhuangze, although, of course, Descartes makes famous use of it.
Right.
The idea is how do you know, if you do know, that you're not currently dreaming right now?
And normally we think we feel pretty confident that we're awake.
At least if you ask a waking person, if they're confident they're awake, they'll tend to say yes.
Yeah.
But what justifies that?
And I think there are a few ways it could be justified.
I think there are some empirical features of dreams that make them different from waking life.
So, for example, I think of waking sensory experience as pretty richly detailed and pretty stable.
Whereas the experiences we have in dreams, arguably, are less detailed, kind of sketchier, more image-like, less stable.
Do you know this claim that in dream?
Go ahead.
There's a claim that I think actually has some backing, but I'm not sure how right it is, that you can't read text in dreams.
The text does not look like text.
It looks like that sort of bad AI text that's sort of like letter-like without actually having any meaning.
Yes, that is sometimes called a dream sign.
These are hypothesized tests for whether you're dreaming or not.
So, look at text and see if it's stable and if you can read it.
And some people think of that as, for themselves, a good dream sign.
But of course, there are also dream reports in which people report reading stable text, so it's not universally accepted.
So, I think that if we accept this fact about the stability of text as maybe, at least in the majority of dreams, you can't have a stable text,
that creates some evidence that I'm not dreaming right now.
But a lot of dream researchers, including, for example, Jennifer Vint, who I think is really amazingly knowledgeable about this kind of stuff,
think that we do often in dreams have stable experiences that are a lot like waking life,
maybe even experientially indistinguishable from waking life.
Even boring mundane experiences like that of listening to a podcast.
That's a very exciting experience, Eric.
And so, if we think that there are some dreams like this, or if we invest some credence in a theory of dreaming,
according to which there are either often, or at least sometimes, experiences like I'm having right now,
or like your listeners or you are having right now, in dreams, then it becomes kind of less experientially obvious.
Okay, I can't now be sure that I'm not dreaming based on what seems to be this stable experience that I'm having right now,
of seeming to be awake.
And of course, lots of people, including me and probably most of your listeners,
have had false awakening experiences where you kind of seem to wake up and think,
oh, I just had a dream, now I'm awake, right, and then you wake up again.
So there are reasons, I think, not to be perfectly certain that you are not dreaming right now.
Is it also worth contemplating a kind of inception scenario where we're all dreaming?
There's a more awake version of us that dreams like our existence, pretty detailed, we can read text, etc.,
and then we dream that we are dreaming in this fuzzier way, right?
I think that's possible, but I want to draw a distinction between what I think of as grounded and ungrounded skepticism.
So ungrounded skepticism says, well, I could be a brain in a vat, and then I wouldn't be able to tell the difference.
So can I really rule that out?
An ungrounded dream skepticism could be like, oh, well, maybe we're in an inception scenario.
Grounded skepticism starts with our ordinary background assumptions and says,
looking at these assumptions, there's some positive reason to give some credence to skeptical doubt, right?
So there's no real positive reason to think that you're a brain in a vat to assign that any more than the most trivial likelihood, right?
There's no positive reason to think we're in an inception scenario, but there is positive reason to think that this experience might be a dream experience.
Once we start thinking about the nature of dream experiences and weather experiences like this, at least maybe sometimes occur in dreams,
at least according to some theories that might be true, right?
So I prefer to focus on these grounded kind of sources of skepticism.
So I think it's not just, I mean, one of the critiques that philosophers sometimes give with skepticism is you could cook up anything.
There's no reason for us to take it seriously.
Whereas I think with dream skepticism, given the fact that we dream every night,
given that theories of dreams, at least some mainstream theories of dreams postulate that we have experiences like this in our sleep,
that creates grounds for doubt.
It's not completely just cooked up out of nothing.
Maybe you can add to that the idea that at least most of the time while we're dreaming, we don't think of ourselves as dreaming.
Right?
Most of the time.
Of course, there are some so-called lucid dreams.
And it is the case that if you can get yourself in the habit of thinking,
am I awake so much that that thought starts to come to you while you're actually dreaming,
then that's one way to discover that you're dreaming and start to have lucid dreams.
I'm very bad at remembering.
Even in the dream, sometimes people will say, am I dreaming and then decide,
no, I'm not dreaming, even though they really are.
That's just what I was going to ask because I was just going to say,
I don't remember my own dreams very well at all,
but I don't have any memory of ever being in a dream saying,
I wonder if I'm in a dream and then going,
nope, I don't think I am.
But you're saying other people have reported that experience.
Yes, that's definitely not an uncommon experience.
All right.
It could be the case that the majority of times when people are dreaming
and think to themselves explicitly, am I dreaming?
They come to realize they are,
but it's not clear that that's the majority.
And even if it is, it's not an overwhelming majority.
Yeah, okay, good.
Let's just go through some of the other famous ones
because you draw a very interesting distinction between grounded and ungrounded skeptical scenarios.
What are some of the other skeptical scenarios
you would classify as grounded, in other words, worthy of our attention?
So I find the simulation hypothesis pretty interesting.
So this is the idea that we might be artificial intelligences
living inside a simulated reality, kind of like the matrix.
Except in the matrix, they're really biological bodies,
but you might, you could have a matrix type scenario
where the confused entities are AI systems, right?
Or you could imagine the video game, the Sims,
with these artificial simulated people going around these environments,
except the Sims are really conscious.
There's a couple of ways of thinking about the simulation hypothesis, right?
So Nick Bostrom has a famous argument that gives us some grounds
for thinking it's at least possible that we are Sims, right?
So the idea here would be that it's not ridiculous to think
that consciousness could arise in artificially intelligent computational systems, right?
Philosophers have disputed that.
John Searle, who was actually one of my dissertation advisors,
is one of the most famous skeptics about that.
But there's, it's certainly no consensus that it's impossible.
So if we accept, give at least some credence to the possibility
that artificially intelligent beings could arise on computers,
then it seems possible that such beings could exist
in simulated artificial environments that they take to be their own,
the base level of reality, as Bostrom puts it.
Some of them might even think they're living in Earth in the 21st century.
And then the question arises, okay, how many such beings are there?
And one possibility would be, look, you know, they're not ever going to be beings
like this out there, right?
The civilization will not get that far enough.
Maybe it's really expensive to make such things and no one would bother.
Or maybe there'd be some ethical regulations, like you don't want to create real,
you want to create really conscious entities inside your computer
who think they're living in reality, right?
But on the other hand, it also seems like it's possible
that there would be many such beings, right?
Just like we run computer games like the Sims right now
and we run scientific simulations,
it could be the case that there are lots of games or scientific projects
that involve real conscious beings inside them
who think they're living in the base level of reality.
If the universe contains many such beings,
then it seems not totally implausible to think we might be among them.
So there are various reasons to think we're probably not them, right?
Every step of this argument admits of doubt.
And you kind of stack those doubts on top of each other
and it seems like, okay, probably not.
But again, it's like with the dream case,
it doesn't seem like we should be absolutely certain that we're not Sims.
So yeah, I guess it could be.
So I find that possibility interesting.
And then I guess to turn this into a skeptical scenario,
so one of the things that David Chalmers has particularly emphasized
in talking about this is he says,
well, look, if you're living in a simulation but it's large and stable,
then that's not really a skeptical scenario at all.
He says, because you have a long past, you're going to have a long future.
All the people you know really exist.
And there might be, say, a coffee mug,
and it might be fundamentally made out of computational bits,
but that's enough.
It's still going to be there.
It's going to react the way that you want.
So it really is kind of a coffee mug.
Well, basically, most of your ordinary beliefs would end up being true.
So to turn this into a skeptical simulation scenario,
what we have to do is think about what's the possibility
that if we're living in a Sim, it's a small or unstable one.
And there I guess I'm inclined to disagree with Chalmers.
And I'm inclined to think that if we are in a Sim,
there is a decent chance that it's a small or unstable one.
So if we think about the simulations we run,
they tend to be small and unstable.
If we think about the question of resources,
it probably would take a lot of resources to run a whole galaxy
from the Big Bang through now and on into the future.
So what scientist is really going to want to do that
if maybe all they're interested in is human cognition?
So just run a short, a few people having a discussion on a podcast
or something like that.
So I think conditional upon thinking we're living in a Sim,
we should assign a substantial portion of that credence,
maybe 50%, maybe 90%, maybe 10% to it's being a smaller, unstable simulation.
And in that case, then that in my mind counts as a radically skeptical scenario
because you might be radically wrong.
Maybe this whole simulation was created only 10 minutes ago,
maybe there's no one outside of your room,
it's just you listening to a podcast
or just the two of us having a conversation
and beyond the walls of our rooms, nothing exists.
Those would be various ways of it's being smaller and stable.
So as a professional philosopher, of course,
you know that the idea of these skeptical scenarios goes back to antiquity,
not just Zhuangzi, but the ancient Greeks thought about this.
So we've been worried for millennia now
that reality is not anything like what we think it is.
Absolutely. I love the ancient skeptics.
So what are some of your favorite ones?
Well, Zhuangzi is probably my favorite philosopher,
but Sexist Empiricus is also really wonderful.
And they did not know about the simulation argument.
Right, they didn't know about the simulation argument,
but that opens up the possibility that there are some rounds for doubt
that future philosophers and physicists will think of
that didn't even occur to us.
And maybe we should have some degree of skepticism reserved for that.
Right, I call this wildcard skepticism.
The idea that I should have a certain amount of doubt
about my ordinary assumptions about the world,
just on the basis of the fact that there's some skeptical possibility
that I'm not even capable of considering.
Right. Okay, good.
So there are other skeptical scenarios,
but we have the general feeling between living in a simulation,
we're just dreaming, what do we do about it?
Do we just ignore those possibilities because they're too weird?
Do we reserve a little bit of our credences to say,
who knows, maybe tomorrow I'll change my mind and think this is right?
Yeah, I think we reserve a little bit of our credence.
So the way that I think about it in terms of numerical credence
is that I think it's rational to assign about a 0.1 to 1% credence
to some radically skeptical scenario or other being correct.
That's rough and fuzzy.
It's somewhere between just being completely confident they're false
and being radically uncertain.
So 99.9%, the world's basically just how we think it is.
Setting aside the big picture cosmological stuff,
the ordinary Earth world of middle-sized dry goods at slow speeds
is more or less how we think.
99.9% of our credence maybe should go to that,
but save a little bit of your credence space, so to speak,
for these radically skeptical possibilities.
And then I think that having that little bit of space there
has some influence on your choices and your behavior.
Actually, I do want to get to exactly that issue,
but I realize there's a hanging thread that we should deal with,
which is there's another kind of way in which the world could be very different
than what we think it is, which is just there is a lower microscopic level
beneath our manifest image kind of world, right?
So you're not counting.
We are not talking about something like,
oh, there's a whole new theory where everything is little strings
or wave functions or whatever.
That doesn't count because in those scenarios,
the macroscopic world is still the macroscopic world and obeys the rules, right?
Exactly, right.
So I don't count that as a radically skeptical scenario of the relevant.
Because there still would be our everyday beliefs would still mostly be true, right?
It would be true that Earth has existed for billions of years
and it would be true that there's a coffee mug here
and that sort of stuff and the sun will rise tomorrow, so to speak.
Good, okay, good.
So then we can go back to that 1% skepticism that you're advocating.
I mean, one question is just where did that number come from?
You're saying we should attach a 10 to the minus 2, 10 to the minus 3 credence
to just being completely wrong.
I absolutely agree that we should attach some credence to any crazy idea you have.
I'm a disbeliever that you should attach zero credence to almost anything,
but why not tend to the minus 10?
Why something as big as 10 to the minus 2 or 3?
I don't have a rigorous argument for that,
but let me just do it for, say, the dream scenario, right?
So let's say we invest a 20% credence in the theory,
which some major dream researchers accept,
that we commonly have experiences like we're currently having in our dreams.
Let's say we get 20% credence to that and 80% credence to now dreams
are basically just always sketchy.
Then conditional on that, we say,
okay, how often do I have experiences relevantly like this in dreams?
Well, maybe this is not the kind of thing that I would tend to dream about very much.
Again, if we ordinarily have ordinary sensory experiences of mundane things,
it seems like this is the kind of thing that we should have.
So maybe I should assign a 2% of the time I'm having experiences like this
is actually in sleep, or I should invest 2% of my credence
to the idea that I have experiences like this in my sleep.
Now, once I've attached a 2% credence to the idea that I have experiences like this
commonly in my sleep, it's hard for me to see on the basis of that
how you would then go, okay, so I now only have a 1 in 10 billion credence
that this is a dream, right?
It seems like you can't knock too many orders of magnitude down off that 2%.
I'm not sure what the grounds would be for that kind of decrement.
I think it's a big philosophical problem that I don't know whether you know
if anyone sort of specializes in this particular question,
but what do we do with issues or questions or scenarios
where the credence that it'll happen is incredibly tiny,
but the consequences of it happening are incredibly large.
And it seems maybe AI destroying the world is an example of that
or even better because people think that AI destroying the world might be 10%,
but the large Hadron Collider turning on in a black hole eating up the world
and someone says, well, it's less than a 1 in 10 billion chance.
And someone else says, but it destroys the world, that should still count.
How do we reason about those cases?
1 in 10 billion times 10 billion people, so...
That's why I chose the number, right.
One expected murder as soon as you turn it on.
But even the number 1 in the 10 billion, I mean, if someone said,
oh, no, it's really only 1 in 10 million or it's 1 in 10 trillion,
probably I couldn't give a principled argument in any direction.
Right.
So I don't know how to deal with them.
You talk about those kinds of magnitudes, sometimes it's hard to get...
You lose your sense of magnitude once you get over, I don't know,
a trillion or something like that.
So do philosophers have a toolkit for dealing with these weird numbers?
No.
It's becoming...
It's an interesting issue that's been starting to get attention in the philosophical literature.
There's this idea that's sometimes called Nicolossian discounting,
which is the thought that once something has a low enough chance
or you give a low enough credence to it, you just ignore it completely.
Yeah.
Yeah.
So that is one approach.
What was that called?
And I...
Nicolossian discounting.
After someone named Nicholas, but I've forgotten which Nicholas it is.
So, right, so for example, in the weirdness of the world,
I suggest that once you give something 10 to the negative 30 credence,
you kind of just forget about it.
And this helps solve certain kinds of puzzles and paradoxes in decision theory.
But there are also arguments against this.
So there's been back and forth about this.
This also comes up in the debate about the ethics of long-termism.
Right, exactly.
Right, so long-termism is this idea in the effective altruism movement
that there's a small chance that things we do today could have a huge impact
on a huge number of lives in the future.
Right, so for example, if humanity goes extinct now,
then maybe there are no other entities in our galaxy who will ever have the kinds of lives
with the kind of value that our lives have, right?
And if we manage not to go extinct now,
then maybe we will have 10 to the 40 happy descendants
before the heat death of the universe, right?
So even if there is a one in a quadrillion chance
that something you did now could prevent humanity from going extinct,
given the stakes, maybe you should invest a huge amount in that tiny little chance.
So that's an interesting issue that's been coming up recently with long-termism
where this issue about what do you do when you're trying to balance tiny credences
and giant values against each other?
Do you have a take on what we should do, or is it just an open kind of question?
So I have two takes.
One is I'm still going to stand by Nicolassian discounting.
Okay.
And the other take is radical ignorance about what actions that are currently available to us
would have good versus bad effects.
So the long-termists will typically say or assume that human extinction is likely to have a bad effect
instead of a good effect on future history.
I don't think that that's necessarily true.
So for example, maybe humanity, because we are so technological and prone to violence,
is a kind of unstable species that is more or less certain to doom itself
sometime in the next 10,000 to 100,000 years we're going to blow ourselves up.
And if we do it in an explosive way, then we ruin the Earth for other future inhabitants.
But if we were to say bow out peacefully now by deciding never to reproduce again,
as anti-natalists suggest, then maybe we leave the Earth in a good position for other species
like say dolphins, who might have descendants that are capable of lives as rich as ours
but who aren't technological, aren't going to blow themselves up
and could endure potentially four billions of years on the planet
or maybe not billions, but maybe a billion.
If that's the case, then and you put the numbers into the equation in a certain way,
it turns out that would be better from a kind of long term perspective for human beings
to peacefully extinguish ourselves now.
So I'm not saying that's true.
What I'm saying is it's very hard to know what really,
when you take a billion year time perspective,
what really is kind of objectively good versus bad among options that we have available to us now.
I think that's fair.
So radical ignorance about the very distant future.
And relatedly then, what is the actionable fact about 1% skepticism?
Like how does it affect our daily lives to think that maybe there's a 1% chance
or a tenth of a percent chance that I'm dreaming or that I'm living the simulation?
Right.
Well, for example, just a fun example to start with,
I had been reading a lot about dream skepticism and it was particularly vivid for me this one particular winter break
when I was walking across campus and no else was around.
I was thinking, I wonder if I'm dreaming.
Maybe I should try to fly because I'm probably not dreaming.
But look, if I'm dreaming, it would be so awesome to fly.
No one's around, no one's looking.
There's no cost.
I was kind of walking across campus to the science library to get a book, right?
So why not just like try to fly to the library?
So I did try to fly to the library and I failed.
But I think that was a rational decision because I could have been dreaming
and then it would have been awesome.
It was not so rational that you would have done it had people been watching.
Right.
So low cost things, right?
Don't try to fly when you're standing on the edge of the cliff.
Plug that into your utility calculus and you will not get a positive result.
But if they're very small or no costs to trying to fly,
then why not if you think this might be a dream and could fly?
Of course, as soon as you try to fly and fail,
that should reduce your credence either that this is a dream
or that if this is a dream, you could fly.
So you might, it might not be repeatable.
You might not just be spending all your time trying to fly.
In my dreams, I can fly at least a little bit.
I can float.
Right.
It's just a matter of willpower.
Anyway, this is all, you know, fun, but it is 1% stuff
and a lot of the book, I don't want to give people the wrong impression.
A lot of your book, you're talking about consciousness,
which has the feature that we're all familiar with it.
I don't even want to say the feature that it exists
because people argue about that, but at least we're all familiar with the idea.
So what is it about our attempts to understand consciousness
that drives us into the weird zone?
Right.
So philosophers have tried over and over again for centuries
to make sense of how consciousness fits into the world.
And one of the striking empirical facts about the history of philosophy
is that every single attempt to make sense of this is jaw-droppingly bizarre.
So there are, I divide attempts to deal with the question
of how consciousness fits into the broader world into four broad categories.
One is substance dualism.
You've got an immaterial soul.
Another one is materialism.
There are no immaterial souls.
You're just a biological entity.
Another one is idealism.
This is the idea that there is no material world at all.
All that exists are minds or souls.
And then there's what I call compromise slash rejection views,
this kind of grab bag of other alternatives.
And the striking thing to me about this is
all of these alternatives end up committing to bizarre and dubious
theses of one form or another.
There's not really a live option here that is non-bizarre.
It's not always obvious.
I mean, idealism is bizarre on its face, I think.
It's contrary to common sense to think there's no material world,
and it's only just minds.
Dualism and materialism are not maybe bizarre in their face,
but once you try to get into the metaphysical details
and think about how it really works,
end up pretty swiftly faced with theoretical choices
where there are going to be bizarre consequences
for any of the choices that you make.
I think that's the important point,
because people are going to hear you say that,
and they'll be both materialists and dualists in the audience
who go, I have no trouble thinking that consciousness works that way.
But your point is that if you really take the consequences of that view
seriously, you're led to something that we should recognize as bizarre.
Correct.
Right.
So why don't you tell us for Ethan Pink one?
So for example with dualism, right?
The dualist faces two questions where all of the answers seem to be bizarre.
One concerns what kinds of entities have souls,
and the other concerns the causal relationship between material world and souls.
The causal question is a little more complicated,
so let me just talk about the question of what entities have souls.
Basically, you have four choices.
You could say only humans have souls,
or you could say everything in the world has a soul.
Both of those are pretty bizarre,
because if you think souls are the locus of consciousness,
then except the first, like Descartes,
then you think dogs and cats aren't conscious.
So there's this story of Descartes taking a cat
and throwing it out of a second-story window saying,
see, cats, they're just machines.
I never heard that story.
He probably didn't actually do this.
Man.
But that story kind of reveals the bizarreness of those
that only humans have souls.
And of course the panpsychist view that everything has a soul,
even say a proton, that's also pretty bizarre.
So then there are two other options.
One is that there's a sharp line somewhere.
So dogs have souls, cats have souls, but not frogs.
Where do you draw that line?
Across the continuum of animals,
it seems like there's a continuum of psychological capacities,
a continuum of physiology.
It would be weird if you said, OK,
toads of this genus have souls,
toads of this other genus do not.
So a sharp line is pretty implausible,
at least bizarre.
And then that gives you maybe the fourth option,
which is having a soul is not an on or off thing.
You could have a kind of soul or a half soul.
Dogs have an eighth of a soul.
What would that even mean?
We normally think of souls as things that either have or don't have.
It seems like a discrete category rather than a graded category.
But you've got to take one of those horns,
but they're all bizarre.
So that illustrates why I think on the face of it,
it seems like having a soul is not a bizarre view.
But as soon as you face that choice of saying, OK,
what animals have souls?
You're forced into committing to some
strikingly bizarre position.
And as a matter of fact,
this was a hot topic in ancient philosophy,
which animals have souls, right?
Exactly.
And the modern conception of the soul as a locus of consciousness
is a little different from an ancient philosophy.
There was the vegetative soul as well.
So there's a sense in which even plants had souls,
but they didn't think of souls maybe as a locus of consciousness.
So actually, the concept of a soul that we find
in our current philosophical and religious tradition
has a certain history.
It is not a straightforward translation from, say,
ancient Greek.
So it's complicated, but it's been an issue
throughout philosophical history.
But here at the Mindscape Podcasts,
we are hardcore materialists about consciousness.
So tell us why that leads us to weirdness.
Well, one of the issues here to think about
is, again, what kind of entities have experiences.
I guess there are a few different ways to angle in on this.
But one of them, and this is the theme of Chapter 3
is to point out that according to a broad class
of materialist theories, it's very plausible
that the United States has a stream of conscious experience.
The United States conceived of as a concrete entity
with people as its parts, kind of like you are a concrete entity
with cells as your parts.
So think about that concrete thing
with hundreds of billions of people.
Hundreds of millions.
Sorry, hundreds of millions.
Sorry, I misspoke there.
Don't want you misquoted, yeah.
So that entity processes a lot of information.
That entity represents itself.
That entity responds to its environment,
kind of intelligently or semi-intelligently.
You scan space for asteroids that might threaten Earth
and we're prepared to try to deal with them if that happens.
The United States monitors its borders.
It engages in import and export.
It sends its army out to do certain things.
It scolds people in UN Security Council meetings.
It digests bananas, mounts the bananas.
It exudes smoggy exhalations.
So if you take standard,
materialist theories of consciousness out of the box
and you don't rule around with them post-hoc
to try to exclude the case,
then I think it turns out that probably
the United States is going to count as conscious.
So there are a couple of ways to react to this.
You could say, okay, well, so much the worse for materialism.
Or you could say, okay, well, look,
we need to mess around with these theories
to exclude this bizarre possibility.
And I think that is maybe a reasonable response.
One question here is how we know
the United States is not conscious
whether you should take that as a fixed point
in our theorizing about consciousness or not.
You know, and the third possibility is to say,
okay, well, maybe there is group consciousness.
I mean, we don't have a consciousnessometer
that we could put up against the head of the United States.
It doesn't even really have a head, right,
to determine whether it's conscious.
So that would be one area where I think
if you accept the United States is conscious,
then you end up, I take that as a pretty bizarre kind of view.
If you don't, then you adopt other theoretical commitments,
and then we could get into the details of those.
But I think those other theoretical commitments
often then involve kind of further choices
among various bizarre possibilities, right,
kind of like with the immaterial soul case, right?
As soon as you start making those commitments,
once you develop them, you see, oh boy,
this is going to have this consequence.
This is pretty unintuitive.
Well, how certain should we be in that conclusion?
Is there a theorem that says that any version
of materialist theories of consciousness
are going to have this property,
or is it just, well, as far as we know,
according to our best current art,
that seems to be the case?
In other words, could the appearance of bizarreness
go away with better understanding?
Yes, it could.
And there are two separate reasons, right?
One is, kind of as you suggested, right?
Unlike what I call the dualist quadrilemma,
I don't think we have a kind of rigorous argument
that all of the choices have to be bizarre.
It's that the choices that I've seen articulated
all have bizarre consequences.
But there might be some unarticulated choice
that I haven't run across yet
that turns out to be commonsensical, right?
So I think that's possible, but empirically unlikely,
given the current state of things
and the history of philosophical discussion on this.
So it's an empirical conjecture.
The other way in which bizarreness could end up vanishing
is our intuitions and our sense of commonsense could change, right?
So the idea that the Earth moved around the Sun
was bizarre when Copernicus suggested it,
but we no longer seem to find that
a sharp violation of commonsense.
Commonsense has changed over time, right?
So it could be that someday we'll find it very commonsensical,
for example, that the United States is conscious.
You say, oh, yeah, of course.
Or maybe panpsychism.
Oh, the whole universe is conscious, right?
The ordinary person in the street, of course they think that.
Commonsense can change.
It's not a fixed point.
And we should...
So it's a little bit different
than the previous examples of the skeptical scenarios, right?
Here, unless I'm misinterpreting,
you're not arguing that we should hold out 1% credence
for some bizarre possibilities.
You're just saying, look, all the possibilities
seem to be bizarre.
We should, I guess, learn to accept that
or fold that in, not use it as a draft,
as a knockout argument against something.
We can't say, well, I can't accept that it's bizarre,
because all the other options are too.
Exactly.
So this is why people like panpsychists and idealists
like my stuff on this, right?
Because part of the reason,
the main reason I think people reject panpsychism,
for example, the idea that everything in the universe
or maybe the universe as a whole is conscious,
is that it just seems so contrary to common sense.
But if I'm right,
well, something contrary to common sense is probably true,
so maybe that's it, right?
So, right.
I mean, I do think we have to rely on common sense
to some extent.
I don't think we can just toss it out the window
when we talk about issues like this.
We don't have, in my view,
really any great tools for answering these questions,
and so we have to rely on highly imperfect ones
like common sense.
But the fact that something violates common sense
is not automatically defeated.
It does seem very similar to things
that even I have said about quantum mechanics.
I presume that we're going to put
the many-worlds interpretation of quantum mechanics
into the bucket of things that you would say
are pretty bizarre.
Yes.
I remember a quote from,
I think it was David Merman,
who is a very famous, very great physicist,
who is an epistemic person
when it comes to quantum mechanics.
So he thinks the wave function is just a tool
for understanding our knowledge and prediction,
not reflecting anything real.
And, you know, he does little surveys of the field,
et cetera, and at some point comes to many worlds,
and he says, yes, you can follow the Schrodinger equation
and its consequences, and you end up with a theory,
and the price you pay is seriousness.
So basically he's just saying, like,
surely you can't take that seriously, right?
And that's it. That's the entire argument.
And that feels like not a good enough argument to me,
because, like you said, in the context of consciousness,
for me, every version of quantum mechanics
is going to lead us somewhere strange.
Right. In fact, I think the,
I like the interpretations of quantum mechanics
as an illustration of what I call the universe of Dubaiity
and the universal bizarreness claim,
because I think maybe especially your listeners
will find that plausible, right?
Every viable interpretation of quantum mechanics is bizarre.
There's no, like, common sense way of thinking
about quantum mechanics, right?
And, you know, with apologies to the many worlds advocates,
right, they're all dubious, right?
There's at least grounds for doubting all of them.
I don't mean, when I say dubious,
I don't mean that we have to assign
a very low credence to them,
but it's reasonable to be doubtful among them,
to not feel like, ah, we're epistemically compelled
to accept many worlds over all the other interpretations.
So it's a good, interpretations of quantum mechanics
is a good example of a domain in which I think
the universal Dubaiity and universal bizarreness claim is true.
And then I want to say the same thing about, say,
the theories of consciousness,
and theories of the fundamental structure of the cosmos.
And both of those, I think, are, I mean,
the interpretation of quantum mechanics
and the nature of consciousness are both part of
the fundamental structure of the cosmos.
I kind of almost get that for free once you get those two.
You know, I generally, when pressed,
put my credence in many worlds at between 90% and 95%.
You know, depending on the time of day,
I'll give one of those two numbers.
And I did that in conversation with Philip Goff,
the famous panpsychist and previous mindscape cast,
and he was just flabbergasted.
He's like, you give a 95% credence
to the many worlds interpretation of quantum mechanics.
But dude, you're a panpsychist.
You think electrons have feelings.
Don't give me a hard time for giving large credence
to following the Schrodinger equation.
I'm sorry.
Right. Totally fair. Totally fair.
I mean, I wouldn't give many worlds quite that high
in interpretation.
I think we should be more epistemically cautious
about our favorite interpretation of quantum mechanics.
But yeah, there's room for reasonable disagreement.
I mean, I think if you're in the ballpark of 90 to 95%,
you're getting on the cusp of denying universal dubiety.
But you know, how, what exactly counts as being dubious
is kind of a fuzzy.
You do suggest in the book that when you're in this position
where every option is bizarre,
we should give fairly large credences
to the competing possibilities
because we kind of don't have a right to be too confident
about preferring one bizarre alternative
to other bizarre alternatives.
We shouldn't be too definitive.
Yes.
I think that's generally true
about the kinds of questions that we're asking
because I think we have basically three
broad types of epistemic grounds
for choosing among these theories, right?
One is common sense,
which is that what we've already talked about
is going to be imperfect
and things are going to violate it.
These theories are going to violate it
in one respect or another.
Another is scientific evidence.
You know, just kind of direct scientific evidence,
you know, like measure it, right?
And on something like whether electrons have souls
or what interpretation of quantum mechanics is correct,
we can't now at least run an experiment that says,
ah, yeah, this experiment proves,
obviously on the face of it,
that many worlds interpretation, right?
And then the third tool we have is something
like theoretical elegance.
And again, that's kind of going to be indecisive
because, you know, there's something elegant
about panpsychism
and there's something elegant about materialism
and there's something elegant about many worlds
and there's something elegant about other approaches too.
So these are not going to be,
they're going to be trade-offs among these very imperfect ways
of trying to settle these questions
rather than
bronze solid grounds.
Well, I wanted to ask you this specifically
in the context of quantum mechanics
because I've put it the following way sometimes.
I wanted to see how it fits in with your views.
If you take something like hidden variables,
versions of quantum mechanics,
so those listeners who don't know what I'm talking about,
we did an episode with Tim Maudlin recently
where he will explain.
And in those theories, you have particles
and they have locations.
And that's what you observe when you do a measurement
and you also have a wave function.
The phenomenology is much closer to the world
than it is in something like many worlds
where you have this abstract wave function
and there's many copies of reality, etc.
I think that there's much less elegance, simplicity,
austerity to the hidden variables version
as a theory.
I think this is indisputable.
Do you agree that it's the best theory or not?
You should also agree it's a clunkier theory
than many worlds.
Many worlds is very simple and austere,
but I should also accept that many worlds
is much further away from our everyday life
and our experience than the hidden variables theory is.
So the question is how do we weigh
these different considerations?
It's good to have a simple theory.
It's also good to have one that tells you pretty directly
and immediately what it predicts and how to understand it.
How do we be good philosophers and scientists
when we're faced with that kind of choice?
Right, exactly.
And I'd say just leave that hanging as a question.
So I am inclined to agree.
You're much more expert on this than I am,
but one of the things that I like about many worlds
is that it is have a certain kind of simplicity to it.
And these other theories all seem to involve
a lot of fussing around.
But right, how do you weigh that against other aspects
that reasonably draw people to resist many worlds
and prefer these other approaches?
And I don't think that there is a really good general answer
to that kind of question.
And that's one of the reasons to have kind of
non-extreme credences in these various theoretical possibilities.
Good, yeah.
And if you do have non-extreme credences,
then you can hope for progress.
You can hope to get better.
I guess maybe to wind up the conversation,
I like giving actionable advice to the people out there.
We've talked a little about how to deal with these crazy things.
Maybe to go back to that idea that I'd never heard of before,
Nicolosi and discounting.
Maybe that's the same idea as when your credences get small enough,
I'm allowed to stop thinking about it.
Is that right?
That is basically the idea, yeah.
That's basically the idea.
I think that idea is important,
but maybe part of your message in the book is
don't be quite so quick to dismiss the tinier, more bizarre possibilities.
I don't know.
Is that right?
Yes.
That is one of the messages.
Absolutely.
I think that people will tend to have a gut reaction
against views that strike them as bizarre,
whether it's many worlds or panpsychism
or the idea that only humans have souls or whatever it is.
I think there's reason to take that kind of reaction seriously,
but there's also reason to not just rely on that
and to allow that some of these theories that you might think are
so bizarre as to be absurd,
maybe they're only bizarre and not actually absurd.
I guess I'm caught maybe in a little bit of hypocrisy here
because that's exactly what I want to say to David Merman and his friends.
He will just dismiss many worlds,
even though he's a brilliant physicist,
he'll just say, that's too bizarre.
I'm just not going to accept that.
I want to say, no, you have to take it seriously.
But then there are other people, panpsychists,
maybe you're an example, who I will say,
no, that's too bizarre.
I don't need it.
I'm not quite sure what the principle stance is here.
Right, yeah.
Maybe you should give a little bit of your credence space to panpsychism.
Just a little.
Maybe here is the issue.
There's sort of in principle credence space
and then there's what I will spend my time worrying about credence space.
When the credence has become so small,
I'm not going to lose sleep over it,
even if maybe someday evidence will come in that will change my mind.
Right, yeah, that's fair.
That's fair, yeah.
Especially as an academic choice, right?
So there's also this question of,
what do you spend your academic time thinking about?
What do you invest your energy in?
And even if you were to say, give a non-trivial,
say, 5% credence to panpsychism, that's not tiny.
But that might not be worth enough of your academic time
to build theories on.
I have spent more time than my credence would warrant
thinking about panpsychism,
so I actually take this advice very well.
You've given it more than it's 5% due.
I think so, I think so.
Anyway, Eric Schwitzcape, if it was all a dream,
it was a very fun dream to have.
So I appreciate, thanks very much for being on the Mindscape podcast.
Yeah, thanks for having me. It's been fun.
Thank you.
