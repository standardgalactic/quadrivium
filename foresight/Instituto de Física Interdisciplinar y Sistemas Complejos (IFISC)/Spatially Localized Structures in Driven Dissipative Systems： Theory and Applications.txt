Okay, yeah, thank you everyone, thanks for coming, well it's a great pleasure to do this
all together today, make up your blog, and while your blog is busy, that's part of most
of the other state activities here in the U.S. that you want to discuss in the future,
you know, and well, if you can use original contract, I'm looking at your blog, it's
in the U.K. of the United States, he's, he got his beauty in Harvard University,
and then he was in Cambridge, and eventually he ended up as a professor in England,
he's a professor since 1987.
I will not go through his very long career, okay, there's a very large number of papers
and models, I'll just say he's a, well, he's a fellow of the American Geo-society,
and of the science, the society where he's here, and he's also a tournament scouser
in the University of Oxford here in Bruce, an University of the U.S.
Well, again, I'll not go through all of these, but he is an extraordinary person,
but I must say without any doubt, he's one of the people who know more about
the issue of thermodynamics.
He's probably a local, so I go out, and he's a, he's a good person to have in here
who's going to give a talk in front of him, well, he's a general talk, so I hope you will
join about, about the mission of the organization and the topic that we will go on a lot
and that will be very easy for you to do.
So, I don't know what to say, of course.
Thank you, Damian.
So, it's a great pleasure to be at IFISC again.
I was here some 12 years ago for an extended period invited by Manuel Matias,
and I enjoyed that visit as well as this one, of course.
So, thank you for hosting me.
So, I was asked to give a general talk about spatial acquisition.
This is a topic that I started working on since my last visit to IFISC.
So, this will not be a repetition in case there are any people who were here 12 years ago.
So, I'm going to start by giving some examples of spatial localized structures
and explain the origins of these structures, kind of in hand-waving terms.
And then I will describe a mathematical model which captures a lot of the behavior
that is seen in the experiment.
And then I will extend the theory a little bit to two dimensions and more.
And I'll mention in particular some examples from fluid mechanics,
which I think are very interesting.
And in fact, it was fluid mechanics that got me interested in spatial localization in the first place.
So, let's start with some simple examples of localized structures.
So, this is an example of buckling.
This is the kind of experiment that you can do in your bathroom.
It's not a very perfect experiment, but you get the idea is that you take a cylinder and you compress it.
And it doesn't, you know, if you don't compress it too much, it will just compress partially.
And in a numerical simulation of this process, you see that it buckles along the mid-secumference, as you can see here.
You can see these cellular structures form that resemble these kinds of structures that you see in the experiment.
So, how does one think about these kinds of structures?
Well, here is the way that people who work in dynamical systems would think about this.
So, on the vertical axis, I have a parameter that I'm varying.
This is the load that I apply to the cylinder.
And on the horizontal axis is the response of the system to that load.
In other words, how much does it contract?
And what you see here is that the onset of linear instability occurs somewhere over here.
So, this is where the perfect cylinder first starts to buckle.
And from this point, there is a branch of stationary, steady solutions, which are all partially buckled.
And they go along here and go through this kind of a curve.
So, let me explain in a few words what happens along this curve.
So, this blue curve represents an unstable equilibrium.
If I perturb the cylinder to the right of this blue curve, then it's just going to collapse.
So, this is a marginal state.
But what is interesting about this marginal state, if I follow it as a function of the applied load that it turns around here.
And at this point, I can increase the load and my partially buckled cylinder will support that load.
So, it gains some strength up to some point where an increase in load makes it collapse a little more.
And then I can load it up some more like this and then it'll collapse again and so on.
So, you get this sequence of partially collapsed states and what they look like is something like this.
So, this is the unloaded cylinder.
So, this is the vertical direction.
This is the circumference.
What you see is this band of cells along the mid perimeter.
And when you go from A to this region, you will have four rows of these cells.
When you go from here to B, you will have six rows of these cells.
And these are examples of partially buckled states or spatial localized structures.
The reason they are spatial localized is because the cylinder here is not buckled.
It's not buckled here.
It's just buckled in some region.
I'm going to give you some more examples with the same flavor.
So, here is an example of a ferrofluid experiment.
So, you take a petri dish and you fill it with a suspension of very small magnetic dark holes.
Held in suspension by surfactant.
And then you apply a normal vertical magnetic field.
Stationary time independent DC magnetic field.
And what happens is initially the surfaces just remain flat.
Modulate these end effects which I'm not going to talk about.
But then when the strength of the magnetic field becomes too strong,
the whole surface of the fluid buckles into a hexagonal pattern.
And that occurs at this value of the applied magnetic field.
So, the system jumps to a new state.
It's a state of hexagonal peaks.
And as you increase the magnetic field, there are any defects here.
And up here you have almost perfect hexagonal structure.
And then when you decrease the magnetic field, the hexagonal structure remains.
The height of the peaks decreases.
And here they collapse back to the flat interface.
So, you have a system here with a large hysteresis loop.
And it's these hysteresis loops that are very interesting to me.
Because within those hysteresis loops, in some range of parameters,
you can do the following experiment that's shown here.
What you can do is you can bring the bar magnet to the surface.
You pull out a peak.
The bar magnet pulls out a peak.
You remove the bar magnet.
And the peak, instead of falling back into the flat interface, remains sitting there.
That's very counterintuitive.
So now that you've done it once, you can do it again.
You can bring the bar magnet to another region of the fluid.
You pull out a peak.
You remove the bar magnet and the peak remains.
And you can do this many times.
And when you do that many times, you get a sequence of individual peaks
that just sit there in equilibrium.
These are indicated by this sequence of dots,
each dot corresponding to a different number of peaks.
So you have one peak, two peaks there.
And these peaks can form clumps, bound states.
And this is from another experiment, a more recent experiment.
And you see these kind of patches of hexagons,
where the hexagons are confined to some region.
And outside, there is no displacement,
essentially no displacement of the interface.
So I'm going to talk about these kinds of structures.
So a lot of people here are interested in vegetation patterns.
So I can't resist showing some examples.
These are also associated with what's called a subcritical instability.
And the reason is the following.
If I imagine that I have a plant growing in some region,
then the plant may have extended roots in the horizontal direction
and the roots take up moisture, of course,
and prevent the growth of the plant to the side.
So this is a mechanism for preferring the plant that's already there.
That's the notion of subcritical instability.
Alternatively, in various deserts, and we have these deserts in California,
you may have a situation where the surface of the desert
is covered by a kind of biofilm, a crust, which is essentially impermeable.
And if it does happen to rain, then any water that's collected
will run into regions where the crust is broken
and it's broken exactly where plants are, right?
So this gives you another mechanism for positive feedback,
whereby the existence of plants, you know,
leads to the collection of water
and therefore enhances the growth of those plants.
So these are the basic mechanisms believed to be responsible
for many types of vegetation structures,
including these remarkable so-called fairy circles.
This is from Namibia, an aerial picture.
This is a region that's covered by bush.
But the bush is broken by these little bare circles,
typically four kilometers across.
And you can see that there's more growth
around the boundary of the circle
because there is less competition for water.
Half of the region is dry and there is no water collected.
So it's believed that these types of mechanisms
are responsible for the presence of these kinds of localized structures.
Now localized structures can be dynamic,
and this is from an old experiment from Harry Sweeney's lab in Austin, in Texas.
You take, again, a Petri dish.
You fill it with very small brass beads,
and then you vibrate the dish up and down
with a certain frequency and a certain amplitude.
And if you do it in the right range of parameters,
you can get structures which oscillate up and down.
So for a while it's a peak,
and then one period of the forcing is a crater.
It's a subharmonic instability.
The interesting thing about this structure is that it's localized in state.
And this is created in the same sort of way
as in that ferrofluid experiment that I mentioned earlier.
This is what it looks like in reflected light.
So this is the peak that I showed you at one period.
One period of the forcing later it forms a crater,
and then it goes back to a peak.
So it's an oscillation between these two states.
This is what it looks like from the side.
These things can also form bound structures,
like these bound states of a peak and a crater.
One period later the peak becomes a crater,
the crater becomes a peak.
They oscillate out of phase like this and remain bound.
And you can get chains of these structures.
You can get these kind of molecules with one peak,
three craters.
A period later you have a crater surrounded by three peaks.
There are a lot of different structures, of course,
that can be made in two dimensions.
This is a nice example from the lab of Hans-Gerl Provence in MÃ¼nster.
He takes two electrodes and partially evacuates the region between them.
It fills it with different types of gas.
And then he puts a voltage difference across the electrodes.
If the voltage difference is large enough,
you get electrical breakdown,
meaning that you get current filaments
shorting the gap between the electrodes.
And of course that radiates,
and so you can see the current filaments.
And this is basically what the experiment is.
And what he finds are the same kinds of structures
that we've been talking about.
You can get a stationary hexagonal pattern,
like the pattern of peaks in the ferrofluid experiment,
that I mentioned.
You can get a structure of these current filaments
where the current filaments are not stationary,
but move around in complicated ways.
And so the analogy might be that this is more like a liquid state
as opposed to a crystalline state.
You can get a gas-like state
where you have fewer of these structures that are in motion.
But you can also get the sort of chains
that we were talking about earlier, networks.
And you can get states where you have, for example,
part of the region is solidified or crystallized,
and some of these current filaments are free to move around
in an irregular fashion.
Now what is interesting about a lot of these problems
is that, first of all, they behave in a similar way,
but also that we don't necessarily even know
the right equations to describe this.
This is a very complicated problem.
The business of the granular media,
you know the brass beads moving up.
Now we don't have an aviastope equation for granular media.
And so what we would like to be able to do
is describe a lot of these structures in some generic way,
which doesn't depend on the basic physics
that's responsible for these different types of behavior
that you see here,
and that captures the common behavior
that's exhibited by all these different systems.
Now there are examples of this in fluid mechanics.
Fluid mechanics is nice,
because I actually know what the equations are.
And so we can study the equations numerically,
and I'll talk about some results that we've obtained.
So this is an example of what we call convectons.
These are localized regions of convection.
And what you see here is a two-dimensional layer
of a binary mixture, a lighter and a heavier component
that is heated from below.
And in response to the applied heating,
the heavier component migrates towards the bottom boundary.
This is a cross-diffusion effect that's called the Sorai effect.
It's very well known in these types of problems.
And what you see here is the temperature fluctuations
about the linear temperature gradient.
It's hot at the bottom, cold at the top,
so there's a linear temperature gradient in the background.
But this shows the region of hot fluid rising
and cold fluid descendant.
But as you can see, the convection rows that are set up.
And the interesting thing here is that the convection
doesn't fill the whole domain.
It just fills part of the domain.
And what is interesting also, like in the examples we saw before,
is that for the same parameter values,
I can get distinct states.
All nominal is stable.
So these states are obtained for the same parameter values,
but they are different.
In an odd state, I have a descending cold plume,
rising hot plume on the opposite sides,
and here I have two rising plumes on the two sides.
So they're distinct states.
Simultaneously stable.
Just like in that buckling problem,
we had lots of simultaneously stable,
partially buckled states.
And you can get more complicated structures
like these turbulent states in couette flow.
What couette flow is, is a shear flow
between two power plates,
the top plate moving towards you,
the bottom plate moving away from you.
And you can get structures of localized turbulence,
which are inclined relative to the direction of motion of the plates.
So what do these states have in common?
Well, they can be found in one, two, and in three dimensions.
I'll talk about some three-dimensional structures at the end.
They may be stationary.
Most of the examples we've talked about were stationary.
They can propagate or they can oscillate in place,
as we saw in the oscillon example.
They are generated by finite amplitude perturbations.
Like the bar magnet that I bring to the surface to pull out a peak,
that's a finite amplitude disturbance.
And therefore the structures are fully nonlinear,
and they have to be described by methods
which go beyond linear or weakly in nonlinear theory.
And they can, of course, experience a variety of instabilities
that lead to splitting, decay, disappearance, propagation,
or localized complex dynamics, in fact.
And they form these different types of bound structures
that we looked at in the gas-like state
that you also saw in the previous slides.
Now, I want to emphasize these things are sometimes called
dissipative solitons,
but they have nothing to do with solitons.
They are not solutions of integral PDEs.
They, in fact, have very different interaction rules,
and I'll talk about some of those in a moment.
So here is my kind of toll problem
that I think is a very interesting equation.
It looks deceptively simple,
but it captures a lot of the behavior that we've seen.
And it explains why lots of systems with different physics
behave in the same way.
So what is this equation?
It's an equation for a scalar field, u, here.
This is the time derivative of u with respect to time.
The field depends on space.
For example, in a plane, this would be x, this would be y.
It has its fourth order in space,
and that's important that it's fourth order in space.
There is a bifurcation parameter like the load,
for example, when I was crushing my cylinder,
and then there is a bi-stable nonlinear term
with a destabilizing quadratic contribution
and a stabilizing cubic contribution.
So I'm going to call this equation with this FSH23,
or I can maybe have a destabilizing cubic contribution
and a stabilizing fifth order contribution.
I'm going to call that equation SH35,
SH for St. Holmberg and the 35 for these systems.
So now we can play the same game that Reinhard Richter played
in his ferrofluid experiment.
What I can do is I can go into a plane here,
and I can generate the localized finite-empadue disturbance
like bringing the bar magnet towards the surface.
And then if I'm in the right parameter regime,
and by right parameter regime I'm in the right range of S
and the associated range of R,
an interesting thing happens that the localized perturbation
that I've created will relax to a non-zero localized state.
It won't fade away.
For example, here I created one perturbation
and it created this target pattern.
Here I generated a different perturbation, created a spot.
Here I generated a third type of initial perturbation,
created a hexagonal patch.
So the same idea, generating different initial finite-empadue disturbances
and they relax to different types of localized structures.
And they're all here sitting simultaneously stable.
So let's try to understand why this might be the case.
So here is my equation, and just for simplicity,
I've written it in one dimension.
And I've also introduced this Qc, which is a length scale.
It's actually the intrinsic length scale of my crystal
that you saw in the previous slides.
And it's important that it's foreordering space,
that you have this intrinsic length scale,
that you have bistability that comes from this nonlinear term
that gives you that hysteresis loop that we saw at the beginning.
And it helps that it's spatially reversible,
that you have the symmetry x goes to minus x.
And it also helps that it has gradient dynamics.
In other words, the dynamics is boring.
What this equation means is that the system just evolves always to steady solutions
and the steady solutions correspond to a local minima of this functional f
that I'm going to refer to as the free energy of the system,
by analogy with phase transition.
So in a sense, what I'm going to be talking about is the energy landscape of the system.
And if I'm going to have multiple local solutions that are linearly stable,
all of those must correspond to local minima of f.
Of course, there'll be local maxima, there'll be saddle points,
the idea is to understand the energy landscape of this functional.
So this slide is, I guess, probably more for the students,
but I think it's actually a very important slide,
probably my most important slide.
So what I want to do is explain to you the idea of the difference
between temporal and spatial dynamics.
These are different ways of looking at the same problem.
Of course, when I'm interested in temporal dynamics,
I want to know how things evolve in time.
And what I can do, for example, to find instability of a uniform state,
u equals 0, I can perturb that state with some time-dependent perturbation
with a growth rate sigma and a spatial scale q.
That's the usual thing that we all do.
And then when sigma of particular q is positive,
you say that q grows in time.
Now, we're interested here in stationary solutions, steady solutions,
independent of time.
And where are those?
Well, those solutions only exist on the curve sigma of q equals 0.
And I've drawn that curve here, here is that curve.
So q is horizontally r, the parameter is on the vertical direction.
In this region, you have instability for some q.
Below the curve, you have no instability.
So steady solutions only exist on this curve.
And notice that if I pick this value of r, there are two types of steady solutions,
ones with wave number q minus and ones with wave number q plus.
And as I decrease r towards the onset of instability,
those two solutions come together and merge.
It's a co-lessons of two distinct wave numbers at this critical wave number qc.
And this is what you would normally call the onset of temporal instability,
because it's the minimum of this curve sigma of q.
And the way we think about this is this is a fourth order problem in space.
If I put this equal to 0, I have an ODE in four-dimensional phase space.
And I can look at spatial eigenvalues of u equals 0.
And there will be four, because it's a fourth of the problem.
And so when r is greater than this critical value, which is 0,
I actually have four eigenvalues on the imaginary axis.
This one corresponds to eigenvalue lambda is iq plus, iq minus,
and then the negative, the complex function.
And the fact that the eigenvalues are on the imaginary axis
is a consequence of the spatial versatility I mentioned.
And then as r decreases towards 0, these two come together at co-lessons.
You have eigenvalues of double multiplicity on the imaginary axis.
And then when I go below r equals 0, I have this quartet of eigenvalues,
a pair in the unstable positive real part of the complex plane
and a pair in the negative real part of the half plane.
And this is important because now I have a two-dimensional unstable manifold
whereby I can leave u equals 0,
but I can also return to u equals 0 along the stable manifold span
by these two stable eigenvalues.
And what this looks like in a picture is something like this,
is that here is u equals 0 as a function of x.
I'm leaving u equals 0 along those two directions, the unstable eigenvalue.
And I can also come back and all I have to make sure
if I want to generate the nonlinear localized solutions
is somehow that these curves connect in the nonlinear regime.
And without going into details,
you can do this using multiple scale methods.
You find that at r equals 0, there is a pair of solutions that appear from u equals 0.
The reason you have a pair of solutions, in fact more than two,
is that it's a multiple bifurcation
because those spatial wave numbers have co-lessed
and leaving you a multiple bifurcation in space,
not in time, but in space.
And the two solutions are these.
You have a periodic pattern with some amplitude that goes like the square root of minus r
because alpha is negative.
And then you also have a modulated solution
where you have a periodic solution that's modulated in envelope
by this sex-like function.
And here the spatial phase phi is arbitrary.
You can just translate the pattern as you wish.
But here I cannot pick any phi
because I cannot translate the periodic pattern relative to the envelope
by arbitrary amounts.
I have to pick certain values of phi and only 0 and phi are permitted.
So this is what we've learned.
So this is a bifurcation diagram, like the ones we've seen before.
Now the parameter is shown horizontally
and the response, the norm of the solutions, is plotted in the vertical direction.
And at r equals 0, you see that there are lots of branches coming out of there.
There is the red branch that corresponds to periodic solutions.
It's a subcritical instability
because that coefficient alpha was negative,
so solutions exist for r less than 0.
And so that solution is unstable initially
and then it requires stability at the top.
But you also get the localized solutions.
They bifurcate simultaneously with the periodic solutions.
They're also subcritical and also unstable.
But when they reach this shaded region, they start oscillating back and forth.
Here the heavy line indicates stable solutions.
And so you can see that in this region,
the localized solutions have required stability
and moreover, you can get a very large multiplicity of simultaneous with stable states.
And of course, the ones you will see will depend on how you do the experiment.
The word you put your magnet.
That depends on what kind of initial disturbance you are applying.
And what is the difference between these states?
So L0 have a peak in the middle.
And you can see that as I follow L0 like this,
the structure gradually grows and extends,
spatial extent.
L pi solutions are similar, but they have a dip in the middle.
And so we call this kind of structure,
the snakes and ladder structure of this region of localized states.
And the ladders, or the rungs of the ladder at these states here,
they correspond to asymmetrical solutions.
For example, you know, if you start with a solution,
it's a peak in the middle on the L0 branch,
and you go to state two, it becomes asymmetrical.
You can see then it becomes again more asymmetrical.
And then at the far end, it emerges as a solution with a dip in the middle.
And so it lies on the L pi branch.
These states are all unstable.
Now, if you do this for a single peak, as I've just done,
then you can also do it for pairs of peaks, right?
And you get the same sort of snaking until you fill the domain.
You can do it for these bound states.
So here is a bound state of two single peak structures.
And they lie on a figurate isola.
These lie in that shaded region.
If I have a two-peak state, they lie on this kind of figurate solution.
These ones lie on this figurate solution and so on.
The isolas depend on the separation of the structures.
So here I am changing the separation between these states.
And you can see that the isola depends on that separation.
There's a lot of possible solutions that you can get in that shaded region.
In fact, you can get more.
You can get solutions which are bound states of similar structures,
like this structure with one peak, two peaks.
At this location, by the time you get to here, you have three peaks and two peaks.
So this one has grown. This one hasn't.
When you go from two to one, this one remains the same.
This one grows and so on.
There's a huge variety of different solutions inside the shaded region.
So I'd like now to tell you why this region might support this great variety of different solutions.
And I'm going to do it by analogy with what you know about phase transitions.
So what I'm drawing here is my parameter. You can think of that as temperature.
And here is the response of the system.
And so this is the periodic state.
Remember, it was unstable. It became stable at the fold.
And there is a parameter value here at which the periodic state actually has the same energy as the homogeneous state.
So this is what in thermodynamics you would call a Maxwell point.
And I want to make use of that analogy to understand why we can get lots of different structures in that shaded region of parameter space.
So imagine in the middle here that I'm plotting the density as a function of space.
And I'm doing it at the critical temperature.
For example, think of this as a liquid and this as gas.
So the liquid has higher density. This has lower density.
Then in the absence of surface tension, I can put any number of interfaces in there.
It doesn't cost me anything.
So I can get very complicated states.
Now if I change the temperature, for example, I increase the temperature above critical where what happens?
Then the liquid wants to evaporate and that means that this front is going to move in.
This one is going to move in and eventually the drop is going to disappear.
So there's no steady solution.
No steady solution when I change the temperature away from critical temperature.
If I decrease the temperature, then of course I have condensation and so the fronts are going to move in the opposite direction and the drop is going to grow.
So that's the thing I want to bear in mind.
But now I want to think about what happens if I don't have coexistence between two homogeneous phases like the gas and the liquid phases.
But instead let's say I have a liquid and I have a solid, a crystal structure, a medium.
Then things change and they change in an important way and that was originally recognized by Yves Poivre long time ago.
You have a front here that you're trying to get to move but this front is pinned to the potential of the heterogeneity behind it and so it's not free to move.
You have to change the temperature by a finite amount before that front can move and for example the crystal can invade the liquid.
We call that crystallization.
And inside that region generated by this pinning potential, that's where all the localized states exist that I've been talking about.
There's a mathematical way of thinking about this and some of you may prefer that even though this is a physics institute, right?
So I mean four dimensions, right?
It's a spatial way of looking at things and it turns out that this equation has a spatial Hamiltonian.
So there's a conserved quantity so I can go from four to three and then I can look at the wavelength one map that takes me from three to two and so I can draw things in two dimensions.
And so here is the fixed point that corresponds to the homogeneous state.
Here is the fixed point that corresponds to the periodic state that corresponds to the fixed point under this wavelength one map.
And these are all associated with stable and unstable manifolds because as I showed you we have some stable eigenvalues, some unstable eigenvalues.
And what you see here for example at the fold here is that I have a tangency between the unstable manifold of this point and the stable manifold of this point.
And then when I cross inside the shaded region which is this region here, I have transversal intersections as you can see here.
And the unstable manifold of the homogeneous state actually has to intersect the stable manifold of the homogeneous state along the line that corresponds to the fixed point subspace.
So the reflection symmetry x goes to minus.
And so this point here, run backwards, goes back to the homogeneous state, run this way, goes to the homogeneous state.
So it's a localized solution.
And you can also see those asymmetric solutions, they also have to form the same mechanism.
And they all accumulate, as you see from this heterogeneic tango, they all accumulate on the periodic orbit as this black dot over here.
So that's what happens in that shaded region is you have these transversal intersections of stable and stable.
And one way to think about this is in terms of fronts, and this is a front that connects the homogeneous state to the periodic solution.
This is another front of the same time. This one is stable, this one is unstable.
You put two of these back to back, you get state one, it's an unstable state.
You put two of these back to back, you get a stable state.
And if you do one of each, you're going to get an unstable, wrong state.
And I just want to say a couple words about the wavelength selection in that shaded region.
As I vary my parameter R, the wavelength can change across that of the periodic oscillations, the localized periodic oscillations,
because there's no boundaries.
And the wavelength that is selected, as you can see here, is the wavelength determined by the requirement that this spatial Hamiltonian is conserved.
That spatial Hamiltonian contains the homogeneous state and the periodic solution,
and any connection between those two has to lie in the level set H equals zero of this Hamiltonian.
So we understand some things about this.
If I go outside of this pinning region, right, so the pinning region has to straddle the Maxwell point, which is this dash dotted line,
I can either go this way or this way outside, then of course I have no localized stationary solutions,
and instead I have dynamical solutions.
And here is an example, space, time increasing upwards of what happens if I go to the right of the pinning region.
In the region to the right, the state that has lowest energy is the periodic state,
and the system approaches a periodic state through a sequence of nucleations that generate new wavelengths on either side.
And so this is an example of a stable state, a periodic state invading another stable state,
but the periodic state has lower energy, so it's preferred.
And you can develop some theory to understand what is the frequency of nucleation events as a function of the parameter, and so on.
And the same sort of thing happens if you go to the other side where the preferred state is the homogeneous state,
and so the periodic structure eventually disappears through these annihilation events.
Now in 2D things are more interesting, of course,
and so I just want to say a few words about, so this is now x and y, not time but y,
and I had a localized structure, a localized region of stripes,
and the front here was unstable to a y-dependent perturbation,
and that deepened the front so that eventually the whole region is taken over by a hexagonal pattern.
But that doesn't have to happen.
In a different region, the hexagons only invade inward, and you generate a localized patch of hexagons like this,
or in another region you can get structures where the front's deepened and send out these fingers,
which then buckle because the wavelength that is selected by this kind of moving front is not the equilibrium wavelength.
And so the system then relaxes to what would be the equilibrium wavelength, subsequent to the passage of the front.
And this is the same sort of thing for the 3.5Ks, you can get these kind of finger structures.
Here is a labyrinthine pattern that is generated by this dynamical evolution,
the moving front between the homogeneous and structured state.
A couple words about how these structures might be connected, I think this is quite interesting.
So this dot here, mu is minus r, so this red dot corresponds to a state like this,
norm in the vertical direction.
If I follow this in one direction, it's going to follow the state up to this red dot here,
and what you see here is that these fingers have grown out.
These are the steady solutions of the Swift-Holbert equation, 3.5.1.
If I follow the red dot in the opposite direction, it generates this kind of structure.
And what you see here is that these dots here or the spots reconnect horizontally
and create these stripes as the front moves away from the central region.
So these kinds of structures and these kind of structures are actually on the same solution branch of the Swift-Holbert equation,
which is quite interesting.
And then you get all these kinds of interconnections that I talked about, there's many more of them in 2D.
You can get lots of isolas of these checkerboard structures.
You can get structures that have this kind of lozenge appearance.
You have fronts which are pinned because of the oscillation behind them.
And they're also pinned here because of the gradient in the wave number due to the curved interface.
And then you have these things which we've called worms, which are very strange things.
And if people here are interested in PDEs, you might ask, you know, what's happening here at that point?
It's not a singularity because the PDE doesn't permit.
Old steady solutions?
Old steady? No. Well, some are stable.
I don't know whether specifically these ones are stable.
But as you go along here, the stability changes at falls in the same sort of way.
But I think it's very interesting that you form these kinds of structures that have these cusp behavior.
It's not understood at all why this might be possible.
I just want to say a few words.
So this is an attempt to draw in parameter space.
So this is R now, and this is the coefficient of the quadratic term for SH23 squared.
You know, where the different kinds of localized structures are.
I want to say a few words about the hexagons here.
So this shows the snaking branch of hexagonal structures.
And what you see that at point one here, what you see is a hexagonal patch like some of the things we saw in earlier pictures.
When I go from one to two, I've nucleated a cell in the middle of each phase.
When I go from two to three, I nucleate new solutions on either side, but I'm still missing the corners.
And when I get to four, I actually generated a full patch so the process can repeat.
So there's a very regular ordered way whereby these structures grow as you quasi-statically vary the parameter or temperature or whatever you want to call it.
And here is a situation with these kind of stripe-like states.
The small oscillations here correspond to adding cells along each row, and then each big row is associated with these large-scale excursions.
So let me go back to now fluid mechanics, because time is running.
So you've seen this picture, these odd and even convectons.
I want to show you how they're generated in the fluid problem.
So here is space, because I have a layer, so I'm just looking at what happens at mid-level.
I just want to see what the temperature looks like at mid-level, and I'm plotting it at a sequence of successive times.
And what you see here is that the initial state is a kind of spatial-temporal complex state,
but that state undergoes a focusing instability you can see over here.
And after some further time, this solution is not a stationary solution of the system,
but in fact it evolves by that same erosion of wavelengths that we saw in the Svthomberg equation.
It collapses back into the chaotic state, and then, of course, that's unstable to the focusing instability, and so the process repeats.
And it generates this kind of relaxation time trace.
We have the chaotic state, here is the focusing instability, here is the erosion of the structure, and the process repeats.
And now you change the parameter from 1774 to 1775, and now the solution remains as far as you know forever.
Here is that focusing instability, it's generated the structure, suppressed oscillations outside,
and all the heat now is transported through this hole, if you like, through this layer that's been self-generated by this focusing instability.
And so this is the bifurcation diagram. This is a measure of the temperature difference across the system.
Here is the response of the system, it's the heat transported.
Here was that primary instability that generated the chaotic state, and here is the appearance of the localized solution,
stationary stable, numerically stable localized solutions that I just showed you, and notice they are inside this hysteresis loop.
They coexist with spatially extended, you know, more or less standard convection.
I've separated the odd and even structures, just so you can see, and I'm going to compare the solutions at these successive points.
For the odd ones, you can see that I'm picking up heavier material from below like this, and then I'm picking up lighter material from above,
because the rolls at the two ends rotate in the same direction, and so I have actually like a little pump that picks up stuff from one side and deposits it on the other side.
And then the direction of the pump changes when I go from A to C, because I've added rolls in the opposite direction at each end,
and so the pumping now is in the opposite direction.
And if I have an even state, then of course the rolls are in opposite directions at the two ends,
so they either pick up the heavier stuff from the bottom, or they pick up the lighter stuff from above.
If I go outside that pinning region, I get behavior that's indistinguishable from the Swigfumberg equation, yet this is Navier-Stokes.
Structure grows by the successive nucleation events that you saw earlier.
I want to say a few words about collisions of these things, because they are one of the things that distinguishes the local structures that we've been talking about from solitons.
And so the way we do that is as follows. We take the three-fold Swigfumberg equation, and we add a quadratic term.
Why do we do that? We do it for two reasons.
One is that the quadratic term breaks the gradient structure of the system, so structures can now move, but also that it breaks the symmetry U goes to minus U.
And that means that structures that were kept fixed stationary by diagonal reflection, you know, left, right, up, down, those solutions are no longer exist, they won't exist anymore,
and therefore whatever takes their place has to move.
Because it messes up my beautiful diagram, but you have lots of possible stable solutions that you can pick up that are now moving.
They have the solutions that were odd solutions, odd parity solutions, when epsilon was zero.
And so here I've taken two of those solutions back to back, and I collide them.
And notice that it's a very inelastic collision, right?
Stick and form a different localized solution.
I can take different solutions, you know, the different structures that are moving and they stick,
or I can take solutions that move in the same direction, the skinny ones travel more rapidly than the fat ones,
and so they catch up and eventually they form a moving localized solution over here.
Here I have a collision with a stationary even solution, and I call this an attractive solution because the fronts here are of opposite type,
down here, up here, and that leads to attraction between these structures.
If I have the same front on both sides that leads to repulsion, and you can see that this little guy hits this one, and then the whole thing moves to the right.
So we can do the same thing in fluid mechanics with these convectons.
The way we do that is we have to change the boundary conditions at the top, so they are now different from those at the bottom.
For example, we can allow Newton's law of cooling to allow temperature heat to escape from the top boundary.
That's a nice, physically realizable way of doing this.
And if we do that, the even solutions remain stationary, just as in the previous suit Hombra example,
and the solutions that were odd are now moving.
After all, Navier-Stokes is not a gradient system, right?
And so I can play the same game.
So here I've taken two solutions with identical solutions with opposite speed,
and I collide them and they glue in the same sort of way as in the Sweden-Homberg equation.
It's a little more complicated because their waves generated is not a gradient system, as I mentioned,
but it behaves in a somewhat similar way.
Here I have a stationary solution that's being hit by a moving one.
And notice that the two fronts are opposite, so this is an attractive solution,
and you can see these are coming together.
It's an asymmetric collision, a lot of radiation, but eventually you get a local solution.
Here I have a repulsive interaction.
This was a stationary solution that's being pushed to the right by the proximity of this guy.
The two fronts are the same at both ends, but eventually they glue again as in the Sweden-Homberg example.
How much time do I have?
Five more minutes.
Five more minutes?
Okay.
I'll just show a little movie.
So we can do this also in three dimensions.
So this is an example of a convecting system in a porous medium.
Same sort of system, heated from below.
You have a mixture of a lighter and a heavier component.
The Navier-Stokes equation is simplified because it's a porous medium, and then we solve these equations.
And of course the bifurcation diagram is a little worse, as you might imagine.
But basically what we do through dynamical simulations, we find the localized solution that is not a steady solution.
It's not an equilibrium solution, but the system poses at this kind of solution.
Then we can converge it, and then we can follow that solution in the parameter space.
And so this hopefully will work.
And what you should see here is a green dot,
marching along here, and on this panel you see the structures that are following that correspond to the location of the green dot.
So this is not temporal evolution.
This is just a sequence of steady equilibrium solution of the PDE that I had on the previous slide.
And you can see these three-dimensional structures growing.
They form this kind of...
A periodic horizontal, but of course non-trivial in the vertical direction.
Well, we have no mass flux and fixed temperature.
So the mass flux boundary condition is like a boundary condition in concentration.
And it's no slip.
So what's basically happening here is that the solution is trying to find that spatially extended state,
that fills the whole domain, but it's having a hard time.
And it's not actually clear in this problem that he ever finds a periodic solution that fills the whole domain.
Because you follow it and it just keeps moving in and out like this,
and it forms these bizarre shapes that people have never seen in convection, as far as I know.
But these are all steady solutions of that system.
And many are stable if you impose some reflection symmetry that we know.
Okay, last thing I want to mention is same things occur in plain coed flow.
So remember that shear flow that I showed you at the beginning with one plate going towards you,
one plate going away from you.
What you see here are periodic array vortices.
So this is a top view.
These periodic array vortices would fill the whole domain.
But they're also localized solutions.
They're localized in the transverse direction.
And this is what it looks like in a vertical cross section through that system.
You can see these vortices.
And there are two of them.
These ones travel because one of them closer to one of the boundary than to the other boundary.
So they travel partly with the boundary.
These ones have diagonal symmetry.
So they're stationary.
And they do the same kind of snaking, the same cross links that you saw in the Swift-Holmberg equation.
And to me, this is really interesting because these kinds of shear flow problems have been studied for more than 100 years.
And it's only taken this way of looking at these problems to try to look for new types of solutions in these very, very old problems.
They go back to Rayleigh and all the famous fluid machinations from the end of the 19th, early 20th century.
So here are my conclusions.
So I've shown you that the growth process of these stationary localized structures in dissipative systems have lots of rules whereby they grow in size,
whereby their stability changes and how they interact.
These things are independent of the physics.
But they're captured by this Swift-Holmberg model in a very effective way.
So much so that, for example, I could make predictions based on the Swift-Holmberg model for the collision, for example.
And they worked out very well in a much more complicated Navier-Stokes system.
And you might ask, how is that even possible?
Because the Swift-Holmberg has nothing to do with fluid mechanics.
And the reason this works is because the structures I'm talking about are robust in the sense that they are there because of transverse intersections
between stable and unstable manifolds in the spatial dynamics description of the system.
And of course, if you have transverse intersections of stable and stable manifolds, you can't unhook those.
You can change parameters and they're still transverse intersections.
You can add an extra term and you still have a transverse intersection.
So you can change not just parameters, you can change equations and these structures are still there.
So that doesn't have anything to do with physics per se, but it's a good mathematical model for understanding the robustness of the behavior that I described.
It was useful for me to use the variation of the gradient structure of the dynamics and the fact that it's a Hamiltonian in space,
in this case of the Swift-Holmberg equation.
But because of what I've just said, those things are irrelevant, actually.
So it works for Navier-Stokes, which is neither a gradient system and it's also, of course, not a spatial Hamiltonian system.
Anyway, I wrote the review article about this if some people are interested.
So thank you for your attention.
Thank you very much.
I want to make you a question that I have precisely about the very last thing that you were saying.
This thing that when you study the structure of Navier-Stokes, you can capture it in a variational equation.
What is the property of this thing that is allowing you to understand what a non-variational equation like Navier-Stokes is being understood by a variational equation?
Is it spatial reversibility in a way?
Well, the spatial reversibility helps, but of course if I have systems in a plane,
then it's spatial reversibility just in a single variable is very nice because it makes the spatial variable time-like.
That's why you get these quartets of eigenvalues.
It's more complicated if you are in a plane because what does it mean to have two time-like solutions?
You have to think about that.
But really the key thing is the dimension of the stable and unstable manifolds,
of for example in the Convecton case of the conduction solution.
So I have a conduction solution which is homogeneous, but there are some stable directions and there are some unstable directions.
And I need these manifolds to be of sufficiently high dimension so I get these structurally stable transverse intersections.
If it's only one-dimensional this way and one-dimensional this way, they're going to miss each other and you won't get these robust structures.
So the dimensions have to work out.
You were writing R, the parameter, I love that.
You were writing the contour parameter, so the rest is all valid.
The formation of this solution is all valid also when R is an object.
Yes, yes.
But then you were making an argument looking at these eigenvalues, but to go from one to the other you were actually changing R.
Yes, so what I was doing in that Swift-Homberg example was I was trying to find a region in R space in which these dimensions actually work out.
So in the case of the Swift-Homberg equation, I needed to have a two-dimensional stable manifold and two-dimensional unstable manifold in order for these things to meet in the nonlinear regime.
And I did that by going into the subcritical regime, because in the supercritical regime I had no stable non-stable direction.
That was the case R equals 0 with the eigenvalues on the imaginary axis.
But the way I got eigenvalues off the imaginary axis was by decreasing R below R equals 0.
So that means I went into the subcritical regime where I had coexistence between the homogeneous solution and the periodic state.
So that's really what's behind.
And that's the kind of calculation you have to do for each separate problem, including the Navier-Stokes problem.
The Navier-Stokes problem is much higher-dimensional of course, because you have a Laplacian in the horizontal velocity component,
you have two horizontal components, you have the temperature, you have the concentration, right?
So you have already five Laplacians, right?
So it's in the spatial description, it's already in ten-dimensional phase space.
So it's a much more complicated situation than the Swift-Homberg.
So Swift-Homberg is really nice because it's actually the minimal, it's the minimal size of the phase space,
the dimension of the phase space that allows this behavior to take place.
So in that sense it's the simplest model of this behavior.
Could you list the other different properties between localized structures and sources?
So one is the collisions, and maybe there are other different differences between localized structures and sources.
I mean there are many differences.
The collisions of course are the most important thing.
I mean the main difference is that these structures physically only exist if I'm driving the system, right?
So what happens inside this convector is that I'm putting energy, I'm heating the system, and that energy is being dissipated inside the structure.
So the structure is an equilibrium state only in the sense that energy in goes out as dissipation.
But it's not a thermodynamically equilibrium structure, right?
Because it's only an equilibrium structure in the sense that I have a balance between energy in and energy out.
And of course solitons are, you know, completely different structures.
There's no dissipation inside the structure.
And of course you're also not no energy input because it's a conservative system.
I'm not sure I answered your question, but...
You discussed the interaction of this sort of...
What kind of interaction?
When you have some...
You introduce some sort of activation, as we've talked about, to introduce a sort of drift.
But even without the drift, the structures should interact by details.
So if you have two such structures, they should somehow interact.
They do.
There's no need to force them with the drift.
So how much is general of this interaction?
I mean, what...
I mean, I guess that something should be similar to the one where you also have the drift.
These two structures collide.
They all rejoin and mess together.
It wasn't because of anything.
Well, so the important thing about being in the subcritical regime is that the...
You have these fronts, and the fronts have oscillatory tails.
Because the eigenvalues have a non-zero imaginary part.
And so if I have two of these structures, they will interact through these oscillatory tails,
and the tails lock.
And so by themselves, they will not start to drift because they're actually a stationary solution.
Because you can push on them, and if you push hard enough, they will unlock.
So that would be one way to do what you say.
What I like about the way we do this is we're not actually putting any extra forces into the system.
We're actually just changing the boundary conditions to change the symmetry,
and then everything happens spontaneously.
You know, we don't have to reach in and push on these things.
But we could.
But basically, you take the symmetry, and then of course,
the drift is proportional to the symmetry, like that.
That's right.
Yeah.
So that would be an easy work transition for now.
Except in our case, the direction of motion is generated spontaneously
by whatever initial perturbation there is.
Because breaking the symmetry at the top relative to the boundary condition at the bottom,
that doesn't select left over right.
The system selects that.
So it's spontaneous symmetry breaking as opposed to forced symmetry breaking,
which is what you're referring to.
And absolutely, we could do that.
I have another question.
Most of these structures would be considered for how symmetric they are,
except for this rating at the end of, so they are,
what's called, busy, light structure.
Because one is in front, if they're symmetric,
you're in two states.
If one considers structures that arise on a block of that symmetry,
in principle, a symmetry of the archival and all that,
how much is known in those structures?
Steer, shape, I mean, I, of course,
we can find some sort of human part,
is the knowledge of extension in this case also?
Well, I mean, less is known.
No surprise.
I mean, so you can think, you know,
if you're interested in reaction diffusion problems,
for example, when you're interested in spiral waves and things like that.
And there are, you know, situations where you can get localized spirals
and things like that, in fact.
Maybe that's not a good example.
I was trying to think of a chiral state.
You can certainly get localized spirals
in these kind of field periods.
Absolutely.
But it won't have localized spirals.
And the reason is that it's not of high enough order.
So, that's, but it's, yeah, if you want to think in terms of
Ginsberg-Landau, of course you can.
You need to kind of...
People, we can't take one or...
No, not so you need to kind of...
Yeah.
I mean, you know, there are equations like the complex Swift-Homberg equation,
which we've also worked on,
which, you know, are better models of that kind of behavior.
Because the problem with Swift-Homberg
is that except in certain very special circumstances,
including some in optics,
you can't derive them from the basic field equation.
In fact, there is no way to derive Swift-Homberg
from Navier-Stokes, for example.
And you certainly can't derive the complex Swift-Homberg
from Navier-Stokes either.
So these have to be taken as mathematical models
rather than physical models.
And it's really in that spirit, I think, that, you know,
you should take what I've tried to describe in this talk.
Is that there are mathematical models,
which, in a sense, supersede, you know,
the details of the physics behind this phenomenon.
But I'll lead you to understand something about the
commonality of the mathematical behavior of these structures.
Okay, so I think we should stop here.
Maybe I'll continue.
And Eger will be here in a few days,
so if you have anything, let's go.
Thank you.
Thank you.
