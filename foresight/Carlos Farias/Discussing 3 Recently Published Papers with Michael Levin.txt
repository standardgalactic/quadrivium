Mike, thanks for coming on.
Yeah, good to see you again.
Thanks for having me.
Yeah, such a pleasure.
Absolutely.
I can't believe we're on round three of our conversations
here right now.
Time flies by.
And for people in the audience who haven't yet
caught our first two rounds, those
will be linked below in the description.
And around one, we covered the computational boundary
of the self paper, the cognitive light cone diagram
that folks will be familiar with, I'm sure.
And then around two, we covered observer-dependent computing,
your paper with Joshua Bungard on polycomputing,
and also the technological approach to mind everywhere.
Today, we're going to cover a couple of papers
that were recently published just in the last couple of months.
Your paper on bioelectric networks
being the cognitive glue for organisms,
and then Darwin's engential materials.
That'll be the second paper we cover.
And then finally, biology, Buddhism AI,
your paper with collaborators that I think
will be the third act of our conversations today.
So I'd love to get us kicked off first.
And those papers will be linked below in the description
as well for folks who want to dive into those.
They can be pretty technical, but I
recommend going through them and discovering them
for yourselves.
There's a lot of great diagrams in there as well
to help people kind of grok these concepts too.
So if we get started off on the bioelectric networks,
the cognitive glue enabling evolutionary scaling
from physiology to mind, your paper,
could you provide us with a brief high level summary
of the paper and what's covered here?
Yeah.
Well, I guess the first thing to do
is to talk about what cognitive glue is
and why such a thing is needed.
And I use that term just to kind of draw attention
to the following thing.
We often people think about collective intelligences
as flocks of birds and colonies or termites or bees
or something like that.
And they contrast that sharply with themselves.
They say, well, I'm not a colony.
I'm a unified individual with my own thoughts and goals
and all of that.
But actually, if you sort of look inside, what you find
is that, no, actually, you are a colony.
Like each of us is a collection of cells, neurons
and a whole bunch of other stuff.
And I want to emphasize this idea
that that is not to be taken for granted.
You cannot take for granted.
It's actually kind of a miracle, not in the sort of religious
sense, but in the scientific sense of something really
profound that needs understanding and explanation.
It's kind of a miracle that a collection of individual cells
with their own agendas and their own ability
to pursue various goals and physiological space
and gene expression space and so on,
that there is a way to arrange those things that
gives rise to this emergent new self that operates
in a different problem space and, in fact, will end up
often will end up denying the fact
that it is made up of parts with their own agendas.
I mean, that's kind of wild.
That's interesting.
Right?
And has its own goals where some of these goals are often
at odds with the goals of the parts.
And we often do things that aren't particularly good
for certain cells in the body and so on, right?
Or even certain organs.
So that's it right there.
That it's very clear that there must be a mechanism
for doing that, for transitioning from just a pile of cells
to something with its own self.
And we can sort of define, we can do a little bit of definition
there too, if you want.
But so that's the goal, right?
So now, even though people don't think about that very much,
like that, the reality is that, of course,
the whole field of neuroscience is predicated on the fact
that we know what the cognitive glue is
for behavior in the brain.
It's electrical signaling.
And let's say electrochemical signaling in the brain.
So that's the idea.
And my point in this paper and in some previous papers
is that there's a reason why electrical signaling is so
good at this in the brain.
It's because it's had lots of practice evolutionarily
where this all comes from is by serving as cognitive glue
for a morphogenetic agent, which is the thing that
arises when a bunch of individual cells in an embryonic
blastoderm suddenly start to cooperate
toward a very specific goal.
They're all going on a journey in this anatomical space
of possible configurations, of possible shapes
that anything can be.
They're all committed to helping each other
get to one particular region of that space that
corresponds to the target morphology of that species.
And so, yeah, so that's what this paper is about.
It's about how bioelectricity serves
as that kind of cognitive glue and then evolution kind of
pivoted it to do the same thing in three-dimensional space
for the control of behavior.
Awesome, yeah.
Thank you for that summary.
And I'd love to hear, I mean, one of the second questions
I had here was, how did you land on the term cognitive glue?
Like, were there any other terms of phrases
that you were kind of deciding between?
For that one, I mean, I don't know,
I use a lot of kind of these kind of terms
that I just sort of come up with.
But for that one, I'm not sure if there were any competitors.
I mean, you can think about some sort of binding policies.
You can call it some sort of an self-emergence mechanism.
I mean, you can come up with it.
But I just thought it was simpler to point out
that it literally is a kind of cognitive glue,
because without it, think about what
happens during general anesthesia, right?
So you walk into the doctor, and there you are.
And you have all kinds of thoughts and hopes about what
happens, and you say, boy, I hope the surgery goes well.
I've got a big thing.
I've got to do a month through now.
And then the gas comes in, and one of the things that happens
is the gap junctions between your cells get inhibited.
So now you're gone.
For the next however many hours, you're not there.
Your cells are still there.
All the pieces are still there.
Nobody's damaged.
Nobody's dead.
The cells are all functional, but you're gone.
And one reason you're gone is because that cognitive glue
has been temporarily dissolved.
It's the there really needs to be something
that binds all this together.
And glue, it's kind of silly, because it's not
that physical kind of thing.
But this idea that everybody has to be kept together
and the way that glue does in a particular space.
It's not just physical proximity.
The cells stay close to each other.
It's a kind of informational proximity.
And actually, people like Giulio Tononi and others
actually study this from an information study,
that integration from an informational perspective.
But that's really what's needed is a mechanism
to hold together the cognitive system that
is then going to make claims about itself
being a separate agent from the parts that make it up.
Yeah, it's interesting.
One very specific question I had in the paper.
And it may have been in there, but maybe I just potentially
missed it.
But there's a quote in there.
If you don't mind me just reading it off here.
It's developmental bioelectricity as a precursor
of brain-like processes, which reveals not only
evolutionary pivots between two different problem spaces,
but also shows a path to solving the problem of collective
intelligence across scales of organization.
What are the two different problem spaces?
And perhaps it's just an example being made there.
But I think there's a mention here of evolutionary pivots.
Can you give the audience an example of what you mean by that?
Sure.
Well, so first, let's name some problem spaces here.
Just kind of roughly in order from the beginning of life.
So you've got the space of metabolism.
That's a problem space because you
have to figure out how to keep.
If you're going to persist in the real world,
you have to figure out how to operate metabolism.
And then there'll be some sort of physiological problem
space where, aside from metabolism,
you have other physiological features
that you're trying to outkeep.
And then at some point, you get a transcriptional space
where there's actually genes now that can be expressed.
And so that space, a very high-dimensional space
of the correct gene expression for whatever
you need to be doing at the moment.
And then when you get to multicellularity,
there's an anatomical morphospace.
How many eyes are you supposed to have?
Are you supposed to have eyes?
What's the where's the head go?
Where's the tail go?
Those kind of things.
So that's the space of that's an anatomical space.
And then after that, you get to behavioral space
because eventually you develop muscles and nerves.
And now you can actually move around in three-dimensional space.
And so now you can do what's classically known as behavior.
All these other things are behavior, too.
They're just behavior in weird spaces
that we don't normally think about.
And then maybe if you're some sort of human
or something else,
you might also operate in linguistic space.
So we actually have a project now looking at navigation
of linguistic space as exactly
that kind of navigational process.
Oh, interesting.
Yeah, yeah.
And maintaining this idea.
So there's one central concept to all of this,
which is navigation.
This idea that the space is rich,
it has structure.
You, as an agent, have various kinds of preferences
about which parts of that space are better for you
and which parts are worse.
And therefore you need to navigate it.
Now, you have different degrees of competency
of navigating it.
You might navigate it the way that a bowling ball
or a dandelion seed might,
which is you have very little internal control,
if any of what happens.
Or you might be some sort of something in between.
You know, there's various seeds with little cork screws
and things that kind of help them
do various simple things.
You might be some kind of a, you know,
a simple homeostatic agent,
like a little thermostat that's actually better
than these other things.
Or you might actually be a learning system
that can have anticipation and associative learning
and things like that.
Or you might be really complex and you might have planning
and you might be able to really think forward pretty well.
And then you might be really complex
and have a gigantic cognitive light cone
where you can sort of imagine lots of complex things
far into the future way outside of your current scenario.
So anywhere along that continuum,
there's some, you might have some competencies, right?
And you navigate that, those spaces.
And so what I mean by evolutionary pivots
is simply that once you're good
at navigating one kind of space,
it's relatively, I think, this is all, you know,
this is all kind of the framework that I work on.
So lots of things we don't know yet,
but I think it's relatively easy for evolution
to switch spaces on you.
Because if you're good at navigating
a particular kind of space,
we can swap some sensors and some effectors
and you can use all the competencies you have
to navigate some other space.
So just for example,
hybrids, right?
Hybrids are when you take a brain
and you put it in a robotic body such as a vehicle.
And so in that case, the brain instead of leg muscles
might be connected to some wheels
and instead of eyes, it might have some photo arrays.
And if the brain is good at doing these things,
and so people have made these things
and they have various behaviors.
And it sounds kind of crazy and wild,
except that that is the normal scenario.
You see, your brain doesn't actually interface with reality.
Your brain interfaces with your eyes
and your muscles and various things.
And all of this is highly plastic.
When we've made tadpoles where the eye is on its tail
instead of in the head,
those animals can see perfectly well immediately.
They don't require new evolutionary adaptation,
periods of evolutionary adaptation,
they could just see in this new configuration.
And that's because, and the same reason why
sensory augmentation and sensory substitution.
So this has been known since at least the 70s,
probably before that, that you can do all kinds of,
you can give humans all kinds of weird sensors
and effectors and they very quickly become part of them.
So they become, for example,
Rocky Rita in the 70s used to do this thing
where it's like, you know that toy,
I don't know what it's called,
but it's like the square thing
with a bunch of metal nails
and you put your hand on it and it kind of makes the imprint.
So you can imagine an inverse of that
where the little pegs go and move in and out.
So you take that thing and you put each peg,
you connect each peg to a pixel on a camera
that you wear on top of your head.
And then you take that thing
and you put it up against your belly
so that it's poking you based on the pixel
that nail is poking you or not, right?
And so he did experiments with people who were blind
who learned to navigate that way
because you can remap the information
that you're getting through your skin
because the plasticity is incredible.
Look at the rubber hand illusion.
You can see these videos online
where you've had, as a tetrapod,
you've had, your brain has known
how many hands you have for how many millions of years now.
And within seven minutes of this visual input
of somebody stroking this rubber hand,
you've now decided that you have three hands.
You're perfectly willing to abandon that prior.
And when somebody hammers the rubber hand,
people jump up and scream.
And so the plasticity is incredible.
And that's why when people get prosthetics
where the wrist goes 360 degrees around,
when they reach for a cup,
they'll rotate the way that your normal wrist never rotates
because they get used to it, that's your body now.
And so all of these things, this kind of plasticity.
So that's why I think evolution fundamentally
makes these kinds of systems
that they kind of figure out what they are on the flies
or like Josh Bongard's robots from what, 2006 or so,
when he made these robots
that didn't have a predetermined model of what they were
and where the effectors were and where the sensors were.
And they sort of flopped around like babies,
they flopped around until eventually
they figured out how to move around
because they built a model of themselves
and what their structure was.
And that has the awesome side effect
that if you rip off one of the legs,
it'll just go through a similar process
and remap to the new and then move in a different way,
given what you have now.
This is exactly what we see in biology
where with a very wide range of various
accommodations to novel circumstances can be had
because evolution makes these problem-solving machines
that are very good at defining
and redefining themselves on the fly.
So that's what I mean, right?
These tricks that work well in one world,
swap some stuff around, swap a time scale,
swap the sensors, swap the effectors
and now you're walking around in some other kind of space.
I have a feeling that that's what's happening.
That's my guess.
That's wild.
I'd never heard about this, the 2006 Bongard.
Oh yeah, look it up, it's great.
I think it's very, it's really foundational, yeah.
I have to do some digging on that for sure.
Thank you for mentioning.
And there's, yeah, so many great,
wow, so much awesome stuff I wanna unpack there.
One of which, well, a few things that I think keep coming up,
sometimes like a phrase or an idea
that from our discussions
or from listening to you on other podcasts,
you know, you say all intelligence is collective intelligence.
So I think it's really great.
I think the emphasis, a lot of people need to hear that.
The other thing, and I think you just touched on it a bit,
is that, or maybe in our previous discussions you did too,
we, a lot of people think of the brain
as having this like exalted status
of that the brain can do all these things
that other parts of the body can't do.
But what's, and it's in this paper as well
and other papers too,
but sometimes there's memory stored outside the brain,
you know, in some of the research that you've done.
Can you give us a sense of what does the brain do
that's actually different than the body cells?
So, yeah, so what does it have
that say other parts of the body can't do?
Yeah, yeah.
So as much as I try to lean on the commonalities
between brain and other tissues,
I mean, it's pretty obvious.
There's a reason why we have brains.
Brains give us extra features
that we wouldn't have otherwise.
And so just to, you know, just, I mean,
the most obvious one is speed.
So neural bioelectricity is way faster
than developmental bioelectricity.
And I think that was part of an arms race
at the beginning when things started moving around
and trying to eat each other and avoid being eaten.
Speed became of the essence.
You know, I mean, developmental biology,
I mean, yes, you want to complete embryogenesis
as quickly as you can,
but it's not under the same speed constraint,
I think as actual behavior, you know,
three-dimensional behavior.
So there's speed in this idea.
Then there are the point connections.
So neurons can be incredibly long.
And so if you want to make a directed connection
from here over there,
without that neural architecture
of having an axon that reaches all the way down,
I mean, they can be meters long in some animals.
Without that, the basic bioelectric system is cumbersome
because it basically thinks spread as waves
or, you know, they propagate
through the gap junctional milieu.
It's not the same as, right?
So those are kind of the architectural things.
I mean, a lot of the components are conserved.
So ion channels, neurotransmitters, electrical synapses,
all that stuff is conserved,
but it's used in a different way,
both for speed and for direct connections, you know?
And then there's just, there are the things
that we know that are associated with brains
that we haven't found anywhere else.
So for just as a sort of high-end example is language, right?
So I've seen no credible claims
that the other organs in your body
are using this kind of syntactic language structures
that brains use.
Not saying it's impossible.
Who knows, we might find some kind of syntax,
but there isn't any evidence for that yet that I know of.
So that I think, you know,
but other basic stuff is the same,
you know, perceptual control and predictive coding
and all kinds of that happens in all cells.
I wanna come back real quick,
because I do think this is important
to something else that you said a minute ago
about the collective intelligence
and the fact that people need to hear that.
So I wanna just talk for a moment
about what it is that I think they need to hear about it.
Because some people, and I keep, I'm always fishing,
let's see if this helps at all,
but I'm always fishing for a better way to make this point.
And I don't know how effective this is.
Some people get really kind of destabilized
by these sorts of ideas,
because what they hear is, I'm not real, I'm an illusion.
And there are lots of scientists
that are pushing this narrative, right?
So we are to blame for this.
I'm not surprised that people have these ideas.
But, you know, this idea that, well, we don't exist.
You know, you're a big pile of cells
and you're not really here and it's all an illusion.
And that's a really destabilizing idea.
It's destabilizing on a personal level,
it contributes to the loss of meaning,
it contributes to societal issues.
And so I wanna just say what I think the lesson here is.
When you see science like this,
the lesson isn't that you are somehow devalued
from what you thought you were,
and that the meaning of your life is reduced,
and that your primary experience
of being a coherent being with choice,
with the responsibility of deciding what do you do next,
that these things are now out the windows somehow.
I think that's the wrong conclusion to draw from any of this.
The conclusion isn't that the majesty
of the integrated mind is reduced.
The right conclusion is, well, two things.
One is that actually we just learned an amazing thing
that matter can do.
We didn't know that before.
We thought dumb matter was just kind of dumb.
And what we're learning now,
we're not learning something that changes
how we view ourselves,
we're learning something that changes how we view matter.
And this is something that I think Ian McGilchrist says as well
that we've underestimated certain kinds of matter.
This idea that, no, actually,
and this is, I know I've used this example before,
but there's a scene in a lot of science fiction,
most recently I saw it in Ex Machina, right,
where the guy starts cutting his arm
because now he's worried that he's an android, right?
And I mean, yeah, a lot of people feel that way,
but if you cut your arm or you go get a CT scan
and they say, whoa, you know what?
You're full of cogs and gears.
The conclusion from that isn't,
oh man, well, I guess I'm not as real as I thought
and I'm not, you know,
I guess I don't get to use my free will now.
And that's not the answer.
The conclusion should be amazing.
Cogs and gears can give me my spiritual meaning like amazing.
I've just learned something about cogs and gears, great.
So that's, you know, I just want to be clear
that I think this kind of analysis of what it is
that we are, how we get here, you know,
the self-construction of the self from cells
during embryogenesis and all that,
that doesn't, it doesn't have any negative implications
for what you are and what you can do, just the opposite.
It sort of raises the remarkable magic
of these unbinding principles that you say, wild,
you can actually create a being that I know I am.
I mean, that's the part that I think Descartes
had had exactly right.
Apparently you can get there through this particular method.
And there was, I forget what it is,
but there was also another,
an old science fiction story where, you know,
these aliens kind of land on earth
and they find out that humans are basically made of meat.
And they say, that is the most disgusting,
like you're telling me a pile of meat
can have these exalted thoughts that we,
in our silicon, you know, implementations,
how like that's, there's no way.
There's no way a pile of carbonaceous agoo
is gonna have these kind of, you know, mathematical truths
that we perceive with our, with our silicon minds.
And right, and it's all completely arbitrary.
Somebody who doesn't want to find gears under their skin
and cogs and things like that.
Why not?
Because they've bought into the fact that proteins
and RNA does it, is that anymore?
You know, why are you any happier with that?
None of that, none of that is intrinsically
any better than anything else.
So I think it's very important not to get,
not to take the wrong message from all this kind of stuff
and to somehow dissolve your fundamental worth
just because we've seen some of the parts
that are under the hood.
We knew that we're gonna be parts under the hood.
In fact, I'll go one step further
and for the people who, right?
Because one thing that people sometimes say
at this point is, you're right,
you've just done a deconstruction of all materialism
and none of it matters unless we're a soul.
Yeah, so some people feel that way
that basically, right, the proteins,
just like the gears all know good.
So the thing with that is without even getting
into the kind of the factual nature
or just think purely logically, fine, fine,
maybe you're a soul.
What's the mechanism of the soul?
There's gonna be one.
It's gonna do something
and it's gonna have some kind of features.
If it doesn't have any, if it has no parts,
then it can't change, then you can't learn,
you can't make decisions, you can't improve,
you can't do anything.
It's gonna have some kind of structure.
Maybe it's, I'll give it to you
that maybe it's a completely different,
something material science has never seen before.
Great, but it's still gonna have some kind of descriptive
laws that govern how it acts in whatever space it lives in.
And then we're gonna be back to the same.
Somebody's gonna say,
but it's got rules that govern its behavior.
That's not what I mean,
but that's not enough to give me my magical feeling of stuff.
So we gotta get over this.
The non-material kind of way forward
doesn't help at all.
And we have to get over the fact
that finding mechanisms under this somehow
robs the larger scale of its meaning.
That's just, sorry, that's a long diatribe,
but that's what I wanted to say.
No, no, that's great.
That's spot on too.
It's funny, because I had on Bobby Azarian,
who's a cosmologist and wrote a great book
called Romance of Reality.
And he refers to this quite a bit,
more in the sort of the deterministic lack of free will,
but the similar kind of vein
that a lot of people feel like
as soon as you start to explain this stuff,
it's like you're explaining away the soul or the mystery
or what makes it interesting, right?
But at least it seems like to me
that it's just like a never-ending process.
Like there's always something to learn
and continue to be curious about.
And it's funny, yeah, if you update your priors
and you're not stuck to, if you're open-minded enough
to all the different possibilities that are out there
and you get this new information,
yeah, you just keep, like you said, if you're a robot,
you just say, okay, well, that's interesting.
Yeah, that's interesting.
And you just update and you move on
and you've changed how you view the world.
Yeah, that's fine.
I'm the world's most amazing robot.
I thought I was a meaty robot.
Now I'm a metallic robot.
Great, who cares?
My list of things I was gonna do,
the amazing things I was gonna do,
still nothing's canceled, still right there.
I'm still gonna go do those things.
So that's what I wish,
I don't know how convincing any of this is to anybody,
but that's one thing that I really wish
people wouldn't internalize.
There's so much, both personal and social loss of,
loss of meaning, I think is the best way,
as Varvaki says, around all of this kind of stuff.
And that's the last thing I wanna contribute to.
Yeah, I mean, that's a whole fascinating route
that I could go down to,
because I feel like, let's just say this,
like if that new information would lead you down
this kind of nihilistic path,
and I kind of feel like
you were probably gonna go down that path anyway.
Yeah, 100%.
Yeah, it's sort of,
you're using it as a reason to get stuck
in a really a vicious cycle potentially,
but yeah, that's really interesting.
But actually, I think this,
where I was gonna go to next anyway,
and it's in this paper and the next paper as well,
you had this concept called the play the hand your dealt.
And you, I mean, you're using this very,
how should I say it, materially,
you're talking about the cellular collectives
that can carry out different steps
with its sort of second order functions.
It's not, they're far more, let's say malleable,
and far more open-ended kind of strategies
for accomplishing their goals.
Can you talk to us about that and what that,
I think you, the acronym is PhD,
so play the hand your dealt.
Yeah, well, let's just start with a specific example.
So you take a salamander egg
and there's a certain tricks you can do
to increase the number of the chromosome count
within the number of copies of the genome
that are in there.
And so when you do that,
so let's say we increase instead of two N,
you can make four N, five N, six N and so on.
So as you do that, the cells,
the embryonic cells get bigger and bigger.
The salamander stays the same size.
If you take a cross section through a kidney tubule,
which normally is made of, I don't know if you can picture
this, but like six to eight cells that work together
to form this kind of like long tube,
they get bigger and bigger,
but the animal stays the same size
and the tubule stays the same size.
So what this means is that fewer and fewer
of these larger cells participate in each tubule, right?
And so far, so we have two amazing things so far.
Number one is you've got the wrong number of chromosomes,
fine, you're still a good salamander, amazing.
Number two, your cells are the wrong size, no problem.
We manage the cell number to make up
for this different in cell size.
You're still a good salamander.
Number three, if you make the cells absolutely gigantic,
and these are I think six or eight N,
I don't remember exactly, what happens is,
there's not room for even two cells to be there.
So what happens is one single cell wraps around itself
and leaves a hole in the middle
to give you that same tubule, okay?
Aside from the whole issue.
So what it is is it's using different molecular mechanisms.
In the first case, it was cell-to-cell communication.
In the next case, it's cytoskeletal bending.
You're using different molecular mechanisms
in the service of an anatomical large-scale goal.
That's a kind of top-down causation, super interesting,
but for our purpose, more importantly,
look at your job as a salamander.
You come into this world,
you can't tell how many chromosomes you're gonna have.
You don't know what your cell size is.
You don't know how many cells you're gonna have
because people have done that too.
You can take away cells, you can add cells.
You don't know any of that stuff.
You need to be able to, your goal
is to be able to make a good salamander
no matter what you start with.
So that's within limits, obviously.
I mean, all of these things are not infinitely stretchable.
So that's one example.
Here's another example, plenaria, flatworms.
The species that we work with
reproduces by tearing themselves in half and regenerating.
That's how they reproduce.
That means that they have somatic inheritance.
Any mutation that doesn't kill the stem cell
is gonna be proliferated into the body
and expanded in the body in the next generation.
So if you look at these worms, they're mix-a-ploid.
Every cell has a different number of chromosomes.
The genome is a total mess
because they just accumulate this stuff.
400 million years they've been accumulating all this junk.
And yet that's the species with perfect regeneration,
high cancer resistance, no aging in the asexual form.
Incredible, right?
And so the same story there is what you have to do
is you have to have an algorithm
that builds a correct plenarian
despite errors in the hardware.
And that's what I think.
So there's my play the hand-in-the-dilts concept
is that coming into this world as a new creature,
there's precious few things you can depend on for most.
I mean, there are hardwired things like C. elegans,
nematodes, and maybe some other species.
But I think, and there's all spectrum.
So I would sort of imagine that something like nematodes
where every nematode, every C. elegans
has exactly the same number of cells
and they all have the same lineage.
So that's a very cookie cutter organism and that's here.
Plenaria are super plastic and they're out there.
And salamanders are somewhere here
and humans are somewhere,
mammals are somewhere here.
We all have different degrees of that competency.
But that's the idea.
Most of us don't come into the world
being able to expect very specific things
and then just crashing and burning
when those assumptions aren't met.
This is why we can make tadpoles with eyes on their backs
that can see, and this is why slippers goat
when that two-legged, right, the goat that didn't have any form.
Shippers, goat, yeah, something like that.
Yeah, learn to walk upright.
And they found that a lot of the changes
that come along with bipedal locomotion were already made
because of the incredible plasticity of the organism.
And it's why skin cells taken off of frog embryos
becomes xenobots and why,
and instead of just like collapsing and dying
and all of these things, that's play the hand you're dealt.
That's the idea that we have to...
There may have been life at one point
that was much more cookie cutter, but none of that survived.
Nowadays, if you're gonna survive,
nowadays, you're the kind of life that is able to do this.
Right, and can you tell us about...
One thing I was thinking about too,
with the play the hand you're dealt,
sort of like whatever materials you have there,
that's what you're gonna use,
is, and with bioelectricity, of course,
like the electromagnetic spectrum,
that's sort of what's available to these cells, right?
And I'm thinking, and perhaps this is just
because it's at the limits of our science,
have you found either in your own research
or in research of your contemporaries,
like evidence of organisms making use of quantum fields?
Like are all the different fields that are available,
you know what, I mean, electricity,
I understand why bioelectricity is so great.
I mean, we use a lot of the same,
the ion, like the ion channels, like logic gates,
we use that stuff in our technology,
you know, similar kind of processes.
But anything in the quantum realm that you've seen?
So we don't study that specifically,
so I don't have any data about it.
There are certainly people that study quantum biology,
there's some great people who, you know,
Claree Ciello and my former postdoc,
Nerocia Morgan, they're into this kind of stuff.
And as our other people,
and I'm sure there are interesting things
that we don't particularly work on it.
My gut feeling is that,
not being an expert in this,
but just for whatever it's worth, my gut feeling,
it's gonna be the sort of thing that if it exists,
it's not gonna be some weird special adaptation where,
you know, all look birds are using, you know,
quantum spin to navigate the magnetic field
and that's it, it's not gonna be like that.
I think, I mean, that may also be,
but I don't mean that.
I think what we're gonna find is that it's everywhere,
like it's a basic fundamental, if it's there,
if quantum biology is there,
which I suspect it probably is,
it's gonna be used for everything.
We're gonna find out all the things
that we take for granted now that are just,
you know, we kind of assume
there's a classical explanation for it,
but we don't know what it is.
I have a feeling we're gonna find out a lot of this stuff
is at bottom, exploiting some of those properties.
That's just, that's totally a guess on my part.
I don't have any data to, you know, support any of that.
But that's my guess.
Yeah, yeah, that's interesting.
I would see, the very little I know about the quantum,
like quantum mechanics is that I would assume
these structures, even cellular structures,
they're tiny to us, but they're too large,
like, you know, it breaks down.
The quantum effects are just,
what happened to a way smaller lens,
but like you just pointed out,
like I think that there's some research
I've done a little bit of digging,
but I have to do more about quantum biology.
Yeah, look at, also look at the work of Chris Fields
and folks that he works with,
because there are aspects of what's important about that field
that has nothing to do with being small.
So there are really important aspects of, you know,
in terms of what's an observer and reference,
for observer reference frames,
and these kinds of things that apply across scales.
So Chris has some beautiful papers about that.
So it's not just for tiny particles and things like that.
That's good to know too.
And before we move into Darwin's and Gentryl materials,
I think it's still applicable here.
Can you tell us about, I think there was one podcast you did
where you talked about trophic memory in deer
and antler structures,
and actually the scientist that was studying it
actually sent them to you,
and you have a bunch of these.
Can you just tell us a little anecdote?
Yeah, well, okay, so first, what is trophic memory?
So there's certain species of deer that every year
they shed their antlers and then they grow them back.
Antlers are real bone, they're not like horns.
They're real bone with velvet and innovation and all that.
So there was this team, last named Bubenek,
and it was two folks, a father and son,
and they live in Canada.
And they did experiments for,
I'm gonna say well over 30 years,
maybe 40 years together, something like that,
where what they found is that if you see,
you got this deer and you take a knife
and you etch a little cut into somewhere
on this branch structure.
And that year, it kind of heals with a little callus,
the bone heals, and that's that.
And then the whole thing drops off.
And then next year, when they regrow their antlers,
it grows with an ectopic branch point at the location
where the damage was last year.
Now, I read this, and so they got these papers
from 60s and 70s and beyond.
It's an amazing data set.
No one's ever gonna get a data set like this.
I mean, who's got a herd of deer
that they can watch for 40 years?
It's a, in modern biology careers,
that's not exactly conducive to getting a good associate,
this is in a professor position.
But they've got this incredible data set.
And when I first read about this,
I thought it was amazing because if you try to think
about the current, what passes for an explanation
for a biological phenomenon nowadays?
So if you find this, you look at a typical cell paper,
figure seven is gonna be a molecular pathway, right?
So there's some arrow diagrams on this thing bind,
so that thing, and then they go over here
and they bind to this other thing.
Just try to come up with a model like that
for what's going on here.
So there's a large scale structure.
It gets a damage input at a particular location.
The whole thing falls off.
The cells at the scalp, which are tens of centimeters away,
remember the three-dimensional position
where the damage was last year.
And then when the bone cells start growing,
they revise the genetically encoded rules to say,
oh, by the way, when you get to this point,
make an extra thing to the right.
Like what possible explanation
using conventional conceptual tools that we have?
Could you come up with it?
It just completely fails.
And so this is one of the things I tell my students
is that your developmental biology textbook
is full of things that are readily explained
by the conceptual tools that we have now.
That's what's in the textbook, other success cases.
So what's fun is to look for the blank space in between.
What are all the things that are not in there, right?
And they're not in there
because we don't have a clue as to how it works.
So this is the kind of, I mean, I love that stuff.
So I'm always thinking about these kinds of things.
So anyway, so at one point,
so we wrote Daniel Lobo and I wrote a paper about this
and explaining like what the implications of that are
for the inverse problem,
which plagues regenerative medicine and so on.
And Bubenek emailed me and he said,
he said, you're one of the few people
that sites this stuff nowadays.
I need to like basically clean out the house, the garage.
Would you like these antlers?
And I was like, to hell yes, of course I would.
And that's such a unique, I mean, it's amazing work.
It's such a unique dataset.
And so we received in my lab 13, I think it was 13,
13 large boxes of these antlers.
And I sent them all to the veteran,
a Tufts Veterinary School.
They have a CAT scan machine where they CT scan horses
and things like that.
And so they CT scanned all of these things.
So I have somewhere, I've still got the antlers
during boxes in the closet.
I have a couple of them on the wall actually
in the lab as you walk into the lab.
There's a couple on the wall.
But yeah, but I still got these boxes.
And it was incredible because every set of antlers
is labeled with the name of the deer and the year.
So it'll be like, Lenny, 1987, Lenny, 1988.
And because you have to do these longitudinal,
like you have to know which deer it was.
And he kept meticulous records.
And so we have all of these antlers.
And it's a very unfortunate model system
because if you want to do experiments,
I mean, who's going to have deer and wait years
for an outcome like it's crazy.
But the closest thing to that actually
is our two-headed plenarium
because it's a very similar kind of thing.
It's a physiological stimulus
that gets somehow catalyzed
into multi-generational repair processes.
Because once you've make them two-headed,
you can keep cutting them.
They stay two-headed forever.
And luckily, plenarium are much more tractable than deer.
So I suspect those things are highly related,
but that's my deer antler story.
That's awesome. That's so cool.
That must be what a fixture to have in the lab, too.
It's right in the front as you walk in.
Great story, too.
Awesome. Thanks for sharing that.
So I'd love to turn towards,
and there's going to be a lot of overlap
between this paper and what we just discussed.
And I'm sure we'll talk more about bi-electricity as well.
But the second paper, Darwin's Ingencial Materials,
Evolutionary Implications of Multiscale Competency
and Developmental Biology.
And both of these papers, the first two,
they really just dropped in the last few months, right?
April 2023.
So these are hot off the presses for folks.
I don't really heard you talk about these in other podcasts.
So it's great that we're getting a chance today to do that.
And before we jump right into the paper,
is this an illusion at all
to the His Dark Materials book series?
Like the title?
No, not really.
No.
Okay, just wondering.
I mean, that's a little bit of a flyer,
because it's Darwin's Materials.
I was like, is there sort of a...
Yeah, it does sound like that, doesn't it?
No, not really.
Okay, cool. Yeah, just an aside.
But would you mind, I mean, just like you did
for the first paper,
could you provide like a simple overview
and then I have a bunch of questions to ask you about?
Yeah.
Let's start from this idea
and I tried to formalize this in my tame paper
from a few years ago.
This idea of a spectrum of,
you can call it many things,
it's a spectrum of persuadability.
That's what I call it in the paper, a spectrum of agency.
Just the idea that you can put any system
on this continuous spectrum
that tries to capture how much autonomy the thing has
from an engineering perspective.
How much can I expect?
How much problem-solving chops does this thing have?
When I'm not around to force it.
So, and you can go from Legos to thermostats,
to animals that learn, to humans,
and then everything in between is there, right?
Okay, so now we can ask the following question.
As an engineer,
and so this is another paper I wrote with Jamie Davies
a few years ago, maybe a year ago,
talking about engineering with agential materials,
because engineering is very different
based on where along that spectrum your parts are.
If you are engineering with Legos, everything is on you.
The only thing the Lego's gonna do is keep its shape.
That's all it knows how to do.
So everything else is on you.
Everything that you need to happen,
you have to somehow make sure it happens.
And this is how molecular synthetic biology works.
You're gonna put in circuits that do specific things.
It's on you to implement every part
of the functionality that you want.
If you, and so humans have been engineering with bricks
and wood and metal for thousands of years,
and use a certain set of techniques to do that.
What are those techniques?
Well, they don't involve psychological tools.
They involve very kind of low level,
put everything where it goes and glue it down
and attach this thing to that thing.
That's your toolbox.
Well, if you're building autonomous vehicles
or self-guided missiles or houses or whatever,
you've got some other stuff,
which are, for example, thermostats.
So if you've got a thermostat, it's interesting
because you don't even necessarily need to know
how the whole thing works.
What you need to know is where is the set point
and how do I change it, right?
And what are the inputs and what are the outputs?
Where does the thermometer go?
Where does the connection to the heating,
to the cooling and heating go?
And what you know is that it's gonna do certain things
when you're out there to micromanage it.
Do you have to leave rules for what to do
at every single temperature level?
You don't.
It's gonna do that on its own.
So you've got some other tools
and these are the tools of cybernetics.
So for more complex systems,
you'll have control theory and all these kinds of tools
to deal with something that has a simple level of agency.
It's got very basic, kind of primitive goals
that it tries to set, and if you don't understand
anything about cybernetics,
you are not going to get the most out of these components.
If you don't understand what homeostasis is,
what goal-directed loops are,
you're not really gonna be very good
at using those in your engineering.
Okay.
And then you move forward and you say,
okay, I'm a proprietor of a circus,
of a rat circus.
And I want these rats to do little tricks, right?
I want them to, and in the Jamie's paper,
I think we talked about building a tower out of dogs.
I could try the traditional route
of stacking them on top of each other,
but that isn't gonna work.
They're gonna crawl off.
They're not gonna just stay where I put them.
So that doesn't work at all.
I have to use a completely different set of tricks
that people who work with wood and metal don't have to use.
I have to train my material.
I have to, now on the one hand,
it's a bit of a pain in the butt
because your material has its own agenda
and you have to have tools to manage it.
But here's the beauty of it.
Once you've trained them to keep a little tower,
if you knock it over, guess what it does?
They get right back up on their own.
You don't have to be there to rebuild it.
Isn't that amazing?
So you've gained something very interesting
by switching the bag of tools you bring to the problem.
You've gained something interesting
and you were only able to do that
because you recognized the agency of the material.
You wouldn't do that, right?
You wouldn't do that if you didn't know,
if you thought that these things are dumb,
like bricks and Legos.
So it's very important.
And then you see this all the way up.
If you're a hacker, you might be hacking the computer,
but you might be doing what they call social engineering.
You might find out that it's much easier
to just trick somebody giving you their password
than to spend all day brute forcing the hashtag or whatever.
So there's this has to be this impedance match
between the tools you bring to the problem.
And the successful engineer is one that recognizes
what's the right level of agency in my material.
And so that leads to the question for regenerative medicine.
We have cells and tissues and you ask,
so what are the tools that I'm gonna use there?
And the assumption up until now,
the assumption has been, well, they're like the bricks.
You have to micromanage all of it.
Yeah, that's been the standard assumption of the paradigm.
And but it's very much an open question.
Are they more like the Legos
or are they more like the rats
or are they more like something in between?
Or are they more like the thermostat or where are they?
And regenerative medicine is gonna be cracked
by the people who pick the right level.
It's not gonna be cracked by assuming the wrong level
nor down, so it's not gonna happen
if you assume these things are low agency machines.
It's also not going to happen if you assume
that they're magical, inexplicable things
that aren't gonna obey any kind of rational rules.
That's not gonna work either somewhere in the middle,
which is what of course what my lab tries to do
is to pick the right set of tools from cybernetics,
from behavioral science to take advantage.
So having said all of that, here's the thing with the paper.
So what I just took you through
is how human engineers view the spectrum
of agential materials, right?
And so now it comes time to, so we wrote,
so Jamie and I wrote that, and then I said, okay,
so now what does evolution do?
Evolution is also an engineer.
So the question is, does evolution assume
and work at the, assume that these things are like Legos
and work at the lowest level,
which means search the really difficult
and really kind of rugged space of molecular properties
or would evolution take advantage
of the competency of the material?
Because the thing about evolution is evolution
doesn't work with Legos, evolution works with cells
and cells and tissues used to be independent organisms.
They don't come as blank slates that are dumb
and have to be micromanaged.
They come with behavioral competencies,
with preferences, with various kinds of agendas.
And so what that paper is, is an exploration of,
if we take that seriously, the fact that evolution,
of course, evolution is very opportunistic,
it makes use of everything it can, we know that.
What can we conclude if we take seriously the idea
that evolution will not have missed the fact
that it's dealing with a very powerful
agential material that these cells
already know how to do things?
And so what I do in that paper is run down
all of the implications.
What does it mean for evolution
that it isn't working with Legos, it's working?
Of course, people have used evolutionary computation,
like genetic algorithms and things like that
with materials that really are dumb.
So the typical evolutionary algorithm
is done over passive data and it shows you improvements
but the material is very passive
and here I'm saying biological evolution isn't like that.
So what does that mean?
What will that do to evolution?
And that's kind of the flip side, right?
A lot of people study how intelligence,
how evolution gives rise to intelligence
of different types, I sort of reverse that
and of course both are happening simultaneously
but I looked at the other side of things
which is how does intelligence impact
the actual evolution, the intelligence of the substrate?
Sure, that's interesting, still thought provoking.
The, can I tell you something,
an impulse I had while reading the paper
even though it's not stated explicitly
and even something you just said.
Would you, how do you view even the evolutionary process?
I mean, it almost sounds like evolution is an agent
in and of itself.
Do you view it that way or how do you look at it?
Yeah, this is an interesting point.
That's a paper that is on my list to write.
It'll probably be next year at this point
but this idea of evolution itself as an agent.
I wanna be very careful here
because a lot of people still have this kind of ancient view
that there are two kinds of things in the world.
There are dumb material things,
like the machines that the quote unquote machines and so on.
And then there are the mindful things
like humans and angels and God and whatever else, right?
And so when I say, actually I do think
that there's a lens on evolution
which does see it as an agent.
What I'm not saying, okay, so super clear,
not saying that evolution has a high level purpose
the way that a human level purpose
or a beyond human level purpose, not saying any of that.
What I am saying is that there's a very rich spectrum
of agency from very low.
I'm not sure there's a zero, but certainly from very low
all the way to human and beyond.
And I don't think we can blindly assume
that the level of agency for the evolutionary process
is down at the low end.
It might be non-zero
and it might be important to understand what it is
but just again, really clear,
not saying that there's any human
or above level intelligence out there
picking where the lineages go.
I think Carl first and probably said this
well before me, this idea that you can use that framework
to you can, so imagine,
so it's kind of two ways to think about this.
One way to think about this is that imagine a lineage,
I don't know, 15 million years of alligators or something
just imagine some kind of lineage.
And you can imagine that whole thing as an agent.
It's a very long lived agent
but we're just bad at noticing agency
at different time scales.
It's a spatially a huge agent
but we're also too fixated on agents
that are roughly the size of us, medium sized objects.
So if you forget that
and assume that agents can be whatever,
what is happening there?
What's happening there is that continuously
generates hypotheses about the environment.
Those hypotheses are cashed out as offspring
with different features.
Some of those hypotheses are proven false.
Some of those hypotheses are supported.
Those supported hypotheses go on
and shape the cognitive system of the collective
to form new hypotheses that might be even better
more correctly described, you know, reality.
And what's interesting is that much like kind of
consistent with what I said before,
what these hypotheses are are not flat
kind of first order statements about the world
meaning a hardwired solution.
And you know, it is what it is.
They're actually, these hypotheses
are actually problem solving strategies.
They're heuristics.
They're like what comes out of evolution is not,
here's how you be a salamander and that's it.
It's a set of policies that cellular collectives
can operate depending on what's going on.
They're context sensitive.
So these, it's like instead of generating guesses
about the world, what you're generating are policies.
You're generating navigational heuristics, right?
And so that's what that agent is doing.
That's pretty good.
That's not super low agency to be able to do that.
That's something.
That doesn't mean you have self-reflective,
you know, I'd love to evolve some humans
because that would be just like, that's not what I mean.
But it isn't, you know, it's being able to generate
hypotheses and get them falsified and have this like,
so Carl, you know, Carl Friston has some great thoughts
on this, Richard Watson has some great thoughts on this.
But yeah, I mean, there's another way maybe to think
about it, which is that the whole evolutionary,
but never mind the lineage,
but the whole evolutionary process itself,
and that gets hard.
I don't have too much to say about it right now,
but I'm working on it.
This notion of what actually can be an agent,
you know, processes as agents.
That's a whole other kind of kettle of fish.
So I think, you know, well, next year,
maybe if I get anywhere with it,
maybe we talk about it next year.
Yeah, yeah, that'd be interesting.
I'm gonna definitely be on the lookout for that paper.
And I think, yeah, you touched on so much, yeah,
so much already about what's in this paper,
the difference between first order and second order,
say goals or say a certain amount of flexibility
that is built in to the first initial levels there.
What else, what do you think is, I guess,
if you had to say for people to take one thing away
from this paper, say a lay audience,
what do you think would be something that,
you know, this is hard.
I wanna get to a little bit of this,
I love your work, it's fantastic.
But what I want to perhaps push
for some of the people I interview a little bit more on
is like, okay, this is amazing stuff.
How does someone, you know, an individual person,
is there stuff that we can take away here
that are there like truths that, you know,
maybe as part of our day-to-day lives
that we can sort of integrate ideas like from this
or anything from your own life, perhaps,
examples of things that this is illuminated for yourself.
Well, let's put it this way, you know,
I don't know if anything from this paper
will, you know, revolutionize day-to-day,
like mundane life, but a lot of people,
but I will, let's try to pull in that direction.
A lot of people think about evolution
and one of the things that always bugs them,
and especially, you know, a lot of engineers too,
is this standard story of, well, we make random changes
and then we pick the good ones, right?
I don't know about you, but when I first learned about this,
I had been building, you know, electronics
and things like that as a kid for some years,
and then I learned this theory, you know,
it sounded laughable, it sounded like,
you're telling me that I'm gonna make random changes
in this thing, I huff and puff for many hours
and then the person who made these transistors
and everything else will put in even more work than that,
like we're all busting our butts on this stuff
and you're gonna make random changes
and you think eventually things will get better,
like that's, you know, if you've ever built anything
or written code, that sounds crazy,
and then okay, you know, so you learn some things
about modularity and evolvability and some things that,
but a lot of people are still left with this idea
that, okay, in theory it might work,
but we kind of know that genetic algorithms,
you know, they did great for a while,
but they sort of peter out, there's some limit,
you know, there's kind of limitations to what they can do,
and in particular, but part of what makes it,
what makes it a little challenging is what Andreas Wagner,
which I think his work is amazing and important,
what he calls the problem of the arrival of the fittest,
which is that if the best solution is hiding somewhere
in your population, I suppose I'll give you that,
I'll give it to you that eventually we'll sort of find it
and let it expand, but who guaranteed it was there
in the first place?
How do you know that the right solution
is ever going to be there,
depending on what your problems be?
So anyway, so a lot of people are still left with this,
you know, this dissatisfaction about how there's just,
how do we know that there's been enough time
for this kind of process to give us the amazing things
we see in the biological world?
And I'm not talking about that, I mean,
so there are some people that will never buy the story
because they are fundamentally like committed
to another kind of story, I'm not talking about them,
I'm talking about people with a scientific kind of worldview
that want to understand in a naturalistic way
what's going on, but the standard story doesn't seem
like it's the whole story, right?
And there's a lot of very smart people
who are sort of thinking along those lines.
So what I would point out, my kind of contribution
to that is this, part of what makes,
part of what makes that process so magical
is not just the process itself,
it's the fact that you're working on a material that's smart,
you're working with an agential material,
that's part of where the power comes from.
If the whole thing seems tough to you,
add to your sort of mental picture,
the fact that it's not really searching
the incredibly difficult and large space
of all the possible things that could happen,
what it's searching is the space
of behavior-shaping signals
by which cells tell other cells what to do.
And that's a much easier space to search, right?
If you're dealing with, if you run that rat circus,
you could try to come up with a kind of
an optogenetic strategy to control every neuron
to get the rats to sort of do whatever they're gonna do,
that's really hard.
We'll be here till the sun burns out
before we can micromanage it.
But you don't have to do that
because you can train the rats.
And that's a much easier, I mean, it's still a bit of search
because you still have to figure out, well, what's the reward,
what's the punishment, what are they capable of,
do they do place conditioning,
do they do associative learning, what do they...
So there's still some searching involved,
but it's a much easier problem than going bottom up.
And so this is what I want people to take away from this
is that part of what makes evolution so magical
is that it's working with an agential material
that has tons of competencies.
It's evolution is playing with hardware
that is so far in capability.
And I don't mean the fact that it goes down to the nano level
and I don't mean that it's, in fact,
it's way noisier and more brittle and whatever
than all the things we try to build.
Despite all that, it is so much more powerful
than anything we've ever made
because it is not a single specific thing.
It's a learning machine, so to speak.
And that puts evolution on steroids.
That's what I think is a huge motivating factor.
And I think until we understand that,
we are not going to have, I mean, that's to me,
that's if I can dare to say this,
the thing that I think is missing
from the standard evolutionary synthesis is this.
It's the appreciation of the intelligence of the substrate.
It treats the standard story,
it treats the substrate as a bunch of dumb Lego blocks
and everything changes.
When the material has agendas, everything changes
and evolution changes massively.
So, I don't know if that counts as everyday life
for people, I suppose that some people think
about that stuff every day, so.
No, no, it's good.
I find it useful because it's a frame,
it's a perspective on how you look at the problem.
I mean, that's something we've talked about in round two.
I think like polycomputing and the role of the absurd,
the same thing can be computed.
But depending on how you look at it, you actually get,
you actually are extracting that different value,
different utility from the same exact thing.
So, yeah, that's wonderful.
And actually, I think this will,
just looking at the time a little bit here,
I do wanna cover a little bit
about the biology, Buddhism and AI paper.
I think it was Kair as a driver of...
I forget exactly.
Yeah, Kair is a driver of intelligence,
but she worked on with a few collaborators,
Dr. Witkowski, Salmanova and Dwayne.
And this, I think actually does bleed into this fairly well
because in the Ingencial Point Materials paper,
you mentioned the idea of like beginner mind.
And you have a quote from Suzuki about the,
in the beginner's mind, there's many possibilities
and the expert's mind, there are a few.
So you kind of wanna have a frame of like always being,
having a frame of always being a beginner
and being like open and curious to things all the time
is a lot better than, this is a straw manning it,
but it's a lot better than being an expert
and being like, I know everything, I've mastered,
there's nothing else left to go, right?
There's always potential for more learning and more mastery.
So for the Biology, Buddhism and AI paper,
would you mind providing us again,
just a brief overview of the overall paper
and also how you got interested in this topic
to begin with and how you got into this group
of folks who are studying this.
Yeah, well, how I got interested in it,
I've been interested in these kinds of things
for a really long time, both from the perspective
of kind of Eastern thought about the philosophy of mind
and things like that and more broadly questions
of concern and compassion and things like that.
How we met up, to tell you the truth,
I don't remember who reached out first,
it might have been Thomas Doctor that emailed me,
I mean, Olaf and I have known each other,
he's a great contributor to the artificial life community
and so I've known him and his work for a long time,
Bill and Eliza and Thomas I met afterwards.
Yeah, I don't recall who made the first step,
but anyway, we've been talking about this stuff
and thinking about it for a long time
and there's actually a second paper
that just got accepted or we just returned it,
I don't remember exactly where it is,
but there's a second paper following up
on all of this stuff.
You can find the preprint is on the website,
but this idea of specifically this idea of care
and what do agents care about?
And for me, it has lots of important implications
because I try to understand collective intelligences
and so if you're gonna have a collective intelligence,
what is it going to care about?
We don't have a good science of that.
And then there's the notion of embedding care
in artifacts that we make.
So robotics, AIs, what are they gonna care about?
It's kind of a funny story when my kid was,
my youngest was, I wanna say he was three or four
and he said, we used to build stuff together all the time
and we did all kinds of engineering things
and one day he said to me, let's make a cat.
And I said, well, like a robotic,
you wanna make a robotic cat.
And I said, well, let's make a list
of what are the design specs here?
Like what does this thing need to do?
And he says, well, it needs to move around.
I'm like, yeah, maybe like that, that may be doable
and it needs to make meowing noises
and it's pretty much doable.
And it needs to do something else that it needed to do.
And I said, yeah, probably we could do that.
And then he says, and it needs to care.
And I said, what do you mean?
You mean it needs to like walk over to you
and let you pet it?
He goes, no, no, not act as if it cared.
I wanted to actually care.
And I was like, all right, well, that's it.
You've just broke the whole project
because we don't have a clue
as to how that is going to happen.
And that is, you know, that,
figuring out how that ties into the whole,
you know, the cognitive light cone story
that I've been telling
and the kind of the spectrum of precipitability.
It's like intelligence is one thing,
problem solving is one thing.
But where does the care come from, right?
And what do we mean by that?
And a lot of people say things like,
I care about stuff.
That's just the machine.
They're usually pointing at some AI thing
or some robot or something.
And they say, well, that's just the machine.
Machines can't care.
And I'm like, well, you used to be a single cell.
And do paramecia care?
Because now you got a problem.
If you say that the paramecia care,
then well, guess what's inside of paramecia?
A bunch of molecular cogs and wheels.
So, you know, you gotta,
so maybe machines and certainly molecular biologists
see single cells as a kind of machine.
And that analogy has done pretty well for us.
On the other hand, if you say, no, no,
the paramecium doesn't care.
It's just a bunch of chemical reactions.
I mean, we can sort of see what's going on in there.
It's a bunch of chemistry that doesn't care.
I care.
Like, well, you used to be a single cell.
So why don't you tell me where that,
when the care got beamed,
like what stage of embryogenesis
does the care get beamed down, right?
That's a problem too.
So you got this real issue with people
who think in binary categories,
they get trapped in this pseudo problem
that I think I'm unsolvable.
So anyway, so we were really interested.
And then of course, from their perspective,
they're interested in the questions of,
there's a Buddhist story about care and compassion
and those kinds of things.
So I was interested to see how compatible those things are.
Can we use some tools from that thought?
I mean, there's a whole other thing,
which is this notion of the impermanence of the self.
And it goes, I mean, there are obviously
all different kinds of opinions on this
all the way from there is no such thing.
It's a total illusion, right?
That's one set of views.
And then on the other is the kind of like
the sort of demand on the street version,
which is, well, I've got this permanent to self
and it's this like thing and then it exists.
And then what I'm interested in
is kind of the space in between,
which I think is more accurate.
So, and by the way, I'm no Buddhist scholar.
I don't pretend to know who thinks what in that area.
I'm just, I'm trying to keep up with Thomas
and Elizabeth and so on.
But there's an intermediate version,
which is that it's not that you don't exist.
You do in the same sense as everything else exists,
which is as a useful metaphor.
And in fact, you are the most useful metaphor for all,
of all, because you might do away with,
you might somehow do away with metaphors
of talking about, I don't know what social structures are,
what grocery stores are.
Maybe you don't, maybe you now see,
like Eddington said, that a table is mostly empty space.
And so maybe you've internalized physics enough
to know that even the table isn't a great metaphor
that it's mostly fields and whatnot.
Like all of that is fine,
but there is this metaphor of a self that can do things
because it's on you to do stuff or not do it.
You have to make those decisions.
That's a pretty useful metaphor.
So I don't think it's not real.
I think it is real in the same sense
that everything else is real,
which is a useful construction.
Also, I think what's useful about it
is that it is continuously self-constructed.
And here's what I mean by that.
At any given moment, so right now,
you don't really have access to your past.
The only thing you have access to are the engrams
left in your brain and body by your past experiences.
That's all you have access to.
And from that, you reconstruct the story of your past.
So including the school you went to
and various other things,
you're building that right now at every moment.
It's a little bit like anterior grade amnesia patients
who can't form new memories.
And so they use these scratch pads,
at least some of them where you write down,
the first thing you write down is that
I have anterior grade amnesia
and then some stuff that happened.
And then at the end, that says,
and don't forget, write this note again tomorrow.
And that's your, like most of us have the same thing.
It's just internalized,
but now they're using the Stigmergically,
this outside tool because there's some problem.
So we are all really in that state.
It's just we're using an internal scratch pad.
Right now, you don't have any access
to what happened years ago.
You just have the memories and they're actively rebuilt.
And we all know our ability to rebuild accurately
is crap basically, right?
And these things morph and change and whatnot.
So the story of ourselves changes all the time.
I actually, I did a, I gave a talk the other day
at this UCLA symposium and I talked about Plenaria
and this idea, in Plenaria, if you teach them something
and then you chop off their heads
and the tail sits there
and then eventually they regrow a new head
and they regenerate their memories, right?
And so that means, okay, the memory is stored somewhere
to who knows where it is,
but the interesting part of that is the memories
are actually imprinted onto the new brain as it develops.
And so this new being, this new Plenarian
has to rebuild itself along with its memories.
I mean, I don't know how rich a Plenarian's memories really are
but whatever they are,
it has to like completely rebuild itself from these memories.
And that sounds all crazy and weird
and it sounds like the cases of like,
what's the, you know, Blade Runner and everything
when you find out that, oh crap, my memories aren't really
my memories, I mean, as far as this Plenarian brain is concerned
it just got downloaded a bunch of false memories.
That brain was not part of any of the things
that it remembers, they wasn't there, didn't exist.
So it's kind of a bunch of false memories.
And so, and so it was like, wow, these Plenarians are crazy
and this thing with the androids is nuts.
And my point was, no, no, no, this is what we are 24 seven.
This is completely normal because all of us
are reconstructing ourselves at every moment.
And I don't know how wide the moment is,
but I'm sure that neuroscientists will tell us
you are reconstructing yourself from these past memories.
And so I think that's a deep kind of philosophical thing
because, you know, your self isn't some permanent
monadic structure that just kind of exists.
It's an active construction, it's a process,
it's a constant information processing.
Autopoiesis, you know, of the mind doesn't stop
during embryogenesis, it kind of keeps going, it has to.
And it has these interesting implications.
If somebody, it will go going back to, you know,
I guess I'm now in the business of trying to normalize
a lot of things that people get freaked out about,
but you know, imagine, right?
So if somebody finds out that, oh my God,
like all of these memories that I have now,
that wasn't me, that were downloaded,
my body was just, you know, was it Boltzmann
or was it Humor, somebody had this puzzle,
like what happens if you're not,
if all your memories were just like,
you were created 10 seconds ago,
including your memories, right, or something like that.
If you think about it hard enough,
given that that's normally our situation anyway,
my answer is, who cares?
Great, like move on, you've got them now, go for it.
Now you've got some great memories, like roll with it,
because what else is it gonna be?
Of course you were just constructed with your memories,
what else could it be?
You are constantly constructing yourself
from the n-grams in your head,
you don't have access to what actually happened before.
You are, I just don't even, you know,
that view seems weird to people,
and I can't even verbalize what the alternative would be,
I just don't even understand what an alternative story
could possibly be.
So from that perspective,
you know, in fact, you can go further with this,
the body that I have now,
given the turnover of cells and molecules in your body,
was this body actually around 30 years ago
to do the things that I remember doing?
It actually wasn't, we know it wasn't,
even though I've not been part of some weird memory
replacement experiment, you know, and I'm not an Android,
this body wasn't there, I know it wasn't,
we know it wasn't there.
And yet I have these memories, so am I complaining?
What would you complain about?
If somebody told you that, you know,
yeah, your body was just, you know,
you were killed in a record,
or maybe your body never existed,
but we just made you,
and like here are some great memories of a past life,
like bring it on, fantastic, you know,
I hope they're good ones.
And because I don't know what the,
I don't even know what the alternative would be.
So I think, for that reason,
I think all of these things are really,
really hopeful and positive.
You know, they just tell us that,
we shouldn't be afraid of these technologies,
this is the amazing thing about being a self
in this universe,
is you get to constantly construct yourself,
and by the way, guide what happens in the future,
what you do now determines the experiences
you're going to have, the reactions you're going to have,
which of course, you know, those kinds of disciplines
and traditions are all about that,
about consistent practice to train yourself to be better,
to have, you know, to improve your cognitive,
you know, apparatus and so on.
And the commitment, this is the last thing,
the bodhisattva vow, which is huge,
it's this commitment, it's a meta goal,
it's the commitment to enlarge your cognitive apparatus
to enable bigger goals,
to enable you to pursue bigger goals
with more compassion facing outwards.
That I think is critical because I think,
once you are a system with the ability
to make that commitment,
it's sort of like, it's an exponential rise after that,
right, it's like discovering the scientific process.
Before that, it was all sort of screwing around,
you know, trial and error,
but as soon as you figured out
that there's a systematic thing that you,
I am going to literally work to get better at this
and to be able to have more,
increase my cognitive light cone of compassion,
you can now sort of exponentially go up
because you understand what you're doing,
it's not just, you know, just a random walk.
Yeah, now I love what you've said before too
about how something to this degree
that you can't control your next thought,
but you can't control your thoughts 10 years from now
by what you do today, right,
and what you do every day,
you can like influence the future.
One thing I really wanted to ask you about,
and it's not in this paper,
but I imagine other folks have worked on this,
the idea of what it's like to perceive,
let's say the self in a broader way.
And like you mentioned with the Bodhisattva vow,
and I think this is actually really nice
because it brings us full circle with our conversation
from our very first one,
which was around the cognitive light cones.
And in this paper, you do have a diagram
where you've like overlaid what the,
what someone with a wider sense of self,
say a one to help out the community
or something that's also one that takes the vow
to not achieve enlightenment until everyone else does, right?
It's like this leave no living being behind kind of idea, right?
But do we have any research or even discussions
with say monks, people who engage
in say like deep Buddhist meditative practices?
Do they perceive themselves as like a part of a whole?
Like is their actual sensory experience different
than say a very enlightened person like myself
or like most folks?
Like does that make any sense?
Like how they perceive themselves in the world?
Yeah, I think that's a great question.
I don't think I've got the expertise to answer that question.
I think you could talk to,
you could have Thomas Doctor on, for example,
and he's a very kind of experienced scholar in that area.
And I think he would, you'd have a good time.
You could explain all that stuff.
Yeah, yeah, I think I'll have to.
And let's see.
And that's great.
So you gave me so much to chew on and so much for the audience too,
I'm sure this idea that who you are today
is not who you were 30 years ago,
just in a very literal materialistic sense.
And that there's like just this illusion
of a consistent, continuous kind of experience.
It's a really, it's a wonderful way to put it.
And if you wouldn't mind, I mean, I do,
I'll probably overlay the cognitive light cone
with the Bodhisattva, the Bodhisattva vowel one.
How has this been, because this came out,
this paper came out about a year ago,
how has it been received?
Have you heard any response from the paper?
A little bit, a little bit.
Yeah, I don't know.
I don't track responses super, super carefully,
so I'm not sure.
Haven't heard a ton, but I'm gonna guess,
I'm gonna guess Thomas heard more on it.
But I think that, I've certainly had interesting people
reach out to me to talk about it,
which is pretty much one of the things
I hope for in writing these things.
So I've had lots of cool discussions.
I don't know more broadly.
I mean, I have no idea how, in any of these papers,
by the way, I have no clue if anybody reads them
or who reads them or what happens after that.
I don't know, yeah, yeah, well, I appreciate that.
And certainly people contact me,
but it's very hard to know how these things
are actually spreading or not spreading
through the community.
Gotcha, and I'm gonna let you go in a moment.
But before I do one last thing,
you're a big mid-journey fan.
You oftentimes have, seems like you're also a fan
of surrealist arts.
I've seen stuff from prompts that are,
like, do this in the style of the Codex Seraphoninus
or in the style of the Chironomous Bosch.
Do you know, like, what is it that draws you towards,
like, those kind of art styles?
I don't know.
I have had zero art training.
I kind of know what I like,
but I don't know anything about art.
I can't draw on myself at all, like nothing.
And yeah, and I mean, all I know is that
I really like, I'm really interested
in the space of the possible
and much, much more so than the actual.
And everything I look at art-wise
is either photography of nature or photography thereof.
I like nature, but other than that,
yeah, I'm really into imagining
what could be the latent space of possibilities.
And I think, you know, mid-journey and systems like that
are pretty cool in that respect.
They let you explore this wacky latent space
that it has of images of all different kinds.
Yeah, that's just kind of generally,
I think very much forward in terms of, like, what now,
what next, what could we do next?
That's, you know, maybe that explains a lot
of my kind of, you know, not getting worked up
about whether the past is real or not or what.
It's mostly the forward-looking stuff.
I mean, like whatever in the past, but like now,
what do we do now?
So that's more what I'm interested in.
And I like this kind of art that lets you,
yeah, imagine things that could be,
what are the possibilities moving forward?
Yeah, I share same love for that style as well,
those styles.
And I just want to say thank you so much, Mike.
These three conversations have been wonderful.
I appreciate your time, your energy.
And where should people find out more about you?
I'll link in the description.
Yeah.
Well, everything is, there's an official website,
the academic website is www.drmike11.org.
So one word, drmike11.org.
And that's got all the links to the papers, the software,
the presentations, everything else.
I've got a science Twitter presence at drmike11.
And I think in a couple of months,
there will be a WordPress site.
So I've been working on a site kind of,
yeah, I was sort of thinking sub-stack WordPress.
I decided WordPress.
And so there's going to be a site
that's kind of less the official academic stuff
and all kinds of writing that I want to do
that doesn't really, you know,
kind of tired of asking the question of,
you know, you write this thing and it's not really,
it isn't a primary paper and it isn't really a review
and it's kind of a perspective,
but it's really interdisciplinary.
It's way too long for a journal.
And I'm sort of just tired of this issue
of finding a home for it, you know,
what they say, like, where are we going to put?
Like, okay, forget it.
We'll just, it'll go there
and then anybody who's interested can read it.
And that'll be that.
So, yeah, so there'll be, that doesn't exist yet,
but in the next couple of months, it should be up.
Awesome, great.
Well, we will watch that space.
And I'll, when it comes live,
I'll update all the other videos so that people can get there.
That's great, I appreciate it.
Thank you, thank you.
Yeah, absolutely.
Thank you, Mike.
Thanks very much.
Yeah, thanks for having me on.
It was great, thanks.
It was awesome.
Thank you so much.
All right, all right.
