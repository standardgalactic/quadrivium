So a new scientific paper is released called Tree of Thoughts.
Deliberate problem solving with large language models.
It's by researchers at Princeton University
and Google DeepMind.
Now, you may have heard that saying,
we only use 10% of our brain.
Now, whether or not that's true,
this paper seems to show that it is true
for our current AI models.
This new approach to chat GPT's ability
to solve complex problems from 4% to 74%.
That's just from a new way of prompting it called
Tree of Thoughts, or TOT, as it's referenced in the paper.
The paper even comes with a warning.
TOT is a framework that empowers LMS
to more autonomously and intelligently
make decisions and solve problems.
While current tasks are limited to reasoning
and search problems, future applications
involving interaction with external environments
or humans could bring potential danger,
e.g. facilitating harmful uses of LMS.
In a nutshell, this approach seems to be a hack
to overclock these LMS to produce more intelligence.
But let's get to the chase.
What is this Tree of Thoughts?
These are different prompting approaches.
When you ask chat GPT a question and it answers,
that's called input-output prompting, IO.
Now, a lot of researchers and individual users
have pointed out that you can get better results from LMS
by using chain of thought prompting.
An example of this might be thinking of three topics
that you want to speak about,
then think through where each of those topics
might lead, then select the best one
and then produce the actual words that you're gonna say.
So same input, but then you're thinking about
the possible topics, what kind of conversations
those might produce, then selecting the best one,
and then the actual output.
This is the thinking before you say it part.
Yet another way to produce even better results
is something called self-consistency with COT,
with chain of thought.
So self-consistency is generating multiple results
for each query and then seeing which results
seem to appear the most,
aka which ones are the most consistent.
Combining self-consistency with chain of thought
can lead to even better results
than all the previous prompting methods.
But what is even better than that?
Well, Tree of Thoughts has the potential
to be many times more powerful
than the previous prompting methods.
This approach works really well for LMS
for more complex reasoning tasks.
Here's the abstract from the paper.
Language models are increasingly being deployed
for general problem solving across a wide range of tasks,
but are still confined to token level,
left to right decision-making processes during inference.
This means they can fall short in tasks
that require exploration, strategic look ahead,
or where initial decisions play a pivotal role.
To surmount these challenges, we introduce Tree of Thoughts,
which generalizes over the popular chain of thoughts approach.
This allows the LMS models self-evaluating choices
to decide the next course of action,
as well as looking ahead or backtracking when necessary
to make global choices.
And this significantly improves
language models' problem-solving abilities
on three tests that these researchers will test them on.
As you can see here, in one of the tests,
GPT-4 with chain of thought prompting
only solved 4% of the tasks.
So chain of thought, that's the next improved one,
that's one step better than base level,
while their method achieved a success rate of 74%.
That's a 10x improvement.
In chain of thought, think of it as two things.
So it's basically the breadth,
it's so how many different scenarios it starts up with,
and then the depth, which is how far down each scenario it thinks.
The key here is that it can look forward and backtrack
and save information in various thoughts
that can be used elsewhere.
So how did they come up with this tree of thoughts?
So they're referencing the work of Newell and Simon
from 1972.
They were pioneers in the field of AI.
They studied how humans solve problems proposing
that our brains work like computers.
We take in information, process it, and output solutions.
Research on how humans solve problems
indicates that people look through
a large number of possible solutions.
You can think of these solutions like a tree
where each point or node is a halfway solution.
And the connections or branches are actions
that can change these halfway solutions.
People decide which action to take based on guidelines
or heuristics that help them navigate
through all these possible solutions
and guide them towards finding an answer.
There are two shortcomings
that our current prompting model has.
One, locally, they do not explore different continuations
within a thought process,
aka the branches of the tree.
And two, globally, they do not incorporate
any type of planning, look ahead, or backtracking
to help evaluate these different options.
To address these shortcomings,
we introduce the tree of thoughts,
a paradigm that allows alums to explore
multiple reasoning paths over thoughts.
Now this paper goes pretty deep into the math
and specifics on how they did this.
I won't go to all of that here,
but I'll link the study in the show notes
so you can peruse it at your leisure.
But let's skip to the results.
So the first thing they did was they made a play game
called 24, Game of 24.
It's somewhat similar to Sudoku.
So Game of 24 is a mathematical reasoning challenge
where the goal is to use four numbers
and basic arithmetic operations to obtain 24.
So how they set it up is they took 1,300 over 1,300 games
and they sorted it from easy to hard
by human solving time.
So they started with the standard input output IO
and they prompted with five in context examples.
They also did the chain of thought prompting
and through each iteration,
the language models conditioned on all the previous history
to reflect on your mistakes and generate a refined answer.
If the output isn't correct,
note that it uses ground truth feedback signals
about equation correctness.
So ground truth is basically the real answers,
the answers that we know to be correct
for the AI to compare its results against.
So in the tree of thoughts approach,
the Chai GPT is asked to think
through all the possible combinations
and then they prompt that language model
to evaluate each thought candidate
as sure, maybe, or impossible with regard
to it being able to reach 24, the answer we need.
And then they perform a breadth first search
in tree of thoughts where each step
they keep the best five candidates.
So in the breadth first approach,
they expand the number of starting points
before going deeper.
Here in the results, the lowercase B here refers to breadth
or how many columns why they decide to go
before digging deeper.
And so here are the results.
The basic input output IO prompt is 7.3.
Chain of thought is 4%.
Then they use the Oracle setup with K equals 100 samples.
In simpler terms, they're testing how well this works
by trying it many times up to 100
and then taking the best results
to evaluate its performance.
In the most favorable conditions.
So it's basically running it a bunch of times
seeing the best outputs.
So that comes out with 9% success rate.
Then we have our tree of thoughts with a breadth of one
and the results are 45%.
That's a massive leap.
And then they run again with again B equals five
meaning so there's more starting points,
five starting points that it thinks through
and the results go up to 74.
So it's bigger by far than any of the other methods used.
Even these three other methods here
where they rerun the results
and pick the best of 100 for example.
So tree of thought absolutely crushes everything else.
Notice it's almost 10x.
The results of just asking GPT-4
to solve the problem one prompt.
So this absolutely crushes game of 24.
Next we're gonna look at creative writing.
Is this approach better for creative writing?
So next we invent a creative writing task
where the input is four random sentences
and the output should be a coherent passage
with four paragraphs that end
in the four input sentences respectively.
So here's basically how that looks.
So for example, it's given a task
of write a coherent passage of four short paragraphs.
The end sentence of each paragraph must be,
so then this is the four paragraphs
that are randomly generated one.
It isn't difficult to do a handstand
if you just stand on your hands.
That's true.
So you had caught him of guard
that space smelled of seared steak.
Okay, three, when she didn't like a guy
who was trying to pick her up,
she started using sign language.
Four, each person who knows you
has a different perception of who you are.
So this would be kind of difficult to put together
in a coherent storyline.
And so it generates several plans
and plan two, it's able to wrap it up
and present it in a self-help context.
So the handstand is part of self-help,
sort of as a metaphor for embracing challenges.
And astronauts embracing challenges,
including the smell of space,
then a woman's clever tactics, so again, challenges,
and contemplate how different perceptions
of oneself can shape one's identity.
That's pretty smart, I gotta say.
It connects the paragraphs with a theme
of self-improvement and embracing challenges,
making for a coherent passage.
So it takes the inputs, it plans out
multiple different plans that it can do.
It votes on which plan is the best
and only then does it actually produce the final results.
So as you can see here, the Tree of Thoughts
is definitely the best one.
It's a great improvement from the standard input-output
with Chain of Thoughts, sort of the halfway point.
But if you're using sort of that refine function
where you're basically asking it, okay,
refine and make it better, refine and make it better,
refine and make it better, over and over
until it determines that it's perfectly coherent,
well then the input-output method works,
you know, almost as well, I would say as the Tree of Thought.
And humans, of course, are creating Tree of Thought
as the most coherent one.
Next, we're looking at mini-crosswords.
So in Game of 24 and Creative Writing,
TOT is relatively shallow and most three thought steps
are needed to reach the final output.
Here we explore five by five mini-crosswords
as a harder search problem involving natural language.
So in the TOT setup, we leverage a depth-first approach
that keeps exploring the most promising,
subsequent word clue until this state
is no longer promising, then backtrack to the parent state
to explore alternate thoughts.
So results as shown is Table 3,
IO and COT Prompting Method,
input-output and chain-of-thought-prompting methods
perform poorly with a word-level success rate
less than 60% while Tree of Thought
significantly improves all metrics
achieving a word-level success rate of 60%
and solving four out of 20 games.
And here's that Table 3, as you can see here,
TOT, again, absolutely crushes everything else.
Next, they quickly dive into limitations.
So search methods like TOT require more resources.
So if you're on GPT-4 API,
it's gonna cost more to run something
that's like wide and deep.
It's cheaper to do sampling methods
in order to improve task performances,
but the modular flexibility of TOT allows users
to customize such performance trade-offs
and ongoing open-source efforts
should readily reduce such costs in the near future.
By the way, if you haven't heard
how open-source is absolutely crushing AI development,
more so than the best-funded companies on the planet,
check out the We Have No Emote video.
I'll link it in the top right of the screen
or in the show notes down below.
So this broader impact is very interesting to me.
So the TOT is a framework that empowers LMS
to more autonomously and intelligently
make decisions and solve problems.
While current tasks are limited to reasoning
and search problems, future applications
involving interactions with external environments
or humans could bring potential danger,
e.g. facilitating harmful use of LMS.
That is the warning, like people might be able
to extract much more power,
much more intelligence out of this
than we realize at this point.
On the other hand, TOT also improves the interpretability
of model decisions and the opportunity for human alignment
as the resulting representations are readable,
high-level language reasoning
instead of implicit, low-level token values.
So that means that using these sort of chains
and having it output its thoughts each time
helps us better understand what it's thinking
because we don't really know what it's thinking
on the super deep level.
When it spits something out,
we don't fully understand how it comes to those decisions.
But by sort of asking it to show its work,
to spit out its reasoning in English or natural language
at each step of the process allows us to kind of like
see where it's going with this.
And the conclusion is the associative system one
of LMS can be beneficially augmented by a system two
based on searching a tree of possible paths
to the solution to a problem.
Their saying is that GPT-4, it's strong out of the box,
but this way you can increase it even further
just by asking it to look down multiple paths
and see which solution lies at the end of each path.
The Tree of Thoughts framework provides a way
to translate classical insights about problem solving
into actionable methods for contemporary LMS.
I wanna know what you think, leave me a comment.
If you want daily AI news, I have a free newsletter.
It's at natural20.com, check it out
and hope to speak with you again.
