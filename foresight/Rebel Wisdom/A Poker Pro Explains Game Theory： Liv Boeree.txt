So, this is one of the most interesting conversations I've had all year, and it's with former
poker pro and scientist Liv Berea.
So Liv has a YouTube channel where she makes films about game theory, complexity, physics,
a lot of other really interesting topics, and we covered a lot of ground in this conversation,
including what she learned about intuition and logic playing poker.
Everyone in the world tells you, oh no, trust your gut when it's got a really strong feeling,
it knows, it knows something that you don't.
And it's like, well, this is clearly not true, because it's often wrong, and it seems to
be largely, am I having a good day or a bad day?
If I'm having a good day, my intuitions tend to be more optimistic, if I'm having a bad
day, my intuition is pessimistic, so I can't trust it that much.
We also talked about game theory and why it's such a useful tool for sense making.
It's just the mathematics of these competitive situations, effectively, looking to see what
optimal strategies are, suboptimal strategies, and the phenomena that arise out of them.
And we delved into a concept popularized by Scott Alexander called Molok, which took the
conversation in a really interesting direction.
And what he really did for the first time was he related Molok to game theory, and talked
about how it seems to be this sort of the force, so again, if there's this force of
something that's driving the emergence and complexity, there seems to be this opposing
force, which is a force of destruction that sort of uses competition for ill.
Molok is the god of unhealthy competition, of negative sum gains, so competitive interactions
that make the world worse off for their existence, as opposed to being neutral or better.
Liv is also one of the speakers at our free state of sense making event on the 25th and
26th of September, so you can sign up for that down in the show notes, and I hope you
enjoy the film.
So Liv, welcome to Rebel Wisdom.
Thanks for coming.
Thanks for having me.
So you're a former pro poker player, and you also have an interest in game theory, which
is something that we've covered on the channel and something we're always wanting to learn
a little bit more about.
But the first question I wanted to ask you is, can we play our way out of all the sort
of game theory traps we find ourselves in, by which I mean the broken information landscape,
institutional corruption, culture wars, polarization, obviously the list goes on, or are we just
completely fucked?
I mean, that's the quadrillion dollar question, right?
I certainly don't know the answer to that.
I sincerely hope that there is a way out of it.
I don't see what it is, in all honesty.
It's something that consumes my thoughts on pretty much a daily basis.
But there's something in me, call it dumb optimism, call it the belief.
If there's these sort of dangerous forces, sort of semi-entropic forces trying to break
down complexity, the complexity that is civilization in one direction, it almost seems like there's
some kind of force pro-complexity trying to hold everything together and keep this weird
world that we're in going, keeping things interesting.
So yeah, I mean, I don't know what the answer is.
All I know is that we are in an unbelievably critical time of the past decade and certainly
the coming decade.
It's definitely, we're definitely in the most interesting time in human history.
Okay, sure, I might be biased, seeing as I'm here, and we like to be the kings of our
own stories.
But yeah, shit's getting real.
Which leads me to a question I wanted to ask you about.
A lot of the people we've had on the channel, like Daniel Spaktenberger or Jamie Weill or
Jordan Hall, who've talked about existential risk in particular, seem to be quite pessimistic.
And then there's other people who have a kind of, there's a meme called Dumer Optimism,
where there's a sense of, yes, we're screwed, but within that we have some kind of hope
and a kind of optimism in spite of that.
And then we have people like, there's lots of different sort of tribes, like extinction.
So deep adaptation, which is a big influence on, for example, extinction rebellion, which
is this sort of environmental version of, we're all screwed, it's already done.
We need to go live in cabins and we need to be, it's all, I think it has kind of a religious
quality to it almost.
Yeah, I'm curious about how optimistic or pessimistic you are about the current state
of affairs.
It depends what day you're asking me.
Right now I'm in a more pessimistic mood simply because I read this article by Kaifuli yesterday
talking about the next generation of warfare that we're entering into with these, you know,
with autonomous weapons and particularly AI-driven ones.
It's not inconceivable within a few years that for $1,000 you can, and a little bit
of know-how basically build an entirely anonymous drone that can take out whoever you want.
And it will not be able to be traced back to you.
And that's just the beginning.
And you read that and you're just like, I don't see how we will ever make it.
So right now I'm in a pessimistic mood, but after the weekend I did a little Burning Man
ceremony and just felt the magic a little bit and I was like, no, we're going to make
it.
And it's weird.
It's like a, I mean, you could almost say, is it like a sort of left brain, right brain
thing?
You know, logically I don't see a way out of it, but there's like some intuition in
me that feels like we're going to make it.
But then sometimes my intuitions are just like, no, like also, like I don't see a solution.
So I don't know.
And I guess perhaps the thing to do in the face of that, you know, this constant uncertainty
and this oscillation between the two extremes is to, you know, which state of mind would
I rather live in more?
Given that I don't know which one's the right one and I seem to be able to go into both,
I might as well invest in what I can in myself to control, you know, am I more likely to
wake up in an optimistic mood or a pessimistic mood?
And I can control that to an extent by, by, you know, taking care of my information diet.
What do I read?
How much time do I spend on Twitter?
You know, definitely the pessimism is correlated to the amount, you know, my, what my, my phone
tells me I've been looking at Twitter, you know, how many minutes per day?
You know, part of the thing I hate about, you know, you go on to Netflix or whatever
right now, it's just the amount of dystopian art out there to utopian art is like a hundred
to one.
Probably worse even.
There's just, there's just so little utopian programming, films, books.
And part of the reason I think is because it's just much easier to imagine a dystopia.
You know, one of the reasons why utopia doesn't exist is because it's incredibly hard to build.
So again, if you have a more optimistic society, then it gives people the space to dream up
and think of more positive things and it gets the ball rolling in the right direction.
Yeah, I like that.
There's a bunch of stuff in there I'd love to pick up on the choice to be optimistic.
You know, I think that is a very interesting thing in the times we live in.
And it doesn't surprise me that it's actually something I've written about before the fascination
we have with dystopia.
I think is in, I think there's lots of reasons for it, but I think in part I've described
the world we're living in sort of culturally is like a noir story, like a noir detective
story where you have the detective going through the often like encountering different institutions
like the church and okay, it turns out the priest is in on it and corrupt and like corrupt
to the core and then the judges are corrupt and the police are corrupt and everyone's
corrupt except for the detective usually and plays this kind of chivalric role of the kind
of broken but all like roughly altogether pure of soul somewhere in there right and
they're like, but there's light in the darkness, but they're sort of like hitting the whiskey
because like just to be the light in the darkness is so much and I think I think there's something
in that as a kind of as an image and there are and also just kind of, you know, it we're
recording this not long after the 20th anniversary of 9 11 and the the sheer shaking foundational
shaking impact of things like 9 11 and the financial crash and many other things that
have happened since then in terms of institutional trust. I think we we have this sense of being
in or moving towards a dystopia, but I'm very interested as well in something you were
just talking about in the the optimism within that right the the kind of and even so there
is this kind of there is this hope so I wanted to talk a little bit about game theory because
this kind of points towards a critique I have of game theory, but I thought it'd be cool
to to just kind of get a bit of a definition of what game theory is before in case anyone's
not really familiar with it. All game theory is is a branch of economics basically, which
typically deals with competitive systems and it looks at the strategic, you know, it describes
people or decision makers within it as agents typically just so that it's not human centric,
you know, AIs could be decision makers or whatever, mice, rats and so on. And it's just the mathematics
of these competitive situations effectively looking looking to see what optimal strategies
are suboptimal strategies and the phenomena that arise out of them. You have an interesting
position in this because you're a former pro poker player. And so, you know, one could argue
maybe this is wrong, correct me, but is that you were sort of having to apply game theory
under tremendous pressure with high stakes. But I'm curious about on the table, how much
of that is game theory and how much of it is, obviously, experience and then intuition,
which is another thing I'd love to talk about. But, you know, the critique of game theory
is often just like with with modern economics is that it relies on on actors being rational.
I know not all game theory does, but this idea of rational actors looking after their
self interest, you know, it turns out we're not really rational actors, but I still think
it has a lot of value. How applicable was it to to your poker career?
So I think we need to step back a bit in terms of like describing what's going on at the poker
table. So you will have, obviously, seven or eight other people around the table. And
your job is to basically sift through all the different forms of information that you're
receiving in order to figure out what the optimal decision is. And you've got multiple decision
points. And there's a broad range of information that you're receiving, like from, you know,
the the the amount that the person bets, the the cards that you have relating to the cards
on the board on the table, the the the demeanor of the of the person, you know, like that
you know about their past experience, how much they've played. But then now their face
is doing something funny that you never noticed before, or they're breathing heavier or something
like that, something they say. So there's this, there's a lot of qualitative and quantitative
information coming in. And where game theory comes in, really, right, in this, in the case
of poker, typically game theory applies to the strictly quantitative stuff. So, you know,
the there will be certain probabilities with which other cards will come out. And you you
know that the sort of odds that the that are being offered to you based upon your bet and so
on. And what that means based upon that information, effectively in a vacuum, the map, the
quantifiable information is that there will be these mathematically optimal solutions to these
different situations, which are, because there's so many possible situations, they're very hard
to calculate. It doesn't, it sounds like, oh, so you just need to remember the math, no. But
what game theory will do is basically suggest that there are certain strategies
that you will want to employ in certain situations based upon this quantified information. But then,
of course, there's this, this like nebula of other stuff coming in, like, well, yeah, but they
were breathing funny, which they weren't doing before. How do you quantify that and so on.
And in terms of how much of that nebula sort of applies to your overall decision making,
I hate to put like, try and put a percentage on it, but it's by and large, like, 90% of the
quantified stuff. And then the the the like, these sort of fuzzy things around the edge will count
for 10% of your decision. A lot of people, so when I first started playing poker back in 2005,
no one really understood game theory, no one understood the mechanics of how the game worked.
And the best players in the world were basically these like, they were typically older,
kind of like hustler types, who had just spent decades in casinos, just seeing the gamut of
human behavior and developing really strong intuitions about people. And so often they'd
make these these these strange plays that would turn out to be correct. And they wouldn't even
be able to explain to you why they did it. It was purely this sort of automatic unconscious
intuitive process going on, which and their intuitions were basically better than everyone
else's. But then when online poker appeared, and we started getting like, data analysis software
and this kind of stuff, you now all of a sudden we had data that pros could look at and and use
to analyze where they were going wrong, you know, where are the leaks in their game. And this kind
of, you know, it lifted the lid lifted the veil on what's going on in poker. And now people to
realize that, okay, there's mathematical solutions to this. And what it meant was that the game
basically went through a sort of scientific revolution, away from this pure artistry of just
feeling and having a vibe of someone to to going, Well, actually, look, this is the mathematical
optimal solution. I'll stick to this until I get such strong overwhelming evidence from
something else that I might override it. And in that, you know, in some ways, I hate this, but
in reality, like you cannot be a top professional these days without having that mathematical
foundation. You just no one's intuitions will be able to surpass knowing if you're playing as
someone who's playing a game theory optimal style, even though in some ways it's kind of robotic,
you just can't beat it by pure intuition alone. But of course, you know, if someone is now playing
not quite perfectly, now you can have these other like these these other like fuzzy skills,
you can bring in these fuzzy skills to figure out how the how to exploit their mistakes.
But yeah, the very long winded way of answering basically, it's it's by and by and large a very
mathematical game over 80 90%. That's really interesting. Fascinating. I really like that
that kind of laying out. I got a nice image there of the various sort of data points that are
happening and many of them at the same time, which is a bit like, I mean, that's, you know,
trying to make sense of something online is a little bit like that as well.
Yeah, and and I think it's interesting with like the particular so the game of poker, I think
can we can look at also life in general through that lens in a lot of ways like we
like I also have this kind of yearning for being purely intuitive, right? But I also am aware that
intuition really does lead us to stray a lot of the time, right, especially when we're trying to
make sense of complexity. Something John Varvakey, we've had on the channel a lot talks about in
cognitive science terms, you know, how do we how do we make sure the frame that we're looking at
everything through like the like he uses the example of like the glasses we're wearing,
how do we know that that frame is accurate? And of course, it's never 100% accurate, but
practices and techniques that help us take the frame off and go, Oh, yeah, shit, that's a crack,
that's smudged that I'm seeing everything wonky, clean it a little bit, put it back on. And that
process of continuously regenerating our frames, I think is kind of more important than ever.
At the same time, there is something, well, I would use the term kind of like transcendent or
magic about the power of intuition. And so when we're looking at something like, well,
actually to rewind a bit, I mean, I see this come up in culture a lot, I'm sure, you know,
this has been a real trend of people trusting their own intuition over, say, the opinion of
experts. And that happens a lot now. And there is good reason why we don't necessarily trust
experts. You know, I mean, I read an article recently, which was, you know, making the point
about America had access to the absolute best experts in international relations,
counterinsurgency, etc. For 20 years, when the and yet the pull out of Afghanistan was a
complete catastrophe, right? Unlimited budget almost unlimited expert credentialed experts.
A few experiments have been done where an educated so there's a caveat to this,
really someone who's decently educated on a topic, trying to predict the future based on that
information, it gets about the scores is roughly in line with a credentialed expert. So and I'll
put in the show notes probably the article that was from actually read it this morning, I think.
It raises an interesting question though, right? So we need to be able to have some
way of not getting completely deluded by our feelings and our intuition, which it which it
tends to do. And every time I notice it's happened to myself, I'm like, Oh, that's a bit embarrassing.
I really shouldn't have been so certain. But it keeps happening, obviously, because we're human.
But and then at the same time, we need to know how to trust it in some way. I think so I'm curious
to hear your your journey with this. I know you were kind of at one point sort of anti intuition,
then you've gone kind of in a bit of a journey with it. Yeah. I mean, I started out, you know,
prior to poker, my decision making process was just a delightful mix of deep overconfidence
and emotionality. Just I was a highly emotional, you know, it was 20 year old girl who
was the bee's knees and everything and hadn't learned about life yet. And then poker came along
and didn't always you know, the great thing about poker is that it's like got these like quite tight
feedback loops where well, just tight enough so that you will eventually realize that you're
clearly not doing something right because you're losing money. But loose enough where you can still
be deluded for a while about your relative skill level, you know, because there is this luck factor.
And so you part of the hardest thing is figuring out when you know, when things are going wrong,
is it because you're making bad decisions? Or is it because luck is not on your side?
Because it can be both or a mixture of the two. So you know, you've got your your system one,
which is like the classic like intuition, this unconscious process, and then system two, as I
call it, well, Kahneman calls it, which is like this, the voice in your head, you know, what's 471
plus 86, that'll be your system two at work. And so then I was like, okay, so really what poker
is about is about this linear system two stuff, this this thinking things through like solving
a math problem, and which it by enlarges. And, and then and I would sometimes try and you know,
I'd be playing, and I would, you know, facing a big, you know, big, typical decision, someone's
put me all in on the river, I'm facing my tournament life, you know, heart's pumping in my ears. And
my gut will be saying, oh, a fold, fold, fold, they've got it this time. And the maths will be
saying, cool, no, you've got to call you've got, you know, your hand is statistically good enough
to do so. And I would, for a while, I would be like, well, my, my, no, my gut is so strong,
I'm going to just listen to that. And on, well, I don't know whether it's more often than not,
but on a sufficient number of occasions, my gut was completely wrong. And I was like, huh,
this is interesting, because everyone's been telling me, you know, but everyone in the world
tells you, oh, no, trust your gut, when it's got a really strong feeling, it knows, it knows
something that you don't. And it's like, well, this is clearly not true, because it's often wrong.
There's bias, and it seems to be largely by large, you know, am I having a good day or a bad day?
If I'm having a good day, my, my intuitions tend to be more optimistic. If I'm having a bad day,
my intuition is pessimistic. So I can't trust it that much. And, you know, that was sort of,
then I did my TED Talk a few years after that where, and I still stand by the contents of it.
Basically, I, I, I shit on intuition a little bit saying, you know, if you Google it, the internet
tells you that it's, it's this perfect source of knowledge, you should never second guess it,
always trust it, and so on. And I think that's actually very dangerous advice, because
there are some things your intuition is really good for, and some things it's terrible for.
And the main, without going into the details of what all those things are, the main thing is,
basically, if it's something that, if it's a decision you've made many, many, many times,
then your intuition is going to be pretty good. Which is why our intuitions are all from quite
good around like social things, you know, you meet someone and you get like a weird vibe off them,
and you don't quite know why. You know, you've met a lot of people, by the time you're in your
thirties, you've met a lot of people. Chances are your intuition is fairly good, and you should
listen to it. But if it's, you know, if you've started a new job, and you're solving difficult
problems, that you haven't quite figured out how to do the like logic for yet, relying on your
intuition isn't a good idea either, because it, ultimately, it needs some data and experience
to be based off. As far as we know, it's not this purely magical thing. Might be sometimes,
but we'll get to that. So yeah, so then I sort of went into this, like, deep skepticism of using
intuition. Certainly, you know, and certainly was, my message was, don't overreel on it,
be very careful, because it can be biased. But then, more recently, funnily enough, after a
conversation with Daniel Schmaxenberger, who always manages to, like, anyone who has ever met
him, he just like shakes people's brains up. One of the things he said to me, we hadn't
had much of a conversation, but he pulled me aside. He's like, you need to get in touch with
your feminine side a bit more. And I was like, what? What does that mean? And I was initially,
like, annoyed me. Because I had, historically, sort of associated femininity a little bit with
weakness. I'd always, you know, I've always kind of been attracted to typically male pursuits,
you know, physics, heavy metal, poker, you know, it's all very predictable. To the point where
I then started to associate feminine things with weakness, and so on. But it was just that I didn't
quite understand what femininity is. And what it kind of, you know, if masculinity is kind of like
this outward seeking, looking for some strict type ways of defining and viewing the world,
femininity is this more sort of passive, inward facing, reflective form of thinking,
a form of wisdom. It's just like another form of wisdom. And that's what I think he was getting
at, basically. He's like, play around with your feminine side and it will enable you to
start listening to your intuition a bit more and respecting it. And he was absolutely right.
And since I started doing that, I don't know, life just became a bit easier. And
just, I don't know, I just felt like more of a whole person. It's hard to describe. It sounds
a bit weird, but it was kind of cool. I really like that explanation of when intuition is useful
and when it isn't, right? It reminds me of, so there's something I've been quite influenced
by is the work of a guy called William Duggan at Columbia Business School. And he talks about
strategic intuition. And strategic intuition is basically our, so he uses it, he talks about
creativity and innovation through it, but has these four different stages of how we come to new
ideas and how we kind of get new insights. And the first one is examples from history. So you've
done, like you said, you have lots of experience in the thing. It might not even just be in that
thing, you have a whole database in your brain of, let you use the example of social interactions.
So that we have all these different kind of social interactions there and are unconscious in the
library of our memory. But then we also have loads of other things connected to that, loads of
different frames, we have lots of different, so let's say kind of horizontal connections. So it
might be, okay, I also know about this person's culture, or I also know about the cultural
context of where we are, or I'm having this interaction with someone at a roller skating rink.
Well, I know how people are at roller skates, so all these different things are going on.
And of all that information, then unconscious, so the second stage of this innovation process is
presence of mind. So you don't try and find the answer, which goes into that receptivity you're
kind of talking about. It's, okay, well, I'm just going to be awake and aware and allow my unconscious
to do its thing. And then the third stage is the eureka moment, which he calls a kudwi, which is a
strike of the eye in French, which I don't exactly know where they got that phrase from. But it's
a kind of, and we've all had that experience of something hits you like a ton of bricks,
and it often happens when you're not trying to solve the problem. You were taking a shower,
you're walking the dog, whatever it might be. And then the fourth stage is the resolution to carry
it through. And something I used to do with companies and was on a kind of campaign to get
rid of brainstorming, because brainstorming is really awful for that creative innovation process.
Because what brainstorming is really good for is going, here's many ideas, let's as a group hone
down the ideas to one, what is terrible for is here's a blank space, make ideas, because that's
not how the process works, according to Duggan. And he goes into the kind of neuroscience of it.
But one example he uses in that is of a fireman going into a burning building and having this
intense feeling of get out, get everyone out. And this is a real life example. And I think
there's quite a lot of them goes in doesn't know why that can't see anything in particular that's
telling him this is incredibly dangerous. But has seen so many fires that somewhere is intuition
is like something's off, get out, obviously get out the building, the whole thing collapses like
five seconds later. That's what you're talking about. It sounds like you have the intuition.
Well, well, I mean, usually when people report this kind of thing, they can't quite identify
what it was. But there will be some element in the in all of the complexity of the environment
that is connecting with a preexisting element, which is Oh, that time where that happened. And
this I also noticed that slight offness to the smell or whatever it might be that you can't
consciously notice. So in those moments that kind of screaming intuition. But if I walked into a
burning building, I'd probably have that screaming intuition the whole time. Get out, get out. So
yeah, I really quite like that example. So one of the aspects of game theory that we've talked
about on the channel before. But I don't understand that well. So I'm going to ask you about it is
multipolar traps seems very relevant to the times you live in life. So what is a multipolar trap?
Yeah, a multipolar trap is is basically another word for race to the bottom type scenarios,
which involve typically coordination problems. So a group of people who are in a system where
there's some level of competition, you know, they're competing for thing x. And in order to get more
of x, it typically means that they have to trade off some kind of values. And inevitably,
that trade off will keep happening more and more because there's individual incentives on each
person to do that. And it results in everyone ending up in a worse state than they they would be
before. So an example that is very fresh to mind because I just made a video on it is
the these new face filters that I don't know if you've seen or if you spend any time on Instagram
don't. But if you do go on there, particularly for women, but men as well, there's this just these
unbelievably good AI driven filters that you can, you know, you put your photo in,
and you press it, and it will just make your face slightly more optimal. And it's often quite subtle.
I mean, there's ones that are very clear and blatant. But the most dangerous ones are these
really subtle ones where if I was to just show it to you and you hadn't really met me before,
or you didn't know me, you would have no idea that it's there. But for the user, you see it,
you know, you can do it before and after of what your natural face looks like. And then with this
thing, it makes you absolutely hate your face. Like, like, it's astonishing. And you can apply
this to like, Angelina Jolie, you name it, the most beautiful people on earth, and it will make them
look like trash. By comparison, because you know, we're such relative creatures, right, we always
just like, we're always comparing. And these things are super cheap, they're completely ubiquitous.
And, you know, I've done all right in the looks department, and I'm like a fairly well established,
you know, mentally, you know, chicken her like mid late 30s. And they're messing me up hard.
Like I like to the point I now I've used them on my pictures to try it out, like I'm like,
how do I ever not use this all the time. So what the hell it's doing to teenagers is just like,
I can't imagine because I mean, like, they're having to compare their faces to the best, you
know, like the Hollywood version of themselves. And so the way this relates to like a multipolar trap
is individually, even if someone knows that this is bad for them to use this, and they know it's
bad for like, their followers to, you know, to be posting these pictures, because it makes their
followers feel worse about themselves. If you're trying to make it as an influencer on Instagram,
how do you do that? Well, you, you, you want to post the best pictures of yourself possible,
like typically beauty and sex cells, ultimately. So individually, everyone is incentivized to
actually use one of these, these, these apps. And then even if, and even if people get together
and say like, this is bullshit, we shouldn't, we shouldn't be doing it, you know, it's bad,
it's bad for us and for everyone else. Ultimately, it's still such a competitive rat race that
there's such a pressure on everyone to quietly go and use one, particularly as no one can really
tell if you're using it. And then people will suspect that others are using it anyway. So then
they're like, well, I might as well. And then basically everything falls back down again. So
it's impossible to get like a, a reliable, you know, a, a solid pact going where no one uses
these things because of these incentive pressures. So it's turning beauty, because beauty was kind
of historically considered to be something that correlated with health, right? That's kind of
how it originally emerged back in, you know, presumably in prehistoric times, females wanted
to mate with males that showed signs of evolutionary fitness for their environment.
But then there are points like, like with peacock feathers and so on where
sexual selection and like what's good for your environment, you know, for your survival can
like decouple and diverge. And then you stop optimizing for this like secondary trait.
And, you know, so basically where beauty can get decoupled from health. And that's, to me,
these, these apps are like the ultimate example of that because you're like, we know they're
unhealthy for us mentally. Like there's tons of studies out there which are showing this just
actually really, really bad for teenagers in particular. And yet we, because they make us
look so good, we can't stop using them. So yeah, that's like a multipolar trap where you just can't
get everyone to agree to not use them. Yeah, that's a great and terrifying example, isn't it? It's
quite, yeah. I mean, it's a very mild example actually, you know, in the grand scheme of
multipolar traps, there are much, much more dangerous ones, you know, like AI arms races
and so on. But it's like a nice little example because it's, I think it's also a good example
because it's something that a lot of people who aren't typically exposed to these kind of ideas
can relate to. Another thing that we're kind of skirting around is the topic of complexity.
And you have a background in physics as well. And the kind of complexity theory,
what doesn't necessarily come from physics, but I think it's kind of the physics and yeah, I mean,
they're like brothers and sisters, they're not the home of complexity theory. So why are you
interested in it? What is it about complexity theory you find useful? I mean, it's just,
I mean, it's kind of the study of what is, right? Because, I mean, whether or not you believe in
aliens, like the earth, what's going on on earth right now is just so, from a computational
standpoint, it's probably the most complex thing within our, certainly within our pocket of the
universe, in my opinion, and probably the observable universe. And it's this weird,
you know, it's kind of poetic in that like complexity to describe something that is hard
to describe. And it's by, even by that, we struggle to even come to a definition of what
complexity is. So like, that's why I just find it so fascinating, because we just, it's like
really like the cutting edge. So it's very much a frontier of knowledge. You know, just like we,
there's certain things in fundamental physics we haven't figured out. We really haven't, we just
don't have like a solid theory of complexity yet as a civilization. We're getting there.
And it, I think will be, again, this is an intuition, but it, I feel like understanding
complexity is kind of essential, or at least having a firm grasp on it is essential for us to
make it through. You know, we are in a more complex stage of civilization than ever before,
and it's only getting more complex. And to an extent, we want it to get more complex, because,
you know, if we do blow ourselves up, that's a permanent reduction and curtailment of complexity
in the universe, which, as I mentioned to you before, I think is very bad. And so, yeah, I just
think it's, I just think it's an absolutely fascinating topic. And every time I speak to
someone about it, I always learn something new. That's the interesting thing as well. You speak to,
not even necessarily experts, just asking people to define it. It's like, wow, I didn't think of
that before, which is usually a sign that it's a really important topic. Yeah. And what are some
of the elements, I mean, maybe useful if we talk a little bit about the elements of a complex system
compared to, well, one useful way as well is the difference between complex and complicated.
Yes. So maybe we could start there, and then we can talk a little bit about what happens in
complex systems. So a nice definition of complex versus complicated. Complicated is the opposite
of simple. So something that has, you know, many, many different bits and so on, and is, you know,
many, many sort of constituent parts. Whereas complex is the opposite of independent.
So the, the, the, so the main way a complex system differs from a complicated one is a
complex one is sort of, it has this, this level of sort of self, self-referentialism,
and it has these feedback loops and so on. And also it evolves over time. So a complicated system
has lots of different parts, but is otherwise static in time by and large. And so it's, you know,
if you were trying to simulate it, you could actually simulate it quite easily and also explain
it. Whereas a complex system, because there's sort of so many more like levels of dimensionality to
it, which are like changing and feeding back into one another. And it's sort of like these
sweet spots between all these different dimensions of things. It's very, very hard to describe
and also predict, which is sort of relates to this idea of emergence as well, because
a complex system is basically something that has emerged from something of lower complexity.
And this process of emergence is often like kind of a black box. We don't understand how and why
it happens. You know, like no one could have predicted the internet, even in like, probably
like 1890, which, you know, in the grand scheme of the timeline of humanity is nothing. But it was
this unbelievably complex thing that came out of an already complex system, and yet it would have
been impossible to predict. And so, yeah, that's the main difference to me. Yeah, that's a great
explanation. I haven't heard that one before. The image that came to me was a complicated system.
It's like a grandfather clock, right? And a complex system is the Amazon rainforest. Yes.
Yeah. And I just got this image of a grandfather clock sitting in the Amazon rainforest, as this
kind of juxtaposition, but just how incredibly different they are. You know, it's really recent
that I've become more interested in complexity. And part of it, part of what's really exciting
me about it, as I'm on this kind of, what I feel like will be a very long journey of understanding,
is that the sort of enlightenment project that began perhaps in the 1700s, all the way up until
now, I would argue, was we can look at the world and figure out how it's like a grandfather clock,
given enough time. And then as scientists progress, we've been like, okay, actually, maybe our model
was wrong. Maybe maybe the universe isn't like a grandfather clock. Maybe it's a complex system,
which I think is pretty much the truth that we've kind of arrived at. But what I'm seeing as I kind
of delve into this is just how important complexity is as a framing for so many different things.
So many of the things we've talked about on Rebel Wisdom as well, like, you know, trying to make
sense of the information landscape, trying to look at the culture wars and figure out, okay, how the
hell do we come into some sense of coherence with one another? How do we revive the common so we
can actually have new type of conversation? All of those are complex problems, because they're all
feeding back on each other. And then there's this hope of emergence, because we don't know,
like you said, we don't know what's going to emerge from the interaction of all those different parts.
My sense is there's something like a new religion of sorts could emerge, which would completely
flip would be the next thing that completely flips our entire way of working and communicating with
each other because we cannot coordinate right now. And the thing that has helped us coordinate has
been that in the past, right? So I mean, yeah, a really appealing meme. Exactly. Something that is,
and I think we have no, I don't think it would look anything like the religions that have come
before. And I've argued that it's sort of brewing as we speak online, and then breaching, I've called
it the age of breach, because things are brewing online, and then breaching into consensus reality.
And so far, it's been quite nascent, like the like GameStop, or the capital riots, where it's like,
oh, God, that looks like a new thing. And then it's like, well, it all collapsed, but
who knows? Yes, there's like a boundary between this like this, this whatever is underneath
there, and then what's in our world, and that boundary is becoming more and more
looped in some way. Definitely. That's what you describe it. It's like a larger surface area or
something. And, you know, things will pop through. And then, yeah, no, I mean, I mean, the religion
topic is a whole other thing. I, I by and large agree that not only will we likely see some kind
of new religion, and it's almost seems like people want to need that. But I think we should have
something. And my main problem I've had with all the past religions is just they've been,
they're just really unfun. They just buy not all of them, but by and large, they're about
no sex, no drinking or whatever, like just they're the antithesis of partying.
And again, like, there are some good pockets within some of them. And I think those are the
ones that, you know, have flourished for a while and so on. But clearly, it seems to be some part
of the human spirit we want to worship. We want to think of something bigger than us. That to me
is some evidence that there might be something bigger than us. And but regardless, like, why,
you know, why not play into that? Why not use that? But at least, I mean, I've been thinking
about this for a little while, I think there's, there's value in actually brainstorming,
collectively, what would we want if we were to design a religion, what would it look like?
I think it's worth certainly the viewers of rebel wisdom and people thinking about like,
just spending some time to write down five things that they would like about religion or
something like that. And then we hive mind it and see what comes.
Yeah, I'll join right now. Straight up. Before it even gets developed. Yeah. Yeah,
that it's a very it's an interesting one. It touches on something we've talked about as well,
which is this sort of this strange relationship we now have with with rationality and reason and
our understanding of of what that is. And our conception of ourselves as rational actors when
we're we're sort of anything but and yet we do have this capacity to take a step back and be
reasonable. I'm fascinated by that dynamic in particular and how it's how it's showing up
culturally, you know, this sense of on every side of the political, let's say every tribe
in the political spectrum, there seems to be this sense of, I feel like this, therefore,
this is truth, whether it's in sort of successor ideology of progressives right now, or whether
it's in the the kind of rabid certainty of, you know, some people on the right about their
their own views. There's a sense of feeling an emotion overtaking our sensemaking. And I think
often religion has been the necessary place to pour that energy with other people as well.
Yeah. And so I think without it, we're, I mean, we've talked about this a lot, we're totally
adrift in a hurricane. Yes. Yeah. Yeah. So yeah, I'm I'm curious. And I think it'll be weird as hell,
whatever, whatever emerges will be weird. Yeah. Yeah. So you actually, when we were talking before
before this discussion, you actually introduced me to a concept I hadn't heard of before,
which comes from, well, Scott Alexander popularized it, but it comes from an Allen Ginsburg poem
originally. And before that is it, I think a believer Sumerian God, Canaanite God called
Moloch, right? Yes. And I got quite excited when I came across this, and I'll talk about why in a
bit first we should talk about what exactly it is it relates to complexity. And there's this
other concept called Moloch. And yeah, what is it? Yes, I mean, you summarized where it's where it
came from quite well, it was originally the, it's either the Canaanites or the Coffinogens,
I don't know, but it was a God of war, that they supposedly sacrificed their children to
by putting them into an oven and burning them so that Moloch would be happy and they'd win their
wars. So really, that was dark as it gets. And then it became more popular when, when Allen
Ginsburg wrote this amazing poem called, it's actually called Howl, talking about this thing
that sounds sort of analogous to capitalism, making people mad. And then Scott Alexander
really nailed it. But he wrote this unbelievable blog called Meditations on Moloch, which was
the first time I've seen, basically, he's trying to analyze what Allen Ginsburg is talking about,
this this sort of mechanistic thing. And what he really did for the first time was he related
Moloch to game theory, and talked about how it seems to be this sort of the force. So again,
if there's this force of something that's driving the, you know, emergence and complexity,
there seems to be this opposing force, which is a force of destruction that sort of uses competition
for ill. And, you know, the way the way I'm terming it, I'm doing a video series on this,
and I'm terming it as basically Moloch is the God of unhealthy competition of negative sum games.
So competitive interactions that make the world worse off for their existence, as opposed to
being neutral or better, because games can be good or bad, you know. And, and so Moloch is kind
of like this personification of that. But in reality, what it is is just this diet, there's
like dumb blind force of like, evolution and economics, where basically you'll have these
systems where individuals are incentivized to do sort of the selfish thing, kind of like a prisoner's
dilemma, like a multi-person prisoner's dilemma, where they, everyone is individually incentivized
to do the thing that will give them a short term gain. But if everyone does that, then everyone
overall ends up worse off. So from, basically, from a God's eye view, everyone should do the
cooperative thing. But in reality, because it's so hard to get so many people to coordinate,
there's no way of enforcing it, then everyone ends up in a bad place. And that's, you know,
it's called a multipolar trap, or a Moloch trap, as I like to call it. So yeah, that's kind of,
it's kind of an abstract concept. But for simplicity, think of it as like the God of unhealthy,
when competition goes wrong. Very cool. Yeah, that's a really cool explanation. And I like in
that essay that he points out, it just takes one person to be a dickhead for in many of those
multipolar traps, everyone's cooperating except for one person, and that can then... In the really
bad ones, in the worst designed ones, like a good example would be like, you're at a stadium
at a football game, and you're in a block, and everyone's sitting down at the start of the game.
But then the team comes on, and someone at the very front gets excited and just wants a slightly,
slightly better angle so they stand up, and then makes the person behind them stand up,
and then the next person ends on. And everyone has to stand up now. And they're just stuck there,
basically the system has fallen into this lower state where, yes, sure, you could quit the game
by being like, I refuse to stand, I'm going to sit down, but now you don't get to see. So
either way, you don't have a better strategy than the current one, which is now standing up.
But if you could poll everybody, they would much rather everyone be sitting and have the
same view, effectively. So yeah, that's just one example of where a poorly designed system,
due to competitive dynamics, can have this like cascading effect where everyone ends up
in this annoying situation where they'd rather not be.
Yeah, and I think what's, I really love the concept, because I think one of the things that's
useful about it is that in the various circles who are interested in changing the world in some way,
changing the system, finding ways to create a better system, which is something I really also kind
of identify with and I really care about a lot, there is often very little, it's often very meta,
it's often like, it gets very zoomed out, and doesn't necessarily look at the forces acting
again. Sometimes it does, sometimes it doesn't, right? And there's something about the concept.
So I got really excited when you, sorry, when you introduced me to the concept, because I looked at
the, you described it a bit, I read the Scott Alexander essay, and then I, for me, there was a
lot of crossover with the model I'm really familiar with from, from mysticism, from the
Gnostic Gospels. So the early Christians, well, arguably they weren't really that Christian, but
some of them were a little bit more of kind of Hellenistic mystery tradition. So we're talking
kind of maybe the third century, you know, second and third century. And they had this incredibly
sophisticated model of, I would say a model of human psychology, of the human psyche. And they had a
creation myth in which the earth is a living goddess, and the god of the Old Testament, Yahweh,
is this kind of, this false god, which is just pure ego, right? And he kind of, he gets created
by mistake by her. It's kind of complex why, but he's, they describe him as like an abortion,
like he's, so she is a goddess and has the all the kind of divine creativity of a goddess, right?
She's tapped into the sort of universal source of emergence, let's call it. And he comes along
and he says, well, I'm the god of everything there is. And she's like, well, no, you're not,
because you're not, you're not, you're almost like a cracked reflection. You're not even real,
really. And it's interesting because the neuroscience of our egos has been argued that
the, the narrating eye, our egos looking out for our own ends is a kind of conglomeration of many
different aspects of our brain. And we kind of cobbled together a self from our essence. And so
in a way, yeah, yeah, exactly. Yeah. And that's exactly a lower complexity self. And in a way,
it's real, but it's not real at the same time. So you have this dynamic there.
And then they argued that when we, so human beings have that divine intentionality and
that divine creativity. And also, though, we are very easily diluted by Yahweh and very easily
diluted by the Archons, his sort of weird, mech, super weird cosmology they had, but like this
kind of mechanistic self replicating almost like machine angels, right, really out there.
So, so for the Gnostics, their argument was like, look, we see Yahweh or we say see Moloch and,
you know, it's very similar in the systems that we're part of, we see it in the Romans,
we see it in the tax collectors, we see it in the way that people replace the kind of
hierarchies of nature, the natural hierarchies with fake human made hierarchies of society.
And so they were sort of outsiders. And their argument was you have to tap into
the deeper spiritual wisdom inside yourself, the Gnosis, in order to kind of liberate, they were
like quite, you know, into like liberating yourself kind of quite psychedelic as well.
And Carl Jung was a huge, like fan of the Gnostics, right? The two of the codices are called the
Jung codices, because he bought them basically, he found them after they were discovered, the
scrolls were discovered in a cave in the 1950s by two Egyptian farmers. It's crazy.
This is amazing. That's a crazy cool story, yeah. And then the final bit of it, for me the
synchronicity was that there's a book on Jung by Peter Kingsley, he's a classical scholar called,
it's kind of, he's also kind of a mystic, which is called Katafalk. And he talks a lot in that
book about this biblical, this kind of mystical tradition that he argues Jung was very familiar
with, which is about prophecy. And the prophecy, a part of knowing who the prophet was was that
they howled, right, which is the name of the Ginsburg poem. So I was like, oh, very cool.
There's a lot, I know, right? There's a lot of, there's a lot of crossovers like everywhere.
Yeah. And what I love about that is like, for me, I look at it like, I think they were, and Jung
thought they were incredibly sophisticated, mappers of the conscious of human consciousness.
But there's also some aspect to it, which can't be quite explained for me, which is that
there is this, it does seem there is this entropic force that humans create that we create
from our own, I don't know what your take on it is, is it do we create it from our own
bad incentives that are built into us or? I don't think humans in particular create it.
I think it's just, I mean, again, depending on sort of the mood of the day, like it almost
feels like it's just like there are these two opposing types of forces going on within the
universe, like deeply metaphysical forces, where, you know, it's not that it is entropy,
but it's like it uses entropy to its advantage. It's basically a thing trying to,
I don't know, but like, Mike is like, the way, the way I envision it, it's just like, you know,
that feeling where you are playing something and you want to win so badly. And I know this,
because I had this like pathologic, I was pathologically competitive as a kid. And it's
like eyes on the prize, but to this like all consuming extent, and you can't see anything
else, you can't see the externalities of what you do. And all you care about is this like,
optimizing for this one narrow reward. And the byproduct of that is that if you play that out
to its logical conclusion, it means that you will turn basically the everything into the
universe into this one thing. So the ultimate instantiation of that is actually like the
paperclip maximizer, right? Which is why when you mentioned the Gnostics talking about this
like mechanization of all these many, many things of like the same thing.
Could you describe what that is in case that someone isn't familiar with it?
Yeah. So the paperclip maximizer is this, this thought experiment, I think by Eliezer Yudkowski
of like, a way in a super intelligent AI could go wrong, whereby it's super intelligent in that
it's unbelievably good at getting whatever it wants done done. But it's stupid into the extent that
it was basically programmed to do this one narrow thing, which in this instance, you wanted to
make paperclips. I just wanted my AI to make some more paperclips better than what I can
currently do. I'm a paperclip maker. But because it's so unbelievably good, it turns everything
from, you know, the factory it's in, it figures out how to pull the constituent parts of the
atoms, the blood, you know, the hemoglobin in your blood, the iron extracts it and, you know,
dismantles everything until it can tie all the entire universe, anything it can in the universe
into paperclips. Why? Because basically, it was so laser focused eyes on the prize, winning
the goal of making as many paperclips, that you end up dismantling the universe into this
very low complexity state. So it's effectively like kind of a, it's analogous a little bit to,
you know, the heat death of the universe. Because what is that? It's actually a very low complexity
state. Where basically, it's just like, how would you describe it? Well, it's just homogenous
gray soup. You know, that's all it is. The universe started out very low complexity in that it was
kind of like this singularity of matter and energy. But you know, if we're talking in terms of
Korma-Garov complexity, which is like basically how many, how many bits of code do you need to
describe a thing? It started at the universe, started out pretty simple. And then time started
and things started unfolding. And suddenly we, you know, we've started seeing hydrogen and
then helium. And that would coalesce into stars, which created greater, heavier elements. And all
this beautiful complexity started emerging, patternicity. There's like dance between order and
disorder, you know, with like a bit of hierarchy, but a bit of anarchy and so on that creates this
like highly complex dynamic system that's very hard to describe. Like to write the piece of code,
to describe the universe, you basically have to just create the universe. That's what a highly
complex system is. And, but at some point, the stars will die out and so on, all this sort of
free energy that is used to create all this complexity will start dissipating. And then it'll
slowly, as far as we know, turn into this gray soup, which is low complexity. So it'll do this,
entropy will do this over time. And so, yeah, so this like this gray soup is kind of analogous to,
in my opinion, like what a paperclip maximizer would would do. It's not a very, basically,
it's permanently curtailing, you know, there's no more complexity to to arise. The universe has
reached this steady state. And that is, you know, it seems like a tragedy on enormous potential
because at least up until now, it seems like the universe is trying to emerge into greater and
greater states of complexity. So I hate to boil it down to like good and evil terms. But
to me, good is that which creates, you know, allows for greater emergence and complexity
to appear and thereby utility, you know, useful information that we can process and do and make
wonderful things with. And evil is that which does the opposite. In other words, like turns
things into this like low diversity, low, like high, you know, like very basic situation,
whether it's, you know, a cloud of hydrogen, which in the mountain, the, the, the howl poem he
and Ginsberg describes Moloch as Moloch, who is a cloud of sex as hydrogen. So it's like this,
yeah, it's like this kind of a force of entropy, but slightly different because entropy is actually
just kind of neutral. Entropy is just like time effectively. Whereas Moloch is a thing that turns
everything into this like one mono focus of sacrificing everything in order to win this one
thing. Hence the like child sacrifice. Brilliant. Yeah. It's so I think it's a really, really
excited to introduce this model into kind of, you know, into the channel and like our thinking
in general, because I think there's, there's something I don't quite know what, and I think
this is the journey you're on, right? Like there's something in it, right? There's something in it.
Well, so the current thing I'm trying to figure out right now. And I mean, a lot of this again is
like a sort of an offshoot from conversations with Daniel Schmacktenberger, Forest Landry as well.
But I don't think so like Moloch is tied to the competition, right? But competition gone wrong.
But competition can also be an enormous force for good. Because actually, like,
you know, the capitalistic model has risen the world to what it is right now. Like we would not
be living the cushy life with our, you know, nice cameras in this cool room and so on without the,
a lot of the luxuries that capitalism has provided. And in its best form, capitalism is,
you know, it's like a positive sum game. It's using competition in order to like
drive progress faster than it would without and creating these novel things that arguably wouldn't
exist without it. So it seems to be that there's like some kind of optimal
amount of competition, like zero sum type competition that we would want within the
universe, but kind of just like encapsulated in little pockets, you know, constrained in certain
ways, whereby Moloch can't get his dirty claws into it and like turn it, turn the whole, you know,
twist it into something bad. And again, like we, because a lot of, you know, a lot of people
are like, no, we just need pure, pure cooperation. Pure cooperation is all we ever want. No competition
whatsoever. But that's a lower complexity state than a universe that has mostly competition,
as I mostly cooperation, with little pockets of competition driving, driving it forward,
but in just like delicately constrained ways. So I'm trying to, it is very much just a working,
you know, a thing I'm just playing with, but there seems like there's something to that.
It's like a higher order level of complexity where you're using games in a beneficial way
without letting them get too out of control. Yeah, it's very interesting. I mean, what comes up
for me is something around intention and values, right, on the individual level, because so to
to use that Gnostic model again, another aspect of it was that the the issue is the ego disconnected
from the self in Jungian terms. So we all have an ego, we need one. That's great. I consider myself
very competitive, like, but there's also a question of priorities. And would I be competitive at the
expense of, say someone else's well being, or would I decide to be competitive instead of
loving my wife, right, if it was the trade off, which one of those priority, which one of those
are hiring my value system. So there's something about that going on, I think, which then applies
right back to the game theory examples, because in Scott Alexander's essay, you know, he ends each
of those examples with like, but from a God's eye view, if we all cooperated, better outcomes for
everyone. And what I find interesting about, yeah, so that Gnostic model saw saw the ego
disconnected from the self as unable to create anything truly novel, because all it can do
is replicate. And what it does, so we have that God and we have Mother Earth Gaia, or Sophia,
they called her. So that's kind of divine creativity that each human has. But when the ego
is disconnected from the self, it can't do anything except mimic that divine creativity. So and what
it ends up doing is creating like a Disneyland reality that looks real, but isn't real. Nothing's
authentic. Everything is skin deep. Think of kind of reality TV, for example, there's so many aspects
of our culture. I read a great essay, which I'll put in the show, it's about solar punk and the
author talked talked about, we've run out of authentic things to frack from our cultures, and
now we're fracking our own future, you know, fracking our idea of the future just to get some
that extractive thing. And then I guess it also goes to the idea of sociopathy and psychopathy
and Machiavellianism, which is this kind of dark triad in psychology. And, you know, I've
heard Daniel Schmackenberg and many others in this space talking about that being a major problem
when you're trying to create cohesion and cooperation is like the sociopath problem,
because a sociopath or a narcissist looks like they care about other people, but they do not
care at all. They don't have empathy, but they're mimicking empathy. And it is insanely destructive
because how do we cooperate when that's in the mix? I don't even know if it's that they don't
have empathy. I think often psychopaths do have empathy, because empathy is just being able to
put yourself and like, you know, like feel what someone else is feeling. And a truly powerful
psychopath is someone who would be able to actually really feel what you're feeling, but then just
not actually give a shit about what happens to you. And like, they're doing something that will
be ultimately self-serving at the expense of you. But yeah, that's probably a good distinction to make.
And an unsolved problem, I think, in terms of, okay, we want to find new ways to cooperate,
we want to find new ways to kind of build a sustainable future. How do we deal with that
problem? I mean, it's a really, on the game theory level, it's fascinating. I'm just on the kind of
like being a human being level. It's such a big question. I mean, yeah, it's about building robust
systems whereby a few defectors, you know, of people playing this multi-person prisoner's
dilemma, where the system can sustain, you know, having a few people do it, because I think it's
going to be next to impossible to ever have everyone working purely cooperatively, purely like,
and I'm speaking from really a personal level here, because I was on a game show, which was the
prisoner's dilemma to an extent. And it was, you know, it was a one time one. And I did the,
you know, I defected. I did the selfish thing by, you know, doing the clearly dominant strategy
in terms of winning money, which was my goal on the thing. I went in and I was like, I need to win
money. So I did the selfish thing. But man, like, I'm still getting hate messages from that today,
like 14 years later. What was the game show? It's called Golden Balls. It's on YouTube. I hate it.
And you're worth watching. Did you win? I won. Yeah. I mean, I played it. I played the game
perfectly from a, if you're optimizing for the value of winning money. But that's again,
it's this bigger question of like, what are the externalities to this? Overall, you know, I was
doing the sort of the, yeah, I was doing the strategically, I picked the game theory optimal
solution within the definitions of the game. But outside of that, there's other externalities
about the value of cooperation, the value of not looking someone in the eye and saying,
yeah, I'm going to split this with you. And then actually stealing it, you know, and
and it taught me like a really important lesson of thinking about the externalities of whatever
it is we do. And so, but what we need really is to build a system that is robust enough,
complex enough, but in the right way, where it minimized where the amount of externalities
any one individual can do, negative externalities, any one individual can do are contained and
constrained. And I don't know how we do that, but we have to find a way. Yeah, so it's a really
good point. I think an example I've used before is the, how the US Constitution was made, because
they did a quite good job. Obviously, not perfect, but quite good job of thinking. Yeah,
really credit at the time of creating an antifragile system with that in mind, because they were
focused on how do you prevent tyranny. And the process whereby they went through it was,
you know, in part the federalist papers, we're just writing to each other constantly being like,
well, what if someone does this, like, oh, shit, yeah, what if someone does that? Yeah,
stress testing constantly. And I think, I mean, that's probably a good place for us all to start
is just to kind of, yeah, start having that conversation, which I think a lot of people
already having and start to kind of stress testing. And now we have the luxury of being
able to actually make models and play them out. Like, we can, you know, there's like,
I think, you know, game designers, et cetera, a lot of people out there who can go, okay, well,
let's let's put it in a simulation and see what happens, you know, that's really exciting to me.
Yeah. Yeah. No, I mean, that's exactly as they're, the blessing and curse of technology is that
technology is particularly exponential ones are making Moloch's life much easier to,
to destroy the universe. But at the same time, we're also building technologies that
enable cooperation better coordinate, you know, the ability to coordinate with one another.
You know, like a simple internet forum, it's just such a valuable thing that like just never
existed before. You know, it's not only because it's a way of sharing information across multiple
minds, across time, not just in the moment, but also storing it so that new people can come in
and retroactively go back and learn and then like, and now add something new and so on.
So when we were prepping this interview, you mentioned like quite a few different things
you're doing, which sound very exciting. And I think our viewers will be quite interested in.
So, and you also have a YouTube channel, which I think is where they're going to be coming.
Yes. And as a reminder, you're appearing and our state of sense making free event at the end of
September. So people can check you out there. But we'll put your YouTube info below in the
show notes and maybe you could tell us a little bit about like what's coming up, like what you're
working on. Yeah. I've been down the rabbit hole on this like Molek concept and to an extent complexity.
So yeah, making a series, trying to pick apart what Molek is and also bring it to life. I do
some acting in it for the first time, which is weird. I dress up. It's a whole thing. But
a lot of it relates very tightly to what we've talked about today. So yeah, people enjoyed
this, then they should check it out. Yeah, I'm really looking forward to that. So yeah, subscribe
to live. We'll put the your different social handles down the show notes and thank you so much
for coming on. Thanks for having me. This is awesome. Our ability to make sense of the world
is breaking down. We're making more and more consequential choices with worse and worse sense
making to inform those choices, which is kind of running increasingly fast through the woods
increasingly blind. Over the last two years, Rebel Wisdom has interviewed some of the world's top
thinkers. Now we've brought them together for an eight week online course, Sense Making 101,
with Daniel Schmacktenberger, Diane Mushow-Hamilton, John Vivecchi, and more. Improve your sense making,
develop your sovereignty, and join a wider community looking to do the same.
