Okay, welcome to the session number two is now I have the pressure to present to Kevin
Nutt from the University of Albany. He will talk about quantity with uncertainty,
defines the basics of quantum mechanics and space.
All right, great. Thank you for having me. Hello, everyone. And yes, I'm doing this. This work has
been working on this with John Skilling from Ireland and so we'll dive right in as long as
everyone can see my screen here. So this work basically takes advantage of a slightly different
perspective of what we are doing in physics. Instead of thinking about the natural laws,
the laws of nature as being laws that are dictated by mother nature that we all have to obey,
we're looking at I'm looking at this from a perspective of
of people wanting to quantify things. And we've gotten so used to quantifying
things. And by that, I mean assigning numbers to things that we almost give it no second,
no additional thought. And of course, this is a very simple process. We learn to do this as
children. We assign numbers for different properties of objects. And the larger things are typically
assigned larger numbers. And of course, there's some arbitrariness here, there's some some choice
you can make. So here I have pictures of some batteries, 1.5 volt battery, a six volt battery,
a 12 volt battery. And so we are assigning numbers to one aspect of these, this set of batteries.
And classically, we tend to, because we're so familiar with this, we have come to
think of these quantities as being properties of the objects themselves. So, so in fact,
we even use them in the name. It's a, this is a 12 volt battery. And that's the
that number 12 is considered to be a property of the battery, which I, which I think is a very,
that's a little too strong. And you can start to see where this is going to be problematic when we
consider things like very small objects, where the probes that we're using to study them are
equally small. The assigned quantities in these cases really describe interactions rather than
describing properties of the objects. So we often, you know, our language often governs how we think
and how we think is described by our language. So these two things are coupled and very often
we'll hear people say or will, or will, I myself will say things like an electron has an energy E
or has a momentum P. And, and that's really not a good way to think about it. The electron can't
possess a momentum because the momentum of an, of an electron is really observer dependent.
You boost to another observer in a different frame and they'll measure a different momentum
for the object. They'll say this, no, this electron has this momentum P. And of course,
we know how these two numbers are related. But, but I think that one of the difficulties that
we've faced conceptually is, is taking these numbers that we're assigning as descriptions of,
of objects, descriptions of properties of objects, descriptions of the way that they're
interacting with observers and attributing them to being numbers describing properties of the
objects. And that I think that's really a wrong way of thinking and it's caused us a good bit of
trouble. The momentum and position and energy, these types of quantities really are describing
the relationship between the electron and the observer. And so momentum is one description
of the relationship position is a different description of that relationship. And the fact
that the two descriptions are incommensurate really isn't surprising or unusual. They're just
two different descriptions. And so there's been in quantum mechanics, historically, there's been a
lot of puzzlement over the fact that how can, how can an electron not have a definite position
and a definite momentum at any given time? Well, the fact is the electron doesn't have either.
Those are descriptions of the relationship between the electron and the observer. And you can't
have both of those descriptions can't hold at the same time. That's really what's going on there.
It's really only mysterious if you think of these quantities as properties. So we've worked hard to
give up these ideas of properties and thinking of this more in terms of description.
So contextuality, in this case, becomes a little less mysterious, the context of the, or the details
of the interaction matter. And, and of course, what you are going to, how you are going to describe
in interaction depends on the details of those interactions. And descriptions need not be
commensurate. You can have complementarity. The electron doesn't simultaneously possess a momentum
and a position the electron doesn't possess either. That's a bad way of thinking.
So, so what this does is it gives you a bit of freedom, which is, which is interesting. And, and
the profitability of such a perspective then is measured by what it allows you to do. And, and
we've found that it allows you to, to actually do quite a bit. So if you're going to assign numbers to,
to objects or properties of objects or interactions between objects and, and probes,
or observers, then you need to do so consistently. And that's the question becomes,
how does one consistently assign quantities? So, so different operators may have different
frequencies and, or I'm sorry, may have different symmetries. And these symmetries
can be quite important because they will constrain the number of ways in which you can
assign numbers to things. So let's say I have two sets of candy taffy here. And I'm using candy
because what I'm going to be doing with these, these taffy is, is rather simple. You've all known
about this since you were kids. So I've got a set here A of some taffy and I've got a set B of some
taffy. And I'm going to combine the two. So let's say I've set A in one hand and set B on the other
hand and I'm going to put them together. Now, if I want to quantify these sets, basically assign
numbers to the, the, the sets of taffy, one way obvious way to do this that you're very familiar
with is to count them. We'll assign a number describing the cardinality of the set.
And one can then ask the question, well, how do you take the number that you assign to set A
and the number that you assign to set B? And how do you combine those numbers to arrive at the,
a consistent number that you're going to assign for set A with B? Of course, you all know the
answer to this already. You add them. And my interest in this question came from the deeper
question that I had in graduate school, which was, why, why do you add them? And I know that it works.
It's obvious that it works. I've been doing this since I was a kid. But why is that the case?
Can you prove that it has to be that way? And indeed you can.
There's several different properties that this with operator, basically combining stuff in two hands
exhibits this, this, this combination property with exhibits closure in this case. So if I take
stuff A and combine it with stuff B, the stuff that I have in A with B are the same kinds of
stuff. If I take taffy in my left hand and taffy my right hand and combine them, then I still have
a bunch of taffy. So that's closure. Another symmetry that you have with this operator is the,
is commutivity. Doesn't matter which hand I have set A of taffy and which hand I use to pick up
the sets in the first place. I could switch hands and I still have the same result when I combine
them. That's a symmetry. If I have three piles of taffy and I start picking them up,
I can pick them up in various ways. And the result is equivalent. That's called associativity.
And the idea is that the with operator is such that I can keep grabbing piles of taffy if I want.
And so mathematically I ought to be able to keep combining them.
So these are the four conditions that the with operator has to satisfy.
You can prove, this is a theorem, you can prove that if the with operator satisfies
these four conditions. And you can think of associative commutivity as just shuffling.
I can shuffle up the piles and I get the same result. Then you can show that if you're going
to quantify the set A with a number representative of lowercase A, and you're going to quantify the
set B with a number given by lowercase B, then A with B is basically going to have to be quantified
by something that's isomorphic to A plus B. And that's a theorem. That's something you can prove.
So you might say great. That's something we've known this all along. Not very exciting. I've
known this since I was three years old. But it turns out it's rather profound.
And so here's the example. If I assign number A of three to the set A, I assign 10 to set B
and a little taffy hiding under this one. So now when I combine them, the number that I assigned
to the set A with B is given by three plus 10 or 13. And that will give me a consistent
means of quantifying these objects.
So how well does this work in general? Well, it works pretty well in general. We use it all the time.
We count all sorts of things from taffy and rocks to gallons of gasoline to cars on the
highway to stars in the sky. But let me give you an example where it doesn't quite work.
Because one might be led by because of the generality of the application of the mathematics,
you may be led to thinking that this is some kind of universal physical law.
And it's not quite that simple. This is a description. I can emphasize the fact that
it's a description by showing that it is observer dependent. So here's another example. I have two
sets of objects. Each of these sets contains molecules. And the ones on the left, I have
two butane molecules. And in the set on the right, I have 13 oxygen molecules.
This is in the way on my screen. So now I'm going to combine the two. So on the left, I have
two molecules. You can see I'm assigning this in number two. On the right, I have 13 molecules.
I give it the number 13. And I'm going to combine them. And you expect to have 15 molecules, which
is nice. And that works as long as you don't shake this up and make it too hot. Once you make it too
hot, this happens. And you no longer have 15, you have 18. And you have 18 carbon dioxide
molecules and water molecules, both. So what went wrong with our little rule of additivity?
In this case, oh, two. It should be two plus. Now you have the numbers up here wrong.
But our two plus 13 actually gives me 18. So why did that happen? What went wrong?
The answer is quite simple. What went wrong is we violated one of the conditions for the
width operator. The width operator lacks closure. You don't have the same kind of stuff at the end
that you had in the beginning. So whether addition worked or not depended on our description.
If I were to go back here to the beginning, and instead of assigning, instead of counting out
molecules, if I counted how many atoms I had, and here I have four times two, which is eight,
and then 10. So that's 20. So I got 28 atoms on the left. And I have 26 atoms on the right.
And now I throw them together and shake up the box. I still have the same number of atoms.
You can add the number of atoms and you get the right result. So
addition works if you count the atoms, but it doesn't work if you count the molecules.
So that shows that there is a dependence on the level of description that you choose.
So whether additivity works depends on the description you chose. And the laws of nature
shouldn't depend on description if they're going to be some universal law. So this isn't about a law
of nature. This is about describing things with numbers. So of course, there are other
operations you can do. You can take three copies of the set A. And I'll call that three of A.
So this is a new operator called of. I can replicate things. And it turns out this of operator
is obeys associativity. And the of operator is
distributes across the width operator. So you have distributivity. So here we have
associativity and distributivity. And you can prove, again, similar to the proof before,
the associativity means that the number that I assign to, so if I assign a number to,
if I have this number A, and I assign a number to B, a little A and little B,
then the number that I assign to A of B is going to have to be, is going to be some function of
little A and little B. And associativity forces that to be isomorphic to addition.
But because we used addition for the width operator, the fact that we have distributivity
forces that isomorphism to settle on one particular, once particular transform,
which is basically multiplication. So multiplication is isomorphic to addition,
so it satisfies the associativity, and the multiplication will satisfy the distributivity.
So this is a theorem. And so the idea is you multiply the numbers together.
So now when I take three of A, if I assign a number three to A, kind of unfortunately I use
three here, basically when I'm done, three of A is going to give me three times three or nine
pieces of taffy. And you can prove that this has to be the case because of associativity and
distributivity. So these are rules, rules for consistently quantifying numbers or quantifying
things with numbers. And now we're going to push this to an extreme.
We're going to consider the case that's that we encounter in quantum mechanics where we are
studying very small objects with very small objects. There are, there's a point where we
get to where we are studying objects for which there are no smaller probes by which we can use
to study these. And we may obtain some number x in a measurement, and which we would use to
quantify this interaction. But we have to acknowledge that we're going to have some
uncertainty as to the value of this assigned quantity x. You can also think of it this way,
we have some quantity describing the system, some describing the probe. So you put the two together,
you really need two numbers to describe the interaction between the system and the probe.
Now this, this uncertainty, the relationship may be more intimate than the usual x plus or minus
sigma uncertainty that we're used to from dealing with Gaussian probabilities and probability theory.
And instead, and in fact, I would like to, in this case, if I did want to quantify
things this way, I would have to derive this plus or minus as, as being a function relating
these two. So to back up and work to do something like that, we're going to not assume that this
is the case. Instead, we're going to assign two numbers here. One number is related to the
a number quantifying the interaction x and another is going to x one and say, and the other is going
to be x two, which will quantify uncertainty. We just have two numbers here instead of one.
So what happens when we consider similar operations like the width operator and the
of operator, and we start combining things, and we are using two numbers to describe
these interactions rather than just one. So we'll look at associative commutivity again,
which previously was scalars gave in the taffy gave us a sum rule. We find that that's the
case here as well. So if we have some set a something a that's described by two numbers x
one and x two, and then we have a B described by two numbers y one and y two, then a with B,
where this width operator is any operator that exhibits closure, associative commutivity and
reproducibility, then a with B has to be represented up to isomorphism by component wise
summation. So we would then assign for a with B, we would assign numbers x one plus y one is one
number and x two plus y two is the second number. That's not so unusual is it's not so different
than you can see the scalar case right there. Things get a little more interesting when you
when you consider operator an additional operation like the of operator, where you have
associative distributivity as well. So here, upon interaction associative distributivity, which
we'll use this operator as dot, is we're trying to figure out what dot would would be. We should
we should have we will have distributivity here we also have associativity and
and we also have that we have component wise summation for the plus here. And that requires
that this dot operation has to be bilinear. So whatever numbers x and y you have in the original
pairs. The result is when you combine them has got to be some some linear bilinear combination
of these objects where these gammas here are our coefficients that we have to identify.
So these basic symmetry these symmetries are common in the systems that we work with and
that is why we use addition of the time because we have associative commutivity holds often so
addition works. And in physics, generally we have associative commutivity and associative
distributivity. And that is why physics is fundamentally linear. Excuse me.
So now, whereas scalar quantification resulted in one multiplication rule, the pairwise
quantification where we're carrying with us a number quantifying some uncertainty results
in three multiplication rules, which is interesting.
So in that they these come about from looking and seeing what gammas are possible. So it turns
out that there are three sets of gammas that are are possible. And they all the different versions
reduced to three different types of operations. One of these here you'll see the first one a
looks like complex multiplication. So you're basically treating these as complex numbers.
And B is is similar, but where we have addition here. And C C is also similar, but not the same.
We can rewrite this as this as a multiple as a matrix operation, where a looks like this,
B looks like that and that and then we operate on the vector y one, y two.
So these are the three different multiplicative operators that we have. And we will see that
much of physics comes from these three operators. So without loss of generality, we set the determinant
of these operators to one. And we do that so that repeated application doesn't diverge to infinity
or collapse to zero. That would be pointless. And that means that there's really only one free
parameter related to the ratio of x two to x one, which gives us three possibilities. We have
something like a rotation matrix for multiplication rule a, we have something like a hyperbolic
rotation for multiplication rule B. And we have this other
matrix for operation C. Each one, each of these three will obey the symmetry. So they
may be useful in quantifying things in the real world that obey the symmetries or interactions
in the real world that obey the symmetries. So we, of course, we can write these operators in
terms of infinitesimal generators. This is what the generators look like. And
we then see that generator a is basically rotation by some phase angle
and which is what I had originally said. So there's a rotation matrix. So generator a basically
rotates by a phase angle and the sum and product rules in these case are those of complex arithmetic
and the pairs are complex numbers. Unit quantities identified with unit modulus determinant, which
is modulus squared. And we find that the inherent uncertainty in a unit object refers to what is
remains unidentified in X, which is namely the phase, this rotation so that
every time we have an interaction, each new object you interact with brings with it an unknown phase.
So now we have to rely on probability to deal with this inherent uncertainty properly.
Our ignorance of phase is uniformly distributed. So we can assign a prior probability to the phase
1 over 2 pi. And to obtain the likelihood of a given outcome, which is what we're quantum,
which is what we're computing when we do quantum mechanics, we must marginalize over all of the
unknown parameters, which are all of the unknown phases and the interactions. And if we perform
this marginalization, you see that we're basically summing modulus squared quantities. And this is
really why quantum mechanics is a probabilistic theory. And the likelihood is additive because
of the scalar sum rule, and it depends on the modulus squared, which is the Born rule. So you
can show that all of these things arise from these simple symmetries. So here you can see,
here it looks like the foundation of quantum theory is pretty elementary and simple.
Quantity and uncertainty fused together into complex numbers with uncertainty really referring
to phase. And the observable quantity is the modulus squared, which is the Born rule for
arbitrary amount, and that represents ensemble averages, which is what the experimenter measures.
So we have that, what's nice about this is quantum mechanics and probability theory are
derived from the same symmetries that can't possibly contradict one another for that reason.
And in physics, we make predictions, which are quantified probabilistically in terms of
likelihoods. And so given those likelihoods, Bayesian analysis then computes posterior
probabilities, which assess the models and the lights in light of the outcomes that are actually
observed. And that is the relationship between quantum mechanics and Bayesian inference.
Quantum mechanics deals with computing likelihoods, and likelihoods are used in performing inference.
So now we can go a bit further and see how the multiplication rule B comes into play. These
three different rules are potentially going to be used to describe different types of interactions.
And so rule A, multiplication rule E, A we see is used in quantum mechanics.
What is B good for? Well, B, because these are all possible descriptions, we can then ask what
could be possibly described with B or C. They're going to be consistent with the symmetry, so they
would be good descriptions of something. And I'll look into that briefly here.
So here we can consider objects that can exist in two states, let's say up and down.
This gives us a quantification consisting of a pair of complex numbers,
basically using the rules A, the multiplication rule A, and we'll have pairs of complex numbers now.
And qubits, we'll call these qubits, will obey associative distributivity. So the representation
is two-dimensional over the complex field. And these generators, these generators that we have
will give us the polymatrices. So B, the generator for multiplication rule B gives you sigma x,
I times the generator for multiplication rule A gives you sigma y, and then together
B times A gives you sigma z. So these are the polymatrices.
And so the multiplication rules A and B together give you the concept of spin.
And we see that we get the scalar quantifications come from these different, these three polymatrices.
And this gives us a relationship between these new quantifications that we can construct from
these operators. And this is really the first clue that 3 plus 1 spacetime emerges from quantum
mechanics. So with complex coefficients, these generators define the six-parameter Lorentz group,
under which ensemble averages of independent samples results in this relationship, which is
invariant, or this quantity, which is invariant. So if we go back to those original multiplication
rules, these two here together basically give us a six-parameter Lorentz group.
So we can see that when you think of these multiplication rules as being constraints that
constrain your description of things, you can see that the descriptions we use in physics are
actually coming from these constraints, and they ought to be. It gives you the possibility of
deriving physics, which is quite interesting. One could have potentially derived physics before
encountering the physical world, which is quite a thought when you imagine that the
physical laws are somehow laws dictated by mother nature. If you think of the physical laws as being
constrained equations that constrain any attempts at quantifying physical things, then it's not so
surprising. So the shift in perspective on what you mean by a physical law gives you a great
deal of freedom. So we now have these symmetries of associativity, commutativity,
and associative distributivity, along with consideration of uncertainty, give us the basic
mathematical descriptions of the universe. We get from this, you can get the quantum mechanics
as a probabilistic theory. The polymatrices and spin derive from multiplication rules A and B.
This also gives you concepts of energy and momentum and phase and action. And from that,
you can then integrate using rule C, which I don't have a slide for. I should have made that.
I didn't want this to take too long. And you can see that operator C is an integrator.
I'll go back to that. Here we go. So here's operator C. If you imagine multiplying at times
something like dt on the top and then t0 down below, you can see that this is going to basically
integrate phase. So time, it comes about from integrating phase. And this basically allows
you to integrate time, which then when combined with the other to allow you to integrate,
integrate, you can integrate phase up to obtain time and you can integrate momentum in the other two
up to obtaining positions. So it works backwards from what we're used to. What we're used to is we
start out with wave functions and we have positions and times and we take derivatives to obtain
energy and momentum, which are supposedly more fundamental. So we basically work backwards
in the traditional way. We start out with something higher level, position and momentum and position
and time and we take derivatives to get momentum and energy. This is actually going from the ground
up, which is what I think would be a better foundation. That's how you build things from the
bottom up. So here basically we have energy and momentum and phase coming in from the beginning
and then with operator C, you can then integrate that to getting a three-dimensional spacetime
and that comes out as an integral of phase and energy and momentum.
So this is the direction our work has taken and why does mathematics work, which is a question
that's always had me wonder. Here it's easy to see the symmetries. These symmetries constrain
our mathematical description of physics, which is why it works and that's why it's derivable,
which is interesting. Universes can't just do anything. As long as you have these symmetries
hold, then your description of systems or interactions that obey these symmetries are
going to have to follow these mathematics and that basically is the theorem.
So here's one of our most recent papers on this, so I hope you enjoy that and thank you.
Okay. Thank you very much, Kevin, for this nice talk. The people who want to make a question or a
comment can indicate it in the chat. I have a little question. Do you think that this analysis can be
replicated in another physical theories that use another type of space or spacetime?
Oh, I didn't quite follow that. I'm sorry. The connection wasn't so good for me.
Oh, sorry. Do you think that this analysis can be replicated in another theories that
use another kind of spacetime like in the string theories? No, that's a good question and that's
basically where we're headed with this is we want to see it from what we have so far. It looks like
these symmetries allow you to generate spacetime as integrals of more fundamental quantities like
phase and energy and momentum and so we want to look into that to see if you can build spacetime
up from that foundation and if you build spacetime that way, if you can do that, then it's going to
automatically be consistent with quantum theory. So we would have a theory of spacetime that's
consistent with quantum mechanics from the get go, which is really how you would want it.
There's a question from Erika Holi. Hi, Kevin. Thanks for this from this talk. Yeah, it's great.
So I wanted to know what's your take on photons because you mentioned that when you count atoms
and molecules, well, that the counting, it depends on the level of description that you are taking,
right? But then if I have a laser, an attenuated laser, and you prepare a coherent state,
then you will have a superposition of different numbers of photons. So you don't have a definite
particle number. So what would be your take in that situation? How many photons do I have or
photons in that case will not be real entities and only the quantum field? What would be your take?
Oh, that's a really good question. That's something I hadn't considered.
If additivity doesn't work, then you've violated one of those four conditions and that would be my
first guess. Then the question would be which of the conditions are violated in that situation.
So in the case where I combine butane molecules with oxygen molecules, the condition that's
violated is that of closure. So it's hard to imagine that you're going to have a problem
with closure when combining photons. So yeah, so I'm curious about this. I'll have to think about
that. Thank you. That's a very good question. Thanks. Okay, we are in time. So thank you, Kevin.
Okay, thank you so much.
