Okay, we'll start with the second part of the first session this morning.
The first talk is in charge of Schubert Cercione from the University of Caglione.
Thank you, thank you very much and thank you to all the organizers who invited me. For me it's
very proud and very proud to be invited to this 10th conference of Quantum Foundation.
I'm very happy to be part of this very prominent panel of scientists. I warmly thank all the
organizers and especially Federico Olic and Martin Bosic, who are also a strict friend of
Italian University and of Cagliari and also personal friends. So what I want to introduce
here is Quantum Information Meet Smashing Learning. So basically I like to introduce
generally this topic by starting from a provocative question. I ask you, can you show me a picture
of your Christmas 2018? I am sure that you can and I am sure that if you try to find a picture
of your Christmas, for instance in your mobile, you will find it but probably you need time to
find it just because now we use to make a lot a lot of pics with our mobile because the memory
that our mobile has now is very, very huge and many, many pics can be kept, can be considered,
can be stored in a cell for instance in a mobile. So what we can say is that we can,
can we say that many data corresponds to many information? Basically not because information
means recover from the data what we really need. So the fact that now we have to deal with a very,
very huge amount of information means that potentially we can have a lot of information
but the problem is the process we need to do in order to extrapolate this information
from this big amount of data. So this is the reason why in the last decades big data science
corresponds to face with just this kind of process, this kind of problem and so the problem is how
to manage huge amount of data in order to retrieve in the short time as possible the information
we need, the information we need. Okay so this is why big data born in the in the in the last
decade. So this is just a very brief summary of what I said in these five minutes. So in other
words, enlarging the dimension of the data set is a good thing because it increases the potential
information but it's also bad because it makes the extraction of the required information out.
So from another side you know very well that you know very well how quantum information
born, how quantum information became in the recent past a really new discipline of
quantum theory in general, quantum computing mostly, and we know that the advantage of
quantum computation are most of the the advantages are most of all based on the fact that we have
a speed up of the computation. We can obtain, we can
perform a computer and strong and hard computation in a very very shorter, a shorter time
with respect to a classical, a classical one. Okay so so we know also that quantum computation
is not so futuristic. We can say that till 10 maybe 20 years ago we were speaking about
quantum computation as something that was phantasyntific, that was not really concrete,
but we know that the application in quantum computation has a very very speed up in the
last in the last decade and now we know that the quantum processor already exists and we know
that also by using for instance our our computer in our house we can connect with the IBM quantum
experience and we can just design a quantum algorithm and by a click we can send this
quantum algorithm to a real quantum computer that will perform it, that will give us back the result
as a as a statistical result. So basically the quantum computation is now real, is now real
and also we know that this this topic is is going on and on and for instance just one year ago,
just one year ago in in china that was there was was declared that the
achievement of quantum supremacy because it was possible to perform a calculation in
200 seconds, a kind of calculation that will take more than half a billion years on the
world's faster, no quantum or classical computer. So now we really trust in quantum computation,
we really trust in this. So we were speaking about the data and about quantum computation
but because well summarizing the main problem of big data when machine learning with big data
is the time complexity of the computation but the main advantage of quantum computation is
the possibility to reproduce to use the time complexity. So in a certain sense,
quantum computation and machine learning appears as a very natural and maybe unavoidable,
unavoidable connection but the connection can be deeper and deeper with respect to what we can
think. Indeed the question that they want to ask you in this in this talk is can quantum
information theory help classical machine learning, classical by using classical computer only
and we will provide a positive answer to this question. So this approach that we will speak
is known as a quantum-inspired machine learning and the important thing is that well very often
we know that in many disciplines we speak about the inspiration from quantum mechanics.
Okay now what I want to focus on is the fact that our inspiration is not just an analogy,
it's not a metaphor but it's just a really inspiration regarding a real inspiration to quantum
work in order to have a real benefit in machine learning and in the next minutes I aim to show
you what they mean by real inspiration. Okay in particular we focus on the classification problem.
What is the classification problem? Okay the general idea is that the quantum classification
in the idea that we want to perform is the idea of a quantum classifier where quantum
classification is the idea of quantum classification is to formalize the standard
classification problems in terms of the mathematical quantum object and then
inspired by certain properties of quantum state discrimination we define a quantum
classifier that will provide interesting and real good advantages. The procedure is
based on three fundamental steps that we will describe not now but a few slides later encoding
classification and the coding but we will meet this slide again in a bit. First of all
I want to very very quickly summarize what is the
sorry the general framework of classification problem. So when we have to classify an object
we describe this object as a vector where each component of this vector is a feature of this
object like this object could be a cat and this feature could be the length of the tail,
the weight of the cat and so on and we have different classes of objects for instance
dog and cats and what and so on and this so a pattern is represented by a pair where this is
the vector the object represented by a vector and this is the label that characterized the class
for instance class for instance label one means class of the cat, label two means class of the
dogs for instance okay and the goal of the classification is to have a classifier
I mean a function classifier is a function that allows us to study the vector and gives as an output
the label so looking at the vector looking at the object I can say you if this object is a cat or is
a dog basically okay okay okay so in a general supervised scenario I will be very very very
I will skip many slides but but sometime I can focus on some technical data sometimes not
generally generally in what we say supervised learning we mean that we consider a data set
for instance a data set of dogs and a data set of cats for instance and we divide this data set
at the beginning in two parts the first part is given by the training set this is the set
useful in order to train our algorithm and this is the test set but the set is a set of
object that we use in order to know whether our algorithm is good or not just in order to know
just in order to measure the performance of our algorithm and so obviously then all of these
objects are already labelled so we already know the level of the object so the goal is just to
evaluate how the right if the classifier is good or not so we use a already labelled set of object
we divide it in training and test and obviously also the training is divided with respect to the
classes the classes will get the classes of dogs the classes of foxes and so on and so on okay so
the the first idea of the quantum classification is just to translate formally translate each
object each vector each cat that is represented by a vector in terms of a quantum object that we
represent by a density operator row and there are many many ways to encode this is just encoding to
encode a real vector in terms of the quantum object okay in terms of a density operator obviously
it is only a formal translation we are not transforming a cat in a photon or a dog in
an electron obviously okay so now once we have translated all the data set of real data in terms
of the data set of quantum data or quantum data again we can consider the distinction between
training and test training and test again and the idea is just to obtain a quantum classifier
that is a function that has as input a quantum object of the quantum test set and has the
output level so given this quantum object that is the density operator that represents an unknown
object we can say that we can we can obtain by the classifier that this object is a dog okay so
obviously what we have to show is that this translation from classical to quantum object
has some benefit provides some benefit otherwise it's totally useless okay so okay
now let us talk regarding the general setting in quantum state discrimination okay that probably
most of you already know but I very briefly summarize here let R be a set of density operator
and suppose that Thelis wishes to communicate information to Bobo by using a quantum system
that is one of the system belonging to this state okay to the same Thelis prepares a quantum system
in one of this state in one of this state and hands the system over to Bobo in principle Bobo has
a complete knowledge about R so Bob knows in knows already knows which are row one row two row
M but he does not know the actual state of the system that he have received by Thelis so in order to
so that the Bob's task is to determine which one is among this state in one shot just by making a
single von Neumann measurement over all possible sorry or possible physical observable so there
and so the possibility is that the measure the outcome of the measurement could be just the
row that Thelis sent to Bob or not or can be another one in the first case okay we say that Bob
succeeds in another case we say that Bob fails okay so what is the probability for Bob to
succeed okay given a set R or quantum state and a von Neumann measurement M the average
probability to Bob for Bob to perform a correct discrimination so to correct individuate which
is the state that was sent from Thelis is given by this quantity is given by this quantity and
the aim of course is the maximize maximize this probability so to minimize the probability to
have an error okay so the question is what what is the measure the measure that maximize the
probability to have the correct discrimination and this measure this measure was obtained by
by this strategy okay the strategy is is related only to the binary case so consider to have just
row one and row two and if we consider this quantity p1 row one minus p2 row two where p1
and p2 are a priori probability okay that can be obtained in some different but empirical way for
instance we obtain this quantity we calculate the positive and negative eigenvalues of this
quantity we consider the respective eigenvectors and we consider the sum of the projector built
over all of each of these eigenvectors in this way we can obtain p plus and p minus
and hence from showered that this p plus and p minus is a von Neumann measurement that is optimal
that is the optimal measure for the discrimination problem for the binary discrimination problem
that we have introduced at the moment so this is the this is the bound this is the bound and
intuitively p plus and p minus represent the property for the system to be correctly
identified as being the state row one or row two respectively okay and that's from bound can be
seen as a measurement of distinguishability between row one and row two so now again with
this light because now we have all the ingredients we need in order to put together this discrimination
not to put together classification problem and quantum state discrimination the first stage
is the encoding we say that we need to have real object and translate the real vector and translate
them in terms of quantum object like a density operators like a pure states and for instance
it is easy to see because there are several way several way to do this this is one simple way for
instance by using the stereographic projection we map each object in this simple case two feature
object in a point over a sphere and of a surface one sphere and that's correspond to the point of
the block sphere so a pure density matrix a pure state a pure state but there are many other
possibilities to encode real object in terms in terms of density matrix pure density matrix okay
so once we do that once we have set of quantum states set of density operators
for each training set we for each training set for each class of the training set we we represent
each class by a quantum centroid that is defined in this way this is just the beginning of our
orbit and it is no longer a pure state of course because it is just the sum of all of the state
of all the encoded vector belonging to a to a given class to a given class okay obviously the
quantum centroid are mixed states are mixed states and they are not the encoding of the
respective classical centroid they are a totally new object a totally new object that
has not any counterpart in the real world in the world of real object in the world of real vectors
okay okay so now we use quantum state discrimination we use the Elstrom measurement
that is optimal so we use p plus and p minus that we built we built by considering
as the two states to discriminate we will consider the two centroids so let us consider
a case where we want to discriminate between cats and dogs we consider the training set of the cats
we are encoding this set in terms of quantum object we consider this you can see that the
centroid of this class we do the same for the dogs and we have these two centroid these two
quantum centroid these two quantum centroid define the finding are two density operator
and from this from these two quantum centroids we can apply the Elstrom
discrimination and we cannot take the Elstrom measurement the optimal Elstrom measurement
p plus and p minus okay so once we pick another quantum object from the test set we have to do
we have to say okay this quantum object is a set or is a dog in order to determine if this
we consider this classifier that is called the Elstrom quantum classifier we consider
these two values if the trace of p plus times rho is greater than p minus times rho we say that
in a certain sense rho x is closer to the centroid of the cat otherwise rho x is closer to
the centroid of of the dog and so we can make a really a proper classification a proper classification
okay why we use quantum state discrimination what is the intuition that that is above this idea
the application of quantum state discrimination for classification is inspired by the idea that
better is the discrimination between two centroid and better I can distinguish between two classes
and so more performance is the classifier in other words greater is the Elstrom bound that
remind me I said it is that can be considered as a measurement of distinguishability between two
centroid and greater would be for instance the accuracy of the classifier where the accuracy
means just the number of times that the classification was correct over the number of total over the
total number of experiments okay okay this idea is not only an intuitive idea but that was just
exploited that was just proven by an experiment so we have provided an experiment where this
classifier has been applied to 40 different data sets and compared with 11 different and
general well-performing classifier standard classifier for instance what we can see is that
generally generally once the Elstrom bound increase the Elstrom bound increases
together with the increasing of the balance of accuracy so this idea seems to be correct
that increasing the measurement of distinguishability between two centroid it
is together with the increasing of the accuracy of the classifier so this intuition is corroborated
by the experience is corroborated by the experience and okay we have many data when we
perform it when we compare this classifier is Elstrom classifier with many standard classifier
and we show that our classifier is generally better not always not always but okay the average
performance of the quantum inspired classifier is very very high with respect to the others
standard classical classifier okay now I have many data to show but okay this is
just a comparison okay are we okay in these data in these tables you can realize these
I don't say supremacy but something like this of our Elstrom classifier with respect to the other
but that's not all that's not all indeed a sharp difference between classical and quantum
information theory is also based on the fact that sometime made considering a tensor copy
of an object can provide a benefit in our computation can provide let's say a kind of
additional information with respect to the original information that is given by the
initial single state so what we do is just repeat exactly the same algorithm that I have described
you above before but by considering but off after the encoding after the encoding instead of the
density operator raw the time obtained from the encoding by the encoding from the initial
object instead of this row I consider all times itself and times I calculate a new centroid
and I define again a new classifier in a new Elstrom of several in the new dimension has been a new
k dimensional space in a new larger space and again I define a new Elstrom quantum classifier
let's say k tensor product Elstrom quantum classifier what we see what we see is that by increasing
the number of the copy also there's strong bound increase and so we see that the accuracy that
we obtain after making this copy this copy in a just in a computational way just by making
a in bi-mathematica okay or by fighting this copy but what we see is that by making this
procedure we have benefit because we increase the accuracy of the of the process we increase
again the accuracy of the process okay and again we have data to to show okay we have something but
okay I want to use just the last five minutes talk maybe to show you a practical experiment
a practical experiment that was provided together with the University of Cambridge and the Institute
of Molecular Bioimaging of the University of Catania and the topic is a chronogenic essay
the chronogenic essay is a quantification technique of the survival degree of an in vitro cell
cultures which is based on the ability of a single cell to grow and form a colony of cell
this colony is not a good thing that is a symbol of something with a of something
disease something great disease the purpose is to count the number of their colonies so
the picture that we are today like picture like this where this is a colony this is a colony
this is a colony and so on okay recent results show how bi-classification between pixel x
belongs to the colony or pixel x belongs to the belongs to the background by making this
classification it is possible to have information about the number of of the colonies there is a
correlation between this this is a biological result in a in a in a quantum imagine and biology
fields that this result but it is it is an assist for us because it allows us to move
the chronogenic essay in a binary classification context so for each pixel if we are able to
classify if this pixel is in the colony or it is in the in the background we can have some result
regarding the number of the code that is in the chronogenic essay and so you have 10 minutes
including the question okay so just I thank you I just spend a few minutes to conclude
and I and I leave a few minutes also for four questions okay okay so the experiment
involved with the many many many data about 10 millions of data and the result that we had
was against that the performance of our elstrom classifier with respect to other in this case
18 well-performance classifier is very good because our classifier in most of the cases
was one of the best one of the best with respect to to the other and that was very very nice for us
so let me conclude with some open problem okay the first open problem is the is this
the generalization of this quantum is pirate quantum is pirate and now we know why I say quantum
is pirate and now we know why I really say that this this inspiration is useful it's not only
a matter of metaphor but this quantum inspiration was based on only a binary quantum state discrimination
so the challenge is to have a multiclass classifier a multiclass classifier and the second goal
should be just to use this quantum inspired algorithm also in a quantum computer just in order
to come from one to be spirited to one so we have some partial result regarding both of these
this point and basically regarding the idea of multiclass classifier we are working on this but
we are we are taking inspiration from the pretty good measurement that is not an optimal but
sub the optimal measurement that allows us to have a multi a quantum multiclassifier
and on the other hand well I am not time to show you the detail of the pretty good
classifier but the idea is the same but instead of to have an optimal we have a sub optimal
measurement but but also we this sub optimal measurement can be used for any classification
instead of only binary classification and also the final challenge as I said is just to
come from a quantum inspired to really quantum machine learning in order to put together the
double benefit of quantum so increase the accuracy but also speed up the computation
well by appealing to the neomarks deletion theorem is it possible in principle to reproduce
and POVM measurement and for instance also the health strong of the pretty good measurement
this is an this is an example but we are working on this and till now we have only only partial
result regarding this but the works are still in progress and okay this is the the bibliography
that the reference that you can refer to and okay thank you all for listening thank you
okay thank you Shusepe for your interest in talk now we have some minutes
questions and comments if you want to make a question please
and I have a little question
for your future but do you know if there is a mathematical relation between the
hand strong bound and the accuracy of your classifier okay so yes are you asking if
there is a connection between a strong bound and accuracy
right okay well basically not basically not because it's very strange because
there are really two topics that are that was never merged together between with within
before now because in a certain sense health strong was not thinking about the classification
problem so in a certain sense health strong well quantum state discrimination
and has not the idea of what is the accuracy because the accuracy could be calculated empirically
empirically only by making the experiment what the what the theoretically we have is this result
is this result that is interesting regarding that strong bound and it is easy to misleading
because easy to misleading because we are not saying that if okay we are not saying this
that strong bound between two states is less of that strong bound between the states
that you obtain by making the tensor copy of itself by itself because in this case it is
an already well known result here we are saying this something different because this object
our quantum centroid this tensor k row is not row times row times row k times k times it is
something different is the centroid that we obtain by making in principle k copies of each
object of the data set and after making the centroid so in a certain sense this is a first
let me say that theoretical result that put together quantum state discrimination and
classification problem because there is the idea of centroid and there is the idea of
a strong bound put in together i hope to answer to your question thank you very much welcome
another question or comment
if not thank you again for your talk thank you all thank you
