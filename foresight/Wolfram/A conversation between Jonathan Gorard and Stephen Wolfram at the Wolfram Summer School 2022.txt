Our event for the evening is a chat between myself and Jonathan, which might have the
subtitle of I'm Trying to Understand What Jonathan's Been Up to for the past several
months, which can sometimes be challenging.
But I think what I really like to do is talk about some of the things that I know Jonathan's
been working on, and maybe my kind of mundane questions will help illuminate some of these
things for everybody.
So if I understand correctly, people talk about categorifying things.
And could we say that you are, that part of what you're doing is categorifying multi-computation.
Would that be a reasonable thing to say, or is that way off base?
No, I think that's a pretty reasonable way to phrase it.
I mean, in a sense, one of the reasons I wanted to have this conversation, or I thought
it would be useful to have this conversation, is I kind of feel as though both of us in
slightly different ways are trying to kind of investigate the abstract science of multi-computation
and its various applications.
And people often say that sort of category theory is like a mathematical language for
processes and how processes compose.
But in the modern world, the standard way that processes get represented is as computations.
I think in many ways it's more fruitful to just think of it as being a mathematical
formalism for computations and how they compose.
And in a sense, ordinary category theory where you just have sequential composition is like,
I think, is basically akin to classical theory of computation.
Monoidal category theory where you can do composition both sequentially and in parallel
I view as being like the kind of categorification, as you put it, of multi-computation and multi-way
systems.
So yeah, and to a great extent what I'm trying to do right now is make that connection a
bit more concrete, develop the formalism a bit further, and see how some of the areas
in which we've been attempting to apply multi-computation so far, like in physics or in chemistry or
to foundations of mathematics, how those can be potentially informed by this connection
to compositionality.
I'm excited.
OK.
So let's go and answer more, sir.
So first of all, for everybody's benefit, let's just start off by talking about what
is category theory, what's the, maybe everybody knows that.
Does everybody, does everybody think they know that here, or some Yorick is saying yes,
but that's not, that doesn't count.
I've talked about nothing else for the last couple of weeks.
Oh, is that right, it's off lecture, right, well, for my benefit perhaps, can you, can
you say what you think, what do you think at this point, now that you've studied category
theory and the nodal category theory and so on.
What is the essential idea of category theory?
OK.
So, in a sense, the, OK, the way I like to think about it is that this, you know, the
set theoretic picture of mathematics involves, you know, you can ask the question, what is
a mathematical structure, right, you give me some group, what is that group, you give
me a topological space, what is that topological space.
The set theoretic perspective says, well, we just break it up into pieces.
We look at, you know, for a topological space, we look at its point set, or for a group,
we look at its group elements and we get some notion of identity of that structure from,
you know, breaking it up into pieces.
Category theory, I think, is a more relational, more process theoretic, ultimately more computational
way of answering the same question that you say, no, instead, you, you, you don't want
to, you know, you don't want to look inside the object, right, you don't want to break
the group up, you don't want to break the topological space up into points or into elements.
What you do is you say, well, what gives this structure its identity is how it relates to
all other structures of the same kind.
So, you know, what, so if you want to identify a particular group, another way, another way
you could answer that question, you know, what is that group, is you can just say, what
other groups does it have homomorphisms to?
What other groups is isomorphic to?
How does it relate to all other groups in the category of groups?
And that's effectively, or similarly with topological spaces.
What other spaces, instead of talking about points and point sets and topologies and open
sets and things, you could just say, well, what other topological spaces can this be
continuously deformed into?
What other spaces can be continuously deformed into this space?
If you give essentially, you know, the collection of all continuous functions to all other topological
spaces of the same kind, the remarkable feature about compositionality is it's an equivalent
answer to that question, right?
The same information you get by breaking the topological space up into pieces is also captured
by the information about how it can be, you know, continuously deformed into other spaces.
So let's take that apart for a second.
So let's take a simple example, actually let's take an unreasonable example.
Let's talk about Turing machines.
What is the category theory view of Turing machines?
Well, OK, so one thing that's definitely, one very interesting general feature of category
theory is that, and this is really, I mean, more concretized in Topos theory, but we can
just stay at ordinary category theory for now, that it makes this kind of, there's this duality
or more precisely what's called an adjunction between sort of, between syntax and semantics,
effectively between.
So for, if you give me a formal model of computation, and generally people talk about this in terms
of type theory, but there's no particular reason to talk about it, it's just that happens
to be the approach that was adopted.
But if you give me some formal model of computation, I can construct a category, which is really
just a multi-way system that encodes the syntax of that computation, right?
So, you know, for the case of a Turing machine, I can construct some multi-way system where,
you know, every state vertex is a Turing machine state, you know, a state of a tape and a state
of a head, and every evolution edge is some, you know, is the application of some Turing
machine rule.
And obviously, those different threads of Turing machine evolution can compose sequentially,
and they can compose in parallel, and that's what gives you kind of the structure of the
multi-way evolution graph.
But there's also a kind of semantic view of what's going on, which is that you can talk
about this, you know, in the case of Turing machines, you could talk about the partial
functions that that Turing machine is computing, and how they relate to it, you know, you can
effectively, you could imagine instead a semantics on the category of sets and set-valued
functions, and then there's this very nice relationship where you can define a pair of
functors that take you from the kind of syntactical category to the semantic category and back
again.
Let me try to take my simple way of thinking about this.
OK, so in a multi-way system, we have the nodes of the multi-way system are states of
Turing machines, and then there are, in some real multi-way system, there are multiple
possible rules that can be applied from every state of the Turing machine to make new states
of the Turing machine.
Right.
So we have this time evolution of Turing machines going in this multi-threaded time evolution
of Turing machines.
So that's our standard sort of multi-way story.
Now you say there's a dual picture, which is consider the functions that Turing machines
compute.
Right.
So we have to define a little bit what we mean by what functions the Turing machine
computes, because that's imagining, you know, we've got in this original view of multi-way
systems, we've got a particular state of the Turing machine, involves a particular state
of the Turing machine.
Right.
How do we get to, so a function, it means you've got a whole range of possible initial conditions
for the Turing machine mapping to a certain range of possible final conditions.
Right.
Right.
So we've got a bunch of different dots in the multi-way graph, and we've got that kind
of, you know, how they flow through to a bunch of other dots in the multi-way graph.
Right.
Yes.
Yeah, absolutely.
And so in a sense, okay, I mean, we're skipping maybe a head a little bit, but that duality
between syntax and semantics has a very concrete realization in the context of multi-way systems,
because effectively the semantics is given by branch ill graphs and mappings between branch
ill graphs.
And so maybe Turing machines is a bit of a, is a, is a, is a less nice example to get
your head around.
I mean, so the example I might give that's a bit less sort of mind bending would be something
like groups.
Right.
So you can build a multi-way system, you know, multi-operator system or something that encodes
the axioms of group theory.
Right.
And so you just start from some seed and in principle, every proposition that's true
about, you know, in universal algebra about group theory will, will exist as some state
vertex in that multi-way system.
But you could say that very quickly, but I think it's a little bit more, I mean, there's
there's more to say that, right?
Because, because you're saying, well, let's not give up on the Turing machines per second,
because you're, you know, what you're saying is there's this notion, which I like very
much of this, you know, the function computed by the Turing machines is this mapping of
this whole collection of possible states, which could be a particular slice captured
by a branch ill graph mapping to another whole slice captured by a branch ill graph.
Right.
Right.
Exactly.
The branch ill graph mapping you identify as being the function defined by the Turing
machine, as opposed to the kind of, you know, the individual path followed, which is the
actual, you know, the execution of the Turing machine.
Right.
Right.
And so this is so actually the syntax semantics duality is deeply related to this sort of
vibration, foliation duality.
Right.
Okay.
So I'm not wild about this notion, this term syntax versus semantics, because I've spent
so much of my life in conversation of languages, you know, as semantics as a whole bag of other
issues.
But, but, but in the case of what, so what you're saying is we can think of this collection
of this multi-way collection of Turing machines as being in terms of every threat of evolution.
We can also think about it by saying, we take all the possible states of the Turing machines
at a particular post time and we look at the mapping of that whole collection of things
onto some future state.
Okay.
So actually, I mean, so just on that point, so I agree in some ways, the, you know, using
the terminology syntax and semantics may be unnecessarily obscure or something, but how
would you, I mean, so it does seem to me that there is an inherent distinction between,
you know, you've got some bare metal multi-way system that's just producing a bunch of states.
There's then some interpretation or encoding step where you say, and this computes such
and such a function.
So how, so how would you just terminologically, how would you distinguish the bare metal multi-way
system from the kind of interpreted one?
Well, when you say interpreted here, we've got this whole giant branch of God, which
is something that an, you know, in our view of the observer is something where the observer
has to be the thing that's knitted together this whole collection of different, as you're
putting it, you know, bare metal computations, right?
And I suppose, I suppose the, that concept of an observer to observer, you know, observer
state to observer state transformation, I mean, for me, that's sort of a new concept.
I mean, you know, in the sense that I'm not sure, not sure that I would associate that
with, you know, when I think, okay, let's talk about syntax versus semantics as it's described
in languages.
Okay.
I mean, so the syntax of English is, you know, how do you put the words together?
The semantics is what is the, what is the quotes in a meaning of that piece of English?
Right.
The problem is people have always had a hard time understanding what an earth in a meaning
actually is.
We finally have, you know, language and the whole computational language idea.
We now have a sort of, for me, I see that as a concretization of what inner meaning actually
is.
But I don't really quite get what, okay, there are many syntaxes, many ways I can say a sentence,
which map to the same inner meaning.
Right.
And, you know, presumably, and, you know, somewhat obscurely, there can be a sentence that can
be, have a particular syntax that can be interpreted with many different inner meanings.
Right.
Which is semantic ambiguity.
Yeah.
Which is, you know, depends on where you are and what, where it's said, all this kind
of thing.
Wow.
Even seeing things as mundane as how the sentence is parentricized or whatever.
Right.
I mean, yeah.
You know, I'm doing this, or I'm, you know, I'm doing this and your voice goes up again.
And it's kind of, it's a question.
Right.
Right.
It's neither injective nor subjective.
Yes.
So these are, these are two separate, and I don't quite see the analogy between kind
of, kind of the, the syntactic level is an easier to define structural level.
The semantic level is this thing that's operating above that, that I've always found very hard
to define.
Right.
And that's actually why I brought up the example with groups, because I think that so in, in
generally in foundations of mathematics, I'd say the distinction between syntax and semantics
is slightly better to find because you have this distinction between proof theory and
model theory, which is quite, you know, quite a hard distinction.
So the, I know that we disagree on this.
I mean, the fact is what, what are the questions is, what is mathematics actually about?
Right.
And, you know, Hilbert famously said, it might be about tables and chairs.
It doesn't really matter.
It's just a formal system where you set up the rules for the formal system and then
you, you know, prove things from it.
Whereas other people, like, I guess, who was Pankeray, for example, was very much, no,
it's not just about tables and chairs.
It's about things we actually imagine are somehow real in some platonic sense.
Or famously, I mean, that, that actually influenced Goedl's research.
Right.
And we thought showing, for instance, that there existed models that were consistent
with, with the continuum hypothesis was equivalent to showing it was true, which is only really
acceptable if you replace this.
Well, Goedl was very much a place, I mean, Goedl, that's what I'm saying.
I mean, I've only learned quite recently, you know, the, the, the usual picture of kind
of the Goedl operation was, you know, there was, there was Hilbert who was trying to define
this model where, you know, mathematics would all become mechanical, you just had to set
up the axioms.
And then as, as Pankeray described it critically, he said, you know, you're turning mathematics
into a thing like this machine I've heard about in Chicago, where, where things going
at one end and, and what was it, hot dog?
Yeah, sausages.
Yeah.
And that, you know, mathematics is then turned into just this machine where you mechanically
go from the, from the underlying axioms to everything that might be true.
And that was kind of the view of mathematics in the first few decades of the 20th century.
And then, you know, the, the, the usual picture is Goedl came along and said that can't be
right because there are these undecidable propositions, these things that can't be established
to find out proofs from by the machine when the machine would never, would never actually
produce the sausage.
And the, the, but I think what I, what I recently learned is that, you know, the picture was
Goedl was operating within this framework of this very mechanical view of mathematics,
but actually Goedl, you know, he has this one footnote where he says, well, this might
be true that there are these undeterminable, you know, propositions of things.
This might be true, but for brains, for human minds, things might work differently.
And I think what I've only learned recently, maybe other people knew this all along is
that Goedl really had a very platonic view of mathematics that there really is an underlying
to mathematics and that all of this stuff with Hilbert's, you know, axiomatic framework
and formalism and so on, was merely an attempt to kind of provide a sort of a, a sort of
a, a set of mechanical accesses to that, but there was something different and fundamentally
different underneath.
And so he thought that by showing that this sort of formalistic wrapper was going to blow
itself up, that that would establish that there really was something underneath that
simple type sets.
So I have a couple of comments on that.
I mean, one is, so there's a version of that argument, which is, I mean, attributes it
to Goedl, but which is kind of made a little bit more, maybe a little bit phrased a bit
eloquent, a bit more eloquently in some of Roger Penrose's writings, where he also defends
the Platonist position, but essentially using a modification of that Goedlian argument,
which is that that, that both, as far as I can tell, both Goedl and Penrose have the
same kind of philosophical interpretation of Goedl's second incompleteness there in
the statement that you can't, you know, you can't prove the consistency of piano arithmetic
from within the piano arithmetic itself.
So, you know, essentially a version of the argument, okay, there's a, there's a lazy
version and there's a slightly more sophisticated version, the lazy version of the argument
is, oh, but we can see, clearly we can see that, you know, arithmetic is consistent and
therefore we must be doing some process that's not captured by this formal specification
of the machine that's doing the proving.
A more interesting version of that argument is you say, well, the fact that one of the
things that that theorem tells you is that in effect, there's now this whole infinite
hierarchy of arithmetic, because you, you know, for any, if you have some, you know,
if you have piano arithmetic, you can always construct a stronger system, which is piano
arithmetic plus the axiom that piano arithmetic is consistent, or that axiom system plus the
axiom that that system is consistent and so on.
And so, you know, the argument goes, well, for it, for any attempt you make to kind of
box mathematics in, to formalize it in some, in some finitary deterministic way, there's
always some way that it's going to be able to break out of it again, which again is kind
of viewed as a, as a defensive, of the platonic view.
I mean, I know you are aware of this and I know we've discussed this in some detail.
Maybe it's worth saying just in case it kind of wasn't clear to other people that, you
know, one of the things that comes out of, well, NKS, and I'd say more recently from
the physics project, I mean, you have notes in the, in the foundations of mathematics section
of the, whatever the principle of computational equivalence chapter of NKS to this effect.
But, you know, this distinction between, you know, the sort of girdle view of Platonism,
the Hilbert view of formalism, the sort of Russell whitehead view of logicism, etc.,
that those distinctions kind of evaporate when you start to think about, well, science
and mathematics in more explicitly computational terms in no small part, because, you know,
if you take something like the Wolfram model, right, it's in its most abstract form, it's
just a collection of rewriting operations on, you know, hypergraphs or collections of
elements.
And those elements have no intrinsic meaning, they're just purely symbolic, right?
And I realize you have this kind of term EMS to kind of sort of refer to this in, in,
yeah, in, in the more, in the more.
It's now being captured in the fine science fiction novel that somebody is writing.
Right.
So it's, so it's real.
Right.
But so if, you know, if that is a good model for, for science and for physics, then one
is confronted with the, with the realization, you know, so, so Hilbert may famously defended
this formalist position by saying that, you know, mathematics is nothing more than this,
this meaningless game played with meaningless symbols on bits of paper.
But if we now have to confront the possibility that, you know, our universe is a meaningless
game played with meaningless symbols on what presumably not bits of paper, but on, on some
as yet undefined substrates, then you're forced into this rather awkward philosophical position
of either you have to afford physical and mathematical objects the same degree of ontological,
you know, substance, or you have to kind of argue that this is a, this is the wrong way
to view, you know, the structure of reality.
And so, so, you know, in a sense, it, it, when taken to its logical conclusion, I'd
argue, and I suspect you'd argue too, that is, you know, it really means that formalism,
that Hilbert's version of formalism also implies a version of Platonism.
I suppose you could say that.
I mean, my, my argument would be kind of forced to a position where if we say we exist, we
also have to say mathematics exists.
Right.
Or physical objects exist or whatever.
Right.
Yes.
Either, either, yeah, either nothing exists or mathematics has to exist.
Right.
I have to fundamentally exist as a, as a, as a sort of a thing that you can kind of, it's
not something where you're just defining it formally.
It's, it's a, it's an inevitable existing thing, so to speak.
But I think we, we, we kind of,
Yeah, sorry.
Sorry.
That's the matter.
Yeah, the point I was going to make in really, you, you were, you were disagreeing with my
statement that the distinction between proof theory and model theory is, is, is rigid.
Whether, whether we can have an, you know, in our imagination, whether the integers are
a real thing, whether the integers are merely a, maybe you should go on with your.
What, all I was going to say was that, you know, so you can imagine to take this back
to something more concrete and computational, you could imagine having two different kinds
of multi-way systems, right?
You could imagine having multi-way systems that effectively multi-way operating systems
based on the group axioms.
And you could also have, imagine having a multi-way system where every state vertex is
a group and every evolution edge is, is say a homomorphism.
And that would be so in the, yeah, in, in the, in the sort of, in this adjunctive relationship
in category theory between type theory and models for type theory, you would call the
first thing the syntactical category and the second thing the categorical semantics.
And the interesting thing is that you can generate one from the other, right?
So that, so there's a, there's a, there's a pair of left and right adjoint functions
that take you from, I mean, again, the standard way you describe it is that you've got, you've
got a category that represents a type theory in which every object is a, is essentially
a, a, a, like a type environment and every morphism is a kind of, you know, a replacement
of, as a substitution, as a replacement of variables.
And then you've also got this other category, which is like the actual semantic thing where,
you know, the objects are groups and the morphisms are homomorphisms or something.
And you can, and there's, yeah, there's a, there's a sort of procedure that will freely
generate say the semantic category from the syntactical one, and you get this thing called
a walking model.
And so there's, it's a fairly, I mean, it's, there's a lot more that needs to be kind
of concretized, but it's a fairly well developed sort of idea.
Yeah.
This is interesting.
And okay.
So, you know, on one picture here is you've got a multi-way system where every node is
a whole group.
Yeah.
And every edge is something that, that connects that group to a group to which it is homomorphic.
Yeah.
Okay.
That's thing number one.
That's your sort of semantic level version.
Now you've got a level where the individual elements are what are, are, are, that, how
are you constructing your syntactic level thing?
What are, what are the pieces of the multi-way system in that case?
Well, so for the case of an, so this is an algebraic, you know, group theory is an algebraic
theory, which kind of what it means to be an algebraic theory is that you just, you
have some binary operation and you have equational rules.
So probably the words, right, right, but, but you should, but generally words that
are quantified, right?
They're not, they're not specific words in some model of a group.
They are universal algebraic statements.
And so when you say statements, okay, just, just for clarification, right?
So, you know, groups, you can, you can, I mean, this is something in that metamathematics
piece I, I did, you know, was something that held it up for a year and a half was, was
the, the sort of messy correspondence between a theorem being something which is this word,
this set of symbols is equivalent to this other set of symbols versus a theorem which
says this set of symbols is, is equivalent to the set of symbols and deriving another
equivalence from that first equivalence.
Right.
Those two things are not fundamentally different.
One is just applying rules to, to elements and the other is applying rules to rules
effectively.
Right.
They're not fundamentally different.
But I, I'm just to clarify, maybe it doesn't matter.
But this is why I brought up the thing about algebraic theory.
So I, so in an algebraic theory, I would argue the most natural representation is have every
state, every state vertex be an equation and have every evolution edge be an application
of some, you know, some equation or a one-way application of some of the equation or rule.
Whereas in more general non-algebraic theories, it makes more sense to have each, have each
state vertex be a proposition and then have the evolution edges effectively be one-way
implications.
Fine.
But what you're saying is we've got an equation that says a dot b equals b dot a dot a or something.
Right.
You have a transformation which turns that equation, which potentially is another equation
applied to that equation, which where you substitute one equation into the other and
you get the result, you know, b dot b equals a dot a or something.
Right.
Right.
And that's okay.
So we've got, we've got this notion.
So in the token event graph formalism, for example, we will be saying that these tokens
are equations and that the typical sort of rule of evolution, the law of inference, rule
of inference is two equational tokens, equation tokens kind of mixed together and one is substituted
into the other and you get a new equation out of it.
Right.
Is that the kind of picture that, that term?
Right.
Do I write something like that?
Okay.
Fine.
And so then in effect, what you're, that sort of syntactical multi, I mean, again, we may
want to go over proof, theoretic multi-way system is essentially defining, it's, you
know, as with, as any multi-way evolution graph is, it's defining some partial order on
the state vertices.
And that partial order is essentially telling you what you can, what you can deduce from
what, right?
You've got, you know, if, if A proceeds B, then it means you can derive B from A.
It's a little bit more complicated in this case where you're applying, you know, whether
two equations coming in, they get mixed together and make one equation out because things are
going to do reverse.
I mean, these equations get reversible and so on.
Right.
But that's why, that's why, you know, if you, in effect, your state equivalence function
has to like take into account these things like paramodulation, but, you know, that deal
with things like rule orientation, but.
Well, right.
I mean, what you're saying there is, is when you take one equation and you apply it to
another equation, there are a bunch of weird little pieces of knitting that you can do
as you apply one equation to the other.
Right.
And that, you know, substitution by substitution, you know, cosubstitution, paramodulation,
which is, I think, I think it's the same as by substitution, but I'm not sure.
You know, these are all just complicated things about which variable is replaced and etc, etc.
But, but okay, but we've got something where we have theorems, effectively, in the system
that are derived from other theorems.
Right.
Right.
And you've got some path of theorem derivations and that's, that's view number one and you're
saying view number two is you take a, you're taking a thing that's formed from a collection
of theorem so that, that term for which a group is a thing for which a bunch of theorems
are true.
Okay.
Crucially, though, a specific group, you know, what distinguishes doing group theory in relation
to a particular group from just doing universal algebra, right, and just proving statements
about groups in general.
Well, the, the, the key difference is that for a concrete, for a specific instance of
a concrete group, there will be additional theorems that are true about that group, which
are not true for the, in the universal algebraic case.
So effectively, what you're doing, one way you can think about it is that you're taking
this partial order that your syntax multi-way system, your proof theoretic multi-way system
defines and you're, you're making it more like a total order, right, you're, you're
introducing new orderings between states that were not true in the existing multi-way
system.
So another thing you could say is of all of those relations which were there, only some
subset of them are now considered true for this group.
So you're taking a slice out of this whole complicated network of, of, of theorems.
There's some bag of those theorems that's true for the group.
Well, no, but every theorem that's true about in universal algebra is obviously going to
be true for any specific group.
So it's more that it's not that you're removing some theorems, it's that you're, you're effectively
introducing new ones.
Right.
There are additional theorems which are true.
Right.
You're saying and those.
And so it's, so the, and so the, you can make the analogy to relativity when, you know,
you've got the conformal structure or the causal structure of space-time that is kind
of a universal thing.
And then individual observers impose new, you know, so a particular observer can introduce
new causal, you know, new chronological relationships between space-like separated events.
Well, in particular, they can choose, this is simultaneous.
Right.
Right.
Right.
Which is to say.
And to generate, as you, as, you know, as you approach the speed of light in the relativity
case, your partial, your space-time partial order becomes a total order.
Right.
That's the sort of, that's the, that's the degenerate case.
So one way you can think about boosts is that it's a way of taking this partial order and
making it more like a total order.
Let's walk through the total order.
So you're saying that normally you have a bunch of events happening in space-time.
Right.
You are, the claim is, if you're a photon, you, there is only a, if you're, let's walk
through this, so, so, you know, normally there are things that happen in different places
in the universe and you get to define whether, you know, what counts the simultaneity, what
was, you know, noon on Earth, noon on Mars, when were these things relative to each other?
Right.
Okay.
But if you're a photon, you don't get to do that.
Well, photons have no notion of space, right?
That's, that's, that's the basic point, or, well, all time.
Right.
So, you know, so as, you know, what does it mean to say that you're undergoing a time
dilation or length contraction?
What it means is that effectively your anti-chains are getting shorter and your chains are getting
longer.
And if you take that process to its, to its conclusion, eventually everything is just
a chain.
So, so the, so the, the maximum boost is the case where your space-time becomes totally
ordered.
Let's, okay, so your claim is, when you're using up all your computation on, on kind
of ongoing as fast as possible, you, you don't get to move at all in space as the basic
claim.
You don't, you know.
Something like that.
Yeah.
You, you, you, everything is still not quite internalised in that, but, but, okay.
But, but so, all right.
So now you're going to tell us what the analysis of that in mathematics is.
Well, so as I say, I mean, just abstractly, all that you're doing is you're taking a partial
order and you, you know, by, by, by foliating it, by constructing these equivalence classes,
you're just introducing new, you know, new relations that didn't exist before, which
is what happens when you define a model in, in, in a, in a mathematical theory.
So one way that you could think about a model is that it's taking this proof theoretical,
this proof theoretic multi-way system and it's foliating it in such a way that you introduce
these new, these new, these new relations that didn't exist, that exist only as a consequence
of the model you've chosen.
Yes.
Okay.
And so, and that's essentially the branchial graph story, right?
That that's now you're viewing the multi-way system in terms of its, in terms of its branchial
decomposition for some reference frame.
And so that leads to this rather interesting realisation that essentially this duality
that exists in, in category theory between, I know you don't like syntax and semantics,
but you know, proof, proof theory and model theory or whatever, the syntactical category
in the, in its, in its, in its sort of compositional semantics, that's really just a special case
of this duality between looking at a multi-way system in terms of its multi-way evolution
graph and looking at it in terms of its decomposition into branchial graphs, right?
We know that they encode essentially the same information, except the branchial graph also
has this additional thing about, you know, its observer dependent.
And that's really the, and that's, that's what model theory is about.
And then for instance, something like the first incompleteness theorem just becomes
a statement that, you know, one way you could phrase, you can phrase the first
incompleteness theorem is that, you know, in any formal system that's sufficient to encode
piano, sufficiently strong that it can encode piano arithmetic, there will be propositions
that are true in some models and false in others.
And so that becomes essentially a statement that, you know, if you make, again, going back
to the relativity analogy, that's equivalent to the state, or analogous to the statement
that there can exist space like separated events where, you know, A proceeds B in one
reference frame B proceeds A in a different one.
So effectively, the first income witness theorem becomes a statement of gauge, essentially
a statement of gauge freedom, which is although the other piece to that has to be something
about how they're infinite like paths.
So how does the infinite length path story, and the not non-finance approves how does that
come into that, that version of thinking about things that there exists different models.
Why is it, why is it the case that, I mean, it must be something about how you can always
find a different model, which has this different ordering, and that must be related to the fact
that there are infinite potential proof paths.
Right.
I mean, so in a sense, if there's an infinite proof path between two propositions or two
state vertices, then for any finite size of multi-way system that you compute, they're
going to be treated as an anti, you know, they're going to be treated as unrelated by the order.
And so, yeah, eventually, if you could write, if you could somehow, if you could take some
infinite limit of the multi-way system, they would no longer form an anti-chain.
But the point is that for any finite length of computation, you still have that gauge
freedom to choose one to proceed the other in any way you like.
Well, I'm just saying that you might be, another way to say this is, you think you've got a
valid model, but actually, you know, if you were to go long enough in the multi-way graph,
your model would blow up because the thing wouldn't actually be consistent anymore, that
you could take that as an anti-chain.
Right.
You know, it wouldn't actually be an anti-chain.
It wouldn't actually, but the people who don't know this wouldn't go, anti-chains
means you have a partially ordered set, things, you know, you're saying something precedes
something, et cetera, et cetera, there's a chain, which goes, you know, A precedes,
B precedes, C, and so on.
An anti-chain is just the transversal of that, where you're saying what doesn't have a particular
ordering that it needs to, what doesn't have its ordering defined, what can be sort of
at the same time as something else.
I think there's a clearer way to say that.
That was a bit of an obscure.
It's basically the transversal to a chain.
You know, a chain is what has to precede what, and an anti-chain is what doesn't have its
ordering defined for it.
Right.
It's the stuff you have freedom to choose, you know, the precedence relation for.
Right.
Okay.
So let's come back to this group's thing.
So you're saying you've got, well, maybe the general point, that is that, you know, you
can look at branch of evolution, or you can look at the underlying, essentially temporal
evolution.
I mean, in a sense, it's the spatial slices of all the interspatial slices, or it's the
individual sort of threads of time evolving.
Right.
And which you are going to interpret as foliations versus vibrations in, you know, all sorts
of systems.
Right.
Right.
Which is quite lovely.
But again, you're about to say the interpretation of the speed of light, of the infinite boost
in mathematics.
I know you've had a version of this for a while.
What's the, if we imagine in mathematics, we've got, you know, these different models
that we can take, and they correspond to these different, different foliations.
And then we've got this extreme model where, you know, where you tip things to the point
that there are no anti-chains.
Right.
So it's formally the opposite of, you know, a free structure.
Right.
So ordinarily in mathematics, you would say, if you talk about, say, a free group, or a
free ring, or a free whatever, what you mean is, you know, this structure contains no additional
relations beyond just what is imposed by the axioms of the theory.
So that's the analog of, like, you know, the rest frame.
Right.
There are no additional relations beyond just what the syntax of the theory implies.
The infinite boost case, for which I don't want to claim it doesn't exist.
I'm not aware of any standard terminology for this in mathematics.
It's kind of the maximally restricted version of the structure.
It's as far away from being a free structure as you can get.
It's introducing all possible, you know, obviously, there's not just, there isn't a unique maximally
restricted structure, right, because there are many different directions in which you
have a boost, so to speak.
So is it something for which all theorems are true?
I mean, a free one is something for which there are a few theorems.
No theorems are true beyond the, you know, beyond what's implied by the axioms of group
theory.
So maybe this extreme case is all possible theorems.
True.
Except, well, except it can't be all possible theorems, right?
I mean, it would still be consistent.
You'd still want it to be a consistent theory.
Yes, but it's still the case that you're adding an infinite collection of relations.
Right, right.
No, I'm just asking, can you briefly explain why that is well-defined?
Why the sort of...
The opposite, so your infinite boost object, whatever you call it, why is that a well-defined...
No, I'm not...
I think it's probably not...
Well, yeah, I'm not claiming that it's well-defined.
Okay, yeah.
But yeah, in fact, that's the point I was making about, you know, just like with boosts, there
are, you know, infinitely many directions you could apply your boost in.
And it's just, yeah, effectively, you're somehow maximizing, you know, it's some sort of optimization
problem where you're maximizing the number of theorems that are true about this particular
structure.
And yeah, I don't think that's...
Let's nail that down a little bit more carefully.
This seems interesting.
So what's the analog, I mean, the free group, free any algebraic structure, just...
I mean, what's the simplest case?
What is the simplest case?
The simplest case is there are no relations.
So in group presentation theory, your presentation has generators, but no relations, right?
So it's just a freely generated group.
No, I understand.
I need to forget the group part.
If we just have something where a pure binary operator is just hanging out and doesn't have
any particular relations at all, that's the case, the free case there.
It's a free magma, I think.
Okay.
So in that case, is that what a magma is?
I can't remember.
Yeah, I think that's...
Magmas have closure and nothing else, I think, as if I recall.
Okay.
All right.
So it's just this thing that's got a binary operator, but there are no relations that are
true.
So its free version has no theorems, I think.
Maybe it has a theorem that A equals A, and maybe that's something to do with this closure
property.
Or the thing is equal to identical.
Well, yeah.
I mean, there are things that are true just...
So I mean, this is an effect of what paramodulation is about, an equational theorem proving.
It's about...
There are certain statements that are just structurally true by the nature of equality
being an equivalence relation.
So A equals A...
It's reflexive.
If A equals B and B equals C, then A equals C and that kind of stuff.
Okay.
So the free, free, free case is just identical things are equal to identical things.
Nothing else is true.
Well, and as you have the standard properties of an equivalence relation, right?
You have transitivity and...
Well, but that's not going to say very much.
I mean, transitivity is just saying the identical thing equals the identical thing equals the
identical thing.
It's not saying A equals B, B equals C, therefore A equals C, which is the usual transitivity
relation.
There isn't any such relation because it's only saying identical things are the same as
identical things, isn't it?
Why?
Well, if there are no relations, if there are absolutely no relations, all you can do...
Then you may not be able to distinguish.
Yeah, yeah.
That's what you're saying.
Yeah.
Okay.
Okay.
So now that's the absolutely free limit.
Now, what's the take that and start adding relations?
So the relations you're going to add are expression equals expression.
Right.
No possible expressions.
So eventually the thing will be gummed up to the point where first of all, I thought
everything was free floating and it had no relations to anything else.
And then eventually it just makes a single big blob where everything is equal.
Right.
So then the end result, so you're saying the boosted thing is an everything equals
everything type situation.
Yes.
So that's saying that in a sense there's no...
What is that really saying?
From a proof theory point of view, that says that everything is connected to
everything.
You've got this giant...
Your multi-way graph is just this...
What is it?
It's just every node...
It's a complete graph.
Every node is connected to every other.
True or false too.
Right.
I mean, yeah, normally you'd want it to be consistent.
So in particular you shouldn't have...
Yeah, you shouldn't have cycles where you can...
But what is consistency with universal algebra?
Isn't that a different story?
I mean, you can't...
In other words, the notion of consistency is a different thing from these algebraic
theories.
The notion of true and false doesn't enter as such.
I mean, a group true is not an element of a group.
No.
A group just has words.
Mm-hmm.
And so...
But I think...
Okay, so what you're saying is...
I mean, the basic point...
Ignoring the true false...
I'm claiming you can ignore when you're thinking about things algebraically.
What you're saying is that in the extreme boost...
The extreme model is the model where you've poured in every possible group relation,
for example.
Okay, sure.
And therefore everything equals everything.
Mm-hmm.
And so how should we think about that?
How should we think about that?
What the heck is that?
That's a...
As you get closer to that limit...
Okay.
Is that the same thing as saying that for a photon, time never passes?
Well, it's suddenly related, right?
I think it is.
Yeah.
Because for a photon, it sees the whole history of the universe.
And for a photon that was emitted 100,000 years off the beginning of the universe,
and we just catch it in the cosmic microwave background,
as far as it was concerned, it was just emitted.
And it ended its time in that random detector.
But so what this is saying, I think, is that...
Okay, so time never passes for a photon because...
Or it is seeing, in some sense, the whole history of the universe.
In one moment of its time, it's seeing the whole history of the universe.
So similarly in this completely connected algebraic system,
in one relation, it is seeing every part of the algebraic system.
But I think that's right.
Yeah.
So in other words, time in the algebraic system,
we can think of time as being proof steps, right?
And what this is saying is there are no...
You can get to everything in one proof step,
just as in the photon, you can get to everything in one moment of time.
Okay.
So, okay.
I'm not sure where we're going.
But that was actually very interesting.
The correspondence between the infinite boost in mathematics becomes...
This is our interpretation of that.
The infinite boost in mathematics is that everything is instantly true.
I think...
I'm not sure if that's...
Just like everything...
Okay, anyway, I'm distracting because the original prompt was,
so you're a categorical computation.
Right.
So I want to...
You were making point about mathematics, which I think I did right.
Sure.
By the way, so, Tarius, did you have your hand raised?
Yes.
I want to ask something about the notion of having a group
and putting in all the compatible group relations which I have.
I don't know if it's what people get.
You see this answer by the categorization of the groups.
Because the categorization itself is all the possible groups I have.
No matter how many relations there are, it should be something of both groups.
Right.
For the particular case of groups, I think Dugan has already pointed out in the chat,
that it's up to naturalisomorphism, it's the trivial group.
Because if everything is equal to everything, then everything is equal to the identity.
So it's...
It doesn't mean that everything is related to everything.
Because one relation with a useful structure, another relation with another structure.
And this structure is not that we provide it to each other.
But the things for both, the set of all things in case,
must be something among the things that categorize as what the groups,
for a particular order.
I think so.
Once you start in enough relations,
it's just going to relate everything to everything, doesn't it?
Right.
I mean, you can run this experiment.
If you run multi-way group and you just add more and more relations,
the state's graph will become more and more connected.
What I'm saying is that when you go for some free relationships,
they don't have to hold, so to speak.
If something is equal to one relation,
it doesn't have to be equal to the other relations.
It's just three groups, different groups.
We have some morphic structures.
I want to come back to this correspondence between the multi-way system,
where it is theorems, where the nodes are theorems,
and where the nodes are groups.
Right.
That's what you, in some sense,
maybe that's at the heart of this notion of categorification,
is that you made the statement that the original multi-way system,
it might be the case that nodes are theorems,
and then you can make a correspondence between that,
and I don't understand this, so I'm trying to understand this.
You can make a correspondence between that and a multi-way system,
where the nodes are whole groups.
Right, right.
Okay, so can you explain that?
So the first multi-way system is just the universal relations about groups.
It contains all the universal relations about groups.
Right.
And now you say, what is the correspondence between that?
Given that, you're saying, I mean,
each blob in the thing which has particular groups
has had additional relations thrown into it.
So each blob could be labeled by its additional relations.
Right.
Is that true?
Yes.
This is why it relates to the duality between multi-way evolution graphs and branch-o-graphs.
So the multi-way view of what's going on is you take some multi-way evolution graph,
you define a model, it produces a sequence of branch-like hype,
essentially a sequence of branch-o-graphs.
Then you could imagine treating that sequence of branch-o-graphs as a single thread
in some other multi-way system that's effectively acting on branch-o-graphs.
But you could also consider, you know,
that's just one possible sort of foliation of the original multi-way system.
There are many, many different foliations.
I'm confused already at that point.
In order to get from the original giant, you've got this multi-way system.
It represents all possible things,
all possible theorems you can derive from pure group theory.
Okay.
Now you take a branch-o-graph out of that.
It's a slice across the whole multi-way system at some time step, basically.
Yes.
So now I don't understand the statements that you're taking
that those branch-o-graphs can be rolled up into single nodes
because that branch-o-graph extends over the whole space, doesn't it?
Of course.
But that's why it's a different multi-way system that you're constructing.
I mean, again, it's analogous to the power-set construction
in something like in non-deterministic computation.
When you convert a non-deterministic finite automaton to a deterministic one,
you're defining the deterministic finite automaton
as acting on the sets of permissible states of the non-deterministic one.
Okay.
In the same way, you can compress any multi-way system
into a single-way system that's acting on the branch-o-graphs
of the original multi-way system.
That's the generalization of the power-set construction.
Okay.
So let me go through that for a second.
Okay.
So you have this multi-way graph and you can say,
I can summarize what happens in this multi-way graph
by just taking these spatial slices, which are the branch-o-graphs.
And there is a single-way story because it is just one thing goes to,
you know, one, you start at the beginning, you have a branch-o-graph
that slices across the whole multi-way system,
goes to another branch-o-graph, and so on.
But if I'm understanding correctly, you're saying,
but actually there's another thing I could do,
which is instead of looking at that single-way evolution of one branch-o-graph
with that, in this particular foliation of one branch-o-graph
to that branch-o-graph, I could consider all possible foliations.
And that is a different encoding of the multi-way graph,
which is the mapping from all, you know, a branch-o-graph
as defined by some weird foliation.
Right.
And all possible, you know, you make a branch-o-graph with that weird foliation,
it will map to another branch-o-graph and another weird foliation
and another weird transversal slicing.
And then you can make problem from, okay, so this is,
okay, so this leads to the question of,
there's a function that like Nick wrote,
and maybe you have a version of this function as well.
This will simply take a multi-way graph and turn it into this dual branch-o-graph,
well, maybe not, maybe it isn't this function, I'm not sure.
But so it should be the case that you could write a function,
take a multi-way graph and simply turn it into its corresponding branch-o-graph.
Yes, I do.
Yeah.
Do you have such a function?
I have code that does that, yeah.
Okay.
But what is that?
I never thought about that function before, I think.
Maybe I already did in some other world or situation, but okay.
So what you're saying is, but now how do you parameterize these weird foliations?
Are they parameterized by adding relations?
In a mathematical sense, you can presumably parameterize them by saying what relations you add.
Right, exactly.
In effect, what new orderings between state vertices are you introducing,
which is another way of saying what relations are you adding?
So by ordering between state vertices, normally it will be a slice where you've got simultaneously,
so to speak, defined like this, but sometimes you want to have your simultaneous surface go up.
Right.
Turn what was previously a time-like connection into,
what was previously a space-like connection into a time-like connection?
Something like that.
I mean, yeah, the point is that the rest frame is like the free case,
and then anything that's not the rest frame is going to introduce new relations.
Or anything which has a gravitational field, in fact, because it's bumpy.
Yes.
But it doesn't even, I mean, even inertial non-gravitational frames will introduce new relations.
Yes, I agree.
Okay, so then what we've got is this duality, what a nice object.
This duality between the pure multirate graph and this all possible foliations thing
where each possible transversal in the multirate graph is a branched graph,
which can be rolled up into a single node of the branched multirate graph.
Right.
And my claim is that that conversion of one multirate system to another is the kind of concretization
of this functor that takes you from the syntactical category to the semantic one,
the categorical semantics.
And there's a sense in which this has been studied.
There's one area that I'm aware of in which this functorial relationship has been studied quite extensively,
and that's in quantum field, in functorial and topological quantum field there.
I mean, I don't know if that's worth.
Okay, yeah, sure.
Let me just absorb this big idea before we get onto the next one.
Okay.
Okay, so just, I mean, the notion here, let's just try the same idea in a bunch of different ways
just to understand it better.
Sure.
I mean, the original idea is we've got just a plain multirate graph and which could be represented.
Let's say it's a string substitution multirate graph.
Okay.
And now we're going to make its branched multirate graph.
Right.
What is the interpretation of the branched multirate graph in terms of the string of writing?
What are the nodes of the branched multirate graph in a string of writing system?
Is that obvious?
Well, they're collections of strings that have, each node is a family of strings with certain
ancestry relationships in the original multirate system.
Yeah, I understand that point.
I mean, it's a branched graph.
The question is, is there a different way to say it than just to say, in other words,
in the case that you've interpreted in terms of group theory, one can say every node is indexed
by a collection of additional relations for the group.
So, oh, I see.
It's the same thing.
Yes, string of writing is just monoid theory.
Right.
So what you're saying is that.
So the original system is like the free monoid generated by the axioms that you gave it.
But you can also have restricted monoids.
So here's a way to say it.
The way to say it is the original graph has all these different, let's say it's a graph where you derive
strings from strings and so on.
And every node is a theorem.
What you're saying is, in the original graph, you've just got theorem to theorem to theorem to theorem.
Every node is a theorem.
In the other graph, you have bags of theorems.
You said it actually, the subset power set construction.
Right.
Every node is an element of the power set of possible theorems from the previous graph.
Right.
But it's more general than the power set construction because it's branchial and therefore also encodes
ancestry information.
That's the sense of which it's a generalization of the NFA DFA conversion.
Let's just go through both of those pieces.
Okay, so the first statement is that you have this original graph that has a bunch of, you know, it's essentially theorem to theorem to theorem.
There's a little bit of fuzziness there for me, because of this thing about theorems and token event graphs versus theorems as pods.
And I don't quite understand that, but let's let's set that aside for a second.
I mean, that's considered a technical detail.
Okay, now.
Okay, so then you're saying the first thing we want to do is instead of thinking about it as this, you know, graph of theorem to theorem to theorem.
We say it is a big bag of theorems here that evolve to a big bag of theorems here.
Right.
It's the branchial, but there's additional structure in this bag.
It's not just a bag of these things.
It's a it's a collection of these theorems that are branchially where we know the branchial relations between those theorems.
Right.
Why does it matter that we know the branch relations?
Is that important for reconstructing this branch of multivariate graph?
So probably so in the metamathematics case, possibly not, I don't, I actually don't know, but one case in which it's very important is in the sort of the QFT case.
Okay, well, that's, that's, that's, I think we've absorbed, anybody have any comments or questions or about this?
I understood something.
At least things coming up on Zoom.
Oh, yeah, let's have a look.
Okay, it's Dugan's comment, which I saw knows a symbolic sentences.
Nick is asking if this dual branch of multivariate graph is the union of path graphs made by all possible affiliations with branchial graphs as dual states, I think that's true.
I think that's a good summary.
The branchial multivariate graph is a union of path graphs made from all possible affiliations.
Right, because, because, because each, each foliation is a path graph, it forms a path graph and so you just take a union, right, just like the same way that we do, you know, Monte Carlo or something.
That's correct. That's correct. Because that's saying that it's a path graph is a single way system.
Yep.
By branchial.
By doing the power set of construction.
Right.
Okay, all right. Now, now we prime to jump into a corner field.
Well, I mean, sorry, I'm not bringing up the QFT thing to be obscure. I'm actually bringing it up because I think it's, it's the area where this is where this is most concretized.
I understand. I'm all for it. I'm just, I'm just, I was just pausing for a second. That's, you know, like a digestion.
Okay.
All right, let's go into corner.
So, yeah, as I know, we've discussed, well, we've discussed quite recently, but maybe to rehash a little bit, there's a sort of, okay, you know, one hand in ordinary quantum mechanics one has this, this, this duality between the Schrodinger and Heisenberg pictures right you've got the Schrodinger
which is the Schrodinger picture which is kind of time evolution oriented, and you've got the Heisenberg picture which is sort of observable oriented.
And we know that there's a, there's a way in fact again in category theory there's an explicit functor that lets you that encodes the passage from one picture to the other.
So there's a general.
Can we just, can we just hover on that for a second. Let's think about a quantum circuit.
Yep.
In a quantum circuit, you're, let's walk through what is the Schrodinger picture for a quantum circuit.
Well, the quantum circuits are a Schrodinger picture, right.
So what is the Heisenberg version of the quantum circuit?
The Heisenberg version would be something like, so the, if you imagine the measurement step at the end of your quantum, that actually maps things onto real, you know, eigenstates with, you know, with, with probabilities.
If you imagine that was sort of progressing through time rather than the unitary operators. So, you know, ordinarily in a quantum circuit, you've got a sequence of unitary operators, these gates, and you know, tensor products of them.
And then right at the end, you do this Hermitian measurement step. If instead you had a time evolution of those measurement operators, rather than of the unitary operators, that would be a kind of Heisenberg analog of a quantum circuit.
Well, in, in, in one way quantum computing, that's, that's what's done, right.
So it's Hermitian stuff.
Right. So, so in, in one way quantum computing, what you do is you set up some, some big maximally entangled resource state. And then you effectively just do local measurements on bits of that state.
And then at the end, you've got some results. And so it's a sort of, yeah, it's a version where your, your circuit has the, has time evolution of measurement gates rather than the kind of unitary gates.
Let's remind ourselves just in terms of ordinary quantum.
The Schrodinger picture is kind of the, the, you know, you have the wave function and the wave function is evolving and changing what it is.
And in the Heisenberg picture, you have an observable operator, like position operator or something, and you are imagining that that evolves with time.
Right, right, exactly. And, and so, but, but in terms of, let me see.
So in terms of S matrices and S matrix, which in quantum mechanics gives you this mapping from the initial states to the final states.
Right.
That is a very Schrodinger picture story.
Absolutely. Yes.
So what is the, what is the Heisenberg picture analog, the S matrix?
Right. Okay. So, well, there is a, mathematically, it's what's called a local net, a local net of monoids.
Oh, boy. Okay. That's why I never heard of these things.
I used to do particle physics.
They required submerging to the categorical marsh.
Well, actually, I mean, that's, that's a purely algebraic thing.
And so, because mathematically, all that's happening is, you know, in the, basically in the Schrodinger picture, what you care about are linear transformations of vector spaces and, you know, effective vector spaces and isomorphisms.
Whereas in the Heisenberg picture, what you care about are endomorphisms and their isomorphisms.
Endomorphisms of observables to observables somehow.
Yeah. Or, I mean, the algebra of observables is an algebra of endomorphism.
You know, each observable is an endomorphism on your, on your space of states.
Okay, so I want to come back because I understood S matrices years ago as, you know, the basic idea of an S matrix, which shows up a little bit, even in chemistry, chemical reactions, things like that, is you've got an initial state of the system.
You know, you've got the state vector of the represents the different possible configurations in the system.
You have a giant matrix that tells you what the new state vector is going to.
So, so the point I was going to make was that you've got so the, all the S matrix is formally is, you know, you've got two vector spaces and you want to ask what's the linear transformation between that kind of all the S matrix is really encoding.
And then, yeah, the analogous thing is you've got to endomorphism algebras, and you want to know, how do I map from one to the other.
And then there's this, yeah, this, this local net construction which I don't claim to understand particularly well but it's used in, in algebraic quantum field theory.
In S matrix theory, for quantum field theory, does anybody know because you know the S matrix maps a particle and incoming collection of particles come in for infinity they interact, they go out to infinity.
S matrix represents the translation between the amplitude of the incoming particles the amplitude of the outgoing particles. What is the observables analog of that whole thing.
Is there a picture of that I have no idea what the observables must be the correlation functions in particles so this must be a, that must be the sort of mundane particle for this version of this is some kind of statement about correlation functions and some, some mapping
Okay, so that you're, that sounds plausible. Right, so I mean so what it must be is that the correlation functions of the initial correlation functions as well no it's not initial and final.
It's a mapping between collections of correlation functions.
Right.
Okay. And what is the remind me the interaction picture is some intermediate version.
Right, exactly, exactly. So, so, so, so part of the evolution is taken on by this by this effectively the states in your in your herbert space part of the evolution is taken on by the, by the endomorphism by the observables.
I definitely got this picture where I mean for me as a mundane particle physicist. It's kind of the, you know, initial state to final state versus correlation functions to correlation, you know, collections of correlation functions to collections of correlation functions.
Right, right. That sounds reasonable.
Okay, so that's the, you know, Schrodinger versus Heisenberg picture, right. Okay, so now now so now explain that you're going to explain algebraic versus.
Right, right. So, so functorial field theory is essentially the Schrodinger picture, but in the more general, you know, QFT context. So now you've got some space time you got some manifold.
And you can imagine take you can imagine looking at co dimension one, you know, slices effectively space like space like hypersurfaces in that manifold.
Which are, which are, you know, bronchial slices are co dimension one.
Oh, but crucially we're in space time right now. Right. So this is this is these are these would be fullyations of the causal graph rather than of a multi way system.
Okay.
Okay.
At least for now, they will become branch of graphs in a moment. But so, alright, so you look at these co dimension one slices. And then you want, and then effectively you want to compute a an estimate you've so you know you've got these two manifolds say they're in four dimensions these would be
three dimensional space like hypersurfaces. And then you want to you want to connect them along their boundaries you want to define some co borders them between them. Right.
Let's get the original picture. So we've got we imagine a causal graph that represents the evolution history of the universe.
And then we imagine a foliation of that causal graph that represents a essentially a space like hypersurface that has, and you're saying that that space like hypersurface is has a three manifold has a three dimensional manifold.
That is that space like hypersurface and look at three dimensions in the case of ordinary three plus one dimensional space. Right. And if you have two of those if you have an initial and final hypersurface, then you could imagine gluing the boundaries together in some way.
Right.
These are infinite. Well, okay, these are not necessarily they don't have to be infinite. No, so there's some big blob of space. Yeah, and if they are infinite then they're then you know they inherit the boundary structure of the space time they're embedded.
There's a blob of space. It's the shape of a, you know, it's some drum that's in some particular shape. Have another blob of space is a drum in another shape. Right. Now which boundaries are you going together?
Well, I mean, you're doing the entire boundary of one to the entire boundary of the other. And that's that's what the co borders and relationship is. Yeah, I understand that. Why would why do you want to do that?
Because ultimately what you want to do is computer, an S matrix for you know if the if the first thing is your initial configuration the last hypersurfaces is your final configuration and you want your S you want to define an S matrix for a process of a given shape.
Then I shape you mean you're conforming the boundaries of this. Right, right. And so, so the, so the possible shapes of field theoretic processes are given by the possible co borders of those manifolds.
So, okay, so we've got these manifolds. This is a quantum gravity story. This is not a, this is not a quantum field. So it's about this is about it's both quantum gravity and but also more on a more mundane level just topological quantum field theory, which is kind of
I mean, you describe this as a causal graph.
Whereas, I mean, doesn't it have to be a multi way graph to get to quantum stuff. Well, yes, as it will, we'll see that in a moment. Yes.
Okay, but first of all, we've got one manifold. And we've got another manifold that is from a later slice of a causal graph. Right. And you're saying co borders is this idea of being able to, you know, knit these things together so that their boundaries agree.
Right. And, and then you're asking, you're saying, there is some, what are you computing about the interior is somehow one is evolving to the other.
Right, exactly. And you want to know the amplitude associated with that evolution. Okay, but I don't know how amplitude comes into this yet.
Well, okay, so, right. So now, now if you imagine it as a quantum mechanical thing so now that these are effectively multi way causal graphs. And so you've got so you've got multiple, you know, hyperserve multiple space like hyperservices distributed in branchel space, you're
you know, connecting those boundaries. And you want to know what's the amplitude associated with that collection of evolution pods. Why are we not doing this purely in the multi way graph. So we have the multirate graph.
We have a branchel graph here from the multirate graph. We have another branchel graph here. We look at the co borders and the multi of the branchel graphs. What does that correspond to isn't that an ordinary quantum mechanical amplitude.
Yes. Yes.
Okay, and in the most open field.
Right, right, because the whole the whole thing that distinguishes QM from QFT is that you have to you also have to take the causal structure into account with a QF, you know, you have to take some spatial structure some right to genuinely believe in spatial structure.
Right, is the difference. I mean, the, okay.
Yeah, in a sense.
Somehow, you know, general relativity is the approximation you get when you ignore the multi way structure and you just look at hyper graph evolution quantum mechanics is what you get if you ignore the hyper graph structure and you just do look at the multi way evolution.
That's beautiful.
I mean, that's that's the one of the main kind of punchline to the whole physics project. Right. And QFT quantum gravity is some mix of the two. Right. QFT being the more structured case.
Right. Right. So, okay, you know, this relates to a question that was asked by one of the summer cap kids about what is the rural analog quantum computing.
See, didn't get that way. I, this is the question of in quantum computing is following the different parts of the multi way graph.
And what is the, you know, is there a way of accessing rural quantum computing, so to speak.
Yeah, I mean, I don't know. There isn't really a, at least in my mind, there isn't really a sharp distinction between an ordinary multi way system and a rural multi way system, right.
It all comes down to how you encode the parameters, you know, the original parameter space of your rules. Yes. And so, you know, you could imagine, for instance, building a quantum circuits that used, you know, you could you have two different circuit might, you know, you could have clip it plus
T gates, and you could also have, you know, you know, something that includes that's just stabilizer quantum mechanics with some different gates that are something. And then you can imagine merging those two and building some quantum circuit that combines both.
And in some encoding that's like, that's analogous to a really, yeah, of a real multi way system. So I'm not convinced there's that sharp a divide.
Well, but maybe the ultimate divide, which is not unrelated to some of the talking about is you've got a whole factory of gates, you've got all possible.
You apply all possible unitary transformations.
The question is, is that a realizable thing? That is, is there a way of, I mean, you know, we, we, we try with quantum computing people are making this big effort to kind of constrain or kind of physical processes can happen.
Maybe the statement of the rule your limits is, you allow all these physical processes to happen. It's not just these particular ones you're constraining to happen.
This is the answer that the rural, you know, the rural analog of quantum computing is just all possible physics happens, and you must pick your answer out of the all possible things that happened.
In other words, unlike, well, except that's not, that's not quite true because that's not how it works in ordinary quantum computing.
Well, but in ordinary quantum computing, you have to knit your answer.
So you have to get things to interfere in a way that, so I mean, ultimately, I think it ends up being an observer theoretic, you know, the final step ends up being an observer theoretic thing.
It's not you're selecting the answer from some God's eye picture. It's you, you know, you actually have to sculpt some reference frame that picks the answer out for you.
Right. All right, let's go back from the real limit of quantum computing, which I think will be, you know, if, if basically the basic theory of these things is first it goes branch ill, then it goes really.
And then that's the end.
So is quantum computing speed real or is it an illusion?
I'm pretty sure it's an illusion. But I mean, I'm pretty sure that the observer, you know, the knitting together of things and maybe we'll maybe even some of these talking about right now will help clarify that that the, you know, the extent to which.
And when you think about your observer observables versus Schrodinger picture, the basic idea of quantum computing has to be that in the Schrodinger type picture, you know, okay, my, a version of what you can say about quantum computing speed up is the Schrodinger picture is enough.
But the measurement doesn't matter. Whereas, there's a different picture that you could take that, you know, that's the question is that is that sufficient is the Schrodinger piece sufficient, or does the measurement, you know, does the measurement actually take effort.
And I think this duality with these observables might actually tell you something about that. What do you think.
Yes. Yeah, I mean, in effect, Paul's question is a question of branchial cosmology. Right. What you're asking is, in a sense, what is the value of Omega, but for branchial expansion rather than from for spatial expansion.
And because that that will effectively factor into the question of, can your branch it can branchial space expand rapidly enough that the forward time evolution speed up exceeds the slow down you get from having to, you know, to actually apply the observation process.
So I think this is like, okay, the claim would be quantum computing is the analog and blonde shield space of something like perpetual motion.
So, you know, the reason that there's, you know, there is in fact perpetual motion physical space, and it has the expansion of the universe.
That is you can get, you know, and it's, you know, if you have a big wire, a big, big spring connects to galaxies that are distant galaxies in the universe.
Then we'll get more and more attention in it as a result of the expansion universe.
I mean, at least if the spring isn't too big, it doesn't affect the expansion.
But that that sense in which you can, you can get energy by energy is not conserved in full cosmology.
And I don't do cosmologists have a I haven't really followed the recent stories of energy conservation and cosmology. I mean, it's it's basically there isn't a Hamiltonian formulation in which energy is truly concerned.
No, no, no.
That hasn't changed.
That hasn't changed.
Well, I mean, resolving that question is equivalent to resolving strong cosmic censorship in some form.
Explain that.
Well, because being able to write down, so we don't even know whether there exists a Hamiltonian formulation of GR that's applicable to our universe, right?
That's really what the strong cosmic censorship conjecture is.
Why, why is that what explain that in terms of the remind me what is the strong cosmic censorship versus week.
Okay, so so the strong weak cosmic censorship of both statements about effectively whether GR is a is a whether you can, whether you can pose the Einstein field equations as a well posed initial value problem.
You know, essentially as a well posed system of hyperbolic PDE is weak cosmic censorship as a kind of local version of that, which says that you can't.
You can't have, you know, see one future in extendable regions of space time that effectively correspond to naked singularities. Right.
Strong cosmic censorship is a global version of that statement that effectively says you could define, you know, that the evolution of the universe is in at least relativistically is determined by some initial cochi data defined at, you know, at the, you know, at some T equals zero point.
So let's just unpack this for a second. So you're saying, in the case of weak cosmic censorship. If we form this talk about it just in terms of black holes, we, we, you know, or space time singularities as in the curvature tensor goes to infinity type thing.
Right, right. But so, I mean, the cosmic censorship conjectures are really statements about hyperbolic analysis right so analytically what's happening is.
So what does it mean for a hyperbolic system of equations to become ill-posed? Well, it means your characteristic lines intersect, right. And in general relativity, the characteristic lines have a very direct physical interpretation, which is that they are the paths taken by time like rays, right.
They're the normal vectors to your space like hypersurfers.
They're where light goes and space time. Right. I mean, yeah. Right. And so those, your hypers, and when you think about that geometrically as those light rays being normal vectors to your space like hypersurfers, you realize they can only intersect if the space like hypersurfers is intersect.
And so in a, and that's exactly what happens in a singularity, right. So singularity is a place where characteristic lines converge and so the field equations become ill-posed there.
But, and the weak cosmic censorship conjecture says, okay, well that's fine because they're cloaked in this, in this, in this, you know, those singularity regions are cloaked in this event horizon, which means that although, you know, technically your theory becomes ill put, you know, there is a region where you can't see one future extend your time like curves.
It's okay because they're kind of, they're sealed off from the rest of the universe. Strong cosmic, that's really a statement about black holes in the event horizon. Strong cosmic censorship conjecture is a statement at the level of the entire universe, whether that happens at a global scale rather than just at a local scale.
Well, but so the strong version does not have a, does not have the event horizon.
A strong version doesn't really say anything about, about black holes, right. It's, it's, it's whether the singularity is whether, I mean, it's like if you have fluid dynamics, and you look at the future evolution of the nanostatic equations, do you ever get infinite velocity, infinite density regions of the nanostatic equations?
Right, right. I mean, concretely here, it's a consequence of the fact that even though it's one of those necessary but not sufficient things, right, you're, you're, if you have a singularity, it forces your characteristic lines to intersect.
But the characteristic lines can intersect without forming a singularity. And that's really the case with this, which the strong sense of conjecture is addressing.
And so effectively those conjectures, we know there are space times which they fail, but they're saying, you know, for physically reasonable space times, given by some, some energy conditions, that the, you know, these things should be true.
And so, having a well posed, hyperbolic, Hamiltonian formulation of GR is predicated in some sense on, on the, on the cosmic censorship trajectory being true.
We, like, we can't even really address the question of, of energy conservation.
If space time kind of self destructs, assessing the total energy space.
So, so, so, so then that's, that's the case of, so, you know, the issue is, in branchial space, what is the corresponding rate of expansion.
The, the claim would have to be in quantum computing, as Jonathan was saying, basically, that if the rate of branchial expansion is high enough, then you might be able to get something by basically doing the equivalent of the perpetual motion machine physical space time, but in branchial space.
Right, but the place, the thing you brought up, which is this connection to, you know, sort of vector spaces and isomorphisms versus endomorphism algebras and their isomorphism.
The, the place where those things connects to Paul's question is, you know, in what sense is it that the multi way evolution graph models, you know, linear transformations models the shredding picture and what sense is it the branch of graphs model endomorphisms and they model the Heisenberg picture
Well, the reason is because ultimately it comes down to something as simple as the evolution edges in the multi way evolution picture are directed and in the branch of graph they're not.
And so when you, when you reverse everything which is the analog of a Hermitian adjoint that's the analog of taking your conjugate transpose in the multi way evolution graph time goes backwards so that's like unitary evolution.
In the branchial graph, it remains the same. So that's the analog of hermeticity.
It's in that sense we can say the branch of graphs are sort of model modeling endomorphism algebras of some kind.
And so then in effect, Paul's question is, you know, you've got this apparent speed up that comes from the fact that you can do many, you know, in the same amount of time you can do many, many more linear transformations because your branchial graph is expanding.
You're going to have to apply those, those, you know, you're going to have to apply those endomorphisms you're going to have to perform those observations that collapse anytime you've got a pair of states connected by a branchial edge, you've got to collapse those back to one state eventually.
And it's not clear a priori because it depends on the structure of the multi way system, whether the slow down from having to do those observations of collapsing things along branchial edges is going to outweigh the speed up you've got from being able to do the things in parallel in the first place and that's ultimately the question of whether whether, you know, true quantum speed up as possible.
In these terms, we should be able to figure this out. I mean that is what characteristics. I'm looking at your because he's thought about multi graphs in this kind of way. The question is, what, under what circumstances does the number of parallel threads outweigh because the, you know, because what you're
asking is, how many, you know, can you have a bunch of parallel threads in the multirate graph that do not require so much knitting in the branchial graph to get them all back together.
You might think, every time you have a parallel, every time you have a branch in the multirate graph, that's going to lead to one piece of knitting in the in the branchial graph.
So every time, every time you have a pair of a parallel edges, that is one piece of knitting you have to do.
So the question is, when, you know, is it the case that what you have is just a whole cascade of loose ends, which you then have to knit together, and where the number of the amount of knitting you have to do is simply proportional to the number of loose ends.
If the amount of knitting is proportional to the number of loose ends, then quantum computing is toast.
Yeah, because, because that that necessarily will just be the same, the same work, you have to do the same work to knit the things together, as you would have had to do to just follow each part separately.
So can I rephrase that as whether, as the question being, whether it is physical to have rules that collapse a large number of parallel threats and introduce a bunch of branches in one single step.
I think some rules exist, right, the question is, if they are physical, or if they have physical interpretation, is that the correct reason?
I'd say that it's more like, does the, is the number of rules that you'd need to introduce in order to collapse things down to a single state comparable to the number of evolution edges that you've gained by doing this, by doing the computation in parallel in the first place.
But this question about the number of new rules you have to introduce, this is an observer theory story.
Right, right, exactly.
That's a question of whether the observer has, I mean, you know, we don't yet know how to think about a good metamodal observers.
I don't yet know that.
And, you know, and so the question is, is there a, you know, in that metamodel, could you get a boatload of, I don't know.
It seems like as soon as you physicalize the observer, you'll never be able to win, because those rules, if you have to enumerate all these separate rules, those all have to be sort of my intuition is those have to be separately physicalized.
My guess is, but in the end, it's just going to be exactly the same.
But it's just going to be that you can do this quantum computing, and it's the, you know, one of them is thinking about, in fact, it's exactly the description that Jonathan is giving of this foliation versus vibration story, because one of them is going to be,
you know, the classical evolution is just you follow a single fiber.
The actual evolution is you're going foliation to foliate, you know, foliation slice to foliation slice. And in the end, you know, a foliation slice doesn't give you an answer. You have to compress the foliation slice.
And the story will be, this is going to take you exactly the same effort to do the measurement, as it's going to take you to do the original, original classical computation.
Right, my guess.
Right.
And so it's a reformulation. So in a sense, from that point of view, quantum mechanics is a mere reformulation of classical, you know, at the computational level, quantum computing is a mere reformulation of classical computation.
That will be the, that will be the basic statement.
Right.
It's another one of those palisette constructions, right, in a sense, which the, I mean, so, you know, class classical simulation of quantum computation is, you know, essentially what there's something like this, right.
It's the, it's the, you know, do it, evolving the branchial graphs directly rather than evolving the whole multi-basis.
Yeah, right. So, okay, we'll start through on factorial versus algebraic.
I was also going to, sorry, things that were, were now, whatever, several tangents deep. I did, on the, on the metamodelling of observers thing.
So I know we've previously discussed Robin Gandhi's PhD thesis and how it kind of missed the point of a lot of, it was.
Robin Gandhi's PhD thesis, because I was trying to figure out what Robin's, Robin Gandhi's handwriting looked like.
Right.
Because I had this random sheet of paper. Okay, this is a, this isn't a relevant story, but I wrote about this in some posts that I wrote, but a, a former high school teacher of mine was a friend of Alan Turing's.
And somehow when Alan, when Alan Turing died, this former high school teacher of mine got a bunch of books from Alan Turing.
When my former high school teacher died, he gave those books to, well, various places, but including one was to another former high school teacher of mine with the instructions, give this book to sort of,
I may have been basically to give this book to me, but it was, give this book to me.
Okay, so eventually I get this book, which is this, actually, a copy of Dirac's quantum mechanics in German. Okay, just slightly obscure because after all Turing was English but anyway he had Dirac's quantum mechanics in German.
So I'm literally sitting there, this person just handed me this book.
You know, it's an interesting old book I should just flip through the pages. So I flipped through the pages and what should happen but a piece of paper flutters out.
And a piece of paper had on it, a bunch of combinators meets landed calculus, which is pretty weird for a book about quantum mechanics.
And so then I went and saw a hunt of, you know, who wrote this piece of paper, and that was an adventure and was it Alan Turing's handwriting, was it whose handwriting was it.
And I consulted with this person I know who's a forensic handwriting specialist and all sorts of other things who said, who, and she immediately said it's not Alan Turing's handwriting, and gave a whole bunch of personality analysis of why couldn't
that's a set of a different story. But anyway, the end result was eventually this was tracked down to, oh my gosh, what's his name.
Oh my gosh, the executor of Gandhi's will. So basically, the Gandhi was the executive Turing's will.
And this person in Wales was the executive of Robin Gandhi's will. Anyway, we tracked all these various people down. And in the end bottom line was the piece of paper and book was written by Robin Gandhi, who had somehow had this book for some
reason. Therefore, that is a very, very shaggy story. But that's why I looked at Bob and Candy's PhD thesis was because it had handwritten stuff for Bob and Gandhi.
That was sort of definitively his. And it's why I spent two afternoons grubbing around the archive center of Kings College, Cambridge, taking photographs of Richard Bevan Braithwaite's collected correspondence.
Right. Okay, so, so.
And interviewing people at HEPA's, as I recall.
Oh yeah, that was another way. There was also a bookmark in this book. And the bookmark came in HEPA's, which is a bookstore in Cambridge, and the bookmark question was how old was the bookmark.
The bookmark had a phone number on it. And it was a phone number that, you know, British phone numbers gradually got longer over time, as, as these things do when, you know, when commentarily you need that.
And so this was a particular like the phone number turned out that bookmark have been used for like 4050 years or something. They've been using the same bookmark, which kind of might tell you something about British prisoners of that time for something like this.
We also tracked down Champanel, who was another candidate. Champanel was a, was a friend of, I was a friend of Turing's, famous for the Champanel number, which is the number zero, 0.12345678910111213.
It's a number that has a property that's a normal number. Anyway, Champanel was also involved in chess machines and things, but later became a well known conquest, turns out.
And anyway, so we tracked down some handwriting samples. I don't know whether you're involved in that part, the handwriting samples of Champanel.
Because I've now had multiple pieces of email from people asking me things about Champanel and handwriting samples. So, who knows, it's, it's someone gets tangled up in these historical stories.
They're, they lead to things like people saying, you know, I am the granddaughter of famous scientist X. And in our attic, we have many boxes of interesting notes from, you know, the grandfather or the great grandfather, and I have a great urge to go look at these boxes in many cases, but it takes a bunch of time.
Sorry, that was, it was, it was the only, like, on the ground detective story I've ever been directly involved in.
Right. It's not as dramatic, probably, as the Champanel story, which we digress.
Sorry, the point I was going to make was that, so one of, so most of Gandhi's PhD thesis is pretty boring, but the, the, the second half of it actually has a bunch, has a couple of interesting ideas.
And one of the interesting ideas was that he was, I mean, he didn't quite, he didn't formulate it in these terms, but my reading of what he was trying to do, which is quite interesting.
It was, he was essentially trying to construct a formal model and analogous to a Turing machine that would take in effectively data and output scientific hypotheses.
And so he was trying to construct, I mean, he was trying to do it in the language of type theory, which I think was completely sort of inappropriate as a choice of mathematical formalism, but he was really trying to construct what I would now characterize as being a
model of the observer. And the interesting thing is, because of this known connection between sort of type theory and categorical semantics, I have a suspicion that the meta model of the observer that at least I've been implicitly using, in terms of branchial
completion, has a formulation in terms of Gandhi's original formalism.
So, what would you output? So, okay, if the output is, you know, it's just like people say, you know, mathematicians and machines for turning coffee in the theorems or something.
This is a machine for turning scientific data into hypotheses about into scientific laws, right, which is, I mean, kind of that's the story of statistics that's the story of the scientific of science in general, is turning of experimental science, natural
science, I shouldn't say natural science, natural science.
Well, it's also the story of, I mean, more abstractly, it's the story of cryptanalysis, right, you're given the output, you're just given the output or partial output of some computational system, you're asking what rules generated it.
Yes. I mean, so, okay, but so you're saying, in that picture, you're saying that did Gandhi make progress on having some, so, no, we've parametrized, so we're saying the system, since we can now represent
everything in terms of computation, the thing, the output is just a program.
Right. I see. So the basic point is, it's a code versus data story. And normally the code makes the data, but this is the case where the data is making code.
Right. Right.
Okay, that's interesting. So that's basically the theory of, so that's a core way to think about observer theory, is that whereas a turning machine turns code into data, basically, an observer has to turn data into code.
Interesting idea. Right. Okay. And it's one of the reasons why, in a sense, things like combinators are interesting because they, you know, they don't have that distinction.
Yeah, the code versus data.
Right. Right. Well, not as well as language.
That's true. That's true. There's a, there's a, based on, there's a programming language theory for that, a theory term for that, isn't it? It's like unimodular or something. It's not unimodular, but
No, it's not one of the meta circles.
Okay.
Okay, I forget the term.
What you're saying is, given data emit, you know, what's the formulation in terms of combinators? You would say, given, what is the representation? See, the problem is, it's not obvious what the model actually does.
And maybe that's related to your kind of models idea and what, how you knit things together branch away.
Right. Right. But I mean, for instance, one concretization of that is you're given the causal semantics for a combinator evaluation. Can you reconstruct what the combinator was?
Well, okay, here's a, here's a simpler version of that. You're given, you're given a collection of combinator expressions. Can you generate a single combinator expression on whose mounted multi-way graph, those combinator expressions
occur? Right. Which is to say that you've got essentially a branch, but you can think of that as a branch of graph of combinator expressions. And you're asking, is there a, you know, is there a generator that produces that
branch of graph, which you could also think of in terms of your branch of the branch of evolution, is there a branch of graph that generates that branch of graph? Or you could say, is there a, you know, is there an underlying sort of
providential picture, you know, multi-way generator that, you know, multi-way thing that generates that. Right. Okay, that's interesting. So, so back.
Yeah, I'm sorry. Rob and Gandhi tangent, probably not, not necessary.
No, that was very interesting. I mean, the, you know, code to data, data to code, that's really quite an interesting way to think about.
And I think this model of, you know, can you make a combinator, which has a specified set of combinators as it's multi, as it's branch shield.
I mean, see, that's, that's a very interesting thing for another reason, which is we've been interested in what does it mean to do multi computational universality.
And so this is an interpretation of that, which is to say, you know, find a computation where on the branch of graph, you have certain kinds of things generate. That's very different from the question of, you know, if you're doing an NP computation,
right, that that's, there's probably a term for that. Maybe there is, maybe there isn't a computational complexity theory. Normally an NP computation is like there are many possible branches.
And the question is, is there a winner? Is there a single branch that's the winner? So this is the question of, is there a, of all the branches, do you get a certain set, if you look across all the branches?
Is there a name for that in computational complexity theory? Anybody know? I mean, it's, it's the one that I'm aware of.
I mean, because that's, that's, I think a different concept.
Although, although again, I mean, in relation to the, in terms of the relationship to multi computational universality, I again have to stress that I have concerns about the syntax semantics distinction, right?
Because, you know, you're making a statement about what, you know, for instance, what specific combinator expressions were produced on a given branch like hyperservice.
But that's not, that's not the important thing from university, from a universality point of view, right? It's not, it's not important, you know, saying that a system is universal is not equivalent to saying that it generates all, you know, combinator expressions of a particular kind or something.
Right, right, right. Exactly. What, what universality is, is more of, you have to have an encoding of what the combinator expressions mean. And then, you know, it has to be, you know, the, the, that, the combinator evaluation has to be a subject, has to be subjective onto that encoding, but not
subjective onto the actual syntax.
Let me give you an outrageous version of this.
Question is, can you on the branch shell graph reconstruct the time history of an arbitrary chart machine?
Right.
Right.
That's a version, that's a definition of multi multi computational universality, right? Bizarre idea. So that's turning a time series into a branch shell series.
Right. So that's saying, you know, normally, and if you go long enough, can you reproduce an arbitrary long time history of the Turing machine in the branch shell direction.
So what is that like, that's like in, I mean, in the ADS CFT world of that correspondence, what is that like, that's like saying, I mean, that is in fact that's reconstructing light rays from, from, you know, spatial structure or something.
Yeah, something like that. Right. But that, that's a good, that's a good case. I mean, of looking at, you know, can you, that's the thing I could actually do experiments on is, is there a branch shell correspondence for that term.
You know, branch shell history reconstruction. Right.
Are we, are we, are we now ready to.
Yeah, I forget what we were saying. Yes. All right. That's I was, I was on the first line of explaining what an FQFT it's right. So, you know, you've got this co borders in between these space like hypersurfaces.
And then the point is, you know, when you when you go multi way, so to speak, now you associate to the two initial, you know, co dimension one surfaces you now got some space of states right you've got some vector space that's the space of quantum states.
And then in the multi way system that's going to be some, some branch, you know, some collection of state vertices in some branch of graph.
And then your, your co borders and the connects them is some linear transformation, right, and that's the thing that's encoded by your S matrix at the S matrix is concretely the linear transformation that takes you from one vector space to the other.
But, and that's effectively what FQFT is all about. So in functorial quantum field theory, you know, the, the, the core ideas go back to the TSE Galaxians, the, the, the so called sewing laws that effectively encode the locality of time evolution in terms of functoriality.
Wait, wait, wait, wait.
Ordering quantum field theory has a time evolution, given by the path integral.
Right.
That is, just like what you're saying, it maps one quantum state to another quantum state.
Right.
And those quantum states can be thought of as corresponding to branch of graphs.
Right.
And so,
With the path integral just does that.
So, in trying to come up in trying to nail down a mathematically precise version of what, what the path integral is, Michael of tier made an initial proposition, which was then slightly refined by Graham Segal for the case of topological field theories.
But the idea was, you know, one principle that your path integral absolutely satisfies locality of time evolution. In other words, if you've got, if you've got, you know, if you've got a co borders and Sigma, and you, you know, you take the path integral for that co borders them.
The co borders them can be can be decomposed into a into a disjoint union of Sigma one and Sigma two. It should then the path integral for Sigma should be equal to the sum of the path integral for Sigma one and Sigma two.
Some.
Not product.
Well, I mean, I'm using some in that I mean, it would be a direct some or a semi direct product or whatever, depending on depending on exactly how I'll prioritize.
And they lead into parts of Sigma two. And each one has a has a.
I see if you're doing it in terms of the actual amplitudes in quantum field.
Right.
But in terms of I said in terms of the parts of some of parts. Right. Right. Okay. By the way, just for my historical information, that must have post dated my interaction with Michael of tier my paying attention to one.
Well, the the tier sequel paper, the one I'm aware of the one by Segal at least is from 1986, I think where he formalizes the sewing axioms.
That's that's that's post post your high energy phase.
Okay.
Okay, so what these axioms then have this have certain properties for these two borders.
Right. Well, I mean, so the really beautiful thing and the reason why, you know, Tqft got so deeply connected to category theory was this realization that well what the sewing axioms really say is equivalent to the statement of functoriality right functoriality is the statement that, you know, if you if you that
your functor you're mapping between categories respects composition. So f of, you know, if f big f is your functor and you've got morphisms a and b f of a compose b is f of a compose f of b.
Well, now if your if your time evolution is a functor, then the then functoriality is precisely the statement of locality.
Let's go through this. I think I understand.
The, so, you know, in a standard category setup, one of the key aspects of category theories is compositionality idea that if you can go if you have a mapping, you know, a and a morphism a and a morphism b, then you also have a morphism a compose b.
Right. Yeah, so as long as they share, you know, domain and co domain in the obvious way.
Right. Okay, then the idea of a functor is you've got this series of mappings that are these morphisms and a functor says you might have parallel sort of in two different categories you have parallel, you know, chains of morphisms, and the functor takes you from one category to
another. And this statement is that the structure of the morphisms in one category are preserved by the functor, you know, in the structure of the morphisms in the other category.
Right. Right. Exactly. So now, so now let's, let's, let's understand what that means in terms of, of these, of the statement that the full code board is a path into little sigma is decomposable into sigma one and
sigma one and sigma two, you can think of as morphisms.
No, those are fun. No, so, okay, so, so what's really going on is, okay, you've got two categories here, right, there's the, there's the category of manifolds and their co borders.
Right. So, so effectively, the objects and manifolds, the, the morphisms are co borders between those manifolds, and there's also a tensor product, there's also a minoidal structure, which is just disjoint unions of manifolds and co borders.
And so you've got this one symmetric minoidal category of, which is called board of just, you know, n dimensional co borders and you've got some other symmetric minoidal categories some other category equipped with the tensor product structure which is the category of vector spaces.
Right. So, so the object is a vector space or some Hilbert space in the finite dimensional case.
And yeah, each morphism is some of the near transformation and there's also a tensor product which is just the usual tensor product of Hilbert spaces.
And then, so, in a sense, abstractly, what the quantum field theory is is a functor that takes you from one to the other, right, it's the thing that that takes the specification in terms of space time of your of your process shape and maps it to an S matrix.
That's what that function is encoding the passage from from one to the other.
So you're saying the S matrix is this mapping this linear algebra type thing, mapping from this vector space to another vector space.
Right. And, and so.
But then you also on the other side you've got this picture of hyper you know manifolds and co borders and so in a sense you, you know, what do you want from a quantum field theory well somehow what you want to some machine that you give me a parent you give me an incoming space like
a surface an outgoing space like hypersurface some some process that connects them. And I want to be able to crank some handle and get out an S matrix, and that's what that function is doing.
So it's there's some symmetric monoidal functor from this category of co borders and so this category of vector space.
So another thing to say, in a sense of quantum field theory in quantum mechanics psi, you know the wave function gives you, you know, you give it an X and psi of X returns an amplitude.
Right. And that's that's what it's that's its role, a field operator, given given a given field operator tells you for how to think about this.
It tells you the whole occupation, a whole stack of occupation numbers for any given point.
What is the field operator. What's the, because this is this is what you're talking about is your, your vector space thing.
The instantaneous moments inside the operation of the S metrics are a series of states of the field operator. Right. But what is that what is that what is how do we think about field operator was the question so long time as I thought about this, the field
operator takes, I mean the whole point of quantum field and quantum mechanics, you just have one and this is the amplitude in an electron. What is the amplitude that the electron is this position of that position in quantum field theory.
It's a stack of things in the Fox space, where you're saying there can be one electron two electrons three electrons, etc. And at each point in space, the field operator tells you what the, what the essentially amplitudes of every possible
particle at that point are. So, so this is some, so this now is asking you, so that's the microscopic version of the, of the S matrix at the moment in time.
So, how does that, how does that. Well, I mean, it's, it's important to know so far everything I've said is just quantum mechanical will make it feel theoretic in a moment, right.
So, so that yeah this this locality of time of you know the the locality of time evolution that you want from your path integral is now just a statement that this functor is a functor right that if you that when you when you take disjoint unions of manifolds and
you can map to essentially just matrix products in the, you know, in the category of vector spaces and linearize.
Functorial correspondence between yes, the sort of the partial, a little piece of co borders and evolution, so to speak, right, a little piece of vector space evolution, right, and so you can split it you can split them up, however you know as much as
that's what the locality is saying that you could say, you know, the steps in this co borders evolution, one step and then multiplied by another step, and that's like two pieces of an s matrix, the initial s matrix the final s one and s two, and then you just take a matrix product.
Exactly.
Right, right, but the important point here though is that we've all we've in doing in constructing that we've already assumed effectively a default time slicing right we've assumed some we've assumed a gauge choice and how we've broken up the co borders and you know between these
Yeah, whereas we don't even know how that works because that because in the S matrices that we thought that in terms of Feynman diagrams, we'd be having a bunch of political lines, and then we'd be deciding in this in fact it's kind of amusing that the Feynman diagrams itself graph, and you could imagine essentially
Well, you know, not not seem like too much of like a category salesman but that that's not that's actually not so much of a coincidence when you appreciate the compositional structure of what's happening, a Feynman diagram is a string diagram for the for the symmetric
matrices and their isomorphisms, right, which kind of makes sense when you think about it right right right.
Okay, but yeah so so, and obviously we don't know how to do this in general because in a sense if we knew how to do this in general we'd have solved quantum gravity.
But we know that you know in order to get quantum field theory you at least have to consider some you have to mod out by gauge choices in some sense right.
So, you know, in a sense quantum mechanics is like the one category case where you've already assigned, you predestined your time slicing, but then you could imagine having high amorphisms you could imagine having.
If you imagine several different possible time slicing cobaltism category, and then gauge transformations being high amorphisms between them, then you get some some n category of cobaltism and some n category of vector spaces.
And, and then and that's so so in a sense, this is, this is one of the reasons why I think this is such a mathematically beautiful formulation, because in a sense quantum mechanics is the one category case quantum field theory is the n category case, and then the hope would be that quantum
gravity is some infinity category case.
Right.
Right, let's go through that play. So you're basically saying quantum mechanics has this has a specific time evolution independent of spatial gauge choices.
And what you're saying is, although, although I claim there is another kind of gauge choice, which is this branch or gauge choice, which will come to the map, maybe.
Right. Well, precisely, but, but that functor, the functor between those two higher categories is the thing that maps you from a space, you know, from a space time gauge choice to a branch or gauge choice.
I see. That's your plan. Okay. All right. So that's my plan.
Okay, so let's let's do that. So what you're saying is, in the, I said it's kind of nice.
So, so on the one side we have a bunch of these co-border zones between these different layers in this causal graph type thing.
And then, then we've got, and we've got either one seek one variation, which means one co-dimension one sequence of these space like hypersurfaces that corresponds to a particular evolution.
And that's, that's, that sounds classical, but it's actually a quantum, a particular quantum evolution.
Right. Right. Okay. So another possibility is that we pick different choices for those for that foliage, you can pick an infinite number of different choices that fallation, the mapping between
those variations is a, is, is a, is a gauge choice mapping. And that's, you know, that's, that's making gauge changes. And those correspond to a different kind of more, a different, I guess, what is that?
That's, that's again, that's a, that's an, is that another function or is that just, no.
No, that's a higher morphism.
Okay. It's a higher morphism. So it's a morphism between morphisms.
Yeah. So in the multi-way picture, right? You could imagine, you've got some multi-way system, each path is a different gauge choice. But you could also imagine, you know, rather than just like, sort of somehow imposing from the outside that, you know, you pop from this path to the other to make a gauge choice,
you could imagine having an explicit rule that lets you map from one path to another. And those are, those are effectively higher morphisms.
So in mathematics, those are proof to proof transformations.
Right. Right.
Which is something that you were working on, but I think more work needs to be done.
Yeah, no, absolutely. But I mean, so for the case of multi-way systems, the work that, well, particularly Xerxes has done, but also myself and Hatem have kind of helped out a little bit with is, you know, essentially looking at that quite, how do you define higher morphisms, higher
morphisms and so on in kind of arbitrary, in arbitrary multi-way systems. And so in the, yeah, in the field theory case, those higher morphisms have a pretty tangible interpretation as essentially gauge choices.
Right.
Right. So just, just gauge transformation.
Sorry.
I mean, you know, proof to proof transformations as things like you have one proof, can you find a simple proof? Can you, can you simplify that proof? That's, that's a, which is a concept of sort of higher level symbolic map, you know, symbolic computation concept, rather than just,
can you simplify this algebraic answer? Can you simplify the proof that led to this algebraic answer? Anyway, so okay, so we've got, on the one hand, we've got these, these higher morphisms, and you say that we are mapping those higher morphisms to higher morphisms on the S-matrix side,
which correspond to different cuts in, in the, oh boy, this is the, you know, there used to be these things, this is fine, but there's the sense called these Kutkowski, Kutkowski, Kutkowski rules, I think.
Okay.
Which are in fact probably the same as cuts in the, in, in, in, in proof theory, which is just really ironic. You know, one of them is just named after a person.
Okay, so the idea is you've got a finding diagram that represents all of these different possible, and when you, you can say, I've got the beginning of my S-matrix is one part of the finding diagram, I've got the end of the S-matrix is another part of the finding diagram, and I can make an arbitrary slice between those two.
I've got a bunch of loose electrons and photons and things going through, and I can decide to make that cut after the, you know, after the electron and positron annihilate or before, and those are different possible choices of essentially sort of, what the heck are those called?
So in finding diagrams, those are the, that, that kind of factoring, boy, that was studied in QCD back in the day.
Yeah, okay, that is, it's clear what that means. You have a finding diagram, and you can slice it at some point. And then, you know, as you knit those things together, you have a bunch of complicated integrals to actually evaluate the finding diagram.
Right.
And then you can, you can conceptually sort of slice it in that way. Okay, so, so what, so now what happens?
Right, I mean, yeah, and so as I say, if you, if you restrict only effectively to the gauge choices that correspond to Lorentz boosts, then you get some end cat, you get some restricted kind of end category, and that models quantum field theory, at least that would be the claim.
Yeah, okay. If you're saying, you're saying on the, on the, if you restrict the gauge choices that you're making on the co-borderism thing, to only what Lorentz transformations you're saying?
Well, or Poincar transformation, yeah.
All right, as opposed to general autistic general different morphosomes.
Right, exactly, exactly. So, so effectively, you, yeah, you've got one class of high morphosomes that's just modding out by the Poincar group or some connected component to the Poincar group.
And you've got another that's modding out by the full conformal group or the full different morphosome group of space time. So QFT corresponds to the former case, which is a restriction of the latter, and the claim would be that full quantum gravity would correspond to the latter case.
And the case where you just described, where you just have Lorentz transformations, you're saying you just sold me this thing about Feynman diagrams or I sold myself about Feynman diagrams.
And that, but in that case, the slicing of Feynman diagrams, in the case of general different morphosome, what, oh, I see.
It's just, you can stretch it topologically, any topological transformation of the Feynman diagram is permitted, whereas, you know, the ordinary transformation is you can just, you were only allowed to affect.
Because I think the particle states change. In other words, the, I mean, what happens when you go into, into, you know, non trivial space time is this notion of particle states which was just a, you know, the electron with the electron propagator, the electron propagator changes, because you're redefining, you know, you're redefining the
particle states, you're redefining, you know, even in a boosted, even in an accelerated frame, you're redefining the particle states.
Right.
So how does that, I mean, and you know, there isn't really a good generalization I'm aware of, of, I mean, you can, you can do, I mean, like the original Hawking fact is associated with doing Feynman diagrams, basically, very simple Feynman diagrams, where the propagators are in a curved space time.
Right, right. But, but the, yeah, I mean, QFT in curves based on this pretty well solved, except for the back reaction. Right.
Which is otherwise known as the effect of gravity.
Yeah.
Which is always known as the main story of gravity.
Right. Of course, I mean, this, yeah.
Right. But so, so what you're saying is, I see. So, so maybe the point is that you're saying that there also have to be gravity on lines in Feynman diagrams.
And then the traditional stuff all goes to help because, because I mean the back reaction in a Feynman diagram back reaction has to be represented by the effects of gravity on other particles which is otherwise known as gravity.
You know, right.
Gravity on lines.
Okay, but so.
All right, so we've understood a little bit about the correspondence. You were going to make some other point about this correspondence between between.
I mean, this, actually, I have a question about, about the correspondence to quantum field to ordinary quantum field from this, from this multivariate graph.
One important question, one important practical question is, can we find a better way to do numerical quantum field theory, because numerical quantum field theory, the only way that's known right now is last gauge theory.
That is gauge there requires this rotation space, this big mess.
Right. And so the question is, will this correspondence between the multivariate graph on the one hand, and final diagrams as matrices on the other hand.
I don't think that one could use that to use the pure multivariate graph as a way to do, you know, computations.
Do we know if that works.
I don't think we know if that works. I mean, one way that you could do, okay, certainly one way you could do relativistic quantum mechanics, which takes you most of the way there would be so if you've got a multiway evolution graph right that that's the kind of model of a
one category. If you then add in the causal edges, so you get a multiway causal graph, evolution causal graph, I should say, that's effectively a weak form of two category.
And in a sense of relativistic, so, you know, whereas we know how to pretty much know how to do ordinary quantum mechanics over, you know, over sort of over the one category over the multiway system.
If we could do an analogous thing for that week to category for multiway evolution causal graphs that would be that presumably correspond to relativistic quantum mechanics.
How would we see that so I mean let's say, how would we get like the direct equation out of that. I mean, how would we see the difference between getting the Schrodinger equation and getting the direct equation.
So we know, okay, as we discussed the other day, there's a there's a sort of standard way you can get something like the kind Gordon equation in a causal graph, right, or in a multiway causal graph.
What you were saying by putting weights on the causal graph.
Yes, but also I mean, that's one way you can get it. You can also.
Yeah, that's essentially that's one of the approaches that's developed and see in causal set theory right because you define it you take it.
You define a delambate operator by essentially equipping the causal set with a bunch of, you know, every element is associated with some scale of value and then you just sum over causal layers.
But you can also think of the causal graph is intrinsically defining a differential operator.
Okay, so just for legal benefit. And so the issue is, you know, normally a causal graph is just a thing with no, but you can always put values on those nodes, and then the thing becomes more like a partial differential, you know, more like a, we should call it a finite graph as opposed to finite
elements, the finite graph approximation to a partial differential equation.
So, in that finite graph approximation.
One would eventually, the point Jonathan is making is that there's a limit that in which that finite graph approximation limits to a kind of equation to the massive massive for massless mass.
I believe the massless is the I may be wrong on this I believe the massless case is the only one where it's known.
So there is an ansatz for the massive form I don't know if that's been proven to be correct.
Okay, I mean, in a sense, this is going to be obvious because this is essentially a form of wave equation.
Right, right, which is works on the causal graph because the characteristic lines of the wave equation are just this crisscross thing I think.
Right, right. Anyway, so what one would expect I assume is if you did the associated thing on the multi way evolution causal costs and now you've got two classes of edges you've got causal and evolution.
There's some mixture of the Schrodinger operator and the kind Gordon operator would give you a Dirac operator on this structure.
Of course with the rack operator we need to spend a half which we don't understand.
But that might be some square root of some I mean that would be very nice. In fact, that's a good point that just as if it is true.
The kind Gordon operator comes by having these sort of crisscross in these diamonds. Yes, in the multi regard right then then commutation of your field operators that gives you spin zero for instance is essentially merging of branch pairs and
right, which is the square root of that, right, would naturally be a single branch, right, which is what we guessed.
Yeah, just curious.
So that would be so that that's actually worth working out. Yeah, whether that because that that would mean that in a very literal sense, the rack, you know, fermions and square because they are the things that come from single branches and in the multi work off.
Right.
Okay, so how many more things can we solve.
That's a good piece. So, so okay, but let's see you were, you were, I think you will still have to explain this functorial one of your theory, which would explain this being this notion of this co borders.
Right, right, and then you were going to explain maybe also a break.
Right, so the point is that in addition to associating a space of states, you could also to each hypersurface you could also associate an endomorphism algebra, right, you can also associate some algebra of observables.
Right, and that's not so obvious.
I mean that is, that is, you've got this. So, the algebra is sort of yacking before that correlation functions. I don't really understand given a graph.
I mean, the, the algebra, I don't see this, because I mean that the entry evolution, I clearly understand it's just you go, you follow the edges you go from this to this.
Right, right.
The case of observables is the algebra of observables.
Is it something as simple as you're looking at the relationship of edges in the branch of golf or something.
Right, well, exactly. I mean, so, okay.
Exactly correlation.
Right, right.
Right, and the reason they correspond to endomorphisms is because they're the things along which you can complete. Right. So if you want to perform observations, those are the observations you are able to perform.
I think that's right. But notably, the point is, and I was wondering about this. I mean, there's this statistical mechanics of cluster expansions of things.
I wonder, I wonder this because I wonder this in connection with Matt's project about from whenever it was 2020. Yeah, right.
About hard sphere gases, because I wondered whether there was a, a, what the interpretation the branch of golf, and I guess that the interpretation the branch of golf is one of these cluster expansions.
That's sounding more convincing. Okay, so anyway, so what you're saying is the branch of golf represent maybe branch of golf represents the collection of correlation functions is essentially an encoding just like it's an entangled map.
It's also a correlation function.
Right.
And, okay, so then, then.
Yeah, because in effect, each state is, is some eigenstates, right, and then, and then every branch of which one way you can think about it is it's one possible projection you can perform of an eigenstate onto another.
Yeah, which is otherwise known as essentially correlation.
Right. No, I'm, I'm, I'm agreeing.
That's nice.
All right, so anyway, so, so we've now ended morphism.
Endomorphism collection of endomorphisms between operators.
Right.
Okay. So, which is otherwise known as a branch of golf, branch of golf.
Right. Right. And so, so the, you know, the original white man axioms for axiomatic quantum field theory and the more modern kind of hard.
I think more modern, not particularly modern, but the, the, the, the slightly more refined version of the hard Kessler axioms for algebraic.
We're effectively describing the same field theory, but at the level of the endomorphism algebras and their isomorphisms, rather than the level of the vector spaces of states and their linear transformations.
And so the statement of these two pictures are dual that Schrodinger and Heisenberg are dual is stating that effectively the multiway evolution graph and the sequence of branch of graphs are encoding the same multiway evolution.
Right.
And that one can be reconstructed from the other.
Right, right.
And in a QFT, just a modern question, does the ace time axiomatic algebraic because both are axiomatic, right.
Both fqft and aqft are axiomatic field theory. So just two perspectives on it.
But the hard axioms were not stated in terms of observables.
No, stated in terms of asymptotic states and field operators.
The hard Kessler formulation is a modern refinement, although, as we discussed the other day, there is a, there is a pretty direct way of obtaining the statements about asymptotic states from, from those acts, you know, from the, from the modern formulation.
Right.
Right.
Yes.
Yes, that's true.
So, so, okay, so, so what's the conclusion is the conclusion is that there's this nice correspondence between launch shield evolution and, and temporal evolution, basically.
Right, right. And so, I mean, one of the exciting things is that so as I say this, the reason I got interested in this was actually not so much because I was interested in field theory, although that's obviously interesting in its own right but more because this seemed to be the case of this.
What I would now reasonably think of as this functorial transformation between multiway vibrations and multiway foliations.
There's, there's a, this was the case where that functorial relationships seem to have been explored to the greatest depth, because for instance in some of the work of O's Schreiber and other people who are doing kind of higher gauge theory stuff.
There is a very concrete construction of this functor that takes you from endomorphism algebras and their isomorphisms to vector spaces and bear isomorphisms.
I mean, just, we should probably, that's, I mean, let's just zoom out from it. Okay, so we've got this categorical, this correspondence that between, I mean, this is what's interesting about this is the same stories,
it's the same thing as, you know, AF, AQFT versus FQFT, it's the same thing as Heisenberg, Schrodinger, these are just, this is just some sort of fundamental duality that exists across lots of kinds of systems.
Right.
So the, the, what else can we figure out?
And it's also the thing between multi-theorem theory.
Right, right, I think so.
And these are all equivalent dualities. So what other dualities might that be like that?
Well, I mean, this is actually something I wanted to ask you about, because in a sense, so we, I think both of us for various reasons are getting interested in this question of, you know, how can these multi-way, you know, how can the formalism of multi-computation, for instance, be applied to chemical
reaction networks, or, you know, ecological systems in biology and so on. And in those situations, I think a lot of those correspondence, I mean, presumably if multi-way systems are a good model, then those dualities should also exist, but I don't think we know their interpretation in those kinds of areas.
Right. I think the Branschel graph, I mean, the story in chemistry, for example, the story of the Branschel graph.
It's just what, what, what ambient chemicals are around at a particular moment of time, right? That's the.
Yeah, I mean, the story of causal graphs is the thing which is less clear in chemistry. I mean, chemistry, people don't talk so much about causal graphs. They talk merely about what chemical, you know, they talk about chemicals making chemicals.
They talk about the causation of one reaction, having an effect on another reaction.
Right. Although, I mean, again, as I, as I think I mentioned the other day, it's like, so like in a very minimal case of this, you could just say, so, you know, imagine you have a multi-way system that is just encoding stoichiometry, right? So you just know populations of certain chemical species, but you don't know anything.
There's, there's no other kind of reactivity rules encoded, and they're just interacting in ways that sort of algebraically permitted.
Well, if you start from the assumption that everything's a kind of uniform pressure and temperature and so on, then in a sense the causal structure of that stoichiometric multi-way system is telling you about the energies of particular chemical species, right?
How many previous times are these things interacting? How many times is this thing bounced off that thing? How many times are these things interacted? And so then you can start to, you can start to develop a pretty minimal model of something like activation kinetics just in terms of causal structure.
That's a place where I think even in conventional chemistry, there is, there is.
Well, I mean, because of every reaction, there's a change of energy, and you're saying the causal graph is measuring the change of.
You can do energy bookkeeping using causal structure, even, you know, even in a multi-way system where there's no information about that.
It's sort of a shame, though, that in the, in the world of correspondences that the, or maybe it isn't, maybe, maybe, gosh, that would be terrible.
That the density of causal edges, which in physics corresponds to energy density, is also energy density in chemistry.
Right, but at a completely different scale.
Yeah, completely different scale. It sounds like in this interpretation that is what's being said.
And actually, again, I'm going to necessarily be a bit more speculative because these are areas I don't really know anything about.
But so, you know, one thing I've become interested in recently is, so for instance, the, when you're looking at, when you're modeling either chemical reaction networks or biological systems as, as multi-way system, you know,
there's a very multi-way like approach that's already been adopted in kind of mathematical formalizations of these things, which is PetriNets.
And we know, as we know, PetriNets are effectively token event graph.
I would argue more precisely they are their global multi-way systems in which the token, you know, the PetriNets tokens are tokens and the, and the transition firings are event firings in some global multi-way system.
Although PetriNets have deduplicated all, I mean, a minimal ordinary PetriNets, it duplicates the tokens.
Right, right. But not in, for instance, the colored case that Paul is interested in or, I mean, there are other, there are things like whole-grain PetriNets and SigmaNets and so on, which have slightly more sophisticated semantics.
What is, I wondered for years what a second net is.
I'm not sure I can reasonably explain it.
I was totally wondering if it's eventually, eventually it might show up.
Or at least not in a reasonable timeframe.
But no, I mean, they're effectively like PetriNets, but with a different deduplication semantics and a different execution semantics.
That's the basic idea.
But the point I was making was, okay, so in, in kind of very, if you take something like either chemical reactions or ecology, you know, ecology, it's pretty standard in very minimal mathematical models to use essentially a kind of mass activation law, right?
You know, that's effectively what things like the logical Volterra equations do. That's what the, you know, that's what, that's what the exponential growth model does, et cetera.
But we know that that's a bad model for things like macromolecules and chemistry and for things like enzymes.
We also know it's a bad model for population species because, for instance, in predator prey models, you get predator satiation and that kind of stuff.
And so.
You're saying, I mean, PetriNets were originally invented by, you know, Carl Adam Petri, as a, he was a high school kid as a way of modeling chemical reactions.
That's the, that's some, and I'm not sure, wasn't he, was he, he was like, was he younger than that?
It was 13 or eight or some ridiculously early age.
Was he in high school by that point?
I don't know.
I think I might have been middle school.
Maybe middle school.
I don't know, depending on the German, you know, divisions between, I don't know whether they happen.
It's very, I mean, it must be strange to have the really the only thing that you're known for.
You know, he has some long distinguished academic career and the only thing he's really known for is this thing he invented when he was like 13.
I was reading, you know, he has an autobiography.
And it turns out, I had thought that, you know, and also I exchanged some letters with him actually, which were quite odd.
And so I was really kind of confused about what his whole story was.
But the fact is, the fact is that this thing he invented early, you know, he went through and as computer systems became important, he kind of applied Petri Nets to computer systems and that became the whole story.
So the chemistry application of Petri Nets kind of fell away very quickly.
Right.
But but now the chemistry applications back, because the Petri net, you know, says you have these tokens, they accumulate, so to speak, and then, and you can have a firing thing that happens an event that happens.
But it's like, you have to have, you know, I know nothing about chemistry to have two hydrogens and you know, and an oxygen or something and then you can make water.
So both of those tokens, you know, all of those tokens to have the event of making water.
Right, right.
Anyway, so the point I was making, yeah, I mean, there's a pretty standard approach to setting up that formalism and chemistry where you essentially say, you know, we've got some, we've got some set of chemical species, you've got some function that maps that's that set of species to the natural
and you're essentially like, how many of such and such a molecule is there, you construct some, some directed graph that where every vertex is labeled by, you know, by a function by what's called the chemical complex which is that function.
And then there's, you know, there's a direct way of mapping those graphs onto Petri Nets and back again. But the point I was making was so you know, ordinarily rate laws are not encoded in Petri Nets, right.
That's something you have to encode subsequently.
You have to place some kind of weighting on each edge. And similarly, I mean, that's kind of true with the multiway system, right, you can use the kind of trivial, when you, you know, when you construct a multiway semantics for these Petri Nets, you can use the kind of trivial path weighting, but you could also imagine having a multiway system where there's
a different kind of function that tells you about what the pathways should be. And that's really the same as what's going on with rate laws. The point I was making though is that so, you know, the in traditional mathematical models we've used pretty terrible rate laws, you know, things like logical
and voluntary use essentially these these mass laws that assume that, you know,
boxes that can be eaten by right, right, which is kind of which is kind of assuming that biological species act like, you know, idealized gas molecules or something with us, you know, but but what you want is, you know, for instance, there's
I should remember this name, it's like the Michaelis Merton model, there's some trivial modification you can make to the mass law that's used in that's like the most popular model of enzyme kinetics, that's like a kind of satiation version of that which can also be applied to population dynamics to model predator satiation.
Oh, no, I mean, it's just a mass activation law but with like a denominator that kind of induces a decay effectively.
Anyway, so the, the point I'm making though is that that my suspicion, which I have some technical, you know, I have some formal evidence for but it would be nice to get more is that is that in general those kinds of those different activation models effectively correspond to different functions that you can apply to the causal structure of the
associated global multiway system. So for instance, you know, statements about thermodynamic equilibrium and chemistry, I suspect effectively correspond to statements about causal cyclicity in the, you know, when you when you equip the global multiway system with some causal semantics if it becomes possible, you know,
thermo thermodynamic equilibrium is equivalent to the statement that there's, you know, the your chemical reaction kind of go in both directions with with equal, you know, with with with some kind of
Well, let's see and then go and then yes and then and then so things like the the activation kinetics that I was talking about earlier in relation to like a stoichiometric multiway system that would be again a very simple kind of use of the causal structure where you're just using causal
edges to essentially book keep information about energy, but one could imagine defining kind of arbitrarily sophisticated functions over the causal structure that would correspond to presumably different kind of activation models different energetics models.
Well, if you look in general, the plain multiway graph, I mean, it's kind of reminiscent of, you know, the sort of capacity and information theory versus Shannon information, so it's the unweighted.
It's the what can happen versus with what weighted happens right and in that traditional multiway graphs, there is no way to accept pathway right and so what you're saying is, you could in effect one okay very concretely what I'm trying to say is that you could imagine in the multiway system
of classification there being another kind of function that selects pathways based on information about the causal history of that path. Yes.
But let's think about that for a second. So I mean, the most naive thing is, you've got a node in the multiway graph, and has certain pathways coming into it.
And you could imagine one thing you could do is you could take, take the outgoing pathway to some function of the pathways, just to the pure multivariate level to getting anything about causal stuff.
Yeah. And then you could ask, you could equally well have a causal graph, you could also have this kind of waiting theory where a particular event, if it is caused by a couple of other events, has some waiting some path waiting of its outgoing edge.
So that is some function of the pathways of the incoming edges.
Right, right. And to the point I'm making with in relation to those different models of kind of rate laws and like the Michaelis Merton model is, you know, if you want to model something like predator satiation, then satiation satiation.
Sorry.
You're one of the few people I expect to be able to understand my accent. Why are we having this communication problem.
Satiation. But no, so, you know, if you just have the pure multiway structure, it's hard to encode that, whereas, you know, what you want to be able to do is say effectively, if this, you know, if this lion has eaten 20 gazelles in the last day, probably doesn't want to eat another gazelle.
And that's really a statement about causal history. And so, you know, so my kind of and my abstract statement is that these different activation models are just different functions you can apply to the causal history of parts.
Right, right. But I mean, I'm not sure that that's the I mean that saturation idea is not not sure that's the most important idea, but maybe it is.
No, but it's one example of where because in effect, if you just have a multiway system that's doing ordinary something like ordinary patronage semantics just, you know, just transition fire when they can fire.
That's just like the mass law. Right. And so, so I'm saying if you if you want to have more realistic rate laws, Mads and who's an actual chemist has a
some functions, some species.
Is it like a function that tells you to start with some kind of some kind of.
What do you mean by those?
Right. Okay, so we got we've got two different levels of stuff going on here right so it in terms just the ordinary multiway semantics or the ordinary patronage semantics. Yeah, exactly.
So you've got, I mean, it's coming, it's going back to like the statement about axioms and free structures right in the sense that the free algebraic structure of chemistry is stoichiometry right where you just things have to balance.
And so in that case every token in your global multiway system or in your petri net is labeled with some chemical species.
And then there are just simple rules that are imposed axiomatically that say that transitions can fire as long as they preserve the numbers of those chemical species, you can then define a more sophisticated function that restricts that more based on, you know, exactly as you say, as some
statement of the form, these things can come in these things can go out. But you know but this class of chemical reaction is not permitted for some other reason.
The point that I'm making is, well, you can have situations where, you know, chemical reactions are only the transitions can fire only in certain situations where those situations are not just a question of, you know, do we have the requisite tokens but for instance is do we have the right
temperature is the right is that you know do we have the right energy conditions. And my speculative claim is that in general those activation conditions can be encoded as questions, essentially queries of the causal history of those tokens.
Right. If you if you can know how many other tokens is that token interacting with how many other things is it bounced off. You know, what is its complete causal ancestry.
Then my my conjecture would be that gives you all the information you need to be able to encode kind of arbitrary activation condition.
In other words, the actual actual models will not need to know the complete history of all meals the land.
Right, right. It would be some coarse grained thing.
John.
Just to increase that point that you're saying that the sort of course range from a dynamic variables can be read off the causal history of the individual events is that the thing.
I think that's the idea. I mean, and we see that in for instance, as you say in maths projects right where you can infer essentially temperature and when you've got causal graphs generated by hard sphere gas collisions you can read off things like temperature, just from causal structure.
So if it's a general principle, which I think we think we believe it is, then, right, we have to figure out what's the number of the boosts reference frames and event horizons, and so on.
We know some of those things for chemistry.
Yeah.
We are we are talking about coarse graining in a much more abstracted.
It's a general concept. I mean, coarse graining and statistical mechanics is part of this observer theory story.
That is, you know, the molecules bounce around as the molecules bounce around, but we observe only certain aspects of what's happening with these molecules.
One of the observations back from MTS times is that the reason the second row of thermodynamics works is because the only course screenings we can do a computationally bounded course screenings, and the underlying system is generating
computationally irreducible behavior. And that's why we believe in the second row of thermodynamics.
By the way, I mean, in terms of history of statistical mechanics, the history of statistical mechanics is, you know, Boltzmann originally had this idea of entropy and all this kind of stuff, but then there's this kind of bug that you really have to be
in a course grained entropy. Otherwise, it's always entropy zero because it's a unique state. And the question is what's about course screening, you know, Gibbs in the 1920s 1930s, kind of terrified this notion of course training, but not how you would do course
training. And so I think the thing that we understood I understood in 1990s was this fact that, you know, you can think about course training as a computational process.
And when you think about that, you actually can nail down what is a course plan. Nobody have been able to do that before this idea of what is a valid course plan in the in the books of, you know, my favorite is a book about statistical physics, which proves Boltzmann's
theorem that entropy increases with time, which is based on some statistical argument like our collisions. And it says, at the end of that, at the end of the section it says, you know, proves that the HD pieces entropy increases
with time. And it says, but you can run this whole direction in reverse, which means that entropy would decrease with time. The last sentence says, this point is often puzzling to the students.
It's been puzzling to everybody. It was puzzling to everybody from Boltzmann on. I think that that's finally resolved by thinking about this computational boundaries observer story.
I mean, and by the way, the reason you can do those proofs both way round, both ways round, just from a chemist fact is that in the proof you assume that molecules are uncorrelated before they collide.
But the fact that they're uncorrelated before they collide, once they've collided necessarily they're correlated, because they just had a collision. And that's, and that's probably not unrelated to things that we have to think about for chemistry.
I mean, and, you know, some of this is not figured out. And by the way, when we talk about, you know, entropy and entanglement entropy and all these kinds of things, it's all, you know, there are all kinds of issues that come up about what what what kind of course screening
we're dealing with, what, you know, when you talk about entanglement entropy, it's like what, what is the set of things that you are constraining to say that you're talking about and then how many states are consistent with that.
I mean, so in the context of multi computation or at least in the stuff that I'm talking about in relation to global multiway systems course graining has a very precise meaning which is just that it's the state equivalence function that you use right so you know in ordinary multiway systems.
You could imagine if you're doing graph rewriting you could imagine treating every pair of graphs that where same Q returns false as being distinct.
In most cases where you want to do graph rewriting that's not particularly useful you want to merge based on a coarser criterion which is graph isomorphism, right and see your state of your state equivalence function is not same Q it's isomorphic graph Q.
And those, and so those are two rather trivial examples of kind of essentially core screening functions, and the point with observer theory is that one's one's defining a much stricter and therefore much coarser potential class of course
so we don't expect physically realistic observers to be able to do actual isomorphism distinction that they're distinguishing something that's much coarser that's more like at the level of thermodynamic variables.
I have a question.
The question is why this book said that reversing the the process would increase the end because we know for example.
The heat equation is a parabolic equation is at a higher level of description. I mean this is at the level of molecular dynamics where every, every molecular collision is reversible.
And so what the age theorem is doing is trying to say, based on just looking at a collection of reversible collisions. What is the conclusion for the entropy as measured in terms of the number of states consistent with the system.
And that that that's the so by the time you're at the heat equation you've already got you've already assumed the answer.
Yeah, but that that argument, this will off topic that argument goes will self destruct because you end up with with as soon as you're talking about.
You're making assumptions about the range of initial states, and that's going to end up being something which is essentially about state preparation. It's a little bit different course grading effect state preparation as well as state observation.
And that what you're what you're saying there is, it's just a, I mean, it's just like state preparation version of the second of the problem of the second row of thermodynamics says, is there a way that we can arrange the molecules of gas in this room, so that they'll all go to one corner in a minute.
Right. And, you know, we argue we can't do that. And it's the same statement as the, what's that.
I think that's not the main point. The main point is, do the computation, you know, actually do the computation to figure out how to get those molecules to arrange themselves so that they will go to that corner.
That's irreducibly difficult. And by the way, if you succeed in doing that, go down to the level of the atoms of space and figure out how they're going to arrange themselves, and then you can travel faster than the light.
I do think, okay, I do think Soteris raises an interesting point though, right, which is so, I mean, to rehash the kind of nks explanation which I know is itself a kind of rehashing of earlier stuff that you've done on statistical properties of CAs and things.
But, you know, so if one views second law of thermodynamics as being essentially a cryptographic or cryptanalytic statement right that essentially even if you have perfect reversibility, the, you know, because of computational irreducibility your the action of the system can effectively encrypt details of the initial conditions to an arbitrary
extent.
Therefore, turning that on its head, if you're, if you're, if you as an observer are computationally bounded, then, you know, you that then you're only ever going to be able to talk about equivalence classes of initial conditions and equivalence classes of you know possible
which is the course grading point. So here is the you then bring up the point about well what if your course gratings themselves have an element of uncertainty to them, which is, I think a kind of meta version of the observer theory question which is the observer is computationally bounded but they don't know how computationally
bounded they are.
What conclusions can they draw, which I think is quite an interesting question.
I mean, right, maybe we've almost exhausted the set of things we can talk about.
Is there any other, I mean, another thing that I'm, I mean, I should wrap up.
I have one other thing, one of the weird comment I want to make about chemistry in case that's, yeah, which is so one thing that one place where I think, weirdly, there's a very direct connection to some very abstract pieces of mathematical physics.
Is so this this issue that this question about chemistry and reactions between species and so on, turns out to be very, very mathematically similar to the question of D brains in B mode topological string theories, which is something I don't understand the physics
of in any sense but mathematically what's going on is, you've got, you know, these D brain things which are just objects in some triangulated derived category, and they can affect the things in string.
Right, right. I don't, I don't know what they correspond to in string theory. I'm also not entirely convinced that string theorists know what they correspond to in string theory, but they, they, you know, as a mathematically you can treat them as objects in this in this category that
that's effectively like a, it's a, well, it's a triangulated category which means it's kind of take you, you take some, some infinity category and you kind of collapse it down to a one category in a way that you have some nice, nice properties of the of the
just my understanding is a string is this, you know, one dimensional thing that traces out a world sheet.
Yeah.
And that's and string theory is the story of, you know, is variational principles on that will.
Right, right. And to the point is in a topological string theory that we're back to the functorial qft case right the initial and final strings are your, are like the initial and final states in the in the fqft and the and the world sheet is the co borders and
relation between them. So again, they naturally define some kind of.
Yeah, what's happening is instead of this one dimensional string, you've got some high dimensional brain. Yeah.
And so all that's happening is that you're looking at this, you know, relation, which is, as you're describing co borders relation right between the initial deep brain and final.
Exactly.
Okay. Yeah. So they form objects in this in this in this triangulation.
It's it's.
But anyway, so these, these deep brains can can merge and they can split in various ways, right. And so in particular, so they can merge into into effectively something like a direct sum of deep brains but it's a direct sum with interaction that's kind of like a, like a semi direct product.
Yeah, right. You're having the whole point of string field theories that you have all these different ways in which the strings can split and join you have this instead of having this, you know, plain surface that is the world sheet.
You have this thing with all kinds of holes in it and so on. Right. And I assume there's a topological version of that which I don't really understand, which is a topological point of field theory.
Yeah, exactly. Well, that's what topological string theory is.
Yeah. So, and so, yeah, anyway, so, so, then there are specific. And okay, mathematically, those, you know, you've got, you know, deep brain a and splits into a sort of direct sum with interaction of deep brains b and c, mathematically, in the derived triangulated
category, although that that corresponds to a homotopy, but essentially a homotopy fiber sequence of B to A to C.
And so, then there's a set of purely mathematical principles which I think are called the bridge land conditions on that category that tell you effectively what, you know, what, which reactions are not permissible right you know in which situations will you get using
splitting, etc. And you can associate various different triangulated categories with different sets of bridge land conditions. And formally, it looks very, very similar to essentially this description of like, you know, what chemical what reactions between chemical species are and are not permitted.
And if that's true, that's quite interesting because now suddenly a lot of that, you know, the mathematical apparatus that we were talking about earlier that comes a lot of it from topological field theory, where you can actually talk quite explicitly about this duality between
multiway fibers and foliations, you can now wheel that in and essentially solve a whole bunch of or translate a whole bunch of these concepts in chemistry to the same formalism.
So there's a weird kind of I know, I have this, you know, I think, you know, Feynman diagrams are also not completely unlike chemistry. But what you're what you're dealing with here is something which where you know the in string field theory you could imagine a Feynman diagram like representation
of string field theory. Right, right. And so this is, this is something, although it is a little bit more complicated because in, you know, in Feynman diagrams are a story of particles.
And these things are a story of more general objects that aren't just localized things moving one dimensionally through time. Right. And so that's a more, you know, so that's a generalization of that.
Now whether whether in chemistry, there's, it's a meaningful thing to have these more extended objects in, in, in space time, I mean, I would imagine a molecular biology, it might be a molecular biology might, you know, it could be that a molecular
biology, I mean, it matters that molecules are big in molecular biology. But as most of the time in ordinary chemistry, gas phase chemistry, for example, it doesn't matter how big the molecules are they just, you know, molecules just float around freely and every so often they collide.
The collision frequency is comparatively low. The inter in solid state chemistry, you know, they're just locked in place and they only know about the neighbors liquid state is the reason that's why, you know, that's why the, you know, the airport security people are concerned about people bringing large amounts of liquid.
That's what comes with reactions happening in a significant way because there's enough density to have significant chemical reactions and not some.
And so, so the liquid state case is, let's see, what was I going to say.
Given this new paradigm to do science.
What are the potential physical phenomena or physical systems that we might be able to see a clear distinction between conventional science and this new paradigm of the site.
Do you think that in your future, you place an experiment, then one can say, you know, this is the thing you think about this approach that is not explained at all by the conventional science.
I mean, look, the most, the most immediately applicable one will be a formalism for practical multi competition.
That is, you know, distributed computing, which has been hard that hopefully this formalism will give us a way to think about that that makes it much easier to understand and much more accessible.
And then then there are a whole list of other areas between, you know, economics, chemistry, molecular biology, immunology, linguistics, machine learning, neuroscience.
I'm counting my fingers but I don't actually know the number that we've enumerated so far but each one of these fields for different evolutionary biology, each one of these fields for different reasons.
It's also promising that one could use this kind of multi computation approach, and potentially derived. I mean, the main things that happen is that in the world of computational paradigms.
When it's face to face, you know, when it's faced with computational energy services limits what one can say, in the case of multi computation plus observers, the right kind of observer can, can find general laws.
The other kind of observer is what kind of observer is that. And for example, let's say in economics or for that matter of chemistry or micro biology, it could be the case that the observer that we have normally been using is one that can't find a global law.
But there is an observer that maybe some other kind of observer that measures, you know, different kinds of things in economics or neuroscience or whatever, that other kind of observer can find global laws.
It could be that you just go right out and measure such and such a weird thing in economic systems and say my gosh, you know, the economists who've been trying to find global law for years and everybody thinks that many people think they haven't really found anything.
Maybe, you know, as soon as you measure some different bizarre thing that you could measure in a virtual world, you can measure some detailed thing about correlations between, you know, amounts of money, when you're in there, suddenly boom, there'll be a global law.
So that's the type of thing that I think will happen.
So, okay, in relation to your question about, you know, potential experiments and things like that. So, I think it's important to make it's, it's, I think it's important to make a distinction between sort of paradigms and theories, or, or metamodels and theories or however we however you want to formulate that I mean so, in a sense, it's very directly analogous to the distinction between a formal model of computation and a specific computation.
So, in a sense, a scientific theory is like a specific computation. It predicts that the output of such and such a thing will be X. And if the output is not X, then your theory is falsified and that's kind of so so individual specific computations and classes of computations that's what the whole you know
you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know
Son, like I said, there is a sense in which you could sort of imagine falsifying a paradigm, but it's it's it's the distinction is much less sharp than it is, you know, for ordinary theories.
It's because it's ultimately one of aesthetics, right. So in a sense, you know, what's actually happening is you've got these computations that are that correspond to your models.
correspond we think to, you know, processes, actual processes that occur in the universe.
And the problem, the basic problem of theoretical science and observational science
is to essentially define some kind of encoding function, some intermediate computation that
lets you translate between abstract computational states of your model and concrete, you know,
physical natural states of the system you're trying to, you're trying to construct the model off.
And so then the strength of a paradigm lies, I would argue, in the simplicity of its encoding
functions. A good paradigm is one where you can write down encoding functions that have very
minimal algorithmic or computational complexity. And a bad one is one where the encoding functions
have to be extremely convoluted and contrived. And so in a sense, you could imagine falsifying
the multi-computational paradigm if you could find an example of some system where, yeah,
of course, because of universality and so on, it's possible to construct some simulation of it if
your encoding function is allowed to be arbitrarily weird and contrived. But, you know, if it were
the case that, for instance, you know, with the physics model, you can, you know, you can reproduce
general relativity, you can reproduce quantum mechanics, you can reproduce quantum field theory
very naturally, as it appears, maybe the case. But, you know, to be able to reproduce the mass
of the muon or something, you know, you require some big 100,000 line program, that's a sign that
that's, you know, that's, that's a, it's not a falsification, but it's a weak point of the paradigm.
And so it's, as I think, ultimately, it's a, your question is one that requires, in the end,
a kind of aesthetic judgment rather than, there's no sharp distinction, I'd say, when you're, when
you're reasoning at the level of entire models of, you know, rather than at the level of specific
theories. But it's also like the question of, you know, could calculus be wrong? The answer is,
it's not, that's not the right type of question, because calculus is just this formal setup.
And, you know, calculus could be irrelevant to things in physics or things in the world,
but it can't be just wrong. So it's, I mean, that is, you know.
Right. But that comes back to the encoding function thing, right? I mean, so calculus,
as far as we can tell, is a sort of universal paradigm for doing math. You know, in principle,
you could do combinatorics with calculus. If you, you know, if you set up some weird combination
of step functions and used integrals to count things and whatever, but it would be horrible,
like no one would want to do that. In effect, the encoding function would be really, really
complicated. You could do set areas. Right. Exactly. Yeah. Yeah. So it's some, yeah. Right.
But why would you? Yeah.
It's an interesting question, whether a paradigm can have paradoxes and whether that
is a sign of what, what the heck that's a sign. See, I would argue paradoxes, again, they, they
live at the level of the interpretation. They live at the level of the encoding. They don't
live at the level of the underlying model I would claim. Well, I mean, there's an interesting
question of whether the Rouliat is self-interpreting. What's that? Well, so, so if one makes this
distinction between computations and the kind of interpretation of the encoding of their semantics,
does, does the Rouliat contain its own encoding function?
Yeah. And, you know, and the answer, and the answer, sorry, some levels, yes,
but it depends on what the observer picks out. In other words, it formally contains what the
observer does just as any universal computer formally contains the encoding of, you know,
any encoding of that universal computer. Right. But it's not necessarily instantiated.
Yes, but it really is instantiated.
Like one would assume, sorry, Mads had some interjection, which I didn't hear.
Yeah. Sorry.
Well, because again, if you go back to proof theory, you know, so, so, so Banak Tosky
is about a specific model of, of general topology. It's about a model in which, well, ultimately,
well, I mean,
measure theory is topology with an additional function. But anyway, but
we know, so it's all I'm saying. Yeah, it's based on a proof. I think the place where your confusion
may be coming in is that the, the, it's based on a proof theoretic thing, right, which is the fact
that if you allow axiom of choice, you can have, as you say, non-measurable sets. And one of the
consequences of that is, you know, if you have uncountable choice, I should say, that you can
have the Banak Tosky paradox be true. But it's a paradox. The paradox makes reference to particular
balls, right? It makes it makes reference to an actual semantic mathematical structure. It's not
a proof theoretic statement. So again, I maintain the paradox exists at the level of the encoding.
It's not, it doesn't exist at the level of proof theory, right? Similarly, Russell's paradox is
a statement about a set. It's about a model of set theory. It's, you know, it's, it's, it's, it's,
it's generated by a proof theoretic problem with set theory. But the way that the paradox is actually
formulated involves you having some kind of semantic interpretation to the underlying term.
Let's go through this one. Let's take a favorite paradox. Should we take Russell's paradox or
should we take the one on Tosky, which is, which is the light one term? Well,
Banak Tosky is based on a much more sophisticated formal system.
Okay. So I think it's probably easier to analyze the simpler case, but.
Okay. So, so can you, can you.
We don't, it's part of the, please be a better example.
What's that?
We also say that it's part of the calculus, but I think that's a better example.
Right. Maybe these guys should, should comment because, yeah.
Aren't we, if I understand Jonathan correctly, then aren't we essentially making the statement
that if you have one Wolfram model where relativity holds but something,
some cosmological thing contradicts itself so it cannot be a physical model.
That's not evidence against Wolfram models in general as formalism, whereas,
whereas if all Wolfram models had the shortcoming that they couldn't predict
something in reasonable effort and you would need to add lots of unnecessary complexity,
that would be a criticism against the paradigm itself.
And I think it's the exact same thing with, I don't know that we created it.
No, no, I mean, and it's the same thing with calculus. Is calculus useful?
And no, it seemed to be for the last 200 years.
No, that's, but I'm going to go back to the final question.
It's actually a much more straightforward question that we kind of answered somewhat
of basically, which is I don't think mine is asking, you know,
will multi-competition be proved wrong or not?
He's asking, you know, can this overall paradigm, you know, will that lead to us
positing new theories that could be, you know, confirmed with empirical or experimental, you
know, evidence? That's going to be true. I mean, with economics, for instance,
we have some global law of economics, you know, we could actually test that out.
And if it's right, then we'll do very well. I mean, or whoever tries to...
No, we've also got laws of mathematics that we're talking about, which, you know,
I mean, look, with molecular computing, if molecular computing works well,
which it has some, you know, we understand how it works.
We should be able to make them more like our computer, for instance, with physics.
I mean, you know, this is something that we want to do at the Institute,
because we want to actually bring in an experimentalist.
We have the design experiments that we think can actually verify.
Yeah, it's really a shame. There's so many experimenters that contacted me and said,
you know, just tell us particle accelerators, telescopes, you name it.
You know, what should we do to, you know, to...
Justify some graphs that give us excuses to...
Well, yes, give us new experiments to run, but I think, you know,
that's why several projects at the summer school have to do with things about,
you know, photon propagation through fractional dimensional space and things like this,
because that's where we can tell some, you know, some, you know, person with a telescope,
so to speak. Go look for this absolutely bizarre form of gravitational lensing,
and that will be something you couldn't possibly have seen in interdimensional space,
for example. That would be a nice, nice effect.
There are three things that we can do.
One is we can build up the overall paradigm.
We can also do what Jonathan was suggesting, which is there are existing theories.
We see how we would model those theories and we can apply, you know...
Fancy stuff.
We can kind of often raise our comparisons in our, you know,
how we model or how other people model it.
And we should also have new theories, and those will be tested experimentally,
but also when what we do relates to things like technology like distributed computing,
I mean, it's solving problems in the industry as well as perfectly valid, you know,
kind of experimental stuff, I think, as well.
So all three, you know, building new paradigms, you know,
comparing our models with other existing theories and doing new stuff.
Yeah, I was also interested in some of the kinds of science that we might have things to say about
are not really natural science.
They're things like economics, linguistics, you know,
areas, you know, metamathematics.
These are areas that are not traditional natural science.
So they're areas where it's observations rather than experiments.
Same with the illusion of biology as observations rather than experiments.
So it's a little bit of a different thing, you know,
that a Popperian model of how science works is exceptionally narrow.
And, you know, it's really a very physics-based idea.
Experimental physics-based idea.
I'm reminded of it.
When I worked at the Institute for Advanced Study, there was this older physicist there
who was, I would not say a great friend of mine, but who, when he first was an astronomer,
when he first come to the Institute, he was telling a story.
He'd met a girl who was there and this guy who explained with great enthusiasm
all the stuff about how he was studying star clusters and all these kinds of things.
And Goethe had said, that's very nice young man, but I do not believe in natural science.
You can see that the platonic view of, I mean, that's interesting.
He says he doesn't believe in natural science because he has this ultimately platonic view of
everything and that tunnel.
So, you know, this stuff.
Yeah, but even Goethe said that the real world is a shadow of the world.
I do think that this part of the natural science, I think the other penrose has a right to describe
all of the physical world-based, mental world, mental world-based, platonic world,
platonic world, which describes the physical world.
Penrosean trialism as opposed to Cartesian dualism.
I think we should be able to have it kind of both ways in some sense.
In the one hand, we're able to understand ourselves as observers and we're able to do,
we're able to find applications of multiplication.
It seems to be accurate, you know, whether it's through observation or through other
definitions or whatever, you know, that kind of helps to buttress and,
you know, validate physical to our paradigm.
But on the other hand, as we get farther into the rouliades of the speak,
when we do rouliomotion and there's like some coordination with rouliatomy,
part of those pockets aren't going to correspond to anything in our world whatsoever.
Right? But if it seems as though we're kind of, we have authority over our domain in the rouliadomy
and that seems quite solid, then people will have to take some leap of faith
that you can also use this paradigm to explore things beyond what we have access to.
But if we don't have any authority over our domain, then it will all seem to be somewhat
speculative. If we do, then someone will have some faith that this applies more generally,
which will make it very interesting.
I'm going to try, I'm going to interpret Satira's comment as a conjecture that Plato's
fall of the good is actually a veiled reference to the rouliad.
It's how we illuminate all other computational structures.
Yeah, right.
Nice. I mean, this isn't the idea.
There's no new ideas on this stuff.
I mean, in addition to Plato, we go to the theologians and all this kind of thing.
But I mean, this whole point about the role of science and the role of us in science
is interesting because in a sense, it could be the case that to make progress in science,
we simply have to understand ourselves more because that's the story of, you know,
if the rouliad is just out there and to know what the science as we perceive it is,
we have to understand more about how we do the perceiving as much as we, you know,
as we have to look outwards into kind of natural world.
I'm going to disagree with you there a little bit.
I mean, as we've discussed before, and I think has come up in other conversations,
I mean, my view of this is more like you as the scientists have complete freedom
on where you place the computational burden, right?
The traditional case that, you know, as you discussed in NKS of like, you know,
you assume the observer is infinitely computationally sophisticated relative to the system they're
observing, that effectively corresponds to the situation where, you know, if you like,
the observer's computation doesn't matter at all.
And all of the dynamics is going on in the computation of the system.
The rouliad picture is, you know, in a sense, the system is doing some trivial thing,
trivial in the sense that it has basically no algorithmic complexity.
It's just all possible computations occurring in parallel.
And all of the burden has shifted onto the observer and how they encode things.
But I would argue that, you know, in a sense, you have freedom to choose either of those extremes
or anywhere in the middle.
And so I don't think it'll ultimately be the case that if you make that selection,
that you'll end up being forced to learn more, you know, to encode yourself as an observer
to a greater or lesser extent than you initially had to to begin with.
No, but I think the point is that if we were sort of utterly trivial observers,
the fact that we are observers as we are means that our sampling, you know,
we are taking a certain burden in your picture as observers.
And the burden that we are taking is causing us to perceive things the way that we perceive things.
Yes.
If we were taking a different burden, if we were different from the way we are,
we would perceive different things.
And so to know what we are going to perceive,
we have to know some characterization of how we are, so to speak,
which is not something that science usually discusses.
Well, it actually has discussed many times, right, to know, you know,
relativity was the result of being realistic about simultaneity, quantum mechanics,
the result of being realistic about, well, some kind of measurement thing.
Right.
You know, so it isn't the case that science has never had to confront this thing about what observers are like.
But I think what we realize in this really odd picture is that there's a much more of a spotlight
back on what we like as observers.
But again, I would say that's really the kind of whole algorithmic complexity aesthetic encoding thing,
right, that my conjecture would be that, yes, general relativity and quantum mechanics
are elegantly formulated if you are realistic about the limitations of the observer,
which we agree upon.
But, you know, the counterclaim would be that there would be scientific theories
which are observationally isomorphic to general relativity and quantum mechanics,
which assume nothing about the nature of the observer,
but which are much more contrived to specify.
Yeah, it's just a challenge.
Right.
So good.
I mean, then you have everything.
I mean, then you can construct everything.
It's just not, it's an observer of immense complexity that's needed to go and, you know,
go and construct the Turing machine that constructs the universe, so to speak.
It's just a Turing machine.
It's all good.
Should have been the subtitle 10 KS.
Well, I think that the, I mean, this question about rule of jumps and what happens, you know,
we live where we are in rule of space, what it's like elsewhere in rule of space.
This is why, this is why I keep on obsessing about this animal communication stuff,
which might seem, might seem relative, but that's, you know, that's a case where we actually have
a different place in real space, so to speak.
And, you know, I don't know, it's some, I mean, the other example is in rheology,
where we're just jumping to some random place in the rouliad and where we have no current,
you know, and I'm curious in this, in this whole categorical view of things, right?
To what extent, where does the observer picture come in, come into this categorical view?
I mean, in other words, where does the observer enter the categorical view?
And if we jump, if we jump not through hyperspace, which is old science fiction,
we jump through rural space and we land somewhere, maybe that's what really,
really science fiction story, which I haven't yet read about,
is jumping through rural space to somewhere else.
But anyway, if we jump through rural space to somewhere else,
we land in this utterly alien, you know, world that is not described in the same way that our
world is described, can we still have category theory?
Right. I mean, in some sense, that functoriality is a version of bad idea, right?
Functoriality is a version of rural translation.
You're saying, you know, the semantic interpretation of everything we're dealing with
is completely different, but the underlying compositional structure of our computation is
preserved. And that's, you know, that's at least one form of rural translation.
But, and then on a potentially more interesting level, you know, one way that you can reason
towards the Rulliard, so to speak, is, you know, you take this model of multi-way systems as,
sort of, as monoidal categories, and these completion, these towers of completion procedures,
which you can do to effectively populate an entire rural space, you can code, you know,
as is discussed in stuff by Zakti's myself and Hatem, you can encode those completions as the
introduction of these higher homotopies or these higher, these higher morphisms and so on.
And so eventually, you know, you reach some point where, in the end, you obtain some infinity
category that is the sort of full Rulliard multi-way system. And then, I don't know whether it's the
hyper Rulliard or the ordinary Rulliard or something, there's then a classifying
space of those Rulliard multi-way systems, which is given by some infinity one top-offs.
And then the role of the observer is that they are some sort of principle by which you can take
that, either the initial infinity category or that infinity one top-offs, and you vibrate it in some
particular way in such a way that the, you know, the multi-way systems or Rulliard multi-way systems
that you obtain by taking some global section, inherit some nice features of the overall
infinity category or infinity one top-offs. For instance, something like spatiality,
is it would be a common form of inheritance. So what you're basically saying is what fibers of
aliens are likely to be understandable, right? So you're asking the question of what, I mean,
this is the setting question, basically, is in the expanse of Rullial space, you know, where we
likely to find, you know, aliens that we can understand, and how dense is the set of aliens
that we can understand in Rullial space? And is it a set of measures zero in some sense in Rullial
space of aliens that we can understand relative to not, and you're saying, you're describing
this selection in this infinity one top-offs, so to speak, of things that have certain properties
like spatiality. So, okay, so prove whether the set of aliens we can understand is a set of measure
Well, so my hypothesis about that, again, is getting very speculative, it's similar to the
speculations about chemistry, is that essentially, okay, you know, my philosophical perspective on
that question is that, you know, that beyond this, if you're outside a very narrow domain
of shared cultural experience, communication is impossible because it's essentially the
computational equivalency thing, right? It's indistinguishable from essentially thermodynamic
noise. And my hypothesis, my operative hypothesis has been when thinking about this,
that essentially a way you can encode shared cultural history is through the causal structure
of the Rullial multi-way system, right? So effectively, so the fibers over which you can
have effective communication are those that have sufficient shared causal history in the event
structure. And if you've got fibers that are completely causally disconnected, then communication
becomes theoretically impossible for essentially reasons that are not similar to, you know,
sort of event horizon type arguments, right? Right, so what you're saying is there's a Rullial
space because there's a Rullial graph just like there's a branched graph, and you're saying that
the, you know, you're distant in Rullial space. Right, right. And there's a certain level of
distance beyond which, you know, essentially, your past causal ancestor is far enough away that,
you know, communication has come so close. Well, if you're past the big back, that would be one
possibility, that you're actually in disconnected regions of Rullial space, and then you're totally
toast. And the aliens in disconnected regions of Rullial space are truly, truly gone. Right.
Truly separated. But I think this, let's see, we will, yeah, it's just going to comment,
just a side cultural comment. I mean, for some reason, this is the year of growth. It seems like,
you know, everybody's talking about growth. You know, there was an article in New Yorker,
there's this person called Michael McCarthy who's writing a novel that has a big growth
indeed, like character and so on. And I'm trying to understand why, you know, and that's, that's
the world infinity categories and things like this. And I'm just trying to understand from it.
Sorry, someone was sitting here talking about what?
Growth indeed. Alexander growth indeed.
And part-time wizard.
I'm probably pronouncing it. I don't know, can anybody pronounce growth and deek and it's
maybe something like, okay, all right, close. I'm just wondering whether some of his
thinking about the infinity category, infinity group, and so on, what more can we mine?
Well, that's, that's the comment I was making about spatiality, right, as you know, so in
effects growth and deek, growth and deek had this idea that, you know, one kind of abstract
model you can give for topological spaces that doesn't require you knowing anything about points
and whatever, is to model them as infinity categories. And the reason for that actually is
very interesting. I mean, it's kind of intuitive when you, I mean, it sounds really weird and
abstract. It's kind of intuitive when you think about it in the right way, which is what you're
saying is, you know, okay, so you've got some topological space, you can look at paths in that
space and you can look at, you can look at homotopies between those paths and you can construct
then a homotopy space, where the points in the homotopy space are paths in the original space
and the paths in the homotopy space are homotopies in the original space. And then you can construct
its homotopy space and so on, you get this large tower. And in this, in the categorical
interpretation of what's going on now, you know, points are just objects, paths are just morphisms,
now this is, this gives you a way of constructing an arbitrary infinity category. And we know that
for homotopy spaces, there's at least a large class of cases in which if you know the infinity
homotopy space, you know, the infinite limit of this, of this picture, that then the structure of
that infinite, the infinite limit of these, of this homotopy tower determines that once you get to
the infinite limit, something really rather remarkable happens where the structure of that
space determines the structure of all the spaces in the hierarchy below it, at least up to weak
homotopy equivalents. And so then Grotendie basically took that and took that, took that idea. So,
so if you, if you construct the infinity category, that is the infinity homotopy space for some
topological space, it determines everything that you as a topologist might reasonably care about,
about not just the original space, but also all of its higher homotopy spaces. He took that idea
and he just like took it to its logical conclusion. He said, well, maybe not just, it's not just the
case that every topological space is modeled by an infinity category, but maybe every infinity
category can be thought of as a model of a topological space. And so maybe an abstract
definition of what the topological space is up to high up to weak homotopy equivalents is that
it's an infinity category of some description, which then motivated a lot of this work on
trying to classify infinity categories and infinity group points and all this kind of stuff.
And so in the, yeah, in the, in the, in the rural picture, and this again is an insight,
it's really originally due to, due to the complexities. But, you know, one question you
can ask is why do, why do so many of the structures that we encounter in the physics
project, like causal graphs, hypergraphs, multiway systems, et cetera, have spatial
interpretations as Lorentia manifold, Ramanian manifold, projective Hilbert spaces, et cetera.
And one perspective on that, which is the kind of cognitive perspective, is that you've got this
really adds that, that is, that has the structure, the formal structure of an infinity category. So
it is, it is naturally spatial. It is naturally a topological structure. Then you take an appropriate
global section. And if you take those sections sufficiently judiciously, then those sections
effectively inherit spatial structure from the really add. And so, so one reason why we have
one possible explanation why, for why we have spatiality in physics is that it's all, it's
spatiality that's being inherited from the infinity group void structure of, of the really add.
Although observers like us, I mean, I, I claim that spatiality is a feature
observed by observers like us. Right. Well, I agree. But that's where the, the, the phrase
up to we come out to be equivalence comes in, right? So, so, so the, so the spatiality,
so up to we come out to be equivalence is really a statement about a observer course
great. Yeah. Right. Right. Which is also a statement about computational boundaries of
observers. Right. And so we come out to be equivalence. It's, it's, it's all the same,
same story. Yep. And so, you know, we observe space because, you know, so I mean, you know,
there's this, I'm just so curious to understand, you know, something, you know, in a sense,
the growth of knowledge is a growth is an expansion of real space. And I'm sort of impatient to jump
to a different place in real space and understand what's out there. And as, as seen by, but, but
of course, then we have a problem of communication between, you know, it's, I have to say, I'm
reminded of sadly, a thing in the 1950s, when people are first talking about cybernetics,
okay, there's this big proceedings and so on. And there's, there's one of the, one of the core
articles is called communication between the same and the insane, which is kind of a, you know,
it could be a version of this kind of familial thing. But in those days, the notion of these
things were a bit different. All right, we should probably wrap up many, many, many things that
could be followed up, but we can go ahead. Thanks very much.
