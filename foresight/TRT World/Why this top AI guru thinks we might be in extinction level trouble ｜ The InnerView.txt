Konolehi is one of the world's leading minds in artificial intelligence.
He is a hacker who sees the rise of AI as an existential threat to humanity.
He dedicates his life to make sure its success doesn't spell our doom.
There will be intelligent creatures on this planet that are not human.
This is not normal.
And there will be no going back.
And if we don't control them, then the future will belong to them, not to us.
Lehi is the CEO of Conjecture AI, a startup that tries to understand how AI systems think
with the aim of aligning them to human values.
He speaks to the interview about why he believes the end is near and explains how he's trying
to stop it.
And Konolehi joins us now on the interview, he's the CEO of Conjecture.
He's in our London studio, good to see you there, good to have you on the program, Konolehi.
You're something of an AI guru and you're also one of those voices saying we need to
be very, very careful right now.
And a lot of people don't quite have the knowledge or the, they don't quite have the vocabulary
or the deeper understanding as to why they should be worried.
They just feel some sort of sense of doom, but they can't quite map it out.
So maybe you can help us along that path.
Why should we be worried about AGI and tell me the difference between AGI and what is
widely perceived as AI right now?
So I'll answer the second question first just to get some definitions out of the way.
The truth is that there's really no true definition of the word AGI and people use it to mean
all kinds of different things.
When I talk about the word AGI, usually what I mean by this is AI systems or computer systems
that are more capable than humans at all tasks that they could do.
So this involves, you know, any scientific task, programming, remote work, science, business,
politics, anything.
And these are systems that do not currently exist, but are actively attempting to be built.
There are many people working in building those systems and many experts believe these
systems are close.
And as for why these systems are going to be a problem, well, I actually think that a
lot of people have the right intuition here.
The intuition here is just, well, if you build something that is more competent than
you, it's smarter than you, and all the people you know and all the people in the world is
better at business, politics, manipulation, deception, science, weapons development, everything.
And you don't control those things, which we currently do not know how to do.
Well, why would you expect that to go well?
Yeah, it reminds me a little bit about the debate about whether we should be looking
for life in the universe beyond our solar system.
Stephen Hawking said, be careful.
Look at the history of the world anytime you sort of invite us a stronger power, more competent
power, they might come and destroy you.
And then the counter to that is that you're mapping human behavior, human desires, passions,
needs, wants onto this thing.
Is this natural to do and fair to do because humans created it, humans created the parameters
for it?
So it's actually worse than that in that it's really important to understand that when we
talk about AI, it's easy to imagine it to be software.
And the way software generally works, it is written by a programmer, they write code,
which tells the computer what to do step by step.
This is not how AI works.
AI is more like organic, it's more like it is grown.
You use these big supercomputers to take a bunch of data and grow a program that can
solve the problems in the data.
Now this program does not look like something written by humans, it's not code, it's not
lines of instructions.
It's more like a huge pile of billions and billions of numbers.
And we know if we can run all these numbers, if we execute these numbers, they can do really
amazing things, but no one knows why.
So it's way more like dealing with a biological thing, like if you look at like a bacterium
or something.
And the bacteria can do some crazy things and we don't really know why.
And this is kind of how our AIs are.
So the question is, will humans impart emotions into these systems?
We don't know how to do that.
It's more if you build systems, if you grow systems, if you grow bacteria, who are designed
to solve problems, to solve games, to make money or whatever, what kind of things will
you grow?
And by default, you're going to grow things that are good at solving problems, at gaining
power, at tricking people, at building things and so on.
Because this is what we want.
You reverse engineered GPT-2 at the age of 24, which was a few years ago, that's part
of the legend, I mean, that's part of the credentialing of you before they say, well,
this guy is saying, we're in big trouble.
They say, well, by the way, he knows what he's talking about because technically he
knows what he's doing.
Tell me about the pivot point between being a believer and enthusiastic about this to
becoming a warner.
What happened?
So the story goes back even further than that.
Reverse engineering is a bit generous.
It's more like I built a system and I found out that no one can reverse engineer it.
And this is a big problem.
But it was even before that.
So I've been very into AI since I was a teenager because I want to make the world a better place.
And I think of a lot of people who believe in AI, a lot of tech people who are doing
the things where they think they're dangerous, I think most of them, maybe not most, but
most of them probably, are great people.
They're trying to build technology to make the world a better place.
When I grew up, technology was great.
The internet was making people more connected.
We were getting access to better medicines and there was solar power was improving.
There was all these great things that science was doing.
So I was very excited about more science and about more technology.
And well, what is the best technology than intelligence?
If we just had intelligence, well, wow, we could solve all the problems.
We could do all the science.
We could invent all of the cancer medicines.
We could develop all the cool stuff.
So I was thinking when I was a teenager, and this is, I think, a common trajectory is that
people, when they're kind of first exposed to some of these techno-utopian AGI dreams,
it sounds great.
It sounds like such a great solution.
But then as you think about this problem more, you kind of realize that the problem
with AGI is not really how to build it.
It's how to control it.
That's much harder.
Just because you can make something which is smart or that solves a problem does not
mean you can make something that will listen to you or that will do what you truly want.
This is much, much harder.
And as I started looking into this problem more in my early 20s, I started realizing
like, wow, we are really, really not making progress on this problem.
So in that worst case scenario, whether we have an apocalyptic ending for all of us, we
get destroyed existentially or we become enslaved in the matrix or whatever it might be.
Tell me how it actually happens in your mind.
How does this AGI assume control?
I mean, there are these famous moments in Terminator and elsewhere.
One of the Terminators, that final scene where the nuclear bombs are going off all over.
I mean, there are lots of different ways people have imagined this.
The way you see it, tell me how it happens and how, if things continue to go in the direction
that you fear, how long will it take to get there?
Well, of course, I don't personally know how exactly things will play out.
I can't see the future.
I can give you a feeling, though, of how I expect it to feel.
How do I expect it to feel like when it happens?
The way I expect it to feel is kind of like if you play chess against a Grandmaster.
Now, I'm really bad at chess.
I'm not good at chess at all.
But I can play a little bit of an amateur game.
And then, but when you play against a Grandmaster, there's someone who's much, much, much better
than you.
The way it feels is not like you're having a heroic battle against the Terminator.
You're having this incredible back and forth, and then you lose.
No, it feels more like you think you're playing well, you think everything is okay, and then
suddenly you lose in one move, and you don't know why.
This is what it feels like to play chess against a Grandmaster, and this is what it's going
to feel like for humanity to play against AGI.
What's going to happen is not some dramatic battle that the Terminators rise up and try
to destroy humanity.
No, it will be things get more and more confusing.
More and more jobs get automated, faster and faster.
More and more technology gets built, which no one even quite knows how the technology
works.
There will be mass media movements that don't really make any sense.
Do we really know the truth of what's going on in the world right now?
Even now with social media, do you or I really know what's going on?
How much of this is fake?
How much of it is generated with AI or other methods?
We don't know.
And this will get much worse.
Imagine if you have extremely intelligent systems, much smarter than humans, that can
generate any image, any video, anything trying to manipulate you, and being able to develop
new technologies to interfere with politics.
The way I expected will go is that things will seem like mostly normal, just like weird.
Just like things are getting weirder and weirder.
And then one day, we will just not be in control anymore.
It won't be dramatic.
There won't be a fight.
There won't be a war.
It will just be one day the machines are in control and not us.
Even if there is a fight or a war, they've handed us the gun and the bullets and we've
done it.
It's us that might do all of this, precipitated by being controlled in some way.
Absolutely possible.
I don't think AI would need to use humans for that, because it could develop extremely
advanced technology.
But it's totally possible.
Humans are not secure.
It is absolutely possible to manipulate humans.
Everyone knows this.
Humans are not immune to propaganda, not immune to mass movements.
Even if an AGI gives Kim Jong-un a call and says, hey, I'm going to make your country
run extremely well and tell you how to build superweapons.
In return, do me this favor.
I mean, Kim Jong-un is going to think that's great.
And it's very easy to gain power.
If you're extremely intelligent, if you're capable of manipulating people, of developing
new technology weapons, trading on the stock market to make tons of money, well, yeah,
you can do whatever you want.
So you're sounding the alarm.
Geoffrey Hinton, seen as the founder or father or godfather of AI, he's sounding the alarm
and has distanced himself from a lot of his previous statements.
Others in the mainstream are coming out, heavily credentialed people who are the real deal
when it comes to AI are saying, we need guardrails, we need regulation, we need to be careful,
we should stop everything, yet open AI, Microsoft, DeepMind, these are companies, but then you
have governments investing in this, everybody's still rushing forward, hurtling forward towards
a possible doom.
Why are they still doing it despite these very legitimate and strong warnings?
Is it only about the bottom line and money and competition, or is there more to it?
This is a great question, and I really like how you phrased, you said, that we're rushing
towards, because this is really the correct way of looking at this.
It's not that it is not possible to do this well, it's not that it's not possible to build
safe AI, I think this is possible, it's just really hard, it takes time, it's the same
way that it's much easier to build a nuclear reactor that melts down than to build a nuclear
reactor that is stable, like of course this is just hard, so you need time and you need
resources to do this.
But unfortunately, we're in the situation right now, as we're currently in a situation
right now, we're at least here in the UK, there is currently more regulation on selling
a sandwich to the public than to develop potentially lethal technology that could kill every human
on earth.
This is true, this is the current case, and a lot of this is because of slowdown, it's
just governments are slow, people don't want, and vested interests.
You make a lot of money by pushing AI, pushing AI further makes you a lot of money, it gets
you famous on Twitter, look how much, these people are rock stars, people like Sam Altman
is a rock star on Twitter, people love these people, they're like oh they're bringing
the future, they're making big money so they must be good, but I mean it's just not that
simple, unfortunately we're in a territory where we all agree, somewhere in the future
there's a precipice, which we will fall down if we continue.
We don't know where it is, maybe it's far away, maybe it's very close.
And my opinion is if you don't know where it is, you should stop.
Well other people who gain money, power, or just ideological points, a lot of these people
is very important to understand, do this because they truly believe like a religion, they believe
in transhumanism, in the glorious future where AI will love us and so on.
So there's many reasons, but I mean yeah, a cynical take is just I could be making a
lot more money right now if I was just pushing AI, I could get a lot more money than I have
right now.
How do we do anything about this without just deciding to cut the undersea internet cables
and blow up the satellites in space and just start again?
Because this is a technical problem and it's also a moral and ethical problem.
So where do you even begin right now or is it too late?
So the weirdest thing about the world to me right now as someone who's deep into this
is that things are going very, very bad.
We have crazy corporations with zero oversight just plowing billions of dollars into going
as fast as possible with no oversight, with no accountability, about as bad as it could
be, but somehow we haven't yet lost.
It's not yet over.
It could have been over.
There's many things where it could be over tomorrow, but it's not yet.
There is still hope.
There is still hope.
I don't know if there's going to be hope in a couple years or even in one year, but there
currently still is hope.
Wait, hold on.
One year.
Come on, man.
I mean, we're probably going to put out this interview like a couple of weeks after we
record it.
A few months will pass.
We could all be dead by the time this gets 10,000 views.
Explain this timeline.
One year.
Why one year?
Why is it going so fast that even one year would be too far ahead?
Explain that.
I'm not saying one year is guaranteed by any means.
I think it's unlikely, but it's not impossible.
This is important to understand is that AI and computer technology is an exponential.
It's like COVID.
This is like saying in February, a million COVID infections, that's impossible.
That can't happen in six months, and it absolutely did.
This is kind of how AI is as well.
Exponentials look slow.
They look like you don't go up one infected, two infected, four infected.
That's not so bad, but then you have 10,000, 20,000, 40,000, 100,000 within a single week.
This is how this technology works as well, is that as our computers get, there's something
called Moore's Law.
It's not really a law.
It's more like an observation that every two years, our computers get about, there's
some details, but about twice as powerful.
That's an exponential, and it's not just our computers are getting more powerful.
Our software is getting better.
Our AIs are getting better.
Our data is getting better.
More money is coming into this field.
We are on an exponential.
This is why things can go so fast.
While it would be weird if we would all be dead in one year, it is physically possible.
You can't rule it out if we continue on this path.
The powerful people who can do something about this, especially when it comes to regulation,
when you saw those congressmen speaking to Sam Altman, they didn't seem to know what
the hell they were talking about.
How frustrating is it for you that the people who can make a difference have zero clue about
what's really going on?
More important than that, they didn't seem to want to actually know.
They had weird questions that made no sense.
You're thinking, okay, these guys are in charge.
No wonder the AI is going to come and wipe us all out.
Maybe we deserve it.
Well, I wouldn't go that far, but this used to annoy me a lot.
This used to be extremely frustrating.
But I've come to peace with it to a large degree.
Because the thing that I've really found is that understanding the world is hard.
Understanding complex topics and technology is hard, not just because they're complicated,
but also because people have lives.
This is okay.
This is normal.
People have families.
They have responsibilities.
They have ... There's a lot of things people have to deal with, and I don't shame people
for this.
I have Turkey with my family or with Thanksgiving or whatever, and my aunts and uncles, look,
they have their own lives going on.
They maybe don't really have time to listen to me and give them a rant about it, so I
don't.
I have a lot of love and a lot of compassion for that things are hard.
This of course doesn't mean that solves the problem.
But I'm just trying to say that it is, of course, frustrating to some degree, that there
are no adults in the room.
This is how I would see it.
Is that there is sometimes a belief that somewhere there is someone who knows what's going on.
There's an adult who's got all under control.
Someone in the government, they've got this under control, and as someone who's tried
to find that person, I could tell you this person does not exist.
The truth is, is the fact that anything works at all in the world is kind of a miracle.
It's kind of amazing that anything works at all with how chaotic everything is.
What the truth is, is that there are quite a lot of people who want the world to be good.
They might not have the right information, they might be confused, they might be getting
lobbied by various people with bad intentions.
Most people want their families to live and have a good life.
Most people don't want bad things to happen.
Most people want other people to be happy and safe.
For us, most normal people, not elites, not necessarily politicians or technologists,
but normal people do have the right intuition around AI, where they see, wow, that seems
really scary, let's be careful with this.
This is what gives me hope.
When I think about politicians and I'm not being in charge, I think this is now our responsibility
as citizens of the world, that we have to take this under our own hands.
We can't wait for people to save us.
We have to make them save us.
We have to make these things happen.
We have to make our voices heard.
We have to say, hey, how the hell are you letting this happen?
One of the beautiful things is that, to a large degree, politicians can be moved.
They can be reasoned with and they can be moved by the voters.
You can vote them out of office.
That's a good argument for democracy.
That's a great argument for democracy.
It's wonderful.
Democracy is the worst system except for all the other ones.
To the point of people's feeling, and I asked about this at the very beginning, that intuitive
feeling of something's up here, there's something ominous, there did seem to be a little bit
of a plateau with something like chat GPT.
Initially, people were very anxious, very surprised, but very wowed by what this thing
could do.
Could write your university thesis and whatever.
It could do all these fancy gimmicks.
They seemed like magic tricks.
But then once the hype died down a little bit, people began to input new things, ask
maybe better questions, and you could see some of the limitations of something like
chat GPT and its forerunners.
That led a lot of people to say, well, I mean, okay, sometimes this thing just sounds like
a PR department or an HR department in a company.
Sometimes it actually, it's there to detect plagiarism, but sometimes it feels like a
plagiarized college paper, which led to, and this is anecdotally, a lot of friends of mine
going, oh, maybe this thing, maybe we're okay for a while because this thing has severe
limitations.
Address that for me because a lot of people are still sort of like, well, I know there
was the hype, but now I'm not so sure.
Tell me about that.
So there is a story, I'm not sure if the story is actually true or not, but it's a good metaphor
where if you take a frog and you put it into a pot of water, you know, a cold pot of water,
the frog will sit there happily.
If you slowly turn up the heat on your pot, the frog will sit there, there's no problem.
And if you do it very slowly, very slowly, slowly increase the temperature, the frog
will get used to the temperature and won't jump out until the water boils and the frog
dies.
I think this is what is happening with people, is that people are extremely good at making
things which are crazy normal.
Is that if it's a normal thing, if it's a thing all your friends do, then it just becomes
normal.
This is like during war, why people can slaughter other people because if all your friends are
doing it, well, it's normal.
It's like, yeah, you slaughter people, it's normal, you know, killing people is fine.
This is how it can happen.
And the same thing applies here, is that, well, okay, you can talk to your computer
now.
Like, sure, we can argue about, oh, chat APT, it's not that smart.
You can talk to your computer, like, slow down.
If this was a sci-fi movie from 20 years ago, everyone would be yelling at the screen, like,
what the hell are you doing?
Like, this thing is obviously like crazy, like, what the hell is going on?
But because it's, you know, available now, you know, cheaply online, it doesn't feel
special.
So the way to address this is, I think, a lack of coordinated campaigning effort.
What I mean by this is, is that the general, when we think about our civilization, not
just individual people, when we think about our civilization, how does our civilization
deal with problems?
How does it decide which problems to address?
Because there's always so many problems you could be putting your effort on.
How does it decide which one to pay attention to?
And this is actually very complicated.
And it can be because of a natural catastrophe, or a war, or whatever.
It can be because of some stupid fashion hype, just like some viral video on TikTok makes
everyone freak out, sometimes, yes.
But usually, if you actually want your civilization to address a problem, a big problem, it takes
long, hard, grinding effort from people trying to raise this to saliency, to raise it to
attention.
Because, again, people have lives.
Most people don't have time to go online and read huge books about AI safety, and like,
oh, how do we integrate chat, GBT, or how do we deal with their safety trips?
They don't have time for that.
Of course they don't.
And I'm not trying to judge these people.
I understand.
It's not their job.
In a good world, there should be a group of people that deals with this.
The problem is, they don't really exist.
Before we go, I'm glad you mentioned that people don't know where to look.
If there was one resource that you could point people in the direction of so that they can
educate themselves about the reality of the situation and can bring themselves up to speed,
that would be what?
There's not one who, I think, has the whole thing, which is a big problem.
Someone should make that resource.
If someone made that resource, please let me know.
So what I would probably point people towards is Control AI, which is a group of people
who I'm also involved with who are campaigning for exactly these issues, who are trying to
bring humanity together to solve these problems.
Because this is a problem that not you or me can solve.
No human can solve these problems we're dealing with right now.
This is a problem that humanity has to solve, that our civilization needs to solve.
And I think our civilization can do this, but it won't do it without our help.
It won't happen without us working together.
So if there's one thing I can do, go on Twitter or Google or whatever, go to Control AI and
support them.
Listen to what they have to say, and this is the campaign I'm behind as well.
I support them.
Okay, we'll put the link also in the YouTube description if anybody wants to check it out.
Karna, you have a brilliant mind, and I'm really grateful that we got to talk.
Thank you very much for joining us on the interview.
Thank you so much.
Take care.
