Okay, so welcome back. Right, so we've kind of finished a broad arc in this
course that I was kind of setting up from the beginning and finished with our
discussion of social construction, broadly trying to motivate the idea that
there's both values influence on science, especially in the sense of deciding
which questions we ask and how we ask them, but that nonetheless science can
come up with reliable and in some sense objective knowledge in the sense that
it's at least intersubjectively reliable. So that was kind of the point of that
the course so far. We're going to shift gears a little bit now, so the rest of
the course is basically just taking a look at a couple of various issues in
philosophy of science. Today we're going to shift to doing more philosophy-ish
philosophy, so less. We've been doing a kind of integrated history and philosophy
of science largely for the course, so lots of interest in actual scientific
practice and that sort of thing. Now at least today we're going to start talking
about kind of more pure philosophy of science, so we're going to take a step
back historically, start talking about stuff that happened in the 40s in
philosophy of science and move on to more modern stuff. Specifically we're going
to start talking about explanation. One of my favorite topics in philosophy of
science is something I dealt with a lot in my PhD thesis. So if we think about
what we want out of science, so consider what we're after. We want to be
able to predict things, of course. You want to be able to know what's going to
happen next, but you also want some capacity. I would insist that
these are two different things. You also want to be able to explain things.
So if you think about how long it's been the case that we were able to predict
that the sun was going to rise tomorrow, I mean we've been able to predict that
for ever. I mean as long as we've been able to predict things, we've been able
to predict that the sun would rise tomorrow. But when would you say that
we have a correct explanation for that fact?
When you can explain why we didn't have a...
So when did we learn how to explain that the sun's rising tomorrow?
Like where we infer, because if the sun has come up every time, every 24 hours.
Yeah, but that's the prediction part. So this is, I mean there's the prediction
that it's going to come up tomorrow, which we've been very reliably right about
for a very, very long time. Probably before language, we had this figure there.
Yeah, yeah, that's where I would roughly put it. There might be some gray areas there where like
Copernicus had a, you know, here's why the sun rises, it's because the earth is spinning
round and round. I take it that that's the correct explanation, roughly.
So we didn't have that until 500 years ago, something like that. So there's this vast
difference between being able to, historically at least, being able to predict that the sun's
going to rise and actually understanding why it rises. Like we had previous explanations,
one of which was that the sun is spinning round and round us, or that the chariots of the gods
are dragging it across the heavens. That was a previous explanation. I take those are attempts
at explanation, but we might want to require that our explanations be true. Like an explanation in
some sense is a, it's a success term, right? You say you've explained something when your
explanation is both good and true, rather than just trying to explain. Yeah. So let's distinguish
prediction from explanation. Explanation might say you have explanations when you
understand something in some deep way. So there's a, typically there's a connection made between
explanation and understanding. And philosophers have spent a whole bunch of time and energy trying
to understand specifically scientific explanations, that there might be something different about
scientific explanations than other kinds of explanations, not just sort of pseudoscientific
explanations, but the style of explanation that scientists are interested in seems to be different
than other types of explanation. So let me give you a contrast for scientific explanation,
which is something like historical explanation. Okay, now I don't want to insist that historical
explanation has to have this character, but I'll tell you as a matter of fact, the kind of explanation
that professional academic historians have been interested in, since like the 70s or 80s or
something like that, has been less focused on grand overarching theories of history. Something
happened in the 70s where historians noticed that their explanations had a specific character,
they call it wig history, where, you know, they developed these grand historical stories that
basically had the narrative structure of Europe saves the universe, that the grand march of
history was all heading towards the modern European nation state, and that that's where it was all
leading the whole time. They noticed that their stories had this character and got really uncomfortable
with that fact, probably rightly so. A, because it was politically bad, and B, because it was
simply distorting how things happen, like that's not how history works, it doesn't head specifically
towards some outcome, it's things happen and there's a bunch of reasons why they happen. So
they got really nervous about these grand historical narratives and started telling historical stories
that were very specific in their time and place. So a historian now will focus on like medical history
in Italy in 1450 to 1470 in this specific social class or something like that, right? They'll get
these really, really specific things that they want to explain and the style of explanation that
historians tend to use, again this is not a fact of nature, this is just the historians that I hang
it with. They want to understand things not by trying to fit them into kinds and categories of
events. What they want to do is understand all of the detailed specifics of that moment in time
and space. They understand the event more deeply by layering in more and more context so that you
can see what's absolutely unique about that thing that they're trying to understand. So this is a
way of explaining and understanding the world. It's a kind of contextual specific focused and
detailed way of understanding and the explanations they give are kind of long detailed stories about
that time and place. And I want to suggest that this contrasts with the way that scientists are
typically interested in explaining and understanding things. So in scientific explanation the tendency
is to be focused more on understanding the similarities between different things than
understanding one thing in its kind of complex context. So every single snowflake is of course unique
but that's the uniqueness of the snowflake is not what somebody who's doing a scientific study on
it wants to understand. They want to understand the general regularities of all snowflakes. What
are the rules of construction that snowflakes follow? What are the general principles that
describe their geometry? These are the kind of things that scientists try to understand. So their
explanations are not pitched at the level of why does this specific snowflake have this specific
structure? It's an extreme example but I think it kind of carries over. Scientific explanations
typically more interested in the general features of the world rather than zooming in and getting
the very detailed understanding of one specific thing. Does that contrast make some sense? Good.
So again these are not, I mean it's not a fact of, it's not a fact about nature that these different
disciplines have to have these different interests but there's certainly an actual fact about what
these groups are interested in today and that seems to be the distinction. So yeah.
Maybe it's the difference between memorizing all the code for a piece of software versus
knowing the principles of how to code. Something like that. Yeah. And knowing the
principles of how to code would be more valuable than just memorizing an individual piece of software.
What depends what you're interested in, right? Like I take it that these are two different ways
of processing the world actually. So there's different styles of understanding and each
style of understanding is more appropriate for some context than for others. So for example,
when you're dealing with human beings on a one-to-one basis, you probably don't want to go,
ah well here are the general categories that you fall under and I'm going to just
understand you in terms of those general categories. Most people, if you're dealing with
somebody on a one-to-one basis, prefer for you to be interested in the specifics and details of
their actual life, right? Like you don't want to just reduce somebody to a category, you want them
to meet you as a unique individual with unique properties that have to be understood in terms
of your life history and context. I don't know, that's how I prefer to be met and understood.
So depending on your project, depending on your interests, one or the other of those styles of
understanding might be more appropriate and we kind of mix and match them, right? So it's not the
case that all scientific explanation is purely general. I mean if you're doing paleontology,
you're interested in history, if you're doing some types of history, you're interested in
generalities, but this is a this is the broad trend and there are these two sort of semi-separate
but interacting ways of getting at the world. And today we're going to talk about just one of them,
we're really going to focus on the scientific style, the general style of explanation, okay?
Okay, so as I said, scientific explanation tends to be interested in classes and categories,
right? You want to find the kinds of things and understand the kind of thing that you're looking
at. A political scientist, for example, kind of science, might want to try to understand
revolutions in general, right? So political revolutions, say under what conditions do
revolutions arise? And to understand that and to answer that question, what you do is
try to find all the conditions that are similar across revolutions in history, right? And then
if you have that, maybe you'll be able to do things like predict future revolutions and
understand the causes and factors that lead to one coming about. Whereas a historian, somebody in
a more historical mode, doesn't want to understand, so they say they're looking at the French
Revolution, they don't want to understand the similarity between the French Revolution and
all the other revolutions. They want to understand that moment, what exactly was going on in France
at that time, you know, kind of very detailed way without really worrying too much about whether
it generalizes. So it's about the difference between understanding the class kind or category of thing
that you're interested in versus trying to understand this specific object. Okay, so
and the way that this has usually been formulated by philosophers of science is trying to understand
things in terms of the laws of nature. So for most of the 20th century, philosophers assumed
that scientific knowledge takes the form of laws of nature. And the assumption was that they'd be
universal laws of nature. We've had some debate about that since, but for our purposes, this is a
good place to start. So laws have the form, the following form, all members of the category X
have the property Y. That's a universal claim. It's a claim of all members of the category.
And it's attributing to all members of the category, some property. So all copper is
conductive. That's a classic, for philosophers, that's a classic law of nature, or all electrons
have negative charge, all massive objects attract each other gravitation. These are the kind of
laws that philosophers are interested in. You can see how they are categorical in the sense that they
try to understand the properties of a category. Just saying that it's got this form is probably
not sufficient. So just having universal form doesn't make something a law of nature. Philosophers
spend a lot of time trying to figure out what the extra secret sauce is. But here's the problem. So
compare the following three claims, and they all have that universal form. They all attribute to
all members of a category the property. So there are no spheres of uranium bigger than one kilometer
in diameter. And I'm pretty confident that that one's true. I've never been to most of the universe,
but if you put that much uranium all in one place, it explodes. Like it has a very strong
tendency to undergo a nuclear reaction. So you can't have a sphere of uranium bigger than one
kilometer. Okay. Probably there's also no spheres of gold bigger than one kilometer in diameter.
I don't know of any. But I can't say that with the same certainty. Because there's no law, I don't
think this one is a law of nature. Some bizarrely motivated alien species could go around and collect
just an unbelievable amount of gold and put it all into a sphere. It's not impossible in the same way.
I think there's no naturally occurring ones. Very probable. But again, there's a sort of
difference in character here where one's very unlikely and one is just not going to happen.
Like if you studied all the asteroids in the universe, you might find one that just has
a ridiculous amount of gold in it? It could. I mean, it's extremely unlikely.
But even if both of this, so let's for the for the minute, for the for now, let's assume that
both of these are actually true. I think it's not unreasonable to say that there's probably no spheres
of gold bigger than a kilometer. But one of them has to be true. One of them kind of happens to be
true. Consider this one, all the coins in Corey's pocket on March 9th are quarters. I should have
brought some quarters to make this true. This is I have no change in my pocket right now. But
suppose I've got a couple of quarters in my pocket, that sentence is true of the entire
class or category of things that it's describing. But that could definitely be some other way,
right? Like if I put a loony in my pocket, it wouldn't suddenly turn into a quarter.
So all of these have got the structure that I just described. So it's attributing so all
members of the category X have the property Y. If you put these in logical form, they actually
apply to every object in the universe because they say, if something is a coin in Corey's
pocket on March 9th, then it is a quarter. And that's true of literally every object of the
universe. You say that's the chair, it's not a coin in Corey's pocket. Therefore, it's true that
if it's a coin, then it's a quarter, that kind of thing. So these in the kind of logical form that
philosophers like to phrase these things, these are all true of literally every object in the
universe. But only the top one, only this one about uranium seems to have the sometimes talk
about the modal force of a law of nature. Laws of nature are not supposed to be coincidentally
true generalizations. They're supposed to be things that have to be true. Not in a logical sense,
but in a physical, the physical properties of the universe preclude something from being
a uranium sphere bigger than a kilometer. Whereas there's nothing in the laws of nature,
as far as I can tell, that requires that there can't be a one kilometer sphere of gold,
or that I could have a coin in my pocket that's not a quarter. That one I'm very confident about.
So these laws are supposed to be universal generalizations, and they're supposed to have this
kind of sort of necessity. So this is the thing that philosophers, I won't spend too much time
troubling you about this, but trying to characterize what property this top one has that these other
two don't has been a bone of contention. Because if you're an empiricist, if you believe that
all of our knowledge comes through our senses, all you ever observe is something never happening.
Like, I never see any gold spheres bigger than a kilometer. That's a true observation,
and you don't see the necessity of this, of this uranium thing. Necessity is not something you
can observe. You just see that it never happens. So trying to describe what makes one of these
necessary, an actual law, and the other two not laws, is we've been working on it. There's some
debate. Okay, so there's laws of nature. The classic view of scientific explanation is that
your explanation should involve a law of nature, of this form. So I'd like to introduce you to the
deductive, nomological account of explanation. So Carl Hempel and Paul Oppenheim wrote this up in
the 40s, mid 40s, presented this as a trying to kind of very clearly say what counts as a scientific
explanation. And the basics, the basic idea is a scientific explanation deduces the thing that
you want explained from a law of nature and some initial conditions. So what an explanation does is
take a law of nature and some specific facts about the world and then deduces the thing you want
explained from that pair. That's what makes something a good scientific explanation.
Here's the general form of it. There's a condition or fact. There's a general law,
and then you just deduce that from that, from the conditional condition or in general law.
In the explanation literature, we separate the parts of an explanation into
explanands and explanandum. I won't make you memorize that, but this is if you want to refer to
the thing you want explained, that's the explanandum, and the thing doing the explaining is the explanands.
Okay, so here's an example very similar to the one
Hempel and Oppenheim give. So the explanandum is why did the pipes in my house burst? So you go
to your kitchen and you see water pouring out, and you say why, why? Well, here's a condition,
here's a fact of the world. The pipes are made of metal and they're filled with water and it's
freezing. So you're allowed to give yourself several facts, but like metal pipes, water in them,
freezing cold. And here's two general laws. When water freezes, it expands. When metal gets cold,
it contracts. And you can put those facts and those rules together to get that the pipes are
going to break. Hempel's one was like a radiator, but I don't know if I think it's more familiar
now than having a radiator filled with water. Okay, so this is what a scientific explanation is,
according to Hempel and Oppenheim. Here's the picture. Here's what it is to explain something
scientifically. You take some facts, you take some laws, and you use them to deduce the thing that
you're interested in. Yeah, pretty good, right? And then we figured it out and it was all over
and nobody talks about it again. Hey, like it always happens in philosophy. We just come straight
to the correct answer and then nobody talks about it anymore. Okay, not really. All right.
Okay, so that was their first pass at this, the deductive nomological account, deductive in
that you deduce things nomological in that it's law based. Of course, a lot of our scientific
knowledge is not universal in that way, right? The laws of nature that I just showed you are
kind of exceptions because most of our scientific knowledge takes the form of statistical facts.
We know something happens a lot of the time or most of the time or regularly, something like that.
So they developed a second model to kind of handle the second style of laws of nature,
the inductive statistical method. So instead of deducing the thing to explain what you get,
so in a deduction, if you haven't done sort of philosophy stuff, in deductions, you get the
conclusion with certainty. So if the premises are true, the conclusion is certain to be true.
In induction, what you say is, if the premises are true, then the conclusion is likely to be
true. So you get a high probability or something like that. So you suppose you've got a tank of
water and you drop an ink drop in it, and it spreads out. So why does that happen? Why does
the ink spread out? And you can give a really good statistical answer to this. So if you characterize
the number of possible states of the system, so all of the ways that the ink can be distributed,
there's just way, way more ways in which it's evenly distributed than if it's like clumped up
in one little spot. So if you say the system is randomly chugging through states, it's just going
to go to some random state, there's almost infinitely more states in which it's randomly and
evenly distributed than there are states in which it's clumped up in one corner or something. So
if you drop an ink drop in a thing of water and it all zooms to just one spot, that's super weird.
It's not impossible. Statistically speaking, that is a thing that it could do, but it's exceptionally
unlikely. This is by the way the same kind of explanation you'd give if you want to know why
is the air in this room roughly evenly distributed? Like why isn't it all pressed down against the
floor or against one wall? The answer is because there's just way, way, way more ways for it to
be roughly evenly distributed than there are for it to be pressed up against one wall. And the system
is just randomly going through states. If you sat in this room for a trillion, trillion, trillion
years, maybe for one second, it would be unevenly distributed. It would mostly be on this side as
it just kind of randomly goes through its states. But you can get that the air is not going to do
that with extremely high probability by doing this kind of statistical explanation. Okay,
so good. We've got the deductive account for things that are always true. We've got the
inductive account for things that are mostly or usually true. Yeah. So in that situation,
wouldn't the vacuum created destroy the room? Maybe. It could only be, it could happen for a
split second and not destroy the room. I don't know. It's extremely, I'm not super worried about
what would happen because it's so hilariously unlikely to happen. We could sit here for many
times the age of the universe and it would never happen. Yeah. If you're laying in bed waiting,
worried at night that the air might all suddenly rush to one side of your room,
it's you'll be fine. Don't worry. Okay. Okay. So let's do some problems with this. So this,
this was the kind of first pass at this stuff comes out in the 40s. People pretty quickly
noticed that there are some issues with both of these accounts. So I started by saying that
there's some big difference between explanation and prediction. Temple actually just goes ahead
and denies this. He says, no, no, no, that's basically the same thing. Because if you can
deduce that something's going to happen, then you've got a prediction that it's going to happen.
The only real difference between an explanation and a prediction for temple is that an explanation,
the thing has already happened. Whereas in a prediction is still in the future. That's it.
That's the only difference. But that produces some weird results for his view. For example,
the famous flagpole. So if I want to explanation, so we got a flagpole, we got the sun and the
flagpole is casting a shadow. So on Hempel's account, you can explain the length of the shadow
by citing the specific position of the sun, and then some universal laws about geometry.
You just your, your, you know, grade A geometry lets you predict how long that shadow is going to be.
But you can do this the other way as well. Suppose you ask, why is the sun where it is?
I want an explanation for the position of the sun in the sky. Well, I know the length of the shadow
and the height of the flagpole. And I know some geometry. And I can deduce where the sun is.
Now, it's perfectly fine to say you can predict where the sun is based on those facts. That's no
worry. But can you explain basis? So say, can you explain to me why the sun is right there? And you
say, well, there's a flagpole, it's this high, and there's a shadow, it's this long. Therefore,
that's why the sun is where it is. That's weird, right? That's not why the sun is where it is.
But on Hempel's account, that comes out as a good explanation, as good as the other way around.
Like, I'm real happy with like, why is the shadow that long? Like, well, the sun's there and had
flagpoles this high. Why is the sun there? You shouldn't know facts about the flagpole are helpful
for understanding why the sun is where it is, right? Predicting yes, explaining people like,
no, no, no, no, no, that's not that's not going to work. Okay, so the famous flagpole example,
people get pretty worried about that. They also get worried about things being cited that are
kind of irrelevant. So here's John Jones, John Jones does not have a uterus. But every day,
John Jones takes a birth control pill. And John Jones does not get pregnant.
Good for him. He's very careful. He's very cautious.
He's got no uterus, but he does take birth controls. John Jones fails to get pregnant.
Well, here's a good, here's a good deductive explanation for that.
Anybody who doesn't have a uterus and takes birth control pills will not get pregnant.
John Jones does not have a uterus. He takes birth control pills. Therefore, he does not get pregnant.
Yeah.
It's not recommended. Okay, it's not generally recommended. Yeah. But if you're going to ask,
why does John Jones not get pregnant, the birth control pills are really a super important
part of the story, right? I mean, maybe the problem is his boyfriend isn't for time.
Right. Thank you. Thank you for that. That's okay. So you can cite, so following
Hempel's model to the letter, you can cite stuff that's irrelevant. You can put it into the story,
and it still counts as part of the explanation.
Yeah. So you can cite irrelevancies. Another example that he uses, critics of Hempel use,
every morning I have a cup of coffee and I say a magical ritual over it, and then I drink the
coffee and it wakes me up. Therefore, saying a magical ritual over my coffee and drinking it
is responsible for explains why the coffee wakes me up. Like, yeah, no, it doesn't. You can deduce
it, right? So there's a very strong regularity. Every time you drink a cup of coffee that you
set a little magical ritual over, it does wake you up. So that's a universal regularity.
You can say a law of nature about it if you want. But that's not an explanation.
Okay. So diagnosing these problems, philosopher said, okay, here's what you messed up,
Hempel, here's what you left out. You can't just cite the universal laws to explain something.
You need to cite the causes of that thing, right? You have to cite the things that caused it to
happen. That's the problem with these examples, right? What you're citing are true universal
regularities, but you're not citing the causes of things. So yeah, you can explain the length of the
shadow by citing the position of the sun and the height because they caused the length of the
shadow. That's what caused the shadow to be where it is, the sun and the flagpole and geometry, I
guess. But the length of the shadow doesn't cause the sun to do anything, right? There's no, if you
somehow manipulate the length of the shadow, you're not manipulating the sun, right? So that's the
problem with that example. Say, look, you cited a universal regularity, but you didn't cite the
causes. You can explain stuff, you got to tell me what caused it. That's the critique.
And again, you can't explain why John Jones feels to get pregnant
because that's not what caused it. That's not the causal story about John Jones not getting pregnant.
If he hadn't taken the pills, he still wouldn't have gotten pregnant. So this is one of the tests
that you do for something being a cause. If it's there, then you get the effect. If you take it
away, then you shouldn't get the effect anymore, right? And similar problems appear for the
inductive statistical explanations. You get similar issues. So let me, I don't expect I can do this
better than the article. Right. So this is an old-timey example. I don't think
syphilis gets talked a lot about anymore, but here's the classic example.
Okay. Okay. Then this is topical. All right. All right. So the town mayor suffers from a
motor deficiency characterized by the limitation of certain movements and a loss in muscular strength,
which is called peresis. And we know roughly a quarter of patients with untreated latent syphilis
are victim to peresis. And we know that the mayor has precisely such latent syphilis,
the condition he was not aware of and was constantly not having, consequently not having
treated. Intuitively, what we have here is an explanation of the mayor's peresis, right? Why
did the mayor have this muscular condition? Because he had syphilis. However, the law linking
syphilis to peresis only brings the, and the fact that the mayor's got syphilis, only brings the
mayor's probability up to 25%. And the inductive statistical account doesn't tell us exactly what
counts as high probability, but 25% doesn't sound about, doesn't sound right. That doesn't sound
like a high probability. It's actually odds are lower than even that he's going to get this condition.
So inductive statistical account said, you explain something by showing how it was very likely.
I mean, the ink blot thing is the ink spreading in water is unimaginably likely. It's so close to
100% probable that there's kind of no difference. But this time it's like less than half. It's a quarter.
Nonetheless, seems like we can explain why he has peresis based on citing the fact that he's got
untreated syphilis. Yeah? Okay.
Would it depend on there being another way of explaining, like if there was another medical
condition that could? Well, in this scenario, so supposing this scenario, this is the cause of
his peresis. We know for a fact that syphilis caused his peresis. So if what we wanted of our
explanations is the causes, then this is fine as an explanation. And intuitively, most people say,
yeah, that's a good explanation. Why is this guy got peresis? Because he had untreated syphilis.
But on the inductive statistical account, this doesn't work as an explanation because you're
supposed to get out that it's got a high probability. So that's weird, right? It's worrisome for the
inductive statistical account. Yeah? Yeah, yeah.
They didn't do it that everyone got syphilis in the town.
Then you could say, I think it was 100% or it was very likely that 25% would have syphilis.
Good. Okay. So interesting. Now, what you've done is shift the
explanandum there. So you say, why is it the case that 25 people, so if there's 100 people in
town with syphilis, why is it the case that there's 25 people with peresis? Now you've got
this nice statistical explanation, 25% of cases develop into peresis, and you've got 100 cases,
therefore it's very likely that 25 people will have it. Yeah. So if you shift the thing you're
trying to explain to the population, then that works nicely. Yeah. But if we're just interested
in the mayor, then the inductive statistics, it seems like intuitively, it should still explain
why this one specific guy got peresis, and it doesn't seem to do that. Yeah. Good. Okay.
So all of the examples I've shown you so far are pretty neatly resolved by just looking at
the causes. Say, how do you explain something? Well, you cite the causes that brought it about.
Ta-da. Pretty good, right?
So, but that gets us into some weird and tricky issues. So,
like, what does it mean for one thing to cause another thing? It turns out there's a
humongous debate about this, especially in complex cases. Yeah.
One of the issues is that something always causes another thing to cause effects. So
you might know how snow is caused, temperature and stuff, but then you have to ask why. Like,
if there's another, once you know how snow is made, you ask why does water create this, and then
why does it just keep going? There is, there is, this is how people end up being philosophers.
They do this, like, why is, okay, say, why is it, why does snow create it? Oh, because
water freezes. Why does water freeze? Because chemical properties. Why does it have those
chemical properties? And then eventually you get to metaphysical questions and
A, people stop talking to you and B, you end up doing philosophy degree. So careful, careful
about that. Yeah. In order to make an apple pie from scratch, you must first recreate the universe.
Close Carl Sagan. Very good. That was my best Carl Sagan person.
Okay. But even absent this kind of regressive why questions, we've got serious and difficult
questions about assigning causes to things that were pretty sure happened. So what are, what would
you say are the causes of the weather today? I mean, you obvious things. There's pressure. There's
season. There's geography. But what we know about weather is that it's unimaginably sensitive to
small changes. So if you make an incredibly tiny difference 100 years ago, it, or even 10, 10 days
ago, sometimes it translates into big, big changes in the overall system. So this is one of the
things we learned by studying weather simulations. For example, when you run a weather simulation,
and you change one variable at the like 10th significant digit, you run it for a little while,
it very quickly diverges to some other state. Yeah, yeah.
That's right. Yeah. So this is the sometimes called the butterfly effect.
It's the idea that a butterfly flaps its wings in the Andes. And then two weeks later,
there's rain instead of sun across the world. And that's, I mean, so it's a general property of
complex nonlinear dynamical systems that that's going to be true, or at least some class of them.
And we're pretty confident that it's true of the weather. So if you want to ask, okay, so what's
the weather? Why is the weather the way it is today? You might have to talk about the weather on
Jupiter 10 years ago. You might have to talk about an errant comet passing beyond the bounds
of our solar system. Like, you might have to talk about random quantum mechanical fluctuations in the
sun. Like, yeah. Yeah, yeah. So the, the number of factors and the numbers factors, if you say,
I want to explain something, okay, great. So just cite the causes. Well, that makes the explanation
very quickly expand out to include the whole history of the universe, which is kind of inconvenient.
I take it that I mean, the assumption in this is that my assumption is typically that an explanation
is something that a human being could give or receive, right? Explanation is something that
we do amongst people. And if you have to cite the entire history of the universe since the Big Bang,
that's not going to work for us in any practical sense, right? I take it the scientific explanation
is something that we can do. And if it's suddenly the case that, okay, we figured out that it's
got to be causes, but now we just figured out that we can't explain anything because you'd have to
describe the entire history of the universe. That's kind of worrying. So Hempel notices this
actually. And one way, one way of dealing with this is to just say, look, we got too many causes.
The real explanation of any event is actually infinitely complex or practically, for our
practical purposes, it's infinitely complex. And that all that you've ever received or given
are what you might call explanation sketches, tiny, tiny, tiny little slices of the real
explanation, something like that. Yeah, so it's a weird, it's a weird philosophers move that
they get kind of pushed into here. So this, you start out from, hey, people explain things.
I know that you know that we explain things, explain things all the time.
How does that work? Well, here's a story. Okay, that story doesn't work. Here's another story.
That story has the consequence that that thing that we started off trying to understand
is kind of impossible. In the sense that you can't ever actually explain so you can't give
the whole explanation for anything. All you can ever give is the tiniest infinitesimal fraction
of the explanatory story. I don't know how you I don't know how you feel about that. I'm a little
uncomfortable with this as a move to sort of turn something very normal and ordinary into something
inconceivably complex and unrelated to any human activity. I don't know, you could be okay with
that. So this is, yeah, this is the human activity, this end of the front end of the
horse. And then the back end is what the universe is like. It's got much more detail and complexity
than this is what happened. What happened if I tried to draw a horse the front, the front half.
Okay, yeah, yeah, okay, so you could have a reverse situation where like the truth is
this stranger or sorry, sometimes fiction is stranger than truth, where you have a very boring
event that's exaggerated in a way to appear more complex than what actually happened. Okay,
that's a possibility, but that's not what's happening here, right? Okay, so causes as explanatory.
They got some issues. There's some serious questions about
whether this story is acceptable. They kind of hang on what you mean by cause.
So maybe you're willing to consider something much smaller as the cause of today's weather. So
you might say, look, I'm not going to talk about the weather on Jupiter 10 years ago. That's not
part of the story. It's not a big enough factor or an interesting enough factor, something like that.
But now we have to be sort of somewhat more selective. Once again, our interests have kind
of come back into the story. Once again, we've sort of been unable to get this clear. I mean,
what Hemple was going for was a clear objective criteria for what counts as an explanation.
The story he told us was too simple. And as soon as you start trying to complexify it are
what we're interested in gets back into the story. And we'll all develop this a little more next
time. We'll talk a little bit more about causes, what counts as a cause, what counts as a causal
explanation. We'll also talk a little bit about whether all scientific explanations have to cite
causes. So it might be the case that there are non-causal explanations. So that's our topic for
next time. Okay, that's it for today. Thanks everyone.
