The stated aim of a company like OpenAI
is the development of artificial general intelligence.
Now, artificial general intelligence
is in Google AI terms,
the equivalent of human intelligence.
What I kind of want to point out here,
when you look at what a general intelligence is,
then that's actually rooted in Charles Spearman
and the idea of the G factor.
But Charles Spearman was a hygienicist.
And his reason for developing this ranking
of general intelligence was to rank human intelligence
for selective breeding, et cetera.
So you've got this drive for artificial general intelligence.
But when you actually work out what general intelligence is,
it's got some very, very dark histories.
Hello and welcome to Planet Critical,
the podcast for a world in crisis.
My name is Rachel Donald.
I'm a climate corruption journalist and your host.
Every week, I interview experts
who are battling to save our planet.
My guests are scientists, politicians, academics,
journalists and activists.
They explain the complexities of the energy,
economic, political and cultural crises we face today,
revealing what's really going on
and what they think needs to be done.
These are the stories of the big picture.
Go to planetcritical.com to learn more and subscribe.
My guest this week is John Wilde.
John is a London-based artist
who works across performance, sound, text, code,
electronics and machine learning
to research the future's imminent
within digital technology.
John joined me today to talk about
culture and artificial intelligence,
how the stories we tell ourselves inform our technologies
and then how those technologies inform the stories
we tell ourselves,
getting caught in these kinds of circular loops essentially,
which make it increasingly difficult
to imagine a different way of being.
John talks about this in relationship
to artificial intelligence.
Artificial intelligence is an incredibly
energy-hungry technology.
It is being used for profit motives.
We have very little understanding
of what it could do when unleashed upon the world
and at the moment, all it's doing is threatening jobs
rather than creating new ways of being.
John's research shows what we could do
if we imagined using mycelium as a framework
for developing something decentralized, interconnected,
entangled and symbiotic.
To begin with, John explains the history of thinking
and artificial intelligence.
How Silicon Valley is infused with theories and stories
that came out of Russia in the late 19th century.
The desire to pollinate the universe with consciousness,
creating a hierarchy of consciousness,
as if humanity is the only thing that is truly conscious
or would be able to do such a thing
as if the universe isn't already conscious.
And he also explains how this hierarchy
of consciousness or intelligence
that is directing Silicon Valley
to make an artificial general intelligence
comes out of eugenicist thinking.
This is such a fascinating conversation.
We had so much fun recording this.
I knew a fair bit about AI
thanks to research into the effective altruist movement,
but I did not know the history that John lays out today.
And understanding more of that history
makes me really grateful
that people like him and artists around the world
and technologists around the world
are trying to think about how to develop permacomputing
or the wood-wide web,
collaborative, interdependent, entangled projects
that reflect the intelligence and harmony
of natural ecosystems
in order for us all to live more sustainably
with one another.
And we end our conversation with a dialogue
on exactly that.
What is sustainable computing
and what is sustainability more widely?
I hope you all enjoy the episode.
If you do, please share it far and wide.
And if you're loving the show,
become a patron on Patreon
or support Planet Critical
with a paid subscription at planetcritical.com.
By signing up, you'll get the Planet Critical newsletter
inspired by each episode
delivered straight to your inbox every week.
You'll also have access
to the wonderful Planet Critical community
who are full of inspiring thoughts, ideas, critiques
and determination.
The links are in the description box below.
I'm so grateful to everyone
who chooses to support the project.
I'm a vehement believer in ad-free
and open-access content,
so Planet Critical wouldn't exist
without the direct support of the amazing community.
Thank you so much to all of you
who believe in Planet Critical
and keep the project going every week.
John, thank you very much for joining me
on Planet Critical.
It is a pleasure to have you on the show.
Well, thank you for inviting me.
Happy to.
As I was saying before we started recording it,
such an interesting conversation with Maggie
who platformed you.
And I think that speaking with artists
is a really critical component
to understanding what the hell is going on in the world
and what we can do about it,
which leads me to my first question.
Why is the world in crisis?
That's such a big question, isn't it?
I know.
I mean, I'm going to start with a report
which was out last week, which really struck me.
So I read an article by Duncan Agnew in Nature Magazine,
which suggested that climate change
is having an effect on universal timekeeping.
What?
So Coordinated Universal Time, or UTC,
is the primary time standard
globally used to regulate clocks.
So UTC closely follows the rotation of the Earth.
But accelerating melt from Greenland and Antarctica
is adding extra water to the world's sea.
It's redistributing mass around the globe,
and that's causing a very slight slowing
in the Earth's rotation.
And if you combine that with what we know
about the shift in the Earth's poles.
So since the 1980s, it's been shown
that the massive melting of glaciers
as a result of global heating
has caused a shift in the Earth's axis of around four metres.
So I think if we think about this question,
the shifting of the Earth's axis
and the slowing of the Earth's orientation
mark both an impressive, to be honest,
but terrifying achievement of human,
global, well, geoengineering.
The impact that we've had as basically fundamentally
has shifted time and the axis of the Earth.
And that seems to be the ultimate mark of the amphipersine.
But I think what troubles me with this,
well, I mean, there's lots of things
which troubles me with this,
but such a feat could only be the outcome
of sustained and coordinated human action and interaction.
Yet no one's planned, organised,
voted for, or even imagined such a venture.
And I kind of wanted to start this conversation
with a kind of provocation which comes from my own research.
My own research is looking at artificial intelligence,
specifically narratives around artificial intelligence.
But what is the coordinating force
that's playing a role here?
And I think the provocation that I want to put forward
is that it's a non-conscious intelligence.
Or an artificial intelligence that we call the market.
I think the market struck producers emergent forms,
which you could call a form of non-conscious intelligence.
Yeah, I totally agree.
What a way to kick us off, by the way.
Wow, I didn't know that,
but climate change has been an impact
on universal timekeeping.
I was thinking about this question that you asked
as this appeared in my feed, and I'm like, wow.
But not only that, it's that universal time,
it affects computing because the computer programmes
made to keep track of universal time
are going to struggle with this slowing down of the Earth.
So it kind of comes into the territory
that I'm also interested in, in a way.
There's so much there, isn't there?
Like the idea of having a human system
mapped onto a natural system,
the human system impacting the natural system,
and then the natural system,
and then being unable to deal with the fallout,
to deal with the consequences,
to understand even the new reality,
because the limits of that system were so fixed and rigid,
which is kind of a really classic feature of modernity.
Like there just being no flexibility.
And then watching reality as we understand it,
just kind of peel away in that moment,
because the systems aren't built for it.
So it really reveals this thread of domination
that runs through modernity, like domination over nature.
It doesn't work, the domination over ourselves.
It just doesn't work.
There is a, it's brittle and it's fragile and it will snap
if it's met with enough kind of shifting, evolving resistance.
I guess the challenge that we have
is if we understand this as a form of,
or if we understand the market
that produces these kind of emergent forms,
as a kind of structural system
that has an intelligence that structures human activity, et cetera.
How do we, how do we move beyond that?
How do we imagine futures, which are structured a different way?
How do we imagine technologies, which are,
which behave in a different way, which are sustainable?
My own research actually looks at the kind of imaginaries
around artificial intelligence.
And I think they can tell us quite a lot really about why we end up
kind of looking to the stars rather than looking to the soil,
rather than looking to the earth.
That's beautiful.
On this artificial intelligence,
I mean, this is kind of what Hayek spoke about as well.
The invisible hand of the market directing people.
The sort of godfather of neoliberalism, essentially.
And yes.
I think you were Smith as well, weren't you, in the wealth of nations?
I think Smith initiated it, and then people kind of took on this idea.
But yeah, the idea of the invisible hand.
Which is interesting, isn't it?
Because there's a concept there of this physical thing being shaped.
But they weren't talking about a brain.
They weren't talking about the invisible brain.
Whereas what is directing that hand to move?
The idea is that it would respond to needs or whatever.
And it's obvious that's obviously not been the case.
Like we've sort of created a system that is impacted,
but also impact its environment around it as it accumulates more
historical precedent and knowledge.
And it's just embodied really with historicity, you might say.
Kind of like self-perpetuate itself and grows and grows and grows.
Well, I think that self-perpetuation is the thing.
I think where this kind of connects with the kind of research
that I do on artificial intelligence, it's kind of like looking at what
intelligence is in some sort of way.
And obviously with the kind of common sense for you is this kind of
conscious intelligence, the kind of the human conscious intelligence.
But conscious intelligence is very rare in the world.
Most forms of intelligence that would come across
are a form of non-conscious intelligence.
So this is kind of sensing and acting on the world
in a way that produces very complex outcomes.
But but don't don't have but don't have at the car this kind of
conscious drive that maybe maybe language produces in humans.
OK, and we pause there.
Yeah. So conscious intelligence is rare in the world,
but this unconscious intelligence is sensed.
Is that the word you used?
Well, I'm saying that for something to act, for something to act,
there's some sort of sensing, some sort of information.
And then there's a behavior that responds to that,
which produces complex outcomes.
So I'm thinking I'm thinking as a good example,
or an example is quite often used as a slime mold.
And in my own practice, we've also been using mycelium,
but slime mode is quite a common one.
So slime mode is a single celled algorithm organism,
which it basically produces filaments
which stretch out to find food in all directions.
And then when it finds finds food,
it solidifies the filaments that is produced.
And it's it's been used to mimic the Tokyo.
Tube map.
So the Tokyo tube because of the kind of geology of the area, etc.
The planning of it is there's quite a lot of complexity
to how to produce the most direct routes.
But by by creating an artificial map of the tube
using the food for the slime mold,
the slime mold managed to
calculate the most direct routes,
which pretty much mimic the the actual Tokyo underground.
So that's that's the way that you could see
that there's a non-conscious intelligence working.
And NASA has used exactly the same model to map
to map the dark matter that holds together the universe.
So these kind of intelligences,
which aren't a model of conscious intelligence,
still produce very complex behavior in the world.
And I'd go.
Sorry, it's just I suppose I'm getting stuck
on this conscious unconscious binary.
Because what we're talking about then
when we talk about consciousness,
because there's quite a lot of, you know,
stuff now coming out of physics
and other sort of theories that suggest that,
well, everything is just consciousness
and that perhaps it's consciousness that predates matter.
And thus, you know, perhaps the slime mold
doesn't have a brain in the way that we
well, definitely doesn't, right?
It's one cell.
But that doesn't necessarily mean it's it's not conscious.
Like, I guess I'm concerned.
Yeah, I agree.
I agree.
I agree.
And it's exactly the hierarchy of consciousness,
which I want to break down.
Right.
I mean, I'm using the term conscious in this way.
As a relationship to language and the the modelling
of the world as an abstract ship.
Of which then things are planned.
But I don't believe this is how humans behave.
I think humans, the vast majority of human activity
is non-conscious.
Like, ride a bike, you don't have to do
with the mathematical calculations to stay on the bike
and direct and route, et cetera.
I think the vast majority of action is non-conscious.
But wouldn't that suggest then that consciousness
is only these kind of consciousness is language
because mass, for example, could be, you know,
understood as like a language for understanding the universe
or other laws for which words don't quite
aren't quite useful.
And so does it not then become that consciousness is language
and everything else is non-consciousness?
I think so in the way that I'm trying to say it.
But the reason the reason why I'm going down this rabbit rabbit hole
is because of the drive of an artificial intelligence
to develop what they call AGI.
So like, which is a general intelligence,
which is trying to trying to mimic human reason in some sort of way.
But what I'm kind of arguing is against that
in favour of something closer to
accepting the intelligence that exists in all species
and plants, et cetera, on the earth.
And then recognising the importance of that kind of intelligence.
So I'm kind of trying to make an argument in opposition
to the artificial intelligence
that drive towards AGI.
So assuming this comes back to your beautiful line,
you know, wondering why humans look up at the stars and not the soil.
Which I think we should unpack as well in relation to this.
So please.
I mean, I mean, I think a good way forward to that is.
I mean, I.
It's probably good to introduce myself a little bit in that.
My own research explores artificial intelligence and real world narrative.
So I'm actually interested in the imaginaries
and the relationship between storytelling and imaginaries
and how that.
As a cyclic causality with technical production itself.
When computer scientists.
Bring something new into the world, it's a creative act.
It's an act of futurism or future, is it?
Like you've got to you've got to think in the future.
To babes to produce technology in the present.
So there is a creative act involved in that.
And that's the kind of creation of narratives or imaginaries.
And this as an impact on on technical production,
the technical production, like what what is possible as an impact on imaginaries.
So so you have a cyclic relationship between the creation of
kind of speculative imaginaries and actual technical production.
So the two things are different in in technical production is
technical production is rooted in in the constraints of the present
in the regulatory framework and politics and ethics, etc.
Whereas imaginaries are that kind of creative leap
into the future that that are used by developers
to basically order.
Like to create goals really for for the technologies that get produced.
And by looking at the kind of imaginaries,
the kind of stories that circulate within tech communities,
then you can get a sense of where the technical development is going.
Is kind of what I'm arguing.
Go on, do you have any good examples?
You said I just wanted to make sure that that made sense,
that relationship between the two.
Oh, definitely.
I think it's just much in the same way
when like scientists come on and speak science.
There's a lot of us here that are laymen
and I think breaking it down
of some sense quite academic language is helpful.
To talk about how these two things inform each other all the time.
So yes, I have a better understanding now.
Thank you.
I think when we're looking at developer narratives,
so the kind of ideas which are driving tech developers.
I mean, these people don't normally come
from a creative background.
So so where where do the graph grab the imaginaries?
Is is quite an interesting thing.
And what my research has found is that a lot of these imaginaries
are driven by, I suppose, obviously sci-fi.
But.
More specifically by the kind of speculative avant-garde movements
which circulate in tech circles.
So to name a few, there's Cosmism,
Transhumanism, Extra-Pianism and Effective Accelerationism.
Oh, what are they exactly?
So like if you delve into tech communities,
you come across these kind of like quite far out
and fascinating ideas.
But what struck me is when I started when I started research
in this territory is the massive impact that Cosmism has had.
Now, Cosmism was a movement which developed in Russia
at the end of the 19th century in the beginning of the 20th century.
So to discover that these ideas from from this period
from pre the Russian Revolution or around the Russian Revolution
currently has a massive impact on
on AI and tech developers in Silicon Valley and California
is a little bit, whoa, really?
But.
So if I dig a little bit deeper into this into the ideas of Cosmism,
it I think I think where your tech is is kind of
to answer that question of why the developers looked at the stars.
So Cosmism emerged in Russia at the end of the 19th century
in the beginning of the 20th century.
And one of the key figures was a guy called Nikolai Fedorov.
And Fedorov connected his kind of quite strong
Christian beliefs with a with a futurism.
And he thought he believed that the common task of humanity
was to end death.
So to end all death to move towards immortality.
Very good. And.
And this wasn't enough
because this betrayed the older generations.
So the first step is to kind of end death.
But once you've achieved that, then the next step is to resurrect the dead.
That's that's that's the duty of all good son.
Sons is to resurrect their fathers.
That's the language, the language he used, not mine.
I just sorry, just a very, very quick side note.
But it's just fascinating to me that this man, for example,
wasn't burned at the stake.
It sends an awful lot like sorcery.
Imagine if that had been coming out the mouth of a woman.
Hey, please continue.
But anyway, you've got to remember, my interest is the relationship
between like imaginaries and technology itself.
Now, one of his students was a person called Constantine.
My Russian is appalling, so please forgive me.
Any listeners who speak Russian, but Sayel Sayelkovsky.
So Sayelkovsky.
He took on a lot of the philosophy of Fedorov, Fedorov, so.
But he took it in a very practical way.
So Sayelkovsky studied kind of the physics of his time and etc.
And he developed some of the first practical divide
designs for the space rockets and the equations
required to for space travel.
And he did this in 1896.
So this these kind of like developments in kind of the technology
of space travel emerged from.
Following Fedorov, realising that if you ended death.
And resurrected the dead, then the planet would get overrun quite quick.
So it was so it becomes necessary to leave the cradle of the earth.
Does that make sense in the logic?
As logic, sure.
OK. So.
The reason this becomes interesting is because
Sayelkovsky is basically the founder of the Russian space program
and the former Soviet space program.
And his rocket designs are currently like
I'm not not exactly the same, but
but are the forefathers of our current rocket design.
So you've got this link between kind of.
Quite fascinating and crazy.
Imagineries, so futurist imaginaries,
linked with technology, which ultimately developed the US space program.
But how does this link with Silicon Valley?
Well, if you look at, say, Ray Kurzweil said,
you know, Ray Kurzweil was kind of the profit for Google's AI program.
Is.
I think he's probably a chief engineer.
But.
He also believes in.
Moving towards immortality.
He wanted to be the first person to kind of end death.
So they've like a lot of these ideas
that came from Cosmism have been translated
directly into the kind of AI tech circles which circulate.
So so Kurzweil is a serious technical.
Player within the AI world, particularly in Google.
And this idea of extending life or eradicating death
is part of the discourse which circulates within within this community.
That that would be a kind of group
in which called themselves extra extra pianism,
extra pianist, so that's not sure how you say it properly.
But these ideas link directly to actual technical production.
So so things like the Fitbit and the quantitative self movement.
So the idea of like monitoring your health and maximising health,
which you must have come across because that's part of the kind of like tech
scene, human optimisation.
Exactly.
This human optimisation comes out of this attempt to extend life and eradicate death.
So you can see how the kind of Cosmism has kind of like
been kind of plagiarised really right into these kind of like tech ideas,
which then find themselves been sold on Amazon as Fitbit.
So various other optimisation technologies.
Kurzweil himself, in an interview in a film called
What was it? Are you man?
Declared that one of his driving force for developing artificial intelligence.
And you got to remember that this is a chief engineer.
Is to resurrect his own father.
Oh, my God.
So so so you've got Federer repeating himself
right at the top of the kind of Google development chain.
Oh, God.
And and taking a kind of slightly
a slight side move here.
But when we talk about artificial intelligence,
in tech circles, it gets broken down into
three different areas.
The first one's narrow artificial intelligence, which is what we
what we have at the moment, which.
It's mainly what we call machine learning.
So it's narrow in that it can do very intelligent
activities such as playing go or chess or predicting
texts, but in a very narrow domain.
But the next, like the state of them
of company like open AI
is the development of artificial general intelligence.
Now, artificial general intelligence is
in in Google AI terms, kind of the equivalent of human intelligence.
So it's this this ability to abstract
and apply intelligence to multiple domains.
So so it's wider.
But what what I kind of want to point out here
is that this idea of a general intelligence, which is
is what people are striving for, an artificial general intelligence.
When you look at what a general intelligence is,
then that's actually rooted in what
in the statistic statistician,
Charles Spearman and the idea of the G factor.
But Charles Spearman was a hygienicist
and his reason for developing
this ranking of general intelligence
was to rank human intelligence for selective breeding, etc.
So you've got this you've got this kind of
this drive for artificial general intelligence.
But when when you actually work out what general intelligence is,
it's got some very, very dark histories.
I mean, Spearman developed this to support his colonial
to support colonial policies, etc.
Trying to prove that perhaps other humans were less intelligent for various reasons.
So you've got this kind of hierarchical drive
within artificial intelligence for basically a superhuman
or an intelligence which is beyond human in that kind of way.
And just to kind of
just linking back to
the Cosmist kind of ideas,
you see that the idea of colonising the solar system
or spreading intelligence to the solar system
is is something which is a core concept
within AI development circles.
I mean, it's also the reason why tech billionaires
building their own spaceships, if you think of SpaceX, Blue Origin,
they're all they're all influenced by by these imaginaries.
It's like.
And I'm sure there's probably a lot of people saying I'm over exaggerating
this at this point, but I just want to give you a couple of quotes.
So so this is from
JÃ¼rgen Schmid, Schmid, who developed the natural language model,
which is used in Apple, Siri and Amazon's Alexa.
So let me let me just get this and so I can read it properly.
So this is this is his understanding of what he's doing.
He says,
So I'm not a very human centric person.
I think I'm a little stepping stone in the evolution of the universe
towards a higher complexity.
It is clear to me that I am not the crown of creation
and that human kind as a whole is not the crown of creation.
But we are setting the stage for something bigger than us.
That transcends us and we'll go out there in a way where humans cannot follow
and transform the old universe or at least the regional universe.
So I find the beauty and awe in seeing myself as a part of this much grander theme.
I've got another one for you if that's not enough.
Go on, hurt me.
This is this is Professor Dr.
Hugo de Garis, who was the former director of the China Human
the China Brain Project Institute for Artificial Intelligence.
And he writes,
Humanity has the duty to serve as a stepping stone towards building
the next dominant rung of the evolutionary ladder.
And Kurzweil himself says, does God exist?
I would say not yet.
Oh, God. Right.
So so what what what you get when you start digging into these these narratives
is the idea of of building intelligence, which goes beyond humans
and goes beyond our our time frame, our 70, 80 year limitation
and our body's limitation of living within certain environments like the Earth,
like our need to be within a kind of ecosystem, etc.
and can survive out there on the planets.
And it starts to feel like a spiritual movement
to to spread consciousness to to the universe.
So so the tech development, as as I said at the beginning, looks to the stars.
Whereas I think to solve this problem, we need to start looking back to the soil.
I'm so upset.
Sorry about that.
It's so upsetting.
I mean, I think we've got to I think we've got to be upset.
Yes. To to disrupt
and and start saying we need to change these imaginaries.
I mean, you've got to remember, I'm coming from an artist background
and I kind of do a lot of work within the tech sector.
But we have got to be able to create some imaginaries
which can compete with these kind of these
these dominant narratives which circulate within the kind of tech environment.
I have a I have a few things to say on everything you just said.
Number one, these men need therapy.
That is the sound like those are the words of
fairly traumatized people, I would say.
Number one, especially the buggers that want to, you know, resurrect their fathers.
I'm so sorry for your loss.
Please go and pay a therapist to therapist to walk you through it
rather than trying to develop a very energy hungry.
We don't know what would happen if we released it.
Intelligence thing.
Number two.
The other thing I find really interesting about it is like this.
Oh, no.
Number two, one funny thing before number three.
And that bit that you said at the end, when you were quoting these guys,
especially the, you know, I'm not a human centric person.
I consider myself a stepping stone.
It's not about me.
You could just imagine that quote being pasted on top of a
a cartoon of like one sperm cell talking to the other sperm cell
and it would totally fly.
It would be really in place there and which leads me on to point number three,
which kind of struck out to me.
And then what we will get into the imaginaries, of course, but like
in a culture that is so deeply individualistic,
there is like a lack of individualism in what they are saying in a sense.
And that's fascinating.
What is going on there?
I agree with you.
I think this is like there's a religiosity, religiosity
in what they're saying.
It's very culty, but like to.
This isn't fringe, though, by the way.
Oh, no, no, no.
These ideas are really, really move in these circles.
Yeah.
And I think the.
Yeah, that kind of spiritual that that link back to the kind of
cosmos linked to religion.
Is it is definitely there in that it gives people that goal
that like this drive towards AI.
Is is a bigger goal for these people.
So you're right, it's not necessarily that individual thing.
It's that they are seeing themselves literally forming.
Well, they said it themselves that the next stage in evolution
are spreading consciousness to the universe or ultimately creating God.
It's so it's funny because they managed to like make themselves
as small as sperm cells and yet be still incredibly arrogant.
Like the universe doesn't need you, you know,
ejaculating all over it with consciousness.
Likely there is consciousness everywhere.
So it's funny, isn't it?
Because there's like there's these interesting moments of kind of disruption,
even in the thinking of like lack of individuality in it.
And yet it's still so fundamentally hierarchical.
Like running with narrative domination.
That's why I was pointing out the AGI, the the the absolute link to eugenics in there.
Now, what was how does Charles Spearman link to them?
Is there like do we have a kind of because, you know,
we can walk through the Russian thing pretty clearly.
No, no, no, no, Spearman is general intelligence.
So if you if you look at the stated aims of open AI on their website
and and they will tell you that they are developing
that their aim is to develop artificial general intelligence.
And if you research general intelligence, that term is Spearman.
Right. OK. So that's where it comes from.
Yeah. And and and the G factor as a measure of intelligence.
So if we are measuring intelligence with general intelligence,
then we're already in the territory of.
Of eugenics as an idea.
I mean, I've got a feeling in this territory,
a eugenics which goes beyond the human and wants to develop the.
The the superior artificial.
Mm hmm. Mm hmm. Totally.
And I think this I can do a little linking of Silicon Valley
to Eugenics is thinking at this point,
which is the effective altruist movement,
which is very frightened of there not being enough babies
of a certain kind being born in the world, in an overpopulated world.
And so I kind of like, you know, Elon Musk is throwing money at reproduction
research. There's this like Silicon Valley couple that are planning on having
10 babies and inculcating those babies to have 10 more because they want
they literally want to replace, you know, sort of like,
I can't remember what it was exactly, but in a hundred years,
I think they could replace like 50 percent of the United States population
at that rate, essentially.
And and their purpose here is this.
Oh, well, because they believe that you should be investing in the top
one percent of humanity rather than the bottom, you know, 10, 20, 30.
Because it's the top one percent that are going to have the, you know,
intellectual reasoning and capacity to sort of fix the world really.
So there is a hierarchy of ability, capacity and intelligence.
Yeah. And we don't have enough of the smart ones being born,
which does equate to white, essentially.
Yeah, of course, because that that's also what the general
intelligence historically did anyway, with it within the colonial,
well, British colonial, I think, Spierman would like British.
I think you're working at King's, I'd have to reset.
I'd have to look that up again.
I mean, I mean, yeah, this, this, I mean, what you're saying there makes sense
with with the general shape of of thinking that I come across as well.
This is kind of like a shift towards like a super, super intelligence.
And then there's, there's either the direct mechanical group
or there's ultimately the developing the human
and kind of the cyborg and kind of shift, really, where
where you enhance the human to such a level that it becomes
the super intelligence that they seem to be the two, the two directions.
Yeah, that's so interesting.
I don't think I hadn't quite clocked that as being
sort of parallel tracks heading in the same direction.
The desire to, you know, birth as many superior humans as possible
and this drive to create this kind of, yeah, mechanical.
I mean, I mean, in my list of things such as
immortality, et cetera, I actually missed off the human augmentation.
But maybe I should have because human augmentation
is is definitely one of the things which comes up a lot.
The kind of cyborg is an Elon Musk himself owns Neuralink.
Yeah. Neuralink is is the company
which which aims to connect the brain directly to kind of computer systems.
So, yeah, those ideas of human augmentation kind of completely link in with
with this side, with this idea. Yeah.
I interviewed Olivia Luzard recently and she was talking about the fact
that Mark Zuckerberg has been quoted as kind of, you know,
you can't wait to like get rid of his body to get rid of
get rid of the weight of physicality.
I think it's get rid of the flesh.
Yeah, yeah, yeah, yeah, yeah.
And which, of course, links into this idea of like, oh, well,
if I can upload myself, then I can live forever.
Like, transhumanism, I think, is this stepping stone as well towards
towards immortality and then towards, you know, the ever expanding stars.
Yeah, those ideas are all all interconnect.
So in various ways.
But for me, yeah, the important thing is these ideas
aren't just crazy ideas of crazy people.
These these are ideas which are completely
embedded in the development of technology, of current technology.
Well, the idea what I was talking about earlier, the kind of
cyclic causality of of imaginaries and technology.
These ideas are part of the process of developing
our technologies and our future technologies.
So that's why I think as an artist and as a creative
that there's an important activist job to be done
challenging these ideas and and developing alternatives.
Which is kind of the second part of of what we do in our research
is kind of carrying out like workshops with with different communities of people
kind of discussing these ideas, but also trying to get people to
kind of think what what a different form of technology would be.
What a technology that does look to the soil that looks to biological systems
that that sees all species as intelligent and doesn't create this
hierarchy with with a
so-called conscious intelligence versus a non-conscious intelligence,
which you quite rightly picked me up on earlier.
Kind of like break down those ideas and recognize the entanglement
that exists between humans, other species, plants, the the biosphere.
Yeah, beautiful.
The interconnectedness, the oneness, which leads to a different kind of
you know, potential for the duality.
The multi oneness, the multiplicity, the entanglement of multiplicity,
which isn't a oneness, but but is entangled into.
Well, as we started started off kind of like
our actions do have an impact.
Let's talk then about some of these potential technologies
that look to the soil or what happens as well to our own kind of
thinking and processes when we look to the soil.
What have you found?
What's good is like working with other communities and getting getting
voices, which aren't normally heard within these environments.
And we've done a lot of workshops with.
Yeah, just all sorts of different people.
But one of the projects which has emerged out of this is a project
that I've been working with together with Shira Vashman,
which is trying to rethink AI with mycelium.
I think when I listened to your conversation with Maggie,
you raised the idea of mycelium, which I thought was interesting.
For people who don't know, mycelium is the organism which
it which produces mushrooms, ultimately, but mycelium
lives under the soil.
It's an interconnected organism of individual high fee,
which connecting to a network and the remain as that organism,
as long as there's no threat, as long as there's no food shortage of food, etc.
When when when there is a problem, when there's a say a temperature change
or the area where they're existing runs out of food,
they produce mushrooms, which then spar
and produce more mycelium networks.
But one of the interesting things about mycelium is the way that
it's evolutionary or some mycelium, because there's there's lots of different mycelium,
but some mycelium kind of work in a symbiotic relationship with other species.
So the the best example of this is the idea of the Woodwide Web,
which has been circulated quite a lot, which is the way that mycelium
connects between different trees within the forest.
And and sugars and nutrients are shared between different species
or between different trees within
a species.
So so mycelium works
in in symbiotic relationships
within the kind of forest environment.
And another example of the way it works, in vertically, it would be with the orchid.
So orchids
cannot photosynthesize while they are young.
So they couldn't exist, basically, while they are young.
But what they do is they create symbiotic relationships with mycelium,
which provides the kind of sugars that they require in their early stages.
And then when they when they mature,
they become a net producer of sugars, which feeds the mycelium.
So you get these kind of symbiotic relationships
developing micro-risal networks between different species.
And
so by working with people
taking mycelium as a starting point,
we've kind of been
kind of looking at at the way if if we were if we were going to think of a technology like AI,
what would that look like?
And I think the question that emerges from
from our rethinking AI with mycelium
is
I'm going to read this, sorry.
Go for it.
Is a what if AI significance lies not in competing with us,
supplanting or surpassing us in a mainstream AI narrative as in mainstream AI narratives,
but in fostering complex, ecologically sustainable symbiotic relations with both mechanical and
dogonic intelligences.
We suggest the study of AI should involve a redress of our relationship to other non human
intelligences on the planet.
So that's the kind of
the kind of
outcome that we're kind of developing with
rethinking AI through mycelium is to kind of shift it away from the kind of
hierarchical model that we've been discussing and towards
rethinking intelligence in this kind of wider way and how can we connect to
these intelligences in rather than a
combative survival of the fittest
eugenicist kind of model.
But rather in a model of symbiotic, I suppose,
solidarity.
And what would these technologies look like?
So I think one of the first things is that we've got to understand the impact that
computing, obviously I'm coming from an AI computing background, so this is important to
me, the kind of impact that computing itself has on the world.
So computing itself contributes to global heating and environmental degradation.
I think on some recent research that I read in Nature magazine,
it stated that the IT industry could use 20% of all electrical production by 2025,
given that's next year, that's a lot.
And that 5.5 of the world's carbon emissions comes from 5.5% of the world's
carbon emissions comes from basically the global IT industry.
Now, that's bigger than most countries by, say, China and India, U.S.
extract, that's the big countries.
So we've got to take these ideas seriously.
And so if we're going to continue developing computer systems, then we've got to think
of how to create a sustainable computer.
And there's quite an interesting movement called permacomputing, I don't know if you've
come across it, but permacomputing is it kind of takes permaculture as a model, but looks
at how we can develop computing in a kind of sustainable and a kind of viable way, kind
of moving away from this ever-growing storing of data within data centers, which use mass
amounts of electricity to keep them cool, and also has an impact on water as well, because
water's used in these kind of large data centers.
Many of which, the storing of mass data is the reason why we're storing mass data is
ultimately to train AI models, to train machine learning models.
It kind of comes round in a circle to some level.
The kind of the form of computing that we are developing, storing all of this data in
the so-called cloud, is ultimately collecting the data that is required to train mass machine
learning models to develop the AI.
So how can we shift away from this kind of circular model to one where we can use computing
perhaps to help solve some of the problems that we have, we're having with the environment,
but that kind of computing itself needs to be developed in a way which is sustainable
with the environment.
So that's the kind of thinking that we are trying to develop with our practices.
Wonderful.
This is kind of the reckoning of all industries of this juncture in history, isn't it?
How to get away from our legacy, essentially, and reimagine entirely new ways of being in
order to survive ourselves.
I think that the ultimate job at the moment is to create these imaginaries, to create the
imaginaries so that we've got something to drive for and develop the technologies that
allow for its existence.
By technologies, I use that term broadly.
My ceiling itself can be a technology.
If we can use it as a way to understand what's going off within the forest ecology, it is
a computer system itself, or a computing system itself, that if we can learn to understand
and read.
I don't mean instrumentalizing, I mean in a kind of non-destructive way, then that's
kind of an interesting way to kind of move forward, I think.
Definitely.
I think the third thing we maybe need to bring in at this point, though, is as you spoke
about the circularity between the ideas and the tech and how they inform one another.
We've also got to add in for-profit motive and private ownership and the competitive
market.
That very first artificial intelligence that you spoke about at the beginning of this interview.
Whether or not it is possible to, not to reimagine, but to actually create the sustainable
solidarities necessary when that artificial framework will be, sorry, when that artificial
intelligence will be moving to shut those kinds of things down.
Yeah, absolutely.
I mean, I think within our project that we've been working on, particularly the rethinking
AI with Mycelium, is we've got to think about, if we are developing intelligence, if we were
developing AI, then we've got to think about the particular environments that AI has been
brought up in, what sort of ecosystems we are raising and developing artificial intelligence
in.
Currently, it's this kind of aggressive, domineering, environmentally destructive, competitive
environment.
If you think of the way machine learning is where it's currently used, high-speed trading,
etc., then it's all about systems of winning and losing, of profit and loss, etc.
So what would an artificial intelligence look like if it was developed in a symbiotic relationship
like a Mycelium?
I mean, I've actually got a good quote from this from Tim Ingold, but thinking through
the social and the way the social is structured, I think has to play a massive role in our
rethinking, say, the market.
Let me just find this quote from Tim Ingold, because it would fit here really nicely.
Please.
I've got it.
Where's he gone?
Here he is.
Okay.
So what Tim Ingold wrote in his book Lines a Brief History is, and his dad was a mycologist,
so this is probably why he's kind of talking about Mycelium, but what if we take the Mycelium
as our exemplar of the organism, arguably, the oil of biological science would be different
and so too would the science of society be different, where every person to be considered
like the Mycelium as a thing of a line and the social as the domain of their entanglement.
So I think what he's arguing for here is a breaking down of that neoliberal individualism
that is so dominant within our culture and to see ourselves both entangled with each
other, but also in a species relationship with the planet itself, like how would we
develop science and technology if we could, if we saw the world in these terms of entanglement.
And I think that's quite a good imaginary to kind of base our technology on.
So the image for me that came to mind was a weaving, a weaving of threads, a braiding,
which kind of like...
It's not a loss of the individual to the mass, but at the same time, it's not a separation
of the individual from the mass, it's a layer weaving textiles, that's I think a good way
forward.
Beautiful.
I think if all of reality is relational, which it is everyone listening, it just is.
And then the more that you braid and weave these relationships, the more that you are
literally reinforcing the structure of reality in a good way, you're fortifying it with that
entanglement.
And I think that's...
I think that's a beautiful note to end on, John.
Yeah, brilliant.
Yeah.
I've so enjoyed this.
Thank you so much.
I have as well.
It's a bit of a crazy journey, aren't we?
But a good one.
Hopefully from the stars back to the soil.
Yeah, exactly.
Rewind people.
Let's bring it back.
My final question for you is, who would you like to platform?
Okay.
So the person I'd like to platform is an art activist called Jay Jordan.
So Jay Jordan is perhaps the most committed art activist I know.
He played an important role in the activist movements, Reclaim the Streets, and was one
of the founders of the laboratory of insurrectionary imagination and the clown army.
And he kind of lives resistance daily in the occupied zads in France, the kind of...
So hopefully we can get him on and he can take some of these imaginaries forward in a
way of how we can actually take them into the streets and into the fields and turn them
into direct action, which he's amazing at.
Oh, that is just wonderful.
I can't wait to speak to them.
John, thank you so much for today.
It was just great.
If you want to learn more, I've put links to everything in the description box below.
Remember to subscribe to the channel if you're new here and share the episode if you enjoyed
it.
To support the show, subscribe at planetcritical.com where you can read the weekly newsletter
inspired by each interview.
You can also become a Planet Critical patron.
All links are in the description box below.
As always, my deepest thanks to that community.
Planet Critical wouldn't exist without your support.
Thank you everyone for listening and for coming on this journey together.
Thank you.
Bye.
