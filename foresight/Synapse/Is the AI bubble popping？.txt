The promise of AI has led to a flood of investment, but the chaotic rise has produced a dramatic
stretch of events.
A heavily funded startup led by a leading AI entrepreneur gets stripped for parts, severe
instability threatens a promising open source company, and revenue from a leading generative
chat startup points to a reality the industry has to face.
Is this the beginning of a broken AI startup landscape?
Is it a sign that AIR is coming out of the AI funding balloon?
And what does all of this mean?
For the future of AI?
Some optimistic researchers and economists claim that AI has the potential to supercharge
growth to 20% a year, a significant bump from the 3.2% growth average the US has experienced
since World War II.
If that supercharged growth materializes even slightly, that's an amazing change in society.
A Northwestern economist found that the typical American is 100 times richer than in 1870
when growth was stalled at 0%.
With growth at 20%, the typical American would be a thousand times richer than they are today
in a relatively short time window.
This is the promise of exponential technology meeting exponential times.
But there's a lot of things that would have to go right to meet that growth dream.
And AI is entering a turbulent phase in the hype cycle.
The head of Amazon Web Services, Adam Salipsky, who has overseen much of the company's massive
investment in generative AI, has made connections to the dot-com bubble of the early 2000s.
The internet in the long term was underhyped, but a slew of companies trying to cash in
were gravely overhyped.
And those companies led to a bubble that popped, hurting everyone else.
We may be at the point where the needle is starting to pierce the balloon, with three
big examples to investigate in this video.
We're going to start with stability AI.
Emod Mestak started stability AI in late 2020, and based on research from a project called
latent diffusion, stability released a model called stable diffusion in August 2022.
The model used a denoising process in its architecture that enabled unique image generation.
The result was a really effective open source model capable of creating great images and
enabling users to train the model on their own dataset.
Stability AI raised $101 million at a billion dollar valuation in 2022, just days after
launching stable diffusion.
Buied by AI interest and a growing base that featured tens of millions of active users,
2023 promised to be a big year for the company.
And Emod had an engaging vision for what AI could do for the world.
If we do it right, then we can really uplift the entire of humanity, which I think is pretty
crazy and pretty awesome.
It's the first time we've ever had the tools to do that.
He wanted to create AI models that could help governments, poor and underserved communities,
and aspiring entrepreneurs across the globe.
And he took zoom selfies with Microsoft CEOs.
Emod was ambitious and creative, but also unfocused and unprepared.
Stability has had serious issues across business operations, funding and talent retention.
The company was burning through cash at an alarming rate next to the compute needed to
power its models and overwhelming research spend.
In 2023 alone, stability spent almost $100 million on cloud services and the company
generated a grand total of $11 million.
Unpaid debts started to accelerate.
Stability was $1 million short of its AWS bill in July 2023 and didn't even have a
plan to pay the $7 million it owed for its usage in August.
They're kind of lucky Amazon doesn't run on mafia rules.
It also had an outstanding bill of $1 million to Google Cloud and $600,000 to GPU data center
CoreWeave.
Despite this foundational financial issue, Emod continued to make promises he couldn't
keep.
He told prospective customers, including the Singaporean government, that he could deliver
custom national AI models within 60 days.
All of us are engaged with governments.
We're trying to help them.
It's a bit difficult when they're just catching up to the internet right now.
The timeline was untenable and confused the company's leading researchers.
Stability was unable to develop a model for Singapore, which never became a customer.
A viable business model was failing to materialize.
They tried to monetize through an API, then a managed service arm, both of which have
struggled to gain traction and the service may have infringed on their contract with
AWS.
Emod scrambled to come up with funding that would pay off debts and retain talent.
In July 2023, he shared a plan to raise $500 million in cash and $750 million in computing
credits from marquee investors like Nvidia, Google, Intel, and the World Bank.
However, most of these investments did not materialize, with only a small fraction of
the targeted funding being secured.
The debts and empty promises led to an even bigger issue.
These at Stability AI grew increasingly unhappy with the company and its leadership.
The whiplash shifts in priorities and resources, often based on Emod's changing whims, demoralized
and infuriated workers.
Projects were abruptly reallocated and researchers were reassigned.
One former executive described Emod as the most disorganized leader I have ever worked
with in my career.
Problems over the company's financial situation and Emod's leadership led to a steady stream
of executive departures.
Some departed over worries about cash flow and potential legal liabilities, such as Emod's
reportedly lax approach to preventing the generation of sexually abusive imagery.
The final blow came in March 2024 when the star research team behind Stable Diffusion,
including lead researcher Robin Romback, turned in their resignations.
Other senior leaders issued an ultimatum to Emod, resign or they would walk as well.
The departure of the researchers, widely viewed as the company's crown jewels, underscored
the depth of dysfunction and discontent within Stability AI under Emod's leadership.
Just days later, Emod announced that he would step down as CEO, claiming he wanted to decentralize
power in AI.
However, sources say he fought to maintain control until the very end, despite mounting
pressure to leave.
Emod also resigned from the board, which has initiated a search for a permanent replacement.
The temporary leaders put in the role have inherited a company in crisis.
Stability continues to burn cash much faster than it generates revenue, making only $5.4
million in February 2023 against $8 million in costs.
It faces ongoing concerns about making payroll for its 150 remaining employees.
Just existentially, Stability has been hit with a trio of copyright lawsuits alleging
its AI models were trained on unlicensed art and photography.
The litigation could drag on for years and threaten the entire generative AI industry
if Stability puts up an insufficient fight.
Once flush with over $100 million in funding, Stability is now in a deep hole, needing not
just more cash but a viable business model in a fast-moving competitive space.
Some employees have expressed optimism that Emod's exit could make the company more appealing
to investors or acquirers, but after his disastrous tenure, any savior will have their work cut
out for them to write the ship before the money runs out.
The entire Stability situation points out some really key takeaways about the state
of the AI industry.
But first, be sure to subscribe so you can catch all of our deeply researched videos
on artificial intelligence.
And if you have an opinion, we'd love to chat with you in the comments.
So far, our audience has brought up some great points, so be sure to check it out.
1.
Open-source models without a strong underlying business can be tricky to monetize.
Stability diffusion's open-source nature allowed it to be used by millions worldwide
in a highly creative way.
But Stability struggled to translate this popularity into a sustainable revenue stream.
The massive computational power required to train and run AI models is costly.
Stability's expense is far outpaced its revenue.
You need not only strong upfront funding, but a clear path to monetizing.
Popularity alone won't keep the boat afloat.
2.
AI ethics need to be smartly thought out and readily addressed.
The beauty of the models that Stability has released is that they put full creativity
in the hands of the users rather than keeping them in a system with strict guardrails created
and enforced by tech giants.
But there's also pretty clear drawbacks in the form of explicit and illegal content.
Furthermore, Stability hasn't had an overwhelmingly strong response to the copyright infringement
claims made by Getty Images and others.
3.
Talent acquisition is the name of the game right now.
With a floundering business plan, insufficient funding, and a lack of direction, great talent
from research to business operations will leave.
This brings us to the ultimate example of the AI war for talent.
Inflection AI.
Inflection came out of nowhere to raise $1.5 billion and launch a chat GPT competitor.
At the time, the $1.5 billion was the third largest round in the space, right behind Open
AI and Anthropic.
Now, it's stripped to the bones, and most of its key talent went to Microsoft.
This is the story of an unexpected acquisition that technically didn't happen.
Mustafa Suleyman is one of the most influential figures in AI.
Much of his mass influence comes from a great book called The Coming Wave, highly suggested,
which details the convergence of exponential technologies like AI, robotics, biotech, and
more.
In fact, their fusion will have on the world.
Based on his experience forming DeepMind, which eventually sold to Google in 2014 and
gave the company an AI boost, Suleyman co-founded Inflection AI in 2022.
The company quickly raised over $1.5 billion from big name investors like Microsoft, Bill
Gates, Eric Schmidt, and Nvidia at a valuation of $4 billion.
Suleyman's flagship project was Pi, an AI chatbot focused on providing emotional guidance
and companionship for users.
They also poured money into infrastructure, amassing 22,000 expensive Nvidia H100 GPU
chips, which recently just got outdated with the announcement of the new Blackwell chips.
Pi wasn't the original product that Suleyman imagined and pitched at the start of Inflection's
funding.
The big idea was creating an AI chief of staff for businesses that could carry out many of
the tasks across an organization that require adept staff planning, HR prowess, and a certain
level of emotional intelligence.
Pi was the first iteration of what that could look like, but its use case diverged quite
aggressively from something that would be integrated into a business.
It struggled to gain traction with consumers in the crowded AI chatbot market.
Then within a year of its bloated funding round, Suleyman, his co-founder, and many
key team members left the company to join Microsoft, and Suleyman would be named the
head of their consumer AI.
This move was highly unusual.
Typically if a company wants all of the key talent from a company, they'll buy it and
integrate the people or make it a subsidiary, but Microsoft didn't have to do that and
were able to bring on everyone that they wanted.
As for inflection, Microsoft agreed to pay the company $650 million to license the company's
technology as long as they agreed not to sue over Microsoft's hiring of its top talent.
This also allowed Microsoft to provide somewhat of a positive outcome for initial investors,
paying out $1.5 times the investment for the funders in the first $225 million round,
and $1.1 times the investment for those who participated in the round that was well north
of $1 billion.
As for what's left of inflection's business, they have pivoted to an AI studio helping
companies work with large language models, but then again, it's just a shell of what
was left.
There's a lot to dissect here, but let's start with Suleyman.
His book details some of the perils associated with AI that advances too quickly and without
guardrails.
He also makes a claim that it's unlikely that massive companies, such as, hmm, Microsoft,
move too slowly to curb potentially dangerous AI advancement, is becoming the head of consumer
AI at Microsoft his best chance at ensuring a safe AI future, or a damning example that
the economic drive to create bigger, better and faster, whittles away at the key values
held by AI thought leaders.
Then there's the Microsoft part of this.
Overall, it's an example of how their CEO, Satya Nadella, plays the game like a chess
grandmaster.
He's been able to situate deals that keep key investors happy and accelerates his company's
AI ambitions.
He has built up a trove of impactful AI models running through his cloud, including models
from open AI, Mistral, and now inflection.
The creative acquisition is likely to come under scrutiny from the US government, which
is looking to prevent potentially monopolistic acquisitions and investments Microsoft has
carried out in the generative AI space.
While they avoided a lot of red tape that would follow an outright acquisition of inflection,
it matches many of the beats of an acquisition.
The government has already put Google and Apple under a close monopoly microscope.
There's also an open AI part of this worth noting.
Remember the insane couple of days when the open AI board kicked Sam Altman out of the
company he built?
At the time, Nadella moved quickly to offer Altman and his loyal followers at open AI
a home to continue their work at Microsoft.
Even though that backup plan never panned out and Altman returned victoriously to his
company, the event clearly led Nadella to rethink how he approaches the risk of relying
on a single AI innovator.
By adding Suleiman and inflection's key talent, Microsoft has mimicked the game plan they
set up in a time of crisis and bolstered their in-house efforts.
Microsoft has spread out its bets rather than putting all their chips in the open AI basket.
For open AI, this could diminish their leverage and their $85 billion valuation.
The biggest and most important takeaway from the inflection situation is how competitive
the AI talent market is.
Tech Titans are offering huge compensation packages and equity to lure the best in the
industry to their projects.
They've even tried some personal tactics.
For example, Meta's Mark Zuckerberg has been personally crafting emails to some prospective
employees to show how committed he is to bringing them on board.
Google's Sergei Brin has reached out to employees that have left the company in hopes of getting
them to come back.
The overall pay range for AI talent has risen about 40% across the board.
Even those new to the industry with recent PhDs are getting salaries in the $800,000
range from open AI and Anthropic.
When things are this competitive and expensive, it may become a common tactic for the big
companies in the space to dismantle promising startups and consume their best talent.
For the future of AI, that's probably not a great thing.
Startups inject energy, competition, and innovation into the market and diversify power away from
incumbents.
This benefits users and therefore, in something as important as AI, the future of humanity.
The talent, models, and compute being stored in the hands of only a few companies threatens
a vibrant startup market and the story of inflection has so far demonstrated that path.
It's important to note that both stability and inflection are side effects of unsustainable
core business models despite huge funding.
This brings us to Cohere, which mimics much of the leading player's approach to generative
AI chat.
The Canadian AI startup was founded by some of the Google DeepMind researchers that pioneered
the transformer model, which has defined the current generative AI architecture.
They've attempted to position Cohere as the go-to enterprise AI chat provider.
Their models are customizable through fine-tuning and other techniques to provide businesses
with fast, accurate, and relatively cheap AI chats.
Their models also branch into business search solutions, classifying, and other functions
that have become mainstream offerings from LLM providers like OpenAI and Anthropik.
The startup has raised $445 million and is seeking new funds that would push their valuation
to $6 billion.
But there is a huge, glaring issue that needs to be addressed.
The company brought in only $13 million last year.
That means the new valuation would be 450 times its annualized revenue.
In comparison, OpenAI generated 130 times what Cohere made last year.
And its beefy $85 billion valuation was a far more reasonable but still insane 50 times
annualized revenue.
And it's not like Cohere's product is bad, or it has struggled to onboard customers.
They're just playing a very expensive AI chat game that has some unclear economics.
This brings up a really key question that will define the next wave of AI investment.
Is generative AI a money pit?
That says nothing of its effectiveness or the incredible power of generative AI or the
fact that you should learn everything you can about AI as fast as you can.
But does it make sense for investors to keep pouring money into what has so far proven
to be an expensive endeavor with a shaky business model?
The answer could be a resounding yes.
And if AI is the definitive technology of the future, then throwing money at companies
leading the charge is a short term pain that could result in a huge windfall.
But that was also the thinking among many investors in the dot com bubble, as noted by the head
of AWS which has poured billions and billions into the generative AI race.
When the tide goes out, once promising startups with poor underlying financials or vision
or leadership or zoom selfies, go under, no matter how impactful the tech is.
So what do you think?
Are we starting to see the shoreline recede?
