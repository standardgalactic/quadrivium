This is a presentation, a competing light essay on the Unit Lama. We will be covering
some very basic category theory with minimal formulae involved. Everything in this presentation
is very much simplified as it is just an introduction. So with that out of the way,
let's begin.
Here is a formal definition of a category. Don't worry about reading it, we'll be going
through it soon, bit by bit. But many structures and mathematics come alongside some notion
of maps, which are used to relate different objects with those structures. For instance,
groups come alongside groups of morphisms, vector spaces of linear transformations, probability
spaces of measurable function, and topological spaces with continuous maps to name a few.
A category is a collection of objects with arrows or maps between those objects called
morphisms, and that's it.
All of the previous examples are thus specific types of categories, and many common constructions
in all of these fields do not actually rely on the specifics of that field, and can be
carried out and unified together when at a level of a category. Most common of these
constructions are products and co-products, direct sums, kernels, that kind of thing.
We unfortunately don't have the time to cover these things in particular detail, but it's
a good motivation as to why category theory is studied. Oh, and it's also important to
type theory in functional programming.
We begin with objects.
An object can be really anything we want, but we often work with mathematical objects,
such as numbers, or sets of numbers, often with additional structure on top, like groups
or fields.
The collection of objects in the category C forms a class called the object class of
C, and note that there are set classes that are not set. This is because these collections
of objects don't usually count as sets under ZFC. For instance, the set of all sets would
be disallowed on the set of C, but such a collection of objects is useful to use in
category theory anyway, so we use classes instead.
Next we have morphisms.
For any two objects, A and B, we can have a morphism between them. It can be helpful
to view a morphism as a type of directional relation. There is a morphism F from A to
B if A is related to B, but B does not have to be related to A, and we write this to note
this relation. We can also have multiple morphisms from A to B if A and B are related in multiple
ways. We could also be the case that A and B are not related at all.
For any two objects, A and B, the collection of all these morphisms forms the homset of
A and B. In the case where A is not related to B, this homset is empty. And because morphisms
are directional, note that the homset of A and B is not the same thing as the homset
of B and A. And again, despite the name, homsets do not necessarily count as sets. We'll largely
be ignoring this distinction in this introduction, as the categories we construct will be locally
small. This means that the class of morphism between any two pairs of objects does happen
to be a set. If the object class is also small, then the category itself is called small.
The collection of all homsets in the category C is also written like this.
Of course, now that we have things that point from one object to another, we're going to
be able to combine them. So, if F is morphism from A to B, and G is morphism from B to C,
then we'll require for that to exist a composition morphism from A to C.
Compositions have to obey two axioms, the first one being the identity axiom. For any object
A, a category requires an identity morphism from the object to itself that follows a few
constraints with respect to the composition. Identities must compose with any other compatible
morphism and leave them unchanged. They're the neutral elements of composition, just
like zero for addition or one for multiplication. The second axiom is associativity. It just
states that the composition is associative, nothing special there. So, these are the things
that a category can post off. Let's go through a few simple examples.
Let the object class of C contain A, so the category only contains a single object. Categories
require identities, so we have that in as well. But the identity morphism by itself trivially
satisfies the identity and associativity axioms, so this category is called the trivial category.
And apart from the trivial category, we usually omit the identity morphism from these diagrams.
Let the object class of C contain A and B, the homset of A and B contain F, and the homset
of B and A be empty. This is the arrow category, consisting of a pair of objects and a single
morphism between them, pointing in one direction only.
So let's move on to some more interesting examples.
Let G dot be a group, and let the object class of C contain a unique object X. We set the
homset of X to X equal to G, and define the composition of F and G to be G dot F, so morphisms
have group structure and the composition. Because groups require associativity and identity,
the morphism axioms are satisfied, and we see that a group is really a miniature one
object category. In fact, there's nothing really specific about groups here, we could
have started with a monoid or any other algebraic structure that has identities and associativity.
So these last few categories are pretty simple, but they give us an idea of how basic categories
can be. We visit a few more important categories now.
We have set. The category of sets and set functions. Objects are unsurprisingly sets,
and morphisms are functions between those sets. Identities are just the identity function
on each set, and the identity and composition axioms follow from the basic properties of
the functions. We also have group, the category of groups, and group homomorphisms. The morphisms
are just functions that happen to express group structure, so identities and associativity
are inherited from set. We have top, the category of topological spaces and continuous maps.
We have vector sub k, the category of vector spaces over a field k, and linear transformations.
These last few examples might give the false impression that objects are always sets, perhaps
with extra structure, and morphisms are functions that preserve that structure. This doesn't
have to be the case. We build another simple example of this now.
The objects in our categories will be the real numbers, and we define the morphism from
x to y if x is less than or equal to y. The problem here is that we can't really say
what a morphism is. It's not a function that acts on anything like a function in set, and
in fact it doesn't seem to do anything at all other than existing whenever x is less
than or equal to y. The morphisms f and g imply that x is less than or equal to y, and
y is less than or equal to z. So we have x is less than or equal to z by transitivity,
so there is this morphism to assign the composition of f and g.
We also have x is less than or equal to x for all real numbers x, so identities also
exist. Associativity and identity axioms are also easy to verify. So the set of real numbers
equipped for the non-strict ordering is a category. And again, there's nothing specific
to the real numbers here, so any set equipped for the non-strict order is in fact a small
category.
Given some existing categories, there are two ways to construct new categories that
are of interest to us. There are more, but these are the two that I want to talk about.
So if you have categories c and d, we construct the product's category by taking the Cartesian
products of their object classes and by matching up compatible pairs of morphisms from the
original category. This looks a little complicated, but basically, if you have a morphism f from
a to a prime and c, and a morphism g from b to b prime and d, then in the product category
c cross d, we have the morphism fg from av to a prime b prime. We just take pairs of
objects and compatible morphisms between them in the original categories. Next, given
the category c, we construct the opposite dual category c op by reversing the direction
of all the arrows in the category. We note that this operation is an involution, so
the dual of the dual of a category is just the original category, because just reversing
the arrows twice just gives you the arrows back. This leads to an interesting theorem.
The principle of duality states that every categorical definition and theorem has a dual
definition and theorem obtained by reversing the direction of all morphisms in the category
involved. We often prefix a dual notion with co, such as products and coproducts, or domains
and co-domains. The proof is pretty simple. If a statement holds in the category c, then
the dual statement holds in the dual category c op. For every category is the dual of its
dual, so the dual statement also holds in all categories, as required.
We've already been using arrows to show morphisms between objects, but we can do a lot more
with these diagrams. If we take a selection of objects in a category and draw morphisms
between them, then we can compose morphisms by following a path through the diagram, because
of associativity each path corresponds to exactly one composition morphism. This is
useful enough by itself, but certain diagrams have an additional helpful property. A diagram
is commutative if for every pair of objects in the diagram, all roots between them are
equivalent. For example, this diagram here is commutative if and only if h is equal to
the composition of f and g. Now, suppose we have objects a and b in the category, and morphisms
f and g are such as this diagram commutes. That is, f composed of g is the identity on
a, and g composed of f is the identity on b. Then, f and g are called isomorphisms, morphisms
with inverses, and we alternatively label g as f inverse. If a life morphism between
a and b exists, then we write this symbol to denote this relation. A nice morphism is
the mathematical way of saying that we only care about some specific property of an object.
You've probably heard that a topologist cannot tell a difference between a coffee mug and
a donut. This is because in top, these two objects have the same number of holes, a topological
variant that does matter in top, and they can be bi-continuously and bijectively deformed
into each other. So, they're isomorphic.
One central theme of category theory is the idea of mapping between objects. Whenever we
encounter a new type of mathematical object, we should always ask if there is a sensible
notion of a map between them. But of course, categories are also mathematical objects we
can ask this question on. Let's see in the eb categories. A functor, f, consists of
two parts. A mapping on objects, and a mapping on morphisms. The object mapping just maps
objects x in c to an object fx in d. Nothing unusual here. But the morphism mapping maps
morphisms in c to corresponding morphisms in d, as in the morphism has the corresponding
objects not at the end, as defined by the object mapping. But this mapping is subject
to constraints. Basically, functors have to send identities
to identities, and they have to preserve compositions. As a consequence of this, functors
preserve the connectivity of diagrams. We're not going to cover the proof here, because
this is just a bit of algebra and it's chasing symbols around, but it follows quickly from
the second constraint. In particular, functors preserve isomorphism diagrams, so if f is
an isomorphism in c, then f of f is an isomorphism in d.
This definition is rather long, so more concisely, we can say that each pair of objects a and
b induces a mapping that respects the structure of the categories. So, functors act as morphisms
between categories. They compose by composing these induced functions, and identities are
just the identity functors from a category to itself. This suggests the construction
of a category where objects are categories, and morphisms are functors, and indeed we
have cat, the category of categories. We also have little cat, the category of small categories.
This is a sub-category of capital cats, but we're not going to go into that at the moment,
because there's way too much to cover. Now, for a small bit of terminology, the
functors we've been considering so far are sometimes called covariant functors. A covariant
functor from c to d is just as shown here. This is in contrast to a contravariant functor.
A contravariant functor from c to d is just a functor from c op to d. So we would say
that the upper functor is a covariant functor from c to d, while the lower functor is a
contravariant functor from c to d. This is mostly just a terminology slash notation
thing. Like, if we're working with a named category like set, it might make more sense
to say that a functor is covariant than to start writing set op everywhere. We'll give
a few specific examples of functors now. A forgetful functor does nothing to the objects
and morphisms in the category, apart from forgetting some additional structure that
mattered in the original category. For instance, we have the forgetful functor from group
to set. Every object between group is a group, that is, a set to g with some extra structure
in the form of a binary operation and a set of axioms. The forgetful functor u forgets
this extra structure on objects, mapping groups to their underlying sets, sets which are
just objects of the category set. Similarly, morphisms in groups are group from morphisms,
which is just set functions that happen to respect this extra structure. Forgetting
that extra structure still leaves a normal set function, or a morphism in set. Forgetful
functors don't have to get all the structure on the object either. Consider a ring r. Mapping
r to the underlying set s yields the forgetful functor from ring to set. If we keep addition
and the additive identity, we get a functor from ring to the category of abelian groups.
If we forget commutativity on top, we get a functor from ring to group.
Let g start to be a group, and it approaches the category c with the unique object x. We
will construct a covariant functor f from c to set. We only have one object in c, so
we choose a set s to map x to. Every morphism g must be mapped to a function f or g from
s to s in set. However, we still need the functor axioms to be satisfied. There are
two natural ways to do this. We can either define the function f for g by left multiplying
by g, or right multiplying by g. It should be clear that the two functor axioms are satisfied
by either definition, so this choice is rather arbitrary, but we'll pick the upper option
here since it more closely matches the existing notation. We can really interpret this mapping
to be a two-argument function, taking a morphism from g and then elements little s from s and
returning their products. So, f is determined by the choice of a target set, s, and a function
from g cross s to s. We can then see that a covariant functor from a group to set is
really just the left action of a group on some set s, or a left g set for short. For
a contravariant functor, we just pick the other mapping, so a contravariant functor
is a right g set. So, as we said earlier, whenever we encounter a new type of mathematical
object, we should always ask if there is a sensible notion of mapping between them. Well,
functors are mathematical objects, and can we map between functors? Yes, of course we
can. These are actually called natural transformations.
f and g in each map are objects in morphisms and c's, objects in morphisms and d. To define
a mapping from f to g, we want to associate objects in morphisms and d in maps by f to
objects in morphisms and d in maps by g. So, first, consider the effects of f and g on
a single object, x in c. x is mapped to two objects, fx and gx in d. Since we're trying
to define a map from f to g, it would seem sensible for us to associate these two objects
together. But since fx and gx are just objects in the category, such a relation is just a
morphism in d. So, eta maps each object x to a morphism from fx to gx, called the component
of eta at x. However, we should recall that there are possibly many morphisms in the home
set of fx and gx. So, which one should we pick? To help us decide, consider a morphism
f from a to b in c, in a left there. The top and bottom are just the same diagonals before,
they've just been skewed slightly, so we can draw other morphisms in. But under f and g,
we have two additional morphisms, f of f and g of f. Probably should have picked different
letters here, but we'll work with it. So, we want to relate these two morphisms under
our natural transformation, since looking from f to g. We also have two morphisms we
want to assign to the components, eta a and eta b. These morphisms we can control, these
are the ones we're trying to pick. But on the square on the right, there are two paths
from f a to gb, we can either take the upper route or the lower route. If the components
are assigned arbitrarily, these paths are not necessarily equal, and there could be
many such possible paths. But we can use this to relate f of f and g of f by requiring that
there's quite a commence. This is called the naturality requirement. So, overall, a natural
transformation is just a collection of morphisms in the target cascary, indexed over objects
in the source cascary, such as this diagram commenced. Now that we have the notion of
mapping between functors, we want to compose them, so how do they compose? Consider the
following setup. Here, c and d are categories, f, g and h are functors, and alpha and beta
are natural transformations. From the diagram, it would seem sensible to define the composition
of alpha and beta to be a map from f to h. Such composition of natural transformations
is called a vertical composition. There's also a notion of horizontal composition,
but it's not super relevant to the construction we're leading up to, so we'll leave it out.
Consider an object x in c. Two components of alpha and beta are alpha x, from f of x
to g of x, and beta x, from g of x to h of x. Because these are just ordinary morphisms
in d, they can be composed according to regular morphism composition rules, so we define the
component of the composition of alpha and beta at x to be this composition. We still
need to show the naturality of this new composition transformation, but that's simple enough.
We just glue two naturality diagrams together. Because alpha and beta are natural transformations,
they individually satisfy the naturality requirement, so each square commutes individually, and
hence the diagram as a whole also commutes. So this composition is natural, as required.
Putting the components together, we get this definition of the vertical composition. With
this, it's clear that identity natural transformations leave other natural transformations unchanged
on the vertical composition, as one of the components will just be their identity.
Friendly to categories, we can now define functors between them, and natural transformations
between those functors that obey the morphism axioms. This suggests the construction of
a new category. For two fixed categories, c and d, we construct the functor category
by taking objects to be functors from c to d, morphisms to be natural transformations,
composition of morphisms to be vertical compositions of natural transformations, and identity morphisms
to be identity natural transformations. Recall the isomorphism diagram. Here, a and b are
objects while f is the morphism. If we take the case of a functor category, we have this
instead. Now, objects are functors, and morphisms are natural transformations. In this case,
we say that f and g are naturally isomorphic. Because this is just an isomorphism in a particular
type of category, we reuse a notation and we write to this. We also say that f is isomorphic
to g naturally in x whenever we need to bind a variable. Note that this is very different
than these objects being isomorphic for all x. The upper statement is a statement about
the functor's f and g, while the lower is a statement about the objects in the target
category. f of x and g of x being isomorphic naturally in x is a far stronger condition
than f of x and g of x being isomorphic for all x. It could be the case that these objects
are indeed an isomorphic, but there doesn't exist a natural transformation from f to g
at all. But natural isomorphism doesn't imply that every pair of corresponding morphisms
are isomorphic as well, so this is actually an implication. And in fact, if we're given
a natural transformation from f to g, then this implication is biconditional. Suppose
we wish to study the properties of an object a in a locally small category c. One way to
do this is look at a from all of the possible objects in an examinate that way. By looking
at how a is seen from other objects, we can obtain a lot of information about a. But thinking
about the totality of maps from every other object to a is rather hard, so let's just
pick one object x and look at a from there to start with. The relationships an object
x has with a are exactly the hom set a in x and the hom set of x and a. Let's just consider
the former for now. As we move between the objects, we see a from different viewpoints.
If the category is locally small, then what we're really doing is assigning a set to
each object. Sets are objects in the category of set, so we've really just defined a function
from the objects of c to the objects of set for a fixed a. As it turns out, every morphism
x to y induces the functions from the hom set of a in x to the hom set of a in y. So this
is just the morphism between two sets in set, and the whole thing describes a function from
the original category to set. Let c be a locally small category and fix an object a in c. We
define the covariance hom functor from c to set, also denoted h sub a as follows. For
each object x in c, define the hom functor to map x to the set of maps from a to x. We
can interpret this as the hom functor mapping objects to how they are seen by a. For each
morphism f from x to y in c, define the hom functor to map f to a function hom of a and
f, defined by post composition by f. That is, we map each morphism g from x to y to
the composition of g with f. Or in the diagram, we comb the morphisms on the left through
to y through f. We can interpret this as the hom functor mapping morphisms f from x to
y to how a sees the objects y through f. These will show up visually prefer diagrammatically
symbolic. I initially found the diagram more enlightening, but it's become less and less
useful the more I actually work with categories algebraically. The contravariant hom functor
is defined duly, mapping objects and morphisms to how they see b rather than how they are
seen by me. We haven't actually proved that either one is a functor, but it is again just
a bit of algebra, and you only have to prove it one because the principal duality proves
it for the other. For each object a, we have now assigned the functor h sub a from c to
set, encapsulating how the category is seen from a. But since it's the same category
being seen from all objects, it wouldn't be unusual for us to expect that this assignment
has some internal consistency. As it turns out, each morphism f from a to b induces a
natural transformation h sub f from h sub b to h sub a. Note the change in direction
here. A collection of covariant functors come together to define a contravariant natural
transformation. And if we started with a contravariant hom functor, they would all come together
to define a covariant natural transformation. We'll show how this works now. Consider the
components of this natural transformation as an object x. Recall that this map just
sends morphisms from b to x to form morphism a to x. We can alternatively interpret these
hom sets as contravariant hom functors with a fixed x, but we've already seen this before,
or at least the dual of it. This is given exactly by pre-composition by f. And in fact,
there's no reason why we should have to fix upon arguments at the time. The notation here
suggests that we may take both inputs of the hom functor to be variable. Let f from x to
y and h from b to a be morphisms and consider this diagram. Consider a morphism g from a
to x on the top left here. We'll follow how it's mapped under the square along the two
different paths in a technique called diagram chasing. Along the upper path, we pre-compose
with h before post-composing the result with f. Along the lower path, we post-compose
with f before pre-composing the result with h. But by associativity of morphism composition,
we see that these paths are equal and the diagram can meet for any point of regime. This
suggests that the double-argument hom functor is a bi-functor from c cross c to set, covariant
in the first argument and contravariant in the second.
A functor f from c to set is representable if it is naturally isomorphic to the hom
functor for at least one choice of a and c. The object a, along with the natural transformation,
are then a representation of f. It turns out that a is determined uniquely up to isomorphism
in c. The name is also rather suggestive of the fact that a in some way determines f,
which is a corollary of a lemma we'll prove later. We give a few examples of representable
functors.
The identity functor from set to set is represented by the singleton set 1. Any function from
the singleton set to a set x just amounts to picking elements from the set x, so there
are exactly as many functions 1 to x as there are elements of x, which is exactly the statement
of the isomorphism. Naturalty follows directly from the associativity of function composition.
The forgetful functor from group to set is also representable. Actually, forgetful functors
in general are representable, but we'll just look at the forgetful functor for groups for
now.
We're looking for a group that satisfies this condition. Take a moment to see if you can
spot it.
Orgud.
The additive group of integers is what we're looking for.
Let g be a group, and let phi be the group homomorphism from z to g. Because group homomorphisms
send identities to identities, 0 is always sent to the identity in g. This is also why
we can't pick the singleton set to represent this functor. This requirement stops us from
mapping the salt elements in the singleton set to the whole group. However, we're free
to pick the image of 1 in z, which also determines the rest of the map due to the cyclic nature
of z.
This suggests that we send each homomorphism to a determining value at 1, and this mapping
defines the components of the natural transformation in alpha. This map is also invited by sending
each element g to a map that sends integers to that power of g.
Naturality is shown by chasing f around this diagram.
I'm not going to talk through this one, it's just evaluating and simplifying the functions
at each step. Pause if you want to read it through and make sure you've understood what
each function is.
We can also represent the functor that sends a ring to a set of units.
We can't pick the integers here, because ring homomorphisms require us to send both
identities that correspond to the identities, so 0 is sent to the additive identity and
1 is sent to the multiplicative identity, so we don't have any variables free. This just
gives us a point.
If we try a polynomial ring, then z is fixed by the homomorphism requirements, and the
free variable is free to pick out points in r, so we just get all of r back.
To ensure we only pick elements which have inverses, we use the ring of Lorentz polynomials,
which you might recognize from Lorentz series in complex analysis.
We give an example of a non-representable functor next.
Consider the functor from set to set, defining objects from having each set x to the co-product
of x with itself. You might also call the co-product of this joint union in set theory.
If you're unfamiliar with it, it's just the union operation, but we keep track of
which set every element came from.
Now, suppose there exists a set y, such that the homset of y and x is isomorphic to the
co-product of x with itself. If we take the case where x is the singleton set, then the
homset of y and x is just the singleton set. But the co-product of the singleton set with
itself is the set with two elements, so these sets are not isomorphic, and hence no y exists.
One almost universal problem in mathematics is to figure out how to describe and classify
objects. While a mathematical axiomatic definition of an object certainly distinguishes that
object away from many others, this doesn't tell us much about the collection of all these
objects as a whole. For example, while we can define a group in four short axioms, classifying
all groups is a much harder problem. In fact, we've only done it for finite groups, and
even then, it took thousands of phages, tens of thousands even. For a simpler example, imagine
we're tasked with classifying the real numbers.
The real number line is a classification of all real numbers by embedding them in some
space that has more properties than the real numbers had alone. For instance, the number
line is a smooth manifold, a metric space, a topological space, etc.
While we can define real numbers with dedicated cuts, or with completeness axioms, this kind
of embedding gives a lot of additional and useful information that isn't visible from
the axioms alone. Importantly, there's a bijection between points in the number line
and the real numbers, but we also have the new information in that real numbers near
each other on the number line are similar in magnitude. We can try to extend this idea
of a classifying space through other kinds of objects, where nearby objects have more
similar properties than distant objects. Unfortunately, this classifying space for
any kind of useful object is often completely unrecognizable and has very few properties
we can learn for its short advantage. However, we can attempt to examine these spaces by
looking at the maps from other spaces to them. Let one be the set with one element. Any map
from one to r effectively amounts to picking an element from r, so there is a bijection
between the functors one to r and the points in r. And the fact that there's nothing
specific about r here. Well, generally, the maps from the one point space one to any space
x amounts to picking points from x. If x is a metric or topological space, then this
is a set equipped with an extra structure in the form of a metric of topology. By examining
the maps from one to x, we can recover half of that information. Just by looking at x
from the simplest possible non-trivial space, we recover all of the points of that space.
Now, what if we look at maps from a more complicated space? A map from the interval
zero one to x is just a parameterization of a carbon x, so the maps zero one to x recovers
the path to an x, while a map from the circle s one to x is just a topological loop, so
the maps s one to x recover all the loops on x. The point is, we get more and more information
about any space x by examining how it appears from other programming spaces. But exactly
how much information can we recover? Is it always possible to obtain as much data from
looking at maps as we would from just analyzing the space itself? After all, we have no reason
to expect that the entire structure of the space is always captured by these maps. Except,
it always is, and that is the Unidol Emma, or at least part of it. The remarkable thing
about the Unidol Emma is that it's a proof at a level of categories, so it holds for
any category of spaces, topological or metric, smooth manifolds, sheaves, algebraic varieties,
anything. We begin the lemma by asking what information representables recover. Let's
see be a locally small category and fix A and C, inducing the covariant functor h sub
a. For each covariant functor f from C to set, what are the natural transformations
h sub a to f in the functor category C set? We should unwrap what this is saying in exact
terms. Firstly, there is a nice morphism of sets, so there is a bijective function between
the hom set for the hom functor at a and f and f of a. There are exactly as many natural
transformations from h sub a to f as there are elements of f of a. Secondly, this isomorphism
is said to be natural in a and f, suggesting that both sides are functorial in both a and
f. Precisely, we can regard the left and right sides of this expression as bifunctors, from
the product of the functor category of C and set, crossed with C to set, and the Unidol
Emma states that these functors are naturally isomorphic. In particular, the functor on
the right is also known as the evaluation functor, since it takes the functor and an object's
input and evaluates the functor at that object. I'm not going to cover the proof of naturality
here since there's a lot of algebra, but we'll just show the isomorphism for now. Let a to
be a natural transformation from h sub a to f and consider its naturality diagram. We'll
trace the identity on a around the diagram. Along the upper path, we apply the component
of a to write a to the identity, then apply f of f to the whole thing. Along the lower
path, we apply h sub a of f to the identity, which is, if you recall, post composition
by f. So, we compose the identity on a with f, which just gives f. Then, we map as the
component of a to write b. But, since a to write a natural transformation, these paths
should be equal since the diagram meets. If we look at the function on the left, the
input is always a to write a applied to the identity on a. This implies that any natural
transformation from h sub a to f is completely determined by its value at the identity at
a. This naturally induces a function mapping a to the object that determines its value,
and moreover, this function is a bijection, as every such value in f of a conversely extends
to a unique natural transformation, and this establishes the required isomorphism of sets.
Naturality is left as an exercise.
At the beginning of this session, we asked how much information we get when we examine
how an object looks from all of the possible viewpoints. This corollary states that we
recover the object up to isomorphism. That means that the maps into, or the maps out
of an object, contain exactly as much information as the objects itself with regards to the category.
And I think that is a good place to stop.
