Hi everybody, I'm Peter Morgan, so I represent a company called Deep Learning Partnership
which is an AI consulting company, so it's plain old deep learning for my bread and butter.
But today I'm going to talk outside of that into what I see as the future.
So here's a little book that I wrote for O'Reilly, it's free to download, so go ahead, machine
learning is changing the rules, there's my company website, there's my Twitter handle.
I tweet on sort of what I'm going to be talking about today a lot, so you can sort of keep
up to date if you so desire.
So what am I going to talk about?
So what is intelligence, a good place to start, if we're trying to solve it, we need to ask
what it is, figure out exactly what it is we're trying to solve.
So I'll start by outlining what I think intelligence is, I'll answer that question today.
And then we'll look at physical systems, biological, non-biological, so the non-biological ones
being computers, silicon, that type of thing, biological systems being us, we are what we
are trying to model, this is it, we're trying to model the human brain.
And not only the human brain, but how biology does intelligence, how biology does intelligence.
The aim of my talk is to describe that and a system that might actually build it.
And then we'll do a quick recap, a very quick recap on deep learning, because I've just
tried to convey that, you know, biology isn't actually deep learning at all, and a lot of
the talks today, particularly the neuroscience talk I saw earlier before lunch, made that
very clear, we're not deep learning won't get us to intelligence, right?
And I'll explain exactly why, well basically it's statistical in what we want as a physical
theory of intelligence, right?
So I'll go more into the physics and the neuroscience.
Finally we'll have a look at a theory of AGI, and I'll talk about that, so that's the very
end of the talk.
Okay, so without further ado, if, yeah, so why do we, okay, hopefully the clicker will
work.
So why do we want to build AGI, well we want to solve intelligence, we want to understand
intelligence, so we want to build systems that we can use to do all these tasks and
then make money from that, or just do all the automate all the boring stuff, and ultimately
if it's general intelligence, we can automate everything.
So then we got to ask, you know, philosophically what do we do, right, if we build these systems,
and my answer to that is we'll just get back to being more human, right?
We won't have to work in factories and production lines, and you know, even though we, a lot
of people have convinced themselves, you know, this is what the true meaning of life is,
I don't buy it, so once we build it, it'll become more obvious what we'll have to do
with ourselves.
Okay, nothing to get too worried about, okay.
I'm not a doomsayer, I'm not here to say, oh my God, you know, the world's ending.
But you know, the conversation at some point always goes there, so I thought I'd just get
that out of the way at the beginning.
So let's focus on trying to build it for the rest of the talk.
So what is general intelligence?
Are any of these, general intelligence, AlphaGo, AlphaStar, playing StarCraft from DeepMind,
you know, I've come over from London where DeepMind are based, the Google company, DeepBlue
from IBM, back in the late 90s, IBM Watson, winning at Jeopardy, natural language processing,
none of those are even close to general intelligence.
They do very specific things, they're completely dumb, they're completely stupid, they use
statistical methods, so no, they're super clever, it's like they can totally outperform
us just like a calculator outperforms us with multiplication, right?
So not dismissing it entirely, but it's not general intelligence, that's not what I'm
here to talk about.
That's what DeepMind does, it's not what I'm trying to do, although ultimately they do
want to do that, and they've said that very, very, very clearly.
But right now they're not doing it.
So what is intelligence?
Well here's the answer, it's not one thing, it's many things.
So it's basically we are agents in our environment, so it's our adaptation to our environment.
If we were living in a different universe with different laws of physics, gravity goes
up instead of down, we would be adapted to that, and so that would be, our intelligence
would be adapted to that environment, okay?
So it's simply adapting to our environment, exploiting our environment, modeling our
environment and predicting, successfully predicting what's going to happen next in our environment.
If you think about it, it just kind of boils down, it's, you know, deflate everything
right now, it just kind of boils down to that, whether we're trying to win the lottery or
build a rocket to the moon, or even build journal intelligence, we're just trying to
model our environment.
It just so happens that we're trying to model our brain, okay, with journal intelligence.
So we've done a pretty good job, you know, we've done, you know, the laws of physics,
we've had Newton, we've had Einstein, we've had Feynman, we've had some super clever computer
scientists, biologists, neuroscientists, but it's all the same thing, we're just trying
to model, just trying to model our environment, okay?
So it's not just Einstein, that's not the only thing that has to do with intelligence,
it's spatially, you know, we have athletes, you know, that are way better than Einstein
at doing the high jump, right?
So he was crap at that, but very good at modeling general relativity.
But when it came to hurling himself over a high bar at seven feet, you know, he would
just fail miserably.
When the high jumper goes to solve, you know, to understand the universe right down mathematically,
he would fail.
There's not one type of intelligence, okay, there's many.
And that's what the G and AGI stands for, it's general, okay?
So we're trying to build things that are spatially intelligent, aware of the environment, we're
not doing a very good job there, are we, with climate change and everything like that, Donald
Trump, blah, blah, blah, right?
So, you know, that's, for me, is a big part of intelligence is to understanding our environment,
not destroying our environment, but, you know, kind of living in harmony, that might be a
definition in naturalist intelligence, not getting too political, but, you know, that's
what I believe.
Musical, you know, Mozart, Beethoven, the Beatles, whatever type of music you like, and
I've managed to turn that off, that is a type of musical intelligence.
Not everyone can create, write a beautiful melody or a symphony, but some people can,
right?
These are all the different types of intelligence, linguistic, you know, Shakespeare, or, you
know, who can write a great poem, et cetera, et cetera, interpersonal people relationships,
how we relate to one another, social intelligence, emotional intelligence, introspection, how
we understand ourselves, you know, how we react in society, how we go about, you know,
place in the world, and then you build it up hierarchically into nations, you know,
do we go to war, do we not, I mean, how do we keep peace internationally?
These are all different types of intelligence that these machines will have to do if they're
truly general intelligence, okay?
So it's not just the building the Einstein, you can see that now, it's everything.
It's physical, it's political, it's social, it's emotional, okay?
A big ask, a big ask, but we do that in three pounds in our skull, right?
So biology has done it, using 100 billion neurons, roughly, somebody said 86 billion,
but it's of that order of magnitude, and perhaps it's the connections, 1,000 to 10,000 synapses
per neuron, so it's a very complex system.
So it's no wonder, you know, we can't give ourselves too hard a time that we haven't
built it yet, because, you know, it's complex, and also, you know, the earth's 4 billion
years old, we've had a few years, okay, we didn't just come up with this stuff yesterday,
you know, we can go back 10,000 years, 20,000 years, we were pretty much living in caves,
right?
It's only the last 100 or so years that we've kind of, you know, hit this exponential where
we're taking off, and the singularity is there, and all that kind of stuff, right?
So we're living in very interesting times, but this is where intelligence has brought
us, and this is where we are, we're sitting in this conference talking about it, right?
We wouldn't have been doing this maybe even 10 years ago, okay?
So we're ready to build it.
How far have we come?
I would argue not very far.
All these talks we've seen today have all been about deep learning and statistical methods.
The best we've done, I think, is around 50% for logical, mathematical, linguistic.
The last talk was on BERT, it's super impressive stuff.
There's GPT2 with open AI, there's BERT with Google, you know, Facebook, Microsoft, everyone,
all the big tech companies are plowing ahead with these statistical methods, but there's
nothing to do with general intelligence, so, you know, statistics will only get us so far,
right?
And in fact, when it comes to introspection, thinking about the universe, they're actually
zero, they're not even off the ground, okay?
They haven't even started, haven't even begun, and they never will do because it's, statistics
won't do it.
Physics will, statistics won't.
I'm not trying to discredit anyone here, I'm just trying to focus on general intelligence,
okay?
Okay, so how will we get there?
Well, it takes a village to create an AGI, just as it takes a village to raise a child,
right?
It's going to take a village to build these things, so it's not just physicists, it's
not just computer scientists, it's not just, you know, psychologists, it's all of us together,
so it's neuroscientists, psychologists, physicists, computer scientists, everybody, politicians,
because this is general intelligence, we need everybody in the room together.
Okay, so, you know, so physically, you know, biology, biologically and non-biologically,
let's have a, take a look at, you know, how, how physically intelligence manifests, okay?
So, biology, very clever, we start with bacteria, no, no central nervous system, no neurons,
nothing, and yet they survive, they reproduce, they're intelligent, okay?
They're much more intelligent than us, maybe they'll survive longer than us, the rate we're
going, I'm not putting my bets right now, so, you know, that is intelligence without
even a single neuron anywhere to be seen, so they're using chemical gradients, they're
just using the laws of physics to wiggle and wobble about, but they've learned how to reproduce,
create DNA and reproduce.
They haven't learned anything, right, that's a, that's an anthropomorphism, you know, this
is, this is what the laws of physics can do and has done, you know, in terms of biology.
The first thing with the central nervous system is the C. elegans, I think it has 130 odd
neurons, so arguably this is the dumbest thing with the central nervous system, so, but yet
it can, you know, understand, it can survive, it eats, it reproduces, the bumblebee has
about a million neurons, this is how biology does things, it can navigate, it does its
wiggle dance, it's societal, it lives in a society, and right up to us, the brain, the
human brain in fact, you know, you've got all the mammal elephants, fish, chimpanzees,
us, right, so there's a whole spectrum here of intelligence, you know, assuming, assuming
we'll start with the, you know, the simplest systems and build up, but is there something
here that unites these, all of these systems here, you know, because I'm interested in
understanding theoretically what intelligence is, in other words, you know, writing down
the mathematical equations that we will use to guide us when we build these things, okay,
not just sort of trying, does this work, does this work, I'll add another neuron, another
layer to my deep neural network, I want to understand the basic physical, the physics
of intelligence, or, you know, we do as a community, the AGI community, okay, so the
first thing we notice is that biology is hierarchical, we start off with atoms, they're certainly
not intelligent, molecules, neurons, they're not intelligent unto themselves, but when
you start connecting these things together, they connect home, then intelligence emerges
from there, and then we have us, you know, agents, and then we have societies and nations
and finally the world, so, you know, the whole thing is hierarchical from atoms up to nations,
so this general theory will have to explain the whole lot, okay, so it's a big ask, right,
we're actually trying to describe the whole thing and not just bits of it, okay, so just
to kind of sort of expand your mind, put it all in perspective.
So we're coming up with a truly general theory of intelligence, and that's what a neuron
looks like, it's super complex, do we need to go to this level, you know, there's a lot
of open questions, we don't know, we'll see, okay, we'll just see, nature does, clearly,
because that's what a neuron looks like, but when we build these systems will we have to,
it's a very, very, very interesting and open question right now, okay, but it won't stop
us perhaps coming up with the underlying theory.
So this is what a brain looks like, this is what intelligence looks like, it's organized
into structures, repeating structures of about two million neurons in these so-called cortical
columns, again and over and over and over again, so if somebody goes blind, God forbid,
some of those neurons that we use to process visual information are quickly repurposed
into processing sound, okay, so the kind of general, there's a generality there, these
are just information, these are information processing systems that seem to have some
sort of generality, so we do know that, that's something we do know so far, and I'm going
up the hierarchy here, here's the connectome, so it's all connected, besides these tens
of tens of thousands of synapses between each neuron, these things are organized into
some larger, if you go up one level in this hierarchy, then you start to see this connectome
forming, whether that's in humans or even bees, you know, there's this layer above
the neuron set, maybe that's the right layer to start with, okay, and then above that then
that's attached to a central nervous system and all living beings, a fish, a bee, a human,
so it's not just a brain and a jar, although some might argue Stephen Hawking was kind
of that because he had that terrible disease and there are people, so we can function like
that, but we're really interested in building the whole physical as well, but the brain
is the main thing, once we've cracked that, we've cracked intelligence, I'm just saying
we connect it to the rest of our system, do we need kidneys? I doubt it, I doubt we'll
have this thing, a system with kidneys and lungs and everything else, right, but that's
how biology has done it in every single thing, so there's this other part, 90%, you know,
which I think we need to worry about the brain more than the rest of it, but the rest of
it's super clever, but kind of clunky, it's just, nature's put us together like that,
we may not need to go down to that, consider that so much, but if we're building robotics
we will, but a robot might not have kidneys, but it needs to be able to move around fluidly,
and we haven't quite got that yet, even though Atlas does nice backflips and super, I mean
it's getting pretty good, isn't it, every month Boston Dynamics comes out with a new
video, it's like, oh my God, it's like so human, and then they beat themselves, but
it's not intelligent, it can't play chess, it can't ponder the universe, its own existence,
it doesn't even know it's alive, that's how dumb it is, but it's very good with the
physical part, okay, that's all part of intelligence, and then the social systems, we talk about
cloud robotics, form robotics, social intelligence, that's the final layer, okay, so here's where
we are with the non-biological, you know, we've started off with CPUs of von Neumann
architecture we've heard about today, separating the processing from the memory, and then we've
also heard that biology doesn't do that, it does the processing in the memory on the
same thing, Neuron is both a memory and a processor, so none of these, there's this
little von Neumann architecture, okay, so that's what it looks like, it's beautiful,
we saw a picture of a TPU version 3 in the last slide, it's like a supercomputer, it
does like a petaflop or something or more, graph core, there's 100 petaflops in like
eight racks, you know, that's the world's most powerful supercomputer, almost, not quite,
but it's getting up there, so these are ASICs, they're specifically designed to multiply
huge matrix, billion by billion matrices together, which the brain isn't doing clearly, and you
know, that's how many times bigger than the brain is that, right, it's got nothing to
do with general intelligence, but it's super good at multiplying, it's good at linear algebra,
it'll statistically, you know, calculate things, that's why BERT will get statistically brilliant,
but it'll never understand Shakespeare, because it can't, because it's linear algebra, right,
linear algebra doesn't do that, okay, and there is the world's biggest, it's 3x a flop,
it's summit, chock full of GPUs and I think AMD processors, super impressive, but it's
as dumb as a brick, right, doesn't do anything, it's a big calculator, so what are we missing,
so we do all that in three pound, right, we don't need three football fields or 10 megawatts,
we need a couple of sandwiches and apple and a drink, you know, and we can discover the laws
of the universe, okay, so clearly we're not even close by any of those other approaches,
maybe one approach in hardware is neuromorphic computing, which stated aim is to replicate
the brain, okay, in hardware, and so there's a project called Spinnaker, part of the human
brain project, which is doing that, Steve Furber, who was part of ARM, based at University of
Manchester, been working for the last 20 years, he's built, their team there have built, now under
the wing of the human brain project, have built, I think, a billion artificial neurons, so they're
analog, they process the information using analog, not digital, and it's more, it's not the von Neumann,
it's kind of combined, so they call that memristors, where the memory and the processing is combined in
the same place, and the architecture looks completely different, there it is, that's a
billion neurons right there, so immediately we see, you know, it's a little bit smaller than
the others, that's all analog computing, and that's what it looks like, so yeah, we start off with
a thousand neurons per core, and then we put them into chips, and it's hierarchical, then we put 48
chips on a board, 24 boards in a rack, we have 10 racks, right, and that's sitting in a data center
in Manchester today, and you can log in now if you want to, set up an account, log in and start
processing stuff using neuromorphic computing, and you can put in the MNIST data set, you can
place a doku, you can play chess, and it doesn't do deep learning at all, it's processing it with
neuromorphic algorithms and hardware, okay, so for me this is definitely a step in the right
direction, so hardware is important, it's not everything, obviously the algorithms need to be
there as well, but I think we need to be running it on the right hardware, otherwise it's a simulation,
you can always simulate anything on a chip, but you need, you know, they've done that in the human
brain project using, you know, the von Neumann architecture, I think they processed a second
of what the brain can do, it took them like a week in the whole data center, so you know,
you can always simulate things, but it's not efficient, so you can actually simulate in real
time using this neuromorphic architecture, because it runs efficiently like the brain,
I think it's about a thousand times less efficient than biology, whereas the CPUs and
everything else that we saw, digital is about a million times less efficient, so it's definitely
a step, and this is the first generation, so we're going to iterate just like we did with the CPU
processing and the digital, we've had 50 years, we've got 10 billion transistors on a thing,
a centimeter big, right, so we'll do the same with neuromorphic, we'll have generation upon
generation, and soon we'll have 100 billion neurons, because it's Moore's law, it's exponential,
and we will see, you know, sort of human level intelligence, whether it will be sentient and
is down to the algorithms, actually, so I think we have the hardware, we're at the very beginning
of this journey with the hardware, but we need algorithms, so let's look at the algorithms, so
that's another one, the brain scales, that's the University of Heidelberg here in Germany,
that's part of the human brain project as a spinnaker versus the Google TPUs, I would argue
the one on the left with neuromorphic is the right hardware to be working on for general
intelligence, okay, and it's quantum computing, nothing to do with how the brain works, but,
you know, sexy pictures, so I put it up there, and it is, it is like the last form of computing,
right, you cannot forget it, it's a big deal, it's going to come online, but I don't think it will be,
you know, used to, you know, understand nature too well, I think biology doesn't use it, so I
doubt we might have to go to the quantum level, but the quantum will be very important in other
aspects, perhaps not general intelligence, okay, so there's the four summary of everything I've
talked about, the four different types of hardware, the digital, the neuromorphic, quantum, and then
biology, right, so we want to try to build the thing in the lower right hand corner here,
and I think neuromorphic is getting, that's the way we'll do it, and that's what they look like,
okay, so the brain, you see the similarity a little bit, the neurons in the brain, the digital,
the neuromorphic, and quantum looks a bit out on its own weird, but ultimately it's these little
units of information processing, okay, and then the data center of the future won't just be classical
computing, it'll be a mix of quantum, neuromorphic, and classical, so deep learning, quick recap,
that's what it looks like, this is what general intelligence isn't, so it's not that, it's not
that, and that's, you know, deep learning is not AGI, so AGI is linear algebra, so you know,
you're just summing up the weights times these vectors, and billion by billion matrices,
it does not give us a neuron, absolutely, not even close, but never will do, and it was never,
it was never meant to, to be honest, if you talk to the researchers like Jan Lacoon and Jeff Hinton,
they, we're not trying to imitate the brain at all, we just found the stuff that works really well,
but, and then Jeff Hinton, he's in my last slide, says that, you know, if we think really hard about
how nature does it, biology will, that's how we're going to do it, and he's recently said,
everything I've ever done on deep learning is sort of, I'm going to have to put that to one
side now, because to get to the next level, and I saw a slide in some other presentation today,
you know, it's starting to get a bit mainstream now, you know, deep learning is running out of
steam, you know, we can maybe tweak the knobs and get another two or three percent of accuracy,
but yeah, where do we go, it's not general, it's very specific, it's not going to give us those
nine types of intelligence, and I think that's what people are trying to say, even though they
don't quite realize perhaps what they're saying, but that thing on the left is what we're trying to
build, not that little bit of linear algebra on the right. Okay, so what is the theory, okay,
you know, I'd be, I could just walk off the stage now and say, ah, you know, we don't,
I don't know, thanks for coming, you know, spending all your money, but I'll try, I'll try, I'll give
you something, a bit more than that, so let's see, so I mentioned earlier that it's not statistical,
right, so what is it, it's physics, right, everything is built using the laws of physics,
so why not the brain, right, why not, let's start there, it's nice and simple, so what do we know
about physics, right, well we know Newton's laws, we know relativity, we know general relativity,
we have Maxwell's equations from last century, we're standing on shoulders of so many giants
here, Maxwell, Newton, you know, all the greats, Helmholtz, Boltzmann, Gibbs, you know, we got the
laws of thermodynamics, we got quantum mechanics, we don't think we'll need that, but we still have
it, we have relevance at quantum mechanics, we have dark energy, we have stuff we don't know,
dark energy, dark matter, we're probably not involved with intelligence, the thing is that
all of that can be encapsulated in something called the principle of least action,
which says that nature behaves to minimize the free energy of any system, you know,
whether that's microscopic or macroscopic, whether it's a millisecond, a nanosecond,
or the age of the universe, there's this fundamental underlying principle of physics,
if you did a PhD in physics, who did a PhD in physics, yes, so a couple of people here
will have seen this principle of least action, and you write it down, it's a nice beautiful
formulation, you can write it down in Lagrangian or Hamiltonian form, but it's, you know, one line
and you can use it in principle to describe any system, okay, I say in principle because, you
know, nature is complicated, you know, the brain's complicated, as soon as you get more than a few
atoms, you know, or a few molecules, it's hard, right, so, but in principle, this is the underlying
principle, so that's where I'm going to start, right, with the theory of intelligent, I'm going
to say if we can use it for everything else, then let's apply it to the brain, see how far we get,
that's what it looks like, there's a beautiful book just written, I think, yeah, last year at Cambridge
University Press, surprisingly, there's nothing else before this, because it's been around about
100 years, it's called the principle of least action, it's got all the different examples in the world
of thermodynamics, classical mechanics, steam trains, computers, digital, quantum, everything,
chapter on each, how it's applied, how it's applied, how it's applied, how it's applied,
so they need an extra chapter on how it's applied to the brain, I think, but that's what it looks
like, you know, that s is the action, the q is momentum, t is time, and q dots, you know, the
dv dt, the change of momentum with change in time, and delta s equals zero is all the physics,
it's the change in action, nature acts so that delta s, where s is the action,
is, it tries to minimize that quantity where s is that in terms of Lagrangian, okay, don't
worry about the math or the physics, we're not going to go there, but so let's apply that to the
intelligence and see how far we get, because it works for everything else, okay, so again, it's not
just about pattern recognition, it's about modeling the world, okay, we model stuff, we can imagine,
we problem solve, we can build new models, we can understand, right, we don't just do statistical
analysis, otherwise it'd be zombies, right, or we'd be a silicon chip, we'd be built into our
factory and we're not, so here are some theoretical approaches, I'm going to choose the Friston
active inference one, which uses the delta s equals zero, the others don't, but these are, these are
very, very, very, you know, credible attempts at general intelligence and all of these people
have been working at least 30 years on these theories, so they're certainly not to be dismissed,
and let's pick this one and just do all the others are wrong, there's going to be bits of each that
it kind of have, have some, there's going to be overlap, so you know, we've, Helmholtz started
with statistical physics, right, it's, the brain is 100 billion neurons, it's a big messy, warm,
complex system, so statistical physics is over 100 years old.
Okay, so I will wind it up, yeah, let me wind it up, so yeah, 30 years for all of these, right,
I'm going to pick Friston in the last two minutes, okay, now active inference, we can look this up,
again it uses the free energy, it's minimizing the free energy, let me just flick through and then I'll
sum it up, there's Professor Friston there and we, we don't have time to hear, so this is what it
looks like, we can draw diagrams and pretty pictures, we can write down equations, we can have
me, us in the environment, the environment acting back on the agent, the agent acting back on the
environment, all the physics is in place, we can write down the equations for it, we can do it for
bacteria or the brain, so it works on all systems, there's the math that's super, super ugly, but
it's, you know, it's, that's theoretical neuroscience and this is, that's the equation of, that's like
the general theory of relativity for, for the brain, right, so there you saw it, he's got loads of
papers, can we build it, I say yes, we have the data, we have the theory, we have the algorithms
and we have the hardware, okay, and there's some AGI project, there's Merrick's here, Ben's here,
there's a, JÃ¼rgen Schmidt-Huber's not here, these are all super clever people doing super clever
things and I picked our active inference as one because I feel it's the one most based on physics
and I'd say we're at the beginning of our journey, it might take us five or ten years to sort of
build us as we wait for the hardware especially to mature, I believe we have the algorithms,
it's a super bold statement to be saying, but I encourage you to read some of the papers
and there's Jeff Hinton saying at the very end, you know, this is three years ago,
the conceptual breakthroughs will take us, we need new conceptual breakthroughs,
I believe the breakthroughs are going to come when we understand the brain, thank you very much.
I'm, I'm so sorry for being so rushed, I also would like to know more,
can I steal five minutes of the Q&A, so like for just one question, I know that he overtake,
he's going to make it up to you. Okay, one question. He owes you five minutes of lifetime,
yeah, I'll make sure you get that. I do, I do. Five minutes of your lifetime to him. Thank you so
much. Thank you so much for the question, sorry for your time, just in taking one question,
so I'm just going to be very quick to keep on schedule, so I'm going to just speak in very
short words, so Richard Feynman, you know, you've been a music producer, besides all your other
work in the academia, and you've shown us a great slide where you said for AGI we need
computer sciences, physics, neurosciences, and psychology, so bringing these four things together,
I mean, the question is, and you've been in academia, in our society every, every incentive
is to be very specialized and to really focus on one subject and then people don't talk and connect
enough with each other, and I think we need that for AGI. What are you doing or what can we do as
a society to bring these four groups together? Is there conferences to exchange with those four
groups? I mean, how do you get these different people, these different tribes talking with each
other? Is that the short question? Is that the short question? Well, it was a long question, I hope he
has a short answer, but yeah, okay, yeah, so Professor Friston's group's a neuroscience group,
it's a theoretical neuroscience group, they have very strong mathematicians, very strong computer
scientists, DeepMind's a bit of a, you know, case study in this, they get neuroscientists,
computer science, sitting in the same room, so it's the very beginning, but I think you need
more, I think you need psychologists, yeah, so we need a little bit more input from other science
sectors to begin with, and yeah, I mean, it's, yeah, I mean, ultimately you have to build these
things, the theory is going to come from a very, very strong scientific, mathematically competent
person, okay, you can get all the psychologists talking in a room and everybody else, but ultimately
someone or a couple of people have to write down a scientific theory, just like Einstein wrote down
the theory of relativity, so maybe I was a little bit generous, you know, we need everybody, we need
the ideas from everywhere, but the actual person himself or herself is going to be, have to be
super strong a math, we saw some of the math, it's not simple, it takes a while, right, it's a huge,
just like the theory of general relativity, and I'll end here, you know, we can understand the
concepts, but the actual math is really, really, really hard, right, I don't know if you've ever
tried it to solve the, no, the field equations, I have, they're not easy, right, yeah, so don't
expect this to be easy, it's going to be simple, but the math is still going to be, you know, hard,
okay, yeah, okay, thank you. Okay, Peter, one more question, where can we find your slides,
are you going to upload them somewhere? Yeah, I thought the conference was going to upload them,
if not, then my slide share is, they're available on my slide share, so if you go to
slide share and just Google Peter Morgan, I guess, you'll find you, you'll find him, okay,
I think that's the best way, and the other thing is just to look at Carl Friston, he has a great
website with all his papers, which is super heavy going, but if you're really, really,
I don't know, you know, if you really believe you want to try and solve intelligence,
that's the best place to start.
