WEBVTT

00:00.000 --> 00:19.560
Hi everybody, I'm Peter Morgan, so I represent a company called Deep Learning Partnership

00:19.560 --> 00:26.480
which is an AI consulting company, so it's plain old deep learning for my bread and butter.

00:26.480 --> 00:34.800
But today I'm going to talk outside of that into what I see as the future.

00:34.800 --> 00:43.320
So here's a little book that I wrote for O'Reilly, it's free to download, so go ahead, machine

00:43.320 --> 00:48.040
learning is changing the rules, there's my company website, there's my Twitter handle.

00:48.040 --> 00:53.960
I tweet on sort of what I'm going to be talking about today a lot, so you can sort of keep

00:53.960 --> 00:57.680
up to date if you so desire.

00:57.680 --> 01:00.240
So what am I going to talk about?

01:00.240 --> 01:05.760
So what is intelligence, a good place to start, if we're trying to solve it, we need to ask

01:05.760 --> 01:10.400
what it is, figure out exactly what it is we're trying to solve.

01:10.400 --> 01:17.960
So I'll start by outlining what I think intelligence is, I'll answer that question today.

01:17.960 --> 01:23.000
And then we'll look at physical systems, biological, non-biological, so the non-biological ones

01:23.000 --> 01:34.400
being computers, silicon, that type of thing, biological systems being us, we are what we

01:34.400 --> 01:40.040
are trying to model, this is it, we're trying to model the human brain.

01:40.040 --> 01:46.600
And not only the human brain, but how biology does intelligence, how biology does intelligence.

01:46.720 --> 01:53.920
The aim of my talk is to describe that and a system that might actually build it.

01:53.920 --> 01:59.760
And then we'll do a quick recap, a very quick recap on deep learning, because I've just

01:59.760 --> 02:05.520
tried to convey that, you know, biology isn't actually deep learning at all, and a lot of

02:05.520 --> 02:10.600
the talks today, particularly the neuroscience talk I saw earlier before lunch, made that

02:10.600 --> 02:17.160
very clear, we're not deep learning won't get us to intelligence, right?

02:17.160 --> 02:21.520
And I'll explain exactly why, well basically it's statistical in what we want as a physical

02:21.520 --> 02:23.040
theory of intelligence, right?

02:23.040 --> 02:27.280
So I'll go more into the physics and the neuroscience.

02:27.280 --> 02:34.360
Finally we'll have a look at a theory of AGI, and I'll talk about that, so that's the very

02:34.360 --> 02:35.760
end of the talk.

02:35.760 --> 02:45.200
Okay, so without further ado, if, yeah, so why do we, okay, hopefully the clicker will

02:45.200 --> 02:46.200
work.

02:46.200 --> 02:50.640
So why do we want to build AGI, well we want to solve intelligence, we want to understand

02:50.640 --> 02:56.840
intelligence, so we want to build systems that we can use to do all these tasks and

02:56.840 --> 03:03.800
then make money from that, or just do all the automate all the boring stuff, and ultimately

03:03.800 --> 03:06.800
if it's general intelligence, we can automate everything.

03:06.800 --> 03:13.240
So then we got to ask, you know, philosophically what do we do, right, if we build these systems,

03:13.240 --> 03:17.240
and my answer to that is we'll just get back to being more human, right?

03:17.240 --> 03:23.360
We won't have to work in factories and production lines, and you know, even though we, a lot

03:23.360 --> 03:26.920
of people have convinced themselves, you know, this is what the true meaning of life is,

03:26.920 --> 03:31.240
I don't buy it, so once we build it, it'll become more obvious what we'll have to do

03:31.240 --> 03:32.240
with ourselves.

03:32.240 --> 03:36.280
Okay, nothing to get too worried about, okay.

03:36.280 --> 03:40.840
I'm not a doomsayer, I'm not here to say, oh my God, you know, the world's ending.

03:40.840 --> 03:44.720
But you know, the conversation at some point always goes there, so I thought I'd just get

03:44.720 --> 03:46.920
that out of the way at the beginning.

03:46.920 --> 03:51.360
So let's focus on trying to build it for the rest of the talk.

03:51.360 --> 03:53.880
So what is general intelligence?

03:53.880 --> 03:59.800
Are any of these, general intelligence, AlphaGo, AlphaStar, playing StarCraft from DeepMind,

03:59.800 --> 04:04.000
you know, I've come over from London where DeepMind are based, the Google company, DeepBlue

04:04.000 --> 04:12.280
from IBM, back in the late 90s, IBM Watson, winning at Jeopardy, natural language processing,

04:12.280 --> 04:15.800
none of those are even close to general intelligence.

04:15.800 --> 04:19.600
They do very specific things, they're completely dumb, they're completely stupid, they use

04:19.600 --> 04:24.040
statistical methods, so no, they're super clever, it's like they can totally outperform

04:24.040 --> 04:28.360
us just like a calculator outperforms us with multiplication, right?

04:28.360 --> 04:33.240
So not dismissing it entirely, but it's not general intelligence, that's not what I'm

04:33.240 --> 04:35.000
here to talk about.

04:35.000 --> 04:39.680
That's what DeepMind does, it's not what I'm trying to do, although ultimately they do

04:39.680 --> 04:43.800
want to do that, and they've said that very, very, very clearly.

04:43.800 --> 04:46.400
But right now they're not doing it.

04:46.400 --> 04:47.400
So what is intelligence?

04:47.400 --> 04:50.680
Well here's the answer, it's not one thing, it's many things.

04:50.680 --> 04:56.720
So it's basically we are agents in our environment, so it's our adaptation to our environment.

04:56.720 --> 05:00.720
If we were living in a different universe with different laws of physics, gravity goes

05:00.720 --> 05:05.000
up instead of down, we would be adapted to that, and so that would be, our intelligence

05:05.000 --> 05:08.880
would be adapted to that environment, okay?

05:08.880 --> 05:13.600
So it's simply adapting to our environment, exploiting our environment, modeling our

05:13.600 --> 05:18.440
environment and predicting, successfully predicting what's going to happen next in our environment.

05:18.440 --> 05:22.160
If you think about it, it just kind of boils down, it's, you know, deflate everything

05:22.160 --> 05:25.400
right now, it just kind of boils down to that, whether we're trying to win the lottery or

05:25.400 --> 05:30.040
build a rocket to the moon, or even build journal intelligence, we're just trying to

05:30.040 --> 05:31.320
model our environment.

05:31.320 --> 05:34.960
It just so happens that we're trying to model our brain, okay, with journal intelligence.

05:34.960 --> 05:38.520
So we've done a pretty good job, you know, we've done, you know, the laws of physics,

05:38.520 --> 05:44.280
we've had Newton, we've had Einstein, we've had Feynman, we've had some super clever computer

05:44.280 --> 05:48.480
scientists, biologists, neuroscientists, but it's all the same thing, we're just trying

05:48.480 --> 05:53.040
to model, just trying to model our environment, okay?

05:53.040 --> 05:57.680
So it's not just Einstein, that's not the only thing that has to do with intelligence,

05:57.680 --> 06:03.720
it's spatially, you know, we have athletes, you know, that are way better than Einstein

06:03.720 --> 06:05.240
at doing the high jump, right?

06:05.240 --> 06:09.560
So he was crap at that, but very good at modeling general relativity.

06:09.560 --> 06:14.080
But when it came to hurling himself over a high bar at seven feet, you know, he would

06:14.080 --> 06:15.600
just fail miserably.

06:15.600 --> 06:20.120
When the high jumper goes to solve, you know, to understand the universe right down mathematically,

06:20.120 --> 06:21.120
he would fail.

06:21.400 --> 06:24.880
There's not one type of intelligence, okay, there's many.

06:24.880 --> 06:28.560
And that's what the G and AGI stands for, it's general, okay?

06:28.560 --> 06:33.880
So we're trying to build things that are spatially intelligent, aware of the environment, we're

06:33.880 --> 06:39.120
not doing a very good job there, are we, with climate change and everything like that, Donald

06:39.120 --> 06:41.240
Trump, blah, blah, blah, right?

06:41.240 --> 06:45.520
So, you know, that's, for me, is a big part of intelligence is to understanding our environment,

06:45.520 --> 06:48.800
not destroying our environment, but, you know, kind of living in harmony, that might be a

06:48.880 --> 06:54.520
definition in naturalist intelligence, not getting too political, but, you know, that's

06:54.520 --> 06:55.520
what I believe.

06:55.520 --> 07:04.080
Musical, you know, Mozart, Beethoven, the Beatles, whatever type of music you like, and

07:04.080 --> 07:08.680
I've managed to turn that off, that is a type of musical intelligence.

07:08.680 --> 07:13.480
Not everyone can create, write a beautiful melody or a symphony, but some people can,

07:13.480 --> 07:14.480
right?

07:15.000 --> 07:19.680
These are all the different types of intelligence, linguistic, you know, Shakespeare, or, you

07:19.680 --> 07:26.160
know, who can write a great poem, et cetera, et cetera, interpersonal people relationships,

07:26.160 --> 07:33.160
how we relate to one another, social intelligence, emotional intelligence, introspection, how

07:33.160 --> 07:39.200
we understand ourselves, you know, how we react in society, how we go about, you know,

07:39.440 --> 07:45.760
place in the world, and then you build it up hierarchically into nations, you know,

07:45.760 --> 07:49.640
do we go to war, do we not, I mean, how do we keep peace internationally?

07:49.640 --> 07:53.880
These are all different types of intelligence that these machines will have to do if they're

07:53.880 --> 07:56.080
truly general intelligence, okay?

07:56.080 --> 07:59.360
So it's not just the building the Einstein, you can see that now, it's everything.

07:59.360 --> 08:03.920
It's physical, it's political, it's social, it's emotional, okay?

08:03.920 --> 08:08.400
A big ask, a big ask, but we do that in three pounds in our skull, right?

08:08.440 --> 08:13.120
So biology has done it, using 100 billion neurons, roughly, somebody said 86 billion,

08:13.120 --> 08:19.760
but it's of that order of magnitude, and perhaps it's the connections, 1,000 to 10,000 synapses

08:19.760 --> 08:23.000
per neuron, so it's a very complex system.

08:23.000 --> 08:27.200
So it's no wonder, you know, we can't give ourselves too hard a time that we haven't

08:27.200 --> 08:32.400
built it yet, because, you know, it's complex, and also, you know, the earth's 4 billion

08:32.400 --> 08:38.120
years old, we've had a few years, okay, we didn't just come up with this stuff yesterday,

08:38.120 --> 08:42.800
you know, we can go back 10,000 years, 20,000 years, we were pretty much living in caves,

08:42.800 --> 08:43.800
right?

08:43.800 --> 08:47.840
It's only the last 100 or so years that we've kind of, you know, hit this exponential where

08:47.840 --> 08:51.400
we're taking off, and the singularity is there, and all that kind of stuff, right?

08:51.400 --> 08:56.040
So we're living in very interesting times, but this is where intelligence has brought

08:56.040 --> 09:00.080
us, and this is where we are, we're sitting in this conference talking about it, right?

09:00.080 --> 09:03.880
We wouldn't have been doing this maybe even 10 years ago, okay?

09:03.880 --> 09:05.200
So we're ready to build it.

09:05.200 --> 09:06.720
How far have we come?

09:06.720 --> 09:09.280
I would argue not very far.

09:09.280 --> 09:14.080
All these talks we've seen today have all been about deep learning and statistical methods.

09:14.080 --> 09:20.560
The best we've done, I think, is around 50% for logical, mathematical, linguistic.

09:20.560 --> 09:23.720
The last talk was on BERT, it's super impressive stuff.

09:23.720 --> 09:29.480
There's GPT2 with open AI, there's BERT with Google, you know, Facebook, Microsoft, everyone,

09:29.480 --> 09:34.560
all the big tech companies are plowing ahead with these statistical methods, but there's

09:34.600 --> 09:38.880
nothing to do with general intelligence, so, you know, statistics will only get us so far,

09:38.880 --> 09:39.880
right?

09:39.880 --> 09:43.680
And in fact, when it comes to introspection, thinking about the universe, they're actually

09:43.680 --> 09:45.800
zero, they're not even off the ground, okay?

09:45.800 --> 09:49.880
They haven't even started, haven't even begun, and they never will do because it's, statistics

09:49.880 --> 09:51.640
won't do it.

09:51.640 --> 09:53.160
Physics will, statistics won't.

09:53.160 --> 09:58.640
I'm not trying to discredit anyone here, I'm just trying to focus on general intelligence,

09:58.640 --> 09:59.640
okay?

09:59.640 --> 10:01.400
Okay, so how will we get there?

10:01.440 --> 10:06.160
Well, it takes a village to create an AGI, just as it takes a village to raise a child,

10:06.160 --> 10:07.160
right?

10:07.160 --> 10:10.560
It's going to take a village to build these things, so it's not just physicists, it's

10:10.560 --> 10:15.680
not just computer scientists, it's not just, you know, psychologists, it's all of us together,

10:15.680 --> 10:21.680
so it's neuroscientists, psychologists, physicists, computer scientists, everybody, politicians,

10:21.680 --> 10:26.320
because this is general intelligence, we need everybody in the room together.

10:27.320 --> 10:34.560
Okay, so, you know, so physically, you know, biology, biologically and non-biologically,

10:34.560 --> 10:41.680
let's have a, take a look at, you know, how, how physically intelligence manifests, okay?

10:41.680 --> 10:50.960
So, biology, very clever, we start with bacteria, no, no central nervous system, no neurons,

10:50.960 --> 10:55.400
nothing, and yet they survive, they reproduce, they're intelligent, okay?

10:55.400 --> 10:58.640
They're much more intelligent than us, maybe they'll survive longer than us, the rate we're

10:58.640 --> 11:04.200
going, I'm not putting my bets right now, so, you know, that is intelligence without

11:04.200 --> 11:09.360
even a single neuron anywhere to be seen, so they're using chemical gradients, they're

11:09.360 --> 11:14.160
just using the laws of physics to wiggle and wobble about, but they've learned how to reproduce,

11:14.160 --> 11:15.560
create DNA and reproduce.

11:15.560 --> 11:21.880
They haven't learned anything, right, that's a, that's an anthropomorphism, you know, this

11:21.880 --> 11:29.480
is, this is what the laws of physics can do and has done, you know, in terms of biology.

11:29.480 --> 11:35.360
The first thing with the central nervous system is the C. elegans, I think it has 130 odd

11:35.360 --> 11:42.520
neurons, so arguably this is the dumbest thing with the central nervous system, so, but yet

11:42.520 --> 11:47.880
it can, you know, understand, it can survive, it eats, it reproduces, the bumblebee has

11:47.880 --> 11:53.160
about a million neurons, this is how biology does things, it can navigate, it does its

11:53.160 --> 11:59.400
wiggle dance, it's societal, it lives in a society, and right up to us, the brain, the

11:59.400 --> 12:05.200
human brain in fact, you know, you've got all the mammal elephants, fish, chimpanzees,

12:05.200 --> 12:12.240
us, right, so there's a whole spectrum here of intelligence, you know, assuming, assuming

12:12.600 --> 12:18.480
we'll start with the, you know, the simplest systems and build up, but is there something

12:18.480 --> 12:25.360
here that unites these, all of these systems here, you know, because I'm interested in

12:25.360 --> 12:30.240
understanding theoretically what intelligence is, in other words, you know, writing down

12:30.240 --> 12:35.400
the mathematical equations that we will use to guide us when we build these things, okay,

12:35.400 --> 12:40.120
not just sort of trying, does this work, does this work, I'll add another neuron, another

12:40.120 --> 12:44.360
layer to my deep neural network, I want to understand the basic physical, the physics

12:44.360 --> 12:50.840
of intelligence, or, you know, we do as a community, the AGI community, okay, so the

12:50.840 --> 12:57.680
first thing we notice is that biology is hierarchical, we start off with atoms, they're certainly

12:57.680 --> 13:03.680
not intelligent, molecules, neurons, they're not intelligent unto themselves, but when

13:03.680 --> 13:08.920
you start connecting these things together, they connect home, then intelligence emerges

13:08.920 --> 13:15.360
from there, and then we have us, you know, agents, and then we have societies and nations

13:15.360 --> 13:22.800
and finally the world, so, you know, the whole thing is hierarchical from atoms up to nations,

13:22.800 --> 13:28.320
so this general theory will have to explain the whole lot, okay, so it's a big ask, right,

13:28.320 --> 13:32.320
we're actually trying to describe the whole thing and not just bits of it, okay, so just

13:32.320 --> 13:37.080
to kind of sort of expand your mind, put it all in perspective.

13:37.080 --> 13:41.420
So we're coming up with a truly general theory of intelligence, and that's what a neuron

13:41.420 --> 13:45.760
looks like, it's super complex, do we need to go to this level, you know, there's a lot

13:45.760 --> 13:52.800
of open questions, we don't know, we'll see, okay, we'll just see, nature does, clearly,

13:52.800 --> 13:58.080
because that's what a neuron looks like, but when we build these systems will we have to,

13:58.080 --> 14:03.160
it's a very, very, very interesting and open question right now, okay, but it won't stop

14:03.160 --> 14:06.680
us perhaps coming up with the underlying theory.

14:06.680 --> 14:10.920
So this is what a brain looks like, this is what intelligence looks like, it's organized

14:10.920 --> 14:17.320
into structures, repeating structures of about two million neurons in these so-called cortical

14:17.320 --> 14:24.320
columns, again and over and over and over again, so if somebody goes blind, God forbid,

14:24.320 --> 14:30.360
some of those neurons that we use to process visual information are quickly repurposed

14:30.400 --> 14:37.240
into processing sound, okay, so the kind of general, there's a generality there, these

14:37.240 --> 14:43.120
are just information, these are information processing systems that seem to have some

14:43.120 --> 14:48.880
sort of generality, so we do know that, that's something we do know so far, and I'm going

14:48.880 --> 14:54.680
up the hierarchy here, here's the connectome, so it's all connected, besides these tens

14:54.680 --> 14:59.960
of tens of thousands of synapses between each neuron, these things are organized into

14:59.960 --> 15:04.520
some larger, if you go up one level in this hierarchy, then you start to see this connectome

15:04.520 --> 15:09.720
forming, whether that's in humans or even bees, you know, there's this layer above

15:09.720 --> 15:15.480
the neuron set, maybe that's the right layer to start with, okay, and then above that then

15:15.480 --> 15:22.160
that's attached to a central nervous system and all living beings, a fish, a bee, a human,

15:22.160 --> 15:27.480
so it's not just a brain and a jar, although some might argue Stephen Hawking was kind

15:27.480 --> 15:31.440
of that because he had that terrible disease and there are people, so we can function like

15:31.440 --> 15:36.520
that, but we're really interested in building the whole physical as well, but the brain

15:36.520 --> 15:40.600
is the main thing, once we've cracked that, we've cracked intelligence, I'm just saying

15:40.600 --> 15:47.200
we connect it to the rest of our system, do we need kidneys? I doubt it, I doubt we'll

15:47.200 --> 15:53.520
have this thing, a system with kidneys and lungs and everything else, right, but that's

15:53.520 --> 15:59.800
how biology has done it in every single thing, so there's this other part, 90%, you know,

15:59.800 --> 16:04.400
which I think we need to worry about the brain more than the rest of it, but the rest of

16:04.400 --> 16:09.920
it's super clever, but kind of clunky, it's just, nature's put us together like that,

16:09.920 --> 16:15.440
we may not need to go down to that, consider that so much, but if we're building robotics

16:15.560 --> 16:23.120
we will, but a robot might not have kidneys, but it needs to be able to move around fluidly,

16:23.120 --> 16:27.600
and we haven't quite got that yet, even though Atlas does nice backflips and super, I mean

16:27.600 --> 16:32.880
it's getting pretty good, isn't it, every month Boston Dynamics comes out with a new

16:32.880 --> 16:39.160
video, it's like, oh my God, it's like so human, and then they beat themselves, but

16:39.160 --> 16:45.400
it's not intelligent, it can't play chess, it can't ponder the universe, its own existence,

16:45.600 --> 16:48.880
it doesn't even know it's alive, that's how dumb it is, but it's very good with the

16:48.880 --> 16:54.920
physical part, okay, that's all part of intelligence, and then the social systems, we talk about

16:54.920 --> 17:05.000
cloud robotics, form robotics, social intelligence, that's the final layer, okay, so here's where

17:05.000 --> 17:10.280
we are with the non-biological, you know, we've started off with CPUs of von Neumann

17:10.320 --> 17:16.560
architecture we've heard about today, separating the processing from the memory, and then we've

17:16.560 --> 17:20.600
also heard that biology doesn't do that, it does the processing in the memory on the

17:20.600 --> 17:26.240
same thing, Neuron is both a memory and a processor, so none of these, there's this

17:26.240 --> 17:31.520
little von Neumann architecture, okay, so that's what it looks like, it's beautiful,

17:31.520 --> 17:36.720
we saw a picture of a TPU version 3 in the last slide, it's like a supercomputer, it

17:36.720 --> 17:44.840
does like a petaflop or something or more, graph core, there's 100 petaflops in like

17:44.840 --> 17:49.680
eight racks, you know, that's the world's most powerful supercomputer, almost, not quite,

17:49.680 --> 17:55.360
but it's getting up there, so these are ASICs, they're specifically designed to multiply

17:55.360 --> 18:00.600
huge matrix, billion by billion matrices together, which the brain isn't doing clearly, and you

18:00.600 --> 18:04.240
know, that's how many times bigger than the brain is that, right, it's got nothing to

18:04.280 --> 18:08.520
do with general intelligence, but it's super good at multiplying, it's good at linear algebra,

18:08.520 --> 18:15.680
it'll statistically, you know, calculate things, that's why BERT will get statistically brilliant,

18:15.680 --> 18:20.560
but it'll never understand Shakespeare, because it can't, because it's linear algebra, right,

18:20.560 --> 18:26.560
linear algebra doesn't do that, okay, and there is the world's biggest, it's 3x a flop,

18:26.560 --> 18:34.240
it's summit, chock full of GPUs and I think AMD processors, super impressive, but it's

18:34.240 --> 18:40.160
as dumb as a brick, right, doesn't do anything, it's a big calculator, so what are we missing,

18:40.160 --> 18:48.320
so we do all that in three pound, right, we don't need three football fields or 10 megawatts,

18:49.600 --> 18:55.840
we need a couple of sandwiches and apple and a drink, you know, and we can discover the laws

18:55.840 --> 19:04.400
of the universe, okay, so clearly we're not even close by any of those other approaches,

19:04.400 --> 19:11.600
maybe one approach in hardware is neuromorphic computing, which stated aim is to replicate

19:11.600 --> 19:16.320
the brain, okay, in hardware, and so there's a project called Spinnaker, part of the human

19:16.320 --> 19:21.120
brain project, which is doing that, Steve Furber, who was part of ARM, based at University of

19:21.120 --> 19:27.200
Manchester, been working for the last 20 years, he's built, their team there have built, now under

19:27.200 --> 19:32.720
the wing of the human brain project, have built, I think, a billion artificial neurons, so they're

19:32.720 --> 19:41.280
analog, they process the information using analog, not digital, and it's more, it's not the von Neumann,

19:41.280 --> 19:47.280
it's kind of combined, so they call that memristors, where the memory and the processing is combined in

19:47.280 --> 19:52.480
the same place, and the architecture looks completely different, there it is, that's a

19:52.480 --> 19:57.920
billion neurons right there, so immediately we see, you know, it's a little bit smaller than

19:57.920 --> 20:06.480
the others, that's all analog computing, and that's what it looks like, so yeah, we start off with

20:06.480 --> 20:11.680
a thousand neurons per core, and then we put them into chips, and it's hierarchical, then we put 48

20:11.680 --> 20:17.120
chips on a board, 24 boards in a rack, we have 10 racks, right, and that's sitting in a data center

20:17.120 --> 20:22.640
in Manchester today, and you can log in now if you want to, set up an account, log in and start

20:22.640 --> 20:29.040
processing stuff using neuromorphic computing, and you can put in the MNIST data set, you can

20:29.040 --> 20:34.480
place a doku, you can play chess, and it doesn't do deep learning at all, it's processing it with

20:34.480 --> 20:40.000
neuromorphic algorithms and hardware, okay, so for me this is definitely a step in the right

20:40.000 --> 20:45.120
direction, so hardware is important, it's not everything, obviously the algorithms need to be

20:45.120 --> 20:50.400
there as well, but I think we need to be running it on the right hardware, otherwise it's a simulation,

20:50.400 --> 20:55.040
you can always simulate anything on a chip, but you need, you know, they've done that in the human

20:55.040 --> 21:01.600
brain project using, you know, the von Neumann architecture, I think they processed a second

21:01.600 --> 21:07.200
of what the brain can do, it took them like a week in the whole data center, so you know,

21:07.200 --> 21:11.520
you can always simulate things, but it's not efficient, so you can actually simulate in real

21:11.520 --> 21:16.160
time using this neuromorphic architecture, because it runs efficiently like the brain,

21:16.160 --> 21:22.960
I think it's about a thousand times less efficient than biology, whereas the CPUs and

21:22.960 --> 21:28.640
everything else that we saw, digital is about a million times less efficient, so it's definitely

21:28.640 --> 21:33.360
a step, and this is the first generation, so we're going to iterate just like we did with the CPU

21:33.360 --> 21:38.640
processing and the digital, we've had 50 years, we've got 10 billion transistors on a thing,

21:38.640 --> 21:43.760
a centimeter big, right, so we'll do the same with neuromorphic, we'll have generation upon

21:43.760 --> 21:48.640
generation, and soon we'll have 100 billion neurons, because it's Moore's law, it's exponential,

21:49.200 --> 21:55.760
and we will see, you know, sort of human level intelligence, whether it will be sentient and

21:56.880 --> 22:02.000
is down to the algorithms, actually, so I think we have the hardware, we're at the very beginning

22:02.000 --> 22:06.560
of this journey with the hardware, but we need algorithms, so let's look at the algorithms, so

22:07.120 --> 22:10.880
that's another one, the brain scales, that's the University of Heidelberg here in Germany,

22:10.880 --> 22:15.920
that's part of the human brain project as a spinnaker versus the Google TPUs, I would argue

22:15.920 --> 22:21.280
the one on the left with neuromorphic is the right hardware to be working on for general

22:21.280 --> 22:26.160
intelligence, okay, and it's quantum computing, nothing to do with how the brain works, but,

22:26.160 --> 22:31.520
you know, sexy pictures, so I put it up there, and it is, it is like the last form of computing,

22:31.600 --> 22:36.320
right, you cannot forget it, it's a big deal, it's going to come online, but I don't think it will be,

22:37.120 --> 22:42.480
you know, used to, you know, understand nature too well, I think biology doesn't use it, so I

22:42.480 --> 22:46.800
doubt we might have to go to the quantum level, but the quantum will be very important in other

22:46.800 --> 22:52.560
aspects, perhaps not general intelligence, okay, so there's the four summary of everything I've

22:52.560 --> 22:57.360
talked about, the four different types of hardware, the digital, the neuromorphic, quantum, and then

22:57.360 --> 23:05.920
biology, right, so we want to try to build the thing in the lower right hand corner here,

23:05.920 --> 23:12.160
and I think neuromorphic is getting, that's the way we'll do it, and that's what they look like,

23:12.160 --> 23:16.800
okay, so the brain, you see the similarity a little bit, the neurons in the brain, the digital,

23:16.800 --> 23:21.520
the neuromorphic, and quantum looks a bit out on its own weird, but ultimately it's these little

23:21.520 --> 23:28.400
units of information processing, okay, and then the data center of the future won't just be classical

23:28.400 --> 23:36.880
computing, it'll be a mix of quantum, neuromorphic, and classical, so deep learning, quick recap,

23:36.880 --> 23:42.000
that's what it looks like, this is what general intelligence isn't, so it's not that, it's not

23:42.000 --> 23:49.280
that, and that's, you know, deep learning is not AGI, so AGI is linear algebra, so you know,

23:49.280 --> 23:53.680
you're just summing up the weights times these vectors, and billion by billion matrices,

23:53.680 --> 23:59.680
it does not give us a neuron, absolutely, not even close, but never will do, and it was never,

23:59.680 --> 24:04.000
it was never meant to, to be honest, if you talk to the researchers like Jan Lacoon and Jeff Hinton,

24:04.000 --> 24:09.360
they, we're not trying to imitate the brain at all, we just found the stuff that works really well,

24:09.360 --> 24:14.880
but, and then Jeff Hinton, he's in my last slide, says that, you know, if we think really hard about

24:14.880 --> 24:19.280
how nature does it, biology will, that's how we're going to do it, and he's recently said,

24:19.280 --> 24:22.720
everything I've ever done on deep learning is sort of, I'm going to have to put that to one

24:22.720 --> 24:26.960
side now, because to get to the next level, and I saw a slide in some other presentation today,

24:28.080 --> 24:31.840
you know, it's starting to get a bit mainstream now, you know, deep learning is running out of

24:31.840 --> 24:36.480
steam, you know, we can maybe tweak the knobs and get another two or three percent of accuracy,

24:36.480 --> 24:40.320
but yeah, where do we go, it's not general, it's very specific, it's not going to give us those

24:40.320 --> 24:45.360
nine types of intelligence, and I think that's what people are trying to say, even though they

24:45.360 --> 24:50.400
don't quite realize perhaps what they're saying, but that thing on the left is what we're trying to

24:50.400 --> 24:55.920
build, not that little bit of linear algebra on the right. Okay, so what is the theory, okay,

24:56.800 --> 25:01.040
you know, I'd be, I could just walk off the stage now and say, ah, you know, we don't,

25:01.040 --> 25:07.280
I don't know, thanks for coming, you know, spending all your money, but I'll try, I'll try, I'll give

25:07.840 --> 25:16.160
you something, a bit more than that, so let's see, so I mentioned earlier that it's not statistical,

25:16.160 --> 25:21.040
right, so what is it, it's physics, right, everything is built using the laws of physics,

25:21.040 --> 25:26.480
so why not the brain, right, why not, let's start there, it's nice and simple, so what do we know

25:26.480 --> 25:31.760
about physics, right, well we know Newton's laws, we know relativity, we know general relativity,

25:31.760 --> 25:37.440
we have Maxwell's equations from last century, we're standing on shoulders of so many giants

25:37.440 --> 25:43.040
here, Maxwell, Newton, you know, all the greats, Helmholtz, Boltzmann, Gibbs, you know, we got the

25:43.040 --> 25:49.280
laws of thermodynamics, we got quantum mechanics, we don't think we'll need that, but we still have

25:49.280 --> 25:52.800
it, we have relevance at quantum mechanics, we have dark energy, we have stuff we don't know,

25:52.800 --> 25:57.600
dark energy, dark matter, we're probably not involved with intelligence, the thing is that

25:57.600 --> 26:02.160
all of that can be encapsulated in something called the principle of least action,

26:03.280 --> 26:09.920
which says that nature behaves to minimize the free energy of any system, you know,

26:10.640 --> 26:15.440
whether that's microscopic or macroscopic, whether it's a millisecond, a nanosecond,

26:15.440 --> 26:20.240
or the age of the universe, there's this fundamental underlying principle of physics,

26:20.240 --> 26:25.520
if you did a PhD in physics, who did a PhD in physics, yes, so a couple of people here

26:25.520 --> 26:29.920
will have seen this principle of least action, and you write it down, it's a nice beautiful

26:29.920 --> 26:35.040
formulation, you can write it down in Lagrangian or Hamiltonian form, but it's, you know, one line

26:35.040 --> 26:43.440
and you can use it in principle to describe any system, okay, I say in principle because, you

26:43.440 --> 26:47.600
know, nature is complicated, you know, the brain's complicated, as soon as you get more than a few

26:47.600 --> 26:53.360
atoms, you know, or a few molecules, it's hard, right, so, but in principle, this is the underlying

26:53.360 --> 26:57.200
principle, so that's where I'm going to start, right, with the theory of intelligent, I'm going

26:57.200 --> 27:02.000
to say if we can use it for everything else, then let's apply it to the brain, see how far we get,

27:02.560 --> 27:07.040
that's what it looks like, there's a beautiful book just written, I think, yeah, last year at Cambridge

27:07.040 --> 27:11.440
University Press, surprisingly, there's nothing else before this, because it's been around about

27:11.440 --> 27:16.000
100 years, it's called the principle of least action, it's got all the different examples in the world

27:16.000 --> 27:22.720
of thermodynamics, classical mechanics, steam trains, computers, digital, quantum, everything,

27:22.720 --> 27:26.800
chapter on each, how it's applied, how it's applied, how it's applied, how it's applied,

27:27.600 --> 27:32.080
so they need an extra chapter on how it's applied to the brain, I think, but that's what it looks

27:32.080 --> 27:39.920
like, you know, that s is the action, the q is momentum, t is time, and q dots, you know, the

27:39.920 --> 27:46.800
dv dt, the change of momentum with change in time, and delta s equals zero is all the physics,

27:47.360 --> 27:52.880
it's the change in action, nature acts so that delta s, where s is the action,

27:54.320 --> 27:59.280
is, it tries to minimize that quantity where s is that in terms of Lagrangian, okay, don't

27:59.280 --> 28:04.080
worry about the math or the physics, we're not going to go there, but so let's apply that to the

28:04.080 --> 28:10.720
intelligence and see how far we get, because it works for everything else, okay, so again, it's not

28:10.720 --> 28:15.760
just about pattern recognition, it's about modeling the world, okay, we model stuff, we can imagine,

28:15.840 --> 28:21.040
we problem solve, we can build new models, we can understand, right, we don't just do statistical

28:21.040 --> 28:26.720
analysis, otherwise it'd be zombies, right, or we'd be a silicon chip, we'd be built into our

28:26.720 --> 28:34.640
factory and we're not, so here are some theoretical approaches, I'm going to choose the Friston

28:34.640 --> 28:40.560
active inference one, which uses the delta s equals zero, the others don't, but these are, these are

28:40.560 --> 28:49.040
very, very, very, you know, credible attempts at general intelligence and all of these people

28:49.040 --> 28:53.200
have been working at least 30 years on these theories, so they're certainly not to be dismissed,

28:53.200 --> 28:57.760
and let's pick this one and just do all the others are wrong, there's going to be bits of each that

28:57.760 --> 29:04.640
it kind of have, have some, there's going to be overlap, so you know, we've, Helmholtz started

29:04.640 --> 29:11.600
with statistical physics, right, it's, the brain is 100 billion neurons, it's a big messy, warm,

29:11.600 --> 29:15.360
complex system, so statistical physics is over 100 years old.

29:22.960 --> 29:31.280
Okay, so I will wind it up, yeah, let me wind it up, so yeah, 30 years for all of these, right,

29:31.280 --> 29:39.120
I'm going to pick Friston in the last two minutes, okay, now active inference, we can look this up,

29:40.400 --> 29:45.200
again it uses the free energy, it's minimizing the free energy, let me just flick through and then I'll

29:45.200 --> 29:51.360
sum it up, there's Professor Friston there and we, we don't have time to hear, so this is what it

29:51.360 --> 29:55.760
looks like, we can draw diagrams and pretty pictures, we can write down equations, we can have

29:55.760 --> 30:00.720
me, us in the environment, the environment acting back on the agent, the agent acting back on the

30:00.720 --> 30:05.920
environment, all the physics is in place, we can write down the equations for it, we can do it for

30:05.920 --> 30:11.200
bacteria or the brain, so it works on all systems, there's the math that's super, super ugly, but

30:11.200 --> 30:17.520
it's, you know, it's, that's theoretical neuroscience and this is, that's the equation of, that's like

30:17.520 --> 30:22.480
the general theory of relativity for, for the brain, right, so there you saw it, he's got loads of

30:22.480 --> 30:28.960
papers, can we build it, I say yes, we have the data, we have the theory, we have the algorithms

30:28.960 --> 30:35.600
and we have the hardware, okay, and there's some AGI project, there's Merrick's here, Ben's here,

30:35.600 --> 30:40.400
there's a, JÃ¼rgen Schmidt-Huber's not here, these are all super clever people doing super clever

30:40.400 --> 30:47.120
things and I picked our active inference as one because I feel it's the one most based on physics

30:47.120 --> 30:51.680
and I'd say we're at the beginning of our journey, it might take us five or ten years to sort of

30:51.680 --> 30:56.320
build us as we wait for the hardware especially to mature, I believe we have the algorithms,

30:56.400 --> 31:01.680
it's a super bold statement to be saying, but I encourage you to read some of the papers

31:01.680 --> 31:06.000
and there's Jeff Hinton saying at the very end, you know, this is three years ago,

31:06.000 --> 31:10.080
the conceptual breakthroughs will take us, we need new conceptual breakthroughs,

31:10.080 --> 31:14.240
I believe the breakthroughs are going to come when we understand the brain, thank you very much.

31:16.960 --> 31:21.360
I'm, I'm so sorry for being so rushed, I also would like to know more,

31:21.840 --> 31:26.640
can I steal five minutes of the Q&A, so like for just one question, I know that he overtake,

31:26.640 --> 31:30.480
he's going to make it up to you. Okay, one question. He owes you five minutes of lifetime,

31:30.480 --> 31:35.760
yeah, I'll make sure you get that. I do, I do. Five minutes of your lifetime to him. Thank you so

31:35.760 --> 31:43.120
much. Thank you so much for the question, sorry for your time, just in taking one question,

31:43.120 --> 31:48.640
so I'm just going to be very quick to keep on schedule, so I'm going to just speak in very

31:48.640 --> 31:54.640
short words, so Richard Feynman, you know, you've been a music producer, besides all your other

31:54.640 --> 31:59.200
work in the academia, and you've shown us a great slide where you said for AGI we need

31:59.200 --> 32:06.240
computer sciences, physics, neurosciences, and psychology, so bringing these four things together,

32:06.240 --> 32:11.200
I mean, the question is, and you've been in academia, in our society every, every incentive

32:11.200 --> 32:16.240
is to be very specialized and to really focus on one subject and then people don't talk and connect

32:16.320 --> 32:21.440
enough with each other, and I think we need that for AGI. What are you doing or what can we do as

32:21.440 --> 32:25.440
a society to bring these four groups together? Is there conferences to exchange with those four

32:25.440 --> 32:29.440
groups? I mean, how do you get these different people, these different tribes talking with each

32:29.440 --> 32:33.440
other? Is that the short question? Is that the short question? Well, it was a long question, I hope he

32:33.440 --> 32:38.560
has a short answer, but yeah, okay, yeah, so Professor Friston's group's a neuroscience group,

32:38.560 --> 32:43.200
it's a theoretical neuroscience group, they have very strong mathematicians, very strong computer

32:43.200 --> 32:47.920
scientists, DeepMind's a bit of a, you know, case study in this, they get neuroscientists,

32:47.920 --> 32:51.840
computer science, sitting in the same room, so it's the very beginning, but I think you need

32:51.840 --> 32:59.520
more, I think you need psychologists, yeah, so we need a little bit more input from other science

32:59.520 --> 33:06.800
sectors to begin with, and yeah, I mean, it's, yeah, I mean, ultimately you have to build these

33:06.800 --> 33:14.320
things, the theory is going to come from a very, very strong scientific, mathematically competent

33:14.320 --> 33:19.760
person, okay, you can get all the psychologists talking in a room and everybody else, but ultimately

33:19.760 --> 33:24.320
someone or a couple of people have to write down a scientific theory, just like Einstein wrote down

33:24.320 --> 33:28.960
the theory of relativity, so maybe I was a little bit generous, you know, we need everybody, we need

33:28.960 --> 33:33.920
the ideas from everywhere, but the actual person himself or herself is going to be, have to be

33:34.000 --> 33:39.120
super strong a math, we saw some of the math, it's not simple, it takes a while, right, it's a huge,

33:39.120 --> 33:43.920
just like the theory of general relativity, and I'll end here, you know, we can understand the

33:43.920 --> 33:48.400
concepts, but the actual math is really, really, really hard, right, I don't know if you've ever

33:48.400 --> 33:54.320
tried it to solve the, no, the field equations, I have, they're not easy, right, yeah, so don't

33:54.320 --> 34:00.720
expect this to be easy, it's going to be simple, but the math is still going to be, you know, hard,

34:00.720 --> 34:06.400
okay, yeah, okay, thank you. Okay, Peter, one more question, where can we find your slides,

34:06.400 --> 34:11.760
are you going to upload them somewhere? Yeah, I thought the conference was going to upload them,

34:11.760 --> 34:18.640
if not, then my slide share is, they're available on my slide share, so if you go to

34:18.640 --> 34:23.600
slide share and just Google Peter Morgan, I guess, you'll find you, you'll find him, okay,

34:24.560 --> 34:28.800
I think that's the best way, and the other thing is just to look at Carl Friston, he has a great

34:28.800 --> 34:33.840
website with all his papers, which is super heavy going, but if you're really, really,

34:34.560 --> 34:38.000
I don't know, you know, if you really believe you want to try and solve intelligence,

34:38.000 --> 34:44.720
that's the best place to start.

