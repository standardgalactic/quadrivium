Hi. I'm delighted to have with us here today my old friend Professor Fei Fei Li. Fei Fei
is a professor of computer science at Stanford University and also co-director of HAI, the
Human-Centered AI Institute. And previously, she also was responsible for AI at Google
Cloud as a chief scientist for the division. It's great to have you here, Fei Fei.
Thank you, Andrew. Very happy to be here.
So, I guess, actually, how long have you known each other? I've lost track.
Definitely more than a decade. I mean, I've known your work, right, before we even met.
And I came to Stanford 2009, but we started talking 2007, so 15 years.
And I can still have very clear memories of how stressful it was when, collectively,
you know, a bunch of us, me, Chris Manning, a bunch of us, were trying to figure out how
to recruit you to come to Stanford.
It wasn't hard. I just needed to sort out my students and life, but it's hard to resist
Stanford.
It wasn't really great having you as a friend and colleague here.
Yeah, me too. It's been a long time. And we're very lucky to be the generation seeing
AI is great progress.
Okay, so there was something about your background that always found inspiring, which is, you
know, today people are entering AI from all walks of life. And sometimes people still wonder,
oh, I majored in something or other. Is AI a right path for me? So I thought one of the
most interesting parts of your background was that you actually started out not studying
computer science or AI, but you started out studying physics and then had this path to
becoming, you know, one of the most globally recognizable AI scientists. So how did you
make that switch from physics to AI?
Right. Well, that's a great question, Andrew, especially both of us are passionate about
young people's future and their coming to the world of AI. The truth is, if I could
enter AI back then more than 20 years ago, today, anybody can enter AI because AI has
become such a prevalent and globally impactful technology. But myself, maybe I was an accident.
So I have always been a physics kid or STEM kids. I'm sure you were too. But physics was
my passion all the way through, you know, middle school, high school, college. I went
to Princeton and majored in physics. And one thing physics has taught me till today is
really the passion for asking big questions, the passion for seeking North stars. And I
was really having fun as a physics student at Princeton. And one thing I did was reading
up stories and just writings of great physicists of the 20th century and just hear about what
they think about, you know, the world, especially people like Albert Einstein, Roger Penrose,
you know, Erring Schrodinger. And it was really funny to notice that many of the writings
towards the later half of the career of these great physicists were not about just the atomic
world or the physical world, but pondering about equally audacious questions like life,
like intelligence, like human conditions. You know, Schrodinger wrote this book, What
Is Life? And Roger Penrose wrote this book, Emperor's New Mind, right? And that really
got me very curious about the topic of intelligence. So one thing led to another during college
time, I did the intern at a couple of neuroscience labs, and especially vision related. And I
was like, wow, this is just as audacious a question to ask as the beginning of the universe,
or what is matter made of. And that got me to switch from undergraduate degree in physics
to graduate degree in AI, even though I don't know about you, during our time, AI was a
dirty word. It was AI winter, so it was more machine learning and computer vision and computation
on neuroscience. Yeah, I know. Honestly, I think when when I was in undergrad, I was
too busy writing code, I just, you know, managed to blithely ignore the AI winter and just kept
on coding. Yeah, well, I was too busy solving PDE equations.
And so actually, do you do you have an audacious question now? Yes, my audacious question is
still intelligence. I think since Alan Turing, humanity has not fully understand what is
the fundamental computing principles behind intelligence. You know, we, we, we today we
use the words AI, we use the word AGI. But at the end of the day, I still dream of a
set of simple equations or simple principles that can define the process of intelligence,
whether it's animal intelligence or machine intelligence. And this is similar to physics.
For example, many people have joined the analogy of flying, right? Are we replicating birds
flying, or are we building an airplane? And a lot of people ask the question of the relationship
between AI and brain. And to me, whether we're building a bird or replicating a bird or building
an airplane, at the end of the day, aerodynamics and physics that govern the process of flying.
And I do believe one day we'll discover that. I sometimes think about this, you know, one
learning algorithm hypothesis, could a lot of intelligence, maybe not all, but a lot of
it be explained by one or a very simple machine learning principles. And it feels like we're
still so far from cracking that nut. But in the weekends, when I have spare time, when
I think about learning algorithms and where they could go, this is one of the things I
still, you know, I'm excited about, right, just thinking about.
I totally agree. I still feel like we are pre Newtonian. If we're doing physics analogy
before Newton, there has been great physics, great physicists, a lot of phenomenology, a
lot of studies of how the astrobodies move and all that. But it was Newton who start to
write the very simple laws. And I think we are still going to that very exciting coming
of age of AI as a basic science. And we're pre Newton, in my opinion.
It's really nice to hear you talk about how despite machine learning and AI having come so
far, it still feels like there are a lot more unanswered questions, a lot more work to be done
by maybe some of the people joining the field today than work that's already been done.
Absolutely. I mean, let's let's calculate. It's only what 60 years about. It's a very
nascent field modern his physics and chemistry and biology are all hundreds of years. Right. So
I think it is very, it is very exciting to be entering the field of science of intelligence
and studying AI today. Yeah, I think I remember chatting with the late Professor John McCarthy
who had coined the term artificial intelligence. And boy, the field has changed since when,
you know, he conceived of it at the workshop and came up the term AI. But maybe another 10 years
from now, you know, maybe someone watching this will come up with a new set of ideas.
And then we'll be saying, boy, AI sure is different than what you know,
you and I thought it would be. That's an exciting future to build towards.
Yeah, I'm sure Newton would have not dreamed of Einstein. So, you know, our evolution of science
sometimes takes strides, sometimes takes a while. And I think we're absolutely in an exciting phase
of AI right now. You know, it's interesting hearing you paint this grand vision for AI.
Going back a little bit, there was one other piece of your background that I found, you know,
inspiring, which is when you're just getting started, I've heard you speak about how,
you know, you're a physics student, but not only that, you also you're also running a laundromat
to pay for school. And so just tell us more about that.
So I came to this country, to New Jersey, actually, when I was 15. And one thing great
about being in New Jersey is it was close to Princeton. So I often just take a weekend trip
with my parents and to admire the place where Einstein spent most of his career in the latter
half of his life. But, you know, with typical immigrant life, and it was tough. And by the time
I entered Princeton, my parents didn't speak English. And one thing led to another, it turns out
running a dry cleaner might be the best option for my family, especially for me to lead that
business because it's a weekend business. If it's a weekday business, it would be hard for me to be
a student. And it's actually, believe it or not, running a dry cleaning shop is very machine heavy,
which is good for a STEM student like me. So we decided to open a dry cleaner shop in
a small town in New Jersey called Persephone, New Jersey. It turned out we were physically not too
far from Bell Labs and where lots of early convolutional neural network research was
happening, but I had no idea. Actually, a summer intern at the AT&T Bell Labs way back.
That's right, with Rob Shapiro. With Michael Curran was my mentor. And Rob Shapiro invented
boosting great algorithms. So your coding AI, I was trying to cling to. No, that was only much
later in my life. Did I start interrunning? Yeah. And then it was seven years. I did that for
the entire undergrad and most of my grad school and I hired my parents.
Yeah, no, that's really inspiring. I know you've been brilliant at doing exciting work all your
life. And I think the story of running a laundromat to globally prominent computer scientists,
I hope that inspires some people watching this that no matter where you are, there's plenty
of room for young everyone. Don't even notice, my high school job was an office admin.
And so to this day, I remember doing a lot of photocopying. And the exciting part was using
this shredder. That was a glamorous one. But I was doing so much photocopying in high school,
I thought, boy, if only I could build a robot to do this photocopying, maybe I could do something
Did you succeed? I'm still working on it. We'll see. And then when people think about
you and the work you've done, one of the huge successes everyone thinks about is ImageNet,
where Hub established early benchmark for computer vision. It was really completely
instrumental to the modern rise of deep learning in computer vision. One thing I
bet not many people know about is how you actually got started on ImageNet.
So tell us the origin story of ImageNet. Yeah, well, Andrew, that's a good question,
because a lot of people see ImageNet as just labeling a ton of images. But where we began
was really going after a North Star, brings back my physics background. So when I entered
grad school, when did you enter grad school? Which year? 97. Okay, I was three years later
than you, 2000. And that was a very exciting period, because I was in the computer vision
and computational neuroscience lab of Pietro Peronna and Christoph Koch at Caltech. And
leading up to that, there has been, first of all, two things was very exciting. One is that the world
AI at that point wasn't called AI, computer vision or natural language processing,
has found its lingua de franco, its machine learning, statistical modeling as a new tool
has emerged, right? I mean, it's been around. And I remember when the idea of applying machine
learning to computer vision, that was like a controversial thing. Right, and I was the first
generation of graduate students who were embracing all the base net, all the inference
algorithms and all that. And that was one exciting happening. A second exciting happening that
most people don't know and don't appreciate, is that a couple of decades, probably more than
two or three decades of incredible cognitive science and cognitive neuroscience work
in the field of vision, in the world of vision, human vision, that has really established a couple
of really critical north star problems, just understanding human visual processing and human
intelligence. And one of them is the recognition of understanding of natural objects and natural
things, because a lot of the psychology and cognitive science work is pointing to us,
that is an innately optimized, whatever that word is, functionality and ability of human
intelligence. It's more robust, faster and more nuanced than we had thought. We even find neural
correlates, brain areas devoted to faces or places or body parts. So these two things led to my PhD
study of using machine learning methods to work on real-world object recognition. But it became
very painful, very quickly, that we are coming, banging against one of the most,
continue to be the most important challenge in AI and machine learning is the lack of
generalizability. You can design a beautiful model all you want if you're overfitting that model.
I remember when it used to be possible to publish a computer vision paper showing your
works on one image. Exactly. Yeah, it's just the overfitting, the models are not very expressive
and we lack the data. And we also, as a field, was betting on making the variables very rich by
hand-engineered features. Remember, every variable carrying a ton of semantic meaning,
but with hand-engineered features. And then towards the end of my PhD, my advisor,
Pietro and I start to look at each other and say, well, boy, we need more data. If we believe in
this North Star problem of object recognition, and we look back at the tools we have,
mathematically speaking, we're overfitting every model we're encountering. We need to take a fresh
look at this. So one thing led to another. He and I decided we'll just do a, at that point,
we think it was a large-scale data project called Caltech 101. I remember the data set. I wrote
papers using your Caltech 101 data set way back. You did. You and your early graduate student.
It helped benefit a lot of researchers. Yeah. Caltech 101 data set. That was me and my mom
labeling images on a couple of undergrads. But that was, it was the early days of internet.
So suddenly the availability of data was a new thing. You suddenly, I remember Pietro still
have this super expensive digital camera. I think it was Canon or something like $6,000
walking around Caltech taking pictures. But we are the internet generation. I go to Google
Image Search. I start to see these thousands and tens of thousands of images. And I tell Pietro,
let's just download. Of course, it's all that easy to download. So one thing led to another.
We built this Caltech 101 data set of 101 object categories. And about, I would say,
30 to 50, 30,000 pictures. I think it's really interesting that,
you know, even though everyone's heard of ImageNet today, even you kind of took a couple
of iterations where you did Caltech 101. And that was a success. Lots of people used it.
But it's the, even the early learnings from building Caltech 101 that gave you the basis to
build what turned out to be even, an even bigger success. Right. Except that by the time we start,
I became an assistant professor. We started to look at the problem. I realized it's way
bigger than we think. Just mathematically speaking, Caltech 101 was not sufficient to,
to power the, the algorithms. We decided to image, to do ImageNet. And that was the time people
start to think we're, we're doing too much. Right. It's, it's just too crazy. The idea of
downloading the entire Internet of images and mapping out all the English nouns was a little bit,
I start to get a lot of pushback. I remember at one of the CVPR conference when I presented the
early idea of ImageNet, a couple of researchers publicly questioned and said, said, if you cannot
recognize one category of object, let's say the chair you're sitting in, how do you imagine,
or what's the use of a dataset of 22,000 classes of 15 million images? Yeah. But, but in the end,
you know, that giant dataset unlocked a lot of value for, you know, countless number of
researchers around the world. So that, so that works. Well, I, I think it was the combination
of betting on the right North Star problem and the data that drives it. So it was a fun process.
Yeah. And, and, you know, to me, one of the, when I think about that story, it seems like one of
those examples where, you know, sometimes people feel like they should only work on projects without
the huge thing at the first outset, but I feel like for people working in machine learning,
if your first project is a bit smaller, it's totally fine. Have a good win, use the learnings
to build up to even bigger things. And then sometimes you get a, you know, ImageNet size win,
all of it. Yeah. Well, but in the meantime, I think it's also important to be driven by
an audacious goal, though, you know, you can size your problem or size your project as local
milestones and, and, and so on along this journey. But I also look at some of our current students,
they're so peer pressured by this current climate of publishing nonstop. It becomes more incremental
papers to just get into a publication for the sake of it. And I, I personally always push my
students to ask the question, what is the North Star that's driving you? Yeah, that's true. Yeah.
And you're right. You know, for myself, when I do research over the years, I've always
pretty much done what I'm excited about, where I want to, you know, try to push the view forward.
Doesn't it don't listen to people, have to listen to people, let them shape your opinion. But in
the end, I think the best research is, let the world shape their opinion. But in the end,
drive things forward using their own opinion. Totally agree. Yeah. It's your own inner fire,
right? So as your research program developed, you've wound up taking your, let's say, foundations
in computer vision and neuroscience and applying to all sorts of topics, including your very visibly
healthcare, looking at neuroscience applications. Would love to hear a bit more about that.
Yeah, happy to. I think the evolution of my research in computer vision also kind of follows
the evolution of visual intelligence in animals. And there are two topics that truly excites me.
One is, what is a truly impactful application area that would help human lives? And that's my
healthcare work. The other one is, what is vision at the end of the day about? And that brings me to
the, trying to close the loop between perception and robotic learning. So on the healthcare side,
you know, one thing, Andrew, there was a number that shocked me about 10 years ago when I met
my long-term collaborator, Dr. Arnie Milstein at Stanford Medical School. And that number is about
a quarter of a million Americans die of medical errors every year. I had never imagined a number
being that high due to medical errors. There are many, many reasons, but we can rest assured most
of the reasons are not intentional. These are her errors of unintended mistakes and so on.
For example? That's a mind-boggling number. I think it's made about 40,000 deaths a year from
automotive accidents, which is completely tragic. And this is even vastly tragic.
I was going to say that. I'm glad you brought it up. Just one example, one number within that
mind-boggling number is the number of hospital-acquired infection resulted in fatality is
more than 95,000. That's 2.5 times than the death of car accidents. And in this particular case,
hospital-acquired infection is a result of many things, but in large, a lack of good
hand hygiene practice. So if you look at WHO, there has been a lot of protocols about clinicians'
hand hygiene practice. But in real healthcare delivery, when things get busy and when the
process is tedious and when there is a lack of feedback system, you still make a lot of mistakes.
Another tragic medical fact is that more than $70 billion every year are spent in
in fall resulted injuries and fatalities. And most of this happened to elderlies at home,
but also in the hospital rooms. And these are huge issues. And when Arnie and I got together
back in 2012, it was the height of a self-driving car, let's say not hype, but what's the word,
right word, excitement in Silicon Valley. And then we look at the technology of smart sensing
cameras, LiDARs, radars, whatever, smart sensors, machine learning algorithm,
and holistic understanding of a complex environment with high stakes for human lives.
I was looking at all that for self-driving car and realized in healthcare delivery,
we have the same situation. Much of the process, the human behavior process of healthcare is in
the dark. And if we could have smart sensors, be it in patient rooms or senior homes, to help our
clinicians and patients to stay safer, that would be amazing. So Arnie and I embarked on this,
what we call ambient intelligence research agenda. But one thing I learned, which probably will lead
to our other topics, is as soon as you're applying AI to real human conditions, there's a lot of human
issues in addition to machine learning issues. For example, privacy. And I remember reading some
of your papers with Arnie and found it really interesting how you could build and deploy
systems that were relatively privacy preserving. Yeah, well, thank you. Well, the first iteration
of that technology is we use cameras that do not capture RGB information. You've used a lot of that
in self-driving cars, the depth cameras, for example. And there you preserve a lot of privacy
information just by not seeing the faces and the identity of the people. But what's really
interesting over the past decade is the changes of technology is actually giving us a bigger tool set
for privacy preserved computing in this condition. For example, on device inference,
you know, as the chip's getting more and more powerful, if you don't have to transmit any data
through the network and to the central server, you help people better. Federated learning,
we know it's still early stage, but that's another potential tool for privacy preserved computing
and then differential privacy and also encryption technologies. So we're starting to see
that human demand, you know, privacy and other issues is driving actually a new wave of machine
learning technology in ambient intelligence in healthcare. Yeah, that's great. Yeah, I've been
encouraged to see the, you know, real practical applications of differential privacy that are
actually real. Federated learning, as you said, probably the PR is a little bit ahead of the
reality, but I think we'll get there. But it's interesting how consumers in the last several
years have fortunately gotten much more knowledgeable about privacy and are increasingly
so important. I think the public is also making us to be better scientists.
Yeah, yeah. And I think, and I think ultimately, you know, people understanding AI holds everyone,
including us, but holds everyone accountable for really doing the right thing. Yeah, yeah. And,
you know, and on that note, one of the really interesting pieces of work you've been doing has
been leading several efforts to help educate legislators or help governments, especially U.S.
government, work towards better laws and better regulation, especially as it relates to AI.
This sounds like very important. And I suspect some days of the week,
I would get somewhat frustrating work, but we'd love to hear more about that.
Yeah, so I think first of all, I have to credit many, many people. So about four years ago,
and I was actually finishing my sabbatical from Google time, I was very privileged to work with
so many businesses, you know, enterprise developers, just just a large number and variety of vertical
industries and realizing AI's human impact. And that was when many faculty leaders at Stanford
and also just our president provost, former president and former provost all get together
realize there is a role, historical role that Stanford needs to play in the advances of AI.
We were part of the part of the birthplace of AI, you know, a lot of work our previous
generation have done and a lot of work you've done and some of our work I've done led to AI,
today's AI, what is our historical opportunity and responsibility? With that, we believe that the
next generation of AI education and research and policy needs to be human centered. And
having established the Human Center Institute, what we call HAI, one of the work that really took me
outside of my comfort zone or any expertise, is really a deeper engagement with policy thinkers
and makers. Because, you know, we're here in Silicon Valley and there is a culture in Silicon
Valley is we just keep making things and the law will catch up by itself. But AI is impacting human
lives and sometimes negatively so rapidly that it is not good for any of us if we the experts
are not at the table with the policy thinkers and makers to really try to make this technology
better for the people. I mean, we're talking about fairness, we're talking about privacy.
We also are talking about the brain drain of AI to industry and the concentration of data and
compute in a small number of technology companies. All these are really part of the changes of our
time. Some are really exciting changes, some have profound impact that we cannot necessarily
predict yet. So one of the policy work that Stanford HAI has very proudly engaged in is
we were the one of the leading universities that lobbied a bill called the National AI Research
Cloud Task Force Bill. It changed the name from Research Cloud to Research Resource. So now the
bill's acronym is NAIR, National AI Research Resource. And this bill is calling for a task force
to put together a roadmap for America's public sector, especially higher education and research
sector to increase their access to resource for AI compute and AI data. It really is
aimed to rejuvenate America's ecosystem in AI innovation and research. And I'm on the 12-person
task force for under Biden administration for this bill. And we hope that's a piece of policy that
is not a regulatory policy, it's more an incentive policy to build and rejuvenate ecosystems.
I'm glad that you're doing this to help shape U.S. policy and this type of making sure enough
resources allocated to ensure healthy development of AI feels like this is something that every
country needs at this point. So just from the things that you are doing by yourself, not to
speak of the things that the global AI community is doing, there's just so much going on in AI
right now. So many opportunities, so much excitement. I found that for someone getting
started in machine learning for the first time, sometimes there's so much going on,
it can almost be a little bit overwhelming. What advice do you have for someone getting
started in machine learning? Good question, Andrew. I'm sure you have great advice. You're one of the
world-known advocates for AI machine learning education, so I do get this question a lot as
well. And one thing you're totally right is AI really today feels different from our time.
During our time... Just further, I thought, now is still our time. That's true, when we were
starting in AI. I love that, exactly. We're still part of this. When we get started,
entrance to AI and machine learning was relatively narrow. You almost have to start from computer
science and go. As a physics major, I still had to wedge myself into the computer science track
or electrical engineering track to get to AI. But today, I actually think that there is a
remaining aspect of AI that creates entry points for people from all walks of life.
On the technical side, I think it's obvious that there's just an incredible plethora of
resources out there on the internet, from Coursera to YouTube to TikTok to GitHub.
There's just so much that students worldwide can learn about AI and machine learning compared
to the time we began learning machine learning. And also, any campuses, we're not talking about
just college campuses. We're talking about high school campuses. Even sometimes earlier, we're
starting to see more available classes and resources. I do encourage those of the young
people with a technical interest and resource and opportunity to embrace these resources,
because it's a lot of fun. But having said that, for those of you who are not coming from a technical
angle, who still are passionate about AI, whether it's the downstream application or
the creativity it engenders, or the policy and social angle or important social problems,
whether it's digital economics or the governance or history, ethics, political sciences,
there, I do invite you to join us, because there is a lot of work to be done. There's a lot of
unknown questions. For example, my colleague at HAI are questioning, are trying to find answers on,
how do you define our economy in the digital age? What does it mean when robots and software
are participating in the workflow more and more? How do you measure our economy? That's not an AI
coding question. That is an AI impact question. We're looking at the incredible advances of
generative AI, and there will be more. What does that mean for creativity and to the creators,
from music to art to writing? There is a lot of concerns, and I think it's rightfully so,
but in the meantime, it takes people together to figure this out, and also to use this new tool.
In short, I just think it's a very exciting time, and anybody with any walks of life,
as long as you're passionate about this, there's a role to play.
Yeah, and that's really exciting. We're going to talk about economics, think about my conversations
with Professor Eric Brynoson, studying the impact of AI on the economy. From what you're saying,
and I agree, it seems like no matter what your current interests are, AI is such a general purpose
technology that the combination of your current interests and AI is often promising. I find that
even for learners that may not yet have a specific interest, if you find your way into AI,
start learning things, often the interests will evolve, and then you can start to craft your own
path. And given where AI is today, there's still so much room and so much need for a lot more people
to craft their own paths to do this exciting work that I think the world still needs a lot more of.
Totally agree, yeah. So, one piece of work that you did that I thought was very cool was starting
a program, initially called Sailors, and then later AI for all, which was really reaching out
to high school and even younger students to try to give them more opportunities in AI,
including people of all walks of life. We'd love to hear more about that.
Yeah, well, this is in the spirit of this conversation. That was back in 2015. There was
starting to be a lot of excitement of AI, but there was also starting to be this talk about
killer robot coming next door, terminators coming. And I was, at that time, Andrew,
I was the director of Steveria Lab, and I was thinking, you know, we know how far we are from
terminators coming, and that seemed to be a really a little bit of far-fetched concern,
but I was living my work life with a real concern I felt no one was talking about,
which was the lack of representation in AI. At that time, I guess after Daphne has left,
I was the only woman faculty at Steveria Lab, and we're having very small, around 15% of women
graduate students, and we really don't see anybody from the underrepresented minority groups
in Stanford AI program, and this is a national or even worldwide issue, so it wasn't just Stanford.
Frankly, it still needs a lot of work today. Exactly. So how do we do this? Well, I got together
with my former student Olga Rosakowski and also a long-term educator of STEM topics,
Dr. Rick Sommer from a Stanford pre-collegiate study program, and thought about inviting
high schoolers at that time, women, high school young women, to participate in a summer program
to inspire them to learn AI, and that was how it started in 2015 and 2017. We got a lot of
encouragement and support from people like Jensen and Laurie Huang and Melinda Gates,
and we formed the National Nonprofit AI for All, which is really committed to training or
helping tomorrow's leaders, shaping tomorrow's leaders for AI from students of all walks of
life, especially the traditionally underserved and underrepresented communities, and
you know, till today, we've had many, many summer camps and summer programs across the country. More
than 15 universities are involved, and we have online curriculum to encourage students as well as
college pathway programs to continue support these students' career by matching them with
internships and mentors, so it's a it's a continued effort of encouraging students of all walks of
life. And I remember back then, I think your group was printing these really cool t-shirts that
asked the question, AI will change the world, who will change AI, and I thought the answer of
making sure everyone can come in and participate, that was a great answer. Yeah, still an important
question today. So that's a great thought, and I think that takes us to the end of the interview.
Any final thoughts for people watching this? Still, that this is a very nascent field.
As you said, Andrew, we are still in the middle of this. I still feel there's just so many questions
that, you know, I wake up excited to work on with my students in the lab, and I think there's a lot
more opportunities for the young people out there who want to learn and contribute and shape
tomorrow's AI. Well said, that's very inspiring. Really great to chat with you, and thank you.
Thank you, it's fun to have these conversations.
