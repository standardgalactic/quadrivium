Even Wolfram is a mathematician, computer scientist,
physicist, and businessman. Have I lied so far, Steve?
I don't know. So some people would not put mathematician first, but that's okay.
He's known for his work in computer science, mathematics, and theoretical
physics. The fellow of the American Mathematical
Society, founder and CEO of the software company
Wolfram Research, where he works as chief designer of Mathematica,
at the Wolfram Alpha NSERP engine. Now I'm going to move that away,
and I'm going to give it, you have also, besides the people in the
the attendees, there's also one, two, three, four, five
panelists that are here so far, and there might be some more.
Carl Friston, Ronnie Katzier, Sammy Benjiro. I can see the names, yeah.
Hi, Carl. The rest of you, I don't know, so nice to meet you.
Sammy, it's the other Benjiro. We'll find out more about that. He's the
brother of Yoshua, who is the co-sponsor of this event.
Okay, it's all yours. Wing it. Okay, so, well, let's see.
So I think you guys want to talk about language,
and computation, and AI, and all those good kinds of things, and I was
thinking I could talk about things about LLMs and so on.
You know, I wrote this little book last February about
ChatGBT. You can find a version of it online. I can put it in the
chat. It's, let me not talk about that, but if
people want to ask about it, I'm happy to chat about it.
I thought what I would try to do in 45 minutes give you
kind of the, a very rough tour of my last four and a half decades of
development of a worldview, and see how that relates to
things about AI, and language, and so on.
So to begin, you know, I think a thing that,
sort of the, there's kind of this progression of paradigms
to do with how we formalize the world. So there's sort of this
question of what, what can we do? We start, when we, when we see the
world, we're interested in finding ways to have sort of formal
descriptions of it that we can build on. So historically, kind of the
first of those, the big one for our species, was the invention of
human language, and the idea that you didn't have to just point at
each individual rock, but you could have this kind of symbolic
name, rock, wasn't rock originally, obviously, for that concept, and
you could communicate abstractly about that thing using human language.
Now then, we've had sort of a stack of other ideas,
another big idea is logic, being able to, as a way of sort of
abstracting things about the world, formalizing things about the world.
Another big direction is mathematics, being able to,
something that sort of became big in the late 1600s,
of being able to describe our world by mathematical concepts and constructs.
In this century, and the end of the last one, the big new thing has been
using computation as a way to formalize and describe the world.
Being able to specify kind of if you, the way I think about computation,
it's a way of setting up rules, and then saying, let these rules run.
And the question is, can we set up rules that describe the way the world is,
is, or the aspects of the world at least that we care about?
And my kind of day job for the last four decades has been building our
computational language, Wolfram Language, Mathematica, and so on,
as a way to kind of take the things that we humans care about,
whether they're molecules or cities or algorithms or whatever,
and create a systematic computational language to let one describe those things,
and not only describe them in a way that humans can read,
but also something where computers can help humans to execute those things.
So that's been kind of the way I see sort of that effort,
is take the things that we humans care about, and find a way to formalize them
computationally, so that we can provide sort of the raw material that we need
to work with the world computationally. It's kind of the effort,
is a bit like the effort that happened maybe 500 years ago,
with the development of mathematical notation, where people went from kind of talking about
math in terms of words, to having sort of a streamlined notation with plus signs and equal
signs and things like that. And that idea of notation, that sort of streamlined notation
for mathematics, is what ended up launching algebra and then calculus, and basically the
modern mathematical sciences. Kind of my day job mission has been to create a computational
language that lets one kind of launch computational x for all fields x. So okay, that's, so kind of
this idea is computational language as a way to sort of formalize things that happen in the world,
things that we care about in the world. Now the next question is what is the intrinsic description
of the world, so to speak? How should we describe the world in general? And the thing that sort of
had been the tradition of exact science for about 300 years, was use mathematical equations,
write down an equation that describes this or that aspect of the world. The thing that I got
interested in in the early 1980s is how does one generalize that idea? How does one, how does one,
what kinds of raw material can you find to talk about the world? And the thing that I started
studying a lot was using computation as kind of the raw material for describing the world.
And so the question, the first question is, well okay, what kinds of, how do you set up kind of
computational systems to do that? And for example, let's see, let's actually do something here.
Okay, let's say we are just kind of, we want to see what do
programs that might be computational descriptions of the world, what, let's just look at some
program that, just say what do the typical programs out there do? So this is a very simple example,
it's just you imagine a line of black and white cells and you have some simple rule that says,
given the colors of cells on one row, these are the, this is the color, this is how you determine
the color of the cells on the next row. So if you run this and just run this starting,
let's say, from one black cell, let's run it for like 40 steps. According to that rule,
you start off from, you end up with something where you have this very simple rule, very
simple computational rule, you run it, you get this very simple pattern. Now the question is,
what happens if we look at other kinds of rules? What happens if we kind of turn our
computational telescope out into the computational universe and just look at what's out there?
So we can do that, let's do this, let's just make a, let's just make a table of
all possible rules, let's say the first 63 of these rules, 64 of these rules.
Okay, so each one of these rules corresponds, each one of these pictures
corresponds to a different rule for how the colors of cells are determined by colors of
cells above them. What we see is many of these patterns are very simple, sometimes we'll get
slightly more complicated patterns, we might get a nested pattern, for example, here,
but the thing that is kind of my all-time favorite science discovery that I made almost
exactly 40 years ago, it was 40 years ago on June 1st, is this thing that I call rule 30.
It's specified by this set of cases here, and if we just run,
just run this, started off from single black cell, let's run it for let's say 200 steps,
this is what we get. And to me, this is something very surprising and kind of intuition breaking.
We have a very simple rule, and yet when we run that rule, we're generating something that looks
at least to us very complicated. And actually, you can go and you can sort of work out what's the
center column of cells here, and for all practical purposes, it seems completely random. But so what
this is telling us is out in the computational universe, even very simple rules can easily give
one very complicated behavior. And there are a lot of consequences of this. One thing that this led
me to is this thing I call the principle of computational equivalence. So the thing that is
sort of a big question is, how do you characterize what's going on in a system like this? Well,
you can think about the system as performing a computation. It starts from its initial conditions
at the top, and then it's going crunch, crunch, crunch, and and executing a computation. The
question then is sort of how sophisticated is that computation? And we might have thought, well,
it's just a simple rule, it's doing what it does. If we think about the kinds of computations that,
for example, we do in our brains, well, those are going to be much more sophisticated than this.
But what the principle of computational equivalence says is that actually that's not true.
Above some very low threshold, essentially, all of these kinds of systems, regardless of how simple
their rules are, are equivalent in the sophistication of the computations that they can do. So that
means that in a sense, this little rule 30 thing is doing a computation that's just as sophisticated
as the computations that go on, for example, in our brains. Well, what consequences does that have?
One consequence that has is this phenomenon I call computational irreducibility. So let's say
you want to know what this, well, how this pattern is going to work out a billion steps
later from now. Well, how do you how do you figure that out? One way you can figure that out is just
to follow those billion steps and see what happens. Another thing you can do is to say, wait a minute,
I'm much smarter than this system. I'm just going to jump ahead and I'm going to say,
I know what the answer is after a billion steps. That's the thing we've become used to
in doing, for example, mathematical science. You imagine an idealized planet orbiting a star.
You say, do you have to work out where it's going to be a million years from now? Do you have to
follow those million orbits? Or can you just use a formula and kind of fill in the number of million
and jump ahead and see what the answer is? That kind of what we can call computational
reducibility is what we've become used to from kind of what happens in mathematical science.
But the principle of computational equivalence tells us that will not generally be what one
can do. In general, the systems that we're studying will be just as computationally sophisticated
as anything that we can muster in studying them. And so that means we won't be able to do that kind
of jumping ahead. We won't be able to do that kind of computational outrunning of the system
and will be reduced to something where to work out what the system does,
we basically have to follow every step and see what the outcome is. So this is something which
or kind of in a sense for science, it's telling when there's a major limitation on science. And
by the way, this idea is something, things like girl's theorem, a sort of a special case of this
idea and lots of other kinds of things that one knows about universal computation and so on
is also related to this. But this is kind of a tighter version of those kinds of ideas
and one which I think sort of shows one kind of the relationship of these things to science.
And sort of the big consequences, there's lots of stuff that you won't be able to
have a theory for, work out, jump ahead, know what's going to happen. You'll have to just follow
every step and see what happens. And so in a sense, that's a limitation on science. From within
science, one is seeing kind of a fundamental limitation of science. It's actually something
which for many purposes might, one might not think of being a such bad thing, because in a sense,
it's the thing that makes, for example, the passage of time meaningful. If it wasn't for
computational irreducibility, then if you live for 50 years, then in a sense, that would not be,
nothing would be achieved by that. One would be able to say, oh, I know what's going to happen in
the end. I can jump ahead and say what the outcome is going to be. But because of computational
irreducibility, there is something sort of really happening in the passage of time. It is a sort of
an irreducible computation that's going on. There are many other consequences of computational
irreducibility. For example, when it comes to things like AI, we can ask the question,
what in so far as AI is doing computation? And we'll talk about the sense maybe later
in which typical modern neural nets are doing only very weak levels of computation.
But let's imagine that we have a system that is doing computation as computation can be done.
Well, we sort of have a choice. Either we can say that system is we're going to make that system
computationally reducible. So we know what the outcome is going to be. And so, for example,
we can say we're absolutely sure this system will never do the wrong thing because we know its outcomes
and we can constrain it to say that, to set it up so we can sort of prove that we'll never do the
wrong thing. It's reducible enough that we can know enough about what it's going to do that we
can know it isn't going to do the wrong thing. So that's plan A. But the problem with plan A
is that means that the system can't do irreducible computations. The system can only do computations
where we can jump ahead and foresee the outcome. So in a sense, that means we're crippling the
system. We're preventing it from doing what it could do as a computational system. We're saying
it's only going to do those things which are kind of reducible. So in a sense, I think it's going
to end up being sort of a big societal choice is, do we want the AIs, computational systems,
to be able to do all the powerful things that computational systems can do,
or do we want to insist that they'll only do things where we can foresee what they'll do?
And in a sense, it's kind of like we have a, you could say, well, I'm going to set up all these
rules for the AIs that make sure they only do the right things. Well, to make that work,
you have to have the AIs be sort of computationally reducible. If they're computationally
irreducible, well, maybe you can constrain it in all sorts of ways, but there'll always be surprises.
There'll always be things where you can't foresee that particular outcome. By the way,
computational irreducibility has many, many consequences. But another consequence it has
is that sort of science will never be finished. There will always be, if we think about kind of,
there'll always be things where we can't foresee the next thing that will happen.
There will always be surprises in mathematics. There will always be new theorems that can be
proved and so on. The thing that is an issue there in terms of things like will science be
finished and so on is, well, okay, there might be things that were surprises, but are they surprises
we care about? If we were exploring all of mathematics, we would prove more and more and more
theorems. But it could be that we get to the point where we know all the theorems we care about,
and anything else is something we're not going to care about. So in a sense, it's a,
there's sort of this, this connection to sort of human issues in what, but the point is that
there is ultimately an infinite and unlimited frontier of what's possible to discover in science
and so on. By the way, that also relates, maybe we can talk about, to things like,
well, okay, let's, let's maybe talk about, so, so kind of this, this idea of computational
irreducibility, that you can't know the outcome of a computational process in general, except by
running it and seeing what happens. Limitation on science, thing that makes the passage of time
meaningful, kind of dichotomy for thinking about AI and so on. It's the, so that, so let's see,
one of the things that's sort of interesting about this is we can just sort of, in this
computational universe, we'll find all sorts of, of things that go on. The question becomes,
sort of, are those things that we find out there, things that we care about or not? In other words,
we can go and we can, oh, I don't know, we can, you know, that's a, an example of just a simple
rule and what it does and we can get the lots of other, lots of other examples we can, we can,
we can go and do this ourselves if we want to, let's see, and just go find very simple rules
that do very complicated things. It's easy to kind of launch out into the computational
universe and find these things. The question ends up being, so how, what do we humans care about
these things? Well, it could be that this particular thing, we will be able to use it for
technology in some way. It could be that we'll think this is something very important for art,
but it's something where out there in the computational universe, there's kind of an
infinite supply of original things. The question is, which ones do we humans choose to care about?
And, and for example, if we imagine kind of the, the, the future of AIs, you can say, okay AI,
go out into the computational universe, you can go and create things that have never been seen
before, all kinds of things. The question is, are those things that are of, of kind of human
relevance to us now? Well, one thing you might do, you can actually do a little experiment here,
let me show you something. Where is it? So for example, we could say we could take some image
generation AI, and this is just a diffusion image generator. And we could say, let's, let's look,
let's ask the thing to make a picture of a cat in a party hat. Okay, but inside the AI,
it's got some, you know, embedding vector, it's got some, some set of numbers that describe
that is its version of what that concept is. But one thing we could do is something very simple
to sort of explore the universe of possibilities. We could say we're going to take this AI that's
very aligned with human interest because it's been trained on billions of human images.
But nevertheless, we could say, let's take this AI and let's sort of move around in this space of
possibilities. And so for some set of numbers, we've got the cat and the party hat. But as we
change those numbers, we're moving out from that. And we have this kind of in the middle,
we have this thing we might sort of describe as kind of cat island, that is things that to us kind
of look like cats. But then we go further away, and we'll get into things which aren't like cats.
If we go far enough, you know, we'll, we'll be able to go, I don't know, as an example, we'd be
able to go from, what is that going to? That's, well, okay, here's one that goes from a cat to
a dog, we're going through through this kind of meaning space from a cat to a dog. But in general,
what we'll find is that we in this sort of space of possibilities, there's this region that corresponds
to this concept that we have of a cat and a party hat. But as we go away from that, eventually,
we move far enough, we'll get to a picture of a, you know, a dog wearing a sweater or something.
But we go through a large volume of inter concept space of things which are images,
which were generated by this AI using, you know, computationally generated out there in the
computational universe, even set up to be quite aligned with kind of the pictures that we humans
have put on the web. But nevertheless, they're not things which are normally described by a
word like a cat or a dog or whatever else. So you might ask the question, you know, in an image
generation AI, what volume of the space of possibilities is covered by concepts that we
have already defined? The answer is maybe one part and 10 to the 600. So in other words, there's
this vast kind of inter concept space of possible images, only tiny corners of which are described
by words that we have in human languages. So in a sense, as we look at this kind of inter concept
space, we could say, you know, we don't necessarily have a word to describe some of these patterns,
but we might say, oh, that's kind of a cool pattern. And maybe we decide at some point that
that's a particular style of art. And eventually we get a word for it. And then we develop this
whole kind of human interest in that particular piece of what was inter concept space. And now
that becomes a concept in our languages and so on. So this idea is sort of this core idea that
there's this huge space, this huge kind of computational universe of possibilities,
even reduced here by ones that are sort of images aligned with images that we put on the web.
Even if you reduce it in that way, the part of that space that we have so far explored,
that we have so far come up with words for and described with concepts, is a tiny part of the
space. And there's vastly more that is kind of be found in the sort of inter concept space.
Now, what, you know, can we describe kind of the way that kind of we, we think about
sort of our progression in kind of the progression of human civilization and so on.
In some sense, you can think about us as progressively colonizing inter concept space.
We're progressively coming up with things coming up with, we're coming up with sort of this
social construct of language that that different ones of us sort of collectively understand,
that corresponds to the, these different points in the space of possibilities.
And sort of the progression of civilization, we can think of as being this progressive kind of
progressive exploration of inter concept space. And, you know, as we invent new paradigms for
things, we get to kind of, or new ways of describing things, we get to kind of move
outwards in the space. Now, for example, in my day job of creating computational language to
describe things, my, my mission in a sense is to find those, those places in the space of
possibilities that we humans care about, and that we can use as kind of building blocks
to construct kind of in a computational way, a description of what we want. But there's kind
of a broader science of what's in principle out there, which is broader than the things that we
humans have so far chosen to, to come up with words for and so on and have languages for.
Well, just to kind of fill out a little bit, kind of the, a little bit more of kind of the,
the world view that develops from all of this, we can ask questions about, okay, what about
our physical world? How is that constructed? What is the, what's kind of the, the underlying
structure there? And one of the things that's been very exciting to me in the last few years,
something I really did not expect sort of to, to, to happen is that it's, it's turned out that we've
been able to work out that how this kind of computational ideas provide sort of an ultimate
infrastructure, an ultimate kind of machine code for the physical universe. And what, what,
let me describe that a little bit because we're going to come back to this question of concepts
and into concept space and so on, but we're going to come at it now from a different direction
from understanding the structure of the physical world. So, sort of big picture, back in antiquity,
people were arguing, you know, is the world discreet or is it continuous? Is it made of
atoms or is it just things that are sort of flowing? And one didn't know. End of the 19th
century, it became clear, yes, there are molecules, matter is discreet. A little bit later, became
clear, there are photons like can be thought of as being discreet. At that time, people mostly
assumed that space would turn out to be discreet as well. But for various reasons, nobody technically
managed to make that work. And so physics kind of went on with the space is continuous, you can
kind of put things anywhere you want in space. Well, if you're thinking about things in kind
of computational terms, you're immediately led to say, wait a minute, you know, perhaps space is
actually fundamentally a computational construct, fundamentally a discreet kind of thing. And the
big surprise of four years ago now was that, yes, we actually managed to figure out how to make that
work and managed to figure out how that connects to the big theories of current 20th century physics.
And actually, the really remarkable thing that maybe I'll have a chance to describe
is that the big theories of 20th century physics, essentially general relativity, the theory of
gravity and spacetime, quantum mechanics, and statistical mechanics for the second law of
thermodynamics, those are sort of three big theories of 20th century physics. It turns out that all
three of those theories are not just things that we can kind of say, oh, that's what's true.
There are actually things that we can in some sense derive from fundamental considerations.
I had not expected any such thing to be the case that we could derive the laws of physics, so to
speak. But we can and I'll explain how that works. And that's kind of loop back to questions about
language and concepts and so on. But okay, so what's the universe made of? Well, in our models,
the universe consists of a bunch of sort of discrete atoms of space, we tend to call them
eames, kind of atoms of existence. They're things where the only thing you can say about them is
they exist, and they have an identity, and they're distinct from each other.
And then there's one more thing, which is you can say how these eames, how these atoms of space
are related to each other. You can say this one is related to these two other ones. It's kind of
like what atom of space is friends with what other atoms of space? And you define this whole
collection of relations between atoms of space, and you can represent that by a graph, a network,
or actually more formally in our models, a hypergraph. But the essentially one's just dealing
with this big network of relations between the atoms of space. And so everything in the universe
in our models is just made of the relations between atoms of space. So for example, if
something like a black hole, for example, is just a structure in the, I might even be able to show
you a picture of one, let me see if I can pull this up. This is actually in kind of the fabric
of space. This is two little tiny black holes. And we'll see in this video kind of space, most of
the activity of the universe actually is knitting together the structure of space. But there are
two black holes there, and you can kind of see they eventually merge. They produce gravitational
radiation. Actually, what we get from this model, where we're looking at kind of the
discrete structure of space, we can successfully reproduce the actual things that are observed
in black hole mergers and so on. But in any case, the basic point is what the universe is made of,
everything in the universe is just a feature of the structure of space. And when it comes to time,
time is the progressive rewriting of the structure of that network that represents space.
So time is actually a very different kind of thing in these models from space.
Things like relativity emerge as a feature of the model. They're not things that are put in
from the underlying structure of the model. Okay, so we've got sort of the notion of space,
notion of time. It turns out quantum mechanics is a thing that inevitably emerges from the fact that
when we are updating this network, there isn't just one possible path of history. There isn't
just one possible way that the network can be updated. There are many possible paths of history
that branch and merge. And essentially, the structure of those things is what leads to
quantum mechanics. Well, one of the issues is when we're looking at the system, and we're
seeing all these rewrites and the structure of space and so on, the question is, how do we experience
that? There are all these things microscopically happening, but we have a certain experience of
that. And it turns out that sort of a critical feature of what's going on is that we are observers
of a certain kind. So let's take the case of, let's look at, for example, let's see,
let's look at something like statistical mechanics. We've got a bunch of molecules
bouncing around in a box. And one of the kind of big principles is the second law of thermodynamics
that says when you start those molecules off in an orderly way, their motion will tend to
eventually look disordered and random. It will look as if it has higher entropy. And the question
is sort of what's really going on there? And it turns out that what's actually happening,
something I finally understood, I've been thinking about this for like 50 years, actually, is that
what's ultimately going on, you can look at different kinds of versions of this, what's
ultimately going on is that these molecules are bouncing around in a certain determined way
according to some rule. And in fact, that rule can be reversed. So you can take this pattern of
molecules you get at the end and you can say, I can figure out, oh, yes, that pattern of molecules
came from the simple initial state. Well, in principle, you can do that, but it's a computationally
irreducible process. And the difficulty is that we human observers of things
computationally bounded, we can't do that, that, that all the computation that's needed to reverse
what happens in the molecules, we're just stuck saying that we can, we can get this
impression of what's going on. And with that impression of what's going on with that computationally
bounded impression of what's going on, all we can say is, oh, it looks random to us. And that's
kind of the ultimate origin of the second law of thermodynamics is something which is to do with
the relationship between underlying computational irreducibility and our computational boundedness
as observers. Well, it turns out that both general relativity and quantum mechanics
come from the exact same thing. They both come from this idea that there is computational
irreducibility underneath. But we are, well, actually, there are two attributes that we have
to have as observers, that we are computationally bounded, and that we believe we are persistent
in time. So in this model, for example, we are at every moment in time, we're made of different
atoms of space, yet we all have the impression that we are experiencing things through that it's
still us a second later, so to speak, and that we experience things we are persistent, we have a
continuous thread of experience through time. Well, okay, so the really ultimately big concept
here is this thing we call the Ruliad. And so here's how this works. When we look at
these, this underlying hypergraph and its rewrite rules and all those kinds of things,
we can, we say, okay, there are these underlying rules. And if we run those enough times,
we'll eventually get something that seems like our universe that satisfies Einstein's equations
of general relativity, that shows the Feynman path integral for quantum mechanics, all those kinds of
good things. But we still might be asking the question, well, why did our universe get one
particular rule and not another? And that had me very confused for quite a while, until I realized
that actually we can think of the universe as running all possible rules. So what we imagine is
that there are these possible computational rules that can be used to update this hypergraph and so
on. But let's just imagine that we use all possible rules. What we get are all these different parts
of history that branched and merge and so on, corresponding to the application of all these
different rules. And this whole object that is the entangled limit of all possible computational
processes, we call the Ruliad. And the Ruliad is a completely unique thing. It is, it is you take
every possible Turing machine, every possible computational system, you run all of them, and
you run them in such a way that they are producing kind of, that they don't just have one possible
outcome, they have all possible outcomes. You might say, what an incredible mess, how could you ever
conclude anything from this Ruliad object? It is the case that this Ruliad object is a unique thing,
there's not, it's not like there's seven different Ruliad's, there's just this thing that is the
entangled limit of all possible computations. And so then the question is, well, how can you conclude
anything about, about this Ruliad object? Well, what you have to realize is the Ruliad object
represents everything that's possible, everything. And so, for example, we, as observers of what's
going on, we must be embedded within this Ruliad. And so what we can think of is that this, this
was I sharing the screen or did I stop sharing? Well, anyway, the, this, so the issue is we are
observers embedded within this Ruliad, observing the Ruliad. And the question is, what do we
conclude about the Ruliad? And the Ruliad is a necessary thing, there's no choice about it.
But the nature of us as observers is contingent, so to speak. And so what turns out to be the case
is that observers like us, observers that have certain attributes necessarily conclude that
necessarily describe the Ruliad in certain ways. So in a sense, by being an observer who is
computationally bounded, who believes they're persistent in time, those two attributes alone
are sufficient to tell us that the slice of the Ruliad, the way that we parse the Ruliad
is exactly the way that corresponds to the laws of physics that we know.
So in other words, what we're saying is you can derive the laws of physics, the laws of physics
are derived by starting with this Ruliad, which is a necessary unique object, and then saying what,
for observers like us, which happen to have the properties that we have of being computationally
bounded and believing we're persistent in time, any observer with those very coarse properties
will necessarily conclude that the universe operates according to Einstein's equations and
the path integral and so on. So that's a rather interesting philosophical conclusion.
Now you can ask, well, what would observers not like us conclude? Well, we don't know.
You can kind of, and that's sort of a question of how do we think about observers not like us?
Well, one thing to realize is we can think of in the Ruliad, we can think of different possible
observers as being sort of at different points in the Ruliad. There are different places in Rulial
space. Just like in physical space, we could be here on this planet, we could be on a galaxy on
the other side of the universe, we can be at different places in physical space, and each
different place in physical space will give us a different point of view about how the universe
works. Well, so it is in Rulial space, each different place in Rulial space will give us
a different point of view about how the universe works, how things work. So here's a way to think
about that. We can think of essentially different minds as being at different places in Rulial
space. It's as if, and these different minds are kind of experiencing possibilities in a
different way. So if we think about that in terms of, you know, the LLMs and so on, it's kind of
like we could imagine just having a differently trained LLM and that differently trained LLM
basically exists at a different place in Rulial space. So for example, minds that are sort of
similar and sort of similarly trained will be fairly close in Rulial space. Minds that are
different, like, you know, let's say cats and dogs, further away in Rulial space.
Minds, I tend to, I think that one of the consequences of the principle of computational
equivalence that I mentioned earlier is that one could sort of attribute mind like things
to lots of systems in the world and lots of abstract systems. And so for example,
when one says the weather has a mind of its own, in the principle of computational equivalence says,
yes, that's a meaningful thing to say. But in a sense, the mind that corresponds to the
weather is pretty far away from us in Rulial space. Also now there's a question, how do you
communicate across Rulial space? How do you, what is it what's involved in doing that? Well,
at some computational level, one point in Rulial space corresponds to sort of computing,
according to let's say one Turing machine, another point in Rulial space computing,
according to another Turing machine, another computer. We know that in principle, we can
make a translation from one place in Rulial space to another place in Rulial space takes
effort. We have to actually create that interpreter that's going to interpret the
instructions of one machine as the instructions of another machine. It takes effort in the same
way as it takes effort to move in physical space. In a sense, when we move in physical space in our
models, we're reconstructing ourselves at a different point in physical space. And by the way,
you can understand things like time dilation and relativity. There's a nice kind of mechanical
explanation of that. If you're always in one place, you're spending your kind of computation
budget figuring out what the next behave what the what the next stage you'll be in is. But if
you're moving, then you're using some of your computation budget to kind of recreate yourself
at a different place in space. And so that's used up having used up some of your computation budget,
you necessarily sort of moves go through time more slowly time time goes more slowly because
you used up some of your computation budget in moving in space. But in any case, you can you
can think of so so by the way, in our models, the possibility of motion is non trivial. It's not
obvious that you can you know pick up a glass and move it somewhere, and it'll still be the same
glass. That's something that we generally assume about the world that pure motion is possible.
But it's something in our models that you have to prove that pure motion is possible. And even
in traditional physics, if you're sufficiently near a space time singularity, for example,
no no material object will maintain its identity as you move it around that that singularity.
But in our models, the the possibility that that thing can just move, and that it's still the same
thing is non trivial. And actually, in a sense, the the particles of motion are exactly the kinds
of particles that we know about like electrons and quarks and so on. What is an electron an
electron in some sense in an abstract level is a lump that is capable of pure motion. It's something
where you can have an electron in one place, and you can move it and it'll still just be that electron.
So it's it's a particles are kind of the carriers of pure motion and physical space.
So here's a here's a thing in rural space, we can ask sort of what is motion in rural space about.
Well, in a sense, what what it means to have motion in rural space is you're effectively
transporting something from one mind to another if different points in rural space
correspond to the positions of different minds, you're asking the question, what does it take
to kind of transport things around rural space. And I think this is one of the very bizarre
kinds of things that one realizes is it seems to be the case that concepts are the analog of
particles. So what in physical space and an electron that doesn't change as you move it from
here to there, in rural space, it's the concept of a cat, for example, that can be moved from one
mind to another without change. I mean, the particular details of the neural firings that
exist in my brain, when I think of the concept of cat, in any of your brains, the particular
neural firings will be different. But yet, we can package up the concept of a cat, and I can say
the word cat, I can transport it to you, and then you can unpack it. And in your place in rural space,
you can end up with the same thing, so to speak. So it's kind of a way of understanding that that's
sort of the fundamental thing that's going on. And we can think of kind of concepts as being
the particles of rural space. Well, there are lots of lots of things I see I'm running out of time
here. But there are lots of things we can talk about about what, well, let me just say a couple
of other things about, I'll talk a little bit about AI. And I mean, the AI has had many different
meanings over the course of time. And many things where people have said, if we can only have that,
then we have AI are things that I've built as kind of pure computational systems. And then
people say, well, it's just a computational system, it's not really AI. And in more than seconds,
just one second, I want to, you do have more time, because for some reason, I can't explain,
Caillou, who has been extremely conscientious in everything, is not here, which may mean that he
had misunderstood being a discussant for being a member of the panel, which means he won't be here
until the panel starts, in which case you have more time, if you wish. I just compressed four
and a half decades into a remarkably short time, I hope people could follow it.
Nothing, you could have taken place at this time.
Well, okay, so let me let me finish what I was saying here, and then maybe we can
turn this over to discussion, which is more fun for me. So talking about kind of modern
AIs, and you know, to many people, modern AI is neural networks. And the, there's sort of a
question of, well, what can, how do neural networks relate to all of the things I've been talking
about? And one of the questions we can ask is, okay, we have, we have our friendly neural net
here, let's see, oops, share the screen and then,
okay, we have some typical trained neural net, let's say we're trying to train it,
let's say we're trying to train it to reproduce the sine wave. So what we're doing is we're going
to feed in the x value at the top there, and we're going to have set up these neural net weights,
and it's going to compute the y value down here. And actually, we'll do a pretty crummy job of that
typically. And you can, you can change the neural net, you'll get different kinds of behavior,
it's usually not particularly good at computing something like this. Well, so one thing you can
ask is, you know, neural nets, let's say if we have a big enough neural net, maybe we can break
computational irreducibility, maybe we can just predict what's going to happen in any kind of system.
That is not going to work. I mean, the way that a neural net of this type works, it's just having
kind of numbers ripple through the sequence of layers. And we're ending up with something where
you can, this is something trained, I used a modern transformer architecture and trained it
to try and recognize what was going to happen in a cellular automaton. And it has certain,
it says, well, there's certain probability of what's going to happen. But when the behavior is
pretty simple, it'll nail it. When the behavior is more complicated, it's like, I'm sorry, I can't,
you know, I can't figure that out. This is, this is different levels of training of one of those
neural nets. So in a sense, it's not surprisingly, the kind of very finite computation of these layers
of a neural net can't do the unboundedly large computation required to kind of solve a computationally
irreducible problem. And you can see that again. See, where do I have an example here? This is,
these are examples of the three body problem in celestial mechanics, Earth, Moon, Sun, all idealized,
all with interacting through gravity. You can ask the question, if you train a neural net,
can it correctly reproduce the behavior? The answer is the neural net is the kind of solid
line here, that's its prediction. When the behavior is fairly simple, yes, it can do it.
When the behavior is kind of computationally irreducible, no, it can't do it.
None of this is really very surprising. But there's kind of the question, for example,
when we look at something like chat GPT, and we say, oh my gosh, it actually worked, it produced
something that is like human language. How did that work? What I think is the main thing going on
is something which tells us a lot more about human language, probably, than it does about
neural nets. Because what it's telling us is, if we think about how does chat GPT work,
it's basically just saying, I'm going to predict the next word by figuring out certain probabilities.
And it's going to do that by, at the very simplest level, it might just do it, let's see if we've got
one here, might just do it by knowing the frequencies of different letters. And then,
if you just use the frequencies of different letters, you get pretty much nonsense.
If you use blocks of letters, you'll start getting more sensible kinds of things.
If you use kind of whole words occurring with the probability that they occur in English,
you'll get things that don't make much sense, but they're kind of things that can construct.
Now, the big thing that's interesting and surprising is that when you kind of train
a neural net from kind of all of the text, you know, a trillion words of text or something,
that the extrapolations it makes about what make meaningful sentences tend to agree with
the extrapolations that we humans would make about that. It's very similar to the fact that if we
train a neural net to recognize cats from dogs and images, that the distinctions it will make
seem to be similar to the distinctions we will make. At a theoretical level, if we say,
where's the dividing line between cat pictures and dog pictures? There isn't a good mathematical
characterization of where that dividing line is. It's really a question of where do we humans say
is a dividing line between cats and dogs? And the thing that's interesting about neural nets
is they tend to make the same kinds of decisions about that that we tend to make.
Probably the reason is that ultimately their architecture is similar to the architecture
of our brains. But the main point is that those kinds of distinctions, there's not a theorem,
there's no theorem that says the neural net will reproduce the distinction between cats and dogs,
because you don't know what the target is. The target is what do humans think is going on there,
and it does a pretty good job at that. So now the question is, in the case of language, what's
going on? And I think what's happened is that the thing that allows an LLM to produce reasonable
language is something that is a regularity of language that we could have recognized a long
time ago, but we didn't. And so we know certain regularities in language. We know that, for example,
in English, you tend to have sentences that go noun verb noun. But there are plenty of sentences
of the form noun verb noun that are total nonsense. So the question is, you have this kind of
syntactic grammar of language that says that you go things like noun verb noun. But now you have
the question of, well, what noun verb nouns actually make sense? And so what I think chat,
you know, chat GBT and LLMs and so on are kind of showing us is that there is also a semantic
grammar of language. There's also a construction kit, not only of what the parts of speech might be,
but also what kinds of words they might be to have them make sense. And that's something that
eventually kind of sort of expands up to write a whole essay and have these puzzle pieces fit
together in a way so that the whole thing makes sense. So, you know, in a sense, what one's
seeing and one can kind of look at, let's see if I have some pictures here. Maybe I have some pictures.
Yeah, these are from, these are very ancient, actually, there's better ones now for GBT-4.
What extent can you kind of imagine semantic laws of motion where you're kind of moving around in
meaning space, and where, just like Newton's laws tell you in physical space, how you move
from one, you know, how motion happens when in the absence of a force you just keep moving in
the same direction and so on. So you can ask questions about rural space, and you can ask
questions about kind of the structure of rural space and how that works. And I think we're kind
of learning some scientific things from the operation of LLMs about how that works.
Now, another question would be, so in other words, I think the reason LLMs work as well as they do
is because there are a bunch of regularities in human language that we kind of didn't know were
there and that we've never really codified. People started codifying these things back in the 1600s,
for example, people tried to invent these so-called philosophical languages that would be kind of
not specific to any particular language, but they would be things that sort of represent the
meaning of things without the specificity of particular languages. Well, actually,
I've had a project for a while now much more energetic to make what I call a symbolic discourse
language, a language where just like in Wolfman language, we have this computational language
that describes many aspects of the world. I mean, we might have all sorts of different
sort of categories of thing that we describe in our language. And the question is, can we kind
of describe all, can we describe sort of things that come up in everyday language? Can we describe
those kinds of things in a sort of precise symbolic way? And I have to say that I can't say I've got
the full answer to that, but it's going really well. And it's become clear, and by the way,
LLMs are quite helpful in this, to having a way to take something not the level of language where
we're actually putting words together, but the representation of the core meaning of what's
going on. Just like in our computational language, we have that representation of sort of the core
meaning of what's going on in a way that can be read by humans, but also executed by a computer.
So in any case, that's sort of one direction about things with LLMs and so on. Another question
that I was curious about is, okay, why does machine learning work at all? Why is it the case that you
can train one of these neural nets to do something like, I don't know, recognize digits or recognize
cats and dogs or generate language or whatever else? Why does that work? When I played around
with neural nets back in 1981, and I couldn't get them to do anything interesting. And I kind of
thought at the time, oh, if I've got a simple enough problem, I'll be able to get a simple neural
net to do things, didn't really work very well, wasn't very interesting. The big thing that got
sort of accidentally discovered basically in 2011 was that if you have a big neural net and you
bash it really hard, you show it enough training examples, it'll learn, well, lots of different
kinds of things, it'll learn almost anything. And the kind of the big meta discovery of modern
machine learning is that if you bash a neural net hard enough, it'll learn almost anything. We don't
know quite what the almost is. We can't really characterize what kind of thing it can learn.
For example, as I said, it can't break out of computational irreducibility. So there's limitations
to what it can learn, what it can do. But nevertheless, there's a broad class of things that seem to
correspond a lot to kinds of things that we humans can do easily that the neural net can
successfully do. And so that's sort of the meta discovery. The question is, why does that work?
Why is it the case that this neural net can be successfully sort of bashed into learning
things? Why doesn't it get stuck? Why doesn't it get to the point where you just can't get there
from here? You can't arrange it. Why is it the case that it's possible to do it and then why is it
the case that you can iteratively do it by sort of adaptively training it? I got interested in
this very recently, actually. And I don't know whether I can show you pictures. Let me see. I can
show you some things that I did recently. And then maybe I'll be able to pull up some pictures
just from the last few days that let me see here. Right. So actually, I decided to look at a simpler
problem, which is the problem of biological evolution, which is sort of another case of adaptation
that is a little simpler than neural nets. But let me explain what I figured out about
biological evolution. For a long time, I wondered what sort of the minimal model of biological
evolution was always very unsatisfied because models, you know, natural selection seems like a
simple principle. But when you actually try and make explicit models for it, you end up with all
kinds of hair about, you know, how many sub, you know, suboptimal organisms do you keep and all
this kind of thing. So I was interested in sort of a minimal version of that. So here's a version
of that. This is actually one of these cellular automata. It's got these rules here, starts off
from one red cell here. And with these particular rules, you get a pattern that lives for this amount
of time and then dies out. Okay, so let's imagine that you're interested in doing something where
you just keep on tweaking the rules, you keep on resetting the rules, you keep on making
single point mutations in the rules to try and get it to live longer and longer. This is what
happens. You start off from something that that is just a blank rule. For example, it dies immediately,
you keep tweaking the rule, you have to go through many different tweaks and so on. But
eventually you'll get to the point where it lives there for 50 something steps.
Well, and you can see that the sequence of mutations that got made there. And if you look at how the
fitness of this organism, the length of time it lived, varies as you go through all these
different sort of steps of adaptive evolution, you'll see there are, you know, it's going along
and there are many things that don't work out. But, you know, it'll kind of cruise along here at a
certain fitness, and then it makes a discovery. And then it can go to higher fitness. And actually,
you can end up with all kinds of discoveries that it makes. These are different sort of
paths of evolution. And you'll see that, for example, here, it's kind of going along and
eventually it manages to discover a lot. It manages to live a long time. You could sort of imagine
in the fossil record, you might find, you know, a critter from the Cambrian period that looks
like this. And then it uses that idea to extend further. And by the time it's in the Silurian
period, it's looking like this. And maybe it makes it to this in the Triassic period or something.
But what's happening here is that there are sort of, it's having progressively more ideas,
in a sense, about how to live longer in this particular case. And actually, you can even
go ahead, this is a simple enough system, that you can actually work out. Let's see, that's an
example of a better example. There we go. This is, this is the path of all possible paths of
evolution for a simple system like this. So every different picture here is a possible organism.
And the arrows show the possible adaptation paths. And what you see is something that's very much
like what happens in biological evolution. There are different branches in the tree of life.
There are, you know, one set of ideas leads to long life over here. In this way, a different
set of ideas leads to kind of long life over here in a different way. Okay, what does this have to
do with machine learning? Well, you can, you can ask the question, let me see if I can pull this up.
I am going to have to pull up something that I just made. So I'm not sure whether I can find it here.
Hold on, you can get hot off the press or not really off the press at all. Where is it?
Let me see. Maybe.
Maybe this will have it. Oh yeah, this is, this might be it.
This is a very minimal model for,
let's see if I can get this bigger. It's a very minimal model for a neural net where
it's actually a cellular automaton as well. But instead of having a fixed rule that it keeps on
applying kind of like a recurrent neural network, it has something more like a feed forward neural
network where you have a discrete choice of one of let's say two different possible rules. And at
every point in space time, so to speak, you're picking a different rule. And so then the learning
consists of, well, what's the pattern of rules you should pick to get a particular outcome. In
this particular case, we're trying to learn to live as long as possible. And what's interesting
here, and again, this is just raw off the literally raw material that from a couple of days ago,
this is kind of showing in a sense how the thing does what it does. So in a standard neural net,
it's just much more complicated to display what's going on. You've got these neurons with
continuous weights and you've got connectivity all over the place and so on. This is a much simpler
case. So you can kind of see more about what's going on. What's non trivial is that training
actually works in this case. And it does, you can find this arrangement of bits that will cause
the thing to do, I don't know whether I have it in this example here, but that will cause it to
learn, see if I have one here. Now those activation levels, well, it doesn't matter, but that will
basically cause it to learn something like, you know, to tell whether the number of bits at the
beginning is even or odd or something like this. And we actually even tried training this on the
MNIST training set, and it doesn't do too badly. So the point here, the thing that's interesting
here, these are all different solutions that this kind of very idealized neural net found
to living for this exact number of steps. What's interesting about these is they're very bizarre.
They're not sort of engineered solutions. They're not solutions where we can say, oh, yeah, let me
look inside and see how this works. Let me show you another example of that. And this is more back
to the biological evolution case. This is kind of all the different ways that a certain class of
systems manages to live a long time. And some of them, it's kind of pretty structured. You can imagine
sort of this was an engineered thing, but some of them, it's like it just seems to sort of happen
to live that long, and then it dies out. So in other words, there's a lot. And by doing this
sort of adaptive evolution, you're ending up finding these things which are very not,
they're not mechanical, they're not engineered kind of ways that things work. They're things
where kind of this is sort of what's happening inside. This is the thing that's going on,
but it's not something where you can say, oh, I've got a mechanism. By the way, if you're interested
in neuroscience, this is something you should pay attention to, because in a sense, if you're
trying to explain what's happening in the brain, and you say, oh, I'm going to figure out how this
works. Well, how this works is an attempt to have kind of a human understandable narrative
for what's going on. But if I were to look at these pictures in the background here,
if this was something going on in a brain, I might be able to say, okay,
I can have some human narrative about what's happening here. If this is what's going on in a
brain, it's just, well, it happens to work that way, and it happens to give this result. It's
kind of a computational irreducible story. It's something where there's no sort of narrative
mechanistic explanation. It's something which just works that way, and it's computationally
irreducible, but it just comes out in that fashion. And I think there's sort of an interesting question
for in machine learning. Why does machine learning work? Okay, so let's look at,
was a nice picture of that. By the way, this is in biological evolution. People often talk
about fitness landscapes. This is an actual fitness landscape correctly drawn, so to speak.
And you can start seeing all kinds of things about things evolving on fitness landscapes.
But the thing I really wanted to show you, here it is. This is kind of the local behavior
at a particular point in rule space at various steps in the adaptive evolution.
So what's happening here is at this step, for example, in the adaptive evolution,
here are different possible directions in rule space that you might go. And the ones inside
the circle are ones that are losers relative to where you've already got. They're ones that would be
live less long than what we have here, but there are some that would make progress.
And in fact, this is the one we happened to choose in this particular random
sequence of adaptive evolution steps. And that was the thing that made progress. So
the thing that is not obvious is in this sort of high dimensional space of possible ways you could
go, the question is, will you always be able to make progress? Will there be a direction that
makes progress? Or will you get stuck? Well, I think that this is again a computational
irreducibility story that basically what would make you get stuck? Well, if the structure of
this rule space was very orderly, very reducible and easy to predict, you might end up in a box
with very precisely defined walls and you just can't escape from that. But the presence of
computational irreducibility kind of implies a certain degree of unpredictability, a certain
degree of intrinsic randomness effectively in the structure of rule space. And that's what
means that in these high dimensional spaces, there's always a kind of a path to success.
So in a sense, I think computational irreducibility, which is a limitation on what one can do with,
for example, a neural net, what kinds of things computations one can expect to do,
is also the reason that training of neural nets, for example, can work. And so I think that's a,
anyway, this is still an in progress kind of investigation. But I sort of think it's
an interesting connection between a lot of different things I've talked about.
All right, I've gone on longer than I intended to. So let me wrap up there and I'm happy to
have a discussion, questions, whatever else. I just fed you an awful lot of material.
Yes, good. Let's first applaud this president.
The problem was that Kaiyou had an emergency during your talk, so he couldn't hear it.
Kaiyou, do you think that you have, from the background material you might have looked at,
you have a basis for saying something? Sorry, I missed most part of the time, so probably.
If you haven't seen, this is a large amount of material. I would be surprised if we could
have a useful conversation without having some anchor to this. Could you please explain to Kaiyou
and to me and to us how computational irreducibility differs from ABC,
the commagor of complexity, the church-touring thesis, and NP completeness.
Okay. All right, let's start off with Chetan Komogorov complexity. So when we look at a picture
like this, the algorithmic complexity of this picture is tiny. That's the program that's needed
to produce it, just a few bits. The thing that is remarkable is that even things with very low
algorithmic complexity are very complicated. In fact, they're complicated enough that to us humans,
we wouldn't even be able to distinguish them from things that have high algorithmic complexity.
One of the things I've had a long-running discussion with my friend Greg Chetan,
where the question is, is the universe like Pi or like Omega? Omega is this thing that Greg
invented 50 years ago, actually, that is the halting probability for a universal Turing machine.
It's a fundamentally non-computable object. It's an object with infinite algorithmic complexity.
It is a thing where there is no small program that you can't specify it by a small program.
Pi, on the other hand, is a thing that is specified by a quite a small program.
Once you generate its digits, it looks for all practical purposes random.
So the question that one can ask is, in our universe, is there anything of high algorithmic
complexity? Or is the whole universe actually a thing that is like Pi generated from something
which is a very simple underlying sort of program? And in our model of physics, the answer is the
universe is like Pi. The universe is something that is generated from a thing of very tiny
algorithmic complexity. So that's kind of the distinction between everything I'm talking about
is things of incredibly low algorithmic complexity. The remarkable fact that is not obvious,
it kind of breaks one's intuition, is that things, very simple programs, things of very
low algorithmic complexity can produce what seems to us like great complexity. And the
seems to us becomes much harder when we start talking about our computational boundedness.
It's not the case that it's just, oh, it seems complicated. It's that for a computationally
bounded observer like us, there is no way to compress it. So in algorithmic complexity,
algorithmic information, when saying this is the program and there is no shorter program,
one can say for a computationally bounded observer, this is the set of bits and there is no way to
make it shorter. So that was algorithmic information theory, algorithmic complexity.
I think the second one you had was, what was it? Church Turing. Okay. So, okay. The thing that,
if you go back to the beginning of the 20th century, and you'd wanted to get an adding
machine, you might go to a store, you buy an adding machine. You want to get a square root
machine. Okay, you go to a different store, perhaps, and you buy a different machine that
is the square root machine. The big discovery that actually originally got made by Moses
Schoenfinkel with combinators in 1920, but nobody understood it then or since, basically,
but then kind of got clarified by Turing in 1936 is that there exist kind of,
there exist systems that are universal in the sense that you can have a single piece of hardware
that by feeding it different initial conditions, by feeding it different inputs,
you can make it compute different kinds of things. So, for example, you can have a Turing machine
that has some, where just by feeding it different initial conditions, it will emulate any other
Turing machine. So, for example, if we go to, in terms of Turing machines, there's some, I'm going
to show you something. There we go. Well, so, the big point is there exist machines that are
universal in the sense that they can at least emulate all other machines of their type. The thing
that then became clear, starting in the 1930s, is that Turing machines, you can have a Turing machine
that emulates every other Turing machine. It also, by the way, can emulate every register machine,
every piece of lambda calculus, every combinator and so on. So, there's this notion that in the
class of computational devices, there's a certain degree of universality. People had not thought
that that extended to physics. That was the thing that basically was my effort in the 1980s was to
kind of imagine that this notion that what is computationally computable would also be what
is what can happen in physics. People had sort of assumed that physics kind of breaks out of
kind of this computational paradigm. It has real numbers, precise real numbers, has other kinds
of things like that. So, the first thing is the realization in the principle of computational
equivalence. The first thing is kind of the claim that, well, first part of it is sort of the
physics part that, yes, actually, in the physical universe, this is all we've got. We can't say,
oh, we're going to make an analog computer that jumps beyond kind of the church Turing level.
Second point is this. People imagined that to make a universal machine was a complicated
matter. It was something that would be kind of, you have to build this whole microprocessor. It
might have a billion gates in it. It has all these instructions. It's got if statements. It's got all
this kind of structure. And the question is, well, what's, you know, is that really necessary?
Or is universal computation actually something much more naturally occurring? Is universal
computation a special thing? Have to go to a lot of trouble to get? Or is it something that's just
sort of lying around the computational universe? One of the big points to the principle of
computational equivalence is, yes, it's just lying around the computational universe. So,
for example, if we look at these different possible rules here, some of them behave in
such simple ways that we can readily see what they're going to do. They're computationally
reducible. There's nothing more to say. But some of them behave in a complicated enough way
that we're kind of not really sure what they do. Let me show you an example of one of those. So,
this is, let me show you rule 110. This thing actually only grows on one side here, but
just show that. I shall make it, just show just the part where it's growing. So that's,
after 200 steps, let's run it for 1,000 steps. Okay, there it is. It's a little bit unclear what
it's going to do. This is kind of computational irreducibility in action or undecidability,
ultimately in action. What's it going to do? Is it going to have all those little things,
structures? Are they going to survive or are they eventually going to die out?
After, I think it's about 4,500 steps, they do eventually all die out and they just get left
with this one single structure here. But this kind of computational irreducibility in action,
you can't tell what's going on. This particular rule turns out, if you just look at it, let's
start it off from random initial conditions. Let's say 600 across. No, let's say 1,000 across.
And let's say 800 down. Okay, oh boy. It's a little bit on the screen here. Let me
make it a bit bigger. Okay, there we go. So what you see there is that's the initial condition.
This is what happens. What you see is a bunch of little structures here. And you might imagine as
you look at these structures, oh, they're kind of interacting and maybe that's like a logic gate
and maybe we can make an OR gate out of this and so on. But it turns out with considerable
effort, you can do that. And you can show that rule 110, which is kind of just the 110th rule
in this very simple enumeration of possible rules. It's universal. The first one that you
might imagine could be universal is actually universal. So in a sense, you know, the church
touring thesis is saying it is possible to have a universal machine, at least universal within the
class of computational devices that we're talking about. The principle of computational
equivalence says not only is it possible, it's also generically the case it is ubiquitous.
And in fact, it goes on to talk more about individual computations rather than
programmability, but that's kind of a bonus. By the way, in terms of touring machines,
I was very curious what is, you know, if you just look out in the space of possible touring
machines, just start enumerating touring machines. The first one whose behavior is not
obviously simple as this one here that I found sometime in the 1990s. And so then I was really
curious, is this in fact a universal machine in 2007? I put up this little prize and a chap called
Alex Smith managed to show that yes, this particular touring machine, the first conceivably
universal touring machine actually is universal, which is a nice piece of evidence for the principle
of computational equivalence. So that's kind of the relationship between church touring and
principle of computational equivalence. And computational irreducibility is something that
is sort of, it's made tougher by the fact that this property of universality
is ubiquitous in the computational universe. Okay, thank you. MP completeness. What's that?
We have a question here already, so. Wait a second. You get me. My software is not empty yet.
So you asked about NP completeness. So let me try and address that. So
normally, in a touring machine, for example, you have this touring machine, it has a rule,
you started off from some initial condition, it just evolves in some specific way. It has a specific
history. But you can also have, let's see if I have a picture of this.
I have a bunch of these multiway systems. Well, here, let me show you
a tag.
Find some multiway touring machines. There we go. Multiway touring machines. Okay. So
that's a typical touring machine. It has a rule, it evolves in a particular way.
But you can also have a multiway touring machine in which there isn't just a single
possible path of evolution, but there are many paths. So you can end up with this
kind of branching structure. This turns out to be closely related to what happens in quantum
mechanics. That's a separate issue. But so this idea of NP completeness, NP problems versus
P problems and so on, it's this question. If we have a touring machine and it computes something
and it takes a certain amount of number of steps to compute it, an ordinary touring machine
might take n squared steps to compute a size n version of some problem. But we can also have
a non-deterministic touring machine. We can have a multiway touring machine that follows many
different possible paths. And we say, if we have a path that gets to the answer, then it's a winner,
so to speak. And that's the story of NP problems, non-deterministic polynomial time problems,
ones where there exists a path in this multiway touring machine, which gets you to that answer.
So in a sense, this question of NP, sort of the big question, is P equal to NP? Is the class of
problems that you can solve with in polynomial time with an ordinary touring machine, the same
class or different class, than the ones that you can solve with a non-deterministic
with a multiway touring machine? And actually, that question, so, well, let's see. I mean,
we can talk about computational irreducibility and its relationship to computational complexity
theory in general. But NP completeness in particular, there's perhaps a more interesting
thing to say, which is, if I can find this one. Okay, so we can look at all possible touring machines.
This is in a sense in rural space. Where is this? Nice picture somewhere here. Do I? Yes, here we go.
Okay, so this is a picture of kind of the behavior of all possible multiway touring
machines. So in a sense, all possible programs. And this is showing sort of all possible
non-deterministic programs. The red part is the part that's showing deterministic programs only.
It's not allowing the possibility of the rules changing, so to speak, as you go through the system.
So the P equals NP problem, one of the things that's pretty interesting that comes out of
our physics project is essentially a geometrization of the P equals NP problem. That is a question
of the structure of these objects in rural space, that P equals NP becomes the question of
whether essentially the red bit here eventually fills out the gray part of this picture. So you
can kind of have a geometrical version of this ball in rural space that corresponds to the
P problems and the NP problems. So that's a little bit of an indication of that. But you can,
I mean, this whole question about non-determinism and so on, it's a, oh gosh, there's much to
say about that. I've studied this a lot because it ends up being sort of a proxy for quantum
mechanics. What happens in quantum mechanics is that you are following many paths of history
and the observer in quantum mechanics is effectively a sort of an interesting situation.
The observer is branching in the same way that these actual paths of history in the universe
are branching. So quantum mechanics becomes this question of how does a branching mind
perceive a branching universe? And so it's interesting to kind of see a bunch of different
examples of multi-way systems as a way to get sort of more intuition about that.
Okay, another question, apparently.
Well, let's bring it back to our universe just for now. I want to, if possible, in a few minutes
left, because I don't want to say anything. I want to make a connection between what you said
and what Kyle, what Kai you said before. His program was related to computer aided proof
and transformation of verbally stated truths and conjectures into
formal form called auto formalization. And my question to you is what does the irreducibility
principle say about all the possible theorems and all the possible paths to their solution?
And Kyle, you can say a couple of words in response, but you have to say it in your own
words first because you missed your talk. Well, let's see, I wrote a book recently about the
physicalization of metamathematics, which I think is pretty relevant to this. And so, you know,
we can imagine some, let's see, where's a good example? This is that might be some axiom in a
mathematical system. And we can ask the question, what are the consequences of that axiom? That
axiom is saying x dot y is equivalent to y dot x dot y. And now we can say, well, what things are
also equivalent based on that axiom, we can start figuring out. So every path here is a theorem,
that that's equivalent to that. We can start just following, we can start making this network
of all possible equivalent things. And actually, and so a proof becomes a path in this whole network.
And actually, it's a little bit trickier than that when you start looking at,
there's a good example here. The way one actually does, let's see where I've got a good example.
Okay, so this is an example of what more is actually what's happening in mathematics. You have
basically, let's say two axioms here, and you are combining them to get a new theorem. And so you
can kind of build up this kind of this structure you get with those two green axioms, you're,
you're deriving all those theorems, you get this big network that represents all possible
theorems derived from a particular set of axioms. So you can go on, you can get pretty complicated
versions of this, you can derive all sorts of theorems that are true based on certain axioms.
And what's happening is in this, in this graph, the every blue dot is a theorem. Okay. So then you
can ask the question, if you look at, do I have an example of this? If you look at actual axiom
systems in present day mathematics, so for example, you can look at, there's the axiom for semi-groups.
You can start proving theorems about semi-groups. Okay, so we've got this whole network of theorems
about semi-groups. And so one big question is, if you do that, well, okay, so here's, here's an
example based on the axioms of Boolean algebra. So this is proving theorems based on axioms in
Boolean algebra. And you can go and you can build up this giant network of theorems of Boolean
algebra. And this is, this is kind of the, the enumeration of all possibilities. Okay. So now
the question is, is we enumerate all those possibilities? Where are the theorems we care
about? We've got gazillions of theorems that we can just build out eventually. And this is kind
of spoiled. If you didn't know, you don't haven't followed this, but this really odd object that
I talked about in the talk I gave, that is the ultimate limit of all possible mathematics is
this really odd object. And the question of what theorems are, so all these theorems here are true.
All these theorems can be constructed from the axioms. But these are the only two theorems that
people give names to in textbooks of logic out of this collection. We can keep going. We can find,
we can go to, to lots of other theorems. If we, if we use a theorem proving system,
we can, in that big giant explosion of possible theorems, we can go and say, this is the theorem
we're searching for, and we can find a path to it using, using theorem proving. And those are the
paths in that, in that structure of, of, of possible theorems. Okay, so one question then is,
well, out of all these possible, this, this complicated network of all possible theorems,
where are the ones that we humans care about? And so I looked a little bit at that. And so,
for example, you can, you can look, well, that's, that's, for example, that's Euclid. So Euclid
has 465 theorems. And you can start off from the axioms at the top. And you can see what are the
connections between those theorems, according to the proofs in Euclid. Perhaps more interestingly,
you can take a proof of existence system. I looked at lean. I looked a little bit simpler
to look at the system called metamath, which is a formalized math system. And you can ask questions
like, well, that's the Pythagorean theorem, proved from the axioms in metamath. And you can see
they're a different, it's a pretty complicated thing. This somewhere, I think at the bottom here
is the Pythagorean theorem. And you start from the axioms there, and you can kind of count up
of the various axioms, you know, how many times did you use the axiom of equality?
Five times 10 to the 31 times. This is a, you know, this, this is kind of a, a, this is what
happens if you start from sort of the axiomatic foundation, and you build up to something like
the Pythagorean theorem. So, okay. So one interesting point here is this is the axiomatic
sort of structure of the Pythagorean theorem. The question is, do mathematicians care about this?
So, you know, a decade ago, I was very interested in formalization of mathematics. I organized
this conference. We invited all these formalization of mathematics people, all these people interested
in mathematics itself. The formalizers all showed up. The mathematicians didn't show up.
And so the question is, what does a working mathematician actually do? You know, working
mathematician who's, who's thinking about the, you know, the Pythagorean theorem, are they
thinking about it in this kind of axiomatic way? Are they drilling down to kind of this, this low
level axiomatic structure? Or are they just saying it's the Pythagorean theorem and I'm going to do
things at that level? The thing that's pretty interesting and relates to a lot of what I was
talking about is at this kind of axiomatic level of mathematics, it's kind of like molecular
dynamics in a, in a fluid. You've got all these molecules bouncing around. They're doing all these
complicated things. But then at the higher level, at the more human level, what we get to see is
fluid dynamics. And we can ask the question, can we make conclusions at the fluid dynamics level?
Or do we get dragged down to the molecular dynamics level and have to address things at that level?
So in the question of, you know, using the Pythagorean theorem, for example, do you need
to go down to the level of these axioms and worry about how you define the real numbers and so on?
Or are you actually operating in practical mathematics at a higher level, at this level,
where you're, you're just operating in terms of, of, of these kind of sort of fluid dynamics
concepts? So I have to say, I was curious in, you know, in the, in sort of the world of LLMs and
so on. So I will say that the mission of taking kind of a piece of informal mathematics and
formalizing it seems like a fairly, fairly promising use case for things like LLMs.
I don't know whether the formalization in terms of, you know, existing proof assistance and so on,
I don't know how useful that will really end up being. I was curious whether you could use
LLMs as a way to, as a way to, to kind of guide theorem proving. So I looked here at, here we go.
May I make another suggestion instead of looking at, let Kai answer, just a second,
because there's so little time now we can continue in the back.
Please. Am I, let me just ask a very practical question. I have another thing in 30 minutes.
Am I, I could push it back, but am I going to make that or not?
Yes. The other thing in 30 minutes is the plan, is the panel where you, where you plan,
Oh really?
The panel, are you going to do something else?
Well, I don't know. It really depends, but go ahead.
Danielle, Danielle said that you were going to do both.
Okay. All right.
I think she, if you got the other thing from Danielle, it is in fact the panel.
No, no, no. It's a completely different thing, but that's okay. We'll, we'll, we'll tell you a panel.
That's great.
Say this.
Yeah. I think the short answer is yes. Yes. People are using informal mathematics and
auto formalization, which means translating informal to formal to guide theorem proving.
For example, given a proof, you can use language model like GPT-4 to,
you just ask it to generate informal proof or even a sketch, some ideas of,
could be high level idea of how this proof might go.
And then conditioned on this informal sketch,
you, there will be a second step to generate the formal proof.
And, but I think a caveat is if you rely on auto formalization to give you the proof,
it only works if human already discovered this proof.
Because then there's no, if not, if it's completely alien to mathematics,
then there's nothing for you to auto formalize.
I think another direction related to what Stephen mentioned is,
how can we even take one step further? Can we use language models to generate conjecture?
Like generate the huge graph Stephen was mentioning.
But of course the graph, I think it might be infinite or it may be simply too big.
So a really interesting question I want to maybe learn from Stephen is
say we want to generate this graph, but how do we tell if a node is worthy?
Like if a math statement is interesting, because I imagine in this infinite graph,
most of the nodes will be just garbage, like two greater than one, three greater than two.
But we really want to focus on this interesting nodes.
Yes, it's an interesting question. So I've looked at this a bit and I can tell you that in the case
of Boolean algebra, there is a criterion. So maybe I can pull up a picture of that.
If you order, here we go. Hold on. Let's see. If you order the theorems of Boolean algebra
in lexicographic order, then you can ask which are the theorems of all possible theorems? Which
ones are given names in logic textbooks? And sort of a surprise to me is the theorems that
are given names in logic textbooks are the theorems that have, in this case, no back links.
So there's a backlink from this result here, which might be one of your boring results.
This result is derivable from something earlier in this lexicographic list.
So in a sense, it gives you no new information. It turns out the ones that get given names
are precisely the ones that do not have back links. They are not derivable
from lexicographically simpler theorems. So in other words, I was surprised that I discovered
this sometime in the 90s. I was surprised by this, that there was actually a criterion
for what would be given a name in a logic textbook. Now, the general case of is this
theorem interesting? Can we learn enough about the humans to know what they'll think is interesting?
It's a good question. I mean, by the way, in this connection between formal and informal,
obviously, Wolfram language gets connected to LLMs. And we've done lots of work in kind of
tool calling from LLMs to Wolfram language. And there's this whole question of, can you take,
to what extent can you get the LLM to crisp things up to the point where you can, I don't know,
I mean, if I say something like draw a pentagon and a hexagon, for example,
let's see what it does. I don't know if it'll figure it out or not. It might be able to,
we could, the question is, can we generate a, can we turn that informal statement into a piece
of formal Wolfram language code? Okay, not bad to manage to do that one. And if we look here,
I'm sure we can get it to, there we go. So that showed us the actual code that did that,
wouldn't have been the way I would have done it, but it's okay. That's a reasonable way to do it.
But so this is a case where we're going from an informal description to this computational
language, which we can then compute from. And that's a very powerful thing to do. And in fact,
we even have a product that's coming out soon that is based precisely on that idea.
But so I think this question of whether you can sort of, can you guide the proof this way?
I suspect you can. Now this question of what is a human proof, what's, okay, this is an example.
So in automated theorem proving, one of the shocking things about automated theorem proving,
I believe you might correct me and tell me, one day somebody is going to tell me I'm wrong about
this. But so far as I know, essentially all the theorems that have been proved by automated
theorem proving were theorems that somebody already believed were true. In other words,
there is no newly discovered thing that came from automated theorem proving with one counter
example. The one counter example is something I found 24 years ago now, which is this is the
simplest axiom system for Boolean algebra. So you can think of that as a NAND operator.
This is of all possible from that one axiom, you can derive all the true statements of Boolean
algebra. The proof of that is this long 100 step automated proof. Let's see if I have a picture
of it. Yeah, I mean, that's sort of some kind of visual representation of that proof. It has
various popular lemmas in it and so on. In the last 24 years, despite quite a bit of effort,
actually, nobody has ever understood this proof. But it is interesting because it is a proof of
something surprising, potentially interesting, depending on whether you care about simplest
axiom systems for things. But it was found by automated theorem proving without already knowing
what you were searching for, so to speak. And that's a case where now you ask the question,
if you're out in the wilds of, I mean, we can look, I have a nice picture of this,
we can look at, oh, here, is that one? Yeah, this is, these are axiom systems down the left.
Those are theorems across the top. And there's a dot, a blue square, whenever that theorem
is true in that axiom system. So we can ask the question, given an axiom system that we decide
is exciting, and how we decide that is an interesting question, it's unright. But given an axiom system,
we can say, here are the theorems that are true. Now, which are the theorems here that we care about?
And that's essentially a model for humans. And I think it's an interesting question. We've done
some experiments kind of grinding up archive and so on, and trying to figure out, can we deduce
what, in a space of possible theorems, what theorems are likely to be interesting? I don't
know if you've looked at that. Is that, I think that's an interesting thing to look at. Have you
looked at that? Yeah, I think the way I'm looking at it is more, so I kind of am not considering
its relationship with other theorems. I'm taking the theorem statement itself and try to have some,
for example, have the language model telling me whether it's interesting. I believe the language
model can look at some kind of superficial cues, like how long the theorem is and what are the
variables, how they are arranged, how messy it is, and which can already give us some way of
judging how interesting it is. But I agree, like maybe ultimately what an interesting theorem is,
it can help you prove a lot of other theorems. Is that your definition of an interesting theorem?
I'm not sure that's right. I mean, in other words, that is one possible way, I guess.
There are many different criteria you can imagine for interestingness. That particular one
would be saying that if that was the correct criterion, then what you could do,
like I was just showing that picture, actually, in the Boolean algebra case,
wherever it is, then I would deduce from your statement that the theorems that are big here are
the ones that have many, those are the high-out-degree theorems. In other words, those theorems,
that theorem there should be the one I should care about. I don't understand these theorems,
honestly. What's that? I mean, in that sense, yes, because they are special in this graph.
That's right. But the question of whether those are human useful is, I think, a different question.
I mean, in other words, what is, you know, there's this question. It could be the case that two,
okay, first question is, if you look at many different possible things you might prove,
you can ask the question, are there repeated theorems that often, are there repeated lemmas
that often come up in those proofs? Okay. So I looked at that. And the answer is there are.
And so, for example, that axiom system of mine for Boolean algebra, if you use it to prove
theorems in Boolean algebra, you can just look at what intermediate lemmas does a theorem prove
are typically proved to make progress. And the answer is, for example, it takes it 100 steps
to prove the commutativity of NAND, and it often does that and then goes on and does other things.
So in that sense, you know, you can, I mean, it is an interesting experimental question.
To what extent are there repeated lemmas that show up? And that might be a criterion,
but that's a criterion that has nothing to do with LLMs and so on. That's a criterion that just
has to do with the mathematical graph. I think this question of, you know, if we look at images,
for example, you didn't see what I was showing earlier, but here I'll pull up a,
I was just showing something like this. This is in, you know, embedding space of a
generative AI system with in the middle is the cat in the party hat, then there's sort of a cat
island of cat-like things, and then you're out in sort of inter-concept space that we have not yet
explored. And so you can imagine the same kind of thing for mathematics. You say, here's a theorem
that somebody wrote down. Let's sort of change the embedding in some sense and say here are nearby
theorems that weren't necessarily, you know, where is the island? How far out does the island of
interestingness go? What happens in this kind of inter-concept space between this theorem
that we thought was interesting and this other one we thought was interesting? So I mean, I think
it's a, I mean, let's take an example. Let's say, I don't know, let's take, well here, we've got,
you know, these are random pictures generated in inter-concept space that maybe are of things
that we care about. I don't know. I mean, that one on the right, we might kind of think it's,
I don't know what it is, but you know, it was just generated by a generative AI.
And similarly, imagine that was a theorem. The question is, is this a theorem that we care about?
You know, it's just like, is this a picture we somehow
seems relevant to us? And I think, you know, this question of whether, I mean, if we look,
one of the things that's sort of interesting that one can do is to kind of look at this whole space
of, let's see, we can kind of look at metamathematical space and we can kind of ask,
let's take a look here. I think I had a nice picture and find it. I mean, we can ask all sorts
of questions about different possible proof structures, which are, that's a meta mathematical
thing, but let's see if I can find a picture here. Yeah, that's a picture of, I think this is
from metamath. This is empirical metamathematics. It's asking, in the space of all 200,000 theorems,
discussed in, you know, presented in the metamath corpus, where do these famous theorems of mathematics
lie in that space? So it's kind of asking this question that this isn't all possible theorems.
This one is reduced to just the ones that are in the, I think it's set dot mm corpus for metamath.
But, you know, this is again related to this question of where are the ones,
where are the ones one cares about, so to speak. And you can kind of, well, you can kind of see,
this is kind of how the different theorems and different areas of mathematics kind of
get related to each other. But I think it's a really interesting question. What,
you know, and you mentioned that, I mean, I suspect LLM is a really good at picking up on
cues from humans. And so I'm sure there's ways that people will write their master theorem.
You know, they'll make, there'll be more trumpets blaring when they present the master theorem in
their paper than when they present a little lemma. But here's a good question. Here's a question.
If you try and make this, this is an easy thing to test. Okay. Can an LLM classify,
given a statement, can it decide whether the, whether the author of the paper will have called
it a theorem or a lemma? Well, I would guess yes, because there are different subtle cues,
but I didn't try. What I tried, what I did try is I gave LLM some inequalities, like very simple
elementary inequalities. Some were written by humans from the problem sets, from MO problem
sets, for example. And others are just generated randomly by machines, which typically look very
messy. And LLMs can do a reasonably good job at that task. Although I would say that task may not
be very difficult. Well, okay, so we've tried to do things like this, because we've been interested
in automated testing of Mathematica and Moulton language. So we're interested in generating
tests that are plausible input, so to speak. So we've indeed tried doing things like that.
Not been particularly successful. I mean, in other words, you can, you can generate an
expression at random just by some Markov process, for example, and you can generate an expression
by using some LLM like device. And you can ask the question, you know, given, given that you've seen,
I don't know, we've got billions of sort of human related Wolfram language expressions.
And then the question is, can we generate others that are like those? That's one question. Another
question of great practical interest for us is, can we guess whether something that somebody entered
is likely to be what they meant? Or is it something, in other words, it's like asking the question,
is this a, a plausible sentence, or is this a sentence nobody would ever write,
which is something which LLMs in a sense implicitly are capable of doing?
I must make an executive decision now. And it's a calculated risk. We may lose
Steven Wolfram, if it turns out he has something else of higher priority. We may use lose other
people for the panel, in which case I will have called closure on this needlessly. And there may
be nothing in the panel, but I have to call closure because we have to stop this session
and then restart for the next session. I want to thank you very much, Steven, for your, for
your talk. And I hope we'll be seeing you again in 10 minutes, but we'll see. Okay.
Are we using the same link for the panel?
Are we using the same Zoom link for the panel?
I will redo it on, I'll restart it for the panel and I hope you'll be there.
Steven's there too, but I have to break it now.
