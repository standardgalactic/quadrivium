Daniel Schmartenberger, thank you for being with us.
Thanks for having me.
So, you're a philosopher, a founding member of the Consilience Project.
The goal of this conversation today is to analyze the direction our civilization is
taking in half an hour, because you've been doing like so many great podcasts about the
metacrisis during lasting three to four hours, and I suggest that people go and watch them
on the Internet.
They're very good.
We'll start with the harvest of the day.
The question I'm asking to all the guests here for Harvard Podcasts, if something easy
or simple could be done and would make the world a better place, what would it be for
you, Daniel?
When I saw the note that you sent me, that that would be a last question.
Is there a simple or easy thing that everyone could do that make the world a better place?
That kind of cringed?
Because I usually really am not a fan of that question, because the world needs so many
different kinds of things done that require different skills and capacities and orientations
and to try to reduce it to some thing that would be true for everybody.
You get a platitude like be kind or loving or something like that, or you get something
like recycle or pick up trash or try to use less carbon or something that doesn't map
to the whole set of things that the world needs.
I think there's a process where movements have been associated with political processes
and markets in a way that it's like, here's this great catastrophe that'll happen if the
other side gets elected, so everybody needs to get out and vote for so and so.
That's like everybody can do a simple thing because we're relating to everybody as voters
or everybody donate to this cause or boycott this thing, but the complexity of the world's
issues from climate issues to AI risk to supply chain issues to electrical grid issues, like
there's no action like that.
There's no somebody to vote for or not to vote for thing to donate to that addresses
it.
One thing that is not necessarily easy, but is relatively simple, that would be great
if everybody in the world could do more, is to seek to try to understand other people's
perspectives much more deeply, particularly those that are most different than their own.
If you can try to take the opposite perspective on abortion, on gun control, on climate change,
on the Ukraine-Russia war, on the Chinese versus Western system, on any of those things,
on the Israel-Palestine issue.
If you can try to earnestly be able to make the argument that the person on the other
side would make as well enough that they don't have anything to add to it, and not
just as a rhetorical process, but connect to the values that they care about and what
it feels like to be them and see the world through their eyes, realizing that there might
be distortion.
There might be a lot of things missing, but there's not zero truth or zero value to it.
That process, if everyone did that, would actually result in addressing the metacrisis
in all of its complexity, the issues in synthetic biology risk, and pandemics, and escalation
pathways to warfare, and economic issues, and geopolitical issues, and all of them.
You can say that they either come down to conflict or externalities, like we cause harm
directly, intentionally, which a war is a great example of, or harm gets caused that
we didn't intend to cause.
No one intended to cause climate change.
We just wanted to have transportation and energy, and the secondary byproduct of that
was climate change.
All of the environmental issues, no one intentionally had a conflict with the environment that was
causing it.
It was the externality of optimizing something and causing harm somewhere else.
There are problems that we intentionally cause, and there are problems that we accidentally
cause.
Both of them would be corrected by seeking to understand all the perspectives more,
because if you sought to understand the perspectives well enough, conflict theory would evaporate.
Most of the mistakes, when you're trying to optimize for one thing and you end up causing
externalities to something else, somebody else saw that and knew that, and if you were
in wide enough conversations, then the thing that you're trying to optimize for that's
going to cause harm somewhere else someone else would have mentioned and said, actually,
let's improve your design or your strategy by factoring this.
Both the unintentional externalities and the intentional conflict would be resolved through
active perspective seeking and then perspectives and this is wonderful.
When you look at the history, as you said, humans seem to have a talent for innovation
and progress, but also a natural tendency for war and chaos.
These two tendencies fit each other and make things bigger and bigger, so greatest but
out of control technologies can cause a huge damage.
What do you think should be done about technologies and do they represent innovation or danger
for you?
First thing about technology is that even if we're not talking about a military technology,
we're talking about a technology for some other purpose, even if we develop a technology
for some non-military purpose, it will have a military application or some kind of conflict
oriented application, basically saying all technologies dual use.
Maybe we're doing the synthetic biology gene editing for trying to cure cancer, but as
we get better at making tools to do gene editing, can that be used for bio weapons?
Totally.
Maybe we're making the AI to try to do drug discovery, but can that same AI do autonomous
drones?
Of course it can.
Whatever purpose we're developing technology for, we're also making that technology cheaper
and easier for all other types of purposes simultaneously, and that's a huge thing we
have to factor.
From a conflict point of view, obviously people with stone age technology can't cause a war
that blows the world up, and people with bronze age technology can't cause a war that blows
the world up.
The harm is proportional to the amount of tech, so as we move into exponentially more
powerful tech, we can't continue to use it with the types of conflict orientation and
irresponsibility we used previous tech.
The other thing is that even when we're not using tech for intentionally conflict oriented
purposes, all of the tech we use does externalize harm in different ways.
So whether we're talking about agricultural technology where the nitrogen fertilizer fed
a lot of people but also causes all the dead zones in the ocean and soil erosion and biodiversity
loss, exponentially more technology also means exponentially more externalities.
And so we can't handle exponential war and we can't handle exponential externalities.
So we have to change our relationship with technology really fundamentally and say no
other animal have the ability to destroy the biosphere that it depends upon.
We now do.
We did not for all of human history, so we didn't have to really wrestle with that power.
We did kill and enslave and genocide and every previous civilization doesn't still exist
because they all ended up collapsing mostly for reasons that were largely self-induced.
Even when wars happened, oftentimes a war that overtook a civilization was from an enemy
that was less powerful than ones that they had vanquished in their prime.
They had already went through some internal institutional decay from infighting and things
like that.
Many early civilizations died from environmentally induced causes.
They cut down all the trees.
They over stripped the soil of nutrients.
So civilizational breakdown is actually the norm.
It's just never been at a global level.
Now we don't live in the United States or China.
We live in a place where the cell phone that we're watching this on or the computer we're
watching it on took six continent supply chains to make communicating via satellites
so we live in a kind of global civilization where none of the countries are actually
autonomous for fundamental things that they need.
Now that we do have the ability to destroy the biosphere either very rapidly through
exponential technology like synthetic biology or AI or warfare or kind of slowly through
the limits of growth and environmental issues but that's not all that slow.
If you have the power to destroy the nature that you depend upon you have to consciously
steward it or you'll self-terminate.
So the gist is we don't have evolutionary capacities.
We have trans evolutionary capacities meaning-
What's the difference here?
Yeah.
So and I'm meaning evolution in a biologic evolution sense.
So another animal has the capacities that it has corporeally built into its body based
on its genes.
So a predator can't become radically more predatory quickly.
It is only through genetic mutation that maybe it becomes slightly faster or has slightly
bigger teeth and then it's going to be a relatively small change and then there will be co-selection.
The slightly more effective predator will eat the slightly slower preys which means
that the faster prey genes and breed and you get this kind of co-selective process.
We threw our ability to build tools and then tools on tools, recursive abstraction.
If you look at a true apex predator, you look at an orca in the ocean, an orca maybe can
catch one fish at a time, one tuna at a time, then you look at a trawling boat that has
a mile long drift net that can pull up 100,000 fish at once.
They're not apex predators, right?
Like it's wrong to think of us as apex predators.
We have power that is not encoded in our bodies, extra corporeal technological capacity.
You look at a nuclear bomb explosion versus a pissed off polar bear.
They're not similar levels of destructive capacity.
So since we have beyond evolutionary capacity, we actually have to have beyond evolutionary
motive to guide that capacity.
And if you want to say that mythopoetically, it's if you have the power of gods and by
gods here, like I mean little G, right?
I mean it mythopoetically meaning you can make species extinct.
You can destroy ecosystems.
You can create an Anthropocene where the largest effect on the geology of the planet is human
activity.
You can genetically engineer new species, right?
That's much closer to the power of gods than it is the power of an apex predator.
If you don't also have the love and wisdom of gods and prudence of gods to guide it,
it doesn't go well.
And so, you know, that is just another way of saying if you have recursive abstraction
on tools that gives us and tools and coordination that give us the radically more than evolutionary
capacity to affect the world, we have to move into trans evolutionary motive, which means
the same recursive abstraction that we're doing right now saying, oh yeah, I guess it
makes sense that we can't run an exponential financial system that's attached to a linear
materials economy that takes stuff out of nature faster than it can be replenished and
turns it into trash and pollution in nature faster than it can be processed.
You can't do that exponentially forever on a finite planet, so we have to do something
fundamentally different, which means you can't orient towards continued, maximized growth
and maximized conflict orientation forever.
So that's what I mean by a trans evolutionary motive.
Is it naive to think that we need a global government and we can make a global governance?
When you look at the problem of countries having competitive dynamics with each other
where nobody wants to price carbon properly, because if they do, their own economy will
be so damaged relative to whoever doesn't that the radically decreased geopolitical
power will express itself as less military power, less trade power, and particularly
with whoever is at the leading edge of guiding the world system.
This classic, the US isn't going to if China doesn't and vice versa, so then everyone is
mostly actually just in an economics race that is also bound to an actual arms race.
And that's true for pricing carbon and climate change.
It's also true for fishing of the oceans and aerosols and on and on and on.
So if you have an issue like the atmosphere, aerosols and the atmosphere and ozone layer,
or you have an issue like the oceans or climate change, no country can solve that problem.
And any country that does the thing that is doing its share that is economically disadvantaged
in the short term by doing it, it just isn't going to do that if everyone else doesn't
because they are caught in the competitive dynamics.
So when you look at that, you're like, all right, well, we need global government because
we have global issues.
We don't just have national issues and you have to have governance at the level that
you have issues.
But then of course, most thinking people aren't really a big fan of the idea of global government
because it's not a great idea to have unchecked power, though we don't have a good history
of being good stewards of unchecked power.
And so in many modern governments in the United States, it was kind of like the foundation
of the whole idea was let's separate church and state, let's separate the judicial branch
and the legislative branch and the executive branch.
Let's even separate the legislative branches in the separate houses.
Let's try to create as much check and balance on power as possible.
So if you had a one world government that had enough power to be able to price carbon
properly and enforce fishing laws and et cetera, how do you prevent it from becoming
corrupted or captured?
And so we need global government and we don't want global government and so that this is
this like you have catastrophes on one hand that need to be avoided and that typically
looks like more control mechanisms of things that if you don't control will lead to catastrophe
and the control mechanisms typically lead to dystopias.
So we want something that is not catastrophes or dystopias.
We kind of call this the third attractor and that means you have to have control mechanisms
that prevent catastrophes, but you have to have checks and balances on the power within
those.
How do you do that?
So global governance and global government are not the same thing, right?
Global government, the idea that there's some centralized global monopoly of violence,
the bad idea.
The idea that there is some more effective process of global coordination, even whether
it's a more effective process of nations engaging in multilateral agreements that can
be facilitated by technology that can make the participation or violation of those agreements
more transparent or there is some process of global governance that has to occur where
there's both effective power for enforcement.
This is why we can solve those types of coordination problems to some degree, those race to the
bottom within a country where you have a monopoly of violence because the law on monopoly
of violence just basically says, no, you're not allowed to cut down any of those trees.
That's a national park and if you try, the police will stop you and they have more capacity
for violence than you do.
With international issues where you don't actually have international enforcement, it's
really, really tricky.
So for all of the really global issues, and that looks like it's in each nation's interests
to burn the coal as fast as it can and the oil, it's in each nation's interests to win
the AI arms race, even though that increases the likelihood that we all die from it in
the long term.
So global governance that has appropriate checks and balances is a tricky topic, but
it's a necessary topic.
What gives you hope today?
A lot of things can be hoped.
I have noticed in my own work, people in top positions of power and major institutions
that affect the world being radically more aware of things that are fundamentally unviable
about this world system and interested in deeper changes and actually starting to try
to implement some things just even in the last couple of years than I had ever experienced
previously.
So the idea that, you know, the kind of behavior that individuals can do on their own matters
and the kind of stuff we can do locally like, you know, prototyping new types of communities
and new types of cities, you don't solve climate change in time and you don't solve planetary
boundaries in time and you don't solve AI risk that way, right?
That requires kind of agreement from existing top-down organizations.
They can't actually innovate a new world.
They can just stop bad things from happening with the right kinds of agreements to innovate
a new world actually does require local and more participatory activity.
But the fact that after COVID and after the extreme political polarization that has happened
and after how much of Australia burned and then flooded and, you know, now with the war
on Ukraine and I think there was a situation where previously people who were thinking
about it and who were prescient realized this world system is destabilizing and is fundamentally
not sustainable.
Most of the people who were administrating it didn't think that.
Now almost everybody thinks that and that's actually something that gives me hope.
Great.
How much time do we have to react to avoid extinction?
Some species go extinct every day as a result of human activity.
So for them, we're already past existential risk, you know, Kiev was an incredibly progressive
place not very long ago.
It wouldn't have seemed like a place where eminent catastrophic risk was coming for many
people and, you know, that's even true of Syria not that long ago and you see the pictures
of what culture was like in 1968 in Iran.
So it's not like how long do we have before catastrophe hits.
We're already in a rolling global catastrophe.
Like how long does Australia have before it burns that already happened, you know, and
from extreme weather events that are a result of human induced activity poor environmental
management and problems with utility companies and overuse of groundwater and climate change.
And how quickly does war escalate as a result of what's happening in Ukraine at larger scale
and already what we see in regarding Taiwan and Azerbaijan and Armenia and Iran and so
many places.
These things could move very fast or more slowly in ways that are chaotic and totally
unpredictable.
When you look at things like the planetary boundaries, how long until we pass certain
planetary boundaries, you'll hear people talk about this thing happens in 2050 and this
thing happens and by the end of the century or whatever with climate change.
But we've already passed some of the planetary boundaries, you know, there's a study just
published in the American Chemical Society Journal saying that certain toxic chemicals
in rainwater kind of ubiquitous around the world are past the EPA thresholds for human
health.
And this was particularly the the fluorinated surfactants which don't break down, right?
So they come forever chemicals.
But the idea that things that are carcinogens and cause birth defects and are endocrine
disruptors in rainwater all around the world are past the levels of human health tolerability
is a huge deal.
It means even if you go get off grid as can be and try to live off the land, you can't.
And how quickly we're producing those chemicals, not only is there a cumulative effect of them
because they're persistent, but we're also increasing our production of them exponentially.
And so how long do we have?
We're already in a situation of a breakdown of a world system.
It's already existential for many species.
It's already catastrophic for people in many areas of the world.
And so I would reorient the question to be more like, is there anything that we can do
to have it not be totalizing?
And the answer is yes.
And the answer time wise on that is the full life attention of everyone as best as possible
directed at better understanding the issues and participating in the solutions is what's
required.
In individual level, we've become a bit lazy maybe because we think like there is always
a solution and we don't really need to act.
How to wake up and also how do you get the news because you have like so many news in
different directions.
Like we don't know who to believe and we don't know like we're not sure we need to act because
things always have a solution by themselves.
There's a really interesting book called The Politics of the Invisible written after Chernobyl
because after the Chernobyl explosion, the uranium is invisible, right?
We can't see it with the human eye.
Obviously now COVID that's invisible and yet totally lethal.
And what he was exploring in Politics of the Invisible is because of modern technology and
chemistry, we can make things that are totally lethal that we can't see that require people
with Geiger counters and the ability to do physics that not everyone can do to be able
to determine safety levels.
How does that work with democracy when most people don't have the capacity to do that?
So you'll see currently a lot of people doubting climate change science, but nobody can actually,
the average citizen can't run the IPCC's mathematical models to say they work or they don't work
or they...
And so people are largely kind of left to faith and you then end up getting politics driving
people to either be kind of pro-institutional or anti-institutional.
And the institutions get things wrong, so it's easy to be anti-institutional and neither
of the positions are actually viable and there is something other than truth, which is the
movement to power motivated in both of them.
I see that when people think someone else will come up with a solution, they feel kind
of unmotivated, but also when people think there is no solution, they feel unmotivated.
And this is also something I find really interesting is when I talk to someone who has a really
fervent adamant view about whatever it is, that whether it's vaccines or masks or what
should happen in Russia, Ukraine or abortion law, whatever, they go from complete certainty
without understanding the position of the other side or all the complexity or nuance
well.
And if I challenge it and not, regardless of which side it is, and show them the increased
complexity, okay, well if we price carbon that way and China doesn't, then autocracy
ends up running the world, so you're voting democracy out and whatever it is, then for
so many people, the first response when you increase, show them the way they're thinking
about it doesn't actually map to the complexity of the problem, they go from utter certainty
to nihilism in one step.
They're like, oh fuck it, it's too hard, it's too complex, I give up.
And to move from certainty to nihilism in one step is so damn lazy, like cognitively,
emotionally, epistemically lazy.
And so I want people to go from certainty to like, actually I don't understand this
all that well.
Actually, climate change or global science or policy on this thing is pretty complex.
There are experts who spend their whole life working on it who disagree.
That doesn't mean there aren't solutions, but the one that was fed to me that everybody
on my political side agrees with and everyone on the other side disagrees with is probably
not a fair version of the whole truth.
So I'm not going to give up because I don't know.
I'm not going to hold the certainty that I know because I don't.
I'm going to work to try to understand competently while recognizing I don't yet.
And then even once I get to much deeper understanding, I'll still recognize how much stuff I don't
know that's relevant and new information that might come in.
So I want people to be much more epistemically rigorous and epistemically humble at the same
time, epistemology meaning how we go about knowing things.
So I want them to work much harder at trying to come to understand while having much less
certainty about their current level of understanding.
So when you ask what sources should people go to for news or whatever, the ones they don't
currently go to is the first answer.
And then, of course, progressively better sources.
Not all the sources independent of political spinner are equally good.
But when you can see where do the various earnest experts on the topic disagree and
you at least understand those positions pretty well, then you start to have a sense of the
topic.
As a philosopher and because you spoke about politics, do you want to stay away from politics
or are you into politics?
Politics meaning how people organize and how they coordinate and how they make sense of
the world together so they can make choices together.
No, I'm totally focused on that.
The current political system and the United States does not do a very good job of helping
people collectively make sense of issues well, collectively identify all the values that
matter that are shared values and then collectively make good choices in the presence of the shared
sense making and shared values generation.
So it's not that I think there is never a time to engage in voting for a particular
candidate or on a particular proposition, but how to engage in metapolitics, meaning
how to evolve this political system and economic system, how to evolve the political economy
along with evolving the infrastructure and tech stack and the culture and value system
simultaneously because all three of those inter-effect each other.
The culture, the political economy and the infrastructure and technology, they all inter-effect
each other.
So you can't change any of them without changing all of them to think through what has to happen
in all of those for a viable world to come about.
I'm very interested in that.
Okay.
Let's speak a bit about you, something very interesting I found.
You mentioned you were homeschooled by your parents.
Which qualities did your parents manage to let flourish in you that might not have been
so important also in the traditional education when you're changing teachers every year?
I was homeschooled, I did go to school, both private and public schools for little bits
throughout my life.
So I have some experience of it, but most of my childhood was homeschooled, but it was
not traditional homeschooling, meaning I didn't have the state curriculum and just do it at
home.
My parents were kind of interested in running an educational experiment that is a little
bit closer to what people call unschooling today, but there was just no curriculum.
Okay.
What they felt you need to learn.
It's not what they felt.
Their hypothesis was expose the kids to all the different topics, see which ones they're
interested in, facilitate their interest, and kind of trust them.
So it's aligned with some of the ideas of Montessori and Dewey and Constructivism.
But you know, radical had no curriculum at all.
But and I'm not saying that is what I would advise, but there's a lot good in that.
And what qualities that facilitated in me that most educational systems don't is all
of my studies were things I was interested in.
And so my interest in learning was actually growing all the time, right?
There was never a place where I wanted to get out of school and go play or do something
else where learning felt like a burden or where I ended up not having any negative association
with study.
And I had only positive association because I was studying things I wanted to study.
So I find that people tend to become good at things they really enjoy.
And so facilitating, like even if you have a curriculum, really paying attention to where
a student's interests are and where their passions are.
And if there's a topic that isn't appealing to them, trying to find a way that actually
has it really appeal as opposed to just forcing them to do the thing makes a huge difference
not to their learning of that topic, but to their relationship to learning itself.
What a special event that put you on this path of trying to see the truth, what's happening
and observe the complexity of the world.
Lots of events.
I mean, some people have a near death experience turning point that is really kind of singular.
I think most people's life path unfolds from lots of things.
So as I'm mentioning being homeschooled by parents who are obviously kind of interested
in childhood development and the books my parents read to me as bedtime stories were
Buckminster Fuller's Design Science and Fritschof Capra Systems Theory and Eastern
Vedic Philosophy and things like that.
So there were people who were thinking about what is the world?
How does the world work?
How do we integrate across the various philosophic and scientific traditions?
How do we improve civilization?
Those were kind of like just the core thoughts.
And so I didn't really have to get on that path.
And then a big part of my study as a kid was not just studying various areas of philosophy
or science or whatever, but also being actively engaged in activism.
My mom was particularly into kind of hands-on activism with whether it was helping the local
animal shelter or larger kind of factory farm animal rights issues or environmental issues.
So being engaged in activism and then seeing what the problems in the world were and then
similarly having a system science and kind of design science background to look at it
and say, how are these problems interconnected?
What do they have in common as generative dynamics?
What would it take to address them more comprehensively because it's not that hard to see that whether
we're talking about issues in healthcare or issues in war, issues in politics or issues
in the environment, things like perverse economic incentive or one of the drivers of all of
them.
So it's like, well, how do we think through an economic system that doesn't have perverse
incentive?
Yeah, I would say it was working across many different areas of activism, seeing how they
related to seeing why the solutions that we were working on weren't adequate because they
didn't address the deeper dynamics.
Those were kind of key early things for me.
Thank you very much, Daniel.
Yeah.
Thank you.
Thank you.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
Bye.
