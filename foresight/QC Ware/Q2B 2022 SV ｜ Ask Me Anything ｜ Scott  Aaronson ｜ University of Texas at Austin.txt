Hi everyone, great to see you all at Q2B, and very excited to be closing this out.
My name is Anastasia Marcinkova, I'm a research engineer, scientist at Bleximo, and I've spent
the last decade in various parts of quantum computing and information from neutral atoms,
trapped ions, and now in superconducting qubits.
And I'm very excited, you know, 10 years ago I was taking the physics GRE, and very sad
about my scores, wondering if I get into grad school, and this year I get to be up on stage
with Scott Aaronson.
I've never taken a physics GRE, I'm not sure I could pass one.
Oh wow, okay, well, go, so tell us a little bit about yourself and your latest work.
Well, I took the computer science GRE, I came into quantum computing entirely from the math
and CS direction, and got very excited that it was just vectors and matrices, you know,
that was all I needed to know to start working on quantum algorithms.
Now, eventually, after I'd been in this field for long enough and hung out with enough physicists,
at some point I picked up what a Hamiltonian was, and then I learned what a Boson and a
Fermion was, now I'm trying to learn what ADS-CFT is, and then, you know, a little bit
about what a black hole is.
Okay, but, you know, I just sort of pick up my physics on the streets.
Now, in terms of my recent work, I happened to be on leave this year from my normal job
at, you know, teaching computer science at UT Austin, I am working for OpenAI, which
is based in San Francisco, on the theoretical foundations of AI safety, okay, such as if
any of you have tried out a GPT, you know, how can we prevent it from being misused?
How can we prevent every student in the world from using it to write their term paper, okay?
So, you know, that has very little to do with quantum computing, and I, you know, quantum
computing was my first love, and I intend to come back to it, but yeah, that's some
of what I've been thinking about, you know, and I also continue to work with my students
in postdocs, we have some neat projects, one of them about reconstructing the bulk in quantum
gravity, continue to think about quantum supremacy experiments, how can we make them easier to
verify the results using a classical computer, you know, how can we use them for, you know,
certified random bits, or for other purposes, so yeah, those are the quantum things that
I continue to think about.
Great, so we're definitely going to get a little bit into the wormholes and the work
at OpenAI, but first I want to talk a little bit about the quantum space, and what do you
think are the most exciting developments this year in the quantum space?
Yeah, well, I mean, a major milestone in the past year was the proof of the so-called
NLTS conjecture, which showed how entanglement can survive even at finite temperature, you
know, like very large amounts of entanglement, it's, you know, a major step toward potentially
proving this quantum PCP theorem, which has, you know, been a central problem in the field
since 2005 or so.
Now, I was also super excited this past spring by a breakthrough of Yamakawa and Janshree,
and so they've given sort of an entirely new type of exponential quantum speedup, not
yet for a directly useful problem, but it is an exponential quantum speedup for a search
problem, so a problem with verifiable solutions, and which works relative to a random oracle.
Okay, so a random oracle, you know, is a sort of idealized object, but you can substitute
it in real life using a pseudo-random function.
Okay, so their proposal leads to an experiment that, you know, I mean, if you had, you would
need a fault-tolerant quantum computer, the same kind that you would need for Shor's algorithm,
for example, but, you know, if so, you know, this is sort of an entirely new class of exponential
quantum speedups, different from, you know, the kind in Shor's algorithm, for example,
and I think, you know, it's opened up a whole new avenue of possibilities to play with.
Now, there's been progress in the past year in understanding quantum algorithms for homology
problems, for, you know, topological data analysis, both positive and negative.
There have been some de-quantizations of these topological data analysis algorithms.
There's also, like, approximately a QMA hardness for Klee homology, due to, in part to Marcos,
who now works at QCWare, so, you know, so we're getting a better understanding of that.
There has been progress on quantum supremacy experiments.
Xanadu did a Gaussian boson sampling experiment in the past year with a photon number resolving
detectors and, you know, tunable beam splitters and hundreds of photons.
So that was cool, and I think, you know, established a state of the art there.
But there's also been progress in a negative direction, as many of you have seen.
Classical computer scientists have gotten better at figuring out how to take the random
circuit sampling experiments, for example, and spoof them classically.
So I would especially mention work by Zhun Gao and Belaz Barak and others at Harvard,
and also some very new work by Darita Harinov and Umesh Vazharani and others that have given
algorithms, you know, that, you know, I would say leave the quantum advantage that was achieved
by Google a few years ago.
You know, they leave it still standing because, you know, either they're less efficient or
else they get a benchmark and this linear cross entropy score that is not as good as
what the Google experiment demonstrated, okay, but they leave the claim of quantum supremacy
standing more precariously than I would like, okay, and I would say that the ball is now
firmly in the court of the experimentalists to do better quantum supremacy experiments
with better gate fidelities, for example, that will put more distance because, you know,
we would like quantum supremacy not only to have been achieved, but to stay achieved,
okay, so that's been another thing, yes, so those are some of the developments in the
last year.
I mean, there was major progress in understanding, I think, the relation of quantum computing
theory to the black hole information problem worked by Daniel Harlow and Netta Engelhardt
and so forth involving non-isometric codes, you know, and that's lead to all sorts of
open questions that are interesting to people like me, you know, even if we don't know,
you know, even if we didn't care about black holes or string theory or anything like that,
but you know, in terms of the more practical developments, yeah, I think, you know, those
are some of the developments that most excited me.
Yeah, definitely, so I loved reading your last blog post, I know we've all been busy
with the conference, but I highly recommend reading it, it was a great, great analysis
of this, but let's dive in more to the quantum supremacy, so in 2019, Google had the Quantum
Advantage experiment, a few other groups, you mentioned Zandu carried out their own
experiments, but these experiments are really not free of that criticism, and on that blog,
you talked about the random circuit sampling, and even though the authors themselves did
not claim breaking Quantum Advantage, some other people say that it might have refuted
that, so how do we actually clearly establish quantum supremacy, and what do you think is
what we need to do to get to that phase?
Yeah, well, I think that, you know, often it's just a matter of reading what the paper
actually says, rather than just trying to get some kind of vague zeitgeist or vague feeling
about it, so the thing is, from the very beginning of this quest to demonstrate quantum advantage
supremacy, whatever, in the NISC era, we knew that we were playing a game where, fundamentally,
it doesn't scale, right, like we might be able to do this with 50 qubits or 100 qubits,
but you're not going to scale to 1,000 qubits, because if you did, then presumably you would
want an enormous circuit depth to get all your qubits to talk to each other, but the
signal that you can read out when you make a measurement, if your qubits are not error
corrected, then your signal is going to degrade exponentially as a function of the depth,
right, so when the depth becomes too large, you just can't read the signal anymore, your
signal to noise ratio is negligible, so we knew that ultimately what you need is quantum
error correction, right, and hopefully, you know, that message has come through loud and
clear through many of the talks that you've been to over the past three days, right, ultimately
scaling will require error correction, okay, so we've been playing a game where we hope
to eke out, you know, some advantage before that era, that, you know, that at least puts
the ball in the skeptics court, right, at least makes it, you know, gives them the challenge
of saying, okay, if you don't believe that quantum computing can ever work, right, well,
it seems like, you know, how do you explain the results of this experiment, right, without
talking about a two to the 50th dimensional Hilbert space, you know, that was actually
involved in the computation, right, you know, just today I was arguing with people on my
blog who were, you know, you know, and making this point, right, I think these experiments
have put the ball in their court, and that was the original point, right, so now what
the new work by Harinov-Vazharani at all, what that has done is to sort of nail down
the conclusion a little bit more rigorously, that indeed, you know, it's not going to scale,
you know, the quantum advantage will not scale to more and more qubits without error correction.
There was a little loophole in that statement that we, you know, did not know how to rigorously
justify, namely, like, what about when the circuit depth is neither too large nor too
small, like, you know, if the circuit depth is constant, then we, you know, and the gates
are geometrically local, then we know how to simulate the thing using tensor network methods,
if the circuit depth is too high, then, you know, the noise is too great, okay, but if
the circuit depth was like logarithmic in the number of qubits, then we didn't know
how to rule out that random circuit sampling could give you a quantum advantage even that
would scale to arbitrary numbers of qubits with no error correction, and so, you know,
using sophisticated techniques, they've now ruled that out, okay, but it's important to
understand that, you know, this proves a conjecture that, you know, everyone in the working in the
field, I think, would have made. It doesn't disprove a conjecture, okay, so, yeah.
Okay, great. So how do we get there, I guess? So what fields do you think in the quantum space
have been over-served versus under-served? You and I probably remember very well the QAOA craze
a few years ago where every paper, you know, every day was QAOA. Is that over? You're speaking
about it in the past 10. I know, well, maybe, but I'm seeing less of it these days.
All right. Some of the years were a lot, but yeah, have we gone to deep in QAOA? Or not deep enough
in other parts that will get us to that quantum supremacy that we need? Yeah, well, I mean,
the kind of thing that I always want to see less of is, you know, the papers where they say, you
know, we do such and such with a quantum computer, right? We show how you can do
machine learning, optimization, finance, this or that, and they don't even ask the question of,
well, how does it compare against, you know, what you could have done with a classical computer,
right? And where sort of the entire case seems to depend on just no one, you know, everyone
tacitly agreeing to not ask that question, right? You know, as obvious as that sounds,
you know, I feel like that still describes like at least 15 to 20 percent of all of the papers
that I see on the Quant PH archive, okay? And I'm always hoping to see less of that.
Now, you know, in terms of what I'd like to see more of, right? I mean,
yeah, I mean, I always get interested when I see a paper that just sort of steps back and, you know,
looks for a new kind of quantum speedup, you know, just like that this example by
the work by Yamakawa and Jantree that I mentioned earlier, right? Even if it's not immediately
useful for anything that I can see, right? You know, I'm way more excited about a new kind,
you know, a sort of fundamental new source of quantum speedup, you know, that then we can
think about what it is good for. Then I am about, you know, someone who starts with, you know,
what they want, like some, you know, finance application or some vehicle routing application,
and then, you know, tries to, you know, say, well, here's the quantum algorithm to do it. And,
you know, and as long as no one asks too hard about, you know, how, as long as no one pushes too
hard on how well could we have done the same thing classically, you know, we can impress people by
saying that we did this with a quantum computer. So we've talked a lot about the algorithm side,
but what about the hardware side? Have you seen any great accomplishments this year? And what are
you kind of looking for that canary in the coal mine of when you're going to start getting really
excited about this being actually applied to hardware? Well, look, I mean, I mean, I've been
excited enough for 20 plus years to, you know, spend my career working in this field, right?
So, but, you know, with, you know, quantum, the sort of first quantum supremacy experiments now,
you know, three years old, I think, you know, it's clear to most people in the field what the next
steps are, you know, you know, demonstrate quantum error correction, just keep a, a logical qubit
alive for a long time, you know, demonstrate that you can do that, you know, against both X errors
and Z errors, you know, that you can do fault tolerant operations, you know, of course, many
groups are working or racing toward trying to demonstrate that. But I would also stress,
you know, do better quantum supremacy experiments, you know, I do not regard that as a done deal,
right? Because, you know, again, classical spoofers have gotten better and better, right? Now, on the,
you know, what I would really like, you know, this is, unfortunately, you know, when the hardware
people come, you know, this is something that we have not yet managed to solve for them. But to
figure out how to do near term quantum supremacy experiments where the answer can also be
efficiently verified using a classical computer, right, where you don't have to calculate this
linear cross entropy score, which takes an exponential amount of time on a classical computer
in order to verify the results. I, you know, I think, you know, the, the current generation
of quantum supremacy experiments are inherently limited to, you know, 60 qubits, let's say,
because beyond that, we don't even know how to verify the answer. So, you know, I'm, you know,
I have some ideas for how we're going to go beyond that. But I think that will really take a new idea.
Great. So one last question for me before we get back to the audience and,
you know, obviously for everyone else, you know, send your quantum supremacy experiments to Scott
to check up on before, so you don't get a blog post about your paper, or maybe you want that.
So you've done amazing work at OpenAI so far, and, you know, a big question is,
are you coming back to quantum? When are you coming back? And are you going to take any
learnings back? Yeah, I mean, I guess I never really left. Don't tell my bosses at OpenAI that,
but I, you know, I mean, I still, you know, I'm based in Austin mostly. I still run my research
group. I supervise my, you know, students and postdocs. We continue to write quantum computing
papers. But, you know, I'm not, I'm not teaching this year. And so I am, you know, spending the
majority of my time thinking about AI safety. You know, I mean, I mean, quantum computing,
in some sense, was my first love. You know, when I was a beginning grad student in 2000,
I was actually deciding then whether to go into quantum computing or machine learning.
Those were, those were my two main choices. And, you know, I already had a sense then that
machine learning was going to be societally important on a shorter time scale. You know,
this was a decade before the deep learning revolution started, right? So I didn't even
know how important, but, you know, it seemed like, and yet quantum computing was just more fun,
okay? Because, you know, with machine learning, kind of everything was messy and empirical,
right? And, you know, you could just sort of stare at graphs and try to, you know, infer what
was going on. But there was never any theory to explain it. And with quantum computing, even
though we were so far from having the actual devices, you know, we could understand so much
about the various quantum algorithms and why they worked or didn't work. And so,
you know, 20-some years later, I still feel like quantum computing is more fun. And so, you know,
I don't know. But, you know, I just, I tend to get drawn to problems that are fun,
as opposed to having any kind of coherent plan for, you know, what I'm going to work on.
All right. Well, thank you so much for answering my questions. And now we'd like to open it up to
the audience. So ask all your questions for Scott.
Hello, Scott. Hi. It's an honor. I wanted to ask you what are your thoughts on, I mean,
it's an open question, but what are your thoughts on the classes of problems that are
quantumly easy and classically hard to solve? So, to be a bit more specific,
using near-term devices, what area do you think quantum computing can have the most impact on?
Yeah. So our best bet for near-term devices, you know, remains what it was when
Feynman started talking about quantum computing 40 years ago, right? Namely,
simulating quantum physics, right? Learning more about materials, about chemistry, as we heard
in the very nice talk by Brigitte Whaley this morning. You know, learning about reaction rates,
you know, hopefully, you know, learning about condensed matter physics, maybe even learning
about quantum gravity. You know, for anyone who's wondering, I do not think we learned anything
new from this nine-qubit simulation of a wormhole, quote-unquote. We did open one?
We didn't open a wormhole. Yeah. Well, if we did open a wormhole, then it's in a different universe,
you know, not one that we have any access to, right? But, you know, so other people might
equivalently describe the situation by just saying we ran a little quantum circuit on nine
qubits, right? And we knew perfectly well what the outcome was going to be. So, I mean, this is,
you know, like, when this is the thing, like, when you do, you know, when you sort of design a
quantum circuit or a quantum protocol, but then you feel like, well, maybe people won't, you know,
pay enough attention or it won't get into nature, you know, unless I actually run it on a quantum
computer, even though I know full well what the result is going to be, like, this has less of the
character of an experiment, more the character of a PR stunt, right? And so, but having said that,
you know, once you can scale up to devices with, you know, 100 qubits, 200 qubits, you know,
we will be able to test out models of condensed matter physics, even, you know, theoretical
models of quantum gravity in a way that might tell us something that we didn't already know,
and that is genuinely an interesting prospect. And ironically, one of the earliest things that
we might be able to do with quantum computers, just because, you know, with chemistry, for example,
there's all sorts of messy details that you have to get right because you have to match observed
reality, right? With quantum gravity, you can just make up the model.
I always joke that a first quantum computer may build a better quantum computer.
Yes. Well, yeah, okay, so you could say that that's the other main, main application of near
term quantum computers, namely, learn about the problem of building a quantum computer, right?
It's kind of like the main application of sending humans to space, right, which is to learn about
how to send humans into space. Hi, Scott. Over here? Yeah. No, over to your left. Hi. Hi. Mark
Masingly Scott, it's my name. I have a question about, you mentioned that quantum computing is
interesting because it's fun. My question is about the commercialization of quantum computing.
Do you think about that? What do you think about that? And I won't ask you the question,
when do you think it's going to be commercially viable? Because the answer is always in five years.
But what do you think is going to happen between now and it actually becoming commercially viable?
So I certainly think about it. I mean, often I'm thinking about it in the context of someone has
claimed to have something that is already commercially useful. And it's based on statements
that are insofar as we can evaluate them seem to be false. And then I get emails
about it. And then I have to write a blog post about it. But I think that I am cautiously optimistic
that within the next decade, we will see the first quantum computations that are actually useful
for learning about various quantum systems. I think maybe first we will see things that are
scientifically interesting, or that teach us something new about materials. And then maybe
we will start to see things that are also commercially interesting. What tends to irk me
is when people are seeming to jump the cue here, where we haven't even clearly established the
reality of any quantum speed up at all, even for something completely useless, let alone for
something scientifically interesting, let alone for something commercially useful. And then they're
already talking about working with Volkswagen to optimize vehicle routing. If you were actually
going to beat classical here, then you would have been able to do all of these earlier steps in the
process, which are still huge, unsolved challenges. So that tends to be my feeling about it. Now,
when I look at the various quantum startups today, some of them I'm actually very enthusiastic about.
And I hope that they, I'm not like investing my own money in them. But then again, I'm not a
venture capitalist. My money is just sits in the bank doing nothing. Certainly there are startups
where I feel like they're taking a big risk, but I hope that they succeed. But usually when I'm
asked to judge some startup, like I'm judging something different than maybe most people would,
which is I'm looking at, I can't judge all kinds of things about the quantum computing startups
about their hardware, about their plans for the future. I can just judge the statements that they
make now about quantum algorithms and see if they're true or not. Or if they let they comport
with no knowledge. And if they're saying things that I know are false or wildly exaggerated,
then that gives me less confidence, of course, about the parts that I can't judge. And conversely,
if they're careful about the things I can judge, then I have more confidence.
Hi. Oh, sorry. You had mentioned, can you hear me? It's working. I can hear. Okay. You had mentioned
in the 20 years ago, when you were deciding to go one way or another. And during that time,
you wrote a very interesting paper on who can name the biggest number. And therein,
you discussed the busy beaver problem and how huge it gets. But you never mentioned in there
how it gets so big. I mean, you mentioned in there Rado who invented it in the game 1960.
And if I remember right, he said beaver busy number four or five is something humanity can never
know. Well, busy beaver five, we might know. In fact, there's a conjecture that it's about 47
million. Busy beaver of six is at least 10 to the 10 to the 10 to the 10 to the 10 and so on 15
times. And there is my question in that paper. Yes. You mentioned that intriguing effect, but you
never explained how it gets so big. How's that possible? Okay. All right. All right. Fine. Well,
this question has nothing to do with quantum computing. Let's be clear. Ask me anything,
though, right? Yeah. Fine. Fine. Fine. I didn't say I didn't say I didn't say I wasn't going to
answer it. So by the way, I would not have mentioned in 1999 that busy beaver of six is that enormous
because that wasn't known at the time. Okay. That was only discovered actually within the
past year, which is kind of a cool discovery. So the busy beaver of n is defined as the largest
finite number of steps that can be taken by a Turing machine with n steps. So basically think
of like the largest number of things that an n-bit computer program can do if it has to halt
afterward. And what you can prove is that this function as a function of n grows faster than
any computable function. We know that because if it were computable, then you could use that to
solve the halting problem, which Alan Turing proved was impossible. So in some sense, that gives you
the abstract reason why it has to grow ridiculously fast because otherwise you could use it to solve
the halting problem. Okay. But if you want to be a little more concrete, you could say, look, you
can encode and actually someone did this not long ago. You can build a 27 state Turing machine
that halts if and only if there is a counter example to the Goldbuck conjecture. It says every
even number four greater is the sum of two primes. And so in order to know even just busy beaver of
27, you would have to settle Goldbuck's conjecture. Okay. So this one function encodes in it a large
fraction of all of mathematics. And in some sense, that is the reason why it has to grow as quickly
as it does. Yes, that is what I said. I don't know how to answer that question. Okay. I mean,
it's kind of like saying, you know, you said why two plus two is four, but how is it four?
It's like, you know, I don't know what to do with that.
Okay. Yeah.
Hi, Dr. Aronson. Quick question. You were just at the Institute of Advanced Study.
Yes.
I was wondering if there were any interesting takeaways, anything that you found interesting
there? Want to hear your thoughts?
Yeah. No, it was super interesting. You know, I was at the meeting of this community called
It From Cubit. And, you know, there were a lot of talks, actually,
both about quantum gravity, about the black hole information problem, but also talks about
quantum computing theory from, you know, about quantum supremacy experiments and so forth from
Umesh Vazirani spoke and others who might be familiar to some people here. You know,
there was a very nice talk by Bill Fefferman about a new notion called pseudo entanglement.
So they've now shown how you can prepare quantum states that are indistinguishable
from highly entangled states, even though they're not highly entangled,
even though the amount of entanglement in them is actually very small.
That seems like a potentially useful notion. You know, again, it could be useful for all
sorts of purposes just within quantum information, but their motivation for it originally came
from quantum gravity. So it's been kind of amazing to see how these two fields have come
together. Now, there was a discussion, and I should say some dispute at this workshop about this
recent experiment that, you know, some people have misstated as having created a wormhole
on the Google Sycamore chip. And I think, you know, no one who understands actually disagrees
about the relevant facts, which is, you know, it's just some nine qubit quantum circuit,
but they disagree about how to talk about it. You know, some people say, well, we should praise it,
you know, it's exciting, and maybe it'll lead to more in the future. And others of us
are very concerned that, you know, if the public gets the impression that, you know,
these physicists are claiming to have, you know, opened up a wormhole in the lab,
and then they learn the details and they find out that it is, you know, nothing at all like
they thought it was, then, you know, they're going to lose trust in the enterprise of physics itself.
And, you know, and so we ought to be very, very clear about what has and hasn't actually been
accomplished. So I have a question. So the Nobel Prize was awarded for entanglement this year?
Yes. Do you think that topic is closed or there's still very interesting research around entanglement,
like emergent effects for a million qubits, for example? Yeah, I think that entanglement
as a whole is sort of a permanent part of physics, right? It is, you know, I mean, everything that
we do in quantum computing, you know, whether we mention it explicitly or not, right, we are,
you know, trying to understand, you know, what you can do with these highly entangled states
on millions of qubits. Those questions are not going away. Okay, now this Nobel Prize
was specifically for, you know, the experiments that sort of demonstrated the reality of two
particle entanglement, like, for example, via the violation of the Bell inequality or the CHSH
inequality, right? And, you know, that's something that many of us have thought was a way overdue
Nobel Prize, right? It could have been given 20 or 30 years ago, but it's, you know, like usual,
the way to, you know, to win, you know, the Nobel Prize in physics is like a biathlon,
right? You have to, one, do something that deserves the Nobel Prize, and then two, stay alive for long
enough, right? But, okay, but I would say that in terms of the violation of the Bell inequality,
you know, I would say with the experiments in 2015, which simultaneously closed the
locality loophole and the detection loophole, I would say that all of the quote-unquote sane
loopholes to the Bell inequality violation have now been closed. Okay, all that remains
is the utterly insane loophole, which is called superdeterminism, right? Which is basically the
idea that, like, if you just treated the entire universe as a conspiracy theory, right, and said
that, you know, ever since the Big Bang, it was predetermined what experiments we were going to do
and so forth, then you can explain away the violation of the Bell inequality, but then, you
know, you're like, the cure is a billion times worse than the disease, right? So, you know, I think
that, you know, insofar as physics can ever establish anything, I think that with the fully
loophole-free Bell experiments, yes, it has now established the physical reality of quantum
entanglement, and we can at least move on from that question.
Related to your work right now in AI safety, what can we learn from your experience there
on quantum safety in a much more early stage than we addressed it in AI?
Well, I mean, you know, I'm not confident that quantum safety, you know, really raises kind
of novel issues, you know, that are different from those raised by classical safety, right? I mean,
you know, you want to, like, you know, I like to say, you know, a quantum computer is not exactly
like a nuclear weapon, right? It probably won't kill anyone unless the dilution refrigerator
tips over onto them or something like that, right? You know, I mean, I mean, certainly,
there will be national security issues that come into play once you have scalable quantum computers
that can break public key crypto systems, okay? And those are already being discussed,
you know, sort of in principle, we know how to respond to those things, you know, with the
post-quantum cryptography, but, you know, it will be a struggle to get everyone to adopt that
and to sort of agree on standards for that. You know, I mean, that's the closest that I can
think of to a quantum safety issue, right, is just the move to post-quantum cryptography.
You know, other than that, you could say it's just, you know, a new kind of computer that will be,
you know, super fast for certain things. You know, now with AI, you know, the worry specifically is,
you know, you give, you slightly mis-specify what its goal is, and then it's intelligent enough to
think creatively about how to accomplish that goal, even if that means plotting against you,
or, you know, doing something wildly different from what you intended.
