1
00:00:00,000 --> 00:00:04,600
Thank you very much for the very kind considering introduction, Rene.

2
00:00:04,600 --> 00:00:12,000
I'd like to get started by paying homage and thank the people that allow me to do this

3
00:00:12,000 --> 00:00:14,320
kind of work.

4
00:00:14,320 --> 00:00:20,560
Those of you who don't know, there's basically dozens of people involved downstairs in the

5
00:00:20,560 --> 00:00:28,560
facility that take care of our furry colleagues and keep the operation running.

6
00:00:28,560 --> 00:00:35,560
I want to thank the various funding sources, of course, the people in my lab, and then

7
00:00:35,560 --> 00:00:40,360
also this particular group of people, two of which have moved on and are doing post-doc

8
00:00:40,360 --> 00:00:45,360
already that collected the data, some of which that I will show to you guys today.

9
00:00:45,360 --> 00:00:49,040
And last but not least, Nao Tokia.

10
00:00:49,040 --> 00:00:54,280
Each time I get to talk about this in front of a group of young aspiring scientists, I

11
00:00:54,280 --> 00:00:56,160
want to point this out.

12
00:00:56,160 --> 00:01:01,240
You should not just try to connect vertically and that works vertically with people that

13
00:01:01,240 --> 00:01:02,400
are more senior to you.

14
00:01:02,400 --> 00:01:07,160
You should really strive to branch out horizontally and make friends with people that are in your

15
00:01:07,160 --> 00:01:10,560
cohort because they will become more important to you as your career goes along.

16
00:01:10,560 --> 00:01:11,960
Now is such a case.

17
00:01:11,960 --> 00:01:14,080
I met Nao as a graduate student.

18
00:01:14,080 --> 00:01:19,600
We had very strong fellow interests and we've been collaborating basically ever since.

19
00:01:19,600 --> 00:01:24,560
And this has really borne fruit, as you will see, hopefully today.

20
00:01:24,560 --> 00:01:28,440
So actually, I want to give all the credit to Nao because the ideas that I'm going to

21
00:01:28,440 --> 00:01:31,840
show you largely stem from Nao.

22
00:01:31,840 --> 00:01:37,960
And so I'm just basically a humble messenger to introduce you to his theories.

23
00:01:37,960 --> 00:01:39,200
So what allows me to do that?

24
00:01:39,200 --> 00:01:42,240
Well, there's a variety of factors that allows me to do that.

25
00:01:42,240 --> 00:01:48,360
One of them is the situation that we're all in, which is that many of us were forced to

26
00:01:48,360 --> 00:01:52,080
spend more time at home and with family.

27
00:01:52,120 --> 00:01:57,640
And so very quickly, you might have also found that you have more time on your hand and what

28
00:01:57,640 --> 00:01:59,040
should be done with it.

29
00:01:59,040 --> 00:02:04,200
Well, for me, that meant trying to keep connected with other scientists.

30
00:02:04,200 --> 00:02:05,880
And I felt I wasn't the only one.

31
00:02:05,880 --> 00:02:11,840
So what happened was that one more on YouTube channels popped up where scientists were inviting

32
00:02:11,840 --> 00:02:13,480
each other to Zoom talks.

33
00:02:13,480 --> 00:02:18,040
And rather than just doing that over a closed Zoom setting where you needed to have a password,

34
00:02:18,040 --> 00:02:23,160
they would stream that live on YouTube and other scientists could come in.

35
00:02:23,160 --> 00:02:26,600
And so these are three YouTube channels that I just want to point out that I basically

36
00:02:26,600 --> 00:02:28,200
became addicted to.

37
00:02:28,200 --> 00:02:30,920
And they launched me into what I'm talking to you guys today.

38
00:02:30,920 --> 00:02:35,080
So I'm advertising for you guys to use your spare time, use the time before you fall asleep,

39
00:02:35,080 --> 00:02:37,840
go on YouTube, find these channels that they're rapidly growing.

40
00:02:37,840 --> 00:02:42,600
And I think they're revolutionizing science because that allows you to find topics that

41
00:02:42,600 --> 00:02:46,680
you are really interested in, find the other four people on the planet that equally interested

42
00:02:46,680 --> 00:02:49,560
in that and have a rapidly evolving field.

43
00:02:49,560 --> 00:02:52,760
So huge advantages to do this kind of approach.

44
00:02:52,760 --> 00:02:55,280
And so I'm not just talking theory here.

45
00:02:55,280 --> 00:02:59,520
What these three channels have in common is largely what I will talk about today has already

46
00:02:59,520 --> 00:03:01,280
spurred a lot of things into action.

47
00:03:01,280 --> 00:03:07,560
So this society, the Association for the Mathematical Consciousness Science, just got founded about

48
00:03:07,560 --> 00:03:13,040
a month or two ago because of these YouTube channels, out of these YouTube channels.

49
00:03:13,040 --> 00:03:18,120
And that society immediately sprung into action, launched special issues at frontiers

50
00:03:18,120 --> 00:03:20,040
and a journal called Entropy.

51
00:03:20,040 --> 00:03:23,840
It's got funding from various sources and there will be a conference two weeks from

52
00:03:23,840 --> 00:03:28,000
now where many of us are coming together virtually and will speak and next year it's expected

53
00:03:28,000 --> 00:03:29,240
to be in person.

54
00:03:29,240 --> 00:03:33,880
So it really is, I think, a shift here that might have happened throughout the pandemic

55
00:03:33,880 --> 00:03:38,120
for science to become more international, to become more collaborative and for communities

56
00:03:38,120 --> 00:03:41,760
to grow within science around the globe.

57
00:03:41,760 --> 00:03:44,040
So what is this particular community interested in?

58
00:03:44,040 --> 00:03:50,000
Well, some of us might be interested in that as well, which is the basic problem that faces

59
00:03:50,000 --> 00:03:52,840
neuroscience, maybe one of the biggest problems of neuroscience, maybe one of the biggest

60
00:03:52,840 --> 00:03:55,320
problems in science at all.

61
00:03:55,320 --> 00:03:59,480
Which is that we all believe as neuroscientists that there's a causal connection between neuronal

62
00:03:59,480 --> 00:04:05,600
activity in our brain and our conscious experience, our perception of the world, that the fact

63
00:04:05,600 --> 00:04:09,880
that we feel love, that we see colors, the fact that as you fall into deep sleep the

64
00:04:09,880 --> 00:04:11,400
world goes away for you.

65
00:04:11,400 --> 00:04:17,120
If you wouldn't exist, but as you come out into dream sleep or back as you wake up the

66
00:04:17,120 --> 00:04:18,520
world comes back for you.

67
00:04:18,520 --> 00:04:24,240
So I will call this phenomenology, the fact that you subjectively experience.

68
00:04:24,240 --> 00:04:27,760
But the embarrassing fact for neuroscience is that this hasn't worked yet.

69
00:04:27,760 --> 00:04:33,080
So usually what we do as scientists is that we find the causal connection and then mathematically

70
00:04:33,080 --> 00:04:34,600
reduce one onto the other.

71
00:04:34,600 --> 00:04:35,920
And that's when we say we understood it.

72
00:04:35,920 --> 00:04:39,000
That's what we do in physics, that's what we do in chemistry, biology and a lot of

73
00:04:39,000 --> 00:04:40,000
neuroscience.

74
00:04:40,000 --> 00:04:46,000
But for this part of our being, the phenomenology, the fact that we have subjective experience,

75
00:04:46,000 --> 00:04:48,160
this step seems to be hard to reach.

76
00:04:48,160 --> 00:04:52,480
In fact, there are many people that would argue that this is fundamentally impossible,

77
00:04:52,480 --> 00:04:54,920
that we will never be able to do that as scientists.

78
00:04:54,920 --> 00:04:55,920
You shouldn't even try.

79
00:04:55,920 --> 00:04:58,000
Well, I'm going to argue to the contrary.

80
00:04:58,000 --> 00:05:01,720
And that is what a lot of these YouTube channels inspired me to do.

81
00:05:01,720 --> 00:05:04,560
So this is a slide from one of the labs that's involved.

82
00:05:04,560 --> 00:05:09,360
So what they're suggesting is that we have to move away from this conventional approach

83
00:05:09,360 --> 00:05:15,000
of neuroscience of correlating inputs to the brain with activity in the brain or behavior

84
00:05:15,000 --> 00:05:21,440
or perception comes out of it, and to take another step that links, in this case, phenomenology,

85
00:05:21,440 --> 00:05:25,600
our subjective experience of consciousness, conscious perception, with brain activity

86
00:05:25,600 --> 00:05:26,600
via math.

87
00:05:26,600 --> 00:05:29,120
What do I mean by via math?

88
00:05:29,120 --> 00:05:33,520
Well, if we believe that consciousness can be explained in terms of science, what we

89
00:05:33,560 --> 00:05:37,800
have accomplished as scientists, what all of scientists rests on is that we find laws

90
00:05:37,800 --> 00:05:44,120
of nature that were able to express these laws of nature with mathematical formalism,

91
00:05:44,120 --> 00:05:49,520
gravity, Maxwellian equations, you name it, that's when we feel as scientists we've actually

92
00:05:49,520 --> 00:05:50,520
had an accomplishment.

93
00:05:50,520 --> 00:05:51,520
We've actually done it.

94
00:05:51,520 --> 00:05:53,640
So can we do that for consciousness?

95
00:05:53,640 --> 00:05:57,000
And so there's a pathway mapped out, and that's what I want to share with you guys today.

96
00:05:57,000 --> 00:05:58,800
Well, so what's the traditional approach?

97
00:05:58,800 --> 00:06:02,720
So the traditional approach, as a lot of you are familiar with, started obviously with

98
00:06:02,760 --> 00:06:07,360
experimental psychology, but I would argue that experimental psychology, people like

99
00:06:07,360 --> 00:06:13,400
Wundt and others, they were still careful to touch on this subjective consciousness

100
00:06:13,400 --> 00:06:14,400
experience side.

101
00:06:14,400 --> 00:06:19,280
And the first people who made a bold inroad into that was Fechner, together with his

102
00:06:19,280 --> 00:06:20,280
mentor, Vibar.

103
00:06:20,280 --> 00:06:23,640
And so they found a technique, and I'm not going to elaborate too much about it, to

104
00:06:23,640 --> 00:06:26,680
quantify subjective experience.

105
00:06:26,680 --> 00:06:31,080
So to go away from saying you can't measure love, to say I know exactly for love is twice

106
00:06:31,080 --> 00:06:32,280
as much as true love.

107
00:06:32,280 --> 00:06:33,280
And we can measure that.

108
00:06:33,280 --> 00:06:36,480
A lot of you are doing that all the time in the laboratories objectively, and we can

109
00:06:36,480 --> 00:06:41,240
come up with mathematical equations to express these laws.

110
00:06:41,240 --> 00:06:46,600
A little bit later in the 1960s, this was generalized by Stevens by basically introducing

111
00:06:46,600 --> 00:06:51,160
two more techniques that were done by the original inventors of psychophysics, and then

112
00:06:51,160 --> 00:06:54,400
finding a generalization of the mathematical laws that we have.

113
00:06:54,400 --> 00:06:57,000
And then it seemed that we're getting stuck.

114
00:06:57,000 --> 00:06:58,400
And so what might be that next step?

115
00:06:58,400 --> 00:07:02,040
Well, what I'm going to argue about today has many names because it's a new mushrooming

116
00:07:02,040 --> 00:07:05,680
field, but one of them I will use a lot is qualia structuralism.

117
00:07:05,680 --> 00:07:11,000
And the idea is that we can mathematically express our conscious experience of phenomenology

118
00:07:11,000 --> 00:07:15,840
and then find mathematical laws, how that maps onto similar abstract geometrical mathematical

119
00:07:15,840 --> 00:07:17,680
spaces derived from neural data.

120
00:07:17,680 --> 00:07:19,120
That's the basic idea.

121
00:07:19,120 --> 00:07:22,920
Now the first thing that we'll have to do there is we'll have to find the structure

122
00:07:22,920 --> 00:07:23,920
of qualia.

123
00:07:23,920 --> 00:07:27,880
And qualia is a philosophical fancy term for your experience.

124
00:07:28,120 --> 00:07:33,800
So I took this here from a paper by Jennifer Troublat, who has done pioneering research

125
00:07:33,800 --> 00:07:34,800
into that.

126
00:07:34,800 --> 00:07:39,560
And I put it on here because this paper shows that when it comes to these spaces that might

127
00:07:39,560 --> 00:07:45,360
describe our perceptual phenomenological subjective experience, they are non-trivial.

128
00:07:45,360 --> 00:07:49,920
So what Jennifer showed and reviewed in this paper is that these spaces might be non-euclidean,

129
00:07:49,920 --> 00:07:54,200
that certain things that you think are more similar and they move closer to space.

130
00:07:54,200 --> 00:07:57,280
If you look at them from a different angle, all of a sudden they seem to be wider apart.

131
00:07:57,320 --> 00:08:03,080
So it might take more unconventional math, such as quantum, then from quantum theory

132
00:08:03,080 --> 00:08:07,000
and some of the math I'll talk about today to bridge this gap and to describe these things.

133
00:08:07,000 --> 00:08:11,920
But it is, of course, for many of us that study perception, not news that we can express

134
00:08:11,920 --> 00:08:14,760
phenomenological experience in terms of geometrical spaces.

135
00:08:14,760 --> 00:08:19,000
So this right here is the color space that most of us are familiar with, that all of

136
00:08:19,000 --> 00:08:22,560
the colors that we can see, we can put in a three-dimensional space and map onto what

137
00:08:22,560 --> 00:08:24,600
might be largely looking as a sphere.

138
00:08:24,600 --> 00:08:29,720
If you're interested in music, there's a similar geometrical description of the phenomenological

139
00:08:29,720 --> 00:08:35,440
space that you hear in music, which is that if you have a note and you go up an octave,

140
00:08:35,440 --> 00:08:38,960
the note clearly is a higher note, but at the same time there's similarity with the original

141
00:08:38,960 --> 00:08:39,960
note.

142
00:08:39,960 --> 00:08:42,640
And if you do this with all of these notes, you end up with a helical three-dimensional

143
00:08:42,640 --> 00:08:43,720
structure.

144
00:08:43,720 --> 00:08:48,840
And more recently, face space is an example of multi-dimensional spaces that people have

145
00:08:48,840 --> 00:08:54,560
come up with for objects, for faces, for other structures of our experience and mapping them

146
00:08:54,560 --> 00:08:57,200
into these geometrical mathematical spaces.

147
00:08:57,200 --> 00:09:02,080
So if we accept this, that we can come up with mathematical descriptions of a phenomenological

148
00:09:02,080 --> 00:09:05,040
space, then what's the next step to go to the brain?

149
00:09:05,040 --> 00:09:10,440
So this is the suggestion of qualia structuralism, that let's say you have a chord and you have

150
00:09:10,440 --> 00:09:14,960
another chord where you move one of the notes, it sounds similar, it also sounds different,

151
00:09:14,960 --> 00:09:19,680
and that's because it would basically be a transform within that helical musical space

152
00:09:19,680 --> 00:09:22,440
from one of these loops to another.

153
00:09:22,440 --> 00:09:40,640
So if I play an example for that, let's see if this works.

154
00:09:40,640 --> 00:09:44,360
Pretty much the same song, but all I did here is transpose by an octave.

155
00:09:44,360 --> 00:09:48,760
So you were listening to the same structure, I just moved it down in this three-dimensional

156
00:09:48,760 --> 00:09:50,080
helical space.

157
00:09:50,080 --> 00:09:54,760
So the proposal is that if we derive neural activity from the brain and we come up with

158
00:09:54,760 --> 00:09:59,360
a similar mathematically-formalized abstract structure of neural activity, we should see

159
00:09:59,360 --> 00:10:05,280
some kind of relationship as we are experiencing one of these songs and the other song that

160
00:10:05,280 --> 00:10:08,440
might resemble in some way what the phenomenological space does.

161
00:10:08,440 --> 00:10:13,320
So now, in fact, and me in this case as a co-author, we were suggesting that there may

162
00:10:13,320 --> 00:10:17,960
be an isomorphism, that you would find a similar kind of transformation in these space, in

163
00:10:17,960 --> 00:10:23,480
these abstract spaces, but there's many ways, I'm sorry about playing the song again, there's

164
00:10:23,480 --> 00:10:27,680
many different ways that these spaces could relate, and I'm just, I'm not going too much

165
00:10:27,680 --> 00:10:31,840
into depth here, but category theory is a relatively new branch of mathematics, so there's

166
00:10:31,840 --> 00:10:35,800
a lot of buzz around it, and that is exactly what category theory is trying to do.

167
00:10:35,800 --> 00:10:39,720
It's taking different mathematical structures, in this case here you can see geometry and

168
00:10:39,720 --> 00:10:42,680
algebra, and trying to find the relations between them.

169
00:10:42,680 --> 00:10:46,160
And these relations, they can be mathematically expressed, we call punctors.

170
00:10:46,160 --> 00:10:50,840
So in the end, what we're trying to do is we try to find a functor between the abstracted

171
00:10:50,840 --> 00:10:57,000
brain activity and the mathematically-formalized phenomenological structure to translate between

172
00:10:57,000 --> 00:10:58,000
them.

173
00:10:58,000 --> 00:10:59,800
This could be isomorphism, this could be something else.

174
00:10:59,800 --> 00:11:04,800
Well, I hope I convinced you that this part here is a fruitful research program and already

175
00:11:04,800 --> 00:11:08,920
underway, and you might agree with me with this, but you might have doubts about this

176
00:11:08,920 --> 00:11:09,920
one.

177
00:11:09,920 --> 00:11:14,200
So how do we get to these structures from brain activity that would allow us to find

178
00:11:14,200 --> 00:11:18,960
some kind of mapping between the structure-ized qualia space and neuronal space?

179
00:11:18,960 --> 00:11:19,960
Yes?

180
00:11:19,960 --> 00:11:20,960
Yes?

181
00:11:20,960 --> 00:11:21,960
Yes.

182
00:11:21,960 --> 00:11:22,960
Yes.

183
00:11:22,960 --> 00:11:32,400
So what I'm saying, so most of them are correlative, and so what I would go to now is that I'm

184
00:11:32,400 --> 00:11:37,440
trying to find rather than a Pearson correlation, what I'm trying to go at is something that's

185
00:11:37,440 --> 00:11:42,840
actually more like a mathematical law of nature, and I don't want to go too much into the

186
00:11:42,840 --> 00:11:47,320
problems that correlational approaches have, but what I'm going to back to in the next

187
00:11:47,320 --> 00:11:52,000
couple of slides is that we're trying to get something that's deeper in terms of breaking

188
00:11:52,000 --> 00:11:57,600
correlation into causal structures, and that might allow us to make that look more directly.

189
00:11:57,600 --> 00:12:02,000
So am I not convinced yet, but maybe at the end of the talk we can talk about it?

190
00:12:02,000 --> 00:12:06,400
Well, okay, some of the ones that I think about are, but maybe we should talk more about

191
00:12:06,400 --> 00:12:08,240
that talk.

192
00:12:08,240 --> 00:12:15,520
So the theory that, again, I'm just using here to make that leap is integrated information

193
00:12:15,520 --> 00:12:19,440
theory by Giulia Tornoni, and there's a lot to say about integrated information theory.

194
00:12:19,440 --> 00:12:22,400
It's a very complex theory that's truly interdisciplinary.

195
00:12:22,400 --> 00:12:29,320
It spends a lot of different branches of how we usually divvy up our thinking and academia,

196
00:12:29,320 --> 00:12:34,720
so I'm not going to talk too much about it in terms of what the background is and explaining

197
00:12:34,720 --> 00:12:35,720
it.

198
00:12:35,720 --> 00:12:39,320
I think that would be at least another lecture if not a whole graduate seminar of a whole

199
00:12:39,320 --> 00:12:44,200
semester, but I will give you some of the ideas of integrated information theory.

200
00:12:44,200 --> 00:12:50,240
The first one is that if we think about consciousness, typically this is a consensus diagram that

201
00:12:50,240 --> 00:12:53,760
has made around that last couple of years, which is that consciousness seems to be at

202
00:12:53,760 --> 00:12:59,080
least two-dimensional, and that there's one axis, which we would call the level of consciousness,

203
00:12:59,080 --> 00:13:00,560
how much you're conscious.

204
00:13:00,560 --> 00:13:04,440
You might want to call it arousal or something related, and then the other one is the content

205
00:13:04,440 --> 00:13:09,200
of consciousness, which is how much you experience, what you experience, the qualia.

206
00:13:09,200 --> 00:13:13,360
The reason that we think it's at least a two-dimensional state is that we can take various states of

207
00:13:13,360 --> 00:13:17,400
consciousness and put them within this two-dimensional plane, and then you'll find, for example,

208
00:13:17,400 --> 00:13:22,480
that vegetative state is a state of coma where people clearly have a different level

209
00:13:22,480 --> 00:13:26,000
of consciousness, a different arousal, so they wake up in the morning, they open their

210
00:13:26,000 --> 00:13:30,520
eyes, they go to sleep at night, but there's no sign of actual conscious experience in

211
00:13:30,520 --> 00:13:33,520
a lot of these patients, so there's almost no content, but there's a lot of changes

212
00:13:33,520 --> 00:13:34,520
in arousal.

213
00:13:34,520 --> 00:13:38,120
That means we can dissociate these two parts of consciousness, and they're probably orthogonal,

214
00:13:38,120 --> 00:13:39,640
as I put them right here.

215
00:13:39,640 --> 00:13:44,200
Now, for understanding consciousness, I think the really interesting case is up here, where

216
00:13:44,200 --> 00:13:49,400
you are highly aroused and you have a lot of content, as I hope in a state that you're

217
00:13:49,400 --> 00:13:50,960
still in right now.

218
00:13:50,960 --> 00:13:55,320
I'd probably get you more to this state as I keep talking on, but in this state, what

219
00:13:55,320 --> 00:14:01,040
I'm arguing is that you still don't fully have all the access to what consciousness

220
00:14:01,040 --> 00:14:02,040
is doing.

221
00:14:02,080 --> 00:14:04,120
So the example for that would be over here.

222
00:14:04,120 --> 00:14:07,760
If you read this really fast, you would say, oh, I read a bird in the bush, and if I say,

223
00:14:07,760 --> 00:14:11,320
well, try again, you would say, oh, wait a minute, it says a bird in the bush, but the

224
00:14:11,320 --> 00:14:14,760
first time you see that, you probably didn't see the second the.

225
00:14:14,760 --> 00:14:19,840
So that's a famous example of repetition blindness, so that means that even if you're up here

226
00:14:19,840 --> 00:14:25,480
and you have the highest level of consciousness, there are still parts of the world that are

227
00:14:25,480 --> 00:14:30,000
closed up to you that you fail to experience.

228
00:14:30,080 --> 00:14:31,520
When I put it out, you can actually experience.

229
00:14:31,520 --> 00:14:32,040
Yes, question.

230
00:14:49,440 --> 00:14:52,360
Yeah, so I would argue it would be more to this.

231
00:14:52,360 --> 00:14:55,280
It doesn't go without a traditional notion of subjective experience.

232
00:14:55,280 --> 00:14:55,440
Right.

233
00:14:55,440 --> 00:15:02,640
So you have a living being that's undergoing all the signs of arousal, but it doesn't have

234
00:15:02,640 --> 00:15:04,040
any delight to offer.

235
00:15:04,040 --> 00:15:06,200
There's no subjective experience.

236
00:15:06,200 --> 00:15:09,880
That person would be conscious in this definition, but not in this definition.

237
00:15:09,880 --> 00:15:15,520
And that has led to a lot of debate in the field, because there's been a lot of confusion

238
00:15:15,520 --> 00:15:16,840
misunderstanding about it.

239
00:15:16,840 --> 00:15:21,880
So you can have, if you do anesthesia, for example, for more than 24 hours, so some of

240
00:15:21,960 --> 00:15:25,640
us do, they know that the animal gets more aroused in the morning and you have to increase

241
00:15:25,640 --> 00:15:29,720
the anesthesia, but we don't think that the animal is having any subjective experience,

242
00:15:29,720 --> 00:15:31,160
but it's a sign of arousal.

243
00:15:31,160 --> 00:15:36,240
So other people that would say, well, if you're a Buddhist Zen monk and you can reach a state

244
00:15:36,240 --> 00:15:40,240
of consciousness without content, if you really look into the phenomenology of that, there

245
00:15:40,240 --> 00:15:42,760
would still be some content because there is subjective experience, right?

246
00:15:42,760 --> 00:15:44,360
So I'm not talking about that.

247
00:15:44,360 --> 00:15:48,920
So I'm really dissociating basically the almost behavioral signs of arousal from actual subjective

248
00:15:48,920 --> 00:15:49,920
experience.

249
00:15:49,920 --> 00:15:50,920
That's my definition, though.

250
00:15:50,920 --> 00:15:51,920
This might seem different.

251
00:15:51,920 --> 00:15:52,920
Does it make sense?

252
00:15:52,920 --> 00:15:56,360
Yeah, we can talk about that after the talk.

253
00:15:56,360 --> 00:16:00,320
So luckily, this is the part that we're probably in agreement in that I'm most interested

254
00:16:00,320 --> 00:16:01,320
in.

255
00:16:01,320 --> 00:16:05,400
So what integrated information theory does, and that is what it's mostly known for, is

256
00:16:05,400 --> 00:16:09,360
to quantify this axis of consciousness space.

257
00:16:09,360 --> 00:16:13,880
So what integrated information theory does, it gives you a scalar, a single value, and

258
00:16:13,880 --> 00:16:19,600
it tells you how much the system has in terms of level of consciousness.

259
00:16:20,600 --> 00:16:25,000
Lesson well-known is that this orthogonal dimension is also explained by integrated

260
00:16:25,000 --> 00:16:27,320
information theory, and I put this down here.

261
00:16:27,320 --> 00:16:31,240
So when you had this first experience of a bird in the bush, and you missed the second

262
00:16:31,240 --> 00:16:36,240
the, versus you had this experience of a bird in the bush, there was no change in the world.

263
00:16:36,240 --> 00:16:38,680
There was just a change in your mental state.

264
00:16:38,680 --> 00:16:42,840
So that means you had two phenomenological states, and that difference is also quantified

265
00:16:42,840 --> 00:16:48,360
by integrated information theory as a difference in the causal effect structure, or the short,

266
00:16:48,360 --> 00:16:50,200
I will call this the CES.

267
00:16:50,200 --> 00:16:54,320
So there's a delta phi, which is what IET is known for, that shows you the levels of

268
00:16:54,320 --> 00:16:58,400
consciousness, and then a delta CES, which shows you the difference in the contents of

269
00:16:58,400 --> 00:16:59,400
consciousness.

270
00:16:59,400 --> 00:17:00,400
Yes.

271
00:17:00,400 --> 00:17:07,280
Are you saying one of those is more content than the other?

272
00:17:07,280 --> 00:17:08,280
It's different.

273
00:17:08,280 --> 00:17:13,840
Well, I see that, but it's like interesting to figure out your axis of content here, because...

274
00:17:13,840 --> 00:17:17,520
Yeah, so in this particular example, I would say that you have more content when you are

275
00:17:17,680 --> 00:17:20,520
aware of the second the, because you see an extra the.

276
00:17:20,520 --> 00:17:21,520
But that seems questionable, right?

277
00:17:21,520 --> 00:17:25,520
Because in one case, you're paying attention to the meaning, and there's a whole lot of

278
00:17:25,520 --> 00:17:26,520
certain kind of processing.

279
00:17:26,520 --> 00:17:30,520
Whereas in the other case, you're paying attention to something very superficial that may not

280
00:17:30,520 --> 00:17:31,520
be important.

281
00:17:31,520 --> 00:17:35,520
So, and then I might pay attention to the fact that some letters touch the triangle there,

282
00:17:35,520 --> 00:17:38,520
and then I'm aware of that, and I, is that important?

283
00:17:38,520 --> 00:17:39,520
But that's more.

284
00:17:39,520 --> 00:17:40,520
So I...

285
00:17:40,520 --> 00:17:41,520
That's a fair point.

286
00:17:41,520 --> 00:17:46,520
I mean, for me as a vision scientist, just from the visual perspective, I would say you

287
00:17:46,520 --> 00:17:48,520
have more content here than you have here.

288
00:17:48,520 --> 00:17:51,520
But in fact, I'm not...

289
00:17:51,520 --> 00:17:55,520
I don't want to make too much of a point of quantification here, when it comes to the

290
00:17:55,520 --> 00:18:01,520
difference in phenomenology, more that we can look at the difference between two phenomenological

291
00:18:01,520 --> 00:18:02,520
states.

292
00:18:02,520 --> 00:18:07,520
It might be equally content rich, but the fact that there is a difference, we can quantify

293
00:18:07,520 --> 00:18:08,520
the difference.

294
00:18:08,520 --> 00:18:11,520
So that doesn't mean that one, that there has to be an unequal sign between those.

295
00:18:11,520 --> 00:18:12,520
Does that make sense?

296
00:18:12,520 --> 00:18:13,520
Okay.

297
00:18:14,520 --> 00:18:15,520
Yeah.

298
00:18:30,520 --> 00:18:34,520
So let's try and maybe move away from the concept of amount of content.

299
00:18:34,520 --> 00:18:35,520
Okay.

300
00:18:35,520 --> 00:18:39,520
Just the fact that there's different contents, that there's different states of consciousness

301
00:18:39,520 --> 00:18:40,520
that you're in.

302
00:18:41,520 --> 00:18:44,520
They can be formalized in IIT.

303
00:18:44,520 --> 00:18:45,520
Okay.

304
00:18:45,520 --> 00:18:50,520
And so that's all I'm getting at, that there's two formally different states, mathematically

305
00:18:50,520 --> 00:18:51,520
different states.

306
00:18:51,520 --> 00:18:54,520
So let's make it less about the amount, but just the fact that there's a difference and

307
00:18:54,520 --> 00:18:57,520
we can mathematically get at it.

308
00:18:57,520 --> 00:19:03,520
And so just to give you an idea, so these are not just abstract ideas.

309
00:19:03,520 --> 00:19:06,520
There's actual mathematical formalism associated with that.

310
00:19:06,520 --> 00:19:10,520
And so this is from a paper that I will talk about a little bit more about today, where

311
00:19:10,520 --> 00:19:15,520
now and his colleagues, they took neural data, in this case from a fruit fly.

312
00:19:15,520 --> 00:19:20,520
The fruit fly had multiple neurons in its mushroom body, which would be equivalent to

313
00:19:20,520 --> 00:19:21,520
what we call a brain.

314
00:19:21,520 --> 00:19:26,520
And then they measured Phi, which is the level of consciousness between awake and anesthetized

315
00:19:26,520 --> 00:19:27,520
fruit flies.

316
00:19:27,520 --> 00:19:32,520
And you can see that the theory made the correct prediction, which is that Phi should be smaller

317
00:19:32,520 --> 00:19:36,520
in an anesthetized animal than in an alert animal.

318
00:19:36,520 --> 00:19:43,520
This right here corresponds to that in that they tried to get at this causal effect structure.

319
00:19:43,520 --> 00:19:48,520
Now, back when they did that study, the mathematical formalism for the causal effect structure wasn't

320
00:19:48,520 --> 00:19:49,520
fully developed yet.

321
00:19:49,520 --> 00:19:52,520
So that's one of the things I'm saying this is really cutting edge what I'm telling you

322
00:19:52,520 --> 00:19:58,520
today, but they were trying to get at that by coming up with a geometric space that puts

323
00:19:58,520 --> 00:20:03,520
the neural data of the various causes and effects that you find across the neural data

324
00:20:03,520 --> 00:20:07,520
into a multi-dimensional space, in this case, broken down to a three-dimensional space.

325
00:20:07,520 --> 00:20:11,520
And you can see that there's a difference in the causal effect structure as well.

326
00:20:11,520 --> 00:20:12,520
So note the date.

327
00:20:12,520 --> 00:20:16,520
This is really a cutting edge publication.

328
00:20:16,520 --> 00:20:19,520
So what I will show you today is that I think we can go a step further.

329
00:20:19,520 --> 00:20:21,520
So how does this come about?

330
00:20:21,520 --> 00:20:26,520
Well, at the very heart of integrated information theory is this idea that if you have an interconnected

331
00:20:26,520 --> 00:20:33,520
system in which information flows with causal effectivity, let's say that you have four neurons

332
00:20:33,520 --> 00:20:37,520
and they're interconnected in this way and you see the causal flow between these neurons,

333
00:20:37,520 --> 00:20:43,520
that if you can find out about these causal effects by severing some of these connections

334
00:20:43,520 --> 00:20:47,520
and you can do that either experimentally or you can do that.

335
00:20:47,520 --> 00:20:49,520
And this is the interesting part that I hopefully can show you guys today.

336
00:20:49,520 --> 00:20:53,520
You can do that computationally, analytically, with your own data.

337
00:20:53,520 --> 00:20:59,520
And once you do that, you compare the mutilated system where you severed some of these connections

338
00:20:59,520 --> 00:21:00,520
with your original system.

339
00:21:00,520 --> 00:21:04,520
And if there's any difference in the statistical description, then you know what you just mutilated

340
00:21:04,520 --> 00:21:06,520
had a causal effect.

341
00:21:06,520 --> 00:21:08,520
It actually was important for the system.

342
00:21:08,520 --> 00:21:11,520
So you changed the system by mutilating some of these connections.

343
00:21:11,520 --> 00:21:16,520
But if you mutilate some of these connections and there's no difference for the system as a whole,

344
00:21:16,520 --> 00:21:22,520
then you know that these were reducible connections that were actually not important for the function of the system.

345
00:21:22,520 --> 00:21:24,520
And this can be done mathematically.

346
00:21:24,520 --> 00:21:30,520
So this right here is some of the simplified formalism that goes with integrated information theory.

347
00:21:30,520 --> 00:21:35,520
This is when you put it into practice with Python computer code that has been available.

348
00:21:35,520 --> 00:21:38,520
Again, this is the paper that I just referenced from the fruit fly.

349
00:21:38,520 --> 00:21:42,520
And all I will do today is give you a little bit of an overview of what's going on here

350
00:21:42,520 --> 00:21:47,520
and then give you resources that if you are interested and you want to try it with your data,

351
00:21:47,520 --> 00:21:49,520
how you can do that for yourself.

352
00:21:50,520 --> 00:21:52,520
Okay, so why might this be interesting?

353
00:21:52,520 --> 00:21:56,520
Well, more and more what we are doing is when we're talking as neuroscientists,

354
00:21:56,520 --> 00:21:58,520
especially as cognitive neuroscientists,

355
00:21:58,520 --> 00:22:04,520
when we're thinking about the brain, we're thinking about it more and more as a causally connected network circuitry system.

356
00:22:04,520 --> 00:22:09,520
And we are, because of that, measuring more and more data simultaneously across the brain

357
00:22:09,520 --> 00:22:15,520
because the idea is that we just need to know more about what each of these individual parts is doing and how they interact.

358
00:22:15,520 --> 00:22:19,520
And there's two steps involved in that that I think are crucial.

359
00:22:19,520 --> 00:22:22,520
The first one is that rather than just looking at activation,

360
00:22:22,520 --> 00:22:26,520
what integrated information theory does is it abstracts it to information.

361
00:22:26,520 --> 00:22:28,520
And so why is that interesting?

362
00:22:28,520 --> 00:22:33,520
Well, activation is actually more confined than the flow of information.

363
00:22:33,520 --> 00:22:38,520
So if we have, let's say, three neurons here and three neurons here and they're connected with these three axons,

364
00:22:38,520 --> 00:22:43,520
what activation can do is cross over between these neurons, cross its path

365
00:22:43,520 --> 00:22:48,520
because activation has to flow along the physically hard-wired lines of an axon.

366
00:22:48,520 --> 00:22:56,520
But neurons, of course, are not as simple as these systems right here that just receive activation and pass it on.

367
00:22:56,520 --> 00:22:58,520
Neurons can act as logic gates.

368
00:22:58,520 --> 00:23:00,520
They can make, they can compute.

369
00:23:00,520 --> 00:23:05,520
So in this case, if I replace these neurons with X OR gates that are only active,

370
00:23:05,520 --> 00:23:08,520
depending on what the input state is,

371
00:23:08,520 --> 00:23:12,520
then you can see that information now can cross the system.

372
00:23:12,520 --> 00:23:17,520
So as the activation is confined with the physical connections, information flow is more fluid

373
00:23:17,520 --> 00:23:22,520
and actually can process the system in various ways that the activation per se can.

374
00:23:22,520 --> 00:23:28,520
So that's why abstracting from activation to information might be interesting for many of us

375
00:23:28,520 --> 00:23:30,520
in trying to understand what the brain is doing.

376
00:23:30,520 --> 00:23:36,520
The second issue with collecting all of these data simultaneously is that most of the techniques

377
00:23:36,520 --> 00:23:40,520
that we then use analytically to analyze these multidimensional data,

378
00:23:40,520 --> 00:23:42,520
so this would be in this example.

379
00:23:42,520 --> 00:23:46,520
And for Mariah, but the same gets done in EEG or in a singular physiology field,

380
00:23:46,520 --> 00:23:50,520
is that we're trying to get at the multidimensional of the data,

381
00:23:50,520 --> 00:23:54,520
but there's always a step in there that basically boils down to pairwise comparisons.

382
00:23:54,520 --> 00:23:57,520
Very often, Pearson's correlations. It's just a very powerful technique.

383
00:23:57,520 --> 00:24:01,520
So if we do ICA, if we do graph theory, if you look at the various steps involved,

384
00:24:01,520 --> 00:24:04,520
typically somewhere you find that there's pairwise comparisons.

385
00:24:04,520 --> 00:24:09,520
And I would argue that that's a limitation and I would argue that integrated information theory gets past that.

386
00:24:09,520 --> 00:24:10,520
So what do I mean?

387
00:24:10,520 --> 00:24:14,520
So let's take this very simple example of heavy learning that I took from one of the textbooks.

388
00:24:14,520 --> 00:24:19,520
So if you are taking a system of three neurons interconnected, so these neurons connect onto these neurons,

389
00:24:19,520 --> 00:24:24,520
and then you have weights, synaptic weights that you can scale up or down to come up with a learning rule.

390
00:24:24,520 --> 00:24:28,520
Well, in the conventional approach, you would look at this correlation and that correlation.

391
00:24:28,520 --> 00:24:32,520
You look at these pairwise correlations, you can make up a matrix and then make this examination.

392
00:24:32,520 --> 00:24:36,520
But what you're missing out on is the synergistic effect of these two neurons onto that neuron.

393
00:24:36,520 --> 00:24:40,520
So there could be a combined causal effect that you're missing by breaking up the system

394
00:24:40,520 --> 00:24:42,520
and just looking at the pairwise correlations.

395
00:24:42,520 --> 00:24:45,520
And so IIT doesn't do it. Why doesn't it do it?

396
00:24:45,520 --> 00:24:49,520
So here's an example of how the formalism of IIT works in practice.

397
00:24:49,520 --> 00:24:53,520
And the example is that you have a system with two buttons, A and B,

398
00:24:53,520 --> 00:24:58,520
and they basically have causal effects on, in this case, let's say another button C.

399
00:24:59,520 --> 00:25:06,520
So the idea is that we're looking at if button A and B are inactive.

400
00:25:06,520 --> 00:25:09,520
So in this case, shown here in white, so they're not being pushed.

401
00:25:09,520 --> 00:25:15,520
What does that mean for the state of this causally affected system C?

402
00:25:15,520 --> 00:25:21,520
And so you can empirically do that by just taking a system and looking at what's happening.

403
00:25:21,520 --> 00:25:25,520
So let's say you're taking many, many trials, as we often do 100 trials,

404
00:25:25,520 --> 00:25:29,520
and you see what happens if A and B are un-pushed and what happens to C.

405
00:25:29,520 --> 00:25:35,520
And so you see that in this case, in 90% of the cases, C would also be off,

406
00:25:35,520 --> 00:25:37,520
and in 10% of the cases, C would be on.

407
00:25:37,520 --> 00:25:43,520
So this could be because of noise, this could be because of a whole lot of different mechanisms.

408
00:25:43,520 --> 00:25:47,520
And then the logic is to just step through all of the possible states.

409
00:25:47,520 --> 00:25:52,520
So you ask what happens if A is pushed, and you can see 90% again C is off,

410
00:25:52,520 --> 00:25:54,520
what happens if B is pushed, and here the interesting case,

411
00:25:54,520 --> 00:25:56,520
what if both of them are pushed at the same time?

412
00:25:56,520 --> 00:26:00,520
And so this, of course, some of you might have noticed already,

413
00:26:00,520 --> 00:26:05,520
leads to a table that has been used in statistics for a long time.

414
00:26:05,520 --> 00:26:08,520
That's what we call a transition probability matrix,

415
00:26:08,520 --> 00:26:11,520
or it's at the very heart of Markov-Chakes, yes.

416
00:26:11,520 --> 00:26:28,520
So there's a few things to say about that.

417
00:26:28,520 --> 00:26:32,520
So first of all, this technique works best if you do know the causal structure.

418
00:26:32,520 --> 00:26:39,520
So if you know that these have this kind of causal effect on C,

419
00:26:39,520 --> 00:26:42,520
but you don't need to know that, you can infer the causal structure

420
00:26:42,520 --> 00:26:44,520
just by looking at the statistics of the system.

421
00:26:44,520 --> 00:26:45,520
So you don't need to know that.

422
00:26:45,520 --> 00:26:47,520
And so if one of them would have, let's say,

423
00:26:47,520 --> 00:26:49,520
if you said a positive effect or negative effect,

424
00:26:49,520 --> 00:26:52,520
it also, again, would show up in the statistics that you're measuring that comes out.

425
00:26:52,520 --> 00:26:56,520
So the real big step that I'm doing right here that's questionable

426
00:26:56,520 --> 00:27:01,520
is that I'm moving from a frequentist observation to a statistical description of the system.

427
00:27:01,520 --> 00:27:05,520
But of course, that's something that a lot of statistics us all the time.

428
00:27:05,520 --> 00:27:09,520
But I'm arguing that you could observe a system, come up with that table,

429
00:27:09,520 --> 00:27:13,520
and then go on to describe the system.

430
00:27:13,520 --> 00:27:16,520
Other questions?

431
00:27:16,520 --> 00:27:19,520
Okay, so if you're with me on this, then you would agree that you can, of course,

432
00:27:19,520 --> 00:27:21,520
do this for a much more complex system.

433
00:27:21,520 --> 00:27:25,520
So right here, this would be four logic elements that are interconnected.

434
00:27:25,520 --> 00:27:28,520
These could be neurons, these could be voxels, these could be areas,

435
00:27:28,520 --> 00:27:30,520
this could be whatever you're interested in.

436
00:27:30,520 --> 00:27:34,520
And one more trick that I'm doing here is that rather than looking at

437
00:27:34,520 --> 00:27:36,520
how three of these elements interact with the fourth element,

438
00:27:36,520 --> 00:27:38,520
I'm taking the whole system.

439
00:27:38,520 --> 00:27:41,520
So I'm taking all of the possible states that this system could be in.

440
00:27:41,520 --> 00:27:44,520
All of these are on, three of these are on, none of these are on.

441
00:27:44,520 --> 00:27:48,520
And then what I'm doing is I'm taking a step forward in time.

442
00:27:48,520 --> 00:27:52,520
So I will call this the present, and then I'm taking a step forward in time,

443
00:27:52,520 --> 00:27:54,520
and I say, if this is the present state,

444
00:27:54,520 --> 00:27:59,520
what is the probability that I end up in any of these other possible states?

445
00:27:59,520 --> 00:28:02,520
So this is how I get a true transition probability matrix.

446
00:28:02,520 --> 00:28:05,520
In this case, the numbers are zero and one stone at the confuse you,

447
00:28:05,520 --> 00:28:07,520
this would be a deterministic system.

448
00:28:07,520 --> 00:28:10,520
But what we would be measuring most of the time would be fractions in here.

449
00:28:10,520 --> 00:28:13,520
So it would be fractional probabilities with which the system transitions

450
00:28:13,520 --> 00:28:15,520
from one state into the other state.

451
00:28:15,520 --> 00:28:19,520
And so one simple notion would be that this right here is the cause,

452
00:28:19,520 --> 00:28:21,520
and then this right here is the effect,

453
00:28:21,520 --> 00:28:26,520
because we're looking at what is causing what effect by making the jump into the future.

454
00:28:26,520 --> 00:28:30,520
How far you move from the present into the future, that's again up to you.

455
00:28:30,520 --> 00:28:34,520
So you could take a millisecond, eight millisecond, one TR, whatever you want.

456
00:28:34,520 --> 00:28:39,520
But you can look at how the system, depending on which state it is in,

457
00:28:39,520 --> 00:28:41,520
transitions into any of these other states.

458
00:28:41,520 --> 00:28:43,520
Yes.

459
00:28:43,520 --> 00:28:47,520
Using a Markovian assumption here, doesn't that presume the box,

460
00:28:47,520 --> 00:28:50,520
or neurons are going to have a memory of its property?

461
00:28:50,520 --> 00:28:54,520
Neurons are not memory of its state.

462
00:28:54,520 --> 00:28:56,520
Yes, great.

463
00:28:56,520 --> 00:28:59,520
I don't know if I have time to talk about that, but yes.

464
00:28:59,520 --> 00:29:03,520
So this is one of the first things I ran into, looking at actual data.

465
00:29:03,520 --> 00:29:10,520
So as you will see, maybe as I get to that, my argument is that if there's a memory in the system,

466
00:29:10,520 --> 00:29:16,520
then there's a certain expectation to what the transition probability matrix should look like.

467
00:29:16,520 --> 00:29:19,520
And we can actually use that to our advantage.

468
00:29:19,520 --> 00:29:24,520
For example, we can see if there's anything that deviates just from a system

469
00:29:24,520 --> 00:29:27,520
that has a simple form of memory, or it doesn't.

470
00:29:28,520 --> 00:29:31,520
Another question.

471
00:29:31,520 --> 00:29:33,520
So this right here is not the end of it.

472
00:29:33,520 --> 00:29:36,520
So this right here is not what I really mean by cause-effect structures.

473
00:29:36,520 --> 00:29:40,520
There's a second mathematical trick that's involved where you can break down

474
00:29:40,520 --> 00:29:45,520
each of these supposed cause-effect interactions in your data

475
00:29:45,520 --> 00:29:47,520
to look at which ones are actually causal.

476
00:29:47,520 --> 00:29:49,520
And that's maybe the part that I'm most excited about.

477
00:29:49,520 --> 00:29:54,520
So if I do this for my data, it turns out that most of these do not actually really have cause-of-power.

478
00:29:54,520 --> 00:29:56,520
That's what I find the most interesting.

479
00:29:56,520 --> 00:30:00,520
But you might already have noticed that by doing this kind of trick with your data,

480
00:30:00,520 --> 00:30:03,520
that you're already coming up with something that is really interesting to deal with.

481
00:30:03,520 --> 00:30:06,520
So by just taking your data and putting it in this kind of space,

482
00:30:06,520 --> 00:30:09,520
you come up with these very nice mathematical properties already.

483
00:30:09,520 --> 00:30:13,520
And so in fact, if you think about almost anything that we do in machine learning or big data,

484
00:30:13,520 --> 00:30:17,520
starts out with NP arrays like that, two-dimensional matrices.

485
00:30:17,520 --> 00:30:21,520
So I would argue that even if you're not interested in consciousness,

486
00:30:21,520 --> 00:30:24,520
there's lots of room to explore here for your data by using this approach.

487
00:30:24,520 --> 00:30:25,520
Yes?

488
00:30:25,520 --> 00:30:30,520
So does this work only if you assume that you have all the elements in the system,

489
00:30:30,520 --> 00:30:33,520
but what if there are other elements you're not measuring now

490
00:30:33,520 --> 00:30:38,520
and they could also play a third variable role?

491
00:30:38,520 --> 00:30:39,520
Yes.

492
00:30:39,520 --> 00:30:40,520
So it's another shortcoming.

493
00:30:40,520 --> 00:30:41,520
I totally agree.

494
00:30:41,520 --> 00:30:45,520
So ideally, you would have to do this for all the neurons in the brain at the same time.

495
00:30:45,520 --> 00:30:46,520
And so that's a type dream.

496
00:30:46,520 --> 00:30:51,520
And in fact, as I was showing a moment, it already gets problematic with the data that we have.

497
00:30:51,520 --> 00:30:55,520
But I would argue that when we do a Fourier transform,

498
00:30:55,520 --> 00:30:59,520
in fact, even when we do a simple average, we are violating some of the rules

499
00:30:59,520 --> 00:31:00,520
that apply to these algorithms.

500
00:31:00,520 --> 00:31:03,520
So if you do a Fourier transform, you should never do that on one of our data,

501
00:31:03,520 --> 00:31:05,520
whether the variance and the mean are changing over time.

502
00:31:05,520 --> 00:31:06,520
It should be stationary.

503
00:31:06,520 --> 00:31:09,520
And people that do it, they would say, well, it still works.

504
00:31:09,520 --> 00:31:14,520
And so I would say that even if you have a system where you have confounders

505
00:31:14,520 --> 00:31:18,520
that might be interacting with this as more hidden Markov chains, whatever you want to call it,

506
00:31:18,520 --> 00:31:20,520
you don't have the entire Markov blanket.

507
00:31:20,520 --> 00:31:23,520
It's still interesting to look at that system by making these assumptions.

508
00:31:23,520 --> 00:31:25,520
Yeah, of course it's interesting.

509
00:31:25,520 --> 00:31:28,520
Because when can you jump to the causal input?

510
00:31:28,520 --> 00:31:29,520
Yes.

511
00:31:29,520 --> 00:31:34,520
And so basically, my appeal would be that you can do them,

512
00:31:34,520 --> 00:31:37,520
but you have to take them with a grain of salt.

513
00:31:37,520 --> 00:31:39,520
Kind of like we do already with greater causality and other things.

514
00:31:39,520 --> 00:31:45,520
But yeah, so there's an imperfect match between what the theory and theory provides you

515
00:31:45,520 --> 00:31:48,520
and then what we as experimentalists can do with it in practice.

516
00:31:48,520 --> 00:31:50,520
But as I just said, I think there's other techniques.

517
00:31:50,520 --> 00:31:52,520
Granger causality, I think is a good one.

518
00:31:52,520 --> 00:31:56,520
That we violate stationarity, which is one of its main assumptions all the time.

519
00:31:56,520 --> 00:31:58,520
And yet we found interesting things with Granger causality.

520
00:31:58,520 --> 00:32:00,520
And I'm just talking, there's a different way of doing that

521
00:32:00,520 --> 00:32:06,520
that goes away from pairwise considerations of causality to multi-dimensional ones.

522
00:32:06,520 --> 00:32:08,520
Great questions.

523
00:32:08,520 --> 00:32:10,520
Okay, so let's talk about actual data.

524
00:32:10,520 --> 00:32:14,520
So what my lab is mostly interested in are neural circuits.

525
00:32:14,520 --> 00:32:18,520
And the system that we've been choosing for that are the neural circuits

526
00:32:18,520 --> 00:32:21,520
that they of course have the property that Isabel just mentioned,

527
00:32:21,520 --> 00:32:24,520
that they do get inputs from outside the system,

528
00:32:24,520 --> 00:32:28,520
but they are well-structured circuits and they exist across the layers of cortex.

529
00:32:28,520 --> 00:32:30,520
And so one reason that they're interesting is that

530
00:32:30,520 --> 00:32:33,520
technology has made huge jumps in the last couple of years

531
00:32:33,520 --> 00:32:37,520
in order to allow us to measure neuronal activity across the layers of cortex.

532
00:32:37,520 --> 00:32:40,520
So this of course is a commercial approach to that,

533
00:32:40,520 --> 00:32:45,520
but some people don't know yet that these kinds of electrodes that Elon Musk is using

534
00:32:45,520 --> 00:32:48,520
for his company, they're actually readily available down in my office

535
00:32:48,520 --> 00:32:50,520
if you want to see them to research scientists.

536
00:32:50,520 --> 00:32:53,520
So Elon of course is trying to do this in humans.

537
00:32:53,520 --> 00:32:55,520
What does Elon have to say?

538
00:32:55,520 --> 00:32:58,520
Electrons in human brains are the future.

539
00:32:58,520 --> 00:33:00,520
You might get one some time as well.

540
00:33:00,520 --> 00:33:03,520
So thanks to the fact of machine learning we can do these things.

541
00:33:03,520 --> 00:33:06,520
But we use these kinds of electrodes.

542
00:33:06,520 --> 00:33:08,520
So silence, Elon.

543
00:33:08,520 --> 00:33:11,520
We use these kinds of electrodes to measure along the layers of cortex

544
00:33:11,520 --> 00:33:15,520
to get at what we think is a cortical column in the system.

545
00:33:15,520 --> 00:33:19,520
And then we have these simultaneous measurements of neurons or population activity,

546
00:33:19,520 --> 00:33:23,520
and so I'm trying to get to the causal effect structure of these.

547
00:33:23,520 --> 00:33:26,520
So here's the first bad news.

548
00:33:26,520 --> 00:33:29,520
So if you take this again could be voxels or areas,

549
00:33:29,520 --> 00:33:32,520
in this case it's electrode channels of these arrays where we can make these measurements,

550
00:33:32,520 --> 00:33:35,520
and you look at the size of the transition probability matrix,

551
00:33:35,520 --> 00:33:38,520
of course you run into a combinatorial explosion.

552
00:33:38,520 --> 00:33:41,520
So for most of what I will show today I will be stuck at six channels

553
00:33:41,520 --> 00:33:43,520
because my laptop got stuck at six channels.

554
00:33:43,520 --> 00:33:47,520
So if we go up to electrodes that my lab has been using ten years ago,

555
00:33:47,520 --> 00:33:52,520
you already get to numbers that are twice as large as the number of atoms in a cell.

556
00:33:52,520 --> 00:33:56,520
And then this right here is what my lab will be using hopefully in a week from now

557
00:33:56,520 --> 00:34:01,520
and you can see that we're reaching numbers that are absolutely beyond astronomical.

558
00:34:01,520 --> 00:34:06,520
Again, I feel at first when I hear these limitations of the theory

559
00:34:06,520 --> 00:34:09,520
I feel at first maybe a little bit depressed or discouraged,

560
00:34:09,520 --> 00:34:13,520
but then you go and you watch some YouTube talks again about quantum computing

561
00:34:13,520 --> 00:34:15,520
and the leaps that are being done there,

562
00:34:15,520 --> 00:34:17,520
and I think that these kinds of problems are technical problems.

563
00:34:17,520 --> 00:34:20,520
I think that they're solvable in the long run.

564
00:34:20,520 --> 00:34:25,520
There are 10 to the 80 atoms in the universe.

565
00:34:25,520 --> 00:34:27,520
Yeah, I know there's a way more...

566
00:34:27,520 --> 00:34:30,520
The magnitude more than there are atoms in the universe.

567
00:34:31,520 --> 00:34:34,520
This is just one electrode with two other channels.

568
00:34:34,520 --> 00:34:36,520
So when we're talking about measuring all the neurons in the brain,

569
00:34:36,520 --> 00:34:39,520
you see where the theory runs into serious problems.

570
00:34:39,520 --> 00:34:42,520
But as I said, I think these are technical limitations

571
00:34:42,520 --> 00:34:46,520
and also there's other ways to dimensionality reduce

572
00:34:46,520 --> 00:34:48,520
before you maybe apply the theory.

573
00:34:48,520 --> 00:34:51,520
So let's use six measurements of the brain simultaneously

574
00:34:51,520 --> 00:34:54,520
and I will use this graphic to show you all the 64 states

575
00:34:54,520 --> 00:34:56,520
that are possible for these six measurements.

576
00:34:56,520 --> 00:34:58,520
So all of them on, all of them off.

577
00:34:58,520 --> 00:35:02,520
So if these are neurons, on or off is easy to understand.

578
00:35:02,520 --> 00:35:05,520
This might be a neuron firing an action potential, not an action potential.

579
00:35:05,520 --> 00:35:09,520
But most of us, we're not using neurons, I'm not using neurons here.

580
00:35:09,520 --> 00:35:12,520
So what I'm doing is I'm basically binarizing the data.

581
00:35:12,520 --> 00:35:14,520
So you can just take your data, take a trial,

582
00:35:14,520 --> 00:35:16,520
you take the average activity of your trial.

583
00:35:16,520 --> 00:35:19,520
This might be just your fMRI signal, your EG signal, whatever you have.

584
00:35:19,520 --> 00:35:21,520
And then you just say what's above and below.

585
00:35:21,520 --> 00:35:24,520
And whenever it's above, I'm going to call it a non-state

586
00:35:24,520 --> 00:35:26,520
and whenever it's below, I will call it an off-state.

587
00:35:26,520 --> 00:35:29,520
And so the on-states, I make black and the off-states, I turn white.

588
00:35:29,520 --> 00:35:30,520
So I just binarize the data.

589
00:35:30,520 --> 00:35:34,520
The theory would still work if I break it down into four different states, or three.

590
00:35:34,520 --> 00:35:38,520
So it just gives you a larger matrix, more states to work with.

591
00:35:38,520 --> 00:35:45,520
So what does it look like for having 64 states of actual neuron data?

592
00:35:45,520 --> 00:35:49,520
And I would look at them in the present and then I would look at them in the future.

593
00:35:49,520 --> 00:35:51,520
Well, it gives us a matrix, a transition probability matrix,

594
00:35:51,520 --> 00:35:55,520
where you can see that the color here shows the probability of the system

595
00:35:55,520 --> 00:35:57,520
going from one state into the other.

596
00:35:57,520 --> 00:35:59,520
And you can already see that there's an interesting structure,

597
00:35:59,520 --> 00:36:01,520
most prominently, that the system has memory.

598
00:36:01,520 --> 00:36:04,520
So the system likes to stay in its own state.

599
00:36:04,520 --> 00:36:08,520
And the first interesting analysis that I would propose here is

600
00:36:08,520 --> 00:36:11,520
you can use this for your data and then you can play with the time.

601
00:36:11,520 --> 00:36:16,520
You can see how much do I have to move until the system moves out of its original state.

602
00:36:16,520 --> 00:36:20,520
When I do that for my neural data, I find that it is roughly on the order of one synapse.

603
00:36:20,520 --> 00:36:25,520
So if I go past it, then the system automatically starts to go into more interesting states.

604
00:36:25,520 --> 00:36:28,520
You might also feel that this is not an interesting way to look at the data.

605
00:36:28,520 --> 00:36:31,520
So what I would propose is that each time we have a matrix like that,

606
00:36:31,520 --> 00:36:33,520
we can apply graph theory.

607
00:36:33,520 --> 00:36:36,520
So we can take each of these states as a node in graph theory space,

608
00:36:36,520 --> 00:36:41,520
and then the causal interactions, the probability that the state moves from one to another,

609
00:36:41,520 --> 00:36:45,520
we can take as the thickness of the edges between the graph.

610
00:36:45,520 --> 00:36:49,520
So if I do this, for the matrix that I just showed you, it becomes very hard to even visualize.

611
00:36:49,520 --> 00:36:51,520
So let me make it even more simple.

612
00:36:51,520 --> 00:36:54,520
So what I would do now is take three measures of the brain,

613
00:36:54,520 --> 00:36:56,520
and I would do this in the upper, middle, and lower layers of cortex.

614
00:36:56,520 --> 00:36:58,520
So there's only three states.

615
00:36:58,520 --> 00:37:01,520
So all of them are inactive, all of them are active,

616
00:37:01,520 --> 00:37:06,520
and then you can see how the system transitions from one state to the next state.

617
00:37:06,520 --> 00:37:09,520
One thing that's interesting here, I think from a cognitive neuroscience perspective,

618
00:37:09,520 --> 00:37:11,520
is that you see these loops.

619
00:37:11,520 --> 00:37:15,520
So again, this is the system having a certain likelihood to end up in its own state again.

620
00:37:15,520 --> 00:37:18,520
So in a way, you can think of this as feedback.

621
00:37:18,520 --> 00:37:23,520
Well, you can already see that feedback is more likely for some states than for other states.

622
00:37:23,520 --> 00:37:28,520
And you can, again, play around with, for example, the time that you take in between these measurements,

623
00:37:28,520 --> 00:37:30,520
and you can investigate.

624
00:37:30,520 --> 00:37:33,520
Some of the feedback loops, they might become thinner or go away,

625
00:37:33,520 --> 00:37:36,520
and then as you look further into your data, they might reemerge,

626
00:37:36,520 --> 00:37:38,520
as feedback re-enters the system that you're looking at.

627
00:37:38,520 --> 00:37:39,520
Yes, Gordon?

628
00:37:39,520 --> 00:37:42,520
Why is that a feedback loop and not just like...

629
00:37:42,520 --> 00:37:43,520
Or memory.

630
00:37:43,520 --> 00:37:44,520
Yes, yes.

631
00:37:44,520 --> 00:37:46,520
I should be more careful how I phrase these things.

632
00:37:46,520 --> 00:37:47,520
I'm totally agnostic about it.

633
00:37:47,520 --> 00:37:49,520
So the system could just persist.

634
00:37:49,520 --> 00:37:50,520
Could just be history.

635
00:37:50,520 --> 00:37:51,520
Yes.

636
00:37:51,520 --> 00:37:52,520
I think it would be feedback.

637
00:37:52,520 --> 00:37:55,520
It would be easier to argue if you look at that as a function of time,

638
00:37:55,520 --> 00:37:57,520
and it disappears and then reappears again.

639
00:37:57,520 --> 00:38:00,520
That would maybe show that there's some reverberance going on.

640
00:38:00,520 --> 00:38:02,520
But yeah, that's a great point.

641
00:38:02,520 --> 00:38:10,520
And so I'm cutting a long story short of looking at these transition probability matrices

642
00:38:10,520 --> 00:38:14,520
in these actual graph structure.

643
00:38:14,520 --> 00:38:15,520
It does show you...

644
00:38:15,520 --> 00:38:18,520
When I looked at my lab's data, it does show you a lot of interesting structures.

645
00:38:18,520 --> 00:38:20,520
So for example, the question before,

646
00:38:20,520 --> 00:38:22,520
what if the system has a very strong memory?

647
00:38:22,520 --> 00:38:26,520
Well, we do know that a lot of the neural data is one over F distributed,

648
00:38:26,520 --> 00:38:28,520
so it does have memory over time.

649
00:38:28,520 --> 00:38:33,520
And so what I found is that if I compare this actual neural data to a system

650
00:38:33,520 --> 00:38:37,520
that I artificially produce, where I have control over these variables,

651
00:38:37,520 --> 00:38:41,520
and I can't just introduce correlations however strong I want them

652
00:38:41,520 --> 00:38:43,520
between the data or causal directions,

653
00:38:43,520 --> 00:38:45,520
or I completely uncorrelated the system,

654
00:38:45,520 --> 00:38:50,520
then I do find that there's a stereotypical pattern right here.

655
00:38:50,520 --> 00:38:52,520
And as I said before, we could use this as a baseline.

656
00:38:52,520 --> 00:38:55,520
We could say, well, that is what an uncorrelated system looks like,

657
00:38:55,520 --> 00:38:58,520
and any deviation from that would be a more interesting deviation.

658
00:38:58,520 --> 00:38:59,520
Yes?

659
00:39:06,520 --> 00:39:08,520
That's basically what I just said.

660
00:39:08,520 --> 00:39:12,520
I mean, you can take artificial data and you can uncorrelated it.

661
00:39:12,520 --> 00:39:15,520
And so I took it out because I want to use the rest of the talk

662
00:39:15,520 --> 00:39:17,520
to get at the maybe most interesting part.

663
00:39:17,520 --> 00:39:19,520
But if you take a system that's completely uncorrelated,

664
00:39:19,520 --> 00:39:21,520
you end up with a structure that's called the Hamming Distance.

665
00:39:21,520 --> 00:39:25,520
And so the Hamming Distance is that the transition probability of a system

666
00:39:25,520 --> 00:39:31,520
that's in 001 to go to 001 should be higher

667
00:39:31,520 --> 00:39:35,520
than the transition probability from a system to go from 001 to 111,

668
00:39:35,520 --> 00:39:37,520
because more has to change.

669
00:39:37,520 --> 00:39:39,520
The system is more likely to end up in this state than in that state.

670
00:39:39,520 --> 00:39:43,520
And so that you can measure, it comes out as the Hamming Distance,

671
00:39:43,520 --> 00:39:46,520
a very well-characterized geometrical space.

672
00:39:46,520 --> 00:39:49,520
And so you can either use it as a matrix, or you can use it as a graph,

673
00:39:49,520 --> 00:39:52,520
and then you can take any kind of distance that you like

674
00:39:52,520 --> 00:39:54,520
between multidimensional sets of data,

675
00:39:54,520 --> 00:39:57,520
the mahalano-bisterstand, euclidean norms, anything like that,

676
00:39:57,520 --> 00:40:00,520
to see how far it differs.

677
00:40:00,520 --> 00:40:04,520
Okay, so this is just the first step of integrated information theory,

678
00:40:04,520 --> 00:40:06,520
but you can maybe see why I'm already excited about that.

679
00:40:06,520 --> 00:40:09,520
As an experimentalist, we tend to look at new tools

680
00:40:09,520 --> 00:40:11,520
that might allow us to look at our data in new ways,

681
00:40:11,520 --> 00:40:13,520
and I think this is what it does.

682
00:40:13,520 --> 00:40:15,520
And so all of us might have this feeling that Galileo had maybe

683
00:40:15,520 --> 00:40:17,520
when for the first time he was able to look for a telescope,

684
00:40:17,520 --> 00:40:20,520
and he discovered things out in the solar system that haven't been seen before.

685
00:40:20,520 --> 00:40:23,520
So I'm not arguing this as Galileo's telescope,

686
00:40:23,520 --> 00:40:26,520
I'm just saying that here's another interesting tool to look at your data

687
00:40:26,520 --> 00:40:29,520
that might be worth your time and more consideration.

688
00:40:29,520 --> 00:40:31,520
But there's more to it.

689
00:40:31,520 --> 00:40:34,520
So what I said in the beginning is that integrated information theory

690
00:40:34,520 --> 00:40:38,520
severs some of these causal connections and see what the system does.

691
00:40:38,520 --> 00:40:42,520
And so that rests on something called due algebra

692
00:40:42,520 --> 00:40:47,520
that was introduced to the field actually decades ago already by Julia Pearl.

693
00:40:47,520 --> 00:40:49,520
So that's a tool of statistics.

694
00:40:49,520 --> 00:40:51,520
And so again, I'm not going to do it justice, of course,

695
00:40:51,520 --> 00:40:53,520
in the short amount of time that I have,

696
00:40:53,520 --> 00:40:55,520
but I'm just going to give you the general idea.

697
00:40:55,520 --> 00:40:57,520
So if you have a very simple statistical system,

698
00:40:57,520 --> 00:41:01,520
so say you have one variable and you're interested in its effect on the other variable,

699
00:41:01,520 --> 00:41:03,520
and you have a confounding variable that affects both.

700
00:41:03,520 --> 00:41:07,520
That's a very common statistical problem because if you just do a correlative approach,

701
00:41:07,520 --> 00:41:10,520
this right here causes huge pain.

702
00:41:10,520 --> 00:41:13,520
And so we call this a fork in a causal statistical sense.

703
00:41:13,520 --> 00:41:21,520
So what Julia Pearl said is that we can get at the causal effect right here

704
00:41:21,520 --> 00:41:25,520
beyond the correlative approach using his due calculus.

705
00:41:25,520 --> 00:41:27,520
So what is this magical approach?

706
00:41:27,520 --> 00:41:31,520
Well, we know as scientists that in order to find causality,

707
00:41:31,520 --> 00:41:33,520
you have to make interventions.

708
00:41:33,520 --> 00:41:36,520
You have to intervene into the system and then you see causal effects.

709
00:41:36,520 --> 00:41:41,520
What due calculus allows you to do is to intervene into the system without physically doing so.

710
00:41:41,520 --> 00:41:44,520
So you're intervening it statistically, if you will.

711
00:41:44,520 --> 00:41:46,520
So how do you do that?

712
00:41:46,520 --> 00:41:51,520
Well, if you think of this system described in a similar way as I just did,

713
00:41:51,520 --> 00:41:54,520
where you know the transition probabilities between each of these states of the system.

714
00:41:54,520 --> 00:41:57,520
So you have a full statistical description of the system,

715
00:41:57,520 --> 00:41:59,520
and you also know the causal graph.

716
00:41:59,520 --> 00:42:01,520
So you know the causal connections.

717
00:42:01,520 --> 00:42:08,520
What you can do is you can computationally keep one of these variables constant or manipulated

718
00:42:08,520 --> 00:42:10,520
and then study the effect on the whole system.

719
00:42:10,520 --> 00:42:13,520
So in this case, if you keep this variable at a certain value,

720
00:42:13,520 --> 00:42:15,520
you're severing this connection.

721
00:42:15,520 --> 00:42:19,520
Now this variable right here, the confounder, can't affect this one anymore

722
00:42:19,520 --> 00:42:20,520
because you're keeping it constant.

723
00:42:20,520 --> 00:42:21,520
It can't change.

724
00:42:21,520 --> 00:42:23,520
So whatever this guy does, it doesn't affect this guy.

725
00:42:23,520 --> 00:42:24,520
Does it make sense?

726
00:42:24,520 --> 00:42:26,520
It can still affect this guy, but it can't affect this guy anymore.

727
00:42:26,520 --> 00:42:28,520
So you're making an intervention.

728
00:42:28,520 --> 00:42:31,520
And you're also doing what I just said, you're mutilating the system

729
00:42:31,520 --> 00:42:34,520
by getting rid of one of the causal connections.

730
00:42:34,520 --> 00:42:38,520
So you're different in targeted attack analysis in graph theory?

731
00:42:38,520 --> 00:42:42,520
No, I think it's out of my wheelhouse, but it might be very similar.

732
00:42:42,520 --> 00:42:44,520
So let me give you a concrete example.

733
00:42:44,520 --> 00:42:49,520
So if you have a simple transition probability matrix,

734
00:42:49,520 --> 00:42:54,520
so in this case you have only two different parts of the system,

735
00:42:54,520 --> 00:42:57,520
and they're either both off, one is on, the other's on, or both are on.

736
00:42:57,520 --> 00:43:00,520
And then you look at t plus some point in the future,

737
00:43:00,520 --> 00:43:02,520
and you look at the transition probabilities,

738
00:43:02,520 --> 00:43:04,520
and you want to make this intervention.

739
00:43:04,520 --> 00:43:07,520
So you want to mutilate the system.

740
00:43:07,520 --> 00:43:13,520
So what you can do is you can disconnect the system through what,

741
00:43:13,520 --> 00:43:16,520
in this case, would be called statistical noising or marginalizing.

742
00:43:16,520 --> 00:43:20,520
So in this case, let's say the first element we want to get rid of.

743
00:43:20,520 --> 00:43:23,520
And so what you can see right here is that in this case,

744
00:43:23,520 --> 00:43:26,520
in that case, if we eliminate it or eliminate it,

745
00:43:26,520 --> 00:43:30,520
it comes out as basically just averaging these two states together,

746
00:43:30,520 --> 00:43:34,520
because this is zero zero, so let's average where the second one is in zero,

747
00:43:34,520 --> 00:43:36,520
and you get this transition probability,

748
00:43:36,520 --> 00:43:38,520
or in this case the second element is one and one.

749
00:43:38,520 --> 00:43:42,520
So we don't care about this anymore, so we just average that and we come out at point five.

750
00:43:42,520 --> 00:43:44,520
So you come up with a new transition probability matrix

751
00:43:44,520 --> 00:43:47,520
where you artificially intervene and you took out part of the system.

752
00:43:47,520 --> 00:43:51,520
Now this transition probability matrix is different than this transition probability matrix.

753
00:43:51,520 --> 00:43:56,520
So if you look at the transition probabilities,

754
00:43:56,520 --> 00:44:00,520
it looks like you severed something that you shouldn't have.

755
00:44:00,520 --> 00:44:02,520
There's a causal effect in the system.

756
00:44:02,520 --> 00:44:05,520
If you would have done this and it would be exactly the same outcome,

757
00:44:05,520 --> 00:44:09,520
then what you just severed, what you artificially intervened,

758
00:44:09,520 --> 00:44:10,520
didn't have an effect.

759
00:44:10,520 --> 00:44:13,520
And you can basically eliminate it in this approach.

760
00:44:13,520 --> 00:44:14,520
Yes.

761
00:44:14,520 --> 00:44:15,520
Can you go back one?

762
00:44:15,520 --> 00:44:16,520
Yeah.

763
00:44:16,520 --> 00:44:20,520
So you started describing this by saying, assuming you know.

764
00:44:20,520 --> 00:44:21,520
Yeah.

765
00:44:21,520 --> 00:44:26,520
But, I mean, this is a very simple third variable problem.

766
00:44:26,520 --> 00:44:29,520
I mean, we definitely want it now, usually.

767
00:44:29,520 --> 00:44:30,520
Yeah.

768
00:44:30,520 --> 00:44:34,520
And simple, just with three variables,

769
00:44:34,520 --> 00:44:37,520
trying to figure out what's needed and what,

770
00:44:37,520 --> 00:44:42,520
I mean, we can't turn this into correlation and complication with three.

771
00:44:42,520 --> 00:44:46,520
What aspect of this is fixing that problem?

772
00:44:46,520 --> 00:44:47,520
Yeah.

773
00:44:47,520 --> 00:44:51,520
So two responses that, again, you might not find satisfactory.

774
00:44:51,520 --> 00:44:55,520
So the first one is that I would say, we just make that assumption again.

775
00:44:55,520 --> 00:44:58,520
In this case, if you're looking at an individual column,

776
00:44:58,520 --> 00:45:00,520
we're just going to assume that it's closely close

777
00:45:00,520 --> 00:45:02,520
and we're just going to make these assumptions.

778
00:45:02,520 --> 00:45:04,520
So we know, for example, that the middle layer is connected to the upper layers

779
00:45:04,520 --> 00:45:06,520
and the upper layer is connected to the lower layer.

780
00:45:06,520 --> 00:45:09,520
So we can come up with a very simple graph like that.

781
00:45:09,520 --> 00:45:11,520
And we know that there's assumptions and maybe even violations in there.

782
00:45:11,520 --> 00:45:13,520
But we can still use it as a model.

783
00:45:13,520 --> 00:45:17,520
And every model has a shortcoming to look at the data.

784
00:45:17,520 --> 00:45:20,520
But I would agree with you that's problematic.

785
00:45:20,520 --> 00:45:23,520
So what's the other response that I have to that?

786
00:45:23,520 --> 00:45:26,520
Well, these electrodes, those are very specific response, maybe,

787
00:45:26,520 --> 00:45:28,520
to those of us that are doing neurophysiology.

788
00:45:28,520 --> 00:45:32,520
Those electrodes that we have, they now allow you to actually look at connected neurons.

789
00:45:32,520 --> 00:45:37,520
So you're getting 100 neurons at a time and you can look at the correlation of the activity

790
00:45:37,520 --> 00:45:40,520
and you'll find neurons that always basically fire together

791
00:45:40,520 --> 00:45:44,520
with a little lack of, let's say, four milliseconds or so.

792
00:45:44,520 --> 00:45:49,520
So that means that you can establish very simple systems,

793
00:45:49,520 --> 00:45:52,520
in this case, something like this, where you have interconnected neurons

794
00:45:52,520 --> 00:45:56,520
and you're not making any major violations.

795
00:45:56,520 --> 00:46:03,520
This having said, yes, the whole theory, if you take the theory at heart

796
00:46:03,520 --> 00:46:07,520
and if your end goal is to find out if the system is conscious,

797
00:46:07,520 --> 00:46:09,520
how much it is conscious, what the conscious states are,

798
00:46:09,520 --> 00:46:13,520
you would have to do this for maybe all of the neurons at the brain

799
00:46:13,520 --> 00:46:14,520
measured at the same time.

800
00:46:14,520 --> 00:46:18,520
In fact, the people that talk about the theory, they would admit that it could be worse.

801
00:46:18,520 --> 00:46:21,520
It could be that it's not the neurons that matter but the synapses.

802
00:46:21,520 --> 00:46:24,520
And we would have to measure all of the synapses at the same time.

803
00:46:24,520 --> 00:46:28,520
But it could also be that that isn't what is the physical basis

804
00:46:28,520 --> 00:46:32,520
of what gives rise to phenomenology and areas is the way to go, or columns.

805
00:46:32,520 --> 00:46:34,520
We don't know what the right level is.

806
00:46:34,520 --> 00:46:37,520
And so what they are arguing is, I think what is a part of the research program,

807
00:46:37,520 --> 00:46:42,520
is to compute these different values on these different spatial and temporal scales

808
00:46:42,520 --> 00:46:43,520
and see where it peaks.

809
00:46:43,520 --> 00:46:48,520
So, but yes, there are, as with any technique, there's a chasm here

810
00:46:48,520 --> 00:46:52,520
between the theoretical foundations and then how we can use it.

811
00:46:52,520 --> 00:46:58,520
And so my appeal is take it with a grain of salt, but just give it a try.

812
00:46:58,520 --> 00:47:00,520
Violate the assumption and see what happens.

813
00:47:00,520 --> 00:47:04,520
So here's maybe the good transition why I think that might be interesting.

814
00:47:04,520 --> 00:47:07,520
So this right here is actual data from my lab.

815
00:47:07,520 --> 00:47:13,520
And so in blue and in red, you see these are basically neuronal activation.

816
00:47:13,520 --> 00:47:17,520
While the animal in this case is just fixating at the screen, nothing is happening.

817
00:47:17,520 --> 00:47:20,520
Then a stimulus comes on and then in blue, the animal pays attention.

818
00:47:20,520 --> 00:47:23,520
And in red, the animal does not pay attention.

819
00:47:23,520 --> 00:47:28,520
And so we're measuring activity across the layers in this case of area before.

820
00:47:29,520 --> 00:47:32,520
And so there's two things that I want to point out.

821
00:47:32,520 --> 00:47:37,520
So this right here are these representations and graph theory that I just told you about.

822
00:47:37,520 --> 00:47:40,520
These down here are just two of the Pearson correlation coefficients

823
00:47:40,520 --> 00:47:45,520
between the matrices that are underlying, in this case, the red versus the blue state.

824
00:47:45,520 --> 00:47:50,520
And so if the animal is just fixating and nothing is going on,

825
00:47:50,520 --> 00:47:55,520
and I'm computing the phi value, which would be about the level of consciousness in this case,

826
00:47:55,520 --> 00:47:57,520
you can see it's pretty low.

827
00:47:57,520 --> 00:47:59,520
And then when the stimulus comes on and I'm computing the phi value,

828
00:47:59,520 --> 00:48:02,520
making all of these assumptions, you can see it's going up.

829
00:48:02,520 --> 00:48:07,520
So despite all of these assumptions being violated, the theory still seems to hold.

830
00:48:07,520 --> 00:48:09,520
The really interesting part is right here.

831
00:48:09,520 --> 00:48:12,520
If I compute phi versus the state where the animal pays attention,

832
00:48:12,520 --> 00:48:15,520
it's the highest versus if the animal doesn't pay attention,

833
00:48:15,520 --> 00:48:18,520
it sinks even below the baseline value,

834
00:48:18,520 --> 00:48:22,520
as you might expect if the animal is now sucking up all of the attention

835
00:48:22,520 --> 00:48:26,520
to one part of the field rather than widely distributing it.

836
00:48:26,520 --> 00:48:32,520
So this is just one example that the summer break allowed me to do

837
00:48:32,520 --> 00:48:35,520
by getting into my own data and doing MATLAB.

838
00:48:35,520 --> 00:48:39,520
They got me excited because I just put the theory to its test.

839
00:48:39,520 --> 00:48:43,520
I held its feet to the fire and it did what it was supposed to do.

840
00:48:43,520 --> 00:48:46,520
Now, of course, there's many more of these examples in the literature.

841
00:48:46,520 --> 00:48:50,520
So it seems that most of the tests to the fire have so far held true.

842
00:48:50,520 --> 00:48:53,520
The original idea, as I told you guys, was this,

843
00:48:53,520 --> 00:48:55,520
that we're not just getting at the level of consciousness,

844
00:48:55,520 --> 00:48:57,520
but at the contents of consciousness.

845
00:48:57,520 --> 00:49:01,520
So in order to do that, we have to take another step.

846
00:49:01,520 --> 00:49:05,520
And so this step is a transition from integrated information theory,

847
00:49:05,520 --> 00:49:07,520
as you know it, as I've just introduced it,

848
00:49:07,520 --> 00:49:11,520
which got published as Integrated Information Theory 3.0.

849
00:49:11,520 --> 00:49:14,520
It's actually the third revision of the theory.

850
00:49:14,520 --> 00:49:19,520
Now, Integrated Information Theory 4.0 is about to come out next year, I've been told.

851
00:49:20,520 --> 00:49:23,520
But all of the math, most of the math has already been developed

852
00:49:23,520 --> 00:49:27,520
and computer code is available for free on the internet

853
00:49:27,520 --> 00:49:30,520
so that you can already run your data for Integrated Information Theory 4.

854
00:49:30,520 --> 00:49:33,520
What is interesting about Integrated Information Theory 4?

855
00:49:33,520 --> 00:49:37,520
Well, it comes up with a new way to come at that cause-effect structure.

856
00:49:37,520 --> 00:49:39,520
Sorry about that.

857
00:49:39,520 --> 00:49:41,520
I slug it in at a time.

858
00:49:41,520 --> 00:49:44,520
So what it does, it basically takes what I just said

859
00:49:44,520 --> 00:49:47,520
in terms of looking at these causal interactions,

860
00:49:47,520 --> 00:49:50,520
but rather than just looking at the states of the system,

861
00:49:50,520 --> 00:49:52,520
it becomes even more multi-dimensional.

862
00:49:52,520 --> 00:49:56,520
It now takes, you see, combinations of different states

863
00:49:56,520 --> 00:50:00,520
and the more measurements you have, the more come out of it

864
00:50:00,520 --> 00:50:03,520
and basically applies the same kind of logic,

865
00:50:03,520 --> 00:50:05,520
not just to the individual states,

866
00:50:05,520 --> 00:50:07,520
but the combinations of states in between.

867
00:50:07,520 --> 00:50:11,520
And so IIT 4.0 calls these relations

868
00:50:11,520 --> 00:50:15,520
and as I said, the math and the code has just been available for that.

869
00:50:15,520 --> 00:50:17,520
So just give you a brief insight again,

870
00:50:17,520 --> 00:50:20,520
just very little time that I had available to look into that.

871
00:50:20,520 --> 00:50:23,520
For this example that I've been showing a couple of times now

872
00:50:23,520 --> 00:50:26,520
of neural data recorded in the middle upper lower layers

873
00:50:26,520 --> 00:50:30,520
and I'm running this IIT 4.0 code to look at

874
00:50:30,520 --> 00:50:32,520
out of all these possible combinations,

875
00:50:32,520 --> 00:50:35,520
which one of those are irreducible, which one have actual cause of power.

876
00:50:35,520 --> 00:50:37,520
So one thing that's a little confusing is that

877
00:50:37,520 --> 00:50:39,520
we now move to different terminology,

878
00:50:39,520 --> 00:50:43,520
so A, B, and C would be in this case the different layers of cortex

879
00:50:43,520 --> 00:50:47,520
and you can see that only one of these layers turns out to have cause of power by itself.

880
00:50:47,520 --> 00:50:50,520
The other layers of cortex, they only act synergistically.

881
00:50:50,520 --> 00:50:54,520
But more surprisingly to me, most of the possible interactions

882
00:50:54,520 --> 00:50:59,520
that you can theoretically come up with in this multi-dimensional space

883
00:50:59,520 --> 00:51:00,520
turn out to be reducible.

884
00:51:00,520 --> 00:51:02,520
They actually turn out to be non-causal

885
00:51:02,520 --> 00:51:05,520
and I think that is very exciting for most of us that are interested

886
00:51:05,520 --> 00:51:07,520
in how do I deal with these massive amounts of data

887
00:51:07,520 --> 00:51:10,520
that I'm getting from fMRIEG, neurophysiology,

888
00:51:10,520 --> 00:51:14,520
and we can reduce the dimensionality of these data in a meaningful way.

889
00:51:14,520 --> 00:51:17,520
So rather than what a lot of techniques do these days,

890
00:51:17,520 --> 00:51:20,520
take an external perspective and saying I'm decoding the system,

891
00:51:20,520 --> 00:51:22,520
I'm looking into the system, what allows me to predict behavior,

892
00:51:22,520 --> 00:51:25,520
what allows me to post-dict the stimulus conditions.

893
00:51:25,520 --> 00:51:27,520
This is taking an intrinsic perspective and it's saying

894
00:51:27,520 --> 00:51:31,520
which one of the interactions in my data are important to the system.

895
00:51:31,520 --> 00:51:32,520
They actually matter.

896
00:51:32,520 --> 00:51:36,520
So I would argue this might be a way for us to get closer

897
00:51:36,520 --> 00:51:39,520
to understanding the system as it functions itself.

898
00:51:39,520 --> 00:51:43,520
So if you agree with me or if you have only slight disagreements,

899
00:51:43,520 --> 00:51:46,520
you can now see why this qualia structure approach

900
00:51:46,520 --> 00:51:48,520
is something that has gathered a lot of YouTube channels,

901
00:51:48,520 --> 00:51:52,520
a lot of fanfare, a lot of special issues and conferences.

902
00:51:52,520 --> 00:51:55,520
If not, you might feel, one more time.

903
00:51:55,520 --> 00:51:57,520
If not, you might feel like Albert Einstein

904
00:51:57,520 --> 00:52:01,520
that maybe we're going a little bit too far with the math

905
00:52:01,520 --> 00:52:04,520
and we should maybe stick a little bit closer to the data.

906
00:52:04,520 --> 00:52:07,520
In either case, I say the franais, merci.

