WEBVTT

00:00.000 --> 00:04.600
Thank you very much for the very kind considering introduction, Rene.

00:04.600 --> 00:12.000
I'd like to get started by paying homage and thank the people that allow me to do this

00:12.000 --> 00:14.320
kind of work.

00:14.320 --> 00:20.560
Those of you who don't know, there's basically dozens of people involved downstairs in the

00:20.560 --> 00:28.560
facility that take care of our furry colleagues and keep the operation running.

00:28.560 --> 00:35.560
I want to thank the various funding sources, of course, the people in my lab, and then

00:35.560 --> 00:40.360
also this particular group of people, two of which have moved on and are doing post-doc

00:40.360 --> 00:45.360
already that collected the data, some of which that I will show to you guys today.

00:45.360 --> 00:49.040
And last but not least, Nao Tokia.

00:49.040 --> 00:54.280
Each time I get to talk about this in front of a group of young aspiring scientists, I

00:54.280 --> 00:56.160
want to point this out.

00:56.160 --> 01:01.240
You should not just try to connect vertically and that works vertically with people that

01:01.240 --> 01:02.400
are more senior to you.

01:02.400 --> 01:07.160
You should really strive to branch out horizontally and make friends with people that are in your

01:07.160 --> 01:10.560
cohort because they will become more important to you as your career goes along.

01:10.560 --> 01:11.960
Now is such a case.

01:11.960 --> 01:14.080
I met Nao as a graduate student.

01:14.080 --> 01:19.600
We had very strong fellow interests and we've been collaborating basically ever since.

01:19.600 --> 01:24.560
And this has really borne fruit, as you will see, hopefully today.

01:24.560 --> 01:28.440
So actually, I want to give all the credit to Nao because the ideas that I'm going to

01:28.440 --> 01:31.840
show you largely stem from Nao.

01:31.840 --> 01:37.960
And so I'm just basically a humble messenger to introduce you to his theories.

01:37.960 --> 01:39.200
So what allows me to do that?

01:39.200 --> 01:42.240
Well, there's a variety of factors that allows me to do that.

01:42.240 --> 01:48.360
One of them is the situation that we're all in, which is that many of us were forced to

01:48.360 --> 01:52.080
spend more time at home and with family.

01:52.120 --> 01:57.640
And so very quickly, you might have also found that you have more time on your hand and what

01:57.640 --> 01:59.040
should be done with it.

01:59.040 --> 02:04.200
Well, for me, that meant trying to keep connected with other scientists.

02:04.200 --> 02:05.880
And I felt I wasn't the only one.

02:05.880 --> 02:11.840
So what happened was that one more on YouTube channels popped up where scientists were inviting

02:11.840 --> 02:13.480
each other to Zoom talks.

02:13.480 --> 02:18.040
And rather than just doing that over a closed Zoom setting where you needed to have a password,

02:18.040 --> 02:23.160
they would stream that live on YouTube and other scientists could come in.

02:23.160 --> 02:26.600
And so these are three YouTube channels that I just want to point out that I basically

02:26.600 --> 02:28.200
became addicted to.

02:28.200 --> 02:30.920
And they launched me into what I'm talking to you guys today.

02:30.920 --> 02:35.080
So I'm advertising for you guys to use your spare time, use the time before you fall asleep,

02:35.080 --> 02:37.840
go on YouTube, find these channels that they're rapidly growing.

02:37.840 --> 02:42.600
And I think they're revolutionizing science because that allows you to find topics that

02:42.600 --> 02:46.680
you are really interested in, find the other four people on the planet that equally interested

02:46.680 --> 02:49.560
in that and have a rapidly evolving field.

02:49.560 --> 02:52.760
So huge advantages to do this kind of approach.

02:52.760 --> 02:55.280
And so I'm not just talking theory here.

02:55.280 --> 02:59.520
What these three channels have in common is largely what I will talk about today has already

02:59.520 --> 03:01.280
spurred a lot of things into action.

03:01.280 --> 03:07.560
So this society, the Association for the Mathematical Consciousness Science, just got founded about

03:07.560 --> 03:13.040
a month or two ago because of these YouTube channels, out of these YouTube channels.

03:13.040 --> 03:18.120
And that society immediately sprung into action, launched special issues at frontiers

03:18.120 --> 03:20.040
and a journal called Entropy.

03:20.040 --> 03:23.840
It's got funding from various sources and there will be a conference two weeks from

03:23.840 --> 03:28.000
now where many of us are coming together virtually and will speak and next year it's expected

03:28.000 --> 03:29.240
to be in person.

03:29.240 --> 03:33.880
So it really is, I think, a shift here that might have happened throughout the pandemic

03:33.880 --> 03:38.120
for science to become more international, to become more collaborative and for communities

03:38.120 --> 03:41.760
to grow within science around the globe.

03:41.760 --> 03:44.040
So what is this particular community interested in?

03:44.040 --> 03:50.000
Well, some of us might be interested in that as well, which is the basic problem that faces

03:50.000 --> 03:52.840
neuroscience, maybe one of the biggest problems of neuroscience, maybe one of the biggest

03:52.840 --> 03:55.320
problems in science at all.

03:55.320 --> 03:59.480
Which is that we all believe as neuroscientists that there's a causal connection between neuronal

03:59.480 --> 04:05.600
activity in our brain and our conscious experience, our perception of the world, that the fact

04:05.600 --> 04:09.880
that we feel love, that we see colors, the fact that as you fall into deep sleep the

04:09.880 --> 04:11.400
world goes away for you.

04:11.400 --> 04:17.120
If you wouldn't exist, but as you come out into dream sleep or back as you wake up the

04:17.120 --> 04:18.520
world comes back for you.

04:18.520 --> 04:24.240
So I will call this phenomenology, the fact that you subjectively experience.

04:24.240 --> 04:27.760
But the embarrassing fact for neuroscience is that this hasn't worked yet.

04:27.760 --> 04:33.080
So usually what we do as scientists is that we find the causal connection and then mathematically

04:33.080 --> 04:34.600
reduce one onto the other.

04:34.600 --> 04:35.920
And that's when we say we understood it.

04:35.920 --> 04:39.000
That's what we do in physics, that's what we do in chemistry, biology and a lot of

04:39.000 --> 04:40.000
neuroscience.

04:40.000 --> 04:46.000
But for this part of our being, the phenomenology, the fact that we have subjective experience,

04:46.000 --> 04:48.160
this step seems to be hard to reach.

04:48.160 --> 04:52.480
In fact, there are many people that would argue that this is fundamentally impossible,

04:52.480 --> 04:54.920
that we will never be able to do that as scientists.

04:54.920 --> 04:55.920
You shouldn't even try.

04:55.920 --> 04:58.000
Well, I'm going to argue to the contrary.

04:58.000 --> 05:01.720
And that is what a lot of these YouTube channels inspired me to do.

05:01.720 --> 05:04.560
So this is a slide from one of the labs that's involved.

05:04.560 --> 05:09.360
So what they're suggesting is that we have to move away from this conventional approach

05:09.360 --> 05:15.000
of neuroscience of correlating inputs to the brain with activity in the brain or behavior

05:15.000 --> 05:21.440
or perception comes out of it, and to take another step that links, in this case, phenomenology,

05:21.440 --> 05:25.600
our subjective experience of consciousness, conscious perception, with brain activity

05:25.600 --> 05:26.600
via math.

05:26.600 --> 05:29.120
What do I mean by via math?

05:29.120 --> 05:33.520
Well, if we believe that consciousness can be explained in terms of science, what we

05:33.560 --> 05:37.800
have accomplished as scientists, what all of scientists rests on is that we find laws

05:37.800 --> 05:44.120
of nature that were able to express these laws of nature with mathematical formalism,

05:44.120 --> 05:49.520
gravity, Maxwellian equations, you name it, that's when we feel as scientists we've actually

05:49.520 --> 05:50.520
had an accomplishment.

05:50.520 --> 05:51.520
We've actually done it.

05:51.520 --> 05:53.640
So can we do that for consciousness?

05:53.640 --> 05:57.000
And so there's a pathway mapped out, and that's what I want to share with you guys today.

05:57.000 --> 05:58.800
Well, so what's the traditional approach?

05:58.800 --> 06:02.720
So the traditional approach, as a lot of you are familiar with, started obviously with

06:02.760 --> 06:07.360
experimental psychology, but I would argue that experimental psychology, people like

06:07.360 --> 06:13.400
Wundt and others, they were still careful to touch on this subjective consciousness

06:13.400 --> 06:14.400
experience side.

06:14.400 --> 06:19.280
And the first people who made a bold inroad into that was Fechner, together with his

06:19.280 --> 06:20.280
mentor, Vibar.

06:20.280 --> 06:23.640
And so they found a technique, and I'm not going to elaborate too much about it, to

06:23.640 --> 06:26.680
quantify subjective experience.

06:26.680 --> 06:31.080
So to go away from saying you can't measure love, to say I know exactly for love is twice

06:31.080 --> 06:32.280
as much as true love.

06:32.280 --> 06:33.280
And we can measure that.

06:33.280 --> 06:36.480
A lot of you are doing that all the time in the laboratories objectively, and we can

06:36.480 --> 06:41.240
come up with mathematical equations to express these laws.

06:41.240 --> 06:46.600
A little bit later in the 1960s, this was generalized by Stevens by basically introducing

06:46.600 --> 06:51.160
two more techniques that were done by the original inventors of psychophysics, and then

06:51.160 --> 06:54.400
finding a generalization of the mathematical laws that we have.

06:54.400 --> 06:57.000
And then it seemed that we're getting stuck.

06:57.000 --> 06:58.400
And so what might be that next step?

06:58.400 --> 07:02.040
Well, what I'm going to argue about today has many names because it's a new mushrooming

07:02.040 --> 07:05.680
field, but one of them I will use a lot is qualia structuralism.

07:05.680 --> 07:11.000
And the idea is that we can mathematically express our conscious experience of phenomenology

07:11.000 --> 07:15.840
and then find mathematical laws, how that maps onto similar abstract geometrical mathematical

07:15.840 --> 07:17.680
spaces derived from neural data.

07:17.680 --> 07:19.120
That's the basic idea.

07:19.120 --> 07:22.920
Now the first thing that we'll have to do there is we'll have to find the structure

07:22.920 --> 07:23.920
of qualia.

07:23.920 --> 07:27.880
And qualia is a philosophical fancy term for your experience.

07:28.120 --> 07:33.800
So I took this here from a paper by Jennifer Troublat, who has done pioneering research

07:33.800 --> 07:34.800
into that.

07:34.800 --> 07:39.560
And I put it on here because this paper shows that when it comes to these spaces that might

07:39.560 --> 07:45.360
describe our perceptual phenomenological subjective experience, they are non-trivial.

07:45.360 --> 07:49.920
So what Jennifer showed and reviewed in this paper is that these spaces might be non-euclidean,

07:49.920 --> 07:54.200
that certain things that you think are more similar and they move closer to space.

07:54.200 --> 07:57.280
If you look at them from a different angle, all of a sudden they seem to be wider apart.

07:57.320 --> 08:03.080
So it might take more unconventional math, such as quantum, then from quantum theory

08:03.080 --> 08:07.000
and some of the math I'll talk about today to bridge this gap and to describe these things.

08:07.000 --> 08:11.920
But it is, of course, for many of us that study perception, not news that we can express

08:11.920 --> 08:14.760
phenomenological experience in terms of geometrical spaces.

08:14.760 --> 08:19.000
So this right here is the color space that most of us are familiar with, that all of

08:19.000 --> 08:22.560
the colors that we can see, we can put in a three-dimensional space and map onto what

08:22.560 --> 08:24.600
might be largely looking as a sphere.

08:24.600 --> 08:29.720
If you're interested in music, there's a similar geometrical description of the phenomenological

08:29.720 --> 08:35.440
space that you hear in music, which is that if you have a note and you go up an octave,

08:35.440 --> 08:38.960
the note clearly is a higher note, but at the same time there's similarity with the original

08:38.960 --> 08:39.960
note.

08:39.960 --> 08:42.640
And if you do this with all of these notes, you end up with a helical three-dimensional

08:42.640 --> 08:43.720
structure.

08:43.720 --> 08:48.840
And more recently, face space is an example of multi-dimensional spaces that people have

08:48.840 --> 08:54.560
come up with for objects, for faces, for other structures of our experience and mapping them

08:54.560 --> 08:57.200
into these geometrical mathematical spaces.

08:57.200 --> 09:02.080
So if we accept this, that we can come up with mathematical descriptions of a phenomenological

09:02.080 --> 09:05.040
space, then what's the next step to go to the brain?

09:05.040 --> 09:10.440
So this is the suggestion of qualia structuralism, that let's say you have a chord and you have

09:10.440 --> 09:14.960
another chord where you move one of the notes, it sounds similar, it also sounds different,

09:14.960 --> 09:19.680
and that's because it would basically be a transform within that helical musical space

09:19.680 --> 09:22.440
from one of these loops to another.

09:22.440 --> 09:40.640
So if I play an example for that, let's see if this works.

09:40.640 --> 09:44.360
Pretty much the same song, but all I did here is transpose by an octave.

09:44.360 --> 09:48.760
So you were listening to the same structure, I just moved it down in this three-dimensional

09:48.760 --> 09:50.080
helical space.

09:50.080 --> 09:54.760
So the proposal is that if we derive neural activity from the brain and we come up with

09:54.760 --> 09:59.360
a similar mathematically-formalized abstract structure of neural activity, we should see

09:59.360 --> 10:05.280
some kind of relationship as we are experiencing one of these songs and the other song that

10:05.280 --> 10:08.440
might resemble in some way what the phenomenological space does.

10:08.440 --> 10:13.320
So now, in fact, and me in this case as a co-author, we were suggesting that there may

10:13.320 --> 10:17.960
be an isomorphism, that you would find a similar kind of transformation in these space, in

10:17.960 --> 10:23.480
these abstract spaces, but there's many ways, I'm sorry about playing the song again, there's

10:23.480 --> 10:27.680
many different ways that these spaces could relate, and I'm just, I'm not going too much

10:27.680 --> 10:31.840
into depth here, but category theory is a relatively new branch of mathematics, so there's

10:31.840 --> 10:35.800
a lot of buzz around it, and that is exactly what category theory is trying to do.

10:35.800 --> 10:39.720
It's taking different mathematical structures, in this case here you can see geometry and

10:39.720 --> 10:42.680
algebra, and trying to find the relations between them.

10:42.680 --> 10:46.160
And these relations, they can be mathematically expressed, we call punctors.

10:46.160 --> 10:50.840
So in the end, what we're trying to do is we try to find a functor between the abstracted

10:50.840 --> 10:57.000
brain activity and the mathematically-formalized phenomenological structure to translate between

10:57.000 --> 10:58.000
them.

10:58.000 --> 10:59.800
This could be isomorphism, this could be something else.

10:59.800 --> 11:04.800
Well, I hope I convinced you that this part here is a fruitful research program and already

11:04.800 --> 11:08.920
underway, and you might agree with me with this, but you might have doubts about this

11:08.920 --> 11:09.920
one.

11:09.920 --> 11:14.200
So how do we get to these structures from brain activity that would allow us to find

11:14.200 --> 11:18.960
some kind of mapping between the structure-ized qualia space and neuronal space?

11:18.960 --> 11:19.960
Yes?

11:19.960 --> 11:20.960
Yes?

11:20.960 --> 11:21.960
Yes.

11:21.960 --> 11:22.960
Yes.

11:22.960 --> 11:32.400
So what I'm saying, so most of them are correlative, and so what I would go to now is that I'm

11:32.400 --> 11:37.440
trying to find rather than a Pearson correlation, what I'm trying to go at is something that's

11:37.440 --> 11:42.840
actually more like a mathematical law of nature, and I don't want to go too much into the

11:42.840 --> 11:47.320
problems that correlational approaches have, but what I'm going to back to in the next

11:47.320 --> 11:52.000
couple of slides is that we're trying to get something that's deeper in terms of breaking

11:52.000 --> 11:57.600
correlation into causal structures, and that might allow us to make that look more directly.

11:57.600 --> 12:02.000
So am I not convinced yet, but maybe at the end of the talk we can talk about it?

12:02.000 --> 12:06.400
Well, okay, some of the ones that I think about are, but maybe we should talk more about

12:06.400 --> 12:08.240
that talk.

12:08.240 --> 12:15.520
So the theory that, again, I'm just using here to make that leap is integrated information

12:15.520 --> 12:19.440
theory by Giulia Tornoni, and there's a lot to say about integrated information theory.

12:19.440 --> 12:22.400
It's a very complex theory that's truly interdisciplinary.

12:22.400 --> 12:29.320
It spends a lot of different branches of how we usually divvy up our thinking and academia,

12:29.320 --> 12:34.720
so I'm not going to talk too much about it in terms of what the background is and explaining

12:34.720 --> 12:35.720
it.

12:35.720 --> 12:39.320
I think that would be at least another lecture if not a whole graduate seminar of a whole

12:39.320 --> 12:44.200
semester, but I will give you some of the ideas of integrated information theory.

12:44.200 --> 12:50.240
The first one is that if we think about consciousness, typically this is a consensus diagram that

12:50.240 --> 12:53.760
has made around that last couple of years, which is that consciousness seems to be at

12:53.760 --> 12:59.080
least two-dimensional, and that there's one axis, which we would call the level of consciousness,

12:59.080 --> 13:00.560
how much you're conscious.

13:00.560 --> 13:04.440
You might want to call it arousal or something related, and then the other one is the content

13:04.440 --> 13:09.200
of consciousness, which is how much you experience, what you experience, the qualia.

13:09.200 --> 13:13.360
The reason that we think it's at least a two-dimensional state is that we can take various states of

13:13.360 --> 13:17.400
consciousness and put them within this two-dimensional plane, and then you'll find, for example,

13:17.400 --> 13:22.480
that vegetative state is a state of coma where people clearly have a different level

13:22.480 --> 13:26.000
of consciousness, a different arousal, so they wake up in the morning, they open their

13:26.000 --> 13:30.520
eyes, they go to sleep at night, but there's no sign of actual conscious experience in

13:30.520 --> 13:33.520
a lot of these patients, so there's almost no content, but there's a lot of changes

13:33.520 --> 13:34.520
in arousal.

13:34.520 --> 13:38.120
That means we can dissociate these two parts of consciousness, and they're probably orthogonal,

13:38.120 --> 13:39.640
as I put them right here.

13:39.640 --> 13:44.200
Now, for understanding consciousness, I think the really interesting case is up here, where

13:44.200 --> 13:49.400
you are highly aroused and you have a lot of content, as I hope in a state that you're

13:49.400 --> 13:50.960
still in right now.

13:50.960 --> 13:55.320
I'd probably get you more to this state as I keep talking on, but in this state, what

13:55.320 --> 14:01.040
I'm arguing is that you still don't fully have all the access to what consciousness

14:01.040 --> 14:02.040
is doing.

14:02.080 --> 14:04.120
So the example for that would be over here.

14:04.120 --> 14:07.760
If you read this really fast, you would say, oh, I read a bird in the bush, and if I say,

14:07.760 --> 14:11.320
well, try again, you would say, oh, wait a minute, it says a bird in the bush, but the

14:11.320 --> 14:14.760
first time you see that, you probably didn't see the second the.

14:14.760 --> 14:19.840
So that's a famous example of repetition blindness, so that means that even if you're up here

14:19.840 --> 14:25.480
and you have the highest level of consciousness, there are still parts of the world that are

14:25.480 --> 14:30.000
closed up to you that you fail to experience.

14:30.080 --> 14:31.520
When I put it out, you can actually experience.

14:31.520 --> 14:32.040
Yes, question.

14:49.440 --> 14:52.360
Yeah, so I would argue it would be more to this.

14:52.360 --> 14:55.280
It doesn't go without a traditional notion of subjective experience.

14:55.280 --> 14:55.440
Right.

14:55.440 --> 15:02.640
So you have a living being that's undergoing all the signs of arousal, but it doesn't have

15:02.640 --> 15:04.040
any delight to offer.

15:04.040 --> 15:06.200
There's no subjective experience.

15:06.200 --> 15:09.880
That person would be conscious in this definition, but not in this definition.

15:09.880 --> 15:15.520
And that has led to a lot of debate in the field, because there's been a lot of confusion

15:15.520 --> 15:16.840
misunderstanding about it.

15:16.840 --> 15:21.880
So you can have, if you do anesthesia, for example, for more than 24 hours, so some of

15:21.960 --> 15:25.640
us do, they know that the animal gets more aroused in the morning and you have to increase

15:25.640 --> 15:29.720
the anesthesia, but we don't think that the animal is having any subjective experience,

15:29.720 --> 15:31.160
but it's a sign of arousal.

15:31.160 --> 15:36.240
So other people that would say, well, if you're a Buddhist Zen monk and you can reach a state

15:36.240 --> 15:40.240
of consciousness without content, if you really look into the phenomenology of that, there

15:40.240 --> 15:42.760
would still be some content because there is subjective experience, right?

15:42.760 --> 15:44.360
So I'm not talking about that.

15:44.360 --> 15:48.920
So I'm really dissociating basically the almost behavioral signs of arousal from actual subjective

15:48.920 --> 15:49.920
experience.

15:49.920 --> 15:50.920
That's my definition, though.

15:50.920 --> 15:51.920
This might seem different.

15:51.920 --> 15:52.920
Does it make sense?

15:52.920 --> 15:56.360
Yeah, we can talk about that after the talk.

15:56.360 --> 16:00.320
So luckily, this is the part that we're probably in agreement in that I'm most interested

16:00.320 --> 16:01.320
in.

16:01.320 --> 16:05.400
So what integrated information theory does, and that is what it's mostly known for, is

16:05.400 --> 16:09.360
to quantify this axis of consciousness space.

16:09.360 --> 16:13.880
So what integrated information theory does, it gives you a scalar, a single value, and

16:13.880 --> 16:19.600
it tells you how much the system has in terms of level of consciousness.

16:20.600 --> 16:25.000
Lesson well-known is that this orthogonal dimension is also explained by integrated

16:25.000 --> 16:27.320
information theory, and I put this down here.

16:27.320 --> 16:31.240
So when you had this first experience of a bird in the bush, and you missed the second

16:31.240 --> 16:36.240
the, versus you had this experience of a bird in the bush, there was no change in the world.

16:36.240 --> 16:38.680
There was just a change in your mental state.

16:38.680 --> 16:42.840
So that means you had two phenomenological states, and that difference is also quantified

16:42.840 --> 16:48.360
by integrated information theory as a difference in the causal effect structure, or the short,

16:48.360 --> 16:50.200
I will call this the CES.

16:50.200 --> 16:54.320
So there's a delta phi, which is what IET is known for, that shows you the levels of

16:54.320 --> 16:58.400
consciousness, and then a delta CES, which shows you the difference in the contents of

16:58.400 --> 16:59.400
consciousness.

16:59.400 --> 17:00.400
Yes.

17:00.400 --> 17:07.280
Are you saying one of those is more content than the other?

17:07.280 --> 17:08.280
It's different.

17:08.280 --> 17:13.840
Well, I see that, but it's like interesting to figure out your axis of content here, because...

17:13.840 --> 17:17.520
Yeah, so in this particular example, I would say that you have more content when you are

17:17.680 --> 17:20.520
aware of the second the, because you see an extra the.

17:20.520 --> 17:21.520
But that seems questionable, right?

17:21.520 --> 17:25.520
Because in one case, you're paying attention to the meaning, and there's a whole lot of

17:25.520 --> 17:26.520
certain kind of processing.

17:26.520 --> 17:30.520
Whereas in the other case, you're paying attention to something very superficial that may not

17:30.520 --> 17:31.520
be important.

17:31.520 --> 17:35.520
So, and then I might pay attention to the fact that some letters touch the triangle there,

17:35.520 --> 17:38.520
and then I'm aware of that, and I, is that important?

17:38.520 --> 17:39.520
But that's more.

17:39.520 --> 17:40.520
So I...

17:40.520 --> 17:41.520
That's a fair point.

17:41.520 --> 17:46.520
I mean, for me as a vision scientist, just from the visual perspective, I would say you

17:46.520 --> 17:48.520
have more content here than you have here.

17:48.520 --> 17:51.520
But in fact, I'm not...

17:51.520 --> 17:55.520
I don't want to make too much of a point of quantification here, when it comes to the

17:55.520 --> 18:01.520
difference in phenomenology, more that we can look at the difference between two phenomenological

18:01.520 --> 18:02.520
states.

18:02.520 --> 18:07.520
It might be equally content rich, but the fact that there is a difference, we can quantify

18:07.520 --> 18:08.520
the difference.

18:08.520 --> 18:11.520
So that doesn't mean that one, that there has to be an unequal sign between those.

18:11.520 --> 18:12.520
Does that make sense?

18:12.520 --> 18:13.520
Okay.

18:14.520 --> 18:15.520
Yeah.

18:30.520 --> 18:34.520
So let's try and maybe move away from the concept of amount of content.

18:34.520 --> 18:35.520
Okay.

18:35.520 --> 18:39.520
Just the fact that there's different contents, that there's different states of consciousness

18:39.520 --> 18:40.520
that you're in.

18:41.520 --> 18:44.520
They can be formalized in IIT.

18:44.520 --> 18:45.520
Okay.

18:45.520 --> 18:50.520
And so that's all I'm getting at, that there's two formally different states, mathematically

18:50.520 --> 18:51.520
different states.

18:51.520 --> 18:54.520
So let's make it less about the amount, but just the fact that there's a difference and

18:54.520 --> 18:57.520
we can mathematically get at it.

18:57.520 --> 19:03.520
And so just to give you an idea, so these are not just abstract ideas.

19:03.520 --> 19:06.520
There's actual mathematical formalism associated with that.

19:06.520 --> 19:10.520
And so this is from a paper that I will talk about a little bit more about today, where

19:10.520 --> 19:15.520
now and his colleagues, they took neural data, in this case from a fruit fly.

19:15.520 --> 19:20.520
The fruit fly had multiple neurons in its mushroom body, which would be equivalent to

19:20.520 --> 19:21.520
what we call a brain.

19:21.520 --> 19:26.520
And then they measured Phi, which is the level of consciousness between awake and anesthetized

19:26.520 --> 19:27.520
fruit flies.

19:27.520 --> 19:32.520
And you can see that the theory made the correct prediction, which is that Phi should be smaller

19:32.520 --> 19:36.520
in an anesthetized animal than in an alert animal.

19:36.520 --> 19:43.520
This right here corresponds to that in that they tried to get at this causal effect structure.

19:43.520 --> 19:48.520
Now, back when they did that study, the mathematical formalism for the causal effect structure wasn't

19:48.520 --> 19:49.520
fully developed yet.

19:49.520 --> 19:52.520
So that's one of the things I'm saying this is really cutting edge what I'm telling you

19:52.520 --> 19:58.520
today, but they were trying to get at that by coming up with a geometric space that puts

19:58.520 --> 20:03.520
the neural data of the various causes and effects that you find across the neural data

20:03.520 --> 20:07.520
into a multi-dimensional space, in this case, broken down to a three-dimensional space.

20:07.520 --> 20:11.520
And you can see that there's a difference in the causal effect structure as well.

20:11.520 --> 20:12.520
So note the date.

20:12.520 --> 20:16.520
This is really a cutting edge publication.

20:16.520 --> 20:19.520
So what I will show you today is that I think we can go a step further.

20:19.520 --> 20:21.520
So how does this come about?

20:21.520 --> 20:26.520
Well, at the very heart of integrated information theory is this idea that if you have an interconnected

20:26.520 --> 20:33.520
system in which information flows with causal effectivity, let's say that you have four neurons

20:33.520 --> 20:37.520
and they're interconnected in this way and you see the causal flow between these neurons,

20:37.520 --> 20:43.520
that if you can find out about these causal effects by severing some of these connections

20:43.520 --> 20:47.520
and you can do that either experimentally or you can do that.

20:47.520 --> 20:49.520
And this is the interesting part that I hopefully can show you guys today.

20:49.520 --> 20:53.520
You can do that computationally, analytically, with your own data.

20:53.520 --> 20:59.520
And once you do that, you compare the mutilated system where you severed some of these connections

20:59.520 --> 21:00.520
with your original system.

21:00.520 --> 21:04.520
And if there's any difference in the statistical description, then you know what you just mutilated

21:04.520 --> 21:06.520
had a causal effect.

21:06.520 --> 21:08.520
It actually was important for the system.

21:08.520 --> 21:11.520
So you changed the system by mutilating some of these connections.

21:11.520 --> 21:16.520
But if you mutilate some of these connections and there's no difference for the system as a whole,

21:16.520 --> 21:22.520
then you know that these were reducible connections that were actually not important for the function of the system.

21:22.520 --> 21:24.520
And this can be done mathematically.

21:24.520 --> 21:30.520
So this right here is some of the simplified formalism that goes with integrated information theory.

21:30.520 --> 21:35.520
This is when you put it into practice with Python computer code that has been available.

21:35.520 --> 21:38.520
Again, this is the paper that I just referenced from the fruit fly.

21:38.520 --> 21:42.520
And all I will do today is give you a little bit of an overview of what's going on here

21:42.520 --> 21:47.520
and then give you resources that if you are interested and you want to try it with your data,

21:47.520 --> 21:49.520
how you can do that for yourself.

21:50.520 --> 21:52.520
Okay, so why might this be interesting?

21:52.520 --> 21:56.520
Well, more and more what we are doing is when we're talking as neuroscientists,

21:56.520 --> 21:58.520
especially as cognitive neuroscientists,

21:58.520 --> 22:04.520
when we're thinking about the brain, we're thinking about it more and more as a causally connected network circuitry system.

22:04.520 --> 22:09.520
And we are, because of that, measuring more and more data simultaneously across the brain

22:09.520 --> 22:15.520
because the idea is that we just need to know more about what each of these individual parts is doing and how they interact.

22:15.520 --> 22:19.520
And there's two steps involved in that that I think are crucial.

22:19.520 --> 22:22.520
The first one is that rather than just looking at activation,

22:22.520 --> 22:26.520
what integrated information theory does is it abstracts it to information.

22:26.520 --> 22:28.520
And so why is that interesting?

22:28.520 --> 22:33.520
Well, activation is actually more confined than the flow of information.

22:33.520 --> 22:38.520
So if we have, let's say, three neurons here and three neurons here and they're connected with these three axons,

22:38.520 --> 22:43.520
what activation can do is cross over between these neurons, cross its path

22:43.520 --> 22:48.520
because activation has to flow along the physically hard-wired lines of an axon.

22:48.520 --> 22:56.520
But neurons, of course, are not as simple as these systems right here that just receive activation and pass it on.

22:56.520 --> 22:58.520
Neurons can act as logic gates.

22:58.520 --> 23:00.520
They can make, they can compute.

23:00.520 --> 23:05.520
So in this case, if I replace these neurons with X OR gates that are only active,

23:05.520 --> 23:08.520
depending on what the input state is,

23:08.520 --> 23:12.520
then you can see that information now can cross the system.

23:12.520 --> 23:17.520
So as the activation is confined with the physical connections, information flow is more fluid

23:17.520 --> 23:22.520
and actually can process the system in various ways that the activation per se can.

23:22.520 --> 23:28.520
So that's why abstracting from activation to information might be interesting for many of us

23:28.520 --> 23:30.520
in trying to understand what the brain is doing.

23:30.520 --> 23:36.520
The second issue with collecting all of these data simultaneously is that most of the techniques

23:36.520 --> 23:40.520
that we then use analytically to analyze these multidimensional data,

23:40.520 --> 23:42.520
so this would be in this example.

23:42.520 --> 23:46.520
And for Mariah, but the same gets done in EEG or in a singular physiology field,

23:46.520 --> 23:50.520
is that we're trying to get at the multidimensional of the data,

23:50.520 --> 23:54.520
but there's always a step in there that basically boils down to pairwise comparisons.

23:54.520 --> 23:57.520
Very often, Pearson's correlations. It's just a very powerful technique.

23:57.520 --> 24:01.520
So if we do ICA, if we do graph theory, if you look at the various steps involved,

24:01.520 --> 24:04.520
typically somewhere you find that there's pairwise comparisons.

24:04.520 --> 24:09.520
And I would argue that that's a limitation and I would argue that integrated information theory gets past that.

24:09.520 --> 24:10.520
So what do I mean?

24:10.520 --> 24:14.520
So let's take this very simple example of heavy learning that I took from one of the textbooks.

24:14.520 --> 24:19.520
So if you are taking a system of three neurons interconnected, so these neurons connect onto these neurons,

24:19.520 --> 24:24.520
and then you have weights, synaptic weights that you can scale up or down to come up with a learning rule.

24:24.520 --> 24:28.520
Well, in the conventional approach, you would look at this correlation and that correlation.

24:28.520 --> 24:32.520
You look at these pairwise correlations, you can make up a matrix and then make this examination.

24:32.520 --> 24:36.520
But what you're missing out on is the synergistic effect of these two neurons onto that neuron.

24:36.520 --> 24:40.520
So there could be a combined causal effect that you're missing by breaking up the system

24:40.520 --> 24:42.520
and just looking at the pairwise correlations.

24:42.520 --> 24:45.520
And so IIT doesn't do it. Why doesn't it do it?

24:45.520 --> 24:49.520
So here's an example of how the formalism of IIT works in practice.

24:49.520 --> 24:53.520
And the example is that you have a system with two buttons, A and B,

24:53.520 --> 24:58.520
and they basically have causal effects on, in this case, let's say another button C.

24:59.520 --> 25:06.520
So the idea is that we're looking at if button A and B are inactive.

25:06.520 --> 25:09.520
So in this case, shown here in white, so they're not being pushed.

25:09.520 --> 25:15.520
What does that mean for the state of this causally affected system C?

25:15.520 --> 25:21.520
And so you can empirically do that by just taking a system and looking at what's happening.

25:21.520 --> 25:25.520
So let's say you're taking many, many trials, as we often do 100 trials,

25:25.520 --> 25:29.520
and you see what happens if A and B are un-pushed and what happens to C.

25:29.520 --> 25:35.520
And so you see that in this case, in 90% of the cases, C would also be off,

25:35.520 --> 25:37.520
and in 10% of the cases, C would be on.

25:37.520 --> 25:43.520
So this could be because of noise, this could be because of a whole lot of different mechanisms.

25:43.520 --> 25:47.520
And then the logic is to just step through all of the possible states.

25:47.520 --> 25:52.520
So you ask what happens if A is pushed, and you can see 90% again C is off,

25:52.520 --> 25:54.520
what happens if B is pushed, and here the interesting case,

25:54.520 --> 25:56.520
what if both of them are pushed at the same time?

25:56.520 --> 26:00.520
And so this, of course, some of you might have noticed already,

26:00.520 --> 26:05.520
leads to a table that has been used in statistics for a long time.

26:05.520 --> 26:08.520
That's what we call a transition probability matrix,

26:08.520 --> 26:11.520
or it's at the very heart of Markov-Chakes, yes.

26:11.520 --> 26:28.520
So there's a few things to say about that.

26:28.520 --> 26:32.520
So first of all, this technique works best if you do know the causal structure.

26:32.520 --> 26:39.520
So if you know that these have this kind of causal effect on C,

26:39.520 --> 26:42.520
but you don't need to know that, you can infer the causal structure

26:42.520 --> 26:44.520
just by looking at the statistics of the system.

26:44.520 --> 26:45.520
So you don't need to know that.

26:45.520 --> 26:47.520
And so if one of them would have, let's say,

26:47.520 --> 26:49.520
if you said a positive effect or negative effect,

26:49.520 --> 26:52.520
it also, again, would show up in the statistics that you're measuring that comes out.

26:52.520 --> 26:56.520
So the real big step that I'm doing right here that's questionable

26:56.520 --> 27:01.520
is that I'm moving from a frequentist observation to a statistical description of the system.

27:01.520 --> 27:05.520
But of course, that's something that a lot of statistics us all the time.

27:05.520 --> 27:09.520
But I'm arguing that you could observe a system, come up with that table,

27:09.520 --> 27:13.520
and then go on to describe the system.

27:13.520 --> 27:16.520
Other questions?

27:16.520 --> 27:19.520
Okay, so if you're with me on this, then you would agree that you can, of course,

27:19.520 --> 27:21.520
do this for a much more complex system.

27:21.520 --> 27:25.520
So right here, this would be four logic elements that are interconnected.

27:25.520 --> 27:28.520
These could be neurons, these could be voxels, these could be areas,

27:28.520 --> 27:30.520
this could be whatever you're interested in.

27:30.520 --> 27:34.520
And one more trick that I'm doing here is that rather than looking at

27:34.520 --> 27:36.520
how three of these elements interact with the fourth element,

27:36.520 --> 27:38.520
I'm taking the whole system.

27:38.520 --> 27:41.520
So I'm taking all of the possible states that this system could be in.

27:41.520 --> 27:44.520
All of these are on, three of these are on, none of these are on.

27:44.520 --> 27:48.520
And then what I'm doing is I'm taking a step forward in time.

27:48.520 --> 27:52.520
So I will call this the present, and then I'm taking a step forward in time,

27:52.520 --> 27:54.520
and I say, if this is the present state,

27:54.520 --> 27:59.520
what is the probability that I end up in any of these other possible states?

27:59.520 --> 28:02.520
So this is how I get a true transition probability matrix.

28:02.520 --> 28:05.520
In this case, the numbers are zero and one stone at the confuse you,

28:05.520 --> 28:07.520
this would be a deterministic system.

28:07.520 --> 28:10.520
But what we would be measuring most of the time would be fractions in here.

28:10.520 --> 28:13.520
So it would be fractional probabilities with which the system transitions

28:13.520 --> 28:15.520
from one state into the other state.

28:15.520 --> 28:19.520
And so one simple notion would be that this right here is the cause,

28:19.520 --> 28:21.520
and then this right here is the effect,

28:21.520 --> 28:26.520
because we're looking at what is causing what effect by making the jump into the future.

28:26.520 --> 28:30.520
How far you move from the present into the future, that's again up to you.

28:30.520 --> 28:34.520
So you could take a millisecond, eight millisecond, one TR, whatever you want.

28:34.520 --> 28:39.520
But you can look at how the system, depending on which state it is in,

28:39.520 --> 28:41.520
transitions into any of these other states.

28:41.520 --> 28:43.520
Yes.

28:43.520 --> 28:47.520
Using a Markovian assumption here, doesn't that presume the box,

28:47.520 --> 28:50.520
or neurons are going to have a memory of its property?

28:50.520 --> 28:54.520
Neurons are not memory of its state.

28:54.520 --> 28:56.520
Yes, great.

28:56.520 --> 28:59.520
I don't know if I have time to talk about that, but yes.

28:59.520 --> 29:03.520
So this is one of the first things I ran into, looking at actual data.

29:03.520 --> 29:10.520
So as you will see, maybe as I get to that, my argument is that if there's a memory in the system,

29:10.520 --> 29:16.520
then there's a certain expectation to what the transition probability matrix should look like.

29:16.520 --> 29:19.520
And we can actually use that to our advantage.

29:19.520 --> 29:24.520
For example, we can see if there's anything that deviates just from a system

29:24.520 --> 29:27.520
that has a simple form of memory, or it doesn't.

29:28.520 --> 29:31.520
Another question.

29:31.520 --> 29:33.520
So this right here is not the end of it.

29:33.520 --> 29:36.520
So this right here is not what I really mean by cause-effect structures.

29:36.520 --> 29:40.520
There's a second mathematical trick that's involved where you can break down

29:40.520 --> 29:45.520
each of these supposed cause-effect interactions in your data

29:45.520 --> 29:47.520
to look at which ones are actually causal.

29:47.520 --> 29:49.520
And that's maybe the part that I'm most excited about.

29:49.520 --> 29:54.520
So if I do this for my data, it turns out that most of these do not actually really have cause-of-power.

29:54.520 --> 29:56.520
That's what I find the most interesting.

29:56.520 --> 30:00.520
But you might already have noticed that by doing this kind of trick with your data,

30:00.520 --> 30:03.520
that you're already coming up with something that is really interesting to deal with.

30:03.520 --> 30:06.520
So by just taking your data and putting it in this kind of space,

30:06.520 --> 30:09.520
you come up with these very nice mathematical properties already.

30:09.520 --> 30:13.520
And so in fact, if you think about almost anything that we do in machine learning or big data,

30:13.520 --> 30:17.520
starts out with NP arrays like that, two-dimensional matrices.

30:17.520 --> 30:21.520
So I would argue that even if you're not interested in consciousness,

30:21.520 --> 30:24.520
there's lots of room to explore here for your data by using this approach.

30:24.520 --> 30:25.520
Yes?

30:25.520 --> 30:30.520
So does this work only if you assume that you have all the elements in the system,

30:30.520 --> 30:33.520
but what if there are other elements you're not measuring now

30:33.520 --> 30:38.520
and they could also play a third variable role?

30:38.520 --> 30:39.520
Yes.

30:39.520 --> 30:40.520
So it's another shortcoming.

30:40.520 --> 30:41.520
I totally agree.

30:41.520 --> 30:45.520
So ideally, you would have to do this for all the neurons in the brain at the same time.

30:45.520 --> 30:46.520
And so that's a type dream.

30:46.520 --> 30:51.520
And in fact, as I was showing a moment, it already gets problematic with the data that we have.

30:51.520 --> 30:55.520
But I would argue that when we do a Fourier transform,

30:55.520 --> 30:59.520
in fact, even when we do a simple average, we are violating some of the rules

30:59.520 --> 31:00.520
that apply to these algorithms.

31:00.520 --> 31:03.520
So if you do a Fourier transform, you should never do that on one of our data,

31:03.520 --> 31:05.520
whether the variance and the mean are changing over time.

31:05.520 --> 31:06.520
It should be stationary.

31:06.520 --> 31:09.520
And people that do it, they would say, well, it still works.

31:09.520 --> 31:14.520
And so I would say that even if you have a system where you have confounders

31:14.520 --> 31:18.520
that might be interacting with this as more hidden Markov chains, whatever you want to call it,

31:18.520 --> 31:20.520
you don't have the entire Markov blanket.

31:20.520 --> 31:23.520
It's still interesting to look at that system by making these assumptions.

31:23.520 --> 31:25.520
Yeah, of course it's interesting.

31:25.520 --> 31:28.520
Because when can you jump to the causal input?

31:28.520 --> 31:29.520
Yes.

31:29.520 --> 31:34.520
And so basically, my appeal would be that you can do them,

31:34.520 --> 31:37.520
but you have to take them with a grain of salt.

31:37.520 --> 31:39.520
Kind of like we do already with greater causality and other things.

31:39.520 --> 31:45.520
But yeah, so there's an imperfect match between what the theory and theory provides you

31:45.520 --> 31:48.520
and then what we as experimentalists can do with it in practice.

31:48.520 --> 31:50.520
But as I just said, I think there's other techniques.

31:50.520 --> 31:52.520
Granger causality, I think is a good one.

31:52.520 --> 31:56.520
That we violate stationarity, which is one of its main assumptions all the time.

31:56.520 --> 31:58.520
And yet we found interesting things with Granger causality.

31:58.520 --> 32:00.520
And I'm just talking, there's a different way of doing that

32:00.520 --> 32:06.520
that goes away from pairwise considerations of causality to multi-dimensional ones.

32:06.520 --> 32:08.520
Great questions.

32:08.520 --> 32:10.520
Okay, so let's talk about actual data.

32:10.520 --> 32:14.520
So what my lab is mostly interested in are neural circuits.

32:14.520 --> 32:18.520
And the system that we've been choosing for that are the neural circuits

32:18.520 --> 32:21.520
that they of course have the property that Isabel just mentioned,

32:21.520 --> 32:24.520
that they do get inputs from outside the system,

32:24.520 --> 32:28.520
but they are well-structured circuits and they exist across the layers of cortex.

32:28.520 --> 32:30.520
And so one reason that they're interesting is that

32:30.520 --> 32:33.520
technology has made huge jumps in the last couple of years

32:33.520 --> 32:37.520
in order to allow us to measure neuronal activity across the layers of cortex.

32:37.520 --> 32:40.520
So this of course is a commercial approach to that,

32:40.520 --> 32:45.520
but some people don't know yet that these kinds of electrodes that Elon Musk is using

32:45.520 --> 32:48.520
for his company, they're actually readily available down in my office

32:48.520 --> 32:50.520
if you want to see them to research scientists.

32:50.520 --> 32:53.520
So Elon of course is trying to do this in humans.

32:53.520 --> 32:55.520
What does Elon have to say?

32:55.520 --> 32:58.520
Electrons in human brains are the future.

32:58.520 --> 33:00.520
You might get one some time as well.

33:00.520 --> 33:03.520
So thanks to the fact of machine learning we can do these things.

33:03.520 --> 33:06.520
But we use these kinds of electrodes.

33:06.520 --> 33:08.520
So silence, Elon.

33:08.520 --> 33:11.520
We use these kinds of electrodes to measure along the layers of cortex

33:11.520 --> 33:15.520
to get at what we think is a cortical column in the system.

33:15.520 --> 33:19.520
And then we have these simultaneous measurements of neurons or population activity,

33:19.520 --> 33:23.520
and so I'm trying to get to the causal effect structure of these.

33:23.520 --> 33:26.520
So here's the first bad news.

33:26.520 --> 33:29.520
So if you take this again could be voxels or areas,

33:29.520 --> 33:32.520
in this case it's electrode channels of these arrays where we can make these measurements,

33:32.520 --> 33:35.520
and you look at the size of the transition probability matrix,

33:35.520 --> 33:38.520
of course you run into a combinatorial explosion.

33:38.520 --> 33:41.520
So for most of what I will show today I will be stuck at six channels

33:41.520 --> 33:43.520
because my laptop got stuck at six channels.

33:43.520 --> 33:47.520
So if we go up to electrodes that my lab has been using ten years ago,

33:47.520 --> 33:52.520
you already get to numbers that are twice as large as the number of atoms in a cell.

33:52.520 --> 33:56.520
And then this right here is what my lab will be using hopefully in a week from now

33:56.520 --> 34:01.520
and you can see that we're reaching numbers that are absolutely beyond astronomical.

34:01.520 --> 34:06.520
Again, I feel at first when I hear these limitations of the theory

34:06.520 --> 34:09.520
I feel at first maybe a little bit depressed or discouraged,

34:09.520 --> 34:13.520
but then you go and you watch some YouTube talks again about quantum computing

34:13.520 --> 34:15.520
and the leaps that are being done there,

34:15.520 --> 34:17.520
and I think that these kinds of problems are technical problems.

34:17.520 --> 34:20.520
I think that they're solvable in the long run.

34:20.520 --> 34:25.520
There are 10 to the 80 atoms in the universe.

34:25.520 --> 34:27.520
Yeah, I know there's a way more...

34:27.520 --> 34:30.520
The magnitude more than there are atoms in the universe.

34:31.520 --> 34:34.520
This is just one electrode with two other channels.

34:34.520 --> 34:36.520
So when we're talking about measuring all the neurons in the brain,

34:36.520 --> 34:39.520
you see where the theory runs into serious problems.

34:39.520 --> 34:42.520
But as I said, I think these are technical limitations

34:42.520 --> 34:46.520
and also there's other ways to dimensionality reduce

34:46.520 --> 34:48.520
before you maybe apply the theory.

34:48.520 --> 34:51.520
So let's use six measurements of the brain simultaneously

34:51.520 --> 34:54.520
and I will use this graphic to show you all the 64 states

34:54.520 --> 34:56.520
that are possible for these six measurements.

34:56.520 --> 34:58.520
So all of them on, all of them off.

34:58.520 --> 35:02.520
So if these are neurons, on or off is easy to understand.

35:02.520 --> 35:05.520
This might be a neuron firing an action potential, not an action potential.

35:05.520 --> 35:09.520
But most of us, we're not using neurons, I'm not using neurons here.

35:09.520 --> 35:12.520
So what I'm doing is I'm basically binarizing the data.

35:12.520 --> 35:14.520
So you can just take your data, take a trial,

35:14.520 --> 35:16.520
you take the average activity of your trial.

35:16.520 --> 35:19.520
This might be just your fMRI signal, your EG signal, whatever you have.

35:19.520 --> 35:21.520
And then you just say what's above and below.

35:21.520 --> 35:24.520
And whenever it's above, I'm going to call it a non-state

35:24.520 --> 35:26.520
and whenever it's below, I will call it an off-state.

35:26.520 --> 35:29.520
And so the on-states, I make black and the off-states, I turn white.

35:29.520 --> 35:30.520
So I just binarize the data.

35:30.520 --> 35:34.520
The theory would still work if I break it down into four different states, or three.

35:34.520 --> 35:38.520
So it just gives you a larger matrix, more states to work with.

35:38.520 --> 35:45.520
So what does it look like for having 64 states of actual neuron data?

35:45.520 --> 35:49.520
And I would look at them in the present and then I would look at them in the future.

35:49.520 --> 35:51.520
Well, it gives us a matrix, a transition probability matrix,

35:51.520 --> 35:55.520
where you can see that the color here shows the probability of the system

35:55.520 --> 35:57.520
going from one state into the other.

35:57.520 --> 35:59.520
And you can already see that there's an interesting structure,

35:59.520 --> 36:01.520
most prominently, that the system has memory.

36:01.520 --> 36:04.520
So the system likes to stay in its own state.

36:04.520 --> 36:08.520
And the first interesting analysis that I would propose here is

36:08.520 --> 36:11.520
you can use this for your data and then you can play with the time.

36:11.520 --> 36:16.520
You can see how much do I have to move until the system moves out of its original state.

36:16.520 --> 36:20.520
When I do that for my neural data, I find that it is roughly on the order of one synapse.

36:20.520 --> 36:25.520
So if I go past it, then the system automatically starts to go into more interesting states.

36:25.520 --> 36:28.520
You might also feel that this is not an interesting way to look at the data.

36:28.520 --> 36:31.520
So what I would propose is that each time we have a matrix like that,

36:31.520 --> 36:33.520
we can apply graph theory.

36:33.520 --> 36:36.520
So we can take each of these states as a node in graph theory space,

36:36.520 --> 36:41.520
and then the causal interactions, the probability that the state moves from one to another,

36:41.520 --> 36:45.520
we can take as the thickness of the edges between the graph.

36:45.520 --> 36:49.520
So if I do this, for the matrix that I just showed you, it becomes very hard to even visualize.

36:49.520 --> 36:51.520
So let me make it even more simple.

36:51.520 --> 36:54.520
So what I would do now is take three measures of the brain,

36:54.520 --> 36:56.520
and I would do this in the upper, middle, and lower layers of cortex.

36:56.520 --> 36:58.520
So there's only three states.

36:58.520 --> 37:01.520
So all of them are inactive, all of them are active,

37:01.520 --> 37:06.520
and then you can see how the system transitions from one state to the next state.

37:06.520 --> 37:09.520
One thing that's interesting here, I think from a cognitive neuroscience perspective,

37:09.520 --> 37:11.520
is that you see these loops.

37:11.520 --> 37:15.520
So again, this is the system having a certain likelihood to end up in its own state again.

37:15.520 --> 37:18.520
So in a way, you can think of this as feedback.

37:18.520 --> 37:23.520
Well, you can already see that feedback is more likely for some states than for other states.

37:23.520 --> 37:28.520
And you can, again, play around with, for example, the time that you take in between these measurements,

37:28.520 --> 37:30.520
and you can investigate.

37:30.520 --> 37:33.520
Some of the feedback loops, they might become thinner or go away,

37:33.520 --> 37:36.520
and then as you look further into your data, they might reemerge,

37:36.520 --> 37:38.520
as feedback re-enters the system that you're looking at.

37:38.520 --> 37:39.520
Yes, Gordon?

37:39.520 --> 37:42.520
Why is that a feedback loop and not just like...

37:42.520 --> 37:43.520
Or memory.

37:43.520 --> 37:44.520
Yes, yes.

37:44.520 --> 37:46.520
I should be more careful how I phrase these things.

37:46.520 --> 37:47.520
I'm totally agnostic about it.

37:47.520 --> 37:49.520
So the system could just persist.

37:49.520 --> 37:50.520
Could just be history.

37:50.520 --> 37:51.520
Yes.

37:51.520 --> 37:52.520
I think it would be feedback.

37:52.520 --> 37:55.520
It would be easier to argue if you look at that as a function of time,

37:55.520 --> 37:57.520
and it disappears and then reappears again.

37:57.520 --> 38:00.520
That would maybe show that there's some reverberance going on.

38:00.520 --> 38:02.520
But yeah, that's a great point.

38:02.520 --> 38:10.520
And so I'm cutting a long story short of looking at these transition probability matrices

38:10.520 --> 38:14.520
in these actual graph structure.

38:14.520 --> 38:15.520
It does show you...

38:15.520 --> 38:18.520
When I looked at my lab's data, it does show you a lot of interesting structures.

38:18.520 --> 38:20.520
So for example, the question before,

38:20.520 --> 38:22.520
what if the system has a very strong memory?

38:22.520 --> 38:26.520
Well, we do know that a lot of the neural data is one over F distributed,

38:26.520 --> 38:28.520
so it does have memory over time.

38:28.520 --> 38:33.520
And so what I found is that if I compare this actual neural data to a system

38:33.520 --> 38:37.520
that I artificially produce, where I have control over these variables,

38:37.520 --> 38:41.520
and I can't just introduce correlations however strong I want them

38:41.520 --> 38:43.520
between the data or causal directions,

38:43.520 --> 38:45.520
or I completely uncorrelated the system,

38:45.520 --> 38:50.520
then I do find that there's a stereotypical pattern right here.

38:50.520 --> 38:52.520
And as I said before, we could use this as a baseline.

38:52.520 --> 38:55.520
We could say, well, that is what an uncorrelated system looks like,

38:55.520 --> 38:58.520
and any deviation from that would be a more interesting deviation.

38:58.520 --> 38:59.520
Yes?

39:06.520 --> 39:08.520
That's basically what I just said.

39:08.520 --> 39:12.520
I mean, you can take artificial data and you can uncorrelated it.

39:12.520 --> 39:15.520
And so I took it out because I want to use the rest of the talk

39:15.520 --> 39:17.520
to get at the maybe most interesting part.

39:17.520 --> 39:19.520
But if you take a system that's completely uncorrelated,

39:19.520 --> 39:21.520
you end up with a structure that's called the Hamming Distance.

39:21.520 --> 39:25.520
And so the Hamming Distance is that the transition probability of a system

39:25.520 --> 39:31.520
that's in 001 to go to 001 should be higher

39:31.520 --> 39:35.520
than the transition probability from a system to go from 001 to 111,

39:35.520 --> 39:37.520
because more has to change.

39:37.520 --> 39:39.520
The system is more likely to end up in this state than in that state.

39:39.520 --> 39:43.520
And so that you can measure, it comes out as the Hamming Distance,

39:43.520 --> 39:46.520
a very well-characterized geometrical space.

39:46.520 --> 39:49.520
And so you can either use it as a matrix, or you can use it as a graph,

39:49.520 --> 39:52.520
and then you can take any kind of distance that you like

39:52.520 --> 39:54.520
between multidimensional sets of data,

39:54.520 --> 39:57.520
the mahalano-bisterstand, euclidean norms, anything like that,

39:57.520 --> 40:00.520
to see how far it differs.

40:00.520 --> 40:04.520
Okay, so this is just the first step of integrated information theory,

40:04.520 --> 40:06.520
but you can maybe see why I'm already excited about that.

40:06.520 --> 40:09.520
As an experimentalist, we tend to look at new tools

40:09.520 --> 40:11.520
that might allow us to look at our data in new ways,

40:11.520 --> 40:13.520
and I think this is what it does.

40:13.520 --> 40:15.520
And so all of us might have this feeling that Galileo had maybe

40:15.520 --> 40:17.520
when for the first time he was able to look for a telescope,

40:17.520 --> 40:20.520
and he discovered things out in the solar system that haven't been seen before.

40:20.520 --> 40:23.520
So I'm not arguing this as Galileo's telescope,

40:23.520 --> 40:26.520
I'm just saying that here's another interesting tool to look at your data

40:26.520 --> 40:29.520
that might be worth your time and more consideration.

40:29.520 --> 40:31.520
But there's more to it.

40:31.520 --> 40:34.520
So what I said in the beginning is that integrated information theory

40:34.520 --> 40:38.520
severs some of these causal connections and see what the system does.

40:38.520 --> 40:42.520
And so that rests on something called due algebra

40:42.520 --> 40:47.520
that was introduced to the field actually decades ago already by Julia Pearl.

40:47.520 --> 40:49.520
So that's a tool of statistics.

40:49.520 --> 40:51.520
And so again, I'm not going to do it justice, of course,

40:51.520 --> 40:53.520
in the short amount of time that I have,

40:53.520 --> 40:55.520
but I'm just going to give you the general idea.

40:55.520 --> 40:57.520
So if you have a very simple statistical system,

40:57.520 --> 41:01.520
so say you have one variable and you're interested in its effect on the other variable,

41:01.520 --> 41:03.520
and you have a confounding variable that affects both.

41:03.520 --> 41:07.520
That's a very common statistical problem because if you just do a correlative approach,

41:07.520 --> 41:10.520
this right here causes huge pain.

41:10.520 --> 41:13.520
And so we call this a fork in a causal statistical sense.

41:13.520 --> 41:21.520
So what Julia Pearl said is that we can get at the causal effect right here

41:21.520 --> 41:25.520
beyond the correlative approach using his due calculus.

41:25.520 --> 41:27.520
So what is this magical approach?

41:27.520 --> 41:31.520
Well, we know as scientists that in order to find causality,

41:31.520 --> 41:33.520
you have to make interventions.

41:33.520 --> 41:36.520
You have to intervene into the system and then you see causal effects.

41:36.520 --> 41:41.520
What due calculus allows you to do is to intervene into the system without physically doing so.

41:41.520 --> 41:44.520
So you're intervening it statistically, if you will.

41:44.520 --> 41:46.520
So how do you do that?

41:46.520 --> 41:51.520
Well, if you think of this system described in a similar way as I just did,

41:51.520 --> 41:54.520
where you know the transition probabilities between each of these states of the system.

41:54.520 --> 41:57.520
So you have a full statistical description of the system,

41:57.520 --> 41:59.520
and you also know the causal graph.

41:59.520 --> 42:01.520
So you know the causal connections.

42:01.520 --> 42:08.520
What you can do is you can computationally keep one of these variables constant or manipulated

42:08.520 --> 42:10.520
and then study the effect on the whole system.

42:10.520 --> 42:13.520
So in this case, if you keep this variable at a certain value,

42:13.520 --> 42:15.520
you're severing this connection.

42:15.520 --> 42:19.520
Now this variable right here, the confounder, can't affect this one anymore

42:19.520 --> 42:20.520
because you're keeping it constant.

42:20.520 --> 42:21.520
It can't change.

42:21.520 --> 42:23.520
So whatever this guy does, it doesn't affect this guy.

42:23.520 --> 42:24.520
Does it make sense?

42:24.520 --> 42:26.520
It can still affect this guy, but it can't affect this guy anymore.

42:26.520 --> 42:28.520
So you're making an intervention.

42:28.520 --> 42:31.520
And you're also doing what I just said, you're mutilating the system

42:31.520 --> 42:34.520
by getting rid of one of the causal connections.

42:34.520 --> 42:38.520
So you're different in targeted attack analysis in graph theory?

42:38.520 --> 42:42.520
No, I think it's out of my wheelhouse, but it might be very similar.

42:42.520 --> 42:44.520
So let me give you a concrete example.

42:44.520 --> 42:49.520
So if you have a simple transition probability matrix,

42:49.520 --> 42:54.520
so in this case you have only two different parts of the system,

42:54.520 --> 42:57.520
and they're either both off, one is on, the other's on, or both are on.

42:57.520 --> 43:00.520
And then you look at t plus some point in the future,

43:00.520 --> 43:02.520
and you look at the transition probabilities,

43:02.520 --> 43:04.520
and you want to make this intervention.

43:04.520 --> 43:07.520
So you want to mutilate the system.

43:07.520 --> 43:13.520
So what you can do is you can disconnect the system through what,

43:13.520 --> 43:16.520
in this case, would be called statistical noising or marginalizing.

43:16.520 --> 43:20.520
So in this case, let's say the first element we want to get rid of.

43:20.520 --> 43:23.520
And so what you can see right here is that in this case,

43:23.520 --> 43:26.520
in that case, if we eliminate it or eliminate it,

43:26.520 --> 43:30.520
it comes out as basically just averaging these two states together,

43:30.520 --> 43:34.520
because this is zero zero, so let's average where the second one is in zero,

43:34.520 --> 43:36.520
and you get this transition probability,

43:36.520 --> 43:38.520
or in this case the second element is one and one.

43:38.520 --> 43:42.520
So we don't care about this anymore, so we just average that and we come out at point five.

43:42.520 --> 43:44.520
So you come up with a new transition probability matrix

43:44.520 --> 43:47.520
where you artificially intervene and you took out part of the system.

43:47.520 --> 43:51.520
Now this transition probability matrix is different than this transition probability matrix.

43:51.520 --> 43:56.520
So if you look at the transition probabilities,

43:56.520 --> 44:00.520
it looks like you severed something that you shouldn't have.

44:00.520 --> 44:02.520
There's a causal effect in the system.

44:02.520 --> 44:05.520
If you would have done this and it would be exactly the same outcome,

44:05.520 --> 44:09.520
then what you just severed, what you artificially intervened,

44:09.520 --> 44:10.520
didn't have an effect.

44:10.520 --> 44:13.520
And you can basically eliminate it in this approach.

44:13.520 --> 44:14.520
Yes.

44:14.520 --> 44:15.520
Can you go back one?

44:15.520 --> 44:16.520
Yeah.

44:16.520 --> 44:20.520
So you started describing this by saying, assuming you know.

44:20.520 --> 44:21.520
Yeah.

44:21.520 --> 44:26.520
But, I mean, this is a very simple third variable problem.

44:26.520 --> 44:29.520
I mean, we definitely want it now, usually.

44:29.520 --> 44:30.520
Yeah.

44:30.520 --> 44:34.520
And simple, just with three variables,

44:34.520 --> 44:37.520
trying to figure out what's needed and what,

44:37.520 --> 44:42.520
I mean, we can't turn this into correlation and complication with three.

44:42.520 --> 44:46.520
What aspect of this is fixing that problem?

44:46.520 --> 44:47.520
Yeah.

44:47.520 --> 44:51.520
So two responses that, again, you might not find satisfactory.

44:51.520 --> 44:55.520
So the first one is that I would say, we just make that assumption again.

44:55.520 --> 44:58.520
In this case, if you're looking at an individual column,

44:58.520 --> 45:00.520
we're just going to assume that it's closely close

45:00.520 --> 45:02.520
and we're just going to make these assumptions.

45:02.520 --> 45:04.520
So we know, for example, that the middle layer is connected to the upper layers

45:04.520 --> 45:06.520
and the upper layer is connected to the lower layer.

45:06.520 --> 45:09.520
So we can come up with a very simple graph like that.

45:09.520 --> 45:11.520
And we know that there's assumptions and maybe even violations in there.

45:11.520 --> 45:13.520
But we can still use it as a model.

45:13.520 --> 45:17.520
And every model has a shortcoming to look at the data.

45:17.520 --> 45:20.520
But I would agree with you that's problematic.

45:20.520 --> 45:23.520
So what's the other response that I have to that?

45:23.520 --> 45:26.520
Well, these electrodes, those are very specific response, maybe,

45:26.520 --> 45:28.520
to those of us that are doing neurophysiology.

45:28.520 --> 45:32.520
Those electrodes that we have, they now allow you to actually look at connected neurons.

45:32.520 --> 45:37.520
So you're getting 100 neurons at a time and you can look at the correlation of the activity

45:37.520 --> 45:40.520
and you'll find neurons that always basically fire together

45:40.520 --> 45:44.520
with a little lack of, let's say, four milliseconds or so.

45:44.520 --> 45:49.520
So that means that you can establish very simple systems,

45:49.520 --> 45:52.520
in this case, something like this, where you have interconnected neurons

45:52.520 --> 45:56.520
and you're not making any major violations.

45:56.520 --> 46:03.520
This having said, yes, the whole theory, if you take the theory at heart

46:03.520 --> 46:07.520
and if your end goal is to find out if the system is conscious,

46:07.520 --> 46:09.520
how much it is conscious, what the conscious states are,

46:09.520 --> 46:13.520
you would have to do this for maybe all of the neurons at the brain

46:13.520 --> 46:14.520
measured at the same time.

46:14.520 --> 46:18.520
In fact, the people that talk about the theory, they would admit that it could be worse.

46:18.520 --> 46:21.520
It could be that it's not the neurons that matter but the synapses.

46:21.520 --> 46:24.520
And we would have to measure all of the synapses at the same time.

46:24.520 --> 46:28.520
But it could also be that that isn't what is the physical basis

46:28.520 --> 46:32.520
of what gives rise to phenomenology and areas is the way to go, or columns.

46:32.520 --> 46:34.520
We don't know what the right level is.

46:34.520 --> 46:37.520
And so what they are arguing is, I think what is a part of the research program,

46:37.520 --> 46:42.520
is to compute these different values on these different spatial and temporal scales

46:42.520 --> 46:43.520
and see where it peaks.

46:43.520 --> 46:48.520
So, but yes, there are, as with any technique, there's a chasm here

46:48.520 --> 46:52.520
between the theoretical foundations and then how we can use it.

46:52.520 --> 46:58.520
And so my appeal is take it with a grain of salt, but just give it a try.

46:58.520 --> 47:00.520
Violate the assumption and see what happens.

47:00.520 --> 47:04.520
So here's maybe the good transition why I think that might be interesting.

47:04.520 --> 47:07.520
So this right here is actual data from my lab.

47:07.520 --> 47:13.520
And so in blue and in red, you see these are basically neuronal activation.

47:13.520 --> 47:17.520
While the animal in this case is just fixating at the screen, nothing is happening.

47:17.520 --> 47:20.520
Then a stimulus comes on and then in blue, the animal pays attention.

47:20.520 --> 47:23.520
And in red, the animal does not pay attention.

47:23.520 --> 47:28.520
And so we're measuring activity across the layers in this case of area before.

47:29.520 --> 47:32.520
And so there's two things that I want to point out.

47:32.520 --> 47:37.520
So this right here are these representations and graph theory that I just told you about.

47:37.520 --> 47:40.520
These down here are just two of the Pearson correlation coefficients

47:40.520 --> 47:45.520
between the matrices that are underlying, in this case, the red versus the blue state.

47:45.520 --> 47:50.520
And so if the animal is just fixating and nothing is going on,

47:50.520 --> 47:55.520
and I'm computing the phi value, which would be about the level of consciousness in this case,

47:55.520 --> 47:57.520
you can see it's pretty low.

47:57.520 --> 47:59.520
And then when the stimulus comes on and I'm computing the phi value,

47:59.520 --> 48:02.520
making all of these assumptions, you can see it's going up.

48:02.520 --> 48:07.520
So despite all of these assumptions being violated, the theory still seems to hold.

48:07.520 --> 48:09.520
The really interesting part is right here.

48:09.520 --> 48:12.520
If I compute phi versus the state where the animal pays attention,

48:12.520 --> 48:15.520
it's the highest versus if the animal doesn't pay attention,

48:15.520 --> 48:18.520
it sinks even below the baseline value,

48:18.520 --> 48:22.520
as you might expect if the animal is now sucking up all of the attention

48:22.520 --> 48:26.520
to one part of the field rather than widely distributing it.

48:26.520 --> 48:32.520
So this is just one example that the summer break allowed me to do

48:32.520 --> 48:35.520
by getting into my own data and doing MATLAB.

48:35.520 --> 48:39.520
They got me excited because I just put the theory to its test.

48:39.520 --> 48:43.520
I held its feet to the fire and it did what it was supposed to do.

48:43.520 --> 48:46.520
Now, of course, there's many more of these examples in the literature.

48:46.520 --> 48:50.520
So it seems that most of the tests to the fire have so far held true.

48:50.520 --> 48:53.520
The original idea, as I told you guys, was this,

48:53.520 --> 48:55.520
that we're not just getting at the level of consciousness,

48:55.520 --> 48:57.520
but at the contents of consciousness.

48:57.520 --> 49:01.520
So in order to do that, we have to take another step.

49:01.520 --> 49:05.520
And so this step is a transition from integrated information theory,

49:05.520 --> 49:07.520
as you know it, as I've just introduced it,

49:07.520 --> 49:11.520
which got published as Integrated Information Theory 3.0.

49:11.520 --> 49:14.520
It's actually the third revision of the theory.

49:14.520 --> 49:19.520
Now, Integrated Information Theory 4.0 is about to come out next year, I've been told.

49:20.520 --> 49:23.520
But all of the math, most of the math has already been developed

49:23.520 --> 49:27.520
and computer code is available for free on the internet

49:27.520 --> 49:30.520
so that you can already run your data for Integrated Information Theory 4.

49:30.520 --> 49:33.520
What is interesting about Integrated Information Theory 4?

49:33.520 --> 49:37.520
Well, it comes up with a new way to come at that cause-effect structure.

49:37.520 --> 49:39.520
Sorry about that.

49:39.520 --> 49:41.520
I slug it in at a time.

49:41.520 --> 49:44.520
So what it does, it basically takes what I just said

49:44.520 --> 49:47.520
in terms of looking at these causal interactions,

49:47.520 --> 49:50.520
but rather than just looking at the states of the system,

49:50.520 --> 49:52.520
it becomes even more multi-dimensional.

49:52.520 --> 49:56.520
It now takes, you see, combinations of different states

49:56.520 --> 50:00.520
and the more measurements you have, the more come out of it

50:00.520 --> 50:03.520
and basically applies the same kind of logic,

50:03.520 --> 50:05.520
not just to the individual states,

50:05.520 --> 50:07.520
but the combinations of states in between.

50:07.520 --> 50:11.520
And so IIT 4.0 calls these relations

50:11.520 --> 50:15.520
and as I said, the math and the code has just been available for that.

50:15.520 --> 50:17.520
So just give you a brief insight again,

50:17.520 --> 50:20.520
just very little time that I had available to look into that.

50:20.520 --> 50:23.520
For this example that I've been showing a couple of times now

50:23.520 --> 50:26.520
of neural data recorded in the middle upper lower layers

50:26.520 --> 50:30.520
and I'm running this IIT 4.0 code to look at

50:30.520 --> 50:32.520
out of all these possible combinations,

50:32.520 --> 50:35.520
which one of those are irreducible, which one have actual cause of power.

50:35.520 --> 50:37.520
So one thing that's a little confusing is that

50:37.520 --> 50:39.520
we now move to different terminology,

50:39.520 --> 50:43.520
so A, B, and C would be in this case the different layers of cortex

50:43.520 --> 50:47.520
and you can see that only one of these layers turns out to have cause of power by itself.

50:47.520 --> 50:50.520
The other layers of cortex, they only act synergistically.

50:50.520 --> 50:54.520
But more surprisingly to me, most of the possible interactions

50:54.520 --> 50:59.520
that you can theoretically come up with in this multi-dimensional space

50:59.520 --> 51:00.520
turn out to be reducible.

51:00.520 --> 51:02.520
They actually turn out to be non-causal

51:02.520 --> 51:05.520
and I think that is very exciting for most of us that are interested

51:05.520 --> 51:07.520
in how do I deal with these massive amounts of data

51:07.520 --> 51:10.520
that I'm getting from fMRIEG, neurophysiology,

51:10.520 --> 51:14.520
and we can reduce the dimensionality of these data in a meaningful way.

51:14.520 --> 51:17.520
So rather than what a lot of techniques do these days,

51:17.520 --> 51:20.520
take an external perspective and saying I'm decoding the system,

51:20.520 --> 51:22.520
I'm looking into the system, what allows me to predict behavior,

51:22.520 --> 51:25.520
what allows me to post-dict the stimulus conditions.

51:25.520 --> 51:27.520
This is taking an intrinsic perspective and it's saying

51:27.520 --> 51:31.520
which one of the interactions in my data are important to the system.

51:31.520 --> 51:32.520
They actually matter.

51:32.520 --> 51:36.520
So I would argue this might be a way for us to get closer

51:36.520 --> 51:39.520
to understanding the system as it functions itself.

51:39.520 --> 51:43.520
So if you agree with me or if you have only slight disagreements,

51:43.520 --> 51:46.520
you can now see why this qualia structure approach

51:46.520 --> 51:48.520
is something that has gathered a lot of YouTube channels,

51:48.520 --> 51:52.520
a lot of fanfare, a lot of special issues and conferences.

51:52.520 --> 51:55.520
If not, you might feel, one more time.

51:55.520 --> 51:57.520
If not, you might feel like Albert Einstein

51:57.520 --> 52:01.520
that maybe we're going a little bit too far with the math

52:01.520 --> 52:04.520
and we should maybe stick a little bit closer to the data.

52:04.520 --> 52:07.520
In either case, I say the franais, merci.

