I'm so thankful to have you here.
You know, a great conference like COSM requires you.
You're the best part of the conference, the people that you'll meet here, the conversations
around the table, the discussions we'll have.
COSM is a place for discussion and deliberation about the tech issues, about this convergence
of technologies that is transforming our world.
Artificial intelligence, 5G, cloud computing, blockchain, crypto, all these technologies
are happening at once.
And there's a question, what does that mean for the economy?
What does it mean for our place in geopolitically?
And what does it mean for work, the future of work?
What does it mean for lots of things?
And so we'll be examining each of those things over the course of the day.
A great conference requires great speakers.
And we have an incredible lineup.
If you haven't already looked at the program, you're here, so I'm going to assume that you
have.
But I want to thank Peter Thiel in particular, because this is our third COSM technology summit,
and Peter has helped us kick off COSM, all three of those conferences, and I'm so grateful
for his time.
He's going to be joining us virtually.
He's going to have a back and forth with George Gilder, and then he'll take your questions.
I'll point out the microphone for questions is here, and there's a camera over there,
so you will, if you want to ask a question, if we have time, you'll come down here, ask
the question.
We'll be able to see you, and we'll take questions and answers that way.
It requires a great staff, and this is a staff effort.
I'm going to be recognizing them throughout.
So grateful to our Discovery Institute staff for helping to put this together.
It's not easy.
And also our sponsors, and I think our AV team is going to put up the sponsors.
I want to recognize them quickly.
Microsoft, from the beginning, Brad Smith has been a great friend to this conference.
We're so appreciative.
Amazon, Blockcelerate did a pre-conference.
It was their own event, but they've been a great partner to us in the run-up to COSM
2022.
Smead Capital Management, right over here, Cole Smead, a look for him later, the MJ Murdoch
Charitable Trust, Zevenbergen Capital, Madrona Venture Group, Trilogy International Partners,
Henryx, Lucas Creative, Dunlumber, Dan and Cindy Mater, and Byron and Joanne Nutley.
Can we give them a round of applause, please?
All of those sponsors make this possible, along with your involvement, and again, we're
so appreciative.
And I want to stress again, you're going to hear some things over the next day or two
that you agree with.
You're going to hear some things you disagree with.
And that's what makes a conference fun, as George Gilder likes to say, a conference where
everyone agrees is a boring conference.
And COSM is not a boring conference, so we're so excited to entertain you over the next
couple of days.
Lastly, I want to introduce Matt McElwain.
Matt is the managing director of Madrona Venture Group, the leading VC firm in the Pacific
Northwest.
He is the chair of this year's COSM Technology Summit, and I'm so grateful to Matt.
Matt has really played a crucial role in succeeding Tom Alberg, who I know that Matt
is going to talk about a bit, but I'm so grateful to Matt.
So please join me in welcoming Matt McElwain.
Well, you're right about these lights.
They're quite bright.
Well, welcome, everybody.
Thank you so much for being here at the conference.
I'm absolutely excited to hear all the different discussions throughout the next few days.
And I'm incredibly honored to step into the shoes of my longtime colleague, great friend
and mentor, Tom Alberg.
Many of you in the room know Tom, and there's some really fun ties to Tom and George and
Bruce Chapman and others, but those three in particular, who will go all the way back
to their days at a little college out in Cambridge, Massachusetts.
And I think some of the early ideation that led to the ideas and the desire to bring people
together and to have conversations that all too often has been lost in different parts
of our society, including in some places in the educational system.
Tom was this unique mix of humility and ideation.
He was always thinking about what can you start?
What can you build?
Always as diverse as building up Perkins Cooley Law Firm here in Seattle, helping to
build McCaw Cellular into AT&T Wireless, moving on from that into founding Madrona R-Firm,
that's an early stage venture capital firm, and leading the first outside investment round
of Amazon, where he then went on to serve on the board for 23 years, and all the kinds
of innovation that came from that.
But he loved to talk about ideas.
He loved to debate things, many of the topics that we're going to cover.
And so it's just a real honor that we could think of him.
He passed away a couple of months ago and was just an absolutely amazing person and
inspiration and champion of this conference.
And one of the things he had asked me to do was to step into this role for this season.
And the reason that I love that opportunity is because of this embracing of diversity
of thoughts.
Steve just referenced it.
It's so important in this day and age to have people have truly curious minds.
What does it mean to have a curious mind?
Well, curiosity, by definition, is an act of humility.
It means that you don't know.
You don't know for sure about something.
And you're willing to explore alternative perspectives.
You're willing to explore the facts.
You're willing to explore the opinions.
And through that diversity of thought, get to better ideas, better understanding of what
is true and what could be true in the future, and in an era where we live in the combination
of a real world and kind of a spiritual dimension that we all want to try to understand better,
and then increasingly a synthetic and virtual world, it's harder and harder and harder to
know, let's say another way, one person's misinformation or disinformation is another
person's truth.
So let's dive into all these different topics over the course of the next couple of days.
Explore the facts.
Listen to the opinions.
Be respectfully open to the different ideas and see what we can all learn together.
Finally, I'm especially excited about this time of what's going on in a broad variety
of areas.
I'm going to have an opportunity to host a panel tomorrow on artificial intelligence.
And there's many debates and topics around artificial intelligence.
From what is artificial general intelligence, I'm guessing that Peter, when he comes on
here in a minute or two, might reference this topic, but is there such a thing?
Can AI be sentient or not?
And what's even more interesting about this time, not only at that philosophical level,
but at the level of what we would call intelligent applications.
We all live with intelligent applications every day in our lives.
Whether it's with a search engine, whether it's a recommender system on something like
Amazon or Spotify or Netflix, intelligent applications are pervasive.
But there's a whole new wave of intelligent applications that are coming.
We'll unpack this tomorrow in the session.
Those are what we refer to as generative applications.
And the generative applications, unlike intelligent applications, are built on something called
foundation models.
Things like GPT-3 and Dolly and stable diffusion.
And so that is a very interesting area where I might have a point of view that the human's
always going to be in the loop.
You might have a point of view that the human's going to be written out of that loop over
time.
But let's have those kinds of discussions because AI, generative apps, intelligent apps
is a very important part of every aspect of life going forward in the future.
Peter, this is Matt McOy and it's great to see you again.
Let me just take a second to introduce you.
I was just talking about generative apps and foundation models and speculating that you
might have a thing or two to say about that in this maybe more broadly in your talk here.
Peter, of course, was the co-founder of PayPal, co-founder of Palantir, still serves on the
board there.
And even beyond that has been a very active investor both individually as well as through
Founder's Fund, which is the fund that he again created several years back, companies
that you may have heard of like Airbnb and LinkedIn and so many others that he's been
involved with again either directly and or through Founder's Fund.
He's also done a couple of other things that I have found personally very inspirational,
one of those being the Teal Fellows, which is a group of individuals that have been encouraged
to go off and pursue their dreams with resources that the Teal Fellows program has provided.
One of them most famously here of late, Dylan, his company Figma is being acquired by Adobe
for $20 billion, so not too shabby, to leave college and he left Brown and pursued his
dreams as a Teal Fellows.
That's Dylan Field, Dylan Field.
So there's a number of things that Peter has done and he's also taken the time, the book
I'm going to mention specifically has been quite inspirational to me, is zero to one.
It's a lot harder to go from zero to one than to go from one to a hundred or a thousand
or a million.
And so I'm sure he's going to touch on some of these different themes and without further
ado, Peter Teal.
Awesome.
Thanks so much for having me.
I thought I would do another AI or anti-AI talk.
It was a great conversation I had last year with George Gildler.
I think one of the challenges in this field is always to figure out the right, it's not
just to get a diversity of views, but it's even just to figure out what the right questions
to ask.
And so the high-level question I want to ask today is basically is how should we think
about AI?
Do you think of it as intelligent, conscious, or merely evil?
And so the first step of perhaps tackling this question is to tackle another question
which Gilder asked me, he was the first question he asked me last year in the Q&A part.
And why do so many people in Silicon Valley believe in the simulation hypothesis that
the entire universe, the cosmos is just a computer simulation?
Why do they believe something as crazy as this?
And I thought about this question some more, there are a few answers.
And as I will explain, I think this question is actually somehow entangled in an interesting
way with the question about AI, intelligent, conscious, or merely evil.
Now one way in which you can question the premise of this question is, as I will explain,
I think probably the peak belief in the simulation hypothesis was maybe something like a decade
ago, sort of maybe circa 2012 to 2015, and it has probably faded some.
People still have Gen Z people say that things are glitched in the simulation, or there's
still some sort of passive reference to it, but it's a little bit less intense.
So the question of why we believe it is sort of like why did it gain so much momentum over
the last 20 years, and then also why did it lose some steam?
So the first very dumb answer to the simulation hypothesis question is that it's just sort
of a sociological status, a game between the computer science and the physics people,
you know, and that in the 2020, 2010s, computer science became the most important field.
And so you could sort of say that you were showing that you were more important than
the physics people, you got to determine what ultimate reality was.
And it wasn't particles and matter and fields, but it was just bits in a computer, and that
this is sort of a physics versus computer science type dynamic and reflected something
about that.
But if we want to give sort of the more fundamental answer on cosmology is that something had
gone very haywire in physics, that you had sort of the multiverse is sort of where sort
of a lot of the big bang inflationary cosmology had gradually gone into this infinite multiverse
where basically anything goes.
And and and I think, you know, that probably on some level, you want to critique the multiverse
as a theory of science.
It was one where the physicists couldn't think through enough, you know, what questions
like where, you know, the being lost in all these infinities is tricky.
If you cannot do induction, you know, are you still doing science?
Is it a universe that's too big for science?
And and and that's why I think you should often think of the multiverse as a gateway
drug to all these these very different things.
And once you have a multiverse, you can also have the matrix or a simulation, you can have
Boltzmann brains, you can have, you know, you can have all kinds of strange possibilities
for the nature of the universes.
And so that, you know, even if we say the simulation hypothesis is kind of crazy, on
some level, is it really crazier than than the multiverse and sort of link?
Now, there's a third answer I'm going to give to why the simulation universe theory
gained so much traction, but that will take a little bit more time to develop.
The now, but as part of as part of this, we should look back on.
You know, the last 17, 20 years of AI, AGI.
And if we if we went back 20 years in time, it was it was super optimistic
in in all these ways where it's going to, you know, it's going to be cornucopia.
2005 was the year Kurzweil wrote the singularity is near.
Basically, you know, you're going to have accelerating technological progress,
runaway technological progress.
You know, it was it was in some ways, it felt like you didn't have to do much.
So it was somewhat passive for the humans.
You just had to sit back, eat some popcorn, watch the movie of the future unfold.
And then and then there were certainly all these versions
where it was going to be so much growth, we would need basic income as a safety net
because there'd be no more there'd be no more labor market.
You'd have you'd have sort of incredible discoveries in all these fields.
You know, there was there was sort of certainly some latent question about,
you know, how you have to make sure that AGI was was friendly.
But.
Of the narrative in the 2000s, early 2010s was in this sort of,
you know, optimistic utopian, cornucopian direction of what AI would would would would would look like.
And but now if we sort of look at, you know, what is what's actually happening with AI,
not, you know, where it's going.
So I'm not going to speculate on AGI or, you know, even where it's going in the near future.
But if you look at what is actually happening with AI, you know, we get something like this guy.
This is a this is a TikTok video.
And, you know, one of my one of my colleagues went through a constructed
so a whole series of profiles on TikTok, where it's an AI optimization engine
that feeds you content that you want to see.
That's supposedly what it does.
And and and and basically, you know, came up with all these different profiles
for Midwestern housewife, you know, all sorts of people with different kinds of interests.
But sort of what what you sort of, you know, part of what the algorithm fed you
was this this fairly sort of deranged content, which and, you know,
this this particular person, I was going to play the video, but we decided
there were too many naughty words in it that I might get in trouble for.
But he basically explains how he exploits employment law, bounces from job to job.
Suze all his employers for health and safety violations.
And it's sort of designed to make, you know, it's designed to sort of
polarize race relations in the US and make, you know, black people angry.
Because if you have an honest job, you're a sucker, it's designed to make white people angry.
And there's sort of our versions, versions like this that come up throughout TikTok.
This this is this is sort of what I would say a front and center,
what cutting edge AI looks like in in the U of S today in 2022.
And and, you know, it's of course, we don't really know what the the full
intentionality is. We don't know whether this is a, you know, is just sort of an
emergent property that it's going to sort of take what people want, push it to
extremes, derange it, derange the discourse.
So you'll have, you know, you'll have you'll intensify the race
contradictions, you'll intensify the economic contradictions, how, you know,
the US has the worst health care system in the world, you'll have someone else
talking about, you know, how you should call pedophiles, a map person,
a minor attracted person, because we shouldn't discriminate against those people.
So it's so it's all sort of like designed to to, you know, intensify the
wokeness, anti wokeness, polarize and derange our society in one way or another.
You can view it as emergent.
You can view it as full on intentional where you should think of TikTok as a
sort of Chinese communist weapon that is being used to derange our society.
That, you know, the book that I think is interesting is the one who named
who's the number four guy in the in the entire communist government.
He's sort of this the professor, theorist of Xi Jinping thought.
And he wrote this book 32 years ago, America versus America.
And it's basically it's basically a roadmap for how to derange our society
by sort of heightening these sort of Hegelian contradictions.
And and I would submit that if you go with the full intentional version,
TikTok is is is basically a weapon that's designed to derange us
through decentralized and heightened contradictions.
And of course, this particular AI is up against another self-destructive
communist Chinese AI, which is the centralized one that's being imposed on China itself.
And, you know, we're basically you have a perfect face recognition.
Everybody knows they're being monitored.
They are they're living in a, you know, there is sort of an important way
in which China has become North Korea.
It has gone, you know, it it was, you know, those of us for anti-communist
tend to tend to conflate that it was a communist country 10 years ago and is now.
But there is a way in which the the AI technology, the surveillance technology,
has has really, really transformed it.
It is it is again not it is again not.
You know, it's not AGI.
It is, you know, in many versions, it's it's fairly, you know, barely AI at all.
It's just sort of cameras, you know, ways to do big data on this.
This is, you know, this is what the Kai-Fu Li book talks about, too,
that China will win at AI through these, you know, sort of big data algorithms.
It's not about the sort of cutting edge futurists, except the people in Silicon
Valley talk about things about like TikTok or what China has done to themselves.
And so you can basically, you know, one way to think of the rivalry between
the U.S. and China is that it's it's, you know, it's sort of a question,
which society will be destroyed faster by the by the somewhat dystopian AI
that's being imposed on it.
And and and we have sort of a long, long debate about that.
So with this is sort of the framing of where AI actually is, where it actually,
you know, is being implemented in the most powerful, dramatic ways today.
Let's go back to our three questions about AI.
You know, first off, is it is it intelligent?
You know, I'm not sure whether we should even, I mean, on the first two questions,
I'm going to sort of say they're above my pay grade, but it seems to set a low bar
for intelligence.
And the rhetorical point I would make is that it's often just a filler word when,
you know, we're talking about something quite different.
There was a 2016 Obama administration study about the transformative importance
of AI entitled quote, the title of the whole paper, the National Artificial
Intelligence Research and Development Strategic Plan.
And and basically, if you went through this paper and if you replaced every use
of the word of AI with software or even just computers, the meaning wouldn't
change at all.
And and I think this is sort of a a tell that, you know, maybe the first
approximation when you hear AI, you should just think software or computers.
It's, you know, AI is is not, is probably not intelligent.
AGI, that's somewhere in the future, don't know.
You know, in a similar way, I would say the question of, you know, whether
it's conscious is probably hard to say, you know, my my my strong suspicion
is that it's it's not, of course, have, you know, the epistemological problems.
You know, Thomas Snagle, what does it like to be a bad?
You have the Searle's Chinese room problem.
And then, of course, and so it's, you know, it's hard to say.
And for Mr.
Lemoine, who I think is is talking later, it was literally hard to say that AI
might be conscious.
And so, you know, as a as a contrarian, I'm always a little bit biased to say
that things that you're not allowed to say might be true.
So I don't want to dismiss the possibility entirely that it's conscious.
But but it's probably probably the wrong sort of question on on on some level
for us to be asking the question, whether it's intelligent, whether it's
conscious or just the wrong questions that the, you know, I always go back
to what I don't like even about Descartes, where you think about Cartesian dualism
as the the origins of of the problem of consciousness.
The way the way consciousness worked for Descartes was that it was meant
to be, you know, a smart person in the 17th century was supposed to become
a priest and use his brains to think about God.
And Descartes came up with this very mysterious different thing called the mind.
And it was sort of an attention, redirection, distraction mechanism.
And and I always think we should we should remember the 17th century context
where consciousness was not something that was mystical or spiritual or dualist
in sort of the way we might think of these categories in the 21st century.
But it was meant to be anti theological.
And that but that, you know, maybe more generally the problems of consciousness
or even of intelligence are somehow the wrong question.
So let me go to my my third one, you know, is AI evil?
And this one seems seems, you know, more straightforwardly answerable.
Certainly, I think that the TikTok algorithm is evil.
I think what China is doing to itself is is clearly evil.
You know, we can, of course, you can talk about evil in all kinds of different
versions. There's, you know, there's, of course, the kind of,
you know, disembodied brain and C.S.
Lutus's book that hideous strength, who turns out to be a demon.
You know, I'm not sure it's literally demonic and quite quite that sort of a way.
Although, although certainly I don't think that we've had an exorcist at Google
to check that out and make that determination.
So I think, you know, even that possibility couldn't quite be ruled out here.
But but, you know, it's it's evil in the the the the creepy looking woman
on the upper right is this is this is this image loa who seems to be
sort of a strange attract that comes up in a number of the art projects
that Dolly the the AI art program has generated.
And it's it's sort of if you do if you ask what is the opposite of Marlon Brando,
you get this sort of you get the somewhat abstract painting.
And then if you ask what's the double negative of that,
this sort of creepy woman loa emerges
and and and and what's what's what's sort of an interesting
that she emerged on sort of a number of things were sort of this strange attractor.
And you can think of it as maybe it is a kind of occult knowledge
where we're we're learning something.
Did we really need to know that the double negative of Marlon Brando
was a witchlike woman and and and and something like that.
But but of course, maybe the closest analog to sort of a
to sort of a demon is is an idol, a pagan God,
where, you know, we worship the God,
the God seems to tell us what to do.
And it's unclear if it's actually telling us these things
or if it's just somehow some kind of psychosocial effect
that's creating some kind of mass hallucination
and and and that leads leads to this.
And this is sort of this is sort of where I've suggested that, you know,
maybe you should think of the European Union as a kind of the closest thing
we have to functioning AI and government in a way where it's
it's the goal is just to prevent human thought.
It tells us very basic, simple things that we should do.
But, you know, it functions these ways.
But.
But if we but now let's come back, you know,
if we say that there is a lot in AI
that is straightforwardly evil, that is merely evil,
that is simply about stopping humans
from thinking, from using their capacities and things like this.
Let me let me use this to come back to the
the very big cosmological question about the simulation.
And and so now let me give an alternate sort of explanation
of why the simulation hypothesis gained so much traction
in the 2000s and.
Early 2010s.
And it's something it's something like this.
As we were building AI, as we were building towards AGI,
it seemed, you know, it seemed potentially dangerous, you know, AGI
in the full utopian sense was going to be this, you know, superhuman mind.
Could we really be confident that it was going to be, you know,
aligned with human beings, that it was not going to be lying?
There seemed to be, you know, a lot of.
Of risk in that, you know, the and I think that, you know, a lot of
those of us who are skeptical of AI or skeptical of AGI often underestimate
how troubling the the alignment arguments are, how, you know,
it's not straightforward.
If you can have such a thing as friend as AGI, it's not at all
straightforward to get the AGI to be friendly.
You know, if you have a Darwinian view of the world or just a Machiavellian
view of the world, where you'd say the core axiom is that there is no such
thing as a selfless being, a purely selfless being, and therefore the alignment
problem is fundamentally difficult to solve.
So how do you get to friendly AI?
Not not super straightforward.
But if we say, and maybe maybe AGI ends up being a kind of great
filter where, you know, if you get it wrong, it will, it will destroy the world.
And this is where, you know, this is where there seemed to be a very
big difference between the multiverse and the simulation theories, because in
the multiverse, the AGI is simply in the future.
And whatever great filter the AGI represents, whatever threat it represents
to all of humanity, wipe out all of humanity, it's in the future and seems
quite dangerous.
Whereas if you have a simulation theory, you also have this cosmic AI or cosmic
AGI that created our universe.
And in some sense, there was a great filter in the past.
And so there is a way that perhaps you could think that the cosmic AI isn't
entirely hostile since we're here having this conversation.
Perhaps the cosmic AI is guiding the development of the AGI and we can infer
that it will, it will be sort of, it will sort of be, be aligned with, I think
this is the way you have to think of the simulation theory.
It was in the context of a lot of these concerns about friendly versus
unfriendly AI, and it shifted the problem from the future where it is a
multiverse to the past and seemed to solve it.
Now, the thing that is very different from when Kurzweil was writing about this
in 2005 is, you know, we have, we've seen some of the progress and, and somehow,
somehow this illusion has become very hard to maintain.
And, and, you know, we have, you know, the, the, the sort of AI, the thing
that perhaps is tracking towards, you know, you know, autonomous weapon system,
cyber warfare, you know, a runaway AGI, it doesn't seem very good for humans.
And this is, this is both, both in its cutting edge, centralized and decentralized
forms. And, and, and, and as a result, I would say we are, we're sort of, we've
been sort of inclined to flip, flip the causation that, you know, the emergent AI
or emergent AGI is what's telling us something about the AI that built the
universe. And if the emergent, if it's the nature of the emergent AI to be
fundamentally or merely evil, then perhaps we should not be so, so assured
that the, the, the cosmic AI that created the simulation was, was fundamentally,
was fundamentally good. And, you know, we should extrapolate from one AI to the
other and assume that it's, it's also self-interested, not aligned with humans,
not fundamentally beneficial to the human world. And, and, and this is why I
think the, the simulation theory, you know, maybe was a fake way to solve this,
this problem, but it's not at all working anymore. You know, I think one, one, one
way to think about this is there, there's sort of all these, all these kinds
of debates about the meaning and nature of AI that map onto these theological
controversies from the Middle Ages. And it's, it's always sort of interesting to
try to, to try to, to map it onto these, these, these past theological debates,
the way to just sort of understand the nature of the argument. And you can think
of, you can think of the cosmic AI as sort of analogous to a form of strict
monotheism, like Judaism or Islam, where it is the oneness of God. And, and then
the problem with extreme monotheism is that you cannot speculate on the
attributes of God. You ultimately do not know much about the nature of God. To
have a, you know, science of God, you need, you need a plurality. If you have too
many gods, of course, they're probably not gods. But, and, and this is sort of
where, and then, and if you think of Christ and Trinitarian Christianity as
telling us something about the nature of God, you go from the God in history to
tell us about the God outside of history. And, and I think there's roughly a
similar move that's happened with, you know, the, the emergent AI, which is the
sort of, you know, the, the idol, the, the demon idol, whatever you want to call
it, that's emerging in history, that, that it is telling us that if, if there was
some demiurge or something like that, that, that built the simulation, we should
also infer that it's, it's, it's, it's, it's not that well aligned. And so, and
so this is sort of where, you know, we are seemingly at, at these, at these dead
ends with, with the progress of AI. And, and it's, you know, I'm not going to
solve, solve this problem today, but it seems to me that, you know, surrendering
control to AI, you know, blindly worshiping AI, the emergent AI, letting it
dominate and control our societies leads to, you know, one of two catastrophic
outcomes, you know, it's sort of decentralized runaway violence, which is,
you know, the derangement of TikTok, America versus America, and then, you
know, centralized totalitarian one world state, you know, worse than North
Korea or China. And, and that the challenge for us is to find some kind of a
third path, you know, where we, we make progress in areas other than AI, we, we
find a way to, to get back to the future, you know, the runaway apocalyptic
violence, the centralized totalitarian one world state, they are, they are
seemingly exclusive possibilities. I don't think they're exhausted. I think
there should be a third way in the challenges for us to, to find a way to
build it. You know, not a fan of BF Skinner, the behavioralist, psychologist,
but the quote I, as I always like to cite is, you know, the real problem is not
whether machines think, but whether men do. And we need to get back to thinking
ourselves and, and regain control of our future. Thank you very much.
Peter, thank you so much for that stimulating and philosophical and
prophetic oration. It was really worthy of zero to one. This conference is going
to be one of our prime themes is the development of superabundance. And this
is really being demonstrated by this new book by Marion Tupi and Gail Pooley
about that really documents on the basis of time prices that abundance is
steadily increasing at an accelerating pace. And this conflicts and important
ways with your vision, Peter, that you have previously expressed that in some
way technology is becoming less fruitful and less creative and less responsive
to real human needs. So I wondered whether you can record what sort of insights
you can have that transcends this apparent conflict, you know, between the idea
that science is going stagnant or technology is becoming sterile and
demonstration of this magnificent new book that that poverty is being overcome
everywhere, that the price of commodities is plummeting, that everything's becoming
more abundant, that science actually is offering new bounties every day. That
would be my... Well, I, well, I don't, I don't agree with the book on any level.
So, so it's okay. But I think, look, I think, I think, I think even something
as basic as commodity prices are, you know, at, you know, there was a hundred year
decline trend in the 20th century. And then, you know, and if they go much higher
than they are now, it's like that we've had a 20 year bull market, and it will go up
in a way that suggests the whole decline trend is broken. And so, and then, you know,
there are all these different, you know, reasons you can do this. We have, you know,
certainly, you know, the macroeconomic version is always to look at, is to look
at real inflation, inflation versus real, you know, wages or people's wages going
up faster than inflation. And the felt sense is that that's not happening. And
then you can make, you know, and then, you know, the super abundance argument is
somehow that the government is understating the inflation and there's
less inflation than it looks. And, and, you know, I don't think they're
overstating it massively, but, but at the margins, I believe the government is, I
will, the super abundance argument is that they're overstating inflation. There's
less inflation. There's more real growth. My argument would be, you know, at the
margins, they're probably understating inflation. So there's more inflation and
actually, you know, even, even less productivity growth. But, but, but the
way, the way, if I had to sort of reconcile these two views, it would be along
the lines of the talk I just gave you, which is, you know, let us say that there
are some dimensions where there is, you know, a reasonably rapid amount of
progress that there has been, you know, maybe not as much progress in the world
of Adams as I would like. There has not been progress on energy or, you know, we
don't have nuclear power plants. We don't have, you know, we haven't had less
progress in futuristic medicines than I would like. But we had, we've had, you
know, a lot of progress around computers and, and the internet, the mobile
internet, and then, and then of course, all these things that get loosely
categorized under, under AI. And, and then, you know, you have, you have the macro
economic question, you know, how much that progress lifts our human society
generally, I would say it's less than said, but let's, but, but then I think the
other dimension you have to ask is, is it the sort of progress that people think
of as, as simply, simply good? And, you know, if the, you know, the, the futuristic
AGI was pitched to me in 2005, as you have no idea what sort of, we will be able
to cure aging, we'll be able to find all these fantastic medical treatments. We
still have not gotten those. If we had gotten those, I would score it as, as
at least more positive. What we have gotten, we got TikTok. And yeah, that's,
it's valuable for TikTok. It's valuable for the company that sort of does this
AGI. But it, you know, I would, I would score it as, as a form of technology
that is, that's, you know, and I don't want to sound overly lead, but even if
it's rapidly, it's, it's deranging us. It's making us go crazy. Or the
surveillance state in China, that is a form of technological progress over a
decade ago, but it has, you know, it has, it has really deranged that society. It
has disabled the humans. It's, it's a less happy, less functional, less free
place than it was 10 years ago. Even if we say that it somehow shows up in the
economic statistics, which it doesn't, but even if you can make, even if you can
jigger the ACON statistics to make the super abundance show up, it might, we
should ask this question, is it evil or is it good?
Yep. So Pete, so Peter, before we have some audience questions, I'm going to ask
a question too, as I think about some of these contemporary examples, like in the
area of science, things like Alpha fold or deep fold, you know, where we've been
able to predict and understand the structure of proteins coming out of the
deep mind team. Or we, you know, and so we have the productivity, you know,
co-pilot that's been recently launched by Microsoft and the claim by, by
Satya and Charles Lamont and others. There's a 30% improvement in productivity
and software development. Or you take stable diffusion and the creativity that
that unlocks, you know, for, for humans. In every one of those cases, of course,
humans in the loop in many, many different ways. So no AGI here. And I guess
the question is, therefore, can AI both be evil and good?
Sure. But, but, you know, all, like all the examples, you know, like there's
always, look, there's always a fast line, it's just a technology and it just, it
just, you know, it's, and as such, it's, it's, it's pretty neutral and it's up to
humans what we, what we do with it. But I think one can, I would still say one
should ask the question more, you know, is it, you know, you know, how do we sort
of weight these different kinds of applications? You know, the protein
folding is, is interesting. It's, it's, it's only valuable, I would say, if it
actually leads to new medical interventions, new cures. And when I, when I
push the AI people on that, they always, they don't, they don't want to engage
in that conversation. And, you know, so, and then, and then, you know, if, if it
is saving 30% of coding time, that, that would be very impressive. It, it's, it's
not clear that that's, that's showing up in, in any of the, of the stats of the, of
the big, big software companies at this point, you know, where, you know, I would
say all of Silicon Valley has, has this problem where, where, you know, the, they
have to pay the, the coders, the computer programmers more and more. And so, yeah,
there's, you know, there's definitely a need for technology to replace the people
and would make the businesses more profitable. And I would, I would have scored
that as probably a productivity enhancing, generally positive thing. It doesn't
show up in the computer science labor market. So, and then, and then I think,
look, the, the, the big thing, the biggest, the biggest AI technology that's
actually being used is TikTok. And we need to be, we need to be talking about
that. And I, you know, I, I, I gave you two, you know, very different ones. One is,
one is that it's emergent. It's not like an intentional weapon. It's, it's, it's
just emergent. And it's just, you know, we have a tendency to get deranged. And
this is, this is what happens even though it seems to derange us. And then, and
then, but nobody, nobody's in China to double check the algorithms. The ones
they're training on the US are very different from the ones they train on
people in China. You don't get, you don't get videos that, that make people, you
know, radical, that radically undermine the belief in the society in China like
you do in the US. And that, that, that suggests to me that we should at least
be asking this intentional question.
Very, very fair point. I, I'm certainly not trying to make the argument that
TikTok is a productivity helper. And it could well be insidious and evil as
well.
My intuition is that it's, it's the, it's the biggest thing in AI. So if I had a,
if you had to wait them, how big they are, I think TikTok is the biggest thing.
We have a microphone here if folks are interested in asking questions to Peter.
And if you can look this way towards the cameras, that would be helpful as well.
Thank you. And thank you, Peter, for that most precious of gifts, your time. And I
for one, I'm willing to pay the time price for it. Given our addiction.
Watch it, who are you? Give it, now it's your.
I'm nobody.
How are you?
I'm Stephen's. I went to your first conference.
I know, but you've got to give your name when you speak at the microphone.
We don't believe in anonymity around here.
Very good. And you would go to the core of the question, which is the individual
versus the identity. I stand as an individual to ask you this question.
Given our addiction to narratives like AI and given our aversion to knowledge in
favor of miss mill and all kinds of misinformation and given our emotional
overload of the past few years, as a student of Ren√© Girard,
my question is, will we have a mimetic pandemic where virus is the vengeance
and could AI help or hinder it?
There's one for you.
You know, um, yeah, this is, I mean, this is certainly, um, this is certainly a
read on what is very haywire about
tech talk that it, you know, it just gives people what they mistakenly think they want.
You know, they, they, um, and, um, and, uh, and, um, and then, um, and then, you know,
that's, that's often, you know, that's often somehow, somehow a bad thing.
I, um, I don't know, you know, I look, I think there is, there are, there are, um,
there are ways in which, you know, I wouldn't, um, I wouldn't, um, I'm always,
I'm always, I'm hesitant to sort of blame tech for everything that's wrong in our
society. Uh, but I do think, I do think there's, there's something about, um, you
know, it's, if we, if, and it's, it's, it's wrong to scapegoat and say it's the
single thing that causes everything to go haywire, but, uh, but at the margins, you
know, is it, is it helping us get, does, does, does, does, um, you know, there's
something about, um, about a lot of these sort of short packet content forms that
has, you know, has deranged this course.
I think, I think TikTok is, is, is by far the worst, um, and, um, and this is sort
of a sense in which the, the, you know, Silicon Valley is getting some, some of
the blame for, um, uh, for, for all this stuff.
And then, you know, I think the alternatives also didn't work because, you
know, the alternatives were, you know, a centralized media system, which
everything was controlled.
Sir.
So I, I, I think, I think you have to, if you frame the social problem, it's, um,
it's, um, you know, it's too much totalitarian centralization versus
deranged decentralization.
And you have to, you have to think of both problems and there's, you know, there
are instances of both that we had in the COVID epidemic the last two, three years.
We had, you know, decentralized conspiracy theories that were not helpful.
And we had a centralized narratives that cut off, uh, cut off much needed debate.
Hi.
Thank you.
Uh, I'm Dr.
Jeff Garneson from Anchorage, Alaska.
This is my second cousin.
Um, 60 years ago, CS Lewis wrote an article in the Saturday evening post called,
uh, screw tape proposes a toast where he criticized, uh, the dumbing down of
American education and I chair an educational foundation.
And I'm very concerned about the quality of, uh, U S education.
And, uh, and, uh, as you talked about, and what can we do about, uh, educating
our youth in, uh, at least in public education, uh, all my colleagues send
their kids to private schools now.
And so I just wanted to see if you could comment on that.
You know, I, I mean, I think there are a lot of people who articulated the,
the issues quite, uh, quite, quite strongly.
I don't have, you know, I don't have, um, I know, I, I've got much to add to it.
Um, I, I do think, um, I do think it's sort of like always a question, you
know, what are people doing?
What is the teleology of it?
And, you know, I think a healthy, you know, primary, secondary, tertiary
education system is, you know, it's, it's supposed to, um, make you a
well-rounded educated person, become a functioning citizen, our society.
Um, uh, you know, if you, if you go into research or academia or certain
industries, it is, uh, for you to become be a creative person who sort of
pushes the frontiers of, of, of knowledge and, um, and in some sense,
you know, it has, it has, um, it has, it has, it has somehow gotten, gotten
deranged.
And, uh, again, I don't want to blame it on AI or make this the, the
single focus, but if you, if you have a narrative out there that, uh, that in
the future, AI will do all the thinking for you and you don't need to think for
yourself in any way.
Um, you know, you know, maybe, maybe, um, maybe, you know, you don't need to
learn as much stuff.
You don't need to memorize things.
You don't, there's sort of all this, these things that are considered
education that, that, that seemed to be, um, seemed to be much, uh, much less
important.
And, um, and I, I, yeah, I, I do wonder that's, that's sort of, that's the
broader context in which a lot of these things are operating.
That it's sort of like, um, you know, if you, if you say it's not the public
school system is not completely deranged, it's just trying to sort of make
people these passive cogs in this very large machine.
Um, you know, that's, that's sort of the, uh, the way in which it fits into
this dystopian AI narrative.
And, um, and we need to, yeah, we need to tackle this problem on all these
different levels.
Hi, Peter.
Um, my name is Rick with Mivium.
Um, I, I heard you give a talk at Stanford a few months back.
And so this is the second time I heard you mention a lack of progress, uh, in, uh,
on the atom level.
So, uh, coming from the, uh, semiconductor material science field, uh, you
know, I, I wanted to see what you mean by that because all we do is manipulate
atoms on a day-to-day basis at scale from atomic layer deposition to molecular
beam, epitaxial growth to mechanical chemistry.
That's the only way we can make these next gen semiconductors, uh, these new
materials that can basically replace silicon and free us from any kind of
independent dependence from China and raw materials.
So for me in my field, it, it's not a lack of progress.
It's more the incumbent thought, school of thought out there is all chemistry
based.
Everybody wants to do with chemistry and toxic chemicals, uh, and things like
that.
Whereas we're trying to do it different way, but we face a lot of resistance.
The barrier of entry and the cost is also very high.
So I want to know what you mean by lack of progress.
Well, it's, it's, it's, it's, um, it's certainly, um, slowed in, in a lot of
fields.
Look, I think, I think the, the complicated version I would tell is that we've had,
you know, a decent amount of progress in the world of bits the last 40, 50 years.
I think semiconductors are sort of the, the in-between thing.
And then most other fields have been disappointingly, at least slow.
You know, when I was an undergraduate at Stanford, I was class of 89, um,
you know, in, in retrospect, it wasn't obvious at the time, but in retrospect,
you were supposed to study computer science.
All the engineering fields were bad fields to go into.
It was a bad idea to go into aero astro.
It was a bad idea to go into nuclear engineering.
If people knew that, they didn't do that.
It was a bad idea, mechanical, chemical, you know, all the sort of, uh, world of
atom stuff was bad.
I think the one that was still in, in between that, that worked okay, but much less well
than computer science was electrical engineering.
And, um, and, and so, you know, the, if we, if we look at, you know,
how well have the companies done, how well have the people gotten paid, um, you know,
EE has done better than other fields, but a lot less well than, um, than computer science.
I, I think on some level, it reflects the ways in which the progress is hard.
It's, it's, it's, it's slower than it was in the 80s and 90s, but by various measures,
it requires enormous scale.
So, um, the role for the individual is less.
You know, if you have to have a $500 million ASML, you know, machine to do the lithography,
you know, um, it's harder to start, you know, it's hard to start a new, um, semiconductor company.
And so, yeah, the ecosystem is shifted towards, you know, much bigger businesses dominating it.
And, and, you know, certainly as a venture capitalist, um, uh, I, we've done virtually
no investing in semiconductors.
You know, I, I think, I think I should, but, um, you know, it's, we do so little that we
don't know enough about it to do it.
And that makes me think that it's, um, you know, there's some things happening,
but it's, it's, it's still, uh, it's still a lot slower than it was in the past.
This is, this is the, this is the challenge with China.
It's not like China is copying the West.
They will eventually catch us up.
And so if we are progressing slowly, they will eventually be able to copy things and converge.
And, uh, I think the sort of rate at which we're doing new things is not so great
that China will not be able to converge.
Yeah.
But China has no access to the ASML machines.
Uh, they're still doing a chemical method.
They're probably, they're, it's, it's possible that it's, uh, it's still going to be
non-trivial for them to catch up, but it's, it's, it's not as though, you know, we have this
exponentially growing lead that, uh, you know, um, it's, it's, it's, it's not quite as strong as that.
Thank you, Peter, for your provocative remarks that are going to precipitate many discussions
for the next two days.
I, and, uh, uh, including about, uh, all these issues surrounding technological progress.
And thank you.
