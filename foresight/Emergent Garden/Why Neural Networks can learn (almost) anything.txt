You are currently watching an artificial neural network learn.
In particular, it's learning the shape of an infinitely complex fractal known as the
Mandelbrot set.
This is what that set looks like, complexity all the way down.
Now, in order to understand how a neural network can learn the Mandelbrot set, really how it
can learn anything at all, we will need to start with a fundamental mathematical concept.
What is a function?
Informally, a function is just a system of inputs and outputs, numbers in, numbers out.
In this case, you input an x and it outputs a y.
You can plot all of a function's x and y values in a graph where it draws out a line.
What is important is that if you know the function, you can always calculate the correct
output y given any input x.
But say we don't know the function, and instead only know some of its x and y values.
We know the inputs and outputs, but we don't know the function used to produce them.
Is there a way to reverse engineer that function that produced this data?
If we could construct such a function, we could use it to calculate a y value given
an x value that is not in our original data set.
This would work even if there was a little bit of noise in our data, a little randomness.
We can still capture the overall pattern of the data and continue producing y values that
aren't perfect, but close enough to be useful.
What we need is a function approximation, and more generally, a function approximator.
That is what a neural network is.
This is an online tool for visualizing neural networks, and I'll link it in the description
below.
This particular network takes two inputs, x1 and x2, and produces one output.
Technically, this function would create a three-dimensional surface, but it's easier
to visualize in two dimensions.
This image is rendered by passing the xy coordinate of each pixel into the network, which then
produces a value between negative one and one that is used as the pixel value.
These points are our data set, and are used to train the network.
When we begin training, it quickly constructs a shape that accurately distinguishes between
blue and orange points, building a decision boundary that separates them.
It is approximating the function that describes the data, its learning, and is capable of learning
the different data sets that we throw at it.
So what is this middle section then?
Well, as the name implies, this is the network of neurons.
Each one of these nodes is a neuron, which takes in all the inputs from the previous
layer of neurons and produces one output, which is then fed to the next layer.
Inputs and outputs sounds like we're dealing with a function.
Indeed, a neuron itself is just a function, one that can take any number of inputs and
has one output.
Each input is multiplied by a weight, and all are added together along with a bias.
The weights and bias make up the parameters of this neuron, values that can change as
the network learns.
To keep it easy to visualize, we'll simplify this down to a two-dimensional function, with
only one input and one output.
Now neurons are our building blocks of the larger network, building blocks that can be
stretched and squeezed and shifted around, and ultimately work with other blocks to construct
something larger than themselves.
The neuron, as we've defined it here, works like a building block.
It is actually an extremely simple linear function, one which forms the flat line, or
plain when there's more than one input.
With the two parameters, the weight and bias, we can stretch and squeeze and move our function
up and down and left and right.
As such, we should be able to combine it with other neurons to form a more complicated function,
one built from lots of linear functions.
So let's start with a target function, one we want to approximate.
I've hard-coded a bunch of neurons whose parameters were found manually, and if we
weight each one and add them up, as would happen in the final neuron of the network,
we should get a function that looks like the target function.
Well, that didn't work at all.
What happened?
Well, if we simplify our equation, distributing weights and combining like terms, we end up
with a single linear function.
Turns out, linear functions can only combine to make one linear function.
This is a big problem because we need to make something more complicated than just a line.
We need something that is not linear, a non-linearity.
In our case, we will be using a ReLU, a rectified linear unit.
We use it as our activation function, meaning we simply apply it to our previous naive neuron.
This is about as close as you can get to a linear function without actually being one,
and we can tune it with the same parameters as before.
However, you may notice that we can't actually lift the function off of the x-axis, which
seems like a pretty big limitation.
Well, let's give it a shot anyway, and see if it performs any better than our previous
attempt.
We're still trying to approximate the same function, and we're using the same weights
and biases as before, but this time we're using a ReLU as our activation function.
And just like that, the approximation looks way better.
Unlike before, our function cannot simplify down to a flat linear function.
If we add the neurons one by one, we can see the simple ReLU functions building on one
another, and the inability for one neuron to lift itself off the x-axis doesn't seem
to be a problem.
Many neurons working together overcome the limitations of individual neurons.
Now, I manually found these weights and biases, but how would you find them automatically?
The most common algorithm for this is called back propagation, and is in fact what we're
researching when we run this program.
It essentially tweaks and tunes the parameters of the network bit by bit to improve the approximation,
and the intricacies of this algorithm are really beyond the scope of this video.
I'll link some better explanations in the description.
Now we can see how this shape is formed, and why it looks like it's made up of sort of
sharp linear edges.
It's the nature of the activation function we're using.
We can also see why, if we use no activation function at all, the network utterly fails
to learn.
We need those non-linearities.
So what if we try learning a more complicated data set, like this spiral?
Let's give it a go.
Seems to be struggling a little bit to capture the pattern.
No problem.
If we need a more complicated function, we can add more building blocks, more neurons,
and layers of neurons.
And the network should be able to piece together a better approximation, something that really
captures the spiral.
It seems to be working.
In fact, no matter what the data set is, we can learn it.
That is because neural networks can be rigorously proven to be universal function approximators.
They can approximate any function to any degree of precision you could ever want.
You can always add more neurons.
This is essentially the whole point of deep learning, because it means that neural networks
can approximate anything that can be expressed as a function, a system of inputs and outputs.
This is an extremely general way of thinking about the world.
The Mandelbrot set, for instance, can be written as a function and learned all the same.
This is just a scaled-up version of the experiment we were just looking at, but with an infinitely
complex data set.
We don't even really need to know what the Mandelbrot set is.
The network learns it for us, and that's kind of the point.
If you can express any intelligent behavior, any process, any task as a function, then
a network can learn it.
For instance, your input could be an image and your output a label as to whether it's
a cat or a dog, or your input could be text in English and your output a translation to
Spanish.
You just need to be able to encode your inputs and outputs as numbers, but computers do this
all the time.
Images, video, text, audio, they can all be represented as numbers, and any processing
you may want to do with this data, so long as you can write it as a function, can be
emulated with a neural network.
It goes deeper than this though.
Under a few more assumptions, neural networks are provably turing complete, meaning they
can solve all of the same kinds of problems that any computer can solve.
An implication of this is that any algorithm written in any programming language can be
simulated on a neural network, but rather than being manually written by a human, it
can be learned automatically with a function approximator.
Okay, that is not true.
First off, you can't have an infinite number of neurons.
There are practical limitations on network size and what can be modeled in the real world.
I've also ignored the learning process in this video, and just assumed that you can
find the optimal parameters magically.
How you realistically do this introduces its own constraints on what can be learned.
Additionally, in order for neural networks to approximate a function, you need the data
that actually describes that function.
If you don't have enough data, your approximation will be all wrong.
It doesn't matter how many neurons you have or how sophisticated your network is, you
just have no idea what your actual function should look like.
It also doesn't make a lot of sense to use a function approximator when you already know
the function.
You wouldn't build a huge neural network to, say, learn the Mandobrot set when you can
just write three lines of code to generate it, unless of course you want to make a cool
background visual for a YouTube video.
There are countless other issues that have to be considered, but for all these complications,
neural networks have proven themselves to be indispensable for a number of really rather
famously difficult problems for computers.
Usually, these problems require a certain level of intuition and fuzzy logic that computers
generally lack, and are very difficult for us to manually write programs to solve.
Things like computer vision, natural language processing, and other areas of machine learning
have been utterly transformed by neural networks.
And this is all because of the humble function, a simple yet powerful way to think about the
world.
And by combining simple computations, we can get computers to construct any function we
could ever want.
Neural networks can learn almost anything.
Thank you.
Thank you.
Thank you.
Bye.
Bye.
