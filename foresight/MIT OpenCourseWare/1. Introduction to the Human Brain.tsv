start	end	text
0	11520	All right, it's 11.05.
11520	14560	I'm going to try to start promptly at 11.05 each time.
14560	16080	So welcome.
16080	17800	Has everybody psyched?
17800	20040	I'm psyched.
20040	22200	This is 9.13, the human brain.
22200	23240	I'm Nancy Canwisher.
23240	25280	I'm the prof for this class.
25280	28080	Unless you were wondering, I have a brain.
28080	28880	And there it is.
28880	31240	That's me with some bits colored in
31240	34840	that you will learn about in this class.
34840	36240	What I'm going to do today is I'm
36240	39720	going to tell you a brief story for around 10 minutes.
39720	43280	And then I'm going to talk about the why, how, and what
43280	46440	of studying the human brain, why it's a cool thing to do,
46440	48360	how you do it, and what in particular we're
48360	50240	going to learn about in here.
50240	52120	And then we'll do some mechanics and details
52120	54560	of the course and allocation of grades and all that.
54560	56800	It's on the syllabus anyway.
56800	58000	Cool?
58000	60640	That's the agenda.
60640	61520	All right.
61520	64360	So let's start with that story.
64360	69840	And for this, I'm going to set up here.
69840	71400	The story isn't that long, but it has
71400	73440	a lot of interesting little weird bits.
73440	75960	So I have cue cards to remind myself of all the bits
75960	78480	I want to remember to say.
78480	81240	So you can put away your phones and your computers,
81240	82480	and you don't need to take notes.
82480	84720	This is just a story.
84720	87400	It's going to foreshadow a lot of the themes in the course,
87400	91320	but it's not stuff you're going to be tested on.
91320	94640	So this is a true story.
94640	98080	And I've changed only a few tiny little bits
98080	101040	to protect the identity of the people involved.
101040	104560	But otherwise, it's an absolutely true story.
104560	107720	It's a story about a scary medical situation
107720	110960	that happened to a friend of mine a few years ago.
110960	113200	But at the same time, it's a story
113200	115520	about the nature of the human mind,
115520	119680	about the organization of the human brain.
119680	125160	And it's also a story about the ability or lack thereof
125160	127880	to recover after brain damage.
127880	135360	It's also, incidentally, a story about resilience, privilege,
135360	137560	expertise, and all of those things
137560	143800	that are characteristic of many people in Cambridge society.
143840	149160	Not so relevant for the course, but all right, here goes.
149160	152160	So a few years ago, a friend of mine
152160	154200	was staying over at my house in Cambridge,
154200	157600	en route to a conference in a nearby state.
157600	162120	And this guy, I'll call him Bob, was a close friend of mine.
162120	165320	I'd known him for years and years.
165320	166560	We talked regularly.
166560	168640	We went on hiking trips together.
168640	170360	We were pretty close.
170360	172040	So he's en route to this conference.
172040	175800	He's staying over at my house the night before.
175800	178920	And the plan was for him to get up early the next morning
178920	180040	and drive to the conference.
180040	182840	So we hung out the night before and chatted.
182840	185440	And the next morning, he's sleeping in the next room
185440	186840	over from mine.
186840	189640	And early in the morning, I hear some shuffling.
189640	192360	I think, yep, OK, Bob is packing to leave.
192360	194000	And thank god, I don't need to get up.
194000	195840	I'm only dimly awake.
195840	198560	And so I'm not paying that much attention.
198560	200400	Shuffle, shuffle, shuffle in the background.
202160	203160	And then I hear a crash.
206440	209400	And I think, what the hell is that?
209400	212920	And I get up, and I go into the next room.
212920	216680	And Bob is lying on the floor, not moving.
216680	218280	I say, Bob.
218280	220160	And there's no answer.
220160	222400	And then I shout, Bob.
222400	224240	And there's no answer.
224240	227400	And then I dialed 911.
227400	230280	While we were sitting there waiting for the ambulance
230320	233760	to arrive, Bob starts to wake up.
233760	236200	And he's very woozy, but he's alive.
236200	238800	And he's making a little bit of sense.
238800	240720	And he can't figure out what's going on.
240720	242520	And neither can I.
242520	245040	And so we're talking and chatting.
245040	247680	And he's making a little more sense.
247680	250200	But we still know what's happening.
250200	253640	So then the ambulance arrives incredibly fast.
253640	255120	So like three minutes, boom.
255120	258560	There's three EMTs rushing in the front door, rushing up
258560	260280	to the room where Bob was.
260280	262480	And they take all his vitals.
262480	265080	And they can't find anything wrong.
265080	267000	And so they're really casual.
267000	269640	I guess they confront stuff like this all the time.
269640	270640	I don't.
270640	271800	Bob doesn't.
271800	273440	But they're very calm about it.
273440	276440	And they're saying, well, you could take him to the hospital
276440	278720	or not.
278720	281560	And I was like, I think we need to know what just happened.
281560	282920	Even though he seems OK, we kind of
282920	285520	need to know what this is all about, don't you think?
285520	288320	They're like, yeah, you could take him to the ER.
288320	291560	And I said, well, do we need to waste ambulance resources?
291560	293720	Or do you think it's safe if I drive him myself,
293720	295400	since there's a hospital not far away?
295400	297760	They said, you could drive him yourself.
297760	301240	So I drive Bob to the Mount Auburn Hospital
301240	304400	ER, which is less than a mile from my house.
304400	306480	And we do the usual ER thing, which is mostly
306480	308320	waiting and waiting and waiting.
308320	309920	But various docs come by.
309920	311360	And they take all these tests.
311360	313520	And they take all these history questions.
313520	314280	And it goes on and on.
314280	317680	And basically, they're just not finding anything.
317680	319600	So after about an hour or two of this,
319600	320640	they're still doing tests.
320640	322080	They don't want to quite let him go yet,
322080	323720	because they don't know what happened.
323720	325720	Everybody's calm about it.
325720	327440	I figure, OK, fine.
327440	329520	I got work to do.
329520	333080	And I tell Bob, text me throughout the day.
333080	337240	And I'll come get you whenever they're ready to release you.
337240	341040	And so I go into work.
341040	343280	But just before I go into work, a thought
343280	345040	flashes through my mind.
345040	351640	And I say to the ER doc, you should check Bob's brain.
351640	354240	And the reason that thought flashed through my mind
354240	357520	is that, actually, I had been worrying about Bob
357520	359040	for a number of years.
359040	362280	And it hadn't quite registered consciously.
362280	364440	I hadn't was kind of too horrifying a thought for me
364440	367080	to really allow myself to realize
367080	368640	I was worried about Bob's brain.
368640	370600	But I was worried about a very particular thing.
370600	374360	And that is that Bob had been showing these weird signs
374360	379520	that he often got lost and didn't know where he was.
379520	381680	And on the one hand, this just didn't make any sense,
381680	384520	because he was fine in every other way.
384520	386280	But it was really pretty striking.
386280	389720	So one time, I was over at Bob's house
389720	391640	with some other friends of ours.
391640	395600	And the friend asked Bob, how do I drive from your house
395600	397080	into Cambridge?
397080	399280	And Bob said, well, you go to the end of the driveway,
399280	400960	and you turn left.
400960	405600	My friend and I looked at each other like, Bob.
405600	406280	What?
406280	407680	And Bob thinks about it for a minute, yeah,
407680	410240	end of the driveway, turn left.
410240	413880	I just had this sinking feeling of dread
413880	416400	in the pit of my stomach.
416400	419120	But we sort of made light of it and made fun of it.
419120	419920	And it went by.
419920	421200	It was like, no, you turn right.
421200	423520	And we gave the directions.
423520	426440	Another time, a friend of mine was driving with Bob
426440	428400	in Bob's hometown.
428400	431800	And noticed that Bob didn't seem to know
431800	435080	how to get to the grocery store in his hometown, where
435080	438040	he'd lived for a really long time.
438040	442320	And a trip he'd made hundreds of times.
442320	446120	Another time, I was at a conference in Germany.
446120	449720	And I saw these arrays of posters of people
449720	452600	presenting usually pretty dry scientific things.
452600	455440	And out of the corner of my eye, I see the title of a poster.
455440	459960	And it says, navigational deficits, colon, and early sign
459960	461400	of Alzheimer's.
461400	462280	And I saw that.
462280	464480	And I just thought, oh.
464480	467280	And I just kind of suppressed the thought.
467280	469960	And I thought, oh my god, Bob wasn't that old.
469960	472480	I know Alzheimer's can very rarely strike early.
472480	473960	I didn't want to think about it.
473960	479160	But it was like rattling around in the back of my consciousness.
479160	481240	So there had been these signs.
481240	483160	But as I say, they didn't make sense.
483200	486960	Because Bob was holding down a very high-powered job.
486960	489120	He was writing beautiful prose.
489120	491240	He was the life of every party he was at.
491240	496800	Witty, funny, everybody's favorite life of the party.
496800	498320	So how could that be?
498320	500320	It just didn't make sense that there would be anything
500320	502080	wrong with Bob's brain.
502080	504920	So I managed for a few years to notice these signs
504920	507080	and ignore them and not pay any attention.
513520	520160	So the killer thing is I should have known better.
520160	523240	My research for the last 20 years
523240	525200	has been on the very fact that there
525200	528760	are different parts of the brain that do different things.
528760	531040	And one of the corollaries of that
531040	533680	is you can have a problem with one of those parts,
533680	536000	and the other parts can work just fine.
536000	539600	And so I, if anyone, should have realized, yes,
539600	542280	there's something really wrong with Bob's navigation
542280	543320	abilities.
543320	546520	And the fact that he's smart, and witty, and funny,
546520	548560	and holding down a high-powered job
548560	551440	doesn't mean there isn't something wrong with his brain,
551440	554080	with a part of his brain.
554080	556920	But I didn't realize that.
556920	561240	But then, as I'm leaving the ER, it kind of all clicked.
561240	566000	And I said to the ER doc, you better check his brain.
566000	568080	I thought Bob was out of earshot when I said that.
568080	568680	He heard it.
568680	569880	He's like, what?
569880	572520	I was like, oh, never mind.
572520	575200	Anyway, the ER doc, with the kind of confidence
575200	578960	that only docs can muster, said, no, not a brain thing.
578960	584120	This is a hard thing, which wasn't exactly reassuring.
584120	588640	But I set aside the brain thought, and I went off to work.
591560	597440	So throughout the day, I texted with Bob a few times.
598080	599200	Things seemed to be fine.
599200	600120	They'd done more tests.
600120	602080	They weren't find anything.
602080	604040	We just got calmer and calmer about it.
604040	605880	I guess sometimes weird stuff happens,
605880	608160	and you just move on.
608160	611520	But then that night, around 7 or 8 at night,
611520	614520	I was over at a friend's house, and the phone rang.
614520	615800	And it was Bob.
615800	620000	I picked it up, and Bob says, get over here.
620000	623200	They found something in my brain.
623200	625720	So I ran out of the house, grabbed my phone,
625720	629720	and as I'm driving to the Mount Auburn ER,
629720	634360	I called my trusty lab tech, an amazing guy who
634360	637160	keeps track of all kinds of things much better than I do.
637160	641880	And I said, I remember that we scanned Bob a bunch of years
641880	645000	ago for a regular experiment in my lab.
645000	646080	And I don't remember.
646080	649280	The date, I don't remember anything about it,
649280	652440	but dig around in the files and see if you can figure it out.
652440	656360	It might be useful to have that scan.
656360	659360	So by the time I get to the ER, my lab tech
659360	662960	has already texted me back and said, found the scans.
662960	665640	I'm putting them in a drop box for you.
665640	669600	So I go into the ER, and there's Bob in the ER doc.
669600	675840	And Bob says to me, do you want to see it?
675840	678440	The ER doc, the radiologist, has already
678440	681040	shown Bob the picture of his brain.
681040	685400	And so they take me in there, and I look at it, and I gulped.
685400	687960	There was a thing the size of a lime smack
687960	691080	in the middle of his brain.
691080	693480	Pretty terrifying.
693480	702400	So this lime in the middle of Bob's brain
702400	705440	was right next to a region that my lab had studied
705440	706680	in great detail.
706680	710720	In fact, my lab had discovered that a brain region,
710720	713240	right next to where that lime was located,
713240	717480	was specifically involved in navigation.
717480	719600	How could I not have put all this together,
719600	721160	but I didn't until that moment?
721160	723000	And I thought, of course.
723000	724840	Of course, there's a thing in his brain,
724840	727920	right next to the perihippocampal place area, which
727920	730600	I discovered, and a nearby related region
730600	732360	called retrospective spoolyneal cortex.
732360	733400	Of course.
733400	736160	And how the hell could I not have known?
736160	739640	But I didn't know.
739640	743760	In that earlier work, it had been nearly 20 years ago,
743760	746280	I had a postdoc named Russell Epstein.
746280	748440	And Russell was a computer vision guy,
748440	752280	and he wanted to understand how we see by writing code
752280	754520	to duplicate the algorithms that he thought
754520	758040	go on in the human brain when we understand visual images.
758040	760760	And that's a very respectable, cool line of work, which
760760	763200	we'll learn a little bit about in here.
763200	765320	And Russell was really a coding guy.
765320	768680	At the time, we were just starting doing brain imaging.
768680	770720	But Russell was like poo-pooing at all.
770720	772000	It's like the flash in the pan.
772000	772920	It's going to go by.
772920	773760	It's trashy.
773760	775920	So you guys get nice blobs on the brain.
775920	777800	I'm not having any of it.
777800	781040	And I kept saying, Russell, you need to get a job.
781040	783880	Just do one experiment so you can show in your job talk
783880	785200	that you can do brain imaging.
785200	786520	It might help you.
786520	787800	You don't need to do a lot of it.
787800	790320	Just do one dumb experiment.
790320	793080	Russell was interested in how we recognize scenes, not
793080	794800	just objects and faces and words,
794800	796200	but how do we know where we are?
796200	799680	And how do we recognize if the scene is a city or a beach
799680	801640	or whatever it is?
801640	804240	I said, OK, Russell, we'll just scan people,
804240	806280	looking at pictures of scenes, and looking
806280	808000	at other kinds of pictures.
808000	809560	And we'll just kind of see if there's
809560	812280	any part of the brain that responds a lot to scenes.
812280	814000	It really was not well thought out.
814000	815960	This is not how you should do an experiment.
815960	819440	It shouldn't be based on political calculations, lack
819440	821080	of theory, any of the above.
821080	823360	But the fact is, that's why we did that experiment.
823360	825560	Russell needed to be able to show a brain image
825560	829280	in his job talk, so we scanned some people looking at scenes.
829280	831360	And the results knocked our socks off.
831360	834480	We found a part of the brain that responds very selectively
834480	836800	when you look at images of scenes,
836800	839120	not when you look at faces, objects, words,
839120	841400	or pretty much anything else.
841400	843840	And so we'll learn more about that later in the course.
843840	846280	We called it the Parahippocampal Place Area,
846280	849240	and that launched a whole major line of work in my lab
849240	853160	and now dozens of other labs around the world.
853160	855720	So backtrack, we'd already found that region.
855720	858440	And here's this lime in my friend Bob's brain
858440	861440	sitting right next to the Parahippocampal Place Area.
868160	873920	So then I remembered, let's look at the scans from my lab
873920	876760	from a few years ago in Bob's brain.
876760	879360	And so I fiddled around and found,
879360	882400	managed to download the files.
882400	883680	And there it was.
883680	886000	You could see that same blob.
886000	889000	But in the scans from a few years before, it was much smaller.
889000	892160	It was the size of a grape.
892160	894840	And so that told us a bunch of things.
894840	897720	Most importantly, it told us this thing is growing really
897720	899240	slowly.
899240	902360	And that was hugely important because brain tumors
902360	905960	are very bad news, and they usually grow really fast.
905960	908200	And the fact that it grew really slowly
908200	912240	told us that this was not one of the worst, most invasive,
912240	913320	most horrible ones.
913320	914920	It was clearly a problem.
914920	921360	It was big, but at least it wasn't growing hugely fast.
921360	925160	But how poignant that there it was in my own damn data,
925160	927800	and I hadn't seen it in my friend's brain.
927800	930320	Well, I'm not a radiologist.
930320	932520	I'm a basic researcher, and I didn't look,
932520	935040	and I didn't see it.
935040	938840	So indeed, the next day, the docs told us
938840	941880	that they thought this was meningioma, not cancer,
941880	944000	who knew that you could have tumors that weren't cancer,
944000	945720	but you can.
945720	948040	And they still need to come out if they're big enough,
948040	949640	and that's very serious, but it's not
949640	954320	as bad as having a cancer in your brain.
954320	956080	So as we're collecting information,
956080	959040	the next day I'm hanging out in the hospital room,
959040	961960	and there was an amusing moment when one of the residents
961960	963560	came by, and he's taking the history
963560	965120	and asking all the basic questions.
965120	967040	And I said kind of sheepishly because you
967040	969440	don't want to seem like you know more than the residents.
969440	970920	And in fact, I didn't really know more,
970920	972840	but I just thought I'd provide a little information.
972840	975200	And I said, you know, he's actually
975200	976800	had symptoms for a bunch of years,
976800	979200	and there's a region of the brain nearby
979200	981680	that I've actually studied a little bit.
981680	984000	And the residents is like, we know who you are.
987920	993560	So much for my trying to stay under the radar.
993560	996320	That afternoon, I talked to a neurosurgeon friend of mine
996320	998440	because I figured, OK, we need advice.
998440	999640	We need help.
999640	1005680	And the neurosurgeon friend said, quote,
1005680	1007440	it got branded in my brain.
1007440	1010200	She said, it is of paramount importance
1010200	1012520	that you find the best neurosurgeon.
1012520	1014800	It's the difference between whether Bob
1014800	1019000	dies on the table or goes on to live a normal life.
1019000	1020880	So this is the privileged part of the story.
1020880	1023600	I'm not that well connected, but I'm a little bit connected.
1023600	1026280	And I kind of dug around and did what I could.
1026280	1028920	And we spent a couple of weeks, and we
1028920	1032760	found the best neurosurgeon.
1032760	1038440	And the night before the surgery,
1038440	1040880	Bob is staying over at my house because the surgery was
1040880	1042520	in a Boston hospital.
1042520	1044520	And I thought, you know, I've been dancing around this
1044520	1046600	for years, but now, like, it's all out in the open.
1046600	1048960	We know there's a problem, and I'm going to test him.
1048960	1051640	I'm going to find out what the hell is going on.
1051640	1055480	This is, after all, one of the basic forms of data
1055480	1056880	that we collected in my field.
1056880	1059720	That is testing people with problems in their brain
1059720	1061960	to try to figure out what things they can do
1061960	1063280	and what things they can't do.
1063280	1065560	It's a way of figuring out what the basic components
1065560	1067080	of the mind and brain are.
1067080	1069840	It's actually the oldest, most venerable method in our field,
1069840	1072640	and it's still a hugely important one.
1072640	1074280	So I thought, what the hell?
1074280	1077600	So I said, OK, Bob, draw me a sketch map of the floor
1077600	1080080	plan of your house.
1080080	1083200	And so Bob takes a few minutes, and he draws this thing.
1083200	1085640	And it was shocking.
1085640	1090240	There weren't even the rooms in a rectilinearly arranged house.
1090240	1092520	They weren't even aligned.
1092520	1094240	There was like a soup of lines.
1094240	1097600	There was no organization from one room to the next.
1097600	1101040	And Bob kind of realized this kind of isn't right, is it?
1101040	1102720	But he didn't know how to fix it.
1102720	1105480	And he said he just couldn't visualize what it looked like
1105480	1109680	to be in his house, and so he couldn't draw the floor plan.
1109680	1112120	And I thought, OK, he hasn't been there in a couple of days.
1112120	1114320	I gave him another piece of paper, and I said, OK,
1114320	1120000	draw the floor plan of my house, where you are right now.
1120000	1125800	And so Bob took a couple minutes and delivered a similar mess.
1125800	1129680	He couldn't even imagine the layout of the room next to him
1129680	1134280	that he'd been at, been in a few minutes before.
1134280	1137280	And then, trying to channel my inner neuropsychologist,
1137280	1140280	I thought, OK, gave him another piece of paper.
1140280	1143800	And I said, OK, Bob, draw a bicycle.
1143800	1144880	Why did I choose a bicycle?
1144880	1146520	Because it's a multi-part object that
1146520	1148120	has a bunch of different bits that
1148120	1150400	have a particular relationship to each other,
1150400	1153240	just as the rooms in a house have a particular spatial
1153240	1154680	relationship to each other.
1154680	1157160	And I wanted to know, is his problem specifically
1157160	1161640	about places, or is it about any complex multi-part thing
1161640	1165040	that you have to remember the relationships to?
1165040	1167520	Bob is no artist, to put it mildly,
1167520	1170640	but his bicycle was clearly recognizable as a bicycle.
1170640	1172840	It had the two wheels and the right relationship,
1172840	1175880	and it had all the basic parts in roughly the same,
1175880	1177520	the right place.
1177520	1180840	I then had him draw a lobster, another multi-part object,
1180840	1182840	and also his lobster was not beautiful,
1182840	1186040	but had everything in the right place.
1186040	1187600	And so that's very telling.
1187600	1191360	He had a specific problem in, I don't know, imagining,
1191360	1192680	reproducing, remembering.
1192680	1194480	It's not totally clear.
1194480	1196640	The arrangements of parts in a room,
1196640	1200680	but not the arrangements of parts in an object.
1200680	1202720	We'll get back to that more in a few weeks.
1206720	1211640	So what do I want to say here?
1211640	1213840	Is that all that?
1213840	1218040	So the next day, Bob has an 11-hour surgery,
1218040	1221680	major hardcore extreme neurosurgery.
1221680	1225040	Remove a huge piece of bone from the back of your head,
1225040	1227480	pull apart the hemispheres of the brain like this,
1227480	1234160	go in multiple inches, and remove a lime, like holy crap.
1234160	1238080	Said lime was right near the vein of Galen.
1238080	1240720	Galen lived, what, a couple thousand years ago.
1240720	1242360	The fact that there's a vein of Galen
1242360	1245680	means it's a big-ass vein, the kind of vein that even Galen
1245680	1249920	would have found with dissection 2,000 years ago.
1249920	1252680	This lime was all wrapped around and interleaved
1252680	1254000	with the vein of Galen.
1254000	1255400	Not good.
1255400	1258520	But because we found the best neurosurgeon,
1258520	1261560	and because we have extreme privilege,
1261560	1265040	and all the possible medical resources and expertise
1265040	1268880	you could possibly hope for, Bob sailed through the surgery.
1268880	1271680	And an hour after the surgery, I'm chatting with him,
1271680	1273080	and he's making sense.
1273080	1276240	Amazing, right?
1276240	1282160	So literally, two days later, they sent him home.
1282160	1285880	And a few days after that, he's back at work, no problem.
1285880	1287960	Totally fine.
1287960	1291760	But now we get to the question you're probably thinking about.
1291760	1294880	What about his navigational abilities?
1294880	1298360	The sad answer is, nothing doing.
1298360	1301880	None of it came back at all.
1301880	1303880	Thank God for iPhones.
1303880	1307040	If Bob lived 30 years ago, he wouldn't be able to function.
1307040	1313560	But he goes everywhere using his iPhone GPS, everywhere.
1313560	1316680	And this fact that he didn't recover his navigational
1316680	1320200	abilities is consistent with the whole literature that
1320200	1322840	we'll consider later in the course.
1322840	1325680	That often, not always, but often,
1325680	1328040	if you have brain damage, especially
1328040	1329960	to some of these very specialized circuits
1329960	1333520	that we'll talk about, you don't recover later.
1333520	1336160	If the damage is early, you may well recover.
1336200	1338160	Children have much more plastic brains
1338160	1340120	that can adjust after brain damage.
1340120	1341720	Adults, not so good.
1345560	1348720	So Bob's doing fine.
1348720	1350560	That's my story.
1350560	1353120	Any thoughts or questions?
1353120	1354120	Yeah?
1354120	1356640	He can tell the difference from the right to the left,
1356640	1357640	not on the left.
1357640	1358880	Yes.
1358880	1360200	Yes.
1360200	1361840	And it's very interesting.
1361840	1363840	There are many of his spatial abilities,
1363880	1366200	that are absolutely intact.
1366200	1370600	And yet, the ones related to navigation are not.
1370600	1371600	Yeah?
1371600	1372600	Yeah.
1372600	1373600	Yeah.
1373600	1374600	No problem.
1374600	1377600	But he's always looking at his damn phone to get directions
1377600	1383200	or to listen to the GPS directions system.
1383200	1384200	So driving is no problem.
1384200	1385400	It's another kind of left-right.
1385400	1387920	The immediate spatial orientation abilities
1387920	1389280	are absolutely fine.
1389280	1391600	But knowing where am I now, I don't know.
1391600	1392360	Fine.
1392360	1396280	But knowing where am I now and how would I get there from here
1396280	1398920	is blitzed.
1398920	1399520	Other questions?
1399520	1400520	Yeah?
1400520	1402520	Can you recognize what familiar is?
1402520	1404200	Great question.
1404200	1404840	Yes.
1404840	1407080	He can recognize familiar places.
1407080	1410040	What he can't do is he can say, oh, right.
1410040	1411240	That's the front of our house.
1411240	1417040	Or that's such and such cafe that's near our house.
1417040	1419120	What he can't do is say, which way would you
1419120	1420840	turn from there to go home?
1425840	1427120	Great question.
1427120	1427960	Great question.
1427960	1429680	A little bit.
1429680	1432240	So he can navigate a little bit with his GPS.
1432240	1434120	And because he's learned certain routes
1434120	1437000	as a series of almost verbal commands,
1437000	1439120	like if you're here, turn right, then do, do, do, do,
1439120	1440760	like that whole kind of thing.
1440760	1443000	It's not what any of you guys could do.
1443000	1445760	If you guys are driving around in Cambridge
1445760	1447960	or walking around campus, remember
1447960	1450640	where they blocked off this whole middle of campus
1450640	1451760	a couple of years ago?
1451760	1452880	It was so irritating.
1452880	1454200	I would go there and it's like, oh, god.
1454200	1455080	They blocked it off.
1455080	1457440	I can't get over to lobby 7.
1457440	1459440	Well, you immediately come up with an alternate route.
1459440	1461240	It's like, OK, I guess we're going to have to do this.
1461240	1462640	You come up with an alternate route.
1462640	1465560	This is what a normal navigation system can do.
1465560	1466800	Bob can't do that at all.
1466800	1468840	He's like, route blocked?
1468840	1469520	No idea.
1469520	1472800	Get out the phone, right?
1472800	1473300	Yeah?
1473300	1475580	Does he get at estimating distances?
1475580	1478940	Does he know something is a certain number of miles away?
1478940	1480740	Yes.
1480740	1481980	Yes, he is.
1481980	1484380	And that's very interesting.
1484380	1486460	But that seems to be kind of a different thing.
1486460	1488420	You could think about all the different kinds of cues
1488420	1493020	you have for distance beyond your kind of literal navigation
1493020	1495020	skills.
1495020	1496020	Yeah?
1496020	1500380	Can you retrace the steps a couple of minutes after?
1500380	1501660	A little bit.
1501700	1503700	A couple minutes, yes.
1503700	1506820	The next day, I mean, it would be kind of like this thing.
1506820	1509460	It's like, you know, I vaguely remember that I was here.
1509460	1511820	I turned right, so I better do that again.
1511820	1513340	Yeah, did you have a question?
1513340	1517100	Can you navigate within buildings?
1517100	1518500	No, not very well.
1518500	1521580	And this is a problem, because iPhones don't usually.
1521580	1525460	So new hotels, big problem.
1525460	1528180	Finding the bathroom down the hall or the front door
1528180	1531300	in a hotel, big problem.
1531300	1534580	Yeah, I mean, you know, these are problems you can come up
1534580	1537340	with workarounds, but it's not life-threatening.
1537340	1540100	But it's extremely inconvenient.
1540100	1541020	Yeah?
1541020	1544900	So this is the case that those navigational skills
1544900	1547860	that he developed longer, a long time ago,
1547860	1548660	those are stronger.
1548660	1551580	So he has a harder time developing.
1551580	1553300	Sorry, I mean, so new hotels are a problem,
1553300	1556500	but if it's a fixie, it's more familiar like his home.
1556500	1557900	Is it easier for him to navigate?
1557900	1558900	It's a great question.
1558900	1562340	You might think that the kind of navigational maps
1562340	1564260	you laid down long ago would be intact.
1564260	1567380	So is it just that you can't learn new ones?
1567380	1570060	So it's a great question.
1570060	1572620	The answer is kind of complicated in this case.
1572620	1576020	For routes that he's memorized, there's
1576020	1578060	a whole different system for knowing a route
1578060	1581420	and really having an abstract knowledge of a place that
1581420	1583380	enables you to devise a new route if something
1583380	1584620	is blocked on that route.
1584620	1587660	So for highly over-learned routes, he's OK.
1587660	1589420	Like he remembers, like this you do.
1589420	1590220	It's like a sequence.
1590220	1592460	It's like a memorized motor sequence.
1592460	1594780	You do A, and then B, and then C, and then D.
1594780	1597900	So he's OK with those with routes he learned long ago.
1597900	1602500	But he is not good at coming up with a new route in a place
1602500	1605900	that he learned long ago.
1605900	1606300	All right.
1606300	1607340	We'll take one last question.
1607340	1608340	Yeah?
1609020	1611820	Does he have conscious access to past knowledge
1611820	1615620	that he can't use in the case?
1615620	1618660	And does he have conscious knowledge that this is the case?
1618660	1620620	Can he, how does he specify that?
1620620	1623780	Oh, I'm having trouble figuring this out.
1623780	1624900	No, he knows.
1624900	1626820	Well, he knows, because when he tries to figure out
1626820	1628580	which way to head, he has no idea.
1628580	1632460	So he's extremely aware of it and very articulate
1632460	1634060	on precisely what happens.
1634060	1638300	And so what he says is, like, if he's looking at a place,
1638660	1639660	here's something he says.
1639660	1640860	He's looking at a place.
1640860	1642260	He knows where he is, because there's
1642260	1643820	all kinds of other bits of information
1643820	1645940	that tell you where you are, because you intended to go there
1645940	1647580	and the relevant things are happening and all this.
1647580	1651220	He knows where he is, and it looks familiar.
1651220	1655340	If he tries to imagine what's behind him,
1655340	1657420	he says that he, like, starts to get it,
1657420	1659180	and it just kind of vaporizes.
1659180	1660620	He just can't hang on to it.
1660620	1664420	He can't kind of construct a stable mental image
1664420	1666500	of nearby places.
1666500	1668060	So I don't know exactly what that means,
1668060	1670620	but he's very articulate and can report
1670620	1673140	what he experiences when he tries
1673140	1675100	to access this kind of information.
1676380	1678620	So what you guys, we'll go on, but what I want to say
1678620	1682540	is what you guys just did is exactly what we do in my field.
1682540	1685820	We try to take a mental ability and tease it apart
1685820	1688260	and say, is it exactly this or is it exactly that?
1688260	1691740	And you guys all just did it beautifully, right?
1691740	1694620	So a lot of what we do in my field is kind of,
1694660	1698660	this kind of common sense parsing of mental abilities.
1698660	1701500	What is a particular mental ability?
1701500	1703100	How does it relate to some other one?
1703100	1704300	Are these things separable?
1704300	1706220	Can you lose one and not the other?
1706220	1709100	Do they live in different parts of the brain, et cetera?
1710260	1712260	All right, so that's the story.
1713100	1718100	I'm gonna cash out some of the particular themes
1719580	1721540	that came out from this story
1721540	1723540	that we'll echo through this course.
1723540	1725060	And the first and most obvious one
1725060	1728460	is the brain isn't just a big bunch of mush, right?
1728460	1731460	It has structure, it has organization.
1731460	1734020	The different bits do different things, okay?
1735820	1739060	Importantly, when Bob had this big lime in his head,
1739060	1741540	he didn't just get a little bit stupid.
1741540	1745180	No, his IQ, if he'd take an IQ test, would be unchanged.
1745180	1748360	He lost a very specific mental ability, okay?
1749340	1752020	And that is fascinating,
1752020	1753860	but it's also good news for science
1753860	1755500	because often when you try to understand
1755500	1758100	a complicated thing, a great way to make progress
1758100	1760220	is to first figure out what the parts are
1760220	1761540	and then later try to figure out
1761540	1763160	how does each individual part work
1763160	1764660	and how do they work together?
1764660	1765900	But if there's part structure,
1765900	1768140	there's at least a place to start, okay?
1769300	1773860	Okay, second theme is that some parts of the brain
1773860	1776860	do extremely specific things, right?
1776860	1779180	Not all of them, some of them are quite general
1779180	1781720	and are engaged in lots of different mental processes,
1781720	1783760	but some are remarkably specific.
1783760	1785200	We'll talk a lot about that.
1786400	1790160	Third big theme, the organization of the brain
1790160	1793520	echoes the architecture of the mind, okay?
1795640	1798120	And I would say the fundamental pieces of the brain
1798120	1801640	are telling us what are fundamental parts of the mind.
1801640	1803120	And that's why I'm in this field.
1803120	1804360	That's what I think is cool.
1804360	1806040	You know, the brain is just like a bunch of cells,
1806040	1807080	like it's a physical thing.
1807080	1808740	Who cares about a physical thing?
1808740	1811780	The reason we care about it is that's where our mind lives.
1811780	1813140	And if we study that physical thing,
1813140	1815500	we can learn something about our minds.
1815500	1818180	And that's pretty cosmic, I think.
1818180	1820740	So the point of all of this kind of work is not to say,
1820740	1823380	oh, that mental process is here, not there.
1823380	1824220	Who cares?
1824220	1825060	I don't really care.
1825060	1826980	I mean, at some point you need to have a ballpark sense.
1826980	1828780	You need to know to study the things.
1828780	1831620	But the interesting question is not where these things
1831620	1834060	are in the brain, but which mental processes
1834060	1837380	have their own specialized machinery and why those?
1837700	1840020	Yeah.
1840020	1843460	Another important theme, how do brains change?
1843460	1845260	Bob didn't recover after his brain
1845260	1847740	damaged in that very particular mental function
1847740	1849580	that he lost.
1849580	1852500	If all of that had happened when he was five years old,
1852500	1854980	he probably would have.
1854980	1858180	So how do brains change over normal development?
1858180	1861140	How do they change from learning and experience?
1861140	1863780	How do they change after injury?
1863780	1866980	And the final theme echoed in that story
1866980	1868700	is there are lots and lots of different ways
1868700	1870820	to study the brain.
1870820	1872980	There are the simple behavioral observations.
1872980	1875300	Bob can't navigate, but he can do everything else.
1875300	1877100	OK, that's really deep and informative.
1877100	1880980	Low-tech, but really powerful.
1880980	1884340	The anatomical brain images that showed where the line was
1884340	1887300	in Bob's brain, that gives you another kind of information
1887300	1890340	where's the physical structure of the brain.
1890340	1893020	The functional images that we had done in my lab
1893020	1896780	to discover the parahippocampal place area.
1896780	1900020	And the studies of what mental abilities are preserved
1900020	1902460	in which are lost and people who have alterations
1902460	1904020	of their brain.
1904020	1907180	So those are just a few of the kinds of methods in our field,
1907180	1910620	each of which tells us about a different kind of thing
1910620	1912540	about the brain.
1912540	1916580	So those are the themes I was trying to get at here.
1916580	1920780	So let's move on to the why, how, and what
1920780	1922300	of exploring the brain.
1922300	1926300	I'm going to assign the TAs to get me to shut up at,
1926300	1928460	let's see, are we're supposed to end at five minutes before the end
1928460	1929460	of class, is that right?
1929460	1930540	Is that MIT tradition?
1930540	1940340	OK, so at, oh my, shockingly soon, 11.45, you're going to know.
1940340	1942020	Oh, great, thank you.
1942020	1942580	Thank you.
1942580	1944980	This is one of the many things TAs are for.
1944980	1947900	They pick up the hundreds of typos and mindos and all
1947900	1948380	of that.
1948380	1948940	Excellent.
1948940	1951060	I'm thinking, how the hell did I so mis-timed this?
1951060	1951940	Thank you, Heather.
1951940	1953900	OK, good, we'll go on.
1953900	1956660	OK, why should we study the brain?
1956660	1959340	First most obvious reason, know thyself.
1959340	1962780	Know what this thing is that's operating in our heads.
1962780	1966340	This is who you are, right, is your brain.
1966340	1971900	There are lots of very fine and important organs in the body,
1971900	1974380	but the brain is special, right?
1974380	1978500	So a heart is important, you die without it,
1978500	1981860	but it's the brain that's your identity, right?
1981860	1985340	So there's a reason that surgeons do heart transplants.
1985340	1986140	That makes sense.
1986140	1989460	Something wrong with your heart, you need another heart, OK?
1989460	1991660	But why don't they do brain transplants?
1991660	1993420	That wouldn't make sense, right?
1993420	1995260	If there's something wrong with my brain,
1995260	1997740	it doesn't make sense to take someone else's brain
1997740	2000260	and put it in here, because then I'd be that other person.
2000260	2003540	It doesn't make sense, because the brain is who you are.
2003540	2004980	OK, so the brain is really special.
2004980	2007740	It's not just another organ.
2007740	2010780	That's why a few years ago we had the decade of the brain,
2010980	2013860	not the decade of the pancreas or the liver or the kidney, right?
2013860	2015100	People need to study these things.
2015100	2017060	They need to know how to fix them.
2017060	2021780	They're important, but they're not as cosmic as the brain, OK?
2021780	2028500	All right, second reason why we should understand brains,
2028500	2032220	and that is to understand the limits of human knowledge.
2032220	2034900	Like the more we understand about the human mind,
2034900	2040020	the more we can actually evaluate how good our knowledge is.
2040020	2043420	Are there things that we might not be able to think?
2043420	2045460	Possible true scientific theories,
2045460	2048220	we might not be able to understand ever?
2048220	2049900	You can think of studying the mind
2049900	2052580	as a kind of empirical epistemology,
2052580	2055060	a way to actually know about the knower
2055060	2058900	so we can figure out how good the knowledge is in that knower.
2058900	2060820	So that's another reason.
2063180	2065980	A third reason is to advance AI.
2065980	2068380	And so up until a few years ago, I
2068380	2069820	used to give lectures on vision,
2069820	2073460	and they would all start with some version of this.
2073460	2076540	You guys all have amazing visual abilities
2076540	2078620	in the back third of your brain that does vision.
2078620	2080300	You can do all this incredible stuff
2080300	2082540	that no machine can touch.
2082540	2083740	That's off to you.
2083740	2086300	You have an amazing visual system back here,
2086300	2090180	and those guys in AI, it is mostly guys, guys, gals, whatever,
2090180	2093580	those people in AI, could only dream
2093580	2095860	of coming up with algorithms as good as the one that's
2095860	2099300	running in the back of your head.
2099500	2102380	You can't quite start the lectures that way anymore.
2102380	2104020	So if any of you have been living in a cave
2104020	2106940	and not heard about deep nets, there's
2106940	2109380	been a massive revolution.
2109380	2112500	And all of a sudden, deep nets are
2112500	2115020	doing things that are really close to human abilities,
2115020	2117020	particularly in vision.
2117020	2120140	So for example, in visual object recognition,
2120140	2123180	machines were way far behind human vision
2123180	2128860	until very recently, especially when this paper here came out,
2128860	2131700	was published in 2012.
2131700	2134660	First author, Khrushchevsky, it has now
2134660	2137540	been cited an astonishing 33,000 times.
2137540	2139420	Actually, I made this slide a couple of weeks ago.
2139420	2142060	It's probably been cited 36,000 times by now.
2142060	2144660	You could look it up on Google Scholar and find out.
2144660	2147020	That is a huge number of citations.
2147020	2149020	The influence of this paper is ginormous.
2149020	2151220	Probably half of you have already heard about this paper.
2151220	2153180	Raise your hand if you've heard about this paper.
2153180	2155060	OK, all right.
2155060	2157420	Major big news.
2157420	2160220	So what's so important about this paper?
2160220	2162980	Well, they trained, as probably most of you know,
2162980	2166820	they trained a deep net on the over a million images
2166820	2171140	in ImageNet, a massive computer database of images.
2171140	2174340	And they basically taught it to do object recognition.
2174340	2176660	And it performed much more accurately
2176660	2181340	than any previous system, and it approaches human abilities.
2181340	2184380	So this is major, this is a radical change in the situation
2184380	2186140	that we were in five years ago.
2186180	2187780	So things have changed radically.
2187780	2190820	So just as an example, here's one
2190820	2193500	of the figures from that seminal paper.
2193500	2196260	So here is one of the images from ImageNet
2196260	2200500	that AlexNet, this trained network, was tested on.
2200500	2202460	And the correct answer, according to ImageNet,
2202460	2204260	is that that's a mite.
2204260	2205820	And here's what AlexNet says.
2205820	2208380	Its number one first answer is mite.
2208380	2210100	And its second, third, fourth answers
2210100	2212740	are black widow, cockroach, et cetera.
2212740	2214100	So pretty damn good.
2214100	2215980	The mite is even sticking off the edge of the frame,
2215980	2217060	and it gets it.
2217060	2220660	Containership, first choice, container ship, pretty good.
2220660	2224020	Second choice makes sense, lifeboat, not bad.
2224020	2225460	Look at that, motor scooter.
2225460	2227420	I can barely even see the motor scooter in there,
2227420	2230380	but AlexNet, awesome.
2230380	2232820	Leopard, awesome.
2232820	2235260	Even when AlexNet makes a mistake,
2235260	2237540	the mistake is totally understandable.
2237540	2240820	Like, according to ImageNet, that is a picture of a grill.
2240820	2243020	And AlexNet calls it a convertible.
2243020	2246700	I'm siding with AlexNet on this one over ImageNet.
2246700	2250100	This, the correct answer, is mushroom.
2250100	2252060	And AlexNet says agaric.
2252060	2253140	I had to look that up.
2253140	2256260	It's like a particular kind of mushroom.
2256260	2258220	This one's pretty funny.
2258220	2260700	ImageNet says that's pictures of cherry.
2260700	2262060	There's cherries in the foreground.
2262060	2263900	But AlexNet says dalmatian.
2263900	2266540	I'm siding with AlexNet on this.
2266540	2268580	And Madagascar, cat, et cetera.
2268580	2270260	So pretty amazing.
2270260	2274220	And nothing even close to this was possible before 2012.
2274220	2275580	So this is very recent history.
2275580	2280140	And it has totally shaken up the field in lots of ways.
2280140	2281740	And so that's been transformative,
2281740	2283620	not just for computer science, but it's also
2283620	2287260	been transformative for cognitive science and neuroscience.
2287260	2290260	Because now we have algorithms, like here's this deep net,
2290260	2291860	and it does this thing.
2291860	2294660	So that's a possible theory of how humans do it.
2294660	2298140	It's a possible computationally precise theory
2298140	2299460	of what's going on in here.
2299460	2300660	And we didn't used to have those.
2300660	2302820	And now we have those for a number of domains.
2302820	2304540	And that's shaking up the field.
2304540	2306220	There will be a whole lecture on deep nets
2306220	2309060	and how you can use them to think about minds and brains
2309060	2310660	toward the end of the course, guest lecture
2310660	2313100	by my postdoc, Katherine Dobbs.
2313100	2316420	And we'll hear more about that.
2316420	2318700	But let's first step back a second and say, OK,
2318700	2320660	do they really perform as well as humans,
2320660	2323700	even on just object recognition?
2323700	2328180	Well, what if we tested it on images, not in ImageNet?
2328220	2330180	ImageNet is a pretty good test, because these things,
2330180	2331900	as you can see, are highly variable.
2331900	2332820	They have backgrounds.
2332820	2333580	They're complicated.
2333580	2335300	They're real-world images.
2335300	2339500	But they were photographs taken by people in a particular way
2339500	2341780	with a particular goal.
2341780	2343780	And most of the photographs you take, you throw out,
2343780	2345500	they don't end up in ImageNet.
2345500	2348940	ImageNet is a weird little idiosyncratic subset
2348940	2351380	of the kind of visual experience that we have.
2351380	2354260	So would this really generalize?
2354260	2357100	So it so happens that Boris Katz and Andrei
2357100	2359380	Marbu across the street in Seasale
2359380	2361180	have been doing some very interesting studies.
2361180	2363260	This stuff isn't published yet, but I got their permission
2363260	2365420	to tell you about this cool stuff they're doing.
2365420	2367300	And they're saying, hey, let's test
2367300	2371180	AlexNet and other similar deep nets since then
2371180	2374420	on a more realistic, harder version of object recognition
2374420	2377060	that's more characteristic of what humans do.
2377060	2380700	And so they're generating this huge data set of stimuli
2380700	2382260	that they crowdsource.
2382260	2383980	And so people, workers on Mechanical Turk,
2383980	2385740	go on there and create images for them.
2385780	2389420	So they get instructions like, hold a object
2389420	2391540	in this particular location or at this angle
2391540	2393860	or move it here and send us the images.
2393860	2397340	So they are getting, I think, hundreds of thousands of images
2397340	2398740	to test this on.
2398740	2400700	And they're much more variable in the location
2400700	2404220	of the object in the image and its orientation and so forth.
2404220	2406500	So for example, you guys have no problem
2406500	2407820	telling what that thing is, but it's
2407820	2410340	a slightly atypical example.
2410340	2412580	Likewise, what's the object on the floor there?
2412580	2414260	You can tell what it is, but it's
2414300	2416540	slightly atypical example.
2416540	2420500	And so what Boris and Andre are finding
2420500	2422380	is that human performance is still pretty good
2422380	2424100	on these images.
2424100	2427900	But the deep nets are terrible at this stuff.
2427900	2431940	So ResNet, one of the more recent ones,
2431940	2434460	drops from 71% correct on ImageNet
2434460	2438220	to around 25% correct on these images.
2438220	2441980	And the other similar, fancy, more recent networks
2441980	2443860	do similarly badly.
2443900	2450820	So on the one hand, the deep nets are awesome and transformative.
2450820	2452300	No question about it.
2452300	2455460	But on the other hand, despite all the hype,
2455460	2458540	they're still not quite like human object recognition.
2458540	2460380	They're a whole lot closer than they used to be,
2460380	2463860	but they're not really there.
2463860	2466780	And more generally, what about harder problems
2466780	2470500	like image understanding, not just labeling and classification,
2470500	2473100	but understanding what's going on in image?
2473100	2477300	So you guys have probably seen image captioning bots.
2477300	2478540	There are lots of these around now.
2478540	2482340	This kind of hit the scene in 2016
2482340	2485380	when Google AI came out with a captioning algorithm.
2485380	2487020	And of course, right around the same time,
2487020	2489340	Microsoft had a captioning algorithm.
2489340	2490980	And let's see how they do.
2490980	2492180	So this is an example.
2492180	2495060	You give this algorithm this picture here,
2495060	2499620	and it says that's a dinosaur on top of a surfboard.
2499620	2502020	That's pretty damn good, right?
2502060	2504500	OK, wow.
2504500	2506340	Let's look more generally how well this thing works
2506340	2508500	at other examples.
2508500	2509980	It looks at this, and it says, that's
2509980	2512220	a group of people on the field playing football.
2512220	2515220	It's like, wow, OK.
2515220	2517060	A snow-covered field.
2517060	2519500	Pretty good.
2519500	2523700	Yu Xiuen and Ding Ning posing for a picture.
2523700	2526460	I don't know, but these things are very good at face recognition.
2526460	2530140	That's probably exactly those two people, right?
2530140	2533220	A car parked in a parking lot.
2533220	2534700	Pretty good.
2534700	2536140	A large ship in the water.
2536140	2537940	Pretty good.
2537940	2540180	A clock tower lit up at night.
2540180	2543060	Awesome, right?
2543060	2545580	A vintage photo of a pond.
2545580	2548020	Well, the vintage part, I don't know where the pond is.
2548020	2549260	There's a little water in there.
2549260	2549820	I don't know.
2549820	2550500	Not way off.
2553020	2556060	A group of people that are standing in the grass
2556060	2558180	near a bridge.
2558180	2559220	Not really.
2559260	2560580	There's grass.
2560580	2561700	There's a bridge, sort of.
2561700	2566020	There's people, but not really, right?
2566020	2569100	A group of people standing on top of a boat.
2569100	2569860	Definitely not.
2572980	2575020	A building with a cake.
2575020	2575500	What?
2577860	2580260	A person holding a cell phone.
2580260	2582900	Not.
2582900	2584260	A group of stuffed animals.
2587540	2588700	I love this one.
2588700	2591180	A necklace made of bananas.
2591180	2593620	Wow, we've really landed on Mars here.
2596260	2599180	A sign sitting on the grass.
2599180	2600300	Talk about missing the boat.
2603140	2604700	Now, look at this picture for a second.
2604700	2606300	Just figure out what's going on here.
2609180	2610780	Takes a couple seconds.
2610780	2613260	Everyone got it?
2613260	2615660	There's a lot going on here.
2615660	2618140	OK, so this algorithm says, I think
2618180	2620220	it's a group of people standing next to a man
2620220	2622660	in a suit and tie.
2622660	2625180	And the algorithm is correct, but the algorithm
2625180	2629100	has profoundly missed the boat.
2629100	2631500	So I'm channeling, actually I stole these slides
2631500	2633660	from Josh Tenenbaum, but let me channel him for a moment
2633660	2635460	and say what his big idea is, which I think
2635460	2637220	is really important.
2637220	2639460	And that is that both humans and deep nets
2639460	2642860	are very good at pattern recognition, pattern classification.
2642860	2646740	This is a cat, or a dog, or a car, or a toaster.
2646740	2649580	What they're not good at, what humans are good at,
2649580	2652180	but the deep nets are not, is building models
2652180	2654380	to understand the world.
2654380	2656020	And so when you look at this picture,
2656020	2657300	there are all kinds of things that
2657300	2659940	are crucial for really understanding at a deep level
2659940	2661620	what's going on in here.
2661620	2665420	We need to know what some people here know,
2665420	2668740	but the guy on the scale does not know.
2668740	2672100	Namely, even if you don't recognize that that's James
2672100	2676260	Comey, I think it is, here's Obama with his foot on the scale.
2676260	2679260	You need to know that people find it embarrassing
2679260	2680780	if they weigh too much.
2680780	2683900	You need to know that he can't see that Obama's doing it.
2683900	2686740	You need to know that they can see it, even though he can't.
2686740	2689020	And that's kind of the essence of humor.
2689020	2692980	There's just a whole universe of rich structural information
2692980	2695140	going in here that is part of what it means
2695140	2697300	to understand this picture.
2697300	2702740	And no deep net is even close to doing that kind of thing.
2702740	2704420	OK?
2704420	2708740	So bottom line of all this is, or let me just go on more
2708740	2714340	generally, AI systems can't navigate new situations,
2714340	2719020	infer what others believe, use language to communicate,
2719020	2722740	write poetry and music to express how they feel,
2722740	2726780	or create math to build bridges, devices,
2726780	2729020	and lifesaving medicines.
2729020	2731300	That's a quote from our leader, Jim DeCarlo,
2731300	2734020	head of this department, published and wired a year ago
2734020	2737780	in a beautiful article on the limitations of deep nets.
2737780	2741540	But more generally, the point is that, yes, AI is taking
2741540	2743780	a massive leap now when we're right in the middle of it,
2743780	2746380	and it's super exciting, and it's helpful to neuroscience
2746380	2748700	and cognitive science.
2748700	2751700	But AI has a lot to learn from us, too.
2751700	2753340	A lot to learn from what's going on in here
2753340	2756460	and how this thing works that those AI systems still
2756460	2758220	can't touch.
2758220	2758940	OK.
2758940	2761340	So all of that was my third reason for studying.
2761340	2764020	We're still in the Y. Are we studying the human brain?
2764020	2765980	The fourth reason to study the human brain
2765980	2768140	is the one most compelling to me,
2768140	2771820	and that is that it is just simply the greatest intellectual
2771820	2774220	quest of all time.
2774220	2776300	We could fight about cosmology.
2776300	2778340	I'm not going to fight with you about anything else.
2778340	2780020	I don't think there's any contest.
2780020	2782700	It's the greatest intellectual quest of all time.
2782700	2784700	And that's why I'm in it, and that's why I hope
2784700	2787020	it'll be fun for you.
2787020	2789820	OK, that was the Y. How are we going
2789820	2791660	to study the human brain?
2791660	2793060	So here's this thing.
2793060	2794740	How are we going to figure out how it works?
2794740	2796020	It's kind of daunting.
2796020	2798060	It's not totally obvious.
2798060	2799580	The first thing to realize is that there
2799580	2802420	are lots of levels of organization in this thing,
2802420	2804620	and hence, lots of ways of studying it.
2804620	2807100	We could look at molecules and their interactions,
2807100	2809340	lots of people in this building do that.
2809340	2812460	We could look at properties of individual neurons.
2812460	2814780	We could look at circuits of neurons interacting
2814780	2816500	with each other.
2816500	2818620	We could look at entire brain regions
2818620	2820340	and what their functions are.
2820340	2823060	We could look at networks of multiple brain regions
2823060	2825700	interacting with each other.
2825700	2828980	And so all of those things are possible.
2828980	2830860	But actually, what we're going to do in the course
2830860	2833060	is none of those things in particular.
2833060	2835860	Instead, we're going to ask a somewhat different question.
2835860	2840340	And that question is, how does the brain give rise to the mind?
2840340	2842420	And to understand that question, we're
2842420	2845380	going to do more at this level and less at the upper levels.
2845900	2848220	OK?
2848220	2850980	So to answer this question, we need to start with the mind.
2850980	2852380	We need to, if we're going to understand,
2852380	2854420	how does this thing produce a mind,
2854420	2856300	we need to first figure out, what is a mind?
2856300	2858500	What do we know about minds?
2858500	2860620	OK?
2860620	2863140	And so we need to start with the various mental functions
2863140	2866460	that minds carry out, things like perception, vision,
2866460	2870900	hearing, aspects of cognition, like understanding language,
2870900	2874580	thinking about people, thinking about things, et cetera.
2874580	2875820	OK?
2875820	2879740	And so for each mental function, what we're going to do in here
2879740	2883060	is start by trying to understand how it works in minds,
2883060	2885180	as well as we can, or what it is that we're
2885180	2887460	trying to understand that minds can do.
2887460	2889260	What is computed and how?
2889260	2891220	And then we're going to look at its brain basis
2891220	2892660	and try to figure out what we can
2892660	2895140	figure out about how that mental function is implemented
2895140	2896380	in a brain.
2896380	2899140	So the first question we'll ask for all of these domains
2899140	2902820	is, is there specialized machinery to do that thing?
2902820	2904380	And then we'll ask, what information
2904380	2907140	is represented in the relevant parts of the brain?
2907140	2910060	And when is that information represented?
2910060	2911220	OK?
2911220	2912780	And how?
2912780	2915500	OK, so how are we going to answer those questions?
2915500	2918060	Well, there's lots and lots of methods in our field.
2918060	2918860	OK?
2918860	2922140	And so the first set of methods, if we want to understand minds,
2922140	2924740	the first set of methods are the basic stuff
2924740	2926900	of cognitive science, psychophysics.
2926900	2929580	That means showing people visual stimuli
2929580	2932420	or playing them sounds and asking them what they see or hear.
2932420	2935700	Nice and low-tech, but lots has been learned from those methods.
2935700	2937740	You collect reaction time and accuracy,
2937740	2939660	and it's amazing how much you can learn
2939660	2943620	from these methods that have been around for 100 years or more.
2943620	2946580	Perceptual illusions are similarly very informative
2946580	2948300	about how minds work.
2948300	2952260	Now, let me say an important thing that arises here.
2952260	2954220	Last year was the first time I taught this course,
2954220	2955780	and I would say it went so-so.
2955780	2958580	I'm aiming for it to be much better this year.
2958580	2960100	And one of the ways I'm trying to do that
2960100	2963700	is to be responsive to the student evals I got last year,
2963700	2966100	which were not fabulous across the board,
2966100	2967380	hurt my feelings badly.
2967380	2970180	But once I got over myself, I decided to just listen to them
2970180	2971540	and try to fix it.
2971540	2974300	And one way to fix it is to be honest with you today about what
2974300	2975980	this course is going to cover.
2975980	2983060	So in my evals, student 50458, bless them, offered this comment.
2983060	2985180	This class was not sold in the correct way.
2985180	2986660	It should not be called the human brain,
2986660	2989020	because it was basically just a cognitive science not a brain
2989020	2989520	class.
2989520	2992480	I expected to learn very different material.
2992480	2994040	So I don't know who the student is.
2994040	2998120	I wish I could apologize to them, but I will say to you,
2998120	3002720	sorry, student 50458, sorry to make that clear.
3002720	3004920	The fundamental reason the brain is cool
3004920	3007240	is that it gives rise to the mind.
3007240	3010280	And that means that studying the biological properties
3010280	3012680	of the brain without considering the mental functions
3012680	3015440	it implements, it'd be kind of like trying
3015440	3017320	to study the physical properties of a book
3017320	3020480	without considering the meaning of its text.
3020480	3022240	So we're going to spend a lot of time
3022240	3023920	doing cognitive science in here.
3023920	3027080	And if you had a different impression, sorry about that,
3027080	3029040	but that's what we're doing here.
3029040	3030040	OK?
3030040	3030720	All right.
3030720	3032160	So how are we going to answer this up?
3032160	3034280	Lots of cognitive science.
3034280	3037120	So how are we going to look at the brain basis?
3037120	3039320	Well, we're going to look at neuropsychology patients,
3039320	3041360	people like Bob, who have damage to the brain
3041360	3043960	and what functions get preserved and lost.
3043960	3047160	We'll look at a lot of studies with functional MRI,
3047200	3049120	neurophysiology, where you can record
3049120	3052040	from individual neurons in animal brains
3052040	3055320	and in rare cases, even in human brains,
3055320	3056920	under clinical situations where they
3056920	3060720	need to have electrodes in their brain anyway for neurosurgery.
3060720	3065800	We'll look at EEG, recorded from electrodes on the scalp.
3065800	3068280	And MEG, recording from magnetic fields,
3068280	3071360	from squids placed next to the scalp.
3071360	3073160	We'll look at connectivity measures
3073160	3076720	with a method called diffusion tractography, et cetera.
3076720	3078760	So lots of methods.
3078760	3081920	And so which mental functions will we cover?
3081920	3083680	Well, to tell you about that, I need
3083680	3085880	to tell you about the huge progress that
3085880	3088480	has happened in our field in the last 20 years.
3088480	3088880	OK?
3088880	3091320	All of this is quite recent.
3091320	3094640	And so let's back up to 1990.
3094640	3096440	Here is approximately what we knew
3096440	3099800	about the organization of the human brain in 1990.
3099800	3101840	The black ovals are the bits that
3101840	3104160	are primary sensory and motor regions
3104160	3107800	that have been known for a long time, even by 1990.
3107800	3109160	And the colored bits are the bits
3109160	3112280	where we had some idea that face recognition might go on
3112280	3115480	somewhere in the back end of the bottom of the right hemisphere
3115480	3118160	because of people who had damage back there and lost
3118160	3121760	their face recognition ability, sometimes preserving
3121760	3125440	their ability to visually recognize words and scenes
3125440	3128760	and objects, only losing their ability to recognize faces.
3128760	3130080	OK?
3130080	3133360	The language regions we had known about for nearly 200 years
3133360	3135280	were Broca and Wernicke and others
3135280	3137880	who had studied patients with damage in those regions
3137880	3140920	and noted that they had problems with language function.
3140920	3142920	And similarly, many people had reported
3142920	3145640	that if you have damage up here in the prideelobes,
3145640	3148520	you sometimes lose your ability to direct your attention
3148520	3150720	to different places in the visual scene.
3150720	3155720	So that was approximately what was known in 1990.
3155720	3158280	And here's what we know now.
3158280	3163040	We now know, thanks largely to functional MRI,
3163080	3167440	that for dozens of regions in the brain, in every one of you,
3167440	3171520	we have a pretty good idea of the function of that region.
3171520	3173480	This is major progress, right?
3173480	3177120	This is a kind of rough sketch of the organization
3177120	3179320	of the human mind and brain that we have now
3179320	3181400	that we didn't have 20 years ago.
3181400	3184480	And that's awesome.
3184480	3188000	And so that has made possible a lot of progress
3188000	3189640	building with other methods.
3189640	3192840	And so what we'll study in this course
3192840	3195000	is we'll focus on those mental functions
3195000	3198040	where the brain bases are best understood.
3198040	3201000	And that will include things like the visual perception
3201000	3204280	of color, shape, and motion, visual recognition
3204280	3208040	of faces, places, bodies, and words, and scenes.
3208040	3209800	Didn't make it on the slide.
3209800	3210560	Oh, yes, it did.
3210560	3213880	Perceiving scenes and navigating.
3213880	3216200	Understanding numbers.
3216200	3217720	Yes, there's a whole lot about the brain
3217720	3219560	bases of understanding numbers.
3219560	3222920	Perceiving speech and perceiving music.
3222920	3225000	Understanding language.
3225000	3228720	Understanding other people and their minds.
3228720	3230280	So those are the kinds of topics
3230280	3232840	where there's been a lot of progress recently
3232840	3235600	in understanding the brain bases of those mental functions.
3235600	3237840	And so those are the ones we'll focus on.
3237840	3240120	And that means there's going to be a lot on perception,
3240120	3243960	high level vision, and high level audition.
3243960	3247200	Because that's one where a lot of progress has been made,
3247200	3249080	and it's also a lot of the cortex, right?
3249080	3251280	As I mentioned a moment ago, the whole back third of your brain
3251280	3253760	does vision, construed broadly.
3253760	3255160	And so some people might say, why
3255160	3256400	should spend all this time in vision?
3256400	3258200	Well, it's like a big part of what your brain does.
3258200	3259720	We are very visual animals, so we'll
3259720	3263000	spend a lot of time on vision.
3263000	3266280	OK, and so for each of these functions,
3266280	3270280	we will ask, to what extent is this mental function implemented
3270280	3273600	in its own specialized brain machinery?
3273600	3275480	Are there multiple different brain regions
3275480	3278320	that carry out that function?
3278320	3279480	What does each one do?
3279480	3282840	Is there a division of labor between those different regions?
3282840	3286720	How does that system arise in development?
3286720	3289840	How does it have homologs in other species?
3289840	3294440	Are these things uniquely human, or which of them are?
3294440	3297240	And also, along the way, other side cool questions
3297240	3299320	that will come up.
3299320	3302000	What if anything is special about the human brain?
3302000	3307440	How come we are taking over and largely destroying the planet?
3307440	3310080	And other species are not, right?
3310080	3311680	Besides destroying the planet, we're
3311680	3314280	doing some other cool things, like inventing science
3314280	3317840	and engineering and medicine and architecture and poetry
3317840	3319880	and literature and all these other music,
3319880	3323200	all these other awesome things that other species aren't doing.
3323200	3327040	How come our brains are doing that and other species aren't?
3327040	3328960	Where does knowledge come from?
3328960	3330960	You guys know all this stuff.
3330960	3333400	How much of that stuff was wired in at birth?
3333400	3336160	And how much of it did you get from experience?
3339200	3341960	How much can our minds and brains change over time?
3341960	3344200	Can we go study a new thing and get a whole new brain
3344200	3345280	region for that thing?
3348640	3352000	Can we change the basic structure just by training
3352000	3353960	or after brain damage?
3353960	3356920	Can we think without language?
3356920	3359640	How many of you have wondered about that question?
3359640	3362000	Yeah, really basic question.
3362000	3363600	Anya's answering it.
3363600	3364640	Anya and some others.
3364640	3366720	But Anya's doing a lot to answer that question.
3366720	3369040	There are actually empirical answers
3369040	3370920	to these longstanding deep questions
3370920	3372520	that everyone wonders about.
3372520	3373120	That's pretty cool.
3376160	3378680	Somebody back there asked a while ago about awareness.
3378680	3381480	Can we think, perceive, understand without awareness?
3381480	3384200	How much can go on, like in the basement of the brain,
3384200	3386320	when we don't even know what's going on down there?
3386320	3389000	We'll consider all of these other cool questions.
3389000	3389600	OK.
3389600	3393320	There's a bunch of things we won't cover in this course
3393320	3395880	for various reasons that could have been in here and just
3395880	3396280	aren't.
3396280	3397720	There's only so much time.
3397720	3399240	Motor control, it's really important
3399240	3400880	to know how you do things like pick up
3400880	3403240	objects and plan actions.
3403240	3406200	And we're just not covering that.
3406200	3409160	Something had to go.
3409160	3412440	Subcortical function, this is a very corticocentric course.
3412440	3414840	Most of the course will deal with the cortex.
3414840	3417360	That's where most of conscious thinking and reasoning
3417360	3418800	and cognition happens.
3418800	3420920	There's a lot of good stuff down in the basement of the brain,
3420920	3423600	and it's going to get pretty short shrift.
3423600	3426440	Not for any good reason, just what it is.
3426440	3428080	Decision making, important field,
3428080	3430320	not getting much coverage in here.
3430320	3433000	Importantly, circuit level mechanisms,
3433000	3435320	explanations of cognition.
3435320	3437800	If you think that we're going to understand not only what it
3437800	3439880	means to understand the meaning of a sentence,
3439880	3442840	but that I'm going to give you a wiring diagram of the neurons
3442840	3445520	that implement that function, sorry to be
3445520	3448720	the bearer of bad news, but nobody has a freaking clue
3448760	3450480	how you could get a bunch of neurons
3450480	3452800	to understand the meaning of a sentence.
3452800	3454040	So that's exciting.
3454040	3456240	That means there's a field for you guys to waltz into.
3456240	3457720	And probably in your lifetimes, people
3457720	3460200	will start to crack these things.
3460200	3462760	But just to know what we're headed into,
3462760	3465920	rarely, for almost no high-level mental functions,
3465920	3469920	do we have anything like a wiring diagram level
3469920	3474560	understanding of any perceptual or cognitive function.
3474560	3476040	So that's not in the cards for this course,
3476040	3479280	because it doesn't exist in the field.
3479280	3480640	OK, for that kind of thing, there
3480640	3482440	are cases where you can make progress.
3482440	3485520	You can understand, say, fear conditioning in a mouse.
3485520	3488720	Like, those circuits are being cracked wide open
3488720	3491000	by people in this building, people all around the world
3491000	3493080	with spectacular precision.
3493080	3495160	They know the specific classes of neurons,
3495160	3496400	their connectivity.
3496400	3498120	They know every damn thing about them.
3498120	3499960	But it's like, how does a mouse learn
3499960	3502400	that this thing is to be afraid of this thing?
3502400	3503560	OK, that's important.
3503560	3508680	But for more complex aspects of cognition in humans,
3508680	3510880	we can't usually have that kind of circuit level
3510880	3512720	understanding.
3512720	3514760	Lots of other things that will get short shrift.
3514760	3516600	Memory, not for any good reason.
3516600	3520080	I mean, there's a lot of coverage of memory in 900 and 901.
3520080	3522440	And it's just somehow I've a blind spot for understanding.
3522440	3524920	I've heard knowing how to talk interestingly about memory.
3524920	3526960	So I'm not going to give you a boring lecture on memory.
3526960	3529400	Instead, I'm not going to give you any lecture on memory
3529400	3532480	till I learn how to talk about it interestingly.
3532480	3534400	Reinforcement learning and reward systems,
3534400	3535840	I'm going to try to pull some of that in.
3535840	3537280	But it's not going to be a major focus,
3537280	3539960	even though it's a really important part of cognition.
3539960	3541960	Attention, there might be some at the end.
3541960	3544160	OK?
3544160	3549280	OK, how many of you have taken 900?
3549280	3552600	OK, looks like a little over a half.
3552600	3557280	OK, how many have taken 901?
3557280	3558400	Yeah, a little over a half.
3558400	3559280	OK, good.
3559280	3564120	So if you have great, good for you,
3564120	3566680	this course is designed as a tier two course for people
3566680	3568920	who have taken 900 or 901.
3568920	3571120	If you haven't, you're probably OK,
3571120	3573520	but you might need to do a little extra work.
3573520	3577960	And so I've already posted online and in the syllabus
3577960	3580960	information about actually a lecture I gave a year ago
3580960	3583120	on some of the background stuff that is no longer taught
3583120	3583680	in this course.
3583680	3585920	People hated it when I taught them stuff they'd already
3585960	3589640	encountered before, so I'm trying to minimize that.
3589640	3591200	And so that's a backup for those of you
3591200	3592400	who haven't taken these courses.
3592400	3594840	If you're worried about this, chat with me afterwards.
3594840	3595800	I think it will be OK.
3595800	3598400	Just count on doing a little bit of extra work, not much.
3601040	3605120	OK, for those of us who have taken it,
3605120	3606720	there's going to be a little bit of overlap.
3606720	3609080	It's simply impossible to have zero overlap.
3609080	3613080	I mean, what does John Gabrielli in 900 and Mark Baer in 901 do?
3613080	3614720	They survey the whole broad field,
3614720	3617400	and they pick the coolest stuff out of every little bit,
3617400	3619400	and they teach it to you exactly as they should.
3619400	3621480	But that means that when I come along and try to say,
3621480	3624040	I'm going to do a more intensive coverage of the coolest
3624040	3626640	things, there's going to be a teeny bit of overlap.
3626640	3629200	But I'll try to not make it too much, OK?
3629200	3631640	Just because the coolest stuff is the coolest stuff, right?
3637400	3639480	Also, the spin and the goals of this course
3639480	3643360	are quite different from both 900 and 901.
3643360	3646400	You will have to memorize a few things, but not much.
3646400	3649160	My real goal in this course is to have you understand things,
3649160	3652560	not memorize a sea of disjointed facts, OK?
3652560	3654280	So a little more on the goals.
3654280	3656360	Really, what I want you to get out of this course
3656360	3658760	is to appreciate the big questions in the field,
3658760	3663680	and what is at stake theoretically in each.
3663680	3665080	I want you to understand the methods
3665080	3667640	in human cognitive neuroscience, what each one can tell you,
3667640	3670480	what it can't, how different combinations of methods
3670480	3673520	can work synergistically and complementarily
3673520	3677800	to answer different facets of a question.
3677800	3679680	I do want you to gain some actual knowledge
3679680	3681320	about some of the domains of cognition,
3681320	3683480	where we've learned a bunch, both at the cognitive level
3683480	3685360	and the brain level.
3685360	3687880	Things like face recognition, navigation, language
3687880	3692160	understanding, music, stuff like that.
3692160	3694880	And crucially, I want you guys to be
3694880	3698000	able to read current papers in the field.
3698000	3700000	So if you look in the syllabus, the first few papers
3700000	3702680	are like 20 years old, but it's going to accelerate quickly,
3702680	3704440	and you'll be reading papers.
3704440	3706840	I'm trying to choose mostly papers published in the last year
3706840	3708520	or two, OK?
3708520	3710600	I'm trying to take you straight to the cutting edge
3710600	3712080	of the field, OK?
3712080	3712840	Yeah?
3712840	3715360	Are the papers going to be like people straight out of research
3715360	3717200	labs, or are they going to be like the annual research labs?
3717200	3719080	No, straight out of research labs.
3719080	3721920	You're going to read the real deal, not someone else's
3721920	3723760	blurry, they just read the abstracts
3723760	3725520	and put in some stuff in the review article.
3725520	3727720	No, you're going to read the actual paper.
3727720	3731120	That's the whole deal, yep.
3731120	3734000	OK, so those are the goals.
3734000	3735320	Good?
3735320	3737360	A few things, why no textbook?
3737360	3739400	This field is moving too fast for a textbook,
3739400	3744160	plus I have strong opinions, and I don't like any of the textbooks.
3744160	3746440	So any textbook is out of date.
3746440	3749080	We're going to be reading hot stuff that's hot off the press,
3749080	3751440	and so there's no that's not in the textbooks yet,
3751440	3753560	and so we're skipping that, and you're
3753560	3755680	going to go straight to original research articles.
3755680	3758240	So we'll be occasional review articles where relevant,
3758240	3760240	but mostly part of the agenda of this course
3760240	3763240	is to teach you to be not afraid of and able to read
3763240	3765760	current articles in the field.
3765760	3767800	All right, you've all been waiting for this.
3767800	3770400	OK, details on the grading, pretty standard,
3770400	3774920	midterm 25% of the class of the grade, final 25%.
3774920	3778680	It will be cumulative, but weighted toward the second half.
3778680	3782120	There's going to be a lot of reading and writing assignments.
3782160	3787800	Approximately two papers to read per week,
3787800	3790440	and for usually one of those papers per week,
3790440	3794400	you will have a very short written assignment in which
3794400	3797760	usually I ask a few simple questions and maybe one
3797760	3801200	like paragraph level think question.
3801200	3805320	The essence of these tasks is not the written assignment
3805320	3808720	itself, the essence of the task is to understand the paper.
3808720	3810800	If you've understood the paper as you read it,
3810800	3812760	then you should be able to answer those questions
3812760	3814880	pretty straightforwardly.
3814880	3817760	And let me just say that understanding a scientific paper
3817760	3818680	is not trivial.
3818680	3821840	When I read a scientific paper right in my area
3821840	3825080	where I have all of the background, it takes me hours.
3825080	3826280	Hours.
3826280	3827360	There may be five pages.
3827360	3829360	It still takes me hours.
3829360	3830800	It's just how it is.
3830800	3834400	So when I assign a paper and you say, oh, it's only three pages.
3834400	3835920	I could do that in 20 minutes.
3835920	3837600	Oh, no, you can't.
3837600	3839120	No, you can't.
3839120	3841440	And that's part of what I want you to learn how to do
3841440	3843800	is how to really read and understand the scientific
3843800	3847680	paper, allocate the time it takes to really get it.
3847680	3852440	So that's a big part of the agenda in this task.
3852440	3855560	All the stuff, the assignments and the submission
3855560	3858120	of the assignments will all happen on Stellar.
3858120	3860120	Your first written response to a paper
3860120	3864240	is due February 12 at 6 PM on Stellar.
3864240	3866560	But there are other readings that are assigned before that.
3866560	3867800	A note about the schedule.
3867800	3870560	I struggled a lot trying to both have the assignments happen
3870560	3872400	when you have already learned enough in lectures
3872400	3875000	to know how to do it, but have it close enough
3875000	3878280	to the topic at hand so it didn't seem like no longer relevant.
3878280	3880000	That's hard to do both of those things.
3880000	3882320	So the compromise is all of the assignments
3882320	3885360	are due at 6 PM the night before the class in which they're
3885360	3886200	assigned.
3886200	3891240	And so if you see that it's assigned on the 13th,
3891240	3894120	if it's listed on the lecture for the 13th, check carefully.
3894160	3896560	It's probably due the night of the,
3896560	3898920	I'm getting this wrong, the 12th, the night before.
3898920	3901200	And that's so that we in the TAs can look at it,
3901200	3902960	figure out what you understood, what you didn't,
3902960	3905400	and how to incorporate and explain whatever you didn't
3905400	3908840	get in the next lecture.
3908840	3910800	All right, quizzes.
3910800	3911960	I haven't done this before.
3911960	3913760	No thing I'm going to try.
3913760	3915360	There are going to be about eight of these.
3915360	3916560	They're going to be very brief.
3916560	3919880	They're going to happen at the end of class, in class.
3919880	3922280	And you will do them on your computer or your iPhone
3922280	3923400	using Google Forms.
3923400	3925400	If anybody doesn't have a computer or an iPhone,
3925400	3928520	they can bring to class the days of those quizzes.
3928520	3931240	Let us know after class, and we'll come up with a solution.
3931240	3933200	OK?
3933200	3936640	And the idea of these is not to fish out an obscure fact that
3936640	3939800	was in one of the reading assignments and ding you on it.
3939800	3941760	Like, I'm not interested in that.
3941760	3944120	The goal of this is just to keep you up to date,
3944120	3947480	keep you doing the readings, keep you up with the material.
3947480	3949360	And if you basically are understanding what you're
3949360	3951520	reading and understanding the lecture material,
3951520	3954280	maybe you glance at it briefly before you
3954280	3955400	should do final inquisits.
3955400	3957400	They're just kind of reality checks, right,
3957400	3959440	for us to know what people are getting and not.
3959440	3961920	OK?
3961920	3966200	OK, first quiz is February 20th, blah, blah.
3966200	3968240	There is one longer written assignment
3968240	3971200	that is not due with the usual schedule of all the other things
3971200	3972080	to do near the end.
3972080	3973800	And in that one, you will actually
3973800	3976080	design an experiment in a particular area.
3976080	3978400	And that will be, I don't know yet, three to five pages,
3978400	3979160	something like that.
3979160	3980880	We'll give you more details on exactly how
3980880	3981920	you want to organize this.
3981920	3983960	And it will be very specific, like state
3983960	3987760	your exact hypothesis, state your exact experimental design,
3987760	3988320	et cetera.
3988320	3991840	And you'll get practice with those things in advance.
3991840	3995000	All right, so those are the grading and requirements.
3995000	3998080	And you have this all in the syllabus in front of you.
3998080	3999840	This is the lineup of topics.
3999840	4004080	But very briefly, let me try to give you the arc of the class.
4004080	4005920	So this is the introduction.
4005920	4009080	Next time, we're going to do just a teeny bit of neuroanatomy.
4009080	4012360	There will be a teeny bit of overlap with 900 and 901 there.
4012360	4015080	I'm going to whip through it in very superficial form.
4015080	4018120	I'm doing that largely because on the following class,
4018120	4020240	we have an amazing privilege, which
4020240	4023840	is that one of the greatest neuroscientists alive today,
4023840	4027040	Anne Graybill, will be doing an actual brain dissection
4027040	4029240	right here in this class, right in front of you.
4029240	4030800	It's going to be awesome.
4030800	4031880	I can't wait.
4031880	4033160	It's an incredible privilege.
4033160	4035920	It will be a real human brain, and you guys will be here
4035920	4037520	with all her apparatus, and you guys
4037520	4039080	will be clustered around.
4039080	4040640	And if it's this many, God help us,
4040640	4042120	but we'll figure out how to make it work.
4042120	4044240	I may, let me just say, if there are listeners in here,
4044240	4046280	I may have to tell listeners they can't come,
4046280	4048680	because it's very sensitive about not having too many people.
4048680	4049680	So stay tuned on that.
4049680	4050840	I haven't quite decided yet.
4050840	4053200	Depends how many people are taking the class.
4053200	4055080	But it's going to be amazing.
4055080	4057280	And I want to remind you of just some basics.
4057280	4060600	So you're not asking her, like, what is the hippocampus?
4060600	4064320	I know you should all know that, but we'll just do bare basics.
4064320	4065760	OK, and then we'll have the dissection.
4065760	4066720	That will be great.
4066720	4068560	And also, another thing to say is,
4068560	4070640	I mentioned that the subcortical regions are
4070640	4072280	going to get short shrift in this class.
4072280	4073760	That's true.
4073760	4076040	But a lot of what you see in the dissection
4076040	4078360	is the subcortical stuff, right?
4078360	4081000	Cortex is great, but it kind of all looks the same.
4081000	4083000	You kind of can't say, oh, that's this region.
4083000	4083720	That's the other region.
4083720	4087000	You can, but it doesn't look any different from any other region.
4087000	4090360	So that's where the subcortical stuff will happen.
4090360	4093800	OK, so then I'm going to do a couple of lectures
4093800	4099000	that focus on high-level vision, perceiving motion and color
4099000	4102920	and shape and faces and scenes and bodies and stuff like that.
4102920	4106200	And we will use those both to teach you that content
4106200	4110240	and also to teach you the vast array of methods
4110240	4112800	in this field, OK?
4112800	4117320	We will then have a lecture on the kind of debates
4117320	4120680	about the organization of visual cortex in humans.
4120680	4122040	I have a particular view.
4122280	4125720	I'm very fond of views that some patches of cortex
4125720	4128040	are very, very functionally specific.
4128040	4129320	Not everyone believes that.
4129320	4131840	So I have signed readings of people who have different views.
4131840	4132840	And we will consider that.
4132840	4136160	I will try to expose you to the alternate views
4136160	4138480	and tell you why I'm teaching, why I still believe mine,
4138480	4141520	but why other smart people believe different things, right?
4141520	4145600	OK, we will then move up the system from perception.
4145600	4148600	And we will spend two meetings talking about scene perception
4148600	4149920	and navigation.
4149960	4152320	You've got a hint about what an interesting area this is
4152320	4153680	from the story of Bob.
4153680	4155560	We'll consider more what we've learned
4155560	4158160	from studies of patients with brain damage,
4158160	4161320	from functional MRI, from physiology and animals,
4161320	4164160	from cognitive science, from the whole glorious menagerie
4164160	4166600	of methods, to understand navigation.
4166600	4170040	It's a really fascinating area.
4170040	4172800	In the two lectures after that, we'll consider development.
4172800	4174440	How do you wire up a brain?
4174440	4176120	How much is present at birth?
4176120	4177960	What is specified in the genes?
4177960	4179600	What is learned?
4179640	4182960	And a lot of that will focus on the navigation system
4182960	4184840	and the face system, simply because that's
4184840	4186280	where there's a lot known.
4186280	4187680	We'll consider some other things.
4187680	4189840	But those are two areas where there's
4189840	4192360	super exciting work from just the last three or four years.
4192360	4195680	And so that's what we'll focus on there.
4195680	4200120	I'm then going to do a lecture on brains in blind people.
4200120	4201040	How are they different?
4201040	4202080	How are they the same?
4202080	4204680	What does that tell us?
4204680	4207080	And then you have the midterm.
4207080	4209320	Then we're going to move on and consider number.
4209320	4212240	How do you instantly know that that's three fingers
4212240	4214400	and that's two without having to do anything
4214400	4216240	all that complicated?
4216240	4218400	And if I had 25 fingers and held them up,
4218400	4219840	you would immediately get a sense
4219840	4221440	that it was about 25.
4221440	4224200	You might not know if it was 22 or 28,
4224200	4226640	but you would know it was about 25.
4226640	4228240	And there are particular brain regions
4228240	4230800	that compute that for you, and we will consider all of that.
4230800	4233600	And there's a very rich array of information
4233600	4237760	from studies of infant cognition, from animal behavior,
4237760	4239640	from brain imaging, from brain damage,
4239640	4243000	from single unit physiology, and from computation,
4243000	4245160	all of which inform our understanding of number.
4245160	4246280	Those are my favorite lectures, where
4246280	4247640	we can take one domain of cognition
4247640	4249800	and inform it with all of the methods.
4249800	4252840	And numbers are a really great example.
4252840	4254840	Then we'll talk a little bit about, well, what
4254840	4255560	have my TAs said?
4255560	4256600	Call it neuroeconomics.
4256600	4257280	It will sound good.
4257280	4258600	But actually, what I'm going to try to do
4258600	4259840	is sort of neuroeconomics.
4259840	4264960	But it will be about pleasure and pain and reward
4264960	4268320	and how we think about those things.
4268320	4271240	And then, that's down to April 3.
4271240	4273680	Just as a side note, all of these things
4273680	4276240	are things that are pretty similar between humans
4276240	4277520	and at least primates.
4277520	4280960	And some of them are shared with rodents.
4280960	4282560	And most of the things after that
4282560	4285280	are things that are really uniquely human.
4285280	4288400	So we'll be really moving away with less available animal
4288400	4290200	literature to inform the stuff we're looking at,
4290200	4293120	because animals can't do these things.
4293120	4295320	And so necessarily far from the details
4295320	4296760	of individual neurons and circuits,
4296760	4298000	but there's still lots cool that can
4298000	4301240	be said about how you understand speech,
4301240	4304040	how you appreciate music.
4304040	4306200	There will be a guest lecture just for fun
4306200	4309480	on Brain Machine Interface by Michael Cohen, who's
4309480	4313160	working in my lab now and who has a great lecture on this topic.
4313160	4315840	Then we'll spend a couple lectures on language,
4315840	4318160	how you understand and produce language
4318160	4320360	and what the relevant brain regions are,
4320360	4322080	what we know about it from cognition
4322080	4324360	and lots of other methods, and what
4324360	4328360	the relationship is between language and thought.
4328360	4331720	Then we'll think about how we think about other people.
4331720	4333400	This is called theory of mind, how
4333400	4336920	I can look out at this lecture and try to evaluate
4336920	4338200	from your facial expression.
4338200	4341840	Are they bored, sleepy, overworked, fascinated,
4341840	4344400	excited, all of this kind of stuff
4344400	4347080	that all of us do moment to moment in any conversation
4347080	4350720	and that, yes, lectures are doing all the time,
4350760	4352600	even if I know that you guys have too much work
4352600	4356560	and that's why you're sleepy and I shouldn't take it personally.
4356560	4357440	I'm still noticing.
4357440	4361960	Anyway, then we'll go on and consider brain networks.
4361960	4363800	So of course, brain function doesn't happen
4363800	4366360	in just a single region, even if we spend a lot of time
4366360	4368280	studying individual regions.
4368280	4370080	There's considerable work trying to figure out
4370080	4371800	which sets of regions work together
4371800	4373240	and how could we discover that and what
4373240	4377040	are those broader networks of brain regions.
4377040	4378880	And then on May 6th, you will have
4378880	4381600	turned in your longer written assignment
4381600	4382880	designing your own experiment.
4382880	4385440	And then on May 6th, we will work together
4385440	4387160	in groups to refine those experiments
4387160	4389000	and really hash out the details so you actually
4389000	4392640	know how to design an experiment.
4392640	4395200	And then we will have this guest lecture
4395200	4397880	from my postdoc, Katharina Dobbs, on deep nets
4397880	4401320	and what they can tell us about cognition and brains.
4401320	4403680	And then we'll talk about attention awareness.
4403680	4405040	And then I'm not totally sure what
4405040	4406240	we're going to do in the last class,
4406240	4408720	I'm voting for, is it the amazing TAs?
4408720	4411600	Each give a short talk on the cool stuff they're doing.
4411600	4413560	But that's under discussion.
4413560	4416600	OK, that's the arc of the class.
4416600	4417080	Questions?
4420400	4420900	All clear?
4424000	4424640	Great.
4424640	4427040	Well, if I have five more minutes,
4427040	4428840	maybe I'll do one other little thing.
4428840	4430920	Let me try this.
4430920	4432960	You asked, I'm going to try to learn everybody's names,
4432960	4433920	but I'm not doing that yet.
4433920	4435120	Because some of you might not show up
4435120	4436840	and I will have wasted a whole piece of my brain
4436840	4439920	encoding it now, just kidding.
4439920	4441920	But anyway, I remember that you asked,
4441920	4443240	you're going to read current papers.
4443240	4445760	Yes, and you're right, it's daunting.
4445760	4448680	But let me just say a little bit about how to read papers.
4448680	4452760	This is not a stats course, and we haven't prerequisited stats.
4452760	4457480	Neither is it a course on the physics of MRI.
4457480	4459520	So there will be parts of every MRI paper
4459520	4461120	that have a lot of gobbledygook.
4461120	4465000	We scan with this scanning procedure.
4465000	4467640	We use this kind of scanner, and this kind of blah, blah,
4467640	4469080	blah, lots of gobbledygook.
4469080	4471160	You guys don't need to worry about that.
4471160	4473880	About the stats, it's kind of a judgment call.
4473880	4477720	Everyone in here should have an idea of what a P level means.
4477720	4480960	And I hope a sense of what a T test is and an ANOVA.
4480960	4483280	If you don't, I should probably tell you that offline,
4483280	4484680	because that's pretty basic.
4484680	4486520	But what a correlation is.
4486520	4490440	Beyond that, just use your intuitions about those things.
4490440	4492680	And this is not a course about understanding
4492680	4494520	the details of the stats in each experiment.
4494520	4496600	It just isn't room to cover all that in the substance
4496600	4498280	of the studies as well.
4498280	4503440	So when you read a paper, for example, here's a paper,
4503440	4505760	a very old paper, you come across this,
4505760	4507640	and it's like, OK, here are all these words.
4507640	4510880	And it goes on for 20 pages, and like, how do you even dig in?
4510880	4513240	Well, the way to dig in is to start
4513240	4517040	by saying, what question is being asked in this paper?
4517040	4518800	If the paper is well written, you'll
4518800	4522680	be able to find that in the abstract, blah, blah, blah,
4522680	4524440	to study the effect of face inversion
4524440	4526240	on the human fusiform face area.
4526240	4527720	OK, we'll talk about that more later.
4527720	4529560	But if you fish through the abstract,
4529560	4531440	you should be able to find what question is being asked,
4531440	4535280	and it's the first thing you should figure out about a paper.
4535280	4537600	You don't necessarily read a paper,
4537600	4539080	start beginning through the end.
4539080	4541000	I think it's better to start with this list of questions
4541000	4545280	in your head, and look for the answers to those questions.
4545280	4548800	Second question, what do they find?
4548800	4550120	If the abstract is well written,
4550120	4552600	you can find that in the abstract as well.
4552600	4554840	Signal intensity from the fusiform face area
4554840	4558360	was reduced when grayscale faces were presented upside down.
4558360	4560040	OK, kind of boring, but there it is.
4560040	4561720	That's a finding of this paper.
4561720	4564960	OK, what is the interpretation?
4564960	4566840	Like, in other words, who cares?
4566840	4569320	Like, who cares about this?
4569320	4573480	OK, if you look in here in the abstract,
4573480	4577680	FFA responds to faces per se, rather than to the low level
4577680	4580040	features present in faces.
4580040	4581880	OK, we'll talk more about what that means.
4581880	4583240	You guys have an assignment about that,
4583240	4585840	probably several assignments about that kind of question.
4588480	4589880	Next question you want to ask yourself
4589880	4593200	is, what is the design of this experiment?
4593200	4596040	Often for this, you have to go beyond the abstract.
4596040	4598840	And I should say, for even these earlier questions,
4598840	4600840	sometimes you won't find them in the abstract.
4600840	4603400	That just means the abstract is not well written.
4603400	4604840	But that exists.
4604840	4608240	OK, to get the design, like, what exactly did they do?
4608240	4611280	Usually you have to fit in what exactly was done,
4611280	4612440	and how were the data analyzed?
4612440	4613800	You need to fish farther.
4613800	4617880	You need to fish around other parts of the paper.
4617880	4619920	And of course, all of those questions.
4619920	4621760	OK, so I just said, OK, what question?
4621760	4623360	And I circled this part.
4623360	4625800	But there are many levels to what question.
4625800	4630000	So you can get more on, why is that inverted question
4630000	4630480	important?
4630480	4633880	You look through, usually, in the introduction to the paper.
4633880	4636440	Does the FFA respond to faces per se,
4636440	4638400	or to a confounding visual feature, which
4638400	4640640	tends to be present in faces?
4640640	4643120	Second, is it true that inverted faces cannot engage
4643120	4644320	face-specific mechanisms?
4644320	4645080	Blah, blah, blah.
4645080	4646720	So that gives you a little more background
4646720	4648080	on what the question is, right?
4648080	4650360	There are different levels and depths, OK?
4650360	4652360	So these are all things you want to be looking for
4652360	4653880	when you read a paper.
4653880	4654880	What exactly was done?
4654880	4656920	We measured MRI responses in the FFA
4656920	4658640	to upright and inverted faces, right?
4658640	4659960	I don't expect you to understand all this.
4659960	4662280	You're just giving you schematically how you proceed
4662280	4665720	when you're reading a paper, OK?
4665720	4668480	More on the interpretation, or who cares, right?
4668480	4670880	This result would show that face-specific mechanisms
4670880	4673320	are engaged only or predominantly by upright faces,
4673320	4674320	blah, blah, blah, right?
4674320	4676040	You can fish through for those things.
4676040	4677720	Point is to have those questions in your head
4677720	4680360	when you read a paper, OK?
4680360	4683520	It's much more easy and engaging to read something
4683520	4685400	if you have an agenda when you read it.
4685400	4688000	And so your agenda in reading scientific papers
4688000	4692880	is to answer those questions for yourself, right?
4692880	4694720	More stuff, what was the design and logic?
4694720	4696120	Often that's deep in the methods.
4696120	4697560	You have to fish around and find it.
4697560	4699560	There will be some set of conditions and designs.
4699560	4702520	We'll talk more about all this kind of stuff,
4702520	4705600	what exactly was done, blah, blah, more details.
4709560	4711600	And this is my example of the kind of gobbledygook
4711600	4713960	that you can ignore, OK?
4713960	4717160	So subjects were scanned on a 1 and 1 12 T scanner.
4717160	4718400	And there are all these, like this here's
4718400	4721000	the example of said gobbledygook.
4721000	4723240	You can ignore this in this class, right?
4723240	4725520	Every method will have different kinds of gobbledygook.
4725520	4726880	This is MRI gobbledygook.
4726880	4730080	You can ignore it, OK?
4730080	4733960	It matters a lot, but not here, OK?
4733960	4734360	What else?
4734360	4736200	How are the data analyzed?
4736200	4738480	If you look in the sometimes there's
4738480	4742160	a data analysis section or a result section or a method
4742160	4745120	section that will tell you, you can find that, figure it out,
4745120	4747240	OK?
4747240	4748240	What was the finding?
4748240	4749520	Here's more on the finding.
4749520	4752560	Again, you just fish through for these things.
4752560	4755440	So the point is just, when you're reading a paper,
4755880	4758760	it's not necessarily, what I do is I read the title,
4758760	4760280	I read the abstract.
4760280	4762400	And then I start answering those questions for myself.
4762400	4764560	And sometimes at that point, I'm skipping to figures,
4764560	4766200	I'm skipping to methods.
4766200	4768480	Any of that is fine, OK?
4768480	4772160	So don't feel like you need to understand each word, especially
4772160	4773480	deep in the methods.
4773480	4775520	I don't know, is that helpful at all?
4775520	4777480	We'll try it, and you guys will give me feedback.
4777480	4779480	And if it works, great.
4779480	4783200	And if not, we'll do more on how to read papers.
4783320	4785640	All right, it's 12.25.
4785640	4787800	See you on Monday.
