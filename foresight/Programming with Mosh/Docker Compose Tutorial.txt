In this video, you're going to learn about Docker Compose, so by the end of this video,
you'll be able to use Docker commands with confidence.
Hi, I'm Mosh Hamidani, and I've taught millions of people how to code through this channel
at my online school code with Mosh.com.
This video is part of my ultimate Docker course, so once you finish this video, if you want
to learn more, you may want to look at the complete course.
Now let's jump in and get started.
Welcome back to another section of the ultimate Docker course.
In this section, we're going to talk about running multi-container applications.
So I'm going to give you a real-world application with three building blocks, a front-end built
with React, a back-end built with Node, and a MongoDB database.
Once again, you don't need to be familiar or use any of these tools.
Our focus here is on Docker and not on development tools.
I think this is the most exciting part of this course, where you can see everything coming
together.
So we're going to talk about Docker Compose for building and running multi-container applications.
We'll also talk about Docker networking, database migration, and running automated tests.
So let's jump in and get started.
In this section, we're going to use a tool called Docker Compose, which is built on top
of Docker Engine.
It makes it incredibly easy to start applications with multiple containers.
So Google Docker Compose install.
You will find this page, docs.docker.com, slash compose, slash install.
On this page, you can see the installation instructions.
Now at the time of recording this, Docker Compose is shipped with Docker desktop for Mac
and Windows.
So if you're on Mac or Windows, you don't have to do anything extra.
You already have Docker Compose.
To verify it, just go to the terminal window and type Docker Compose dash dash version.
So I'm running Docker Compose version 1.28.5.
Make sure your version is the same or newer.
If you're using an older version, again, Google upgrade Docker Compose, or you might
just install the latest version of Docker.
Now back to this page.
If you're using Windows Server or Linux, there are specific instructions you have to
follow to install Docker Compose.
So go ahead and install Docker Compose and I will see you in the next lesson.
Before we get started, I want to show you a couple of techniques for cleaning up our
workspace.
So on this machine, we have a bunch of images and some running containers.
They're getting in the way.
I want to get rid of them all.
How do we do this?
Well, you know that we can remove images using Docker image remove command.
And here we can type one or more image IDs.
Now how can we get all image IDs and pass them here?
Let me show you a cool trick.
So we can run Docker image LS.
We see all the images, right?
But if you pass dash Q at the end, we only get image IDs.
Now we can pass this as an argument to Docker image remove.
So Docker image remove.
Now here we add a dollar sign and in parenthesis, we type that other command.
So Docker image LS dash Q.
Now if we run this, we're going to get an error because some of these images are already
in running containers or stopped containers.
So we should always remove containers first.
We're going to do that using the same technique.
So I'm going to replace image with container.
So we get all container IDs and then we're going to remove them all in one go.
Also I would like to add dash A here as well.
This will bring stopped containers as well, okay?
We can also combine switches.
That's another technique.
Let's go ahead.
All right, we get an error saying you cannot remove a running container because I forgot
to pass the force option.
So let's bring this up one more time.
When removing, we're going to use dash F, okay?
Great.
So all these containers are removed.
Now let's remove the images.
So Docker image LS and Docker image remove.
Great.
Now take a look.
We don't have any images here and no containers, including stopped containers.
So we have a clean workspace.
That's one way.
There is a shortcut for this as well.
If you're on Mac, you can find the Docker icon on the top status bar.
If you're on Windows, you will find it in your notification tray.
Let's click on this and then go to preferences.
Now on this page, let's click on the troubleshoot icon.
On this page, we have a bunch of useful utilities.
For example, we can restart Docker desktop.
We can also clean and purge data.
This will essentially remove everything in Docker, your images, your containers, your
volumes and so on.
Now be aware that if you click on this, this is going to restart Docker engine.
So on the top, look, you can see this animation showing that the Docker engine is not started
yet.
So at this point, if you go to the terminal window and execute any of Docker commands,
you're going to get an error.
So you'll have to wait about half a minute for the Docker engine to start.
That's another way.
So now that we have a clean workspace, next we're going to talk about our application.
So in this next section, we're going to look at a real-world application with multiple
building blocks, a front end, a back end and a database.
So below this video, I've attached a Z file.
Go ahead and download it.
Inside that Z file, you're going to find this folder structure.
We have this backend folder, which is our node project.
This is a basic node project that starts a web server on port 3001.
Once again, you don't need to know node to go through this section.
Then we have the front end project, which is a React application that talks to the back
end.
Now, if you want to run this application outside of Docker, there are a number of steps
we have to follow.
Let's say we just check this out from a GitHub repository.
First we have to go to our back end project, install all dependencies and then start the
web server.
At the same time, we have to open up another terminal window and do the same steps with
our front end project.
So we have to go to the front end project, install all the dependencies and then start
the web server.
And of course, we need two more terminal windows for running our front end and back end tests.
And not to mention that, we should also download and install MongoDB on this machine.
So there are so many steps we have to follow the moment we check out the source code from
our GitHub repository.
Now with Docker, we don't have to do any of these things.
All we have to do is run a single command.
Let me show you.
So I'm going to get outside of the front end folder.
Now we are in the root of this project.
If you look, here we have a file called Docker Compose, which is used for composing a multi-container
application.
We're going to talk about that in detail soon.
Now, once we have this file in our project, we can simply run Docker Compose up.
That's all we have to do.
Now, Docker is automatically downloading this particular version of MongoDB, so it's downloading
all these layers.
Then at the same time, it's going to install all the dependencies for our front end and
back end projects.
It will start web servers and run automated tests all in this window.
Now, this is going to take a little while, so I'll be right back.
All right, our application is up and running, and we can access it at localhost for 3000.
So here's what we get.
We have a mini application for managing a list of movies.
Now, you know what's the beauty here?
The beauty is that our database is populated with these movies as part of bringing up our
application.
I didn't have to manually insert these movies in our database.
So we have a migration script for populating our database, and Docker automatically executed
our migration script as part of bringing up this application.
This is a very common real-world scenario.
Now, here we can add new movies, movie one, movie two, whatever, and we can also delete
these movies.
So, we brought up this application using a single command.
Now, I briefly mentioned this file, docker-compose.yaml.
Before we talk about this file, first you need to understand the YAML format.
This is a format that a lot of people are not familiar with.
So in the next lesson, we're going to talk about JSON and YAML formats.
Let's talk about JSON and YAML formats.
If you know this format as well, feel free to skip this lesson.
So in the root of this project, we're going to add a new file called data.json.json, as
you probably know is a language, it's a human-readable language for representing data.
So in this JSON file, we can have an object or an array, let's say we want to represent
a course.
A course can have properties like name, price, and so on.
So in this object, we can add one or more key value pairs.
Our keys should always be surrounded in double quotes.
So we can add a key called name, and set its value to, we can use a string, the ultimate
docker course, then we add a comma to define the next key value pair.
So we can say price, we can set this to a number.
Now the value can also be a boolean, so we can define another key value pair, and set
the value to true or false.
We can define another key value pair, and set the value to an array.
So we define an array using square brackets.
Now in this array, we can have any valid objects.
So we can have strings, numbers, booleans, or other objects.
So I'm going to add a couple of strings, let's say software and DevOps.
And one last key value pair, author, I'm going to make this an object, so once again we use
curly braces to define an object.
In this object, we add a couple of key value pairs, first name is mosh, and last name is
what?
I'm a darling, and yes, I am Iranian, I get that question all the time.
Alright, so here we have a JSON file, now let's see how we can convert this to YAML.
YAML is another language for presenting data, but it has less clutter than JSON, it's easier
to read.
So I'm going to copy all this code, here in the project, we're going to add a new file
called datum.yaml, the extension can be YAML or YML.
Now on the top, we add three hyphens to indicate the beginning of a YAML file, then we paste
our code.
Now in YAML, we don't use curly braces to indicate hierarchy.
This idea has come from Python, if you have programmed in Python, you know that in Python
we use indentation to represent hierarchy, so we don't have curly braces.
So let's get rid of these braces, and remove the indentation, good.
Now the next thing you need to know about YAML is that we don't have to use quotes.
So we can bring up the replace dialog, and replace all these double quotes with nothing.
That immediately takes a lot of clutter away.
Also, we're not going to use commas to separate key value pairs.
So on the top, we have name, price is published, and how do we represent a list or an array?
We use hyphens.
So I'm going to remove this, we press enter, add a tab on a new line, we type hyphen to
define the first item in the list, software, then at the same indentation, we add the next
item, DevOps.
Now author is an object, but as I told you, we don't use curly braces, we use indentation.
So because these two properties are indented, they belong to the author property, okay?
So this is our YAML file, let's compare this with JSON.
As you can see, YAML is easier to read and understand.
Now why don't we use YAML all the time?
Well, because parsing YAML files is a little bit slower than parsing JSON files, because
the parser doesn't know if this is a string or a number, so it has to read everything
as a string and then try to evaluate it.
In contrast, in JSON, strings are represented using quotes and more specifically double
quotes, so the parser knows that this is a string and it shouldn't evaluate it, okay?
So quite often we use YAML files for configuration files and JSON for exchanging data between
multiple computers, like a client and a server.
So now that you understand these formats, next we're going to talk about compose files.
Alright, let's see how we can create a compose file from scratch.
So for this lesson, I'm going to rename this file to underline docker compose.
We want to set it aside and create a new compose file from scratch.
So here we are, the new file called docker-compose.
All in lowercase, make sure to spell it properly, otherwise docker-compose is not going to find
this file, because this is the default name that docker-compose assumes, okay?
So YAML.
Now the first thing that we need to set here is the version property.
What version should we use?
Well, let's search for docker-compose file.
On this page, you can see various compose file formats and their compatibility with
docker-engine.
We are using the latest version of docker-engine, so I want to use the latest compose file format
so we have access to the latest features.
So we're going to set this to 3.8.
Now here we need to wrap this number with double quotes, otherwise it will be evaluated
as a number, but docker-compose expects this value to be a string.
Why?
I have no clue.
Here's the version.
Now in this file, we define various building blocks or services of our application.
So we have a property called services.
Now what services do we need here?
Well, our application has a front-end, a back-end, and a database.
Your application might have other moving parts, so you can define them here.
Now these names are arbitrary, so we can call them anything.
We can change this to db, we can change the back-end to api, and the front-end to well.
The idea here is that we're defining various services and telling docker how to build images
for each service and how to run these images.
So here we're going to have properties, and the value of these properties will eventually
be used when running our containers.
So in the previous section, we had to manually run our containers using docker-run, and here
we used parameters like dash-p for port mapping or dash-v for volume mapping.
We also had to specify an image like react-app.
All these values can be defined in our compose file.
So we don't have to manually start our containers.
Docker compose will take care of starting our containers under the hood.
So for each service, we need to tell docker how to build an image for that service.
So here we can use the build property and tell docker compose where it can find a docker
file.
So if you look at this project, you can see that in our back-end and front-end folders,
we have a docker file.
This docker file is almost identical to the one we created in the previous section.
So we start from a node image, we create a user, we set our working directory, copy all
the files and install the dependencies, then expose port 3001 and start the web server.
We have a similar docker file in our front-end project.
Let's have a quick look.
So that was the back-end, here's the front-end, and here we have a docker file, almost identical.
But the front-end application or the front-end server starts on a different port.
That is the only difference.
So each service should have its own docker file, okay?
Now back to our compose file, for our web or front-end, we're going to set the build
property to period, meaning current folder, slash front-end.
This is where we have a docker file.
For our API, we're going to set build to back-end.
Now for our database, we're not going to build an image, we're going to pull an image from
docker hop.
So instead of the build property, we're going to use the image property.
Now for this application, I'm going to use Mongo version 4.0-Xenial.
So that is Mongo version 4 built on top of Xenial, which is Ubuntu version 16.
Now if you look at docker hop, you can see that Mongo also has images built on top of
Windows, but Windows images are very large, over two gigabytes.
So that's why I prefer to use Linux images.
So for any of these services, we can either build an image or pull it down.
Now here we also have port mappings, so we set ports to.
Now because we can have multiple port mappings, here we need to use the array or list syntax.
So we use a hyphen, and then define a port mapping.
So our frontend application starts on port 3000.
So I want to map port 3000 of the host to port 3000 of the container running this image.
That's similarly for our API, we're going to define a port mapping.
This one is going to be 3001 to 3001.
Now MongoDB by default, listens on port 27017.
So I want to map the same port, so we can access MongoDB using a MongoDB client like
MongoDB Compass.
If you don't use MongoDB, you have the same concept with other database engines.
All these database engines listen on a default port.
You want to map that port so you can connect to your database engine using your favorite
database client.
What else do we have here?
Back to this page for compose file.
If you look at version three, on the right, you can see all valid properties.
Now a lot of these are for really special cases, so you don't need to use them all the
time, but the ones that we use most of the time are build or image.
You also use ports, volumes, environment, and so on.
So our API project needs an environment variable that tells where our database is.
So here we set environment, and here we can use the list syntax because we can have multiple
environment variables.
So we set DB underline URL to, here we need to type a MongoDB connection string.
These connection strings always start with MongoDB, colon, two forward slashes.
Here we need to type the name of a host.
So as I'll show you later in this section, when we start an application with Docker compose
under the hood, a network is created.
On this network, we're going to have three hosts.
The name of these hosts are equal to the names we have defined here.
So we're going to have a host called DB.
So that is the connection string to our MongoDB server.
Now on this server, we can have multiple databases.
So we're going to specify the database name and the connection string as well.
So this is one way to set an environment variable.
But instead of using the list syntax, we can also use the object or property value syntax.
So we get rid of the hyphen.
We say DB URL is a property and this is the value of that property.
I find the syntax more readable because we get color coding and it's just cleaner.
That similarly we can add additional environment variables.
Now we're almost there.
The last thing we want to add here is a volume because we don't want MongoDB to rate data
to the temporary file system of the container.
So here we set volumes and again, we can have one or more volume mappings.
So we had a hyphen.
We're going to map a volume called Widley and of course we can call it anything.
Widley is the name of this application in case you didn't notice.
So we're going to map this volume to a directory inside the container.
Now if you look at the documentation of MongoDB on Docker Hub or just a typical MongoDB
documentation, you know that by default MongoDB stores its data in slash data slash DB.
So we want to map this volume to this directory.
So whatever that is written inside this directory is actually outside of this container.
It's somewhere else in our volume.
Now because we have used this volume here, we have to define it in our compose file.
So we press enter, remove all the indentations.
So now we are at the same level as services.
Here we're going to define another property called volumes and here we're going to add
another property called Widley with no value.
I know this looks a little bit weird, but this is the syntax we have to follow.
We just have to define the volume first before we can use it.
So this is our compose file.
Now we can make this more readable by adding line breaks in between these properties.
We can also order these services any way we want.
So currently I'm ordering them from front to back.
We can also order them from back to front.
So we will put database first, then API and then web.
So we're done with our compose file.
Next I'm going to show you how to build the images.
Earlier I told you that Docker compose is built on top of Docker engine.
So everything we have done with Docker engine like building images, listing them, starting
containers and so on, all of these operations are also available using Docker compose.
Let me show you.
So we type Docker compose, without any arguments, enter, look, we have all these subcommands
like we have RM for removing stopped containers, we have run, we have push, pull and so on.
The difference is that any of these commands will apply to our application as a whole.
So most of these commands will impact multiple services or multiple containers in our application.
So let's look at Docker compose build and also use the help option.
So we have a bunch of options here.
A couple of them I want to point out that are useful to know is no cache.
With this we can prevent caching when building the image.
Sometimes you encounter weird issues and you want to make sure that cache is not used.
In that case, you use this option.
Another useful option is dash dash pull.
With this, we can always pull a newer version of the image.
That is also good to know.
So in this lesson, I'm not going to use any of these.
We're just going to run Docker compose build.
This built our web and API services and as you noticed, our build was super fast because
pretty much everything came from the cache.
So let's run Docker images.
So I have five images on this machine.
With the front end, with the web, with the API, with the back end and Mongo.
Mongo obviously came from Docker Hub.
Now as part of this build process in this lesson, we built with the web and with the
API.
These two other images with the front end and back end were built when we started this
application earlier.
So back to our project.
In this original compose file that I included in this project, look, I call these services
front end and back end instead of web and API.
That is why we have these two images, with the front end and with the back end.
Also as you have noticed, when building images with Docker compose, our images are prefixed
with the name of our application.
Now where does this come from?
It is the name of the directory.
So currently we are inside a directory called Widley and that is why all these images are
prefixed with Widley.
I think this is a great convention.
I got a question for you.
If you look at the created column, you can see all these images were created an hour
ago.
But didn't we just build the web and API images?
Why do you think this happened?
Here's the answer.
Because I built these images front end and back end an hour ago when I was recording the
first lesson in this section.
Now when building these new images, Docker used everything in the cache because all those
files were already available, all those layers were there.
So Docker didn't have to do a full rebuild.
That is why we are still using the build from an hour ago.
Now if you want to force a full rebuild, we can say Docker compose build dash dash no
cache.
All right, this is going to take a few seconds.
So I'll be right back.
All right, our images are built.
So let's run Docker images.
There you go.
Look at the first two images, API and web were built less than a minute ago.
So that's all about building images, next we're going to talk about starting the application.
You briefly saw how we can start an application with Docker compose.
We just type Docker compose up.
Now if the images are ready, Docker compose will run them inside containers, otherwise
it's going to build the images automatically.
Now before executing this, let's look at the available options.
So here we have a ton of options, a couple of them that are useful are build.
With this we can force a rebuild every time we want to start our application.
So we don't have to explicitly run Docker compose build and then up.
We can combine the two using the build option.
The other useful option is dash D for detached mode.
So we will start these containers in the background.
So take a look.
All right.
Now if we run Docker compose PS, we can see all the containers relevant to this application.
In contrast, if you type Docker PS, we can see all the running containers across all
applications.
So here we have three containers, Vidly, API one, Vidly DB one and web one.
Now what is this one?
Well, we can start multiple containers from the same image.
And this is used for high availability and scalability.
And something we'll look at in the future.
So here you can see the container.
You can see what command started that container.
So for our API, that was npm start.
For our database, that was MongoD or MongoDemon process.
And for our web front end, that was npm start as well.
You can see all these containers are up and running.
And over here, you can see port mappings.
So now if we go to local host, port 3000, we can see our application.
Beautiful.
How do we take this down?
Let's say we're done with this application and we want to free up resources.
Back to the terminal, we type Docker compose down.
This will stop and remove these containers.
But the images are still there.
So next time we want to start the application, our application will start pretty quickly.
Let's talk about networking in Docker.
Let me run our application with Docker compose.
Docker compose will automatically create a network and add our containers on that network.
So these containers can talk to each other.
Let's see this in action.
So I'm going to bring up the application one more time in the detach mode.
Good.
Now look at the first line.
Creating network with the default.
So we can run Docker network LS.
Here we can see all the networks on this machine.
I think every Docker installation has three networks.
Bridge, host, and none.
Honestly, I'm not sure what these networks are for, but what matters here is that we
have a network called Widley default.
The driver for this network is bridge on Linux or NAT on Windows.
Now this network contains three hosts or three containers, web, API, and DB.
So these hosts or these containers can talk to each other using their name.
Let's see this in action.
So back to the terminal, let's look at the running containers.
So we have Mongo, web, and API.
Now we're going to start a shell session on the web container and ping the API container.
Take a look.
So we're going to execute in the interactive mode.
The container ID is 8c6 and we're going to run shell.
So let's ping API.
We get a permission error because we have logged in with the app user that comes from
our Docker file, remember?
So we have logged in with the app user and this user doesn't have ping permission.
So let's exit.
I'm going to bring up the last command.
Now here we have to use an extra option for setting the user.
We're going to log in as the root user.
Good.
Now look at the shell prompt.
We have a pound sign, which means we have the highest privileges.
So here we can ping API.
Now look, we're getting responses from a machine with this IP address.
Now on your machine, this IP might be different.
Now let's press Ctrl and C to get out of this.
So this is what happens under the hood.
Docker comes with an embedded DNS server that contains the name and IP of these containers.
Now inside each container, we have a component called the DNS resolver.
This DNS resolver talks to the DNS server to find the IP address of the target container.
So when we ping the API container, this DNS resolver asks the server, what is the IP address
of the API machine or API container?
The DNS server returns the IP address and then the web container can directly talk to
the API container using its IP address.
So each container has an IP address and is part of a network.
Let me show you one more thing.
So back to the terminal, here we can run ifconfig to see the IP address of this container.
Take a look.
So this container has two network adapters, one of them is Ethernet zero and over here
you can see the IP address of this container.
So 172.21.02 is the IP address of the web container.
Now back to our compose file, earlier when we defined the API service, we added an environment
variable that contains a database connection string.
In this connection string we have DB, which is the name of a host, that is the DB host
or the DB container.
You saw that our API container can talk to this container because both these containers
or all containers in this application are part of the same network.
Now one thing I want you to understand here is that this host is only available inside
the Docker environment.
So if I open up my browser and go to localhost slash DB, I'm not going to get anything.
So the API container can directly talk to the DB container, but if you want to access
this container we need port mappings and that is why we have this port mapping over here.
So this port on the host is mapped to this port on the container.
So if you open up MongoDB Compass, which is a popular MongoDB client, we can establish
a connection to localhost port 27017, because this port is mapped to our container.
Let's verify this real quick.
So connect, great.
So here we can see all our databases, here's our vitli database and in this database we
have a collection called movies with four documents.
So here are the movies that we currently have in the database.
So this is all about Docker networking, next we're going to talk about viewing logs.
Thank you so much for watching this video.
As I said, this video is part of my ultimate Docker course that teaches you everything you
need to know about Docker from the basics to more advanced concepts.
So if you want to learn more, I highly encourage you to take a full course.
It's much faster and better than jumping from one tutorial to another.
If you're interested, the link is below this video.
Thank you and have a great day.
