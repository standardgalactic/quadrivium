Then when it came to giving a talk, it made me think about some things that transpired
between both of our societies some decades ago.
For example, in 1957, when the Soviet Union launched Sputnik, the world's first man-made
satellite that orbited the Earth successfully.
Back in the USA, everybody freaked out about this.
They didn't like being behind in space and said, oh my God, we got to catch up.
We have to get a satellite into orbit in 90 days, which seemed crazy.
And it was.
Our first attempt blew up on the launch pad.
But the second attempt succeeded.
That was January 31, 1958.
It was almost 120 days after that initial launch.
It's pretty fast by modern standards.
Then in April 1961, Yuri Gagarin became the first human being to orbit the Earth.
And again, that made news all over the world.
Everybody was very impressed by that.
And back in the United States, people were upset because, again, we were behind.
We were behind in what was becoming clear was the space race.
And we didn't like that and what were we going to do about it.
So in May 1961, one month after that flight, our president at the time, Kennedy, made a
speech to Congress saying, look, if we're going to catch up and not be behind forever,
we have to do something big.
We have to commit a lot of money, a lot of resources.
We're going to go to the moon, right?
And that was kind of a crazy idea.
And in 1962, he reiterated this in a famous public speech.
And he said, look, we're going to go to the moon before the decade is over.
And that was crazy.
He was really crazy because we hadn't done anything remotely like that.
But lo and behold, eventually we did.
So Apollo 11 launched on July 16, 1969, before the decade was over.
And just this year, there's a very good documentary that came out about this whole mission.
What it is is it's made of all original footage that NASA took during the mission that's been
sitting away in cupboards and closets, and they restored the footage, and they sort of
made a recreation of what it was like to live through this mission.
And I'm going to play a short excerpt from that documentary just to give you a sense
of what the scale of this whole thing was like.
It's a lot.
And it's crazy.
We went from nothing to all that stuff in something like 12 years.
Before Sputnik flew, we didn't have much of a space program in the United States.
And in the end, we had all that stuff.
And then, of course, after that, we continued to do space things, right?
We made the space shuttle.
It seemed like a really cool thing.
It's like a ship out of science fiction.
It could take off and then land again.
That's so great, right?
Problem is, actually, most of it couldn't land, like those tanks in the background there.
And therefore, it was very expensive to fly, and it was very unreliable.
People died on this on a couple of different missions, and we decided to stop using it
for all these reasons.
So after that, if we wanted to put people in orbit, we had to get a ride on the Soyuz.
And then, from there, the trajectory of our space program kept going downwards.
And so if you talk to somebody like me, sometime around the year 2002 or 2005, we all had this
attitude like, isn't it a shame?
Like the USA used to do all this cool stuff in space, and now we don't really do anything
in the science fiction future that we visualized isn't really going to happen.
And we don't ever see that changing, but what can you do about it?
Well, shrug, right?
That was just everybody's attitude, but not quite everybody, right?
At some point, somebody came along who made a bunch of money on a website and said, hey,
I want to do something about this.
Despite having no rocket experience, I'm going to start a company to launch rockets and to
do bigger stuff than we've ever done before.
And so here's an excerpt of a video about why he did that stuff.
Then there's becoming a multi-panel species in space-frame civilization.
This is not inevitable.
It's very important to appreciate this is not inevitable.
The sustainable energy future, I think, is largely inevitable, but being space-frame
civilization is definitely not inevitable.
If you look at the progress in space, in 1969, we were able to send 70 to the moon.
In 1969, then we had the space shuttle.
The space shuttle could only take people to low-Earth orbit.
Then the space shuttle retired, and the United States could take no one to orbit.
So that's the trend.
The trend is down to nothing.
This is not...
If you are mistaken when they think that technology just automatically improves, it
does not automatically improve.
It only improves if a lot of people work very hard to make it better.
And actually, it will, I think, by itself degrade, actually.
You look at great civilizations like ancient Egypt, and they were able to make the permits,
and they forgot how to do that.
And in the Romans, they built these incredible aqueducts.
They forgot how to do it.
So his idea was pretty successful.
And today we're like landing rockets, and we're seriously talking about doing another
moon mission as soon as the year 2024.
We'll see if that actually happens, but we're at least talking about it seriously, and that's
a pretty good thing, given where we were not long ago.
So Elon talked about a few things from the past that were great achievements that have
been lost, and I wanted to go through a few more of those.
To reiterate his point, that technology automatically degrades.
This thing here that you see is the Lycurgus Cup.
This was a relic found and dated back to the Roman Empire, 380, and it's made of glass,
and this glass that it's made of is the world's earliest known nanomaterial.
The color of the glass changes based on how you look at it, like where the light source
is.
So if you're looking at it standing in front of the glass, and the light source is over
here with you so that you're seeing it with reflected light, then the goblet is green.
But if light is passing through it, the goblet is red.
They had this in 300 AD, and then the Roman Empire fell, and that knowledge was lost until
basically forever.
The way this worked was actually, it got figured out around 1990.
The glass is suffused with very small particles of silver and gold.
By very small, I mean 50 to 70 nanometers, which is so small you would not be able to
see them with a physical microscope.
You would require an electron microscope to see these particles, right?
But at some point the Roman Empire fell, and they forgot how to do it.
A lot of craftsmanship went into this.
You could see how it's hollowed out on the inside where the little guy's body is, to
give him more of a purple sheen as opposed to a red in the background.
If you hear people talk about this today, or you read up on this, they tend to have a
dismissive attitude toward it, like, oh, the stupid Romans didn't understand technology.
They probably didn't even know it was silver and gold that made this happen.
It was probably just an accident, and they made like five of these, right?
Which is complete nonsense.
Anybody who actually builds things as opposed to just writing about them knows you do not
get a result this good without a constant process of iteration and refinement.
You can imagine there was some initial accident.
Maybe somebody wanted to make glass sparkly, and they tried to put silver and gold in it,
and then they noticed a little bit of discoloration, and they said, why is that there?
Maybe they pursued that.
What happens when I change the proportions?
How thick should the glass be?
Engineering results this good takes a long time.
What that means is that in Rome, people were doing something that we would recognize today
as material science, and then that was lost.
Other stuff happened.
Like, in the Byzantine Empire, they had flamethrowers, and not like little dinky things.
They had giant pressurized vessels in the bellies of ships that shot out a napalm-like
substance out of metal tubes that they would use to incinerate neighboring vessels.
It was napalm-like in the sense that, like, water would not put this fire out, right?
It was a very serious weapon.
It was a state secret of the Byzantine Empire.
They used it to defend Constantinople over and over again for hundreds of years until
one day they couldn't really do that anymore, for whatever reason, and this military secret
just faded from knowledge.
Nobody knows how to do it now, right?
Obviously, we've reinvented flamethrowers, but they're different.
This is the Antikythera mechanism, which is named after an island in Greece where this
was found on a sunken ship.
It was just a corroded hunk of metal, or a number of corroded hunks of metal, but it
was very clear when they originally discovered that gears were involved, and over time people
analyzed this, they realized it's a mechanical calendar that was used to say things like,
you know, what year is it, what are the phases of the moon, where are the planets going to
be right now, when is the next Olympic Games, right?
And people have run scans on what is left of this and managed to deduce what all the
gears were in this mechanism, and it's very different from what I thought.
When I first heard news about this, I thought like, oh, they must have had some cute little
gear things in Greece.
That's surprising, but let me just show you the scale of the generally agreed upon reconstruction
of what this device actually was.
That seems like a lot of gears, right?
But wait, there's more.
So, ancient Greece had that, but that is not the picture that we have today of ancient
Greece, right?
And the thing to realize is, you don't just get here from nothing.
It's not like one day there weren't any gears, and then the next day some guy makes this,
right?
You need a whole process of science to create something that's sophisticated, and we don't
know anything about that today, right?
All of that was lost.
And I could go on and on with examples.
There's a whole bunch of things from history that are like this, but we don't have time.
I just want to restate that right now we live in a very privileged time where technology
has been in a good shape for a long time.
We see it getting better, and so we imagine that the natural course of history is that
technology always improves, and that these moments in history are just like little blips
or something that we heard about, but they're not just little blips.
It's actually sort of the regular course of world history that great achievements in technology
just get completely lost because the civilizations that made those achievements fell or had a
sort of a soft fall where they failed to propagate the knowledge into the future, right?
Technology goes backward all the time, and not just in ancient history, also in the modern
day, right?
We lose knowledge all the time.
So I'm going to read an excerpt from an interview with Bob Colwell, who was the chief microprocessor
architect at Intel for a while, but this interview is from before that.
It was from the booming days of Silicon Valley when he worked at a startup called MultiFlow.
They were trying to make a very large instruction word processor when that was a new experimental
idea, and they were having a lot of problems like when you try to design the chip, you're
using components from other manufacturers, and he just couldn't get anything to work
reliably, and he was like, what the hell, right?
So he says, Rich Lethen and I made a pilgrimage down to Texas Instruments in Richardson, Texas,
and we said, as best as we can tell, many of your chips don't work properly, and does
this come as a surprise to you?
I half expected them to say, what?
You're out of your mind.
You've done something wrong.
Come on.
You don't know what you're doing.
Go use somebody else's chips.
But no, they said, yeah, we know.
Let me see your list.
And they looked at the list and said, well, here's some more that you don't know about.
And by the way, it wasn't just TI.
Their parts were no worse than anybody else's.
Motorolas were no good.
Fairchilds were no good.
They all had this problem.
And so I asked TI, how did the entire industry fall on its face at the same time?
We are killing ourselves trying to work around the shortcomings in your Silicon.
And the guy said, the first generation of transistor logic was done by the old graybeard
guys who really knew what they were doing.
The new generation was done by kids who are straight out of school who didn't know to
ask what the change in packaging would do to inductive spikes.
So when you change the voltage in places on a chip, it generates a magnetic field, because
that's just what happens.
And when those fields interact across a chip, it's bad.
And the new people designing these chips didn't know to take that seriously.
And that's why technology degrades, or it's at least one reason.
It takes a lot of energy and effort to communicate from generation to generation these important
things that you need to know in order to do a competent job making the technology.
And there are losses in that communication process almost inevitably.
And without this generational transfer of knowledge, civilizations can die because of technology
that those civilizations depend on degrades and fails.
So let's talk about a civilization that fell, actually a whole group of civilizations.
The diagrams I'm going to show here are from a lecture you can find on YouTube called 1177
BC, the year civilization collapsed by Eric Klein.
And we're talking about the late Bronze Age, which was the time of a number of civilizations
you've heard of probably like the Egyptians, or the Mycenaean Greeks, right, or the Hittites,
the Babylonians.
And so this civilization, or this network of civilizations was sort of spanning Mesopotamia
and the Mediterranean Sea, and they had developed quite a sophisticated network of trade.
So in this graph here, each of these points is one of the civilizations, and the lines
are established communication and trade routes between those civilizations.
And whereas not all of them were connected to all of the other ones, they were interconnected
enough that you could relatively efficiently route things from one place to another if
you needed to, and that was very important.
Because Bronze, which the civilization depended on for things like defense, was hard to make
back then.
You had to do it by combining copper and tin, and copper was relatively hard to find and
was found in places like the island of Cyprus, and tin was also really hard to find and was
found very far away from those copper places like in Afghanistan.
You somehow had to persistently ship these things around in order to make your bronze,
and the other things that your society depended on.
And nobody's sure exactly what happened in this collapse, but people believe there was
some kind of environmental stressor to kick it off, like there was a huge drought, possibly
also some floods are theorized, and this led to some people attacking some other people,
and maybe you need to start using your ships for defense instead of trading.
And basically you went from all these flourishing civilizations to 100 years later, none of
them were left.
And by none of them were left, I don't even mean that the nation states were gone, like
many of the cities were burned to the ground, and the languages and cultures don't survive.
Even though they wrote by pressing things into stone, like nobody was able to translate
those languages, even today we still can't translate a lot of them.
So like so much knowledge was lost here in this collapse, we'll get back to it later.
But so I want to bridge this to the modern day in some way, and my thesis for the rest
of this talk is that software is actually in decline right now.
It's in maybe a soft decline that just makes things really inconvenient for us, but it could
lead to a hard decline later on, because our civilization depends on software.
We put it everywhere.
All our communication systems are software, our vehicles are software, so we now have
airplanes that kill hundreds of people due to bad software, and bad software only, right?
There was no other problem with those airplanes.
Now I don't think most people would believe me if I say software is in decline, it sure
seems like it's flourishing, so I have to convince you at least that this is a plausible
perspective, and that's my goal for the rest of this talk.
And what I will say about that is, these collapses like we're talking about, that Bronze Age
collapse was massive, like all these civilizations were destroyed, but it took a hundred years.
So if you're at the beginning of that collapse in the first twenty years, you might think,
well, things aren't as good as they were twenty years ago, but it's fine, we're basically
the same, right?
But then you keep thinking that, you keep thinking that, every twenty years another
couple cities get burned to the ground, and then eventually there's like nothing, right?
Fall of the Roman Empire was about three hundred years.
So if you're in the middle of a very slow collapse like that, would you recognize it?
Would you know what it looked like from the inside?
So of course I expect the reply to what I'm saying to be, you're crazy, software is doing
great, look at all these internet companies that are making all this money and changing
the way that we live, you know, and I would say, yes, that is all happening, but what
is really happening is that software has been free riding on hardware.
For the past many decades, we've had amazing advances in hardware technology, computers
keep getting faster and faster, it's really one of the greatest accomplishments in human
history that we've somehow managed to do that, and software gets better in air quotes, because
it has better hardware to run on.
That's the main reason.
Software technology itself has not improved in quite a while, I claim, right?
And you can say, but look at all these examples of cool stuff we can do, even in the past
couple of years.
So like AlphaGo was an AI that'll beat human players at Go, and you can go on like Instagram
or whatever app and like make your face look like somebody else's face, that's crazy, we
didn't used to be able to do that, and that's true.
But one, most of these again are products of hardware being fast.
Most of these cool things that we do now are due to machine learning algorithms, and those
really are relying on quantity of computation right now to produce impressive results.
It's hard to imagine being able to train AlphaGo 20 years ago on the computers we had at that
time.
So there are software technology improvements here, machine learning algorithms have legitimately
gotten better, but there's two things to say about that.
Well, the main thing to say about it, I will say, is just that it's a minority of actual
software technology, right?
So of the volume of things that we run, the thing that runs the machine learning algorithm
that produces the actual impressive result is a very small piece of the program.
It's actually really simple once you understand the math, and especially if you don't have
to train it, if you just have to use it, right?
And so when you take an app on your phone like that, that does something funny with
your picture, the part of it that does the thing that we think is cool and really value,
that piece of software is tremendously simple compared to all the stuff about like loading
the bitmap for your face, or responding to user input events, right?
That part of the software is huge and complicated and is the part that's kind of falling apart.
So I would characterize software as having small, local, technological improvements like
machine learning with overall inertia or degradation in the rest of the field.
And we're very impressed by the improvements, though, right?
And let me illustrate the degradation part as best I can.
And it's to say that we simply don't expect software to work anymore.
And I'm not sure when this happened.
So I always had a reputation for being a little bit funny, but if you go back many decades ago,
it was generally due to not being user-friendly or hard to understand how to use it.
But today, if you're using a program and it does something wrong, you're just like, yeah,
it's software, restart it, whatever.
And that didn't used to be.
And if our standards are shrinking over time, how low can they shrink before it becomes unsustainable?
So I decided to say, you know, I want to quantify or illustrate how much I put up with this from
day to day. So from now on, I'm just going to take a screenshot every time any piece of software
that I use has an obvious bug or, you know, unintuitive or incorrect piece of behavior.
And, well, right when I decided that, I was working on my compiler in the command line and
the console that I use after a while just starts saying attempt to index a nil value in the prompt
because it's written in Lua for some reason. Then I go to Emacs and I'm working on my code
and Emacs is set to reload files that have been modified. And that used to work fine,
but at some point they broke it so that it reloads the file too early and doesn't get the whole
thing and half of it is cut off. And I have to like manually reset that every time it happens.
Then I go to Gmail and I'm going to send an email to the rest of the team about some graphics
stuff, making decisions about what to do and I copy a line of a previous email and paste it into
the reply box and then I start typing my reply and it goes into like a three-character wide column
over here because somehow they've managed to reproduce all the kinds of stupid Microsoft Word
formatting bugs that everyone was frustrated with in the 90s and 2000s. Now those are in Gmail
and I don't know how to fix it. Like you fight with it for a while to get it to stop happening.
You have to like delete something invisible. I don't know. Very annoying. So then I say okay,
I'm going to get some real programming done. I go to Visual Studio and I say I'm going to type in
my command line arguments up there and as soon as I do that we get this box that says, hey,
collection was modified, enumeration option may not, your operation may not execute.
Why? I don't exactly know. Why that's a problem? Like I'm just telling it a string,
we're not even trying to do anything with the string. It's just like save this for later for
when we want to run the program. But apparently that's too hard, right? And this is far from the
only problem with Visual Studio. Visual Studio has many, many bugs, but this is the funniest one
because it's so simple what I'm trying to do and it can't do it all the time. I don't know what
percentage of the time this happens. It's probably like 5%. I don't know, 4%. So then I decide to
break off, blow off some steam and play some games. So let me download a game on the Epic store,
but we're unable to start the download for some reason. So maybe I'll go to steam because that's
a more reliable, longer lasting store and I'm able to actually download a game. But then when I go
to the install window, it's just like a black window and I have to restart steam to play the game.
Then I manage to play the game and then I all tab out for a second to check something and then
now full screen is all messed up and the game's like up in a corner of a window, right? And then
I have to restart the game to get full screen again. And then I'm watching some Counter Strike.
There was a really good match between Cloud9 and Luminosity Gaming about a month ago. But for
the entire match, there was a mysterious six player on the Cloud9 side called Undefined up in
the corner there. Let me zoom in on that map for you Counter Strike fans. It's undefined as on the
left. 100,000 people were watching this match and it was there the whole time. I was thinking about
a game I like called Ultima 4. So I went to this website that had the map and the map was like
screwed up because it was like wrapping into extra lines. So I opened a different browser to see it
correctly. I needed to get a visa to come to the Russian Federation. So I go to the visa site and
I start typing my information and maybe I type out my phone number or I put the plus one and it
didn't like it or something. So it says phone number is invalid over here. But I couldn't fix
the phone number. No matter what I put in, it wouldn't accept it because whatever the variable was
for phone number is invalid would never get reset. So I had to like stop the application,
close the website, like clear my cookies, go back and reapply in order to be able to be very
careful when I was typing my phone number. There's just so many of these. All of this was within a
couple of days. I didn't have to try hard to find these. I just had to stop collecting them. But
then I come here and as if to give me more examples in this talk. So here in this hotel where I've
been writing this talk for a couple of days, they have this software controlled heating and lighting
system where it's like you kind of push the non button buttons and things happen. And some percentage
of the time, not all the time, when I turn the air conditioning on or off, the phone rings.
It's not a full ring even. It's just like a little bloop and then it stops.
But I know it's not intentional because it doesn't happen every time. And I am not making this up.
This actually happens in my room right now. Okay. And then for this talk two hours ago,
I was working at the last minute to make a diagram and I downloaded fully legitimate licensed,
creative cloud Photoshop to my machine. The first thing I do is go file new document,
bam, the new document extension could not be loaded because of a program error, right.
And so my whole point though is we are not surprised by any of this.
My other point is that it's getting worse over time. So try this every day yourself
because we've gotten used to it. I didn't even think it would be as much when I had the idea
to record this. I didn't think it would be as much as it was. Try counting for yourself just every
day, just make a little list of all these things. And I think you'll be surprised how many there are.
I don't know if anyone knows what this phrase means five nines. I'm sure a lot of people don't.
This used to be a very common phrase in the 1990s and 2000s when people wanted to sell you
software or a hardware system. What it means is this system is up and working and available
99.999% of the time, right. Four nines would be 99.99, whatever. And we don't use this anymore.
I think in part because the number of nines would be going down and we can't make it go up again.
And nobody, well certain parties don't seem to care. So I was working on this speech
for about the past week and twice, once when I was asleep on the airplane and once the other
night in the room, my laptop just rebooted while it was in sleep mode and just killed all my programs
and stuff. I guess because it was an update. Maybe it wasn't an update. Maybe it was just
the operating system failing, but I think it was an update. So that automatically takes my laptop
down to like three nines or less, less than three nines. And if the laptop is less than three nines,
nothing running on it could be three or four or five nines, right. So we've even lost the rhetoric
of quality that we used to have, right. And so if you say this kind of thing that software is buggy,
then people like web programmers or hacker news people or whatever will say, yeah, we know, but
the market won't pay for it, right. Like we could make software better, but that takes time and
money to fix the bugs and all that stuff. And our client won't pay for it or the market punishes
that because you take longer to get to market. And that's true to some extent. I could definitely
argue with some parts of it. But here's the thing that I'm thinking today. If you haven't seen an
entire industry produce robust software for decades, what makes you think they actually can,
right? They're saying we could do it if we wanted to, but we're just totally not. But why would I
believe that they actually can do it, right? Because like we've said, there's this generational
transmission of knowledge factor that I don't think is being passed along, right. So I think the
knowledge of how to make things less buggy is lost. And even the knowledge of a technology
company has changed. And again, this illustrates the difference between software and hardware.
A hardware technology company used to be a place that makes advanced materials or designs new
radar or like does something that you didn't used to be able to do before, right. So now in Silicon
Valley and as nearly as I could tell around the world, a software quote tech company is just a
company that does stuff with computers and is then hoping to stumble into a market niche that it can
exploit. And the point is the market niche, the point isn't the software. And the point is especially
not designing higher tech software that pushes the threshold of technology forward, which is what
hardware companies always used to do. And so we've even corrupted the words tech company, right.
Okay, so now I want to bring it a little closer to what we do.
There's been this sequence of abstraction that we've gone through as programmers over the decades,
right. Originally you had to program your computer and machine language.
Then there was assembly language. Then we had this sequence of higher level languages like Fortran
and C or C++. Nowadays we have stuff like C sharp or Haskell or JavaScript that are even further
away from the machine. And the justification for this is like, look, we're working at a higher
level of abstraction. The higher your level of abstraction, the more work you get done because
you don't have to worry about scheduling machine instructions and stuff. So we're really being
smart and we're saving effort. And I think that's actually true. I don't think we want to program
things in assembly language. That's a waste of time. But somewhere through this chain it becomes
wrong. And that's how people are wrong a lot of the times, right. Like you start out by being right
and then you extrapolate it too far into wrong territory. But the important thing to all of
this is that we only see one side of it. We see that we're being smart and saving effort and we
don't see the flip side of all of these things, which is that there's a corresponding loss of
capability, right. Because I don't program in assembly anymore, I no longer am able to program
in assembly, right. If I don't, you know, if I use languages that are too high level and I'm a
little bit lazy as people often are, I don't know where my variables live in memory or what they
look like or even how remotely how big they are, right. I certainly don't know what the CPU is doing
in response to the code that I've written. I may be scared to use non-managed languages because
the very idea of memory allocation just seems too hard and scary. Or even if I'm a person who
programs in a non-managed language, maybe I'm afraid of pointers and start generating this
cult of being afraid of pointers and what to do about that like the modern C++ people do, right.
And so the rhetoric that we have is I'm being smart, I shouldn't have to do the low level stuff,
right. But part of the reality is the loss of capability that corresponds to those choices.
And both of those things can be true at the same time. I'm not saying that we're not being
smart by going up some level a little bit. I mean, there's a problem which is at the point of going
up all these levels is supposed to be to make everybody more productive. But programmers are
not more productive now than they used to be. In fact, it looks to me like productivity per
programmer is approaching zero. And if that's true, then where's the proof that going up this
ladder of abstraction further and further is really helping. So the way to at least, you know,
get a feel for this is you look at a company like, you know, Twitter or Facebook, it's the
employees a lot of people. And you look at their product and you say how much does that product
change from year to year, right. How much functionality is added to Twitter year after year.
How much functionality is added to Facebook. It's not that much, right. And then just divide
by the number of engineers at the company, right, which is thousands or tens of thousands sometimes.
That's a very small number when you do that division, right. It's it's going to be pretty close
to zero. So what's going on, right. And to illustrate again the difference in productivity
and that it's not just me that thinks this, I'm going to show an excerpt from an interview
with Ken Thompson, who is the original author of the UNIX operating system.
And he's talking about the time at Bell Laboratories when he first started making
UNIX on a computer that by modern standards had like no software at all, right.
At some point, I realized without knowing it up until that point that I was three weeks from an
operating system with three programs, one a week. An editor, I needed an editor to write code.
I needed an assembler to turn the code into language I could run. And I needed a little
kernel kind of overlay, call it an operating system. And luckily right at that moment, my wife
went on a three week vacation to take my one year old roughly to visit my in-laws who were in
California. Disappeared all alone and one week, one week, one week and we had UNIX.
Yeah, I think programmers aren't quite as productive these days as they used to be.
Yeah, he says programmers aren't productive these days like that and everybody laughs,
but it's funny, but it's not funny, right. It's really not funny when you consider
like how much waste there must be in the difference between how productive people are and how
productive they could be if everything wasn't so messed up, right. So I've made a case that
robustness of software is declining, productivity of programmers is declining. So if you're going
to say that actual technology of software is somehow advancing, it seems contrary to those
two facts, right. So I think the argument that software is advancing is clearly false, except
again maybe in tiny local bubble like areas. So now why is it so bad? Why is it so hard to write
programs? Why are we so miserable when we try to write programs today? It's because we're adding
too much complication to everything, right. And I have a way that I think about this called
you can't just, right, where there's all kinds of things that you used to be able to do on a
computer that you can't do today, right. So today you can't just copy a program from one
computer to another and have it work, right. You need to have an installer or like a flat pack
on Linux or like containers if you're a server hacker news guy, right. And so people think this
is a cool, oh, now we have containers. That's an advantage or it's an advancement of software
technology. All containers are doing is get us back to the 1960s when we didn't have to do any of
this stuff, except it's actually not because it's adding all these steps that you have to do,
right. And things you have to maintain. So now think about for a second, like why do you need
an installer to install software? Is it because of the CPU? Not really. Like imagine you have,
well, you know, imagine you have some x64 machine code and don't worry about how you got it into a
computer's memory, but you just got it there and you just jumped to it. You set the program counter
to that code. That code is going to do the same thing on a Windows PC as it does on a Mac, as it
does on a Linux machine, as it does on an Xbox, as it does on a PlayStation 4, all right. Because
all of those systems use compatible CPUs. So what's the installer for? The installer is to get
around the incompatibilities that we added at the OS layer, which is this immensely complex thing
that we mostly don't want, actually. And so we tend to think about operating systems as adding
capabilities to a system, to the system of the hardware and the software, but they also remove
capabilities like compatibility, right. And it's often very arbitrary and it doesn't get any worse
than I think it does for us today when it comes to shading languages. Anyone who shifts 3D engines
is going to know what I'm talking about. So it used to be that if you wanted to compile a program
for many platforms, you could write it in some portable language like C or C++, and you might
have to do some little if-defs to modify it for the different platforms, but you could do that,
and it's mostly the same program. Today, you can't do that because we've decided if you're running a
shader, it needs to be in a different programming language on every single platform, even if the
hardware is the same, right. So if you have an x86 CPU and an NVIDIA GPU, then on one OS, you need
to write your shader in metal shading language, and on another OS, you need to write it in HLSL,
right. And they're different even though they're the same. And so you either have to rewrite
everything n times where n is large, or you have to start using auto translation systems
to rewrite your shaders, and those come with a lot of complexity and annoyance and bugs.
And why, though, a shader is a simpler program than the old programs that we used to write,
but why have we made it harder to build a simpler program? It doesn't make any sense. We don't care,
right. So the list of things you can't just do. You can't just copy a program. You can't just statically
link. You can't just draw pixels to the screen. Oh my God, the number of steps you have to do to
draw a pixel today is crazy. You can't just write a shader. You can't just compile a program on
Windows without a manifest and stuff. And on these new closed platforms, you can't just run an
executable unless it's signed through this whole process, right. And all of these things, and many
more that are not on this list, add friction, bugs, time, engineering time, and headspace
that keeps us from thinking about interesting things to actually do. There are a couple of
examples of this that illustrate this isn't going to end anytime soon, have entered my own life. So
one of my side projects is a compiler, and to compile programs, you need to link them against
libraries on people's machine, like, for example, the Windows SDK and the C runtime library.
And now different versions of things install those in different places on the machine,
and so you have to, like, be able to find them to do the linking.
And rather than make this easy, today, Microsoft gives you a program called VSware,
which you can find on GitHub. And the job of VSware is just to tell you where these libraries
are installed. It is more than 7,000 lines of source code in 70 files. And they didn't even try
to bundle it as a library. It's a standalone program. So what they're thinking now is,
you can't just make a compiler that's a standalone program. It's obviously going to be a suite of
applications. And once you have a suite of applications, what's one more? What's, like,
a little VSware hanging out in there, right? They're not even thinking that this would be bad.
It's crazy. I made my own version of this based on some other people's work and got it down to,
like, 500 lines of code, which is still way too many to basically ask two questions that
should be two lines of code, right? It's a multiplier of 250. And then, also in the programming
language world, there's this thing called language server protocol that is pretty much the worst
thing that I've ever heard of. And there are just proponents of this all over. They're building
systems for this right now that are going to be living on your computer tomorrow or today.
Already, maybe. And as far as I can tell, it's basically a more complicated, slower way to do
libraries. So say you've got an editor for some programming language and you want to be able
to do stuff that we've been doing for decades already, like, look up the declaration of an
identifier by clicking on it or have tooltips that say, like, what type is this value, right?
Well, they say the way you should do that is, you know, you have your editor and then it's a hassle
to make plugins. This is the made up problem. It's a hassle to make plugins for all these different
things. So in order to standardize, you're going to run a server on your machine, and then your
editor talks over a socket to the server, and the server talks back and gives you the answer,
right? Which has now turned your single program into a distributed system. But the flaw in this
whole line of thinking that none of these people seems to actually, like, think about at all,
is that there's nothing special about, like, looking up the location of an identifier in your
that's just an API like we have all the time for everything. So the obvious next step, if you're
saying that we should architect our APIs like this, is to do this for other tasks, right? So now your
editor or whatever program is going to be talking to multiple of these things. And now if you ever
want to author anything for this, you now have to author and debug components of a distributed
system where state is not located in any central place, and we all know how fun that is, right?
But of course, libraries are not that simple, right? Libraries use other libraries. So what
happens at that point is you're running all these servers on your system, and who knows,
some of them are going to, like, go down and, like, have to restart, and people are synchronizing
with each other. No, this is a disaster, right? And people are actively building this right now.
And meanwhile, while we're spending all this time over-complicating stuff that we used to be
able to do in 1960, in the games industry, we're not even able to do the things that we've needed
to do forever. So, like, today, games can't run consistently in full screen, as you see from
the screenshot. And I don't wish to bag on that particular game, because we all put a lot of
engineering work into trying to make our game run in full screen. It's kind of embarrassing, like,
why, right? Also, it's actually impossible on a PC right now to render at a smooth frame rate.
It is simply not possible no matter what you do. Alan Ladovac of Croteam has a talk at GDC and a
paper about what you actually would need to do this. We just don't even have that capability,
which is insane, right? And yet we're spending all this effort on other things. And so this
complication that's introduced into all of our systems not only makes our lives difficult in
the present when we're trying to build something, it accelerates the loss of knowledge over time,
right? So, first of all, there's more to know when things are more complicated. And so if you
talk about a job spread among many people, each individual person knows a smaller percent of
what they need to do. They have a less global view, which makes it harder to do good work,
right? And harder to transmit their knowledge onto people in the future. Another thing that
happens is that deep knowledge becomes replaced by trivia. So, deep knowledge might be a general
concept. Like, here's how cache coherency works, and that enables software to run fast on, like,
different processors and stuff. And trivia is something like, well, this sprite in Unity doesn't
display properly for some reason, but we know we can fix it if you open this panel and toggle
this Boolean, and that fixes it for a while, but then some weeks later, for random reasons,
the Boolean mysteriously untoggles. So, just make sure to check that before you ship,
and it'll be fine, right? And the reason that's trivial is not only because it doesn't apply to
anything else in the world, but it's also going to be outdated in six months when the next Unity
comes out. And it's just offensive that we're spending our brain power on these things, okay?
And the third thing that happens is good information is drowned by noise. So, if something is really
hard to understand, the percentage of people who put the effort into understanding it is going to
be small. And the harder it is, the smaller that percentage. And so, if you ask people or you learn
at a school or you search on the web, your probability of getting a bad answer to the problem
is much higher for more complicated things than it is for less complicated things. And so, the
complication propagates and magnifies. So, let's get back to this collapse of civilization stuff,
right? The more complexity we put in our system, the less likely we are to survive a disaster,
right? Because we have to maintain all that complexity. We're acting right now
like we believe that the upper limit of what we can handle is infinity amount of complexity,
right? But I don't think that makes any sense. So, what's the upper limit? How would we decide
how much complexity we can handle? And that's different from what people today actually can
handle. So, if you have an engineer who can hold a whole system in his head that's really complicated
and work on it, when that guy quits and needs to pass on his job to somebody new, he's not
necessarily going to be able to communicate all that, right? So, the amount of complexity we can
sustain over time is less than the amount of complexity that individuals can do today, right?
So, why am I talking about this at a games conference, right? Like, everybody knows that
games aren't serious and whatever, right? But video games at least used to be about maximizing
what the machine could do and like really impressing the people playing the game. And
maximizing the machine means you have to understand the machine very well and that correlates
with robust software because if you understand the machine well, you're less likely to
make the kind of bugs that come from misunderstanding. There's anti-correlations with robust software
too. But anyway, now we're not really about that so much, especially talking about
independent developers. People are shifting to Unity and Unreal and Mass, right? Not very
many people write their own engines anymore. So, we have entire generations of programmers
who have grown up learning to program by, you know, making little C-sharp snippets that just
plug into other parts of Unity or something and they've never written something systemic and
they've never written something low-level. Which on the one hand is fine. Like, I'm not
saying we shouldn't do that because there's a degree to which it's smart. It reduces development
time, right? It helps you ship your game sooner. But like I said before, there's a flip side.
That flip side is giving up the capability of doing the other thing, giving up the knowledge
of how to do the other thing. So, I don't think it's bad in isolation if a lot of people make
games where they just put snippets into Unity, right? But if everybody does that, then nobody
knows how to do anything but that. And then after a while, what's going to happen? Because
we're assuming that we'll just be able to use these engines forever. But Unity and Unreal were
created in an environment where there were lots of people at games companies making engines all
the time, right? And that's where they hired people from. And when there's no longer a natural way
to learn how to make engines because nobody does it, where are Unity and Unreal going to hire
employees from to maintain those engines that everybody's using, right? And to the extent
that they can hire people is the quality of people going to go down because they have less
experience. It just takes a long time to ramp up, right? So then maybe at some point, well,
certainly at some point, there's not enough people to make a new competing engine. But maybe even at
some point, you can't really maintain the old ones and they just keep decaying over time.
That can happen. And so the way I used to think about game developers is kind of like the foundation
in the Asimov books where we kind of knew how to really program computers. And also some other
kinds of programmers like embedded systems people and high performance computing people all sort of
knew what was going on with computers. And after the rest of software just kind of decays and falls
apart, we still have the knowledge and we could bring it back and give it to people. But I'm not
really sure that that's going to happen now because I just don't know. I mean, I don't know if there
will be enough of us doing low level work or even people doing high level work who understand what's
happening at the low level while they do the high level, right? So maybe there needs to be a second
foundation spoiler alert for anyone who hasn't read the book. So back in the Bronze Age, one of
the reasons those civilizations disappeared is that the way things were set up was that reading and
writing was only done by a small elite class who went to school for years and this was protected.
The public couldn't know how to do this. They probably mostly didn't want to know.
And because those skills weren't widespread, they were fragile. So when the society was disrupted,
they weren't continued because not enough people could carry it forward. Today almost nobody knows
what's happening on a CPU, right? That skill is not widespread, so it's fragile. And so do we think
that this immensely complicated thing that we've built today is somehow more robust than what they
had in the Bronze Age with just making bronze because that didn't survive. If that didn't survive,
why do we think what we're doing now is going to survive, right? And we might have some similar
stressors. We might have some climate change issues, right? Or we might have some new stuff.
Like what happens if there are so many cyber attacks that countries just start cutting each
other off the internet, right? Now, lots of people in lots of countries can't get to stack overflow
to figure out how to copy and paste their code. So their code production is impacted, right?
Or what happens if China just says, you know what, we're just going to keep all the CPUs now.
We don't want to sell you any. What's going to happen, right? None of these things in isolation,
I don't think will bring down civilization. But it can certainly hit the system with a big
shock. And if the system is too complex, it may not survive that shock very well.
And so I'm just trying to say, like Elon Musk was saying, the technology by itself will degrade.
And we need to, as soon as we can, start working against this, right? At every level that we have
access to. We have to simplify the hardware we're running on. We have to simplify the operating
systems we use, the libraries we use, the application code we write, the communication
systems we do this over, like the internet. We have to simplify how we compile, debug,
and distribute software. And we have to simplify how people interface with software.
And that sounds like really a lot of stuff to do. But the good news is that all of these things
are so ridiculously complicated right now that it's very easy to find things to improve. Simplifying
any of these systems only requires the will to do it. And at taste, you have to have a taste
to recognize how complicated things are and how they would be better if they weren't so complicated.
Okay, now a lot of people are probably like, okay, whatever, software is complicated, but I don't
believe civilization is going to collapse or anything. And so, you know, maybe, maybe, but
uh, I would say if you're a programmer, you should care about this anyway, because even
just your own personal future, like programmers are not that happy today. We're often very grumpy.
And the reason we're grumpy is because we're doing stupid things all the time instead of
interesting things. And that's not going to get better if we keep doing things the way that we
do them, right? So you personally will be happier if we change the way we do things. And if we do
things the way they are now, maybe the future is deeply mediocre in the way that America's space
future was going to be deeply mediocre. Now, even if you just want to survive as just an individual
game developer, like you're thinking, look, I just want to get my game done. I want to ship it.
I want it to succeed financially. Even if you just want to have a very limited scope of concern
like that, removing complexity is still the right short term play. Even if it doesn't seem
like it, I'm sure we all are very familiar with cases like, well, we're going to ship in five months
and we're having a lot of problems with this particular system. It's really buggy, you know,
it loses people's work all the time, whatever, but we just have to stick with it for five months
and it'll be passed. It'll be history. And that's good because rewriting it would be a lot of
effort. It might delay shipping. And so we're going to stick with it. We're going to stick out the
five months. And that's always wrong because always what happens is it takes two years to ship
instead of five months. And so the amount that you suffered from the system is way worse than it
otherwise would have been. And maybe in fact that system was a large ingredient in why it took so
long to ship. So simplify. And in simplifying your own code to solve your own local problems,
you're also building institutional knowledge about how to simplify, which sounds really basic,
but I would claim we don't even really have that anymore. Here's some references of videos you
can watch. If you're interested in this kind of topic, Casey Meritori's video, the 30 million line
problem, Samo Beria's video, civilizations, institutions, knowledge in the future. And then
Eric Klein's video, which I showed snapshots of earlier, 1177 BC, the year civilization collapsed.
And that's all I have to say for now. Thank you for your time.
Wow. Very impressive. Don't you think that the collapse will happen when we reach the point
of technological singularity? Because simplifying is, I think, some kind of way to prevent it.
You know, once you start saying singularity, it's too hard. The point of singularity is you
can't predict what's going to happen. Sure. Yeah. Maybe it'll be bad. Maybe good. Yeah. I don't
believe in singularity the way a lot of people do. It doesn't seem realistic to me. But
as you get close to that kind of situation, things move faster. And if things are moving fast,
they break easily. Okay. Yeah. It's what about foundation, by the way, right? Yeah. Well,
and one of the objections, because I'm always criticizing my own, like, what is the counterpoint
to this? And what if we just let software get really complicated and then just make an AI that
understands it? And that's fine. And it's like, okay, maybe, but you really want human beings to
not be able to understand software. It doesn't seem good. Okay, we have about five, 10 minutes
for questions. So if you have one, you can ask. Yeah, come here and ask.
Thank you very much for this beautiful speech and beautiful mind. Welcome to Russia, by the way.
Thank you. And I've been doing games in Game Maker for 17 years, and we spent one year on
doing 3D in Game Maker. And I was asking myself a question why we did this. And actually now I
know the answer. And I have another thought about it. Friedrich Nietzsche, when he was already an
old man, he started to lose his sight and he couldn't write anymore, couldn't think actually,
because he would think while writing. And so he started using Hansen's writing ball. And this
was the first type writer to use. But his style changed. And when I switched from Game Maker to
Unreal, as a game designer, saw that my style, my way of thinking changed. Don't you think that
tools, they somehow force us to think in a certain type of way, and for you making a new language
as somehow to break through this and start thinking wider, broader? I think I would agree with that.
And I would also say, though, because we think with tools often, unnecessary complications or
bugs in the tools interfere with the thought process. Like you're in flow, you're doing stuff,
and then something bad happens, and you're like, now I have to go fix this thing, and you can't
do what you were doing. So I definitely think that's important. When I'm making my new language,
I'm trying as best I can to get rid of all these complications that don't make sense.
But there's so many of them. And some of them are baked into our assumptions, because I learned
a program by using these complicated systems. So what I see as simpler may be very far from
the actual simplicity that we could achieve, because my thinking has been trained on those tools.
So we'll see. We'll see how it comes out. Thank you. Thank you.
Hi. So let's say I'm an indie developer, and I'm sold on your ideas. I don't like
Unity either. And I want to put pixels on screen with great ease, but I'm not yet ready to write
my own engine as you do. Well, you would have to write your own operating system to put pixels on
the screen. So what is the set of currently existing tools I can use? Well, I don't know,
because part of the problem is everything is this way. So really what needs to happen is not
about specific tools that you use. It's about developing the aesthetics for things that are
not a giant horrible mess. And whatever tool looks like that to you, just use that instead of
whatever you're using, and then maybe we could migrate everybody slowly over time. Yeah, the
problem is when I look for ways to get to the lower level things I find is like Visual Studio and
C++, and it doesn't help very much. It's super complex, and it breaks every time, and whatever.
Yeah, I don't know, man.
Thank you very much for your talk. My question is, in 1968, 30 years after the concept of the
computer was invented, Edgar Dijkstra said that where the mainframes were having two megabytes
of memory, even then, Edgar Dijkstra said that the programming is just too hard by its concept
to be done by human beings. Are you sure that simplification will help to any extent?
Well, it'll help, whether it makes them completely understandable by us. I don't know. I mean,
I think you could, I haven't read the Dijkstra piece that you're talking about.
It's called Humble Programmer. Okay. I think you could rate it by what problem are you trying
to solve, right, and how complicated, like there's an inherent complexity to a problem,
first of all, and so there may be problems that are so complicated it may be hard to understand
what the software looks like to solve that, but then there's also added complication because
we're solving this with existing systems, and those systems already prevent us from doing certain
things. And so there's a difference between ideal complexity and actual complexity, and I just
want to get closer to ideal complexity. Whether that's good enough, I don't know.
