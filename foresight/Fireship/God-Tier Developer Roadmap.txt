You've likely seen videos on YouTube telling you the number one programming language to learn
right now if you want to be rich. That's not what we're doing today. Instead, we're going to travel
to the deepest, darkest depths of the software engineering field to discover the programming
languages that are loved, hated, beautiful, ugly, compiled, interpreted, useful, weird, and everything
in between. If you make it to the end, you'll have a roadmap for everything you need to know
to land a job as a junior developer in 2023. Or it might just make you extremely depressed
because this iceberg is just the tip of the iceberg of what you actually need to learn.
Choose any language and you'll find another iceberg within this iceberg that goes on forever
like a Mandelbrot set, which ironically you can represent in code with any one of the languages
we're about to look at. Before we get started, there's quite a few programming icebergs out there,
but this one ranks languages based on where I think you might encounter them as a beginner
learning how to code from scratch. Each level has its own theme, so let's get right into it,
with languages that are designed to make programming as easy as possible. If you know
absolutely nothing about programming, the best place to start in my opinion is Scratch. It was
developed at MIT, like some other languages on this list, but instead of typing out code, you drag
and drop these blocks together like Lego bricks to represent things like variables, control flow,
and operators. It makes the thinking process behind programming much more accessible, and you
might be surprised at what you can actually build with it. Long before Scratch, though, we had basic,
or beginner's all-purpose symbolic instruction code, which came out of Dartmouth in 1964. At the
time, Fortran was all the rage, but it wasn't beginner-friendly. Basic provides a bunch of basic
commands like print, go-to, and for, and was included in most personal computers, which made it the
go-to option for people learning to code for the next 50 years. Now moving on to the next tier,
we have the extremely popular dynamic high-level languages. The language most people start with
today is Python, primarily because of its minimal syntax. It doesn't require curly braces, semicolons,
and stuff like that, and instead uses indentation to represent different blocks of code. The other
popular high-level language is JavaScript. Syntactically, it's pretty ugly, but it's a requirement
if you want to do web development, and almost every developer will have to touch it at some point in
their career. Any application that can be written in JavaScript will eventually be written in JavaScript.
Now, after learning one of these languages, you'll be able to build pretty much anything you can
imagine, and you could have an entire career as a software engineer without going any further down
the iceberg. But you don't want to be on your deathbed wondering if you should have tried out PHP.
On this next tier, we have languages that are extremely popular, but a little more specialized.
Programmers like to get things done from the terminal, and there are scripting languages,
like Bash and PowerShell, that allow you to interact with your computer programmatically,
instead of typing out the same commands over and over again, write a Bash script to make it
reproducible. Now, if you get into web development, you'll also need to learn HTML and CSS, which,
when combined together, arguably form a turing-complete programming language. They're not
used for programming in the traditional sense, but rather to define the structure and style of a
website. And if I were to say HTML is not a programming language, I would be immediately
canceled by the tech community. In addition, most apps need a database, and the most common
language for working with databases is structured query language. You can call it SQL, SQL, or
SQL. This turing-complete, although not used for regular programming, but rather to read and
write data in a relational database. Now, Python is great and all, but there are many other dynamic
languages that might be a better fit for certain projects, like PHP made it easy to build server
side web apps in the 90s, and is still very popular today. Lua is easier and faster than Python,
and is embedded into many engines like Roblox and World of Warcraft. Ruby is an easy-to-learn
object-oriented language, also commonly used to build web apps with the Rails framework. If you
work in data science, you'll come across R, which is used for statistics and data viz, or Julia,
a more modern option, also used for scientific computing. The one thing all these languages
have in common is a dynamic type system. However, as you build more complex software, you may realize
that you need a more rigid framework, and one way to accomplish that is with a static type system.
This tier makes up the bulk of production code out in the world. First up, we have Java, which
kind of revolutionized programming with the Java virtual machine. It compiles to bytecode that
runs on the JVM, and that allows developers to target any computer architecture from a single
codebase. Syntactically, it's an absolute dumpster fire for beginners. I made an entire video about
why people hate Java, but having explicit types in your code can make it much easier to understand
and refactor, and modern IDEs like IntelliJ will pretty much make the code write itself.
Java is legendary, but it was followed up by Microsoft with C-sharp. It's similar to Java in
many ways, but gets a lot more love from its users. It's used to build games with Unity,
as well as web and desktop apps with the .NET framework. Another well-loved tool from Microsoft
is TypeScript. It takes JavaScript and adds a type system on top of it, making it much easier to work
with on large complex projects. If you're building a mobile app today, you'll likely be working with
Kotlin for Android, Swift for iOS, or Dart with the Flutter framework. These languages are all
statically typed, but they go about it in a more modern, concise way, with features like type
inference that minimize boilerplate code. Next up, we have Go, which is a high-performance
language developed at Google, to build low-level systems. It was designed as a replacement for C,
and Ken Thompson, one of the original creators of C, helped design it. The syntax is nice and
concise, making it approachable to beginners, and it has a garbage collector, which means unlike C,
developers don't need to worry about manual memory management. Okay, so at this point,
we've reached the level of the iceberg, where most people are afraid to go any deeper. Things
are going to get weird. What happens is that many developers get jaded with these big, heavy,
object-oriented languages and go searching for a better way. At this level, we have functional
languages, the most famous of which is Haskell. Instead of classes and heritans and all kinds
of crazy design patterns, the only abstraction you really need is the function. It was inspired by
the Miranda language and is named after the mathematician Haskell Curry. Most importantly,
variables are immutable, and functions have no side effects. Surprisingly, you can build almost
anything with these limitations, although most production code out there is not functional.
Most of us run into problems when trying to figure out what a monad is, which in layman's
terms is just a monoid in the category of end functors. Haskell is great, but Microsoft developed
a functional sister language to C sharp called F sharp. Unlike Haskell, which is purely functional,
F sharp is also imperative and object-oriented, making it more approachable to developers
coming from higher up in the iceberg. Now, if you hate Java, a good alternative is Scala.
Like F sharp, it supports both object-oriented and functional programming, but it runs on the
JVM. It's statically typed, but there's another JVM language called Clojure that is both functional
and dynamic. This makes it more well suited for getting things done quickly with the trade-off
of type safety. Other popular functional languages include OCaml, which is used extensively at Facebook,
and Elixir, which has a very nice ruby-like syntax and is capable of building high-performance,
real-time web apps. There's also Elm, which is a purely functional language that compiles to
JavaScript, which can build front-end UIs with zero runtime errors, but now it's time to go one
level deeper to the heart of the iceberg. These languages are absolute chads. They're low-level
systems languages that can manually manage and optimize memory and are used to build things
like operating system kernels and compilers that make all the other soy-based languages possible,
the most legendary of which is C. It was used to build the Windows, Mac, and Linux operating system
kernels, and its curly brace syntax inspired many other languages on this list. Surprisingly,
it's not all that hard to learn and has a relatively small set of keywords to memorize.
However, being able to use it effectively requires extensive knowledge of algorithms and computer
architecture. For example, C doesn't have hash maps or dictionaries, so you'll have to learn how
to code up that data structure on your own. C was the perfect programming language when it came out
in 1969, but it only supported procedural programming and eventually developers wanted more. C++ was
originally a superset of C designed to extend it with object-oriented programming patterns,
like classes and inheritance. Unlike C, it's extremely hard to learn and provides many opportunities
to not only shoot yourself in the foot, but blow your entire leg off. This is a reference to manual
memory management with pointers, which got that name because they're just as dangerous as pointing
a gun at someone. Despite its learning curve, it's an extremely prolific language used to build
highly optimized software like game engines, compilers, and so on. C and C++ are still extremely
relevant today, but the modern Chad tends to prefer rust for low-level programming. It doesn't
have a garbage collector, but unlike C and C++, it uses a technique called borrow-checking instead
of pointers for memory management. This makes it much easier to write memory-safe programs and
consistently ranks as the most loved language in the world. The languages on this tier are
extremely popular, but now we descend further into the modern languages that you probably haven't
heard of. First up, we have V, which is a high-performance systems language that feels very
similar to Go, but unlike Go, it doesn't use a garbage collector, and unlike Rust, it doesn't do
borrow-checking, but it can still create memory-safe applications with its own auto-free innovation
where the compiler basically cleans everything up. I have no idea how it works, but it looks cool.
Another modern replacement for C is Zig. It's designed to simplify low-level programming by
eliminating features like macros and metaprogramming and is very explicit when it comes to memory
management, and it can cross-compile C and C++ just like Clang. Zig is not to be confused with NIM,
another high-performance language that's very expressive like Python, but is statically typed,
and interestingly, it has a tunable garbage collector that can be turned off altogether to
enable manual memory management. Recently, Google announced Carbon, designed to be a successor to
C++. What makes it special is that it can fully interop with a legacy C++ codebase. Another low-level
specialty language is Solidity. It's a statically typed object-oriented language, but is designed
for implementing smart contracts, especially on the Ethereum blockchain. Then we've got Hack from
Facebook, which is designed to interop with PHP. The original website was built with PHP,
but they needed a language with better performance and a type system to scale it up to the monstrosity
that it is today. There are many other good modern languages at this point in the iceberg,
like Crystal, Hacks, and Ferro, just to name a few, but now it's time to go down to the next level,
where we look at languages that are still either widely used or historically important,
but not something you would likely choose to program in. Fortran was the first high-level
programming language, and was by far the most popular language for many years until C came
around. Not long after Fortran, Lisp was invented in 1958. It pioneered many ideas we take for granted
in computer science today, like dynamic typing, higher-order functions, recursion, and repel.
It inspired many other languages like racket, scheme, closure, and to a certain extent,
JavaScript. Another highly influential language that came out this year was Algorithmic Language.
It's a big, complex language and never got as popular as Fortran, but its type system and use
of expressions had a major influence on the development of C and C++. The following year,
in 1959, Kobal was born. If you want to make money in the 2020s, learn Kobal, because over 40%
of banking systems still use it, with over 200 billion lines of code in production today. In 62,
APL first appeared, which stands for a programming language. It implements linear algebra directly
into the language with a multi-dimensional array or matrix being the central data type. This leads
to extremely terse code that resembles mathematical notation and makes heavy use of the Greek alphabet.
In 1970, Pascal was invented and took the programming world by storm. It's a procedural
language with a familiar syntax and also had very fast compile times. It eventually became the most
popular language in the early 1980s before the rise of C a few years later. There are many other
important languages from this time period, like Simula, the first object-oriented language that
went on to inspire Smalltalk, which itself inspired many other object-oriented languages like Python,
Java and Ruby. Then there's Erlang, a concurrent functional programming language that basically
powered the entire telecom industry and is still in use today. There's Ada, a general purpose
language named after Ada Lovelace, who's generally considered the world's first computer programmer.
It was extremely popular in the 1980s and is still used today by the Department of Defense
to blow people up. In addition, we should mention Prolog, the language that pioneered
logic programming, and MetaLanguage, which pioneered the polymorphic type system used by
other statically-typed functional languages like Haskell. There are many other historical languages
we could talk about, but now it's time to descend into the realm of the esoteric, where we find
rare and bizarre languages that feel more like works of art than engineering tools. The first
known esoteric language came out in 1972 and was called Intercal, which stands for compiler language
with no pronounceable acronym. It was designed as a parody to make fun of the languages of the day,
like Algol and Fortran. It has an entire paradoxical reference manual that makes no sense,
and has an interesting choice of keywords like please and mingle. Please doesn't actually do
anything, but it makes you a more polite programmer. Next up, we have brainf**k. Brainf**k is most
well-known for being extremely minimal. Urban Mueller created brainf**k in college, and it works
by initializing an array, then gives you a pointer and eight different characters to manipulate memory
in that array. This results in a codebase that will f**k your brain up. It inspired another language
called MaleBulge, or maybe it's Malbulgia, which is named after the Eighth Circle of Hell in the
Divine Comedy or Dante's Inferno. If you thought brainf**k was difficult, this language takes things
to a whole other level. It makes programming so difficult that I can't even summarize how it
works in a single sentence. If that's a little too dark, a far more fun language is Chef, which
is stack-based and is designed to make your code look like a cooking recipe. Instead of concise
keywords, it uses sentences like put ingredient into mixing bowl to push a value onto the stack.
Put these commands together to create a Hello World souffle, then specify how many it serves to
write it to the standard output. That's pretty cool, but it may seem kind of silly to an intellectual.
The Shakespeare programming language will make your code look like a Shakespearean play. It provides
the low-level control of assembly with the verbosity of 16th century poetry, but if words
aren't really your thing, then a good language choice would be Piat, which is named after Piat
Mondrian. It's also stack-based, but you write code utilizing patterns of 20 different colors
on a bitmap image. The end result is a code base that looks like abstract art. Now, if you're a
crazy cat lady, you're really going to love this next language, LOL code, which provides a developer
experience similar to an LOL cat meme. You open a program by saying hi, then end it by saying k
thanks bye. Loops can be performed with I'm in your or broken out of with I'm out of your. That's
nice and easy to understand, but it would be even better if it included emojis. Emoji code is a
language where the syntax is entirely based on emojis. Modern developers like to use so many
emojis in their documentation that this language would just streamline the entire process. It's
a fully featured object-oriented language where you can define code blocks with grapes and watermelons,
classes with rabbits, and generics with shells and eggplants. Another language that's not
necessarily esoteric is C minus minus. It's designed as a portable assembly language that
borrows heavily from C, but omits many of its features. The ultimate dialect of C, though,
is Holy C, which was created by Terry A. Davis and used to build TempleOS, an operating system
written under the direction of God. Holy C is actually really cool because it works like C,
but it's just in time compiled on the operating system, which means you can use it like a scripting
language that can interact directly with the operating system kernel. And that brings us to
the final tier, the absolute lowest level you can go with your learning as a software engineer.
Assembly is a language of which there are many variations that correspond directly to the
architecture on the CPU. Different CPU architectures like x86 and ARM require different machine
code instructions. Assembly allows you to represent this code with simple commands
that manipulate values on the CPU's registers. Now, if that looks too easy, the next level down
is machine code. At this point, we're looking at ones and zeros, or raw binary, usually represented
in hexadecimal format. To code at this level, you'll need to have intimate knowledge of the
computer's architecture and also be able to count in binary. But if we go beyond machine code,
now we're looking at billions of transistors on a CPU. A single transistor represents one bit,
like a one or zero, by controlling the amount of electricity that flows through a piece of
silicon. Now, in order to do anything useful, the transistors need to be organized into logic gates,
like not and or exclusive or and so on. Ultimately, it's these very simple chunks of logic that
perform the miracle of taking some electricity as an input that can produce some other electricity
as an output, and do it billions of times per second all over the world so you can play video
games with your friend in Vietnam. If that was too easy, then you may want to look into the field
of quantum electrodynamics. You fully understand how these particles behave in the electromagnetic
quantum vacuum. You can then use your skills to build a next-gen, blazingly fast quantum computer
and become the richest person in history. At this point in the iceberg, there's only one place left
to go, the scariest place of all, yourself. Once you know everything, the question becomes,
what is knowledge? Epistemology is the theory of knowledge, and philosophers still don't have a
good answer to this day. Reality only exists within my own mind. For all I know, the entire
external world and all the knowledge I've acquired are just illusions and projections from my own ego.
Maybe there's a godlike being that controls all the sensations and knowledge received by my mind,
or perhaps my real body isn't a vat of goo and I'm already living in Zuckerberg's Metaverse,
or maybe I never came out of that ayahuasca trip I took 10 years ago. The only thing I really know
is that I know nothing. Thanks for watching, and I will see you in the next one.
