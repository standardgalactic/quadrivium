Howdy, this is Jim Rutt, and this is The Jim Rutt Show.
Music
Listeners have asked us to provide pointers to some of the resources we talk about on the show.
We now have links to books and articles referenced in recent podcasts that are available on our website.
We also offer full transcripts.
Go to JimRuttShow.com. That's JimRuttShow.com.
Music
Today's guest is Alicia Herrero.
She's a professor of philosophy emerita at Prince George's Community College in Maryland.
This is kind of old home week.
I actually grew up in PG County as we used to call it in the day.
They tell me you're not supposed to say PG anymore, but that's what we always call it.
I lived there from the time I was two to the time I was 22, and my wife is from PG also.
My brother is a distinguished alum of Prince George's Community College,
and probably half my friends went there, so it's great to connect with Alicia.
She is a complexity person.
She is the author of Dynamics in Action.
I have not read that book, but I ordered it and look forward to reading it.
It's very interesting, and she's co-editor of Reframing Complexity, Perspectives of North and South,
and Emergence, Self-Organization, and Complexity, Precursors, and Prototypes.
And she's written lots of publications and refereed philosophy journals.
She's also written a couple of things that I read while I was doing my research for this episode
that I think the audience might find interesting.
One's called Downward Causation, Poliani, and Progosian,
and another one called Western Science and Philosophy.
Can't deal with the relations between parts and holes.
You know, they're pretty serious, but they're not quite scholarly papers, right?
And so I think our audience could deal with them, and as always, links to those papers
and the books will be on our website at JimRucho.com.
So, welcome, Alicia!
Thank you for having me. It's a pleasure to meet you.
Yeah, it's a very good conversation. I really enjoyed reading the book.
It's quite short, 235 pages, but it is chock-full of stuff.
I mean, there's lots of ideas in this book, but we probably aren't going to get to them all.
My topic list is, I try to keep it to seven pages, but it looks like I got more like 11,
so we'll see how far we can get into it.
But I'd also like your writing styles very clear.
Oh, no, it is not.
You must have not read much of it because it is horrendously...
No, no, for philosophy book, it's damn readable.
No, no, no, it's awful. I wish I were here.
Well, no, no, I would disagree. I would disagree.
But today we're going to talk about her newest book just published called
Context Changes Everything, How Constraints Create Coherence.
So, the book was just published a couple of weeks ago, right?
A couple of weeks ago, yes.
Well, again, we'll have a link to the book on the episode page.
So, let's actually start with something.
We talk about a fair bit.
A number of our guests, for some reason, have found this framing useful.
And that is Aristotle's Four Causes.
This is a theme that runs throughout the book.
Why don't you remind the audience what the Four Causes are and what they are?
Well, I think Aristotle probably got it from the potter's wheel.
You know, he started thinking about causes and effects using the example of the potter's wheel.
Four Causes are material cause, the clay, the stuff from which the pot will be made.
Then final cause or purpose or teleology, which is the goal to which the thing that you're making will be put,
which is pouring water.
So, the final cause of the picture would be water.
The formal cause, it's not quite shape.
It's sort of the what makes a picture a picture.
So, it is the essence, the basic fundamental identity of the thing.
And then finally, efficient cause, which is the actual force exerted by the hands and the on the on the clay to turn it into the picture.
So, it's energetic.
Efficient cause is energetic exchange.
One of the things, the points you make is that prior to maybe the late 16th century,
people tended to consider all those causes when they were thinking about nature and the pre-scientific era.
But one of the moves that probably came off accidentally more or less from the invention of modern science was a very heavy focus on the efficient cause.
Correct, correct.
In a sense, material cause, people figured, well, science will take care of that.
And formal cause and final cause were sort of discarded.
They went out with a bustle.
You know, this is something we don't have to worry about anymore.
So, we can explain everything in terms of forceful causes.
It seems to me that when you're talking about complex dynamical systems, somehow final cause and formal cause kind of gets snuck in indirectly, not the way Aristotle thought.
People were born with an act or organisms or all natural phenomena had an inherent internal and teleki internal kind of like an acorn has the form of an oak built into it.
And all it has to do is unroll and unfold into the final form.
But I think what we have now with complex dynamical systems is that interactions with the environment and in my view constraints are the contemporary version of formal and final cause.
Yeah, and the over focus on efficient cause, matter and motion bumping into each other.
I often refer to that as naive Newtonianism and you know, most nerdy smart kids go through that period, right?
And they make the error of thinking the famous Laplacian area where he says, yeah, give me the position and velocity of everything in the universe and I can predict the future in the past with total precision.
But fortunately, once you get exposed to ideas of complexity, you realize it's completely crazy.
And that has actually caused for those people who've gotten the complexity lens to realize there's much more to our universe than naive Newtonism.
But, but it's amazing how it's persisted and you can't blame people.
I mean, it seems to do a hell of a job predicting eclipses, but even Newton knew the three body problem would mess things up.
Right.
But that was a warning Newton gave us that went on heated for many centuries.
My first paper was about Kant and Prigogene and exactly about that subject matter.
Yeah.
And then as you talk about in your book, one of the current manifestations of it, though, I will say it depends where you are in the sciences.
Now, I've had the good fortune to be around complexity people for the last 20 years.
And so there's much, much, much less of that there.
But I suppose out in the wilds of solid state physics and places like that, there's still a lot about what you call nothing but ism.
Right.
Explain what nothing but ism is.
Well, the idea that the whole is nothing but the sum of its parts and therefore anything that appears to be an emergent property is really an epiphenomenon.
It is, it is, it is sort of froth that's thrown up, but it really has no causal power.
Well, of course, not because if causal power is only thought of as efficient causality, then clearly the synchronization of the photon streams in a laser beam.
Don't align their component laser beams as another efficient cause.
So that's the problem.
Yeah, that's it leads very quickly to absurd conclusions.
What makes me wonder why did it hang in there so long?
Well, and you know where it hung in.
I came at this because I wrote a dissertation on the difference between explaining and justifying behavior.
Well, justification has to do with moral reasons so on.
But explaining behavior, the first sense of that first book that you quoted is what is the difference between a wink and a blink?
Presumably, it's the cause, right?
Meaning that an intention causes a wink, but a, my throwing some sand in your face would cause you to blink.
Well, but then the next question is what the hell's an intention and how can an intention cause the action in an efficient cause way?
Correct?
And my answer was obviously, well, there can't be just one neuron pushing another neuron pushing.
I mean, forget it.
That doesn't work that way.
And at the time I was living in Berkeley and I was hanging around people who were into network theory and systems analysis and so on.
I'm going, you know what?
There's got to be a network property.
We're talking the 70s gym.
There's got to be a network property that somehow produces emergent properties, which in turn can loop back down and cause the neurons that are responsible for motor control to move the arm in a way that it satisfies the intention that I started out with.
All right.
So how is this going to work?
You were talking about PG community college.
The nice thing about teaching a community college is nobody gives it them to publish anything or not.
You're going to be judged by how well you teach.
So nobody cares about whether you publish.
On the other hand, nobody's forcing you to write papers on the fifth decimal point of the existing theory.
So I could play around and in this area in DC, I could hang around NIH and start listening to people come talk.
And so you start understanding how patterns in neural systems work and so on.
So it's got to be something.
It's got to be something like that.
So that's when I decided, all right, you know what?
I'm going to give the term cause to the Newtonians.
I'm not going to fight that battle.
It's going to take me forever to fight that battle.
So instead, what I want to do is look at the notion of constraint because as soon as the hard scientists get into trouble with that Newtonian silly understanding of efficient causes.
You mentioned they retreat and hide behind the notion of constraint.
And I thought, you know what?
That's going to work.
So that's that's how the whole that's how my, my, my trajectory towards reconceptualizing causality and specially formal and final cause in terms of constraints developed.
It's interesting.
And actually it worked well with the little analogy I use.
When I'm trying to explain complexity to just random people at a party or something, I will say you can think of reductionism, you know, classic science as the study of the dancer.
While complexity is the study of the dance, right?
And a dance is not random motion.
It has constraints, right?
If it's going to be, it's going to be a jitterbug.
It has one form of constraints.
If it's going to be a waltz, it has another.
And so when I read that and saw the movie you were making, I say, works perfectly with my good old.
Absolutely.
My good old analogy.
Absolutely.
And it held held together quite well.
So now let's move on to your next topic, which is a term that most non philosophers will have never heard of.
I've heard of it a few times, but it's not term we use very often.
Santa Fe Institute.
Myriology.
Is that how you pronounce that?
Myriology.
And that's, again, the whole parts, parts whole.
Because let's use an example from Brian Arthur's note that I love.
That's a Santa Fe book on complexity of economics, economics and complexity.
What, what a, an economy is, are a bunch of individual elements that interact in a constrained way to result in an
emergent phenomenon that has certain properties that the components don't have.
An economy has certain characteristics that the individual trader and seller don't.
But once that whole WHLE, which is a coherent whole, and I really want to emphasize the fact that a coherent whole is different from a
mass clump of stuff because it's organized.
And what organizes it are the constraints.
But once it's organized, then all of a sudden the components also acquire different properties because suddenly they are now traders and regulators and so on and so forth.
Correct.
So there you have the whole part.
The parts of the components, correct, and, and the interact the constrained interactions among the components.
The whole is what I'm calling in this new book a constraint regime.
Because one of the problems we've also had, I don't know if it's Newtonianism or what, but we tend to reify things, things, no pun intended, we tend to reify things.
But an economy is nothing other than all these constraints all held together by an overarching set of constraint regimes once the constraints close into it into a coherent whole.
But they can then loop back down and affect their components and they acquire, they acquire, now they have a role, right?
In a society, once a society is a socially organized structure, people can be citizens, they can be senators, they can be teachers.
Those roles don't exist except within an organized society.
So then the next question is, well, on a more general level, what is the relationship between the parts and the holes and the holes and the parts?
If you really buy the whole Newtonian idea, ain't no difference between the parts and the holes, the holes are nothing but the sum of the parts.
But that means you cannot explain how it is that my behavior is constrained top down by my living in a particular culture.
The fact that I was born and raised in Cuba, the fact that all of these affect my behavior, but they don't do that as an efficient cause.
A culture, an economic system doesn't cause my behavior to differ in any kind of efficient cause.
But since the Newtonian Revolution, pretty much myriology got thrown out of the picture.
So that messes up philosophy of mind because you cannot explain mental events.
If you think of mental events as emergent properties because they should be reducible to a bunch of neurons pushing each other around.
But where does the emergent property go when you have that?
I'll tell you a little example. I've got my little homey examples that I love to use on this as people who doubt.
We'll get this later, the idea of top down causality.
I say, let's imagine me dead and run through a blender and poured into a bathtub, right?
What's the chances that those chemicals are going to hop out of the bathtub, walk down the hill and go to the ice cream store?
Essentially zero, right?
And on the other hand, if it's me and I'm operating up in cognitive space and it's after dinner and we just had a nice dinner
and I feel like a walk with my wife to go down and get something nice, then we may decide to haul all these atoms and molecules
and they have nothing to say about it because this top down idea, well, let's go get some ice cream, causes the,
and by the way, Newtonian physics is never, or let's say physics is never violated, right?
The atoms are dragged along and they are dragged along through efficient causes.
You know, they're all stuck together and bound by various forces, but the decision to go get the ice cream came at a higher level in the stack.
And, you know, and again, some of the attempts to deny that that happens is just bizarre, right?
Well, it is to me and you, but it isn't to an awful lot of people.
And even folks, and I may, I hope there hasn't been a change in the last couple of years,
but even somebody like Brian Rockland, who recognizes the reality of the emergent properties nonetheless gets very weary about ascribing causal properties,
causal powers, let's use that for causal powers to those emergent properties.
In a sense, the notion of supervenience is continuous.
So they're very few of us, people like Carl Gillette, people like Robert Bishop, they're very few of us who are willing to go the next step and say,
not only are emergent properties real, they have causal powers with respect to their own components and that's what homeostasis is for God's sake.
Homeostasis readjusts the metabolism, the neural system and so on in order to maintain the integrity of the whole.
But the idea that nonetheless that should be explicable in a reductionist fashion, the power aspect of it is still not quite,
the physicists haven't bought it.
Philosophers, I hate to say this, I have, I never read philosophy anymore.
I, because all the, I grew up, I was trained as an analytic philosophy for in the United States, all they're worried about is the meaning of words.
I mean, they're very few people.
And you can tell why, how this is when you have people like Chalmers and Christoph Koch, who Chalmers has sort of thrown in the towel and he's really saying,
the only way you're going to have mental properties is if you build them in from the get go from the, from the bot, you know, so therefore electrons have mental quality.
Oh, come on, give me a break.
Yeah.
We had Christoph Koch on the show sometime back and he actually is a panpsychic.
But you, but do you understand why?
Because if all of reality comes from innate internal fundamental properties that only interact with efficient causes, there's no way you can get a coherent whole.
And that's the key word coherently organized that then and from which emergent causal powers come.
And it's interesting that they, another extremely bright guy named Ben Gertzel has been on my show many times, good friend of mine.
I think he's a panpsychic for exactly that reason, because otherwise he's wedded to his model of the universe.
And where does consciousness come from?
If it doesn't, if it isn't innate, while a complexitarian would say, well, it's obviously emerged just another level on the stack, right?
And that's not that hard.
Correct.
But it's this notion that my nature, you know, oh, it's in my nature is somehow given as an essence in the fundamental tiny, tiny bits that make up the rest of it.
That's still much more widespread than one would think.
Yeah.
We'll get to supervenience later.
And I think we have a somewhat different point of view, but not entirely different.
We'll get to that later.
But I think we're on the same page that, hey, this need to smuggle in something like consciousness or cognition as a fundamental property of matter seems to be a big overreach.
I mean, do we try to smuggle in the fundamental nature of digestion?
I don't think so, right?
But we get overly confused when it comes to cognitive processes.
But digestion is a good example.
And that's the one John Searle has always used.
That's why I always use it.
Yeah, exactly.
And I used to fight him.
We were on the NEH board together.
But the thing about digestion is digestion really doesn't do much.
I mean, it is an effect.
Digestion is an effect of all these other processes.
The reason I like homeostasis is because the metastability of homeostasis is causally effective.
It does, if I have the fudge brownie, it's going to switch all my glucose and all everything else around to keep the integrity of the whole.
So it has caused what I would want to call causal powers, but I've given up that term because people will say, oh, but it is an efficient causation.
No, that's right.
It isn't.
But it is DS Lewis's notion of cause meaning without which not.
If that weren't the case, it wouldn't be.
So that's the causal notion I would espouse.
Okay, let's now make the next step, which is why don't you start to define what you mean by constraints and lay out a taxonomy of different kinds of constraints.
This is where the book really started to get into new territory for me.
I've had it very interesting.
And that's what the new one is all about.
That's what the new one is all about.
I think in the first book, I made a distinction barring from Lila Gatlin's book called information in the living system, which was from 1960, something or other.
A distinction between I use the term at the time, context free and context sensitive or context dependent.
There's a lot of grief from people saying ain't nothing that's context independent.
All right.
So in this one, I call it context.
I mean, nothing's context free.
So in this book, I call it context independent and context dependent context independent according to Lila Gatlin are conditions that take a system far from equi probability.
Now, whatever takes conditions away from random from white noise from random noise.
So if you institute a gradient, you have you have instituted a context independent constraint.
If you institute if you institute polarity or charge, we were talking the early universe here probably that were those were probably the earliest constraints.
And I call them context independent because in a sense what they do is they set the context in a sense they set the boundaries of possibility space and inhomogeneities within that possibility space.
So it's no longer white noise.
Lila Gatlin calls context dependent constraints, those that take a system away from independence.
So one of the things that's that I find interesting also is that we might put Newtonian is now.
But when you look at the second law of thermodynamics and I'm petrified because I kind of talk about the second law of thermodynamics in this new book.
But according to the Boltzmannian everybody's interpretation of the second law of thermodynamics, the the events in the particles are independent of one another.
And I think you're never going to get complexity if you have independent particles.
That's the beauty of Stuart Kaussman's button example button mesh example, you know, you tie one button to another tower, and all of a sudden, the thing turns into a mesh, right you have a phase transition, and you have a mesh.
So what would I consider context dependent constraints that take a system far from independence.
I would consider catalysts.
Context dependent constraints. I would consider feedback loops.
Context dependent constraints. And I think since that first book was published 20 some years ago, what's nice to me is the burgeoning of epigenetics nowadays, because if epigenetics isn't an example of context dependent constraints with a vengeance.
I don't know what is so once you have all these context dependent constraints, acting inside a context independent possibility space set possibility space.
Then I think the possibility of complexity appears you don't have a possibility of complexity just with emergent, just with efficient causes.
These forms of constraints do. I also make a distinction between temporal and spatial constraints. I give two examples from from playground devices.
In the playground swing. The child learns very quickly that when they kick is as important as how strong they kick. And the timing of the kick does not impart more energy to the kick.
So that's an example of where Newton alone efficient causes alone won't work. Does that make sense. I mean you have to otherwise it won't kick.
So that's another example is another example of a spatial context dependent constraint, because depending on the length of that plank on the top and the plinth on the bottom the base on the bottom.
Then when where the child sits will be determined by those context dependent constraints in order for them to be able to do your daughter.
Another example that I like a lot which I know you know Dave Snowden and he likes to use a lot.
I think I used it first but that's okay is is the roundabout the the traffic circles. Right. The architecture of the roundabout is a context dependent constraint that affects the behavior of pedestrians and drivers in a system.
So that's another example of a context. I think sequencing is a beautiful example of temporal constraints. A has to be done before B which has to be done before C which has to be done before E and it's done in a different order.
The order of the make a huge difference in the outcome.
So all of these I consider context sensitive constraints. I lump a lot of those into enabling constraints because I think of enabling constraints as particularly those context dependent constraints that together achieve closure such that this coherent whole emerges.
Interesting. And you also I think that was interesting about your your use of the word constraint is you use it very broadly. Yes, you include it. I mean for instance one of my mentors in the complexity space was Harold Morowitz.
Oh, sure. He was here nearby at George Mason for a long time. Yeah, I used to live out in Loudoun County and see him quite once a week.
He has this idea that you know the 27 emergencies or whatever it is and then each one is defined by a set of pruning rules which you know tilt things one way or the other and that those faith those changes are fundamental inflection points in the evolution of the universe and some of them may have been
some of them probably are contingent and some of them aren't and the ones that aren't maybe maybe correspond to your non contextual constraints. For instance, one of his steps is defined by the poly exclusion principle for instance.
Absolutely. I mentioned that in the second book. I think notions of symmetry and conservation prints. You know, it's funny. Physicists all use word causality and so on and use half of the time they're talking about Newtonian cause then when they figure it can't fit and all of a sudden they move to principles.
Right. To to consider that sort of thing and I absolutely agree. I think rules regulations are examples of constraints.
They set the possibility space and they determine what is more likely within it than otherwise.
And I did like the point and this is Harold makes the same point that especially higher up in the stack. We're talking more probabilities than we are blacks and whites.
Absolutely. And perhaps what I speculate on in this new book is that whenever you have the emergence of a coherent dynamic, you have a phase transition to a continuous function.
If you have that if I'm right on that, then it seems to me that top down control is analog. It's a it's a change in the setting of the system to an analog notion so you're going from your old fashioned toggle switch to a dimmer switch.
And that's why homeostasis can keep the timeliness because that's very important for homeostasis in most ecosystems and it also can keep the sensitivity to local conditions.
I think only analog them do that. I the Dyson's have been were poo pooed a lot, but there's something that tells me that their emphasis on analog control somehow might be might be on to something.
I had to make it clear for the audience talk about Freeman and George.
All deceased now. Yeah.
Did George die recently about the last six months or a year.
I used to come by the Santa Fe Institute.
Freeman, I don't believe ever did at least I never met him there, but very interesting family also knew very interesting family also knew Esther Dyson who was George's brother who was a very, very extremely influential thinker in the early days of the computer industry and then later has become a
brilliant venture capitalist, particularly in the Eastern Eastern Europe.
That was her area.
I didn't know.
Yeah, quite amazing woman really.
Yeah, she really was really quite.
Okay, let's I haven't way later in my topic list, but let's talk about it now, which is analog versus digital.
I actually have a fair bit of background in this.
I had two of my companies back in my business career.
They weren't mine.
I was on the I was a chairman of one.
I was a investor and director or another were both involved in software for designing computer chips.
And in particular for designing analog computer chips.
And so I learned quite a bit about analog versus digital.
And for instance, I learned I probably should have known it that digital actually is analog below some level, right?
And then there's there's a whole series of clever things they do to go from analog to digital.
But then the other point, what you allude to is that on comparable computational tasks, analogs, literally six orders of magnitude more efficient.
That's it.
And that's not to be the reason why the brain doesn't overload.
Correct.
That has to be the reason why the brain.
So the brain is a good example of that.
Why the why the mind, why the mind when you transit, when you do the face transition to a mental event.
What you're doing is you're transitioning from neuronal electrical exchanges to control on the basis of some kind of typology, a facial recognition.
So now you're talking on the basis of how close is that pattern to this exemplar face.
Though, again, to keep in mind, the brain is a good example because the brain is both digital and analog.
Exactly.
Exactly.
Exactly.
Correct.
And it switches back and forth.
Yeah.
And so, you know, the domain of ideas or concepts or objects, you know, the, you know, the very important object ontology that at least mammals and above develop probably Burge to is continuously variable.
And it's not perfect.
It's classic analog classification.
And yet it's actually implemented on digital circuitry.
Correct.
Correct.
It's not digital, but the command top down is cut is analog.
That makes perfect sense to me.
Yeah.
Though I would also just add that the continuously variable while true of analog versus digital is maybe less important than people think is one of the principles of computation is you can simulate analog at any level of detail you want.
On the other hand, to simulate analog at extremely fine detail is very expensive computationally while you get it for free with analog.
So that's the, that's the cool thing about analog.
So that George Dyson used to use as an example, you know, even though the internet and all the computers that we use now are digital.
When you look at social media and that stuff, it's what's connected to what.
So we're back to the dance, right?
Yeah.
And that's the people who are analog, right?
And it's the dance of the people and the people in a sense are the condensated nodes of the intersections of all these constraints.
Right.
So that's what I argue in this new book that everybody's all bent out of shape about identity because they all think of identity of something internal essential.
The same thing as coach and and and Chalmers were concerned in, but we need to transition to identity as a set of interdependent constraints.
That's what makes me me.
Right.
I am a set of interdependent constraints and high dimensional.
Very high dimension.
The other thing that's so annoying about the stupid identity politics of both the left and the right is both sides want to condense down to just one or two dimensions.
And there's hundreds of dimensions, right?
You know, I'm a cat, you know, someone's a dog fancier who loves mountain laurel, but not Rotodendrons.
There's so many dimensions.
And I say that these two are the ultimate ones, just like just kind of dumb, right?
You know what did it for me that I finally decided I can finish that first book where was worked by Hinton, Jerry Hinton, who's now a big shot.
Clout and Chalmers and they were doing early work in artificial networks that read words.
It was one of the early text reading networks.
And they were working on simulating.
I had never heard it at the time.
Have you ever heard the difference between surface and deep dyslexia?
No, I was very interesting.
I thought that was in your book.
You gave a great example in your book.
Oh, God.
And I use it in a sense.
No, well, it was their example.
Okay.
It was their example.
They, you know, do you want me to repeat it here?
Sure.
I want you to tell the story.
It's very interesting.
I'll tell the story.
Surface dyslexia is what most dyslexic human beings have.
They transpose letters.
So they read caught for cat or they read tag for cat.
They just transpose letters or four gets read as a seven, that kind of thing.
There was the point being, there's no semantics involved.
It's purely the appearance of the input.
Okay.
Apparently deep dyslexia is very different.
Now what I'll give you the example first.
What Hinton Plout and Chalice, and the reason I plunked them all together is because Hinton
and Plout would write Hinton and Chalice Plout and Chalice.
So there's zillions of papers that came out about 25 years ago about this.
And they trained these early reading neural networks.
And when they had, when they train them with feedback loops, so they were current, recurrent
networks, and they lesioned the networks above the feedback loops.
The network would be shown cat and it would say tack.
So it would do surface dyslexia.
It would produce surface dyslexia kind of errors.
But then if they lesioned the artificial neural network below the feedback loops, they might
show the network again.
These are, these are silicone networks.
They're not organic.
They would show them B, A, N, D band.
And the thing output would say it had read orchestra or they would show it B, E, D.
And the thing would say it had read cut.
That is.
And so somebody, not me, asked one of them, Hinton, Blauser, Chalice, how do you explain this?
And their answer was the only way I can explain this is to postulate that the system, because of the
middle layers that we don't quite know what's going on.
And that has got to be what's going on with Chalice BD, by the way.
The middle layer has created semantic attractors, period.
Case closed.
And the output is just showing from the semantic attractor.
That makes perfect sense.
But there's your emergent property being causally powerful.
Interesting.
By the way, for all my computer people who listen, and there's a lot, the GE Hinton she's talking about is the
Jeffrey Hinton.
He's the Jerry Hinton.
I want, I shouldn't say this on, on the air, but I will.
I said to John Sterle at one of these NEH meetings, John, I think Hinton's work is so very good.
I don't understand why everybody's so interested in Hinton.
I thought, he's very good.
Trust me, he's very good.
It is, it is the Jerry Hinton.
Right.
He's the guy that broke through the breakthroughs that drove all the stuff that we're doing today.
Absolutely.
And everybody was paying attention to these reading networks a long time ago, or at least not as many people should have been.
Yeah, I was actually doing neural nets back in 2001, 2002.
In fact, that's how I got invited out to the Santa Fe Institute.
It was my work on evolutionary neural nets.
Well, my book was published by MIT 1999, and this has been published before.
So I think that stuff was published in 1995, 1998, thereabouts.
Yep, that was.
They did it for me.
I thought, now I can write this book because I have some kind of evidence that the semantic attractor in the brain, in a culture, whatever you want to call it, has causal effects.
Now, when I was reading the book, I write a lot of notes I always do.
One I wanted to ask you about, because how does it fit into your concept of constraints?
It certainly is one of Harold's pruning rules.
And that's the idea of the species competitive exclusion principle.
And which actually, my core field is evolutionary computing.
And so I understand a lot of how speciation works from a mathematical perspective.
And it's more or less a thing that is just true, right?
If a competitive dynamic has these attributes, there will be, and a fitness landscape has a certain shape, there will be competitive exclusion principle around species.
Does that fit into your idea of constraint?
Well, if what I speculate about there existing a constraint regime, correct, then that is the constraint regime for that possibility space, right?
Yeah, it basically says that if anything is competitive, if you get too far away from the center of what's efficient in that part of the fitness landscape,
inevitably you'll be less, not inevitably, most of the time you will be, you know, less fit than the ones right at the near the peak.
And therefore your numbers will go down.
So it's very hard to move away from the peak of the species definition.
The phenotypical collection, of course, as you point out, they're not all the same.
They're an ensemble, but they nonetheless cluster around a species type.
Correct.
Correct.
I don't know if this is an attempt to answer your question or attempt to evade it.
I'm not sure.
Tim Allen, T.H. Allen and Starr who have that book, they've got two editions of it.
I like the first one, the first edition better called Hierarchy Theory.
And they use as an example prairie grassland ecosystems in the Midwest, where apparently the prairie grassland competes against flowering plants.
It also competes of obviously against forbs, horses that eat the grasses.
Correct.
Apparently, if you look at the, if you look at that whole ecosystem, and you look at it from the point of view of the grass.
Right.
Competition with the flowers is a lot harder than competition with the horses.
Apparently, flowers will really do a number of flowering plants.
I don't know.
Dicotillodons or whatever the other things are called.
All right.
So over history, over a period of time, the prairie grasses send out have sent out.
And of course, this is all selection.
I'm not at all disputing, obviously.
They are winning.
They have sent out Mary stems, Mary stems or these shoots right below the surface, but that stick out enough that the horses can eat them.
And so in a sense, Jim, they, the grass invites the horse to come in to feed and incorporates it into what is now an enlarged ecosystem.
So instead of having two competing species, what you having is the enlargement of the niche or the constraint regime.
And Tim Allen says it's kind of like a Shanghai where was a predator and to incorporate it into a an enlarged constraint regime.
Now the, now the horse is part of the grasslands ecosystem.
And that's how they keep the flowers at bay.
I think that way of looking at it as a dynamical, mutual adjustment system is an awful lot better than two species competing.
Yeah, two species are competing, but this other stuff.
And then I get from the fact that I didn't realize until fairly recently that the understanding of the term fit during Darwin's era meant more like you go to a tailor to get a fitting for a new suit of clothes.
So when you think of fit in that sense, it's what is it?
It's a mutual adjustment, correct?
Which means that when I talk about constraint, the form of bottom up and top down relationships has to be one of mutual constraint adjustment.
That's what it basically is. You're adjusting all the constraints to see how you can best satisfy the overarching dynamic.
Yeah, then to your example of the grasses and the horses, etc. It's always in a co-evolutionary context.
Exactly. And that's your idea of context, right?
It's temporal too. It's temporal too. You've got to include temporality. Absolutely.
All right, so let's move on here. That was good, actually.
In the interest of time, I'm going to skip over the COVID example and let's talk more about time temporal constraints.
I think you did a really nice job of talking about cardinality, ordinality, and indexiality.
Inexicality.
Inexicality, okay. I want you to distinguish those, particularly the distinguished cardinality from ordinality.
Well, cardinality is just a mount, correct?
So a pile of sand has a cardinality.
A pile of sand is bigger or smaller, correct.
Ordinality is first, second, third.
I don't see where you can get first, second, thirds much out of Newtonian mechanics.
Whereas once you have temporal constraints instituted, this has to occur and this sets the stage for then the next thing to occur.
Once that sets the stage for the third thing to occur, then you have ordinality, which is first, second, third, orders, right?
Indexicality takes it a bit further.
It's like perspective or the position you are in in a complex dynamical structure means there are certain properties that are indexical.
This is to the left of this. This is to the right of this.
That's what I mean by indexicality.
It really has wreaked havoc in philosophy of mind because intentional causation again is eminently indexical.
So one example I use in this new book is that philosophers use all the time.
Mary told John's wife that he was cheating on her, but Mary doesn't know that John's wife's name is Alice.
So did Mary tell John's wife that it was Alice?
You see what I mean? It has to be interpreted, I think, in terms of the emergent dynamics and emergent properties.
So it has to be treated in terms of indexicals, inside and out.
So I think once you have emergent constraints in place, that's what, and I wish there were a verb that makes...
How could you make a verb out of the word rugged?
Ruggedify.
It ruggedifies the possibility space, right?
And each one of those valleys and attractor basins or attractor separate tricks is right.
They are the ruggedness of a possibility space.
And that explains why the view from inside an attractor looks real different from the view from the hill overlooking the next basin of attractor, correct?
And when we talk about causality, we have to take that kind of indexicality into account.
Yeah, then with respect to ordinality, many things are inherently ordered.
In fact, I just published last night a very interesting podcast, Currents Number 100, with Sarah Walker and Lee Cronin.
Ooh, I've got a note to her. Sarah and Mary Walker. Her stuff's really interesting.
Yeah, and on time, it's an object.
And their hypothesis is that evolution and other expanding complexity is essentially a series of steps that get taken, right?
They point out that the most complex chemicals created by abiotic processes never have more than 13 or 14 steps.
But abiotic processes can go much higher than that, and then man-made processes can go a bit further than that.
And so I thought it was a very interesting juxtaposition with your idea of ordinality.
One of the examples you gave was the social evolution of the processing of cassava.
I believe it was in South America.
That's from Heinrich's book on the secrets to our success or something.
Heinrich is what, head of sociology or something at Harvard.
It's apparently something that's poisonous, but yet nutritious if it weren't poisonous.
The indigenous community in South America has figured out a way of leaching out that poison, but the preparation for that root vegetable has to be done in a particular sequence,
because if you don't, you're going to kill out the entire population.
Going back to Sarah Walker, somebody told me day before yesterday that apparently there's something I'm not on Twitter,
which I probably should be neither on Twitter nor on Facebook.
Somebody told me that somebody wrote a Twitter comment saying that Sarah Walker's driving forces are my constraints,
which is flattering, I think, for me.
She's very good.
She's very good.
And Lee too, the two of them were one of the better science, hard science episodes I've had in a while.
Lee probably is very good. Yeah, I like his stuff.
Interesting.
Okay.
Now you mentioned, why not hit on these, because they're classic rich examples.
Kaufman's Buttons, Huygens Pendulums, and Benard Cells.
Benard Cells.
And paint those in with your ideas around.
Well, the Benard Cells was the source of all my interest in complexity theory.
It was the early 1980s, Jim.
Could you tell us, folks, what it is, not everybody knows.
Okay, a Benard Cells is you take a pan of water.
They're called Ray Lee Benard Cells, and they were discovered at the beginning of the 20th century by Ray Lee and Benard.
Take a pan of water, any kind of viscous fluid, and you heated the uniformity from below.
All right, you still have conduction.
After a certain gradient, after a certain threshold of instability, that's my context independent constraint, Jim.
After you pass a threshold of that gradient, the system cannot handle any kind of fluctuation, and the context will amplify any minor bubble or perturbation.
And all of a sudden, you will get convection cells, those rolling hexagonal cells made of billions of molecules of water that all align in a self-organized way.
And that the cell itself constraints top down the individual molecules of water cell they behave as if they knew what was the one next to them was doing.
All right.
So, it was the 1980s, and I had to go to jury duty here in Montgomery County, and so I took a bag full of stuff that I had to read, and I figured, and I was reading,
Kant's critique of practical reason.
Kant's critique of practical reason says the problem with T, and by the way, at the time that Kant wrote, teleology was synonymous with self-organization.
Go figure, 1804.
Kant said, in order to understand this kind of phenomena, he said, we need an understanding of circular causality that is unknown to us.
Because remember, Kant had bought the Newtonian-Humian collade that was all effective, efficient causality.
So, he said, but look at how nature works.
A tree produces the leaves and then is produced in turn by the leaves.
So, the whole tree is produced by the component parts and in turn loops back down and produces the components that created in the first place.
And so, I'm reading this, going all right, yeah, but how do we fit this into modern science?
And then the Prigogene and Stenger's order out of chaos had just come out of print, come in print, and he's looking at dissipated structures which all have that process.
You get individually constrained interactions that after a threshold of instability,
cross a phase transition and self-organize to produce a whole which then loops back down and constrains the component parts.
So, that to me was, whoa, I found a scientifically respectable way of explaining teleology and formal cause.
That's what did it for me in the 80s.
You were at the right place and right time because Prigogene certainly-
Well, and just seeing again, not having to publish so that you-
Go where you want to go, right?
Decimal point of whatever you already exist allowed me to be a dilettante and play around with ideas just because they were interesting.
And one of the things that Prigogene predicts is that these, especially these abiotic complex systems will actually be more efficient at burning energy than their predecessors.
And that's the Bernard cells for sure.
They actually move more heat through by convection.
And one of my favorites is the whirlpool in the toilet actually allows the water to go down faster.
So it actually is dissipating the potential energy of the water in the tank more quickly than if it didn't form the whirlpool.
You know what I used in class when I taught courses about mines, rains, and machines?
I actually taught a seminar on mines, rains, and machines at PG.
But I take the two, you know, the standard two large gallons.
Oh, yeah.
Put them together.
And then watch the tornadoes.
And the students would, ooh.
Yeah, we made one of those for my daughter when she was like a middle school student.
Yeah, that was a cool thing.
It's pretty cool.
They can really appreciate it intuitively.
Yeah, so the idea of Prigogene and the idea of dissipative systems, even though they have more structure and more interesting things going on, are also, generally speaking, more efficient at burning energy.
And so the good old second law never actually gets violated.
It's just in a different form.
So this, then, you've set me up perfectly.
But thermal equilibrium gets retarded a bit because you have a structure that gets created in the process that persists a bit longer than the component parts.
But that's the explanation for social systems.
That's an explanation for its cities, right?
Cities are more energy efficient than they were organized, right?
Though they burn a lot at per unit square foot, they burn a lot, but per person, they're less, which actually now it sets up to my next time.
You're not going to fool the second law.
No, exactly.
That's the one law.
If anyone ever comes to you and tells you they beat the second law, tell them to go pound sad, right?
And so now we get to where it gets more interesting.
And this, of course, is the secret of life is catalyst loops, autocatalytic networks, et cetera.
This is where we go from whirlpools, which have a self-forming part, but they're not fully closed loops, right?
Well, I really liked a book that came out about seven years ago by two...
Well, a lot of them worked out of the University of the Basque country in Spain.
And the good thing about those folks is they published in English, otherwise they would go into black hole.
But they published in there.
Unfortunately, this book is Springer, and Springer's so damn expensive, nobody buys the book.
But I think they're very good.
And the book is called Biological Autonomy.
And their argument is that, well, things like the Krebs cycle and so on, these are closures of process.
But once you start having autocatalytic and hypercycles, a la eigen and so on, what do you have that...
The constraint loop that closes is a loop of constraints themselves.
And so the constraints create the constraining conditions that make them possible to begin with.
And that is what enables their self-reinforcing, but their self-perpetuating.
And so these Matteo Moreno and Mocio argue that is what makes living things different from, say, even the BZ reaction,
where the boundary conditions, the constraints are, in a sense, self-set from without.
You set the conditions of the pan of water or the chemicals.
But once you get a situation where the constraints themselves become self-perpetuating,
then you have the possibility of reproduction of species and that sort of thing.
Now, you didn't really hit on it as hard as I thought you might.
But the perfect example of that is that the autocatalytic reactions within a cell are also responsible
for building and maintaining the membrane that allows the concentration.
And that's hugely important to my mind.
Absolutely, absolutely.
I think that's what they mean because, from memory, we've always thought of it as boundary conditions.
And that was my beef with Polani, because Polani says, Polani was ultimately religious.
And so Michael Polani, the philosopher at the beginning of the 20th century, I guess it was,
he believed that God sets the original boundary conditions.
And then once you've got that, then everything else self-organizes within it.
But the whole point of, I think, the closure of constraints is that it creates the boundary conditions
within which it self-organizes as well.
So yes, you're absolutely right.
Yeah, I think that's hugely important.
And of course, as we've learned, the nature of these membranes changed over time,
and it's continually changing.
And the fact that they're semi-permeable with different rules for what goes from the inside out
and what comes from the outside in are hugely important to maintain the reactions that are going inside.
I think we finally understood that because of the role of interfaces in computers.
Yeah, I think that helps.
And what, therefore, what that also means, I think, is once you have a phase transition to a new dynamic,
you have a new code.
And a new code means simply the settings and the rules that govern that membrane,
that boundary conditions, what it allows in and what it produces as waste and as action.
Absolutely.
And then the other interesting example you gave, which I had thought of before,
is you talked about the architecture of the circulatory system as another...
That's more anointing, which is a really nice example,
because the vasculature of the body, the lymph node and the blood circulating system,
really prevents the seeping out, right?
But it is not an energetic force.
That's what the heart does.
But the vasculature is more like the timing of the playground swing in that it controls the settings.
You know what?
After I submitted this MIT, which was, geez, it was almost a year and a half, two years ago,
but it took so long.
I am fascinated recently by the inflammatory system and the immune system connection,
because they are now talking about three levels.
They're talking about structure, function, and then regulation.
And that, you know, if my arm gets cut off,
then the inflammation hits it immediately to try to repair the wound.
All right?
If all of a sudden the interactions in the body are out of kilter,
then the function of homeostasis may not work as well.
That you get diabetes and so on and so forth.
But the idea recently is that perhaps there is a third level,
which is the setting of the functional system.
I'll call it the set points or the settings,
and that perhaps things like PTSD, chronic inflammatory disease syndrome,
that kind of thing is that on and off switch, for example,
the dimmer switch, the analog is screwy.
So it's the set point, it's the regulatory control of that function.
That's often that maybe that's the way to attack PTSD, for example.
There's nothing wrong with the function of PTSD.
We're supposed to freak out if we think someone's attacking us at night.
What's wrong is the fact that we are now reacting in a different context
the way it should have been before.
Then that means there's something wrong with the toggle switch.
There's nothing wrong with the switch, which I find really interesting,
because I think that has a lot to say with two for social systems.
It has a lot to say, not just for the inflammatory system.
Perhaps all of complex dynamical systems have those three layers,
structure, function, and then regulation.
And then, of course, the question is, how do these three levels interact?
And they do not interact by efficient causes, they interact by constraints.
That everybody who's done hierarchy theory in biology is comfortable with that.
Okay, let's move on to another topic here, which is that you described them as constraints,
though I would not normally think of them that way, but I think in your lens they work.
And that's the idea of scaffolds and scaffolding of affordances, etc.
Talk about your thoughts on scaffolding and how you can use the language of constraints around that.
I think you have the old-fashioned architectural scaffolds that are external artifacts
that are temporary and that guide the construction of new buildings, correct?
But if you think of constraints, of context-sensitive constraints as conditions and factors
that take a system away from independence, they link things together.
What scaffolds do, and I love the work of Bishop and especially the word of WimSat,
they've done work on scaffolding long before they got fashionable recently.
They provide a temporary equilibrium point from which to take the next step,
and it's not only, it's like a ratchet.
I think of scaffolds almost like ratchets.
They provide a temporary, metastable position from which the next step,
whose direction the scaffold itself also suggests, can be more easily taken.
But that chapter you're thinking about from the new book,
there's so many other different types of constraints, of that kind of constraints.
There's entrenchment.
That's a hell of a constraint that we use a lot, especially in social systems, correct?
To retard any innovation or buffers.
I think probably the difference between a buffer and an entrenchment might be how long it lasts, right?
But it's a way to control the relationships between the inside and the outside,
and the next step, that's why I think of it as a form of constraint.
Because the scaffold, again, is not, my bent noir is always efficient cause.
I'm always thinking, well, this is something that has effects, but it's not as an efficient cause.
So I have buffers, I have entrenchment, I have scaffolding.
I have that kind of process that we use a lot.
And now you could throw those in with catalysts.
Absolutely.
And certainly, let's say scaffolds and catalysts both have the effect,
while they don't necessarily provide energy themselves,
they lower the activation energy for something to occur.
Correct, correct.
And even those scaffolds that are not temporary like the flying buttresses of Gothic cathedrals
that end up being part of the structure,
and that is also true of these lattices.
They implant that are embedded with nutrients that promote bone growth, right?
The point being that the location and the direction of the holes in that lattice are what pattern the bone growth.
But then they end up getting absorbed and becoming part of the bone itself.
So these are all forms of affecting consequences that are not, or that are in addition to.
I don't want to discount efficient causes, obviously.
I just don't believe they're the full story.
And this, in some sense, the basic laws of physics continue to be true,
but there's much more interesting structure being built that's in addition.
And that's what the naive reductionism misses.
Correct.
And now, go ahead.
I'm sorry.
I interrupt.
I'm Cuban.
I'm sorry.
You talk with your hands.
That's right.
That's right.
And that's, again, I think that it's kind of this myopia of over-reductionism.
Nothing wrong with reductionism.
No, no, there's nothing wrong with that.
You need to know both the dance and the dancer.
But there's a sense that somehow the relational and the dynamical are not real.
Every bit is real as the primary properties.
And that's my problem with myriology and nothing but is so on.
The problem that everybody complained about top-down causation is not possible
is because it would violate physical closure and it would violate the conservation of energy.
Sure, if you think of it as efficient causes, of course, it's going to do those two things.
But if it operates as constraining dynamics, you're not violating physical closure
or constraint or conservation.
So that's why it works very nicely.
It's not violating any basic physics tenets.
Why don't you do a little riff on that?
Because that is one of the questions in complexity.
And it befuddles the laymen in particular.
What?
Top-down causality.
And how you can have top-down causality and no magic needs occur.
Well, in the very same way that homoestasis changes my glucose production
or how does a culture affect me?
That is top-down causality.
That is causality from the hole in which I am embedded.
If I were not part of that culture, it would not affect me.
Correct?
Right.
And that means that the constraint dynamic of the culture in which I am embedded
be the college at which I taught, the society in which I live, the family to which I belong,
the constraint structure of each of those organizations
changes the likelihood of different behaviors that might otherwise have been open to me that are not.
In the very same way that once entrained into a Benard cell, the molecule of water
has different probabilities of where it is going to go
because the constraint structure of the Benard cell affects it.
And that is what I mean by top-down causation.
So there is nothing magical about it, but it is not efficient causality.
If you think of it as efficient causality, then of course it is magical.
Gotcha.
And there has been many, many pointless conversation on this as you no doubt have experienced it.
Absolutely.
Well, my centuries of this going on.
Indeed.
Let's move on.
We are getting kind of late on time here.
We have got about another 13 minutes.
And this was something new to me.
Very interesting to always run across something new.
And that is the idea of many to one transitions.
Maybe you can dig into this in some depth.
Okay.
And that was, all right, when at the beginning, once behaviorism got put to bed,
then functionalism came into play or the identity theory.
So the idea was that mind is to brain as a computer software is to its hardware.
So then people said, all right, just like a lot of different,
Microsoft Office can be run on different, on Apple and the different hardware devices,
that's the explanation that gives some legitimacy to the notion of a mind.
These are the notion of the brain.
The brain is the hardware, the mind is the software fight.
But there was also always the idea that the notion of supervenience and Donald Davidson's
term is there will be no change in the supervenient properties without any corresponding changes
in the subvening in the hardware.
So there was always implicit in the notion of supervenience, a one to one relationship.
And the reason I think that was true was because I don't think they ever got away from the
physicals out.
So there was always that one to one relationship.
So the idea was, all right, so a mental event, my thinking of my grandmother,
my pain in my leg will always be correlated one to one with this particular neuro pattern
in the brain, which indicates pain in my leg.
This one about indicates that's my, my grandmother.
But very quickly, multiple realizability, many to one relationships, all sudden came about.
And that was that, well, though, and behold, if this part of the brain is excised,
the hearing function might be taken over by the other part of the brain.
Another part of the brain that was supposedly not at all dedicated to hearing, but all of
a sudden it was.
So the notion, and I almost wanted to name this title, this new book, Imprasive Degeneracy.
Don't get so, don't get cutesy here, because biologists have always been very comfortable
with degeneracy.
That is, there are many ways for the same amino acids to produce different amino acids to produce
the same protein.
That's what I mean by many to one, many different lower level paths to realize the same emergent
property.
That's what I mean by many to one.
And that seems to be true in general for the higher level properties of complex dynamical
systems.
An economy can stay itself despite many different varieties or many different configurations,
as long as that overarching constraint structure remains within a certain range.
Does that, have I made sense here?
Yes, ish.
Let me drill it a little further.
All right.
You also talk about many to one, because, you know, we do have multiple realizable domains,
and the idea of degeneracy is very important.
And for the audience, degeneracy basically means that things with different forms can
have the same function, right?
Correct.
Different lower levels, same higher levels.
Same higher level.
And there's a bunch of famous examples in biochemistry where it's more famous, but you also talked
about many to one as something analogous to dimensional reduction in systems.
And think about the fact that, you know, with the example I gave before, Jim gets up out
of his chair and goes down the hill to the ice cream store.
There's lots and lots and lots of predicate signals that probably led to that, right?
And they eventually got concentrated down to a single decision.
Should I get up, go down the hill, get an ice cream cone, or should I go to the refrigerator,
freezer and pull out a frozen yogurt bar, right?
And the fact that there's many, many, many inputs, but there's a single decision around
the affordance was also the way you described many to one.
The reverse of it is pluripotentiality, which is one lower level that has the potential
for becoming much more different functionality.
And of course, stem cells are the example of that, right?
They are pluripotents.
They are not totipotents, which people thought might, they might be for a while,
that they could become any other.
They're not quite their totipotentiality.
But that was the problem with supervenience.
Because then the question was, how can the same neural processes in the brain produce
such very different, differently property functions, higher level properties?
And Davidson said, if you can't identify a causal relationship between the two,
then you might as well go back to behaviorism.
And at that point, J-Wan Kim at Brown, who had been a big advocate of supervenience at the time,
decided supervenience won't work.
It either is one to one or it's not.
And that's why he titled that.
Was it a paper or was it a book called Descartes' Revenge?
Because then again, the problem was, how do you get top down causality in that once you decide to go to the fridge, Jim,
you could decide to walk directly to the fridge.
You could decide to go outside because somebody is going to watch you take something from the fridge
and you go outside, you go all the way around.
So there are a lot of different ways to implement that top down decision, correct?
And the problem with again, efficient causality is that it only worked for instantaneous relationships.
Efficient causality cannot handle what used to be called in philosophy standing causes.
In other words, I decided I'm going to write a book and it took me two damn years to do so.
So how on earth does that intention continue in force and continue exerting an influence all throughout those two years?
That's what I meant in that sense by multiple realizability top down.
Yeah, and then of course that goes back to the very classic Greek philosophical question of the ship of Theseus, right?
Our audience goes, okay, the supposed ship that Theseus took to Crete, I guess it was,
then it was preserved in Athenian harbor and then over the years, the boards rotted and they replaced one by one.
Eventually every plank on the ship had been replaced.
There was nothing original, but it was the same ship or was it, right?
Correct.
And we can say the same thing about organizations and cultures and societies and, you know.
And humans, you know, basically every one of our atoms gets replaced, what, every year or something like that?
Every seven years, every cells or whatever.
Exactly.
So I think I stick my neck out more than maybe I have a right to, but that's why I wanted to show in this new book that people say,
you're reducing everything to physics and chemistry.
No, I'm showing that there are, I never know the difference, homologous analogous constraint dynamics that operate all along the spiral.
It's not a, it's not a reduction.
It is to show that once you do the phase transition from physics to chemistry, then you've got new emergent properties, new codes, new everything.
Once you go there from, from chemistry to biology and so on down the line.
Got it.
Well, let's wrap up with the future of these fields.
And you talk a fair bit about the relatively new 4e approach to cognitive science, which I think is maybe getting closer to your way of thinking.
Yes.
I mean, I really like the work of the Paolo probably Andy Clark started the whole thing with the embodied mind idea.
And people like Merlin Donald, who I love his book, all of these folks started realizing the mind just ain't in the brain.
Because it takes me forever to write because I literally realize that I work out the ideas as I write.
Now I type, but it's not that I sit down thinking all through and then I just write it out, you know, because it's all been worked out in my mind.
Literally. So, so the notion that that that that our minds extend beyond the boundaries of our body to artifacts to tools.
For example, when you're driving, I'm the designated teach your grandchild to parallel park person because their parents are petrified.
Nobody else wants to do it.
I'm a good parallel parker.
You know, I say, look, after a while you realize that that you can almost feel the car as the extension, you know exactly where it's going to fit in a in a tight space.
So the idea that the mind ain't just in the brain, it's embodied.
But then it's also enacted because it's not just that it's embodied in my in the agent's body, but it's also the mind is enacted in their behavior within a particular context and so on.
What I what I try to do in this new book is then the question is, well, how does this holistic ecosystem within which this embodiment and enlightenment, how does that coherent dynamic come about.
And that's why I want to show that before you have a an enact.
I don't think that if you're not Japanese, a tatami mat affords sleeping.
I don't think a Victorian throne and that's seating to somebody who's never seen it before.
So to somebody who's used to sleeping on the ground, and I don't think it does it automatically.
It is part of a whole ecosystem, a whole coherent dynamic.
And my question is, how do those coherent dynamics come about.
And again, my answer seems to be I don't know what else to call constraints, all of these processes.
And accumulation of constraints over time and their channel.
But it's not just accumulation in that one at one damn thing after another.
It's how they into how they interweave with one another.
That's what creates this overarching interlocking set of constraints.
Yeah, and then and that that and those constraints are real.
See, I say from the beginning in the book, I'm never since can't ever.
Every time something gets bored, we all we all hide behind epistemology.
Oh, well, it's the way we make sense of things.
No dammit, I think that's the way reality works.
And you know, I don't need to I have to I have tenure.
I don't need to worry about pleasing somebody else.
I can say this if it's wrong, it's wrong, but that's okay.
Oh, right.
Well, I really want to thank Alicia Herrero and her new book, Context Changes Everything,
as you can tell by our conversation.
I learned some things, had some new ideas I've never been exposed to.
I thought it was really interesting.
And despite what she said, I thought it was damn well written.
So thank you, Alicia.
Thank you so much.
Audio production and editing by Andrew Blevins Productions.
Music by Tom Mueller at modernspacemusic.com
