Hello, and welcome to another episode of TwimbleTalk, the podcast where I interview interesting
people doing interesting things in machine learning and artificial intelligence.
I'm your host, Sam Charrington.
Just a couple of quick announcements today related to the Twimble Online Meetup.
First, the video from our December Meetup has been posted and it's now available on our YouTube
channel and at twimbleai.com slash meetup. It was a great meetup, so if you missed it,
you'll definitely want to check it out. But, you definitely don't want to miss our next meetup either.
On Tuesday, January 16th at 3 o'clock Pacific, we'll be joined by Microsoft
Research's Timnit Gebru, who will be presenting her paper Using Deep Learning and Google Street
View to estimate the demographic makeup of neighborhoods across the United States,
which has received national media attention for some of its findings. Timnit will be digging
into those results as well as the pipeline she used to identify 22 million cars and 50 million
Google Street View images. I'm anticipating a very lively discussion segment as well to kick
off the session, so make sure to bring your AI resolutions and predictions for 2018.
For links to the paper or to join the Meetup Group, visit twimbleai.com slash meetup.
Alright, on to today's show. In this episode, we hear from Kenneth Stanley,
professor in the Department of Computer Science at the University of Central Florida
and senior research scientist at Uber AI Labs. Kenneth studied under Twimble Talk number 47
guest Risto Mikulainen at UT Austin after Geometric Intelligence, the company he co-founded with
Gary Marcus and others, was acquired in late 2016. Kenneth's research focus is Neuroevolution,
which applies the idea of genetic algorithms to the challenge of evolving neural network
architectures. In this conversation, we discussed the Neuroevolution of Augmenting Topologies,
or NEET, paper that Kenneth authored along with Risto, which won the 2017 International Society
for Artificial Life's Award for Outstanding Paper of the Decade 2002-2012. We also cover some of the
extensions to that approach he's created since, including HyperNEET, which can efficiently evolve
very large neural networks with connectivity patterns that look more like those of the human
brain and that are generally much larger than what prior approaches to neural learning could
produce, as well as novelty search, an approach that, unlike most evolutionary algorithms, has no
defined objective, but rather simply searches for novel behaviors. We also cover concepts like
complexification and deception, biology versus computation, and some of his other work, including
his book and Nero, a video game complete with real-time Neuroevolution. This is a meaty nerd
alert interview that I think you'll really enjoy. And now, on to the show.
Alright everyone, I am on the line with Kenneth Stanley. Kenneth is a professor in the Department
of Computer Science at the University of Central Florida, as well as a senior research scientist
at Uber AI Labs. Kenneth, welcome to this week in Machine Learning and AI. Thanks very much.
Real happy to be here. Fantastic. Why don't we get started by having you tell us a little bit
about your background? Sure. I've been interested in artificial intelligence since I was a little
kid, maybe around eight years old. Went on to major in computer science because of that,
and carried that interest into graduate school, where I was at the University of Texas at Austin,
where I did my PhD. And there I became interested in particular in neural networks, artificial
neural networks, which are now the basis of deep learning, which everybody's talking about,
and also what's called evolutionary computation, which means kind of Darwinian type of principles
being applied inside of computer algorithms. And so the intersection of those two things
is what's called today neuroevolution, which means like evolving neural networks or like
evolving brains, you could think of it as in a computer. And I guess my particular interest
is just how brains evolved, you know, these amazing astronomically complex things that are in our
heads. I was always fascinated by how an unguided process, seemingly an intelligent process like
evolution could just produce something so astronomically complex and amazing as our own
brains. And so as a neuroevolution researcher, I've been trying to figure out how can you actually
make algorithms that would evolve something of similar scale and complexity. Was there anything
in particular that you came across at the age of eight or so that got you interested in AI?
Yeah, yeah. So at the age of eight, that's when my family bought a computer. It was like a Commodore
64. Yes. And it was also I, my parents put me in a programming class and that was on a TRS-80.
It was a very old computer system. Frash 80. Yeah, exactly. And I guess for some reason,
like as a little kid, it just really made an impression on me that I could tell the computer
to do anything. Like I had this feeling like there was like infinite freedom in the things that I
could get the computer to do. If only I could just figure out how to tell it what I wanted.
And I felt like if I could just tell it how to have a conversation with me, then it would basically
be my friend or like talk to me. And I was really, really interested in just getting the computer
to have a conversation with me, like a casual conversation, like how are you doing, what's
your name, that kind of thing. And at first I would write really simple programs in basic,
the basic computer language that would have like little conversations like this.
Like I'd say, what's your name? I'd say Ken, like basically in typing and they would say,
hi Ken. And I was very impressed that we could have this kind of conversation and that I got
it to do that. But I quickly hit a wall where I couldn't get it to like really do anything
interesting, you know, just a very stock scripted thing. And at the time, like around age eight,
I thought there's some way to do this that I just need to read a book or something like there's
something that would just tell me how to get it to have a real conversation with me. And I didn't
realize that this is like one of the greatest problems like facing humankind, like how to get
a computer actually be intelligent, like a real person. It took me a while actually for it to
strike me that this is actually like an extremely hard problem. And there's not just like some
manual you can read that can get the computer to do that. So probably within a couple of years,
I realized this, this is like a huge problem. And then I was really interested and hooked and like,
wow, this is actually hard. And like, there's got to be a way to do this. And I guess I would just
stay captivated by that problem, like forever. But I guess I changed the shifted a bit in my
interest. Because if you look at that, and you look at it from the lens of like today's subfields
of artificial intelligence, you probably call that natural language processing or something like that.
And I kind of shifted away from that over time to more like lower level stuff, like control,
like neural stuff. Okay, that was like what initially hooked me into it and got me interested in AI.
Interesting. And you mentioned that you studied at UT Austin,
I did an interview with with Risto, Michelin. And did you study with him there?
Yeah. So I guess it's just a coincidence that Risto is my advisor, was my advisor during the
PhD. So I worked with him for years there. Yeah. Awesome. Awesome. Can you tell me a little bit
about your primary research focus? Sure. So my primary research focus is in an area called
neuro evolution. And it's an area that is probably less well known in the general public,
like you hear tons of stuff about deep learning today, but you don't hear so much about neuro
evolution. It's certainly related to deep learning because both of them are about, in effect, neural
networks. But neuro evolution has this twist, which is that we're interested in neural networks,
which are, for those who don't know, basically, these rough abstractions of what happens in brains,
like, you know, the word neural comes from neurons and neurons are in our brain. So neural
networks are roughly motivated or inspired by brains in nature, although they're not at all
accurate models of them. But then in neuro evolution, we're combining that with evolutionary
principles, which really means kind of like breeding, like if you think about it, like it's
like if you had a neural network that does something good, like say drives a robot and makes it able
to do attacks, like say walk, like it gets your biped robot to walk, then like neuro evolution is
kind of like you're breeding those brains. You're saying, okay, I have a bunch of brains. These
are artificial brains. We'll call them neural networks though, because artificial brains exaggerates
like how cool they are. So say, dude, they're artificial neural networks. And we would then
look at like, well, how well do they get the robot to walk? Like a whole bunch of them,
and then call that a population. And then like, we choose the ones that do better,
some will do worse and some will do better. And the ones that do better will have children,
which basically means like new neural networks will be born as offspring of the old ones that
we chose, or we call that selection, we selected those. And our hope is that the offspring of
those better ones will sometimes be even better than their parents. And so if we keep on playing
this game, which is just breeding, so like it's not hard to understand, like some areas of AI are
kind of complex and hard to understand at first. But intuitively, this is easy, because
this is just like breeding horses or breeding dogs, just choose the ones that are better in
respect to whatever criteria you have, and then just breed them and hope that like things get
better over time. And so neurovolution is basically about breeding these artificial things rather
than real organisms, which are these artificial neural networks, and thereby getting them to
get better over generations. And what is interesting about it to me is that like, while it's like a
simple concept in principle, at least like the initial outline that I gave is quite simple,
just in terms of breeding, like under the hood, there's like real mysteries here,
because this is really the process, you know, that produced you and me and like the high level
of intelligence that we have going all the way back to singled cells organisms. And it's quite
amazing to believe that like, there is some kind of path through that space, just through breeding,
that can lead to something like us from something so humble and simple. And to get algorithms to do
that is an enormous challenge and not fully understood right now. And that's where kind of
the research comes in in the field. Interesting, interesting. And then you're also, again, a
senior research scientist at Uber AI labs. What can you tell us about Uber AI labs and how that came
about and what the charter is there? Right. So there was no Uber AI labs around nine months ago,
but I was one of the co founders of a startup company called Geometric Intelligence. My co
founders were included Gary Marcus, Zubin Garmani and Doug Bemis, some of them really quite well
known and very respected researchers themselves. And we were doing in Geometric Intelligence
proprietary machine learning research and developing new technologies and building a team that we were
hoping to be a world-class research team. And what happened was that Uber acquired us nine
months ago in December. And when Uber acquired us, they had partly one of their aspirations was to
start an AI lab, like a real research lab in industry that researchers the cutting edge of
artificial intelligence. Because Uber believes and believed at the time that artificial intelligence
is a critical competitive component of the industry where Uber needs to be staying at the cutting
edge. And Uber has and had before a lot of competence already in machine learning. So it's
not like there was nobody here. There were plenty of people here who were very qualified in the field,
but they didn't have something that was really a fundamental research lab where they're sort of
just really pushing on the cutting edge of AI itself as opposed to just applying it to internal
problems. Like for example, Uber has a team focused already that was focused on autonomous driving.
So they already had that in place, but that's an applied aspect of artificial intelligence.
And so the AI lab that was founded off of the company that we started, which we founded, was
really intended to be focused more on advancing the algorithms themselves. And so what Uber got was
basically all at once, like all of these researchers who had this capacity to push forward the field
of AI. And so you can kind of think about it roughly in analogy with similar types of research
labs at big tech companies, like maybe like something like DeepMind, which was originally
acquired by Google or something like Facebook AI research, or there's also Google Brain and Google.
So there's some rough analogy there between us and them. We're much smaller though,
because we're newer, but we have the kind of similar mandates in terms of researching the
cutting edge of AI. And I should say that actually we're going to, we are going to engage with the
outside world and the academic community. So you'll be hearing from Uber AI Labs,
we're going to be publishing. And we understand that like just we cannot be a successful AI lab
if we are not engaged with the outside world. So we will be publicizing and publishing some
of our work so people can see what we're doing and so that we can communicate with other researchers
and scientists across the world. Okay, great, great. Can you talk a little bit about the
intersection between your work in evolutionary AI and the kind of things that Uber's doing around
self-driving cars? Yeah, so I can't get into specifics about what Uber is doing with their
self-driving cars for an obvious reason, but I can say that that Uber AI Labs is diverse. I mean,
and that was one of the original inspirations behind geometric intelligence or the predecessor
of Uber AI Labs was to have a diverse group that isn't just in one particular fad, which you might
say deep learning is, although it's obviously an important one that's making a lot of important
contributions. But our philosophy was that, you know, we need to not have all our eggs in one basket.
And so Uber AI Labs itself is like that too, and that we have a lot of diversity in terms of the
expertise and areas that we cover. And so among those, we clearly are world class in
neuroevolution, which is the field that I just described where I've focused up most of my career.
And so this is a particular direction within AI and machine learning that offers some unique
insights and angles on certain types of problems that other areas might have a different take on. So
in terms of like autonomous driving, I mean, it's clear that the idea of the evolution of complexity
and how really high level intelligence can be evolved in terms of complex, large, deep artificial
neural networks has a connection in principle to how you could get a really sophisticated
controller for a vehicle or something like that. And so the insights of the field of neuroevolution
both directly, which means like using neuroevolution itself as an algorithm and indirectly in terms
of insights that we gain as a side effect of doing experiments in that area can impact
how we would create algorithms that might control things like autonomous vehicles. But I should
also note that it's not the case that the only application or even necessarily the main application
of AI at Uber is in that area. I mean, Uber has AI problems across the gamut of all of their
business components. So there's a lot of different applications that are under consideration when it
comes to like AI labs and what AI labs does. Sure. So can you talk a little bit about the,
about how your research focus kind of compares in contrast with what Risto is doing down at UT
Austin? Yeah, sure. So I mean, actually, there's a lot of overlap because I mean, I'm his advisee. So
I've taken a lot of the original teachings that he gave me as the basis of my career.
And obviously collaborated with him for years to publish some of the, in the end, it turned out
to be some of the seminal papers in the area, both together. And so, you know, I think we're not
actually so different in terms of like the fields that we're interested in, where we may differ is
more just in like what particular algorithms have we contributed to inventing since we parted ways
when I basically graduated with a PhD. And so, you know, he's focused on his own set of innovations,
and I've focused on my own, and there's some divergence there. But, you know, we really
ultimately tend to be very close because like when I've invented new things, like, and I'm still at
the University of Central Florida, as a professor, Risto would sometimes build on those things and
vice versa. So we're very intertwined and it's not a surprise since we started out in the same area.
Absolutely. Absolutely. And so folks that are interested in maybe some of the background on,
you know, you talked about the kind of breeding process that are really high level,
Risto and I spent quite a bit of time digging into that in more detail. You know, so folks
that are interested in that might want to refer back to that podcast since you've graduated and
now that you're kind of driving your own research agenda, like, what are some of the specific
algorithms that you've published research on and, you know, how do they build on kind of that the
core ideas of, you know, genetic or evolutionary computing or algorithms? Yeah, sure. So, so in
neuroevolution, which is this idea of evolving neural networks, like one of the interesting
things is that when what we're, at least for me, what I find really interesting is not just
optimization, like a lot of people in machine learning think in terms of optimization, which
means just like, how do you get this, this structure to get better and better and better
with respect to a task? But I'm also interested in what you might call complexification, which
means like, how do we get increasing complexity? Like the thing that really fascinates me is
like how in nature things got more complex, like insanely more complex, not just like a little bit
of incremental increases in complexity, but like from a single celled organism to something that has
in our brain 100 trillion connections among 100 billion cells approximately or 100 billion neurons.
And that's just amazing to me that like some kind of unguided process could build something like that.
This is not something that was engineered. And so I'm sort of always have my eye on like,
what is it that allows really high level astronomical levels of complexity to emerge
from this kind of process, kind of automated process. And so the interesting thing in neural
evolution is that every time it seems like we have an advance where we kind of figure out
something about how do you get increasing complexity to happen inside of an algorithm?
And we've made some advances, including the first thing that I did in grad school, which was
this algorithm called NEET, or Neuroevolution of Augmented Apologies, which I did with Risto,
which was basically an algorithm about how can we have the neural networks that are evolving
in the computer increasing complexity over the course of the algorithm running in the computer.
And it was because I had this real fascination with increasing complexity
that it led to us introducing this algorithm that increases complexity.
But then what's interesting is that every time we make an advance like that,
it sort of uncovers some like deeper underlying question, because it turns out that like the
explanation for why it was possible to get from one cell to trillions is really,
really subtle and nuanced and complicated. And when you say that, are you speaking biologically or
from a computational context? Right. Good question. Yeah. So actually,
those things constantly get intertwined in my mind, like whether I'm thinking biologically
or computationally, because you know, the way I look at it is kind of like that biology and
computation aren't really necessarily different things. Like in effect, like if you read a biology
textbook, you know, you feel like you're reading about biology. But in effect, it's also about
computers because, or at least algorithms, you know, because you're talking about a
principled process that basically follows some, some certain kinds of rules. And so like analog
computers that we really don't understand very well. Yeah, you could think of like the universe
as a big analog computer, we don't really understand. And so like, I mean, but like evolution is a
very algorithmic thing, you know, you're talking about, there are individuals and those individuals
reproduce. And then the thing that, and who gets to reproduce is based on a formula, which is,
which is obviously complicated, but basically some, some individuals reproduce, some some don't.
And this can be formalized as basically like a program, you could imagine writing the rules
of the system. And this is what inspired the field of evolutionary computation. I mean,
people saw the theories of evolution and biology and thought like, you know what, this is actually
not that hard to write down as a program and actually make evolution happen artificially
inside of a computer. And it turned out though that like if you just read a textbook and then,
you know, learn these principles that sound like good explanatory principles for like how
evolution worked, like if you read a biology text was like, well, they know how it worked.
That's an explanation. It turns out that explaining something is easier than actually
implementing it, which is basically something that we found across the field of artificial
intelligence. You know, you can read about, you can read a neuroscience textbook and say,
this is how brains work. Of course, biologists will acknowledge we don't know everything, but,
but this is what we understand now. And it's a very comprehensive explanation. But it's far,
far away from like telling you how to actually build a brain. So you don't know how to build a
brain just because we have some understanding of how brains work. It's the same with evolution,
like we don't know how to build a true evolutionary system at the scale and magnitude of what happens
on earth, even though we know a lot of the details about what goes on. And the missing details,
like the gap between what we understand and what we can actually build, that's where the
research is. And that's where like a lot of fascinating insights occur. And like to me,
I think that to some extent, like when we make advances in artificial intelligence,
we're actually learning something about biology in a sense, because we're realizing that there are,
that the gaps in our knowledge, like what we didn't understand, are actually filled by something that
we didn't expect, or that wasn't in the textbook about how things work. And it's true that sometimes
we may be doing things that are not actually the same as biology, but at least they're revealing
gaps in our knowledge of biology. Because like if, in some sense, if we actually knew everything
about how things work, then we could just program it in, but we clearly don't. And so it's kind of
like, I think AI has like a higher bar in a way than biology, where in biology, like you can explain
something or statistically analyze it, but in AI, you actually actually have to build it, which is
much, much harder. So it sort of forces us to grapple with the problems of the gaps in our
knowledge and biology. Now, some people in AI would just sort of like say, not like that way
of looking at things, because some people in AI don't care about the biology, and they just want
to build intelligent things, and they don't really care, do these things correspond or not with
biology, like that's not the goal. The goal is just to build intelligent things. We aren't like
adherent to biology or not. I tend to be more biologically inspired, but I also agree that like
I don't really ultimately care whether what I build is exactly the way it works in biology or not,
but I just find it interesting and inspiring that biology has achieved things that are just so amazing.
I mean, like human level intelligence, and I find it fascinating that we just don't know how. And
like trying to probe those gaps in my understanding, I find leads to over and over again, really deep
insights in artificial intelligence, because it's like we suddenly realize, oh wait a second,
actually there's an explanation here, which is much different than what we thought it might be.
And so after graduate school, like there was a succession of those that I went through,
we would realize that, you know, there's something missing still after like, for example, the need
algorithm, which actually became the most used algorithm in this sort of niche field of neuro
evolution, but we realized, you know, there's limitations on what need can ever do. And so
then it's like, well, how can we get around those limitations? How did nature get around
those limitations? So like one example is that like, in need, there's this artificial DNA,
which encodes the neural network. So we have to do evolution. So we have like an artificial DNA,
which we call a genome. Well, it would have one gene per connection in this brain that's evolving.
And like, this is clearly not going to scale, even though like this, this brain can keep expanding.
But like, if you wanted to get 100 trillion connections, which is what we have in our brain
right now in biology, we would need 100 trillion genes in need. And there is no way that's ever
going to happen. 100 trillion genes is just astronomically insanely large. And like, for
example, our genome in biology only has 30,000 genes or 3 billion base pairs is another way
of thinking about it. So we had to invent new algorithms. And this is after after grad school
and after need that could encode much, much larger structures called these indirect encodings.
And this led to something called hyperneed event eventually, which is a new kind of genetic encoding
that is much more compact than the original need. And so hyperneed was something that I did
after I left UT Austin. And so we're where I did that independently of Risto and led to the
ability to evolve much bigger in effect neural networks. And then I think one of the biggest
things probably that that has had a lot of impact in the field after that was something called novelty
search, which is a result of discovering that in some cases, the best way to get something
in a search process and evolution is a kind of a search process, like you're searching through a
space of possibilities is to not be trying to get it. And this was a really counterintuitive
and paradoxical insight, but really important, I think, for realizing how things are achieved.
So in other words, if you say that you're trying to breed for something, let's say we want to get
human level intelligence, then that actually may doom you from the start. Like sometimes the only
way to get to something is to not be trying to get it. And this is a hard kind of a bitter pill
to swallow, but something that what is the mechanism of trying that keeps you from being able to get
it? Yeah, so the mechanism there is something called deception. And actually, this is something
that applies way, way outside just neural evolution. This is a general principle for everything in life.
Is that deception? It's called deception. Yeah, it's basically the situation when
if you are observing that things are getting better, so it's like you have some metric for what it means
to be doing well, like performance metric, like let's say, how well are you able to walk? And so
you have some metric that says, well, how well am I walking? And so normally, like if I was trying to
get something to walk, I would select things, meaning I would breed things that are apparently
better at walking compared to their predecessors. And I would call that their fitness. And so that's
what I mean by trying, like I keep on intentionally picking things that seem to be better. And this
is a very intuitive idea, like everybody for a long time felt like this is obviously the way to
get things to evolve is to pick things that are better. But it turns out that if you're in a
deceptive situation, which it turns out, unfortunately, you often are in, that you can be moving in the
wrong direction, even though your metric for performance is going up. And that's because like
the world is really, really complicated. So it can appear that you're improving in some way when
you're actually not. And so for example, like when it comes to walking, like lunging forward like a
maniac and falling down like a few feet from where you started may appear to actually be an
improvement in your ability to travel, you know, because basically you're getting farther than
your predecessors by throwing yourself on your head, like five feet in front of you. But this is
actually not a good stepping stone towards really good walking behavior. In fact, like a good stepping
stone might be discovering the concept of oscillation, like that's what your legs do, they kind of
oscillate when you walk. Well, it could be that when you initially discover oscillation, you fall on
your face. And so it actually looks like you're not improving. And so but because your metric is
basically how far did you go, it causes you to basically be blind to the underlying discovery
that's actually essential to making the progress that you need to make in the long term. And this
problem of deception is just like universal across all kinds of endeavors, not just neural
evolution. It's like, is this analogous to almost like a kind of a local maxima kind of issue?
Yeah, I mean, it's basically the same thing. It's related to local maxima, local optima,
or premature convergence. Sometimes people would call it so getting stuck on a local optimum.
But I think that the insight that we have that's different from just saying, okay, well, we just
rediscovered local optima because we already knew about local optima is just how utterly profound
the problem is that like, you cannot just like, I mean, people think, well, there's ways of getting
around local optima, you know, I mean, there's tricks, we have diversity, we have randomness,
stochasticity, there are things we can do to kind of jiggle things around a little so we don't just
get stuck on a peak, which is what kind of we think of local optima is like getting stuck on a
peak in a big space that like, that's just not going to cut it in certain types of problems because
they are just so absolutely complex that almost no matter what you do, deception is going to kill
you. And we showed this when we introduced this algorithm called novelty search that in some problems
that it was like shockingly terrible what deception could do to you in these spaces.
And what was profound was that we showed that in certain problems like this where deception is a
really big problem. And I would claim that deception is a really big problem in like almost
any interesting problem. And I can kind of demonstrate that later if we want to get into it.
But when it is a serious problem, then we showed that with this novelty search algorithm that we
introduced, which was basically not trying to solve a problem, but rather it was just driven by
selecting things that are more novel. So not things that are better, but just more novel,
that this would actually be better at solving a problem that was deceptive than an algorithm that
was actually explicitly being driven by selecting things that were better. So the lesson it showed
is it can be better sometimes to not be trying to solve the problem than to actually try to
solve the problem in terms of getting a better solution. And this is obviously really counter
intuitive and paradoxical and upsetting maybe even because it's like embarrassing in a way
for anybody who's like saying, okay, I've got this really good optimization algorithm
to lose to an algorithm doesn't even know what kind of problem it's trying to solve.
And that's sort of what novelty search is. Novel research is a divergent search algorithm. So
basically, it's just trying to find things that are different than what it's found before.
It sounds a little bit like, you know, explore exploit where your explore is kind of optimizing
for newness. Yeah, yeah, it is. It is related to this kind of exploration exploitation dichotomy
that a lot of people talk about in machine learning. But it's also different, I think. So
like, there's an additional element of insight here beyond that, which is really important,
which is that when we think of exploitation versus exploration, like often we think of
exploitation as following some gradient, which means information towards something that we
are trying to get to. So in other words, we're using information to move in a direction that's
intelligent. But interestingly, exploration, we tend to think of as sort of random moves that are
sort of ignoring the informed gradient. So it's like, let's just go somewhere and see what happens.
And that's what we think of exploration. But what novelty search showed is that there is a
principled kind of exploration that is not random, that actually exploration is something that's
also very informed. And so in the novelty search case, you're informed by where you've been,
because novelty is basically a comparison between where I am and where I've been before.
So it's anything but random. It's a very informed gradient. It's just that it's the gradient of
novelty instead of the gradient of the objective. And this is actually a very information rich
gradient, because if you think about it, you know a lot about where you've been. In fact,
you know more about where you've been than you know about where you're trying to go,
because the whole problem with where you're trying to go is you don't know about it.
Otherwise, you would just go there. So novelty is actually more informed, I'd say, than the
objective gradient. And for this reason, it's an extremely interesting gradient to follow,
like the gradient of novelty, because you're being pushed away from where you've been before.
And it turns out that you will be inevitably pushed towards higher complexity. So it's really
tied into this idea of increasing complexity, because if you think about it, as soon as you
exhaust all the simple things you can do in the world, the only choice you have if you want to
continue to create novelty is to do something more complex. And so ultimately, there's an
inevitability that with novelty search, that you're going to be pushed towards increasing
complexity. So I think of it as almost like an information accumulator. In order to continue
to do novel things in the world, you have to accumulate information about the world.
So for example, you could imagine if you were trapped in a room, and I told you to just do
novel stuff. For a while, you could just run around randomly, and you'd bump into walls,
and everything you do would be novel. But eventually, you'd bump into all the walls in
the room. And so at some point, you're going to have to learn how to not bump into walls. And
when you do that, you're going to have to learn what a wall is, and how to sense a wall, and how
to navigate walls. And eventually, you have to learn how to open a door, because you have to get
out of the room eventually to do something new. And eventually, you're going to have to get off
planet Earth and go to Mars. And clearly, doing that requires learning extremely deep and complicated
facets of how the universe works, like physics. And so you're going to be forced to become an
expert on the domain where you find yourself if you're going to be pushed towards doing more and
more novel things. And so novel search actually is a very deep and interesting kind of a process.
And that's why sometimes it alone will do better than actually trying to solve the problem you're
trying to solve. If you think about evolutionarily, if you think about how could we get to
human intelligence from a single cell, it'd be crazy to do selection based on the intelligence
of single-celled organisms. Like, we wouldn't start out by applying IQ tests to single-celled
organisms. That would just kill the population. I mean, because none of them are intelligent at all.
And so it's funny, but in a sense, the reason that we got to where we are today is because we
were not trying to get there. Like, if we had started out where selection was based on intelligence,
then everything would have died, or we would have gone nowhere, and we wouldn't have gotten to where
we are today. So we see this issue of deception come up over and over again. Like, it turns out that,
like, there was a turning point long ago, eons ago, where symmetry, bilateral symmetry, was
discovered. These are our ancestors. There's these bilaterally symmetric flatworms. There's no
indication that it's had anything to do with being more intelligent, but actually it does in some kind
of, like, really, really long-term sense. Like, that was an important discovery that led ultimately,
or stuff like that leads ultimately, to human-level intelligence. But you wouldn't be able to predict
that on the basis of doing an IQ test. And yet we needed to lock that in. So in some sense,
we could recognize that was interesting from a novelty perspective, because it was a very new
innovation. But we cannot recognize it from a performance perspective, because at that long,
long ago point in time, it's not an indicator at all from the point of view of performance,
like, if the ultimate indicator is intelligence. And this is another kind of example of deception,
and why many things are not going to be possible to discover if we just set them as a goal and
just select based on those things. And this is a principle not just for evolution, but for life,
too. You know, like, there are many inventions that, like, would not have been invented if
they had been our goal to invent them, which is, again, the paradox coming up. Like, computers,
for example, were the first computers were based on vacuum tubes. But the people who invented
vacuum tubes were not trying to invent computers. Like, if you had gone back to the 1800s and told
all the researchers working on vacuum tubes, who were interested in electricity, that, like,
actually, there's something more interesting, like a computer, and maybe you should just invent
that, like, forget this boring vacuum tube stuff, you would neither have vacuum tubes nor computers.
So, like, once again, we needed people to be exploring very diverse ideas without having their
eyes on the prize, if you think of the prize as like a computer, in order to eventually get the
prize. And so there's a paradox there. And so this concept is so general and connected to this
novelty search idea that we wrote this whole book about it called Why Greatness Cannot Be Planned.
After a long time researching novelty search, and a long time for me talking in various forums
and venues about novelty search, and I realized that, like, the principles are really general
about this paradox, this is what I call the objective paradox, that, like, it's actually
relevant to all society, like, how we run our institutions. Like, you know, we give money to
people based on them making progress with respect to an objective, like, this is what granting
agencies do, like, in the sciences. And it's actually not principled in the long run. Like,
we have, there are other processes that need to be recognized and respected if we really want to be
able to achieve really, really ambitious ends. And so that's why we wrote this book, basically,
to introduce these principles of deception and divergent search and the objective paradox
to the general public. We were hoping that maybe this would actually provoke a discussion of these
things in a larger sense because of the fact that it affects many of the kind of attempts at
innovation that we as a society are engaged in. So it turned out to have really broad implications
across culture and society. Interesting. And then one of the papers that I noticed is one called
Galactic Arms Race. Is that an extension of this work, or is that a different direction?
It's related. Yeah, it's related. So, like, we, as we started to understand this idea of dive,
we call it sometimes divergent search, like, searches that are not aimed at a particular
goal, but rather, which are diverging through the space of what's possible.
They're kind of searches that, like, show you all the cool stuff that you could find,
like, not just one thing. Like, Evolution on Earth is kind of like that. It's like,
there's not, like, one thing it's trying to do. It wasn't, like, trying to get human level
intelligence. It's kind of, like, illuminated all of the possible cool stuff that's out there in
nature, like, all of the, you know, diversity of nature. And so we started to realize these
algorithms are really cool that do stuff like that perhaps for applications in the real world.
Like, in Galactic Arms Race, the application is a video game. And our idea there was, like,
maybe we could put one of these divergent search algorithms in a video game so it would generate
the content in the game. And you'd get more and more cool content just, like, flowing into the
game from nowhere. Like, no human has to actually design or invent it. And in the case of Galactic
Arms Race, it was the weapons of the ships that you fly. Like, people are familiar in video games,
like, with playing games where, like, you have to pick up new types of lasers or weapons or guns
or something like that. And so we said, let's let evolution invent the weapons. But with a kind
of a novelty search, like, process where it's not, like, aiming for, like, the optimal weapon.
It's just diverging through the space of weapons. But with some information about how humans are
actually using them. So it's informed by the humans in the game and in real time inventing new
weapons for the humans to try. And so there's an interaction, we call it interactive evolution,
between what humans do and what evolution does. And it caused, like, all these cool weapons to
be invented. Things that I don't have never seen in any other game that were just invented by the
computer itself. And it's kind of, I think, a really nice exposition of, like, the potential
of, like, divergent search or novelty-like searches to create kind of open worlds where
things are just continually generated. And sometimes we call this open-ended evolution
that are interesting and hopefully without end. What's an example of a type of weapon that was
invented in this game? Okay, yeah, there's a couple good ones. So, like, one was I,
so there's funny, we started naming these things after the fact because they don't actually have
names because they're invented by the computer. But, like, one we called a tunnel maker,
which would basically generate, like, two streams of particles. These are all particle weapons that
would sort of, like, very slowly shoot on the left and right side of your spaceship. So basically,
it created a protective tunnel that you could fly through. And then in the middle of that tunnel
there was another faster stream that was actually used for shooting things. So you would be creating
basically, like, a shield that would, like, shoot out from your sides that you could then
fly through. Okay. There was another one that we called a lasso, which would just look like,
it looked like a cowboy's lasso, you know, just, like, shot out and, like, created, like, this
spiral around the enemy and then, like, closed in on it. And it was really surprising that this
thing was invented. And it was kind of interesting because I actually, it's not a great weapon in
an objective sense, like, the lasso one. Because, like, I think it's much better probably just to
shoot straight at something and kill it. But, like, the players loved it because of the aesthetics.
It's just so interesting and fun, like, to have the lasso weapon and to kind of show off because
it was a multiplayer game so people could see each other's lassoes that it became popular. And the
game just kind of went with it. You know, the game didn't say this is objectively worse or
objectively better. It just saw that people were interested in lassoes or created more
lassoes and diverse lassoes. And we had all these lasso weapons proliferate in the world
because people like them, whether they're, you know, optimal in some objective sense or not.
Hmm.
Is there an argument that says that the, you know, the, you know, issues around, you know,
that you identified in novelty search and, you know, getting led down the wrong path. The example,
I guess, you gave us with, you know, a robot trying to learn how to walk and kind of using a
motion that kind of allows it that kind of doesn't lead it towards walking and eventually
let it fall on its face. I guess the thought is, are, you know, can all this be boiled down to
just not being able to express enough sophistication in our objective function or not being able to
express our objective function in the right time frame or something like that?
Yeah. Actually, there's an element of truth to that view that like, yeah, like if we knew enough
about the world, we could just write the objective function to take into account how the world
actually works. But the problem is that like in practice, that's just impossible because like,
you ultimately would have to know every single thing about all the stepping stones that you would
have to go through to write the objective function to take that into account. So it's like, say there's
like, you know, a million steps between here and a human level AI. So, well, obviously, if I wrote
a fitness function where your score is literally how far you are along that path, then of course,
this is like the ideal objective function is going to work out fine. But the whole point,
the whole problem that we're facing just begs the question of how are we going to figure
out what the stepping stones are? So we're back to square one again. And so in practice, like,
you're probably not going to be able to do that in even like a relatively simple problem.
Because the whole problem of search is we don't know the stepping stones. If we did,
we wouldn't be doing search because we would just build the thing because we would know all
the steps towards how to get it. Right, right. So this paradox is basically unavoidable, you know,
like if the problem's not interesting, then we do know the stepping stones, then we don't need to
do these things. But the problem's not interesting. But if the problem is interesting, it's interesting
because we don't know the stepping stones, like that's what makes it an interesting problem.
And so almost any interesting problem is going to be confronting this paradox. Now,
that doesn't mean that there aren't some cases where search will work. Obviously,
it will with an objective sometimes. There's no doubt about it. In fact,
deep learning has exposed that like in really high dimensional spaces between spaces of many,
many parameters, like many weights in a neural network, that there's less deception than we
thought. Like, and this has been a surprise for everybody, including me. And so sometimes we
still can just push sort of brute force through the objective function because high dimensional
spaces have some very odd properties and succeed at solving some problems. So we shouldn't conclude
from what I'm saying that like, oh, well, the objectives are completely useless. They do work
in some cases. But I think that it's still the case that in very, very complex problems,
we are going to be facing deception. We are not going to know how to write the correct
objective function to go through all those stepping stones, which are basically reflecting
eons of progress to get to some of these really ambitious ends that we have. And so it's an
element. It's not like everything should be done this way, but it's an ingredient that's added
to our toolbox now, which is going to be important in concert with sometimes explicit objectives.
And so it gives us kind of a powerful new tool. And this has actually led to a field called quality
diversity, where we combine quality measures with kind of diversity measures and try to do both at
once in order to make a principled attempt to leverage what we know about both of those kinds
of searches. Super interesting stuff. Kenneth, I really appreciate you taking the time to speak
with us about neuro evolution and your research. Is there anything else that you'd like to leave
us with? Well, I just, I guess, just to say that take a look at neuro evolution, like it's,
it's actually becoming now more recognized in deep learning that, you know, we have actually
a lot of synergy with deep learning because we're also doing neural networks. And so both fields,
I think are realizing today that we have something to offer each other, perhaps, you know, like
neuro evolution can evolve architectures and deep learning can apply really powerful learning
algorithms to those new complicated architectures for just as one example, neuro evolution can
can contribute to reinforcement learning in new ways because of the way that fitness can be a
different kind of driver of progress than say the typical gradient based approach. And so in the end,
we get a possible really powerful synergy. And so I think it's worth looking at how these two
things can possibly feed into each other going forward. Awesome. And what's the best way for
folks to learn more about what you're doing? I'd point people to, I mean, I'm guessing you probably
have some links associated with the interface. We can include a link. And I know you've got a page
on the UCF site. Is that the best one? Yeah, I'd point people to my homepage and my research group
homepage, both are at UCF and also I can provide a link to Uber iLabs where we actually are hiring
too. So people are just interested in jobs in general. That's another opportunity there. So
I'll also point to that. Fantastic. Well, thanks so much, Kenneth. Yeah, thanks. It's been a pleasure.
Thank you. All right, everyone. That's our show for today. Thanks so much for listening and for
your continued feedback and support. Thanks to your support, this podcast finished the year as a
top 40 technology podcast on Apple podcasts. My producer says that one of his goals this year
is to crack the top 10. And to do that, we need you to head over to your podcast app, rate the show,
hopefully we've earned your five stars and leave us a glowing review. And more importantly, share
the podcast with your friends, family, coworkers, the Starbucks barista, your Uber driver,
everyone who might be interested. Every review, rating and share goes a long way. So thanks in
advance. For more information on Kenneth or any of the topics covered in this episode,
head on over to twimlai.com slash talk slash 94. Of course, we would love to hear from you either
via a comment on the show notes page or via Twitter to at Sam Charrington or at twimlai
or at twimlai. Thanks once again for listening and catch you next time.
