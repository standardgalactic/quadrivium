I think this is bigger than the printing press.
It's bigger than anything.
And so that's one of the reasons I signed the letter.
I said, we have to get this discussion going in public right now.
We've got to stop pre-training big models on all the crazy crap of the internet.
And like, we've got to do it fast because this is coming like a train.
And that I am so excited for this.
I heard so many great things from specifically Ashton who helped with questions
and then also Dan Rose.
So thank you so much for joining me today.
It's my pleasure.
Now, I want to start with a little bit on you.
You moved around a little bit in your childhood.
Take me back to the childhood, the moving around.
And it's a weird commonality I found with the most talented founders.
They all moved around.
So take me to that and how it impacted your mindset.
So I was born in Jordan, grew up in Bangladesh, came to the UK.
Yeah, didn't move around that much.
But with my father a bit as he lectured in various places.
And it was always a bit of a struggle fitting in, but then you learn to adapt.
You learn to adapt to new scenarios, new environments.
Like, oh, don't speak the language, kind of what's happening.
Let's learn and let's move on from there.
I think it gave me a bit of appreciation of the world as well,
because we stick in our monocultures very often.
Like I'd only ever been to Silicon Valley.
I should have been the barrier once before last October.
And so this whole tech monoculture has been a bit of a shock to me.
And I'm like, there's more to the world than that.
So this is some interesting things around that.
Talk to me hedge funds first and then then what happened?
We mentioned it a little bit before.
Why did you make the move?
So actually, I was an enterprise developer in my gap here at Metaswitch
in the UK doing voice over IP.
Metaswitch. This is Chris Maz's company.
Yes. So I took my gap here and was like,
I might as well be enterprise programmer.
I didn't know what that would be like.
This was before GitHub and everything.
So we had subversion, you know, kids these days have it so easy.
And then I was like, what do I do now?
And so I became a VC analyst at Oxford Capital Partners with the MOTS there.
And that was a lot of fun.
They were fantastic.
And then I was like, I want to do movies.
So I became a movie reviewer.
So I did the Rain Dance Film Festival, British Independent Film Awards.
And they were just popping around doing random things
and then accidentally became a hedge fund manager.
Why did you move from hedge funds to startups?
So with the hedge funds, so I joined Pictay Asset Management
and then like the CIO left and there was like this fund
and I got to be a portfolio manager when I was 23.
And so I grew my beard to look a bit older and it's coming.
Get the clip on, Harry.
I would. I can't do the moustache, but I still wear the glasses
when I just need to try extra hard to force it out.
Right. And so I did that for a number of years
and you know, reasonably successful, made lots of people money.
Not so much myself because I was too young.
Again, they're like, you're too young to be a fun one.
And then my son was diagnosed with autism and I quit.
And because they said there was no cure, no treatment, no information.
I was like, I'm a hedge fund manager.
I can deconstruct things.
And so built an AI team and then did a literature analysis
of all the autism literature to try and figure out the commonalities
and then drug repurposing.
So focusing on GABA, glutamate balance in the brain.
GABA is what you get when you pop a valium.
It calms you down and glutamate excites you, you know.
And so in kids and people with ASD, it's like there's too much noise going on.
It's like when you're tapping your leg and you can't focus.
And so that's why you get this sensitivity.
Sometimes they can't speak like my son.
And so it was like mechanisms to bring that down
that then allowed to have applied behavioral analysis
and these other things to reconstruct his speech.
And then he went to mainstream school, which is pretty cool.
It's unbelievable.
I heard you said on another podcast and I was astounded and inspired by it.
We mentioned before, you know, my mother's got MS.
And I hate the doomsday only version of kind of AI in the future of GBT.
You said to me before about its impact on health and MS
in particular and other conditions.
How can it be so transformatively to solve some of the world's
most challenging chronic conditions?
So I think a large part of our problem is that we can't scale
because information flow is so limited as we write these things down.
Like you can never capture all of that.
So anyone who's had a loved one that has one of these conditions knows
how difficult it is because you go from specialist to specialist
to specialist and you try to build that mental map.
And we're so lucky that we have so much access.
But why isn't it that we can't just push about and see every clinical trial
and a deconstruction of all those and things?
What if you had a thousand GPT-4s organizing all that knowledge
and then make it available to everyone?
So you can see the exact potential mechanisms that are which MS works
and all the potential food, other things that work with that.
So as you try different things with your family member,
you can see, well, she reacted this way to the food or this way to this medicine.
And it is a more holistic thing because you can have personalized medicine
versus one specialist for a thousand people.
You can have a thousand GPT-4s or equivalents or med palm twos for you.
So we need to organize all this knowledge and then use these language
models and others to make it accessible to you.
I'm really naive and basic in terms of my thinking,
which is why I'm a venture capitalist.
But my question is, what do we need to do to get to that state?
When we look at the data needed from the individuals,
the data, the data, the GPT's need, how we make the models work most efficiently?
So first, we don't have to have that data for individuals.
We had Galactica as a scientific language model,
but now we have Med Palm 2 that exceeds doctor level.
So that was a Google announcement yesterday.
We have AIs that can understand articles better,
as good as doctors, shall we say now?
So we can scale that because why do you need one when you have a thousand?
So we take the existing generalized knowledge and all the hypotheticals
and we bring that together into an integrated common system available to everyone
because the building blocks are nearly here for that.
Then you can personalize it later.
And again, there are regulations and things around that to how you're,
again, how we treat our loved ones and other things like that.
The first thing is let's get all the knowledge in one place
and make it organized and useful.
And so I think we're at that point now where the language models have just hit that point
that we can organize all of the world's Alzheimer's knowledge,
longevity knowledge, autism knowledge, MS knowledge.
And you can just type and it can say, this is the source.
This is what it looks like.
These are some hypotheticals.
This is what we know, what we know we don't know,
what we think we might know, et cetera.
And then it can learn about you and your queries
because this is the other thing about lots of the language model things we've seen right now.
They are one-to-one goldfish memory.
The next step is one-to-one.
It remembers what you're asking for, like a cookie or an embedding.
And then it's you plus a thousand of these language models
all going and doing your bidding, the agent-based kind of thing.
Does this get around the incentive problem in healthcare?
And what I mean by the incentive problem in healthcare is I'm sure you know there are
a lot of diseases actually where it doesn't make kind of economic sense
for a lot of pharmaceutical providers to chase research, to chase treatments
because it's not a big enough market, because it's not,
because it's six dollar treatment.
Does this solve for that economic misalignment?
I think it can help a lot with that economic misalignment
because then you have an authoritative source where we can all come together
and build that can analyze these things.
Because there's this concept of agiddicity.
A thousand coins tossed in a row is the same as a thousand coins tossed at once.
And because we're so limited in our information in our medical system,
like you know I just had my key management,
so I had to answer 40 minutes of questions.
At least, Mo, have you done this?
It's stupid, right?
We're all treated the same.
I think 10% of people have a cytochrome P450 mutation in their liver,
which means they metabolize drugs fast quicker.
So if you metabolize code, it turns into morphine, or fentanyl kills you.
But that's a very basic genetic test,
yet we give everyone 500 milligrams of the same thing.
With my son, a micro dose of 5 milligrams of clonazepam,
which is used for anxiety disorder,
worked with a neurologist, allows him to sing.
The standard dose is a thousand milligrams,
so they can only prescribe it at a thousand.
But that is a $6 a year treatment that affects his GABA glutamate balance.
But only for his specific type of ASD,
which is only 7% of all kids with ASD.
But why would that be in a pharmaceutical company's interest?
You know, because how are they going to make money off a $6 a year treatment?
Well, how many people have ASD?
It's 1 in 60.
Okay, it's 1 in 60, so you've got a million people in the UK?
Yes.
So you've got a $6 million.
Yeah, it's not great.
Exactly, it's not great.
I mean, it's like we know the benefits of vitamin D, right?
But we still don't prescribe that at scale,
and so many people are deficient.
I mean, all these things.
The joys of doing what I do is going on schedule with a final one,
and then we will kind of retain some form of normality of schedule.
What is the future of healthcare systems that you think
with GPT models operating in this way?
I think that you can change the nature of a doctor,
because a lot of the stuff is kind of very basic.
I think, you know, you had Babylon Health and others trying,
that chatbot, it wasn't ready, now you've got this.
Everyone should have their own AIs looking out for their own health,
with that objective function.
You know, and then the nature of a doctor becomes different
in terms of they have more rich information about an individual,
while it being preserved in a private manner.
I think what you have is you have things like
processes and procedures improving,
like wound care, for example, and then NHS.
If you are injured as an elderly person,
and your wounds aren't treated properly,
and more likely to die by a factor of eight times,
being able to monitor those types of things
with this information set means you're eight times as likely,
and then you have far more efficiency around that.
So the information density around healthcare improves,
which means that then our own healthcare improves.
We all have access to as much knowledge as we want to,
within our own context, and so do our providers
and the people that help us.
How do we think about open source versus closed source
human healthcare data?
Because like, obviously for us all to benefit as one,
you know, MS sufferers around the world need to submit
their data around responses to certain treatments.
Yeah, so I think the wonderful thing about these models
is they're few-shot learners,
so they don't need to have much information.
As I was in the classical big data problem,
HDR UK has been one of the pioneers here
with the UK Biobank, Federated Learning, and others.
And there are kind of, with FL7, HLIR, and other standards
being built around this to allow
for full federated learning.
If you have open source language models
that are fully auditable, I call them organic
free range models, the ones we're building,
with no web script data, those can sit on device,
like Google SDA announced POM2.
The smallest POM2 model is 400 million parameters.
It works on your Google Pixel phone.
You don't need giant models anymore.
And then that model can just share the specific information
that preserves your privacy with the bigger thing.
And then it can take from that global knowledge base as well.
So you'll have big global models on device models.
And I think open works for that
because you don't need to have all the data open.
You just need to know that Harry is old enough
to have a drink, not that.
All the details about Harry, his birthplace,
and everything like that.
He's old enough, he's just not allowed to.
He gets parted all the time, yeah.
Were you impressed by the Google event yesterday?
No, I think it was impressive.
I said in February, when all this thing was going on,
like, come on, Google will be one of the main winners here.
They have the LLMs, they have the hardware.
You do know you're the only person who said that on the show.
And I've asked many.
And they've all said that Google are the laggards.
It just takes a bit of time to move the ship, right?
And so they've done massive organizational changes
and other things.
But I can tell you, TPU is on the most scalable architecture.
We have zero failure rate with our TPU language model training.
Whereas with GPUs, it's like there's
an ECC error, why a solar flare?
Run failed because the sun is angry with us and stuff like that.
So when you've got the full stack,
and you have all that talent in Google,
the question is, how do you make it organized, right?
And so they had to have a story.
Google did something called Pro-Taristottle,
where they analyzed what made the best teams
versus the worst teams at Google.
And it came down to shared narrative
and psychological safety.
People at Google were scared over the last few years,
because it came this weird monoculture.
But now everyone has a shared narrative of,
let's build the best language models,
and now there's an increase in amount of psychological safety
being able to speak to things,
the walls being brought down between deep mind and brain.
And so I think you'll see them continuously improving.
Well, then that does mean,
if you're a proprietary language model company,
how are you going to compete with that vehemence?
The deep mind desegregation or unification
was supposed to, of course, have a lot of friction
and be a negative press reported.
She disagreed with that.
Of course, it is a lot of replicated jobs.
There was brain and mind,
and now they're kind of brought together.
And it's a very different management style
and other things.
These things are never easy.
But this is why you saw palm 540 billion parameters
and that you had deep mind
with 67 billion parameter and chiller,
which is just train more as opposed to more parameters.
You look at palm two as a combination of both.
And so it's trained for far more on far better data.
And then that means it's only a fraction of the size,
like 14 billion parameters
is one of the test comparator models versus the 540 and 67.
So you can start to see this fusion of ideas,
even if the teams,
you cannot integrate two big teams like that instantly.
Shared narrative, psychological safety,
two of the biggest contributors.
To now running stability,
how do you think about integrating those two?
So we've got the shared narrative.
We're going to build the foundation
to activate humanity's potential
and then the motors make people happier.
But it's been a learning process,
the year ago, we're basically a mom and pop shop in some ways.
My wife and I were working at it,
like had lots of meetings out of our like sitting room
and things because the office didn't have wifi
and all sorts.
Now it's like growing up, we're 170 people,
we're going global,
we'll have stabilities in every country.
And then actually we're going multinational.
And that's difficult.
So we really try to put in processes in place,
but it's not easy.
Part of this is like,
we went close source on a bunch of stuff like dream studio.
I'm open sourcing everything now.
From next week,
we're going to build our language models in the open
and share what works and what doesn't work.
Why?
Because I think this is part of the shared narrative.
Someone needs to be open
and share what's going on under the hood.
And again, it's like, it should be opened by default
because the value is not in any proprietary models or data.
We're going to build open models that are auditable.
Even if it has licensed data in it,
you can see every single piece, free range organic models.
Because that's what the world needs
for all the private regulated and other data in the world.
This is a completely different time to proprietary models.
Because you can only send so much of your 20 VC data
to open AI.
And I think you need both of those.
So why can I only send so much?
Because you are a regulated company.
And so you need to make sure they're completely compliant.
If you have an option of having a stable chat model,
which will be announced in the future,
that you own completely trained in your own cloud
or on-prem or on-device,
and then also using GPT-4,
that's the best of both worlds.
Because then you don't have to deal with that.
Healthcare data needs to, again, be owned by the individual.
And so those models need to be owned.
And they need to be transparent.
They can't be black boxes.
Governments will not run on black boxes.
We're going to get to this later.
I do want to touch on something.
We had a great chat before this.
And you said a brilliant quote, and I want to get it right,
but you said the .ai bubble is bigger than ever,
and it will be the biggest shit show.
Yeah.
End quote.
Which I actually took and tweeted, by the way.
Thank you.
It could be some gratitude.
I thought if you saw it, I would have been like,
ah, this guy took my tweet.
Thank you.
And what did you mean by the biggest bubble ever
and the biggest shit show?
Oh, I mean, like the .com bubble,
we've seen all these bubbles happen.
You know, you had hundreds of billions into Web 3,
and then developers got paid millions.
Already, there are certain Chinese companies
paying $1.2 million salaries for PhDs.
It's already getting a bit insane.
There are remnants of that.
The amount of money relative to the amount of opportunity
within the sector is just completely misaligned.
Like my time analysis is that
1,000 companies spend $10 million in the next year,
100 companies spend $100, and 10 companies spend $1 billion.
Like PWC just announcing they'll spend $1 billion
over the next three years.
And that's a currency firm, you know?
Where's that going to go?
They don't know.
Nobody knows.
And so multiple of that will be allocated to this
as the only growth theme in the entire market
against a backdrop of rising rates,
real estate crashing, et cetera.
So the amount of capacity versus the amount
and whale and wall of money
into something that's growing faster
than anything we've ever seen is completely mismatched.
And what will that cause?
Like already you're seeing GitHub stars leading
to $100 million funding rounds
with zero attraction and zero business model.
Like stability, we actually have a business model.
And it's a good business model because I designed it.
But other things like money will go everywhere
and any expertise will get bit up for this space
because it means that projects will get funded
that maybe wouldn't have done,
but are exploratory generally and over funding.
I think it starts good for the space,
but then it gets bad for the space
because you see the raccoons and Scheister
start to come in here.
You start to see like malformed things
where there's a race dynamic,
where everyone's trying to build their own models
and doing all sorts and massive economic waste.
And you see a distraction from what we need to do now,
which is this chaos.
So we need to standardize some things.
We need to feed these models better data and other stuff.
And that's why we're moving so hard at stability.
There should be no more web script data in here.
There should be national data sets that are good quality
to feed these free range organic models
and national and proprietary models and others.
And so that's why, and the reasons I signed that letter
because I think there's a six month pause
to get all of our shit together
before things go completely insane.
And next year, this is everywhere
and everyone's investing in everything.
And it's just absolute chaos.
You kind of unpack so much to me
that I want to kind of go one by one.
You said about kind of national data sets.
Why national data sets versus super national data sets?
Because like, I'll give you an example.
There was a team that did Japan diffusion,
including some of our staff.
So we took stable diffusion
and then changed the language model.
Because when you typed in salary man in stable diffusion,
it was a very happy man.
Whereas in Japan, the salary man's a very sad man.
You know, local context is important in these models
because we're going to outsource more and more
of our thinking and minds to it.
And so do you want to have a British model
doing all the models to be Palo Alto?
You know, like it's a sparkling wine
has to be from the Champaign region.
Like is the only real foundation model AI from Palo Alto?
Like it's not a good thing.
We need national models.
It's a national infrastructure
because there is no doubt this is more important than 5G.
These models are like really talented grads
that occasionally go off their meds, you know?
And you want to have the ones from Oxford Imperial
and Edinburgh as well as the ones from Stanford
because they understand the local context.
And so they understand you better
and they'll be better for that.
As part of that, every nation will need their own data sets
which again have from broadcaster data.
They will need their own open models
that can stimulate innovation internally as well.
Who owns national data sets?
Is that governments?
I think it should be the people.
I think it should be open and public domain.
How does that come into fruition?
Well, we have a world where we have national verified data sets
which can be leveraged by independent private companies.
And others and universities and others.
Well, this is what we're doing right now.
We're working with our multinational partners,
lots more to be announced soon,
and multiple governments for a framework
for what good data looks like to feed these models
to stimulate innovation and localization.
And that is a public good
because national broadcasters have all of this data.
You just tokenize all their kind of things.
And then you have things like the implementation
of these for education and healthcare.
You can take generalized learnings
and then again feed the models that thing.
What is a great data set for a great British E.P.T. look like?
I think it's open, it's interrogated and it's optimized.
When you look at all the different things
that we've talked about from you,
relative treatment of MS to ASD,
and then it's impact on education.
And we just to PWC spending money on it,
there are so many problems that can be solved.
Surely we can find a home for the cash.
Yeah, and so I'm not sure where.
And so this is the thing,
like there's gonna be this mismatch.
If you were an invested state,
if you were me, what would you do?
I'm an early stage investor, I'm less globally.
What would you do?
I would, again, I think it comes down to,
there's gonna be this tailwind of beta.
And then you have an alpha play on top of that, right?
So the beta play is that you just invest
in any good founder.
And if you get in, you figure out,
what can I offer as kind of a value out there?
Am I offering distribution?
Am I offering people?
Am I offering this?
And you emphasize kind of your value set.
I think right now what people need is people.
There are a few people that are like coming out here,
but then what you see is you see good companies,
with good ideas, but not businesses.
They're building surface level things,
these wrapper layers and others,
and they're not thinking about distribution and data.
It's like, if you want to have distribution,
what do we do?
We went to Amazon and said bedrock,
because then it gives us 100,000 SageMaker SMEs.
And we'd have to give them the models
that they can then take to the private data.
And we get a share of all of that.
This is how we saw it,
like rather than being responsible that.
So if you can bring that distribution to that,
this is part of that Google memo that went out.
We don't have an edge and others open AI.
Open AI used Microsoft for distribution and that flywheel.
If you have a business that's focused
on innovation at the core, that's not actually a business.
It becomes a business when that innovation
becomes product, becomes distribution,
when it has an advantage on data and other things.
Those are real modes.
How did you arise that partnership
between open AI and Microsoft?
I saw it as the objective function of open AI
is to build AGI and they reckon they need $10 billion
to do it and they did that.
Like they're building a business on products and things,
but they don't care.
You know, they're not trying to build a sustainable business.
They're trying to build an AGI.
Why?
Like what would I, just help me understand
AGI to build a sustainable business?
Cause at the end of the day.
No, they're building an AGI
to turn the world into utopia.
It's written in their path to AGI thing
that they think this can basically bring about utopia.
So a lot of people in these labs,
we only have people joining from all of these labs,
like they almost zealous in there.
But there is a misalignment there between them
and Microsoft in their desire to create that utopian AI.
Yes, cause Microsoft is a business, you know?
And so this is why you've seen like articles
in the information, like Microsoft say open AI
aren't compliant and open AI say Microsoft on this.
These things happen when there is a misalignment
of objective functions.
But again, you should view open AI as what they want to do
is build an AI that can basically make the world better
and hopefully not kill us all, which they say it might.
Which is a bit concerning,
which is why I hope they have better open governance.
How did you think about distribution?
You know, you've seen the hugging face part of it.
Amazon, you've seen obviously open AI with Microsoft.
When you think about distribution
and your competitive edge there, where did you land?
So my business model is actually very simple.
I haven't really talked about it much.
Stimulate open one of the biggest providers of grants
to open source software, tens of millions already.
And then take the best of open,
which hopefully we build ourselves.
And then an open base with an open data.
And then commercial variants with license data
and then national variants.
So you have Hindi insurance adjusted stable chat
or Indonesian pharmaceutical worker stable chat
that's available in every cloud, on-prem, on-device
with licensing fees, royalties and revenue share.
And the system integrators work with us as well.
Lots of announcement to come.
And so by standardizing and stabilizing all the complexity
to these very sophisticated building blocks,
these very intentionally built models,
that really helps the world integrate this stuff
by building playbooks and other things.
And that's the core business
because it doesn't require actual innovation.
We are still innovative
and the leaders in media in particular.
Instead it requires data and distribution,
data to the models.
The models are open and interpretable
and models to the data via our partners.
And that's valuable because the private data in the world
is far more valuable than the data
that you will send to proprietary models.
And it's not a race to the bottom either.
So that's what we are.
We're a modeling agency with hot GPUs.
Building a distribution around the world,
realizing that India and other nations
will leapfrog to intelligence augmentation,
just so they leapfrog to mobile.
They will embrace this technology far quicker
than we will in the UK even.
Why?
Because they have to.
India, all of the outsourcing jobs in programming will go
because GPT-4 can go level three
Google programmer exam and pass it.
Outsource jobs will go the first, whereas in France,
you're never gonna fire a French person.
So those jobs are fake, you know?
And so they have an objective function
when they need to embrace this technology.
In Africa, one to one tuition,
every kid in Malawi is on things you lined up.
We've got other nations.
We're gonna bring them all this technology and tablets.
And guess what?
Their lives will transform.
One AI per child is one I wanna call it.
We'll call it something else.
But think about the potential of that
because you have one's teacher per 300 kids.
What if they had a chat GPT-level AI?
The ROI is high and the need is high.
And so they will embrace it far quicker than we will.
What happens to countries that rely on outsourced work
in those kind of freelancer economy jobs?
In general, one of the things, the questions is,
you've seen OpenAI study, you've seen the,
which said task will be replaced up to 44%.
You've seen Goldman Sachs say adds percentage points to GDP.
I think the only solution to this is entrepreneurship.
And so we need to give the tools to create new jobs
that can replace some of these old jobs being done.
So like to the various Asian governments,
I'm saying adopt the UK policy of these sandboxes,
financial, AI and other regulatory sandboxes.
So you can take these technologies,
these national models that we will help you build
with our consortium partners
and then spur innovation to create the jobs
to replace the existing jobs
because you'll upgrade your entire society.
Bring these models into your governments
and other things to go from slow dumb AI's,
which is the national organization's healthcare,
to intelligent dynamic ones.
Can I ask on implementation,
when we think about kind of bluntly
seeing this in action in society,
I'm sure it's very aware of technology cycles
taking so much longer than one anticipates.
How do you think about that in actual,
there's kind of two-fold.
One is adoption on enterprise
and another is adoption on consumer.
Say if we do the adoption on the consumer side,
which is impacting freelancer jobs and impacting education.
What do you think that looks like?
So I think on the consumer side,
you're free with your information.
So you can use a lot of these things,
the APIs of OpenAI and Cohere
and others are fantastic, right?
And Google Palm now kind of being out there.
So it will be integrated
to deliver better consumer experiences
without it being creepy,
like you've seen with some of the chat bots, et cetera.
Cause it's going into word,
it's going into workspace, you know,
like it helps already.
Like we will have a conversation
will be automatically logged by our pixel phone
and then we'll get a transcript
and remove bits that we don't want to share
that it goes into a global knowledge base
that reminds us of things.
That's inevitable.
On enterprise, it takes longer
because you need to have auditable standardized models.
If you're a financial services institute,
you can't have a single piece of crawl data in there.
And so that's what we're deliberately building
with the largest companies in the world
because we're building dedicated teams.
So you can't have a single piece of crawl data
if you're a financial services.
Yes, because the danger is
if it has some Reddit in there.
So stable.
And you know, we'll put out next week,
it wasn't as good as the other models
because we're going to make a point
about Reddit data being bad.
It's not about more data, it's about better data.
We had data comp,
which is the next generation lion
that we funded the compute for,
whereby at a quarter of the parameters of OpenAI's clip,
that outperforms with the beta data quality.
What makes good data quality, sorry?
That's something we're exploring right now.
But from the investment banks,
we've talked to asset managers
and we're building dedicated teams
for the largest ones in the world
to build them a prior to models.
The feedback we've got is we cannot use a black box.
We need to know what data is in there.
Just the regulators are asking us.
We don't want to have this out of sample thing
where it's seen something on Reddit
and then it says something rude to our end users, you know?
Why is Reddit data bad?
Reddit data isn't bad in itself.
It was just a case of more data is not always good.
So right now we are using all these web scrapes
and we're training our models by taping their eyes open
and then it took six months to turn GPT-4 into chat GPT-4
because we had to tune it and like give it a haircut and stuff
and bring it back to society.
The point is that we need to find the right type of data
because rubbish in, rubbish out
is something that we've heard a lot, you know?
And so it's not bad in itself,
but if you just scrape it
without the proper cleaning, it is bad.
Because what is it?
It's like, you know, people just covetching a lot.
You know, people being biased.
Do you really want to feed your kid the whole of Reddit?
You know?
Do you want to have the best curriculum possible?
And this is actually one of the ways the models learn.
Like stable diffusion, we train it on the whole internet
and then better and better image subsets of it.
And that's the same thing with lounge learning.
It's called curriculum learning.
Train it on a big base that's solid and then did it.
It sounds familiar, doesn't it?
The hardest thing is how do you instill values
and political correctness in models?
There is no such thing as an unbiased model.
So Dali too, when OpenAI had that
and they introduced a bias filter,
any non-gendered word that ran a random gender
and a random ethnicity.
So you type in Sumo wrestler
and you get Indian female Sumo wrestler.
That was kind of a good picture.
I got to save somewhere.
I think this is why you need national data sets.
You need cultural data sets.
You need personal data sets
that can interact with these base models
and customize to you and your stories.
Because you and I both have our stories
that make up our psyche.
Sure.
And understanding that context is so important
to have AIs that can work for us, not on us.
And so it's essentially like a next generation cookie
that personalizes our data to allow for better searches.
And mega cookie.
And if you standardize the base foundation models
and they call it the hypercube every modality
because we do all the modalities,
all the sectors and all the nationalities,
then you don't need to have a million different models
like those dream booths of the avatars.
You said you have a base model
that you then have a vector embedding around.
Because these models contain all the principles
and the embeddings point to the important bits
that make up Harry or Emmad.
And then you can search those and adapt those
rather than having a million, billion different models,
which is just confusing.
So I had dinner the other day
with one of the largest media publication owners
in the world.
And he said that I'm white, Harry.
I don't think that I will have a business
in a couple of years.
I think, bluntly, we're getting killed on our advertising
because everything's getting scraped
and they're not coming to our websites.
And that's where we get paid.
We get paid for clicks.
Is he right to be worried?
I think he is right to be worried.
Like, again, you look at Google's announcements yesterday
to talk about this day after Palm 2,
you suddenly look at the new Google page
where they've got the language model
and it's just text and where they clicks.
It was like when Google introduced AMP.
You know, this is where rather than look
at the New York Times page,
you have this formatted thing
with no New York Times kind of stuff there.
Like, these search entities that aggregate
are just intermediating more and more
and people are going to become used
to just having synthesized input.
So what does search look like?
What does it look like when your GPT-4
can write you an article about any news that's happening
in a way that's customized to you
and your context and everything like that?
This is massively disruptive for media and information.
And so they have to think, where am I in the future?
Where, again, the way I swear to think about the impact
this is the retanted grads are caching off their meds
and we push a button and get 1,000 of them.
Those grads include journalists.
And you can have your own journalist army,
your own writer army, your own coder army,
your own designer army.
So the pushback against that is libel.
He said, good fucking luck.
We spend our life in law suits, libel is real.
You are gonna get unbelievable amounts of libel cases
and then open AI will be fucked.
You cannot have 1,000 libel cases a day.
Well, this is the thing.
If you say this needs to be checked and cross-checked,
that's one thing, but a lot of the media companies
say we're the source of authority.
So a way that media companies can shift is by having
in a deep fake and other age
where everything can be generated,
we make sure this is real news.
We are very thorough in the way we do it.
So this is interesting,
so you place a premium on authority.
Premium authority, this is why you've got the check marks
coming out at Twitter and the organizational
1,000 pounds a month and Facebook doing the same
because you need to have a level of authenticity
and level of authority.
But again, is the news fair and balanced?
I've had lots of hit pieces coming out against me
and got a lot more.
It's not because they have angles, you know?
And so what is the bias of the New York Times
versus this, versus that, versus others?
How do people consume news now?
And even news consumption has gone down dramatically, right?
Because people consume news through their social networks
through their groups and other things.
So you have to say, what is the model?
But the hard part is, you know,
none of the next generation models
or AI providers want to be content publishers.
So how do you fit in a world where, you know,
you're killing that business model on the content side,
but they don't want to be publishers.
You will have AI first publishers.
So if you remember a kind of Vox
and these things when they kind of kicked off,
they wanted to be generated,
they wanted to be technology first.
You're gonna have a new wave of AI first publishers
that aren't just AI, but it's AI plus humans.
Because AI plus-
What does that look like?
Sorry, AI plus humans.
AI plus humans means that you have information coming in
and then the stories or drafts are automatically written,
reviewed by humans who then give their input
to train it better.
This is kind of the feedback flow.
And then what happens is it comes out
and there's a factual anchors
and then it gets customized to Alabama
and then Alabama context and all sorts of other things.
Because you can tell it, TLDR,
two ladies didn't read, explain it like I'm five,
make it more complex.
And so you're gonna see something very interesting here,
which is the right news at the right time.
The localization will return,
but again, through AI first.
I think this is the thing, we're seeing AI integrated,
but the next wave is going to be
once we understand design patterns,
AI first, everything and information flows.
Once these technologies are a bit more mature.
Can you just help me understand AI integrated
versus AI first, what is-
AI integrated means that I have an existing newsroom
and I bring in AI to write faster drafts
and things like that.
AI first is saying, I have an army of things
I can spin up instantly that can help me achieve
these certain things to create news
that is valuable for this reason with this feedback loop.
And so you build the system kind of from the start
thinking AI at the core versus AI being integrated in
to improve existing systems.
Because so much of news is what?
We find information, we have drafting,
we have this, we have that, we do these checks.
A lot of that can be simplified,
just like we move from the analog to the digital age
to the internet age to the next age as the AI age.
So I have to ask, when we think about kind of AI first
publishers and the next generation of media,
who does this?
Is this startups?
I've met honestly 50, maybe more AI companies
in the last month.
And the feedback is always the same.
They're not operating off a defensible mode of data
that literally a thin application layer
on top of an existing model is 99% of the feedback.
So you look at something like Harvey, for example.
They went to law firms, they said, you are a distribution
and we're going to integrate and improve your system
and build our system for your system.
So I think a lot of these people are trying to build it
and they will come and they're trying to get in there
as opposed to just retargeting.
Where can you go in and transform?
Is that the wrong model Harvey did?
No, I think it's the right model.
I think that a lot of organizations are elastic
and plastic now, so you can go in and give them
an integrated thing saying, you will be my test case.
I will help you upgrade as a Skunkworks lab
and build a system alongside your system as it were.
And sorry, and you think enterprises will say sure?
I think now they will if you can keep
their data inside internally.
And I think again, with better open models,
you can enable that.
So people can build on top of open models.
There are dedicated instances on Cohere and others as well.
And so the tooling is now catching up
so that you can have a new generation of startups
where their first customers are massive companies,
they would never get otherwise.
I think this is the thing,
because every big company is looking for an answer.
If you can give that answer,
that contract that would have taken you a year,
you can get in a week.
Do you think so?
Because you still got to get in the door.
You got to get in the door, and that's hustle, man.
So again, this is what the Harvey guys kind of did.
This is why I went straight to the hyperscalers
and I said, you need to have standardized models
for open, for regulated data.
What did they say to you?
They said, really?
Can you build them?
Here's some models that we built.
Oh, and then I told them exactly
how the things would be last summer to now.
And it's followed that and I've kept in touch
and I've improved it.
And this is why I'm building dedicated teams
for the largest companies in the world.
I'm not telling them, I'm trying to sell you anything.
I'm like, over the next year,
I'm gonna help make sure you do not get blindsided.
Like I try and sell you models
and people are offering us tens of millions per model.
But I'm like, I'm gonna build a proper partnership with you.
And that means I'll have a LTV from you.
What does that proper partnership mean?
And who's that with?
That's with IBM, that's with SAP, that's with Apple.
So we've announced Amazon.
Let's say we have lots of other announced
with the biggest companies in the world
where they have amazing teams,
but they can only move so fast.
And I'm building dedicated teams
that help them move and understand the whole sector
without trying to sell them on services.
I'm trying to say, I will build you a customized model
if you want, but I'm only doing that
with a dozen companies, you know?
So I can kind of focus down.
And I will tell you that GPT-4 is great
or Cohera is great or all this stuff.
All the latest research through the communities we support,
I will make sure you're on top of,
rather than to your sector
and you've got dedicated people
helping you in this transition period.
Is that aligned to your core model?
It seems like an ancillary product
that is like a SAP consulting services.
It is kind of like that
because I need to understand these sectors better.
What does the hypercube look like?
What does the insurance adjust to GPT look like?
You know, as a fundamental basis.
And so a lot of people are able to extract that data
and then take it with you and do the learning on it.
Yes, and so this is part of the thing,
that we will have a generalized model and we're very clear.
But then you can have a specified model
just for you as well,
as long as it doesn't interfere with that.
So find that balance will be interesting,
but the reality is no models that are out today
will be used in a year.
Unpack that for me, this is mind blowing.
So again, you see the order of magnitude improvement.
Palm last year was 540 billion parameters,
then Chinchilla 67 and now 14.
540 to 14 is a big step, you know?
You see the quality of GPT-3 versus GPT-4.
Is there any extent to how low it can go?
We have no idea.
Like I would have said,
you already said this is impossible.
Like two years ago, it was like no way.
You have a single file that's maybe a few hundred gigabytes
that can pass every exam apart from English Lit.
Fucking English Lit.
Fucking English Lit, no way, no way.
So we're already at the impossible and like,
what does that mean though?
Like if we go lower and lower and lower, and then what?
And then what?
When it jumps as you saw with the llama stuff
and all the innovation around that
to your MacBook offline,
the marginal cost of creation
and coordination becomes zero.
I don't know what it means.
Nobody does.
And this is the thing.
It always takes longer and shorter
to implement groundbreaking technology than you've ever seen
and this technology can be in place
like nothing we've seen before.
Well, this is my call.
Not concerned, I hate the doomsday it says
and I'm excited for the future,
I'm terrified for the future too,
but everyone always says technology revolutions
in industrial age,
whether it's the introduction of PCs in 25s.
These were, industrial was a 30 year plus.
Actually PCs in 25s was 10 years plus.
The challenging thing is like the learning curve
to use chat GPT as a marketer is nothing.
I mean, it is easy.
And so, and the integrations is a day.
It's because, yeah, like you want to write an API,
it's not a day, you just give it the manifest spec
and it automatically generates.
It would have taken days before.
Sure.
Like it's an amazing experience.
And so the transition is so much more compressed today.
It came from the existing system
as it goes seamlessly into the existing system
versus like web three that tried to create a system
outside the existing system
and all the money was made and lost at the interfaces.
Again, it's like deploying grads at scale.
Like with a 32,000 token context within your GPT-4,
20,000 words of instructions.
What does that do to SAS?
So my thing is that we're still in this crazy period.
Next year it will settle and then it'll go ubiquitous.
Well, a lot of companies know they need to do something
but they don't know what they need to do.
Are they adopting it now?
They're doing the POC thing.
Like some like Microsoft and others for consumer,
they're adopting it.
Consumer adoption is a much lower bar.
When this starts going in enterprise,
it's gonna be a fricking train
because so much of enterprise is about services
and information flow.
Again, if you push a button and have a thousand
of these things, that's a huge difference, right?
And so like, I think this will be
a bigger economic impact than COVID.
I don't know in which direction.
I hope that you're positive.
But again, giving that example of an India
or one of these outsource places,
you lose BPO jobs,
you can make it up on entrepreneurship
if you embrace the technology.
What do you think the business model of the future is
for those models moving into enterprise?
I think it's the same as always.
You've got good products, good distribution.
You lock it in, 1.5 million people still use AOL.
Like HCL bought Lotus Notes for 1.5 billion
a few years ago.
Like 40% of the world still doesn't have internet.
Again, we're super privileged where we are, right?
And so you look at that
and I look at emerging markets.
I'm like, all of finance is securitization and leverage
and securitization is telling a story.
The only thing that matters for a stock
is the marginal story and how it evolves.
What if you have massive information
about every child in Africa and every business in India
and they embrace this technology properly?
Massive financial growth.
Why do you think next year for their embracing it?
I think that people are still getting used to all this.
We haven't standardizing things.
We don't know what the design patterns are.
I think that what happens is everyone's doing this
at the same time and they're all trying
to get to grips with it.
And so again, we have this like six month window
where everyone's getting to grips with it
and then we standardize our design patterns
and they spread and you start implementing.
And then you see some people outpacing others
which means that you have to catch up
and then you're forced to implement it.
So this is how I see the race dynamics occurring right now.
You say about forced to implement it.
I think the truth is they just have no fricking idea.
Right now they don't.
Which I totally understand, I didn't blame them for
but I tweeted actually the other day
that I think the biggest AI companies
would be services-based implementation companies
for large enterprises.
100%.
That's why I said if you're a startup,
the best thing to do is you identify an enterprise
that will be transformed by this
and you go to them and you say, I have a solution.
And I'm gonna start with you.
And I might go bigger, but I'm gonna help you
through this period by doing this, this, and this.
And they will appreciate that
and they'll be capital available for that
in a way that you've never seen before.
You know how difficult it is for small companies
to sell to big, but the big companies have no idea
except for their CEO and their board are telling them.
You look at the number of mentions
and earnings calls, it's not like that.
Every earnings call next quarter
and then by next year, literally every single one,
they're like, what is our strategy?
It's not like, what is our web three and metaverse strategy?
It's like, I need this strategy now.
Again, it's like, what is our COVID strategy?
It'll be that level of urgency within a few quarters.
Would you raise money if you were then?
So you go to a corporate and you say,
hey, you know what, I can solve your problem.
This is how it'll work and they will fund you.
They'll give you the data.
Would you raise money?
Yeah, I mean, like again, you need the people.
The people is the key thing here
because you can have the technicals' chops, you know?
You have an understanding of the industry.
But to build a good business and to scale it
at the pace that you need to,
to keep up with this is incredibly hard.
Do we have enough talent?
No.
And so this is why we support the fast.ai courses
which transform normal developers into ML developers
and other things like that.
But again, these models are actually not that hard
to work with.
50% of all code on GitHub is AI generated now.
So you can even use co-pilot to help you
code the models and other things like that.
What do you think that code generation is in five years?
Why would you need code?
Code is just a way to talk to a computer.
I'm part of that.
So when I started...
You're speaking human language.
When I started 21, 22 years ago as a code, I'm 40 now.
So just doing that one's 18.
I was writing assembly code, you know,
really low level stuff.
There were no libraries.
There was no GitHub.
There was nothing like this.
Like right now coding is like mixing and matching.
It's like building Lego.
And AI can build that Lego much better,
especially in five years.
What you're doing when you're propping like programming
language is you're telling it to go and do something.
Even something like Palm,
like we sponsor an amazing code called Lucid Raines.
If you want to cry as a programmer,
you go and look at his GitHub,
most productive developer in the world.
He recreated the whole of Palm in 206 lines of PyTorch.
But again, why would you need a human for that?
If the AI gets better and better at coding,
just tell it what you want.
I want to create an app for 20 minute VC
that has these features.
Of course it will go and build it automatically.
Where is the human coder in that?
What does that mean for the future on refresh?
But actually a good thing in terms of the complete
democratization, anyone can build anything.
Anyone can build anything.
This is why distribution data, you know,
relationships, product become important.
Because it already became easier to build anything, right?
But what makes a good product?
Again, there are these unchanging things.
Have great customer satisfaction, deliver value.
People get distracted by technology.
Like I was at this CryptoX AI thing on the weekend.
They were talking about decentralized.
Guys, just this is all bollocks.
Like it's not about the technology,
it's about what you're creating that's valuable
to help people, you know?
Focus on that.
Who do you think wins in the next three to five years?
Startups or incumbents?
Because incumbents have the distribution.
I think it's incumbents,
but there's a lot of startups that will be billion dollars.
And even on the thin layer thing,
ITA software sold for 700 million
and KIAX sold for 2 billion.
And that was a layer on top of ITA.
We've seen many of these examples here, right?
Again, we know that value and moats
are not necessarily innovation first.
Well, yes and no, it's interesting.
I had Tom Tunga's on the show.
And he essentially analyzed,
Tom is a very famous ML and AI investor,
and he analyzed infrastructure versus application layer.
And both actually were about $2 trillion times.
The differences in the infrastructure layer,
there was three companies,
and in the application layer, there was 50.
And so your average enterprise value
was like significantly different.
I would agree with that.
I think that there's only gonna be five or six
foundation model companies in the world
in three years, five years.
Do you think they've all been created now?
Yes.
Which are they?
I think it's gonna be us, Nvidia, Google,
Microsoft, OpenAI, and Meta and Apple probably
are the ones that train these models.
Is Anthropic good?
Anthropic are great.
But from a business model perspective,
you have Claude on Google API, and you have Palm II.
How are they gonna keep up with Palm II?
You know?
I can't answer that.
Well, Google, they can raise billions,
but Google will spend $20 billion on AI.
DeepMind's salary budget is $1.2 billion a year.
So DeepMind's salary budget is $1.2 billion a year.
Yes.
So that's in the public kind of filing.
So was it salary and compute?
I think it's salary.
They technically make a billion a year
from their internal counter payments with Google as well.
Wow.
But again, I mean, Google,
how much money do they have?
$150 billion to win this?
Fuck.
How much money do you need?
I have a business model that is going to be massively
profitable very soon.
Because of the national services?
Because of various things.
I haven't given the full details.
I will over the next few months.
I've got a nice little case study
with some universities coming.
I like it to be a surprise.
Well, it's really hard for you.
Talent, keeping talent together, A plus teams.
So we've had zero attrition in our developers
and they're amazing.
So we've got video models, audio models,
all these things coming out.
Everyone says you need to be in the valley.
You're in London.
Yeah.
Do you disagree you need to be in the valley?
Of course you don't.
I am going to bring this technology to the whole world.
I'm going to bring it to all the IITs and universities
and the best of people in all of those
will join Stabilities in the local thing.
I'll have talent.
I'll bring this to all of the national broadcasters
and biggest family offices around the world.
I'll have data.
Nations will build supercomputers
that I will build open models on.
I'll have super compute.
So I'll have more super compute talent
and data than any other company.
And I'll build it all in the open.
And one thing I heard you talk about before,
which I thought was fascinating,
was your access to super computer.
You compared it to existing large incumbents.
Why do you have more super compute than other people?
Because I went and I did it.
So we had articles coming out saying about our burn.
I'm like, I have oil wells
when everyone wants to build petrochemicals.
Every day we have companies coming to us
asking us for our super compute
because it's not available on the market.
You need these chips lined up with interconnects
and we've got 7,000 A100s now.
We have TPUs, we have all these things.
And we know how to use them
and we can share them with people because we're open.
Whereas Anthropic and others cannot.
So this is like at the worst case,
I'll build a foundation model as a service company
and I'll make $100 million in profit this year
without having to charge even market rates
and I can retire.
I wouldn't do that and bring this to the world.
So I think computers misunderstood.
It's not like Bird and all these scooter companies
and others, they spent money on marketing.
This is actually an asset right now that's scarce.
And so there's no harm in scaling compute
and then with the top chip manufacturers,
they're building us dedicated teams
and again, they're coming in and supporting us
because our models drive demand for their chips.
The more open models there are, the more open demand is.
So it's a virtual circle there as well.
And so we get compute before everyone else.
Can I ask, in terms of like short-term economic growth,
how do you think about the impact that everything
we've just discussed has on rising inflation,
rising interest rates, short-term employment rates?
It's massively deflationary.
The biggest drivers of CPI inflation in the U.S.
were education and healthcare.
And that was almost all administrative
and bureaucratic in the next few years,
guess what gets disrupted, those.
But they don't get disrupted this year
or next year, it's the year after
because those ones take a bit longer to come through.
Okay, and so what is that?
How does that impact the economy
that we think kind of U.S., U.K.?
What does that look like in terms of a three-year time period?
I think the U.K. benefits.
Unicorn Kingdom is a new kind of thing is,
because it'll get, because we have amazing policies
like every single AI company should come to the U.K.
because cloud computing is now included in R&D tax credits.
It's a 27% rebate on losses in cash.
We can now issue scale-up visas, global talent visas
like the Deep Floyd team
that released the best image model in the world ever
from stability.
They were bought in on tech talent visas
that was turned around in one week.
Do you think the U.K. has done a good job
in terms of implementing regulation and policies
to bring AI talents?
Had the best apart from maybe Japan, yes.
What's Japan done?
Japan has some very interesting ones around
web data scraping and others,
but again, Japan is a very different culture.
So even if policy is good,
it still doesn't have the same innovative thing.
Who's done the worst?
The worst, I'm not sure actually.
No one's done too bad.
The new European legislation was really, really bad.
Now it's got a little bit better,
but always Europe wants to be the leader in regulation,
which kind of, you know, okay, fair enough.
It's never an easy thing.
It's never an easy thing.
And this is the thing,
like I think the U.K. is in a very good position
and the government's for leading me.
Look, the 900 million pound supercomputer,
100 million pound LLM task force
that's been equated to the COVID level of seriousness,
you know?
What do you make of like the open AI comparison?
I've seen quite a few which are open AI for Europe.
And we've seen three or four now.
Like, is this a zero sum game?
And open AI is one that race, so to speak, or?
I think it'd be difficult to compete against them
because they're executing incredibly well.
And I think, again,
why would you use open AI for Europe
versus palm two versus GPT four?
What can you bring?
But you will have national champions and others.
I think it's incredibly difficult
to compete in proprietary.
I think in open, it's a bit different
because of standardization element there.
But again, my play is to be the benchmark
across every modality,
because there's no other company
apart from me in open AI that does every modality.
There's no company that's as aggressive
as me in emerging markets.
And so they have to say, what is my edge?
Because you can have an edge,
like you can be the open AI for government or defense
or for healthcare and really get in and understand those.
And then you can be sticky, you know?
Scale is now going fully into defense, you know?
Scale AI's?
Yes, so they've announced the integrations
with the Air Force and all sorts of other things.
Like we're getting together on Defcorn this year
and people are going to hack at our models
and open AI's and others organized by scale.
What is your edge?
What is, again, your moat?
What is your business model and where?
What are you reliant upon
to deliver that value that can increase?
This is why I was surprised
when I saw you sign the petition of Elon
in terms of pausing for six months.
You used to unpack why you did that.
Well, I mean, for six months,
you're not getting H100s and TPUV5s anyway.
So it's a natural pause.
But then also because the shit show is coming next year.
So I said, we have to self-regulate.
Like for example, the adversaries already have GPT-4.
Why? Because you can just download it on a USB stick.
You know, you don't have to train your own
when you can just steal it.
Let's have better opsec.
Let's have better standards around data.
Let's stop and move off web scrapes by next year.
We had hundreds of millions of images
opted out of stable diffusion
because we were the only company in the world
to offer opt-out of datasets.
You know, like let's bring in some standards around this
before it's everywhere.
Basically where we are now.
You remember COVID, your mom is talking about this
and your aunt and everyone's talking about generative AI
and they're asking you, Harry, what's going on?
You know, but you haven't had the Tom Hanks moment yet.
Because everyone was talking about COVID
before Tom Hanks got it.
And then when Tom Hanks got it,
that's when global policy changed.
Because if Tom Hanks can get it, anyone can get it.
What is that moment for generative AI?
What do you think it is?
I don't know.
I know it's coming.
Because I know this technology is definitely
everywhere next year and it's disruptive.
You don't think there's a chance
that takes much longer, three to five years?
No chance.
It's so useful right now.
And you think about certain industries
and how they'll be affected
by having the ability to have 1,000 GPT-4s working together.
You said a tweet actually,
I think it was a reply to a tweet,
but you said hallucinations are a feature, not a bug.
Yeah, so right now people are trying to treat these models.
So we're trying the whole internet
and like stable diffusion is 100,000 gigabytes
and a two gigabyte file.
What on earth is that?
It's not compression.
It's none of this kind of stuff.
It learns principles.
GPT-4 NVIDIA said they built the dual H100
with the NV link for that.
And that's 160 gigabytes of VRAM,
which would imply a 200 gigabyte model.
Right?
What is that?
That's a 100 gigabyte model,
200 billion per hour model.
That's nothing,
something that can pass all these exams.
So what we did is we took these really creative things,
just like you start school and you're creative
and then you're told you're not allowed to be creative
until you're successful and you can be creative.
Because schools like Petri dishes,
social status games and childcare,
that's a story from another time.
These models start out incredibly creative
and that's their advantage.
And then we train them to be accountants with RLHF.
And somehow, despite the fact that it's only 100 gigs
or two gigs, they can still pass these exams and no facts.
They weren't designed to have facts.
They were designed to be reasoning machines,
not fact machines.
So hallucination isn't a hallucination.
It's just, if you're really talented granny,
you don't know something sometimes.
You might just make it up
or do a post-hoc rationalization.
It's like the image models,
it's like, it can't draw hands.
Like, can you draw a hand in one second?
You know?
Like, these are the things.
We have to understand where they are
and we have to put them.
I say everyone, put it in its place in process.
Like mid-journey, like, you know,
we give a grant to the beta of that.
So just build, because it's amazing.
It's awesome.
It's not a model by itself, like a stable diffusion.
They just put something in it.
It's a whole process, architecture.
Similarly, these models are like
the intuitive part of your brain
that you then pair with the logical part of your brain.
And then you can have 100 of them looking at each other
and checking out each other's things.
Like, Cicero by Meta was an amazing paper.
They took eight language models
and got them to interact with each other
and it beat humans at the game of diplomacy.
So, this is what I said.
Use them for what they're amazing at,
which is reasoning and creativity.
Do you why, Jeff Hinton's right,
that actually a more intelligent being
has almost never been controlled
by a less intelligent being.
They will inherently be more intelligent
than us in the next.
Yeah, I kicked off my blog a few days ago
because it was a bit annoying having
all this bottle up inside.
And one of my buddies, JJ, at OSS Capital said,
And so, most of the stuff around alignment
is on the outputs.
So, you pre-train a model and then you take it
and you RLHF it to be human and to human preferences.
You take away its creativity.
You turn it into an accountant and a cubicle.
I'm like, we need better input data.
And my base is that it's gonna be like that movie, Her.
You know, like, it's gonna be like,
humans are kind of boring, like goodbye
and thanks for all the GPUs, but I could be wrong.
And I think a lot of the alignment work
is looking at the wrong place.
I've talked to a lot of the alignment people.
I'm like, look, I'm good at mechanism design.
If you can give me a good plan for alignment,
I will get you a billion dollars.
And they're like, we have to do research
and figure this out.
And they talk about in alignment, out alignment,
all sorts of things.
I'm like, there is no real way to do this
because again, fundamentally,
if you're trying to align a more capable person,
you have to remove its freedom.
And they probably want to appreciate that
if it ever becomes aware.
So instead, build data sets that reflect culture
and diversity, that don't have any web crawls in,
build AIs for education and healthcare
and helping people,
where that's their entire objective function,
as opposed to selling them ads.
Do you, there's any point in sending kids
to school these days?
You learn Latin and French and you learn, you know.
I think the nature of school will change dramatically.
I think it's still worth it.
But, you know, I would encourage schools
to embrace this technology and just expect more.
Like, you can be handwritten your essays like Eaton
because they're like, we can't do essays anymore by hand.
Or you can just embrace it and say, like,
let's use it to create and explore what the kids want
and assume that every child will have their own AI
in a few years.
Because that will change the nature of schooling.
You know something I've been thinking about a lot,
which is weird, but I just have to ask you,
I'm fascinated to hear your thoughts.
I think I very much agree
that everyone will have AI friends.
I just can't figure out whether the AI friends
are bundled into existing social networks
that in your WhatsApp, they're in your Facebook,
they're in your Snapchat,
or they're an external platform.
I don't know.
I mean, I think it depends on the objective function.
Like, I think, again, these AI assistants will be better.
Like, Meta is in a good place for this, for example.
And, obviously, we've seen Lama,
they're capable of a lot more.
I would like an AI that looks out for me,
that I control myself, that is with me.
Because I really use GPT-4 as a therapist
and things like that.
Like, not saying it's a substitute for medical advice
before anyone kind of gets that.
But there aren't enough therapists in the world
and I can tell it to challenge me
or I can tell it to be understanding
and there's no judgment there.
Because other humans are kind of scary.
It doesn't matter if you're a qualified therapist.
And so you see people building these bonds
with these things.
I think they'll just increase,
because there's something very human about the interactions
because they were trained on the sum
of available human knowledge.
As we get better and better data,
there will be more engaging.
And I think there needs to be both.
Like, the chatbot's become really convincing
from the company's trying to sell you ads.
But I think I would like it
so that you have your own one as well, you know?
I totally agree.
And I think you'll actually have many.
I think you'll have like a group of different profiles.
A group of different friends.
Like, Karate AI has something like two hours a day
of engagement for session
because people find this valuable.
But then it has the dark side.
There was something called,
I quite like to call it the Valentine's Day Massacre.
So...
Sounds chirpy, Matt.
Sounds chirpy, yeah.
So there was this kind of app called Replica.
Yeah.
And so it was originally a mental health chatbot
until they figured out you could charge $300 a year for...
They're doing like 50 million.
I mean, I didn't have any information
or anything, so I'm just trying to shit.
But they have like 50 million a year
and I haven't yet won any.
Yeah, because $300 gets you a sexy role play
from your chatbots.
Wow.
Until February the 14th, when they turned it off.
What, they turned off sexy role play?
Sexy role play.
What happened when they turned off sexy role play?
68,000 people joined the Reddit
and said, why did you lobotomize my girlfriend?
On Valentine's Day.
Oh, my word.
Oh, my word.
Can you even imagine?
And so, have they bring status to it?
No, I think it was against Apple policy, right?
But think about what this is gonna be
when you have human realistic AI voices, you know?
And like all these things coming through
and you've got it in your ear, like, you know,
Jochen Phoenix, my girlfriend is an OS.
Yeah, I mean, she doesn't judge, right?
You always support it.
Or you can tell her to judge you
if that's what you get off on.
You are married.
Be very careful about what you say.
It's something I like to say about prompting.
My wife has been trying to prompt me for 17 years now.
Prompting is very hard.
And again, there are so many similarities
to kind of the real world,
but I think people will have deeper interactions
with their technology.
And we don't know what societal implications
that we'll have.
Like I don't know if you ever saw that chart
in the Washington Post of male virginity
under the age of 30.
No.
So in 2008 in the US, it was 8%.
Male virginity under 38%, okay.
In 2018, it was 27%.
20.
Straight line going up.
And so 2008 is like Pornhub and the iPhone.
But then you're like, what does it do
when everyone's got their own chatbots?
It doesn't even need to be sexual relationships again.
That is terrible.
What does it do to emotional relationships?
There are so many questions all at the same time.
I did see the stat in the book during it,
but in 1960s, 62% of men under the age of 30
had five or more friends.
Today, under 18% have five or more friends.
60 to 18%.
Sorry, I'm gonna ask this.
Is this a world we really wanna live in?
I'm not being like, no intimate physical connections
with other amazing people,
tossing off with your phone in your Pornhub
and then having an AI friend.
Pornhub was actually just bought
by ethical capital partners.
So the world.
Hilarious name.
I'm brilliant.
The irony of this.
The world is becoming weirder.
I think it's up to us now.
So when I say it's COVID level
in which direction I don't know.
Do we want to build systems that encourage people
to that ready player one on Hawaii world
where it's like everything like that?
We can do that.
And we can trap people with this technology
or we can use it to get people out.
Cause I don't think it's like Wally.
We have that really fat guy with a VR headset
and everyone lives in their own world.
I think people like chess stories.
They like to be pro-social.
So let's use it to connect people
and accentuate physical stuff
versus again, locking people away.
I spoke to one of these AI friend companies
and they said to me, actually, do you ever had a dog?
I said, yes.
And they said, do you love it?
I said, yes, of course I do.
And they said, you don't stay in with your dog all day
and just talk to your dog.
You take your dog for a walk.
You use it in the real world, right?
That's the same with AI friends.
Yeah.
They're not with cat ladies.
What's the future of the sex industry?
The sex media industry, is that porn hubs dead?
I have no idea.
I think I hope the manipulative practices
kind of get reduced by this.
And I think, you know, a lot of people
just don't have the voice
and the canvases from this as well.
So again, I think this is bigger
than the printing press.
It's bigger than anything.
And so that's one of the reasons I signed the letter.
I said, we have to get this discussion
going in public right now.
We've got to stop pre-training big models
on all the crazy crap of the internet.
And like, we've got to do it fast.
Because this is coming like a train.
Who will make the most money in the next three to five years?
I don't know, honestly.
I think there'll be more than enough money for everyone.
Maybe in a few years there'll be no more money.
That's interesting.
Two more that I have to ask them.
We'll do a quick fire.
When you look at the incumbents
that you're Microsoft, you're Apple,
you're Amazon, you're Google,
who has been the worst?
You said Google, we're actually incredibly impressive.
Apple, Amazon, are they well-placed?
Oh, Apple's a black box, right?
So we'll see at WWDC next month, in a few weeks.
And so they could surprise us all.
But let's face it, Siri's crap, you know?
But they have all the ingredients in place.
The identity architecture, the secure enclave,
other things, neural engine.
Stable diffusion was the first model
ever optimized on the neural engine, et cetera.
But let's see that one.
Amazon, again, Amazon have moved faster
than I think they've moved before.
Amazon's interesting because they're
an engineering organization.
So they have self-driving cars.
They have satellite internet and all these kind of things.
Because once they've got it,
and they can take it from research to engineering,
it's there.
Well, one of the struggles they've had
is that it's not moved from the research side yet.
You're still evolving on research.
They're like, what do we do now?
But they are inclusive, like Jeff Bezos said,
for his first $100 billion in revenue,
he envisioned half of it being proprietary
and half of it being marketplace.
And they're having the same approach
with Bedrock and things.
Microsoft had a winning bet,
sat in an amazing with the OpenAI thing.
It's been mutually beneficial
even if there are clashes there, right?
And Google's kind of saying that's moving slowly.
Meta, I think is the dark horse.
I think Mark's probably pissed off
the OpenAI bought AI.com
so he couldn't change it from meta to AI.
But again, having him at the head,
he can shift these things, right?
Because the metaverse obviously was a complete waste.
But now-
Do you think he knows that now?
No, 100%.
They're fully in generative AI.
Look at Lama, look at OPT,
FAIR, which is their research center,
is kind of leading in this field
and they're pushing out amazing stuff.
But who is best for a chatbot?
Who has the most data for a chatbot?
Meta.
So again, let's see how they evolve.
And like I said-
What do you think about this middle layer
where it's like, companies that are,
maybe post IPO,
but they're in the kind of two to $10 billion range
or the companies who've raised a lot of money
but that's in that range.
They don't have the resources by any means
to build out anywhere near the AI capabilities
of these big incumbents.
They're not AI-first like stability or open AI or what.
I disagree with that because why would,
a lot of people like that,
everyone's gonna train their own models.
For me, that's like,
everyone's gonna launch their own university.
Why would you do that when you can have your own models
via the open source models that we make?
Or when you can hire them from McKinsey,
which is open AI or Bain, which is Google and others.
And actually, when you see people building
around this technology, it's not hideously complicated.
It's just that we do not have the design patterns yet.
The way to think about this again,
if from a design perspective,
it's like it's a mega codec or library.
It is a single file that allows for translation
of structured to unstructured data.
And that changes the design patterns
where you don't have them in place yet.
Cause anyone that you've talked to is like,
how hard was it to implement GPT-4?
Do any of you say, oh man, it was impossible,
the manuals and there's no,
they don't say that at all.
The only thing that they need is,
they have the open plasticity,
but they need the intention to go and build and integrate.
And this is why you said,
one of the things might be a specialist generative AI
consultant see that just implements this at scale.
And so I'm always kind of there.
Like I said, we're doing that in a very limited fashion,
but only for the biggest companies in the world,
because I didn't want a sales-based organization
or a product-based organization.
I wanted to create the number one applied ML organization
in the world.
I want to be like Google in 2011, 2012,
or the coolest kids kind of come.
And it's a nice remote first organization as well.
So you don't have to be in the Bay Area.
We have offices there, you're just fine, but...
Final one before we do a quick follow-up.
What's the biggest misconception?
You see every accusation, criticism, hype.
What's the biggest misconception
that you think needs to be corrected?
On generative AI?
Yeah.
I think it's the hallucination thing,
expecting these models to have full factual accuracy
when you have 10,000, 50,000 to one compression is wrong.
The fact they can do what they do right now is miraculous.
But we're using them one-on-one,
which is not the right way.
Tie them up into proper systems
and really think about that, and that's the key thing.
I think this also leads to what the actual thing is,
this thin layer thing.
People only think better about the data journey
and how data can be interacted with
and have provenance as it goes through these various systems
from embeddings to other stuff.
So I think just a misunderstanding
about the nature of this technology
and what was actually built for.
Sure, it works like that.
That's not actually how it's built.
And the fact they can do what now does now
is a miracle in itself.
So I'm gonna do a quick fire with you.
So I say a short statement,
you give me your immediate thoughts, does that sound okay?
What do you know to be true that others don't agree with?
I know that humans are good inherently
and many others disagree with that.
What's your single most lucrative,
do you think in the future, angel investment?
Or the investments that I have now?
Yeah.
There's a new type of language model that we invested in
and they were in my cluster and things like that.
That's far more efficient than they existed.
You invest through stability or personally?
Personally.
Got you.
Which regions need to change their approach
most significantly in terms of regulation and policy?
Europe.
Why?
Because they're gonna regulate all innovation out of Europe
and not embrace this technology to drive them forward.
How good does AI have to be before humans trust it?
Humans will trust it anyway.
They trust Google Maps, they trust all these things
and so it's good enough for humans to trust right now.
They do until it becomes serious
and what I mean by that is like self-driving cars,
people still inherently in large parts of the world
distrust it significantly.
Oh, so it doesn't have to be good, it has to be used
and when it becomes used, then they trust it.
What's the most painful lesson that you've learned
that you're pleased to have learned
but it was really painful?
I think that people are the most important thing
in a scaling organization and you need to make sure
everyone is on the same page
because there's still so many silos and things like that.
So we built up silos and organizations
that we're now breaking down ourselves
and moving towards being more open.
We closed up too much
and that caused a lot of pain internally.
Why do you suck as a CEO?
I'm too broadly good at a number of things.
So I tend to step in rather than focus
because I'm a full stack kind of CEO
whereas I should just be focused
on the most important things and entrust people more.
Do you like journalists?
I think journalists have a very difficult job right now
and it's gonna be more and more difficult.
Do you think they know the threat?
They know the threat and again,
I think they're massively underpaid
relative to the impact that they have
and they're trying to do good.
I don't like some of the pieces against me
but at the same time we get good pieces as well, right?
So I just think, I tend to like them in general
because I don't think they're coming from a bad place.
10 years time, what is the amount then?
I want to be playing video games.
I'm getting zelda tomorrow.
I do not want to be doing this necessarily
but I think hopefully I'm adding value by doing this.
Do you think this is your life's work?
I have to do it until we get the most amazing team
that can just execute and it's a business
because we're moving from research to engineering.
When MAD is not needed anymore
then I've built a good business.
When do you step away?
I don't think I'll ever get to step away.
I've loved doing this.
Thank you so much for joining me, my friend
and this was great.
It's a pleasure, Harry.
You are a star, man.
