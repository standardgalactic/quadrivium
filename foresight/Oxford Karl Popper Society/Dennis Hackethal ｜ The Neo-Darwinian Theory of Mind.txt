So everyone can hear me then. Good afternoon. I'm very pleased to announce their speaker
today is Dennis Hackenthal, who is a software engineer, artificial intelligence researcher
and author of the book, A Window on Intelligence. And today we'll speak about the role of replicators
in creativity, a topic in which Dennis has written for Conjection Magazine in an article
called The Neodorinian Theory of Mind, which we've linked to on Twitter and which we'll
link to in the video as well. And I should also say that I think Conjection Magazine
is open to pictures from writers, for those of you who are interested in possibly contributing
an article to the website. And in general, I also really recommend checking out Conjection
Magazine, I think is a great initiative. And yeah, with that introduction, I give the floor
to Dennis. Dennis, thanks so much for joining us. And I look forward to your talk.
Hi, I'm glad to be here. It was very nice of you to invite me. And I should also mention
Logan Chipkin, who I think is behind this. So shout out to him as well.
Yeah, shout out to Logan.
Yeah, so I'm here to talk about what I call the Neodorinian Theory of Mind. Before I start,
I should say that to give credit where credit is due, I'm indebted to Karl Popper and David
Deutsch, because without their epistemological work, I could never have thought of what I'm
about to tell you. And also Richard Dawkins, who's influenced my thinking on evolution
quite a bit. And it occurred to me recently that maybe the Neodorinian Theory of the Mind
is much too grand a term. I think maybe it should be called the Neodorinian aspect of
the mind or the Neodorinian approach to the mind or something like that. I think that
would be a better name because I think theories of the mind are a dime a dozen and none of
them work. And otherwise, we could already build AGI, artificial general intelligence.
And so it might be better to choose a smaller name than that. But also there's some construction
going on outside. So apologies if you hear anything, if there's any noise. But yeah.
So the meat of the theory of the approach or whatever you want to call it is very simple.
But it does take just a moment to kind of sneak up on it. And so in the papyrian fashion,
what I'd like to do is I'd like to start with some problems. Some problems that I like to
think that the theory or the approach solves are, for example, one, how does the mind create
new conjectures? Two, how does memory work? Which includes things like why do we forget
things? Why are memories so unreliable? Why do some memories last longer than others? Those
kinds of things. And how did people evolve? And then lastly, I want to give by no means
any theories just some small pointers for why I think we are conscious of some things
and not of others. It's interesting to note that originally I only set out to solve the
problem of how people evolved. And then I later found that this approach also allows me to
solve these other problems. So I only have a few slides. This is the last slide. I'll leave
this open. I want to give, I actually want to start in biology. And then I'll tie this back in
with a mind later on. I promise they're related. And I'd like to talk about the origin of life
for a moment. And many have said that what happened there was so unlikely and incredible. It's
almost too good to be true that that happened. And as far as I understand it, there are still
some mysteries around it, what exactly happened there. But there are some good explanations
that I think give us a pretty good idea of what may have happened. And the theory that I
subscribe to is called the RNA world hypothesis. And the idea is basically that a long, long time
ago when the Earth had just formed, the oceans were still highly chemically active. And there were
molecules forming spontaneously in those oceans and disintegrating. And it was a big mess. It was
a big chaos in this so-called primordial soup. And what some of those molecules were is they were
enzymes, they were chemical catalysts. And what that means is that they were able to, they were,
they were able to cause a change in other molecules, for example, while retaining the ability to cause
those changes again at a later time, they didn't undergo any changes themselves. And what happened
then, so to say, that some of these molecules happened to, to cause chemical reactions that
produced some of their own components. So that in this primordial soup, over time, you would get
more and more of the building blocks of which these molecules themselves were made. And so what
I'm kind of sneaking up on is the role of replication in biological evolution. Because once
these molecules, once these enzymes get targeted enough, it makes sense to call them
replicators, because that is what they end up doing. They create a copy of themselves. So the
idea is that this way, gradually, we get replication happening in the primordial soup. But
this alone isn't enough for evolution to occur. You also need variation in selection. But I think
once you have replication, variation is bound to happen sooner or later, because replication is
not going to be perfect forever. And sooner or later, the replicators are going to make a mistake
during replication. And this is what introduces variants. And what you get then is you have, if
the variant is even fit enough still to keep replicating, what you get then is you have slightly
different kind of replicator. And if that is still able to replicate, now what you're getting is
you're getting two different pockets of this population. One pocket of the population is still
the old replicator, the copies of that replicator. And the new pocket of the population is this new
kind of replicator. And so then the question is, well, which one is better at replicating than
the other? And these differences in the rate of replication is what we call selection. I think
Richard Dawkins in his book, The Selfish Gene, I think he uses the technical term as the non-random
differential reproduction rate or something. And usually, because a replicator is already adapted
to replicating, that means that any variant, if a mutation is going to occur, more often than not,
it's going to be worse at replicating. So usually, you could expect that if the replicator mutates,
the mutant variant is going to have a harder time replicating. Because by definition, this is how
William Paley, I think, defined adaptation, something is adapted to something, for example,
replication, that by definition means that if you make any slight change to it, it's going to get
worse. It's very difficult to get it to make it better. But every now and then, a mutation can
lead to a benefit. And by benefit, I don't mean that there is some well-meaning force in the
biosphere. It just means that it helps the variant spread through the population of replicators at
the expense of its rivals. And I think it's important to keep things simple when it comes to the theory
of evolution. Really, all that the replicator wants to do, I say in scare quotes, it's not a
conscious being, but all the replicator wants to do is spread through the population of replicators.
So it's all it cares about. And sometimes, in service of that goal, complex adaptations can
arise. So I'm going to start tying this back in with the mind now. Carl Popper said that the
information that is stored in such replicators is adapted. And so therefore, it's knowledge.
Adapted information is knowledge. Or maybe that particular phrasing originated with David Deutsch.
And Popper's conjecture is that people also create human knowledge by evolution. So evolution, in
that sense, is not limited to the biosphere. Excuse me. Although there are important differences
between biological evolution and the evolution that occurs in our minds, there are strong parallels
are strong parallels between them. And so Popper offered this analogy of a new conjecture that
people come up with being analogous to the mutation of a gene and criticism being analogous to the
selection of a gene. And the old theories that we derive knowledge from the census, for example,
which is empiricism, or that we create them by extrapolating repeated observations, which is
inductivism, which is completely false, as Popper explained. And instead he argued that we
create knowledge by starting with problems, not with observations, which are conflicts between
ideas as David Deutsch defines them. And then we guess solutions to these problems and we criticize
them until we hopefully come up with a solution that we deem good enough to adopt tentatively.
And this is not only scientific knowledge that grows that way. All human knowledge grows that
way. And an example I like to give is that of losing your keys. If you're not sure where your
keys are, and let's say you need them now because you want to leave, really all you can do is guess
where they might be. So maybe you left them on the kitchen counter. So that is a tentative
solution to the problem. And then you can go look for them there. And if you don't find there,
then you know that your theory was false. And so you have to guess another solution, maybe they're
in your pocket or something. And if you find them there, that's great. Then you've made progress.
So knowledge, even in the most mundane scenarios like that, knowledge grows that way.
And I do think that Popper was right about all of this. And I even like to think of them as the
foremost artificial general intelligence researcher of this time, although I don't think
he would have called himself that. But as should be expected, if we're papyrans and fallibilists,
there are open problems with hispistemology. And these are some of the open problems.
The open problems I mentioned at the beginning are some of those. So just to reiterate them,
those were how does the mind create new conjectures? How does memory work? How did people evolve?
And then the big one is consciousness.
And to solve them, what I would like to suggest is the following, that if we can think of the
biosphere as an arena of self replicating genes, that analogously, we can think of the mind as an
arena of self replicating ideas. Now, having said that there are still many important differences
between the mind and the biosphere, I don't by no means do I want to equivocate those two.
But I do think there are strong parallels that may help us explain some things.
I should also mention, once I say replicating ideas, we may jump to memes, which are Richard
Dawkins idea of the cultural unit of a replicator. Those are not what I mean, just to clarify. Memes
are ideas that replicate across minds. Memes are not just funny pictures on the internet.
It's basically any idea that manages to jump from one mind to another, or at least enough minds that
it becomes meaningful to call it a meme. So a joke is a meme, but also catchy song could be a meme.
And with the example of the joke, I think this is an example David gives in his book.
You know, if the joke is good enough, then it causes the holder, the person who knows the joke,
to tell it to somebody else. And so now the joke is in two minds, not just one. And that's why
it's meaningful to call it a replicator. But again, I'm not talking about memes here. I'm only
talking about ideas that replicate strictly within a single mind. So it can help, I think, to just
think of a mind that's just cut off completely from the outside world to make things easier. So you
can just imagine a brain in a vat, if you like, doesn't have any access to the outside world.
And still, I think there would be self replicating ideas in the mind. It's also a nice way to
make sure that we can't accidentally adopt any empiricist or inductive notions if we just completely
disregard sense data. And so I think with this simple premise that the mind is an arena of
self replicating ideas, we can now start solving the problems that I mentioned. And I think when it
comes to the question of how people evolved, I would say that the evolution of the mind and
the evolution of people is analogous to the origin of life in the biosphere. Because I'd like to
suggest that the evolution of self replicating ideas in a mind happened analogously to the
evolution of self replicating molecules in the primordial soup. And I think what happened is,
well, so this is Popper again, so all organisms contain knowledge in the objective sense,
meaning, for example, wolves know how to hunt in packs and dogs know how to fetch balls, beavers
know how to build dams and so forth. This all takes knowledge. All of these activities have
the appearance of design. So we know that there must be knowledge behind them. And that knowledge
is stored in their genes. And so we could just call the knowledge that results in these behaviors.
We could call those ideas in the objective sense. And the set of all ideas that an organism has,
I call its idea pool. And some of these ideas, I think, act just like the enzymes,
those molecular catalysts from the primordial soup. They're able to make a change in other ideas
within the same organism without undergoing any net change themselves. And in one of our ancestors,
because of a genetic mutation, there was one such idea, one such catalyst, that happened to
promote the production of ideas of which it itself was made. But more technically speaking,
you could say that it happened to promote the production of source code of which it itself was
made. And then the same thing happened that happened in the primordial soup. Whenever that
catalyst happened to become a little more targeted, it produced more of its components more
faithfully, until at some point you could say it was targeted to meaningfully call it a replicator.
Except this time it's not a molecule that self replicates. It's not a material, a physical thing.
It's an abstract thing. It's an idea. And this thing now replicates over and over
during that single organism's lifetime. So in addition to biological evolution that we have
happening, we now have what we could call mental evolution happening during that single organism
lifetime. I also call it runtime, the runtime of that software. And like I said, just like in
the primordial soup, once you have replication, well, replication is not perfect forever. Even
the best replicator makes mistakes every now and then. So sooner or later, variation and selection
will kick in. And that's how you get evolution in the mind. And so that's how you get a dynamically
changing idea pool, much like you have a dynamically changing gene pool in nature.
And this is how this organism can now create new knowledge, knowledge that was not genetically
given. And that's something people do all the time. Everyone in this column is doing it right now.
And I believe that this, what I've laid out is the underlying logic that allows them to do so.
So we've solved now the, I mean, hopefully, we've solved the problem of how people evolved.
And the second problem also, which is where do conjectures come from? I think they're just
the result of a long string of ideas replicating them perfectly, accidentally morphing into a new idea.
And we can also explain now how memory works. Memory,
as with so many things of the mind that are unfortunately explained on the level of the brain,
memory is often explained on the level of neurons. And so I'm going to butcher it probably, but
one idea that I've heard many times is that one set of neurons is said to encode one idea. And
then if that set is wired to another bundle of neurons, then whenever one thinks of one,
one also thinks of the other. So this is how associative memory is explained.
And also they say that the more you think of those ideas, the stronger the physical connection
that these neurons get. I think that's completely false. I think it's reductionist. And it also
sounds a bit like there might just be a tinge of Lamarck's use and disuse theory sprinkled in there.
But I think the reason that can't be true is that we know from computational universality,
here I'm influenced by David Deutsch again, that we know from computational universality
that we could simulate a mind on a computer, including that mind's memory, even if that
computer hardware doesn't have any neurons. So you don't need neurons. We need to explain
memory on the appropriate level of emergence. And that is software, not hardware.
And I think with this approach, the new Darwinian approach with the replicator approach,
we can answer the question of how memory works. In the biosphere, some species survive
for much longer than others, although it's really the genes that we're concerned with,
not with the animals themselves. And I think the same is true in a mind. Some self-replicating
ideas just manage to stick around longer in that mind's idea pool. And those replicators that are
longer lived than others and happen to encode events from the past, those are the ones that we call
memories. But there's nothing else that's special or different about them that separates them from
other ideas. I think memories are usually thought of as a special class of idea. I certainly used
to think of them that way, but I think that's wrong. And then when a certain population of ideas
and coding memory dies out, let's say because they can't compete with rival ideas in that idea
pool, then that's just what it means to forget something. And we can also explain why memories
are so unreliable. It's because replication isn't perfect and mutations happen eventually.
So memory is just an emergent phenomenon of that underlying pool of self-replicating ideas.
And memory being unreliable is just a special case of knowledge being unreliable.
And now just some small pointers for when it comes to consciousness. Why are we conscious
of some things and not others? Popper conjectured that consciousness has to do with disappointed
expectations. I think this was in his book, Objective Knowledge. If I recall correctly,
he gave this example of walking up a flight of stairs. And if you get to the top and you think
that there's one more step, but there isn't, we've all been there, it feels very weird. And you,
not only are you surprised at that sensation, but you also realize that you had an expectation
that there was another step. And you wouldn't have realized that if there had been another step.
So this is what why Popper argues that consciousness may have to do with disappointed
expectations. Something I'd like to add to that is that when we, for example,
when we're children and we learn how to ride a bike, initially this process is a very
conscious, effortful process. We're very aware of everything we're doing. We're aware of the
peddling. We're aware of keeping our balance. We're aware of steering and everything because
all of this requires error correcting. But as you get better at riding your bicycle,
as you get better at riding your bicycle, you become less aware of those things.
Until now, when I ride my bike, I don't really know how I do it anymore. I just do it,
but I couldn't tell you how I keep my balance, for example. And that allows me to free up my
attention and focus it on the road, for example, so that I can avoid potholes or avoid accidents.
So it seems to me that consciousness has to do with error correction, generally.
And I'd also like to add this observation that I think what's curious is that despite the mutations
of ideas that we know must be happening in our minds because mutations are inevitable,
we never seem to be aware of any junk ideas. But if mutations are usually detrimental,
and only rarely beneficial, that must mean that at any given moment, there are probably
many of these junk ideas in our minds, but we're never aware of them. I think that's curious.
So I conjecture that maybe a necessary condition for something to enter our consciousness
is that it be sufficiently adapted by some yet to be defined criterion. Now, to be clear,
none of this explains consciousness by any means, and it's not meant to. But these are just some
pointers. Something else that I think this approach allows us to do is we can start thinking, taking
maybe what Richard Dawkins would have called the genes I view, and we can take the
ideas view, ideas I view, I guess it would be called, and think about what it would be like for
an idea to live in that self-replicating pool of ideas. And we can think about different
replication strategies that these ideas may have and what effect this could have on the mind.
So now I do want to take it back to the level of memes for a moment. Dave, do I just conjecture
that there are two different replication strategies for memes, static and dynamic.
And I quote from the beginning of Affinity, a dynamic meme is an idea that relies on the
recipient's critical faculties to cause itself to be replicated. So these are ideas that,
broadly speaking, help progress and they help their holder make progress. They can at least.
And opposed to that are static memes or anti-rational memes. And those are quote,
an anti-rational meme is quote, an idea that relies on disabling the recipient's critical
faculties to cause itself to be replicated. So these are ideas that prevent criticism of themselves
and thereby prevent their holder from making much progress. And so
the David Deutsch calls the societies that are dominated by either kind of those memes,
static versus dynamic societies. And so static societies, he says, are the kinds of societies
which rarely ever change on timescales that the people living in those societies could notice.
Whereas the dynamic societies change rapidly and they can make rapid progress because they're
dominated by dynamic means. So those are the memes. But what I wonder is if we could
introduce the same replication strategies inside of minds. So instead of the level of society,
we're now looking at the level of the mind with ideas being the individual actors, not people.
Or ideas, or I should say the self replicating ideas in a mind being the actors, not memes being
the actors. And so that could then lead us to identify, say, certain minds as static
and certain minds as dynamic or more or less of one of the other. And then we could think about
how static minds differ from dynamic minds and maybe what that would mean for mental ailments
and their alleviation. Given the damage that static memes can do to static societies,
or societies, I would not be surprised if static ideas inside a mind can also do great damage to
that mind. And I would expect a static mind to have a much harder time making progress than a
dynamic mind. And perhaps, just like a static society, a mind that's dominated by static ideas
would be overly concerned with faithfully enacting some lifestyle and focusing too much on prevention
strategies, which isn't sustainable. I'm borrowing here from Dave Deutsche again, which isn't
sustainable because the mind would eventually encounter a problem that overwhelms completely.
So that's just an idea to play with. Maybe we can find something interesting there
when it comes to replication strategies inside minds. And then one last thing that I'd like to
mention when it comes to the approach itself is another reason or another explanation for why
you cannot download an idea from one mind to another, which is a direct conclusion from Popper's
critique of what he called instruction from without. It's not like we need another explanation,
but I think this maybe illustrates a little more. So as a thought experiment,
let's say that we have the technology to read people's minds or read their ideas somehow.
It doesn't matter how it works, but let's say you somehow connect their brain to a computer
interface, and then the program in that interface parses all the ideas in that brain and presents
their source code to you. So you could read them technically. And let's just say that's a given.
And let's say that you could then, via the same interface, you could connect to another person's
brain, and you could just copy-paste the idea from one brain to another. So technically,
couldn't we say that that would constitute a successful download of an idea from one mind to
another? And maybe we could, but even if so, I think it still wouldn't refute what Popper meant
when he said that instruction from without is impossible. And I think the reason is that
the transferred idea, once you copy and paste that idea, it most likely will not make it in the new
mind. It's a bit like taking a penguin from an arctic on a place you get in the African jungle.
That penguin is not going to survive, because I think our minds are all extremely different,
just like extremely different ecosystems. So placing an idea from one mind is not going to
make it. We shouldn't expect it to survive in the other mind. The idea, if we want to
get the second mind to have that idea, a much better approach, I think, is to get that mind to
evolve the idea itself, in other words, through persuasion. So this is the new Devonine approach,
more or less, in a nutshell. What I'd like to do is respond to some criticism that the approach
has received. And I'll start with Ella Hepner, who most notably has offered several different
criticisms of the theory. One such criticism says that replication is wasteful. It's computationally
wasteful. And so there wouldn't have been enough memory in our early ancestors' brains for ideas
to replicate. And now I mean memory in the sense of storage space, not in the sense of remembering
things. So my response to that is I'm not sure that that is true. Many complex animals already seem
to have enough spare memory to store additional information during their lifetimes. And in particular,
our ancestors must have had enough memory, at least memory that was free at the time of birth,
for them to copy and store relatively complex memes, at least complex compared to other animals'
memes. Now to be clear, they didn't replicate those memes creatively because this is pre
the evolution of minds. But as David Deutsch points out in the beginning of infinity,
meme evolution already drove the evolution of our ancestors. So there was already selection pressure
favoring the development of ever more free memory in our ancestors' brains so that they
could copy ever more complex memes. And that would have been space that our ancestors'
self-replicating ideas could have used. On the note of memory, I would think that
biological evolution, even long before the evolution of people, would have discovered
basic memory management solutions, such as garbage collection, for example. Garbage collection,
I don't have a computer science degree or anything, but my basic understanding is that garbage
collection is a way to monitor a program's memory usage and monitor its memory pressure.
And if you only have so much memory available on your computer and your program is using,
say, 95% of it, then the garbage collector will go in and look for any stale references
to data that you're not using anymore, that the program isn't using anymore, and then it just
deletes those references. Though I may be butchering now, but I think that's the gist of it.
And I would expect that evolution would have stumbled upon something like that much earlier,
because it seems to me that any organism that can store additional information during its lifetime
would eventually run into memory pressure issues. And so evolution must have evolved,
there must have been a solution to this problem. Also, these increases in memory that I think are
needed for those self-replicating ideas, they would have happened very gradually. So I'm not
suggesting that once self-replicating ideas came on the scene within minds that suddenly brains
had plenty of extra storage, certainly possible that initially there wasn't all that much extra
memory to go around, but maybe just enough to help that adaptation spread. And then there was
selection pressure, biological selection pressure to increase memory in humans brains if that
adaptation was helpful enough. By some accounts, there was a large and relatively sudden increase
in memory in our evolutionary history, and I've heard theories that attribute that to a change
in diet or upright posture or opposable thumbs and all that stuff, but it could also be possible
that that increase in memory in our brains was caused by the selection pressure I've just described.
And lastly, for this particular point, the claim that replication is wasteful or redundant
in the sense of being unnecessary, it reminds me a bit of, although this criticism is not meant
as a creationist standpoint, but it reminds me a bit of what a creationist might say about
replication and biological evolution. A creationist might think that genes carrying
the same knowledge millions of times over in each organism is unnecessary. To them, it might seem
much more parsimonious and efficient to simply say that a single entity, God, for example,
contains a single copy of all the knowledge that's required to create each organism,
and then each organism is just the result of him doing that.
Okay, then another criticism that Ella has offered is the self-replicating ideas. They sound
dangerous. They could have led to all sorts of dangerous behavior in our ancestors,
and so biological evolution would have selected against them. I don't think this is true either.
I think animals around us are evidence that they contain sophisticated knowledge with
enough reach to guard against unwanted behavior, for example,
being stuck in an endless loop or something. I've tried this. Even a well-behaved dog won't repeat
a trick forever when instructed to. It'll only do it so many times. It just stops at some point.
There seem to be built-in criteria that can override erroneous behavior. It seems to me that
biological evolution has already has built-in safeguards. Self-replicating ideas wouldn't
automatically have led to ever repeating behaviors or something that would
certainly cause death for the organism. I think actually the opposite is the case.
Self-replicating ideas were then and are beneficial, and they helped the genes spread
that code for them. Because whenever there was a detrimental genetic mutation present in an organism
that led to a bad mutation in one of those organisms' ideas, it was thanks to those
self-replicating ideas that there was an opportunity that broke in functionality
with working functionality. Because detrimental mutations are much more numerous than beneficial
ones, that actually means that the existence of self-replicating ideas was favored by biological
evolution up to a rate at which detrimental mutations occur. I think there would have been
strong selective pressure in favor of self-replicating ideas in mind because it would have helped the
genes spread. And then Ella has offered another approach that one could implement the same
algorithms, the same self-replicating idea pool without replication. And the idea is basically
you just have a single instance of each idea and a score or weight that you attribute to each,
and then increasing and decreasing the weight as you go. And David George recently independently
suggested this criticism as well. Now, it seems to me that denotationally that sounds
similar to my theory, and I think Ella in particular has in mind, although she's here,
she should correct me on this, but I think Ella in particular has in mind what's his name,
Donald Campbell's work on evolution, that you don't really need replication so the argument
goes, you just need variation and selection. Imperfect replication can be the source of
variation, but it need not be. Now, I've said in the past, and I'm still of the opinion that I'm
agnostic as to the question of necessity, but if we were to make this change, I think it would come
at some costs. The one thing that I think the New Darwinian approach, the approach that does adopt
replication brings to the table is that we can explain how people evolved. I'm not sure how we
would do that, because it allows us to explain with a very simple accidental small mutation.
I'm not sure this algorithm that would store and decrease weights, we would have to explain
how that one came about. That seems to require a different explanation that I'm not aware,
I'm not familiar with. And then the question is, when does it decide to mutate an idea and
why and how, and at which location in the idea source code?
It also seems to me that such an algorithm would make plant mutations, but in real evolution,
mutations are not planned. So, what I like about the, what I like about my approach is that
none of these questions need to be answered in explicit programming. These are all just
things that automatically fall out of having self-replicating ideas.
So, in a way, actually structurally speaking, maybe it's the pool of self-replicating ideas
that's more parsimonious, because you don't need to explicitly program any of these other things.
And if the goal of that approach is to, if the goal of that approach is to get rid of replication,
because it might be wasteful or redundant or whatever, then the thing is, let's say you'd
have one instance of an idea and you'd have a weight associated to it, and let's say at some
point this master algorithm decides to make a copy of it and mutate it, and so at that point
you would store a second entry, and over time you would get more and more entries in some registry
of ideas or whatever. And I think then you would still get source code that is shared among many
of these entries, and so it's a little bit similar to what Dawkins has pointed out with in regard to
the cisterns and the DNA versus the genes, which he defines separately. The cisterns,
or maybe butchering the term, but I think that's what is called the cisterns, are like the actual
section in the genome that code for eye color say, whereas the gene he defines as the longest
possible stretch of the genome that gets replicated over and over without changes.
You'd get a very similar phenomenon in this registry of ideas where you'd have sections
of those ideas that stay the same across those entries, and then that would be the replicator.
So although the idea is set out to get rid of replication, I'm not sure it actually does.
And I think what's nice about adopting replication is that it gives us consistency
with other evolutionary phenomena that we know exist and we know are powered by replication,
that's biological evolution and meme evolution, and I think that consistency is valuable
because it means that we can share knowledge between these different disciplines.
So I like to think that this new Darwinian approach has a unifying character and I think
that's worth keeping. And we couldn't, excuse me, we couldn't investigate the static and dynamic
replication strategies in the mind anymore without replication. Those really are replication
strategies and they don't work without replication. And then the last criticism that I'm familiar with
that Ella has offered is that it's unclear how the mind creates and discovers problems
and contradictions and that that's the driving force of creativity. So that's a really important
thing to answer. And I agree with that. So I want to clarify. My current idea is that
when there are populations of ideas that are competing in a mind, especially when they compete
fiercely over resources, memory, for example, then that leads to cognitive dissonance that
the cognitive dissonance that we experience when we experience a problem. And depending on the nature
or the fierceness of the competition that we may, a problem may seem interesting or annoying or
downright depressing, like I said, depending on the nature of the competition. And then when we solve
such a conflict, it could mean, for example, that there's a third population of ideas that
has evolved and operates as a sort of mediator, enabling the two conflicting populations to
coexist peacefully, or it could fight and win against both populations and largely replace them.
I think that's what might be happening when you have one theory that supersedes and explains
two conflicting ones, which then live on in the new theory as approximations.
Or it could just enable one of the two to win over the other.
And then recently, David Deutsch suggested that we need not mimic how biological evolution
created creativity, the same way that planes don't need to mimic birds to fly.
And I agree with that. I just, I don't know of any other way yet.
And, yeah, and I forget if I mentioned it, but he also just like, just like Ella Hepner
suggested that replication would be inefficient, that it wouldn't be necessarily the approach that
a programmer would take. So all these criticisms would be very helpful and have motivated me to
think more about this idea. But what strikes me is that I think none of these are conclusive
criticisms. And this brings me to something that many of them have in common. I think they're
along the lines of, they say something like self replicating ideas are not necessary to explain
the mind. And like I said, I agree with that. In fact, I'm pretty certain that my, that my
approach is wrong. What I'd like to find out is why. And I think the, a, an avenue that I would
find more, more productive is what, what is an explanation for why self replicating ideas
cannot be part of the mind, not why they need not. And like a real refutation of the idea
would be extremely helpful. That also brings me to what could change my mind about this,
this approach. That is one of them, just just an explanation of why it cannot involve self
replicating ideas. And then also an internal contradiction or something like that that I'm
unable to fix. At least that would, that would definitely constitute a big problem that I would
need to solve. I should point out that the idea that self replication, for example, would have hurt
the genes encoding that it would have hurt genes in biological evolution. I think that was a
candidate for why creativity cannot involve several self replicating ideas. So I think something
like that would be promising. And then lastly, some outstanding problems. There are still big
unknowns left. Like I said, consciousness is the big one. Something that I've been thinking about
recently is that when you, the, the approach kind of goes along the lines of, well, as long as you
have self replicating ideas, you kind of get variation automatically eventually because the
mind is messy. And therefore you also get selection automatically because different variants spread
with different rates at different rates. But if you actually write a self replicating computer
program, they're also called a quine. They don't ever mutate. You can run them a billion times in
a row. They don't mutate unless you force them to, but then mutations are planned. So that tells
me that the self replicating programs that people have written are too good at replication for
evolution to occur. And then there's the problem with evolutionary algorithms generally that David
Dorch has written about in the beginning infinity, which is that as a programmer, you can't really
tell if the knowledge that you find in the program after running it is knowledge that the
program created itself, or if that is knowledge that you as a program just happen to put into it
without realizing it, you leak that knowledge into the program. And so you can't really judge
whether the program is creative. You'd need to know to make that call. So we'd need to find a
solution for that before even trying to implement this theory. And yeah, so that is the approach.
And I'd be ready to take questions if there are any. Great. Thanks so much for the talk.
Um, yeah, so we have about 45 minutes of questions. And I think what we'll do is,
Dennis, if you could first close the presentation, because I think it's nice.
Go back to
And then I will open with a question. And then anyone who wants to answer,
who wants to ask a question can do so afterwards either by raising your hand, as I see David has
done, or by typing in the chat. Yeah, so the first question I had was, I really liked the idea set
out. And I like, especially explanation of memory. And this idea that memories are replicators and
the memories that you retain, other ones that have replicated best. But memory in my computer
is just accessible, like the files in my computer don't replicate. If I require an old file,
I get an exact copy of that file, and I just retrieve it as it was when I first stored it.
Why do you think that minds store memories differently? Why do you think that they will
have to replicate? Yes. I think it's sort of a quirk, maybe of the English language that we
use the term memory to refer to both of these phenomena, even though I think they describe
different things. Memory in the second sense, in the sense that your computer uses,
actually our brains have too, because they need to store data in that sense. And that
is just the plain old memory storage that you've described, and nothing changes. Like if I store
very rarely, because our hard drives are very reliable. So yeah, if you store a file on your
computer, it just stays there and it doesn't replicate. So this is, I think that is like a
lower level kind of memory phenomenon, like the direct interaction with the hardware for how to
store information. The kind of memory in the sense of remembering things,
I think it's just a different phenomenon. And that is the phenomenon that involves
the self-replicating ideas. So I would just distinguish between the two.
Very nice. Okay, thanks for your answer. Then I see that David has a raised hand. David,
go ahead and ask a few questions. Hi. Well, I too found that very persuasive,
and I also liked the way that it kind of explains features of the would otherwise
perhaps seem accidental features of the human mind and memory as well. I just,
I can't quite see the overall picture though. So in RNA world, there were, as it were,
genes, but no organisms. Right. And in the brain, in your picture, I think there's also
genes, but no organisms. Is that right, first of all? Yes, that is right. I've wondered if maybe
sometimes ideas, as they get more complex, as they replicate in the mind, if they stumble upon
a replication strategy, something like the genes stumbled upon when they invented organisms.
Well, yeah. Well, so the thing is that if you imagine a huge soup of RNA, then it doesn't have
an outside world. That is the only outside world it interacts with is other RNA molecules.
Things started happening in RNA world to make more sophisticated replicators when RNA started
manipulating things that aren't RNA and started, for example, making enzymes, making proteins,
and so on. So I would guess that there's only so far you can get by twisting RNA into different
shapes and trying to get them to produce more of those. But at some point, they invented enzymes.
And then, from then on, there's phenotypes. There's organisms. I, I, I don't know, I don't know,
there's organisms. I, I'm not, I'm not asking how you explain the origin of species, you know,
why a bunch of DNA just moves along through the world together. It's not that. It's, it's the,
it's, it's the, when it gets to encounter the non RNA world. And I think most selection in the
biosphere and most selection in the brain, I'm guessing, is caused by problems to do with the
non RNA, to do with the outside world. It's the outside world that causes things in the inner
world to come into conflict. Right. Okay. So, you know, I'm just kind of asking or asking for
comment or whatever. I mean, I don't have any objection to the idea. I think it's a great idea.
And, you know, please pursue it. Great. No, you know, I think that is a really helpful
pointer that is, I don't have an answer off the bat for you for that. I think that's something
I'd very much like to explore. So I'll, I'll keep thinking about it. Okay. Can't ask for more.
Oh, then Timothy, do you have a race time? Yeah. Hi, Dennis. Thanks for the talk. I really enjoyed
it. Hi. I think, I think one term that I'm sort of stumbling over in this framework is accidental.
How do you think about our sort of effectiveness at problem solving or the kind of deliberateness
of it in terms of this accidental idea creation?
Do I understand correctly that you're trying to square the purposeful thinking or the, at
least the purposeful, the feeling that we get that we're purposefully solving a problem, say,
with the notion that ideas mutate accidentally? Am I understanding that right?
Yeah. I mean, not just the feeling, the fact that we actually approach problems and solve them.
Right. Yeah. I do, I've thought about this too, and I think it's a really interesting
thing to explore. The, I think those things can be squared. And I think the way we introspect and
look at the way we solve problems is often deceptive. And this has led to ideas such as induction,
for example, where people even though they could not have induced from experience,
that's what they thought they did. So people can be mistaken about what they, what they're doing
when they solve problems. And the thing that ideas happen to morph into a new conjecture that,
that solves a problem, say, I think isn't really at odds with purposeful problem solving.
We, we purpose, we want to solve problems. That means we have ideas that we would like when
there's a conflict, we would like to solve it. And that idea exists even before we encounter a
solution to a problem. But the, the solution to the problem itself, we can't really move toward
in a targeted fashion because we don't know yet what it might be. It's unknowable in advance. We
only know it once we've evolved it. And at that point, we just kind of happened to know it.
I think that's just true of evolution generally is whether it's the gene or the self-replicating
idea in the mind. There's only, I think Popper called them happy accidents. There's only happy
accidents, or sometimes not so happy ones. That's, I think, all we have. We can't think of a solution
before we, before that idea mutates into one. Does that make sense? I'm not sure that I,
that I really put my finger on your, on your question.
I am not hearing the participants. Sorry, sorry, that, that, that does make sense. I'm not,
yeah, I'm not sure if it, it quite feels the gap for me, but I'm,
yeah, I'm not sure of a better way of framing it, but thanks for the, thanks for your response.
Okay, sure. Okay, then I see you have two more raised hands. I don't know who was first. I think
I'll go with Paarek. I, I think he must be asking your name. So, so go ahead.
That's all, yeah. That's Paarek. Thanks a million. Really enjoyed the talk, Dennis. Thanks a lot for
it. And so yeah, my question was sort of related to the last question a little bit, but you remarked,
I think about halfway through the talk about, there may be, because ideas will self-replicate,
there will be these junk ideas, which are analogous in some ways to, to junk DNA. So,
I guess my question is about the self-replication. So within this model is the replication a matter
of degree, so that the, the idea, which isn't the junk idea, which presumably is the one that
we're, we're then conscious of, you know, because you're, you were mentioning that we, we, there's
a lot that we're, we're unconscious of, and those would be the, the sort of the ridiculous answers,
let's say, to a problem or the ones that we don't get promoted into our awareness.
But the ones we are aware of, would those be more active replicators in, in, in this way, or, or
they're, so yeah, I guess it's sort of a two-part question. One is like, is the replication a
matter of degree? And secondly, are the, the ones we become conscious of, the sort of better at
causing their, their copying? Yeah, I'll, I'll, I'll try to answer the second one first.
They, I think being better at copying oneself is one way to just retain the, the faithfulness and
the, the coherence of an idea, for sure. So that if, if that idea wants and scare quotes to be,
to be thought of again, one, a good way to do that is to make sure that one retains one's
faithfulness. I could see that. Now, with regard to whether that makes it a more active replicator,
I don't know, I could certainly imagine that there are ideas with different replication rates.
One might replicate twice as often as the other. And if it can make up for, for, you know, the
mutations that might be introduced during that, the, the double replication, then it's fine.
So I guess it just depends on how reliable the replicator it is, or it is not very reliable,
but thanks to those mutations, it creates a new idea. And then that new idea is coherent enough
that you become aware of it. So that could also be the case. So I'm not sure that we could tie it to
the activity of a replicator per se. With regard to your, your first question, I'm not sure what
you mean by degree of replication. Yeah, I guess just to clarify it a little bit. So, you know, some
questions. So to, to bring it back to the analogy that within genes, there will be,
like the junk DNA is a replicator of sorts, although it's, it's not usually referred to
as a replicator because it's, it's not, you know, it would contribute within its environment,
it contributes to its copying more than, you know, a whole lot of other physical objects.
And both it's, you know, it's, it's, for some, it's maybe not worth calling a replicator because
it does so far less well than, than the ones we call replicators. So I was just wondering if that's
the same sort of implication that was being drawn between the analogy of junk ideas and junk DNA,
that they are sort of, they're still self replicating, but they're, they're less,
less good. I got you. Yeah. No, I think, I think absolutely that could happen. Yeah, you get,
you could through an, through mutation, you could get a junk idea that's, it's junk in the sense
of that doesn't result in a coherent idea anymore, but it's still kind of manages to get itself
replicated every now and then that could happen. Or sometimes the mutation might be so detrimental
that it's just, it dies immediately. Yeah. Then I see Danny has a raised hands. Danny, go ahead.
Hi Dennis. I really enjoyed the talk as well. And one of the things that I really like about this
theory, which is something that I've wondered about myself in the past, is the fact that
Popper's notion where we conjecture ideas, I've always wondered why the ideas that appear in
our conscious mind seem to be non random. You know, so the, you know, to take your example about
the keys, you know, some silly idea about your keys being somewhere that you've never been before,
that idea doesn't appear in your mind. So I suppose my question would be, do you have any conjectures
around what is happening in the mind in that moment when an idea, when that first idea appears in your
conscious mind? So what is happening when your mind quote unquote, like selects one idea to
present to you consciously? Have you, have you thought about that at all?
Yeah, I have. And one idea that I've just played with is that maybe what's happening is that
in the pocket of the population of ideas that's relevant to this problem,
um, maybe the idea that you've left your keys on a kitchen counter
is just very good at spreading through this pocket and it outnumbers rivals. And
that's why it gains a foothold in that niche. And maybe that is why you become aware of it. This
is just a, you know, purely conjectural, I'm making stuff up kind of thing. But
um, that's an idea I've played with. So, so more broadly than it's, you think it might be possible that
um, the distinction between, you know, the ideas in the conscious mind and the ideas in the unconscious
mind has something to do with, we'll say the number of, of replicas of an idea or, or am I maybe
stretching, stretching what you just said as Marlon? Well, I think it may have to do with that.
And um, it, it may have to do with one idea outnumbering or overwhelming,
or one population of that idea, like one set of replicas of that idea, outnumbering another
competing set. And that's why you don't think of the other set. I think that is one, one thing.
And then as I've mentioned, there's the thing about ideas competing fiercely and that constituting a
problem. That is also something that become aware. I would imagine that their ideas competing all the
time, countless ideas competing all the time in our minds, but the competition is so small and,
you know, the conflict is so small that you don't, you don't realize it. But because the, the key,
and the key example of the missing key, it must mean that just by virtue of you thinking and
recognizing it as a problem, it could mean that there were two populations of ideas
encoding, um, conflicting preferences. Say one, I want to leave, um, that is my preference,
conflicting with the idea that I can't find my key, so I can't leave. And this, this conflict is
both on both sides, the ideas are numerous enough that the conflict conflict is noticeable
that you, I mean, it's a bit circular because I'm trying to explain what we notice in terms of what
is noticeable. Um, but I'm suggesting that that is what makes it noticeable. Uh,
if that makes, I hope that makes sense. Yeah, yeah, I know it does. Thank you. Thank you.
Okay, I don't see other raised hands, so I will ask another question. And it has to do with
uh, these higher level concepts. So we, we, we also, like, you, you draw this picture of, of
single ideas, uh, evolving in a mind and, and partly you say that, for example, we
experienced suffering as a, as a consequence of competition between ideas. Uh, and I think what
I'm wondering is, like, where does the sense of self come in and where does, uh, this is kind of
related to the question of where does conscious problem solving come in? And, uh, just truly,
I mean, I can imagine there would be such an explanation of consciousness or, of, uh, maybe
that's asking too much, but where, where do these seemingly higher level, uh, entities come in? The
sense of self, uh, sense of direction, sense of purpose. Um, and yeah, this is kind of a vague
question that is pointing at something. I hope it's enough. No, no, it's a great question. Um, yeah,
I'm afraid it really is the big one. I don't have any, any good answers for you. I mean, I, I have
thought that there, that there is a sort of meta algorithm in the mind that, that we've inherited
from, from our ancestors that used to just be, um, responsible for interrupting, you know, bad
loops or stuff like that. But, um, and maybe that is, because it looks over the pool of replicating
ideas, that maybe that is why we have this, we, at least that's how we feel, that we have this
bird's eye view of our ideas. But I don't know. Uh, I would really like to know.
Yeah, same. But it's, yeah, as I said, it's, it's maybe too big of a question.
I see there's more race hands now. Uh, and I think Antonio was first. So,
Antonio, if you want to ask a question, go ahead. That's right. Thank you. Um, so I don't want to get
into a play of definitions, but what do you mean when you say an idea? And do you differentiate
it between the explicit content or the inexplicit content? Do you think it matters at all how they
are instantiated in the brain? What would be like the goal of an idea? Why wouldn't want to exist
in your brain in the first place? Because, yeah, unless you actually define what you mean by idea,
having self-replicating ideas doesn't say much about what's going on.
So the, the, what's throughout to me is when you said that, why would an idea want to be
in a, in a mind? I don't think it does. Um, this, the same way that there's no gene that wants to
be in the biosphere just kind of finds itself there. And because it's a replicator, it makes
ever more of itself. Um, there, there, there's nothing, um, you know, the, the, on the level
of the replicator, there's, there is no consciousness or purposeful purposefulness. So,
um, now when it comes to what, like, how, what do these ideas actually look like? How are they
implemented? Um, I have given this some thought now at the risk of it getting too technical.
I think of ideas the way they're stored in the brain when it comes to source code as
functions in the sense of the lambda calculus. And I do think there are important parallels
between, or not just parallels, I actually think they're the same between functions in the sense
of the lambda calculus and explanations. And so I use the term idea just for those functions.
Um, before just those functions, I should say. Um, so that would be my technical answer to
how our ideas implemented in the mind. Um, if that helps. Okay. If you imagine a brain,
a human brain, okay, human baby raised without language. Okay.
In 2021, now you can raise a human being without, say, speaking to it, to humor her, whatever.
Um, do you think that it will contain knowledge? Will it only contain like inexplicit knowledge,
but it will be able to move around, to hand, to eat, to feed, to interact with other human beings
purely on an inexplicit level?
Yeah. Um, I think so. I think, I mean, our ancestors at some point were in that stage,
right? Before the invention of language, presumably they had the same brain, the same genes.
Yeah. Um, no, I do think that language comes after. Um, you have creativity and that's what
allows you to learn language. It's not the other way around. Um, so yeah, I think there's plenty
of things that people can learn even without language and the inexplicit ideas will do.
And what is the mechanism of how they learn all these inexplicit ideas be different
to how they learn explicit ideas?
Um, I don't think so. I think the, the method and scare quotes of conjecture and criticism is universal.
I mean, yeah, I think it worked the same for, for explicit ideas as for inexplicit ideas.
And wouldn't it be more easy if the mechanism is the same to try to explain
how we learn inexplicit ideas before jumping to the explicit ones and having all these extra
dimensions of language of science, all these meta levels?
Um, I would agree. Yeah.
Yeah. Okay. I'll pause here and maybe we can
thank you. Yeah, go ahead, Dan. Okay. Hi. Hi, Dennis. I missed the beginning of your talk,
but I think this is a really important line of inquiry and my apology for exploring this.
Um, I, I feel like the area which needs to be fleshed out more is the selection
mechanism. And I wanted to mention that there is an existing theory called neural Darwinism,
but it seems to be that theory is more on the, to explain perception
rather than the formation of ideas. And in, in neural Darwinism, the idea is you have,
you have basically a bunch of, when, when, when, in a newborn brain, it's known like you have tons
of random connections and then there's sort of a pruning process. And the idea of neural Darwinism is
the different groups of neurons are selected by how faithfully they replicate the incoming
sensory data streams. With your, with your theory, you, you were talking about more of an internal
process, right? So I was thinking, when, when you need some kind of like world simulator,
to, to, to test different ideas, to see if it makes sense. And like, have you thought about how
there might be like a world simulator and then basically, so for example, with the missing
keys example, which is, which is really interesting one example, different parts of your brain would,
would be simulating different scenarios and sort of seeing if they, if, if,
if the idea, if, if the simulation maps onto the idea, like, like you'd have different ideas,
like you'd have an idea of the keys or location X, and then you'd run a simulation based on the,
all the information you know, and you see if it confirms that idea. Have you thought about anything
like that? Well, just to give a general answer, the, as I, as I said earlier, I like to just
leave sense data out of it completely. I mean, I do think that sense data is important to, to test
your theories. But so to make progress, sense data is important in that sense, but I don't think sense
data is required for, for creativity to work, or for any of the evolution that occurs in a mind to
work. And I mean, you could, you could simply ask, you know, if somebody is born, and I don't want to
put words in his mind, I think David does this in the beginning of infinity, and if somebody is born
blind, they're not any less creative. I mean, they might, they're still people. They're fully
qualified people, right? So they might have a harder time correcting some errors because they
don't have access to sense data from the eyes, but then they might creatively find other ways to,
to correct those errors. But what I, like I said, what I like to do is just leave sense data out of
it completely just to avoid any empiricist pitfalls. And I also like to leave the brain out of it
completely. And I like to think only in terms of the mind, just to avoid any, any accidental
reductionist mistakes. So I, so I, you know, the thing about neuronal structure is self replicating.
I don't know. I would, I was more just mentioning that for the audience's
benefit, not, not, I'm not saying that you should go in that direction. I actually think the
direction you're going, which is more at the higher, higher level, extracting away from the,
from the, the neural circuitry is, is, is very, is very interesting.
As I guess my question was really about the selection mechanism, like could, could you
elaborate more? Cause so far on the selection mechanism, cause so far you, I mean, at least for
the part I heard, you just mentioned, you know, some will be better at replicating than others, but
um, what is the selection? How is, how does selection occur? Is it context dependent or is
there some, how does that, how does that work? Yeah. So again, borrowing Dawkins definition of
selection, that is, it's the non random differential reproduction of a replicator in a pool of
replicators. Um, that is how I would describe the selection effect or the selection mechanism
in the pool of self replicating ideas in the mind as well. It's just the fact that once a
mutation arises, if the mutation either helps or harms the, the new copies ability to spread,
now you have differences in the rate of replication and that itself constitutes selection.
In addition to that, um, the, the, this meta algorithm, which by the way caught myself
not crediting the, uh, this, the, the idea of the meta algorithm originated with
a temple in a different context, but the, the meta algorithm could also, um,
have, you know, act as a sort of arbiter of ideas or select or arbiters, but impose additional
selection pressures on the idea pool. Um, now how in detail that would work, I think is depends on
what happens at runtime, um, because it might, it might, um, look at some ideas for what to do
and what selection pressures to enact on the idea pool itself. So there's some kind of feedback
loop there, but the details of it, the kinks I think need to be worked out there.
Okay. Then we have two questions in the chat by Taha. The first one is in the case of genes,
RNA, DNA, uh, we know what the replication unit is made of, a sequence of nucleotides.
What constitutes the replication unit of an, of an idea?
Yes, this is a great question. Um, I would, uh, I would follow Dawkins here who, who says, well,
you know, on the one hand we have the, the physical instance of the replicator,
um, which is the molecular structure itself. Um, but, um, so actually the terminology I use is that
that I would call an instance of a replicator, a physical instance of that replicator. And
although maybe I'm jumbling biological terms, but I would consider even that, um, physical
instance of that string of molecules itself, part of that replicator's phenotype, which may sound
a bit confusing until you realize that the replicator itself is actually an abstraction.
Um, the replicator is not physical. It has physical instant physical instantiations,
but the replicator is an abstraction because as Dawkins explains, the replicator is that part of
this, this string of DNA that manages to stay the same over many, many generations for, you know,
for as long as possible. And so this is just a chain of instances and that, of course, that chain
physically exists, but it also exists over time. And so some of the older chains, some of the older
part of the chain would already be gone at that point. And still we would consider all that part
of the same replicator. So it's abstract. Those are independent of the, the physical instantiation.
Um, but so the unit of, the unit of replication, in that sense, we could ask the same question
also when it comes to memes. Um, in the mind, I think are, are again these, the, again, at the
risk of sounding too technical, the functions in the sense of the lambda calculus, these little
programs, just think of them as programs, really. Um, those are the ones that replicate. And of
course they're going to have a physical instantiation in the physical memory now again, in the sense of
storing stuff, not in the sense of remembering stuff in the brain. Um, I think Dawkins even went
so far as to say one time that, you know, he proposed this conjecture that maybe we, if, if you have a
joke in your mind and I have a joke in my mind or in your brain, I have a joke in my brain,
that maybe that means that the neuronal structures and coding that joke are the same. So maybe
meme replication implies, uh, replication of neuronal structures across brains or something.
Um, actually I think I'm getting ahead of myself here. Um, so the replication unit of an idea
is the function in the sense of the lambda calculus. I hope that helps.
Yes, I think it makes sense. Just get a clear picture for myself. Do you mean that, uh,
there is, there is something that you and I have in common when we have the same idea in, in our
minds, or that we have a similarity when we have the same joke, then whatever is encoding that joke
in our, uh, in our brains has to be, uh, fundamentally the same thing. Like it is, it is encoding the
same abstraction, as you would say. And it might do so differently. It might use a different encoding,
a different encoding, but it is, they're both encoding the same abstractions in that sense.
Yeah, provided that enough error correction has gone into it, the, the, I agree, the abstraction
that, that encodes the idea in your mind should be roughly at least similar to, to the encoding
in my mind. Yes. Right. Okay. And then there's the second question, uh, also from Taha, uh,
which goes knowing that the sequence of a gene allows us to target it with a strip of DNA,
how can we do the same and target this specific idea?
Yeah. Um, that's also a really great question. Uh, well, if you, maybe we can go back to the,
the thought experiment I suggested earlier with the, with the brain interface that allows you to
connect to someone's brain and, you know, read the source code. I don't know how exactly you would
do that, but if you somehow manage to, and I think that process itself would involve
conjecture and refutation. So the brain interface may need to be a person, but, um,
if somehow you manage to do that and you, you can turn the zeros and ones in the brain somehow back
into, um, functions, you know, represent them as functions in the sense of the Lambda calculus,
then what you could do is you, at any point in that source code, you could make modifications or
split it or put something new in there. Um, all this stuff would be available to you.
Seems to me a challenge to, to make that happen, that, that interface.
Great. Um, then yeah, we, uh, we're almost through the 45 minutes
and I don't see any further questions, uh, unless someone has them now in which case,
please, please go ahead and ask. Um, uh, yeah, go ahead. Yeah, if you don't mind me asking a
second one, that's okay. So I was just wondering about like, uh, so do you think, uh, a conflict
or problems are a necessary precondition for a conjecture or, uh, because I was thinking about,
like in order for us to, um, identify a problem, would we first need to conjecture that a problem
exists? So in other words, there's like, let's take a simplistic, probably unrealistically
simplistic case. There's two conflicting ideas. Um, and, uh, we're, we're conjecturing solutions to
that problem. Do we need to conjecture that there is a problem? Uh, and then like just as a related
idea, uh, in order to conjecture anything in order for any new variation of an idea to, to come about,
does that kind of conflict need to, need to exist? If that makes sense.
Um, I think the answer is no for, because new ideas will just evolve by virtue of replication
being imperfect over time. Um, but when there is a conflict between ideas, um, that certainly
helps. And I would imagine that at least that is the main thing. Like I said, that we're consciously
aware of when we do come up with a new conjecture is, is because it is in response to a problem. So
I still think that problems are the raw material of creativity and so forth. Um, but strictly
speaking, no conjectures could arise just by virtue of, of imperfect replication. Okay. Okay. Thanks.
Okay. Uh, any other questions?
Antonio, go ahead. Thank you. Um, do you think there's a difference between
the perception of a problem, so this conflict between ideas and sensory perception in general?
Um, could you elaborate a little more? Yeah. Do you think there is, I mean, when you realize
that there is a conflict between two ideas, isn't this something you perceive via your senses?
Is there, is it a different physical structure, say from vision or from looking at the screen or
recognizing a bicycle? When you recognize that there is a problem between two ideas,
do you think it's a different object in a way than recognizing a physical object around you?
Um, I think those are, those are different things. Um, when we experience a problem,
um, experience, yeah. Right. When we experience a problem, I mean, maybe I use the term experience
differently, but this, the sensation we have, sensations also tricky term because it has sense,
but the, the sensation we have when we experience a problem with cognitive dissonance
need not result from sense data. It certainly can happen that you're, you know, with an optical
illusion, for example, you think you're looking at one thing, but it's actually another and you
can change, if you change your perspective, you see, and then you experience that problem,
that's a problem you want to solve, but the experience of the problem itself
as all experience, I think, is entirely within. That is not something that is induced somehow by,
by sensory data. And again, if I agree, I agree, but they're both inside, both when you perceive
a bicycle on the road and when you perceive a problem in your mind, both of them are inside you.
That's what I'm saying. Is there a difference? Yes. I think there's still a difference when
you just look at a bicycle and say you have, you know, I imagine that children learn this when
they're very young, they, they creatively conjecture recognition algorithms like shape
recognition algorithms so that later they can recognize bicycles. That stuff just happens
automatically. Once you see it, once you've created that algorithm, you just recognize bicycles,
unless you're horribly deformed or something. Whereas when you have a problem, there's something
unknown there. There's something mysterious there. So I still think those are qualitatively
different experiences. If that, if maybe if that's where you're getting at it, I don't know if I'm
answering the question. Okay. I don't think there is a difference, but yeah. Well, can you elaborate?
What, what is it? You think that is the same about it? I mean, at some point to a child,
seeing a bicycle was a mystery in the same way that when you think about supernovae or whatever,
it's a mystery for you. Right. There is no automatic thing going on. I mean, if at some point,
because if you're never exposed to bicycle, then you can be as old as you want, but at some point,
you will be mystified by this new object. So I see. Yeah, no, I think you're right that when,
for the, when, for the first time you see a bicycle that is a mystery, you know, what is that thing,
how does it work and how would I recognize it again? At like that first time, you're confronted
with a problem and you want to solve that problem. And in response to it, you learn about the bicycle
and you come up with a shape recognition algorithm for the bicycle and so forth. But once you have that,
now it's automatic. Now you can just recognize bicycles again. If I look at the window and I
see a bicycle that doesn't constitute a problem. So I would, I would still consider those two
different things. Well, fair enough. Yeah, I think aren't they just the same thing only one is subjected
to empirical criticism and the other is just an internal idea. I'm maybe well. Yeah. I mean,
your internal ideas, aren't they criticism? How do you experience? How do you think?
Don't you visualize your objections to something?
Why do we need to distinguish between these two worlds?
It's the same distinction as between science and philosophy, I think. And it's not really a
distinction. It's just a matter of where the criticisms come from. And it's useful in some
cases, but this is not a fundamental distinction, I think. I'm not sure if Dennis agrees with that,
this is how I would understand that. I do, although I still have the feeling that I can't
quite put my finger on, on what's your name, Antonio's question. So I feel that I haven't
really answered it satisfactorily. Yeah, well, maybe a topic for future discussion. I'm
afraid we've run out of time, though. And yeah, I just want to thank Dennis for his great talk. I
will do so as usual with appalling in emoji. There you go. And that was a lot of fun. It was
great to be here. Yeah, yeah. Thanks so much for coming. And again, I encourage everyone to check
out your article on the Conjection Magazine website, which we'll link to in the description of the
video. And yeah, so thank you for Logan for helping range this. Thank you and good luck.
Yeah, thank you. Okay, goodbye. Thank you, everybody.
