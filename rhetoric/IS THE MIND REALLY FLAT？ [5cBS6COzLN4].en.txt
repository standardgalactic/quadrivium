Nick it's it's a it's an honor to have
you on mlst um we are at your house in
Oxford so I had to drive up from Ascot
today but um yeah um just welcome
welcome to the show well thanks very
much Tim it's lovely to be here
wonderful so um one of my um Discord
community members uh recommended to me
last week that I should check out your
other book as well and have a chat with
you about that first and that book is
called the mind is flat and it's really
really interesting actually it it echoes
many of the things that I have been
thinking about but perhaps didn't
articulate quite as clearly particularly
after speaking with Daniel dennit
recently um because he spoke about this
intentional stance but maybe we'll we'll
get there in a minute but you started
off in the book um discussing to story
and even tol keen and you you sketched
out what happened to Anna kenina um at
the end of the story so could can you
start there yes I I don't want to do too
many too many spoilers for people
haven't read the read the book but but
um yes so the the climax of of anak ker
is the her her leap leap under a train
in a in in a Russian station probably on
the outskirts of Moscow somewhere I just
can't remember the details um and and
the question is why what what what is it
that leads her to this terrible um
terrible end and um the natural answer
is to think well I must be an answer to
that in context of her her beliefs and
her expectations about the future her
sense that you my relationship with with
with ronsky has failed this whole
thing's a mistake and you know my my my
marriage has broken down with my husband
and you know what am I going to do with
my my child and this the whole how
everything is falling apart and she's
becoming a parara in Russian Society so
there must be some sort of story we
could tell that story and if we could
look inside her head closely enough we'd
be able to work out exactly what was it
what were the the key triggers that made
her jump then um and I want to suggest
in the book that that that's that's
really wrong um of course there are
motives forces driving driving her to a
desperate ax but if you were to imagine
asking her just as as she's about to
make the Fatal leap now can you just
quickly run through what the issues are
here she'd really struggle to tell you
she'd you she said well I'm desperate
I'm you I'm very unhappy I I feel you
there's no hope why exactly well you get
you get some salad of stuff but it
wouldn't be a particularly coherent one
if you asked it several times you get
different answers um and the thought
would be that the intuitive thought the
sort of uh the starting point for lots
of thinking in Psychology and indeed
economics where actually there's a kind
of very strong um sense that people are
very rational and they their actions are
driven by that their values and their
beliefs that there's a sense that there
ought to be some true answer she may
give you a rather incoherent answer but
there really is underneath everything
there's a true answer so the um the idea
would be that supposing she supposing
she survived um miraculously she doesn't
actually get moaned down by the train um
and and she's convalescing and he you
say well actually now now we can really
get to the bottom of it we got the time
you we can we can talk you through it we
can give you questionnaires we can brain
scan your brain would there be any way
to reconstruct the the true answer and I
think the true answer what her motives
were and I think the answer again is I
want at least to to give you the
intuition give the reader the intuition
that maybe not actually um it's not
really the case that um the there's kind
of true story as we're going through our
lives we're continually inventing
stories about why we're feeding as we're
feeding and why we're doing what we're
doing and but the stories are sort of
coming rather late in the day even at
the trivial level of um you sort of I
don't know something doing something
like um you going to the fridge you find
just if you had to explain why am I
doing that I know what it is uh I want I
want some coffee and I need my the
milk's in the fridge so that's the
explanation but it's sort of a bit bogus
to think I I'd thought all that through
you know i' I'd just worked out a plan
and part of my plan was going to the
fridge I just found myself setting off
or setting off to turn on the coffeee
pot or turn on the tap or whatever it is
um so the the story comes after and I
want to say that's true sort of
everywhere I mean like our behavior is
generally too quick for us to tell the
story um beforehand as it were I me if
you're playing tennis to say you're you
charging about the court reacting to all
sorts of you know subtleties of what's
happening to the opponent opponent's
play um you can tell a story about oh
well I thought they quite weak on the
back hand or I if I tried to crosscar
I'd definitely you not been able to
execute the shot you can tell that story
retrospectively but yeah you kind of
know it's retrospective at a
rationalization um so the thought is
that that that sort of patter we give
ourselves about why we do what we do um
it's always rationalization it's always
retrospective and Anna Cora even this
most desperate and extreme of states is
in just that kind of state and I think
any of us who've been we all have in
extreme emotional states it's exactly
the kind of situation where you might do
something drastic but you don't really
know why you're doing it and you're as
puzzled as anybody else um so I suppose
the the sort of insight um if you the
I've pushing um here which is not by any
means unique to me it's very much a in
some ways a standard perspective in
social psychology and uh and aspects of
philosophy Daniel dennit um has been
talking about this kind of thing for you
many many decades very very lucidly um
so the idea is that you don't have any
deep insights into your own mind you're
creating stories about your own behavior
as you're going along um you shouldn't
take those particularly seriously they
should be listened to and thought about
but really because they're helping you
for form um a vision of who you are and
what you want to do next rather than
they are actually as it were burrowing
back into the brain processes that led
you to act yeah it's so true I mean I've
been speaking a lot with um Professor KL
friston and I interviewed one of his PhD
students Thomas par on Wednesday and
he's just written a book all about
active inference and um I mean I guess
there's a line of thinking here around
thinking of the brain as a kind of
prediction machine and um you know so
per ception as inference is roughly what
you're speaking about in the book but
obviously it goes on to thinking about
action and planning as inference and you
know I think like the punch line of of
this book the mind is flat is that um
explanations are a kind of inference and
um there's this famous thought
experiment in the world of deep learning
called the shogo um it's a story from
kind of love crafy and horror fiction
that you have this horrible tentacled
monster and nobody understands how the
monster works and it has a smiley face
on the front and that's what rla Chef is
you know to help us kind of understand
or bend the behavior of language models
to suit our preferences but um our brain
is a bit like the shog off in in a way
yes yeah I think that's exactly right so
we we tend to think that other people a
bit are a bit mysterious um but we
should think our own brains were just as
mysterious as anybody else's brain and
in fact the fact the fact the fact that
it's possible to to create any kind of
rationalized stories about anybody's
Behavior including oneself is is a bit
of a miracle but they are rationalized
explanations they are these um yes
they're not it's not that you've somehow
penetrated the Deep workings of the deep
um the Deep Learning System inside your
head I mean how would that even work I
mean the you the complexity and the have
this gigantic sort of Cooperative
parallel computation you know it the
idea that you could somehow capture that
by saying oh actually um that you
complex pattern of activity that's the
belief that things have become too
desperate to go on and there is the uh
the desire for you obliv or the desire
to go on with life or I mean it's
completely crazy really the obviously
you could say well as a levels of
explanation thing maybe at some higher
level some sort of pattern of neur
activity could have this higher level
interpretation but when people actually
build complicated um learning models
like you large language models there's
certainly no sign that you can read off
in some direct way how they're how
they're operating and of course another
nice thing about the world of large
language models which came a bit after
uh the mind is flat um
so I I I missed a trick there because
these they're a wonderful illustration
exactly of this of this kind of point so
you you can you ask a large language
model a question it will give you an
answer you can say well why did you say
that and you what and it'll give you an
answer to that too but you'll be kidding
yourself if you think that the large
language model is quickly having a quick
look inside its own processing history
and saying oh yes why did I say that let
me look inside no it's just another
improvisation so so the key Concepts I
think which um which comes up in in the
mind is flat and also of course in the
language game um which we'll be talking
about later um is that is is that humans
are spectacular improvisers uh and we're
so good at improvising we are so we
often give this have have the sense that
we must just be reading off the truth so
we're sort of novelists thinking we're
Jour doing journalism so we're sort of
making up stories and thinking well I I
it just came to me that story it must be
that must be how I really do feel I must
have been feeling that all along that
sort of sense of you revelation
sudden you you blurt something out and
you think that's what you've been that's
what you've been feeding all this time
isn't it well not really I just made it
up and tomorrow I'll make the opposite
thing happen we are inco in coate sort
of um mushes and yeah our
rationalizations are attempt to try and
put sense and organization onto what is
you know really a very mysterious uh
mysterious underlying system which we
you we don't you we our brains are far
too complex for us to understand yes I
mean I've spoken with many people who
try to um come up with some kind of a
clear difference between us and machines
and a lot of the um the language model
people say oh you know you're you're
just the same we're the same I spoke
with Max Bennett he's got a book out
about intelligence and he said that you
know the brain is is a simulation
machine and we do self-modeling because
we have this a granular prefrontal
cortex which you know can actually model
ourselves and then we can change the
pointer and we can have a theory of mind
and model other people in this Daniel
denes sense but as you are sketching out
in I think it's around chapter six of
the book there was this thing about well
imagine there was a a wireframe cube and
imagine what would happen if you kind of
put a plane against three of the
coordinates of of the cube and imagine
what kind of Shadow it would it would
cast on the floor and when we do these
kind of experiments we realize just how
incoherent and inconsistent our
simulations of the world are but but but
the trick is that's what it is it is a
simulation all we're doing is we're just
running these trajectories in the moment
and when we we articulate them and we
actually just stand and just think what
did I just say it it just doesn't any
sense no no I think these these cases of
imagery are really interesting because
as you say if you take a a sort of
simple piece of simple geometric thing
like a cube and you imagine well I must
be able to imagine how that works
because after all I can imagine you know
whole elephants and whole roomfuls of of
people so surely try to imagine the the
shape and structure of a cube would be
easy but actually as you say if you try
to do simple simple um simple uh thought
experiments you find you can't do them
fact Jeffrey Hinton um obviously one of
the the key pioneers of of deep learning
he did a very early um and very
interesting paper on exactly this he has
a paper on I think 1979 in the journal
cognitive science I think that's roughly
the right reference um where he talks
about um essentially the the incredible
shallowness and um uh weakness of of of
human inference with with examples of
things like cubes being viewed from odd
positions so for example there's there's
an angle you can look at a cube from so
it's where it suddenly looks like a a
hexagonal pin wheel so it's a hexagon
with little made up of little triangles
and in fact if you look at a hexagonal
pin wheel you can find if you look at it
enough it suddenly looks like a cube you
go my goodness there's a 3D object I've
suddenly seen how that could be a cube
so your brain is kind of able to to to
spot um that this has is a possible
interpretation but I would you know
invite invite everybody to to try to
imagine moving a wireframe cube around
in your mind and try and turn it into
that that pin wheel sh and you you know
I think you'll never do it um so yeah
our our um the thing is our stimulations
of the world are very momentary and and
fragmentary and they are local so we've
got lots and lots of you know bit
experience of the world and we got lots
of ways of extrapolating from it if you
then say how do how do all those
extrapolations tie together into one
Uber model of everything the answer is
well they don't
they don't they they are
incoherent yeah I mean this is one of
the themes and we'll get onto the
language model um The Language game book
it in in a minute as well but um the
world is gnarly it's just more
complicated than we could ever possibly
understand and in my opinion
intelligence is about building models to
um explain as much of that cone around
us with as much consistency as possible
but it's a bit like the no free lunch
theorem you know you need to have lots
of lots of models because no one model
is going to going to work in in all
different cases you're coming at this I
think from the direction of
connectionism I think in in the mind is
flat and you're of course citing Hinton
and this is in contrast to let's say
psychology where we try to build these
abstract consistent models of of how the
mind works and and the key is is the
word consistency I think there are many
folks in in Ai and even mathematics who
you know dared to believe that the world
was a consistent place and and could be
defined using mathematical structures
and I think one of the the kind of
lessons of of the last 50 years or so is
that's just not the case yeah I think
that's right I you can only only
describe very local bits of the world in
a consistent way so it's a kind of
tremendous Miracle when any consistent
piece of mathematics turns out to
describe some tiny um sliver of reality
so one that I'm very fond of because
I've been doing a bit of worked with it
recently is um in an indirect kind of
way is thermodynamic so thermodynamics
wonderful amazing that it's possible to
to think about heat and work and and as
a concept of entropy which is always
increasing or at least not decreasing
and yeah it's it's it's just astonishing
that that this this way of seeing the
world turns out to predict a lot of
stuff very accurately um but it doesn't
explain everything it just sees the
world through a particular prism and
miraculously it turns out there's a very
clean way of understanding what's going
on when you look through that prism um
and that's generally the way I think
science is so we we try to find any
squinting way you can look at the world
so that patterns emerge and when they do
that's you know Ma massive progress and
it's very important but we mustn't
forget that almost everything is not
like that I mean the the amount of thing
we things where we there is a consistent
tractable theory of universal
application is is vanishingly small and
the gnarly uh sort of fractally
complicated nature of the world is is
the def is the default um and of course
in some sense it's bound to be the case
that we can't um we can't we can't model
the world in any decent way in our own
heads partly because um obviously the
the world is much larger than we are so
that would be very strange and also
other people are in it so um so
obviously I can't be modeling you if
you're modeling me I we're off in some
kind of horrible infinite regret
straightway so it's always going you
know inevitably going to be a matter of
extreme approximation and almost
everything what's miraculous I suppose
about human intelligence or intelligence
in general is the ability to cope pretty
well with a world that's way too complex
to really understand um so it's kind we
have to be doing that by you know
working to a large extent by analogy
from experiences and um things we've
already already seen and learned about
we can't be trying to drive all the way
back to a sort of acatic consistent
framework because that's going to be
only possi in tining number of cases but
even if it were
possible we're never going to you're
never going to get there you know some
sort of finite amount of time you each
each child has to learn to understand
the physical world each child is not
going to infer nenan Dynamics or
thermodynamics from scratch in the first
two years of life yes I mean I I suppose
it's interesting that we were capable of
producing a model which is reasonably
consistent let's say the Newtonian model
but no I I really agree with what you're
saying that I've spoken with many
physicists recently who are trying to
conceive of life and intelligence using
thermodynamic descriptions and there
seems to be a hierarchy of resolution so
of course there's like Dynamics and then
there's Behavior which is roughly where
machine learning people operate and then
there's function which is where
psychology operates and there seems to
be various trade-offs when you go to all
of these different levels and of course
there are some folks who say well no you
know things like Consciousness are
outside of those three there there's
something a little bit extra but when
you do go to the highest resolution and
talk about Dynamics um it almost becomes
a useless Theory because when you look
at dynamical system there's no such
thing as causality physics equations
don't have the notion of causality you
can reverse time and it wouldn't make
any any difference and also it no longer
um brightly divides the phenomena that
you're interested in so if you say well
all life is just Dynamics then well
what's the difference between living
things and non-living things can't tell
you yes I mean it's true I think there's
just a general point which you're
absolutely right to to uh to highlight
here which is that we're we're all
attracted to don't certainly am by
abstract Frameworks but the danger with
excess excess um enthusiasm for abstract
Frameworks is you then abstract away
from the things that actually matter so
as you say you suddenly and really
abstract framework for understanding
life might it might very May absolutely
be something where you want to say um
using simple physical principles which
are you so there's no magic there's no
Ilan vital there's no sort magical life
force um under with with simple physical
principles we want to explain how cells
work or how you know how bodies work
that's sort of right um but it's very
unlikely you go to do that without any
um with the conclusion that well you
know life's pretty much like rocks it
really really isn't like rocks and what
you're going to have to do is understand
that what deep new principles have
Arisen U which allow you know
self-organization or whatever it
whatever it is which allow you life to
be possible and I suspect the same is
true with you know complicated thoughts
and Consciousness obviously is a
completely mysterious thing um but it
would be yes it'd be wrong to think that
just by abstracting away one's kind of
solved the problem one's got to them
with with that one's abstract framework
have a sense of oh right so um you know
life what's special about life is this
or what's special about conscious things
we're conscious of is this thing over
here and and of course as you do that
you might then blur the distinction you
have started with you might say oh
Consciousness isn't quite what we
thought or some things are alive that we
thought weren't alive or you we might
start to wonder about you know our
viruses alive and all that kind of thing
those those boundary cases start to get
re renegotiated
um but but yes the idea that you can
just abstract abstract enough and all
the problems go away so it's terribly
appealing I fall I fall into that trap
all the time but I I try to extract
myself yes indeed indeed I mean it's
quite interesting in parallel I mean I
interviewed David Charmers and he's got
a book called reality plus and he's
talking about Virtual Worlds and whether
they can be real you know seen as real
and whether they could be seen as having
um moral value and to me it often comes
back to the agency question which which
is that I see technology as being a kind
of extension of our existing ontology
but you know the there is a bright line
I think that is crossed when the
machines become the the agency producing
Nexus rather than just being part of our
Nexus because you can talk about
transhumanism and plugging ourselves
into machines or even as um Andy Clark
does the the extended mind and you know
just thinking of of there being this
this Nexus of of cognition but um yeah
it's um it's really interesting I mean
on on that moral question
actually aliens could come and land on
the planet and they could be deciding
whether or not to blow us up and they've
just read your book the mind is flat and
they were um you know struck by the fact
that we can only pay attention to one
color at a time one word at a time that
we're not really looking at them you
know because we're just deluded by our
confabulatory predictive models and you
know we're very very similar to mini
chat gpts and they might just reasonably
think well let's just blow them up yes I
think it' be very harsh of them to do
that but but I think um I mean they
certainly would I mean alien sort of
super intelligent alien looking from
space at our intuitive understanding of
ourselves would say these people have
got it completely wrong I mean I think
one of the things that's quite
interesting about psychology as a
discipline is that when you start doing
it um there's a there's a part it
depends on which bit you're studying so
bits of it you think oh this is kind of
common sense I mean it may common sense
with evidence so you know Common Sense
is you know especially like everything
else very inconsistent and some bits
stand up better than others to analysis
and there are you there are nice
elegant experiments and and theories
which allow you to um guide your common
sense but a lot of it sounds like Common
Sense Common Sense plus um but on the
other hand um when you start to look at
the the Machinery takes of the brain and
look at the things we do without having
a sense that they're U psychological at
all so things like seeing the world or
understanding language or moving our
bodies around I mean intely most of us
don't of course in the in in in the
world of machine learning and Ai and so
on we we don't see it this way but
intuitively as Everyday People we don't
think of these as psychological at all
we think well these these are just sort
of happened I me just my arms move about
and my eyes just see um so we but of
course most of our most of our mental
activity most of the brain activity is
actually dealing with all of this stuff
and when you think about that way that
works you realize oh hang on almost
everything psychological is is my all my
all my ideas about my own psychology
were completely wrong so rather than
psychology playing back um your
intuitions at you and saying yeah you're
basically right but here are a few
adjustments I think in when you look
more deeply um it's the psychology our
sense of our own psychology is almost
100% wrong so as you say I mean we I
look around the world I think
everything's in full detail and color um
if you say to me oh but hang on your
phobia is only very very narrow you've
only got good Vision in about one you
one degree of angle and and that's where
most of your color vision is I think
yeah I kind of know that but but on the
other hand the world's full of color and
full of and full of precise definition
and that's an illusion um and and and my
sense that I have a deep understanding
of my own motivations I'm not sure I do
have that really but if I if many people
do that's an illusion too um you look at
a page of text as you suggesting um I
think I see all those words actually if
you BL them all out put make no X's
except the word I'm looking at pretty
with a few letters either side I won't
notice anything different all these you
know basically the world of sort of
psychophysical psychological
demonstrations is just absolutely stack
full of things that make you think oh my
goodness my mind works totally
differently from what I thought um so so
I think the thing is that we've got this
sort of rationalizing perspective on how
how our minds work um and that's what
some bits of psychology textbook are
telling you they're saying oh yeah well
you want to you want to do that
rationalizing we'll help you rationalize
better but the other part of the book
saying actually all of rationalizing
it's rationalizing It's not really how
you work don't fool yourself
yes yes and and even in the language
game when when you spoke about um
philosophers who really study Concepts
deeply um these are Concepts that have
still arbitrarily emerged from The
Language game but you know there is this
interesting kind of tendency to to think
of objective reality as we experience it
as being the real thing and um I mean
you know you you were just talking about
the the the phobia so we only see color
you know just in our in our fial cone
and we hallucinate the color everywhere
else and then the Temptation is to kind
of think well you know um I guess we're
talking about phenomenology and you
could read your book and you could say
okay so there is maybe only a tenuous
relationship between our percepts and
our phenomenal experience of the world
um but a lot of philosophers really
don't like that idea I mean what why is
that yeah um I mean I I think there's a
there's a strand in
philosophy U this may not go to the
heart of the problem but for me it's my
best shot there's a strand in philosophy
which is starts from the point of view
that that Common Sense can't be far
wrong so you essentially say look the
common sense view of the world is the
thing we're trying to explicate we're
trying to clarify and so for example if
you talk about um beliefs um you want to
understand what is a belief then there
must be such things we talk about them
so let's try and establish you know what
they are and how we know we've got one
um similarly with desires similarly when
you talk about perceiving a color you
think well there must be um there must
be a blue to be perceiving that's what I
that's the way talk so we're trying to
to make sense of the way we talk um and
assuming that that is a kind of ground
truth and and and that from that
perspective annoying um sort of
physicists and physiologists and
psychologists coming along and say what
you know if you look at how color Vision
Works and how color actually works it's
all hard to complicated very different
from what you imagine that's that sort
of um Common Sense grounded sort of
approach to philosophy wants to say well
that's all very well but it doesn't
really doesn't really change anything um
so yeah I think there's a there's a kind
of
um a desire to to hold on to the
intuitive position even though I think
that's not always defensible yeah I I I
spoke with dennit about you know he's
got some wonderful ideas about color
perception and this is a great one of
those things about you know whether
color is an ontological thing you know
whether whether it exists in the
physical world or whether it's only like
a mentalistic property and this kind of
you know um intentional you know I guess
you would call it the physical stance
wouldn't he but what what your take on
that yeah so I think I would be
skeptical of thinking of of colors as
part of the fabric of the Universe um
essentially the same reason I'd be
skeptical about almost any common
sensical notion um I mean the whole
history of science is a is a history of
Common Sense ideas that either break up
um completely or get modified to the
point of looking you almost
unrecognizable so we have a sort of
intuitive Notions of temperature say um
and you might think well our temperature
is part of reality well I mean people
have go gone about forever saying that
hot and they're cold but then if you
think about the trying to understand the
difference between you the the coldness
of of ice versus the coldness of I know
equally cold metal or various other you
equally cold air um you know some things
feel a lot colder than others so we'd be
saying to ourselves well I do understand
concept of hot and cold hot and cold is
definitely part of reality and I can
tell you this cold metal thing is a
jolly lot colder than the cold air say
or cold water but You' be totally wrong
um at least if you try to understand
temperature from a modern physics point
of view um so as soon as you start to
break up um the uh
intuitive way of seeing the world and
make it rigorous then you Concepts like
temperature just blow up because You'
haven't really properly distinguished
heat flows and you know temperature as
thermodynamics would would talk about it
and so on they're just not you they're
not they're just different parts of the
Physical Realm which get bundled
together which when that and that
bundling is going to be determining our
you know our sensory uh
essentially perception of temperature so
you whether I feel hot or cold is going
to be detered by all kinds of funny
things you think about the wind chill
factoring which weather forecast is so
keen on um how cold it feels well of
course once upon a time there was just
the feeling of cold and hot um now we
realize there's an enormous plethora of
factors determining how hot or cold we
feel only one of which is this actual
temperature thing um so saying well I
have this sense of a category that um is
sort of available to me perceptually or
from a senty point of view that must map
onto the world absolutely not and I mean
color is another extreme example of that
really the forces that drive color
perception are you really complicated
and they're very contextual and so yeah
I mean I think um I would be um I'd be
with Dennis on this one I think yeah um
colors are great example I mean and and
temperature as well because I guess
they're actually very vague complex
Concepts but um I I've got a good friend
wed saber and he's a rationalist just
like Chomsky and um a GOI guy you
someone who's trying to use these um you
know psychology rationalizations to
build AI from first principles and in a
way the the world of GOI has shrunk
because I think over time people are
starting to sign on to the fact that
it's very narly and it's very complex
but but wed is one of the last Hangers
On and he's making a similar argument to
what you do in the language game which
is that there's a kind of information
hierarchy so you you speak about n
learning and clearning so you know like
nature and culture and culture of course
is very complex and fractionated and
arbitrary and um I guess he might be
speaking even one level above n learning
which is like the platonic realm so he
says there are certain templates
cognitive templates that would exist if
the universe didn't exist so
transitivity is a great example or the
located in or contains template so you
know um I put a thing in the bucket I
put the bucket over there the the bucket
is now located over there so you know
he's quite reasonably I mean Marcus
makes the same argument he calls it
reasoning quite reasonably arguing that
this does not exist in current AI
systems and possibly should be but it
does seem to be quite a small set of
models that um because rationalism of
course is reasoning in the um domain of
certainty yes yes well I think this
point about certainty is really crucial
so um there aren't many aspects of the
world where we can really reason with
certainty because of this sort of um
unkempt and gnarly nature the world has
um so in reality sort of acatic
approaches are only helpful in very
small numbers of cases and we have
retrospectively managed to aati a few
things so it is possible source of to
aati thermodynamics um and that that
happened quite recently um so you've
have you working away with people are
working away with thermodynamics forever
um even formerly mathematically and SL
got the atiz straight and that comes
later and probability theory of course
was only atiz at the beginning of the
20th century and you know in general you
even the things which where certainty is
possible like mathematics even there the
expertization usually comes sort of late
think about calculus I mean just trying
to understand you Newton and Li were
sort of setting off doing
differentiation and integration but they
hadn't really got any atic foundation
for that and it took ages and took 19th
century real analysis to figure out how
on Earth how you make sense for this
this stuff um so I think always the atiz
for me always comes last um and anyway
um almost everything we're thinking
about is never going to be acable so um
now I don't I don't deny and I think
it's it's a very interesting thought
that there maybe certain
abstract patterns of thinking things
about like basically patterns of logical
inference thoughts about the geometry
and so on um which may be things that
you it's not impossible that those
things are important and may maybe
they're even built into us that's you
know not not not not not a crazy idea at
all um but I do think yes that's that's
going to be a a small aspect of you the
total chaotic complexity of the world
our understanding of the world around us
yes and and final question on that I
mean you know there there's there strand
of mathematical realism um or there are
folks who think that it's basically
something we we've invented I mean where
do you place yourself on yes I mean
that's that is very difficult because um
I want to take a line I'm not quite sure
what the
philosophical um sort of right label
philosophical label is for this but I
want to take a line in which one thinks
of mathematics as bit like one thinks
about Chess so you we could have had
different rules for chess uh any number
of different rules and it would play
differently but given the rules we've
got you kind of you these this is mating
four is kind of mate in four or it isn't
um so you don't have Limitless Choice
once you've sort of pinned pinned down
the the the details you you know once
you've got a formal system then what
that formal system does is kind of
pinned down so it's but it's not the
case one so for example if we take um
numbers um one could say well um you
know know what's the what's the right
acation for numbers and the answer would
be well there's no answer to that
because um Once Upon a Time people
didn't even know about negative numbers
or um fractions or um or um difference
between real and um the idea of
irrational numbers and the whole number
the real line and all of this stuff so
continually as as we as people study um
mathematics more new things start to
appear mean complex numbers after all
and and on it on it goes so you know
sort of thinking to self um oh well this
kind of pre-existed before we came to it
is a bit misleading but on the other
hand it's not the case that we have sort
of free Power of creation at every step
and once we've sort of set the rules of
Chess once we've set the rules of your
piano or arithmetic or something well
then you're locked in but you could
change the rules you could do something
different if you want it yeah I know and
I asked the same question to Thomas par
um on Wednesday because um a lot of
people argue that you know the free
energy principle for example is is
ontological you know that that that it
basically is a statement about how how
the world works or even with the you
know the basian brain hypothesis you
could ask the question well is the brain
actually doing a basian update and the
response is usually I don't know what
you mean by is it real and does it
matter because frankly it kind of
doesn't I think that yeah I
think I take a slightly different view
of that I suppose because I think it's
certainly if it's a good approximation I
mean the kind of classic um I think it
was the statistician box with this F
famous phrasebook we all all hear all
the time
that you some models are all models are
wrong but some are useful and I think
that's that's basically deeply right um
with the possible exception of extreme
extremely basic physics everything else
is clearly approximation um and
essentially wrong out of out of some
tiny little domain um so I think saying
is it useful the question really is is
it theoretically useful to think of the
brain from a basian point of view having
said that there is still the question if
you looked inside the system can you see
something that looks like basian
calculation or not and I think people
would differ about that um the
overall uh sort of input output Behavior
that's one thing can you Rec canr that
from a basing point of view I think
often the answer will be more or less
yes roughly at least at qualitative
level even if you can't actually see the
the update calculations going on but on
the other hand if it turned out that you
know some kind of um you basian
propagation was going on in the mind I I
don't believe it is but I'd be delighted
I think is absolutely marvelous
Discovery um however I think it's very
likely because that requires that one
has a model of the world uh which one
can update in a consistent way and
that's the whole thing I think is wrong
um I think we don't we only have models
of teeny slivers of the world um So
within your tiny sliver maybe there's
something you basian going on I'm I'm
glad we explored that actually because I
was trying to wrestle with the apparent
contradiction of obviously like um
making the connectionist argument but
also talking about perception as as
inference because you actually stopped
short then of of saying it's a kind of
inference but but you do think it's some
kind of well you know the interesting
thing is that it's the same argument
before whether or not it's doing basian
inference it's as if it is yes that's
right yes and I I'm I am conflicted on
this I mean I am a very great believer
in the utility of the basian approach um
and indeed um Tom Griffith and Josh Tab
and I have a book with many co-authors
coming out only in you a year or two uh
on basian called reverse engineering the
mind which is going to be a big sort of
synop of ban approaches to cognition
coming out in a year well we we we're
doing the copy editing at the moment so
maybe it's a yeah something like a year
or 180 months can you send me an
advanced copy yeah yeah yeah yeah yeah
I'm a huge fan of Josh by the way he's
work at MIT is okay so I think he's
doing some of the most exciting Frontier
work in AI at the moment thinking back
to not only dreamcoder but I mean in in
the sort of beun world is's incredible
yeah no no Josh is absolutely fantastic
and Tom Tom Griffith is an amazing guy
so there it's a great and this is with
many other co-authors on individual
chapters but it's going to be yeah I
think it's going to be a really really
nice really nice book um but as I say
I'm I'm conflicted on these issues
because on the one hand I'm very very uh
taken with the the basian approach to
understanding specific bits of the
cognitive system but I TR you
extrapolate that up to thinking oh
really the brain is just doing a sort of
basian model of reality and all the
people in it I that's that's hopeless
the best we're very locally braing and
very
approximately yeah it's I'm I'm torn as
well it's a wonderful way to to think
about it even things like model
selection you know because a lot of
intelligence or even abduction is about
selecting models or intelligence about
creating models and doing so efficiently
is is how we understand the world it's
how we communicate we this improvisation
process on the language game um is the
mutual creation of models and sharing
model yeah yeah yeah and from a basian
perspective I guess that is quite a nice
framework to understand it yes I think
that's right yeah but it's as you say
it's um it's it's difficult to to to
think of that as the sort of total model
because of the uh the fact that
hopelessly computationally intractable
and anyway we don't we clearly have a
very partial understanding of the little
bits of the world we encounter whereas
the world's complexity is vastly exceeds
our Compass so it can't be the case that
this is the the right way to to think
about
cognition at an aggregate level but
little pieces of the system I think look
quite
basian yes yes I think it's um it's
unlikely that we are solving that
intractable yeah I mean it it seems
mathematically or just you know
statistically impossible but perhaps um
there is some um you know smaller
version of the problem that we are
solving which could be thought of in in
analogous terms yeah I think that's
right yeah yeah yeah in a way um you
seem like strange bedfellows because um
he's really close with um you know
intellectually some of the active
inflence people because he talks a lot
about like core knowledge for example
and this this like Elizabeth spelly type
um you know core knowledge and
presumably that is not what you no I
mean that's not I'm deeply hostile to it
but I know that's not my not my starting
point at all no no I think that's right
we are U we have lots of things in
common but
um yeah I think and I think I think the
mind is flatter than he does I think for
example he's very keen and and I must
say it's very very charming and
interesting set of ideas the kind of
idea of the vision is a an inverse
Graphics engine yes um that's yeah that
that's fine if you but then have real
inverse Graphics engines you have a lot
of physics built into them so you have
to assume a kind quite idealized model
of the physical world um anyway yeah I
mean we are we we we we're very agreed
on some things and very distant on
others we do we do do other stuff
together we have a you we have we have
um one or two papers over the years
we've got one one of coming out at the
moment so it's though we're coming from
different places where um yeah there are
some connections because in a way
basanis in general is about solving lots
of inverse problems yeah and I guess
that that's an a cognitive interface for
us to reason about problems but you're
you're almost kind of like um you know
you're just moving the complexity
somewhere else at some point you still
need to actually like you know solve
this problem y yeah indeed I I already
said this to you last time Nick but um I
was reading this book when I was jetting
or cruising around the Norwegian fuds
and uh it was a Serene setting I had you
know mountains all around me I was in
The Spar on the boat and um I was
reading your book and taking uh notes on
every single page and I even had some
stickers as well so when it was
particularly interesting I put a gold
star on there um but no the reason why I
love this book so much is it's one of
the you know like every few years or so
you read a book that really changes how
you think about things and this is
definitely one of those books great
thank especially because after speaking
with
Chomsky um I was kind of stuck between
two worlds and I always had leanings
towards this direction of thought but I
think your your book really really
pushed me um you know completely into
that um school of thought so maybe we
should just kind of start off um talking
about um you you spoke about was it
Captain Cook and and yes um talking
about you know how they they used the
game of shads to um you know get some
mutual understanding yes yes yes so so
one of this is apparently quite a common
phenomenon in the days of uh of Cook's
voyages that that that the voyagers
would just trundle along the coastline
in some remote spot and they'd put in
and on the assumption that some some
some native people would appear and
there'd be a bit of trade and
interaction um and they this this would
be mutually beneficial um but of course
they'd be doing this with no no common
language so cook does this on a
particular occasion and they talk about
now um the uh the the the people that
are on the beach Wait on one side they C
cooking team waiting on the other side
um I think what two of the the the the
the people I think this is ter Cher Del
fuo so the people from probably the
house um community in ter cherro Del fuo
now pretty much extinct I think sadly
due to brutal um you brutal effects of
colonialism um so a couple of people
come come out um with with weapons and
they throw down the weapons and um
Cook's team think okay so they're
obviously saying you we don't want to
fight you we're we're throwing aside our
weapons um and this is they've never
they have no common language never
interacted before this is completely day
noo contact um but that's that turns out
to be dead right so they they do bit
more of this kind of dance and before
you know it now the uh the native people
are on ship they eating and drinking and
hating most of what they eat I think um
but then exchanging exchanging goods for
Mutual benefit so the ability to to
forge a communicative relationship where
you can actually do practical useful
things and avoid disaster such as as
conflict which does did does happen and
indeed cook himself was in fact killed
in a a later incident I think in in
the somewhere in Hawaiian irelands um
but the stakes are really high but it's
possible for people to actually invent
communicative signals which are mutually
interpretable and I think this is you
incredibly interesting because I mean
you don't see any any sign of this in
any other species I mean this is an
amazing thing that that that the human
beings can figure out if I go through
this set of actions this sort of chard
likee acting pretense someone else will
look at that and think now you're trying
to communicate with me here and the
message you're trying to convey is this
um in fact we have to have the same
understanding you're sending a signal
out into the world and saying what do we
think what do we think this means I have
the sticks I throw the sticks down
what's the blood about and I have to
think as if I'm doing that the action I
have to think well I think it means this
and I have to think you you're going to
think the same thing so we've got to
converge on the same Mutual
understanding uh even though we have no
um you know no no no very little common
cultural background and no language um
and this is something that we it's it's
an amazing feat uh and I think it's
something that's uniquely human but I
think that's the uniquely human that
that pragmatic communicative drive and
ability that's the thing that really
makes humans um distinctive perhaps
unique but I mean whether it's a precise
whether it's a categorical distinction
or a gradation it makes us very special
and that's the thing that's going to
drive the ability to create
communicative system so the point of the
language game is saying start with that
kind of example or think about playing
shards as a parlor game where you're not
allowed to speak you just do funny
actions to indicate Godzilla or King
Kong whatever you're trying to do um
then you realize that you create these
momentary uh signals which mean
something also you can reuse them so
once you've done for example the stick
throwing aside you can you can do that
again to mean something you know
something similar or if I've done a
chest Beating For King Kong I might
think well now I want to do you a
chimpanzee well I'll try chest beating
that seem to work pretty well before and
I'm going to somehow you know I don't
know do a gesture for smallness to say
oh it's not King Kong anymore it's now
it's a chimpanzee or whatever but but we
then we create these um simple actions
which will start to have more more and
more specific meanings and we can chain
them together like you know King Kong
but smaller oh but smaller could be a
kind of you know changing the going from
a well parted hands to you know to to to
parted fingers say and that might then
become a generic way of making things
smaller whatever they happen to be so
you can quickly quickly generate
something which is a little bit language
like in the sense it has a set of
standardized conventions and they become
sequence and so on and and those
conventions will become um quicker and
quicker more crude so you don't go the
whole sort of full King Kong um sort of
panto you just do a few Clues and we
think oh yeah I know what that is so the
the signal becomes stylized it becomes
sequence and so on and so on um and the
thought is that this is this is really
what's underlying the foundations of of
human communicative systems so we know U
through the there's amazing observation
in Nicaraguan orphanages for for Deaf
children in the 70s and 80s um that you
can get the spontaneous creation among
groups of people children who have no
other means communication they start to
spontaneously create um Sign Language
sign systems which turn pretty quickly
into full-blown sign languages as
complicated as any um PRI prior sign
language or nearly or or any other human
language at all I mean these are these
are just as complex um as as languages
and they're created in a few generations
of kids over you know decade or two um
through spontaneous interaction so
that's I mean if you're for some people
some someone with a more nativist
perspective that uh that the message of
that story is ah language is pretty much
built in it just needs to be triggered
look it's just emerging spontaneously um
for my friend and collaborator Morton
Christenson and I we'd say no that's the
completely the wrong Story the right
story is um we're amazingly good at
creating communicative conventions in
the moment we're good at reusing them
and give us a bit of a chance and we'll
create you a system these things these
system s of sort of spontaneously
arrives um through reuse and and
purposing um and of course when you
think from that point of view um it
changes everything really so the first
thing it changes is one's answer to the
question oh why are languages so well
adapted to us um you why is it that we
find them so easy to learn in the sense
that you every child exposed to any
language can learn it quite quickly and
then the answer is going to be oh yeah
of course because we we just we created
them didn't we they are the things that
are natural ways of for us to
communicate because that we we created
them over you over period of incremental
Shad playing so the things that seem
natural to us and the categories that
seem natural to us and the ways of you
doing syntax that seem natural to us
those those are the ones that languages
embody because the languages have
evolved to be culturally through
cultural Evolution to be natural um and
if you ask yourself you know why is it
that languages have um uh similar
structures to each other which is a
fairly arguable question actually
because they they're much more diverse
than I mean I'm no expert but the people
who look at the full panoply of the six
or 7,000 human languages on the planet
would say my goodness they are pretty
diverse but to the extent there are
commonalities then the answer would be
well that's going to be in the same way
that Shard playing is going to have
commonalities there's going to be yeah
at the beginning there might be bits of
iconicity you're trying to do King Kong
you do a king kong like action yeah that
that s Fades away becomes rather
marginal pretty quickly in most
languages um and but you're going to
have compositionality you're going to
have to create complex messages from
simple components well that's that's
something that's going to be sort of
wired into the basic system we're
probably going to have to have a small
number of meaningful units um we can't
have a an infantry of meaningful units
which is
only as Tiny as five or six because
there's there's more things in the world
we want to talk about but if we make it
too big we can't learn them all and blah
blah blah so there's going to be same
communicative pressures the same
challenges that we're facing when
creating these these cultural forms so
they're going to have some common
properties so that you don't have to
explain those common Properties by by
focusing on the um the properties of the
brain you're more thinking of course
brains do have properties that are
relevant but the languag is basic the
languages are adapting to us rather than
there being a a surprising um degree to
which the the brain is kind of built to
do language yes yeah I mean like I guess
we'll get on to the um the kind of the
memetic properties of of language in a
bit but but also um as well as having
the same brain we we we share the same
physical environment we have the the
same physical embod um you know which
would presumably create certain guard
rails in in how this language game could
be played but just to go back a tiny bit
so the interesting thing about humans is
that because of our evolutionary history
we don't necessarily need to have
language so you you can raise um humans
without language but they will be very
very different to humans with language
and you were talking about you know so
we we do this incredible mental
gymnastics we play The Language game you
know with Ingenuity and and inventiv and
and and we create language and then
there's a kind of um maturity curve so
it starts off as pigeon and then it
becomes Creole and then over time we see
this conventionalization and and and we
see the you know sort of Concepts
becoming formed and further embedded and
shared especially if they have value so
I mean could you could you talk to that
Evolution a little bit yes um so to say
a little bit about the pigeon Creole
story so when um groups of people have
contact where they have no common
language this would be like the the
house and cook um when that happens for
an extended period of time uh pretty
quickly some convention system of
conventions emerges so although it's
true that people can live without
language and there are these horrendous
cases where children are raised with in
very bizarre circumstances where their
caregivers inverted commas are not
actually speaking to them at all they
don't don't learn language because
they're not not exposed to one and that
has pretty pretty cataclysmic um social
and cognitive consequences um but it's
that's incredibly unusual you put two
people together they start communicating
as best they can and um so when you have
people with with with with different
languages they will start to create a
system uh which has very very simple
syntax which at least will allow them to
talk about specific objects they need to
you move around or trade or whatever um
but as as the children of people who
speak who have learned this pigeon um
which is is the name for of this this
kind of very simplified language for
working across the divide the children
of those people will take that pigeon
and elaborate it and turn it into
something which is essentially its own
language so you there will be a you know
there will be structures and patterns in
that language which didn't exist the pig
pigeon speakers won't really understand
and you before you know it you've
essentially got a full-blown language
and you Creos are full-blown languages
so you end up with something which is s
of mixture of uh of the two two base
languages or maybe sometimes more than
more than two
so the tendency to create Rich systems
is is very basic to us you give people a
chance to communicate they'll they're
driven not by the desire to create a
language no one's ever bothered no one's
interested in doing this unless you're
um unless you're sort of inventing
aspirant or you're you know talkling
trying to create an Elish language or
something I mean most of the time people
aren't interested in creating languages
they just want to communicate but they
want to get their message across to
another person they've got to do it
somehow and they'll try and use some
signals using based on signals have
already got to hand and the person will
respond in kind and that process of
incremental struggle to just to get our
messages across and get to work
successfully together that will drive us
to create um you know create a system to
piece by piece so it's so it's a very I
think it's a very interesting phenomenon
that um this is it goes back to Adam
Ferguson the Scottish Enlightenment
philosopher of the 18th century has this
wonderful phrase that um that many
aspects of society are created um by
human action not a human design and I
think that the Deep Insight in that is
that um most of the time when we're
creating almost any aspect of culture
it's not that we're blindly just
randomly sort of um thrashing um we're
we're trying to solve a particular we're
acting you know in a purposeful way
trying to solve a particular problem
trying to make communication try to
build uh a house that stands up or
trying to solve some problem but by
trying to do solve the problem in front
of us we're incrementally creating new
tools and new methods that can be used
in you unexpected ways so we're
contributing rather like a termite
contributing to the the creation of its
its Mound we contributing to this this
this Collective construction of which we
no particular interest we don't we don't
care about that we just want to solve
the problem in front of us but but
nonetheless we are creating this this
Collective um collectively we're
creating something that shouldn't be
complicated and human languages are you
they are one of our most perhaps our
most astonishing achievement as a
species really yeah and and I'm
fascinated by this idea of collective
intelligence um so the extreme view is
that we are just like ants we discussed
this last time um but that can't be true
because we are capable of solving
problems and planning and and doing some
form of sophisticated cognition so so
then there's this notion of okay so I I
learn how to use a tool and then I share
that simulation with others and it and
it becomes mimetically embedded in in
our culture and then the interesting
thing though is is it becomes a form of
collective intelligence because other
people in the uh in the environment they
might learn to use the tool differently
or they might improve on it and then
that will be propagated back to me and
the fascinating kind of progression from
my point of view is is when almost the
locus of intelligence becomes more um
kind of focused on the um the meme
sphere than the individual agents like
when does that transition happen yeah I
I think I think it it does happen quite
early actually in in in human
development so um I mean if every if if
we all had to solve all our sort of
cultural um and technological problems
from scratch we we'd be struggling yeah
so I know Michael tomasel is always keen
on pointing out the the um developmental
psychologist and primatologist he's
always Point keen on pointing out the
the thing about humans is that um we're
always improving on past solutions by
other people and if we weren't um and
often blindly I mean we we can't be
thinking I want to validate and fully
understand why this is the right
solution think through all the
Alternatives you take nothing for
granted that would be a mad approach um
because we'd all be trying to understand
the world you from from scratch and
human progress would be impossible
whereas in practice we largely take
everything around us on faith we think
oh this is seems to be how we hunt and
this is how we make a boat um I guess I
I'll go with that and you might make a
incremental change or Improvement but
largely you're taking the the the the
way of life of the people around you and
the way the way it work Works including
your systems of communication including
language you're taking them for granted
and working with them and and and and
and creating um small variations uh and
perhaps improvements um and but because
you're doing that um it's not really
right to think that the the location of
uh sort of cultural and intellectual
progress is in any particular head and
we have this sort of great person theory
of of uh of progress as we do uh when
thinking about history generally so we
tend to think well it's these particular
individuals that have brilliant insights
and of course there are undoubtedly
particular individuals with brilliant
insights no doubt that's true but really
um I if you took Einstein out of the
19th century uh physics background
where's he going to be nowhere right
he's got no chance of making spectacular
um breakthroughs in 1905 if he's got
hasn't got this enormous intellectual
mure of people probably less smart than
Einstein most most of us are a bit
mildly but um but you know these people
have created this enormous
infrastructure of mathematics and and
experimentation and physical
understanding in which and indeed
philosophy which it's language and all
of this stuff so Einstein can make an
incremental contributions it's a it's a
small step of course it turns out to be
a spectacularly productive step um but
the productive it's it's it's productive
um because there are all these other
people around and all the other
infrastructure around so that that the
further incremental changes can be built
on top of the of that indiv ual so I
think you know in a way we should we
really should be thinking of human
progress much more than we do and I
don't quite know how to think about this
correctly but we should be thinking of
human progress um and of course it's not
always forwards um as as a kind of
collective computation so we to think
about the computational system as not
it's not the only computation the the
brain isn't the only computational
system in town probably the more
interesting one is the you know the
collective computations that we're doing
think about thinking about this say as a
scientific or mathematical Community or
in inventing new technologies or um
creation of artistic forms these are
things that are really a collective
computation and we don't really have a
good ways to understand that but we do
know that um you parallel computation
with large numbers of of Agents is you
is is you often a very powerful thing um
and I think yeah that we should be
trying to understand ourselves as small
components in a big parallel computation
a lot of the time yeah I've been reading
a book about creativity and it's um it's
something that wasn't even a concept
that we spoke about or could conceive of
we you speak about that in the language
game that many Concepts even things like
money for example are just cultural
inventions but um yeah and we started
studying it I think only in the 20th
century and Through the Ages it was
thought of first of all is um you know
like when when when we had the Greek
gods it was not seen as possible for
anyone to be creative and if it was it
was something expressed through through
God and um and then we've gone into the
sort of r period and and then we did
have you know folks like Leonardo da
Vinci and and and they they were deified
as being very creative and in more
recent centuries we're moving towards
this kind of we concept of of creativity
that we see it as a social thing and you
were just describing like Einstein and
there's this information graph and you
know perhaps a creative act is some um
you know big gradient on that graph
where we introduce something of novelty
and value and then there's a social
proof component as well which is to say
that it needs to be recognized by other
people but creativity is one of these
Concepts just like we were talking about
earlier with things like intelligence
that you can describe it in many many
ways and you never seem to capture the
whole phenomenon yeah yeah I think
that's right it probably isn't a a well-
defined thing really um another example
I really like is the will which I think
in the sort of um early philosophy of M
go back as suppos the 18th century was
hugely important everyone was going on
about the will and everything's driven
by the will and try to understand the
will was was really crucial and we've
all sort of forgotten about it now and
we occasionally talk about willpower and
so but we just don't go about thinking
what really explains the will um and
similarly it's very interesting and I
had wasn't really aware of it that the
idea that creativity is seems in
retrospect quite natural to think well
why would we yes why why would we think
of that as a as a as a as a as a
category rather than just people doing
things well or badly just doing
paintings doing bits of you know um
Anatomy um why do we suddenly say oh
hang hang on this is this is a creative
activity we're in here and this is a
particularly large creative moment um
that's you know so it's very it's a very
particular way of thinking and speaking
we shouldn't um yes we shouldn't
shouldn't take that as take that for
granted it's a a game we've yes a game
we've just invented it's quite quite a
western thing as well to think in this
way and I suppose the irony is that your
book is telling the story of every day
moments are extremely creative and in
fact um there is a drive to
um to to do this language game even
gratuitously so you know I'm traveling
with my girlfriend and we are just
creating words for things you know like
it's not a glacia it's an Enrique and
glasius and then it's an Enrique and
it's just a private language and there
there's it's Rapport building there's
there seems to be a very natural drive
to do that yeah oh absolutely no we we I
think to the extent that one should
think about creativity as a useful
concept at all we should absolutely be
thinking of ourselves as in daily life
unbel ably creative yes it's completely
wrong I think to be to to be thinking uh
that there are some creative people and
other creative people or the creative
people are being creative when they're
doing their special creative thing we're
all being amazingly creative all the
time um and Ju Just understanding things
like these simple shads and doing shads
is is is an astonishing astonishing feat
from a sort of computational point of
view I mean there's so many possible
actions you could carry out um you have
to think well what knowledge do I have
what does the knowledge do the other
person have which means that if I do
these
they're going to draw this inference
it's like really a really hard thing to
do and yet we do it you absolutely you
with no effort at all without thinking
anything about it and you know some
people are better at these things these
particular things than others but it's
either it's cre creativity through and
through or Pictionary is another one
people can think oh I can't really draw
I'm absolutely hopeless but they will
still manage to convey you know a movie
title or a book or something through
some sort of bizarre drawing and that is
an astonishingly creative thing to do in
fact in some ways the more hopeless
you're drawing the more creative it is
because you're forced to rather than try
to produce a you know a convincing
likeness of M Gibson or something you
have to do something much more indirect
but we can do that um and it's it's an
incredible um yeah it's an incredible
feat but the the other thing about this
process that's worth stressing is it's
incredibly um ad hoc and momentary so
the thing about this viewing language as
a sort of sherad likee process is that
we only have to solve the problem for
the moment we're in so with your your
your fun names for for glaciers um that
only has to work um in the context of
you and your girlfriend and this
particular place and if you were to come
across some other icy formation perhaps
in Antarctica and to think does is this
a glacier or not I'm not really sure
it's there's a lot of ice but is there a
mountain behind it I and what exactly is
the definition it doesn't matter it
doesn't matter at the point you're
having the interaction um you have a
clear sense a clear enough sense that
that that's one of those Glacier things
and that's another one um and we might
ask all kinds of abstract questions
about what you what would be one of
these you could you have such a thing on
Mars for example or would it be a
glacier if it was made of something
other than water it's just irrelevant
it's course it becomes relevant if you
start to think of this as a scientific
project of universal application but the
thing about communication is it never is
it's about getting our message across
right now saying look at that fun thing
oh it's moving or oh it's retreating or
you know you're just trying to convey a
specific um specific message in a
particular moment and the the ability to
talk generally about the world is is
that's the thing that comes last so the
language is specific specific first in
general later and I think that's a just
a gigantically s of G in some ways very
obvious but it's possible to make a
gigantic Mistake by thinking no the
right starting point for thinking about
language is to think of it as sort of
like a formal logical language which
makes Universal statements about reality
because then as soon as you mentioned
glaciers you think oh what is the set of
all glaciers in the universe and that
must there must be well defined
otherwise what are we talking about and
then you're immediately into you sort of
rabbit holes of uh which you need in
practice be even contemplating you're
you're solving the problem right in
front of you yes and so this bottomup
approach is is quite interesting so
you're talking about the moving from the
specific to the general and I think that
is how a lot of our cognition works even
though like a lot of um you know
psychologists might argue otherwise and
you get this beautiful example you call
it the lightness of meaning yes and cuz
this is one thing I wanted to get to
which is that when we play The Language
game uh we're physically situated in the
same space this is very high resolution
I I can point to any objects like you
know we can do multimodal gestures
sounds and so on and of course we do all
the time without again in this very
creative way without thinking anything
about it we we gesture and Nod and you
know do shrugs and all these things
without without batting an eyelid
exactly so so so the language game
starts off high resolution tion and then
there's this kind of cone where things
become overloaded compressed
conventionalized there's you know
euphemization of language is is is
another one and and part of that is
because of the carrying capacity you
know so so it's quite it's quite
efficient for words to be transmitted
because we can't really you know
transmit a pointer to a flower anymore
um so how how does how does that process
work and maybe speak to the overloading
of of lightness I think as a great examp
yes yes so I think the so um I think the
starting point we often have when we
think about words is that we think well
every word must have a meaning and okay
there are ambiguous words but let's put
them to one side if they're just they're
just like other words but they just
happen happen to have several several
meanings just cring onto the same word
so it's a bit like so thinking they're
river banks and and Financial Banks yes
but basically one word One meaning but
when we think about a bit more and this
has kind of been very much explored um
in the later L part of the 20th century
especially since VI 's um analysis of
language games so vicenin obviously used
the term language game in a slightly
different way to us but you know he's
clearly a major inspiration for what
we've been thinking about um as he has
been of course for many many people
thinking about language for the past
sort of 60 or 70 years um so vicenin
would have say well H look look closely
at the the way words are used and you'll
notice that there are all kinds of
usages which are are not actually
particularly distinct but they're not
quite the same either so if you take
something like um so he used the term
family resemblance for them so that the
different usages can resemble each other
in a variety of ways and there may be no
common feature um so if you take
something like light um you can talk
about um light uh objects so you think
oh that's that's pretty much what light
means it's about weight but then you can
talk about light Cavalry and you think
well I suppose that sort of Cavalry with
lot very heavy stuff on light music ah
now we're getting into trouble so what
what is this it's um or Indeed heavy
music is a bit strange but um it's
entirely you know entirely uh entirely
comprehensible
um and we can have we can think about um
uh light opera or or a light um uh a
light Cruiser or a light almost anything
and when we think about these different
meanings that they're not unrelated it's
not it's not that they're um completely
disconnected um but they are it's it's
not completely clear what the what the
connection is so we talk about a light
blue it somehow would be weird if a
light blue was extremely extremely dark
it seems sensible that if a light thing
is something feather-like then a light
blue ought to be sort of pale and this
is because of you know the way you
different modes um different perceptual
modes so we interact it seems natural to
think of um you know uh pale things as
connected to sort of delicate things in
but this is all coming out of our you
know sort of perceptual systems um and
those connections make sense when you
think we're doing something shirad likee
so if I want to talk to you about um a
light blue or a um a light load or
whatever it may be if you realize that
I'm playing shirar the whole time and
I'm thinking well I haven't got a word
handy for that pale blue oh well it's
sort of you know sort of ethereal and
sort of weightless ah light I'll call it
light and if I go and call it light blue
and you think I see what you mean yes I
guess um and then before we know we've
established this now of course this is
actually established in the language but
this doesn't come from nowhere it's come
from sort of analogical kind of
extrapolation of a chard like type and
that's going to be true you wherever you
look the number number of number of ways
light is used is gigantic but they have
this common sort of analogical pattern
so they're emerging from this from our
perspective they're emerging from this
sort of sherad likee um improvisation
where the same conceptual tools have
being continually reused and reused and
reused so it's not one word One meaning
it's one word many many possible
meanings put words together in different
contexts they will mean completely
different things that's okay because we
can track this because we are these
words are um they Flex ility is is is
being shaped by what our natural
communicative Instinct so we don't have
to think well light blue I'm starting
toally from scratch here that could be
absolutely anything it could be blue
mixed with lots of red or it could be um
very very deep or no it's not really
true it's sort of the the natural
analogy that for some reason we have is
you know feathery ethereal things pale
things kind of go together okay for
whatever reason that's the way we are um
so that's a natural a natural transition
to make so this is really interesting
because we're getting into analogical
reasoning and you could look at all of
the usages of light and that that is a
beautiful example so you know go in the
dictionary and look at you know a light
Curry might be another example and you
might look at those and and think well
they're really Divergent um it seems
arbitrary and it might be even more so
if the language Evolution has progressed
and and the the kind of the cognitive
distance has has progressed and so on
but weirdly in many cases we can look at
them and and we can see see the analogy
between them and it's it's difficult to
understand why that is it might be
because we're like a neuron Network and
and because we we've seen it used in all
of those cases that's the only reason
for the analogical link it might be
because they were conceived in a shared
physical and cognitive space which means
even though it seemed quite random at
the time there was some grounding
because with creativity that there seems
to be like a degree of Randomness a
degree of grounding a degree of
interestingness maybe some kind of
intuition it's very Myster ious isn't it
yeah yeah yeah and I think you're right
that these are when you think about the
the um the origin of the vocabulary we
speak with now um it's I think you for
our for Morton and I we'd like to think
think of that as a as a as the outcome a
long a long game of shards but of course
as you say in the latter stages of that
game we may well have completely
forgotten quite why what was the analogy
between X and Y well who knows we we've
forgotten that but now it's become
established off we go so we might be
using um the same the same a term in
ways which you where we've completely
forgotten the connection um so the the
history is always going to be sort of
difficult to to dis entangle but but I
think the crucial point is to try and
put aside the idea that oh there must be
some common core there must be some real
meaning what's light deep down I think
that's almost invariably an error it's a
bit like going back to your point about
you know creativity and think thinking
um well what what what's creativity what
what's the what's the underlying real
thing thing um the fact that we can talk
fluidly uh about a concept light or um
creativity or anything else in a huge
variety of con contexts is telling you
something about the clever analytical
ability of the mind so for example I
mean a creative um idea in mathematics
versus a a creative recipe versus a a
creative Shard I mean it's really very
hard to understand what what is the the
connection between these but there's
some sort of analogical it's like oh
that's when you think about it you think
well that's wasn't obvious but it seemed
really cool or something but all you
need is that crude crude analogy because
all you're trying to do is communicate
in the moment you're um you know you're
trying to say oh that idea seems like a
really boring idea but this is you know
bit more you know productive or you know
or maybe we'll call it creative um
you're only trying to to to to to solve
the problem in the moment which would be
to say steer away from this boring thing
and steer towards this more exciting
thing or whatever it may be the thinking
of thinking of the purpose of languag is
always contextual and always just trying
to coordinate our interactions in in the
moment they're happening that makes it
puts a lot less load on the the the idea
of of of meaning and it doesn't it sort
of abstracts or pushes one away from
thinking there must be some abstract
cord there must be a an underlying
meaning I mean the whole search for the
underlying Essences is a is almost
invariably doomed to fail I think yes I
know but but um many do um try to
essentialize language and they would be
forgiven for thinking that there is an
Essence because there is an apparent
consistency yes and but but if you think
about it we could contrive mutations to
the language where there was no
analogical link it's but it is
surprising though just how consistent it
is given how arbitrary it was yeah yeah
and I think if if if languages um were
not deeply patterned and
analogically even though there will be
some of that patting will be lost in in
the midst of time if they weren't deeply
pattered we wouldn't be able to learn
them um so that's the the thing all the
all the cases which just don't really
fit the pattern they're going to go
we're going to we're going to lose them
because we don't quite remember why they
work the way they should and um so
they'll be they'll be the things that
get that dropped pretty quickly yes
because I think another reason we think
this way is in school we're taught um
you know about grammar for example and
uh my mother used to say uh Timothy
we'll speak the queen's English in this
house and uh you know when when text
message abbreviations came along there's
a chorus of people you know just talking
about the decline of of our language and
um apparently that happens almost every
generation yes yes it's lovely there's
just this incredibly long history going
back to I think Roman times and
certainly through the history of the
English language have a continual sense
of Despair that the language is falling
into total ruin and and of course it it
does go back to this kind of failure to
to really believe in the improvisational
power of human communication because if
you if you change people's constraints
so you force them to type awkwardly on a
on a keypad uh on their phone um then
they will they will improvise
differently they'll start to use little
symbols they'll start to use emojis they
they'll use all kinds of shortenings
they didn't use before but if you take
those constraints away they're not um
it's not they've got this fixed
structure they're now stuck with and all
they can do is sort of do Emojis send
emojis to each each other um they will
simply jump back to using the full
repertoire of communicative
possibilities so there's always this
sense that the language is going to the
dogs um but it but it never factly does
and of course the other aspect of it is
that um when languages change there's
there always this terrible fear the
distinctions that were really very
important are getting lost and how will
we ever be able to communicate about
this you this particular idea or concept
or this distinction which is being
blurred and the answer is we'll invent a
new one if it matters then will be a new
distinction before you know it so you
know one needn't worry um the the human
ability to to creatively solve
communicative problems that need to be
solved is not um is not going to get go
away and the fact we have distinctions
that we think they're important is is is
is telling us that there's a drive to
make those distinctions in certain
circumstances so they're going to get
they're going to get made and the
languages around the world are all very
different they all allow us to
communicate about just everything we
want to communicate about and they're
flexible we can add new words as you do
uh as as you do casual conversation with
your girlfriend you add you you make up
new words and play with language and you
make distinctions that haven't been made
before that we all do that and that's um
you know that that capacity the
open-ended nature of language is You is
our Salvation really and I think that
should make make us much less worried
about the idea that um that language is
this kind of fixed system continually
endanger of erosion
which rather like this the Greeks had
the sense that um their own civilization
was was a sort of a collapse from the
Golden Age and the um that sort of uh
human progress is already sliding
disastrously um and I think that's just
a natural a natural a natural tendency
and I think we should uh yeah fight
against it we should have a more
optimistic perspective we are actually
astoundingly creative creatures and
we'll um find our way to to to
communicate and think intelligently
about almost anything given half a
chance yeah I mean I think a lot of this
is because we feel that it's the
personification of an objective reality
and it's converged and and any deviation
is a kind of derangement of that but of
course that's just not the case at all
but it's interesting that that that
you're using the word you know um
communication expedience and there is an
interesting justos with communication
and thinking because I I I think you're
communicating a model and a model is
knowledge and the the process of
language evolution is epistemic foraging
so it's it's the search for new know
knowledge and knowledge which becomes
mimetically ensconced um is knowledge
that works because it has intrinsic
value by other people I mean we could
argue whether it has intrinsic value or
it just has memetic value because
everyone's using it but o over time we
you know the the the knowledge is being
shaped we're taking parts of the models
away that we don't need anymore and
we're adding in new models when we do
need them but some of that knowledge is
grounded to objective reality but
probably the the bulk of it as you argue
in the book is is really quite
relativistic yeah I think um the degree
to Which languages are shaped around the
physical world is is pretty loose um I
mean again the the thing that we're
mostly worried about in in in
communicating successfully is is really
local stuff so it's not that if you look
for example at the tax the biological
taxonomies that different languages have
it's not the case they all just map on
neatly onto either each other or what
sort of Modern Biology would tell us if
you looked at as it were the The
evolutionary history we're not
reconstructing that and we're solving
practical problems like these are edible
things these are not edible things these
are things that need to be cooked these
are things that don't need to be cooked
these are things you that run about and
have to be chased and these are things
that sit on the light on trees and just
could be forage the it's um these are
the you the things that um that the
Practical challenges we Face are going
to shape the way we we use words and
those will be flexible from one culture
to the next but but also from one
situation to the next um and as ever we
shouldn't be thinking ask thinking we
should ask the question and for this
language you know what are its Concepts
you what are the key Concepts in this
language that's a mistake because the
the um as we were talking about with
light there's no answer to the question
you know what does light mean or what
does creativity mean or what does
anything mean in the abstract there's
simply the sort of network of particular
um particular examples of how this can
be used
effectively so yeah in page 101 you said
that Nome chomsky's entry into the study
of language in the mid 1950s sparked a
revolution both in terms of ideas and
you know more literally as as an
academic kudat um the young Chomsky was
an iconic class and Brilliant scholar
you say deeply immersed in philosophy
logic and what would now be called
theoretical computer science and he had
a radically new agenda aiming to wrestle
Linguistics from the study of culture
which is what we've been talking about
and reconstruct it on abstract
mathematical and scientific foundations
so I what's your take on Chomsky yeah
well I think I think there's no doubt
the chomskian revolution in linguistics
is an astonishing achievement I mean
it's it's an amazing thing to take the
the the the intellectual ideas that have
been developed
for understanding formal languages um in
in logic and what became the foundations
of computer science and to realize that
that could be used as a basis for
understanding grammar so it's an amazing
um and an amazing
Insight but I think I think the breaking
away breaking language away from um
culture was a is a kind of fundamental
mistake from from Mor in my
perspective so we want to see we we want
to say the see the kind of chaotic and
um ill disciplined nature of language is
inevitable and the patterns that arise
within it are coming about both periods
of entrenched usages and repeated
analogies and so on so we want to see
the ordering language is coming up
coming about spontaneously through
process of cultural Evolution um so it's
going to always be inherently um messy
and inconsistent it's not not going to
be governed by um general principles
that the the the Rel relationships and
patterns within it are going to be ad
hoc um arising bottom up and therefore
conflicting like any other bottom up
principles of order different principles
will be governing different parts of the
language and there will clash and there
will be distances between them now if
we're coming from chomsky's perspective
you don't want to see language as a
cultural product at all uh you want to
see it as essentially an abstract
mathematical object and then the
messiness and awkwardness of language
gets sh shuffled off to be either
performance or just to be in the
periphery of the language so you say
there's this kind of there's this Core
Essence the essential part of the
language which in fact for Chomsky he
wants to view that as the that Essence
as the same for all languages aside from
parametric variations um and and there
but for us we we want to see the um the
patterns in language as as as as the as
a secondary so rather than saying
there's this kind of core um and then it
kind of um for some mysterious reason is
varied and sort of messed up by you know
actual linguistic use and the evolution
of actual languages but the core is kind
of solid we would like to say the the
patterns and commonalities and and sort
of regularities in language are things
that are emerging um over time so you
start playing shirad without any of
these but after a bit of shirad play
suddenly pattern start to emerge so of
course that from that perspective you
don't want to have you shouldn't be
looking for um the kind of mathematical
abstraction which is going to perfectly
capture language it's just a mistake to
think that's such a thing um and and the
only way you can maintain that Viewpoint
is by an awful lot of violent um
cajoling of language to fit the pattern
um so my feeling would be that um it's
much better to to see language as are
soft flexible culturally uh created and
ever ever mutating uh
construction rather than having a a
fixed mathematical basis so I think the
chopski Insight is is is the program is
a fascinating one but I think ultimately
it hasn't proved to be the right tack
yeah I mean as a computer scientist I
can really understand where he's coming
from and you know he he developed this
um formal language hierarchy yeah mean
he he was thinking about um you know
touring machines for example as being
able to recognize recursively
innumerable um languages and it's it's
mathematically beautiful but it does
point to this tendency that I think
we've seen particularly in the 20th
century to develop theories of
everything and what I would call
universalism which is his idea to try
and describe the world in just some very
simple abstract model I mean we've
spoken with Steven wolf from he's he's
another great example of this even um KL
friston had you know people have argued
that the free energy principle is a form
of universalism and um why why why do
you think there is such a tendency to
try and reduce the world in this way
well I think it's it's a great trick if
you can pull it off I suppose so it's
not obvious to start with that um
newtonium mechanics or something close
to it is a pretty pretty good
description of large amounts of reality
but my goodness it is so miraculously it
turns out that you planets and and
apples uh obey the same laws fantastic
um so I think it's natural it's a
natural ambition to have but I think
it's also in most cases a hopelessly
unrealistic one because the world is
actually just a very uh chaotic and
complex place and and it's it's
essentially historical so I suppose the
Universalist perspective is saying um
it's started from the assumption that
there are sort of deep templates which
are not forged by sort of random
historical contingency and the Deep
templates got to be um got to be found
but but the more you think of the
aspects of reality you're interested in
as historically contingent and you know
like these are the shrads we play this
is the way the the the um our thinking
took us these are the environments we in
this is how our bodies are constructed
these are the challenges we face this is
you know this is the stuff that this
particular group of people um wanted to
talk about here's their language here's
another one if they had even the same
problems face them again they'd have
come up with something else it's just
not you know it's just not going to be
something that's that yields to that
that strategy um so I think but but but
of course our most successful uh and
sort of
striking U theories in in in science
have that character so it's very natural
to want to emulate them if I could think
of a universal theory of language which
works I'd go for it I just don't think
it's possible yes I mean what I like
about chomsky's theory is is that it's
intelligible it's high level and it kind
of you know carves up the world in in an
interesting way whereas you know um
Steven wolfram's Theory um the the
content of the universe is still in the
emerging complexity even if it can be
constructed from simple um building
blocks which I guess would distinguish
it but um we should we should move on a
tiny bit so um my very good friend
Professor Mark J Bishop um we both read
your book at the same time and we were
messaging each other on LinkedIn
remarking on on your book and he says he
started the book and um a couple of
things cropped up for him was that um he
thought you were focusing on an
anthropomorphic aspect of language and
he cited Ferdinand cersa so he defined
language as an internalized system of
symbolic units defined by their inter
systemic relations um following Roy
Harris um who's he's a fan of of Roy
Harris by the way is a linguist who
invented a theory of communication
called integrational ISM which
emphasizes Innovative partition
participation by communicators but he
said he thinks to he prefers to think
about language or languaging as a mode
of exercising influence about an
entity's future intent and he actually
gave the example of Imagine The embodied
language of an operating theater where
even the bodily positions of the nurses
and the doctors and the technicians can
the meaning of a game you know in in
kind of operation so would you entertain
that kind of expanded view of the game
yeah yeah no absolutely indeed um I
think that goes back to the viian notion
of course of a language game where um
vicenin has a an example of of two
people doing some building together so
you one person says slab and it means
something like I need a you know slab
over here to put put put in position or
it might mean um you that slab's the
wrong slab or it might mean you know
break a slab into pieces for me or it
could mean all sorts of things and it
would be clear from the context just as
and the Au raing theater obviously has a
similar kind of setup so sort of a shout
of you know forceps or scissors or
whatever it's probably going to be have
different meanings if you're you know
doing the operating versus um if you're
you know cleaning up the instruments or
something yes um so so yes I think we
should always be thinking of the game is
very much embedded and we don't you we
don't particularly emphasize this but
embedded in the the sort of moment
interactions that you're engaged in so
and then it becomes even more clear that
the the the work the language is doing
is is is is always scaffolded by all of
the other stuff I mean we're trying to
we're trying to successfully do stuff
together we're trying to co have
coherent coherent um interactions where
we you know collectively operate
successfully build something you know
how take turns whatever it is share
things cook meals and that that that's
that's the the the purpose of having
communication at all um so so yes in
some ways the load that language is
bearing is quite a light one and and the
more we have this other Rich stuff than
the lighter it is and I suppose the
illusion is thinking yes but if you took
all that away and just dealt with the
null context some sort of you know free
floaty rounded space then if you just
what would language mean then which the
answer is well sort of nothing really
you take take all the context away and
you've just got you sort of empty empty
symbols but on on this anthropocentrism
point though I think Mark feels that
there isn't such a bright line between
humans and animals and and in the
language game and the thing is I I was
on board with your argument because you
you are I think pointing out matter of
factly that we have this social memetic
plasticity and complexification and
animals don't so it's not that they
don't have a social world but they don't
have the plasticity that we have I think
that's that's right so certainly an
animals have communication systems but
they don't have communication systems
that differ from one species to another
so you the wagle Dan of the be for
particular system of species of be will
always be the same now you people
sometimes say aha but wait a minute what
about Bird song bird there are birds
which have variable songs but of course
they don't actually have a communicative
function so it's not that the bird is
singing something it's like ah now you
know over there there's some some food
or um you um there's no there's no
there's no sort of um conflict of
flexibility and communicative function
that's the thing that that's amazing
about people so I do yes on on that
aspect about anthrop anthropocentrism I
think I'm I'm with it so there's no
analog of the operating theater for
animals where um they're engaged in some
collective activity and sort of grunting
and nodding to each other and those
Grunts and nods are being systematically
interpreted or at least if there is such
a a thing we you that would be very
interesting to discover but I think I
think that's that would be a
non-standard perspective to think that
there's n other animals other than us
who can do that yeah it's weird because
I was reading that Max Bennett book and
and he talks about mellian apes so they
they do develop sort of like plastic
behaviors but then but the the the
templates are not shared mimetically I
think that's the difference gpt3 can
write short stories technical manuals
and press releases and do other simple
tasks such as answering questions but
gpt3 is not mimicking the human mind it
has no mind at all and you said to put
it metaphorically human language is to
GPT as the horse is to the motor car
horses have indeed been replaced by
Motorcars and buses and trains as the
most efficient um means of human
transport but they're um scarcely
artificial
horses yes yes well I I think that I
think that is right really so I'm I'm
not as worried about the singularity as
many people um so I'll I I'll give you
my my my positive perspective which is
don't worry about the singularity we're
okay but also I'll just add a note of
caution because I feel a bit more
cautious these days so the positive
perspective is I think yes the idea that
the ability to to answer questions in
natural language is somehow the sum
total of human intelligence I think is
is is a fundamental mistake and an
interesting question to ask oneself is
if um we allow large language models
purely to talk to each other forever
more how far are they going to get right
what they what new things are going to
do or invent nothing is my suspicion so
they're just pumping out they're they're
taking our language they're pumping it
back out and then just pump it back in
and out and in and round it will go and
we're going to get absolutely nothing
new whereas humans are creating new
culture and um new inventions new ways
of doing things all the time of course
obviously these models aren't engaging
in in acting in the world as well they
didn't perceive but irrespective of that
um there just not you they're in a kind
of echo chamber so we can create uh a
culture which they can um reflect back
at us but that's that's just reflection
and you might say well we aren't we
doing that well I think to some extent
not we are of course we are hoovering up
information and we are able to U reflect
it back at each other but we're also
able to you we we're sophisticated
reasoning beings who are actually able
to generate new ideas and thoughts and
so I I I think I don't I don't think we
should be too worried I think this is a
very narrow though impressive um
achievement so that's my positive sense
that you the the um the thing is that
these these systems cannot in particular
place your BRS in a way that we can um
so the thing about human communication
is it's not just all about firing back
reflecting back things that have been
said before it's about solving problems
in particular situations in Creative
clever ways and this is not yet what
these systems can do and maybe maybe
it's very very far from what they can do
so the sort of thing that makes humans
remarkable is that with practical
objectives and goals in front of us and
the language that our disposer we can
you say intelligent things and work
together in in a creative flexible way
which is you not um yeah it's not not
not just a generation of abstract text a
quick point of that though so these
models are now embedded in our cognitive
Nexus and they are um they are referred
to as generative AI people even think of
them as being a creative thing and I can
understand why people think that you can
put any input into GPT and people think
that you can kind of explore the space
of any possible output but of course
that space is constrained perniciously
by data and model bias and various weird
motifs that are baked into the model and
um so I think in in many ways having
these things embedded in our cognitive
Nexus will kind of constrain our
creativity in a very kind of pentious
way I think we have to worry about that
for sure yes I mean if we're all it's a
bit like it's a kind of more extreme
version of um if everyone uses the same
search engine we all find the same
things when we're interested in the same
topic yes and all the other stuff gets
kind of lost and we it becomes even more
dangerous if we have the same
essentially the same summary paragraph
keeps coming out of the
the way to look at this is this and
these are the crucial issues um so I
think we should be very cautious I think
people doing research um very rarely get
in sensible answers out of large
language models so if you actually have
something tricky that you don't
understand then asking asking a large
language model is almost invariably just
gives you a a pile of stuff which is
exactly the stuff you didn't understand
in in a slightly random order it's not
that the large Lage model has you sort
of solved the puzzle that you were
struggling with it's not said oh yes I
was wondering about this too and in fact
the answer is this it never does that it
just gives you the the salad of various
odds and ends that you don't quite you
know what to do with so it's not I mean
you know it' be an awful lot to ask for
it to to sort solve all our problems for
us but it but it isn't doing that um so
so I'm yes I'm optimistic that if you if
you think to build a uh a system that's
really going to contribute to you you
Human Society at the level of a fellow
human being then it's going to have to
be engaging in this charad likee
Behavior it's going to have to be able
to have conversations with us in in in
better in the world we're in helping us
do the things we're doing having
struggling with the problems we're
thinking about and wrestling with and
the context we're in as well as just
firing back sort of disembodied streams
of of text so that's why so my positive
view is Lang machines don't large
language models don't Place Shas then
nothing like as smart as we are are
doing something very different Sor just
quickly on that do you need agency to
play Shard well well I mean I don't know
um how we tie it to agency I'm not sure
um isn't that isn't that a fascinating
thought yeah it is it is very
interesting I
mean I I've sort of Mo my instinct would
be to play
shrads well in a of consistent way you
need to have um a sense of your joint
understanding with the other person
because you have to have a sense of
these are the things know in comma and
if I do these actions that will remind
you of the same thing it would remind me
of if I were in your shoes and that's
going to be that that and that's going
to trigger the thoughts that would
trigger in me so we've got to have some
sort of sense of common understanding of
the world so it's an interesting
question whether you can actually do
this without essentially being um
yourself something awfully like a human
intelligent agent um yes and and I I
used the word agency but a deflationary
word would be to use Divergence there's
something about a Divergent search
process accumulating these epistemic you
know nuggets of information putting them
back into our um information ecosystem
it feels like if we had a like a
monolithic centralizing algorithm it
wouldn't have the same characteristics
well I think any monolitic centralizing
algorithm is going to lead um yes to
sort of a centralized and standardized
way of seeing the world which very
different will not not lead lead us
forward as a as a society so and this is
this is a sort of General point about
distributed computation I suppose you
need um to have large numbers of a
agents thinking in Divergent in
different ways and The evolutionary
process U generated by those Divergent
thoughts uh and and and perspectives
will and some of which will be abandoned
most of which will be abandoned other
which others of which will catch on
that's actually the process to to search
a large that's the way to search a large
space of of of an open-ended space of
interesting possible things to think
about and do once you've have
centralized this in in one giant Echo
chamber then then you're we're in
trouble um yeah but but but just to
bring it home I mean so X risk people
worry about the singularity and I think
the I think recently they've
cannibalized AI ethics in governance and
they're they're moving away from the
previous mono maniacal AGI that's going
to kill everyone and now they're talking
about mtic intelligence which is the
same thing we're talking about but um I
me I don't know whe whether you think
that the mon maniacal superintelligence
is even possible but if we are talking
about the memetic collective super
intelligence that we already are a part
of presumably you don't think we need to
worry about that killing everyone no no
I think I don't so the the monom
monarchal um super intelligence I I'm
basically not that worried about but the
Staggering effect effectiveness of large
language models has slightly shaken my
confidence
um so I suppose one thing is we should
always be suspicious of any any
confident feelings we have about
anything you know obviously we we're all
we're always making errors all the time
about these things we're always thinking
no one will need more than the world
won't need more than three computers and
all sorts of The Beatles With You guitar
groups are on our way out we don't need
the Beatles and all of these you
pronouncements that have been made
throughout history with great confidence
by people with great expertise and
turned out to very rapidly to be total
nonsense that we should always be
doubtful about those thoughts and in
particular if you if you'd asked me 20
years ago say or probably 10 um would it
be possible in the 20 uh 2024 to create
models which can chat about any topic
can write write a poem about any topic
can decide to um can be instructed to
respond without using the letter b and
so on and so on I said no way no way
there's never possible you must be
totally joking go to the 22nd century
what are you thinking and and I was
completely wrong now I'm not sure that
the people who developed large language
models had a particularly different
intuition either um or if they did maybe
just a personality trait just more
optimistic characters but no one really
could see the path I think no one could
see oh yeah we're kind of here and if we
just move a bit further along suddenly
um these problems are going to be
solvable it's just it's sort of
miraculous I think it's an amazing thing
that they proved to be solvable so I
suppose I've slightly been shaken in my
intuitions about you where what's near
and what's far my I suppose having lived
through the sort of good oldfashioned AI
um period the the story for such a long
time was oh massive changes around
around the corner amazing things are
about to happen oh no they didn't oh no
they haven't no still that still that
happening they're just about to happen
we give it a bit more time and neural
networks of course look like they were
part of this coming in in you know even
in 50s 6070s um it's very interesting um
I remember seeing Jeff Hinton give a
talk 1985 and being sounded by it I'm
just amazed I just thought this is this
is most wonderful wonderful stuff but um
the idea that we get to a point where
suddenly all sorts of applications and
all kinds of um capacities were emerging
no one really saw coming uh that's
amazing so so I'm I'm just a little bit
less gung-ho and relaxed than I might
have been in the past but but but
ironically it's apparently intelligent
but not intelligent and you know but you
know you could argue it's just the
mordak effect you know you're just
moving the gold po posts and everything
but it it feels to me that while it's a
miraculous achievement and what open AI
are doing with the generative Vision
models it's fantastic but I still don't
see a path to it dramatically changing
the job market because you still need
agents doing things they can these
things are tools right they don't do
anything on their own no no I mean of
course tools can change things very
drastically over time I mean language
itself of course from the languages
language shad's perspective anded from
lots of perspectives is a in a way the
most spectacular tool of all and that
has changed what's possible for humans
to do over long periods of time and you
I suppose you might say Well when
mathematics first started up it seemed
pretty pretty impractical didn't seem to
do very much of any use um and so
probably in the long term and maybe it's
not we're not talking about centuries
here we may be talking about shorter ter
term than that then the these systems
will will radically change what we can
do um but like you I am skeptical of the
immediate totally revolutionary impact
these models are going to have on our
lives I think it's going to be um it's a
bit like sort of Google search with with
bells on uh from a practical point of
view as a piece of technology it's
miraculous and I think it's actually
giving us probably deep insights into
the way brains and intelligence systems
can work which we didn't have before
it's incredibly exciting it's very
exciting to be alive at this time it's
really is a massive um yeah it's a
massive intellectual shift and I'm sure
um I hope I very much hope there are
people around in many centuries to come
and if there are that I think they will
look back at this as a as an absolutely
seminal moment and they won't won won't
be forgotten and lost in the midst of
time this will be you massively I viewed
as massively significant um but it isn't
I think it's not the emergence of it's
not an emergence of a new species of of
intelligent being it's going to be
living alongside us anytime soon Nick
Jor it's been an absolute honor to have
you on the show thank you so much it's
been a great pleasure thank you so much
Tim wonderful right great stuff that's
