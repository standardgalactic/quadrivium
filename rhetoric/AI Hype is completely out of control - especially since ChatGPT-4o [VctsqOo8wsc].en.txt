so I made a video early last month about
how I thought the current trend of large
language model AIS would impact the
software development industry over the
next handful of years since that time
there's been a lot more discussion about
that a lot of it driven by the release
of Chad TBT
40 now that release has caused a lot of
people to buy even more into the
hype some of those people are in the
comments on this channel some have even
been from major news outlets and that
makes sense the hype says that within a
handful of years we will have human form
factor robots with roughly human
intelligence for what could be the
current price of a luxury car or the
haters say that LMS will soon be as dead
as
nfts as always or at least almost always
the truth surely lies somewhere in
between but
where we know there's going to be
disruption in the job market indeed ai's
already caused issues in the job market
I've talked about that several times
we're starting to see companies
reporting that they're using fewer
programmers due to AI or holding off on
hiring due to AI for example BP is
saying they're now needing 70% fewer
coders looks like
contractors and yet the number of times
AI was mentioned on earnings calls this
past quarter was a fraction of the
number of times it was mentioned in any
of the previous four quarters so which
is it is it cutting into programmers a
lot or is it dying out right now we
don't know it's possible the staff
reductions are only temporary and that
the code quality will be poor enough
that they need to hire more programmers
to fix fix it we won't know that for a
while and neither will those companies
lots of bugs take a while to get noticed
especially when you're not actually
trying to find
them and we don't know how the numbers
of programmers reduced at companies like
BP compared to the numbers of
programmers that are being hired because
of AI so at the moment while things are
in flux and companies are making bets
and we don't know which way the bets
will turn out what do we
do I say we try to look further ahead we
try to look at the fundamentals and try
to guess how we think it's most likely
to end up if not when if it's a bubble
it'll pop they always do although it's
basically impossible to predict when
they will pop if it's not a bubble and
the hype is correct it's going to be a
huge societal disruption and if that's
the case it's going to be really hard to
plan for or both back in 99 2000 there
was a bubble in Tech startups and it
popped and there was a drop in overall
Tech sector jobs that didn't start
growing again until about 2004 but the
underlying teex was real and it was
valuable and it enabled the internet as
we know it to day the promise of the
internet back then took 15 or years or
so from the start of the bubble to
really take off and maybe that's the
kind of time we're talking about it's
kind of hard to know
yet which means we need to know what we
can about whether this is a hype bubble
and will pop soon or a tech that's
fundamentally disruptive and where we
have to start that investigation because
it's the best data point we have right
now is with chat GPT 40 and based on
what I've seen so far I think it's
pretty clear that
this is the internet of bugs my name is
Carl and this was originally going to be
an explanation of what I thought about
chat GPT 40 and why and it still is but
it ended up being a little more ranty at
the end hopefully you'll stick with me
till then so to start with Chad gp40 is
much faster than I expected it's very
fast and that's great aside from that
though I'm not really impressed
the thing that everyone seems excited
about is the voice interface and I think
that most of the people excited about
that haven't really been paying
attention as I explained in my AI agent
video before Faro came out we had voice
and Camera Graphics interfaces to chat
GPT and other llms for a long time now
below I've linked instructions on
hooking chat GPT up to a voice interface
from February of last year the
functionality works out of the box now
and that's great it's very convenient
and it's faster but it's nothing new and
it's not really an advancement
doing tasks cheaper and faster isn't
nearly as disruptive if the tasks aren't
difficult or they aren't done well or
they aren't done correctly and doing a
wide variety of tasks correctly
determines how autonomous an AI can be
and therefore how many and what kinds of
jobs it might be able to displace and
most relevant to my expertise how it
might impact software
jobs and how the jobs that have already
been impacted are likely to stay
impacted or likely to come
back so the next question is what do we
know about about 40 doing tasks better
or more
correctly my personal experiences with
it have been disappointing in my last
video I talked about how perplexity doai
found a Steve Jobs quote from 1983 for
me but 40 told me it didn't exist and
for the record Google couldn't find it
either even if I gave Google the exact
quote to search for but I started my
career as a physicist and physics and
science is all about experiments and
evidence and that's really served me
well over the years believe it or not
both in being able to separate hype from
reality but also when I'm in my
day-to-day work and I'm troubleshooting
or debugging using evidence to actually
narrow down what the real problem is and
finding and fixing it and figuring out
what experiments to run to make the bug
show up has been incredibly
useful I do my best to gather the
evidence I can find I look at the
evidence I've gathered I draw
conclusions if I see new evidence I'll
revise the conclusions this is a pretty
much constant
process it has been pretty much my whole
career when I hear news stories or read
articles that are relevant to technology
trends see if it's information that
changes my guesses about what's popular
or what's becoming more or less
important even before I started this
channel I did this it's important for me
to decide what I'm going to spend my
time on and being frank if that's not
something that sounds like you'd want to
be keeping up with for the rest of your
career then maybe a technology career is
not for you so briefly and so I can
point people to this section of video
when they spout garbage in my comments
what counts as evidence one researchers
publishing peer-reviewed papers are the
gold standard of evidence they aren't
always correct in hindsight people make
mistakes some falsify even data but
that's as good as evidence ever gets and
the papers that are wrong eventually get
found out two benchmarks are evidence in
fact that's the whole point of
benchmarks benchmarks are generally what
are used in most of the peer-reviewed
papers that we have about LM
performance some people in the comments
have tried to argue that benchmarks
aren't evidence or don't count as
evidence or they can't be taking at face
value for some
reason what I can tell you is lots of
researchers use those benchmarks as
evidence paper after paper many of those
papers are linked in this video and as
long as they keep doing that so will I
and I won't care about your
opinion three firsthand observation of
facts not speculation not things that
might happen in the future but things
that have actually happened count as
evidence if they come from unbiased
sources that have relevant
experience and lastly and least usefully
Trends actually are evidence it's pretty
crappy evidence but when it comes to
predicting the future that's often all
we've got but it only counts if the
circumstances in the future are the same
as the circumstances in the past but if
the circumstances might be materially
different then I don't trust the trend
will continue and I don't think that you
should either and I don't count that as
evidence so to be
explicit A commenter on a YouTube
video's opinion on the future doesn't
count unless it's backed up with sources
a commenter's opinion about a video or
an article doesn't count unless they
back it up with sources or facts but the
same is true of me I try to back back up
the information I give you and the
conclusions I draw with sources my video
descriptions usually have lots of them
when I talk about things I'm an expert
in I try to give examples and sources
and citations and further reading and I
try to explain what scenarios and
experiences I've seen that lead me to
draw the conclusions that I have at the
time of this recording there are close
to 60 URLs in the list of references for
this
video so back to chat GPT 40 the
consensus is it's way faster I've been
told it's much better at many
non-english languages although I'm not
an expert in that it interacts with
sound and images without having to have
pre-processors and post-processors to
convert and that's cool and convenient
but when it comes to accuracy it's
sometimes better and sometimes worse so
mlu is 2.2% better than for Turbo uh GP
QA which is a science benchmark is 5.6%
better but on the drop Benchmark which
is complex reasoning and math it's 2.6%
worse than four turbo and there's a new
Benchmark called seal um at which 40 is
actually worse than for Turbo um it's a
very promising new Benchmark now don't
take my word for it here's a link to a
tweet from Andre kpoy who's the former
Tesla director of AI hope I got that
name even close to right um he's an open
AI founding team member um I talked
about him in my last video there were
some complaints in the comments one my
earlier videos about some benchmarks
that I graphed that were on a scale of
0o to 100% seal shows the same kinds of
Trends but it doesn't have that
limitation and and neither does this
paper about how chat gpts behave
behavior is changing over time note that
this paper only Compares 3.5 and four
and so I'm looking forward to when they
add 4 o to it but according to this
there's actually not a lot of
improvement between 3.5 and 4
even so you can choose to believe that
40 is better if you want but the
evidence is mixed so it can't be
dramatically better at least not in the
realm of how well it's able to correctly
perform tasks and according to some
research on some benchmarks there hasn't
been a lot of improvement since
3.5
so if that's the evidence we have about
40 what does it tell us about the future
so this
graphic I guess this counts as evidence
it counts as a fact but it's evidence of
the fact that they're going to be
spending a lot of money training GPT 5
it doesn't actually tell us anything
about how much better or worse it's
going to be at what tasks it can do and
how well it can do them uh despite what
people on the internet tell you we know
that there a trend that the models have
been getting exponentially faster and
cheaper for years and that seems to have
continued through 40 so it's likely to
continue for some time and that's good
for lots of reasons but when it comes to
tasks and correctness we know there's
mixed evidence and so we don't really
know how to extrapolate from that so the
best method of predicting the future is
about extrapolating from Trends what
other Trends are there that we can draw
from turns out there are two important
ones and they're not actually discussed
very much which is interesting the first
thing we don't talk about much is a
bunch of experts who have been doing
relevant research for a very long time
but very few people in the tech industry
have paid any attention to them at all
because they're not part of the tech
industry these people are psychologists
and ethicists and philosophers who study
not what neural networks can do but why
humans are predisposed to be
particularly gullible about the
sentience of AI it turns out that the
human brain seems to be hardwired to
believe that things that we interact
with have thoughts and feelings and
desires and such and such I'll put links
down below there's a very long history
of people attributing thoughts and wants
and desires to everything from weather
and nature to tools to pet
rocks and not only do we naturally tend
to believe that non-human things have
thoughts and feelings but lolms have
been giving attributes that make us even
more likely to believe it there's a
thing called the Eliza effect which has
been known since the 70s where a chat
interface causes powerful delusional
thinking in humans that has been likened
to a slow acting poison so there's a
term ter that has been coined by
researchers that's called Dark patterns
it describes user interfaces in products
that trick people or trick the brain
into behaving in ways that the producer
of the product wants that is contrary to
the interest of the consumer or the user
dark patterns are a huge topic and
researchers are just starting to study
the dark patterns in llm chat Bots paper
below but two recent other papers on
dark patterns are particularly relevant
to chat GPT 40 one of them is about how
synthetic voices impact human decision-
making and the other is about how
cuteness is a dark pattern does the fact
that 40 has not only synthetic voices
but cute a effects like giggling does
that influence what people think of 40
that specific research hasn't been done
yet but based on past findings I expect
it's going to be very revealing when it
happens but we know that intentionally
or not llm chat Bots have been designed
in a way known by psychologists and
ethicists to trick into believing that
they're intelligent and that trend is
getting worse and shows no indication of
getting better one more Trend that's
relevant to all this it's been going on
for at least eight years with respect to
AI specifically and a whole lot longer
in general so for once I'm only going to
go back as far as 2016 for brevity sake
I could go back farther but it would be
less relevant so last year we found out
in a lwuit deposition that Tesla faked a
self-driving demo in
2016 the independent which a
an outlet in the UK recreated a Tesla
demo in 2022 and found that it actually
crashed right into a cutout of a child
as opposed to what the Tesla demo
did okay enough of Tesla let's talk
about Google for a minute so in May of
2018 Google famously faked its duplex II
demo oh and Google faked their Gemini AI
demo in December of 2023 so they didn't
learn
much recently Google claimed that they
Deep Mind created 2.2 million new
materials VI actual researchers said
quote we examine the claims of this work
and unfortunately find scant evidence
for compounds that fulfill the trifecta
of novelty credibility and utility in
other words very few of the 2.2 million
compounds that Google claimed are of any
use or haven't already been
discovered a Google BP recently released
a thing that said quote in addition to
designing AI overviews to optimize for
accuracy we tested the feature
extensively before launch this included
robust red teaming efforts evaluations
with samples of typical user queries and
tests on proportion of search traffic to
see how it performed and yet Google AI
said that we should eat at least one
small rock per day and add about an
eighth of a cup of glue to pizza
sauce so we can really trust Google
let's talk about Amazon so Amazon's AI
checkout technology the let's walkout
technology turned out to be thousands of
remote workers in India instead of an
actual AI ironically that was done via
Amazon's online task platform that's
called Mechanical Turk which is named
after a famous fraud from the 1770s
where a chess playing robot just turned
out to be a man hiding in a box pulling
its
strings usually I don't go back to the
1770s but I guess it happened sometimes
and there have been a bunch of times
when something that was said to be AI
just turned out to be a bunch of remote
people doing the work so GM's Cru
self-driving car technology used 1 .5
remote humans for every vehicle on the
road to quote remotely control the car
after receiving a cellular signal that
it was having
problems Facebook had an Siri competitor
called M and it was supposedly
supervised by humans reportedly though
quote in practice over 70% of requests
were answered by human operators it was
shut down in 2018 supposedly it was very
expensive the SEC has recently started
charging companies with what they call
AI washing which is when companies say
that they're doing things with AI when
there's actually no AI
involved and then there's things that do
use AI but that companies insist on
lying about how well it does the AI so
on January 23rd
2024 Microsoft said quote Microsoft aims
to provide transparency in how its AI
systems operate allowing users and
stakeholders to understand the
decision-making processes and outcomes
48 hours after that Microsoft's products
were used to make viral deep fake
non-consensual porn of Taylor
Swift after the Taylor Swift deep fake
porn went viral it was reported quote a
Microsoft AI engineering leader says he
discovered vulnerabilities in the open
ai's Dolly 3 image generator in early
December allowing users to bypass safety
guard rails to create violent and
explicit images and that the company
impeded his previous attempt to bring
public attention to the issue so much
for transparency
the rabbit R1 demo showed a bunch of
things that reviewers said just don't
work and it turned out to be just an
Android app the Humane iip pin gave
false information in its demo video and
then the company quietly re-edited the
demo with new audio to make it look like
it gave the right
answers the AI pin was famously called
the worst product a particular reviewer
had ever
reviewed what about open AI though have
they been caught lying about demos
quote perhaps the most widely touted of
gp4s at launch zero shot capabilities
has been its reported 90th percentile
performance on the uniform bar exam well
new Reports say it was actually in the
15th percentile of those that took the
test for the first time turns out that
what open AI seems to have done was
arranged it so that their AI got
compared to a bunch of people that had
taken the test before and failed the
test before and were really likely to
fail it again and it got better than 90%
% of people that were likely to fail it
again at least one of open ai's Sora
demo videos was done by an FX group
called shy kids link below for that
there was a recent interview with an
former open AI board member who said
that Sam Alman had created quote a toxic
culture of
lying H oh and then moving on from open
AI there was this thing called Devon um
they kind the company that made Devon
kind of Li about that um there's a video
about that you might have heard of it
and there were other examples I didn't
put in this list because they were less
directly related to Ai and keep in mind
that's just the companies that have been
both
caught and that were high enough profile
to actually make headlines and get
reported
about I've been part of many software
demos and many product launches over the
last 35 years and in my professional
opinion in my experience lots of demos
LIE there's nobody to know for for sure
but based on my past experience I'd
guess that maybe for every demo that
gets exposed at least a couple of demos
get away with it maybe more and yet we
have people insisting that this is all
real a wire.com article called it's time
to believe the AI hype came out on the
17th of May just after the chat GPT 40
demo it tried out the same old joke
about a friend that takes another friend
to a comedy club to see a dog telling
jokes and the first friend said what do
you think and the second friend says
well the joke's bombed I'm not that
impressed the article then says folks
when dogs talk we're talking biblical
disruption and maybe but let me ask you
this if you're confronted with a talking
dog at a comedy club what's more likely
that there's a dog that's actually
talking or that like Amazon Fresh what's
supposed to be an unprecedented
breakthrough is really just a bunch of
people behind the scenes trying to trick
you I know what I'd bet on and to top it
off the concluding paragraph of that
article insists quote this is a direct
quote but the demos aren't lying except
for you know Tesla self-driving and GM's
Cru self-driving and Google duplex and
Google Gemini and Facebook's M chatbot
and open AI Sora and chat gpt's for's
bar exam and Amazon freshes just walk
out and rabbit R1 and human AI pin oh
and Devon
again deep
breath so there's no clear evidence of
accuracy in task performance getting
better there is clear evidence that the
features being added to these products
are attributes like voices that are
known to make humans more likely to
believe that the products actually think
there is clear evidence that the
companies have been lying about ai's
capabilities for years not all the
companies but many of them and there's
clear evidence that journalists again
not all of them but many of them have
and will continue to make irresponsible
statements like the demos aren't lying
all evidence to the contrary but we have
to make decisions about what we're going
to spend our time on and we have to
decide what we're going to learn and
what we're going to avoid and whether we
want to switch Majors or switch careers
or what what's going to happen with AI
is one of the bigger questions in
software careers right now in Tech maybe
even in the world and I'd really love to
know what's going to happen and if I did
I would tell you but I don't and
honestly nobody
does what I know is that there's
currently no clear evidence that we're
going to get human level artificial
intelligence anytime
soon and what we really know for
definite sure is that many of the people
that are telling us how great it's going
to be not only have a financial
incentive to lie about that they've been
lying about it for years and have been
lying so obviously about it that they've
been caught lying about it over and
over and that many people we should be
able to trust like journalists who
should know better keep saying things
like the demos aren't lying even though
many many of the AI demos have been
lying and have been proven to be lying
over and over since at least
2016 so we're on our own and we have to
make up our own minds and like
generations of scientists going back to
at least the 16th century I'm going to
choose to follow the evidence and I'm
going to choose to reject the narrative
that's being promoted by the people who
have a toxic culture of lying but hey
you do you never forget the internet is
full of bugs anyone who says differently
probably thinks you're so stupid that
you would believe that dogs can actually
tell jokes let's be careful out there
