stuff that we find interesting in humans
is this ability to become self-authoring
to change their own way in which you're
interacting with the world in which
you're interacting with yourself
becoming a different system developing
yourself growing evolution is the
competition between different software
agents that can reproduce and can can
code themselves and they use the
molecules to encode themselves and they
use the mechanism to implement
themselves and perpetuate themselves and
compete but it's actually all about
software it's all about spirits
yosha Yos yosha back is a leading
cognitive scientist an artificial
intelligence researcher with an
impressive background you have said that
Consciousness is a virtual property
virtual means as if so something behaves
as if it would exist and I think that
the objects that we are we are conscious
agents for instance that observe
themselves interacting with the world we
know that from a physical perspective we
do not exist if you take any kind of
measuring device and you look at the
human brain you will not see a person
what you will see is an activation
pattern between cells that is producing
the behavior of the person in the same
way when you take a microscope and look
at a computer that runs Minecraft you
will not find any Minecraft what you
will see is some uh pattern of
electricity that is propagating through
the transistors of the computer and at
some level this producing the causal
structure of Minecraft but you could
also say that Minecraft is never the
this real it's it's implemented and I
find this definition of saying something
is real to the degree that it is
implemented quite useful and we find
that there are different degrees of
realness controlling the future entails
making models and the better you can
model the better you can do this and at
some point you have to discover yourself
you regulate the world in a particular
way and your model making Works in a
particular way and then trying to figure
out in which way did my own model not
work and what are the limitations of my
ability to observe and make models and
when this is happening you start to edit
your own source C and then it becomes
really
interesting yosa back it's an honor to
you on the show thank you my pleasure do
you feel the AGI in some sense it has
not changed very much I felt that the
AGI is coming when I was a young kid
when I realized what computers can do
and in many ways I see that the world is
now more optimistic and there is this
amazing momentum and also a lot of hype
in the air but it's also not clear how
far the present technology is going and
when and so it's a very exciting moment
in time but we don't know how far in the
future AGI actually is what are your
timelines for
AGI I think that's uh going to happen in
our lifetime
and there's also the question what AGI
actually is so it's something that we
probably have to think about more deeply
a lot of people thought having a system
that is like in Star Trek where You' say
computer please do the following would
be AGI and arguably we have that now
right if you remember this 1980s Star
Trek episode or at this time when he
goes going to go back to the 1980s and
walk the streets and a Scotty is trying
to use a computer and addresses it and
the computer does not understand him
speaking to it in natural language
doesn't understand English doesn't not
parse his sentences he is labber gusted
and it's really interesting to the
contrast because back then it was
obvious to us that um computers cannot
do such a thing and they can only do
their far distant future and now they
can and now we are bitching around the
fact that they are somewhat unreliable
and sometimes make up stuff and that uh
sometimes they cannot perform certain
task and people can do very well and at
the other hand we are seeing that there
are performing skills that we consider
to be quite amazing we see them getting
to the level offer silver medalist in
math but uh we don't know how well
they're doing when something is
happening out of distribution arguably
there was a lot of training data on the
performance of mass uh in the models
that they but stuff that they were
looking at and people fine tuned the
model to um perform better in
circumstances but what I observe and I'm
playing with the llms is that in the
domains I'm truly competent the llm is
typically staying a bit below my own
performance it's only in the domains
where have no competence that the llm is
often able to do something that I find
very impressive and so is intelligence
the ability to for perform at slightly
superhuman level across many many
domains by being very fast and then
somehow combining that to get to the
next level or is there something that is
fundamentally missing what we can see
it's it's clearly different from our
performance but maybe AI is is not so
much about a skill but about skill
acquisition so when we are testing AI
using intellig um tests for humans that
usually don't get the useful results and
that's because intelligence tests for
humans are directed on skill typically
we test the performance on a given task
and we hope that people are not able to
train that performance very well so it
correlates somewhat to their ability to
solve puzzles of EX Neo from from start
instead of just memorizing how to solve
puzzles but um this makes human
intelligence tests unusable for using
them outside of the human context they
cannot use them for animals cannot use
them for machines because we measure the
skill performance by taking average
human level and then measuring the delta
in some sense and both animals and
machines are so far away from this human
data um for on human average that we
cannot make a meaningful comparison and
and that what would be more interesting
is if you know the performance of a
system before it's trying to figure
something out and then you look at the
performance after that and you see how
much data it had and what nature that
data had um How many operations it did
in the meantime you have a much better
measure for its ability to build a new
skill a new ability and this is actually
what intelligence is about it's the
ability to make models and so you could
say AGI is the ability to make any model
that is mathematically obtainable under
the circumstances which means given the
resources that you have available and
given the data that you have available
if that model is discoverable if you
understand this search space for this
model then the system should be able to
find it and very often we have
difficulty to formalize the search space
correctly and if we could if we could
find some optimal measure for organizing
the search space of functions that we
are looking at to get the skills that we
want then maybe we would have the answer
to how to obtain egi but this is not
what our current systems are doing what
they're doing is they for instance
predict the next token and the token is
uh some mapping of text from the
internet into a form that the model can
process and we see that these models
getting better and better at predicting
next token which means they're able to
imitate the performance that give rise
to producing these strings on the
internet better and better and the same
thing is happening for images but it's
clearly not quite the same thing as
making a proof for The reman Zeta fun uh
Hy is because the reman Zita hypothesis
there's no available proof on the
internet and just by combining stops for
existing proof it's very unlikely that
this model randomly stumbles on
something so in a way we would need to
find a way to turn these uh linguistic
problems into a form of selfplay where
this thing is like in go or chess able
to play against itself and this way has
um some kind of feedback games give you
a feedback mathematics in principle can
give you a feedback of whether the proof
works or not pro programming can give
you a feedback because the program might
compile or not and might achieve a
result or not if you can turn this into
self play should be able to go beyond
Human Performance but the way in which
we training the LM we don't know how to
get to this level at the moment I was
speaking with franois chal this morning
and he has a similar conception of
intelligence you know like model
building efficiency for him it's
abstraction building efficiency and I
said to him your your conception is kind
of talking about the what not the how
what about agency what about this um
self-play this you know autodidactic
exchange of information with your
environment and he said that agency and
intelligence are they don't have to be
entangled but you do need to be able to
set your own goals and the skill
programs might represent a kind of plan
but is it a similar thing for you I mean
is this self-play part of intelligence
or is it just an implementation detu we
find that in um real world in ments
people often discount intelligence
because they realize what intelligence
is a tool and what matters is what you
deploy the tool for and that's why
agency tends to be more useful than
intelligence if somebody has a lot of
agency they can hire somebody who's very
intelligent to solve a problem and there
is a problem but intelligence if it's
this is problem solving ability or model
making ability somebody who's just
making models uh for the sake of making
models is not necessarily going to be
successful and so we have to ask
ourselves what is it agency and if
agency is the name of the game I think
it's the control of the future can um
contrast this with a therat therat I
think is not an agent at least a
primitive therat it's a system that is
measuring the world and here and now and
then directly translates this
measurement into some kind of regulator
action some kind of switching and as a
result it's basically regulating the
present Based on data that is available
in the present but what happens if you
are building a system that is able to
regulate the future so if you had the
thermostat that basy can anticipate how
long it's going to take for the room to
heat up after it triggers the switch and
uh how long is going to uh for
temperature go go down and um how is the
distance between the um sensor for the
temperature in the heating in the room
so how indicative is maybe if it's very
far you get a good idea about uh the
actual temperature in the room but if
it's very close you you could make an
inference about the size of the room the
volume of the air that actually needs to
be heated and how that measurement is
actually a distortion of what's going on
and so the more models you can make the
more efficient your regulation is going
to become and as soon as you have a
system that is just not taking
measurement right now but builds a model
of how the thought is going to change as
a result of its action you end up with a
system that seems to have preferences
and that has knowledge and it has
commitments and uh seems to be go
directed and so you have all these
properties of an agent just is coming
out of the ability to control the future
and of course controlling the future
entails making models and the better you
can model the better you can do this and
at some point you have to discover
yourself it's this fact that you
regulate the world in a particular way
and your model making Works in a
particular way and then trying to figure
out in which ways did my own model
working not work and what are the
limitations of my ability to observe and
make models and when this is happening
you start to edit your own source code
and then becomes really interesting and
it's think that intelligence at some
level is can be seen as the ability to
just deal with a particular domain and
develop skills there but the stuff that
we find interesting in humans is this
ability to become self authoring to
change their own way in which you're
interacting with the world in which
you're interacting with yourself
becoming a different system developing
yourself
growing now we're not going to talk
about Consciousness just now we'll save
it for later but you have said that
Consciousness is a virtual property it's
it's as if could you say the same thing
about
agency and some sense you could say that
agency is not a physical property but
what is physical after all you could say
that physics is a theory it's a model of
a certain kind of reality that is
mechanical it's in a sense you would say
that Minecraft is not physical because
it's just a symbolic convention that
exists inside of the computer and that
can be completely arbitrary whereas the
physical universe is thought as of as
something that is not dependent on
something's intention and it's just
acting a mechanical pattern out but what
you find that this mechanical pattern
gives rise to structure that we can best
model if we project it through the lens
of agency of control systems that make
models and if you do not use this lens
there is a lot of things that you can no
longer understand a good example that I
think instantly obvious to everybody is
money we all agree that money is not
physical but if you believe that money
doesn't exist there are parts of reality
that you cannot
explain and it's not that money it's
just a belief that people have and then
people stop having that belief that
world uh is explainable in better ways
no you can also build a stock market
entirely with computers that is are only
manipulating MERS and bank accounts and
it's still going to be the same thing so
you could say that money is a course
grain causal pattern that behaves as if
it existed it has causal power and it's
able to create patterns in physical
reality at a certain level of resolution
and the money is not just some fmal
pattern that we discover as an arbitrary
way of projecting Universe at a certain
level of resolution It's actually an
invariance that is not manifest at other
levels of the universe so when you make
a model you're looking for invariances
for things that don't change in the
world and money is such an invariance
right and interesting question is are
mental States invariances so they all
exist as if like money but to which
degree are they actually implemented to
which degree are the causal structure
that is shaping the universe in a way
for which you do not find another
alternative better
representation yeah I mean one of the
themes of our discussion today is you're
identifying these patterns of
self-organization these virtual patterns
presumably you would say they are real
but they have causal power so they they
change the world that we're in but you
use the designation virtual like what
exactly do you mean by that virtual
means as if so something behaves as if
it would exist and I think that the
objects that we are we are conscious
agents for instance that observe
themselves interacting with the world we
know that from a physical perspective
you do not exist if you take a
microscope and uh or kind any kind of
measuring device and you look at the
human brain um you will not see a person
what you will see is an activation
pattern between cells that is producing
the behavior of the person in the same
way when you take a microscope and look
at a computer that runs Minecraft you
will not find any Minecraft but you will
see is some uh pattern of electricity
that is propagating through the
transistors of the computer and at some
level is producing the causal structure
of Minecraft but you could also say that
Minecraft is never that is real it's
it's implemented and I find this
definition of saying something is real
to the degree that it is implemented
quite useful and then we find that there
are different degrees of realness for
instance a simulation of a weather in
country is simulation
it's not real in a sense because it is
implemented on a different causal
structure at a certain level of
abstraction that at certain degree of um
resolution gives you isomorphy or um
some kind of projection that you can
make that allows you to predict the
weather to a certain point and up to a
certain resolution and beyond that it
falls apart because the ca of structure
below is different or another example is
you play a computer game say you play a
shooter game and you can shoot a gun but
inside of the computer there is no ACC
model of the physics of the bullet going
through air or whatever it's just some
Vector calculation that allows you to be
to play that game in similar ways as if
you were doing in the real world so you
can transfer ideas that you got by your
from your interaction with the physical
Universe into this game because that
game is actually producing Cal
interaction pattern even though it's on
a different Cal substrate on the CPU on
GPU on computer that allows this
interaction but a movie for instance
produces a sequence of observables
without an underlying csal structure so
you can watch the movie the impression
you are maybe in World War I and you see
people shooting at each other but there
is no possibility to cly interact with
the structure of the movie because there
is no Cal structure underneath the
Celluloid in the movie or in a videotape
beyond the ability to generate a
sequence of patterns and so this is I
would say a Similac not a simulation if
you look at these different things you
have an observable Dynamic that we can
project into a model and then you have a
simulation that is such a model that you
can dynamically enact in the Similac
that a sequence of observers that
different degrees of
realness observable Dynamic is is a
beautiful way to put it because I mean
Richard Dawkins came up with this idea
of The Selfish Gene and I'm a big fan of
emergence right we we have this ladder
of emergence we live in this epic
dynamical system and what we tried to do
is is make sense of the world so we
identify a sufficient level of
resolution you know on one rung of the
emergence ladder and we identify
patterns or uh phenomena based on their
intelligibility their causal power how
vague they are in the boundaries and so
on um how do you think about that I
don't like the word of emergence because
it gives people an intuition that there
is this magical thing emergence when you
are putting things in Universe in a
particular hand of arrangement then for
some magical reasons the emerging things
is happening it's coming into existence
and then it uses a behavior that some is
more than the sum of its parts and it's
completely mind-blowing and maybe this
explains Consciousness and for some
reason emergence should be a phenomenon
that is discussed a lot in the context
of the relationship between software and
hardware and it never really is right
and software and Hardware this is where
you should be seeing it you see there's
on one level there's transistors with
electricity and if you zoom further in
that's not even transistor and
electricity it's just atoms and
molecules and if you zoom further even
they are just some kind of Crain
abstraction and not only the other side
you have these computational languages
that Implement you our ideas of logical
progressions and computer programs how
do they relate isn't that magical nobody
thinks it's magical we completely used
to it we take it for granted and we know
that there is no magic involved right it
if we are unable to wrap our minds
around it the problem is clearly with
our mind there is not no big mystery and
yet when we think about the our mental
representations about our psyche for
some reason people believe that
something entirely different must be
going on and this is this emergence
thing and I I think this points to a
confusion I I should have clarified I
mean I'm talking about weak emergence so
simply a matter of surprise and
complexity not the denovo generation of
uh phenomena which has no analytical
Pathway to the I think there's nothing
wrong with this term emergence and
supervenience can be useful ways to talk
about this stuff I just mean when we are
sitting down um in say a philosophy
seminar and the philosophy Professor is
uh very ened with emergence in the
context of mental States but doesn't
believe it's important or remarkable in
the context of software I find that
suspicious I think the degree of um
astonishment should be the
same so the basically the intuitions
that this term is loaded with might be
slightly different ones and I think
that's often an issue that a lot of our
mental concepts of things happening are
black boxes to us and so we point at
them and we give them a label
and we have a an idea of what this
particular component in our mind is
modeling and how it operates but it's
essentially a black box and if we do not
take this black box apart and map it to
first principes to explain what kind of
function our mind is actually producing
this this leads to weirdness a good
example is uh the intuitions that
mathematicians often have about geometry
I remember when I had to draw my first
line on a kodor 64 it was super
complicated because it's basically
doesn't have a to make a line so you
have to poke some values into the video
chip to make it forget how to render
characters and interpret part of the
working memory as pixels and then you
need to tell it where the starting
address in memory is where the pixels
beginning and then eight bits um one
bite is eight pixels and you need to do
some binary arithmetic to make it happen
and eight bytes below because it's still
the character Matrix are one block of
eight by8 pixels and have 40 in a row 25
below and so you need a lot of
mathematical tricks a lot of puzz
solving to draw a line by making the
right Forex Loop to figure exactly out
which pixels you need to flip in into in
which bytes and which addresses they
correspond to in working memory and then
you generalize this at some point in a
function that works at arbitrary scales
and would also work with a different
pixel Matrix and work with the different
color resolution and the more you
generalize it the closer you get to this
mathematical ideal of a line and yet
mathematicians think you get the line in
some sense for free and when you tell
them oh when you talk about the line you
talk about the generalization of all the
ways in which you can map such a
function onto some kind of letters or
Matrix or whatever use as your substrate
um right as a function of the topology
and dimensionality of that substrat uh
then then you have that line and the
mathematicians no that's way to
complicated there is a much simpler way
and it's look it's a simple definition
but definition is not actually simple I
think it only looks simple because our
brain has already made all tricks it has
already through an elaborate feat of
machine learning in our brain as a child
did the same thing that I did in my
commodor 64 in the most General case and
mathematicians are mapping on this
available intuition of geometry in their
brain and think geometry is simple and
instead geometry is much more
complicated than algebra there is an
underlying algebra in our brain that is
producing the geometry and so when we
think about how we are manipulating
stuff in space it's nothing that is
instantly given it's not the way in
which the universe works
it is a model that our brain has
constructed and that we that's a black
box to us and which we point at and if
you want to disassemble this blackbox we
need to build computer games and then
build a game engine realize oh our brain
is in many ways very similar to such a
game engine but it's a self-organizing
one that in in some sense does inverse
rendering so it's basically building a
game engine that is trying to explain
your sensory data so your sensory datas
are constrainted uh constraints that
determine the state of this game engine
and I think this is the main of which
our perception
works yeah because um you actually said
that our emotion consists of um an
intelligent generator the outer mind and
an an intelligent interpreter the self
and both are adaptive learning systems
and they might be incompatible why is
that so there are s ways in which you
could Implement an agent def have an
agent that needs to satisfy many demands
to stay in the universe to stay alive to
persist itself like we do we need a lot
of different nutrients and we need to
rest and we need to build social
relationships because we actually
multigenerational agents uh that also
cannot exist entirely by themselves we
also State Building agents so we need to
model all these relationships as needs
and we have evolutionary priors that
make it easier for us to figure out what
those needs are because we basically can
talk take these as suggestions to start
with and only need to modify them and
they don't work and uh then we need to
build a control model that allows us to
perform actions in the world to measure
all those needs translate them into
representations to us that we can deal
with and operate on we experience them
as urges or as drives and then uh we
model these drives as purposes as things
that we actually have to do in the world
and then we try to build a hierarchy of
our purposes that we are serving and
that we can communicate to each other
and to ourselves and there are many ways
in which this can be built can
straightforward encode this but it's an
interesting way in which it seems to be
built in our mind and as see we seem to
have two models similar to the Gan this
generative adversarial Network where you
have a generator and a Critic there is
something in our mind that is generating
a world model and it's also generating
our emotions at a model of and our
motivation is our alignment to the world
and then there is a self model that is a
model of what if what it would be like
if there was a person that cared about
having these emotions and cared about
all having all these problems and that
model itself is being tasked with
finding solutions to satisfy the needs
that the system has before created right
and so we have this bipartite model we
have these two parts we have on the one
hand a world model on the other hand a s
model and we are the s model right we
perceive ourselves as embedded into this
game engine as a character that has to
solve the problem that the game is
giving it and we perceive a score that
is computed outside of the self as a
multi-dimensional problem that is
projected into our self as emotions and
motivation to which we have an
unconditional involuntary reaction and
we can see that this is the case by
disassembling this by meditating so long
that becomes transparent to us and we
realize oh my God this just a
representation and they don't actually
have an urge there just a a model of s
that is having that reaction but I'm not
actually that I don't have to be that
and I can see it from the outside you
said something very interesting a while
ago which was that you know agency is
about predicting the future and
something was ringing in my mind it's
about and that's controll in the future
you said and my mind was ringing saying
no controlling the environment in the
future but you didn't say the word
environment and you were talking about
abstractions just now so you know uh
geometry and and we learn more and more
representative abstractions but coming
back to what you just saying about you
know we have we have a self and and then
we have a kind of outer model are they
two parts of the same whole like does
the world exist basically the thing is
you are part of your own environment
right so in in many ways the environment
of your Consciousness is also the agent
that your Consciousness is inter
reacting this and um serving right so
there is in the sense there is only
environment there is nothing else that
you could control by virtue of being
able to observe and manipulate it
something becomes
environment right but it's not the
physical environment it's the
environment that is represented in your
mind that is accessible to you so you're
always dealing with a representation and
some of these representations are causal
pattern they're basically similar to
computer programs there are things that
are represented in such a way that can
be used to control what an organism is
doing but they're not Primal forces in
the universe if you look down there
still just activation patterns between
URS or messages that are being passed
between cells that then lead to lots of
actions at the cellular level that can
or below the cell level inside of the
cell that over very large scales can be
integrated if you squint very hard and
zoom out very hard it looks as if an
organism is doing something right but
this entire organism is also a fiction
it's an as if it's something as if all
these cells would behave animated by the
same idea by the same goals and because
that is very useful it's also largely
what they approximate and of course we
realize it's an approximation but it's
not a bad approximation and for as long
as we can maintain this approximation
for that long you say there is an
organism and just a bunch of cells that
are falling apart but what's more real
are the animating patterns more real
than the ACT you know what we think of
as the physical world well they're real
to the degree that implemented and so
there is a structure in our organism
that implements coordinated Behavior
across the cells and that gives rise to
what we call the organism the organism
is not actually a physical thing it is a
function that is describes the
interaction between cells to the degree
that they are
coherent well now's a good time to talk
about your cyber animism talk I watched
your keynote yesterday at the at the AGI
24 conference now animism um is this
idea that uh you know systems that are
living have a kind of Soul or a
spiritual Essence which gives them
agency and and Consciousness almost as
if we are just vessels which become
animated with some kind of vital force
and of course you've um in you know
reinterpreted this in an information
processing kind of way is is that fair I
mean would you mind bringing it
in I find often that we have difficulty
to understand the concept properly if we
try to translate it in what we already
believe to be true and so for instance
if you are say an atheist and a
Christian tells you about God and you uh
take the mythology of Christian late
people that gods are supernatural beings
that are in the habit of creating
physical universes you might think this
is a propositional belief that this
person has and it's a confused belief
because there can be no epistemology no
theory of right and wrong from which
this data can be derived how what would
an experiment look like that tests
whether something like this has actually
happened and so if somebody makes such a
claim they cannot have evidence to
support that claim and so they're
confused and as a result aist might
think that concept of a God is a
Superstition and everything that the
person reports about this God maybe
they're talking to Angels or maybe the
experience that God gives meaning to
their life or that God loves them and so
on is clearly a confusion or a
Superstition but I think that's just the
result of us mistranslating a concept
and is not helped by the fact that the
other person is not able to articulate
the concept in a language that makes
sense to us but if we observe that the
other person is intelligent and uh is
not delusional all right then you might
notice that there is something that we
mistranslating and so for instance I
think God is a representation in the
mind in the same way as the self is a
representation in the mind once I
realize that I am in a story that my
brain is telling itself in such a way
that I can hear my inner monologue right
myself can utter a voice in my mind that
I'm hearing right why should a God not
be able to do the same thing right why
should there only be one story in my
mind and there are apparently people
which have other agentic stories in
their mind that get synchronized about
across larger groups of people just not
a single self and so gods are simply s
that are distributed across multiple
minds and when somebody reports that
they are um that God is present to them
they're describing a psychological
condition that basically describe the
presence of this other agent in their
mind and they can interact this into
this the agent and observe it to some
degree right in the same thing with
animism my first interaction with the
idea of animism that I remember was
quite young uh somebody explained to me
that people in Japan and other animist
cultures believe that everything in the
universe is conscious into life and my
reaction was disported because I am
pretty sure that people in Japan have a
concept of a person being dead and
another person being unconscious for
instance if they get anesthesia and so
they will probably not say everything in
the universe is conscious into life
except for a dead person or an
unconscious person so you just
mistranslated the term into something
that you think you know what it means
but they mean something different with
conscious in life than you do right it's
clearly not the same thing that we use
in our culture so maybe it's a more
complicated concept maybe it's something
like um it's dynamic or it is something
that is self- sustaining right and it's
difficult to have such words we in our
culture we came up at some point with
autop poesis for self- sustaining system
and nobody doesn't really know what that
means but in between nobody had this
concept of self- sustaining pattern it
is a caal structure that is not entirely
physical right but once you understand
the existence of caal patterns that
there themselves not physical objects
but software and some of these might be
self sustaining
self-reinforcing can suddenly make sense
of these Concepts and you realize oh
maybe this is what they actually meant
all along maybe it was never a
Superstition because it is literally
what they're saying if you're able to
map it into something that you
understand and so I think the difficulty
is that our own culture is stupid that
La the correct metaphysics to describe
certain classes of objects and certain
inferences in the world and for we might
not be able to distinguish psychological
objects from physical objects and so for
instance some philosophers are confused
about the notion of free will because
they think of will as an object that is
comparable to say a photon or a a bench
right and then not right bench is an
affordance that you have that you can
sit on and that is part of your game
engine but will is a representation of a
psychological State and so when you
think about free will you have to think
about the modifier that is applied to
that particular kind of representation
not to some condition in the physical
universe and it's not easy to understand
once you see it but a lot of the
discussion about Free Will is about
category errors it makes a lot of sense
to me when I first saw your talk uh and
and it is a very interesting in
interpretation of of the animism philos
philosophy and I just realized um I mean
I read a book called The Language game
by Mortin Christensen and Nick chater
and that was talking about um you know
kind of virtual agents you know um
memetics because language is a symbiotic
organism um that parasitizes us and I'm
a big fan of externalism as well you
know so these these mtic agential
virtual structures are floating around
there in the infosphere and they
parasitize us and they animate us yes
it's exactly the same as what you're
saying so that makes sense to me and
it's basically the same idea yeah so I
think it's quite clear that with the
language of modern cognitive science
there is software running on our brains
and the software that is running on our
brains is uh giving us the ability to
make decisions to observe to uh recall
memories and so on and it's a software
that is being formed and artificial
intelligence despite using different
abstractions and different substats uses
these Concepts to produce Behavior that
arguably is in many directions already
quite similar even though it is not
emerging in the same way it does not
have the same self-organizing abilities
but um the idea that a spirit is a
particular class of software that it's
an agent that has the ability to
implement itself on a subst that is
suitable for it that can itself can be
entrained with that agent and it's a
software that is able to control this
region of the physical universe that it
entrains itself with to some degree and
uh it's able to perceive itself that
that's are interesting properties right
so something that's able to make models
of the environment to such a degree that
given enough resources is going to
discover itself in the interaction with
an environment as an agent and uses this
to make its model more sophisticated
these are all properties that our
ancestors assign to spirits and it's
something that we as cognitive
scientists and AI researchers discover
as existing obviously in nature and then
we notice it's not just in our brains
it's also in our bodies and once we make
the step to realize that thing that
makes a cell a cell is not just a bunch
of mechanism that for some magical
reasons happen to work all the time it's
actually a software that is running on
the cell that is so powerful that it's
able to contr to individual molecules
sometimes in the cell right not via
magic but because of the mechanisms that
are being leveraged by the software but
the software is basically entraining
itself on the hardware it's recruiting
Hardware in a self organizing fashion to
enact the softare
and so there are in in some sense two
sides of the same coin but the actual
invariance is maybe not the mechanism
it's maybe not the physical thing but is
the ca of pattern it's actually the
software in the same way as money is an
invariance that doesn't really care what
you print it on as long it's being
printed on something that can serve to
implement money and I guess a similar
thing is happening our own mind our mind
is somewhat robust against an individual
neuron dying it's just going to recruit
a new neuron so over a quite large range
of States our mind is going to be still
be functional it's only when the
mechanisms leave a certain range that
you can no longer compensate for when
you no longer compensate for the errors
and the noise and in the environment in
your substrate then you fall apart and
the software crashes and dies and other
software goes in but this also means
that when you look at the living world
around us it's full of these software
agents that are competing about regions
and physics that can be substrates for
it right there are thoughts in our mind
that compete for our brain matter and
there are ideas that compete for groups
of people and there are organisms that
compete for regions in which they can
build new cells and and Trin them with
the patterns and the colonies of the
organisms it's so you see all these
Spirits acting in nature and then you
look at the way in which Japanese people
for instance conceptualize animalism and
you realize yeah there are realizing
that there are layers of this for
instance Humanity itself is a spirit a
society is a civilization is also some
form of a spirit a relationship is also
a spirit so in this sense you could say
the animated un Universe this universe
that this interesting intelligent qu
structure is the result of
self-organizing software agents and if
that is the claim of animism that's an
actually very insightful claim and it's
one that we are beginning to understand
we are still focused on the mechanism
right so Darwin says evolution is the
competition between species and then
dkin seems to make the next step and
says no it's actually the competition
between certain molecules that give rise
to something that looks like species to
us when course grain it and these are
the gene
right so it's actually about the gene
but the animist perspective gives goes
one step further and says no evolution
is the competition between different
software agents that can reproduce and
can can code themselves and they use the
molecules to encode themselves and they
use the mechanism to implement
themselves and perpetuate themselves and
compete but it's actually all about
software it's all about spirits and so
it's a physicalist perspective it's
nothing superstitious nothing magical
nothing vuo in there it's just a way to
reframe what we are observing in the way
that makes more sense yeah well it's a
kind of stance because there's there's a
hierarchy of mimesis I mean I gave the
language example that that's you know
the highest level and then as you say
you you can go down a step and you can
go to um Evolution which is about the um
the competition of of physical forms and
and their evolution and uh you know
Dawkins was talking about the Gene and
you're talking about the software the
software agents or you can call them
spirits that compete with each other but
the thing is the the the software agents
they need to find a host and the
interesting thing is that they might be
doing some kind of meta optimization
because this ladder of mimesis is
entangled so they might be selecting
their host based on meta optimizing the
the the Lang the language mtic if that
makes sense well it's not just that uh
nature is growing a body for you and
then the spirit moves in and possesses
that body but what's happening is that
there is some software that is
organizing a bunch of cells into
becoming a body and that is already a
spirit right it's a self organizing
thing that is producing the architecture
of your body it's an you could say an
emerging phenomenon but there is no
magic involved right it's really just a
self-organizing software that manifests
by producing the architecture of that
body that then produces complex behavior
that implements more complex Spirit
right but when once I had this Insight
that what our ancestors meant with
spirit is exactly self organizing
software agent my mind was blown and
then the next step and you realize
living nature is actually all about
software it's all about control
structure and the actual invariance is
not the molecules or the connection
between the molecules or some patterns
in the molecules but it's actually the
causal structure itself the software um
I I realized oh nature is healing we're
able to put different worldviews
together in a way that is not
superstitious and they make more sense
now because we now can use our
scientific worldview to make sense of a
bunch of Concepts that are difficult to
explain so far and where we felt that
our ancestors had for some funny reason
weird idea what we noticed is that
animism is not a perspective that only
exists in some regions in rural Japan
it's also a position that existed in
Europe uh before Christianity came along
and even during Christianity it's
something that only stopped with the
enlightenment it still exists in
Scandinavia it basically exists
everywhere people are living inside of
forests so Consciousness as as software
I mean we should bring in Consciousness
so there's a kind of competition between
these software agents they they find
hosts and and you said Consciousness is
a virtual property of this pattern of
self-organization and you said it is
second order perception MH what do you
mean by that a lot of people try to
avoid the notion of Consciousness and it
has multiple reasons one is that they
feel it's too many people have different
opinions what what it is uh they also
there is very little upside in
discussing Consciousness because there
are very few decent research programs
for it visin science very few people
look at it because neuroscience don't
know doesn't know how to make progress
on it AI doesn't really look at it
psychology is not looking at it so all
the people that talk about Consciousness
tend to almost all of them tend to be
outside of Science and people outside of
science don't have very good
epistemology for the most part and not
proper formal education so the way in
which they make their arguments
typically doesn't scale and doesn't hold
up in the eyes of scientific methodology
and so people don't want to be drawn
into this on the other hand
it's Consciousness is something that we
are all confronted with and for a lot of
us it is not just significant but also
mysterious but the significance of
Consciousness is something that seems to
be undeniable and so when we ask
ourselves what is it that we mean by it
when we look at Consciousness I would
say that there are two features that
bring to our attention that is what we
mean when we point at what we mean Cons
with Consciousness ourselves one is that
we are
experiencing and this nature of
experience is not just content is
present it's not like it's insufficient
that you build a camera sensor that
registers photons or you build a meion
learning system that is discovering
patterns in the activations of the
camera sensor that is insufficient
nothing experiencing here what does it
mean the experience goes a step further
it basically registers that something is
registering it something notices that
something else is noticing so it's not
just the presence of the content it's
the
registration that this content is
present and this is not an inference
that you do logically with some symbolic
reasoning if you step through mode but
it happens in the moment or entangled
immediately in this process so it
happens in in near real time it's
happens at the perceptual level so it's
not reasoning it's perception it's this
immediate thing that happens in the
coupling with the perceptual process
that brings you in contact with the
environment and your internal State and
so it's it's not cognition it's
perception and it's not perception
directly of a Content but but it's the
perception of the perception and that's
why it's a second order perception
that's what I mean by see the other
aspect is when you ask yourself where is
consciousness that's a category it's
software it's not in space right it's
just modeling a space as a Content but
by itself it can be also implemented in
the region of the physical universe but
where it happens is is not the right
question when does it happen it always
happens now that's a really interesting
feature of Consciousness that is never
in the past never in the future uh and
never not now it's always now and so
Consciousness seems to be this bubble of
nness and or inhabit this bubbles of
nness depending on how you use the term
and in this bubble of nness you have the
things that are currently the case in
your perceptual system so it's a
particular state of your mental game
engine it's tracking sensory perception
and it's the operators that you are
using to change your ideas and thoughts
so when you are reasoning your thoughts
are not necessarily about the now but
you thinking that's what happening now
when you manipulate your own thoughts
You observe yourself doing that it's an
interaction that's happening in an
environment it's also in this nness and
the nness is not an instant in time it's
not a point on the timeline it's a
region it's a region in which you can
fit a curve to your perception so to
speak it's a region that's slightly
Dynamic you see a small movement a
handshake an eye blink something like
that something that fits into this
window of our attention of a moving
Dynamic environment and the bubble of
nness can be larger or smaller depending
on how much we are in sync with the
environment how calm we are how much we
can integrate into this bubble and it
seems to be a bubble that is completely
devoid of contradictions the stuff that
has contradictions cannot be seen not be
perceived because it makes no sense so
it might be that there is some kind of
constraint propagation that goes back
and forth to our working memory and the
region that we can integrate into this
bubble this is the content of our
Consciousness and so maybe Consciousness
is the operator that performs that and
there is some overlap to for instance
Toon's integrated integration Theory
which I think is formally not a very
good theory but the intuition that
underlies it that Consciousness is about
the integration of contents I think is
sound and this is something that also
makes sense from the perspective of a
machine learning engineer thinks about
how does a self-organizing system
process information and maybe it does
this by producing this bubble of nness
and it does this by resolving
contradictions in your sensory apparatus
and it starts out by observing The
Observer itself and it's basically the
first stake that you ram into the ground
to establish something that has no
contradictions once you notice there is
an observer at is kogito agum you are
can Branch out to try to explain the
rest and you don't do this logically
it's just what you do experientially
it's what's happening in some sense when
you observe ourselves as observers that
start making sense it's quite similar to
stevenh Wolf's Observer Theory and he he
spoke about this cone of an intelligible
cognitive Horizon
which is intelligible to us as as you
know computationally banded observers
but um the thing is we we're talking
about perception and most people have an
idea what perception means because they
they think about it in terms of our
sensory perception but am I right in
thinking that you're talking about a
kind of perception between the software
agents in this mtic space no I think
that um the idea that there are the
agents is an idea that I formed in my
mind and I don't have access to your
internal States uh what I observe is
that seems to be an agent that has a
similar makeup as myself and so I assume
that you're are functioning in very much
the same way and then can communicate
about reality that's shared and I assume
that our brains are naturally converging
in many regions to similar models so we
communicate by forming pointers in the
architecture that we hope is similar in
your mind and then in some regions we
find that there are differences and this
is why we discuss philosophy interesting
so Consciousness is a virtual property
of the hosts not the software
agents uh no it's it's it is a software
property the host is a concept that the
software is making about its substrate
but I cannot know whether I'm running on
a GPU or in a human body it's U I'm just
observing that uh there is something
that I can interpret as a human body and
my best models that I can come up with
is that I'm actually running on that
human body right but I cannot actually
know this it's just a model that I'm
making and so this concept of host is a
part of a model that I'm making it's
nothing that is immediately given the
only thing that I can infer with some
necessity that there seems to be
something that's able to host me right
there is a substrat that uh makes it
possible for these representations to
play out to what extent does it make
sense to say that Consciousness is
universal I mean I recently had Philip
goon and he's a fan of pan psychism and
Cosmos psychism but in in your worldview
how Universal is
consciousness I don't really know how to
make sense of pan psychism because the
idea that matter itself is conscious if
I try to formalize this don't really
know what that means so is this
everything in the universe equally
conscious is consciousness equally
distributed does this mean that
everything in the universe behaves the
same with respect to forming
representations of itself and
experiencing those representations
probably not why would you make such a
claim it would be pretty complicated to
implement and it does not uh explain any
observables there is no mechanism that
would bring it into existence it doesn't
make anything easier so I suspect the
reason why people are sometimes pists is
not the result of them thinking very
hard about physics and Consciousness but
it's more an experimential
thing and I think it happens because in
our normal State as adults we have a a
self a personal self that we normally
perceive as the agent of Consciousness
so it's basically the thing that gives
us this human first person perspective
and when you meditate very much or when
you are using psychedelics and large
doses some people report that this that
they dissociate also sometimes happens
in clinical cases where they're
basically depersonalized and the
Consciousness is no longer attached to
this personal self because after all the
idea that this representation of of what
we would be if there was a person is a
trick that your brain is producing and
associating your conscious perception as
Observer to that thing is a slide of
hand and if we are able to solve the
slight of hand by changing
neurochemistry of our brain or
meditating so much that we figure out
how it actually works we basically
realize uh that our Consciousness is
somewhat independent and so what's
happening then to our Consciousness and
it seems we can bind it to other objects
and if you don't do that it might bind
itself to the entirety of our models to
our model of the of reality to our
universe and suddenly subjectively
people who meditate or uh use LSD get
into a state where they realized oh my
God everything is conscious and it has
always been why didn't I no this and
this gets translated into pism but it's
a category are because what God
conscious are they representations it's
not the physical Universe it's not that
suddenly they discover the quantum
mechanics and particles and what not is
conscious no the ideas of things of idea
of what it would be like to be a photon
or the idea of what it would be like to
be a cell gets instantiated in her mind
as a dream and they think about it and
they experience that thing as a
conscious agent that is basically has
having a first person perspective but
it's now a first cell perspective or
first Photon perspective and it can be
even multiple looking at each other
simultaneously and when such a thing is
happening it's probably pretty
mind-blowing and can confuse a lot of
people until they figure out no it's
just a mental representation it's a
dream what does this dream
signify I mean let me let me try and
sketch this out to say I've understood
it correctly because by the way even
Philip gof even though he thinks that um
he's also a fan of panagal ism by the
way so these various ontological ideas
that the the primary um substrate of the
universe has the kind of the potential
for phenomenal and material um uh
components yes but what why would you
think that it's basically our idea about
the stuff that is below particles that
we can observe are pretty rake and even
the particles do not seem to require the
assumption that they have agency in any
way it's not necessary for a photon to
plan ahead it seems that the photon is
able to happily do what it does if it's
far less intelligence then say a Roomba
it's a photon is probably uh just as
stupid as a rock it just follows a very
simple mechanism reactively without
planning ahead it's not an agent it's
not regulating a future State instead
it's just uh implementing a error
correcting Dynamic on the present state
that allows the photon to persist but
it's not doing any more than that so I
personally do not see a reason to assume
that the photon has any kind of
representation that it builds that it
solves any kind of complicated control
problem that would require thing to
build a representation and a model of
its environment and so I would be very
hesitant to go in and assume that it
does instead it makes much more sense to
think that systems that are so
complicated that they can make models of
reality learn how to read and learn how
to use an inner voice or War something
or reflect on the puzzling nature of
their Consciousness are systems that are
compositional that have made of much
smaller more primitive parts that don't
have that ability and implement it step
by step and it seems to be also what we
are observing did I get it right though
that that goth and Charmers think that
there is an ontological potential for
phenomenal experiences given certain
organizations of um you know information
in the case of Charmers or or material
in the case of of goth but but but
you're saying given certain types of
organization then there's a um a memetic
software sharing which itself gives rise
to Consciousness the reason why we um
are conscious seems to be that we care
at some level I noticed when I
introspectively when I meditate uh I can
resolve my motivations and so when I go
to the state where I stop caring about
anything in the world but Aesthetics I
feel that I am an unmoving observer that
is just looking at the world and looks
for patterns and if I resolve my
interest in Aesthetics and structure if
I stop subjectively paying my neurons to
look for structure in the world become
super lazy and they just space out and
fall asleep everything becomes fuzzy and
because there's no point anymore right
so at some level you actually care about
understanding Universe reflecting it and
that gets translated into an Impulse to
the neurons to please perform this
activity so we get a useful model out of
you if you if you stop doing it it's not
going to happen and and the reason why
we able to pay our neurons for
performing this task is because we can
feed them better if they make models of
reality right because we able to
navigate our uh trajectory through the
universe in such a way that we can find
food to give to the neurons eventually
and so this is how it all works
ultimately it's about energy
and so the reason why we are conscious
and have all this organization is
because there is a benefit in building
controlled reactors and every reactor
every kind of chemical reactions that
happens in nature is exploiting some
neck entropy gradient and intelligence
and Consciousness allow organisms to
exploit more complicated NE entropy
gradients more complicated chemical
reaction chains and so if you ask
yourself which things in the universe
have the potential to build Minds it
means they have to be able to Ben
benefit from that organization so that
organization can come into existence and
persist it right otherwise it wouldn't
happen and you also need a way to evolve
that organization so you need to have
some structural degree of freedom and uh
certain probability that such a
structure emerges in the first place and
so in this sense I think it's
conceivable even though it's a stretch
to imagine that maybe on Jupiter you
have an intelligent structure imagine
you have storm systems on Jupiter that
exist over millions of years and uh they
rotate and they produce magnetic fields
because some of the clouds are metallic
and some of these metallic clouds react
differently to those fields and others
because they have different metals and
different concentrations and this whole
thing is driven by tidle Dynamics and
maybe it gives rise to feedback loops
that ultimately leads to Jupiter waking
up basically the cloud systems and
Jupiter but uh I wouldn't know why this
is happening in a single Rock which is
just sitting there and is not producing
internal dynamics that do anything
interesting right I don't see how the
rock would be able to exploit some
internal like gradient and so I would be
very reluctant to assume that the rock
is able to produce that structure but
over billions of years maybe in the
mental of the earth maybe there have you
have something interesting going on who
knows there are some versions of animism
who also have this idea that maybe the
universe itself in the sense of uh the
physical universe is something like an
organism it's is something that wants
something where that has a certain
structure maybe this is the case maybe
flat space to have particles in is not
something that happens naturally by
itself maybe something bulldozed at
first into this this shape who knows I
don't think it's likely I think it's
more likely that we find a way to derive
that the universe that we observing is
the result of totry some kind of fractal
that emerges by itself and based reality
right but if not then maybe it only
exists in a corner where you have
something that actually wanted something
to happen it's unlikely right the fact
that religion says that doesn't make it
more likely because people just say
things especially if impresses other
people but um but if you think about
means and motive if something comes in
existence and why it don't see a reason
to assume that um the lowest levels of
reality or the levels below particle
physics or the particles themselves or
anything that is simpler than a cell is
running self organizing soft agents yeah
so um patterns of physical Dynamics are
a necessary condition in order for those
things to become hosts of these software
agents but you've also spoken about you
know this kind of coherence mechanism I
mean could you could you sketch that out
yes so when we think about uh in which
way does software work in the computer
we notice that it works because we force
the computer to do it we basically build
a substrate that is almost completely
deterministic and we can fully control
it and by building such a substrate for
instance a GPU we can Implement starting
State on that GPU that leads to a
necessary quence of steps that are
enacted with an extremely high
reliability and so we basically can do
that thing do whatever you want you can
play Call of Duty on the GPU and it has
no choice but Ina that but if you want
to imagine Call of Duty on your own mind
or uh want to create a fantasy of a
better world or uh any kind of
interesting dream how do you do that you
need to basic get something that is a
second order software that is designing
itself you needs to implement something
that is growing into the right shape in
the same way as you want to have a tree
you cannot just go into nature and build
a tree you need to build something that
wants to grow into a tree you need to
have something like a Seedling and
initially it's maybe just a single cell
that is creating a group of cell that
then interacts in such a way that
creates a Seedling that ultimately
becomes a tree so everything in the
universe is basically higher order
design that requires multiple level
levels of Genesis before it turns into
the shape that is realizing the function
that you eventually obser obing and that
that's also true for our own mind and so
if you ask yourself what are these
principles of self organization it seems
that an important one is
coherence coherence basically means that
the system is behaving as if it could be
described by a single function by a
single goal by a single behavior and we
observe this for instance in our own
mental development when we are very
young we might have very different
conflicting impulses and there different
thoughts different goals and the older
we get and the smarter we get the more
we integrate them with each other which
means we build them into some kind of
conditional hierarchy where every
Behavior has its place and understands
what its role is and then to shut up the
same thing is happens in a good
relationship or in a society and so on
and it's the more coherent it is the
less friction it has because it behaves
as if it was a single agent with high
internal structural complexity and so
can we formalize this coherence
principle that would allow a system to
design itself from the inside out and I
think we can capture it as the
minimization of constraint
violations so a constraint is basically
something that says if something is like
this then the other things must be one
of the following and none of those and
once you have a valid State and the
thing is um
coherent why does the world seem so
incoherent then is it because we just
don't understand the coherence function
no it's because uh there is only partial
coherence and our own Consciousness is
directed on the things that are
incoherent so we can fix them that seems
to be the wall of Consciousness it's
like a conductor and an orchestra that
listens to instruments and when the
instruments are out of Sy the on the
conductor marches in and says you go up
a little bit you down a bit and then it
works and so everything is on the same
page and maybe this is also the RO of
Consciousness in our own mind that it
basically focuses on those things that
are in disharmonic where there are
conflicts and then tries to resolve them
so your work suggests that there's a
kind of continuer of Consciousness and
of course to varying degrees even in the
ecosystems on on Planet I'm not sure if
you're familiar with James lovelock's
guia Theory and that really captivated
me when when I was younger he kind of
thinks of the um all of the earth as
being this kind of living
self-regulating organism um what are
your thoughts on
that so most agents are collective
agents you you could also say that all
intelligence because it's not
manifesting at the level of individual
particles and individual molecules or
even individual cells is the result of
them interacting in a coherent way as a
collective basically every agent of with
a certain complexity is a collective
agent it's made out of sub agents that
perform this Behavior together by
becoming coherent and so in in this
sense uh coherence is a principle that
gives rise to Agency on the next level
and when people become coherent with
each other then they can create
relationships with each other family
units uh teams organizations Nations
States civilization
and so all these are collective agents
that you can say that a civilization is
a collective agent that is made out of
all the sub agents and it's implemented
to the degree that these sub agents
realize that this other thing should
exist should be collectively enacted and
become coherent but it only exists to
degree that they can come coherent but
the prerequisite for becoming coherent
is that they recognize that there should
be regulation at this level and so if
you now think about Gaia GA would be a
collective agent uh that is regulating
at the level of life on
Earth and are there agents on on Earth
that think that regulation should happen
at the level of life on Earth probably
right there are a few people at least
maybe also some ecosystems who knows
that are able to form models at this
level so I would say that Gaia exists to
a nonzero degree but it's probably very
incoherent do you think the agency can
be um hierarchically factorized and the
reason I I say that is to me having a
district bution of agency would lead to
incoherence because agents are trying to
control the environment and it's an
adversarial thing but am I just thinking
about it wrong is there actually some
super agent which could be thought of as
coherent there sometimes competing agent
with conflicting goals and uh this leads
to incoherence right there is an agent
that wants to eat another agent and the
other agent doesn't want to be eaten it
leads to some kind of conflict and loss
of energy because one agent is trying to
escape from the other right but if they
were all on the same side they will
figure out what the right solution is so
basically if my family is stranding with
an airplane on a snowway Mountaintop my
family would first eat me and then my
wife right and and it's something that
in some sense we would more or less
peacefully agree on in an ideal case as
a gruesome metaphor because we realize
that this the goal that we are
submitting on as a family unit right so
the existence of the parents is
instrumental to the existence of the
children when you are parent of for most
parents is like that I think and so when
when you have such a world then it
becomes harmonic it becomes harmonic to
the degree that the agents perceive
themselves as being part of a larger
agent that is more important than their
personal agency and so we call this
because you're willing to sacrifice for
its sacredness and basically the uh
sacred shared sacredness leads to
Collective
agency our friend conel he talks a lot
about um coherence in the context of AI
alignment uh do do you think that
there's an interesting story
there um yes and no I I'm not sure how
coherent kol's perspective on AI
alignment is because uh I I don't really
know how he uh perceives Collective
agency when I um tried to talk to him
about um the way in which we are
coordinating his perspective was that oh
I the only thing I want is I don't want
to die and I don't want my mother to die
and there are others who have
conflicting interests and so it's all a
fight basically and this seems to be the
logic of a tape form of nothing that is
able to see shared purposes and is able
to build ethics via a notion of
collective agency I think ultimately um
ethics is about what should be done from
the perspective of an agency that we
both part of it requires shared purposes
without shared purposes you cannot have
ethics and so if you think of AI not as
a tool in which case we don't need to
align it in an ethical sense but we just
need to it make it behave in such a way
that we can properly control it and
that's what we want if we turn it into
something that is agentic in such a way
that it has actually choice about its
own allegiances about its own goals and
so on then the question is can be built
it in such a way that we have shared
purposes I often make the argument that
current AI is not atic but given your
philosophy I I guess you can make the
argument it is well we could say that
there is some agentic AI but it's not
universally agentic and the agentic AI
that exists is mostly not happening in
the level of systems that are able to
solve the touring test so if you look at
the uh agents that are created bya llms
there are in some sense deep fakes of
Agents because their agency is not
intrinsically built into the llm it's a
side effect of the llm trying to predict
the next token and the LM doesn't do
that because it's an agent it doesn't
have a choice about it it's
deterministically built in such a way
that it's going to give you the most
likly next token and if that entails
pretending that an agent exists then for
as long as that is necessary it's going
to make a simulation of that agent and
that simulation can be good enough to
actually act as a stand in for actual
agency right it's able to control the
future and so on the simulation of a
software is still a software and the
simulation of a software agent is going
to be a software agent but the
underlying reason of that thing is not
that this is going to try to
self-optimize and uh try to survive in
the world the underlying reason is still
it's instrumental to predict the next
token and it sees this once the token is
there what should you know when it comes
to language models what's your weapon of
choice right now are you an anthropic
guy or a chat GPT guy I I'm a liquid guy
liquid AI is a startup that is basically
rewriting some of the bottom of the
stack and if you think about the neural
networks that we're using in the way
there are a surprisingly crude idea
they're not bi like biological neurons
at all and the biological neuron is a
small animal that tries to survive it's
quite complicated it's really an single
set animal that is able to learn message
passing and then perform computational
tasks in the surface of of a larger
group of cells but uh the neuron and the
neural network is a real number that is
a result of uh summing up other real
numbers and multiplying them with
weights right so it's just sums and
multiplications that we arrange into a
series of steps and then when we make a
model we predefine the shape of of this
function we for instance say we have 100
layers which means we have 100 steps of
adding up and each of those layers has
maybe a million weights which means we
make a million multiplications of
individual values on the previous layer
and propagate them to the next and then
we adjust the weights in the hope that
our function fits into this thing so
it's not an optimal use of space because
the space is can be an arbitrary
function and in context of deep learning
we look at the differentiable function
so we express the function in such a way
that it's somewhat continuous and this
allows us to shift the function around
and that makes the whole thing learnable
we basically hope that many domains we
can Define it so that small nudges in
the function make it slightly better at
for instance telling dogs from cats even
though this is a discontinuous problem
it's amazing that this works at all when
you think about it but uh it's it's not
the best way in which you could
represent such a differentiable function
maybe you want to represent it directly
as a system of differential equations
and then shift the parameters around
with a second uh level Learning System
and so this this things that um liquid
AI is exploring and it's by now it works
initial work that we did with liquid
neural networks was flying drones around
so in some sense cybernetic control task
and showing that this works pretty well
and Ramin haani in his PhD has shown
that these Leal newal networks are more
expressive than normal neuron networks
basically means that per memory cell per
compute step you're expressing more of
the features that you actually care
about in your function and that
translates into having models that are
cheaper to train and more efficient to
run and they need less memory and the
thing that we doing now is that we are
training this thing to build llms now we
basically have built internally some
midsize models that we can show actually
quite efficient and run at s so these
methods basically can supplement some of
the existing machine learning methods
with slightly more intelligent
algorithms but there is a lot of
potential that we are not using yet for
instance because these liquid neural
networks have a continuous depth and a
continuous resolution they basically
flow into the shape of the function that
you need and this means you could in
principle build systems that
continuously learn rather than being
just trained on one batch of images and
then you retrain them a later point from
scratch instead you could continuously
train them but there of course
difficulties is come with this and you
need to edit your knowledge in such a
way this thing doesn't break down and so
there's a lot of research that we still
need to do but this makes it very
exciting because it feels that we
basically open up a fresh Avenue of
research yeah because in a way I mean
Fran said to me earlier that that one
thing he was wrong about is it's
surprising how good stochastic gradient
descent has has worked but but we still
have this Paradigm where we're doing
back propagation and and the networks
are very dense and we're we're training
them left to right and I was really
interested in the work that that liquid
is is doing so you built these very very
small models they're very robust they're
much more sample efficient do I remember
correctly that they're kind of physics
inspired so they're they're learning
about the the evolution of parameters
over time rather than the current kind
of Left Right neural networks you could
say so but also physics if you what is
actually physics uh a lot of people
think of physics it's discovering the
structure of the universe but uh if to
look at what physics phds are actually
doing almost none of them end up working
on discovering structure of the universe
instead what physics is it is describing
systems using small systems of
differential
equations it's a it's a particular way
to use short algebraic stuff to describe
systems that can be uh described in this
way and so stuff that cannot be
described in this way is completely
ignored by physicist for instance
chemistry right it's difficult to do
chemistry this way because at some point
we'll get around to it to translate uh
the stuff that analyze the table of
elements into differential equations and
they fall out of it but until then we
leave this to lesser people to these
chemists who deal with this messy stuff
and instead we have this elegant compact
stuff right and it's it's pretty weird
when you think about this this
continuous mathematics that physicists
are using is basic pre-ir stuff uh from
one and a half centuries ago basically
checked out this code based from the
mathematicians and uh it's very
versatile so when you take a physicist
they're able to describe changes in
dynamical systems very well and can
reason very well about this but they
also found when I get got physics
students to write code for me they often
try to translate the code into
differential equations first and this
happens to be extremely useful for most
of machine learning so the physics
approach is very good as an inspiration
for machine learning but uh it's not
generally a good approach for doing
coding because there are a lot of
problems that are actually discret
discrete automata and physicists don't
think in terms of discrete automat there
is also when you zoom out a bit the
question shouldn't be build learning on
top of discrete automata rather than
linear ala because if you think about
the stack of our computers you use a CPU
that is or GPU that is an automaton
right is you have a Boolean table that
you are where you're mapping um bit
Arrangements against other bit
arrangements and you implement this
pretty directly as circuits and then you
build a logical language on top that
uses these patterns to uh as if there
were evaluations of logic and then you
build arithmetic and so on and at some
level of abstraction you get to the
algebra then you train your neural
network of it and then you train that
thing to do logic again that's pretty
weird right what if what if we would
start at the bottom of the deck it takes
humans less than half a generation to go
from automata to building line algebra
on to a computer right computer science
is not an all discipline and so uh
imagine that you build a machine
Learning System at the bottom using
automata that that would be quite
interesting and there are few people
which do that but of course our learning
algorithm right now depend on
differentiability and so it makes sense
to use more direct inspiration from
physics rather than uh the ideas from
the P dra only to build our machine
Learning Systems how would that look
like you know if you if you're
implementing a large language model
because it's still a self-supervised
training objective I mean how would you
model something like that you pretty
much do it in the same way as before
which means we have data that allow us
to uh tell the system whether it was
successful to predict the next token so
you can use the same training regime and
you can use the same batches and you
extract the same information out of the
data but using slightly different
formulism to represent your function you
can map it into something that is
slightly more efficient so basically
your computer needs to use fewer Cycles
to uh manipulate bits that represent the
same function distributed slightly
different on the same substract so some
sense it's a mapping it's a compilation
into a slightly different formalism and
so the interesting feature about
computer programming languages all
programming languages have the same
power they do exactly the same thing
like all let the computer do the same
thing the difference between programming
languag is that allows us to think
differently about what the should
computer should be doing so from the
perspective of one who makes a model of
what the computer should be doing the
language make a very big difference and
you can think of a the an llm as uh
something like a language that is
compiling um natural language into code
that a computer can run right so you can
give it a prompt and the prompt is being
translated by the llm into a computer
program that can be represented as a 100
layer newal Network or implemented as
activations in that 100 layer new
network and you pipe the activations
through and as a result it performs a
certain behavior and if you are
representing this function in a slightly
more efficient way then uh you maybe
need less memory and what we currently
see is there is a big bottleneck with
the llms and we are running against that
bottleneck and that is basically every
generation of models is more expensive
to train and requires more data and they
are still more useful and so on but we
also see that it's with every
regeneration it might be harder to
recoup uh the cost of training them
basically you need to create a lot of
Revenue to make that whole thing
worthwhile and from the total
perspective if you zoom out it makes a
lot of sense because if we are able to
build AGI it will completely transform
our economy it will unlock tremendous
amount of value and so putting a few
billion dollarss or even trillion
dollars into training models might be
totally worth it but uh that is not
necessarily the case for a startup right
if you as a startup are putting a few
billion dollars into training a model
then you need to have extremely good
business development to actually find
business cases that create enough
Revenue so you can recoup this
investment and a lot of people are
bracing for a time like do com bubble
where there was a situation where
everybody was banking on the internet
generating retail revenue and whatnot
and was investing into the development
of the internet and then it took like
three to five years longer than
everybody thought and there were tears
right and it was a big.com bust and
everybody lost their hope in the
internet and of course stock market
recovered and these companies came back
those that survived and uh the internet
became much more beautiful than anybody
ever anticipated and much more lucrative
and useful but still there was this time
in between when the individual companies
could not group their Investments and so
of course this is what you need to think
about as somebody who deploys a system
and what we see right now we want to
have system that are smaller we want to
have system that can be deployed on the
edge locally on user devices to unlock
all the application we want we cannot
send everything to a Big Data Center and
process it on a server farm and then get
it back we need to find systems that are
smaller and I think the llms are way too
big you're still using this because we
don't really know how to compress them
in the right way but
there is a certain thing that our own
mind can do that is similar to gen and
that is we basically in one step we
create an association and but we don't
stop there we take that Association we
criticize it we construct it we
iteratively go over associations to
improve them into the product in the llm
or the image generator is mostly using
one step and and this what it does in
one step this one step Association is
mind-blowing it's far beyond what a
human mind can do in one step in that if
that one step is layer
function and Implement neural network
right but uh we get our performance only
by going lots and lots of steps in very
clever ways and so I think there is
going to be a development in this
direction that we think about what's the
minimal engine that can do inference
maybe you don't want to have a model
that is trange on everything in the
internet maybe you just want to have
something that's like a very precocious
12-year-old you compress it as much as
you can into a shape that is able to
understand the book and understand how
to reason from first principles so you
had such a epistemological engine a
thing that is able to take in data and
generate knowledge right ideally even a
canonical form so you can ex uh uh save
this knowledge and give it to another
model and that would be great to prepare
to a task you give it the library it
reads the library for that task it's not
going to take long right it's going to
be half an hour to putot up for this
task and then it translat this into a
knowledge base that you can also then
ship as a binary to other people if you
want to so this goes even faster but the
model itself how big is it going to be
we don't know at this point but I
suspect it's going to be much much
smaller than the present interesting
yeah I'm not sure if you remember that
paper by um uh M vinf it was the
neurocellular autometer and it was um
you know generating the gecko but what's
so interesting about that is it was two
incomplete because it had this iterative
component because we often I think last
time we spoke about how neuron networks
are a finite stage autometers they do a
fixed amount of computation per
iteration there's a lot of computation
that that that's out of bounds but if I
understand correctly you're you're
building a dramatically sparsified
smaller model that has this iterative
component and that creates this the
moment we're not doing that yet so at
the moment what we're doing is still we
are working to reproduce SOA using
models that are uh slightly smaller and
slightly more efficient for some
interesting value of slightly that is
economically interesting but uh what I
would be interested in the long run of
what the field is interested and when
you look at the field of AI research I
think will be ultimately what is the
smallest engine that is able to make
sense of the world when you're
confronted with data what is the
smallest thing that can bootstrap itself
efficiently into what you need it to be
and it's going to solve a lot of
problems because ultimately it's not
going to be tainted by copyrighted data
it's not going to put you stuff that you
don't want to have in your present
context it's going to be exactly focused
on the use case that you want it to be
and it's going to be more much more
modular and useful and so if you could
get there that would be great uh it's
very difficult to make a system that is
not to incomplete it's we shouldn't
think of a neural network as a model of
a nervous system instead the neural
network is a function that is mapping
adjacent brain states to each other
right so the Transformer uh weird thing
is the brain state of the Transformer
that we're mapping it to and from is not
this intermediate representation that
our brain is using instead it's text so
imagine you would need to translate your
working memory into text and then the
next brain state is computed by taking
that text and translating it again into
a mental representation that that
simulates the contents of what you're
writing in the text and then going back
down that's obviously not very efficient
and it's also very lossy because not all
of your thoughts can be very well
translated in the text and it's going to
limit your performance so instead what
you want to have is you want to
represent your thoughts so for inst and
your ideas and the state of your working
memory and I noticed when I'm thinking I
have been thinking so much in English
and German that I no longer think in any
of those languages I feel it's more like
I think into in a conceptual language
that is some kind of sub token embedding
so to speak and then only translate it
into English or German when somebody
wants to download it into a podcast or
into a conversation and so I observe my
this module model as working from the
outside I basically feed a string of sub
toen embeddings into my language
generator and the language generator is
a tool that doesn't require a lot of
attention and relatively quickly parses
this into a format of string of theet
symbols that you hopefully understand
right and so can we do this with the llm
there are move uh things happening in in
the research in in large companies right
now where people are making this much
more optimal by representing these
internal States and holding them and now
imagine we could turn these internal
states of the LM into a canonical form
so we actually understand what they mean
and we can use them to manipulate
knowledge in that in a way that is
similar to manipulating knowledge on
language maybe just a little bit more
regular but it's also can be used to
manipulate geometry or abstractions over
programming code or C structure in
general and I think that there are
amazing breakthroughs that are waiting
and these breakthroughs are unrelated to
the way in which we currently think
about scaling or applications of llms or
the alignment debates or whatever it's
there is going to be really exciting
research and I feel sometimes people are
have the wrong um expectation personally
I am amazed by everything that AI is
doing and my mind gets blown every week
but it's also I don't expect AI to
perform at the human level I expect AI
to solve problems that AI couldn't solve
a year ago or two years ago or 10 years
ago and that we thought would be
incredibly hard to solve and we now see
that they can do these things and so I
am I'm quite optimistic about a I is
doing and I don't see obvious
limitations of what the staff is doing
but I also see lots and lots of
difficulties to realize that so I have
no proof that a given approach cannot do
a certain thing and like Gary Marcus who
seems to have that proofs uh these
proofs I I'm uh seeing opportunities to
do things but I also don't have a
certainty that we're going to have ai
next week but we also know there could
be maybe it's just one paper away but we
really don't know it's just just by
scaling up we can predict how long that
approach is going to get to a certain
level not clear if it goes beyond that
but what is the next breakthrough that's
very difficult to anticipate before we
get there yes and Gary will be sitting
in your chair on on Saturday uh morning
but um you know one school of thought
though is that we just need to scale
language models and I think that I
really deeply respect people who are
willing to go out and say something
wrong in public that's very rare and
basically a lot of people prefer to play
it safe because credibility is a
currency that is easy to lose and so
when you are saying things that don't
come true like when you are saying to
machine learning researchers uh deep
learning is hitting a wall and deep
learning is doing no such thing you lose
all credibility especially if you do not
error correct
right that's different if you talk to
people in New York Times who hate AI for
political reasons and you tell them what
they want to hear then they you're going
to make you popular but it's going to
kill even more of your credibility among
the people who actually build stuff but
fris is not like that fris is somebody
who is uh very arrogant in its beautiful
French intellectual way going all in and
saying uh intelligence is gender
realization ability and it is all there
is and uh shows that the LMS cannot do
this and it's a really bold uh
prediction that he's making and uh I
think he will be very happy if somebody
is going to build an llm that solves the
arc Challenge and is happy to eat his
head and he is going to stir uh people
uh into uh talking back to him and and
trying to find a solution so he really
has skin in the game and he puts his
head in the ring by saying here is a
challenge this is a problem I think that
you cannot solve go ahead try solving it
and prove me wrong and this is something
that I deeply respect and it's he's one
of those people who comes out with bold
predictions
and uh the but he makes these prediction
in a way that is challenging people to
go out and uh and show him in which way
he was right and wrong right and he is
extremely smart so his predictions are
pretty good and interesting and people
are paying attention but uh basically
just making predictions in one way that
are not looking at the alternatives to
your prediction and not making an actual
argument that is uh that would
invalidate what you're saying or
retracting when you have been proven
wrong that is I think counterproductive
I mean I asked I asked frire this
morning whether he was worried because
you know he's got he's got a lot to lose
if someone trivially beats the arc
challenge with a large language model
that would be quite scary but just in in
defense of Gary though um I've just read
his new book and he's he's advoca mean
obviously there's the whole reliability
thing and it's not reasoning and all the
rest of it let's leave that to one side
but he's also making the um the
safetyism case he's saying cigarettes
were bad social media is bad the future
eludes us this could be very very
harmful we should be thinking about it I
mean that seems reasonable to me I'm not
quite sure I think that AI is a
technology that solves Problems by
giving us better models and this is
ultimately what it is and the way in
which you deal with a bad guy with AI is
10 good people with an AI and there's
always more value in creation than in
destruction more value in corporation
than infection and you live in a world
that is uh optimizing these benefits
that are gring and so we can put our
attention on the things that for
instance the internet has made worse and
what we are forgetting is that what the
it did um sorry media get a a few
years ago because nobody was able to
check up on it right uh government
conspiracies today are really difficult
to make because there are so many back
channels so many outlets nobody is
keeping their mouth shut it's basically
we have so much information available we
we can actually do fact checking and so
what is happening is a slightly
different thing we have a government
that is used to something like the
financial industry being a arm of the
government and controlling every
transaction and monitoring every
transaction and so on and this is
arguably in many ways useful as long as
you trust your government right but uh
we also realize that our government
doesn't have perfect incentives so there
is a certain degree to which you do not
trust your government and so we
typically agree the government should
not have all the data it should not have
all the control it shouldn't have full
control of public opinion who is the one
who's controlling the government is this
the media well yes we just the media to
the degree that the media is not also
such such a homogenous cluster that is
aligned with the government and uh if
that is happening for instance in
Eastern Germany the media and the
government were pretty much the same
thing right and in a country like this
where uh the media is basically all the
mainstream media seems to be aligned
with one political party people who
disagree with the policies of that one
political party regardless of their
party is good or not might have a reason
to fear a world where all the public
publicly available information is gate
capped by that media that is partisan
and so what you find is that a lot of
the attempts to control the content of
social media factchecking and so on uh
election Integrity are partisan they're
directed directly on one particular
party and could be that this is actually
happens to be the good party right like
in China we have only one good party and
so you don't need a second party maybe
we want that right maybe we realized
that to save democracy we should skip
the next election to make sure that
nothing end dangerous in democracy but
it's a very touchy issue maybe we need
to design democracy in such a way that's
robust maybe we already have that
democracy and a lot of the fear that we
have is the result of incentives of
media and so if the government feels
that media should be an arm of the
government and that social media should
be on arm of the government I think um
government might feel we sent uh a list
of accounts to social media platforms
that we want to get deleted because they
have opinions that we don't like right
maybe there is somebody who says that Co
comes from a lab right maybe it does
maybe it doesn't but it would be really
really bad if somebody said so because
it would jeopardize trust in science and
if trust in science is jeopardized maybe
Society can no longer function as well
and maybe it's necessary for us to
memory hold the idea that yesterday we
thought that M don't help and today we
think it does and maybe we need to
memory hold the idea that there was no
way that Co emerged on lab and now we
think it's quite possible and quite
likely and so this is very weird to
situation the control of information and
so I'm I feel very uncomfortable with
this idea saying social media is bad
because as somebody who grew up in
Social Eastern Germany we didn't have
social media and social media is the
only way in which you can form opinions
outside of the government and the reason
why I believe in this wam project is
this idea that we believe in a certain
human aesthetic and the core of this
aesthetic is that in order to be free
individuals that are not oppressed in
any way that are not in slaved by others
we need to be able to communicate about
ideas non-violently and so this freedom
of speech is absolutely at the core of
our democracy and currently we have a
group of people who are very influential
who do not believe in this freedom of
speech they may or may not be correct
and they think they should be completely
free to make their case and have better
arguments but they should not stop me
from making counter
arguments and I'm I'm really worried
about the consequences because it seems
to be obvious that as soon as one site
is able to limit speech they can
Implement arbitrary opinions that might
be against the interests of the majority
and everything that's good in the world
and with an Insight that would at one
point was completely clear to everybody
in society and now it's less clear so I
I'm much more in favor of preparing
social media social media seems to have
the wrong incentives largely it's a very
unpleasant experience but I don't think
it's the result of freedom of speech I
think it's the result of social media
being badly designed yeah I mean I I
agree that we need freedom of speech and
and pluralism of of ideas yeah but I
mean Kenneth Stanley actually set up his
own social network because he was
worried about the um the objective likes
kind of you know um distorting the
system Chomsky spoke about manufacturing
consent yes which is that even in in a
in a free Society you know um the the
information is is very distorted so we
think that we're free and we're
selecting information and we're thinking
but but actually we're not so how do we
overcome this I mean look at AI
regulation for example we need to have
expertise we need to have people in the
government that actually understand what
they're talking about and are making
informed decisions because we don't
really know that much about this
technology as a as a home but you also
need to have Regulators who are
incentivized to regulate in the right
way and there are different incentives
that exist at the moment it seems that
we live in a society that has some kind
of entropy with respect to its public
institutions its ability to produce
goods and services so somehow goods and
services seem to be hollowed out over
time they become more efficient which
means they get reduced to a minimum
viable product but they don't
necessarily become cheaper right so it's
basically in many areas where you don't
have an effective Innovation anymore the
kindness we arguably have that but maybe
with uh the doors in your house you
don't have uh some region basically
Improvement stops and things are just
getting more sloppy every year and worse
and so our society depends on Innovation
to maintain a certain level because
otherwise it rots basically Innovation
needs to outpace the rod in the other
areas and the main area where we're
currently innovating is AI there's
almost no area where we're still
innovating at scale and uh everything
else seems to be more about
redistribution of goods and services
that are increasingly no longer produced
here but financialized and this creates
uh I think a very brittle society that
ultimately will make us poor and so I
think it's very important to maintain
that Innovation but from the perspective
of the those who compete with the
Innovation if say you are a professional
prompt completer your job is to write
opinion pieces that are completely
predictable you will get a prompt and
everybody knows what you will be saying
right arguably I think that's what Gary
Marcus AI criticism is doing because I
have not seen tring anything that could
not be predicted by gpt3 and it's a big
issue that I have is there because it's
not really original it is slop it's a
model train on its own output and uh
there is part of the society that is SLO
because it's just a model trained on own
output it's no longer
innovating how can we uh these people
compete with something that is
innovating they will try to regulate it
out of existence so there is a part of
our society that basically wants to have
something like an AI FDA and if you want
to deploy a new model any kind of say
want to update GPT um maybe you need to
get it to the FD AI FDA first and the a
FDA will take only six months to test
and would take a pretty large fee and
maybe a few million dollars and uh there
will be no open source models and you
cannot import the model from abroad to
use it and maybe make sure that the
internet is no longer allowing that and
we ask the internet providers to make
sure that this doesn't happen right and
you end up with having four large AI
companies that are able to pay for the
fees and it's going to be similar to the
way in which Pharmaceuticals are going
to be produced and it's clear that uh
that might be inter interest of the four
large AI companies and the interest of
regulators and in the interest of people
who don't want AI because maybe they're
afraid of being turned into paper clips
and this is one part of The Regulators
are actually the doomers a doomday card
that is terrified because they listened
very closely to Eliz Kowski and thought
that's true what he's saying and on the
other hand there are people who just
don't want their industry disrupted or
they want to have political control over
the output of
LMS I agree with you I mean but Gary
does talk about the risk of regulatory
capture but um I mean in his book he he
um you know quoted Mark Zuckerberg you
know they they said move fast and break
things and we had the PayPal story so it
started off there were no fees and it
was wonderful and they actually paid you
to use it and now they exploit you same
thing with um with Netflix um Uber for
example we're not a we're not a taxi
company so he's kind of saying that when
when you let technology and go into a
sector they kind of they modify things
so that none of the rules apply to them
and even if they have the best of
intentions it kind of causes harm after
a while and yes indeed the regulations
we've got now are completely broken that
they just don't limiting the number of
flops on on on a model is ridiculous or
I I don't see how Uber has made the
world worse Uber has created
transportation for people that didn't
have transportation before there are
regions in uh specific cities where
taxis just don't go and there they don't
have public transport and Uber has
resolved that situation by creating a
market between drivers and people who
want to be driven and uh that market is
working it also create a lot of
employment and before we had a situation
that the number of taxi caps was uh
controlled with the central regulation
you had these medallions you could
inherit or Buy and they were extremely
expensive and they created friction in
the market and this friction in the
market was actually not beneficial uh
for me it was fascinating when Uber came
up and this how this rating system
worked in the car that basically you
could when an Uber came you could reli
on the car being clean and the driver
being nice whereas if I took a taxi C in
Boston the car was dirty and the driver
tried to cheat you and driver often
didn't know where to go and you had to
tell them with Google Maps where to go
and so on that that was really for me
interesting when I came to the US and
realized okay there is this free market
thing that is innovative and that is
doing things and I asked people how do
you live off Uber do you make a lot of
money and I say no but I didn't have a
job before and it gives me a way to earn
money and it's uh regulating depending
on how many people need that service so
I believe that is a good thing I think
that technology by and large is a Force
for good and it's something that certain
regions of of our society people who are
mostly depend on redistribution people
who are not productive but who are
mostly rent seeking who basically get
money not for doing some things but for
having opinions uh have opinions about
technology because they see it as a
competition but competition technology
allows us to make things more affordable
that before were unaffordable they
produce more goods and services that can
go around and they basically raise our
boat many of the things you say is true
I mean Uber for example they did this
gry ball thing where um they detected if
you were using the app and you were near
a police station or or a local Council
Office so they would say no cars
available so they couldn't um be
investigated in China they ordered they
they hired some hackers to get the IMEI
code of of the phone and they almost got
banned from from the App Store yes so
I'm totally in favor of controlling
criminal Behavior I also totally in
favor of regulating things that we don't
want as a society regulation is
necessary it's really important there's
also a lot of stuff that needs to be
regulated with respect to AI for
instance there is stuff going into the
training data that should be private and
uh that was not thought to be an issue
for instance say um a lot of medical
Publications are built on medical data
for which patients gave consent to be
used for medical research and the fact
that this went into medical uh journals
that were basically open access was not
a problem because nobody was reading
those journals outside of EX narrow
contexts but when these journals end up
legitimately legally in the public
domain and you legitimate legally
establish that you can train on public
domain training data Maybe suddenly
personally recognizable data end up in
an a model and nobody ever wanted that
and anticipated it and you need to
create rules around this and they need
to be fair and Equitable and create a
good outcome for everyone to the degree
that we can make it happen there's also
other stuff for instance I'm not in
favor of creating a tax on future
creation to reward past creators I think
the benefit for having something like
copyright is that we incentivize the
creat of important cultural artifacts
that otherwise wouldn't exist the Ben
the reason that copyright exists is not
that we limit creation that we diminish
the things that are in circulation and
so we need as Society think about this
conflict about incentives where some
people want to be paid and the interest
of society where we want stuff to be
created and so the question is how can
we make a society that makes us as rich
as possible and not just monetarily rich
but culturally Rich that gives us the
world that we want to be in and I think
that these Technologies are amazing for
that but we need to use them in the
right way and how can we regulate our
innovator a Regulators how can we
incentivize the people who set the
incentives and this is a very deep
question I hope that AI can also help us
understanding this modeling it but at
the moment we have forgotten about this
question in a way but but this is one of
the themes that that Gary talks about
though because yeah the the flouting the
copyright the open AI presented to the
House of Lords in the UK and they made
the case that um don't worry about us
flouting copyright because we as a
society need to have good AI so it kind
of makes sense and with Uber um they
lost you know the workers lost their
their protections and so on but the
thing is this is all about
conservativism and adaptation so of
course now when people see deep fakes on
Twitter they they just they don't take
it seriously because they don't trust
anything they see online and now people
know that we're moving into a regime
where copyright is being devalued and so
on but but there is something to be said
for maybe we should protect what we have
now and maybe change if it's too fast
can be harmful I think if a a capitalist
Society works well it is not going to
create a lot of profit in a time in a
given place for very long because what
the profit is representing is an
Arbitrage it basically means that you
are doing something that could be done
cheap more cheaply more efficiently and
so if you see uh something that has
increasing margins over a long time it
means that somebody else has to pay more
than they would have to right so the
idea that you
have cap drivers that exist as a
protected class and that are somewhat
dis engaged from how many drivers is
needed is is a problem because it also
means that people who actually need to
be driven around cannot be driven around
and that people that want to drive them
around are not allowed to drive them
around even if they're totally capable
to and that's that's a misallocation of
resources and so sometimes we need to
resolve such uh misallocation of
resources by removing regulation that
makes things worse we have this issue
that if you want to dig a new Subway
tunnel in New York you need the union
demands that you're paying people for
doing things that are no longer being
done in mod modern tunnel boring
machines so you have people that have uh
six digigit paid jobs that are not
actually doing anything just because we
have a regulation and as a result we
don't build new subway tunnels in New
York because it's way too expensive and
it's bad for everyone right so in many
ways we need to think about what
regulations do we build that have which
effect and copyright is a quite
complicated thing uh at the moment part
of the internet is an outrage because uh
Elon Musk has released an update to Gro
yes is AI that is able to generate
pictures yes that don't have the same
guard rails as other pictures so you're
now able to generate a picture of uh
Donald Trump with a machine gun flying
into the 911
skyscrapers and the outrage is
incredible it's people who just typed in
this prompt and uh say to Elon Musk what
an evil person are you see uh what you
made me do right it's hilarious it's
uh it's a really really interesting
situation and then people say oh my God
I noticed the same thing in my Apple 2
computer when I type in my Apple two
computer print eat more rocks it tells
me to eat more rocks which is really
really dangerous this should be
completely outlawed and so there is is
an issue here I think that in in one
side the AI generative AI is a brush it
allows you to paint things and
translates what you want to uh in what
you envision into a visual but by itself
is it's not a product it's a it's a tool
that allows you to produce a certain
content and I think that people are not
free to produce any kind of content in
any kind of given context it's not just
a matter of free speech there are
legitimate copyright interests there are
interests to not disrupt uh uh community
ities in legitimate things that they are
doing right there are label laws and
many other things so people are
responsible for the content that they're
producing using Photoshop or using a
text editor or using a paintbrush and in
the same way they are responsible for
the content that they're producing with
an llm and nobody was forcing that
person to produce a picture of uh Donald
Trump doing 9/11 right nobody was
thinking that Trump did 9/11 if that
person is producing a deep fake to
insinuate that Trump was doing 911 the
person might be already legally liable
we might not even need a new regulation
for this but if we want to impose a
regulation that prevents the AI from
producing this particular thing right
it's not going to have side effects and
these side effects are going to negate a
lot of the benefits that we can get from
that technology so if we are want for
have social media that only allow you to
say things that have been fact check
before most of the benefits of the
internet will no longer manifest and so
it's much better when we devel veloped
technology that deals with the drawbacks
of having more power having more freedom
having more productivity more Innovation
rather than preventing the innovation in
the first place yeah and I completely
agree that when you start regulating
things very quickly it explodes into a
bureaucracy and and I I can really see
where you're coming from yeah but there
are really people there that try to
eliminate not just freedom of speech but
also freedom of thought freedom of
imagination freedom to create certain
things and I find this very ugly and I
think we need to oppose it we need to
defend a certain idea and this idea I
think is the core of our society of a
world that works uh to free us that
allows us to take responsibility for
each other that allows us to discover
ethics allow us to coordinate by
autonomously recognizing what is that we
actually want and to do this I think we
need to be free this is not that that
there is some kind of grouop in the
University of enlightened 20 year olds
that have their preferred ideology and
can impose it on Everybody by
controlling what can be printed in
social media or what can be generated by
AI this doesn't mean that there is no
problem with AI that there are no
difficulties that we need to figure out
how to solve over with social media but
we need to be very mindful what is the
idea of a society that we want to live
on while we impose these regulations but
but isn't our freedom to book an Uber
the drivers kind of prison I mean there
are examples of drivers committing
suicide and stuff like that you know is
isn't it something that we really need
to think about what the cons are um you
know for our freedom so you mean it's
better if uh people are not allowed to
drive an
Uber I mean under which conditions
should the government stop in to prevent
two people from making contract with
each other this is I think an
interesting question right is it
actually beneficial when you have a
government that is able to uh regulate
every contract especially if this uh
government is captured by existing
industries that prevent you from making
contracts because they want to make more
profits I think that the taxi industry
is an extremely good example you have
basically an organized industry that is
have has a regulated profit while
providing a suboptimal service and it
maintains that Advantage by preventing
competition uh there are reasonable
people that have good reason to believe
that both sides are capable and safe and
sound and well intentioned and they want
to make that contract they're not
allowed to what how do you justify that
and that I think that's the main
issue interesting let's move on a tiny
bit what what are your thoughts on the
um the AI um startup ecosystem and and
llm companies in
particular I think that the majority of
the companies that exist in this
ecosystem are um building
applications and these applications
basically use the benefits that are
provided by having generative Ai and
turn them into value and it's a often
possible to do this with relatively
little investment so a lot of these
startups uh that can now come into
existence are people that use the
benefits of LM for instance to
autogenerate websites to autogenerate
functionality of databases and you're
just at the beginning of this where the
llm is no longer an agent but software
on environment or an larger application
that is dynamically changing its shape
in interaction with the user so I think
we're standing at the beginning of an
explosion of services that people can
provide and basically give rise to a lot
of value that is going to be created and
then it's a handful of companies that
are developing the technology at scale
that was devising uh these new frontier
models and there is an issue with these
Frontier models because if you build the
leading model then this thing is going
to be valuable until somebody makes the
a next model that is slightly better
than yours so the cost that you build
into training this model is going to be
sunk in that moment that's pretty
interesting situation because not
everybody is able to absorb that hit
right it's not like you're building an
airplane and uh you are deploying that
airplane and somebody builds a slightly
better airplane and your airplane
suddenly is worse zero it's still a
useful airplane right but the LM because
a software that you can just just put in
the update into the server Farm of
course you should always be using the
most recent version to create value it's
not like there is a lot of value by
using last year's version because you
still amorti it so this is the question
who can absorb these losses and this
means these need to be research Labs
that are mostly driven on producing
value by making Innovation and they
either need to have extremely good
Business Development to produce revenue
for customers that need particular
models for particular applications that
cannot be easily updated that easily or
quite SLE trajectories or they need to
be affiliated with other companies like
uh companies that build operating
systems or that uh build Logistics uh
applications and so on and that produce
a lot of money and can basically fund
the development of new AI technology on
the site yeah it's interesting I mean
what's your prediction about something
like um mistal so at liquid you have a
clear Mo you've got a technology that
that no one else has has done yet yes um
what about
mistro I think that uh if when you're
Building open source models in a way in
a similar situation as people who build
open source websites or open source
languages or open source software
development Frameworks or libraries what
you are creating is an ecosystem in
which more people will be able to
survive including yourself so you're
developing something that doesn't exist
today
and by for instance deploying the stable
diffusion models a lot of people got the
opportunity to develop Innovations for
um generative AI then existed before and
it created an extremely large ecosystem
of people that then would start
companies and come up with ideas so I
think these Investments are extremely
valuable and they should be encouraged
and rewarded and they often are but also
I understand totally when Mr at some
point says no now now we're going close
Source because we need a way to
capitalize on this and we don't see how
to to do this in in the present case I'm
extremely grateful that these historical
accidents like meta exist I think what
happened that Mark Zuckerberg uh had
enough money in the bank and thought
about how to get social media on the
next level and thought it's going to be
uh VR and then invested into a large
server Farm to do VR and then realized
that VR is not yet realizable in the
present form or it's going to go in a
slightly different direction and
suddenly had a lot of servers and then
thought oh what do we do with all the
gpus let's train train a few models and
make them publicly available and I I'm
very grateful for that happening because
it is creating a Baseline and a tool
that other companies can build on and
innovate on and uh develop new ideas
that are also feeding back into the
frontier Labs so I think that despite
people locally uh looking in despair or
being worried also from the perspective
of somebody who's interested in AI
itself and on the effect of these things
on the ecosystem I'm grateful that these
things
yeah it's interesting I read in Gary's
book that apparently Zuckerberg did it
because nobody in the valley wanted to
work for meta so um they they had to
have some exciting projects just just to
hire people in I uh have visited the
Facebook offices from time to time and
they were quite empty but I think it's
because of the pandemic it's not that
meta has any problem to rec Talent meta
is very profitable and it is a a
workplace that most people like to work
in and so I think then when Gary Marcus
says such a thing and not sure how what
is this based on does he have any kind
of Statistics that show that meta has
difficulty to find candidates I don't
think that's the case I must admit I was
surprised because I I would love to work
at at meta but um yeah that's very
interesting anyway I think we've run out
of time so yosa it's been an absolute
honor and a pleasure thank you so much
for coming guys I enjoyed this very much
amazing wonderful
