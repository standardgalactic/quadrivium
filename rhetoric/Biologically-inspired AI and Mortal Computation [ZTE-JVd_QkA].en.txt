in the race to build artificial
intelligence we've been missing
something
fundamental we want to draw inspiration
from how things like real
neurobiological systems work and somehow
map that or rather transform that
mathematically and computationally to
Frameworks that we can simulate what if
we could create AI which thinks more
like us why is the brain something that
can work with just a few watts of energy
and generative pre-trained Transformers
or GPT operate with essentially the
carbon footprint of a large city
Professor Alex Oria thinks that he has
the answer it's a very much an embodied
cognition View and then we of course go
further it's inactive it's extended it's
also embedded but creating bioinspired
intelligence has its own set of
challenges it's not very easy for you to
work with a neuromorphic chip and uh
something that my own lab and it's no
criticism it's just a particular
difficulty that we have right now
perhaps it's just too new of a
technology how can we overcome these
obstacles to build a new generation of
AI and what was cool is that I wasn't
giving it that data right after I had
trained it on its training database you
could synthesize this data and it
actually added a concrete bit of proof
that this really worked as the
generative model that Carl would want it
to be bioinspired artificial
intelligence might just be the next
Frontier if we are talking about things
that want to also serve Humanity we have
to understand that we're going to
coexist with these
entities but what happens when machines
start to think and feel like
[Music]
us Alex it's a it's a great pleasure to
have you on mlst thank you for having me
introduce yourself okay yeah I'm Alex uh
and I'm in a researcher in computational
neuroscience and cognitive science at
the Rochester Institute of Technology
and I am the director of the neural
adaptive Computing laboratory or Knack
we have a knack for neuroscience and
that I work on biometic intelligence
well that that's a good segue what is
biometic intelligence and the reason
this is interesting is almost every
other sentence Professor Carl friston
says biometic intelligence what does he
mean well I will Al admit uh I'm friends
with Carl and uh I have embraced his
phrase biomimetic intelligence uh and I
used to call it uh biologically inspired
credit assignment or neurobiological
inference um I I think especially in my
recent working with Carl uh I think of
biomedic intelligence as this grander
project on how can we move machine
intelligence towards a space that is
almost naturalistic because you I'm sure
you're familiar with naturalist
philosophy so uh in our most recent
paper uh mortal computation a uh
foundation for biomic intelligence I
believe is um we talk about a
naturalistic form of machine
intelligence and this sort of gets the
idea that obviously biomimicry is
copying right we're copying biology and
that's kind of the raw definition and
the idea is that we want to draw
inspiration from how things like real
neurobiological systems work and somehow
map that or rather transform that
mathematically and computationally to
Frameworks that we can simulate um but
even more strongly as Carl and I have
been recently argued uh that can that
software and that Hardware we care about
the substrate uh and how do those two
are entangled we called that mortal
computation we can talk more about that
if you like um and then of course
there's the bigger thing where you know
it's in a niche and you have to account
for that so biomedic intelligence is
really just understanding how does
nature as a good Exemplar there might be
many ways to do intelligence and I I I
can't say that I know what's the right
one uh but we have an existence proof of
the world around us and this could serve
as a good place to start and build a
foundation and that's where I think
biometics you know and bionics which is
the engineering application of things
that we learn from biology uh it creates
I would even tie it in with a field
called cybernetics uh which we draw
heavily from and biophysics and it's
kind of a fusion of those two fields to
build uh intelligence systems or just
even sentient or just basic systems that
uh operate in ways that we know certain
natural organisms abide by and yeah I
mean biologically inspired um approaches
to intelligence are very interesting to
me and of course we've had Michael Levan
um on the show and friston's been a huge
inspiration to me just break it down
though so biometic what does the memetic
part mean um well it is the essential I
mean it's copying right is the raw word
but I would
say when we're talking about mimicking
what we see in biology it is can we
distill a principle of some like for
example organization of how neurons
operate maybe their structure maybe how
their Dynamics operate and Dynamics I'd
say is the biggest aspect of it and can
I characterize that and so the bio the
mimicking is we're using the tools of
mathematics to capture that in some way
and they usually we can and a lot of my
groups work and Carl as well operate in
the language of differential equations
and can we describe how things change
with time how they adapt to aspects of
the environment from the language of
mathematics and then the final piece to
the mimicry is we take that mathematics
and now since we have some formalization
of it we can turn that into code right
and we can write that in software uh and
then that's the beginnings of trying to
BU to mimic what we observe in actual
neurons so you obviously need studies
like those from the wonderful work of
Michael Levens group uh I know Mike and
you know what do we learn from real
biological systems observational studies
and can I extract some principle and
turn that into a mathematical formalism
that can then learn be translated to
code and ideally can I translate that
into Hardware that implements that code
does that make sense Wonder yes it does
it does wonderful so um i' I've been
reading your you you you've got a really
interesting paper called mortal
computation can we start with I mean
what what is Mortal computation and what
is the difference between Mortal
computation and Immortal computation
very good question um well I will also I
since I believe firmly in giving credit
to those that came before me uh my
friend Jeff Hinton actually introduced
this phrase back in 2022 and one of his
papers a Ford Ford learning algorithm
and uh about 20 days after and I was in
conversation with him over email I came
up with the predictive forward forward
algorithm and Drew a lot of inspiration
from our chat in two sentences he
introduces part of what I call mortal
computation which is um the the software
which we were just talking about that
earlier about how to model biological
systems or properties of biological
entities
um that cannot really be divorced from
the substrate that implements it and
what do I really and that it's a tricky
and very weird area to think about that
you can't think of software as
disentangled from the substrate it is
mer it is together it's actually we
could go into this later if you would
like embodied right it is you cannot uh
think of the calculations or
computations that are being carried out
by the system independently of the sub
rate that instantiates it you take
advantage even at one way to think of it
is you're using the structure to do
those calculations it could mean like I
take advantage of my morphology and I
have a particular form and this allows
me to say things about like again if we
go back to neurons which is one of my
more favorite examples the message
passing structure like how did these
little electrical signals transmit along
these neuronal units and there is a
certain morphology a form an arrangement
um so essentially what Jeff was trying
to say originally about that or at least
my interpretation of the few sentences
that he wrote I've since then written
like 40 plus pages about that idea is
that leads to things that are very
important and we're missing today in
machine intelligence Energy Efficiency
why is the brain something that can work
with just a few watts of energy and
generative pre-rain Transformers or GPT
operate with essentially the carbon
footprint of a large city right and and
I could be wrong now Carl and I had some
estimates but they were even outdated
it's worse if in some ways today um and
Mortal computation speaks to that Energy
Efficiency that you get by bringing the
calculations and this is what Carl and I
took a thermodynamics view as close to
the substrate to the point where you can
think of things that we don't have real
in real implementation today in memory
processing and computation belief
updating but in terms of the hardware
whereas Immortal computation to properly
answer your question uh is the idea that
you can think of you can write your
software program without any knowledge
of how it's going to be instantiated or
executed and that's also a source of
great energy and efficiency because if
you think of the vanon noyman
architecture that we all use every day
you have layers of memory that are
transferring data from your weight
tensors uh that contain the you know
knowledge of your let's say deep neural
network the data we have to transfer
them to more and more volatile memory
and we go through Ram all the way until
we reach the CPU and then we can do the
calculation um every time you move
across subsystems of memory you're
expending jewels of energy and that's
where one of the great there's always
going to be a greater uh uh
thermodynamic cost to doing that compute
um and physics has these wonderful ideas
uh and Carl I talk a little bit about
them in the paper like the land our
limit and the jinsky inequality all they
really tell us at the end of the day is
that to change information content like
erase a bit there is a like lower bound
on that cost and the closer we get to
that bound you can't go past it there is
a certain amount of energy heat exchange
to do that and neurons we don't say it
quite like this but they are closer to
that bound once someone asked me are
they at that bound the answer is
probably not but they're much closer
than the way we do machine intelligence
today so that's kind of what Jeff and uh
we just fleshed that part out the other
part to Mortal computation and then I'll
I'll be brief about this is the uh
thinking about that Energy Efficiency
and being close to the substrate there's
this notion of uh a a directive or uh an
imperative and this gets at to what's
missing in intelligence largely today uh
we are at AGI so we can you know
obviously a lot of people care about
this but in the machine Learning
Community which is largely what I speak
in from uh there's this idea that the
machine has no drive to keep its
identity alive it doesn't want to
preserve itself uh and again you'll be
familiar from the free because this is a
the moral computation is now the way
Carl and I have phrased it it's another
coraly it's a new coraly of the free
energy principle just like active
inference is a coraly this is the new
one you just never knew that it was
there um so if you pop it out the ideas
that uh entities and these mortal
computers as we call them uh do not want
to disintegrate in their haat path the
idea is they want to remain in
thermodynamic uh inequilibrium or
disequilibrium and they do not want to
reach equilibrium otherwise their
identity is gone and you uh your
organization which is just for the
viewers uh the relationship of your
substrate your biological Parts your
things that give rise to you as a
self-organizing system that organization
is what you're trying to persist because
once it's gone it's gone at least in
let's say this Physical Realm this
implementation we're not speaking to uh
religion or other domains we're just
speaking to the Physical Realm um and if
I could somehow take you and put you in
another body somehow take your brain
maybe parts of your brain or some
digital approximation if that's doable
um you would not be the same Tim that I
am speaking to now uh you know your body
dictates a lot of that functionality um
and that's the part again going back to
Jeff's argument you can't think of your
personal your cogn
your computation in that view in that
view be careful about what I mean by
cognition and computation but I think
that's kind of the general idea and that
Primal uh directive is not enough to
explain the vast complexity of
intelligence and I am not speaking to
Consciousness the this is the foundation
like you need to start from this as
maybe a possible pathway for machine
intelligence to go starting from that
and thinking of the little building
blocks we need to even begin creating
that
drive that that makes sense yes so I
mean we are both frisians and and KL
speaks of this existential imperative
and this need for systems to maintain
their own Integrity through the
mechanism of this non-steady state
equilibrium which is beautiful um a
couple a couple of things to to to
comment on though so mortal computation
we deliberately entangle the the
morphology so the the structure of the
computation um with the with the um you
know so what the computation does and
the structure or the morphology of of
the computation because it's more
efficient but when we look at the Von
nyman architecture and when we look at
toing machines they're more abstract
which means we need to do more work but
the good thing about abstract
computation is you can um you can
reliably know what it's going to do and
you can take the same code and you can
run it on multiple machines what what
what what's the trade-off there well the
trade-off is you're going to lose that
ability that Immortal aspect of software
so that is a benefit in fact uh that's
what uh Jeff is nowadays or at least
more recently was saying is digital
intelligence right uh whereas mortal
Computing goes more towards like analog
intelligence right um and so you're
going to lose that ability for example
chat GPT if you put it on a GPU server
and the server breaks down the power's
cut off um as long as you have the code
and perhaps the weight tensor stored
somewhere and you can retrieve them put
it on another server it's going to work
pretty much the same but you will lose
that ability Immortal computation
because it sort of gets that that notion
again as we just said the Frisian
concept of identity which that is all we
say this in the paper too it's like your
peculiarities your
eccentricities uh the things that make
you specifically your set of experiences
they are firmly grounded in your very
specific substrate it's um another piece
to it just to uh to add to this is it's
a very much an embodied cognition View
and then we of course go further it's
active it's extended it's also embedded
uh and we added this extra term to uh
below it so we added a new Theory Carl I
don't know what Carl exactly thought of
it but he approved of it uh so there's
4E cognitive theory we made 5e cognitive
theory we took Michael Levan's ideas in
the merging area of Basil cognition and
called it Elementary cognition because
that's the 50 and that's the part you
need to have at the base of this uh
conceptual architecture right it doesn't
really tell you exactly how to implement
them because there's a lot of ways you
could do this there's so many different
organisms right um but that also gets at
that the last piece to this is it hints
at we might want to be thinking about
very very simple organisms like eoli
right thinking about how do they do
their basic compute because I don't
think we even have that quite right
biologists have studied them so we have
tools to look at that um but you're
going to lose to get back to your main
point you're going to lose that
transference that easy copy you're not
going to have the same program you know
across substrates because it's also
dictated by that morphology if you had
more arms and more legs your cognition
will be different because now you have a
different mechanism in which to interact
with the environment that is grounding
you even your mental
representations something I you can cut
this part if you like I but you and I
talked about computationalism yesterday
yes um and uh I did some thinking I did
some studying and prep for this uh more
computation very much leans on the
embodiment or the uh counterargument to
computationalism you can't have a brain
in the that and I realize that and again
it depends on what you mean by
computations I realize there's a lot of
interpretations um but the more uh
traditional older one about that there's
mental representations and you don't
really need to understand the sensory
motor systems I firmly disag at least
mortal computation firmly disagrees with
it says you are those representations
are deeply driven by those
the the particular morphology that you
have they shape those thoughts those
those experiences how you and I point to
things and how we understand those
physics it's inherently very body
oriented if that makes sense well it
does I mean we speak with a lot of folks
right now are computationalists and the
fores rail against computationalism but
it's mostly because of
representationalism because they're
they're either making um an epistemic or
an ontological argument that it's not
possible to represent cognitive
processes and you could argue that it's
just a matter of complexity um as an
externalist I do make that argument
because I think cognitive processes are
distributed far um outside of the body
but this is why I made the point about
abstractions right because the thing is
even though in computers now we we can
code abstractions and we have
reliability and so on but computers
don't understand us right because it
rests on this idea that we can
essentialize Concepts in the natural
world to abstract formulas or bits of
code that can run on a computer and the
reason why GPT doesn't understand us is
because you can't essentialize a lot of
semantic cognitive processes right yeah
I I I firmly agree with that statement
wonderful well I'm I'm glad you agree
well in in which case and that's by
sorry not to interrupt you but that's
what Mortal computation speaks to right
it gives you some tools and we go
further like a definition to get started
uh to say how could we build systems
that might begin to understand us
because towards the end of that work
Carl and I brief
because there's people far more
brilliant than myself that know way more
the ethics of it right because there but
I think that's our best chance it's not
a guarantee as I was discussing with
someone recently at AGI um but it's a
good chance for getting human value
alignment because if the these systems
can feel pain they can they have apri
receptive nature to themselves and again
all goes back to that identity
preservation there could be negative
outcomes to that but I think there's a
chance of that empathy emerging right
because you know especially if we can
coexist in a more positive way with you
know these mortal computer entities um I
think that's a good pathway towards that
alignment at least it's an an
opportunity wonderful so what are the
role of um Markov blankets in Mortal
computation a everything so I again as
you said earlier forian uh so we cast
mortal computation and that's where uh
again mortal computation can be probably
done and hopefully we Inspire other
generations to carry this further um but
that was our first formalism to say that
because we are in the act of trying to
avoid thermodynamic
disintegration uh we can also say
identity is all about boundary
preservation so the free energy
principle and there's a lot of different
ways to speak about it um is that you
have internal density dynamics that are
conditionally independent of the
environment and conditional means you
need something else to be conditional on
that's the market off blanket it's that
boundary that has active in sensory
States and this is where you can see how
active inference is also a part of this
Mortal computation is naturally
integrated it's just another correlator
that depends on you need active
inference you need active sample
selection uh and you're always and it
also has that flavor or that notion of
self- evidencing right that's also one
of Carl's favorite words and I've
embraced his favorite words um but uh
it's the idea that you're preserving
that Mark of blanket you are essentially
interacting that world through those
sensory States through or perceiving
those sensory States through the active
States um and you are preserving your
internal density Dynamics and so uh
mortal blankets is the formalism to
describe how this works and as I'm sure
you're also very familiar with you can
Nest them so this is how you start to
build nested or hierarchical or complex
systems out of Marco blankets you have
markof blankets of markof blankets of
markof blankets and that gives us a a
beginning point but only the starting
point towards how you'd begin designing
the atomic elements of a mortal computer
and you could think of them all as well
little cells are essentially markof
blankets or at least that's the
interpretation because of my work with
Carl I chose to embrace um and cells
have their internal you know components
their Dynamics and that's the thing that
they are preserving the boundary is the
cell wall that's their markco blanket
then we have our Niche and it's very
important to account for what the niche
is to Mortal computation says the type
of mortal computer has depends on where
it is right um and you're in this
process of energy exchange and substrate
exchange as well and removing toxins and
that's what cells are in the business of
doing and I think that's a great place
to start for thinking about what are the
fundamental elements of how we could
build intelligence systems and it could
look towards cells I mean maybe we build
artificial they don't have to be I mean
I do like Mike's work on xenobots and
anobot and they are mortal computers
according to our framework too they are
great examples of work that's been done
um but we could look to that and maybe
study the principles of xenobots and
then um essentially building nested
systems of markup blankets I think
that's one way that you could look at
these self-organizing systems because
that's what a moral computer really is
um it is a self-organizing system it is
also and I know I'm drawing from a bunch
of the parts of the paper but it is a
cybernetical system that is in the act
of also regulating environment it is an
example of the good regulator theorem
from Ashby's work you cannot forget his
wonderful ideas the law of requisite
variety and all these ideas just for the
viewers are just saying how do I
interact with the world around me um and
what are my degrees of freedom that
allow me to change where I go as I look
for stable States and uh that's all we
really need to pull for now from uh
cybernetics and then biophysics gives us
those Notions that we all know and love
when we learn to you know in school
homeostasis which is just act of keeping
variables within a certain range and
that gives you again the beginnings of
how we preserve aspects of our internal
density Dynamics allostasis is just a
predictive version and the final piece
to this puzzle that I want to make sure
I say is Mortal computers have to be
autopoetic which means and I I might not
be saying it quite right but they are
constantly in this process of renewal of
gener regeneration and destruction and
cells are wonderful examples to tie it
back of that so you know you have your
markof blanket markof blanket boundary
um but you know things are changing with
time it's inherently that morph
morphology substrate is changing and
we're what we're doing is we're
preserving that organization that
relationship between the parts that's
What Makes You Tim and that's what makes
me Alex and Carl Carl right it is our
identity that we are preserving because
we changed with time and you're still
roughly the same person you've been
right we grow we change and this again
I'm being very careful not to touch the
Consciousness aspect of it because I
don't think uh mortal computation gives
enough to speak to that and there's a
lot more brilliant ideas but I want but
I think that hopefully the CW is welcome
here Mark I think I said to you the
other day Mark SS has done some great
work linking FP to um to Consciousness
and and Folks at home should should
watch that when we drop it but um what
is um Mortal inference learning and
selection ah so that that was also what
Carl and I called the backbone of mortal
computation um since we are embracing
the free energy principle and uh at
least that's where this framework stems
from and I just said one of the parts of
it which is preserving my internal
density Dynamics uh and I'm you know
working with my markup blanket and you
know against the external world the
pertubations of the environment um and
I'm also by the way the other part to it
is I'm coupled to my environment we are
weakly coupled but vicariously coupled
and we enact change in our world um so
the free energy principle also gives us
almost what you could call in machine
intelligence uh an objective function
right and again it's there's beautiful
connections and information Theory and
thermodynamics to say they're two sides
of the same coin um and so as we What
Mortal inference uh Mills mortal
inference learning and selection really
tells you is that there are at least
three primary time scales at which we
optimize our variational free energy and
we'll just use free energy for now
because there's all these nice
approximation that you can do to make it
tractable um our objective function and
if we think about this energy objective
that we are trying to optimize and again
it's all just in service of the gold
preventing thermodynamic uh
disintegration um inference the first
one the bottom level component of Mills
is that we are following the gradient
flow of variational free energy and
again this is nice for the machine
intelligence Community because we like
derivatives and I said to you earlier
that we can use the language of M
mathematics to describe how for example
let's use neurons their neuron
activities are following the gradient
flow of variational or sorry of just
free energy I'm going to keep out
variational for now and we are following
that gradient flow and that tells you
how we can describe how their Dynamics
change with time which is really useful
it also gives you design principles too
because now we can say oh I can talk
about how components of that cell
interact with each other and how did
they evolve and so inference is like a
shorttime scale it's very fast um and
it's basically you know in Neuroscience
it's also called short-term plasticity
um things get forgotten quickly you
can't really encode long-term memories
they operate on a certain small time
scale learning Builds on top of that and
there is a an entanglement or a circular
causality here that I might touch on but
learning is a slower time scale it lives
above inference it doesn't happen at
every moment that neuronal Dynamics
change or activities or spikes are
emitted at different time steps um but
it is our plasticity it is how our
experience is encoded and it allows us
to persist and also uh funny enough as I
was discussing with someone earlier
today you could think of the inference
Dynamics as a way of following a
trajectory to a particular useful Point
let's say an encoded memory um but it
takes you a while to get there uh
learning is your way to amortize that
cost it'll let you get there faster
right because obviously you know uh
exponential learning is a about how do I
improve my ability to do something in
the environment for example in service
of my biological needs my homeostasis um
so that's what learning does and again
it can talk to and speaks to things like
synaptic change um and the reason why
neurons are wired together and how
things happen over time and you get
certain activity patterns that they
emerge that are more regular and then
the final part which is actually so we
have pieces of that in machine
intelligence inference we don't quite
get right unless you go the OD route a
lot of machine learning doesn't get
inference it's just instantaneous but we
could talk about that if you'd like
later um the last part that and and Carl
and I both firmly believe this is
structural selection so that's the S of
Mills and that is the slowest time scale
but it is the most important one which
is how you get things like synaptic
pruning and synaptic growth
synaptogenesis or neuronal neurogenesis
or neural death um and this is how that
structure changes over time and gets us
this idea that we have something called
Dynamics on structure you have an
evolving morphology your morphology is
not like your traditional deep neural
network or chat GP or generative
pre-train Transformer where you give it
a fixed set of synapses and neurons of
course these don't really have a
morphology they're just our
representation of them to uh teach
others um and this doesn't change you
have a fixed allocation and that is the
structure of the whole time we do have
some work on sparsification and things
but the machine Learning Community
hasn't really firmly embraced that too
much there's neuro architecture search
but um those are kind of like little
bolted on tools just to help do a little
bit of meta optimization um but real
biological entities and Mortal computers
which those are ones example of them uh
have this change in their structure over
time and so um those are very important
to be able to describe a mortal
computation at those time scales if you
can't do that uh you're missing at least
an important part you might have have
sub versions or suboptimal versions of a
mortal computer let's say you only do
inference and learning um that's a step
in the right direction but I think
you're cheating yourself of the way that
we get adaptivity how do we really
change to the environment um and so
Mills is really important and there's
again the way that uh Carl and I put it
there's a circular causality between the
different time scales and by the way
there could be many time scales in
between these are just like the big
Strokes right and things get more coar
grained as you go up but uh you can't
have good inference if you don't have
good learning you don't have good
learning if you don't have good
inference and there's also that same
relationship between structure and
learning um we can't have good structure
without learning and vice versa and
what's really interesting is that
oftentimes we take shortcuts in the
history of machine intelligence and
statistical learning like common filters
are a wonderful tool I deeply enjoy them
um but often times we we avoid the
learning part by saying well I'm going
to encode those Dynamics in a a fixed
transition Matrix right or maybe we have
a slowly slightly slower learning
version of inference but we don't really
have a good learning algorithm for them
you can learn common filters um machine
intelligence doesn't really address most
of these issues uh we do have maybe the
learning component right although I
completely disagree uh and I don't think
back propagation is the right way to go
we can chat about that if you like um
but uh we do have some version of
learning but we don't get inference
right so we don't even have the right
low L I think the most important step is
you start with inference and that's why
for example uh and this Falls natural
out of the free energy principle like
predictive coding is a natural
implementation or instantiation of
saying how do we get inference right
first which follows literally the
gradient flow of variational free energy
yes does that make sense too it makes it
makes a lot of sense makes a I'm just
thinking about the the evolution of of
software here so you know um we can
write code so we're explicitly telling
the computer what to do we could do
something like supervised machine
learning where we just you know model
the St statistical distribution of a
bunch of data and that data might be
kind of modeled around doing some task
and now we're talking about this this
bio memetic approach and we're throwing
away you know things like um gradient
based back back propop learning and so
on now how does this work I mean maybe
we should sketch out an example because
I'm thinking in the real world we we we
live in this incredible Orchestra of um
emergence and evolution and so on and
we're in this physical dynamical system
and and all of this structure has has
emerged and it's as if there's agency
and all sorts of sophisticated things
going on and we want to have ai which is
useful right so we're talking about
building a simplified version of
biometic intelligence and we want it to
do a specific thing how do we do that um
so if we're talking about what would be
the first step to building a toy model
right of a of a a mortal computer I do
think predictive coding is a useful
formalism for how we could begin to do
something that adheres to the free
energy principle so what predictive
coding really at the end of the day says
is uh think of groups of neurons that
are arranged in a particular morphology
but uh and one layer of neurons or one
little group of neurons his only goal is
to predict the activities of other
neurons so and so it's kind of different
already from the way that we build our
deep feed forward networks which is I
give some data and I run it through it
and uh the thing that I like to explain
to individuals is that uh the neurons in
a deep neural network don't technically
exist until data has run through it
otherwise it is just a pile of linear
algebra all right and those operators
don't do anything right um whereas
predictive coding already says neurons
exist throughout time it's inherently
temporal so like I said through the
language of differential equations you
can describe how neurons change with
time let's assume you can come up with a
set of Dynamics it can be many things uh
you're not really constrained to how
they change with time but you can come
up with like a linear equation and so
these neurons change with time and their
job at every instant is to make a
prediction when they make a prediction
you also have the other group of neurons
they wanted to predict so you have the
prediction you have a Target you can do
a subtraction right and that gives you
error and then that's your message and
so what Carl often means again it is a
simplification but you have a message
that can now be passed along the
architect cure so that message can be
transmitted back to the group of neurons
that made the prediction and you can
change their Dynamics because of that
that's like guess and check um and so
and then obviously you build a nested
hierarchies of of these predictors and
they're all predicting each other and
passing those messages up and down every
step in time and you get for free
parallelism and all these other things
that you can't do with neural networks
it's inherently parallel um and
asynchronous as well which biology is
very synchronous as synchronous it
doesn't have a clock coordinating
exactly what's going to happen at every
time even though we talked about
orchestration there is orchestration but
not uh not in the way that we do machine
learning today um that already solves
inference right there if you construct
that very simple little predictive
message passing structure you have now
inference Dynamics and you can write
down without going into the exact math
you can write down what the objective
function is of that prediction error you
could choose a gausian distribution or
some something that you like um and now
you have your variational free energy
for that little prediction and then you
can sum them up and you have your
variational free energy or your free
energy of that entire circuit you have
now an inference dynamics that follow a
gradient flow and then it's easy then to
think about how learning falls out of
that so you now got the Mills part as we
were discussing right you got inference
probably right so now learning depends
on inference so now every so often you
can schedule where synapses change right
you can do synaptic plasticity turns out
it's very easy we have plenty of
Neuroscience to also motivate this it's
a hean roll you know Donald Hebb and
some of the oldest ideas neurons that
fire together wire together uh the only
difference is that we are using error as
the other signal in this little update
so synapses happen at certain a slower
time scale so they don't have to happen
every so often um we can now encode
memories um and then of course from
there you can start to think about how
could we write the structure in terms of
the variational free energy and really
it's another gradient flow which you can
do is you can calculate the derivative
of essentially your uh variational free
energy with respect to the structure
which this is where it really touches on
the morphology is important now and that
can tell you how it needs to change
right to better serve this objective
function that gives you a foundational
idea for how do we build uh
sparsification and how do we change the
model to optimize that objective so that
gives you all three scales and that
right there is the uh let's say
computational simulated version of a
mortal computer uh obviously what that
structure is depends on what's your
choice of morphology and how do you
write down the physics of that system if
you're going to simulate it you need to
be able to say what are the properties
of that morphology I mean all of this is
great so you're describing this kind of
distributed asynchronous predictive
processing architecture that can do um
you know learning and inference and and
even and even um structure learning as
well you know so it's very biometic it's
beautiful but let's let's have a
concrete example because let's say I I
built a mortal computer to control a
thermostat and and at some point because
you know like the the juer position here
is in the olden days software was
designed whereas this this type of
software kind of it's grown it it
emerges so I need to shape or tune or
optimize this thing to do what want it
to do how how do I do that okay so this
gets at something that Mike was also uh
Michael Lan was talking about
programmability or you know how do you
you know direct this and it's
interesting at first glance this is very
difficult to do with Mortal computation
because like you said growing it right
it is a uh an entity that now wants to
optimize its own directive right it
wants to preserve its own identity
you're not really at least at first
glance you're not in much control right
so I think it starts with how do you
specify first of all the environment in
which it exists because you need to
under you need to say what the niche is
what is the body that all these dynamics
that I've just described earlier are
going to occur and then of course you
can maybe write down and specify then
what was the inference learning and
selection I think that is your chance to
program what you want the system to
rough it's a very loose way there is no
like oh I want it to do a predictive
task like I would maybe the better way
to think about this actually I just
realized is if you think of it as a
living entity you would have to start
thinking of this how would you teach a
child to do a certain task right you
would be interacting with it so again
there is the part where Michael Levan
talks about you know the genetic
programmability that what I'm describing
is kind of like that foundational part
you can start at the beginning because
you get to play the role of sort of like
the Creator right you're we're also
skipping another part that you know you
could simulate but I'm not saying we
have to is all Evolution right you know
we we're going to skip ahead and say you
can install also the right priors and
the right inductive biases which are
morphology is going to encode some of
those priors right you're going to be
encode what are those homeostatic
variables that the system does so you
have control at that level but if you
wanted to do certain tasks right like
the machine learning Paradigm you
brought up supervised learning you'd
have to now interact with it as since
you are a mortal computer and we are
supposed to be in an environment of
mortal computers of all kinds
um you would be teaching it like a child
and I think this starts to get at things
like educational curriculums now we
don't talk about this in the P I think
that's a wonderful question that I
should give more thought to but I think
you would have to start treating it as
another entity and how would you
interact by training that right and say
uh if you show a child an object and you
say this is a block right now they are
learning that mapping as well you're
communicating with it you are also
dealing with another aspect of mortal
computation uh you're eded added with it
right so I do think that if we are
talking about things that want to also
serve Humanity we have to understand
that we're going to coexist with these
entities because if you don't want it to
just for example say I need to live and
uh to achieve that directive you're in
my way and we don't want negative
outcomes right we don't want destruction
we want these to benefit humanity and we
want to coexist peacefully uh with you
know the other Mortal computers uh we
need to think of it as we're going to be
a collective right because the other
part of this picture that mortal
computation by itself doesn't explain is
there's other Mortal computers and we
are in a collective system and then of
course there's the extended part we have
objects that are not mortal that
interact with this process so you would
be basically saying you want it to do
prediction uh you're going to be guiding
it as if you were guiding a fellow human
right to learn certain tasks what those
curriculums look like will not be
identical obviously to how humano human
interaction happens um but I think that
will change the fundamental Paradigm of
how we do things like supervised
learning um you can look to the
framework of reinforcement learning to
some degree as a a way to think about
how would we teach a computer to do
classification uh with positive and
negative reinforcement but again you got
to think about it as this is also going
to have that active inference element to
it and intrinsic curiosity is at play so
I could keep going on but I don't know
if that helps shape what you were
looking for what's really interesting I
spoke with Thomas par about this because
you know um he wrote a book on active
inference and an act of inference is
basically a theory of agency and to what
extent is it agency if we're kind of
telling it what to do and of course
these you know these mortal computers
will be embedded in in our cognitive
Nexus and there'll be agency smuggling
to a certain extent because we'll be
kind of directing them and teaching them
yeah that's true yes but that will be
part of it you are right that we through
this uh manipulation or guiding you are
robbing of their agency to some degree
right but uh think that that's going to
happen if we embed them in you know the
world that we live in and we sort of
that's going to be the way you train a
mortal computer or at least a starting
point I mean there's an interesting
discussion there around um coherence
because of course you know nothing
exists um in in a vacuum right you know
we we're all embedded in in this in this
big soup together and and we influence
each other in very complex ways but we
should move on to your brain inspired
machine intelligence survey paper can
can you tell us about that because you
weren't not a fan of back prop no I'm
one of its strongest uh critics um okay
so biological or brain inspired
intelligence uh and it again there's
decades and Decades of work that we try
to review in that paper is this idea
that uh there's got there has to be a
way to play the credit assignment game
what do I mean by credit assignment it's
the blame game essentially when you have
an objective function which again that
means you can describe and write down
how performance you know is a function
of what you're looking for like oh if I
do classification uh accuracy or some
soft approximation the higher it is the
better it is or the lower it is the
better it is and vice versa um and so
backrop is one way to say I'm going to
take derivatives of this cost function
and that allows me to go back along the
pathway I took to get to the output of
my network and say how much did this
neuron play a role in that change of
this function given a certain piece of
data and a certain Target um so credit
assignment is all about the blame game
how much is this neuron playing a role
and how badly I do and how important is
it when I do things right um and so
backrop just has one way to say I take
data I run it through the network as you
explained to me the other day I like
this left to right right you take the
data you run it to the output plug it
into a loss function now you have a real
valued function you can take derivatives
of it as long as it's differentiable
which is already going to highlight one
of the problems with backrop and as long
as all the operations I took from the
input to the output are smoothly
differentiable right they have at least
one derivative um then I can go
backwards right to left along the
network pathway that I took to get to
the input and calculate gradients or
derivative updates to the weights that's
back prop essentially um and brain
inspired intelligence tries to address
among its many questions uh how do do I
do that blame game without going
backwards um and we know from
neuroscience and I think one of the
principles that emerges throughout all
the different algorithms that people
have come up with is this notion of
locality or local plasticity so synaps
is when they adjust at least the current
Neuroscience is that things are very
local we have a pre synaptic neuron so
before the synapse uh maybe it fires a
spike or some real value if you want to
use those uh it transmits that signal to
another neuron which then eventually
spikes and we just look immediately at
that time Step at the two exact
statistics and that's almost all you
need to update synapses in the brain I
mean there is also the role of chemicals
and neuromodulators and you can you know
somehow approximate those um how do we
get that principle in machine
intelligence because backprop is
completely the opposite of that you have
to wait for other neurons Downstream to
go backwards to make that update so
you're inherently locked and from a
computational point of view you've lost
parallelism uh at the inference time uh
and you've also lost parallelism in
terms of the plasticity so we can't even
make these more efficient without
hacking it and there's a lot of work on
hacking back prop but you incur error
because there's all these approximation
errors and you might not be optimizing
correctly and so uh getting that
principle of locality how do we build
neuronal systems or machine in
intelligence systems that actually
adhere to that principle of locality
also in time because the other part of
machine intelligence not so much today
but when recurrent neural networks were
in play to train them you just do back
propop on them you take the network and
since they are a recursive relation you
take that math equation and you stretch
it out backwards in time you build a
really really deep Network and you just
do what I explained to you earlier you
go right to left and train the entire
network and if the brain did that that
would mean like you took a copy of your
brain you went back in time and copied
every time step of it and stitched it
together to create a very temporally
extended version of yourself compute all
the updates change the weights synap uh
sum all that updates back up roll it
back up and then we move on to time t
plus one so basically you'd be doing
this every single time and storage
requirements for that are ridiculous um
but if we have locality and time you're
doing online learning things are
changing kind of like we were discussing
ear
you get the inference Dynamics right and
so part of what that survey really tells
you is to get that local principle I'm
explaining uh you might need to
reconsider how you do inference it's
almost like I'm saying in that paper
without saying it you you got to address
Mills really directly we have to come up
with computational processes to do
Mortal inference learning and selection
we just might not be talking about the
mortality component at the moment um and
so if you get those inference Dynamics
right that starts to tell you you things
like in predictive coding which is my
favorite example and it is reviewed in
there um you have to consider what the
architecture the computational message
passing architecture is and again like I
explained earlier you could just adapt
that example of those little neurons
trying to predict another group of
neurons that actually tells you how to
design the network so you're not going
to get this blank uh feedforward Network
where we just Stitch a bunch of linear
algebra together and call it a day uh
neurons will inherently be temporal and
you get but if you do that you get these
free uh heavent rules and it's very
efficient because the layers operate
again they can operate asynchronously
but they at least operate in parallel so
you could imagine putting parts of your
network on different gpus very easily uh
whereas backprop you're just not going
to get that it's very difficult the
other nice thing about all these
biological me uh biological learning
algorithms like what I'm explaining is
you don't need derivatives of functions
they don't need to be smoothly
differentiable why is that valuable we
talk about it talk about in the survey
is that gets you to things like discret
pulses in the brain neurons very
efficiently communicate with spikes
which are just you could think of them
as one or zero they're actually Action
potentials um Hardware loves one and
zero means I don't do the calculation
this opens up the door to things like
spiking neural networks which are just
essentially the principle that neurons
communicate with pulses now we can take
take advantage of analog Hardware or
neuromorphic chips which basically allow
us to bring us back to earlier what we
talked about in memory processing
neuromorphic chips are an example of
inmemory processing you have to think
about how those Dynamics translate to
the hardware and you're going to need a
credit assignment approach that is
friendly to that and I also think even
though it doesn't say it in that survey
uh it's essentially giving you what are
Credit algor Credit assignment
algorithms you could use to build a
mortal computer doesn't ever say the
word mortal in there it's not about
Computing directly but I think those are
the tools that we could use to allow us
to start constructing things that live
at the substrate and you need that
otherwise you you have all these
constraints that back propop prevents us
from you know working with the substrate
so so in in the survey mean you you
spoke about six families of approaches
and there is synergistic and and non
synergistic and implicit signal
algorithms and and explicit um sketch it
out for me so what that taxonomy was
trying to do is again there's been a lot
of approaches to biological learning
besides predictive coding um one of the
questions that I thought would be an
interesting way to organize them is uh
where do the teaching signals or the
target signals come from and when you
try to answer that question you can kind
of see how different biological
algorithms were designed so predictive
coding is an example of like synergistic
explicit and what do I mean by that
explicit means you can kind of point to
where the target value of any layer in
your network is going to be um and you
just need to be able to explain how is
that Target produced so you have to come
up with a process predictive coding just
to keep using the same example I've been
using uh gives you feedback Pathways
that tells you how those signals are
produced every layer says I'm going to
take a message I project it that gives
me a Target we have an explicit Target
now you can compare to predictions and
we have our errors that we discussed
earlier uh synergistic means there's a
certain amount of coordination across
the layers that isn't like back propop
where you're locked and you know you
have to go in a sequential process that
message passing as things move across
the network up and down or left to right
however you want to sketch it out um the
there's an orchestration it could be
asynchronous but you know the idea is
that uh some neuronal Dynamics will
change later in time because of the
error I had at this particular layer uh
it just won't happen instantaneously so
synergistic means we get coherence in
how the algorithm works because
otherwise you know you have no control
over do these Dynamics diverge all of
the sudden these converge and you're not
going to get a system that sort of like
settles to a representation that for
example Maps an input to an output that
you wish to happen now that's
synergistic obviously non- synergistic
means we're not worried about the
orchestration and there's a lot of
algorithms that have come out over the
time even like for example Jeff Hinton
has a one of I actually really enjoy it
is called recirculation it's just like
you're using autoencoders right you say
I take an encoder I run something
through a little tiny Network it's not
like layers it's just one layer I run it
through the decoder so I bounce it back
down and then I run it back up again and
I compare the statistics of that decoder
to the original input and I take that
re-encoded value and I compare it to the
other latent
representation right there there's no
coordination if you stack these building
blocks together um but you get systems
that learn they might not work as well
with that Synergy I mean obviously I
lean more heavily to some
orchestration um uh implicit by the way
uh just so we can finish the picture uh
is you don't necessarily have a place
that you generate a Target to change
neur activities too you can think of
targets like labels except uh obviously
you have output labels but you don't
know what the internal labels are if you
don't want to use like feedback loops to
do that uh you do things like
contrastive heavan learning which is
basically taking a generative model I
specify a positive phase and I let the
DAT let's say I have an input and an
output I let the network settle to some
activities that please that mapping um
and then I also have in parallel to that
or maybe couped to it uh I remove the
label let the network run in a freely
running open phase and then I compare
the statistics of the neural activities
after running it for so many steps in
time and I can do a subtraction there no
feedback loop was used to generate like
a particular Target to move towards it's
just just you're saying I'm punishing
the confabulations or the imagination or
the uh uh nonsense that is produced from
an open Free Running phase of my network
to the thing that I really care about
which was I want X to map to Y this is
would be like the supervised learning
flavor and you're moving or punishing
those negative phases to move closer
towards the positive phase and you get
for free local learning rules as well
but there's no like feedback pathway I
didn't design a message passing
structure and that's kind of like how
you can you can actually with those
Concepts implicit explicit synergistic
non- synergistic you can kind of group
all the different algorithms we've seen
over time sometimes they have certain
properties sometimes they overlap uh
predictive coding is as we said earlier
it's synergistic and explicit contess of
heian learning uh is synergistic but
it's implicit there is no targets that
are being generated so yeah that that's
one way to look at the taxonomy and how
we tried to organize all the different
algorithms and credit assignment schemes
you you spoke about energy based
approaches as well can you tell me about
that okay so energy based approaches and
funny enough it's not necessarily
grounded in free energy principle it can
be you can squint at them and make them
look like is we specify an energy
function and it comes from statistical
Dynam thermodynamics or statistical
mechanics sorry and the idea is that we
have an energy function we say for data
that are actually meaningful like in our
data set we have a function that we can
push down and say this is low energy I
want low energy for things that are real
that are actually part of my data could
be again an input output mapping it
could be unsupervised I just want you to
learn a generative model or a
reconstruction model for things that
truly exist for things that are not in
that data out of distribution I want to
raise my energy and so the idea is you
pull up this energy function if you
could plot it out and for toy models you
kind of can it's like you're pushing
down the points of data and you could
call those memories like long-term fixed
points uh again John hopfield for
example deserves some attention and love
uh the the hopfield network is one of
the earliest models of an energy model
right and so basically you want all your
memories to lie at these fixed points
and you want everything else to be
pushed up because they're nonsense right
and so um that's effectively what an
energy model is Yan Yan Lon has done uh
nice little tutorials on them as well
and when you have this energy function
essentially you can use the tools of
calculus again and take gradients of
this with respect to you know your
neural activities or particularly the
synapses and what you end up finding is
you make a bunch of approximations along
the way and you get like what I was
explaining earlier this contrastive Pro
a lot of energy models and we talk about
it there uh whether it's also yashua's
more recent equilibrium propagation it
is like a a generalization of
contrastive heavan learning um you're
going to have to have your network run
in essentially two phases and that's how
you get the positive like a for the
positive phase that's allowing you to
push an energy down and I hope I'm
getting this right and not
misremembering that it's the opposite
pushing down the energy for data points
and for the negative phase we are
pulling them up and that's where you
have to create some nonsense which is oh
I don't want to give you the label that
corresponds to this data let the network
just diverge find its own trajectory and
then I punish that trajectory because
that's not a meaningful memory right um
and then you get things in an energy
based model like audio so Auto AIO
associative recall right I can now do
pattern completion I can tell you this
thing is more similar to this other
thing um and you can build basically
from this principle of energy functions
uh which you can then write down and you
can track them this also gave rise to
something called boltzman machines I'm
not sure if you're how familiar you are
with them but that Jeff and Terry
sanowski did some wonderful work with
them in uh the early days of what I call
biological credit assignment and
essentially they are a stochastic
version of exploring that energy
function because you're just adding
noise now to the system um and noise is
a very biorealistic thing to model so
you can add corruption to it and now you
can do things like den noising and
pattern completion uh that you know I
have corrupted data and I want to clean
that up and you know these beautiful
boltzman machines could sort of do these
properties and uh while they didn't work
all the time for very deep architectures
uh it was nice to connect it to
statistical thermodynam uh statistical
mechanics very cool so um there's two
other reviews you've done as well so
there's a a neuro review and and a
machine learning review the machine
learning one in particular is very
interesting for the audience because of
course you know how can we build
software Frameworks to build this out
how can we use existing deep learning
libraries like pytorch to do some of
this stuff I mean could could you
introduce those two surveys as well sure
um so are you talking about the brain
inspired learning one or is this the
review of Neuroscience yeah sorry the
review of Neuroscience yeah yeah so that
one is like a like a distilled version
of the one that I was sort of explaining
the very deep one and it tries to say
there's a few representative algorithms
that we might want to look at um things
I want to highlight from that paper
obviously predictive coding is one of
those Frameworks the other one is
something called forward only learning
uh my friend Adam Kohan uh in and Hava
seelman invented uh some of the earlier
ideas where I can do learning in a
contrastive way without feedback which I
think is a really nice thing to
highlight so predictive coding requires
you to design message passing uh that
doesn't require it and uh I think that's
a promising alternative direction to
look at and so to answer your question
about how would I begin what what does
it mean to like build software to
leverage the tools of deep learning to
construct these libraries well we we
know that deep learning tools rely on
linear algebra so linear algebra is a
beautiful mechanism there's no need to
reinvent that so we can construct our
learning algorithms with those tools so
you could take P torch and say well I
want to exploit the efficiency of GPU
computation and these tools have
wonderful Engineers that work have
worked for a long time they work really
well for GPU computation so all I need
to do is not use the back propop part
right the autograd my my goal is okay
I'm going to write down the ordinary
differential equation that governs my
Dynamics if you're going to do let's say
predictive coding but you could do this
with forward only learning as well and I
need to also write down in terms of that
lingo and again it's like Python
Programming basic code um I'm going to
construct my hebbian R so you have to
write these out explicitly um so it is a
little more work whereas a lot of deep
learning today you just specify a feed
forward architecture call uh autograd
depending on the level of involvement
you want to have and you're Off to the
Races um but again you're not going to
get the benefits of like parallelism
right you're going to trust that the
sequential operation is all that you
need um so as long as you're willing to
write down those Dynamics plasticity and
inference and of course we could add
structural selection as well um you can
leverage these tools to do that
calculation in a fast way um so not not
to do too much of a Shameless plug but
my lab came up with a tool called NGC
learn which we do talk about in one of
those surveys
uh because there isn't a whole lot of
tools or at least in my experience that
support those that want to work in
biological learning um when I was a
young grad student I was kind of
navigating the field and looking at
wonderful papers and dreaming but uh had
to teach myself like a garage band
musician and I didn't want that to
happen for future Generations so what
NGC learn is is we work in Python since
that's the current lingo of the machine
Learning Community uh and we say okay
I'm going to give you these little tiny
building blocks if if you want it's also
very customizable to build neuronal
Dynamics and everything centers around
what I told you at the very beginning
ordinary differential equations and it
does all that nicely for you but you can
look at and inspect the internals if you
want um and it allows you to write those
explicit equations from an inference or
learning perspective very easily so that
way it supports your way of design it's
also in Jacks which is heavily optimized
it's a Google's Tool uh for GP
computation um so it's essentially
trying to do what py torch and
tensorflow did for backrop but for
computational neuroscience and biomedic
intelligence so I'd say you can take
those Frameworks and as long as you can
write down what it and by the way this
also supports new ideas because I don't
think that there's a Galaxy as Terry
sanowski once told me of learning
algorithms and credit assignment out
there you might have a completely
different idea but as long as you can
just write down its mathematical
underpinnings and you know it could be
be using the tools of differential
equations uh then libraries like NGC
learn or you can appropriate tools like
pytorch uh can instantiate them and I
think that's like a good way to think
about not being afraid of uh for new
users the explicit writing down because
that's what biological learning forces
you to do it forces you to know what the
learning process is whereas back propop
is like a blackbox right you can learn
how it works but often times you're
ignoring what learning is doing one
thing you spoke about in the paper was
stability issues because we are now
becoming
neuroscientists right we we're building
brains in in in a way how how did you um
you know talk about overcoming these
stability problems so the stability
plasticity dilemma if I'm making sure
I'm oriented correctly um so stability
is this idea that when I am learning a
series of tasks so when you train a deep
neural network let's say I train it to
classify cats and dogs
then all of a sudden I train it to
classify the same network that could do
that uh I don't know airplanes and cars
something you know very different well
if I were to re-evaluate that backrop
deep learning based Network on cats and
dogs I'd find my performance has gone
down quite a bit depending on how long
ago I did that task and how much data
I've been giving it um neural networks
catastrophically forget they have it's
even when you build them as recurrent
neural networks and try to give them
some versions of memory they're not very
stable that knowledge doesn't stay and
persist with time it's very uh unhuman
likee but it's also just very
unbiological um so uh when you when you
look to biology and things like
predictive coding can be tools to combat
this um you you can do things uh like
for example manipulate the Dynamics if
you think about something very simple
since you brought up Neuroscience um the
brain has a lot of complementary systems
so you have for example a cortical
circuit the the predictive code we're
going to go with predictive coding since
we keep using it and I want the viewers
to be able to follow with that example
if we design a predictive coding circuit
to perceive something and we also train
that you know with predictive coding so
at least now the algorithm is local
you'll still observe forgetting in most
cases so that alone doesn't solve the
stability problem it's just very plastic
which is great it means it changes it
adapts very robustly um so what would
you do to fight it well since you can
write out these explicit equations know
how the Dynamics change every time step
you have like the hood of your car the
uh engine of your car exposed you can
design another neural circuit and
something that my group did was we
designed a basil ganglia model and in
the brain basil ganglia one of the
theories is that it is like an
information routing system so you design
another system we actually used
competitive learning it's just it allows
us to do some simple heavan learning and
its job was to just turn off and turn on
neurons it was just doing almost like a
version of structural selection except
our networks didn't grow uh it was doing
Dynamic resource allocation and when you
take that little circuit and you Stitch
it to that cortical circuit I described
earlier forgetting goes away almost
entirely and we you can beat out back
propagation because basically what
you're doing is you're saying I'm
allocating resources for a particular
task and I'm preserving them when I
switch to something else I can tell the
difference between data points and
that's what the tool of Neuroscience
allow you to do because now you have
control over all aspects of the process
you know how the Dynamics change so then
it's very simple for you to think about
gaing variables and adding these new
Concepts so it gives you all these tools
then to allow you to build memory
systems uh backprop has so many
constraints and again too uh it's very
hard to add things like recurrence uh
without having to unroll them and when
you use biological systems it's easy
almost like putting little Lego blocks
together to build ever complic more
complicated
systems what are some of the scaling
bottlenecks of implementing these
systems uh I think it's actually the
hardware that is available to run them
now again I've talked about what would
be the ideal Hardware that you could use
uh but democratization is a problem I
don't have access for example to the
neuromorphic chips that I would want so
what ends up happening is you even
though they have this potential for
great parallelism uh and could scale far
better than backprop we're running them
on the tools that we run backprop on so
we are still executing them sequentially
even though mathematically it is
inherently asynchronous and parallel
we're not running it like that so these
things run slower than back propop and
that is an and you know there is no
Silver Bullet but when you simulate them
on the tools of back propop or the gpus
of back propagation based Frameworks um
a spiking neural Net's going to take
longer than a feed4 network feed forward
Network for all its problems is as
simple as I run a chain of Matrix
multiplies and then the backward pass I
run essentially a reverse of linear
algebra operations to compute
derivatives uh predictive coding and all
these inference Dynamics I'm talking
about or spiky neural networks you have
to think in terms of biology I have to
simulate them over a period of
milliseconds and so when you have to
simulate time which you know allows you
to do all those nice Dynamics um I'm
always going to be slower on a
sequential Hardware system that back
propop is faster so that they're not
going to scale as well if you use the
same tools of back propop particularly
the substrates right I think the B way
to circumvent that I know you didn't ask
how to avoid those bottlenecks is to do
things like inmemory Computing and to
take advantage of chips right and uh I
think the democratization of that and
making that type of Hardware available
to the general public is going to be one
of the biggest problems uh preventing
biological learning from being the new
paradigm I think that that's something
we need to work on we need to have um a
computational substrate that can do
Mortal computation that can take
advantage of this incredible distributed
asynchronous form of computation that
we've just been talking about we don't
want to be running them on uh deep
learning Frameworks on gpus we we want
to have Hardware which is optimized for
this type of computation what what's the
landscape well in terms of what is
available today there's companies like
Intel that have like their lowy heu chip
uh IBM has the true north there's a
couple of companies however I would say
that while there are communities that
are trying to democratize that to some
degree to allow Cloud access to
neuromorphic chips um it's not very easy
for you to work with a neuromorphic chip
and uh something that my own lab and
it's no criticism it's just a particular
difficulty that we have right now
perhaps it's just too new of a
technology is you can write these models
down like you could use our tool NGC we
actually have a translation tool NGC
lava for taking your model and your
Dynamics and making it compliant with
Intel's uh Loi 2 however it runs on the
simulator or the emulator there is a
bottleneck in terms of translating what
runs on the emulator of the chip versus
the micro code and the foundational
tools you need to literally run it on
the chip uh obviously if you're an
expert engineer and worked on the
original neomorphic chip it's Tri for
you to implement it uh but for those of
us that are engaged with the neuronal
Dynamics that's a bottleneck that's
going to prevent you from easily
translating your models and I think
that's what also slowing down in some
cases the adoption of neuromorphic
platforms um and I think that's going to
be that that's kind of what is difficult
about the landscape because it's not
easy to get a neuromorphic chip it's not
easy to get a cluster of gpus to run
your simulations on it's not like oh I
want a a neuromorphic chip for my
students to play with right now um and
they're very expensive I mean I think
that's the thing it's a newer technology
and it's going to take time for that to
settle uh and you know be more readily
available and I'm not sure exactly what
that will look like to make it uh easily
available to everyone um however the
promise that they offer is astounding I
do think that the Energy Efficiency that
we talked towards the beginning of this
interview is going to be what they help
resolve the most because uh they are
literally doing in memory processing so
as long as you're comfortable with
working the Dynamics of spikes um which
again is all going back to like
Electronics in electrical engineering
it's all about voltage and electrical
current and then basically gradient
Dynamics and we just add little Spike
pulses or discrete values to them uh you
can now run them on memisa crossbars and
so these things Naturally Fit almost to
the way that we think of a synaptic
efficacy or a synaptic connection they
map to particular MERS and you can kind
of point to where the neuronal cells are
and there's a lot of like things that
these naturally translate to and I think
the computation almost like fit it fits
like a glove right and it feels very
much in line with what I was trying to
get at with Mortal computation I do
think a neuromorphic mortal computer is
a very interesting direction to explore
but I think the availability of chips
and I will even broadly say too we talk
about it in the Mortal Computing paper
uh biotic constructs like organoid
intelligence or organoids stem cells to
create uh you know living computers or
even xenobots Michel I know works with
them they're his but uh I don't have
easy access to a xenobot or an anthr
robot uh which are wonderful platforms
to try to implement these gradient
Dynamics or these candidate uh brain
inspired algorithms um but it's not easy
for everyone else to work with them so I
think that's going to be a road block
that we're going to need to consider in
the future so the landscape is it looks
a little Bleak at the moment um but I
think there's the potential to change
that I yeah I've often wondered about
this because it's very hard to do this
kind of thing in Silicon um the reason
why we have this um you know Symphony in
the real world is because it's physical
and you know physical things are
presumably kind of you know controlled
by the laws of of of the universe and
they don't need to be simulated ad
nauseum in in in a computer but one
thing that caught my eye in your neuroml
um review paper was um neuro Evolution
approaches now I I remember covering the
neat algorithm do you remember from
Kenneth Stanley the neuro um evolution
of augmenting topologies and I guess you
can kind of think of that as as a form
of um you know morphology generation so
so you have like a population of neural
networks and you're kind of
complexifying them and doing some like
you know um Fitness selection and and so
on um that was really cool yeah and that
gets that that speaks to structural
selection yes because you're you're
changing the topology right they're
evolving with time so if we we think of
the message passing structure right of
any of these neuronal architectures uh
neat and algorithms that are like them I
think are a tool that we could use to
emulate how structure changes with time
add the Dynamics to the structure yes so
yeah that's a wonderful uh point to make
very cool well in closing can can we
talk about your neurogenerative coding
paper oh sure um so that paper written a
few years ago uh was an interesting take
again on predictive coding um and what I
wanted to do in that paper was show uh
well answer at least two questions one
was that a lot of predictive coding
makes further simplifications I was
evangelizing all these wonderful
properties um so when I talked about one
group of neurons trying to predict
another what we often do is we reuse
those same synapses to do the message
passing to transmit the error backwards
biology there's no reuse of synapses we
have a lot of feedback loops um but
there are other synapses that learn
Dynamics so what that paper tried to do
is say let me decouple that and show you
that you can use heian learning to learn
that feedback system jointly with the
generative model so that was one part
and I and it it pays homage also to Rish
ra who you know I've studied his work a
lot his 1999 paper with uh Dana Ballard
and the original predictive coding
circuit um and basically saying well in
in his work he also talked about trying
to decouple feedback from the generative
pathway so that paper showed you how to
do that the other thing is that also
showed you how to put Precision at the
Forefront of it um which these Precision
matrices how would you learn them
neurally that was another nice little
contribution but I think the bigger one
and I I'm getting lost a little in those
details is the fact that I showed that
that circuit could actually synthesize
data now oftentimes we talk we've just
talked about the free energy principle
PR coding is argued to be a generative
model you can write down the equations
you can actually write down the
probability value that it calculates
that is a generative model but we never
use it like one at least I hadn't
perceived it being used up until that
point so I was uh I asked myself the
question what would it be like if I
could dump noise into this and see what
it produced and that was one of the
coolest parts of that paper was uh it is
a directed generative model so we added
a little gussian mixture at the top to
act as like a long-term memory you could
dump noise into it and what it would do
is it would confabulate the kanji
Japanese character that I I trained it
on or the amness digits of course you
have to use nness when you work on these
or the Caltech silhouette examples and
what was cool is that I wasn't giving it
that data right after I had trained it
on its training database um you know and
again with the biological credit
assignment schemes that I was explaining
to you earlier um you could synthesize
this data and it actually added a
concrete bit of proof that this really
worked as the generative model that Carl
would want it to be right it was a free
energy learned freee energy principle
driven generative model um and what was
also super cool about that work is that
we compared it to variational Auto
encoders which is a back propagation
based generative model and generative
adversarial networks this was at the
time this was before the generative
pre-train Transformers were a thing um
and we outperformed them which was
really neat it was actually better in
terms of the metrics that we measured uh
and that was really useful because it
helps make that argument that me might
make people avoid biological learning
which is that you can perform on par or
even better in some ways than back
propagation and then a lot of work built
on that since then about like how do you
do outof distribution generalization
which is a problem that we have in
machine intelligence today in predictive
coding uh the neurogenerative coding
version that I proposed uh offered you
tools to do to tackle those issues so I
thought that was the coolest part but I
think the my favorite part will always
be that I could make that thing generate
and synthesize its own samples and see
what it looked like walk across the
manifold and look at what its topmost
Laten codes would produce and you know
it really embodied that gener the notion
of a generative model that was my
favorite part of that work beautiful
beautiful um we've spoken about so many
different approaches to you know
biologically plausible computation what
do you think is the most promising
one H if you had asked me that question
a few years ago I would have said
predictive coding and I still believe
that predictive coding is very promising
that's what I was talking about at AGI
there is another approach that I think
is really important and I think it's
forward only learning um I think it's
very promising because you could argue
that predictive coding has this
limitation that I need to design a
feedback pathway um while I believe in
message passing and again that's a very
Frisian concept too um I think it's
interesting if I can learn with just the
forward pass or the forward Dynamics
without going backwards or doing any
message passing itself and what that
opened the door and I did some work with
this and I have uh it's on archive
currently but working on getting it
finally published um uh the spiking
version of contrastive learning so the
idea of self-supervised learning without
working as a generative model is a way
to I think take the free energy
principle and invert it and say can we
work in a latent space rather than
trying to work with reconstructing
exactly pixels because it's really hard
to work with raw sensory data and so
what contrastive learning and fordon
learning does is it says let me take in
parallel which was different than
contrast to heavan learning as we talked
about earlier uh I'm going to take data
and I run it through my network and I'm
going to take nonsense and run it
through my network at the same time and
then I'm basically going to punish the
parts of the network that got the data
that was wrong and push up that it's
almost like an energy function um but
you're not uh the limitations of
contrast of heavan learning is they kind
of depend on each other these are
parallel so what's cool and Jeff had it
in one of his earliest arguments and
I've since emphasized or Amplified it is
that you can decouple these positive and
negative phases and almost makes it look
like wake and sleep because when we
sleep we do a lot of memory
consolidation and I think this framework
opens it up whereas predictive coding
could be probably bent to do that but
again you're forced to now explicitly
specify what that feed backpack way is
and so I think Ford only learning is
among the most promising nowadays and I
think probably if you want my final
final take on this is probably there's a
Synergy between the two of them yeah and
I mean I think Hinton was always a fan
of contrast of learning but um laon
moved in the direction of
non-contrastive learning yeah do you
think that could be applied to
contrastive heavan learning yeah I think
in predictive coding too could be bent
to do uh what Yan is doing and I
actually am currently working on some
ideas to try to prototype that to show
everyone how to do that I think uh I
think we do need and I like the the
thing of uh Yan's more recent comments
that resonates really strongly with me
is working in Laten space working uh why
why is that useful at a quick uh quick
comment on that is that it allows you to
avoid getting distracted with noisy
details um oftentimes when we're proc
processing sensory data we are trying to
sort of again abstract away and ignore
more uh distractors we want just the
core Salient information that we need to
do the task at hand and so we need to
learn certain representations that are
immune to that noise and in
reinforcement learning I think this is
really really important uh there's a
problem called the noisy TV problem
which is Agents get distracted by
continuous noise and they just stay
forever staring at that TV and they
never do the tasks that you want but
learning representations uh at the
latent space like Yan uh has you know
been proclaiming uh allows you to
sidestep the noisy TV problem and I
think that's a thing that we need to
consider in biological learning going
forward that's interesting I was
interviewing Rand Bellis rero at icml
and he's done a lot of work with with
Yan and I think he was talking a lot
about the the negative sampling problem
as well yeah yeah which which is that
there's an exponential number of
negatives you know to to to sample
outside of your distribution and you
mentioning that actually points to a
problem and this is why I also like what
Yan was talking about predicting in
latent space and predicting the future
of Laten space it sidesteps one
limitation of fordon learning even you
know Jeff's work on Ford for Learning
and my work on predictive Ford forward
learning is you need a process to
generate those negative samples and the
quality of that negative process
dictates how good you learn um so if we
can find a way to not have to do that I
think that's a secret sauce or a secret
key to moving past the you know why Ford
only learning has degenerate cases it
doesn't always work I still think is
very promising but it allows you to not
have to design the negative sampling
process it got rid of the feedback loop
which was great uh if you don't want it
um but you you do need to generate uh
good negative samples and like you said
there's exponentially more uh an
exponential size of negative samples
that you need to properly train these
indeed Alex it's it's been an honor and
a pleasure thank you for joining us
today thank you for having me it was it
was it was fun talking to you wonderful
[Music]
