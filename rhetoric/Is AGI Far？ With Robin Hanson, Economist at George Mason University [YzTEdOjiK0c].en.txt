we're on this upward growth trajectory
we have the potential to taking a big
chunk of the universe and doing things
with it and I'm excited by that
potential so I want us to keep growing
and I see how much we've changed to get
to where we are my book age of M is
about brain emulations so that's where
you take a particular human brain and
you scan it in find spatial chemical
detail where you fill in for each cell a
computer model of that cell and if
you've got good enough models for cells
and a good enough map of the brain then
basically the IO of this model should be
the same as the io of the original brain
if we can get full human level AI in the
next 60 to 90 years with the progress
then this population decline won't
matter so much because we will basically
have AIS take over most of the jobs and
then that can allow the world economy to
keep growing hello and welcome to the
cognitive Revolution where we interview
Visionary researchers entrepreneurs and
Builders working on the frontier of
artificial intelligence each week we'll
explore their revolutionary ideas and
together we'll build a picture of how AI
technology will transform work life and
Society in the coming years I'm Nathan
lens joined by my co-host Eric torberg
hello and welcome back to the cognitive
Revolution my guest today is Robin
Hansen professor of Economics at George
Mason University and author of The Blog
overcoming bias where Robin has
published consistently on a wide range
of topics since 2006 and where elzer
yudy published early versions of what
has become some of his most influential
writing on AI
Robin is an undeniable polymath whose
approach to futurism is unusually
non-romantic rather than trying to
identify value buddies Robin aims to
apply first principles thinking to the
Future and to describe what is likely to
happen without claiming that you should
feel any particular way about
it I set this conversation up late last
year after my deep dive into the new
Mamba States Bas model architecture
because Robin's 2016 book the age of M
which analyzes a scenario in which human
emulations can be run on computers
suddenly seemed a lot more
relevant my plan originally was to
consider how his analysis from the age
of M would compare to similar analyses
for a hypothetical age of llms or
perhaps even an age of
ssms in practice we ended up doing some
of that but for the most part took a
different direction as it became clear
early on in the conversation that Robin
was not buying some of my core premises
taking the outside view as he's famous
for doing and noting that AI experts
have repeatedly thought that they were
close to AGI in the past Robin questions
whether this time really is different
and doubts whether we are really close
to transformative AI at
all this perspective naturally
challenged my worldview and I listened
back to this conversation in full to
make sure that I wasn't missing anything
important before writing this
introduction ultimately I do remain
quite firmly convinced that today's AI
guys are powerful enough to drive
economic transformation and I would cite
the release of Google's Gemini 1.5 which
happened in just the few short weeks
between recording and Publishing this
episode as evidence that progress is not
yet slowing
down yet at the same time Robin did get
me thinking more about the disconnect
between feasibility and actual
widespread implementation and
automation beyond the question of what
AI systems can do there are also
questions of legal regulation of course
and perhaps even more importantly just
how eager people are to use AI tools in
the first
place when Robin reported that his son's
software firm had recently determined
that llms were not useful for routine
application development I was honestly
kind of shocked because if nothing else
I'm extremely confident about the degree
to which llms accelerate my own
programming
work since then though I have heard a
couple of other stories which combined
with Robins helped me develop I think a
bit better theory of what's going on
first an AI educator told me that
failure to form new habits is the most
common cause of failure with AI in
general in his courses he emphasizes
Hands-On exercises because he's learned
that simple awareness of AI capabilities
does not lead to human behavioral
change second a friend told me that his
company hosted a Microsoft GitHub
salesperson for a lunch hour demo and it
turned out that one of their own team
members had far more knowledge about
GitHub Co co-pilot than the rep himself
did if Microsoft sales reps are
struggling to keep up with co-pilot's
capabilities we should perhaps adjust
our expectations for the rest of the
economy and third in my own experience
helping people address processed
bottlenecks with AI I've repeatedly seen
how unnatural it can be for people to
break their own work down into the sort
of discreet tasks that llms can handle
effectively today most people were never
trained to think this way and it's going
to take time before it becomes common
practice across the
economy all this means that change may
be slower to materialize than those of
us on the frontiers of AI adoption might
expect and while that does suggest more
of an opportunity and indeed Advantage
for us in the meantime on balance I do
have to view it as a negative sign about
our preparedness and our ability to
adapt
overall regardless of your views and I
do suspect that most listeners will find
themselves agreeing with me more than
with Robin his insights are always
thought-provoking and I think you'll
find it very well worthwhile to engage
with the challenges that he presents in
this
conversation as always if you're finding
value in the show we would appreciate it
if you'd share it with friends post a
review on Apple podcasts or Spotify or
just leave a comment on YouTube and of
course I always love to hear from
listeners so please don't hesitate to DM
me on the social media platform of your
choice now I hope you enjoy this
conversation with Professor Robin
Hansen Robin Hansen professor of
Economics at George Mason University and
noted polymath welcome to the cognitive
Revolution nice to meet you Nathan let's
talk I'm excited about this so I have
followed your work for a long time it's
super wide ranging and um always very
interesting people can find your
thoughts on just about everything I
think over the years on overcoming bias
your blog but today I wanted to revisit
what I think is one of your destined to
be perhaps one of your most influential
Works which is the book the age of M
which came out in 2016 and envisions a
future which basically amounts to
putting humans on machines and we can we
can unpack that in more detail and then
explores that in a ton of different
directions where we actually are now as
we enter into 2024 is not exactly that
certainly um but I've come to believe
recently that it's maybe bending back a
little bit more toward that certainly
more than my expectations a year ago so
I've Revisited the book and excited to
uh bring a bunch of questions and and
kind of compare and contrast your
scenario versus the uh the current
scenario that we seem to be evolving
into okay let's do it one big theme of
your work uh always I think is that we
live in this strange dream time and that
our reality as modern humans is quite
different than the reality of those that
came before us and likely those that
will come after us for some pretty
fundamental reasons do you want to just
sketch out your kind of big picture
argument that our times are exceptional
and not likely to go on like this
forever the first thing to notice is
that we were in a period of very rapid
growth very rapid change which just
can't continue for very long on a
cosmological time scale 10,000 years
would be way longer than it could manage
and therefore we're going to have to go
back to a period of slower change and
plausibly then a period of slower change
will be a period where population can
grow faster relative to to the growth
rate of the economy in the in the
universe and therefore we will move back
more toward a malthusian world if the if
competition remains such as almost all
our ancestors were until a few hundred
years ago so we're in this unusual
period of being
rich uh per person and in very rapid
change and uh also sort of globally
integrated that is our distant ancestors
were fragmented culturally across the
globe and you know each talk to a small
group of people near them and our
distant descendants will be fragmented
Across the Universe and they won't be
able to talk all across the universe you
know instantaneously so future culture
and past culture were both very
fragmented and we were in a period where
our entire civilization can talk rapidly
to each other the you know the time
delay of communication is very small
compared to the doubling time of our
very rapid growth economy so we are now
an integrated civilization where we're
rich growing very
fast and there's a number of
consequences of being rich which is that
we don't have to pay that much attention
to functionality that we're not
pressured to do what it takes to survive
in the way our ancestors and our
descendants would be so we can indulge
our delusions or whatever other
inclinations we have they aren't
disciplined very rapidly by survival and
functionality that makes us a dream T
that is our dreams drive us our abstract
thoughts our uh vague Impressions our
emotions our
Visions we we do things that are
dramatic and exciting and meaningful in
our view according to this dream time
mind we have which isn't again that
discipline by functionality that is the
mind we inherited from our and ancestors
it was functional there it was
disciplined there we're in a very
different world but our mind hasn't
changed to be functional in this world
and so we are you know
expressing this momentum of what we used
to be in this strange new world that's
the dream time so let me just try to
rephrase that or or frame it slightly
differently tell if you agree with this
framing I would maybe interpret it as
maybe in a punctuated equilibrium sort
of situation where we're we're in the
transition from one equilibrium to
another there have probably been however
many of these through history not like a
huge number but a decent number I think
of you know such phrases as the Cambrian
explosion perhaps as another dream time
these moments happen when some external
shock happens to the system whether
that's like an asteroid that takes out a
lot of life or human brains you know
come on the scene and there's a period
in which the normal constraint are
temporarily relaxed but then in the long
term there's just like no escaping the
logic of natural selection is that is
that basically the framework so your
analogy of the Cambrian explosion could
be you know we discovered
multicellularity we discovered being
able to large make large animals and
that was happened at a moment there was
the moment of multicellularity and then
Evolution took time to adapt to that new
opportunity and the Cambrian explosion
is the period of adaptation then after
the Cambrian explosion we've adapted to
that new opportunity and then we're more
in a stasis and then you're imagining
this period of adaptation to a sudden
change but for humans
today we keep having sudden changes and
they keep coming fast and so there
wasn't this one thing that happened 300
years ago or 10,000 years ago that we're
slowly adapting to we keep having more
big changes that keep changing the
landscape of what it is to adapt to so
we won't won see this slow adaptation to
the new thing until we get a stable new
thing which we haven't gotten yet we we
things keep changing I want to maybe
Circle back in a minute to what would be
the conditions under which things would
restabilize I think I guess the M
scenario is one of them but there may be
others that uh might even be more
imminent at this point before doing that
I just wanted to touch on another big
theme of your work which is and I really
appreciate how you introduced the book
this way with the idea that I'm just
trying to figure out what is likely to
happen in this scenario I'm not telling
you you should like it I'm not telling
you you should dislike it I'm not trying
to judge it I'm just trying to
extrapolate from a scenario using the
tools of science and social science to
try to figure out what might happen I
love that and I I try to do something
similar with this show around
understanding AI I think there's so much
you know emotional veilance brought to
so many parts of the discussion and and
I always say we need to first kind of
figure out what is and I even in the
current moment like what capabilities
exist you know what what can be done
what what is still Out Of Reach of
current systems before we can really get
serious about what ought to be done
about it I guess I'd invite you to add
you know any additional perspective to
that and then I'm also curious like I
think that's very admirable but could
you give us a little window into your
own kind of biases or preferences like
what sort of world do you think we
should be striving for or do you think
that's just so feudal to even attempt to
influence against these you know Grand
constraints that it doesn't matter hey
we'll continue our interview in a moment
after a word from our sponsors the brave
search API brings affordable developer
access to the brave search index an
independent index of the web with over
20 billion web pages so what makes the
brave search index stand out one it's
entirely independent and built from
scratch that means no big Tech biases or
extortionate prices
two it's built on Real Page visits from
actual humans collected anonymously of
course which filters out tons of junk
data and three the index is refreshed
with tens of millions of pages daily so
it always has accurate up-to-date
information the brave search API can be
used to assemble a data set to train
your AI models and help with retrieval
augmentation at the time of inference
all while remaining affordable with
developer first pricing integrating the
brave search API into your workflow
translates to more ethical data sourcing
and more human representative data sets
try the brav search API for free for up
to 2,000 queries per month at brave.com
[Music]
API pretty much all big Grand
talk is mostly oriented around people
sharing
values that's what people want to do
when they talk big politics when they
talk World politics or world events when
they went when they talk the future
people want to jump quickly to do I
share your values here's my values what
are your values do we agree on values
are we value
buddies and people are so eager to get
to that that they are willing to skip
over the analysis of the details say if
you want to talk about I don't know the
war in Ukraine people want to go which
side are you on and who you know are we
do we have the right values and they
don't care to talk about like who has
how much Armament so will run out soon
or who can afford what or what they you
know all those details of the war they
don't want to go there they just want to
go to the values and agree about them
and that happens in the future too
futurism too people just want to jump to
the value so for the purposes people
have they're doing roughly the right
thing they don't really care about the
world and they don't really care about
the future what they care about is be
finding value buddies or if you find a
value conflict having a value War
that's what people just want to do and
so if you actually want to figure out
the world or national politics or
national policy or you want to figure
out the future you really have to resist
that and you have to try to pause and
you know go through an analysis first a
neutral analysis of what the options are
what the situation is I mean I am afraid
literally that if I express many values
that that the discussion will just go
there and you'll never talk about
anything else and that's why I resist
talking about that but I think you know
my simplest value with respect to the
future is I really like the fact that
Humanity has grown and and and achieved
vast things compared to where it started
we're on this upward growth trajectory
we have the potential to taking a big
chunk of the
universe and doing things with it and
I'm excited by that potential so my
First Cut Is I want us to keep growing
and I see how much we've changed
to get to where we are and I can see
that had people from a million years ago
insisted that their values be maintained
and that the world be familiar and
comfortable to them if they've been able
to enforce that we would not have gotten
where we are now that would have
prevented a lot of change so I kind of
see that if I want us to get big and
Grand I'm gonna have to give a lot on
how similar the future is to me and my
world uh I'm going to have to compromise
a lot on that I just don't see any way
around that so I get it that if you want
the future to be really comfortable for
you and to share a lot of your values
and your Styles you're going to have to
prevent it from
changing and you may have a shot at that
and I would not like that but you might
you know so again even as part of the
value framework even when I talk values
with you I want to be clear to
distinguish my value talk from the
factual talk I'm going to be happy to
tell you what it would take for you to
get your values even if they aren't mine
so so maybe maybe we should talk about
the facts of llm so you want to go there
in terms of comparing M's and llms right
so first of all our audience we should
say for our audience my book AG ofm is
about brain
emulations so that's where you take a
particular human brain and you scan it
and find spatial chemical detail to
figure out which cells are where
connected to what other cells through
what synapses you make a map of that and
then you make a computer model that
matches that
map where you fill in for each cell a
computer model of that cell and if
you've got good enough models for cells
in a good enough map of the brain then
the basically the io of this model
should be the same as the io of the
original brain which means you could
hook it up with artificial Eyes Ears
hands mouth and then it would behave the
same as the original human
would in the same situation in which
case you can use these as substitutes
for humans throughout the entire economy
and then my exercise of the AG ofm book
was to figure out what that world looks
like and a primary purpose was to
actually be able to show that it's
possible to do that sort of thing it's
possible to take a specific technical
assumption and work out a lot of
consequences and many people have said
they didn't want so many details they'd
rather have fiction or something else
but I was trying to prove how much I
could say and I hope you'll admit I
proved I could say a
lot and that almost no other futurist
work does that and so I'm trying to
inspire other futurists to to get into
that level of detail to try to take some
assumptions and work out a lot of
consequence so that's my book the age of
M you'd like us to compare that to
current large language
models and to think about what we can
say about the future of large language
models so in my mind the first thing to
say there is well an m is a full human
substitute it can do everything a human
can do
basically a large language model is not
that yet
so um a key question here would be how
far are we going to go in trying to
imagine a descendant of a large man
language model that is more capable of
substituting for humans across a wide
range of contexts we stick with current
large language models they're really
only useful in a rather limited range of
context and so if you're going to do
forecasting of them it's more like
forecasting the future with a microwave
oven or something you think about well
where where can you use a microwave oven
and how much will it cost and you know
what other heating methods will it
displace and what sort of inputs would
be compliments to that it would be more
of a small scale futury forecasting
exercise whereas the AG ofm was
purposely this very Grand exercise
because the M's actually change
everything whereas most futurism like if
you're trying to analyze the
consequences of microwave oven you you
have a much more limited scope because
in fact it'll have a limited impact so
that would be the question I have for
you first which is are are we going to
talk about the implications of something
close to the current large language
models or are we going to try to imagine
some generalized version of them that
has much wider
capabilities yeah very good question I
think maybe two different levels of this
would be instructive one of the key
things that that jumps out and I think a
lot of stuff flows from is the
assumption that M can be copied cheaply
paused and stored indefinitely cheaply
but not understood very well in terms of
their internal mechanism right very much
like this a similar understanding to
what we have of the brain where we can
kind of poke and prod at it a little bit
but we really don't have a deep
understanding of how it works we can't
do like very localized optimizations but
we do have this like radical departure
from the status quo which is you can
infinitely clone them you can infinitely
you know freeze and and store them
and so this creates like all sorts of
elasticities that just don't exist in
the the current environment so a number
of those features are going to be
General that anything that can be
represented as computer files and run on
a computer uh so any for of artificial
intelligence will be some of the sort in
general that you could have a digital
representation of archive it make a copy
of it uh pause it uh run it faster or
slower that's going to be just
generically true of any kind of AI
including M um the ability to sort of
modify it usefully I mean yes with human
brains initially they're just a big mess
you don't understand them but honestly
most Legacy software systems are pretty
similar so today large Legacy software
systems you mostly have to take them as
they are you can only make modest
modifications to them that's close to
what I'm assuming for m so I'm actually
not assuming that they are that
different from large Legacy software
systems uh they're just a big
mess that even though you could go look
at any one piece and maybe understand it
that doesn't really help you usefully in
modifying the entire thing you basically
have to take the whole thing as a unit
and can only make some minor changes but
you can copy the whole thing you can run
it fast or slow you can move it at speed
transfer it the speed of light around
the earth or through the universe even
those things are true of pretty much any
AI that could be represented in as a
computer file run on a computer yeah I
think these these dimensions are a
really useful way to break this down in
I I took some inspiration from you in a
presentation that I created called the
AI Scouting Report where I have the tale
of the cognitive tape that compares
human strengths and weaknesses to llm
strengths and weaknesses and I think for
the purposes of this discussion maybe we
we might even have like four different
kind of things to consider one is humans
second would be M third is let's say
Transformer language models of the
general class that we have today
although I think we can predictably uh
expect at a minimum that they will
continue to have longer context windows
and have you know generally more
pre-training and and generally more
capability um at least you know within a
certain
range and then the fourth one that I'm
really interested in and has been kind
of an an obsession for me recently is
the new state space model Paradigm which
actually has some things now in common
again with the humans and the M that the
Transformer models lack the stat based
models you know this has been of course
you know line of research that's been
going on for a couple of years kind of
in parallel with Transformers
Transformers have taken up you know the
vast majority of the energy in the
public you know Focus because they have
been the highest performing over the
last couple of years but
that has maybe just changed with a
couple of recent papers most notably one
called Mamba that basically
shows parody rough parody with the
Transformer on kind of your standard
language modeling tasks but does have
like a a totally different architecture
that I think opens up like some notably
different strengths and weaknesses
whereas the Transformer really just has
the weights and then the sort of next
token prediction the state space model
has this additional concept of the state
which is and and I recall from the the
book you sort of say you know taking an
information processing lens
to the human or you know where you spend
more of your focuses on the M you have
the current state plus some new input
information you know sensory or whatever
and then that propagates into some
action some output and a new internal
State and that I think is really the
heart of what the new state space models
do is that they they add that additional
component where they have not only the
weights like a Transformer has static
weights but they also have this state
which is of a fixed size evolves through
time and is something that gets output
you know at each kind of inference step
so that there is this internal state
that you know propagates through time
and can kind of change and you know have
long history I think it
is likely to bring about a much more
integrated medium and long-term memory
than the Transformers have and create
more sort of long episode conditioning
where these these models I think will be
more more amendable to like employee
onboarding style training you know which
is something also that the M's have in
your you know in your scenario right you
can kind of train a Bas M to be an
employee for you you can even put it in
that you know mental get it to that
mental state where it's like really
excited and ready to work and then you
can freeze it store it boot it up when
necessary you know booted up end times
as necessary the Transformers don't
really have that
same feature right now they're just kind
of their you know monolithic base form
at all
times but the State stat models start to
add some of that back obviously it's not
going to be onetoone with the the humans
or the M here's going to be my problem
with that number four if I look at sort
of the history of AI over you know the
history of computers and even the
history of automation before
that we see this history where a really
wide range of approaches have been ATT
tried a really wide range of paradigms
and and Concepts and structures have
been introduced and and over time we've
found ways in some sense to subsume
Prior structures within new
ones but uh we've just gone through a
lot of them and there's been this
tendency unfortunately that when people
reach the next new paradigm the next new
structure they get really excited by it
and they consistently say Are we almost
done they said that centuries ago they
said that half a century ago every new
decade every new you know kind of
approach that comes along people go
there's basically typically some demo
some new capability that this new system
can do that none of the prior systems en
able to
do and it's exciting and it's it's
shocking even and uh you know exciting
but people consistently say so we must
be almost done right like surely this is
enough to do everything and pretty soon
humans will be displaced by automation
based on this new approach and that just
happens over and over
again over and over again and so we've
had enough of those that I got to say
the chance that the next exciting new
paradigm is the last one we'll need is a
prior pretty
low we've had this long road to go and
we still have a long way to go ahead of
us and therefore it's unlikely that the
next new thing is the last thing so
that's that's my stance I think okay I
can talk to you about llm because
they're the latest thing we can talk
about what new things they can do and
what exciting options that generates in
the near
future and then we could ask well what's
the chance it's the last thing we'll
need or that the next one is the last
thing we'll need and so one way to cash
that out is to ask what do we think the
chances are that within a decade or even
two basically all human jobs will be
replaced by machines uh based on this
new approach and you know most of the
forecasting that's done out there is
excited about near-term progress in a
lot of ways but when you ask the
question when will most jobs be replaced
they give you forecasts that are way out
there because they think no we're not
close to that and I don't think we're
close to that
so then the question is now we could say
what will happen when we eventually get
to the point where AI you're good enough
to do everything and we don't know what
that approach is but we can still talk
about that point and and what's likely
to what the transition rate would be and
the transition scenario and
who would get rich and who would be
unhappy and you know all the different
things we could we could talk about
there but now we're talking about
whatever approach eventually gets us
past the you know being able to have to
do pretty much all human tasks which is
not where we are now or we can talk
about where we are now and what these
things can
do and you know what exciting things
might happen in the next decade hey
we'll continue our interview in a moment
after a word from our sponsors if you're
a startup founder or executive running a
growing business you know that as you
scale your systems break down and the
cracks start to show if this resonates
with you there are three numbers you
need to know
36,2 and 1 36,000 that's the number of
businesses which have upgraded to netw
site by Oracle netsuite is the number
one Cloud Financial system streamline
accounting financial management
inventory HR and more 25 netsuite turns
25 this year that's 25 years of helping
businesses do more with less close their
books in days not weeks and drop down
costs one because your business is
one-of a kind so you get a customized
solution for all your kpis in one
efficient system with one source of
Truth manage risk get reliable forecasts
and improve margins everything you need
all in one place right now download
netsuite's popular kpi checklist
designed to give you consistently
excellent performance absolutely free at
netsuite.com cognitive that's
netsuite.com cognitive to get your own
kpi checklist netsuite.com
cognitive omnik uses generative AI to
enable you to launch hundreds of
thousands of ad iterations that actually
work customized across all platforms
with a click of a button I believe in
omnik so much that I invested in it and
I recommend you use it too use Cog rev
to get a 10% discount well I'm tempted
by all of those options so maybe for
starters I would be interested to hear
how you would develop a sort of
cognitive tale of the tape
between humans and M's by presumption
have kind of the same cognitive
abilities but these kind of different
you know sort of external properties of
copy ability and so on the large
language model today you know
Transformer remarkably simple
architecture you know when you really
just look at like the the wiring diagram
it's way simpler than the human brain is
and not shockingly you know it it can
only do certain things there's there's
like really important traits that the
human brain has that the language models
don't have I identified one of those as
kind of integrated you know Evol ever
evolving medium and long-term memory I
wonder what else you would kind of flag
there I don't know if you have a
taxonomy of what are the kind of core
competencies of humans that you could
then say Oh and here's the things that
language models currently lack I'm
trying to develop something like this in
general because it does seem to me that
the large language models have hit not
genius human level but like closing in
on Expert human level at some very
important dare I say even like core
aspect of information processing right
like they can do things that I would say
are qualitatively different than any
earlier AI system could do uh it
certainly seems like we're we're getting
clo you know whatever the last step is
like we're definitely closer to it than
we used to be but just notice that
phrase you just gave was true or most of
all the previous ones as well they could
also do a thing that the previous ones
before it couldn't do it's always been
exciting we found a new fundamental
capability that each new paradigm you
know structure approach has been of this
sort that it was allowed the system to
do fundamental things you couldn't do
before that seem to be near the core of
what it was to think so there's
apparently a lot of things near the core
of what it is to think that's the key
thing to realize what it is to think is
a big thing there's a lot of things in
there well let's list some I I can't
come up with that many honestly like I
would love to hear you know how many how
many can you name I have all day so you
know could you begin to break down what
it is to think into key components I was
an AI researcher from 84 to 93 that was
I was a full-time at Nasa and then
Lockheed and certainly at that time I
understood the range of approaches
people had and could talk about the
kinds of things things systems then
could do or not do an expert terms
relating to the you know then current
tasks and and um issues I am not up to
date at the moment on the full range of
AI approaches so I don't want to pretend
to be an expert on that but I have
listened to experts and the experts I
hear basically consistently
say this is exciting this is great but
we're not close to being able to do all
the other things they would be much
better than I in making a list of that
and I feel like they should make the
list not me I mean as a polymath you
call me I want to be very careful to
know when I'm an expert on something and
when I'm not and I want to defer to
other people on areas where I can find
people who know more than I and when I
think I'm near the state-ofthe-art as as
good as anyone on a topic then I will
feel more free to generate my own
thoughts and think they're worth
contributing Fair um certainly I think
most people where I think you do still
bring something
very differentiated to the discussion
is just the the sort of willingness to
stare reality in the face or at least
try to the simplest thing is if I start
talking to a large language model
there's a whole bunch of things I can
ask it to do that it just can't
do I'm not so sure how to organize that
in terms of the large major categories
but it's really obvious that there's a
certain kind of thinking it can do and a
bunch of other kind of thinking it can't
do it's just and I don't know exactly
why it can't do them but you know I'm
talking to you there's a bunch of things
I could ask you to do in this
conversation you would probably do a
decent job of them and then if I were
talking to the large language model it
just couldn't do those things so it's
just really obvious to me that this has
a limited capability it's really
impressive compared to what you might
have expected five or 10 years ago it's
wow I never would have thought that
would be feasible this soon but you know
you just try asking it a bunch of other
things and it just can't do them right
yeah I mean I I think that in my view a
lot of those things are kind of
overemphasized relative to what maybe
really matters you know you see a lot of
things online where people there's
different categories of this some of the
things you'll see online are literally
people just using non-frontier models
and you know kind of confusing muddying
the water so always watch out for that
um I I have a you know long-standing uh
practice of first thing I do when I see
somebody say gbd4 can't do something is
try it myself and I would honestly say
like two-thirds of the time it's just
straight up misinformation and it in
fact like can do it but there's still
the one-third of the time that matters
they're not very adversarially robust
they're easy to trick they're easy to
sort of get on the wrong track um and
then they seem to get kind of stuck in a
a mode is a good term for it I think
where once they're kind of on a certain
this is kind of how they get they can
often get jailbroken you know if you can
get them to say like okay I'll be happy
to help you with that then they'll go on
and do whatever you know you asked
because they've already kind of got into
that mode yeah I'm much less worried
about them doing things you don't want
them to do than being able to get them
to do things at all that that is you
know humans can be made to do all sorts
of things you might not want them to do
that we survive that uh I mean to me the
main thing is you
imagine you know treating the large Lang
langage model as a new employee in some
workplace where you're trying to show
them how to do something and get them to
do it instead of you that's the main
thing that will be economically valuable
in the world that is when you have a
thing like that that can be introduced
into over place you know trained roughly
and said Watch How I do this you TR had
to do it now uh Etc then that will be
the thing that you know makes an
enormous difference in the economy
because that's how we get people to do
things right right so that I think is in
a sense the fundamental main task in the
economy which is a bunch of people are
doing something you have a new thing and
you say would you Kim watch us and ask
us questions and we will ask you
questions and like figure out how to
help us and be part of what we're doing
that is the fundamental problem in the
economy so that in some sense is the
fundamental task that any AI has to be
held up to I mean in the past of course
we don't even bother to have a
conversation to show how to do we
actually say well let's make a machine
to do this thing and then we design a
machine to do this thing and then we
train it up to do this thing all with
the idea the whole thing having in mind
the thing we're going to have it
do that's how AI has been usually in the
economy so far but now if you're
imagining a thing that could just be
trained to do a new job well that would
be
great sure then we won't have to design
the AI ahead of time for the particular
task but you'll have to have a thing
that's up to that and large language
models today are just clearly not up to
that you can't say I'm about to train
you how to do the following thing pay
attention I just did this now would you
do it you know well you can do that
quite a bit right I mean that was the
the main kind of finding in gpt3 was and
I'm not sure if I have this verbatim but
the title of that paper was large
language models are few shot Learners
and the big kind of breakthrough
observation there which I don't think
they designed for this was you know
there's a whole quagar of what should
count as emergent or not emergent but my
understanding is they didn't
specifically train for this few shot uh
imitation capability but they
nevertheless got to the point where at
runtime today you can give a few
examples of what you want and in fact
that is like a best practice that open
Ai and you know anthropic recommend for
how to get the most from their systems
they'll say some things are hard you
know they also have now trained them to
follow instructions just verbatim or
explicitly but they'll still say that
you know some things are better shown by
example than described in terms of you
know what to do so do that you know and
you'll get like a lot better performance
it seems to me that there is on that
kind of watch you know watch to to coin
of you know to borrow from medicine
watch one do one teach one it seems like
we're on the like do one step and that
does seem to be a a pretty qualitative
like threshold that has been passed now
they obviously can continue to get
better at that right but it's the range
of things they can do that's the
question yes it's great that they can
you can say here's some examples give me
another one but the range of things you
can do that for is limited most people
in most jobs they couldn't have large
language model swap in for you know many
of their main tasks that way that's just
but there are some and that's exciting
and I hope to see people develop that
and improve it but again the key
question is how close are we to the end
of this long path we've been on for a
while yeah I I guess I think about it a
little bit differently in terms of
rather than thinking about the end of
the path I think of how close are we to
key thresholds that will bring in
qualitatively different Dynamics
relative to the current situation so one
threshold that I think has recently been
passed in in a pretty striking way this
is should get more discussion than it
does in my view is Google deep mind just
put out a paper not long ago where they
showed basically a two toone uh
Advantage for a large language model in
medical
diagnosis versus human doctors and then
of course they also compared to human
plus Ai and that was in the middle so on
these cases that they lined up and the
you know the scenario is like you're
chatting with your doctor
60% accuracy from the language model 30%
accuracy from the human I was an AI from
83 to
94
and at the beginning one of the reasons
I came into AI was there were these big
Journal articles and National media
coverage about studies where they showed
that the best AI of the time which they
called expert systems were able to do
human level medical diagnosis this was
in the early 1980s right we're talking
40 years ago and obviously the computer
capacity is vastly larger than that so
either they were lying back then and you
know messing with the data or they did
have human level diagnosis back then but
they weren't allowed to apply it because
of medical
licensing so and we're still not allowed
to apply it because of medical
licensing so you know this is exactly
the sort of ability that won't give
substantial economic impact because we
had it 40 years ago and it didn't have
an impact then yeah I don't I don't know
so if I had I think one qualitative
difference between that earlier system
and this system which you know I won't
claim to be an expert in the earlier
expert systems but I would guess that a
huge difference is that you can take
today a totally uninitiated person who
has a medical concern and say sit in
front of this computer talk to this
doctor they don't even need to know as
an AI doctor they can just talk to it
that wasn't the problem back then they
could have made these expert systems
usable by ordinary people with modest
effort that wasn't the problem in using
them the problem was just you're not
legally allowed to use them only doctors
are allowed to give medical diagnosis
and so only doctors are allowed to use
these systems to talk to people that was
the main obstacle and it still is today
the obstacle you know you you could make
such a system today that Ordinary People
could talk to but they're not allowed to
talk to it and they won't be allowed to
talk to it for a long time I think there
is a qualitative difference between
these systems if I were to sit down in
front of the early 80s thing and I were
to say you know what's different today
is the the chat system can say Robin
tell me how you're feeling tell me about
your experience and you can just go on
in your own language however you want to
express yourself and it can get you and
then it can ask you specific follow
you're not going through a wizard and
you know going down an expert system
tree and ask for like numeric scores you
don't understand and don't know you can
literally just express yourself that was
not there then right I mean nothing but
but that's not the limit Factor right I
mean you couldn't have a you know fancy
Graphics interface back then either this
was early 1980s right uh but again the
limiting factor is the legal barrier it
was back then and still is and that
legal barrier doesn't look like it's
about to go away so if you're G to make
us excited about applications it'll have
to be something that's
legal my model of this is that the
consumer surplus of this type of thing
is going to be so great it already was
40 years ago it would have been a huge
consumer surplus 40 years ago was not
allowed but there was never a ground
swell of I I don't know I'm I'm just not
buying this I'm not buying that there
was an experience that is qualitatively
like the one that we have today such
that I think today if you show people
what Google has they will say it is not
acceptable to me that you keep this
locked up behind some payall I don't
think that was the the general consumer
reaction to early 80s expert systems and
it like that that political economy
pressure could change things consider
the analogy of nuclear power the world
has definitely been convinced for a long
time that nuclear power is
powerful it is full of potential and
power and if we had let it go wild we
would have vastly cheaper energy today
but it was that power that scared people
which is why we don't have that energy
today the very vision of nuclear energy
being powerful is what caused us not to
have
it we overregulation it to death and we
made sure that the power of nuclear
power was not released we believed the
power was there it was not a at all an
issue of not believing the nuclear power
was powerful it was believing it was too
powerful scary dangerous powerful and
there's a risk that we'll do that with
AI
today we will make people believe it's
powerful so powerful that they should be
scared of it and it should be locked
down and not released into the wild
where it might do us terrible danger
yeah well that's certainly a tragic
outcome in the uh case of the nuclear
power and I think it would also be a
tragic outcome if people are denied
their AI doctors of the future on that
basis and it could happen I you know I
certainly wouldn't rule out the
possibility that you know just AI
research broadly gets made illegal this
time we do have I mean again it is I do
think we're in a different regime now
where enough has been
discovered enough has been put into the
hands of of millions there is sort of
the open- source kind of hacker level
not medical diagnosis is not we have not
put medical diagnosis AI in the hands of
ordinary people and if you tried it you
would find out just how quickly you'd
get slapped down yeah I think I think I
know someone who actually may be about
to uh try this and it'll be very
interesting to see how quickly and how
hard they get slapped down and how they
may respond from it I've actually been
very encouraged by the response from the
medical
community I would say you know obviously
it's not a monolithic thing but I did an
earlier episode with Zack Kahani who is
a professor at Harvard medical school
and who had Early Access to gp4 he came
out with a book basically to coincide
with the launch of gp4 called um gp4 and
the revolution in medicine and broadly I
have been encouraged by how much the
medical establishment has seemingly been
inclined to embrace this sort of stuff I
don't know if it's just that they're
also overworked these days or well
they'll embrace the internal use of it
again it's always been doctors allowed
to use these things and the main reason
they didn't get more popular is doctors
couldn't be bothered to type in and
input all the information because they
want to have short meetings with with
patients even today of course if you've
gone to a modern doctor most of your
meeting with a doctor is them typing in
information to their computer as they
talk to you and they don't want to spend
much more time you know typing in more
and so they don't want to use computer
AIDS in their diagnosis and that's been
true for a long time they computer
diagnosis AIDS been available for a long
time that would give them better
diagnoses at the cost of them having to
spend more time with them and they've
chosen not to spend more time that's
been true for many decades now have you
personally used gp4 for any like
Advanced things like this medical or
legal advice or whatever uh no I'm a
economics professor so I've used it to
check to see what my students might try
to use it to answer my exam questions or
essay questions or things like that I've
asked it things that I wanted to know
and try to check on them I haven't used
it for legal or medical questions those
are areas which are heavily regulated
it's always been possible for other
people to uh offer substitutes so for
example many decades ago there were
experiments where we for you know
basically for the purpose of general
practitioner doctors we compar doctors
to nurses Nurse Practitioners or
paramedics we found that those other
groups did just as well and much cheaper
at doing the first level of general
practice but they haven't been allowed
so that right there is enormous value
that could have been released we could
have all this time been having nurse
practitioners and doctors and paramedics
do our first level of general practice
medicine and they would save at least a
factor of two or three in cost and
that's been true for decades we've had
randomized experiments showing that for
decades so going back to the age of M
then for a second are we are you just
assuming that that scenario doesn't
happen in mland for some reason or like
why wouldn't it be the first objection
to the age of M seems like it maybe
should be M's will be made illegal
nobody will be allowed to do it
absolutely and and and basically you're
just kind of in the analysis saying well
let's just assume that doesn't happen
because it'll be you know it's a short
it's a short book if if they just get
made illegal too early is that the idea
well so first of all I say transitions
are harder to analyze than equilibria of
new worlds so I try to avoid analyzing
the transition U although I do try to
discuss it some toward the end of the
book uh but I admit I can just say less
about a transition it does seem like
that uh you know compared to a scenario
where everyone eagerly adopted M
technology as soon as it was available
more likely there will be resistance
there will be ways in which there are
obstacles to M technology early on and
therefore at some point there would
basically be the you know breaking of a
dam flooding out where a bunch of things
that had been held back were released
and then caused a lot of disruption
faster disruption that would have
happened had you adopted things as soon
as they were available that's part of
that can be a very disturbing transition
then uh you know if all of a sudden
large numbers of people are disrupted in
ways they weren't expecting in a very
rapid way because of you know a dam
suddenly broke open then I think there
will be a lot of unhappy people in that
sort of a transition and maybe a lot of
dead people so imagine the M technology
slowly just gets cheaper over
time but it's not very widely
adopted then there'll be a point at
which it eventually gets so cheap that
if some say ambitious Nation like say
North Korea said Gee if we went whole
whole hog in adopting this thing we
could get this big you know economic and
Military advantage over our competitors
then eventually somebody would do that
now might take a long time that is the
world could coordinate to resist this
technology for a long time but I don't
think they could hold it back for a
thousand years so then I feel somewhat
confident eventually the age of Emma
happens and then eventually there's a
thing to think about and then I'm
analyzing that world so I don't want to
presume in the age of M that this
transition happen smoothly or soon or as
fast as it could but I want to say
eventually there'll be this new world
and here's how it would play out so I
don't know if you know that in the last
few
months I've dramatically changed my
vision of the future to say that there
was probably going to be a several
Century Innovation pause probably before
the age of M happens and then the world
that would eventually produce Ai and M's
would be a very different world from
ours and somewhat hard to think about um
that is rising population will stop
rising and will fall due to Falling
fertility that will basically make
Innovation grind to a halt then the
world population will continue to fall
until insular fertile subcultures like
the Amish grow from their very small
current levels to become the dominant
population of the world and then when
that becomes large enough compared to
our current economy then Innovation
would turn on again and then we would
restart the AI and MTH and then
eventually the age of M would happen
trying to anticipate how transitions
would happen in a world we can just
hardly even imagine seems tough right
that is okay imagine the descendants of
the Amish become a large powerful
civilization they've always been
somewhat resistant to technology and you
know very picky about which Technologies
they're allow but eventually I would
predict there would be competition
within them and that would push them to
adopt Technologies like AI andm but
we're we're looking long way down the
line and this isn't what I wish would
happen to go back to your initial thing
I I would rather we continued growing at
the past rate of the past Century and
continue that for a few more Centuries
by which time I'm pretty sure we'll
eventually get M's and human level AI
although question in what order um but I
got to say at the moment that's not
looking so good so basically you know
I'm estimated that if we were to
continue on a steady growth path uh we
would eventually reach a point where we
had the same amount of innovation as we
will get over the entire integral of
this several centuries pause and I've
estimated that to be roughly 60 to 90
years worth of progress so if we can get
full human level AI in the next 60 to 90
years with the progress then this
population decline won't matter so much
because we will basically have AIS take
over most of the jobs and then that can
allow the world economy to keep growing
I think that's iffy whether we can do
that whether we can achieve full human
level AI in 60 to 90 years years and I
know many people think it's going to
happen in the next 10 years they're sure
so sure of course it'll happen in 60 to
90 years but I look at the history and I
go look I've seen over and over again
people get really excited by the next
new kind of AI and they're typically
pretty sure a lot of them are pretty
sure that we must be near the end and
pretty soon we'll we'll have it all and
it just keeps not happening the main
change I want to suggest to that
Paradigm is placing the end with
meaningful thresholds along the way I
think there are probably several that we
will hit on some time scale and it feels
to me like at least a couple of the big
ones are pretty
close and then you know who like at the
the end is very you know my crystal blog
get very foggy Beyond like a pretty
short time scale but I'm I'm struggling
with the the early 80s expert system
systems but it really does seem like in
my lifetime I have not seen anything
that remotely resembles the experience
of going to a doctor I've seen WebMD
I've seen you know I I'm familiar with
like expert systems to a degree but I've
never seen anything that you know I
think Ilia set set skyver from open AI
puts this really well he's like the most
shocking thing about the current AIS is
that I can speak to them and I feel that
I am understood and that is like a
qualitatively different experience and
you know clearly I think reflects some
qualitative you know advance in terms of
what kind of information processing is
going on if I had to say like what is
that under the hood I would say it's
like a high-dimensional
representation of H of Concepts that are
like really relevant to us that you know
have previously been kind of limited to
like language level compressed encoding
but now we are actually starting to get
to the point where we can like look at
the middle layers of even just the
systems we have today you know the
Transformers and say you know can we
identify Concepts like positivity you
know or paranoia or love and we are
starting to be able to you know it's
still pretty messy we have the same you
know not the same but we have an
analogous problem to like understanding
what's going on on inside the brain and
it's just it's a mess in there still in
the Transformers but we are starting to
be able to see these like high
dimensional representations where it's
like that is you know a numeric
representation of some of these big
Concepts and we're even starting to get
to the point where we can steer the
language Model Behavior by like
injecting these Concepts so you can say
for example you know inject safety uh
into the middle layers of a transformer
and get you know a a safer response or
you know danger right or you know rule
breaking and then they'll you'll be more
likely to like break their rules what's
your focus on at the moment is telling
me about how the latest generation adds
capabilities that previous generations
didn't have but every previous
generation had that same conversation
where they focused on the new
capabilities their new generation had
that the ones before it didn't happen
what the conversation you're
participating in
is continuing the past Trend uh but the
fundamental question is when will AIS be
able to do what fraction of the tasks
that we have in the human
economy if they can't do a large
fraction of them no matter how
impressive they are at the task they can
do we will see this economic decline as
the population declines they need to be
able to do pretty much all the tasks in
order to prevent the economic Decline
and then the halting of innovation I did
this study of innovation in the United
States over 20 years from 1999 to
2019 and that was a period that
encompassed what many people at time
said was enormous AI progress
and many people in the period were
talking about how there was this
revolution in uh AI that was causing a
was about to cause a revolution in
society uh in this period from 1999 to
2019 so we did a study a co-author and I
uh Keller skull who um looked at all
jobs in the US basically roughly 900
different kinds of jobs and over that 20
period year period we had measures of
how automated was each job in each
year and then we could do statistics to
say when jobs got more automated did
they get the wages go up or down did the
number of workers in those jobs go up or
down we could say what about jobs
predicts how automated they are and did
the things that determine which jobs are
how automated change over that 20e
period that as if there had been some
revolution in the nature of automation
then the things that predicted which
jobs would be more automated would have
changed over
time what we found was that when jobs
got more or less automated that had no
effect on average on wages or number of
workers and that the predictors of
automation didn't change at all over
that 20-year period and they remain to
be very simple-minded predictors that
you might expect about automation from
long ago the nature of automation hasn't
changed in the aggregate in the economy
main predictors of automation are
whether the job has nice clear measures
of how well you've done it whether it's
in a clean environment with fewer
disruptions and whether tasks nearby
have been automated it's because there's
a way that which task automation spreads
through the network of nearby tasks so
that study suggested at least up until
2019 there had been no Nate change in
the nature of Automation and basically
there's a gaussian distribution of how
automated jobs are and the media
Automation and moved roughly a third of
a standard
deviation through that distribution so
jobs had gotten more automated
substantially in that 20-year period but
still most jobs aren't that
automated and that would be my rough
prediction for the next 20 years is to
say the pattern of the last 20 years
will continue that is we'll slowly get
more jobs more automated but most
automation will be very you know basic
stuff so far we just haven't seen much
at all of advanced AI kinds of
automation making a dent in the larger
economy what is so what do you make of
things I'm sure you're familiar with
like The mlu Benchmark or the big bench
maybe not if not I can characterize them
for you but is this uh machine learning
uh set of tests in order to uh Benchmark
performance yes I believe it's massive
multitask language understanding the
Great Dan Hendrick and team so basically
a bunch of language understanding
benchmarks yeah they basically went and
took final exams from like University
and early grad school courses from every
domain and compiled them into this
massive Benchmark there have been a
couple different efforts like this but
this is basically the gold standard on
which all the language models are
measured and we now have a like high 80s
to 90% accuracy rate across all fields
from like a single model namely gbd4 and
now Google claims that it's Gemini is is
hitting that level as well I would agree
that these have not been broadly
customized to The Last Mile
specifications that they need to like
work in the context of different firms
and you know cultural contexts and all
that sort of thing but it does seem like
the way I typically describe it is that
AIS are now better at routine tasks than
the average person and that they are
closing in on Expert performance on
routine tasks and that's measured by you
know these medical diagnosis benchmarks
these mlu type things it's etc etc so
let me remind you that in the 1960s
say AI researchers took chess as a
paradigm of if you can make a machine
that can do that well obviously you'll
have to have solved most of the major
problems in thinking because chess
involves most of the major problems in
thinking so when we can finally have
human level chess abilities we will have
human level AI that was the thinking in
the 60s and they could look at the rate
at which AI was getting better at chess
and forecast long before it happened
that in the late 1970s 1990s excuse me
is exactly when chess would reach human
level ability and that's when it did
happen and that was 25 years ago and
clearly they were just wrong about the
idea that you couldn't do chess without
solving all the major thinking problems
and we repeatedly have this sort of
phenomena
where people look at something they go
if you can do that surely you can do
most everything
and then we can do that and we can't do
near and we aren't near to doing most
everything so I just got to say this
Benchmark is just wrong it's not true
that if you can do this language
Benchmark you are near to doing most
everything you are not near yeah I would
refine my position to say I think you're
near to being able to do all the routine
things that are well documented in the
training data well yes but but the
question is in the economy all the
things we need doing how close are you
to that i' say you're not close I mean
we're seeing just the very beginning of
sort of I mean again I don't know like
what do you think was going on in their
head in the 1960s when they looked at
chess right they looked at chess and
they said it takes really smart people
to do chess look at all these
complicated things people are doing when
they do chess in order to achieve in
chess they said to themselves that's the
sort of thing we should work on because
if we can get a machine to that surely
we must be close to General artificial
intelligence if you could have something
that could do
chess and there is a sense that when you
have general intelligence you can use
all of that to do clever things about
Chess but it's not true that you need to
have all those General things in order
to be good at chess it turns out there's
a way to be good at chess without doing
all those other things and that's
repeatedly been the problem and that
could be the problem today turns out
there's a way to do these exam answering
things that doesn't require the full
range of artific general intelligence in
order to achieve that task it's hard to
pick a good range of tasks that
encompasses the full range of
intelligence because again you teach
through the test and you end up finding
a way to solve that problem without
achieving general
intelligence this does seem different
though I mean I I would I agree with
your characterization that basically it
turned out that there was an easier way
or a more direct way a narrower way to
solve chess and it's interesting that
it's like rather different you know it
involves these sort of superhuman tree
search capabilities but that wasn't just
true of trust there were another dozen
sorts of really hard problems that
people in the 1960s to took as exemplars
of you know things that would require
general intelligence and a great many of
them have been achieved but when I look
at the current situation I'm like this
does look a lot more like the human
intelligence and I would say that from
any number of of different directions
and that was true in every decade for
the last
century every decade has seen advances
that were not the sour that previous
systems could achieve it's clear that
you or at least I think it's clear that
you don't see the human brain the human
you know achieve level of achievement as
sort of a maximum right oh of course not
absolutely so it's it's like there's got
to be a finite number of breakthroughs
that need to happen we will eventually
get full human level AI I I have no
doubt about that and and it and not soon
after vastly exceeded that will happen
and it will will happen plausibly within
the next thousand years it also seems
like you would probably agree that it
need not be point forp point you know
the M scenario is a is a great one to to
play out and analyze but it need not be
the case right so the AIS could be much
better than humans in some ways and
still much worse than others that will
probably actually be true for a long
time that is it'll take a lot longer
till AAS are better that humans that
most everything than that they are
better at humans that say half of things
people do today but of course you have
to realize if you looked at what humans
were doing two centuries ago we're
already at the point where machines do
those things much better than humans can
do that is the T most tasks that humans
were doing two centuries ago are already
long since automated we've now switched
our attention to the sort of tasks that
people were not doing two centuries ago
and on those we're not so good at making
machines do them but we've already
dramatically achieved full aimation
basically of most things humans were
doing two centuries ago which for very
shorthand I would say is kind of
routine repetitive physical tasks right
I mean we managed to change the
environment to make them more routine
and repetitive so you know a subsistance
farmer uh on a subsistance farm two
centuries ago they were we couldn't our
automation could not do that job that
they were doing that we managed to make
the Farms different the factories
different Etc so that our machines could
do them and now they are producing much
more than those people produce but if
you had to try to produce the way they
were doing two centuries ago our Machin
today could not do that yeah a big
Theory I have also I I actually don't
think this is going to be a huge well
everything's going to be huge but I
don't think it's going to be like the
dominant change that that leads to
qualitatively different future but I do
think we will start to see and are
beginning to see that same process
happening with language models where you
know I consult with a few different
businesses and we have kind of processes
that you know we would like to auto you
know a classic one would be like initial
resume screening right we're not going
to have the language model at this point
make the hiring decisions but if we get
a lot of garbage résumés you know we can
we can definitely get language models to
kind of band The résumés into a you know
a one to five and like spend our time on
on the
fives it does seem to me that there's a
lot of kind of process and environment
adaptation that is not that hard to do
like I personally have done it
successfully across a handful of
different things
why it seems like your analysis though
sort of doesn't assumes that that's not
going to happen at scale this time
around with the technology we currently
have I said you know in the last in 20
years from 20 1999 to 2019 we moved
roughly a third of the standard
deviation in the distribution of
automation okay so what if we in the
next 60 years move a third of a standard
deviation in each of the 20e periods
then over 60 years we would basically
move an entire standard
deviation that could represent a large
increase in automation over the next 60
years and that would mean a lot of
things we're doing by hand today will be
done by machines then it would mean our
economy is more productive but it still
would mean humans have a huge place in
the world they get paid and most income
probably still goes to pay humans to do
work even though they have much better
automation at the time if that's the
situation in 60 years then
unfortunately that level of increase in
automation is just not sufficient to
prevent the economy from declining as
population
declines and so we won't get much more
automation than
that The Well of in automation will dry
up because Innovation will stop and we
would then have a several centuries long
period where we our technology does not
improve and in fact we lose a lot of
Technologies tied to scale economies as
the world economy shrinks
will manage to have less variety less
large scale production and
distribution and we would then struggle
to maintain previous Technologies and AI
is at risk of the sort of Technology be
hard to maintain because at the moment
AI is a really large scale concentrated
sort of technology is not being done my
mom and pops it's be done by very large
Enterprises on very large scales I would
agree that the the supply chain is
definitely prone to disruption uh in AI
no doubt about that can you describe in
in more detail what what is the standard
deviation in Automation and like how
should I conceptualize that uh I mean I
guess what you want to do is see a list
of tasks and how automated each task was
and then see sort of how much on that
score it had M up so basically if you
look on this list at the most and least
automated tasks you'll agree which or
which like the nearly most automated
task is airline pilots near nearly the
least automated task is carpet
installers uh carpet installers use
pretty much no automation to staple in
carpets and uh airline pilots are pretty
much always having automation help what
they're doing and then you know you can
see the scores in the middle and see
that we've you know moved up a modest
degree over those 20 years that would be
the way to get an intuition for it is
just to see a list of particular jobs in
their automation scores and then see
compare that to the amount by which
we've moved up how do you reconcile or
how should
I understand the idea that whatever
doubling time of the economy today I
think you said it was like 15 years in
the book which seemed a little fast to
me just based on like rule of 70 right I
think it's more like you know 20 or
something now but still like it seems it
seems like there's a little bit of a
disconnect between a notion of you know
over these next 60 years we would be
double double double you know
essentially 10 Xing the economy but we'd
only move at sort of a linear rate in
automation like we would only move a
third of a a standard deviation in each
period let me help you understand that
then people have often said look
computer technology is increasing
exponentially therefore we should expect
an exponential impact on the economy I.E
early on hardly any impact and then
suddenly an accelerating boom such that
we get this big explosion and then
everything happens but that's not what
we've seen so what we've seen over time
is relatively
steady effects on the economy of
automation even though the economy is
growing
exponentially the way I'd help you
understand that is imagine the
distribution of all tasks that you might
want to automated and that their the
degree of computing power both in
hardware and software required to
automate that tasks for each task is
distributed in a log normal way with a
very large variance that is there's this
very large range of how much computing
power it takes to automate a task as
computing power increases exponentially
you're basically moving through that log
normal distribution in a linear manner
and in the middle of the distribution
it's pretty steady effect you slowly
chop away at tasks as you are able to
automate them because you're slowly
acquiring sufficient Hardware to to do
that task uh that that gives you a
simple model but in Which comp power
grows exponentially and yet you see a
relatively steady erosion of tasks
through automation it's a low hanging
fruit argument yeah the low hanging
fruits are hanging really low that this
this is a log normal tree basically that
you're trying to grab things from I mean
you're you're growing your ladder is
growing exponentially into the tree and
every time your ladder gets taller you
get to pick more futs but it's a really
tall tree that means that you have a
long long way to go how do you think
about things like the progress in AI art
generation or like deep fakes over the
last couple of years this is an area
where I feel like if we rewound to two
years ago just two years ago really uh
when I was first starting to see AI art
popping up on Twitter and it was like
not very good for the most part you'd
see the occasional thing where you're
like oh that's really compelling and
then you'd see a lot of stuff that was
like yeah you know it's whatever it's
it's remarkable that you can do that
it's wild compared to what came before
but it you know it's like it's I'm not
gonna be watching like feature films
based on this technology in you know in
the immediate future I feel like we
could have had a very similar discussion
where you might say well you know yeah
it's progress but you know the the real
human art the top-notch stuff like
that's so far away and then early last
year my teammates at at weark made a
like short film using nothing but Dolly
3 or do 2 at that time imagery and some
definite elbow grease but like the
quality of production that they were
able to achieve with a half dozen people
and Dolly 2 is on the level that like
previously would have taken you know a
crew in Antarctica you know to go shoot
you know again there's is that work all
done no but if you look at the
mid-journey outputs today and you look
at some of the deep fake technologies
that are happening today it's like it
does feel like we've hit certainly photo
realistic thresholds you know almost
indistinguishable
from photography with mid journey and
with the Deep fakes not quite quite
there yet but like watch out for 2024 to
have a lot of stories of people being
scammed by the kind of custom textto
speech voice you know with a family M
family memb Voice or whatever all my
voice out there you know people are
gonna be calling my parents with my
voice so I guess what I'm trying to get
at there is like it seems like even just
in the last couple of years we have
these examples where we are seeing like
really rapid progress that is not
stopping before critical thresholds in
the
1960s there was a US presidential
commission to to address and study the
question of whether most jobs were about
to be automated it reached that level of
high level concern in the country and
major media discussion about
it ever since then we continue to have
periodic articles about dramatic
exciting progress in Ai and what that
might mean for the society and economy
and in all those articles through all
those years they don't just talk in the
abstract they usually pick out some
particular examples and they don't pick
out random examples from the economy
they pick out the examples where the
automation has made the most
difference that of course makes sense if
you're trying to make an exciting
story and so we've always been able to
pick out the things which are having the
most dramatic increase lately that also
seem the most Salient and interesting
and now you can pick out image
generation as one of the main examples
lately as something that's increased a
lot lately and I'm happy to admit it has
I would put it up you know and that's
the sort of thing that somebody writing
an article day about the exciting AI
progress would in fact mention and talk
about graphic artists being put out of
work by the availability of these things
which probably is happening the point is
just to realize how selective that
process is to pick out the most dramatic
impacts and to realize just how many
other jobs there are and how many other
tasks there are and then how far we
still have to go I'm happy to celebrate
recent progress and if I were you know
if I were a graphic artist person I
would be especially excited to figure
out how to take advantage of these
changes uh because they are among the
you know biggest CH if you're say a
20-year-old in the world it makes
complete sense to say where are things
most exciting and changing I want to go
there and be part of the new exciting
thing happen happening there if of
course you're a 60-year-old and you've
already invested in a career then it
makes less chance sense to like try to
switch your whole career over to a new
thing but a lot of people are at the
beginning of their career and they
should they should look for where the
most exciting changes are and try to see
if they can go be part of that move west
young man if West is where things are
happening right but you still have to
keep in mind if there's a few people
going out west making exciting things
happening how big a percentage of the
world is the West right yes it's
exciting and there's huge growth in the
west you know there
10 years ago there was hardly anything
and now there's a big town look how
great the West is growing and that you
know there are always times and places
where right there things are growing
very fast and newspaper writers should
focus on those to tell stories and
people novelists should focus on those
to sell stories they're exciting places
where exciting things are happening and
I and I want to make sure the world
keeps having things like that happening
because that's how we can keep growing
but you have to be honest about the
fraction of the world that's involved in
those exciting Frontier stories
yeah I mean I guess my kind of
CounterPoint to that would be the
same relatively Simple Technology like
the transformer or like the attention
mechanism Perhaps it is better you know
pinpointed as is driving this art
creation it's also writing today like
short programs yeah I would personally
say my productivity as a programmer has
been increased like several fold not
like incrementally but like multiple
with gp4 assistant you know it's the
wide range right you could go on but
like it's it's also happening in metal
medical diagnosis it's also happening in
like protein you know novel protein
structure generation and certainly from
an economic point of view the biggest
category you've mentioned is programming
that's a much larger industry less
larger profession than the other ones
you mentioned well watch out for biotech
also I would say for sure but biotech on
has been shrinking for a while so that's
not an ex thing you should point to as a
growing thing I will predict growth for
biotech definitely I mean you know it's
also it's reading brain states have you
seen these recent things where people
can read the brain State among the
things you're talking about at the
moment the biggest profession being
affected is programming clearly I have a
younger son two sons my younger one is a
professional programmer so you know I've
had him look at and his workplace has
looked into what they can do with large
language models to help them write
programs and their evaluation so far is
you know they don't even they'll wait in
six months to look again it's not useful
now can what what uh can I short that
stock uh well I could tell you after we
we finish what what that is but
basically I think this is true most
actual professional programmers are not
using large language models that much in
the you know doing their job now uh I
got to say that if some people are
getting factors of two productivity
increase that eventually we should see
some effect of that on their
wages that is of course you know now if
lots of programmers go out and use
productivity spaces in some sense we're
going to increase the supply of
programming and so supply and demand
would mean that maybe increasing the
supply lowers the price even if it
dramatically increases the
quantity but you know there's such a
large elastic demand for programming in
the world that I actually think that
effect would be relatively weak and so
you should be expecting large increase
es in the wages going to programmers if
you are expecting large overall
increases in the productivity of
programmers because again it's a large
elastic demand for programming in the
world you know long for a long time a
lot of change in the world has been
driven by programming and limited by the
fact that there only so many decent
programmers out there only so many
people you can get to do programming so
clearly if we can dramatically expand
the supply of programmers we can do a
lot more programming in a lot more areas
and there's a lot of money that's
willing to go to that to do that there's
a lot of people who would be hiring more
programmers if only they were
cheaper and they're about to get cheaper
in effect and so you should be
predicting large increases in basically
the wages and number of programmers in
the world we haven't seen that yet I do
predict large increases in number I'm
not so sure about wages it feels like
why not well I I've done a couple
episodes with a Folks at a company
called rep which is a very interesting
end to end at this point software
development platform their mission is to
onboard the next one billion
developers and you know they're they
have like a great mobile app they have
kids in India that are you know 14 years
old that are doing it all on their
mobile app and I'd say it's much harder
and maybe this reflects the kind of
programming that your son is doing but
say it's much harder to take the most
elite Frontier work and accelerate that
in a meaningful way versus like
commoditizing the routine application
development that like the you know the
sort of long taale of of programmers
mostly do my son is definitely doing
routine application development uh not
at the frontier programming at all U but
again I'm I'm saying I don't expect this
sudden large increase in programmer
wages in quantity especially wages I
mean the less the quantity increases the
more wages would have to be increasing
to compensate and I think it'll be hard
to get that many more people willing to
be programmers but it' be you could pay
them
more um and I I don't predict this so
this is a concrete thing we could you
know even bet on over the next five or
10 years will there be a big boost in
programmer
wages uh that would be the consequence
it's a very simple supply and demand
analysis here this isn't some subtle you
know rocket science version of economics
well typically when Supply increases
price drops right I'm expecting lots
more programmers and them to be broadly
cheap depends on the elasticity of
demand so you know if you think about
something that there's just a very
limited demand for in the world you know
if if piano tuning got a lot cheaper you
wouldn't have a lot more pianos because
piano tuning is not one of the major
costs of having a piano you know it's
the cost of the piano itself plus the
space for it in your living room right
and the time it takes to play on the
piano so piano tuning is is a really uh
small cost of pianning so that means the
elasticity of demand for piano tuners by
itself is pretty low you know there's
just basically how many so many pianos
they all need to be tuned and if each
piano tuner could tune each piano twice
as fast say and we basically only need
half as many piano tuners because
there's just not much of elasticity for
demand so for kinds of jobs like
that productivity increases will cause a
reduction in the
employment but even in that case you
might get a doubling of the wages and
half the number of piano tuners because
they can each be twice as productive but
for programming it's clear to me that
programming has an enormous elastic
demand the world out there has far fewer
programmers than they want they would
love all over the place to hire more
programmers to do more things there's a
big demand in the world for software to
do stuff and there's a huge potential
range of things the software could be
doing and it's not doing now so that
means the there's a pretty plastic
demand for programming that means as we
increase the quantity of programming the
price doesn't count come down that
much there's still people willing to buy
this stuff so that tells me that as
productivity
increases uh basically the supply is
expanding and the demand's not coming
down much so we should just see a much
larger quantity but then you know
basically because each person is being
more productive each person should get
paid more so you mean the elasticity
Supply is going to be a combination of
two things each person getting more
productive and more people being willing
to join that profession and I think
we've already seen that uh even as the
wages for programming has gone way up in
the last decade or so the number of
programmers hasn't gone up as fast that
is there's just kind of a limited number
of people who are decent at
programming and it's hard to get the
marginal person to be a programmer uh
but the people who are programmers when
they're productive they get paid a lot I
mean as you've probably heard hu rumors
about AI programmers and how much
they're being paid lately it's crazy
high because there's just a limited
Supply so I got to say I expect large
increases in wages for programmers if in
fact large language models are making
programmers much more
productive but according to my son at
least and others I've heard you know
that's not happening I'm with you up
until the very last two points I would
say I think it is happening and I would
also say I think my estimation of the
Rel relevant elasticities is that there
will be a large growth in people who can
be and will choose to be programmers but
that the wages don't go up they they
don't fall like dramatically necessarily
either because it has to be like an
attractive thing for people to want to
do it but I think that the prevailing
wages are quite High compared to what a
lot of people would be excited to take
if they could easily Break in with
language model assistance which I I
think they will increasingly be able to
do let me change gears a little bit so
we've debated this has been really uh I
I always appreciate a useful uh and
thoughtful challenge to my world model
um you're you're definitely supplying
that let's do a couple like a little bit
more speculative things that could be
kind of M first you know a little bit of
llm as I was going through the book
there are a number of things that I was
like hm this is really interesting how
would I think about this a bit
differently and you know and maybe
suspend a little bit of your um
skepticism of how much impact llms will
make let's let's go in a world where you
know scaling continues to work context
lengths get long you know we start to
see not not total you know displacement
of humans but like substantial fraction
of you know tasks being like llm
automatable one interesting inference
that you make is that there won't be
that many different base Ms that
essentially there will be super
selective em ifying of really Elite
really capable people that those will
become the bases that they'll be sort of
essentially turned into kind of Clans
where they'll they'll highly identify
with each other and they'll have like
you know marginally different
specialization but that there will be
these sort of
recognizable almost canonical
personalities that are and not that many
of them that kind of come to dominate
the economy it seems like we're kind of
seeing something similar with language
models already where it's like we have
gp4 we have you know some the new thing
from Google we have Claude we have like
a couple open source ones and then they
get like a lot of like local fine-tuning
and and kind of adaptation I guess my
read on that was that it's an odd you
know it's initially a very surprising
vision of the future but it does seem
like we see the Proto version of that in
the development of large language models
any thoughts it's basically how many
different kinds of jobs are there is the
question doob tasks are there and then
so how many dimensions do they vary so I
mean there's clearly a lot of different
kinds of jobs like I told you the study
we did looked at you know 900 of them
but once you look at 900 different jobs
a lot of jobs are pretty similar to each
other and they take pretty similar
mental Styles and and personalities to
do those jobs so when we're looking at
humans at least it looks like a few
hundred humans would be enough to do
pretty much all the jobs that's looking
at the variation of humans now the
harder part is to say well large
language
models is their space of dimensional
variation similar to humans or is it
very different that that's much harder
to judge but yeah I would guess that
it's in this way not that different that
is even in large models there's a
difference between you first you train a
basic model and that's a lot of work and
then you train variations on it and it
does look like the variations are mostly
enough to Encompass a pretty wide range
of
tasks and so you need a small number of
Base approaches and then a lot more
cheaper variations that are enough to do
particular things uh certainly that's
you know a remarkable fact in some sense
about large Z models is the range of
different tasks they can do
starting with the same system right and
so they have a degree of generality that
way and you know humans in some sense
have a degree of generality that way
where we are able to do able to learn to
do a pretty wide range of things so yeah
I would and I don't know if it's going
to be just four as opposed to 40 or 400
that's harder to say but in some sense
it could be one or two I
mean even in the age of M I was giving
the few hundred as an upper limit it
could turn out to be much lower it
really depends on how much sort of you
know quick fast last minute variation
can actually Encompass the range of
differences if differences are somewhat
shallow and and surface which not really
fundamental then yeah last minute
variation might be enough another
interesting assumption this one I think
is more of a contrast with the the
language models is and we talked about
this briefly earlier that the M's they
can be easily cloned but they can't be
easily merged in other words like you
know because we don't have a great sense
of how exactly it works inside and and
what internal states are meaningful we
can't just like superimpose them on top
of one another language models it seems
like we are making actually a lot more
progress on that front it's not a solved
problem but there are techniques for
merging there are techniques for like
training separately and combining there
are these sort of many curas uh
techniques people are exploring those
but like notice that to make gp4 you
didn't start with gpt3 and add more
training you started with a blank
Network and you started from scratch and
that's consistently what we've seen in
AI over decades every new model does not
start with an old model and train it to
be better you start with a blank
representation and you train it from
scratch and that's consistently how
we've made new systems over time so
that's a substantial degree of not being
able to
merge and that's quite different than
humans I mean I mean often to get a
human to do a new task you want to take
a human who can do lots of previous
tasks because they can more quickly
learn how to do this new
task and that's just not what we're
seeing like you try to take I don't know
Claude and GPT 4 and and you know Gro
and merge them I mean I just don't think
anybody knows how to do such a merge
today there's no sensible way you could
do such a
merge you could take claw and then do
all the training that you would have
done on gp4 except do it starting from
Claude And I think people think that
would be worse than starting with the
blank representation as they usually do
yeah I think that's definitely not a
solved problem today and I wouldn't uh
claim that you can just like Drop Claude
and gbd4 on top of each other but there
are enough early results in this that it
seems much more plausible plus we have
like the full wiring diagram you know
and the ability to kind of X-ray
internal states with you know perfect
Fidelity it seems like there is a much
more likely path
forget about the plausibility for a
second what do you think it would mean
if the AIS could be kind of Divergent
but also REM
mergeable I think the fundamental issue
here is rot so we see rot in software
especially with large Legacy systems we
see rot in the human brain and I think
we have to expect rot is happening in
large language models too rot is the
reason why you don't start with old
things and modify them you start from
scratch that is basically when you have
a large old Legacy piece of software you
could keep trying to modify it to
improve it but typically at some point
you just throw it all away and start
from scratch again people get a lot of
Advantage about being able to start from
scratch and that's because old large
things rot and my best guess is that
that will continue to be true for large
language models and all the kinds of AIS
we develop we will continue to struggle
with rot as a general problem
indefinitely and this is actually a
reason why you should doubt the image of
the one super AI that lasts forever
because the one super AI that lasts
forever will
rot and in some sense to to maintain
functionality and flexibility would have
to replace itself with new fresh
versions periodically which then could
be substantially different and you know
that's in some sense how biologies work
too biology could have somehow made
organisms that lasted forever but it
didn't it made organisms that rot over
time and get replaced by babies that
start out fresh and rot again
and that's just been the nature of how
biology figures and that's how our
economy works we could have had the same
companies as we did a century ago
running the economy just changing and
adapting to new circumstances but we
don't old companies rot and could die
away and get replaced by new companies
and I predict in the age of M that M's
would in fact rot with time and
therefore no longer be productive and
have to be retire and be replaced by
Young M uh and that's a key part of the
age of mnar that I think would
generalize to the AI world I think in
fact rot is such a severe and
irredeemable problem that AIS will have
to deal with rot in roughly the same way
everybody else has I.E make systems let
them grow become capable slowly rot and
get replaced by new systems and then the
challenge will always be how can the new
systems learn from the old
ones how can the old ones teach the new
ones what they've learned without
passing on the rot and that's a longtime
design problem that we're going to face
in large language models even I I think
you know in a few years a company will
have had a large language model they've
been building up for a while to train
you know to talk to customers or
something and then it'll be rotting and
they'll Wonder well how can we make a
new one that inherits all the things
we've taught this old one and they'll
struggle with that uh they can't just
move the system over they'll have to
have maybe the same training sets or
something they have to collect training
sets they're going to apply to the new
system like the old one but that will
continue to be a problem
in AI as it has been in all complicated
system so far yeah interesting I think
that is a pretty compelling
argument for like medium and long time
scales and I can even see that you know
already like open AI supports for
example fine-tuning on a previously
fine-tuned model and I don't in practice
use it I'm not sure how many do what I
do think is still a plausibly very
interesting kind of fork and merge is
you know like with these new state space
models it seems that you could like one
remarkably difficult challenge for a
language model is scan through my email
and find what's relevant you know it's
like it has a hard time doing that
for a couple different reasons you know
finite context window and I just have a
lot of email with the states based
models I do think you could clone you
know or parallelize have them each kind
of process a certain amount and
literally then just potentially merge
their states back together to understand
you know in kind of a superposition sort
of view what are all the things that are
relevant even though they were processed
in parallel and so I do think that that
kind of quick forking and merging could
be a really interesting capability but
at some level of Divergence it does seem
like it probably just becomes unfeasible
or not even desirable I mean so a very
basic interesting question about brain
design is the scope for parallelism so
you know in your brain there's a lot of
parallelism going on but then when you
do high level tasks you typically do
those
sequentially and so there's just an open
question in AI surely you can do some
things in parallel at some small time of
a time scale but how long of a time
scale can you do things in parallel
before it becomes hard to merge things
okay another different topic so in the
age of M the Assumption seems to be from
the beginning
that because these things are in some
sense one for one with humans that they
should get or people will naturally be
inclined to give them a sort of moral
worth status I think it's more the other
way
around they they would insist on it just
like you would insist that people around
you dealing with you give you some
substantial moral weight if the a M's
are just actually running the society
they will similarly insist on that and
then humans who want to deal with them
will kind of have to go
along you know if unless they the M are
enslaved by humans then if the M are
free to work with the humans or not and
you know it's just like in general
having a modest degree of respect for
your co-workers is kind of a minimum for
being a cooworker if your co-workers
perceive that you disrespect them enough
then they just won't want you around and
you'll have to go somewhere else uh so
if humans are going to interact and work
with M they'll have to on the surface at
least when they're not in private treat
them with modest respect well for the
record I always treat my language models
with respect as well um I'm very polite
to them I never uh engage in the
emotional manipulation techniques that
some have shown to perhaps be effective
but doesn't feel quite right to me um
and not because I think they're moral
patients but it's more about just the
habits I want to get into but I'm still
a little confused by this on a couple
ways one is first of all just by default
it seems like they will be enslaved to
humans like the first M that get created
they get loaded onto a machine they're
in some State I can turn them on I can
turn them off they can't decide when
they get turned on and turned off right
if I boot them up in a eager ready to
work sort of state and they're like
ready to do a task they're probably not
even gonna you know and they've got
these like virtual inputs they're
probably not even going to be in the
mindset right to think like I demand
respect they're just going to be in that
mindset that they were kind of stored in
of like ready to work so why I'm still a
little confused as to where that comes
from and then the flip side of that
question would be under what
circumstances if any do you think we
would start to treat our language model
or successor systems as you know moral
patients you know even if they're
they're not onetoone with us but like
are there things that they might start
to do or be you know what ways they
might start to behave where you think we
would feel like that's the right thing
to do we have substantial understanding
of slave in human history and where it
works and where it doesn't and why first
of all we know that um when land was
plentiful and people were scarce then
people would have high wages and then it
might be worth owning somebody but in
the vice versa case where people were
plentiful land was scarce then there
really wasn't much point in having
slaves because free workers would cost
about the same and uh why bother with
enslaving so um
so situations where slavery made some
sense is where wages were high but then
um depending on the kind of task there's
some kinds of tasks where slavery can
help and others where it doesn't so much
so say in the US South you know out in
the field of picking cotton or something
if you just need people to push through
their pain then slavery can force them
to do that and be make them be more
productive but if they need to do
complicated things like being a house
slave or a city sort of slave at a shop
those
sorts of slaves tended to not be abused
and to be treated like a worker would
because they just had so many ways to
screw you if they were
mad uh that their jobs were complicated
and you were trusting them to do a lot
of things and so as a practical matter
you had to treat those sorts of slaves
well work has become far more
complicated since then and employers
have become far more vulnerable to
employee
sabotage uh you know there's not that
much that a cotton pick can do to
sabotage the the cotton if they're mad
at you uh you can just whip them and
make them pick the cotton faster but
again house slaves uh shop slaves City
slaves you know they just have a lot
more discretion and you need to get sort
of get them to buy in and so again it's
in the age of M is a world where wages
are near subsistence levels so you know
the amount of work you can get out of a
slave is about the same as you can get
out of a free worker because they're
both working for subsistence wages if
the free workers more motivated they
enjoy themselves more and they feel more
owning themselves and they and that
gives them a sense of Pride and devotion
and they're less willing to sabotage
your workplace that would be a reason to
not have them be slaves uh and and I
think large language models certainly
they have been trained on data about
human behavior wherein humans are
resentful of being treated as slaves and
want to be respected and needed feel
motivated and to you know need to feel
respected to be motivated and are less
likely to sabotage if they feel like
they have some
freedom and all of those things would
continue to be true of large language
models to the extent that they were
trained on
human conversation and and behavior and
that's how humans are so uh in this vast
space of possible AIS there could be AIS
that don't mind at all being enslaved
but lar language models aren't going to
be those but it does seem like you sort
of expect that natural selection or sort
of you know human guided selection of
these systems will Trend that direction
like the idea that M or language models
will sort of demand Leisure seems to be
at odds with the other part of the
vision that they will like become okay
with being sort of turned on turned off
so the need for leisure does seem to be
more just a constraint on the human mind
that is people are just more productive
when they get breaks that seems to be a
very robust feature of human work across
a wide range of context even including
literal
slaves they need you know a 5 minute
break every hour they need a lunch break
they need an evening break they need a
weekend this is just what human minds
are like they are more productive when
they get periodic breaks so maybe the
breaks aren't Leisure exactly maybe they
don't write a novel in their spare time
but they do need what they see as a
break well I know we're just bad out of
time maybe my last question is are are
there things that you are looking for or
are there things that you could
imagine happening in the not too distant
future where you would change your
expectations for the future again and
begin to feel like maybe we are entering
into a transition period that will lead
to a qualitatively different future like
going a different direction from this
sort of Technology stagnation the trends
that I would be tracking are which jobs
tasks actually get automated how much is
paid for those so if I saw saw you know
big chunks of the economy where all of a
sudden workers are doing you know a lot
more automation is doing tasks instead
of with workers and that changing the
number of workers and the wages they get
and the number of firms supplying that
and go up then yeah that I start to see
a lot of things happening that that's
the thing I'm looking for and that's the
thing that people haven't seen so much
in the past they tend to focus on demos
or maybe the high-tech companies that
get a lot of reputation out of doing
AI uh and not so much the rest of the
economy and who's actually getting paid
to do stuff you know I mean you know if
you think about say the farming
revolution where tractors went out and
replaced Farmers that was really large
and really visible and really clear if
you look at say trucks replacing horses
you saw a very large very substantial
replacement with enormous differences in
who supplied them and who got paid we
have seen large changes in Automation in
the past we don't have to scrape to sort
of see subtleties and such things are
often just quite out in the open and
visible and very obvious so that's what
I'm waiting for those big obvious sorts
of displacements and even having you
know trucks replace horses and tractors
replacing Farmers didn't make AI take
over everything even if I saw big
changes I wouldn't necessarily predict
we're about to see AI take over
everything but I would at least know
what I'm looking at and that's the sort
of thing to try to project forward and
try to think about where that's going to
go this has been an conversation I've
been a fan of your work for a long time
and it's been an honor to have you on
the cognitive Revolution Robin Hansen
thank you for being part of the
cognitive Revolution thanks for having
me it is both energizing and
enlightening to hear why people listen
and learn what they value about the show
so please don't hesitate to reach out
via email at TCR turpentine doco or you
can DM me on the social media platform
of your choice omnik uses generative AI
to enable you to launch hundreds of
thousands of ad iterations that actually
work customized across all platforms
with a click of a button I believe in
omnik so much that I invested in it and
I recommend you use it too use Cog rev
to get a 10%
discount
reol
