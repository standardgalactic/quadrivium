hi there my name is paul niujukin i'm an
assistant professor of bioengineering
neurosurgery and electrical engineering
at stanford university
i direct the brain interfacing
laboratory which is a research group at
stanford
i have an md and a phd in bioengineering
which means
i'm a doctor an engineer and a scientist
for the last 15 years or so i have been
a brain computer interface researcher
spanning both non-human primary work as
well as clinical trials and people
and i'm here to give you an expert
opinion on the recent neurolink mind
pong video
because to me it represents some pretty
exciting steps forward in the field
now before i get into that i need to go
over a couple quick disclosures
this is just my own opinion on speaking
for the university and two
i'm not affiliated with neuralink in any
way there's no i've never been paid or
consult or
received any resources from them uh they
didn't ask me to do this
um no one is no one is is twisting my
arm to do anything like this
uh the the field of neuroengineering is
relatively small
so i do know a lot of the people that
work there uh or advise they're in
various capacities or have worked there
and it's important for me to just maybe
make a couple of notes um
my phd advisor and postdoc advisor
krishna shannoy
is a an advisor for neural link and has
been since day one
and my other post-doc advisor jamie
henderson
both of these individuals are faculty at
stanford
what has for the last couple of years
been an advisor for neurolink as well
so those are two sort of potential
disclosures i should just put out there
but understand that i'm not privy to any
information that's that's you know be
it that i have any insider information
or anything special because of the
relationships
of being in the field i only know
what what is out there publicly
neuralink is a very private company
and is remained that way um but i have
an expert
sort of exp i have an expert opinion in
this space because i'm in this field
i've been following early very closely
since it started because it's
directly working in my space and i can
share
a lot more about what's in this video
because they put a lot of stuff in here
that would not be obvious
to to to someone not in this field and
i'm here to sort of
share more of what i see and why i think
it's exciting
so with that out of the way let's begin
the video
and um and go through it
this is pager he's a nine-year-old
who had a neurolink placed in each side
of his brain about six weeks ago
if you look carefully you can see that
the fur on his head
hasn't quite fully grown back yet
okay so right out of the gate there's
already a lot being communicated here
um you're seeing is a rhesus macaque
monkey which is a very common animal
model in the field it's the same monkey
that i work with
in our research group for our animal
studies
it's got 100 plus years of history that
has contributed to systems neuroscience
and much of what we know about the brain
is because of the rhesus macaque
what you're seeing is pager this is the
monkey that that is in the video is
interacting with this task while sitting
on seated on
this you know really nice you know
comfortable looking
uh or appropriate for a monkey at least
comfortable looking um
wooden wooden looking branch uh sort of
perch
um this is this is flexing neural this
is nearly flexing their highly enriched
environment here
the monkey is you know fully fully
unconstrained just sort of climbs up
and starts participating voluntarily
while they're in this
you know really pretty uh enclosure
that's plastic and i'll show you more
about the plastic enclosure in a moment
with the background that's got you know
this faux woodland
forest scene so as far as as far as
their environment
enrichment environment for the monkey
it's it's a highly enriched space that's
that's um that's very conducive to uh
to um happy happy uh a happy
uh happy animal sort of interaction the
the little piece they were talking about
about the shared the shaved piece of
head that's that little bald patch
you're seeing on the top of the head
um and that's because when they did
surgery they shaved off the all the
thick fur so they could get access to
the
to the scalp um and then implant do the
implantation now
one of the things that's very
interesting about this is that had you
not told me
that that that that was that that was
shaven for the purposes of an implant
i would have never been able to tell uh
the vast majority of this type of work
is using wired implants that have
external connectors so there's hardware
that's visible from the outside
and here you're seeing for the first
time you know
high channel count implants that are
fully implantable that are basically
invisible so once this hair grows back i
wouldn't even be able to tell you that
the animal had a surgery and that's sort
of
an important consideration from a
cosmetic perspective if this is ever to
to if these devices are available to
make it to be white you know to be
accepted um by by people for
for uh for therapeutic use
let's keep going it learned to interact
with a computer
for a tasty banana smoothie delivered
through a straw
we can interact with the neural links
simply by pairing them to an iphone
just as you might pay your phone to a
bluetooth speaker
so here they are flexing again all right
this is yet another knurling flex
um they've got they're showing off that
the inner the actual interface from
their neural link device um from the end
from the n1
is actually a bluetooth interface so you
know
there's an iphone paired with the
parabolas neural link that's
picking up debugging information it's
it's a it's a really nice demonstration
of you know using industry standard
protocols
to build you know proper engineering
infrastructure on top of this type of an
interface
this view is actually also really nice
because you can see a bit more about
the about the about their enclosure
right here is the corner that's a corner
gusset
here's another corner of the wall um
that's made up and so
you can actually see the reflection of
the of the person who's holding the
phone
their hand is like right their hand
reflection's right there so that's the
there's another
piece of plastic right in front here
that's uh that's
you know separating the person from the
animal so that the animal can you know
safely uh interact with the task without
any concern
it's a it's a really nice setup that
they that they that they've created
the links record from more than two
thousand electrodes
implied in the regions of page's motor
cortex that coordinate hand
and arm movements so here they are again
you know flexing once more um that's a
2048
uh electrode implant that's 1024 on one
side 1024 to the other side bilateral
each of the links gives you 1024
channels that's an order of magnitude
higher
than what we what is currently
clinically approved
uh for for this type of work which is
the utah electrode array which only
gives you 100 channels
that that device that that electrode
implant uh that electrode array
is 20 years old and so this is the this
is uh you know a promising new point of
technology
that that we hope um will give us an
order of magnitude more
more channels than what we currently
have i'll also point out that while
we're looking at this view of the task
this is this task is something that's
actually very very dear to me because i
actually
created this task uh when i was a
graduate student it's a grid task it's a
six by six
grid and this is this implementation
they're doing here so there's 36 total
options the monkey has to pick one
uh to communicate the to communicate the
signal of interest if you choose the
wrong one it gets it wrong
and because you've tiled up the
workspace this way you've turned the
system now into a communication channel
and that's what this little marker here
is talking about this is a bit per
second
text this is the maximum bit rate that's
the that's the
current running count bit rate and so
there you're seeing the
actualized maximum and current
throughput
information transfer right actual bit
rate or achieve bit rate of the system
through through the interface and this
is really exciting because this is
actually what we did in our in our
studies as well
if this is of interest here's some
papers that talk about bitrate and the
one in which we introduced this metric
is this one here
task optimization the 2015 paper and
then in 2017 we we add a click decoder
using hmm to make it even faster
so you know here's some of the papers in
the field that
talk about bitrate and i'll come back to
this again this isn't fully exhausted
but just some of the ones that highlight
these ideas
let's keep going neurons in this region
modulate their activity with intended
hand movement
for example some might become more
active when he moves his hand
up and others when he moves it to the
right
so that's not anything surprising for
the field we've known this for decades
but what is very interesting is in the
blog piece they actually
show us a plot of that tuning profile of
all
thousand 24 channels presumably in pager
but actually i'm not sure they actually
specify which one this
is very impressive because because what
we have
is the larger the sphere the stronger
the depth of modulation the smaller the
sphere the less important that
that electrode is contributing to to the
to the tuning and each this each of
these pillars
represents you know 16 of the contacts
on that on that wire that's implanted
and if you play this video all the way
out to the end they actually then go and
co-register it
over the piece of brain that is that
it's being implanted in
um in in presumably page's brain and so
this view is actually really pretty
which shows to us it's another flex
right that shows us that they know where
every single electrode they're putting
in
is relative to the surface of the brain
now
this may not mean mean this may not be
very informative for you but again four
neuroscientists in the field you know
exactly where this is i know exactly
what this is because
this right here is an anatomical
landmark that's unmistakable it's the
central sulcus
and anterior to that is premotor as is
motor cortex
and then pre-motor cortex would be
further anterior to that this could be
right the spur of the arcuate somewhere
in this area it's really hard to tell
whether it's this or that but i'm not
going to venture too much well they're
clearly in
i need i wouldn't know a larger a larger
view to see for sure but what they're
clearly
get in is motor cortex and they're
getting lots of modulation here
and not so much modulation here um
and you know we've never i've never seen
you know a modulation plot with this
much density before because we
don't have 1024 channels ever recorded
from
um in in the system so this this
actually has significant neuroscientific
value
just as it is
let's go back by recording from many
neurons
and feeding their activity into a
decoder algorithm
we are able to predict page's intended
hand movements
in real time first
we calibrate decoder by recording neural
activity as pager uses the joystick to
move a cursor to targets presented on
the screen
so that's nothing you know there's
nothing surprising this is just
explaining how you build a decoder it's
all
it's all standard in the field as he's
playing this game we are wirelessly
streaming
in real time the firing rates from
thousands of neurons
to a computer so
here we get a first little glimpse of of
uh the console and i'll just point out
one something real quick before i let it
let it continue because this view is
really nice or has something that i
can't see in a later in a later segment
is that it's friday 11 41 a.m when this
ex when this
when this uh when you know when pager is
playing so this is
that you know that when exactly in time
this is happening which is which is
pretty cool
using these data we calibrate the
decoder
okay i've stopped it again because i
actually want to talk about the the
various items that we're seeing up here
on this top row
uh this the the panel here is very
informative and shares a lot of
information
um the
the item over here oops the item over
here is a mac address and more of it was
visible earlier which is the actual mac
address of the radio
this is the firmware revision number
this is which of the chips of the 256
channel chips that are doing that
implantation
uh that so each chip is 256 channels
each of the
each chip has 16 wires and each wire has
16 electrodes
so each chip is 256 and there's four
chips 1024 that's where they get 1024
per neural link device that's the signal
strength the rssi signal strength just
like your wire your wi-fi signal
strength
of how well that the bluetooth signal is
coming through this
and this represent the coil voltage
and the charging rate in milli in
microamps
of the inductive coil that they can
recharge the battery with and obviously
it's sitting at negative voltages and
negative
microamps because it's not charging
right now it's nothing connected it's
just fully it's fully wireless
um it's it's not there's no there's no
inductive there's no coil-based charging
thing applied right now
the the monkey doesn't have anything on
the head and this and this represent the
battery state
so this is 3.6 3.7
volts which to me signifies that it's
just you know it's probably a
lithium ion battery and this here is the
drain state which means
that's the amount of microamps or
milliamps of current that are being that
are being consumed right now it's 17
if you do the math on this you get to
something that i believe is around 64
milliwatts of power this is also
milliamps which given the fact that
they're doing bin
streaming spike data is not bad at all
that's a super low power device
um especially since we're talking about
1024 channels
to do that in 64 milliwatts is is
dang impressive it's a nice it's a nice
piece of equipment
uh here we see some humidity temp
pressure and temperature debugging
information
that's you know very nice to see that's
funny to see um it's just
impressive that that you know that they
built that in hibernation auto wake this
is you know presumably sleep states
about the system
drops i'm guessing that drop has
something to do with like
the the amount of network packets coming
off the bluetooth
chip that are being dropped is is my
guess what that is i don't know what
interval means it's not that's not
that's pretty vague streaming is just as
it says that the system is streaming
it's two little nods here that are that
are interesting for neuroscience so this
is a raster
plot right as you go down this way
you're walking down the channels
each one is a different electrode and
this is time
presumably in those 25 millisecond bin
time so the brighter ones are larger
higher activity and the the dimmer ones
are lower activity
there's two aspects here that are worth
pointing out that are that are
interesting to neuroscientists there's a
little knob here that shows
that you can tweak between normalized
versus non-normalized and
that just means that you know they're
they're scaling each of the channels
uh with respect to some normalized
parameters so that no single channel
that's super loud drowns out all the
others it's it's it's a you know
something that's conventionally done in
our field and this this is really
interesting where
um this says you know choose the channel
of interest and press the enter key to
hear spikes and that's just
another little nod to what we do in
neurophysiology because that means you
can pick a channel and actually listen
to the spikes pop
pop pop as it comes through and that's
just you know how we how we
often um listen to our data as we're
as we're capturing it there's a lot of
information down here as well
in the lower sections that that are that
are that are you know
really really sort of interesting to see
this little this little blurb i think is
probably aggregate activity and so you
can sort of see that this
this patch of area is much brighter than
the rest i think with that that's what
is the significant it could be one
channel but
it's not exactly well well explained
these are buttons to toggle
different types of recording modes in so
switching on you know broadband for four
channels versus
20 channels and whatnot and this
indicates here that they're able to
record
channels of broadband activity off of
the system as well as conduct impedance
measurements
and bin spike measurements and that's
the button right here that says
impedance which is cut off a little bit
importantly right there tells you the
date of the experiment of this study
right
um this happened on april 2 2021. this
is just over you know
just just a week ago and there they put
it out there less than a week or two
later because this was 402 and
when the video was published on the 9th
or on the 8th i believe
um so you know within a week they they
released they released this video which
shows them sort of how recent this all
is
uh this little log actually is extremely
informative because it tells us the
nature
of how the broadband channels are coming
out the fact that these are spaced out
every 10 seconds
and there's here that says 10 seconds of
broadband indicates to me
that the system is capable of streaming
one channel of broadband
at a time and not more which makes sense
because they're using bluetooth probably
bluetooth 2.1 because it's really low
power which has got about a you know
upper bandwidth limit of around 2
megabits a second and that you don't
really want to you don't really want to
stress the system
uh and consume a lot of power they could
maybe go to bluetooth 3.0 but i doubt
they've implemented that way even though
it's got 24 megabits a second of
transmission
it burns a lot more power so here you're
seeing that the system is every 10
seconds
switching between channels uh and that's
for that that
that actually matches up exactly with
these right 433 468 617
and it's 433 468 617 here as well so
that all makes sense this is actually
really flexing what they can do
impedance measurements broadband bin
spikes here are different
modalities of what you can measure and
stop streaming here's a little like
you know zmq data stream which is you
know a network protocol that's used
for for um you know common modality to
to encapsulate an abstract network
streams is zero mq is a
is a high level library for socket
programming or unix socket programming
or other types of things
but that's what they're using here it
even tells you what port they're they're
broadcasting on so you know
pager's pagers uh stream off of that mac
address is is sitting at
port 5556. i just don't know what ip
address it is that's the one thing that
i that i don't see
um i'm guessing this is udp and not a
tcp stream because if it was
tcp i would expect this drop number to
be at zero because tcp is a handshaking
protocol so they're probably
implementing
a udp zmq stream over these 5556 port
this last one presumably is this implant
settings
toggle which lets you turn the chips on
and off or turn one or more of them on
and off at any given time so if you want
to scale it down and save power
and only use half the half the chips and
half the channels
because you want to turn off a
particular chip altogether i presume you
can do that with this console
there's a lot that's being shown here
that is is you know
really interesting to see and hasn't
been disclosed before
uh the the system is pretty
sophisticated it really is
mathematically modeling the relationship
between patterns of neural activity
the different joystick movements they
produce
after only a few minutes of calibration
we can use the output from the decoder
to move the cursor
instead of the joystick pages still
moves the joystick out of habit
but as you can see it's unplugged he's
controlling the cursor
entirely with decoded neural activity
so this is the first time we see an
actual bci being played live and
this is this is this is very cool
because you know there's the indication
that the little
the little connector for the joystick
which was normally plugged in is now
disconnected that looks like a micro usb
connector to me
um which makes sense because it's
probably just you know conventional
computer that they're that they're doing
all the displaying through
um and there's
now you can actually see the the brain
activity
um or the the bit rate in in of the
brain computer interface and its
max hit was 3.67 which is a respectable
number it's not groundbreaking but at
the same time i don't think they've
necessarily tried to optimize the
algorithm yet um
they're just they're just you know
running running uh running a brain
machine interface
and measuring there and measuring their
uh measuring their their output
the the specific decoding algorithm
isn't really disclosed but there's
actually ways you can tell what they're
actually what they're running
um if you look carefully at the cursor
unlike the hand control one if you go
back to the joystick control and you see
how quickly that one just sort of stops
right on
and that goes into a set still this one
sort of drifts a little bit when it's
trying to stop so you know it's under
it's under brain control but the other
aspect is that it's making the
selections
not be a dwelling like it did in the
joystick one here there's definitely a
click implemented meaning there's both a
velocity in x and y decoding as well as
a click
intention to choose a target being
decoded why
because some of these target selections
happen
way too fast for it to be a dwell and
there's no way they could do that if
unless it was there was a click decoding
being influenced so this is actually
both
a velocity decoder plus a click decoder
running in parallel i can see if i can
point out a couple of those elements as
you see them our goal
is to enable a person with paralysis to
use the computer or phone
with their brain activity alone
because they wouldn't be able to move a
joystick they would calibrate the
decoder by
imagining hand movements to targets
there
so that last one for example is a good
example of one that sort of clicked
really quickly
um when when you know it it shouldn't
have
um or it couldn't have if it was a dwell
so
if you if you pay close attention to
these issues
earlier there that one for example as
well
it clicked way too fast so that it
wasn't actually being triggered by a
dwell
that this is definitely running an hmm
so basically if you see it
clicking you know as it's ripping
through one of the cells very quickly
one of those targets and then it clicks
then that can't happen because of a
dwell detection so it's definitely
running a a click decoder as well which
is which is cool they haven't talked
about that
enable a person with parameters they use
a computer or phone
with their brain activity alone
because they wouldn't be able to move a
joystick they would calibrate the
decoder by imagining hand movements to
targets
so that is just um a description of
of um here are some freely moving papers
that have you know various
forms of wireless or implanted sort of
technology
that's that's uh that's uh relative to
what what they're talking about here
um but you know the the imagined
movements uh the imagine movements and
being able to train the cursor is just
you know uh commenting about the other
types of human work
in this space that's happened all of
these are human intracortical papers
that that build decoders in various ways
and since these individuals are all
all have paralysis um you have to
kick the you have to bootstrap the
decoder off of imagine movements which
actually
ends up modulating the the brain
activity in the same way
one of the things the neural links allow
pager to do is to play his favorite
video game
pong to control his paddle on the right
side of the screen
pager simply thinks about moving his
hand up or down
we've removed the joystick altogether
now that he's up to speed
let's increase the difficulty and see
how well pager can play the neurolink
so this is this is really nice um it's a
very cute demo it's you know it's
a game which is always fun to fun to see
from a technical standpoint the previous
the previous decoding algorithm that's
doing cursor plus click is way more
technically sophisticated because this
is just a 1d task but
uh i get why they did this because it
it's you know it's easy for people to
remember
uh and capture the imagination but this
technically is a
is a simpler task to perform uh the
actual behavior itself is probably
harder to learn because it's difficult
for an animal to understand the games of
things like physics and walls and
bouncing
uh as we understand it um all that being
said it's it's a nice demonstration
as you can see pager is amazingly good
at mind-boggling
he's focused and he's playing entirely
of his own volition
it's not magic the reason neurolink
works
is because it's recording and decoding
electrical signals from the brain
great game pager and what better reward
for a monkey
than a banana we still have challenges
spanning many fields of engineering so
if you're good at solving hard problems
and want to change people's lives even
if you've never worked with the brain
before
we would love to hear from you
so that's the end of the video um and
you know
this is this is a really in my opinion
um pretty compelling demonstration of a
company that
that you know has built brand new
hardware from scratch
and and has gotten it working fully
implanted wireless rechargeable
uh bluetooth streaming in a primate
which is sort of the last step before
you then apply for an fda id exemption
to conduct your first clinical trial
uh assuming this is representative and i
have no reason to believe that it's not
um and they've done everything you know
carefully meticulously
they have all their documentation you
know in a row which of course they i
think they do because they've been very
careful
i expect them to be um to be very close
if not already submitted their fda ide
approval
uh of some uh uh application and
that means that you know if everything
if everything tracks as
as as uh as it would appear they should
be ready to
to you know enroll their first
participant uh their first participant
with paralysis
within the coming year or two that's
that's well within as well within the
timeline
it's a really exciting time for our
field because for the first time in 20
years
we have you know we're on the cusp of a
new device that might be useful
uh it might be that might be you know
fda fda approved for clinical trials
um to to record multiple channels from
the brain
and uh and multiple neural uh multiple
neurons multi-channel neuron activity
from the brain it's not just like
100 channels anymore we're an order of
magnitude higher than the utah electrode
array
so we're long overdue for for a first
step forward and this is really exciting
because
there's tremendous clinical potential
for this there's even tremendous
neuroscientific potential for this i
know i would i would
i would very much welcome having these
types of devices um
available for for research in the in the
monkeys that we work with in our group
um so i'm i'm very excited to see what
what you know that this that this video
came out and there's a lot in here
much of which i wasn't really able to to
comment on are only
mentioned in passing but for an expert
in the field this
video represents a pretty big step
forward for us and
um i look forward to seeing i look
forward to seeing the next steps
thank you for the time
