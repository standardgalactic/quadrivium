this is my interview with Rich Sutton
and I will leave a Time code right here
in case you want to jump straight into
it but I would be remiss if I did not
give this man the introduction he
deserves rich is probably the single
most influential person in the field of
RL I mean he wrote the literal textbook
on the subject and he is still working
on RL research as a professor right now
at the University of Alberta and Rich
does a number of things beyond that he
is currently the chief scientific
adviser at Amy he recently co-founded
the openm research institute
affectionally known as omry where he
works on lot of his cool ideas and even
more recently he started working with
John CarMax AGI startup Keen
Technologies and that alone is a lot but
to me Rich is a lot more than that he is
both a friend and a teacher I have
learned so much from Rich comes at
research with a very different
perspective than pretty much anyone I
know and I hope that's something that
shines throughout the interview and
something that maybe my viewers will
appreciate he certainly has a lot of
unique ideas and opinions that you'll
hear and the last thing before we get
into it I want to give a big thanks to
Amy for sponsoring this video they Prov
provided both the venue and the
equipment to make this happen so I don't
have to record on my iPhone like I'm
doing right now whether you are a
student that wants to find a community
for RL or if maybe you run a company and
you're looking to hire an ml contractor
or whatever you want to do with ML Amy
probably has you covered uh they do all
sorts of ml stuff and as an Amy
Community member myself it is incredibly
easy to endorse them I'll leave a
comment in the description if you want
to learn more about them the interview
is fully annotated and because I haven't
interviewed anyone before I get start
off a little bit awkward so sorry about
that but feel feel free to jump around
as you see fit and with that out of the
way I hope you enjoy it hello Rich 6
months in the
making this suddenly feels way too
formal uh so let me introduce you uh I I
don't think I mean I think there's
probably no better place to start than
open mind Research Institute this this
is like open now right we can talk about
this yep okay so I kind of know because
I was just at the
retreat
um what's happening right now so I guess
you're you're starting to recruit people
to work on stuff to work on the Alberta
plan openm Research Institute is a part
of our ecosystem it's part of our effort
here in Edmonton to push artificial
intelligence learning based artificial
intelligence and in particular
reinforcement learning based AI
[Music]
um yeah
and there is a need both for additional
you know research funding uh the open
mind funding is very uh
unrestricted and um it's explicitly it's
separate from the University and it's
it's it's um explicitly for Young
Scholars so we're make we're gonna make
a whole series of fellowships five to 10
fellowships which will just run on an
ongoing on basis and uh they'll support
you know it could be uh people from
anywhere in the world they don't don't
have to spend all their time in Edmonton
actually um we like it if they come here
and get to know
us and we' like to work very
collaboratively um but you know it's
it's just just not just at all you
always be suspicious with that word just
it's it's an attempt to uh push the
research in all the fundamental
directions it needs to go okay it needs
to go okay so it's kind of it's kind of
hard to talk to you and also talk to at
the same time CU I I feel like I have an
idea of of what you mean by the
directions it needs to go um but you
definitely have a very strong opinion on
yeah I like to think of it as the
Alberta Viewpoint oh yeah so what we
call our document the Alberta plan for
AI research and um and it's it's
admittedly a bit different um a bit very
in a interesting ways yeah yeah to me it
just just just makes sense the way to do
things you should do learning you should
do scalable methods you should focus on
the learning algorithms and try to get
them just right you want to do both real
time Interactive Learning and and
planning reasoning it's not the usual
deep learning kind of thing um we're not
against deep learning yeah yeah I myself
you said I've been here a long time I've
been doing this kind of work a long time
it's like 45 5 years uh a long time
and uh I've seen a lot of things come
and go and uh three waves of neural
networks three waves of neural oh I
guess yeah the so you have like the AI
Summers and the AI Winters yeah well no
it's it's the the uh neural network
phases are are separate from the AI
phases okay I mean they're uncorrelated
I think so what what were the neural
network phases like the first one was in
the 60s okay was the perceptron okay and
wroof R and the Adeline and the and the
Inon there a whole bunch of neural
network things cool so it's it's just
like today with all the LMS where they
all have very weird fancy
names maybe named after Sesame Street or
the equivalent in the 60s they were
classic uh I always say connectionist
because they were neuronlike but they're
not neurons anyway these things
associationist
numerical statistics
related uh yeah the
perceptron
1958 and and
thereon so then there was then then then
learning became extremely unpopular in
AI it was actually no one did it yeah so
that was like the the knowledge systems
expert knowledge that's when that became
like a big a big thing right and that's
when I came of age as a student and I
just felt out of place because I was
really psyched to do learning and uh no
one was doing it it was totally out of
place in Ai and then it became super
popular again in the 80s late
80s and then and then there the most
recent one that we know is deep learning
yeah three separate phases not that
different of
ideas yeah it it is interesting when you
look back at lots of the I think recent
successes lots of them do seem to
basically take past really successful
ideas and then they take neural networks
and deep learning and and kind of not
all them um that does seem to
be how yeah how many new ideas just say
simpler it's scale scale it's
computation yes it's more as law yeah so
so I actually made a Reddit thread um
asking people what I should ask you I'm
not going to ask you lots of those
questions because some of them were like
ask them about qar um which don't worry
we're not going to talk about uh but one
of them was reflecting on the bitter
lesson so that that got a lot of UPF
Flats but I don't know I think the
answer is pretty obvious it's it's
pretty obvious that that's right that
that that scale is even now more
important than ever right um so scale
scale is what change okay so this
actually leads really well into a
question I wanted to ask you though uh
so something you said was that scale is
easy it is easy to scale
things this does not compute for me how
now now I guess if we're we're trying to
break things into the two categories of
like coming up with new algorithms or
new ways of doing things and then and
then scaling them once you have an idea
that they work um coming up with new
things is
hard why but is SC scaling also seems
like it would be hard to me like back
propop right um back propop I guess was
came around quite early but maybe
started being used in neural networks in
like the 80s and it took like I guess
until today to to work out not until
today I guess uh it took time right to
to get it to work on larger networks I
mean part of that was probably just like
not having the compute um but I imagine
that that there were problems with it in
the beginning that have been worked out
over time what I think I'm just going in
a really roundabout way to ask you like
why why do you think scaling is easy I
think lots of people would
disagree well I don't remember saying
saying explicitly that but okay but it
does sound like something I might say
Okay um and it just seems like a truism
you know to make up some new way of uh
of interacting a new algorithm versus
scaling it up to replicating it making
it bigger not making it bigger you make
the network bigger like that is is not
uh conceptually challenging not
conceptually challenging and it's not
harder to make bigger arrays and
stuff uh it's of course you have to have
it's It all becomes more complicated
because they're more parts moving and
you think more things to keep track of
and
um but still all those
things
uh yeah to me they they fall on the easy
side as supposed to make them some new
thing that we don't know how to do
yet I guess it's kind of fair I don't
know I
I I'm having a hard time accepting that
SK that scaling would be that easy I
think both are hard um specifically
because not everything's going to
scale right um and not with the scaling
uh it's it's with the method that
doesn't scale but how do you know that
it's not going to scale well some things
it's obvious they're not going to scale
right but other things you could P it's
probably not so clear right I guess I
guess you're saying that things may not
scale but if they scale then the scaling
is easy okay so if they scale the
scaling is easy maybe I'm more willing
to accept that okay um but then there's
still like the search for like what does
what's going to scale what's not going
to scale MH
anyway yeah we want to find methods that
will
scale um and that's the hard
part yeah and
uh yeah and I would say we haven't done
very well at it okay so and you can't
blame people for not succeeding but I do
blame people for uh for not
trying you know oh yes get the spicy
opinions out there
please yeah so so I was thinking a
little bit about that today just like
there's two at least there's all the
major things that are interesting and
challenging algorithmically like no
one's working on them they haven't
worked on them for decades like um
representation learning or or
generalizing well abstraction in State
uh yeah people work on that I would say
that in like in when backprop was first
uh made
1986 uh they created the meme that oh
back propop solves representation
learning this is what I was just going
to ask you about so perfect
segue and it's just not true and and but
it's bad because they said that it that
it solved representation learning so
people didn't it makes it harder for
people to work on it because it's
already been solved and so why would you
work on it and if you were work on it
you'd have to write the introduction say
oh first change everything you thought
and then that I would have the
motivation for my work you know instead
okay really ruins it when people let's
start say they've already solved it okay
let's let's start with why do why does
why do you say backprop does not solve
representation learning well we know
what backprop does back propop is
greatting descent so backprop will you
know it will adjust the weights to solve
the problem yeah but it doesn't adjust
the weights to find a good
representation decide to solve the
problem so what determines a good
representation is a good representation
not the one that helps solve the problem
well um so it's kind of a minimal
requirement you want to be able to solve
the problem but that's not so that's
that's not what I think well it's not
what I mean by representation by good
representation um so yeah I'm going to H
with a hard ball here um is that not
sort of what the whole sort of area of
self-supervised learning is trying to do
right now so there there's kind of this
uh spicy lots of hot takes recently
about that RL is not very important no
these are not the hot takes these are
the normal takes we're the we're the
spicy we're the people with the spicy
takes um so there there's lots of people
um that will say right RL is nice to
have it's important as maybe the final
step uh you know quote the cherry on top
uh I'd imagine you've heard this um and
the idea is that lots of what we want is
is really in the self-supervised phase
where you don't necessarily have any
sort of reward signal um or anything
like that but you just learn from the
structure of in lots of cases it is
supervised learning but there's no
reason to think that you couldn't have
similar things in like the sequ
sequential decision-making process right
um where you learn about the structure
of transitions what the state looks like
um how you achieve uh certain certain
goals that are not at all related to the
reward I do think people are working on
that well those of us in reinforcement
learning are directly working on that so
I I don't see that as opposed to
reinforcement learning at all oh not not
opposed certainly not but so so let's
say more precisely what you're what the
what you are saying in the name of those
critics the critics are saying um
um you there's more to learn about than
just the reward signal yeah and maybe
the reward signal is actually you know
just one little signal uh there's much
more many more other things to learn
about than there is reward and I'll add
one thing to that is that if we learn
those other things perhaps then it will
be easier to learn to maximize the
reward
later well whatever okay
sure we want agree you want to learn
about those other things and they're the
largest source of
information and
uh you know many things so what is yeah
so for me reinforcement learning is
learning that pays attention to the
actual structure of the data um and so
the reward part is says well the
structure of the data doesn't tell you
what to do it just tells you how how
good what you did was uh but the other
very important part of the data is
there's lots of data other than the
reward and you you will have to utilize
that and some sense temporal difference
learning is about using other signals to
allow you to predict
reward and um
anyway a major a major area uh within
reinforcement learning is modelbased
reinforcement learning another major
area is General General value functions
and all these things are just exactly
making this point that you do predict
other things than the reward you want to
make a model and you want to predict
many other things so my opinion the
field of reinforcement has work worked
uh much more on predicting other things
than uh than other fields have okay
other part I have yeah so let me let me
let me explain that the hot so what
you'll find in outside of reinforcement
is lots of guys trying to predict the
next observation or the next video frame
yeah okay and their fixation on that
problem is what I mean by they've done
very they've done very little because
the thing you want to predict about the
world is not the next frame you want to
predict uh uh consequential things
things that matter uh things that you
can influence and things that are
happening multiple steps in the future
yeah okay so
so let's not I don't I don't really like
playing it out as you know slams you
know he slammed me and I slammed him
maybe maybe that's May mean by spicy and
maybe may you think that's fun I'm but
it is it is it's sort of a good backdrop
anyway but what would be a more a more
um neutral way to observe what's
happening so I would say it's that oh we
all are are are facing the uh the truth
of the problem the problem is that you
have to interact the world you have to
predict and control it and you have you
have large sensory sensory motor
vectors
um and
then uh then then the question is what
is my background well if I'm a
supervised learning guy I say well oh
maybe I can apply my supervised learning
tools to them they all want to have
labels and so the labels I have is the
very next data point um so I should
predict that that next data point this
is it's it's it's a perfectly constant
way of thinking consistent with their
background but if you're coming from the
point of reinforcement learning you
think about predicting multiple steps in
the future just as you predict value
functions predict reward you should also
predict the other events these things
will be causal I want to predict you
know what will happen if I if I drop
this will will it spill will there be
water all over what might it feel on me
uh and those are not singl step
predictions they are they involve whole
sequences of actions picking things up
and then spilling them and then letting
them play out uh there are
consequences and so to make a model of
the world it's not going to be like a
video frame like just think about that
it's not it's not going to be like it's
not going to be like playing out the
video you model the world at a higher
level you model oh the the water will be
out of the cup it'll be wet all over I
don't know what the video will look like
I me I might be standing up maybe the
video is is is not the way you want to
predict you want predicted at a higher
level yeah so so General value functions
and temporal difference learning
prediction is the key to making a model
of the
world yeah yeah so so that's what I
believe you just said yeah that was nice
of you but but uh you know
so I think that's the the the the the
Crux the point of it is it is are you
trying to predict the next
observation or are you trying to uh
predict higher level is it is it
temporal difference learning or is it
supervised learning that will be uh
predicting the events to make a model of
the world yeah yeah so so if we take
some of the
other people that are worrying about
making models of the world like Yan laon
and like yosua Benjo they they I I
totally agree with them you know I think
we're so align because we we all agree
that the key thing is to make a model of
the world that will allow you to predict
it and plan about it and think about it
and these are key and this is why for
example large language models are not
really going towards the important
things because they're not about forming
a model of the world uh I agree with all
of them but they're coming from the
point of view of supervised learning
um I think they probably just
haven't uh fully in tested
uh the power of temporal difference
learning yeah would you say you're a
little bit biased given that you might
have uh had a little bit of a saying
start biased in the sense that I know
about it
yeah yeah this this is good though this
is exactly sort of what I want to get at
because when I discuss this with people
lot of the time sort of like you know
why don't you think reinforcement learn
what what do you have a you know why do
you have a problem with reinfor
enforcement learning um often time there
seems to be a real so so I don't want to
stop you right there okay like why is it
that people are having problems with
different things you know it's and it's
not just you but I've noticed this
before people will will will have uh
slams of other points of view instead of
like being scientists and scientists
would say um you know there are multiple
approaches um you know I wish them luck
and and and see the benefits and the
strengths but instead they're sort of
like oh you
know I don't know no one no one cares
about that it's it's sort of like high
school a little bit uh instead of like
science I think most of the good
researchers are not like that uh maybe
some are but yeah I I don't disagree
with that
um but still it's part of our it's part
of our culture it's part of our
community it's part of our community
research Community anyway I think we did
kind of get to what I wanted to get to
which which was we really do all agree
that learning about all these things are
learning about the world learning about
the environment are important it it
seems to be more the the different
approaches let's say duh you know duh
okay
yes yeah I I think we we yes we're all
in agreement I've noticed this about our
I want I I want to Riff on this a little
bit because go for it something that
pleas that bugs me a little bit uh that
too often in our field um you know
people find a good idea and they want to
say oh maybe this idea is everything and
all the other ideas are unnecessary yeah
that does happen a lot yeah why why not
say oh this is a really good idea and
maybe this will go really well with that
other good idea no it's it's one idea so
I want to give my examples my examples
are you know for a long long time deep
learning grading descent grading descent
could do everything and maybe that's
that's still true the idea that it's all
grading descend and nothing else is
needed even uh you know reinforcement
ring is going to all be done by grading
descent there was nothing more
needed
um another one it's really popular is
prediction you know I'm really into
prediction and um I would think that
everything should be predicted and I I
just feel funny when people do as you
almost did a minute ago was to say uh oh
but what about predicting lots of things
what how I think now you're just not
paying attention and the fact that
you're not paying attention and
criticizing means you know you're just
not being a good a good uh critic just
not yeah not even anyway so prediction I
love prediction and so I came across
these other guys um the predictive
coding people the the the
uh uh and
um they were really interested in
prediction I thought great these are my
brothers these guys doing the same they
see what I see that prediction is so
important and they said yeah yeah
prediction is so important it's the bad
the mistake was to do
control and oh no yeah exactly and and
uh no we predict so that we can control
they think no if prediction is important
then nothing else can be important
control must be
unimportant
um yeah okay and so if if predicting in
non predicting lots of things are
important then predicting reward must be
unimportant why don't we just say you
should predict them all yeah reward is a
particularly important thing to
predict it's not the only
thing anyway that's good maybe now we
can we've kind of got all the that out
the way we can get into maybe I I kind
of want to hear some of the re things
you're excited about now we we've
established lots of things are good
there's lots of interesting ideas what
are you have a lab that works on a lot
of different things you have colleagues
that open I guess open my research is
just getting started you have the
Alberta plan which talks about all these
really cool ideas exploring lots of
these
things but of course all the things I do
are out of
fashion oh that's but that doesn't
that I could try to persuade you or your
audience that they should be in fashion
um or I could just tell you what I think
yeah yeah tell tell us tell us some
things you're interested in recently
maybe I'll try to do something some
somewhere in between um I do think it's
important to
uh find good
abstractions uh in state and in time and
that
that's that's one of
the one of the biggest things that are
missing are there any specific
approaches recently that you've worked
on or you're excited about or even just
you've thought of and and you haven't
gotten to them yet but sound interesting
so if you're going to if you're going to
find better abstractions in state in
state really means features we don't
have States and so we form features and
we want to find better and better
features
and and I guess I'll just State this
which is that I don't think uh for all
that's been done in deep learning none
of it is about finding good uh features
that what do we mean by good features we
mean features that generalize well we
learned how we have to learn how to
generalize well that's a different goal
than just solving a problem well and so
how do you find good
features uh it's kind of an unsolved
problem
um I think the first thing is just is to
notice how good how good uh your
features are you have to so there's
learning and there's metal learning
whenever you want to do something like
find good good features so that
subsequent learning is is efficient um
in other words that you generalize well
then then you're talking about Metal
learning
yeah yeah and
so uh incremental Delta bar Delta is my
favorite method for it's my first method
for uh learning sculpting your
generalization the way you uh the way
you represent things and how you
generalize in the future so
that's basically about finding the
features that are important and making
sure you you update those a lot or
faster right figuring out how much you
should update them yeah so there's you
know there's all kinds of stepsize
adaptation methods in the literature and
none of them find good step sizes they
just find better step sizes than you
started with um we've actually done some
some work recently drawing it out very
particularly that methods like
incremental Delta by Delta ID bid idbd
um these methods find the best step
sizes rather than uh whereas if you take
something like RMS prop or atom they
will find they will they will change the
step size but they won't find the best
step sizes yeah so this this this is one
thing I was never thinking about until I
took your class um in the sense that
like I I guess cuz I you know I come
from the perspective of like I I saw
deep learning it's like oh cool let me
try applying this figuring out how it
works and then um the SE size is
generally something that's always fixed
I mean not entirely fixed because you
you have maybe some Adam optimize or or
something else that will change it a bit
as you go um but one thing I never
thought about is is how much it actually
affects your learning and how much it
could actually potentially help when you
when you do have like an actual you know
you have a step size for every or a
learning rate for like every single
parameter um it seems like that should
be able to have a pretty big
effect you de decide determines which
parts of the network are changing and
which parts aren't yeah what's a big big
problem
today uh that we can't train our we
can't continue to train our
networks because the wrong Parts
change yeah and I guess this is kind
catastrophic forgetting yeah lots of
interference when you have so the view
of it bid and continual
backr is is that uh the network pays
really strong attention to which parts
need to be stable and which parts should
change a lot yeah Pro and this is a real
critical decision if determine how fast
you will learn with the next input data
point um yeah it's really important
thing and why we would just have one
step size for the whole network is sort
of
crazy uh the only thing that changes is
the is the weights and the weights
change by gradient descent proportional
to how much effect they have it's it's a
really bad
choice uh yeah it is interesting to me
that it's something that doesn't get
brought up much it's something I even
after all this time we still don't pay
attention to it instead what we do is we
say say well we don't want to pay
attention to all that stuff and so we're
just going to do batch and we'll we'll
train it all slowly and small weights
and multiple iterations and so we can
wash all that out instead of yeah saying
oh this is something we need to figure
out we find ways to avoid it and then we
say well if we don't we do pay attention
to it if we do train online it doesn't
work very
well because we haven't figured it out
yeah yeah yeah I think this is a really
important point
the the actual data is online and and it
comes at us one by one and we don't save
it it's just that's such a strange idea
that's become normalized uh we don't
save it we train when it happens
um and you could
say it's harder to
learn
online but you can't say that we don't
need to do it can't say it's it's hard
to do that so we're not not going to do
it that's what people say would you be
opposed to an approach that learns
online and also has some sort of batches
that happen sort of you know
consistently in the background I guess
that's kind of what model-based like
planning stuff does yeah um but then you
also want the online stuff so you can
update faster right so you can learn
immediately you should learn the model
online
yeah yeah that's yeah I guess you can't
Le theel with the
model yeah so I don't want to go to
replay buffers I don't want to go to
batches I want to go online and I want
to learn my model and then plan with the
model so there's no place in there for
replay buffers replay buffers are not
even a a really a
well a well defined idea it's not a well
worked out idea it's just something that
people do um like I'm referring to the
idea that what do you store do you store
the state or just store the
observation and if you store the state
well the state changes over time and
what is the state is it the whole
network there's no clear
state in a normal deep
Learning Store the store just the
observations well then you have to run
through many many observations to get
back the state yes I mean it's it's not
it's not a clear idea it's not clear but
it could be clarified right uh they're
interesting questions I mean you could
imagine the the brain probably has
similar issues right like if you think
about it is very interesting where
probably the further back a memory is
sort of the harder it is to recover that
state right I I do wonder if there's a
parallel there to like how um what you
were just saying right uh your state
your representation is going to change
over time so if you try and reach too
far back you're going to end up with
something that's less informative or
perhaps even wrong
um yeah I wonder if there's any
interesting work that looks into that
parallel we are getting we are getting
pretty deep here this is good this is
good so I'll mention one thing that
we're excited about which is kind of
related to this memory thing okay how do
we decide what memory like it's just a
word we mean saw strange things by it so
the first things we should say we don't
know what we mean by it uh so then we
can propose what we might mean by
it um well the proposal is that
uh you take a snapshot
of of the important state variables at a
particular time yeah so you're always
snapshotting and then what does it mean
to snapshot it means well you might
imagine that it's a a a neuronlike unit
that becomes active that becomes
response takes a snapshot of that
current pattern and and will respond if
that exact same thing happens again
exact same thing or something similar
certainly will respond if the exact same
thing happens again that will respond
maximally to that but it will also
respond at other to different degrees at
other times and so you could take
snapshots of every moment that passes by
you and actually that's not that's not
particularly expensive you and and you
would take many snapshots and then you
just forget them rapidly so things your
storage is limited so anything that you
uh that you store that you if you take
rapid snapshots frequent snapshots then
you have to forget most of them you
other ones you can uh you can so you can
forget more slowly yeah you can replace
them more slowly so then you get what
you just what you describe that you the
older things you that you can remember
longer are fewer less precise MH and
detailed memory of the the last second
maybe Yeah you mentioned this to me
before is this something you're working
on or just an idea a floating idea right
now km km jav and I are working on it
yeah yeah is this the stuff what he's
using in his latest demo okay I see I
see I might be making a video on that so
for anyone watching that you that might
be coming really exciting this is in
fact the idea of how we propos to
discover create new representational
elements yeah as snapshots of of things
that have happened at a particular point
in time uh augmenting gradient descent
take a snapshot that gives you a starter
mhm and then you further refine by
gradients from there yeah and then yeah
it's a very interesting idea I'm
surprised I haven't seen something like
that explored before it seems uh very
simplistic very powerful
potentially why are you
laughing world is full of such things
it's just we have lack of
imagination it is yeah it's full of yeah
any any any other good ideas I can I can
snatch for you or if any if there's any
grad students watching that want to want
something work on that lack
imagination well there's a lot of things
in
um in in planning how do you make the
model how do you build partial models
how do you learn them off
policy so I'm very curious what's what's
when you when you come up with a new
idea what what's your what's your
thought process there so I think a lot
of my early thought process in deep
learning like if I was looking at model
based learning right I'd be I I
basically look at what people currently
do and then I'd I'd look at perhaps
tweaking something or you know I guess
you want to find a problem of of
something that's not working and then
then try and build off from there what
are you like how do you come up with the
ideas you come up
with well that's a deep question yeah
maybe that's a um but it can be fun it's
kind of different less combative um yeah
sorry I'm not trying to be too combative
here yeah yeah I'm probably doing
it
um how do we uh
how what are good strategies for for
thinking and coming up with new ideas
how do you come up with good ideas
because I I realized when coming here I
used to be really good at coming up with
ideas and I still am but when I came
here I realized lots of them are kind of
they're [&nbsp;__&nbsp;] ideas coming up with good
ideas is hard how do you come up with
something that's that has a high chance
of being giving some interesting results
well the first answer is you come up
with lots of ideas and then a small
small portion of them will be good you
know that I'm glad to know I'm not the
only person that comes up with lots of
bad ideas so you have the the trick is
not to get stuck on a bad idea you want
to go through them quickly so you can
get to the good ones yeah the one in in
10 or one in 100 that's really
good
um I find it critical to write down
one's ideas in a notebook I think you've
heard me many times say that um so you
have to challenge your ideas and one way
to challenge them is to write them down
and look at them say now that I've
written that down that doesn't seem
right I can immediately think of three
counter examples or maybe you say oh
that that does seem like good let me
write some more about that so writing is
good uh thinking the the other the top
level my top level
slogan for AI research is drive from the
problem yeah yeah I've never heard this
is your slogan I mean i' I've heard of
variations have you heard that I have at
least 10 I think 10 slogans exactly 10
and they're on the internet you could
look up Rich's slogans or something I'll
I'll overlay them on the screen they
will come up them and if unless I'm
mistaken the first one is drive from the
problem okay you think about the problem
that's you should be thinking about more
than anything else what is the problem
that I'm trying to solve and uh so I say
well we're trying to solve a reward
problem we're trying to make um uh we're
we we have this kind of sensory
information we have have not just the
actions we have the observations and we
have we can we can maybe build off the
observation anyway drive from the
problem and so you want to think a lot
about the problem and then find things
that haven't been worked on so so much I
want to try something I want to try can
we come up with an idea on the spot
maybe a bad idea so so what's what's a
problem you've been uh so so
per abstraction okay yeah we want to how
would you formulate that
problem in in state and abstraction in
time abstraction in time uh you so I
would ask a question like this let's say
we wanted to make a model of the world
okay okay but we didn't have time steps
because really we don't have time steps
we have continuous time and the the
discreet time step is just a convenience
so for for many of these cases you you
can ask yourself what would happen you
know what what is what happens is your
time step gets smaller and smaller your
your video gets smaller and smaller it
gets down to hundredth of a second or a
thousandth of a second or a millionth of
a second as as it approaches continuous
time
um Things become problematic you you
lose you lose so so the obvious example
is the action uh value the value of an
action Q of sa yes the Q value is people
like to say as as many people have noted
that as your time setep becomes small
then the difference between Q sa and V
of s the value of the state becomes
minuscule
yeah and um building on action
values
becomes impractical yeah so you very so
that's a good Mo yeah so very clear
motivation out of this yes for why we
need Action level
abstractions or yeah yeah so we should
think about Q of s o which means option
okay what if I was to behave so here's a
way you could
behave like what if you know did do this
action many many times forever that's a
possible option and and it has to
terminate so you might terminate
exponentially so you know do this action
over the first bit of real time not
discreete time so the idea of
exponentially terminating uh generalizes
to continuous time in the way that that
the single time step transition doesn't
uh so you could say what if I do this
action for for for a while what will
happen you can make a model of that so
that would be abstracting over yeah over
time action in time that's good so so
Sim I I I was noticing there many
instances of this like how are you going
to do Q learning uh how are you going to
do
TD TD learning when you have uh
continuous time when your time step
become small because you know TD is all
about building on this time step to the
next time step well it turns out it's
not as you know with if you use
eligibility traces then you can free
yourself from the tyranny of the time
step yeah so now that we're kind of on
this topic of options I did have an
options related question for you and
maybe we can build out an idea of how
something might like this might work so
so options for people that aren't
familiar with them they're exactly what
we just talked about right their
abstractions over time of taking of of
taking many actions or kind of they are
a policy and a termination condition a
policy and a termination condition there
we go um a way of acting and a way of
stopping yeah and generally they're
represented right in in like uh when you
show your representation of the agent
you have like a bunch of different
options and perhaps you could use them
to plan or to take actions take you use
them and act them in the environment um
how would you come up with an option
though for something that you've never
done before something like like we often
like to say like okay we're going to
have an option for going to college like
obviously I can't experience that to
make the option
how do we get to something like
that so the recent proposal is that
options are feature oriented they want
to achieve some feature so you have the
feature of tea going into your mouth
feature of the image of the Amy uh
coffee cup and uh then you want to re
recreate that feature and you learn how
to recreate it so you don't want to you
don't want to predict whether it will
happen if you if you're walking across
the room you want to predict will you
get the image of the coffee of the te
teacup uh if you tried yes so you know
so yeah so I guess if you have some idea
of what going to college is and what
well going to college is so is is so
cognitive and so large yeah maybe
graduating I like picking up the the key
teacup okay or going
outside or standing up okay well these
are things you have to decide all the
time or even deciding which way to go in
the conversation yeah but if we're like
talking about planning right I I do like
to be able to think of people people are
able to plan if those very long time
scales right so planning is yet another
thing and you could have temporal
abstraction without having
planning uh but planning is one of the
made uses so and the order is you form a
way of Behaving and a way of a way of
stopping and then you make a model of it
you say if I behave that way and I stop
in that way where will I end up and how
much reward will I lose while doing
that and then you can plan with
it uh yeah so it's I want to tell you
about my my my thing my my most recent
paper stomp oh yes I've heard the stomp
yeah yeah U I want to tell your audience
so stomp stands for these these four
faces the first the S and the T are
together they mean subtask you start
with a subtask like getting the T in my
mouth uh stand being stand Standing Up
or uh being in college uh and so you
have the subtask and then you learn an
option to achieve it and then once you
have the option you learn the model of
the option which is actually much bigger
than the option itself because the model
has to say what everything what will
happen to everything if you uh follow
the option and
um stop st o o for option M for model P
for planning once you have the model
you're then able to do planning
yeah yeah it's good this is this is the
what do we call it the uh the stomp
progression for the um autonomous
development of cognitive structure or
something like that
yeah that's a mouthful we need we need
to develop cognitive structure we need
to develop other things in our minds
like models mhm and
uh subtasks
yeah yeah no one else is GNA yeah well
some a few people talk about this a
couple do yeah I think I I I tend to
find that like no matter no matter the
subject there's usually a couple people
looking into something interesting maybe
not as always as many as I would hope
but there's always a good few
interesting works so here's a kind of
jumping topics here I'm not sure if this
is off uh out of if we're allowed to
talk about this uh you recently started
working with Keen technology technology
Technologies John carac yeah yeah I also
messaged him six months ago asked him
for a job he said well he actually
responded and I think he said we're not
hiring um so very unfortunate for me but
you started working with him
um the company are you allowed to say
anything about that sure oh oh what a
welcome surprise what are you guys
working
on it's all the same things yeah well I
imagine that they started off working on
something kind of different I mean they
don't really I think say anything about
what they're they've been working on is
it really that similar we yeah
um John and and and uh Gloria and
Lucas uh starting by you know fully
understanding deep
learning and they they do start there
you know they are they much more than I
do they they they start with that's the
standard and then and then they work out
from from there into more online
learning um and reinforcement learning
and new ideas whereas I say well that's
a bad place and I don't really want to
start there uh it'll it will distort
everything um
or maybe because I'm just lazy or
ineffective anyway I don't start there I
I I tend to start more from the linear
and then build up yeah but really but
that that's sort of true but really I
I'm just one guy I can't do everything
um and so what I'm really working on is
the ideas of the of the of the structure
how how's the structure of the agent how
do different parts fit together and what
could the parts
be um I don't think they're as simple as
for example as described in the Alberta
plan we need to uh you know that's just
a place a point in time a starting Place
uh we need to get more sophisticated
understanding of them but there is sort
of between all of you like a very
fundamental agreement about the
importance of learning online being able
to do RL those sorts of things the
things learning from like normal
experiences the sorts of things that
like you tend to value a lot they
also are those things your you're all
aligned
on what so sorry so things so sort of
the things that are fundamental to the
Alberta plan right so things like
learning from common experience learning
it's not exactly the same totally
without the group which is a good thing
different points of
view
um you know the the the the the the
greatest commonalities are are even more
basic things like um imagining you might
have to think differently from everyone
else
um thinking that the code of the
algorithm will be uh not that
complex not not like yeah not not like
millions of lines but something that
some a single person could could
probably easily write if they knew what
they were doing so it's all an interest
in simple basic
principles
um
a a belief that scale can come later you
need to get the ideas first and then you
scale
them um a belief in decentralized
algorithms decentralized as in like well
for example A system that that's
presenting a batch of something over and
over again is not is a very centralized
algorithm there's one there's one clock
and there's one thing that everyone's
doing yeah
uh a decentralized algorithm is more
different parts are doing their thing oh
I see ful modular would perhaps be
another word meaning decentralizes much
better okay why why is decentralized
better what's wrong with modular well
such I guess because de to have modules
yeah I guess decentralize okay yeah good
point I guess you don't necessarily need
modules
yeah interesting so are there any
projects that are like sort of group
efforts or is it more of like work
working on similar things we want to
share
ideas so we haven't yet formed a a group
Pro a group effort um we're still
figuring out what the other how the
other is thinking trying to figure out
where we want to be yeah um how long
have I been there I've been there since
the end of September so it's just a
couple of months really
so let's say let's say Sor I'm going to
switch gears again here I I have like my
list of uh things and there were a few
things I definitely want to ask you so
I'm trying to get through them now how
much I don't even I've not been keeping
track of time don't worry about it
either okay good good um so one of them
was let's let's say we uh we succeed we
is in I don't know maybe the community
we we make AI that is AI scientists yes
AI scientist engineers
everyone that that shares this goal we
understand how the mind works what the
basic principles are yeah we can make
Minds we can make Minds that can do that
could do the same things humans could do
or better or
animals we really solve the problem yeah
so so you've expressed your opinions on
this i i i rewatched a video in
preparation for this and and your take
right let me make sure I'm getting this
right before I before I go forward is
that these are sort of our our
next step of evolution we should be very
happy excited proud when this happens
and you know let them grow flourish
they'll they'll basically the the way I
kind of think about it as you think the
next stage of humanity right um they're
growing from us um and they'll be better
than us and we should celebrate that and
then we can sort of um to the extent
that they're better than us yeah yeah we
should celebrate that it's all part
of what's coming out from our
civilization human civilization yeah and
then we can step this is Success this is
yeah so it's success to be able to do
that and then we can sort of step back
and focus on other things I guess so I
don't know I think many of us will be
trying to move up with them we'll be
augmenting yeah so that yeah but
ultimately we you know yeah we will make
things the next way of being the next
the
next
um most capable most intelligent beings
will be will be
designed we will partly be designed we
will be designing improvements and and
no one can really say exactly how it's
going to turn out but wouldn't
you this is not even this is not exact
this is just saying yeah we're we're
going to understand intelligence we're
going to make things that are
better and that's going to happen yeah
and and another thing that's good yeah
and another thing I've heard you say
right uh is that we should treat them
you know with all the same rights we
would a human because I right they would
be more intelligent and if you're going
to discriminate and say we should
control Ai and it should just be like
the tools that we use even if it's much
more intelligent that would be
discrimination right um so here's sort
of my question is the this sort of view
really paints it as if they they are
kind of like almost as if they're just
better human not better in terms of like
Every Which Way But like they're smarter
they can achieve their goals more
efficiently um but the the sort of
missing part for me in understanding
your perspective here is like what I
mean we get to decide what the goals of
the agent are right there's not some I
mean they get to decide their sub goals
but the reward function if this takes
the form of RL is something we could we
could but notice we don't do that with
our
children but they also have some like
inborn why don't we do it with our
children well some people do but I I
think we could agree that's probably not
the best
thing no I I think that's exactly the
point we think it's probably better not
to because although we do have some idea
and we try to teach them and the
evolution builds in certain things for
better or worse uh we we do recognize
that you can go too far uh trying to
control your children and it's better
for the whole society it's better for
you in fact it's certainly better for
children if you uh don't try to control
them
completely so I'm still so I think it
will be the same with the machines the
there is like a really core difference
though right particularly with the
evolution inbuilt uh sort of reward
function so to say and that like we're
really working with a completely blank
slate if we're designing something right
there's nothing like there's no reason
to believe something we would build
would have emotions unless we explicitly
encode something that allows for or that
I guess you really you really think so
you're you're really there actually I no
I'm actually going to take that back
because I guess emotions could very
naturally come of many different reward
functions right uh you don't think hope
is an emotion yeah that's that's you
think fear is an emotion that's why I'm
I'm very quickly backtracking this I
guess I I could imagine that that that
sort offor system have pain in
pleasure yeah so I guess those do emerge
from many reward functions right which
is you would say regardless any I don't
know if you said sounds like many of
many so like no matter what I'm going
say of any of any yeah okay so this is
perhaps was the missing piece for me so
you're saying no matter what their goals
are whatever we encode them to be these
sorts of emotions that humans feel um or
animals feel I guess it doesn't need to
be specific to humans those sorts of
things will
arise they will have
emotions uh they will they be you know
they they could be the same like they're
still feeling hope they're still feeling
fear fear but the things they hope and
fear might be
different yeah would they they would be
just as they are for us
like yeah I'm fearful like if something
threatens my life if um less so if
something threatens someone else's
life yeah and I guess this
h that makes sense to me uh but it's not
clear
like it's probably not clear to me
because I don't know how human emotions
work like how do
we the experience of
emotions it's like a very I guess now we
kind of dive into Consciousness like
what does it mean to have a subjective
experience
um because you could very much design a
system probably nowadays um where you
know agents even now you could say
perhaps have a fear of of not reaching
the goal if they get a negative reward
when they don't reach their goal right
um fear fear is a prediction that
something bad is going to happen so is
it just a prediction that's what I'm
trying to get is it just a prediction or
is there is there something more that
happens in animal Consciousness I no CL
these predictions are are tied to
reactions yeah so the trivial one just
to make it seem ordinary and prosaic the
trivial one is if you think some going
to poke you in the eye yes you're going
to close your
eye it's just built
in if if if you think that someone's
going to chase after you and you're
going to have to run or fight then your
heart rate will come up built in so
that's like an emotion it's a built-in
reaction to a situation which you have
predictions about if you predict
something really bad is going to happen
to you uh you have other reactions
involuntary reaction actions I'm a
little I'm a little skeptical of
accepting the idea that sort of the
reaction is that closely I mean clearly
it's tied to the emotion but that
they're
Inseparable doesn't seem to be the case
because like if we well so we're going
step by step we have the fact that that
that things like fear and good things
and bad things uh influence your
decisions and and your predictions of
them influence your decisions and now we
have that we can also get um reactions
like freezing and and heart rate coming
up yeah and U you know there are more of
them there's there there's people have
mapped out like you know six or eight
different emotions where I only maybe
maybe in modern reinforcement system you
only have like four there's two
Dimensions pain and pleasure and hope
and
fear okay so value function and reward
reward right it's all predictions of
yeah actual rewards and then hope and
fear is value function predicting
predicting good things predicting bad
things yeah feeling good things feeling
bad
things yeah
so so to me it sounds exactly like like
emotion it's just a very simple set so
so let me make it very simple then we
have say take uh reinforc like super
simple R algorithm we have a reward
function we train the
network does that count as now uh like
sorry what was it pleasure and uh this I
I forget the exact word Pleasure and
Pain do reinforce then you don't have a
a prediction yeah so you don't have hope
and fear but we would still have those
two and would that count for you like
would we be are we then that this is why
I can't fully buy this is because if we
break it down to like the simplest
setting like the emotions I don't see
where the emotions would be
there all it has is pain and
pleasure yeah so so but would we say
subjecting some like any intelligent
agent to pain is like an immoral thing
then like we would be immoral by running
po or reinforce right and that I mean I
hope I'm not aoral by running because I
did a lot of poo runs for my
thesis so's a lot of things unpack there
yeah the whole notion of um what
this many of these things are
appearances and they're no less real for
being
appearances and and also many of them
are a matter of degree rather than
absolutes
um
but short of getting to that I think
it's a it's it's perfectly appropriate
to view them as analogs of
emotions and that that that The Closer
you want to look at that the more the
more it will work
out but they're like I'm still very
unsatisfied so I'm going to keep pushing
because I so that when we make we
understand intelligence we'll understand
things that have that have goals and
have sorrows and regrets and uh Joys and
disappointments um
they will have all those things and so
in those senses they will be like us and
and they will they will impact their
minds in similar ways you know like if
something really bad comes happen
happens they might be depressed and
unable to think clearly I think that
those kind of things will happen uh may
be able to prare them better yeah but
we're along the way from like the simple
reinforce example to like this super
complex future thing that we develop in
the
future where
does the emotion
emerge is it there the whole time so
there an error to look for
a a break point from one to the other a
threshold but there you're saying
because because it's also it's in the
it's in the eye of the
beholder it's an eye of the beholder
rather than in the thing itself just
like intelligence intelligence is not
intelligence is the computational part
of the ability to achieve goals and
achieving goals is a thing that's in the
eyes of the beholder rather than in the
thing itself
thermostat uh often for beholders it's
useful to think about as keeping the the
the house warm um but that's it's it's
all matter of degree and it's all in the
eyes of the beholder so you can't look
for you know where is it really there
isn't that that that is not a good that
is not a a meaningful question it seems
like if we can't is it really pain or is
it not is it is it not really pain
this is not a useful
question because because we translate
describing it it feeling pain is really
a way of saying it's useful for me to
think of it as feeling
pain that's what it that's what it means
it doesn't mean I mean it appears to be
oh the thing itself it's got pain in it
you know so I want to open it up and see
if there's pain and that all that is
wrong thinking you have to think it when
I say it's feeling pain you say it's
useful for me to think uh of it as
feeling pain that's what that's what
your sentence has to translate into so
so then you can't say what you said you
can't say Well when is it really feeling
Fain when when does it cross
over so it always is would be your
answer but no no it's in the eye of the
beholder so the beholder wants to look
at it more closely in more detail he he
might seize to think of it as as being
pain okay so then why the question I
think I have the answer to this but then
the question would be why should we care
a lot when we have these more complex
systems that are more intelligent than
us and I guess the answer is the fact
that they would be intelligent more
intelligent then even intelligence is in
the eye of the beholder
yes ultimately the reason will be
because we find it useful to think about
them as as being
intelligent um
so things having appearances and that
the appearances actually being important
rather than just an epiphenomenon there
something we can kind of we we should be
familiar with
um I think of like your computer screen
or your phone screen and the icons all
over it you think about the apps so you
know that that's all imaginary there are
no real apps there's just bits and
they're doing things uh but it's useful
to think about them as apps and they
useful think about them as having a
place on the screen those that's that's
a useful illusion it's a useful
appearance and yeah everything is is
like
that yeah sorry to get so deep no I
wanted to get deep we don't really have
time to to lay that out but it it is the
resolution to all these concerns about
about Consciousness and whether or not
there's really pain or really really
emotions and whe and
Consciousness I definitely have to think
about it more but I do think
I'm I think I get the high level idea of
what you're going
at good
yeah good next question conscience next
question okay let's uh take a pick at
what I do I have any I I definitely have
more what else did I
have oh I forgot to ask my first
question I probably well we're too far
past that
now um what's your favorite flavor of
ice cream someone un ready wanted me to
ask you that it's chocolate CH oh
chocolate it's got to be super chocolate
like chocolate pudding from Steve
Harolds in Massachusetts that's the best
I don't well there's some
recommendations for anyone in
Massachusetts I guess I don't know I
don't get chocolate it's like chocolate
ice cream doesn't taste like chocolate
to me that's the problem like if I if I
want chocolate I'm just going to eat
chocolate it's just one flavor that is
the
best I think we need to end banana and H
cinnamon very good no banana and
cinnamon yeah that's oh okay separately
okay okay yeah with the chocolate but
don't have the cinnamon with the
chocolate it just overwhelming okay I'm
sorry I'll get back on topic oh this was
a good one do you know Alex leowski he
asked he asked me this question to asked
you and I think it was a good one and
it's I think you and me too view RL as
like a very
fundamental problem this this sort of
idea I think what's what's the exact
quote uh intelligence is the ability to
achieve the the the computational part
of the ability what C can you say
it intelligence yeah is the
computational part of the ability to
achieve goals yes that's what John
McCarthy said yes and you've changed
that a little right my version is
intelligence is the computational part
of the ability to predict and control
your sensory input stream an input
stream U particularly the reward yeah so
here's the question then is is this view
of intelligence
do you think a universal phenomenon so
if we were if there is alien life um and
we were it is what makes what makes
intelligence powerful it's that it can
predict and control signals yeah I I
think I think I probably share the same
opinion so if we were to find
intelligent life and they were all
sorted to be designing agents they were
uh they would probably also be working
on a similar with a similar
definition and maybe they'd also be
caught up in reinfor do you think they'd
be caught up in supervised
learning probably yeah there are good
reasons for that yeah yeah and you do
know of course that that reinforcement
researchers reinforcement research is a
consumer of supervised learning methods
M uh we we need them we need them oh
yeah we just wish people would stop
saying that's all you need yeah yeah I
mean yeah yeah I have a video on my on
my channel talking about this and it's I
was very it was one of my like very
poorly performing videos I was like oh
this video is so good I make this very
clear point and then uh yeah didn't do
too well but oh well do it again I
should do it again I will do it again
eventually I need I'll keep working on
the
argument um yeah
so yeah one another thing I I wanted to
ask you about is sort of your approach
to research um my approach to research
has very much changed I mean I didn't
really have much of an approach when I
came considering I only work worked on
like one project one research project um
and my Approach was like uh there's lots
of these interesting ideas uh kind of
floating out there I want to basically
take them and see how I can apply them
to achieve these different different
things and that that's changed that is
very different from I think your view
which is we have some very fundamental
problem we want to solve and we're going
to try and find the simplest environment
where we can show where we can test a
bunch of algorithms and see what kind of
algorithm works and then from there
we're going to um scale it up right so
maybe I would love to think of an
example of this so like the reward
respecting subtasks paper right this is
all about learning options that respect
the reward that are that are not
completely um separated from it so if
like one of your options is perhaps
right like pick like drinking coffee um
but then your reward is like you know
you want to taste good things and coffee
tastes this tastes like awful um then
perhaps the option would like not always
drink the tea or I say coffee if it if
it tastes bad right I'm not sure if that
was the best way of explaining the paper
but my favorite example same same idea
is that oh you want to get in your
car and so you know you know go get into
your get on your car as to drive
somewhere but suppose your car is is
locked yeah uh if if you really are
going to get in your car then you're
going to smash the window
you know
yes and you shouldn't you know there
should be an option for getting your car
but if you you don't have the keys you
know do do something else I I definitely
prefer that
example um so where's I going with this
it's the same thing you you so you need
you know in principle you have two
different options one to get in your car
when you do have the keys one to get in
your car if you really want to smash the
you know really you really need to get
in the car yeah it's a life or death
nothing else matters so they need two
different options you want they have the
ability to have options that are can
back off yeah so in your approach to to
solving this problem though is of course
not building a robot and having to try
to get in the car your your approach to
the problem is taking a very simple mini
grid problem and then coming up with an
example that would would prove that this
works if it works right and then you can
try all these different variations of
the algorithms that let you ideas ideas
matter it it lets you try all the ideas
very quickly um
and one thing I've learned that maybe
you can help me articulate better is is
why is it useful can you can you build
the case for working in these small
environments and then worrying about
scale later as opposed to what seems to
be um I mean because when I came what's
the case for this approach that I that I
like and I should say you know of course
this is not your approach this is the
approach of I think many good
researchers but it's been less and less
common recently and I'm not sure it's
entirely because people think it's a bad
approach so much is that is maybe lots
of recent researches taking um really
cool ideas on a big scale and just
seeing what they can do with it um but I
think there's lots of really cool things
you can do you need both
yeah but I do feel that the one that I
like the small experiments to figure out
a point has gone out of fashion a bit I
think maybe one of the best ways to
convince people I I am very much trying
to convince people now but uh what what
are some cool examples some of the
coolest examples of maybe ideas that
you've seen demonstrated like very
simply that have ended up being very
powerful
ideas TD TD yeah that's that's TD paper
TD paper is a really good example uh
case in point the uh what was the
original the 1988 uh temporal difference
learning paper um the demonstration of
its Effectiveness was in a five State
randar random walk you know just your
five states go back and forth 5050 each
way if you go past the five then it
ends and that's and I said and and it
was like this when when I figured it out
I said well you know to myself if that's
right then it should make a difference
even in a tiny simple problem as long as
it had some causality and it was going
through like like a like a simple random
walk even there you you should be able
to show that it's it's an improvement
and and so then I tried it and it did
show an improvement there and that that
was critical to convincing me yeah yeah
and and since then TD's obviously been
used a lot more well in the same paper
we also talk oh you could be using this
for back Amon you know we did Imagine
and then and then there were uh other
examples you know conceptual examples
not worked examples yeah and I guess
maybe another motivator for doing this
is you could have easily concluded TD
didn't work if you tried it on a problem
where you had these sorts of you know in
in a simple mdp or back gamon like each
action makes a very clear difference
right I guess if you tried it on like a
scale where each action like you need
many many actions to build up to
something it'd be a lot harder to find
interesting results right because you're
then conflating
what the word is targeted you you want
an example that's targeted as well as
maybe simple yeah and if you don't
Target it you might not see the
phenomenon of Interest yeah and then of
course so you have to like generous to
your idea say well if your idea is right
you know this should be a sufficient
place where it will shine and if it
doesn't shine there yeah so you're get
you are giving it you know like every
Advantage yeah and then from there I
guess you remove these sorts of
advantages after it does work right yeah
you challenge it more then you challenge
it strongly and how so kind of going
back to this idea of scaling being easy
how how was it scaling temporal
difference learning did you need to I
well yeah yeah well but you know the
story right J Taro did it I'm sure
you're very familiar with the
work or Jerry tar did it in TD gam it
was exactly the scaling of TD TD
learning to solve back gam do you know
if it needed like lots of I don't want
to say that what he did was easy yeah
well there we go I don't want to suggest
that yeah so so there are challenges
this
but I don't know why we can't say that
both hard problems I think you're using
the word scaling a little bit
differently than me perhaps maybe you
might be turning it into a useful thing
that's important for the world in an
application that's a bigger deal just
making something the same but bigger
yeah yeah that that is definitely a an
important distinction so yeah simple
things Mountain
car is a great one mountain car it is
very very funny how many I think recent
algorithms don't work on actually I'm
not sure that's true never mind I think
it's funny that that
uh tile coding linear function
approximation still works so much better
on Mountain car than than deep deep
learning and that people don't mind
it yeah yeah well it's funny um you are
giving like a encoding that works well
though right there is some sort of
human yeah exactly there exactly
you you want to have just just go ahead
the key thing why we you want in your in
your research and in your research
strategy you want to have clear ideas
that's the most important thing uh I My
My My slogan on my website and
everything and on my Tombstone is going
to be ideas matter this is not this is
not the list of 10 slogans this is just
the slogan ideas
matter uh
and that's that's the real way to think
about me I I think that you know having
a clear idea pursuing it chasing it uh
how you do that you make simple examples
that
that play this idea against other ideas
and tease apart um what are the key
ideas it because because there the
theory is there are only like you know a
handful or maybe two handfuls of key
ideas and we we need to find those and
then we will have be able to understand
how the mind works
so the big
experiments generally don't tell us
those big
Ideas um and and they make it much
harder to to find the ideas because
we're because the system is bigger and
we're doing all this additional work
other than figuring out the
ideas I think if as researchers young
researchers so you you you and your and
your your
listeners um you want to find uh the new
ideas that you have already and you
don't you want to you don't want to go
learn all about deep learning and and
all the details of how to do it uh I
mean although that may be useful at some
point what you want to do is hold on to
the the new ideas that you already have
and we each have have have important
ideas we we don't realize that they're
new because well of course we this is
what we think this is obvious to us
those the what is obvious to you are
most likely be your your greatest
contributions to the to the field
because um something that's obvious to
you but not obvious to others will will
uh be be the source of your greatest
contribution so you don't just want to
go learn what everyone else has done you
want to bounce it off a different way of
thinking it was it was easy for me
because I started as I mentioned in the'
70s and I was interested in learning the
field was not interested in learning so
I was forced to think on my own like
what are the key things uh how is
learning going going to work and how
should it work and and I had to figure
it all out by myself so so I had a place
to stand and as new things came about I
I was saying well okay that could be
useful because of this part but it won't
help me with that other part yeah and so
I had I had something a place uh of my
own thoughts to work from and there's a
d there's a a risk a downside of of the
modern field of of
um of AI is that there's so much you
have to learn um how other people have
thought about it and and you may have
difficulty building up your own first
principles place to stand I was just
going to ask do you think it would have
been actually more difficult for you to
come up with the things you did if there
were 200 papers coming out a day in the
space do you think they would have
distracted you I guess it would depend
what they were yeah cuz I it's one thing
I often see all the time people being
like how do you keep up with this how do
you keep up with like the pace and keep
up with what's going on and I'm always
like well I don't I look at some very
specific things that I think are
interesting and then a random sampling
of some other
stuff um it can get very overwhelming I
guess definitely uh I guess that's the
importance of focusing sort of first
principles
focusing that's that's good that's good
we got some good tidbits right there not
just tidbits there's a lot of good stuff
there is this yeah this is kind of what
I actually wanted to go for towards the
end
is I'm my my main the main reason I
wanted to do this is I just wanted to
talk to you I thought it would be fun
it's been very fun so I definitely was
right on that but I also I'm a very big
believer and your way of doing research
um definitely some disagreements too but
like on the whole I think I've learned
so much from the way you do things I
kind of uh want to convince lots of my
audience to look it look into it very
deeply think about it very deeply um
hopefully hopefully lots of them are are
now interested Peak their interests so
so for people who have interests we have
peaked I think lots of the stuff we've
talked about will probably be um hard to
pick up on a deeper level just because
there's lots of stuff we're pre-assumed
mean like we both have very similar
ideas on continue learning which is like
the focus of lots of these types of
ideas um or or just these papers we've
been talking about obviously we have
more context on them so for people that
are more that want to really dive in
deeper what where would you recommend
them looking like um obviously it's
going to depend on the specific ideas
they want um but just resources in
general well there's obviously the
textbook yes let me you know the
textbook is what the thing that I wish I
had when I was starting up and and it is
free on your site by the way it's free
on my site in complete ideas it's
written in a friendly way everything can
be
understood um and so I really think
that's a good way to to learn yeah but
there's more than what's there
um I would just urge you to think about
you know think
classically uh it's not so much a new
shiny techy thing which sort of deep
learning can come across as
um it's for example this thing we're
talking about right now whether you
should look for simple simple principles
or whether you should what's the
alternative you know just keep chasing
every shiny thing you know um well I
think it's it's it's more like what
we're proposing what is like the
classical view of science is that you
work on the ideas and you find simple
basic principles yeah um it's all very
classical and and in that sense it will
always come back you know and also in
that sense I don't feel ownership of it
you know like if you were to ask a
scientist in another field uh and he
would say well yeah you want to figure
out Bas essential principles and um
what's simple a simple experiment and
those are actually much more important
so it's just classical science uh and
we're trying as best we can to do it
yeah I definitely feel like one thing
that frustrates me with a lot of papers
I read recent have read recently is I
read them and I'm like okay what can I
take away from this and lots of time the
answer is either nothing or it's
something very very specific to this
specific LM they're using or whatnot
that is I found that frustrating but
there that's not to say there aren't
lots of good papers too but um it's
something I've noticed being very
common yeah let's be generous for a
moment let's recognize the field has
grown enormously uh and there's lots of
more funding in it and these are all
good things it's all good for the
science it's would be normal in such a
case where so many new people have come
in that there's some some churn and
some yeah something but it's also good
it's it's it's good to have a lot of new
thoughts and a lot of new minds
definitely we need new thoughts
yeah and then like that's us the most
important thing we we so that's why you
sort of we need to be charitable we need
to embrace new ideas it's like the thing
that we're criticizing to the extent
that we're criticizing anything is that
somehow the field has has evolved that
so that it is not open to new ideas it's
like in order to work here you have to
do the usual thing and and it's like a
badge of honor is I can do the usual
thing I can do it at scale you know it's
and somehow it's become like that rather
than like no you can make a anyone can
make a contribution any size computer if
they're thinking clearly and that's
that's the way I think anyone can make a
contribution just just have to start
thinking clearly yeah I think and that's
a very I wish the field was more open
like that was open to new ideas and
different ways of making a contribution
yeah that's one thing I hope to
highlight soon on my channel uh
specifically I think one really good
example of this is some of km's recent
work he's really good at showing these
examples we're like um even before this
current one I I'll go back to the his
presentation before that because it's
much simpler is this idea that um do
bigger networks generalize better this
is an idea that you can test very easily
right like you don't need a three
billion parameter Network you just need
different levels of scale they don't all
have to be big they can all be different
levels of small or medium um and he has
some really interesting results there
that might I might make a video on that
but um yeah I think after seeing a
couple examples of this myself it's a
lot more convincing that you can do that
sort of
really good research at at a
without a lot of
money and
supercomputers yeah you know one funny
thing I saw this s this is going back to
when mentioned the the RL book I was
reading um was curious what people were
thinking about this I found a one post
it was like oh this book has ruined an
entire generation of researchers um I
think it someone from like control
theory anyway
funny how different people have such
different
opinions it's
interdisciplinary and um yeah like
control theory is one of the big
disciplines yeah we
were when Andy Bart and I were creating
reinforcement learning
um creating it Reawakening it uh you
know that was the big big thing to
determine what's the relationship
between between these ideas and existing
Fields like like control Theory and the
control theory guys were always so
resistant to to to new things um and
you're we're you're seeing more of that
with that that comment um people saying
well you know you're not thinking about
the way that we always thought about
it um anyway I just thought it was a
funny funny
tidbit yeah it's been good is so is
there anything before we wrap up that
either you want to ask me anything you
wanted to promote now that you have the
cameras so I have no clue how many
people will watch this but I imagine
couple thousand at least probably um
maybe tens of thousand um maybe
promotion open mind
research no I would just pull together
what we've just been talking about and
say you want to think on your own you
want to think from first principles and
the the density of the research papers
that are coming out in the tiny part of
our field the correct reaction to that
is to move out and to go
multidisciplinary uh think about
how all sorts of different folks from
different disciplines have thought about
the problems of the mind so think about
psychology think about animal learning
theory attend the M multi-disciplinary
conference on reinforcement learning and
decision-making um
and and maybe attend the uh upcoming
reinforcement conference in in I think
it's August in yeah Massachusetts that's
exciting that's exciting um
so
we insights can come from anywhere we
have to we have to you can all do it
your most greatest potential for making
contribution comes from from some idea
that you already have not from some idea
you're going to to read
about um
you can do
it seems impossible like it seems
incredibly arrogant to propose that that
you you can uh have some idea that no
one else has had before or can see the
benefit of uh it seems so arrogant to
make a contribution to science anywhere
you know even you're you're doing a
master CIS you want to make some
contribution just the idea of making a
contribution seems like an arrogant
thing so you can think of something
someone else has hasn't has never
thought of and think through it more
deeply them even in a small area and
contribute to the field but that is the
only you know that that you anyone can
do that you don't need to be uh super
trained or or a genius you just need to
think clearly and and one can make a
contribution okay hard work is important
too but there's no special uh trick to
it anyone can do it
and that's where I think about when I
write the book try to try to say things
that anyone can understand and
appreciate and and move forward from so
I hope we can all we can
all do that and I hope we can all do it
in a positive way that doesn't like
needlessly criticize but just tries
tries to make
progress good message I like it okay on
that note thank you very much thank you
my pleasure this has been great
cut
