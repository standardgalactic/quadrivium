foreign
[Music]
today by Barry Smith and jobst
lundgraber to discuss their fascinating
book why machines will never Rule the
World published by Routledge in its
philosophy imprint the subtitle of the
book is artificial intelligence without
fear
anyone who's watched UK color news for a
while will know that in almost every
episode references are made to the
supposedly imminent takeover of one
profession or the other by artificial
intelligence and there's certainly a lot
about fear in UK column news and special
broadcasts so with that subtitle at an
excellent promise of what's to come but
we can discuss the subjects without fear
I'm delighted to welcome you both I will
read the blurb from the back cover of
the book and then it's over to the both
of you to introduce yourselves as you
see fit
Barry Smith is one of the most widely
cited contemporary philosophers he has
made influential contributions to the
foundations of ontology and data science
especially in the biomedical domain most
recently his work has led to the
creation of an international standard in
the field of ontology which is the first
example of a piece of philosophy that
has been subjected to the iso
standardization process
landgreiver is a scientist and
entrepreneur with a background in
philosophy mathematics neuroscience and
bioinformatics lundgrieber is also the
founder of cognultict a German
artificial intelligence company which
has since 2013 provided working systems
used by companies in areas such as
insurance claims management Real Estate
Management and medical billing after
more than 10 years in the AI industry
he's developed an exceptional
understanding of the limits and
potential of AI in the future
very I suppose it might be over to you
first because people listening to that
may have wondered what ontology is for
starters and it does come into the book
repeatedly ontology so perhaps you could
explain something of your career what it
is that's taken you to Upstate New York
where you're speaking to us from today
and something about ontology and data
science how the two relate and what they
are
good so um ontology started life as the
Latin translation of the Greek word
metaphysics and so that may give some
people some idea of what it is it's the
study of being in the uh traditional
definition but um in a more modern
definition is the study of the kinds of
beings that there are and of the
relations between them
and this study uh was um involved in the
very birth of artificial intelligence so
the first attempt to create artificial
intelligence in computers consisted in
attempts to replicate the ontologies of
ordinary human beings
the idea would be that if we understand
how ordinary human beings classify
entities in the world
and if we can transmit that information
to a robot and the robot would be able
to navigate its way through the world in
a way which is similar to how humans do
it
now with that ontology became
established as not just as part of
philosophy but as part of computer
science
and it's been of growing importance I
would say since around 1970 when these
experiments were first made in Stanford
they all failed incidentally no one
succeeded in creating a robot on the
basis of an ontology but it was uh
certainly an important stepping stone in
the development of artificial
intelligence so um the the uh the great
successes of ontology are not to be
found in uh AI but rather in biology and
medicine so what happened was that in
Iraq well at the the point in time when
the Human Genome Project was beginning
to be completed
medicine in particular and the life
sciences in general began to realize
that they were faced with a gigantic
Avalanche of new data new technology new
devices uh new kinds of experimental
methods which they knew absolutely
nothing about
and these these data and methods were
based upon a new kind of chemical
information really and the problem was
to find ways of translating this
chemical information which consists of
incredibly long strings of letters
into a language which a clinician or a
biologist could understand and the the
key to that was something called the
gene ontology
and the gene ontology is a collection of
terms nouns and noun phrases used by
biologists to describe biological
phenomena
which has been used to tag
sequence data Gene Gene sequence data
protein sequence data RNA sequence data
and so on over many years resulting in
an investment of several billions of
dollars
and this ontology the gene ontology
serves effectively as the bridge between
old biology and clinical medicine on the
one hand and the new chemical biology
which was Unleashed by the Genome
Project
I was one of the people involved at a
crucial stage in the development of the
gene ontology
in turning it into something which is
logically coherent so I'm a philosopher
by training and I know something about
logic that the people who built the gene
ontology they knew a lot about genes and
a lot about genomic data but they didn't
know very much about logic and so they
built an ontology which was full of
logical
gaps and and logically embarrassing
steps and missing items and unclear
items and I showed them basically how to
do a better job of the logic of the
ontology
and that that gave me a certain
influence in the world that bio ontology
as we might call it and that led me to
become uh involved in critical work
shall we say of other biological and
medical
um artifacts which were created to to
keep uh Pace with developments in
computer science and
um I was very critical of some of this
work uh some of it was uh scams that is
to say use of claims about the powers
the computational powers of new uh
medical terminologies which were
unsupported in the the terminologies
themselves and in connection with my
work I was one of the few people who
would speak out about these scams in
connection with my work along these
lines I was
approached by orbs two at that time was
actually working for one of these scam
organizations he he can justify himself
um and he wrote to me uh pointing out
that he agreed with everything I was
saying and uh for a time he worked as my
mole in the uh in this world
and um I have been working uh not since
then in various other kinds of ontology
efforts but I think that's probably
enough to give your uh audience some
idea
so are you currently in an academic post
I know that you're in Buffalo New York
uh yes I'm a professor of philosophy of
computer science and engineering of
bioinformatics and of Neurology but my
my union card it says philosophy on it
what a fascinating combination and jobs
lundgraber who is going to introduce
himself now has no less a fascinating
combination he's the kind of figure that
there is perhaps more of in the European
continent than in the English-speaking
world because as I read uh he has got
qualifications in philosophy uh
mathematics Neuroscience but also
biology and chemistry so he's got all of
the ologies he's got uh fields which
have a lot of formulas in them but also
fields that require a lot of writing and
thinking on particulars uh with using
language also I think you're properly
trilingual aren't you yields because as
well as being a German who uses English
for professional life your long maternal
is French but you're speaking from your
native Germany so why don't you give us
something about your background and what
it was that impelled you to study all of
these different disciplines so thanks
first of all for inviting us here
um Alex so um I will try to make it
short so in the end uh after I finished
uh gumnazim with just the equivalent of
high school
um or grammar school in England I really
did know dwell what to do and um I so I
first started philosophy which I then
gave up because I was shocked by the
state of University philosophy at the
beginning of the 1990s
um and um it was also time when Barry
started to think that you should
diversify within philosophy so I wasn't
completely wrong with my impression and
so then I switched over to Madison and
biochemistry which I finished
um in 1998 and then I started a postdoc
at the Max Planck Institute of
psychiatry neurogenetics
and um made experiments which yielded so
many data points that I this brought me
into mathematics and so then I I didn't
get a degree in mathematics but I
studied it long enough to start
publishing a lot of mathematical papers
and so that's how I became a biome
mathematician and but my interest in
philosophy never never really died off
and so when I later got involved into
bio
um medical terminology and ontology I
discovered Barry's writings and then got
into contact with them I also since
since the late 90s started to work in
what is now called or what is already
was called artificial intelligence at
the time but I prefer to call it
statistical learning or machine learning
and I used it a lot in the bio
mathematical research that I was doing
since the late 90s and I've I've always
used it since then in different fields
and applied it to different areas and
that's that's why I was because I used
professionally as a technique as a form
of Applied Mathematics I then also start
thinking about it and in the end this
led Barry and me to write first papers
about the topic of artificial
intelligence and then later on also our
book so you had a definite writing aim
in mind and the title really brings that
out doesn't it why machines will never
rule the world one or other of you will
have proposed that title to the other
we've heard from both of you that you
dislike scams and low standards in
Academia and I have recorded already one
three-part series and transcribed it
with my father on low standards in
Academia and there's another one in the
can coming out so you're certainly not
the only figures who've become
disenchanted
um when did it come about
apart from the world of science fiction
which I think we might get into as well
because it's far from peripheral here
but in in the world of mainstream hype
uh commercial hype and academic hype
which I know are symbiotic they feed off
each other when did people start popping
up saying it's not long until machines
will rule the world
um and perhaps even more to the point
you hint at this at various points in
the book what kind of people were they
who are making this claim did they have
the rounded view of life and learning
that both of you have
so I think that that claims that
machines could become as intelligent as
human beings have been made since the
50s the the famous paper by Alan Turing
where he describes the touring test also
discusses this possibility
Turing himself believed that this would
come about in somewhere in the future
but it became more I think in each wave
of AI there was these claims were made
and they were made more aggressively
with each wave so the first wave which
was the one in which touring
participated uh at least at its
beginning it was the claim was made in
the second one it was also made and led
to a rebuttal
um by the rifles who wrote a book
against the possibility of artificial
intelligence in the early 70s and then
in the third wave of which we are now
contemporaries it is made in the most
aggressive way and I think one of the
leaders making the claim was courtswell
Ray courtswell was technology director
at Google or who was technology directed
Google a really important man in
um in the development of optical
character recognition so he really did
good technical things but as an engineer
I think he misses or yes he misses the
the understand standing of what the
human mind is and what it can do and
therefore he his claims are ungrounded
well this segues me nicely to the next
question which I'd like to hear both of
you talk about what is the mind I know
that's a pretty massive question but you
do dare to broach the topic in the book
and you do so apathetically you do so by
saying what the mind is not you say that
the mind or the brain which you use
roughly interchangeably is not a machine
and you then bring out some
characteristics which it it does have so
over to you on that what is the mind and
perhaps you might want to have another
Pop I think it's quite legitimate at the
Cutz Wireless of the world who say that
the mind is reducible to being a
mechanical device and thus can be
mathematically modeled so I'll have a go
at this um the the whole theme of the
book is uh that there is a distinction
between two kinds of systems one kind of
system is the mechanical system as you
this is the term you used and computers
are mechanical systems your laptop is a
mechanical system a toaster is a
mechanical system and mechanical systems
are built by humans we understand how
they work because we understand physics
and we can predict the behavior of the
systems on the basis of what we know
about that parts and the way they're put
together on the other hand are complex
systems and all organisms are complex
systems and the oceans of the world are
complex systems and so on we can talk a
lot about complex systems and now the
problem is that the claim of the
artificial intelligence
enthusiasts shall we say is that the
Mind itself is a is just a mechanical
system and therefore sooner or later we
will be able to understand how it works
in just the same way we understand how a
computer or a laptop or a a toaster or a
car works
uh and that we argue on the basis of a
quite complicated series of arguments
some of which are grounded in
mathematics uh is not the case no
organism not even the simplest organism
is ever going to be able to
um be understood in the way that we
understand the workings of mechanisms
and so
um this means that we cannot understand
in particular how the brain works
this is one of the consequences of our
general thesis the brain is I don't want
to say it's a mystery because that will
upset Yorks since he he knows a lot
about neurology and neurobiology but the
brain is such that we can we will never
be able to understand it in the way that
we understand mechanisms
now what that means is that there are
two kinds of intelligence there's the
kind of intelligence that can be
achieved by using mechanisms such as
computers that's artificial intelligence
and then there's the kind of
intelligence which we might call general
intelligence which is the kind of
intelligence exhibited by an organism
specifically the the human being
and given this uh Gap this is necessary
Gap which will never be uh eliminated
and that's that's probably the weakest
point in our argument
um it this means that that can never be
artificial general intelligence
and now just one other point relating to
this which grew out of the discussion of
courtswell the course file it was one of
the very first people to talk about the
the singularity
and our book is really addressed to
those people who are worried that the
singularity is near I think that was the
title of one of course file's book he's
been saying that the singularity will be
here by 2030 at least somebody once gave
me a transcription job to do in which uh
he told an audience some years ago it's
here by 2030 so just to put that in
context
you know I mean which was postponed also
yeah the idea behind the singularity is
that once we have a computer which is as
intelligent as human beings that
computer will be able to program device
somehow assemble even more intelligent
computers in a uh uh a a a kind of
Snowball Effect to bring about
gigantically intelligent computers who
will take over the Galaxy
uh and that idea how I know from
experience of people I talk to causes
real fear in the uh in in a large group
of people in our book was uh aimed to be
an antidote to that so yeah it's it's it
it's groundless and just one other thing
I am actually
not so happy with our subtitle
because people assume that the world is
going to be without fear wherever
artificial intelligence is involved the
problem is that there are still going to
be people
and there are going to be evil people
who use artificial intelligence to do
things which people might reasonably be
afraid of
and so it's artificial intelligence
in itself which we should not be afraid
of
but once humans start using artificial
intelligence for instance in scams but
also in creating super powerful weapons
or creating social uh control mechanisms
then we quite recently should be afraid
of it but that means we're afraid of
what the humans are doing with AI not
with AI itself now this is
underappreciated by people who hear
perhaps with reference to their own
profession that some of the work is
going to be taken over by AI or as you
are helpfully directing us to say
artificial general intelligence a more
specific term used in the book people
are hearing that AI will take all these
roles on such as claims adjustment which
I read in the book occupies a quarter of
a million people in Germany although
that seems to be rapidly dwindling with
this uh computerization now in a
sentence in a nutshell what your book
points out is that AI in order to
improve itself needs a continual
dialogue with people just picking up
there on what Barry said about not
people and their intent behind Ai and
that forms part of the key argument the
syllogism right there in your
introduction there will never be the
singularity super duper AI why not
because it's going to have to be
designing a more competent and more
amazing successor than itself and in
order to do that it is going to have to
have natural conversations with very
intelligent human designers saying now I
need to build the better version of me
and it's going to have to instill
confidence in the human colleagues no
longer programmers but colleagues and
informers that it knows what on Earth
it's doing and the last stage of your
syllogism is in order to do that it
would already have to be artificial
general intelligence it would already
have to be a human mini me which can't
happen have I got the syllogism more or
less right there it is very beautiful
actually it's one variant of it
um uh and I I would I would
um uh how it can be put and these
variant rests on um the inside that
machines cannot um use
um propositional thinking right so when
when a machine uh like now the chat GPT
which is creating a huge hype again of
how you know dangerous and and almost
already fully intelligent to say I seems
to be
when when such an AI is used to to
create utterances then it is not
uttering anything but it's just
producing a sequence of symbols which it
doesn't understand
and this is what what many people don't
realize they they think this is
impressive and this sounds almost right
but they don't realize that this is just
a sequence model that that is not
thinking at all it doesn't have any
intentions it doesn't have any
self-awareness it's it's just a
syntactic um uh Reckoning machine
um like the one about which other
lovelers wrote built by her husband uh
Charles Babbage in the middle of the
19th century so of course the machines
now are much more powerful they can can
compute billion times faster
um than these old Machines of 150 years
ago but they are still based on the same
principle and so
um they they don't they cannot develop
Consciousness or or think they are just
performing mathematical operations
um which were defined um in the 1930s by
ensuring and uh Alonso church and they
are just performing combinations of
these mathematical procedures and this
is not thinking at all and so to call
the machine intelligence the marketing
trick
um used to create high but this is just
Applied Mathematics let's thrash out
these terms then because intelligence
has the is the term that's been marketed
now
um your book is in some ways
complementary to one written uh about 40
years ago now which I've tipped off to
jobs because it's called Uh architect or
B question mark by Mike Cooley from an
educated man coming from the labor
movement uh organized labor in Ireland
and then Britain uh pointing out that
there's many more orders of magnitude
involved in human consciousness and
cognition than merely intelligence and
we could go into some of the vocabulary
it varies from author to author but I
mean if we start very classically with
the the platonic scheme a character a
personality is made up of Mind feelings
and will
and intelligence is a subset of mind
it's not the whole of a character
right at feelings you don't ignore but
you don't particularly mention in the
book either will is an absolutely core
Concept in all three parts of your book
the first part on the mind the middle
part on the hard maths what can be
modeled and what are complex systems and
the third part bringing them together
what can maths do to model a mind but
will before and we not that we really
meditate upon this unless like you we we
look at the philosophers will is
absolutely key to having even the most
basic conversation isn't it because uh
in a conversational exchange there is a
will to compete a will to live in
harmony a will to understand each other
this this is what's missing when you
have a game of chess
or a conversation with a computer isn't
it it doesn't want to be your friend it
just does in a symbolic syntactical
sequence what it's told so if you speak
to an AI bot in healthcare it doesn't
want to heal you if you speak to a bot
in a courtroom which I understand
According to some reports is happening
in China the bot doesn't want to do
justice it doesn't have feelings or will
for justice and then there's also in the
introduction questions about the terms
Consciousness and cognition and I if I
understand correctly Consciousness as a
study that is what has become in
philosophy phenomenology you pay a lot
of tributes to Edmund Hussein not a very
well-known philosopher in the
English-speaking World although I think
educated viewers will have heard of him
and a couple of hustles near
contemporaries possibly disciples or
colleagues Max shailer and Arnold Galen
uh your this is your domain these are
German thinkers and they have a happy
marriage of being realists so they're
not normalists they don't think that
everything's in the mind they think that
what's in their mind is connected even
physically to the real world but they
are phenomenal just they're studying
Consciousness they don't go off into the
later the long grass of later 20th
century franco-german philosophy that
says nothing really exists
um that might sound irrelevant to some
of our viewers but that's the
philosophical uh glue in this isn't it
that we now know after a lot of study
that Consciousness cognition is a lot
more than just the mind yeah I mean
before I answer Barry should also on
this because Barry is is a
phenomenologist uh I mean that this is
also the the foundation of one of the
foundations of our friendship because
when I first contacted him I really
mentioned phenomenology and and I mean
Barry is now doing ontology but it's
very much based on the work of heaven so
I just would like to mention this but
yes um phenomenology I see as the the
peak of the development of um Western
philosophy so I think it is the the
highest form that philosophy has taken
on since it came about in the
presocratic times and um it is still as
one can see in our book extremely useful
as a tool to understand reality and this
is what we do in the book so we use
as two very important philosophers to as
a foundation for our work and the reason
they can use so well is that they are
not only realists but they are also able
to give and provide an explanation for
phenomena that cannot be derived from
experience so if you ask yourself what
is the mind what is consciousness what
is intelligence it's not it's not
sufficient to only look like positivism
proposed at empirical data and so
phenomenology provides
um a philosophical framework how to deal
with with
um Concepts or entities which are not
made of matter and so because we need
this when we discuss intelligence and
Consciousness it is so useful to use
this philosophy and and the main
philosophical failures of the 20th
century uh derive either in positivism
from the inability to to understand
these immaterial
um entities or in the case of
heideggerianism from from an
unwillingness to accept rationale
rationalism realism Aristotelian
thinking and I think feminology provides
a foundation for uh for a mature and um
realistic
um view of the world that is also in
harmony with common sense and this is
also I think one of the driving uh
foundations of our book is that it is
really written and thought through in
harmony with common sense and that's a
bridge to uh Barry's own response to
that Barry you mentioned that Circa 1970
so half a century ago now the big drive
a perhaps slightly informed by the the
science fiction of uh Isaac Asimov and
Robert Heinlein and such like the big
Drive was to have a robot that as you
very aptly said could navigate its way
around the world or even just one
profession in the world
um
have we got there even now is there any
prospects given what's just been said by
yours of a robot an artificial general
intelligence navigating its way around
the world
well I think that the the key and you
you recognize this uh to all of this is
the will
so we can build robots that can navigate
their way around Disneyland for instance
because it's a controlled environment
and only a certain limited range of
phenomena can be encountered and that's
that's the key difference between
artificial intelligence and the
artificial general intelligence we have
intelligent machines
but they're intelligent only in special
worlds where everything is simple so
this we call narrow intelligence but we
don't have machines that can navigate in
the ordinary real world that humans
navigate in where where conditions are
changing all the time where strange
phenomena can happen where we're called
upon to um to make snap decisions uh in
relation to phenomena that we've ever
never encountered before
and I think that the key here is the
will in the following sense
so some of the environments in which
machines can navigate are created by
games so video games or just chess or go
and and computers can as we know can be
humans when playing games like chess and
go and so people assume that the
computers must want to win
uh therefore computers can want and
therefore computers can want to take
over the Galaxy they they can want to
win the game of life with real people
but actually if you look at the way uh
computers do things like win at chess
they don't do it because they want to do
anything they do it because they've been
trained in a certain highly specialized
way
to have what a human would call a reward
system this is what the AI people call
reinforcement learning and you can build
a reward system which will imitate
having a will
only if you can assign a reward
computationally that means just by doing
a certain piece of arithmetic now you
can't you can't assign Rewards
through contributions to a conversation
and if you don't believe me just try it
try and set up a reward system with you
and your friend or your wife can agree
on and then you'll give each other
rewards for each step in the
conversation you will never succeed
because a conversation is a realization
of a complex system namely the people
involved so the the AI people can indeed
create something that looks very much
like a will but only in those very
narrow areas where we have what we have
in games namely a strict set of rules
which allows allows the calculation of
rewards so that you can train the
machine to get higher and higher rewards
by having the machine play itself
millions of times and that's what they
do that's how they create machines that
can play chess or go better than humans
and most of the real really impressive
uh and I I there are many really
impressive achievements of
um
computers in the recent years most of
the successes are in areas like games
including mathematically equivalent
areas logic games
all of the successes are in what we call
narrow areas that is to say areas where
we have something like a logic system or
a simple system which we can understand
in other words something mechanical key
here is the closed world so closed World
means that the attributes and the the
um
what is called the phase space which you
can imagine like the multi-dimensional
Cartesian coordinate system that this
phase space is somehow predictable and
either you have a real game situation
like the game's very mentioned in which
this uh this is uh how the games are or
um you can also model a complex system
in reality
um like in this way if you only model it
partially so when these these partial
models of complex systems can be very
successful at modeling certain very
regular patterns of complex systems for
example the traffic pattern
um in a big town is very regular there's
a lot of traffic in the morning in the
afternoon and then there are other
traffic patterns throughout the week and
there are Cycles depending on the season
and Cycles depending on on bank holidays
and all of this creates irregularity so
that you can actually get an AR to model
this very well so whenever also complex
systems can be modeled with AI methods
if they have a regularity but the but
the problem of complex system is that
they have a lot of irregularities and
they make them unaccessible to modeling
with AI and that's why whenever complex
systems interact and create unexpected
outcomes
um which happens in every conversation
or in in many many other human
interactions as well even just movements
of crowds
um these irregularities happen when
whenever this is the case the AI failed
and that's why the automation potential
of AI is only can only be applied to
very regular events
and so that's why for example
um uh a self-driving car cannot drive
freely in Disney World it could drive in
an empty Disney World but as soon as
people are running around it will not
drive freeway it can only then drive on
a certain limited area where where
everything is controlled but as soon as
the the um
um this this chaotic nature or um
irregular nature of the behavior of
complex systems comes into play the AI
will always fail and it's neither logic
possible to train it then using um
types of mathematical logic nor the
stochastic algorithms which now dominate
AI which are called Deep neural networks
and which have created the big hype
so in a nutshell it's the people Factor
AI can navigate a world in which there
are things but uh people and they're
irritating unpredictable desires and
ways of expressing themselves is going
to be Beyond it is always going to say
no When an unexpected conversation
remark is made hence if you go to a
computer to heal you or to judge your
case in the law uh if it doesn't
understand your behavior from a
mathematical model it's going to tell
you that you are the problem you do not
compute it it's not only human beings
it's nature in general because most of
the natural phenomena are complex so
it's also animals the weather
um and and the whole way our world is
structure is a complex system world and
so therefore the machine can't cope with
the real world because it can only cope
with simple system settings and and so
um in in if you if you think of for
example using um a machine as a as a
robotic policeman and this would
completely fail because the machine
would just not be able to cope with the
real world because no situation that it
encounters is like the situation it was
trained for in the laboratory so
it will just miserably fail and that's
why the fear that that um machines were
used in this way is wrong we'll be using
this very strong there are legitimate
fears though but this one for example
isn't because it just doesn't take into
consideration that that uh machines
can't be made to act autonomously in
such a setting but it is happening isn't
it I don't know which of you would like
to answer but UK column used just in the
last couple of months has covered from
multiple jurisdictions across North
America some in East Asia as well that
robocops are being let loose in certain
situations and the lawyers are the men
who are all the women of course in this
in these days who are writing the
algorithms for them and they're always
telling the robocops to ER on the side
of not getting the police department
sued which isn't very uh promising as a
set of rules of engagement but it is
happening so perhaps we need to have a
footnote here on the claim there is no
need to fear in the AI ear so so what's
happening is that barely let me you can
answer this so so what's happening is
that they are now using robots
um for um in for
um enforcement activities of police but
these are not autonomous robots they are
like the toys that we use as children
the with the
um how do you say they call this with
the um remote control like remote
control toys so you can actually have a
robot that goes into a danger zone uh
with a remote control that has sensors
and a camera and can explore it but it's
not active autonomous autonomously and
this is this is also not any time to
come so yes robots are being used in law
enforcement settings but they are not
this is not AI this is just you know a
sensor on weird and the Samsung Wheels
may also become ironed soon and be able
to shoot or detonate and all of all of
this is nice but it is not it it is not
um that this robot acts autonomously and
also there is no I've never I've I've
not seen that anywhere there is an
automated
um
usage of automated AI in any you know
called system or legal system there are
of course AI Tools in social media
surveillance which are being used which
are very primitive but um they are but
there's not nothing like this in the
actual workings of the jurisdictional
system
so I think that there are working
examples in traffic law
and there is some academic literature
which demonstrates that the uh the the
use of not robots but computers in in
simple traffic law situations is both
cheaper than using people and also more
often correct than using people where
correct means applying the law to a
given traffic situation and I think what
what one needs to say and this is
something that you did in your uh in
your own AI work your is that those
systems only work if you have humans in
the loop uh who are there in the
whatever it is the 10 percent of cases
where the computer is not confident that
it's giving the right uh assessment
because it doesn't have the right data
or because there's something which
confuses it and I want to uh to use this
as a segue to talking about GB GPT chat
um so I think gbt chat or is it chart
GPT I I'm
I'm always confused
uh is the current Target of hype and it
is indeed possible to generate
impressive looking material uh out of
chat GPT
um but I I've been trying all day
yesterday and all day today to work out
what's going on when I enter into jack
chat GPT simple questions about two
people called Barry Smith both of whom
are philosophers
um one lives in London he's got Barry C
Smith
and he also does work which is vaguely
phenomenological the other one lives in
Buffalo and that's me and I don't have a
middle initiative now when email was
first introduced and both Barry C and I
are old enough to have been around
before email
um when email first started we used very
occasionally to get emails from girls
who thought that they were in love with
like some kind of compound Barry Smith
which included features of him and
features of me it didn't happen very
often but it did happen
uh it doesn't happen anymore because the
email systems are now using AI in fact
almost certainly in such a way that
those kinds of ambiguities happen Almost
Never
but chat GPT
did I get it wrong again
um
is still making exactly the same
mistakes so it thinks I'm from London
and that it makes a number of mistakes
like that it thinks that my job is in
Leipzig which it was
10 years ago it still thinks that my job
is in Leipzig so I tell it it doesn't
think of course and I tell it you are
making a mistake
please correct this information and then
so I ask it exactly the same question
again a few seconds later and it says
along with the complaint that I'm making
a mistake and it says I am very sorry
that I made this mistake and then it
repeats exactly the same false
information this is Alex if if I may
react to this immediately this is a
typical instance of uh which has been
described for a long time for stochastic
learning that stochastic systems can't
be corrected at will so they are trained
on a huge set of data and which which
create patterns um that that direct them
how they should then uh create new
sequences of of symbols which is what
they then print out on the screen their
output and so they can be retrained but
there is no guarantee that they will
then learn the right things so when you
when you give a high load of a certain
type of language to these models you can
indeed induce a certain learning effect
for example
um the the chatbot Tie by Microsoft five
or six years ago when it went online at
Twitter it was retrained by the users to
utter
um uh extremist language and sexist
language and it had to be shut off
because it was flooded with these
utterances by users and then it copied
their behavior so this can be induced
but to teach a stochastic model to
answer a certain special question
exactly is almost impossible especially
when the model is very big so so these
models are just approximative sequence
models they don't understand anything
and what bell just told us is a good
example for it and for those who aren't
regularly hearing language of stochastic
I know David Scott one of our presenters
who's very keen on economics will say
that in some contexts it's just Posh
talk for guesswork but you're here
talking about it in terms of the the
hard maths at the center of your book
aren't you you're talking about it as
referring to the kind of system where
the whole world is happening at you and
you just have to deal with it without
Computing in a straight syntactic line
as programmed we when we talk when we
say when I just said sarcastic system I
mean really that the training type of
the AI so to to today's AI systems the
one that create the big hype are trained
using stochastic approaches so this
means that they're basically given a
huge set of data from which they learn
patterns or from which patterns are
distilled and these patterns are then
applied in in novel situations and this
works really well if and only if the
pattern of data that was used for
training is also is the same as the
pattern that is encountered later upon
the usage of them all and so when that's
the case you have the models can be
wonderful and can be super successful
and can perform better than human beings
but if there's a deviation from the
training pattern
um then they fail miserably and it's
very hard to correct them did Barry want
to comment on that
um I guess I wanted to
um
draw a quite General conclusion in in
regard to the general thesis of our book
from what uh we're talking about now so
AI can only work with simple systems but
these system for systems can be huge so
the English language
um
it's not a simple system
but you can create a simple system which
is a model of the English language and
which is very very large and Powerful
that's how Google translate works it
turns the different languages into
simple systems and then it can build uh
codes which enable them to be translated
between each other now chart GPT has
Crea has created a simple system out of
knowledge on the internet basically
which is certainly not simple and which
is changing all the time but it does
this by creating a temporal cut
it doesn't have information after I
think it's 2021
and that means it could never replace
Google
because Google will often be required to
answer questions about what's happening
four minutes ago or four hours ago and
chat GPT if you ask it for questions
about very recent Affairs we'll say I
apologize I only have information up to
2021. the reason it has to have a cut
off is because it's not going to have
anything
static which it can build a simple model
of so that they can use uh computational
tools to process in the way that
Europe's just described and that's yet
another reason why chat GPT is going to
be making all kinds of mistakes and it
will be making similar kinds of mistakes
even when it's gpt4 which is used as a
basis which will have many more data and
I think we should underline what jobs
has just said
many people in the AI World think that
if we just have more training data then
we will crack ever more aspects of
intelligence that we have hitherto not
been able to crack but that's not true
the size of the training data is not
relevant what's relevant is it's
representativeness it has to be
representative of the entire Target set
which is open-ended not a closed world
and that is always impossible when we're
dealing with systems which involve
organisms like human beings the core
property that that makes this saw is
that they are the process that happen in
animate systems are non-egotic and that
means that they don't create repeating
distributions and so if the distribution
always like for example simple example
are is the pattern of each single wave
that occurs at the English Coast
so since England emerged a long time ago
there have been
a huge number of waves
which arrived at England's Coast but
none of them is like the other each one
is unique
and so and so this is a good example for
a system that that no people don't think
so much about which seems rather simple
but it's highly complicated and even if
you would make movies at a very high
resolution of millions and billions of
waves still we couldn't predict how the
next wave would look like at a molecular
level
and this is this gives you an example
for for complex systems in in in
inanimate nature and and that tells you
why mathematical modeling of complex
system is always only an approximation
this approximation can be very powerful
in in some context it can also be
dangerous
um we can talk about usage of AI and
warfare if you're interested in this but
but
um it still is based on the design and
usage by humans so we've rather nicely
Hit Upon a couple of the other Concepts
I wanted to bring in here
um one relating to language artificial
translation and artificial interpreting
that is voice translation and the other
being this key distinction between
inanimate and animate which is in many
fields of study including Linguistics a
key concept literally meaning not having
a soul and having a soul respectively
because he also was just sketching out
there when things become animate there
is no predicting the individual
components that go into them now a
moment ago Barry was talking about uh
machine translation and that's a term
that's more common in my profession of
translation and interpreting it's more
accurate than to say artificial
translation people who haven't any
background and this will have got a
sense from the first part of this
interview that a machine is a model for
the purposes of this discussion a model
of reality not reality so for the whole
time since your book mentions 2014 since
Google translate and its competitors
like deep L by langanchite being German
it's better of course
um since they came to maturity just
getting up to a decade getting on for a
decade ago now people have been struck
by how well they do in some areas and
how awfully in others I'm a Bible
translator and a literary translator the
things I do would never go through deep
l or Google translate although I have to
confess like the whole of the profession
I have the dirty secret of using them
for the legwork I remain responsible for
the end product much like we like to
compare ourselves with pilots and
surgeons in that you have to have tens
of thousands of hours getting the Habit
into your muscle memory after you get
your qualifications before you're any
good to fly solo right so a machine can
do the simple operation to flying in
clear uh air or or doing the not too
challenging parts of the operation or
doing the boring bits of a translation
but you can't do any of the human
intensive bits you have to be looking
over the machine's shoulder and so about
10 years ago I started to get pinged as
a freelancer by companies promising to
build translation and in the end voice
translation so interpreting systems that
would be good enough to be used at the
United Nations and they all fall over
they're all predicated upon this idea
that
um you the the paid monkeys are going to
fill in syntax cards and in the end the
whole English language we've just heard
it's a very complex system is going to
be reduced to syntax and all these
annoying variations that these pesky
humans use in their wording
is going to be reduced uh so a sentence
that starts with
um although has to be rephrased by a
human to one that starts X is true but Y
is not true then supposedly the machine
has got the full syntactic model but
your book points out the machines fall
flat at a much earlier State than that
and this goes right back to NSA and gchq
in the 1950s using systrand which is
still available as a machine translator
to process a lot of Russian interceptive
material to get from the semantics in
other words what the speaker or writer
is getting at to the syntax
isn't going to work
right let's take a very simple sentence
of German such as I might hear at a
conference that I'm interpreting for
let's say that the speaker says at some
point in a new paragraph
is
right
supposedly that's syntactically
reducible so that is will be reduced to
their is or there are
but that's not how I'm going to
replicate it generally right so I might
actually like some conference
interpreters use some of the logic
symbols that are featured in your book I
might use an upside down capital E there
exists a logic symbol in the margin of
my notes to tell me that at this point I
have to predicate something I have to
say it exists but when it comes to the
end of the speech in German if I'm
working in consecutive mode and I then
have to speak English to the audience
I'm going to be reading the room
at that point before I decide how to
interpret it if I see that it's a bunch
of non-native speakers of English or
native speakers who are half asleep and
who need a bit of a jolt I might go into
Jack and Jill mode of English and say
there are several reasons why not and I
would use the intonation as well that
says listen up guys this is a new point
if I'm in full flow and I see that the
audience is with me and hanging on the
edge of their seat I might start with
the predicate and at the end of the
sentence say and there's no end of
reasons why that won't be the case right
so there's infinite numbers of ways of
saying things
from German to English and it's not at
the syntactic level the computable level
that the problem resolves
resides it's at the level of what am I
getting at what are my feelings and
above or what is my will in this
conversation what am I trying to achieve
and so you're quite confident the pair
of you that given another decade we
won't see more of this asymptotic shoot
upwards at one point in the book you say
that will you quote an author in the
introduction to saying that what looks
like a curve towards Infinity often
turns out just to be one of those long
s-shaped curves and it might flatten out
and you're fairly convinced
philosophically that that's the way it's
going to be we're not going to carry on
for a few years and then find that
interpreters are completely replaced I
gave a talk a couple of weeks ago in Sao
Paulo to a big German software
conference and I gave the talk in
English but there were two
um uh simultaneous translators
Brazilians
in Portuguese yeah they were translating
my talk into Portuguese most of the
audience had headphones
and um but both of them wanted to have
lunch with me they were they were
basically they wanted to kiss my feet
because I had shown why they would still
have a job in the in the next five or
ten years and we truly do believe that
so the GPT 4 will create something which
in some respects is slightly better than
gpt3 but it will still have some of the
same problems and um and I think we need
to deal with the distinction between
different sorts of audiences when we
evaluate these phenomena
so when we look at GPT we're trying to
find ways in which it goes wrong or when
we look at Google translate we're trying
to find way ways in which it goes wrong
but most people are happy if it seems to
go right and they will be happy over and
over again because they won't be looking
for the errors in fact I didn't notice
when I first asked GPT chat GPT about
myself the the errors
it was only when I looked more carefully
on the next day that I realized that
they were confusing me with another
barriers I I would like to add that um I
think we are already seeing in machine
translation we already seen a saturation
and the saturation comes from the
problem that we have not only the level
of syntax which which machines can only
um uh dealers in a limited way but we
also of course have the layers of
semantics and tax pragmatics so that
there is also
um the context which a sentence creates
for each other's situation which the
text occurs and so on to to interpret
this correctly you need and you describe
it really well unless you need
intentionality so your intentionality
allows you you will and your
intentionally derive from you will allow
you to to understand what does the
situation mean for me what does it
probably mean for the others you need
intercept activity you need to put
yourself in the in the shoes of the
other thing aha what is the relevant
part for them and so on and and if you
are a good interpreter and especially
also in simultaneous interpretation
you're able to do this very fast and the
good results means that you have
captured the intentionality both of the
speaker and also the probable
intentionality of The Listener so which
will let you interpret in a different
way given even if you interpret the same
speaker uh to different listeners you
will give the different interpretations
and different translations and all of
this you can't model mathematically and
so therefore this process profession is
not endangered at all basically Google
Translate for translators and I
translate a lot of texts as well and
have all I've always done it in my life
um I I use it now as a kind of
dictionary that can also Trend head to
translate phrases or to give
approximations for phrases and and
sometimes sentences but of course
um the real work of the translation
always has to be done by the human who
understands what's going on who
understands the situation and so so this
is an area where um where AI can't
replace human beings
um
where it can do with where I I works
best is when you have a situation that's
completely repetitive like an assembly
line
um or also Warfare in which um certain
patterns of uh destruction can be
repeated and automated now so there are
no approaches involved that you use
um armies of drones that are not as
precise as human being in their
destructive work but that will basically
clean out the whole area out of the
tanks that are in the area so these
systems are now
um being developed and they will soon be
deployed and um there will be very very
effective and menacing and terrible but
they will
um they will not be intelligent they
will just be a enable a new form of
destructive Warfare so so this these
things happen and we have to think about
them they may have to be regulated we
have to cope with them but it's much
better to do this from a point of view
of truly understanding what is
mathematically happened shall we in the
final section of this interview then
talk about the hierarchy of Sciences
because Yorks has just ended there by
saying what's mathematically possible in
the introduction you talk about three
levels of impossibility of which
mathematical impossibility is the most
interesting to me physical
impossibilities has to do with the laws
of physics of course and technically
impossible has to do with the state of
our development as humans the third
mathematics and this only really dawned
on me very recently when reading a
history of science written by an
objectivist a devotee of aim Rand I have
question marks over her and her school
but be that as it may this objectivist
summary of science feel free to disagree
with the conclusion here gentlemen but
it said mathematics itself is very
deeply human uh that the problem with
certain philosophical traditions was
that it wasn't thought to be human but
it is because it's how we relate things
in the world to each other being an
objectivist this historian of science
went further and said that mathematics
is how we relate quantities of things to
others in the world so it's a model in
our mind so maths model mind getting
closer and closer together than the
Layman might care to think in other
words mathematical impossibilities isn't
just things that the Universe says no to
they're things which won't go because we
uh at least under God if you're a
Believer we are in a sense running the
universe we are understanding what works
and we're telling we're winding the
machines up and telling them to go so
it's something the mathematical
impossibility there is no way around it
by waiting for further technical genius
developments am I right I agreed with
some of what you were saying there in
fact
we're writing at the moment a paper uh
which will be the beginning of a series
of papers if everything works out which
defends the view of mathematics along
precisely the lines you just described
so mathematics like physics is a part of
human culture it develops historically
with time
um but it it hand in hand thou with goes
to the discovery of necessary laws
and some of these necessary laws will be
internal to mathematics and some of them
will be laws pertaining to the
application of mathematics and so one
necessary law which we've been talking
about all morning or all afternoon in
your case uh has to do with what
computers can do and computers can only
execute programs if those programs
require computations in the
mathematically defined sense which are
called Church during computations
computability in the church during sense
which is very limited to a very small
number of very boring trivial operations
but which when you have a big enough and
a powerful computer can be applied to
bodies of data which have trillions of
data points and so they can achieve
great things so chat GPT achieves the
great things which it seems to offer by
simple very very simple steps applied to
long long long vectors of ones and zeros
there's no knowledge no will no
semantics there are just very simple
steps applied very quickly in a very
powerful way so these long strings of
ones and zeros and it will always be
thus there is never going to be a
computer which is not working like that
that's what
uh that's what e Turing held and that's
what everyone will continue to hold and
that is the weak point in our book
because many people who are Visionaries
they will say oh mathematics may
discover a new way of computing which is
not Church during Computing it may be
some kind of uh organic Computing or
non-digital Computing uh analog
Computing and when we have that then we
will have artificial general
intelligence and that's where we draw
the line that's where we have to say
well maybe you're right but we're not
holding our breath yeah I would go a bit
further than Barry so first of all
mathematics is of course a part of our
culture but it's also
um it's preconditioned it's a structure
of our brain and so the limitations we
have in mathematics which are which
mathematics is much less limited than
Turing computability right so true
compatibility is a subset of mathematics
mathematics is broader and we could
think of machines that could do more uh
mathematics and today's Turing machines
can this might really evolve however we
still have the limitation of mathematics
itself where does this limitation come
from I think it comes from the human
mind or the Mind Body Continuum as we
say in the book that the human mind is
limited structurally by its biology to
certain to a certain level of complexity
and the laws the necessary laws that
Barry has um just alluded to which we
have in mathematics and physics I think
these necessary laws there are um
related they are determined by the
maximum complexity that we can
mathematically figure out or imagine and
so um if we look at
um the most advanced part of physics
like Quantum field Theory we very very
clearly see that Quantum field theory is
limited by our mathematical capabilities
now I believe that there are that they
are consequence of the structural
limitations of the brain that we have
and that evolved
in the process of human evolution and so
yes this Evolution might go on but we
are not to expect
exponential changes of our mathematical
capabilities and even if we had them
that we would still be completely
overwhelmed by the number of variables
um and the complexity of their
relationships that occur for example in
the human mind or even in uh in the
brain of an animal so so I think that
the mathematical limitations are there
to stay and that it's much better as a
scientist to to to select the fields of
study with these limitations in mind and
that is what all the clever and great
physicists of the 20th century and also
21st century and all the good
mathematicians have done they have
focused their minds on problems that are
accessible
um to mathematical thinking and they all
know the great ones all know very well
um how limited this is and they have all
said it and those who who make us
believe that artificial intelligence can
can be created and that machines can
become more intelligent than human
beings are not these mathematicians and
physicists there's one exception of
Stephen Hawking but Stephen Hawking I
think never took the time to think
artificial intelligence fully through
but and he also has a tendency for
sensationalism but other than him I know
no really great physicist or
mathematician who has ever who believes
in the feasibility of artificial
intelligence because all of them by own
experience what they do when they do
mathematical models of reality they know
about the limitations is it perhaps part
of the problem that physics and
Mathematics have become much less
experimental much less doing in the real
world for perhaps a century and have
become much more deductive much more
theorizing for which obviously there is
a place but could it be that the
induction the the keeping of a whole
model of the world in our mind and
refining it as we find new facts has
fallen by the wayside it was there
obviously as we built up from classical
geometry to algebra astronomy physics
the whole line you mentioned in the book
that biology is is an odd man out in
this because as you mentioned a moment
ago and in the book even animals let
alone people have a Mind Body Continuum
so you can't model what the body's
feeling even animals are placing
themselves to some extent in the in the
person or the other animal that's their
predator or prey and that that can't be
modeled you know so but even where it's
just inanimate phenomena in the world
have the Sciences at this point started
Naval gating with their theories that
they're unable and unable even to see
what they're missing by not inducting
more before Barry answers this just one
very important remark here AI as its
practice today is highly inductive
so the the applied artificial
intelligence research that has led to
GPT and many many other applications
highly inductive because it's using
empirical material to create to
automatically create mathematical
algorithms or equations so it is highly
inductive
um how so but you are still you are
still um uh I think
um pointing at a very important problem
and that is that the reflection
um of science uh by theoreticians has
become detached from reality to a
certain extent and and this has this is
create this is in the humanities this
has this is a huge problem that has been
ongoing for quite a long while now but
even in physics itself there are no
areas with physicists have detached
themselves from the from experimentation
and are claiming that they that they can
produce pure theories of validity this
is a very dangerous Trend in physics but
it I don't think that it explains uh the
the hype around artificial intelligence
this hype rather comes from people from
practitioners on the one side who don't
understand well enough method the
mathematics of what they're doing on the
other hand of course from from
entrepreneurs and politicians who want
to exploit AI for certain purposes are
there no worse intentions at play than
that yourbst and I bounce that back to
you because in the previous uh interview
you gave about your book with Jamie
Franklin on irreverent podcast you made
no secret of your Christian profession
and you've talked about the there's
different intentions there may be here I
asked because
the most famous science fiction scenario
in the world and I don't know it was
influential in Germany as well was Isaac
asimov's uh series foundation and of
course the classic three volumes are
written in 1940s and 50s they're part of
this
california-based exuberant of the
post-war era in which a number of
questionable characters are writing
science fiction some go on to found
Cults or to become drunk at drug-addled
Maniacs later including Aldous Huxley of
course who oversees that scene and
approves of it as it were but others are
more sober minded like I seem often have
a better intent for mankind although I
have to say he was brought into science
fiction by Robert Heinlein who was a
senior member of an out and out Satanist
group the auto template orientalis and
it was Heinlein who told us him off
after the war you'd better write science
fiction interesting detail but Asimov
lives until the early 90s and at the end
of his books uh the the last sequel he
writes before his death has his favorite
character the robot Daniel Oliver who in
the mid 20th century is doing what Barry
told us the robots failed to do which
was to navigate their way around the
world poor Daniel Oliver who's is the
real hero even more than Harry Selden
there at the very end of the whole
series so he's a spoiler if you haven't
read the series uh he summons the humans
who've been trying to unite the Galaxy
in peace and says well I was behind the
drive to artificial intelligence uh I
who am myself a robot
um I tried to get through physics and
through biology everyone to will the
same will to get rid of this annoying
problem that people have their own Wills
I can't cope with that I've now managed
to engineer the universe or at least the
Galaxy rather to a point where everyone
wants the same thing I even set up the
environmental movements as the robot so
that people would feel an impulsion to
want the same things okay you could you
can say with Goodwill asimov's got good
intentions here but that the whole end
of this of this Saga which I think
leaves its Mark deeply on other sci-fi
and people who come out of that cultural
media like curse file is okay we have to
get everyone pointing the same way we
have to have them sharing the same will
and feelings in other words they become
a single Mind Body
so it can we discount the possibility
that there are some
actively dark evil actors in the field
who want AI or who want to robotize the
human brain to do just what Asimov says
his robot wants to do at the end which
is having failed to build a smarter
model of himself using circuitry at the
very end he has to take hold of the most
advanced human in the Galaxy he can find
and basically steal his brain
um in order to go further with the plan
so how much of that is going on right
now in AI I would say so from the
intentions perspective there may be
people who have this intention and this
is it if if you allow me to make one
religious remark here Barry in Matthew 4
The Temptations that the devil sets up
for Christ there are there's they are
around power and bread right creating
bread for everyone and having one world
power that governs the whole world so
that peace can be established and that
we can create heaven on Earth and I
think that that this is not for nothing
that these are the big Temptations
because because this seems so nice but
we know that we can't achieve this and
we know that by by no means even in
North Korea we cannot have everyone
intend the same thing even with the most
cruel system the most violence and and
abuse of power this can be achieved and
if there are people who want this where
they are bound to fail and the question
is just how much pain will be will
happen on the way to failure to failing
um however nothing of what you described
from the from the foundation zaga is
currently happening because all of it is
so far away from mathematical physical
and Technical feasibility that it's just
not happening so give you an example
this firm by Elon Musk to create brain
implant ships has failed so miserably
that he is now sorry that he is now
um that is now getting back to just
creating good old Basel ganglia
simulating chips which have been around
since 25 or 30 years so this is so
um far away from feasibility that it's
just not even
um the intent may be dangerous but the
way to to to try to create this will not
go via AI but much more traditional ways
of um uh exerting power upon human
beings I'd like to to
volunteer a more modest thesis uh more
modest than what both of you uh just
speculated about so I think that there
are limits to Evolution there will never
be nine feet tall humans because you
just can't make the biology work in such
a way that those humans would be
selected for
and this applies not just on Earth it
applies on all conceivable planets
and it applies not just to height it
also applies to intelligence so there
will never be considerably more
intelligent people than the ones we have
now there will never be a people who are
cleverer than leibniz and Newton who
will evolve and establish societies and
neither here nor on other planets and
this has the beautiful consequence that
we can explain families paradox
the reason why we don't see aliens
regularly landing on Earth flying in
spaceships which would go faster than
the speed of light is because they're as
stupid as we are
and all the governments on it are just
as stupid as we are so they'll never be
able to create these big effects which
Alex
has dreams and nightmares about it will
always be just stumbling through from
one bad outcome to another which and we
pick up pieces and move on to the the
next stumble let's round off then with
some practical encouragement we've
already consoled those who are Dreaming
Dreams and Nightmares uh people in their
own line of work may be told whether
they're in management or at the coal
face AI is replacing you or your boss or
your underling or part of your job it
may be framed positively it's taking the
donkey work off you whether you're a
soldier or a lawyer or a doctor
uh people may have their qualms about
that perhaps them also having heard this
or at least they'll understand it's not
really feasible
what kind of
uh educated doubts should people sound
in their own meetings at work in order
to bring a measure of reality back to
the conversation and D hype or perhaps
in the longer term what kind of more
rounded figures should people in their
own line of work be seeking to produce
so that that's the next generation of
leadership will not be enticed by the
huxturism that's prevailed for so long
with regard to AI I think that there are
two for the normal Workforce person the
best thing is to look at Industrial
Revolution as it has happened in the
last 150 years and so industrial
revolution has has certainly
um mechanized the part of human work and
I think most of this was really
beneficial because dangerous and very
painful work has been taken on by
machines and um new work opportunities
have been created
um so I think that that this will
continue but it won't continue and this
is the second point at a speed that is
comparable to the mechanization of Labor
in the in the second half of the 19th
century at that time there was really a
very fast mechanization of human Labor
uh for example in the in the um cloth
manufacturing and Industry and and this
this is not happening because we have
had the AI technology that is now being
developed and deployed we have had it
now since 25 years now and since 10
years there has been a huge or 15 years
there has now been a huge progress with
the neural networks but we haven't seen
a big change in productivity
and so that means that the usability of
these Technologies is fairly limited
otherwise they would now already be used
massively in in various Industries and
they are being used but the effect on
productivity is quite modest and so this
this is the second point to point to is
that it's uh it is part it is part of
historical development but it's not as
extreme and radical
um as uh it was thought and and the
other advice one can give is of course
education right
because education always helps to cope
with changing environments
Barry you're involved in education so
your contribution on this is most
welcome as the last word so for a long
time people were arguing that just a
simultaneous translators would soon be
out of the job because of computers uh
so ontologists would soon be out of the
job because AI can create the ontologies
and do a better job than humans uh all I
can say is that all my students get jobs
immediately and they're earning some of
them are earning straight from uh PhD
more than I am
because there is a need for human beings
who can build ontologies and I I um I
take comfort from that I think if you
have a coherent
problem to solve in relation to complex
systems and every science every data
Gathering effort every uh new
experimental method is a complex system
you're going to need humans to work out
how to make use of the results
so I'm I don't worry and I tell my
students not to work this has been an
extremely rewarding conversation about
why machines will never Rule the World
by yob's landcraber and Barry Smith
published by Routledge in its philosophy
series but don't be put off by that if
you've never read a book knowingly from
the philosophy section of a Bookshop or
library before make this the one because
if you read it chapter by chapter and
there's a guide in the introduction to
which order is best for you depending on
what kind of reader you are you will get
through it even if you have to skip a
couple of equations I would very much
recommend that people read that book and
I hope that we'll be talking to both
yorkster and Barry again thank you very
much Alex thank you Alex
