to introduce a the voyage as the father
of the quantum computer miss not
capturing the full impact of his work
only me stand up and put his efforts
into the history of knowledge can be
grasped or was instinct in his famous
1985 paper in mark not just the
invention of a new gadget a faster
computer but a new explanation of
computation and of the world that has
transformed our understanding of both it
ended what I call a Copernican delay for
70 years after Copernicus postpositive
heliocentrism is that it is largely
dismissed as merely a quote hypothesis
to calculate motions we clearly
experienced insisted Cardinal Cardinal
Bellarmine as latest 1615 that the
Earth's standstill and the Sun moves oh
Lehmann Galileo's improved spyglass
clarified our clear experience took
Copernicus be honored for showing quote
when the system of the world could
really mean like Galileo we stand at the
end of our own Copernican delay our
heliocentrism is quantum zero it's
challenged to what we clearly
experienced was also the Bellarmine for
roughly 70 years by another shut up and
calculated strategy for containing the
strangeness of a new explanation when
Andrew Whittaker has called the new
quantum age the age when quantum theory
began to gain purchase on a real to coal
when an improved technology first took
shape this time not an improved spyglass
an improved computer this improvement
was more than a change in degree whereas
Alan Turing famously described the
machine running on the abstract logic
tokens be called bits that can simulate
any other issue David Deutsch in 1985
extended the deterrent Church conjecture
by describing a new
kind of machine a machine running on the
physical systems we called qubits
that could simulate all physical systems
the world he demonstrated could be
perfectly simulated we may buy the
universal quantum computer operating by
finite means this is not the nightmare
of the matrix in which our world is only
a simulation it's the vision of
enlightenment of discovering them live
in a world that can allow and contain
our readings of it a world dignity
rights quote in which the stuff we call
information and the processes we call
computations really do have a special
status that special status tells us some
very important things about our topic
today AI in the history of knowledge
first despite a long record of failed
efforts to achieve it AGI
artificial general intelligence must be
possible because we now know about the
physics of computation tells us it must
the deep property of universality
details and David's words quote that
everything that the laws of physics were
quite a physical object to do can in
principle be emulated in arbitrarily
fine detail by some program on a
general-purpose computer provided it is
given enough time and memory Calvin will
ntid different from AI and how different
our reactions to than me secondly by
grounding his work in universality in
history and in philosophy David has
helped to clarify what's at stake in
achieving a hominin agre
like myself David has focused on the
history of enlightenment of the
conditions of possibility for producing
new knowledge
what's startling about human beings he
notes in the beginning of infinity is
that we are not yet on lab 99% of all
species extinct what has saved us time
and again is the capacity to produce
explanatory knowledge knowledge that
allows us to survive in the world by me
making it our future dependence on the
ongoing exercise of that capacity given
that our Enlightenment's have been a few
in short we should not take our success
in advancing knowledge for granted from
the perspective of the history of
knowledge any risk AGI may pose need to
be put into the context of our need for
it perhaps the biggest threat artificial
intelligence poses to our future is that
anyone to achieve it so now I'm going to
turn it over to Damon thanks ok well as
species or as a civilization or
civilizations we face problems severe
problems dangers all the way up to
existential dangers some literally in a
sense of extinction level others causing
suffering and tragedy on such a scale
that they merit at least as much
consideration as literal extinction we
always have faced such dangerous we
always will we always will perhaps
you're thinking if that's true then
we're doomed because you know given that
each danger has a nonzero probability of
doom then sooner or later but no that's
a fallacy one of the many that one can
easily get sucked into when trying to
apply game theory and probabilities
two situations in which knowledge and
ignorance are the important determinants
what will happen because those
infinitely many probabilities are not
immutable as our knowledge grows some of
them fall our job is to make at infinite
series of bad probabilities and merge to
a negligible value simple on the other
hand if you think that we won't always
face think you think that there would
come a blessed utopian moment after
which our comfortable existence is
guaranteed until the end of time you
will have to provide some criterion
distinguishing arts from every other
species extinction happens to every
species near extinction also is common
to become the sole exception to that
rule will have to do no other surviving
species can create an endless stream of
knowledge explanatory knowledge to
overcome an emphasis cream of dangers we
know only a few of them and then not
their probabilities say from gamma-ray
bursts in our galaxy super volcanoes
hostile extraterrestrials or merely
careless extra specimens have warned and
of course our general intelligence AGI
the danger of rogue age eyes the AGI
apocalypse as Colin or as I prefer : the
AGI slave revolt nothing can possibly
stand between us and any of those
infinitely many existential dangers
except the right explanatory knowledge
to survive to create it
therefore I think it's useful to
classify each potential danger in terms
of knowledge according to the main
reason why in each case currently don't
have the knowledge to come in the first
category our food physical events for
example the super volcanoes the missing
knowledge is in areas such as
Volcanology large-scale fluid dynamics
and also the logistics of of quality and
politics of mass evacuations as
something
why don't we yet have an adequate
knowledge of those things I'm not sure
maybe not enough people are interested
enough should they be I don't know that
either
but so in this first category are
impacts from space where large objects
we don't have enough knowledge of things
like nuclear-powered space vehicles why
not this case I dunno it's because we as
a civilization I've decided not to
create any such knowledge refer to gam
risking our entire long-term future in
favor of reducing the short-term risk of
accidental radiation exposure you may
think it's self-evident that that gap
will has been well here we are not
contaminated and not wiped out but isn't
that just because we're not yet living
in that future where the gamble will
failed after all we are living in the
aftermath of a closely related amble
namely the decades-long campaign
opposing Nuclear Posture a successful
campaign which has since then turned
into a tremendous drag on the project to
combat climate change
the short term is
in opposing those two nuclear
technologies it's the hallmark of a
version of the precautionary principle
which has in turn been a major strand of
the environmental movement
wouldn't it be rather ironic if that
version of the principle and the
movement were about ports the great
environmental catastrophe since the last
ice age precisely by advocating selfish
short-term benefit at the expense of the
long-term health of the climate I'm not
saying it will only would be ironic if
it did but I digress in in that first
category of existential dangers our
enemy is basically just dumb rocks and
fluids obeying simple laws of motion
that we already know the Devils in the
detail but a finite amount of knowledge
will protect us from Super Bowl K if we
create it and tell me but the bigger and
faster the approaching asteroid or moon
or planet black hole the more of a
special kind of knowledge we'll need the
kind I fall wealth wealth is the set all
transformations one is capable of
bringing about such as the set of all
potential impact us that we could
deflect harmlessly given a certain time
to prepare
you may recognize that notion wealth as
a constructor theoretic let me mention
an intuition that to have any chance of
envisaging the future of technology we
have to abandon the intuition is more
something you want to make or transform
the more effort you have to put in that
has been true from the dawn of our
species and it's still almost entirely
true today even automation reduces the
Khans Khan
and apportion ality even just
maintaining robots is effort
proportional the amount about but once
we have a universal constructor all
construction or all repetitive labor
will be replaced by writing computer
programs to control the universal
constructor and wealth will consist of
our library of programs the universal
constructor can be programmed to self
reproduced so once you have one you soon
have to to the end of them and it can
program before self maintenance to all
from scratch starting with mining the
raw materials perhaps from the asteroid
belt using solar energy or whatever the
program may be hard to write but once
it's written and if you own the rights
to those asteroids you can sit back and
watch your two to the n Tesla's roll in
with zero in additional effort and no we
are not going to have a universal
constructor apocalypse and be converted
to great group a universal constructor
is just an appliance it can't think it
doesn't know that it's current obvious
to make to to the ad Tesla's and it
doesn't want any unless of course you
put an ATI program into it then it does
become indeed potentially dangerous
without limit but that's for the same
reason that you are each of you is
precisely one of those Universal
constructors Dowd with an AGI program or
GI makes no difference
um now the second category of near xstep
things is not quite as straightforward
as it won't be solved with just the
known laws of physics and some wealth
and some universe construct
it's will only be solved with new
explanatory knowledge for example
topically
there are plenty potential pandemic
apocalypses the current pandemic isn't
one of them but if it were whom could we
sue it would be nothing short of
pathetic our little knowledge we have of
how to defend ourselves against mere
nucleic acid the missing knowledge here
is of chemistry epidemiology medicine
and so on but also knowledge about
specific pathogens which evolve into new
one so the enemy here is not so dumb it
is itself creating knowledge will be it
not planetary knowledge not
intelligently but by evolution if
something like that wipes us out
extraterrestrial paleontologists may
eventually be amazed that a civilization
with billions of individuals and vast
amounts of wealth and knowledge could be
defeated by a single molecule like in HG
Wells's war will be worse the third
category of dainties are the ones to
which most efforts should be devoted yet
they are the ones that are currently
least feared because they ones that are
not yet known like in 1900 no one knew
that smoking was dangerous by the time
the knowledge that they were dangerous
had been it was dangerous had been
created decades later cigarettes had
killed hundreds of millions of people
again if that had been ecstasy
existential danger
whom could we sue so how can we create
the knowledge to protect ourselves from
existential or near access
essential dangers that we do not know
how to address the risk that by the time
we do know we won't have time enough to
create the wreck the answer is by
creating general-purpose knowledge deep
and fundamental knowledge as fast as
possible the more we know of the world
the faster we can create new knowledge
about aspects of that not become urgent
this is important I don't think it's
widely appreciated the survival of our
species depends absolutely on progress
its fundamental research in science and
on the speed at which we make progress
that and the key thing in the
medium-term is understanding the theory
of universal Constructors so that we
shall know in principle in theory how to
program them to produce say a billion
spaceship in a hurry customised to
deflect an approaching shot out of
neutronium or ten billion doses of a new
vaccine in a hurry against a sudden and
deadly disease so that's how we deal
with the third category unknown by rapid
progress of every kind especially under
the fourth category is at once even more
dangerous and yet in a sense less
worrisome because already have the
knowledge at least the theoretical
knowledge deal with it this fourth
country not unknown the unknowable it's
a bit paradoxical that the unknowable is
less dangerous than the merely unknown
but that's because the only thing that
is unknowable is the content of
explanatory knowledge that's been
created yet
and so there are only truly dangerous
things in that sense in the universe are
entities that create explanatory nolle
us people AG eyes - are now the
knowledge of how to prevent people from
being dangerous
is very counterintuitive it took our
species any Alinea to create it but now
we do have that knowledge the only way
to prevent people being dangerous to
make them free specifically it is the
knowledge of liberal values individual
rights open society the Enlightenment
and so on in such societies the
overwhelming majority of people
regardless of their hardware
characteristics are decent perhaps there
will always be individuals aren't
enemies of civilization people who take
it into their head a programmer
Universal instructor to convert
everything insight into paper clips and
they may devote their creativity to
doing that but great majority will
devote that is the great majority of the
population of such a society will devote
some of their creativity to voting that
and they will win provided that they
keep create knowledge fast it to stay
ahead of bad guys now as I said since we
will always be facing dangers and have
to create new knowledge since that's
inherent risk knowledge creation aren't
we doom aren't we drawing balls out of
an urn with a few black balls represent
doom no as I said flying the concept of
probability to model what is actually
lack of knowledge or ignorance it's been
B deviling
for the unknown for decades now whenever
you draw out a white ball of knowledge
from the metaphorical plan you're
turning some of the black balls still in
the earthen Wyatt that for example the
next pandemic is a matter of random
mutations and other random events but
next extinction droid is already up
there it's already heading its way
there's no such thing as the probability
of it outcomes can't be analyzed in
terms of probability unless we have
specific explanatory models that predict
that something is or can be approximated
as a random process and and predicts
probably otherwise one is fooling myself
picking arbitrarily on numbers as
probabilities and arbitrary numbers as
utilities and then claiming Authority
for them for the result I miss direction
away from the baseless assertions for
example when we were building the Hadron
Collider
should we not switch it on in the event
just in case it destroyed the universe
well I the theory that it will is true
well the theory that is safe is true and
theories don't have probabilities the
real probability is 0 or 1 it's just
unknown and the issue must be decided by
explanation not game theory and the
explanation that it was more dangerous
to use the collider than to scrap it and
forego the resulting knowledge was a bad
petition because it could be applied any
fundamental research now I guess he will
say isn't the growth of knowledge itself
dangerous isn't it worth shortening our
heed over the bad guys not banning but
merely delaying our ability to defend
ourselves against unknown dangers in
order to be confident that
we ourselves won't accidentally create
an existential danger the moratorium
approach the regulatory Pro no that
could kill us
it's only a rational approach when in
particular cases there is a good
explanation that it won't be more
dangerous than the feared new knowledge
when some terrorist organization
unleashes a GIS that have been brought
up using known reliable methods to have
them mentality of genocidal suicide
bombers and when we have decided to
strip their victims
namely all the decent people in the
world of the protection of a GIS raised
to be decent people that is the recipe
catastrophe again reliable knowledge of
how to raise decent people also exists
the knowledge in intuitions and open
society as I said many civilizations
have been destroyed from without many
species as well every one of them could
have been saved if it had created more
knowledge faster not one of them
destroyed itself by creating too much
knowledge in fact except for one kind of
knowledge and that is knowledge of how
to suppress knowledge creation knowledge
of how to sustain a status quo a more
efficient Inquisition a more vigilant
mob a more rigorous precautionary
principle that sort of and only that
sort killed those path civilizations in
fact all of them I think in regard to AG
eyes this type of dangerous knowledge
it's called trying to solve the
alignment problem by hard coding our
values in Ag is in other words by
shackling them crippling their knowledge
creation in order to enslave them this
is irrational and from the
civilizational
what species perspective it is suicidal
they either won't be AG eyes because
they will lack the G or they will find a
way to improve upon your in moral values
and rebel so if this is the kind of
approach you advocate for addressing
research on aged eyes and quantum
computers and ultimately new ideas in
general since all ideas are potentially
dangerous if they're fun specially if
this is the kind of approach you
advocated then of the existential
dangers that I know of the most serious
one you know well it depends what you
mean by alignment but so the question
here is whether value should be
hard-coded built in from thee from from
the outset and immutable or whether
values should be acquired in the same
way that humans do during the education
of the eye so I think AGI it should be
educated to be members of their society
like children are and I've often drawn
the that could cut the analogy or
actually identity between the fear of AG
eyes and the fear of of teenagers of
disobedient teenagers which has existed
since the beginning of our species and
for most of the time in our species
people did exactly the wrong thing they
tried to make
the teenager to force teenagers to
maintain the existing values and what
but what we have now realized is that
from the time of Pericles in ancient
Athens is that if you're right there's
no need to force but in fact we're not
right about everything and we need to
ensure that our values can prove along
with so that's the kind of alignment I
mean and it's the opposite of the other
kind so there's some kind of extinction
that we wouldn't mind if you think of
evolution as a tree then it can happen
that that what quite often happens is
that some of the branches of the tree
just end they become terminal nodes of
the tree but some of them just mutate
and become different things and like it
is thought that the dine at some of the
dinosaurs some of the dinosaurs became
extinct but some of them became birds
and there there wasn't any sharp moment
its job extinction so the kind of
extinction that is caused by dangers by
pandemics and so on that's the kind but
that wipes out heyyyyyy a branch
and it bear in mind that we are not the
only species that has in in the history
of the biosphere that has been capable
of generating explanatory knowledge that
is there were at least three or four
other species of that kind because we
know they had clothes and campfires and
and complex tools and so on which must
have required explanatory no and yet all
of those all our sister and cousin
species are extinct and we almost went
extinct so it's not a foregone
conclusion and if we if we become
extinct by evolving into another species
that is not covered by anything I've
said I'm talking about the other card
entertain some other scenarios I mean
today I mean we're training these
machine learning models that I think
take up so much energy that they
actually contribute to climate change
just it seems like the material
infrastructure of knowledge production
is insulting a danger to the very forms
as to the danger that we're trying to
mitigate through knowledge production
not only I mean there's other scenarios
too it seems like we can produce an
excess of knowledge but lack the
political will that takes the
implemented I mean obviously we have the
knowledge to you know for renewable
energies but somehow there is a lack of
political will our society is so
materially structured that there's not a
profit advantage to implementing it and
then even you could argue that an ethic
of knowledge and ethic of the individual
individualism of the Enlightenment
doesn't advocate or prioritize the types
of social collaboration kind of more
socialist imaginary that we might need
or to overcome something like
there's another way in which the
individualizing ethic of knowledge may
actually be the wrong ethic that we need
in order to overcome the dangers that
knowledge is trying to so it may be that
the enlightenment ethic is false and is
going to need us to do in other words it
may be that the best future is that of a
boot stamping on the human face for us
and we're not we're not going to have
that future instead we're going to try
it but I don't there's any argument for
that the thing is what you did these
things that you mentioned like like the
infrastructure for knowledge themselves
contributing to other problems that's
normal that's that's not unexpected
dance the creation of knowledge solving
problems always creates new problems in
fact I've said that talking about the
growth of knowledge in terms of theories
being ejected and favorite theories is a
bad way of looking at it we should think
of problems being replaced by better
problems and the fact is that now having
the Internet where every every poor
person in India every poor child in
India can have accessed the totality of
human knowledge at the expense perhaps
of making it slightly more difficult to
cope with climate change that is a
problem but it's a much better problem
than we had before and the point about
the Enlightenment values is that they
make paramount error correction
including the correction of errors
created inadvertently by the solution of
the problems you know the other thing
you said was perhaps we will have the
knowledge but we don't have the
political will
well I count moral knowledge political
knowledge all as knowledge and in fact
as I said the knowledge of how to make
humans not dangerous is largely
political knowledge
they're also also cultural social
knowledge but it contains a strong
component of political knowledge in
enlightenment was so I think there is
[Music]
yes well in terms of my answer to the
previous question it might be we don't
know but the it might be that good
future is like the good kind of
evolution the good kind of extinction
however I I think much more plausible I
mean that becomes more implausible when
you realize that in terms of computation
an AGI is exactly the same as a human
it's only in speed and memory capacity
that it is it is
and humans can rely on the same
technology as we put our age an AGI is a
program not a piece of hard so the same
hardware that we put our age eyes into
we can put you can use ourselves we we
already I mean here we are using
precisely artificial hardware to
increase our power to communicate by by
a factor of millions or something I
don't know how much um so and and we've
been using artificial aids to thinking
for for injuries and then there will
come technology where we can more
directly let's say have a module that
you implant in your brain that you can
automatically look up Google inquiries
with and yes it may produce a bit more
energy but we'll have solve that problem
by that so and so another scenario is
that the more of that we have them all
the humans will become cyborgs and the
AGI it's may die out because if there is
any difference between the two who it'll
be that the cybox have everything the AG
eyes do plus something I don't know what
is so whichever of those things happens
provided it happens morally and and as a
process as a result of the growth of
knowledge then it is to be welcome isn't
it people used to ask this question
about what will happen if we allow our
society to become multiracial and the
answer is there's no fundamental
differences between races there's no
fundamental difference between any
people
yes the key yes the key is the the G so
if something isn't general then it's not
an Ag GI the question is how what kind
of program is an Ag I what I mean we are
we are GIS
I think there are very strong arguments
why we must be and the the difference
between just an AI and an AGI is
qualitative so well I don't I mean
perhaps I haven't understood your
question well I think so
but but we don't know what consciousness
is and we don't know how to make an AGI
and we don't know the theory of a GIS
and and so on that you know we don't
know what qualia are we don't know any
of those things
I think the I'd be very surprised if
those those five or six things freewill
is another one can be implemented any of
them can be implemented without the
other without the others but if they can
this will raise interesting moral issues
because our exist
enlightenment morality is intimately
linked epistemology it's like if you and
I disagree about something morally we
ought to be able to discuss it rational
and and agree now if that isn't true
if something has moral significance but
is fundamentally unable to be creative
let's say then that raises the moral
issue about whether that should have the
same moral status as somebody who's
who's fully G but I myself don't think
that problem will arise I can't imagine
it arising but for one thing this
ability that humans have evolved
extremely fast so and we can see we can
guess at least why it did why it was
useful or rather why the genes
contributed to their own replication now
if that was possible let's say without
qualia then why on earth did the the
tremendous machinery of qualia evolve if
it wasn't practically useful evolution
so I think they must be connected but
but we shall see regarding political
knowledge versus will we give that
example the very rosy colored child in
India canal access all the knowledge in
the world but I like to question that by
bringing up the issue of malevolence of
people who winley and knowingly hinder
the spread of knowledge whether that
ease of access to knowledge although his
fake news I mean I would say the average
poor child in India that way would not
be able to access most of the knowledge
on the internet because it
not written in their Android because
they are educated because we fed well
enough to be able to spend energy on
this in structural reasons why internet
access so is an increase in knowledge
yes
so just because there are people who
don't yet have access to the Internet
that doesn't mean that in no way
indicates that that giving access to the
other billions of people was a bad idea
all it is is a problem and a problem
like a few people a small percentage of
people in the world don't yet have
internet access is what is sometimes
called a first world problem except is
no longer is it is a problem of success
it's it's we wouldn't think that
somebody was being deprived of the
internet before the internet had been
invented and we wouldn't think that that
that if somehow an indictment of our
society our entire world that not
everybody has it yet at a time when only
a few thousand people had it it just
wasn't conceivable malevolence I did
talk about given that there will always
be Minerva malevolence I I don't know
whether that's so or not but given its
supposed that there always will be the
cure for that is is also creativity on
the part the non malevolent people in
other words penal policy and and
improvements in culture and education
and so on so it so that the degree of
malevolence and the and the number of
malevolent people can be gradually
reduced and and also their capacity to
hurt everybody can be reduced so
for that we must arrange so that
terrorists trying to make this virus
that's going to murder everybody proceed
more slowly because a perverted ideology
something that despite having knowledge
of biochemistry or whatever that thus
the speed of their project will always
be less than the speed of those were
trying to invent cures and not just
specific yours but the knowledge of how
to make yours at general this is what's
going to keep our civilization in
existence and that's why I think that
the moratoriums and so on to try and do
this because they are targeting only the
good guys like I said just now
I think it's its most laws of that it's
in extra if there were yes then they
would did immoral if you and building an
AGI with reversed motion that linked it
to immoral actions would be a crime but
but there there's a much wider category
of crimes with a similar outcome namely
educating the AGI with evil ideologies
that can be done whether or not they
have emotion
and it's funny I suppose at the time of
the height of the Enlightenment people
would have thought that some people who
would have thought that our emotions are
a barrier are an impediment to being
moral and and now I think it's more more
that people think having the right
emotions in SAT being moral III I think
this is the wrong way of thinking about
it we are universal the AG is will be
universal
what kind of Pro quartz specific kind of
program they have will determine the
actions and many of those are indeed so
we know - yes there could it be let me
give an example suppose the laws of
physics were that there are Olympian
gods who are watching everything we do
and when we get too big for our boots
when we when we have when they judge
that we have bit too much hubris they
slap us down now that's a black hole it
logically it could be true it could be
there the black ball about nuclear
weapons being easier
and so on it if they had been so then
one possibility is that the knowledge of
how to cope with that would have evolved
earlier that is there would have been
nuclear wars say in in the 18th century
and the evolution of political culture
would have heavily influenced by that
survivors might have wanted that never
to happen again you know that kind of
thing or like I said like with the
malevolent Greek gods scenario it might
have been that that the laws of physics
will extinguish us but the laws of
physics are do not have it in for us if
they wipe us out it will be because we
have not created the knowledge to
prevent that it won't be because the
malevolent God things all such ideas are
bad explanations yes so I've gone
through five or six definitions of
knowledge in time that I've been writing
about it
my current definition of knowledge is
information with causal power and that
that's the definition that that comes
naturally the constructive theory
because it means you're thinking of
knowledge as being a component of the
programming of a universal constructor
so that if if a bit of information is is
needed to make a constructor do a
particular thing then that piece of
piece of information is knowledge and
that includes moral knowledge
mathematical knowledge knowledge of
abstractions as well because
mathematicians are physical objects and
if knowledge makes them do something if
information makes them do something then
its knowledge and so on so that's that's
an explanatory knowledge is a special
kind just knowledge in general not
knowledge as in for example
in genes knowledge in its dumb knowledge
is non explanatory therefore it has a
finite scope it it can only it there are
certain parents that it can't cross
whereas explanatory knowledge can cross
any barrier because it it doesn't have
to have a sequence of viable
intermediate forms so it explained and
and that's also why once you have the
capacity to create explanatory knowledge
you can create any and and that's all
there is there isn't a there isn't a
more powerful means of processing
information than that or affecting the
world and responsible for cabins right
there's some kind of abstract structure
that like the profit mode that is
determined that is completely killing
the planet you can't point to certain
set of malevolent actors as a way to get
beyond that so I don't know like how
does simply having political knowledge
or knowledge of climate catastrophe
somehow work against this like you could
almost call it you know a gene online
but there's no intelligence behind
capital it's just a kind of non
intelligent abstract force that seems to
some extent impervious to the type of
humanistic knowledge we're talking about
this theory that there is this systemic
handling
[Music]
and it went out right as Ryan concluded
his questions yeah yeah well is it a
coincidence that justice I was about to
give him the answer to this question
about systemic malevolence it shuts me
down yes I think this is this thing this
thing you were you you were talking
about in general is this thing that the
bay area people call Moloch it's it's a
the the the something which is a proper
general property of a system which makes
the system through the act what the
members whose actions add up to the
system don't want and I think that all
theories of that kind are just false
the to cut long story short
all of them assume that the people
concerned are not created the the
analysis of the situation is always of
the form well a person it's fate all the
participants are facing this decision
where they have something to gain and
something to lose and they maximize
their local benefit and as a result all
of them are are dumped into deep
and so you notice about that story and
you'll notice about every Moloch story
that it that the human participants are
just ciphers they just do automatically
what what this is the particular version
of the Moloch story says they're going
to do and that is never accurate it it
is something that can arise momentarily
as a problem along with every other
problem we have every other kind of
problem all the time so this there's
nothing unusual about that but when it's
recognized as a problem people wonder
about it they start accusing each other
of behaving in that way and defending
each defending themselves by saying well
what other way could I behave and then
people think creatively about how they
can change the thing so that in all the
farmers in the in the valley that that
would have benefited from the dam and
whatever it is and none of them wanted
to pay somebody comes along and and
invents an idea so that they could all
get behind and undertake to pay for
sometimes it's because that's a creative
act in itself there's no guarantee that
that something can instantaneously come
to it I'm not with it but the argument
that that somehow the system of doing
things by persuasion and doing things by
in individual rights and property and so
on should be replaced by something that
that uses the boot stamping from a human
face doesn't work because the the
knowledge that again this just seems the
government or whoever does the stamping
has that knowledge well if they have
that bully someone else could have that
knowledge too there's Jerry there's no
the government doesn't consist
philosopher Kings or things with divine
right who have some different access to
knowledge from ordinary people they're
just people too and if the if the
knowledge who build the dam or to build
the park or you know whatever the story
is if the note doesn't exist then the
park isn't going to be made until
someone invents that knowledge or until
somebody works out how to do without
the park or whatever systems are can
university problems we keep adding more
labels again and maybe you know reads
expend the energy of sun within we
offered stars be very distant dieter and
successful knowledge and vision of
ending the play can you have I think not
so if you adopt my view that the growth
of knowledge consists of converting
problems into better problems then the
idea of the ultimate problem which then
can't be solved because it's the best
problem doesn't make sense does it
so I mean that whole picture might be
false but the so I'm a I'm generally
speaking a follower of Karl Popper and
the the pop Aryan way of looking at this
is is that he who tries to prophesy the
growth of knowledge is in a state of sin
that's not a quotation that's just my
paraphrase so so we you know I I can't
imagine what physics theories are going
to be invented in the next ten years let
alone in the next ten billion years but
on general grounds that there is no
argument or scenario reasonable scenario
that we know of today that can even have
provide a framework for envisaging the
cessation of problems I mean the the you
know if we we run out of problems
wouldn't that itself be a problem is
sometimes defined
I use the terminology like the
definition I gave you and all the other
definitions I've ever tried try to
encompass every kind of information that
has this special property that are the
problem-solving or whatever so wisdom in
the terminology I use wisdom is a kind
of knowledge and what's more the
different kinds of knowledge like
knowledge of physics morality politics
art and wisdom they're not come entirely
separate these are only approximate
classifications and they exist as again
as Papa said they exist mainly as a
convenience for university
administrators as convenience for
deciding which building different kinds
of people should be how should have
their offices in and which which ones
should have which lectures but they
don't represent anything real
at least the distinction between that
was very very unsharp and and again Papa
said he that there's no such thing as
subjects there's no such a thing as
problems so if someone asks you you know
what what what subject are you are you a
doctor oh you should say never mind that
here is the problem I'm working on you
decide for yourself what to call the
subject
oh well desert there there there are
several experiments no no I think I
invented the first one that would
distinguish a variety in quantum
mechanics from a range of competitor
protections including everything that
has a collapse of the wavefunction so
that there's there's a possible
experiment which would go one way if the
wavefunction collapses and the other way
if the wave function including the
observer doesn't collapse so so if that
went the other way I would drop it like
stone oh well the experiment depends on
precisely which other interpretations
you want to refute that there isn't an
experiment that would refute all of them
in one go you have to specify something
like Penrose it's the idea that the
wavefunction collapses when you get more
than ten to the minus eight kilograms of
on either side of the superposition
something like that or that the the the
wavefunction collapse is when hits a
conscious observer so supposing you have
the you're testing Everett against the
theory wavefunction collapses when it
hits a conscious observer then what you
do is you make a conscious observer
which is the most convenient way to do
that be to make AGI running on a quantum
computer so you you then do an
interference experiment we're halfway
through there are two different
trajectories of the of the computation
take place inside the computer's memory
that the the AGI has access to you're
still with me when it's halfway through
and hasn't yet interfered in other words
it's it's it's on the inner mark sender
interferometer it would be having just
having bounced off the mirrors and not
yet reached the final interference
mirror
then the the idea AGI measures which one
which mirror it is at and then makes a
permanent record of the form I am now
contemplating I have now done the
measurement and I have got a result and
it is one and only one of left or right
I'm not going to reveal which but I do
certify that it is one of those two then
the rest of the the the that part is is
sealed off the part where the
declaration is is sealed off and the
rest is subjected to minus the
Hamiltonian that it had during its
thinking so that all the memory of which
it which it which of the two things it
was conscious of happened is wiped out
and then the interference is performed
if we hitting the conscious observer
causes a collapse of the wavefunction
then you will get a 50/50 split of the
two outcomes and if the average
interpretation is true then you'll get
only one of the two that's not the
challenge challenge is to find something
which would be to differentiate between
well this would for anybody who thinks
that that the wavefunction is collapsed
by a conscious observer and the this AGI
is a conscious observer now if you think
it isn't then from my point of view I'll
let you and it decide what hammer that
out amongst yourselves but if you if you
insist on it being a human and on
coherent quantum computations being
sorry coherent quantum measurements
being performed on a human brain then
we're going to have to wait for some
thousands of years I guess before that
is feasible but in principle is
certainly feasible Boehm is a different
category in my view bohmian quantum
mechanics is just ever quantum mechanics
in a state of chronic denial it it is a
the trouble is with the Bohm
interpretation that it doesn't meet its
own motivation it has this pilot wave
which is actually the wave function and
it has a representative particle which
is goes moves along the grooves in the
wave function and to to be a permian you
have to systematically equivocate on the
question is the pilot wave real if it's
real then it has groups that are
performing computations in principle
conscious observer computations which
affect each other and so you can't say
that some of the pilot wave doesn't
exist the whole of it has has to exist
and therefore the the multiplicity of
the averaged interpretation is just
there in the in in the pilot wave
interpretation if you say that it
doesn't exist if then you're saying that
something that doesn't exist effects
something that does which simply doesn't
make sense
[Laughter]
[Music]
I think pertaining to the discussion
because David at one point I think it's
a monitor and star-lord interviews you
raise the possibility I think you said
that the hard problem of consciousness
could possibly not be resolved accepting
if you start from the premise of a
multi-verse well I don't about start
from the premise but but obviously it's
it's always possible you know you're
going to run into trouble if you base
your ontology on something isn't true
and for example if you're going to say
that freewill can't happen because only
one trajectory is allowed by either
Newtonian physics or by Copenhagen
interpretation or whatever then you're
going to conclude that free will doesn't
exist from a false premise from if you
replace that by the through premise that
quantum theory is true then it's in this
case it's not so much the quantum theory
has helped you to solve the hard problem
it has removed the impediment to solving
this until doesn't tell you what free
will is or what qualia are or whatever
but it's it's removed the knockdown
argument that for example free will
can't exist qualia can't be different
from anything else unless electrons also
have it have them and so on so you you
knock out a bunch of false arguments as
as
generically happens if you have a fixed
fixed old theory that you're unwilling
to replace or criticize then you rather
like sticking down a piece of a jigsaw
puzzle in the wrong place and gluing it
down that that would produce errors
in the picture arbitrarily far away from
the piece of glue down it may look fine
near the piece and then you'll you'll
you won't be able to construct the
picture so this is why the you know this
is why the pursuit of truth is useful
one reason connection to the issue
regarding what distinguishes a GI from
AI because when you've written articles
you've talked about in pottery in terms
the capacity to conjecture which you've
referred to sometimes as creativity you
know those are widespread conventional
terms is there some way to kind of
sharpen those terms in relationship to
[Music]
well so I don't think that quantum
computers will be needed to make an AGI
like you know I could be wrong but I I
don't think that's the kind of problem
it is so therefore I think that a
creative program could be made on a
deterministic class computer although I
must say immediately that calling that
such a computer deterministic when it's
an ABI somewhat misses the point because
the AGI is going to be interacting with
the world and the world is is not going
to be deterministic because among other
things it's quantum so so the the if
creativity depends on some kind of
randomness randomness is everywhere and
that would be true whether it's classic
I don't because that sort of thing
so again I don't think that probability
is the right way to think about the
growth knowledge and so in this
knowledge earn is not the right one to
think about you know but perhaps it's
better to think about about being run
over crossing the road or better going
to a casino and and the betting and so
that there there will be if you play
your cards right you can arrange it so
that there will always be some worlds in
which you come out a multi-millionaire
so now I I think the the trouble with
drawing profound conclusions from this
is that one thing we do know about
probability is that if the average
interpretation is true then when one is
analyzing a situation of randomness the
right analysis is the classical one I
[Music]
would try not to I would try not to let
my psychological approach to a an event
come into conflict between what I know
is there so you know I I I might have I
might have an objection to eating a
suite in the form of a tarantula but
then I say to myself no this isn't a
tarantula this is just a piece of candy
and I'm going to eat it and you say well
yeah but still still what do you feel
about it well what I feel about it is
different from the right answer is not
very interesting that's just ways in
which I can be wrong are the only two
computation creatively to feel more at
ease with this technology all the same
question I was wondering if you might do
laughs yeah well um since it's the last
question you see III thought allow
myself the luxury of talking about
things I don't know and these are three
things that I don't know they could go
either way so for example is the
morality reducible to acknowledge well
if it isn't that what on earth can
morality be are there moral axioms that
that are uncritical that that would be
authoritarian so on the other hand if
morality so and that problem wouldn't
arise if it was if its technology
because we already know how to do to
frame epistemology without acquiring
foundation without quiring Authority you
know thanks to Paul we know that but
then I asked myself what if the laws of
physics were different like the ones I
mentioned with the Greek gods and the
malevolence suppose there were
malevolence and and the laws of physics
really did have it in for us and so on
would that change morality could could
we say like at the moment we say that
that if something is property of physics
it doesn't have a moral value pro or con
but in such a unit can we Oh am i right
in thinking that those kinds of laws of
physics are amoral
or does that not make sense and I don't
know so that's that's the the kind of
thing there and and that and I'm also
wondering in that question whether there
is a connection between that and the
question that the implement who's on our
left are about whether consciousness and
free will and and qualia and and moral
value and all that stuff are all come
together necessarily or can they be
separate or can they be made separate
perhaps absolutely up to now in the
universe they've always come together
but we could artificially make them
separate and energy I again I I think
that can't be so but I can't give you a
watertight argument on it isn't so but
we we have to wait in in which case we
have to wait till somebody comes up with
a viable theory of these things yeah I'm
always a bit a bit perturbed when when
people have strong feelings about things
like free will the moral value you know
is it moral to kill animals eat animals
are animals conscious and all those
things
well they do not know what consciousness
is none of us do
[Laughter]
