let me tell you what how I really feel
about thought I was be
honest rich thank you very much for
joining us here and approximately
correct we're very pleased to have you
here thank you Scott it's my pleasure to
be here we've been wanting to have you
on for a while so it's great to have you
we've talked about reinforcement
learning a few times on the podcast
already but we're interested to hear
about what exactly about that
reinforcement learning setting was
appealing to you why did you start
working on this well I was always
interested in systems that interact the
world and learn from that and that's all
that reinforcement is to me I mean you
have to have a goal right which we
formalize as a reward but it's kind of
surprising that if you look into AI uh
when I started in the 70s and all
throughout this time there really isn't
that much that's about you know system
interact with the world and learning
from it and having a goal and even in um
in the early days of cybernetics
and and throughout pattern recognition
and supervis learning those systems
don't have a goal they're just trying to
pick up on a pattern which is important
an important part of part of
intelligence but it's not it's not
interacting with the world to have a
goal and so that always seemed like it
was kind of missing you know there
wasn't reinforcement learning when I
started we had to make
it because there wasn't anyone doing it
and was there a particular moment for
you that you kind of remember having
that feeling of oh I think this is I
want to look to at this goal oriented
Direction yeah was it was a gradual
moment when we just studied all the
different things people had studied like
like pattern recognition like control
theory all these things you know kept
looking where are we going to find the
one where you're trying to do something
and you know there there was Bandits
there were always Bandits Bandits where
you know you kept doing action till you
get to the most reward but that was as
close as it came and they didn't have
something that says oh I remember I
should do this in this situation and
that and that
situation and in order to get my goal
right Bandits you just do one thing over
and over again right it's fundamentally
stateless yeah yeah that's right it's
stateless why do you think it started
that way why was it all focused on
prediction well it didn't in my reading
of the history is it didn't really start
that way I think they they began they
wanted to do interacting to achieve a
goal um and then they fell slid back
into pattern recognition because pattern
is clear right and simple um and then
then they gradually kind of forgot about
like some of the very earliest things
1954 like Farley and Clark they talked
about having uh trial and error and then
it gradually became supervised learning
like a clearer path forward it was it
was a clear path yeah simplification and
that's always been the been the
case I'm sorry to start so far back
no it's fun it's important to build a
foundation and it's also one of the nice
things about having you on is that
you you remember those things let's move
forward though what what are the things
you're thinking about in the context of
reinforcement learning today what what
interests you about reinforcement
learning right now the only way to
describe it is not to talk about
reinforcement to talk about all of AI
and what's what's needed in what's
happening in Ai and what's not happening
there what needs to happen I'm still
thinking AI is interacting with the
world to achieve a goal uh and I guess
that
means we're talking about reinforcement
learning but if you just interact with
the world to achieve a goal then you got
to uh make a model of the world you've
got to have a goal you've got to model
the world at multiple time scales you've
got to uh learn what are the right
structures and right features and
Concepts to understand the world and I
didn't say you know where we start which
is what you have to do things you have
to try things and see what works which
is where reinforcement wining starts so
I would say that over the years we have
developed good methods for linear
mappings if you have to you want to
learn a linear
relationship then we're fine we can
learn online we can learn continually
could you give an example of of one of
those linear uh relationships that would
work really well so all the algorithms
are actually defined for the linear case
and for the nonlinear case you get
linear TD Lambda nonlinear TD Lambda
um Q learning you have both linear and
you know it started as linear versions
and the linear versions learn rapidly
and they can adapt as the world changes
but they can't learn nonlinear mappings
they can't
learn exclusive War they can't learn new
uh features so 1986 we found backprop
and we started to be able to learn
nonlinear
mappings but it was like a a devil's
choice or whatever when we had to learn
when could we want wanted to learn
nonlinear things we had to give up the
ability to to to change rapidly and to
learn continually I mean did you have
to I me I don't think you should have to
but but the methods that were first
found uh were not able to learn
continually and they were so exciting
and Powerful they were able to learn
nonlinear things that you know we were
not dissatisfied to give up the
continual learning in return for being
able to learn non- layer maps that was
good trade-off and you know it was a
good trade-off but it's we've kept on
too
long and um more than that somehow the
the I feel the Aesthetics of the field
has changed and the field wants to focus
on what they can do instead of noticing
what they can't do what do you think
that
is so it's just that simple you know we
can do certain things and uh so we could
work on those so um all of deep learning
is all about hey what can we do with we
take a data set and we we learn from it
and then and then we freeze our learned
system and we justplay it in the world
chtp doesn't learn at all but it is
highly learned to construct it and so
yeah we've done
language it's an amazing accomplishment
uh but we had to give up something that
can learn to use language as going mhm
during use during normal operation it's
a test of the uh
researcher uh do does he want to see
what we can't do and try to work on that
or does he see what we can do and go
further with that it's like this problem
of looking under the Street Lamp right
like i' I've lost my keys and I'll look
under the street lap because that's
where I can see even though that might
not be where it's like that the keys are
anyway you know I think it's fine to do
all different things but I think the the
important observation is that the field
has has has overwhelmingly Gone In One
Direction Going Gone towards uh and and
so and so much so that you're you're
strongly discouraged if you want to say
oh there's something we can't do um they
say well well yeah but we could do all
these other things so don't criticize us
you know um that's I see that as a big
effect uh in the early days um machine
learning it was much more open oh this
is a interesting let's do that that and
then like at some point deep learning or
was the the field uh went to a stage
where unless you're doing something
complicated at least like Atari you
can't publish right you you know you
have some new idea
well how does it work on a big problem
right and and I think it's gradually
easing off think there's more interested
in what we can't do and the whole thing
about continual learning is exactly uh
the thing that's more more uh acceptable
to work on now um so maybe I'll get you
to Define like what is continual
learning what does that mean continue
learning just means that you continue to
learn rather than learning in the
factory and then being frozen when you
go out into the world I see sometimes I
try to search for what's if we have
continual learning and that's almost the
normal one well what should be the
abnormal one the abnormal one I don't
know I'm trying calling it transient
learning so what deep learning does is
transient learning you know we learn
a special phase and then you're done
learning you never learn again that's
that's Transit learning that's the
unusual one episodic learning episodic
well I can't do that because
reinforcement learning uses episode in a
very particular way yeah can't get past
that it I mean it does kind of strike me
as so reasonable I mean like when you
think of like how we learn yeah I don't
go home and forget everything that I've
done whenever I get new information most
times bad day maybe so I guess I'm I'm
kind of curious like why was that not
sort of the
default from it's just it was the
default from the start just in recent
decades we got into this group think
where we all think in a particular way
yeah so I like to think about it in you
know what are we trying to produce are
we trying to produce a system that is
fixed and behaves really good our final
product will it be something that can
continue to look
as they can encounter new things and
learn about them you know when you come
in each day to work do you think oh I'm
really good I just have to do the same
thing or do you think no the reason
they're paying me something is because I
can adapt to what happens and I can be
flexible and learn new things yeah most
days I don't know they're they're both
important yeah but with that
adaptability always seems really
important to me hard
intelligence is intelligence a policy or
is intelligence an ability to to adapt
to whatever happens so what are the
challenges when we come when it comes to
trying to build these systems that can
learn
continually okay so this is the first
question you asked me you asked me like
what is the exciting thing to do now
yeah and I and I I went in my Spiel um
the field is has gone off and done this
trade-off they can do not they can do
nonlinear things but only if they give
up continual that's the way the field
has gone very strongly it's it's done
great success with it I don't begrudge
that at all I I do begrudge it that they
don't leave space for working on the
other um but I'm a successful academic
and I'm and I'm old and I can do
whatever I want so I so I'm going to
work on what I actually think is the
most important even if no one else
thinks it is important so I think it's
time well it's long past time for
someone to figure out how you can do
continual nonlinear learning and there
my opinion there's actually no reason
these should be opposite to each other
at all so I'm doing it in
a a particular way focusing on online
learning and a single
task uh just like the world is gradually
changing and you have to keep following
it and and and learn in that setting
just want to fill in this Gap we should
be able to do nonlinear learning and
just still be fully
continual so why can't we what's the
hang well I think we just haven't tried
yeah yeah but like what are the
technical things that are standing
between you and and well so we've
created all these specialized things to
make transient learning work pretty well
okay so replay buffers right and um the
way we do
normalization and and like early
stopping we've developed this huge
technology and techniques for making the
transient learning work and so
um that that that inhibits doing the uh
doing the other doing the continual
learning for networks because well like
you're not going to do very well on on
image dead you're not going to do
because image net is standard Benchmark
and it's meant for the transient case uh
you're not going to do very well on
Atari right away because we developed
all these customized methods to make
Atari work pretty well with transient
learning methods it's both the methods
are different and the problems are
different I you can't just step in and
do better on the standard problems
because all the standard problems are
designed for the transient case so it
almost sounds like you're kind of saying
it's time to maybe just like take a step
back and look at the wider picture
rather than these narrow fixes to
absolutely you you can also talk at the
other way you say yeah people don't
realize how important it is that just
means it's going to be all more you know
and
bigger result when it's worked
out it's good not bad to be a contrarian
if you can afford it as I say I'm I'm
lucky I can work what I want and and
it's okay yeah let me tell you what how
I really feel about
it thought I was being honest I thought
other people were going to do this you
know when I was in a PhD Su my brother
student Charles Anderson also student
van Bardo he did you know the nonlinear
part I'm going to work on the
reinforcement specific part then we'll
put them together it' be good and then
I'm just disappointed it's 40 years
later and those guys haven't figured it
out uh instead the nonlinear stuff went
off and did offline transcent learning
and they didn't give me method they
didn't give me methods that I could use
to do to do to learn the policies to
learn the value functions to learn the
models of the world the transition
models of the world and they didn't they
didn't figure out representation
learning they didn't figure out oh let's
let's figure out what are the right
representations for the world the ones
that are going to generalize well and
let me learn fast now it's absolutely
the bottleneck for going forward in
reinforcement and I would say in AI we
don't have methods that can learn
continually uh except for the linear
case and yeah don't have methods to
confine good
representations like we we always have
to fight against arrogance because
arrogance hurts your ability to see
truth you know but what I'm saying is
kind of arrogant I'm saying you know I
gave these guys 40 years to figure it
out they did do it some no I'm going to
have to do it you know that's sort of
what I'm saying which is extremely
arrogant at least the second part that
I'm just going to be able to do it right
uh in in a couple years or whatever I
mean I haven't thinking about it for a
long time I really wish I didn't have to
do it it's such a shame but they have I
mean they've set some of the groundwork
right like the work that they've done
isn't isn't completely useless it will
help you I feel maybe maybe you're being
maybe you're being accurately nice but I
feel like it's it's not it's not the
groundwork it's actually away from the
solution it makes it harder to do the
right thing because because they're not
saying oh this is a problem that we need
to solve they say we don't we're we've
done the backrop paper about learning
representations they considered that to
the solution to the problem of how you
learn representations but shouldn't a
representation be General and useful in
many situations and then whatever you
need to do you learn a linear mapping on
top of it yeah I'm good with that I
think that they think that backprop
learns good representations ah okay that
I also was AUM me that and I don't think
so ah okay interesting or they say that
they have that it makes it harder for
someone to go along and say oh this is
an unsolved problem I'm going to work on
it they say oh no no backp did that and
if you're going to work on it you'd
better work you
know right next to back propop and show
you're better than it so what's wrong
with the representation what aren't they
doing so this backb was just grading
descent and there's nothing in grading
descent which will um Drive The Learning
System to find features that generalize
well it just finds features that that
solve the existing problem well so it's
not a problem with backrop it's a
problem with the the goal the loss
function the backr is solving there a
problem with gradient
descent gradient descent is just the
objective is just to the objective yeah
that's a problem with the objective
right the objective so it sounds like a
lot of the work is not even is just
convincing people that we don't have the
right solution okay you could do that
this is a way to lose you know you say
oh no one's working on this I got first
I got to convince people that this is
the right thing to do and then I'll work
on it you know but no you'll spend all
your time convincing people and you'll
never actually work on it and so you'll
never actually succeed at it and
everyone else will say oh look you know
he says we need to do it but he's not
getting anywhere you know it's a good
way to lose is to spend your time trying
to convince other people that they
should do what you think is important
okay so what's the alternative you just
do the important thing and ignore hard
yeah you have to be uh
contrarian and actually do it you have
to do it I you can spend some time
convincing that trying to convince other
people and you have to if you hope to
get published but I mean in some ways
this is what our friends in the
nonlinear setting did right they ignored
everyone for a good decade or so while
they all told them that you know there
was nothing principled about what they
were doing everybody was in in love with
their principal statistical machine
learning and they kept plugging
away yep but they always had good
results they always had something to
point to that was an advance always
always is too strong I remember a time
my early grad school years there was
certainly a lot of noise around deep
learning and yeah and also people still
thinking it was silly yep so anyways
maybe might give them a bit of credit
for sticking with it it's the story of
you know the Wilderness uhuh neural
networks had their decade in the
wilderness so no one thought it was
good so I guess I'm sort of saying
continual learning has has had its
decade in the wilderness and now it's
starting to be acceptable that's good
and there little it all come back all
these problems with science are
self-correcting well I mean are they it
takes a person to decide right the
science itself is the people in it right
so it's only self-correcting if somebody
decides and it can take a long time yeah
yeah over what time frame yeah right so
we've talked a lot about the I want to
do you want you want do I want to do
that these are the decades when we are
going to figure out how the M works okay
all right I'm so happy that you're it's
plural
decades well I think we should strive
for like you
know 2030 uh and knowing that we
probably won't succeed but you have to
you have to try and when we when we say
Su succeed like what what understand how
the mind works understand how a system
can can can learn by trial and error by
trying different things and learn make a
transition model of the world so we can
understand the world it can find the
fulcrums of decision- making you know
should I go to this talk or that talk
should I go to the washroom should they
take take a sip of tea all these you
know are are you have to to find those
choices the lowle choices are there but
you have to find the meaningful choices
in your life so all that involves in a
model so it's not too much to ask that
we learn by trial and error and also
that we make a model of our world and
are able to lose use that model at to
plan like that's the set of things that
I think make up a mind I think also a
uniquely human property is the ability
to have multiple goals at the same time
I have many things on the go I could
bore you to tear with all the things
that I'm currently working on right you
know we all have all of our things that
we're doing we have families we have
careers we have you know friends we have
hobbies all of these things and they
layer on top of each other and every day
we decide what our goals are what will
be the thing we do today sometimes it
moves us towards a bigger goal sometimes
it's just Sunday and it doesn't matter
but yeah and you have to find that
balance to keep like sometimes like a
house of cards but then I think of like
animals like what's an an animals goal
are they're just there is perhaps less
to the to the complexity of a of a goal
they're also less often about some sort
of
internal reward right I I don't disagree
with you okay but I think it's both true
that there's only one goal and then and
there are lots of goals so I do believe
in the reward hypothesis that everything
all goal-seeking can be well thought of
as understanding the maximization of a
single scaler externally received signal
oh yeah that's part of a achieving that
we we form we pose many sub problems for
ourselves like I have the sub problem
how I could pick up my my tea and and
get it to my mouth successfully without
spilling it and everything else all
these things are are sub problems that
are really useful for us to solve uh as
part of achieving the overall goal so I
think the subtasks sub problems are a
solution method for the single overall
problem
so that lets me have both right I have
one goal and yet I also have that the
mind of the agent is full of oh will
this let me do that well L let me do
that I've got to learn all these
separate things and learn the solutions
to each one and then and then I'll make
my my life will be full of oh I'll
decide to Cho to work on that goal for a
while and that'll drive me to end up in
some place and then I can work on
another goal so you think at the level
of
goals as sub problems and all these
different goals and sort of like
creating those sub goal creating them
absolutely posing you pose them for
yourself PhD I want to get a PhD I want
to get tenure I want to so in that case
like what would be the singular goal
that those are all sub goals of well the
singular goal is going to be reward we
don't really know what people's rewards
are but it's it's like Pleasure and Pain
and maybe maybe uh people's attitude
towards you respect from other people um
so the amazing claim of the reward
hypothesis is that there's there's one
tiny little
scaler juice that you're trying to
maximize and then out of that lowlevel
it's a low-level thing it's listen a
number coming into your mind at each
moment in time it's computed in the
hypothalamus then out of that comes like
you know I want to raise a family I want
to have a career where I'm a a
successful uh research scientist you
know all those so out of a non-abstract
thing comes out very abstract
goals and very abstract Concepts now
there was a time when that was just so
uh
inconceivable that it would it would be
embarrassing to say it but now it should
be straightforward like we we've seen
that happen many times you know like
Alpha go learn to play go and had as all
all these abstract Concepts uh learn to
play chess and has all the abstract
Concepts you need in in chess or like
language models it blow knows my mind
what they've learned from this simp much
better little problem oh my gosh the
next word yeah from Tiny things can come
very abstract yeah okay okay that's a
that's a convincing
story it does I mean I'll be honest when
you put it that way like it also feels a
little psychologically uncomfortable
I'll admit like it yeah you sort of feel
less complex than I might like feeling
about myself yeah these decades we're
going to learn we're gon to understand
the Mind much better and I think it's
not all going to be
comfortable I think the fact that it's
uncomfortable actually makes me think
that we are making progress we are
understanding things better yeah we
we're not just and finding out what we
want to be true find out what's actually
true and you think about it it really
wouldn't be possible to make a person
who wanted to do something like become a
research scienti it's like how would
Evolution program you to to have that
goal right it's inconceivable and it
wouldn't work it's got to give you a
goal that that it can sense that's
concrete takes us down a pay that's this
psychological uncomfort you there are
going to be other things that are smart
and we're going to understand how they
work and they're just going to be trying
to get this number high and that's
interesting it it's also seems like kind
of because you were talking about animal
intelligence it sort of erases the
distinction just object for a minute
okay humans are animals sorry I guess
yes that's fair
nonhuman animal intelligence that it you
know I think it's very tempting that to
think that we are very different as I
just did when I said that but it might
erase some of those divisions that we've
set up that don't actually exist and
that's not fun it's accurate maybe but
not
fun so you're saying you think we'll
have this understanding within the next
six years at this point no I do have a
prediction the prediction is One Chance
in
four by 2030 that will that we will
understand this is it's going to be
vague but it's we basically we'll
understand intelligence which means
doesn't mean we're going to understand
the human mind that will take much
longer we will understand how you can do
trial and error learning to achieve a
goal how you can um make a transition
all the world that enables you to plan
multiple levels of abstraction and uh do
that with no major gaps you know it's
going to have to learn Lear good
representations learn to generalize well
it'll be a neural network just how some
different algorithm it will have a
reward what is the world the world the
world is the thing that we interact with
and we send we send bits out to but do
you mean all of this or do you mean some
constructed world I think the world is
constructed though the world we send
bits to it and it sends bits back to us
to our eyes and so forth right and so we
make sense out of out of this thing that
we send bits to and get bits back from
so you're saying any world I guess
that's what any world any world yeah to
be able to make models transition
models so then you're able to plan if
you can plan and you can learn by also
by trial and
error that's that is what I think a mind
is if your prediction holds true like
you said a one and four chance I think
you you said by one and four chance 2030
one and two Chance by 2040 okay what
does that mean like how how will that
change things we understand how Minds
can work this will help us understand
our own minds the AI researchers will
understand it as detailed level and it
will gradually filter out to the society
to the consciousness of the world and we
will get uncomfortable feelings and then
we'll gradually get more comfortable
this will have technological changes it
will change you know the economy and I'm
not sure which of these going to be more
important the sociological or the
technical there going be lots of
technological changes anyway even if
without understanding even would
mind I think we'll change us really
because it will we'll understand
ourselves better which is maybe the
whole
point so I think that's going to be
really
profound totally separate from its
impact on the economy its impact on
geopolitics do you think it will impact
the way we teach the way we educate
people if we understand it better yeah
totally well one big will happen will be
augmentation if we understand how our
minds work then we ought to be able to
add you know a better memory uh I want I
want to be augmented I want to I want to
think better I want to uh you there many
advantages to digital substrate or the
biological
one um so we could be
better so like there so many things are
held back as we don't know how we
work now as I said said you know
understanding Minds is not the same as
understanding the human mind it's not
the same as understanding the human
brain that will you know that will take
longer so Al you're you're psychologist
you're on the edge of Neuroscience what
do you think of things like neurolink
brain interfaces I mean I guess I see a
lot of the places in which they could be
helpful I think we're pretty far away
from most people feeling like that's
thing that they would want I don't think
that's probably a 2040 thing what do you
think well some sense you know it's just
an interface but are there so many other
ways to have interfaces without actually
opening my skull that's
true you can get high band with
interfaces in it's hard to get Hand by
high band with interfaces out maybe it's
about compression though like I often
think about like if GPT takes your like
quick summary of what you want to
explain to somebody and turns it into a
verbose email and then the person on the
other side is taking that for both email
and using chat gbt to turn into a
summary why aren't we just sending
summaries to each other so maybe maybe
we can do better than
language yes yes we really ought to be
able to B language is it's it's you know
taking your whole thoughts and squeezing
them into these words these linear words
yeah and it's a there must be something
much better yeah are you going to be
disappointed in that if we don't have
language no yeah just when when we get
as it came out of my mouth I thought
that's sacrilege you shouldn't say that
yeah personally we're getting back into
psychologically uncomfortable right
that's right I love language and I think
language you know been the way that we
communicate these complex thoughts that
we have in our minds and also the way
that we think through things ourselves
as with language so I don't think we
need to throw it away completely but I
often think about sometimes it's a
little to it's more than we need I
guess our last question for you is do
you have any tips for students or other
budding researchers about research in
general how to choose what to work on
how to how to make good progress uh yes
I I think I do get a research notebook
and write in it write in it every day
write what write your thoughts and and
and work on your thoughts try to CH to
challenge them and make them better if
you want other people to be interested
in what you think then you should start
by caring about it yourself and you
should care about at least enough to
write it down and challenge it and
develop it to progress it that's the
most important thing I hit on that
strategy and it really changed my whole
trajectory um it's really hard to do
because it's a blank page and you know
what do you have to say and maybe you're
not maybe you're confused about what
you're what you're thinking one saying I
thought to help with that is that
usually the value of writing down your
thoughts
is directly proportional to how vague
and Confused they are the value is
proportional to how hard it is to write
them right if you say I don't even know
how to I'm thinking six things at once I
can't possibly write this down that's
when it will be super valuable when you
do write something down is that a way
that you know that you have an idea that
you really want to pursue is that a sign
no it's it's that would be scary it's
got it's got to be just like you in the
page and you're trying to be clear to
yourself what are you thinking if you
can't think of anything else to to write
just write down what what do I think are
the
six interesting ideas that I've got
rolling around in my head so just then
write them down one through one through
six and then say well is is that really
all of them is there a seventh one well
these six are two of them really the
same or or just take another paragraph
on each one of those six things and
explain what you meant by it
explain to yourself what your thought is
and just by doing that you will say oh
now that thought kind of just
disappeared into nothingness when I
tried to explain it you know maybe it
isn't anything you know or maybe it grew
and and changed as you wrote it down all
those things will happen and so it's
important just to keep keep keep writing
try to do a page a day don't don't
stress out it too much but do keep doing
it on a regular basis that's my advice
second advice is that you should try to
be neutral on on what's popular you know
if it's popular unpopular that's
shouldn't influence you at all because
if it's popular well then it'll be
easier to work on it because people will
understand it but but it'll be less
valuable because everyone's doing that
so you should be neutral pick your
problem what makes sense to you as being
important and and potentially fruitful
do you have any tips for deciding on
what what is the next thing I should
work on yeah so like I write down the
six things these six things I think are
interesting and then explain them and
then I go back and say okay now let's
try to say which one could I possibly
work on now and what if there's like
three yeah then what do you do the three
things write them down and keep going
until there's only one or oh no no uh
you yeah that's a good a good
question I don't mean to suggest that
you find one thing and you do that you
have to do work out a few things because
because it is research and some things
are not going most things are not going
to work out out and not work out right
away yeah from the sounds of it you
probably go through a lot of
notebooks uh I have about 25 in the like
current ones or actually 25 at the time
when I stopped using physical notebooks
right now I just write on my MacBook do
you ever go back to revisits yeah not as
often as you might think yeah but uh you
do sometimes for
sure now that it's all on the computer I
can search it and find those things even
more easily do it a bit more yeah and
also that takes a little less space than
a whole bunch of notebooks although
there's something pleasing about the r
notebooks
yeah seems like
progress yeah I would always write in
ink scratch scratch things
out well I think that's about all that
we had unless there's something else
that that you wanted to touch on that we
didn't we didn't talk about well thank
you very much for giving me this
opportunity learned a lot not all of it
comfortable as we noted but all of it
fascinating so thank you very much Rich
thanks
[Music]
