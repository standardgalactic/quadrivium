the AI regulation in Europe is
incredibly stupid Von in her state of
Europe addressed this here was like
Europe is saving Humanity from
Extinction with the AI Act and the rest
of the world should follow it's like
what what have you been smoking Ed those
light you can't be a powerful prosperous
country in the 21st century if you don't
get AI right AI is not just another
technology AI is the automation of
intelligence the way democracy works
today made sense in in the 18th century
you vote once every four years it's
ridiculous voting is is quite smart in
some ways but we have ai now the
algorithm that makes the decisions can
be way better than this in ways that we
don't even imagine so I think in the
future we are going to want the
important decisions to be made by
algorithms and God help us if the
algorithm isn't making a decision
there's already a lot of people saying
like oh AI are going to be conscious
therefore they must have rights my
position on that is that you must be
insane if you think machines should have
right rights who are
you um my name is Pedro Domingos uh I'm
a professor of computer
science um I live in Seattle my
specialty is AI and in particular
machine learning so as you can guess I'm
having an exciting time these days yeah
very very exciting time but I want to I
heard you talking about the AI
regulation in Europe that you think is
very stupid that they did what they did
and I'm curious to hear more about
that yes you're right the AI regulation
in Europe uh is incredibly
stupid Europe has a good track record of
producing stupid legislation but you
know the AI Act is just on another level
uh so congratulations to the European
Union and its legislators so um where to
even
begin first of all the idea of
regulating AI as AI makes no sense it's
like like regulating mathematics we
don't regulate mathematics because it
might be used for bad purposes or
regulating a programming language we
don't regulate python right or even
regulating quantum mechanics it's like
oh quantum mechanics can be used to make
nuclear bombs we got to put some guard
rails on it right now it just doesn't
make sense AI is a fundamental
technology the right approach uh is to
regulate specific
applications you know according to the
problems in the application area like
self-driving cars can be regulated as
cars right they're different because
they're driven by computers so that's
some interesting uses medical
applications etc etc trying to have some
blanket you know agency that regulates
all of AI is just a recipe for conflict
you know bureaucratic
duplication uh you know never ending uh
uh you know bureaucracy and and and for
uh for hindering progress now that's
that's the first problem the second
problem is is then of course before you
regulate AI you have to Define it uh
they Define it so broadly that includes
almost
everything uh uh like literally if you
look at the letter of the law everything
you do with a computer potentially Falls
it's like computer you know system used
to make decisions like well you know
everything does that right so who knows
what might might be regulated as AI one
of these days because there's always
people you know eager to regulate more
and then take advantage for whatever uh
you know purposes they have another
problem is that AI is is is evolving
very fast so this idea that we're going
to regulate AI now for you know the
future for the foreseeable future is
just crazy like imagine trying to
regulate you know the internet in 1996
when social networks didn't even exist
right it would be a disaster right but
but people now want to regulate AI
against super intelligence which we have
no idea what it's going to look like
right right so you know we need to like
you know let AI develop and in fact some
of us warn the European legislatur that
by the time the law came out their
definition of a would be
outdated they went ahead and a year ago
chat GPT came out and then they
scrambled to outdate the definition
leading to a lot of problems and of
course by the time the law is put in
practice it'll be outdated again so
that's another problem now here's may be
the most shocking part of all follow
this so the legislation divides AI
applications by risk
level and the highest risk level or what
they consider the highest risk level is
simply
outlawed there's a number of
applications of AI that are going to be
outlawed in Europe like for example
predictive policing face recognition
emotion recognition right emotion
imagine you trying to talk with me or
anybody without recogn izing the
emotions on their face right that was
the recipe for a dysfunctional
conversation but AI because it's too
invasive is not allowed to read try to
understand your emotions so you're just
condemning a to be stupid in the name of
some you know misot of privacy same with
predictive policing predictive policing
is a wonderful thing it's predicting
where crime is most likely to occur and
therefore send the police officers there
this is of great benefit to the
potential victims it lets a smaller
police force do the job of a bigger one
of course you can have problems but
that's the reason to do it well not a
reason to Outlaw it okay and then Etc
right and then it goes down these tiers
with you know at every level of risk
there's all these reporting requirements
and and and and um you know restrictions
and whatnot like for example they want
AI to be uh you know uh they want AI
safety to be tested and assessed and
insured by law in in ways that not even
the Googles and Facebooks know how to do
now they're mandating that a bunch of
things be done that nobody actually
knows how to do right this just a recipe
for for disaster right so at the end of
the day what's going to happen is that
you know European consumers are going to
suffer European companies are going to
suffer in particular European AI
startups are going to suffer because the
big companies can have all the lawyers
and the people to get around these
requirements and so on and so forth but
the ones don't now ai is already far
behind in sorry Europe is already far
behind in the technology race sadly
Europe used to be a leader in AI like
America was and now it's just going to
ensure that it's going to become
increasingly reol I mean this is going
to cost Europe trillions of dollars it's
going to be bad for the quality of life
and for the health and and everything of
of Europeans and and like what does it
accomplish that is actually useful or
positive I can't name a single thing so
that's a very brief summary although
might seem long of of what's wrong with
with the AI act can we do this in a
right way or any regulation anything
will be uh harmful for the long-term
potential as I said I think regulating
AI as AI just makes no sense this
doesn't mean that there are there's no
need for regulations on anything but but
as I said the right approach is to
regulate specific applications in their
own right you regulate medical
applications of AI as medical
applications and the issues are
completely different from regulating you
know self-driving cars and in most cases
the fact that something is done with AI
does not even affect how it should be
regular like for example if something
should be illegal it should be illegal
regardless of whether it's being done
with
AI and and and and and and and likewise
if something should be legal there's no
reason why it should be illegal if it's
done with a act right now what so what
you need is not some big Global or up
white you know regulatory agency as
people are are are are looking at is for
the existing agencies in their domains
Transportation Health Etc to look at
what is the impact of AI in their domain
and how does it change the way it's
regulated now because what happens now
and there certainly a lot to do there is
that you know all the laws and
regulations are done with the assumption
that decisions are made by
humans once decisions start being made
by AI a lot of things change in some
cases you need reg new regulations in
some cases they need to be different in
some cases you can actually remove them
because there's a presumption of biases
and things on shortcomings and evil
intent and and uh you know lack of
transparency on people that is not the
case for AI so this I think is the right
way to to to regulate AI or AI
applications okay so as I understand you
think that let's say some with shouting
we need more regulations and all this
stuff basically shouting that I don't
want
competition well there's a there's a
combination of of players in this game
if you will uh but the first one you
mean
so there
are where to begin um there's a lot of
people who are screaming for AI
regulation because they honestly believe
it's very dangerous okay they're not ill
intention they're not corporate chills
they're just a little crazy in my in my
view right AI has this amazing potential
to evoke in US these sci-fi scenarios
right and Hollywood has fostered that
right like when people think of AI they
think of Terminator and kind and like
real AI is not like that but a lot of
people don't understand that right and
and even you know uh uh and I can see
late people falling into the but there's
even some people who are AI experts
who fell into this and I think partly
it's because AI is really a new thing
and we've never seen intelligence before
except in people and and animals which
in some in that regard are similar and
so anytime you see an intelligent thing
like computers being intelligent you
start projecting onto them human
characteristics that they just don't
have like Free Will and emotions and and
intentions and and Consciousness and
blah blah blah right none of that is
there but people can't resist you know
in the beginning when you try to chat
GPT you think it's very human right most
of that is just being projected by you
after a while we start to understand
that actually it isn't right and it's
it's good that people are are doing that
learning but in the in the beginning
people are very easily fooled even
experts can be fooled so those people
are raising you know the alarm uh uh
then there's sort of like the media
loves this right the media loves alarm
stories right they're not you know you
don't get headlines saying like AI will
not harm
anyone you get headlines saying AI will
extinguish human civilization and then
of course this is what people read so
they start to get worth because that's
the information they being fed right now
as you mentioned there's also another
aspect here which is the incumbents the
big tech companies have a lot of
interest in actually keeping AI closed
right they they you know like it is well
known that in every domain regulation is
to the benefit of the incumbents over
the newcomers and the irony about Europe
is that like the incumbents are American
and they don't like you know the you
know the power you know that that that
American companies have they are without
realizing it helping them with the AI
act helping them against startups that
might come from Europe and so some of
these companies are playing a somewhat
cynical game of being in favor of
Regulation because they know they know
how to get around it right you has had
previous regulations like the gdpr that
have been harmful but largely harmless
because you know the companies know how
to ignore them and pretend you know like
it's again they're so illd defined that
if you're a big company you have the
lawyers to get around this it and it's a
barrier to entry like income it's like
barriers to entry right and you know AI
could be very threatening if you if you
leave it open for everybody to do it so
of course a lot of you know not just
companies but various organizations you
know like being protected also I
think um some of these companies say
they're in favor regulation because they
are convinced that regulation is
inevitable and they want to have a seat
at the table if they come out saying
like no we're against it then they'll be
excluded they are like yeah yeah we're
in favor so they get to shape it right
it's a very political thing right and
then there's another one which for
example companies like Facebook have
learned very well which is and I think
Google is also learning this for example
which is a lot of these decisions around
AI are very
contentious and very you know polit
people from the left and right will have
very opposing views on them and no
matter what you decide it will be
unpopular and the people who like your
decision will take it for granted the
ones who don't like it will hit you for
it so no matter what you do you'll
always wind up less popular so they just
want off flow this to the government
this is why Facebook created this panel
to make independent right Mark
Zuckerberg is not known to be you know
um uh um you know easy on control right
but like he actually you know
deliberately gave power away to make a
lot of this like sort content decisions
to an independent commission precisely
for that reason because now then they
they take the blame right so there's a
number of reasons and the number of
players why this you know a regulation
is promoted unfortunately none of them
are good
ones you are making a lot of fun of
Europe and since I'm from
Europe I I want you so you think uh this
can play a big role to
the to like now United States is a lot
more powerful than Europe anyways but
you think it will play a big role to
Europe going downhill if it doesn't
adjust to the AI
uh well yes so first of all I'm European
as well I'm originally from Portugal and
and and the reason I care about what's
happening in Europe and I'm very
frustrated by it is that you know I care
I'm European right most of my American
friends is like or Chinese for that
matter like well Europe is irrelevant
like who cares you know like they're
gone right never mind I'm not I'm not
I'm not ready to concede that so you
know so I care because I'm European uh
also like there's also around the world
a lot of people including in America
like in States like California even now
you know at at the federal level say
like oh we should follow Europe's
example right so so so so the the the
damage that starts in Europe could go
beyond Europe But to answer your
question uh absolutely I mean AI is not
just another technology AI is the
automation of intelligence it's like
everything that use intelligence for
which is just about everything can in
principle in the shorter longer term be
automated with AI so whoever is in the
lead in AI will be in the lead
economically not just technologically
economically
militarily right China you know is going
all out they have a plan they say we
want to you know they recognize the
importance they want to be world leaders
in AI they're still behind the west but
they coming up rapidly they're going to
overtake the West in maybe a decade or
so it depends in some Fields they
already have in others it'll take longer
but you can't be a a powerful prosperous
country or economic zone in the 21st
century if you don't get AI right there
there is a lot at stake in
this so you are doing this criticism out
of pure
love well it's it's it's you know I care
what happens in Europe right and and and
you know first of all I care what
happens anywhere as a human being but
particularly in Europe because because I
am European and also I mean because I'm
I mean I think I mean I grew up in
Europe being interested in Ai and you
know Europe Europe used to be a leader
in AI right now now that it's a is
becoming important they figured out how
to basically lose the race that they
were aheading not ahead of the United
States but but comparably so so you know
I feel you know terribly frustrated with
this also um the AI act doesn't come out
of the blue like the the EU has passed
the series of laws like the gdpr and the
digital markets Act and the Digital
Services act that are all stupid all
stupid in the same ways instead of I
mean like nobody I mean like nobody can
name you know gdpr is supposed to
protect our privacy does harm in a whole
bunch of ways you know it's the Cookie
Monster right like now you have to click
on all these cookie authorizations but
you know that's that's the list list of
things right anybody who has a small
company in Europe in Tekken or even says
like oh the GPR is such a pain to deal
with right like you know like I I called
you know like some months ago to like
you know to cancel hotel reservation in
Portugal and I had to listen to a
message explaining you're blah blah blah
and your privacy rights and like you
know multiply this by millions like this
is just ridiculous right so Europe has
done a of these things but instead of
listening to the backlash they think
they're very proud of themselves you
know the so-called Brussels effect that
they passed these laws and then you know
companies would rather you know use them
um companies don't want to have one
product for Europe and one for the rest
of the world so when Europe passes these
laws as happened with the gdpr they will
often make changes to their product
worldwide so the European legislators
are very proud of this it's the one area
where Europe is having a lot of
influence
you know I kid you not like America and
China want to be the world leader in
AI their lion the the the president of
the European commission the president of
Europe says that Europe wants to be the
world leader in regulating AI wow what
an amazing accomplishment is really that
what you're shooting for you're kidding
me so I want you to explain a bit for a
stupid me and some people that don't
know what AI is we hear this word all
the time what is it is
there AI is the automation of things
that traditionally only humans can do of
the higher level cognitive abilities if
you will it's the automation of things
like Vision uh manipulation navigation
uh understanding language Common Sense
reasoning uh solving problems and very
importantly learning
the amazing thing about humans or
mammals in general is that we can learn
machine learning is the subfield of AI
that deals with automating learning and
then now Powers the rest of them right
so this is what AI is there's a lot of
this sort of like if feel sort of like
the lay person's definition of AI
there's you know there's a lot of
confusion a lot of hype it's you know
it's almost become a vacuous term in
some quarters there is also a more um
technical definition which I actually
think is worth knowing because it's very
enlightening with respect to some of
these things that we've been discussing
and this is that AI is the subfield of
computer science that deals with solving
intractable problems using heris methods
intractable problems means problems that
take an exponential amount of time to
solve or or memory and so on most things
in computer science can be done
efficiently like you know databases and
computer graphics and whatnot AI even
just playing the game of chess perfectly
would require a computer bigger than the
universe so you have to resort to heris
rules of thumb strategies that sometimes
will go wrong this is unavoidable and AI
is the field that deals with this so if
we want to solve problems like urine
cancer for example we have no choice but
to resort to AI techniques right but you
know but at the end of the day an a
system is just an Optimizer it's just a
problem solver it's not a little agent a
little being with you know intentions
and emotions and whatnot that's like you
know so keeping the real definition in
mind I think is very important you know
as a as is a first step to knowing what
you're doing when you're discussing what
to do about Ai and and regulating it or
or or you know how to use it in your
company
Etc and can anyone start AI in
2024 Ani llm L
language anyone can use Ai and does
right anyone can use a chatbot uh I
would say there's sort of like maybe
three major categories there's the L
user which we all are which use AI every
day without even realizing it when you
use the Google search engine you're
using AI you just don't know it when you
use Twitter you're using AI because
there's an AI algorithm selecting the
tweets that you
see so we are all power users of AI
without knowing anything about it now
there's another level which is where you
people who can use and do use today and
they'll be more AI
professionally without understanding in
detail how it works think of for example
a cab driver right who drives a car for
a living doesn't necessarily know a lot
of mechanics right the mechanics the
mechanics you the engineers know how to
deal with that right so a lot of these
people you know and now there can be of
course a spectrum of expertise there but
a good example this is a lot of people
who do data science they do modeling of
various problems in various areas could
be biology and Medicine could could be
businessing economics could be a lot of
things they do they know AI at some
level but they don't have a PhD in
machine learning right and then there
are the people who do have a PhD machine
learning who are exceedingly valuable
and and costly these days who really
know how to build this machine learning
algorithms and and refine them and and
you know develop new algorithms for a
problem for example as opposed to just
using existing ones off the shelf so you
you could be in any one of these buckets
if you will and you can of course move
from one to
another
so I'm not sure if you answer that
question is it easy from one average
person to get involved and immediately
start his own AI to do something with a
goal with the AI to do something so I
mean let me give you an example um you
can an average person can go on chat GPT
and just start asking it questions and
asking it to do things so anybody can do
that right and they can learn to prompt
it and become a prompt engineer right
there's this new occupation called
prompt engineer so people can do that
another thing that people can do let let
me give you an example there's a little
more advanced so like there's this site
called kaggle that runs machine learning
competitions a company has a problem
like say I'm a I'm a drug company and I
want to do some drug design or like I
have some prediction problem they make
they publish the data set and they
publish a prize for whoever wins it for
whoever you know is most accurate at
predicting whatever these tumors or
whatever they care about right churn you
know in in insurance or telecoms or
whatever right and anybody can enter
that
competition anybody you or me right and
they can use off the-shelf algorithms to
do it in fact most of the time that's
what people do and and if you win you
win and if you win a bunch of these
things you become a kagle Grandmaster
and and and you can get hired by in some
cases like you know the Googles of this
world just on the basis of being very
good in kagle with no degree no anything
in machine learning right of course you
can also in kagle develop your own
algorithms and you know there there's a
a gray zone between am I using off the
shelf or I'm building something from
scratch right usually what happens that
you know you start with the off the
shelf and you play with the various
options and at some point you realize
you want to extend it right so like it
is a very natural path you can both you
can go from being a 16year old late
person to being a world expert I mean
I'll give you an example uh uh there was
this thing some years ago called the
Netflix prize which was the predecessor
of a lot of these things Netflix you
know has this recommend a system that
they use to recommend you know films uh
uh and TV shows for you to watch that is
really crucial to their business three
qus of the things that people watch come
from the
recommender and and at one point there
machine learning people said like well
we don't know what else to do we're
already predicting as well as we can and
somebody had the idea of you know having
a public competition so like well we're
just going to give a million which at
the time was an astronomical amount of
money this was in the 2000s and say you
know anybody who can improve predic you
know we're going to run this for
whatever two years and there'll be
partial prices for anyone who can
improve prediction by more than I don't
know one or 2% and then you know the
winner will get a million dollars okay
and they the Netflix folks themselves
didn't think anyone would succeed
because you know it was just too hard
within three months the late people were
already beating them right and I have
you know I teach these evening classes
to people you know in Industry that have
their jobs one person in my and I gave
this prize you know a simplified version
of it as a class project right you know
here's some Netflix data uh you know go
go and predict you know what movies
people want to watch and there was one
guy there who didn't know any machine
learning before he knew some computer
science so he was not a complete lay
person but he he did that and then he
got interested and you know a few months
later he was in one of the winning teams
of Netflix of the Netflix prize so he
went from knowing no machine learning to
being one of the winners in I don't know
six months so it's definitely
possible uh you wrote this book that was
very successful about AI in 2015 what
you got wrong about it because uh a lot
of years
passed well honestly to give you a very
honest maybe self- serving answer I
don't think I got anything wrong about
it uh I I I wrote so obviously uh you
know uh eight years have passed and a
lot of new things have happened and
there's a lot of new developments
particularly related to deep learning
obviously also I had the chapter about
you know what's going to happen in the
future and and uh the chapters that are
about Ai and the different types of
machine learning and whatnot all of that
is
current uh because I wrote it with that
in mind I was like I want to write a
book with things that will not be
outdated tomorrow right and I you know
and again the interesting thing about
machine learning and AI is that there's
new things by the day but the basic
ideas haven't changed since the '
50s there are key ideas in machine
learning that that have been there since
the field began right and you know and
of course I tried to focus more on these
things the chapter that uh you know if I
had to say where I you know um went
wrong in some degree was like like I
predicted some things that happened to a
much greater extent than I
imagined so I thought you know like
these companies are doing this and
trying to keep a ey in their hood and
you know hoping to fly under the radar
and this is going to blow up and then
people are going to call for
restrictions on AI and whatnot and I'm
telling you this is coming wow I had no
idea just the
scale on which that happens so if I ear
on anything in that book wasn't just you
know underestimating how big you know
some of the um reaction and the backlash
and the changes would
be and uh curiosity about the book so
the book is selling uh B better now than
it did in the start because of the
relevancy of the event or no so the book
had a very unusual sales trajectory so
the book by now is a worldwide best sale
it's been published in maybe I don't
know at least a dozen countries it sold
over a third of a million copies which
for a non-fiction book is is pretty rare
uh in the beginning it it wasn't I mean
it reached the bottom of some bestseller
charts but it wasn't a huge bestseller
and and and I can understand like this
is B about algorithms all the publ was
like algorithms like why would anybody
care about algorithms like trust me
people will care about algorithms and
you know again now now now nobody
questions that but it wasn't an obvious
like you know bestseller but I think it
it it it sold a lot largely onward of
mouth and people who wanted to learn
more about machine learning and you know
they don't they're not going to read the
textbook right and this just not
different level this is for like you
know one of the pictures I had in mind
was like you know a 16y old old kid
smart you know 16 years another one is a
CEO I'm the CEO of a company I need to
get on top of this day I think I'm not
going to read a a thousand page machine
learning textbook it ain't going to
happen like so like machine learning for
CEOs and indeed a bunch of CEOs um you
know for example Jensen Wang who's not
very famous because Nvidia is not very
famous but back then wasn't this was
when they were about to make their pivot
to AI he told everybody at the company
that they had to read the
book very smart on his part like he was
you know they used to do computer
graphic like now we're going to do AI
people read this book everyone has to
read this book right I had many sort
like people from Nvidia companies like
oh wow I read your book because Jensen
made me uh but you know but this spread
the word a lot and then the book never
books usually sell well for a few months
and then they kind of disappear the book
has continued to sell well you know even
now right it's not selling as well as it
did at its peak which again was maybe
I'm going to say like six months after
it came out again as opposed to like the
following week but it's still selling at
at a steady clip which I think is
remarkable given you know how fast
moving AI
is what do you think you did right on
the book is it by the way I want to
compliment you you are explaining things
very well you are amazing communicator
but I'm curious to see if that's what
you think uh you did WR in the
book I think I I think I did a few key
things right in the book I also made
some choices uh that I could have made
differently and they and might have been
better I think uh the most important
thing was writing that book at that time
right I had the idea of writing a
popular book on machine learning since I
Popular Science book if you will on
machine learning since I was a PhD
student because you know I've read many
popular science books I like the genre
when it's well done it's very useful and
and fun and it was clearly in the '90s
when I was a pent that M leing was
becoming very important and someone
should read a popular science book about
it and I only saw and nobody ever really
did that there were various books of
like that science this but like I was
very dissatisfied with all of them the
thing that finally dis this you know
made me decide to write the book was two
things this was around 2010 2012 there
was this big wave of hype about big data
right it machine learning under the name
of big data was now you know in
newspapers and whatnot and the sheer
amount of incorrect information was just
like ah and the mistakes like companies
like wasting years and millions or more
of dollars on on just like stupid
projects that you know if they'd read a
simple book they wouldn't have I was
like somebody needs to write it the
other one was the idea of the master
algorithm because like when you write a
popular science book it's not a textbook
right it has to have a theme and a
thread that keeps people interested
otherwise they'll put it down right when
you write a textbook you have a captive
audience the students have to read to
pass the exam public science book you
know it's like a novel if you're bored
you stop reading it and then the rest is
wasted right and and the master
algorithm that's when I had that idea
right like the master algorithm is this
idea of a single algorithm that can do
everything which seems like magic right
like how could one algorithm do you know
drive a car and play chess and do
medical diagnosis you know all at the
same time one algorithm can and does in
particular for example back propop is
behind all of these things uh but
training on the appropriate data right
and this is really the idea at the core
of machine learning the reason the thing
that's so exciting about machine
learning is that you can write one
algorithm that will be good for an
Infinity of different things so I
thought this is a great threat to
organize the book around I think that
was a good call the third one and and I
agree with you was that I put a lot of
thought and a lot of I already knew the
stuff right I've been teaching it for
you know I've been teaching it for over
10 years when I wrote the book The
question is like how do you explain it
in a way that is interesting and
accessible to someone who has no
background in computer science so you
have to use a lot of sort of like
analogies and and and and examples and
and put things in a way this is the key
that is that anyone can understand but
it still conveys the essence popular
science books tends to either be written
by scientists and then it's about their
own research and it's like full of
overly technical stuff right so people
don't read it or they don't get it like
they they don't get most of it or
they're written by journalists and
they're full of mistakes or they're like
they don't really get at the heart of
things so that I you know I put a lot of
work into that having said all of that I
I did sort of like I had this
determination which in in in retrospect
is kind of makes me smile that I'm going
to write a book that really covers all
of machine
learning right I was very also
frustrated by like you know there are
these different schools in machine
learning like you know deep networks is
one but there's others and people tend
to you know write books as if their
school is the only one and grow up
thinking like you know deep networks are
all there is or symbolic as all this and
this just bad right so I wanted to write
a book that cover the whole Waterfront
and and and a certain level of detail so
I could have written a book that that
that would be more
accessible by not going so deep it might
have had a bigger impact because maybe
instead of you know 300,000 people you
know reading it or buying it there would
be 3 million right so I deliberately
made that trade-off but you know I could
have made it otherwise I also tried and
this really is an art to write a book
that would work at multiple levels you
sure more of a late reader and a quick
reader you will read you should be able
to read enough and then skim some other
parts that you got the idea and then
there's other parts usually later in
each section or in each chapter where if
you're more you know interested and you
know more you can you know you can go
deeper so now I've had a lot of feedback
from people on on on the book and I
would say that at the it's interesting
at the end of the day the people that
got the most out of it were people who
do have some technical background maybe
engineers in another area or biologists
or scientists or even computer
scientists who didn't know machine
learning before or even machine learning
people who actually didn't know half of
the things in the book they they they
they can get what's in the book at a
level that people who are just reading
it you know with a fresh mind can't but
but hopefully everybody
benefited the big question do you think
they they have or they will uh G
Consciousness on the
way well first of this is a big question
indeed uh but the first question within
that question is like what is
consciousness nobody knows what
Consciousness is so since nobody knows
then we can't answer the question do
machines have that Consciousness or not
right so there is What's called the easy
problem of Consciousness and the hard
problem the easy problem is I can find
things that are correlated with
Consciousness so for example there are
neuroscientist like Christoph cook for
example who what they do is they look
for things in the brain that correlate
with being consciously aware certain
neurons firing or certain circuits being
on and whatnot so you can do that and a
lot of progress has been made there and
you can look through those correlates in
AI right then there's the hard problem
which is like but how do you know that
that thing really is conscious and the
truth is that at the end of the day this
is not a question that can be answered
scientifically because only objective
questions can be answered scientifically
and ultimately consciousness is
subjective I know that I'm conscious
that's in some sense the only thing I
know right and I'm willing to believe
that you're conscious but for all I know
you could be a robot and for all you
know I'm a deep fake of Pedro domingus
I'm not the real one right so in the end
nobody really can answer the hard
question now the way I think this is
going to play out is that 99% of the AI
systems in the world are not going to be
conscious at least by any you know
Common Sense definition of Consciousness
and they don't need to be right they're
just solving some problem they're
finding a kid from cancer they don't
need to be conscious there will be some
AI systems like for example think of a
house bot right a robot that you know
cooks dinner you know does the dishes
makes the beds blah blah blah this robot
has to be so similar to humans in terms
of their perceptual and motor abilities
that it's hard to think of it being able
to function without at some level in
terms of the correlates being conscious
right it's got to do it's got to have
Vision it's got to have hearing it's got
to manipulate things it's got to
transform one to the other you know it's
got to process a very intense you know
stream of incoming information so at
some level you could say that it must be
conscious now but you but the
philosophers could say like no no no
this is just some computer circuit that
does something that looks like it's
conscious but it's not and I think
that's what going to happen at the end
of the end in fact this is already
happening is that even
prematurely is that as soon as the
computers the AIS the robots start
acting as if they're
conscious when you look at them I mean
like this was the lamba guy right the
Google engine says like lambas conscious
because it felt conscious so people will
start treating the systems as they
conscious and you know for the purposes
of the lay person in 2050 AI will be
conscious the ones they know right you
know whether or not they really are
conscious is is a question that we the
experts and the philosophers can debate
but people will just treat them as being
conscious so you are saying
having Consciousness or not is
irrelevant if we are treating them as
conscious no I mean exactly I mean an
ultimately this again depends on your
philosophical point of view uh but I
think from a practical point of view
it's like AI is are tools and the
question is what they do for us right
and if they're doing for us what we want
to do for them then these questions like
do they have Consciousness I really not
you know like what I care is whether the
machine found a cure for my cancer and
say my life or whether my house bot does
my choice for me or breaks down right
well now it does become relevant you
know there is one important Point here
which is and again you see that today
there's already a lot of people saying
like oh AI are going to be conscious
therefore they must have
rights so there are some people who say
if they're not conscious they don't have
rights but if they're conscious they
have rights so at that point this is not
just a philosophical question because
you have to decide whether they do have
rights or not my position on that is
that you must be insane if you think
machines should have rights I already
think that animal rights is a bit of an
oxymore like why should animal have
rights right it makes no sense right so
if animals shouldn't have rights then
machines for sure shouldn't have rights
but there are philosophers you know like
the Peter singers of this world that say
well there's this you know like first we
gave rights to other humans and then to
animals and the next thing we're going
to give rights to machines they're going
to have rights because right and this to
me is like completely um confused and
wrongheaded but there's people who
believe
that uh so many questions about what you
said but so you don't think animals
should have rights
no so I mean like let me ask you the
question let's assume that you think
animals should have rights right animal
you right there are now laws in the
books in many countries if not most
giving rights to animals right what is
the rationale for doing that and again
this is useful exercise because then you
can do is the parallel of that with
machines well are these Reasons by which
we gave rights to animals if we if we
don't buy them then never mind but if we
buy them then by analogy should we give
those rights to machines as well you
could also think that like if at the end
of the day you don't want to give rights
to machines you have to be very careful
about what bases you give rights to
animals on because it's a slippery slope
so tell me why animals should have
rights well because we don't know like I
don't know if you are conscious we don't
know if they are conses and if I killed
them why I don't kill you then if I kill
a chen so you so to rephrase your
argument you're saying like well animals
are similar to humans so they should
have similar rights right but again this
is a very slippery slope right I can
pick up anything that's similar to
humans and say well this thing should
have rights right like that that you
know similarity is a very squishy very
vague concept right the the question is
and again this is a machine learning
question is like and where where do you
draw the boundary right there's all the
things in the world you know including
rocks and Grains of stone of sand and
you know plants right uh plants are
living beings right why shouldn't they
have rights right there are some crazy
people who think they should right and
the question like where do you draw the
boundary right and and now you could to
me the obvious place to draw the
boundary because it's other the humans
the ger it's not to say that there
aren't similarities to animals of course
there are but the jump for humans to
animals is huge right but now there and
you could also say but now like but
there's a deeper reason right which is
you could say right as somewhat implicit
by by what just is like I'm the only one
who's I know conscious so I'm the only
one who has
rights I shouldn't have rights I Pedro
you know you should right so now good
luck enforcing that if you're the king
of the world then maybe you can enforce
that otherwise it doesn't matter right
you can believe whatever the heck you
want right now to me the real question
and this really is the main point is
that there is no philosophical answer to
this what you need to ask is like what
is for the greater good right you
compare two societies which one will do
better one where people have rights or
one where they don't and I would say you
know glossing over lot of philosophy
that a society where people have rights
functions better will progress more will
outdo do a society where they don't
animal rights I have seen no such useful
consequence in fact I see a lot of
negative ones but this actually thing in
some ways it Wells down to an
evolutionary question in my mind
everything is subject to Evolution
including ideas like human rights that
didn't exist and could go away again and
and you know in the struggle for
survival between societies right like
the Nazis didn't believe in human rights
we did but we won right was that an
accident or did it have something to do
with the fact that we believe in human
rights
right so I think that is that is the the
the the only sort of like way to discuss
this question that doesn't get mared and
sort of like a philosophical
bug uh I'm curious to so I saw a robot
in Real Life uh and I was talking to it
uh and it was one of the craziest
experience of my life it's it's it's
easy to see it on a video I saw so many
videos before but actually talking and
communica with a robot and AI it's it
was a striking experience so that got me
really thinking about the Friendship
yeah I wanted to uh impress the AI I
want saying smart things I was asking
smart questions to makebe uh also I was
thinking wouldn't be cooler to get
married with a robot instead of a human
so I'm curious to hear what you think
about all these things and the future of
these things well so first of all all of
these things are already happening and
they will happen more there are people
who say they fall in love with chatbots
10 years ago there was already a chatbot
in China called ja Weiss that has the
Persona of a teenage girl and you know
40 million Chinese teenage boys have
said they're in love with
her this is not one or two crazy people
and it's not today it's not chaty P this
is 10 years ago and it's tens of
millions of people right and now and and
and you know and there's companies that
for example produce sex bots right and
they're getting better and there's there
are serious scientists you know at
places like MIT for example that say
like yeah you know humans are going to
have relationship with robots and it's
on balance a good thing because you know
we'll be less lonely and whatnot and
again this gets back to my earlier point
that like when you talked with that
robot I agree it can be an uncanny
experience and you were projecting onto
it all of these human characteristics
that it does not have you were
interacting with it as a human but
people will do that to some extent they
will learn to not do that when they see
how they really aren't you know like
real humans but to a large extent they
will and and now you can say and it's
unavoidable and you probably shouldn't
fight it you can ask yourself is it for
the better or for the worse right and
some people are like oh what a horrible
thing people having relationships with
robots what could be more you know sad
right and I again I I'm I'm practical
about these things right if you're like
some poor you know in cell who's given
up on women and is going to not have a
relationship with anybody their whole
life then may be having a relationship
with the with the with the bot of some
form it will actually make them happier
and a better Citizen and whatnot so you
know who am I to judge right go ahead
and have a relationship with a robot
right in fact I can well imagine the
future not tomorrow because you know the
the this the the the technology isn't
there where most people their partner is
a
robot and they look at they you know and
they they have you know they you know
imagine this scenario right like every
most people have as a partner a bot
right designed to their liking that you
bought like you can buy a car and then
they do everything for you they're your
romantic partner they're your slave they
they they they are they are a search
agent they're like you know they just do
absolutely everything for you right
including sometimes challenging you
again part of why Chia Weiss was very
smart was that sometimes you know like
you you say like oh I had such a hard
day sometimes she commiserates and
sometimes she's like oh man up right so
so how you do that I think there will be
a lot of competition among the producers
of this is to figure out like the most
engaging but like at the end of the day
most people are going to live with a
robot and they going to look at the PMS
who still live with another human being
with equal rights and all those like oh
my God like why do you put yourself
through that miseries is like you know
maybe the Amish will still you know have
human Partners I could see that
happening wow by the way I'm I I really
I got to understand the rhythm of
thought that you had during podcast you
always ask is this going to help the
humanity in the future and you re and
can you tell me more about this rhythm
of thought like you when you want to
solve a problem you ask this question so
I found that very interesting no so I
agree with you and in fact I I I try to
do that I think we all should do the
following right like when
we when we for example let's say you're
deciding what to do with your life right
what are you going to major in what
profession are you going to go into what
project will you work on you want to do
something that you will enjoy right so
that's that's good but that's a very
under constrainted thing I enjoy a
million different things so where things
get interesting is like you shouldn't
I'm always telling this to my grad
students don't just pick the first
research project that you like try to
pick the one that has the biggest
possible
impact this is what makes this so great
is humans can look farther ahead
right a dog doesn't look years ahead
they just can't right but we can and so
what you do is like you said like so
what you know what is for the greater
good and unfortunately we humans have in
us a lot of things from evolutionary
time that kind of tend to sabotage us
like we actually have tendencies that
were maybe good and million years ago
but not now so you have a conscious
reasoning mind to overcome those you
know it's the marshmallow test do things
for the short term pleasure that
actually you know bad for you in the
long term so you can overcome that and
we should make all these decisions from
the personal level to the policy level
to the whole society level like you know
should you go to war right a bunch of
people will die but maybe it's worth it
because you know in the end you know
many more people will be happier free
etc etc so you should always be trying
to do this now technology and AI in
particular are a very um you know sharp
Proving Ground for this because there's
a bazillion things that you can do most
of them wrong right and and you're right
I'm always trying to do this so like
well there's all these questions and
analogies and hand waving which is okay
but at the end of the day you got to ask
okay we have this choice between us
should we regulate AI for example or or
or you know what machine should we make
you should reason back from what will be
for the greatest good of the greatest
people and if you do that at the end of
the day you'll do much better than if
you don't do that but it takes a certain
discipline right there something I don't
think it comes naturally to people you
know including myself you have to train
yourself to think like this interesting
so now you're
elevating you and you're say maybe when
you have a part to choose or a decision
to make and you are between some parts
you are
asking what PA will have uh also
something that I'm good and all these
things but greater impact in the world
and that's most likely the right path
yeah you have to think about the people
do things too much without really
thinking the consequences through
and without thinking far ahead enough so
for I'll give you a very simple concrete
example people in both uh you know
research world and in tech companies
they're often working on things that say
say for example you're doing a PhD right
it takes five years don't work on
something that in five years time will
be outdated because Mo's law has made it
irrelevant you got to be doing research
for the technology that will be there
when the research is ready which if the
technology wasn't moving wouldn't matter
and in some cases that's okay but in
something like AI right I think one of
my complaints about a lot of what's
happening today is that like everyone is
sort of like converging on like doing
all these tweaks on llms right which in
10 years time are going to be completely
irrelevant because like LMS will be
outdated it didn't matter right so like
think further ahead right and for
example someone who actually I I saw
recently like a snippet of an interview
that he gave that did is very I think
was Steve
Jobs Steve Jobs you know said like you
got to start working on something before
the technology is really there because
if you only start working on it when the
technology is there you'll be late to
the
game but if you're too early then you
know then you're going to fall flat so
you got to be doing this thing of saying
I'm going to do this it's going to take
five years and I hope that in the
meantime with five years of progress the
technology will be there and then you're
the pioneer of course things can go
wrong right but you got to try to make
that projection and and and and and
continually updated and that's how you
do things with great impact it's not
just like oh what is a cool thing to do
today let me go you know do some better
prompt engineering right five years from
now probably no one will care about
prompt engineering or maybe they will
but then that should be a rationalist
like I really think that prompt
engineering is going to be super
important and so that's what we should
focus on so I think doing that thinking
ahead is very
important I want you to do a more
exercise with me and try to imagine uh
the future in some areas like it's
politics uh with AI how like how does a
government looks with AI and maybe we
can touch on education as well after we
do
these so I think politics with AI will
look very different from what it does
today so uh number one uh autocracies
like China they're already making full
use of AI to control their population
better and
whatnot democracies unfortunately so far
they're mostly paranoid about how AI is
going to damage democracy which again is
is doesn't make any sense to me there's
going to be all this disinformation and
whatnot like we already have
thisinformation why the bottleneck is
your
attention what we really need to do and
unfortunately not enough people are
thinking about and this is going to
happen sooner or later is how do we make
democracy better with
AI the way democ Cy works
today made sense in the 18th
century you vote once every four years
it's like you know the number of bits
information that you send to the
government per year is close to zero
it's less than you send to Google in a
minute by clicking on things it's
ridiculous right and voting is just like
chel said it's the best system apart
from all others but with technology now
we can have a better democracy what
would a better democracy look at for
example this is one one of the sections
in the last chapter of the massin is
precisely about the future of politics
and democracy right what would that look
like for example you can have models of
people for
example Netflix has a model of view to
recommend
movies which serves you very well right
A lot of people go like well like
Netflix is this uncanny ability to guess
things that I'm goingon to like you
recommend something like I don't think
so but like you know I got a
subscription let me watch an episode and
go like wow I love this and you know
it's like some BBC TV series from the
70s that you never heard of right now
politics right your representatives
should know what you want it's their
freaking job to do what you want they're
representing you not themselves but part
of the problem is that they actually
don't know you that well and you're
suspicious maybe also of letting them
know too much but what they should be
able to have with your consent or to the
extent that you want right is a model of
who you are what you believe in you know
are you pro choice or or or or or pro-
lifee right or or or at a deeper level
what are the considerations that are
important to you what are the things
that you care about right and not just
sort of like on the top 20 questions
like you know proun and - gun or
whatever right but like you know what
really affects you and then they can as
people already do in other domains when
they're about to make a decision whether
whether to vote for something or to
propose a legislation they can run it by
the models of their constituents and see
what the constituents
think and then what happens is this
apparently magical thing which is you
now have a lot more influence in what
the politicians do without spending a
lot more time people don't have time for
politics right it's like I got a job I
got a blah blah blah I don't like you
know like the week before I figured out
who to vote for based on a few ads or
things that I saw this is terrible right
you got to make it easy and effortless
for people to inject their preferences
into into politics because that's what
democracy is and machine learning allows
us to do that so this is just one
example so I think a a more a and you
know and then of course the politicians
could use this to manipulate you but you
also going to have other organizations I
can have Watchdogs I can have media I
can have journalists that also have
their models and go to the politicians
ah look you know you're promising one
thing to Pedro and another one to Fus
how come right so so everybody is going
to be an ecosystem politics today like
everything is an ecosystem with the
politicians you know like the the
journalists the everything right the
activists
you you're still going to be an
ecosystem but every part of their
ecosystem is going to have ai at their
disposal they're going to have models of
themselves and of others and these
models a lot of the talking is going to
happen between the models without you
know even the people intervening because
they can just do it a thousand times
faster at a thousand times greater
volume right and then some things they
have to push them up to like you they're
so important and so unclear that you
know it really comes you know down to
asking you but those will be the
exception rather than the rule right so
again this this you know um I in in in
the master algorthm in that last chapter
I called it a society of models right
societ is a bunch of like it's like you
know if you're a very rich person today
you can have a thousand people or maybe
a 100 people working for you right in
the future you will have a million
people working for you some of them will
be your own permanent activist that is
always in touch with the agents AI
agents of your Senator or you're you
know Member of Parliament or whatever
right so these are things are going to
work in the
future
uh so uh generally you agree with the
concept of democracy but you think it
can be done more efficient or because
maybe we give power to the people maybe
it's not good because the average person
is
stupid so a very good question so I am a
Democrat I am a very very strong
believer in
democracy uh but what we have to realize
the following is that the the struggle
between democracy and autocracy here or
other Alternatives is perennial it
existed in Greek times it will it will
exist forever and and this is the key is
that technology changes the nature of
that struggle when new technologies come
along I mean you couldn't have countries
with votes before because you know it
just couldn't right like and you know
when the American Constitution was
drafted you know you had to go by horse
or by whatever you know from you know
the west coast to DC or not the West
Coast but whatever other states right so
like and when radio and TV came along
that changed the nature of democracy
right and and when you look at democracy
or autocracy they each should look they
each will look at how they can best make
use of the new technology so it's not a
static field and the autocrats are using
AI the democracies have to use AI It Is
by no means guaranteed that democracy
will always win there's being better and
there's winning I think it is better for
a number of reasons right also because
one of the fundamental reasons why
democracy is better than tocy is that
democracy brings more intelligence to
bear on the decision-making
process the me let me tell you because
it goes exactly to your point of like
which for example in in in the in the in
the in the framers of the US
Constitution this was something they
were very even worried even paranoid
about which is like you want to give
power to the people but not too much
because sometimes they turn into a mob
and they're you know an uneducated Rebel
so we let them elect these
Representatives but then the
representatives are the people right so
like so this is one view right so
there's different kinds of democracy and
in a way what I'm saying is going to
happen is that we're going to have other
yet different kinds of democracy
tomorrow but in particular right I would
say that one of the crucial things that
like we do not need rep we are with AI
we're not going to need Representatives
as much as we did before because AI can
do some of that work for us your AI is
your representative and and the problem
that we have in politics is actually in
economies and a lot of things is the
agency problem your representative
interests are never quite the same as
yours they want to get elected they have
their own agenda sometimes they're
corrupt etc etc with a eyes right if you
control them enough which is a whole set
of other issues like you can avoid that
right and now you can say like oh but
the people are too stupid well people
today are far less are far more educated
than informed and and and knowledge and
everything than they were 200 years ago
right and so for example I am in favor
of having referendum for key issues some
people think referendums are bad things
because then people will vote themselves
uh you know inconsistent things and
whatnot but then it's for the
politicians to decide how to make them
consistent right I think at the end of
the day the big decisions should be made
by the people also because I mean like
again positions will appear on this but
it's like I could say sorry you're
stupid I'm going to make decisions for
you but my view is like who the hell am
I to say you're stupid I'm going to make
decisions for you like just go to hell
already right that is so condescending
it's like and I honestly my fellow
academics and experts fall into this a
lot is like I know a lot more about
economics than this random guy on the
street so the mark this is like the
platonic idea right it's like you know
the the knowledgeable the experts the
good guys should rule the problem is
that first of all then the self-interest
dis like you know your interests become
destroyed by mine so maybe you even if
you're stupid are better making
decisions than me intelligent who I'm
not really making them on your behalf
but according to my distored view of you
and my own you know prejudices and
preferences right number one right
number two is that like again people
often don't appreciate this and and
again AI is going to exacerbate this or
or improve it is I as one expert may
know more about economics than you as a
non-economist let's say but that's not
the comparison the comparison is between
a thousand experts and a million
people the total intelligence of a
million people just dwars the total
intelligence of even the Thousand most
smart smartest people in the world you
know the details of your life and what's
good and bad for you way better than I
ever can I don't know anything about
your life right I may know some
economics laws and whatnot but but like
my intelligence does not outweigh the
individual intelligence of the million
people about what's happening in their
lives and what we see all the time
because you know today this is an Avo
like politicians just make bad decisions
often because they you like look at what
happened with mron for example in France
and the jilon he's like oh let's raise
the price of gas because save the planet
right and then a bunch of people in rur
are like are you kidding me I need this
car to live and I don't have money to
pay that gas I don't care about your
green blah blah right and this almost
brought him down right so why wasn't
that intelligence in the system to begin
with it should have been so I think
first of all I trust people's
intelligence more than a lot of my you
know fellow experts number one and
number two to again AI can make this a
lot better just like people today are
more informed because you're like
reading newspapers is an amazing thing
right now we take it for granted but
like you know newspapers change really
really change like like and then so does
TV and then so does the internet and so
we AI so I think in the future we will
have let let me um Let me give sort like
a very Stark example of this people hate
the idea of important societal decisions
being made by algorithms
it's so
dehumanizing like again the European
Union is full of laws forbidding this
like CU like what could be more inhuman
than an algorithm that makes some
important decision right I think there's
a I think it's quite likely that
there'll be a point in the future which
we will we will we will be suspicious of
any decision that is not made by an
algorithm because it's made by
corruptible politicians and
self-interested politicians Now The
crucial thing is I mean think about it
this way and this I think sort of like
is a very AI way to look at things but
to me very enlightening democracy is an
algorithm the US Constitution is an
algorithm for how to run a
country the European Union Constitution
is just a big pile of garbage it's like
a thousand pages that no I never read
honestly it's an embarrassment but very
then there is also an algorithm for how
to govern Europe right so and the
algorithm is like this is like a bunch
of people vote right and then you you
you add up their votes the majority
representative wins and then the
representatives in turn they also vote
this is like the dumbest algorithm that
you ever saw right like what a joke of
an algorithm right but it's better than
one guy make that's an even worse
algorithm like one dictator making all
decisions that is the worst right again
there's a lot of results both practical
and theoretical that you're like voting
is is quite smart in some ways but we
have ai now we have computers the
algorithm that can makes the decision
can be way better than this in ways that
we don't even imagine right so I think
in the future we are going to want the
important decisions to be made by
algorithms and God help us if the
algorithm isn't making a
decision but a lot of people are afraid
of that moment because how do you know
the algorithm doesn't have an agenda of
something absolutely so that is a
crucial question right you can't be
naive and think oh again this is also a
trap that people fall into people who
don't know computer science like oh
algorithms are somehow magically
objective and perfect and abstract and
like no algorithms do not fall for that
illusion I mean some of them are but at
least the ones that we're now talking
about they're never going to be like
that right algorithms are creations of
humans we can put whatever prejudices
whatever like we I can make an algorithm
saying if this person is black do not
give them a job that's an algorithm
right it's biased right there's nothing
stopping me from from doing that right I
don't I don't know anybody who has but
they could for all I know right so but
also more importantly and again you all
you already see this today is like well
I have a search engine that's Google I
have whatever Facebook or Twitter are
they just choose they're using AI right
this is today now they're using AI to
choose what to show me or what to
recommend or you know like are they just
doing it for my own best interests well
no I mean to a large extent they are
because the you know like it's it's a
nonzero game right it's the Invisible
Hand Google does more business if they
actually serve me at the end of the day
but at the end of the day our interests
are not the same right they you know
like um why does Facebook have likes but
not
dislikes because likes Drive engagement
and this likes drive this engagement
right I mean there there's examples
Galore like this so these algorithms if
we have ours making decisions for like a
societ like I just described everybody's
going to be trying to to put their thing
into those algorithms again we see the S
today right this whole fairness in AI
thing is basically progressives trying
to inject Progressive politics which I'm
not saying I agree or disagree with
right like fairness is I going for
example you have ai algorithms now and
this is like you know best paper Awards
and companies like Google and Facebook
that have people who do this like they
say you got to produce you know you know
if if whatever women are 50% of the
population 50% of this has to be like
the recommendations have to be the same
or whatever things that to my mind are
are are crazy but like you see the
rationale right it's like they are
injecting their politics into the
algorithm so how do we avoid that right
one there's a number of ways right but
one way that you avoid is by making the
algorithm maximally
transparent so for example it's better
to have a simpler algorithm in this area
not in others this a whole other you
know of worms if I have an algorithm
making political decisions it should be
an algorithm that anybody can
inspect open source open source and it's
like I don't believe that you made the
right decision let me download a copy of
you and and certify myself that that you
that you w manipulated or maybe find
some like so like there's going to be
whole organizations whose job is to be
on top of this process to and like and
they going to be in a left wing right
wing like like pulling in the different
directions there's going to be a never-
ending struggle just like today about
what goes into that algorithm and and
you know but that's just the way it
is
wow I love
you the next question is about the
education how do you think uh will
unfold with the
education I think education is going to
be dramatically Changed by
Ai and I think most of my esteemed
colleagues in you know both universities
and and schools and whatnot are not
prepared for that but for the students
it's just going to be a fantastic
Improvement now people have been trying
to improve education with AI since the
beginning and it's actually very hard
because education unlike say
recommending a movie is extremely subtle
for example when you teaching a student
you need to understand their
misconceptions so that you can fix them
which means you need to understand their
reasoning process and so there's this
whole field called int intelligent
tutoring systems where the idea is to
have an AI
tutor and why not right like this whole
mass produced education that we have
where one Professor gives a lecture to
500 people this sucks right I mean it's
better than nothing right but you know I
remember so like when the whole you know
online the whole Mook you know online
course thing came out like a lot of sort
of like my you know colleagues at sort
of like top univers like oh but like how
can this ever be as good as a lecture by
me right and I'm like buddy there's like
10 people in the front row listening to
your lecture the other ones are asleep
are on their phone why would you think
you are oversampling the people that
interact with you and and they think you
know and you think they're everybody
right so already you have you know like
for example I've talked with Andrew in
about this I'm not sure whether Corsair
is doing this or it's something that
they consider doing but like you know
like you take you have these Snippets
right and then you take quizzes and now
you could choose what next segment to
show automatically using machine
learning by the error that you made in
answering the quiz I can say oh this is
what you're struggling with so this is
already making it more interactive than
a lecture is but now imagine that what
you have on the other side is a
full-blown Chet GPT like system so for
example K Academy right you know what K
Academy is yeah it's an academy is this
very you know beautiful nonprofit that
puts out they were the inspiration the
they were were the first Muk uh uh
company um uh in some sense they just
make these online courses about
everything started with math a cellan
was like a Quant and then you know had
to explain some stuff to his niece and
he did it on on you know like you know
with with a with a video and it's like
why don't I post this went viral uh so
so they already do that um and they have
an AI agent you know building on on chat
GPT that does this right and if you
listen to Saul is like amazing probably
more amazing than really is but you can
see where as the improves right you're
going to get to a point where it's not
that the AI tutor I think for the
foreseeable future will completely
replace the teacher it's that it's going
to be more like a triangle right there's
the student there's the teacher there's
the AI and the student you know knows
what to draw on the AI for which is
going to be most of the time because the
AI has the time right that's the beauty
right AI is cheap intelligence like you
can use it all day long unlike a real
teacher right some things then the the
student or the or the AI will say like
no this is for the teacher the teacher
will have a um a whole dashboard of like
and again do you you see you see
examples of this already today of like
okay how is this student doing right
like what's their report card what is
the I saying this student is having
trouble with or ar to help and then the
teacher comes in so like so the teacher
and the I work together to for the
student in fact all three of them work
together and the boundary of what is
done by the teacher and by the ey will
change over time as the ey gets better
and as we discover better ways of doing
this you know there will be a lot of a
lot of experimentation it's hard for
that experimentation to help in in
today's school systems and today
universities because they are so
conservative right the irony of
universities you know and I spent my
life in universities or almost all my
life is that Universe are supposed
discovering new things and research and
the future there are the most
conservative change ofers organizations
in the universe right the universe is
like worse than a church it's worse than
the military it's like you know in the
military at some point some general says
like damn it we're going to do this and
people do it univers like no like you
want me to improve my teaching sorry I'm
busy with my research my my my mom
started out as a high school teacher got
into teacher training then got a PhD in
sociology education blah blah she said
like the number one reality in any
educational reform is that it fails
because the teachers don't care I have
this beautiful idea about how to teach
things right very well proven like this
is going to make teaching so much better
the students will learn more and then
the teacher's like oh no I'm sorry I'm
too busy I'm just going to keep doing
the things they pretend to comply if
they need to but you know they're human
like the rest of us AI aren't going to
have that problem right if I have an
innovation right I push it out to the AI
and is doing it right it doesn't have
rights it doesn't say I have the right
to say no right I want you know I'm
going to call call my union to see if
you're allowed to this know it's an AI
right and so what we're going to see I
think in the educations other things
like and again it's interesting because
you see a lot of these like there's
these PODS of like groups of children
like that happened during the pandemic
right parents got together to recruit
some person to teach their children I
think you're going to have a lot of this
and and it will involve more and more Ai
and then the things that work will
spread just like they do on social
networks today right there's not going
to be a top- down process like wow you
just found a great new way to teach
people about you know the gas and
distribution so now I copy it I give it
to my AIS maybe then it gets adapted and
then may some guy in India adapts in a
way that works better for Indian
students or whatever right so you're
just going to have an education system
that is way more customized to the
student than than today but also where
the if let's say there's some Innovation
that like you just came up with right
now right you you know you know today's
ASA can right and it really works right
you know and before you know everybody's
doing it all over the world in a way
that just can't happen today because
it'll be the AI is doing it for the most
part
so so you mentioned so so many times the
AI but I don't think you reference the
AGI in our
conversation can you touch
why uh yes you're C I haven't and it is
for a reason is that AGI is a very so
what is Agi right a is artificial
general intelligence and now why does
that term even exist right AI is Agi so
why put in the G right the founding
fathers of AI their goal was to replace
human intelligent in fact they were very
optimistic right back in the 50s there
were saying within 10 years humans will
computers will be better than humans at
everything I kid you not right so so
we're 50 years behind but but okay maybe
that's not such a big deal in in the in
the long you know in the grand scheme of
things right but then what happened was
that AI turned out to be a vastly bigger
harder problem than people thought and
it got
specialized into a huge number of
different things like you know I got my
PhD in classification which is a
subfield of machine learning supervised
learning where you have examples with
labels about what is the right answer
and in natural language there's syntax
and there there's parsing blah blah
right so people got very specialized and
there in any field the Specialists
weren't talking to each other anymore
and a bunch of of people not AI
researchers uh um or at least mainstream
AI researchers they got frustrated with
this this was like maybe 20 30 years ago
I was like no we need to get back on
building you know human level AIS AI
that can do everything right the AIS for
the most part until recently at least
any one AI would be very good at one
thing it's like I just built you an AI
to diagnose lung
cancer it's very good at finding the
tumors but he can't do anything else so
we have a growing number of subfields
not really talking to each other that
much and a growing number of very narrow
applications that I was good at and the
idea of a is like no we need to get back
to having General AI General being
meaning that does everything a human
does right and now until recently this
my sorry my personal goal from when I
was a student has always been to build
you know AI in the human not not human
level ai superum ai right that's like we
want like my one of my motivations for
doing AI was that like human
intelligence like is clearly so limited
like so like I mean we got to do better
than this and maybe back when there was
200 of us in the tribe that was okay but
like in today's society is our
intelligence is just you know willfully
inadequate so like you know AI right
that was always my goal but you got to
be realistic about that goal and the
thing about a lot of these AGI folks to
you know maybe paint them with two broad
of a brushes that they're a little flaky
right you're like these crazy guys who
like ah you know like I you know Ai and
then the really just go like yeah buddy
like come back when you have something
to show us which for the most part
they've never had right like now the
exciting thing about the last decade is
that these Labs like deep mind and open
AI came along right who are populated by
these people who are the AGI crazies
right and not surprisingly they've been
making the progress that the others
haven't because they've been
trying right you can't succeed unless
you try right now what has changed right
what has changed is that 20 years or I
mean like 15 years ago I gave a talk at
the Symposium on the future of AI where
I said nobody's really doing AI research
yet because we don't have the computing
power to do it we work on like these
very things like you know image
classification that's not Vision vision
is working on real life video but nobody
has the power to do that but 10 years
from now like if you look at how the
computing power is changing we are going
to be give or take at the point where we
have the power to do real I and that's
when the real action will begin well
guess what we're there now real AI has
started now like you know like those 50
years were a preamble the real AI is is
is is starting now and therefore those
guys who wish to be the AI crazies now
they actually you know they have
something to show right and and like and
talking to people about you know AGI is
no longer seem as silly within the field
right now having said that
the the there is still a vast gap
between the claims that people make and
where really is and we need to combat
that these same AI folks because they
being true to themselves they also think
that AI is just around the
corner I mean like ilas the you know the
one of the founders in Chief scientist
of AI he told me some years ago was this
maybe five years ago that like one of
the things they ask their their their
highes that open is like even when
they're interviewing them is like how
far do we think think we are from AGI
from Human level general intelligence
right and and and and he says the
average was I forget exact like three
years and I'm like you got to be kidding
right the average open AI researcher
thinks were three years away from AGI
this explains a lot of things right a
lot of the you know ridiculous things
that you see come from this frm of mind
right now maybe they're right and I'm
wrong right or most of us in the field
are wrong but like chances are they're
just delusional hii is not on the court
so the lot of discussion that we have
today including about regulating Ai and
the dangers and la la is like it to me
it's happening is kind of like virtual
reality people think like you like again
R Von in her state of Europe addressed
this here was like Europe is saving
Europe is saving Humanity from
Extinction with the AI Act and the rest
of the world should follow it's like
what what have you been smoking right
who those L how big of a FL of yourself
are you making right so so I think we
also need to be careful about you know
when you say AGI the term brings a lot
of baggage that I think we need to be a
little clear about like a AI is already
better than humans in some ways in in
most ways not yet some things will
happen at different times right there's
not going to be a point that which you
say oh AGI is here I mean you us have
people saying like oh we chat GPT you
know this year 2024 you know like on May
21st you know 2024 at 5:54 p.m. a I will
be riched it's not it's not going to
work like
that so you think the word that's why in
the beginning you said that European uh
laws are stupid about a AI because uh
there's going to be a bunch of AI small
AIS doing all the war and we're nowhere
near the
AGI well that's one reason I wish there
was only one reason the ACT is stupid
but it's got a real you know a treasure
Trove of reasons why it's
stupid in fact most of the AI act
because you know this is a process that
took several years is not motivated by
these long-term risks of AI it's
motivated by what are considered the
current risks of AI right and in fact
it's because like the current risks of
AI are things like
discrimination disinformation the jobs
apocalypse right these these risks don't
require AGI to be real I think they have
also in their own right been massively
exaggerated right that's a whole
different conversation it's interesting
for me to see how like the you could
think of them as s like the short-term
AI risk or the AI risks now and the AI
risks tomorrow folks they're two
different sets of people thei tomorrow
folks tend to be like these you know
effective altruism you know think tank
you know AI idealist types the the AI
now tend to be sort of of like these
Progressive activists AI is aess of bias
you know uh type and they're very
different kinds of people almost opposed
and and they are very much at odds with
each other so like the people who care
about AI now risks are are really pissed
about how the extinction risk is sucking
up all the oxygen they're like stop
talking about that crap you know women
and minorities are being discriminated
by a today we are being submerged in so
why are you talking about Terminator and
go like you don't understand those
problems are small I'm talking about the
extinction of humanity and I just sit
back and eat my popcorn so yeah there's
those two
kinds uh
so so I have one question on this
podcast that we ask every guest and I'm
ready to ask it to you uh I give you1
trillion doar how do you spend it for
Maximum Impact positive impact in the
world uh I would at a high level what I
would do with that trillion dollars is
give it to
everybody but I wouldn't just give it to
everybody saying like you know here's
you know you know the whatever a
trillion dollars divided by 10 billion
people I would I would I so like if you
think about the things that we've just
been talking about right what I would do
is try to set up a structure that has
this money and where you think of it as
a company or a nonprofit that owns those
trillion dollars and everybody has a
share in it but the decision process of
this organization is of the type that we
just described right you have to decide
for example what choices to make what to
invest in how to spend that
money and the people and and now you
could spend it well or not right so you
if you if you don't spend your money
well it's gone but if you and I get
together and do something with that
money that then becomes you know 10
times the money then you keep it so so
you know I guess maybe a very short
slightly oversimplified answer to this
you know how like you know there's
socialism where everybody owns
everything and there's capitalism where
the capitalist own everything but what
actually you have for example in America
today something much more interesting
it's a kind of like socialist capitalism
or capitalist socialism where
like 60% of the stock or like I forget
what the percentage is but like the
great majority so sorry 60% of Americans
own stocks and the great majority of
stocks are not owned by the rich people
that were all heing about their money is
like is is like nothing right they're
owned by the the Pension funds by like
individually you know retirement
accounts like it's like we the people
actually own the means of production in
a way that KL marks never
imagined and this is great because we
all have a stake it's not like oh those
companies are evil capitalists no they
they're doing it on my behalf right I
can complain about whatever Apple does
but I'm an investor in apple vimi Index
Fund right this is very so you want
again to bring the maximum intelligence
to Bear you give everybody a steak so
what I would do is give that trillion
dollars to everybody so they all have a
stake right so like this trillion
dollars is for the benefit of humanity
right it's not going to be for me so
like one way to do this would be like I
am the next Bill Gates or the next Elon
Musk you know I'm going to spend you
know I'm going to have you know the pay
to domingus foundation with a trillion
dollars to spend that's not bad right
and in fact Bill Gates was very smart
about his philanthropy is actually a
great example at Big ban very result
driven very Again part of what I was
describing is like I'm not just going to
give some money away I'm going to try to
give it where it has the most impact ah
Global health is a good one but I'm just
going to give money I'm going to
evaluate the results right he gave money
for a whole Institute at udub my
university called The Institute for
health metrics and evaluation to see how
much interventions are having and then
you put money on the ones that so that's
all good but even better than that is to
have the intelligence of the all 10
billion people deciding how to spend
that trillion dollars right I'm not
going to presume that I know what that
is I'm just going to try to set up the
algorithm in fact in computer science we
call this mechanism design right a
Google auction is a mechanism with a
certain mechanism design a constitution
is is a mechanism designed right and and
the question like how can we best design
the mechanism for this organization so
that that trillion dollars will bring
the most benefit to everybody and I
think this for sure at a minimum will
have to involve everybody it's like you
have a share in this you know if you
want to not care and let others make the
decisions for you and vote by proxy
that's fine but you're going to be
losing out the ones who care the ones
who show up will be the ones making the
decisions wow very unique answer I it's
the first time someone uh says this I'm
curious to hear your thoughts on at some
point
probably as humans you will be
useless and we are going to have plenty
of time to read
poetry how do you think uh we solve this
problem is it UBS is it like how do how
do you think about this no so um let us
look at the following scenario I think
is what you're suggesting let us suppose
that we reach a point where Ai and
robots can do every job better than
humans right I think there's a very good
chance that that point will come not
soon but it will come right what will
that Society look like right and and
what and again this is not a passive
question is what do we want it to look
like so that we start making it happen
should there be Ubi uh so so uh uh you
know what jobs will people do right so
so here are some things that I think um
are worth considering I I actually think
having a Ubi is a good idea a lot of
people are very opposed to that because
like Ubi makes people lazy and blah blah
blah the experiments so far tend to not
show that you give people an income they
put it to good use right they been exper
like you give people a thousand bucks
and they invest it right it's amazing
they just just right so uh also one very
good book I read about that humankind
it's an amazing book about this anyway
continue sorry for interrupting who's it
by
humankind
Roar is and Dutch philosopher I think
I'm not or Netherland I'll look it up
yes I we going to put the link all all
your books in the description are you
coming with a new one as well a book
soon uh I have I've written another book
that my agent is currently shopping to
publish so yes that it should come out
one of these days okay how of how soon
we don't know the date the publishing
industry moves glacially slowly compared
to computer Industries so maybe in a
year yeah I think a year is between a
book let me put this way between the
time when I finish writing a book and
when it's in the bookstores if it's been
a year that's that's that's that's good
it could be several years six months
would be amazing but that not and it's
about AI if I have to guess it's a it's
a
novel it's a satire of of AI and and the
tech World wow okay it's about it's
called 2040 and it's the story of the
2040 presidential election where one of
the candidates is an AI it's basically
you know chat you know chat GPT runs for
president I could describe it that way
when I started writing it but as you can
imagine the comic potential in this is
just infinite so hopefully my goal was
that it I mean I had fun writing it the
goal is for it to be fun but also
everything in the novel every element is
actually there to try to you know uh in
form people or or for example uh I I
want them to see AF for what it really
is and the issues so so the book also
has a very serious intent so that's um
you know that's uh we we'll see how it
goes but yeah that's that's my um that's
that's my latest book sorry you have
asked me another question I forgot yeah
about the Ubi and you were elaborating
about the future I think we should have
let me put it this way the question that
we should ask about you
so there are many ways to do Ubi here's
one way that I think would
be that I that I think is the best one
is it was not only about Ubi it was
generally about when we are not going to
have nothing to do when we're going to
have nothing to yeah so so okay so let
me let me do this first so Ubi so one so
one question is if the robots and the
are doing everything how do people get
by right how does that income get
distributed right and actually and I
think it's going to be a few different
ways Ubi is probably going to be one of
them the other one is that whoever
controls the means of production is
going to make more money right the
people who created the companies that
created this say yeah I will make a lot
of money and they deserve to so I think
we're probably going to have a society
where there is some Ubi and nobody
starves etc etc but there will also be
people who don't just have a hundred
billion dollars they have trillions of
dollars youri might be a trillionaire
and highly deserved because you did
something that really useful worth a
trillion dollars not just 100 billion
right and I have nothing against that in
fact I want you to encourage to do that
right so so on the one hand they'll be
remember like AI is going to increase
World GPT not just by a few sorry G GPT
GDP interesting slip of the tongue byy
not just a few perent buy a lot right so
we will have more wealth to distribute
it some of it will go to everybody but
some of it will also see richer people
than ever before and that's okay right
and the other thing is
that um
humans have both sort of like this
equality tendency where I want my fair
share but also they have like this is in
US it can't be changed right every we
all we all know about the totem pole we
like to have totem poles and to be
higher on the totem pole than our
neighbors I want to be higher on the
totem pole than you are even if we're
friends you know we're buddies but like
I'm better than you are I don't tell you
that and you think the other way around
right just like bzak said the ideal
friendship is where each one thinks he's
superior to the other slightly right so
people are going to so so here's nothing
that could happen and again you also see
some of this today like look at games
right I can't imagine a very large chunk
of wealth going to the you know people
by how much they win in some game that
they play right completely made up thing
you know it's like some whatever you
know next Generation uh um you know pick
your favorite you know multiplayer
computer game and as you ascend you make
more and more money so there'll be a
very large bipe you know popular consent
there'll be you know there will be
people are billionaires just because
they they're very good at playing this
game and people will will will come up
with ways of doing this which to us
would seem completely meaningless but
again a lot of the ways in which people
get very rich today would be completely
meaningless and stupid to the people of
200 years ago let alone 2000 right you
seriously you get what for sending a
ball through a hoop you must be kidding
me right so there will be that as well
so there will be all these different
ways in which you know the income is is
distributed right and and I don't so
another but another thing that people I
also think there will
be just as happens with manufacturing
today right because things are
mass-produced things that are
handcrafted have a special
cache right so I think even like a l
this thing was handmade and often it's
way worse than the piece of plastic that
costs you know $2 but plastic is plastic
right plastic is very underappreciated
so I think we're going to have for
example restaurants where it's like we
are a really expensive upill upskill
restaurant so upskill that we have human
waiters and bartenders whoa those are
the best so I think there will always be
jobs for people even when the machines
do the job better right for various
reasons like Prestige and taste and like
how human minds work so there will
always be some jobs for people there
will always be a job for people which is
mining the
AIS being on top of them making sure
that they do the right thing in fact I
think think even in this beautiful
future that is going to be everybody's
job is to keep making sure that the a
eyes are doing what they're supposed to
do right so everyone will have a job
just doing that
right now another question that kind of
saying like oh but people's lives will
be so meaningless because it's work that
gives you meaning and whatnot right and
and you know that resonates with me
because my work gives me a lot of
meaning but if look at people look at
the people who are you know
independently wealthy or retirees
they're not miserable for the most part
they don't feel that their life is
meaningless they found out ways to give
meaning to their life it's not written
in the stars that it's that it's you
know work that will give us meaning like
for example I like to disc discover
things and maybe there will come a day
when they when they as are way better at
discovering things than than me or
anybody like in whatever in any area but
then I think what I will do is like I
will discover things for myself right I
will be discovering what the real laws
of physics are with the help of AI who
explaining to me or whatever right for
my own Enlightenment right the these
days I get to earn a living doing
computer science research but you know
but if I really like to do it I can
still like I mean like look at chess
right people still play chess they don't
say like oh you know the best chess
players are computer so it's just not
worth it right it doesn't work that way
so I think people will find all sorts of
meaning in all sorts of new things and
old ones right there will be a
Temptation for people to sit back and
watch TV or play video games all day
long and some people will fall into it
and we need to you know combat that as
parent as Educators and whatnot but the
notion that you know in a world where
everything is done by AI humans will be
you know miserable and and have
meaningless lives I just I don't see how
that's going to happen we're better than
that why do you do these
podcasts I well great question so um uh
which we can answer sort of like very
concretely you know building on what we
talked about before I get a lot of
requests for interviews you know radio
TV newspapers podcasts you know to write
pieces like you know the full range
right uh you know basically started when
the book came out there was a lot of
interest uh and of course I get way more
than I way way way more than than I than
I you know that I can do and so I I try
to do the ones that have the most
impact which can be often very hard to
guess right I mean
um and H so one example is like you know
if I don't know the BBC wants to do an
interview with me I probably will say
yes right but if a podcast that has a
large audience wants to do an interview
maybe I'll do it as well right because
you know like I I don't care whether
it's old Media or New Media I care about
who's it going to reach and I ALS and
and again I often will do things for
very small audiences because they are
very influential audiences or or for
example audiences in a field subfield of
AI that I think could you know I could
help go in the right direction like for
example you know a few months ago I was
in Portugal where where I you know I
took place in an event that that had
like I think 50 participants and they
had a session on AI but those
participants were like ministers Supreme
Court Justices CEOs of Corporations blah
blah blah I was like you know it's only
50 people but they matter right so I
actually flew to Portugal on purpose to
do this so I use basically the same rule
as for everything else which is and and
then also this also has to compete with
like doing research or writing books
right two hours that I spent doing a
podcast accomplish something right there
but when you add this all up if that's
all I do then I don't do research and
maybe at the end of the day my research
is where the biggest impact is because
you need to move AI forward so I try to
manage that in a way that of course is
very heris and very fallible but that's
what I try to
do uh the way that we end this podcast
is by beautiful exercise which you are
going to die after this podcast and uh
let's say hypothetically after 40 50
years you die actually we're going to uh
look back to this and will be your last
word and a message to the word so you
have 30 40 seconds one minute to say
your last
words learn as much as you can
learning is is one of the greatest joys
in
life and it also makes you a better
person so not only is it good in the
moment it's how we make everything
better you
know Einstein said if he had one hour
left to live and this is always on my
mind he would spend 55 minutes figuring
out what problem to solve and the last
five solving it and this is exactly
right you will have the biggest impact
if you learn the most so the first and
most important thing is to do is to
learn not just when you're in school but
your whole life one of the things that I
try to do is learn every day learn when
you make a mistake there's a lesson to
be learned there if you learned that
lesson it was for the better that you
made that mistake because now will will
you not you will not only not make that
in the future but you've probably
learned a more General lesson that will
avoid making other mistakes as well
right so when you have a choice between
doing a and b and they're both fun and
maybe B is even a little more fun but
with a you learn more do
a thank you for your time you are
amazing thanks for having me
