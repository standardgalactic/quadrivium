yeah
[Applause]
I've taken to sitting at lectures
because I I like being on the same level
as the audience to some degree so
um hey
um
so yeah over at Microsoft we've had
we're having quite the AI year as you
might have noticed
and um we uh
we've uh
work very closely with an organization
called open AI in the city anybody here
from opening hour today anybody come
over the bridge no anyway
um
we put out this as you know
something called chat TPT I guess it's
not getting close to a year ago and it
just really took off and
um it was a fascinating moment
it was not the most powerful
um
AI Chat thing that we had released but
it was released with a UI that people
responded to so it's more of a user
experience difference
and all of a sudden I'd be at parties
and people would say oh we had chat GPT
right our wedding vows I'm like really
that's what you're doing seriously or
things like that and it kind of blew my
mind all right so
I have been around this AI thing for
quite a while I don't like the term AI I
don't like to use it but I know it's the
standard usage so I shouldn't be so much
of a jerk as to not use the same
language as everybody else but it still
bugs me
I came by my dislike of the term
honestly a long time ago and so I'm
going to tell you about my most
important Mentor when I was just a kid
in computer science because that's where
it starts for me and his name is Marvin
Minsky
uh who has heard of Marvin Minsky who's
a younger person who's like a student
okay all right get with it learn history
it's important
um Marvin is one of the foundational
computer scientists and if you've ever
had to study this hierarchy of comp of
models of computation like you know
the financial State automata and the
turing machine and this notion of the
generality of the turing machine Marvin
was probably the main contributor to
that hierarchy he developed many many
fundamental concepts and back in the 50s
he and a cohort of others a few of whom
are still around
um who had a conference at Dartmouth
it's 57 or 58 or something where they
came up with the term artificial
intelligence
uh
according to what I've heard from people
who were there but I was I was not born
yet uh so I did not know this for sure
the whole idea of artificial
intelligence and their way of talking
about it was in part
um a political response to an opposing
group that was read by led by a guy
named Norbert weiner anybody remember
Norbert weiner
so yeah but you're old enough to have
done students students all right Norbert
weiner wrote a very famous series of
books one of which was called
cybernetics
um in the post-war period and especially
in the 50s he was a wonderful
mathematician and philosopher
and his idea was that instead of
thinking of computers as being like a
turing machine where you have a device
that reads a tape
you should think of them as a network of
thermometers it's a set of feedback
devices that become ever more
complicated and instead of just running
and then either halting or not remember
the halting problem from your classes
right
they would just be in continuous
interaction with the world and might be
almost understood as creatures however
he felt that if we thought of them as
creatures instead of tools there would
be political negative ramifications
which is quite interesting he wrote a
book called the human use of human
beings and what he thought was that if
you personify the machines of this kind
too much you might end up with some
people exploiting other people and at
the end of the human use of human of
human beings is a thought experiment and
the thought experiment proposes what if
someday there could be a small device
that was connected by radio signals to a
big
cybernetic device which these days we
might call a large model or a neural
neural network or something
and what if
what if what if that device had
information about you and was following
you and entered into a feedback loop
that might manipulate you for the
benefit of whoever owns the central
device
that would be the end of civilization it
would just make us insane fortunately as
a renowned scientist I can tell you this
is impossible it's only a thought
experiment
that's what it says
okay obviously we built that thing okay
so now
um what I have heard from people and I
just don't know if this is true I I
never met I um I never met him I like
his ideas his writing is not designed to
be accessible he's obviously got a bit
of a snobbish thing going on you need
there's equations in it it's not that
it's not like popular writing
apparently he was kind of a jerk and
turned people off and made enemies so it
is said I'm not sure at any rate this
other group of people including Marvin
and some other folks promoted this other
notion of artificial intelligence
directly in opposition to weiner
whatever he liked they didn't like
Marvin and a colleague of his absolutely
destroyed research on on neural Nets and
similar things for decades
uh with the proof that they couldn't be
absolutely absolutely perfect which is
like he needs Perfection but at any rate
that turned this whole field off for
decades and decades and they were just
really not into it
um
Marvin had a gigantic influence on the
culture he used to hang out with the
golden age science fiction writers so he
influenced Isaac Asimov to create the
laws of robotics in some of his novels
and also Arthur C Clarke to create the
Hal computer in 2001.
and in both cases the idea is that the
computer comes alive it's like a
creature instead of a tool exactly the
opposite of what weiner would have
wanted but you keep the creature from
getting out of control by giving it
rules to live by
and the rules are like you know don't
kill people
all right and then in science fiction
stories it always turns out that those
rules aren't reliable
because otherwise there wouldn't be a
story
um except for Commander Data they work
for Commander data but that's the only
example everywhere else The Matrix
movies Terminator they always fail okay
so the way they fail is very ancient
there are Ancient Ancient stories
about the impossibility of coming up
with perfect laws to protect people and
they're usually in the form of Genies in
lamps you get you find the slamp you rub
it as Genie comes out
and the genie says I will grant you
wishes and then you try to be very
clever and come up with wishes that the
genie will twist into horrible things
for you it never works
sorry if it worked
all right
fast forward
it turns out Marvin and the other from
wrong about neural networks they
actually function
they function at Great scale
so we've entered into this curious time
where the difference between usable
performance and sort of okay cute
performance involves tremendously
expensive preparation of models
that not a lot of entities can afford to
do
so when you look at the difference if I
may say our stuff or a few other places
in the world we're able to get to a
level that maybe some others don't in
terms of reliability and consistency and
usability
I'd love to say that we have brilliant
insights in our code
of course we do however
you don't get to see it so what's the
use of that uh what we definitely have
is larger scale preparation we
definitely have bigger training
and we definitely have more extensive
training passes and it's like it's just
this fantastic scale so scale turns into
quality will it remain so no one knows
no one knows where the top of the S
curve is obviously you can't keep on
getting more quality from scale
indefinitely so we don't know
so what that's done is it's created the
scenario
that Norbert weiner warned against where
a small number of entities control the
most functional
Central devices as he imagined them
which in our case are these city-sized
servers
that respond to your queries so that you
can get your wedding vows written
now uh back when I was a teenager I
wasn't ever Marvin Minsky student but I
got hired as a researcher working for
him
and I'd been in college young and he
hired me very generously
and I worked for him and a guy named
Alan K at MIT
Alan was very much on the other side of
the fence or he is Alan's with us and
Alan was very much on the the same side
of the fence that I would occupy with
Norbert Weiner and many others including
venovar Bush and Ted Nelson and Ada
Lovelace and other figures you should
know about
um
and I used to argue with Marvin all the
time
marvinella said I was the only Protege
of his who just gave him hell constantly
and he liked it to his credit when he
was dying and I saw him for the last
time in at his house in Brookline
message she sits I was on the way and a
mutual friend called me and said you
know Marvin's very frail don't have the
argument with them like like just don't
like just let it go let it go ai's fine
and I showed up at his house and he
looks at me with this guy says are you
ready to argue
it was great so we had the argument and
the way the argument went is I said you
know this whole thing is subject to a
figure ground inversion meaning you can
look at it in a different way you can
flip the the sign on it and still have a
completely functional and equivalent way
of thinking about it from a technical
point of view but this inversion might
actually be better from a societal and a
practical engineering point of view
and so the way you flip the bid on this
uh I used to call it the life of the
parody which is a bad pun
which
two two people laughed at I feel very
old somehow I like come on people that
was funny anyway
um
the life of the parody anyway the parody
bit goes like this if he set the bit one
way
you think of the AI as like this
creature and you you refer to it as this
thing that is an entity that does things
that is like another person or maybe
some a pseudo person who's in the room
and you talk to it and you ask it to do
things
and that is the most common way of
thinking about it in fact it's uh
overwhelmingly the most common way to
think about it
in I mean we have a chat interface as if
you're chatting with a person why would
you have that if you didn't think of it
that way
there's another way to think about it
which is that it's a form of social
collaboration
so it's closer to something like the
Wikipedia maybe where you have a whole
bunch of people who provided example
data training data and then what this
thing has the ability to do is mash it
up in new ways
but it still is a collaboration of
people
and if you analyze it on those terms you
have a more actionable way of
understanding it
and if you integrate it into society in
those terms you have a brighter and more
actionable set of paths open for the
future of society
from a purely technical point of view
they it doesn't matter it's just how you
think about this thing it doesn't change
the thing necessarily but in these other
ways it does matter
so let me go over a couple of the ways
that I think it matters
now let me start with the question of
explanation
so one of the frequent topics in the
study of large model generative AI is
why the hell did it do that thing it
just did
okay so for instance a very famous
example is a New York Times Reporter who
lives in town here uh talked to our chat
GPT not too long after it became famous
and it started it was like my nephew you
should leave your wife because I love
you and it's like really weird and so
the question is why did our chatbot do
that okay now
the the contingent answer is that if you
go too many cycles on a chat bot they
can go off the rails because they start
to rely too much on the memory of the
interaction cycle which is actually not
that reliable a way to guide them and so
one of the things we've done is we've
limited the number of cycles that you
can you can interact with the bot that
actually helps a lot great we've also
tried to do a lot of improvement on
watching if it goes wrong which is the
genie approach like
the Cha-Cha the chatbot should not
declare love for the little user you
know like that's really not great all
right so and those things sort of work
but you run into the genie problem where
the restrictions aren't totally reliable
okay so what's another way to do it well
if you use this other inversion this
parity bit flip as I mentioned which
which we call data dignity is our term
for it
um if we do that then you ask a
different question you say hey which
were the important source examples that
fed into this particular output from the
model
very concrete thing if you say don't
profess love that's hard to judge that's
actually not that concrete if you say
what were the sources that is now
you might think to yourself wait a
second these large models are called
large for a good reason aren't there
millions of anti-billions of antecedent
examples that fit into it isn't that why
it can even talk it has grammar and all
that and the answer is sure however in a
particular output there's going to be a
power law or a Pareto Principle in which
there'll be a peak of certain special
inputs that'll matter to that particular
output
and then the question is how many
examples how many input documents matter
to that particular output above a
threshold that you set all right now if
you think the question that way you end
up with a much smaller number
and you have to do it with a little more
sophistication because on the one hand
you want to have the examples that are
the most influential which involves
estimating counterfactuals how different
would the output be without this thing
but then you also worry about how
replaceable it is like is this thing
really the equivalent of a million other
things and this was just chosen at
random and it didn't bring anything
special
so you know actually defining this is a
bit more subtle than it might appear but
it remains concrete it doesn't become
some weird subjective approximate thing
described by natural language only
and now you can say in that example as
it happens
what did that well it was a bunch of fan
fiction and soap opera transcripts
all right so
what you could do is if the bot gives
you something weird you could say hey
but why so weird and it would say oh
this is fan fiction and soap operas
don't you like it say no no leave that
stuff out this is supposed to be a fake
essay for my seminar and uh and and the
Bible says okay got rid of that how's
this and then so you can start to prune
it by inputs
and if you prune by inputs you have I'm
not suggesting that it's the universal
solution or the only solution but it's
the most concretely defined solution
so I like it we don't do that currently
because to do it efficiently if you if
you have all the if you have all the
money in the world when you know or
Microsoft if we can we can conduct
expensive research to to run something
routinely you need efficiency and to do
this efficiently you have to do some
different work in the training phase and
this is I'm advocating that we shift to
that
if I was the dictator of all computer
science we would have already instead
I'm here advocating and I'm attempting
I'm attempting to move to a world in
which we do that
so
um let us suppose that I have made at
least a passable argument that tracking
and here's another keyword the
provenance
of sources relevant to a given large
model output if that's an effective way
of improving the explanation for model
outputs and for improving the quality of
model outputs
and for addressing security issues with
model outputs and a whole bunch of like
a lot of the issues we have that we're
concerned about can we at least improve
this way I'm not suggesting it's
exclusive but I think it's important
I mentioned there's another reason to
care about this approach which is the
larger societal frame
and here I want to suggest a few ways
that I think this could matter
I'm going to start with a concrete one
it in a way it's the most controversial
and the hardest to argue for because
it requires empirical study that is
barely done it all so I might be wrong I
don't know but give this a try uh I
think it's at least worth it worth
experimenting with
right now
there's great uncertainty and anxiety
about human role displacement because of
large models
now there's a lot of controversy a lot
of different opinions about this there
are those who believe that most paid
work is just going to go away and will
all survive off of universal basic
income
and my good buddy Sam Altman who runs
open AI is starting to do a crypto thing
with like these weird balls that measure
your eyeball so that you'll be able to
sign up for your Universal basic income
payments
I don't like that scenario I like Sam
I'm not into that scenario
there's several reasons I don't like it
one reason is that
although we don't have this precise
experiment under our belt as Humanity we
have some that overlap with it and what
I believe we see from a lot of Social
and economic experiments is that if he
channel the support for everybody in a
society through a single organization
that organization will be seized by the
worst people
and societies do better when there's a
bit more of a mashup a mix-up of a lot
of different institutions and different
organizing principles so that there
isn't any single Central thing to seize
so the way I have put it with students
is you start with Bolsheviks and you end
up with stalinists right and uh now
that's not to say
that's not arguing against any universal
basic income if it's but it's it's
arguing against making it the principal
organizing principle for society
um
and so that political problem for me is
is a serious one and I can't find
counter examples
I can find lots of examples of modest
universal applications of a strong
social safety net the the Scandinavian
model but not as big as would be
required if this Vision were to be
fulfilled those all seem to go bad
and I'm saying this in Berkeley so
go easy on me
um okay so uh but there's another issue
which I would Define as a spiritual
issue which is
I think it's hard to separate human
identity from human activity like we're
not just nouns we're verbs we do things
and if what we do is not valued it's not
economically important in the event we
live in a market Society to any degree
at all
um
there's a problem
and I
uh
I think this is really serious I mean
what I observe in the world might be
different from what others do but what I
observe is that in recent decades as
Tech has become more and more of the
guiding principle of our civilization
and the thing that gets the most
attention and the most discussion
we tend to have a lot of the sort of
hard AI Viewpoint discussed that
machines are people too and people will
become somewhat subordinate and either
will live lives of ease or will be eaten
and destroyed by our machines one or the
other but probably lives of heat so it's
like a very common thing that you hear
how does that sound to people who are
removed from the center of power I mean
when we're here in the Bay Area
we all know we're either doing this
stuff or we immediately know the people
who are it's not some mysterious remote
thing to us so we don't feel like it's
some alien force from Over the Horizon
but everywhere else in the world that's
how it feels
and what I note
is that everywhere in the world there's
been a rise of a certain kind of feeling
which is hardly new has been with us
from the dawn of civilization but not so
much as just recently in recent
Generations which is this kind of like I
am defined by my human identity and my
human identity is the important thing
and everything else is garbage and you
find that in in I think it's to an
extreme and so I think uh and like so
I'm going to just play Both Sides here
because I really think it's a universal
phenomenon in the American right you see
this rhetoric of we need to go back to
Pure biology we can't allow abortions
anymore because we must be you know
we're not just abstract beings we're
sacred and whatever and uh and of course
we are sacred but does it have to be
expressed that way
um as per some one person's power over
another well for some yes we have to
send we have to double down on our
ethnic identity even if it's sort of
made up whatever we have to do that same
thing sure on the left we've had a kind
of obsession with identity
um that in
maybe gets a little overboard once in a
while I I have to say
um once again be nice to me I know it's
correctly
um and but the thing is it's all over
the place in other parts of the world
you see it's not just they've been
religious extremists but there's a kind
of I would say Retreat into
um
almost
uh magical identity bio religious
identity like all over the world it's
it's really crazy so I don't know how
far to develop this thesis exactly
because all of these things are very
approximate and dissipate if you try to
make it make them too perfect as
Expressions but I do think there's
something going on I think we're
creating we being the tech Universe I
think we're creating a future that
repels most people
makes them feel
unloved and unneeded and left behind
um
and we say it all the time I mean if you
look if you look in a rhetoric as it
must read to the outside it's appalling
you know it and anyway the thing is if
we reformulate AI it doesn't like I say
it's technically equivalent if we call
it a social collaboration instead of
this new creature on the scene
that problem goes away
we just got rid of that problem if we
say you know what
this thing is not some new entity that's
writing your it's not some alien
intelligence that's writing your college
essay for you what you just did is you
mashed up these specific 20 people here
they are they're not just hypothetical
they're real real people
that's kind of cool so it completely
human centers the whole Enterprise
but there's more
[Laughter]
um one of the things I'm interested in
is applications so by the way I love
this stuff I love if I think of it as a
social mashup technology but I think
it's great I can give you a bunch of
examples where I'm really using it all
the time one is I uh the groups I work
with do a lot of math and one of the
problems we have in math is that there
there are a very small number of Greek
letters
and there's very small number of favored
terms like you know meta and cover and
whatever and you might think that these
things are all formally defined but we
have so many Concepts that we need to
apply things to that we end up using
them over and over again and what that
means is you can't search literature
anymore
and so we have this problem in math that
it's kind of an oral tradition still we
have to call people say have you ever
heard anybody doing this to say well
they might have called it this other
thing using the large models I can skip
over the keywords and find things I
wouldn't have found before and it's been
transformative because it reveals a
story of math that was actually hidden
from us before I really like that's a
big deal it sounds a little
maybe less romantic than some of the
others like wedding vows or whatever but
I think it's really great and and that's
the magic we can do when we if you have
one pile of examples of pictures of cats
and another pile of examples of people
in hot air balloons and you ask for a
cat in a hot air balloon
it has to
meet both constraints both classifiers
requirements at the same time and in
order to do that there's an intrinsic
sort of
bounded problem solving within those two
piles of examples
it's important to understand it doesn't
go beyond that it's not arbitrarily
creative but it is kind of creative in
joining those two piles of examples
that's what we can do and that's great
that's a fantastic capability so I I
actually am very Pro doing it if I
didn't I wouldn't be spending all day
trying to get this stuff to happen for
this this big company but um the um
what we can do
if we reveal the people whose examples
were important
is we can motivate filling in types of
training data that are sparse so an
example there's lots and lots and lots
and lots and lots of examples of
websites on GitHub
if you go to copilot and you say
I'd like a website no problem it'll make
you a website
and if you say oh could you change this
part to python no problem it'll do that
and part of the reason that all works so
weirdly well is that the amount of
example data is really vast because
there's just a big Community that's been
doing it for a long time
if you say hey I'd like a virtual world
with avatars that look like cephalopods
and whatever it starts because there's
really not that much antecedent Dana for
to John we didn't have data to train it
it just isn't there it's like a little
itsy bit not a lot
so how do you what do you do about that
well it's a very interesting research
topic and there are some things you can
do for the moment we do it with
multimodal approaches where for instance
we might render into a domain where we
do have training data like in 2D and
then use that iteratively to improve
rendering into one where we don't and 3D
Etc there's lots of interesting
techniques that's a lot of the current
research but
wouldn't it be cool to say there's a
commercial opportunity add great data of
this kind to the big model you can make
some money you can earn some Glory some
recognition people will know you did it
like why not what is wrong with that why
not motivate people to add great data to
a tool that'll then help other people
that would be good right now we don't
have any way to do that because
everything is supposed to be lost in the
great sea and you're supposed to subsume
your identity to the great creature in
the sky but why there's no reason it
doesn't actually accomplish anything
it's just I think a lot of what it is is
when people grow up on certain science
fiction
it becomes their vocabulary it's almost
like when you grow up with religious
stories and so just again and again I
have to create Skynet even the skynet's
really bad I still have to create it or
I have to create those agents in The
Matrix movies or whatever it is I have
to make my commander data it's an Isis
one the only nice one really
um
and uh
I have to do it that's what I that's the
vocabulary I know but why it doesn't
actually make rational sense there's no
reason to think of it that way
um
then there's this other interesting
question which is the future of the
economy so
most people who study
how this might play out economically
we'll say it's not black and white it's
not so much that the whole of the
population will be unemployed and
everything will be AI systems and robots
or what some people do believe that
pretty strongly and there's others who
say oh no no it's just like in the past
new technology creates new jobs this
isn't that different probably there's a
lot of Truth in that too but anyway we
don't know for sure
um it's all speculation until we get a
few more decades into this thing right
and
uh let's say that there's some group of
people who might experience some loss of
well-being or Prestige or something
because of AI systems
What If instead they could become
celebrated contributors to AI systems
and the way I just described and maybe
and here Doug gasp earn money
like why not like the amount of money
that flows through
Central internet hubs now is like
spectacular
um
we're I don't I haven't checked the
stock today but we're worth two point
something trillion dollars I mean come
on trillion
trillion it's this gigantic Hub of the
economy just as Norbert weiner had
predicted it would be
we can create an economy we where more
people participate in that it's not
charity of us to them it's growing the
economy but keeping more value on the
books instead of throwing it off the
books
so if you believe in market economies at
all they don't have to be the only thing
going on but if they have any role at
all
then having more value on the books
grows the economy and is better for
everybody and we can do that with this
data dignity approach it doesn't mean
that it's Universal for every situation
for everyone always but why not create a
new creative class
instead of a new dependent class
whenever that's possible
all right that would be the vision you
want to create creative classes instead
of dependent classes and this issue the
creative classes to me has a sort of a
long-term
I would call it a spiritual Dimension if
we imagine what is the future of a
really Advanced economy with Advanced
software Advanced robots Advanced
Materials a better energy cycle instead
of our sucky one and things just get
like what is human life like how do we
think of ourselves and
the obvious answer to me is more people
should Define their lives as creative
lives
rather than lives driven by a narrow
necessity of one sort or another
isn't that obvious isn't that what we'd
want what is the other alternative like
what what what other ideas better than
that
I've been criticized by saying oh well
you're an artist so you want everybody
to be an artist but really like what is
the better idea
what is the better idea what do we want
from all this technology
um
so I think there's a there's a general
direction in data dignity that offers us
a human-centered feature that just has
more concrete terms for improving the
performance of technology and more
positive human roles in it and just the
whole thing makes more sense
the cost of it is a high cost which is
giving up
the vocabulary of one's childhood the
science fiction movies of the big
entities of the sky that we're supposed
to be building
I don't know you could still believe
that in your heart
you know I'm not I'm not the thought
police
[Laughter]
anyway that's the very briefest summary
of data dignity I know how to make
of course I could I can and sometimes do
go on for hours and hours and hours
about this stuff how's my time is this
okay
that was amazing
um your time you're you're actually uh
you know I I think the threat that I hug
you stopped too so I'm going to use that
again in the future when um okay all
right all right
um so uh we're we're Gathering
um some questions from the audience and
Meredith is busy trying to consolidate
some of those questions uh and uh so so
here's here's a question that you're
probably not surprised that you're
getting
um uh it's it's written in a kind of
Stark form
do you think the development of AI
should stop and why or why not
well see I don't think AI is a real
thing so
um so the the famous petition for
pausing AI for six months was written by
a good buddy of mine who's also a
neighbor
um
physicist Anthony Aguirre and when I
look at it and a lot of people Microsoft
actually signed it
um
I just feel like the problem with it is
that in the very formulation it
emphasizes this idea that AI is like
this entity or like this thing and I
don't think it is I don't think there's
anything there to stop I think the way
we should think of it is to focus on the
people in the social collaboration
and if you think of it that way it just
becomes less intelligible to talk about
stopping it and I think it just makes it
safer and better to think of it that way
so my problem with the the pause
petition is it reinforces a way of
thinking about AI that I think makes it
harder to avoid troubles
hey here's another one as AI becomes
more powerful
how can we guarantee that it may decide
whether or not it may decide to break
the rules that it has been given
there is no AI it's not an intelligible
question there's nothing there if you
insist on thinking that way it will
definitely break the rules because you
can't write the rules you can't trick
the genie so the way you've posed the
question is the problem and guarantees
failure
how's that
that's that's an amazing answer to that
question and as a mathematician I love
that answer no because it's a yes
because it's ill opposed you have to
have defined right you have to have
well-posed questions yeah you and so
look I I don't I'm a little concerned
that I'm going to sound too
post-modern or deconstruction Mr
something and like oh no no what you're
saying doesn't make sense but in this
case really really the Practical idea is
to question your question that is
actually the former practical approach
so what are the impediments to your
approach being realized
yeah
um
a lot of it is um
I had wanted us to try to do it to do
the recent GPT three to four this way
however
the problem with it was that we didn't
even know like if the code copilot would
work at all like like this has all been
so experimental and the experiments have
to happen at such large scales and the
trick the tricky thing is that if you
put too too many research questions into
a very large scale experiment
it's very hard to figure out what your
reason how to interpret your result
right so like if I'd gotten us to do it
and then it worked it would be hard to
know
so like in other words what you want to
do is you want to put as little as
possible into a large scale experiment
so that the results are more easily
interpretable
um and that is the correct answer from a
science point of view however from a
society point of view we did the stuff
right in the middle of everybody's
weddings right and so there's I I don't
know you know like it it's
um I think the reasons for not having
done it so far are reasonable and the
difficulty with doing it now just to be
really blunt is it's hard to argue with
success we're crazy successful with this
thing it's making a lot of money and
then it's hard to go it is a commercial
Enterprise it's hard to go and say well
let's just do it this other totally
different way
um the other thing is that most people
in the world do think in terms of AI
being this creature the way that I don't
like to think of it and it's very hard
it's very hard to come up and say oh
you're all thinking wrong you're all
doing it wrong it's a hard position to
be in I'm trying to do it with good
humor and as much clarity as I can
muster and I have
faith in my fellow human beings that
eventually this point of view will gain
more traction but also have to be
realistic about how difficult it is
I got a couple more questions here if
Chad CPT could be considered a social
collaboration so in other words you were
your inverted way of looking at it how
do we reckon with the fact that most of
the training data is heavily
white and male and Western
foreign
by making the training data explicated
you know like I think I think what
should happen is when you get a result
you should be able to get a
characterization of the key antecedent
examples that influenced your result and
I think the problem with this idea that
this is this Oracle this mysterious
infinitely large Oracle that's with the
trackless interior that no one can
interpret is that
when you complain about bias your only
option is to try to slap another AI on
the output to try to catch the bias
which gets you back into the genie
problem now
um
we've been doing a little bit of that
and I think it works a little bit I'm
not saying that we should stop doing it
I just think
um like oh God I can give you so many
examples of this a long time ago in the
90s I had a group that did the first um
uh robust official feature tracking
right and it was based at USC and one
day we just discovered it didn't work on
black people
it's like oh my God that's this is so
horrible but you realize that it was
just trained on the people who happened
to be in the room
and it was USC
in the 90s there were not black people
in the in the engineering world at USC
in the 90s you know it just wasn't
happening
um and so there it was reflected right
back at us and then so
the approach that worked to fixing it is
exactly what I've been talking about
like the antecedent data has to reflect
humanity and not be some sort of
imagined you know whatever
um that you pretend not to know about so
that I I got introduced to that in the
rudest most you know difficult way but
the thing is we're still doing the same
thing but if we pretend that the
antecedent data is some trackless
impossible to know gigantic mush and we
can't even talk about it and all we can
do is try to moderate it on the output
it's a very we're putting ourselves in a
needlessly difficult position
you know why can't so why aren't why
can't people be motivated to make the
training data work data work better for
society and to me this would be a
sterling example of where it should
so
one more question what role does
citizenship
as a concept
play in AI ethics
um
this this opens up
a sort of a complicated topic so in my
view
earlier programs that are called AI have
done
horrific Global damage to citizenship
everywhere At Once by
detecting uh rather crudely
attention generating
choices in in constructing online
experiences for people for the benefit
of
the reach of social media platforms and
advertisers and whatever and so we've
ended up with the whole world kind of a
little I mean everybody's always humans
have always been a little paranoid and
cranky and whatever we've always been
this way but we're just a little bit
more this way it just accentuates those
parts of us and that directly undermines
citizenship because people turn on each
other
um like I don't know I don't know if the
US will be around in a couple years it's
like I've never felt that way before in
my life uh
um I and it's it's horrible and it's
happening all over the place in in um
this is something I've written a lot
about and uh when I started writing
about it nobody believed me and now it's
normal to worry about this at any rate
um what we're all terrified of now uh in
in the industry and everywhere is that
um
if the current generation of generative
AI is used to make people insane like
for upcoming elections we're really
screwed and the issue oh God
let me just try to say a few more
sentences about this
there's an illusion that has taken over
the minds of the whole generation like
the whole technical world
that is obviously a falsehood and yet we
can't let go of it which is that a naive
form of democratization makes sense and
it obviously doesn't and this is
something we knew way back when I was
when the when the internet didn't exist
yet and I was um I was working with a
guy named Al Gore who had helped um get
you know Al Gore just just to I don't
know if you're laughing because there's
a there's a Trope that he says he
invented the Internet which I don't
think he did but the thing is he
actually did because the internet is a
lot of technical inventions it's a
political one and the invention was very
simple uh we're going to bribe all the
people who are running packet switch
networks so they'll stop being dicks and
will interoperate and we'll use
government money to bribe them that was
the invention and it worked so I
remember saying you know you realize
because of how Network effects work
because of basic math they're going to
be a few gigantic winners of people who
are able to make hubs on this thing
which is very Bare Bones and will need
will need to have these services that
figure out where data came from that
that's Google or who did it that's
Facebook or meta and Etc and we're going
to create these giant giant hubs and we
don't we're making a gift of trillions
and trillions of dollars to parties
unknown and that's going to happen and
the answer was yeah but at least
there'll be American companies okay so
now the one that owns the minds of the
youngest people is a Chinese company
it's tick tock and I uh God this is also
very uncomfortable to talk about because
I don't want to spawn some sort of
paranoia about child but
I have another role kind of in the world
that looks at these things uh with DARPA
and I gotta say they're totally on top
of using this thing if they need to and
there's a lot of horrific scenarios that
could come about and
I'm worried I'm really scared another
thing is that we tech people make
ourselves insane with their own
inventions like in my view Twitter
x-made Elon Musk insane in a way that he
didn't used to be insane
and I think it's it's a very clear and
obvious thing that's happened and
everyone who knows him has seen it
happen and has seen how it happened and
it's it just gets worse and worse and um
and uh so yeah we have a big problem
this is we're gonna go through harrowing
times in the next few years and I kind
of believe if we can make it through the
next few years then we can
and we can make it through a long time
after that at least as far as these
issues go then we still have the climate
and everything but
um I think we're about we're going to go
through a very difficult crunch here
that's myself so I was given one final
question which is uh what
um unique role can a public institution
like UC Berkeley play in all of this
going forward
you could accept some funding to do
provenance research in AI
which hey yes Karen has been trying to
get me and a group of people to accept
some funding to to really be the people
who look at the technical yeah you guys
are slow you should you should you
should try offering money to Stanford
and see what happens they're like oh
that'll be fine and we'll take your
firstborn and plus we want that property
okay fine fine we'll accept it that's
Stanford Berkeley is kind of like well
yeah you know
okay let us thank jiren for this amazing
talk
[Applause]
