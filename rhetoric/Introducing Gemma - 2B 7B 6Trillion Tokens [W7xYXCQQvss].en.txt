okay so it's been just under a year
since the original llama model was
released and the license around that was
quite unusual but in some ways it was
semiopen and then the weights got leaked
and that triggered the floodgates of
open llms to start last year after the
first llama we saw things like alpaca we
saw things like vicuna and then
eventually we saw the Llama 2 Model come
out and the Llama 2 model really changed
everything with being reasonably
opsource model that people could use
people could build on people could do a
lot of open- source projects with it out
there and then along with that later on
we saw models from mistel both the
mistol 7B and the Mixel model that came
out and around this time a lot of people
were asking why hasn't open aai open-
sourced any models or why hasn't Google
open sourced any models so Google has a
long track record of open- sourcing
models back from some of the early
models through to things like Bert
through to things like the T5 model
which was a series of models that they
open sourced back in 2019 and even a
while back they open sourced the UL 220
billion model but since then
everything's been quiet up until today
as of today Google's open sourcing a new
suite of models that they're calling
Gemma and in this video I'm going to
talk about the different sizes of Gemma
I'm going to talk about the different
models I'm going to show you how you can
basically start using these and trying
them out and then in future videos we'll
talk about how you can do fine-tuning
with Laura and Gemma and some of the
other cool things that you could do to
build your own open-source projects
based on these new models so let's jump
in and have a look at in the details
about the model okay so if we jump onto
kaggle here we can actually see the
model card for the new Gemma models now
I have to keep practicing pronouncing
Gemma and not Gemini here so there are
currently four models available there's
a 7 billion base model a 7 billion
instruct Model A 2 billion base model
and a 2 billion instruct model so they
describe them here as Gemma is a family
of lightweight state-of-the-art open
models from Google built from the same
research and technology used to create
the Gemini models they are textto text
decoder only large language models
available in English with open weights
pre-trained variants so it is possible
that there may be some other variants
coming along but for now we've basically
got some really nice core models that we
can use especially the 7 billion model
is a really nice size the same sort of
size as the mistal model and we'll be
able to use these for a variety of
different things so they talk about
these aren't multimod models these are
basically text in text out models you
can see here they've got the inputs and
outputs being text strings such as
question prompt output is going to be
generated English language one of the
things that is really interesting about
these is the whole sort of model data
and the big thing being that they are
actually trained on 6 trillion tokens
here so if we think back to the original
llama models were around 1 to 1.4
trillion Tokens The Llama 2os were
around 2 trillion tokens we've seen some
of the Chinese models get up higher to 3
trillion tokens we don't know for sure
what the mistrals were actually trained
on but it does seem like that this is
certainly getting up there for the
highest number of tokens in training for
an open style model that's out there so
they talk a little bit about the
training data set that these are web
documents this is code this is
mathematics in here they've done data
processing to take out a bunch of
different kinds of sensitive data and I
think that's similar to what they've
done with the Gemini models there so so
these models were trained on the TPU v5e
here all right so they've trained with
Jack and ml Pathways framework and here
we can see that they've actually got the
benchmarks for the different models so
for the 2 billion model for the 7
billion model in here and we can see by
looking at these benchmarks that they're
certainly respectable so it's going to
be interesting to see when people start
to fine-tune these models you know what
they can actually get out of them it is
going to be really interesting to try
out the 2 billion parameter models in
here and see you know how well they do
they've also done a bunch of evaluations
in relation to you know toxicity and and
a various things like that so rather
than keep going through this I will put
the link for this in the the description
you can come and check it out yourself
one of the things that people are going
to probably be interested in is the
license and the actual uses so they do
have a terms of use for Gemma I'm not
going to go in depth into this now but
look look at this the prohibited use
policy so far seems reasonably good in a
similar way to perhaps the Llama models
although it does seem like they're
restricting certain uses on chat Bots
and that kind of thing as well all right
let's jump in have a look at the code
and have a look at getting the Gemma
model going all right let's jump in okay
to get access you're going to have to
fill out the Gemma access request here
so you can see I've just put in my name
Etc you have to go through read the
definitions read the restrictions and
then accept this so that you can
actually get access to the model weights
all right so once you've done that not
only we be able to use the weights in
kaggle but you'll also be able to then
download the weights externally to
collab or to something like that going
through this okay so the notebook that
I'm going to have a look at is this get
started with Gemma using Caris NLP so
I'll just go through this very briefly
and then in a future video I think the
hugging face version will be out and
I'll make a more extensive sort of look
at using it in there so to basically do
this with Caris NLP you need to make
sure that you're using Caris 3.0 so this
is set up for this and along with Caris
3.0 you also want to be using Caris NLP
so if we actually come in here we can
have a look at the models and if we
scroll down in this is in the Caris NLP
models we can see that we've got the
base models we've got the instructor
models in here so there's four models
for Caris NLP for pytorch there are
actually the same four models but also
two quantized versions of the the 7
billion models in there as well so if we
come in here we basically uh just set it
up I've set the back end up to ja which
is what they had as the standard and
then just bringing in the base model
here you'll see some interesting things
when you bring it in so one of the
things that I find really interesting is
that the vocab size on the token izer is
actually
256,000 so to give you a sort of
comparison on llama 2 it's
32,000 so that means that this model is
much more likely to be very good at
fine-tuning for multilingual now the
weights are only English at the moment
so it does make me wonder whether
they're actually going to release a a
multilingual version of this later on at
some point anyway you can see I've
brought in the model in here if we ask
it some simple questions we can B
basically just use the this generate
command and and run it through things
like that if I ask it some questions
about what is the Llama you can see and
this is not the remember this is not the
instruction fine tune uh model so I was
actually having some issues with the
instruction fine tune model so like I
said I will make another video doing
that you can also basically run it in
batches so if you want to go through and
run a batch of this you can if you want
to change the sampling strategy you can
also do that in Caris NLP so you can do
uh top K sampling like this or the other
option you can come in here and actually
set the the top K so you'd probably set
this to around 40 or so you can set the
temperature you can do a number of
things like this that have built into
Caris NLP like I said my I'm expecting
the hug face version to be up in the the
next few hours or so so I will make
another video going through that and
then looking at using the model in there
and then also we can see how the
instruct models actually
compare I I would say that my guess is
that Google has overly been careful on
the instruct models so I'm not expecting
the instruct models to be the best sort
of teller of how this model will perform
I actually think we'll see really good
instruction find tune models made by the
community from the original base models
that are probably going to be the really
interesting models so something like a a
Gemma Orca something some of these
models that we've seen out there you
could imagine that people will start
training these up and we'll see them
probably over the next few days or or
week at Max for this anyway as always if
you've got any questions or anything put
them in the comments below if you found
the video useful please click like And
subscribe and I will talk to you in the
next video bye for
now
