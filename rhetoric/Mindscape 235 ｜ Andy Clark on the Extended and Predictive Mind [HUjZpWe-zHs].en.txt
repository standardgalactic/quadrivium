hello everyone welcome to the mindscape
podcast I'm your host Sean Carroll when
you think about how we conceptualize
human beings someone once pointed out
that we're always using metaphors that
depend on our current best Technologies
you know when clocks were just invented
wrist watches and so forth it was A
Clockwork Universe when robots and
machines came on the scene we thought of
organic beings kind of like that and now
we have computers besides which we have
you know cameras and video cameras and
and audio recorders and so forth so we
tend very very roughly you know we tend
to think about a person as kind of like
a robot with some video cameras for eyes
and audio recorders for ears hooked up
to a computer inside and the sensory
apparatus brings information into the
computer which then tells the robot body
what to do it's a simple kind of
straightforward compelling picture it's
also wrong that's not actually a very
good description of what we are how we
behave for one thing intelligent design
is not the way that human beings came
about we evolved over many many years
and we weren't aiming for that you have
to think about what is the kind of
architecture that actually best serves
the purposes of surviving and
procreating and reproductive Fitness and
so forth and it turns out to be very
different so today's guest is Andy Clark
who is a philosopher and a cognitive
scientist in fact his title at the
University of Sussex is Professor of
cognitive philosophy very well known in
philosophy very very highly cited for
thinking about the brain and the mind
and how they're related and how they
work he became very famous with a
co-author paper with David Chalmers
where they proposed the extended mind
hypothesis the idea that what he should
count is your mind is not just your
brain but also all the little extensions
of the brain that help us think whether
it's inside or our bodies or whether it
is things we scribble down on a piece of
paper or use to enhance our memories or
calculational abilities and so forth and
so on
he also has a great interest in the idea
of the brain as a predictive machine and
that is the subject of his new book The
Experience machine how our minds predict
and shape reality so the idea here is
that the brain is not a computer just
bringing in sense data and then thinking
about it our brains are constantly
constructing a set of predictions for
what's going to happen next what is
going to be the situation in which the
body finds itself what is the sensory
data that we're going to bring in and
then you compare what you're actually
experiencing versus what the brain was
predicting and you try to play the game
of minimizing the error between what you
predicted and what you're actually
perceiving this sounds like maybe a
small change of emphasis or an angle and
a similar kind of process rather than
the brain just being a passive receptor
of information it is sort of actively
engaged in the feedback loop but it has
very very significant consequences for
how we think about thinking how we think
about fixing thinking right when we when
we go wrong one way or the other whether
it's you know being in pain or having a
mental disorder of some sort how do we
get better at it taking seriously how
the brain is a prediction machine is
very useful here as well as for
philosophical problems about how you
carve up nature how you think about what
the brain does what is consciousness
what is Free Will and so forth so this
is one of those podcasts that touches on
many issues that we're interested in
here at mindscape from Consciousness to
time all over the place and occasional
reminders you can support mindscape by
pledging at patreon go to patreon.com
Sean M Carroll and pledge a dollar or
two or whatever you like for each
episode in return sense of fulfillment
but of course also ad free versions of
the podcast as well as the ability to
ask questions for the ask me anything
episodes you can also if you're
interested leave reviews of mindscape at
Apple podcast or forever there are
reviews those reviews help draw other
listeners in so if you think winescape's
worth listening to make it an even
bigger Community listening and that
would be awesome for all of us concerned
so with that let's go
[Music]
foreign
y Clark welcome to the mindscape podcast
hey it's great to be here thanks for
having me you know you've done as many
people have of a certain age many
interesting things over your career uh
your new book is the prediction the pre
what is the new book what is the title
it's the experience machine The
Experience machine I keep wanting to say
the prediction machine because obviously
prediction is the experience between
with um how predictions shape and build
reality good good yeah reality will be a
theme that we want to get to but I I
can't give up the opportunity to also
talk about uh extended mind and extended
cognition and things like that so I
thought it would make sense to talk
extended mine first and then get into
prediction does that make sense
logically to you I think that's a good
route um that's certainly that was my
route so why not good good let's do it
uh so apparently there are people out
there who think that well there are
people who think that the mind is not
even related to the brain which which is
which is funny to me but there are other
people like yourself perhaps who think
that the brain is just one little part
of our minds and our thinking so I'm not
gonna put words into your mouth what
does it mean to talk about the extended
mind yeah I mean this is uh this is a
view that I've kind of held and defended
for many years it goes back to a piece
of work that I did with David Chalmers
um is famous for his kind of almost
dualistic views on Consciousness after
all uh many years ago back in 1998
um the basic idea that Chalmers and I
agreed on is that when it comes to
unconscious cognition then there's no
reason to think that the brain is the
limit of the Machinery that can count as
part of an individual's cognitive
processing where that has to include
unconscious processing because it's
unconscious processing that we think
mostly is what gets extended there's a
whole other debate have about conscious
processing
um and the idea there is that um Moment
by moment the brain doesn't really care
where information is stored it cares
about what information can be accessed
how fluidly
um you can get at it whether or not
you've got some idea that it's there to
be got at at all so the idea was that
calls to biological memory and calls to
external stores like a notebook or
currently nowadays maybe a smartphone or
something like that are working in
fundamentally the same kind of way and
actually interestingly it's that that I
think the predictive processing story
ends up cashing out in an interesting
way so we can Circle back around to that
later on that's the core idea is that
you know the Machinery of mind doesn't
all have to be in the head David
Chalmers of course another former
mindscape podcast guest so we're we have
an illustrious alumni base
um but let's let's make a little bit
more more concrete what do we mean you
know I think that what immediately comes
to mind is I can remember almost no
phone numbers now because they're all in
my it's my smartphone does that count as
extended mind
that counts um I think it's after all
you have a fluent ability to access at
least a functional equivalent of that
information
um as of when you need it because you
know you just pick up the phone and
there it goes uh if on the other hand
you had all those numbers stored in a
notebook but the notebook was in your
basement and you know you had to run
down into the basement to get it
whenever you needed it that wouldn't
count because you wouldn't have
the constant robust availability of that
resource woven into the way that you go
about
every kind of problem that daily life
throws at you so there is I think a
genuine intuition which is that whatever
the Machinery of Mind Is it better be
more or less portable it better more or
less kind of be going around the world
where you're going around the world
where bio is going around the world
um and so for that reason I think you
need you need robust and trusted kinds
of access but only to the extent that
biological stuff is robust and trusted
you know now and again my biological
memory goes down now again I don't trust
what it throws at
should be more or less in the same
ballpark well okay so robust and trusted
access is that the Criterion I mean I
guess an immediate question that comes
to mind is where do I draw the boundary
does everything in the world count as my
mind
yeah I mean it's a it's one of the
original worries about this view it's
one that we used to call or I used to
call cognitive bloat worry somehow
there's no good way of stopping this
process but actually if you take that
robust availability and uh Trust of the
product stuff reasonably seriously that
does rule an awful lot of things out
but I think in addition there's
something which I've never I've never
given a full account of to be honest but
there's something about the sort of
delicate temporal nature of the
integration of the biological system
with this non-biological proper Aid or
resource or whatever it is so that you
can have the brain if you like making
calls to this stuff in ways where it
kind of knows about the temporality of
that it doesn't all have to go through a
little bottleneck of attention you don't
have to kind of think to yourself oh I'd
better get that information from over
there that's not what it feels like to
go about your daily things as you so
it's this sort of idea of something
where if it were taken away suddenly you
would feel very much at a lot so a sort
of kind of general purpose loss there
will be many situations that you'd find
yourself in where you were no longer
able to perform in the ways that you
expected yourself to perform so there's
there's something there that could do
with a bit more unpacking about temporal
dovetailing does it relate to ongoing
conversations that I'm very interested
in about emergence and strong weak
immersions or just being able to core
screen the world in such a way that you
have units that have explanatory power
yeah so well I think it certainly
relates to a lot of stuff about
emergence because the idea here would be
that um by dovetailing things together
in this way you get basically an
emergent you you are the emergent
property you the thing that goes around
um with a sort of sense of its own
capacities
um but doesn't really care
how they get cashed out so something
that that I think comes out quite
strongly in the predictive process in
stories is that brains are kind of
location neutral when they when they
estimate where they can get good
information back from so they're very
good at estimating what they're
uncertain about and going about getting
more stuff but it doesn't really matter
where that stuff is so as long as it's
accessible trusted there when you want
it that's fine and then there'll be a
story to tell about how the actual how
the actual selection process operates
but we come around to that once we talk
about predictive processing let's stick
with txl I mean I guess one way that
philosophers think about their job is
that they're supposed to be carving
nature at the joints and is that does
this count is that this is it is it a
sort of betrayal of that goal because
you're including all my smartphones and
my you know card catalog as part of my
mind or is it an improvement of that
because really the action of our brains
relies on all this stuff
yeah that's a very the very very good
and very delicate kind of question so
you know when when Dave Chalmers and I
put it forward we try to argue that this
was
um this was where the right way to carve
nature at the joints um because of
functional similarities
that said you know it it doesn't
intuitively always seem like the right
way to carve nature at the Joint so I
think that we're making a decision here
and that that decision oddly enough is
in part a moral decision so okay I I I'm
very much moved by the analogy with
prosthetic limbs for example if you took
somebody with a well-fitted prosthetic
limb and then looked at them and said
but you know your basic uh physical
capacities are just those of you without
the limb we would in a way be doing them
a certain kind of Injustice and I think
we'd be doing ourselves a certain kind
of Injustice if we treated people say
with mild dementia that rely very much
on that on a smartphone or on their home
environment in just that kind of way we
would be
we will be sort of regarding them as
less I think than they really are so for
me the sort of non-moral Route the kind
of functional similarity route is a kind
of stalemate because it's kind of
carving nature at the joints and it
kinda isn't and then it's when you Chuck
the moral or ethical considerations into
the pot that I think you have a strong
argument that overall the best way to go
is to err on the side of caution and buy
into the picture of the extended mind I
I bet that depends on one's definition
of caution but
okay all right is there an intermediate
there probably is an intermediate stance
in which your whole body your physical
body counts as your what goes into
cognition and and the mind but but
things outside the body don't is that a
well uh populated space in the thoughts
about this
yes I think that is reasonably well
populated I personally I think it's an
unstable space so I think you better go
one way or the other I think that you
know as soon as you start thinking okay
if I'm using my fingers to help me count
then my fingers somehow count as part of
the Machinery of mine
um yeah a lot of people do feel that I
think that's true but um I think you
can't think that and then simultaneously
you think that the constantly carried
and pocket calculator can't count as
part of the Machinery so so yes I think
the body is often a for me it's a very
useful stepping stone because I can suck
people in by getting them to agree that
continuous reciprocal interactions
between brain and body do a lot of what
really looks like cognitive work and you
know there are there are good examples
of that from even things like the role
of gesture as we speak so spontaneous
gesture by Susan Gold Medal and
colleagues have shown that it it kind of
eases a certain sort of problem solving
if your if children are forced to
explain how they solve the maths problem
but not allowed to gesture they're
actually a lot worse at it so there's
something there's something going on
continuous reciprocal interaction is
probably allowing us to somehow offload
aspects of work in memory into these
gestures yeah you stick what they're in
the world which is good news for
philosophers to worry about hand waving
not just part of my thinking respectable
cognitive task going on right there can
we
ask how this was different back in the
day you know obviously a lot of the
things we've been talking about are
technological or or modern uh so was was
the mind of a human being a hundred
thousand years ago very different
I think I would say it was despite the
fact that the brain of a human being a
hundred thousand years ago was a very
nice so yes I would say that um
the mind of a hundred thousand year old
human uh was very different but the
brain obviously wasn't but think of
intermediate Technologies before maybe
we go back that things like just using
pen and paper and
in particular I'd like to think about
the example of sort of scribbling while
you think the thing that many of us
those of us at least old enough to have
been brought up with pen and paper do an
awful lot of and so as we try and think
a problem through we write things down
um I think it was Richard Feynman who
has a rather famous exchange with a
historian
um Viner I think the historian was where
weiner said um
um these so this is a record of your
thinking and thing and said something
like hmm no it's not a record it's what
did he say it was it's not a record it's
working you have to work on paper and
this is working and I think there he had
a an intuition that this isn't just
offloading stuff onto a different medium
this is actually part of a process that
that solves the problem do we see this
then in other animals I mean I presume
the answer is yes but is it is it more
or less dramatic depending on the
species yeah I mean I think we humans do
this to a a really ridiculous degree and
it's because we invented symbolic
culture somewhere along the way we came
to create these arbitrary systems of
recombinable elements
um that we could then you know
re-encounter as objects for perception
so creating these sort of structured
encodings of in some sense our thoughts
and ideas and putting them out in the
world is a huge opportunity for any
creature that is a good information
forager any creature that is very good
at at reaching out into the world to
resolve some of its current uncertainty
once again that's a theme that we'll
look back to later on so so humans do it
a lot more other animals do it too I
don't think it's a purely human thing it
didn't just suddenly arise you know if
you have a chimpanzee that or an
orangutan better example the constantly
uses a stick to gauge the depths of
rivers before going into the rivers I
think there's enough of a sort of weave
in and robustness for that to count as
part of the sort of extended cognitive
load
I guess I'm very interested in Phase
transitions you know small changes in in
things that allow enormously different
capacities Etc clearly the ability to to
think and and communicate symbolically
was a big one it opened up things but I
guess what you're saying is one of the
things that opened up is not just we can
think more abstractly or generally but
we can think in literally different ways
because these symbols allow us to more
easily offload some of our cognition yes
I think that's right I think that um I
think that one thing we can do is we can
use one of our biological capacities in
very very different ways and that
capacity is attention so when we put
something out into the world in that
sort of way kind of clothe it in
materiality that lets us attend to it in
a whole bunch of different ways and
interestingly I think by doing that we
can often break the grip of our own sort
of
over-constrictive internal models of
what kind of thing it is and how it
might behave and how you might
re-engineer it so even think about
something like designing a new training
shoe or something if you build a big
scale model and then you start looking
at it and poking it and prodding it you
can come up with all kinds of ideas that
you wouldn't come up with just by kind
of sitting down and trying to imagine
all that in your head so I think we're
unusual in that respect but it's a great
power of of us being perception action
machines that we can really make the
most of this and then you look at
current more disembodied AI they've got
really no use for this kind of strategy
the way they work is is just not such
that they get to start putting stuff out
into the world and then poking and
prodding it just to think better they
might do that for all kinds of other
reasons but is that their fault or ours
I mean we haven't really given them the
capacity to do that I think that's right
I think it's our fault I think we've um
to be honest I think well it's our fault
we redesigned a class of tools that are
really really useful for what they're
useful for but I don't think actually
that those tools will ever achieve what
I would call true understanding because
they don't have their grip on reality
grounded in perception action and it's
that ground in imperception action Loops
that I think we're leveraging with
material symbolic culture let me just
create these things and poke and prod
them in different ways we're super
specialized for being good at perception
action limits so I think that's a
there's a trick there that disembodied
AI is missing out but then it gets all
kinds of other things instead sure it
does but okay I'm gonna I'm just gonna
download a little bit because you what
you just said sparked several ideas and
it's it's prefiguring things we'll get
to later but two things one an idea I
heard more than 10 years ago that
attempts to make AI systems suddenly
work much better when you put them in a
robot they can go out there and interact
with the world and secondly a podcast I
did with Judea Pearl who claims that
babies spend all of their time making a
causal map of the world by poking at
things and seeing what happens uh and I
know that the whole uh prediction models
that we'll be talking about are kind of
this like you know the brain making a
model of the world so all that together
do we imagine that if we do put modern
large language models in an embodied
context and let them go out and poke the
world they will change dramatically how
they think
yes I think it would uh you know there
are companies out there that are that
are kind of trying to do this like
versus AI is one of them
um and you know the idea certainly is to
see what happens if you kind of Leverage
the active inference framework as a way
of creating these sorts of new
ecosystems of human artificial
intelligences although I wouldn't start
I think with a large language model
exactly just because you know something
like that has been trained to predict
basically the next word in in corpuses
of text and that's a very funny place to
start if what you want to be is a
perception action machine it seems much
more like developmental trajectories
where you start without that huge body
of nonetheless maybe relatively shallow
um successor item information you want
to learn Basics about causation and and
flow and you probably want to understand
those things in a way that is more
grounded than it will if you just knew
how all the words about causation and
flow tend to follow one another it
sounds like you this is my very cool
question it reminds me it might be that
if you bang the large language modeling
a good enough robot that it's just like
giving a baby a super head start or
something but but it does sound like you
might be at least sympathetic to the
idea that we need that I've had some
people on the podcast uh advance that AI
would be better off if we didn't just
dump large data sets into deep learning
networks and instead also poked and
proud of the AI to have a symbolic
representation of the world yes I think
that's right I think I do agree with
that I think if our goal is not good
tools to think alongside but rather
something like artificial general
intelligence is so colleagues you know
if you if you want to build an
artificial colleague yeah then I think
large language models are not the right
place to start but if you want a really
lovely tool that can do an awful lot of
work and that you can work with then
then they're really interesting honestly
I don't want an artificial colleague but
an artificial graduate student or
postdoc would be very very helpful so uh
or someone who could answer my email I
guess I I it would be weird not to
ask the obvious question you know I get
annoyed when sometimes My Philosophy
colleagues
seem to claim to have an immediate and
obviously true view of what is natural
and real in the world but maybe I'm
going to do that right now by saying I
feel like I'm inside my body I feel like
the eye myself is located maybe even in
my head so is that just I have old
intuitions that haven't quite caught up
to the modern world
no I think I think that that's a a valid
intuition if you like because I think
that we we infer that we are wherever it
is that the perception action Loop is
closing
we're basic you know we're we're
perceiving the world and we're launching
interventions and we're receiving the
effects of those interventions
um and that's such a fundamental part of
how we learn about things I think it's
no surprise that that's where we think
we are notice that that's where we think
we were even if part of our brain was
located in a nearby Cliff top
communicating wirelessly with the rest
of the brain right we'd still think oh
this is where the perception action Loop
is closing this is where I am
um Dan Dennett has a beautiful old
philosophical short story called where
am I where he plays with that idea where
there's someone whose brain is in the
cliff top and they think that they think
they they are closing perception action
Loops using a body in the world but then
at some point you know the the it's cut
off and suddenly they think oh now I'm
claustrophobically stuck in the in the
quick talk because they knew they would
their brain was there anyway it's a
beautiful story no that that is very
interesting and okay so we might as well
uh dig into this phrase that you're
using over and over again the the
perception action Loop and I think the
word Loop crucially important there
right
um and maybe the way I like to think
about it is and and perhaps this is true
because of of Technology but we have a
naive metaphor for how the brain works
as kind of like there's a video camera
with a computer hooked up to it right uh
just taking in our sense data processing
it and doing something and and a big
part of your message is no it's really
not like that at all yeah no that's
exactly right I mean um how
let's think about one way which it's not
like that if you think about something
like running to catch a fly ball in
baseball where you're kind of running to
try and catch this as ball that's flying
out there the the way to do that isn't
to take in all the information about the
flight so far and then plot where you
think the ball is going to go and then
tell the robot you as it were go over
there instead what you do is you run in
a way that keeps the apparent trajectory
of the ball in the sky looking
motionless as you look up there it turns
out that if you just keep doing that
then you'll be in the right place when
the ball comes down you need to do a bit
more to actually catch it but anyway
you'll be you'll be in the right place
when the ball comes down and there's a
way of solving an embodied action
problem that involves keeping the
perceptual signal within a certain sort
of bounds and then acting so as to
um well so as to do that basically
um something that again prediction error
minimizing systems would actually be
rather good at so perception action
Loops I think it
the important thing to think about there
is that they're not solving problems all
in one go generally it's sort of like I
do a little bit of this I do something
that gets more information or that keeps
the perceptual stuff within bounds and
then repeat the process again and again
and again until the thing you start
so I do appreciate your use of a USA
based Sports metaphor there but we have
an international audience that's that's
obviously I have no idea what it really
means the library
but okay so the The Motto then is the
brain is a prediction machine and I just
want to sort of home in on what is the
difference between that view and another
view you might like if you I think maybe
people don't think about the brain too
much they would say okay sure yeah my
brain makes predictions but you really
want to put that front and center as the
point of what the brain does yeah yep I
mean it's um it's both the Beauty and
the burden if you like of this story
that it is really on this account until
about to use the word story because it
doesn't sound scientific it's a count
um that it's basically saying this is a
canonical operation of the brain if you
like the canonical computations that the
brain performs and that it strings
together in different ways to do motor
control and interception and
extraception
um is basically one in which you're
attempting to predict or the brains
attempting to predict the current flow
of sensory information of course there
are different time scales at which you
could predict it and the basic time
scale the bed stroke one is predicting
the present which of course is a rather
funny use of prediction that using
predictions about the future somehow but
this is a sense in which the brain is a
guessing machine it's trying to guess
what the current sensory evidence is
most likely to be and then crunching
that guess based on past experience
together with the current sensory
evidence and that turns out to be a very
very powerful way of estimating the true
state of the external world because it
goes wrong sometimes but it's um it's a
very powerful strategy it's it allows
you to use what you've learned in the
past to make better sense of what the
raw sensory energies are kind of
suggesting in the present this seems
very related certainly to Carl friston's
idea ideas we had him on the podcast uh
the free energy principle the Bayesian
brain what is the relationship between
all these ideas
yeah I mean they're basically I
basically I'm just being an apologist
for Carl Preston
Carl's basic picture the um free energy
minimization picture is a sort of high
road version of the low road version
that I give you so the low road version
comes kind of out of out of thinking
about perception and thinking about
action whereas a high road version comes
out of thinking about what it takes to
be a persistent living system at all you
know you have to you have to
preferentially inhabit the kind of
states that Define use the system that
you are that means that you end up in
the states that in some broad sense you
predict your to be in so in that broad
sense the fish kind of predicts it all
to be in water because it's yeah it's uh
its actions are all designed with that
in mind
um the low road is is a bit less
um less challenging I guess I'll be why
I take it the low road is just all the
same look we have good evidence that the
canonical computations that human brains
and the brains of many other animals
perform involve this attempt to guess
the sensory signal and it turns out that
you can use that to do motor control in
a very efficient way it's been known for
a long time I think that it's important
in perception and the other thing that I
think Carl Krista's work has really done
is being shown that that old story about
perception
becomes so much more powerful when you
see that it's got a direct echo in an
account of action so the idea there is
that you know perception is about
getting rid of prediction errors as you
try to guess the state of the world
using everything you already know
an action is getting rid of prediction
errors but it's getting rid of them by
changing the world to fit the prediction
so you have these two ways to get rid of
prediction error you find a better
prediction or you change the world to
fit the prediction you got and one's
perception the other's action okay but
they're performed using the same kind of
basic neuronal operations well you know
not CM there are differences between
motor control and and sensory perception
but if you look at the wiring of motor
cortex it turns out it's actually wired
pretty much like ordinary sensory cortex
in fact
um so much so that many people don't
like to talk about sensory and motor
cortex just for that reason so these
stories or these accounts give you a a
sort of principled way of understanding
that in each case you're predicting a
sensory flow but in one case
um
you're trying to retrieve an old model
of the world to fit the flow and that's
perception and in the other case you're
trying to change what you're getting to
fit the prediction we can circle around
to that I think I can say that a bit
better in a in a mud is is the idea that
it's the same neural circuitry that is
doing sensing and control or is is it
that the two circuitries look parallel
yes it's that they look it's that they
look very much parallel okay um they
operate in the same sort of way the
reason they're not the same is a
proprioceptive prediction is playing a
very special role in motor control so
the idea is so proprioception is uh is a
sort of um system of internal sensing
that lets us know how our body is
currently arranged in space so the idea
is that you make you put that in order
to reach to pick up the Coke can that's
in front of me I predict the
proprioceptive flow that I would get if
I were a region following and then I
slowly get rid of those Errors By moving
the motor plant in just that sort of way
so you get rid of the Errors By moving
the arm in this case to reach out to the
Coke can so proprioceptive predictions
are especially placed here they act as
motor commands the other kinds of
predictions don't
so it's I I hesitate to use the word
think here because thinking and
cognition and thought I'll have
technical meanings that I that are
slippery to me but the idea is that your
brain sort of thinks intentionally or
unintentionally that your arm is
somewhere slightly different than it is
and then the muscles move it to make
that more accurate that is one way of
putting it and people have put it that
way so that some people have said look
you've got to kind of lie to yourself
right so I've got the lie to itself it's
got to it's got to ignore all that good
information that says that my my arm
isn't living it's got to predict the
trajectory of Sensation that you would
get if it was moved in and that
prediction is given so much weight that
the other information is overwhelmed and
off it goes you'll see where you get rid
of the Errors By
um I'm moving it
um I'm not sure personally that's
exactly the best way to put it I kind of
think it's it's really about attention
so I think it's like you've got
information that says that you're not
moving the arm you've also you're
because of your current goals you can
you're predicting this proprioceptive
flow that would correspond to reaching
for the Coke can and by as it were
disattending to the information that
says that it's stationary
you allow the other prediction to do its
work so I think it sort of targeted this
attention rather than actually lying to
yourself I not quite sure I prefer that
I think we're probably saying the same
thing you know the the math and the
models all work out just the same okay I
think if we if we call it targeted
disadvention we understand it a bit
better I think we you know it makes more
contact with sports science for example
where you don't really want to be
attending to the position your body is
currently in you want to attend to
something like um how it ought to be you
want to
you want to entrain Yourself by knowing
what it would feel like if you were
doing it right right now
so is it similar to the idea of file
compression you know if we have a JPEG
or an MPEG that they're sort of there
are some patterns that are repeated so
you don't have to keep track of every
pixel you can just assume that they they
keep going and then you pay attention to
the differences and and those are what
we're talking about as errors in the in
the brain case that's that's certainly
correct when we when we come back to to
thinking about perception and something
like that is involved in action too but
so but it does seem like in the it's
easier to think about that bit in the in
the case of perception oh where the idea
would be that um you know I predict the
current sensory flow and it's only the
Aerials in that prediction but then need
further processing so you know if I
think I've woken up in my bedroom and I
predict a certain sensory flow and as I
turn my head around I'm not getting any
information that corresponds to that I
might have to go scrabbling or use these
prediction errors to retrieve the
information that actually I'm in a hotel
room and it's going to look pretty
different
um so so I think it's in that sense that
when you don't have to Scrabble that
hard this is a super super efficient way
of doing Moment by moment processing
because if you already predicted it
properly using what you know about the
world you don't need to take any further
action so that in that sense it's
exactly like jpegs and motion compressed
video where the idea is you know if I've
already transmitted the information
about this Frame of the video then in
order to know what the next frame is all
I need to do is react to whatever the
errors would be if I assumed it was just
like the frame before and normally then
there's a few residual errors and if you
um if you use those as uh the
information that you need to deal with
you get the right picture so
these prediction errors these residual
errors
um they carry whatever sensory
information is currently unexplained
right so explain whatever you can with
prediction and then just you don't need
that much bandwidth really to just use
the rest to refine it I remember hearing
it might have been in a conversation
with David Eagleman here on the podcast
the idea that the reason why the years
seemed to go by faster as we get older
is because there's less novelty in our
lives you know the first time we go to a
beach it's all new and we really expend
a lot of mental energy taking it in
whereas the 20th time we already have a
background and the the errors are not
that big is that does that fit into this
story it sounds like it does yeah I
think that fits really really well
um it also helps explain why why it's so
hard to learn new things at a certain
point in your life because the the
inputs that you're receiving get sucked
into these well-worn trots in your kind
of current world model if you like yeah
I think us academics find that a lot as
we get older you know into something
like oh yeah I understand that you know
that fits with this kind of story that
I've already got sometimes it's very
very hard to to give the new evidence
it's proper due and of course attention
is a tool for doing that but um but that
takes a lot of deliberate effort
sometimes to really really attain the
tension kind of with attention reverses
the dampening effect the prediction
normally has so part of the evidence
base for this story this account is that
um
well-predicted sensory inputs cause Less
in your own activity than other sensory
inputs right so there's something odd
there these are the ones we deal with
very fluently and yet there's less going
on in the brain when you deal with them
then in other cases so that's one of the
signatures that uh that led I think to
predicted coding coming on C you know
you open a can of worms when you say how
the old academics get stuck in a rut
there but so I have to just follow up a
little bit I mean I think there's two
different perspectives I could put
forward one is more or less what you
just said as we get into our ruts it
takes more and more energy you know
activation energy or whatever to think
in new ways but the other is uh maybe
this is more optimistic because we are
older and good at certain ways of
thinking we forget that it was hard to
not be good at any ways of thinking and
you know we forget how hard it was to
learn calculus or French or whatever and
therefore we're just not willing to put
in the work anymore even if it were
exactly the same amount of work
yes I think that's right I mean we we
end up in the situation of um expert
perceivers in general where you know
expert perception clearly is being able
to take this unruly sensory information
and just um just you know see what it
actually means for victory on the
chessboard or whatever it or whatever
you happen to be engaged in so I think
in a way all successful perception is is
expert perception in that sense and um
academic expertise is in the same sort
of ballpark
um and it's the same it has the same
sort of blind spots as well so you know
if there is something interesting going
on but it's not doesn't fall within that
um the bound of the existing generative
model to to use the the right vocabulary
for the predictive processing story then
you know the only thing you can do with
it is use it to drive tortuous new slow
learning yeah I'll see why a lot of time
we don't really want to do that don't
want to do that no well look you've used
the word relatedly use the word
efficiency as one of the benefits to
this model you know if we think of
probably the first ever
video storage software was more or less
like a movie where you just had every
frame and you stored it right and then
then only later did you realize it was
much more efficient to just update the
the changes presumably since our brains
were not intelligently designed and grew
up through Evolution this is a a nice
feature to have you know we're trying to
do the most with finite resource courses
is that a big part of the attraction of
this story that it is it requires less
thinking or energy or calories or what
have you
yes I think that's right I think if the
brain didn't work this way
but we were able to do the kinds of
things that we do we probably have
brains overheated repeated
um the you know the the amount of energy
you know there is a trade of it the
trade-off is is kind of keeping the
world model the generative model that
you're using to make the predictions
going and that of course is a big
metabolic cost that's kind of the cost
that is being
um his signature you see in spontaneous
cortical activity it says stuff going on
all the time all the time the kind of um
think about the resting state work from
recall and others as well
um so so that is a cost but that is
traded against the moment by moment cost
of processing all this incoming
information so I think what we're doing
is we've we've traded the cost across
time there and we're using a fairly
expensive
clearly metabolically expensive upchief
of a world model to allow a much more
efficient Moment by moment response a
faster one as well so you know being
somewhat anticipatory about what's going
on in the world around you is pretty
good thing if you're a an animal
involved in all kinds of conflicts and
um dangerous situations uh and also
they're a wiring costs
um it's hard to know how best to think
about the wiring costs but
um the amount of sort of downward
flowing wiring and information seems to
very often outnumber the inward flowing
stuff like sometimes you know up to ten
to one certainly four to one so it looks
as if brains have decided you know it's
been decided over evolutionary time that
this is a good thing to do and I think
that that means is overall the most
efficient way to proceed
I also worry that in a way if you want
understanding there might be no other
way to proceed and that's kind of maybe
there's something more more abstract or
philosophical going on there but I don't
know what understanding would look like
if does it were you won't bring in a
world model of some kind to bear on the
current sensory
um evidence in a context sensitive way
so there's a question there that I I
don't know I really don't know the
answer to because I know there are kind
of formal formal proofs or anything that
can be done using a system that has
feedback like that can be unfolded into
a feed forward system okay
um maybe the upshot there is or maybe
you could unfold us into a feed forward
system for a few bits of processing or
something but it would require a huge
brain and a ridiculous amount of energy
but somebody out there maybe might want
to think about that yeah exactly I was
going to say this this does sound like a
research project for somebody but the
there are so there's the benefit of this
mechanism that the brain uses the
predictive processing model
um presumably there's also
downsides for maybe one is that we're
very susceptible to Illusions right we
see we think we're seeing things that
aren't there because it's part of what
our brain is predicting very very
strongly yeah yes absolutely
um you know I'm I'm subject to several
of these Illusions I'm sure we'll our
Phantom phone vibration is probably a
good one very often might think that
phone's going off in your pocket when
it's not even in your pocket
um I'm now susceptible to Phantom wrist
vibration since I gave in and bought a
bought a smart watch
The Hollow Mask illusion I guess is a
classic in this area where an ordinary
joke shop mask is viewed from uh the
viewed from the concave side so viewed
from behind in a certain sense with a
light source and behind the mask you'll
think that it's an ordinary outward
facing face that you're seeing
um again that seems to be because we
have very strong predictions about the
concavity of normal face structures we
very seldom see anything that isn't like
that and that prediction now trumps the
real sensory evidence specifying
concavity
um except it doesn't in everyone and so
you know autism spectrum condition folk
are slightly less susceptible to that
illusion and to the mcgurk Illusion for
example uh what is that from a
predictive processing Viewpoint that's
probably because of a slightly altered
balance one where sensory inputs are
somewhat enhanced relative to
expectations what was the other illusion
you mentioned the mcgurk oh the mcgurk
this is the sort of it's like a
ventriloquism illusion yeah sorry it's
this one where um it's a sort of bargar
Illusion
um if you
there there is there is a sound which
you can be played such that
um yeah if the lips are moving a certain
way you'll hear it as gar and if they
move the different way you'll hear it as
well but it's exactly the same thing
exactly the same sound so it's uh it's
not entirely clear what that's an
illusion or something else it's it's
hard to know exactly where the
boundaries of Illusions and other kinds
of inference
um lie I mean these kind of optical and
auditory Illusions almost seem fun and
benign but presumably we can take the
basic picture that there's an enormous
amount of information coming into our
Senses at every moment and we can't
possibly process it all therefore we
filter it right we filter it to fit our
perceptions and and then correct for the
errors that must also work with abstract
Concepts or news items just as much as
uh pictures that we get through our eyes
uh yes I think that's right so you know
there is a tendency to not just to see
what we expect to see which can be very
damaging too but sometimes to read what
we expect to read well by read there I
mean sort of read into a text what you
expect to be learning from that text
um I think we probably many of us do
this like that all of us probably do
this when we read news articles where it
looks like they're saying something that
we're very much either sympathetic to or
opposed to
um but maybe when you look at that text
again or you go over it with a
fine-tooth car where you look at it with
someone that's got a different
perspective you realize that's really in
that text it was just a suggest what I
brought to bear in some way
um in the visual case Louise
um Feldman Barrett Lisa Feldman Barra
has this lovely
um but very very
um scary example of the way that
um intrusaptive predictions predictions
about your own bodily State I'll get in
perhaps crunched together with extra set
to ordinary sensory information in ways
it could perhaps give you experiences
where
um a weapon or sorry a weapon where an
object that is reached for in the dark
alley might actually appear to you as a
gun when really it's us just a
smartphone
um you know in sort of you know much
less
um less worry and sort of more
controllable cases you can show that if
you give people false cardiac feedback
so you make them think their heart's
beating faster than it is then a face
that would otherwise look neutral to
them is judged to be an angry face or a
or a worry and say so it does seem as if
we're using internal inflammation to
help make the predictions that structure
our experience of the external world and
so you know that's that's something that
can go right or go wrong as well so we
end up seeing what we expect to see and
maybe even believing what we expect to
believe in some sense yes I mean there
is a sort of you know
um
some people say seeing is believing but
in these cases believe in this kind of
seeing and maybe in these intersection
cases
um feeling is seeing as well that's the
way that Feldman Barrett puts it another
former mindscape podcast guest I gotta
say we sir Philbin Barrett
um are there are there therefore
features or or things out there in the
world that we are systematically bad at
perceiving because of this way that we
process information it's a lovely
question the one that I haven't thought
about
um so things that we just all of us yeah
and Miss because
um well I suppose the most obvious
answer there is unusual events
um so you know you you wouldn't have
seen the you know the uh footage of the
uh gorilla walking across the scene
where you're trying to um to count the
passes of the baseball
um so it's uh worked by
um Simon and chapras anyway it says
classic it's classic work that uh in in
sort of um potential blindness and uh
sorry an attention of blindness so the
idea there is if you're concentrating on
one task something really quite dramatic
could happen and you just wouldn't
notice it I think we're all very very
subject to that
um so outliers I suppose so it's a
predictive brains are tuned in to
patterns that have uh that have helped
them solve problems before and so
whenever we're confronted with an
outlier situation we're likely to miss
it unless for some reason we're
attending right there but why would we
be because attention is driven by where
we expect the good information to be and
this is why for example
um expert drivers are very very good at
a lot of things but they can miss a
cyclist if they're approaching a
roundabout from entirely the wrong
direction somewhere that you know you no
one comes from that direction at the
roundabout so there's a lot of these um
looked but didn't see as they call them
accidents where people might even move
their heads in that direction but if
it's that unexpected
um they just don't see what's going on
presumably these are all quantitative
questions I mean if something is blatant
enough we're going to see it even if we
didn't predict it is that is that fair
to say
um I think yes that's that that's fair
to say as long as we're able to attend
to it
um so it needs to be able to and some
things will try and grab our attention
so like a loud noise if they're really
loud noise like those scaffolders I had
out my window earlier happens then that
will grab my attention unless I'm really
really desperately focusing on my
attention somewhere else as as I might
be so if you think about stage magic
stage magic is a really nice case where
a rather dramatic things can suddenly
appear on stage and most people don't
notice them because uh attention has
been so very very carefully
um carefully controlled by the magician
so because attention is is up in the
waiting on either specific predictions
or prediction errors
um so it's a it's a really really super
important part of the predictive brain
story this balancing act that is varying
Moment by moment that's a great example
I like the idea that professional
illusionists are just leveraging the
fact that our brains are predictive
processors
that's true yeah no there's a there's a
beautiful book I can't remember the
title now but it's by Luis Martinez and
it is um a book written by uh
neuroscientists uh about stage magic uh
leveraging the picture of the predicted
brain as a way of understanding a lot of
it very very good okay so let me then be
put on the skeptical hat just a little
bit
um if and this this is similar to
questions that are raised for Carl
ferson Etc look if our brain is trying
in some sense to minimize prediction
error can't it do that best by not
collecting any data
just by you know hiding away and being
completely unsurprised because we never
leave our room
yeah I think that's that's such a nice
worry to have because it leads right
into this hugely important dimension of
interceptive prediction and artificial
curiosity so let's maybe talk about
these things for a moment so there's
this there's this sort of worry that is
sometimes called the darkened room where
the the best place for a predictive
brain to be would be to lead us into a
dark corner and just keep us safe so all
of those sensory inputs they just keep
on keep on coming just the same you
predict them perfectly but you wither
and die
now we don't do that obviously does that
mean the predictive brain story is wrong
obviously I don't think so I think what
it means is that there's more to the
predictive brain story than
um just bringing extra set of sensory
information into line with predictions
um we're making all these interceptive
predictions all the time I'm predicting
um the state of my own body I'm
predicting for example that
um I should at all times have sufficient
supplies of water and glucose for
example and then infomain action is
automatically taken not when I don't
have enough water or glucose but long
before I don't have enough water or
glucose so you know if I if you start to
feel thirsty that will be happening
before you've reached the point at which
you're going to wither and die without
water and if you take a drink when
you're thirsty you'll feel relief but
that water will have no effect on you
physiologically for about 20 minutes so
the relief is as much a prediction as
the original thirst was it's against an
example from Lisa Feldman Barrett
um so once you put interception in that
way into the picture then of course
we're not going to stay a naughty to not
drink in a darkened room because we have
these kind of chronic systemic
um expectations if you like of staying
alive
but then there's a bit more to it than
that I think as well because we don't
stay in boring rooms either so you could
put me in a very boring room but give me
enough food and water and all of that
stuff
um and I wouldn't like that very much
either you know I might I might even
start to do things I might start to um
play games by um drawing on the wall or
something like this
um and so this now falls under the
umbrella of kind of working artificial
curiosity and predictive brains are
naturally artificially curious Braille
sorry curious brains because
minimizing prediction error is their
basic reward so you could sort of say
for brains like that the only thing
really that's rewarded is minimizing
prediction error that's what they want
to do and um if they're not performing
any particular task they'll still try
and find some prediction error to
minimize because that's the kind of
thing that they are and this is what
makes predictive brains general purpose
structure Learners so
um so there's some there are some rather
nice work that's been done by Rosalind
Moran at uh UCL I think it's UCL
um and what she's been doing is
comparing reward driven Learners with
prediction driven Learners and finding
that the purely reward driven Learners
will learn a way of solving the problem
more rapidly than the prediction for
even Learners very often but frequently
a more shallow way of solving the
problem because as soon as they find a
way to reliably get the reward they they
kind of stick whereas a prediction
driven system it basically wants to
minimize prediction error as much as
possible and that leads it to explore
its environment repeatedly learning more
and more about it and if you then seed
it with a goal and you think
simultaneously uh it will outperform a
pure reward driven agent so so that I
think when you put those two things
together you kind of see that the
darkened room isn't really much of a
threat we don't like we don't like death
and we don't like boredom and both of
those things seem to be natural effects
of being driven to minimize errors in
prediction I guess the way out that
comes to my mind directly which I'm not
sure if it's the same thing is as what
you are proposing or it's something
different but you know in physics when
we calculate the entropy of assist them
and we say it's at maximum entropy
that's telling us some distribution of
all the possible States it could be in
blah blah blah but famously we can
calculate maximum entropy of a system
subject to different constraints right
like subject to it's at a certain
temperature or it's at a certain
pressure or whatever and we'll get
different forms for that probability
distribution so it couldn't we just say
that there are two things going on we
want to minimize prediction error but we
also want to survive so There's a
constraint we want to survive and under
that constraint it's actually useful to
go out and be surprised sometimes so we
can update our predictive model and I
think I think that would that I don't
know how mathematically that would work
out but it does seem a little bit
intuitive to me yeah and I think that
does mathematically work out I think
this is the sort of stuff that Carl
Kristen can speak to more reliably than
I can but um but it looks as if very
often
um the the correct move for a prediction
driven system is to temporarily increase
its own uncertainty right so as to do a
better job over the long time scale
right of minimizing prediction areas and
that looks like the value of surprise
actually and that we will I think we
artificially curate environments in
which we can surprise ourselves I think
actually this is maybe what Art and
Science is to some extent at least the
curating environments in which we can
harvest the kind of surprises that
improve our generative models our
understandings of the world in ways that
enable us to be less surprised
um about certain things in future
I wonder if you could use this idea or
set of ideas to make predictive models
for what kind of games people would like
to play or what kind of stories or
novels or movies people would like to
experience you want you know or I guess
in music it's very famous right you want
some Rhythm some predictability but you
also want some surprise also there's a
sweet spot in the middle yeah yes I
think that's exactly right um
a literary theorist in
Scandinavia somewhere has written a nice
book called probability designs and so
she is using the vision of the the
predictive brain as a way of
understanding the shape of literary
materials poems okay there you go and my
idea is that we should think of every
novel every poem as a probability design
leading us through sort of building up
expectations cashing them out building
them up at multiple levels giving
Precision weight into some of the
expectations versus others and clearly
you know this makes sense of music as
well there's an awful lot of that going
on in music
um and probably it applies to all sorts
of things even like rollercoaster design
I imagine it's exactly that a roller
coaster is a kind of probability design
what's what's interesting is how we get
surprised again and again even if we
ride the same roller coaster or read the
same novel right or listen to the same
piece of music and I think that shows
the skill of the construct in giving us
inputs that that activate bits of our
model Drive in expectations again and
again to the point where you're still
surprised
even though you could have said
beforehand that's what's going to happen
yeah yeah but be surprised and this in
some sense that some level would be the
best thing to say and I think this
speaks a little bit to the idea that as
prediction machines we are multi-level
machines we're not just it's not just
there's a prediction and it's either
cached or it isn't but this prediction
exists as a high level abstraction
predicting a lower level one predicting
a lower level one predicting a lower
level one all the way down to the actual
income in notes of the tuning or words
on the page
um it's because we're multi-level
prediction machines I think that um
things like honest placebos work so you
know Placebo is obviously fall rather
nicely under this sort of general
account because expectations of relief
thrown into the pot can make a
difference to the amount of relief that
you feel but if you're told that you're
being given a placebo it can still make
a difference to the amount of relief
that you feel presumably that's because
there are all these sub levels of
processing that are getting
automatically activated by good
packaging and delivery by people in
white coats with authoritative voices
and this sort of thing
um so I think that's something that we
might learn from these accounts too that
we should maybe medicine and Society
could could make more use of ritual and
um yeah ritual and packaging and things
that are in some sense
other than that in some well I won't say
ineffective what I mean is they don't
they they bring about their effects but
not through the standard routes good
okay very very good okay when you know
we're late in the podcast we can get a
little bit Wilder and uh and more
profound here so you you in the book you
gesture toward ideas along the lines of
we are not only you know the thing that
the thing to get in mind is that we're
not just sensing reality and writing it
down we are in some sense participating
and bringing it about
uh maybe even using phrases like what
you think of as reality is really a
hallucination tell us exactly how far we
can go along that rhetorical road yeah
um
proceed with culture
would be the the right thing to say
because lots of people talking about
these things myself included use this
phrase perception is controlled
hallucination
um and you can see why because the idea
here is that perception is very much a
constructive process
um in which our own expectations get
thrown into the pot and they help you
see what you see
um and those same expectations are
thrown into the port of feeling your
body the way that you feel it and so a
lot of our medical symptoms in fact all
our medical symptoms reflect some kind
of um combination of expectation and
whatever sensory evidence a body is
actually kind of throwing up at that
time so this is really a very very
powerful story
but when you think about perception as
controlled hallucination we need to take
the notion of control pretty seriously
um for that reason in in some slightly
more philosophical works I've tried to
argue that we should flip the phrase
around and think of hallucination as
uncontrolled perception and that that as
it were puts a boot on the right foot
somehow yeah it lets us say that you
know when these things are working
properly you're in touch with the world
this is a way of using what you know to
stay in touch with the world as it
matters to an embodied organism like you
trying to do the things you're trying to
do
um but then of course when it goes when
it goes wrong when the perception is
uncontrolled if you like then you get
hallucination you will get a
hallucination when you're kind of
disconnected from the world in your
predictions your brain's predictions are
doing all the work
and then if you turn the dial in the
other direction and your brain's
predictions aren't doing enough work you
fail to spot fight patterns in noisy
environments it can be easily
overwhelmed so so
um I feel like
thinking of thinking of hallucination as
uncontrolled perception is actually the
better way to do it even though it's
clumsy to saying it doesn't even roll
off my tongue that easily which is why I
didn't I don't think I actually bothered
making that move in the in the
experience machine book
you know it's really hard to resist
drawing a parallel with large language
models here because of course their
entire job is predicting what's supposed
to come next right and guess what they
famously hallucinate uh they say things
that are completely false but and
interestingly they do things with
apparent confidence right they don't
they don't hesitate or Mumble when
they're hallucinating to them it comes
out just as definitive as as the truth
does and maybe there is a parallel there
yes I think that's right I mean they are
um
their hallucinations are are in a way I
think partly at least the result of them
not being anchored in perception action
Loops in the right sorts of ways so you
know it's this anchoring and perception
action Loops it sort of teaches us a
lesson when we're young it's like you
know if you get things wrong bad things
are going to happen too if I don't spot
the edge of the path that's being at the
right place then I'm going to fall over
and I'm going to get signals that I
chronically don't like as it were so
well the intercepted predictions are
coming into play there
um whereas if all you're doing is
predicting the next word in a sentence
and your your reward is basically being
kept alive as a large language model
then then why not just you know Go the
whole hog and be confident about a nice
structured um piece of that you
can uh that you can generate
um at the same time it's interesting
that by changing the prompts to the
large language models or to chat and
chat GPT anyway okay you can make it do
substantially better so you can say
something like um you know write this
for me um in the style of a
well-informed uh scientific expert it
makes less mistake so it'll still still
tends to hallucinate references but at
least it's a little it's a little bit
better
um but yeah so something very thin about
just predicting the next symbol right
you know I just feel like it's not very
well anchored in reality and so
hallucinations are kind of um
it can't tell the difference between a
hallucination and something else maybe
that's the point unfortunately when
we're in the grip of hallucination we
can't tell the difference either
someone on Twitter coined the term
hallucitations when uh chat makes up
papers you haven't written I like that I
like that yeah they appear all the time
I'm going to start including them on my
CV uh are there
implications you know if we get down and
dirty and and not philosophical for how
to treat
mental issues that we have uh whether
it's you know
um uh depression or pain or or anything
like that or do we get actionable
intelligence from this way of thinking
yes I think we do I mean it's early days
um but I think particularly in the case
of pain there are some clear sorts of
recommendations here that are being
implemented by people working in what
they call pain reprocessing Theory which
is just a kind of high pollutant label
for the idea that you reframe your pains
um so you know
yep the the thought would be that we
tend to treat pain as a signal that we
shouldn't be doing something right if
you reframe it as okay
um my pain signaling system is misfiring
then you can begin to think so this pain
doesn't mean that I shouldn't be doing
it and it turns out that if you get
people involved in those regimes they
start to be able to do a bit more
because they're not scared of stopping
because of the pain and actually as they
find that they can do or the pain itself
presents itself to them as as listening
I think because the brain sort of infers
well if I'm doing this stuff it can't be
that bad can it so there's a kind of
virtuous cycle that replaces the Vicious
Cycle that was aired before because you
know
um this is going to hurt so I'm not
gonna do it
um and then if I do start to do it all
it really seems to hurt I'm not doing it
um so pain reprocessing theory is one
nice case ISO
close self-affirmation is another case
the idea that um the idea that you know
if you're prone to thinking that perhaps
you're not going to do well in some
tests because you're in a certain
minority group or you're a female and
it's a math test or something like this
um self-affirmation in advance of the
test can really make a difference you
know I'm good at this I can't do this
um lots of people like me do this that
that kind of thing
um it's important of course not to over
over egg the custard as we might say on
on this side of the uh the Atlantic
anyway
um you know you can't reframe
um you can't reframe having uh having
the sort of bacterial infection in a way
that is really going to make any
difference to the bacterial infection
that you've got and reframing makes a
big difference to cancer related fatigue
it doesn't make much difference to
cancer
um so I think we have to be you know we
have to be aware of the limit and in
general I don't think that these stories
these accounts are kind of positive
thinking sorts of the cow they're kind
of they're more like you know there are
many factors that are involved as we
construct our experiences and some of
those factors are our own expectations
yeah okay now that that sounds perfectly
sensible put that way I'm not an expert
but my rough impression is that we don't
we know embarrassingly little about pain
and and how it works it's an
understudied area I guess I don't know
whether it's for moral or psychological
reasons so any little insight might be
very helpful yeah yes I agree and I
think that um I think pain research is
actually moving into some very very
interesting stages now as we understand
more about about the ways in which
people's own expectations make a
difference so even where um where
there's a very standard physiological
cause it people's experiences of their
of their pain very tremendously and even
within a certain individual their
experiences
vary tremendously from Context to
context and day by day in ways that just
aren't tracking the organic as well I
don't like this word organic there's
always something organic going on aren't
tracking the sort of the standard the
standard calls
um so what's probably happening is a
different contexts are activating
different expectations of pain or
disability and without the standard
organic calls changing in any way that's
making a difference to how you feel and
what you can do
I actually just realized I forgot to ask
a crucially important question earlier
um we had shenan Ismail on the podcast a
while back and my new colleague at Johns
Hopkins and uh talking about physics and
the arrow of time and you know through
talking to her and through talking to
other people I have this vague idea of
why we think that time flows why we have
the sense of time passage and it's
because we are constantly predicting a
moment in the future and also
remembering a little bit in the past and
updating right and you know the updates
happen in One Direction of time and
that's what gives us this sense of flow
or passage uh given your expertise does
that sound at all on the right track
yeah that sounds very that sounds that's
that sounds like a really nice story to
me
um or account even there's an account
there waiting go ahead of a story
it's um I mean it reminds me a little
bit actually of um uh the the
kind of classic
um classic philosophical phenomenologist
who had this idea that um experience is
this sort of this thing which is rooted
rooted in the past but always looking
towards the future and the present is
this this sort of um just a kind of just
where those things meet
um whether you know I don't know what
really gives us the arrow of time
um that that sort of sense that the the
idea that you can't sort of unscramble
the egg or whatever it is I it's not
obvious to me quite why my prediction
Machinery is is kind of what's uh what's
delivering the uh the fact that it looks
like I really can't
um recreate the egg from scratched
I halfway agree in that the account has
not been fully fleshed out although I'm
100 sure it's ultimately because entropy
is increasing we just have to draw the
connections there which is the the usual
work exactly sounds like a great account
of why we think there's an arrow at a
time yeah why we feel it right that's
part of our uh image of the world okay
so then the last question uh is the flip
side of the pain question there's this
idea called the hedonic treadmill which
I think some people has said have been
has been discredited but the idea that
you know we get happy not because of our
overall welfare but because of changes
in our welfare and if if we win the
lottery and now we're rich and living in
luxury soon we have exactly the same
happiness as we had before this yeah
there are challenges to this view so I'm
not even sure if it's true there's a
replication crisis in Psychology
everything is very easy to me but it
does seem compatible with the whole
predictive modeling view of what the
brain is doing you know if what we're
doing is constantly predicting what's
happening next then can happiness be
understood as noticing that our
prediction was a little pessimistic and
things are actually a little bit better
yeah that's interesting I haven't I
haven't thought about this but it sounds
like it should it should fall rather
neatly into place with this sort of
dampening of the well predicted so you
know the the fundamental starting point
for a lot of these accounts was that the
neuronal response to well-predicted
sensory inputs is dampened
um so if these are sensory inputs are
supposed to be uh Drive in pleasurable
experiences but you've really been
through that 100 million times before
then the pleasure is I think going to be
diminished perhaps unless you can
actively reach in there with attention
and try to stop that happen so I wonder
whether someone that really loves the
taste of a particular wine when they've
had it a million times before as long as
they can reach in with attention and up
the dial on what's coming in through the
senses then maybe they can sort of
artificially surprise themselves a
little bit if you see what I mean I do
yeah much longer about that but I feel
like there's something there of you know
wine tasters are told to do this to sort
of sit back and kind of let it let it
speak for itself so you don't get sucked
into your own expectations but now it
brings up questions I said I know I said
it was the last question but there's an
issue here of High versus low Pleasures
or simple versus subtle Pleasures right
I mean I'm a big wine fan and I
absolutely do get pleasure from very
fancy complicated sophisticated wine
because I don't I don't I can't afford
to have it too often so that it's not
boring to me but I also get pleasure
from like the perfect slice of pizza
which is very simple and predictable and
whatever but I get that comforting
pleasure so now I'm not sure what to
think yes I mean
you know I think I'm not quite sure what
to think about those cases either I mean
it does seem to me that we you know
because our brains of prediction
minimizing engine then in a way we do
kind of want to live in Worlds that we
can predict well and not have certain
sorts of things and so when those things
are bringing hedonic benefit then I
think
um existing there is going to be a
rather comfortable way of existing even
though we also have a sort of a company
and drive to increase our states of
information to sort of you know learn a
bit more in case it lets us um generate
a slightly alternative future in which
you know the pizza is square but we're
liking it even better or something but
but I think that I think that if we
think about these things delicately a
sort of multi-level and
multi-dimensional prediction engines
that we can accommodate both the both
the drive the novelty and the
attractions of staying within the space
where um we're actually uh all that
stuff that wants us to minimize errors
is doing rather well in a local sense
even just looking at a pizza you're
minimizing lots of errors after all just
to see the shape of the pizza in front
of you you're kind of moving your eyes
around harvesting information minimizing
errors you're getting some head on it
kick out of it nothing bad is happening
anywhere it's a pretty comfortable place
to be
you know I'd like to leave messages for
the young intellectuals out there who
are deciding what to do with their lives
it sounds like there's a sweet spot here
where we do know something about the
brain and the body and how they work and
how they fit together but there's still
a lot of good questions left on the
table to be answered by the future I
think there's a huge number of questions
you know every every story every account
we've had so far has turned out to be
wrong and I'm sure this one will too so
the question is you know what's it a
stepping stone towards well it's a very
good story you're telling us Andy Clark
thanks so much for being on the
mindscape podcast thank you it's been a
real pleasure thank you
[Music]
thank you
[Music]
