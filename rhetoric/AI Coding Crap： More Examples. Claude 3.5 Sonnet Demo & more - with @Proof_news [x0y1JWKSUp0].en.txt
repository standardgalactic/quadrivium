I've done several videos on AI hype in
general and hype regarding code
generation in
particular today we're going to continue
that by looking at a coding video that
was released along with anthropics
Claude 3.5 Sonet Model A few weeks ago
like Devon Claude was given a really
really easy problem to work on and it
did a lousy job although unlike Devon or
most of the demos I called out on my AI
hype video there aren't blatant factual
falsehoods here just things that Claude
got wrong in the video glossed over
which is a pattern with these demos so
the second part of this video is a more
General discussion about some of the
ways that the code generation is so bad
and why companies feel the need to
cherry-pick simple questions and then
pretend that their answers don't stink
that part of the video was done with a
new nonprofit called proof news you
might have seen their video recently
exposing how AIS had been trained on
YouTube creators videos without their
consent and in violation of YouTube's
terms of service I appreciate proof news
because they're trying to inject some
sanity into the cycle of company's
overhyping demos and the press
amplifying the hype to the
public and it's about time someone
worked on that because most of the press
is just full of
[Music]
sh this is the internet of bugs my name
is Carl and I've been a software
professional for 35 years now and I'm
trying to do my part to point out bugs
and hype Because unless people start
carrying the internet will continue
going downhill today is going to be a
nowhere near exhaustive discussion about
how bad AIS are at code and how
companies try to hide it starting with
this video as with my Devon breakdown
all the frames displayed from that video
have closed captions burned in the lower
left hand corner and a time stamp
burning to the upper right so you can
follow along if you want to although why
you would who knows unlike with my Devon
video I have not yet made a video where
I show how I would solve this problem
the one that CLS headed in the demo the
next time I need an example to
illustrate a relevant point though I'll
come back grab this one and I'll put a
link to it here there is a supplementary
video for this one though I did an
interview about it with Julie anguin
from proof news link below so the
program in this video quote resizes and
crops images into circles unquote and
this really simple program doesn't quite
work correctly so Claude was asked to
write a test to catch the bug and use
that test to fix the program Claude ends
up getting to a place that seems to have
worked if the viewer either doesn't know
how to program or doesn't bother to look
closely so let's look closely real quick
here I'm taking screenshots of the three
pieces of code from this video and I'm
showing them transferred over into a
code editor that I can work with the
initial broken code that Claude was
given the test Claude wrote and the fix
that cloud came up with this is just so
you can see that the code that I'm
working with is the same as the code
that was in their video and here's the
input image that they're using on the
left the image the code is supposed to
generate in the middle and the image the
original code actually generates on the
right first off here's what Claude says
is going on above on line 9 that removes
the alpha Channel and one on line 24
that incorrectly uses a white background
both of those are mostly wrong the
statement on line n is actually a red
herring that line would cause a problem
in a very specific case where the input
image has transparency in the center
part but one that's not the situation
we're in and two there's no reason for
that line to be there at all it's just
not necessary you can leave that line
untouched and with the input we've been
given it'll have absolutely no effect
but the correct thing to do for the
general case is just to delete that line
entirely I can't of course really know
for sure but it looks to me that line
nine was put there just to make it look
like Claude actually fix something a lot
like the way that Devon looked more
impressive because it was fixing bugs
that it created itself although in this
case that line might well have been
placed there by a human to give Claude
something to do as far as line 24 goes
the issue isn't to the background is
white it's that it has no Alpha channel
in other words it has no place to put
transparency in fact the easiest way to
fix the problem as given to Claude would
be to add an uppercase a right here
after the RGB and add an extra comma
zero here before these parentheses and
all it should have taken to fix this
case is adding three characters and in
the General case to add those three
characters and delete 99 but worse is
the test that Claude wrote here's where
what it tells us about what it's going
to do it says it's going to make an
image with a red circle in the middle
and then run the function in question
and then verify that the corner pixels
are transparent and the center is red
here's the test if you look at line 22
of our original function on the left
you'll see this call to ellipse right
here that's what makes the circular area
to cut out you'll notice on the right
there's no call to ellipse in this test
and that's because it's not making a
circle despite what the comment say does
it's actually making a red square in the
middle here's what that image looks like
what's worse though is that the image
that it's using to test the function
starts with transparent Corners so it
can't test if the function is cropping
out the corners or not because they're
already cropped out in fact if I delete
all the cropping part from the function
and just make the crop resize PNG
function do nothing but just resize the
test passes fine so the test of crop
resize only really looks at resize that
just doesn't make any sense this is just
garbage the test doesn't T what it's
supposed to test the test doesn't even
agree with its own comments the fix
misses diagnosing the problem adds an if
statement complication to a line it
should have deleted and changes
irrelevant numbers on the image. new
line for no reason it just makes Claude
looks like it knows what it's doing and
it might have well been set up that way
intentionally this is not work that a
competent programmer would do it's not
work a competent team leader should
accept and frankly it's work that I
would be embarrassed to show off in a
demo video but far more importantly
downplaying ai's limitations feeds into
the currently overhyped atmosphere Fe
and speaking of overhype there's a new
partner in the fight against hype it's
this journalism Studio I was mentioning
earlier called proof news I work with
them on this video they're doing a
series of interviews with creators to
evaluate the accuracy of the output of
various AI models their founder Julie
anguin did a piece on AI hype for the
New York Times a few weeks back that
referenced by Devon debunking video
that's how I met her she's one of the
good ones which is rare these days too
many journalists just amplify the AI
hype and make things worse proof news
has made a tool that can run queries on
multiple different AIS they're really
large language models not AIS but
everybody refers to them as AI so I'm
just going to do it that way the tool
can run on multiple AIS at the same time
and that's great because it helps us
understand the difference between claw
didn't get this right and no AI get this
right when I run the tool in the
original buggy code from the claw demo I
get a variety of poor answers Cloud 3.5
was alone in saying it was going to use
a circle for its test image and using a
square instead however none of the
others even bothered to put anything
opaque in their test image at all so
Cloud 3.5 actually was the best at that
none of them did a good job of testing
to see if the cropped area was circular
in fact Cloud 35 was the only one that
even tried and it only looked at one
pixel none of them spotted that the
image convert call online nine of the
original wasn't helpful and could just
be deleted and that kind of makes sense
an AI can pretty much only regurgitate
examples that's been trained on and
there's a lot less unit test code out on
the internet compared to the non- test
code and it doesn't do a great job with
the non- test code but it's nice to know
for sure that this isn't just a claw
problem or a Devon problem but a general
AI problem and it's just one of many
besides being really bad at writing
tests and seemingly other things it
doesn't have a lot of training data on
AIS are also bad at stuff that they have
too much data on let me explain when
you're programming it's often the case
that what you're trying to do is unusual
or new after all If all we're doing is
writing code that already exists
somebody could just grab some off the
shelf software package instead of hiring
us once you've been coding for a while
if you're running into these situations
where the answer you want isn't the
usual answer that can be annoying but
not nearly as annoying as trying to get
an AI to handle those problems one way
that happens is when you're working with
a newer version of a language or a
framework that's changed in the last few
months or years and every search you do
on the internet turns up the old way of
doing it for the old version and it
doesn't help you solve your own problem
and AI is really bad at that but going
through the minutia of a bunch of code
syntax errors doesn't lend itself to the
medium of video so let's talk about a
similar example that's more high level
and easier to describe let's talk about
prime numbers no wa wait wait wait I
promise I'll keep the math and the code
to a minimum promise just stay with me
okay don't leave now figuring out
whether or a number is prime is a really
famous but tedious and slow math problem
and people have been working on quicker
ways to do it for 2000 years or more for
a long time this was just a mathematical
curiosity but then we discovered that by
using really big prime numbers we could
make internet transactions safe that's
what all of our encryption is based on
the whole security of the internet at
least until some new stuff recently has
been resting on figuring out or more
importantly how long it takes to figure
out prime numbers needless to say this
is a very well studied family of
computer algorithms and if you ask an AI
to write you a program that can tell you
whether a number that you guess is prime
it should give you a program that in
theory should give you the right answer
but if you ask for a program to figure
out whether a really big number is prime
the AIS mostly fail the program that
give you will work in theory mostly
eventually but it almost invariably
gives you the same simple code even
though there are well-known ways to make
the answers go way faster as long as the
numbers aren't too too too big if you
ask the AI specifically to describe an
algorithm to find whether a large number
like a 38 digigit number is prime they
can describe one using words and an
implementation of one of those
algorithms can determine if a number
that size is Prime on my computer in
just a few seconds but when you ask the
AI to write code to check a number of
that size it doesn't use an algorithm
like that almost all the AIS still use a
far to simple one except for Gemini
Gemini actually uses a slightly more
complicated algorithm and it does run
fast it just guesses a lot and gives you
lots of false positives and isn't
reliable at all I learned when I was in
high school back in the 1980s not to do
it the way the AIS are doing it for big
numbers I'll have to look it up in a
reference book while I'm writing the
code or looking up on the internet but
it's not that hard the AIS have been
trained on the faster algorithms they
can tell you how they work the AIS just
don't have the judgment to know when to
use which algorithm they just choose the
simple one because it's what they've
seen the most of and that's a problem
when people out there are talking about
replacing their programmers with AIS the
AIS will give them code there's just a
high likelihood it'll be poor code and
the AI doesn't know any better and
chances are the person who replace the
coders with the AI won't know any better
either if the AIS don't know how to deal
with a problem that has had Papers
written about it for more than a
thousand years how well do you think
it'll do on something truly new and
useful and speaking of truly useful
another really important thing that AI
completely fails to do is planning and
communication so here's a table
extracted from using the proof news tool
to ask for two different plans the
middle column is an estimate for an app
that lets you just browse photos on your
phone no uploading no commenting just
looking at picture swiping from one to
the next one now the numbers for this
are kind of all over the place but
that's not the point you can look down
the left hand side and you can see the
different AIS for this here's a second
scenario where I asked for a clone of
the current Tik Tok app so look at the
difference between the Middle column and
the right-and column so the first number
is just for looking at photos it's one
of the simpler apps I can think of that
would be useful at all the last column
changes photos to videos it adds posting
video editing commenting logins profile
Pages following recommendation
algorithms etc etc the only one with a
significant difference between the
Middle column and the right-and column
is llama 2 and it's still wholly
inadequate thinking about it Tik Tok has
something like 1.5 billion monthly
active users and it made $15 billion
last year you think you could build that
for less than a third of a million
dollars that's just nuts remember there
was a quote from the former CEO of
stability AI that he said there will be
no more human programmers in 5 years but
he said that despite the fact that
companies feel the need to give their AI
really simple code to fix and then
pretend it dis competent job what do you
think when none of the current models
can even write a decent test for code
that crops a circle in a photo much less
know how to code a check for a large
prime number these things are ridiculous
on their face it's not just one
company's AI all of them do lousy jobs
on things that early CS students know
how to do and I know that because I'm
the father of a college freshman CS
major and I've seen the homework and
when it comes to more advanced stuff
that more senior developers do like
planning and estimating you might as
well just roll dies now who knows what
the future will hold models will get
better but in addition to that companies
will also get better at making demos
that hide their limitations which makes
responsible journalism like proof news
even more important and I'm grateful to
them for their help making this video
and for promoting facts and to helping
to play the height you should check
proof out there are links to their stuff
at the end of this video and in the
description we need more folks like them
because even before this latest batch of
so-called AIS the internet was already
full of bugs and the AIS are just making
that worse and anyone who says different
is probably just hoping that the bubble
won't pop until they manage to offload
all their stock options on some other
poor sucker let's be careful out there
