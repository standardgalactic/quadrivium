hi I'm Ken Stanley I live in San
Francisco and I just started a new
Social Network it's actually a
Serendipity Network called Maven I can
tell you a little story about this book
Kenneth so this is the second physical
copy I've got of your book and you know
why um I lend it out to some of my
friends and my friend Kate loved it so
much that I never saw it back again so
um just so just so I can have the Bible
in my studio um I've I've got the second
copy of it but um but yeah you know I
can't really think of any book that I've
read that has changed my thinking as
much as this book has uh it has massive
implications not only for philosophy but
also for how we as artificial
intelligence researchers think about
building the next generation of AI to
achieve your highest goals you have to
be willing to abandon them we have a
nose for the interesting that's how we
got this far that's how civilization
came out that's why the history of
innovation is so amazing everything
washes out when we start ruling by
committee like we have to allow people
to follow their passions to their
extremes and yet we run society as if
this actually makes any sense at all I
think the gradient of interestingness is
probably the best expression of like the
ideal Divergent search you get to this
problem that like I don't know how to
formalize interestingness what you get
to then are proxies for interestingness
that not everything that's novel is
interesting but just about everything
that's interesting is novel it is in my
personality and nature to want to
overthrow this I guess we could say
tyranny of objectives my particular area
of interest and research has been in
what's called neuroevolution which is a
combination of neural networks and
evolutionary computation so I'm saying
we got to flip this completely like the
smart part is the exploration the dumb
part is the objective part because it's
freaking easy the first interview that
you had with me that was like incredible
yeah and that was early on I remember I
used blender to create this 3D
environment for the stepping stones and
uh that was so crazy I couldn't believe
that I was like wow that's like the
coolest thing I've ever seen like for
just about anything that I've ever said
because it's it's like a music it's like
this 3D thing moving around it's like
wow this is like seriously professional
well it wasn't professional but yeah so
yeah I mean that kind of be cool when
you left open AI you had um an
interesting conversation with Sam Alman
this is obviously a huge departure from
my career trajectory like that's one
reason I'm nervous cuz like I I'm known
for AI research like that's where my
reputation is stti and I'm like just
leaving it to do a social network he
said that you know the thing that I
think you need to do is to think about
the theme of your career not what you've
been doing like you've been doing AI
research that's what you've been doing
but what is the theme the thread that
connects everything you've been doing
like even maybe since before your career
like what are you about as a person it's
not AI research cuz he said for example
like take my career and what he said was
that I have realized that I am all about
scaling it's scaling that's what
connects all these things you scale a
startup but the beautiful thing is that
AI is all about scaling there's a deep
insight there actually um you know like
to understand that at the heart of this
AI currently is the idea of scaling and
there's nobody better than Sam whose
entire life is about scaling things um
to actually like you know supercharge
the scaling now I personally don't know
if scaling is about every everything is
about like I'm not totally bought into
the idea it's all about scaling I'm not
even sure Sam would even claim that I'm
not putting I don't mean to put words in
his mouth um but it's the thing that
ties together his career so it's what
he's about not Alli I is about but what
he's about scaling and this just made
things click for me not just like about
me but about him like that was the first
thing I thought was wow this is so
interesting that I understand him better
like in this instant it was such a short
thing to explain but it just made me
understand why is he even here like why
is Sam Elman in charge of opening eye
then I just suddenly understood this
it's scaling that's who he is he's like
the best in the world in scaling in and
then he said you don't seem you know
you're not you the theme that cuts
across everything you've done like the
book that you wrote the research that
you've done it's this open-endedness
stuff it's Divergence you're interested
in you seem interested in like this
Freedom exploratory type of systems like
Divergence in in in all kinds of
contexts I'm about scaling I don't think
he said this literally but basically way
I took it is I'm about scaling you're
about Divergence that that sounded so
neat and nice so Professor Kenneth
Stanley has created a new type of social
network a Serendipity Network where all
of the popularity contest is gone the
likes are gone it's designed to
accumulate information to Foster
creativity just like things work in the
real world what it is not is a
popularity contest and that um is
clearly I think a radical move because
basically all social media I don't think
there's an exception is a popularity
contest um you've got got like buttons
you've got popularity you've got follows
you've got popularity this all driven by
that um and so we have actually taken
that away um we don't use those
mechanisms um and so the question then
is what do you actually do in a system
like that you've taken away our drugs of
choice um of course it's kind of like a
detox um so we're going to actually make
your life more healthy hopefully like
that's the Hope here but how like how
does it stay interesting well the thing
that really drives our system is folling
interest so like one way that we put it
is that you follow interest instead of
following in
influencers um and so following interest
means that influence means that
interests are kind of uh first class
citizens um where like you can follow an
interest in our system way you would
follow a person maybe in another system
even has its own profile for the
interest and these interests arise whole
cloth out of nothing um in the system uh
so it's not like there's this fixed set
like in a lot of systems there's like
fixed sets of things that you can join
or follow like this is just created as
it goes um and so users kind of have an
experience where they're discovering and
adding new interests often they're
through other users like you'll see
interests that other users follow
sometimes you'll even find out if
someone Falls an interest because of you
because that's kind of a way of uh
having a more maybe a healthy form of
validation socially so it's like oh I
got someone interested in something
rather than you know somebody likes um
my post or somebody's trying to follow
me um like I'm a brand but you got
somebody interested in something because
it's about the interest and so people
are finding you interest also through
new posts um like when when you post
something on the system in artificial
intelligence will extract interests out
of it and it'll suggest those to people
who are uh exposed to that post and so
people can find new interest that way
too and so adding interests is kind of
the recreational activity instead of
liking and following fans of mlst will
know that we've carved out a niche in
the kind of center point between
philosophy and artificial intelligence
and this book the episode that we did on
on this book was really emblematic of us
starting to cut out that Niche a few
years ago the main thesis of Kenneth and
Joel's book is that objectives or
consensus mechanisms lead to the intific
of society systems and everything
there's nothing really insightful or
interesting about just doing objective
optimization yeah we've got plenty of
good algorithms for doing that and it's
not counterintuitive at all it totally
makes sense but it's not going to get us
hardly anywhere interesting whatsoever
it's kind of the curse of optimization
and what that means is when you build an
optimization system you have to take a
metric you have to take a utility
function or a cost function and you have
to optimize it but then it suffers from
the shortcut Rule and good Hearts law
the shortcut rule is that you get what
you optimize for exactly what you
optimize for and nothing else which
means if you can't specify all of the
richness and complexity that you want to
capture in the cost function then it's
all gone and good heart's law is this
very interesting idea that when a Target
becomes a measure it ceases to become a
good measure which means many of the
systems we design including current
social networks are divorced of all of
the richness and creativity which exists
in the real world we need to create
systems that capture the creative
generative processes which exist in our
physical and social worlds and with
naive objective optimization it's
impossible in my opinion the reason why
chat GPT is the antithesis of creativity
is it's designed to reduce entropy it's
designed to make things simple whereas a
creative process is about producing new
information so there's a tug OFW with
things like G GPT which are centralized
because we have access to creativity we
have access to serendipitous novelty and
we can put it into GPT but GPT is always
pushing back on us it wants to make
things simple this is model bias in
order to produce a truly creative
process we need to design platforms
which eliminate this centralizing Force
maybe you could call it a
self-organizing worldwide group chat um
it's got this self-organizing component
which I think is interesting to think
about that you know so what's happening
you know usually when you go into a
forum like you go into Reddit or
something like that and you have to
choose which Silo are you going to be
addressing this obviously advantageous
if you want to talk to people who share
your interest because you can choose a
place where the interest is reflected so
go to that particular Forum but the
thing is like that really is limiting
when you think about it because of the
fact that like often as conversations
Meander within something like that you
touch on things that other people in
other form forms would have really found
interesting um you know for example like
if I was had an issue with say the
architecture in San Francisco I mean I
could go talk to the San Francisco
subreddit and like tell people about my
my my problem with it um but then it
starts to touch on General urban
planning let's say well there is an
urban planning subred and none of them
see this conversation they won't be part
of it um they probably would have had
something to say about it might have
been something interesting um that's
where self-organization
self-organization could have kicked in I
mean people could have actually come in
from there and that is what Maven does
like constantly always like every single
thing anybody says is reanalyzed by the
AI to think about what is now who to
whom is this now interesting as a
conversation and then those people are
drawn in so you're having because of
that basically different communities are
getting crossed over constantly in
cross-pollinating um because as the
conversation the ERS new communities are
brought in um and that's what I mean by
self-organizing so it's constantly
organizing around like who should be
interested um and uh and so you don't
have to think about like which Silo do I
belong in you just send it out it gets
sent to people who would find it
interesting and as the conversation
continues it'll just reorganize um
around those people um and by adding
interest you're expanding your kind of
like Serendipity surface Horizons things
that might be interesting to you and the
system works in such a way that like
it's trying to expose things that match
your interest but in doing so it will
also sometimes expose things slightly
adjacent and so your interest will
gradually expand um as you discover oh I
actually am interested you know like I
didn't even think about 3D printing but
now I realize actually that's something
I would like to follow like what's going
on there when people talk about that and
then that comes like part of your part
of your interest set um and so if you
think about it in aggregate like the
system is a giant interest graph that's
growing over time the more people come
in the more we discover new interests
because these aren't things like I said
they're not from a stock list so it's
just growing and growing and this
interest graft lets us understand things
like what interests relate to others you
know because we know people who follow
this interest Al follow that interest or
like we see these interests co-occur a
lot in posts like when people post like
often Ai and ethics occur at the same
time or something like that so we have
this like really interesting graph that
I don't think anywhere else has um
showing how everything is related in in
in an interest graph rather than in a
person graph um which again I think is
Gen arguably more healthy um since it
doesn't have this popularity uh contest
a aspect to it and so the last thing I
just wanted to mention about like how it
works as you're kind of expanding
interest and discovering new things on
the system is one thing that may people
may wonder is but where's the quality
control um you know because like the the
the kind of um Topline billing for
things like likes or follows is quality
control um it has all these other
implications you know it has convergent
aspects like when we have consensus we
get convergence which is an unintended
consequence of legs you know so if like
a million people like something that's
definitely consensus but what happens is
that we have these convergent points
like throughout the day on these very
very high agreement things and that
filters out diversity so we're
counteracting that and that's a good
thing so you get way more diversity is
one effect of a system that's about
following interest rather than um
following influencers but you still may
be wondering so took out this thing
which is the supposed the purported
quality mechanism what is left there
well we we're doing something
interesting which is more subtle which
is worth a little mention which is we're
using something called a minimal
Criterion to understand what is not
actually good content so actually we're
not interested in
maximization um and I speak a lot like
when I speak about like um why greatness
cannot be planned about like what's bad
about maximization and optimization on
everything so we actually got rid of the
idea of optimizing content um but we do
something which is saying there's a
minimal threshold below that we do try
to circulate less if it's below a
minimal threshold and we have different
ways to measure engagement to like sort
of set our minimal threshold but above
that threshold there's no contest
everything is treated evenly and
agnostically um and so you get this kind
of churn of ideas that are all of like
minimal at least minimal interestingness
and it's worth noting that this kind of
idea of a minimal Criterion has been
used in research in the field of
open-endedness and there's also an
interpretation of Natural Evolution
based on minimal Criterion so it's not
just like a totally ad hoc thing and it
does really interesting things like it
leads to a very rapid fast Divergence
and increasing complexity like in
artificial systems um but without
convergent properties and it's extremely
simple and so this is a completely
different kind of quality mechanism but
there is it is in there um and so you
should be one maybe philosophically just
to make it make some sense is that kind
of the philosophy behind a mental
Criterion is that it's really just
pointless after a certain point to argue
about is something better than something
it's like once things hit a good enough
especially in the world of subjectivity
like if you're talking about like movies
or something or even like intelligence
like if you're talking about like is
this guy more intelligent than that guy
at some point just stops mattering like
on an absolute scale it's true like
below a certain point it's like it can
matter a lot you know it's like if if
you're like in like you know the
disability range of IQ or something but
above a certain point um it just gets
ridiculous to like split hairs and like
is that actually better like this person
said this and that person said that
which is the better statement they're
both interesting um then we actually try
to rate them and then you get rich get
your get richer phenomena and all kinds
of artificial aspects start to come into
play which have really nothing to do
with any kind of true objective absolute
sense of quality because there is none
in subjective domains so we can say like
above a certain amount let's not play
that game it's stupid because it leads
to conversion it filters out all the
diversity and let's let diversity rign
when you're within that range where
things are good enough that it's not
degenerating my couple of co-founders um
one of them is Jimmy sron who um some
people might know I worked with him many
years ago on the pick breeder uh project
um Jimmy actually was the lead of that
project and um we've talked for years
about maybe reuniting at some point um
he's had a lot of Industry industry
experience since then he was a VP Brave
recently um and so it was just a good
opportunity um to get back together and
uh work together again um and my other
co-founder is named Bloss moros and he
has some really unique experience
building online communities uh he's
built some communities like uh the
lattice work which some people may have
heard of or um also something called The
Rabbit Hole where people follow um books
and readings together that he's uh he's
been sharing with people
this book changed my life Kenneth this
book changed my life if there were just
a few things you can summarize you know
from this book what would it be so the
book is um a result of AI research and
it's a it's a really strange story
because it's very unusual that AI
research results lead to something that
looks a little bit like social critique
in fact I think I'm unaware of any other
example like that and I certainly wasn't
trying to do something like that that
was my career goal um but the thing is
that we were seeing results that had
really large scale implications outside
of AI um and I mean in hindsight it
starts to make sense to me that like if
if you're really trying to understand
intelligence which is like this one of
the most Salient aspects of Being Human
then you should expect to learn
something about what it means to be
human I mean that that seems to make
some sense in hindsight so that should
be happening at that should be a side
effect of our field like to the extent
we don't do that it might be a sign that
we aren't necessarily digging in the
right places or or learning the things
we should be learning but in any case we
what we found was this really strange
paradoxical uh uh phenomenon which is
that pursuing an objective can actually
get in the way of achieving the
objective but more than that it's also
that it gets in the way of achieving
anything else even outside of the
objective you started with um and this
is something that originated from
observing results from experiment so
this is not um like an opinion um this
is just empirical results that we were
observing and experiments that we did um
some of those experiments had people in
the loop so we had people searching
through spaces finding in in our case
pictures was the original experiment
it's called pick breeder and we saw this
phenomenon of people only finding things
when they're not looking for it um which
is really hard to absorb you can only
find things if you're not looking for
them it's like some kind of Zen
statement or something like that but if
you think about it it starts to make
sense even algorithmically because it
also sounds philosophical but it's
really an algorithmic observation but
algorithmically it makes sense because
there's this this phenomenon of
deception in complex spaces which is
like a well understood I mean sometimes
we use other other words for it we might
call it like getting stuck in a local
Optimum or something like that or
premature convergence but really what
deception means is that it appears that
you're going in the right direction when
you're going in the wrong direction or
vice versa it could appear that you're
going in the wrong direction when you're
going in the right direction and the
thing about is that it's much more
pathological and pervasive than the way
that we usually think about it because
it's not a surprise that that exists in
search spaces but it's so pervasive in
spaces that are complex and that is what
we didn't appreciate I think and that
the book is really keying in on because
you see like in complex spaces that
should be the rule rather than the
exception like by complex I'm just mean
things that are hard like things in the
world that are hard to solve so
something like creating AGI or curing
cancer or creating um infinite renewable
energy or things we might want to do uh
those things the stepping stones that
lead to those things don't look like
those things they are in obvious in
other words like if they were obvious
then we would just do them and they
wouldn't be considered hard problems so
obviously we don't know what the
stepping stones are which means that
when we do find the right Stepping
Stones they will be surprising which
means they won't be things that we would
initially guess are the important things
you need to do to get to those things um
and this was initially observed in these
artificial search spaces like Pi breeder
um but it was clear that this is a
general principle in all complex spaces
um because they will always have this
kind of circuitous property or else
they're not complex it's basically like
a truism and so the the the problem uh
which the implication for the problem we
have in society gradually grew in my
mind over time after this like looking
at the AI results especially from also
talking to people about the results cuz
people often would ask what does it mean
for me because people would say like AI
conferences they'd say I have I have
objectives like is this like applicable
to the way I think about things or this
only about algorithms but of course it's
not only about algorithms because we all
are facing search spaces like that's a
problem that's generally ubiquitous in
life not just in algorithms and because
of that it it started to emerge in my
mind that like this matters to people
this matters to institutions it matters
to governments it matters to education
like there's a objectives everywhere is
completely saturating everything that we
do and if this deceptive principle which
I call the objective Paradox because
it's a paradox that pursuing something
can cause you not to achieve it if it
holds with really tough problems then
like we're all in trouble because like
we're all doing everything by setting
objectives and the more I thought about
it the more this seemed like a serious
social problem um even though it's not
the kind of thing you know that is
currently debated in society like you
don't have like protest going on about
like anti- objective movements or things
like that but that made it even more
seem like this needs to be brought up at
least we can have a conversation maybe I
can't change the way things work in the
world but at least we could have a
conversation um and it seemed important
to to bring it up because nobody doesn't
seem to be on anyone's radar and I mean
just just give one concrete example like
think about like when you apply for
science funding since I know a lot of
people who watch this show probably do
they want to know what your deliverables
are that's your objectives like what are
you going to achieve like we're already
off to a bad start um because that's not
how Innovative systems work Innovative
systems work by collecting stepping
stones and not knowing where you're
going because they're interesting in
their own right because we don't know
which ones will lead to what um and
already the entire science funding
system almost across the world works in
the opposite objective Paradox way um
and so that's a mistake and most
institutions work that way um and so I I
we wrote the book Joel lemman and I um
to try to highlight this and start a
conversation
in a way a goal or a stepping stone is
like knowledge so I kind of think of
your your philosophy as as describing a
kind of epistemic Roadblock so the the
Paradox is that in science we want to
accumulate knowledge and we're shooting
ourselves in the foot because you're
saying well you're only allowed to
operate inside the space of this known
knowledge because the goal presumably
shrouds out any other knowledge that you
don't already know so it's about this
kind of paradox of the unknown unknowns
but I want to bring one other thing in
because some might say that um it's you
know there's in reinforcement learning
there's exploration versus exploitation
and you have a fixed goal but people
might argue well yeah you have a fixed
goal but uh there's this implicit
motivation you know so so the agent can
still learn sub goals and do lots of
kind of weird and wonderful things that
might be somewhat orthogonal to the end
goal and I've always felt that I mean
again this is a thology question the
reason why there is noology in evolution
it's a process that is Divergent it
generates entropy and and complexity all
the time and that is precisely because
there is no um end Tey you have these
independent agents kind of doing things
on their own and not necessarily sharing
information with each other uh yeah so
it's true that um you know exploration
versus exploitation is is is very welln
and well studied I mean it's no surprise
to anybody that we should do some
exploration um but you know there's
there's a couple things about that that
I think fall very short of the the kind
of uh observations the book is making
about like how how What exploration
really should be you know and and one of
them is basically like related to what
you just said that that it's just like
just having this subjective at all in
mind can be just too much uh too much of
a drag on your ability to explore that
it just doesn't all add up I mean and we
should we should note that like of
course and I we can see it in the book
that modest objectives do work so the
book book is not saying no objectives
ever work that's important to concede
here um modest objectives can work and a
lot of the time reinforcement learning
when it works works because it's what I
would call a modest objective so like
you you keep your eye on the ball um and
exploration you can think as a little
bit of distraction moving you around but
you need to have that distraction
because you need to sometimes get off
deceptive paths um and it works that
works out um but the problem is when
like you're looking at something that's
like radically ambitious you know that's
what you know I talk about something uh
like curing cancer like this is like Way
Beyond like where we understand what
will lead to what um then it actually
doesn't make sense anymore uh it becomes
actually like a huge weight on your
ability to explore um and that leads to
you know that that like it's actually
the case that having an objective is
much more powerful than a force for
diversity like sometimes you know what
this this field that the original
experiments that led to the book led to
a field called quality diversity
algorithms and this whole field is sort
of about this idea that quality is is is
is kind of like a a huge powerful force
and diversity is this very delicate
feather and you you try to combine them
together and if you're not careful about
it it's always going to be that quality
crushes diversity diversity is the hard
thing to do and so that leads to kind of
the the second point I want to make
about exploration versus exploitation is
that exploration is actually a very
complicated subject and when we think
about it as just making random moves
that is the most trivializing way to
think about what exploration means ation
is an intelligent process it's not
random I mean of course an algorithm it
might be defined as something random but
real exploration means fall in gradients
of interestingness which is highly
information rich like understanding
what's interesting in the world people
are really good at that like that's one
of the remaining deficits I think for
models today um artificial models
because um understanding interestingness
is extremely difficult problem um but
those gradients you can think of them as
gradients you can follow um that's what
it means to explore it's not taking a
random move in a reinforcement learning
algorithm and so exploration algorithms
like forget about having an objective
like it's its own Topic in its own right
like the way to motivate to to represent
where you want to go what does it mean
to be interesting what is novelty things
like that they'll have to be confronted
in order to understand what it means to
uh explore an informed way and what that
will do then is it will accumulate
things that are interesting and some of
those things will lead to other
interesting things and ually one of
those might turn out to be the stepping
stone that leads to something you care
about or it may turn out to be something
someone else cared about but what you're
doing is collecting stepping stones and
so you're making it more likely
something something important will
happen in the
future yeah and we were talking about
this minimum uh Criterion earlier but I
suppose what we're trying to do is is
create algorithms which are naturally
plausible maybe even biologically
plausible because we see these
fascinating Dynamics in the real world
and we select features of it you know so
it needs to have diversity preservation
it needs to be entropy generating um uh
agents need to follow their own gradient
of interestingness and the almost all of
the algorithms that that you've been
associated with are population method so
this kind of population idea seems
really interesting and I guess like one
one question is how far can we go with
computers right I mean the the reason
why we have an interesting um concept
built into US is because we're
physically and socially embedded so it's
not necessarily that we have knowledge
of what's interesting it's quite
serendipitous but the the I think the
key is that the knowledge is actually
embedded in the system like the reason
why a bird knows how to fly well a bird
doesn't know how to fly the knowledge of
flight is actually encoded into its
physicality and how it's embedded in the
system right so I guess I'm saying like
that's how interesting this work works
in the real world and we want to write
algorithms to do that
artificially mhm yeah I mean I think
that the trick in this is that we really
want these algorithms to do things that
are interesting to us um so it's it's
true like our experience and things that
we find interesting are idiosyncratic in
some way I mean I guess it's it gets
philosophical because as's a question is
there any absolute way of thinking about
what what it means to be interesting um
but it's like if you started a whole new
world and things just evolved inside of
that world independently of this world
uh you know to what extent is that
interesting to us um and that's actually
like an artificial life kind of view um
which I think probably some of it
actually is interesting um but like at
The Cutting Edge like that's hard like
in other words like The Cutting Edge of
what's Cutting Edge for us um so like
The Cutting Edge of Technology of all
aspects of society of art of music of of
uh political organization like all of
that stuff has a cut Edge um and those
things are interesting to us for
idiosyncratic reasons that have to do
with how we developed on this Earth and
our embodiment and all kinds of things
and so like it's just we have to somehow
if we want to incorporate machines into
that Cutting Edge so that they can
explore along with us to push it Forward
um in ways that we would actually care
about then they have to absorb a lot of
the understanding that we have that
comes from our Legacy somehow so that
they can ex draw from that to understand
what's interesting and yeah the problem
is it's non-trivial and information rich
I think is it's not like just like a
couple rules um like it's like your
entire lifetime of experience Bears on
what you find interesting um and so to
endow them with sufficient
representation to capture that is very
challenging and it doesn't just happen
because they absorb all the language on
the Internet is the problem like that
would be convenient um but interesting
this is another matter than just
knowledge um and so it's this is a real
tricky thing uh but we can um we can
imagine this happening I mean I I I can
imagine trying to you know bring them
into the fold of where we are at The
Cutting Edge and helping them to see
what's interesting and they would you
know gather some degree pick up some
degree of of uh Instinct from us um I
just want to point out that there's a
whole completely different way of
thinking about how to get
interestingness which would be which
would be like from first principles kind
of like just starting with single cell
things and just thinking like well would
it just become interesting because I
mean Evolution did that so I guess it's
it's a little bit um it's a little bit
circular because like we're a product of
that process so it's like well that's
why we think it's interesting I mean you
could argue that like well if we weren't
we wouldn't find it as interesting but I
don't totally believe that because like
it seems like to me that it's like not
debatable that what happened on this
planet is interesting no matter where
you come from uh now I mean we could
definitely debate that but like to me
it's just like there is some level at
which like something happened here
that's interesting like it's not clear
to me that like the TV show you like is
interesting in some absolute sense but
just generally the entire process of
evolution on Earth all the way up to
humans is somehow it just seems
intrinsically interesting and I think
the reason is because like there's some
builtin there's some built-in conditions
that uh that that encourage
non-triviality of some sort or
complexity um which is sufficient to be
somewhat interesting at least um from
from the point of view of anybody who's
intelligent I guess you could say and so
that's obviously very debatable and
again a huge side discussion about this
um but I think it's important to still
think about even outside of the
philosophical part of it because we do
want to understand if there are
relatively simple principles that can
help us to get a leg up on this um like
in terms of actually producing
interestingness like generatively
producing it um like that are not that
don't require like knowledge of what it
was like to live your entire life and
every other person who ever lived on the
planet like that's a lot to ask like if
there are some basic fundamentals um
that can sort of scratch at the surface
of interestingness then that can help us
um get our Fe foot in the door and and
start to move forward I really like this
idea that interestingness is just the
knowledge that we don't understand so we
we have these um when I say
anthropocentric I mean we have these
like kind of human perspectives on
things and we think of knowledge is the
kind of stuff you get on Wikipedia But
knowledge is everywhere and and in a
sense I I think of intelligence as being
everywhere intelligence is distributed
far outside the brain I was reading a
book by Max Bennett earlier arguing that
you know language is in the brain well I
don't think language is in the brain
language is is an organism um if
anything language tells us what to do
not the other way around so um yeah it's
just a completely different uh
perspective and and our anthropocentric
priors really kind of guide how we how
we think if that makes sense but but
just just to to close the loop though I
was uh watching a presentation by J Jim
fan from Nvidia and you know he's kind
of got this these three axes where you
have embodiment and you have skill and
you have realities and he's got these
different agents that operate on
different parts in that 3D space and I
just kind of disagree just based on my
last point because I think all of these
things are entangled together like he's
making the point that oh we could have
these foundational agents that could
generate Iz between different forms and
different realities and have different
skills and they're all the same thing
right all of these things are just
embedded in the world I guess a reality
could be an environment and a form could
be I mean I kind of think of those two
as basically being affordances so how
can I interface with the environment but
if you think about it interface I mean
you're great to talk about this because
you did this poet um um paper which was
kind of diversifying doing curriculum
learning across different environments
but but in a sense the environment
affords an interface you can only
interact with it in a certain way so you
can kind of you can kind of think of the
embodiment and the environment as being
the same thing but if you were trying to
argue that intelligence was abstracted
away from physicality that you could
build this General agent that you could
just plump into any world and it would
just automatically be able to do
anything so do you see what I mean
there's this tug of war between I think
intelligence just is the physical and
social world and another school of
thought is now you have these int agents
that just know what to do in any
world I see I see yeah yeah that's um
that's that's that's a a hard question
to think about um like these other
worlds and how they would relate um or
if there is something like truly General
Beyond any world and they could work
successfully in any world that's
conceivable uh yeah I I wouldn't be
confident in that um I mean it it that I
I agree with I think I agree with that
but I but I also not always sure like
when you get down to very specific
points like it has to have a body then I
become less sure of things like that um
like is that really essential in our
world to have a body in order to be an
active participant in the you know
advance of knowledge or something like
I'm not sure that you need a body for
that um you need some exposure to our
world though I'm not saying you wouldn't
have some exposure um and so uh of
course we live in a physical environment
with like vision and sound and things
and that there's some of that's going to
have to get in somehow um in order to to
Really participate in a meaningful way
um and so but I I just don't know
exactly what the you know deserada are
like that you have to have this you have
to have that i' be a little more open to
different variations than you know some
strict like person who's only about
embodiment or something like
that very interesting just before we go
on on to the to the other bits we
discussed um maybe we should just
describe pick breeder in in really
simple terms so this this picture on on
the front of your book came from P
breeder right pick breeder was an
experiment in open-endedness um I was
really interested in systems that are
what what I what I call open-ended and
now this like kind of recognized as as a
subfield in in machine learning
basically open-endedness but open-ended
systems actually I should know um for
historical reasons that the the term
open-endedness where I first encountered
is in artificial life where there was a
subc community there called open-ended
Evolution or o e um and so I I was
really interested in from from that
perspective and um of course evolution
is often cited as like the the the the
most canonical precedent of
open-endedness like it's this process
that for uh more than a billion years
has been you know diverging into more
and more interesting stuff and doesn't
seem to end it's almost Eternal um and
so so it started out with these kind of
open-ended Evolution researchers in
artificial life um but I always thought
that this is a general issue across like
not just artificial life but AI as well
because I think open endedness is also
the the big thing that characterizes
what it means to be human it's it's
interesting because it's what created
humans like Evolution created us so
we're a product of an open-ended system
but I also think we produce
open-endedness and that's like the most
Salient thing about us it's like
Civilization is basically a giant
open-ended system produced on top of
human intelligence so there's like an
open-endedness sandwich with us in the
middle you know we come out of evolution
and then we produce civilization and
both are open-ended on both sides um and
so to understand us and intelligence I
have this intuitive feeling we need to
understand open-ended processes because
AI will have to be one eventually and a
lot of the time that's like the last
thing missing I feel like like AI can do
all these impressive analytic things it
can like solve a test or something to
answer your question brilliantly but
like it doesn't produce things that move
civilization forward um that's like
inventions and ideas and you know like
things that change the way we think and
that just doesn't really happen um and
that's like what it means to be human I
think because if you think about like
what uh what is um how how much what do
you think what is it elicit in you if
you hear that somebody can multiply 10
digigit numbers in their head it's
impressive but I wouldn't say oh the
humanity it's not that kind of thing
where you're just like clutching your
heart like that's just so moving it's
just like that's impressive that's
that's like a computation the humanity
comes out in like when someone invents
something you know it moves you it
changes your life like that's Humanity
um and that's open-endedness and so
I so I think that's what we need to
capture and so and also just as a
practical matter for AI people the thing
the other thing about it that I think is
important is that because it produced us
like we are a product of an open-ended
system we might need to create an
open-ended system to produce another us
um and so that that was really
motivating me a lot with like the pick
breeder um I want to understand how
these things work because I wanted to
understand how brain like things could
evolve artificially um and so I'm
mentioning all this like in detail
because like when you hear what this is
it doesn't sound like a really serious
experiment it's like what we're going to
do is we're going to have people go on
the internet and breed pictures um so we
give them an interface where they could
see a picture and then they could see
several pictures and then they could
choose one and it becomes a parent and
it has children um just like if you're
breeding dogs or breeding horses or
something like that um it could be you
know it could be like sexual or asexual
it doesn't really matter it would it it
could be both but a lot of people would
just do it asexual meaning one one
parent because this isn't a computer so
you could do whatever you want um and so
so people would choose pictures and and
make children and so you hear that
you're like oh that's that's like a toy
like what is the point of all of this
but you see the point of it for me it
wasn't the toy even though I was hoping
people would enjoy it as a toy because
that would get people to use it but was
to see the unfolding Divergent process
of discovery that was really what
interested me I wanted to see a new tree
of life form on the internet a tree of
life like you know the kind of
philogenetic trees you see like with the
Single Cell at the bottom and humans and
some Branch somewhere um I wanted to see
a new one happen um because I wanted to
understand the process it's not the
individual images that I care really
about like there are images they were
pretty impressive like people found
things through random mutation so this
is not like Del or something this is not
like modern generation this is like old
school stuff through random mutation
they would find things like butterflies
and skulls and cars and really
impressive discoveries extreme needles
in a hay stack um but it wasn't the
individual images that interested me I
wanted to understand the process because
I thought if I could see an actual
open-ended process then I could
understand algorithmically how it works
um and this is something we desperately
needed to understand and the problem is
there's not a lot of reference to see
processes like this you know evolution
is a is a reference but we can't see it
because it's buried in the ground like
you need to go digging and and get
fossils out of the ground and I wanted
to see every single little step exactly
what happened in a process like that so
I could totally analyze it and
understand it I just thought something
interesting will happen um and it's you
know it's notable that I didn't know
what would would happen I didn't know
what we would discover um it was totally
unclear which made it very hard to get
to get funding actually um because it's
not they're like what's the point of all
of this but the point was to see the
process um and so we put this out there
and indeed the the the the result was we
we did discover this very shocking
fundamental thing about objectives like
that the people on that site it turned
out when they found these amazing things
like the butterfly or the car uh it was
because they were not looking for them
or to be more clear it's because
everybody along that trajectory was not
looking for it um like the very last
couple steps someone might have been
thinking because they realized they're
getting close you know they might have
been thinking oh I'm getting close to a
car so I'm going to try to optimize this
towards a car but all the other steps
along that trajectory nobody was
thinking about cars um and so the only
way to find things on there is by not
looking for them and for people who were
looking for things which is most people
because that's how we've been trained to
think most of us are acculturated to set
an objective and go towards it by the
time we're adults so most people
actually don't like pick breeder I I
found I think that's true because they
would automatically come in with this
predisposition towards setting an
objective and then it would be
frustrating it' be extremely frustrating
because a deceptive space like any
complex space but it looks like they're
going in the right direction they're not
they hit a dead end they experience this
intuitively so they feel stuck and then
they're just like this this sucks and
then they're like but why did all these
other people succeed in discovering all
this stuff like it doesn't make sense
but it's very frustrating to an
objective person and so I think this is
why a lot of people just leave very
quickly and never come back because it
doesn't work like the way You' expect it
toy to work a quick point but um there's
another amazing book called The Language
game and it basically talks about you
know there's this idea that that what if
culture and language itself was alive it
was a living breathing organism and the
um yeah so it's it's this idea that
essentially we humans have this Proto
ability to um use improvisation to make
sense in the moment and we also have
other Proto abilities like shed
attention even babies will look at
things they'll they'll make sure you're
looking at it so there's an Interactive
Shar detention process and there's a
whole bunch of things that we do that
give rise to this incredible kind of
social complexification that we have and
it's a bit mysterious how it happened in
evolution but the fascinating thing is
that I think the real intelligence of
humans is culture and Society if you
take an individual human and you put
them on mars or put them in a in the
wilderness then that human it's like
going back in time a long long while so
it's almost like our collective
intelligence is the is the culture and
then if you contrast that to something
like GPT so they said well GPT isn't
learning how to play shads it's learning
to find incredibly complex patterns
across billions of words of language
humans in GPT can write short stories
technical manuals and press releases and
do simple tasks with language such as
answering questions but GPT is not
mimicking the human mind it has no mind
at all so there's always this kind of
interesting tug of war between like you
know creating the actual um thing which
has the high resolution Dynamics which
is alive in the same way versus kind of
creating this very simplified version
that appears to be like the thing you
want to create but actually
isn't yeah that's true I mean some way
when you say like the intelligence is
the society and the culture like it's
basically saying it's this collection of
stepping stones are part of the
intelligence of the process you know
because I always speak in terms of
Stepping Stone Collection in open-ended
processes and so like that's what makes
them really powerful is that like the
longer they run the more Stepping Stones
there are it's like the Next Generation
of inventions are going to be more
interesting than the last generation
because there's more inventions to build
on um and so you know it's like back in
the day when there's only like wheels
and fire there's only so many things you
can do but now you've got you know
you've got computers you got the
internet so these are stepping stones
that we can build on top of um and it's
the the whole collection of Stepping
Stones which is all of our culture and
Society is the the potential we have to
do something new um so you could say
that's a store of intelligence it's part
of an intelligence system I mean I think
it makes it certainly means that any
individual is empowered more uh to do
more to do more interesting things um so
that yeah that's one way to think about
it I mean just just a final point on
that I I think though the the real gap
between us and machines is this
creativity and I think also autonomy is
is part of that so the reason why we
have built this incredible culture this
infosphere with all of these Stepping
Stones is is because every time you and
I or any people have interactions they
um creatively do things just to just to
understand each other just to just to um
make sense in the moment you use this
Ingenuity of creativity and then that
just gets recursively rinsed and
repeated and reapplied and all of these
things just bubble up into our culture
and um there's just nothing like that in
in AI systems I mean obviously the
closest we have gotten to that is all of
the work that that you've done but I
think the autonomy Gap and the
creativity Gap that's that's The Elixir
that we don't yet
have yeah that that is actually
interesting because I i' I've often said
that um you know one of the keys to
getting open-ended systems to work is
that you you don't just want to have
more solutions you want more
opportunities or more problems is one
way to think about it but they're not
necessarily problems they're
opportunities to do something new um and
so that's like where create that's what
allows you to have creativity like you
can't have Shakespeare if you don't have
an audience like to actually listen to
it it um and you can't have giraffes if
you don't have trees what's interesting
is that we are both like as as organisms
in this world both opportunities and
agents in the world we're creating
opportunities for other people to do
things just by existing and that what
you said just made me realize that like
it's the creative opportunity that like
every single interaction provides um
which is causing things to move forward
it's like me talking to you right now
like you're presenting an opportunity to
me and it's a creative opportunity like
the way I'm addressing this conversation
is actually creative because I'm trying
to figure out like what is actually
something that I can create here with
you and also for the audience um that's
like not existing in the world yet like
that's why I'm having the convers like
I've already existed in the world there
be no point to have the conversation um
and it's kind of interesting that like
everything is a creative act almost
everything is a creative act in that
sense like everything you confront
confront you with a new opportunity to
do something creatively and that is that
is really interesting how it Stark
different from the perspective of like
GPT or something like it doesn't look at
it wouldn't see things that way at all
which is really bizarre you know because
I I think a lot of us do see like each
each interaction that we have as a new
creative opportunity although no one
would probably articulate that way it
just occurred to me now even to think of
it like that um but that's just like
very deep in human nature that like you
want something new to come out of this
not the same thing you just did
yesterday um and that's just not
intrinsic at all uh in the AI is not
trying to do that so yeah it's not going
to be a participant in the advance of
things of society of culture and
civilization just not going to be a
participant yet um until we address that
yeah although final point on that I
think the autonomy Gap is quite
interesting because people
anthropomorphize AI they think of it as
an agent or it could be an agent if only
you gave it autonomy even though they
don't have agency so they do silly
things when you give them autonomy but
um you know at the end of the day
people confuse combinatorial creativity
with inventive
creativity and and also people confuse
where the locus of the agency is so it's
more like a paintbrush if I use a
language model I'm giving it the entropy
so I'm entropy smuggling from my
physical and social world and people
kind of get confused and they think oh
the language model is is giving you the
entropy no the entropy came from you it
might be surprising what it what it gave
you so yeah you know it's still
interesting in in the sense that are
tools which have become established in
in in our kind of ecosystem but they're
not agents and they don't they don't do
things on their own yeah yeah yeah I
agree that they they have what you might
call combinatorial creativity like they
can combine two things and sometimes
it's it's really entertaining like when
they do that um often though the things
that they combine are because you ask
them to combine them so it's actually
the real creative seed was from you but
then they do a good job with it so
that's actually entertaining um but they
can sometimes come up with their own
combinations like it does happen
um and but I also agree that that's not
transformational type of creativity that
this is like a a lower grade of
creativity but like even beyond that I
think the real problem is they don't
really understand what's interesting um
like regardless what kind of creativity
we're we're identifying like I think
this relates to things that Bowden said
about creativity um but like the
regardless of even that like it's just
they don't really understand what's
interesting so they can come up with
arbitrary combinations but it's not
because they really have an intuitive
sense of this is going to be interesting
to somebody like often there are things
that already were combined by somebody
else or otherwise are just like totally
arbitrary and are only interesting
because an AI did it but not really
interesting in their own it's not like
something you would ever be like oh that
was great that you came up with this
bizarre combination of ideas um you know
like like I had uh like for example yeah
I mean one thing I had fun doing with
GPT was like having it come up with
ideas from movies um it's just kind of
funny you know and they can be quite
entertaining like to hear these ideas so
so you know it came up with this idea or
I was asked at one point to come up with
sequels so it came up with um a a sequel
to The Wizard of Oz um where um she
comes back and The Wizard is a drug
addict and she has to help him recover
um from his addiction um and that's like
a it's just like an arbitrary
combination of ideas like it's like it's
actually really funny because it came up
with it but I don't think that's
actually a really interesting idea um
it's like doesn't make any sense it
doesn't really follow from like the
ethos of like this kind of like Wizard
of Oz like fiction that like he would
turn into a drug addict and that would
be like the next book um but that's what
it comes up with so so it's like that
kind of commor creativity it can do but
it's not yeah it just doesn't have a
sense of true interestingness in novelty
and I think that's deep deep in in in
like a deep challenge uh for us right
now is to overcome that um if we if we
wanted to get to AGI because that that's
really like the the star of human nature
yes I mean this is so interesting I will
ask you other question in a second but
this is this is such a fascinating topic
I mean um I think of creativity as
something novel which makes sense the
early versions of information retrieval
were kind of content filtering and then
it became more collaborative filtering
and the kind of the the bright line I
think between those two worlds is one is
is a social concept so I mean for for me
creativity is about the instantiation of
a durable social concept which means
it's recognized that the relevancy is is
kind of like social proof
right so um everyone thinks it's a good
idea so it stays and you get these weird
phenomena where you know things go viral
only because of the social proof so it's
got nothing whatsoever to do with the
content of the thing it's just because
everyone else thinks so so yeah like
maybe creativity is is purely just a
kind of social ranking function and
nothing whatsoever to do with the
entropy or the the embeddedness I don't
totally agree with that because I I
don't like consensus like in in
creativity um like I think consensus is
is anti- creative in some ways so like
if everybody agrees something is really
cool that's consensus um and so those
things matter like things that we all
agree on like those can be actually um
valuable creative products so there's no
doubt about that but the problem is that
the the process requires some things
that not everybody agrees on to actually
get to see the light of day also because
those are Stepping Stones to things that
everybody agrees on you know I mean it's
often the case that like some major
breakthrough came from somebody who did
something that nobody agreed on um so we
need room for things that we don't agree
on also which is why we need a diversity
of interestingness detectors like we
don't want just one um and this is like
yeah this is why this is such a hard
problem there's not a universal sense of
interestingness that we could actually
formulate I think it's it's like a set
that's why I like population based like
you mentioned I like population based
things like I I I'm I'm suspicious of
everything being Point put into one
single convergent system um even though
that that gets into really interesting
questions about whether there could be
such like M like a super brain that just
encompasses everything that Civilization
does in one mind um but I think even if
it could theoretically exist it would be
incredibly complex to actually construct
compared to a population where there are
actually like walls between different
parts of it like that makes it a lot
easier to have this bubbling up without
consensus um and so it's not that no one
should care you know that's not like
it's not like the most interesting
things are things no one cares about
it's that there should there are
different niches of expertise like and
different niches of uh you know of
aesthetic uh preference and like they're
all somehow good to have around because
they flow into each other and then build
on each other and intersect with each
other over
time could could I just touch I agree
with you that so collaborative filtering
the way it's implemented it's basically
um convergent you know it it has a
consensus mechanism but but then we were
talking about whether it's about the
content or the social validation and it
might it might sounded like I was saying
oh it's completely arbitrary if it's
social validation but let's look at
cariz so like you know the the
independent um morphological evolution
of crab-like forms well the reason why
they independently converged in
different places in the philogyny is
because they were just so physically
well attuned and there could be a
similar thing with um social validation
that it could just be so finally
socially attuned that that's the reason
why these diverse clouds of memes exist
and then maybe they kind of converge
together later on but it still sort of
maintains that diversity preservation
that that you that you think is so
important and I agree yeah that that
could be I mean the the the
independent discovery of similar motifs
um like Crustaceans um is yeah it's it
is there's an interpretation of that
where it's because uh it's because yeah
there's it's a generally well adapted
thing and but I actually CU I I usually
don't like think about Evol in terms of
adaptation so that that's why I struggle
with that because I I understand the the
adaptation Arguments for evolution but I
feel like a lot of the adaptation
explanations or the explanations for the
less interesting parts of it like I'm
always interested in the Divergent
aspect of evolution I want to know why
does it diverge and so if you only go
with adaptive explanations you're
actually sort of like asking for
convergence because it's like those are
the things that work whatever that means
so like that's where we should go so
it's we should all converge to
crustations eventually because it's such
a well- adapted form um and I think that
like actually maybe another explanation
of why you see all of those things like
lots of different realizations of a
similar theme it's just cuz it's easy to
make it that could be it's it's actually
an a priori like property of the search
space that making stuff like that is
just easy it follows from a lot of
different paths so you'll just hit on it
again and again because what we're doing
is just Illuminating everything that's
possible over time um and so we'll just
see these things and some things are
just more likely than others because
representationally in DNA they just
happen to be
taking up more of the space not
necessarily because they're better or
something in that way um you know
because it's like what is is a
crustation better than a than a single
cell like I there's no really relative
comparison there they're both successful
in their own right um it's not an
absolute competition over like the
entire
world so Kenne you just created this
Serendipity social network um you know
why why did you do it setting objectives
can actually be bad for creative
achievement Innovation or even achieving
the objective itself that you wanted to
achieve um it can get in the way because
it closes your mind to all the other
things that could lead in different
directions that would actually be
opportunistic for you in other words you
can be deceptive to set an objective and
and we we did a lot of research in AI
that showed this um algorithmically but
then we wrote this book for General
audiences not AI audiences although it
was meant to be also interesting to AI
audiences but we hoping other people
could appreciate it because we started
to believe Joe Layman and I my co-author
um who worked on me with on novel search
we started to believe that the lessons
there aren't just algorithmic but are
actually social like in other words they
apply to the way we run institutions the
way that people run their individual
lives the way we run Educational Systems
the way we run businesses and investment
like everything because everything in
this world is saturated in objectives
including by the way social networks are
extremely objectively driven like
they're based on maximization principles
you maximize likes or you maximize
follows you try to maximize exposure by
maximizing attention and then you get
more and it's reinforced it's very
objective and so it reflects a
widespread ubiquitous culture which is
like worldwide which is really
interesting um which is just like we all
believe in this Idol of of objectives
that it should guide everything that you
do and the book is arguing that there
are other incentives and or other uh
gradients that you should follow like
especially interested
like not knowing where you're going to
end up but knowing that this path looks
really interesting for independent
reasons because it opens up a whole new
playground of possibilities even though
I don't know what the payoff will be um
that that is very important to the
advance of civilization but it is not
recognized in the way that we
institutionalize everything that we do
and so like the algorithmic Insight led
to this like kind of social critique
View and that is why we wrote this book
because we wanted to we thought this is
like a big problem like he's granting
funding agencies run on objectives like
that's probably the most Salient thing
for us cuz we were like researchers so
it's like when we have to ask for money
to do research we would have to ask we
would have to tell them what is our
objective and we' be evaluated based on
the objective whether it's worth worth
funding the research which is completely
backwards if what I'm saying is actually
true which I'm very confident that it's
true and so I wanted to convey that
confidence to the World by writing it
down and putting all the arguments in a
book so everybody could see this and
then it applies to all kinds of things
is not science funding it's like
investing it's the way that we run the
the country the way we run education
everything I said so we wrote this book
and so this the beginning of the story
is we wrote this book and the book is
old now it's like eight and a half years
old but around when it was about 7 years
old um that's around where this this
this idea started swirling in my head of
like that we I should do this kind of uh
new kind of n social network how did
that lead to that well the thing was
that over the course of these seven
years before I started feeling like I
should do this I was the the thing that
the book did which might be an
unintended consequence was it created a
situation where I became the worldwide
focal point for people who don't like
the fact that everything in the world is
objectively driven it's like I was the
the place you go to complain about the
system um and everybody thinks they're
in the system I mean I shouldn't say
everybody of course there's some people
who just like are invested in objectives
but actually you'd be surprised how few
that is like I thought at first the book
would be very polarizing and that
there'd be like these two sides and it'
be super controversial but I rarely meet
someone who really is willing to stick
up for objectives that's that's actually
quite unusual so it's actually like the
book seems to be a relatively popular
message that most people agree with but
it's very paradoxical because of the
fact that a lot of the people who I talk
to are people who are literally
perpetuating this objective system and
they actually hate it you know and so I
started to realize this like but but the
reason that they perpetuate the system
is because everybody feels like they're
locked into it because of the next level
up you know so you could talk to some
somebody who's running like some you
know sort of like billion doll like
Government Federal lab or something and
they they allocate money very
objectively like to projects but but if
I talk to that person they're like I
hate the way this whole system works
like we would love to change things like
the way that your book describes but we
answer to Congress or we answer to an
executive are we answer to like our
investors or it depends what
organization is but everybody feels like
they answer to someone and that someone
they answer to Is objectively oriented
and so there's no way to just do
something radical and just like Tamp
down uh Tamp down those objectives um
and so of course um you know you what
I'm talking about is just tamping down
I'm not talking about eliminating
objectives from the face of the Earth we
can still we can we can we can split the
difference to some extent it's we need
to move the pendulum a little bit in the
other direction is all I'm saying so
it's just not like I'm saying get rid of
all objectives that that would be a
kooky thing to say um but like even
moving the pendulum seems be very hard
and so I got to meet people at all the
levels like at the top levels and the
bottom levels everybody affected by this
system and they all hate it they're all
sick of it and even in like their
personal life like they don't they feel
like they they can't actually just do
things because they want to just do them
because they're fun or explore like they
have to justify everything they do this
is particularly true of adults you go
the far the younger you go the less this
is true which is one of the sad things
like if you're 5 years old this is not
true you just go to the playground and
you do whatever you want you don't care
what it's going to do for payoff um but
this is basically sucked out of us over
the course of of our education because
the education system is extremely
objective um and so you know I I met
people at all levels you know I met
people from like I would meet diverse
walks of life and also diverse age
groups um like I would meet people like
artists and doctors and retirement
planners and Military planners like I
met such a diversity of people but I met
everything you know from like the most
senior person to like a 14-year-old high
school student um and like the
14-year-old actually I met because his
grandmother found me from hearing some
of my stuff and
and and and ask me if I would come talk
to her kid because he's too obsessed
with objectives or to her
grandson um and that was just like
really surprising you know like each one
of these things is like a revelation for
me as an exper because it's like you
wouldn't expect an AI researcher to have
experiences like this it's like a
therapy session I mean the these people
came into my office and we had therapy
basically I I you know I basically
snapped them out of the objective
fixation um and it was really
interesting to me too to to experience
that like to see like what it does to
somebody because you're really changing
someone's life in 30 minutes um and
that's really fundamentally interesting
and so After experiencing these kinds of
things over years like seven years of
this you can imagine this is like
messing with my head in a way which is
different than like AI research it's
like a parallel life I was living um I
was seeing that like you know there's a
huge demand for a more serendipitous
world because like what we're really
talking about here is Serendipity um you
know because when you talk about good
things happening that aren't planned
because you don't have the objective
when you get to
that's like the definition of
serendipities unplanned greatness
basically which is you know it's not a
surprised the book is called why
greatness cannot be planned um and so
like I think what people really wanted
was more opportunity for Serendipity you
know a lot of people argue that
Serendipity Is Random so for a lot of
people that be a non-starter from a
business perspective because you can't
package Randomness like sell it to
people but the thing is that um I
believe because of my all my research
and all the things I've been doing to me
Serendipity is not random like that's a
very important thing Serendipity is is
something that that is that can be
increased in probability by increasing
the number of stepping stones that you
collect in your life or the number of
stepping stones that we collect as a
society this jumping off points that are
interesting the more you have at your
disposal that you've been exposed to the
more places you can get which means
you're more likely to experience
Serendipity that's why some people seem
so much more luckier than others it's
not just an accident like they've put
themselves out there collected more
Stepping Stones they've basically
increased their serend surface so that
there more likely something chance will
happen that's interesting um and this is
why by the way like if you go to
Wikipedia and you look at like the
Serendipity Wikipedia page your
serendipitous invention page there's a
book on uh sorry there's a page on this
like Serendip invention it has like a
whole list of like inventions from
people that were serendipitous you know
like the microwave you know was invented
because somebody like walked by like a
radar device and it like melted a candy
bar in his pocket and and and what's
really interesting about it is that that
if it was true that sendy was random
those would all be just totally random
people but they're all really smart
really accomplished people like across
the board like that doesn't make any
sense if this is a random process smart
people have more of an opportunity to be
exposed to something um and by smart you
know I don't mean conventional smart I
just mean people who actually do things
that are interesting um which isn't
necessarily conventional IQ or something
like that um those people have just more
chance more chance um and so Serendipity
is not random and so coming from that
perspective I started thinking we should
be able to do something about this like
everybody is so unhappy with the way
that the world Works um you know from my
experience over years and I'm like well
wait a second you know for a while I was
thinking well this this is all a
reaction to social critique but it's not
because it's a reaction to algorithms
because the book is not a philosophical
book the book was based in concrete
algorithms and empirical results which
had nothing to do with philosophy like
they were just things that I was
exploring for algorithmic purposes
they're totally concrete things that
were actually implemented and led to
these conclusions and so when I started
thinking about this um like a like like
a year and a half ago when the book was
seven years old I started to feel like
it because it comes from algorithms it
should be able to to swing this back to
algorithms like there should be a
systematic way to construct a world that
works the way it should work because
everybody's so unhappy with the way the
world works and so I was starting trying
to think like what could that Poss what
does that even mean but then it was the
first thing I thought was well it's
going to be it's going to be on the
internet because I can't algorith matize
uh like the world itself so something
has to be different about the internet
like the internet can work in a
different way so now I was like oh is
this a network it's some kind of new new
kind of a network which exposes people
to Stepping Stones in this more
open-ended way which is like inspired by
open-ended algorithms it's inspired by
things like a novelty Searcher minimal
Criterion types of algorithms um poet
like it's inspired by these kind of
insights we've had over the the years um
and um and then it could be wrapped
around people through a network um to
make the world work that way so then I
thought oh that's a Serendipity Network
that's like a cool idea a Serendipity
Network it's like a a thing you could
imagine but then the next thing I
realized which is is that well obviously
like within a second I realized that's a
new kind of social network because as
soon as you connect people in a network
and it's information moving back and
forth among people like that that's
basically a a social network so a CD
network is a social network um but
what's so fascinating about it at least
to me at the time is that the trajectory
of thought that leads to this has
absolutely nothing to do with social
networks up to that point it's a totally
independent trajectory of thinking like
social networks has this whole history
of decades now of thinking about
mechanisms and stuff to increase
engagement and blah blah blah and that's
why we have likes and follows and it's
super objective it reflects the the
overriding prevailing objective culture
we live in it's like just that start
started to seem really interesting to me
that this is just another angle of the
same culture that we're seeing that we
all accept and assume as normal because
it's been beaten into us that everything
has to be objective that just seems
natural but it doesn't have to be that
way um and so I I started to think the
serip network is a Counterpoint that's
like really interesting sorry see see
you have something in your mind people
presumably see this differently so some
people have come up to you saying I
really hate the way societ is run and
you giving the example of creatives and
artists and
a lot of that is because it's it's not
possible to quantify what they're doing
but I I I like the lens of agency so
what you're basically saying is um you
want to live in a high agency society
and that's because the more agency you
have the more Serendipity you have the
more Stepping Stones you collect and
then it becomes a political thing right
so people on the left they don't think
we have any agency and people on the
right they they want a high agency
Society the reason they don't want a
government is because what does a
government do it erod your agency it's
kind of like a agency eroding well I you
know it's that's that is an interesting
point that that I have not I've rarely
addressed the connection of any of this
to politics it has come up in some rare
occasions actually but very rarely like
it's come up because there are specific
cases that have happened where somebody
very political did come to me uh excited
because they thought the book Justified
their point of view um and in some cases
it was people who I totally disagree
with their political point of view but
it was really interesting to me that
that they they they saw the book as sort
of empowering to them um and I've seen
that on both sides um and so rarely have
I discussed this though um and I want to
point out though that like it it is the
book is very apolitical because of the
fact that I see this on both sides but
if you really dig into this you know I
think what you just did by by by putting
agency as sort of like the the the
abstraction of what I'm saying you you
succeeded in couching this in a way that
that that would NE potentially bias
people one way or another politically so
you've basically just pushed it to the
right um but I don't think that that's
what people usually do um that's your
interpretation of it not not not to the
right necessarily I think it's more of a
um the the words Authority and
paternalist paternalism and autocracy so
in a in a company we run companies in a
very autocratic paternalistic way we
have you know like big corporations have
um lots of Ethics boards and you know
policy boards and the and I think the
justification is it's about control and
alignment and even with Facebook for
example that there's there's power
seeking Behavior and the way you gain
power is well the way you subjugate
people is by taking away their agency to
give you more
agency but you see this on the left and
right there so on on the left you you
you you get kind of like you know um you
might be um like Chomsky and a Naros
syndicalist and and you want a diffusion
of agency or you might be like ma or
Stalin or whatever and and want to have
like you know you don't want anyone to
have any agency so I think you see it on
both
sides yeah that that's that's right yeah
I think you see you see agency
deprivation on both sides um and so like
you can inter you can interpret you know
the book with respect to agency as sort
of an argument against whatever side you
want I think um you know because like
it's true that you know like I I've I've
heard this more right leaning argument
like like in that that sort of like the
book seems to enable um that like
there's a lot of like belief and top-
down planning that like is like sort of
leftist kind of belief that like you
just have the government plan everything
and that this book sort of like
disabuses all of that this is really
great but on the other hand like from
from the left side like you have this
idea that like exploration is extremely
important in life you know and you think
about like things like youthful
exploration and it involves like doing
things that you actually want to do um
which could involve things like doing
drugs it could could involve things like
having partners in different forms that
aren't necessarily socially sanctioned
in in the way that people on the right
necessarily want them to be um and so
you feel this kind of like also attempt
to kind of like control autonomy coming
from the other side um and so you know
and it's true like if you go to either
extreme like obviously like you have
dictatorships on the left or the right
or autocracy and then then you get a lot
of control in a lot of different ways
but it's a different kinds of control
because there's different different
kinds of political inclinations there um
that I think I want I would like this
book and this point to be totally
apolitical because I don't think it has
to do with any particular political
movement um I think all of us can agree
on this which is rare that we all want
to be able to explore things that are
interesting um and it's true we have to
put limitations on that that is true
that that's what Society needs to do and
I think every side would agree some
limitations are necessary somewhere but
we can we can disagree on what those
limitations are and that's left ver
right but the general point that we want
to maximize our autonomy and ability to
explore is still important I think and
we can then go on to interpret it
politically in terms of what those
restrictions should
be yes yeah and I wrote an article
recently and I was talking about the
strange bed fellows um in in in the free
energy principle but that was just that
you get people on the right who uh I
don't know they believe in crypto and
decentralization and and so on and and
you would actually think that the people
are arguing for you know agency
maximization but the interesting thing
though is that when you look at the
behavioral complexity of the sphere of
the left and the right all of the
complexity is actually on the left the
left has this tendency to infinitely
fractionate and kind of produce entropy
and there's a famous saying that the
left eats itself and that that's kind of
like you know almost saying that that
they're spending more time infinitely
kind of um slicing and dicing them up
and creating complexity whereas the
right is is very um monolithic
homogeneous
yeah okay yeah I mean I could see that I
mean you know like the concept of a
social experiment like you know the the
left sometimes wants to do social
experiments this is actually exploration
it might be interesting actually might
be bad but it could be interesting um
and and the the the disagreements come
with this idea of where to put the
constraints you know because I think we
should all agree I mean algorithmically
I totally agree that open-ended systems
need to be constrained like there's some
things you can't actually invest in
they're too dangerous to invest in so we
just won't go there um and you know even
Evolution has that like that's why some
millages stop they basically have run
into the constraints of the of the
physical world um and so it's a question
of what the constraint should be is
really the the political debate um I
mean obviously in in the open goes
beyond politics because if you're
building an algorithm it's generally not
a political issue well it's becoming one
because AI is becoming political um but
a lot of the time you just wanted the
algorithm to do what you wanted to do
and it has nothing to do with politics
but these issues still come up if it's
going to be open-ended it's going to
explore if it's going to be creative and
it's a creative algorithm then you're
going to deal with what the Restriction
should be it's just not really political
in that case it has something it's is
more of an algorithmic question but
constraints just come up and and we
really fight with each other a lot about
them um but I've been I've been
extremely happy that the book has
remained effectively apolitical um
because it allows it to make a general
point that doesn't just get everybody
that we don't immediately form sides on
like I that's something I really would
like to avoid because it hasn't done
that yet um like we you tend to like C
form camps immediately around every
issue you know you don't you can't it
happens like lightning fast it's like Co
happens like everybody's on one side or
another it's like instantly like we're
all mad about one thing but like here
like it hasn't happened and I feel very
happy about that because it's a social
point that we could actually rally
around here matter what side we're on in
politics because not really a political
point you know deep in your call deep in
your core why did you do this thing uh
well I I think so yeah deep in in my
core uh the the the the well there's a
number of things um it's even though it
looks on the face of it like this is not
a natural thing for me to do well like I
remember somebody when I first tweeted
about Maven like somebody said wow I
never would have expected him to do that
um and I can see that if I simulate what
people would think I would do but the
thing is that it actually really follows
very naturally from who I am because
I've always been interested in these
kinds of Divergent systems and like the
ultimate Divergence system is the world
itself and the people in it it's the
people in it who do the surprising
things who invent the things is to
facilitate that in the real world is
like the sort of ultimate extreme of
like investigating open-ended systems
even though it isn't just pure AI
because obviously if there's people in
it then the ey is coming from the people
and the system so it's not it's not only
people there's a system too that's like
connecting those people in an
intelligent way which is drawing from
insights and AI but it's not just pure
AI research but for me it's basically an
extension to the extreme of like let's
do the ultimate open-ended experiment
you could possibly do today um and so in
that sense it's like really invigorating
for me like experimentally but also the
thing that really appealed to me which
is deep I think is deep in my core is
that I was um like everybody I was
starting to feel the um the the the
social implications of AI more strongly
um like in the last couple years um and
like as somebody who's been around a
little longer um like for a couple
decades in this field I um I I was used
to not that not being part of it you
know like so so it might be more
shocking for me like someone growing up
in AI today might might be less shocked
and this is kind of like the way the
field is but for me it was a it was more
like just like a playground where people
were friendly and doing intellectual
stuff like it wasn't like this
polarizing political issue like where's
AI going to go so when that started to
hit you know around the the time of GPT
and then Jet chat GPT just exacerbates
it the large language models and and
then the image jenders too and like a
very strong political ideology start to
grow up around it um and concerns and
worries about things like ethics and
safety and so forth it was complicated
you know to to square that with the way
i' thought about it before and it made
me feel uneasy I would say um because
suddenly things that had just been
really for fun became like really
serious in my mind um and I I hadn't
really grappled through like what
exactly I think because it's hard to
really conclude on some of these things
like what should we do it's very complex
so like unlike a lot of people who seem
to immediately take like certitude style
of views I I just like take a long time
to decide what I think um on complicated
topics like this so I was like not
really in a camp exactly but just really
trying to understand um and I just felt
like I would just like to do something
something that's just like clearly
socially virtuous like that isn't
ambiguous in this way for a little while
uh well I don't really know what's right
or wrong um and it just seemed like that
like doing something to make you know
humans and the way that they interact
with each other more human is just like
an obvious virtuous thing to do for the
world it might not work I mean I I I
admit that like I could be wrong about
how this going to work could it could
fail it could even like succeed in a bad
way where it's actually unintended
consequences overwhelm it but at least
what I'm trying to achieve to do
something to facilitate uh communication
that's different that's serendipitous
rather than popularity and attention
driven I feel very confident that that's
a good thing it's a good thing to be
involved in and it uses Ai and it's
open-ended it's still using the things
that I think about and so it just seemed
like such a good fit for the moment like
to actually like take Ai and just do
something that's nice and um and then it
just puts all the things together that I
care about and the only downside to it
is that it's ridiculously ambitious and
likely to fail but other than that it's
a really really good thing to try quick
point on that because a way of reframing
what you're what you're saying is that
living in a agency amplifying Society
where people can do what they want to do
without being stuck in the orbit of
other people and that will have the
effect as you were saying of increasing
the behavioral complexity and diversity
of knowledge and diversity of everything
diversity of stepping stones in our
society you're making the the kind of
the statement that that is a virtuous
thing to do like that that is what we
want but in simple terms why is that a
good thing yeah right thanks for asking
that um yeah I want to be more clear
about that you know because just
increasing like Serendipity surface is a
kind of an abstract concept um it's I I
think it's cool and and there's probably
some people listening who think it's
cool to think about like a more
open-ended type of network or something
like that where you more Discovery more
diversity more Divergence of thought but
like why is that virtuous is the
question and when it comes to being
virtuous it's because it's a
Counterpoint to all the other stuff
that's going on on the internet and
social media um and like all that it's
sort of um a coincidence that wasn't
what was motivating me um like when I
like thought about this at first you
know it's more the the kind of like oh
why greatness cannot be planned and
stuff like that but but like once the
idea came into my head it was obvious
that is a Counterpoint to a lot of stuff
that is not virtuous right now um and
it's because of what is social media
doing to us in our heads and doing to
our society has become um like a
rallying cry like again across left and
right like everybody sees that there are
problems here they may disagree on the
problem some extent but we all recognize
some of these problems universally um
which are just bad for us like and they
span uh like a really wide range from
like just mundane things like the fact
that you just spent hours of your day
addicted to something when you could
have been doing something else to like
much more dangerous things like
disruption of democratic processes and
things like that um and and you've got
things like clickbait and you've got
things like flame Wars and you've got
misinformation and you've got lots of
things but toxicity that like make you
feel similar to to me it's like after if
you just like couldn't stop eating a big
chocolate cake and just ate the whole
thing in one sitting it it's just like
you you feel a little sick after you
consume that feed like the Doom
scrolling um and we we all recognize it
and describe it in different ways you
know it's not the same for all of us the
way we see the problem but I think we
all know that there's some kind of
problem here and I think I've come to
conclude that the reason there is this
problem is that it is the unintended
consequences of the deceptive objective
like we think that having an the
objective of maximizing likes and
maximizing follows is a a steady path to
the ultimate best thing that you should
be exposed to
like that's the search process is we're
going to get consensus and we're going
to show you the thing that's the most
important of the day and that that is
actually that is actually a coherent
thing to be doing that that gradient
actually makes sense but it's a complex
system and this is deceptive and so we
we are seeing all of this stuff that
makes us feel pathological is because
actually that objective does not make
any sense it is a deceptive objective
like all other deceptive objectives and
what I could do is help us to uh Escape
that and have a different alternative
way for the world to work one reading is
it's just the wrong objective it's a
deceptive objective so we're trying to
create a a system which is a high
fidelity representation of how the world
works but Facebook have got this
deceptive objective that just brings out
all the worse than us and you know I
think I think we intuitively know that
it makes us unhappy but is it because of
the erosion of agency is it because of
the particular deceptive objective I
mean I guess there's a thought
experiment where what if it was a
different objective which was more
closely aligned to how humans worked so
is it the lack of agency or is it that
particular deceptive objective which is
causing the harm well it's it's a really
complicated topic obviously because the
the implications of the objective are
are really multifaceted so it's not like
there's just like one thing that this
this relates to um it's
multi-dimensional and so um there there
are some good things about it you know
like I I it's not like all ubiquitous
bad news like there's some good things
about social media in fact like I would
not Advocate a world where everybody
just shifted over to Maven and just
dropped all the other social media like
I don't I don't think that's good either
because it accomplishes some things that
actually are good like for example like
I think it's useful for getting
announcements out um like if you want to
reach an audience and you have an
important thing to say and it's the
people who care about the things you say
then this is very convenient that you
have this megaphone which is provided by
the these systems that maximize follows
and attention and things like that um
but it doesn't work for most people you
know because it's very tiny tiny Elite
minority who have the megaphone like
those are the people who've attracted
all the attention and then the perverse
incentive of it is that getting
attention requires you to do things that
I think like relates to what you're
saying reduces agency you know because
like if you were really just being
yourself you wouldn't do those things
you you wouldn't do those things in
public even like you're doing things
that are actually embarrassing um and
people are doing it every day because
your agency is reduced because you're
responding strongly to these powerful
incentives these incentives are like
surprisingly powerful like I don't think
anybody would have known including the
founders of these Services how how
powerful just a like is on the human
psyche but it's like it's a truly like
you know hardcore drug um and it can get
you to do crazy things um and so like I
you know at first I think they might
have sincerely thought this will
actually lead to better content like
that's like the key here we need a
differentiator to know what's good and
this is so easy like you just have
someone press a button and then we can
like get consensus and it's just it's
not like this is some like maniacal plan
to control the world um but like it has
it it turns out it's like a really
powerful drug and it's reducing agency
you know so like it's from everything
from the fact that like you know you've
got people you respect who are just like
dribling with clickbait um which is
embarrassing at some level because they
they're just responding to the fact
that's what they need to do to get a
megaphone um to things that I think are
like more on the humorous level which is
that like something I didn't realiz is
that like the truly Pinnacle achievement
in the world for like the the like the
most the most accomplished person you
could ever imagine would be to just have
one little quote in one of those books
of like famous sayings like that's what
people really want they just want to be
like you know when you hear a quote of
George Washington or something they just
want their name as beside that with
their little py quote and you see these
these like wannabe sages every day with
their Pearls of Wisdom like dling out
onto the Internet it's somehow like even
though they're like like the most famous
people in the world they have like a
Nobel Prize but they just got to keep
letting you know like I've got really
interesting things to say that is not
normal behavior like this is all
responding to like this really deceptive
this really deceptive objective um and
in some ways a little embarrassing
because to me it diminishes the
greatness in some way to see people
acting like that like I would think
they're like above it in a way like
these are these are the great role
models of our time um and and they're
acting in this way because it shows
we're all just human um or at least I
would have thought they were and so I I
think you know like all of this is is a
reduction and then another thing that
reduces our agency is this like the
mundane fact that I would like to pursue
things I'm curious about but I don't
feel like I can that's clearly a lack of
agency like when I tweet or something
you know I have enough followers that it
could be useful to tweet something
because I can reach a number of people
um and so but I because of that I feel
like I can't tweet certain things um
because I know what their expectations
are it's like I'm a brand that's why
everybody talks about personal branding
I mean what a disgusting idea to Brand
your own self but this is like
considered just like normal stuff now
like everybody's brandings and you can't
avoid it because you're going to lose if
you don't you know like because I I
might have some interest in washing
machines or something but I'm not going
to I'm not going to start talking to my
followers about that like that's not
what they expect from me it's going to
be total disappointment and I know I
don't know what I'm talking about too so
like part of my like you know brand is
that I know what I'm talking about like
everybody else so if I start saying
things that are like way off Bas and
ridiculous you know I'm just diminishing
my brain and like actually the guy's an
idiot and so I'm embarrassed and I don't
want to do that but I actually might be
curious about these things like where
can I go to just talk about things I'm
curious about is actually really
interesting that can't do it there then
you've got this huge population 99.9%
who don't have enough followers that
they even could get their message out
and are like totally disempowered and
have no agency at all um you know they
actually have interesting things to say
not all of them but a lot of them do
obviously um because some of them don't
even want to play that game that's why
they don't have their megaphone but they
still might have something interesting
to say where can they go so I think all
of us have a really diminished agency in
this like totally deceptive objective
culture um which I think is is like a
really cool opportunity it would be
virtuous to fix that I'm not saying that
I know I can fix it you know you know
I'm like this savior like figure like
that's not what I think I'm just saying
it's worth trying to do something about
this that is virtuous to just try to try
to create a real
alternative yeah that was that was
beautiful but yeah just to comment on
what you said it's so true I mean um
what what's even more interesting is how
quickly it's become received wisdom and
accepted by everyone like um LinkedIn
for example they're giving out these top
voice Badges and people are now you know
that it's their full-time job to be the
marketing department for open AI so
every time a new model gets released
they'll use GPT and they'll generate a
press release and um and then they've
become a top voice on LinkedIn and I
always thought that YouTube was quite
immune to this because YouTube does
actually you know um it optimizes for
satisfaction and you get some very
interesting long form content but what
little did I know the more I learn about
YouTube the realiz the more I realize
how debased and deranged it is because
you start learning about thumbnail
optimization and clickbait titles and
how important the first 5 seconds are
and how you're doing this psychological
manipulation and actually just look at
all the popular videos on on YouTube and
it's just garbage it's just debasement
and and also it's it's it's debasing our
Behavior it's lowering our moral
standards in in many ways and all sorts
of weird stuff like that and nobody
notices can I add to that because um
there there there's also an interesting
thing about that like YouTube when you
think about that that intuitively you
would think that it would contribute to
like in other places we've talked about
like open-endedness and how it
contributes to the continued March of
civilization like more diversity more
Divergence of ideas more interesting
things going on so you would think
YouTube is like going to Absolute like
pour rocket fuel on that like that's
what I would expect and to a little
extent you see pockets of this like you
do see certain new stepping stones that
you wouldn't have seen before because
there's such a vast amount of like
opportunity now to reach an audience
with something that hasn't really been
tried before um but somehow something
about culture also seems broken at the
same time you know because like where
are all the new musical genres that used
to happen like they don't seem to be
happening anymore um like like things
seem to have stopped somewhere around
the year 2000 a lot I was you know I was
saying like that like in rock music used
to have like a new form like every like
10 or 20 years like what what happened
like the radio sounds exactly the same
as it did 25 years ago um and like I
think part of it is that this is another
side effect of these kinds of objective
driven algorithms these are convergent
algorithms the the like aggregate effect
over decades with millions of people is
incredibly hard to understand or digest
but I think we actually seeing the
aggregate effect now that like it's
actually causing a kind of like slowdown
of cultural progress um and convergence
to like already agreed upon standards
that is just like really deleterious to
to to cultural and probably other types
of progress that otherwise would be
happening that's so true I mean you
could argue that it's a kind of
continuation of globalization in general
but we've certainly seen this in in the
UK so we used to have quite a distinct
culture and since even since MTV and
cable TV and so on but even more so
since YouTube there's just this Global
mono culture now and I completely agree
with you that all of the interesting
diversity preservation has gone and
everything's just becoming the same um
slave to the algorithms and all that so
yeah it's um it's really interesting the
other thing I wanted to comment on is
even things like um our search engine
and our infosphere um if you think about
it where's all the new information
coming from so like now we're using
things like perplexity or we're using
retrieval augmented generation on top of
the search results so no one's looking
at the search results anymore no one's
looking at the individ ual pages and
they're kind of cannibalizing each other
and now we're producing this thing where
there's there's no fresh information to
build a search index anymore right so
we're just kind of like feed you know G
um garbage in garbage out and and we're
kind of eating our own poop to a certain
extent so um it almost feels like
there's going to be a mode collapse of
of all the information and the reason
for that is as you said we now have um
an entropy and agency minimizing society
which is the complete opposite of what
we need
yeah yeah it's like ultimately it's a
kind of a permission not to think is
what it creates like to think for
yourself because everything's been
ranked and everything's been already
classified and there's already Mass
consent like how can you disagree with a
million people um it's like it's already
consensus like it's just you come in and
you're like this must be the best thing
and of course you you still have your
own brain and you can still feel like I
didn't really like that even though
everybody else seems to like it but the
truth is it's having a massive effect on
you um like with the fact that every
single thing that like comes out even
like a single sentence that somebody
tweets out like in the middle of a
conversation is ranked it's such insane
could you imagine if that was like
happening while you're at the dinner
table and like you're having a
conversation like numbers appear above
people's heads while they're talking
like to's see who says the best thing to
say it would totally distort you I mean
you would you would be mentally deranged
from something like that but that is
what's happening um that that's the way
we experience the world on in every
level from like like a like a big new
movie to like a single sentence on on on
on X and it's just a it's it's it's a
crazy pathological perversion of human
nature um which is which is being just
just totally like like forced upon us um
and so so yeah like the the idea like
some people can't imagine there's an
alternative world is it weird because
like 25 years ago there was an
alternative world like this stuff didn't
even exist like I used to socialize I
think so I had social I had social uh
social experiences and there were no
like buttons and but now it's like but
what there is no such thing as a like a
social network without a like button
like what the heck does that even mean
that's that is what social is but there
are alternative worlds and I think um
you know I I feel like it's possible to
to pursue one um in my CA like the
problem is it's really dangerous to to
pursue them because they seem crazy it's
like if you just said oh Facebook would
be better if you got rid of like button
if you got rid of reactions and you get
rid of following your friends and but
it's like that's better like what what
is that like that's the whole premise of
the whole system like I will not be able
to sell that to Mark Zuckerberg he won't
do that um and so like that's not that
is so dangerous that that's why I think
nobody's trying any alternatives because
it sounds crazy but the reason that I
feel like I'm empowered to actually do
something radical like that is because I
came to the conclusion and the framework
for it not by trying to undo what
already exists but just through a
completely independent trajectory of
thinking like I have nothing to do with
all that stuff I wasn't trying to get
rid of it I was just thinking about how
serendipit systems work I was working on
open and algorithms for decades um like
I just have a trajectory of thought that
just totally independent and it just
leads me to a point which happens to be
different and that's a reason that it
isn't crazy like it actually comes from
thing it's not just I'm just trying to
overturn the status quo because those
kind of that kind of radicalism often is
just like doomed for failure but I have
like a just a different set of thinking
and so like I think that that gives some
hope that like an alternative world
could exist um and it's worth a try you
know worth a try to to give this
alternative and and see what that might
have should be like it feels to me that
human beings must be better than chess
computers and we just don't know yet we
haven't proven it yet because human
beings have creativity and chess
computers don't so presumably there is
something a human could conceivably do
that would break the chess machine we
just haven't found it yet and what you
know my read and what you're saying
there is that there's almost no scale
when it comes to creativity if you're
doing something creative one thing which
is creative isn't necessarily better
than another thing
yeah yeah that's a good way to put it
like it's totally true you know it's
like when we talk about Evolution and we
talk about Fitness we think of it as
like this absolute measure that like
helps us to understand like why
something survives why something doesn't
but think about it like when you think
about creativity like think about it
like between like very disperate species
it's like a meaningless thing to talk
about you know like the fitness of a a
bacteria versus the fitness of a human
being it's like what do we even mean
like maybe we could mean that like the
the bacteria actually reproduces it a
much faster rate and actually any given
bacteria has many more offspring than
any given human like there's different
ways we could talk about so they're
winning I don't know if you want to put
it that way they have more higher
Fitness and actually in absolute numbers
they also would there's like way more
bacteria than humans on the face of the
Earth uh but what's the point of this
comparison like it's the creative aspect
that's actually the interesting it's
like we're we're missing the forest for
the trees we're trying to be extremely
objective and of course you generally
wouldn't talk about bacteria R humans in
that way because it would be ridiculous
but we do that with content
um which is ridiculous um because like
the actual interesting thing is the
creative component not some superficial
stuff like how many bacteria can you
count in the world um and so it's like
these these like more these orthogonal
Dimensions like what humans actually do
in their lifetime and stuff like that
that makes it worth caring about us even
though we don't actually have as much
biomass on the world in total and so
yeah it gets silly at some level in
Creative very creative domains or when
you care about creative ity to try to be
extremely objective to make decisions
about what we should focus on what we
should not focus on um and if you think
about it like the entire social media
World works that
way I just wondered whether you could
bring in the the market system and the
profit motive here because you could
argue that even in a corporation where
the central goal is to make profit there
is still even though it's a constrained
space there is still an infinite number
of instrumental sub goals that would
lead to the company making more money so
you know the the whole greatness cannot
be planned idea is that we should be
discovering new stepping stones and the
and the uh the powers that be in the
company shouldn't necessarily be eroding
your agency and telling you what not to
do but in a purely creative pursuit or
or even maybe in a Serendipity social
network there really is no grounding
principle at all yeah I mean it's very
true that corporations also face this
issue I mean because of the fact
creativity just reoccurs over and over
again in many many different situations
I mean you can go from Evolution to
social networks to corporations like
it's just a ubiquitous issue um and so
yeah like even in corporations like you
will have a lot of convergence obviously
if you have a single objective guiding
the entire Corporation and you you'll
wipe out things like research Labs I
mean you can't have them they won't be
doing research at least you can call it
a research lab but if they're all
basically subservient to the bottom line
it's not actually research lab because
research means you have to do things
that actually are not necessarily Guided
by the final ultimate short-term
objective and that's um or even
long-term objective we need to be
independent of objectives in order to
explore interesting paths and that's a
way of preventing disruption you know
that's why it's strategically important
even though it may seem like it's off
path you know because it's like what
what do we really care about and other
than the bottom line if this is about
profit but the thing is that like you
won't be having any profits anymore if
you're disrupted and disruption comes
from unpredictable areas and it's not
just about optimizing along the path
that you're on um so to prevent
disruption you need some ility to look
outside and that means yeah not qu
caring only about a quality maximization
principle and then of course that
crosses over like you say into social
media really strongly because there
isn't even a profit motive to a large
extent I mean there has become a lot of
profit motive I mean there's a lot of
people who are using their brands to
make money on social media um but like
from the point of view of the aggregate
system or just an end user who's just
trying to experience something
interesting what does profit even matter
it has has nothing to do with what
you're getting out of this thing um
which is partly why Maven is such a risk
risky Endeavor um but this is this is uh
going to be um arguably better for for
like the end user to just be exposed to
more interesting things for them based
on what they're interested in um and get
away from the maximization principle
that sort of guides everything in the
world yeah and we were saying before
because you could take a cynical take on
this but but you convinced me before
that Serendipity is a natural thing
because you could argue that for example
I can go and set up a YouTube channel
and actually Serendipity is instrumental
to power seeking or me wanting to be
famous or or whatever but it it comes
back to this notion of agency and I want
I want to try one one more time with
this because I just think it's so
powerful as a lens to kind of think
about some of some of the things you you
speak about and I think of agency as a
thing with preferences or or valtion
which uh successfully shapes the world
around it to match its preferences so
that's kind of what I think of as as
agency and I think it's really related
to power seeking so for example one of
the reasons why things want to shape the
world around them is because they want
to kind of Commander or even steal
agency away from the things around them
and then there's this notion that um you
know innovation in a sense or in its
Essence is quite heretical right so you
know there is this story of U I think
jordano Bruno um in the sort of the 16th
century in Florence OR Rome or whatever
um he thought that the stars that we see
at night are actually quite similar to
the Sun and you know they might have
their own planets and even suggested
that the universe is infinite and uh you
know there could be no Celestial body um
at its Center and he was burned at the
stake in 1600 right so you know there's
there's a saying that science advances
one funeral at a time but I I think the
reason he was burned at the stake was
because such an idea would diminish the
agency of the Catholic church and
similarly you know when um this
einsteinian relativity was doing the
rounds in the 1920s even though Newton
died hundreds of years ago there were
still people who were kind of like
sequestering power and agency just being
on the orbit in the orbit of the legacy
of Newton so presumably they were
writing books and reputations were made
and so on and and as soon as you kind of
tear down that myth all of their power
dissipates so that there seems to be
like a real power dynamic to this as
well yeah I would agree with that um and
it's I mean we become invested in uh
whatever has given us success or where
we've staked our career where we've
built our reputation I mean it makes
sense that that that would matter a lot
to people and people tend to stake their
reputation in the previous Paradigm I
mean it's basically always the case I
mean the next Paradigm hasn't happened
yet um and so when somebody comes around
with a new paradigm it's a threat to
everybody it's a threat to everybody how
they've sted their careers and so it's
it's going to be heretical um
intrinsically heretical yeah um and you
know you you can see uh like growing
consensus around certain paradigms like
large language models like today um and
of course there's always going to be you
know some some people some pranks that
are you know snipping at the side and
saying like we you know that we're going
to get rid of LMS or something like that
but those aren't really the things that
are threat I mean it's more like if
somebody really has something creative
to say that's like totally out out there
then it's a threat then we would expect
um there's going to be an immune
reaction to protect the status quo um
it's a problem I mean you see that in I
mean that definitely happens in like you
know the way Grant review happens like
that like you're reviewed by your peers
but your peers generally represent the
status quo so um of course it makes it
hard to get anything through like a like
a grant committee um to get funded if it
is truly heretical like how can you find
something heretical um and um it's it's
just a big problem with uh the way that
you know our objective based way of
working like like if you we try to
imagine systems that actually can
function around um assessing heresy uh
in like a productive way that's like not
the way anybody's really thought about
the system I mean because like obviously
some heresies are are actually a waste
of time there's no question about that
um but like sorting between which are
and which you aren't is is not really
anything anybody's concerned with
officially um and so that that's just
like it isn't a really great function
that we have right now and I see the
connection to agency and power seeking
um yeah because like it's it gives you
power uh to be connected to the status
quo um and yeah you can build a career
in the status quo uh so that's that's
going to be that that's that's an maybe
unfortunate side effect of of actually
discovering things it creates power and
then be people get invested and then
they become entrenched the last year's
heretic is now like you know today's
dictator so um it's just a cycle that
it's hard to get out of because we're
humans yeah but um one interesting take
though is that I mean first of all there
are many degrees of freedom when it
comes to agency and power seeking so
just uh the agency to read the kind of
books I want to read is a kind of power
or dominion over my intellectual life
and there are some things we I mean even
like murdering someone for example we we
technically have the agency to do that
but we wouldn't because there'd be
consequences so that there's all of
these kind of conditioning forces and so
on okay let's see is any s indous
process a form of power seeking I mean
the um that is that sounds cynical but
let's let's see does it make any sense
um so you know because I I do think that
um without without that point without
you making that point I would have said
that you know Serendipity is one of the
more pure types of of motivations if if
you can call it a motivation that like
you know so just doing things because
you're curious um just exploring the
world or something like that um is not
like intrinsically trying to figure out
how to gain power in the world because
trying to explicitly gain power is is an
objective type of thing I mean that
would be your objective then is to gain
power um and so you know if if you're
you're just truly just curious what
would happen if I did this I mean it's
not clear that you're actually
explicitly aiming towards power um but I
mean so it seems like if you are getting
power through Serendipity it's more
implicit like it's something like just
by virtue of truly falling into
something some stumbling into something
cool it creates a little bit of power
around you it's like people might care
about it you might be empowered because
you can do more because it's it's I mean
what does it mean to be cool it's like
something something that does something
that's worth some attention um so there
there's some there's some like sort of
um yeah maybe tangential power power
that's acquired through Serendipity but
not always I mean I think some some of
it's just pure um just purely for your
own consumption you know like if you
find a show you like or something I
don't know what level of power uh you
know maybe you can tell your friends so
you did get a little bit of you get a
little empowered by it um but I remember
thinking like um early on when I was uh
you know when I was researching neat
like the earliest thing that I did was
the neat algorithm like in grad school
that was my dissertation
um like I didn't have much experience
like understanding how people get like
uh known or some something like that in
research or or famous for that matter I
didn't really understand any of this and
I kind of just assumed that no one would
care like I don't I don't think I was
really motivated by people caring
because I was just like the thing that's
really good about this is that I'm
allowed to do it more it was more that
like I can just do what I want because
it's interesting and I thought that was
really cool that I could just like
explore stuff and had no idea like a
single person would ever care about this
at all but I thought well it's really I
like the fact that no one seems to have
done this before that was sort of my
motivation um it did maybe create power
in the future because other people did
end up liking it which really shocked me
um you know like I I didn't actually
expect that um but um but I think like
the motivations there were not very
objective I mean it was just like I was
just really just curious and just really
grateful that I was allowed to pursue my
curiosity like I remember when I did my
proposal that I felt very very
successful that they approved it but
mainly just CU it was like oh I'm
allowed to look at this for 2 years or
something I can just think about stuff I
want um that's I think that's more
serendipitous thinking um than just like
how am I going to influence people and
control things and stuff like that um
but this is an issue I haven't put huge
amount of thought into so maybe you have
other thoughts about that I think it's
it's fasinating for a couple of reasons
mean first of all I guess I'm only
arguing that it's the same kind of stuff
as power so I'm not necessarily saying
that um you know serendipitous exploring
will turn you into a you know into a
maniac who wants to take over the world
I think there's a difference with having
the valtion and the ambition to want to
take over the world but the Paradox is
as you just said if if the person were
to be successful taking over the world
it would be via a serendipitous process
and in a way there is because because
you always make the argument that
there's not a monotonic increase if you
line up the objectives but but in a way
there there kind of is because the the
first stepping stone embarking on this
serendipitous process is as you just
said oh my god I've now just got
dominion over my creative thoughts I'm
no longer in the for in the
gravitational pool of these people I can
now explore things that I genuinely find
interesting and I'm in a very happy
place so I I I now have power over my
you know my even deciding how to brush
your your teeth on the left side or the
right side is a kind of a kind of power
an agency and then and then for whatever
reason the thought might occur to you oh
I want take over the world or it's an
externalized process and when you see
several pockets of you know independent
Serendipity being executed those Pockets
become clouds and then the clouds become
very powerful yeah I mean there's I
would probably more use the word
autonomy than than than power when I
think about like what I what I would be
excited about um when I get the chance
to explore on my own like I I gained
autonomy rather than that person telling
me that this is your project now I can
just say my own project and uh but I
mean it autonomy is a form of power um
so but I mean going away from just like
uh semantics I think that um the problem
is that there there's some kind of
entangling here between uh like
algorithmic issues and um human
psychology because I mean like power
seeking is not just an issue of an
algorithmic question like is it an
objective or not it's also like a
psychological issue like with us and you
you know algorithms might not have that
psychological component to them uh like
if I try to create an open-ended
algorithm or something not really like
the psychological explanation for why
it's doing things um but in terms of
humans we actually yeah we we do seem to
like getting dominion over more and more
stuff so it's true that like a stepping
stone might be interesting because it
gave us more influence over the world
and then we can jump off from there to
something else that would also be
serendipitous which actually as a side
effect creates even more influence and
in some way we're following a gradient
of power we're getting more and more
influence um and that's that seems to be
um just a something that's psychological
like the fact that we like that or care
for that um and um but but I guess like
the point about agency makes sense that
like you know you're you're actually
gaining agency um well if you can do Ser
I'm not sure if Serendipity is causing
you to have more agency or is it that
agency is causing you to have
serendipity
um because the agency is sort of like
necessary in order to explore but then
you could argue that because you were
successful and you found something
you'll have more Agency on the next
iteration um of your exploration I mean
so maybe they they they feed into each
other in some way um but that's just a
side effect of the way that Society
rewards things um I'm I'm sure that's
like an algorithmic principle um but
yeah there's definitely some some uh
entangling between these two ideas I can
see that what would your main argument
be for the morality of people being able
to independently shape their world well
I guess there is a moral component to it
I mean if I didn't think so I wouldn't
have gone on with Joel to write a whole
book I mean I I thought that this is
actually a a wrong that should be
corrected in the world and it it's um
it's it's partly for practical or you
could even say utilitarian purposes that
I actually think that we will be more
effective as a Society um by allowing
more serendipitous exploration like that
that actually is important for our
survival and continuing progress so but
but but I mean it's also true that for
individuals and um the uh like the human
flourishing like to be to actually be
happy it seems like it does seem to be
an intrinsic aspect of human nature that
there's a need for self-expression I
mean I do believe that too um which is a
really interesting thing about you know
human nature because like when we think
about things that are getting better at
disseminating content to us that we
would like um like that is that sort of
implies that human nature is mostly
about consumption um you know it's like
the whole thing is to optimize your
consumption um so that you're satisfied
you feel satisfied and like it's like
the the ultimate end point of that seems
to me to be like that there'll be an AI
that just basically 24 hours a day
generates movies that are just optimized
for your brain um so you don't have to
do anything just sit there and consume
it's like all perfect for you like
that's the best show I ever saw and then
another best show you ever saw all day
long but the thing is that like that
can't possibly work because of the fact
that at least in my theory is human
nature requires
self-expression um you have to also um
produce in in addition to consume to be
a satisfied person um and that relates
to serendipitous exploration like you
cannot produce without exploring um and
so like people deserve and need this
like in order to have meaningful lives
um and that's harder to achieve um but
it's I think it's a moral issue though
um because to me yeah there's a there's
a real uh diminishing of the value of
life if everything is consumption um and
that seems to be actually where these
systems are heading like in terms of
social media systems um content ranking
systems like it's not just social media
ranking of movies and ranking of books
and everything about ranking um is all
to optimize consumption so that you're
you know most of your time is taken up
consuming with the optimal thing which
is like the thing that most people want
to consume um and that does seem like
there's like more and more going towards
like actually it can consume your day um
so it can work I think like you can
actually just sit around consuming
things all day it's easier to do that
than it was 200 years ago um but um but
yeah you're sacrificing something like
really important um which gives meaning
to life and existence which is way
harder to build for like is to to enable
self-expression that's another maybe
angle on I think why I wanted to do the
the maven system because it's like um
not trying to optimize for consumption
it is TR giving you diversity of things
but the hope is that those trigger you
to do something like to your own self-
exploration um like it's going to lead
you to participating in that discussion
or just to doing something else outside
in your own life um because you've been
exposed to something different um than
what's like the optimal consumption
object which is just something that we
could keep you around for hours but it
doesn't only do anything for you um so
yeah I mean I think there's a a huge
moral component to it um and it's like
really really uh sad to me like that
like everything is consumption oriented
when I I just don't think I think
everyone is ultimately needs
self-expression we're just like running
trajectories in our head and we're kind
of think you know when I go to that
place I get the coffee I get the
dopamine but then there's the question
of well where does the valtion come from
because just from a neuroscience point
of view there there is kind of goal
optimization because your brain is just
doing this clever search problem we
don't know how it solves the search
problem so it's somehow cutting down the
exponential trajectories and it's doing
all of these like little BS and you know
we we eat the cookie and we get the
dopamine and and then the valtion arises
from that prediction process but then
aren't you just isn't that just a form
of of goal seeking in a way and the the
Serendipity and the Stepping Stone
Collection is kind of instrumental to
that well it to me it highlights that
any Grand Theory which it sounds like um
this is one attempt at one uh needs to
account for um our inic drive to explore
for its own sake um and if it doesn't
account for it in a satisfying way it
wouldn't be a satisfying Theory to me so
if it really like get it turns out like
it's like a mystery within the the you
framework of the theory why would
anybody care about just exploring like
why wouldn't you just try to maximize
dopamine immediately and go to the
coffee shop or something like that well
then there's I feel like the theory is
missing something it's not that theory
is completely wrong throw it out has no
value but this is the thing we need to
figure out like it's really um it's it
comes up everywhere because it it always
seems to be the last afterthought um of
like every Theory every algorithm like
an AI it's like all of them are very
good at dealing with goals and how we
figure out how to get rewards and things
like that but it's this huge
afterthought of like where is intrinsic
motivation coming from and I you know
obviously there even intrinsic
motivation algorithms it's not that no
one thinks about this but even that
often is thought it was an after thought
it's like there's like the main branch
of reinforcement learn then there's this
little weird section of intrinsic
motivation people thinking about but to
me it's like that's not the side show
that's the real show um you know it's
like it's amazing to me like how
insanely creative people are um that
like you know because like even like
mundane conversations are actually
creative um and like that's something
that really like hits me when I talk to
like CH chat GPT or something like that
it's like I I wonder why I can't I don't
want to it's not that I can't but I
don't feel very motivated to just like
you know just talk about like random
stuff with it just like you know shoot
the breeze and just enjoy like a
conversation like it's just like
pointless there's no it doesn't because
seems like even like just talking to
some random like let's say someone who's
not impressive in any other way whatever
that might mean like you can still have
a conversation with them where it's
unpredictable and interesting but people
are just really good at doing that on
like a moment by- moment basis and just
like that is not part of current AI at
all like at at the granular level or at
the macro level just not there um and
then these theories don't account for it
either like and yet it seems to me but
this is all just um you know speculative
that this is not like some kind of
formal Theory but it's just my intuitive
strong belief that um this is Central to
what it means to be human and
intelligent as a human is that like the
the fundamental Drive is towards
exploration um you see it from childhood
all the way out and it's just like I
think it's and if you want to know why
like where does the Drive come from it
probably relates to some extent to Our
Success um you know like as a species
like we're um it's useful to be this way
um it doesn't have to be that useful
because like remember evolution is not
itself only about optimization um but it
has to be useful enough to Keep Us Alive
um and so it's it's it's it's useful
enough it may be that like it's you know
it's related to highly efficient
algorithms that can create things like
us um you know for example like early on
in life when you're learning things like
how do you walk or something or how do
you how do you talk um I think it may be
helpful that it's not an optimization
process it would actually be less
efficient it was an optimization process
like we optimize Walkers you know this
was a classic experiment in novelty
search was we took like a bed robot and
tried to evolve it to be the optimal
Walker and we also did a novelty search
and the novelty search produced better
Walkers um because it's just like the
Stepping Stones like starting from
scratch are just like not what you would
expect so actually optimization like the
ones that lead to walking so
optimization turns out actually fairly
relatively inefficient and it's maybe
better to just have this baby just like
interested in trying stuff like what can
I do with my arm and I just like swing
it around what can I do with my leg and
maybe this is a good way to build up um
like a repertoire of skills which is why
repertoire keep coming up in like
quality diversity and stuff like that um
it's just better for building up a
repertoire then like you have to learn
how to do this you have to learn how to
do this you have to learn this like this
all big set of objectives one is a
separate optimization process um like
that's just like really inefficient and
awkward um and so maybe it emerges from
the fact that's actually a good way of
like you know encompassing a huge bundle
of skills and and abilities or a
repertoire um and then emerges from that
that that just like remains a driving
force throughout life although it's
squatched because of social types of
pressures um but it's still part of our
nature I think um and so um I I don't
actually want to claim to have a
all-encompassing theory here about this
um but I I do think I can uh criticize
any theory that doesn't have it um yeah
because like it seems to be always
missing and always just like well you
know I don't why should I have to defend
myself by how I'm going to fit it into
friston's Theory I mean it's his problem
like he if he can't like just show that
strongly it's predicted by his theory
you know that that we should have this
huge Drive I think the theory needs to
be um get some scrutiny and again I
don't mean to criticize it like
holistically there's probably lots of
good ideas in there um but something
there it really needs to be addressed
yeah I mean there's also this spectrum
of um enactivism which is to say on the
extreme enactivism side of things you
could just argue that there is no
valtion there is no planning there is no
kind of sophisticated exploration so you
could just argue in some sense that you
know I just happen to be here and what
what we think is creativity is pure
Serendipity it's just my local physical
and social embedding the reality I'm
sure is somewhere in the middle that
it's a combination of serendipity but
also some sophisticated planning and Val
yeah yeah I mean I I I I accept that
planning happens I believe so um there's
planning volition um and it's a mix like
you said that that's my my my guess
about things um so um yeah we we should
we should try to understand I just don't
get interested in it because I feel like
it's the easy thing to explain um you
know is it's like you have all these
grandio theories about how we plan yeah
I mean I agree it's something we should
figure out um and by easy I don't mean
it's actually truly easy but it's the
easier part of the problem I mean
reminds me of Cher's hard problem and
stuff I mean I'm not talking about
Consciousness that's a really really
hard problem but you know charmer splits
up Consciousness into the easy part and
the hard part is it's a hard problem of
Consciousness um I think that's really
conceptually useful like to think about
like the easy part and the hard part um
so that we understand there's still
something missing here that like even
with all these Grand theories like this
still over here is not being addressed I
think it's sort of similar in the world
of intelligence even or like human
intelligence and AI um that like there's
this like tendency to like spend all
this time rinding away at the easy
problem um of like you know this like
just cognition and planning and
following objectives and optimization
it's like how does all this happen and
prediction prediction is another one of
those like easy things I think the hard
thing is creativity like that's much
more complicated
actually and difficult to explain
because it requires Computing things
like interestingness which are far
harder to formalize than something like
you know how well am I walking right now
compared to five minutes ago like you
can you can pretty much formalize that
kind of thing um so there's the easy
problem and the hard problem and I just
find the easy problem like somewhat less
interesting um when we really want to
get to the heart of what is like going
going to be AGI like it's going to have
to somehow account for the creativity
side of things yeah and I would argue
that can be no creativity without agency
so there seems to be a very close
relationship between those two concepts
is there an interesting point there
though that on on most social media now
99% of people are consumers and they're
perfectly okay with that maybe that's
not the right way to to frame it because
every everyone's a publisher in the
sense that they have their photos and
they have their status and stuff like
that but but most of their activity is
is consumption
yes
um that's true uh that will be still the
case here so um you know I don't think
we're going to fundamentally change the
fact that the major the vast majority of
users are just consumers and lurking um
and and and but remember that like you
know one thing people have been telling
us is that like the emotional experience
of like scrolling through this feed is
very different so for those people who
just want to consume um you know you're
not going to have this feeling of uh
constant conflict and um like constant
emergencies like this feeling I remember
when the pandemic started like Twitter
was Absolut or even quora was just like
sickening to scroll through I mean it's
just like caused mass panic in my mind
um like that kind of feeling of like
everything is in your face as it
possibly can be to grab your attention
to freak you out as much as possible
like that's not like that at all um
people are just pursuing curiosity um
and so it's a it's it's also I think a
beneficial to to those who don't care
about um actually producing content but
it's worth emphasizing that for those
who want to actually be part of a
conversation it's it's definitely
presents an opportunity because you
don't need followers like you come into
the system and you know there are there
there's no concept of following in the
usual sense you can actually like
another person's profile um which just
means you'll remember their profile but
it won't affect your feed in any way so
it's not like you'll see more of their
stuff if you do that so it's not
following just a way of remembering
people that you thought were interesting
um and so because of that um you know
like the 1% of people or the 0.1% of
people who have like 10,000 followers or
something like out in the other parts of
social media uh they have a huge huge
advantage over you um in terms of you've
got something interesting to say today
but nobody's going to hear it so you got
to build up that following but on Maven
you could just day one like it doesn't
matter everybody's equal in this sense
like it's just going to be sent to
people who share the interest that you
have so you have a shot uh regardless of
following um that's equal to everybody
else and so for the 99% of people in
that boat it's worth a try you know
because if you want to actually discuss
like 99% of people want to post who in
that boat if you want to discuss
something you have a chance here to
actually find like-minded people who
will actually respond to you but even
the people who are in that small Elite I
still think they get a benefit because
of that whole point we discussed about
um the fact that they're not they're not
obligated to continue to perpetuate
their Persona that they feel they're
obligated to perpetuate like in all the
other social media because that's why
people are following them is because
they are who they are um and so like
yeah if they want to inquire about some
random concept that they don't really
have authority in um they should feel
totally comfortable because you know the
thing about Maven is they can do it and
the people who follow them for other
reasons probably won't see it it doesn't
matter they're in a different Community
sent to people who do have those
interests um so I think everybody could
get a potential
um productive benefit from just uh the
different the different way that
participation Works in this case some
people say that on Facebook you get Echo
Chambers so in a way your your desire to
be heard is met through this
fractionation into many many small
interest groups in a way no matter who
you are your voice can be heard but of
course heard in a weird Echo chamber
that nobody cares about but you could
say the same about Maven in a sense that
your voice is heard but only by John in
mer land and you know like if I'm if I'm
trying to get my voice heard by the
right people to seek power or to get a
job or something you could argue that
that doesn't help me much more than
Facebook does yeah no I I I do agree
that like if your point is to actually
uh to amplify your voice like to make an
announcement this is probably the wrong
service for that yeah because it's it's
not like a a medium for virality so it
doesn't offer that um what you get here
is the to pursue your curiosity um and
so like John and Maryland it's probably
not enough to start a social movement um
but if you're interested in whether it's
even viable to start your social
movement or like what are the pros and
cons or the arguments about what you
want to say well John and Maryland might
actually be an interesting foil to have
a discussion with um because John and
Maryland is interested in talking to you
about this which is a good thing because
like how are you going to find someone
who is interested in talking about this
thing um and so you can have a
conversation there and it doesn't
doesn't have to be this um inflammatory
style of conversation where John needs
to beat you because he needs to get
followers for his cause um even if he
disagrees with you because he can't get
followers for his cause through this
it's just it's just an intellectual
exploration and so for that purpose this
is really good like you can talk to
people about things you're interested in
then if you want to go through
amplification and like have a newsletter
or something you you would do that
somewhere else um but we offer this
opportunity to actually have a
conversation yeah no you're absolutely
right this is about this General theme
of following your own gradient of
interestingness and you can talk to John
in Maryland because he has the same
gradient as you yeah yeah and you're
certainly not an echo chamber in terms
of agreement because I mean I mean you
you both may be interested in AI ethics
but you both may have the opposite
opinion um so that's different than
following a person you know because you
follow the person because you agree with
them so that's why I like that person
you tend to have a lot of people who
agree with you um and so this is not
like that at all do you feel social
media is broken and are are you seeing
how it affects people around you yeah I
mean you know I was feeling there's
something I was feeling in AI around the
time that I decided to do this uh like a
year and a half ago um when I started
thinking about this seriously um and I
was just like getting this feeling
probably from social media of just
negativity lingering around AI like
increasing which is like really new to
me um cuz you know I I was in AI for
decades and and it was like a really um
like just like a nice fun Club of people
pursuing their intellectual interests
for a long time like there was no
ethical consideration I mean it would
come up like uh you know like in in very
abstract terms like like decades ago
like whether you know there might be
danger in AI or something it's like
that's so far off like you really need
to worry about this um but like suddenly
it just hit like a couple years ago you
know like everybody not just me but this
just like suddenly hit that like this is
now like a political issue a social
issue it's a polarizing issue and I was
starting to try to understand like where
do I fit into all those issues that that
are like complicated answers and
arguments about them like in terms of
like the ethics and the safety and all
these different things um and then also
this idea that like just like our our
lives are going to be pervaded by like
chatbots and stuff which hadn't really
occurred to me like concretely um for a
long time um and I yeah so just kind of
hit me all at once like all this stuff
and I just started feeling
like I would just like to do something
that's just like definitively clearly
nice like just really nice like I was
starting to feel like I'm not sure what
I'm doing is nice anymore it's not that
I advocate that we all stop AI research
I'm not one of those people I'm not
saying stop AI research but it was just
for me personally as I'm sorting out all
these issues um I was just like what
could be just like clearly definitively
socially positive at least to try
um so I can just feel good like I'm just
doing something without having to think
about all this other complicated stuff
it just makes my mental burden easier
and that's something that emotionally
contributed also to going in this
direction because I just thought you
know there's obviously there's obviously
a problem socially with social media um
it's having a lot of bad effects on us
and there's not a lot of disagreement
about that from like all sides like
everybody seems to agree with that it's
got a lot of negative effect on
discourse On Emotion on how people feel
about themselves like and and so I I I
was like you know if AI could help with
that like that actually is like a
win-win probably on all sides so I could
just do something I feel proud of
basically for a while and then in the
meantime I can think about what I really
think about all these issues that are
very complicated because I wasn't really
sure what I think about all of it um
it's hard to adjust when you just think
of it as a game basically for 20 years
and it's just like a fun game that
you're playing and then suddenly like it
has all these social implications you
didn't really think about like it's just
like I need time to absorb this and
understand it so I'm just going to do
something I feel like Maven would be a
social positive I'm not 100% sure it's
going to succeed um but I feel like it's
pretty clear it's trying to do something
nice because if I try to give up likes
and follows I'm going against the grain
in a way that's extremely risky it's not
like I'm trying to exploit people and
extract money from them I'm like going
the opposite direction so how can I make
that into a business it's going to be
complicated um but I can feel good about
myself so that's kind of like another
thing that led me in this
uh Direction the thing that was nice
about it is that it's it is dovetailing
on my AI research right it's not like I
just like oh let's just forget about Ai
and do social media it's like all the
insights from quality diversity from
open-endedness they all come to bear on
this so I didn't feel like I was just
like giving up like all of the
intellectual effort of the last 20 years
I felt like this just naturally Builds
on top of it like it doesn't have to be
explicitly an autonomous AI system just
like pick breeder itself wasn't you know
like you can make a system that wraps
open-ended principles around people and
still use a lot of the ideas like the
minimal criteria and stuff that I've
been thinking about and so it wasn't
like just like I'm just dropping out
it's just like an extension but like in
a direction that allows me to sidestep a
lot of these sticky issues right now you
know I interviewed your student and
co-author Joel lemon and you know he
obviously he grew up on this idea of of
um greatness cannot be planned and now
he's very concerned with um AI risk and
you were saying about ethics and
actually a lot of this a lot of your
concern with face with ethics with risk
and so on is because it's um Serendipity
eroding so I said to Joel how do you
kind of ju ju oppose this kind of thing
that you wrote about with Kenneth which
is that we should be serendipitous and
now you're being quite paternalistic and
consequentialist which is the complete
diametric opposite of serendipity how do
you just Jose those two ideas and he
said I don't know look when it comes to
those AI risk issues safety issues
ethics issues um I just just feel
comfortable saying I don't know about a
lot of like I don't know what I should
conclude exactly about a lot of things I
do have opinions about it of course but
I mean they'll be a hold of the show um
but like yeah I don't have firm
conclusions to come to yet um and
um I think we we need some time um to
understand uh like like like
open-endedness um it's still like it's
super fascinating from just like an
autonomous AI perspective it may be
essential to achieving AI
uh but what are the implications of it
in terms of safety and things like that
uh it's like a very complicated issue um
so yeah I mean I agree with Joel it's
it's a little bit tricky to uh um to try
to reconcile all these different things
now with everything we we've been doing
um and uh yeah why not just drop some
people into a nice open-ended system and
do something else for a while um while
I'm trying to figure this out um and um
you know I think there are things open
ends can contribute one thing I think is
you can't get out of you can't get out
of the problems of
AGI uh without confronting
open-endedness like I think
open-endedness is part of this like it
has to be confronted like the whole
problem is that it is open-ended in my
view like that is actually the most
fundamental aspect of the problem like
if it wasn't open-ended it wouldn't be
as much of a problem but also wouldn't
be very interesting um and so I wouldn't
be AGI in my view um but then on the
other hand like the the open-endedness
is helpful then for understanding what
the risks are at at some level because
like controlling an open-ended system
which is like a paradoxical thing to try
to do is the problem of safety um like
how do you actually get an open-ended
system to not go over certain lines that
are like really like unacceptable but
still have it be open-ended like that's
a challenge well that's what
open-endedness research is about um so
in some sense open end this could be
very important to continue to research
because we need to understand this now
from a safety point of view um but
anyway for now uh I'm yeah going to be
uh just building this network uh and uh
but yeah on the side I think about these
things a
lot yeah and I agree I don't know I'm a
little bit skeptical about AI safety but
just as a thought experiment AI could be
the technology that if if you
democratize it it could just have
catastrophic unex you know um unforeseen
consequences and then as you just
alluding to if you place constraints in
the system then you have all of the
problems that you've spent your career
talking about so it's it seems like it's
it's almost like um Pandora's Box that
this is the one technology that kind of
breaks everything and now we need to
have a paternalistic
society yeah yeah except I mean the the
thing that I think about is just that
you know humans are also very dangerous
and open-ended we are open-ended and
we're we have AGI sort of like we are
General um and and we're really
dangerous and we can like kill each
other and kill many of each other and so
forth and we can destroy Society if we
want if we if we put our minds to it we
could do it um and um but so we've been
confronting this issue it's not like a
new issue actually um the issue of how
to control an open-ended system is the
issue of society itself or I would say
the issue of civilization because
civilization Al also confronts the
problem that like it needs to be
open-ended enough to continue to
progress like if you put the brakes on
too much then progress stops and like
you have extremely authoritarian systems
then um like if people can't have any
freedom at all um but you know then
there's the problem is there too much
freedom and too much Freedom too much
openend is also extremely dangerous like
there have to be breaks on something um
but it's interesting that this is this
is a problem we have been dealing with
like that's how I think about it so it's
it's not like a new problem actually
it's new what it's applying to but the
problem itself has existed and so I
think that like you know all the
institutions of government and society
and culture have grown up around trying
to control an open-ended system from
going out of control but still be
open-ended we actually have a lot to
draw on there like how we've done this
in the past um but it's different than
let's make a benevolent dictator that
like loves us all like that actually is
not what Society has done and when it
tried to do that it didn't work very
well um and so like this is much more
complex at like a a cultural and
sociological level you know controlling
open-ended systems but it's I think it's
interesting that we've seen it
um and it involves people you can think
of um it as being an agency problem so
we're we're a society that values
individual agency and the technologies
that have a large blast radius at the
moment are controllable in the sense
that it need significant resources to
get access to them but if you did
believe that AI posed an existential
risk and it's democratized then given a
high agency Society it would presumably
be impossible to control it
yeah um yeah it's true AI is a a very
special uh case that isn't like things
that have come before I mean I agree
with that um and but you
can something like
institutions are relevant like because
institutions prevent certain things from
happening I mean like a bunch of people
could get together build a nuclear bomb
if there weren't institutions um like
like if you say anybody could just do
whatever they want they can go mine
uranium and do whatever they want um
like like there are restrictions on what
can go where and how it can go because
there are institutional restrictions and
I think AI needs to be embedded in some
kind of institutional framework but it's
probably some of the institutional
framework are AIS um which would bound
what AIS can do and so it's probably a
multi-agent thing um but in the end
that's just like you know really
speculative like what am I even talking
about like in reality right now what
you're saying I think is true like we're
looking at um unprecedented
possibilities that that can't be fully
understood
and therefore it makes sense to to move
cautiously um and think about it um but
but I think also you can't just not move
also you have to move um and so um it's
just a needle threading exercise for for
society I kind of think of a lot of this
gold directedness stuff that you're
talking about as being a story of agency
and how there's a very complex natural
way of things in the world and we all
have spheres of agency and there are
physical agents and social agents and
you could think of um agency or autonomy
as just being a kind of force of
yourself around the world around you a
bit like a gravitational force of the
sun you know things orbit around the Sun
and having autonomy is about having
things orbit around you rather than you
orbiting around other things so it's
about the you know there's almost you
can kind of Imagine a solar system of of
of orbits and and where the the kind of
the generating sources of agency are
coming from and then of course it gets
much more complicated when when you
think about that in the world of
intelligence because then agency isn't
just about this very simple
gravitational force it's about active
sensemaking and planning and being able
to kind of you know develop
sophisticated behaviors to change the
world around you well that's that's
interesting um
so yeah I mean the agency point is
interesting I can see the connection
between agency and objectives um you
were sort of like uh objectives reflect
the
set of rules that already confine you
and so you're operating within those set
of rules um but you could create your
own rules and that would be to actually
um express some agency in the world so
if if goals are an instrumental fiction
and I guess what I mean by that if if
planning and goals are an instrumental
fiction there are way of post Haw
rationalizing complex Behavior so we we
kind of project this cognitive map if
you like to understand the physical
phenomena and it's not to say it doesn't
exist in the real world of course it
does but it's um it's very diffused and
that what we think of as planning is
actually a very complex low-level
information sharing between all the
particles in the system and so on but
but then but then the question is well
obviously if we if we simulated the
system at a sufficiently high resolution
um obviously we would capture those
Dynamics but I think what you're saying
is well why don't we come up with an
abstract model and still capture as many
of the Dynamics as possible and I guess
that's that's the Gap that I'm trying to
understand yeah so maybe it's like
instead of because that's that's pretty
high level abstract to to think about
like how you know at what how many
Dynamics can be captured through some
abstract algorithm I mean I think maybe
it's better to think like what exactly
more concretely am I saying I mean like
algorithmically capture something um
like what exactly am I talking about
like basically what I'm talking about is
the fact that for individuals um in
order to have Serendipity you need to be
exposed to the right Stepping Stones um
like this is what leads to Serendipity
and like the assumption that I have is
that the right stepping stones for you
are not the same as the right stepping
stones for me um it's very idiosyncratic
like what is actually going to be
transformative for you which also makes
it hard to predict for you what's
transformative for you soes nobody
really can say for sure um but it has
something to do with exposure um like
you need to be exposed to things that
would be transformative or else they
just won't lead to the transformation
you're the one who can make the
transformation if you were exposed
because someone else won't do it but if
you're not exposed you won't do it um so
it's important for people to be exposed
to right things I it goes all the way
back to pick breeder that we saw things
like you know the the The woman there
who really loved the bugs um and so
being exposed to bugs or bug precursor
was like a triggering event for her
although she didn't know it um and then
she was like really uh crazy inside of
bug space um and so that was important
for her to get exposed and and like the
pick breeder system was good at like
large scale exposure of Stepping Stones
partly because it's images so it's a
little bit of a it's a little bit of a
cheat because like it's really easy to
scan huge numbers of images very quickly
it's not so much true of like just
content in general or especially written
content um but so people were were
getting a diversity of exposure which
meant that they can go in many
directions which is like in aggregate
very Divergent as a system um and so
this this is what's interesting is that
it's conflicts with social media which
is actually consensus driven and
convergent because of that which is
basically like it's basically based on a
Model that says like if more people
agree that something would be
interesting to you then will you have a
higher probability of being exposed to
that thing um which is like antithetical
to your idiosyncrasies but it's still
going to be true that like if most
people like it then there is a high
chance that you'll like it because you
are one of most people usually um but it
what it doesn't do is expose you to the
things that are idiosyncratic to you
because consensus can't do that um so
you're missing all those things um and
so there then what we should be doing in
a system that's geared toward
Serendipity is not allowing consensus to
decide what you're exposed to um and so
that's clearly radical I think that's
quite radical because like all of social
media rests on this assumption it's
almost like a natural law in social
media like people don't even question
that like that is like it's like the way
in the notes you use the word social
it's like you call them social features
like as if that like there's a syn
synonymous with being social like you
have to have these things these are
consensus mechanisms um but I think like
what I'm saying in like these kinds of
want to say algorithms like the insights
from the algorith let see the algorithms
themselves because I'm not saying like
run novelty search on top of a person um
but the the insights from the algorithms
they suggest that that won't work for
serendipitous exposure um and so what we
can do is basically try to expose you to
things that match your interest and then
from there you'll be able to see lots
more of that like opportunity surface
you could say of what might actually be
triggering to you and the assumption is
like look there's like a lot of stuff
bubbling around under the surface of all
this consensus um which is very like
spiky in terms of convergence you know
because like if you think about it like
a lot of a lot of the conversation of
the day even if it doesn't involve
somebody with a big megaphone like it
goes back to the person with a big
megaphone you just don't realize it um
you know if Yan laon says something
about AI today because he has I don't
know 300,000 followers or something on
on X then like a lot of people are going
to be talking about that thing
unwittingly or not um and so there's a
lot of convergence day by day on like
what are the topics and yet there are
lots of people who have something
interesting to say in Ai and I I
wouldn't say that like Yan Lun isn't
interesting because he's obviously
earned his place and his megaphone but
the thing is he's redundant because he
says similar things constantly and they
keep on dominating and of course it's
not just him there's like maybe a
hundred people that like are like this
um but those people basically are
dominating and con setting conversation
with they and then there's the 100,000
people who aren't those people because
after all like you know I think I read
the statistics that like on X like it's
about 0.1% of the population that has
10,000 followers or more so 99.9% of
them are at a level where you're likely
never to hear anything they have to say
unless they're replying to Yan laon um
and so those people have lots of
interesting things to say but not
interesting in a consensus sense but
interesting to you um in a sort of
idiosyncratic sense some more than
others but they have idiosyncratic
things to say um some are would probably
be consensus interesting but like they
just have trouble getting consensus
because they don't have enough followers
yet um but the thing is that like all of
that churning stuff um you're not
getting exposed to generally a
consistent level um and so it would make
sense to intentionally design something
to work like an open-ended system
because an open-ended system would have
these mechanisms that actually that kind
of exposure would be routine rather than
like require enormous effort and a
megaphone and very rare um and so that
would be that is possible actually to
create a system like that we understand
how systems like that work they're
actually not that hard to understand the
problem with the reason that they can be
built the reason they're hard to build
like artificially is because they're
missing human intelligence um I mean
because human intelligence is part of
what makes these kinds of systems run
and that hasn't quite been conquered yet
but the thing is like if humans are in
the loop the outer structure of such a
system is understood like we do
understand this now we have humans in
the loop if the social network um so we
just have to fold this thing around them
that has this kind of exposure and we
can um fix that but I just want to point
out that like the side effect of that
it's not just about increasing
Serendipity it's that it the incentive
change being so dramatic changes like a
number of things that really change
dramatically you know like where's the
incentive for clickbait it's not there
anymore because there is no such thing
as virality um and like you why would
you promote yourself in a situation like
that like if you actually want to cause
a scene say something offensive maybe
that gets you attention here what's the
point of getting you won't get more
attention because it won't be Amplified
um and so like in a large sense like
human behavior is vastly changed the
incentive system has vastly changed on
top of it and so this should be it
should be actually a good form of like
detox from like all of the bad things
that you see that are happening happing
is unended consequences you said
something interesting about Yan Lun I
noticed this as a podcast interviewer
myself people only really talk about
three things at a time three themes
people are incapable of thinking about
too many things because of this
convergence I feel sorry for Yan Lon
because he he he always practices saying
the same things over and over again so
obviously for me as a podcaster there's
a trade-off between um clout and actual
real sources of entropy and I'm trying
not to influence the um the interviewee
with my own views and sources of entropy
because again that creates these
convergent measures but anyway on to the
most important thing you you were just
saying that um some people argue that
certain things are just the way they are
so there's this book called H the status
game by Will store and he says that we
all um you know we play the success game
we play The Virtue game we play the
dominance game and you could argue that
this is the real reason why social
networks have verality because people
are playing the social games and if you
create an asocial Network work then
there's no game to be played so maybe
people won't be interested anymore mhm
well um so so first I mean I that the
fact that the word social get gets like
uh you know kind of um entangled with
this issue of like popularity is just
like crazy to me like I can't the the
word should be separated in my view um
you might argue that the network would
fail because everybody is too motivated
by popularity driven mechanism so
there's no way we're going to have a
network like commercially successful
Network or or even successful enough to
have a community but that that's
different to me than saying it's not
social like that's a strange point to me
like like socializing didn't used to
have to do with these things like these
are all ridiculous new ways of
describing what it means to be social I
mean there was no like button in my life
before like 20 years ago I mean I did
plenty of socializing it was not a
problem not only that but I mean maybe
more relevant to that because that
that's that's more of just an emotional
reaction action like it's basically um
it's there is precedent for having
networks that are successful without
these mechanisms um and you know
bulletin board services are really
interesting great pres you know because
obviously I spent of course a lot of
time thinking about this I understood
that like this is a very radical
proposition including risky proposition
like will people be able to stick around
in a place that's lacking things that
they instinctually expect at this point
um which are not only like instinctual
but like actually literally addictive um
and so it's like you know it really is
like a detox so you take people out of
that like canot even work and of course
I was thinking about that I mean I think
one thing that creates an opportunity
for that is like it the Counterpoint to
the fact that it is so pervasive and
people are so disgruntled gives a little
bit of a boost to the opportunity to
have an alternative like it may not have
been in an earlier like 10 years ago um
as potentially obviously appealing like
why this like it's not as fun as that
but but now people know that like this
actually makes me feel ill like when I
do this all day maybe not everybody but
enough people um that there's an
opportunity there but going back to
precedent like precedent is interesting
here because like whether or not people
would just do it as some reactionary
thing um like these buling board
Services I started studying because
because I was trying to understand is
there any example of successful social
networking like without these popularity
mechanisms um and I was you know
surprised like looking at phpbb which is
like 1990s technology you know it's a
really barring thing that nobody in the
industry talks about I mean like I'm I'm
not an expert actually I should be on
the industry not my industry but you
know I I listen to some um you know some
of the pundits and the pundits and the
critics and things in the industry and
you like never hear them talk about oh
wow phpbb really interesting you know
Cutting Edge thing but it is actually
Cutting Edge like they still exist and
at huge scale um you know like the
probably the biggest I think is city
data um which has like on its form two
million people um none of these
mechanisms like completely absent from
it um and I was trying to understand you
know why why is that and there's lots of
those by the way it's not just City they
may be the biggest but there's lots of
just local websites with VAR thriving
communities of people who have none of
these mechanism they just use primitive
bulletin boards a lot of time
phpbb um and why is that um well it's
like obviously there like different one
reason is because like everybody there
is interested in the same thing um so
they they have shared interests um um
and they know that people are interested
in what they have to say and they also
are motivated because you don't have to
be famous in order to actually be part
of the conversation um like nobody has a
particular megaphone over anybody else
um and I was you know I'm shocked when I
look at phpbb uh individual contributors
like you can see for people you can see
how many times their their posts have
been read in Aggregate and there are
tens of millions tens of millions of
reads on complete no nobody's like like
you know Mr poodle 24 you know he's got
like 20 million views um like he would
be a celebrity in Twitter with that kind
of thing but this is in like this world
where it this doesn't even get noticed
um and so people are getting they are
getting attention um but it's through
completely different mechanisms and they
feel part of that Community um and so
like some of that guided some of the
design choices that that I went to
because I was trying to understand you
know they they're very different kind of
way presenting conversations and things
like like it's very more simplistic than
most of these networks like networks use
these kind of hierarchical structures to
like have conversations break down into
trees and things like that like phpbb is
like totally linear it's more like a
dinner conversation it's just the topic
is set by the first poster and then post
post post post post everything's just in
order the only thing you see is the
latest like there's no attempt to rank
anything at all um is just time that's
all um it's ridiculously simplistic and
that I wasn't necessarily taking a
lesson that we're just going to recreate
phpbb because I want to apply some of
what I understand about open-endedness
but I thought in some ways it's like
taking phpbb into the future this is
like the futuristic version of phpbb you
don't need to go to one website you just
automatically get sent to the people who
find what you say interesting um and we
will actually have one thing that that
we that is maybe not clear that comes up
in sort of implicit in some of what
you're saying is we will have some
quality mechanisms I'm not totally
against like you made an interesting
point which I thought was really
insightful and they notes about why
would you in pi breeder have things like
star ratings um you know you did do
things like that like you let people
have individual autonomy in their
individual paths but you still gave some
ability to express quality directly and
explicitly like why wouldn't that also
be true here I think that's
thought-provoking to think about that um
and but you know we what may not be
obvious even even like having visited
Maven is that there actually is a
quality mechanism in there um but what I
took was the minimal Criterion idea
which is like obscure probably um like I
wrote a bunch of papers with minimal
Criterion maybe well not a bunch maybe
like five they had minimal criteria like
there was no novelty search with minimal
CR minimal criteria novelty search there
was minimal Criterion in coevolution
poet had a minimal Criterion inside of
it it's this like obscure idea which
I've like always I've Loved for the
whole time that I've thought about it
which nobody else well maybe a few but
it never caught on like the way
something like novelty search did um
it's it's more obscure but I but I've
always really loved it and um because
it's it's a way of interpreting
Evolution um that I really liked um
where it's like you don't necessarily
think about it as on a Continuum of
quality where it's like Fitness is often
presented that way rather you think of
it either you succeeded or you didn't
like if you get over the threshold it
doesn't matter there's no need to rank
and the thing about this is is about
interpretation it's not like a right or
wrong type of thing because it's not
really saying any specific explicit
thing you should do but I just like
interpretations of evolution I really
like this minimal Criterion view because
it suggests it puts an emphasis on a
different aspect when you think about
Evolution um rather than the aspect of
competition which like I said like I
think leads to convergence so I'm trying
to understand what leads to Divergence
well the minimal Criterion is very
effective at having some kind of quality
standard like there's a minimal quality
standard you can't go below so you can't
degenerate but other than that you have
total Divergence um and I think that's
really appropriate for very subjective
domains where it's very hard to say this
is better than that um and it really is
that way with text and and speaking you
know because if you think about like um
stuff that's said on Twitter that's very
subjective like Pearls of Wisdom or
something um like those really don't
belong in a ranking it's quite odd
actually to have a like on a strict
Continuum like it and this I thought of
this because like someone a maven said
like a like a few weeks ago like listen
could you just everybody reply with some
really succinct pearl of wisdom that's
meant a lot to you throughout your life
so you get this big list of like little
Pearls of Wisdom from everybody and I
read through all of them and I just
absorb them in my own way because like
they mean specific things to me some of
them resonate more than others and I was
just thinking like what would I have
done if one was ranked at the top
because it would be the rich get richer
so this' be this extremely like top
level piece of wisdom so I wouldn't be
thinking about anything I would just be
like I don't want to waste my time on
the crap ones this is the good one and
then I can just leave and there would be
no thinking involved and I wouldn't get
to absorb each one for its own right
like how it interacts with me in my
idiosyncratic way and so of course there
is total crap in the world and we don't
want that um you know like I wouldn't
want like the reply that said like
everybody should just eat bananas or
something um but but there is something
above that threshold it starts to be
much less clear like how we should rank
things so I've always been interested in
this mental Criterion but what you said
and and we have that so basically we
have a minimal Criterion standard so
you're going to see this kind of
evolutionary Divergence where like this
stuff below that you won't see circulate
as much so there is a quality standard
but it's not a maximization algorithm
that's what's so interesting about it
it's just a minimal algorithm um so
above that you just get churn like total
churn round robin the way you put it um
but your point made me think because I
was thinking why didn't I just go to uh
you know the the pick breeder view of
the world like I we could have done that
too in this kind of context um and tried
to intermingle like ratings in some
level but I think like I thought about
this a lot just since I read your your
notes and I think I concluded that um
it's not that it's like there's a strict
principle that would like that suggest
you shouldn't do that it's more that
like I think the medium is it's the
interaction of the medium with the
quality standard is very subtle um so I
obviously made a decision but it was
intuitive and implicit like I hadn't
really thought about it a lot until you
pointed this out to me but I think that
um after thinking about it like there's
there's a mismatch between the pick
breeder way of showing things and like
this kind of text-based social media
content because I think the pick reader
stuff worked because I could really
quickly show you all kinds of
perspectives simultaneously like there
was only one section of the pck breeder
site that showed top ranked like alltime
top ranked was and like but but then
there was a newest top ranked like new
top ranked or the highest quality new
stuff there was random there was most
branched and so there's like a whole set
of different categories plus you could
like go into individual like you could
go to like faces or something um like
individual categories and I and I think
that that works there because they're
pictures you can see all of it at once
but I can't present all of content that
way to you and I think that if I gave
you top ranked um as an option like if I
gave you a bunch of different panels you
would spend your whole life there like
in the consensus driven world and it
wouldn't be Piper at all like we need to
get Divergence we need to expose you to
diversity and so like if I have this
very narrow window like the screen of a
phone and also it's much harder for
people to consume the content because
it's not picture you have to read it I
think the minimal Criterion works a lot
better um because it doesn't require you
to prevent present all these different
views simultaneously and have people
like like equitably look at all of these
different options like it's just like
totally intuitive it's just like every
other social media from their
perspective but under the hood we're
taking care of things to make sure that
this is Divergent and has like a bottom
where you can't go below it um so think
where we get to that point yeah because
when I when I started using it and we'll
introduce it properly um you know for
folks to understand but um I was met
with a little bit of mild confusion
because I didn't understand what was
going on so we all have a mental kind of
reference frame to understand the world
and we were talking about goals and
planning are quite a common one so um
the thing about pick breeder is um I
mean the clues in the name with the neat
algorithm there is a topology there and
in my mind and in the user experience
you can actually see the topology you
can understand the structure and on
Maven my my read of it was that it was
quite flat so there's this minimal
Criterion but we don't know what that is
and then so it's a bit like the bias
ference trade-off there's some structure
and then like you you allow for complete
variation um above the minimal Criterion
and then all of those posts are kind of
round robin um allocated to to folks who
use the system and then um I guess I'm
naturally looking for the next level of
structure now based on your answer I I
agree with you you convinced me that the
the kind of the will store status game
thing um it might be a component of the
reason why Facebook is viral but I agree
with you look at my Discord server look
at you know these PHP websites people
love recognition they they're interested
in things they love this serendipitous
process so yeah absolutely that that
completely works but I think what
Facebook did though is is they chose a
proxy for interestingness which perhaps
is quite deeply ingrained with us
because it's this social state thing
that we all care about very much and
what you're desperately trying to do I
assume in Maven is to not choose any one
topology but to allow the topologies to
emerge naturally but I guess my point is
is that without the user experience kind
of guiding what the topology is then
it's almost like you don't get this
reflexive feedback loop that you need
for the system to work yeah there such a
complicated thing I mean there's a lot
of points to that so like Facebook in
its genius um
is you know that I don't know if it's
genius as much as obvious like I feel
like this were the first things I would
try too like like it's like I would put
a like button it's just such an obvious
thing to think of um I think what what
wasn't necessarily obvious was how
addictive that is like that is such uh
such a like a worm into human psychology
like it wouldn't be obvious at the at
first I mean I noticed it like getting
likes on a post in an X or something
it's it's like very distracting and
consuming like it's when you're poting
is getting a lot of likes and that is
weird cuz it's just a number going up
like there's there's nothing actually
happening um like it's not like I'm
learning anything or something but I
can't look away from it anyway um and so
you could say that's genius because it
hit on something really really powerful
um and I don't think we can create
anything as powerful as that like that
is it's just like you know it's it's
like um you know um you know green beans
can't compete with heroin or something
like it's is like heroin is going to win
like on the addiction scale um but like
so we're gonna that is an uphill climb I
think at some level um that we have to
deal with um but there is but in terms
of structure there is still structure
like it's it's it's still not as
powerful as that in terms of an
addiction mechanism um but we certainly
have structure I mean it's not just like
you kind of sort of present it as kind
of like a flat like thing where it's
like it's like you totally have to just
um derive your own structure from
reality you can't get any from the
system itself but you have to the thing
is what we tried to do there's two
things we try the first thing is we
tried to replace you know the the kind
of addiction mechanism which is this
like um this kind of a self-affirmation
that you get like when you get these
kinds of signals like a like signal or a
follow signal with something else to do
because you need something to do to
occupy your time um something that feels
like an activity and that was to follow
interests um so that's why we said you
you follow interests and not influencers
was like our first slogan it's current
slogan maybe we'll change the slogan um
but so like yeah we see that so like by
following interest of course like your
world will not look like my world um
they're all customized around interest
um and you know the system is using AI
to generate interests so those interests
it's not like you just decide what your
interest you can if you want you just
type them in um but you're seeing them
surface constantly and we've definitely
seen people have been using that the way
that it's intended which is to
constantly expand that like surface of
serendipity um because they see
something pop up you know it's like you
see something like AI for um uh for
architecture and it's like yeah I hadn't
thought about that so it's like okay
I'll click that one and then I'll follow
that and now that becomes something that
they're interested and they didn't know
and you definitely see people growing
their interest graph um and so that's
that's a new activity that we've
introduced I don't think it's as
compelling as getting likes or follows
but it's something that's it's a it's a
recreational activity and the other
thing is though that you you you
mentioned like the reinforcement signal
like that that's something that
obviously is Rel it's like directly is
the likes and follows too but it's it's
important um for for keeping people um
engaged and there is a subtle thing
going on like that um I mean in addition
to the Minal Criterion which is a weak
reinforcement signal but there's the um
the fact that replies get resurfaced in
our system like our system is very
respectful of replies like in a way that
like um X isn't for example like X
sometimes you see replies in your main
feed but it's not systematic like
generally that's not that common um I'm
not sure what the algorithm is to decide
but you don't see them that much but in
ours every single reply goes back to the
top and this is like respecting phpbb
style you know because they like the the
top thread you'll see when you go there
is always the one with the most recent
reply um and so we kind of show like the
last few replies always like whenever we
like pop something back up to the top of
the feed um and this is basically
causing that thing to get more exposure
it's just implicit um and so like the
most engaged posts you see more and
you're going to see like what's most
recent on them so there is a mechanism
and it's even arguably objective which
is you could say it's bad in the big
picture but like you point out like the
real truth is it's not that you don't
want any objective mechanisms that you
want to balance um like like we can have
people say something as high quality and
pick breeder and still get an overall
Divergent process but you can't have a
dominate that's a big problem so I'm
just trying to reduce the domination of
the objective component cuz I've always
always thought like when it comes to
Quality and diversity the real problem
is that quality kills diversity when you
make it like the primary thing like all
the quality diversity algorithms are
about trying to put quality in a box so
it won't destroy diversity because if
you're not careful that's what will
happen um and so we still have some we
still have some structure because of
that it's just like through the um yeah
through the actual exchange uh between
person in person um and you would start
to notice that hopefully implicitly like
as a US
that like the big conversations keep
coming back over and over again and
that's what phpbb users experience so
that's been shown to be uh enough to
keep people
around from an engineering perspective
do you have a cold start problem and do
you have any thoughts on how the
Dynamics of the system will change at
different levels of
scale yeah there's definitely a cold
start problem obviously of course um we
we Face a stark horrendous version of
the cold problem because I mean you have
uh just the general cold star problem
for any company then you have the cold
star problem for social network which I
think is like generally really bad um
and then you have a cold star problem
for a social network in the world today
which is worse than it used to be um
because there already are all these soci
established social networks you know
when when X started or Twitter started
uh it was a lot easier and in fact um
one of our investors our leader investor
is EV Williams um who is one of the
founders of X or of Twitter when he
founded it um so we've had a lot of
conversations about like how did he
start Twitter and stuff like that the
story there is just uh um of course it's
just impossible to reproduce today you
couldn't do it that way um it was a
different world where things like this
could catch on um organically just
independently but now you're fighting
against the fact that people already
have homes or more compelling places to
go because we're saying come here and
talk to a few dozen people or he could
go over there talk to a million people
like what which would you rather do
that's a horrible cold start problem
then it's even more exacerbated by the
fact that we don't use addiction
mechanisms so we're not exploiting human
psychology in the in the usual way that
can get you like you know off the ground
with something like this um so we
obviously have an enormous cold start
problem um and so but the thing about
cold start problems is I know much has
been written and said about cold start
problems um but I think like one
important insight about cold start
problems and by the way I'm not an
authority because I haven't succeeded
yet so don't take my word for this like
I could be wrong but what I think is
that um you know every cold start
problem has to be solved in a way that
is different from the past um like
there's not like a formula for how to
win in the cold start race so there's
all this conventional wisdom but it's
from the past it's like this is how it
was won before the next thing that cold
starts successfully it'll be totally
counterintuitive it will be something
nobody thought of as a way of handling
the cold start problem and so this is a
unique situation that has never been
confronted before like how can Maven
actually solve the cold problem and it
will be solved in a way that doesn't
reflect conventional wisdom um and so I
think you know what gives us the
opportunity so they we're obviously
working on this from many angles because
that is our problem is the qu start
problem um like we have but we have some
opportunities some inroads into the cold
St problem uh one of them is just like
we do have the the Goodwill of people
because of the fact many people resonate
immediately with the idea of getting
some way out of all of the mess um like
it's now in the air and you know some of
our investors like say and like they
keep pounding on us too they're like
look this is the time to act like like
look everybody's upset like some new
article comes out but it's in the air
that like everybody's disgruntled in
social media for numerous reasons and
it's not it's like P it's at a general
public level like pundits are saying but
also individual level like individual
people people say you know I just feel I
feel slimy and yucky and anxious and
tired after I go through my feeter
there's like terms like Doom scrolling
and it's like that creates a huge
opportunity you know it's like an
opportunity to actually go through a
feed and not feel that way um that's
something people have been telling you
so I think if enough people can latch on
to that that's something something else
that I think is going to help which is I
wanted to preview a little is that we we
are adding other features too like
obviously you're just seeing like
version one here we're going to add some
other cool features I think like there
some of them are like just gestating
right now but um they going to be some
more pick breeder is things you can do
in the service these are you know some
people say you know there has to be a
single player mode like that's one way
out of the cold start problem that's one
thing you hear sometimes like something
fun to do if there aren't other people
around which makes sense because if
you're starting cold there's no other
people okay we're taking that to heart
there'll be there could be some fun
things to do like that um so we're going
to you know approach this not just at
the high-minded level but also at the
Practical level too but hopefully coming
at from these all these different angles
um and exploiting the fact that like we
actually are saying something virtuous
which is very unusual you know we're
taking away all of these nasty things
that exploit human nature and just
letting people just be themselves like
you can just pursue something for
curiosity's sake you don't have an
incentive to get attention anymore
because you can't get any followers um
and so like what would be the point so
you also don't have a reason to be
embarrassed because like you don't have
followers they don't care um if you want
to go ask something about something you
don't know about cuz I feel I have
enough followers on that I feel like I
don't want to say certain things cuz I
know what they expect and I'm going to
sound like an idiot you know because I
actually only know about the things I
know about but there are some things I'd
like to talk about but like I don't
really know well about them very
uncertain but I just basically don't
feel comfortable doing that because I
have all these followers well you don't
have that problem here um and so you can
do all these things and I think that
that can be powerful because you know
people would will like to have some
relief um from this kind of pervasive
nastiness which like just like surrounds
everything I just like like wonder what
it's doing to us that every single thing
you do is launched into the most cynical
darwinian competition you could possibly
imagine it's like it's not even like the
big things it's like every single
statement like just one little reply for
like one sentence it's immediately
launched into a darwinian competition
for the top comment and it's just crazy
like what is that doing to our
psychology you can go here you can relax
be yourself pursue your curiosity I
think we have a chance because of that
the reason why I asked you the question
about the scaling though is is it was a
bit of a trick question um Facebook they
went through this kind of I mean you can
think of it as a revolution that
Facebook and Google um invented this
relevance ranking which is this idea
that we've got a whole bunch of data in
our system and and we do some
collaborative filtering and machine
learning and we do some objective
optimization and and we create these
convergence things and and in a way
that's very good because you know
there's lots of complicated information
and it's a way of discarding what's not
relevant and giving you what what is
relevant but on your system it's almost
like going back in time to the 1990s
where you just you just have a PHP
bulletin board and you just do Rand
Robin and you just give people what they
want and so my observation was that it
works brilliantly now at the very
beginning you almost don't have a cold
start problem it works great but but but
the question is more like well what will
happen when you have a million users
yeah yeah missed that part of the
question that that is a really
interesting part of the question um you
know probably my mind doesn't go there
first because I'm I'm I'm like that's
like the best problem to have so that
that's like what I think about less I
like you I really got to worry about the
problem of are we going to have a even
like you know a 10,000 users um but like
yeah that's really interesting to think
about so what happens at scale and and
many people have commented this like the
very earliest users on Maven you know
loved the nice Community everybody they
could trust like it's just like
everybody's really interesting thinks
about what they're saying obviously you
pour in a million people that's not true
of everybody anymore I mean people have
I've heard people say like about uset if
anybody's old enough to know remember
uset I know some people old enough to
remember newset that they say that was
the Golden Age of social media like
everybody was interesting and polite to
each other and just said said things
sincerely they weren't looking for
attention like that that kind of uh you
know that that kind of uh us that era
stuff
um that's going to be um and people
people talk people remember that from
social media um and and and that is that
that is going to change its scale and
people say like why did us that fail or
like not fail but why did it sort of go
out of style well because the millions
of people poured in that it was the it
was the smart people I heard somebody
say this recently like it was like the
top 10% or something of IQ was there and
as soon as everybody else came in it it
went downhill um I'm not endorsing that
I don't necessarily think IQ is what
tells us whether somebody's be good at
social media but but it's it's somehow
there's like the best people of some
kind of theory and but I do agree I
don't agree with that but I agree that
like obviously the more people you P the
more people you're going to get that
aren't doing what we wish they would do
they're going to make the experience
worse for other people um how does that
scale um but I think that first it's
just super interesting to think of the
minimal Criterion at scale like that is
that is that is going to kick in more
like right now minimal Criterion is
almost irrelevant and that's why I don't
know I probably no one would notice it
one way or another it's it's not
necessary at the moment because the
people who have come in generally have
some connection to me or my co-founders
and so there's a level of trust that
they're just generally people have
similar interests and like everybody's
sort of on the same page there's a few
there's a few people who came in who who
probably weren't great um but like it's
not really a problem at this point um
and so um so there it's yeah you've got
this kind of like Community we almost
curated they're nice and and so it
doesn't really matter you might not even
I don't even know if you knew there was
a minimal Criterion I'm assuming you
didn't know that uh when you visited
there you probably I would assume you
wouldn't know
that is that true it looked like there
wasn't but I assumed there there had to
be you because um you You're Building A
system that because we can think of it
topologically so on on Facebook it's
quite homogeneous and in your system you
can think of this landscape where you
have Peaks going out to the Horizon and
it's it's much more even and balanced
and then you might argue well there's a
real risk that you might have something
very important which doesn't really get
mixed together because you so many
people are independently thinking of
very important things and they're not
being raised up because we don't have
this kind of homogenizing force but but
then you can bring in well you do
because we're in a globalized world and
everyone's everyone lives in the same
world everyone watches the news everyone
uses Facebook and so on so there's this
weird kind of like convergence from
other platforms that will leak into your
system that's a so are systems leading
to convergence in general like outside
those systems that that's the
implication of what you're saying um so
actually I would just just so I don't
lose that train of thought about the
Criterion I do think it's really
interesting to scale I just put that
like to hold that point point in the
conversation too CU like that's um you
know we see really interesting Dynamics
in these Minal Criterion algorithms like
when we run them in like like with
without people and and they they they're
very good at diverging and in and
filling up a space of possibilities um
and so I think at scale you would start
to see that true filling um like filling
up because the space of possibilities
that like we play with in these toy
domains like a robot in a maze is not so
interesting but the space of
possibilities of human thought is super
interesting
um and so I think that's one benefit at
scale that like you've never ever seen
an experiment like that at scale with
people um that will be interesting but
you're saying that nevertheless like the
world is inside of this kind of
convergent Loop like it's it's it's most
systems and it's not just like
conventional what you might call social
media but things like YouTube look like
they're they're all working on this like
based kind of convergence stuff and I
mean I see commentary in the news every
day even even today like about um why
things like Pitchfork are closing down
and stuff like it's like these these
ranking algorithms are turning into the
controlling force of culture um and I I
do wonder how how much that's affecting
uh everything because you know like like
things that seem weird to me culturally
that I don't understand like for example
it seemed like until around the year
2000 that like rock music was evolving
in some way like you could be pretty
sure that like the music of today is
really different than 20 years ago um
and like I was enjoying that until
around then and then seem to stop like
now it's like almost 25 years later like
I it doesn't sound much different from
what it was 25 years ago and I'm I'm
like sorely disappointed I expect it to
be in shock by now um and I wonder if
it's because like there's this major
convergent mechanisms like across
culture are you worried about um
objective measures creeping into Maven
in the future the ultimate like version
of drifting towards quality over
diversity is is a sellout like if I did
that um but it's you know it's I would
be a little worried um cuz yeah like
commercial pressures exist um but uh I I
don't imagine myself doing that at the
moment that seems
unlikely I mean that's our
differentiating Factor too it's kind of
interesting some people have said like
you know you you going to have to
introduce like these things in like
people just like somebody said to me
like um the only reason anybody going to
go to another social network is can take
their followers with them like you're
going to have to have
followers and so I'm just like well but
that's our different in Factor also so
it cuts both ways like if we just have
follows and likes like why would why
would you go to us you already have that
in your other network like it's just
absolutely makes no sense I mean I
understand that's like the argument in
things like um threads or blue sky or
Mastadon like they are basically just
Twitter run by different management um
and then like you know you kind of try
to import your followers um they all
have a uh like some other kind of you
know motivation like why why should you
just go play the same game somewhere
else um some of them try to say like we
have a more kind of like fun-filled
culture we're not about arguing but but
I mean who's to say that you can't
control culture um and so you know I I
think like create creating another one
of those is just not not going to do
anything it's going to be an absolute
failure from business perspective so in
some in sense sense it's an advantage
that we are so different like it it
allows us to differentiate in this
market um and uh I'm not sure what we
would gain by becoming more objective
other than and just like having no
differentiation yeah and I've been
reading this book broken code talking
all about the evolution of of um you
know Facebook and uh Zuck had this
methodology of just copying everyone
else's ideas as quickly as possible but
your one is so paradigmatically
different even more so now that I've
understood it more deeply speaking with
you that there's no risk whatsoever of
him copying it um which is actually a
bit of a mo right right yeah exactly I
can't get rid of lik that would be or or
friends I mean that' be crazy that's not
going to happen I mean they could try to
start a separate service but I I think
it's way outside their philos philosophy
to do something so crazy um and so
nobody else can get rid of it either
it's X isn't going to get rid of likes
it's not going to happen so and I I by
the way I think those Services still
serve a purpose you know I I think of it
not as social I think of as announcement
service know like I I feeling it's
really weird that we think that social
means having popularity metrics but like
to me it does help you to get a
megaphone and it's useful if if you want
a megaphone or if you want to listen to
the people who like have you think whose
megaphone you want to hear like I I
don't feel like we should get rid of all
of that it's just very convergent
because there's only so many megaphones
to go around um but there's nothing
neily like there's a lot of bad side
effects to it but I don't think we
should just completely get rid of it or
that it's necessarily the case that
Maven has to replace all of that like we
can have something good for having
megaphones and making announcements to
our followers and we can have something
for exploring and curiosity um and they
can coexist and but yeah I don't see
Zuck or anybody else in this field like
going going in our Direction um it's
just impossible yeah there was this
really interesting thought experiment
about a a panopticon which is this
hypothetical building where I think it's
a prison and everything you do can be
observed through a kind of series of
mirrors and the whole idea is that when
you know when you're in front of the
judgmental eyes of others you don't
explore um any new interesting behaviors
you don't discover yourself and so on
and we were talking about Yan Lon
earlier and in a way you might feel
sorry for him because it's not
necessarily that he's incapable or
doesn't want to talk about other things
it's almost like because his personal
identity and because people's um
understanding and expectations of what
he says are so kind of defused and
solidified in the system he has no free
will he can talk about nothing else
because that's what he's supposed to say
and the only way to break out of that
pattern is to kind of step away from
your social personal
identity yeah which is really hard and
risky and frightening to do that um so
it's it's true I I do think he like
almost everyone else in his position is
trapped um that's why I want it was very
interesting to me to uh experience just
dropping out of my field um which I
effectively did you know because was
like machine learning research and then
just like nothing um and um my mind like
just outside of Maven even like it just
completely started going in New
Directions like in machine learning you
know cuz it's like it no longer mattered
like I have no incentives anymore um
like like I don't I'm not trying to
satisfy anybody's expectation
professionally um I don't have to
publish a paper so I just um I just
noticed immediately like a Liberation in
my thinking which yeah made me think a
lot about this issue of why people start
to get stagnating when they get older um
like is is it just aging or is there
like more to it you know because of just
like the the social effects being so
powerful um so i' I've kind of been
enjoying just like my mind being
completely free um not not having any I
mean I still have social media
expectations so that's still true like
if I talk about AI online I know what
people expect but like in terms of just
like thinking about AI or what I need to
do I don't need to do anything just
think about whatever I want to think
about it's kind of
interesting yeah I've often thought
about this um you know yoga teachers
talk about the tyranny of your Social
embedding and of course they don't use
that technical language which they'll
talk about it in terms of um not
thinking about your social world and
just being present and experiencing
things as they are and just being but
basically what they're talking about is
escaping the the tyranny of the social
World which erodes your agency and
forces you to do things and makes you
worry and um yeah I agree with you it's
not about aging um I I think as you as
you get more and more sclerotic in ins
sconed in the social world you kind of
like you don't even your your
optionality just just just disappears
yeah yeah it's it's very true it learns
this epic tag cloud and it's not
hardcoded in any way it just grows over
time it's it's a bit like a huge Cloud
you know a new interest arises um and it
might be a side effect of old interests
you know this is sort of like the idea
of just like diverging kind of like
going into new areas from where you've
been you know because if you're talking
about computers then you might start
talking about AI is as a side effect of
that now ai is introduced to the system
it's a new interest at that point
computer computers was an was an
original interest now we have ai as an
interest um it's implicit that like AI
is related to computers like that's you
think in a graph they would be related
in some way um but we don't actually
have like this massive data structure
that shows all those implicit
relationships they just exist implicitly
we extract them at certain points so
like when you go to the profile of an
interest because like I said you can
follow interest as if they're almost
like people and has a profile like one
section of of that profile are uh
related interest and those related
interests are known for reasons like
that they co-occur um and so it's it it
understands that these have co-occurred
before and it figures that out at that
point but the whole graph is not stored
in any one place at least not now now um
so it's an implicit graph that's growing
um and it has different aspects to it
you know it's not like one graph either
because there's also uh interest graphs
that go through people you know because
you can see that I have these interests
and then I overlap that overlaps a lot
with you and then we can see what what
are the other interests you have and so
those are interests that are likely
interesting to me too um you know
because like we share a lot of interest
anyway um and so we could actually say
you know what is the graph that goes
from interest to person interested in it
to other interest to another person
interested so there's a there's a
there's a graph like that too um and all
those exist implicitly inside of the
system and I think eventually we would
if if the system is successful we would
analyze those like we would try to
extract some parts and let you see it
more explicitly because that would be
fun you know it would be fun to see the
graph to navigate the graph explicitly
along its edges and just see what this
thing looks like um it's a little bit
like like visualizing like the the
family tree and evolution or something
like what's related to what um and uh
that tool does not exist yet but I
imagine we would eventually build it um
just because it would be fun for people
to see and probably also useful
scientifically for for
for researchers Professor Ken Stanley
it's been an absolute honor as always
thank you so much for joining us
today thank you again uh this was a
great opportunity I always love being on
this show be happy to be here any day
amazing amazing
