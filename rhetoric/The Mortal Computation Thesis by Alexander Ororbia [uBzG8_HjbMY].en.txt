yeah thank you for having me Michael uh
and thank you everyone for coming to the
talk uh so I'm gonna talk to you today
about some work that my friend Carl and
I have done we call it the Mortal
computation thesis uh and I think it uh
complement some of the things that I
know uh Michael's group does uh actually
in fact we site particular uh mortal
computers that I will get into a little
bit later uh and we can talk about that
perhaps so um just very briefly who am I
so I'm Alex Ria and I'm the director of
the neural adaptive Computing laboratory
at Rochester Institute of Technology um
these are my students as you can see and
we work on quite a few things but our
primary focus is Building biomimetic
Systems and the learning algorithms and
computational architectures uh that
would facilitate their learning and
inference uh with the goal of obviously
building things uh in Hardware substrate
so again neuromorphic Computing might be
familiar to some of you uh we also work
on a lot of things uh based on the free
energy principle some of you might have
heard of predictive coding or active
inference and my group contributes to
that um and we have a lot of
collaborators but uh this is just our
brief little intro um so you might be
asking what exactly is Mortal
computation and if you're familiar with
it you might be you might be aware that
Jeff Hinton uh last year came up with a
phrase called mortal comat computation
in one of his works the Ford Ford
algorithm paper the idea effectively is
that software cannot be divorced from
the physical substrate or Hardware in
which it is instantiated and the idea is
that the calculations and processing are
embodied and in fact Inseparable from
The Medium the medium uh when the medium
breaks down stops functioning the
software ceases to exist and cannot be
carried out on another medium this sort
of effectively says that the software
should die uh as long along with its
quirks and its properties if the
hardware or substrate that executes it
ceases to function uh and of course this
is going to have implications for Edge
devices energy efficient systems and
Robotics uh and so on and so forth uh
however this challenges the notion of
immortal computation in computer science
it's sort of a foundational idea that we
can essentially write our program
independently of the medium that we're
going to execute it and that this
program or software can be copied or
executed on another GPU or TPU server
for example if you're doing machine
learning uh and it's going to pretty
much run the same uh it's not going to
have any particularities that are tied
to its actual medium and so effectively
the knowledge and characteristics that
your program acquires is done
irrespective of the medium in which
you're executing it so this is the work
that maybe I believe you were linked to
it's a little bit long so I don't blame
you if maybe perhaps you didn't read at
all um but this is uh work that we sort
of did like a review and then sort of a
perspective on what Mortal computation
really should be as Jeff sort of just
introduced it in about a couple of
sentences so Carl and I wrote 40 pages
roughly about it so why exactly mortal
computation well part of it is a
thermodynamic consideration and this is
basically getting at the relationship
between information processing and
thermodynamic efficiency the idea
effectively is that we want to adhere to
land our's principle and these are just
some principles I'm going to briefly
introduce those of you that might have
deep physics background might even
understand them even better than myself
the idea is that there is a minimum
amount of energy required for any
irreversible operation think of like
erasing a bit on your computer and it is
proportional to the operational
temperature of the Computing system and
I just give you the relationship here KB
is boltzman's constant and the idea is
that in ireverse ible change in a
computer stored information requires
dissipation of a minimum level of heat
to the environment this is paired with
the jar zinski inequality and I have a
floating bullet point there but that's
because I wanted to remove some
unnecessary detail but the idea is that
we're talking about the difference of
the free energies the physics free
energies between two states X and Y and
we are saying that the difference
between them can be constrained to be
equal to the average of the work the
physics work done from all paths taken
from perhaps an equilibrium State X to a
typical non-equilibrium State Y what is
this really mean in plain English well
roughly we can know something about A
System's equilibrium by observing the
system when it is not at equilibrium um
and so the main takeaway when you pair
these ideas together as Carl and I argue
is that there's a lower amount lower
bound on the amount of thermodynamic
work that you need to do uh to change
information content in an information
system
and so this of course has wonderful uh
implications if we can get our
intelligence systems that we try to
strive today in artificial intelligence
to emulate to build something that
adheres to inmemory processing and
effectively this just means that we are
changing the computer's information
content and we are saying that it's
equal to the inference belief updating
in response to external privation so as
the Computing system is dealing with an
environment uh we essentially want to be
working at as close as possible to the
substrate these calculations should not
be divorced um and then of course we can
tie this as I'll show you a little bit
later to the variational free energy
formulation and effectively that when a
Computing system or an intelligence
system is minimizing its variational
free energy it's the same Minima as the
thermodynamic free energy and there is
equivalence in work that we point you to
um and so of course the idea is that we
need to essentially try to uh circumvent
What's called the one noyman bottleneck
or the memory wall and that's the idea
that when we are doing things you might
be aware of deep learning and what is
rocking the world of artificial
intelligence to this day we're
effectively executing uh our programs on
software that is in random access memory
and as you can see in the bottom left
diagram there's a lot of expended energy
to start moving information from
long-term memory uh depending on your
Computing structure to uh random access
memory and so we essentially would like
to overcome that and that's sort of what
uh uh just one common example that we
see today in memory Computing is
neuromorphic Computing where we're
effectively designing our biological
models our neuronal models actually as
close to the hardware as possible and
using things like BS to adhere to
synaptic connections and so on and so
forth But ultimately the idea is that
realizing thermodynamic efficiency of
beian computations which is effectively
what biological systems we are doing
requires updating in memory to be Baye
optimal is to be thermodynamically
efficient and vice versa this also has
some wonderful implications for green AI
which is this argument that we need to
essentially figure out how to do the
intelligent operations we do today uh
without expending M quantities of energy
uh Chad gbt and Transformers themselves
are pretty
expensive so so then there's also
cognitive philosophical motivations I
won't dwell too long here as well but
the idea is that there is in cognitive
science the embodiment thesis or the
embodiment hypothesis and in activism
which is just effectively saying at a
high level that the mind your mind or
any mind is grounded in its sensory
motor en comping so the idea is that we
are shaped by the actions that we take
the nature of mental activity uh depends
on your body effectively you need to be
uh in some type of actual physical
instantiation you cannot have what is
known in classical cognitive scientists
known as brain inovat so the idea is
that we don't have something called
isolated cognition we are actually
primarily driven by our body and an
activism takes us an extra step further
uh and the idea is that we are dependent
on our environment our cognition is we
are coupled to an environment we act and
effectively that affects us as well as
affects our environment so a mortal
computer in effect is an active
participant in the generation of the
information that it processes thus
shaped by the consequences of how it
acts and has acted on its Niche
effectively this is called Niche
construction um and then we also talk a
little bit about some other nice
Connections in naturalist philosophy and
existentialism that actually refers to a
little bit the initial quote that you
might have seen in the paper by sain
kard um but the idea is that there is a
finite to to life it endows us with
purpose entails reproduction and
motivates us to pass on knowledge to
Future Generations um ultimately death
is a horizon that shapes our behavior
and Consciousness now of course while
mortal computation doesn't go as Broad
and as far-reaching as existentialism
and other aspects of natural philosophy
does uh it does actually we do pull or
extract a small part of it talk about
that even animals in any organism is
implicitly constrained and conscious or
maybe not conscious of the fact that
they have a finite Horizon and they act
accordingly um and then of course
there's some other parts that uh we
touch on in our framework about
operational closure which is just the
idea that the system must Auto undergo
autopoetic met self assembly and
self-maintenance to keep separate its
internal States from its external States
this is going to motivate the Markov
blanket construction of the Mortal
computer I'll talk to you about later
and then of course the idea of sense
making which is that there's a mutual
dependence between external processes
and an entity whether it's a biological
organism or rather any mortal computer
as we generalize because a mortal
computer does not need to be artificial
we are all effectively mortal computers
a biological system must distinguish
itself from its Niche yet be coupled to
it uh in order to persist in that Niche
and this will motivate the idea that we
don't want to dissolve in our heatbath
we don't want to uh cease to exist so
effectively a part of the work that
again you might have read is a it's a
review this idea is interestingly enough
echoed for many many decades across all
kinds of thinkers and engineers and
wonderful ideas have cropped up
throughout time so we sort of unified
them and scoped them out obviously this
talk given time constraints is not going
to possibly go into all the details um
but I will give you a swath so sort of
you can think of the paper or the
concept in terms of three particular
slices that's why it's called the three
slices of moral computation we have a
biophysics physiological naturalist
philosophies interpretation in the top
left uh towards the top bottom left we
have a cybernetics interpretation and
then a cognitive science interpretation
and I'm going to give you some of the
highlights this so we're going to start
with the biophysics aspect of our
framework and I'll just leave this
diagram to sit here as I explain just a
few of the key Concepts to sort of parse
it so the idea is that a mortal computer
self-organization constitutes its
thermodynamic and metabolic efficiency
and we talk about metabolism and
autocatalytic closure as some motivating
Concepts but effectively these ground
it's the Mortal computer's agency or its
ability to adapt ultimately we need to
understand that a mortal computer is not
a thermodynamic equilibrium and it
operates as a dissipative system given
that energy and matter would be lost uh
by essentially uh in the idea is that we
are adhering to the first order uh first
law of biological thermodynamics which
allows us to to uh reconcile and ensure
that we are still adhering to the
classical Second Law thermodynamics uh
entropy has to increase in the
environment but in uh biological open
systems we don't see that we see entropy
decreasing so the ideas you have to kind
of view it all as one big close system
you need the environment and the entity
itself um but ultimately a mortal
computer or any entity that could be
considered one its metabolic
organization stands far from
thermodynamic equilibrium and so
ultimately needs to forage like any
living system or any system to continue
acquire new resources this sort of
motivates like that bottom level uh the
diagram the metabolic processes are
essential Primitives this is something
that Carl and I chose as language to
pull a little bit from cybernetics and
bring it back into the biophysics
interpretation But ultimately these are
the foundational components of a
computer or a mortal computer or any
system arranged within a morphology of
course uh and then other we need
homeostatic or horo
processes that live on top of it this is
our active regulation of those essential
Primitives and the idea is that we have
metabolic processes we discuss reactions
that use energy to trans materials into
structures that then harness further
energy to transform transport material
eliminate toxins or surplus material um
and of course this is sort of our way of
keeping track of set points if we want
to stay within a certain range or near a
particular value and so we need to be
designing out homeostatic processes
which ultimately by the way you'll
notice that there's these arrows for
influence in the diagram so all of these
processes in effect should have some
type of influence on their sensory motor
action this is motivated actually a
little bit by work uh by Eggbert and
others um on chemotaxis and talking
about metabolic dependencies and the
idea that action is shaped driven by
your metabolic function sometimes it can
be entirely dependent on only depend dep
on that um but we sort of generalize it
a little bit to allow some design
flexibility on top of this many of you
are most likely aware of what allostasis
is but we also need allostatic processes
because this is instead of having error
reaction or reactive processes we have
error correction processes as well so
this is what serves homeostasis or
homeis precludes future deviations to
the essential variables and then of
course at the very very top is our
autoptic autonomy level and this is
where we need to account for the fact
that a mortal computer if to be you know
a unification of artificial as well as
biological systems uh needs to have the
ability to make itself from within it
must continuously reproduce organize
maintain the relationships between its
parts uh and as well as uh do this
without external intervention it must
come from within and of course then we
have the Notions of morphogenesis
because the idea is that the Mortal
computer needs to persist long longer
than its actual physical instantiation
of its components so means its actual
organization or relations live longer
and that's its identity throughout time
this will also motivate the self-
evidencing aspect of mortal computation
and it's continuously reproducing itself
um and then as I mentioned there are
motor sensory motor dependencies that
couple this to its Niche so ultimately
what is this really tell you at the
highest level uh well that we need to
essentially design our mortal computer
system with the niche in mind the niche
cannot be dis decoupled or disentangled
we need to understand the properties of
the niche as well um again some might be
wondering from computer computational
backgrounds won't this make the system
rather brittle because it's rather
dependent on the body and the niche that
you are designing but that's sort of the
point the idea is that your behavior and
your cognitive functionality is directly
dependent on your physical instantiation
and the environment or niche in which
you live so again the organization
closure of the Mortal computer it
depends or sorry it's that means that
the Mortal computer operates on the
basis of self reproduced structures um
and you know as I've said already the
Mortal computer is autoptic um and so
this is where we have sensing actuation
and we need to be uh modeling or and
essentially accounting for energy
exchange and matter transformation and
so again at the bottom right is our
reinterpretation of the homeostatic
dependencies of some good work over the
years so we just have that as a little
oh it was called home well we
generalized and called it homeostasis
dependent but you know it was originally
called metab metabolistic or metabolism
dependencies so now we can move on to
what we call uh the cybernetics backend
and again this could take a while but
I'm not going to dwell too long on it um
effectively what I want to say to you is
there's a couple of Concepts that we can
bring from classical cybernetics it's
sort of like the Forerunner to uh
aspects of computer science and
certainly to artificial intelligence but
ultimately cybernetics deals with this
concept known as retroaction a system
must incorporate ends or goals into its
means or mechanisms in order to ensure
goal attainment is absolutely inevitable
or almost inevitable and so the system
essentially the question that
characterizes cybernetics is how can a
system learn what it needs to know in
order to act effectively this gets into
the Notions of self-organizing systems
Elementary parts and local interactions
with upward and downward cation and we
detail these a bit more in the paper and
point you to plenty of references for
all those details but the idea is that
the system is dealing with variety and
this is the central concept behind uh
cybernetics and you can see as you see
on the slide it's the number of
distinguishable States in a system State
space another way you can interpret it
is the degrees of freedom that a system
has in choosing what state it will be in
uh this can be reduced via selection and
this leads us to sort of organizing and
another aspect of cybernetics is there's
a lot of principles and laws uh and so
we try to organize a couple of them into
three Central pillars that we felt were
uh useful and complimentary to the
notion of mortal computation so we
organized them into as you can see in
the bottom uh stability regulation and
growth and so effectively stability is
going to relate really nicely to
homeostasis and hesis as we discussed in
the uh biophysics part of the talk and
the IDE is that the system ultimately
its goal is to reach a state of
stability or Ultra stability and all
this means is that it performs uh
selections to cross state space to try
to reach new States until it converges
to a place where essentially doesn't
need to alter its part-to-part
relationships it sort of stabilizes and
can Ultra stability means it's found in
a tractor it really likes so this is a
good place for the system it's very hard
also for it to leave that particular
state so Ultra stability is effectively
it's able to maintain its homeostasis it
keeps those variables near its set point
it has all that it needs to sort of stay
uh in a good configuration and then of
course there's other principles like the
principle of asymmetric Transitions and
these are things that are characterized
deeply in cybernetics system in unstable
configurations usually moves to stable
ones but not the opposite um and again a
system as it rejects fewer States as it
reaches more stable ones the variety
decreases as a the system becomes more
organized again it's sort of converged
to a good State um you can equate
variety with thermodynamic free energy
um but the idea is that then the system
does work or it exerts its variation to
reach those stable States if it is
stable it's not going to undergo
variation and it's less likely to expend
the energy to leave its current stable
state so then the other aspect or the
other pillars you can see on the right
slice of the diagram is growth and again
we're not going to talk about all little
sub principles again I recommend reading
work to see how they all kind of fit
together um but the idea is that our
mortal computer must be morphogenic it
maintains its continuity and integrity
by altering aspects of its organization
and structure over time morphogenic
processes may also be triggered by
environmental conditions um and then of
course we have this principle in
cybernetics of self-replication this is
kind of really important something we
don't really have in uh artificial
intelligence systems today system
behavior is is important that it results
in copying or generating copies of
itself we do have some classical work
like the Von noyman Universal
Constructor you might have heard of
Conrad's Game of Life or Conway's Game
of Life sorry uh and the idea is that uh
these are models of rules or rule-based
systems that can show you how you have
uh death and life in computational
systems um and then another important
notion is that reproduction in a mortal
computer would not just be replication
but you would add mutation so if we have
perturbations to a replicated copy now
we have an offspring and now that is
subject to the same pressures that the
original Source computer uh is subjected
to and it will undergo selection and try
to find its own stable States ultimately
then you can think of reproduction as
another means to prop at one's identity
through time and then the last principle
or the last pillar that we organize is
cybernetical regulation um I do mention
sometimes cybernetical homeostasis is
kind of like implied throughout various
principles but we have the law of
requisite variety um just very briefly
what these three principles ultimately
try to tell you is that you need to have
enough internal Variety in order or at
least enough equal amount of internal
variety compared to to your
environment's variety uh in order to
successfully maintain for example
homeostasis or block particular
variables and stay in a stable state or
more you could have more variety that's
fine so it is an inequality um but the
idea is that this is important for a
system essentially to uh try to maximize
its internal Variety in order to be
optimally prepared for all possible
perations or things that the environment
could throw at you the good regulator
theorem complements this a bit and it's
just basically saying that every
self-regulating controller of an
environment must itself contain a model
of that environment and this motivates
the notion of a generative model that
effectively one way you could think of
it is that the Mortal computer or entity
is a generative model of its own
environment um so the Mortal computer
ultimately seeks to become a model of
the niche that it wishes to control and
then this motivates aspects of survival
and the principal model internal model
control I'm not going to go into it for
sake of time complements the good
regulators theorem it just basically
talks about things that are how you deem
if the system is structurally stable um
and I'm going to move on because I want
to make sure that I get through to the
actual definition so then the last slice
that we review are and we had a preview
of this earlier is aspects of cognitive
science so effectively Carl and I sort
of uh generated something that we call 5
a 5e cognitive theory you might have
heard of for cognitive theory um so we
slightly extended it very briefly uh if
you look at like the center component
the extended ended inactive embodied in
elementary you'll notice Elementary is
the new aspect of the new extension to
cognitive theory Elementary cognition
and I know many of in Mike's group uh is
very familiar it's basil cognition and
is that cognition stands on fundamental
functions and structures that enable
acting and tracking aspects of an
entity's Niche to ensure it's survival
finding food avoiding danger uh trying
to reproduce so these are again known as
phasal cognition and it's a
manifestation uh manifested through A
System's autop poesis so this is sort of
the base level that you must have as the
starting point essentially to build a
reasonable or effective mortal computer
and then of course on top of that lives
the embodied cognition aspect and this
again they all depend on each other so
if you have one you're going to start
getting the others uh if you add these
levels of complexity so it's kind of
organized as the higher up in this chain
you go the more complex your mortal
computer is EMB body cognition as we
talked about earlier is that you can't
describe your cognition or mental
processing without a body the idea is
that you must involve the body or
morphology of the living system and yes
this is a little bit more of the extreme
version of the embodiment thesis there
are a spectrum of different types uh but
we sort of leaned in more on the idea
that we even offload cognition to
aspects of our body and this is
motivated by like morphological robotics
where again we know that if we can
offload the physics onto particular
Limbs and things of that form you can
reduce the processing of the
computational brain that you build into
the computer we know that inactive
cognition lives on top of this is the
idea that you depend on your environment
and you have a meaningful relation
two-way relationship with it um again
not only for extracting resources and
transmitting waste um but you are
essentially uh inhabiting and actively
shaping your Niche Niche construction as
I mentioned earlier then on top of these
we didn't really go into DET I'm just
going to mention that you can get
further and further uh more complexity
introduced you have embedded cognition
because the idea is that you live in a
syst a system of other Mortal computers
so that's kind of what we have there on
the left we show some neuro robots is
just an example um and the idea is that
you are determined your cognition is
affected by uh cultural norms and other
social interactions and the behavior of
other entities that are also in this
environment undergoing uh the same
forces that you are and so again the
Mind extends now Beyond boundaries of
the individual and then of course uh
extended cognition is the final one
where you offload cognition or the
theory of extended mind into
non-biological or non-mortal objects so
if we generalize things to Mortal
computation these are not mortal
computers like your pencil or your phone
so essentially we are using objects as
an extension of our cognitive
functionality and of course that P that
kind of like pie sliced circle is just
sort of grouping them in another way so
we have basil cognition as like the
biggest slice it's more the foundational
component morphological cognition deals
with anything that would be bodily kind
of cognition or processing inactive of
course you need to account for the
environment and externalize sort of
absorbs extended embedded so that was
another way that we organized it some of
you might have heard of kof's lifemine
continuity thesis this is another way of
saying like it's an artificial man man
estation of it so what now with equipped
with all this review of wonderful work
of far smarter people than myself uh we
get to the Mortal computation thesis so
there are a couple of parts that I'll
just introduce briefly uh and I have
reduced and cut away some of the
mathematics uh we can talk more about
that if you want later uh the Markoff
blanket is really the central
underpinning of a mortal computer and
effectively what this does is this is
our interface between what's inside you
or the entity or the Mortal computer and
what exists outside of it it is that
particular interface and things are
exchanged through that interface we'll
be couple um we can break it down a
little bit further you could think of by
the way markco blanket like a cell's
surface uh which separates intracellular
from extracellular elements and then of
course we talk about sets uh and again
these can be viewed as discreet States
but everything's really continuous and
it makes things more complicated but as
you can see in the diagram to the right
we can decompose the Markov blanket into
sensory States and active States and
these are the ways in which the agent
actually gets information from the
environment and transmits information to
it can do things to it uh o is the
external states of the environment and Z
is the internal states of the system
itself so these again are not observable
by the environment and the observable
states are not observed by the agent it
must interact through this markup
blanket uh formalism or this construct
um and again this motivates again how
you now need to design the body you need
to account for the morphology uh of the
agent so here we have a little bit of a
more expansion uh where again I told you
what all the different ones are we have
iterators and we talk about them as
actual sets of states and they evolve
with time as well um so again ultimately
what we want to take away from this is
that there is uh a weak coupling in
local interactions and this will
motivate the free application of the
free energy principle shortly um and the
markup link it provides that necessary
partitioning um non-living systems by
the way uh that exhibit persistent local
Dynamics do not maintain a boundary so
you could argue oh well this is your
framework and the concept of the free
energy principle Marco blankets apply to
a campfire and the answer is no because
the campfire dissipates rapidly in the
flux of the universe it is extinguished
by the downpour of rain so this is not
going to have uh persistent Dynamics it
just has local Dynamics or you can think
of a candle flame as well as an example
of a system that would not be AAL
computer so now we get to uh the idea
that mortal computation or the Mortal
computation thesis is really just
another corollary of the free energy
principle and just to briefly review
what the free energy principle at uh one
perspective is is all centers around
what I was already hinting at before
which is the non-equilibrium steady
state solution or the NES this is what
agents or any mortal computer really
wants to strive to reach um and so the
idea is that according to the free
energy principle or the Fe entities
maintain their structural and functional
Integrity by changing their relationship
with their econ Niche through action um
so action is really important because
this is our way of which we the the
system can actually forage for materials
so the free energy principles about
random dynamical systems that actively
resists the natural tendency to disorder
going to equilibrium and non-equilibrium
is bad that means you have died um and
so the kind of the whole idea of
mortality is we uh act so that way we do
not die that we do continue to persist
um and then the free energy principle
can then be broken down into kind of two
key Parts as you can see with uh numbers
one and two um Mortal computers internal
density Dynamics are conditionally
independent of its environment what does
that mean the environment and the more
moral computer are weakly coupled and
the Mortal computer has states that are
distinct from its external or
environmental states that was again what
was ZT versus o oft and then the second
key point or the key aspect of the Fe is
that the Mortal computer will
continually self- Evin uh or
self-evidence uh by returning to or
trying to be as close as possible to its
NES its nesting um so the Mortal
computer behaves to preserve its
functional integrity and its Dynamics do
not diverge when a part a is applied so
it's the trying to gather those
resources to continue to survive it's
striving to reach Ultra stability which
connects back to the cybernetics back in
um and then we talk a little bit about
the formulation of the variational free
energy I removed uh all the terms for
you for Simplicity here again for the
sake of time but really under the hood
of the free the F curly f is that an
entity has a morphology CU this is
referring to its actual structural
organization it has a set of internal
States and it has parameters move and so
again ultimately uh the free energy
principle is following the gradients or
the differentials across each of those
aspects and we talk a bit more detail um
but I'm going to shift you to the final
piece of the puzzle which is just and
we've seen this again impli throughout
morphic versus amorphic is an important
distinction uh we've talked about
biological entities having a 3D physical
structure and vanoyan computers do also
have that physical structure uh they're
designed to maximize heat dissipation
and things of that form um but our
programs and our software do not adhere
to that structure they are not entangled
with it they are not taking advantage of
that and so we have again in a morphic
system we have a thermodynamic cost and
we have information coupling these are
very important constraints that
characterize entities in this category
and so the morphology itself is a
computational resource in living
entities we also go in the paper in the
free energy principle of about how you
need to do structural optimization which
connects back to
morphogenesis um but our computers are
amorphic or sorry our programs our
intelligence systems today our software
is independent of that substrate think
of when you if any of you have
experience writing a a mathematical
model for a deep neural network you can
write those equations independently of
any realization of a 3D environment the
execution of that program is possible
because of that computer's architecture
but you are not accounting for its
morphology it is amorphic even though we
present it pedagogically as dots and
arrows and try to connect them back to
synaptic structure so ultimately uh
mortal computers follow self- evidencing
the same self- evidencing principles as
enduring entities they are inherently
morphic thus we can apply or ground them
in the free energy principle um as I
mentioned briefly earlier uh you can see
to the far right those are the gradient
flows that you follow um and of course
we formulated them as differential
equations or differentials that you
could essentially Traverse as the free
energy sort of gets you back towards or
Trying to minimize your variational free
energy to get back to that Ness um but
this is essentially we talk about the
relationship between inference learning
and structure and how there is a
circular causality between them and we
go at quite length and I'm not going to
go into in this talk because that's
going to take a while we also talk about
mean field approximations and
simplifications that give rise to known
structures or neural structures in the
brain um but the idea is that a mortal
computer is a Dynamics on structure with
Dynamics was ultimately one conclusion
that we lead and we call this backbone
mortal inference and learning or Mills
for short this is a key part of the
final definition I'm about to show you
um and remember that learn inference uh
changing or altering your internal
States or variables internally uh
depends on learning and of course
learning depends on those internal
States and then there is another
interesting relationship we point out
that the morphology or the structure
depends on the learning or the synaptic
parameters if we're thinking about uh
neuronal networks and vice versa so
there are these causal relationships or
these circular dependencies that are
necessary and actually important to
embrace that a lot of modern-day machine
learning or artificial intelligence does
not Embrace and we should be looking to
biology and neurobiology for those
sources of inspiration for design um and
I also mentioned that mortal computers
are an instantiation of physically
realized beian efforts now I'm not going
to read to you this entire definition
but this is effectively one starting
point an informal definition of mortal
computer uh or Mortal computation and
what it would mean for Designing this
going forward for artificial general
intelligence um very briefly the core
agent goal is to remain in
non-equilibrium steady state of
stability in the face of a changing
environment um very briefly from the
high level view of this definition you
will notice that it emphasizes strongly
you need to have a morphology although
we give you sort of a back door for
those that do computational modeling
perhaps a virtual morphology would be
acceptable for now um and then we
obviously need to have accounts for
homeostatic homeotic processes so a
generalized horo hesis or homeostasis we
also need to ensure that we have
implementation of various aspects of
Mills as I just briefly discussed
earlier um and then we end by talking
about categories of different types of
mortal computers and we came up with
some very Broad and these are subject to
change because this sort of pointing in
a completely new direction for
artificial general intelligence research
to go into uh or biomimetic intelligence
so we have homeostatic mortal computers
and they satisfy essentially the core
principles of the definition but in a
very basic sense um so it has
homeostatic regulation over those
essential variables or Primitives I
mentioned very early on you also then
have higher level regulatory processes
so allostatic mortal computers these
might evince hormesis in contextualized
by allostatic regulatory processes
obviously the ultimate goal is to have
an fully autopoetic mortal computer and
we actually already have some of these
interestingly enough I'm going to wrap
up uh with those examples some of which
uh Mike's group definitely knows for
sure uh and of course we need to evince
homeostasis allostasis uh and engage
self repair and
self-replication so what you might ask
do any uh mortal computers currently
exist uh we already have some of them
not necessarily that the problem is
solved but rather we have some wonderful
examples that we could bring back to the
science as the artificial one of the
earliest ones is ashb uh Ross Ashby is a
very uh important founding figure of
cybernetics which was one of the slices
that I re Carl and I reviewed earlier
and Ashby's homeostat which is what
shown in the picture here it's one of
the earliest examples of what we would
consider a homeostatic moral computer
it's very very simple but it is able to
stay uh autonomously in its own stable
state so it's able to maintain a form of
homeostasis uh without any external
intervention and usefully enough if you
read into the literature uh without any
knowledge on the designer's part of
really how this even works um which is
kind of interesting so the primary aim
is it keeps its control variables within
certain ranges
um and we'll do this with random
exploration uh there are modifications
that were done over the decades to add
learning components to it and then you
can kind of make it look like what uh
Carl tells me is an allowat if you add
some form of memory or learning you sort
of get a little bit more of an
allostatic interpretation um the funny
thing was the homeostat can survive as
one comment from an early satici says uh
something that any normal computer
cannot or digital computer uh uh wire a
cut a wire cutter uh you can turn off
your normal computer and break it down
um but a homeostat would learn to
replace one of its sub modules if you
cut one of its wires which is really
interesting um then we also have things
by ba pask and beer and many of those
that contribute to what was known as
Maverick machines these are actually
variants of uh autopoetic mortal
computers in some sense the
electrochemical ear wasent essentially a
system made of several Platinum nodes
inserted in a dish uh given an
electrical stimulation and they would
grow and self-organize um you can also
give them positive reinforcement and
that's why it was called the
electrochemical ear it would actually
grow sensory organs uh in some sense
that it could actually pick up sound
waves um and it could build con uh
filters conducive to its survival we
also have fungal and mold-based
Computing some of them are uh designed
based on or using actually integrating
the pink oyster mushroom which is known
for its internal geometrical
calculations that can be reprogrammed um
and then it can leverage uh the
resultant electrical activity from the
pink oyster mushroom to drive the actual
circuits of a system so you sort of get
a chimic hybrid type of system um and
they have many useful properties that
have aspects of autoptic moral Computing
but not all of them and it's not quite
clear uh the current direction that
fungal or mold-based Computing will go
but it is a promising example of aspects
of mortal computation um I don't need to
spend your time on this one I know you
guys know xenobots quite well um but
they are certainly an example of an
autopoetic mortal computer and you know
it's a swarm of Bio biobots or
biological robotic agents uh essentially
really I'll just digest to the point of
that they essentially exhibit a form of
morphogenesis and basil cognition
idealized in a multicellular form of a
biological mortal computer um this could
serve as a source of inspiration for in
silicone moral computer designs as well
especially for example in neuromorphic
Computing maybe we could borrow a couple
of the principles that we get the nice
thing about xenobots is they heal which
I think is the most important part um
yeah and then there's some nice aspects
about the hardware we talk about this in
the paper and the Very the extra
appendix uh that the hardware includes
the genome whereas the software is the
cellular communication uh oh sorry the
emergence cellular structures and the
software is the cellular communication
that underwrites the creation of higher
level structures and then of course what
was uh let me see if I have it here why
is it not showing up um ah for some
reason my oh there it is uh we also had
very new recently actually we'd already
finished drafts anthr robots uh which
are wonderful as well we also have the
uh organoid there to the bottom right or
known as intelligence the dish I also
know you guys are quite aware of that so
I don't necessarily need to talk about
sentian organoids um but these are
examples of autopoetic MC's or Mortal
computers um and the idea is that they
have aspects that strongly embody those
Central five tenants of mortal
computation that we discussed
earlier and since I don't want to take
up any more of your time there's a lot
of implications for artificial general
intelligence um the Mortal computation
thesis could be one possible Catalyst
for what we think is the next stage of
artificial intelligence research where
we need to go uh a lot of today's uh
work again from the bi artificial trans
formers you might have heard of uh is
that we have a sort of centered around
tool oriented view or perspective of
artificial intelligence while it's
valuable and stands to make a lot of uh
nice uh benefits for Humanity uh the
idea is that this is very different uh
than how animals and humans for example
conduct uh processing and how we are
naturally intelligent so we should be
pursuing uh survival and its
relationship to mind and how what that
can teach us about embodiment in an
active intelligence this could be the
place that we need to go for biomimetics
by the way bionics is just the
engineering application of biomimetic
intelligent Concepts um and then we have
some things these are actually the
appendix but I just wanted to briefly
mention uh we're essentially working
towards like a form of artificial
sentience rather than using the word
intelligence uh we are also not dealing
with the questions of Consciousness we
we try to not really deal with that
because that can get quite messy
philosophically um that's not important
for what mortal computation says we need
to go but there are some implications if
we actually built the exact idealized
mortal computer well now we have uh the
fact that they can feel they can think
that do we have to consider giving them
rights and I think that's a wonderful
and important ethical discussion that
would need to happen uh assuming that
this uh research program gets built on
and then we have this problem called the
body Niche problem very briefly just
means that uh let's say research groups
like myself we don't have xenobots we
don't have access to organoids um so
it'd be very hard for us to actually use
those re uh resources um unlike those in
the biological domains um but perhaps we
could build virtual morphologies um and
we talk a little bit about how that's
done in robotics and that could serve as
an example uh to democratize aspects of
biological mortal computers um and so I
just I'll leave here I'm not going to
lab about this slide but I'll leave it
hanging here these are some questions
that even I had as I was reading or
rereading some of Michael's group
wonderful work about anthr robots and
xenobots um and some potential
interesting collaborative or at least
directions that could be explored and I
am shamelessly plugging my lab software
uh for uh modeling neuronal Dynamics uh
in biological credit assignment uh and
so forth so with that thank you very
much and uh if there's any questions I
think we have like at least 10 minutes
or
so cool thank you so much um anybody
else else have
questions uh I've got a question so um
yeah thanks this was really interesting
um so I back when you were talking about
um these three pillars of the Cy
cybernetics as they apply to this um I
was interested in the growth pillar um
could you just expand a bit upon what
that is telling us
basically yeah so and I don't know if I
have it here actually it's good to look
at the uh actually I'll do it this way I
don't have to uh yeah the growth uh yeah
so there was a there's a couple of more
principles and things that I sort of hid
here can you kind of see the slide at
least the picture yeah so um the nice
thing about growth from cybernetics is
the idea that and I mentioned uh that
you know one of the starting points is
self-replication the idea that you
should be able to produce copies of
subsystems or produce uh essentially
duplicates or be able to produce extra
parts and change and repair with time um
but autocatalytic growth was something I
didn't really mention and this is idea
that um you sort of get a feedback
process so you can see from some of the
arrows that this is leading to self-
assembly and so what it really was
saying that we need a morphogenetic
process and As We Gather resources then
what ends up happening is you see like
an increase on a catalyst right the idea
is that growth will start to grow up to
a certain point until of course you have
no more resources this is what we talk
about the niche providing that substrate
that material and energy exchange is
really important and it of course
doesn't allow you to just keep growing
infinitely ultimately what this leads in
cybernetics view is this another
principle called the principle of
recursive growth uh which ultimately
leads to the emergence of heterarchical
uh not hierarchical heterarchical
systems they are saying things grow
really really really big and of course
they start creating things that are
stable in the sense of building blocks
so there's a point where uh a system
that's reached like an ultra stable
state or has reached a certain point of
organization becomes a building block to
a much bigger higher level system um and
so that's kind of where the idea that
like Herbert Simon and other classical
thinkers talked about heter emergence of
heterarchical systems so effectively
it's trying to say that you need to
essentially build in these morphogenetic
changes you need to have this process
that promotes growth and self-repair
because this is what's ultimately going
to allow that system to continually
persist over time um and again it sort
of affects that the idea is that you get
more and more complex systems I didn't
mention it later in the talk but you can
have nested marov blankets you can have
marov blankets of marov blankets of
marov blankets and now you get
the of top down and bottom up causal
modulation um but ultimately growth is
just trying to say that we need these
resources and we need to be able to
replicate either your entire entity and
then add mutation which creates The
Offspring as I mentioned earlier or you
need to be able to reproduce and grow
and replace subsystems and that's the
part where the building block concept
comes in there's also one final comment
that at least I recall which is that as
these things become stable systems the
that are built of lower subsystems make
it easier for those building blocks to
join in because again now we have this
organizational principle from a high
level relationships between Parts I
don't know if that was helpful okay yeah
it was uh okay thanks yeah thank you
it's a good
question anybody else oh uh yeah I also
have a question um so one of the
Hallmarks of classical one computers is
a programability right um what type of
computer I just didn't hear you uh one n
computer
the conventional computers it's it's uh
programmability uh so we can almost
anyone can write a program almost using
natural language um what about
programmability of model computers do
you think that uh we might need some
sort of model programming language
framework which is fundamentally
different from a traditional programming
language framework that is a really good
question and yeah that is something that
in my view you would lose uh from class
iCal computer because the idea is that
uh as I just said and everything is sort
of dependent on the morphology and the
niche in which that morphology is to
exist and that agent or that mortal
computer is to interact with so I would
say that it gets difficult because you
need to now account for the properties
of the morphology and sprinkled
throughout the paper we talk about uh
that the homeostatic variables or the
sorry the uh metabolic Primitives will
largely depend on the actual substrate
in which you are building and it could
be in silico it could be biological um I
think that there is potentially and it's
not clear to me how so I'm just
speculating to design General
specifications not so much that it would
be like you can program an immortal
computer just like you would in your you
know standard Von noyman computer and
like the Python programming language but
you could take advantage that the
systems organizationally closed and that
they have essentially relations between
the parts so there are some sort of
design principles that they adhere to
and I think you could design some level
of general programmability for certain
classes of mortal computers it wouldn't
be like oh let's say I have an an animal
let's say a very low-level type of
mortal computer something very low-level
cellular versus um a complex organism I
would say that the programming
specifications might be dependent on the
class of mortal computer and the type of
entity and even the niche in which it
interacts but you could essentially
program classes or slices of mortal
computer so again if we're dealing with
like I had in my other
diagram the neuro robot that was a
version of like the dog robots that come
from like Boston Dynamics um you could
essentially imagine designing
programming language around those types
of quadrip heads um and so I think it
would be you'd need to account for like
the essential Primitives and the
environmental variables that are part of
this process and we need to be able to
specify them to some degree if we want
the programmability I think it gets
complicated though because I do think
while we are sort of arguing for this
entanglement right because the software
really isn't divorce from the hardware
and real entities um the place where
maybe you get some of that General
programmability is in the virtual
morphology and I think that's our best
bet because ultimately when you're
building these uh systems themselves you
sort of need to work with the actual
Hardware if we're talking about let's
say robotics uh it's a little bit
different with biological entities too
although I know like the xenobots that
you have way or the anthr robots even
you have ways of which you can program
them uh you know there was uh some
biochemical processes that were
described in some of Mike's work um I
don't know if that helps though but I do
think you lose some of that
programmability but what you gain is
this massive energy of efficiency as you
start to approach uh those lower bounds
you start to approach the place of
thermodynamic efficiency the best that
you can get with physically realizable
uh bayian inference I do think though
that programming part can come in from
more more virtual morphologies to allow
us to deal with the organizational
properties and allow us to experiment
and you know work with different designs
does that answer your question to the
