yeah here we go so it's Wednesday April
17th 2024 and I'm talking to Monica
Anderson hello I'm pleased to be here
thanks for being on Monica I regard you
as the person who really Built My
intuition about what this Revolution was
going to be like and when I moved back
to Phoenix I'm like okay people need the
same education I got I kind of stammer
around and I can I can say a few things
but in the end you can drive it all the
way to the math and so when I talked to
you about this you're like here's a pile
of things we could talk about and the
thing that stuck out is why AI works and
I I hope that you'll walk the audience
through exactly the same kind of thing
that you walked me through and I haven't
heard all of your updates to these
things that's it Monica other than that
I expect to listen so uh do you want to
give a quick intro on your background
and uh some of your other you know where
point to some of your other work
certainly uh I'm born in Sweden I
immigrated to the United States in
1982 I have a master's degree from ning
University in Sweden I've been
interested in AI ever since College uh
and uh what so I have Decades of
experience industrial experience with AI
industrial grade AI as I call it for
decades and then I have on top of that I
have 20 years of research into the
modern kind of AI uh so there was a
change in AI roughly around the the
shift from the 20th to the 21st century
and the sad thing is that nobody really
noticed how big a shift it was and
that's basically has been my mission if
you will for the past decade and a half
20 years almost to basically educate the
world about what a big difference it is
and how it sets everything we know about
a whole lot of things into question
including the value of science as a
whole um and uh there are so many people
struggling with various aspects of AI
which for them to them is completely
mysterious and it can be even more
mysterious to people who have a solid
mathematical physical scientific
background and education they are the
ones that can be the most
confused um and uh this confusion leads
to cognitive dissonance it leads to many
poor decisions and mean focusing on the
wrong things and it means spending
billions of dollars in the wrong places
when you're trying to create an AI and I
have I basically because of my
experience with the old kind of AI in
the 20 20th century um I among other
things I
was had the pleasure of playing with the
psych system which is the largest AI
system of the 20th century for a while
and me playing with it for about five
hours um in
1998 convinced me that it was not the
path to go to artificial intelligence
and so I was desolate for a year or so
and then I discovered there was an
alternative path thanks to uh my friend
K who gave a talk about it at the
conference and uh I basically decided
there and then to spend the rest of my
life on working on this alternative
aspect of AI so I started doing that as
it happens on January 1 2001 I had
basically before Christmas I had quit my
job and I had been thinking all
Christmas weekend about stuff and I
basically started working on this is a
real product January 1 2001 I
Incorporated my company Sunan syc in
2004 I worked for Google for a few years
I worked for a couple of other companies
but in on the whole I have easily spent
20 years on these ideas and this project
and the what I have been doing at at one
end what I've been doing is basally
creating theories for how intelligence
work but then I have been doing
something like very few people are in a
position to do which is I've used my
program skill to program up large
language models starting in 2001 so I
have basically created 23 major large
language models in 2001 only two of
which worked and so uh that's basically
the experience uh that I have gathered
and I've been working on the on the
second one of those uh for the past four
years now five years almost H trying to
improve it to the point where the other
language models are uh and it's likely
doable and it's it's likely going to be
a big deal but at the moment I don't
have it so I basically I can use the
other aspect of what I do and that is
basically a an Outreach an educational
Outreach try to get people to understand
this enormous difference that we
underwent in AI um and to understand
what it means for everything that they
believe about AI includes what you
should how hard it should be how
expensive it should be what should be
done first uh uh Etc how important is
the Corpus uh how important is it to
have a robot Etc these are all questions
that people are easily misled by the
20th century views of of artificial
intelligence and setting them straight
should be a priority and that's why I
basically am doing my Outreach because I
want people to focus on that which works
now fortunately a lot of people are
focusing on on deep R networks and
Transformers and so on and these things
do work
so I I'm not I'm not dissing them I'm
just saying them they're doing it wrong
it could be done better it could be done
easier if you followed my theories and
so we we can talk about in which aspects
uh that that is true and and what
matters the most in this thing so my
main uh discussion to bring it to a
conclusion is basically that there's two
kinds of problem solving methods in the
world and people are have always been
used one of them but some people people
have been taught to use the other one
and now they get confused when they are
told to use the first one and so this is
this is uh the problem in a nutshell and
the two methods are called uh The
reductionist Stance and the holistic
stance and we can talk about that a lot
very good that I mean when again when I
when I thought of it you have taught
this stance forever and you know there's
this there's this total moment where I
saw the things that you predicted just
like coming true and then on a plane I
was listening to a Sam Alman speech from
before chat GPT and I had just listened
to it and I got a text from you like Sam
this I believe everything Sam Alman says
and I'm reading it having been trained
by you and I'm like Sam Alman is making
sense and I made sense of with what you
had taught me and then I get this
immediate text Loop and I'm like okay
that's super ultra helpful helpful and
so you know do you want to lay out this
kind of philosophical approach between
reductionism and holism because that is
where you started me right uh there is
if you go to the Stanford Encyclopedia
of philosophy for instance you can find
about a half a dozen different
definitions for the term
reductionism and they vary a lot and
some go back to the Greeks to people
like an
Xander uh but the what they have in
common
is that they are all describing various
simplifications of the world and in so
doing they do things like okay let's
switch it to a different problem domain
like if we have a gas we can switch it
to Newtonian mechanics by basically
treating gas molecules as as balls that
count collide with each other so these
are basically domain to domain
reductions there is all kinds of other
reductive ideas that they have but in
general it comes down to basically
building models of the problem you BAS
basically somebody with some sense like
a scientist or a engineer looks at the
problem situation decides what matters
and they find a formula equation they
may make it themselves like Newton did
or they might take it from a book like a
lot of Engineers uh and then they know
they understand the problem well enough
that they can apply this equation to
their system and they can they can get
an answer and then they can use this
answer in the real world problem and
this has worked so well for 450 50 years
we went to the moon using this principle
we've done all kinds of cool stuff but
there's problems we couldn't do such as
protein folding and then these neural
networks come along and they do protein
folding like nobody's business uh and
that's because they are using the other
problem solving methods the other
problem solving method and so they come
in two classes and we can call them the
scientific methods which is the
modelbased one The Limited ones they
work 100% of the time at least the
simpler ones do and they provide
clear-cut answers they also require
perfect input data and then the other
have the other set of problem solving
methods which I call the riffraff
methods they are the holistic methods
and they basically take sensory input
and they learn from it and they create
patterns of patterns building up
experience and they can't do anything
until they have a problem that matches
their experience so the moment if you
build up a lot of experience over a
lifetime like an ed ation when you
become an engineer and you got to build
something like the Golden Gate Bridge
you know exactly in your education you
have been going through exactly what
matters you need to Anchor these points
you have to measure the depth and so on
you have to do all of these computations
and you can do them because you're
educated to do this uh but the basis of
being able to pick the right model is
the understanding of the situation and
this is something that only comes from
experience and it cannot be explicitly
taught so let me uh uh
possibly I should uh uh tell the little
uh story of Holly and her chocolates and
this story illustrates basically why we
need to do something that is not
scientific we need to go beyond science
and I call it I mean Elon Musk and other
people talk about first principles the
science as the place where you have to
start if you have a serious problem you
have to bring it down to first principal
size because otherwise you can jump to
conclusion and make mistakes higher up
in your abstraction tree and and that's
could be detrimental to the end result
so they say go to First principles and
that's how he describes his rockets and
whatnot I say that in artificial
intelligence that is not sufficient you
have to go one level deeper you have to
go to the zeroth level and the zeroth
level is the level of epistemology and
things that don't make sense at all in
the scientific World suddenly start
making a lot of sense in epistemology
and we find that if we're going to build
artificial intelligence or even large
language models we have to understand
this we have to do it the way uh
basically that the brain does it and
that is collecting experience so the
story is that uh imagine you're back in
grammar school and you are in the math
class and your teacher tells you the
story uh the following story problem she
says Holly has three boxes of chocolates
and there are six chocolates in each box
how many chocolates does Holly have and
somebody will say 18 and and I say
almost right and somebody says 18 and I
said that's correct because you have to
add the unit to it and that's something
is extremely important to an
epistemologist maybe not so for a for a
great school teacher um but basically
science is very good at answering
questions like how many chocolates does
Holly have you multiply three by six and
you get 18 chocolates but science is not
very good at answering a whole bunch of
other questions the typical one is how
did you know you had to multiply how did
you know you had to multiply if you
can't answer this question with a
straight face uh and saying that you
learn it in school doesn't count because
you didn't learn about Holly and her
chocolate in school you learned so many
other things but you didn't learn about
Holly the point is that in order to be
able to solve these kinds of problems
you have to do an abstraction and the
abstraction is something that science
cannot handle they don't have equations
for abstractions they basically when
they scientist doesn't extra an
abstraction they're solving an integral
and suddenly they figure out what
substitution to make they don't know how
they did it they don't have an equation
for finding the substitution there are
such equations Mathematica uses but
scientists when they basically using
solving an equation that looks like a
sphere I'm going to substitute M Mumble
Mumble pi squared or whatever uh and so
uh uh that's uh that's their experience
talking that's their experience of
solving thousands of math problems
throughout their education that has led
them to a position where they know when
multiplication is the correct thing to
do and the answer to the question is how
do you know you might have to multiply
is because you gathered enough
experience to be able to pattern mash
the situation with Hol and chocolates to
a multiplication solution and that is
basically what reductionism is all about
that's the epistemic reduction going
from a rich World situation to a simple
equation you can solve in a computer or
a calculator and then you can find the
result 18 appli back to the world and
say 18 chocolates incidentally the word
apply is interesting because it means
it's used in application in our iPhones
and that's exactly what we have we have
a computer-based model of a real world
problem in our iPhone we enter some data
and we get back a result and the result
is applied to the real world that's what
basically we call this application goes
all the way back to the beginning of
computer uh so anyway that's holyer
chocolate holyer Chocolat and basically
explains why we have to go to
epistemology in order to understand AI
because how can you figure out that you
have to multiply or use any other
problem solving method for that matter
if you don't have this context and
that's where we can go on with you can
ask questions or whatever perfect let me
see if I can summarize the Holly and or
chocolates problem right so so for so
much of this you have to you have to
walk along a thinking path and and
that's hard for people the reason we're
recording this is so people can rewalk
this thinking path but the but I would
say there's a sort of Touchstone which
is hey you can figure out that if you
want to know how many chocolates total
in three boxes of of common unit you you
know you can do that but how do you know
this or this operation set at all how do
you know the operation set and how do
you know which one to use yes I actually
normally I forgot to do it here but I
actually say hly is seven years old I
usually start with that and then I say
and by the way why doesn't seven occur
in your multiplication because it
doesn't matter how you know it doesn't
matter because experience tells me so
yeah you see how this basically
reduction is this discarding the
irrelevant and discarding Holly's age is
extremely important as irrelevant it's
Wednesday April 17th 20124 and you're
listening to the PHX appdev podcast and
we're talking with Monica Anderson today
Monica when we left you said you know a
magic pointer to something that you
taught me a long time ago which is
reductionism discards context as a
nuisance and that I mean to me that's
the best leading into holism there is so
you know can you tell can you tell us
more about that and how you think about
it uh yes uh consider something as
simple as the equation f equals ma which
is Newton's second law that is a very
simple equation and you have to
basically if you're looking at the
problem H such as you want to estimate
how good are the brakes in your car did
you know that you can estimate the power
of brakes in Horsepower it basically
completely equivalent to to accelerating
or you can just break it so you run the
car up to 40 mil an hour and you shoot
it with a video camera hit the brakes
you see how long it takes for to
decelerate and now we can plug it into
the formula you can say how many
horsepower your brakes are so that's a
typical way of solving a reductionist
problem now we didn't take into account
the wind resistance we didn't take into
account the rolling resist we were just
interested in the brake but all of these
other things also decelerate the car and
the engineer that looking at this
problem trying to do it using this
method have to decide whether the
rolling resistance and wind resistance
should be included in the model or not
and they can include them and there's
formulas for this but it complicates the
model it might not be right in an
educational situation so they go with
ethical MMA and they're happy with the
result it's going to be correct within
percent or two and that's typically good
enough for engineers so the question of
what to include and what to exclude is
crucial when you're doing a reduction to
something that is scientific and a model
and equation Etc we'll get back to how
you solve problems without doing these
things but we can look at what
disappears when you're doing this thing
and and and it becomes increasingly
annoying and increasingly embarrassing
for reductionists to deal with more and
more complicated problems they try to
predict the stock market they can't keep
track of all the variables they try to
predict things like
intelligence based on race and you know
where this is going and they get
criticized for doing these kinds of
things and they don't I mean they look
at intelligence as a result of where you
live and they don't take all the factors
into account because they reduced them
way as irrelevant too early and now the
results are controversial and people can
point that the as at the as the discards
as important things that they should
have included and and so this is the
problem with reductionism is that there
is a scientist always that has a model
of the problem and of the world in their
head and they are one dictating which
equations to use and this can be
incorrect it can be correct when it's
correct it's fine and surprisingly in
places like rocket science these
equations are simpler than they are on
the street because there's no friction
in space for instance so U it's a
depends a lot about which domain you're
in but the moment you step into life the
moment you go from physics and uh
mechanics and basic chemistry you go to
biochemistry you go to
medicine you go to biology you go to
psychology you go to ecology moment you
step the border of that which is living
you're basically on the other side of a
complexity barrier that is enormous and
the reductionist methods they fail in
everything that has to do with life and
this was discovered this was debated and
by no other than Urban sheringer of
Shing years equations um back in
1947 or eight I think in a paper called
what is life where he basically the
first 80% of the paper he discusses how
difficult it is to take anything in the
living domain and create physical models
for them um and scientific models for
them um and in the last few perc of the
of the book he goes on and takes back a
lot of that and I wonder if that is a
pressure from somebody else because
otherwise the paper would have been too
radical this is something we've seen
again and again uh for in yeah but uh
the net of this is that is that we can
recognize in general that life is the
hard barrier to where physics basically
can't do a thing and beyond that we rely
on the holistic methods protein folding
is currently a shining example of that
but even before that we use Shad Scot
genetics which is a semi holistic method
for doing Gene analysis um and and
basically PE shooting at the genome
picking pieces random and then
assembling them from from the pieces and
that's something a reductionist will
never do because doesn't guarantee a
correct result but hey it works really
well for for the gomic domain because
there's no alternatives to it in general
we use reductionist methods whenever we
can if you have a working model that
gives you good results you would be a
fool to stop using it but uh including
going to AI because they are holistic
we're going to get back to that a lot
they are basically working in the other
domain um um but um the scientific
methods they are always dependent on
there being somebody else doing the
epistemic reduction and throwing away
the irrelevant and it typically is the
scientist who creates the equation or
the engineer who uses it okay yeah that
that's great and I I think the update of
biological life is that's new in the
teaching and so that's real that's that
that makes a super clear line in it and
that snaps lots of stuff into place okay
well this discussion is nominally about
why this works and so given this
background and reductionism and holism
why in the world does AI quote unquote
work and let's let's try to refine that
definition it starts to work in the
biological domain so big top question
why does it work and then what how do
the example of biological domain show it
working um it is significant that some
of the things that work in biology s say
evolution in natural uh between species
Etc Darian evolution is frowned upon by
everybody in
science they some people say evolution
is scientific principle turns out that
they're wrong it's actually an
epistemological principle it's not that
the level of science it has to go below
because science doesn't have equations
for evolution but epistemology explains
how it works and it also explains how
intelligence works and the similarity
are W in one would think that basically
once we can establish there's you can
basally make a short epistemological
argument that says whenever you have
these conditions for evolution such as a
competition for survival and a pattern
that can propagate with some chance of
error when you have those situations you
basically have an evolutionary situation
and that can happen in many many places
it can happen I think it can happen in
cosmology but definitely can happen uh
in in uh uh in in real life it can
happen in certain uh I mean I don't know
even chemical fraction distillation
sounds to me like something that almost
evolves so there's all kinds of examples
of these kinds of things in life but
evolution between species is the number
one example of something that is really
powerful and because it has brought out
all the life on the planet an enormous
variation the creativity of evolution is
powerful and we can get back to how
powerful how basically computers can
harness that gravit for themselves and
how we harness the same methods the same
algorithms for creativity as Evolution
does anyways back to the disdain for
evolution among reductionist because it
isn't reliable it doesn't provide you a
an explanation it has all kinds of
problems and it requires large
populations it cost a lot of effort to
do it they prefer to just be able to
pinpoint the equation and get the answer
point is that nature in the beginning
didn't have these scientists so it had
to be basally make do what it had and it
basically nature discovered by Evolution
basically discovered how to get better
at it and the one way to get better at
evolution is to be able to evolve ideas
in your mind in your head and so nature
discovered intelligence as a competition
between ideas in the mind and this is
called the neural Darwinism idea um it's
also then generalized to something
called selectionism which is basically
idea that Evolution works all over the
world for instance the cars we can buy
are the cars that are made because we
have selected those cars and and similar
cars in the past and so even the cars we
can drive is the result of a select
evolutionary process and so
understanding that in the brain we have
an evolutionary process that makes ideas
compete with each other and they breed
with the best ideas get to breed with
each other and generate even better
ideas that is extremely important to me
I've been following that trend for 30
years years that idea for 30 years and
still nobody notices it uh to me it's
obvious that that's how the brain works
because that's a kind of simple
algorithm Evolution could come up with
Evolution cannot come up with with sotic
gradient descent it can't even come up
with floating Point there's no floating
point in our brains so clearly the the
the approaches that we haven't taken in
deep neural networks and in in
Transformers and in llms they can be
improved upon by going to something that
is closer to that which is epistem
epistemologically necessary and that is
basically a system that ties Concepts to
each other through correlations
relations synapses and that uses a
darnis Evolution to uh throw out the bad
stuff the bad ideas over time and just
breed the good ones and these are key
ideas in epistemology the key key ideas
for my system but you don't really see
them explicit mention in large language
models I have this feeling that large
language model are doing these things by
luck and not by somebody understanding
the problem and designing it okay well
so maybe we need a specific definition
of epistemology here you know if there's
someone who's not familiar with all of
this then what kind of handle can you
give people on just the concept of
epistemology so if you you can make a
quick sketch of philosophy at the bottom
and then we build science on top of
philosophy but there's a few now I can
use my so there's a few interesting
details about that so if we this suppose
this is philosophy you can see this I
see it I got it the the writing is hard
to pick up but okay but this okay this
is philosophy I'll bigger and then at
the top of philosophy here is a layer
which We call we can call epistemology
and the epistemology layer it talks
about things like truth and falsehood
about understanding learning um about
reasoning about logic all of these
things are can be defined at the
epistemology level they basically they
are born out of philosophy and you can
see why it takes basically a bunch of
Greeks to come up with the good stuff
here and that's what happened but then
on top of this we take some methods that
we like and we build basically what what
is science on top of epistemology like
that and these are the reductionist
methods these are equations and other
models equations
formulas hypothesis
theories um and they are all basically
reductions all the world the
simplifications of the real world but
they work every time pretty much and
they require perfect input data when you
have a situation that doesn't match that
when you can't use these equations for
instance in the case of understanding
language which is not
reducible understanding protein folding
it's not
reducible uh in these situations you
basically stuck with using all kinds of
stuff on the right here the rest of the
problem solving methods they are varying
quality some of them are very good some
of them are very fast some of them are
completely useless in most situations
but these we can call these the Riff
Raff methods they are the holistic
methods this is what people used for
millions of years since we were insects
and basically we learned things and we
solve problems by pattern matching and
only in around 1550 to 1650 we get the
brilliant idea of gathering all the
reductionist models in the book and
calling that science and and but we
still have to do the way to get to one
of these reductionist equations is that
you have to use your brain using nothing
but these riffraff methods to form your
understanding of the problem domain and
until you have that understanding until
you build all the cross links uh between
the the the correlations that you need
to solve problems in this domain uh you
can't even use science so this comes
after scientific education after having
studied the topic these methods you can
just use immediately I think of the
difference sometimes between
reductionism and holism as the
difference between plan it and do it if
you need to plan it is reductionism is
you can just do it right away it's
holism language understanding is
holistic Etc taking a step forward is
holistic you can't SE sequence your leg
muscle by an algorithm because you don't
even know what leg muscles you have so
uh basically most of the time
99.999% of the time we're using nothing
but holistic methods in our daily life
even if you're a scientist you're using
nothing but these methods it's using
nothing but experience and your brain
are lower levels of understanding and
only when you're writing a paper in
science do you have or you or trying to
solve a problem using basically bridge
building after you have do you have to
use those methods and they do require
this understanding before you can even
touch them so this is the difference the
thing that I'm addressing mostly and
this becomes important because AI
actually lives in this right hand side
AI doesn't live inside of science which
is the biggest surprise to many people
I'm saying AI uses these methods and
because they're using refra methods
they're going to sometimes give us refra
answers and people have started noticing
that LMS lie to you a lot and that's
just a method matter of how many methods
they can how much information they have
many methods they control and putting
these things in there doesn't help this
trying to make AI scientific by putting
in equation solving systems in them
doesn't necessarily improve the
understanding of the problem that they
have so it may not be that helpful but
these are the kinds of issues that
epistemology can help you discuss in the
AI domain uh in the in the samean manner
if you will awesome okay is that enough
background to start answering the
question why does it work yes it works
because it's the the principle of
gathering information creating patterns
that you can search and matching those
patterns to problems in the real world
is something that is so simple that
Evolution that nature could Discover it
and science took human intelligence and
hundreds of years to discover so these
are much more important methods than the
scientific ones and now that we have AI
working on the right hand side of the
equation AI are actually understanding
the problems we may not need as much
science going forward we may not need
much much sence going forward we're
going to basically ask our AIS and
they're going to come up with an answer
like that and it's going to be correct
often enough that we don't have to
double check using science and that's a
very different world yeah that's
certainly I I I never had this point of
view that um I I look at I really like
uh I really like Steven Wolfram right in
his focus is what is computationally
reducible and that's all the stuff in
the science box and what is not
computationally reduc reducible and
that's all the Riff Raff but it is now
computationally reducible to find the
pattern to build Riff Raff models yes I
mean that you notice that it's very
expensive to build an large language
model because you have to gather enough
of this stuff to have something to throw
at every problem you can encounter you
have to have seen everything before in
some way shape or form at least and have
enough abstractive capability to be able
to do it a trick question let's drop
down the rabbit hole let's just answer
the most basic question how in the world
even if you have a lot of data do you
link all the this is the how the why it
works what are we doing with a machine
because there's clearly a reductionist
machine involved here they can still
only work on zeros and ones
how like why does this thing work so the
basic problem of AI is one of
discovering abstractions you have
basically a situation with all kinds of
data you can basically take the Bridge
Building example you have all the
numbers for the whatever you got to
understand what kind of abstraction
makes sense um and so discovering the
correct abstractions the correct models
actually I shouldn't say that because in
the in everyday life we're happy to disc
discover an abstraction a little bit
higher up we don't have to go all the
way up to the Real Models to solve
something scientifically we can go
quarter way up and solve problems using
whatever we have and this is easy to
explain in a physical uh skill context
suppose you're learning to go ski
downhill well if you you can't have a
friend tell you how to ski downhill over
the phone that doesn't work you can't be
taught how to ski over the phone so you
have to basically do it yourself you
have to experience it you have to
basically fall down in so that you have
enough responses to your balance
shifting and your she SK sketching Etc
all of these little things and all of
these things have to happen fast and if
you have to experience something and
analyze and think about it you have
spent 500 millisecond this is not as a
liet delay you're living half a second
in the past this is not known to most
people but basically after you see
something happening there's a half a
second delay before you get conscious of
it and you can find out that this is the
case because I mean for instance I open
my bathroom cabinet and a lipstick falls
out I can catch it before I even notice
that it fell and that's like 200
milliseconds of fall um and but if
you're playing tennis the first time you
try to compute where the ball is and
it's always behind you so to speak so
you have to get to the point where you
can answer not going all the way to the
top and going down to the bottom again
you get basically this shortcut that
goes from sensory input to physical
output okay hit the ball there hit the
ball there um you can you basically get
there only by practice practice is
exactly what you need here's here's a
key difference between the methods in
the box and the methods outside of the
box these guys get better with practice
those don't anything scientific gives
you the same answer every time anything
holistic gives you better answer as it
learns more and the question is which
one do you want well depends on the
application okay we're still circling
the why does it work so you have to do
iterations why do these systems why do
these systems allow iterations to pay
off what are they doing at the bottom
they're learning a little bit every time
and here is the basic rule of of
epistemology is that you can only learn
that which you already almost know
learning a new factor a new skill or a
new input or even a new correlation it
means it's a creative task because you
have to fit it in in the right place in
the existing World model and
um this takes um this takes a lot of
effort to get it right and we have
algorithms for that great all right
Monica so we're circling the question of
why does it work and you suggest that
the Transformer case makes a really good
example here yes I mean uh the function
of the brain is I have this saying that
says about theories of the brain that
says the story of what the brain has to
do which much shorter than the story of
what the brain does the brain carries an
enormous amount of evolutionary baggage
including things like uh microcolumns
and and and long-term things and and
hypoc campus and all kinds of other
stuff and tempor whatever different
regions in the brain and they have
evolved over time from previous species
etc etc so it's hard to make sense of
everything so going to epistemology is
one way that you can see the pure pure
problems
and and the pure problems are basically
the problem of reduction of discovering
and abstraction for instance one reason
to know what's what's abstraction is
that you can tell whether something is
important or not if it's a completely
new thing you may want to learn it then
if it's not then you always just another
one of those you don't have to explicit
learn it so what you learn how much to
crank up the learning in your large
language model are basically things that
can be controlled directly by by looking
at at uh uh these things so large
language models they basically uh they
are gathering experience and the way
that they're experience works is that
they discover correlations between these
different um phenomena that it's
experiencing I mean you in in the simple
case of language um we have we must
discover patterns uh of um words Etc and
and and we must ReDiscover them when we
see them again I mean basically 90% of
of cognition is
recognition um and and so they have to
uh recognize everything that they have
seen before and that requires that they
have some kind of a data structure where
you can um take Concepts that you have
read about and compare them to other
Concepts that you have read about and
this is what large language models are
using they're using currently they're
using a 20,000 dimensional space there
basically 20,000 floating Point vectors
uh with 20 uh sorry there's floating
Point vectors in 20,000 entries and and
they live inside of a graphics
Processing Unit because they have to do
computations on that and the computation
they want to do is you can think of this
word if you will start with words words
basically occupy spaces in this 20,000
dimensional space and uh and two words
are related to each other like cat and
kitten could be related to each other
and uh the difference basically dog is
much further out than cat and kitten are
so the distance in this space is what
determines how close something is to
something else and now you can take a
bunch of items in this space and wrap a
bubble about it and say this is
everything that matters about a cat and
you don't have a cat neuron but you do
have a bunch of neurons if you will or
or floating Point numbers in the case of
of llms that basically embody the
concept of a cat and whenever we talk
about a cat in any aspect of this you
get some points lighting up in this
space um so the ability the power of
this structure is how well can you
determine whether two items are related
or not how closely how well can you
create a a reification a a physical or a
mathematical construct that says this is
a cat in our system if it lands in this
bubble we have a cat um and and that can
basically be done at that point that can
be done uh completely uh mechanically by
Bas as long as you have this Vector
table it takes a word and it it gives
you this Vector in this concept space
and 22,000 floating Point number is a
very large space uh you basically
difference between cat and kitten might
be a difference in 20
dimensions of of 0.6 or something like
that but most of them are going to be
the same and the reason that most of
these dimensions are the same have the
same values means that cat and kitten
are close to each other they might
differ in size or some other stupid
Dimension yeah let me get that let me
get that uh that relationship straight
so it's a 20,000 Dimension space yes and
a cat cat and kitten might really
Encompass 20 of those Dimensions so no
they Encompass all of them you have to
specify every single one of those 20 for
every single point in this space so that
takes a whole Vector to say cat it takes
a whole Vector to say kitten and they
are close to each other in some number
of those in most of those Dimensions but
not in all and it's a transformation
from word to a point in a sematic space
which is the trick of the llm how can
they do this how do they come up with
this magic Vector that's the big trick
and it predates llms by a few years uh
and you may have heard of this this is
basically called wtu and wtu is the idea
that you can read a bunch of text even
one word or a large fraction of text and
when you're doing that you're navigating
this 20,000 dimensional space to a point
and when you read the whole sentence you
are at at the at the point in the space
and this is the space what the sentence
was about it's not just the word cat
this is what the entire sentence is
about and the system works basically uh
the whole learning process allows you to
do this uh and and it basically embodies
embeds all of the syntax and other
things that language has uh which is not
necessarily for analyzing it but it
basically all of these things become
part of this cloud of uh of points that
the system can handle and and you give a
sentence you end up in the space in this
and you can immediately see what's
around it and uh if you're for instance
if you're building a a spam filter you
enter a bunch of spam and they all up on
the cluster over here and then you enter
in a message and if it's the Clusters in
that cluster then you have a Spam thing
so this it's very straightforward once
you have this Vector where does the
vector come from this is a a beautiful
story so verc um it's you can recognize
we're talking about ver because
everybody uses this wonderful example of
King minus man plus woman equals Queen
so that's basically how you can navigate
this if if king queen man woman are
vectors in this space it turns out and
you can do this Vector arithmetic which
is extremely which reduction is like a
lot to navigate Concepts in the concept
space and this was why they went down
this route the moment they discovered it
but basically the one how do you
discover that for instance cat and
kitten are similar well you can read
bunches and bunches of text and we talk
about more text and what actually goes
into the learning of a large language
model at least in the early cases but
you take a whole bunch of text and and
the best models currently I think are
done by Google maybe there's something
elsewhere but they read all this text
and they go through five word they take
five words and and uh first second third
fourth fifth and then they take the word
in the middle and they bury it so
basically you you you find in the text
you say feed the cat before leaving and
you see in another place you say feed
the kitten kitten before leaving feed
the dog before leaving you can cluster
all of the things that you feed before
leaving into a category into words that
mean roughly the same thing they are not
the same thing they are slot Fiers for
the same expression but that's good
enough for a lot of stuff and this is
basically how you discover the
abstraction of pet from just these kinds
of sentences we we have a category we
don't may not even have a name for it
but the system can discover the concept
of petness by just discovering how we
treat our various dogs and rabbits and
cats and whatever and so that's how how
World to gives us the abstraction the
semantics of words the semantics of of
sentences and uh deep learning
discovered this started using this and
then Transformer started using this
Spades and that's basically the
foundation of everything we have in
natural language today natural language
understanding and is based on the
ability to take a ver Vector called an
embedding and then uh use that for
learning other stuff around it and and
and increase the power of the embedding
in the current sentence by refining it
and so on this is these the kind of
mathematical operations that we can do
in this situation but the verto tric is
the one that made this possible okay so
so the I realized asking this question
of like why does it work it's a is we're
back to Riff Raff methods and holism
here like okay I given what you have
taught me like I I just look at first of
all the machine essentially is going to
break anything it gets into a kind of
mad lib this is my my rudimentary thing
is that am my I love I love your Mad Lib
experience Mad Lib to me is basically
these little wor that you put on your
fridge door and you can move them around
you can imagine as machine learn in of
languages being throwing them on the on
the fridge door in random order and
whenever you read something that's close
to it something that's related you nudge
them quarter inch closer to each other
and you keep doing this for a year with
every piece of news item that you find
and over time you will find that cat and
kitten are very close to each other and
this is basically machine learning on a
fridge door I never thought of this
before but this is a lovely mod nice
well great that there we go here's my
reductionist question how do you do one
yeah and and so with the Mad Li fridge
door thing you would get like some
phrase that pops up on a screen and you
would and cat and kitten have occurred
more closely in your own mind your mind
will sort of make these connections yeah
you the easiest algorithms basically say
worse that or next to each other will
get close to each other in the graph and
this is a well-known equation and you
can do it mathematically and then it's
called the vby algorithm it's BAS
basically use this Basi and learning to
um do the same thing it's not strong
enough to be used for uh language
understanding because it discards too
much of the context U but it's basically
the same idea you basically learn to
move things towards each other as you
encounter them in Paris and triplus and
whatnot Perfect all right well let's
let's roll off from there I think this
gives the audience like a super great
landing spot and uh maybe why don't you
do a teeny summary here and then maybe
even offer for us what next idea we
should learn and maybe we'll pick that
up for the next one certainly yes the
summary is that that humans use one way
of solving problems for millions of
years and then say science came along
for 400 years and found a better way and
now it's run its course and we have to
go back to doing it the first way and
therefore the 21st centur is going to be
revenge of the whole this is going to be
revenge of methods that do it rather
than plan it and we're going to see at
all kinds of levels inside even inside
of science we're going to do more things
like protein folding which is a
scientific problem but science can't
solve it we're going to do more of those
using H artificial intelligences and
other holistic methods to jump to
conclusions on scaned evidence awesome
so great Monica it's just it's fantastic
okay what is the next concept we should
be thinking about and that we'll talk
about next we can think about we can
think about this I'll give you as an as
a homework for next time how do you know
something is important
sence right how do you know that
something is important this is a
significantly important question in AI
all right and we have good answers but
you may not think of them unless you
have a holistic mind okay salience is
next all right this is the PHX appdev
podcast it's Wednesday April 17th 2024
and we've been talking in the first of a
series to Monica Anderson about how to
build your intuition about artificial
intelligence Monica as always you know
thank you so much uh and we will we will
talk to you next time I enjoy sharing
this thank you very much
