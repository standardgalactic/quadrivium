all right so um I told you guys last day
that um I'd covered most of the new
material that I want to cover um for
this class in terms of uh small
molecules and and Drug Discovery so
today um what I want to do is kind of
take what we've learned and um put it to
like real practical use so um last night
I I got
online um I went to uh the kaggle web
website which is a fun website if you
guys uh haven't seen it they have um a
lot of different like competition like
machine learning type competitions there
in like every you know possible domain
uh and a number of them are uh you know
in um life sciences and and this one uh
and so so you can download models you
can download data sets and uh this
particular data set uh is a set of um
molec ules with like a binary classifier
on whether or not they cross the blood
brain barrier right and we talked the
other day about blood brain barrier so
that's going to depend a lot on uh the
hydrophobicity and the size of the of
the molecule but let's see if we can
build a model to to get a little more
precise than that and and start to you
know predict whether whether different
molecules are going to cross the barrier
so um we can go online and um read about
the uh the data set so it's got about
2,000 compounds and they show you um
kind of a like a preview of the data set
here so you can see it's just
a it's just a spreadsheet right and so
it's got a numerical ID it's got the
name of the molecule if there is one uh
and then a number one or zero depending
on um whether it does or does not cross
the the bloodb brain barrier and then
the smile string right and we walk
through like what the um what the smile
strings mean the other day um so the
first thing we notice here is that uh
there's um about
483
zeros and uh 1500 ones right so um it's
75% one and so now we know if like later
on we're going to look at uh the
accuracy of our um classifier we know
that we can build a classifier that's
like uh about 75% accurate um by just
having it spit out one right so so so
that's our Baseline right 50% accurate
is um is is is not our lower bound it
should be 75% accurate and then we want
improvements on that so we want to see
how far how far can we get from a dumb
classifier that just says oh yeah
everything goes across to a Smart
classifier that you know uh ideally
would be like 100%
predictive okay so um that's where we're
starting and I'd like to kind of walk
through um how we would build that model
I'm going to try to like build the model
for you guys in real time but I also
like uh built it last night so if we
don't get through it I'll scroll scroll
down to the right answer but I want to
go through it slowly so that you can
kind of like see the see the logic here
okay like in the cooking shows like in
the cooking show yeah we're gonna we're
gonna French chef it you know um
actually this model is going to be
really I I thought about that like oh we
we'll do like a little French chef where
we'll start to like run the model and it
might take hours and hours and I'll show
you the answer and it turns out we're
going to build we can actually build a
very uh small model here we can train it
even without gpus and and it'll kind of
run in in in real time okay um so I'm
just setting up uh you know if if you
guys have used Google collab I'm just
giving it access to my my Google Drive
um Can Can you guys see the the text
there or should I does everybody want to
call closer please just you
know um but can you can you guys read
the text I mean from here I can okay I
can they
can well I know
right um let's see see if I can increase
the the font size oh zoom in
yeah you think yeah okay all
right um so we're going to call uh
install a couple packages um that are
going to be useful so we'll install
rdkit and uh and kaggle just so we can
uh download this data set from
kaggle we'll run that
cell okay um and then this is just uh
this is just downloading the
um the data set
itself okay so um so now we've got our
data okay so we have um like a a
spreadsheet basically that has all of
the the smile strings and it has this
label one or zero as to whether or not
it crosses the blood brain barrier
so what's the next thing I need to do
like what do I need to do to to start
building a model I can't just put in
smile strings I I I'm going to need
something else as
um uh something else as the input to my
model right any any ideas any
suggestions what what we should use we
talked about a lot of different like
representations of of molecules like
what what would you guys recommend
yeah it's definitely going to be a
pytorch
tensor but how are we going to get from
a smile string to uh to like a a tensor
of
numbers we've got we've got lots of
options and they're they're kind of all
valid uh I I picked one but I'm I'm
curious to you know let's let's see like
the universe of of options that we have
to choose from
so what are like what are the problems
what are the problems from going from a
smile string to like a fixed length
Vector of
numbers or something yeah so that would
be a great choice right because we
talked a lot about gnn's um and they
make a lot of sense that it it really
starts with the molecular graph so it's
got all the information on the on the
molecule um the problem with the GNN
right is like we've got a vector of
numbers for every atom in the molecule
or like the paper we talked about last
day you know is a vector of numbers for
every bond in the
molecule but what we want to train our
model is we want a like a fixed length
Vector going in right so so there's a
lot of ways to to do that in the GNN
lecture we talked about okay how you
know how how do we do graph based
classification we can kind of add all
those vectors together we could add them
and then divide by the number of atoms
um we could connect them all to like a
dummy node and and you know parameterize
that um so so we have a lot of options
but that's basically the problem how do
we go from um you know a a list of uh
inputs of variable length and go to a
fixed length Vector so um the solution
that uh that I came up with um last
night was uh well let's get online let's
get online and see what people are doing
right um so uh this is another uh
website that you guys should all uh
check out and be familiar with um it's
the the hugging face website and so this
is uh like a really popular website
where people uh share different trans
former based models uh and there's a
nice API so if you find a model on
hugging face it's very simple to like
download that model and and start using
it right out of the box and you don't
have to do a lot of coding on your own
so uh this model is called
kber uh and so Bert is uh is is a
language model and this uh kmta has
basically been trained on um uh smile
strings okay so we're going to input a
string and then it's going to give us
out one fixed length um uh embedding
from uh from that input
okay um and so if you guys are
interested you can you can look up kimta
and and find out more details on you
know exactly how that uh embedding is
made uh I haven't actually looked at it
very closely I'm kind of familiar with
Bert but I don't know exactly what's
going on um you know under the hood for
uh for this one but I do know a lot of
people use it and it's you know it's one
of the leading kind of Transformer based
models
so um so I I pulled that in here okay so
I'm I'm importing um uh the uh
Transformers API which uh has access to
to hugging face um and I just wrote a
like a little function here to convert
smile strings to embeddings from that
Transformer based model okay so we'll
run
that and
yeah yeah good good good question so um
how do you tokenize a smile string how
do we how do we go from that string of
characters to a string of
tokens um in the past uh you know I've
tried just uh well you can do character
by character um and that's probably not
going to be the best bang for your buck
because you know you'll have something
like a like a C1 character and then a
few other carbons and then another C1
where the where the ring gets closed and
so C1 is kind of an entity in and of
itself as opposed to treating it as C
and then one um obviously you can do
everything on the character based level
but then you need a lot more data
because the the model has to learn you
know like what the appropriate chunks
are um so so I've tried very different
um uh things kind of like ad hoc uh and
yeah they they they tend to work okay um
in this case and this is one of the um
one of the nice things about using these
models on uh hugging face is that um uh
like once I uh once I pulled in that
model from hugging face for that
Transformer it comes with a tokenizer
that people who built the model
like thought was like pretty reasonable
and so I'm just using their tokenizer
and I don't I don't actually have to
know how it's uh how it's chunking those
things okay um then the next thing we're
going to do when we Define a model and
and this part you know I want you guys
to uh kind of uh pay attention to I'm
not going to try to like write it out
like in in uh
detail but
um it always pays to make a data set
class okay and data set uh will sub you
know whatever you make it it'll subclass
the you know the the data set you know
the uh parent data set
class and um this uh this class
basically uh only has to have uh like
three different functions so it has an
anit function and here in uh in my nit
function I'm going to read in this uh
this file that I've downloaded from
kaggle okay um I'm going to make a list
of all the smile strings I'm going to
make a list of all the NAB uh the labels
I'm going to ignore the other other
columns I like I don't really need them
um and then I'm going to uh make a list
of embeddings so I'm going to call that
uh that function smiles to embeddings um
that's you know that's using the kta
model and I'm going to convert that list
of smile strings to a list of embeddings
and and now now this data set class is
just going to serve up um you know one
embedding and then the the label which
is one or zero whether across the blood
brain barrier okay so that's all that
all happens in the um init function um
when I instantiate this uh this data set
class uh the other methods that uh that
need to be defined are uh a length
function so if we ask for the length of
the the data set um here it's just going
to return the you know the length of um
the list of embeddings all three all
three lists are the same size so we can
just you know return any of those
links and um then it has to have a get
item class and get item is going to take
one parameter the index and then it's
just going to serve up the um the uh the
embedding and and the label right so
like the example and the and the the
label that we want to train on okay so
so that's all that does um so we're
since we have these things in lists
anyway um we're just going to you know
we're just going to pull that item that
index uh out out of the list and and
then uh we'll return both of
them okay
[Music]
um okay so so that's our data set class
uh the next thing that um I encourage
you guys to always do is uh Define a
data loader and the data loader operates
um on the data set class and it just
makes things really easy um so here I'm
going to separate out my uh training set
from my test set okay and um what I've
done here is I've said um well I'm going
to take the length of the data set um
times 80% and that's going to be my
training size and then the remaining the
you know the other 20% that's going to
be the the size of myh test set um and
then I'm just going to call this
function random split uh with my data
set and then you know the then the size
of my like uh uh training set and test
set and that's going to uh that's going
to return um uh this this split here
with my training data set and my test
data set and then I'll make a data
loader uh you know for the training data
set and I'll make it data loader for the
test data set okay and in the data
loader I'm going to specify uh a few
different
things okay so in the training
loader um the the first thing that I'm
going to specify apart from data set is
the batch size okay and this is this is
really important in general
um we're going to choose the we we kind
of keep an eye on the uh the memory that
um
uh that we're using because we're often
running on a on a GPU uh and we're going
to get the the best efficiency if we can
you know fill up most of the memory on
that GPU with with a batch and so
depending on like how big the data is
that's uh that's going
in um we may be able to use like a very
large batch size or or we might have to
use a smaller batch size okay um the
advantage of using a large batch size in
addition to the speed up is that uh when
we compute the gradient we're always
Computing the gradient on the the batch
of inputs that we're looking at um but
like ideally we kind of want to be
Computing the gradient on the entire
data set when we're up updating the
parameters right so so the more of the
data set we can look at at any given
time
um the more uh the more accurate of a
gradient uh we can get and the more
accurate the gradient potentially the
the fewer steps of optimization that
that we need to go through
yeah um and when I'm training the data
uh so I'm I'm G to like train it I'm
going to pass through all the data once
that'll be like my first Epoch of of
training and when I pass through the
data again um I probably don't want to
go in the same order I want to you know
I want to kind of mix things
um because it could be that uh you know
there's one parameter in the model that
gets trained on a few examples and maybe
all of those examples like are crammed
into like one batch um and so as soon as
that parameter gets updated it sort of
forgets it because you know those those
examples aren't in the other batches and
so I just kind of want to like smooth
things out and prevent it from uh like
getting stuck in in in a rut so I'm
going to shuffle the um the the examples
every time I instantiate the or every
every time I call this uh this data
loader um and then with my test data
loader well I'm probably going to use
the same batch size um but in this uh in
this example I'm I'm not going to
shuffle them because uh like I I I want
to compare the the test from uh from run
to run you know and maybe I'm not going
through like the entire uh maybe I'm not
going through the entire set of uh uh
example so so you know I I just want it
to be really consistent this this is
going to be my test it's not involved in
the in the training at all okay all
right so um once I run this um it's
going
to uh instantiate that data set class
and it's going to start converting those
smile strings to uh the embeddings from
my Transformer yeah do you have a
question
um
shoot oh good point uh oh all right um
yeah so so that was a bug in my code and
now now we're gonna see because like
when I ran this last night I I got to
like 100%
accuracy and now now we're going to see
like for real how
how well it it does or doesn't
work all right that was not
[Laughter]
intentional I'm glad you guys are paying
attention all right so um that's going
to run for a couple of minutes it's so
exciting now um and uh while that's
happening um let's uh let's figure out
what uh what our model should be okay
so we're going to use a
torch uh I'm just going to import um a
few things
here um and so torch. uhnn torch. neural
Nets is uh you know that's where like
most of the functions that um that we're
going to use are are
found and we can Define our model okay
so one of the easiest uh ways to Define
models and you can still Define like
pretty powerful models like this is um
stop
it um through NN sequential okay and so
here I'm just going to put different um
torch.nn layers in and it's going to
take the output from the one feed it
into the next one take the output from
that feed it into the next one take the
output from that feed it into the next
one so I can Define the whole thing as
this you know NN do uh sequential and
and then torch knows that's that's a
model uh if I want to however I can go
through and I can take each of these
layers and I can say like x equals you
know nn. linear and then like X2 equals
like another one of those on the output
of X1 and and like so on and so forth so
I can you know I can I I I can Define it
kind of as an uh like an arbitrary
python function and if I wanted to make
like a variational Auto encoder with
those steps in the Middle where I have
to do like sampling or something like
that um then that's like that's how I
would um uh put that in so so it's you
know it's a kind of a powerful uh
framework we're going to build a really
simple model so it's easy to just use
this uh nn. sequential and we're going
to stack up uh different uh different
layers here so the size of my latent
Vector coming from the embedding from
the converta model is uh
768 okay so I've got a a linear layer
with
768 uh inputs uh and then I want to
downsize that so so let's go from that
to like
128 and then I'll put
another put another layer in here um
that takes 128 and let's downsize it
again we'll say uh
64 uh and then let's put in maybe one
more
layer where we'll take uh 64
inputs and in this case uh we're just
predicting one thing so if we were doing
something uh multic class like there
were uh 10 different um possible outputs
then then we'd want uh we'd want you
know uh to to Output 10 different logits
um in this case there's two different
outputs like zero and one um so so like
I could Define it that way um
but I'm just going to uh I'm just going
to like put it down to one and and have
a have a number between zero and one
that'll kind of predict you know whether
it goes through the barrier or or not
okay
um and so if I want that number to be
between zero and
one uh well I can pass it through a a
sigmoid layer okay and so each of these
layers and you can get on um you can get
on the torch documentation and and you
can see like what are the different um
layers that are in the torch.nn and
that's like a good list of you know
pretty much everything you've seen in in
class and some of the things we'll talk
about today those layers are are all
there and it'll tell you how to define
them so you know if I'm doing a sigmoid
it's just like taking a number in uh and
running it through a sigmoid function so
it's between zero and one so I don't
need any parameters there um for my
linear layers I just need to specify
like how many nodes um are going in and
then how many notes are are coming out
and different layers you know will will
have different uh um different uh
mandatory and optional parameters that
that that we have to specify okay all
right so so this is my neural net I'm
going from 768 to 128 or yeah 768 128 64
and then down to one um what have I
forgotten
what's
that yeah so this is this is all just
going to be linear right so um so I
wouldn't even need three layers I could
just mul you know I could just pre
multiply those layers together um so
that's not going to do me any more good
than than if I just said it was a 768 to
to one layer all right so let's put a
nonlinearity in
here um o yeah and Google already
guesses that I want to put a reu in I do
than thank
you um we'll put one after
this okay uh and then our last one is uh
is going into our sigmoid function so uh
so we don't need a activation there
either
um okay so uh so here's our model uh and
now let's run that hopefully that's
syntactically valid okay
[Music]
um all right
so we have our uh we have our data
loader our train loader here um and we
have our uh model okay so now
um now we just need a like a loop toh to
train this thing on okay so each each
iteration through our data set uh we're
going to call an epic so let's say um
number of epics equals 10 okay so we'll
we'll run through it 10
times um for epic in um one through 10
uh here uh it's suggesting that I do
this and it's it's always a good idea um
so when you're training your model you
can say model. Trin and then when you're
evaluating your model you say model.
eval uh and then if there's any uh
bookkeeping that it needs to do uh in
terms of you know whether to update the
parameters and and things like that
it'll kind of take care of that for you
which is very
nice
um or updating the gradient actually um
and
so for each epic uh I'm going to Loop
through all of the batches uh in my data
loader okay I'm going to
say um embeddings and L labels
in train
loader uh and my
outputs uh whoops are going to
[Music]
be uh the output of my uh model
embeddings um
and uh my uh my model uh even if it's uh
like outputting a scaler it's G to um
it's going to put an extra dimension on
the end of it so it's not really going
to be a scaler there's going to be
another dimension there that's uh you
know that that only has one thing uh and
that's going to cause me some headaches
so uh I can get rid of that with this uh
with this squeeze
function uh and that's just like a lot
of the bookkeeping um that we have to do
in in torch to to make sure that
um uh you know the we're we're operating
on the right dimensions of the of the
tensors that we
have um okay and then for my loss
function uh I'm going to use one of
these built-in loss functions uh pretty
much everything we'd you know ever need
is already built into a torch. neural
net and in this case we'll use uh BCE
loss um of our uh outputs and and and
labels okay um oh look at that all right
it's autocom completed the the next
thing I want to do um okay so uh now
we're We're looping through our our data
loader um we're Computing the the model
output uh and then we also have the
labels so we comp we can compute our
loss function fun okay uh now we need to
um back propagate that loss function so
for every parameter we know how like a
small increase in that parameter affects
the the loss right and we want to
minimize the the loss so uh the first
thing I need to do is um if any of the
parameters in my model um have a
gradient that's already stored from some
previous operation so for example the
second time I run through this Loop
there's going to be a gradient stored in
all those parameters from the first time
I went through the loop so uh I'm going
to Loop over you know for p in in model
parameters uh I'm going to just uh zero
out the the gradient so p. grad equals
equals zero or equals none here um so so
that's that's good practice well not
good practice it's absolutely required
um but I can uh I can either do that
before um before I calculate my my
gradient or I can do it uh after I'm all
done it doesn't matter too much uh and
now I want to calculate my gradient and
nice thing about working in torch is
whatever computations that have been
done up to this point to calculate the
loss now I just uh I just call loss.
backwards okay and all the prameters
that uh that went into that calculation
that backwards function is going to back
propagate it through and for each of
those parameters it's going to store
their gradient um like as as part of
that uh parameter right so it's going to
store it like P.G grad so it'll have p.
dat that's the value of that parameter
and then P.G grad is going to be the uh
the gradient that was calculator from
from from my backward
computation okay so now every parameter
in my model has you know has some value
and and it has a a gradient with respect
to our loss so I'm just going to Loop
through all the parameters in my model
and I'm going to
subtract um some constant uh here it's
01 times uh times the gradient and I'm
just going to subtract that from uh from
from the data here
okay all
right uh great now let's
um uh let's see
let's keep track
of all of our
losses so say loss
list and we'll initialize that have
nothing in it at this point and then
after we calculate the the
loss um let's just append the um the
value of that loss to to a list okay and
then down here when we're done
oh
lovely uh we can say uh we'll make a
dummy variable temp which is um just the
the average loss um in that in that list
so that's going to be the average loss
over that whole uh epic uh and then
we'll print the number of the Epic uh
and then uh what the value of that loss
is and and we'll see hopefully that our
loss will start out quite large um and
as we train it'll it'll get smaller and
smaller right so should we give it a
try it works nice um okay so we're
training over 100 epex here uh and our
loss started out at like 61 but as you
can see it's it's getting smaller and
smaller um and because this model is uh
is pretty simple like it it worked
pretty well and you know I put in a
fairly so this parameter here 0.001 is
called The Learning rate um and we just
kept it constant and it's constant for
um like every parameter uh and so it's
it's really kind of a a vanilla model
and it tended to work pretty good if if
we try to train uh like much larger uh
and more complicated models uh we like
we might need to do more in terms of uh
uh getting that to to to work
efficiently
okay all right um so now let's uh let's
move on and um let's calculate
uh let me just redefine my my model
here uh so that'll that'll erase what uh
what we've done before
and um now I I I just want to
um uh train it with uh a few more
additions so that we can make a plot of
uh kind of what the loss uh what the
loss looks like um and
uh we can compute
the
H well for some reason the the code I
wrote last night night is
uh is Now not working um and the the one
we did on the Fly is is working better
okay uh I'm not going to worry about
fixing that uh right now
um but uh maybe uh maybe if we have time
after the after the lecture I'll I'll
come back sorry that was like um that
was uh
anticlimactic um hm
h h i wonder maybe if I just start again
like start again up
here okay we'll we'll try that and then
then we'll come back to it because maybe
uh you know maybe I overwrote something
in fact
uh why don't we just uh restart the
whole thing
okay
um load it
up we
will oh I yeah I actually know what
happened all right um
I need to
Define few
variables uh my Criterion so that's
going to be my um binary cross entropy
loss and I need to Def find my
Optimizer um and that's just to use some
of the um some of the fancier features
uh here so so we're going to train with
um uh with an optimal ER called Adam or
Adam Adam W actually Adam with weight
Decay um okay so we'll do that we'll
we'll let that run in the in the
background um okay and so so now I want
to switch uh to uh talking about like
how how do we train these uh networks in
general and kind of what are
the principles and and um pitfalls and
things like that
so you saw the kind of of the the most
barebones way to like train parameters
in in my model
um and uh that's really just a gradient
descent and so I take my parameter and I
uh subtract the the gradient of the
parameter times some uh learning rate
okay if I'm doing that uh like in theory
or in principle I'm doing it on my
entire data data set then I'm doing
doing gradient descent in practice um
I'm always running in these mini batches
right in this case we're doing 32 at a
time uh and so I'm only calculating the
the gradient over those examples in in
the mini batch and and then I'm then I'm
updating um updating the parameters um
based on that calculation so um that's
often referred to a stochastic gradient
descent because it's it's kind of random
right we we shuffled our data loader
every time we went through it's kind of
random which examples are uh put
together into the same batch and so it's
not GNA it's not really going to be the
same thing as uh as as a gradient
descent and you know in in practice
uh um that's really the the batch size
and everything is is done for um
pragmatic reasons and uh making the
computation uh use the GPU uh more
efficiently things like that
um but it also has this property of uh
regularizing the uh the optimization and
it makes it harder for the model to kind
of memorize the the answer to you know
what's going on in in in the trading
training set okay and we'll talk more
about different ways to regularize later
um okay so if we want to get fancier
than
um just subtracting um some constant the
learning rate times the the gradient
from our parameters there's a number of
ways to do that um one is a whole class
of uh uh methods called momentum methods
and we'll talk about what that is uh but
it it's kind of like how how it sounds
like once once you start driving the
parameter in this direction you tend to
keep driving it in that direction um and
the advantage of that is if the surface
that you're optimizing over is a little
bumpy
well you've got this momentum and it
sort of like pushes through and and sort
of effectively Smooths it out um and
then we'll talk about adaptive learning
rate methods uh there's many of them and
the idea here is that um you know we at
different points of the optimization we
may want to spend more or less we want
to put more or less attention onto
specific parameters
okay and so those are our adaptive
learning rate methods and we may want to
uh change the the learning rate not only
over parameters but like over time as
well okay so um how does momentum work
uh momentum is pretty simple here's like
the the basic formula is if I want to
calculate the um the momentum the
momentum is uh what I'm going to use
instead of the
gradient okay and it's basically going
to be it's kind of the
gradient but I'm also going to say like
um what was the what was the gradient or
actually what was the
momentum um in the previous time step
and then I'm going to take some average
between the gradient that I'm
calculating based on based on the loss
for for this batch of
examples and like whichever direction um
I you know I I I moved in the in the
previous time step so if the previous
time step Straight Ahead like this and
then I look at these batches and it's
saying no you want to move in this
direction action well you know if uh if
my momentum is 0.9 then I'm going to
move you know in a Direction that's
that's mostly you know where I was going
before with a slight correction um and
if uh you know if if the momentum is 0.1
then then it would be the opposite right
I'd be moving in the direction of the
gradient with like a slight correction
um based on the momentum in general it's
it's you know probably going to be more
like 0. n so I'm I'm you know moving in
the in the uh generally in the same
direction from time step to time step
but if I get a lot of Corrections that
are all pointing in the same direction
then you know then I can uh then I can
change that okay uh and actually this is
like parameter by parameter so it's not
really this orthogonal thing it's more
like you know if my gradient was here
and then the in this batch is going the
other way then I'd still kind of be
going
forward okay um so with this formula um
every time um every time I apply this
this parameter this momentum term um I'm
I'm applying it uh again to all of those
previous time steps right and so this
term even if it's like
0.9 um you know my gradient from Three
Time steps ago is like 09 cubed my
gradient from 100 time steps ago is like
0.9 to the 100th power so it's like
basically zero uh and so it's this you
know what happens is at each time point
I have like an exponentially decaying
influence from the the previous time
points okay so that's the whole idea
behind uh momentum methods that's
basically what a momentum
is um adagrad is uh is an an algorithm
that um basically I identifies uh
features that are used less frequently
and what it says is um you know once
you've
um once you've done a lot of updates to
a certain parameter then then you want
to go slowly because often times we see
the loss go like way down initially and
then you gota you got to you know uh
turn the learning rate down because
you're getting close to uh to where you
want to be and and you don't want to
move as far so you want to like slow
down a little bit uh and at the same
time when you get to a batch where um
you have examples in that batch that are
really informative for part of um for
one of the parameters in your model okay
so maybe it's a like a a certain
molecule with a certain kind of ring
structure where in your 2,000 examples
you only see it like 20 times so when
when you see like part of the model that
is informative about that feature and
you want to learn from it then you
really want to pay attention okay so it
keeps track of like how big have the
updates been on this parameter um and it
uh basically accumulates them by taking
this the squared value and then taking
the square root so it's like a root mean
square and then it's just dividing the
um the size of the parameter update um
by the um kind of how much that
parameter has been updated already okay
so you'll start to start to optimize um
a lot of your parameters in initially
and then as you keep training you're
going to really focus on the parameters
that haven't been updated yet okay so
that's kind of the idea behind uh adrad
the um the problem with adaag grad is
that uh um you can you can get to a
point where um like lots of your
parameters they've been they've already
been updated a lot uh and you might need
to update them again because the rest of
your parameters have moved but now like
that denominator is is so small that
your learning rate like goes to you know
close to zero and it just takes forever
to train so so that's a problem um RMS
prop uh kind of Builds on Ada grad
because it says okay well instead of um
just adding up all of the previous
gradients So eventually like things are
like approaching zero um let's uh let's
use momentum on that you know that uh
accumulation terms so it kind of
exponentially dies off and then you're
only ever looking at like a window of
previous gradients so like once you've
updated enough um if you've stopped
updating this parameter then um then you
will forget that you updated it a lot in
the beginning and and it sort of takes
care of that problem okay
um so uh
the the U method that kind of Builds on
that now is is uh is atom and so what
Atom does on top of uh RMS prop and you
know on top of uh like keeping track of
um that
gradient uh that accumulation of
gradients is it puts a momentum term on
on the gradient itself so it's combining
it's taking RMS prop and then saying
okay what if we also put momentum on the
gradient
itself um and uh that ends up being uh
being pretty useful for a lot of
practical problems and so if we just
look at you know the number of machine
learning papers that um that use these
different algorithms uh you can see that
uh like Adam has has really taken off in
terms of um you know being a like a
really effective way to uh to to train a
lot of these
nets okay so um let's walk through how
we use these to uh to fit like a simple
model so the data I'm showing you here
um this is from a line um you know uh ax
plus b you know yal ax plus b you can
figure out what um a and and B are
probably by by looking at it I don't
actually remember um I think it's 2x +
one or something um and and I just
generate ated points on that line and
then I added a random number right so I
just made like a noisy I just made noisy
linear data but like my model literally
has two parameters um like plus plus the
noise term and we'll never fit the noise
term we kind of don't want to fit the
noise term but if I put like a a
gigantic neural net and train it on this
it's you know it's going to fit it um
it's going to memorize all those data
points um but it's not necessarily going
to produce anything useful
okay so um here's just a kind of an
example of what I just said uh on top is
uh this is the model that I'm going to
use to to train it right so I've got my
linear layers I've got my nonlinearity
I've got another linear layer um that's
taking those you know those thousand
inputs and and um adding them up uh in
in According to some waiting function
and then outputting a number right so
that's model I'm going to train um and
below is is my model of appropriate
complexity right it would just be a
linear layer with one input one output
um that model is going to have two
parameters it's going to have our our Y
intercept or our our bias term and then
it's going to have our it's going to
have one weight right um which which
would be our
slope um but let's say you know op
priority we don't we we don't know what
the internal structure of the model is
so we're going to fit it with uh with a
model that has way too many parameters
and and is way too powerful and then and
then see what happens right uh and
generally what's going to happen is if
we have some some loss function and we
look at our training data uh the
training loss is going to is going to
drop precipitously at the beginning and
then it'll continue to drop um you know
as as as we go on the more we train it
um like the the lower it's going to go
in general and there there there can be
bumps
um if we hold out a a test set or a
validation set and then we train on the
on the training set but then we evaluate
on on the loss of the um uh the
validation set what we're going to see
is well probably the validation loss is
going to go down initially with the with
the training loss and and it's going to
go down because you know we we start
with uh like random parameters um so
it's pulling us generally in in in the
right direction um but then at some
point um as we start to if we have a
simple model and we start to memorize
individual data points it's going to
make us perform worse on data points
that we haven't seen okay um and in
general there's uh we we have a a
tradeoff between
um model complexity in different types
of uh different types of error and we
can break the the error down into uh
three three different components one is
going to be the the bias okay and that
really is um how you know if we um if we
were to look at uh an infinite number of
examples where would the model be
converging on like our model is probably
not the true underlying model um and so
it's GNA um you know it's it's not the
perfect model so it's going to converge
on on some point that is uh potentially
not the right answer right so so here we
can see like there's a there's a Target
and and like a
bullseye um and the um the the Y AIS
here these are um examples of models
with high uh uh High bias okay so the
you know the the ground truth is here
and you know our models predicting
points here or the ground truth is here
and our models predicting points over
here um so we have a bias model down
here um you know as as as we sample an
infinite number of points we're we're
like spot on so our bias is very low and
here you can see the points are more
spread out but the more we sample the um
you know the the closer the average gets
to the to the true answer because the
bias is low so that's our bias term um
there's also a a variance term and uh
the variance is exactly what it sounds
like you know these these two examples
there's very little variance between
what the model predicts for um for these
different
inputs
um and uh over here in in uh on this
side we can see two models that have
high variant so this is high variance
around a biased answer and this is high
variance around an unbiased answer right
so so these are uh these are kind of our
our our two terms um and there's really
uh there's a tradeoff uh between these
two and then the last form of error is
just irreducible error and you can think
of that as well gosh if we're if we're
collecting data with some um instrument
that we're using to measure a physical
process uh and now we're going to try to
like fit the um uh you know we're taking
that as the ground truth and then we're
going to like build a model to to
predict the output of that instrument
well that instrument um it might be
noisy in itself right every physical
measurement we we take is going to have
some some error um and even if we have
the best model in the world it will
never be able to um you know uh predict
like what is the what is the error in
our uh instrument right okay
um
so uh we have this trade-off between um
bias and uh variance and that's where
regularization comes in and so
regularization is uh basically what we
use uh like when we have these models
that have way too many
parameters um we can trade a little bit
of bias so we're not going to try to
predict the the exact answer we're going
to like we're going to put another
constraint on the problem that is really
intended to prevent overfitting but by
virtue of the fact that like the thing
we're trying to optimize is not the
right answer like that that inherently
is going to put some um put some bias
into the into the process right so it's
going to it's going to take a model with
very high complexity and reduce the
effective complexity of that model
because we're putting a a constraint on
it and hopefully the the goal is that
that's going to help us generalize to to
new data or you know like go from our
training set to our test set okay so
what are some uh regularization
techniques um well the first one is is
really simple um if we go back
to uh this curve um you know we could we
could just stop here
right if we if we remember let's say the
last um you know 10 iterations of our uh
of you know of our our model or on this
axis maybe the last 100 and we see that
the validation loss is going down and
then is bottoming out and then it's
starting to come back up well then we
could like go back a few steps to to
where we thought it was a minimum and we
say like this is this is our model we're
just going to like stop there right so
that's just early
stopping um but we can also um put
constraints on the model so one popular
one is uh
L1 um and that's basically where we take
all the parameters in the model and we
take their absolute value and we add
them together and then we're just going
to add that to the loss function with
with some constant okay that'll be L1 uh
L2 is kind of the same thing but we're
going to take um the square of of all
the parameters uh and then we're going
to add that to uh to our loss function
um we can we can take a little bit of L1
and L2 uh together so we can have two
constants and we can we can put them
both in uh and that has some really nice
properties and um there's many other um
techniques that will help regularize the
data in fact doing stochastic radiant
descent in and of itself regularizes the
data
uh and we talked earlier um about batch
Norm that um that actually ends up
regularizing the data and so like a lot
of uh a lot of things we do um help to
to regularize data um one thing that
prevents the model to some extent from
memorizing the training input is Dropout
and so with Dropout we can add Dropout
after any of the layers in our model and
then um while we're training it will
just
ignore like some percent of the of the
neurons so it might ignore like you know
10% or 20% like a like a good fraction
of of the neurons in any particular
batch
okay um and that that really helps it um
you know uh prevent uh helps prevent it
from from memorizing specific answers
and
overfitting um okay okay
so if we're going to put in these
regularizers um we're putting in a lot
of additional hyperparameters in in our
model so you know like how much L1 how
much L2 are are are we putting in how
much drop out uh these these are all um
new parameters that we have to optimize
over and so that's where cross
validation uh becomes really useful and
so you know I've shown you well I can uh
you know divide my data set into like a
a training set and and a test set um but
I can also take that training set and
and I can divide it up um and I can um
kind of optimize uh all the different
hyperparameters in in my model uh you
know like leaving um uh leaving
different um validation sets out and so
so I can use all of my data
um to to fit those hyperparameters
instead of just you know like 20% of
it um skip that okay um so here's an
example of uh what would happen as we
start to overfit the model right and
here you can see it's uh you know the
orange points are are the the data
points that that I
generated uh I generated them from a
simple model just a like you know a
single line uh and you can see um here
we're getting we're getting like fairly
poor Behavior it's the loss is going to
be really low because the model is like
you know predicting uh most of those
orange points exactly uh in fact I think
this model may be fitting all of the
orange points
exactly um and and I think that the
Orange is just like in in front of the
uh the blue so you can't see it uh but
but regardless um the
the things that the model is doing
interpolating between those orange
points is is kind of nonsense right um
and certainly uh everything it's doing
extrapolating from that line is you know
um complete
nonsense okay um so uh we can take the
same model and we can run it um with
early
stopping uh and when we do that we get
the following curve
um which looks pretty good like it's not
uh it's not quite linear on the on the
edges but uh but the rest of it looks
pretty good like that's that's a pretty
good answer and and it's only getting
weird in the in the extrapolation range
and honestly like if you looked at that
data and you didn't know that um it was
generated from a from a linear model you
might think that it's got a little curve
in there you know it almost looks like
quadratic um we can overfit our model um
and then add an L1 term okay uh and this
is kind of what we get uh if if we put
some L1 in and now we can you know uh
overfit the model as much as we want and
here's our output so it's still doing
pretty good it's doing bad in the
extrapolation range but it's doing
pretty good over you know over most of
the range of our model and on the left
um what I'm showing you is uh I'm
showing you the value of all the
parameters in the model right so you can
see what L1 is doing L1 is driving
almost all the uh parameters in our
model to zero right uh and then you can
count you know uh the the total number
looks like 10 there's 10 10 nonzero
parameters and and those are uh kind of
driving the the whole model and if you
were to look at the line you know you
can probably um you can probably see
like 10 different like segments there or
something
okay what about L2 um well if we look
like that's a pretty similar fit but the
uh what it's doing with those parameters
is very different right and so if if we
think about it this way if um if we have
multiple parameters in our model that
are all saying the same thing L1 is
going to want to U it's going to pick
the best one the the one that is just
infinitesimally better on like one data
point in our set than the others uh and
it's going to like over optimize the
loss based on like whichever parameter
actually fits the data the best okay so
it's it's going to pick the 10 best you
know or however many best parameters and
it's going to drive everything else to
zero
L2 um is and and is driving it to zero
right because we're putting a penalty
we're the loss function is is going to
include the sum of all those parameters
so it wants them to be to be small with
L2 we're going to square those
parameters so if we have two parameters
that um you know maybe one is
infinitesimally better than than the
other one um if we want to put the full
weight of the the slightly better
parameter into the
model um you know let's say that's uh
the the weight is like 0.1 right so
we're going to put the full 0.1 in and
we're going to drive the other parameter
down to zero and so now our
our um our L2 is uh going to be 0.1
squared or or or 01 but now what if we
um what if we take you know
0.05 of this parameter and 0.05 of that
parameter right and
now um because it's squared like we
we're actually um uh the the L2 penalty
is much less right because now I'm uh
I'm I'm taking half of those numbers and
then squaring it so so I you know I get
a fourth and a fourth I add them
together I get a half right so so you
know if we have two parameters that are
equal my L2 is only going to be one half
as large if I split it between them as
opposed to making you know one zero and
the other one full value and so you can
kind of see that right like look at all
these parameters um in the middle here
that are that are essentially like the
same
value it's like it's creating a model
and you can you can almost see like
there's a parameter here there's a
parameter here there's a parameter here
there's one here there's one here
there's all these parameters in in my
model that are like they're about the
same um and and I'm I'm splitting the L2
over um overall of them right okay um
and so uh you know produces produces
something similar but it you know makes
us pay attention to to uh more of our
points uh so it's a little more popular
than than L1 and L1 plus L2 has some uh
nice properties as well okay um
now so L2 is is probably like the the
most popular um one of the most popular
ways to just add some regularization to
our loss function um in general um we
don't just add the we could add the L L2
term if if we were Computing the
gradient ourself uh like we did in the
you know in the first example that that
we wrote out where you know P um equals
P minus learning rate times gradient um
if we're doing our update that way it's
kind of okay if we just add L2 to our
loss function um but in in general
um because uh uh Adam and
um a lot of these um terms that use
momentum um are are storing like what
the gradient was in in the prior term if
if we add our L2 to the loss function
then compute the gradient of that um
then that gradient is getting Amplified
every every step that the uh that you
know um that that we do an update and so
it builds up a a momentum in a certain
direction and the amount of momentum it
builds up is depend you know depends
on how big that parameter was when it
was uh initialized and and it just like
uh it kind of WS Havoc um with things
and and it
uh uh it's it's not good and it sort of
dilutes out and sort of randomizes the
the regularization effect of the L2 and
so in in practice um we're probably
going to use an Optimizer an Optimizer
like Adam and then um uh sometimes it's
called Adam W sometimes it's just called
called atom and there's a parameter for
for weight Decay but we put the we
basically compute the gradient first and
then after we've computed the gradient
so we don't put the L2 in the loss
function after we've computed the
gradient um we uh like we we add the L2
term in you know as part of the as part
of the optimizer in the parameter update
but we don't includeed in the gradient
so it doesn't it doesn't like have
momentum and and keep pushing Us in in
that direction yeah so uh in general
when you guys are like building models
you you can just use some of these um
existing optimizers like atom you can
put in you know like weight Decay equals
like whatever and and it'll take care of
all this uh all this stuff for
you um yeah okay uh Dropout I think is
kind of interesting too um so uh here's
what uh here's what overfitting that
same model looks like um with Dropout
and and here you can kind of see it's
yeah it's uh it's not really um as
linear uh as as the other ones and it's
still doing weird stuff at uh at the end
but it's got kind of a nice like
smoothing effect uh in in the middle um
and you we get that just by dropping out
50% of the neurons like every time we we
run it and it kind of makes everything
like a little
redundant um this is on the left you can
see what the parameters look like I
don't have an intuitive explanation for
uh like what that cloud means I just
thought I would like also also show it
I'm I'm sure there is a like a good way
to to understand that
um and uh adding Dropout is is pretty
easy we just put in um a a Dropout layer
and then we can specify uh like what
fraction of nodes to to drop out like in
in that layer and we just stick that
into our model
okay um batch
normalization uh is another way to
regularize things um and also uh help
the the back propagation algorithm um
you know distribute gradients from all
the way from the loss function to
earlier in the model and one of the
problems there is as we go layer to
layer to layer um some of those
gradients can can disappear um and so or
or explode and so batch normalization
helps that by um saying for for each
activation in our model we're going to
um set the mean in the standard
deviation to zero and one
respectively um for all of the examples
in uh in a particular batch okay uh
that's kind of how how that works um
it's uh ends up working really well uh
and it allows us to train like much
bigger models
uh this was the original paper batch
normalization um accelerating training
by by reducing internal covariant shift
so the idea there was uh you know I I I
used to have um I used to be getting
input from these other layers uh that
you know that had some um some set of
weights and in my parameter updates like
those other layers and the inputs coming
in have shift did and so now like I I
also need to like shift this layer
because it's on like a it's on a moving
landscape um there was a nice paper uh
well I guess I don't have it a nice
paper that came out of a group here at
MIT that actually showed that's not true
that's not uh that's not what Bas
normalization does but empirically we
know Bas normalization works and and so
the new hypothesis on on how it works is
that um it actually uh Smooths out the
the Lost land ape so if the Lost
landscape is like kind of bumpy it it it
Smooths it out um so you get not as easy
to get stuck in in in local
Minima um I don't think I want to get
too far into oh yeah here's so here
here's the paper from from MIT kind of
uh showing how it works um and I think
uh I think that's all I want to say um
kind of about uh uh some of the some of
the theory and some of the algorithms
behind um training these networks so uh
let's go back and let's see how how our
model did is this uh is this from this
run okay
um yeah I think I think this is from
here so uh we started out with our uh
our first epic and we got up to
86% accurate so better than 75% that's
great um as we and here I'm looking at
my test accuracy so I'm only looking at
the so you can see the loss here let's
let's go back uh my loss um started out
after the first epic at 38 okay so
that's the function I'm trying to
minimize um and that's uh that's my loss
on on my training data right so that
should just like generally be uh just be
going down each each
epic um but my test accuracy this is on
the data I I held out right so this is
my loss on on the training data is my
accuracy on the on the test data um so
definitely my loss is going down that's
to be expected um but what's nice is uh
my my test accuracy is uh is generally
going up so here we're kind of
um in the we were in
the90s we're hovering around around 90
and and if we get a let's go all the way
down our loss is getting pretty small
um and our test accuracy is about uh 90%
so pretty good better than random uh
it's I I I thought it was like
99.9 because uh because we because I had
the wrong training set um but it means
there's uh there's more to learn here so
uh what else could we do
well we could start with um with a more
sophisticated model we just had like a
really
simple um uh neural net with uh with
three layers so you know we could put uh
different kinds of layers or or more
layers in there or um we could actually
start with uh with a different way to
represent those molecules like a graph
neural net or or something like that and
and that that's probably if I had to
guess that's probably where um where we
could gain some ground is is having a
more
sophisticated uh embedding that that was
going into our model um but here we kind
of uh see how all the all the features
work uh and let me just uh let's plot
this out let's see what our loss
function looks
like um and so we can see it it starts
out pretty high um and then as as time
goes on it it it it really starts to
uh starts to decrease here uh and and
you know our our loss gets pretty low
and and uh sometimes it spikes right um
and uh and the same is true of our
accuracy and part of the reason for this
is when we're when we're fitting our
model
um we're not just trying to get the
right answer right so if it um if it
crosses the bloodb brain barrier and it
and it's a one um we're not just trying
to get a a probability greater than um
0.5 our model is getting um uh
maximum uh or minimum loss if it's
predicting with 100% confidence that it
crosses the bloodb brain barrier and you
know if it doesn't um it's getting like
it's it's you know maxing or minimizing
the the loss by you know predicting uh
100% confident that it that it doesn't
right and so even if the model is um
perfectly accurate the loss is not
necessarily zero unless the model is
100% confident of of the answer and so
that's really where like a lot of the
overfitting comes in is your model is
getting trained and it's getting
rewarded for being like overly confident
about um uh you know testing answers
that it's that it's memorized rather
than um you know just just trying to uh
to generalize based on on what it's seen
okay uh and that also explains a lot of
the you know why your loss can go down
um and your accuracy can go up or or or
vice versa okay um so uh that's all I
have to say on that and that is the end
of uh the small molecule section
um Professor Kellis is is going to talk
to us about a few more topics I think uh
gwas and um uh some some other exciting
uh areas of of deep learning in life
science for the next two lectures and
then um then on to the the final
module all right
