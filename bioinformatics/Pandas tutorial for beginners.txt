As the sun and the noise comes in through the side window, let's talk about what we're going
to discuss in this video. I'm going to show you the library called Pandas. P-A-N-D-A-S. Pandas
is the animal. It's one of the success stories of Python or at least one of the libraries that
has helped Python become so successful. And it's all about managing your data. Your data is going
to be in a spreadsheet and we're going to bring that spreadsheet in and we can use Pandas,
the Pandas library, to manipulate that data. Because when you analyze data, you only want
certain parts of that data when you want to use that data inside of a student's t-test
or chi-square test. And that brings me to another thing that I'm going to start this video off
with and that's to tell you about the different data types. All the data that we collect are
of a certain type and that's very important because that type is going to determine what
statistical test we can eventually use. So this is going to be quite a long video. There's
quite a few things I want to show you. Pandas is a massive library. We're only going to
scratch the surface, but we're going to scratch the surface of the stuff that we are going
to use when we analyze our data and when we do our statistical tests. And here's our notebook.
We're going to talk about manipulating data. So you see, I've given it a nice title there
underneath the clinical research, all in capitals. Both of these, by the way, as you can see,
they're just under the one hashtag there. So I'm going to get the title size for both of those.
But just to distinguish them, I put the first one all in capitals, uppercase letters, and the
second one not. You see my name there. I just wanted to show you how to do that. So if you have
this little greater than symbol there for a line with a greater than symbol, you're going to get
this nice little gray bar. And as I said, we'll get to how we import all these little images a bit
later. So the pandas library, we're actually going to work with data. I think there are very few people
who have not seen a spreadsheet before. I'm going to show you a few things about spreadsheets.
But the data is going to be in a spreadsheet and we're going to bring it in to Python so that we can
stop manipulating and working with the data. We want to answer questions from that data that
I always teach the fact that the data hides a story, it hides information, and it is our duty
to bring that story out of the data. We've got to pull it out of the data so we can use it for
inferential statistics and inform or infer at least those results to a larger population. And we'll
certainly get to all of those things. Now, one of the libraries that has made Python so successful
is called pandas, and it's P-A-N-D-A-S, just as the animal, pandas. It is one of the most successful
libraries inside of Python. And as I said, it's really one of the success stories, or at least
contributed greatly to the success of Python as a language for data science and for statistics.
So we're going to use this library to extract all of our data. So let's just go back one step here.
This is my Google Drive. You can see there, my drive. You can see I've created a folder in there
called Coursera. And I've created another folder inside of Coursera, which is understanding clinical
research, because most of these videos really aimed at people taking my Coursera course, although,
as I mentioned, it's open for everyone. And inside of here, I've just created two other folders as
well. And that you can just do by clicking on new and then hitting folder, you can have a folder,
a couple of those. And if I right click on them, I can even change the color, give them a bit of a
color just to distinguish them, which is always nice. And so I've created this data folder. Let's
just open the data folder. And you see there's a bunch of stuff in here, mostly CSV files, CSV, CSV,
CSV. And a CSV file, well, it's CSV stands for comma separated values. So it's basically a text file,
a very old fashioned TXT file, and the different values, the data point values that were collected
for every patient or every subject in your research and every column, which is a variable. And I'm going
to talk about that in this video. It's just all of those data points are just separated by commas.
So it's just interpreted nicely as a spreadsheet would be, of course, if you use something like
Microsoft Excel, it's going to save it as an XLSX format. And certainly, you can use Python and
Pandas to import those, but it's much more common to have files in CSV format. And the good thing about
CSV files are that they strip all the unnecessary bits of a Microsoft Excel file. In a Microsoft Excel
column, you can format that column so that it looks different, so that the values are displayed
differently. That's no good for data analysis. That's no good for statistical analysis. We want
to strip away all of those just fancy added things that make the spreadsheet look a little
bit better. And I'm going to show you a spreadsheet that might look good when you open it, but it's
actually horrible for data analysis. You want to strip all those things away. So when you are in
Microsoft Excel or LibreOffice or whatever the software you use as your spreadsheet software,
when you save that file, save it as a CSV, comma separated values file, it makes it much easier
at least for us to work with that data. And you'll find, as you start analyzing data, as you learn how
to do your own statistical analysis, calculate your own confidence intervals, calculate your own p-values,
is that a lot of the work is just about cleaning up the data and getting the data in the right form
in the spreadsheet before you bring it into panels. That's certainly, or into Python, that's certainly
part of the work. So I've got one file here, problematic, and I've just created it as a Google
sheet instead of an Excel file or something like that. And if we open it, it looks like this. And
at first glance, it looks beautiful. Look at the lovely colors. And I've got these totals for the
columns down here. And I say on the left-hand side that that's a line for average and that's a line for
SD. And I've got a little pivot table going on here. And I've got a nice plot here, scatter plot.
And everything is nicely colored. And I see the dollar symbols there and percentages there.
It looks lovely. You cannot analyze this data. This data, as it's captured here, is not for
statistical analysis at all. Well, you can do a little bit of statistics inside of Google Sheets or
Microsoft Excel. Yeah, you can do quite a bit. But it's not nearly as powerful as using a language.
So no, this is not good. This is not how you save your data. This is not how you analyze data.
What we are after is sometimes called tidy data. And in R, there's this whole thing about tidy data.
And there's actually the tidyverse. That's a bunch of libraries that just conform to a principle
of the use of tidy data. So let's look at what a spreadsheet should look like. It looks bland,
but this is exactly what we want. Look at this. There's no colors. There's all your columns,
all your rows. And it's just very neat. And that's what we want. So what makes it neat? Let's have a
look at it. First of all, let's have a look at these columns. I have a name column there in my first row.
So my first row is going to be used for my statistical variable names.
There I have DOB for date of birth and age for age. So what is a statistical variable?
Well, we've spoken about computer variables, but a statistical variable
is something that is of data that you can describe as very contained, all the same forming,
all the same format, following the same format, I should say. So age might be an appropriate one
there. It's just a bunch of whole numbers, integers. So down that column, I have this variable called
age. Sometimes you'll come across something called a random variable. So random variable would refer to
any one of these values. So the data point values can take on a random value. If I just walk down the
street and just grab some people, ask their age, that's just at random. Of course, we can be biased
in our data collection, because if I walked around an old age home, there's going to be a bias in that
random data. It's not going to be as random as you might think. If you walk around a school, that's going
to be, likewise, have a little bit of, well, have a lot of bias in it as far as it comes to age. But
random variable means random value in that variable. I like to use the term a data value,
a data point or data point value. And that for me is more descriptive of the fact that I'm going to
collect one data point value for that variable for that specific patient or whoever's in my study.
So on that first line, I have all my variable names. Quick note, if you look at these, let's look at
instance for this one, cholesterol before. And that looks odd because I used uppercase C, uppercase B,
and I left no space there. Forget about these fancy typing. Don't put spaces in those. Either put an
underscore, as we do with the computer variables, or bunch them together like camel case here. I can
still read what these variables mean. But it's so much easier to analyze if I don't have these illegal
characters like spaces and all sorts of funny symbols. Don't put them in. Look at this one,
SBP, systolic blood pressure. I just put in lowercase s and uppercase BP. That's fantastic. I can still
see I mean systolic blood pressure there. And I haven't written it out. And I haven't put spaces in
between the words. Forget that. Keep it nice and simple like this. Another thing about a statistical
variable. If I look at age there, it's a bunch of numbers. If I look at the vocation here,
this first patient is an energy manager. That's a tax advisor. That's definitely not a number.
Then I come to smoke. And zero, I think here was for the patient doesn't smoke. One was they do smoke.
And I think two was they're an ex-smoker. If you smoke or not, that's not really a number, is it?
If you smoke, you smoke. If you don't smoke, you don't smoke. That's not a number. I can't do
arithmetic with that. I can't say three smokers and divided by four smokers. Well, yes, I can by
counting them. But I can't do sums with the words smoke and ex-smoker. Those are not numbers. But I can
capture them as numbers. These are just placeholders for what they actually mean. So that variable smoke
right there is not a numerical variable, as we call them. It's not a numerical variable.
Heart rate would be a numerical variable because those are real numbers. If someone has a heart
rate of 100 and someone has a heart rate of 50, the patient with a heart rate of 100 has twice the
number of beats per minute as the person who has a 50 beats per minute heart rate. So certainly,
systolic blood pressure. Someone with a diastolic blood pressure of 50 and someone with a diastolic
blood pressure of 100, that's twice as much or half as much depending on how you look at it.
Cholesterol there. Lipids there. Survey. Now, what is that? Do you think that's a real number?
In this instance, people were just given a survey and they could say whether they agreed with something
or not. And you see those typical Likert scale with an odd number of choices. Totally disagree.
Disagree. Neither agree nor disagree. Agree. Strongly agree. It's five. And the number was just
jotted down for each of those choices. Again, that's not a number. And even if that was a pain scale,
the patient could rate how much pain they have from one to five. That's not a number. Because someone
who's rated their pain as a four does not have twice as much pain as someone who chose two.
You can't define that. And you can also not say that the difference between someone who chose two
and three versus the difference between someone who chose three and four is the same difference.
How do you quantify that? The point is you can't quantify it. These are not numbers. Also,
you can't have a pain value of 4.5. So if your average of all your pain values came out to 3.475,
what does that mean? And you can't just round that off and say, well, now that makes sense. That's
nonsense. So that is not a number. Let's look at the cholesterol after, the cholesterol difference,
and then the group the patient was in. Active or control group. Once again, those are not numbers.
So what you've learned here is that there are two large types of data. We call them numerical data
and categorical data. Write that down somewhere. Numerical data, obviously numbers, numbers that
we can do some arithmetic with, like age. I can calculate the average age and someone who's 40
has been on this earth twice as long as someone who's 20. Absolutely. So those are real numbers,
numerical variables. Now, there's a nitty gritty there. There's two types of numerical variables.
Basically, you get the interval type and the ratio type. Interval is the fact that there's no true zero.
If we think of temperature, for instance, zero degrees Fahrenheit, zero degrees Celsius, that is not the
absence of temperature. Hence, you cannot say if it's 40 outside, it's twice as warm as when it's 20
outside. I'm talking degrees Celsius here. There is an absolute zero on the Kelvin scale. That is the
absence of temperature. But zero degrees Fahrenheit or zero degrees Celsius is not the absence of
temperature. There's still temperature there. And fortunately, we don't use that too often, and it doesn't
really impact on what we're going to do. The ratio type is, of course, what we deal with. And then
an absence, zero means an absence. So if your systolic blood pressure is zero, never mind that you're not
alive anymore, but it really is zero. There's an absence of blood pressure. And then we get the
categorical variables and the two main types of categorical variables too. Nominal and ordinal.
Ordinal. Now, the ordinal almost sounds like order. So there's some natural order to the possible
values in that variable. So if we look at the survey that someone filled in, maybe this was how happy you
are with something. How happy were you with taking this drug or some question like that, and you could
rate it one to five. Clearly, if five was you more satisfied than versus one that you're not, there's some
order to this level of satisfaction or order to this pain scale. That's an ordinal scale, and it's usually
easy to express those as placeholder numbers. But then we get to the vocation, say, for instance, of
these patients or participants in this study, and there's no natural order to that. How do you order?
Well, I suppose you can do an alphabetical order, but you can just use a synonym for someone's job, and
then it's out of order. So things that you can't naturally order, those would be nominal categorical
variables. So please write that down. So we have numerical and we have categorical. And it's very
important to know which is which because that is going to decide what statistical test you're going
to do. If you see a student's t-test, you better be working with continuous numerical data. You can't do
students t-test on a nominal categorical data. It just doesn't work that way. It's impossible.
So you've got to know what kind of data you're dealing with. It brings us back to this idea
of tidy data. Because if I look at each of my variables, the values in there, they all are the
same data type. I haven't put here that this patient is 43 and put that in words. I'll get to that.
That's a problem as well. But I didn't put something in there that meant something else.
I didn't put the year of birth there. And I could then calculate how old they are.
But it is the same data that's in there. It's clean. It's neat. And that's all you're going to
find in that column. So you've got to be able to break down your variables into something that is
that specific. Now, a specific variable like this has what we call a sample space. So write down that
that word as well, a sample space. That's all the possible values, random values that that variable
can take. So if you ran a study and you only included patients from the age of 18 to 80,
that's the sample space of that variable. All the possible random values that can occur if you went
out and you accrued 100 patients to your study or 2000 patients to your study, that's the only
values from which the ages can be taken. If we look at the group that the patients fall in, active and
control group, so placebo group and an active drug group, the sample space of the group variable
only has two elements in it, only two possible values. That's the sample space from which a random
variable can be drawn. Okay, so the survey, for instance, has a sample space of five elements.
And that brings me to this idea of continuous numerical. When I said students t-test, I said
continuous numerical, because age, even though we're capturing it there as a whole number,
someone can be 43 years old, 12 months, two weeks, six days, five hours, two minutes,
three seconds, comma, as small as you like to go. There's a continuum there.
It's very difficult to make little blocks of that. You can,
you can, but the numbers themselves are continuous numerical. Someone's blood pressure,
for instance, yes, the millimetres of mercury we always can express as an integer whole number,
but in reality, in reality, if our apparatus could measure more accurately,
someone could have a systolic blood pressure of 145.745689. It just depends to what accuracy
we can measure this. So that's a continuous numerical variable. Look at the cholesterol there as well.
We would see those as continuous numerical. And as opposed to that, we get discrete numerical
variables. And that becomes a bit of a gray area. Sometimes, or I suppose you can make the argument
that it becomes gray. But say, for instance, someone receives, and we want to include that
in our analysis, how many units of blood that they receive. And usually people are going to receive
these as discrete units of blood, so much blood. But I suppose you can break this down into volumes,
milliliters, and now we're on the slope to a continuous numerical variable. So when we talk
about discrete variables, sometimes there's a bit of a gray area, and I suppose someone can talk of
the survey numbers as discrete numbers. They can only take discrete values. But be careful,
those are still not numbers in this instance. That still remains a categorical variable.
So look at this data and keep these things in mind. I hope you've written them down so you can look at
them. This idea of numerical variables and discrete variables. That we have this idea of a variable,
and it has a sample space, and values for everyone in there can only be taken from that sample space.
That brings me to the fact that, remember I said the first row is then all your variable names,
and then every patient or participant, they have their own row. That's another part of tidy data.
So everything about that participant in the study falls in that one row, and we're going to collect those
random variables or data point values for each variable, and for each of them they are drawn from
some sample space. She's starting to think like a statistician here. We're building this understanding
of what this is all about. So that's fantastic there. You see this is all tidy. And now it's going to bring
me to one of the last points here is sometimes people are bad at typing and all fingers are pointing
at me because I'm bad at typing. So when I double click say for instance on this active, and I might
type active here and put a little space behind that active. If I click off of that, you would never see
that space. Believe you me, Python can see there's a space and it's going to see that as something
completely different from all the other actives. That patient is going to be counted totally
separately as if now there are three elements in this sample space. There's active and there's active
with a white space behind it. It doesn't work like that. So sometimes you have these hidden things.
Likewise, one of the actives might be written with a lowercase a. Now suddenly again, I have three
elements in the sample space of this. So you've got to be very clear when this data is collected or when
you clean up this data that you get rid of all these sort of mistakes. Dates are horrible. Sometimes
people put years first, months first, days first, all sorts of things, forward slashes, back slashes,
hyphens there for the date. It has to follow the same pattern. That's why I said initially a lot of your
work goes into cleaning up data before you analyze the data and hence when you are part of a project
see to it that that data is collected as cleanly as possible. Put your effort in there. You will be
rewarded because that's not what we want to concentrate on. We want this information, the story that is
hidden in the data, we want to bring that out. And there's a story here because if I just look down
all these values, I don't know what the story is. I have to do statistical analysis on all these values.
And for the story to come out. And one of the first ways that we're going to do that is to
start with summary statistics and we're going to graph and plot this so we can turn these numbers
into something that us as humans can understand. So I hope my few words have taught you something
about data. Please, this is not acceptable. There's no ways we analyze data like that. This is acceptable.
Tidy data. Remember the term tidy data and make sure that your data is tidy like this.
Now this file, I'm just going to close these two down. They do reside inside of this data folder. So
there's the data.csv file. We're going to import some of these and I just want to show you at the top.
Remember, they are in on my Google Drive. Now this is mock data to be sure. Putting actual patient data
on Google like this, even though I've got a paid account. So I pay Google every month.
And there is still some security issues here. And you have to know what is allowed in your country,
your region, to put patient data like this. This is mock data.
It's absolutely made up data. So it's easy enough to put it here. And as I said late in the course,
I'll show you how to install Python on your own system. If you want to work securely and you have
to work securely, you can run all of this on your own machine. But to make it easy for us,
we're running all this because we're not there yet to go through the hassle of installing Python on
our own. Although that has become very easy as well. But notice I'm in my drive, Coursera subfolder,
Understanding Clinical Research subfolder, and Data subfolder. Look at this. That's horrible.
I put spaces in between those words. That wasn't a good idea. But my drive, Google puts a space there
anyway. So I can't do anything about that one. So we'll see how to get around those things.
But that's where I stored all my data. And if we go back one, by the way, I've also got this image
folder. That's where these images that you keep seeing appearing, that's why I've hidden them.
And there's a way that we are going to show you how to bring those images out, just use them
for decorative purposes inside of your, well, I suppose you can use them for explanation. And we create
this notebook to share your research findings with others. You might also want to use images. So
there we go. I've got a little template notebook here, because I've done all those things. And I just
copy this template and start working, we'll get to those things. So what we are doing right now,
we're in this week one data folder, that is where we are. And I'm going to show you this
manipulating data with pandas. So after you understand now, the way that you have to look
at your spreadsheet files, let's start importing them. So on the left hand side, you see there's
quite a few things that we have to get through quite a few ways that we can use pandas to manipulate
our data. I'm going to show you where the pandas website is, you can just look it up, just type pandas
in Python, you're going to get to their website. It is an enormous library. You can make multiple
courses just on pandas. But I'm going to show you the most useful things. And the things that you
would need when you get started. So there we go. As you can see, I've also neaten up things nicely.
These are all my level two headers with the two hashtags. And I've tooled them all down. So we can
see there's two hidden cells there, four hidden cells, 20 hidden cells there, etc. First of all,
although it's been a while since I've been at this computer. When you watch this, hopefully the
the world pandemic has calmed down one day when you watch this.
So it's back and forth for me after work so that I can record a little bit,
keep on contributing to the educational resources. Those are getting left behind and I really want to
keep contributing to that. Anyway, so I've got to reconnect. And I'm going to reconnect to the
Google service. So if you've been away from your computer a while, it'll kick you out. And for good
reason, we don't want to overload this fantastic free resource that we do have. So we want to overload
Google. So if you start running code, it'll reconnect automatically. But if you hit that button,
now I'm connected. So let's see pandas. As I said, it's a library for ingesting your data and analyzing
your data. And let's import these libraries. So I'm going to import pandas. And remember,
so pandas is going to have a lot of new functions that's not inside of of Python. So if I have to use
one of those, I have to type pandas dot and then this function. And as is the norm in Python,
we use this namespace abbreviation. And most people just use PD for pandas. You don't have to
but assist the norm. So let's just stick with it. So I'm saying import pandas. You've seen that before.
We're just importing a library. But I'm going to import it as something. And look at that. It's
always like English language. I mean, import pandas as PD. It's like a normal English language. And that's
what makes Python so beautiful. So now I don't have to write pandas dot that function. Although
there are people who really do that. They don't like this laziness of these abbreviations. But anyway,
that's a different story. We're going to import NumPy. NumPy is short for numerical Python.
Some people pronounce it numpy. I don't know. That just rubs me up the wrong way. But anyway,
also a story for a different day. Import NumPy numerical Python as NP. Again, that's just the
standard abbreviation. You can use whatever you want. And that's what we're going to go for here.
And then from google.colab. So the Google is a library inside of Python. And it has a sub module
inside of it, a sub library called Colab. So I'm going from google.colab. I'm importing the drive
keyword. So that drive function we're going to import. Now that is specific to using Google Colab.
And my data is inside of my Google Drive. If you have your own system running off of your own
hardware, you're not going to have to do this. This is specific to using Google Colab.
So this last one is specific as well. You see this little percentage symbol there.
Percentage load underscore ext. That is a very specific here to Google Colab.
If it starts with a percentage like that, it's called magics commands. And that is just going to
do something to the rendering engine of your web browser so that something happens in this load
external and then google.colab.data underscore table. That's just going to format the way tables
are presented by your web browser. Remember, we're working the web browser here. So that's just something
that Google designed. If you use your own system, you're not going to do this. I'm just doing this
so that we can see the tables nicely on our screen. So with those things imported, let's connect to our
Google Drive. And you might think, but I'm really connected to my Google Drive. I'm inside of my Google
Drive here. And I'm using one of the things that Google provides. I'm using the Colab here. Yes, but
you still have to connect securely to your own Google Drive. And this is the way that Google does
it. Again, if you're running Python in your own system, you won't have to go through this. But yeah,
you do. So remember, we imported the drive function. So we're going to use drive.mount.
Well, the drive was actually another little sub module. And it has a function called mount. Let's be
let's be more specific. So I'm going to say drive.mount. Because look there, I've already imported this
module, the drive. So now I can say drive.mount. And it's the G drive. This is specific to Google.
Don't ask questions. That's the way it's done. So inside of little single quotation marks here,
forward slash, even if you're on Windows, Google's running on a Unix system, that's Linux,
that's the same as Mac OS, everything is a forward slash. So us poor Windows people have to deal with
backslashes. This is a forward slash. Suppose depends on how you see these things. Anyway,
G drive, you've got to do that. And I've used comma, a second argument here called force
remount equals true. I always put that in case I had to walk away, there was some emergency,
and I didn't shut off properly. And I just have to force remounting of my connection to my own drive.
You don't have to put that if you're just running this the first time. Now something's going to happen.
It's going to say click on this URL in your browser, so that you can connect to your account. Now I'm
going to blur some of the stuff out that comes because another browser window is going to open
with a bit of detail. So let's just look at what is going to happen now. It's going to let you choose
between some of your accounts. And at the moment, this is the account I'm using to do all of this.
It's going to say, you are now allowing Google Colab to have access to all of these things.
Well, you can't go ahead if you don't. So might as well do. It's quite secure, not to worry.
So now we get to this page, the sign in page. And this is what I'm going to blur out. Well,
this code does disappear after a while. So it's not like anyone can make use of it. But nonetheless,
so I'm just going to click here on this copy, or I can highlight all of that text and copy it. But
I'm just going to click on that. And now it's copied. I can close this. And I'm going to come into
this enter your authorization code, right click on it and paste as plain text. And just hit enter or
return. So now, internally, I'm signing in and giving all those permissions to this Colab notebook
to work with stuff in my Google Drive. Right. Now on your normal computer, if files were on your normal
hard drive, you would just navigate to it using Windows Explorer or the other operating systems
version of that. But yeah, we have to navigate slightly differently by using another magic's
command. Now CD stands for change directory. Because we want to change to this directory,
just like on your hard drive, where your files are in some folder or some directory,
we've got to do the same here. Because data dot CSV file that we want to import our spreadsheet file
is in this folder, remember I showed you before. So the way that we get rid or get away from
these illegal characters like spaces is just to make it a string. So I'm going to say percentage CD.
And then inside of these quotation marks, which makes this a string, I'm just going to write this
whole address that I have to that pointing to that folder that contains my CSV files. And that's
forward slash G drive forward slash my space drive. Remember, we looked at all of these things up here.
That's exactly what we're typing. Coursera, understanding clinical research. And now I can
put the spaces, no problem, forward slash data. And it's exactly I wrote it all with uppercase,
so it's got to be there. So now I'm just changing directory to that directory, because that is where
everything lives. And the file from there that we're going to import is data dot CSV.
And this is how the import happens. I'm going to create a computer variable called DF for data
frames. Remember, I said within the limits that we spoke about before, you can name your
your computer variables, whatever you like, but it is sort of everyone does DF for data frame.
So I'm going to say DF equals. And now because we imported pandas is PD. So I can just say PD
dot. And one of the functions inside is read underscore CSV. There's also read underscore
XLSX for Excel files. But read underscore CSV, it is a function. So you see the parentheses there.
And then I pass as a string. So inside of quotation marks, I'm passing the name of the file.
So these are just things, these are things you really have to memorize. And after you've used them a
couple of times, it becomes, you become unconsciously competent, you know, just know how to do it.
So exactly the name they stick to exactly the same name, uppercase, lowercase, exactly the same.
So we're going to import that nice neat data file that we saw that nice spreadsheet file is now
imported into Python. Very nice. Remember the type function in Python, let's see what this data type
is this type of this object that is now stored in this piece of memory on Google side.
They're mighty machines called DF. And the type is a pandas dot core dot frame dot data frame object.
There you can see the full name of it. Remember before we also said that all objects have these
attributes and they have these methods. Method is a function that pertains specifically to that object.
Now to get to all the attributes, and by the way, pandas, I think calls them properties,
not attributes, doesn't matter, properties, attributes, and the methods available to that object,
DF now, we can just use this DIR function. And if I pass the data frame object to it,
you see all these methods and attributes that are available. So I can say DF dot,
any one of these, and all of them are going to do something. Some are attributes,
some are functions. And look at the lot of stuff you can do. It's just absolutely phenomenal,
and we're going to do some of these. Is in, is in a, is null, items. All these things,
just look at them. Dot mean, dot median. Oh, this starts looking interesting. Some statistical analysis
here. But all of these things are available to this object. That's the way Python and pandas designed it,
so we can use all of these things to do useful things to this object called DF. By the way,
you'll see these starting with underscores. Those are dunder methods, double underscore methods,
et cetera. No, they're the dunder. So those are not dunders with a single underscore. There's the dunder
things, double underscore things. All these things mean something in Python. If you want to get deeper into
Python, they're actually quite easy to understand, and they make a lot of sense. Anyway, notice these
first few ones. They're age, cholesterol after, cholesterol before, date of birth, delta, group,
heart rate, name, smoke, survey. Oh, they're also available to this object data frame. And those were our
statistical variables, our column headers in our first row. They are also available to this object.
That's interesting. Okay, let's scroll down. Let's get some more information on our data frame object,
this spreadsheet file that we've brought in, by the way, that is where I put that link to data frame
objects inside of the documentation of pandas. But you just type in Python and pandas in Google or your
favorite search engine, and you'll get to this. So the first method we're going to use is the head
method. So dot head. It is a method, in other words, a function. So open, close parentheses.
I'm not passing any arguments to it, because there is a default argument, and that argument is five.
And what the head function does, it prints the first five rows. And remember, right in the beginning,
we imported this magic thing to have tables printed nicely to the screen. That's what this one is doing.
So we see these white and light gray alternative rows. And we see we can change the number of views
per page to 10 or 25 or 50 or 100. So if I clicked on 10, for instance, it was going to show the 10.
It is not doing so now because we are using the dot head function. So just a little caveat there.
If I just typed a df, it would have only printed so many rows. But I'm using dot head. So it's
constraining it to what this head is doing. As I said, the default is five. But I can also put in
another value there, depending on how many rows I want to see. Again, look at the left hand side,
the index telling us what row value it is. Python starts counting at zero. So we can only see zero to
four here for the first five. The first patient Dylan pattern has an index of zero. But you see all of
them there. And if I just did, let's do that. Let's just do that. So I'm just running df. And now it's
totally under the control of that initial magics command that we imported. Now I can easily go to page
two, page three, page eight, etc. Back to page one, I can say no, no, I only want 10 lines displayed
here. So it's under that control. And even if I when I click on these, it's going to allow me to change
the order the sorting that's not going to be available if we don't use colab here. And we don't
use that magics command. So that's specific to here. Don't worry about all of these. There's also
filter there. That's all from this magics command. And that makes why working in colab is so nice,
because you've got this extra functionality. But we're going to do it all with code.
The next thing that you want to know about your data frame is its shape. And that shape is a
property or attribute. So you're not going to put parentheses there. So just df.shape. And that's
going to tell you the number of rows, comma, the number of columns. Get used to that. It's always rows,
comma, columns, everything in Python, rows, comma, columns. So there are 200 rows, so 200 patients or
participants in the study. And there are 13 columns, 13 statistical variables on which we gathered some
data. The dot columns is also an attribute or property. And that's going to give us back
all the values in that first row. And because we were particular about it, we've got tidy data,
that's going to be all our statistical variables. And it's going to create this index object for us.
And inside of it is a list. And sometimes I call this repeatedly, because now I'm going on to the
next analysis. I can't exactly remember how that variable name was written. Just call df.columns all
the time, just to remind myself what are all the variables in there. And there they list them.
Name, DOB, age, vocation, smoke, heart rate, started blood pressure, cholesterol before,
your triacylglycerols, that's your lipids. Survey cholesterol after delta is the difference
between the before and after, and what group the patient was in. So you can well imagine,
this is a little mock data set that had these patients take either a placebo drug or a new drug,
and we looked at their cholesterol before and after. Simple as that.
NDIM is another property. Number of dimensions. And you can see two. Two stands for the rows and
the columns. They're two things. They're two dimensions here. The row and a column. Okay,
and that's as simple as that. The size is just going to give me all the values. How many values
there are. So number of rows times number of columns. So that's how many data point values
we have. 2600. And then we get this dtypes. And that's also an attribute. And that's an important
one because it tells me what Python or Pandas thinks these types are. Remember we spoke about
numerical variables, categorical variables. Now let's see what Pandas thinks about all of this.
It thinks names are an object. And object is another word for categorical variables. So that's
quite right there. DOB, it sees that as an object. And there's actually a date. And we haven't spoken
about what a date is. What kind of thing is a date? Anyway, then there's age. There's vocation. It sees
that as an object and age as an integer. And see in 64. Now the 64 refers to how many
little bits. So that's the little on-off switches, microscopically small, and you're inside of your
computers, CPU, etc. 64 means it takes 64 of those switches, bits, to describe that number. But it's
an integer. It's stored as whole numbers. That's right. Smoking, which was zero, one, and two,
which is a categorical variable. And nominal at that because there isn't a natural order. What,
you put X smokers before smokers now, before no smokers. You know, there's no natural order.
But we use zero, one, and two. And it sees that as an N64. That's wrong. Ding, ding, ding. That's wrong.
Okay. It's a started blood pressure. It says N64. Float 64. That's decimal point value. So that was
correct. Survey, it sees as N64. That's wrong, because it's a categorical variable. And so on,
and so on. But it gives us an idea of what Python is seeing, or pandas are seeing. And we have to work
with that. So that's very important, the D types. So let's start extracting some of the rows and some
of the columns. So the first thing I'm going to do is show you just to look at a single column.
I'm not interested in all the columns. I'm just interested in the age group, the ages of these
patients in my study. And there's two ways that I can extract just that column. This is probably the
proper way, df. And then I'm going to put inside of square brackets, which we've learned about
before, it's going to be something like indexing. But inside of quotation marks, I'm passing the
computer, the I should say the statistical variable, the column header, I'm passing as a string. Okay,
and I'm saving this inside of a computer variable called age underscore column. There we go. So that is
one way to extract only a certain column. And I've saved it in its own computer variable now. So what
is the type of this new thing? If I only extract a single column from a data frame object, it becomes
a series object. A series is something that has just this one column. But it also has an index,
it keeps an index, just as we saw with the data frame here, if we scroll back up, there's this index
column that pandas adds to the data frame so that each of these rows has its own index. And we don't
have to stick with this default index, we can actually if you want it, you can even make one of the columns
the index, but then it's got to be kind of unique to do. And sometimes it is done for dates and times,
etc. But we won't get into that.
So there we go. I have created a pandas series by selecting only one of the columns. So if it's
only a single column, it's a pandas series. Okay, there is another way to do it. And that is if we
don't have any illegal characters like spaces, then we can use dot notation. So see there, I had to put
it inside of square brackets and indicate that it's a string. But if there's no illegal characters in
there, I can just use dot notation. So df dot age. And that's a little shorthand, I like to use it.
But it's not, it's probably not the proper way. And it's safer if you have illegal characters,
because if you put that inside of a string, you can just do it. Good. Let's look at the first five
rows of our pandas series. And you can see that it's a series because it still maintains this index
on the left side. There's no column headers there. In other words, it's not saying index and age.
But you can see that I just have this one column of age values. Now one thing I want to teach you,
because it can be very useful at times. It's probably not absolutely necessary, but it is nice.
And that is to convert an object to another object. So we have this age underscore column. At the moment,
it's a pandas series object. And I'm going to convert it to a numpy array. It's going to be a new
object type. And I like a numpy array because now I strip away that index and I'm only left with the
values that I'm really interested in. And for that, we're going to use the to numpy method that is
peculiar to series. So pandas series, because if I say df.h, I've got a pandas series. And one of the
methods of a pandas series is that to underscore numpy method. So I'm going to call that method on
the series. And I'm going to store that in a new computer variable called age. So let's do that.
As I say, these are useful things and not absolutely necessary. But sometimes I find them very useful.
And the type of this now is a numpy.nd array, n dimensional array. At the moment, it's one
dimension because it's one list of numbers. It's not two dimensional. As remember, there's no rows
and columns as our data frame. And because this is a numpy array, it will have its own set of
attributes and methods. And if I pass that to the dir function, you see all these are dunder methods
there with a double underscore. And there's our normal methods and attributes all listed there.
So let's look at a few of them. Very useful ones, if you've converted to numpy arrays,
although they are also available for pandas series, by the way, but let me just show you
is the dot min method. So age dot min, it's a method. So parentheses, that is going to give me the
minimum age of that whole array of ages. I can do the same for max, I can do the same for the average.
So what was the average age? Of our mock data here, it was 53.07. See how easy that was to do some
statistical analysis. I extracted it as a numpy series, I converted it to an, I should say a
panda series, converted it to a numpy array, and just called one of the methods that is available
for that type of object. Dot min. As I said, it's also available for pandas. I didn't really have to
convert it to a numpy array first. But hey, I just want to show you what's, what is available.
Now, let's look at just look, just extracting the rows. And for that, we're going to use this
attribute called iloc, iloc, iloc. So df dot iloc, i-l-o-c, that's integer location, in case you're
interested. And that is followed by a set of square brackets. And what I'm asking for here is just
zero. Now, iloc, integer location, is strictly going to go rows, comma, columns. If I don't put a comma,
just put values there, it's going to assume just the rows and give me all the columns. So if I put
zero, remember, that's going to be the first row of data. Now, it's printed very nicely as two columns
here. But you can think of it as that first patient, all their values in that first row. So
there's their name, their date of birth, their age, their vocation, etc. All the values, the random
variable values for these variables. And there you go. Now, what if I wanted rows two, three, and five?
Well, that's index two, three, and five. That makes it rows three, four, and six. Remember the zero?
It's counting. I pass that as a list. So do you see the inner set of square brackets there? I'm passing a
list to these outer set of square brackets. And again, to the iloc attribute. And now I'm going to see
index two, index three, and index five, those rows of patients, the ones that I want. So that's one way
to go about it. But I want what it might be contiguous. So one, zero, one, zero, one. And this,
by the way, is all that I'm going to get. Remember, the right hand side, usually in Python is ignored.
So it's up till two, but it's not going to include two. So it's going to be row zero, and row one.
One way to remember it is I'm going to get two rows back. So that's why the two is there. Anyway,
let's have a look at that. It's going to give me this contiguous set. So zero and one, but it's not
going to include two. It's going to give me two, but it doesn't include two. It's two rows, but it
doesn't include that third one, which would be index two. So let's do rows, comma, columns, because
every time I've just asked for rows now, you didn't see any single comma in there. I listed them.
Yeah, there were commas in my list that I passed, but there's no rows, comma, columns. So here we have
rows, comma, columns. And for my rows here, you see I'm using a range. Remember range from the last
video? So it's zero, colon, five. So zero, two, five. What do you think is going to happen to that five?
I wonder what happens to a panda's range. Does it exclude that five? Does it include that five? I guess
we're going to find out. But now you see the comma and then the columns. And I've passed the columns as
integers because I'm using ILOC, integer location. So I can't use the names of the columns. I have to
use the column number. And the first column, the name column there is going to have a value of zero.
That's the zero width column. And DOB, date of birth, is going to be the first column. So I'm asking for
columns one and two. That's index one and two, meaning it's going to be DOB and age. Okay, but let's see what
happens to the rows. There we go. Zero, one, two, three, four. No surprise there. I hope I didn't
entice you. So that five is excluded even in the range here in pandas. Okay, so we're sticking to
that rule. So you can see the columns that we were after, the DOB and the age column. And you can see
the five values that I wanted there, the five rows. So zero, one, two, three, four, five being excluded.
So over and above the ILOC, you also get the LOC. That's just location. And now I can use actual
words. Now remember, my index was just numbers. That was done automatically. But I can make one of
the columns, a column I could make the index. For instance, if I have something like date time
and the patients come sequentially, those are all going to be unique values. And I can turn something
like that into an index so that all the values are still unique. And then I can use LOC to refer to a
a specific string, and the column to the specific string, the column header, the statistical variable
name. So LOC allows me to do that. But we are stuck here, remember, with just the normal integer indexing.
So I can say dot LOC. So the rows again is zero comma five comma. And now as a list, I'm passing
these two. So DOB and age. So instead of ILOC, which I created a list for those two that I want,
I can now pass as a list the actual names with LOC. And that's going to give me back exactly the same
thing. Lo and behold, though, is it? No, we're breaking the rule here with LOC. Here with LOC,
that five was included. So I have zero to five, I now have six. So just bear in mind,
sometimes you do get these little, these little differences. Just live with them. It's not a big
issue. There's the I act, integer act. And that's more like what you would think of a spreadsheet
file. I want that row and that column. So row number three, column number two, which will actually
be four and three. Remember, we start counting at zero. And there's the value that was exactly at
that. And we can also just use dot at if we want to use the actual names like we did with LOC. Okay,
let's go on to something much more interesting. I want to filter the data based on some information
that I want. I'm just going to filter the data instead of calling out the actual rows and columns
that I want. I want to finesse a little bit here. I want something more interesting because
I don't know in what order these patients were captured in. That's not what I'm interested in.
So let's go and ask the first filtering question. We want to find all the unique
values in a column. Remember what that meant? That meant the sample space specifically of a categorical
variable. So let's go do that. The sample space of a categorical variable. So the smoke,
remember that was, I think, zero, one, and two for non-smoker, current smoker, ex-smoker.
I want to find out it might be many more than that. And I'm only seeing the first five or 10 rows,
but there might be many more. And I don't want to go through something that has 2000 columns. So for
that, we have this unique method for pandas series. So I've got df.smoke. And that's going to give me back
just that column as a series. And one of its methods is unique. So open and close parentheses.
It's going to go look down that column and return for me the sample space elements. So that's the
only thing that occurs in that column. There's a zero, a two, and a one. So why did it give me this
order? It just goes down and finds the first thing that it found. And there was a patient with two,
an ex-smoker, before there was a patient with one. So it's just going to give me that order. It
doesn't matter. I can see the sample space now of that. And it helps a lot, of course,
when we use it on categorical variables, not so much for numerical variables,
especially when we get to floating point values, because then you're going to get back
a lot of values. So there it would be much better to use minimum and maximum.
So let's have a look at filtering all the ages of the non-smokers. Now that's interesting. I might want
to know just give me all the ages of the patients who don't smoke. Think about it. That's a very
interesting question. And how do we translate that? Just teasing out just those values from our data
frame. So let's have a look at how to do that. And we're going to do that by using Boolean logic. Now
we've looked a little bit at that. That is where I can ask a question and it's going to return either
true or false behind the scenes. Now, first of all, I'm going to create a computer variable and
I'm going to make it very descriptive. I'm going to say non underscore smoker underscore age so that
I know inside of there, I am going to just store things that are the ages of non-smokers. So if I
looked at this a week from now, I probably will be able to make it if I give it to someone else,
they'll probably be able to make out what values are in that computer variable. Okay.
So there's a couple of ways to go about it. I'm going to show you the very short way.
And it is a bit different from what you've seen before with loc and iloc and those columns. So
have a look at this notation. Just got to get used to it. So it's df, the data frame. And then
inside of a set of square brackets, I'm going to say df.smoke equals equals zero. So the double
equals, we've seen it before to ask the question, is this equal to zero, true or false? And it's only going
to include the rows where that is true. So only going to look at ones where the patient is a
non-smoker, if that is what the code was for. If this was a string value, one of the sample space
elements I was looking at, I can just put that inside of quotation marks and just look at that
one specific one. So it says df.smoke equals equals, the double equals sign is a Boolean question. It asks,
is this true? Yes, it's true. Include the patient. No, it's not a zero. Don't include.
So what do we want to include? That goes in its extra set, its own set of square brackets with the
name of the column inside of quotation marks. That's why the quotation mark format is probably
better than the dot format. Because here, there's no ways to use the dot. Well, I think I'd tell a lie.
I think you can actually. But let's stick to this for now. And then on all of that, I want a conversion.
Because I'm going to get back a panda series from this. But I want to just convert it to NumPy. As I
said, this is something extra I'm showing you. So the object inside of this non underscore
smoker underscore eight computer variable is going to be a NumPy ND array. And that's very nice,
because I can call dot mean on that. So I'm going to say non underscore smoker underscore age dot mean.
And that method is now going to calculate the mean. And I can see the non smokers had an average age
of 50.1. Great stuff. Now, let me just show you other ways to do this. Again, I'm going to use the
exact same variable. So I'm going to overwrite it, computer variable, non underscore smoker underscore
age. And I'm going to use the dot loc method. So here, I'm going to say df dot loc inside of square
brackets looks almost the same as that top one. I've just added dot loc. So I'm going to say df dot
smoke equals equals zero. And then in a separate set of square brackets, age to NumPy, I'm going to
get back exactly the same thing. There's another way to do it. And as I've written down here,
it might be confusing in the beginning, there's so many ways to do exactly the same thing. Well,
there's power hidden behind that, because the reasons why you can do things differently for now,
except the power that is at your command. So non underscore smoker underscore age exactly the
same numerical computer variable, I should say, df dot loc. And now I'm just going to pass them like
this almost a row comma column version. So I'm going to say df dot smoke equals equals zero comma age.
This is probably the more appropriate way because you'll remember this way. So I'm doing rows comma
columns, go down that column smoke row by row, and only include the rows for which the smoke is zero.
And then give me comma the age column. And then again to NumPy. And I'm going to get back exactly
the same NumPy nd array object. No problem. Okay, let's filter something else. Filter all the
non-smoker ages where the survey choice is more than three. Oh, we're getting very specific here.
Of course, that doesn't make much sense in the context of the data that we have here.
But when you have a data set, you might want to be this specific in your subgroup analysis.
So you want to be able to extract very specific things here. So let's just let's just tease this
apart. I'm looking to filter all the non-smoker ages. The ages of the ones who are non-smoking
and the survey choice must be three or more. So that survey choice was perhaps are they satisfied
something. So I want to satisfy people here. Let's have a look at how we construct that. So I've got to
look at two things here. Both things have got to be true. They've both got to be non-smoker.
And in the survey column, they've got to have a value of three, four or five.
Both of those things have to be true before we get a true value. And then that age will be included.
And you can think about it, I can string even more together. So let's put it together. I'm going to show
you this long way and then show you a slightly better way. But again, I'm going to give it a descriptive
name. I'm going to say non-smoker-satisfied-age. We've decided that if you mark a three or more,
you are satisfied, by the way. Okay, so it's df.loc. And now I'm going to pass each of these
little Boolean things inside of its own set of parentheses. So I'm going to say df.smoke
equals equals zero. And I have df.survey greater than three. So I should say yeah, more than three.
So it's only four and five, not three, four and five, not greater than or equal to.
So really, they are satisfied that just four or five. And then I'm going to bind these two together
with this little ampersand. Ampersand here in Python is a symbol for and. And both must be true
for that row to be included. Not either of them, because that would be an or. Yeah, I want an and.
And then, comma, age. So I'm using this row, comma, column, sort of notation inside my square brackets,
and then to numpy, because I want a numpy nd array at the moment. Again, I'm just showing you that this
is possible. Now I've got those ages only. They'll have a survey score of four or five, and they will
be a non-smoker. Guaranteed. And they'll only have the ages for those. And now I can look at the mean
for those. Very powerful stuff here, if you think about it. I want to show you as many examples as
as possible. If you want to take a break or have some tea or coffee, whatever your favorite beverage
is. Come back. But come back. Okay, more, more, more, more. Filter the ages of all non-smokers or those
who have a satisfaction score of more than three. So now it's an or. So if either one of those are two,
I want the age. Not both of them want to be. And so instead of putting these together with the
ampersand, which means and both of them have to be true. If I have more of them, they all have to be
true. This pipe is what we call it, the single up, down. And my keyboard, it's above my enter,
which is shift and my backslash key on your keyboard might be somewhere completely different. Search for
it. Just this. Sometimes it's actually a broken vertical line. There's a little empty space in the
middle. So just watch it. Check out your keyboard. But what I'm doing here is I'm saving it as a
computer variable. And I've called it crit for criteria. There's more than one. So again, each
one in their own set of parentheses, importantly, df.smoke equals equals zero or df.survey equals more
than three. And then I'm just going to pass this as my row here. So df.loc row, column. So that's my
rows go down that column and that column row by row. And just look for any of those to be true.
And then include that age, express it as a numpy array or convert it to a numpy array and store it
in this non-smoker. Oh, I didn't run the crit there. So let's run that. Now it's in memory. And now we can
use it as this criterion. Okay, so now we're going to have the ages of patients who are either non-smokers
or have a score of more than three or both. Like someone could both be a non-smoker and have a
survey of more than three. But there certainly are going to be people there who are not on the zero
and whose survey is one, two or three. And the other part of that or must be true for them to be
included there. Okay, more, more, more. Filter the ages of all patients who are not non-smokers and who
do not have a survey score of three or more. Wow. So two, two, two negations here. Let's just
think about this for a while. Let's twirl this open. So we're dealing with, I'm going to read
you for you, we're dealing with negation. So we can change our language a little bit if you think
about it, where we can say, where we can take this opposite view. So if you are not a non-smoker,
that means you are a smoker or an ex-smoker. And if you do not have a survey score of more than three,
that means you have one that is three or less. So you can change it into a positive way to look
about it. But sometimes that can become a bit difficult, especially if you're not. Say you
have a sample space of 20 elements and you just want one of them excluded. Now you have to include
all the other 19. It's easier to go about this way. First of all, we're going to create the same
criteria. So smoke equals equals one. So the ones that you don't want and the survey value more than
three that you don't want. And now when you pass the crit, you're just going to put this little
tilde, squiggly line in front of it. That's negation as far as that's the not operator,
if you know that kind of thing inside of Python. So not this criteria. So I want exactly the opposite
of this criteria. And both have got to be there. So I'm using the ampersand there to indicate,
and if I run this now, it's going to do exactly that. It's going to have the ages of people who
are not non-smokers and who do not have a score of more than three. Excellent.
More. Create a new data frame object that only contains patients younger than 50. Sometimes I
want to create sub data frames. Because I only want to, from now on, I'm only going to do subgroup
analysis on this group of patients. And I want a new data frame so that I'm not, it's not contaminated
by these other patients. So let's have a look at that. Very simple. I'm going to give it a computer
variable name. And I suppose I could have called it younger underscore df. That would have been a
bit better, don't you think? Anyway, it went with new df here. So I'm going to call the df. And then
I'm going to look at a specific series in there, df.age. And I want the age to be less than 50.
And if I do that, there's no comma column there. So it's going to return all of them for me.
So you see, I've got all my columns still there. But if I look at the ages, I'm not going to find
anyone who's 50 or older. Okay. So now let's just make sure that that is so. So new df. That's my
data frame. .age. That's going to return a pandas series for me. I can call the .max method on that
series. And I get 49. That's the oldest patient there. If I remember .age, just a little reminder
there. It's probably better just not use the .notation, but use the full notation there.
Still going to get back the same thing. And here's just another way. Again, I'm just showing you
what is possible here. Don't let all this abundance of ways to do things confuse you.
But for the interest sake, just look at this one. So I'm saying new df.loc. And that means
I can refer to the names. And I'm going to use comma. So I'm going to have rows, comma, columns.
And you see a colon there. Remember we see a colon was for range, if it was say from 0 to 5. Remember
for .loc, the 5 was going to be included. But if I just put a single colon there, it is short
notation, shorthand for all. So that's all the rows, comma, just the age column, and then the .max
method on that pandas series. And again, I'm going to get exactly the same thing. The oldest patient
was 49. Now, create a new data frame for patients with a restricted list of job titles.
Because that's one thing we haven't spoken about. When we spoke about the tidy data, I said,
have this clean sample space element. And how many data sets have I analyzed where there was
columns that had free-form input? And one of the most famous ones in healthcare research is the
list of comorbidities. So one patient will have hypertension and diabetes. The next one will have
hypertension and diabetes and ischemic heart disease. And then the next row, those three things will be
listed with commas in between them, but the order will just be changed. So you can just put all the
stuff in a single column. That is not tidy data. That is not tidy at all. You cannot analyze that.
That's impossible to analyze. Everything must be in its own column. So if you think of comorbidities,
you'll have to think of all the comorbidities that you're interested in. And they've each got to
become their own column. And the sample space for each of those will be yes and no. So hypertension
will be its own column, and its sample space will be yes, no, yes, no, yes, no. Next column will be
diabetes. And its sample space will be yes, no, yes, no, yes, no, yes, no. Or just yes and no,
the sample space elements, but then yes, no, yes, yes, no, no, etc. So you have to break that down.
It's called dumbifying, but we were not of interest for us now. But sometimes you just,
there's just no other way that there's this free form input. So I want to give you some sort of idea
of how to do this. So for instance, that vocation column had all sorts of jobs for the people in our
study. But what if I were just interested in these three jobs? I'm just interested in people
for some bizarre reason. I want IT consultants, the energy managers, and the clinical embryologists.
Now you'll have to know what is inside of your data set. And remember, I mean, if that embryologist
was written with a couple of uppercase E, and some other ones, they were written with a low case E,
that's two different, that's two different elements. So be careful of those. But those are the only ones I
want. I'm passing them as a list to this jobs underscore, just jobs computer variables. So
I'm passing this list object to it. And then I'm going to use a criterion. And my crit, I'm just
calling it. So I'm saying df dot vocation. So that gives me a panda series. And then on that, I'm using
this is in is in as a method. And I'm passing this list jobs, this list object to it. So that is in
actually ask a little question. Is it in in this panda series? So if IT manager or energy,
IT consultant, energy manager or clinical embryologist is in that row, one of those three,
yes, then it's going to go into this crit that I've got there. And then I'm going to create a new
new data frame, I'm going to call it jobs underscore df. And I'm going to pass this
df. Vocation is in jobs. I'm going to pass that to the loc function, the loc attribute,
I should say. And then let's have a look at that first rows. And if we now go down this vocation,
it's the only ones we're going to find, we're only going to find people with those three jobs,
I think there are only four on this old data set, mind you. But I'm only going to find those
inside of this data set. So remember, this is in method. And you can pass a list of things to it,
and it'll only look for those things in a panda series. And you can pass that to the dot loc function,
and then the dot loc property there, and then you're just going to get the ones that you're interested in.
Of more use, when it comes to free-form input, is to look for specific words or phrases in this
column where people can just type anything they want. So what if I only want to include patients
where somewhere in that vocation column, they had the word manager in it? Now, of course,
you can think of this idea of hypertension, diabetes, pulmonary, chronic obstructive airway disease,
comma, the keywords that you're looking for. And this is what you're going to do. Now, this gets
complicated, because this dot str string, oh, it has so much to it, there's so much you can do,
and it becomes so complex, but it's actually a lot of fun. But this is a useful one. So this is the one
that I want you to practice. And this is the one that's going to go into the memory banks.
So look at what we do, we're creating a criteria again. And our criteria is going to be this,
df.vocation. So that's a panda series that we're going to get. And then we call this str on it,
string.contains. The string.contains, you can see that as a method, the contains is actually the
method, but manager, I'm just passing this word manager in it. And na equals false. You don't have
to do that. I'm just letting you in on a little secret, because later on in this video, we're going
to look at nan values. I'll keep that as a little surprise. Na equals false. I think that's the
default. You don't have to put it there. Let's get back to what I'm actually trying to tell you.
I'm only looking for down that column for rows that actually has the word manager in it. And I'm
saving this as a computer variable called crit. And I'm passing this to the dot loc. So df.loc,
that criteria, and I'm giving this a new data frame name, vocation underscore df.
And let's have a look at the head of that. So I see energy manager, tourist information
center manager, estate manager, forward slash land agent, anywhere where there was manager. And you
can well imagine if it was this hypertension that you're looking for, it's only going to draw out
the rows in which hypertension appeared. So that can help you a lot. So remember that dot str dot contains.
Great stuff. Let's move on to something brand new. Do you want a break? Go have a break. Come back.
Are you back? Great stuff. Updating or changing the values in a data frame object. First thing we're
going to do is to rename some columns. That is a very useful thing to do because I said people write
all sorts of weird things with all sorts of illegal characters in their spreadsheet files. And sometimes
you just want to clean it up. The best way to clean it up is to use a panda num Python, use a Python
dictionary. Remember dictionaries, key value pairs, go inside of curly braces, go watch the other video
again. All right, df dot rename. Rename is a method for a data frame object. So df dot rename,
and I'm going to say columns equals. That's the argument, columns equals. And I'm going to pass
a Python dictionary. In this instance, I just want to change the name column to patient. Just showing
you that is possible. You can use other names for your statistical variables, column headers.
Okay, so if I had more, that would just be comma and then another key value pair. And we indicate
key value pairs by this colon in between. Remember? But what this is going to do, it's only going to
do it temporarily. If you want to make it permanent, some of these functions and panners you've got to
watch out for, and you'll pick them up as you go along. Some of them really have to have this argument.
In place equals two. In place equals two. You've got to have that. Then it will make the change in place
and permanent. Right. So let's have a look at df dot columns. Remember, that's how you get
the list of your columns. And there we say we don't have name anymore. We have patient there. That's
our new column header. If I look just at the head and the first five rows, you'll see patient there
instead of name. So we've changed that. What if I want to add two values, add two to each of the age
values? That is how we change actual data point values in that column. Now, one thing you can do
if you want to protect patient privacy, as a rule, everyone who's involved in that research,
you can have your little team. And the team says when we capture patients' ages, we are just going to
subtract two from everyone's age. So we're capturing these false ages. So if someone tries to track those
patients, they might have difficulty in finding them. And there are many ways to obfuscate the
data that you capture. You just have to put them back into the right values. Okay. So this is not
often necessary. I just wanted to show you that this is available. So let's not spend too much time with
that. The first way is to create a function. And I'll show you about creating functions.
Functions. Remember, I told you Python is full of functions. You add extra functions by importing new
libraries. But you can even create your own. Isn't life fantastic? So the def is our keyword.
We do that stands for define. We're going to define a function. We're going to give it a name.
And our very fancy name is add two, because we want to add two to every value. So seems kind of
appropriate as a name for a function. And then we say we have this argument. And the argument is some
placeholder, which we're going to call x. After that line has always got to be a colon, because
if you hit enter, there's going to be some white space. And I told you before, Python's very specific
about its white space. So I couldn't do that. The r right underneath the d. No, no, no. When I hit return,
the notebook's actually going to do that for me, it's going to have this white space. So it says return
x plus two. So whatever I put into it, my argument, it's going to return whatever I put in,
hopefully, it's got to be a number. Otherwise, this ain't going to work. It's going to add two to
it. We've created our own little function. Now there's a lot more to functions. But anyway,
so let's have a look at the ages before. So first one was 43. Remember, this is now a series 43, 53,
33. So let's use this very useful function dot apply. We're going to apply something to a pandas
series. So there's df.age. That's a series. And we use the dot apply method on that. And what we're
going to apply to it is our new function add two. Guess what it's going to do? It's going to look
at every value and it's going to add two to it. So let's have a look at that. Patient one was or
patient zero was 43. That's now he or she is 45, then 53, 55. So that all of that for us,
I'm going to show you another way to do this also quite hectic and to learn about function creation and
lambda, the lambda keyword. It's a bit a bit more advanced Python. But it can be useful and I want
you to know about it. So df.age, I'm going to overwrite the age column with df.age. So remember,
equal is not an equal, it's an assignment operator. So on the right hand side, I have this
spender series, I'm going to use the dot apply method. And what I want to do is this lambda function,
it does exactly the same as our little function we created. So lambda and we're going to have this
placeholder x. And what does it do? That's what that colon here means. Symbols have different meanings
inside of Python here, it means what to do with this placeholder. I'll take this placeholder and
subtract two from it. So I'm using that as my argument to the apply method. And if I look at what happens
now, because I've overridden it, I have what is on the right hand side, I'm assigning to what's on the
left hand side. So now I'm back to having subtracted from 45 minus 2 is 43. And we've subtracted all of
that. Okay, I wanted to show you that. Keep it in the back of your head, in case you ever might ever need it.
Now changing nominal variable to an ordinal variable. Hmm. So I have my groups.
And the sample space element for group had two elements in it, where Python was either control
or active. So in the control group, getting placebo and active, getting an active drug.
If I wanted to do something like logistic regression,
regression, I would have to use numbers inside of my logistic regression model. So I want to change
these names, these strings, I want to change them to numbers. So what I'm doing here is changing a
nominal categorical variable to ordinal. I'm being slightly naughty there, because just because it's
one and two, it's not really ordinal. And so I should probably change that. But I think you know what I'm
trying to say here. So one way to do that is the dot map method. So again, df.group is going to give
me that column as a series. And I'm saying doing the following map. And we're going to use a Python
dictionary. So wherever it says control, replace that with a zero. When it says active, replace that with a
one. And I'm overwriting the df group. So if I look at df group, that series, its head, I have 111,
because those were all active, active, active, but there'll be zeros in there as well. Now,
there's another function that you can just look at. And that's dot replace, it's going to do
basically the same thing. Good, we're almost there. Hang in there, we're going to change,
just mentioned changing the columns. We can add some columns, add new columns. And let me show you
some of these, I'm going to split the patient column, the patient column, remember, there was
a first name and a last name, into a first name and last name column, I'm going to make new columns. Now,
doing it with names is not that exciting. It's perhaps more exciting just to do that with other
variables. But let's let's just do that. And it's one of those SDRs again. So a bit more advanced,
but be aware of it. So new underscore data. It's a new data frame that I'm creating. I think I've
used it before. But anyway, it's just going to override df dot patient. So I have this
panda series of the patient column dot string str dot split. And I'm going to split it on
a space, because remember, it was first name, space, last name,
and expand equals true. Now, that's a bit of a difficult
one, always put it in for now. Just remember that always put it in.
Now to create a new column, I can just use this kind of notation, I'm going to say
df first name inside of a string. So just as you called them up, if they already existed,
you do the same thing if you want to create a new one. And what do we assign to that this new data
zero, because it's splitting, it's going to split this series into two series, basically, behind the
scenes. I don't know if you can really say that. But anyway, a zeroth one and the first one,
oh, I shouldn't do that. The zeroth one and the first one. So I'm going to put the zeroth one in
the new first name column, and this first one, which is the second one in the last. And let's look at
what df head looks like now. There we have right at the end, two new columns, first name, last name.
So here we had in patient, Dylan, Patton, now becomes Dylan and Patton, because the split
appeared on this little space that was between the n and the p for Dylan Patton.
Right, let's do something else. Let's combine two columns into a new column. So I'm going to create
this new column called name. Remember before it did exist, and we changed it to patient, so it doesn't
exist no more. So df name, and what am I going to assign to it? I'm going to concatenate these things
together. I'm going to concatenate the series last name, plus, that's the concatenation, putting them
all together, a comma and a space, which is a string, so I'm putting them inside of quotes, and then the
first name, pandas series. So if I put all of those together and look at it, now it's last name, comma,
space, first name. I've concatenated things into a new column. Wonderful stuff.
Perhaps slightly more interesting is changing a categorical variable,
create a categorical variable from a numerical variable by binning. It's called binning.
So let's just have a look at cholesterol. I see the minimum cholesterol before was 1.2.
Now, that's units we use locally. Other parts of the world don't use SI units. But anyway,
and the maximum in our data set was 11.1. Just roll with it or those are not the values that you're
used to seeing. So let's cut that up. So between that minimum of 1.2 and a maximum of 11.1, I want
to create three groups of people, those with low cholesterols, those with intermediate cholesterols,
those with high cholesterols. So that's an ordinal categorical variable. There is some order to it.
Low, intermediate, high. It is categorical because we just now have these three discrete categories.
So I'm going to create a new column. I'm going to call it cholesterol before level. Makes sense.
And so what are we going to do? We're going to use the cut function. It is a pandas function,
so it's not a method of an object. So I've got to say pd.cut. What do I want to cut? Well,
the series, please, cholesterol before, and create bins for me. And I said bins equals three.
So pandas is going to go automatically go from 1.2 to 11.1 and divide that up equally into three equal
sections of equal size. And I'm going to give each of them a label. So the first, and it's got to be an
order. And it's got to make sense how you construct this to what you're trying to achieve. So I've got
low, intermediate, and high. And let's just look at the first 10 of those. So I'm using the dot head
and then to an umpire array. So it was kind of in order. So 1.2 is low, 1.2 is low, 2.0 is low,
2.1 is low. But if we did 100, you'd see the intermediates and the highs as well. But just to show
you here, that 3.2 is indeed low. So this all works out for us. Sometimes it doesn't work out.
So you want control, you don't want three equal bins, you want to control the size of the bins.
And here we have that, I'm just going to show you exactly that. So I'm overwriting the cholesterol
before level already exists, I'm going to overwrite it with this pd.cut. So I take pd.cholesterol before
that series and the bins, I still want three bins. But I've written four numbers here. It's because if you're
looking between them, you're going to have three bins from 0 to 5, 5 to 10, and 10 to 20. So if I
look in between those, I have three bins. And I'm going to say right equals false. And I'm still going
to have the same labels. So what does right equals false? Because right equals true, I think is the
default. So we've passed right equals false here. If you remember something about intervals from school,
you get the closed intervals and the open intervals. And closed intervals, we have the
the note by a square bracket, and the open interval with a 5. So if it's square on the
side 0 to 5, that means the 0 is included. But on the open side here, we have a 5. So the 5 is not
included. So the next lot would be 5 to 10. But the 5 is on the closed side, meaning that it is included.
Right is the right hand side of this interval. So the 10 that's set to false, right equals false,
means it's excluded. So think about this. What if a patient has a cholesterol of exactly 5? Which of
the two groups are they going to fall in? In the low or in the high? Well, if they're 5, they're going
to fall into this intermediate group because 5 is included. The right hand side set to false. So if
they were in 5, they are on the open side and they are not in this group. So 5.0 exactly will be in the
intermediate group. 10.0 exactly will be in the high group. They will not be in this group. So that's how
you control your bins. As simple as that. I hope it's simple. So you can control the size of these
bins exactly where you want the cutoff to be because medically that's going to make a hell of a lot more
sense. So let's delete a column. That's just the drop method. So df.drop. And then I'm going to say
columns equals. That's the argument. And I'm going to pass a list of column names that I want to drop.
So you've got to put it inside of square brackets. You've got to pass a list. And you can say comma
others. And the drop method is one of those that if you want the changes to be permanent, you have
to put the in place equals true argument. This is one of those things. So if I now look at df.columns,
that name, remember that we did first name, comma, last name, comma, space, first name,
it's gone now. It's gone from our list of columns. Sorting. Let's go on to sorting.
I want to sort values. And so that is a method. So I'm passing df to it, my data frame object,
it has a method called sort underscore values. And it has a argument by equals, and I want to sort
by last name. By default, this is going to be where's our last name? Where's it here? It's going
to go in alphabetical order. So now Abbott becomes first and etc. And look at the index on the left hand
side. That's all scrambled up now. We've sorted alphabetically by the last name. I can do other
things. I can say sorted in ascending equals false order. So another argument. And if I were to run
that, and if we look on the right hand side, now we're going to start with the z's here.
Okay, simple, simple stuff. Now what if I want to sort by more than one thing? Well, I give it that
order in which I want to sort. So first by the age and then by the systolic blood pressure. So the
youngest patient was 30, but there were three of them. And if we jump to the systolic blood pressure,
that is now an ascending order, 133, 159, 168. So all those three patients were 30 years old.
But now it's going to move on to the second one that I want to sort by. And you can even do that
mix and match. So I can say ascending and pass a list of values to it, true and false. So age,
true. So that's going to be an ascending. But SPP and descending please, I'm passing ascending
is false to SPP. So I've got to have equal number of argument values in my list there.
But now look at it, 30, 30, 30. They're in that order and then 31. But if I look at SPP,
now the highest SPP is first of those three patients that were 30 years old, 168, then 159,
133. So you can mix and match as much as you want. A couple of useful methods I just wanted to almost
finish off here before we get to missing values and dates and times is the n largest. So yeah,
I'm passing 15 to it. So I'm saying go take, give me this df.spp series, the systolic blood pressure,
give me the 15 largest, please. Boom, it's there. I can change things around slightly differently.
And this is a different notation. This is pandas, it can do things in many different ways. And you
just see the other notation there. But this time, it's going to return the whole data frame object
for me, instead of this method that is, remember, first it's going to give me
this syntax is going to give me the panda series. And this one is row comma column,
not row comma column, I shouldn't say that because look at this, it's a function. Oh,
I'm really probably getting tired here. Am I not? I hope you were taking breaks.
It's n dot largest, give me 10 and go down the SPB column, but give me back this whole data frame.
So you can see the difference there. If you haven't taken a break, take one now,
because now we're going to get to something very important. And that is missing values.
Are you back? Let's look at missing values. The NumPy library's NAN
value. NAN stands for not a number. But it's actually for any kind of missing data, basically.
But anyway, let's stick with pandas here. With NumPy, we're going to do not a number.
NP, remember, we used the abbreviation for NumPy dot NAN. And that gives us back NAN, not a number.
So if I have a list, and it has 1 comma 2 comma 3 comma NP dot NAN in it, and I look at what my list
looks like. Lo and behold, it's going to have 1, 2, 3, and then not a number. So can I sum?
Can I use the NumPy's sum function to sum over? We saw that before. We can just sum over all of these.
What do you think is going to happen? It's going to return a NAN because that's not a number.
It doesn't know. Python doesn't know. You don't know. I don't know. So how can we add these values?
It's going to say 1 plus 2 is 3 plus 3 is 6 plus what? It depends on what NAN is. Well,
it's NAN. It's not a number. So we don't know. So it's going to turn that NAN for you.
So let's see how that applies to missing data. So inside of our data folder, which we are still in,
because we changed directory to it right in the beginning, I'm going to import this missing data.csv
file. And I'm going to very appropriately give it this computer variable name missing underscore df.
So let's look at missing df. Print it to the screen and look at that. That cell was empty.
If you looked at the spreadsheet file, you'd see that was empty. And now they pop up as NAN values here.
Oh, boy, are you going to have difficulty in analyzing this data now? So let's try and get rid
of some of these NA values or do something with them. One way is just to drop them. Missing data,
missing df dot drop NA. It's a method for data frame. And now it's just going to drop all those
values. And if I now look at this, all the all those patients, but look at them, they're missing
now because we go from patient zero, one, two, three, four, five, and six are gone. Just because
they had perhaps one missing value, those patients are now gone from my analysis. That might be a bit
tough. We all know how many times we don't have any data. Now I can specify, just read here,
you can specify how to be dropped. The default how is to any arguments you can set values to arguments.
So if any one of those in that row, anything is missing, just one thing is missing is going to
drop that. You can also say, all have to be missing before you drop that row. There's a bunch of stuff
you can do. And you can also drop, we were dropping rows now, but you can also drop columns.
And then you just add this access equals one, or set it to columns, access equals columns or access
equals one. That's going to drop a column for you if it finds anything. And you can do the how there as
well. Okay, more importantly, as you can specify that you want to drop something only if something
is missing from a very specific column or more than one column. So over there, we can choose the
argument subset. So missing the underscore df is our data frame. We're using the drop in a method,
and we're using the subset equals argument and we're setting it to a list of values. So here,
we will only drop a row if the age was missing. So the ages are all there now, but see, we've dropped
some patients now because there was some of the other columns had an in value in there.
Now we can also just call a data frame, I should say, pandas series, missing underscore df dot age,
and we call this isNA method on it. And it's going to go down that series and just say true or false.
Is it missing or not? False? No, it's not missing. True. Yes, it is missing.
And behind the scenes, I think I've told you before, false is stored as the number zero,
and true is stored as the number one. So that makes it for a little nice cheat because I can say
missing df dot age. So that is the pandas series we're looking at, the age series there.
And I can say isNA, which is going to give me a bunch of true and false. And I can say dot sum,
dot sum method on that. And it's going to count all the trues as ones and the falses as zeros,
add all of them up. And that's an easy way to show me how many of the values in that column
are actually missing. And I can see there's 17 missing. OK, so they're missing. What can we do
about it? Well, we can replace them. Replace missing values. Yeah, you needn't throw that whole patient's
data away. We can impute the data. Data imputation. And that is where you fill in values that you
didn't know before. And that is a huge subject, all on its own. So I'm going to show you some of
the easy ways to fill that in. You can use this method on a series object, fill in a. So I'm going
to say missing underscore data, data frame dot age. So that's a series and I use this dot fill in a
method. And I can set a method for that and F, F, F, F, F, F, I, L, L. That means forward fill.
So when you look, when we look here, for instance, forward fill means it's going to take the one just
above it, that two, two, two, five, oh, and fill that in there as well. And just going to forward
fill. And if there were two in a row, they're both going to have that value. There's a forward fill.
And there's also a back fill. So it's going to take the number after that to fill in there. And
that's not very scientific, but hey, it works. So there, I'm just using the forward fill.
Another way more for numerical variables is perhaps to fill in the median value. So take
the median of a numerical variable and just fill in all the NAs with the median for that variable.
So let's look at age. MissingDF dot age dot median. Now you see something
very important here that we should just stop at. Pandas is very nice at automatically ignoring
missing values. Unlike NumPy, remember, we couldn't sum those because there was a NAN value.
Now Pandas by default is going to ignore NAs, but we can set that whichever way we want.
So the median age was 40. I can now say missing underscore DF dot age. So that series, fill NA,
use that method, and I'm going to fill it with missingDF dot age dot median. So I'm going to fill
all the missing values with the median, which is 40. That's scientifically a better way to go about it.
Of course, if I wanted to make it permanent, I had to use this in place equals true argument.
Okay. Default missing data is something I want to talk to you about as well. Sometimes when we
collect data, with the people who collect data, we have these codes. We say, if you don't know,
if that data is just not available. So it's not like someone didn't fill it in, they were lazy or
whatever. Somehow that data is, no matter what, it was not measurable. It does not exist. We're going
to use a code like 999 or nil or actually use the word missing. We can have all these codes. And so when
we import a data frame, a data set, a spreadsheet file that we know that these values do not exist,
we can say to this import function, the pd dot read underscore csv, import for me this data frame,
this spreadsheet file. But these are the values that if you find them, please change them to NA values.
That's much easier to do than later on they're going to go change all these with, remember I said dot
replace or dot map, and we can use curly braces as dictionaries. Just put them all as NANs right from
the beginning. And we can say this NA underscore values equals and pass a list of all these codes
that you have. And now in my data set, instead of seeing 999 and nil and missing whatever code you
came up with, you're going to see them as NAN values. And sometimes that is a lot helpful.
If you want to go take a break, the last exciting thing is going to come up and I'm going to brush
lightly over it because again, it's a very deep subject, but I want to show you the easiest ways to
deal with it. And that is dates and times. As I said, you're going to get dates and people do the
most horrendous things when they capture dates. Then they put them day first, then they put,
they just change halfway down the line. It is, it gets crazy. Okay. So let's import this data set.
It's a spreadsheet file, dates, times dot csv. And I'm going to use the computer variable for it.
Instead of df, I'm using dt. Felt like something different. We have an id column there.
Okay. So patients got an id when they got into the study, first name, last name, date of birth,
and time of admission. So somehow, you can see this is very contrived because I just want this
type of data so that I can show you. If we look at the DOB, the date of birth column there,
it looks to be month, forward slash, day, forward slash, full year. So not just 58, but 1958.
If we look at the times, the second one there is 23, 52. So that's on a 24 hour clock.
And that's eight minutes to midnight there. Okay. That becomes important. So let's look at the d
types of this dt data frame object. Contrived, the id is integer 64, right? First name is an object.
Categorical, that's right. Last name, that's right. DOB, that's not an object. That's a date.
And time of admission, somewhat was important what time of day these people were admitted. But anyway,
that's an object as well instead of time. That's all wrong. So let's do something. But let's do
something useful that we've seen before. We're going to create a new column. We're going to call
it daytime. And it's going to be this concatenation of different series. So give me dt dot DOB,
concatenate or plus to that space. So that's a string. So put inside of quotation marks plus
dt time of submission. And let's have a look at that now. So now we have this DOB and
date time all in one row. Okay. That's very wrong because the time of mission and the date of birth
have nothing to do with each other. I just wanted to show you, you can combine this. Because we have
this thing called a date time object. Date time. There's date and time in there. And that's why this
contrived example, I did both of those. I suppose I could have called that the time of their birth.
But not all of us know what time exactly we were born. But let's look at it now.
This date time column that we've created, it's still a date type O. It's still kind of an object,
is it? So we get this to underscore datetime pandas function. So PD, we've got to use PD dot,
because it's peculiar to pandas. So PD dot to date time. So I'm going to create this new column,
just because I can, and I'm going to call it date time, but with lowercase d
and t. So it's a new column. So I'm going to use this to date time pandas function. And I'm going to
say take the dt dot date time column as it stands now, and interpret the following format for me. So
there's this format equals argument. And you can go on pandas on the website and look at these,
because there's uppercase m's, lowercase m's, and they all mean something very specific.
But here we have, inside of quotation marks, we have percentage m, lowercase m. And that just means
it's going to be an integer month value. Then we're going to see a forward slash. And I'm going
exactly, if we look here at this last row, this 24 here, index 24, 25th patient, I'm going exactly
according to that recipe. Then there's a forward slash, and then a percentage d, because the month,
or the day, sorry, is also written just as an integer. So it's a lowercase d,
forward slash again, and then percentage uppercase y, lowercase y would have just been that shortened
year, 59, 58. But it's uppercase y. So it means it's the full year, 1959. Then there's a space,
because we have a space there. Then there's a percentage h, and then a colon, and a percentage
m, and they're all uppercases, tell us hour and minute, and they buy military time. So it's 24 hour
clock time. So you've got to tease out what it is all about. And now look at what it's done. There's my
new date time column. Beautiful. Because this is now really a date time object. And we can extract
stuff from a date time object. For instance, I can create a new column called month. And I can see,
say, dt.datetime.dt.month underscore name dot string dot slice stop equals three. Goodness gracious,
great balls of fire. I hope your mind is refreshed, and you can just tease that apart a bit. It's not
that difficult. So dt, a data frame, has this property called date time. If indeed it is a,
oh, well, date time, I should say that's our series. Let's start there. dt.datetime, that's our series.
It has this property called dt, which has a method called month underscore name. So that's going to give
us, it's going to look at that date time object. And it knows now which one of all those values is
the month. And it's going to extract for us the month name. So just that it's going to give us the
month name. I've added to that the fact that I want this short three month abbreviation. So if you just
stop there, you're going to get the full January, the full February, the full March. But I want to slice
it a bit. So I'm going to use the str.slice method. And I'm going to say stop at three. So January is going
to become J-A-N. February is going to become F-E-B. So you needn't put this if you want the full ones.
I can just say dot month name. Okay, there we go. And now I have look at this last column here.
Month, February, March, January, February, August. And it extracted that from the fact that it's the
daytime object this and it knows exactly where it is. So stop there if you want the full,
just stop there. This extra bit is just me confusing you. But you know, it looks nice when
it's like that. So I want to show you how to do it. And because it's a datetime object, I can also
extract other things. I'm saying give me this datetime series. So dt.datetime. And there's a dot dt.year
attribute. So it's going to look down all that and just extract for me the years. Or I can say just
extract for me something like all the hours. Or I could say dot minute. And now it's going to extract
for me all the hours. And I can put that in a new column because that might be important for my
analysis. Okay, I'm up. It's done. Congratulations. You've made it. You've learned something about
pandas. Again, the first time you see this, it's going to be difficult. And you're going to have this
question. I want to do this to my data. And you won't remember. Come back to this video. Come back
to this notebook. Search on Google. You'll find help anywhere. Just type it in. Formulate it somehow
in Google. Type it in. Someone is going to answer your question. Go to the pandas website. The
documentation is going to answer your question. And after you've used it for just a little bit,
go through one project. Go through your second project. By the way, your third project, all of this
is just old news. You just know how to do it. And you can even, if you haven't seen it before,
guess how to do it because these things form a pattern. Python pandas is beautiful this way.
Once you figure out how to do one thing, you can kind of guess what a new thing is going to look like.
I hope you enjoyed this video. Give it a thumbs up. Subscribe. All those nice things I should say,
I should probably also say so that you can confuse me with a real YouTuber.
And then tell others about this. So many people have taken the Coursera course. It's been such a
wonderful thing. And I want to keep on spreading these resources to teach you how to do this yourself.
Because in so many areas where we need answers from research, people can't do their own research
because there's no one there with the ability to do it. It's expensive to get. There's expensive
software to do it on. Again, looking at you, IBM and SPSS, I hate that because it just removes the
ability for people to do research. And through that research, we can get proper answers, answers that
otherwise might be hidden from us in the medical community. So I hope you're enjoying this. Tell others
about this so that they can learn how to do their own data analysis using Python. I hope I get some time
to make more of these videos.
