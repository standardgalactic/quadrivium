In this video I want to talk to you about regularization. Now we looked at this issue
of high variance where the model that we build is just way too specific to the training set
and it doesn't generalize well. And regularization is one of those ways in which we can tackle
this problem. Now when you start writing the code it's just simple little additions that
you make. It's a few characters that you type when you create this. So strictly speaking this
video is not necessary. You don't have to watch this especially if you're not interested in the
mathematics behind what is going on. I would advise though that you just listen to it with one ear
or at least just read the rpubs document or download it from github and just read through it. As with the
previous one really to have the document in front of you and go through it a couple of times is
perhaps better than than listening to this video. So if you're interested in the mathematics or at
least some of the philosophy and lightly touching on the mathematics watch this video. So the problem
here is that we have high variance that the model is just fitting our training data just too well. It's
memorized that data and we need to do something about it. The first concept I really want to talk
to you about is the hypothesis space and a way to look at the hypothesis space one way to look at it is
just to look at all the possible solutions that our cost function can take by doing this gradient
descent and getting these optimum values for the weights and biases the parameters and that all of
those values together make up the hypothesis space and one way to do it is just to try and constrain this
hypothesis space so that not all the possible values are available to the model during this gradient
descent process this back forward and back propagation process if we can limit that hypothesis space
then perhaps we can get to some values they might not be the best but they might
for the training data at least but they might generalize better to to the training set or the real
world data and one way that we can go about this is to just consider this concept called complexity
complexity so the hypothesis space is large i mean then the more variables we have
and the the bigger our network is just the more and more and more and more parameters we're going to
have and so many possible values to those and if somewhere if we if we can if we can create a measure of
complexity if we have such a measure then perhaps we can start cutting down on that complexity
and the way that it is done is just to to take this hypothesis space and make a sequence out of it and
we're just using this this double script notation here of the h just denoting that that is a set
and h1 hypothesis subspace one is contained within two is contained within this total one at the end here
so we just create the sequence so everyone is totally within the next one so this is the big one and then
if you just take some of it and some of it and some of it getting smaller and smaller and smaller
you can you if we can create this we can start thinking of of you know putting a number or some value or
something to this hypothesis space and deciding where we want to make the cut off so that anything beyond that
is now not available as a solution because that is perhaps where this these solutions lie that are just too good for the
training set and not so good for the rest so let's look at ways that we can can denote complexity can
we can can we wrap our head about one way of classifying complexity well there's four for you here
and i'm just considering simple linear regression we started the the series off with that but it really
just expands naturally as i write here two parameters in neural networks so one way to look at it is just to
look at the dynamic dimensionality of the input space you know how many feature variables you have
if you have fewer feature variables you cut down on complexity that is a measure of complexity
now that's not something that we can use here and that's nothing to do with regularization i just
wanted to introduce this concept of complexity because i can now constrain that that this measure by only
taking four of my possible 34
variables feature variables or i can take you know i can take any number but you can see that i i have this
sequence of complexity if this is my measure of complexity
two feature variables will be less complex than having five which is less complex than having 10 which
is less complex than having 20. another way is just to look at the number of my non-zero coefficients
so remember in linear regression we had and then even in the in the feed forward the forward propagation
section we take a weight times x sub one plus the weight times x sub two so all these weights these
parameters they are coefficients and if i take all the ones that are non-zero i can i can count them up and
that can be a measure of complexity and i can cut down by just throwing away some of these and this
measure of complexity that's known as this this script l sub zero that's l sub zero complexity
another way to do it is just to take all these weights my parameters and just take all the absolute
values so make them all positive and just add all of them all of them and there's millions of them just add millions
and that is called l1 complexity or lasso complexity and then if i square each of them and then add all
of them that's called l2 complexity or ridge complexity and that's the one that we're going to concentrate
on here when we talk about regularization because you get l1 and l2 regularization but if you think about
it this these measures of complexity say we take number four that allows me to symbolize it let's
call our symbol for the complexity based on this little equation as omega and then therefore we
can choose some element of omega let's call it r so such that we can constrain the hypothesis space
so we're only going to look at stuff that is within this level of complexity and it doesn't carry on on
on here to the right hand side and so now let's get to regularization because we can set this r now
it's not a value that we're going to set it's just just think of it as a concept some somehow we're
going to build a constraint into the system now there are two ways to go about it when we look at the cost
function here's in three i'm just showing you the cost function again this curly c is a function of all the
weights and the biases and remember this cost function is just a function of all the predicted
values and the actual value so if it was linear regression it's you know the difference between
those squared etc but it's going to be some measure of error between what the predicted value was and
what the actual value was and we sum over all of those and then we divide by how many there are so
that would be one there's this idealized form a generalized form i should say of the cost function
and the whole idea here is that we want to if we do this forward and back propagation all the time
we're going to get these idealized values values of all the weights and biases the parameters but
we want to constrain that somehow and we can build something into this function that will constrain it
that's called even of an even of type of constraint but another way to go about it is called the ticker
of regularization and what we do there is we're going to add a term as we can see here in function
and in equation four we're going to add this term it looks horrendous but we'll break it down it's
actually very very simple now when you see stuff like this you think wow but it really is this very
fancy writing for something that's very simple we're going to have this lambda value now lambda
is a hyper parameter that is something that you will have to actually decide on when you design your
network divided by 2m and what we just do is we take the square of something to do with the weights you
can see something to do with the weights now look at this what's happening though we are adding
something to the cost function so we're making the cost remember as a value in the end we're just
trying to make it more we're increasing the cost and when the back propagation tries to through
gradient descent tries to minimize this cost function it is actually has something added now to deal with
and one way that it's going to minimize this cost function is by making each of the weights because
you can well imagine that this is some matrix of all the weights it's going to make the weights tend
towards zero if they tend towards zero that makes the model simpler less complex if some of the values of w
get closer and closer to zero you can well imagine that it means easy to imagine that we have a simpler
we knock out even knock out some of these weights that it just becomes a simpler model and if it's a
simpler model we have actually constrained the possible values that it could take and the way that we did
that was this ticking off regularization we add a term to it if we add a term plus there's an addition
here of a positive value we're going to therefore force this gradient descent to select out smaller
and smaller and smaller versions of all the parameters another thing that it actually does if
you think of the tanh function when we do the activation if we make it smaller the weights closer to
to zero we're going to be in this linear part of the tanh function and if we do that
we almost have a linear model and remember a linear model gives us a much a much straighter
decision boundary the decision boundaries that we discussed in the previous video gives us a closer
to that kind of model and and the end effect of these things these hyper these thoughts are that we are
constraining the hypothesis space not all values are possible anymore and that's where this r
is an element of omega idea comes in because i can set this lambda value up here when i write the code
and that is somehow going to you know the larger i make it obviously the better i bigger value i add
to my cost function thereby driving the value of w even less and less and less until they come closer to zero
and that is the thought behind this so there is this even of regularization where i actually build
something into this function adding something is sort of a different idea but they all they all sort of
boils down to a similar thing it's called you can see down here the lagrangian duality theory we're not
going to discuss that but it all boils down to the same thing specifically then if we think about the
ultimate goal here and the ultimate goal is just to generalize the model and whether you build
something in there or whether you add another term you're going to end up with the same thing so this
is done all the time in machine learning this is called l2 regularization because we use this form
here and if you look at it just taking this part down here let's break it up it looks something like
this and you think well well that looks even worse doesn't but let me just let me just show you what
it's all about remember in the in the forward propagation we take the weight and we multiply it
by the vector the weight matrix times the vector of this is the vector here of the column of the previous
layer and this x here the l refers to the current layer l minus one is the previous layer so to get the
values inside of that layer the previous layer you take the weights of that layer and you multiply it
by the previous layers column vector watch those videos again and to do that just look just look at
the weights or the dimensions at least so after transposing the weight matrix should actually be
l times l minus one so that's the number of nodes in the current number of nodes in the current layer
times the number of load nodes in the previous layer and remember this is the previous layer has
dimensions it's a column vector of l minus one times one and if you multiply those out you are going
to get l times one so let's just look at w and let's make w something that's three by two and there we
have it three rows two columns and what all of this does at the top of there is very simple it just
runs through each of the rows well so this column in this column through each of the rows so it says
three squared plus four squared and then two squared plus one squared and then one squared plus one squared
and you just add all of those and you get 32 it's as simple as that this whole just thing just means
to square all the values and that's ridge or l2 regularization and that's all we're going to do
we just add this term which just squares all the values in the weight matrix and just adds all of
the values that's as simple as that and if we think about taking the derivative now of this
if this uh if this function siya is what we would have had without the regularization term the derivative
of this extra term it's just this very simple and that's why we put the half in there it's just a
scaling factor because if we bring the two forward during during the derivation it cancels out with
the half that's there so we're just left with lambda lambda over m times actually the weights there
so it's just bringing that forward remember these are just additions and if you think back at
derivatives if you just have a bunch of terms that are just added you can just take the derivatives of
each of those separately and that's all that happens so this term is actually very easy and when we
update the weights let's just subtract from that the learning rate times this very simple derivative
so it doesn't add much to the computation if and in the end you're actually just going to write a line
of code just to add just to add the regularization to it but i think now you would have a deeper
understanding of what this regularization is you can of course do l1 regularization we just add the
absolute values there we looked at it at the top here there we would just add the absolute values of
all of those that would be l1 um regularization here we have l2 regularization you can see what it really
is very simple and that's it we're adding to the comp we we adding to to the cost function thereby
driving some of the weights to zero making for a less complex
system and that really constrains this to only certain values of the weights the parameters that
we are trying to learn only certain number of them being available we're constraining the hypothesis space
so we're going to get worse performance on the training set but that will might generalize and
that's what we're after generalizing better to the test set or real world data so in short that is
regularization the document will be available read through it it'll make sense when you read through
it a couple of times it's actually very easy to understand the calculations are very easy
and just eventually when we do write the line of the code and using tensorflow or keras then with
the tensorflow backend and r it is i mean it is simple so as long as you have some
understanding of what is really happening behind this behind the scenes which is trying to constrain
the hypothesis space in the hypothesis space i'll speak to you again
you
