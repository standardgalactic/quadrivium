In this video, I want to continue our talk on what to do if we have this problem of overfitting,
high variance, so that we have that our model fits the training data very well,
but when we look at the validation or test set or some real-world data,
we notice that that fit is very poor. And the method that we're going to talk about in this
video is called dropout regularization. In short, I'm just going to refer to it as dropout,
just so that we differentiate it from the term regularization, by which we usually mean L2
regularization, which we looked at in the preceding video and chapter.
So what dropout does is just remove some of the nodes. Now it doesn't remove them,
they're still there, but it creates a zero. So the value of that node becomes zero. And you can
well imagine that if we have a couple of nodes in a layer become zero, that is very much the same thing
that we achieve with L2 regularization, whereby we drive the value of those parameters to zero,
giving us during the multiplication stage, giving us values close to zero for those nodes.
So how it actually works is, well, there are different ways, but the normal is just to use what
is called inverted dropout. So what inverted dropout does is it looks at a layer, and a layer contains
a number of nodes, where you can see there a layer of nodes, and some of them are just going to be
chosen to be zero. And how does that work? Well, we create a vector of the similar number of elements.
Here we have one, two, three, four, five. So we would create a vector of five elements,
and each of them will receive a random value in this domain from zero to one inclusive.
And we set this value, say, 0.2. And if it's if that random value is less than 0.2,
we turn that value in the vector into a zero. And if it's 0.2 or more, it'll become a one. So we'll
have this vector of zeros and ones, with that just be random. And then we have element wise
duplication, multiplication. Therefore, some of the values that remain in that layer after activation,
remember, this happens after activation, that is going to be either the actual value,
or zero, the actual value or zero. So we have these zeros in there. Now we actually,
when this all happens during randomizing those values, we actually actually subtract that value
that we decide on the 0.2 as our cutoff, we subtract that from one, and that gives us an 0.8.
And that is our what we refer to as our keep probability value, you see the keep probability.
And in essence, then you can think what that is what happens, we're going to keep 80% of these
at random, and 20% are going to drop out. So our key probability rate, if we said 0.2 would be 0.8,
if it was 0.3, it'll be 0.7. And I'm just going to refer to that as a kappa value,
the key probability value is 0.8. Now with the inverted dropout, there's actually one more step.
Now remember, when we do this feed forward, when we do the forward propagation,
we're going to multiply our matrix of the coefficient of parameters with this column vector x
of the previous layer. And we add all of those once we once the multiplication takes place to give
us this value, but some of them doing this addition is now going to be zero. And imagine we
use a rectified linear unit activation for this node. It is now going to be smaller than it would
have been before, because during all of those additions, additions from each of these inputs,
some of them are now going to be zero. And we have to, we have to compensate for that somehow. And the
way that we compensate for that, it's each of these values that come in,
or each of these values that we now have after this multiplication gets divided by the kappa value.
That's very important. We divide all of them by the kappa value so that when we do add,
before we do our rectified linear unit activation, for instance, that we are on a similar scale that we
would have been should that not have been should we not have had zero. It is a very important step.
And if we write the code, that's actually going to happen automatically. But I think it's important
just to realize that we don't want we that we have a scaling problem where about the node is going to
be different, the value is going to be different for the activation. So we divide these values by
by kappa. And the effect of all of this is that we might have some of these nodes starting to overwhelm
the system, they become more important. And they become more important during the training phase. And
then that fits the training data very well. But it's a false, false hood. And we want to try and prevent
that. So there's this random chance of removing some of these. And as you can imagine, then once again,
we constrain the hypothesis space. And thereby, we create this model, a simpler model, which might
then fit our test or validation or real world data a lot better. So I'm very short, that is dropout,
those are just the key thoughts on dropout. So just understand what is happening, we are just going to
create some of these values to be zero, the technicalities of that you needn't be too concerned
about simple addition to our code. And very excitingly, in the next video, I'm going to show
you how to implement L2 regularization, as well as dropout, and we're going to see how that affects
the data, and how that's going to try and at least try and fix the problem of overfitting that exists in
the data set that we are going to use.
All right, let's get started.
You
