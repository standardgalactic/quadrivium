So today we're going to talk about randomness and probability and sampling and sampling
distribution. So this is actually a very important notebook that we're going to work our way through.
We're going to start off with by rolling some dice and flipping some coins so that you can
understand this idea behind probability and how that is eventually, the randomness in that,
is eventually going to help us in data science to analyze the data that we work with. So we're here
in notebook number seven, randomness and sampling. So let's just have a look at the packages that we're
going to use. Remember, I use that line of code if I work on a MacBook. So in this instance, I'm
recording on a Windows machine. So that's not going to be too important, but we'll run that line of code
anyway. And then my usual percent load underscore ext and then the google.colab.data underscore
table. That's my magic command there, just so that the tables print out nicely. And then things we've
seen before. So we're going to import from NumPy or at least import NumPy with a namespace abbreviation
np. We're going to import from SciPy the stats module. We're going to import pandas, use the namespace
abbreviation pd. So let's do all of those. And then for plotting, we're going to do graph objects.
We're going to do IO, just to set the plotly underscore white theme for us there. Plotly Express
and then also figure underscore factory. That's a different module. And we're going to import that as
FF. And let's just set that default to plotly white. So we're going to talk a little bit about
randomness. You flip a coin, you roll a die, random numbers come up. And a computer can to some extent
simulate that. Because as human beings, we're very, very bad. If I asked you to just say, to say from
zero to nine, give me a list of a hundred random numbers, or do it a hundred times, so nine, eight,
seven, six, four, three, there's no ways that human beings come up with real random values. We form
little patterns in our head. So and somehow we've got to replicate that on a computer. And what a computer
does it uses an algorithm. And it can use infinitesimal little time fractions on the clock cycles of your
computer CPU. There's all sorts of algorithms that it can use to come up with these random numbers. But
they're not really random in as much as we won't go into the depths of this topic. But they are actually
pseudo-random numbers, because they come from some algorithm. So we've imported NumPy as NP. And we can
do this seeding. So numpy.random.seed. So that seed function gives a value to the algorithm, so that
when it generates random numbers, and you run the cell again, I run it, you run it on your computer,
we're going to get the same set of pseudo-random numbers. And we do that a lot in data science if we,
you know, if we're involved with teaching, or if we want to share our code. And we put those random
seeds in there because we want those results to be reproducible. So if we're putting in any integer
value there, I've put in 42. If you wrote this line of code, and you put in 42, you're going to get the
same set of pseudo-random numbers as me. And then in this random module, there's also a choice function.
And what you do with a choice function is you pass a Python list. And this time I'm passing a list with
two elements, and they're both strings. And what is going to happen is one of those two are going to
be chosen at random. And as I said, I know what the result is going to be when I do 42, because I've run
this line of code before. And if you do exactly the same, you're also going to get the same result.
So let's look randomly, or pseudo-randomly, what the value is that was chosen. And we can see that it's
heads. So heads came out at random. So this choice function also takes a second argument. So I've set
the comma 10, and this time it's going to do this 10 times over. So it's going to draw heads or tails
for me 10 times over. But I've set the random seed to 42 again, so that if me and you, if we both are in
this line of code, we're going to get the same pseudo-random numbers. And this time it's heads, tails,
heads, heads, heads, tails, heads, heads, heads, heads, tails. As simple as that. So let's ram things up a bit.
We, you know, this is a powerful computer. We're running this in the cloud on Google servers,
quite powerful machines, obviously. So let's go nuts. So I'm going to, this time, set the seed to
none. And otherwise, now I'm going to get real pseudo-random numbers. In other words, if I run
this line of code twice, I'm going to get different values. If you run it, you're going to get different
values. So I'm going to create this computer variable called flips. And to that, I assign a
pandas data frame. So pd.dataframe. And what I'm going to do is generate a column through,
just using index notation. So a dictionary there. So you see the curly braces, curly braces. So it's
a dictionary. So key value pairs. My key is going to be flip. So that becomes the name of the column.
And the values is numpy.random.choice, heads or tails, 10,000 times. And let's look at the first
five rows with the head method. So that's going to run in it. Got heads, heads, tails, tails, heads.
As I say, you run it, you might get something different. I run it again, I'm going to get something
different. But it's 10,000. So the random.choice function, random.choice function, that's an
equal likelihood for both. So let's just see what happened in this 10,000. We can do, because
this is a data frame, so we can call the series or just that column by saying flips.flip, because
remember, I made flip the column header, dot value underscore counts. So that's going to tell me,
you know, the frequency of the sample space elements. So it got 5,097 heads and 4,903 tails.
That's very close to each other. It's theoretically, we're going to get a 50-50. But we'll have to do a
lot more than 10,000, you know, to get closer to that theoretical 50-50. And there's actually a term
for that. And we'll get to that a little bit later. And that's that, how we get from our actual values
to the theoretical values. There's a little term for that. So that's the coin flip. Let's roll a die,
a fair die. So by fair, we usually mean all the six values have equal likelihood of landing face up.
That's not some loaded die that's going to fall on certain values more frequently than others.
So we can simulate that as well. And I'm going to create another Pandas data frame,
and I'm going to call it die. And to that, I'm going to assign, again, a single column. And I'm
setting that up right there as a dictionary, key value pair. So die is my column header. My values
are going to be a random dot choice. And the choice is going to be made from this Python list that I've
created up here sides. And it's just a Python list of six values, one, two, three, four, five, six.
And it's going to do that 10,000 times. So let's do that. So we've rolled our die within a fraction
of a second. We've rolled it 10,000 times, and we can just create a bar chart. So I'm going to do that
from the Plotly Express module. So px.bar. And then we want to know what the variable is. We're going to
do the bar chart of. So x equals the sides. So what are the sides? Remember, if I hover over there,
we'll actually see the tooltip come up. It's one, two, three, four, five, six, the six items.
On the y-axis, I want the count for each. But just be very careful there. Remember what this
value count is going to do. It's going to put the most frequent one at the top, the mode at the top.
But we want it to sort by the index. And the index is one, two, three, four, five, six. So that,
you know, the first bar is the value counts for one. And the second bar is the value counts for two.
So we do put this .sortIndex method there. And then from that, we just want the values,
and we want it converted to a list. I think, you know, by now, you know what this little line of
code does. You can just tease it out as it goes along. I'm going to put a title there,
Frequency of Faces Following 10,000 Roles. And instead of x, you know, I'm changing the labels
because it's going to put x on the x-axis. I want face values. And instead of y, I want frequency.
So let's have a look at what this looks like. And you can see there,
you know, this is what we would term a uniform distribution. And we'll talk about distributions
a little bit later. But you can see all the values are almost equal number of times they landed face
up. So this is, you'll see later, this is an empirical result, the result from our actual data.
Theoretically, it should be a six, a six, a six, et cetera, because each value has one over six
chance of landing face up. So let's talk a little bit about probabilities because
it becomes very important data science as we work, as we work. And it's not easy at times,
the first time you see this. But if you sit down after the fact, after having worked through it,
then it starts making sense. So the first thing in probability theory, and we use it,
it's a branch of mathematics, a very important branch of mathematics, where we just investigate
random events. And that's all based on set theory. So, well, most of mathematics, all of mathematics,
the axiomatic system of mathematics is based on set theory. And so you can really take very long
and complex courses at university about set theory. And what we're just going to view a set as,
is a collection of objects. And, you know, we're using very poor language, our language skills,
and our communal understanding of what the definitions are in a dictionary of these terms
that we're using. But let's just use that conceptualization. Is that a word of a collection
of elements? And those can be numbers or can be many things. That's this collection. And that
is a set. And that element in a set, we would say it is a member of that set. So this is some terms
that we use. And here are terms that you've seen before, intersection and union. Remember the
intersection of two. Think of Venn diagrams. Remember those? Where they intersect. In other
words, we're looking for members that are common to two sets. So that member occurs in set number one
or set number A, set A, and it occurs in set B. And if that is a member of both, it lives in the
intersection of those two sets. If I combine those two sets together, then I have the union of those.
And remember with a union, the little bit that's the intersection of a union, those elements actually
get duplicated because they occur in both sets. That's why they're in the intersection. So we just
have to delete those duplicates. And later that's going to become important as well. But I think if
you just think it through a little bit, if there is an intersection between two sets, of course the
elements that are in the intersection are duplicated when we do the union. And we don't want
duplications in the union. So it's just the elements themselves. And then we have this concept of a
universal set. So imagine you're doing some study, you're working in the lab or working with clients,
doesn't matter what it is, and you're collecting data for a specific variable. There's a range of values
for that variable, but you're only working with ten samples. So not all the possible values that are
in that interval that are possible for that variable is going to occur in your data set. But that larger
set, we usually refer to that as the universal set. And our sample space comes from that, or sometimes is
that universal set the sample space for a variable. In any case, if not all the values occur in our little
sample that are in the universal set, the ones that didn't occur, we call that the complement. So those
are the values that are that are in the universal set, but that did not occur in our little sample. So
that would be the complement. So terms you'll come across also are terms like experiment, event, and outcome.
And sometimes they use very interchangeably, but they are, you know, slightly different things. I think if we
can start with an experiment, that's just the thing you do. That's the thing that you set up. And imagine
it is an organism in a laboratory, and you're going to take some fluorescent score from it. You know, that's
your experiment. You're actively doing something so that you can get some result out of it that you can
jot down or capture in your spreadsheet or in your database. That's your experiment, and you do that over
and over again. And then the event is that actual value that you're going to collect from that experiment.
There's a value. But then there's also an outcome of of events. And we'll see that when we talk about
this flipping our our fair coin here twice. So independent events means that if I do this twice,
the second one, the first one has no bearing on what happens to the second one. So that second one
doesn't care what happened to the first one. If you flip a coin twice, the coin doesn't care what the
previous flip was. That's every time you flip that coin, there's an independent event. But now we change
our experiment and we say, my experiment is flipping the coin twice. Each time that I flip the coin, there's an
event, but my outcome is jotting down both of the events. So I actually have four outcomes. If you think
about it, I can flip the coin head-head, head-tail, tail-head, or tail-tail. So I can certainly do that.
And my outcome is now not just the single event, but that combination of events I want. My outcome is
I'm throwing, I'm flipping the coin twice. So that event, the what I'm recording, heads or tails,
that happens twice. So each of these four events, if it's a fair coin, they have an equal likelihood
of occurring. So flipping a head-head would occur 0.25 or 25 percent of the time. Flipping a head then a
tail would occur 25 percent of the time. Tail and then head 25 percent. Tail will be 25 percent.
And now I can change my outcome. My outcome is something as a researcher that I state I want to
know what the probability is of at least one head. That becomes my outcome now. So you see this idea
of an outcome is very fluid. That is my research question. And in those cases, well, three of those
have at least one head in it. The first one has two heads in it. That is at least one head. The second one
has head-tails and the second one tail-heads. Each of them has a head in it. It's only the last one
tail-tail that has no heads in it. So if my outcome is the probability of at least one head,
that is a probability of 75 percent. I have a 75 percent probability of at least one head. And you
can see starting to develop the notation here, the P and then in parentheses at least one head.
Later on we won't use a full word. We'll just use a symbol to mean at least one head. So the probability
of at least one head is 75. Okay, we researchers, we can change our outcome. This time I'm going to flip
my coin three times. So my experiment is flipping a coin. My event is recording, you know, what came,
and my outcome is I want all three here. So I've got all these different outcomes. Head, head, head, head,
head, tail, head, tail, head, tail, head, head, head, tail, tail, head, tail, tail, head, tail, tail, tail.
So now my question can also be, what is the probability of at least one head? That's now my
outcome of interest. Of all my outcomes, this is my research question. I want to know what the
probability of at least one head is. And if we quickly look down there, we see, again, it's only
this last one. So the probability will be seven out of the eight. So if we say seven divided by eight,
of course, we're going to get 0.875. So 87.5%. That is my theoretical probability.
So let's do an experiment. So we're going to set up, it's going to run some code here. Let's have a look
at that. Let's see numpy.random.choice. And what are we going to choose from? From this array,
this numpy array with zero and one. So let's call that tail and head. And I want three of those.
And I say replace equals two. And we've got to do that because there's only two choices there.
And I can't select zero the first time, one the second time, then there's nothing left.
If the coin is flipped and it's a zero, we throw that zero back into the bag to be randomly selected
the next time. So let's do that. If I were to do that, we're going to see zero, one, zero. So that
would be tail, head, tail. And if you run it again, you're going to get something different.
So let's do this five times. And I'm going to do this with list comprehension.
So list, remember, that goes inside of a set of square brackets. So I'm going to say
numpy.random.choice in this array zero to one, three times, replace equals true,
for i in range five. So that's going to be zero, one, two, three, four. So it's going to happen five
times. So let's see at random what our coin flips were. It was tail, tail, head, head, tail,
head, tail, tail, head, head, tail, head, head, head. That's what happened. Okay, fair enough.
We understand how the code works. Let's do this many more times. But what we want to keep track of
is how many times there's at least one head. Now what we can do, of course, we can just sum over
that each of those little arrays. And if it's one or more, you know, or at least greater than zero,
that signifies there was at least one head in there. So that's what we're going to do.
So I'm going to seat the pseudo-random number generator with an integer two.
So that's the choice. I'm going to have a counter, count, and I'm setting that to zero. And then I'm going
to say for i in range 1000. So we're going to run through this for loop a thousand times. I'm going
to say flip underscore three is the sum of that little random values that I have. And then if the
flip is, this flip underscore three is larger than one, I'm going to increase my counter by one. So that
I know that at least there was one head in that specific set of three numbers. And then I'm just
printing the results out to the screen. And so let's run that and see how close we get to this idea of
87.5%. And there we go. We see a total number of experiments was a thousand. And the total number
of at least one heads, that's my counter that kept on counting every time the value was larger than zero.
So there was at least one head in there. It was 87, 877. So that gives me a probability of 0.877.
So my empirical, my results here, my actual values for my experiment is very close to the theoretical
87.5%. And that's from a thousand times rolling the dice three times. So you start getting this idea
of the theory, what it should look like. And then our experiment is not quite there,
because it really depends on the sample size, how many times we do this.
Now, one little thing I think you must always be, this is the summing you just absolutely have to
know. Probabilities range from zero to one. You can't have a probability of something happening
minus three percent of the time. That's not how it works. And you can't have the probability of
something happening 110 percent of the time. It's from zero percent to 100 percent inclusive.
Or in fraction terms, they're zero to one. 0.0 to 1.0. And if I have all these events,
and I put them together, it must add to one as well. So the probability of something occurring,
an event occurring, plus the probability of the event not occurring, must also be one. So the
probability of the event not occurring is the one minus the probability of the event occurring. Such
a simple thing there in equation one. But those two facts, you know, the probabilities must be between
zero and one, and they must sum to one. And so the probability of something not happening must be the
one minus the probability of it happening. Because that brings us to this idea of negation,
which I want just to use equation one there in a little example. So we're going to
roll our fair die again. And we're going to ask, what is the probability of rolling a six given a single
roll? Of course, that's one out of six. But then what is the probability of at least one six in two
consecutive rolls? So only one of them need to be a six. They don't both need to be a six. And then what
about the probability of there being at least one six if I rolled it three times or four times or more times?
Well, what we're going to use here is just this idea of equation number one there. And we use this
idea of the event not occurring. Instead of the event occurring, sometimes it's useful to look at
the event not occurring. So what is the probability of not a six? So that symbol you see there in equation
two, that's a mathematical notation for not a six. The probability of not a six. Well, that's going to be one minus
the probability of a six. The event not occurring is one minus the event occurring. So one minus one point
one over six, that's five six.
So that's the probability of not rolling a six.
And what we can do here is to start squaring this. So if I roll it twice,
it's one minus the probability of not a six squared. So one minus five over six squared. So that's 11
out of 36. And the probability of a six in n rolls then is one minus five over six squared.
So let's just look at the code there. So I'm going to say
computer variable six, one minus five over six to the power n for n in range one to 11. So one to ten times.
So the probability of at least one six in
a single roll is one over six. It goes up to 30 percent if you do it twice. And if you do it ten times in a row,
the probability that there will be a six, at least one six in those ten rolls, are actually 83.8 percent.
So we can do a little scatter plot of that.
And let's just have a look at that. And you can see the more rolls I have,
the higher the likelihood there's going to be at least one six. By the time we get to 40 rolls,
it's 99.9 percent that there will at least be one six in there.
So just remember, sometimes we have to use negation.
Okay, so that's all fun. And we, you know, you can play around with that, play around with some code,
see what you can come up with.
More importantly, we've got to talk about types of probability,
because we're going to work with this kind of thing. And the first one we're going to do is
unconditional probability. So actually going to talk about unconditional,
and then also we're going to talk about joint probability.
And then if we scroll down a little bit, and there we go, our conditional probability.
So let's talk about unconditional probability. I'm going to create a little scenario here where
I have two containers. And in container number one, there is some red balls, some green balls,
and blue balls. And the same goes for container number two. And we're going to look at the relative
frequency. And I'm just going to set up a little data frame here with hard coded values.
So let's have a look at this. On the left hand side, I have container number one and container number two.
And this is the relative frequency. So in container one, red balls, that makes up 26% of the total of
all, both containers and both balls. So it's relative frequency. 36% green balls, container one.
18% it's a blue ball in container one. 9%
17% it's a red ball in container two. 7% it's a green ball in container two. And only 4% it's a blue
ball in container two. So if I sum all of these up, these are relative frequencies. So relative
probabilities there, it has to sum to one. And that's exactly those six values sum to one. So no problem
there. But now I can also look at the sum totals for the different rows.
So let's do df.sum and I'm going to set axis equals one. So what that's going to do for me,
it's going to just add up all the column values for each of the two rows. That's what axis one means.
So 80% of the balls are in container one and only 20% of the balls are in container two.
But if I do it by axis equals zero, that's going to be the other way around. So now we're going to get
the relative frequency of the balls. 35% of them are red, 43 are green, and 22 are blue.
So down the margins we can write container one is 80%, container two is 20%, and if we go down the
bottom we can say red is going to be 35%, green is going to be 43%, and blue is going to be 22%.
And we can just sum up these totals because they're relative frequencies of the whole. So 0.26 and 0.09,
that's going to be 0.35. And 0.18 and 0.04, that's 0.22. So the blue balls would be 0.22. Or we can sum
along these. So this is quite common to have this sort of thing. So we, you know, we've got to spend
some time on that. So now we're going to talk about this unconditional probability. We see the
unconditional probability of a green ball is 0.43, because it doesn't matter which container it is in.
If I just look at that, it's, if it's a green ball, it's the 43% chance,
because there's 35% chance it's a red ball, and 22% chance it's a blue ball, if those balls were all
put together. It's independent of the container that it's in. Now we're going to talk about the
joint probability though. So we are interested in two outcomes here. Two things have to be. They are
joined. It's got to be a certain color ball from a certain, from a certain container. So let's have
a look at this. If it's container number one and it is green, it's the intersection of this idea of it
being green and being in one. And that's just our relative frequency there. If we go to the chart,
it's green and it's in container one. That's 0.36. That's the joint probability. So both the container
and the color. Joint probability. Both have got to be true. Is it on container one? Yes. Is it green? Yes.
They both have to be true. That's 36%. And that is our joint probability. And now comes the important
bit. Conditional probability. Now that's the probability of an outcome given that something
else has occurred. And this time that other thing that has occurred has an influence on this thing
occurring. It's not like flipping two coins. And when you flip the second time, what happened before
is of no consequence. Now there's some consequence. So this makes it infinitely more interesting to us.
So the question that we're going to ask here, what is the probability that it is from container one if
it's a green ball? So you've got the two containers and someone, you know, your eyes are closed. Someone
swaps them around, round, round. And, you know, randomly you take one ball out of it. And I'm asking,
what is the problem? And you open your eyes and it's a green ball. So you're asking yourself, what was the
probability that this came from container one versus it came from container two? Remember, if we asked
it comes from container one, that would be one minus it coming from container two. But that's
not what we're interested in here. We're interested in what is the probability that it came from
container one given that it was green? Of course that's going to matter because the relative frequencies
are all over the show. And here in equation six, we see this idea of conditional probability.
And so we say the probability of A, given that B occurred, that's equal to B and A having occurred,
divided by the probability of B. So let's just have a look at the numerator there. The probability of A
and B. A and B. Joint probability. So this is the ratio of the joint probability divided by this
unconditional probability at the bottom. So it's the probability that it's in one and green. We know
that's 0.36 divided by the probability that it's green. And the probability that it was green depends
on nothing other. There's blue balls, red balls, green balls, and that was 43 percent. So in the end,
it's going to be 0.36 divided by 0.43. As simple as that. Okay, so A, we're going to say it's,
it is a container one and B that it's green. So what is the probability of A? It's from container one,
A, it being green, given that it's green, you look at it and it's green, is B. So that's the joint
probability A and B divided by the second one, the given something has happened, the probability
of it being green. So that's 0.36 divided by 0.43. So if we run that code, you see the result there.
It's going to be 83.7 percent. The probability that that comes from container one. Now container one had
80 percent of the balls, but, you know, green was a certain likelihood as well. So given that it is green,
it has certainly raised the probability a little bit that this was actually from container number one.
Remember then the probability of being from container two would be 1 minus 83.7, you know, 100
minus 83.7 percent. So how do we know if something was a conditional probability or if the two
events were independent of each other? We can actually test for that.
And what it would do is, the probability of A given B, we've just seen the equation for that
here in equation six, how to do that. If that equals the probability of A,
and if it was probability of B given A, that that is equal to the probability of B,
you know, if those two things are equal to each other, then it was actually,
the events were independent of each other. It didn't matter what happened before, what we were given.
So we see an equation two there that, you know, writing it out twice. A given B is A and B over B,
and B given A is A and B over A. So we've done this here. Let's have a look at it. The probability of A
given B, A given B, so that's this joint probability divided by the probability of B
being 80. So probability of being in container one, given that the ball is green,
and the probability of B given A, so the probability of a green ball, given that it was from container
one. So this time, you know what container came from, what is the probability of it being green,
and then the probability of A, a green ball, probability of B being from container one. So
we're just saving all of those up as values. And I'm asking, is the probability of A given B equal
to the probability of A? No, it's not. Is the probability of B given A equal to the probability
of B? No, it's not. So I can say these two events are dependent upon each other. So that's how you would
measure if events were independent of each other. So joint probability, remember, means and. So both
have got to be true. It's got to be green and it must be from container one. But what if it's all?
So here we're talking more about the union of something. It's in, if you think of the union of
two sets, it's all. It's either in one set or it's in the other set, or it's in that intersection
between the two. That's what union means. It can be in this combination of them. It can be in one
or the other one. So what we're talking about here is the probability of it being in A or in B.
And think about a Venn diagram. Those two circles and they intersect some way.
Now that union of those two is the probability that it's in the one and the probability that's
in the other one, or plus, I mustn't say and. That might be confusing. Probability of one or the
probability of the other one. But remember what we said before, that intersection, those things get
counted twice. So we better subtract that intersection, the probability of it being in A and B.
So the probability of A or B, that's a probability of A, probability of B, sum those two up minus the
intersection, the joint probability. So the probability of it being red, we sum up over all
the reds. The probability that's two, sum up over all the twos. The probability of red given two is 0.09.
And if we just sum all of those up and subtract the intersection, we get 46%.
So that's the probability. And this time, I didn't say the colors I was interested in. This time,
it's the red one or it's in container two. So you draw it. What is the probability that it's red
or it comes from container number two? So that's when we're going to use this idea of this Venn diagram
and this union of them minus the intersection of them. And then the last one, or second last one, is
just what is the probability that our random ball is both red and in container two? You can see the
equations there, but you can see it's only, it's just simple algebra of what we have before. Because
if I divide this first little one, if I divided that by probability of B, then I have, again, probability
of A given B is the probability of A and B divided by the probability of B. So it's just a very simple
algebra from what we had before. And if you run through this code, what you're going to see,
well, that's just the relative frequency, isn't it? It must be both red and in container two.
Well, if we go back to our little table there, that's exactly what it was. That joint probability,
that's nothing other than the relative frequency. And again, we have this idea of
the complement. So if it doesn't occur, it's one minus the probability of it occurring,
given some universal set. So let's work through a very interesting example here.
And I wonder if you're going to get this one right. If we were to play some bets, I wonder what,
not that I'm a betting person at all or condone it in any way, but fun nonetheless to think about
what you're going to select as a solution. So imagine we have three cards. One is red on both sides,
one is white on one side, or white on both sides, and the other one's red on one side,
and it is white on the other side. So red, red, white, white, and red, white.
Now we're going to just shuffle them under the table, and we're going to select a card that's
chosen at random, and you get to see one side. And that one side is red. And I ask you,
what's the probability that the other side is red? So don't read any further. Just think about it.
Don't read. So red, red, white, white, red, white. And I pick one and I show you the one side. You
don't know what the other side is. And that front side that you see is red. What is the chance that
the other one is red? Well, let's just think it through with what we know about probabilities now.
So what are all the different outcomes that we could have from these cards?
It could be red, red.
So I show you red, and the other side is red. It can show you red, red again, because there are
two red sides. Think about it. I can draw the card and show you red side number one for that red,
red card. Or I could have drawn it and shown you the other side of the red, red card.
So that's two red, reds. Think about it. The red, white card, I could have picked it up and
shown you the red side front, and then the white would have been at the back. Or I could have picked
it up and shown you the white side, and the other side was red. And then the same argument for the
white, white card. I could have picked it up showing you the one side white, and the other side was
white. Or I could have picked it up and shown you the other white side, and the other side was white.
So there's actually six outcomes. So now I think about it. If I show you a red that's in the front,
that's going to be one of those first three ones. And look at what it's at the back.
There's a red at the back, red at the back, or white at the back. So the probability that the
other side was also red is two thirds. And I think many people would have said it's a half,
but it's not. It's two thirds. So that's just a little teaser there to mess with your mind.
And congratulations if you've got two thirds the first time around. So always come up with all
the possible outcomes. That's what it's all about. Come up with all the possible outcomes.
So now I want to talk to you about random variables. So a random variable is a function,
a mathematical function, and that maps the outcome of an experiment to a number.
So we're just actually in our spreadsheet capturing a number. And by number I'm using sort of a loose term.
I can code a categorical variable as a number. You know, so it doesn't matter what the variable is.
Let's just call anything that I then capture. Let's just call that a number. So very abstract
definition here. So I'm just mapping the outcome of my experiment to a number.
So imagine then that I'm rolling two die, a pair of dice, and I sum up the values that land face up.
So there are all the outcomes if you think about it. I can, you know, both can be one, and that's a two.
I can have a one and a two, that's a three. Or it can be a two and a one, and that's three.
I can roll a two and a two, that's four. A one and a three, and it's four. And a three and a one,
that's four. And for a five, I can roll a two and a three, and a three and a two, and a one and a four,
and a four and a one. So you can look, have a look at that. There's only one way to get a two.
There's no ways to get a one. I mean, one dice, you're rolling two dice. So you can't sum to one.
So the, but there's only one way to get two. And right on the other side of the spectrum,
there's only one way to get a twelve, a six and a six. But if you look at a three,
there are two ways to get a three with these two dice. One can be a one and the other one a two,
or the first one can be a two and the second one can be a one. If we look at a four, you know,
there's four ways to get, three ways to get a four. Two and two, one and three and three and one.
And there's one, two, three, four ways to get a five. And there's one, two, three, four, five ways
to get a six. And there's six ways to get a seven. And then it drops down again.
Fewer ways to get eight. Fewer ways to get nine. Fewer to get 10. Two to get 11. One to get 12.
So it's most common to get a seven. So there's this pattern to this random variable of us.
So I write it down. So what we would say our random variable is x. So it gets a bit confusing.
That x is just going to be our column header. That becomes our variable. And the values that we jot down,
those are random variables. So it gets slightly confusing. So I try to stick to the fact that we
call that column header in our spreadsheet. That's our, that's our variable name. And we have data
point values for that. But each one of those values, technically, that is a random variable,
because it maps an outcome to a number. So the probability that x is two, that our random variable
x equals two, that's one over 36, because there's 36 of these, one, two, three, four, five, six,
36 possible outcomes. So two, there's only one way to get a two. For three, there's two ways to get a
three. And up to the seven, there's six ways to get a seven. And then it drops down to one way to get a
12, all the way in the end. So you can just run that little list comprehension there. And we can see
the probability. So the highest probability was a seven at 16.67%. So let's just plot that as a little
bar plot, because remember, these are discrete variables. And you can see this nice, nice distribution.
So for a seven there, that was the highest probability of occurring. It occurred most of
the time. And now we can start thinking about probability in a new way. We can think about it
graphically. Because I can ask, my outcome could be, what was the probability of my random variable
being 10 or more? So this is how we're going to write it. Probability, my random variable x being
greater than or equal to 10. While I just sum up these, the one for 10, 0.0833 plus 0.0556 plus 0.0277. I can
add the area of these rectangles. I want you to start thinking about that. So I can say 0.083,
0.055, 0.028. So I'm just rounding off there a little bit. So I can now start saying that the
probability of my outcome and my outcome of interest is a 10 or more. If I roll two die,
what is the probability that the score is going to be 10 or more for the summing up those two face
values? Well, it's 16.6, 16.6%. So just start thinking about that. So I want to start thinking
about this idea again of a theoretical distribution and an empirical distribution. So certainly this was
theoretical. We worked this out by pure numbers. So let's roll some actual die or at least we're going
to simulate them. And this is going to give us an empirical distribution versus our theoretical
distribution that we saw there. So I'm going to reset the random seed, the pseudorandom number
generator. I'm going to seed that with an integer of three. I'm going to say roll underscore totals
and I'm going to create a data frame object and I'm going to have one column. So I'm setting this
up as a Python dictionary with a key value pair. My key is going to be the column header. That's roll
total. And I'm going to do list comprehension 10,000 times. I'm going to draw from this
random.randint. And randint is almost like choice. I'm just giving it a lowest value and a highest
value. Low of one, high of seven. Remember this is Python. The upper one is not going to be included.
So it's actually going to be one, two, three, four, five, six that it chooses from. So that's just a
different way of doing this random choice thing using randint, random integer between a whole number
in other words, between one and seven. But seven is not included. So it's one, two, three, four, five,
six. Choose two of them and then I'm passing that to the sum function. So I'm summing those two.
So I'm just simulating here rolling two dice and I want that to be converted to a list. And I do that
for in range 10,000. So I'm doing that 10,000 times. And let's look at those sum totals then. So
the first time I rolled a four, then a six, then a two, then a seven, then a 10. So you get the idea.
So let's do value counts to see, you know, how close we got to this. And lo and behold,
seven was most likely at almost 17%. So, you know, not too bad. But let's just sort it by this index
rather than the mode, the most common first. So I'm going to use the dot sort index method for this. And
now it's going to sort by the index. So it's going to go two, three, four, five to 12.
So you can see this idea 1699 of my, of my, uh, $10,000 that was a seven. And it was very unlikely
to roll a two or 12. So let's just create a bar chart of that. So this is going to be my empirical
distribution. And it looks very much like my theoretical distribution. So there's my empirical
distribution of values. And again, I can ask what was the probability of there being a 10 or 11 or 12.
So I'm just going to sum up. There was 854 of those, 559 of those, 299 of those, sum those up,
divided by 10,000. That's the probability of a 10 or more in my empirical experiment that I set up here.
Good. So let's talk about distributions then. It's this pattern that we get from our data. How many times
occurred their frequency or then their relative frequency? So imagine now I'm going to do the
following thing. I'm going to set up, uh, this normal distribution. So without us, me explaining
explicitly what a normal distribution is, I think you've got quite a fair understanding of it already.
Most people have that intuitively, this bell-shaped curve. So near the middle, near the mean or the
average, it's more likely to have values there. And as they go away with a symmetric bell-shaped curve
towards the smaller side and the bigger side, those values get less. So there's an idea of a mean and
a standard deviation. So we have this norm.rvs function in the stats module of SciPy. So stats.norm.rvs,
it's going to work very much like the numpy.random. It's actually just slightly more powerful. There's
a few more things you can do, but it's really nothing other than numpy.random dot one of the
random, uh, functions that you do get. But here you get stats.norm.rvs.
And I can set the LOC location. That's a keyword for mean. So I'm setting a mean of 160. Scale is the
keyword for standard deviation. So standard deviation of 10. I want 200 values, please.
And I'm setting a random underscore state. That's the same as setting numpy dot random dot seed.
Here we have an argument in the rvs function, a random seed. And I'm going to assign that to the
computer variable height. So what I'm imagining here is 200 people, and the mean of their heights
is 160. Their standard deviation is 10. Just from that distribution, please draw me 200 random values.
And there we have it. So let's draw a histogram. Now height is now a continuous numerical variable,
so we're not interested, we're not interested in a bar chart anymore. We now want a histogram. So there's
our histogram. And you can see now Plotly decided that it's going to do these steps of five centimeter
increases, 150 to 154.99. And the count of this was made up 0.135 of all the values. So let's go to
the top there. Between 160 and 165 point, or then 164.999, it made up 22 percent of the total.
So this is a nice little histogram. So the reason why that happened is because I said hist norm equals
probability. So we don't get the actual values, we get this relative frequency. So I just want to show
you this little other plot. I don't think it's going to be around that much longer, this figure factory.
They are changing. Plotly are changing it. But we create the create underscore dist plot. That's
going to do exactly the same thing. We're going to hit the histogram. But I've also done this nice
little curve. It's kernel density estimate. So it gives us this nice little bell-shaped curve instead
of this blockiness, of course, of our histogram. But it's trying to tell us the same thing other than the
fact, remember that this is an artificial binning of our values. They're actually a continuous numerical
variable. So in the end, this is really what we want to deal with is the smooth curve. And we're
going to see a lot of these smooth curves, and you're going to understand exactly what that means.
What we're trying to get to here is this, what I said right in the beginning, there's this empirical
distribution and the theoretical distribution. And there's this law of averages. And this law of
averages, that really states that our theoretical, or our empirical distribution,
that is going to start approximating our theoretical distribution. So our empirical distribution is
going to start to approximate or get close to the theoretical distribution if our sample size gets
bigger and bigger and bigger. And that's something I think most of us in research also, you know,
have heard a million times. And we sort of understand that the larger our sample size, the closer we are
going to get to what the actual values are. So this idea of the law of averages. So let's look at this at
play a little bit. So what we're going to do here is something very interesting here at the end. I'm going
to simulate a population of 10,000 subjects. So I'm going to imagine in a lab or working with some
economic data or some human data, it doesn't matter what it is, some astronomical data, really doesn't
matter. I have 10,000 subjects. And I'm going to measure this random variable in them. So this is
going to be this variable. And we know what it is in each and every. Just imagine, we know what the
value is in each and every one of those 10,000 subjects. And we're going to make as if it comes
from what we call a chi-squared distribution with degrees of freedom of three. Don't worry about that
at all. So let's just set that up. And that's my population. So in my population, there's a certain
variable. And we measure them. And we know what it is in all 10,000. Hardly ever do we know this in
real life. But this is a computer. We can simulate these things. So random dot c dot 42. And then
I'm going to use the round function and just round to one decimal place just to make things easy. But
I'm using numpy dot random dot chi-square. And there's its parameter three, three degrees of freedom.
And I want 10,000 of those. So I said, don't worry what it, you know, what, what it means. That's not
important. But I want to show you what it looks like. So here's a histogram of this variable for all
10,000. You can see what a chi-square distribution is. It goes up till here about, you know, maximum here,
and then sort of has a long tail on the right hand side. So we know this. We know what this is for
the actual whole population. But now as researchers, we can't, you know, get 10,000 subjects in our study.
We only select at random 30 of those individuals. So 30 subjects from our whole population of stars or
whatever it is. We only take 30 of them. And let's look at a histogram of our 30.
And sort of, oh, I can imagine it forms a chi-square distribution to some extent. But from a sample
of 30, you know, we're not quite sure. But what we're going to do now is we're going to increase
that sample size. And of that population, I'm increasing the size of my study. And I select 100
samples. So let's do that. 100 samples. And now I can, it looks almost, well, like some other distributions,
but sort of suppose we can start seeing chi-square. So let's ramp it up to 10,000.
And now we see the chi-square distribution starting to come out. So my empirical distribution is starting
to resemble my theoretical distribution. Now it wasn't really theoretical because my sample,
my whole population was also actually only a sample from something that was theoretical.
But I think you get the point. The larger the sample size, the more it's going to approximate
the population from which those values were taken. And now for something really interesting. And this
is really going to be one of the most important topics in data science. We're going to talk about
sampling distributions. So let's stick to our population that we had. And we're going to take
30 samples from our whole population of 10,000 subjects. And what we're going to do is we're going
to calculate the mean of our tiny little sample. So have a look at this. We went out, we planned our
research, we took it to an ethics committee if that's what you have to do, or no, we submitted it
somewhere for approval. And we got a grant to do it. And we're going off now. And all we could do,
because it's very expensive, either in time or human resources or finances, we can only take 30
from that. And we take our 30 samples from this population of 10,000. We, you know, we have this idea
of mapping our event to some value that we can do, our random variables. In other words, we collect
this value for this variable and this 30 sample size of ours. And we get a mean of 3.183, 3.183.
And that's what we're going to report on. That's what we have. But, you know, is this representative
of the actual population? Well, presumably we took this at random. There was no bias in how we selected
that. But, you know, we're not quite sure. And we need to, you know, we need to do some statistical
analysis, perhaps on this, you know, express, you know, how certain we are that 3.18 is actually the
mean of our population. Now, I want you to imagine you have infinite riches. So you don't only do your
study once, but you do it 50 times over. Every week, someone gave you lots of time, lots of resources,
lots of money, and you do your experiment again, and the next week again, and the next week again.
And every time you take 50 or 30, a sample of 30, you know, at random, some of them might,
might be the same ones, some might be different ones. But you're doing this 50 times over every
time selecting 30. And every time you select your 30, you calculate the mean of your 30. Now you're going
to have a bunch of means. You're actually going to have a distribution of means. And that's what we
call a sampling distribution. The sampling distribution is this pattern of a statistic.
Remember, a statistic is something we calculate when we did a summary statistics or descriptive
statistics. A statistic is a value from a sample, a value from a population. So the mean of a population,
that's a parameter, but a sum calculation, point estimate, or measure of dispersion from a sample,
let's call a statistic. So if you had a bunch of statistics that they form a distribution,
and that's exactly what we're going to imagine we have the power to do here. So I'm going to create
this computer variable, mean underscore 50. You can use list comprehension there. Let's see what it is.
It's going to calculate the mean of a random choice of 30 from my population,
and it's going to do that 50 times. So for iron range, 50. So what I'm going to have now is I can
imagine, as I said, all the riches in the world, and I can do my experiment, my research 50 times over.
And let's see, remember when I did it once, my mean was 3.183. Now every time it's going to be
slightly different because I'm going to have different members from the population in this. So let's
have a look at what the histogram looks like now. So if I do this 50 times over, now that looks a bit
strange because this distribution does not look like a chi-square distribution anymore. The empirical
distribution of the actual value. Those are, those are distributions, empirical distributions of the
actual value. This is a sampling distribution of a statistic, not of the actual values. So let's ramp that
up. And now I'm really rich and I've got oodles of time and resources. I'm going to do this a thousand
times over. So I'm going to imagine that I can do my, my exact same research a thousand times over
every time I choose 30. And have a look at what happens here. This is starting to look like a normal
distribution. A sampling distribution of the means, so the sampling distribution of a statistic, and
you can do it for standard deviation, for variance, whatever you like. There's going to be a pattern
to that as well. And that eventually is going to allow us to do some data science, to understand the
story that's hidden in our data. Our result, because we can only do our research once, is going to be one
of many possible outcomes. And that is going to tell us if our outcome that we found was a rare event,
or it was a very common event. And that is what we're building towards.
