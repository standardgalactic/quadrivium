In this lecture I want to look at sensitivity and specificity,
predictive values that would be positive and negative predictive values, and odds ratios.
As a matter of introduction, let's consider the following clinical research scenario.
Imagine we have N number of patients,
and we know by some definitive test that some of them have a disease and some don't.
So those with the disease we'll call X, and those without the disease we will do Y.
As an example we might have taken a biopsy,
and under histological examination we know who has the disease and who does not.
Now we want to perform a certain test on them,
and we want to look at the sensitivity, specificity, and predictive values of this test.
So can we use this test to identify the patients that have and do not have the disease?
So we have two columns here, those with the disease and those without.
We'll call those with the disease X, my first column, Y, the second column without the disease.
And those with the disease, if we test them and they test positive,
that would be a true positive, we'll call that A number of them.
If it tests negative, that would be a false negative,
because they really do have the disease and the test is now negative,
we'll call that number B.
Same for those without the disease, if they test positive, that will be a false positive,
and if they test negative, they'll be a true negative.
And we'll call the number of patients in those groups C and D.
So let's look at sensitivity. What's the definition?
It's the probability that a test result will be positive when the disease is present.
So first of all, we have the disease, it is there, we do a test and the test comes back positive.
So what is the probability that we will have that positive test in a patient with a disease?
That's a true positive rate.
So all we're going to do is A divided by A plus B.
What is that?
That's the true positive divided by X, everyone with a disease, A plus B.
And we multiply it by 100% because in most journals we express this as a percentage.
Let's look at specificity.
That's the probability that a test result will be negative when the disease is not present.
So the disease is absent, we do a test, what is the probability that that test will be negative?
That is specificity or the true negative rate.
So I'm going to take the true negatives, D, and I'm going to divide it by the total number of people without the disease.
That's Y, so it's C plus D.
Now we flip things around.
Positive predictive value.
The probability that the disease is present when the test result is positive.
So I get back a positive test result.
What is the probability that the patient will actually have the disease?
So now I'm only dealing with positives.
So I'm going to take A, the true positives, and I'm going to divide it by the sum total of all the positives.
True positives and false positives, A plus C.
Let's look at the negative predictive value.
What's the probability that the disease is not present when the test result is negative?
So I'm going to take the true negative and I'm going to divide it by the sum total of all the negatives.
True negative and false negative.
Times 100% again.
So let's look at an example problem just to cement our understanding.
Busy slide, but let's go through it.
So imagine you have 1000 patients.
We do some definitive tests on them and we know 100 of them have the disease.
That would be my X.
And 900 don't have the disease.
That's Y.
So now I have a new test that I want to do some research on.
I apply that to the patients with the disease and to those without.
So in those with the disease, 95 test positive.
There will be two positives.
My A, 5 will test negative.
That's my false negative.
That was B.
So those without the disease, 900 or Y, 90 test positive.
That will be false positive then.
My C and 810 will test negative.
That's a true negative.
That will be my D.
So let's look at sensitivity.
So I took the 95, the true positives, and I divide it by the sum total of those with
the disease.
That gives me a sensitivity of 95%.
Specificity.
I take everyone that tested truly negative, 810, divided by everyone without the disease.
So that's 900.
The 90 plus the 810.
Multiply by 100%.
That gives me a specificity of 90%.
Positive predictive value.
Positive predictive value.
So now the test comes back positive.
So I'm going to take the true positive and divide it by the sum total of true positive
and false positive.
90 plus 95.
So positive predictive value.
If the test comes back positive, there's only a positive predictive value of 51.4% of
actually having the disease.
So not good values there.
Negative predictive value.
So if the test comes back negative, so I'm taking the true negative and divide it by
the sum total of the true and false negatives.
And that's 99.4%.
So that's a very good negative predictive value.
If this test does come back negative 99.4% chance that the patient actually does not have
the disease.
Lastly, just a quick look at odds ratios.
I'm not going to do an example.
Just the equation there.
So it's the ratio of the likelihood of the outcome in two groups.
I've got two groups.
They're dissimilar in one aspect.
Perhaps do some intervention on both groups.
And there's going to be a positive or negative outcome due to my intervention.
So consider these two groups.
So you'll number all the cases with the positive outcome in the first group and the positive
outcome in the second group.
And then you'll do the same for the negative outcomes in the first group and the negative
outcomes in the second group.
If you call those numbers of patients A, B, C, and D, and you simply take A divided by
C multiplied by D divided by B, you are going to get the odds ratio.
For more videos, visit my YouTube site there, youtube.com forward slash jhclopper.
My website, jeanclopper.com, or follow me on Twitter at doc, J-U-A-N-K.
Thank you.
Thank you.
Thank you.
Thank you.
