In this video, the Gram-Schmidt orthogonalization of polynomials. I'm Dr. Jean Klopper. I'm with
the School for Data Science and Computational Thinking at Stellenbosch University. So I'm going
to talk about how to orthogonalize a set of basis vectors, but those vectors are not vectors. In the
usual sense, they are polynomials. We all know famous polynomials, x squared, and we're going
to look at how to work with that. So I'm going to do this video cast in the Wolfram language.
So if you have access to a Wolfram language product, feel free to use that. If you don't,
of course, you can always go and search for the Wolfram Programming Lab on the internet,
sign up for a free account, and you can code along right in your browser. Of course, I think when it
comes to computer language software, although I would always punt the open source products,
I think value for money is also a very important factor in life. And I think it doesn't come
much more, a much better example of value for money than the Wolfram language. Really for the
money that will buy you a couple of cups of coffee a month, you can get access to a very powerful
computer programming language. So I've chosen for this videocast, at least the Wolfram language.
Let's have a look. So introduction, we're going to look at a set of polynomials of degree n.
Remember n is then a positive integer. If it's 2, it'll go up to x squared. So any polynomial
up to the power x squared, something like x squared plus 2x plus 3. That will be within
that set of polynomials. And from that, we have this idea of a vector space. And we're going to denote
the vector space p, uppercase p of n. And it's a vector space under the binary operations of
polynomial addition, and then scalar polynomial multiplication. So I'm going to assume that you
have some idea of what a vector space is, and also what an inner product is, although I'm going to show
you exactly what the inner product is defined on a set of polynomials. Now we're going to consider
this basis that we see in equation number one. And that is the set of polynomials to the nth
degree. So 1x, x squared, x cubed, x to the power 4, all the way to x to the power n. That's my set of
polynomials. And that clearly is a basis for a polynomial vector space to the nth degree. In
other words, a linear combination of that set of vectors that we can see here in 1, that will give me
any polynomial up to degree n. So we have to look at our inner product that we're going to define. And
remember, we're going to take two examples, two vectors in this vector space, p and q. They're both
polynomials then, of at most degree n. And we denote the inner product, as you can see right there,
with these nice little brackets, p and q. And that is how we define this inner space,
inner product space between these two polynomials. It is the definite integral on this interval negative
one to one of p times q. So just a product of the two polynomials with respect to the variable. Now
these variables, these equations, these polynomials, of course, only have a single variable. And we're
going to use x, such as x squared, x cubed, etc. So you just multiply the two polynomials with each other.
And then you integrate that over the interval negative one to one. That is how we define the
inner product in this instance that we're talking about now. What we also have to talk about is the
norm, or the length, or the magnitude of a polynomial. Now there are correct terms to use,
but let's just say norm, of a polynomial. And such that if we take any polynomial p in this nth degree
polynomials of ours, the norm squared is just the inner product of the polynomial with itself.
So if we look at two again, that's just going to be p times p, the product of the polynomial with itself.
And if we take that definite integral on that interval of negative one to one, that's going to
define the norm squared. Of course, we take the square root of that, then we'll get the norm.
And then very importantly, when we talk about Gram-Schmidt, the Gram-Schmidt process, if you
don't exactly know what it is, if you want a refresher, there's also some links down below
where I use Python and where I use Julia, just to go through the steps of the Gram-Schmidt process
to orthogonalize a set of column vectors in a matrix. And this is what it's all about, equation four.
You've got to know this one. Now I'm putting Us and As in there. You read different textbooks,
you're going to see different notation. So if you scroll down just a little bit to five here,
I've got my set of vectors, basis vectors, for this fourth degree polynomial vector space.
And I've just labeled them vector a sub one, vector a sub two, vector a sub three, all the way to
vector a sub five. So they're bold there, they're vectors, but as I said, we use the term vectors
because this is a vector space, but they are polynomials. And u, or the u sub one, u sub two,
all the way to u sub five, that is going to be the five, my five polynomials, that will now be an
orthogonal basis. So I'm going to change the basis from the one that we have here,
one, x, x squared, x to the power three, and x to the power four, we're going to change that basis,
such that all five of our polynomials are going to be orthogonal to each other. And each one of those
is going to be u sub n. So we'll have u sub one, u sub two, all the way to u sub five. And how you work
that out, of course, u sub one is very easy, we're just going to take one of these to be
our first vector, and then we'll get polynomials that are orthogonal to that one, and then what next
one orthogonal to both of the previous ones. And that's how we build it up with the Gram-Schmidt
process. But equation four is a very nice, succinct way of looking at it. So if I want u sub four,
for instance, that's u, the n is four, that'll be a sub four, so you'll just go look what a sub four is,
and then minus, and then the summation. And the summation really goes from one,
so the very first one you're working with, till the one just before the one you're working on. So
it only goes to n minus one, remember that. And then it is the inner product of the two vectors,
as we define there with our, with our definite integral, of a n, the n that you're working on,
in this instance, if we're looking at u four, that will be a four. And then we're going to go from
i sub one, i sub two, i sub three, all the way to i sub n minus one. And then the norm,
we've seen how to do the norm, squared, so this is very easy, and then multiply by
that specific one you're working with, ui, then u1, u2, u3. Okay, that's not the best explanation.
The best explanation comes from an example, and that's exactly what we're going to run here.
So first here in the Wolfram language, I'm creating two functions. And this is how you
create a function. I'm giving mine a name p and q, and it's going to take two parameters.
Other languages might call them arguments. Remember with the Wolfram language, we always use square
brackets and not parentheses. And I put a little underscore after each just to show that this is a
parameter, an argument, something that I'm going to pass to the function, actual values,
and this function will now return something for me. So I've got two there, that's separated by a comma,
and then colon equals, the colon there means don't execute this now, I'm just defining a function here.
And what I'm doing is, let's set that equal to x to the power n. So I'm assigning
some, returning some value to this function I'm creating. So if I put in x and three, it's going to
return x cubed for me, if I put in x comma four, it's going to return x to the power of four.
So I'm just doing two of them, you needn't do two of them, but just to keep the clarity of there being
two polynomials in my inner product. So below, if we, if we just run this,
that's going to create those two functions. So if I want a three, and remember a sub three here was
x squared, as you can see there. So I'll just pass in p, and then x is the variable that I want,
and two is the power that I want, and it's going to return for me x squared. So it's just an easy
way to do this. And then I'm going to define a function called inner product. As per usual,
with the Wolfram language, we always start the first word with a lowercase, and each subsequent
word, we just concatenate, and the first, first letter will be in uppercase. So it's easy to read,
if someone else reads this code, they know I tried to generate a function that calculates the inner
product. So it's nice just to, to use a descriptive name, and that's of your choice.
And it's going to take two things, p and q. Again, the delayed execution there, which just means this
is an assignment. This is what's going to be returned to this function. And I'm using the
different integral and going from negative one to one. Now you see this beautiful notation that we have
here, that is part of the Wolfram desktop that I'm running here. It has a palette that has all these
lovely buttons that you can click on. And it generates this nice looking values for you. And
of course, remember, if you look online, there is definitely still the integrate function, you can
just type in integrate. And you'll see the integrate function there. So you can still do it by hand.
So you look up that function in the help section. But if you have access to a desktop version, you can
just use this kind of notation. So I'm just saying take p and take q and multiply that. And there's a
space between the p and q. And that is shorthand in the Wolfram language for multiplication. So I don't
have to put a star there, I can just put a space. And then with respect to x on that interval negative
one to one. So there we go. So I'm just going to show you here, I'm going to take now the inner product
of x squared and x cubed. So I'm passing my p and my q. Remember, p takes two arguments or two
parameters, the x and the power, and q takes two the x and the power. So what I'm just doing here
is this definite integral of x squared times x to the power three, in other words, x to the power five,
with respect to x on that interval. Now, that's going to be an odd function. And this is important
to remember, because it's going to save you a lot of time and effort if you do this by hand.
And if you have an odd function like this, and your interval is symmetric around zero,
so we're going from negative one to one, it's always going to evaluate to zero, isn't it?
And there we go. So I'm using inner product passing x squared and x cubed there. And we see
the inner product indeed is zero. So if we just look at a plot of that. So it's a plot of x squared.
And again, I can put that little square up there, just some keyboard shortcuts or clicking on just
the easy little button in the math help palette that you have access to in the desktop version.
And then there's a little space in between, just to denote that that's multiplication.
And then I'm saying go for an x from negative one to one. And the filling is towards the axis.
And you can clearly see why this results in a zero integral, because I have positive area at the top,
negative area at the bottom, it's symmetric, because this is an odd function, it's going to yield zero.
So let's get started. As I mentioned with Gram-Schmidt process, we're always going to
assign one of our vectors to be the first vector that we deal with. And it's easy in this instance,
we're going to make u1, u sub one, we're going to set that equal to a sub one. And remember, a sub one is
this one. So my first new basis vector is this going to be the first one in the original list.
Next, I have to create one, I have to generate one that is orthogonal to this first polynomial. And
there, I'm going to use my equation. And that is the summation we notation we had in equation four,
I'm just expanding that. So for u sub two, that is going to be a sub two minus. And then remember,
we're going from i equals one to i equals n minus one, and n is two at this instance,
so I can only go to one. So there's only going to be one, one expression here in the expansion of my
summation. So that's going to be a sub two comma u sub one, that's the inner product between
those two polynomials, over the norm squared of u sub one, and we already know what u sub one is,
it's there, it's one, we've already decided that, and multiplied by u sub one. So if I just substitute
a sub two was x, and then a sub two is x, again, it's there, u sub one was one. So I'm taking the inner
product of these two polynomials, x and one, I'm dividing it by the norm squared of the polynomial one,
and I'm multiplying it by one. So let's have a quick look at that. Remember, if we just look at,
if we just look at one times x, and the product of the two polynomials p and q,
I'm going to get y equals x. And again, that's symmetric above and below the x axis. So of course,
it's going to yield zero. So to get one remembers x to the power zero. So that's going to be my q there.
My p is x to the power one. And if we take the inner product of that, it's going to be zero.
So all of this is just x minus zero there. So u two is just going to be x. Well, so far, it's exactly
the same as our original basis. But what we've learned from that is the polynomial one, and the
polynomial x are orthogonal to each other. Let's go for u three. Now u three has got to be orthogonal
to u one and u two. Remember that. So we're going to do our summation expansion. So this time, we're
going to have two of these, we add them, but remember, there's a negative sign in the front of that
summation. So it's minus and minus. And so we're starting at i equals one. So u one, u one, but we're
busy with u three. So it'll be a three there and the a three there and the a three there. But now we're
just cycling over our summation counter. So it's u equal, i equals one, i equals two, we're only going
to go to i equals two, because we're working with n equals three, and we only go to n minus one in the
summation. So I think you can clearly see where nine comes from. And when I substitute these, remember,
a three, the inner product of a three and u one would be a three is x squared, and u one we know
is one. And there's u two, we know that it's x. So I'm taking the norm of x. So let's just do these.
If I look at the inner product of x squared and one, that's what we have there, the inner product
of x squared and one, there we go, x squared and one. If we do that, we see it's two thirds.
And what about the norm of the polynomial one? So that's x to the power zero. Well, remember,
the norm squared is just going to be p times p. And I'm doing that integral over my interval.
So I'm using p x zero, q x zero, I could just have said p and p there, should be more proper.
Because this is p times p, that's how we that's how we define the norm. And I'm taking the inner
product of that, and we see the inner product of that is two. And next, we need this inner product
here, x squared and x, there we go, x squared and x, if we get that, of course, it's going to be zero,
because x squared times x is x cubed, which is an odd function. And it's the interval is symmetric,
negative one to one, of course, it's going to be zero. We wish. And that's why I mean,
if you do this by hand, just look at it before you evaluate an integral, because you can clearly
see just by looking at it that it's going to be zero. So if we substitute what we've done up till now,
we get u3 here in equation 10. u sub 3 is x squared minus a third. Let's, you know,
ramp it up a bit. u sub 4, which is now going to be orthogonal to u sub 3 and u sub 2 and u sub 1,
they're all mutually orthogonal. So again, I've expanded my summation notation there. And you can
clearly see that it follows that pattern. And I've substituted it there in the second line of equation 11
here. So it's going to be x cubed is a 4, a sub 4 is x cubed. And then I have the x cubed in the front
there. And then I cycle over u sub 1, u sub 2, and u sub 3. And u sub 3, remember, we multiply by that
vector as well. So I've got to put that in for u sub 3, that one in for u sub 2, that one in for u sub 1.
So if we just do this, remember, what do you think is going to happen to the last term?
I have an x cubed times an x squared, that's x to the power of 5. Anyway, let's just do this one,
x cubed, I'm going to show you x cubed, and then x squared minus a third. If I do that in a product,
I get zero. And once again, just to show you very quickly the plot, why this would evaluate to zero,
you can clearly see that it does not function. So here, what I've done is I've just done all my
inner products. And we can see the inner product of x cubed and x1 is 2 fifths on my interval,
the inner product of 1 and 1, that's just 2, we've seen that one before, of x cubed and x,
that's going to be 2 fifths, and of x squared, x to the power 1, sorry, and x to the power 1,
that's 2 thirds. And if I substitute, this is what I end up with. So do that substitution,
you'll see we get to x to the power 3 minus 3 fifths x. So that's my fourth polynomial,
and it's now orthogonal to all the others. And then eventually here, we go to 5, the fifth
orthogonal polynomial. And again, it's just that simple expansion. Have a look, pause the video,
and have a look at it. And if we expand it, all the ones that we're interested in, of course,
we're going to get the zero there. Remember, x to the power 4 times x to the power 1, that's x to the
power 5. Odd function, symmetric interval, definite integral is zero. And there is the one of x to the
power 4, and then x squared minus a third. And also x squared minus a third, and x squared minus a third,
so that's going to be the norm of that one. And then our last inner product there, of course,
again, that's going to be an odd function, that's zero. So in 14 here, I show you how we just simplify
this, and we end up with our last orthogonal basis vector for this vector space up to polynomials with
degree four. So let's just visualize what happened here. Because what I've done here,
is put all my my new basis there, my new five basis vectors, and they are mutually orthogonal.
So if we plot them just to see what that would look like, this is what they look like. And it just
plot that original basis as well. And you can see the difference. And if you think about just normal
vectors, say in two space, why are orthogonal vectors better? And you can clearly look at them
as a basis versus two vectors that are very close to each other. And it all comes down to the application
of what we're dealing with here. If you think about vectors in two space, if you if you want to span that
space, you need two vectors, as long as they're not linearly dependent, but they can be very close to
each other. But what we're doing here is in applications, we're trying to add some values
to these things. And if we take any kind of measurement, any kind of value, there's some
uncertainty in that measurement. And if you have two vectors very close to each other, that becomes
unstable, because just with a little bit of measurement in the wrong direction, then you're going to land
exactly on one of the basis vectors. Whereas if they are mutually orthogonal, there's no ways that,
you know, in that close measurement error, you're going to land up with with problems. And the same
here. So we can see when x equals one, of course, they land up in the same spot. But they're all very
close to each other. If we look at them here on the right, right hand side on the positive x axis.
And if you look at all of these on the new orthogonal basis, it's not a problem at all.
Which just brings me to a neat little subject that I just want to just make you aware of,
and that's the Legendre polynomials. And they are orthogonal, just as the ones we've had before,
through the Gram-Schmidt process. But they just each multiply by a constant. Remember,
that does not change the fact that they are still all mutually orthogonal to each other,
I'm just multiplying each one by a scalar. And the scalar that they multiplied with,
the five that we've got up here, is five. I'm just multiplying each of them by a scalar. And the
way that I'm doing it is such that p of one equals one. So for all of them, p of one equals one. And
you can see all of them there, very close to the ones that we have up here. Just change by a,
by a, exactly by a constant, a scalar, so that p of one equals one. And they usually denote it uppercase
l sub zero, sub one, and to whatever degree you need to go. And there's a neat function in the
Warframe language called Legendre p. And I give it the order that I'm looking for, and the variable that
that I'm interested in, and it'll just generate that for you. And you see, it's exactly what we have
there. 35x to the power 4 minus 3x squared, plus 3, all of that times an eighth. And there's a,
it's very useful, these Legendre polynomials, so you can start reading up about those. So I hope that
clears it up for you, how to take, you know, how to change the basis of a, of the basis of a, of a
polynomial vector space. I have to change that basis so that my new basis vectors are all mutually
orthogonal.
