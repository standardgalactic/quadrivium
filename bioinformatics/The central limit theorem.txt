The Central Limit Theorem
The Central Limit Theorem
Now, it's a very important theorem.
It is what all our statistical analysis,
at least our inferential statistical analysis is,
are built around.
Don't have to have a deep understanding of it,
just appreciate it.
Sit back, watch, it's quite exciting stuff.
As per usual, I'm just setting up my CSS style sheet.
The environment that I want to run,
I'm going to import numerical python again,
as np numpy.
From math, the math library there,
I'm going to import factorial,
that's the one extra computer code word I want to use.
As again, matplotlib, seaborne, you know them now,
from warnings, filter warnings,
and I'm going to do my matplotlib inline,
and my filter warnings ignore.
This is something new though, set,
SNS dot set style.
Now, this is what SNS is all about.
To some extent, you can do it with matplotlib as well,
but you can actually import various styles.
So, if you google seaborne,
have a look at it,
of setting the style here,
and setting the context,
changing the font scale,
and the default fig sizes,
you can do a lot of things,
just by setting some defaults initially.
You can also set the defaults as you do SNS,
as arguments.
I'm not going to go,
there's not a course on how to do seaborne.
Google it, play around with seaborne,
you can draw some fantastic plots.
So, the central limit theorem,
what is it all about?
Now, you'll remember from the previous lecture,
just looking at probability and area,
I said that this curve is always normally distributed,
but you're going to gather some data,
you draw a plot of the data,
and you say,
well, it's very skew,
my data is very skew,
and comparing the two groups,
some variable between the two groups,
it's very skewed.
What is happening here?
You know,
how can I now draw this nice,
beautiful graph that is symmetrical
and bell-shaped,
and get area from it,
because this thing is skew.
How is this going to work?
Well,
the central limit theorem to the rescue.
Very simply stated,
think about this.
Take a very large population,
how many people on the face of this planet?
In excess of 6 billion,
so large,
wherever you live,
there's a large population.
Let each member of that population
have a known random variable for,
a random value for a certain variable.
Let's take age.
everyone is a certain number of months or years old,
and it's completely random.
You can have a random value for age.
Now, if I repetitively take a random sample from that population,
okay,
so there's 6 billion people,
and I selected,
well, let's make that much smaller.
Say there's only 20,000 people in the little town that you live in.
It doesn't matter.
Let's take a sample of 30 patients.
At random,
I pick 30 people.
And I say,
what's your age?
What's your age?
What's your age?
And I take the mean of that age,
that age group of that 30,
and I put that in my pocket.
The mean age of my first 30,
out of the 20,000 people in my little village,
I've got that mean of those 30 people in my pocket.
I now chase them out the doors,
and I randomly pick 30 people again,
which might include some of the ones I've had before.
It might not.
There's 20,000 people there,
and I'm just taking 30.
And I say,
well, 30,
what's your age?
What's your age?
And I calculate the mean of that little group,
and I've got another mean in my pocket.
It's like rolling the die.
Every time I roll the die,
I add the two up.
I've got a value,
and that's a value in my pocket.
And I keep on doing that,
and I keep on doing this,
and I do this for a long time.
Take 30 people,
get the ages,
calculate the average,
put that average in my pocket.
If I were now to do a histogram
of all those sample means,
the central limit theorem guarantees
that a histogram of all those means are calculated
will be normally distributed.
Even if the initial data set,
the ages of all those 20,000 people,
are not normally distributed at all,
a histogram of the sample means
will be normally distributed.
Now think of that.
Any trial you do,
you've got some people in one group,
some people in another group.
I'm going to say people all the time,
but it can be anything else.
You've got one lot of subjects in one,
and subjects in another.
It can be test tube results,
it doesn't matter.
And you compare the difference in means
between the two.
That difference in mean is but one
of many possible differences in means
you could have done
if you repetitively ran your trial.
So yours is just one of countless others.
And if I could do all those countless others,
I would see that the means
or then the differences in means
or whatever is normally distributed.
I'm going to show that to you
in a very visible way.
To do that though,
we just need to understand
something called combinations.
So suppose you have five patients.
We name them for privacy-saic patients,
A, B, C, D, E.
I ask you a question.
How many distinct combinations
can you make choosing
only a pair of two patients?
Just two patients.
For example, I can choose patient A and C.
If I choose patient C and A,
though that's the same combination.
You can't count that twice.
It's not like rolling the die
and one die is one
and the other one is two
and then two and one.
So combinations means
if I take patient A and patient C,
that's the same as having
taken patient C and A.
Let's have a look.
I can draw patient A and B,
A and C,
A and D,
A and E,
then B and C,
B and D,
B and E,
C and D,
C and E, D and E.
That's all.
Ten.
So from only five people,
imagine my whole town
consisted only of five people
and I drew a random sample of two,
take the ages and calculate a mean.
then I can get from those five people,
I can get ten different means
by taking two people at random every time.
So there's ten possible ways,
just five people,
and my experiment only calls for two samples,
a sample size of two,
I could have taken ten different combinations.
Now there's a mathematical equation for this,
I promised you no equations,
but there's a little one,
I'm sneaking a little one in,
you don't have to remember it,
there's just for illustrative purposes here,
and it says n factorial divided by r factorial,
that exclamation mark is pronounced factorial,
times n minus r factorial,
what is a factorial again?
Well a factorial of,
say for instance a factorial of four,
you just start with four
and you count backwards,
so it's four times three times two times one,
four times three is twelve,
twelve times two is twenty-four,
twenty-four times one is one,
so factorial four,
you can calculate there's twenty-four.
So you just start wherever you are
and you count backwards,
it actually comes from expansion,
a series expansion,
so actually the factorial of zero is one,
it's just a little,
if you don't know mathematics that well,
it might look a bit funny,
but trust me the factorial of zero is one,
but no matter.
So n is the number of patients you have,
I have five patients,
I want to choose two,
the r is two.
Let me just show you,
n equals five,
computer variable,
bucket called n,
I'm putting the integer value of five into it,
r, two into it,
and I'm going to say combinations,
so factorial,
remember factorial is a code word
I imported from NumPy up there,
so factorial n divided by factorial,
r times factorial of n minus r,
you're never going to do this with your own,
I'm just showing you for illustrative purposes,
then the print command,
I'm going to concatenate a whole string together there,
so I'm going to have a string,
the number of possible combinations choosing r,
which is two,
patients from a possible n is five is,
and then do this little calculation,
and look at that,
I didn't lie to you,
the number of possible combinations choosing two patients from a possible five is ten,
let's ramp things up,
let's put ten patients in there,
and we want to choose three,
boom,
look at that,
things are escalating,
so choosing three patients from a possible ten is a hundred and twenty,
now think about this for a little minute,
a thought experiment there,
suppose there are a thousand patients with acute appendicitis in your town over a period,
now you start your study,
you only include thirty,
the next thirty that walks through the door,
in essence that was just a random sample of thirty,
you could have started a day later,
you would have had another set of thirty,
you could have done this last year,
or the next year,
whatever,
the point being is your city is actually just one of many,
many, many, many, many, many, many, many, many possible ones,
see how quickly this escalates,
I mean if I were to say take just twenty,
I'm not increasing things by many more,
four,
we're jumping to four thousand,
eight hundred and forty-five possible combinations of taking,
four patients from a set of twenty patients,
it escalates,
can you think a thousand,
can you think of ten thousand,
twenty thousand,
and if I were to take the mean of my one little sample,
and if I could repeat this,
I mean if this was my town,
and this was the number of people,
I could have had four thousand,
eight hundred and forty-five means,
if I were to just draw a histogram of all those means,
I guarantee you,
that histogram will be normally distributed,
and the mean of your little sample that you've got,
will fall somewhere on that graph,
that graph will have an area under the curve of one,
we can work out from yours,
out towards one of the two sides,
what the area of that would be,
and we can now say was your finding,
or your little experiment statistically significant or not.
Don't believe me, carry on, let's see.
I'm going to run a bit of code here,
and really you don't have to learn how to do this,
I'll just explain to you what's going on here,
you don't have to learn,
this is proper Python coding,
it's fun though to do it,
if you are interested in doing this,
you are going to learn something from this little block of code,
but this is for illustrative purposes only,
to show you the central limit theorem at work.
I'm just going to have a little counter,
it's customary to call that counter i,
and I'm going to set it to zero,
and I'm going to make this empty list,
and I'm going to call it AVE,
it's just an empty list,
and this is a loop,
you get different types of loops,
this is a while loop,
it says while i is less than 10,000,
carry out this code,
so you're going to see when you put a little,
a colon behind something,
if you hit the enter line,
it's going to create this little space,
this is Python syntax,
anything with this tab in front of it,
so the code doesn't start directly under the W,
it starts there,
and ipython notebook will do it for you automatically,
after a colon,
if you hit enter,
it's going to jump there,
it's going to run through this,
as long as this boolean value is true,
is i less than 10,000,
well at the moment it's zero,
so it's going to run through this code,
as soon as i gets to 10,000 or more,
it will escape this little loop,
and start executing the next lot of code,
so this is a while loop,
so i'm going to introduce inside of this loop,
this value x,
this computer variable x,
and i'm going to give it a value,
now forget this 10 times,
let's just concentrate on this little bitty there,
np is numpy,
and it's got the sub module called random,
which has another sub module called random,
and the argument there is 40,
it says,
choose for me,
a random variable,
actually choose 40 of them for me,
and the random dot random,
chooses values between 0 and 1,
so any decimal value between 0 and 1,
and i multiply that by,
each one by 10,
remember if i multiply the list by 10,
each individual entry,
now i'm just going to multiply that by,
by 10,
i want you to,
to choose for me,
a random value,
of,
now actually,
i should actually,
be quite correct about this,
this random dot random,
actually creates an array,
and if i multiply this 10,
it's going to multiply each one of those,
so 40 there,
so i'm going to choose 40 random values,
between 0 and 1,
multiply it by 10,
so i'm going to get a value between 0 and 10,
and i'm going to get 40 of them,
and i'm going to then,
append,
AVE is empty at the moment,
append means put,
the value inside of AVE,
inside of this empty list,
and what do i want to put into that,
i want to put in np.mean,
so it's going to calculate the mean of my 40 values there,
it's going to calculate the mean of my 40 values there,
and it's,
it's going to put that inside of AVE,
and i'm going to do this 10,000 times,
and this is just shorthand for i equals i plus 1,
i plus 1,
let me write it out for you rather,
so you see i equals i plus 1,
remember before we talked about this,
this is computer variables,
not algebra,
so it's going to say at the moment i is 0,
I'm going to add 0 to 1,
that's 1,
and I'm going to put it inside,
so i is now 1,
I'm running through my loop again,
it says,
is 1 less than 10,000?
Yes it is,
it runs through the loop again,
and again and again and again,
until I have this i being 10,000,
and then we'll escape that loop,
so what i'm doing in essence is,
i'm taking a value between 0 and 10,
40 of them,
i'm getting their mean,
and i'm chucking it into that bucket,
again and again and again and again,
10,000 times,
and now remember this plot,
i'm going to choose 20 bins,
so and this average which is now 10,000 values long,
i'm going to distribute,
and lo and behold,
there it is,
my kernel density estimate,
very nearly,
very nearly normally distributed,
very nearly normally distributed,
and i want to show you,
on a proof to you,
if i just say random dot random 10,000,
if i were to take 10,000 random values,
now this is going to be between 0 and 1,
i'm not multiplying by 10,
and i would just to distribute,
and i would just to get a histogram of that,
see,
my actual values,
just choosing 10,000 random values,
and just my one sample of 10,000,
that's not normally distributed at all,
it's actually,
just totally random,
but if i were to repeatedly take 10,000,
and i put in the bag,
each and every time i put my mean for that,
inside of the bag,
inside of the bag,
inside of the bag,
and i'm just counting all the means,
how many times was i,
i was much more likely to find a mean,
of just over five,
just over five,
that was the most common mean i could find,
and this is just to prove to you,
the central limit theorem,
the means of all the possible means,
will be normally distributed,
if you take a random sample of 30 patients,
and you take another random sample of 30 patients,
one has got group A,
one has group B,
one lot has got a mean value,
the other one's got a lot,
it's got a mean value,
and you take the difference between those means,
that will be one mean in the bag,
you've got one in the bag,
but your two sets of 30 patients,
are just one tiny little drop in the ocean,
of billions of other combinations,
you could have had,
and if you could have all of that,
which we can never ever do,
I mean no one can do a trial like that,
but there is a mathematical way,
in which it takes your little sample,
it's called Z and T distributions,
and it can estimate that little plot,
see that kernel density estimate there,
yeah, it's got something to do with that,
it draws that little graph for us,
depending on your specific findings,
and then it sees,
where your specific findings falls on that graph,
it works out the area under that curve,
and lo and behold,
you have a P value.
Phenomenal.
