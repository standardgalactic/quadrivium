In this video, I'm going to show you how to import images that are saved in your Google Drive
and use them inside of TensorFlow. So if I just scroll down here on my Google Drive,
we're going to look at classifying pneumonia on a chest X-ray. This is a video that is going to be
a part of a forthcoming course. And as soon as this course is done, I'll put the link in the
description below. But I wanted to show you just how to use images that exist on Google Drive,
your own Google Drive, and how to use them with an image data generator inside of TensorFlow 2.0.
What you'll notice here, I have pneumonia.chestxray.zip. So I've archived that file as a zip file
containing all my images, and I've uploaded, just dragged it onto my Google Drive
right here, and I've set it to be shared. You can see the little share icon there.
Okay. So it lives in this same folder as this IPython notebook that we are going to look at,
this Jupyter notebook. So let me just increase the size so that we can have a look at this.
Now, what I've done is I have set the runtime to the GPU, and we've got to import TensorFlow.
So what we have, just by the by, is we're going to have images of three different kinds,
chest X-rays. Some of them are normal, some have bacterial pneumonia, and some have viral
pneumonia. That's infection of the lung tissue itself, either by a bacteria or by a virus.
Now, as of October 2019, there's two ways to get TensorFlow 2.0 to work in CoLab. Eventually,
it'll just be the default. And you can just use either of this code.
So I have %tensorFlow underscore version 2.x. And I just put that in a try and accept arguments there.
And let's run that. And we see TensorFlow 2.0, or 2.x at least selected. We can also do a pip install
TensorFlow GPU equals 2.0.0. So that would be the alternative way of doing it. But it's
this %tensorFlow version 2.x that will suffice. So let's just import TensorFlow as tf, and then just
look at the version, just to make sure that we have version 2.0. And there we see 2.0.0.
Now, we're going to use a convolutional neural network. So I'm going to import a few functions we
have from tensorflow.keras.models, the sequential model. So we're going to stick to this high level
way of constructing our convolutional neural network. From tensorflow.keras.layers, we're going to do
dense, conf 2d, flatten, dropout, and max pooling 2d. And from Keras pre-processing image, we're going
to do the image data generator. Because our images now exist in Google Drive. And what we're going to do,
we're going to feed that into our model, batches at a time. So not everything has to fit into memory.
And you can do this obviously on your own machine as well. But to save all of those images loaded to be
a need for it at least to be loaded into memory, all we have to do is just to feed it in batches.
And for that, we're going to use this image data generator function. I'm also going to import
OSS. That is just so that we can navigate the file structure, the folder structure, and matplotlib there
just for some images. Now I'm going to plot the training using plotly. So I'm going to import
plotly.io as PIO. And I'm setting PIO.templates.default as plotly white, just so that we have
these nice white backgrounds. I'm not a fan of the new blue background. So we're just going to keep it
old fashioned and with a white background. Now, when these files, these images were uploaded to
Google Colab, they were in a certain folder or directory structure, and you've got to do exactly
the same. Now, if you want some of these images, get yourself an account, a free account on Kaggle.
You know that there are many, many data sets on Kaggle, and you can just download one of the
chest X-ray data sets. Now, the images were in a folder, and you see the name of the folder all the
way down here, pneumonia CXR, pneumonia chest X-ray. That was the folder on my hard drive. And that
folder had two subfolders, a train and a test subfolder. And each of those had a bacterial,
normal, viral, bacterial, normal, viral subfolder or directory. And all the images were inside of each
of these. So I already have them split into train and test images. And it's these names, bacterial,
normal, viral that are going to be used to show that there are three classes in each of my training
and test set. And they've got to be spelled exactly the same, even with this uppercase,
you see there's uppercase B, uppercase N, uppercase V, and it's got to be exactly the same for the test
set. Now, to be able to use these images in Google Drive, you've got to run this code, copy and paste it,
or just type it in yourself, we've got to install PyDrive. So let's do that. And we've also got to
authenticate ourselves, so that we can use the files inside of our drive. So that's run now.
And now I'm going to authenticate and I'll show you how the authentication works.
It's going to run this code. Again, you can just copy or type that code.
And what it's going to do, it is going to give you a little link to click on,
you're going to click on that link, and it's going to open a new tab. You've got to sign in
again to your Google Drive. And then a page is going to open from which you can just copy a code.
And that code you're going to put in a cell that's going to open right underneath here. It's not doing
that for me because I've done it in the session already. Copy that code right there and just hit
enter or return. And now you have access to the file structure, the files, at least in your Google
Drive. This is some code that you have to copy as well. So I'm stating this inside of a dictionary.
The title is pneumonia chest x-ray dot zip. The dot get list method here, please do exactly the same.
And again, list this file in the get content file function here. So let's run that.
And it's now going to examine this pneumonia chest x-ray dot zip file and make it available for us
in this notebook session. There we go. We can see three chest x-rays, three of the sample chest x-rays
there just at random. So let's create our neural network here. We're going to use the sequential
model. You see one, two, three convolutional layers with 16 3x3 filters, 32 3x3 filters and 64 3x3 filters,
max pooling and dropout in between each of those. And I end up by flattening out my network, a 512 node
dense, densely connected deep layer there. And lastly, only three nodes as my output with a soft max
activation. So let's run that. That's our model. Now I'm going to use, to compile my model, I'm going to use
the Adam gradient descent optimizer, categorical cross entropy, and my metric is going to be
simply accuracy. Let's have a look at this model summary. And we see we have about 10.6 million
parameters that we have to train. I'm going to do a batch size of 128 and 10 epochs. Now what I need to
know is I just need to know the total number of training images and the total number of test images.
And you can see I'm using the length function and then the os.listdir, which is going to list all
the files in that directory. And you see my six directories there. And I'm just summing all of
those so that I have a total for my training and validation step sizes that I'm going to use.
So here we go. We use model.fit underscore generator. So you can't just use model.fit.
I'm passing my training data generator, my step size, steps per epoch,
that I'm going to use as the total train divided by the batch size, double forward slashes so that I
get an integer value, my epochs equals the epochs that I saved. Validation data is my test data
generator. And I have a validation step size, exactly the same total test divided by batch size. I'm going
to use a single callback. Remember these callbacks have to be passed as a list. So I'm going to use
tensorflow.keras.callbacks.early stopping. I'm monitoring my validation loss. My minimum
improvement that I want to see is 0.01. And if that doesn't happen for four instances in a row,
I want early stopping. So let's train this model.
So we can see the model winding down, the training winding down. And we have some overfitting. We see
a difference between the accuracy of the training set and the validation set. And it's a very simple
network. So of course, we are not going to see the best of accuracies. Now, I like to use Plotly
to create my graphs and figures. So I'm going to use the graph objects package inside of Plotly and
saving that, importing that at least as go and as go.figure. And we create the traces,
the different traces there. There'll be two traces and we're using the history.history,
the accuracy. So this is a data frame and the validation accuracy. And if we plot those two together,
let me just make this a bit smaller. You can see it's an interactive plotting library. So if I hover
over these different epochs, we can see what the validation and training accuracies were. And we can
clearly see that we're dealing with a bit of overfitting there. So that is how you would use
your own images, upload it to your Google Drive, and then use image data generation to take batches
of those images and import it into your training, into your model as it trains, so that you don't
have to fit all of those images into memory at one time. You can do this exact same thing if you're
using Jupyter Notebooks on your local system and these images are in your local system. Just be
aware of the folder structure and then using the OS package or library just to concatenate those paths
so that TensorFlow would know where to find those images.
