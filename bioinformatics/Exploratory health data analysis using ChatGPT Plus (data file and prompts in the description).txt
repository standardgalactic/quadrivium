Hi there, everyone calls me Professor Jay. I'm from the Department of Biostatistics and
Bioinformatics at the Milken Institute School of Public Health at the George Washington University.
Now this is a short video tutorial on exploratory data analysis which means summary statistics and
data visualization using the ChatGPT large language model. Now this video tutorial is
specifically for our postgraduate students in the school especially those that are planning to or
have taken my postgraduate class in introduction to biostatistics. But this tutorial is open to all
of our students at the school and at GWU. And as always I extend an invitation to anyone interested
in a career in public health. If you want to study at one of the leading schools of public health in
the US or indeed in the world why don't you consider GWU here in our nation's capital Washington DC.
I can hardly think of a better place to start your career. Now I will leave information about our
school in the description. The plan in this tutorial is to use the GPT-4 model with the code interpreter
from ChatGPT. Now this requires ChatGPT Plus which is the paid subscription. In a later video I will take
another look at a large language model that is available for free. Now for this video though I
will start by uploading a spreadsheet to ChatGPT and then show you a variety of prompts that you can use
to perform EDA using a large language model. We will take a look at summary statistics, comparative
summary statistics and data visualization. Now stick around till the end because I have included a sneak
peek into how you can set things up so that you can perform statistical tests in ChatGPT. To get us
started we'll look at the data set. Now this data set is available on Kaggle and in other repos on the
internet. I've simplified it a bit by removing some of the columns just to keep it easy because what
we're trying to do is just some exploratory data analysis. I'm going to call it just EDAE. As mentioned
this is a simplistic data set. If you want to learn more about the diagnosis of coronary artery disease
which you'll see is our last column here whether someone has heart disease or not. If you want to
learn more please have a look at this link down below and you can read up a little bit more about
the proper diagnosis of coronary artery disease. So we're just going to use this data as it is,
quite simplistic view of it but we just want to do some simple EDAE and have a look at how to do it
using in an LLM. So a couple of things about this data set. First of all I've noted there for you that
this is in tidy data, tidy data format which means we have very well well it's very well defined what
a row and what a column is. So along all the rows each separate row, a row of these would be a single
observation. That's so a single participant in the study and then for each of these variables we'll have a
a random value for a very specifically defined variable. So each row is a separate observation.
Each column then is a separate and individual variable. So we see the names at the top, the column
headers, age and then binary sex, cholesterol, resting ECG, max heart rate, exercise angina and heart disease.
And then for each of these columns very specific variable, specific data type, defined sample
space. So if we look at exercise angina there's only n and y. You know that's the only values that are
possible. If we look down the age column it's only integer values. So we won't find anything like a string
or words or sentences in that column. There's only integers allowed. For the next one binary sex there's
only m and f for male and female. There are no numbers in there. So it's a very well defined sample
space. A very well defined variable and a very well defined level of measure. So the age column for
instance that would be continuous numerical. Whereas for the binary sex well that'll be a nominal
categorical variable. So these things are very well defined defining for us this idea of tidy data.
The next thing that we'll notice is if we look at these column headers cholesterol, resting ECG that
there are no illegal characters. Now the most common illegal character would be a space.
Now that might look nicer if we had resting space ECG. That might look nice and certainly if we want
to create plots we certainly want you know that space in between. But if you've got any kind of
experience with python r or any other programming language you'll know if you want to do this kind
of data analysis it's much better if there are no illegal characters inside of these column headers.
So that's just something to be aware of. But as I mentioned if we do want to create plots we'll have to
fix the fact that that looks a bit ugly just max HR. You know you want you want that to say maximum heart
rate. So let's have a look at these seven variables that we do have here. In our first column it's an
age variable with the name age. And as I mentioned there's only natural numbers in there. But it does
define for us as far as level of measurements concerned that that is a continuous numerical variable.
Binary sex so simplistic view of gender there. And as much as it's a binary variable there are only two
unique values in our sample space. There's either F for female or M for male.
So just a very simple data set. In other words cholesterol
that's serum total cholesterol that's measured in milligrams per deciliter.
And you can see the values there. Once again they're natural numbers.
But that does define for us a continuous numerical variable. Next one is resting ECG.
That's a multi-level or nominal categorical variable. There are three levels so three unique values.
There are in other words three classes or three levels. These unique values in the sample space of
this variable. And they are normal for those participants that just have a normal or
a normal ECG electrocardiogram. ST for ST segment changes. Now if you know anything about an ECG
that might indicate that there is some ischemia in the heart. There's not enough oxygen supply to the
heart muscle itself. And then LVH for left ventricular hypertrophy. And that is enlargement of the left
ventricle. So that can be at least
looked at as far as an ECG is concerned giving that idea from the ECG that there is LVH.
So those are three classes or three levels there for resting ECG. Then max HR, maximum heart rate.
That's the maximum heart rate achieved by each individual when they were stress tested. And stress
test is a exercise induced stress. So usually walking or cycling in a lab
allowing for the measurement of the maximum heart rate. And that can indicate various problems.
Next one is exercise induced angina. Now you can either ask the patient, you know,
whether they develop angina when they are physically active or once again in the lab,
on a treadmill or on a bicycle. See if they do develop pain across the chest. That's exercise induced
an angina when they are physically active. And the sample space, there's yes and no,
Y for yes, N for no. So that makes it a binary categorical variable as well. And then finally,
we have heart disease and that's encoded with a zero if there's no heart disease. And one,
if there is a heart, if there is heart disease present, and that makes it binary categorical. That
is not a numerical variable. That's just encoding. So we've got to be, we've got to be careful there.
Again, it's not the simple, we won't just use those six variables to decide whether someone does have
heart disease. So please have a look at the link that I've put down here below if you want to learn
more about the proper diagnosis of heart disease. But this is our data set. So we're going to use an
LLM and we're going to do some EDA exploratory data analysis. So here we go. We've chosen ChatGPT
for this demonstration. And that is a chat.openai.com. Of course, if you want to sign up, there's a whole
signup process, they're going to ask for your telephone number, etc. And as you can see here,
this is ChatGPT plus. So the plus makes this GPT-4 model available to us with all the plugins
and code interpreter. But that does cost money, it costs $20 a month. And if time allows, I will make
a video where we'll look at some of the free options like claw.io. But here we have GPT-4.
So this is in ChatGPT plus, costing $20 a month. So if I hover over GPT-4, you'll see it says there
that it is available exclusively for plus users. And then GPT-4 currently has a cap of 50 messages
every three hours, even though we are paying for it. And then there's the default setting,
the code interpreter setting, which is the one we're going to use. And you can see it already
has a check mark. So you just click on code interpreter. And then there are an abundance of plugins
that you can use as well. But for this demonstration of EDA, we're going to choose the code interpreter.
And that is then already selected. So right at the bottom, we can also see this is the August
third version of the GPT-4 model. And we can see our little box where we're going to interact with
the large language model, you'll see the little plus symbol there for if you hover over that,
it says upload file. And that is where we're going to upload our data set. So in this instance,
for ChatGPT or GPT-4 model with code interpreter, you have to have the CSV file,
the spreadsheet file on your local system, so that you can upload that. One thing I didn't mention
when we had a look at the data set itself, that was saved as a CSV file. So from any spreadsheet
software, you can save in the proprietary format of that software, or you can choose to save as a CSV
file that stands for comma separated values. And what that does is just strips away all the extraneous
niceties that we like to add to our spreadsheet files by, you know, taking the dates and putting
them in a certain format, adding dollar symbols to anything that is financial data, etc, just strips
away all of that. So we're working with the pure values themselves. And I always suggest that you
export your spreadsheet files as comma separated values. So that is the file format that we're going
to use here and upload. So I'm going to click on upload, which will bring up a navigation system on my
explorer on my system here. And I'm just going to select that file, click on it and upload it here.
So there you go. It's heartllm.csv. A link to this file will be in the description. So you can
use it yourself. And then we can just type our message there. So this file is already uploaded.
Once you click on that upload, depending on the size of it, you'll see a little blue spinning disk.
And, you know, that indicates that the file is being uploaded as it stands, the file is already
uploaded. Now we can just hit this little play button here or sending our message so that the LLM
can interpret this file. And it'll do a pretty good job. It really looks at the data type for each
of our columns have very nice if your data is in long format, tidy data, tidy data format. It makes
it very easy for for the code interpreter to analyze your data and your data should be in that format
anyway for proper analysis. But I like to do something else. I like to put a short little message
there telling GPT-4 about my data set. So there we go. I'm going to copy and paste the set of prompts
that I have pre-written and we'll go through each of those. I'm just only doing that just to save time
so you don't have to watch me type. But we'll go through these. As I mentioned, you can just hit the
send message without typing any of this. Once your CSV file, your data file is uploaded. And as I said,
ChatGPT will do a pretty good job of interpreting what your variables mean. But I do like to write a
proper prompt and give it as much information as I can. Now, I would give even more information than
this. But this is just for demonstration purposes. So let's go ahead. So I've said here the CSV file
contains seven columns. And then I talk a little bit about each of these. The age describes the age of
participants in years. Binary sex describes the gender of each participant with two classes,
M for male and F for female. Cholesterol is the serum cholesterol in milligrams per deciliter.
Vesting ECG is a multi-level variable with classes normal for normal ECG, ST for ST segment elevation
or changes, and LVH for left ventricular hypertrophy. Max HR is a continuous variable
measured in beats per minute describing the maximum heart rate reached during exercise.
Exercise angina is a binary variable with two classes, N for no and Y for yes,
and describes whether angina was induced by exercise. And heart disease is a binary response
variable with a zero for no heart disease and a one for the presence of heart disease.
So I would typically do a little bit more than this. But as I said, you don't need to do anything at
all when you just upload this file. So there we go. I'm just going to hit send message.
And there you can see the response. It says, great. Let's start by loading the data from the CSV file
to inspect its first few rows. This will help us get a sense of the data structure. And it'll do that,
you know, without us having given any prompts. And it'll do a pretty good job. But now that I've given
it a little bit more, it should know a little bit more. Now, the other thing that you'll see is
finished working show work. And if I drop down, you'll see the actual code and the results. So
it's going to show you the actual code that was used. So here we see it's always going to be Python
by default here. And so you can actually copy and paste this code and put it in your IDE.
That's an integrated development environment. I like to use Visual Studio Code or you can use JupyterLab.
There's various software that you can use to type in your Python code, but it's going to give you the
actual Python code that it used and the output of that Python code. So it's an excellent way to learn
Python as just to use a large language model. So this is not going to work for our, you know,
other, some of your other favorite languages for your data science. And I suppose it just underscores
the popularity of Python when it comes to data science. Now it's going to tell us a little bit
more about these. As I said, if I had put in no prompts, it would have, it would have given this
same, same set of results here that we can see for these seven variables. But giving it that little
prompt, maybe later on, it'll help the large language model make more sense of the analysis.
So that's it. Our data set is now uploaded. It's very simple. I clicked on the plus
behind the scenes. I just navigated on my internal hard drive on my computer to where the CSV file was.
And I just added a little bit of a prompt and just sent the message and the data is now uploaded.
So let's go for our next prompt. So here we go. I have typed in provide summary statistics for the
continuous numerical variables. Include the number of observations, the number of missing data, the mean,
median, standard deviation, variance, minimum, maximum range, quartiles, and interquartile range.
Generate a table of the results. So that's my prompt. I could probably just have said provide
summary statistics. And that's it. Or at least summary statistics of the continuous numerical
variables. I would not have to put in all of those specific statistics that I'm after for the sample.
But it helps if you guide it this way and be specific about the summary statistics that you want. Let's see
what the LLM does. You can see here the tables being generated line by line.
We get a little message there at the bottom. It says it appears that there are no missing values
for the continuous numerical variables in the data set. So that's brilliant. And there we see there's
our metric, count, mean, standard deviation, min, the first quartile, the median, or then the
second quartile, third quartile, maximum, variance, range, IQR, missing. So put it in a nice
little order there for us as well. And we can see age, cholesterol, and maximum heart rate.
So we'll see there's 918 observations for each. We can see the mean age was 53 and a half years,
with a standard deviation of 9.43, or variance as we see at the bottom, which is the square of the
standard deviation, 88.97. So very nice table. And we can very quickly get some idea. This is EDA. We need
to understand our data. And the first step of doing that is just to print out or determine
these summary statistics. And how easy was that? I typed in a line of a couple of English sentences,
I should say a little paragraph of English sentences. And there's my result. Once again,
I can click on show work. And you can see there, what was done. This is the Python code
for producing this result here at the bottom. And you can see that you can just click copy code.
And as I mentioned before, if you go to your IDE, you can just paste that code, run it. And it'll run,
because here we see the output of that code, which was then used by ChatGPT just to create this beautiful
table that we can see here. So very nice. There's your summary statistics, you have a very good idea of
our continuous numerical variables. So here's my next prompt, I have typed in create a table of the
frequency and relative frequency of the classes for the categorical variables. So here, we don't want,
you know, it's impossible, this is categorical variables. So we can't have mean and quartiles
and variance, etc. We want the frequency and the relative frequency. And as mentioned there, I want this
in a table as well. And there you go, instead of a table, we've actually got a little bit of a list
view here. And there are variables, it's binary sex, it found m, and then for male, f for female,
we see the frequencies there, 725 male and 193 female. And with a relative frequency or proportion, then
it's 78.98% male and 21.02% female. So we'll see that for resting ECG as well, normal LVH for left
ventricular hypertrophy, ST for ST segment elevation, and probably ST segment changes would have been more
appropriate. But look, it is drawing that initial information that I gave about the data set. It's
taking some of that information to be able to write this response for us. Exercise angina, no and yes. And
then heart disease one, presence of heart disease zero, no heart disease. So again, using some of
that information. That's why I like to give it information about my data set when I do the first
upload. So now we've got a pretty good sense of our numerical variables and our categorical variables.
So with this EDA, we start to develop a good understanding of our data set. Now we can get a
little bit fancier than this. So what I've done is I've included all the values for these columns,
for these variables. But what if I just want to do my summary statistics, but I want to filter for
some of the specific classes, for instance, for one of my variables, my categorical variables. So let's
have a look at this, what I've typed here, I have typed create a table of the summary statistics of the
numerical variables used before, but filter only for those with a normal resting ECG. So once again,
just a normal English sentence, I didn't use any of the normal or STLVH, the abbreviations that were
used as the names for those unique values or classes in that variable. No, this is a normal English
sentence. So I want a table of the summary statistics of the numerical variables used before. So it's going
to give me all those statistics. But I want to filter only for those with a normal resting ECG. So let's
just go back up here. And if we look at our results here, resting ECG normal, just have a look at that
frequency, there were 552 instances or observations then that had a normal resting ECG. So let's see what
happens with this prompt. And look at that, it says similar to the entire dataset, there are no missing
values for the continuous numerical variable in this filtered subset. If we look at the count,
we'll see 552. So really, that was correct. There were only 552 observations that had a normal ECG. And
now I'm going to get the summary statistics of my numerical variables, age, cholesterol, and maximum
heart rate, but only for those 552 participants. I'm excluding all the others. So you can start to see
how specific you can get by filtering some of your data, and then redoing your summary statistics.
So you can get a real good sense of what is going on with your data. And I really can't emphasize this
strongly enough. If you want to start to understand this information, the knowledge, the story that's
hidden in your data, summary statistics is just the proper way to start looking at your data. So up till
now, we've only looked at a single variable at a time. So we've included all of the values. So
the whole data set for our summary statistics, both for our continuous numerical and for categorical
variables. And we've seen how to select or filter out only a subset of our participants. And so that's
great if we just look at a single variable at a time called univariate summary statistics. But we can
also do comparative summary statistics, where we're going to compare two or more groups to each other.
And we do remember that one way that we develop these groups is just to group them by the classes
for one of our nominal categorical variables. So what I've typed here is use the same summary
statistics for the continuous numerical variables as before, but only for the age column. So I'm asking
for all those statistics, but only for the age column and group the results by the classes of the response
variable. Now, remember, I told it right at the beginning that heart disease is the response or the
target variable or the dependent variable. So use no heart disease for zero and heart disease.
Now let's just change that that should be a one and heart disease for one as row values for the two
classes of the heart disease variable. So let's have a look at what the large language model does with
that. So remember what I'm trying to do, I'm trying to create summary statistics of my age column,
but I'm doing comparative summary statistics. I'm going to divide all the values into two groups.
And those two groups are the two classes that it finds in the heart disease variable.
So here we go. Here's the summary statistics. And as I said, I wanted two rows, the zero for no heart
disease, one for heart disease. And that's exactly what it's done. So instead of putting a zero here
and a one there, it's actually put the words, no heart disease and heart disease.
So there were 410 with no heart disease, 508 with heart disease. And as far as the age column is
concerned, we see the mean. And now we can see that those with heart disease were slightly older.
They had a mean age of 55.9 versus though with no heart disease of 50.5. And that's what we mean by
this is comparative summary statistics. So if we know that we have a bunch of research questions,
where we're going to make comparison between two groups, and the two groups are the
two classes of our target or our outcome or response variable, our dependent variable,
it's very good if we do this to start off with, if we do this comparative summary statistics.
Now, we need not only do that for our continuous numerical variables, but we can also do this for
our categorical variables. So I have typed, create a contingency table using the resting ECG
and heart disease columns, include row and column totals in the table, also generate a table of
expected values under the null hypothesis that the variables, let's put a little s there, are not
associated with each other. So this is comparative summary statistics as far as frequencies are
concerned. And that's what a contingency table is going to give us. Now along the rows, we'll have
one of the variables, the classes of the one variable, and across the columns, we'll have the classes of
the second. So this is also a form of comparative summary statistics. So here we go. Remember, there's
always the Python code to show you how the results would be calculated if you were to use Python code,
but here we see our results. So along the rows, it's put the resting ECG classes, LVH, left ventricular
hypertrophy, normal or ST, and across the two columns, no heart disease and heart disease. So if we look at
those without heart disease, 267 of them had normal ECGs, 61 had ST segment changes and 82 had left
ventricular hypertrophy. And we see the different frequencies when it comes there to those with heart
disease. And then we can also see the row totals and the column totals. So with no heart disease, once
again, there were 410 and with heart disease, there was 508. And then under the null hypothesis, remember
these two variables, resting ECG and heart disease are independent of each other. And if you remember
a bit of your probability theory, there's a very easy way that all of these expected cell counts can
be calculated. And the easy way to remember that is if we look at this first cell where we get 83.97,
that is in this LVH row and in this no heart disease column. So we're just going to multiply these two,
that 188, which would be the row total times the 410, which would be the column total for this specific
cell, this first cell, and then divide by the sum total 918. That gives us 83.97. But it's best to
think about this in terms of independence of these two. In other words, our joint probability must be
equal to the product of the two separate probabilities as far as the two things that
we would put into the joint probability. So LVH and no heart disease. And so here's our expected
frequencies. We see that all of them are five or more. And from that, we know that's at least one
of the assumptions that we meet for the use of a chi-squared test for independence or Pearson's chi-squared
test. So there's our summary statistics, and then also a very nice table of expected values.
Now, while summary statistics are great, specifically comparative summary statistics,
it's even better when we visualize our data. So what have I asked for here? Create a histogram
of the age column, use the title, and then I've used quotation marks there, distribution of participant age.
Also use the horizontal axis label age in years and the vertical axis title count. Use a light orange
as the bar color. Create bins with a minimum of 20 and a maximum of 80 with a step size of 10.
So what I'm trying to showcase here is I can be very specific about the styling of my plot. I can tell it
what kind of titles, axis labels or axis titles I want. And also, as I said here, the color and the
actual bin size. And what I love about this response is that was actually a mistake in the code here. And
you can see in red there, there's all the error. There's a using a string of single character colors
as a color sequence is not supported. So it actually, you know, executes this Python code,
finds an error, and then tries to correct itself. And then you can see the actual code where the
correction was made so that we can get the proper plot. And there's our plot. I've got the title
that I asked for. I've got the axis labels or axis titles that I asked for. And then the color that
was orange. And we can see the bin sizes. It was from 20 to 80 and in step sizes of 10. So I can be very
specific about this. And that's going to change the code for me. Look, for instance, there it says bins
equals range 20, 81, 10. And that very specifically defines these bins. So don't leave it just to the
default. I can be very specific. It's going to generate that Python code for me. But remember,
this is using a large language model. So if you're not interested in the code, we can just forget
about the code. All we want to do here is just look at the EDA, the exploratory data analysis.
And we can see that age is kind of normally distributed. And we can take a lot away from that.
As far as the majority of cases in this decade, 50 to 60. And very few people on this younger age
group. So there's a little bit of a left tail, I suppose, included there as well. So that's great
for histogram. Let's plot some more. Create a scatter plot of age and max HR. Add the title scatter plot of
age and maximum heart rate. Use the horizontal axis title age in years. And the viral axis title serum
cholesterol in milligrams per deciliter. Group the markers by the classes in the heart disease column.
Add a legend. So I'm not only want the scatter plot, but I want to scatter two different scatter plots,
you know, on top of each other. So I want that separation, that group by the classes in the heart
disease. So there's the two classes, those without and those with heart disease. And I want to see
them separately. Add a legend named heart disease with the class names no heart disease for zero and
heart disease for one. And also insert grid lines. So very specific about this plot that I want. Now you
needn't be this specific, you are still going to get a plot. And this is all EDA. So I'm just trying to
learn about that knowledge, that story that's hidden in all the numbers of my spreadsheet. But I've asked it
to be very specific, and that's what it's done. So look at that. You know, there's sort of a little bit of a
negative correlation there. As people get older, their maximum heart rate goes down a little bit. And we can
see there, the little blue markers for no heart disease, and the little red markers for those with heart disease.
So a lot of information, once again, that I can get from the scatter plot. Now in future tutorials, I'll show you
that you can then indeed, you know, do some or calculate at least the correlation between these
two and calculate the correlation for each of the two groups, those without and with heart disease.
But this tutorial is all about just the EDA. So we've created a nice histogram. And you can go through
all of your continuous numerical variables and create this histogram. You can also then, you know,
create two histograms so that you do summary data visualization or comparative data visualization,
I should say, for those with and without heart disease, for instance. So try out different
prompts. And really ask this LLM to create plots that you want. So that should give you a proper
idea of the power of using an LLM to do your EDA, your exploratory data analysis. It is so easy to do.
You can be very specific. You need not be as specific as I was here. But you can learn,
you know, all that initial information, start to get that story out of your data by comparative
summary statistics and data visualization. Really powerful here. Now as a little sneak peek,
not part of EDA, but if you want to explore a little bit further, have a look at what I've typed here.
So create separate lists for the age values for each of the two classes in the heart disease column.
Determine if the data meets the assumptions for the use of an equal variance t-test to determine
if there's a difference in the mean age values for each list. So think about your classes as far as
biostatistics were concerned. One of the first statistical tests that we learn about is a t-test.
And that is where we compare the means of a continuous numerical variable, the same variable,
between two different groups. Now, if you want to use a t-test, and remember there are various t-tests,
if I want to use a t-test, I must make sure that my data meets the assumptions for the use of that
test. So that's exactly what I've asked here. I've told ChatGPT what analysis I want to do. I want
to compare the means of the age values for these two groups, people with heart disease and without.
But first, let's make sure if the assumptions for the use of this t-test, and I've specified here an
equal variance t-test. So that means it's also going to include those assumptions of, you know, whether
the variances are equal. So let's have a look at these responses. And I think it's absolutely brilliant
because remember, in many postgraduate introduction to biostatistics for public health research,
we're not necessarily going to look at some of these tests. We might just mention these assumptions.
And for the examples that we use, we'll usually say that the data, you know, do meet these assumptions.
But it actually, you know, gives us the important ones here. It says independence of observations. Now,
it cannot determine that from the data that we gave it. But it can say here, the data should be sampled
independently from the two groups. This is typically an experimental design issue,
rather than something we can test for. So you've got to know that about your data. Normality,
each group should come from a population that follows a normal distribution. So age should be
normally distributed in the population from which the sample was taken. And it says this can be tested
using methods like the Shapiro-Wilk test. Now you can read up on these tests, you know, how good they
are, how well they perform and criticism of these tests, you can read all about it. But it's going to tell you
that this would be a possible test that it could use. And there should also be homogeneity of variances.
Now the variances of the two groups should be equal. This can be tested using Levine's test or Bartlett's
test. So, you know, wonderful things that you can read about here. And even if you didn't cover this
in class, well, you can use the LLM to learn about this. First, let's create separate lists for the H
values for each of the two classes in the heart disease column. And once again, there's your code.
It'll show you in Python how to do that, if you're interested in that. Let's just carry on then
with the results. The normality test tells us it used the Shapiro-Wilk test. And for participants
without heart disease, it had a p-value of 0.00483. Now, if our level of significance was 0.05,
this would be less than 0.05. In other words, this suggests that the H distribution for participants
participants without heart disease might deviate slightly from normality. And when we look at the
distribution of ages in those with heart disease, the p-value is very, very small. And suggesting
that the H distribution for participants with heart disease deviates from normality. So we are not,
we are not fulfilling or meeting that assumption for the use of students' t-tests. So we're in trouble
here with the homogeneity of variance, Levin's test, that was also below a level of significance of 0.05.
And that suggests that the variances between the two groups are not equal. So if we wanted to use a
t-test, we would have to consider an unequal variance t-test. And all that information is there.
Now it's going to say, given these results, the data does not meet the assumptions for an equal variance t-test.
Specifically, neither group's H distribution appears to be perfectly normal, and the variances of the
two groups are not homogeneous. In light of this, it would be more appropriate to consider
Welsh's t-test, so that would be for the unequal variances, or better still, a non-parametric test,
such as the Mann-Whitney-U test, if we want to compare the ages of these two groups.
Now, once again, depending on your course, you might cover non-parametric tests, but certainly then
the Mann-Whitney-U test would be used as a non-parametric test instead of a t-test. As I
mentioned, this is not what this little tutorial is all about. It was about EDAE, but here we go. I
couldn't just, you know, it's told us now to use the Mann-Whitney-U test, so let's just ask it to do
the Mann-Whitney-U test. So please perform a Mann-Whitney-U test to compare the two lists of age
values. The null hypothesis is that there is no difference between the two lists, and I'm just saying
list lists of values. And the alternative hypothesis is that there is a difference between the two lists.
Use a 5% level of significance, write a full comment of the result. So please be creative in
what you type here, but try to be as specific as possible just to help the large language model,
you know, do what you ask. And now it's written there for us, the Mann-Whitney-U test returned a
p-value that is basically zero. Given our level of significance of 5%, alpha equals 0.05,
the p-value is significantly below this threshold. Now the comment on the result,
the Mann-Whitney-U test revealed a statistically significant difference in the age distribution
between the participants with and without heart disease, specifically that p-value is less than 5%.
Therefore, we reject the null hypothesis and conclude that there is a difference in the age
distribution between the two groups. So wonderful. So now think of all the other things that you learned
about in your postgraduate biostatistics program or lectures or courses. And you can well imagine
that you can do everything that you learned about using a large language model. Okay, and that's it
for this video. I hope you've enjoyed it. Remember, if you have not joined our school, follow the link in
the description to learn more about the George Washington University. You will learn a lot here. That's a promise.
