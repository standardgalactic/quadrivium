So in this video I want to show you a little bit about gradient descent.
We're going to use a very simple model called linear regression.
So we're just going to have this single feature variable
and we're going to predict a continuous numerical variable.
And gradient descent is really at the heart of all supervised learning,
at least deep learning models.
So we're living in this era of the functional approach to AI
where we can write a function that we're trying to minimize.
And that function is all about the difference between what our model predicts
and what the actual value is.
If we can express that difference between the prediction and the actual value
in a function, as with functions, we can get the minimum of that function.
Think of y equals x squared.
We all know that right down at the bottom where x equals 0
that's where the function is going to be at a minimum.
And that's exactly how we learn.
We're going to have these parameters, the unknowns, the variables,
and we're going to have them in multidimensional space
and we're just trying to minimize that.
And that is what gradient descent is all about.
And think about standing somewhere in a valley and you're looking down.
You want to get right down to the bottom of the valley.
You can't just walk straight down.
You've got to zigzag your way a little bit down.
And that's exactly what it is if you think about it.
If we have a multi-valued function, a multivariable function,
of course that's going to be in hyperspace.
We can't imagine that.
We can only imagine three-dimensional space.
But imagine that multidimensional space.
We are just going to zigzag our way down to the minimum.
And at that minimum for each of the values,
for each of our variable values, our unknowns, our parameters,
we're going to have values for which we have the minimum of this penalty,
this cost function, the difference between the actual and the predicted value.
And that is really at the heart of it.
And if we do linear regression, of course, we can write a very simple gradient descent.
I'm going to show you how to do that in Julia.
But I'm also going to put some pen to the screen on my tablet
and I'm just going to show you the basics of the algebra
and the calculus behind the partial derivatives.
I'm not going to teach you about how to do partial derivatives
or do matrix vector multiplication.
I'm going to assume that you know how to do that.
If not, put something down in the comment and I'll make a video
because it's just a couple of simple things that you need to know about linear algebra.
And about matrix multiplication, matrix vector multiplication.
And that should all make sense.
So I'm trusting that you do know that.
If not, let me know in the comment.
But I'm going to assume that you do.
And I'm just going to show you how we go from the code
to what's actually happening behind the scenes
and from what's happening behind the scenes back to the code.
So they just understand.
It's not just a code, a function or two functions that we write
and you don't understand where that comes from.
I want you to know really where it comes from.
And that's going to make the code so much easier to understand.
That makes gradient descent so much easier to understand.
And that will just help you along as you start developing your knowledge of deep learning.
Because that's what we're going to do in supervised learning.
We're going to do, we are just going to do gradient descent.
So let me open up a Jupyter notebook.
And we're going to use Julia just to make life easy for ourselves.
Let's have a look.
I've opened a Jupyter notebook here using iJulia
and then just the notebook function inside of the REPL.
And we have our Julia kernel running here inside of a Jupyter notebook.
You see I'm running Julia 1.4.0 up in the top right corner.
And let's see what the libraries are that we're going to use.
So I'm using GLM, that's Generalized Linear Models, Statistics, DataFrames, Random and Plots.
And I'm using the Plotly backend.
So make sure that you've installed all of this through the REPL.
So just a few short notes then.
What is linear regression?
Well, it's a type of modeling.
It's all about continuous numerical variables.
And we're going to have a feature set of variables.
We call them feature variables or independent variables.
And then we're going to have a target variable or a dependent variable.
And then for each sample, so that would be a row in a spreadsheet,
we're going to use the values in that row for that one specific sample.
And it's got to predict as close as possible to the value that's in the target variable
or the dependent variable then.
And if we have as many as possible samples, we can run through all of them
and we can use those feature variables to predict each and every one of the target variables.
So it's a continuous numerical variable that we're trying to predict.
And that makes it a regression problem.
And we're going to keep our independent variables, our feature variables,
we're also going to keep them continuous numerical.
And as much as in this first instance, all we're going to do is have a single feature variable.
And we're going to try and predict the target variable.
So I'm using random.seed here in my first, as you can see here, in my first code cell.
And I'm setting that to one.
And if you set it to one, we're going to get the same random values selected.
And I'm going to have this computer variable that I'm going to call uppercase X.
And that's going to be a random value.
It's going to be 16, but a floating point.
And I want 50 of them.
So 50 random values between 0 and 1.
And then for the target variable, I'm going to call that lowercase y.
I'm just going to add a bit of random noise to a constant multiple of each of these.
So I'm taking X.
So that's now going to be each of those 50 values.
Dot multiply with 10.
And that means each of them gets multiplied by 10.
And then each of them, to each of them, I'm going to add a bit of random values.
So on this side, I've got 50 values.
So I better add 50 on this side.
Strictly speaking, I didn't have to have the dot there.
Because it's just a scalar times an array.
And that means each of them are going to be multiplied by that.
But what I need to do is dot plus.
That's very important.
Because I've got another 50 values there.
So that's going to be an array of 50 values.
But this time, it's from a normal distribution.
So rand in 50.
And multiply that by 2, just to get it a bit bigger.
And so that's just adding a bit of random noise to the 10 times the X value there.
So let's run that.
And now I've got some values that will be my feature value in X.
My feature variable in X.
And my target variable in Y.
In case that didn't make too much sense, let's have a look at visualizing the data.
That always helps.
I'm going to use the plot function.
And I'm going to plot my array of feature variables.
My array there of my target variable.
And the series type is going to be scatter.
So I might as well just have used the scatter function there.
And I'm adding a title.
And I'm adding some labels.
So remember, the first time you run this, it's going to take a while.
And there we go.
We see we have our values between 0 and 1 for the X axis down the bottom.
And then for the Y axis, that's going to be 10 times the value.
And then we're going to add just a bit of random noise to that.
So it's not all on a straight line.
But you can certainly see that there is some trend to this.
As we go up in my independent variable, so does the dependent variable value go up.
And in any one of these, when I hover over them, we can see the black at the bottom.
And for the independent variable inside of X, I have 0.58.
And that gives me, given that, I get a dependent variable or Y value of 9.27113.
And you can hover over each of those we see in black what the independent or X value was, variable value was.
And in blue at the top, we're going to see what the Y, the dependent variable value was.
So what a model would like to do is draw a straight line from, I suppose, as we can see, there is this correlation.
And it's a positive correlation.
So some line, a straight line that makes it a linear model, that given any X value, I can go up to that line.
And that will give me what a predicted value would be, a predicted dependent variable.
So you can see right here from school, you remember the equation for a straight line.
That's Y equals MX plus C, where M is the slope and C is the Y intercept.
So if X is 0, this MX term becomes 0, and then Y will just be the intercept.
So Y equals MX plus C.
Now we're not going to use the M and the C.
We're just going to use different symbols, just to confuse things, because that's the way it works.
For C, we're going to use this beta sub 0.
And for M, we're going to use beta sub 1.
So that we have this Y equals beta sub 0 plus beta sub 1 X.
And that's still going to be a straight line.
But you can well imagine, we need to know a slope and an intercept for our straight line.
That would be the unknowns.
How would we know what would be the best model?
So what I'm going to do here is just a random guess.
I'm going to make beta 0.
I'm going to set that equal to 0.
So when X is 0, when my input variable is 0, my output variable is going to be 0.
My Y intercept is going to be 0.
And I'm going to make my beta sub 1, my slope 10.
And I chose that because that's how we designed it up here when we started.
So my guess wasn't going to be too bad.
So that's what I'm trying to plot here.
So I'm using plot with the bang there, the exclamation mark, which means it's going to plot on top of a plot that's already in memory.
And I'm going to use just some values that I want to collect from 0 to 1 in steps of 0.01 so that we can get this straight line going.
And if we were to plot this, there we go, there's my model.
Now you can understand that I have this red line as my model.
And my model is Y equals 0 plus 10X.
So beta sub 0 is 0 and beta sub 1 is 10.
And that gives me this line, which means given any input value here on the X axis,
if you go up where it meets the red line, say there, there, if I just hover just right, I get a little red one.
The model is going to be 3.8.
So for 0.38, of course, it's 3.8 because it's just 10 times.
But that means if I get new data, I've got a nice model now.
If I get new data, you just give me the input variable and I can predict the target variable for you.
It's not going to be terribly accurate because here and amongst the real data that we have,
we see close to here, it's 5 point, if 0.59 is 5.9, but a real value would actually be 6.67.
So it makes a little mistake.
And if I draw vertical lines between each of these data points down or up to the red line,
those are going to be errors, the errors that we make.
And we can well imagine what would be the best possible line that we can draw here.
So I need the best possible beta sub 0.
And you can see mine is the 0 here.
When X is 0, the Y intercept is also 0.
And for beta sub 1, what could be the best possible one so that I make the least amount of errors?
And you can see now the error is that between which the red line predicts for that X value and what the actual value was.
So we're trying to minimize this.
And that's what machine learning or deep learning is all about.
We've gone in artificial intelligence through various ages and we're now at the functional age of artificial intelligence
where we create a function.
And that function we call a cost function.
And we're trying to minimize that cost function.
And we're very fortunate that we can do it.
And I'll show you just exactly how that works.
Why we are so fortunate.
Why this functional age of AI is working so well.
But just to remind you here, right at the bottom, you see I have a Y hat here.
Because Y was my vector of target variable values.
But that's going to be slightly different from the ones that my model predict.
So I'm going to call that Y hat.
That's a very common thing to do.
And Y hat is going to be beta sub 0 plus beta sub 1 times X.
And X is going to be either a matrix or in this instance it's still a vector because I only have one feature variable.
If I multiply beta sub 1 with that, beta sub 1 is 10.
And it can just be a scalar.
But if I wanted to add a vector to that, I've got a bit of a problem with beta sub 0.
And we'll see how we fix that.
So beta sub 0 must actually be a vector of zeros of the same length as X.
But we'll see how to deal with that.
So just below that you see Y hat sub i.
So for any Y hat I can predict, that's any of the samples in my spreadsheet.
Say for instance, I just take that X i in that same row.
I take its X value and I multiply it by 10 and I add 0.
And that's going to give me a predicted value.
So let's see how well it does.
So for X sub 1, if I execute X 1 in square brackets.
So we're just using indexing.
The first of my 50 values was a 16-bit float and it was 0.166.
And let's see what the actual value was.
The actual value was 2.616.
That was the actual value.
Now and then to get the predicted, remember this is 10 times that X sub 1,
that first X value.
And that gives me 1.699.
And that's quite a bit different from the actual 2.61.
So I made a bit of an error.
And you see the error symbol there, just epsilon.
And the term that we usually use is the residual.
Specifically in linear algebra we talk about the residual.
But in deep learning we'll just say that that's the error.
So the error is just going to be my actual value minus the predicted value.
Or you could do it the other way around as well.
And it doesn't really matter because in the end we're going to square those differences.
But you see to get the real Y sub i, you have to add that specific error term,
the residual in each and one of the cases.
So let's do all 50 of them.
So I'm going to store that in a computer variable called y underscore pred.
10 times X.
So it's a scalar times.
That's why I didn't have to put dot multiply as I did before.
You can just say scalar times that vector.
And that's going to broadcast it to every value in the vector.
And my residuals is then going to be the actual ones minus the predicted ones.
So let's just run that.
So that's stored now.
And that difference, y minus y pred.
So the difference between each one of those.
So it's a vector minus a vector.
So it's going to be element y subtraction.
And that's now going to be a vector that RES is going to be a vector of all my residuals.
So let's have a look at what they look like.
And this is going to be actually quite important when we talk about using parametric tests, etc.
But at the moment you can see I have this kind of normal distribution to my residuals.
A better way to do that is rather let's just do a scatter plot.
Let me show you what that looks like.
And what we have to remember is that there's the zero line right down the middle.
All the dots that fall on that zero line or close to the zero line means there's very little residual.
So it was very close, the prediction, and the actual values were very close to each other.
And some were quite far away.
And if our model is the best possible, then these residuals will be as close to this zero line as is possible.
So you've got to imagine that there's a line between everyone straight down to the zero line
or from this bottom one straight up to the zero line.
Those are all my residuals.
That brings us to this idea of a loss function.
So somehow I've got to quantify how bad my predictions were.
And to do that we have a loss function.
And we have the same thing in deep learning.
That there is some difference between my vector of predictions and my vector of actual values.
And because this is the functional age of AI, I can create a function to express the difference between those two vectors.
And in linear algebra, one of the common ones that we're going to use is the mean squared error, MSE.
And that just means I square all those differences, all those residuals.
So here you see I've done it this way around, so it's predicted minus actual.
So we take the first sample, the first row in our spreadsheet that contains the data, or in this instance our two vectors.
But anyway, I subtract them from each other and then square.
So it doesn't really matter in which order I subtract them, I square them.
And then I add all of those and I divide by how many there are.
And that gives me a mean.
A mean is you just add everything and divide by how many there are.
And that's the mean squared error.
The name says it all.
And that little symbol there means from one to M.
M is the number of cases I have, the number of subjects, my sample size.
And in our instance that's 50.
But let's just be clear as to how we got to this y hat.
So if we were to expand this little summation expression here on the right hand side,
remember this is what really is.
Every single one of these y hat sub i's is beta sub 0 plus beta sub 1 x sub 1 minus y sub 1 squared.
That is how I get each and every one of these.
The beta sub 0 plus beta sub 1 x sub 1 and then minus the y sub i on that side.
There's my first sample.
There's my second sample.
There's a third sample.
There's that.
And I'm going to go on until M.
And in our instance M is 50.
And I divide by.
So remember that is what happens behind the scenes.
Not this little shorty thing.
That's what happens behind the scenes.
Is every one of that y hat is quite a long, I mean it's quite a thing.
So let's just have a look at the first three predicted values.
Remember we had that 1699, 693 and what the actual values were.
And then what the feature variable values were.
So there we have them.
So let's just see how we did all of those.
So it's 1.699.
That's the predicted value.
Minus 2.617.
That was the actual value.
I square that.
And I square all of those.
And so it's the predicted minus the actual square.
Predicted minus the actual.
But each of these predictions remember had to be calculated first.
So there we go.
I've written it all out again for you.
To show you it's 0 plus 10 times that minus that squared.
So it's all of those.
Now the 0 is something we just guessed at the moment.
And the 10 is something we just guessed.
But we don't know this to start off with.
Specifically if we have 5, 6, 7, 8, 9, 10 plus feature variables.
We're going to have a lot of these unknowns.
Because everyone will have that x sub 1 there.
There will be more of them.
And each of them will have to have its own beta in front of it.
So we're going to run into problems.
We weren't just able to look at it as we did there in two dimensions with a single feature variable.
And just guess sort of where that line should be.
But let's create a function in Julia.
It's function.
And then the function keyword.
And then I'm going to give it the name MSE.
It's going to take y underscore hat and y.
And it's just the sum of y hat minus y dot squared.
The dot power, I should say.
The dot power there means each one of the elements in the vector.
Because y hat is a vector.
Y is a vector.
It's going to broadcast.
It's element wise minus element wise.
But each one of those elements I want squared.
So it's dot square.
And then I divide by how many there are.
So that's just a code representation of my mean squared error there.
So let's look at the mean squared error for my model at the moment.
And we see it's 3.97.
So that is the average error, the average residual that we have at the moment.
And it's squared.
So because we just square all of those, we don't take the square root of it.
So it's mean squared error.
So that's the average of the square.
Now, that was just my guess.
I'm going to move away a little bit to normal statistics now.
Moving away from what we're trying to achieve here is just for you to understand gradient descent
and how to code that in Julia.
Let's just go back to statistics just a little bit.
The worst case model is the one where we just have mean.
Now, it's not the worst case.
You can draw very bad lines, which is even worse.
But we're always going to compare against the base model.
And in statistics, the base model just uses the mean as your prediction.
So I'm taking all my target variables here and I'm just calculating the mean.
That's 4.7.
And all I'm going to do now is repeat that 50 times so that I have a vector of 50 values.
They're all going to look exactly the same.
And let's look at what the mean squared error is if all my predictions are just the mean of my target variable.
And we see that's quite high.
The mean squared error now of this mean model is 12.28.
That's quite a bit higher.
So that means the average of the square of my residuals is quite a bit more.
And we can actually compare a model that we have created to the baseline model.
And there is that comparison.
So I'm just writing out the word comparison there.
You take the mean squared error of your base model.
This is the one that just uses the mean for all its predictions.
It doesn't have a beta sub 0 plus beta sub 1 times x.
Is this the mean?
You subtract from that the model's MSE and you divide by the base.
And that gives you a comparison between your model and the base.
How much better is it?
And that comparison, as you can see here, we usually call that r square or the coefficient of determination.
And if we multiply it by 100, of course, we get that as a percentage.
And we can say that our model predicts so much of the variance in our variable.
So we see that it's 67.
So we can say that our model with a beta sub 0 of 0 and beta sub 1 of 10 explains 67.7% of the variance in the target variable.
And that's just how we express those.
That's just normal statistics.
That is how we would evaluate our model.
And we wanted, of course, to explain 100% of the variance.
But that would be an r squared value of 1.
That's the highest it can go.
And, of course, 0 is the lowest that it can go.
That's very bad.
Your model is then very bad.
It's just the same exactly as the base model then.
So there we go.
That's just a little bit of statistics.
Back to this idea of gradient descent, this functional age of AI.
And remember I said we can express how bad we are with a function.
Now, let's create a very easy function to work with.
And there we go.
F of x equals x squared minus 10 times the sine of 2x plus 12.
And you can see that green thing there.
Now, just imagine for one second that this is our cost function.
Now, we know it's not our real cost function because we already have two unknowns in our cost function.
Remember when we expanded it up here, we have beta sub zeros and beta sub ones in there.
Those are the unknowns in my function.
X sub one, that's given.
I know for every sample what the x value is and the independent value is and what the y value is.
So don't get your x's and y's confused with what we did in school algebra.
The unknowns are beta sub zero and beta sub one or the y equals mx plus c, m and the c.
Those are the unknowns that I'm looking for.
So imagine I don't have two of them, the m and the c.
I'm only looking for one of them.
And I'm just looking for one of them.
So I'm going to rewrite something in school algebra.
So either the beta sub zero or the beta sub one, one of them.
And imagine that my loss function looked like this.
The whole loss looked like this, which means I can plot it here just as a single variable graph.
And there you see the green one.
And what we're trying to achieve, remember, here is we want to minimize this function.
Now, just to look at it as very easy.
We see here m is right at the bottom.
That's the minimum.
So whatever the value that I read off of here from the bottom,
which will be either beta sub zero or beta sub one, whatever the case is,
that will genuinely just be the value for that variable that will give me the lowest cost function.
Now, I should just go back and very quickly say what is the difference between loss and cost function.
People use them interchangeably.
This will be the loss.
That y hat minus y squared, that's the loss.
The difference, the squared difference between the predicted value and the actual value.
But if I sum over all of them and divide it, that's my total cost.
That's all the losses, all the individual losses combined.
So that's the difference between a loss.
A loss is where it's just a function that just looks at one sample.
And if I combine all the samples together, all the losses together, that's the cost, the cost function.
So right here we are with a cost function.
And it's very easy to find that minimum.
Of course, now just looking at it like this, I can just look at the picture and tell you it's down here by m.
That is where, because on the y-axis, I have cost now.
And on the x-axis, I have different values, possible values for my beta sub 0, beta sub 1, my unknown.
And I can just look that it's there.
But in reality, of course, it's not that easy.
So how do we get to this point if it wasn't that easy, if we didn't have this nice graph to look at?
Because we've got other problems here.
We've got other local minima, which an i there, k, o.
Those are local minimum, but the global minimum is at m.
So how do we get there if we can't see this graph?
Well, what we do is we just start anywhere randomly.
And I've started in this instance here by b.
I can start anywhere, but I'm starting at b.
And I'm going to use the derivative.
Now you've got to know a bit of linear algebra here, of course, as I mentioned.
And you've got to know a bit of differentiation, of calculus.
So I've just started here, be blindly.
But I can imagine this is a valley, and I'm just trying to walk to the bottom of the valley.
How do I get to the bottom of this valley?
Well, if I stand there, I'm obviously on a slope.
And I know I want to get to the bottom of this valley, so just go down the slope.
As easy as that.
And slope...
I mean, in real life, think you're walking down in a valley.
A slope is a slope.
You walk downhill to get to the bottom.
You don't walk uphill to get to the bottom.
Well, sometimes you have to, because you can see here from o, I'll have to go up to n to get down to m.
But let's just imagine you just want to walk downhill now.
And fortunately, in calculus, we can also use the slope, which is the first derivative.
So if I know what the first derivative is there at b, it slants downhill.
And I can use that fact to get to a better value.
So if I go from b straight down here, it'll be 4 point something.
But I know I want to get to this one here, the 0 point, say 0.7, somewhere there.
And if this slope here, this line, if you remember from school, from calculus, that's a positive slope.
So that's a positive value.
That's a positive m value.
Or a beta sub 1 value.
If I use that somehow to change this, iteratively change where I am at the moment.
At the moment, I'm here by about 4.1.
To change that to something that's more negative.
Now, my slope is a positive at the moment.
So if I take x to get it to a smaller value of x, I've got to subtract something from that.
So let me just subtract from that the slope that I have there.
And that's what we get to down here.
So my x sub nu is to start where my x sub old was and subtract from that df dx.
That's the first derivative of my cost function there with respect to x.
Just subtract that from that.
And because that df dx at the moment where we stood here, b is positive.
I'm going to have x old and I'm going to subtract from this a positive value.
Which means my x nu is going to be slightly smaller.
So I'm going to get going in the right direction.
If I was way over on the other side, say up here on the far left hand side to the left of i here, my slope would have been negative.
But a negative times a negative is a positive.
So using that slope, if this slope was a negative here, so a negative type of negative is a positive.
So if I was way out here on the negative x axis, I would have moved towards the right.
So the slope is always going to help me go in the right direction.
But we do add this little step size there.
We don't want to move.
We don't want to take a giant leap.
I mean, imagine you are a big giant and you're much bigger than you are now and you're just walking in this valley.
You can take a huge step, but you might make it so big that you walk straight over to the other side of the valley.
That's not what you want because every time you step now, you're just going to jump back and forth, back and forth.
And that's a very bad thing with gradient descent.
So we add this little step size.
We call it the learning rate.
And we usually make it quite small, maybe start at 0.03, so that we take itty bitty little steps
because what we want to do is not overshoot the minimum.
So we just always multiply that.
But I think you can clearly see how we can use the first derivative, the slope, to guide us always into the right direction.
Now, you can see the two problems here.
One we've discussed, you're going to end up in this local minimum, not the global minimum.
And that is a problem in gradient descent and deep learning.
And there's all sorts of extra things we can do, regularization, et cetera, to help us out with that.
In practice, though, it's not the worst thing.
And as much as we don't want a perfect model, we never want our model to memorize our training data,
we want it to generalize to unseen data.
So it's not as big a problem as you might imagine.
But still, some models can be severely affected by continuously ending up in a local minimum instead of a global minimum.
And just for now, remember, it's not the worst thing.
And that's all we do.
But now you're going to tell me, well, we don't just have one.
We don't just have one unknown.
We have two unknowns in this instance, a beta sub zero and a beta sub one,
which we have to find the best value of in our cost function.
So here we have very simple x squared plus y squared.
That's what I did to create this little bowl here.
And it's now in three dimensional space because I have two variables, not just one anymore.
But fortunately, we have partial derivatives.
I hope you can remember what partial derivatives are.
So here we go with partial derivatives.
And you can see that if I keep one of my two variables constant,
and that represents either this pink or the green one.
If I keep one of them constant, it cuts through my shape.
And you can see here this black line that comes down and becomes dotted on the side.
That's where this green is intersecting my cost function.
And there I just have a nice parabola again.
Or this red one is intersecting here in the front.
And that's just a parabola.
So I can look at them individually and just step in the right direction for each one of them.
And if I combine those steps, I am really going downhill towards the bottom of my cost function.
And no matter if I'm in a hyperspace with many, many more feature variables,
that means I'm going to have many, many more unknowns.
I can find each of them by just one step at a time, keeping all the other ones constant
and just taking the partial derivative, in other words, of the one that I'm interested in.
And so I'll just go through all of them individually and just update all of them again.
Because this X nu here, that just represents either beta sub 0 or beta sub 1.
And if I had more, beta sub 2, beta sub 3, whatever.
I just update all of them individually by keeping everything else constant.
And that's what we do with a partial derivative.
And partial derivatives are very easy if you have multivariable function
because all the other things are just constant.
And taking the derivative of a constant is very easy.
So no problem there.
We can just scale things up as large as we want them.
And if we continuously walk down the slope, that is how we're going to find our minimum.
Now comes the bit of linear algebra.
You've got to understand a bit of linear algebra.
Now what I'm going to do, remember I said we had a bit of a problem with beta sub 0
because we want to add two vectors to each other and beta sub 0 is just a single value.
Ours was very easy, it was 0 at the moment.
But I've actually got to have a whole vector of them
because I can only add two vectors to each other or subtract them from each other.
And that was my loss function resulting in my cost function if the two vectors are equal size.
So my y pred and my y actual have got to be exactly the same size
because I have to have element y subtraction.
So that's very easy.
We just, right in the beginning, add a whole new column of ones.
A constant of 1.
Because beta sub 0 times 1 is still going to be beta sub 0.
But now I have a scalar beta sub 0 that I'm multiplying by a vector of all ones
that gives me a vector of that length.
Very neat.
So I'm changing my x, which was a vector of 50 elements, into a matrix of m times 2.
m was 54.
So this will be a 50 times 2 matrix.
50 rows and 2 columns.
I still have x sub 1, x sub 2, all the way down.
That's still all my feature variable values.
But I've added a column of 1.
And then I'm going to make another column vector.
And that vector is going to hold my two unknowns.
Beta sub 0 and beta sub 1.
And I'm going to call that theta, which is a vector.
You see the underlying there.
And then my prediction becomes a matrix times a vector.
And if you know anything about linear algebra, you know that in this order, the column number
there has got to equal the row number there.
Otherwise, you can't do matrix vector multiplication.
And the result is going to be take the rows from that one and the columns from that one.
So we're going to end up with a m times 1 or 50 times 1 vector.
And that's exactly what we want.
So y hat is just going to be the matrix x, which is a 50 times 2 matrix for us, times a 2 by 1 column vector.
And that gives us a 50 times 1 column vector.
And that's exactly what we want.
We want those 50 predictions.
So if we wrote our feature variables as a matrix, adding the ones right in the front.
And we add and we write our unknowns as a column vector.
And we do matrix vector multiplication.
We're going to get exactly what we want.
Beta sub 0 times 1 plus beta sub 1 times x sub 1.
Next one.
Beta sub 0 times 1 plus beta sub 1 times x sub 2.
That's what matrix vector multiplication does.
And that gives us, now times 1, we can just drop it.
So it says beta sub 0 plus beta sub 1, x sub 1, beta sub 0 plus beta sub 1, x sub 2, etc.
All the way down to 50.
That is how we get our predictions.
So that will make for very easy to write code.
Because it's very easy to do matrix vector multiplication in code.
And then also my loss function here.
Remember, I'm going to write my loss function here.
And it's going to be another vector.
And it takes theta as an input, which is going to be an m times 1.
And that's this y hat minus y.
A 50 element vector minus a 50 element vector.
And that's still going to result in a m times 1 or 50 times 1 vector.
So that's beta sub 0, beta sub 1 minus y sub 1.
And then the second one and the third one.
So that makes it very easy to create these things.
So my prediction is this going to be x times theta.
And my loss is just going to be that x times theta, which is y hat minus y.
Very easy.
So let's look then at this mean squared error thing here.
Now, we don't use mean squared error.
We actually use half mean squared error.
So we add this half term.
Remember, it was everything divided by m.
I sum over all of those and just divide by m.
But we actually divide by, multiply all of that by a half.
Now, that doesn't make a difference to finding a minimum.
Because all I'm doing, I'm just scaling my cost function by a half.
I'm just scaling it by scalar.
It's not going to change anything.
I'm still trying to find the minimum of this thing, this cost function.
But putting the two there makes for much easier partial derivatives.
And you'll see that later.
So if I write it out, I'm going to have this idea of this l, which was my loss.
I'm going to take its transpose times itself.
Now, if I do the dot product between a vector transpose and a vector, what am I doing?
I'm squaring each because I'm just multiplying each term by itself.
And take a piece of paper and convince yourself of that.
If you take a vector, a column vector, and you take its transpose, which now makes it a row vector.
And a row vector times a column vector, if that's the same vector, that is just element-wise squaring of each one and adding all those squares.
That's what a dot product does.
It's element times element, plus element times element, plus element times element.
And that's such a neat way to do the difference squared.
And if we were to write it out, remember this is what it would look like.
It's 1 over 2m.
So that's beta sub 1 plus beta sub 1, x sub 1 minus y sub 1, all squared.
And then the second example, the second sample, all the way down to the 50th or the last one.
That is what we have at the moment.
If we just did this transpose, as I said here, and just all these matrix multiplications and subtractions, vector subtractions that I've talked about there.
And then this transpose times itself there.
That's what I end up with.
And now let's square all of these.
And you see I end up with something like this.
This whole long term.
beta sub 0 squared plus beta sub 0, beta sub 1, x sub 1 minus beta sub 0, y sub 1 plus beta sub 0, beta sub 1, x sub 1 plus beta sub 1 squared.
Just convince yourself to square all of those things.
That's what we end up with.
And we still have the 1 over m.
But we do it by a half, so 1 over 2m.
And that eventually gives us a cost function.
If you just look at all these ones and twos and threes as subscripts, I can write that all as a summation.
And there is my summation.
And now it becomes very easy to take partial derivatives.
Remember this whole long thing now is my multidimensional cost function and I'm trying to minimize that.
So here I have my cost function and I take the partial derivative of that with respect to beta sub 0.
And I take my partial derivative of beta sub 1 with respect to beta sub 1.
And you can see I've done it for you there.
There's the one, there's the other one.
Pause and see if you can do it yourself.
If you can't do it just from the summation notation here, which is actually very easy if you think about it.
If you take this one here and just take from that the partial derivative with respect to beta sub 0, you're going to get that.
And you see if I bring the twos out, that 2 would cancel and that's why we put that 2 there.
Because now we have this very neat, a very neat update.
And remember this is the derivative that I'm going to use, the slope that's going to help me walk in the right direction.
We do the same for beta sub 1.
And now we just have this beautiful thing where we have the column, old column vector, the beta sub 0, beta sub 1.
Yeah, I should say, right there.
And I subtract from that, element wise, my little learning rate times 1 over m times these partial derivatives.
And I'm going to do that with respect to beta sub 0 and beta sub 1.
So this is going to be a column vector equals a column vector minus another column vector.
And they're each 2 by 1s.
And that's it.
As simple as that.
And then in code, if we go back all the way, that is what it looks like.
All the steps up till now.
That is exactly what we have.
So we're going to have this loss, which is going to be x times theta minus y.
And the cost function is then the 1 over 2m.
And to get all that element wise things, it's the loss transpose.
That little apostrophe is transpose times the loss.
And to update, I take my old beta sub 0 and beta sub 1.
So there, that beta sub 1.
I subtract from that alpha over m times this x transpose times the predicted minus y.
That's going to be the cost function.
And we're going to move away from the notebook here.
I'm going to do it with pen and paper.
Well, actually, I do have a screen that is a tablet.
And I'm going to write on that instead of pen and paper and recording the pen and paper.
And I'm going to convince you that this line of code is nothing then using all of these.
I'm going to convince you that those are the same.
So what I want to convince you of is that this piece of code that we saw in the notebook.
So I take theta, which is just going to be this two column vector.
There we have it.
Beta 0 and beta 1, our unknowns, equals theta.
Now remember, in the world of computer languages, we evaluate the right hand side and then we assign it to the left hand side.
So theta equals theta.
So we're going to start with the old theta that we have minus.
We have alpha, our step size or learning rate divided by m, the sample size.
Multiply that by the transpose of x.
And once we've done that, that is multiplied by the difference between the prediction and the y.
And you know what that pred and y and x and alpha and m and theta are from the code.
And I want to show you that that's exactly the same as what we did here.
So what we have is just a bunch of column vectors.
So we're saying that this old, where we stand at the moment, column vector, minus, and we have here a constant.
That's this alpha divided by m.
And if we multiply that by a column vector, it's just like broadcasting.
It's going to multiply, it's going to scale a multiplication with a vector.
So it's just going to multiply each of the two.
And on the top, we have the partial derivative of the cost function with respect to beta 1.
And the partial derivative of the cost function with respect to beta 2, beta sub 1, I should say.
So I have two 2 by 1 column vectors.
I subtract one from the other one.
And what we're doing here, in essence, remember, it's one line by one line.
So what we've got here is beta 0 equals beta 0.
So whatever beta 0 is at the moment.
And we're going to subtract from that alpha over m times the partial derivative of the cost function with respect to beta 0.
And then separately from that, we do beta sub 1.
That equals beta sub 1 minus alpha divided by m.
Partial derivative of the cost function with respect to beta sub 1.
So those are two separate equations.
It's a linear system.
And hence, we can write it as these column vectors.
And I want to convince you that this is nothing other than this.
That that is what we are writing.
So let's start off by looking at...
Let's go back to blue.
Let's do the pred first.
So we see pred there.
And remember, we said that that was equal to x times, in our code, times theta.
So that was just x times theta.
Let's just have a look at the dimensionality of this.
Remember, this was a m times 2 matrix.
That was a m times 2 matrix.
And this is going to be theta, which is just going to be a 2 by 1 column vector.
So that was a column vector.
And if we multiplied those two out, what was it going to look like here?
Remember, the x was just 1, 1, 1, all the way to 1 at the end.
And this was going to be x sub 1, x sub 2, x sub 3, all the way down to x sub m.
That was our matrix.
And we're going to multiply that by this column vector, b sub 0, b sub 1.
And what does that multiplication give us?
Well, we've got a matrix times a vector.
And so we can do that multiplication because, look at this, that 2 equals that 2.
And what we're going to get out of it is an m by 1 column vector.
That's exactly what we want.
So let's just do that.
So what we're going to have here in the end is that very simple thing in as much as we just multiply those out.
So that's going to be beta sub 0 plus beta sub 1, x sub 1.
And beta sub 0 plus beta sub 1, x sub 2.
And remember, there should be a beta sub 0 multiplied by 1 every time.
But anything multiplied by 1 is this 1.
And at the end, we're going to have beta sub 0 plus beta sub 1, x sub m.
And from that, we subtract y.
So again, that's element y's.
So this is going to be minus y sub 1, minus y sub 2, all the way down to minus y sub m.
And this is a column vector, a m times 1 matrix, or column vector.
So that makes it really easy to do.
Now, let's see what is happening on this side.
Alpha divided by m times the transpose of x.
So what does the transpose of x look like?
Well, the transpose of x, here we have matrix x.
So x transpose, well, that's just going to be the columns and the rows swap around.
So this is going to be 1, 1, 1, all the way to 1.
And this is going to be x sub 1, x sub 2, x sub 3, all the way to x sub m.
So this now becomes only two rows and m long.
And we're going to multiply that out by, we're going to multiply that out by, this alpha over m.
So all we need on this side is just alpha over m, that we're going to multiply this with.
And if we do that, we have alpha over m, alpha over m, alpha over m, all the way to the end, alpha over m.
And here we're going to have alpha over m x sub 1, alpha over m x sub 2, alpha over m x sub 3, all the way to alpha over m x sub m.
And there is our, still 2, 2 by m matrix.
Now, what we have here, we have to multiply that by what we have here.
So these two have to be multiplied by each other.
There we go, they have to be multiplied by each other.
So this is a 2 by m, 2 by m, this is a m by 1.
Where are we going to end up with?
Well, let's keep it in pink, we're going to end up with a 2 by 1.
And that's exactly what we have, because this here is 2 by 1.
That is our beta sub 0, beta sub 1 column vector.
So if we multiply these two out with each other, that's just going to be quite a long stretch of things that we have to do.
So let's have a look at it.
So it's going to be each one of these x sub m's.
And we're going to multiply that with each of these.
So what we're going to end up with here is an alpha over m.
And then we're going to have beta sub 0 plus, this automatically makes that little, here we go, beta sub 0 plus beta sub 1, x sub 1 minus y sub 1.
And that's the x sub m for those.
And we have to carry on, we have to carry on with this.
Plus alpha over m, and then in the end we're going to have x sub 2 minus y sub 2 after all of this.
And it just carries on and on and on and on and on and on and on and on.
And then for number 2 here, for number 2 we're going to have the alpha over m and we're also going to have the x sub m.
And then the beta 0, beta 1, x sub 1 minus y sub 1 plus alpha over m, x sub 2 and beta sub 0.
Let's go on on this side, let me just make some space so I don't do that again.
Plus beta sub 1, x sub 2 minus y sub 2 plus alpha over m, x sub 3.
Oops, that is not an x.
x sub 3 and we just carry on like that to the end.
But what we're left with here in the end is a 2 by 1, is exactly a 2 by 1 matrix.
Most importantly we can just shorten this, we have beta sub 0 and a beta sub 1 on this side.
And that is going to equal beta sub 0, beta sub 1 minus what we have here, these two.
And if we shorten that, this is going to be basically an alpha over m,
because that's just a constant multiple with broadcasting.
Here we're going to have the sum from i equals 1 to m, because we've got m samples.
And that's going to be a beta sub 0 plus a beta sub 1, x sub i minus y sub i.
That's what we have every time.
It's just the 1 and the 1 and then the 2 and the 2.
That's the only thing that changes.
And for beta sub 1 we're going to have the sum of i equals 1 to m.
And all we're going to have here is an x sub i.
And here we're still going to have the beta sub 0 plus beta sub 1, x sub i minus y sub i.
And that is still a 2 by 1 column vector there.
So we have a 2 by 1 column vector, a 2 by 1 column vector, and just this constant multiple of a 2 by 1 column vector.
And everything works out.
We can subtract two 2 by 1 column vectors from each other.
Now, let's go about it from the other way.
Remember we had the mean squared error, actually the half mean squared error.
So let's have a look at that.
That's going to be 1 over 2m, remember.
And then it's the sum of i equals 1 to m.
And we're going to have y hat minus y, those two vectors subtracted from each other.
So that's just the i there and the i there and we square them.
That's exactly what we want.
And we remember of course, let's go back to orange, this is 1 over 2m.
And we have still the sum of i equals 1 to m.
And how did we get y hat?
Well, we got y hat.
All we did was we said x.
And remember that was an m by 2.
And then we multiplied by theta, which is a 2 by 1.
So we end up with a m by 1, which is exactly what we want.
And then we subtract from that just y, that vector.
And of course, we just have to square each of those.
So we just have to square each of those.
And remember that we are going through each of those i's.
And for this multiplication here, that is going to give us an m by 1.
So this is 1 by 1 of them, square them, and then sum them.
So let's have a look if this works.
Because if we go y hat and we do sub i, remember that is going to be beta sub 0 plus beta sub 1 x sub i.
That's exactly what we have there.
And if we look at the whole y hat as a vector, that's going to be beta sub 0 plus beta sub 1 x sub 1.
Remember?
And then beta sub 0 plus beta sub 1 x sub 2, all the way down to beta sub 0 plus beta sub 1 x sub m.
So that's our whole column vector, so for all of them.
And what did we do then?
Well, we had this loss, this idea of a loss function.
And that was just y hat minus y.
If we can think about that as two column vectors.
And all that is, is just all of these minus beta sub 1 x sub 1 minus y sub 1.
And beta sub 0 beta sub 1 x sub 2 minus y sub 2, all the way down to beta sub 0 minus beta sub 1 x sub m minus y sub m.
And that's still m by one column.
And that was our loss, remember.
But we didn't want that.
We want each of those squared.
So what do we do?
Well, we said take the loss as it stands now, take its transpose and multiply it by the loss again.
So the transpose of this was going to be this whole long thing, beta sub 0 minus beta sub 1 x sub 1 minus y sub 1 comma, and then beta sub 0 minus beta sub 1 x sub 2 minus y sub 2 comma, all the way.
down to beta sub 0 minus beta sub 1 x sub 2 comma, all the way down to beta sub 0 minus beta sub 1 x sub m minus y sub m.
There we go.
And that is a m by 1.
And what are we going to end up with?
Well, we're going to end up with a 1 by 1.
And that's exactly what we want.
That is our part of our mean squared error.
We just have to divide by 1 over 2m.
But how this works is it's the square.
That one is exactly the same as that one.
And this one is exactly the same as that second one.
So we're just squaring each of those and adding all of them up.
And that's exactly, that is exactly what we want.
Because in the end we have this idea of the loss squared.
So let's do that exactly.
Let's make this loss squared and just see what it looks like.
So it's this squared, because there's this one multiplied by that one and this one by that one.
So let's just see what it starts to look like.
It's going to be beta sub 0 multiplied out with me.
So that's beta sub 0 times beta sub 0, that's beta sub 0 squared.
Plus beta sub 0, beta sub 1, x sub 1.
Minus beta sub 0, y sub 1.
So I've multiplied all of those out.
And then for the next one.
So that's going to be beta sub 0, beta sub 1, x sub 1.
Plus beta sub 1, x sub 1, y sub 1.
Minus beta sub 0, y sub 1.
Minus beta sub 1, x sub 1, y sub 1.
Plus y sub 1 squared.
So it's all those three terms multiplied throughout by all those three terms.
So in other words, beta sub zero minus beta sub one,
x sub one minus y sub one, we multiplied that by itself.
Beta sub zero minus beta sub one, x sub one minus y sub one.
If you multiply all that out, that's what you're going to get.
And it just obviously carries on because now we do the second term
and the third term and the fourth term, etc, etc, etc.
So in the end, if we have the mean squared error, that was going to be one over two m
and we're going to sum it from i equals one to m, all of them.
And if we just group these terms together, if we just group some of these terms
and just remember that we're going from one to two to three all the way to m,
we can just bring them all together in a summation.
So it's going to be beta sub zero squared plus beta sub zero, beta sub one, x sub i,
minus, we're going to have beta sub zero, y sub i is the c,
and we have beta sub zero, beta sub one, x sub i.
Let's just do all of those.
And we can see here we're going to group all of them in the end.
And we have a beta.
Let's just give ourselves some more space.
Beta sub one squared.
We're going to have an x sub i squared minus beta sub one, x sub i, y sub i.
And we're going to have another, let's just give ourselves more space.
You need a lot of space for this.
Beta sub zero and y sub i.
We've got that one minus we've got beta sub one.
We've got x sub i, y sub i.
So that we'll have two of them in the end.
And then all the way in the end we have y sub i squared.
So let's clean those up because we can certainly group some of those terms.
So we're still going to have here one over two m.
We're going to have the sum from i equals one to m.
And if we grouped all of them, if we grouped all of them together,
we're going to have this beta sub zero squared.
We're going to have two times beta sub zero, beta sub one, x sub i.
We're going to have minus two times beta sub zero, y sub i.
And we're going to have beta squared, beta sub one squared.
We're going to have, no, that's not right.
Beta sub one squared, x sub i squared,
minus two times beta sub one, x sub i, y sub i,
and plus y sub i squared.
That's all neatly cleaned up.
So all we've done, there's one term, there's another term,
so there's two of them, etc.
So we just start cleaning them up.
So that's our mean squared error.
That is, in the end, that's our cost function of two unknowns.
And for all i equals 1, 2, 3 up till m.
And that's our cost function.
And all we have to do is take the partial derivative of each of these separately.
So let's do that.
Let's take the partial derivative of the cost function with respect to beta sub 0.
Well, that's 1 over 2m.
The summation for this kind of derivation or derivative stays exactly the same.
And we're treating beta sub 1, our other unknown, as a constant.
So this is going to be 2 times beta sub 0.
It's the first derivative of that.
What remains from this one is going to be plus 2 times beta sub 1 x sub i.
Because there's a 1 power there, we bring it to the front.
This becomes 0, so that goes away.
Here we have minus 2 times y sub i.
That's all we have there.
And now remember, look at all this.
That's why we put the half term there, because now I can take these 2s.
I can take all of them away.
And they're all gone.
And there's my partial derivative, very simply, partial derivative with respect to beta sub 0.
Let's do the partial derivative of the cost function with respect to beta sub 1.
And if we do that, that's 1 over 2m.
We have sum over i equals 1 to m.
And we're going to have 2 times.
So that's a constant.
So derivative of a constant is 0, because we're only doing it with respect to beta sub 1.
So there we're going to have 2 times beta sub 0 x sub i.
As simple as that.
And what remains for us, right?
Here at the end, that's a constant.
And there we have another term.
So that's going to be plus 2 times beta sub 1 x sub i squared.
And right at the end here, we're going to have minus 2 times beta sub 1 x sub i y sub i.
Again, I can get rid of the 2s.
That's why we did the half.
This makes it all nice and neat.
And the other thing that I can also do, you see they all have a common factor.
So I can say that the cost with respect to beta 1 is going to be 1 over m.
And we sum from i equals 1 to m.
And we have x sub i there.
And that's beta sub 0 plus beta sub 1 x sub i minus beta sub 1 y i.
Of course, you see the little mistake that came in there.
There we have 2 times beta sub 1.
And if I take the derivative of that, of course, there should be nothing left there.
There we go.
That looks much better.
And if we go all the way back up, that's exactly what we have here.
That's exactly what we have here.
Nothing other than that.
So with our code and with doing it by hand, we get to exactly the same thing.
We get to exactly the same thing.
In other words, we really have, let me write neatly, beta sub 0, beta sub 1.
That's going to be beta sub 0, beta sub 1.
And we subtract from that alpha over m times this idea of the partial derivative of the cost function with respect to beta sub 0
and the partial derivative of the cost function with respect to beta sub 1.
That's exactly what we're doing.
It's a linear system in two equations.
And we see that's exactly the same thing that comes from this line of code that we have right up here.
That is exactly that line of code which gives us exactly this thing.
And that is what we want to do with gradient descent.
So let's get back to the code.
So now that you're convinced that they're the same, let's have a look at what it would look like.
Function is cost function.
It takes x, y, and theta.
My m is just the size of x, the first of the tuple because it's going to be row, comma, column.
The loss is just x times theta.
That gives me my y pred minus y, which makes my cost function exactly what I showed you right up there.
It's a simple line like that.
So if we run that, I have a cost function.
And now I've got to do gradient descent.
So I'm going to call my function here linear reg gradient underscore d.
You can see, you can give it a name.
It takes x, y, and alpha.
And then a fit intercept is true.
And a number of iterations, we're going to do 5,000.
So length is still going to be my number of cases.
It's going to be m.
That's the length of y.
And if fit intercept, which we are going to set to true, I'm just adding a constant of ones.
And I'm going to add 50 of them at the moment of ones.
And I'm just horizontally concatenating that.
The constants are all the ones to the x.
And that's how I just get all of those.
If not, it's just going to use x.
So you'll see that quite commonly.
But in our instance, we want those ones.
Otherwise, things are not going to work out for us.
So n is the number of columns.
So that's going to be size of x.
The second one, row comma columns.
At the moment for us, it's going to be 2.
And then I've got to have random guesses.
I've got to start beta sub 0 and beta sub 1 some way.
And I'm just going to start it with two zeros.
So it's two zeros on top of each other.
Column vector of two zeros.
And then I'm going to have just this little placeholder of 50,000 cost values.
Because each time I'm going to have a cost value of the 5,000 times that I'm going to run over this.
Remember, every time I'm going to get better and better and better values for beta sub 0 and beta sub 1.
Because my gradient descent is going to walk towards having the minimum cost function.
I'm just creating a vector there with all zeros.
And then for iter, this is my keyword there or my variable name there,
just to run through this range of 1 to 5,000, I said.
The pred, remember, is x times theta.
And then I'm going to start overwriting each one of those 50 empty or zero values by the cost function.
Given what my best theta is at the moment, and we're starting at 0, 0.
And then we're going to update it so that we have mu beta sub 0, beta sub 1.
And then I run through all of that again.
The next time my pred is going to be slightly better and my cost value is going to be slightly lower.
I'm going to run through this 5,000 times.
And in the end, I want this tuple returned of my vector of unknowns, beta sub 0, beta sub 1.
And then the 50, or the 5,000, I should say, values of my cost, what the cost function was.
And hopefully that is going to come down.
So let's run that.
Let's run that here.
We're going to run that 5,000 times.
And because I'm returning a tuple, I'm just going to split them up so that I have them separately.
So here, what I want here for cost values is just the second one, the J there.
And my time step is going to be 5,000 of them as well because I just want to plot this.
I want to show you.
See how quickly that was?
Let's plot that.
We're going to plot that.
And there we go.
My cost started quite high.
And every step that we took, my cost came down, down, down.
And until here by 5,000, my cost was very low at 1.92.
That's a beautiful iteration.
I see I didn't make use of this time step there.
I could put the time step there, but I just used that range there, 1 to 5,000.
So I needn't have put that.
But I want my 5,000 cost values, and you can see how it comes down.
Let's see what my theta values look like.
That was going to be the first of the tuple that got returned there, theta.
Let's store that in a computer variable called PARM's show for parameters.
And we see a beta sub 0 of negative 0.03 and a beta sub 1 value of 9.43.
Isn't that beautiful?
And let's just plot that.
And you see there's my model.
Very close to the one I guessed at before, but this would now be after 5,000 iterations.
It's really getting close to the minima for those two unknowns.
So we've used gradient descent to get to this model.
Now let's just use the GLM to see another way to do this.
Now I'm not going to run through the explanation of that because this was about gradient descent
and how to code it inside of Julia.
But let's just use ordinary least squares.
So I'm not going to explain what ordinary least squares are.
I've got a YouTube video on how to get to that.
But this would be another way to get to the best values of theta.
And that just takes x transpose times x, the inverse of that, times x transpose times y.
Or if you break that up, and that's the video that I really explained this,
how to get beta sub 0 and beta sub 1.
But this is going to be only for a single feature, only for a single feature variable.
And you can see there how to do beta sub 0 and beta sub 1.
So I'm going to use, we've imported the GLM function.
Well, first of all, I should say we've got to write this as a data frame.
So I'm going to have two columns in my data frame, feature and target.
And feature is going to be all the x values, and target is going to be all the y values.
And then I'm going to use the LM function in GLM.
That just stands for linear model.
And we're going to use at formula.
And then we're going to say target dependent on feature in the data frame DF.
So that's just the syntax of that.
And I'm going to store it in a computer variable called OLS, because this is ordinary least squares.
It's going to make use of this equation.
The ordinary least squares for beta sub 1 and beta sub 0.
And then let's just have a look at that.
If we use this beta sub 0 and beta sub 1 equation there, well, so my OLS is still running,
because it's got a low GLM.
And there we go.
It finds, there's our estimates.
Our intercept is minus 0.15.
And my feature, my x variable, my 4 beta sub 1, its value is going to be 9.64.
So those would be the best values.
We can see a p value for that.
And we can see the low and upper bounds, 95% confidence intervals there.
But let's use these two equations there.
I've written them out in code.
You can definitely have a look at that.
And then for beta sub 0, I get negative 0.12 and 9.59.
So very close to the optimized code that is used inside of generalized linear models here.
It's slightly optimized from here, but you can see it's very, very close.
So I can just look at the best model.
We can just store all of those.
Look at its MSE and use that MSE to subtract from that.
And that was the R squared, remember, compared to the base model.
We use the R2 function here.
And it's the C0.686.
It's exactly the same.
So the GLM uses exactly the same function as we did before.
Remember the comparison function that we did compared to the base model.
So this is back to normal statistics.
We can say the best fit model explains 68.6% of the variance in our model.
So that is it.
Gradient descent, I hope you now understand how to go from the concept of it to the code
and why the code is so easy, but also understand gradient descent itself.
That in AI today, talking specifically about deep learning, that we can write a function.
And that function is a representation of how far away are we from the best possible prediction.
And that we can iterate over this and make the unknowns, the parameters, as we call them,
better and better and better until we get somewhere where, given those values,
given those unknowns, given those parameter values,
that we can predict an outcome quite accurately.
And that would be exactly the same for regression problems and classification problems.
Classification problems in supervised learning, remember that we have a categorical variable
as our target variable.
Here we have regression.
We have a numerical variable as our target variable.
Try this yourself.
Play around with Julia.
Create some or at least bring in some of your own data
and see if you can run linear regression as a model.
