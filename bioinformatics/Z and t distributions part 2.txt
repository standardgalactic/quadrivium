So if you ever want to play with some completely random, now it's not ever really, really random,
there's a little algorithm that your computer uses depending on what millisecond it is at the moment
and other forms, but if you just want to draw some completely random variables,
I'm going to make this computer variable called random underscore variables and np.random.random.
So numpy has a sub-module called random and it has a bunch of distributions
and from that I want the completely random one, as I said it's never ever really random, but it's a random
and I want two thousand of those and let's plot them, plot.figure, plt.figure, fig size, let's make it a bit smaller,
let's make it 8 by 6, that's okay, plt.what type of plot do I want, I want a histogram,
I want random variables to be plotted and I want 50 bins, plot.show, semicolon, there we go,
and now you can see there's no distribution to this, it's just completely normal,
so it would say a value, in that little bunch I got 43 or 42 of those and I've got so many of those and so many of those,
so that's just completely random variables and the random variables come between 0 and 1,
so in decimals from 0 to 1, so you can play with some data there if you wanted to.
Now back to the Z and the T distributions.
Now just think back again, I want you to cast your mind to your thought experiment,
you have two groups of patients, group A and group B, group 1 and group 2, your control group, your experimental group,
and you take a certain variable, again say for instance the Whitesop count, you do the mean of the one group,
the mean of the other group, you subtract one from the other, that's the difference in your means,
and now you want to know was that difference significant?
What was the probability of finding this value and more or this value and less?
That's the question you have and you understand now that your difference that you found was just one of countless others.
Now you've got to tell the computer draw that beautiful graph for me and put my value somewhere and tell me what the area under the curve for that is.
Well the computer can really draw two types of curves, well there's more, but let's stick to Z distribution and T distribution.
So the Z distribution, you tell the computer what the mean and standard deviation is of the larger population if you know it or if you can confidently estimate it.
Now that's very rare in healthcare research, usually we don't know what, outside in the population of 7 billion, 6 billion people,
we don't know what the real, in the population what the real parameter is for a variable.
We just don't know, we have to take a wild guess at it.
If you do know, you can use the Z distribution.
And I promised you I'll never show you equations, but just to tickle your fancy, but there's the equation for it.
You can see the computer's going to use that, so it's going to use standard deviation, it's going to use mean for the population, not for your sample.
And it's going to use standard deviation.
And it's going to do that.
What I've asked for here is, this is just writing out the code for that, and I'll show you what it looks like.
There we go.
No need to worry about the code there, but there is a Z distribution of knowing what the population, all human beings, their standard deviation and mean is for a certain variable.
Much more common for us to have a T distribution.
We know nothing about the population standard deviation in this case.
So very clever people had to construct a different mathematical equation.
Once again, to tickle your fancy, there it is, the gamma function there, it is horrendous.
Can you imagine, that is what is used with the little bit of information you'd have.
All you have is your sample values, and it's mean, and it's standard deviation, and it's difference between the means.
That's all you have.
Statisticians, remember when this was done there were no computers, this was done by hand.
Someone sat down and thought this out.
Now, the tea test, there's a rich history to the tea test, wonderful little history of beer brewing.
We won't get into that now.
But look at this wonderful, fantastic mathematical equation to draw that little curve.
And that curve will look differently every time you take a new sample set.
When it really gets generated through the central limit theorem, it generates a nice little plot.
And it tells you where yours will fall.
Don't worry about it here.
This is, I'm saying again, stats dot t, not norm this time, but t dot random variable give me.
Now this works much differently.
It requires this thing called degrees of freedom.
Not to worry about that at all.
There we go.
We plot it.
And there we go.
T distribution.
Again, normally distribute it.
And it will allow you to do your analysis.
So, it uses this very complicated.
If you know the population's variables.
And if you don't know the population's variables.
Those are the two distributions that get drawn.
And the data from only the data that you have.
And especially with the t distribution.
And it then tells you where your value falls.
And what the probability was of finding a value as extreme as yours.
And that is really the beauty of statistics.
That with very little data, you can infer something about a population if you don't.
And it all falls to that equation there that draws a curve for you.
And from that curve, by the central limit theorem.
It is guaranteed to be symmetrically distributed.
Bell shaped.
And from that, your value will fall somewhere.
You calculate the area under the curve.
And you have a p-value.
Absolutely fantastic.
