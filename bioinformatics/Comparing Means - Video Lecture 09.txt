So in this next notebook, really, we're going to build on what we had before, and I'm going to show
you this idea of sampling distribution, but based only on the data that we have for sample.
We no longer know what the data looks like for the whole population, but somehow we still have
to be able to express our findings in terms of a bigger hole, and how likely was it for us to
find these statistics that we do do, how does it fit into the bigger picture, and can we express
this as a probability of the likelihood or the probability of this result having been found.
So notebook 09, comparing means, and let's have a look at these packages that we're going to use.
Those are the usual ones that we've seen before. We're going to have Google the data table parameter
set there with our percentage load underscore xext, so that we have nice tables printed to the screen,
just specifically here to Google Colab. In case you're running this on a retina display, you would
run that cell there with a percentage config magic command, and we're definitely going to import
a spreadsheet file from our Google Drive, and then the usual suspects, pandas, numpy, and the stats
module from the scipy package, and then all our usual plotly modules. So what I'm going to do again,
you know the drill, I'm going to connect to my Google Drive, and then I'm going to change directory
with a percent CD magic there, and as a string I put this whole folder structure, directory structure,
on my Google Drive so that I can get to the data subdirectory or data subfolder, because that is
where my spreadsheet files live. So I'm going to click this button again, run the cell, I'm going to log
back into my account, and I'm going to copy and paste that security key. And there we are, we're back in
business, and the data file that we're going to work with is this comma separated values file data.csv,
and we're going to use the pandas function read underscore csv, and we're going to assign that
to the computer variable df. So let's do that, and it's going to import that data file for us. Now we
have a data frame, let's just have a look at it, printing it to the screen with that magic command
that we had before, and this is a data set that we've seen before. So let's just have a look at the shape
of that, just so that we know, you know, what our attributes are. So the shape attribute there,
200 rows of data, and 13 columns, 13 variables. So comparing the distribution of a numerical variable
between two independent groups. So let's just be clear about what our research question is. Is there
a difference in heart rate values, so the beats per minute, the heart rate, hr variable, between the
active group and the control group. So we know we have a group variable. There's a column called group,
and remember if we said df.columns, we're going to get a list of those, but we certainly have a group.
If we scroll up here, there's our group. It's a categorical variable, active, active, active,
control, active, control. So the participants here were in two groups, and we're looking at the
heart rate column there. That is the heart rate of these participants. So we want to know if there's a
difference in heart rate between these two groups. Note very clearly that we're making up the group by
the sample space elements of a categorical variable. Group is a categorical variable. It has a sample
space of two elements, so we can generate two groups of participants. Heart rate is a specific
numerical variable, so we're going to compare this very same variable between two groups. And that is
what we mean by comparing the means between two groups. Our groups are formed by the sample space
elements of a categorical variable in our data set. And we're going to take a numerical variable,
and we're going to compare the means. And we're going to get a difference of means, and then we've
somehow got to construct those histograms that we saw before, and we're going to see the difference
that we found. Is it a rare finding, or is it a difference that is not that rare at all? So let's do
that. And remember, we're going to use conditionals here. And I'm not using .lock or .ilock, which I should
actually do, but shorthand notation, we can actually do that. So I'm going to create this
two NumPy arrays. So hr underscore control and hr underscore active, because that's nice and
descriptive. We're working with a numerical variable hr, heart rate, and that is the control
group, and that's the active group. So we're going to say df, and then we're going to use,
go down the df.group, down that column, all the rows, where it says control. So equals equals control,
all the ones that return true are going to be included. And from all those that were included,
that are, you know, have a value data value of control in that group variable, we're going to
take the heart rate, and we're going to convert that to a NumPy array. So .to underscore NumPy,
we're going to use that to underscore NumPy method. And then the same for the active group. So it's
same conditional that we're using here. Now we have two NumPy arrays that we can work with.
First of all, let's get back to basics. In data science, when we look at the data,
the first thing that we're going to do is just do some summary statistics. We've got to start
teasing the story out of the data, get the knowledge that's hidden in the data out. And the first way
that we're going to do is we're going to get these numbers that are representative of the whole.
So let's do that, descriptive statistics. I'm using the groupBy method there. So df.groupBy,
I want to group by the group variable, that categorical variable with its two sample space elements.
And then I want to compare the heart rate, and I'm using the .describe method,
because that gives me a count. So I see there's a hundred participants in the active group,
a hundred in the control group. As far as the heart rate is concerned, we have a mean of 76 in the
active group, and a mean of 72 in the control group. And we want to know, is there a difference
between those two means? And again, I can subtract 76.88 minus 72.43, or 72.43 minus 76.88,
and I'm going to get a positive and a negative number. But it sort of starts giving me the idea
that it really looks like there's a difference between these two groups as far as the heart rate's
concerned. We just have to somehow express if that difference is, you know, is it big enough. We have
to express it in some way. We see the spread of the data there. The spread of the data is sort of even.
We see the minimums there, the first quartile, the second quartile or median, the third quartile,
and the maximum. So we have some idea of the spread of the data. Once we know this little bit of
summary statistics, let's just visualize the data, because that's in actual fact a little bit more
powerful. So there we see a box and whisker plot. So it's px.box. I pass my data frame. On my y-axis,
I want heart rate. So up and down here is heart rate. I want it to be grouped by whatever we find
in the group column. And in that column, we found those two active and control. And the argument that
we're going to use for that is the color argument, remember. And then I'm just setting a nice little
title. So there's a little outlier there. And by now, you know what it means for this lower bound
here, the lower fence. It is 1.5 times the interquartile range. So that third quartile value
minus the first quartile value, multiply by 1.5, subtract that from the quartile one value, and that's
the lower fence. And then certainly this value, the minimum value here, that seems to be in a
statistical outlier. Look at that heart rate, only 24. Obviously something odd going on. And it is
clearly indicated here for us that that might be a statistical outlier. So we've got some idea that
there seems to be this difference between these two distributions. So let's employ the scientific
method called hypothesis testing. And our null hypothesis, we haven't gathered any data. So this
actually should go before we do our study. This goes into the protocol of our research. And we say
the null hypothesis is that there's no difference between the two heart rates. So the heart rate in
the active group equals the heart rate in the control group. And by here we mean the means.
That is our test statistic. And it means if we subtract one from the other, we should get zero. So another
way to put our, or state our null hypothesis is that the difference between the means of these two
heart rates is zero. Our alternative hypothesis is two tailed. Doesn't matter which one, which one we
subtract from which one. We just say they are not equal. Our alternative hypothesis is that these, the
means of these two heart rates are not equal. So let's do that. Let's subtract one from the other. And
that's the order I chose there. So I get 4.45. But remember, this could also be minus 4.45 if I flip that
difference around. And now somehow I have got to decide, you know, is that a meaningful difference?
Is it a real difference? Is it not a real difference? And we've got to build up, you know,
build upon what we have in the previous notebooks. So this time around, we don't have access to the
whole population. This is all we have. But listen very carefully again to our null hypothesis. Our null
hypothesis states that there's no difference between these two groups. Now, if that was really true,
it really doesn't matter in which group the participant was, because our null hypothesis state
that those two are equal to each other. So we can randomly reassign a participant to another group.
We can throw them all into one basket and generate two more groups from those.
Because our null hypothesis states there is no difference between the two. And that's very crucial
if you think about this kind of analysis. Our null hypothesis is based on the assumption that there
is no difference. And if we find a very common difference, we can't reject that null hypothesis.
And our distribution of our statistic is going to be based on the null hypothesis being true in actual
fact. We don't know that. We don't know what the whole population looks like. But we've got to start
somewhere. And our base assumption is there's no difference between those. And we say, given that it's
true, we don't know if it's true. We just say, given that it is true, we can randomly reassign these
participants, doesn't matter what group they are. And we can sample from this whole bunch now.
And we can build a distribution of possible differences, because it doesn't matter which
group a participant is in. A very deep, deep, deep and crucial point when it comes to data analysis.
And I really want for that to sink in, so that you can really understand this. Our null hypothesis,
we assume that to be true. We have no idea whether it is, but we assume that it is,
and hence we can build a distribution based on that assumption. But it is just an assumption.
And I think you're starting to get to what statistical analysis really means.
It is a human, we can always see it as a human construct. We're not really proving a difference.
We've got this framework that we build, and we put a, draw a line in the sand, and we say,
if it's beyond that, then there really was a difference. We never proved that. There was no,
that is just not the way that it works. So let's do this. Now, remember, we have 200 samples in our
data set, and it just happens that they were equal. There was 100 participants in each group.
So what we now say is, let's randomly reassign these people. So we chuck all the 200 into,
you know, into a bag. They're all together now, because our assumption is that they're all the
same. And what we're going to do is the following. We're going to imagine that we could do our study
10,000 times over. You can just pick a large number. And we're going to draw at random 100
participants in the one group, and that 100 remains for the other group. So the same number,
we've got to end at 200. But they've randomly reassigned. They're all in one mixed bag now,
and we just draw those names. No problem whatsoever. So we're going to create this
empty Python list, and I'm going to assign that to the computer variable, mean underscore stat,
and then I'm going to run a for loop 10,000 times. So what we're going to do is the following.
I'm going to create a computer variable internal to my loop of grouping, and that's going to be a
random choice, a random choice of my df.heartrate. And so that column of all 200 values, and then I'm
going to put in something new, a size argument. And I'm going to say a size 100, 2. And what that is
going to build for me is two columns of 100 each. And I say replace equals false, because I don't want
the same individual to be selected twice. So that is a complete reassignment, a random reassignment
of individuals. So that there's now two new sets of 100, and they're all mixed and matched.
And what I'm going to do, I'm going to divide them in two groups. One I'm going to call group,
and then a Roman numeral 1, and a group Roman numeral 2. And I'm going to do the following. I'm going to
say, take this grouping of two columns with 100 each, and of those, I want the first 100. So I'm using this
range operator from zero to 100. So that means all of them actually, because remember, it's two columns
of 100 that I'm creating with my size here. And I want the first column of that. So that would be
index zero. And for group two, we're going to use that grouping. And by indexing, give me all the rows
again. So remember, all I needed actually to do is just that, because if I just put a colon, it means
all of them. But let's say 1 to 100. That's all of them. I want the second column of them. And I just
want you to get that. This is important Python code here, with this size argument set to this tuple,
100, 2. It's going to take those 200, mix them up randomly with a random.choice function. And I just
want to create these two little columns of 100 each. And I'm taking the first column, all those 100
values, and I'm assigning that to group one. And all the hundreds in column number two, assign that
to group two. And I'm doing, what I'm doing is I'm taking the mean of those. So I've got two new
random means. And what I'm going to do, this empty list of mine, I'm going to append to that
group one minus group two. So it's the mean of my one reassigned group minus the mean of my other
reassigned group. And I start adding my test statistic, which is the difference in means. I start
appending them, start building them up, and eventually I'm going to have 10,000 different
means. And see how different this is from sampling from the actual population. We don't have access
to the population. We only have access to our little sample that we have of 200 individuals.
So we've got a resample from them. And what we do is we randomly reassign them to a new group,
10,000 times over. Great stuff. So let's just look at the distribution of possible differences.
And look at that. It approximates a nice little normal distribution. I'm warning that this is
not going to be a normal distribution. This is actually a t distribution of 198 degrees of freedom,
but it approximates really a nice normal distribution. And what I've also drawn here
is our difference that we found was way out here. So here's all the possible differences,
given random reassignments of our participants under the null hypothesis that there was no
difference between the two. So I can just mix and match, just take one, someone out of one group
and randomly put them in the other group so that I still end up with equal numbers as my original,
100 and 100. So this is that last step that we had to take, that we went from sampling from the
population to sampling only from our data. And this gives us this distribution of all possible
differences. And we see where our difference was. I want to remind you though, that our difference
could also be on the other side. Okay. But let's look at it just as it is at the moment, just on the one
side. So I can ask a question. Remember, this is a continuous numerical variable. So I can't ask what
the probability of a single value is anymore, because these are just round off. If I had better
instruments, I would have better decimal values. So I can't ask, you know, when we roll the die,
two dice, and we ask what was the probability of a 10 or more, and we just add those, we can't do that
anymore. So we're really interested in how many of all of these was actually greater than our difference
here. And our difference was 4.45 in the order that we did the subtraction. So I just want to count,
of all my 10,000, how many were out here, were more than that. And if I divide by all 10,000,
it's going to give me the proportion of these on the right hand side, that was greater than 4.5. And
that's what I do here. I take my mean stat, remember that is 10,000 values in a Python list,
I pass that to the numpy.array function, because I need it to be an array, because I'm using a
conditional that was larger than 4.45. That's going to give me a bunch of trues and falses.
Because trues are one, I can sum over all of that. And that's going to give me the number
of these, all of these that were greater than 4.45. And then I divide it by 10,000 to get a proportion,
just, you know, what fraction it was. So it says that 0.005, that's a half a percent,
was larger than of all possible differences, having redone my study 10,000 times under the
null hypothesis. So reassignment. Only that small fraction was actually more than that. So this was a,
you know, the difference that we found initially with our data, but it was very unlikely to find
that difference. But now we have to remember that we could also have done it in reverse. So I
two-tailed alternative hypothesis. So we've got to do the negative 4.45 as well. And that's just what
I do with a code here. So remember, that's that as well. And we also have to do this little lot. So
how many was less than minus 4.45? And we do exactly the same there. So I'm passing mean stat,
my list to the NumPyRave function. I'm asking by conditional, how many of those were less than
4.45. And I'm summing over all the true values. And I'm dividing by the sum total. We had 10,000
in that NumPy list, 10,000 values. And I see 0.038. So now I sum these two proportions,
or these two fractions with each other, and I get about 0.009, 0.0085, which is about 0.009.
And that's 0.9 of a percent. That is a very unlikely finding. It's very rare. And once again,
as human beings, we've decided we're going to draw a line in the sand somewhere,
and we're going to draw that line in the sand of 5%. So if our, if these values that we found was
made up less than 5% of the total number, 0.05 of this total number of 10,000, we're going to call
this out and say, we now reject our null hypothesis and we accept our alternative hypothesis. And we say,
there is a difference between these two groups and the heart rate between, you know, between these two
groups. Once again, we haven't, have we really, have we really proved this? No, we built a framework.
And we said, based on the null hypothesis, let's create a distribution of 10,000 or 20,000 or 30,000.
Now, remember before computers came along, this wasn't so easy, was it? But now it's very easy.
I can say, do it 20,000 times, a hundred thousand times, who cares? I can just build all a distribution
of all the possible differences by continuously resampling from my actual values. I know nothing
about the population. And I say, I can now put my difference that I've found in my one study,
I can put it somewhere here and say, well, given the null hypothesis, this is the distribution of
possible differences that I could get. This is my one. It's quite rare. And I draw this line in the
sand at 0.05. So I say, as beyond that 0.05, I'm rejecting my null hypothesis and accepting my,
my alternative hypothesis. It's a framework, decisions that we made. This is how we're going to do it.
And now you can see how this all fits together. So just to remind you, through mathematics,
we have this thing called the t-distribution. Very, very nice equation. You can look it up online.
And I can use the stats.ttest underscore ind. That means independent groups. These two groups
are independent of each other. I pass the two numpy arrays of heart rate values there. It's going to
give me back two things, a t-stat and a p-val. And if I do the p-val, we see 0.009. And that was our
approximation, 0.009. So we can approximate this p-value by this continuous resampling. And it's this
continuous resampling, I think that gives us a good and true understanding of what the probabilities are
of finding the values that we do find, putting it in, in a picture of something, of something bigger.
So don't worry about this code. I'm just going to show you with those mathematical equations,
and just using some code there, this is what it actually looks like. So there's my t-distribution.
And I see my critical values there that would represent two and a half percent on this side,
and the orange line that side, two and a half percent on this side. And these were my actual
differences converted to t-values. And so we're looking at this little area under the curve,
this little area under the curve. And it's obviously beyond my critical t-levels. My critical
t-levels would be 2.5% on the one side, 2.5% on the other side combined, that's 5%, so 5% of the
area under the curve. And we have a statistically significant difference. We reject the null hypothesis,
and we accept the alternative hypothesis. And I just want to say this a million times over. I built this
distribution of all possible differences under the assumption that there was no differences between
the two groups. As simple as that. So let's do another example. We're going to compare the means
of the systolic blood pressure between age groups. And the reason why I do this, I just want to rehash a
little bit of Python code, because our age group, remember that's a continuous numerical variable. I can't
divide the patients by, or the participants, by a continuous numerical variable. I've got to do some
binning. So I'm creating a categorical variable from a numerical variable. And let's, let's just have an
arbitrary cutoff. And we're going to generate this new column in our data frame. So div, and then age
group. And I'm going to assign to that just two groups. And I'm going to have my cutoff at 65. So
everyone that was younger than 65 was going to go in group one, and everyone older than 65 was going
to go in group two. So I'm using the WHERE function in NumPy. NumPy WHERE. And I'm passing at this
little Python, the Panda series. So that age column, conditional, is at less than 65. If the WHERE function
says, if this first part is true, give it this value. And if it's false, give it that value. That's all the
NumPy WHERE function does. And I think, you know, we've looked at it before. And that's just a little
bit of a rehash. So let's look at our age group value counts now. So we see 152 participants are
now in group one and 48 on group two. So no longer 100-100. So there's something new. So first of all,
let's just do some summary statistics on all of this. And there we see in group one, there was 152
participants, only 48 in group two. And we see a difference in as far as the SBP. So that's the
one we're interested in here, SBP, and that's systolic blood pressure. If you look at your blood
pressure, 120 over 80, that's that highest one. So we see in the younger age group, the mean blood
pressure was 153, and the older group was much higher than 168. And we see the standard deviation
and the quantiles there. Let's visualize it now that we have some understanding and knowing, well,
there seems to be a difference here. And look at that. Again, we have this outlier here, someone
with a systolic blood pressure of 52. And that participant is in real trouble. That's a very low
blood pressure. Anyway, so suspected outlier there, and we might have to do something with that
observation. And anyway, now we can start asking, is there a difference between these two, these two,
these two groups, and as far as the systolic blood pressure is concerned. So let's do the following.
What I'm going to do is to show you a slightly different way to do this reassignment. We did that
size, and we passed the tuple 100,2 before. You can do that this time around. And instead of
100,100, we can have 152 and 48 in the two, in the two groups. But that's not going to work so well
with the where. So I'm going to show you a little bit of a difference. What I'm going to do first of
all, in this method of reshuffling my participants, is that I'm going to just make a copy of my data
frame. So I'm going to say df.copy, and deep equals true means completely rewrite in the computer's memory.
Because if I start changing something, it might influence the original, and I don't want to change
my original. And this method is going to interfere with the original. So I'm just making what we call a
deep copy. So it's a full on carbon copy, but it lives in a completely different space of memory.
So I'm just going to work with deep underscore copy. So let's see this way of 10,000. I'm going to,
you know, repeat my study 10,000 times based on just the data that I have. Again, I'm going to start
off with my empty Python list, and I'm going to have a for loop that I'm going to run over 10,000 times.
So what we're going to do is we take this whole, my deep copy, the word df.copy,
sbp. So I'm going to take that series or that column, and I'm going to convert it to a NumPy
array. And I'm going to assign that to a computer variable called sbp, internal to my for loop here.
And then I'm going to do the numpy.random.shuffle of this NumPy array. And if I shuffle this,
it's going to interfere with the data frame that I have. So this df.copy. So I'd rather mess up my df.copy
copy and keep the original data without any kind of reshuffle. So that's why I'm working with a
copier because that shuffle is going to do that for you. So I'm calling numpy.random.shuffle sbp.
So sbp, remember, that's just a NumPy array of all the sbp values, all of them in one hat.
And now what I'm going to do is I'm going to do the following. Remember there are 200 sbp values,
but I don't want to divvy them up 100-100. I've got a different ratio of my participants now. So
I'm going to make group one, and that's going to be the mean of this first 152. It's a complete
reshuffle. They're not in the same order anymore. So I'm using my index from 0 to 152. So that's going
to give me the first 152. And then from 152 to 201, remember that 201 is not included, it only goes to 200.
So that's the other 48. So my resample is in the same proportions as what my patients,
my participants were 152 and 48. So I'm reassigning those by reshuffling them. That's a different
method of doing this. And I'm calculating the mean of each, and I'm starting to append my empty list
here with the differences between those two. So this is a different way for you to go about specifically,
if you have unequal number of participants in both groups. So once again, we're going to view this
sampling distribution. And what we're going to do here is just create the two arrays,
and we're going to look at this difference. So let's calculate that. Now that was our difference
between the two groups initially. So let's just go up, up, up, up, up. There we go. We had 153,
and we had 168. So the difference between those two, there we go. So I'm doing a younger SPP and an
older SPP, where the age group was one, the age group was two, converting that to a numpy array as
far as the SPP is concerned. And I'm just doing the difference. But remember, I could also have
done the subtraction the other way around. So there'll have to be a positive 14.8 difference as
well. So that's a two-tailed alternative hypothesis. And let's just use graph objects to do that.
And we see our 10,000 possible differences. And once again, the actual difference of negative 14,
positive 14 that we found. And I think you can well guess by now, this is going to be less than the
critical value, if our alpha value is 0.05. So let's just do that. So we're going to sum up all
the ones, the total number of ones that were less than this, divided by 10,000, so that it's a fraction,
and all the ones more than 14.8, and divide by 10,000, so we get a fraction. So let's do those two.
And I see it's very, very few. And if I sum that up,
that is going to be the probability of this difference.
Given the null hypothesis that there was no difference, if we build a distribution from that
assumption, this is what we're going to get. We put the ones that we actually found in there,
and we just sum these two fractions of the whole there. And we get a very small value. And let's
compare that with the statistical way of doing it. We're going to use the t-test again. And let's see
what that proportion worked out. 0.0004, and we got 0.0007 from our 10,000 samples. You know,
it's so small. That's it. We reject our null hypothesis. We accept the alternative hypothesis.
There was a difference in systolic blood pressure. That difference of 14
was significant. And that's how we go about it.
Now, I think you've got a very good understanding now, is that we deal with only the data that we
have. We can build a distribution from that, from a null hypothesis, and we can put our difference
somewhere on there. And it really doesn't matter what statistic we're working with. We can build this
distribution of a possible statistic, and see where our study's statistic falls on that distribution.
It really is a beautiful thing. Okay, just for completeness, or maybe I should say just
interest's sake, with these statistical tests, they are also built on stringent, semi-stringent,
I should say, assumptions. So one of them is that the variances between my two groups have got to be
equal. So what I'm going to show you here, is I'm just going to, this has got nothing to do with the
data that we had before. We're just simulating new data now. I'm going to see now my
pseudo random number generator with the integer 12. I'm going to create two groups, and they're going
to have taken from a normal distribution with a mean of 100, both of them. One is going to be taken
with a standard deviation of 10, the other one of 12.1, and 100 participants in each group. So it doesn't
matter. This is now, you know, completely new and random data. And we see there a standard deviation
of 10 and 12.2. So if we square those with 10 squared and 12.1 squared, so that the variances
are quite different. And we have to know if, before we use a t-test, if those variances are equal.
Once again, what is, what difference do we have this cutoff for? And for that, there's something
called the Levine's test. So I'm going to stay stats.levine, and I just pass my two numpy array
values there. And it's going to throw out a p-value for me, and it's 0.04. If my line in the sand was 0.05,
I have to reject the null hypothesis that this variance, these variances were equal. And I accept my
alternative hypothesis that these variances were not equal. Given that, I can't use what we call
students t-test. I actually have to use an unequal variance t-test. And of course, in no problem for
Python, there is such a test, stats.ttest underscore independent. So that's still the normal t-test. I
passed my two arrays, but I have this new argument here, equal underscore var, and I set that to false.
I have to set that to false. And that's going to calculate for me a slightly different p-value.
It's still going to be, there's still that p-value there, but it was calculated in a slightly different
way. The mathematical equation for doing this was slightly different. So that was just a little bit
of, just for extra interest sake. What I want for you to take away from this is really the fact that
we are given data, we choose a test statistic, we continuously resample under the null hypothesis,
and then we put our difference somewhere, our statistic somewhere on that distribution of
possible statistics. And that's as simple as that. We now can express the probability of having found the
the result that we did.
