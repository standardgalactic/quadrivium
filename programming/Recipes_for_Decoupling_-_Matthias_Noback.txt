
Recipes for Decoupling
 
Matthias Noback
 
This book is for sale at http://leanpub.com/recipes-for-decoupling
This version was published on 2022-06-29
*   *   *   *   *
This is a Leanpub book. Leanpub empowers authors and publishers with the
Lean Publishing process. Lean Publishing is the act of publishing an in-
progress ebook using lightweight tools and many iterations to get reader
feedback, pivot until you have the right book and build traction once you
do.
*   *   *   *   *
Â© 2021 - 2022 Matthias Noback
OceanofPDF.com

Table of Contents
Introduction
Coupling, Why is it Bad?
Decoupling, How to Do it Efficiently?
Objection
What's Special About This Book?
How to Stay Decoupled?
Who Should Read This Book?
Overview of the Contents
About the Author
Changelog
10 May 2022
17 May 2022
26 May 2022
31 May 2022
7 June 2022
15 June 2022
29 June 2022
1 Creating Custom Rules for PHPStan
Introduction
Analyzing Code with PHPStan
Catching Specific Node Types
Adding Automated Tests for a PHPStan Rule
Deriving Types from the Current Scope
Putting a Node in Context
Generalizing a Rule
Conclusion
2 Web Frameworks
Introduction
Controllers
Show How the Response is Created
Only Use Constructor Injection for Dependencies
Make Every Step Explicit
Controllers Have No Parent Class
Every Action Has its Own Controller Class

Should We Use an HTTP Abstraction Library?
Rules for Decoupled Controllers
Forbidden Parent Classes
Allowing Only Parameters of a Certain Type
Enforcing Return Types
One Action Per Controller
Views
Pass All the Data That the Template Needs
Don't Pass Objects That Don't Belong in a Template
Rules for Decoupled Views
Don't Use Certain Global Variables in a Template
Don't Use Certain Functions in a Template
Don't Pass Entities to a Template
Conclusion
3 CLI Frameworks
Introduction
Input
Collect Input First
Jump to a Service
Output
Using an Observer for Showing Output
Generalizing the Solution with Event Dispatching
Turn the Command Class Itself Into an Event Subscriber
Controllers Should Call Framework-agnostic Services
Rules for Decoupling
Use InputInterface and OutputInterface Only in Command Classes
4 Form Validation
Introduction
Form Validation
Protecting Data Inside the Model
Delegating Protection to Value Objects
Removing Duplicate Validation Logic
Defining an Explicit Shape for the Input Data
Rules for Decoupling
Don't Pass a Single Array of Data to create()
Enforcing the Use of Closure-based Form Validation
Conclusion
5 ORMs and the Database

Introduction
Repository: an Abstraction for Persistence
Trying an Alternative Implementation
Application-generated IDs
PHPStan Rule: Disallow Auto-incrementing Model IDs
Defining Our Own Object API
Custom Mapping Code
PHPStan Rule: Only Allow Calls to fromDatabaseRecord() from Repository Classes
No Magic Persistence of Related Objects
Using Aggregate Design Rules
Limiting Changes to One Entity
Introducing View Models
Provide Read Models When the Framework Needs Your Data
Use Domain Events Instead of Persistence Events
PHPStan Rule: Forbidden Parameter Types
Conclusion
6 Test Frameworks
Introduction
Use Only the Most Basic Features of a Test Framework
Declare Test Dependencies Explicitly
PHPStan Rule: Don't Allow PHPUnit Extensions
PHPStan Rule: Don't Allow Class-level Set-up and Tear-down Functions
Assertions
Write Tests in Plain Code
Handwritten Test Doubles
PHPStan Rule: Don't Generate Mocks
Conclusion
7 Conclusion
8 The End of the Book
OceanofPDF.com

Introduction
When you're writing a software application you'll need many, many things.
Sometimes it's quite disappointing. Just look at how many packages need to be
installed only to run a very basic web application with a framework like
Symfony or Laravel, and a test framework like PHPUnit. Most projects will
have fewer lines of code in their own src directory than in the vendor/
directory.
If we don't install all those dependencies, we can still create an application. But
we would have to "reinvent a lot of wheels". It would make development so
inefficient, we would never be allowed to make another application. So we
rightfully trade development speed against an increased dependency on other
people's code.
Once we have decided on a certain framework, we experience the highest speed
of development if we do everything "their way". We follow their
documentation, community blog posts, video trainings, e-books, and
conferences. We apply the best practices that are being spread by visible
community members, and we always prefer so-called idiomatic use of the
framework. There are many advantages to this approach: it will be easy to find
answers on Stack Overflow ("How to do X with Laravel?"), you can add the
framework to job descriptions ("5+ years of experience with Symfony"), you
can even raise your team's standard by requesting everyone to join a
certification program.
Coupling, Why is it Bad?
Going all-in on a framework also has downsides. It's commonly known as
vendor lock-in. This term already has enough negative connotations to trigger
some alarms. For almost 20 years now, I've worked on PHP projects that first
benefited incredibly from strictly following the framework approach. In the
end, they had become an unmaintainable mess and were sometimes considered
total-loss.

Looking at the code of such projects, and I guess you also have experience with
them, a lot of work would be needed to save them. You'd have to migrate to a
different framework, a different ORM, a different test framework. All of this is
very hard to do because the code is tangled up with all those frameworks.
Business logic is not in plain sight, but hidden in controllers, hooks, SQL
queries, foreign key constraints, migrations, even in templates. Tests are
completely tied to the framework, and can't be run without it.
All code has the potential to become legacy code over time. Still, based on my
experience with these projects, it's clear that tightly coupled code is more likely
to become legacy code, and to be abandoned completely. Which is a waste of
the expensive development effort that went into it. A part of the application (if
not the whole application) still works and is relied upon by its users, and now it
has to be rewritten. A rewrite is not guaranteed to be a successful process, and
the user is likely to miss some features that weren't noticed by the developers
because they were obscured by framework integration code.
How can we prevent this from happening in the future? I think we, as software
developers today, should make an effort to decouple from our frameworks. All
our domain logic should be in plain sight, and our tests should be executed with
only the most basic test framework. When the time comes to migrate to a
different framework, maybe even upgrade to the next major version, it should
be an easy job, finished within the course of a few weeks. It should never
endanger the life of the project itself.
Decoupling, How to Do it Efficiently?
The trick is to keep a safe distance from your framework, while using some of
its powerful features, so you don't have to write them yourself. This can be
achieved by decoupling, which has two components: you need to decouple your
code, and you need to decouple your approach to software development from
the approach advocated by the framework authors. You need to think about
what your application has to offer to the user, then implement it with code that
leverages the framework's powers, but only in a few places.
Complete decoupling is undesirable as it would lead to too much work. Loose
coupling is what we're after. When you want to replace the thing you're
coupled to, that shouldn't be too much work, and it should only involve a few
local changes. In other words, the framework shouldn't be all over the place. If

you manage to do so, an automated refactoring tool like Rector will help you
transform all the old-style integration code to code that matches the
expectations of the new framework.
Objection
Whenever I propose to decouple from a framework, there's always a common
objection: "YAGNI" (You Ain't Gonna Need It). Although this is not really an
argument by itself - it could benefit from a few extra words - I think it hints at a
valid concern. Should we decouple, even if we don't know how long the project
will live, or if we'll ever face a framework migration? It shouldn't be a surprise,
but I think "yes". If we don't do it now, we're introducing technical debt in the
project. Of course, we can take the shortcut now, and write the code a bit faster
today, but we know that we'll have to do a lot of work later. As with any
technical debt, we can accept it. However,
1. I'm not entirely sure that we will be so much faster. Yes, in the very
beginning of the project we can quickly slap a prototype together, but soon
we'll start running into framework limitations, quirks, and magic that we
didn't understand correctly. Personally I've spent a lot of time debugging
forms, validation, entity mapping, and templating issues, and I'm a
certified Symfony developer (well, I was part of the first class, 11 years
ago at SymfonyLive Paris, so maybe that doesn't count anymore).
2. I'm not entirely sure that everyone is aware of how much debt they
introduce when relying on frameworks and ORMs, or that going all-in on a
framework should even be considered technical debt. This is something
you only realize when you look at one of those almost-dying projects.
I think I'm not the only one who thinks that decoupling deserves to be part of
our daily work as a programmer. I think programmers have always done this,
because I keep recognizing design patterns that seem to have been invented for
the sake of decoupling. Consider patterns from the old "Gang of Four" book,
like Observer, later evolved into Event dispatcher, but also Adapter, etc. Or
from Domain-Driven Design, e.g. Aggregate, Repository, Application service,
and so on. Domain-Driven Design itself seems to be an exercise in moving
focus away from frameworks and databases, the things we developers like so
much, and divert our attention to the business domain itself. The same goes for
development approaches like BDD, which explicitly aim to decouple

specifications written as scenarios from the underlying technology, to keep a
clear focus on what we're doing.
With my writing I'm always looking to place myself as a developer in this long-
standing tradition of software development that doesn't revolve around a
specific language, nor a specific framework. How can we write software in a
way that is timeless, focuses on the business domain that it tries to serve, and
produce applications that are long-term maintainable?
What's Special About This Book?
In another book, Advanced Web Application Architecture, I've already
described in detail how to create an application that primarily consists of a
decoupled application core. It also shows how you can wrap this core inside
any framework or connect it to any ORM you like. That book presents one
over-arching vision of what I consider a good approach for application design.
It helps you do domain-oriented, test-first development.
In this book, "Recipes for Decoupling", I'm taking a much more light-weight
approach. The focus isn't on design patterns or architecture. I will sometimes
reference the relevant concepts or patterns, but only as a way to point out how a
decoupling recipe is related to this larger culture of software design practices.
Instead of spending much time exploring the theory, we'll mostly focus on the
practice of decoupling. We'll consider various popular frameworks and libraries
that are used in web applications, and how you can decouple from them. This is
done using small refactoring steps, showing how you can improve the structure
of your code, while preserving the existing behavior. Something that's very
important with legacy code, of course.
As a reader, you can pick specific topics that are of interest to you, or that pose
a particular risk in your current project, like "ORMs", or "mocking libraries".
The decoupling approaches shown in each chapter can be applied in isolation.
You don't have to decouple your entire application at once. You also don't need
to go all the way on each refactoring. Most chapters offer an incremental series
of refactorings that allow you to turn the dial on the level of decoupling you
need today. If you like, you can do some more work if it provides additional
benefits in the area of maintainability or maybe testability. You decide when to
stop.

How to Stay Decoupled?
A refactor a day keeps the doctor away, but once your code is decoupled, you'll
need to be very disciplined to keep it decoupled. For instance, if you don't want
the service container to be used outside of controller classes, you have to
continuously be aware of this rule. Not just you, all the other team members
need to remember that they're not allowed to use the container anywhere else.
This is a risk for your project. It'll be difficult to maintain that discipline over a
longer period of time. We may oversee a particular "violation" of this rule in a
PR, and accidentally merge it into the main branch. This single mistake
becomes a precedent and will be copied many times; apparently "this is allowed
now". When all the developers who cared about decoupling have left the team,
we can be sure that in the end all the rules will be ignored.
I believe that this tendency towards deterioration of a code base can be
overcome by automation. Many of us have already worked with a project that
performs some kind of automated build for each commit that we push to a
remote branch. The build often consists of installing all dependencies (and
checking that none of them have security vulnerabilities), linting the PHP code
to catch potential syntax errors, running the tests, and verifying that the coding
standard has been applied. These tools catch a lot of potential issues before we
release them to main or even deploy them to production. If there is an issue, the
build turns "red" and merging or deploying isn't even possible.
With an automated build phase for a project, we have a way to prevent bad code
from being merged. So if we can define our own decoupling rules as checks
that run during the build, we have a way to prevent coupled code from being
merged. We only need to find a relatively easy way to write those decoupling
rules. Once we have a platform for this, we can specify rules and run them as
part of the build, now and forever. This will prevent the developers from falling
back into old habits, and will save our code from ever becoming coupled again.
While working on the Rector bookwith Tomas Votruba, he told me how he
deals with user-contributed PRs for the Rector project itself. He noticed that he
had to point out the same issues again and again. This took a lot of time, and led
to delayed merges, and some frustration on both sides. He started using
PHPStanin the project build to automatically report mistakes directly to the
user, without human intervention.

PHPStan is a tool that statically analyses PHP code and points out potential
problems related to incorrect types, argument counts, undefined methods, etc. It
has a lot of built-in rules that can catch a lot of common programming mistakes
before you ever run your code. On top of that, it also allows you to define your
own rules. That's what Tomas did for the Rector project. It didn't only help its
contributors; he was also able to worry less. If he'd forget about some rule,
PHPStan would remind him of it.
Following Tomas' lead, I'm doing the same for this book. Whenever we discuss
a refactoring that leads to decoupled code, we'll also look for ways to solidify
the decoupling in the long run by writing a custom PHPStan rule. This is going
to be much safer than relying on the personal discipline of every developer on
the team.
Before we can do this, we should take a look at the process of writing a
PHPStan rule. This involves a short introduction to PHPStan and how to write
custom rules for it. You'll find this introduction in the first chapter.
In this book I adopt PHPStan because I'm familiar with it, and also because Rector is built on
top of it. You can also use the popular alternative - Psalm. Psalm can be extended with custom
rules as well, and they won't be very different from the ones in this book.
Who Should Read This Book?
I hope this book will be relevant for any developer who has used a framework,
has sometimes been bitten by its magic, or has been unable to upgrade to the
next framework version. This book will be useful if you're looking for ways to
make applications more maintainable in the long run. I expect only some
experience with PHP and one of its currently popular frameworks.
Overview of the Contents
We start with a chapter that introduces PHPStan and how you can create custom
rules for it. If you already use PHPStan and have some experience writing rules
for it, feel free to skip this chapter.

Chapter 2 introduces common coupling issues related to web frameworks. We
consider what would be needed to migrate a controller from a Symfony
application to a Mezzio application, and use this process to gain some
understanding about any potential framework migration. This gives us
decoupling rules for dealing with request and response objects, service
dependencies, and template rendering.
Chapter 3 covers similar issues, but for CLI frameworks. We take a look at a
Symfony-based console command and find out how to decouple the business
logic of this command from the terminal-based input and output objects.
Chapter 4 looks at form validation and how Laravel applications deal with this.
We look for a way out of framework coupling by shifting our focus away from
form validation. We introduce value objects and try to enforce constraints at the
level of the model itself.
Chapter 5 zooms in on a type of library that often takes over a big part of our
application and might therefore be considered a framework itself: the ORM.
How to decouple from it in such a way that we don't lose all the benefits? Part
of the solution is in separating the "write" from the "read" activities of the
ORM. At some point we realize that maybe we don't need an ORM at all. This
chapter has examples based on Laravel's Eloquent as well as Doctrine ORM,
because they don't have much in common and both require a different approach
to decoupling.
Just as tests are usually an after-thought (sadly so), the final chapter of this
book dives into test frameworks and mocking libraries and describes some
options for decoupling from them.
By means of a conclusion we'll look back at all the refactoring and decoupling
activities we did in this book, and we try to extract some common aspects.
Rephrased as decoupling strategies they should help you decouple from things
that don't exist yet, or that we otherwise didn't cover in this book.
About the Author
Matthias Noback has been building web applications with PHP since 2003. He
is the author of the Object Design Style Guide and Advanced Web Application

Architecture. He's also a regular blogger, speaker and trainer. In
his spare time he plays the violin and builds wooden 17th-
century ship models.
Changelog
If you've bought an early version of this book, you can download
all future updates for free. After each update I'll describe what has been added
or changed.
10 May 2022
Initial release.
Added the Introduction
Added Chapter 1, Creating custom rules for PHPStan
17 May 2022
- Added Chapter 2, Web frameworks
Fixed the output of a PHPUnit run in Chapter 1 that was expected to show
echo-ed node types (thanks for reporting, Christopher L Bray!).
Changed the returned rule in NoErrorSilencingRuleTest to
NoErrorSilencingRule (thanks for reporting, Quentin Delcourt!)
26 May 2022
Added Chapter 3, CLI frameworks
Fixed some broken sentences, layout issues, and updated the link registry
(thanks for reporting, Amir Ziapoor!)
31 May 2022
Added Chapter 4, Form validation

7 June 2022
Added Chapter 5, ORMs and the database
15 June 2022
Added the missing sections about PHPStan rules to Chapter 5:
PHPStan rule: disallow auto-incrementing model IDs
PHPStan rule: only allow calls to fromDatabaseRecord() from
repository classes
Added Chapter 6, Test frameworks
Processed feedback about Chapter 1 (thanks, Paul Rijke!)
Added a hint about running composer dump-autoload
Improved the comment about using customRulesetUsed instead of
level
Added a hint about running only the rule tests
Improved the section about configuring a suffix
29 June 2022
Added the Conclusion
OceanofPDF.com

1 Creating Custom Rules for
PHPStan
This Chapter Covers:
Installing and configuring PHPStan
Creating and testing custom PHPStan rules
Working with nodes and types
Class reflection
Rule configuration
Introduction
As mentioned in the introduction, we're going to use PHPStanin this book to
verify that after decoupling our code it will remain decoupled forever. In order
to do so we first need to install PHPStan, and configure it to analyze our project
files, then practice a bit with writing custom rules. I recommend you to follow
along with this chapter, implementing the examples yourself inside one of your
projects.
Analyzing Code with PHPStan
PHPStan is a tool that statically analyzes your PHP code. This means it doesn't
run your code, but only "reads" it. It then performs a number of checks on your
code, which are called "rules". For instance, when your code calls some
method, it checks that you supply the right number of arguments, and that the
arguments match the expected types. If it finds any issues, PHPStan will report
this as output in your terminal.
You'll find all the details about installing and configuring PHPStan on its
website, but the basic steps are:
1. Install PHPStan as a Composer package in your project: composer
require --dev phpstan/phpstan

2. Create a phpstan.neon configuration file in the root of your project
3. Run PHPStan: vendor/bin/phpstan
A basic phpstan.neon configuration file looks like this:
parameters:
    level: max
    paths:
        - src
        - tests
I prefer using the max level, so PHPStan can operate at maximum power. For
existing code, this may be quite problematic - check out the documentation
section about the Baselineto find out how to deal with this.
We need to provide the paths that PHPStan should analyze (in this example src
and tests). Every PHP file in the project, except vendor code should be
analyzed, or we'll miss out on valuable feedback.
When we run vendor/bin/phpstan we'll get output similar to this:
------ ------------------------------------------------------------
 Line   src/example.php
------ ------------------------------------------------------------
 5      Parameter #1 $json of function json_decode expects string,
        string|false given.
------ ------------------------------------------------------------
[ERROR] Found 1 error
PHPStan lists all errors, the files in which they occur, and their line number.
Every error needs to be fixed, in one way or another. In this example we get an
error about the first argument provided to the json_decode() function call. It
expects a string, but we pass string|false to it:
<?php
declare(strict_types=1);
json_decode(file_get_contents('some.json'));
Looking at the documentation of file_get_contents(), it turns out that this
function returns a string, which is the contents of the requested file, or false

if the file doesn't exist. In our code we need to deal with both cases. One way to
do so is to throw an exception in case file_get_contents() returns false:
<?php
declare(strict_types=1);
$filename = 'some.json';
$contents = file_get_contents($filename);
if ($contents === false) {
    throw new RuntimeException('Could not read file ' . $filename);
}
json_decode($contents);
PHPStan is smart enough to understand that below the throw statement it can
be certain that $contents is no longer possibly false. According to the union
type string|false, what remains is that $contents is a string, and it will be
safe to pass that to json_decode(). So when we run vendor/bin/phpstan
again, it shows no errors:
[OK] No errors
To ensure that fixing PHPStan-reported errors isn't an optional activity for
developers, we have to commit phpstan.neon and add the
vendor/bin/phpstan command to the project's build script.
I recommend letting PHPStan analyze your entire project, and setting level to an appropriate
value (see Rule Levels). However, you're not strictly required to use any of PHPStan's built-in
rules or rule levels. You can also instruct PHPStan to only run your custom rules against the
code base. If that's what you want for your project, you can remove the level parameter in
phpstan.neon and instead add customRulesetUsed: true.
Catching Specific Node Types
Now that PHPStan is ready to be used in your project, let's start by creating a
custom rule. As a warm-up exercise, let's report any code that uses the error

silencing operator @ to suppress errors raised by PHP functions like
file_get_contents(), as is done in this example:
src/error-silencing.php
<?php
declare(strict_types=1);
@file_get_contents('not-found.txt');
Instead of silencing errors, we'd like full exposure about everything that goes
wrong in our code. We want to fix issues instead of ignoring them. So let's
make a custom PHPStan rule that forbids the use of @ anywhere in the project.
A PHPStan rule is a class that implements the PHPStan\Rules\Rule interface.
The class should be auto-loadable. I prefer to keep rule classes outside the
normal src folder though, so I have a dedicated line for PHPStan rules in the
autoload-dev section of my composer.json file:
{
    "require-dev": {
        "phpstan/phpstan": "^1.5"
    },
    "autoload-dev": {
        "psr-4": {
            "Utils\\PHPStan\\": "utils/PHPStan/src"
        }
    }
}
When you make a change to the autoload or autoload-dev section of your composer.json file,
don't forget to run composer dump-autoload afterwards.
Our first rule class is going to be called NoErrorSilencingRule:
utils/PHPStan/src/NoErrorSilencingRule.php
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PHPStan\Analyser\Scope;

use PHPStan\Rules\Rule;
final class NoErrorSilencingRule implements Rule
{
    public function getNodeType(): string
    {
        return Node::class;
    }
    public function processNode(Node $node, Scope $scope): array
    {
        return [];
    }
}
For now, I've only added a minimal implementation of the interface. It doesn't
do anything useful yet, but it also doesn't break anything. To make PHPStan
aware of the new rule class, we should add it to phpstan.neon:
parameters:
    level: max
    paths:
        - src
rules:
    - Utils\PHPStan\NoErrorSilencingRule
Run PHPStan to check that it can find the new rule. If it couldn't find the rule
class, it will show an error.
While practicing with custom rules, it will be a good idea to not analyze the full project, but only
a single file that has a representative example of something we want to trigger an error for. You
can do this by running vendor/bin/phpstan analyze [file-path-to-analyze] (note the
additional analyze).
Later on we're also going to write tests for our custom PHPStan rules, which accomplishes the
same thing, and is a much better alternative anyway.
We've set up a new rule class, now it's time to implement it. Note that the rule
has two methods: getNodeType() and processNode(). These work in a similar
fashion as your average event dispatcher does: you register the type of event
you're interested in, and you will be notified when such an event occurs. For a
rule you register the "node type" you're interested in, and when PHPStan
encounters a node of that type, it will call processNode(). But what's a node?

Nodes are elements of the code that can be recognized as meaningful units. For
example, a class is represented as a single node, and all its properties and
methods are also nodes. Within every class method, each statement is
recognized as a node, and also each expression. Nodes can contain other nodes,
or lists of nodes, and so on. Each PHP file can be interpreted as one big tree of
nodes.
PHP itself builds such a tree of nodes when it loads one of your .php files and
runs it. It first needs to understand what's inside the file and if it makes any
sense. In order to do so it parses the .php code, and as a results makes a node
tree of it, which it can then turn into so-called byte code, which is executable by
PHP's virtual machine. Instead of running code based on the node tree, which is
called Abstract Syntax Tree (AST), we could also analyze the tree and spot
potential errors, as PHPStan does.
PHPStan uses the PHP-Parser libraryto parse your project's PHP code and
create an AST for each file. It then walks over the tree of nodes, asking each
rule: are you interested in this node (getNodeType())? If so, here you have it
(processNode()); please let me know if you want to report any errors about it!
To decide if the rule should trigger an error, the rule usually has to take a closer
look at the node. Nodes themselves are simple PHP objects. The classes of
those objects can be found in the PHP-Parser library. When you install PHPStan
as a Composer package, all of its code is inside a single .phar file
(vendor/phpstan/phpstan/phpstan.phar). This file also contains PHPStan's
vendor dependencies, including the PHP-Parser library. If you use an IDE like
PhpStorm you can inspect the contents of the .phar file and find this library.
Look for vendor/nikic/php-parser/lib/PhpParser/Node and you'll find
every possible node class.
When you're creating a new rule, you'll have to decide what type of node you
want to target. Because we don't know much at this point, we pick the most
general node type - the PhpParser\Node interface that all node classes
implement, and return its name in getNodeType(). Since every node that
PHPStan encounters implements this interface, it will call processNode() for
every node in every PHP file we analyze. We can use this to gain some

understanding about what kind of nodes we should be looking for. Let's print
the type (i.e. class) of each node on screen for now:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
final class NoErrorSilencingRule implements Rule
{
    public function getNodeType(): string
    {
        return Node::class;
    }
    public function processNode(Node $node, Scope $scope): array
    {
        echo $node::class . "\n";
        return [];
    }
}
With this rule enabled, we shouldn't run PHPStan on our entire project, since
that would give us too much output. Instead, we should analyze just a single
sample file that uses a silencing error, src/error-silencing.php, which
contains just the following code:
src/error-silencing.php
<?php
declare(strict_types=1);
@file_get_contents('not-found.txt');
To allow direct output via echo we have to add the --debug option when
running PHPStan. The full command is:
vendor/bin/phpstan analyze --debug src/error-silencing.php
The output:
src/error-silencing.php
PHPStan\Node\FileNode

PhpParser\Node\Stmt\Declare_
PhpParser\Node\Stmt\DeclareDeclare
PhpParser\Node\Scalar\LNumber
PhpParser\Node\Stmt\Expression
PhpParser\Node\Expr\ErrorSuppress
PhpParser\Node\Expr\FuncCall
PhpParser\Node\Arg
PhpParser\Node\Scalar\String_
--- consumed 6 MB, total 62 MB, took 0.09 s
 [OK] No errors
The result is a list of the types of nodes that were found in our error-
silencing.php script. Again, each type is actually a class, and you can open
each of them in your IDE to find out more about their internal structure.
Comparing the list of node types to the code in error-silencing.php we can
relate every node to a piece of code. E.g. we see at the end of the list a
FuncCall with a single Arg which contains a String_ node. These are all the
nodes for the expression file_get_contents('not-found.txt').
Right before the FuncCall node we notice the ErrorSuppress node. That's the
one we're looking for, it's the @ in front of the function call. PHPStan should
trigger an error for any ErrorSupress node that PHPStan finds in our code. So
we should change the getNodeType() function of our rule class to return the
ErrorSupress node class instead:
use PhpParser\Node\Expr\ErrorSuppress;
final class NoErrorSilencingRule implements Rule
{
    public function getNodeType(): string
    {
        return ErrorSuppress::class;
    }
    // ...
}
Next, we need to report an error for the line where we encountered an
ErrorSuppress node. PHPStan offers a convenient error builder for this. We
only have to provide an error message, and PHPStan will add the remaining
information:
use PHPStan\Rules\RuleErrorBuilder;
final class NoErrorSilencingRule implements Rule
{
    // ...

    public function processNode(Node $node, Scope $scope): array
    {
        return [
            RuleErrorBuilder::message(
                'You should not use the silencing operator (@)'
            )->build(),
        ];
    }
}
Running PHPStan again, we should now see that it reports an error for our
error-silencing.php file:
------ -----------------------------------------------
 Line   error-silencing.php
------ -----------------------------------------------
 5      You should not use the silencing operator (@)
------ -----------------------------------------------
[ERROR] Found 1 error
Great, we can now run PHPStan on the entire project and find all the places that
still use the error silencing operator! PHPStan sees everything, and will keep
watching forever. Whenever someone makes the "mistake" to use @ again,
PHPStan will warn them about it.
Adding Automated Tests for a PHPStan Rule
In the previous example we used a temporary script (error-silencing.php) to
verify that our rule works correctly. Now we can use this script as an example
for an automated test that verifies that the rule works now, and will work
forever. For more advanced rules, like the one we'll discuss in the next section,
starting with a test instead of adding it afterwards is the recommended
approach. It's easy to get lost in a sea of nodes, and a test will guide you safely
towards a working and maintainable rule.
PHPStan rules should be tested with PHPUnit. PHPStan ships with a base class
called RuleTestCase that extends from PHPUnit's TestCase class. The test for

a rule class should be named [RuleClass]Test. I prefer setting the tests up in a
separate auto-loadable folder:
composer.json
{
    "require-dev": {
        "phpstan/phpstan": "^1.5",
        "phpunit/phpunit": "^9.5"
    },
    "autoload-dev": {
        "psr-4": {
            "Utils\\PHPStan\\": "utils/PHPStan/src",
            "Utils\\PHPStan\\Tests\\": "utils/PHPStan/tests/"
        }
    }
}
Each test also gets its own folder called Fixtures which contains the example
scripts that PHPStan should analyse. The RuleTestCase base class has one
abstract method, getRule() which we need to implement. This method should
return the instantiated rule class that we want to test:
utils/PHPStan/tests/NoErrorSilencingRule/NoErrorSilencingRuleTest.php
<?php
declare(strict_types=1);
namespace Utils\PHPStan\Tests\NoErrorSilencingRule;
use PHPStan\Rules\Rule;
use PHPStan\Testing\RuleTestCase;
use Utils\PHPStan\NoErrorSilencingRule;
final class NoErrorSilencingRuleTest extends RuleTestCase
{
    public function testRule(): void
    {
        self::fail();
    }
    protected function getRule(): Rule
    {
        return new NoErrorSilencingRule();
    }
}

I've also set up a single test method to immediately fail, so we can see if
PHPUnit actually picks it up. First, we need to let PHPUnit know where to find
the PHPStan rule tests:
phpunit.xml
<?xml version="1.0" encoding="UTF-8"?>
<phpunit>
    <testsuites>
        <!-- ... -->
        <testsuite name="PHPStan rule tests">
            <directory>./utils/PHPStan/tests</directory>
        </testsuite>
    </testsuites>
</phpunit>
Then we run PHPUnit (vendor/bin/phpunit), and we should see that one
failing test:
PHPUnit 9.5.20 #StandWithUkraine
F                                                         1 / 1 (100%)
Time: 00:00.782, Memory: 64.50 MB
There was 1 failure:
1) NoErrorSilencingRuleTest::testRule
NoErrorSilencingRuleTest.php:15
FAILURES!
Tests: 1, Assertions: 1, Failures: 1.
If running all the tests takes too much time, you may run only the PHPStan rule tests suite:
vendor/bin/phpunit --testsuite "PHPStan rule tests"
Or just a single test, e.g.
vendor/bin/phpunit utils/PHPStan/tests/.../NoErrorSilencingRuleTest.php

Now we can start working on the actual test. We first create a script in the
Fixtures directory:
utils/PHPStan/tests/NoErrorSilencingRule/Fixtures/error-silencing.php
<?php
declare(strict_types=1);
@file_get_contents('not-found.txt');
Now we want to prove in the test that PHPStan will show the expected error
message for line 5 of this script. The RuleTestCase offers an analyse()
function that we can use for this purpose. We pass an array of file names to
analyze, and an array of expected errors:
<?php
declare(strict_types=1);
namespace Utils\PHPStan\Tests\NoErrorSilencingRule;
use PHPStan\Rules\Rule;
use PHPStan\Testing\RuleTestCase;
use Utils\PHPStan\NoErrorSilencingRule;
final class NoErrorSilencingRuleTest extends RuleTestCase
{
    public function testRule(): void
    {
        $this->analyse(
            [__DIR__ . '/Fixtures/error-silencing.php'],
            [
                [
                    'You should not use the silencing operator (@)',
                    5,
                ],
            ]
        );
    }
    protected function getRule(): Rule
    {
        return new NoErrorSilencingRule();
    }
}
Running PHPUnit again, we see that the test passes:
PHPUnit 9.5.20 #StandWithUkraine
.                                                         1 / 1 (100%)

Time: 00:00.782, Memory: 64.50 MB
OK (1 test, 1 assertion)
In this case we only need one example to show that the rule works. Normally
we'd have to provide more examples and demonstrate that our rule can deal
with edge cases too.
Deriving Types from the Current Scope
Let's work on a more elaborate example now. I'd like to encourage (or actually,
enforce) the use of Dependency injection in the project. No class should
manually fetch dependencies from the service container using its get()
method. This is a rule we can build with PHPStan.
First, we create a new rule class called NoContainerGetRule that implements
the Rule interface:
utils/PHPStan/src/NoContainerGetRule.php
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
final class NoContainerGetRule implements Rule
{
    public function getNodeType(): string
    {
        return Node::class;
    }
    public function processNode(Node $node, Scope $scope): array
    {
        echo $node::class . "\n";
        return [];
    }
}
Just as we did before, we echo the node types, so we can figure out which node
type is the most relevant for this rule.

We also create a fixture with a minimal example of something we don't want:
utils/PHPStan/tests/NoContainerGetRule/Fixtures/method-call-to-container-get.php
<?php
declare(strict_types=1);
/** @var ContainerInterface $container */
use Symfony\Component\DependencyInjection\ContainerInterface;
$container->get('logger');
Then we create a new test class, NoContainerGetRuleTest, and a single test
method that declares what error we expect when analysing the fixture file:
utils/PHPStan/tests/NoContainerGetRule/NoContainerGetRuleTest.php
<?php
declare(strict_types=1);
namespace Utils\PHPStan\Tests\NoContainerGetRule;
use PHPStan\Rules\Rule;
use PHPStan\Testing\RuleTestCase;
use Utils\PHPStan\NoContainerGetRule;
final class NoContainerGetRuleTest extends RuleTestCase
{
    public function testMethodCallToContainerGet(): void
    {
        $this->analyse(
            [__DIR__ . '/Fixtures/method-call-to-container-get.php'],
            [
                [
                    'Don\'t use the container as a service locator',
                    9,
                ],
            ]
        );
    }
    protected function getRule(): Rule
    {
        return new NoContainerGetRule();
    }
}
At first, this test will fail because the rule doesn't report any errors yet:
PHPUnit 9.5.20 #StandWithUkraine
F                                                         1 / 1

(100%)PHPStan\Node\FileNode
PhpParser\Node\Stmt\Declare_
PhpParser\Node\Stmt\DeclareDeclare
PhpParser\Node\Scalar\LNumber
PhpParser\Node\Stmt\Use_
PhpParser\Node\Stmt\UseUse
PhpParser\Node\Stmt\Expression
PhpParser\Node\Expr\MethodCall
PhpParser\Node\Expr\Variable
PhpParser\Node\Arg
PhpParser\Node\Scalar\String_
Time: 00:00.782, Memory: 64.50 MB
There was 1 failure:
In the output we see the echo-ed node types. Correlating the node types with
the method-call-to-container-get.php fixture is relatively straight-forward:
we can recognize the declare statement at the top, the use statement after that
(which imports Symfony's ContainerInterface), then a method call on a
variable, with a single string-type argument.
Our rule is going to be dealing with that MethodCall node, so we should return
its class name from getNodeType(). We also return the expected error using the
error builder again:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PhpParser\Node\Expr\MethodCall;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
final class NoContainerGetRule implements Rule
{
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    public function processNode(Node $node, Scope $scope): array
    {
        return [
            RuleErrorBuilder::message(
                'Don\'t use the container as a service locator'
            )->build(),
        ];

    }
}
Running the test again we should see it pass because the expected error
message is triggered on the expected line:
PHPUnit 9.5.20 #StandWithUkraine
.                                                         1 / 1 (100%)
Time: 00:00.782, Memory: 64.50 MB
OK (1 test, 1 assertion)
Although it makes this single test pass, this can't be the final version of the rule.
We don't want to trigger an error for any method call in our code base. We
should only do so if the method is get() and the object on which it's called is
an instance of ContainerInterface.
This means we need to enhance our test suite with two counter-examples. First,
an example where the object is not of type ContainerInterface, but the
method is get(). This example should not cause any errors, so the rule should
"skip" it:
utils/PHPStan/tests/NoContainerGetRule/Fixtures/skip-object-is-no-container-
interface.php
<?php
declare(strict_types=1);
/** @var NotAContainer $container */
$container->get('logger');
Then, another example where the object is of type ContainerInterface, but
we're calling a method that's not get():
utils/PHPStan/tests/NoContainerGetRule/Fixtures/skip-method-is-not-get.php
<?php
declare(strict_types=1);
/** @var ContainerInterface $container */
use Symfony\Component\DependencyInjection\ContainerInterface;
$container->set('logger', null);

We analyse these scripts in two new methods in our rule test. The empty array
means that we don't expect any errors to be produced when analysing these
scripts:
final class NoContainerGetRuleTest extends RuleTestCase
{
    // ...
    public function testSkipMethodIsNotGet(): void
    {
        $this->analyse(
            [__DIR__ . '/Fixtures/skip-method-is-not-get.php'],
            [
                // we expect no errors
            ]
        );
    }
    public function testSkipObjectIsNoContainerInterface(): void
    {
        $this->analyse(
            [
                __DIR__ .
'/Fixtures/skip-object-is-no-container-interface.php',
            ],
            [
                // we expect no errors
            ]
        );
    }
    // ...
}
Running PHPUnit again, we see these tests fail:
PHPUnit 9.5.20 #StandWithUkraine
.FF                                                       3 / 3 (100%)
Time: 00:00.782, Memory: 64.50 MB
There were 2 failures:
1) NoContainerGetRuleTest::testSkipMethodIsNotGet
Failed asserting that two strings are identical.
--- Expected
+++ Actual
@@ @@
-'
+'09: Don't use the container as a service locator
 '
RuleTestCase.php:83
NoContainerGetRuleTest.php:35

2) NoContainerGetRuleTest::testSkipObjectIsNoContainerInterface
Failed asserting that two strings are identical.
--- Expected
+++ Actual
@@ @@
-'
+'07: Don't use the container as a service locator
 '
RuleTestCase.php:83
NoContainerGetRuleTest.php:47
FAILURES!
Tests: 3, Assertions: 3, Failures: 2.
They fail because the rule still produces an error for every method call. Let's
enhance the rule to deal with these new cases now.
The first thing we need to do is find out if the object on which the method is
called is an instance of ContainerInterface. We'll now encounter PHPStan's
super-ability. As PHPStan analyzes our code, it continuously resolves the type
of each variable in the current scope. It keeps all the resolved types in an object
called Scope. We can use this object inside the processNode() method to find
out if the current method call is made on a ContainerInterface object. Scope
has a getType() method for this purpose, but we have to pass an expression
node to it. This is normally a variable. Where do we get this from? If we pass
the MethodCall node itself, we'll get the return type of the called method.
Let's look for some answers in the source code of the MethodCall node itself,
which we'll find in the phpstan.phar file (in PhpStorm you can also directly
search the class, e.g. using Ctrl + N):
<?php
declare(strict_types=1);
namespace PhpParser\Node\Expr;
use PhpParser\Node\Arg;
use PhpParser\Node\Expr;
use PhpParser\Node\Identifier;
use PhpParser\Node\VariadicPlaceholder;
class MethodCall extends CallLike
{
    /**
     * @var Expr Variable holding object
     */
    public $var;

    /**
     * @var Identifier|Expr Method name
     */
    public $name;
    /**
     * @var array<Arg|VariadicPlaceholder> Arguments
     */
    public $args;
Browsing through the source code of the node classes is always very
informative. Only by looking at the comments for the properties we can learn
that the object on which the method is called is represented by the $var
property, and that the name of the method can be found in the $name property.
According to the type hint of $var it's an Expr (expression) node, so let's try to
feed it to the Scope::getType() method. The result is going to be a Type object
which doesn't let itself be echo-ed or var_dump-ed because of its internal
complexities. Instead, we can call the describe() method on Type, and echo
the result:
use PHPStan\Type\VerbosityLevel;
final class NoContainerGetRule implements Rule
{
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        $objectType = $scope->getType($node->var);
        echo "\n" .
            $objectType->describe(VerbosityLevel::precise())
            . "\n";
        // ...
    }
}
PHPUnit 9.5.20 #StandWithUkraine
.
Symfony\Component\DependencyInjection\ContainerInterface
F
Symfony\Component\DependencyInjection\ContainerInterface
F                                                       3 / 3 (100%)
NotAContainer

Time: 00:00.782, Memory: 64.50 MB
There were 2 failures:
Instead of echo-ing all the time, I prefer using XDebug to step-debug. This works very well
(with PHPStorm at least), and it's very informative to step through PHPStan's own code.
Although echo messes with the output of PHPUnit, we still get some clue about
the types that PHPStan has derived for the variables used in our method calls:
ContainerInterface, ContainerInterface, and NotAContainer. That looks
correct.
In our rule we'd now like to do some kind of check like if ($node->var
instanceof ContainerInterface). Speaking in PHPStan's own terms, we
want to find out if the object type ContainerInterface is a super-type of the
type of $node->var. If it isn't, we return an empty array - we don't have any
errors to report.
use PHPStan\Type\ObjectType;
use Symfony\Component\DependencyInjection\ContainerInterface;
final class NoContainerGetRule implements Rule
{
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        $objectType = $scope->getType($node->var);
        $containerType = new ObjectType(ContainerInterface::class);
        if (! $containerType->isSuperTypeOf($objectType)->yes()) {
            return [];
        }
        // ...
    }
}

Trinary Logic
Note that isSuperTypeOf() doesn't return a bool ("yes" or "no"). Instead it returns "yes", "no",
or "maybe". That's because you can't always be certain that a variable is of a specific type. As
an example, if the type of a variable is mixed, it may be a ContainerInterface object, but it
could also be a string - you really don't know for sure.
You can find out more about yes/no/maybe logic and why PHPStan uses it on the documentation
page about trinary logic.
The result of adding the isSuperTypeOf() check is that we only have one
failing test left:
PHPUnit 9.5.20 #StandWithUkraine
.F.                                                       3 / 3 (100%)
Time: 00:00.782, Memory: 64.50 MB
There was 1 failure:
1) NoContainerGetRuleTest::testSkipMethodIsNotGet
Failed asserting that two strings are identical.
It's the other test where we verify that we don't get an error if the called method
is something else than get(). To fix that, we have to analyze the "name" part of
the MethodCall node:
<?php
declare(strict_types=1);
namespace PhpParser\Node\Expr;
use PhpParser\Node\Arg;
use PhpParser\Node\Expr;
use PhpParser\Node\Identifier;
use PhpParser\Node\VariadicPlaceholder;
class MethodCall extends CallLike
{
    /**
     * @var Expr Variable holding object
     */
    public $var;
    /**
     * @var Identifier|Expr Method name
     */
    public $name;

    /**
     * @var array<Arg|VariadicPlaceholder> Arguments
     */
    public $args;
Apparently the method name can be an instance of Identifier or Expr.
Normally a method name will be an Identifier, e.g. when you explicitly call a
method by its name like $container->get(). However, given PHP's dynamic
nature, we could also encounter a method call that looks like this: $container-
>{$varThatContainsTheName}(). I generally tend to ignore these cases in my
rules and assume that nobody does that (we could write a PHPStan rule for that
anyway, if it doesn't exist already).
We can filter out method names that are not an Identifier, by adding an early
return. Looking up the code for the Identifier node it turns out to be quite
simple:
<?php
declare(strict_types=1);
namespace PhpParser\Node;
use PhpParser\NodeAbstract;
/**
 * Represents a non-namespaced name. Namespaced names are represented
 * using Name nodes.
 */
class Identifier extends NodeAbstract
{
    /**
     * @var string Identifier as string
     */
    public $name;
    private static $specialClassNames = [
        'self' => true,
        'parent' => true,
        'static' => true,
    ];
It has a public $name property that we can access to find out the actual method
name. Let's express this knowledge in another if clause inside our rule:
use PhpParser\Node\Identifier;
final class NoContainerGetRule implements Rule
{

    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        $objectType = $scope->getType($node->var);
        $containerType = new ObjectType(ContainerInterface::class);
        if (! $containerType->isSuperTypeOf($objectType)->yes()) {
            return [];
        }
        if (! $node->name instanceof Identifier) {
            // This is a dynamic method call, let's ignore it
            return [];
        }
        if ($node->name->name !== 'get') {
            // Not a call to `ContainerInterface::get()`, ignore it
            return [];
        }
        return [
            RuleErrorBuilder::message(
                'Don\'t use the container as a service locator'
            )->build(),
        ];
    }
}
This will finally make our tests pass. The rule is fine for now, we can enable it
in our project's phpstan.neon file, just as we did before. Running the rule on
real-world code may give us some more feedback about its correctness and
other edge cases we have to deal with. For every such edge case, make sure to
also add another test with a fixture!
Putting a Node in Context
One thing that's likely to happen is that the rule we imagined is too hard to
comply to in practice. Or maybe the rule is only meaningful in certain parts of
the code base, but not everywhere. For example, in our current example we
may decide that manually fetching dependencies is generally not allowed,

except inside controller classes. Let's describe this new edge case with a new
fixture:
utils/PHPStan/tests/NoContainerGetRule/Fixtures/skip-container-get-in-
controller.php
<?php
declare(strict_types=1);
use Symfony\Component\DependencyInjection\ContainerInterface;
final class SomeController
{
    private ContainerInterface $container;
    public function someMethod(): void
    {
        $this->container->get('logger');
    }
}
We also add a test case for this fixture:
final class NoContainerGetRuleTest extends RuleTestCase
{
    // ...
    public function testSkipContainerGetInController(): void
    {
        $this->analyse(
            [
                __DIR__
                . '/Fixtures/skip-container-get-in-controller.php',
            ],
            [
                // we expect no errors
            ]
        );
    }
    // ...
}
PHPUnit 9.5.20 #StandWithUkraine
...F                                                      4 / 4 (100%)
Time: 00:00.782, Memory: 64.50 MB
There was 1 failure:
1) NoContainerGetRuleTest::testSkipContainerGetInController
Failed asserting that two strings are identical.

The test fails, because the rule doesn't allow any calls to
ContainerInterface::get(), regardless of the context.
To enhance the rule we need to find out if the method call takes place inside a
controller class. We need to know two things:
Are we inside a class? We can figure this out using the method
isInClass() that's available on the Scope object passed to
processNode().
Is the class a controller? We need to define how we can recognize a class
to be a controller.
One option to define a controller class is to say that its name should end with
"Controller". This may lead to a few false-positives, but as a first guess it's
okay. We'll refine this logic later.
We can implement our new knowledge in the rule class as follows:
final class NoContainerGetRule implements Rule
{
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        if ($scope->isInClass()
            && str_ends_with(
                $scope->getClassReflection()
                    ->getName(),
                'Controller'
            )) {
            /*
             * We're allowed to call `ContainerInterface::get()`
             * inside classes that end with "Controller"
             */
            return [];
        }
        return [
            RuleErrorBuilder::message(
                'Don\'t use the container as a service locator'
            )->build(),
        ];

    }
}
PHPUnit 9.5.20 #StandWithUkraine
....                                                      4 / 4 (100%)
Time: 00:00.782, Memory: 64.50 MB
OK (4 tests, 4 assertions)
Let's consider how can we make the rule a bit more reusable by making the
class name suffix configurable. After all, maybe controllers aren't called
[...]Controller, but [...]RequestHandler instead.
We first define the suffix as a string-type constructor parameter:
final class NoContainerGetRule implements Rule
{
    public function __construct(
        private readonly string $suffix
    ) {
    }
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        if ($scope->isInClass()
            && str_ends_with(
                $scope->getClassReflection()
                    ->getName(),
                $this->suffix,
            )) {
            /*
             * We're allowed to call `ContainerInterface::get()`
             * inside classes that end with the given suffix
             */
            return [];
        }
        // ...
    }
}

To make the existing test work again, we should update getRule() to pass the
suffix 'Controller' as a constructor argument of the rule, since this suffix is
used in the existing fixtures:
final class NoContainerGetRuleTest extends RuleTestCase
{
    // ...
    protected function getRule(): Rule
    {
        return new NoContainerGetRule('Controller');
    }
}
When we want to use the rule in our project, we also have to provide a value for
$suffix. We can do this by configuring the rule as a service in PHPStan's
service container, which means adding it to the services section of the
project's phpstan.neon file, and tag it as phpstan.rules.rule:
parameters:
    level: max
    paths:
        - src
services:
    -
        class: Utils\PHPStan\NoContainerGetRule
        tags:
            - phpstan.rules.rule
        arguments:
            suffix: "RequestHandler"
If the rule was previously defined in the rules section, it should be removed
there. Only rules that can be auto-wired by the service container may be added
directly to the rules section. Rules that need explicit configuration should be
added to services. See also Dependency Injection & Configuration.
Generalizing a Rule
We tried to generalize the rule by making the controller class name suffix
configurable. Whether this works really depends on the conventions of your
framework and project. There are many alternatives for recognizing controllers,
e.g.
The namespace of a class contains the word Controller
The file that contains the class is in a folder called controllers/

The class has at least one @Route annotation
The class is mentioned in a routing.php configuration file
The NoContainerGetRule class currently has a hard-coded answer to the
question "Is this a controller?". To make the rule more flexible we should
refactor the code to delegate the answer to a different class, using the Strategy
pattern (from Design Patterns, by Erich Gamma e.a.). This pattern starts with
defining an interface for the question. In our case the interface may be called
ControllerDetermination (optionally suffixed or annotated with "Strategy").
It should have a method isController(): bool. As arguments, we could pass
anything that an implementation might need, but most likely it should be
enough to pass PHPStan's ClassReflection object. This object exposes many
aspects of the class by providing methods like getName(), hasMethod(), etc.
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PHPStan\Reflection\ClassReflection;
interface ControllerDetermination
{
    public function isController(ClassReflection $class): bool;
}
We can "plug" this interface into our PHPStan rule as a constructor argument
and rewrite the if clause for controller classes as follows:
final class NoContainerGetRule implements Rule
{
    public function __construct(
        private readonly ControllerDetermination $determination,
    ) {
    }
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        if ($scope->isInClass()
            && $this->determination->isController(
                $scope->getClassReflection()
            )) {

            /*
             * We're allowed to call `ContainerInterface::get()`
             * inside controllers
             */
            return [];
        }
        // ...
    }
}
At runtime, we'll inject an implementation of the interface that answers the
question in the particular way that we need for the project. In this example we
can have a suffix-based implementation of the ControllerDetermination
interface:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PHPStan\Reflection\ClassReflection;
final class DeterminationBasedOnSuffix implements
ControllerDetermination
{
    public function __construct(
        private readonly string $suffix = 'Controller'
    ) {
    }
    public function isController(ClassReflection $class): bool
    {
        return str_ends_with($class->getName(), $this->suffix);
    }
}
Similar to how we defined the suffix parameter in our PHPStan configuration
file, we should now define this implementation as a service. PHPStan's service
container uses auto-wiring. It recognizes that DeterminationBasedOnSuffix
implements ControllerDetermination and injects it as an argument for rules
that require a constructor argument of this type:
parameters:
    level: max
    paths:
        - src
services:
    -
        class: Utils\PHPStan\NoContainerGetRule
        tags:

            - phpstan.rules.rule
    -
        class: Utils\PHPStan\DeterminationBasedOnSuffix
        arguments:
            suffix: "RequestHandler"
The tests will fail because there we just do new NoContainerGetRule(),
without providing an argument for the ControllerDetermination parameter.
One way to make it work is to hard-code the argument to an instance of
DeterminationBasedOnSuffix, the only implementation that we have so far:
use Utils\PHPStan\DeterminationBasedOnSuffix;
final class NoContainerGetRuleTest extends RuleTestCase
{
    // ...
    protected function getRule(): Rule
    {
        return new NoContainerGetRule(new DeterminationBasedOnSuffix());
    }
}
Another way is to rely on the auto-wiring capabilities of the service container in
the test as well. To make this work we have to define a configuration file that
defines the necessary services:
utils/PHPStan/tests/NoContainerGetRule/phpstan.neon
services:
    -
        class: Utils\PHPStan\NoContainerGetRule
        tags:
            - phpstan.rules.rule
    -
        class: Utils\PHPStan\DeterminationBasedOnSuffix
        arguments:
            suffix: "Controller"
When we return the path of this file from the test's
getAdditionalConfigFiles() method, we can fetch the service directly from
the container inside the getRule() method:
final class NoContainerGetRuleTest extends RuleTestCase
{
    // ...
    public static function getAdditionalConfigFiles(): array
    {
        return [__DIR__ . '/phpstan.neon'];
    }

    protected function getRule(): Rule
    {
        return self::getContainer()->getByType(
            NoContainerGetRule::class,
        );
    }
}
Conclusion
This concludes the introduction about writing custom rules for PHPStan. With
the basics discussed, we're now ready to dive into the main content of the book.
Whenever we have to write a custom rule to enforce some decoupling principle,
we'll be ready for it. I do recommend taking a closer look at PHPStan's own,
well-written documentation for developing extensions. It doesn't take much
time and provides some very valuable information for custom rule developers
like ourselves.
OceanofPDF.com

2 Web Frameworks
This Chapter Covers:
Preparing for a web framework migration
Making every step in a controller explicit
Decoupling from template rendering libraries
Creating PHPStan rules for controllers and views
Introduction
For a long time my favorite framework was Symfony, until the day I started
liking Laminas Mezziomore. There have been many frameworks, and they have
been the favorites of many developers, but occasionally one of them gets
abandoned by its maintainers. And so the quest for the next "best" framework
begins. Something similar that many of us have experienced: the maintainers
were tired of version X, so they rewrote the whole thing, and it was released as
version Y. Why indeed! The result was a lot of work.
My experience in web development has proven to me that we need to be ready
to get rid of a framework. We should also be ready to upgrade our current
framework to the next major version, which can be as drastic as switching to a
completely different framework. In particular if we've coupled our code to the
framework, in all the possible documented (and undocumented) ways.
It may be a clichÃ© by now, but we need to keep the framework at a safe
distance. If we do so, I'm sure we can save ourselves a lot of expensive
development work, trying to get a project up-to-date again. In practice, this
"safe distance" means we should not use any framework facilities in some parts
of our code, while we allow other parts to make optimal use of the framework's
special abilities. This will give us the benefits of working with a framework
(mostly that there's no need to reinvent certain wheels), while giving us the
flexibility to upgrade the framework without too much trouble, or even to
migrate to a different framework.

The million-dollar question is: what are those parts, and where should the cut
be? To find the answer, let's first consider what web frameworks have offered
us in the past, but also: what will they keep doing for us in the future? What's
the common denominator?
What I think a web framework will always have to do, is:
Match the URI of the HTTP request to one of our controllers based on
some pattern (routing).
Instantiate and invoke the matched controller, providing the request itself
as input.
Turn the response returned from the controller into a proper HTTP
response that a browser can show to the user.
Catch exceptions that occur inside the controller and turn them into error
responses.
Controllers play an important role here: they are the place where, as developers,
we can finally do something. But what we do is often quite repetitive: we load
data from the database, apply the changes to it that were submitted using a
form, we save the resulting data, and finally we render a nice page for the user.
Framework authors try to make our controllers simpler by removing some of
this duplication, and providing convenient shortcuts. This is often achieved
with magical features that are implemented by running some code before and
after our controller code. For instance, the framework may magically do the
following things for us:
Validate request data
Load an entity based on a matched URI parameter and pass it as a
controller argument
Provide the logged-in user object as a controller argument
Render a template based on an annotation
These features count as magical because for the reader it's not clear what
happens, when, and based on what input.
Controllers
Framework magic is great and can count on a lot of burning tweets and blog
posts. But if we want to prepare our controllers for the inevitable framework

switch or upgrade, we should refrain from using too much of it. Developers
who have been given this task will be better off if they can look at the controller
and understand everything that it does. If they want to find out more, they
should be able to zoom in by "clicking" on a method. Each of the method calls
should receive all the required input data as actual arguments. If there's some
magic left in a controller, and the developers don't understand how it works,
they may accidentally break, or completely drop some existing functionality.
For instance, consider the following Symfony controller:
<?php
declare(strict_types=1);
namespace App\AppBundle\Controller;
// ...
final class MeetupsController extends AbstractController
{
    /**
     * @Route("/reschedule-meetup/{id}", name="reschedule_meetup")
     * @Template("reschedule-meetup.html.twig")
     * @return array<string,mixed>|Response
     */
    public function rescheduleMeetupAction(
        Request $request,
        ManagerRegistry $doctrine,
        Meetup $meetup
    ): array|Response {
        $entityManager = $doctrine->getManager();
        $form = $this->createForm(RescheduleMeetupForm::class, $meetup);
        $form->handleRequest($request);
        if ($form->isSubmitted() && $form->isValid()) {
            $entityManager->flush();
            return $this->redirectToRoute('homepage');
        }
        return [
            'form' => $form->createView(),
        ];
    }
}
This controller is used for "rescheduling a meetup". We get the relevant Meetup
entity as a method argument. It's automatically fetched for us based on an ID,
which is the dynamic part of the route (/reschedule-meetup/{id}). After

saving the changes the controller either redirects the user to the homepage, or
Symfony will render an HTML page based on the template name mentioned in
the @Template annotation and the array of template variables we return from
the controller.
Show How the Response is Created
When we'd want to port this controller to, say, Laminas Mezzio, we first need
to understand how all of this works, make all the implicit steps explicit, and
implement the same steps with similar functionality offered by Mezzio. Mezzio
doesn't support @Template annotations or magic processing of those, but we
could still use Twig for template rendering in a Mezzio application as well. So
instead of returning an array of template variables and relying on the @Template
annotation for the rendering of the view, we should inject Twig as a dependency
and call its render() function ourselves:
<?php
declare(strict_types=1);
namespace App\AppBundle\Controller;
// ...
use Symfony\Component\HttpFoundation\Response;
use Twig\Environment;
final class MeetupsController extends AbstractController
{
    public function __construct(
        private Environment $twig
    ) {
    }
    /**
     * @Route("/reschedule-meetup/{id}")
     */
    public function rescheduleMeetupAction(
        Request $request,
        ManagerRegistry $doctrine,
        Meetup $meetup
    ): Response {
        // ...
        return new Response(
            $this->twig->render(
                'reschedule-meetup.html.twig',
                [
                    'form' => $form->createView(),
                ],
            ),
        );

    }
}
I'd like to call this a fork, like in chess. Even if we don't have to migrate to a
different framework, we have still improved the code: it shows exactly what it
does, when, and based on what input. This is going to be very helpful for
anyone who is working with this code.
I also like to consider the question: why did we need the "simplification" of a
@Template annotation in the first place? It seems like a way to avoid having to
constructor-inject an actual dependency, and to have a method call. Certainly,
it's possible to get rid of such "boilerplate" code, but at a cost (framework
coupling, and implicitness) that is bigger than the presumed benefits (less
code).
Now that we render the view ourselves, we can simplify the return type of the
controller. Instead of returning an array or a Response, from now on it will
always return a Response object. By doing so we get the additional benefit that
the types in the controller are communicating the purpose of a controller: to
take a Request as input, and return a Response for it.
Only Use Constructor Injection for Dependencies
We made the Twig dependency explicit by injecting it as a constructor
argument. Since Symfony supports method injection too, we could've added it
as a method argument. However, if we're looking to decouple our controller we
shouldn't rely on that. The clue is in the sentence: "Symfony supports ...".
That's great, but another framework may not. In fact, Mezzio doesn't. In a
Mezzio application, each controller can have only one method, and its signature
is completely defined by the RequestHandlerInterface:
<?php
declare(strict_types=1);
namespace Psr\Http\Server;
use Psr\Http\Message\ResponseInterface;
use Psr\Http\Message\ServerRequestInterface;
/**
 * Handles a server request and produces a response.
 *
 * An HTTP request handler process an HTTP request in order to produce

 * an HTTP response.
 */
interface RequestHandlerInterface
{
    /**
     * Handles a request and produces a response.
     *
     * May call other collaborating code to generate the response.
     */
    public function handle(
        ServerRequestInterface $request
    ): ResponseInterface;
}
Mezzio therefore doesn't allow additional parameters to be added to a
controller method. Then again, maybe we'll migrate to a framework that does
support method injection? Again, it's not about what features a framework may
or may not support, but about the common denominator, or: what a framework
definitely will support. So to be safe, we'd rather rely on constructor injection
only, which should always work.
By the way, this results in another fork. The benefit of using constructor
injection is that a controller is instantly recognizable as a service. For any other
service we use the following approach: we instantiate it first with all its
dependencies injected as constructor arguments, then we call methods on it,
providing the actual input for the work it's going to do. We can reuse the same
service again, passing different arguments for each "job".
Make Every Step Explicit
The next step is to make all the magic entity juggling explicit. What happens in
the original controller is that based on the provided ID, which will be extracted
from the request URI (/reschedule-meetup/{id}), the entity manager will try
to load the Meetup entity, which is passed as one of the controller method's
arguments. Instead of relying on all this implicit magic, we may (again!) just as
easily do this ourselves. We can use the ManagerRegistry service for this,
which we already receive as a method argument. Let's use this opportunity to
promote it to a constructor argument too, like we did before. To mimic the
existing behavior we should also throw a "404" exception if the Meetup was not
found.
<?php
declare(strict_types=1);

namespace App\AppBundle\Controller;
// ...
use Symfony\Component\HttpFoundation\Response;
use Twig\Environment;
final class MeetupsController extends AbstractController
{
    public function __construct(
        private Environment $twig,
        private ManagerRegistry $doctrine,
    ) {
    }
    /**
     * @Route("/reschedule-meetup/{id}")
     */
    public function rescheduleMeetupAction(Request $request): Response
    {
        $entityManager = $this->doctrine->getManager();
        $meetup = $entityManager->find(
            Meetup::class,
            $request->attributes->get('id')
        );
        if ($meetup === null) {
            throw $this->createNotFoundException();
        }
        $form = $this->createForm(RescheduleMeetupForm::class, $meetup);
        // ...
    }
}
Controllers Have No Parent Class
Next we have to get rid of the controller's parent class, AbstractController.
This class is provided by the framework, and provides some useful helper
methods, like createForm(), redirectToRoute() and
createNotFoundException(). However, these methods only work with the
current framework. Plus, they use the service locator pattern to fetch services,
which doesn't necessarily work with other frameworks either. It also leaves
some of the controller's dependencies implicit. So let's "inline" the methods we
use from AbstractController and make our controller even more explicit.
Once we've done this, we can remove the extends part from the class
definition:
<?php
declare(strict_types=1);
namespace App\AppBundle\Controller;

// ...
use Symfony\Component\HttpFoundation\Response;
use Symfony\Component\Routing\Generator\UrlGeneratorInterface;
use Twig\Environment;
final class MeetupsController
{
    public function __construct(
        // ...
        private FormFactoryInterface $formFactory,
        private UrlGeneratorInterface $urlGenerator,
    ) {
    }
    /**
     * @Route("/reschedule-meetup/{id}")
     */
    public function rescheduleMeetupAction(Request $request): Response
    {
        // ...
        if ($meetup === null) {
            throw new NotFoundHttpException();
        }
        $form = $this->formFactory->create(
            RescheduleMeetupForm::class,
            $meetup
        );
        // ...
        if ($form->isSubmitted() && $form->isValid()) {
            // ...
            return new RedirectResponse(
                $this->urlGenerator->generate('homepage')
            );
        }
        // ...
    }
}
Every Action Has its Own Controller Class
Although not strictly required, there's one more thing we can do to make
controllers more portable: move every action to its own class. This allows
migrating controllers per action to the new framework, which will be very
welcome during big refactoring projects. It also helps prevent the often heard
concern that a controller class receives too many dependencies because each
action requires different ones.
<?php

declare(strict_types=1);
namespace App\AppBundle\Controller;
// ...
final class RescheduleMeetupController
{
    // ...
    /**
     * @Route("/reschedule-meetup/{id}")
     */
    public function __invoke(Request $request): Response
    {
        // ...
        return new Response(
            // ...
        );
    }
}
In the end, we no longer rely on magical things that happen before or after the
controller is executed. The only thing we do rely on is that the route will be
matched with the request URI and that the framework will execute our
controller. We decided earlier that this is something we can indeed rely on.
We'll always need some configuration to make this work, and in this case the
configuration is in the doc block @Route annotation, but whenever we'd have to
migrate to a different router, we'd always have to do some work here as well, so
we don't have to "decouple" this part now.
Shouldn't we also decouple from Twig and set up our own "template renderer"
abstraction? Shouldn't we also abstract from Doctrine, our ORM? What about
the Symfony Form component? We'll get back to the topic of template
rendering in the section about Views. The ORM will be covered in Chapter 5,
and form validation in Chapter 4.
Should We Use an HTTP Abstraction Library?
What about decoupling from Symfony's Request and Response objects? We
have PSR-7after all, which defines these objects in a framework-agnostic way,
and as a bonus also offers immutable versions of them. Even though at some
point Symfony supported PSR-7, and if you like you can still use PSR-7
objects, you don't really have to. If you migrate to a different framework, it
may come with its own set of Request and Response objects, and you'd have to
rewrite calls to this object anyway. At least those calls have been made explicit

in previous efforts to make our code decoupled to some extent. At that point,
migrating to the new framework will be a matter of rewriting those method
calls (like $request->attributes->get()), which is hopefully a mindless
operation, so it can be automated with Rector.
As a final code sample for this section let's look at how easy it is to migrate to
Laminas Mezzio, given the current state of the controller:
<?php
declare(strict_types=1);
namespace App\RequestHandler;
// ...
use Laminas\Diactoros\Response\HtmlResponse;
use Laminas\Diactoros\Response\RedirectResponse;
use Psr\Http\Message\ResponseInterface;
use Psr\Http\Message\ServerRequestInterface;
use Psr\Http\Server\RequestHandlerInterface;
use Symfony\Bridge\PsrHttpMessage\Factory\HttpFoundationFactory;
use Mezzio\Router\RouterInterface;
final class RescheduleMeetupRequestHandler implements
RequestHandlerInterface
{
    public function __construct(
        private Environment $twig,
        private ManagerRegistry $doctrine,
        private FormFactoryInterface $formFactory,
        private RouterInterface $router,
        private HttpFoundationFactory $httpFoundationFactory,
    ) {
    }
    public function handle(
        ServerRequestInterface $request
    ): ResponseInterface {
        $entityManager = $this->doctrine->getManager();
        $meetup = $entityManager->find(
            Meetup::class,
            $request->getAttribute('id')
        );
        if ($meetup === null) {
            return new HtmlResponse(
                $this->twig->render('error/404.html.twig'),
                404
            );
        }
        $form = $this->formFactory->create(
            RescheduleMeetupForm::class,
            $meetup
        );
        $form->handleRequest(

            $this->httpFoundationFactory->createRequest($request)
        );
        if ($form->isSubmitted() && $form->isValid()) {
            $entityManager->flush();
            return new RedirectResponse(
                $this->router->generateUri('homepage')
            );
        }
        return new HtmlResponse(
            $this->twig->render(
                'reschedule-meetup.html.twig',
                [
                    'form' => $form->createView(),
                ],
            ),
        );
    }
}
Since Mezzio is based on PSR-15, the controller should implement
RequestHandlerInterface. This is okay; our controller action already expects
a Request object and returns a Response object. The migration to PSR-7
request and response objects means that we have to bridge the gap with the
Symfony Form component because it still only accepts Symfony request
objects. That's what the HttpFoundationFactory is for, which comes from
Symfony's PSR-7 bridge component.
Rules for Decoupled Controllers
Looking back at the previous sections there were several things we did to
decouple from the web framework that can be rephrased as "rules" for all the
controllers in our code base:
Inject dependencies as constructor arguments, not as method arguments.
This could be rephrased as: controller methods can only have the Request
as an argument.
Always return a Response from a controller method (not an array of
template variables).
Don't extend from AbstractController (or slightly weaker: don't use any
of its methods).
Each controller has only one method (i.e. one public function), which is
often called "action".

Great news; it's possible to create PHPStan rules for all of these decoupling
rules!
Forbidden Parent Classes
Let's start with one of the simpler rules: that we don't allow a controller class to
extend from the parent class provided by the framework, which for Symfony is
called AbstractController. We start with setting up a new rule class and a
corresponding test class (see the chapter about writing custom PHPStan rules
for the steps involved). We create a fixture that shows an example of the code
we'd like to trigger an error for:
utils/PHPStan/tests/AbstractControllerRule/Fixtures/extends-abstract-controller.php
<?php
declare(strict_types=1);
use Symfony\Bundle\FrameworkBundle\Controller\AbstractController;
class SomeController extends AbstractController
{
}
Then we create a test that analyzes this fixture and declares the error it expects:
<?php
declare(strict_types=1);
namespace Utils\PHPStan\Tests\AbstractControllerRule;
use PHPStan\Rules\Rule;
use PHPStan\Testing\RuleTestCase;
use Utils\PHPStan\AbstractControllerRule;
final class AbstractControllerRuleTest extends RuleTestCase
{
    public function testRule(): void
    {
        $this->analyse(
            [__DIR__ . '/Fixtures/extends-abstract-controller.php'],
            [
                [
                    'Controllers should not extend from
AbstractController',
                    7,
                ],
            ]
        );
    }

    protected function getRule(): Rule
    {
        return new AbstractControllerRule();
    }
}
The rule subscribes itself to any node, and for now just dumps the node type,
just as we did before:
utils/PHPStan/src/AbstractControllerRule.php
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
final class AbstractControllerRule implements Rule
{
    public function getNodeType(): string
    {
        return Node::class;
    }
    public function processNode(Node $node, Scope $scope): array
    {
        echo $node::class . "\n";
        return [];
    }
}
The output of running this test:
PHPUnit 9.5.20 #StandWithUkraine
F                                                         1 / 1
(100%)PHPStan\Node\FileNode
PhpParser\Node\Stmt\Declare_
PhpParser\Node\Stmt\DeclareDeclare
PhpParser\Node\Scalar\LNumber
PhpParser\Node\Stmt\Use_
PhpParser\Node\Stmt\UseUse
PhpParser\Node\Stmt\Class_
PHPStan\Node\InClassNode
PHPStan\Node\ClassPropertiesNode
PHPStan\Node\ClassMethodsNode
PHPStan\Node\ClassConstantsNode

Comparing the node types with the code in the fixture file, our best guess would
be to zoom in on the Class_ statement node. Opening the corresponding class
in our IDE, we discover that it has an $extends property which is of type
null|Node\Name:
<?php
declare(strict_types=1);
namespace PhpParser\Node\Stmt;
use PhpParser\Error;
use PhpParser\Node;
class Class_ extends ClassLike
{
    public const MODIFIER_PUBLIC = 1;
    public const MODIFIER_PROTECTED = 2;
    public const MODIFIER_PRIVATE = 4;
    public const MODIFIER_STATIC = 8;
    public const MODIFIER_ABSTRACT = 16;
    public const MODIFIER_FINAL = 32;
    public const MODIFIER_READONLY = 64;
    public const VISIBILITY_MODIFIER_MASK = 7; // 1 | 2 | 4
    /**
     * @var int Type
     */
    public $flags;
    /**
     * @var null|Node\Name Name of extended class
     */
    public $extends;
This makes sense: a class may or may not extend another class.
We should be able to inspect this $extends property inside our rule, and return
an error if it refers to Symfony's AbstractController class. First, let's make
the test pass in the naive way: by returning an error for any class statement.
We do this by returning Class_::class from the getNodeType() method, and
by always returning an error from the processNode() method:
use PhpParser\Node\Stmt\Class_;
use PHPStan\Rules\RuleErrorBuilder;

final class AbstractControllerRule implements Rule
{
    public function getNodeType(): string
    {
        return Class_::class;
    }
    public function processNode(Node $node, Scope $scope): array
    {
        return [
            RuleErrorBuilder::message(
                'Controllers should not extend from AbstractController',
            )->build(),
        ];
    }
}
Indeed, the test passes:
PHPUnit 9.5.20 #StandWithUkraine
.                                                         1 / 1 (100%)
Time: 00:00.782, Memory: 64.50 MB
OK (1 test, 1 assertion)
When doing test-driven development, this is known as "doing the simplest
thing to make the test pass". It's not always the best approach because you
already know this isn't the correct solution. However, when writing rules I
think implementing the most naive solution first is very helpful. It keeps things
less overwhelming in the beginning. With a working test and a happy but
unrealistic path I find it easier to come up with edge cases that I want the rule to
be able to deal with.
In our case we have to add another fixture that serves as an example of a class
that should not trigger an error, e.g. a class that doesn't extend from any class
at all:
utils/PHPStan/tests/AbstractControllerRule/Fixtures/skip-class-extends-nothing.php
<?php
declare(strict_types=1);
class ControllerExtendsNothing
{
}

We analyze this new fixture in a test that verifies that no error ([]) was
triggered:
final class AbstractControllerRuleTest extends RuleTestCase
{
    // ...
    public function testExtendsNothing(): void
    {
        $this->analyse(
            [__DIR__ . '/Fixtures/skip-class-extends-nothing.php'],
            []
        );
    }
    // ...
}
Of course, this test will fail, since the rule returns an error for all class
statements. We have to adapt the rule to return early if the class has no
extends part:
final class AbstractControllerRule implements Rule
{
    // ...
    /**
     * @param Class_ $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if ($node->extends === null) {
            // This class does not `extend` anything
            return [];
        }
        return [
            RuleErrorBuilder::message(
                'Controllers should not extend from AbstractController',
            )->build(),
        ];
    }
}
This makes the test pass!
But what about the other (maybe obvious) case: where the class does extend
another class, but it's not AbstractController. In that case the $extends
property of the Class_ node will contain a Name node. Looking at the Name class

itself, it turns out that it has several subclasses: Relative and FullyQualified.
Let's find out more about the Name node by var_dump-ing it on screen:
PHPUnit 9.5.20 #StandWithUkraine
.object(PhpParser\Node\Name\FullyQualified)#8016 (2) {
  ["attributes":protected]=>
  array(7) {
    ["startLine"]=>
    int(7)
    ["startTokenPos"]=>
    int(21)
    ["endLine"]=>
    int(7)
    ["endTokenPos"]=>
    int(21)
    ["originalName"]=>
    object(PhpParser\Node\Name)#8026 (2) {
      ["attributes":protected]=>
      array(4) {
        ["startLine"]=>
        int(7)
        ["startTokenPos"]=>
        int(21)
        ["endLine"]=>
        int(7)
        ["endTokenPos"]=>
        int(21)
      }
      ["parts"]=>
      array(1) {
        [0]=>
        string(18) "AbstractController"
      }
    }
    ["statementOrder"]=>
    int(0)
    ["statementDepth"]=>
    int(1)
  }
  ["parts"]=>
  array(5) {
    [0]=>
    string(7) "Symfony"
    [1]=>
    string(6) "Bundle"
    [2]=>
    string(15) "FrameworkBundle"
    [3]=>
    string(10) "Controller"
    [4]=>
    string(18) "AbstractController"
  }
}
.                                                        2 / 2 (100%)
Time: 00:00.782, Memory: 64.50 MB
OK (2 tests, 2 assertions)

Using var_dump on a node object may produce so much output that it's no
longer useful. But in this case it works. We notice it's an instance of
FullyQualified. This may be surprising because in the fixture file we didn't
provide the fully-qualified class name; we used the shorter version
AbstractController, which we imported at the top of the file with a use
statement. This shows to us that PHPStan resolves relative names to the
equivalent fully-qualified names for you, which is very useful in this case. The
FullyQualified node has a method toString() which will return the fully-
qualified class name (FQCN), including the namespace, so we can compare it
to the FQCN of AbstractController.
We know what needs to be done, but before touching the rule code itself, we
should write another fixture that shows a class which extends from a class that
is not AbstractController.
<?php
declare(strict_types=1);
class Controller extends SomethingElse
{
}
Note that the extended class doesn't even have to exist.
We then add a test case to prove that analyzing this fixture doesn't produce any
errors:
final class AbstractControllerRuleTest extends RuleTestCase
{
    // ...
    public function testExtendsSomethingElse(): void
    {
        $this->analyse(
            [
                __DIR__ .
'/Fixtures/skip-class-extends-something-else.php',
            ],
            []
        );
    }
    // ...
}

We can now adapt the rule to include another early return in case the extended
class is not AbstractController:
final class AbstractControllerRule implements Rule
{
    // ...
    /**
     * @param Class_ $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        if ($node->extends->toString() !== AbstractController::class) {
            // The extended class is not `AbstractController`
            return [];
        }
        return [
            RuleErrorBuilder::message(
                'Controllers should not extend from AbstractController',
            )->build(),
        ];
    }
}
Running the tests again, they all pass now.
Often when you're developing a custom rule, you'll realize that it is a specific
example of a generic rule. Looking at our AbstractControllerRule we could
generalize it into a rule that prevents any given class from being used as a
parent class. This would make the rule reusable in other scenarios that you want
to prevent in your project. We could accomplish this by injecting the name of
the forbidden parent class as a constructor argument. We should also rename the
rule to match the new abstraction level:
final class ForbiddenParentClassRule implements Rule
{
    public function __construct(
        private readonly string $forbiddenParentClass,
    ) {
    }
    // ...
    /**
     * @param Class_ $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...

        if (
            $node->extends->toString() !== $this->forbiddenParentClass
        ) {
            // The extended class is not the forbidden parent class
            return [];
        }
        return [
            RuleErrorBuilder::message(
                sprintf(
                    'Parent class %s is forbidden',
                    $this->forbiddenParentClass,
                ),
            )->build(),
        ];
    }
}
You can set up this rule in the services section of phpstan.neon multiple
times with different arguments, like this:
services:
    -
        class: Utils\PHPStan\ForbiddenParentClassRule
        tags:
            - phpstan.rules.rule
        arguments:
            -
Symfony\Bundle\FrameworkBundle\Controller\AbstractController
    -
        class: Utils\PHPStan\ForbiddenParentClassRule
        tags:
            - phpstan.rules.rule
        arguments:
            - DateTime
Allowing Only Parameters of a Certain Type
The next rule we may pick up is the one where we want to ensure that only the
current Request object is provided as an argument to a controller action. As a
side effect, this also rules out any service dependency that is injected as a
method argument instead of a constructor argument. We may call this rule
ControllerActionAllowedParameterTypeRule, but it should fit on a book
page, so let's change it to the less descriptive ActionAllowedParameterRule.
We already covered the initialization phase for new rules several times now, so
from now on I'll leave out the steps where we create a new rule that subscribes
to any Node type and dumps it on screen, as well as the step where we set up a
new test for it that produces the expected error based on a fixture that represents

a typical case. The fixture itself will be useful to show here though. It passes a
service dependency as a method argument:
utils/PHPStan/tests/ActionAllowedParameterRule/Fixtures/parameter-type-not-
allowed.php
<?php
declare(strict_types=1);
use Symfony\Component\EventDispatcher\EventDispatcherInterface;
use Symfony\Component\HttpFoundation\Request;
use Symfony\Component\HttpFoundation\Response;
class SomeController
{
    public function someAction(
        Request $request,
        EventDispatcherInterface $notAllowed,
    ): Response {
    }
}
Dumping the nodes for this fixture, we find out that the node of type
ClassMethod will be the relevant node here. This node contains the method
definition itself, which includes information about its flags (public, private,
final, etc.), its return type, and - most relevant to us - its parameters:
<?php
declare(strict_types=1);
namespace PhpParser\Node\Stmt;
use PhpParser\Node;
use PhpParser\Node\FunctionLike;
class ClassMethod extends Node\Stmt implements FunctionLike
{
    /**
     * @var int Flags
     */
    public $flags;
    /**
     * @var bool Whether to return by reference
     */
    public $byRef;
    /**
     * @var Node\Identifier Name
     */
    public $name;
    /**

     * @var Node\Param[] Parameters
     */
    public $params;
    /**
     * @var null|Node\Identifier|Node\Name|Node\ComplexType Return type
     */
    public $returnType;
As usual, we start with a rule that just triggers an error for any ClassMethod
node, that is, for any method definition it finds anywhere in the project. I did
make the allowed parameter type configurable though:
utils/PHPStan/src/ActionAllowedParameterRule.php
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PhpParser\Node\Stmt\ClassMethod;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
final class ActionAllowedParameterRule implements Rule
{
    public function __construct(
        private readonly string $allowedParameterType,
    ) {
    }
    public function getNodeType(): string
    {
        return ClassMethod::class;
    }
    /**
     * @param ClassMethod $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        return [
            RuleErrorBuilder::message(
                sprintf(
                    'Controller actions can only have parameters of type
"%s"',
                    $this->allowedParameterType,
                )
            )->build(),
        ];
    }
}

We don't want to trigger an error for any class method, but only for action
methods, which could be characterized as "any public method inside a
controller class". Let's start by excluding non-public methods. First we add a
new test case that verifies that the following example doesn't trigger an error:
utils/PHPStan/tests/ActionAllowedParameterRule/Fixtures/skip-not-a-public-
method.php
<?php
declare(strict_types=1);
use Symfony\Component\HttpFoundation\Request;
use Symfony\Component\HttpFoundation\Response;
use Symfony\Contracts\EventDispatcher\EventDispatcherInterface;
class SomeController
{
    private function notaPublicMethod(
        Request $request,
        EventDispatcherInterface $notAllowed,
    ): Response {
    }
}
To make the test pass, we add an early return in case the method is not public.
The ClassMethod node has a convenient method isPublic() for checking that.
final class ActionAllowedParameterRule implements Rule
{
    // ...
    /**
     * @param ClassMethod $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if (! $node->isPublic()) {
            // The method is not a controller action
            return [];
        }
        // ...
    }
}
We still have to implement the other exception to the rule: we should only
trigger an error for public methods of controller classes. That should be easy,
since we already have a way to determine if a class is a controller. In Chapter 1
we introduced the ControllerDetermination interface for this purpose. Let's

reuse it here. This is the fixture that demonstrates the case that should be
skipped by the rule:
utils/PHPStan/tests/ActionAllowedParameterRule/Fixtures/skip-not-a-controller.php
<?php
declare(strict_types=1);
use Symfony\Component\HttpFoundation\Request;
use Symfony\Component\HttpFoundation\Response;
use Symfony\Contracts\EventDispatcher\EventDispatcherInterface;
class SomeOtherTypeOfClass
{
    public function looksLikeAnAction(
        Request $request,
        EventDispatcherInterface $notAllowed,
    ): Response {
    }
}
To make the test pass, we inject an instance of ControllerDetermination and
use it to determine if the class that contains the ClassMethod node is in fact a
controller class:
final class ActionAllowedParameterRule implements Rule
{
    public function __construct(
        private readonly string $allowedParameterType,
        private readonly ControllerDetermination $determination,
    ) {
    }
    // ...
    /**
     * @param ClassMethod $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        if (
            ! $this->determination->isController(
                $scope->getClassReflection()
            )
        ) {
            // We're not inside a controller
            return [];
        }
        // ...
    }
}

There's one other case that we should consider: a controller action that already
matches our expectations, i.e. it only has one parameter, of type Request. Let's
add another fixture and test for it:
<?php
declare(strict_types=1);
use Symfony\Component\HttpFoundation\Request;
use Symfony\Component\HttpFoundation\Response;
class SomeController
{
    public function actionOnlyHasAllowedParameter(
        Request $request,
    ): Response {
    }
}
As usual, we need to have another early return in our rule. The decision should
be based on the parameter types that are used. As we saw in the code of the
ClassMethod node, it has a $parameters property which contains an array of
Param nodes. We should return an error if it's anything else than the allowed
parameter type.
As we saw in Chapter 1, comparing types can be done with the method
isSuperTypeOf(). For this we need two instances of PHPStan's Type interface:
one for the type of the parameter, and one for the type we allow, which is
passed to the rule as the $allowedParameterType constructor argument.
Assuming that the argument always refers to a class, we can turn it into a proper
Type instance by doing new ObjectType($this->allowedParameterType).
The real challenge is to produce a Type object for the type of each parameter.
We want PHPStan to resolve the type for us. It's perfectly capable of doing so,
as long as we pass an expression node (a subclass of Expr). Once we have an
expression, we can get its type by calling getType() on the Scope object. Let's
take a look at the Param node itself and see if we can somehow get an Expr
node from it:
<?php
declare(strict_types=1);
namespace PhpParser\Node;
use PhpParser\NodeAbstract;

class Param extends NodeAbstract
{
    /**
     * @var null|Identifier|Name|ComplexType Type declaration
     */
    public $type;
    /**
     * @var bool Whether parameter is passed by reference
     */
    public $byRef;
    /**
     * @var bool Whether this is a variadic argument
     */
    public $variadic;
    /**
     * @var Expr\Variable|Expr\Error Parameter variable
     */
    public $var;
It turns out, Param has several properties, one of which contains an expression
node: the $var property. In the case of our fixture file, this represents the
variable part of the parameter: $request.
Let's see what happens if we pass that $var property to Scope::getType(), and
echo the resolved type of each parameter:
final class ActionAllowedParameterRule implements Rule
{
    // ...
    /**
     * @param ClassMethod $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        foreach ($node->params as $param) {
            echo "\n"
                . $scope->getType($param->var)->describe(
                    VerbosityLevel::precise()
                )
                . "\n";
        }
        return [];
    }
}

Unfortunately, if we let PHPStan resolve the type of this $var node, it returns
mixed:
PHPUnit 9.5.20 #StandWithUkraine
F
mixed
mixed
...                                                      4 / 4 (100%)
mixed
That's because there is a lot more to determining the type of a parameter than
just looking at nodes. For example, there may be a @param annotation in the
method's doc block that provides a more specific type declaration than the code
itself provides. To benefit from PHPStan's capability to combine type
knowledge from different sources, we should upgrade our rule to use the
InClassMethodNode. This is a virtual node that PHPStan itself creates every
time it enters a class method:
use PHPStan\Node\InClassMethodNode;
final class ActionAllowedParameterRule implements Rule
{
    // ...
    public function getNodeType(): string
    {
        return InClassMethodNode::class;
    }
    /**
     * @param InClassMethodNode $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if (! $node->getOriginalNode()->isPublic()) {
            // The method is not a controller action
            return [];
        }
        // ...
        foreach ($node->getOriginalNode()->params as $param) {
            echo "\n"
                . $scope->getType($param->var)->describe(
                    VerbosityLevel::precise()
                )
                . "\n";
        }
        return [];

    }
}
Note that we can still retrieve the original ClassMethod node by calling
getOriginalNode().
The difference between ClassMethod node and InClassMethodNode is that once
we encounter an InClassMethodNode, PHPStan has modified the Scope object
to include the types of the method parameters. So the resolved parameter types
are now what we expect them to be:
PHPUnit 9.5.20 #StandWithUkraine
F
Symfony\Component\HttpFoundation\Request
Symfony\Component\EventDispatcher\EventDispatcherInterface
...                                                      4 / 4 (100%)
Symfony\Component\HttpFoundation\Request
Finally, we can put the pieces together and correctly implement the rule: if the
allowed parameter type is not a super-type of the actual parameter type, then we
return an error:
final class ActionAllowedParameterRule implements Rule
{
    // ...
    /**
     * @param InClassMethodNode $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        foreach ($node->getOriginalNode()->params as $param) {
            if (
                ! (new ObjectType($this->allowedParameterType))
                    ->isSuperTypeOf($scope->getType($param->var))
                    ->yes()
            ) {
                return [
                    RuleErrorBuilder::message(
                        sprintf(
                            'Controller actions can only have parameters
of type "%s"',
                            $this->allowedParameterType,
                        )
                    )->build(),
                ];
            }

        }
        return [];
    }
}
Note that this rule triggers only on the first parameter that doesn't match the
expected type. Alternatively we could collect errors for each parameter that has
this issue and return multiple errors at once:
final class ActionAllowedParameterRule implements Rule
{
    // ...
    /**
     * @param InClassMethodNode $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        $errors = [];
        foreach ($node->getOriginalNode()->params as $param) {
            if (
                // ...
            ) {
                $errors[] =
                    RuleErrorBuilder::message(
                        // ...
                    )->build();
            }
        }
        return $errors;
    }
}
Enforcing Return Types
The next PHPStan rule we should create is the one that requires controller
actions to return a Response object. There are several approaches we can think
of here. One is that we look at the return statements in each controller action
and verify that Response is a super-type of the value that gets return-ed.
Another approach, a simpler one, would be to check that the declared return
type of the action method is Response. When all controller actions have
Response as their return type, PHP itself will crash if we don't actually return a
Response from it. Even better: PHPStan will also produce an error if we do
that.

Let's call the new rule ActionReturnsResponseRule, and set up the necessary
files and folders. The following fixture shows an example of code that should
produce an error; we return an array of template variables from a controller
action, instead of a Response:
<?php
declare(strict_types=1);
use Symfony\Component\HttpFoundation\Request;
class SomeController
{
    public function someAction(
        Request $request,
    ): array {
    }
}
This rule, just like the previous one, should subscribe to the
InClassMethodNode since it reports errors about the return type of class
methods. I'm skipping the examples where we return early if the class is not a
controller, or the method is not an action, because we already did that for
previous rules.
final class ActionReturnsResponseRule implements Rule
{
    public function __construct(
        private readonly string $requiredReturnType,
        private readonly ControllerDetermination $determination,
    ) {
    }
    public function getNodeType(): string
    {
        return InClassMethodNode::class;
    }
    /**
     * @param InClassMethodNode $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        /*
         * Return early for non-controller classes and
         * non-public methods...
         */
        // ...
        // TODO skip actions that already return `Response`
        return [

            RuleErrorBuilder::message(
                sprintf(
                    'Method %s::%s() should return %s',
                    $scope->getFunction()
                        ->getDeclaringClass()
                        ->getName(),
                    $scope->getFunction()
                        ->getName(),
                    $this->requiredReturnType,
                )
            )->build(),
        ];
    }
}
Going directly to the part of the rule where we have to determine if the return
type is Response, we have several options. We could use the return type as
defined in the PHP code of the method. In that case we should inspect the
$returnType property of the ClassMethod node and check if it refers to the
Response class:
public function someAction(): Response
If we'd pick this option we'd wrongly trigger an error for actions that return a
subclass of Response:
public function someAction(): JsonResponse
We'd also misinterpret actions that use @return annotations instead of explicit
return types, like so:
/**
 * @return Response
 */
public function someAction()
In short: we shouldn't analyze the code itself. Instead, we should let PHPStan
derive the return type of the method. The standard way of doing this is to gain
access to the MethodReflection object for the current method, and then use the
so-called ParametersAcceptorSelector to select a "parameter acceptor". From
this we can get a definitive answer on the return type. It will get us a Type
instance that we can use for the isSuperTypeOf() check:
use PHPStan\Reflection\ParametersAcceptorSelector;
use PHPStan\Type\ObjectType;

final class ActionReturnsResponseRule implements Rule
{
    public function __construct(
        private readonly string $requiredReturnType,
        private readonly ControllerDetermination $determination,
    ) {
    }
    public function getNodeType(): string
    {
        return InClassMethodNode::class;
    }
    /**
     * @param InClassMethodNode $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        $methodReflection = $scope->getFunction();
        if (! $methodReflection instanceof MethodReflection) {
            /*
             * This shouldn't happen, since this rule subscribes
             * to `InClassMethodNode`...
             */
            return [];
        }
        $returnType = ParametersAcceptorSelector::selectSingle(
            $methodReflection->getVariants()
        )->getReturnType();
        if ((new ObjectType($this->requiredReturnType))
            ->isSuperTypeOf($returnType)
            ->yes()) {
            // The action already returns a Response
            return [];
        }
        // ...
    }
}
Why can't we just call getReturnType() on MethodReflection? That's because that method
doesn't exist! The reason for this is that PHP internally - surprisingly - supports multiple
signatures for the same method (see also the PHPStan discussion forum), so PHPStan has to
support them too. ParametersAcceptorSelector first needs to find out which signature is
relevant based on the arguments or the types of arguments provided for a method call, before it
can resolve a return type for it.

One Action Per Controller
Well, okay then, one more rule! Let's ensure that each controller only has one
action, and call the rule OneActionPerControllerRule. We only want to trigger
one error per class that has multiple actions, so we shouldn't subscribe this new
rule to InClassMethodNode. Instead, we want to target the class itself. We could
subscribe to the Class_ node and call its getMethods() function to find the
relevant ClassMethod nodes. But we also need the ClassReflection object to
determine if it's a controller class we're looking at. That's normally available
through $scope->getClassReflection() but since a Class_ node is not
technically inside a class, that method will return null. To solve this problem,
PHPStan offers another virtual node called InClassNode. This node offers
access to the methods that a class contains, and also to its ClassReflection
object. With these ingredients, the rule itself isn't too complicated:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PHPStan\Analyser\Scope;
use PHPStan\Node\InClassNode;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
final class OneActionPerControllerRule implements Rule
{
    public function getNodeType(): string
    {
        return InClassNode::class;
    }
    /**
     * @param InClassNode $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        $actionMethods = $node->getOriginalNode()
            ->getMethods();
        if (count($actionMethods) > 1) {
            return [
                RuleErrorBuilder::message(
                    sprintf(
                        'Controller %s should have only one action',
                        $scope->getClassReflection()
                            ->getName(),
                    )
                )->build(),

            ];
        }
        return [];
    }
}
We need some additional tests that show this rule doesn't trigger an error for:
Classes that aren't controllers
Controller classes that have one public method and also some non-public
methods
Controller classes that have no public methods at all (that wouldn't be
great, but should not trigger an error I guess)
I consider implementing these scenarios a nice exercise for the reader!
Views
Views are some of the most messy parts of web applications. They often work
with a "convenient" programming language specialized in HTML template
rendering. Examples of such templating languages are Twig and Smarty. The
main benefits of using these languages:
You can easily extend from a base template
You can easily include other templates
You don't have to remember to escape the values you print (preventing
security issues "by default")
There are many downsides too. It's yet another language that you have to learn.
There's no type-safety, and no way to enumerate what the available helper
functions are. On top of this, many projects aren't careful about what values
they pass to the template engine (by means of the array of variables we saw in
the previous section). Those values are often not prepared for rendering in any
way. For example, framework documentation proposes to pass entities as
template variables. This means the template could modify the entity while
rendering the HTML. If you're unlucky, somebody calls
EntityManager::flush() and those changes will be saved to the database as
well. On top of that, templates usually have direct access to the service locator,
so a template developer can fetch any (public) service from the service
container. If they want, they can start sending emails from within the template.

Finally, template languages themselves offer many functions and "syntactic
sugar" that may not translate well to the next popular templating language that
we have to migrate to.
At first a project may not suffer from these issues, and developers quickly get
things done. But - as is the premise of this book - the time will come when the
team has to migrate.
I've worked on several projects where there was more than one templating
library in use. This may not at all be a big problem, although inconsistency is
hard to accept for some developers (myself included). However, at some point
one of these libraries will cause issues because it's no longer maintained and the
world around us has moved on (e.g. we run into newer, unsupported PHP
versions, incompatibilities with other dependencies, etc.). Although we've
successfully postponed the migration, at this point we simply have to, and
getting rid of the old templating library will be a lot of work.
There is one thing we can do to improve this situation: just don't add another
templating library to your project, unless you're willing to migrate existing
templates to it immediately. The benefits of the new library have to be really
great in order to justify the high cost of migrating. This should keep us from
installing the new and cool library we'd really like to give a try.
Unless your templating library is outdated and becomes a security risk, it's
likely that you can stick to your current library for quite some time. As we saw
in the previous section, even if you migrate your controllers to a different web
framework, it doesn't mean you have to switch to a different templating library.
You can still inject its renderer service as a constructor dependency into the
controller, and return the rendered template as a traditional HTML response.
When we finally have to migrate though, we'll have to translate all the
templates to the new templating language. So we'll be very happy if the
existing templates don't do any surprising or hard-to-port things. This will keep
our templates "loosely coupled" to the language and the renderer. Some rules of
thumb:
1. The template itself should only use very basic control structures, like if,
else, and foreach.
2. The template should just echo values, and only values that have been
passed to it. It shouldn't fetch additional data, or use any kind of service

inside. What the template needs should be explicitly passed to it.
3. The functions it calls should be very basic and easily portable, and it
should make sense that they are available to a template. Examples are date
or number formatting functions, or functions for translating strings.
Functions that shouldn't be used inside a template are, for example, ones
that can be called on services that are fetched from the service locator. In
other words: don't use the service locator in your template, even if it's
available.
Pass All the Data That the Template Needs
When we follow these rules, it means that the controller has to do a bit more
work. It has to provide additional values to the template renderer. This is a good
thing; knowing exactly what the template needs will make it easier to migrate to
a different templating library. Since we only use very basic functionality, and
don't go all-in on the current library, we can assume that the library we migrate
to can also offer this functionality. This further eases the migration process.
As a small example of the things you can do to decouple from your templating
engine, consider the following controller:
final class MeetupDetailsController
{
    // ...
    /**
     * @Route("/meetup-details/{id}", name="meetup_details")
     */
    public function meetupDetailsAction(Request $request): Response
    {
        // Fetch the requested `Meetup` entity from Doctrine ORM
        // ...
        return new Response(
            $this->twig->render('meetup-details.html.twig', [
                'meetup' => $meetup,
            ])
        );
    }
}
It renders this template:
{% extends 'base.html.twig' %}
{% block body %}

    {# Here we could meetup.setName()... #}
    <h1>{{ meetup.name }}</h1>
    {# We can even call meetup.cancel()! #}
    {% if app.user.userIdentifier is same as meetup.organizerId %}
        <form method="post"
              action="{{ path('cancel_meetup', { id: meetup.id }) }}">
            <input type="hidden" name="id" value="{{ meetup.id }}">
            <button class="btn btn-danger">
                {{ "meetup_details.cancel_button"|trans }}
            </button>
        </form>
    {% endif %}
{% endblock body %}
The template relies on the logged-in user to be available in the template as
app.user. It also has access to all the methods of the Meetup entity, including
the ones that change its state and shouldn't be available in a situation where we
only want to show data.
The solution for getting rid of the global variable app.user is to pass the value
we need, instead of fetching it. In this case, we can pass the user object from the
controller, or we can even pass just its ID:
use Symfony\Component\Security\Core\Security;
final class MeetupDetailsController
{
    public function __construct(
        // ...
        private Security $security,
    ) {
    }
    /**
     * @Route("/meetup-details/{id}", name="meetup_details")
     */
    public function meetupDetailsAction(Request $request): Response
    {
        // Fetch the request `Meetup` entity from Doctrine ORM
        // ...
        return new Response(
            $this->twig->render('meetup-details.html.twig', [
                'meetup' => $meetup,
                'userId' => $this->security->getUser()
                    ->getUserIdentifier(),
            ])
        );

    }
}
Now we can update the template to use userId instead of app.users. Now we
no longer rely on the global variable app.
Don't Pass Objects That Don't Belong in a Template
The most common example of an object that doesn't belong in a template is an
entity. A great alternative for not passing an entity to the template is to design a
replacement object that exposes the necessary data, nothing more, nothing less.
Such an object is often called a view model. The view model for "meetup
details" looks like this:
<?php
declare(strict_types=1);
namespace App\AppBundle\ViewModel;
final class MeetupDetails
{
    public function __construct(
        public readonly int $id,
        public readonly string $organizerId,
        public readonly string $name,
    ) {
    }
}
A MeetupDetails view model object can be retrieved by ID from its own
repository, which populates it with values from the database. The object will be
passed to the template renderer instead of the Meetup entity:
use App\AppBundle\ViewModel\MeetupDetailsRepository;
final class MeetupDetailsController
{
    public function __construct(
        // ...
        private MeetupDetailsRepository $meetupDetailsRepository,
    ) {
    }
    /**
     * @Route("/meetup-details/{id}", name="meetup_details")
     */
    public function meetupDetailsAction(Request $request): Response
    {

        // Fetch a dedicated view model from its repository:
        $meetupDetails = $this->meetupDetailsRepository->getById(
            $request->attributes->getInt('id')
        );
        return new Response(
            $this->twig->render('meetup-details.html.twig', [
                'meetup' => $meetupDetails,
                'userId' => $this->security->getUser()
                    ->getUserIdentifier(),
            ])
        );
    }
}
If we did everything right, the template doesn't have to change. Well, we can
remove the commented warnings we had before, and we could also simplify the
check for the cancel button by adding a method to MeetupDetails that can
answers the question "can this user cancel this meetup?":
final class MeetupDetails
{
    public function __construct(
        public readonly int $id,
        public readonly string $organizerId,
        public readonly string $name,
    ) {
    }
    public function canUserCancelThisMeetup(string $userId): bool
    {
        return $this->organizerId === $userId;
    }
}
The final template version then looks like this:
{% extends 'base.html.twig' %}
{% block body %}
    <h1>{{ meetup.name }}</h1>
    {% if meetup.canUserCancelThisMeetup(userId) %}
        <form method="post"
              action="{{ path('cancel_meetup', { id: meetup.id }) }}">
            <input type="hidden" name="id" value="{{ meetup.id }}">
            <button class="btn btn-danger">{{
"meetup_details.cancel_button"|trans }}</button>
        </form>
    {% endif %}
{% endblock body %}

The result of the decoupling work is that the call to render() passes the name
of the template and all the values needed to render the template. The values are
ready for use inside the template and don't need further processing. No
additional services are needed either, except for a few basic ones that will
always be there: functions for generating a URI, translating a string, and other
localization tools.
Rules for Decoupled Views
We've finished the refactoring steps that lead to a more decoupled use of
templates and a template renderer like Twig. What kind of rules do we need to
keep things decoupled? Some things that come to mind:
1. It shouldn't be possible to pass an entity to the template. Instead,
developers should create a view model for the data they need inside the
template.
2. It shouldn't be possible to use certain global variables inside the template,
like app. Instead, developers should call services in controllers, and pass
any resulting value to the template.
Don't Use Certain Global Variables in a Template
So far all our PHPStan rules dealt with PHP nodes, but for the next rule we
need to dive into Twig nodes. After all, we want to prevent Twig code like {{
app.user }}. We can still use PHPStan and let it collect and display the errors
that we find in Twig templates.
Our new rule, let's call it ForbiddenTwigVarsRule, can look for method calls to
render() on instances of Twig's Environment class. We could extract the
template name from this method call (which is the first argument), load and
parse that template, and look for usages of the global app variable.
This fixture shows a minimal example of code that our rule should trigger an
error for:
utils/PHPStan/tests/ForbiddenTwigVarsRule/Fixtures/twig-template-uses-forbidden-
var.php
<?php
declare(strict_types=1);

use Twig\Environment;
class Foo
{
    private Environment $twig;
    public function foo(): void {
        $this->twig->render(
            'uses-forbidden-var.html.twig',
        );
    }
}
The Twig template that the call to render() refers to can also be found in the
Fixtures directory:
utils/PHPStan/tests/ForbiddenTwigVarsRule/Fixtures/uses-forbidden-var.html.twig
<p>{{ app.user.userIdentifier }}</p>
This is the result of running the test and dumping the node types of the PHP
fixture:
PHPUnit 9.5.20 #StandWithUkraine
F                                                         1 / 1 (100%)
PHPStan\Node\FileNode
PhpParser\Node\Stmt\Declare_
PhpParser\Node\Stmt\DeclareDeclare
PhpParser\Node\Scalar\LNumber
PhpParser\Node\Stmt\Use_
PhpParser\Node\Stmt\UseUse
PhpParser\Node\Stmt\Class_
PHPStan\Node\InClassNode
PhpParser\Node\Stmt\Property
PhpParser\Node\Stmt\PropertyProperty
PHPStan\Node\ClassPropertyNode
PhpParser\Node\Name\FullyQualified
PhpParser\Node\Stmt\ClassMethod
PhpParser\Node\Identifier
PHPStan\Node\InClassMethodNode
PhpParser\Node\Stmt\Expression
PhpParser\Node\Expr\MethodCall
PhpParser\Node\Expr\PropertyFetch
PhpParser\Node\Expr\Variable
PhpParser\Node\Arg
PhpParser\Node\Scalar\String_
PHPStan\Node\ExecutionEndNode
PHPStan\Node\MethodReturnStatementsNode
PHPStan\Node\ClassPropertiesNode
PHPStan\Node\ClassMethodsNode
PHPStan\Node\ClassConstantsNode

Matching the node types with the actual code, it's likely that subscribing to the
MethodCall node will make sense. We already looked at the code for the
MethodCall node in Chapter 1. There we found out that it has a $var and a
$name property. The $var property represents the object on which the method
$name is called.
Based on this knowledge, we can exclude irrelevant method calls (I'm not
showing the relevant test and fixtures here):
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PhpParser\Node\Expr\MethodCall;
use PhpParser\Node\Identifier;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;
use Twig\Environment;
final class ForbiddenTwigVarsRule implements Rule
{
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        $twigEnvironment = new ObjectType(Environment::class);
        if (! $twigEnvironment
            ->isSuperTypeOf($scope->getType($node->var))
            ->yes()) {
            // The object is not a Twig `Environment` instance
            return [];
        }
        if (! $node->name instanceof Identifier
            || $node->name->toString() !== 'render') {
            // The method is called dynamically, or is not `render()`
            return [];
        }
        return [
            RuleErrorBuilder::message(
                'Template uses forbidden variable',
            )->build(),
        ];

    }
}
Next, we have to extract the template name. This will always be the first
argument of render(), and we can only do something with it if it's a literal
string, and not a variable. A closer inspection of the MethodCall node reveals
that we can call getArgs() on it, which returns a list of the actual arguments,
which are Arg nodes themselves:
<?php
declare(strict_types=1);
namespace PhpParser\Node;
use PhpParser\NodeAbstract;
class Arg extends NodeAbstract
{
    /**
     * @var Identifier|null Parameter name (for named parameters)
     */
    public $name;
    /**
     * @var Expr Value to pass
     */
    public $value;
The $value property of each argument contains an expression node (Expr), and
that's useful because we can use the Scope to find out the type that PHPStan
derived for this expression. If it's a ConstantStringType (as opposed to a
variable), we can directly retrieve its value as a string, which will be the name
of the template. We can now even use the template name in the error message:
use PHPStan\Type\Constant\ConstantStringType;
final class ForbiddenTwigVarsRule implements Rule
{
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...

        if (! isset($node->getArgs()[0])) {
            // The method call has no arguments
            return [];
        }
        $firstArgument = $node->getArgs()[0];
        $firstArgumentType = $scope->getType($firstArgument->value);
        if (! $firstArgumentType instanceof ConstantStringType) {
            // The first argument is not a constant string
            return [];
        }
        $templateName = $firstArgumentType->getValue();
        return [
            RuleErrorBuilder::message(
                sprintf(
                    'Template %s uses forbidden variable',
                    $templateName,
                )
            )->build(),
        ];
    }
}
For brevity, I'm omitting the tests and fixtures for the edge cases, e.g. when
there is no first argument, or when it's not a constant string.
The next step is to load the actual template file. In reality this may involve
some more complicated logic, and we should use the fully configured Twig
Environment to resolve the location of the template file. For now, let's take a
shortcut and assume the templates are all in one directory. We'll pass the
template directory as a constructor argument to the rule. Next we set up a
template loader, so we can load and later parse the source code of the template
file:
use Twig\Loader\FilesystemLoader;
final class ForbiddenTwigVarsRule implements Rule
{
    public function __construct(
        private readonly string $templateDir,
    ) {
    }
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...

        $templateName = $firstArgumentType->getValue();
        // Load the template
        $loader = new FilesystemLoader($this->templateDir);
        $source = $loader->getSourceContext($templateName);
        // TODO analyze the template
        // ...
    }
}
Just like PHP-Parser parses a PHP script and gives us a set of nodes, the Twig
Environment can give us the parsed nodes for a Twig template. We want to
analyze all the nodes and trigger an error in case the node "does" something
that we don't want to allow, like using a global variable. Analyzing all the
nodes can be done with Twig's built-in node traverser, which accepts an array
of so-called node visitors. A node visitor will be notified about every node that
the traverser encounters. This is very similar to how a PHPStan rule can be
notified about every PHP node if you subscribe to the generic Node class.
Let's start by adding a node visitor that simply echo-s every node type:
use Twig\Node\Node as TwigNode;
use Twig\NodeTraverser;
use Twig\NodeVisitor\NodeVisitorInterface;
final class ForbiddenTwigVarsRule implements Rule
{
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        $source = $loader->getSourceContext($templateName);
        // Parse the template
        $twig = new Environment($loader);
        $nodeTree = $twig->parse($twig->tokenize($source));
        // Traverse the node tree and `echo` all node types
        $nodeTraverser = new NodeTraverser($twig, [
            new class() implements NodeVisitorInterface {
                public function enterNode(
                    TwigNode $node,
                    Environment $env
                ): TwigNode {
                    echo "\n" . $node::class;

                    return $node;
                }
                public function leaveNode(
                    TwigNode $node,
                    Environment $env
                ): ?TwigNode {
                    // Do nothing
                    return $node;
                }
                public function getPriority(): int
                {
                    return 0;
                }
            },
        ]);
        $nodeTraverser->traverse($nodeTree);
        // ...
    }
}
The result is a list of Twig node types (abbreviated) for the parsed template file:
PHPUnit 9.5.20 #StandWithUkraine
.
Twig\Node\ModuleNode
Twig\Node\BodyNode
Twig\Node\Node
Twig\Node\PrintNode
Twig\Node\Expression\FilterExpression
Twig\Node\Expression\GetAttrExpression
Twig\Node\Expression\GetAttrExpression
Twig\Node\Expression\NameExpression
Twig\Node\Expression\ConstantExpression
Twig\Node\Expression\ArrayExpression
Twig\Node\Expression\ConstantExpression
Twig\Node\Expression\ArrayExpression
Twig\Node\Expression\ConstantExpression
To be honest, this doesn't immediately make sense to me. Fiddling a bit with
var_dump-ing various nodes it turns out that we should look for
NameExpression nodes because they have an attribute called 'name', that
contains the name of the variable used (e.g. 'app').
The next thing to do is collect all the variable names and look for ones that
shouldn't be used. We could continue with an anonymous class, but I think it's
better to create a proper class for the visitor, e.g.

CollectVariableNamesVisitor. The visitor keeps track of the nodes that
represent variable names, and later exposes them through a getter:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use Twig\Environment;
use Twig\Node\Expression\NameExpression;
use Twig\Node\Node;
use Twig\NodeVisitor\NodeVisitorInterface;
final class CollectVariableNamesVisitor implements NodeVisitorInterface
{
    /**
     * @var array<NameExpression>
     */
    private array $variableNames = [];
    public function enterNode(Node $node, Environment $env): Node
    {
        if ($node instanceof NameExpression) {
            $this->variableNames[] = $node;
        }
        return $node;
    }
    public function variableNames(): array
    {
        return $this->variableNames;
    }
    // ...
}
We set up this visitor and traverse the nodes again:
final class ForbiddenTwigVarsRule implements Rule
{
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        // Traverse the node tree and collect all variable names
        $visitor = new CollectVariableNamesVisitor();
        $nodeTraverser = new NodeTraverser($twig, [$visitor]);
        $nodeTraverser->traverse($nodeTree);
        var_dump($visitor->variableNames());

        // TODO produce an error if the variable is forbidden
        // ...
    }
}
The result of running the tests (abbreviated):
PHPUnit 9.5.20 #StandWithUkraine
.array(1) {
  [0]=>
  object(Twig\Node\Expression\NameExpression)#11011 (7) {
    ["nodes":protected]=>
    array(0) {
    }
    ["attributes":protected]=>
    array(4) {
      ["name"]=>
      string(3) "app"
      ["is_defined_test"]=>
      bool(false)
      ["ignore_strict_check"]=>
      bool(false)
      ["always_defined"]=>
      bool(false)
    }
Great, we have an array with the variable name nodes. Now we can complete
the rule by injecting an array of forbidden variable names as strings. Then we
can loop through the variable name nodes and check if their name matches one
of the forbidden names:
final class ForbiddenTwigVarsRule implements Rule
{
    /**
     * @param array<string> $forbiddenVariables
     */
    public function __construct(
        private readonly string $templateDir,
        private readonly array $forbiddenVariables,
    ) {
    }
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...

        $errors = [];
        foreach ($visitor->variableNames() as $nameNode) {
            $variableName = $nameNode->getAttribute('name');
            if (in_array(
                $variableName,
                $this->forbiddenVariables,
                true,
            )) {
                $errors[] = RuleErrorBuilder::message(
                    sprintf(
                        'Template %s uses forbidden variable %s',
                        $templateName,
                        $variableName
                    )
                )->build();
            }
        }
        return $errors;
    }
}
Eventually we would benefit from a more elaborate framework for static
analysis of Twig files. Building one goes beyond the scope of the book, but I
did it as a side-projectanyway.
One final thing we can improve here is to connect the reported error to the
.twig file instead of the .php file where the render() call happens. We can
accomplish this by passing a custom file path and line number on the
RuleErrorBuilder. The file and line of the template itself can be retrieved from
any Twig Node:
final class ForbiddenTwigVarsRule implements Rule
{
    /**
     * @param array<string> $forbiddenVariables
     */
    public function __construct(
        private readonly string $templateDir,
        private readonly array $forbiddenVariables,
    ) {
    }
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        $errors = [];

        foreach ($visitor->variableNames() as $nameNode) {
            $variableName = $nameNode->getAttribute('name');
            if (in_array(
                $variableName,
                $this->forbiddenVariables,
                true,
            )) {
                $errors[] = RuleErrorBuilder::message(sprintf(
                    'Template uses forbidden var %s',
                    $variableName,
                ))
                    ->file(
                        $nameNode->getSourceContext()
                            ->getPath()
                        ?: $nameNode->getSourceContext()
                            ->getName()
                    )
                    ->line($nameNode->getTemplateLine())
                    ->build();
            }
        }
        return $errors;
    }
}
The output:
------ ----------------------------------------
 Line   templates/uses-forbidden-var.html.twig
------ ----------------------------------------
 1      Template uses forbidden var app
------ ----------------------------------------
[ERROR] Found 1 error
Don't Use Certain Functions in a Template
Now that we know how to analyze Twig templates and look for specific nodes,
it shouldn't be too big a step to declare certain functions as "forbidden". As we
discussed earlier, doing so will keep the templates simple, and forces the
developer to move business logic to PHP code rather than hiding it in templates.
I leave it to you to decide which functions are okay, but one function that I'd
like to prevent from being used is dump(). It's fine when debugging, but when
we commit the code, all dump() calls should be gone.
This rule will be similar to the previous rule, so we won't discuss the
preliminary steps again. We start by dumping node types for the following Twig

file to find out which node we should be interested in:
{{ dump(something) }}
A node type called FunctionExpression turns out to be the most logical option.
It has a 'name' attribute, the value of which is the name of the function that's
being called, as a string (e.g. 'dump'). The ForbiddenTwigFunctionsRule can
now compare these to a constructor-injected list of forbidden functions:
final class ForbiddenTwigFunctionsRule implements Rule
{
    /**
     * @param array<string> $forbiddenFunctions
     */
    public function __construct(
        private readonly string $templateDir,
        private readonly array $forbiddenFunctions,
    ) {
    }
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        // Parse the template
        $twig = new Environment($loader, [
            'debug' => true,
        ]);
        $twig->addExtension(new DebugExtension());
        $nodeTree = $twig->parse($twig->tokenize($source));
        // Traverse the node tree and collect all variable names
        $visitor = new CollectFunctionCalls();
        $nodeTraverser = new NodeTraverser($twig, [$visitor]);
        $nodeTraverser->traverse($nodeTree);
        $errors = [];
        foreach ($visitor->functionCalls() as $functionCall) {
            $functionName = $functionCall->getAttribute('name');
            if (in_array(
                $functionName,
                $this->forbiddenFunctions,
                true,
            )) {
                $errors[] = RuleErrorBuilder::message(sprintf(
                    'Template uses forbidden function %s',
                    $functionName,

                ))
                    ->file(
                        $functionCall->getSourceContext()
                            ->getPath()
                        ?: $functionCall->getSourceContext()
                            ->getName()
                    )
                    ->line($functionCall->getTemplateLine())
                    ->build();
            }
        }
        return $errors;
    }
}
------ ---------------------------------------------
 Line   templates/uses-forbidden-function.html.twig
------ ---------------------------------------------
 2      Template uses forbidden function dump
------ ---------------------------------------------
[ERROR] Found 1 error
Don't Pass Entities to a Template
As discussed earlier, you may want to decouple your template from your
domain model by not allowing entities to be passed to templates. Instead, a
view model object should be passed, which would be an immutable object that
provides the data in a format that's most useful for the template itself. This,
again, is something we can guard with PHPStan. Let's call the rule
NoEntityInTemplateRule. It should trigger an error in case the array of
template variables contains an entity:
<?php
declare(strict_types=1);
use Twig\Environment;
use Utils\PHPStan\Tests\NoEntityInTemplateRule\Fixtures\AnEntity;
class Foo
{
    private Environment $twig;
    public function foo(): void {
        $this->twig->render(
            'template.html.twig',
            [
                'foo' => new AnEntity(),

            ]
        );
    }
}
The questions we have to answer are:
1. How can a rule recognize that an object is entity? This question can have
different answers depending on your project setup and the framework or
the ORM that you use. I'll assume Doctrine ORM to be used with its
annotation-style configuration. An entity can be recognized as such
because it has an @ORM\Entity annotation, which refers to the class
Doctrine\ORM\Mapping\Entity.
2. How can we determine what types of values are inside the array of
template variables passed to render()? Of course, PHPStan can help us
with this!
As with previous rules we can zoom in on calls to render() by subscribing to
MethodCall nodes and excluding objects that are not Environment, methods
that are not render(), or calls that pass no template variables (i.e. have no
second argument):
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PhpParser\Node\Expr\MethodCall;
use PhpParser\Node\Identifier;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;
use PHPStan\Type\VerbosityLevel;
use Twig\Environment;
final class NoEntityInTemplateRule implements Rule
{
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {

        $twigEnvironment = new ObjectType(Environment::class);
        if (! $twigEnvironment
            ->isSuperTypeOf($scope->getType($node->var))
            ->yes()) {
            // The object is not a Twig `Environment` instance
            return [];
        }
        if (! $node->name instanceof Identifier
            || $node->name->toString() !== 'render') {
            // The method is called dynamically, or is not `render()`
            return [];
        }
        if (! isset($node->getArgs()[1])) {
            // The method call has no second argument
            return [];
        }
        $templateVars = $node->getArgs()[1]
            ->value;
        echo "\n" . $scope->getType($templateVars)::class;
        echo "\n" . $scope->getType($templateVars)->describe(
            VerbosityLevel::precise()
        );
        // TODO check if any of the template variables is an entity
        return [
            RuleErrorBuilder::message(
                'An entity should not be passed to a template',
            )->build(),
        ];
    }
}
The result of dumping the type of the array of template variables:
PHPUnit 9.5.20 #StandWithUkraine
.
PHPStan\Type\Constant\ConstantArrayType
array{foo:
Utils\PHPStan\Tests\NoEntityInTemplateRule\Fixtures\AnEntity}...
                                             4 / 4 (100%)
This gives us some useful information: PHPStan has recognized the array to be
a "constant" array. It's not dynamically built up, but it's provided as is. For each
of the keys and values in the constant array it can also resolve the types.
Looking at the source code of ConstantArrayType, it looks like we can extract

an array of the Types of the values by calling getValueTypes(). Dumping those
types gives us the type of each value that's in the array:
use PHPStan\Type\Constant\ConstantArrayType;
final class NoEntityInTemplateRule implements Rule
{
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        $templateVars = $node->getArgs()[1]
            ->value;
        $arrayType = $scope->getType($templateVars);
        if (! $arrayType instanceof ConstantArrayType) {
            return [];
        }
        $valueTypes = $arrayType->getValueTypes();
        foreach ($valueTypes as $valueType) {
            echo "\n" . $valueType::class;
            echo "\n" . $valueType->describe(
                VerbosityLevel::precise()
            );
            // TODO check if any of the template variables is an entity
        }
        // ...
    }
}
The result:
PHPUnit 9.5.20 #StandWithUkraine
.
PHPStan\Type\ObjectType
Utils\PHPStan\Tests\NoEntityInTemplateRule\Fixtures\AnEntity...
                                            4 / 4 (100%)
Time: 00:00.782, Memory: 64.50 MB
Once we have an ObjectType we can also get a ClassReflection for it. We
can feed that into a method that can help us determine if the object is in fact an

entity. Similar to how we did this for controller classes, we could also introduce
an interface for "entity determination". An overly simplified implementation
would be:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PHPStan\Reflection\ClassReflection;
final class DoctrineEntityWithAnnotation implements EntityDetermination
{
    public function isEntity(ClassReflection $class): bool
    {
        return str_contains(
            $class->getResolvedPhpDoc()
                ->getPhpDocString(),
            '@ORM\Entity',
        );
    }
}
Using it inside the rule, we can now trigger an error for each entity that is
passed to a template:
final class NoEntityInTemplateRule implements Rule
{
    public function __construct(
        private readonly EntityDetermination $determine,
    ) {
    }
    // ...
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        // ...
        $valueTypes = $arrayType->getValueTypes();
        $errors = [];
        foreach ($valueTypes as $valueType) {
            if (! $valueType instanceof ObjectType) {
                continue;
            }
            if (
                $this->determine->isEntity(
                    $valueType->getClassReflection()

                )
            ) {
                $errors[] = RuleErrorBuilder::message(
                    sprintf(
                        'Entity of type %s should not ' .
                        'be passed to a template',
                        $valueType->getClassName(),
                    ),
                )->build();
            }
        }
        return $errors;
    }
}
Conclusion
We have covered many aspects of decoupling controllers from the web
framework, and also decoupling from template rendering libraries. Keep things
simple and explicit, and don't rely on global dependencies or variables. This is
very simple advice, but many projects don't follow these simple rules. Next up
is the topic of CLI frameworks that need similar, but in some ways different
approaches to decoupling.
OceanofPDF.com

3 CLI Frameworks
This Chapter Covers:
Extracting command-line input and jumping to a service
Delegating output printing to event subscribers
Preventing CLI framework coupling with PHPStan rules
Introduction
Web frameworks like Symfony and Laravel ship with a sub-framework that
helps the developer add command-line-based tasks to their projects. Usually
these tasks are implemented as "commands", which are classes that extend
from some kind of abstract Command class. Out of the box a project already
has some commands available, e.g. for migrating the database schema, or
for setting up a new controller. When developers start adding their own
commands to the project, those commands will be in one way or another
coupled to the command-line-interface (CLI) framework of their project.
Decoupling from a CLI framework isn't always necessary, but it will
certainly give you an advantage when the time comes to upgrade or switch.
In that case, there will be several areas where work is needed:
1. In the code that defines the available command-line options and
arguments supported by the command
2. In the code that reads the user-provided options and arguments based
on these definitions
3. In the code that deals with the output streams (stdout and stderr)
Each framework will offer its own API for that, so these are the areas where
we'll have to rewrite existing code. To make this easier for us, extracting
input and producing output is something that should only happen in a few
places in our codebase. If this is the case, there will be a large chunk of the

code that doesn't have to be adapted when switching to a different CLI
framework.
Input
We need to distinguish two phases during command execution. The first
phase is about collecting all the input. We use the API provided by the
framework to do this. For instance, when creating Symfony commands,
there's an InputInterface object that we can ask which values the user
provided in their terminal. Since this object is framework-specific, we'd
have to rewrite code that uses it anyway. But code that doesn't use
InputInterface and instead only relies on the values extracted from it, will
automatically be decoupled from the framework. So a sensible rule for
decoupling the command itself regarding the input processing phase, is to
make an explicit cut in the command class: beyond a certain point we
shouldn't extract input values anymore.
Let's take a look at a realistic example of a console command: one that
imports data from a CSV file. In this case we import a list of email
addresses and register them as attendees for a meetup. Input for this
command, which has to be provided as command-line arguments, are the
path of the CSV file and the ID of the Meetup to which you want to add the
attendees. Finally, there's a --dry-run option you can add to simulate an
import without making the changes permanent:
<?php
declare(strict_types=1);
namespace App\Command;
use App\Entity\MeetupRepository;
use Symfony\Component\Console\Command\Command;
use Symfony\Component\Console\Input\InputArgument;
use Symfony\Component\Console\Input\InputInterface;
use Symfony\Component\Console\Input\InputOption;
use Symfony\Component\Console\Output\OutputInterface;
final class ImportAttendeesCommand extends Command
{
    public function __construct(
        private readonly MeetupRepository $meetupRepository
    ) {

        parent::__construct();
    }
    protected function configure(): void
    {
        $this->setName('meetup:import-attendees')
            ->addArgument('meetupId', InputArgument::REQUIRED)
            ->addArgument('csv', InputArgument::REQUIRED)
            ->addOption('dry-run', 'd', InputOption::VALUE_NONE);
    }
    protected function execute(
        InputInterface $input,
        OutputInterface $output
    ): int {
        // Fetch the relevant `Meetup` entity
        $meetup = $this->meetupRepository->getById(
            (int) $input->getArgument('meetupId')
        );
        // Read the CSV file
        $csvFile = fopen($input->getArgument('csv'), 'r');
        assert(is_resource($csvFile));
        $keys = fgetcsv($csvFile);
        assert(is_array($keys));
        // Add the attendees to the `Meetup` entity
        while ($values = fgetcsv($csvFile)) {
            $attendee = array_combine($keys, $values);
            $emailAddress = $attendee['emailAddress'];
            $meetup->addAttendee($emailAddress);
            $output->writeln(
                sprintf(
                    '<comment>Added attendee %s</comment>',
                    $emailAddress
                )
            );
        }
        // If the dry-run option is provided, skip the "save" step
        if (! $input->getOption('dry-run')) {
            $this->meetupRepository->save($meetup);
            $output->writeln(
                sprintf(
                    '<success>Saved meetup with ID %d</success>',
                    $input->getArgument('meetupId')
                )
            );
        }
        return 0;
    }
}

Collect Input First
The first thing we should do is move all the method calls on
InputInterface $input to the top of the execute() method. We store the
values that were retrieved from it in local variables:
final class ImportAttendeesCommand extends Command
{
    // ...
    protected function execute(
        InputInterface $input,
        OutputInterface $output
    ): int {
        $meetupId = (int) $input->getArgument('meetupId');
        $dryRun = $input->getOption('dry-run');
        $csv = $input->getArgument('csv');
        // Below this point, we don't use `$input` anymore
        $meetup = $this->meetupRepository->getById($meetupId);
        $csvFile = fopen($csv, 'r');
        assert(is_resource($csvFile));
        // ...
        return 0;
    }
}
Jump to a Service
If we'd stop here, another developer may look at the code and decide to
"simplify" it by inlining all those variables again, replacing them with
method calls to $input. So to make our intentions clear, we should extract
the code that is independent of the CLI framework to a separate class that
doesn't even have access to $input. We collect what we need from it, then
quickly jump away to another function where we no longer use any part of
the framework:
final class ImportAttendeesCommand extends Command
{
    public function __construct(
        private readonly ImportAttendees $importAttendees
    ) {
        parent::__construct();

    }
    // ...
    protected function execute(
        InputInterface $input,
        OutputInterface $output
    ): int {
        $meetupId = (int) $input->getArgument('meetupId');
        $dryRun = $input->getOption('dry-run');
        $csv = $input->getArgument('csv');
        // Jump to a service
        $this->importAttendees->import(
            $meetupId,
            $csv,
            $dryRun,
            $output,
        );
        return 0;
    }
}
We still have to pass the $output service to the extracted service as well,
but we'll improve that part in the next section. Note that since we jump to a
service anyway we could now safely inline the calls to InputInterface if
we like:
final class ImportAttendeesCommand extends Command
{
    // ...
    protected function execute(
        InputInterface $input,
        OutputInterface $output
    ): int {
        $this->importAttendees->import(
            (int) $input->getArgument('meetupId'),
            $input->getArgument('csv'),
            $input->getOption('dry-run'),
            $output,
        );
        return 0;
    }
}

Output
The OutputInterface object is used to print information to stdout and/or
stderr. It's similar to using echo directly, but OutputInterface allows us
to use special formatting and styling options. It also allows the framework
to automatically hide or show output based on the verbosity preference as
provided by the user (e.g. using the --quiet or --verbose options).
The OutputInterface object is a service, but it's also a strange one. It's
instantiated and configured outside the service container, and we can only
access it as one of the arguments provided to the command's execute()
method. Since our ImportAttendees service is going to show the output, it
means we have to pass the output object as a method argument to it. This
leaves our service coupled to the CLI framework. Even if we could inject
OutputInterface as a constructor argument in this service, the service
would still be coupled to the framework because it couldn't be used without
it.
To decouple from OutputInterface means we have to redesign the import
command. Is it essential for the importer to show output? For the developer
it is. They will use the output for debugging purposes, and to get some clue
about the progress. We like CLI applications that regularly print some
progress information on screen, so we know it's still running, or at what
point during the import process it failed. There are alternatives, but visual
output is still desirable.
Another useful question to stimulate the redesign process with regard to
decoupling: can we think of the importer to be used in a different context
than as a console command? Yes, of course. We can imagine a user
uploading a CSV file in a web interface. In that context it wouldn't make
sense to require the importer to have a method argument of type
OutputInterface. We don't want CLI output on a web page, we want to
show progress in some other way, or only show a summary of the import
process. Besides, in a web controller we don't even have an
OutputInterface object to pass to the import() method. So in this sense,
showing output isn't an essential part of the importer. It's just one possible
way of reporting.

In conclusion, we want to be able to show output during the import process,
but the importer service itself shouldn't be doing it. There are several ways
to make this work, and it will make the importer service more portable, in
the sense that you could pick it up and use it in a different context.
Using an Observer for Showing Output
The first option is to borrow from the Observer design pattern and define an
interface that the service can call at various points in the process. Instead of
applying the original, generic, and somewhat overly complicated pattern
from "Design Patterns: Elements of Reusable Object-Oriented Software" I
prefer making a simplified and domain-specific observer.
The first step is to define the important moments that we want to be notified
about during the import process as methods on the new observer interface:
<?php
declare(strict_types=1);
namespace App\Service;
interface ImportProgress
{
    public function attendeeWasAdded(string $emailAddress): void;
    public function meetupWasSaved(int $meetupId): void;
}
We then update the importer service to call the methods on this interface
instead of using the OutputInterface directly. The observer is injected as a
constructor argument. Since the importer no longer needs an
OutputInterface instance, the method argument for it can now be
removed:
<?php
declare(strict_types=1);
namespace App\Service;
use App\Entity\MeetupRepository;
final class ImportAttendees

{
    public function __construct(
        private readonly MeetupRepository $meetupRepository,
        private readonly ImportProgress $importProgress,
    ) {
    }
    public function import(
        int $meetupId,
        string $csv,
        bool $dryRun,
    ): void {
        // ...
        while ($values = fgetcsv($csvFile)) {
            // ...
            $meetup->addAttendee($emailAddress);
            $this->importProgress->attendeeWasAdded($emailAddress);
        }
        if (! $dryRun) {
            $this->meetupRepository->save($meetup);
            $this->importProgress->meetupWasSaved($meetupId);
        }
    }
}
To make it all work again we have to provide an implementation of the
ImportProgress interface. In each of its methods it will print a message
using the OutputInterface object:
<?php
declare(strict_types=1);
namespace App\Command;
use App\Service\ImportProgress;
use Symfony\Component\Console\Output\OutputInterface;
final class ImportProgressUsingCliOutput implements ImportProgress
{
    private OutputInterface $output;
    public function attendeeWasAdded(string $emailAddress): void
    {
        $this->output->writeln(
            sprintf(
                '<comment>Added attendee %s</comment>',
                $emailAddress
            )

        );
    }
    public function meetupWasSaved(int $meetupId): void
    {
        $this->output->writeln(
            sprintf(
                '<success>Saved meetup with ID %d</success>',
                $meetupId
            )
        );
    }
}
How do we get the OutputInterface object inside this service? It's only
available as a method argument of the command class itself. A simple trick
is to add a setOutput() method on the observer class and call this method
in the console command, so we can "inject" the right output object from the
outside. To save ourselves from having to deal with the $output property
being potentially undefined, or null, we could create a NullOutput
instance in the constructor:
<?php
declare(strict_types=1);
namespace App\Command;
use App\Service\ImportProgress;
use Symfony\Component\Console\Output\NullOutput;
use Symfony\Component\Console\Output\OutputInterface;
final class ImportProgressUsingCliOutput implements ImportProgress
{
    private OutputInterface $output;
    public function __construct()
    {
        $this->output = new NullOutput();
    }
    public function setOutput(OutputInterface $output): void
    {
        $this->output = $output;
    }
    public function attendeeWasAdded(string $emailAddress): void
    {
        $this->output->writeln(
            // ...
        );
    }

    // ...
}
Finally, we should not forget to call this setOutput() method in the console
command because that's where we have access to the real OutputInterface
object:
final class ImportAttendeesCommand extends Command
{
    public function __construct(
        private readonly ImportAttendees $importAttendees,
        private readonly ImportProgressUsingCliOutput $importProgress,
    ) {
        parent::__construct();
    }
    // ...
    protected function execute(
        InputInterface $input,
        OutputInterface $output
    ): int {
        // ...
        $this->importProgress->setOutput($output);
        $this->importAttendees->import($meetupId, $csv, $dryRun);
        return 0;
    }
}
This very effectively decoupled the import service from the CLI
framework. When we need to switch to a different CLI framework, the
importer itself remains unchanged; we only have to rewrite the code in
ImportProgressUsingCliOutput to use a different type of output object, or
even to just echo strings directly, if that's what the new framework wants.
The service itself is portable: it can be reused in a different context, e.g. a
web application.
A possible downside of this approach is that by introducing an observer,
which is an abstraction, we also introduced some indirectness. In the first
version of the ImportAttendees service we could clearly see that it
produces output. In the latest version we don't see this anymore. Instead,
we see method calls to the ImportProgress observer, which is an interface.

We don't know which implementation of this interface will be injected at
runtime, so we don't know everything that will happen when this code is
executed. This is a typical example of a trade-off: we trade the benefit of
decoupled code at the cost of indirectness.
Generalizing the Solution with Event Dispatching
There is a second option: we can also generalize the domain-specific
observer interface and use an event dispatcher instead. The method names
of the observer already gave us a clue about this, since they use "event
grammar" like "attendee was added". When we switch to using an event
dispatcher, each observer method has to be promoted to an event class. E.g.
attendeeWasAdded() is going to be represented by the class
AttendeeWasAdded:
<?php
declare(strict_types=1);
namespace App\Service;
use Symfony\Contracts\EventDispatcher\Event;
final class AttendeeWasAdded extends Event
{
    public function __construct(
        private readonly string $emailAddress
    ) {
    }
    public function emailAddress(): string
    {
        return $this->emailAddress;
    }
}
In this example we're using the Symfony event dispatcher, which means
each event class has to extend from the base Event class provided by the
framework. Instead of calling attendeeWasAdded(), we should now call
dispatch() on the event dispatcher service, providing an instance of the
relevant event class:
<?php

declare(strict_types=1);
namespace App\Service;
use App\Entity\MeetupRepository;
use Symfony\Component\EventDispatcher\EventDispatcher;
final class ImportAttendees
{
    public function __construct(
        private readonly MeetupRepository $meetupRepository,
        private readonly EventDispatcher $eventDispatcher,
    ) {
    }
    public function import(
        int $meetupId,
        string $csv,
        bool $dryRun,
    ): void {
        // ...
        while ($values = fgetcsv($csvFile)) {
            // ...
            $meetup->addAttendee($emailAddress);
            $this->eventDispatcher->dispatch(
                new AttendeeWasAdded($emailAddress)
            );
        }
        if (! $dryRun) {
            $this->meetupRepository->save($meetup);
            $this->eventDispatcher->dispatch(
                new MeetupWasSaved($meetupId)
            );
        }
    }
}
The ImportProgressUsingCliOutput class we used before needs to be
turned into an event subscriber that registers itself to import-related events
and shows the correct output when these events have occurred:
<?php
declare(strict_types=1);
namespace App\Command;
use App\Service\AttendeeWasAdded;
use App\Service\MeetupWasSaved;

use Symfony\Component\Console\Output\NullOutput;
use Symfony\Component\Console\Output\OutputInterface;
use Symfony\Component\EventDispatcher\EventSubscriberInterface;
final class CliOutputSubscriber implements EventSubscriberInterface
{
    private OutputInterface $output;
    public function __construct()
    {
        $this->output = new NullOutput();
    }
    public function setOutput(OutputInterface $output): void
    {
        $this->output = $output;
    }
    public static function getSubscribedEvents(): array
    {
        return [
            AttendeeWasAdded::class => 'whenAttendeeWasAdded',
            MeetupWasSaved::class => 'whenMeetupWasSaved',
        ];
    }
    public function whenAttendeeWasAdded(AttendeeWasAdded $event): void
    {
        $this->output->writeln(
            sprintf(
                '<comment>Added attendee %s</comment>',
                $event->emailAddress()
            )
        );
    }
    public function whenMeetupWasSaved(MeetupWasSaved $event): void
    {
        $this->output->writeln(
            sprintf(
                '<success>Saved meetup with ID %d</success>',
                $event->meetupId()
            )
        );
    }
}
Finally, we still have to pass the OutputInterface object from the
command class to the event subscriber:
final class ImportAttendeesCommand extends Command
{
    public function __construct(
        private readonly ImportAttendees $importAttendees,

        private readonly CliOutputSubscriber $eventSubscriber,
    ) {
        parent::__construct();
    }
    // ...
    protected function execute(
        InputInterface $input,
        OutputInterface $output
    ): int {
        // ...
        $this->eventSubscriber->setOutput($output);
        $this->importAttendees->import($meetupId, $csv, $dryRun);
        return 0;
    }
}
An event dispatcher is more generic than a domain-specific observer. The
event dispatcher itself isn't aware of the import process itself, but will
accept any event object. Arguably this introduces even more indirection to
the code than the first solution which used a domain-specific observer. With
the observer we could look for classes implementing the interface to find
out what happens in each of its methods. When using an event dispatcher
we could find all event subscribers by looking for methods that accept the
dispatched event class as an argument (in PhpStorm you can use Find
usages...).
On the other hand, an advantage of using an event dispatcher is that it's a
service that the framework already has, as opposed to the observer for
which we had to provide our own interface and a standard implementation.
However, it feels like we're running in circles. We started relying on the
framework's event dispatcher while we're in the process of decoupling
from the CLI framework. So we have to answer the question: is this type of
coupling okay?
I don't think it's that bad. Switching to a different event dispatcher won't
make a big difference. The new dispatcher will also have some kind of
dispatch() method which accepts some form of event data. The dispatcher
offers ways for subscribers to be registered, either by event name or event
class. So not much will change. One thing we could do is let the calling side

depend on an event dispatcher abstraction like PSR-14. However, it's not a
given that any new event dispatcher will implement this abstraction too.
Turn the Command Class Itself Into an Event Subscriber
Personally I like the event dispatcher approach. It allows an interesting
refactoring to be done. We can merge the event subscriber code into the
command class, making the command itself the event subscriber:
final class ImportAttendeesCommand extends Command implements
EventSubscriberInterface
{
    private OutputInterface $output;
    public function __construct(
        private readonly ImportAttendees $importAttendees,
        private readonly EventDispatcherInterface $eventDispatcher,
    ) {
        $this->output = new NullOutput();
        parent::__construct();
    }
    public static function getSubscribedEvents(): array
    {
        // ...
    }
    public function whenAttendeeWasAdded(AttendeeWasAdded $event): void
    {
        // ...
    }
    public function whenMeetupWasSaved(MeetupWasSaved $event): void
    {
        // ...
    }
    // ...
    protected function execute(
        InputInterface $input,
        OutputInterface $output
    ): int {
        // ...
        $this->output = $output;
        $this->eventDispatcher->addSubscriber($this);
        $this->importAttendees->import($meetupId, $csv, $dryRun);
        return 0;

    }
}
A potential objection is that we're cluttering the command class with those
additional methods, but this approach has one benefit that I like a lot: what
changes together, stays together. If we'd switch to a different CLI
framework, we only have to update the command class. There's no other
type of class in the project that needs OutputInterface or
InputInterface.
Controllers Should Call Framework-agnostic
Services
In the previous sections we've done some work to separate the essential
logic of a console command from the part that collects the input values and
another part which produces the output. This makes the logic portable: you
can invoke it in different parts of the application, based on different sources
for input. For instance, we can import meetup attendees from the command
line, just as easily as we could do it from a web interface, from an API
endpoint, based on a message from a job queue, or in a cronjob. Because
we've extracted the code that produces the output, we can implement that
part in different ways too. We could indeed show output in the terminal, or
we could write it to a log file, show an HTML report on screen, or return a
JSON response to the API client.
This is in part what Hexagonal Architecture proposes, and a similar idea is
conveyed in the Application service pattern. For a more detailed discussion,
see my other book, Advanced Web Application Architecture.
We should realize that web controllers and console command aren't
different types of classes in the end. They both act as controllers, that are
invoked by the framework, that accept a certain type of input (HTTP
request, CLI arguments) and produce a certain type of output (HTTP
response, terminal output).

Rules for Decoupling
Use InputInterface and OutputInterface Only in
Command Classes
The most important rule that comes to mind, and one that we could easily
implement with PHPStan, is that CLI-framework-specific objects like
InputInterface and OutputInterface should only be used in command
classes. A command class will be considered any class that extends the
framework's Command base class.
Let's call the rule InputOutputOnlyInCommandRule, and assume the rule
and the test have been set up. We want to trigger an error for the following
situation, where a class that is not a command uses InputInterface to get
input, or OutputInterface to produce output:
utils/PHPStan/tests/InputOutputOnlyInCommandRule/Fixtures/NotACommand.php
<?php
declare(strict_types=1);
namespace Utils\PHPStan\Tests\InputOutputOnlyInCommandRule\Fixtures;
use Symfony\Component\Console\Input\InputInterface;
use Symfony\Component\Console\Output\OutputInterface;
class NotACommand
{
    public function foo(InputInterface $input, OutputInterface $output)
    {
        $input->getArgument('arg');
        $output->writeln('line');
    }
}
We could look for use statements, parameter types, return types, etc.
Although this is strictly speaking the safest option, it may also result in
multiple errors per class. A pragmatic alternative is to look for actual
method calls on these objects. Once we've removed all the calls to
InputInterface and OutputInterface, PHPStan will start noticing that
some properties or parameters aren't used, and that they may be deleted.

Finally, PHP-CS-Fixer or a similar tool will remove unused import
statements for us.
We already had some experience with analyzing method calls: our rule
should subscribe to MethodCall nodes. We can then use $scope-
>getType() to find out the type of the object on which the method is called.
The relevant node is in the $var property of the MethodCall node.
One other ingredient that we need for the rule is a way to find out what
parent classes a given class has, then check if Command is one of them. This
sounds like something we could figure out with reflection. After calling
$scope->isInClass() it should be safe to use $scope-
>getClassReflection(), from which we can get a list of parent class
names.
The result:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PhpParser\Node\Expr\MethodCall;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;
use Symfony\Component\Console\Command\Command;
use Symfony\Component\Console\Input\InputInterface;
use Symfony\Component\Console\Output\OutputInterface;
final class InputOutputOnlyInCommandRule implements Rule
{
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        /** @var ObjectType[] $forbiddenTypes */
        $forbiddenTypes = [
            new ObjectType(InputInterface::class),

            new ObjectType(OutputInterface::class),
        ];
        foreach ($forbiddenTypes as $forbiddenType) {
            if (! $forbiddenType->isSuperTypeOf(
                $scope->getType($node->var)
            )->yes()) {
                continue;
            }
            if (! $scope->isInClass()) {
                // The call is made outside a class; okay for now
                continue;
            }
            if (in_array(
                Command::class,
                $scope->getClassReflection()
                    ->getParentClassesNames(),
                true
            )) {
                // One of the parent classes of this class is `Command`
                continue;
            }
            // This call is inside a class that is not a `Command`
            return [
                RuleErrorBuilder::message(
                    sprintf(
                        'Object of type %s is used in a class that does
not extend %s',
                        $forbiddenType->getClassName(),
                        Command::class
                    )
                )->build(),
            ];
        }
        return [];
    }
}
Since we want to check for multiple "forbidden" object types, we make a
loop over a list of object types and return an error as soon as the object is an
instance of one of the forbidden types. The loop construction works in this
case, since an object is likely not to be both an instance of InputInterface
and of OutputInterface, so triggering only one error will be sufficient.
However, in cases like this, the rule can be simplified a lot by passing the
forbidden type as a constructor argument instead:
<?php

declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PhpParser\Node\Expr\MethodCall;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;
use Symfony\Component\Console\Command\Command;
final class ForbiddenObjectTypeInCommandRule implements Rule
{
    private readonly ObjectType $forbiddenType;
    public function __construct(string $forbiddenType)
    {
        $this->forbiddenType = new ObjectType($forbiddenType);
    }
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if (! $this->forbiddenType->isSuperTypeOf(
            $scope->getType($node->var)
        )->yes()) {
            return [];
        }
        if (! $scope->isInClass()) {
            // The call is made outside a class; okay for now
            return [];
        }
        if (in_array(
            Command::class,
            $scope->getClassReflection()
                ->getParentClassesNames(),
            true
        )) {
            // One of the parent classes of this class is `Command`
            return [];
        }
        // This call is inside a class that is not a `Command`
        return [
            RuleErrorBuilder::message(
                sprintf(
                    'Object of type %s is used in a class that does not

extend %s',
                    $this->forbiddenType->getClassName(),
                    Command::class
                )
            )->build(),
        ];
    }
}
A big advantage is that we no longer have the foreach loop with its
confusing continue statements. Instead, we can return early as soon as the
rule doesn't apply. To make it work again, you still have to add the rule to
your phpstan.neon file several times but with different arguments:
services:
    -
        class: Utils\PHPStan\ForbiddenObjectTypeInCommandRule
        arguments:
            - Symfony\Component\Console\Input\InputInterface
        tags:
            - phpstan.rules.rule
    -
        class: Utils\PHPStan\ForbiddenObjectTypeInCommandRule
        arguments:
            - Symfony\Component\Console\Output\OutputInterface
        tags:
            - phpstan.rules.rule
This is the output when we now run PHPStan on the directory that contains
the ImportProgressUsingCliOutput class we created earlier:
------ ---------------------------------------------------------------
 Line   App/Command/ImportProgressUsingCliOutput.php
------ ---------------------------------------------------------------
 16     Object of type
        Symfony\Component\Console\Output\OutputInterface is used in a
        class that does not extend
        Symfony\Component\Console\Command\Command
 26     Object of type
        Symfony\Component\Console\Output\OutputInterface is used in a
        class that does not extend
        Symfony\Component\Console\Command\Command
------ ---------------------------------------------------------------
[ERROR] Found 2 errors

It will be very useful to add similar rules to your project that define in
which types of classes you're allowed to work with Request or Response
objects. The same goes for services like RequestStack, or Session, which
should only be available in the part of the application that's highly coupled
to the framework. Any essential business logic should not rely on it.
OceanofPDF.com

4 Form Validation
This Chapter Covers:
Separating request validation from model protection
Reusing and consolidating validation rules using value objects
Preventing validation framework coupling with PHPStan rules
Introduction
Forms and validation go hand-in-hand in most (web) frameworks. A form is
defined in HTML, its data encoded and submitted by the browser, as the
body of an HTTP request. The framework usually converts the data into an
associative array for us, so we can take from it what we need inside the
controller. There are a number of things we always have to consider:
We expect certain keys to exist, but maybe they don't, because the
form didn't show a particular field, the browser didn't submit the data,
or the user has tampered with the request body.
We expect certain values to be provided by the user, and expect these
values to be within certain lengths, ranges, etc. The user may not have
filled in the form correctly, or again, they may have tampered with the
request body.
So before we can use the submitted data we always have to be careful about
verifying its correctness. We have to make sure that we don't process
invalid data, or even save it into our database. This means we should stop
the execution of our business logic as soon as some value is missing or
looks wrong. The only way to reliably stop execution is to throw an
exception, which will let us jump out of the current method immediately.
However, if we stop execution at the first sign of a problem, we'll have a
hard time communicating with the user. We can't just display any exception
message to the user since that poses a security risk.

By relying solely on exceptions for validation, we may also get the user into
an endless cycle of trial and error. They fill out the form, submit it, fix the
first reported error, submit it again, fix the next reported error, and so on.
This isn't a great user experience. Instead, we want to show nice and
friendly (often localized or translated) error messages below each form field
for which the user didn't provide a correct value.
Based on these considerations we may conclude that the two major reasons
for performing validation on user-submitted data are:
1. To offer protection against invalid data being processed by our
application (i.e. guarantee data consistency)
2. To help the user provide valid data (i.e. improve the user experience)
Form Validation
So we want to do form validation, and for different reasons, but we should
also take care to do it in a decoupled way. One that survives a framework
migration, or can be easily ported. As usual, let's start with a realistic
example: a controller that handles the sign-up of a new user. In this example
we use the Laravel framework. The controller validates submitted form data
and uses it to populate the fields of a User model:
<?php
declare(strict_types=1);
namespace App\Http\Controllers;
use App\Models\User;
use Illuminate\Http\Request;
use Illuminate\Http\Response;
final class SignUpController
{
    public function signUp(Request $request): Response
    {
        $validatedData = $request->validate(
            [
                'name' => 'required|min:3|max:255',
                'email' => 'required|email',
                'type' => 'required|in:organizer,regular_user',
                'foo' => ['bar'],
                /*

                 * N.B. 'foo' isn't a real from field,
                 * 'bar' is a non-existing rule
                 */
            ]
        );
        $user = User::create($validatedData);
        $user->save();
        // ...
    }
}
In the controller we use the validate() method on the Request object. This
method doesn't really exist. It's a closure which is registered early in the
service container life cycle. When you invoke Request::validate(), the
magic method __call() of the Macroable trait used in the Request class
will forward the call to the closure. The closure creates a validator based on
the request data and the array of validation rules. The array of rules will be
parsed by the validator, and each of the parts separated by | will be resolved
to dedicated validation rules, which are then checked against the values in
the data array. When any of the values don't pass the validation rules, the
validator throws a ValidationException. The validation errors will be
saved in the session and the user will be redirected to the form, which then
shows the errors together with the submitted data.
I find it interesting to take this kind of in-depth look at the validation
process for one framework, because another framework will likely do
things in a different way. For example, with Symfony you'd define
validation rules as annotations on the object you want to validate. The
validator doesn't throw an exception, but generates a list of "constraint
violations". Seeing such large differences between framework validation
libraries, one can imagine it will be a lot of work to port validation logic
between frameworks or validation libraries. Each has their own specialized
syntax or DSL (Domain-Specific Language).
For me, a positive aspect of Laravel validation is that it validates request
data. This is different from Symfony, which would validate the submitted
values after they have already been assigned to the properties of the model
(called "entity"). This leaves the entity completely helpless. You can assign

values, skip the validation step, and you'll end up with inconsistent data in
your entity (and maybe in your database too).
A downside of Laravel validation is that a big part of the validation process
relies on magic outside the controller. Something in the framework has to
catch the ValidationException and make the decision to redirect to the
previous page, showing the form, and storing the submitted data and the
validation errors in the session. This is a very specialized decision that I'd
like to see in the controller itself. It's also not the only imaginable way you
can deal with validation errors.
Another problem is the way you configure validation rules. If you add a
validation rule for a field that is not in the submitted data, it doesn't produce
an error, so you don't know that you wrote dead code (as is the case in the
previous code sample). Also, when defining the rules that should apply to a
certain field, there's no way to find out what rules can be used or what
configuration options they have. You have to read the documentation to find
out more. If you try to use a rule that the framework doesn't know about,
you'll get a confusing error about a method that doesn't exist.
One other problem is the implicit requirement that the attributes/properties
of the model have the same name as the form fields, which in their turn
have the same name as the columns in the database. This eventually gets in
the way when we want to make changes in any of those places, and need to
find out where certain keys are used, have to be renamed, or where their
types should change. Because the entire mapping process is implicit (from
request, to model, to database), changing anything anywhere will be a
matter of trial and error. By the way, this is not specific to Laravel.
Symfony, for instance, has the same issue. In many applications it results in
the data model being exposed to the public 1:1 via form fields or JSON API
responses, and there's no way to change any of these, without also changing
other parts that you didn't want to change.
Yet the biggest problem is the lack of real protection. We do have some
rules in mind for the data in our User model, but we validate the rules
outside this object. Yes, the validator will throw an exception if the
submitted data is invalid. But a User object can be created in other ways, in
other parts of the code base where the developer doesn't use

Request::validate() before calling User::create(). There we could end
up with a User object with an invalid state, e.g. if we pass an empty array or
an array with invalid values to the create() method. Everything here relies
on the false assumption that we'll always use Request::validate() before
calling User::create(). This is a form of temporal coupling, but we also
couple our entity to HTTP as the delivery mechanism for our data. An
HTTP POST request is likely not be the only source of data for our model,
and it would be unfortunate to link the validity of our model to the validity
of submitted request data.
We can improve the situation by overriding User::create() and
performing the validation inside that method. Whenever we try to create a
User object, if we pass invalid data to it, we may expect a
ValidationException:
<?php
declare(strict_types=1);
namespace App\Models;
use Illuminate\Database\Eloquent\Model;
use Illuminate\Support\Facades\Validator;
final class User extends Model
{
    // ...
    /**
     * @param array<string,string> $data
     */
    public static function create(array $data): self
    {
        $validatedData = Validator::validate(
            $data,
            [
                'name' => 'required|min:3|max:255',
                'email' => 'required|email',
                'type' => 'required|in:organizer,regular_user',
            ]
        );
        return new self($validatedData);
    }
    // ...
}

This still doesn't solve most of the problems we discussed earlier, e.g. the
implicit mapping, the hard-to-maintain rule configuration. Besides, instead
of only coupling the controller to the framework, now the model itself is
coupled to it. A bigger issue is: how does the model gain access to the
validator service? We have to use a faÃ§ade, which is a form of coupling to a
particular style for working with service dependencies, leaving the code
coupled to the framework in even more ways.
Protecting Data Inside the Model
The solution to decouple from the validator, and to properly protect our
domain model, is to own the consistency checks. We check the values
manually, without a dependency on the validator. It results in a lot of extra
code, but we will make an effort to simplify this code later on.
<?php
declare(strict_types=1);
namespace App\Models;
use Illuminate\Database\Eloquent\Model;
use InvalidArgumentException;
final class User extends Model
{
    // ...
    /**
     * @param array<string,string> $data
     */
    public static function create(array $data): self
    {
        if (! isset($data['name'])) {
            throw new InvalidArgumentException('...');
        }
        if (strlen($data['name']) < 3) {
            throw new InvalidArgumentException('...');
        }
        if (strlen($data['name']) > 255) {
            throw new InvalidArgumentException('...');
        }
        if (! isset($data['email'])) {
            throw new InvalidArgumentException('...');
        }
        if (! filter_var($data['email'], FILTER_VALIDATE_EMAIL)) {
            throw new InvalidArgumentException('...');

        }
        if (! isset($data['type'])) {
            throw new InvalidArgumentException('...');
        }
        if (! in_array(
            $data['type'],
            ['organizer', 'regular_user'],
            true
        )) {
            throw new InvalidArgumentException('...');
        }
        // ...
        return new self($data);
    }
    // ...
}
Adding these so-called pre-condition checks to the User::create() method
ensures that even if we skip form validation, we still have a way to protect
our model from having an inconsistent state. This makes the User object
safe to use, in any context.
We should still improve this code a bit. First, the keys of the $data array we
pass to User::create() are literally the names of the form fields in our
HTML template. As we've discussed before, this doesn't give us the
freedom to change the names or types of the values, without also changing
them elsewhere. It's also unclear exactly what values are required for
"creating" a user. Could we pass an empty array? Could we pass an array
with just one key? Let's be more specific about the requirements for
creating a user by declaring explicit method parameters:
<?php
declare(strict_types=1);
namespace App\Models;
use Illuminate\Database\Eloquent\Model;
use InvalidArgumentException;
use function filter_var;
final class User extends Model
{
    protected $fillable = ['name', 'email', 'type'];

    // ...
    public static function create(
        string $name,
        string $email,
        string $type,
    ): self {
        if (strlen($name) < 3) {
            throw new InvalidArgumentException('...');
        }
        if (strlen($name) > 255) {
            throw new InvalidArgumentException('...');
        }
        if (! filter_var($email, FILTER_VALIDATE_EMAIL)) {
            throw new InvalidArgumentException('...');
        }
        if (! in_array($type, ['organizer', 'regular_user'], true)) {
            throw new InvalidArgumentException('...');
        }
        return new self([
            'name' => $name,
            'email' => $email,
            'type' => $type,
        ]);
    }
    // ...
}
In the User model we still pass an array of values to the private constructor,
since that's how Eloquent models want their data: as an array. We'll talk
more about the topic of mapping objects to database records in the chapter
about ORMs.
Of course, declaring separate parameters means we also have to pass
separate arguments, so taking the values out of the array of submitted form
values is now going to be the work of the controller:
final class SignUpController
{
    public function signUp(Request $request): Response
    {
        $validatedData = $request->validate(
            [
                'name' => 'required|min:3|max:255',
                'email' => 'required|email',
                'type' => 'required|in:organizer,regular_user',
            ]

        );
        $user = User::create(
            $validatedData['name'],
            $validatedData['email'],
            $validatedData['type'],
        );
        $user->save();
        // ...
    }
}
We have made an effective split between helping the user to provide the
right values (form validation in the controller) and protecting our
application against processing invalid values (data consistency inside the
model). We can also clearly distinguish form fields from constructor
parameters and database columns, which allow each of these parts to evolve
in different directions.
Delegating Protection to Value Objects
We can now start using value objects in our model. Value objects are useful
when you want to guarantee the consistency of separate values instead of
complete models. It goes beyond the scope of this book to discuss the
concept of Value object, but I recommend looking this up in Eric Evans'
"Domain Driven Design" book.
In our current example we could introduce a value object that represents a
valid email address:
<?php
declare(strict_types=1);
namespace App\Models;
use InvalidArgumentException;
final class Email
{
    private string $email;
    private function __construct(string $email)
    {
        if (! filter_var($email, FILTER_VALIDATE_EMAIL)) {

            throw new InvalidArgumentException('...');
        }
        $this->email = $email;
    }
    public static function fromString(string $email): self
    {
        return new self($email);
    }
    public function asString(): string
    {
        return $this->email;
    }
}
A value object can be created based on a primitive value (string, int, etc.),
or sometimes several primitive values. In the constructor of the object we
should throw exceptions if the value doesn't match our expectations. If you
do this consistently, it means you can only instantiate a value object when
you pass valid data to it. This helps you guarantee data consistency all over
the code base. When you declare a method parameter with the class of the
value object as its type, you can only call that method if you provide an
instance of the object. Since you can only instantiate a value object by
passing a valid value to it, you can use the type as evidence of the
correctness of its underlying value.
As an example, we can promote the string $email parameter of
User::create() to become Email $email. Then we don't have to check
this value inside the create() method anymore:
<?php
declare(strict_types=1);
namespace App\Models;
use Illuminate\Database\Eloquent\Model;
use InvalidArgumentException;
final class User extends Model
{
    protected $fillable = ['name', 'email', 'type'];
    // ...
    public static function create(

        string $name,
        Email $email,
        string $type,
    ): self {
        if (strlen($name) < 3) {
            throw new InvalidArgumentException('...');
        }
        if (strlen($name) > 255) {
            throw new InvalidArgumentException('...');
        }
        // No need to check $email again
        if (! in_array($type, ['organizer', 'regular_user'], true)) {
            throw new InvalidArgumentException('...');
        }
        // ...
    }
    // ...
}
Now the caller of create() will have the additional task to instantiate an
Email object:
final class SignUpController
{
    public function signUp(Request $request): Response
    {
        // ...
        $user = User::create(
            $validatedData['name'],
            Email::fromString($validatedData['email']),
            $validatedData['type'],
        );
        $user->save();
        // ...
    }
}
We've successfully decoupled the form validation from the model
protection. It means that even if we remove the framework completely, our
model will still be able to protect itself. We're free to use form validation,
but we don't rely on it for the consistency of our data.
There is one aspect of our current implementation that isn't great: we're
duplicating the validation logic itself, and we may not even duplicate it

exactly. The framework will have a certain way of validating an email
address, and now we have our own check inside the Email value object.
There may be differences between the two.
Removing Duplicate Validation Logic
We can solve the issue by removing the duplication in the validation logic,
and by consolidating similar validation code. First we have to introduce
value objects for all the values that we have specific validation rules for,
e.g.
A username is at least 3 characters long, at most 255
The user type is one of "organizer" or "regular_user"
For the name of the user we can use the following value object:
use InvalidArgumentException;
final class UserName
{
    private string $name;
    private function __construct(string $name)
    {
        if (strlen($name) < 3) {
            throw new InvalidArgumentException('...');
        }
        if (strlen($name) > 255) {
            throw new InvalidArgumentException('...');
        }
        $this->name = $name;
    }
    public static function fromString(string $name): self
    {
        return new self($name);
    }
    // ...
}
For the user type we can use an enum:
namespace App\Models;

enum UserType: string
{
    case RegularUser = 'regular_user';
    case Organizer = 'organizer';
}
Inside the controller we instantiate the value objects and pass them to the
User model (the syntax for instantiating the UserType enum is slightly
different from the other value objects):
final class SignUpController
{
    public function signUp(Request $request): Response
    {
        // ...
        $user = User::create(
            UserName::fromString($validatedData['name']),
            Email::fromString($validatedData['email']),
            UserType::from($validatedData['type']),
        );
        $user->save();
        // ...
    }
}
The next step is to let the Laravel form validator use the constructor of the
value object, instead of its own rules. If the constructor of the value object
throws an exception, Laravel should consider the submitted value to be
invalid and show a form error about it. To make this work, we need a way
to write our own validation rules, instead of relying on Laravel's built-in
rules. There are several ways to accomplish this. Here I'd like to use
closures. We can add a static validator() method to each value object,
which returns a closure that does the required validation work. We try to
instantiate the value object based on the provided value and call the $fail
callback if it didn't work:
use Closure;
use InvalidArgumentException;
final class Email
{
    // ...
    private function __construct(string $email)
    {
        if (! filter_var($email, FILTER_VALIDATE_EMAIL)) {

            throw new InvalidArgumentException('...');
        }
        $this->email = $email;
    }
    public static function validator(): Closure
    {
        return function (
            string $attribute,
            ?string $value,
            callable $fail
        ) {
            try {
                if (! is_string($value)) {
                    throw new InvalidArgumentException('...');
                }
                // Try to instantiate an `Email` instance
                self::fromString($value);
                // It works, we do nothing...
            } catch (InvalidArgumentException) {
                // It didn't work, we call `$fail()`
                $fail('validation.email');
            }
        };
    }
    // ...
}
We can do a similar thing for the other value objects (UserName and
UserType). To use these closures instead of rules like required|email we
have to modify the rules in the controller as follows:
final class SignUpController
{
    public function signUp(Request $request): Response
    {
        // Controller may optionally validate form data
        $validatedData = $request->validate(
            [
                'name' => UserName::validator(),
                'email' => Email::validator(),
                'type' => UserType::validator(),
            ]
        );
        // The model protects itself no matter what
        $user = User::create(
            UserName::fromString($validatedData['name']),
            Email::fromString($validatedData['email']),

            UserType::from($validatedData['type']),
        );
        $user->save();
        // ...
    }
}
We have now completely de-duplicated and consolidated all the validation
logic. Form validation and model protection both follow the same rules. If
you change the value object's constructor to validate other aspects of a
value, it will be automatically reflected in the form as well.
A side-note from the perspective of coupling: we have introduced a new
form of framework coupling inside the value objects themselves. The
validator() method is only used in the context of Laravel validation.
However, it doesn't introduce a code dependency. If you'd completely
remove Laravel from your project, this code can still be invoked, and it still
works. If you want to migrate to a different validation library, it's likely that
you have to rewrite the code in validator() a bit though. I don't think this
is a bad case of coupling: we fully own the rules, and we can replicate any
validation logic we currently have in any other framework.
Defining an Explicit Shape for the Input Data
Considering a framework switch is one way to find out how coupled your
code is. But switching to a different input/output mechanism will also give
you some useful insights. We already noticed this in the previous chapter,
where we considered both a web user-interface and a command-line
interface as sources for user input. In this chapter, let's consider what
happens if we want to transform our HTML-form-based backend
controllers into API endpoints that can be used by a JS-based or mobile
frontend. In that case, the input data may be provided as a JSON-encoded
object in the request body, instead of form data.
To prepare for this change, we'd have to make the validator work with
something else than form data. We don't have to do a lot of work though:
the validator service itself doesn't need a Request object, it only needs an
array. So if we use the Validator faÃ§ade instead of Request::validate(),
we can pass it the decoded JSON array, and it will still give us the same

validation errors. What also changes is that we can no longer rely on
Laravel's default behavior of redirecting to the previous page. We should
catch the ValidationException ourselves, and return a JSON response
containing the serialized errors:
use Illuminate\Http\JsonResponse;
use Illuminate\Support\Facades\Validator;
use Illuminate\Validation\ValidationException;
use Symfony\Component\HttpFoundation\Response;
final class SignUpController
{
    public function signUp(Request $request): Response
    {
        try {
            $validatedData = Validator::validate(
                $request->json()
                    ->all(),
                [
                    'name' => UserName::validator(),
                    'email' => Email::validator(),
                    'type' => UserType::validator(),
                ]
            );
        } catch (ValidationException $exception) {
            return new JsonResponse(
                [
                    'errors' => $exception->errors(),
                ],
                Response::HTTP_UNPROCESSABLE_ENTITY
            );
        }
        $user = User::create(
            UserName::fromString($validatedData['name']),
            Email::fromString($validatedData['email']),
            UserType::from($validatedData['type']),
        );
        $user->save();
        // ...
    }
}
It seems like we wouldn't have a lot of extra work here if we want to switch
to a different input/output mechanism. Still, I think it would be helpful if
we'd stop relying on associative arrays for our data. The shape of such an
array is not clearly defined. When this array contains submitted form data,
its shape depends on the HTML form itself. When the array comes from a
JSON-encoded request body, its shape depends on what the client has

prepared on their side. In both cases the shape itself is not enforced by our
controller, but by something outside it.
One way to improve the situation is to make the shape explicit and define a
class for it. We call such a class a DTO, short for Data Transfer Object. We
can use it to specify which values we expect, and the types we expect them
to have. In our case it can have a fromJsonRequest() factory method,
which extracts the data from the request and enforces all the expected fields
to be there, throw exceptions if a field is undefined:
<?php
declare(strict_types=1);
namespace App\Http\Controllers;
use Illuminate\Http\Request;
use OutOfBoundsException;
final class SignUp
{
    public function __construct(
        public readonly string $name,
        public readonly string $email,
        public readonly string $type,
    ) {
    }
    public static function fromJsonRequest(Request $request): self
    {
        $data = $request->json()
            ->all();
        return new self(
            $data['name'] ?? throw new OutOfBoundsException('...'),
            $data['email'] ?? throw new OutOfBoundsException('...'),
            $data['type'] ?? throw new OutOfBoundsException('...'),
        );
    }
    /**
     * @return array<string,string>
     */
    public function toArray(): array
    {
        return [
            'name' => $this->name,
            'email' => $this->email,
            'type' => $this->type,
        ];

    }
}
In the controller we create the DTO based on the request, and when the
validator needs an array once more, we can call toArray() on it:
use Illuminate\Http\JsonResponse;
use Illuminate\Support\Facades\Validator;
use Illuminate\Validation\ValidationException;
use Symfony\Component\HttpFoundation\Response;
final class SignUpController
{
    public function signUp(Request $request): Response
    {
        $signUp = SignUp::fromJsonRequest($request);
        try {
            Validator::validate(
                $signUp->toArray(),
                [
                    'name' => UserName::validator(),
                    'email' => Email::validator(),
                    'type' => UserType::validator(),
                ]
            );
        } catch (ValidationException $exception) {
            // ...
        }
        $user = User::create(
            UserName::fromString($signUp->name),
            Email::fromString($signUp->email),
            UserType::from($signUp->type),
        );
        $user->save();
        // ...
    }
}
We can improve this by adding a validate() method to the DTO instead,
encapsulating all the transformation steps (from Request to JSON-decoded
array, to fields on the DTO, to an array that can be passed to the Validator
facade):
use Illuminate\Support\Facades\Validator;
final class SignUp
{
    // ...

    public function validate(): void
    {
        Validator::validate(
            // We don't need a separate `toArray()` function for this
            [
                'name' => $this->name,
                'email' => $this->email,
                'type' => $this->type,
            ],
            [
                'name' => UserName::validator(),
                'email' => Email::validator(),
                'type' => UserType::validator(),
            ]
        );
    }
}
In the controller we can call the new SignUp::validate() method and
decide what to do with a potential ValidationException:
final class SignUpController
{
    public function signUp(Request $request): Response
    {
        $signUp = SignUp::fromJsonRequest($request);
        try {
            $signUp->validate();
        } catch (ValidationException $exception) {
            // ...
        }
        // ...
    }
}
Although we've been able to hide all the data juggling inside the DTO,
converting between an object and an array still isn't very convenient. This
is where it would be helpful if we could validate the DTO instead of an
array that was created only for the purpose of validation. It's possible to
validate objects with the Symfony validator, but I'm not sure if it could also
work with Laravel.

Now that we have a DTO, we can simplify the controller a bit. We can
move the instantiation code for the value objects to the getters of the DTO
(while making its fields private):
final class SignUp
{
    public function __construct(
        private readonly string $name,
        private readonly string $email,
        private readonly string $type,
    ) {
    }
    // ...
    public function name(): UserName
    {
        return UserName::fromString($this->name);
    }
    public function email(): Email
    {
        return Email::fromString($this->email);
    }
    public function type(): UserType
    {
        return UserType::from($this->type);
    }
}
In the controller we can pass the value objects from the command directly
to the model:
final class SignUpController
{
    public function signUp(Request $request): Response
    {
        $signUp = SignUp::fromJsonRequest($request);
        // ...
        $user = User::create(
            $signUp->name(),
            $signUp->email(),
            $signUp->type(),
        );
        $user->save();
        // ...

    }
}
Rules for Decoupling
The result of our refactoring efforts is that we changed the way we deal
with validation and with model creation:
1. We no longer pass a set of strings to validate() (e.g.
'required|email'). We use closures returned by value objects
instead.
2. We no longer pass validated data arrays to a model's create()
function. We pass separate arguments instead, some of which will be
value objects.
We can definitely write some PHPStan rules that help us consistently
enforce these practices in a code base. Whether you want to do that is up to
you. I just want to show what's possible with PHPStan.
Don't Pass a Single Array of Data to create()
Let's start with the rule that prevents us from instantiating models by
passing an array to its static create() method. We may call this rule
ModelCreatedWithArrayRule. Instead of MethodCall nodes we'd have to
look for StaticCall nodes, which are somewhat different. Instead of a
$var node which represents the object on which the method is called, it has
a $class node which represents the class on which the method is called:
<?php
declare(strict_types=1);
namespace PhpParser\Node\Expr;
use PhpParser\Node;
use PhpParser\Node\Arg;
use PhpParser\Node\Expr;
use PhpParser\Node\Identifier;
use PhpParser\Node\VariadicPlaceholder;
class StaticCall extends CallLike
{

    /**
     * @var Node\Name|Expr Class name
     */
    public $class;
    /**
     * @var Identifier|Expr Method name
     */
    public $name;
    /**
     * @var array<Arg|VariadicPlaceholder> Arguments
     */
    public $args;
It extends CallLike, which offers the getArgs() method we used before.
Each argument will be an Arg node, which we also saw before. The value of
the argument can be found inside its $value sub-node, which is an
expression node. So Scope::getType() can tell us more about the type of
argument that is passed. Our rule should trigger an error if the create()
method is called with just a single argument and this argument is an array.
So we want an error for this kind of code:
<?php
declare(strict_types=1);
use Utils\PHPStan\Tests\ModelCreatedWithArrayRule\Fixtures\AModel;
$validatedData = [];
AModel::create($validatedData);
We'd also have to consider the following edge cases:
1. Maybe no arguments are provided. In that case we also want to trigger
an error since the default value for the argument will be used, which is
an empty array, and that also counts as an array.
2. Maybe more than one argument is provided. This case should be
ignored by the rule.
3. Maybe one argument is provided, but it's not an array. This case
should also be ignored.

Note that Eloquent's Model class is an abstract class so to make our
fixtures realistic we have to create a custom model class which extends
Model. This class needs to be auto-loadable, just like the Model class itself,
or PHPStan won't be able to resolve the correct types or do reflection on
these classes. In Chapter 1 we already set up the "autoload-dev" section of
composer.json for auto-loading PHPUnit test classes, so we only have to
use the correct namespace and everything should work:
utils/PHPStan/tests/ModelCreatedWithArrayRule/Fixtures/AModel.php
<?php
declare(strict_types=1);
namespace Utils\PHPStan\Tests\ModelCreatedWithArrayRule\Fixtures;
use Illuminate\Database\Eloquent\Model;
class AModel extends Model
{
}
Combining all these ingredients, and adding the necessary fixtures and test
cases, this implementation will do the trick:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use Illuminate\Database\Eloquent\Model;
use PhpParser\Node;
use PhpParser\Node\Expr\StaticCall;
use PhpParser\Node\Identifier;
use PhpParser\Node\Name;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;
final class ModelCreatedWithArrayRule implements Rule
{
    public function getNodeType(): string
    {
        return StaticCall::class;
    }
    /**
     * @param StaticCall $node
     */
    public function processNode(Node $node, Scope $scope): array

    {
        if (! $node->class instanceof Name) {
            // The class part is dynamic, we can't do anything with it
            return [];
        }
        $type = $scope->resolveTypeByName($node->class);
        if (! (new ObjectType(Model::class))
            ->isSuperTypeOf($type)
            ->yes()) {
            // The class is definitely not a model
            return [];
        }
        if (! $node->name instanceof Identifier
            || $node->name->toString() !== 'create') {
            // Calling some other method than `create()`
            return [];
        }
        if (count($node->getArgs()) > 1) {
            // Multiple arguments were provided: great!
            return [];
        }
        if (count($node->getArgs()) === 0) {
            return [
                RuleErrorBuilder::message(
                    'Model is created with no arguments, ' .
                    'use explicit arguments instead'
                )->build(),
            ];
        }
        $firstArgument = $node->getArgs()[0];
        if (! $scope->getType($firstArgument->value)->isArray()
            ->yes()) {
            // The only argument is not an array
            return [];
        }
        return [
            RuleErrorBuilder::message(
                'Model is created with an array argument, ' .
                'use explicit arguments instead'
            )->build(),
        ];
    }
}
Because there are many types that count as an array, PHPStan's Type
interface has an isArray() function that you can call to find out if a type
should be considered an array.

Note that we are spending a lot of time excluding cases that we're not
interested in. It's best practice to use early returns, but with so many early
returns the value of this practice quickly diminishes. Introducing private
helper methods will be helpful. These methods allow you to summarize
multiple if statements and turn comments into method names,
encapsulating the messy aspects of dealing with nodes:
final class ModelCreatedWithArrayRule implements Rule
{
    public function getNodeType(): string
    {
        return StaticCall::class;
    }
    /**
     * @param StaticCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if (! $this->isCallToModelCreate($node, $scope)) {
            return [];
        }
        if (count($node->getArgs()) > 1) {
            // Multiple arguments were provided: great!
            return [];
        }
        // ...
        return [
            RuleErrorBuilder::message(
                'Model is created with an array argument, ' .
                'use explicit arguments instead'
            )->build(),
        ];
    }
    private function isCallToModelCreate(
        StaticCall $node,
        Scope $scope
    ): bool {
        if (! $node->class instanceof Name) {
            // The class part is dynamic, we can't do anything with it
            return false;
        }
        // ...
        return $node->name->toString() === 'create';
    }
}

Enforcing the Use of Closure-based Form
Validation
A second rule we could write is that when you call Request::validate(),
you may only use closure-based validators. This gives us the guarantee that
the model uses the same rules as the form validator. We can do a similar
thing as we did in Chapter 2, where we wanted to prevent entities from
being passed to Twig's render() function. We could look for values in the
array passed to validate() and produce an error for every value type that
is not a closure (i.e. an instance of ClosureType).
However, such a rule may be too strong. We could try something less
restrictive and say that, instead of using a validator like required|email,
we want everyone to use Email::validator() instead.
Let's set up a new rule for this purpose: UseEmailValidatorRule. Since we
want to trigger errors for $request->validate() calls, and $request is an
object, not a class, we should once more register the rule for MethodCall
nodes. The first argument of this call will be the array with the validation
options. If any of the values is of type ConstantStringType, we should
look inside the string, which PHPStan can extract for us, to see if it contains
the 'email' validator. So the following code sample should trigger an error:
utils/PHPStan/tests/UseEmailValidatorRule/Fixtures/validate-string-contains-
email.php
<?php
declare(strict_types=1);
use Illuminate\Http\Request;
final class SomeController
{
    public function someAction(Request $request)
    {
        $request->validate(
            [
                'email_address' => 'required|email'
            ]
        );
    }
}

Building on our experience with PHPStan, we can quickly create a rule for
this (leaving out the parts that are too similar to what we've already seen
before):
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use Illuminate\Http\Request;
use PhpParser\Node;
use PhpParser\Node\Expr\MethodCall;
use PhpParser\Node\Identifier;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\Constant\ConstantArrayType;
use PHPStan\Type\Constant\ConstantStringType;
use PHPStan\Type\ObjectType;
final class UseEmailValidatorRule implements Rule
{
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if (! $this->isCallToRequestValidate($node, $scope)) {
            return [];
        }
        if (count($node->getArgs()) === 0) {
            // No arguments provided, nothing to analyze
            return [];
        }
        $firstArgumentNode = $node->getArgs()[0];
        $firstArgumentType = $scope->getType($firstArgumentNode->value);
        if (! $firstArgumentType instanceof ConstantArrayType) {
            // No constant array provided, we can't analyze this
            return [];
        }
        foreach ($firstArgumentType->getValueTypes() as $valueType) {
            if (! $valueType instanceof ConstantStringType) {
                // The value is not a plain string
                continue;
            }

            $parts = explode('|', $valueType->getValue());
            if (! in_array('email', $parts, true)) {
                // The string doesn't contain 'email'
                continue;
            }
            // Return an error on the first use of "email":
            return [
                RuleErrorBuilder::message(
                    'Use App\Models\Email::validator() instead of
"email"'
                )->build(),
            ];
        }
        return [];
    }
    private function isCallToRequestValidate(
        MethodCall $node,
        Scope $scope
    ): bool {
        // ...
        return $node->name->toString() === 'validate';
    }
}
All the ifs in the rule already show what "skip" tests and fixtures I have
added for this rule:
Validation options that are not strings
Validation options that don't contain "email"
Calls to validate() on objects that are not an instance of Request
Calls to other methods on Request
Conclusion
Even without controllers and form or request validation, your model should
still be able to protect itself. A good rule is to assume that request data has
not been validated. Make sure your model throws exceptions whenever
some data is incomplete or incorrect.
Although most form validation errors can be prevented by improving the UI
itself, if you still want to do form or request validation you have to make

sure the model uses the same rules as your request validator tool. You can
do this by introducing value objects.
By the way, we didn't even talk about form libraries or helpers in this
chapter. Personally I still think that writing forms in plain HTML is just
fine, but I'm usually not working on applications that use many forms, so
don't take my advice on this subject.
OceanofPDF.com

5 ORMs and the Database
This Chapter Covers:
Creating repositories to abstract persistence
Applying aggregate design rules
Introducing use case-specific view models
Replacing persistence-based events with domain events
Introduction
In the early 2000s we wrote all our SQL queries by hand. This was
eventually recognized as a security hazard. We learned about using prepared
statements. PHP introduced PDO, as a way to abstract away some database
vendor-specific things that we did in our code. It turned out that PDO
definitely wasn't a complete database abstraction library. There were still
many aspects of abstracting the database that Doctrine DBAL (Database
Abstraction Layer) was able to add. Meanwhile, programmers wanted to
move to a more object-oriented style of programming. We needed a way to
write their domain logic in classes, but still save the state of domain objects
in database tables. In other words, we wanted to map objects to records in a
relational database. Hence, the name ORM - Object-Relational Mapper. The
ORM abstracts the work that needs to be done to "save an object to the
database". But that's not all, the ORM also needs to retrieve records and
reconstitute the original objects. Nowadays, ORMs also handle schema
migrations for you.
Since ORMs do so many things, we often don't realize how much our
domain model is coupled to it anymore. We only notice this when the need
arises to migrate to a different ORM, because the old one uses out-dated
programming techniques and design patterns, or is simply no longer
maintained. We also don't realize how much the ORM itself is still coupled
to the relational database. It may abstract from a specific database vendor,
but it has not abstracted from persistence to tables. Using the same ORM,

it's impossible to start saving object as, for instance, JSON files on disk, or
to retrieve them from ElasticSearch. This shows how a domain model is
often tightly coupled to the ORM and the database itself.
To find out how we can decouple from an ORM, we should indeed consider
what happens if we remove it. Then we should consider how much work is
needed if we want to switch from a relational to, say, a document database.
When scanning a code base for places where the model is coupled to the
ORM, we'll find the following use cases for the ORM:
1. In some parts of the application we create an object and then save it to
the database. Sometimes we load an existing object, modify it, and
again, save it to the database.
2. In other parts we load one or more objects from the database and show
parts of the object on some kind of view (e.g. an HTML page, a JSON
response, an email body). We don't need to modify the object here, nor
do we want to save anything to the database. We're only interested in
retrieving and presenting information.
We can summarize these two basic use cases in a more abstract way, as the
"needs" of our application. We need to:
1. Persist a domain model object, and to retrieve that object by its ID, so
we can make further changes, persist it again, etc.
2. Query some data for the user to view.
I've made these descriptions somewhat abstract on purpose: they don't say
anything about the source of the data itself. Does it come from a database?
And if so, a relational, or a document database? It doesn't matter. Our
application just needs these abilities, and we have to implement them
somehow. Defining our needs as abstractions is a way to decouple from
their underlying technical implementations. We first look at how to properly
abstract our code so that the first need is addressed in a decoupled way. For
this we'll need a repository, application-generated identifiers, and non-
cascading updates.

Repository: an Abstraction for Persistence
In the following example we'll work with Eloquent, the ORM that ships
with Laravel. This ORM is based on the Active Record pattern (Martin
Fowler, "Patterns of Enterprise Application Architecture"). We already
worked with this ORM in the previous chapter. Your model classes have to
extend an abstract Model class. In this example we have a Meetup model:
<?php
declare(strict_types=1);
namespace App\Models;
use Illuminate\Database\Eloquent\Model;
use Illuminate\Database\Eloquent\Relations\HasMany;
use DateTimeImmutable;
/**
 * @property string $topic
 * @property DateTimeImmutable $time
 */
final class Meetup extends Model
{
    // ...
    public $timestamps = false;
    protected $casts = [
        'time' => 'immutable_datetime',
    ];
    public function attendees(): HasMany
    {
        return $this->hasMany(Attendee::class);
    }
}
By extending Model, it inherits a lot of methods, like save() and find(). To
"persist" a Meetup object in the database, we first instantiate it, then call its
save() function. When we want to reload it, we call its static find()
method, providing the ID of the object.

Note that in real-world scenarios, this isn't likely to happen in the same
service, but this shows the general mechanism:
$meetup = new Meetup();
$meetup->topic = 'Eloquent Tips & Tricks';
$meetup->time = new DateTimeImmutable('2022-03-04 20:00');
$meetup->save();
$fromDb = Meetup::find($meetup->id);
Extending from a framework class like Model and relying on its public
methods to handle persistence is a way of tightly coupling our model to this
specific framework. It's impossible to see this model apart from the ORM
that we currently use. It's also impossible to store its data in a different
place than the relational database we currently use.
A more decoupled approach is provided by the Data Mapper pattern for
persistence (Fowler, idem). We distinguish the model object that holds the
data (which is called Entity) from the service object that saves the model's
data to the database. This service is called Repository and it's an abstraction
(more about entities and repositories can be found in Eric Evans, "Domain-
Driven Design").
We start by introducing the MeetupRepository interface, which acts as an
abstraction for a service that can store Meetup objects for us. It also lets us
retrieve them again by their ID. I use the method name getById() instead
of find() and like to throw an exception instead of returning null in case
the requested object could not be found:
<?php
declare(strict_types=1);
namespace App\Models;
interface MeetupRepository
{
    public function save(Meetup $meetup): void;
    public function getById(int $id): Meetup;
}

Now we need an implementation for the interface that performs the job of
both methods. At first, we can do what we normally do, and call save() and
find() on the model:
<?php
declare(strict_types=1);
namespace App\Models;
use RuntimeException;
final class MeetupRepositoryUsingEloquent implements MeetupRepository
{
    public function save(Meetup $meetup): void
    {
        $meetup->save();
    }
    public function getById(int $id): Meetup
    {
        $meetup = Meetup::find($id);
        if ($meetup === null) {
            throw new RuntimeException('...');
        }
        return $meetup;
    }
}
The class naming convention [...]UsingX usually works well, but isn't
mandatory of course.
In the next example we instantiate the repository manually, but normally
this should be done by the service container. The service that needs the
repository should depend on the interface, not the class.
$repository = new MeetupRepositoryUsingEloquent();
/*
 * `$repository` should be injected as a service of type
 * `MeetupRepository`
 */
$meetup = new Meetup();
$meetup->topic = 'Eloquent Tips & Tricks';
$meetup->time = new DateTimeImmutable('2022-03-04 20:00');
// Instead of `$meetup->save()`:

$repository->save($meetup);
// Instead of `Meetup::find($meetup->id)`:
$fromDb = $repository->getById($meetup->id);
Note that the Meetup class still has those save() and find() methods, so
Meetup is still coupled to the ORM. But all the places in our code that work
with Meetup objects aren't anymore. They use our own abstraction for
saving and retrieving these objects, meaning that even if we switch to a
different ORM or database, we don't have to change any of those places.
Of course, this strategy only works if we always use the repository. We have
to make sure that $meetup->save() and Meetup::find() aren't used
anywhere in our code. It would be smart not to rely on developer discipline
here. Instead, we should add a PHPStan rule that helps us enforce the
practice of using a repository. It has to register itself for MethodCall nodes,
ignore calls that are not made on some instance of Model or that are not
calls to save(), and also ignore calls to Model::save() that happen inside a
repository. To find out if we are inside a repository, we use class reflection.
Since we've used these techniques before, the rule doesn't need much more
of an introduction.
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use Illuminate\Database\Eloquent\Model;
use PhpParser\Node;
use PhpParser\Node\Expr\MethodCall;
use PhpParser\Node\Identifier;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;
final class EloquentRepositoryRule implements Rule
{
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */

    public function processNode(Node $node, Scope $scope): array
    {
        if (! $this->isCallToModelSave($node, $scope)) {
            return [];
        }
        if ($scope->isInClass()
            && $scope->getClassReflection() !== null
            && str_contains(
                $scope->getClassReflection()
                    ->getName(),
                'Repository'
            )) {
            // Great, the method call takes place in a repository
            return [];
        }
        return [
            RuleErrorBuilder::message(
                'Calling Model::save() is not allowed outside a
repository class'
            )->build(),
        ];
    }
    private function isCallToModelSave(
        MethodCall $node,
        Scope $scope
    ): bool {
        $isMethodCallOnModel = (new ObjectType(Model::class))
            ->isSuperTypeOf($scope->getType($node->var));
        if ($isMethodCallOnModel->no()) {
            // The object is not an instance of `Model`
            return false;
        }
        if (! $node->name instanceof Identifier) {
            // Dynamic method call, we don't know how to analyze it
            return false;
        }
        return $node->name->name === 'save';
    }
}
We may improve this basic rule by checking that if the call to save()
happens inside a repository class, that it's the repository class for the right
entity. E.g. Meetup::save() may only be called inside a class that
implements MeetupRepository (i.e. where MeetupRepository is a super-
type).

We also need a similar rule that looks for usages of Model::find() outside
of repository classes. In that case we'd have to register the rule for
StaticCall nodes.
I consider both of these nice exercises for the reader.
Trying an Alternative Implementation
As an abstraction, the repository looks quite promising: it offers methods
for saving and retrieving objects, without mentioning where the underlying
data is stored. To test the quality of the abstraction, let's see what happens if
we provide an alternative implementation for it: one that stores data in a
JSON file on disk instead of in the database. Here's a repository
implementation for that:
<?php
declare(strict_types=1);
namespace App\Models;
use RuntimeException;
final class MeetupRepositoryUsingJson implements MeetupRepository
{
    public function __construct(
        private readonly string $dataDirectory
    ) {
    }
    public function save(Meetup $meetup): void
    {
        $data = $meetup->getAttributes();
        $filename = $meetup->id . '.json';
        $jsonEncodedData = json_encode($data);
        file_put_contents(
            $this->dataDirectory . '/' . $filename,
            $jsonEncodedData
        );
    }
    public function getById(int $id): Meetup
    {
        $filename = $id . '.json';
        $filePathname = $this->dataDirectory . '/' . $filename;
        if (! is_file($filePathname)) {
            throw new RuntimeException('...');

        }
        $jsonEncodedData = file_get_contents($filePathname);
        if (! is_string($jsonEncodedData)) {
            throw new RuntimeException('...');
        }
        $jsonDecodedData = json_decode($jsonEncodedData);
        if (! is_array($jsonDecodedData)) {
            throw new RuntimeException('...');
        }
        $meetup = Meetup::create($jsonDecodedData);
        return $meetup;
    }
}
When we run this code, we get an interesting error:
TypeError: App\Models\MeetupRepositoryUsingJson::getById():
  Argument #1 ($id) must be of type int, null given
The call to save() somewhat succeeds. The repository saves a file called
.json in the data directory containing the following, correct JSON data:
{"topic":"Eloquent Tips & Tricks","time":"2022-03-04 20:00:00"}
The name of the file tells us what went wrong. Concatenating $meetup->id
and '.json' resulted in just '.json'. That's because Meetup's id property
is null.
This is an example of what often happens when you introduce an
abstraction. Although at first everything looks good, when you start
working on an alternative implementation, you notice that the abstraction
has issues.
In this case we relied on the model's ability to assign an ID to itself. Where
does it get this ID from? In the case of Eloquent, the standard behavior of
Model is that it will add an auto-incrementing integer id column to the
table. After saving, the object will get its ID from the database. When code
is coupled to a particular type of database, like a MySQL database which
offers auto-incrementing IDs, we may not realize this implicit behavior. We

may not even notice that the ID assignment happens magically behind the
scenes.
Application-generated IDs
How should we deal with that? We could make this auto-ID behavior part of
the repository interface contract and write it as a comment in the doc block
above the save() method. We should describe it in a contract test, so it will
be verified not only for this repository implementation, but for any future
one. However, we can also solve this issue in a more elegant way by
switching from a database-generated ID to an application-generated one. If
we can assign an ID to the model before saving it, we don't have to wait for
the database to generate one. If we can generate our own ID, regardless of
the type of database that's behind the repository, it will make the repository
abstraction better, because it will be easier to provide an alternative
implementation for it.
If we're going to generate our own ID and set it ourselves on the model,
one requirement would be that the generated ID is in fact unique. If it
wouldn't be, the repository couldn't do its job. It would fail regularly
because it would try to store a record with an ID that has already been used.
A common solution to overcome this problem is to use a UUID - a
Universally Unique Identifier, which look like this when represented as a
string: 1eaf9e97-a263-4c08-940b-289aed6f805f. Such an ID is
generated based on random input, as well as the current time. Its claim is
universal uniqueness. Although it can't be guaranteed, the chance that an
identical ID is already used somewhere is so small that effectively it never
happens.
Let's switch back to the model and fix the ID generation issue there, before
trying the alternative JSON-based implementation again.
We have to override some properties: one that tells Eloquent not to
configure the id column as an auto-incrementing integer. Another property

that requests the id column (the "key") to be defined as a string-type
column:
/**
 * @property string $id
 * @property string $topic
 * @property DateTimeImmutable $time
 */
final class Meetup extends Model
{
    public $timestamps = false;
    public $incrementing = false;
    protected $keyType = 'string';
If we now try to save a Meetup object through the repository, we get a
database-level error:
Integrity constraint violation: 19 NOT NULL constraint failed:
meetups.id
The id column is still a primary key, and it can't be null. We're ready to
start providing our own IDs now. The next step is to install the ramsey/uuid
library. We can use its UuidFactory service to generate a UUID for us, and
we then set it as the id property:
$repository = new MeetupRepositoryUsingEloquent();
$uuidFactory = new UuidFactory();
/*
 * - `$repository` should be injected as a service of type
 * `MeetupRepository`
 * - `$uuidFactory` should be injected as a service of type
 * `UuidFactoryInterface`
 */
$meetup = new Meetup();
$meetup->id = $uuidFactory->uuid4()
    ->toString();
$meetup->topic = 'Eloquent Tips & Tricks';
$meetup->time = new DateTimeImmutable('2022-03-04 20:00');
$repository->save($meetup);
$fromDb = $repository->getById($meetup->id);

Finally, the $id parameter of the repository's getById() method should be
changed to a string type; it's no longer an auto-incrementing ID:
<?php
declare(strict_types=1);
namespace App\Models;
interface MeetupRepository
{
    public function save(Meetup $meetup): void;
    public function getById(string $id): Meetup;
}
Everything works again. The result is a better repository abstraction
because we don't implicitly rely on a specific database for our ID
generation needs. Another repository implementation won't need to
generate an ID, nor set it magically on the model.
There's one last thing I always do: move the responsibility of generating
IDs to the repository itself, so clients of Meetup don't have to worry about
creating the ID in the right way. The first step is to define a method
nextIdentity() on the repository interface:
interface MeetupRepository
{
    // ...
    public function nextIdentity(): string;
}
Then move the existing call to UuidFactory to the implementation of this
new method:
use Ramsey\Uuid\UuidFactoryInterface;
final class MeetupRepositoryUsingEloquent implements MeetupRepository
{
    public function __construct(
        private readonly UuidFactoryInterface $uuidFactory
    ) {
    }
    // ...

    public function nextIdentity(): string
    {
        return $this->uuidFactory->uuid4()
            ->toString();
    }
}
Client code should now use the repository to generate an ID:
$uuidFactory = new UuidFactory();
$repository = new MeetupRepositoryUsingEloquent($uuidFactory);
/*
 * `$repository` should be injected as a service of type
 * `MeetupRepository`
 */
$meetup = new Meetup();
$meetup->id = $repository->nextIdentity();
Note that besides making it easier for clients to retrieve an ID, it's also a
gret way of decoupling from the ramsey/uuid package!
A common practice for application-generated IDs is to wrap them in value
objects. Instead of returning and assigning string IDs you'd be passing
MeetupId instances.
PHPStan Rule: Disallow Auto-incrementing Model IDs
We can create a PHPStan rule that analyzes model classes and looks for the
$incrementing property. If it doesn't exist, or if its value is not false, then
the rule should trigger an error. Since the property may not be defined, we
can't just look for a ClassProperty node with the name incrementing. We
can use PHPStan's virtual node ClassPropertiesNode instead, which
conveniently collects all the properties of a class. We can foreach over
them and look for the one that's called incrementing. When we find such a
property, we can ask the Scope to resolve the type of the default value that
the class provides for this property. This is supposed to be an instance of
ConstantBooleanType, which means it's explicitly set to true or false.

Only when the property is undefined, or when its default value is set to
true, should this rule trigger an error:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use Illuminate\Database\Eloquent\Model;
use PhpParser\Node;
use PHPStan\Analyser\Scope;
use PHPStan\Node\ClassPropertiesNode;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\Constant\ConstantBooleanType;
use PHPStan\Type\Type;
final class AutoIncrementingModelIdRule implements Rule
{
    public function getNodeType(): string
    {
        return ClassPropertiesNode::class;
    }
    /**
     * @param ClassPropertiesNode $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if (! $scope->isInClass()) {
            // Should not happen
            return [];
        }
        if (! in_array(
            Model::class,
            $scope->getClassReflection()
                ->getParentClassesNames(),
            true
        )) {
            // This class does not extend `Model`
            return [];
        }
        $type = $this->defaultValueTypeOfIncrementingProperty(
            $node,
            $scope
        );
        if (! $type instanceof ConstantBooleanType) {
            /*
             * The default value of `$incrementing` is not
             * recognized as a boolean, we can't analyze it
             */

            return [];
        }
        if ($type->getValue() === false) {
            /*
             * Indeed, we want the default value of `$incrementing`
             * to be `false`
             */
            return [];
        }
        return [
            RuleErrorBuilder::message(
                'This model has an auto-incrementing ID'
            )->build(),
        ];
    }
    private function defaultValueTypeOfIncrementingProperty(
        ClassPropertiesNode $node,
        Scope $scope
    ): Type {
        foreach ($node->getProperties() as $property) {
            if ($property->getName() !== 'incrementing') {
                continue;
            }
            return $scope->getType($property->getDefault());
        }
        /*
         * The default value inherited from the `Model` parent
         * class is supposed to be true
         */
        return new ConstantBooleanType(true);
    }
}
Defining Our Own Object API
We introduced a repository to take over some service responsibilities of the
model (saving, finding). If we want to decouple from Model, there are many
more service-style functions that we should no longer call on the model
itself, but always via a repository. For this purpose we may further adapt
our PHPStan rule set to verify that we don't call them outside a repository
class.
Even if we no longer use the Model for its service capabilities, there are
several other methods on Model which are used by clients of Meetup, which

leaves them coupled to the Model class itself, and therefore the ORM. One
of those methods is create(). With this method you can create a new
Meetup instance. You can populate its attributes directly by passing an array
of keys and values to it. In order to decouple form Model we should define
our own factory method for this, which will be available for clients that
want to "create" a meetup, regardless if we use Eloquent or any other ORM.
Note that we did the same thing in the previous chapter, but for different
reasons. There we wanted to get rid of array-based, shapeless data being
passed from request to model. We also wanted to be able to throw an
exception in case invalid data was provided. Here, we want to stop using
create() because it's a method provided by the ORM, and we want to
decouple from that.
We replace the create() method with our own named constructor which
explicitly declares the values that you need to provide when you create a
Meetup, instead of allowing an unspecified map of attributes to be mass-
assigned. We take this opportunity to define our own, domain-specific
alternative for "create" - "schedule":
/**
 * @property string $id
 * @property string $topic
 * @property DateTimeImmutable $time
 */
final class Meetup extends Model
{
    public $timestamps = false;
    public $incrementing = false;
    protected $keyType = 'string';
    protected $casts = [
        'time' => 'immutable_datetime',
    ];
    protected $fillable = ['id', 'topic', 'time'];
    public static function schedule(
        string $id,
        string $topic,
        DateTimeImmutable $time
    ): self {
        return self::create(
            [
                'id' => $id,

                'topic' => $topic,
                'time' => $time,
            ]
        );
    }
    public function id(): string
    {
        return $this->id;
    }
    // ...
}
Inside the schedule() method, we're free to use the create() method. In
essence, methods like Model::create() are going to be treated as private
methods now.
We'll give the same treatment to the magic attribute modifiers. Attributes
are an Eloquent-specific implementation detail. They replace the standard
way of storing state in objects. Instead of allowing actual properties to be
populated with data, when we assign or fetch properties from a model
instance we implicitly call the Model's __get() and __set() methods. As
soon as we'd remove extends Model, we'd lose this part of the Meetup
object's "API". We can fix this issue by explicitly defining public methods
on Meetup for everything a client wants to change. Instead of directly
manipulating attributes through magic getters and setters, every change has
to go through one of those methods.
Earlier we made the create() method effectively private by only allowing
it to be called inside a model class, now we also make the attributes-related
behavior of the model private. How the model tracks its state, which
variables it uses, and what types they are, is now hidden from the client of
the class. This is traditionally known as "data hiding": we explicitly define
a "public" API for clients of Meetup, and keep the implementation details
including the internal data structures private.
Just as we did before, we can make our own PHPStan rule that flags
"public" usage of attributes as an error. This rule analyzes so-called
PropertyFetch nodes, which are also used for property assignments.

Whenever a Model property is accessed, the rule verifies that it's accessed
inside the class that actually owns the property.
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use Illuminate\Database\Eloquent\Model;
use PhpParser\Node;
use PhpParser\Node\Expr\PropertyFetch;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;
final class EloquentModelAttributesRule implements Rule
{
    public function getNodeType(): string
    {
        return PropertyFetch::class;
    }
    /**
     * @param PropertyFetch $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        $isPropertyFetchOnModel = (new ObjectType(Model::class))
            ->isSuperTypeOf($scope->getType($node->var));
        if ($isPropertyFetchOnModel->no()) {
            /*
             * The object from which the property is fetched
             * is not a `Model`
             */
            return [];
        }
        if ($scope->isInClass()
            && $scope->getClassReflection() !== null
            && (new ObjectType($scope->getClassReflection()->getName()))
                ->isSuperTypeOf($scope->getType($node->var))
                ->yes()
        ) {
            /*
             * We're currently inside a class that is a super-type of
             * the object from which the property is fetched
             */
            return [];
        }
        return [
            RuleErrorBuilder::message(

                'Accessing attributes is not allowed outside a Model'
            )->build(),
        ];
    }
}
We'll only allow state changes to the model to happen through our own
explicitly declared methods. This is great because it gives us the
opportunity to define pre-conditions for the state change. Inside the method
we can look at the current state of the object and prevent changes by
throwing an exception (e.g. if the proposed meetup date is in the past). We
can also inspect the arguments provided to the method and prevent invalid
values from being stored as attributes (e.g. the meetup's name should be a
non-empty string).
Custom Mapping Code
We have successfully decoupled from the Model class by not using its
service-style functions anymore, and by encapsulating the whole attribute
business inside the model. As a client of Meetup you will work with an
explicit API which doesn't allow everything to happen to it. It declares what
types of values need to be passed to it, and what can be changed. It also
prevents invalid state changes from happening, so it becomes a very reliable
object. The Meetup class keeps its ORM or database-specific things inside,
they generally don't leak to the client.
We are not fully decoupled from the ORM though; we are less tightly, or
maybe even loosely coupled to it. If we ever want to switch to a different
ORM, most of the work will be to:
Write mapping configuration in the style of the new ORM. E.g. we
might have to add annotations or attributes, or create a Yaml file, etc.
Convert magic properties to actual properties, and replace a call to
Model::create() with property assignments, and so on.
Provide another repository implementation that uses the new ORM
instead of Model::save().

At least the required changes will need to happen in the repository
implementation, not in the interface, and in the private parts of the model
class. The API of both the repository and the model won't change, so clients
of the repository and the model won't have to be changed either. Great! It's
still quite a lot of work that needs to be done, and it's work that could have
been prevented by not investing in a particular ORM in the first place. We
could do the mapping work ourselves.
Let's make the trade-off more clear: relying on an ORM to map our objects
to the database will generally save us time. But sometimes it also costs a lot
of time: indeed, when we want to migrate, but also when things don't work
as expected. Personally, I've spent many hours debugging problems related
to mapping. I've also discovered mapping issues too late, when code was
already deployed to production.
What the ORM does in terms of mapping happens behind a curtain, and it
happens in a dynamic way, mostly based on configuration, sometimes even
"persistence event listeners" are allowed to do part of the work. We can
read the documentation and learn how to influence the mapping process by
overriding properties, adding annotations, defining type "casters",
registering our "type" classes, etc. In the end, we just hope that we did the
right thing. If we want to debug what happens during the actual mapping
process, it will take a lot of debugging steps before we learn anything, if we
are even able to pinpoint the issue at all. It's also impossible to get early
warnings because the mapping code is beyond the reach of static analysis
tools.
Writing your own mapping code is the solution to all these issues. It makes
it very explicit which column values go into which fields, what their
expected types are, what should happen in the case of null values, and so
on. This is great for static analysis, because we can get early warnings about
accidental or invalid type coercion, potentially undefined keys, etc. We very
clearly see how shapeless arrays become rich domain objects, but also how
they get converted back to database records. All of this happens in our own
code, which can be modified just like any code in an IDE. It can be
discovered and analysed by PHPStan, and refactored by your IDE, and
automated refactoring tools like Rector. And the biggest benefit is: you can

ditch the ORM completely. You only need the database abstraction layer
behind it, that is, Eloquent Database's low-level connection facilities, or
Doctrine DBAL.
Mapping needs to go in two directions: from the database to the model, and
from the model to the database. So we need to methods: one static method
for creating the instance based on a database record, and one object method
for returning a database record.
/**
 * @property string $id
 * @property string $topic
 * @property DateTimeImmutable $time
 */
final class Meetup extends Model
{
    // ...
    public static function fromDatabaseRecord(array $record): self
    {
        $meetup = new self();
        $meetup->id = $record['id'];
        $meetup->topic = $record['topic'];
        $meetup->time = DateTimeImmutable::createFromFormat(
            'Y-m-d H:i',
            $record['time']
        );
        return $meetup;
    }
    public function toDatabaseRecord(): array
    {
        return [
            'id' => $this->id,
            'topic' => $this->topic,
            'time' => $this->time->format('Y-m-d H:i'),
        ];
    }
    // ...
}
If we want, we can write a test that shows that the output of calling
toDatabaseRecord() on a model instance can be fed back into
fromDatabaseRecord() and the resulting model instance will be equal to

the original one. I've used such a test to prove that the model can deal with
the sometimes "surprising" values that are in the database.
public function testFromAndToDatabaseRecord(): void
{
    $originalMeetup = Meetup::schedule(
        $this->uuidFactory->uuid4()
            ->toString(),
        'Eloquent Tips & Tricks',
        new DateTimeImmutable('2022-03-04 20:00')
    );
    self::assertEquals(
        $originalMeetup,
        Meetup::fromDatabaseRecord(
            $originalMeetup->toDatabaseRecord()
        )
    );
}
We still have to rewrite the repository class to use these new methods
instead of save() and find(). It's not the complete solution, but this works
for now:
<?php
declare(strict_types=1);
namespace App\Models;
use Illuminate\Database\ConnectionInterface;
use RuntimeException;
final class MeetupRepositoryUsingConnection implements MeetupRepository
{
    public function __construct(
        private ConnectionInterface $connection
    ) {
    }
    public function save(Meetup $meetup): void
    {
        $record = $meetup->toDatabaseRecord();
        /*
         * This code is copied from Doctrine DBAL's
         * `Connection::insert()` method:
         */
        $columns = [];
        $values = [];
        $bindings = [];
        foreach ($record as $column => $value) {

            $columns[] = $column;
            $values[] = '?';
            $bindings[] = $value;
        }
        $this->connection->insert(
            sprintf(
                'INSERT INTO meetups (%s) VALUES (%s)',
                implode(', ', $columns),
                implode(', ', $values)
            ),
            $bindings
        );
    }
    public function getById(string $id): Meetup
    {
        $record = $this->connection->selectOne(
            'SELECT * FROM meetups WHERE id = ?',
            [$id]
        );
        if ($record === null) {
            throw new RuntimeException('...');
        }
        return Meetup::fromDatabaseRecord((array) $record);
    }
}
Since we have our own mapping methods now, we can remove all the
ORM-specific properties and even the entire parent Model class. We can
finally use properly typed object properties and remove the @property
annotations. This makes things a lot simpler: we can see all the properties
(formerly, attributes) that the model has, and since there is no backdoor for
the ORM, we control all the possible states of the object. This is very
helpful when debugging mapping issues.
final class Meetup
{
    private string $id;
    private string $topic;
    private DateTimeImmutable $time;
    // ...
}
In my experience the most common surprises are:

A nullable database column that results in a null value being assigned
to a non-optional property.
The record didn't contain one of the expected keys (we made a typo, or
we didn't add the column to the SELECT statement)
We have a type mismatch; e.g. we try to assign a string to an object-
type property.
The first step is to be honest about what array $record looks like. It's
actually a map of string keys to string or null values. We then add
assertions to declare our assumptions. I prefer installing an assertion library
like beberlei/assert, as well as its accompanying PHPStan extension
phpstan/phpstan-beberlei-assert to help with that.
use Assert\Assertion;
final class Meetup
{
    // ...
    public static function fromDatabaseRecord(array $record): self
    {
        $meetup = new self();
        Assertion::keyExists($record, 'id');
        Assertion::string($record['id']);
        Assertion::keyExists($record, 'topic');
        Assertion::string($record['topic']);
        Assertion::keyExists($record, 'time');
        Assertion::string($record['time']);
        $meetup->id = $record['id'];
        $meetup->topic = $record['topic'];
        $meetup->time = DateTimeImmutable::createFromFormat(
            'Y-m-d H:i',
            $record['time']
        );
        return $meetup;
    }
    // ...
}

This clutters the code quite a bit, so I like to introduce a set of helper
functions for this, which ease the transition from a rather anonymous array
to specifically typed values:
<?php
declare(strict_types=1);
namespace App\Models;
use Assert\Assertion;
final class Mapping
{
    public static function getString(array $data, string $key): string
    {
        Assertion::keyExists($data, $key);
        Assertion::string($data[$key]);
        return $data[$key];
    }
}
It'll be easy to add other mapping methods that act in a similar way to
extract string|null, int, int|null, etc.
Now that we have Mapping::getString() we can simplify
fromDatabaseRecord() a lot:
final class Meetup
{
    // ...
    public static function fromDatabaseRecord(array $record): self
    {
        $meetup = new self();
        $meetup->id = Mapping::getString($record, 'id');
        $meetup->topic = Mapping::getString($record, 'topic');
        $meetup->time = DateTimeImmutable::createFromFormat(
            'Y-m-d H:i',
            Mapping::getString($record, 'time')
        );
        return $meetup;
    }
    // ...
}

The result of this fairly minimal effort is that we are now in full control of
the mapping between database record and object. We no longer need an
ORM, we can just use the underlying database connection abstraction, and
possibly introduce our own wrapper which offers convenient methods for
inserting, updating, and deleting (like for instance Doctrine DBAL's
Connection class already offers).
PHPStan Rule: Only Allow Calls to
fromDatabaseRecord() from Repository Classes
It might be useful to mark methods as fromDatabaseRecord() and
toDatabaseRecord() as methods that are "internal" to the repositories that
call them. They have to be public methods because the repository class
needs to call them, but they are a different kind of public methods. They
are not like the other public methods which are there to be invoked by
services that want to change their state, i.e. the methods that make up the
object's API. We could mark these methods as "internal" by adding an
@internal annotation to them. But anybody could still call these methods
anywhere, so we might be better off preventing usage of these methods in
classes that did not gain the explicit right to do so.
Taking inspiration from other programming languages, we may call a class
that is allowed to call certain internal methods on another class a "friend" of
such a class. Since this friendship may apply to other classes, not just
repositories and their model classes, we could write a generic PHPStan
"friend" rule that verifies that the caller is a friend of the class that contains
the called method. We only need a way to describe the relationship. We
could create a PHPStan rule that has these relationships configured as
constructor arguments, but taking inspiration from the PHP Language
Extensionspackage, we may also use a relatively new PHP feature called
attributesto establish class friendships.
This is the syntax for declaring a friendship between classes; the
ClassWithFriendAttribute declares that internalMethod() may only be
called by a class called ATrueFriend:
<?php

declare(strict_types=1);
namespace Utils\PHPStan\Tests\FriendRule\Fixtures;
use Utils\PHPStan\FriendOf;
final class ClassWithFriendAttribute
{
    #[FriendOf(ATrueFriend::class)]
    public function internalMethod(): array
    {
        return [
            // ...
        ];
    }
}
The #[FriendOf] attribute refers to a class that we have created ourselves:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use Attribute;
#[Attribute]
final class FriendOf
{
    /**
     * @param class-string $friendClass
     */
    public function __construct(
        public readonly string $friendClass
    ) {
    }
}
In the FriendRule itself we can use class reflection to reflect on the called
method. If we can't find any FriendOf attributes, the called method has no
restrictions so calling it should be fine. However, if the called method has
some FriendOf attributes, we want the class from which the call is made to
match one of the configured friend classes:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;

use PhpParser\Node;
use PhpParser\Node\Expr\MethodCall;
use PhpParser\Node\Identifier;
use PHPStan\Analyser\Scope;
use PHPStan\Reflection\ReflectionProvider;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;
use ReflectionException;
final class FriendRule implements Rule
{
    public function __construct(private readonly ReflectionProvider
$reflectionProvider)
    {
    }
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if (! $node->name instanceof Identifier) {
            // Dynamic method call, we can't analyze it
            return [];
        }
        $objectType = $scope->getType($node->var);
        if (! $objectType instanceof ObjectType) {
            /*
             * We can't find out what type of object this method is
             * called on
             */
            return [];
        }
        try {
            $methodReflection = $this->reflectionProvider
                ->getClass($objectType->getClassName())
                ->getNativeReflection()
                ->getMethod($node->name->toString());
        } catch (ReflectionException) {
            // Could not find the actual method in the code, nothing to
analyze
            return [];
        }
        $friendOfAttributes = $methodReflection->getAttributes(
            FriendOf::class
        );
        if ($friendOfAttributes === []) {

            /*
             * The method has no `#[FriendOf]` attributes, so it's
             * okay to call this method
             */
            return [];
        }
        $thisClassType = new ObjectType(
            $scope->getClassReflection()
                ->getName()
        );
        foreach ($friendOfAttributes as $attribute) {
            /** @var FriendOf $instance */
            $instance = $attribute->newInstance();
            $friendClassType = (new ObjectType($instance->friendClass));
            if ($friendClassType->isSuperTypeOf(
                $thisClassType
            )->yes()) {
                return [];
            }
        }
        return [
            RuleErrorBuilder::message(
                sprintf(
                    'Method call %s::%s() is only allowed inside friend
classes',
                    $objectType->getClassName(),
                    $methodReflection->getName()
                )
            )->build(),
        ];
    }
}
We can now use this generic rule to configure toDatabaseRecord() as a
method that may only be called from the relevant repository class. In order
to use the same approach for fromDatabaseRecord() we need to create a
second rule which subscribes to StaticCall nodes, since that method is a
static method. We may also want a similar rule for object instantiations.
All these scenarios are already covered by the aforementioned PHP
Language Extension package, so it doesn't make sense to reinvent them
here. Still, it's nice to see that we can make such powerful rules, without too
many ingredients.

No Magic Persistence of Related Objects
A single object can be mapped to a database record if it only has "flat"
properties containing primitive-type values, like strings, and integers, or
objects that can be reduced to such values, like DateTimeImmutable and our
custom value objects. But the mapping situation isn't always as simple as
this. We often want to store collections of other objects as well. E.g. a blog
post has a collection of comments, a meetup has a list of attendees. These
relations also need to be persisted. Another common type of object that
needs to be persisted is a related model, like the User model that is the
organizer of the Meetup.
ORMs try to remove the burden of persisting related objects by analyzing
the relationships and looking for data that has changed. It's even possible to
persist new objects in a cascading fashion by persisting the parent object.
This results in an endlessly traversable object graph. E.g. from a BlogPost
to its Comments, to the associated User objects, to all the Comments they have
ever posted, and so on. A change in any of the related objects will be
persisted when the original object gets persisted.
One, somewhat philosophical issue with automatic persistence of related
objects is that it only works when all those objects are in the same database,
in fact, when all those objects are in the same relational database. Imagine
we have the blog posts in one database, and the comments in another, or
that we want to outsource the management of the comments to some
external service that exposes them through a web API. In that case, we
could no longer add comments through the BlogPost model. And what
would happen if we want to store our data in JSON files on disk? We have
to make a cut somewhere: do comments go into their own files, or are they
stored inside the same .json file as their "parent" blog posts? In my
opinion, although automatic persistence of related objects is a given in
some ORMs, it's not something we need to preserve in our decoupling
efforts, because of these conceptual issues. We could just as easily decide:
you can change a blog post, but when you save it, it won't save any
modified comments.

Practically, the problem is that the magical auto-persisting behavior is
impossible to replicate when you use the manual mapping approach. If
we'd try to do that, we would eventually build our own ORM. To avoid this
undesirable result, we should make cuts in the endlessly traversable object
graph. We should put clear boundaries around what can be changed and will
be saved in one step, or one database transaction. In the end, this leads to a
better domain model, because every action we do in our application is one
that explicitly targets one domain object and doesn't try to do more than
one thing in a single step. Limiting each change to one object even solves
random deadlocks that some applications suffer from. It also limits the
chances of concurrent, conflicting updates, a risk that many applications
take, but not many developers worry about.
Using Aggregate Design Rules
It goes beyond the scope of this book to discuss the details, but the
approach of limiting the changes in one transaction to changes in a single
model object is called: applying the Aggregate pattern. You can find more
about this in the Domain-Driven Design books by Eric Evans and Vaughn
Vernon, and there's a nice series of articles on aggregate designby the latter.
These are the main rules for aggregate design:
1. Keep your aggregates small
2. Reference other aggregates by their ID
This means that you can keep model objects inside other model objects (e.g.
BlogPost can keep a collection of Comment objects), but it's often preferred
to make them separate "aggregates" (e.g. BlogPost is just the post, it
doesn't hold Comment objects). When you want to make a relation between
model objects, you don't keep a reference to the full object, but only to its
ID (e.g. Comment only has a reference to the ID of the BlogPost it belongs
to, not the full BlogPost object).
For the next example we switch from Laravel Eloquent to Doctrine ORM,
since it is a good example of an ORM that offers a traversable object graph
and establishes relations by passing entire objects to between models. The

example is about a BlogPost entity (the equivalent of an Eloquent model).
We can add comments to a BlogPost by accessing a collection of related
Comment objects and adding an element to it.
This is the BlogPost class:
use Doctrine\Common\Collections\ArrayCollection;
use Doctrine\Common\Collections\Collection;
use Doctrine\ORM\Mapping as ORM;
/**
 * @ORM\Entity
 */
class BlogPost
{
    /**
     * @ORM\Id()
     * @ORM\GeneratedValue()
     * @ORM\Column(type="integer")
     */
    private int $id;
    /**
     * @ORM\Column(type="string")
     */
    private string $title;
    /**
     * @ORM\OneToMany(targetEntity="Comment", mappedBy="blogPost",
cascade={"persist"})
     * @var Collection<int, Comment>
     */
    private Collection $comments;
    // ...
    public function addComment(Comment $comment): void
    {
        $comment->setBlogPost($this);
        $this->comments->add($comment);
    }
}
And this is the Comment class:
/**
 * @ORM\Entity
 */
class Comment
{
    // ...

    /**
     * @ORM\ManyToOne(targetEntity="BlogPost")
     * @ORM\JoinColumn(name="blogPostId", nullable=false)
     */
    private BlogPost $blogPost;
    public function __construct()
    {
    }
    public function setBlogPost(BlogPost $blogPost): void
    {
        $this->blogPost = $blogPost;
    }
    // ...
}
Skipping most of the fields and methods in these classes, we can focus only
on the part that's needed to establish a relationship between the two, e.g. the
OneToMany annotations and the setBlogPost method.
This is how it's used:
// $em is a Doctrine `EntityManager` instance
$comment = new Comment();
$comment->setMessage('This is over-engineering!');
$blogPost->addComment($comment);
// This will also save the new `Comment`
$em->flush();
The first step is to apply what we've done earlier in this chapter: moving
the EntityManager's activities behind the scenes, in a new class called
BlogRepositoryUsingDoctrineOrm which has its own interface to indicate
that we're jumping to an external dependency (the database):
<?php
declare(strict_types=1);
namespace App\AppBundle\Repository;
use App\AppBundle\Entity\BlogPost;
use Doctrine\Persistence\ManagerRegistry;
use RuntimeException;

final class BlogPostRepositoryUsingDoctrineOrm implements
BlogPostRepository
{
    public function __construct(
        private ManagerRegistry $doctrine
    ) {
    }
    public function save(BlogPost $blogPost): void
    {
        $em = $this->doctrine->getManager();
        $em->persist($blogPost);
        $em->flush();
    }
    public function getById(int $id): BlogPost
    {
        $em = $this->doctrine->getManager();
        return $em->find(BlogPost::class, $id)
            ?? throw new RuntimeException('Could not find BlogPost');
    }
}
This is how the repository is used:
// `$repository` is an instance of `BlogPostRepository`
$comment = new Comment();
$comment->setMessage('This is over-engineering!');
$blogPost->addComment($comment);
// This will also save the new `Comment`
$repository->save($blogPost);
When we no longer want to use BlogPost to add and save new comments,
we can make Comment an aggregate. Each aggregate gets its own repository
interface and class, so we can retrieve and save it separately from other
aggregates.
// We create the `Comment` as a stand-alone object
$comment = new Comment();
$comment->setMessage('This is over-engineering!');
// We still need a `BlogPost` instance to establish the relation
$blogPost = $blogPostRepository->getById(1);
$comment->setBlogPost($blogPost);
// `$commentRepository` is an instance of `CommentRepository`

// We save the `$comment` to its own repository:
$commentRepository->save($comment);
Note that we no longer use BlogPost::addComment() but we create a
Comment object in a stand-alone way. To ensure that we establish a correct
relation, we still fetch the BlogPost first, then pass it to
Comment::setBlogPost(). If a BlogPost with the given ID (1 in this case)
doesn't exist, we shouldn't be able to add comments to it, so it's always a
smart thing to check if the referenced aggregate actually exists. However, to
make the aggregate boundaries really clear, we shouldn't pass the entire
BlogPost object to Comment. Comment has no business with that object. If
we pass BlogPost to Comment it might even change the BlogPost and
because we still use EntityManager::flush(), those changes would be
automatically persisted too. This is why we have the aggregate design rule
to reference other aggregates only by their ID.
To make it clear in our code that we only need the BlogPost entity to
establish that the relation is legit, we should fetch it, but not pass it to
Comment. Comment technically should only need the ID of the BlogPost to
store it in the corresponding foreign key column in the comments table. With
Doctrine ORM, we can make this work as follows: we stop maintaining the
one-to-many relationship on both sides, and from now on just keep a join
column, manually defined by ourselves:
/**
 * @ORM\Entity
 */
class Comment
{
    // ...
    /**
     * @ORM\Column(type="integer")
     */
    private int $blogPostId;
    public function __construct()
    {
    }
    public function setBlogPostId(int $blogPostId): void
    {
        $this->blogPostId = $blogPostId;
    }

    // ...
}
This means we no longer have the magic lazy-loading capabilities for the
comments relation in BlogPost, but that actually makes sense because we
didn't want to jump aggregate boundaries anyway. The relation may be
needed again when presenting data in the view layer, but that's something
for the next section about view models.
When creating a comment, we now call the new setBlogPostId():
// We still need a `BlogPost` instance
$blogPost = $blogPostRepository->getById(1);
// Now add the comment, we pass that
$comment = new Comment();
$comment->setMessage('This is over-engineering!');
$comment->setBlogPostId($blogPost->getId());
// `$commentRepository` is an instance of `CommentRepository`
// We save the `$comment` to its own repository:
$commentRepository->save($comment);
We can improve the code a lot by introducing a proper constructor, which
explicitly declares the required values for creating a new Comment:
/**
 * @ORM\Entity
 */
class Comment
{
    // ...
    /**
     * @ORM\Column(type="integer")
     */
    private int $blogPostId;
    public function __construct(int $blogPostId, string $message)
    {
        $this->blogPostId = $blogPostId;
        $this->message = $message;
    }
    // ...
}

Limiting Changes to One Entity
As long as we still use the flush() method of the EntityManager, we may
be accidentally saving changes to other entities than the one we've passed
to the repository. This is an example of how this problem may arise:
$comment = new Comment(
    $blogPost->getId(),
    'This is over-engineering!'
);
// We "maliciously" change `$blogPost` too
$blogPost->setTitle('The new title');
/*
 * The change to `$blogPost` will be persisted here,
 * since inside the `save()` method we call `flush()`
 */
$commentRepository->save($comment);
If we really want to prevent this kind of issue, we could go the extra mile
and "detach" any entity that is still loaded and managed by Doctrine from
its UnitOfWork:
use Doctrine\ORM\EntityManager;
final class CommentRepositoryUsingDoctrineOrm implements
CommentRepository
{
    // ...
    public function save(Comment $comment): void
    {
        /** @var EntityManager $em */
        $em = $this->doctrine->getManager();
        $identityMap = $em->getUnitOfWork()
            ->getIdentityMap();
        foreach ($identityMap as $class => $entities) {
            if ($class !== Comment::class) {
                foreach ($entities as $entity) {
                    if ($entity !== null) {
                        $em->detach($entity);
                    }
                }
            }
        }
        $em->persist($comment);
        $em->flush();

    }
    // ...
}
Having separated BlogPost from Comment, they have become much
"flatter". It's much easier to provide manual mapping for them, in a similar
fashion as we did earlier for the Meetup Eloquent model.
The point of doing the mapping manually, and to design smaller aggregates,
is to show that you don't actually need an ORM for persisting objects. It's
quite easy to do a bit more work yourself, which as a bonus helps you get
rid of a lot of magic things in your domain model. In the end, these domain
objects can be created as simple PHP classes which don't have any special
parent classes, traits, annotations, lazy-loading collections for relations, etc.
They just carry some state and offer methods for safely manipulating that
state. This to me feels like reclaiming some freedom in an important part of
the application, the one where you try to model your business domain in a
useful and meaningful way.
Introducing View Models
So far we've looked at decoupling from the ORM from the perspective of
changing data: creating a model object, changing it, saving it. In the
previous section we've replaced the ORM by implementing the mapping to
and from the database ourselves. As a result we end up with objects that
align very well with the Domain-Driven Design notion of aggregates, that
guard their own consistency. By focusing on making small aggregates that
are related by ID only, we end up with something that's considered by many
a better domain model, but... this model isn't particularly suitable for
presentation purposes. Since the relations can't be loaded on-demand, we'd
have to fetch a lot of different aggregates for an average view, and also add
lots of getters to them. Using an aggregate for presentation purposes would
put a lot of strain on its design and lead to performance issues because of all
the additional database queries.
We should be careful not to follow a circular argument here. This new issue
only arise because we have been wanting to decouple from the ORM on the

write side of the model. We tried to skip all the magic involved in saving
objects as database records and write out everything explicitly, so we
wouldn't rely too heavily on the specific features of a particular ORM. Now
we have created a new problem for ourselves. Presenting the data from the
write model becomes harder, or even impossible.
I think it would be refreshing to look at this issue from a different
perspective, namely from the view itself. We already discussed decoupling
from template renderers in the chapter about Web frameworks. There we
decided to keep things simple inside the template, not to do any "work"
there, and to pass all the data that's needed instead of expecting the
template to fetch more through services.
If we pass an entity to the view, one that is managed by the ORM, we
wouldn't exactly follow this rule; we wouldn't pass all the data that the
view needs. The view could indeed call some getters on the entity to get
more data, but that would trigger additional queries to load the data for us.
This gives the entity service responsibilities, which confuses its role as an
object. It also regularly causes performance issues because of all the
accidental extra queries. Sometimes we overcome this issue by defining
some relations as eager-loading. But this is certainly framework magic: it's
implicit and also too generic. Eager-loading doesn't consider the context; it
will load the additional data also in situations where it's not needed.
So decoupling a view model from the ORM means we should no longer
rely on related objects to be loaded for us when calling getters. But there's
another aspect to decoupling that needs to be tackled. The assumption of a
view model that is directly retrieved from the ORM itself is that all of its
data can be found in the same database. This assumption is often correct,
but eventually it may no longer be. Teams that want to split a large code
base into smaller parts realize this. The fact that everybody has access to a
single Shared database complicates things a lot, since data is going to be
moved to different applications, running on different hosts. The first step is
always to introduce an abstraction for each query: what do we need here?
The next question is: how do we get it? This gives you the option to get the
data from an API instead, or a search engine, or even to build up a local
projection of remote data based on events.

Revisiting one of our previous examples, let's consider the BlogPost with
its Comments the way it was before we rearranged the aggregate boundaries
and started doing our own mapping. If we were to present a blog post to the
user, including its comments, we'd load the BlogPost entity and pass it to
the view. As we discussed before, it may not be smart to pass an entity to
the view, since it would gain access to its state-changing methods, which
could lead to all kinds of issues. But the more relevant issue in this section
is that loading the comments, and the user who posted it, will trigger
additional database queries.
Here is BlogPost again, showing in particular how it's related to Comment:
/**
 * @ORM\Entity
 */
class BlogPost
{
    /**
     * @ORM\Id()
     * @ORM\GeneratedValue()
     * @ORM\Column(type="integer")
     */
    private int $id;
    /**
     * @ORM\Column(type="string")
     */
    private string $title;
    /**
     * @ORM\OneToMany(targetEntity="Comment", mappedBy="blogPost",
cascade={"persist"})
     * @var Collection<int, Comment>
     */
    private Collection $comments;
    // ...
}
The Comment entity now has an additional relation to User; the author of the
comment.
/**
 * @ORM\Entity
 */
class Comment
{
    // ...

    /**
     * @ORM\ManyToOne(targetEntity="BlogPost")
     * @ORM\JoinColumn(name="blogPostId", nullable=false)
     */
    private BlogPost $blogPost;
    /**
     * @ORM\ManyToOne(targetEntity="User")
     * @ORM\JoinColumn(name="userId", nullable=false)
     */
    private User $user;
    // ...
}
The BlogPostController passes a BlogPost instance to a Twig template,
which renders the blog post including its comments:
{% extends "base.html.twig" %}
{% block body %}
    <h1>{{ blogPost.title }}</h1>
    Lorem ipsum...
    <h2>Comments</h2>
    {% for comment in blogPost.comments %}
        <p>{{ comment.message }}</p>
        <p>By: {{ comment.user.name }}</p>
    {% endfor %}
{% endblock %}
We no longer want to pass an entity that relies on ORM magic to load more
data on-demand. Instead, since we already know what data the template
needs, we'll provide an object to it that has all the data the template needs,
presented to it in the shape that is most useful to it. For example, the
template doesn't need to have access to the entire User object; it only needs
the comment author's name. So before we replace the entity with a similar
object that's not an entity, we may first "flatten" the data a bit. In this case it
means that we add a method to Comment itself that returns the user's name:
/**
 * @ORM\Entity
 */
class Comment

{
    // ...
    /**
     * @ORM\ManyToOne(targetEntity="User")
     * @ORM\JoinColumn(name="userId", nullable=false)
     */
    private User $user;
    // ...
}
And we update the template accordingly:
{% extends "base.html.twig" %}
{% block body %}
    <h1>{{ blogPost.title }}</h1>
    Lorem ipsum...
    <h2>Comments</h2>
    {% for comment in blogPost.comments %}
        <p>{{ comment.message }}</p>
        <p>By: {{ comment.userName }}</p>
        {# comment.user.name was changed into comment.userName #}
    {% endfor %}
{% endblock %}
The next step is to replace the entity with another object that completely
matches the template's expectations: a drop-in replacement. Preferably we
distinguish it from the BlogPost entity by using a more descriptive name,
although you could also use a different namespace. This object is not going
to be an entity, it won't have Doctrine annotations. We're going to pass in
the data ourselves.
This is the view model class that replaces the BlogPost entity:
namespace App\AppBundle\ViewModel;
final class BlogPostWithComments
{
    /**
     * @param array<Comment> $comments
     */
    public function __construct(
        public readonly string $title,

        public readonly array $comments,
    ) {
    }
}
And this is the view model class that contains a comment and its author's
name:
namespace App\AppBundle\ViewModel;
final class Comment
{
    public function __construct(
        public readonly string $userName,
        public readonly string $message,
    ) {
    }
}
We've reduced the amount of code by using public readonly properties
instead of private properties with getters. This works because when Twig
parses an expression like comment.userName it falls back to reading the
value from the userName property if the getUserName() method doesn't
exist. Of course, if you're using a different templating engine you may have
to match the shape of the original entity more closely.
Now we need to introduce a repository interface where the client (the
controller in this case) can fetch the BlogPostWithComments from:
<?php
declare(strict_types=1);
namespace App\AppBundle\ViewModel;
interface BlogPostWithCommentsRepository
{
    public function getById(int $id): BlogPostWithComments;
}
Even if we already had a BlogPostRepository interface for saving and
retrieving BlogPost entities, for each view model we introduce a separate
repository interface. This gives us the guarantee that clients that want to
present data will never use the entity for doing so. Instead, they will fetch

dedicated view model objects. Also, we use an interface again to indicate
that the source of the data could be anything: a database, a search engine, an
API response, or a combination of those.
In our case we're using a database to store blog posts and comments, so for
the view model repository interface we provide an implementation that
populates the BlogPostWithComments object based on the data that comes
from the database:
namespace App\AppBundle\ViewModel;
use App\AppBundle\Mapping;
use Doctrine\DBAL\Connection;
use RuntimeException;
final class BlogPostWithCommentsUsingDbal implements
BlogPostWithCommentsRepository
{
    public function __construct(
        private Connection $connection
    ) {
    }
    public function getById(int $id): BlogPostWithComments
    {
        $records = $this->connection->fetchAllAssociative(
            <<<SQL
            SELECT bp.title, c.message, u.name as userName
            FROM BlogPost bp
            LEFT JOIN Comment c ON c.blogPostId = bp.id
            LEFT JOIN User u ON c.userId = u.id
            WHERE bp.id = :id
            SQL
,
            [
                'id' => $id,
            ]
        );
        if (count($records) === 0) {
            throw new RuntimeException('...');
        }
        $blogPostRecord = $records[0];
        return new BlogPostWithComments(
            Mapping::getString($blogPostRecord, 'title'),
            array_map(
                fn (array $record) => new Comment(
                    Mapping::getString($record, 'userName'),
                    Mapping::getString($record, 'message'),
                ),
                $records

            )
        );
    }
}
The controller uses this repository through its interface, and passes the
BlogPostWithComments object to the template render as is:
final class BlogPostController extends AbstractController
{
    public function __construct(
        private BlogPostWithCommentsRepository $repository,
        private Environment $twig,
    ) {
    }
    /**
     * @Route("/blog-post/{id}", name="homepage")
     */
    public function details(Request $request): Response
    {
        $blogPost = $this->repository->getById(
            $request->attributes->getInt('id')
        );
        return new Response(
            $this->twig->render(
                'blogPost.html.twig',
                [
                    'blogPost' => $blogPost,
                ]
            )
        );
    }
}
Because this object is a readonly object, with no hidden or magic behavior
we know that we pass to the template all the data it needs. And we have a
decoupled view model too: we can switch the underlying data store without
the need to update the clients of the view model (e.g. the controller and the
template).
It always surprises me how simple it is to create your own view model, by-
passing the ORM completely. It gives the view exactly what it needs. The
view is not able to load more data, accidentally, or on purpose, or otherwise
misuse the object passed to it. So besides decoupling from the ORM we've
also improved our object design. This is great for the maintainability of the

application in the long run: entities aren't used for all kinds of scenarios,
they are only used when changing data. View models are only used for
specific use cases, like showing a blog post including its comments. If that
use case is ever dropped, you can safely remove the related code as well.
Provide Read Models When the Framework
Needs Your Data
I consider a view model to be a special case of the more generic read
model. Read model is a term used in the context of CQRS
(Command/Query Responsibility Segregation). There's the write model, the
model that manages and guards the application's state, and there are
multiple read models that expose the application's state. Write and read
model can be the same, for instance if you have entities that also have
getters, but they aren't necessarily the same. For example, a write model
could save its state in a relational database, and a read model could get its
data from a search engine. There's another asymmetry: there's not an equal
number of write and read models. In fact, we may provide any number of
read models, depending on the use cases the application has for retrieving
data. When a use case involves showing the retrieved data to a user, I call
the read model for this use case a view model.
There are many cases where one of your own services is a client of a read
model. In these cases you can define the read model in any way you like.
There are also cases where your read model has to conform to an API
defined by a library or framework. An example that comes to mind is the
UserInterface that we have to implement in order to use our own User
model as input for Symfony's Security Component. In CQRS terms: the
User model is our write model for users, and the UserInterface is a read
model that we have to offer to implement the use case of user authentication
in a Symfony application. The Symfony documentationshows the standard
practice of adding the UserInterface and
PasswordAuthenticatedUserInterface to your existing Doctrine ORM

User entity and using the "entity user provider" to load users from the
database:
<?php
declare(strict_types=1);
namespace App\Entity;
use Symfony\...\PasswordAuthenticatedUserInterface; // (abbreviated)
use Symfony\Component\Security\Core\User\UserInterface;
/**
 * @ORM\Entity
 */
final class User implements UserInterface,
PasswordAuthenticatedUserInterface
{
    /**
     * @ORM\Id()
     * @ORM\GeneratedValue()
     * @ORM\Column(type="integer")
     */
    private int $id;
    /**
     * @ORM\Column(type="string")
     */
    private string $emailAddress;
    /**
     * @ORM\Column(type="string")
     */
    private ?string $password;
    // ...
    public function setEmailAddress(string $emailAddress): void
    {
        $this->emailAddress = $emailAddress;
    }
    public function setPhoneNumberFor2FA(string $phoneNumber): void
    {
        $this->phoneNumber = $phoneNumber;
    }
    // Symfony Security user API:
    public function getUserIdentifier(): string
    {
        return $this->emailAddress;
    }
    public function getPassword(): ?string

    {
        return $this->password;
    }
    public function getRoles(): array
    {
        return ['ROLE_USER'];
    }
    public function eraseCredentials(): void
    {
        $this->password = null;
    }
}
For some developers, importing the UserInterface and related interfaces
in their domain model is a problem because it results in framework
coupling. I don't think it's a big issue, as long as the model itself isn't
limited by this framework integration. If we migrate to a different security
component, we just drop the interface and its methods. The model won't
break. If it would, I'd also consider it a problematic form of coupling.
A bigger issue in my opinion is the fact that we're mixing read
responsibilities into our write model. We pass a User write model to the
Security Component, which it really doesn't need. It does some weird
things to it too, like serializing it and saving it in the session. Another issue
is that we already have our concept of a User model, but then we make it
match Symfony's definition of a user. The two models certainly aren't the
same. Maybe at first, but our User model will attract lots of additional
behaviors, related to profile pictures, public names, permissions, settings,
etc. whereas Symfony's user model is much simpler and is quite static. It
basically just wants a username and a password. Also, the set of our own
users and the set of Symfony security users isn't necessarily the same. We
may have special users, e.g. administrators, that have no corresponding
User model. To make it work we'd have to force such "virtual" users into
our existing User model, and that's going to be quite messy, leading to lots
of ifs in our code.
In summary, I think this situation begs for a dedicated read model. One that
matches exactly, and only, the API expected by Symfony, and where we can
combine data from multiple sources without the need to force-fit one model
into another one. For this we can introduce a new SecurityUser class and

let it implement the UserInterface e.a. Note that it's not an entity. It's not
managed by the ORM:
<?php
declare(strict_types=1);
namespace App\Entity;
use Assert\Assertion;
use Symfony\...\PasswordAuthenticatedUserInterface; // (abbreviated)
use Symfony\Component\Security\Core\User\UserInterface;
final class SecurityUser implements UserInterface,
PasswordAuthenticatedUserInterface
{
    private string $emailAddress;
    private ?string $password;
    private function __construct(string $emailAddress, string $password)
    {
        $this->emailAddress = $emailAddress;
        $this->password = $password;
    }
    public function getUserIdentifier(): string
    {
        return $this->emailAddress;
    }
    public function getPassword(): ?string
    {
        return $this->password;
    }
    public function getRoles(): array
    {
        return ['ROLE_USER'];
    }
    public function eraseCredentials(): void
    {
        $this->password = null;
    }
    /**
     * @param array<string,mixed> $record
     */
    public static function fromDatabaseRecord(array $record): self
    {
        Assertion::keyExists($record, 'emailAddress');
        Assertion::string($record['emailAddress']);
        Assertion::keyExists($record, 'password');

        Assertion::string($record['password']);
        return new self(
            $record['emailAddress'],
            $record['password'],
        );
    }
}
We then provide a new implementation of UserProviderInterface and let
it return instances of the new class. When refactoring we could start by
forwarding the call to Doctrine ORM, but from there we could easily
upgrade to using the DBAL connection directly, in the same fashion as we
did in previous sections.
<?php
declare(strict_types=1);
namespace App\Entity;
use Doctrine\DBAL\Connection;
use Symfony\Component\Security\Core\Exception\UnsupportedUserException;
use Symfony\Component\Security\Core\Exception\UserNotFoundException;
use Symfony\Component\Security\Core\User\UserInterface;
use Symfony\Component\Security\Core\User\UserProviderInterface;
final class SecurityUserProviderUsingDbal implements
UserProviderInterface
{
    public function __construct(private readonly Connection $connection)
    {
    }
    public function refreshUser(UserInterface $user): SecurityUser
    {
        if (! $this->supportsClass($user::class)) {
            throw new UnsupportedUserException();
        }
        return $this->loadUserByIdentifier($user->getUserIdentifier());
    }
    public function supportsClass(string $class): bool
    {
        return $class === SecurityUser::class;
    }
    public function loadUserByIdentifier(
        string $identifier
    ): SecurityUser {
        $record = $this->connection->fetchAssociative(
            'SELECT * FROM users WHERE emailAddress = ?',

            [$identifier]
        );
        if ($record === false) {
            throw new UserNotFoundException();
        }
        return SecurityUser::fromDatabaseRecord($record);
    }
}
We can modify the query and make it smarter, excluding user records that
have no password set for them. We can also load and combine data from
different sources if we like.
In conclusion, whenever the framework wants some data from us, it's going
to introduce coupling. Instead of plugging the write model into the
framework, we should always provide a read model. It allows the write
model to remain decoupled from the framework-facing read model. We can
still benefit from the power of the framework, without trading it for
coupling. When we'd have to switch to a different setup, e.g. when we
migrate frameworks, or when the Security Component is heavily
redesigned, we only have to adapt our read model to the updated
requirements.
Use Domain Events Instead of Persistence
Events
One last topic that deserves to be covered when it comes to decoupling
from an ORM is the use of events. ORMs usually offer a way for
developers to tune into "persistence" events, so they can respond to changes
in their models. As an example, let's take a simple "todo app". Whenever
the due date of a task changes, then the person assigned to it should be
notified about this. With Doctrine ORM you can build such a feature by
creating an event listener service like this:
<?php
declare(strict_types=1);
namespace App\AppBundle;

use App\AppBundle\Entity\Task;
use Doctrine\ORM\Event\PreUpdateEventArgs;
use Symfony\Component\Mailer\MailerInterface;
use Symfony\Component\Mime\Email;
final class TaskNotificationsListener
{
    public function __construct(
        private MailerInterface $mailer
    ) {
    }
    public function preUpdate(PreUpdateEventArgs $event): void
    {
        $task = $event->getObject();
        if (! $task instanceof Task) {
            return;
        }
        if ($task->getAssignedTo() === null) {
            return;
        }
        if ($event->hasChangedField('dueDate')) {
            $this->mailer->send(
                (new Email())
                    ->subject('Re: ' . $task->getDescription())
                    ->text('The due date of this task has changed')
                    ->from('no-reply@example.com')
                    ->to($task->getAssignedTo()->getEmailAddress())
            );
        }
    }
}
You'd have to register this service as a Doctrine event listener in your
service container configuration:
App\AppBundle\TaskNotificationsListener:
    tags:
        -
            name: 'doctrine.event_listener'
            event: 'preUpdate'
The listener is interested in Doctrine's preUpdate event, which Doctrine
dispatches before running an UPDATE SQL statement related to a change in a
flushed entity. The listener will receive a PreUpdateEventArgs object from
which it can take the related entity. If it's a Task, and it has a user assigned

to it, and one of the changed columns is dueDate, then listener will email
the user.
In terms of coupling this is a bad situation. If we'd switch to a different
ORM, we'd have to rewrite this code. We can't assume that it will work in
the same way, or that it's even possible to hook into the update process at
this low level.
There are some other issues. For instance, since this event listener is
notified before the actual database update is completed, what might happen
is that we send the email, but then the database update fails. At that point
the user will have an email about something that isn't true; the due date
hasn't changed after all.
In short, it doesn't make a lot of sense for us to rely on the ORM to handle
these important events. We can easily improve the situation by writing the
event recording and dispatching logic ourselves. We really don't need the
ORM for this.
Since all our entities are fully in charge of any state changes made to it
(because of our previous decoupling efforts), we'll know exactly when the
due date of a task changes. That's when a client calls setDueDate() on a
Task entity. We can start by recording this change as a separate event
object, which we keep inside a private array called $events. Clients can
take out (and immediately clear) the list of previously recorded by calling
releaseEvents():
/**
 * @ORM\Entity
 */
class Task
{
    /**
     * @var array<object>
     */
    private array $events = [];
    // ...
    /**
     * @ORM\Column(type="date")
     */
    private ?DateTime $dueDate;

    public function setDueDate(?DateTime $dueDate): void
    {
        // Make the change:
        $this->dueDate = $dueDate;
        // Then record an event representing this change:
        $this->events[] = new DueDateWasChanged(
            $this->assignedTo,
            $this->description,
        );
    }
    /**
     * @return array<object>
     */
    public function releaseEvents(): array
    {
        $event = $this->events;
        // Reset the array, so we won't dispatch the same events twice
        $this->events = [];
        return $event;
    }
    // ...
}
The DueDateWasChanged event is a simple class that we keep alongside our
entities. It keeps a copy of the data involved in the change that is relevant
for the listener:
<?php
declare(strict_types=1);
namespace App\AppBundle\Entity;
use Symfony\Contracts\EventDispatcher\Event;
final class DueDateWasChanged extends Event
{
    public function __construct(
        public readonly ?User $assignedTo,
        public readonly string $description,
    ) {
    }
}
I'm extending this class from Symfony's base Event class. This is a case of
framework coupling, but not a very bad one, since this class is mostly used

as an indicator that the class is an event. We don't rely on its behavior. If
we'd want to use a different event dispatcher, we can just remove this
parent class.
We need to rewrite the listener a bit to use the new event for its input. It
becomes a lot simpler now, and less concerned with "updated fields", etc.
<?php
declare(strict_types=1);
namespace App\AppBundle;
use App\AppBundle\Entity\DueDateWasChanged;
use Symfony\Component\EventDispatcher\EventSubscriberInterface;
use Symfony\Component\Mailer\MailerInterface;
use Symfony\Component\Mime\Email;
final class TaskNotificationsListener implements
EventSubscriberInterface
{
    public function __construct(
        private MailerInterface $mailer
    ) {
    }
    /**
     * @return array<class-string,string>
     */
    public static function getSubscribedEvents(): array
    {
        return [
            DueDateWasChanged::class => 'whenDueDateWasChanged',
        ];
    }
    public function whenDueDateWasChanged(
        DueDateWasChanged $event
    ): void {
        if ($event->assignedTo === null) {
            return;
        }
        $this->mailer->send(
            (new Email())
                ->subject('Re: ' . $event->description)
                ->text('The due date of this task has changed')
                ->from('no-reply@example.com')
                ->to($event->assignedTo->getEmailAddress())
        );
    }
}

I've turned the class into an "event subscriber"; Symfony's container
configuration will pick it up and register it for the right events. Again,
framework coupling, but easy to rewrite into something the next event
dispatcher supports.
Finally, we have to dispatch the recorded events, which is something we
can do right after saving the Task entity:
$task->setDueDate(new DateTime('+1 day'));
$em->flush();
foreach ($task->releaseEvents() as $event) {
    $eventDispatcher->dispatch($event);
}
Normally this will happen in a service which gets the
EventDispatcherInterface service injected as a constructor argument.
And instead of using $em->flush() we would of course be advised to use a
TaskRepository! Another issue you may have spotted already: if we had
applied the aggregate design rule to only reference aggregates by ID, then
you wouldn't have access to the actual User entity inside Task, so you
couldn't pass it as event data either. If we applied this rule correctly, then
the listener would first have to fetch a User object before it could email
them.
This only shows the beginning of how to use your own events to create
better domain models. You'll find more information about domain events in
my book "Advanced Web Application Architecture" and (again) in the
Domain-Driven Design books by Eric Evans and Vaughn Vernon.
PHPStan Rule: Forbidden Parameter Types
It would be useful to add a PHPStan rule that keeps us from using
persistence events, forcing us to use domain events instead. There are
different options for writing such a rule. We could enforce the practice of
event recording by looking for entities that don't yet have an $events
property. I think that approach is quite error-prone. Some entities may not
need events, or have an $events property that is used for some other
purpose.

A better option is to look for methods that use one of Doctrine's event
classes as a parameter type. We could look for ClassMethod nodes and
analyze its $params subnodes, but we'd benefit a lot from using PHPStan's
virtual InClassMethodNode. That node indicates that PHPStan has analyzed
all the parameters and their types, and can now answer our questions about
whether an argument is of a given type.
We can easily turn this rule into a generic rule by not just disallowing
Doctrine event classes, but by accepting a configurable "forbidden"
parameter type as a constructor argument. Combining these ingredients
leads to a simple and reusable ForbiddenParameterType rule:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PHPStan\Analyser\Scope;
use PHPStan\Node\InClassMethodNode;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;
final class ForbiddenParameterTypeRule implements Rule
{
    private ObjectType $forbiddenType;
    public function __construct(string $forbiddenType)
    {
        $this->forbiddenType = new ObjectType($forbiddenType);
    }
    public function getNodeType(): string
    {
        return InClassMethodNode::class;
    }
    /**
     * @param InClassMethodNode $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        $errors = [];
        foreach ($node->getOriginalNode()->getParams() as $param) {
            if (
                $this->forbiddenType
                    ->isSuperTypeOf($scope->getType($param->var))
                    ->yes()

            ) {
                $errors[] = RuleErrorBuilder::message(
                    sprintf(
                        'Parameter type %s is not allowed',
                        $this->forbiddenType->getClassName()
                    )
                )->build();
            }
        }
        return $errors;
    }
}
Note that this rule makes the assumption that the forbidden parameter type
is always an object type (e.g. not string or anything).
Conclusion
We've seen several ways to decouple a domain model from the framework
or the ORM. It sometimes looks like a lot of work, but that's only when you
start from a totally coupled situation. If I start with a fresh model, and I
have to decide if I'm even going to use an ORM, I definitely pick the
"ORM-less" route, as a rapid development approach. The result is a lot
more insight into what's going on in the mapping code, which benefits the
IDE, static analysis and automated refactoring tools. By default, I also start
with a dedicated write model, and any number of view models, which are
not necessarily related to the write model. This helps the write model to
focus on domain logic, and protecting its state, while the view model can
provide anything the view needs, without necessarily being tied to the
structure of the write model. This gives you the option to evolve the view
models separately from the write model: they can easily combine data from
different sources, and they are separately disposable too, when they are no
longer needed.
OceanofPDF.com

6 Test Frameworks
This Chapter Covers:
Decoupling from test runners by using only their most basic features
Rewriting tests from DSL code to plain PHP code
Replacing generated mocks with handwritten test doubles
Writing PHPStan rules to keep your test suite decoupled
Introduction
So far I've used many frameworks for testing. Some that come to mind:
SimpleTest, Lime, PHPUnit, Codeception, PHPSpec, Behat... Each has its
own unique selling points and is probably easy to use, but do we really need
so many test frameworks? Sure, every new framework introduces new ways
of writing and structuring test code, but if it's new and better ways that
we're looking for, one day we'll certainly want to migrate do a different
framework that offers even more revolutionary ways to write test code.
Many projects suffer from this urge to use multiple test frameworks over
the years. In the beginning a project has only one framework for writing
tests (e.g. PHPUnit with a setup for browser-like testing), then it adds
another one (e.g. Behat for high-level scenario tests), and maybe even
another one (e.g. PHPSpec for class tests). Eventually, one of these
frameworks is going to become obsolete. The maintainer of CoolTest 2000
is going to give up on the project. They liked inventing a new framework,
and indeed, it's probably fascinating to do so, but at some point it becomes
boring. Perhaps it wasn't the maintainer that gave up, but the development
team who didn't like the framework anymore. Then the team has to adopt
the next framework, which is going to do things in a completely different
way.
The same is true for mocking libraries. If you use any number of mocks in
your tests then you end up being invested in one particular mocking library,

like Mockery, or PHPUnit mocks, or Prophecy. Unfortunately, when a new
tool comes around, someone in the team wants to try it, or the team decides
to switch but never takes the time to complete the migration. Now the
project has two or three different mocking tools in use. All their related
packages need to be updated regularly, and for (new) developers it's unclear
what mocking tool they should use.
My hypothesis is that a project ends up with different test frameworks and
mocking libraries because:
Writing tests can feel cumbersome, we want it to go faster, and be
more fun, so we install new and cool tools that promise these things.
Tests aren't production code, so it feels like we can freely experiment
with different approaches.
A new tool is quickly installed and the enthusiasm is contagious, but
no project manager is ever going to "give us time" to upgrade the old
approach to the new one.
Use Only the Most Basic Features of a Test
Framework
One way out of this bad situation is to never even switch frameworks, or at
least, to never add a new framework without actually taking the time to
upgrade the old code to also use that new framework. Something else to
keep in mind when faced with the choice for a test framework is that it
should be a stable, boring one. Stable means, it doesn't often introduce
breaking changes, and it has been maintained and upgraded to newer
language versions for quite some time.
What counts as a "boring" framework? I like to find the answer by boiling
down what I think any (test, web, CLI, etc.) framework can be expected to
offer. We'd end up with a list of features of any current framework that we
can safely rely on, because they are supposed to be offered by any future
framework as well. Once we have this list, we should ignore and not rely on
any of the non-essential parts of the framework. At first this will be
somewhat counter-intuitive because the non-essential aspects of a

framework are usually what makes it unique and desirable. In the long run
this approach will be very helpful, because by relying only on essential
features your code will remain loosely coupled to the framework. You can
migrate to a different one without putting in a lot of effort.
For web frameworks we decided earlier that the essential features are about
routing a request to a controller, then rendering the response returned by
that controller. For test frameworks, I think the following list of features is
absolutely essential, so we can assume every potential test framework to
implement these:
A test runner should invoke our test functions
If a test function throws an exception, it should be marked as a "failed
test"
If it doesn't throw an exception, it should be marked as a "successful
test"
The test runner succeeds (exit code 0) unless any test fails (exit code >
0)
Note that a test "framework" as small as a single tweetwould already
provide most of these features:
A unit testing framework in a tweet.
// The framework
function it($m,$p){echo ($p?'âï¸':'â')." It $m\n";
if(!$p){$GLOBALS['f']=1;}}function done(){if(@$GLOBALS['f'])die(1);}
// The tests
it("should sum two numbers", 1+1==2);
it("should display an X for a failing test", 1+1==3);
done();
Of course, these are really the bare necessities. Eventually we'd need some
other pretty basic things from the framework:
Run some code before and after each test function, regardless of
whether the test function fails
Group related test functions in a class
Test functions that are actually supposed to throw exceptions

It may not come as a surprise that PHPUnit has all of these features, which
is why I think it should be the framework of choice. It's also no surprise
that other test frameworks are often built around PHPUnit and add things
on top of it. For example, frameworks may offer:
A way to extend the framework itself, using
modules/plugins/extensions e.g. for setting up a database, or
configuring the web framework.
A specialized DSL (Domain Specific Language) for writing tests, with
for instance chainable functions like it()->shouldNot()->and()-
>...().
These certainly are unique selling points, but they are not in the list of test
framework essentials, so they aren't features we can safely rely on. If we
stay away from these feature we'll end up with portable test functions that
can be executed by any test framework, present, past, and future. Those test
functions:
Declare what they need (a database, a web server, whatever)
Rely on just a few implicit behaviors of the test framework
A quick test for how decoupled your test code is at the moment: if you
remove the test framework itself, how much of your test code could still be
executed, even if it would have to be done manually? How much work is
needed to get it working again with another framework?
Declare Test Dependencies Explicitly
To find out more about what aspects of tests get in the way of their
portability, let's take a look at the following test class. It's written for
PHPUnit, and uses its assertion functions and parent TestCase class. It tests
an API client:
final class ApiClientTest extends TestCase
{
    public function testGetExchangeRate(): void
    {
        $apiClient = new ApiClient();

        $rate = $apiClient->getExchangeRate('USD', 'EUR');
        self::assertEquals(0.87, $rate);
    }
}
Before we can run this test we have to start a local web server that serves
the API itself so the client can make actual requests. A common solution
would be to create an extension for the framework, which starts the server
before running the first test and stops it after running the last test:
use PHPUnit\Runner\AfterLastTestHook;
use PHPUnit\Runner\BeforeFirstTestHook;
use Symfony\Component\Process\Process;
final class ApiServerExtension implements BeforeFirstTestHook,
AfterLastTestHook
{
    private ?Process $apiServer = null;
    private string $output = '';
    public function executeBeforeFirstTest(): void
    {
        // start web server
        $this->apiServer = new Process(
            ['php', '-S', '0.0.0.0:8001', '-t', 'api/']
        );
        $this->apiServer->start(
            function (string $type, string $message) {
                $this->output .= $message . "\n";
            }
        );
        // wait until the server has started
        // ...
    }
    public function executeAfterLastTest(): void
    {
        if ($this->apiServer instanceof Process) {
            if (! $this->apiServer->isRunning()) {
                throw new \RuntimeException(
                    'API server failed to start: ' . $this->output
                );
            }
            $this->apiServer->stop();
        }
    }
}

The extension has to be configured in phpunit.xml:
<phpunit>
    <extensions>
        <extension class="ApiServerExtension" />
    </extensions>
</phpunit>
This works well, but it's a very coupled solution: the test relies on the
framework's behavior of loading and invoking the extension. Looking at the
test code itself, it's not clear that it relies on this ApiServerExtension. The
test doesn't explicitly declare its dependency on the API server. We can
improve the situation by introducing an abstract class that starts the server
for us before and after the test run. Because setUpBeforeClass is a static
method, we also have to make the properties it uses static, but that isn't a
show-stopper:
use PHPUnit\Framework\TestCase;
use Symfony\Component\Process\Process;
abstract class RequiresApiServerTest extends TestCase
{
    private static ?Process $apiServer = null;
    private static string $output = '';
    public static function setUpBeforeClass(): void
    {
        // start web server
        // ...
    }
    public static function tearDownAfterClass(): void
    {
        if (self::$apiServer instanceof Process) {
            // ...
        }
    }
}
The only change to the test itself is that we use the new abstract class as the
parent, instead of the standard TestCase class:
final class ApiClientTest extends RequiresApiServerTest
{
    public function testGetExchangeRate(): void
    {

        // ...
    }
}
This is slightly better because the dependencies are declared more
explicitly. Using this specific parent class can be considered a useful clue to
the developer who wants to understand this test (or migrate it to a different
test framework...). However, it still relies on an implicit framework
convention, namely that setUpBeforeClass() and tearDownAfterClass()
will be invoked at the right moments. Imagine what happens if we can no
longer depend on PHPUnit's TestCase class. Our setup methods would
never be called and the test would fail because the API server has not been
started.
A better solution is to explicitly start the server when we need it, and stop it
when we no longer need it. We could do this inside the test function, but if
the test throws an exception the web server would still be running
afterwards. For this kind of situation we're better off using the setUp() and
tearDown() functions which will be invoked by the framework whether the
test fails or not:
final class ApiClientTest extends TestCase
{
    private ?Process $apiServer = null;
    private string $output = '';
    protected function setUp(): void
    {
        $this->startWebServer();
    }
    protected function tearDown(): void
    {
        $this->stopWebServer();
    }
    public function testGetExchangeRate(): void
    {
        // ...
    }
    private function startWebServer(): void
    {
        // start web server
        $this->apiServer = new Process(
            ['php', '-S', '0.0.0.0:8001', '-t', 'api/']

        );
        // ...
    }
    private function stopWebServer(): void
    {
        if ($this->apiServer instanceof Process) {
            // ...
            $this->apiServer->stop();
        }
    }
}
Note that we can once more extend from the basic TestCase class instead of
one maintained by us, which is another way to not get too entangled with a
framework. We're still coupled of course, but we're more loosely coupled.
We've removed one level from the class hierarchy. We still rely on the
framework to call setUp() before each test function and tearDown()
afterwards (regardless of the result of the test function). But this feature is
in the list of essential framework features. We couldn't imagine a test
framework without them. Although we'd possibly have to rename these
methods to match the expectations of the new framework, at least we can
assume a similar feature to exist.
If we find that we need to reuse the server setup code in different test
classes, we can always introduce some reusable code for that. It could be a
trait, but since it has service capabilities I'd prefer to use a class for this.
In this case it should contain the start() and stop() methods:
<?php
declare(strict_types=1);
namespace TestFrameworks\TestDependencies\Version3\Test;
use Symfony\Component\Process\Process;
final class ApiServer
{
    private ?Process $apiServer = null;
    private string $output = '';
    public function start(): void
    {
        // start web server
        $this->apiServer = new Process(
            ['php', '-S', '0.0.0.0:8001', '-t', 'api/']

        );
        // ...
    }
    public function stop(): void
    {
        if ($this->apiServer instanceof Process) {
            // ...
            $this->apiServer->stop();
        }
    }
}
The advantage is that the $apiServer and $output properties can be moved
to this class as well, keeping the test class clean. We instantiate the new
ApiServer class in the setUp() method of the test class:
final class ApiClientTest extends TestCase
{
    private ApiServer $apiServer;
    protected function setUp(): void
    {
        $this->apiServer = new ApiServer();
        $this->apiServer->start();
    }
    protected function tearDown(): void
    {
        $this->apiServer->stop();
    }
    public function testGetExchangeRate(): void
    {
        // ...
    }
}
A strict requirement for this is that the class itself is completely decoupled
from the framework and doesn't rely on any of its implicit behavior.
To conclude this section, here are some other examples of things that tests
rely on but often aren't explicitly declared:
A database server has been started and its schema has been migrated to
the latest version
Certain database fixtures have been loaded

Tables have been emptied before the test starts
The service container has been compiled and built
Service objects have been constructed in the setUp() function of the
parent class
Always examine your test functions and look for things that the test is
implicitly relying on. Then make those things explicit. Move implicit test
steps executed by extensions to the tests themselves, so it's clear what
dependencies they have.
PHPStan Rule: Don't Allow PHPUnit Extensions
We don't want to rely on test framework extensions, listeners, etc. so we
should have a PHPStan rule that flags existing and future uses of extension-
related interfaces, like PHPUnit's BeforeFirstTestHook,
AfterLastTestHook, etc. This rule could be quite generic from the start. We
can write a rule that triggers an error when any class implements such a
"forbidden" interface. The name of the interface should be provided as a
constructor argument, and the node type for this rule should be the
InClassNode we used before. This node provides a ClassReflection
object for each class that PHPStan encounters in our project. This object has
a method implementsInterface() which is exactly what we need:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PHPStan\Analyser\Scope;
use PHPStan\Node\InClassNode;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
final class ForbiddenImplementsRule implements Rule
{
    private string $forbiddenInterface;
    public function __construct(string $forbiddenInterface)
    {
        $this->forbiddenInterface = $forbiddenInterface;
    }
    public function getNodeType(): string

    {
        return InClassNode::class;
    }
    /**
     * @param InClassNode $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if (! $node->getClassReflection()->implementsInterface(
            $this->forbiddenInterface
        )) {
            return [];
        }
        return [
            RuleErrorBuilder::message(
                sprintf(
                    'Class implements forbidden interface %s',
                    $this->forbiddenInterface,
                )
            )->build(),
        ];
    }
}
PHPStan Rule: Don't Allow Class-level Set-up and Tear-
down Functions
We can add another rule that prevents us from using non-essential features,
like setUpBeforeClass() and tearDownAfterClass(). These functions are
similar to extensions, and often result in messy code that change global
state since they are static functions. Besides, anything that can be written
in these methods can also be written in the object-level setUp() and
tearDown() methods, so it's better to prefer those.
One option for implementing this rule would be to look for ClassMethod
nodes and trigger an error for any method that's called
setUpBeforeClass() or tearDownAfterClass(). That would be fine in this
case, but could theoretically lead to false positives. We would get an error
for a class that isn't even a PHPUnit test class but still has a method with
one of these names.
A better option would be to look for methods with these names that actually
override a method defined in TestCase. For this we need some class

reflection again. We can set this rule up in a generic way too, and name it
ForbiddenOverrideRule. We'll accept a class name, like TestCase as a
constructor argument, as well as a method name, like setUpBeforeClass.
We register the rule for ClassMethod nodes, and find out if the current class
has the configured class somewhere in its ancestors. We also check if the
method name is the same as the configured name:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PhpParser\Node\Stmt\ClassMethod;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
final class ForbiddenOverrideRule implements Rule
{
    public function __construct(
        private readonly string $overrideFromClass,
        private readonly string $overrideMethod,
    ) {
    }
    public function getNodeType(): string
    {
        return ClassMethod::class;
    }
    /**
     * @param ClassMethod $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if ($node->name->toString() !== $this->overrideMethod) {
            // The method name does not match
            return [];
        }
        if (! in_array(
            $this->overrideFromClass,
            $scope->getClassReflection()
                ->getParentClassesNames(),
            true
        )) {
            // The method name matches, but not the class
            return [];
        }
        return [

            RuleErrorBuilder::message(
                sprintf(
                    'Overriding method %s::%s() is not allowed',
                    $this->overrideFromClass,
                    $this->overrideMethod,
                )
            )->build(),
        ];
    }
}
Assertions
When considering how coupled code is to a certain framework or library,
we normally consider the function calls we make as a point of coupling. For
test code, most of the framework-specific functions are assertion functions,
like assertEquals(), assertCount(), assertContains(), etc. In PHPUnit
test classes they are often called on $this:
use PHPUnit\Framework\TestCase;
final class CollectionTest extends TestCase
{
    public function testCollectionAdd(): void
    {
        $collection = new Collection();
        $collection->add(1);
        $collection->add(2);
        $this->assertCount(2, $collection);
        $this->assertContains(2, $collection->values());
    }
}
When you look at the implementation of these methods, you'll find that
they are all part of an abstract class called Assert. The assertion functions
themselves are public static functions, meaning we can call them from
any place, not just an instance of a class that extends from Assert. So
alternative ways to write $this->assertEquals() are
self::assertEquals() or Assert::assertEquals(). The fact that the
assertion functions can be invoked from any other place, not just a PHPUnit
test class, for me means that decoupling from them isn't that urgent. Even if
we'd switch to a different test framework, we could still include PHPUnit in

our project only for its assertion functions. Potentially we could prepare for
the switch by using Assert instead of $this or self:
use PHPUnit\Framework\TestCase;
use PHPUnit\Framework\Assert;
final class CollectionTest extends TestCase
{
    public function testCollectionAdd(): void
    {
        // ...
        Assert::assertCount(2, $collection);
        Assert::assertContains(2, $collection->values());
    }
}
But we really don't have to do this today. It will be a matter of writing a
simple Rectorrule to migrate the test code when it's really needed.
Write Tests in Plain Code
Compared to relying on framework extensions and assertion functions, the
use of custom DSLs (Domain-Specific Languages) for testing is a truly
severe case of coupling. The DSL is part of the test framework and none of
your test code will work when you remove the framework. A recent
example of a test framework that introduces such a DSL is Pest(others I
know of are Atoumand Peridot). Pest is built on top of PHPUnit, but keeps
it out of sight as much as possible. As an example, here is the Collection-
test we saw before, now rewritten to use Pest's expect() function and
"higher order tests", where each assertion can be chained with a method call
on the subject under test, followed by even more assertions:
<?php
declare(strict_types=1);
use TestFrameworks\Dsls\Version0\Collection;
test('a collection with two, then three items', function () {
    expect(Collection::empty()->with(1)->with(2))
        ->toHaveCount(2) // assertion functions
        ->toContain(2)
        ->with(3) // function of Collection
        ->toHaveCount(3) // assertion functions

        ->toContain(3);
});
The expect() function can be extended with your own functions, or you
can introduce helper functions. This means the DSL itself is dynamic and
this results in a typical problem of dynamic programming. It's not clear
where the code of a method lives. Method calls will be resolved
dynamically to either an assertion function, one of the additional functions,
or a function on the object that is the subject under test. When writing test
code, the main issue is that you don't know which functions are even exist,
and neither does your IDE. You have no auto-completion for these
functions, and you'll end up reading the documentation of the framework,
or just trying something and running into an error. Even after installing an
IDE plugin that solves part of this problem, your IDE can't support you
anymore when renaming a method, or changing a method signature. Static
analysis or automated refactoring tools will have some trouble dealing with
this code too, making the tests harder to write, but also harder to maintain in
the long run.
I'm not sure about the motivation to create Pest as an alternative for
PHPUnit, but it seems that the authors wanted to get rid of test classes. With
Pest, you don't need to create a test class that extends PHPUnit's TestCase,
nor do you have to put every test in a separate method. Instead, you write
every test as function calls in the global namespace. Everything you want to
do in a normal test class now has to be done "from the outside". You can
even dynamically include traits by calling a use() function, or implement
setUp() and tearDown() functions by calling beforeEach() and
afterEach().
Knowing that Pest functions are mostly just PHPUnit behavior but outside-
in, every test you write with a specialized DSL like the one Pest provides,
can certainly be rewritten in plain code that lives in a test class, does the
same thing, and is easier to maintain. Of course, users of a DSL will claim
it's easier to use the DSL than to write plain PHP, but I doubt it. You have to
know about every function the framework offers before you can do
anything, and a developer who is new to the tool will need more time to get
up to speed. Besides, even if you can save time when writing a test, that

doesn't mean it will save you time maintaining it. In my experience it's
often the other way around, not only for test code.
It may sound like I don't want any alternative or specialized language for
tests, and I want tests to be written in just plain code. And that's right! One
thing I do like is to make my test code as expressive as possible. For this I
need no DSL, just good method names and a comment here and there.
Handwritten Test Doubles
Another area of test code that leads to coupling is the use of specific
mocking libraries. Just like test frameworks, mocking libraries also have
their unique selling points. In the end they help you replace certain service
dependencies (injected as constructor arguments) with ones that don't make
a network connection or do similar unstable things. In your test you can
define what the replacement object should return, or verify that the right
methods were called, and the right arguments were provided.
We could have a long discussion about test doubles: if you should use them,
when to use them, etc. In this section I'll assume that test doubles are
valuable, and you sometimes need them, but you don't want your code to be
coupled to a particular mocking library. The solution is to see past the
object builders offered by these libraries and to figure out what they are
really doing. It turns out they do much more than you normally need. Then
the alternative is to write the test doubles yourself, in plain PHP code. This
is often surprisingly simple and proves the same point again: using a
mocking library will make it feel like you can work faster, but that's only at
the moment you write the code (that is, if you correctly understand how the
library works). In the long run, maintaining generated mocks is definitely
harder than maintaining handwritten ones.
As an example of how you can migrate from a generated mock to a
handwritten test double, let's take a look at the following test for the

SignUpService. When a user signs up we expect it to dispatch an event
about this, so we set up a test double and inject it as a dependency:
final class SignUpServiceTest extends TestCase
{
    public function testItDispatchesAnEvent(): void
    {
        $username = 'Matthias';
        $eventDispatcher = $this->createMock(EventDispatcher::class);
        $eventDispatcher->expects($this->once())
            ->method('dispatch')
            ->with(new UserHasSignedUp($username));
        $service = new SignUpService($eventDispatcher);
        $service->signUp($username);
    }
}
The mock does several things:
It provides an implementation for all the methods of the
EventDispatcher interface.
At the end of the test it ensures the dispatch() method was called
once.
Then it also checks that the right argument was provided (it should be
equal to the recreated UserHasSignedUp object).
All of this happens behind the scene: createMock() registers the mock in a
private list of mock objects whose expectations need to be verified as part
of the test that created the mock object. The implicitness and the magic of
this results in hard to refactor code: if we use the IDE to rename the
dispatch() method of the EventDispatcher to, say, dispatchEvent() then
the tests start failing because it still sets up an expectation for a method
called 'dispatch'.
If we would just take a minute to write our own test double we would be
able to get rid of all the magic performed by the mocking library, we'd have
only plain PHP code that's easy to analyse and refactor, and we earn the
freedom to make our own assertions. Here is a test double for the
EventDispatcher interface that can be injected as a constructor argument

of SignUpService, but can also be used to verify that the right event has
been dispatched.
final class EventDispatcherSpy implements EventDispatcher
{
    /**
     * @var array<object>
     */
    private array $dispatchedEvents = [];
    public function dispatch(object $event): void
    {
        $this->dispatchedEvents[] = $event;
    }
    /**
     * @return array<object>
     */
    public function dispatchedEvents(): array
    {
        /*
         * This method is not part of the `EventDispatcher` interface.
         * It's only here so we can later inspect the event objects that
         * have been passed to `dispatch()`.
         */
        return $this->dispatchedEvents;
    }
}
This test double could be called a spy because it makes no assertions about
the methods called or their arguments. It just collects some data that can
later be analyzed in the test itself:
final class SignUpServiceTest extends TestCase
{
    public function testItDispatchesAnEvent(): void
    {
        $username = 'Matthias';
        $eventDispatcher = new EventDispatcherSpy();
        $service = new SignUpService($eventDispatcher);
        $service->signUp($username);
        self::assertContainsEquals(
            new UserHasSignedUp($username),
            $eventDispatcher->dispatchedEvents()
        );
    }
}

A few things have changed when switching from a generated mock to our
own test double.
1. Our test has explicit assertions at the end, which makes it nicely follow
the three stages of the well-known Arrange-Act-Assert template for
tests.
2. The assertions can be as (un)specific as we want. If we create a mock
and pass expected arguments using the with() function, we don't have
any control over how the actual arguments are compared to the
expected ones.
For example, here I've used assertContainsEquals(), which is less
specific than "dispatch() should have been called exactly once". I'd say
this is better because we don't care if other events have been dispatched; in
this test we are only interested in the UserHasSignedUp event.
Effectively we have completely decoupled this test code from any mocking
library. If it's a separately installed library, we can now safely remove it.
PHPStan Rule: Don't Generate Mocks
One rule we can write, to completely get rid of generated mocks, is a rule
that marks TestCase::createMock() as a forbidden method. Once more we
can create a generic rule for this, a ForbiddenMethodCallRule, that checks
if the object on which a method is called is an instance of TestCase and if
the method name is createMock(). In this book we've seen several
examples of this kind of rule already, and they can all be replaced by this
new generic rule now:
<?php
declare(strict_types=1);
namespace Utils\PHPStan;
use PhpParser\Node;
use PhpParser\Node\Expr\MethodCall;
use PhpParser\Node\Identifier;
use PHPStan\Analyser\Scope;
use PHPStan\Rules\Rule;
use PHPStan\Rules\RuleErrorBuilder;
use PHPStan\Type\ObjectType;

final class ForbiddenMethodCallRule implements Rule
{
    private ObjectType $class;
    public function __construct(
        string $class,
        private readonly string $method,
    ) {
        $this->class = new ObjectType($class);
    }
    public function getNodeType(): string
    {
        return MethodCall::class;
    }
    /**
     * @param MethodCall $node
     */
    public function processNode(Node $node, Scope $scope): array
    {
        if (! $node->name instanceof Identifier) {
            // Dynamic method name, can not be analyzed
            return [];
        }
        if ($node->name->toString() !== $this->method) {
            // The method is a different one
            return [];
        }
        if (! $this->class->isSuperTypeOf(
            $scope->getType($node->var)
        )->yes()
        ) {
            // The class does not match the expected type
            return [];
        }
        return [
            RuleErrorBuilder::message(
                sprintf(
                    'Call to forbidden method %s::%s()',
                    $this->class->getClassName(),
                    $this->method,
                )
            )->build(),
        ];
    }
}

Conclusion
To decouple from a test framework, test code should be as simple as it can
be. Just plain PHP code, that declares what it needs instead of relying on
dependencies to be set up for it in extensions, traits, parent classes, etc.
Mocking tools aren't needed at all, you can just write some simple test
doubles (in plain PHP code) whenever you need them.
OceanofPDF.com

7 Conclusion
This book counts about 300 pages now, so it's time for a conclusion. There
may be several other framework-related topics left to discuss, but they
would be similar to things we already covered. So instead of adding more
chapters it may be more useful to revisit the decoupling tactics we've
collected in the previous chapters. How do we arrive at these tactices?
First, we have to realize that we never know exactly what the next version
of one of our dependencies is going to be. So if we want to decouple from
them, we can't really be sure if we're doing it right. We may spend weeks
on decoupling from our framework, but when it's time to really migrate to
another framework, we may have wasted time in certain areas of the code
base because they could easily be reused or transformed to work with the
new framework.
Second, despite the common phrase "Who's going to switch databases
anyway?" we know that many projects suffer from the need to migrate
dependencies in some way. If it's not the database, it's the framework, or
the template renderer, or the test runner, and so on. We shouldn't ignore the
fact that many project teams can work fast in the beginning, but eventually
slow down to a crawl. The main reason is the incredible amount of coupling
that makes it impossible to change or improve anything. Not all of this
coupling is related to dependencies, but much of it is.
Together, these findings establisch a realistic perspective on decoupling.
These findings are based on my own experience as a programmer, and
confirmed by all the stories I've heard over the years from other teams that
I met in workshop or consultancy sessions. What follows from this vision
is:
1. We shouldn't aim to fully decouple, but ...
2. We should do some decoupling at least.

The question is: what are efficient and effective ways of decoupling then?
In this book I've tried to answer this question for many areas of your
average web application. In several cases decoupling is a continuous act of
refactoring. As an ongoing process, decoupling inherits an interesting
property of refactoring: you can keep doing it, but it has diminishing
returns. You'll often experience a sweet spot where making a relatively
small effort gives you impressive results. After that point it doesn't make
much of a difference anymore, or the effort will become bigger than the
benefits. Sometimes you'll even refactor "too far" and make the situation
worse.
To find the sweet spot of decoupling, which is often called "loose
coupling", I've used the following questions. These could be considered
heuristics; guiding questions that help you find the answer:
1. What is the common denominator for some examples of a dependency
you want to decouple from? Everything that is not common should be
considered "special", and should be decoupled from.
2. Can we still run this code if the dependency we want to decouple from
is removed? Can we make it work again without making too many
invasive changes?
As an example of 1: if you are creating controllers in a web application, you
may assume that your next framework will have its own way of configuring
routes for them. So it doesn't make sense to decouple from the current
framework's routing setup, e.g. by enforcing them to be in a Yaml file
instead of using annotations. When you migrate to the next framework,
you'll have to rewrite the routing to their configuration format anyway.
Another example of using heuristic 1, which leads to the opposite result:
even though your template renderer offers some very special features and
all kinds of syntactic sugar, it's likely that they aren't offered by the next
template renderer. So it would be smart to use the simpler, more primitive
alternatives that work just as well.
An example of 2: if you are writing tests with a test runner that uses its own
domain-specific language, nothing will work anymore once you migrate to

a different test runner. So it's better not to rely on this and write your code
just as you write any other code.
And another example of applying 2, which leads to a different outcome: if
your model doesn't use a parent class that facilitates its persistence, the
object is just a plain old PHP object. It's just like any code, therefore it will
survive the migration to a different ORM.
In essence, decoupling turns out to be a kind of risk management. We're
concerned with the chances that a certain way of coupling is going to cause
damage, but we also take into consideration the impact when it happens.
How much work would it be to deal with the change? We can reduce the
chances by following heuristic 1, and we can reduce the impact by
following heuristic 2.
While applying these heuristics I often find that the better option for writing
any code is to prefer the simple solutions over the more complicated ones.
This seems obvious but in practice many projects seem to prefer the
complicated options. Examples are:
Prefering static service locators over dependency injection. The latter
is simpler because fetching a service introduces two dependencies: one
on the service, and one on its locator.
Prefering an ORM over custom mapping code. The latter is simpler
because it requires less code, and makes explicit what's left implicit by
the ORM.
Prefering new tools that wrap existing tools, instead of using those
existing tools, which are by definition simpler than the new tools, and
will therefore be harder to replace.
The journey continues, and I hope that as a community of software
developers we'll keep looking for better, and often simpler ways to achieve
things, without sacrificing too much of our ability to swap dependencies.
We want to move forward, as fast as we were at the start of the project, and
we want to have projects that can survive for more than just a few years.
Best of luck to you, and thanks for joining me as a reader. Until next time!
OceanofPDF.com

8 The End of the Book
You've reached the end of the book. Given that this book is published via
Leanpub, I'll keep improving it based on your feedback. So, if you find
anything that is wrong, or could be better, please let me know. Also, if you
have something nice to say about this book, please share it as well!
On Twitter: https://twitter.com/matthiasnoback
By email: info@matthiasnoback.nl
OceanofPDF.com

