

Hofmann ¬∑ L
ange
Martin Hofmann
Martin Lange
Automata Theory
Automa
and Logic
ta Theor
y and L
ogic
Automata Theory and Logic
Martin Hofmann ¬∑ Martin Lange
Automata Theory and Logic
Martin Hofmann
Martin Lange
Institut f√ºr Informatik
Fachbereich Elektrotechnik und Informatik
Lehr- und Forschungseinheit Theoretische
Fachgebiet Theoretische Informatik /
Informatik

Formale Methoden
Ludwig-Maximilians-Universit√§t M√ºnchen
Universit√§t Kassel
M√ºnchen, Germany
Kassel, Germany
ISBN 978-3-662-72153-7
ISBN 978-3-662-72154-4
(eBook)
https://doi.org/10.1007/978-3-662-72154-4
This is a revised, extended and translated version of the German
"Automatentheorie und Logik", by Martin Hofmann and Martin Lange,
published by Springer in 2011 - ISBN: 978-3-642-18089-7, e-ISBN: 978-3-
642-18090-3
¬© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer-Verlag GmbH, DE, part of Springer Nature 2025
This work is subject to copyright. All rights are solely and exclusively
licensed by the Publisher, whether the whole or part of the material is
concerned, specifi cally the rights of translation, reprinting, reuse of
illustrations, recitation, broadcasting, reproduction on microfi lms or in any
other physical way, and transmission or information storage and retrieval,
electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service
marks, etc. in this publication does not imply, even in the absence of a
specifi c statement, that such names are exempt from the relevant protective
laws and regulations and therefore free for general use.

The publisher, the authors and the editors are safe to assume that the advice
and information in this book are believed to be true and accurate at the date
of publication. Neither the publisher nor the authors or the editors give a
warranty, expressed or implied, with respect to the material contained
herein or for any errors or omissions that may have been made. The
publisher remains neutral with regard to jurisdictional claims in published
maps and institutional affi liations.
This Springer Vieweg imprint is published by the registered company
Springer-Verlag GmbH, DE, part of Springer Nature.
The registered company address is: Heidelberger Platz 3, 14197 Berlin,
Germany If disposing of this product, please recycle the paper.
To Annette, Johanna, Matthias and Elisabeth.
To Becky, Annika and Sophie.
Preface
The roots of this book date back to the year 2004 when Martin Hofmann
and myself gave a course on "Automatentheorie" in the computer science
programme at the Ludwig-Maximilians University of Munich. The course
was inspired - at least for my part - by lectures on automata theory given
by Franz Baader and Wolfgang Thomas that I had attended during my
studies at RWTH Aachen in the mid '90s.
The course was well received by students and consequently was repeated in
the summer terms 2006 and 2008 at LMU Munich, still shared, and then
also beyond that point separately as I had left LMU Munich in 2010. In
order to integrate the parts that we lectured on separately, Martin had at
some point, in his very own way,
"just quickly typed the course notes in ASCII." That was quickly turned into
LATEX
sources and then given some structure and content details to make it proper
hand-out lecture notes.

We then realised that the result was close to being publishable as a textbook
on automata theory and logic. So we approached Springer, a publication
agreement was made and some final touches were implemented.
This could well be the end of this foreword, at least the part outlining this
book's history, but the acute reader may have already wondered about a 15
year gap in the story. During the talks about the publication of a book we
asked the handling editor at Springer whether they would prefer to publish
the book in English or in German, and fatally they left it up to us to decide.
We managed to convince ourselves of the existence of good reasons beyond
pure laziness for which we decided to stick with the German version.
In 2011, the book "Automatentheorie und Logik", just under 250 pages
long, appeared in Springer's eXamen.press series.
Over the next years, we received positive feedback from various colleagues
who seemed to like the book a bit more than they liked buying it, at least
when comparing such feedback to the royalty statements. From most of the
feedback we could also deduce that an English version may have been
appreciated a bit better.
In 2017 we had pretty much decided that it is time to produce an English
version.
Initial work quickly revealed some differences in our vision of the final
result.
Martin favoured a straightforward and quick translation including fixes of
reported vii
viii
Preface
and obvious mistakes, while I grew increasingly discontent with the sparsity
of the lecture-note style and favoured a more thorough reworking with the
aim of better self-containment.

We never got to work out a common vision for how much "the English
version"
should deviate from the original book in German in terms of content and
style. In January 2018, Martin sadly died in a snow storm on a day's hike in
the mountains north of Tokyo which, needless to say, put the project to a
halt.
In early 2022, I was approached by Springer asking if I was interested in
producing a second edition of the book. I told them about our thoughts and
efforts on an English version which had ground to halt, effectively before
they had started properly.
Springer was quite positive about the idea of an English version and so I
convinced myself that I could do it on my own, and also do it in a way that
Martin and I would have agreed to. I do not know about the second part. It
could have been that Martin would have agreed to a more elaborate version,
or perhaps we would still be discussing pros and cons. In any case, I
decided to try to emulate as much of Martin's more minimalistic approach
as possible, and failed. In the end, this book is not just a translation of the
German version from 2011. It has seen some major overhauling in terms of
chapter restructuring, addition of proofs and examples, bug fixes of course,
unification in terminologies and, most importantly, the attempt to make it a
self-contained reading material that can be used for self-study, not just as
back-up course notes. Consequently, it grew by about 150 pages.
A line was drawn regarding genuinely new content: while research in
automata theory and logic is still active and ongoing with new
developments seen regularly, I decided to not include any additional
concepts (apart from examples, proof details, references, etc.) compared to
the German version. This was also done in order to retain the spirit of it
being an actual collaboration between Martin and myself. While the amount
of material in this English version that Martin has actually written is limited
to the skeleton of one chapter, it was decided very early on that he would
have to retain co-authorship of the book. Without him, the German version
would have never been possible, and without that, there would also not be
this English version.

There has never been an equal distribution of the work and task load for this
project.
There has always been an unspoken understanding of both of us
contributing in each one's way. Martin's strength has always been
crunching the heavy and difficult things into digestible chunks, and I had
often felt that I could contribute best by trying to make them presentable to
those who are not blessed with Martin's intellectual abilities. So, even under
more fortunate circumstances, I would have probably done quite a lot of the
polishing work that has gone into the English version anyway. In any case,
this does not diminish Martin's major role in the entire project, so his co-
authorship remains to be genuine even though this book will only appear
more than 7 years after his tragic and early death.
This book is directed at graduate students at the Master's level who have
knowledge and competencies in standard topics of theoretical computer
science, as is given in introductory courses on automata, formal languages,
formal logic and computational complexity, or can be found in standard
textbooks like the well-known ones by Hopcroft et al. for instance [HU80,
HMU01]. This book then delves deeper into
Preface
ix
the world of automata by presenting deeply rooted connections between
automata and logic along the lines of work started by B √ºchi and Rabin.
Also needless to say, such a project is hardly possible without the help of
many people who deserve to be acknowledged and thanked. Florian Bruse,
Lars-Eric Mar-quardt, S √∂ren M √∂ller proof-read a final draft version and
found many mistakes.
Peter Pashkin, Jannik Nordmeyer, Florian Redinger, Jamie Chen and Jiayu
Ma reported typos as well. √âtienne Lozes, Ulrich Sch √∂pp, Steffen Jost,
Krystian Kensy, Thomas Schwentick, Mirco Franzek and Michael Falk had
reported bugs in the original German version. √âtienne Lozes, Florian Bruse,
Daniel Kernberger and Norbert Hundeshagen gave lectures or tutorials for a

course on automata, logic and games at the University of Kassel that is
based on the content of this book and thus have provided suggestions,
exercises and fixes. Marco S√§lzer and Eric Alsmann gave tutorials for a
course on database theory, part of which is based on the material in Chapter
11
on automata on finite trees, and have similarly provided suggestions and
exercises.
Michael M √∂ller redrew some of the original figures using TikZ. I would
also like to thank the people at Springer for their support and also their
patience regarding a few requests for deadline extensions.
Kassel, Germany,
Martin Lange
March 2025
Contents
Part I Finite Words
1
Regular Languages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . .
3
1.1
Regular Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Nondeterministic Finite Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7
1.3
Deterministic Finite Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.4
Decidability and Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . .
17
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . .
17
2
Monadic Second-Order Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. .
19
2.1
Syntax and Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.2

MSO-Definability and Regularity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
2.2.1
From Automata to Formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
2.2.2
From Formulas to Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
2.2.3
Consequences of the Translations . . . . . . . . . . . . . . . . . . . . . . .
30
2.3
The Complexity of MSO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.4
Weak Second-Order Logic of One Successor . . . . . . . . . . . . . . . . . . . .
36
2.5
Presburger Arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40

Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . .
43
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . .
44
3
Alternating Finite Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. .
47
3.1
Run Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
3.2
Expressiveness and Succinctness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
3.3
Closure Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
3.4
Reachability Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

58
3.4.1
Games, Plays and Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
3.4.2
Attractors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
3.4.3
Determinacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
3.4.4
Polynomial-Time Solvability . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
xi
xii
Contents
3.5
A Game-Theoretic Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . .

66
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . .
67
4
Star-Free Languages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. .
69
4.1
First-Order Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
4.2
Ehrenfeucht-Fra¬®ƒ±ss√© Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
4.2.1
Word-Comparison Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
4.2.2
Indistinguishability through First-Order Formulas . . . . . . . . .
75
4.3

Star-Free Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
4.4
First-Order Equals Star-Freeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
4.4.1
From Expressions to Formulas . . . . . . . . . . . . . . . . . . . . . . . . . .
80
4.4.2
From Formulas to Expressions . . . . . . . . . . . . . . . . . . . . . . . . . .
81
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . .
87
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . .
88
Part II Infinite Words
5
Automata on Infinite Words . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. .

93
5.1
Regular Languages of Infinite Words . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
5.1.1
Infinite Words . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
5.1.2
ùúî-Regular Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
5.2
Nondeterministic B √ºchi Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
5.3
Closure Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
5.3.1
Unions, Left-Concatenations and ùúî-Iterations . . . . . . . . . . . .
99
5.3.2

Intersections and Homomorphisms . . . . . . . . . . . . . . . . . . . . . . 102
5.4
Deterministic B √ºchi Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
105
5.5
Complementation Closure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
5.5.1
Ramsey's Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
5.5.2
B √ºchi's Complementation Construction . . . . . . . . . . . . . . . . . . 109
5.6
Monadic Second-Order Logic on Infinite Words . . . . . . . . . . . . . . . . . 114
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 116
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 117
6
Acceptance Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 121
6.1
Rabin- and Streett-Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
6.2

Parity Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
125
6.2.1
Priorities for Acceptance and Rejection . . . . . . . . . . . . . . . . . . 125
6.2.2
Parity vs. B √ºchi Acceptance . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
6.2.3
Parity vs. Rabin and Streett Acceptance . . . . . . . . . . . . . . . . . . 131
6.3
Muller Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
133
6.3.1
The Most General Acceptance Condition . . . . . . . . . . . . . . . . . 133
6.3.2
Muller vs. B √ºchi Acceptance . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
6.3.3
Muller vs. Parity Acceptance . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
6.4
Co-B √ºchi Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
143
6.5

Transition-Based Acceptance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
Contents
xiii
6.5.1
From States to Edges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
6.5.2
From Edges to States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
6.6
Expressiveness of Finite Automata on Infinite Words . . . . . . . . . . . . . 152
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 152
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 154
7
Determinisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 157
7.1
The Inadequacy of Powerset-Based Determinisation . . . . . . . . . . . . . . 157
7.2
Trees and K Àù
onig's Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160

7.2.1
A Formal Model of Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
7.2.2
Infinite Paths in Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
7.3
The Safra Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
163
7.3.1
Refining the Powerset Construction . . . . . . . . . . . . . . . . . . . . . . 164
7.3.2
Correctness of the Construction . . . . . . . . . . . . . . . . . . . . . . . . . 171
7.3.3
A Lower Bound on Complementation and Determinisation . 173
7.3.4
From NBA to DPA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 177
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 178
8
Decision Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 181

8.1
Automata Non-Emptiness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
182
8.1.1
Graphs and Strongly Connected Components . . . . . . . . . . . . . 182
8.1.2
Rabin and Parity Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
8.1.3
Streett Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
8.2
Universality and Subsumption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
8.2.1
From Subsumption to Universality . . . . . . . . . . . . . . . . . . . . . . 190
8.2.2
Universality as a Search Problem in Monoids . . . . . . . . . . . . . 193
8.3
An Application: Size-Change Termination . . . . . . . . . . . . . . . . . . . . . . 198
8.3.1
Recursive Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
8.3.2
Termination Analysis as B √ºchi Inclusion . . . . . . . . . . . . . . . . . 200

Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 204
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 205
9
Alternating B ¬®
uchi Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
9.1
Alternating Automata on Infinite Words . . . . . . . . . . . . . . . . . . . . . . . . 210
9.1.1
Syntax and Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
9.1.2
Memoryless Runs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212
9.2
A Game-Theoretic Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
217
9.2.1
B √ºchi Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
9.2.2
Acceptance as a Game . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
9.3

Expressiveness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
222
9.3.1
Alternation Elimination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223
9.3.2
Universal and Deterministic Automata . . . . . . . . . . . . . . . . . . . 225
9.4
Complementation via Alternating Automata . . . . . . . . . . . . . . . . . . . . . 227
9.5
Weak Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
233
xiv
Contents
9.5.1
Weak B √ºchi and co-B √ºchi Automata . . . . . . . . . . . . . . . . . . . . 233
9.5.2
Weak Parity Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 238
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 239
10

Linear-Time Temporal Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 241
10.1 Syntax and Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 242
10.1.1 Alphabets of Atomic Propositions . . . . . . . . . . . . . . . . . . . . . . . 242
10.1.2 Formulas Built from Temporal Operators . . . . . . . . . . . . . . . . 244
10.1.3 Temporal Equivalences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
10.1.4 Unfoldings of Temporal Operators . . . . . . . . . . . . . . . . . . . . . . 250
10.2 Nondeterministic B √ºchi Automata for LTL . . . . . . . . . . . . . . . . . . . . . .
252
10.2.1 Generalised B √ºchi Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . 252
10.2.2 From LTL to Generalised B √ºchi Automata . . . . . . . . . . . . . . . 254
10.3 From LTL to Very Weak Alternating Automata . . . . . . . . . . . . . . . . . .
260
10.4 An Application: Formal Verification . . . . . . . . . . . . . . . . . . . . . . . . . . .
268
10.4.1 Labelled Transition Systems and Traces . . . . . . . . . . . . . . . . . . 269
10.4.2 Model Checking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 274
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 275
Part III Trees

11
Automata on Finite Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 281
11.1 Finite Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 282
11.1.1 Trees and Tree Languages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
11.1.2 Two Different Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
11.2 Direction Bottom-Up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 286
11.2.1 Bottom-Up Tree Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286
11.2.2 Determinisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
11.2.3 Closure Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
11.3 Direction Top-Down . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 292
11.3.1 Top-Down Tree Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292
11.3.2 Expressiveness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
294
11.3.3 Decision Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
11.4 Monadic Second-Order Logic on Finite Trees . . . . . . . . . . . . . . . . . . .
300
11.5 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 304
11.5.1 Higher-Order Matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304

11.5.2 Tree Automata for XML Data Processing . . . . . . . . . . . . . . . . 308
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 311
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 312
Contents
xv
12
Parity Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 315
12.1 Games, Plays and Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 315
12.2 Basic Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 317
12.2.1 Games with no Particular Initial Node . . . . . . . . . . . . . . . . . . . 317
12.2.2 Uniform Winning Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
12.2.3 Priority Compression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
12.3 Winning Parity Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 322
12.3.1 Subgames . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
322
12.3.2 Positional Determinacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
12.4 Solving Parity Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 327

12.4.1 Theoretical Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327
12.4.2 A Recursive Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 328
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 332
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 334
13
Automata on Infinite Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 337
13.1 Parity Tree Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 338
13.1.1 Infinite Trees and Tree Languages . . . . . . . . . . . . . . . . . . . . . . . 338
13.1.2 B √ºchi Tree Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
13.1.3 Closure Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
13.2 Complementation Closure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
348
13.2.1 Acceptance as a Parity Game . . . . . . . . . . . . . . . . . . . . . . . . . . . 348
13.2.2 The Complementation Construction . . . . . . . . . . . . . . . . . . . . . 351
13.3 Decision Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 358
13.3.1 Non-Emptiness via Parity Games . . . . . . . . . . . . . . . . . . . . . . . 358
13.3.2 Complexity, Expressiveness and Consequences . . . . . . . . . . . 361
13.3.3 Finitely Representable Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361

Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 364
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 365
14
Logics on Infinite Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . 369
14.1 Monadic Second-Order Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
370
14.1.1 Syntax and Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
14.1.2 Capturing Paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371
14.1.3 Decidability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373
14.2 Full Branching-Time Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 375
14.2.1 Syntax and Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375
14.2.2 Decidability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 380
14.2.3 Expressiveness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
382
14.3 The Modal ùúá-Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 384
14.3.1 Modal Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
384
14.3.2 Fixpoint Quantifiers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
14.3.3 Syntax and Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390

14.3.4 Decidability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . 396
xvi
Contents
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . 399
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . 401
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . 405
Acronyms
ABA
alternating B √ºchi automaton
AcoBA
alternating co-B √ºchi automaton
AFA
alternating finite automaton
APA
alternating parity automaton
APA
alternating parity tree automaton

BFS
breadth-first search
‚àó
CTL
full branching-time computation tree logic
DAG
directed acyclic graph
DBA
deterministic B √ºchi automaton
DbuTA
deterministic bottom-up tree automaton
DcoBA
deterministic co-B √ºchi automaton
DFA
deterministic finite automaton
DFS
depth-first search
DMA
deterministic Muller automaton
DNF

disjunctive normal form
DPA
deterministic parity automaton
DPAe
deterministic edge-based parity automaton
DPTA
deterministic parity tree automaton
DRA
deterministic Rabin automaton
DRAe
deterministic edge-based Rabin automaton
DSA
deterministic Streett automaton
DSO
dyadic second-order logic
DtdTA
deterministic top-down tree automaton
FO
first-order logic
GNBA

generalised nondeterministic B √ºchi automaton
Lùúá
modal ùúá-calculus
LAR
latest appearance record
LTL
linear-time temporal logic
LTS
labelled transition system
ML
modal logic
MSO
monadic second-order logic
xvii
xviii
Acronyms
NBA
nondeterministic B √ºchi automaton
NBAe
nondeterministic edge-based B √ºchi automaton

NbuTA
nondeterministic bottom-up tree automaton
NBTA
nondeterministic B √ºchi tree automaton
NcoBA
nondeterministic co-B √ºchi automaton
NcoBAe
nondeterministic edge-based co-B √ºchi automaton
NFA
nondeterministic finite automaton
NMA
nondeterministic Muller automaton
NMAe
nondeterministic edge-based Muller automaton
NNF
negation normal form
NPA
nondeterministic parity automaton
NPAe
nondeterministic edge-based parity automaton

NPTA
nondeterministic parity tree automaton
NRA
nondeterministic Rabin automaton
NRAe
nondeterministic Rabin automaton
NSA
nondeterministic Streett automaton
NTA
nondeterministic (finite) tree automaton
NSAe
nondeterministic Streett automaton
NtdTA
nondeterministic top-down tree automaton
PA
Presburger arithmetic
PSL
property specification language
REGŒ£
class of regular languages over alphabet Œ£

S1S
second-order logic of one successor (function)
SCC
strongly connected component
SFŒ£
class of star-free languages over alphabet Œ£
sNMA
symbolic nondeterministic Muller automaton
SnS
second-order logic of ùëõ successor (functions)
UBA
universal B √ºchi automaton
UcoBA
universal co-B √ºchi automaton
VWABA
very weak alternating B √ºchi automaton
WABA
weak alternating B √ºchi automaton
WAcoBA
weak alternating co-B √ºchi automaton

WAPA
weak alternating parity automaton
WNBA
weak nondeterministic B √ºchi automaton
WS1S
weak second-order logic of one successor (function)
Part I
Finite Words
Chapter 1
Regular Languages
We start by repeating some fundamental concepts from the theory of formal
languages, in particular regular languages. Throughout this book we use the
convention that N denotes the set of natural numbers beginning with 0. For
ùëò ‚àà N, [ùëò ] denotes the interval {0, . . . , ùëò ‚àí 1} .
1.1 Regular Expressions
Let Œ£ = {ùëé, ùëè, . . .} be a finite alphabet. A finite word over Œ£ is a sequence
ùë§ =
ùëé

. . . ùëé
0
ùëõ‚àí1 with ùëéùëñ ‚àà Œ£ for ùëñ ‚àà [ùëõ]. We write ‚à£ùë§‚à£ for the length of ùë§, i.e. ùëõ in this
case, and ùë§(ùëñ) for its ùëñ-th symbol ùëéùëñ. The empty word, i.e. the sequence of
length 0, is written as ùúÄ. Œ£‚àó denotes the set of all (finite) words over Œ£, and
Œ£+ denotes the set of all non-empty finite words over Œ£. The concatenation
of two words ùë§ and ùë£ is simply written as ùë§ùë£, it denotes the sequence that
is obtained by first iterating through ùë§
and then through ùë£, i.e. (ùë§ùë£)(ùëñ) = ùë§(ùëñ) if 0 ‚â§ ùëñ < ‚à£ùë§‚à£ and (ùë§ùë£)(ùëñ) = ùë£(ùëñ ‚àí
‚à£ùë§‚à£) if
‚à£ùë§‚à£ ‚â§ ùëñ < ‚à£ùë§‚à£ + ‚à£ùë£‚à£.
A language ùêø is a set of words, i.e. a subset of Œ£‚àó. This introduces all the
usual set-theoretic operations like union, intersection, complement,
difference, etc. into the world of formal languages. The complement of a
language ùêø is typically written as ùêø, and it is defined as Œ£‚àó ‚àñ ùêø.
Other important operations on languages are concatenation (lifted from
words) and the Kleene closure, also known as Kleene iteration or the
Kleene star. If ùêø1
and ùêø
ùêø
ùë§
2 are languages over Œ£ then so is their concatenation ùêø1
2 ‚à∂= {ùë§1
2 ‚à£ ùë§1 ‚àà
ùêø

, ùë§
1
2 ‚àà ùêø2} that results from concatenating arbitrary words from ùêø1 with
arbitrary words from ùêø2 .
‚àó
For a language ùêø its Kleene closure is the language ùêø ‚à∂= {ùë§ . . . ùë§
1
ùëõ ‚à£ ùëõ ‚àà N, ùë§ùëñ ‚àà
ùêø for all ùëñ = 1, . . . , ùëõ}. It results from concatenating ùêø with itself an
arbitrary but
‚àó
finite number of times. Note that ùëõ = 0 is possible in this construction,
hence, ùúÄ ‚àà ùêø
for any ùêø ‚äÜ Œ£‚àó. Another, yet equivalent, way of defining the Kleene
closure makes its constituent parts more explicit:
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
3
https://doi.org/10.1007/978-3-662-72154-4_1
4
1 Regular Languages

0
ùëñ+1
ùëñ
‚àó
ùëñ
ùêø
‚à∂= {ùúÄ} ,
ùêø
‚à∂= ùêø ùêø
,
ùêø
‚à∂= ‚ãÉ ùêø
ùëñ‚àà N
We are particularly interested in one class of formal languages, namely the
regular ones over some alphabet Œ£, denoted REGŒ£. If Œ£ is clear from
context, we also simply Œ£‚àó
write REG. Note that REGŒ£ ‚äÜ 2
as it is a set of sets of finite w ords.
Definition 1.1
Œ£‚àó
The class REGŒ£ is the smallest set C ‚äÜ 2

that satisfies the following
two conditions.
a) ‚àÖ ‚àà REG Œ£ and {ùëé} ‚àà REG Œ£ for any ùëé ‚àà Œ£.
‚àó
b) Whenever ùêø , ùêø
ùêø
1
2 ‚àà REGŒ£ then ùêø1 ‚à™ ùêø2 ‚àà REGŒ£ , ùêø1
2 ‚àà REGŒ£ and ùêø
‚àà REG Œ£.
1
Here, smallest class means that no language which is not covered by either
of the two cases belongs to REGŒ£. Hence, a language ùêø belongs to REGŒ£
only if it is of either of the forms listed under (a), or it is built according to
either of the constructions listed under (b). The latter means that there need
to be languages ùêø1 (and ùêø2) for which it is already known that they belong
to REGŒ£. Put differently, every regular language can be constructed in a
finite number of steps from the languages listed in (a) using the operations
in (b). Moreover, any language that cannot be constructed in this way is not
regular.
Example 1.2 The set ùêø of all words over the alphabet {ùëé, ùëè} in which
every ùëé is eventually succeeded by some ùëè is regular. To see this, it is
helpful to characterise this differently: no word in ùêø can end on the letter ùëé.
Since the alphabet only contains two letters, ùêø consists of all words that
either end on ùëè or are empty. Hence, we have

‚àó
ùêø
= {ùúÄ} ‚à™ (({ùëé} ‚à™ {ùëè}) {ùëè}) .
‚àó
It remains to be seen that {ùúÄ} is a regular language. This is the case since
{ùúÄ} = ‚àÖ
according to the comment made above.
When giving a formal description of a (regular) language we try to omit
parentheses for better readability. We introduce the convention that the
unary operation of Kleene closure takes precedence over the binary
operations, and that concatenation takes precedence over union. We also
omit curly braces around singleton sets. Then
‚àó
the language ùêø of the previous example is also simply written as ùúÄ ‚à™ (ùëé ‚à™
ùëè) ùëè. An even cleaner way of obtaining a neat description of regular
languages is to introduce regular expressions.
Definition 1.3 Let Œ£ be an alphabet. Regular expressions over Œ£ are given
by the following grammar.
‚àó
ùõº
‚à∂= ‚àÖ ‚à£ ùëé ‚à£ ùõº + ùõº ‚à£ ùõºùõº ‚à£ ùõº
The language ùêø(ùõº) of a regular expression ùõº is defined straightforwardly as
ùêø (‚àÖ) ‚à∂= ‚àÖ
ùêø (ùõº + ùõΩ) ‚à∂= ùêø(ùõº) ‚à™ ùêø(ùõΩ)

ùêø (ùëé) ‚à∂= {ùëé}
ùêø (ùõº ùõΩ) ‚à∂= ùêø(ùõº)ùêø(ùõΩ)
‚àó
‚àó
ùêø (ùõº ) ‚à∂= (ùêø(ùõº))
1.1 Regular Expressions
5
Thus, every regular expression defines a regular language in a natural way.
The minimality condition in Def. 1.1 guarantees that every regular language
can also be described by a regular expression.
The literature contains both the use of '+' and '‚à™' in regular expressions to
denote unions. We will use either of them, whatever is more convenient in
that moment.
We will also often drop the strict distinction between an expression and the
language
‚àó
‚àó
defined by it writing, for example ùêø = (ùëé + ùëè) ùëè instead of ùêø = ùêø((ùëé + ùëè)
ùëè).
It is easy to see that every finite set of words is a regular language; it can be
written in the form ùë§1 + . . . + ùë§ùëõ, using only unions of concatenations of
singleton letters (and possibly the empty word).
Condition (b) in Def. 1.1 means that REGŒ£ is closed under the operations
of union, concatenation and Kleene star, i.e. applying these operations to

members of the class can never yield non-members of this class. REGŒ£ is
furthermore closed under several other operations, in particular the usual
set-theoretic ones. This is not easy to see, in particular closure under the
complement operation does not exactly follow directly from Def. 1.1. Once
this is shown, closure under other operations follows immediately. For
instance, closure under intersections would then simply be a consequence of
the deMorgan law ùêø1 ‚à© ùêø2 = ùêø1 ‚à™ ùêø2.
Note that the class of regular languages is not closed under infinitary
unions, for otherwise every language would be regular since any language
can be written as a possibly infinite union of finite languages, for instance
as {ùë§1} ‚à™ {ùë§2} ‚à™ . . . by simply enumerating all its words.
Another closure result is quite easily obtained through reasoning about
regular expressions, though.
Definition 1.4 Let Œ£, Œî be alphabets and ‚Ñé ‚à∂ Œ£ ‚Üí Œî‚àó a mapping called a
morphism.
It is extended homomorphically to a mapping ÀÜ
‚Ñé ‚à∂ Œ£‚àó ‚Üí Œî‚àó via
ÀÜ
‚Ñé(ùúÄ)
‚à∂= ùúÄ
,
ÀÜ
‚Ñé(ùëéùë£)
‚à∂= ‚Ñé(ùëé) ÀÜ
‚Ñé( ùë£)

for any ùëé ‚àà Œ£, ùë£ ‚àà Œ£‚àó. Consequently, ÀÜ
‚Ñé is called a homomorphism (induced by ‚Ñé).
Œ£‚àó
Œî ‚àó
It is extended even further homomorphically to a mapping ÀÜ
‚Ñé ‚à∂ 2
‚Üí 2
via
ÀÜ
‚Ñé(ùêø)
‚à∂= { ÀÜ
‚Ñé(ùë§) ‚à£ ùë§ ‚àà ùêø} .
We do not distinguish notationally between a homomorphism on words and
on languages. The type will always be clear from the context.
It is often said that the class of regular languages is closed under
homomorphisms which is not correct, strictly speaking. Since
homomorphisms may map languages over one alphabet into another, a more
precise formulation is the following one.
Theorem 1.5 Let Œ£, Œî be alphabets, ‚Ñé ‚à∂ Œ£ ‚Üí Œî‚àó a morphism and ÀÜ‚Ñé its
induced homomorphism. For any ùêø ‚àà REG Œ£ we have ÀÜ
‚Ñé(ùêø) ‚àà REG Œî .
Proof Let ùêø ‚àà REGŒ£, i.e. there is a regular expression ùõº over Œ£ such that ùêø
= ùêø(ùõº).

By induction on the structure of regular expressions we create an expression
ÀÜ
‚Ñé(ùõº)
6
1 Regular Languages
such that ùêø( ÀÜ
‚Ñé(ùõº)) = ÀÜ
‚Ñé(ùêø(ùõº)). In fact, ÀÜ
‚Ñé(ùõº) is simply obtained as the homomorphic
extension of ‚Ñé to regular expressions, i.e.
ÀÜ
‚Ñé(‚àÖ) ‚à∂= ‚àÖ
ÀÜ
‚Ñé(ùõº + ùõΩ) ‚à∂= ÀÜ
‚Ñé(ùõº) + ÀÜ
‚Ñé(ùõΩ)
ÀÜ
‚Ñé(ùëé) ‚à∂= ‚Ñé(ùëé)
ÀÜ
‚Ñé(ùõº ùõΩ) ‚à∂= ÀÜ

‚Ñé(ùõº) ÀÜ
‚Ñé(ùõΩ)
ÀÜ
‚àó
‚àó
‚Ñé(ùõº ) ‚à∂= ( ÀÜ
‚Ñé( ùõº))
for any ùëé ‚àà Œ£.
A straightforward induction shows that ùêø( ÀÜ
‚Ñé(ùõº)) = ÀÜ
‚Ñé(ùêø(ùõº)) holds indeed for any
ùõº. In the first base case we have ùõº = ‚àÖ. Then ùêø( ÀÜ
‚Ñé(‚àÖ)) = ùêø(‚àÖ) = ‚àÖ = ÀÜ
‚Ñé(‚àÖ) =
ÀÜ
‚Ñé(ùêø(‚àÖ). Note that in the first term, ÀÜ
‚Ñé is the syntactical mapping on expressions
while the last two occurrences of ÀÜ
‚Ñé denote the semantical function on languages. In
the second base case we have ùõº = ùëé for some ùëé ‚àà Œ£. Then ùêø( ÀÜ

‚Ñé(ùëé)) = ùêø(‚Ñé(ùëé)) =
{‚Ñé(ùëé)} = { ÀÜ
‚Ñé(ùëé)} = ÀÜ
‚Ñé({ùëé}) = ÀÜ
‚Ñé(ùêø(ùëé)) by the homomorphic nature of both v ersions
of ÀÜ
‚Ñé.
Then there are three step cases. First, let ùõº = ùõΩ1 + ùõΩ2. Then
ùêø ( ÀÜ
‚Ñé(ùõΩ1 + ùõΩ2)) = ùêø( ÀÜ‚Ñé(ùõΩ1) + ÀÜ‚Ñé(ùõΩ2)) = ùêø( ÀÜ‚Ñé(ùõΩ1)) ‚à™ ùêø( ÀÜ‚Ñé(ùõΩ2))
= ÀÜ
‚Ñé(ùêø(ùõΩ1)) ‚à™ ÀÜ‚Ñé(ùêø(ùõΩ2)) = ÀÜ‚Ñé(ùêø(ùõΩ1) ‚à™ ùêø(ùõΩ2))
= ÀÜ
‚Ñé(ùêø(ùõΩ 1 + ùõΩ2))
by the definition of the syntactical ÀÜ
‚Ñé, the induction hypothesis (twice), and then basic
properties of the semantical ÀÜ
‚Ñé.
Next, let ùõº = ùõΩ ùõΩ
1

2. Then
ùêø ( ÀÜ
‚Ñé(ùõΩ ùõΩ
1
2))
= ùêø( ÀÜ
‚Ñé(ùõΩ1) ÀÜ‚Ñé(ùõΩ2)) = ùêø( ÀÜ‚Ñé(ùõΩ1))ùêø( ÀÜ‚Ñé(ùõΩ2))
= ÀÜ
‚Ñé(ùêø(ùõΩ
ùõΩ
1)) ÀÜ
‚Ñé(ùêø(ùõΩ2)) = ÀÜ‚Ñé(ùêø(ùõΩ1)ùêø(ùõΩ2)) = ÀÜ‚Ñé(ùêø( ùõΩ1 2))
in the same way.
‚àó
Finally, let ùõº = ùõΩ . Then
‚àó
‚àó
‚àó
ùêø ( ÀÜ
‚Ñé(ùõΩ ))

= ùêø(( ÀÜ
‚Ñé(ùõΩ)) )
= (ùêø( ÀÜ
‚Ñé(ùõΩ)))
‚àó
‚àó
‚àó
= ( ÀÜ
‚Ñé(ùêø(ùõΩ)))
= ÀÜ
‚Ñé((ùêø(ùõΩ)) )
= ÀÜ
‚Ñé( ùêø(ùõΩ ))
again by basic properties of both the syntactical and the semantical ÀÜ
‚Ñé
and the
induction hypothesis.
‚óª
So instead of saying that "the class of regular languages is closed under
homomorphisms" it would be more precise to say that homomorphisms

map languages from one class of regular ones to another. On the other hand,
a morphism ‚Ñé of type Œ£
‚Ä≤
‚Üí Œî‚àó for two different alphabets Œ£, Œî can always be seen as a morphism ‚Ñé
of
‚àó
‚Ä≤
type Œ£ ‚à™ Œî ‚Üí (Œ£ ‚à™ Œî) by a straightforward extension: ‚Ñé (ùëé) = ‚Ñé(ùëé) if ùëé ‚àà
Œ£, and
‚Ä≤
‚Ä≤
‚Ñé (ùëé) = ùëé if ùëé ‚àà Œî. It should be clear that the homomorphisms induced by
‚Ñé and ‚Ñé
behave in the same way on languages over Œ£. Hence, there is little need to
be too
1.2 Nondeterministic Finite Automata
7
thorough in distinguishing homomorphism closure of some class from
mappings between two classes in this case.
In order to obtain closure under complements (and perhaps further
interesting operations) we need a different characterisation of the class of
regular languages that turns out to be equivalent to the algebraic one in Def.
1.1, and which we recall in the following two sections.
1.2 Nondeterministic Finite Automata

Finite automata can be used to - as the name suggests - finitely represent
regular languages which are, in general, infinite objects.
Definition 1.6 A nondeterministic finite automaton (NFA) is an A = (ùëÑ, Œ£,
ùëû , ùõø, ùêπ
ùêº
)
with
‚Ä¢ a finite state set ùëÑ,
‚Ä¢ an input alphabet Œ£,
‚Ä¢ an initial state ùëûùêº ‚àà ùëÑ,
‚Ä¢
ùëÑ
a transition function ùõø ‚à∂ ùëÑ √ó Œ£ ‚Üí 2
and
‚Ä¢ a set of final or accepting states ùêπ ‚äÜ ùëÑ .
A run of A on a word ùë§ = ùëé . . . ùëé
. . . ùëû
0
ùëõ‚àí1 is a sequence ùúå = ùëû0
ùëõ s.t. ùëû0 = ùëû ùêº and for
all ùëñ ‚àà [ùëõ] we have ùëû

, ùëé
ùëñ+1 ‚àà ùõø(ùëûùëñ
ùëñ ). The run ùúå is called accepting if ùëû ùëõ ‚àà ùêπ . We call
ùêø (A) ‚à∂= {ùë§ ‚àà Œ£‚àó ‚à£ there is an accepting run of A on ùë§} the language
accepted by A. A language ùêø is called NFA-recognisable if ùêø = ùêø(A) for
some NFA A.
The association of a language with an NFA immediately yields an
equivalence relation on NFA: we call two NFA A1 and A2 equivalent,
whenever ùêø(A1) = ùêø(A2).
We assume that they are defined over the same alphabet. The name
equivalence is justified as two equivalent automata simply are two possibly
different syntactical representations of the same languag e.
We need a measure of size of such a representation in order to measure the
efficiency of algorithms that use automata as representations of languages.
For an NFA A with state set ùëÑ we simply define its size as ‚à£A‚à£ ‚à∂= ‚à£ùëÑ‚à£.
Note that this is not entirely accurate: the space needed to write down A is
generally dominated by the ùëÑ
size of its transition function ùõø ‚à∂ ùëÑ √ó Œ£ ‚Üí 2 . It can equally be represented as
a
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
relation ùõø ‚äÜ ùëÑ √ó Œ£ √ó ùëÑ: we have (ùëû, ùëé, ùëû ) ‚àà ùõø iff ùëû ‚àà ùõø(ùëû, ùëé). We will
make use of this correspondence and use both kinds of notation
interchangeably. Seeing ùõø as a finite relation, i.e. a set of tuples, makes the

term ‚à£ùõø‚à£ well-defined; it simply counts the number of transitions. Note that
this is still not an accurate measure for the space needed to write down ùõø, for
example as a table with three columns, as each element connects two states
via an alphabet symbol, and the space needed to write down a state is at
least O(log ‚à£ùëÑ‚à£). Moreover, we clearly have ‚à£ùõø‚à£ ‚àà O(‚à£ùëÑ‚à£2) in general only.
Hence, even though using ‚à£ùëÑ‚à£ as the size of an NFA is not an accurate
measure for
8
1 Regular Languages
32
33
ùëé
ùëé
ùëé
ùëé
ùëè
21
22
23
24
ùëè
ùëé

ùëé
ùëé
ùëé
ùëè
ùëè
ùëè
11
14
ùëè
ùëè
ùëé
ùëé
ùëè
01
02
03
04
ùëé
ùëé
ùëè

Fig. 1.1 Example NFA.
the real space needed to represent it, it is a measure that is easy to handle
and is accurate up to a small polynomial.
NFAs can be drawn as node- and edge-labelled directed graphs. The states
form
‚Ä≤
‚Ä≤
the graph's nodes, and a transition (ùëû, ùëé, ùëû ) is drawn as an edge from ùëû to
ùëû that is labelled with ùëé. The initial state is usually marked by an unlabelled
incoming edge, emerging out of nowhere; final states are marked using
double lines. An example of an NFA is shown in Fig. 1.1. We leave it as an
exercise to determine its language and to find an equivalent NFA with four
states only that recognises the same language.
The main theorem in the theory of regular languages states that a language
is regular iff it can be recognised by an NFA. It is therefore sensible to ask
whether the constructions under which regular languages are obviously
closed, namely union, concatenation and Kleene star, can be executed
directly on NFA. We will show how to do this exemplarily for the Kleene
star; the other cases are left as exercises.
Theorem 1.7 Let A, A ,
1 A2 be NFA over some alphabet Œ£ .
‚à™
‚à™
‚à™
a) There is an NFA A s.t. ùêø(A ) = ùêø(A1) ‚à™ ùêø(A2) and ‚à£A ‚à£ ‚â§ ‚à£A1‚à£ + ‚à£A2‚à£
+ 1 .

b) There is an NFA A; s.t. ùêø(A;) = ùêø(A1)ùêø(A2) and ‚à£A;‚à£ ‚â§ ‚à£A1‚à£ + ‚à£A2‚à£ +
1 .
‚àó
‚àó
‚àó
‚àó
c) There is an NFA A s.t. ùêø(A ) = ùêø(A) and ‚à£A ‚à£ ‚â§ ‚à£A‚à£ + 1 .
Proof We only show (c). The parts (a) and (b) are similar and left as
exercises. Let
‚Ä≤
‚Ä≤
A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
). Take a new state ùëû s.t. ùëû /
‚àà ùëÑ. Let
ùêº
ùêº
‚àó
‚Ä≤
‚Ä≤
‚àó

‚Ä≤
A
‚à∂= (ùëÑ ‚à™ {ùëû }, Œ£, ùëû , ùõø , ùêπ ‚à™ {ùëû })
ùêº
ùêº
ùêº
‚Ä≤
where for all ùëé ‚àà Œ£ and all ùëû ‚àà ùëÑ ‚à™ {ùëû } we have
ùêº
1.2 Nondeterministic Finite Automata
9
‚éß
‚Ä≤
‚é™ùõø
, ùëé
,
‚é™ (ùëû ùêº
)
, if ùëû = ùëû
‚é™

ùêº
‚é™
‚àó
ùõø
(ùëû, ùëé)
‚à∂= ‚é®ùõø(ùëû, ùëé) ‚à™ ùõø(ùëû , ùëé
ùêº
)
, if ùëû ‚àà ùêπ ,
‚é™
‚é™
‚é™
‚é™ùõø
‚é© (ùëû, ùëé)
, if ùëû ‚àà ùëÑ ‚àñ ùêπ .
‚àó
Hence, states in A have the same outgoing transitions as their
correspondents in A with the only exception that final states also inherit the
outgoing transitions of the original initial state. The new initial state is a
copy of the old one that is not reachable from any other state.
‚àó

‚àó
It remains to be seen that ùêø(A ) = ùêø(A) . For the "‚äÜ"-part assume that ùë§ ‚àà
‚àó
ùêø (A ) for some ùë§ = ùëé . . . ùëé
1
ùëõ
‚àà Œ£‚àó. Then we must have some accepting run
‚Ä≤
‚àó
ùëû
, ùëû
, . . . , ùëû
on ùë§. From the observation above we immediately get that
ùêº
1
ùëõ
of A
there are ùëñ , ùëñ , . . . , ùëñ
. . .
0

1
ùëö s.t. 0 = ùëñ0 < ùëñ1
< ùëñùëö = ùëõ and for all ùëó = 1, . . . , ùëö we have that
ùëû
, . . . , ùëû
. . . ùëé
ùëñ
ùëñ
is an accepting run of A on ùëéùëñ
ùëñ
. Hence, this run partitions
ùëó ‚àí1
ùëó
ùëó ‚àí1 +1
ùëó
ùë§ into ùë£ . . . ùë£
. . . ùëé
1
ùëö with ùë£ ùëó = ùëéùëñ
ùëñ

for each ùëó = 1, . . . , ùëö. Then ùë£ ùëó ‚àà ùêø(A) for
ùëó ‚àí1 +1
ùëó
‚àó
each such ùëó , thus, ùë§ ‚àà ùêø(A) .
‚àó
‚àó
For the "‚äá"-part take some ùë§ ‚àà ùêø(A) . If ùë§ = ùúÄ then clearly ùë§ ‚àà ùêø(A )
since
‚àó
‚àó
A 's initial state is final, so A accepts ùúÄ. So suppose that ùë§ ‚â† ùúÄ. Hence, there
is a partition ùë§ = ùë£ . . . ùë£
1
ùëö s.t. ùë£ùëñ ‚â† ùúÄ and ùë£ùëñ ‚àà ùêø(A) for all ùëñ = 1 , . . . , ùëö.
‚àó
We now show by induction on ùëö that ùë§ ‚àà ùêø(A ). Note that the base case of
ùëö = 0 has already been proven since ùë§ = ùúÄ if ùëö = 0. So suppose that ùëö > 0
and
‚àó
‚Ä≤
‚àó

ùë£
. . . ùë£
, ùëû
, . . . , ùëû
1
ùëö‚àí1 ‚àà ùêø(A ), i.e. there is an accepting run ùúå = ùëû
on
ùêº
1
ùëò
of A
‚Ä≤
ùë£
. . . ùë£
, . . . , ùëù
1
ùëö‚àí1. Since ùë£ ùëö ‚àà ùêø(A) there is also an accepting run ùúå
= ùëù0
‚Ñì
of A

on ùë£ùëö. We have, in particular, ùëù0 = ùëûùêº , ùëù‚Ñì ‚àà ùêπ and ‚Ñì ‚â• 1, since ùë£ùëö ‚â† ùúÄ.
But then
‚Ä≤
‚Ä≤
ùëû
, ùëû
, . . . , ùëû
, ùëù
, . . . , ùëù
(but leaving out its
ùêº
1
ùëò
1
‚Ñì , obtained by concatenating ùúå with ùúå
‚àó
‚àó
first state), is an accepting run of A
on ùë£ . . . ùë£
, ùë£

1
ùëö , as we have ùëù1 ‚àà ùõø (ùëû ùëò
ùëö (0))
because ùëù
, ùë£
1 ‚àà ùõø(ùëû ùêº
ùëö (0)).
‚óª
The proof above suggests that the size of the resulting NFA, for example for
‚àó
ùêø (A) , is always exactly ‚à£A‚à£ + 1 instead of just at most that. The
formulation in the theorem however, using inequality, is based on the
observation that during the
‚àó
course of constructing A one may discover that certain states of A are
unreachable and therefore unnecessary or that some can be discarded using
minimisation. A may also be structured in a way that makes it unnecessary
to add a new initial state but instead re-use the old one.
Later we will need the fact that the class of NFA-recognisable languages is
closed under further operations, in particular intersections.
Theorem 1.8
‚à©
Let A ,

1 A2 be NFA over some alphabet Œ£ . There is an NFA A s.t.
‚à©
‚à©
ùêø (A ) = ùêø(A1) ‚à© ùêø(A2) and ‚à£A ‚à£ ‚â§ ‚à£A1‚à£ ‚ãÖ ‚à£A2‚à£ .
Proof
ùëñ
‚à©
Let A
, Œ£, ùõø , ùëû , ùêπ
ùëñ
= (ùëÑùëñ
ùëñ
‚à∂=
ùêº
ùëñ ) for ùëñ ‚àà {1, 2}. Define their product NFA as A
(ùëÑ
, Œ£, ùõø,
, ùëû2
1 √ó ùëÑ2
(ùëû1

), ùêπ
ùêº
ùêº
1 √ó ùêπ2) with
((ùëû , ùëû
, ùëù
, ùëé, ùëù
, ùëé, ùëù
1
2), ùëé, ( ùëù1
2)) ‚àà ùõø
iff
(ùëû1
1) ‚àà ùõø1 and (ùëû2
2) ‚àà ùõø2
‚à©
for all ùëû , ùëù
, ùëù
1
1 ‚àà ùëÑ1, ùëû2

2 ‚àà ùëÑ2 and ùëé ‚àà Œ£. The claim about A 's size should be clear.
‚à©
It remains to be seen that ùêø(A ) = ùêø(A1) ‚à© ùêø(A2).
10
1 Regular Languages
"‚äá" Suppose ùë§ ‚àà ùêø(A1) ‚à© ùêø(A2), i.e. ùë§ ‚àà ùêø(A1) and ùë§ ‚àà ùêø(A2). Then
there are accepting runs ùúå
, . . . , ùëû1
, . . . , ùëû2
1 = ùëû1
0
ùëõ
of A1 and ùúå2 = ùëû2 0
ùëõ
of A2 on ùë§. Note
that they are of equal length ùëõ + 1 if ùëõ = ‚à£ùë§‚à£. Moreover, ùëû1 = ùëû1 , ùëû2 = ùëû2
, ùëû1 ‚àà ùêπ
0
ùêº
0
ùêº

ùëõ
1
and ùëû2 ‚àà ùêπ
, ùëû2 ), . . . , (ùëû1 , ùëû2 )
ùëõ
2. Consider the sequence ùúå = (ùëû1
obtained by zipping
0
0
ùëõ
ùëõ
the pair of sequences of states ùúå1 and ùúå2 into a sequence of pairs of states.
We
‚à©
observe that it starts in A 's initial state (ùëû1 , ùëû2 ), it ends in one of its final
states ùêº
ùêº
‚à©
since (ùëû1 , ùëû2 ) ‚àà ùêπ
ùëõ
ùëõ

1 √ó ùêπ2, and it follows A 's transition function ùõø on the letters of
‚à©
‚à©
ùë§ . Hence, ùúå is an accepting run of A on ùë§ and therefore we ha ve ùë§ ‚àà ùêø(A
).
‚à©
"‚äÜ" This is shown analogously by unzipping an accepting run of A into
accepting runs of A1 and A2.
‚óª
Next we recall the fundamental result that the class of languages
recognisable by NFA coincides exactly with the class of regular languages.
I.e. for every NFA A we have that ùêø(A) is regular and, vice-versa, for every
regular language ùêø there is an NFA A s.t. ùêø = ùêø(A). The second part is quite
easy to see, in fact the main constructions have already been given in Thm.
1.7. We therefore leave a formal proof as an ex ercise.
Theorem 1.9 For every regular language ùêø there is an NFA A s.t. ùêø(A) = ùêø
.
For the other direction we need some more machinery. There are various
ways of showing regularity of an NFA-recognisable language. One of them
uses the following result, known as Arden's Lemma.
Theorem 1.10
‚àó
Let ùëà, ùëâ , ùêø ‚äÜ Œ£‚àó s.t. ùúÄ /
‚àà ùëà and ùêø = ùëà ùêø ‚à™ ùëâ . Then ùêø = ùëà ùëâ .

Proof
‚àó
"‚äÜ" Suppose ùë§ ‚àà ùêø. We show that ùë§ ‚àà ùëà ùëâ by induction on ‚à£ùë§‚à£. In the
base case, suppose that ‚à£ùë§‚à£ = 0, i.e. ùë§ = ùúÄ. Note that if ùúÄ /
‚àà ùëà then ùúÄ /
‚àà ùëà ùêø either. Since
‚àó
ùêø = ùëà ùêø ‚à™ ùëâ and ùë§ = ùúÄ we therefore must have ùë§ ‚àà ùëâ . But since ùúÄ ‚àà ùëà
we have
‚àó
‚àó
ùëâ ‚äÜ ùëà ùëâ and therefore ùë§ ‚àà ùëà ùëâ .
Now suppose that ‚à£ùë§‚à£ > 0. Since ùêø = ùëà ùêø ‚à™ùëâ we can have that ùë§ ‚àà ùëà ùêø
or ùë§ ‚àà ùëâ . In
‚àó
the latter case we get ùë§ ‚àà ùëà ùëâ just like in the base case above. Therefore
we assume that ùë§ ‚àà ùëà ùêø. Since ùúÄ /
‚àà ùëà, there must be ùë¢, ùë£ ‚àà Œ£‚àó s.t. ùë§ = ùë¢ùë£, ùë¢ ‚àà ùëà and ùë£ ‚àà ùêø.
By assumption we have that ùë¢ ‚â† ùúÄ, so therefore we have ‚à£ùë£‚à£ < ‚à£ùë§‚à£ and we
can apply
‚àó
+

‚àó
‚àó
the induction hypothesis to ùë£ and get that ùë£ ‚àà ùëà ùëâ . Now note that ùëà
= ùëàùëà
‚äÜ ùëà
‚àó
‚àó
‚àó
and therefore ùëàùëà ùëâ ‚äÜ ùëà ùëâ . Moreover, since ùë§ = ùë¢ùë£ and ùë¢ ‚àà ùëà, ùë£ ‚àà ùëà
ùëâ we have
‚àó
‚àó
ùë§ ‚àà ùëàùëà ùëâ and therefore ùë§ ‚àà ùëà ùëâ .
‚àó
‚àû
ùëñ
‚àó
‚àû
ùëñ
"‚äá" Remember that ùëà

= ‚ãÉ
ùëà
ùëâ = ‚ãÉ
ùëà ùëâ
ùëñ
, hence ùëà
. We show by induction
=0
ùëñ=0
ùëñ
‚àó
on ùëñ that ùëà ùëâ ‚äÜ ùêø for all ùëñ ‚àà N which then yields ùëà ùëâ ‚äÜ ùêø.
First, we have ùëà0 = {ùúÄ} and therefore ùëà0ùëâ = ùëâ . So we get ùëà0ùëâ ‚äÜ ùêø
simply because ùêø ‚äá ùëâ which follows immediately from ùêø = ùëà ùêø ‚à™ ùëâ .
ùëñ+
Now consider ùëà
1ùëâ for some ùëñ ‚â• 0. By associativity of concatenation we have
ùëñ+
ùëñ
ùëñ

ùëà
1ùëâ = ùëà(ùëà ùëâ ), and the inductive hypothesis yields ùëà ùëâ ‚äÜ ùêø. Hence,
whenever ùëñ+
ùëñ
ùë§ ‚àà ùëà
1ùëâ then ùë§ can be decomposed into ùë§ = ùë¢ùë£ s.t. ùë¢ ‚àà ùëà and ùë£ ‚àà ùëà ùëâ which
yields ùë£ ‚àà ùêø. By ùêø = ùëà ùêø ‚à™ ùëâ we also have ùêø ‚äá ùëà ùêø, and now we have
that ùë§ = ùë¢ùë£ ‚àà ùëà ùêø, so ùëñ+
ùë§ ‚àà ùêø. Hence, ùêø ‚äá ùëà
1ùëâ as well.
‚óª
1.2 Nondeterministic Finite Automata
11
This gives us a tool for successively constructing a regular expression for
the language of a given NFA. The trick is to view an NFA with ùëõ states as a
system of ùëõ recursive equations for formal languages, and then to use
Arden's Lemma to solve this system of equations.
Theorem 1.11 For every NFA A we have that ùêø(A) is regular.
Proof Let ùêø = ùêø(A) for some NFA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
). W.l.o.g. we assume that
ùëÑ = {0, . . . , ùëõ ‚àí 1} and ùëûùêº = 0.

For every ùëñ ‚àà [ùëõ], let ùëãùëñ be the language of all words accepted by the NFA
Aùëñ = (ùëÑ, Œ£, ùëñ, ùõø, ùêπ ), i.e. the one resulting from A by making ùëñ the initial
state.
Clearly, ùêø = ùëã0. These languages can be defined recursiv ely via
‚éß
‚é™
‚é™{ùúÄ}
, if ùëñ ‚àà ùêπ ,
ùëãùëñ
= ( ‚ãÉ
‚ãÉ
{ùëé}ùëã ùëó ) ‚à™ ‚é®
‚é™‚àÖ
,
ùëé‚ààŒ£ ùëó ‚àà ùõø(ùëñ, ùëé)
‚é™
otherwise.
‚é©
Using some obvious equivalences on languages like ùëà ùëâ
ùëâ
1

‚à™ ùëà2
= (ùëà1 ‚à™ ùëà2)ùëâ and
successive applications of Arden's Lemma it is possible to eliminate
recursion from these equations and eventually construct a regular
expression for all ùëãùëñ, in particular ùëã0, thus showing that ùêø is regular.
‚óª
Example 1.12 Consider the language ùêø of the following NFA.
ùëé
ùëè
ùëé
1
ùëé
0
ùëè
2
ùëé
3
The corresponding system of equations is the following.
ùëã0 = ùëé ùëã1 ‚à™ ùëè ùëã2
(i)
ùëã1 = ùëé ùëã0

(ii)
ùëã2 = ùëé ùëã3 ‚à™ ùëè ùëã0 ‚à™ {ùúÄ}
(iii)
ùëã3 = ùëé ùëã 2
(iv)
We can replace ùëã3 in (iii) by its right-hand side from (iv) which yields the
following.
ùëã2 = ùëéùëé ùëã2 ‚à™ ùëè ùëã0 ‚à™ ùúÄ
(v )
By Arden's Lemma we get a definition of ùëã2 that does not use recursion, at
least not directly.
‚àó
ùëã2 = (ùëéùëé) (ùëè ùëã0 ‚à™ ùúÄ)
(vi)
Using its right-hand side to replace ùëã2 in (i) and doing so likewise for ùëã1
with (ii) yields
‚àó
‚àó
‚àó
ùëã
ùëè

0 = ùëéùëé ùëã0 ‚à™ ùëè(ùëéùëé) (ùëè ùëã0 ‚à™ ùúÄ) = (ùëéùëé ‚à™ ùëè(ùëéùëé)
)ùëã0 ‚à™ ùëè(ùëéùëé)
using some simplifications that allow us to apply Arden's Lemma again for
ùëã0 to finally obtain
12
1 Regular Languages
‚àó
‚àó
‚àó
ùëã
ùëè
ùëè
0 = (ùëéùëé ‚à™ ùëè(ùëéùëé)
)
(ùëéùëé)
which gives us a regular expression for ùëã0 and, hence, for ùêø.
1.3 Deterministic Finite Automata
Nondeterministic automata are not very suitable for showing that the class
of regular languages is closed under complements. The problem lies with
the existential quantification in the definition of acceptance by an NFA: ùë§
‚àà ùêø(A) iff there is an accepting run of A on ùë§. Hence, ùë§ ‚àà ùêø(A) iff every
run of A on ùë§ is not accepting.

However, this universal quantification is not something that is built into the
definition of NFA in general, unless it happens to coincide with existential
quantification, i.e.
whenever "there is" and "for all" expresses the same property. This is
generally the case whenever the entities under consideration (here the runs)
always exist uniquely.
This takes us to the definition of a determinis tic automaton.
Definition 1.13 An NFA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
0
) is a deterministic finite automaton
(DFA) if for all ùëû ‚àà ùëÑ and ùëé ‚àà Œ£ we have that ‚à£ùõø(ùëû, ùëé)‚à£ = 1.
The following lemma formalises the key insight into the workings of a DFA
as hinted at above: words in a DFA have unique runs. The proof is left as an
exercise.
Lemma 1.14 Let A be a DFA over Œ£ and ùë§ ‚àà Œ£‚àó . Then there is a unique
run ùúå of A on ùë§ .
It is convenient to see the transition function of a DFA as being of type ùëÑ
√óŒ£ ‚Üí ùëÑ.
Moreover, it is also possible to relax the definition and to require ‚à£ùõø(ùëû, ùëé)‚à£ ‚â§
1 only, i.e. states in a DFA may also be allowed not to have any successor
under some alphabet symbol. It is always possible to transform such a DFA
into one that satisfies the stronger requirement of Def. 1.13 by adding one
more s tate.
DFA are easy to complement, as the next theorem shows.
Theorem 1.15 For any DFA A there is a DFA A s.t. ùêø(A) = ùêø(A) and ‚à£A‚à£
= ‚à£A‚à£ .

Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, ùõø, ùëÑ
ùêº
). Define A ‚à∂= (ùëÑ, Œ£, ùëûùêº
‚àñ ùêπ ). It should be clear
that A is also a DFA, and that it is of the same size as A. It remains to be
seen that ùêø (A) = ùêø(A).
"‚äÜ" Suppose ùë§ ‚àà ùêø(A) for some ùë§ ‚àà Œ£‚àó. Take the unique run ùúå = ùëû , . . .
, ùëû
0
ùëõ
of
A on ùë§ according to Lemma 1.14. By assumption, we must have ùëûùëõ ‚àà ùëÑ ‚àñ
ùêπ since ùë§ must end in an accepting state of A which is any state in ùëÑ ‚àñ ùêπ.
Since A and A have the same initial state and, most of all, same transition
functions, ùúå is also a run of A on ùë§, and it does not end in an accepting state
of A. According to Lemma 1.14, there can be no other run of A on ùë§ and so
we have ùë§ /
‚àà ùêø(A), resp. ùë§ ‚àà ùêø(A).
"‚äá" Suppose ùë§ ‚àà ùêø(A), i.e. ùë§ /
‚àà ùêø(A). Likewise, the unique run of A on ùë§ must
not end in ùêπ, so it ends in ùëÑ ‚àñ ùêπ, and it is therefore an accepting run of A
on ùë§, witnessing the fact that ùë§ ‚àà ùêø(A).

‚óª
1.3 Deterministic Finite Automata
13
The simplicity of the complementation construction is not the only reason
for considering DFA separately from NFA. There are also applications, in
particular games and tree automata as discussed in Part III, that require
deterministic automata for some purpose. A natural and important question
arising with Def. 1.13 is therefore: is the model of DFA genuinely weaker
than that of NFA or can any regular language also be accepted by a DFA?
The answer to this question lies in the famous powerset construction that
transforms any NFA into an equivalent DFA thus showing that the class of
regular languages are not only captured by NFA but also by DFA.
Theorem 1.16
‚à£A ‚à£
For any NFA A there is a DFA D s.t. ùêø(D) = ùêø(A) and ‚à£D‚à£ ‚â§ 2
.
Proof
ùëÑ
‚Ä≤
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, Œ£,
ùêº
) be an NFA. Define D ‚à∂= (2
{ùëû ùêº }, Œî, ùêπ ) where,

for each ùëÜ ‚äÜ ùëÑ and every ùëé ‚àà Œ£ we ha ve
Œî(ùëÜ, ùëé) ‚à∂= ‚ãÉ ùõø(ùëû, ùëé) ,
ùëû‚ààùëÜ
‚Ä≤
and ùêπ ‚à∂= {ùëÜ ‚äÜ ùëÑ ‚à£ ùêπ ‚à© ùëÜ ‚â† ‚àÖ}.
It should be clear that D is indeed a DFA: when reading symbol ùëé in state
ùëÜ, it takes a transition into a unique successor state, even though this is
defined as the union of state sets in A. Note that states in D are sets of states
in A. Moreover, the size estimation on D is also clear. It only remains to be
seen that ùêø(D) = ùêø(A) holds.
"‚äá" Suppose ùë§ = ùëé , . . . , ùëé
, . . . , ùëû
0
ùëõ‚àí1 ‚àà ùêø(A) and ùúå = ùëû0
ùëõ is an accepting run of
A on ùë§. Since D is deterministic there is a unique run ùúé = ùëÜ , . . . , ùëÜ
0
ùëõ of D on ùë§. We
show that ùëûùëñ ‚àà ùëÜùëñ for all ùëñ = 0, . . . , ùëõ. This is rather obvious for ùëñ = 0 since
ùëÜ0 = {ùëû 0}
by construction.
Now suppose that ùëû

, ùëé
ùëñ
‚àà ùëÜùëñ for some ùëñ < ùëõ. Note that ùëûùëñ+1 ‚àà ùõø(ùëûùëñ
ùëñ )
because a
run in A must follow A's transitions. But then we have ùëû
ùõø
ùëñ+1 ‚àà ùëÜùëñ+1 = ‚ãÉ
(ùëû, ùëé
ùëû‚ààùëÜ
ùëñ )
ùëñ
since ùëûùëñ is one of these states ùëû ‚àà ùëÜùëñ. Hence, eventually we get ùëûùëõ ‚àà ùëÜùëõ.
But ùúå is
‚Ä≤
accepting, so ùëûùëõ ‚àà ùêπ and therefore ùëÜùëõ ‚à© ùêπ ‚â† ‚àÖ, i.e. ùëÜùëõ ‚àà ùêπ . So ùúé is
accepting as well and theref ore ùë§ ‚àà ùêø(D).
"‚äÜ" Suppose ùë§ = ùëé , . . . , ùëé
, . . . , ùëÜ
0
ùëõ‚àí1 ‚àà ùêø(D), i.e. the unique run ùúé = ùëÜ0

ùëõ
of D
‚Ä≤
on ùë§ is accepting which entails that ùëÜùëõ ‚àà ùêπ , resp. ùëÜùëõ ‚à© ùêπ ‚â† ‚àÖ. I.e. there
is some ùëû ‚àà ùëÜ
, . . . , ùëû
ùëõ s.t. ùëû ‚àà ùêπ . Our aim is to construct an accepting run ùúå = ùëû0
ùëõ of A on ùë§,
and we will do this from back to front, i.e. starting with ùëûùëõ. For this we
choose the state ùëû that we just identified to be an accepting state in A. We
also need to note that ùëû ùëõ ‚àà ùëÜùëõ.
Now suppose that ùëûùëñ for some ùëñ > 0 has already been picked from ùëÜùëñ.
Remember that ùëÜ
ùõø
ùëñ
= ‚ãÉ
(ùëû, ùëé
ùëû‚ààùëÜ
ùëñ‚àí
ùëñ‚àí1
1). I.e. ùëûùëñ ‚àà ùëÜùëñ does not hold for no reason, instead it can

only be included in ùëÜùëñ if it is an ùëéùëñ‚àí1-successor of some state ùëû ‚àà ùëÜùëñ‚àí1. So
if ùëûùëñ ‚àà ùëÜùëñ has already been selected, we can select some ùëéùëñ‚àí1-predecessor
ùëûùëñ ‚àà ùëÜùëñ‚àí1 and continue doing so until ùëû0 ‚àà ùëÜ0 has been selected. But ùëÜ0
= {ùëûùêº }, so ùëû0 = ùëûùêº showing that every back-to-front construction of such a
run ùúå must eventually end in A's initial state ùëûùêº . Since ùëûùëñ is an ùëéùëñ‚àí1-
successor of ùëûùëñ‚àí1 iff ùëûùëñ‚àí1 is an ùëéùëñ‚àí1-predecessor of ùëûùëñ
for all ùëñ = 1, . . . , ùëõ, and ùëûùëõ ‚àà ùêπ, the run ùúå constructed in this way is in fact
accepting for A and we have ùë§ ‚àà ùêø(A).
‚óª
14
1 Regular Languages
The converse direction - DFA-recognisable languages are NFA-
recognisable -
is of course trivial since every DFA is an NFA. Hence, we have that a
language is regular iff it is NFA-recognisable iff it is DFA-recognisable. An
important consequence of this is the aforementioned closure of the class of
regular languages under complements, resulting from the combination of
Thm. 1.16 and 1.15.
Corollary 1.17 Let ùêø ‚äÜ Œ£‚àó be regular. Then ùêø is regular .
Hence, for any regular language that is accepted by some NFA with ùëõ states
we can construct an NFA for its complement by going through DFA. This
comes with a blowup in size, though. The number of states of the
complement automaton can ùëõ
only be bounded by 2 , and it is possible to show that this is asymptotically
optimal.
ùëõ

Also note that 2 is only an upper bound. The powerset construction can be
carried out on-the-fly, starting with the initial state and then only adding
reachable successor ùëÑ
states, rather than constructing the transition table for the entire 2 . This
leads to smaller DFA in general. For example, when the NFA to be
determinised happens to be deterministic then the on-the-fly procedure
simply returns its input and thus causes no blowup in this case.
1.4 Decidability and Complexity
Automata play a main role in decision procedures for logics which get
reduced to questions about automata. To this end, we define or recall the
most important decision problems on automata. These are not bound to the
models of NFA and DFA that have occurred so far; these questions can
equally be stated for any other automaton model to be introduced in the
remainder of this book. In fact, it is helpful to regard these questions as
effectively being about languages, and automata only serve as finite
representations of these potentially infinite objects, so that algorithmic
questions about such languages become well-defined.
The word problem or membership problem is the following.
given: a language ùêø (in the form of an automaton for example) over an
alphabet Œ£ and a word ùë§ ‚àà Œ£‚àó
decide: is ùë§ ‚àà ùêø ?
The emptiness problem is the following.
given: a language ùêø
decide: is ùêø = ‚àÖ?
The universality problem is the following.
given: a language ùêø over some alphabet Œ£

decide: is ùêø = Œ£‚àó ?
The inclusion or subsumption problem is the following.
1.4 Decidability and Complexity
15
given: two languages ùêø , ùêø
1
2 over a common alphabet
decide: is ùêø1 ‚äÜ ùêø2 ?
The equivalence problem is the following.
given: two languages ùêø , ùêø
1
2 over a common alphabet
decide: is ùêø1 = ùêø2 ?
It should be clear that the computational complexity of these problems may
depend on the formalism used to represent languages. For example, the
universality problem for NFA is PSpace-complete, i.e. it most likely
requires exponential time to be decided. But the universality problem for
DFA can be decided in polynomial time (in fact even in nondeterministic
logarithmic space). So it would in fact be better to consider these problems
as being parametrised by a class of automata. This is in fact what we will do
in the following, for instance considering the emptiness problem for a
specific automaton model. Here, however we focus on the interplay
between these problems, and chosen representation formalisms are less
relevant for such considerations.

We assume familiarity with standard time and space complexity classes like
NLogSpace, P, NP, PSpace, ExpTime, ExpSpace, 2ExpTime, etc. and the
role of complements in the form of co-C classes like co-NLogSpace.
Another class that plays a certain role in the following chapters, especially
when introducing Monadic Second-Order Logic, is Elementary, consisting
of all problems that can be solved by an algorithm running in time
O(1)
ùëõ
2
‚ã∞
22
ùëò
for some fixed ùëò , on inputs of size ùëõ.
A third remark on the definition of these decision problems is concerned
with the underlying language-theoretic objects, namely words as finite
sequences of alphabet symbols. In Parts II and III we present a theory of
automata and its applications for extensions thereof, namely infinite words,
finite and infinite trees. The decision problems stated above still play the
same roles; however, they clearly need to be rephrased slightly. For
instance, the universality problem for automata operating on infinite words
is then to decide whether ùêø = Œ£ ùúî instead of ùêø = Œ£‚àó, since that is the
(notation used for the) set of all infinite words over the alphabet Œ£.
The last remark concerns the exact formulation of these problems with
regards to what counts as a positive or a negative answer. It would be more
accurate to say that it is not the emptiness problem for automata which is
used to solve the most fundamental problem for logics, the satisfiability
problem, but in fact the nonemptiness problem, asking whether ùêø ‚â† ‚àÖ for
some given ùêø. The problems of non-universality and non-inclusion are
obtained in an analogous way .

We will allow ourselves not to distinguish too rigorously between a
problem and its complement problem. Especially when we are concerned
with solutions in the form of deterministic algorithms there is no need for a
separation, as any algorithm solving one of them can easily be modified to
solve the corresponding other one by simply
16
1 Regular Languages
swapping yes/no answers. However, when allowing nondeterministic
algorithms one needs to be a bit more careful in the distinction between
such variants, as done in the formulation of the following result for
instance: non-emptiness is in NLogSpace, and emptiness is therefore in co-
NLogSpace.
Theorem 1.18 The non-emptiness problem for NFA is in NLogSpace.
Proof The key is to see that the language of an NFA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
0
) is non-
empty iff there is a path from ùëû0 to some ùëû ùëì ‚àà ùêπ in the transition graph of
A where edge labels are ignored. Such a path forms an accepting run on
some word, and for the non-emptiness problem the exact word witnessing
non-emptiness is irrelevant.
Moreover, we need to see that such a path exists iff there is a path of length
at most
‚à£ùëÑ‚à£; any path longer than that would have to be of the form ùëû , . . . , ùëû, . . .
, ùëû, . . . , ùëû
0
ùëì

for some ùëû ‚àà ùëÑ and could be shortened by cutting out the loop from ùëû to ùëû.
Then a nondeterministic algorithm only needs to store a state ùëû and a
counter value ùëê, initially ùëû = ùëû0 and ùëê = 0. It then accepts if ùëû ‚àà ùêπ, and
rejects if ùëê = ‚à£ùëÑ‚à£. Otherwise
‚Ä≤
it replaces ùëû by some successor ùëû ‚àà ùõø(ùëû, ùëé) for some ùëé ‚àà Œ£ and increments
ùëê. It should be clear that this algorithm terminates and can
nondeterministically find a path of length at most ‚à£ùëÑ‚à£ if one exists. The
space needed is indeed logarithmic only since a counter of value at most
‚à£ùëÑ‚à£ needs at most ‚åàlog ‚à£ùëÑ‚à£‚åâ many bits, and a state can equally be stored as a
number from {0, . . . , ‚à£ùëÑ‚à£ ‚àí 1}.
‚óª
This proof of course uses the standard argument for showing that the graph
reachability problem is in NLogSpace. In fact, one could have argued
directly that non-emptiness for NFA is just an instance of graph reachability.
Moreover, it is then easy to see that non-emptiness (and therefore also
emptiness) can be solved in deterministic linear time O(‚à£A‚à£), using
standard algorithms like depth- or breadth-first search.
The word problem for NFA can be solved in a similar style. The proof of
the following theorem is left as an exercise.
Theorem 1.19 The word problem for NFA is in NLogSpace.
The other problems listed above are equally decidable for NFA.
Theorem 1.20 Universality, inclusion and equivalence for NFA are in
PSpace.
Proof We consider the inclusion problem first. Suppose NFA A1 and A2 are
given.

Note that ùêø(A1) ‚äÜ ùêø(A2) iff ùêø(A1) ‚à© ùêø(A2) = ‚àÖ. According to Cor. 1.17,
ùêø(A2) can be recognised by an NFA, for instance through the powerset
construction on A2, switching accepting and non-accepting states. At last,
Thm. 1.8 shows that it is possible to construct an NFA for ùêø(A1) ‚à© ùêø(A2)
whose size is linear in the size of A1 and exponential in the size of A2 .
Hence, inclusion can be solved by an exponential reduction to the
emptiness problem for NFA which belongs to co-NLogSpace, according to
Thm. 1.18. Moreover, this reduction can be carried out on-the-fly, i.e. there
is no need to construct the entire NFA for ùêø(A1) ‚à© ùêø(A2) first and then to
analyse its emptiness. Instead, the nondeterministic algorithm from Thm.
1.18 can be used so that it constructs successor
Exercises for Chapter 1
17
states in the product automaton of A1 and the powerset automaton of A2
on-the-fly.
The space needed for this is logarithmic in the size of this product
automaton, which in turn is exponential in the size of the input, i.e. the
space needed is polynomial only. According to Savitch's Theorem we have
NPSpace = PSpace and therefore also co-NPSpace = PSpace which finishes
the argument for the inclusion problem.
It is then easy to see that universality and equivalence are in PSpace as well.
For equivalence this is the case because ùêø(A1) = ùêø(A2) iff ùêø(A1) ‚äÜ ùêø(A2)
and ùêø (A2) ‚äÜ ùêø(A1), i.e. equivalence can be checked by two successive
inclusion checks which can still be done in polynomial space. For
universality this is the case because ùêø (A) = Œ£‚àó iff Œ£‚àó ‚äÜ ùêø(A) and it is
easy to construct a (one-state) NFA recognising Œ£‚àó. Hence, universality is a
special case of inclusion.
‚óª
Bibliographic Notes

The theory of finite-state machines, aka finite automata, as language
acceptors in the sense of computability theory was started by Rabin and
Scott [RS59] who invented the powerset construction for instance. Since
then, regular languages and their theory, including logical and algebraic
aspects, have been studied extensively and the main results are covered in
many textbooks, for example by Hopcroft and Ullman [HU80], later with
Motwani [HMU01], Harrison [Har78], Sipser [Sip13], and many others.
The equivalence between different representational formalisms for regular
languages, in particular between finite automata and regular expressions, is
known as Kleene's Theorem [Kle56]. Arden's Lemma is - not surprisingly -
attributed to Arden
[Ard60].
One aspect of the study of regular languages and finite automata that is
seldomly covered in such textbooks but has some relevance for the
automata-logic connection outlined here, is concerned with lower bounds.
Meyer and Stockmeyer showed that the complexity of decision problems
regarding regular languages is highly dependent on the representation, in
particular, it becomes significantly more difficult from a computational
point of view when such formalisms includes operators like
complementation, intersection [MS73], squaring (in regular expressions)
[MS72].
An investigation into the complexities of formal-language problems,
depending on the representation formalism, is given in Stockmeyer's thesis
[Sto74].
Exercises
Exercise 1 Determine the regular language that is recognised by the NFA in
Fig. 1.1.
Construct an equivalent DFA with 4 states only.
Exercise 2 Prove parts (a) and (b) of Thm. 1.7.

18
1 Regular Languages
Exercise 3 Prove Thm. 1.9 by induction on the structure of a regular
language, making use of the constructions in Thm. 1.7.
Exercise 4 Consider the NFA A = ({0, 1, 2, 3}, {ùëé, ùëè}, 0, ùõø, {3}) with the
transition function ùõø given by ùõø(0, ùëé) = {1}, ùõø(0, ùëè) = {0, 3}, ùõø(1, ùëé) = {0},
ùõø(2, ùëé) = {3}, ùõø(3, ùëé) = {2} and ùõø(ùëû, ùëè) = ‚àÖ for ùëû ‚àà {1, 2, 3}. Use the
powerset construction from
‚Ä≤
‚Ä≤
Thm. 1.16 to build a DFA A s.t. ùêø(A ) = ùêø(A) .
Exercise 5 Prove Lemma 1.14. Hint: Note that this carries two obligations:
first show that for every word there is at least some run. Then assume that
there were two runs and show that they are equal componentwise.
Exercise 6
‚àó
ùëõ‚àí
Consider, for ùëõ ‚â• 1, the languages ùêø
ùëé
1
ùëõ
= (ùëé + ùëè)
(ùëé + ùëè)

of words
whose ùëõ-th last letter is an ùëé. Show that the following holds for any ùëõ ‚â• 1:
a) ùêøùëõ can be accepted by an NFA with at most ùëõ + 1 states.
ùëõ
b) Every DFA recognising ùêøùëõ must have at least 2 states.
Exercise 7 Prove Thm. 1.5 using NFA instead of regular expressions as
representation formalisms for regular languages.
Exercise 8 Show that the class REG is also closed under the following
operations.
a) differences: ùêø , ùêø
1
2 ‚àà REG ‚áí ùêø 1 ‚àñ ùêø 2 ‚àà REG
b) reversals
ùëõ
: ùêø ‚àà REG ‚áí {ùëé . . . ùëé 1 ‚à£ ùëé . . . ùëé
1
ùëõ ‚àà ùêø } ‚àà REG
c) inverse homomorphisms: let Œ£, Œî be alphabets, ‚Ñé ‚à∂ Œ£ ‚Üí Œî‚àó be a
morphism and ÀÜ
‚Ñé be the homomorphism induced by ‚Ñé. Show that for any such ‚Ñé ‚à∂ Œ£ ‚Üí Œî‚àó
we have: ÀÜ
‚Ñé (ùêø) ‚àà REGŒî ‚áí ùêø ‚àà REGŒ£.

Œ£‚àó
d) shuffle product: we define a mapping & ‚à∂ Œ£‚àó √ó Œ£‚àó ‚Üí 2
via
ùúÄ & ùë£
‚à∂= {ùë£}
ùëé ùë§ & ùëèùë£
‚à∂= {ùëé}(ùë§ & ùëèùë£) ‚à™ {ùëè}(ùëéùë§ & ùë£)
ùë§ & ùúÄ
‚à∂= { ùë§}
for any ùëé, ùëè ‚àà Œ£, ùë§, ùë£ ‚àà Œ£ ‚àó.
This shuffling operation can be extended to languages in a natural way.
ùêø
ùë§
1 & ùêø2
‚à∂=
‚ãÉ
‚ãÉ
& ùë£
ùë§ ‚ààùêø
ùë£

1
‚ààùêø2
Show that the following holds: ùêø , ùêø
1
2 ‚àà REG ‚áí ùêø1 & ùêø2 ‚àà REG.
Exercise 9 Prove Thm. 1.19.
Chapter 2
Monadic Second-Order Logic
This chapter introduces logic, in particular Monadic Second-Order Logic
over finite words. Familiarity with mathematical logic, typically in the form
of general First-Order Logic, is helpful but not strictly necessary for reading
this chapter. For those who are familiar with logic in general it is worth
noting that - throughout the entire book - the logics under consideration are
interpreted over structures of particular shape, for instance over finite words
only. This restriction has consequences in that generally invalid formulas
may become valid, like ‚àÄùë•.ùëé(ùë•) ‚à® ùëè(ùë•) saying that every element of the
domain of interpretation (here: position in a word) carries an ùëé or a ùëè.
Moreover, it is common to adjust the syntax of logics interpreted over
restricted domains to reflect parts of these structures. For example, with the
position in a word we usually associate a total order, and in order to enable
logics to formalise statements involving this ordering, we need to introduce
syntactic symbols whose interpretation is tied to this order.

2.1 Syntax and Semantics
The syntax of Monadic Second-Order Logic is similar to that of First-Order
Logic: it is built from atomic formulas formalising basic properties of the
elements of an underlying structure, using Boolean connectives and
quantification over such elements. Second-Order Logic generally also
allows quantification over relations between the elements of the structure,
but in the monadic fragment this is restricted to unary relations (i.e.
subsets).
Definition 2.1 Let Œ£ be an alphabet. Fix two countable and disjoint sets V1
=
{ùë•, ùë¶, . . .} of first-order variables and V2 = {ùëã, ùëå , . . .} of second-order
variables.
Formulas of Monadic Second-Order Logic (MSO) over Œ£-words are given
by the following grammar.
ùúë
‚à∂‚à∂= ùë• < ùë¶ ‚à£ ùëã (ùë•) ‚à£ ùëé(ùë•) ‚à£ ùúë1 ‚à® ùúë2 ‚à£ ¬¨ùúë ‚à£ ‚àÉùë• ùúë ‚à£ ‚àÉùëã ùúë
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
19
https://doi.org/10.1007/978-3-662-72154-4_2
20
2 Monadic Second-Order Logic
where ùëé ‚àà Œ£, ùë•, ùë¶ ‚àà V1 and ùëã ‚àà V2 .

Formulas of First-Order Logic (FO) over Œ£-words are obtained by
forbidding second-order variables and quantification over them in this
grammar.
Note that, theoretically, this defines one logic MSO per alphabet and pair of
variable sets. However, variables can be used interchangeably, and - as with
the definition of regular languages in the previous chapter - we will assume
that the underlying alphabet is fixed and clear from context. This is why we
simply speak of MSO instead of MSOŒ£ or something like that.
In general, we use lower case for first-order variables and upper case for
second-order ones. Sometimes, other objects like e.g. identifiers can be
used for the variables of either order. In this case the context must be used
for disambiguation.
Intuitively, the first-order variables range over positions in a word providing
the basis for an interpretation of MSO formulas to be either true or false,
and the second-order variables range over sets of positions. Then ùëé(ùë•)
intuitively states that the position currently denoted by ùë• carries the symbol
ùëé, and ùëã(ùë•) means that it belongs to the set that is associated with the set
variable ùëã. The other symbols have the usual meaning.
We use the following standard abbreviations.
‚àÄùë• ùúë
‚à∂= ¬¨‚àÉùë• ¬¨ùúë
ùë• ‚â§ ùë¶
‚à∂= ¬¨(ùë¶ < ùë•)
‚àÄùëã ùúë
‚à∂= ¬¨‚àÉùëã ¬¨ùúë
ùë• = ùë¶

‚à∂= ¬¨(ùë• < ùë¶ ‚à® ùë¶ < ùë•)
ùúë ‚àß ùúì
‚à∂= ¬¨(¬¨ùúë ‚à® ¬¨ùúì)
ùë• > ùë¶
‚à∂= ùë¶ < ùë•
ùúë ‚Üí ùúì
‚à∂= ¬¨ùúë ‚à® ùúì
tt ‚à∂= ‚àÉùë• ùë• = ùë•
ùúë ‚Üî ùúì
‚à∂= ( ùúë ‚Üí ùúì) ‚àß (ùúì ‚Üí ùúë)
ff ‚à∂= ¬¨tt
In order to save parentheses we also introduce the convention that ¬¨ binds
strongest, and that the binary operators take precedence in decreasing order
of ‚àß, ‚à®, ‚Üí, ‚Üî. We also introduce the notation ‚àÉùë•.ùúë, resp. ‚àÉùëã .ùúë where the
dot acts as a left parenthesis whose matching right counterpart is inserted as
far right as possible, i.e. at the unique rightmost position that still allows the
formula to be well-formed.
Example 2.2 Consider the formula
ùúë
.
odd
‚à∂= ‚àÉùë•ùêº ‚àÉùë•ùêπ (¬¨‚àÉùë¶.ùë¶ < ùë•ùêº ) ‚àß (¬¨‚àÉùë¶.ùë•ùêπ < ùë¶) ‚àß

‚àÉùëã . ùëã (ùë• ùêº ) ‚àß ùëã (ùë•ùêπ ) ‚àß
‚àÄùë• . ùëã (ùë•) ‚Üî ‚àÄùë¶.ùë• < ùë¶ ‚àß ¬¨‚àÉùëß (ùë• < ùëß ‚àß ùëß < ùë¶) ‚Üí ¬¨ùëã (ùë¶)
Intuitively, ùúëodd states that there are two positions in a word - called ùë•ùêº and
ùë•ùêπ -
s.t. there is none preceeding ùë•ùêº and none following ùë•ùêπ . Hence, ùë•ùêº and ùë•ùêπ
need to be bound to the first and last position in a word. It then continues to
state that there is a set ùëã of positions that contains both the first and last
position, and includes a position ùë• iff it does not include its successor ùë¶.
Note how we can make ùë¶ denote the successor of ùë• by stating that it comes
after ùë• and there is no position in between.
Altogether, ùúëodd therefore states that the underlying word has odd length.
2.1 Syntax and Semantics
21
Definition 2.3 An occurrence of a first- or second-order variable ùë• or ùëã in a
formula ùúë is bound if it appears in the scope of a quantifier ‚àÉùë•, resp. ‚àÉùëã in
the syntax tree of ùúë. Otherwise, the occurrence is free. A variable with at
least one free occurrence in a formula is called free. We also write ùúë(ùëã , . . . ,
ùëã , ùë• , . . . , ùë•
1
ùëõ
1
ùëö ) to indicate that
the free variables in ùúë belong to the set {ùëã , . . . , ùëã , ùë• , . . . , ùë•
1

ùëõ
1
ùëö }. A formula without
free variables is called a sentence or a closed formula.
Example 2.4 In the formula ¬¨‚àÉùë¶ ùë¶ < ùë• the variable ùë• is free and ùë¶ is
bound. In the formula ‚àÄùë•.(¬¨‚àÉùë¶ ùë¶ < ùë•) ‚Üí ùëã(ùë•) the variable ùëã is free and ùë•,
ùë¶ are both bound.
As usual, the meaning of a formula depends on the values of the free
variables it contains and it can be true or false depending on those values. A
sentence thus is true or false on its own, provided an interpretation for
formulas of the form ùëé(ùë•) is given for ùëé ‚àà Œ£. This will be done in the form
of a word ùë§ ‚àà Œ£‚àó. Bound variables can be renamed without changing their
meaning, e.g. ‚àÉùë• ùëã(ùë•) and ‚àÉùë¶ ùëã(ùë¶) are equivalent formulas, but ‚àÉùë• ùëã(ùë•)
and ‚àÉùë• ùëå (ùë•) are not.
We introduce further short-hand notation in the form of some special terms
which we can then be used just like first-order variables. This allows us to
refer to the first and last position in a word in a more readable way:
first(ùë•) ‚à∂= ¬¨‚àÉùë¶ ùë¶ < ùë•
last(ùë•) ‚à∂= ¬¨‚àÉùë¶ ùë¶ > ùë•
This is not restricted to terms containing a single free variable. Another
useful abbreviation will allow us to refer to adjacent positions in a word
more easily.
succ(ùë•, ùë¶) ‚à∂= ùë• < ùë¶ ‚àß ¬¨‚àÉùëß.ùë• < ùëß ‚àß ùëß < ùë¶
pred(ùë•, ùë¶) ‚à∂= succ (ùë¶, ùë•)
We can even introduce terms that refer more directly to the first, last or
some successor position. Suppose that ùúë(ùë•) is an arbitrary formula with a

free first-order variable ùë•.
We use the following abbreviations.
ùúë(0) ‚à∂= ‚àÉùë•. first(ùë•) ‚àß ùúë(ùë•)
ùúë(succ(ùë¶)) ‚à∂= ‚àÉùë•. succ(ùë¶, ùë•) ‚àß ùúë(ùë•)
ùúë(end) ‚à∂= ‚àÉùë•. last(ùë•) ‚àß ùúë(ùë•)
ùúë(pred(ùë¶)) ‚à∂= ‚àÉùë•. pred(ùë¶, ùë•) ‚àß ùúë(ùë•)
We use the constant symbol 0 here for the first position in a word is natural.
We can in fact refer to any position ùëò ‚àà N in a formula like ùúë(k), essentially
using unary representation:
k ‚à∂= succ(. . . succ(0) . . . )
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùëò times
It should be clear that we cannot do the same for the constant symbol end
whose interpretation then depends on an underlying word as words may
have different lengths and therefore different last positions. The reader is
invited to check the truth value of a formula ùúë(k) on words of length less
than ùëò .
Bearing all these conventions and abbreviations in mind, ùúëodd from above
can be rewritten in a more readable form as follows.
‚àÉùëã . ùëã (0) ‚àß ùëã (end) ‚àß ‚àÄùë•.ùëã (ùë•) ‚Üî ¬¨ùëã (succ(ùë•))
22
2 Monadic Second-Order Logic
We define the formal semantics of MSO formulas over Œ£ as a relation ‚äß
between interpretations and formulas. The former are pairs consisting of a

Œ£-word, providing information about which positions carry which letters in
order to interpret formulas of the form ùëé(ùë•), and assignments or valuations
providing an interpretation of the free variables of the formula under
consideration.
The overall goal is to show that MSO is yet another way of describing
regular languages. We will introduce a slight deviation, though: when using
words to interpret logical formulas we require the word to be non-empty.
This avoids strange effects that may occur when interpreting logical
formulas over empty domains: for example, tt should always be satisfied,
and we expect ‚àÉùë¶ ùúë to be equivalent to ùúë if ùë¶ is not a free variable of ùúë. But
‚àÉùë¶ tt would be false in the empty word.
The restriction to words in Œ£+ instead of Œ£‚àó is not a critical one. Note that
ùêø
‚àà REGŒ£ iff ùêø ‚àñ {ùúÄ} ‚àà REGŒ£. Note, though, that ùúÄ may of course occur as
a subword of a non-empty w ord.
Definition 2.5
[ùëõ]
Let ùë§ ‚àà Œ£+, ùëõ = ‚à£ùë§‚à£, and ùêº ‚à∂ (V1 ‚Üí [ùëõ]) + (V2 ‚Üí 2
) be an assign-
ment of the first-order variables to positions in ùë§ and the second-order
variables to sets of such positions.
We say that the interpretation of ùë§ and ùêº satisfies the MSO formula ùúë, if ùë§, ùêº
‚äß ùúë
holds according to the following rules.
ùë§ , ùêº ‚äß ùë• < ùë¶
iff

ùêº (ùë•) < ùêº (ùë¶)
ùë§ , ùêº ‚äß ùëã (ùë•)
iff
ùêº (ùë•) ‚àà ùêº (ùëã )
ùë§ , ùêº ‚äß ùëé(ùë•)
iff
ùë§ (ùêº (ùë•)) = ùëé
ùë§ , ùêº ‚äß ùúë ‚à® ùúì
iff
ùë§ , ùêº ‚äß ùúë or ùë§, ùêº ‚äß ùúì
ùë§ , ùêº ‚äß ¬¨ùúë
iff
ùë§ , ùêº /
‚äß ùúë
ùë§ , ùêº ‚äß ‚àÉùë• ùúë
iff
there is ùëñ ‚àà [ùëõ] such that ùë§, ùêº[ùë• ‚Ü¶ ùëñ] ‚äß ùúë
ùë§ , ùêº ‚äß ‚àÉùëã ùúë
iff
there is ùëÄ ‚äÜ [ùëõ] such that ùë§, ùêº[ùëã ‚Ü¶ ùëÄ] ‚äß ùúë

Here, ùêº[ùë• ‚Ü¶ ùëñ] is the function that maps ùë• to ùêº and behaves like ùêº on all
other arguments; similarly for ùêº[ùëã ‚Ü¶ ùëÄ].
Two formulas are equivalent, written ùúë ‚â° ùúì, if ùë§, ùêº ‚äß ùúë iff ùë§, ùêº ‚äß ùúì holds for any
word ùë§ and any assignment ùêº that fits ùë§ .
‚Ä≤
‚Ä≤
If ùúë is a sentence then ùë§, ùêº ‚äß ùúë iff ùë§, ùêº ‚äß ùúë for all assignments ùêº, ùêº . Thus, the
meaning of a sentence does not depend on the variable assignment and we
write ùë§ ‚äß ùúë instead of ùë§, ùêº ‚äß ùúë for some and, hence, for all ùêº. More generally,
ùë§, ùêº ‚äß ùúë iff
‚Ä≤
‚Ä≤
ùë§ , ùêº
‚äß ùúë holds whenever ùêº and ùêº agree on the free variables of ùúë - the meaning of
a formula ùúë thus depends only on the restriction of the assignment to its free
variables.
Therefore, it suffices to define satisfaction ùë§, ùêº ‚äß ùúë for finite, partial
assignments ùêº , for long as ùêº(ùë•), resp. ùêº(ùëã) is not undefined for any free
variable ùë•, resp. ùëã of ùúë. Also, we have ùúë ‚â° ùúì iff they agree on all pairs of
words and assignments of the smallest set of variables containing the free
variables of both of them.
A sentence ùúë of MSO over Œ£ then defines a language of words over Œ£ via ùêø
(ùúë) ‚à∂= {ùë§ ‚à£ ùë§ ‚äß ùúë}. A language ùêø ‚äÜ Œ£+ is MSO-definable if there is some
MSO
sentence ùúë s.t. ùêø(ùúë) = ùêø.
2.1 Syntax and Semantics

23
If ùë§, ùêº ‚äß ùúë holds for at least one interpretation (ùë§, ùêº) then ùúë is said to be
satisfiable. An interpretation (ùë§, ùêº) with ùë§, ùêº ‚äß ùúë is called a model of ùúë. Its
size is ‚à£ùë§‚à£. A formula that has no model is called unsatisfiable. A formula ùúë
such that ùë§ , ùêº ‚äß ùúë holds for all (ùë§, ùêº) is called valid. Notice that a formula ùúë is
valid if ¬¨ùúë is unsatisfiable.
A natural question that arises with this notion of (un-)satisfiability is: can
we decide automatically whether a given MSO formula is satisfiable? We
formulate this as a decision problem - called the satisfiability problem -
similar to those defined in Sect. 1.4 for NFA.
given: an MSO formula ùúë
decide: is ùúë satisfiable?
A weaker equivalence relation between formulas when compared to
semantical equivalence '‚â°' is only concerned with the existence of models:
two formula ùúë, ùúì are equi-satisfiable, if ùúë has a model iff ùúì has a model. Note
that satisfiability-preserving effective translations suffice to transfer the
decidability of the satisfiability problem of one logic to another.
Likewise the notion of equivalence gives rise to the equivalence problem:
given: MSO formulas ùúë and ùúì
decide: does ùúë ‚â° ùúì hold?
We observe that from a computational point of view, there is no need to
consider both problems separately.
Theorem 2.6 The satisfiability problem for MSO is decidable iff the
equivalence problem is decidable.
Proof Note that ùúë ‚â° ùúì iff ùúë ‚Üî ùúì is valid, i.e. ¬¨(ùúë ‚Üî ùúì) is unsatisfiable. This
yields a polynomial-time (and even logarithmic space) reduction from the
equivalence problem to the complement of the satisfiability problem.
Hence, if the latter is decidable then so is the former .

For the converse direction note that ùúë is unsatisfiable iff ùúë ‚â° ff.
‚óª
We remark that it is the unsatisfiability problem rather than the satisfiability
problem that is computationally equivalent to the equivalence problem. For
as long as we are only interested in decidability this makes no difference
and we could say that equivalence is decidable if satisfiability is. When not
just considering decidability but also computational complexity this could
of course make a difference and needs to be taken into consideration.
However, as we will see in Sect. 2.3, these two problems are of very high
complexity, and the difference between satisfiability and unsatisfiability is
not the real issue there.
In order to estimate the computational complexity of such problems for
MSO
(or in fact any logic) we need to measure the size of an input containing
formulas, i.e. we need a size measure on formulas. An obvious definition is
the length of a string representation of a formula. However, this can be
unnatural for formulas which contain parts that are reused multiple times
and then also lead to exponentially larger size measures. We therefore
measure the size of a formula in terms of the number of different
subformulas it contains.
24
2 Monadic Second-Order Logic
Definition 2.7 The set Sub(ùúë) of subformulas of an MSO formula ùúë is
inductively defined as follows.
Sub(ùë• < ùë¶) ‚à∂= {ùë• < ùë¶}
Sub(ùúë ‚à® ùúì) ‚à∂= {ùúë ‚à® ùúì} ‚à™ Sub(ùúë) ‚à™ Sub(ùúì)
Sub(ùëã (ùë•)) ‚à∂= {ùëã(ùë•)}

Sub(¬¨ùúë ‚à® ùúì) ‚à∂= {¬¨ùúë} ‚à™ Sub(ùúë)
Sub(ùëé(ùë•)) ‚à∂= {ùëé(ùë•)}
Sub(‚àÉùë• ùúë) ‚à∂= {‚àÉùë• ùúë} ‚à™ Sub(ùúë)
Sub(‚àÉùëã ùúë) ‚à∂= {‚àÉ ùëã ùúë} ‚à™ Sub(ùúë)
Then let ‚à£ùúë‚à£ ‚à∂= ‚à£ Sub(ùúë)‚à£ denote the size of ùúë.
We give a few more examples of MSO formulas, in fact FO formulas,
defining certain languages. The reader is also encouraged to check how
ùúëodd given above
+
defines {ùë§ ‚àà {ùëé, ùëè} ‚à£ ‚à£ùë§‚à£ is odd }.
Example 2.8 Let Œ£ = {ùëé, ùëè}. Let ùúë ‚à∂= ‚àÄùë• ¬¨(ùëé(ùë•) ‚àß ùëè(ùë•)). For every ùë§ ‚àà Œ£+
we have ùë§ ‚äß ùúë since no position can hold both an ùëé and a ùëè .
The formula ùúì ‚à∂= ‚àÄùë• ‚àÄùë¶.(ùëé(ùë•) ‚àß ùëè(ùë¶)) ‚Üí ùë• < ùë¶ does not hold for every word.
We have ùëéùëéùëéùëèùëèùëèùëè ‚äß ùúì, but ùëéùëéùëèùëéùëè /
‚äß ùúì because ùëéùëéùëèùëéùëè(2) = ùëè and ùëéùëéùëèùëéùëè(3) = ùëé
‚àó
‚àó
+
‚àó
‚àó
+

but of course 3 /
< 2. It defines the language ùëé ùëè
or, to be precise, ùëé ùëè ‚à™ ùëé ùëè .
Œ£‚àóùëéùëèŒ£‚àó is FO-definable by the formula ‚àÉùë• ‚àÉùë¶.ùëé(ùë•) ‚àß ùëè(ùë¶) ‚àß succ(ùë•, ùë¶).
Now let Œ£ = {ùëé, ùëè, ùëê}. The language comprising of all words ùë§ with the
property that each ùëé is eventually followed by a ùëè and between such ùëé and
the first subsequent ùëè there are only symbols ùëé (and no symbol ùëê) is FO-
definable by the following formula.
‚àÄùë• .ùëé(ùë•) ‚Üí ‚àÉùë¶.ùëè(ùë¶) ‚àß ùë• < ùë¶ ‚àß ‚àÄùëß.ùë• < ùëß ‚àß ùëß < ùë¶ ‚Üí ùëé (ùëß)
Remember the formula succ(ùë•, ùë¶) defined above using quantification and
reference to '<' in order to assert that ùë¶ is the successor of ùë•. It is possible
to introduce MSO
with succ(ùë•, ùë¶) as a primitive binary predicate in place of ùë• < ùë¶. This leads
to two (syntactically) different logics MSO[<] (as introduced in Def. 2.1)
and MSO[ succ]
with the corresponding modification. The reason for not distinguishing
betwen these two in the first place is the following result.
Theorem 2.9 A language ùêø is MSO[< ]-definable iff it is MSO[succ]-
definable.
Proof The right-to-left direction is trivial as any subformula succ(ùë•, ùë¶) of
some ùúë defining ùêø can be rewritten using '<' in the way shown to introduce
succ as an abbreviation. The other direction works in a similar way. It
suffices to show that ùë• < ùë¶
can be expressed in MSO[ succ]. This can be done as follow s.
ùë• < ùë¶

‚à∂= ‚àÄùëã .(‚àÄùë¢.‚àÄùë£. ùëã (ùë¢) ‚àß succ(ùë¢, ùë£) ‚Üí ùëã (ùë£)) ‚Üí ‚àÄùëß. succ(ùë•, ùëß)‚àß ùëã (ùëß) ‚Üí
ùëã (ùë¶) In other words, ùë• < ùë¶ if and only if every set that is closed under
successors and contains ùë•'s successor also contains ùë¶.
‚óª
Thm. 2.9 does not hold for FO: the two logics FO[<] and FO[ succ] do not
have the same expressive power; the former is genuinely more expressive
than the latter.
2.2 MSO-Definability and Regularity
25
In other words, the translation of ùë• < ùë¶ into a formula over succ does indeed
require second-order quantification as used in the proof of Thm. 2.9. By
convention, when we speak of FO we mean FO[<] .
2.2 MSO-Definability and Regularity
In this section we will show that the class of MSO-definable languages
coincides exactly with the class of regular languages.
2.2.1 From Automata to Formulas
We show that every NFA can be translated into an MSO formula defining
the same language.
Theorem 2.10 For every regular language ùêø over some alphabet Œ£ there is
an MSO
formula ùúëùêø such that ùêø(ùúëùêø ) = ùêø .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an NFA for ùêø. We assume that ùëÑ = {1, . . . , ùëõ} and

introduce second-order variables ùëã , . . . , ùëã
1
ùëõ
representing these states in the sense
that an assignment of ùëãùëû corresponds exactly to the sets of positions in
which A can be in state ùëû in an accepting run. Then ùúë
. . .
. . .
ùêø
can be constructed as ‚àÉùëã1
‚àÉùëãùëõ
so
that the existential quantification over sets of positions corresponds to the
existential quantification over runs in the definition of acceptance of a word
by an NFA.
Note that there is a slight mismatch: a run on a word ùë§ of length ùëõ has
length ùëõ + 1 itself. This can easily be remedied for example by not
demanding that the first position in a word belongs to the assignment of the
set corresponding to the initial state, but to one of its successors under the
first symbol in the word. Thus, ùëãùëû (ùëñ) should hold if A is in state ùëû after
processing ùë§(ùëñ). To that end we define the following auxiliary formulas
with free variables as indicated. Let X = (ùëã , . . . , ùëã
1
ùëõ ).

uniq(X) ‚à∂= ‚àÄùë• ‚ãÅ ùëãùëû (ùë•) ‚àß ‚ãÄ ¬¨ùëãùëû‚Ä≤ (ùë•)
ùëû‚ààùëÑ
ùëû‚Ä≤ ‚â†ùëû
init(X) ‚à∂= ‚ãÅ ùëé(0) ‚àß
‚ãÅ
ùëãùëû‚Ä≤ (0)
ùëé‚ààŒ£
ùëû‚Ä≤ ‚àà ùõø(ùëû , ùëé
ùêº
)
run(X) ‚à∂= ‚àÄùë• ‚àÄùë¶. succ(ùë•, ùë¶) ‚Üí ‚ãÄ ‚ãÄ (ùëã
ùëã
ùëû (ùë• ) ‚àß ùëé ( ùë¶ ) ‚Üí
‚ãÅ
ùëû‚Ä≤ ( ùë¶ ))
ùëû‚ààùëÑ ùëé‚ààŒ£
ùëû‚Ä≤ ‚àà ùõø(ùëû , ùëé)
acc(X) ‚à∂= ‚ãÅ ùëã ùëû (end)
ùëû‚ààùêπ
Note that ‚ãÅ

. . . ‚à∂= ff
ùëû‚àà‚àÖ
by convention. These formulas state, successively, that (i)
every position is "labelled" with a unique state, (ii) the first position is
labelled with a successor of A's initial state under the symbol at that
position, (iii) the labels at
26
2 Monadic Second-Order Logic
two successive positions agree with A's transition table, and (iv) the last
position is labelled with an accepting state.
We now put
ùúë
. . .
.
.
ùêø
‚à∂= ‚àÉùëã1
‚àÉùëãùëõ uniq(X) ‚àß init(X) ‚àß run(X) ‚àß acc(X)
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π
¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π
¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùúì(X)

Correctness of this formula follows from the following observation. Let ùë§
‚àà ùêø(A) and ùúå = ùëû , . . . , ùëû
0
ùëö
be an accepting run of A on ùë§. Hence, ùëû0 = ùëûùêº , ùëûùëö ‚àà ùêπ, and
ùëû
, ùë§
ùëñ+1 ‚àà ùõø(ùëûùëñ
(ùëñ)) for all ùëñ ‚àà [ùëö]. Consider the assignment ùêºùúå that assigns to each ùëãùëû to
the positions at which ùúå hits state ùëû (shifted by 1 to account for the problem
with the indices mentioned above): ùêº(ùëãùëû) ‚à∂= {ùëñ ‚àí 1 ‚à£ ùëûùëñ = ùëû}. It is then not
hard to see that ùë§, ùêºùúå ‚äß ùúì(X) because ùúå has all the properties formulated in
the four conjuncts in ùúì(X) under this interpretation for X. Hence, ùë§ ‚äß ùúëùêø .
Likewise, given any assignment for X satisfying these four conjuncts, it is
easily possible to extract a run (by adding ùëûùêº at the beginning) from it.
‚óª
Note that the passage from an NFA for ùêø to ùúëùêø is constructive.
2.2.2 From Formulas to Automata
We are now interested in the converse of the result just proved to the effect
that the language of an arbitrary MSO-sentence is regular. Note that the
method of choice for proving statements about formulas - induction on the
formula structure - cannot directly be employed. The reason is simply that a
subformula of a sentence is in general not a sentence itself, so the inductive
hypothesis would not be applicable.
The problem here is that we only defined the notion of language for
sentence, not for open formulas because the set of models of a formula is a

set of pairs of words and assignments in general, and it was only the
observation that assignments are irrelevant for sentences that allowed us to
see this simply as a set of words.
There is, however, a simple trick that can be used to make the induction
work: note that the language of a possibly open subformula of a sentence
would not have to be a word over the same alphabet Œ£ as that of the
sentence's language. In fact, there is a very natural way to regard an
interpretation (ùë§, ùêº) consisting of a word ùë§ ‚àà Œ£+ and an assignment of a
finite number of second-order variables ùëã , . . . , ùëã
1
ùëõ
ùëõ
by sets of positions in ùë§, as a word ùë§ùêº again, namely over the alphabet Œ£ √ó
{0, 1} .
This way, the external assignment for the word gets internalised as follow s.
ùúí
‚éõ
1(ùëñ)‚éû
‚éú
‚ãÆ
‚éü
ùë§ ùêº (ùëñ)
‚à∂= ‚éú

‚éü
‚éú ùúí
‚éü
ùëõ (ùëñ )
‚éù ùë§(ùëñ) ‚é†
where, for each ùëñ = 0, . . . , ‚à£ùë§‚à£ ‚àí 1 and each ùëó = 1, . . . , ùëõ we have
2.2 MSO-Definability and Regularity
27
‚éß
‚é™
‚é™0
, if ùëñ /
‚àà ùêº (ùëã ùëó ) ,
ùúí ùëó (ùëñ)
= ‚é®
‚é™
‚é™1
, if ùëñ ‚àà ùêº(ùëã ùëó ) .
‚é©

We can think of ùë§ùêº as of a word with multiple tracks: one Œ£-track
containing the original word ùë§, and one additional {0, 1}-track for each
second-order variable.
Example 2.11 Let ùë§ = ùëéùëéùëèùëéùëè and ùêº be such that ùêº(ùëã) = {0, 3, 4} and ùêº(ùëå )
= {1, 3}
Then ùë§ùêº could be written as follow s.
ùëã ‚à∂
‚éõ1 ‚éû ‚éõ0 ‚éû ‚éõ0 ‚éû ‚éõ1 ‚éû ‚éõ1 ‚éû
ùëå ‚à∂
‚éú0 ‚éü ‚éú1 ‚éü ‚éú0 ‚éü ‚éú1 ‚éü ‚éú0 ‚éü
ùë§ ‚à∂
‚éù ùëé ‚é† ‚éù ùëé ‚é† ‚éù ùëè ‚é† ‚éù ùëé ‚é† ‚éù ùëè ‚é†
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π
¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùë§ùêº
We say that ùë§ùêº could be this multi-track word and not that it is, simply
because the representation using such vector symbols obviously requires us
to fix an order on the variables. Ideally, the variables are ordered as in ùëã , . .
. , ùëã
1
ùëõ
for instance. However,

later on, we will make use of the projection construction that eliminates
single tracks from such words. It does not change the order but it causes us
to deviate from the situation in which the tracks correspond to variables ùëã ,
. . . , ùëã
1
ùëõ . In order to avoid
technical overkill, we will simply assume that there is some correspondence
between the second-order variables in a formula and the additional {0, 1}-
tracks. In fact, this will be a one-to-one correspondence between the free
variables and these tracks.
We could extend this construction to the first-order variables, indicating the
‚àó
‚àó
assignment of such a variable ùë• by an additional track of the form 0 10 .
Note that an assignment ùêº assigns a single position to a first-order variable.
We can avoid the additional technicalities with the following trick, though.
Definition 2.12 An MSO formula ùúë over Œ£ is called normalised if it is
derivable from the grammar
ùúë
‚à∂‚à∂= sing(ùëã ) ‚à£ ùëã < ùëå ‚à£ ùëã ‚äÜ ùëå ‚à£ ùëã ‚äÜ ùëé ‚à£ ùúë ‚à® ùúë ‚à£ ¬¨ùúë ‚à£ ‚àÉùëã ùúë
where ùëé ‚àà Œ£, ùëã, ùëå ‚àà V2 .
The term "normalised" is slightly misleading. Clearly, such normalised
formulas are not just of a special form in the original syntax. Instead we
have extended the syntax by new atomic formulas sing(ùëã), ùëã < ùëå , ùëã ‚äÜ ùëå
and ùëã ‚äÜ ùëé for ùëé ‚àà Œ£ with one, resp. two free second-order variables ùëã, ùëå .

Intuitively they state that (i) ùëã denotes a singleton set, (ii) for every position
in ùëã there is a later one in ùëå , (iii) the set denoted by ùëã is a subset of that
denoted by ùëå , and (iv) all the positions in the set for ùëã carry the letter ùëé.
We therefore need to extend the semantics accordingl y as well.
ùë§ , ùêº ‚äß sing(ùëã)
iff
‚à£ùêº (ùëã )‚à£ = 1
ùë§ , ùêº ‚äß ùëã < ùëå
iff
for all ùëñ ‚àà ùêº(ùëã) there is ùëó > ùëñ with ùëó ‚àà ùêº(ùëå )
ùë§ , ùêº ‚äß ùëã ‚äÜ ùëå
iff
ùêº (ùëã ) ‚äÜ ùêº (ùëå )
ùë§ , ùêº ‚äß ùëã ‚äÜ ùëé
iff
ùë§ (ùëñ) = ùëé for all ùëñ ‚àà ùêº(ùëã)
28
2 Monadic Second-Order Logic
The justification for calling formulas of this new form normalised is given
by the following lemma. It states that every formula in the original syntax
can be translated into the new syntax in a way that is almost equivalence-
preserving. Note that the result cannot be equivalent since normalised
formulas have no first-order variables.

However, first-order variables can be seen as special second-order
variables. Suppose ùêº is an assignment of first-order variables V
, . . . , ùë•
1 = {ùë•1
ùëõ } and second-order
variables V
, . . . , ùëã
, . . . , ùëå
2 = {ùëã1
ùëö }. Take new second-order variables ùëå1
ùëõ
and let ÀÜ
ùêº
be the assignment of the second-order variables {ùëå , . . . , ùëå , ùëã , . . . , ùëã
1
ùëõ
1
ùëö }, defined
by
‚Ä¢ ùêº(

ÀÜ ùëã ùëó ) ‚à∂= ùêº(ùëã ùëó ) for every ùëó = 1, . . . , ùëö,
‚Ä¢ ÀÜùêº(ùëåùëó) ‚à∂= {ùêº(ùë•ùëñ)} for every ùëó = 1, . . . , ùëõ .
This simple reinterpretation of first-order objects as singleton second-order
objects is what allows us to almost preserve equivalence in a translation
from original MSO
formulas to normalised ones.
Lemma 2.13 For every MSO formula ùúë(ùë• , . . . , ùë• , ùëã , . . . , ùëã
1
ùëõ
1
ùëõ )
there is a nor-
‚Ä≤
‚Ä≤
malised MSO formula ùúë (ùëå , . . . , ùëå , ùëã , . . . , ùëã
1
ùëõ
1
ùëö )
such that ‚à£ùúë ‚à£ = O(‚à£ùúë‚à£) and for
‚Ä≤

all ùë§ ‚àà Œ£+ and ùêº we have ùë§, ùêº ‚äß ùúë iff ùë§, ÀÜ
ùêº ‚äß ùúë .
Proof The elimination of first-order variables and quantifiers is realised by
the following translation. Let ùëå , . . . , ùëå
1
ùëõ
be fresh second-order variables not occurring
in ùúë.
tr(ùë•ùëñ < ùë• ùëó ) ‚à∂= ùëåùëñ < ùëå ùëó
tr(ùúì1 ‚à® ùúì2) ‚à∂= tr(ùúì1) ‚à® tr(ùúì2)
tr(ùëé(ùë•ùëñ )) ‚à∂= ùëåùëñ ‚äÜ ùëé
tr(¬¨ùúì) ‚à∂= ¬¨ tr(ùúì)
tr(ùëã(ùë•
ùúì
ùëñ ))
‚à∂= ùëåùëñ ‚äÜ ùëã
tr(‚àÉùëãùëñ
)
‚à∂= ‚àÉùëãùëñ tr(ùúì)
tr(‚àÉùë• ùúì

.
ùëñ
)
‚à∂= ‚àÉùëåùëñ sing(ùëåùëñ ) ‚àß tr(ùúì)
‚Ä≤
Then simply let ùúë ‚à∂= tr(ùúë). The claim on the size of ùúë is obvious. Correctness
is shown by a standard induction on the structure of ùúë. Details are left as an
exercise. ‚óª
Lemma 2.13 allows us to restrict our attention to normalised formulas ùúë
over some alphabet Œ£. In particular, they contain no first-order variables.
Moreover, assume that the second-order variables occurring in ùúë are ùëã , . . . ,
ùëã
1
ùëõ and that all quantifiers in ùúë
use different variables. Lemma 2.13 then also allows us to see the set of
models of any ùëõ
subformula ùúì(ùëã , . . . , ùëã
1
ùëõ ) as a set of words over the extended alphabet Œ£ √ó {0, 1} .
We will also denote this as ùêø(ùúì(ùëã , . . . , ùëã
1
ùëõ )).

The goal is to construct, given such a normalised formula ùúë, an NFA Aùúë
such that ùë§ , ùêº ‚äß ùúë iff ùë§ùêº ‚àà ùêø(Aùúë ). Note that this is general enough to be
proved by induction on the structure of ùúë. The next lemma provides the base
case for this induction.
Lemma 2.14 Let Œ£ and ùëõ ‚àà N be given. There are NFA Aùúì for ùúì ‚àà {
sing(ùëãùëñ), ùëãùëñ < ùëã , ùëã
, ùëã
ùëó
ùëñ
‚äÜ ùëã ùëó
ùëñ
‚äÜ ùëé ‚à£ ùëé ‚àà Œ£, ùëñ, ùëó ‚àà {1, . . . , ùëõ}} such that for all ùë§ ‚àà Œ£+ and all
[ùëö]
assignments ùêº ‚à∂ {ùëã , . . . , ùëã
1
ùëõ } ‚Üí 2
with ùëö = ‚à£ùë§ ‚à£ we have
ùë§ , ùêº ‚äß ùúì
iff
ùë§ ùêº ‚àà ùêø(Aùúì ) .
2.2 MSO-Definability and Regularity
29

‚éõ‚ãÆ‚éû
‚éõ‚ãÆ‚éû ‚éõ‚ãÆ‚éû
‚éõ‚ãÆ‚éû ‚éõ‚ãÆ‚éû ‚éõ‚ãÆ‚éû
ùëñ ‚Üí ‚éú
‚ãÆ
‚éú0‚éü‚éü
‚éõ ‚éû
‚éú‚ãÆ‚éü ‚éú1‚éü
‚éú‚éú0‚éü‚éü ‚éú‚éú0‚éü‚éü ‚éú‚éú1‚éü‚éü ‚Üê ùëñ
‚éõ ‚ãÆ ‚éû ‚éõ‚ãÆ‚éû
‚éõ‚ãÆ‚éû
‚éõ‚ãÆ‚éû
‚éú
‚éú ‚éü ‚éú ‚éü
‚éú‚ãÆ‚éü‚éü
‚éú1‚éü
‚éú‚ãÆ‚éü , ‚éú‚ãÆ‚éü
‚éú‚éú‚ãÆ‚éü‚éü, ‚éú‚éú‚ãÆ‚éü‚éü, ‚éú‚éú‚ãÆ‚éü‚éü
‚éú1‚éü ‚éú0‚éü ‚Üê ùëñ
‚éú

‚éú ‚éü
‚éú ‚éü
‚éú ‚éü ‚éú ‚éü
‚éú ‚éü ‚éú ‚éü ‚éú ‚éü
‚éú ‚éü , ‚éú ‚éü
0‚éü
‚éú0‚éü ‚Üê ùëñ
‚ãÆ
‚éú‚ãÆ‚éü
‚éú0‚éü ‚éú1‚éü ‚Üê ùëó
0
1
1 ‚Üê ùëó
‚éú ‚ãÆ ‚éü ‚éú‚ãÆ‚éü
‚éù
‚éú ‚éü
‚ãÆ ‚é† ‚éõ‚ãÆ‚éû ‚éù‚ãÆ ‚é†
‚éù‚ãÆ ‚é† ‚éú‚ãÆ‚éü
‚éù‚ãÆ ‚é† ‚éù‚ãÆ ‚é†
‚éù‚ãÆ ‚é† ‚éù‚ãÆ ‚é† ‚éù‚ãÆ ‚é†

‚éù ‚é† ‚éù ‚é†
ùëé
‚ãÆ
‚éú
‚éù ‚é†
1‚éü
‚ãÆ
‚éù‚ãÆ ‚é†
‚éõ‚ãÆ‚éû
A
A
‚éú0‚éü
A
A
sing(ùëã )
ùëã <ùëã
ùëã ‚äÜùëã
ùëã ‚äÜùëé
ùëñ
ùëñ

ùëó
‚éú‚éú ‚éü
ùëñ
ùëó
ùëñ
‚éú‚ãÆ‚éü
‚éú ‚éü‚éü
‚éù1‚ãÆ ‚é†
Fig. 2.1 NFA for the base cases in the proof of Lemma 2.14.
Proof The four NFA, depending on the type of atomic formula, are shown
in Fig. 2.1.
A close inspection shows that these correctly accept words encoding
interpretations for formulas of these atomic kinds: take for instance A
sing(ùëãùëñ) on the left. It accepts ùëõ
‚àó
a word ùë£ ‚àà (Œ£ √ó {0, 1} ) that represent some interpretation-extended word
ùë§ùêº , iff
‚àó
‚àó
its ùëñ-th track is of the form 0 10 , i.e. if the interpretation encoded in ùë§ùêº
assigns a single position to ùëãùëñ, resp. ùêº(ùëãùëñ) is a singleton set.
‚óª

The NFA for formulas of the form ùúë ‚à® ùúì is obtained from Aùúë and Aùúì using
the union construction for NFA, cf. Thm. 1.7. The automaton for ¬¨ùúë is
obtained from Aùúë by complementation, cf. Cor. 1.17. What remains is to
transfer the effect of existential second-order quantification to NFA.
Interestingly, this seemingly most complex logical operation corresponds to
almost the simplest operation on NFA: ùëõ
alphabet projection. For a word ùë§ùêº over Œ£ √ó {0, 1} and ùëó ‚àà [ùëõ] we denote
by ùë§ùêº ‚Üì ùëó
the word that results from ùë§ùêº by simple removing the ùëó -th additional track.
Clearly, ùëõ‚àí
ùë§
1
ùêº ‚Üì ùëó
is a word over Œ£ √ó {0, 1}
, and it represents a pair of a Œ£-word and an
assignment of one less second-order variable than ùë§ùêº does.
Lemma 2.15 Let ùúì(ùëã , . . . , ùëã
1
ùëõ )
be a formula and Aùúì be an NFA recognising its
language in the sense above. Let ùëó ‚àà {1, . . . , ùëõ} . There is an NFA A‚àÉùëã ùúì
such that ùëó
ùêø (A‚àÉùëã ùúì ) = {ùë§ ùêº ‚Üì ‚à£ ùë§ ùêº ‚àà ùêø(Aùúì )} and ‚à£A

ùúì ‚à£ = ‚à£A ùúì ‚à£ .
ùëó
ùëó
‚àÉùëã ùëó
Proof Let A
, . . . , ùúí
‚àÉùëã ùúì result from A ùúì by replacing every transition label (ùëé, ùúí
ùëõ )
ùëó
1
with ùëé ‚àà Œ£, ùúí
, . . . , ùúí
, ùúí
, . . . , ùúí
ùëó
‚àà {0, 1} for ùëó = 1, . . . , ùëõ, by (ùëé, ùúí1
ùëó ‚àí1
ùëó +1
ùëõ ). Clearly,
ùëõ‚àí

A
1
‚àÉùëã ùúì is an NFA over the alphabet Œ£ √ó {0, 1}
, if Aùúì is an NFA over the alphabet
ùëó
Œ£
ùëõ
√ó {0, 1} , and the size claim is obviously true. Correctness remains to be
seen.
Suppose that ùúå is an accepting run of A‚àÉùëã ùúì on some word ùë§ùêº‚Ä≤ with ùëõ‚àí1
additional ùëó
tracks that interpret the variables ùëã , . . . , ùëã
, ùëã
, . . . , ùëã
1
ùëó ‚àí1
ùëó +1
ùëõ . Since A‚àÉùëã ùúì resulted
ùëó
from Aùúì by projection of the ùëó -th track, it is possible to follow ùúå through Aùúì
by reconstructing the symbols from {0, 1} on the original ùëó -th track. Let ùëÜ

‚äÜ [ùëö] for ùëö = ‚à£ùë§ ùêº‚Ä≤ ‚à£ be the set of positions at which this track sees the
symbol 1. Hence, there
‚Ä≤
is a set ùëÜ s.t. Aùúì accepts the word ùë§ùêº where ùêº = ùêº [ùëã ùëó ‚Ü¶ ùëÜ]. Assuming that
Aùúì is
‚Ä≤
correct, we therefore have that ùë§, ùêº ‚äß ‚àÉùëã ùúì
ùëó
. The converse direction is shown in the
same way.
‚óª
30
2 Monadic Second-Order Logic
The automaton for ‚àÉùëã ùúì
ùëó
thus works like Aùúì but guesses the contents of the
ùëã ùëó -track nondeterministically. This completes the construction of logical
operations on automata needed to prove the main result.
Theorem 2.16 Every MSO-definable language is regular.
Proof Let ùêø = ùêø(ùúë) for some MSO-sentence ùúë. We want to show that ùêø is
regular, namely NFA-recognisable. In order to do this by induction on the
structure of ùúë, we ùëõ

+
need to extend the claim to arbitrary formulas: let ùêø ‚äÜ (Œ£ √ó {0, 1} ) such
that ùêø =
ùêø (ùúë(ùëã , . . . , ùëã
1
ùëõ )) for some MSO formula ùúë not containing any first-order variables.
We can then use induction; the base cases are covered by Lemma 2.14. For
the step cases, Lemma 2.15 shows how to construct NFA for existential
quantifications, Thm. 1.7 for unions and Cor. 1.17 for complements.
‚óª
2.2.3 Consequences of the Translations
The two constructions above, from NFA to MSO and back, have important
consequences. By putting Thm. 2.10 and 2.16 together we obviously obtain
that these two formalisms are equi-expressive.
Corollary 2.17 A language ùêø ‚äÜ Œ£+ is regular iff it is MSO-definable.
The second consequence combines this with decidability of NFA non-
emptiness.
Corollary 2.18 Satisfiability and equivalence for MSO are decidable.
Proof According to Thm. 2.6 it suffices to consider the satisfiability
problem. Given some ùúë ‚àà MSO, according to Thm. 2.16 it is possible to
construct an NFA Aùúë s.t.
ùêø (A ùúë ) = ùêø(ùúë). Then decidability of MSO satisfiability follows from
decidability of NFA emptiness, cf. Thm. 1.18.
‚óª

We also consider the existential fragment EMSO of MSO. It consists of all
those formulas that - when brought into negation normal form - do not
contain universal second-order quantifiers. For example ‚àÉùëã ‚àÄùë¶.ùëÉùëé(ùë¶) ‚Üí
‚àÉùë•.ùë• < ùë¶ ‚àß ùëã(ùë•) is an EMSO formula but ‚àÄùë•.(‚àÉùëã ‚àÄùë¶.ùëÉùëé(ùë¶) ‚Üí ùëã(ùë¶)) ‚Üí
ùëÉùëè(ùë•) is not because the quantification over ùëã is on the left (negative) side
of the implication and thus is effectively universal. Universal first-order
quantification is, however, allowed in EMSO. Surprisingly, EMSO is as
expressive as full MSO.
Theorem 2.19 A language ùêø ‚äÜ Œ£+ is MSO-definable iff it is EMSO-
definable.
Proof It suffices to note that the formulas constructed in the proof of Thm.
2.10
belong to EMSO. Hence, by translating an MSO formula into an NFA and
then back into MSO, we effectively obtain an equivalent EMSO formula.
‚óª
2.3 The Complexity of MSO
31
Some of these translations come with certain costs. While the construction
of EMSO formulas from NFA is polynomial, the translation from MSO to
NFA is not.
The reason is that each negation operation requires a complementation
construction on NFA which incurs an exponential blowup. One may be
tempted to try to opti-mise the translation and eliminate negation first by
putting formulas into negation normal form. This cheap trick does not work,
though. This transformation would leave universal quantifiers, and it is
impossible to translate universal quantification into an equally simple
operation like projection on NFA. It would be helpful to work with DFA
instead to handle universal quantifiers, but determinism is not an invariant
of the translation: while it is possible to construct DFA for the union of two
DFA-recognisable languages at a quadratic blowup only, it is then the

existential quantification that causes problems because projection genuinely
creates nondeterministic automata. Hence, all these ideas only shift the
exponential blowups around, and the translations seem to involve a number
of nested exponential constructions that is dependent on the formula. It is
reasonable to ask whether this may be unavoidable, i.e. whether NFA
equivalent to some MSO formulas may need to be non-elementarily larger.
The following section shows that this is indeed the case.
2.3 The Complexity of MSO
We will show that the non-elementary blowup in translating MSO formulas
into NFA is unavoidable. To this end, we first define two fast-growing
families of functions in input parameter ùëõ:
ùëõ
ùëõ
2 ‚à∂= ùëõ
ùêπ
‚à∂= ùëõ
0
0
ùëõ
ùëõ
ùëõ
2
ùëõ
ùëõ

ùêπ
2
‚à∂=
ùëò
ùêπ
‚à∂= ùêπ
‚ãÖ
ùëò
ùëò +1
2
ùëò +1
ùëò
2
ùëõ
The functions ùëõ ‚Ü¶ 2 for any ùëò ‚â• 0 are ultimately what we are interested in,
namely ùëò
to show that the blowup in translating MSO formulas of size ùëõ into NFA
cannot ùëõ
be bounded by an elementary function. The functions ùëõ ‚Ü¶ ùêπ
will be helpful for
ùëò

ùëõ
ùëõ
technical reasons. Clearly, we have ùêπ
‚â• 2 for all ùëõ, ùëò ‚â• 0, so it suffices to use the
ùëò
ùëò
ùëõ
functions ùêπ
for any low er bounds.
ùëò
ùëõ
ùëõ
The goal is to construct satisfiable formulas ùúë
s.t. the shortest word in ùêø(ùúë )
ùëò
ùëò
ùëõ
ùëõ
has length ùêπ . Specifically, we will construct formulas dist (ùë•, ùë¶) with two
free ùëò

ùëò
variables ùë•, ùë¶ s.t.
ùëõ
ùëõ
ùë§ , ùêº ‚äß dist (ùë•, ùë¶)
ùëò
iff
ùêº (ùë¶) ‚àí ùêº (ùë•) = ùêπùëò
ùëõ
for all interpretations (ùë§, ùêº) and all ùëõ, ùëò ‚â• 0. Then take the sentence ùúë
‚à∂=
ùëò
ùëõ
‚àÉùë• ‚àÉùë¶ dist (ùë•, ùë¶)
ùëò
for instance. Clearly, it would be satisfiable, but any word fulfilling ùëõ
it would have to have length at least ùêπ + 1.
ùëò
ùëõ
In order to construct dist (ùë•, ùë¶)

ùëò
we proceed by induction on ùëò . For ùëò = 0 this is
ùëõ
simple: remember that ùêπ ‚à∂= ùëõ, hence, we can simply take
0
32
2 Monadic Second-Order Logic
ùëõ‚àí1
ùëõ
dist (ùë•, ùë¶) ‚à∂= ‚àÉùë• . . . ‚àÉùë• .ùë•
, ùë•
0
0
ùëõ
0 = ùë• ‚àß ( ‚ãÄ succ(ùë•ùëñ
ùëñ+1)) ‚àß ùë•ùëõ = ùë¶ .
ùëñ=0
ùëõ
ùëõ
Now suppose that dist (ùë•, ùë¶)

(ùë•, ùë¶)
ùëò
is already defined. In order to construct dist ùëò+1
it
is helpful to imagine a given word ùë§ = ùëé ùëé . . . ùëé
0
1
ùëö for some large ùëö to be equipped
ùëõ
with an additional track of symbols 0 and 1 that act as bit values of an ùêπ -
bit counter ùëò
ùëõ
s.t., when read in chunks of length ùêπ
starting in position ùë•, we see the binary
ùëò
representations of the numbers 0, 1, . . . successively along this track. Note
that there ùëõ
ùêπ
ùëõ
are 2 ùëò many such values, and each takes up ùêπ
positions. Hence, writing them

ùëò
ùëõ
ùëõ
ùêπ
ùëõ
all down consecutively takes up ùêπ ‚ãÖ 2 ùëò = ùêπ
many positions in the underlying
ùëò
ùëò +1
word. So if this enumeration starts at position ùë• and ends just before
position ùë¶ then ùëõ
we have ùë¶ ‚àí ùë• = ùêπ
. The following picture shows the evaluation of a monadic
ùëò +1
second-order variable ùêµ representing bits in such a counter with two
positions ùë• and ùë¶ in a fictitious word (over an arbitrary alphabet). To ease
the construction of the formulas in the following, we additionally require
the first position of every block of ùêπùëõ many bits to be marked, using
another second-order var iable ùëÄ.
ùëõ
bin. value:
ùêπ

0
1
2
3
2 ùëò ‚àí 1
bits ùêµ:
0 0 0 . . . 0 1 0 0 . . . 0 0 1 0 . . . 0 1 1 0 . . . 0 . . . . . . . . . 1 1 1 . . . 1 0 . . .
marker ùëÄ: 1 0 0 . . . 0 1 0 0 . . . 0 1 0 0 . . . 0 1 0 0 . . . 0 . . . . . . . . . 1 0 0 . .
. 0 1 . . .
ùëõ
ùëõ
ùëõ
ùëõ
ùëõ
width:
ùêπ
ùêπ
ùêπ
ùêπ
ùêπ

ùëò
ùëò
ùëò
ùëò
ùëò
ùëõ
ùêπùëò+1
ùë•
ùë¶
Note that bits in the binary values are given in increasing order of
significance when reading from left to right.
We define
ùëõ
ùëõ
ùëõ
ùëõ
ùëõ
dist
(ùë•, ùë¶)
‚à∂= ‚àÉùëÄ ‚àÉùêµ.

(ùë•, ùë¶) ‚àß
(ùë•) ‚àß
(ùë•, ùë¶) ‚àß
(ùë¶ )
ùëò +1
mark ùëò+1
init ùëò+1
count ùëò+1
fin ùëò+1
ùëõ
where mark
(ùë•, ùë¶)
ùëò +1
expresses the correct marking of the first position in each block:
‚Ä≤
‚Ä≤
ùëõ
‚Ä≤
ùëÄ (ùë•) ‚àß ‚àÄùëß.ùë• < ùëß ‚Üí (((‚àÉùë¶ .ùëß < ùë¶ ‚àß dist (ùë•, ùë¶ )) ‚àß ¬¨ùëÄ(ùëß))
ùëò

‚Ä≤
‚Ä≤
ùëõ
‚Ä≤
‚Ä≤
‚à® ‚àÉùë• .ùë• ‚â§ ùë• ‚àß dist (ùë• , ùëß) ‚àß (ùëÄ(ùëß) ‚Üî ùëÄ(ùë• )))
ùëò
It says that position ùë• is marked, and thereafter all positions in the same
block
‚Ä≤
ùëõ
(recognisable by being left of some ùë¶ that is at distance ùêπ from ùë•) are not
marked.
ùëò
All positions further away than that (recognisable by being equal to or right
of some ùëõ
position at distance ùêπ from ùë•) obtain their marker value from the position at
distance ùëò
ùëõ
ùêπ
to the left of themselves.
ùëò

ùëõ
ùëõ
Formula init
(ùë•) expresses that the first ùêπ
positions starting at ùë• carry the
ùëò +1
ùëò
symbol 0:
‚Ä≤
ùëõ
‚Ä≤
‚Ä≤
‚àÉùë¶ . dist (ùë•, ùë¶ ) ‚àß ‚àÄùëß.ùë• ‚â§ ùëß ‚àß ùëß < ùë¶ ‚Üí ¬¨ùêµ(ùëß)
ùëò
ùëõ
ùëõ
Formula fin
(ùë¶)
ùëò +1
expresses that the ùêπ

positions before ùë¶ carry the symbol 1:
ùëò
2.3 The Complexity of MSO
33
‚Ä≤
ùëõ
‚Ä≤
‚Ä≤
‚àÉùë• . dist (ùë• , ùë¶) ‚àß ‚àÄùëß.ùë• ‚â§ ùëß ‚àß ùëß < ùë¶ ‚Üí ùêµ( ùëß)
ùëò
ùëõ
ùëõ
Formula count
(ùë•, ùë¶) expresses that each block of width ùêπ
between ùë• and ùë¶
ùëò +1
ùëò
carries a binary value that is the successor of the value written down in the
block to its left. This is easier to express than one may expect: a recipe for
increasing a binary value by one is the following.

Flip the least significant bit. For the ùëñ-th bit, ùëñ > 0, assume that the new
value of bit ùëñ ‚àí 1 has already been determined. Then note that the old and
new value ùëèùëñ‚àí1 and
‚Ä≤
ùëè
of bit ùëñ ‚àí 1 together with the old value ùëè
ùëñ‚àí1
ùëñ
of bit ùëñ uniquely determine the new
‚Ä≤
value ùëèùëñ of bit ùëñ. It is helpful to depict these four values as bits placed in
positions ùëñ ‚àí 1 and ùëñ in consecutive bloc ks.
ùëñ‚àí1
ùëñ‚àí1
ùëñ
ùëñ
‚Ä≤
‚Ä≤
. . . ùëè
ùëè
. . . . . . ùëè

ùëè
. . .
ùëñ‚àí1
ùëñ
ùëñ‚àí1
ùëñ
ùëõ
ùëõ
ùêπ
ùêπ
ùëò
ùëò
Then there are only eight different possibilities for combinations of thes e
four values, determined by how a binary value gets incremented: all lowest
set bits are unset, the first unset bit is set and all higher bits are preserved.
Hence, by compa ring ùëèùëñ‚àí1 and
‚Ä≤
ùëè
we can easily determine which of these three phases the ùëñ-th bit fall s into: if
they ùëñ‚àí1
‚Ä≤
‚Ä≤

are equal or ùëèùëñ‚àí1 has already been increased to ùëè
, then ùëè
ùëñ‚àí1
ùëñ
and ùëèùëñ must be equal.
‚Ä≤
‚Ä≤
If ùëèùëñ‚àí1 has been decreased to ùëè
then ùëè
ùëñ‚àí1
ùëñ must be decreased to ùëèùëñ as well if it is set,
or must be increased if it is unset. The following table shows all these
combinations.
‚Ä≤
‚Ä≤
ùëè
ùëè
ùëè
ùëè
ùëñ‚àí1

ùëñ‚àí1
ùëñ
ùëñ
0
0
0
0
0
0
1
1
1
1
0
0
1
1
1
1
0

1
0
0
0
1
1
1
1
0
0
1
1
0
1
0
It is not hard to see that the formula
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤

next(ùëè
, ùëè , ùëè
, ùëè
ùëñ‚àí1
ùëñ
)
‚à∂= (ùëè
) ‚Üî (ùëè
)
ùëñ‚àí1
ùëñ
ùëñ‚àí1 ‚Üí ùëèùëñ‚àí1
ùëñ
‚Üî ùëèùëñ
expresses exactly this relationship between these four values. We can use
this to ùëõ
construct count
(ùë•, ùë¶) as
ùëò +1
‚Ä≤

‚Ä≤
‚Ä≤
‚Ä≤
ùëõ
‚Ä≤
‚Ä≤
‚àÄùë• ‚àÄùë¶ .ùë• ‚â§ ùë• ‚àß ùë¶ < ùë¶ ‚àß dist (ùë• , ùë¶ ) ‚Üí
ùëò
((ùëÄ (ùë•) ‚Üí (ùêµ(ùë•) ‚Üî ¬¨ùêµ(ùë¶))) ‚àß
34
2 Monadic Second-Order Logic
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
‚Ä≤‚Ä≤

‚Ä≤
(¬¨ùëÄ (ùë•) ‚Üí ‚àÉùë•
‚àÉùë¶
. succ(ùë• , ùë• ) ‚àß succ(ùë¶ , ùë¶ ) ‚àß next(ùë• , ùë• , ùë¶ , ùë¶ ))) This shows that
satisfiable MSO formulas can have truly large models. Combining this with
the fact that NFA cannot, we obtain the impossibility of an equivalence-
preserving translation of MSO formulas into relatively small NFA.
Theorem 2.20 There is no translation of MSO formulas of size ùëõ into
equivalent ùëù(ùëõ)
NFA of size at most 2
for any polynomial function ùëù ‚à∂ N ‚Üí N and any ùëò ‚â• 0 .
ùëò
Proof
1
Consider the family (ùúëùëõ)ùëõ‚â•1 with ùúëùëõ ‚à∂= ‚àÉùë• ‚àÉùë¶ dist (ùë•, ùë¶)
ùëõ
. Clearly, each ùúëùëõ is
satisfiable, and ùêø(ùúëùëõ) = {ùë§ ‚àà Œ£‚àó ‚à£ ‚à£ùë§‚à£ ‚â• ùêπ1 }
ùëõ
. It is a routine exercise to show that
every NFA recognising ùêø(ùúëùëõ) needs to have at last ùêπ1
ùëõ

many states. Note that the
ùëù(ùëõ)
function ùëõ ‚Ü¶ ùêπ1
ùëõ
grows non-elementarily, i.e. much faster than 2
for any fixed
ùëò
ùëù(ùëõ)
ùëò ‚â• 0 and any polynomial ùëù. Hence for any such ùëò , ùëù there is some ùëõ0 s.t.
ùêπ1 > ùëõ
2ùëò
for all ùëõ ‚â• ùëõ0, showing that any family (Aùëõ)ùëõ‚â•1 of NFA growing in size at
a rate of ùëù(ùëõ)
at most 2
, must contain some NFA Aùëõ s.t. ùêø(Aùëõ) ‚â† ùêø (ùúëùëõ).
‚óª
ùëò
This already gives a non-elementary gap between the sizes of MSO and
equivalent NFA. However, the construction is not optimal yet: the size of
(ùúëùëõ) grows expo-ùëõ
ùëõ
‚Ä≤

‚Ä≤
nentially in ùëõ, since every dist
(ùë•, ùë¶)
(ùë• , ùë¶ )
ùëò +1
contains several occurrences of dist ùëò
‚Ä≤
‚Ä≤
for different variables ùë• , ùë¶ . It is not hard, though, to rewrite ùúëùëõ so that it
only ùëõ
‚Ä≤
‚Ä≤
contains polynomially many subformulas in ùëõ: simply replace dist (ùë• , ùë¶ ) ùëò
by
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
ùëõ
ùëõ

‚àÉùë• ‚àÉùë¶ .ùë•
= ùë• ‚àß ùë¶
= ùë¶ ‚àß dist (ùë•, ùë¶)
(ùë•, ùë¶)
ùëò
. Then dist ùëò
still contains several oc-
ùëõ
currences of dist (ùë•, ùë¶)
ùëò
but they are all syntactically equal. Hence, the number of
subformulas of ùúëùëõ then grows only linearly in ùëõ.
Thm. 2.20 only precludes the existence of an elementary and equivalence-
preserving translation from MSO into NFA. But Cor. 2.18 reduces decision
problems on MSO to satisfiability, resp. non-emptiness of NFA. The
existence of a translation from MSO into equi-satisfiable NFA - i.e. a
mapping ùúë ‚Ü¶ Aùúë s.t. ùêø(Aùúë ) ‚â† ‚àÖ iff ùúëùëõ is satisfiable - would not contradict
Thm. 2.20. In fact, such a mapping trivially exists. Take two NFA A0 and
A1 s.t. ùêø(A0) = ‚àÖ and ùêø(A1) ‚â† ‚àÖ. Then the mapping
‚éß
‚é™
‚é™A
,

1
if ùúëùëõ is satisfiable,
ùúëùëõ ‚Ü¶ ‚é®
‚é™
‚é™A
, otherwise.
‚é©
0
cleary has the desired property. However, it is not helpful in order to decide
satisfiability of MSO since, in order to use it to know what ùúëùëõ gets mapped
to, one needs to "know" whether it is satisfiable. Moreover, NFA are not
really used in this translation - one could equally just take two Boolean
values to signal the outcome of this function on any argument.
So the real question behind all this simply is: can the satisfiability problem
for MSO be decided in a way that is asymptotically significantly better than
translating formulas into NFA according to Thm. 2.16 and testing those for
non-emptiness? That test can be done in nondeterministic logarithmic space
in the size of the resulting NFA
2.3 The Complexity of MSO
35
which are of non-elementary size compared to the original MSO formulas.
Hence, the space (and also time) complexity of this procedure is still non-
elementary.
The answer is negative, as the following theorem shows. Note that (ùëò ‚àí 1)-

ExpSpace ‚ää ùëò -ExpSpace for any ùëò > 1. Hence, any ùëò -ExpSpace-hard
problem does not belong to (ùëò ‚àí 1)-ExpSpace. Moreover, ‚ãÉ
ùëò ‚àí
ùëò ‚àí
ùëò ‚â•0
ExpSpace = ‚ãÉùëò‚â•0
ExpTime,
and the following theorem could equally be stated about elementary time
instead of space complexity. Moreover, ùëò -ExpSpace = ùëò -NExpSpace, i.e.
it is irrelevant whether Turing Machines as a computational model for this
complexity class are assumed to be deterministic or allowed to be nondeter
ministic.
Theorem 2.21 The satisfiability problem for MSO is hard for ùëò -ExpSpace
for any ùëò ‚â• 0 .
Proof (Sketch) Let ùëò ‚â• 0. A standard problem that is ùëò-ExpSpace hard is
the ùëù(ùëõ)
following: given a Turing Machine M whose space is bounded by a
function 2ùëò
for inputs of length ùëõ, and an input ùë§, does M accept ùë§? We show that this
can be polynomially reduced to the satisfiability problem for MSO by
constructing a formula ùúëM,ùë§ that is satisfiable iff ùë§ ‚àà ùêø(M), and of
polynomial size in ‚à£M‚à£ and
‚à£ùë§‚à£ onl y.
Let M = (ùëÑ, Œ£, Œì, ùëû , Œî, ùëû
ùêº

acc) with state set ùëÑ, input and tape alphabets Œ£, Œì,
initial and accepting state ùëû , ùëû
ùêº
acc, and transition function ùõø ‚äÜ ùëÑ√óŒì√óùëÑ√óŒì√ó{‚àí1, 0, 1}.
Assume that there is a special blank-tape symbol ‚óª ‚àà Œì ‚àñ Œ£. Let ùë§ = ùëé . . .
ùëé
0
ùëõ ‚àí1.
Note that a computation of M on ùë§ can be represented as a word ùê∂0#ùê∂1# .
. . #ùê∂ùëö
by concatenating successive configurations which can also be represented
as words ùê∂ , ùê∂ , . . .
0
1
over the alphabet ùëÑ√óŒì‚à™Œì. Then, ùúëM,ùë§ only has to express the conjunction
of the following properties. Formalising these properties in MSO is left as
an exercise.
‚Ä¢ A model is of this specific form, i.e. it can be decomposed into blocks
separated ùëù(ùëõ)
by the special symbol #, and each block is of length 2
and contains exactly
ùëò
one symbol from ùëÑ √ó Œì whereas all other symbols are from Œì.

‚Ä¢
ùêº
The first block is of the form (ùëû , ùëé 0)ùëé . . . ùëé
1
ùëõ‚àí1 ‚óª . . . ‚óª.
‚Ä¢ The last block is of the form . . . (ùëû , ùëé
acc
) . . . for some ùëé ‚àà Œì .
‚Ä¢ Each ùê∂ùëñ+1 is a legal successor of the preceding ùê∂ùëñ, i.e. for every position
ùë• in ùê∂ùëñ
‚Ä≤
labelled with a symbol (ùëû, ùëé) ‚àà ùëÑ √ó Œì, there is a transition (ùëû, ùëé, ùëû , ùëè, ùëë)
‚àà ùõø s.t.
the follo wing hold.
- If ùëë ‚àà {‚àí1, 1} then position ùë• in ùê∂ùëñ+1 carries the symbol ùëè, and position
‚Ä≤
ùë• + ùëë carries the symbol (ùëû , ùëê) where ùëê is the symbol at position ùë• + ùëë in
ùê∂ ùëñ . I.e. M has written ùëè at the tape head and moved the head accordingly.
‚Ä≤
- If ùëë = 0 then the symbol at position ùë• is (ùëû , ùëè). I.e. M has written ùëè and
not moved the tape head.
All other positions remain unchanged between ùê∂ùëñ and ùê∂ùëñ+1.

‚óª
36
2 Monadic Second-Order Logic
ùêº (ùëã )
1
= 1 0 1 0 1 0 0 . . .
ùêº (ùëã )
1
= 1 0 1 0 1
ùêº (ùëã )
2
= 0 1 1 0 0 0 0 . . .
ùêº (ùëã )
2
= 0 1 1 0 0
ùêº (ùëé) = 1 1 0 1 0 0 0 . . .
ùë§ = ùëé ùëé ùëè ùëé ùëè
ùêº (ùëè) = 0 0 1 0 1 0 0 . . .
positions: 0 1 2 3 4
domain : 0 1 2 3 4 5 6 . . .

Fig. 2.2 Word and MSO interpretation (left), corresponding WS1S
interpretation (right).
2.4 Weak Second-Order Logic of One Successor
Historically, the automata-logic connection that is developed here started
with the question of the decidability of a logic called Second-Order Logic of
One Successor (S1S) which is syntactically very similar to MSO. S1S
formulas are interpreted over the natural numbers, though, with a variable
interpretation assigning members of N to first-order variables and subsets of
N to second-order variables. If the interpretation of second-order variables
is restricted to finite subsets than the logic is called Weak Second-Order
Logic of One Successor (WS1S).
Note that this is not far away from the interpretation of MSO over (finite)
words.
The most notable difference is a purely technical one: in a WS1S-
interpretation, every position, i.e. natural number, can belong to an arbitrary
number of finite sets interpreting the second-order variables. In MSO,
though, every position (of the underlying Œ£-word) belongs to the
interpretation of exactly one symbol from Œ£, and arbitrarily many sets
interpreting the second- order variables from V2. Fig. 2.2
depicts the difference. Note though, that belonging to exactly one of finitely
many sets can be defined in MSO, for instance via
Œ£
ùúë
‚à∂= ‚àÄùë•.
ùëé(ùë•) ‚àß
¬¨ùëè(ùë•) .
uni

‚ãÅ
‚ãÄ
ùëé‚ààŒ£
ùëè‚ààŒ£
ùëè‚â†ùëé
Hence, we could equally have introduced MSO as a logic being interpreted
over finite initial intervals of the natural numbers, i.e. the positions in a
finite word, without distinguishing between alphabet symbols ùëé and
second-order variables ùëã. Then, an MSO formula with ùëõ free second-order
variables (and no free first-order variables) ùëõ
could be seen as being interpreted over a finite word over the alphabet {0,
1} , so that a single alphabet letter provides the interpretation of all free
second-order variables.
This may even be the more natural interpretation for these second-order
formulas as it leads to a slightly simpler syntax without alphabet symbols.
The reason for why MSO has been introduced in the slightly more
cumbersome way is the use of automata theory in its traditional form where
automata accept words over an arbitrary but fixed alphabet.
There is, however, another difference between MSO and WS1S that is not
simply due to a choice of presentation. Consider the formula ùúë ‚à∂= ‚àÄùë•‚àÉùë¶ ùë• < ùë¶.
As an MSO
formula, ùúë is unsatisfiable, as no finite word can provide a position further
to the right of any position. However, as a WS1S formula, ùúë is satisfiable.
Note that it does not contain second-order variables, let alone free ones.
Hence, satisfiability of ùúë
2.4 Weak Second-Order Logic of One Successor
37

boils down to checking whether in the domain of natural numbers, for every
element there is a greater one which is clearly true.
Thus, MSO over finite words and WS1S are not the same logic. They are,
however, not only almost identical syntactically and very similar
semantically, but they are also similar in terms of their computational
complexity. It is easy to reduce satisfiability of one of them to the other.
Lemma 2.22 For every MSO formula ùúë there is an equi-satisfiable ùúì ‚àà
WS1S s.t.
‚à£ùúì‚à£ = O(‚à£ùúë‚à£) .
Proof The trick is to see that a model of an MSO formula over an alphabet
Œ£ can fit into a finite prefix of the ordered natural numbers, and that
quantifier relativisation can be used to restrict attention of all the logical
operators to such a finite prefix. Let ùëß be a fresh first-order variable not
occurring in ùúë and let
Œ£
ùúì
‚à∂= ‚àÉùëß.ùúë
‚áÇ
‚àß ùúë‚áÇ
uni ùëß
ùëß
where relativisation of quantification w.r.t. some first-order variable ùëß is
defined via (‚àÉùë• .ùúë)‚áÇ
‚à∂= ‚àÉùë•.ùë• < ùëß ‚àß ùúë‚áÇ

,
(‚àÉùëã .ùúë)‚áÇ
‚à∂= ‚àÉùëã .(‚àÄùë• . ùëã (ùë•) ‚Üí ùë• < ùëß) ‚àß ùúë‚áÇ
,
ùëß
ùëß
ùëß
ùëß
commutes with Boolean operators and does not change atomic formulas.
Now suppose that ùúë is an MSO formula over some alphabet Œ£ and first- and
second-order variables from V ,
1 V2, and that it has a model (ùë§, ùêº ) for some ùë§ ‚àà Œ£+
‚Ä≤
and corresponding assignment ùêº. Let ùêº be the interpretation for the resulting
WS1S
formula ùúì that agrees with ùêº on all variables in V1 ‚à™ V2, and additionally
satisfies
‚Ä≤
‚Ä≤
ùêº (ùëß) = ‚à£ùë§‚à£
and

ùêº (ùëé) = {ùëñ ‚à£ ùë§(ùëñ) = ùëé} for any ùëé ‚àà Œ£ .
‚Ä≤
A straightforward induction on the structure of ùúë‚áÇ
‚äß ùúì
ùëß
shows that we have ùêº
. So,
ùúì is also satisfiable. Likewise, a finite word model for ùúë can be extracted
from a satisfying assignment of ùúì.
‚óª
The converse direction, reducing WS1S satisfiability to MSO satisfiability
over finite words, is not as easy as that. In particular, this would have to
capture the satisfiability of the WS1S formula ‚àÄùë•‚àÉùë¶ ùë• < ùë¶ on a genuinely
finite domain. We do not attempt to find some elaborate construction that
realises this. Instead, we observe that the translation of MSO into NFA from
Sect. 2.2.2 can be modified to capture WS1S using NF A.
Theorem 2.23 The satisfiability problem of WS1S is decidable.
Proof As in the case of MSO, we can assume WS1S formulas to be
normalised so that first-order variables have been replaced by second-order
ones. Let 2N denote the set fin
of finite subsets of N. We build, for each WS1S formula ùúë(ùëã , . . . , ùëã
1
ùëõ ), an NFA A ùúë
ùëõ

over the alphabet {0, 1} s.t. for every variable interpretation ùêº ‚à∂ {ùëã , . . . , ùëã
1
ùëõ } ‚Üí 2N
fin
we have
38
2 Monadic Second-Order Logic
‚àó
‚éõ0‚éû
ùêº ‚äß ùúë
iff
enc(ùêº) ‚éú ‚ãÆ ‚éü ‚äÜ ùêø(Aùúë )
(2.1)
‚éù 0 ‚é†
ùëõ
where enc(ùêº) is the shortest word representing ùêº over the alphabet {0, 1}
in the
sense that ùëó ‚àà ùêº(ùëãùëñ) iff the symbol in the ùëñ-th component of the ùëó -th symbol
in enc(ùêº) is 1. Note that being shortest means that enc(ùêº) does not end with
leading zeros, resp. trailing zeros in a word representation with the least
significant bit at the word's beginning. So enc(ùêº) must not end on 0 ‚à∂= (0, . .
. , 0). Thus, (2.1) demands that Aùúë

is built such that it accepts the encoding of ùêº regardless of how many
leading zeros its representation contains.
The inductive construction of Aùúë is similar to the construction of NFA for
MSO formulas. For atomic formulas they are in fact the same. Also,
disjunctions can be handled using an ordinary union construction on NFA
since this preserves (2.1). However, projection and complementation, used
on the NFA side to handle existential quantification and negation on the
formula side, do not generally preserve the invariant (2.1). When applied
straightforwardly, they will result in NFA that only recognise a subset of
enc(ùêº)0‚àó, namely enc(ùêº)0ùëö for all ùëö ‚â• ùëö0 for some ùëö0 > 0. It is then
necessary to amend A‚àÉùëã .ùúë , resp. A
ùëñ
¬¨ ùúë after projection or complementation
in order to maintain (2.1), by making those states final from which an
ordinary final state can be reached under a sequence of 0-symbols.
At last, it remains to be seen that this modified construction can be used to
decide WS1S. We claim that the construction guarantees that ùúë is satisfiable
iff ùêø(Aùúë ) ‚â† ‚àÖ.
So suppose that ùúë has a model ùêº. According to (2.1), we have enc(ùêº)0‚àó ‚äÜ
ùêø(Aùúë ).
Since the left side is clearly non-empty, we get that ùêø(Aùúë ) ‚â† ‚àÖ as w ell.
Suppose, on the other hand, that ùêø(Aùúë ) ‚â† ‚àÖ. Let ùëõ be the number of free ùëõ
‚àó
ùëõ
‚àó
variables in ùúë. Then there must be a shortest word ùë§ ‚àà ({0, 1} ) ‚àñ ({0} ) s.t.

ùëõ
‚àó
ùë§ ({0} ) ‚äÜ ùêø(Aùúë ). Then ùë§ uniquely induces an interpretation ùêº (namely
such that enc(ùêº) = ùë§) which yields ùêº ‚äß ùúë according to (2.1). Hence, ùúë is
satisfiable.
‚óª
The following exemplifies the difference in the NFA constructions for MSO
and for WS1S.
Example 2.24 Consider the formula ùúë ‚à∂= ‚àÄùëã
ùëã
1‚àÉùëã2
1 < ùëã2 where ùëã1 < ùëã2 expresses
that the maximum of ùëã2 is strictly larger than the maximum of ùëã1, if the
latter exists. Note that ùëã1 < ùëã2 is generally definable in MSO, resp. WS1S.
Here we consider it as an atomic formula in order to keep the example
reasonably small.
Since ùúë does not contain any first-order formulas, we simply need to
normalise it to ¬¨‚àÉùëã
ùëã
1¬¨‚àÉùëã2
1 < ùëã2 in order to translate it into an NFA. The first step consists of
building an NFA Aùëã
for ùëã

1 <ùëã2
1 < ùëã2, for instance the following one.
2.4 Weak Second-Order Logic of One Successor
39
‚éõ0 ‚éû ‚éõ0 ‚éû
‚éõ0 ‚éû ‚éõ1 ‚éû ‚éõ1 ‚éû
,
,
,
‚éù0‚é† ‚éù1‚é† ‚éõ1 ‚éû ‚éõ1 ‚éû ‚éù ‚é† ‚éù ‚é† ‚éù ‚é†
,
0
0
1
‚éù0‚é† ‚éù1‚é†
Aùëã1<ùëã2
‚éõ0 ‚éû
‚éù1‚é†
Next we project each alphabet symbol onto the first component, resulting in
the

‚Ä≤
following NFA A .
0
0, 1
1
0
In a construction for MSO, this could be taken as A‚àÉùëã ùëã
. However, for WS1S,
2
1 <ùëã2
this is not correct (yet). Note that it does not satisfy (2.1) from the proof of
Thm. 2.23.
Take, for instance, the WS1S interpretation ùêº ‚à∂ ùëã1 ‚Ü¶ {2, 4, 5} with enc(ùêº) =
001011.
‚Ä≤
‚àó
‚Ä≤
Note that enc(ùêº) is not accepted by A , and therefore enc(ùêº)0
/
‚äÜ ùêø(A ). However,

if we donate leading zeros to the encoding of ùëã1, for instance as in
0010110, then we obtain an accepted word.
The key observation now is that for MSO, the matter of leading zeros is
simply decided by the length of the underlying word that determines the
length of representations of the encodings of the variable interpretations.
For WS1S however, there is no such underlying word length: a variable
interpretation can take any length that includes the largest indices in the sets
associated with any second-order variable. Most of all, if the shortest of
these encodings is captured by the construction, and (2.1) is maintained,
then this guarantees that the NFA make no additional assumptions on the
representation of such words enc(ùêº) other than the ability to write them
down
‚Ä≤
on a prefix of N. Hence, we modify A above to
0
0, 1
1
A‚àÉùëã ùëã
2
1 <ùëã2
0
in order to ensure that it also accepts the shortest encodings of such
interpretations.
Note that the state on the right has become final because it can reach the
final
‚àó

state on the left through a series of 0-symbols. Moreover, ùêø(A‚àÉùëã ùëã
) = {0, 1} .
2
1 <ùëã2
Hence, ùêø(A¬¨‚àÉùëã ùëã
) = ‚àÖ, and this complementation obviously maintains (2.1).
2
1 <ùëã2
Next, we project it down to the alphabet {()} of the empty tuple, yielding
‚àó
ùêø (A‚àÉùëã
ùëã
) = ‚àÖ as well, and therefore ùêø(Aùúë ) = {()} , confirming that
1 ¬¨‚àÉùëã2
1 <ùëã2
ùúë is satisfiable.
Note how the construction for MSO would deviate after building A‚àÉùëã ùëã
as the
2
1 <ùëã2

‚Ä≤
intermediately constructed A above, accepting (0 + 1)‚àó1. Complementing it
yields
OceanofPDF.com

40
2 Monadic Second-Order Logic
‚àó
some A¬¨‚àÉùëã ùëã
accepting (0 + 1) , and projecting it onto empty tuples yields
2
1 <ùëã2
+
A‚àÉùëã
ùëã
recognising () . Finally, complementing it yields Aùúë accepting
1 ¬¨‚àÉùëã2
1 <ùëã2
{ùúÄ}. Now, since its language is non-empty as well, one may be inclined to
deduce that ùúë should be satisfiable as an MSO formula which it is not.
However, note that in the MSO construction, Aùúë accepts all words ùë§,
adorned by an encoding of the interpretation ùêº of its free variables (here:
none), such that ùë§, ùêº ‚äß ùúë. Thus, the construction shows that ùúÄ is the only
model for ùúë, and this can be taken in one of two ways.
First, we recall that, by convention, models of logical formulas should be
nonempty, i.e. satisfiability of ùúë should correctly correspond to Aùúë 's ability
to accept a non-empty word. Here, Aùúë does not, so this does indeed confirm
that ùúë is unsatisfiable as an MSO formula. Second, if we allowed the empty

word as domain for the interpretation of MSO formulas we would find that
ùúÄ ‚äß ‚àÄùëã
ùëã
1‚àÉùëã2
1 < ùëã2 indeed for
trivial reasons, as the only available set for interpreting ùëã1 is ‚àÖ. We can
then choose
‚àÖ as well as the interpretation of ùëã2, and ùëã1 < ùëã2 is indeed satisfied, even
though it looks like it should not, simply because ‚àÖ has no maximal
element.
2.5 Presburger Arithmetic
Presburger Arithmetic (PA) is the first-order theory of the natural numbers
with addition. Its syntax is given by the grammar
ùúë ‚à∂‚à∂= ùë• + ùë¶ = ùëß ‚à£ ùúë ‚à® ùúë ‚à£ ¬¨ùúë ‚à£ ‚àÉ ùë• ùúë
where ùë•, ùë¶, ùëß ‚àà V1. As with WS1S, the first-order variables are interpreted
as unbounded natural numbers, and + denotes the usual addition relation.
Formally, let ùêº ‚à∂ V1 ‚Üí N be a variable assignment. Satisfaction of a PA
formula by an interpretation ùêº is explained inductively as follows.
ùêº ‚äß ùë• + ùë¶ = ùëß
iff
ùêº (ùë•) + ùêº (ùë¶) = ùêº (ùëß)
ùêº ‚äß ùúë ‚à® ùúì
iff

ùêº ‚äß ùúë or ùêº ‚äß ùúì
ùêº ‚äß ¬¨ùúë
iff
ùêº /
‚äß ùúë
ùêº ‚äß ‚àÉùë• ùúë
iff
there is ùëê ‚àà N with ùêº[ùë• ‚Ü¶ ùëê] ‚äß ùúë
Besides the usual Boolean operators, universal quantification etc., several
additional constructs can be defined.
ùúë(0) ‚à∂= ‚àÉùëõ.ùëõ + ùëõ = ùëõ ‚àß ùúë(ùëõ)
ùë• = ùë¶
‚à∂= ùë• + 0 = ùë¶
ùë• ‚â§ ùë¶
‚à∂= ‚àÉùëß ùë• + ùëß = ùë¶
ùë• ‚â† ùë¶
‚à∂= ¬¨(ùë• = ùë¶)
succ(ùë•, ùë¶) ‚à∂= ùë• < ùë¶ ‚àß ¬¨‚àÉùëß.ùë• < ùëß ‚àß ùëß < ùë¶
ùë• < ùë¶
‚à∂=

ùë• ‚â§ ùë¶ ‚àß ùë• ‚â† ùë¶
Not only 0 but in fact every natural number can be used as a constant and
this notation can be extended to variables as well.
ùúë(k+1) ‚à∂= ‚àÉùë¶. succ(k, ùë¶) ‚àß ùúë(ùë¶)
2.5 Presburger Arithmetic
41
ùúë(succ(ùë•)) ‚à∂= ‚àÉùë¶. succ(ùë•, ùë¶) ‚àß ùúë(ùë¶ )
We can define limited forms of multiplications, namely those between a
variable and a constant.
ùúë(0 ‚ãÖ ùë•) ‚à∂= ùúë(0) ,
ùúë(1 ‚ãÖ ùë•) ‚à∂= ùúë(ùë•) ,
ùúë((k + 1) ‚ãÖ ùë•) ‚à∂= ùúë(k ‚ãÖ ùë• + ùë•)
Also note that addition is not restricted to a binary operation only.
ùëõ
ùëõ‚àí1
‚àë ùë•
. . .
.ùë•
ùë¶
ùëñ
= ùëß

‚à∂= ‚àÉùë¶2
‚àÉùë¶ùëõ‚àí1 1 + ùë•2 = ùë¶2 ‚àß ( ‚ãÄ ùëñ‚àí1 + ùë•ùëñ = ùë¶ùëñ) ‚àß ùë¶ùëõ‚àí1 + ùë•ùëõ = ùëß
ùëñ=1
ùëñ=3
Example 2.25 Let ùëÉ = {(ùëö , ùëü
, ùëü
0
0), . . . , (ùëöùëõ‚àí1
ùëõ‚àí1)} with ùëöùëñ ‚â• 1, ùëüùëñ ‚â• 0 for all
ùëñ ‚àà [ùëõ]. For every such fixed parameter list ùëÉ, PA can define the set of all
numbers that are congruent to ùëüùëñ modulo ùëöùëñ:
ùúë ùëÉ (ùë•)
‚à∂=
‚ãÄ
‚àÉùë¶.ùë• = m ‚ãÖ ùë¶ + r
(m,r)‚ààùëÉ
Then the PA formula
‚àÉùëß‚àÄùë• .ùë• > ùëß ‚àß ùúë
(ùë•) ‚Üí ‚àÉùë¢‚àÉùë£ ùë• =
{(3,0)}

15ùë¢ + 27ùë£
asserts that any large enough multiple of three can be written as a
nonnegative linear combination of the numbers 15 and 27 whose greatest
common divisor is 3.
WS1S can now be used to derive a fairly simple argument showing that
Presburger Arithmetic - precisely: its satisfiability problem - is decidable.
Note that the satisfiability problem asks, given a PA formula ùúë, for the
existence of an interpretation ùêº ‚à∂ V1 ‚Üí N s.t. ùêº ‚äß ùúë. As usual, it suffices to
consider interpretations that map the free variables to natural numbers.
Hence, a PA sentence is satisfiable iff it is satisfied by the empty
interpretation iff it is valid.
The trick in the reduction to WS1S satisfiability is to regard a natural
number by its binary encoding. We choose to write the least significant bit
on the left; this is not a fundamental but a very natural choice as we will
see.
Let ùêº be a PA interpretation of the (first-order) variables ùë• , . . . , ùë•
1
ùëõ . With this
we associate a WS1S interpretation ÀÜ
ùêº
of corresponding second-order variables
ùëã , . . . , ùëã
1
ùëõ via
ÀÜ

ùëè
ùêº (ùëã ùëó ) = {ùëè ‚à£ ùêº (ùë• ùëó ) √∑ 2 ‚â° 1 mod 2 }
for any ùëó ‚àà {1, . . . , ùëõ}, Here √∑ denotes integer division as usual.
This turns the first-order PA interpretation ùêº, mapping a variable ùë• ùëó to a
number ùëù ‚àà N, into a second-order WS1S interpretation ÀÜ
ùêº , mapping the variable ùëã ùëó to the
set of positions corresponding exactly to the set bits in the binary
representation of ùêº (ùë• ùëó ). Note that this is necessarily a finite set. With this
we can formulate the core of the reduction establishing decidability of PA.
42
2 Monadic Second-Order Logic
Theorem 2.26 For every PA formula ùúë there is a WS1S formula Œ¶ s.t. ‚à£Œ¶‚à£ =
O(‚à£ùúë‚à£) and for any PA variable interpretation ùêº we have ùêº ‚äß ùúë iff ÀÜ
ùêº ‚äß Œ¶ .
Proof We give an inductive construction of Œ¶ ‚à∂= tr(ùúë). W.l.o.g. we assume
that ùúë
uses the variables ùë• , . . . , ùë•
1
ùëõ only. The translation simply replaces any first-order PA
variable ùë•ùëñ with the second-order WS1S variable ùëãùëñ. The only interesting
case is that of atomic addition formulas. The other cases are handled via
tr(ùúë ‚à® ùúì) ‚à∂= tr(ùúë) ‚à® tr(ùúì) ,

tr(¬¨ùúë) ‚à∂= ¬¨ tr(ùúë) ,
tr(‚àÉùë• ùúë
ùëñ
)
‚à∂= ‚àÉùëãùëñ tr( ùúë) .
Moreover,
tr(ùë•
, ùëã , ùê∂
ùëñ + ùë• ùëó
= ùë•ùëò )
‚à∂= ‚àÉùê∂ .¬¨ùê∂(0) ‚àß ‚àÄùë¶.(ùëãùëò (ùë¶) ‚Üî odd ùë¶ (ùëãùëñ
ùëó
))‚àß
+
(ùê∂ (succ(ùë¶)) ‚Üî two (ùëã , ùëã , ùê∂ ))
ùë¶
ùëñ
ùëó
where
odd ùë¶ (ùê¥, ùêµ, ùê∂) ‚à∂= (ùê¥(ùë¶) ‚àß ¬¨ùêµ(ùë¶) ‚àß ¬¨ùê∂(ùë¶)) ‚à® (¬¨ùê¥(ùë¶) ‚àß ùêµ(ùë¶) ‚àß ¬¨ùê∂(ùë¶))‚à®

(¬¨ ùê¥(ùë¶) ‚àß ¬¨ùêµ(ùë¶) ‚àß ùê∂ (ùë¶)) ‚à® ( ùê¥(ùë¶) ‚àß ùêµ(ùë¶) ‚àß ùê∂ (ùë¶))
+
two (ùê¥, ùêµ, ùê∂) ‚à∂= (¬¨ùê¥(ùë¶) ‚Üí ùêµ(ùë¶) ‚àß ùê∂(ùë¶)) ‚àß (¬¨ùêµ(ùë¶) ‚Üí ùê¥(ùë¶) ‚àß ùê∂(ùë¶))‚àß
ùë¶
(¬¨ùê∂ (ùë¶) ‚Üí ùê¥(ùë¶) ‚àß ùêµ(ùë¶)) .
Note that tr(ùë•ùëñ + ùë• ùëó = ùë•ùëò ) formalises addition of two binary numbers
according to the standard textbook method: at every position we introduce a
carry bit which is unset at the least significant position, and then in every
next position it is set whenever at least two bits of the two summands and
the carry bit at the previous position are set.
Moreover, a bit in the resulting sum is set whenever an odd number of the
two bits of the summands at this position and the carry bit are set.
It is then straightforward to show by induction that ùêº ‚äß ùúë iff ÀÜ
ùêº ‚äß Œ¶ holds. Likewise,
‚à£Œ¶‚à£ is clearly linear in ‚à£ùúë‚à£.
‚óª
Putting this reduction from PA to WS1S together with the statement of
Thm. 2.23
we obtain decidability of PA.
Corollary 2.27 The satisfiability problem for PA is decidable.
The automata-theoretic procedure obtained in this way has non-elementary
worst-case complexity, inherited from WS1S. In practice, however, one sees
that the automata for WS1S formulas that stem from the translation of PA
formulas remain relatively small and that, as a result, the automata-theoretic

procedure is competitive. Indeed, there exists a theoretical justification for
this phenomenon.
Proposition 2.28 The minimal DFA for a WS1S formula resulting from the
transla-O(ùëõ)
tion of a PA formula of size ùëõ has size 22
.
Bibliographic Notes for Chapter 2
43
Bibliographic Notes
The automata-logic connection presented here for Monadic Second-Order
Logic on finite words was started by B √ºchi and Elgot [BE58, B √ºc60,
Elg61] and independently by Trakhtenbrot [Tra61]. The main focus of
attention was WS1S, the Weak Second-Order Logic of One Successor, which
was found to be decidable using the theory of finite automata on finite
words, even though the domain of interpretation in this logic is comprised
of the natural numbers. Weakness, i.e. the fact that second-order predicates
only ever range over finite subsets of the natural numbers, makes the theory
of finite words applicable.
The exposition here considers Monadic Second-Order Logic over finite
words.
It is different in that the domain of interpretation of any formula is always
finite a priori. Hence, MSO and WS1S do not share the same validities. The
fact that decidability of both can be established in a very similar manner is
the reason for them not always being distinguished very clearly. Some
discussions on the semantic differences between MSO on finite words and
WS1S can be followed in works of Klarlund [Kla99], or Ayari and Basin
[AB00]. While the construction of finite automata for MSO formulas is
slightly cleaner than that for WS1S and is often

+
what is presented in the literature, Fiedor et al. [FHJ 17] describe how to
construct automata for WS1S formulas efficiently.
The automata-logic connection, in particular the automata-theoretic
approach to the decidability of logics like MSO, is covered in a survey
paper by Thomas [Tho97].
The original proof of decidability of PA is due to Presburger [Pre27] using
quantifier elimination. The logic has received quite some attention since
then, probably because of its decidability which is in contrast to the
undecidability of Peano Arithmetic [G √∂d31, Kle43] that contains both
addition and multiplication. It is worth noting that Skolem Arithmetic, the
pendant of Presburger Arithmetic with only multiplication and no addition,
is decidable, too [FR79, Chp. 5]. As with Presburger Arithmetic, Skolem
Arithmetic can also be shown to be decidable using automata-theoretic
constructions [BG00], in this case automata operating on trees rather than
words. Trees are the topic of Part III.
Presburger Arithmetic has remained an object of study to date. A problem
that had been open for a long time was the exact complexity of its
satisfiability problem.
Note that the translation into WS1S only yields a non-elementary upper
bound on the time and space complexity, and this is known not to be
optimal. Fischer and Rabin gave a doubly exponential lower bound [FR74]
which is close to a triply exponential upper bound given by Oppen only
shortly afterwards [Opp78]. Later, Berman showed that the complexity lies
in between: it is complete for the class of problems that can be solved by an
alternating Turing Machine in doubly exponential time with linearly many
alternations only [Ber80]. Note that alternating doubly exponential time
with arbitrarily many alternations is the same as deterministic doubly
exponential space [CKS81] which is between nondeterministic doubly
exponential time and deterministic triply exponential time.
The automata-theoretic approach to Presburger Arithmetic has also been
investigated further. Prop. 2.28 about upper bounds on the size of minimal

DFA for PA
44
2 Monadic Second-Order Logic
formulas is due to Klaedtke [Kla08]. The findings there agree with those
about the computational complexity made above: the dependency is doubly
exponential on the size resp. length of a formula but only linear on the
number of its quantifier alternations. A considerable amount of work has
been spent on extending the decidability result for Presburger Arithmetic,
and the automata-theoretic approach has played a significant role in this,
cf. an overview by Haase [Haa18].
Exercises
Exercise 10 Show that every regular language is MSO-definable by
induction on the structure of regular expressions. Hint: Construct, for every
regular expression ùõº, an MSO formula ùúë ùõº(ùë•, ùë¶) s.t. for any word ùë§ ‚àà Œ£+ and
any ùêº with 0 ‚â§ ùêº(ùë•) ‚â§ ùêº(ùë¶) < ‚à£ùë§‚à£
the f ollowing holds:
ùë§ , ùêº ‚äß ùúë ùõº (ùë•, ùë¶)
iff
ùë§ (ùêº (ùë•)) . . . ùë§(ùêº (ùë¶)) ‚àà ùêø(ùõº)
Exercise 11 Complete the proof of Lemma 2.13 by carrying out the
induction on the structure of MSO formulas.
Exercise 12 Write down MSO formulas ùúë(ùë•, ùë¶) that express the following
properties.
a) ùë• = ùë¶ (without using the symbols '=' and '<'),
b) ùë¶ = ùë• + ùëò , i.e. ùë¶ is ùëò positions behind ùë• for any fixed ùëò ‚àà N .

Construct MSO sentences ùúë that define languages which are informally
described as follows.
c) Every ùëò -th position contains the letter ùëé (for some fixed ùëò ‚àà N).
d) Let Œ£ = {ùëé , . . . , ùëé
0
ùëõ‚àí1}. A letter ùëéùëñ (not at the word's end) is followed by
ùëé(ùëñ+1) mod ùëõ .
e) Every ùëé is succeeded somewhere by a ùëè and vice-versa for as long as the
word's end is not reached. In between there are only symbols ùëê.
f) The (finite) language consisting of all words that are permutations of a
fixed word ùë§ ‚àà Œ£+ .
g) The language of all words of the form ùë¢#ùë£ s.t. ùë¢, ùë£ do not contain the
symbol
# and all letters occurring somewhere in ùë¢ also occur somewhere in ùë£ and
vice-versa.
Which of these languages, resp. properties, are already FO-definable?
Exercise 13 Construct an MSO sentence that defines exactly the languages
recognised by the following NFA.
Exercises for Chapter 2
45
ùëè
ùëé
ùëé, ùëè

ùëè
ùëé
ùëè
ùëé
ùëé
ùëè
Exercise 14 Construct NFA that recognise exactly those languages that are
defined by the following MSO-sentences.
a) ‚àÄùë•.ùëé(ùë•) ‚Üí ‚àÄùë¶.ùë• < ùë¶ ‚Üí ùëè(ùë¶)
b) ‚àÉùë•.ùëè(ùë•) ‚àß ‚àÄùë¶.ùë¶ < ùë• ‚Üí ùëé(ùë¶ )
c) ‚àÄùëã ‚àÉùë¶ ‚àÄùë•.ùëã(ùë•) ‚Üí ùë• ‚â§ ùë¶ ‚àß ùëé(ùë¶ )
d) ‚àÉùëã ‚àÉùëå .(‚àÄùëß.ùëã(ùëß) ‚à® ùëå (ùëß)) ‚àß ‚àÄùë• ‚àÄùë¶.ùëã(ùë•) ‚àß ùëå (ùë¶) ‚Üí ùë• < ùë¶ ‚àß ùëé(ùë•) ‚àß
ùëè(ùë¶ ) e) ‚àÄùë•.(‚àÉùëß ùë• < ùëß) ‚Üí ‚àÉùë¶.ùë• < ùë¶ ‚àß (ùëé(ùë•) ‚Üî ¬¨ùëé( ùë¶))
Exercise 15 In accordance with EMSO let AMSO be the fragment of MSO
that contains formulas of the form ‚àÄùëã . . .
ùúì
1
‚àÄùëãùëõ
where ùúì is a first-order formula. Show
that a language is MSO-definable iff it is AMSO-definable.
Exercise 16 The word problem - also known as the model checking
problem - for MSO is: given a word ùë§ ‚àà Œ£+ and an MSO sentence ùúë,

decide whether ùë§ ‚àà ùêø(ùúë ).
Construct an algorithm that solves the word problem for MSO. Its space
usage should only be polynomial in the size of its input, i.e. ‚à£ùë§‚à£ + ‚à£ùúë‚à£.
Exercise 17 Four people are trying to cross a bridge. They only have one
torch. At any time, at most two people can cross the bridge. They can wait
in the darkness on either side, but they can only cross the bridge with the
help of the torch's light.
Person A needs 5 min to cross the bridge, person B needs 10 min, person C
20 min and person D 25 min. The torch's battery lasts for 60 min.
a) Explain why MSO is suitable to model this problem rather than WS1S.
b) Write a formula expressing the solvability of this problem. It should be
satisfiable iff there is a way for all four people to cross the bridge under the
constraints listed above.
Exercise 18 A farmer needs to take his dog, his cat and his mouse across a
river in a boat. The boat can take at most him and one animal, and it needs
him to sail from one side of the river to the other. Whenever the farmer is
with his animals, they are generally kind and leave each other alone.
However, whenever he is not with them, he needs to ensure that . . .
‚Ä¢ the dog and the cat are not together on one side of the river, since the cat
would talk the dog into closing the deal on a very disadvantageous
financial investment;
‚Ä¢ the cat and the mouse are not together on one side of the river, since the
mouse would get the cat to start smoking.
46
2 Monadic Second-Order Logic
Write an MSO formula whose models represent valid solutions to the
problem of taking all four animals across the river. Hint: Use {ùêπ , ùê∑ , ùê∂ ,

ùëÄ , ùêπ , ùê∑ , ùê∂ , ùëÄ
‚Ñì
‚Ñì
‚Ñì
‚Ñì
ùëü
ùëü
ùëü
ùëü }
as the underlying alphabet where the letter ùêπ‚Ñì indicates, for example, that
the F armer is on the l eft side, etc. A solution can then be represented by a
word composed of blocks of length 4 of the form ùêπ
ùê∑
ùê∂
ùëÄ
ùë†
ùë†
ùë†
ùë†
determining the location of all four
ùêπ

ùê∑
ùê∂
ùëÄ
protagonists.
Exercise 19 For ùëõ ‚â• 1 the ùëõ-queens problem is the following: place ùëõ
queens - the chess piece - onto an ùëõ √ó ùëõ chess board without one queen
being able to capture another in one move. In other words: each row, each
column and each diagonal may contain at most one q ueen.
Construct MSO formulas ùúëùëõ that are satisfiable iff the ùëõ-queens problem is
solvable. Hint: An ùëõ √ó ùëõ chess board with placed queens can be seen as a
word of length ùëõ2 over {0, 1}, for instance representing the square board
row by row.
Exercise 20 Complete the proof of Thm. 2.21 by writing down MSO
formulas that express the properties stated in this proof.
Exercise 21 We introduce Dyadic Second-Order Logic (DSO) similar to
MSO over finite words. In DSO, second-order variables are interpreted as
binary predicates.
Hence, atomic formulas ùëã(ùë¶) from MSO get replaced by formulas of the
form ùëã (ùë¶, ùëß) with the straightforward interpretation that the pair of
positions ùë¶ and ùëß
belongs to the set of position pairs ùëã:
ùë§ , ùêº ‚äß ùëã (ùë•, ùë¶)
iff
(ùêº (ùë•), ùêº (ùë¶)) ‚àà ùêº (ùëã )
2

ùë§ , ùêº ‚äß ‚àÉùëã .ùúë
iff
‚àÉùëÄ ‚äÜ {0, . . . , ‚à£ùë§‚à£ ‚àí 1} s.t. ùë§, ùêº[ùëã ‚Ü¶ ùëÄ] ‚äß ùúë
The aim of this exercise is to study the expressiveness and decidability of
DSO, compared to MSO.
ùëõ
ùëõ
a) Show that {ùëé ùëè ‚à£ ùëõ ‚â• 1} is DSO-definable.
b) Show that every CFL is DSO-definable. Hint: Assume that a CFL is
given as a normalised context-free grammar ùê∫ with derivations of the form
ùê¥ ‚Üí ùêµùê∂
and ùê¥ ‚Üí ùëé only. Each nonterminal ùê¥ defines a set of position pairs (ùëñ, ùëó ) in
a
‚àó
given word ùë§ = ùëé . . . ùëé
ùëé
. . . ùëé
0
ùëõ‚àí1 s.t. ùê¥ ‚áí
ùëñ
ùëó . I.e. we can use nonterminals as
second-order variables. Write a DSO formula which states that

‚Ä¢ every pair of the form (ùëñ, ùëñ) belongs to ùê¥ only if ùê¥ ‚Üí ùëé and ùëé is the letter
at position ùëñ ;
‚Ä¢ every pair of the form (ùëñ, ùëó) with ùëñ < ùëó belongs to ùê¥ only if ùê¥ ‚Üí ùêµùê∂ and
corresponding pairs for ùêµ and ùê∂ can be found,
‚Ä¢ the subword from the first to the last position can be derived from ùê∫'s
starting symbol.
ùëõ
ùëõ
ùëõ
c) Show that {ùëé ùëè ùëê ‚à£ ùëõ ‚â• 1} and {ùë§ùë§ ‚à£ ùë§ ‚àà Œ£+} are DSO-definable.
d) Show that the satisfiability problem for DSO is undecidable. Hint: It is
undecidable to decide, given two context-free languages, whether their
intersection is non-empty.
Chapter 3
Alternating Finite Automata
Nondeterminism is a concept that is not inherently self-dual in the following
sense: a nondeterministic automaton may intuitively "guess" at some point
to make a choice that turns out to be good for accepting a word. This is why
it is typically easy to construct NFA for languages which are defined via
existential quantification, for instance Œ£‚àóùëéùëèùëéŒ£‚àó - the set of all words for
which there is a subword of the form ùëé ùëè ùëé. Consider, however, its

complement - the set of all words that do not contain the subword ùëéùëèùëé. By
complementation closure of REG, this is also a regular language, but
constructing a regular expression or an NFA for it directly by hand is more
difficult. What is missing is the ability to "guess" that taking some
transition is good for showing that the input should be rejected. Such an
automaton could equally go through the input from left to right and at some
point make this guess, confirming that the input contains the subword ùëéùëèùëé,
and thus reject it altogether.
We extend the model of NFA to so-called alternating finite automata (AFA)
by adding the ability to make choices leading to rejection, in particular
combining this with nondeterministic guesses leading to acceptance. We
then study the expressive power of this model with respect to the class of
regular languages. As it turns out, languages accepted by AFA are still
regular, i.e. we have only increased the pragmatic power of finite automata,
not the expressive power. Conversely, it confirms the robustness and
importance of the class REG of regular languages.
Technically, we extend the model of NFA by universal branching, the dual
concept of nondeterministic branching. The latter describes the ability to
choose a successor state in a run towards an accepting end. Universal
branching requires accepting ends to be reached through all possible
successor states. This can also be seen as a model of parallel processing of
the input word. At nondeterministic branching points, the automata select
successors state to continue with; at universal branching points, the
automata intuitively split into several copies, and each of them processes
the remainder of the input word starting from a different successor state.
It is not hard to imagine that this power could be used to construct a simple
automaton for recognising the language of all words that do not contain
ùëéùëèùëé: upon reading a ùëè simply continue to the next position. Upon reading
an ùëé, branch universally: one copy continues with the next position in the
same manner, the other copy
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025

47
M. Hofmann and M. Lange, Automata Theory and Logic,
https://doi.org/10.1007/978-3-662-72154-4_3
48
3 Alternating Finite Automata
checks that this ùëé is not followed by ùëèùëé. When all launched copies accept,
the word does not contain ùëéùëèùëé anywhere.
This view of alternating automata running copies in parallel is merely
useful for intuition. Acceptance of a word by an AFA is defined without
referring to parallelism, just like acceptance by an NFA is not defined by
referring to guesses.
It is simply unnecessarily cumbersome to try to formalise the notions of
parallelism and guessing at this point. Instead, the notion of a run can be
extended accordingly to explain acceptance by an AFA.
3.1 Run Trees
The transition function of an NFA A maps a state ùëû and an alphabet symbol
ùëé to a set {ùëû , . . . , ùëû
1
ùëò } of successor states. The connection between the ùëûùëñ is implicitly
understood to be a disjunction - A can continue in ùëû1 or ùëû2 or . . . in order
to accept.
Likewise, one could see the combination of these states to be conjunctive
which yields the model of universal automata. Alternating automata should
possess both modes of branching, hence we need to make the connection
explicit. This is done by replacing sets with Boolean combinations,
represented by propositional formulas.

Definition 3.1
+
Let ùëÑ be a set. The set B (ùëÑ) of positive Boolean formulas over ùëÑ
is the smallest set satisfying
‚Ä¢
+
ùëÑ ‚äÜ B (ùëÑ),
‚Ä¢
+
+
+
whenever ùëì , ùëî ‚àà B (ùëÑ) then ùëì ‚à® ùëî ‚àà B (ùëÑ) and ùëì ‚àß ùëî ‚àà B ( ùëÑ).
+
For example, (ùëû
, ùëû
, ùëû
2 ‚à® ùëû3) ‚àß (ùëû1 ‚àß ùëû2) ‚àà B ({ùëû1
2
3}). We use the usual rules of

associativity, commutativity, idempotence and the usual precedence of ‚àß
over ‚à® to minimise the use of parentheses and to write formulas in shortest
ways possible.
Definition 3.2 An alternating finite automaton (AFA) is an A = (ùëÑ, Œ£, ùëû , ùõø,
ùêπ
ùêº
) just
+
like an NFA but with ùõø ‚à∂ ùëÑ √ó Œ£ ‚Üí B (ùëÑ).
As with NFA, the size ‚à£A‚à£ of an AFA is the numbers of its states.
Hence, the transition function of an AFA maps a pair of a state and an input
letter to a Boolean combination of states, representing a combination of
nondeterministic and universal branchings leading to successor state. For
instance, we can read ùëû1 ‚àß
(ùëû2 ‚à®ùëû3) as universal branching between ùëû1 on one side, and the other
side consisting of a follow-up nondeterministic branching between ùëû2 and
ùëû3. However, it will be more convenient to compress these alternating
choices into one step, associated with the processing of one input letter. To
do so, we need a formal definition of satisfaction of a Boolean formula.
Definition 3.3 Let ùëÑ be a set, and ùëÄ ‚äÜ ùëÑ. Satisfaction of a Boolean
formula ùëì ‚àà
+
B (ùëÑ) by ùëÄ is defined inductively as follows.
3.1 Run Trees
49

‚Ä≤
ùëé
ùëé
0
‚àß
ùëè
ùëè
1
2
ùëé , ùëè
ùëé
ùëè
0
‚àß
Fig. 3.1 Graphical representation of the AFA from Ex. 3.5.
ùëÄ ‚äß ùëû
iff
ùëû ‚àà ùëÄ
ùëÄ ‚äß ùëì ‚à® ùëî
iff

ùëÄ ‚äß ùëì or ùëÄ ‚äß ùëî
ùëÄ ‚äß ùëì ‚àß ùëî
iff
ùëÄ ‚äß ùëì and ùëÄ ‚äß ùëî
If ùëÄ ‚äß ùëì then we say that ùëÄ is a model of ùëì .
Intuitively, ùëÄ is a model of ùëì if ùëì evaluates to true under the usual rules of
Boolean formula evaluation when all states ùëû ‚àà ùëÄ are set to true and all
states ùëû /
‚àà ùëÄ
are set of false. For example, let ùëì ‚à∂= ùëû
, ùëû
1 ‚àß (ùëû2 ‚à® ùëû3). We have {ùëû1
2} ‚äß ùëì and
{ùëû , ùëû
, ùëû
1
3} ‚äß ùëì , but {ùëû2
3} /
‚äß ùëì and {ùëû1} /
‚äß ùëì .

Runs of AFA will become trees rather than linear sequences of transitions,
i.e.
words. For the purposes of this chapter, we only need so-called unordered
trees in which there is no particular order on the child nodes of any node.
Part III of this book will deal with ordered trees instead (that arise as inputs
to automata, not as structures used to explain the processing of such
inputs). Here it suffices to regard a tree as a directed graph without cycles
and which possesses a designated root node with no predecessors. Each
node in a tree resides on a particular level which measures the distance of
this node to the tree's root. Hence, the root itself is on level 0, its successors
comprise level 1, etc.
We will speak of a ùëÑ-labelled tree for some set ùëÑ as a function which
assigns values from ùëÑ to each node of the tree. We will not distinguish
formally between the labelling function and the underlying tree structure.
Definition 3.4 A run of an AFA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
. . . ùëé
ùêº
) on a word ùë§ = ùëé0
ùëõ‚àí1 ‚àà Œ£‚àó
is a ùëÑ-labelled tree ùúå with the following properties.
‚Ä¢ The root node ùë£ 0 is labelled with A's initial state: ùúå(ùë£ 0) = ùëû ùêº.
‚Ä¢ Let ùë£ be a node on level ùëñ for ùëñ ‚àà [ùëõ], and ùë£ , . . . , ùë£
1
ùëò
be the successors of ùë£ on

level ùëñ + 1. Then we have {ùúå(ùë£1), . . . , ùúå(ùë£ùëò )} ‚äß ùõø(ùúå(ùë£), ùëéùëñ).
The run is called accepting if all its leaves are on level ùëõ, and they are all
labelled with accepting states.
As with NFA we define ùêø(A) ‚à∂= {ùë§ ‚àà Œ£‚àó ‚à£ there is an accepting run (tree)
of A on ùë§}.
Note that - as with NFAs - (accepting) runs need not be unique.
Example 3.5
‚àó
Let ùêø = {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ ‚â• 1 and for every position labelled with
ùëé
there is some later position labelled with ùëè}. There is a simple AFA
recognising ùêø which conceptually follows the description of that language.
Consider
50
3 Alternating Finite Automata
‚Ä≤
0
ùëé
0
1
ùëé

0
1
1
ùëè
0
2
2
ùëé
0
1
2
2
ùëè
0
2
2
2
ùëè
0
2

2
2
Fig. 3.2 Run of the AFA from Ex. 3.5 on the input word ùëéùëéùëèùëéùëèùëè aligned
with the transitions between the run's levels.
‚Ä≤
‚Ä≤
A = ({0, 0 , 1, 2}, {ùëé, ùëè}, 0 , ùõø, {0, 2}) with the transitions defined as
follows.
‚Ä≤
ùõø(0 , ùëé) = ùõø(0, ùëé) ‚à∂= 0 ‚àß 1
ùõø(1, ùëé) ‚à∂= 1
ùõø(2, ùëé) ‚à∂= 2
‚Ä≤
ùõø(0 , ùëè) = ùõø(0, ùëè) ‚à∂= 0
ùõø(1, ùëè) ‚à∂= 2
ùõø( 2, ùëè) ‚à∂= 2
Fig. 3.1 introduces a way to represent such AFA graphically with nodes that
do not represent states but Boolean operators in the transition function.
Disjunctions underneath conjunctions can be represented in a similar way
with nodes carrying a symbol '‚à®'. They could also be shown just like
nondeterminism usually is, i.e. using several edges with the same label.
Intuitively, A uses state 0 to search for occurrences of the letter ùëé. When one
is found, the transition to 0 ‚àß 1 makes A continue looking for further

symbols ùëé in the remainder of the input word and to search for an
occurrence of the letter ùëè. State 2
‚Ä≤
is used to signal that such a ùëè has been seen. State 0 behaves in the same
way as 0
and is only used to make sure that the empty word is not accepted.
An accepting run of A on the word ùëéùëéùëèùëéùëèùëè is shown in Fig. 3.2. Note that
it is possible to construct an NFA (and therefore also an AFA) with only two
states which recognises ùêø.
Run trees can, as they grow deeper, become wider than the number of states
of the underlying automaton. Hence, a level may contain nodes which are
labelled with the same state. This occurs multiple times in the run shown in
Fig. 3.2. However, one will not find two such nodes such that the two
subtrees under these nodes differ.
Runs with this property are of particular interest and are therefore given a
special name.
Definition 3.6 A run ùúå of an AFA on some word is called memoryless or
history-free
‚Ä≤
‚Ä≤
if for any two nodes ùë£, ùë£ on the same level such that ùúå(ùë£) = ùúå(ùë£ ), the
subtrees
‚Ä≤
rooted at ùë£ and ùë£ are isomorphic.
3.1 Run Trees

51
‚Ä≤
0
ùëé
0
1
ùëé
0
1
1
ùëè
0
2
0
ùëé
0
1
2
0
1

ùëè
0
2
2
0
2
ùëè
0
2
2
0
2
Fig. 3.3 Non-memoryless run of the AFA from Ex. 3.7.
The name suggests that the decision made by the AFA of how to branch in
node ùë£ on level ùëñ in a history-free run only depends on the current state ùúå(ùë£)
and the suffix of the input word from position ùëñ, but not on any decision
made earlier, i.e. the history of ùë£ in this run.
History-freedom is not a trivial property. The AFA of the previous Ex. 3.5
only has memoryless runs, but it is equally possible to construct AFA
without this property.
Example 3.7
‚Ä≤

‚Ä≤
‚Ä≤
Consider the AFA A ‚à∂= ({0, 0 , 1, 2}, {ùëé, ùëè}, 0 , ùõø, {0, 2}) which only differs
from the AFA A of Ex. 3.5 in a single transition:
‚Ä≤
ùõø(0, ùëé) = ùõø(0 , ùëé)
‚à∂= 0 ‚àß 1
ùõø(1, ùëé)
‚à∂= 1
ùõø(2, ùëé)
‚à∂= 2
‚Ä≤
ùõø(0, ùëè) = ùõø(0 , ùëè)
‚à∂= 0
ùõø(1, ùëè)
‚à∂= 0 ‚à® 2
ùõø( 2, ùëè)
‚à∂=
2
‚Ä≤

In state 1, A can move to state 2 as A does, in order to signal that a letter ùëè
has been found and the rest of the word is irrelevant for this branch of the
run. Likewise, it can move (back) to state 0 to continue scanning for further
symbols ùëé.
‚Ä≤
The run in Fig. 3.2 is not only a run of A on ùëéùëéùëèùëéùëèùëè, it is also a run of A
on this
‚Ä≤
word. As said before, it is memoryless. Fig. 3.3 shows a non-memoryless
run of A on the same word. The two subtrees violating history-freedom are
marked in dashed boxes.
The next theorem shows that, while it is possible to construct AFA that only
have memoryless runs, it is not possible to construct an AFA and a word on
which there are no memoryless runs.
Theorem 3.8 Let A be an AFA and ùë§ ‚àà Œ£‚àó . We have ùë§ ‚àà ùêø(A) iff there is
a memoryless and accepting run of A on ùë§ .
Proof "‚áê" This direction is trivial, since every memoryless accepting run
is an accepting run.
52
3 Alternating Finite Automata
‚Ä≤
‚Ä≤
0
0
ùëé

0
1
0
1
ùëé
0
1
0
1
ùëè
0
2
0
ùëé
0
1
2
0
1
ùëè

0
2
0
2
ùëè
0
2
0
2
Fig. 3.4 DAG representations of the memoryless runs obtained from the one
in Fig. 3.3 by means of the construction in the proof of Thm. 3.8.
"‚áí" Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
. . . ùëé
0
) be an AFA and ùë§ = ùëé0
ùëõ‚àí1 ‚àà ùêø(A). Then there
is an accepting run ùúå of A on ùë§. We now construct a memoryless run by
successively replacing subtrees, starting on level ùëõ .
‚Ä≤
‚Ä≤

Consider two nodes ùë£, ùë£ on level ùëõ, s.t. ùúå(ùë£) = ùúå(ùë£ ). Then the subtrees
rooted
‚Ä≤
‚Ä≤
at ùë£ and ùë£ are trivially isomorphic because ùë£ and ùë£ are both leaves. Now
suppose that the property of history-freedom is satisfied by all nodes on
levels below ùëñ for
‚Ä≤
‚Ä≤
some ùëñ < ùëõ, and take two nodes ùë£, ùë£ on level ùëñ such that ùúå(ùë£) = ùúå(ùë£ ). Take
the run
‚Ä≤
‚Ä≤
ùúå
which is obtained from ùúå by replacing the subtree at node ùë£ with the subtree
at node ùë£. Since the labels at their roots are the same, the result is still an
accepting run of A on ùë§. By successively eliminating violations of history-
freedom in this way, one finally arrives at a memoryless run.
‚óª
Memoryless runs can easily be represented as directed acyclic graphs
(DAGs) by sharing equal subtrees. The result of this sharing, when applied
to the run in Fig. 3.2
is shown in Fig. 3.4. Note that there are two possibilities to eliminate the
violation of history-freedom in the run in Fig. 3.3 since there are only two
subtrees in positions where there should be equal ones, and a memoryless
run is obtained by replacing either of them with the other. One possibility -

shown on the left - in fact leads to the memoryless run from Fig. 3.2. The
other - shown on the right - leads to a different memoryless run.
The following statement will be useful when analysing the expressive power
of AFA in the next section.
Corollary 3.9 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
. . . ùëé
ùêº
) be an AFA over Œ£ , ùë§ = ùëé0
ùëõ‚àí1 ‚àà Œ£‚àó . We
have ùë§ ‚àà ùêø(A) iff there is a sequence ùëÜ , . . . , ùëÜ
0
ùëõ of subsets of ùëÑ such that
‚Ä¢ ùëÜ0 = {ùëûùêº} ,
‚Ä¢ ùëÜ
ùõø
ùëñ+1 ‚äß ‚ãÄ
(ùëû, ùëé
ùëû‚ààùëÜ
ùëñ ) for all ùëñ ‚àà [ùëõ] , and
ùëñ
‚Ä¢ ùëÜ ùëõ ‚äÜ ùêπ .

3.2 Expressiveness and Succinctness
53
This follows immediately from Thm. 3.8 with the observation that the levels
of a DAG representation of a memoryless run of A on ùë§ form a sequence
with the three stated properties.
3.2 Expressiveness and Succinctness
A question arising immediately with the introduction of a new automaton
model is the one after its expressive power. In particular, how does the class
of languages acceptable by AFA compare to the class of regular languages?
It is not hard to see that AFA are at least as powerful as NFA, i.e. every
regular language is AFA recognisable.
Theorem 3.10
‚Ä≤
For every NFA A of size ùëõ there is an AFA A of size at most ùëõ + 1
‚Ä≤
states such that ùêø(A ) = ùêø(A) .
Proof
‚Ä≤
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an NFA. W.l.o.g. we assume /
‚àà ùëÑ. Let A ‚à∂=
‚Ä≤

(ùëÑ ‚à™ {}, Œ£, ùëû , ùõø , ùêπ
ùêº
) be the AFA uniquely given b y
‚éß
‚é™
‚é™
‚ãÅ
ùëù
, if ùëû ‚àà ùëÑ and ùõø(ùëû, ùëé) ‚â† ‚àÖ,
‚é™
‚Ä≤
ùõø (ùëû, ùëé)
‚à∂= ‚é® ùëù‚àà ùõø(ùëû,ùëé)
‚é™
‚é™
‚é™
, otherwise.
‚é©
‚Ä≤

Clearly, ‚à£A ‚à£ ‚â§ ‚à£A‚à£ + 1. Correctness of the construction uses the
observation that any run tree of an AFA whose transitions are purely
disjunctive can be pruned to a single branch, and that this branch is still an
accepting run (tree) if the original one is. It now suffices to see that this
branch is also a run of the NFA A. Conversely, any
‚Ä≤
accepting run of A is in fact an accepting run tree of A on the same word.
‚óª
The more interesting question concerns the opposite direction: we will show
that AFA can only recognise regular languages by translating AFA into
equivalent NFA, making use of Cor. 3.9. This is analogous to the powerset
construction for transforming NFA into equivalent DFA.
Theorem 3.11
‚Ä≤
ùëõ
For every AFA A of size ùëõ there is an NFA A of size at most 2 such
‚Ä≤
that ùêø(A ) = ùêø(A) .
Proof
‚Ä≤
ùëÑ
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, Œ£,

ùêº
) be an AFA. Define the NFA A ‚à∂= (2
{ùëû ùêº }, Œî,
‚Ä≤
‚Ä≤
ùêπ ) s.t. ùêπ ‚à∂= {ùëÜ ‚à£ ùëÜ ‚äÜ ùêπ} and
Œî
‚Ä≤
‚Ä≤
(ùëÜ, ùëé)
‚à∂= {ùëÜ ‚à£ ùëÜ ‚äß ‚ãÄ ùõø(ùëû, ùëé )}
ùëû‚ààùëÜ
ùëÑ
‚Ä≤
for any ùëÜ ‚àà 2 , ùëé ‚àà Œ£. The bound on the size of A is obvious. It remains to
be seen
‚Ä≤
that ùêø(A ) = ùêø(A).
"‚äá" Suppose ùë§ = ùëé . . . ùëé
0

ùëö‚àí1 ‚àà ùêø(A). According to Cor. 3.9 there is a sequence
ùúå = ùëÜ , . . . , ùëÜ
ùõø
0
ùëö
of state sets such that ùëÜ0 = {ùëûùêº }, ùëÜùëö ‚äÜ ùêπ and ùëÜùëñ+1 ‚äß ‚ãÄ
(ùëû, ùëé
ùëû‚ààùëÜ
ùëñ )
ùëñ
54
3 Alternating Finite Automata
‚Ä≤
or, equivalently, ùëÜ
, ùëé
ùëñ+1 ‚àà Œî(ùëÜùëñ
ùëñ ) for ùëñ ‚àà [ùëö]. Hence, ùúå is an accepting run of A
on
ùë§ .
‚óª

"‚äÜ" Analogously.
So AFA are not more expressive than NFA but the translation given here
incurs an exponential blowup. This is similar to the situation between NFA
and DFA, so the question arises whether AFA are truly more succinct than
NFA.
Example 3.12 Let Œ£ = {ùëé}. We leave it as an exercise to prove that the
language ùêø 29393 ‚à∂= {ùë§ ‚àà Œ£‚àó ‚à£ ‚à£ùë§‚à£ ‚â° 0 mod 29393} cannot be
recognised by an NFA with less than 29393 states.
However, there is an AFA with only 57 states which recognises ùêø29393.
This may seem random at first, but the construction principle becomes
clearer when one is presented with a simple connection between the
numbers 57 and 29393. We have 29393 = 7 ‚ãÖ 13 ‚ãÖ 17 ‚ãÖ 19
and
57 = 1 + 7 + 13 + 17 + 19 .
For ùëõ ‚â• 1 let A
, Œ£,
, ùêπ
ùëõ
= (ùëÑ ùëõ
(ùëõ, 0), ùõøùëõ
ùëõ ) with ùëÑ ùëõ ‚à∂= {(ùëõ, 0), . . . , (ùëõ, ùëõ ‚àí 1)}, ùêπùëõ ‚à∂=
{(ùëõ, 0)} be the standard DFA for the languages ùêøùëõ ‚à∂= {ùë§ ‚àà Œ£‚àó ‚à£ ‚à£ùë§‚à£ ‚â° 0
mod ùëõ}. Their transition relation forms a simple cycle: ùõøùëõ((ùëõ, ùëñ), ùëé) ‚à∂= (ùëõ, ùëñ
+ 1 mod ùëõ). Usually it would suffice to name the states 0, . . . , ùëõ ‚àí 1, but

here they are tagged with the constant ùëõ as we will compose several such
DFA, and this will avoid problems with different states of the same name.
Now consider A ‚à∂= (ùëÑ, Œ£, 0, ùõø, ùêπ) with
ùëÑ
‚à∂= {0} ‚à™ ùëÑ7 ‚à™ ùëÑ13 ‚à™ ùëÑ17 ‚à™ ùëÑ19
ùêπ
‚à∂= {0} ‚à™ ùêπ7 ‚à™ ùêπ13 ‚à™ ùêπ17 ‚à™ ùêπ19
and
ùõø(0, ùëé) ‚à∂= (7, 1) ‚àß (13, 1) ‚àß (17, 1) ‚àß (19, 1)
ùõø((ùëõ, ùëñ), ùëé)
‚à∂= ùõøùëõ((ùëõ, ùëñ), ùëé)
for ùëõ ‚àà {7, 13, 17, 19} and ùëñ < ùëõ .
We have ùêø(A) = ùêø29393. Note that the only state in which there is universal
branching is state 0. In all other states, A behaves deterministically. A run
tree (on a word of length > 0) therefore consists of a root from which four
paths branch off.
These branches form runs of the DFA Aùëõ for ùëõ ‚àà {7, 13, 17, 19 }.
The first one only contains accepting states on levels 0, 7, 14, 21, . . ., the
second on levels 0, 13, 26, 39, . . ., and so on. Since 7, 13, 17 and 19 are
pairwise co-prime, the only levels of this run tree on which all states are
accepting are those which are multiples of 7 ‚ãÖ 13 ‚ãÖ 17 ‚ãÖ 19, i.e. of 29393.
So we have seen that at least some regular languages can be recognised by
small AFA - when compared to using NFA or even DFA as models of
regular languages.

However, here "small" is measured in absolute terms, for instance in the
sense that 57
is clearly smaller than 29393. One could and in fact should argue, though,
that they
3.3 Closure Properties
55
only differ by a constant factor, and most of the analyses regarding
automata sizes do not consider constant factors as significant differences.
So the question arises whether there is also an asymptotic size gap between
AFA and NFA. The following theorem can be proved by suitably
generalising the example above. This is left as an exercise.
Theorem 3.13 There is a family of regular languages (ùêøùëõ)ùëõ‚â•1 which can
be recognised by AFA of size polynomial in ùëõ such that any family of NFA
recognising these are of size exponential in ùëõ .
In other words, there can be no polynomial translation from AFA into
equivalent NFA. Then the question arises after the succinctness gap
between AFA and DFA.
Clearly, AFA can be translated into DFA at a doubly exponential blowup by
combining the two powerset constructions from AFA to NFA (Thm. 3.11)
and then on to DFA (Thm. 1.16). Theoretically, it could be the case that this
is not optimal, for instance if NFA resulting from the translated AFA were of
such a shape that they could be translated into DFA more efficiently.
Likewise, it could be the case that the two lower bounds do not combine in
the sense that there is a family of AFA which can only be translated into
exponentially larger NFA, but these are different from NFA which can only
be translated into DFA at an exponential blowup. This, however, is not the
case, as the next theorem states. The proof is deferred to the exercises.
Theorem 3.14 There is a family of regular languages (ùêøùëõ)ùëõ‚â•1 which can
be recognised by AFA of size polynomial in ùëõ such that the smallest family
of DFA recognising these are of size doubly exponential in ùëõ .

3.3 Closure Properties
We investigate the possibility to prove closure properties of regular
languages via AFA directly. It turns out that for some operations, like
complementation for instance, AFA provide easier constructions than NFA
do. For other operations like concatenation for example, the additional
expressive power of AFA is not helpful.
We start with a complementation construction.
Definition 3.15 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an AFA. The dual AFA to A is the AFA
+
A ‚à∂= (ùëÑ, Œ£, ùëû , ùõø, ùëÑ
ùêº
‚àñ ùêπ ), where for each ùëû ‚àà ùëÑ, each ùëé ‚àà Œ£ and each ùëì , ùëî ‚àà B (ùëÑ) we have
ùõø(ùëû, ùëé) ‚à∂= ùõø(ùëû, ùëé) with ùëû ‚à∂= ùëû, ùëì ‚à® ùëî ‚à∂= ùëì ‚àß ùëî and ùëì ‚àß ùëî ‚à∂= ùëì ‚à® ùëî.
Note that the dual AFA has no more states than the original one. This is in
contrast to the case of NFA where complementation incurs a blowup in
general. Still, the dual AFA recognises the complement language. The key
observation in the proof of this statement is the following lemma.
Lemma 3.16 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an AFA and A be its dual AFA. For any
ùëû ‚àà ùëÑ and any word ùë§ ‚àà Œ£‚àó there is an accepting run tree of A for ùë§ with
the root labelled ùëû iff there is no accepting run tree of A for ùë§ with the root

labelled ùëû .
56
3 Alternating Finite Automata
Proof By induction on the length of ùë§. Suppose ‚à£ùë§‚à£ = 0, i.e. ùë§ = ùúÄ. The
only run tree for ùúÄ with root label ùëû is the one consisting of the root only,
i.e. the root is also the only leaf. Now ùëû is an accepting state in A iff it is not
an accepting state in A, so the statement holds in this case as accepting
runs have all leaves labelled with accepting states.
Now suppose ‚à£ùë§‚à£ > 0, i.e. ùë§ = ùëéùë£ for some ùëé ‚àà Œ£, ùë£ ‚àà Œ£‚àó. Since ‚à£ùë£‚à£ <
‚à£ùë§‚à£ we can assume that the induction hypothesis holds for ùë£ already. We
will now assume that there is an accepting run tree of A on ùë§ and show that
there cannot be one of A on ùë§ . The converse direction is entirely
analogous and therefore omitted here.
Let ùúå be an accepting run tree for A on ùë§ = ùëéùë£ and root label ùëû. Since ‚à£ùë§‚à£ >
0, there is a layer of nodes directly underneath the root. Let ùëû , . . . , ùëû
1
ùëò
be the labels
of these nodes. Considering the fact that subtrees of an accepting run tree
form accepting run trees on suffixes we ha ve
‚Ä¢ ‚Ä≤
ùëÑ
‚à∂= {ùëû , . . . , ùëû
1

ùëò } ‚äß ùõø(ùëû , ùëé ), and
‚Ä¢ there are accepting run trees of A on ùë£ with root labels ùëûùëñ for all ùëñ = 1, . . .
, ùëò .
By the induction hypothesis, no accepting run tree of A on ùë£ can be formed
with a
‚Ä≤
root label from ùëÑ .
We now show by a separate induction on the structure of the Boolean
formula
‚Ä≤
ùõø(ùëû, ùëé) that any model of ùõø(ùëû, ùëé) must contain a state in ùëÑ , from which we can
conclude the impossibility to build an accepting run tree of A on ùë§ with root
label ùëû. Remember that a run tree of ùê¥ on ùë§ = ùëéùë£ is such that the labels of the
successor nodes of the root form a model of ùõø(ùëû, ùëé).
Suppose ùõø(ùëû, ùëé) = ùëù for some ùëù ‚àà ùëÑ. Then ùõø(ùëû, ùëé) = ùëù and the only models
‚Ä≤
‚Ä≤
of ùõø(ùëû, ùëé) are sets containing ùëù. Since ùëÑ ‚äß ùõø(ùëû, ùëé) we must have ùëù ‚àà ùëÑ which
immediately proves the base case of this inner induction.
If ùõø(ùëû, ùëé) = ùúì1 ‚à® ùúì2 then ùõø(ùëû, ùëé) = ùúì1 ‚àß ùúì2. By the induction hypothesis, any
‚Ä≤
model of ùúìùëñ must contain a state from ùëÑ for ùëñ ‚àà {1, 2}. Now note that the
only models of ùúì1 ‚àß ùúì2 are those which contain - as subsets - models of ùúìùëñ
for ùëñ ‚àà {1, 2}.

‚Ä≤
Hence, they must also contain at least some state from ùëÑ .
The last case of ùõø(ùëû, ùëé) = ùúì1 ‚àß ùúì2 is proved analogously.
‚óª
As a specialisation of this lemma with ùëû being the initial state we get the
following complementation result.
Corollary 3.17 For any language ùêø ‚äÜ Œ£‚àó we have: if ùêø is recognised by
an AFA of size ùëõ , then Œ£‚àó ‚àñ ùêø is also recognised by an AFA of size ùëõ .
The fact that complementation on AFA is easy and every NFA is also an AFA
according to Thm. 3.10 suggests a simpler decision procedure for MSO
based on a modular translation of formulas into AFA instead of NFA. There
is, however, a problem with the size of the resulting automata. If no
operation incurs an exponential blowup then the translation from formulas
to automata is polynomial contradicting Thm. 2.20.
Put differently, some construction on AFA which would be used in a
modular translation from MSO formulas must incur an exponential blowup,
but it is not the
3.3 Closure Properties
57
complementation construction. Clearly, it also cannot be either of the
constructions for atomic formulas as they get translated into NFA of fixed
size and therefore also into AFA of fixed size. There are only two candidates
left: disjunctions and existential quantification which are handled by union
and alphabet projection on the automata side.
It is easy to construct a (small) AFA which recognises the union of the
languages given as AFA. In fact, the same holds for conjunctions and

virtually any Boolean combination of languages. The proof of the following
theorem is left as an exercise.
Theorem 3.18
‚à™
For any AFA A ,
1 A2 over a common alphabet there are AFA A
‚à©
‚à™
and A
of size at most ‚à£A1‚à£ + ‚à£A2‚à£ + 1 such that ùêø(A ) = ùêø(A1) ‚à™ ùêø(A2) and
‚à©
ùêø (A ) = ùêø(A1) ‚à© ùêø(A2 ) .
It may seem surprising that alphabet projection or, more generally,
homomorphism closure on AFA should incur an exponential blowup. Still,
an example witnessing its failure is quite easy to construct.
Example 3.19 Let Œ£ = {ùëé, ùëè}, ‚Ñé ‚à∂ Œ£ ‚Üí Œ£ with ‚Ñé(ùëé) = ‚Ñé(ùëè) = ùëé and A =
({1, 2}, Œ£, 1, ùõø, { 1}) with
ùõø(1, ùëé) ‚à∂= 1 ,
ùõø(1, ùëè) = ùõø(2, ùëé) = ùõø(2, ùëè) ‚à∂ = 2 .
‚Ä≤
There is no immediate and well-defined way of obtaining an AFA ({1, 2},
{ùëé}, 1, ùõø ,

{1}) by applying the morphism ‚Ñé to the transition function ùõø as there is in
the case of
‚Ä≤
‚Ä≤
NFA. We would obtain ùõø (1, ùëé) = ùõø(1, ùëé) = 1 but also ùõø (1, ùëé) = ùõø(1, ùëè) = 2.
Maybe a natural way of fixing these diverging values of the transition
function is to interpret
‚Ä≤
‚Ä≤
it such that ùõø (1, ùëé) = 1 ‚àß 2. But then we would have ùêø(A ) = ‚àÖ ‚â† {ùëé} = ÀÜ
‚Ñé(ùêø(A)).
One may possibly argue that the construction should form a disjunction
rather than a conjunction out of cases in which two different alphabet
letters get mapped to the same one by the morphism. But this is equally
arbitrary, and likewise one can construct simple examples showing the
failure of such an ad-hoc construction.
Hence, the correct way of obtaining an AFA for ÀÜ
‚Ñé(ùêø(A)) is to transform A into
an NFA by means of Thm. 3.11, then applying the alphabet construction and
then interpreting the resulting NFA as an AFA.
Hence, there is no gain in translating MSO formulas into AFA rather than
NFA.
When using NFA, alphabet projection is cheap and complementation is
costly, and for AFA it is simply the other way round.

It is worth noting that alphabet projection is not the only construction
which can be used rather simply on NFA but not on AFA. Another prominent
example is concatenation.
Example 3.20 Consider the AFA A and B over the singleton alphabet {ùëé}
shown
‚àó
in Fig. 3.5. We have ùêø(A) = ‚àÖ and ùêø(B) = ùëé . Hence, ùêø(A)ùêø(B) = ‚àÖ.
However, applying the concatenation construction known for NFA to these
results in the AFA C shown in Fig. 3.5 as well. It is obtained by adding, to
every accepting state of A, the possibility to move to a successor of the
initial state of B. This extra possibility can be realised using disjunctions in
the transition function.
58
3 Alternating Finite Automata
ùëé
1
4
ùëé
A
ùëé
0
‚àß
ùëé
B

5
ùëé
ùëé
2
3
ùëé
1
‚à®
4
ùëé
C
ùëé
0
‚àß
ùëé
5
ùëé
ùëé
2
3

‚à®
Fig. 3.5 Na¬®ƒ±vely concatenating the two AFA above results in the AFA
below.
‚àó
ùëõ
Note that ùêø(C) = ùëéùëéùëéùëé . An accepting run on ùëé for ùëõ ‚â• 3 has two paths
which split in the root node labelled 0: one traverses the states 2, 3
followed by ùëõ ‚àí 2 visits of state 5; the other traverses state 1, followed by ùëõ
‚àí 1 visits of 5.
‚àó
Recall, though, that ùêø(A)ùêø(B) = ‚àÖ ‚â† ùëéùëéùëéùëé , i.e. this construction is not
correct in g eneral.
Ex. 3.20 shows the problem with concatenation of an AFA A with an AFA B.
It is impossible to guarantee that the moves from A to B are synchronised.
In other words: different paths of a run tree of the concatenated automaton
may split an input word differently into parts on which A operates, followed
by a part from B. This, however, does not correspond to the definition of the
concatenation operation on
‚Ä≤
languages: a word in ùêø ùêø is such that it can be split in a unique position
into two
‚Ä≤
parts which belong to ùêø and ùêø respectively.
A correct way to concatenate two AFA A and B is to first transform A into
an

‚Ä≤
NFA A according to Thm. 3.11 and then to apply the concatenation
construction.
Having eliminated universal choices in the left automaton guarantees that
the move into the right automaton will happen at a unique point in the input
word. Note that it is not necessary to transform B into an NFA first.
3.4 Reachability Games
There is another, equivalent, way of explaining acceptance of a word by an
AFA, namely in terms of reachability games. We first introduce the most
important concepts of such games and then use them to develop the game-
theoretic semantics of AFA in the next section.
3.4 Reachability Games
59
3.4.1 Games, Plays and Strategies
Definition 3.21 A reachability game is a G = (ùëâ, ùëâ , ùëâ , ùë£ , ùê∏, ùêπ
0
1
ùêº
) s.t. (ùëâ , ùê∏ ) is a
directed graph whose edge-relation is left-total, i.e. for every ùë¢ ‚àà ùëâ there is
a ùë£ ‚àà ùëâ
s.t. (ùë¢, ùë£) ‚àà ùê∏ . Moreover, ùëâ0 and ùëâ1 form a partition of ùëâ , i.e. ùëâ0 ‚à™ ùëâ1
= ùëâ and ùëâ0 ‚à© ùëâ1 = ‚àÖ; ùë£ùêº ‚àà ùëâ is a designated initial node in the game,
and ùêπ ‚äÜ ùëâ is a designated set of end nodes.

In accordance with the way that we measure the size of an automaton we
measure the size of a game in terms of the number of its nodes. Reachability
games - and also other games studied later on - need not be finite, but the
finite ones are of particular interest. Here we introduce games mainly as an
alternative tool to explain acceptance of a word by an alternating
automaton. These games can, however, also be used algorithmically to
solve the word problem for alternating automata.
Intuitively, the game G = (ùëâ , ùëâ , ùëâ , ùë£ , ùê∏ , ùêπ
0
1
ùêº
) is played between two players
simply called 0 and 1 in the following way. The initial position is ùë£ùêº .
Whenever the game is in a position of the form ùë£ . . . ùë£
0
ùëõ , here represented as a sequence of nodes,
then we have ùë£ùëõ ‚àà ùëâùëù for a unique ùëù ‚àà {0, 1}, and it is player ùëù's turn to
make a move. I.e. they select some node ùë£
, ùë£
ùëõ+1 ‚àà ùëâ s.t. (ùë£ ùëõ
ùëõ+ ) ‚àà ùê∏ , and the next position is
ùë£
. . . ùë£

ùë£
0
ùëõ
ùëõ +1.
When speaking about a particular player using pronouns, "she" will refer
to player 0 and "he" will refer to player 1. An arbitrary player will be
referred to neutrally as
"they".
A sequence of positions that arises from playing according to these rules
forms a play of the game. For brevity, we represent such a play simply as
the sequence of nodes that have been selected successively, i.e. as ùë£ , ùë£ , ùë£ ,
. . .
0
1
2
instead
of ùë£ , ùë£ ùë£ , ùë£ ùë£ ùë£ , . . .
0
0 1
0 1 2
Clearly, each representation can easily be derived from the
other.

Note that such a play need not be finite. However, as soon as it reaches a
position ùë£ ‚àà ùêπ , player 0 wins this play, and the game terminates. Player 1
wins a play that continues ad infinitum.
Definition 3.22 Let G = (ùëâ, ùëâ , ùëâ , ùë£ , ùê∏, ùêπ
0
1
ùêº
) be a reachability game. A function
‚àó
ùúé
ùëâ
ùëù
‚à∂ ùëâ
ùëù
‚Üí ùëâ that satisfies (ùë£, ùúéùëù(ùúåùë£)) ‚àà ùê∏ for all ùë£ ‚àà ùëâùëù is called a strategy for
player ùëù. Intuitively, a strategy for player ùëù determines the next move
whenever it is their turn to pla y.
A play ùúå = ùë£ , ùë£ , . . .
. . . ùë£
0
1
conforms to strategy ùúéùëù if ùë£ùëõ+1 = ùúéùëù(ùë£0

ùëõ ) for all ùëõ ‚â• 0
with ùë£ùëõ ‚àà ùëâùëù. I.e. in such a play, player ùëù has always made the choices
that were prescribed by ùúéùëù.
Such a strategy ùúéùëù is called positional, memoryless or history-free, if ùúéùëù(ùúåùë£)
=
‚Ä≤
‚Ä≤
‚àó
ùúé
ùë£
ùëù ( ùúå
) for all ùë£ ‚àà ùëâùëù, ùúå, ùúå ‚àà ùëâ . Thus, the choices prescribed by this strategy
solely depend on the node that a play has reached, and not on the nodes
that the play has previously visited, i.e. the history of that play. We will also
consider such strategies simply to be of type ùëâùëù ‚Üí ùëâ and write ùúéùëù(ùë£)
instead of ùúéùëù(ùúåùë£) for arbitrary ùúå.
60
3 Alternating Finite Automata
The strategy ùúéùëù is a winning strategy (for player ùëù) if player ùëù wins every
play that conforms to this strategy. In other words, playing according to this
strategy guarantees them to win any resulting play, regardless of the
opponent's choices in the play.
3.4.2 Attractors
Reachability games are special two-player zero-sum games of perfect
information.

Perfect information refers to the fact that at any moment, both players have
full knowledge of the state of the game - there are no concealed moves, and
both players are always aware of the current position and a possible history
of a play that is being played. In zero-sum (two-player) games, there is no
simultaneous winning or losing for the players: a play is won by player ùëù iff
it is lost by player 1 ‚àí ùëù.
One of the most important concepts in the theory of two-player games is
determinacy, describing the existence of winning strategies. Below, we will
see that reachability games are in fact determined, and that positional
strategies suffice. We will show this for a restricted class only, suited to our
needs: henceforth we will assume that reachability games are finitely
branching. We remark that all concepts and results can be extended to
genuinely infinite reachability games as well, but this would need the
introduction of ordinal numbers. The proof of Thm. 3.25 below would have
to rely on the axiom of choice.
Definition 3.23 Let G be a game with node set ùëâ and edge relation ùê∏ that
is finitely branching, i.e. for every ùë£ ‚àà ùëâ we have ‚à£ùë£ùê∏ ‚à£ < ‚àû.
Let ùëá ‚äÜ ùëâ be some set of nodes. The ùëá -attractor for player ùëù is ùëò
Attr (ùëá ) ‚à∂=
(ùëá )
ùëù
‚ãÉ Attr ùëù
ùëò ‚ààN
0
where Attr (ùëá ) ‚à∂= ùëá
ùëù

and
ùëñ+1
ùëñ
ùëñ
Attr
(ùëá )
‚à∂=
(ùëá ) ‚à™ {ùë£ ‚àà ùëâ
(ùëá ) ‚â† ‚àÖ}
ùëù
Attr ùëù
ùëù ‚à£ ùë£ ùê∏ ‚à© Attr ùëù
ùëñ
‚à™ {ùë£ ‚àà ùëâ1‚àíùëù ‚à£ ùë£ùê∏ ‚äÜ Attr (ùëá )}
ùëù
for ùëñ ‚â• 0 and both players ùëù .
ùëñ
Intuitively, Attr (ùëá )
ùëù
consists of all the nodes from which player ùëù can force every

play to visit the set ùëá in at most ùëñ moves. For ùëñ = 0 this is obviously only ùëá .
For ùëñ > 0, it contains, in particular, those nodes belonging to player ùëù that
have a successor from which player ùëù can enforce a visit to ùëá in ùëñ ‚àí 1 steps,
and those belonging to the opponent whenever they cannot escape, i.e.
whenever all those successor nodes ùëñ‚àí1
belong to Attr
(ùëá )
ùëù
already.
A strategy ùúéùëù for player ùëù that follows this definition is also called an
attractor ùëñ‚àí1
strategy, i.e. we have ùúéùëù(ùë£) ‚à∂= ùë¢ for some ùë¢ ‚àà Attr
(ùëá )
ùëù
whenever ùë£ ‚àà ùëâùëù and
3.4 Reachability Games
61
‚ãØ
0
1
2
3

4
5
6
‚ãØ
0
1
2
3
4
5
6
Fig. 3.6 Graphical representation of Nim as a reachability game.
ùëó
ùëñ
‚à∂= min{ ùëó ‚à£ ùë£ ‚àà Attr (ùëá )} >
ùëù
0, and ùúéùëù(ùë£) arbitrary otherwise. Note that the
minimality condition on ùëñ is important: it does not suffice to simply move to
some successor that also belongs to the attractor. This could lead to cyclic
plays that never reach the target ùëá . Minimality guarantees that every time
a step is taken according to this strategy, the play moves "one step closer to
ùëá ."

The restriction to finitely-branching games is used in the third disjunct of
the ùëñ+1
definition of Attr
(ùëá )
ùëù
above: if the underlying game was not finitely-branching,
then we could have a node owned by player 1 ‚àí ùëù whose successors all
belong to ùëñ
Attr (ùëá )
(ùëá )
ùëù
in a way that there is no maximal ùëñ s.t. all successors belong to Attr ùëù
.
Note that a reachability game G or a target set ùëá does not necessarily
induce unique attractor strategies, but on every attractor Attr (ùëá ) ùëù
for ùëá and player ùëù there
is at least some attractor strategy that guarantees player ùëù to eventually
visit ùëá .
Example 3.24 A popular game that can indeed be seen as a reachability
game, is Nim. Starting with a given arbitrary natural number, two players
alternatingly choose to subtract either 1 or 2 from the current number. The
player who cannot move anymore - because the play has reached the
number 0 - loses. In other words, a player wins when they create a situation
in which the other player has to move on 0.

We can model Nim as an infinite reachability game with nodes ùëâ = N √ó {0,
1}
where the first component of each pair contains the current value in the
play, and the second indicates the player whose turn it is to move.
Naturally, we then get ùëâ ùëù = N √ó {ùëù} for ùëù ‚àà {0, 1}. The possible moves
are giv en as
ùê∏
‚à∂= {((ùëõ, ùëù), (ùëõ ‚àí 1, 1 ‚àí ùëù)) ‚à£ ùëõ ‚â• 1, ùëù ‚àà {0, 1}}
‚à™ {((ùëõ, ùëù), (ùëõ ‚àí 2, 1 ‚àí ùëù)) ‚à£ ùëõ ‚â• 2, ùëù ‚àà {0, 1}}
‚à™ {((0, ùëù), (0, ùëù)) ‚à£ ùëù ‚àà {0, 1}}.
The last moves are only added in order to adhere to the technical
requirement that every node should have at least one successor. The
winning target for player 0 is
{(0, 1)}.
Fig. 3.6 introduces a graphical notation for such two-player games as a
directed graph in which nodes in ùëâ0 are shown in diamond shape and those
in ùëâ1 are shown in box shape. The content of each node (ùëõ, ùëù) only
displays the current value ùëõ for further subtraction, since the player ùëù can
be inferred from the node's shape. As with final states in an automaton, we
mark the target set with double lines.
62
3 Alternating Finite Automata
Note that the definition of a designated initial node is missing. We can see
this infinite structure as a template for the reachability game Nim started in
position (ùëõ, ùëù) by any player ùëù for arbitrary ùëõ ‚â• 0. In this case, one may
simply delete all nodes that are not reachable from (ùëõ, ùëù), and the game
obviously becomes finite.

Fig. 3.6 also shows Attr ({(
0
0, 1)}). The nodes belong to this attractor, i.e. those
from which player 0 wins the reachability game when started there, are
shown shaded in grey. A corresponding attractor strategy can easily be read
off the graph: since edges are always strictly moving to the left, it suffices
for player 0 to remain within grey nodes. Thus, we can see that player 0
wins Nim, when she is allowed to make the first move, and the game is
started with an initial value ùëõ /
‚â° 0 mod 3, or her
opponent begins to play and the initial value is some ùëõ ‚â° 0 mod 3.
The following game shows that it is does generally not suffice to simply stay
within the attractor as a strategy to win a reachability game.
0
1
2
Here, all three nodes belong to the attractor for player 0 to reach node 0.
Thus, any move keeps player 0 inside her attractor region. However, any
strategy that does not make her eventually move from 1 to 0 is not a
winning strategy even though it never takes her outside of the attractor
region. Moreover, a positional strategy is only winning if it lets her move
from node 0 to node 1 immediately.
3.4.3 Determinacy
Attractors can be used to prove the aforementioned result about positional
determinacy.
Theorem 3.25 Let G be a reachability game.

a) Exactly one of the players has a winning strategy for G .
b) A player has a winning strategy for G iff they have a positional winning
strategy for G .
Proof Let G = (ùëâ, ùëâ , ùëâ , ùê∏, ùë£ , ùêπ
0
1
ùêº
). Let ùëä0 ‚à∂= Attr (ùêπ)
0
and ùëä1 ‚à∂= ùëâ ‚àñ ùëä0. Clearly,
(ùëä , ùëä
0
1) forms a partition of ùëâ , and it should be clear that player 0 wins the
game G
started in any node in ùëä0 using some attractor strategy for ùêπ. It remains to
be seen that player 1 has a positional winning strategy for all the nodes in
ùëä1, and both parts (a) and (b) are pro ven.
Define a positional strategy ùúé1 ‚à∂ ùëâ1 ‚Üí ùëâ simply as follows. For any node ùë£ ‚àà
ùëâ1 ‚à© ùëä1 let ùúé1(ùë£) be some node ùë¢ ‚àà ùë£ùê∏ s.t. ùë¢ /
‚àà Attr (ùêπ)
0
, and ùúé1(ùë£) be arbitrary for

all ùë£ ‚àà ùëâ1 ‚à© ùëä 0.
First note that for any ùë£ ‚àà ùëâ1 ‚à© ùëä1 there must be some successor not
belonging to Attr (ùêπ)
(ùêπ )
0
because if all successors did belong to Attr 0
then, by finiteness
3.4 Reachability Games
63
ùëñ
of the game, there would be a smallest ùëñ ‚àà N s.t. ùë£ùê∏ ‚äÜ Attr (ùêπ) 0
and therefore
ùëñ+1
ùë£ ‚àà Attr
(ùêπ ) ‚äÜ
(ùêπ )
0
Attr 0
contradicting the assumption.
Next take a play ùúå = ùë£ ùë£ . . .

0 1
that conforms with strategy ùúé1 and is started in
some node ùë£0 ‚àà ùëä1. We claim that ùë£ ùëó /‚àà Attr (ùêπ)
0
for all ùëó ‚â• 0. For ùëó = 0 this is the
case by assumption. Suppose it is true for some ùëó already. We distinguish
two cases in order to show that it is also true for ùë£ ùëó+1.
‚Ä¢ If ùë£ ùëó ‚àà ùëâ1 then ùë£ ùëó+1 = ùúé1(ùë£ ùëó) /‚àà Attr (ùêπ)
0
by the construction of ùúé1 and the f act
that ùúå conforms to ùúé1.
‚Ä¢ If ùë£ ùëó ‚àà ùëâ0 then ùë£ ùëó+1 is chosen by player 0, and suppose that ùë£ ùëó+1 ‚àà
Attr (ùêπ) 0
, i.e.
ùëñ
there is some ùëñ s.t. ùë£ ùëó+1 ‚àà Attr (ùêπ)
0
. By the definition of attractors we would have
ùëñ+1
ùë£ ùëó ‚àà Attr
(ùêπ ) ‚äÜ

(ùêπ )
(ùêπ )
0
Attr 0
contradicting the assumption that ùë£ ùëó /
‚àà Attr 0
.
Hence, we must also have ùë£ ùëó+1 /‚àà Attr (ùêπ)
0
.
So we know that, if player 1 plays according to strategy ùúé1, he can steer any
play that starts outside of Attr (ùêπ)
(ùêπ )
0
away from Attr 0
forever. In particular, since
0
ùêπ = Attr (ùêπ) ‚äÜ
(ùêπ )
0

Attr 0
, he can avoid visiting ùêπ forever. But then ùúé1 is a (positional) winning
strategy for play er 1.
Altogether, the partition (ùëä , ùëä
0
1) therefore divides the nodes of the game into
two sets according to which player has a positional strategy to win the
game started in this node. Then the membership of the designated starting
node ùë£ùêº in either ùëä0
or ùëä1 determines the player who has a positional winning strategy for G.
‚óª
3.4.4 Polynomial-Time Solvability
At last, we consider the most important algorithmic question regarding
games in general, not necessarily just reachability games, namely the
problem of solving the game:
given: a reachability game G
compute: a (positional) winning strategy for either player to win G
Sometimes we may consider a global variant of this problem, asking to
determine winner and strategies for plays beginning in each of the game's
nodes rather than just one designated starting node. It should be clear that
these formulations are equivalent up to polynomial overheads: a solution to
the global question includes one to the local question; and by solving the
local problem ‚à£ùëâ ‚à£ many times one can obtain - not necessarily in the most
efficient way - a solution to the global problem.
Theorem 3.26 Reachability games can be solved in polynomial time.

Proof According to Thm. 3.25 it suffices to compute the attractor for player
0 and the set of target nodes ùêπ in the game in order to obtain a partition of
the game's nodes into the winning regions for players 0 and 1. It should
also be clear that attractors can be computed na¬®ƒ±vely in time O(‚à£ùëâ ‚à£ ‚ãÖ ‚à£ùê∏ ‚à£)
or more efficiently using a work-list-driven
64
3 Alternating Finite Automata
breadth-search backwards through the game graph in time O(‚à£ùê∏ ‚à£).
Moreover, an attractor strategy for player 0 can easily be constructed along
the way.
At last, once Attr (ùêπ)
0
has been found in this way, a strategy for player 1 can be
constructed in time O(‚à£ùê∏ ‚à£) by selecting, for every node won by him, some
successor not belonging to Attr (ùêπ)
0
as the proof of Thm. 3.25 suggests.
‚óª
3.5 A Game-Theoretic Semantics
We make use of reachability games as an alternative characterisation of
acceptance of a word by an AFA.
Definition 3.27 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùëé
. . . ùëé

ùêº
) be an AFA and ùë§ = ùëé0 1
ùëõ‚àí1 ‚àà Œ£‚àó.
The acceptance game for A and ùë§ is the reachability game G
, ùëâ , ùë£
,
A, ùë§ = (ùëâ , ùëâ0
1
ùêº
‚Ä≤
ùê∏ , ùêπ ) where
ùëâ0 ‚à∂= {(ùëû, ùëñ) ‚à£ ùëû ‚àà ùëÑ, 0 ‚â§ ùëñ < ùëõ} ‚à™ {(ùëû, ùëõ) ‚à£ ùëû ‚àà ùëÑ ‚àñ ùêπ} ,
ùëâ1 ‚à∂= {(ùëÄ, ùëñ) ‚à£ ùëÄ ‚äÜ ùëÑ, 1 ‚â§ ùëñ ‚â§ ùëõ} ‚à™ {(ùëû, ùëõ) ‚à£ ùëû ‚àà ùêπ} ,
ùëâ
‚à∂=
ùëâ
.
0 ‚à™ ùëâ1
The edge relation in this game is given as
ùê∏

‚à∂= {((ùëû, ùëñ), (ùëÄ , ùëñ + 1)) ‚à£ ùëÄ ‚äß ùõø(ùëû, ùëéùëñ ), ùëñ < ùëõ}
‚à™ {((ùëÄ , ùëñ), (ùëû, ùëñ)) ‚à£ ùëû ‚àà ùëÄ , ùëñ ‚â§ ùëõ } .
‚Ä≤
The initial node is (ùëû ,
ùêº
0) and the reachability target for player 0 is ùêπ ‚à∂= ùêπ √ó {ùëõ} .
Hence, positions of this game are states or subsets of the AFA's state set,
annotated with positions in the input word. The game begins in position (ùëû ,
ùêº
0), i.e. the initial
state of the underlying AFA and position 0 in the word. In such a position, it
is player 0's task to name a set of states that is a model of the Boolean
formula obtained through the transition function applied to the state and
the next input symbol in the word. Such a move is followed by a player-1
move who simply picks one of the states in the current set to continue with,
and the play advances to the next position in the word. It is player 0's
objective to end up in a position made up of an accepting state at the word's
end.
Note that, strictly speaking, this definition violates the requirement that
every node in a reachability game has at least one successor: positions of
the form (ùëû, ùëõ) where ùëõ = ‚à£ùë§‚à£ do not have successors. This could easily be
fixed by simply letting the game loop in such states. Moreover, note that
positive Boolean formulas cannot be unsatisfiable. Hence, every node of the
form (ùëû, ùëñ) has at least some successor
‚Ä≤
(ùëÄ , ùëñ + 1), and every such node has at least some successor (ùëû , ùëñ + 1)
because models of positive Boolean formulas over ùëÑ cannot be empty.

The following theorem shows that the game-theoretic semantics coincides
with the runtree-based semantics of AFA.
3.5 A Game-Theoretic Semantics
65
Theorem 3.28 Let A be an AFA over Œ£ and ùë§ ‚àà Œ£‚àó . Player 0 wins the
acceptance game GA,ùë§ iff ùë§ ‚àà ùêø(A) .
Proof
‚Ä≤
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
. . . ùëé
, ùëâ , ùë£
, ùê∏ , ùêπ
ùêº
), ùë§ = ùëé0
ùëõ‚àí1 and GA,ùë§ = (ùëâ , ùëâ0
1
ùêº
).
"‚áê" Suppose that ùë§ ‚àà ùêø(A). According to Thm. 3.8 there is a memoryless
run ùúå of A on ùë§. Remember that ùúå consists of a layered DAG: its nodes
reside on levels 0, . . . , ùëõ and are labelled with states from ùëÑ.
Memorylessness guarantees that every state occurs at most once on every
lev el.

We define a positional strategy ùúé0 for player 0 in GA,ùë§ as follows. Take a
node (ùëû, ùëñ). To define ùúé0(ùëû, ùëñ) we distinguish two cases.
‚Ä¢ If the run ùúå contains a node labelled ùëû on level ùëñ and ùëñ < ùëõ, then let ùëÄ be the
collected labels of all its successors on level ùëñ + 1. Then let ùúé0(ùëû, ùëñ) ‚à∂= (ùëÄ, ùëñ
+ 1).
We have ùëÄ ‚äß ùõø(ùëû, ùëéùëñ) by definition of ùúå, hence, we have ((ùëû, ùëñ), (ùëÄ, ùëñ + 1))
‚àà ùê∏
indeed.
‚Ä¢ If ùëñ = ùëõ or ùëû does not occur on level ùëñ then let ùúé0(ùëû, ùëñ) be chosen
arbitrarily .
We claim that this is indeed a winning strategy for player 0 in GA,ùë§ . The
following invariant holds for any play (ùëû ,
,
,
,
, ùëõ
0 0), (ùëÄ1 1), (ùëû1 1), (ùëÄ2 2), . . . , (ùëûùëõ
) that con-
forms to this strategy: for every ùëó = 0, . . . , ùëõ there is a node on level ùëó of ùúå
that is labelled with ùëû ùëó ; and for every ùëó = 1, . . . , ùëõ, ùëÄ ùëó consists solely of
node labels found on level ùëó in ùúå.
But then we must have, in particular, that for the last node (ùëû , ùëõ
ùëõ

) of the play
there is a node on level ùëõ of ùúå which is the last level. By the assumption ùë§
‚àà ùêø(A), this level only contains accepting states, hence, (ùëû , ùëõ
ùëõ
) is a target node in G and
therefore, player 0 wins the play, i.e. ùúé0 is indeed a winning strategy .
"‚áí" Suppose that player 0 wins the acceptance game GA,ùë§ . Since it is a
reachability game, we can assume that she wins it with an attractor strategy
ùúé0. We use this to construct a memoryless accepting run ùúå of A on ùë§ in a
surprisingly simple
‚Ä≤
way: for every (ùëû, ùëó ) ‚àà Attr (ùêπ )
0
add a node labelled ùëû on level ùëó . Then introduce
edges from any node on level ùëó to any node on level ùëó + 1 for ùëó = 0, . . . , ùëõ.
It remains to be seen that this is indeed an accepting run of A on ùë§ - at
least after removing every node on level 0 whose label is not ùëû ùêº .
‚Ä≤
First consider ùúå's last level ùëõ: note that we can only have (ùëû, ùëõ) ‚àà Attr (ùêπ ) 0
if
0
‚Ä≤
(ùëû, ùëõ) ‚àà Attr (ùêπ )

0
already because these are the target nodes in the game. Moreover,
we then have ùëû ‚àà ùêπ by construction of the game. Thus, ùúå's final level
contains accepting states only.
‚Ä≤
Next, since player 0 wins G
,
A, ùë§ , we must have that (ùëû ùêº
0) ‚àà Attr (ùêπ )
0
. Hence,
there is a node labelled ùëûùêº on ùúå's first lev el.
For ùúå to be an accepting run we only need to show that the labels on level ùëó
+ 1
comprise a model of ùõø(ùëû, ùëé ùëó ) for any label ùëû occurring on level ùëó and every ùëó
‚àà [ùëõ].
For simplicity, let ùëÑ ùëó denote the set of state labels occurring on level ùëó .
Now take any
‚Ä≤
ùëó ‚àà [ùëõ] and any ùëû ‚àà ùëÑ ùëó . Remember that by construction, we have (ùëû, ùëó )
‚àà Attr (ùêπ ) 0
.

Consider player 0's attractor strategy in this game node, i.e. ùúé0(ùëû, ùëó ).
According to the construction of GA,ùë§ we have ùúé0(ùëû, ùëó ) = (ùëÄ, ùëó + 1) for some
ùëÄ ‚äÜ ùëÑ s.t.
ùëÄ ‚äß ùõø(ùëû, ùëé ùëó ). Moreover, since player 1 cannot escape the attractor region,
we have
‚Ä≤
‚Ä≤
‚Ä≤
(ùëû , ùëó + 1) ‚àà Attr (ùêπ )
‚àà ùëÄ
0
for any ùëû
. Thus, we have ùëÄ ‚äÜ ùëÑ ùëó+1. Now note that
66
3 Alternating Finite Automata
models of positive Boolean formulas are upwards-closed, i.e. since ùëÄ ‚äß
ùõø(ùëû, ùëé ùëó ) so we have ùëÑ ùëó+1 ‚äß ùõø(ùëû, ùëé ùëó ). But then ùúå is in fact an accepting
run of A on ùë§.
‚óª
This characterisation of the word problem for AFA as a reachability game is
not optimal from a complexity point of view. The word problem for AFA can
indeed be solved in polynomial time, but this does not follow with Thm. 3.26
because the reachability game, as it is defined here, is of exponential size. It
is possible, though, to refine these games such that they are of polynomial

size only, in which case the following follows from the polynomial-time
decidability of the reachability problem.
Working out the details is left as an exercise.
Theorem 3.29 The word problem for AFA can be solved in polynomial time.
Note that this also avoids a suboptimal solution to the word problem that
one would obtain by translating an AFA into an NFA at an exponential
blowup in the worst case first, and then appealing to polynomial-time
solvability of the word problem for NFA.
Bibliographic Notes
Alternation as a generalisation to nondeterministic choice in a
computational device was introduced and studied by Chandra and
Stockmeyer and by Kozen at the same time [CKS81]. The focus in this work
is on computational complexity, though, which implies results on
expressiveness. Also, alternation is studied in the more general context of
Turing Machines. The application of the techniques developed there to
finite automata, which are essentially very restricted Turing Machines, is
not difficult and one quickly obtains results like alternation elimination via
a double powerset construction. The effect of the extension of
nondeterminism to alternation on the expressive power of various kinds of
restrictions of Turing has been an object of study since, cf. [Kin88, Hro85,
FJY90]. Salomaa and Yu studied alternating finite automata to obtain a
characterisation of star-free languages [SY00], the topic of the following
chapter.
Sometimes, alternating finite automata are introduced differently in the
literature with transition functions mapping states and symbols to sets of
states as it is done for NFA here. The state set is then partitioned into
existential and universal states, and the type of state determines whether the
branching in the outgoing transitions is seen disjunctively or conjunctively.
Clearly, this is a restriction of the model represented here. On the other
hand, it is easy to see that it also captures NFA in that an NFA is an
alternating automaton with existential states only in this sense. Hence,
these two models of alternating automata are equi-expressive.

Alternation becomes more interesting when studied in the context of finite
automata on infinite words (see Part II) or tree automata (see Part III of
this book).
This is also what the most notable work in the literature on alternating
automata targets, and we refer to the bibliographic notes in the
corresponding chapters of those
Exercises for Chapter 3
67
parts for further pointers. Alternation has also been studied as an extension
of finite (nondeterministic) pushdown automata [LSL84, LLS84, IJW92] but
this is clearly leaving the realm of regular languages and therefore the
focus of the presentation here.
Something similar can be said about the game-theoretic semantics of
alternating automata. Reachability games on finite graphs are conceptually
very simple, and it is only when extensions are considered, either by
considering infinite game arenas or stronger winning conditions, that the
study of games as a mechanism to explain acceptance by alternating
automata has brought out the most notable work in the literature. We also
refer to the bibliographic notes in the corresponding chapters of Parts II
and III for pointers in that direction.
The concept of determinacy as a property of two-player games of perfect
information and infinite duration was first studied by Gale and Stewart. The
main goal in such work was to find topological properties of the winning
sets that would guarantee determinacy. Gale and Stewart showed that this
is true for open sets [GS53], and Martin extended this to all Borel sets
[Mar75]. So determinacy for reachability games is an immediate
consequence of the former already since the winning condition, given as a
set of target nodes ùêπ ‚äÜ ùëâ , is just a representation of the open set
‚àó
ùúî

ùëâ
ùêπùëâ
of infinite plays won by player 0.
Exercises
Exercise 22
+
Let ùëì ‚àà B (ùëÑ) for some AFA's state set ùëÑ .
a) Suppose ùëÅ ‚äÜ ùëÄ ‚äÜ ùëÑ with ùëÅ ‚äß ùëì . Show that ùëÄ ‚äß ùëì as well. Hint: Use
induction on the structure of positive Boolean formulas.
b) Argue whether or not it is possible that ‚àÖ ‚äß ùëì holds.
c) Argue whether or not it is possible that ùëÑ /
‚äß ùëì holds.
Exercise 23 Let ùëÄ ‚äÜ ùëÑ for some AFA's state set ùëÑ. We call ùëÄ a minimal
model of
+
ùëì ‚àà B (ùëÑ) if ùëÄ ‚äß ùëì and ùëÅ /
‚äß ùëì for all ùëÅ ‚ää ùëÄ.
a) Construct a positive Boolean formula that has more than one minimal
model.
b) An mAFA is defined syntactically like an AFA, but additionally, in their
runtrees, the labels of successor nodes must form not just some but a
minimal model of the transition function's formula at that point. Show that
mAFA recognise exactly the regular languages.

Exercise 24 Construct an NFA with only two states that recognises the
language ùêø
from Ex. 3.5.
Exercise 25
a) Construct an NFA which recognises the language ùêø29393 from
Ex. 3.12 and which has at most 29393 states.
b) Show that ùêø29393 cannot be recognised by any NFA with less than
29393 states.
Hint: Suppose such an NFA did exist. Consider a long word in the language
ùêø
68
3 Alternating Finite Automata
such that any accepting run must visit some state twice. Use this to
construct an accepting run on a shorter word which does not belong to ùêø.
Conclude that this contradicts the assumption.
Exercise 26 Prove Thm. 3.13 by suitably generalising Ex. 3.12.
Exercise 27
‚àó
Let ùêøùëõ = {ùë§ùë§ ‚à£ ùë§ ‚àà {ùëé, ùëè} and ‚à£ùë§‚à£ = ùëõ} for each ùëõ ‚â• 1.
a) Construct AFA A
ùêø
ùëõ such that

(A ùëõ) = ùêø ùëõ and ‚à£A ùëõ‚à£ = O(ùëõ ).
b) Draw an accepting run of A3 on ùëéùëèùëéùëéùëèùëé.
ùëõ
c) Show that every NFA for ùêøùëõ needs to have at least 2 many states.
Exercise 28 Prove Thm. 3.14. Hint: Use the following family of regular
languages over Œ£ = {ùëé, ùëè} as an example.
ùêø ùëõ ‚à∂= Œ£‚àóùëéŒ£ ùëÉ(ùëõ )
ùëõ
where ùëÉ(ùëõ) ‚à∂= ‚àè
ùúí(ùëñ)
ùëñ=1
and ùúí(ùëñ) = ùëñ if ùëñ is prime and ùúí(ùëñ) = 1 otherwise. In other
words, ùëÉ(ùëõ) is the product of all prime numbers up to ùëõ.
Construct small AFA Aùëõ that recognise ùêøùëõ using similar tricks as in Ex.
3.12.
Then adjust the proof of the succinctness gap between NFA and DFA
established in Exc. 6 to show that the smallest DFA recognising ùêøùëõ must be
of size doubly exponential in ùëõ.
Exercise 29 Prove Thm. 3.18.
Exercise 30 Give a formal description of the construction which takes an
NFA A and an AFA B and produces an AFA C s.t. ùêø(C) = ùêø(A)ùêø(B) and ‚à£C‚à£
= O(‚à£A‚à£+‚à£B‚à£).
Prove correctness of this constr uction.

Exercise 31 Give a construction of a reachability game that characterises
the word problem for an AFA A and a word ùë§ whose size is only polynomial
in ‚à£A‚à£ and
‚à£ùë§‚à£. Here, ‚à£A‚à£ can be assumed to be the collective length of all Boolean
formulas
‚Ä≤
occurring in A ùë† transition function. Hint: The nodes in this game should
comprise of positions in ùë§ and subformulas of formulas in A's transition
function. During the game, the two players then work their way through
these formulas in order to establish whether or not there is a run of A on ùë§.
Chapter 4
Star-Free Languages
A natural fragment of Monadic Second-Order Logic is First-Order Logic
(FO), consisting of all MSO formulas that do not use second-order
quantification over monadic predicates. Only first-order quantification over
positions in a word is allowed. This chapter takes a closer look at FO over
finite words, with a focus on two aspects.
First, while the expressiveness of MSO is reasonably well understood by
now, matching the expressiveness of other regular formalisms like finite
automata (from deterministic to alternating ones), the question after the
expressive power of FO
arises. It would be conceivable that this syntactic elimination does not limit
the ability to formalise regular properties. This, however, is not the case as

we will show: FO is strictly weaker than MSO over words. To show this, we
develop a game-theoretic characterisation of the distinguishability of two
words by an FO
formula using limited resources. This can then be used to show that there
are regular languages which cannot be defined in FO.
This then raises the question in turn, whether there are other
characterisations of the class of FO-definable languages. One of the
reasons for why the class of regular languages is well understood is the
availability of many syntactic formalisms that can be used to represent its
members: regular expressions, DFA, NFA, AFA, MSO, etc. We will show
that the class of languages representable by formulas of FO has a neat
algebraic characterisation in terms of so-called star-free expressions.
These are comparable to regular expressions but do not contain the Kleene
star as an operator. However, they cannot just be obtained from regular
expressions by dropping the Kleene star as this would result in a
characterisation of the class of all finite languages only. Instead,
complementation needs to be added explicitly.
4.1 First-Order Logic
Recall that the syntax of First-Order Logic on finite words over an alphabet
Œ£ and a reservoir of first-order variables V1 is given by
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
69
https://doi.org/10.1007/978-3-662-72154-4_4
70
4 Star-Free Languages

ùúë
‚à∂‚à∂= ùë• < ùë¶ ‚à£ ùëé(ùë•) ‚à£ ùúë1 ‚à® ùúë2 ‚à£ ¬¨ùúë ‚à£ ‚àÉ ùë• ùúë
where ùë•, ùë¶ ‚àà ùëâ1 and ùëé ‚àà Œ£ .
FO is therefore the fragment of MSO in which second-order quantification
is not allowed. One could of course allow second-order variables ùëã in
formulas of the form ùëã(ùë¶) which would necessarily be free in any formula,
and they can be seen as contributing to the underlying alphabet. However,
technically it would be easier to then disallow formulas of the form ùëé(ùë•) in
order not to have to unify symbols ùëé
V
and ùëã, i.e. not to work with words over an alphabet of the form Œ£ √ó 2 2 .
Clearly, this would not change any of the results presented here; it would
only introduce extra case distinctions in the proofs. We therefore adopt the
clean way here and drop second-order variables entirely, i.e. the underlying
words are constructed over an alphabet Œ£ that is not specified any further.
Other logical operators are introduced as abbreviations using deMorgan
rules and the duality of existential and universal quantification for instance,
see Chp. 2.
The semantics of FO is then completely determined by the semantics of
MSO
over words. For instance, the FO formula ùúë = ‚àÄùë•.ùëé(ùë•) ‚Üí ‚àÉùë¶.ùë•<ùë¶ ‚àß ùëè(ùë¶)
defines the language
‚àó
‚àó
‚àó
ùêø (ùúë)

= (ùëé + ùëè + ùëê) ùëè(ùëè + ùëê)
+ (ùëè + ùëê)
of all words in which every ùëé is followed by a ùëè (not necessarily directly).
Remember the first goal stated in the introduction to this chapter. We want
to show that FO is strictly weaker in expressive power than MSO.
Essentially we need to find some MSO formula ùúë and show that no FO
formula is equivalent to it. Na¬®ƒ±vely, one might expect that this could be
done by constructing two words ùë§ and ùë£ which are distinguished by ùúë, e.g. ùë§
‚äß ùúë and ùë£ /
‚äß ùúë, but cannot be distinguished by any FO
formula. This approach is doomed to fail. Clearly, ùë§ and ùë£ can only be
distinguished by any ùúë if ùë§ ‚â† ùë£. But then there is also an FO formula ùúì that
distinguishes them.
We leave it as an exercise to formally prove this f act.
Note that this ùúì would depend on ùë§ or ùë£. A hypothetical FO formula that is
equivalent to ùúë must of course not depend on the words that it is interpreted
on.
In other words, we need to show that for any FO formula ùúì there is some
pair of words ùë§, ùë£ which is distinguished by ùúë but not by ùúì. To establish this
we introduce a measure on formulas such that the distinction of two words
by an FO formula will require a large enough measure while, on the other
hand, formulas with low measure cannot distinguish many pairs of words.
Definition 4.1 The quantifier depth qd(ùúë) of an FO formula ùúë is inductively
defined as follows.
qd(ùë• < ùë¶) = qd(ùëé(ùë•)) ‚à∂= 0
qd(ùúë ‚à® ùúì) ‚à∂= max{ qd(ùúë), qd(ùúì)}

qd(¬¨ùúë) ‚à∂= qd(ùúë)
qd(‚àÉùë• ùúë) ‚à∂= 1 + qd(ùúë)
4.2 Ehrenfeucht-Fra¬®ƒ±ss√© Games
71
Hence, qd(ùúë) measures the depth of nestings of quantifiers in ùúë. It equals the
maximal number of quantifiers on a path in its syntax tree. The quantifier
depth of ùúë = ‚àÄùë•.ùëé(ùë•) ‚Üí ‚àÉùë¶.ùë• < ùë¶ ‚àß ùëè(ùë•) for instance is 2. The quantifier depth
of
‚àÄùë• .ùëé(ùë•) ‚Üí (‚àÉùë¶.ùë• < ùë¶ ‚àß ùëè(ùë¶)) ‚àß ‚àÉùëß.ùëß < ùë• ‚àß ùëè(ùëß) is also 2 since the two
existential quantifications appear on different branches of the formula 's
syntax tree.
Note that the abbreviations ùë• = ùë¶, ùë• = 0, ùë• < max or ùë• = max, as
introduced in Chp. 2, are definable in FO as they do not need second-order
quantification. However, depending on how exactly they are defined, they
may have non-zero quantifier depth already, even though the quantifier is
not directly visible.
We state a rather obvious upper bound on the expressiveness of FO,
obtained directly from the fact that FO is a fragment of MSO.
Theorem 4.2 Let ùúë ‚àà FO. Then ùêø(ùúë) is regular .
Later on we will reason about FO formulas, and it will be convenient to
assume them to be normalised in a certain way.
Definition 4.3 An FO formula over Œ£ is in negation normal form (NNF) if it
is built from literals ùëé(ùë•), ¬¨ùëé(ùë•), ùë• < ùë¶ and ¬¨(ùë• < ùë¶) using only the
operators ‚àß, ‚à® and existential and universal q uantification.
Lemma 4.4 Let ùëò ‚â• 0 . For every FO formula ùúë of quantifier depth at most
ùëò there is a ùúì in negation normal form of quantifier depth at most ùëò s.t. ùúì ‚â° ùúë
and ‚à£ùúì‚à£ = O(‚à£ùúë ‚à£) .

Proof Using deMorgan Laws (¬¨(ùúë‚àßùúì) ‚â° ¬¨ùúë‚à®¬¨ùúì, ¬¨(ùúë‚à®ùúì) ‚â° ¬¨ùúë‚àß¬¨ùúì), the
duality between existential and universal quantifiers (¬¨‚àÉùë• ùúë ‚â° ‚àÄùë• ¬¨ùúë, ¬¨‚àÄùë• ùúë
‚â° ‚àÉùë• ¬¨ùúë) and double negation elimination (¬¨¬¨ùúë ‚â° ùúë) it is possible to push
negation downwards in a formula to achieve the desired form. Since this
does not create or delete quantifiers on any path of the syntax tree,
quantifier depth is preserved. The number of nodes in the syntax tree is at
most doubled.
‚óª
4.2 Ehrenfeucht-Fra¬®ƒ±ss√© Games
As mentioned above, FO is strictly weaker than full regularity. We will show
that, in
+
particular, there is no FO formula ùúë such that ùêø(ùúë) = (ùëéùëé) . In order to prove
this we need a tool from finite model theory which characterises the
indistinguishability of two structures - here: words - by formulas of FO in
terms of winning strategies in simple 2-player games.
4.2.1 Word-Comparison Games
Let ùëò ‚â• 0, Œ£ be a finite alphabet and ùë¢, ùë£ ‚àà Œ£‚àó. The ùëò -round Ehrenfeucht-
Fra¬®ƒ±ss√© game (or EF game for short) Gùëò (ùë¢, ùë£) is played between two
players called Spoiler
72
4 Star-Free Languages
(S) and Duplicator (D) on the two words ùë¢ and ùë£. It is helpful to imagine
the words as being written down in two lines, one above the other. A
configuration in the game is a sequence of pairs (ùëñ, ùëó ) with 0 ‚â§ ùëñ < ‚à£ùë¢‚à£ and
0 ‚â§ ùëó < ‚à£ùë£‚à£. We will use female pronouns to refer to D and male pronouns
for S.

Each round consists of alternating moves; first S picks a position in one of
the two words. Then D answers with a position in the other word. Intuitively
this forms a straight line connecting these two positions. D has to make sure
that the two letters at the positions selected in this round are the same and
that the line formed in this way does not cross any previous line or share an
endpoint with one of them. Otherwise she looses immediately. She wins if
she manages to survive ùëò rounds.
S is allowed to pick a position that has been previously selected. This is
simply not wise as D can always answer with the position that it is
connected to and thus survive one more round.
We say that D wins Gùëò (ùë¢, ùë£) if she has a strategy which guarantees her to
survive ùëò rounds of the game, regardless of S's moves. We leave it as an
exercise to formally define EF games as reachability games in the sense of
Sect. 3.4.
Example 4.5 Let Œ£ = {ùëé, ùëè}, ùë¢ = ùëéùëéùëèùëéùëéùëêùëéùëé, ùë£ = ùëéùëéùëêùëéùëéùëèùëéùëé. D wins
G1(ùë¢, ùë£) but looses G2(ùë¢, ùë£) since S has a winning strategy for this game.
Consider G1(ùë¢, ùë£) first. Player D's strategy is simple: whatever S picks in
his first move, pick a position that is labelled with the same letter. Since
both words contain the same letters, this is always possible. It trivially does
not create a situation in which D would lose. Hence, she can survive one
round in this game.
Now consider G2(ùë¢, ùë£). The following strategy is winning for S for
instance: in the first round, pick position 2 in ùë¢, in the second round pick
position 5 in ùë¢. Since these are the only positions carrying ùëè and ùëê,
respectively, D's only choice is to answer with positions 5 and then 2 in ùë£.
Otherwise she would lose because she would have connected different
letters. But then she loses because she has created a crossover: ùë¢
ùëé ùëé ùëè ùëé ùëé ùëê ùëé ùëé
=
ùë£

ùëé ùëé ùëê ùëé ùëé ùëè ùëé ùëé
=
Being a 2-player game of finite duration and perfect information, the EF
game enjoys determinacy: for every ùëò , ùë¢, ùë£, either S or D has a winning
strategy for Gùëò (ùë¢, ùë£). This is not too difficult to prove, especially not with
the generalisation that we consider in the following as it enables inductive
reasoning.
Definition 4.6 Let ùë¢, ùë£ ‚àà Œ£‚àó, ùëõ ‚â• 0, and s = (ùë† , ùë† , . . . , ùë†
, ùë° , . . . , ùë°
0
1
ùëõ‚àí1) and t = (ùë°0
1
ùëõ‚àí1)
be sequences of positions in ùë¢, resp. ùë£. Hence, we have 0 ‚â§ ùë†ùëñ < ‚à£ùë¢‚à£, 0 ‚â§ ùë°ùëñ
< ‚à£ùë£‚à£ for all ùëñ = 0, . . . , ùëõ ‚àí 1. We write s.ùëñ to denote the sequence that is
obtained from s by appending the position ùëñ to it.
The generalised EF game Gùëò ((ùë¢, s), (ùë£, t)) is played like the ordinary EF
game on ùë¢ and ùë£ with ùëò rounds, assuming that the connections ùë†ùëñ‚Äîùë°ùëñ have
already been formed.
We say that s and t form a partial isomorphism if
4.2 Ehrenfeucht-Fra¬®ƒ±ss√© Games
73
‚Ä¢

ùëñ
ùëñ
for all ùëñ = 0, . . . , ùëõ ‚àí 1: ùë¢(ùë† ) = ùë£(ùë° ), and
‚Ä¢ for all ùëñ, ùëó with 0 ‚â§ ùëñ < ùëó < ùëõ: ùë†ùëñ < ùë† ùëó iff ùë°ùëñ < ùë° ùëó.
The second condition also implies that ùë†ùëñ = ùë† ùëó iff ùë°ùëñ = ùë° ùëó : if ùë†ùëñ = ùë† ùëó then
neither ùë†ùëñ < ùë† ùëó nor ùë† ùëó < ùë†ùëñ , so we neither have ùë°ùëñ < ùë° ùëó nor ùë° ùëó < ùë°ùëñ and
therefore ùë°ùëñ = ùë° ùëó , and vice-versa.
Note that D loses Gùëò ((ùë¢, s), (ùë£, t)) unless s, t form a partial isomorphism,
even if ùëò = 0. Since the tuples of positions we consider here always arise
from choices by the players in (generalised) EF games, and we already
remarked that there is no gain for player S to choose a position that has
already been chosen in a previous round, we can assume w.l.o.g. that these
tuples always contain mutually different positions.
I.e. if s = (ùë† , . . . , ùë†
0
ùëõ‚àí1) then we assume that ùë†ùëñ ‚â† ùë† ùëó for all ùëñ, ùëó with 0 ‚â§ ùëñ < ùëó < ùëõ.
We list some facts about (generalised) EF games. The formal proofs are left
as exercises.
Lemma 4.7 Let ùëò ‚â• 0 , Œ£ be given, ùë¢, ùë£ ‚àà Œ£‚àó and s, t be equal-length
sequences of positions in ùë¢ , resp. ùë£ .
OceanofPDF.com

a) D wins G ((ùë¢, s), (ùë£, t))
G ((ùë¢, s), (ùë£, t
ùëò
iff S does not win
ùëò
)) .
b) Gùëò (ùë¢, ùë£) is the same game as Gùëò ((ùë¢, ()), (ùë£, ())) . In particular, they
are won by the same players.
c) D wins G0((ùë¢, s), (ùë£, t)) iff for all ùëñ, ùëó with 0 ‚â§ ùëñ, ùëó < ‚à£s‚à£ : ùë†ùëñ < ùë† ùëó iff ùë°ùëñ <
ùë° ùëó , and for all ùëñ with 0 ‚â§ ùëñ < s
‚à£
:
‚à£
ùë¢(ùë† ùëñ ) = ùë£ (ùë°ùëñ .
)
d) D wins Gùëò+1((ùë¢, s), ùë£, t)) iff for all ùë† < ‚à£ùë¢‚à£ there is ùë° < ‚à£ùë£‚à£ and for all ùë°
< ‚à£ùë£‚à£ there is ùë† < ‚à£ùë¢‚à£ such that D wins G ((ùë¢, s.ùë†), (ùë£, t.ùë°
ùëò
)) .
e) Let ùëöùë¢ ‚à∂= ‚à£ùë¢‚à£ ‚àí 1 and ùëöùë£ ‚à∂= ‚à£ùë£‚à£ ‚àí 1 be the last positions in ùë¢ , resp. ùë£ .
Suppose that ùë¢(0) = ùë£(0) and ùë¢(ùëöùë¢) = ùë£(ùëöùë£ ) , i.e. ùë¢ and ùë£ agree on their
first and last positions. Let s‚Ä≤ = s.0.ùëöùë¢ and t‚Ä≤ ‚à∂= t.0.ùëöùë£ . Then S wins Gùëò

((ùë¢, s‚Ä≤), (ùë£, t‚Ä≤)) if he wins Gùëò ((ùë¢, s), (ùë£, t)) . I.e. there is no gain for him to
choose the firs t or last position in this case.
f) Let ùúé be a permutation of ùëõ elements and s‚Ä≤ , resp. t‚Ä≤ result from s , resp. t
by applying this same ùúé to them. Then D wins Gùëò ((ùë¢, s‚Ä≤), (ùë£, t‚Ä≤)) iff she wins
Gùëò ((ùë¢, s), (ùë£, t)) .
+
The following lemma will be useful later on in the proof of the fact that (ùëéùëé)
is not definable in FO. It can also be seen as providing another example of
an EF game, and how the extension to generalised EF games is helpful in
reasoning about strategies. The lemma essentially says that S's ability to
point out a length difference between (parts of) two words is limited to
chunks of length that are at most exponential in the number of rounds to be
played.
Lemma 4.8
‚àó
ùëò
Let ùëò ‚â• 0 , Œ£ = {ùëé} and ùë¢, ùë£ ‚àà ùëé
such that min{‚à£ùë¢‚à£, ‚à£ùë£‚à£} > 2 . Then D
wins Gùëò (ùë¢, ùë£) .
Proof It should be clear that the statement is too weak to be proved by
induction on ùëò since, in a (ùëò + 1)- round EF game, one round does not take
us into the initial position of a ùëò -round EF game. However, it takes us into
the initial position of a
74
4 Star-Free Languages

ùëò -round generalised EF game, and this is even true for generalised EF
games. So we consider a stronger statement from which the statement of the
lemma follows immediately.
Let ùëò , Œ£, ùë¢, ùë£ be as above. Furthermore, let s = (ùë† , . . . , ùë†
, . . . , ùë°
1
ùëõ ) and t = (ùë°1
ùëõ )
be tuples of positions in ùë¢, resp. ùë£ that form a partial isomorphism. We
extend them to s‚Ä≤ ‚à∂= (0, ùë† , . . . , ùë† ,
, . . . , ùë°
,
0
ùëõ
‚à£ùë¢‚à£ ‚àí 1) and t‚Ä≤ ‚à∂= (0, ùë°0
ùëõ
‚à£ùë£‚à£ ‚àí 1), assuming that they do
not contain multiple occurrences of positions. Otherwise, extend them
accordingly so that both contain the first and last positions in ùë¢, resp. ùë£.
Claim. Now suppose that the following holds: for all ùëñ, ùëó with 0 ‚â§ ùëñ < ùëó ‚â§ ùëõ
+ 1
ùëò

we have min{‚à£ùë† ùëó ‚àí ùë†ùëñ‚à£, ‚à£ùë° ùëó ‚àí ùë°ùëñ‚à£} ‚â• 2
or ùë† ùëó ‚àí ùë†ùëñ = ùë° ùëó ‚àí ùë°ùëñ. We claim that D wins
Gùëò ((ùë¢, s‚Ä≤), (ùë£, t‚Ä≤)).
Before we move on to proving this claim, we remark that the original
statement of the lemma follows from it: consider the case of ùëõ = 0 in this
claim, i.e. the game Gùëò ((ùë¢, (0, ‚à£ùë¢‚à£‚àí1)), (ùë£, (0, ‚à£ùë£‚à£‚àí1))). First of all, the
assumption in the claim about the ùëò
relative difference in the positions on both sides boils down to min{‚à£ùë¢‚à£‚àí1,
‚à£ùë£‚à£‚àí1} ‚â• 2 , ùëò
i.e. min{‚à£ùë¢‚à£, ‚à£ùë£‚à£} > 2 . Next, if D wins Gùëò ((ùë¢, (0, ‚à£ùë¢‚à£ ‚àí 1)), (ùë£, (0, ‚à£ùë£‚à£ ‚àí
1))) then by Lemma 4.7 (a) and (e), she also wins Gùëò ((ùë¢, ()), (ùë£, ())), i.e.
Gùëò (ùë¢, ùë£) by Lemma 4.7
(b).
Now the claim can easily be proved by induction. The case of ùëò = 0 follows
immediately from the assumption that s, t, and thus also s‚Ä≤, t‚Ä≤ form a partial
isomorphism, using Lemma 4.7 (c).
For the step case, we can apply Lemma 4.7 (f) to assume w.l.o.g. that 0 <
ùë†0 < ùë†1 < . . . < ùë†ùëõ < ‚à£ùë¢‚à£ ‚àí 1 and likewise for t‚Ä≤. Then the premise of the
claim boils down to assuming that the difference between each two
successive rather than arbitrary ùëò
positions in s‚Ä≤ and t‚Ä≤ is either equal or larger than 2 . Now consider the first
round in the game Gùëò+1((ùë¢, s‚Ä≤), (ùë£, t‚Ä≤)). S picks a position which, by
assumption, needs to lie somewhere in between two positions already
chosen. Suppose he chooses some position ùë† in ùë¢ s.t. ùë†ùëñ < ùë† < ùë†ùëñ+1 for
some ùëñ. Now there are two cases.
‚Ä¢ Case ùë†ùëñ+1 ‚àí ùë†ùëñ = ùë°ùëñ+1 ‚àí ùë°ùëñ. Then D can pick the unique position ùë° in ùë£
s.t.

ùë†ùëñ+1 ‚àí ùë† = ùë°ùëñ+1 ‚àí ùë° and ùë† ‚àí ùë†ùëñ = ùë° ‚àí ùë°ùëñ, i.e. the position that has equal
distances to both adjacent already chosen positions.
‚Ä¢
ùëò
ùëò
ùëò ‚àí
Case ùë†
1
ùëñ+1 ‚àí ùë†ùëñ ‚â• 2
and ùë°ùë°+1 ‚àí ùë°ùëñ ‚â• 2 . Then we must have ùë†ùëñ+1 ‚àí ùë† ‚â• 2
or
ùëò ‚àí
ùë† ‚àí ùë†
1
ùëñ
‚â• 2
as it is impossible to divide an interval of length greater than
ùëò
ùëò ‚àí
2 into two parts without at least one of them having length greater than 2

1.
If ùë†ùëñ+1 ‚àí ùë† > ùë† ‚àí ùë†ùëñ then D chooses the unique position ùë° in ùë£ that has
equal ùëò ‚àí
distance on the closer side, i.e. to ùë†
1
ùëñ , obtaining min{ùë°ùëñ+1 ‚àí ùë° , ùë†ùëñ+1 ‚àí ùë†} ‚â• 2
and
ùë° ‚àí ùë°ùëñ = ùë† ‚àí ùë†ùëñ . If ùë†ùëñ+1 ‚àí ùë† ‚â§ ùë† ‚àí ùë†ùëñ then D chooses accordingly s.t. ùë°ùëñ+1
‚àí ùë° = ùë† ùëñ+1 ‚àí ùë†.
In both case, we get that s‚Ä≤.ùë† and t‚Ä≤.ùë° form a partial isomorphism and
respect the assumption of the claim, now for the extended tuple of positions.
The same holds analogously if S chose some position ùë° in ùë£ first, in which
case D would be able to respond with a corresponding ùë† in ùë¢ such that s‚Ä≤.ùë†
and t‚Ä≤.ùë° equally preserve the claim's assumption. The induction hypothesis
then yields that D wins Gùëò ((ùë¢, s‚Ä≤.ùë†), (ùë£, t‚Ä≤.ùë°)).
But then we can apply Lemma 4.7 (d) and obtain that D wins Gùëò+1((ùë¢, s‚Ä≤),
(ùë£, t‚Ä≤)) which finishes the proof of the claim.
‚óª
4.2 Ehrenfeucht-Fra¬®ƒ±ss√© Games
75
4.2.2 Indistinguishability through First-Order Formulas
The result we are aiming for next states that D wins the game Gùëò (ùë¢, ùë£) iff
ùë¢ and ùë£

cannot be distinguished by first-order formulas of quantifier depth at most
ùëò . This means that there is no such formula ùúë with ùë¢ ‚äß ùúë and ùë£ /
‚äß ùúë. Since FO and each of
its fragments of bounded quantifier depth is closed under negation there is
then also no such formula that is satisfied by ùë£ but not by ùë¢.
In the following, when we speak of formulas we will always mean formulas
of FO over predicate symbols of the form ùë• < ùë¶ and ùëé(ùëã) with ùëé ‚àà Œ£, as
defined in Sect. 4.1 above. Formulas like ùë• = ùë¶ are definable without
increasing the quantifier depth of the underlying formula. Formulas of
quantifier depth 0 are then Boolean combinations of atomic formulas of the
form ùë• < ùë¶ and ùëé(ùë•). Formulas of quantifier depth ùëò +1 can be regarded as
Boolean combinations of formulas of the form ‚àÉùë• ùúë(ùë•) where ùúë(ùë•) has q
uantifier depth ùëò .
Now suppose that ùúë is a formula with ùëõ free first-order variables ùë• , . . . , ùë•
0
ùëõ‚àí1, ùë¢
is a word over the corresponding alphabet, and s = (ùë† , . . . , ùë†
0
ùëõ‚àí1) is an ùëõ-tuple of
positions in ùë¢. We then write ùë¢, s ‚äß ùúë if ùë¢ satisfies ùúë under the variable
assignment that interprets each first-order variable ùë•ùëñ by the position ùë†ùëñ.
Alternatively, we write ùë¢ ‚äß ùúë(s).
We formalise an equivalence relation on words ùë¢, ùë£ ‚àà Œ£+: they are called
ùëò -
indistinguishable, written ùë¢ ‚â° ùë£

ùëò
if for all formulas ùúë without free first-order variables
and with qd(ùúë) ‚â§ ùëò we have ùë¢ ‚äß ùúë iff ùë£ ‚äß ùúë.
While we are ultimately interested in exactly this notion of
indistinguishability between two words, it is too weak to enable a proof by
induction on the structure of formulas because a subformula of a closed
formula need not be closed itself. For example, consider ‚àÉùë• ùëé(ùë•). It
contains no free first-order variables but ùëé(ùë•) clearly does. We therefore
need to generalise this definition.
Definition 4.9 Let ùëò, ùëõ ‚â• 0, ùë¢, ùë£ ‚àà Œ£+ and s = (ùë† , . . . , ùë†
, . . . , ùë°
1
ùëõ ), t = (ùë°1
ùëõ ) be ùëõ-tuples
of positions in ùë¢, resp. ùë£. We say that (ùë¢, s) and (ùë£, t) are (ùëò , ùëõ) -
indistinguishable, written (ùë¢, s) ‚â°ùëò,ùëõ (ùë£, t), if for all formulas ùúë with ùëõ free
variables and qd(ùúë) ‚â§ ùëò
we ha ve
ùë¢, s ‚äß ùúë
iff
ùë£ , t ‚äß ùúë .
It should be clear that the special case of ùëõ = 0 coincides with the notion of
indistinguishability between two words as introduced above: (ùë¢, ()) ‚â°ùëò,0
(ùë£, ()) iff ùë¢ ‚â°

ùë£
ùëò
.
We can now formulate the result known as the Ehrenfeucht-Fra¬®ƒ±ss√©
Theorem.
Theorem 4.10 Let ùëò ‚â• 0 , ùë¢, ùë£ ‚àà Œ£+ . D wins the game G
ùë£
ùëò (ùë¢ , ùë£ ) iff ùë¢ ‚â°ùëò
.
Proof As indicated above, it is helpful to generalise this statement in order
to enable a proof by induction. So instead we will show the following
stronger statement: let ùëò , ùë¢, ùë£ be as above and additionally ùëõ ‚â• 0 be given
and s = (ùë† , . . . , ùë†
1
ùëõ ) be positions
in ùë¢ and t = (ùë° , . . . , ùë°
1
ùëõ )
be positions in ùë£. Then D has a winning strategy for
Gùëò ((ùë¢, s), (ùë£, t)) iff (ùë¢, s) ‚â°ùëò,ùëõ (ùë£, t). It should be clear that the theorem's
statement follows from this immediately.
76

4 Star-Free Languages
"‚áí": By contraposition. Let (ùë¢, s), (ùë£, t) be given and suppose there was a
ùúë(ùë• , . . . , ùë•
1
ùëõ ) with qd(ùúë) ‚â§ ùëò such that
(ùë¢, s) ‚äß ùúë
iff
(ùë£, t) /
‚äß ùúë .
(4.1)
We will construct a winning strategy for S in the game Gùëò ((ùë¢, s), (ùë£, t)).
This is done by a combined induction on ùëò and the (Boolean) structure of ùúë.
In the base case, we have qd(ùúë) = 0 and ùúë does not feature Boolean
operators at its top level. Hence, ùúë = ùë•ùëñ < ùë• ùëó for some ùëñ, ùëó or ùúë = ùëé(ùë•ùëñ) for
some ùëñ. In the latter case, assumption (4.1) yields ùë¢(ùë†ùëñ) ‚â† ùë£(ùë°ùëñ), since one of
them must be ùëé and the other must not. In the former case, we get ùë†ùëñ < ùë† ùëó
and ùë°ùëñ ‚â• ùë° ùëó , or vice-versa. In all cases, S wins Gùëò ((ùë¢, s), (ùë£, t))
immediately according to Lemma 4.7 (c).
Now suppose that ùúë = ùúì1 ‚à® ùúì2. Then there is an ùëñ ‚àà {1, 2} s.t. (ùë¢, s) ‚äß ùúìùëñ iff
(ùë£, t) /
‚äß ùúìùëñ , and S can simply use his winning strategy that is derived from ùúìùëñ by
the induction h ypothesis.
Similarly, if ùúë = ¬¨ùúì then we have (ùë¢, s) /
‚äß ùúì iff (ùë£, t) ‚äß ùúì which is equivalent to

saying that (ùë¢, s) ‚äß ùúì iff (ùë£, t) /
‚äß ùúì. Since the truth values have flipped on each side,
S cannot simply use the same strategy that is derived from ùúì to win Gùëò((ùë¢, s),
(ùë£, t)), but actually the one that is derived from ùúì to win Gùëò ((ùë£, t), (ùë¢, s)).
The only non-trivial case is that of ùúë = ‚àÉùë• ùúì
ùëñ
. Note that qd(ùúë) > 0 in this case.
According to (4.1) we either have (i) (ùë¢, s) ‚äß ‚àÉùë• ùúì
ùúì
ùëñ
and (ùë£, t) /
‚äß ‚àÉùë•ùëñ
, or (ii)
(ùë¢, s) /
‚äß ‚àÉùë• ùúì
ùúì
ùëñ
and (ùë£, t) ‚äß ‚àÉùë•ùëñ
. Consider case (i) first. W.l.o.g. we can assume
ùëñ = ùëõ + 1 where ùëõ = ‚à£s‚à£; otherwise one can simply re-arrange the tuple s.ùë†
in the following. From (ùë¢, s) ‚äß ‚àÉùë•

ùúì
ùëõ+1
we get that there is some ùë† with 0 ‚â§ ùë† < ‚à£ùë¢‚à£ s.t.
(ùë¢, s.ùë†) ‚äß ùúì. On the other hand, from (ùë£, t) /
‚äß ‚àÉùë• ùúì
ùëñ
we get that for all ùë° with 0 ‚â§ ùë° < ‚à£ùë£‚à£
we have (ùë£, t.ùë°) /
‚äß ùúì. This provides S with the next step in the game Gùëò ((ùë¢, s), (ùë£, t)): he
chooses position ùë† in ùë¢. Note that regardless of which position ùë° in ùë£ D
responds with, the resulting configuration in the game is given by the
connections between s.ùë†
and t.ùë° with ùëò ‚àí 1 rounds left to play. By the induction hypothesis, S wins
the game Gùëò‚àí1((ùë¢, s.ùë†), (ùë£, t.ùë°)). Hence, by Lemma 4.7 (c), he also wins
Gùëò ((ùë¢, s), (ùë£ , t)).
Case (ii) is entirely analogous with the only difference being that S needs to
pick the position in ùë£ that witnesses (ùë£, t) ‚äß ‚àÉùë•
ùúì
ùëõ+1
instead.
"‚áê": Likewise by contraposition. Now we assume that S has a winning
strategy for G
, . . . , ùë•

ùëò ((ùë¢ , s), (ùë£ , t)) and we construct, by induction on ùëò , a formula ùúë(ùë•1
ùëõ )
with qd(ùúë) that witnesses (ùë¢, s) /
‚â°ùëò,ùëõ (ùë£, t).
In the base case, S wins Gùëò ((ùë¢, s), (ùë£, t)) in ùëò = 0 rounds, i.e. without
making any moves. Hence, according to Lemma 4.7 (a) and (c), we either
have ùë†ùëñ < ùë† ùëó iff ùë°ùëñ ‚â• ùë° ùëó
for some ùëñ, ùëó , or ùë¢(ùë†ùëñ) ‚â† ùë£(ùë°ùëñ) for some ùëñ. In the former case, take ùúë ‚à∂= ùë•ùëñ <
ùë• ùëó , and in the latter take ùúë ‚à∂= ùëé(ùë•ùëñ) where ùëé = ùë¢(ùë†ùëñ). By definition we then
have (ùë¢, s) ‚äß ùúë
and (ùë£ , t) /
‚äß ùúë.
In the step case we have ùëò > 0, and S wins Gùëò ((ùë¢, s), (ùë£, t)) by first
picking a position in either ùë¢ or ùë£ and D responding accordingly, and the
game continuing just like Gùëò‚àí1((ùë¢, s.ùë†), (ùë£, t.ùë°)) with ùë†, ùë° being the two
selected positions. According to Lemma 4.7 (c), S also wins Gùëò‚àí1((ùë¢, s.ùë†),
(ùë£, t.ùë°)), and by the induction hypothesis,
4.2 Ehrenfeucht-Fra¬®ƒ±ss√© Games
77
there is ùúì(ùë• , . . . , ùë•
0
ùëõ ) with qd(ùúì) = ùëò ‚àí 1 s.t., w.l.o.g. (ùë¢, s.ùë†) ‚äß ùúì and (ùë£, t.ùë° ) /
‚äß ùúì.

Otherwise, simply continue with ¬¨ùúì ins tead.
Now suppose that S picked position ùë† in ùë¢ in his first move in Gùëò ((ùë¢, s),
(ùë£, t)).
It is tempting to think that ùúë ‚à∂= ‚àÉùë• ùúì
ùëõ
reflects this on the logical side and can be
used to distinguish (ùë¢, s) from (ùë£, t). This is too simple, though. It does not
suffice to just predict the existence of such a position that S chooses in the
formula; it is additionally necessary to constrain it with respect to positions
already chosen and the letter that is attached to this new position since both
are relevant for S to win eventually. Hence, we take
ùúë(ùë• , . . . , ùë•
.
ùë•
ùë•
ùë•
0
ùëõ‚àí1)
‚à∂= ‚àÉùë•ùëõ ( ‚ãÄ
ùëñ
< ùë•ùëõ) ‚àß ( ‚ãÄ
ùëõ < ùë•ùëñ ) ‚àß ( ‚ãÄ

ùëñ
= ùë•ùëõ) ‚àß
ùëñ‚ààùêº <
ùëñ‚ààùêº >
ùëñ‚ààùêº =
ùëé(ùë•
, . . . , ùë•
ùëõ ) ‚àß ùúì (ùë•0
ùëõ )
<
>
where ùëé = ùë¢(ùë†), ùêº
‚à∂= {ùëñ ‚à£ 0 ‚â§ ùëñ ‚â§ ùëõ ‚àí 1, ùë†ùëñ < ùë†}, ùêº
‚à∂= {ùëñ ‚à£ 0 ‚â§ ùëñ ‚â§ ùëõ ‚àí 1, ùë†ùëñ > ùë†} and
=
ùêº
‚à∂= {ùëñ ‚à£ 0 ‚â§ ùëñ ‚â§ ùëõ ‚àí 1 , ùë†ùëñ = ùë†}.
Then we have (ùë¢, s) ‚äß ùúë. On the other hand, S's move let him win regardless
of D's response with a position ùë° in ùë£. Hence, we have (ùë£, t) /
‚äß ùúë. Thus, ùúë distinguishes

(ùë¢, s) from (ùë£, t), and we clearly have qd(ùúë) = ùëò .
The case where S picked the position ùë° in ùë£ is, again, analoguous. Here, ùúë is
simply constructed according to the letter that position ùë° points to, and its
relative position to the others in t, and then negated in the end.
‚óª
Example 4.11 Reconsider Ex. 4.5 with ùë¢ = ùëéùëéùëèùëéùëéùëêùëéùëé and ùë£ =
ùëéùëéùëêùëéùëéùëèùëéùëé. S wins G2(ùë¢, ùë£) but loses G1(ùë¢, ùë£). Hence, there should be a
formula of quantifier depth 2
that distinguishes the two, and it is not hard to constr uct one:
‚àÉùë•
.ùë•
1‚àÉùë•2
1 < ùë•2 ‚àß ùëè(ùë•1) ‚àß ùëê(ùë•2 )
The formula that can be constructed along the lines of the proof of Thm.
4.10, assuming that S picks positions 2, 5 in ùë¢ in this order, is
‚àÉùë• .ùëè
.ùë•
1
(ùë•1) ‚àß ‚àÉùë•2 1 < ùë•2 ‚àß ùëê(ùë•2 )
which is clearly equivalent to the one above. Intuitively, it is also clear that
no formula of quantifier depth at most one can distinguish ùë¢ and ùë£: such
formulas are Boolean combinations of elementary assertions about the
occurrence of particular letters, i.e.

they can only distinguish words that differ in their set of occurring letters
which is not the case for ùë¢ and ùë£ here.
As a second example, consider ùë¢ = ùëéùëéùëé and ùë£ = ùëéùëéùëéùëé. Since ‚à£Œ£‚à£ = 1 for
the underlying alphabet Œ£, S can never win by causing a connection
between two positions labelled differently and, hence, we can discard
subformulas of the form ùëé(ùë•) from a distinguishing formula.
It is not hard to create such a distinguishing one, for example
ùúë
‚à∂= ‚àÉùë•
.ùë•
.ùë•
1‚àÉùë•2‚àÉùë•2
1 < ùë•2 ‚àß ùë•2 < ùë•3 ‚àß ‚àÄùë•4
4 = ùë•1 ‚à® ùë•4 = ùë•2 ‚à® ùë•4 = ùë•3
78
4 Star-Free Languages
demanding models to be of length 3 exactly. Clearly, qd(ùúë) = 4. This is not
optimal though. Note that ùúë corresponds to S's strategy to pick the positions
0, 1, 2 in ùë¢ and then to pick the one position in ùë£ that D has not selected in
response to the first three moves. D then loses as she cannot respond with
an unselected position in ùë¢ .
There is a winning strategy for S, though, that leads to an earlier win. The
trick is presented in Lemma 4.8 already: by selecting positions that
successively halve the distances between word ends or already selected

positions, S can bring out the difference between ùë¢ and ùë£ in three moves.
The corresponding formula of quantifier depth 3 is, for example,
‚Ä≤
ùúë
‚à∂= ‚àÉùë•
.
.ùë•
1‚àÄùë•2 (ùë•2 < ùë•1 ‚Üí ¬¨‚àÉùë•3
2 < ùë•3 ‚àß ùë•3 < ùë•1) ‚àß
(ùë•
.ùë•
1 < ùë•2 ‚Üí ¬¨‚àÉùë•3
1 < ùë•3 ‚àß ùë•3 < ùë•2)
stating that there is a point (in the middle) such that all points to the left or
the right
‚Ä≤
of it are directly adjacent to it. Even though ùúë may look more complicated
than ùúë, it is structurally simpler in that its quantifier depth is only 3. It can
be obtained from S's strategy as follows: pick position 1 in ùë¢. If D responds
with an extremal position in ùë£, then pick 0 or 2 in ùë¢, depending in whether
D chose 0 or 4 in ùë£. So assume that D responded with 1 or 2 in ùë£. The two
cases are entirely symmetrical, so assume that it is position 1 which she
picked. Then S chooses position 3 in ùë£ to which D can only respond with

position 2 in ùë¢ without losing immediately. This creates the following
situation.
ùëé ùëé ùëé
ùëé ùëé ùëé ùëé
Now it is clear that S should choose position 2 in ùë£ as there is no possible
response for D without causing the crossing of two edges (at one end). Note
how the choosing in ùë¢ first and then twice in ùë£ corresponds to the ‚àÉ‚àÄ‚àÄ
quantifier structure on all paths
‚Ä≤
of the syntax tree in ùúë in negation normal form.
As an application of Thm. 4.10 we prove, as mentioned before, an
inexpressibility result for FO.
Theorem 4.12
+
The language ùêø = (ùëéùëé) is not FO-definable.
Proof Suppose ùêø was FO-definable, i.e. there was some FO sentence ùúë s.t.
ùêø(ùúë) = ùêø.
Then ùúë would have some quantifier depth, say ùëò . W.l.o.g. we can assume ùëò >
0. Let ùëò
ùëò
+
+
ùë¢ = ùëé2

1 and ùë£ = ùëé2 2. Note that ùë¢ /‚àà ùêø but ùë£ ‚àà ùêø. However, according to Lemma
4.8, D wins Gùëò(ùë¢, ùë£), and according to Thm. 4.10, we have ùë¢ ‚àà ùêø(ùúì) iff ùë£
‚àà ùêø(ùúì) for all ùúì with qd(ùúì) ‚â§ ùëò , in particular for ùúì = ùúë. But this contradicts
the assumption that ùêø (ùúë) = ùêø.
‚óª
4.3 Star-Free Expressions
79
4.3 Star-Free Expressions
The class of FO-definable languages forms a genuine subclass of the class
of regular languages, according to Thm. 2.16 and 4.12. A question that
arises, due to the rich variety of characterisations of the class of regular
languages, asks for other characterisations of the class of FO-definable
languages, for instance an algebraic one comparable to regular
expressions.
Likewise, one could search for a restriction on NFA for example in order to
obtain a computational model characterising this class. We do not pursue
this any further here. Instead, we only remark that it is possible to restrict
the model of AFA introduced in Chp. 3 in order to capture the class of FO-
definable languages accordingly. We will elaborate on this later on in the
context of automata on infinite words.
Definition 4.13 Let Œ£ be an alphabet. The class of star-free languages over
Œ£, written SFŒ£, is the smallest class of languages over Œ£ satisfying the
following closure properties.
‚Ä¢ ‚àÖ, {ùúÄ}, {ùëé} ‚àà SF Œ£ for any ùëé ‚àà Œ£ .
‚Ä¢ If ùêø, ùêø , ùêø
ùêø
, ùêø

, ùêø
1
2 ‚àà SFŒ£ , then ùêø1
2
1 ‚à™ ùêø2
‚àà SF Œ£.
In other words, SFŒ£ is the closure of the class of finite languages under
concatenations, unions and complements, just like REGŒ£ is its closure
under concatenations, unions and Kleene iterations. It may be surprising to
note that - with what is to be proved formally below - complementation
turns out to be weaker than Kleene iteration with respect to expressive
power, at least in the context of concatenation and union. Note though that
the class of finite languages is closed under concatenations and unions.
Hence, it is fair to say that complementation is weaker than iteration.
As usual, whenever Œ£ is clear from the context or irrelevant for some
central message, we may simply write SF instead of SFŒ£.
As with regular languages, we introduce star-free expressions in order to
neatly describe star-free languages, for example ùúÄ + ùëé‚àÖ describing the
language of all words not starting with an ùëé. Note that here we explicitly
introduce ùúÄ as an expression while it was only introduced as an
abbreviation for regular expressions. The reason simply
‚àó
is that the abbreviation is ùúÄ ‚à∂= ‚àÖ , and the Kleene star is of course not
available.
However, it can also be abbreviated differently, see below.

Note that being star-free for a language ùêø only means that there is some
expression ùõº that does not use the Kleene star (but perhaps the
complementation operator), s.t.
ùêø (ùõº) = ùêø. It clearly does not mean that all expressions describing the
language ùêø do not contain the Kleene star. In fact, there are star-free
languages which are most naturally described using the Kleene star, for
example Œ£‚àó, because of Œ£‚àó = ‚àÖ.
Finding a genuine star-free expression may be more difficult than finding
one using the iteration operator .
Lemma 4.14 If ùêø , ùêø
1
2 are star-free then so are ùêø1 ‚à© ùêø2 and ùêø1 ‚àñ ùêø2 .
80
4 Star-Free Languages
Proof This holds simply because ùêø1 ‚à© ùêø2 = ùêø1 ‚à™ ùêø2 by the deMorgan
laws, and then ùêø 1 ‚àñ ùêø2 = ùêø1 ‚à© ùêø2 .
‚óª
In fact, SF is closed under all Boolean operators as it is well-known that
each of them can be expressed using unions and complements only.
With the help of the lemma above we find that other regular languages are
star-free as well.
Example 4.15 Let Œ£ be an alphabet.
‚Ä¢ We have {ùúÄ} = Œ£‚àó ‚àñ ‚ãÉùëé‚ààŒ£ ùëéŒ£‚àó. Hence, there is also a star-free e
xpression describing the language {ùúÄ}.

‚Ä¢
‚àó
Let ùê∑ ‚äÜ Œ£. Note that ùê∑ in itself is a star-free language. Then ùê∑ is also star-
free
‚àó
‚àó
‚àó
‚àó
since ùê∑
= Œ£
‚àñ (Œ£ (Œ£ ‚àñ ùê∑)Œ£ ).
‚Ä¢
‚àó
The language (ùëéùëè) is star-free since
‚àó
(ùëé ùëè)
= (((Œ£‚àó ‚àñ ùëèŒ£‚àó) ‚àñ Œ£‚àóùëéùëéŒ£‚àó) ‚àñ Œ£‚àó ùëèùëèŒ£‚àó) ‚àñ Œ£‚àóùëé .
4.4 First-Order Equals Star-Freeness
The aim of this section is now to prove that FO over finite words and star-
free expressions enjoy the same expressiveness. We start with the simpler
part, namely that star-freeness does not exceed the expressive power of
First-Order Logic.

4.4.1 From Expressions to Formulas
Remember the convention that logical formulas do not get interpreted over
empty domains, in this case, over empty words. We therefore only consider
star-free languages ùêø ‚äÜ Œ£+ in the following. Again, this is not a restriction
since, for any ùêø ‚äÜ Œ£‚àó
we have that ùêø ‚àñ {ùúÄ} is star-free iff ùêø is star-free iff ùêø ‚à™ {ùúÄ} is star-free.
However, in order not to have to deal with ùúÄ at all, we have to remove the
clause {ùúÄ} ‚àà SFŒ£, and this could of course be more restrictive than just
removing ùúÄ from each star-free language, since it would also disallow {ùúÄ} as
part of the construction of a star-free language. The following technical
lemma states that this can indeed be done without causing problems. Its
proof is left as an exercise.
Lemma 4.16 Let ùêø ‚äÜ Œ£+ be star-free. Then there is a star-free expression ùõº
not using ùúÄ as a sub-expression such that ùêø(ùõº) = ùêø .
Theorem 4.17 Let ùêø be star-free. Then ùêø is FO-definable.
Proof We construct, for any star-free expression ùõº, an FO formula ùúìùõº(ùë•, ùë¶)
s.t. for all words ùë¢ and positions ùëñ, ùëó with 0 ‚â§ ùëñ ‚â§ ùëó < ‚à£ùë¢‚à£:
4.4 First-Order Equals Star-Freeness
81
ùë¢, {ùë• ‚Ü¶ ùëñ, ùë¶ ‚Ü¶ ùëó } ‚äß ùúì
ùë¢
. . . ùë¢
ùõº (ùë• , ùë¶ )
iff
ùë¢ùëñ

ùëñ+1
ùëó
‚àà ùêø(ùõº)
(4.2)
ùõº
ùúÄ
According to Lemma 4.16 we can assume
to be -free. Hence, the impossible case
of ùë¢ . . . ùë¢
ùëñ
ùëó
= ùúÄ is irrelev ant.
Once ùúì ùõº(ùë•, ùë¶) is constructed, we can take ùúë ùõº ‚à∂= ùúì ùõº(0, max) and get that ùë¢ ‚äß ùúë
ùõº
iff ùë¢ ‚àà ùêø(ùõº), i.e. an FO sentence defining ùêø(ùõº) has been found.
We construct ùúì ùõº by induction on the structure of ùõº.
‚Ä¢ Case ùõº = ‚àÖ. Let ùúì ‚àÖ ‚à∂= f f.
‚Ä¢ Case ùõº = ùëé for some ùëé ‚àà Œ£. Let ùúì ùëé ‚à∂= ùëé(ùë•) ‚àß ùë• = ùë¶.
‚Ä¢ Case ùõº = ùõΩ + ùõæ. Let ùúìùõº ‚à∂= ùúìùõΩ ‚à® ùúìùõæ. Note that the two exist by the inductive
hypothesis, and if they both satisfy (4.2), then so does ùúì ùõº.
‚Ä¢ Case ùõº = ùõΩ. Likewise, let ùúìùõº ‚à∂= ¬¨ùúìùõΩ .

‚Ä¢ Case ùõº = ùõΩùõæ. This is the only non-trivial case, and it is here where we need
the generalisation of FO-definability of languages of subwords as stated in
(4.2).
Suppose ùúìùõΩ(ùë•, ùë¶) and ùúìùõæ (ùë•, ùë¶) are given by the inductive hypothesis. Let ùúì ùõº (ùë•,
ùë¶)
‚à∂= ‚àÉùëß.ùë• ‚â§ ùëß ‚àß ùëß < ùë¶ ‚àß ùúìùõΩ (ùë•, ùëß) ‚àß ùúìùõæ ( succ(ùëß) , ùë¶)
where ùúìùõΩ(ùë•, ùëß) results from ùúìùõΩ(ùë•, ùë¶) by uniformly replacing every free
occurrence of ùë¶ by ùëß, and likewise for ùúìùõæ .
Note that ùúì ùõº states that the part of a given word ùë¢ from position ùë• to position
ùë¶
can be split into a part from ùë• to some ùëß inclusively that belongs to the
language of ùõΩ, while the remaining part from ùëß (exclusively) to ùë¶ belongs to
the language of ùõæ. Hence, (4.2) is satisfied for ùúì ùõº as well.
‚óª
4.4.2 From Formulas to Expressions
To show that star-free expressions are as expressive as first-order formulas,
we need to do a bit of preliminary work. Recall the relations ‚â°ùëò,ùëõ on words
and interpretations like ùëõ-tuples of positions, denoting indistinguishability
by FO formulas of quantifier depth at most ùëò with ùëõ free variables. Also
recall that the index of an equivalence relation is the number of its
equivalence classes.
We call a formula of quantifier depth at most ùëò and with at most ùëõ free
variables a (ùëò , ùëõ)-formula. The names of the free variables are in fact
irrelevant since, in the end, we are only interested in their models as pairs
(ùë¢, s) of words ùë¢ ‚àà Œ£+ and ùëõ-tuples s of positions in ùë¢. Hence, it does not
matter whether the positions are named ùë• , ùë¶, . . . or ùë• , ùë• , . . .
1

2
in the formula. We will therefore always assume that the free
variables of a (ùëò , ùëõ)-formula are ùë• , . . . , ùë•
1
ùëõ . Note that it can contain other, namely
bound var iables.
Lemma 4.18 Let ùëò, ùëõ ‚â• 0 . The relations ‚â°ùëò,ùëõ are equivalence relations of
finite index.
82
4 Star-Free Languages
Proof It is easy to see that each ‚â°ùëò,ùëõ is an equivalence relation. The
formal proof is left as an exercise.
We show by induction on ùëò that for all ùëò , ùëõ ‚â• 0, there are only finitely
many mutually inequivalent (ùëò , ùëõ)-formulas. The claim then follows from
this, since the members of each ‚â°ùëò,ùëõ-equivalence class are uniquely
determined by the (ùëò , ùëõ)-
formulas that they satisfy. According to Lemma 4.4 we can assume formulas
to be in negation normal form.
Let ùëò = 0. Evidently, a (0, ùëõ)-formula cannot contain quantifiers. Hence, it
is a Boolean combination of literals of the form ùëé(ùë•ùëñ), ¬¨ùëé(ùë•ùëñ), ùë•ùëñ < ùë• ùëó and
¬¨(ùë•ùëñ < ùë• ùëó ) for some ùëé ‚àà Œ£ and ùëñ, ùëó with 1 ‚â§ ùëñ, ùëó ‚â§ ùëõ. By a standard
argument, each such Boolean combination is equivalent to a formula in
disjunctive normal form (DNF), i.e. a disjunction of conjunctions of literals
of the above form. Now note that there are only finitely many such literals,
namely ùëõ0 ‚à∂= 2 ‚ãÖ ‚à£Œ£‚à£ ‚ãÖ ùëõ + 2 ‚ãÖ ùëõ2 many. Because of commutativity,
associativity and idempotence of disjunctions, there are at most as many

mutually inequivalent conjunctions of such literals as there are sets of such
literals. The same then holds for disjunctions of such conjunctions. Hence,
there are ùëõ
at most ùëì (0, ùëõ) ‚à∂= 220 many (0, ùëõ)-formulas.
Now suppose there are at most ùëì (ùëò , ùëõ) many mutually inequivalent (ùëò , ùëõ)-
formulas for some given ùëò and ùëõ. We need to bound the number ùëì (ùëò + 1, ùëõ)
of mutually inequivalent (ùëò + 1, ùëõ)-formulas. Note that a (ùëò + 1, ùëõ)-
formula with free variables ùë• , . . . , ùë•
1
ùëõ
can be seen as a Boolean combination of formulas of the form
ùëÑ ùë•
ùúì
ùëñ
where ùëÑ ‚àà {‚àÉ, ‚àÄ}, ùúì is a (ùëò , ùëõ + 1)-formula, and ùëñ ‚àà {1, . . . , ùëõ + 1}. This
includes the case of formulas of strictly lower quantifier rank, because the
quantification may bind a variable that does not occur freely in ùúì, as in ‚àÉùë•
ùë•
3
1 < ùë•2
for instance, which is then equivalent to ùë•1 < ùë•2 and therefore contains
strictly less quantifiers.
Again, by a standard argument about propositional logic, such Boolean
combi-ùëì (ùëò , ùëõ+1)

nations can be transformed into DNF, leaving at most ùëì (ùëò + 1, ùëõ) ‚à∂= 22
many
mutually inequivalent combinations thereof.
‚óª
We write [(ùë¢, s)]ùëò,ùëõ for the ‚â°ùëò,ùëõ-equivalence class of (ùë¢, s), provided that
‚à£s‚à£ = ùëõ .
Again, a (ùëò , ùëõ)-formula describes a set of pairs (ùë¢, s) of words with an ùëõ-
tuple ùëõ
of positions in it, i.e. a set of elements of Œ£+ √ó N . We call such sets
generalised languages when the length of the tuples of positions agrees for
all its elements. We use the same notation ùêø(ùúë) as we use for ordinary
languages defined by sentences.
Note that this is indeed a suitable generalisation, since the generalised
language of a (ùëò , 0)-formula, i.e. a sentence, is then just its language.
Example 4.19 We analyse ‚â°1,1 through its equivalence classes over the
alphabet Œ£ = {ùëé, ùëè}. We first enumerate all literals over two free variables,
i.e. ùë• , ùë•
1
2 by
convention. Since ¬¨ùëé(ùë•ùëñ) ‚â° ùëè(ùë•ùëñ) etc. we only get the follo wing 8.
ùëé(ùë•
, ùë•
, ùë•

, ùë•
1), ùëè(ùë•1), ùëé(ùë•2), ùëè(ùë•2), ùë•1 < ùë•2
1 ‚âÆ ùë•2
2 < ùë•1
2 ‚âÆ ùë•1
Obviously, some of them contradict each other: ùëé(ùë•1) ‚àß ùëè(ùë•1) ‚â° ff for
instance.
Others can be simplified as one implies the other, for example ùë•1 < ùë•2 ‚àß
ùë•2 ‚âÆ
4.4 First-Order Equals Star-Freeness
83
ùë•1 ‚â° ùë•1 < ùë•2. Hence, there are strictly less than 28 = 256 mutually
inequivalent conjunctions that are not unsatisfiable, but still too many to list
them all here. We pick out two.
ùúì1 ‚à∂= ùëé(ùë•1) ‚àß ùë•1 < ùë•2
ùúì2 ‚à∂= ùëè(ùë•2) ‚àß ùë•1 ‚âÆ ùë•2 ‚àß ùë• 2 ‚âÆ ùë•1
Note that unsatisfiability can also occur as a result of conjoining more than
two literals. While ùúì2 is satisfiable, ùúì2 ‚àß ùëé(ùë•1) is not since ùúì2 could also be
written as ùëè(ùë•2) ‚àß ùë•1 = ùë•2.
The proof of Lemma 4.18 states that ‚â°0,2 is characterised by disjunctions
of such conjunctions, and there are clearly too many to list them all here.
We pick out three, based on ùúì1 and ùúì2 above, namely ùúì1, ùúì2 and ùúì1 ‚à® ùúì2. It is
not too hard to describe the ‚â°0,2-equivalence classes that they induce.
‚Ä¢ ùêø(ùúì1) = {(ùë¢ùëéùë£, (‚à£ùë¢‚à£, ùëó)) ‚à£ ùë¢ ‚àà Œ£‚àó, ùë£ ‚àà Œ£+, ‚à£ùë¢‚à£ < ùëó < ‚à£ùë¢ùëéùë£‚à£}.

‚Ä¢ ùêø(ùúì2) = {(ùë¢ùëèùë£, (‚à£ùë¢‚à£, ‚à£ùë¢‚à£)) ‚à£ ùë¢, ùë£ ‚àà Œ£ ‚àó}.
Clearly, ùúì1 ‚à® ùúì2 simply describes the union of these two sets.
Now consider ‚â°1,1. According to the proof of Lemma 4.18, it suffices to
consider Boolean combinations of formulas of the form ùëÑùë• ùúì
ùëñ
, where ùúì is a (0, 2)-formula
(like those above), ùëÑ ‚àà {‚àÉ, ‚àÄ} and ùëñ ‚àà {1, 2, 3}. This yields - amongst
many others
- for instance
‚Ä¢
‚àó
+
ùêø (‚àÉùë•
ùúì
, ùë•
1
1(ùë•1
2)) = {(ùë¢ùëéùë£, ùëó ) ‚à£ ùë¢ ‚àà Œ£ , ùë£ ‚àà Œ£ , ‚à£ùë¢‚à£ < ùëó < ‚à£ùë¢ùëéùë£‚à£};
‚Ä¢
ùëó
+

ùêø (‚àÄùë• .ùë•
ùë§ , ùëó
, ùëó
1
1 ‚âÆ ùë•2 ‚à® ùëé(ùë•2)) = {(ùëé
) ‚à£ ùë§ ‚àà {ùëé, ùëè}
‚â• 0 };
‚Ä¢ ùêø(‚àÄùë• ùúì
, ùë•
ùúì
, ùë•
1
2(ùë•1
2)) = {(ùëè, 0)}. It is also equivalent to ‚àÄùë•2
2(ùë•1
2).
Again, in order to characterise ‚â°1,1 fully, one would then have to consider
genuine Boolean combinations on top of these.
Lemma 4.20 Let ùëò, ùëõ ‚â• 0 and ùëä be an equivalence class of ‚â°ùëò,ùëõ . There is
a (ùëò, ùëõ) -
formula ùúíùëä such that qd( ùúíùëä ) = ùëò and for all (ùë¢, s) we have (ùë¢, s) ‚äß ùúíùëä

iff
(ùë¢, s) ‚àà ùëä .
Proof Let ùëò, ùëõ be given. According to Lemma 4.18 there are only finitely
many (ùëò , ùëõ)-formulas up to equivalence. Let Œ¶ùëò,ùëõ be the set of all these.
Suppose ùëä is an equivalence class of ‚â°
, s
ùëò , ùëõ . Take an arbitrary representative (ùë¢0
0) ‚àà ùëä and let
ùúí
, s
ùëä
‚à∂= ‚ãÄ{ùúë ‚àà Œ¶ùëò,ùëõ ‚à£ ùë¢0
0 ‚äß ùúë} .
Since Œ¶ùëò,ùëõ is closed under negations (up to equivalence) it suffices to
conjoin all formulas that are satisfied by (ùë¢ , s
0
0), and it is not necessary to explicitly include the
negations of those formulas that are not satisfied by (ùë¢ , s
0
0).
Because of finiteness of Œ¶ùëò,ùëõ as well as independence of the exact choice
of (ùë¢ , s

0
0), ùúíùëä is well-defined. Moreover, it should be clear that qd( ùúíùëä ) = ùëò as it is a
Boolean combination of formulas of quantifier depth at most ùëò .
84
4 Star-Free Languages
It remains to be seen that ùúíùëä defines ùëä in the sense of the lemma's statement.
"‚áí" Suppose (ùë¢, s) ‚äß ùúí
ùë¢
, s
ùëä . We need to see that ùë¢, s ‚â°ùëò ,ùëõ
0
0. Suppose this was
not the case. Then there would be some ùúì(x) with qd(ùúì) = ùëò s.t. ùë¢ , s 0
0 ‚äß ùúì(x)
but ùë¢, s /
‚äß ùúì(x) (or vice-versa). According to Lemma 4.18, ùúì is equivalent to some ùúë
‚àà Œ¶
, s
ùëò . I.e. we have ùë¢0
0 ‚äß ùúë but ùë¢, s /
‚äß ùúë. But then ùë¢, s /

‚äß ùúíùëä since ùúíùëä contains
the conjunct ùúë, contradicting the initial assumption. The same holds if ùë¢ , s 0
0 /
‚äß ùúì but
ùë¢, s ‚äß ùúì.
"‚áê" Suppose (ùë¢, s) ‚àà ùëä , i.e. ùë¢, s ‚â°
ùë¢
, s
ùëò , ùëõ
0
0. Hence, ùë¢, s ‚äß ùúë for all ùúë ‚àà Œ¶ùëò,ùëõ s.t.
ùë¢
, s
0
0 ‚äß ùúë. But then ùë¢, s ‚äß ùúíùëä .
‚óª
Lemma 4.21
ùëõ
Let ùëò , ùëõ ‚â• 0 and ùêø ‚äÜ Œ£+ √ó N be a generalised language s.t. ùêø = ùêø(ùúë) for
some ùúë ‚àà Œ¶ùëò,ùëõ . Then ùêø is a finite union of ‚â°ùëò,ùëõ -equivalence classes.

Proof Let ùêø = ùêø(ùúë) for a (ùëò, ùëõ)-formula ùúë and ùëä be a ‚â°ùëò,ùëõ-equivalence
class. We observe that then either ùëä ‚äÜ ùêø or ùëä ‚à© ùêø = ‚àÖ: take some (ùë¢, s)
‚àà ùëä . Clearly, either (ùë¢, s) ‚àà ùêø and therefore ùë¢, s ‚äß ùúë, or (ùë¢, s) /
‚àà ùêø and therefore ùë¢, s /
‚äß ùúë.
Now take another (ùë†, t) ‚àà ùëä . By definition, we have ùë£, t ‚â°
ùë¢, s
ùëò , ùëõ
, in particular
ùë£ , t ‚äß ùúë iff ùë¢, s ‚äß ùúë, i.e. (ùë£, t) ‚àà ùêø iff (ùë¢, s) ‚àà ùêø and therefore ùëä ‚äÜ ùêø if (ùë¢, s)
‚àà ùêø, and ùëä ‚à© ùêø = ‚àÖ if (ùë¢, s) /
‚àà ùêø.
Since every ‚â°ùëò,ùëõ-equivalence class is either contained in ùêø entirely or
disjoint from it, and there are only finitely many such equivalence classes
according to Lemma 4.18, ùêø is the necessarily finite union of those
equivalence classes that are contained in it.
‚óª
This is almost sufficient to show the converse of Thm. 4.17. In order to
prove the following theorem by induction on the structure and quantifier
depth of ùúë, we need to generalise the statement accordingly. As usual,
subformulas of sentences may not be sentences themselves. Hence, the
inductive invariant needs to take care of free variables. This is not a
problem for the assumption in the theorem's statement. A formula ùúë(x) over
ùëõ free variables gets interpreted by a word and an ùëõ-tuple of positions, i.e.
it defines a generalised language in the sense above.

We therefore need to generalise the concept on the conclusion side
accordingly, i.e. we need a notion of star-freeness of sets {(ùë¢ , s
, s
0
0), (ùë¢1
1), . . .} where ‚à£sùëñ ‚à£ = ‚à£s ùëó ‚à£
for all ùëñ, ùëó . In order to obtain this, we can simply reuse the trick seen in the
translation of MSO formulas into automata (see Sect. 2.2.2), accepting
words that are enriched with extra tracks representing the evaluation of
second-order variables. Likewise, we consider a generalised language of
pairs of words ùë¢ over Œ£ and a tuple s = (ùë† , . . . , ùë†
1
ùëõ )
of ùëõ positions in this word as star-free, if the language of words that equip
such ùë¢
ùë†
‚à£ùë¢‚à£‚àíùë†
ùë†
‚à£ùë¢‚à£‚àíùë†
ùë†
‚à£ùë¢‚à£‚àíùë†
with ùëõ additional tracks of the form 0 1 10
1 ‚àí1 , 0 2 10

2 ‚àí1 , . . . , 0 ùëõ 10
ùëõ ‚àí1 is
ùëõ
star-free over Œ£ √ó {0, 1} .
For example, the pair (ùëéùëéùëèùëéùëéùëêùëéùëé, (5, 2)) consisting of a word over Œ£ =
{ùëé, ùëè, ùëê}
and two positions in it is encoded as the word
‚éõ0 ‚éû‚éõ0 ‚éû‚éõ1 ‚éû‚éõ0 ‚éû‚éõ0 ‚éû‚éõ0 ‚éû‚éõ0 ‚éû‚éõ0 ‚éû
‚éú
‚éü‚éú
‚éü‚éú
‚éü‚éú
‚éü‚éú
‚éü‚éú
‚éü‚éú
‚éü‚éú
‚éü
‚éú0 ‚éü‚éú0 ‚éü‚éú0 ‚éü‚éú0 ‚éü‚éú0 ‚éü‚éú1 ‚éü‚éú0 ‚éü‚éú0 ‚éü
‚éú
‚éü‚éú

‚éü‚éú
‚éü‚éú
‚éü‚éú
‚éü‚éú
‚éü‚éú
‚éü‚éú
‚éü
‚éùùëé ‚é†‚éùùëé ‚é†‚éùùëè ‚é†‚éùùëé ‚é†‚éùùëé ‚é†‚éùùëê ‚é†‚éùùëé ‚é†‚éùùëé ‚é†
4.4 First-Order Equals Star-Freeness
85
over Œ£ √ó {0, 1}2.
ùëõ
Clearly, not every element of Œ£ √ó {0, 1}
represents a valid encoding of a pair
(ùë¢, s). A well-formed word of this form is one in which every additional
track contains the symbol 1 exactly once. Note that the set WF ùëõ of well-
formed representations of words with ùëõ positions is star-free, since it can be
constructed as follows. Let Œ£, ùëõ
ùëõ
ùëñ‚àí
ùëõ‚àíùëñ

be given and define Œî ‚à∂= Œ£ √ó {0, 1} and Œî
1
ùëñ=ùëë ‚à∂= Œ£ √ó {0, 1}
√ó {ùëë} √ó {0, 1}
for
ùëñ ‚àà {1, . . . , ùëõ}, ùëë ‚àà {0, 1}. Note that these are finite sets of alphabet
symbols, hence, their Kleene iteration is star-free. Then we ha ve
ùëõ
ùëõ
WF
Œî‚àó
Œî‚àóŒî
Œî‚àóŒî
Œî‚àó
ùëõ
= Œî‚àó ‚àñ ( ‚ãÉ
) ‚àñ (
) .
ùëñ=0
‚ãÉ

ùëñ=1
ùëñ=1
ùëñ=1
ùëñ=1
Note that the operations on generalised languages suitably generalise the
star-free operations on languages. Hence, a star-free generalised language
of elements of the form (ùë¢, ()) is just a star-free language in the usual sense.
However, concatenation extends the number of additional tracks in order to
ensure well-formedness.
Theorem 4.22 Let ùúë ‚àà FO. Then ùêø(ùúë) is star-fr ee.
Proof We show, by induction on the structure and quantifier depth of ùúë, that
any ùúë(x) ‚àà FO defines a star-free (generalised) language over an enriched
alphabet as shown above. We do not assume ùúë to be given in negation
normal form but use the original syntax with negations and existential
quantifications only. A sentence then defines an ordinary star-free
language. Let Œî and Œîùëñ=ùëë be defined as above for given Œ£
ùëõ
, ùëõ that will be clear from the context. Additionally, let Œîùëé ‚à∂= {ùëé} √ó {0, 1}
for
ùëé ‚àà Œ£ .
As usual, w.l.o.g. we can assume the free variables of ùúë to be x = (ùë• , . . . , ùë•
1
ùëõ ).

In the base case, we have ùúë(x) = ùëé(ùë•ùëñ) or ùúë(x) = ùë•ùëñ < ùë• ùëó . They define,
respectively, the generalised and star -free languages
ùêø (ùëé(ùë•
, . . . , ùë†
ùëñ ))
= {(ùë¢ùëéùë£, (ùë†1
ùëõ )) ‚à£ ùë¢ , ùë£ ‚àà Œ£‚àó , ùë†ùëñ = ‚à£ùë¢‚à£}
‚àó
= (Œî ‚àñ ‚ãÉ (Œîùëè ‚à© Œîùëñ=1)) ‚à© WF ùëõ
ùëè‚ààŒ£
ùëè‚â†ùëé
and
ùêø (ùë•
, . . . , ùë†
Œî‚àóŒî
Œî‚àó
.
ùëñ
< ùë• ùëó )
= {(ùë¢, (ùë†1

ùëõ )) ‚à£ ùë¢ ‚àà Œ£+ , ùë†ùëñ < ùë† ùëó }
= Œî‚àóŒîùëñ=1
ùëó =1
‚à© WF ùëõ
ùúë
ùúì
ùúì
ùúë
ùúì
The cases of
(x) = 1(x) ‚à®
2(x) and
(x) = ¬¨
(x) are covered by the fact that
star-free languages are closed under unions and complementations.
The only interesting case is that of existential quantification. By renaming
variables suitably, we can restrict attention to formulas of the form ùúë(ùë• , . . .
, ùë•
1
ùëõ )
=

‚àÉùë•
ùúì
, . . . , ùë•
ùëõ+1
(ùë•1
ùëõ+1). Suppose qd(ùúë) = ùëò + 1 for some ùëò ‚â• 0. According to the induction
hypothesis, ùúì(ùë• , . . . , ùë•
1
ùëõ+1) defines a star-free language (over an alphabet
with ùëõ + 1 additional trac ks).
Claim. We have
86
4 Star-Free Languages
ùêø (ùúë)
= ùêø(‚àÉùë•
ùúì
ùëõ+1
)
= {(ùë¢ùëéùë£, r) ‚à£ ùë¢, ùë£ ‚àà Œ£‚àó, ùëé ‚àà Œ£, (ùë¢ùëéùë£, r.‚à£ùë¢‚à£) ‚äß ùúì}
ùëõ

= ‚ãÉ ‚ãÉ
‚ãÉ
[(ùë¢, s)]
ùëé
ùëò , ùëö
[(ùë£, t)] ùëò,ùëõ‚àíùëö
ùëé‚ààŒ£ ùëö=0
ùë¢, ùë£ , s, t
‚à£s‚à£=ùëö,‚à£t‚à£=ùëõ‚àíùëö
(ùë¢ùëéùë£ , s. t.‚à£ùë¢‚à£)‚äß ùúì
Before we prove the claim, we note that this shows that ùêø(ùúë) is indeed star-
free. By the hypothesis (on quantifier depth), [ùë¢]ùëò,ùëõ and [ùë£]ùëò,ùëõ are star-
free languages. This 1
2
follows from Lemma 4.20 which states that these can be defined by
characteristic formulas of quantifier depth ùëò , i.e. smaller than that of ùúë. So
we can apply the induction hypothesis to them and obtain their star-
freeness. The first two unions are clearly finite, and the third one is finite by
Lemma 4.18 stating that while there are infinitely many words ùë¢ and ùë£ in
general, there are only finitely many equivalence classes for them.
It remains to be seen that the claim is true.
"‚äÜ" Suppose (ùë§, r) ‚àà ùêø(ùúë), i.e. ùë§, r ‚äß ‚àÉùë•
ùúì

ùëõ+1
. Hence, ùë§ must contain some
position ùëñ s.t. ùë§, r.ùëñ ‚äß ùúì. But then ùë§ must be of the form ùë¢ùëéùë£ for some ùëé ‚àà
Œ£, ùë¢, ùë£ ‚àà Œ£‚àó
s.t. ùë¢ùëéùë£, r.‚à£ùë¢‚à£ ‚äß ùúì. Let r be split into tuples s and t of positions less,
respective greater than ‚à£ùë¢‚à£, and of length ùëõ1 and ùëõ2 respectively, i.e. ùëõ1 +
ùëõ2 = ùëõ. W.l.o.g. we assume r = s. t. Then w e have
ùë§ , r
‚àà {(ùë¢, s)}{(ùëé, 0)}{(ùë£, t)} ‚äÜ [(ùë¢, s)]
.
ùëò , ùëõ
{ùëé}[(ùë£, t)]ùëò,ùëõ
1
2
"‚äá" Suppose (ùë§, r) ‚àà [(ùë¢, s)]ùëò,ùëõ {ùëé}[(ùë£, t)]ùëò,ùëõ for some ùëé ‚àà Œ£, ùë¢, ùë£ ‚àà
Œ£‚àó and ùëö, 1
2
resp. ùëõ ‚àí ùëö positions s, t in ùë¢, resp. ùë£, where ùëõ = ‚à£r‚à£, such that ùë¢ùëéùë£, s.
t.‚à£ùë¢‚à£ ‚äß ùúì. Hence,
‚Ä≤
‚Ä≤
‚Ä≤

ùë§ must be of the form ùë¢ ùëéùë£ , and there must be tuples of positions s‚Ä≤ in ùë¢
and t‚Ä≤ in
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
ùë£
such that ùë¢ , s‚Ä≤ ‚â°
ùë¢, s
, t‚Ä≤
ùë£ , t
ùëé ùë£ , s‚Ä≤ . t‚Ä≤ .
ùëò , ùëö
and ùë£
‚â°ùëò,ùëõ‚àíùëö
. We claim that ùë¢
‚à£ùë¢ ‚à£ ‚äß ùúì
as well.

‚Ä≤
‚Ä≤
‚Ä≤
Consider the generalised EF game G
ùëé ùë£ , s‚Ä≤ . t‚Ä≤ .
ùëò (ùë¢ ùëé ùë£ , s. t.‚à£ùë¢‚à£, ùë¢
‚à£ùë¢ ‚à£), in which there
‚Ä≤
‚Ä≤
‚Ä≤
is an initial connection between position ‚à£ùë¢‚à£ in ùë¢ùëéùë£ and ‚à£ùë¢ ‚à£ in ùë¢ ùëéùë£ that
separates
‚Ä≤
‚Ä≤
both words into their parts ùë¢, ùë£, resp. ùë¢ , ùë£ . Moreover, the connections
between s and s‚Ä≤ are not crossing it, and neither are those between t and t‚Ä≤.
The assumptions that
‚Ä≤
‚Ä≤
ùë¢, s ‚â°
ùë¢ , s‚Ä≤

ùë£ , t‚Ä≤
ùëò , ùëö
and ùë£, t ‚â°ùëò,ùëõ‚àíùëö
yield that D has winning strategies for both the
‚Ä≤
‚Ä≤
games G
, s‚Ä≤
, t‚Ä≤
ùëò (ùë¢ , s, ùë¢
) and Gùëò (ùë£, t, ùë£
) according to Thm. 4.10. It is then not hard to
‚Ä≤
‚Ä≤
‚Ä≤
see that she also wins G
ùëé ùë£ , s‚Ä≤ . t‚Ä≤ .
ùëò (ùë¢ ùëé ùë£ , s. t.‚à£ùë¢‚à£, ùë¢
‚à£ùë¢ ‚à£): whenever S chooses a position
‚Ä≤

in ùë¢ or ùë¢ , she responds with a corresponding move as if S had done his
choice in
‚Ä≤
‚Ä≤
the game G
, s‚Ä≤
ùëò (ùë¢ , s, ùë¢
), and likewise for S's moves in ùë£ or ùë£ (with indices shifted
‚Ä≤
by ‚à£ùë¢‚à£ + 1, resp. ‚à£ùë¢ ‚à£ + 1 accordingly). This way, she avoids crossing
existing edges between s and s‚Ä≤, resp. t and t‚Ä≤ by copying her winning
strategy moves in the games
‚Ä≤
‚Ä≤
‚Ä≤
on the smaller words. She also avoids crossing the edge from ‚à£ùë¢‚à£ in ùë¢ùëéùë£ to
‚à£ùë¢ ‚à£ in ùë¢ ùëéùë£
because she only ever responds with a position on the same side of that
connection that S picked his position in. But then we can apply Thm. 4.10
again and obtain
‚Ä≤
‚Ä≤
‚Ä≤

‚Ä≤
‚Ä≤
‚Ä≤
that ùë¢ùëéùë£, s. t.‚à£ùë¢‚à£ ‚â°
ùë¢ ùëé ùë£ , s‚Ä≤ . t‚Ä≤ .
ùëé ùë£ , s‚Ä≤ . t‚Ä≤ .
ùëò , ùëõ
‚à£ùë¢ ‚à£ and, hence, we must have ùë¢
‚à£ùë¢ ‚à£ ‚äß ùúì as
‚Ä≤
‚Ä≤
‚Ä≤
well. Since ùë§ = ùë¢ ùëéùë£ and r = s. t by assumption, we then get ùë§, r.‚à£ùë¢ ‚à£ ‚äß ùúì,
resp.
ùë§ , r ‚äß ‚àÉùë•
ùúì
ùëõ+1
which was to be proved.
‚óª
Bibliographic Notes for Chapter 4

87
Bibliographic Notes
The class of star-free languages has attracted much attention, due to its
natural definition that is very close to that of the class of regular languages,
with complementation instead of Kleene iteration, and the intriguing result
that, amongst the two, Kleene iteration is in fact stronger w.r.t.
expressiveness.
There are many known different characterisations of the class of star-free
languages besides the one presented here via First-Order Logic which is
due to McNaughton and Papert [MP71], see also the book by Straubing
[Str94] or the handbook article by Thomas [Tho97].
The model-distinguishing games known as Ehrenfeucht-Fra¬®ƒ±ss√© games
have been developed, as the name suggests, by Ehrenfeucht [Ehr61] and,
earlier already but probably with lesser immediate outreach by Fra¬®ƒ±ss√©
[Fra54] as this was published in French. It is worth noting that EF-games
are not restricted to words, let alone finite ones. They are an important tool
not only in the theory of formal languages as presented here, but in overall
finite model theory and descriptive complexity theory in order to
characterise the expressive power of First-Order Logic over any kinds of
structures like graphs, etc. EF games are covered widely in the literature,
for instance in Immerman's book on descriptive complexity [Imm99],
Thomas' handbook article
[Tho97] or Kolaitis's article [Kol07] in the book on finite model theory by
Gr√§del et
+
al. [GKL 07].
There is a part of the algebraic theory of formal languages and logic that is
not covered in this book which characterises languages by their syntactic
monoids, and languages classes by classes of monoids. This goes back to
the otherwise (without necessarily coming across monoids) well-known

Myhill-Nerode Theorem [Ner58], and is covered in a variety of works, for
instance the aforementioned book by McNaughton and Papert [MP71]. Sch
√ºtzenberger showed that the star-free languages correspond exactly to the
class of aperiodic monoids [Sch65]. This is also intuitively linked to
characterisations via counter-free automata, cf. Wilke's comprehensive
article [Wil99a].
For a detailed overview of various characterisations of star-free languages
and further pointers into the literature, see also the article by Diekert and
Gastin [DG08].
It deals not only with the case of finite words, as is done in this chapter, but
also with star-free languages of and First-Order Logic on infinite words (as
well as such generalisations of the other characterisations). Automata and
logic on infinite words is the topic of the next part of this book, but we will
not have a closer look at star-free languages of infinite words anymore. It
has to be said that, not only is there a visible increase in combinatorial
complexity in the study of First-Order Logic compared to Second-Order
Logic, things become even more complex for First-Order Logic on infinite
words, while the increase in difficulty for Monadic Second-Order Logic is
much more manageable.
The study of star-free languages and First-Order Logic on infinite words is
mainly due to Thomas [Tho79, Tho81] with contributions by Ladner
[Lad77] and Perrin and Pin [PP86]. Again, the aforementioned overview
article by Diekert and Gastin
[DG08] surveys results in this area nicely.
88
4 Star-Free Languages
Another logical characterisation of star-free languages, which is mainly
interesting in the context of infinite words, is provided by Linear-Time
Temporal Logic (LTL), cf. [Pnu77]. It is known to be equi-expressive to
First-Order Logic and, while the embedding of LTL into FO is trivial, the
other direction, due to Kamp [Kam68]

and also Gabbay et al. [GPSS80], bears much of the aforementioned
combinatorial difficulty of star-free languages on infinite words. LTL will
be studied separately in Chp. 10.
Exercises
Exercise 32 Determine the minimal ùëò for which S wins Gùëò(ùë¢, ùë£) for the
following words ùë¢ and ùë£.
a) ùë¢ = ùëéùëéùëèùëéùëéùëèùëéùëéùëèùëé and ùë£ = ùëéùëèùëéùëéùëèùëéùëéùëèùëéùëé,
ùëõ
ùëõ+
ùëõ+
ùëõ
b) ùë¢ = ùëé ùëèùëé
1 and ùë£ = ùëé 1ùëèùëé for some ùëõ ‚àà N.
Exercise 33 Let ùë§, ùë£ ‚àà Œ£+ s.t. ùë§ ‚â† ùë£. Construct an FO formula that
distinguishes the two, i.e. that is satisfied by one but not the other.
Exercise 34
a) Formally define the ùëò -round EF game Gùëò (ùë¢, ùë£) on words ùë¢, ùë£ ‚àà Œ£+
as a reachability game in the sense of Sect. 3.4.
b) Let ùë¢ = ùëéùëéùëé and ùë£ = ùëéùëéùëéùëé. Construct the graph of the EF game G2(ùë¢,
ùë£) as a reachability game.
Exercise 35 Prove Lemma 4.7.
Exercise 36 Transform the distinguishing formulas in Ex. 4.11 into prenex
normal form, i.e. into the form ùëÑ ùë• . . . ùëÑ ùë• ùúì

, . . . , ùë•
ùëõ
ùëõ
1 1
for suitable variables ùë•1
ùëõ ,
ùëÑ
, . . . , ùëÑ
1
ùëõ ‚àà {‚àÉ, ‚àÄ} and ùúì quantifier-free.
Do this transformation preserve the quantifier depth?
Exercise 37
‚àó
Show that ùêø = (ùëéùëè + ùëèùëé) is star-free. Hint: Take the natural three-state
DFA for ùêø.
ùëé
ùëè
1
0
2

ùëé
ùëè
‚àó
‚àó
The key observation here is that it is the star-free languages (ùëèùëé) ùëè, resp.
(ùëéùëè) ùëé
that take this automaton from state 1 to 2, resp. vice-versa, and that the
automaton must be in state 1 after reading ùëéùëé, resp. in state 2 after reading
ùëèùëè. Thus, take
‚àó
some ùë§ ‚àà (ùëéùëè + ùëèùëé) , and suppose that ùë§ = ùë•ùëéùëéùë¶ùëéùëéùëß for some ùë•, ùë¶, ùëß ‚àà
Œ£‚àó. Then
‚àó
ùë¶ cannot be of the form (ùëèùëé) ùëè. An analogous consideration needs to be
made for occurrences of ùëèùëè. At last, ùë§ cannot begin or end with a repeated
letter.
These observations can now be turned into restrictions in order to build a
star-free expression of the form Œ£‚àó ‚àñ . . . for the language in question.
Exercises for Chapter 4
89
Exercise 38
‚àó
Show that ùêø = (ùëéùëé + ùëèùëè)

is not star-free. Hint: Show that for any ùëò
there are words ùë¢, ùë£ with ùë¢ ‚àà ùêø, ùë£ /
‚àà ùêø, s.t. D wins Gùëò (ùë¢, ùë£). Then argue formally why
this is sufficient to refute star-freeness of ùêø.
Exercise 39 Prove Lemma 4.16.
Exercise 40 Show that ‚â°ùëò,ùëõ is an equivalence relation for any ùëò, ùëõ ‚â• 0.
Exercise 41 Give an upper bound on the number of equivalence classes of
‚â°ùëò,ùëõ for ùëò , ùëõ ‚â• 0, that is asymptotically as small as possible. Hint: Solve
the recurrence for ùëì (ùëò , ùëõ) in the proof of Lemma 4.18. Then argue that,
despite each ‚â°ùëò,ùëõ-equivalence class being determined by the set of (ùëò , ùëõ)-
formulas that are true on its members, the number of such classes is not
exponential in ùëì (ùëò , ùëõ) but is already bounded by ùëì (ùëò , ùëõ) .
Exercise 42 Determine all satisfiable conjunctions of the 8 literals from the
beginning of Ex. 4.19.
Part II
Infinite Words
Chapter 5
Automata on Infinite Words
This second part is concerned with the definability of sets of infinite
sequences of symbols using finite automata. The fact that an automaton

should process an infinite word may seem unnatural at first, especially
when using the intuition that the automaton works through the input
symbols one by one starting from the beginning of the word. However, when
we think of acceptance as of the existence of a run, i.e.
a consistent decoration of input positions with states, then the
generalisation from finite to infinite inputs is rather natural.
Moreover, finite sequences and their recognisability by automata have
several applications in the theory of programming, most of all the following
two: finite words can be seen as encodings of inputs to a program like the
binary representation of a number or an adjacency list representation of a
(finite) graph. Regularity on finite words then captures notions of well-
formed inputs.
Secondly, words also occur as the observed behaviour of programs, for
example by associating each step in a stepwise execution with a particular
action like setting a particular bit, sending some data along some channel,
etc. Clearly, terminating programs give rise to finite words in this sense, but
- whereas non-termination may have been regarded as faulty behaviour in
the early days of programming - it has long been seen as natural behaviour
for many programs, for instance arising in reactive systems, operating
systems, etc. Hence, a theory of definability of languages of infinite words
by means of finite automata and logics provides the basis for methods in the
specification and verification of reactive programs.
The step from finite to infinite words in terms of runs of finite automata is
not such a big one. Clearly, acceptance cannot be explained anymore by
what happens "at the end of the run" as there is no designated end moment.
It is reasonable to complement the inherently local condition on the
labelling of a word by automaton states, saying that it needs to follow the
transition relation, by a global condition making demands on what happens
"in the infinite", leading to what is called an acceptance condition.
A very natural one is the so-called B ¬®
uchi-condition: a run is accepting if it keeps

visiting designated states infinitely often. These states take over the role of
the final or accepting states in an NFA, and it is now less appropriate to
call them final as this may appeal too much to the notion of occurring "at
the end". Hence, we will stick to
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
93
M. Hofmann and M. Lange, Automata Theory and Logic,
https://doi.org/10.1007/978-3-662-72154-4_5
94
5 Automata on Infinite Words
calling them accepting. Automata equipped with such an acceptance
condition are called B ¬®
uchi automata.
Many of the algorithmic problems considered in the context of finite
automata on finite words carry over directly to the world of infinite words.
For example, the emptiness problem is: given a B √ºchi automaton, does it
accept some word? Note that the word itself need not be written down
anywhere. Likewise, equivalence and inclusion problems between such
automata are also well-defined.
The word problem does not carry over straightforwardly because here, a
word is part of the input together with an automaton, and an infinite word
cannot be represented finitely in general. It is possible, though, to restrict
this for instance to infinite words of a specific, repetitive form that has
natural finite presentations.
We start by defining infinite words formally and turn our attention to finite
automata recognising languages thereof. We will see that the step from

finite to infinite words introduces additional difficulties in the algorithmic
treatment of the associated decision problems, and also that the results
known from the world of finite words do not always carry over to the world
of infinite words. However, the theory is rich enough to provide the
algorithmic solutions for problems arising with logic, specifically Monadic
Second-Order Logic again, this time naturally interpreted over infinite
words.
5.1 Regular Languages of Infinite Words
5.1.1 Infinite Words
Let Œ£ be a finite alphabet, as usual. An infinite word (over Œ£), or ùúî-word, is
an infinite sequence ùë§ = ùëé ùëé . . .
0
1
with ùëéùëñ ‚àà Œ£ for all ùëñ ‚àà N. We write Œ£ ùúî, in analogy to
the notion Œ£‚àó, for the set of all infinite words ov er Œ£.
In ordinal set theory, the symbol ùúî is also used to denote the (ordered)
natural numbers. Hence Œ£ ùúî can be read as the set of all total functions from
natural numbers to Œ£, and each ùúî-word is in fact a representation of such a
function and vice-versa.
ùúî
However, here it is more convenient to read ùëã
as the infinite iteration of symbols
ùúî
in ùëã through concatenation. For example, ùëèùëé
is used to denote the infinite word

that starts with ùëè and has ùëé at all following positions.
A subset ùêø ‚äÜ Œ£ ùúî is called an ùúî -language. We will often drop the explicit
referral to ùúî and simply speak of words and languages when in fact we
mean ùúî-words and ùúî-languages as these are the primary objects of interest
in this entire Part II of this book. We will instead explicitly point out when
words are supposed to be finite, or languages are sets of finite words. Note
that these may well occur as building blocks for the corresponding ùúî-words
and -languag es.
Let ùë§ ‚àà Œ£ ùúî and ùëñ ‚àà N. As before, we write ùë§(ùëñ) for the ùëñ-th letter in ùë§, i.e.
ùë§ = ùë§(0)ùë§(1) . . .. Let ùëé ‚àà Œ£. We write ‚à£ùë§‚à£ùëé for the number of
occurrences of the letter ùëé in ùë§, and ‚à£ùë§‚à£ùëé = ‚àû is of course possible. In
fact, the pigeon-hole principle demands that for any ùë§ ‚àà Œ£ ùúî there is at
least some ùëé ‚àà Œ£ s.t. ‚à£ùë§‚à£ùëé = ‚àû.
5.1 Regular Languages of Infinite Words
95
Infinite words cannot be concatenated, intuitively because there is no end.
So it is impossible to first traverse one word until its end, and then traverse
the other. More formally, let ùë¢, ùë£ ‚àà Œ£ ùúî. The concatenation of ùë¢ with ùë£
should respect the orders of letters within each word, and additionally that
all the letters in ùë¢ occur before all the letters in ùë£. Thus, the letter ùë£(0)
would have to be placed at a position ùëñ ‚àà N, for which there are infinitely
many positions ùëó < ùëñ providing space for the letters in ùë¢.
But no such natural number ùëñ exists.
It is, however, possible to define the left-concatenation of an infinite word
with a finite one. Let ùë£ ‚àà Œ£‚àó and ùë§ ‚àà Œ£ ùúî. Then ùë£ùë§ is the unique ùúî-word
defined by
‚éß
‚é™

‚é™ùë£(ùëñ)
, if ùëñ < ‚à£ùë£‚à£ ,
(ùë£ ùë§)(ùëñ)
= ‚é®
‚é™
‚é™ùë§(ùëñ ‚àí ‚à£ùë£‚à£)
, other wise.
‚é©
This can be extended to a left-concatenation of an ùúî-language with a
language of finite words in the natural way: if ùëà ‚äÜ Œ£‚àó and ùêø ‚äÜ Œ£ ùúî, then ùëà
ùêø ‚à∂= {ùë¢ùë§ ‚à£ ùë¢ ‚àà ùëà, ùë§ ‚àà
ùêø } ‚äÜ Œ£ ùúî .
+
ùúî
Likewise, given some ùë¢ ‚àà Œ£ , ùë¢
= ùë¢ùë¢ùë¢ . . . is the unique ùúî-word resulting from
ùúî
concatenating ùë¢ infinitely often. Note that ùúÄ
/
‚àà Œ£ ùúî , and this is why we required
ùë¢ ‚àà Œ£+.

Again, the operation of ùúî-iteration is lifted to languages in the natural way.
Let ùúî
ùëà
‚äÜ Œ£+. Then ùëà
‚à∂= {ùë¢ ùë¢ ùë¢ . . .
0 1 2
‚à£ ùë¢ùëñ ‚àà ùëà for all ùëñ ‚àà N}. This could even be
made well-defined for ùëà ‚äÜ Œ£‚àó, provided that ùëà ‚â† {ùúÄ}, but then we would
have to additionally require ùë¢ùëñ ‚àà ùëà ‚àñ {ùúÄ} for infinitely many ùëñ.
Example 5.1 Let Œ£ = {ùëé, ùëè}. The set of all ùúî-words that contain infinitely
many symbols ùëè, such that in between each pair there is an even number of
symbols ùëé,
‚àó
ùúî
can be described as ((ùëéùëé) ùëè) . The notation is, strictly speaking, not
defined. It
‚àó
appeals to the reader to take (ùëéùëé) ùëè as a regular expression, i.e. a
description of a
‚àó
ùúî
language of finite words, in this case clearly non-empty. Then ((ùëéùëé) ùëè) can
be

read as the ùúî-language resulting from the infinite iteration of that language,
and this clearly corresponds to the informal description given at the
beginning.
‚àó
ùúî
‚àó
ùúî
Similarly, (ùëé ùëè)
‚à© (ùëè ùëé)
describes the set {ùë§ ‚àà Œ£ ùúî ‚à£ ‚à£ùë§‚à£ùëé = ‚àû = ‚à£ùë§‚à£ùëè} where
Œ£
ùúî
ùúî
= {ùëé, ùëè}. It can also be described as Œ£ ùúî ‚àñ Œ£‚àó(ùëé
‚à™ ùëè
) .
5.1.2 ùùé-Regular Expressions
The class REG of regular languages undoubtedly forms an important and
interesting object of study in the theory of formal languages because of its
robustness, i.e. the fact that many natural algebraic, automata-theoretic,
logical, etc. formalisms define exactly this class, and because of the fact
that so many decision problems associated with such formalisms are
decidable.

A natural question that arises concerns the ability to define an analogue of
REG
for infinite words, i.e. a class of regular ùúî -languages, often also called ùúî-
regular
96
5 Automata on Infinite Words
languages. The answer is yes; we give a construction via so-called ùúî -
regular expressions. Their structure may seem rather arbitrary at first sight,
but it arises naturally in the following way.
A na¬®ƒ±ve attempt to define ùúî-regular expressions consists of extending
ordinary ùúî
regular expressions by introducing the infinite iteration operator ‚ãÖ . It is not
hard to ùúî
see, though, that this causes problems. For instance, ùõº
is only well-defined when ùõº
describes a language of finite words that is not just {ùúÄ}. On the other hand,
if ùõº does ùúî
this, then ùõº
describes a language of infinite words. Thus, a simple extension by
throwing in one more operator is unsuitable; one would at least have to
distinguish two types of descriptions: those for finite and those for infinite
words. This can easily ùúî
be done. We then note that, while ‚ãÖ
turns something of type "finite" into something

of type "infinite", there is nothing doing the opposite, at least no operation
that immediately arises from the regular ones like union, concatenation and
Kleene iteration. But we need to consider their effect on languages of type
"infinite".
Clearly, the union of two ùúî-languages is, again, an ùúî-language. But
concatenation is only meaningful when the left argument is a language of
type "finite". Therefore, ùúî-languages can also not be iterated, neither by
finite, let alone by infinite iteration.
This leads to the following grammar for ùúî-regular expressions.
Definition 5.2 Let Œ£ be an alphabet. The set of ùúî -regular expressions over
Œ£ is given by ùõº in the following grammar.
ùúî
‚àó
ùõº
‚à∂‚à∂= ‚àÖ ‚à£ ùõº + ùõº ‚à£ ùõΩùõº ‚à£ ùõΩ
ùõΩ
‚à∂‚à∂= ùëé ‚à£ ùõΩ + ùõΩ ‚à£ ùõΩ ùõΩ ‚à£ ùõΩ
‚Ä≤
‚Ä≤
where ùëé ‚àà Œ£. As before, we may also sometimes write ùõº ‚à™ ùõº instead of ùõº + ùõº
etc.
The separation into ùõº and ùõΩ realises the necessity of introducing two types.
Note, though, that ùõΩ does not derive expressions for all regular languages
but only for those non-empty ones that do not contain ùúÄ. This avoids
problems with ùúÄ in the infinite iteration. The price to pay is the shift of ‚àÖ to
the type of infinite languages.

Definition 5.3 Let Œ£ be an alphabet. The language ùêø(ùõº) of an ùúî-regular
expression ùõº is defined recursively as follows, assuming that for each
regular expression ùõΩ of finite words, ùêø(ùõΩ) is exactly that set of finite words
described by ùõΩ.
‚Ä≤
‚Ä≤
ùêø (‚àÖ)
‚à∂= ‚àÖ
ùêø (ùõº + ùõº )
‚à∂= ùêø(ùõº) ‚à™ ùêø(ùõº )
ùúî
ùúî
ùêø (ùõΩùõº)
‚à∂= ùêø(ùõΩ)ùêø(ùõº)
ùêø (ùõΩ
)
‚à∂= (ùêø (ùõΩ))
An ùúî-language ùêø is called ( ùúî )-regular if there is an ùúî-regular expression ùõº
s.t.
ùêø = ùêø(ùõº). The class of all ùúî-regular languages over Œ£ is denoted ùúî‚àíREGŒ£.
Again, if Œ£ is clear from context, we may simply write ùúî -REG.
ùúî

We will also often write ùõº instead of ùêø(ùõº), for instance as in ùêø = ((ùëé + ùëè)ùëè) ,
when it is clear whether we are referring to the expression ùõº or the language
that it defines.
It is not hard to see that ùúî-regular expressions enjoy a normal form.
5.2 Nondeterministic B √ºchi Automata
97
Lemma 5.4 Let ùêø ‚äÜ Œ£ùúî . Then ùêø is ùúî -regular iff there are ùëõ ‚â• 0 and ùëà , . . .
, ùëà , 1
ùëõ
ùëâ , . . . , ùëâ
1
ùëõ ‚àà REG Œ£ s.t. ùúÄ /
‚àà ùëâùëñ for all ùëñ = 1, . . . , ùëõ and
ùëõ
ùúî
ùêø
= ‚ãÉ ùëà ùëâ
.
ùëñ
ùëñ
ùëñ=1

Proof
ùëõ
ùúî
"‚áê" It suffices to see that ‚ãÉ
ùëà ùëâ
ùëñ=1
ùëñ
ùëñ
is essentially an ùúî-regular expression,
provided that the ùëà , ùëâ
ùëñ
ùëñ
are given by regular expressions. Note that, if ùúÄ ‚àà ùëàùëñ for
ùúî
ùúî
ùúî
some ùëñ, then we have ùëà ùëâ
ùëñ
= ùëâ
‚à™ (ùëà

ùëñ
ùëñ
ùëñ ‚àñ {ùúÄ })ùëâ ùëñ
, and this can be derived in the
grammar of Def. 5.2.
‚Ä≤
‚Ä≤
"‚áí" This makes use of the distributivity law ùëà(ùêø ‚à™ ùêø ) = ùëà ùêø ‚à™ ùëà ùêø and
the associativity of concatenation, including the closure of regular
languages of finite words under concatenations. With these at hand,
anything that is derivable from ùõº
in the grammar above can be normalised into a (finite) union of left-
concatenations ùúî
of expressions of the form ùõΩ
with a single regular expression. The case of ùêø = ‚àÖ is
covered by any such finite union of zero disjuncts.
‚óª
Example 5.5 Let Œ£ = {ùëé, ùëè, ùëê}. The language ùêø = {ùë§ ‚àà Œ£ùúî ‚à£ if ‚à£ùë§‚à£ùëé = ‚àû
then
‚à£ùë§‚à£ùëè = ‚àû} is ùúî-regular. The key insight is a rewriting of the implication
into a disjunction. Thus, ùêø consists of all words that have finitely many
occurrences of ùëé
only, or infinitely many occurrences of ùëè (or both, of course). Then we have
ùêø = ùêø(ùõº) for

ùúî
‚àó
‚àó
‚àó
ùúî
ùõº
‚à∂= (ùëé + ùëè + ùëê) ((ùëé + ùëê) ùëè)
+ (ùëé + ùëè + ùëê) (ùëè + ùëê)
.
This description follows the general form defined in Lemma 5.4 already .
An immediate consequence of Lemma 5.4 is closure of ùúî-REG under certain
operations.
Corollary 5.6 The classes ùúî‚àí REG Œ£ are closed under finite unions and left-
concatenations with regular languages from REG Œ£ .
For unions this is obvious, closure under left-concatenations with regular
languages needs distributivity of concatenation over unions again.
Further closure properties are far less obvious, in particular closure under
intersections and complementation. These hold as well but quite a bit more
work is needed to prove them, in particular the latter. The key is the
introduction of a computational model, namely the aforementioned B √ºchi
automata.
5.2 Nondeterministic B ¬®
uchi Automata

As informally described above, B √ºchi automata arise from NFA simply by
reinterpreting the notion of acceptance to cater for infinite words.
Syntactically they are indistinguishable from NFA.
98
5 Automata on Infinite Words
Definition 5.7 A nondeterministic B√ºchi automaton (NBA) is an A = (ùëÑ, Œ£,
ùëû , ùõø, ùêπ
ùêº
)
exactly as an NFA. Therefore, the size of an NBA is also defined as ‚à£A‚à£ ‚à∂=
‚à£ùëÑ‚à£.
A run of A on an ùúî-word ùë§ = ùëé ùëé ùëé . . .
0
1
2
‚àà Œ£ ùúî is an infinite sequence ùúå =
ùëû
, ùëû
, ùëû
, . . .
, ùëé
0

1
2
of states s.t. ùëû0 = ùëûùêº and ùëûùëñ+1 ‚àà ùõø(ùëûùëñ
ùëñ ) for all ùëñ ‚â• 0. For such a ùúå,
we let Inf (ùúå) ‚à∂= {ùëû ‚àà ùëÑ ‚à£ ‚àÄùëñ‚àÉ ùëó > ùëñ s.t. ùëû ùëó = ùëû} denote the set of all states
that occur infinitely often in it. Note that ùëÑ ‚äá Inf (ùúå) ‚äã ‚àÖ for any ùúå by
finiteness of ùëÑ. Such a run ùúå is called accepting if Inf (ùúå) ‚à© ùêπ ‚â† ‚àÖ, i.e. when
at least some accepting state is visited infinitely often.
The language of the NBA A is ùêø(A) ‚à∂= {ùë§ ‚àà Œ£ ùúî ‚à£ there is an accepting run
of A on ùë§}. A language ùêø ‚äÜ Œ£ ùúî is called B ¬®
uchi-recognisable or NBA-recognisable, resp.
-definable if there exists an NBA A s.t. ùêø = ùêø( A).
So the notion of acceptance and recognised languages are lifted
straightforwardly to NBA from NFA, with the only difference being the
arbitrary but natural convention that runs are considered to be accepting
when they visit some accepting state infinitely often. Note that, because of
finiteness of ùëÑ, a run visits the set ùêπ of accepting states infinitely often iff
there is some state ùëû ‚àà ùêπ that gets visited infinitely often.
Sometimes it will be more convenient to consider a run ùúå on a word ùë§ = ùëé ùëé .
. .
0
1
to be an alternating sequence ùëû , ùëé , ùëû , ùëé , . . .
0

0
1
1
of states and letters. We will make
use of both notions of runs, and the context will make clear whether we only
list states or states and letters.
Example 5.8
‚àó
ùúî
Let Œ£ = {ùëé, ùëè} and ùêø
ùëè
1 = (ùëé
)
be the language of all words that
contain infinitely many symbols ùëè. It is B √ºchi-recognisable; an NBA
recognising it is the following for example.
ùëé, ùëè
ùëè
A1
0
1

ùëé, ùëè
An accepting run of A1 on a word ùë§ containing infinitely many occurrences
of the symbol ùëè can be constructed as follows. Note that, if ‚à£ùë§‚à£ùëè = ‚àû then
ùë§ also contains infinitely many symbols ùëè at positions that lie at least two
steps apart (in the worst case, only taking every second of the infinitely
many positions). Then an accepting run ùúå can be built by moving from 0 to 1
at each of these positions and from 1 to 0 consequently when reading the
letter right after that. The premise about distance two ensures that the run
can move to state 1 infinitely often, i.e. it itself is of the form
+
ùúî
(0 1)
and, hence, is accepting.
On the other hand, on every word that contains only finitely many symbols
ùëè, A will eventually have to remain in state 0 forever, i.e. any run on such a
word
‚àó
ùúî
must be of the form (0 + 1) 0
itself and is therefore not accepting. Hence, ùêø1 is
NBA-recognisable.
Now let Œ£ = {ùëé, ùëè, ùëê} and ùêø2 be the language of all ùúî-words over Œ£ in
which every ùëè is eventually succeeded by some ùëê. We have
5.3 Closure Properties
99

ùúî
‚àó
ùúî
‚àó
‚àó
ùúî
ùêø
ùëê
ùëê
.
2
= (ùëé + ùëê)
+ (ùëé + ùëè + ùëê)
(ùëé + ùëê)
+ (ùëé + ùëè + ùëê) (ùëè(ùëé + ùëè + ùëê)
)
ùêø
An NBA recognising
2 is the following.
ùëé, ùëê

ùëé, ùëè
ùëè
0
ùëê
1
Intuitively, state 1 is used to remember that the symbol ùëè has been seen but
no subsequent ùëê has been seen yet. State 0 can be interpreted as waiting for
a potential ùëè. It is accepting because, if no ùëè occurs or several symbols ùëè
occur but there is at least some ùëê after the last one, or there are infinitely
many symbols ùëè and ùëê, then state 0 gets traversed infinitely often or even
eventually only.
We remark that it would equally be possible to allow NBA to have more
than one initial state. This model is no more expressive than the one with
single initial states: the standard construction on NFA that adds a new
initial state which simulates all original initial states can be applied here as
well.
5.3 Closure Properties
The examples above show that there are ùúî-regular languages that can be
recognised by B √ºchi automata and vice-versa. This is not a coincidence; a
language is ùúî-regular iff it is NBA-recognisable. This correspondence
between recognisability by finite automata and definability by regular
operations is one of the properties that extends from the world of finite
words to infinite words. Others do not, see for instance the following
section on deterministic B √ºchi automata. In order to prove this
correspondence formally, we investigate closure properties of NBA-
definable languages.
5.3.1 Unions, Left-Concatenations and ùùé-Iterations

The proof of the following lemma is left as an exercise. It is done in exactly
the same way as the corresponding construction for NFA.
Lemma 5.9 Let A, B be NBA over some Œ£ . There is an NBA C s.t. ùêø(C) =
ùêø(A) ‚à™
ùêø (B) and ‚à£C‚à£ ‚â§ ‚à£A‚à£ + ‚à£B‚à£ + 1 .
In other words, the class of languages recognised by NBA is closed under
finite unions. Clearly, we do not have closure under concatenations for
NBA-recognisable languages, since the concatenation of two infinite words
is no infinite word as argued above. However, the operation of left-
concatenation with a finite word, resp.
100
5 Automata on Infinite Words
a language of finite words, leads to another closure result. Again, the proof
of the following lemma is left as an exercise since the construction is the
same as the one proving concatenation-closure of the class of regular
languages of finite words.
Lemma 5.10 Let A be an NFA and B be an NBA, both over some Œ£ . There is
an NBA C s.t. ùêø(C) = ùêø(A)ùêø(B) and ‚à£C‚à£ ‚â§ ‚à£A‚à£ + ‚à£B‚à£ .
The last construction we need is not a closure property in the sense that it
turns NBA for some languages into an NBA for a certain language. It is the
pendant of the closure of regular languages of finite words under Kleene
iteration; now we implement ùúî-iteration. This, of course, is an operation
that turns (at most) a regular language into an ùúî-regular one.
Lemma 5.11 Let A be an NFA over some Œ£ s.t. ùúÄ /‚àà ùêø(A) . There is an NBA
B s.t.
ùúî
ùêø (B) = (ùêø(A))

and ‚à£B‚à£ ‚â§ ‚à£A‚à£ + 1 .
Proof
‚Ä≤
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, ùõø ,
ùêº
), and define B ‚à∂= (ùëÑ ‚à™{ùëûùêπ }, Œ£, ùëûùêº
{ùëû ùêπ }) for some
ùëû ùêπ /
‚àà ùëÑ, and
‚Ä≤
ùõø
‚à∂= ùõø ‚à™ {(ùëû, ùëé, ùëûùêπ ) ‚à£ ùëû ‚àà ùëÑ, ùëé ‚àà Œ£, ùõø(ùëû, ùëé) ‚à© ùêπ ‚â† ‚àÖ}
‚à™ {(ùëû
, ùëé, ùëù
, ùëé
ùêπ
) ‚à£ ùëù ‚àà ùõø(ùëû ùêº
)}
‚à™ {(ùëû

, ùëé, ùëû
, ùëé
ùêπ
ùêπ ) ‚à£ ùëé ‚àà Œ£ s.t. ùõø(ùëû ùêº
) ‚à© ùêπ ‚â† ‚àÖ} .
Hence, B is obtained from A by adding an extra state ùëûùêπ and giving it the
possibility to transition into this state instead of into a final state. Then,
from this state, it can only do the same as from the initial state. This makes
the claim on the size of B obvious.
ùúî
It remains to be seen that the construction is correct, i.e. that ùêø(B) = (ùêø(A))
.
ùúî
"‚äá" Suppose ùë§ ‚àà (ùêø(A) , i.e. there are ùë¢ , ùë¢ , . . .
0
1
s.t. ùë¢ùëñ ‚àà ùêø(A) for ùëñ ‚àà N, and
ùë§ = ùë¢ ùë¢ . . .
, ùúå , . . .
0 1
. So there are runs ùúå0
1

s.t. ùúåùëñ is an accepting run of A on ùë¢ùëñ.
‚Ä≤
Since, by assumption, ùë¢ùëñ ‚â† ùúÄ, we have ‚à£ùúåùëñ‚à£ > 1 for every ùëñ. Let ùúåùëñ result from
ùúåùëñ by replacing the first (for ùëñ ‚â• 1) and the last state (for ùëñ ‚â• 0) with ùëûùêπ .
Note that this
‚Ä≤
creates run fragments that are valid for the transition table ùõø since B can
always move to ùëûùêπ instead of some final state, and from ùëûùêπ it can do anything
that it can do from ùëûùêº . We can now glue them together to a run ùúå by merging
the occurrences of ùëû ùêπ at the end of each ùúåùëñ and the beginning of the
subsequent ùúåùëñ+1.
We claim that ùúå is an accepting run of B on ùë§: (i) it starts in the initial state
ùëûùêº .
‚Ä≤
(ii) It obeys the transition relation ùõø everywhere: inside each ùúåùëñ it follows
transitions
‚Ä≤
‚Ä≤
from ùõø, and each step from the end of ùúå
over into ùúå
ùëñ‚àí1
ùëñ
is done via the additional

transitions through ùëûùêπ . At last (iii) the run is accepting since it visits ùëûùêπ
therefore infinitely often.
"‚äÜ". Suppose ùë§ = ùëé ùëé . . .
0
1
‚àà ùêø(B), i.e. there is an accepting run ùúå =
ùëû
, ùëé
, ùëû
, ùëé
, . . .
0
0
1
1
of B on ùë§. Hence, there must be 0 = ùëñ0 < ùëñ1 < . . . s.t. ùëûùëñ = ùëûùêπ for ùëó
all ùëó ‚â• 1, and ùëû
, ùëñ , . . .
‚Ñé
‚â† ùëûùêπ for all ‚Ñé not occurring in the sequence ùëñ0 1

This defines
finite runs ùúå
, ùëé
, . . . , ùëé
, ùëû
. . . ùëé
ùëó
‚à∂= ùëûùëñ
ùëñ
ùëñ
ùëñ
on underlying words ùë¢ ùëó ‚à∂= ùëéùëñ
ùëñ
ùëó
ùëó
ùëó +1 ‚àí1
ùëó +1
ùëó
ùëó +1 ‚àí1
for every ùëó ‚â• 0. Next, we have ùëûùëñ ‚àà ùêπ for all ùëó ‚â• 1. Since ùëûùëñ = ùëû

ùëó
0
0 = ùëû ùêº by construc-
tion, we have that ùúå0 is an accepting run of A on ùë¢0. Likewise, we get that ùúåùëñ
is an ùúî
accepting run of A on ùë¢
ùë¢
. . .
ùëñ
for all ùëñ ‚â• 1. Since ùë§ = ùë¢0 1
we have ùë§ ‚àà ùêø(A) .
‚óª
5.3 Closure Properties
101
We can use these constructions to show that every ùúî-regular language is
NBA-recognisable.
Theorem 5.12 Let ùêø ‚äÜ Œ£ùúî . If ùêø is ùúî -regular then ùêø is B√ºchi-r ecognisable.
Proof
ùëõ
ùúî
Suppose ùêø is ùúî-regular. According to Lemma 5.4 we have ùêø = ‚ãÉ

ùëà ùëâ
ùëñ=1
ùëñ
ùëñ
for some ùëõ and regular languages ùëà , ùëâ
ùëñ
ùëñ (with ùúÄ /
‚àà ùëâùëñ ). According to Lemma 5.9-5.11
we can construct, making use of NFA for the ùëàùëñ and ùëâùëñ, an NBA for ùêø.
‚óª
The converse direction holds as well.
Theorem 5.13 Let ùêø ‚äÜ Œ£ùúî . If ùêø is B√ºchi-recognisable then ùêø is ùúî -regular .
Proof Suppose that ùêø is B√ºchi-recognisable, i.e. there is some NBA A = (ùëÑ,
Œ£, ùëû , ùõø, ùêº
ùêπ ) s.t. ùêø = ùêø(A). Given ùëù, ùëû ‚àà ùëÑ, we write ùêø ùëù,ùëû for ùêø(A ùëù,ùëû ) where A
ùëù,ùëû is the NFA (ùëÑ, Œ£, ùëù, ùõø, {ùëû}). Clearly, ùêø ùëù,ùëû is a regular language of
finite words by construction.
We then claim that we ha ve
ùúî
ùêø (A)
=

‚ãÉ ùêøùëû ,ùëû (ùêøùëû,ùëû ‚àñ {ùúÄ})
(5.1)
ùêº
ùëû‚ààùêπ
which proves that ùêø is ùúî-regular. Note that ùêøùëû,ùëû ‚àñ {ùúÄ} is regular and
clearly does not contain ùúÄ. It remains to be seen that the claim made in (5.1)
is true.
ùúî
"‚äá" Suppose ùë§ ‚àà ‚ãÉ
ùêø
ùëû‚ààùêπ
ùëû
, ùëû ( ùêø ùëû , ùëû ‚àñ {ùúÄ })
. I.e. there is some ùëû ‚àà ùêπ and there are
ùêº
ùë¢ ‚àà Œ£‚àó, ùë£ , ùë£ , . . .
ùë£
. . .
0
1
‚àà Œ£+ s.t. ùë§ = ùë¢ùë£0 1

with ùë¢ ‚àà ùêøùëû ,ùëû and ùë£ùëñ ‚àà ùêøùëû,ùëû for all ùëñ ‚â• 0.
ùêº
Hence, there are accepting runs ùúé = ùëû , . . . , ùëû
ùêº
of Aùëû ,ùëû on ùë¢, and ùúåùëñ = ùëû, . . . , ùëû of
ùêº
Aùëû,ùëû on ùë£ùëñ for ùëñ ‚â• 0. Since Aùëû ,ùëû and Aùëû,ùëû have the same transition table
as A, these ùêº
runs can be concatenated to a run ùúå that is obtained from ùúé, ùúå , ùúå , . . .
0
1
by merging
the double occurrences of state ùëû at the beginning of each ùëûùëñ with the end
of the previous part. Then ùúå is a run of A on ùë§. It clearly starts in the initial
states, and it visits state ùëû infinitely often, namely at the beginning of each
part ùúåùëñ. Hence, it is an accepting run, and we therefore have ùë§ ‚àà ùêø(A).
"‚äÜ" Suppose ùë§ = ùëé ùëé . . .
0
1
‚àà ùêø(A), i.e. there is an accepting run ùúå =
ùëû
, ùëé

, ùëû
, ùëé
, . . .
0
0
1
1
of A on ùë§. We therefore have ùëû0 = ùëûùêº , and there must be some
ùëû ‚àà ùêπ s.t. ùëûùëñ = ùëû for infinitely many ùëñ. In other words, there are ùëñ0 < ùëñ1 < .
. . s.t. ùëûùëñ = ùëû
ùëó
for all ùëó ‚â• 0. This defines a decomposition of ùë§ into ùë¢ùë£ ùë£ . . .
. . . ùëé
0 1
by ùë¢ ‚à∂= ùëé0
ùëñ0‚àí1
and ùë£
. . . ùëé
, . . . , ùëû
ùëó

‚à∂= ùëéùëñ
ùëñ
ùëñ
of ùúå is an accepting
ùëó
ùëó +1 ‚àí1 for
ùëó ‚â• 0. Then the prefix ùëû0
0
run of Aùëû ,ùëû because ùëû
= ùëû. Hence, ùë¢ ‚àà ùêøùëû ,ùëû . Likewise, each infix
ùêº
0 = ùëû ùêº and ùëûùëñ0
ùêº
ùëû
, . . . , ùëû
ùëñ
ùëñ
is an accepting run of Aùëû,ùëû on ùë£ùëñ because ùëûùëñ
= ùëû = ùëûùëñ
. Hence,

ùëó
ùëó +1
ùëó
ùëó +1
ùúî
ùë£
ùë£
OceanofPDF.com

. . .
ùëó
‚àà ùêøùëû,ùëû for all ùëó ‚â• 0, and therefore ùë£0 1
‚àà (ùêøùëû,ùëû )
. In fact, we even have
ùúî
ùë£
ùë£
. . .
0 1
‚àà (ùêøùëû,ùëû ‚àñ {ùúÄ})
because ùë£ ùëó ‚â† ùúÄ for each ùëó which is a consequence of the
ùúî
fact that ùëñ
ùë£
. . .
ùëó
< ùëñ ùëó+1. But then we have ùë§ = ùë¢ùë£0 1
‚àà ùêø ùëû ,ùëû (ùêøùëû,ùëû ‚àñ {ùúÄ})

which
ùêº
finishes the proof of the claim.
‚óª
For the sake of completeness we state the combination of Thm. 5.12 and
5.13
explicitly. This result is also known as B ¬®
uchi's Theorem.
Corollary 5.14 Let ùêø ‚äÜ Œ£ùúî . ùêø is B√ºchi-recognisable iff it is ùúî -regular.
102
5 Automata on Infinite Words
Thm. 5.13 suggests a simple procedure for determining non-emptiness of B
√ºchi automata based on two nested graph reachability searches.
Theorem 5.15 The nonemptiness problem for NBA is decidable in
polynomial time.
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an NBA. The proof of Thm. 5.13 shows that
ùêø (A) ‚â† ‚àÖ if and only if there exists ùëû ‚àà ùêπ such that ùëû is reachable from ùëûùêº
and ùëû
itself is reachable from ùëû with a nonempty path. Using depth- or breadth-
first search (DFS/BFS) we can first compute all accepting states that are
reachable from the initial states. Then we can check, using DFS or BFS

again, for each of them whether they are reachable from themselves in more
than zero steps. Since DFS and BFS
can be implemented to run in time that is linear in the number ùëí of edges of
the underlying graph, i.e. at most quadratic in the size ùëõ of the NBA
measured in terms of number of nodes, the overall procedure takes at most
time O(ùëõ ‚ãÖ ùëí) or O(ùëõ3). ‚óª
This is not the tightest upper bound from a complexity-theoretic point of
view.
Reachability in graphs can be decided in nondeterministic logarithmic
space. The nesting of two searches can be implemented in order not to
exceed this asymptotically. Hence, the emptiness problem for NBA even
belongs to the complexity class NLogSpace.
5.3.2 Intersections and Homomorphisms
Clearly, the closure properties of the class of B √ºchi-definable languages
derived in Lemma 5.9-5.11 above carry over to ùúî-regular languages with
the chracterisation of the latter via B √ºchi-recognisability. This, however, is
of very little help since closure under union, left-concatenation with a
regular language and under ùúî-iterations of regular languages is more or
less a direct consequence of the construction of ùúî-regular languages.
Nevertheless, B √ºchi automata can be used to provide further closure
properties of this class, most notably closure under Boolean operations.
The construction showing closure under intersections is based on the
product construction for NFA. However, for NBA it is more intricate. The
reason is simple.
Let A and B be NFA, and suppose we want to know whether they both
accept a given word ùë§ ‚àà Œ£‚àó. This can be done in one traversal of the word
by simulating both A and B at the same time, i.e. using a synchronous
product construction. When arriving at the end, we need to check that both
have reached an accepting state at that very same moment.

Now suppose that A and B are NBA, and ùë§ ‚àà Œ£ ùúî. Again, using a product
construction we can simulate both of them in parallel. However, we now
need to accept if and only if both of them have seen their respective
accepting states infinitely often, and this need not happen at the same time.
Example 5.16 The following shows three NBA A, B, C over Œ£ = {ùëé}.
5.3 Closure Properties
103
ùëé
ùëé
ùëé
A
0
1
B
0
1
C
0, 0
1, 1
ùëé
ùëé

ùëé
NBA C is obtained from A and B using the na¬®ƒ±ve product construction
where a state pair becomes accepting when both its components are
accepting in the respective underlying automata. Here, the only accepting
pair would be (1, 0) but it is not reachable from the initial state (0, 0).
Hence, we have ùêø(C) = ‚àÖ. On the other hand, ùúî
ùúî
we have ùêø(A) = ùëé
= ùêø(B) and, thus, ùêø(A) ‚à© ùêø(B) = ùëé
‚â† ‚àÖ.
This example shows that a refinement of the product construction is needed
to capture the intersection of two B √ºchi-definable languages. We need a
mechanism that makes the product automaton hit an accepting state
infinitely often if and only if the two underlying automata do this, and this
may happen asynchronously. The trick relies on the following observation:
suppose ùúå = ùëù , ùëù , . . .
, ùëû
, . . .
0
1
and ùúé = ùëû0
1
‚Ä≤
are accepting runs w.r.t. some sets ùêπ, ùêπ of accepting states, i.e. ùëùùëñ ‚àà ùêπ for
infinitely

‚Ä≤
many ùëñ, and ùëûùëñ ‚àà ùêπ for infinitely many ùëñ. Then for every ùëñ s.t. ùëùùëñ ‚àà ùêπ there
is some
‚Ä≤
ùëó
> ùëñ s.t. ùëû ùëó ‚àà ùêπ , and vice-versa. The converse is true as well. This provides
a simple recipe for detecting whether accepting states are seen infinitely
often in both underlying runs in a product construction: simulate both runs
until an accepting state is seen in the first component. Then continue
simulating both runs until an accepting state is seen in the second
component. Then accepting states are seen infinitely often in both
components iff we change infinitely often from one waiting mode into the
other.
Theorem 5.17 Let Aùëñ be NBA over some Œ£ for ùëñ ‚àà {1, 2} . There is an NBA
B s.t.
ùêø (B) = ùêø(A1) ‚à© ùêø(A2) and ‚à£B‚à£ ‚â§ 2 ‚ãÖ ‚à£A1‚à£ ‚ãÖ ‚à£A2 ‚à£ .
Proof
ùëñ
Let A
, Œ£, ùëû , ùõø , ùêπ
ùëñ
= (ùëÑùëñ
ùêº
ùëñ

ùëñ ) for ùëñ = 1, 2. Define
1
2
B
‚à∂= (ùëÑ
, ùëû
,
1 √ó ùëÑ2 √ó {1, 2}, Œ£, (ùëû ùêº
ùêº
1), Œî, ùêπ1 √ó ùëÑ2 √ó {1 })
‚Ä≤
‚Ä≤
‚Ä≤
where, for all ùëé ‚àà Œ£, ùëù, ùëû ‚àà ùëÑ
, ùëû
, ùëó
1, ùëù
‚àà ùëÑ2, ùëñ, ùëó ‚àà {1, 2} we have: (ùëû, ùëû
) ‚àà
Œî

‚Ä≤
‚Ä≤
‚Ä≤
(( ùëù, ùëù , ùëñ), ùëé) iff ùëû ‚àà ùõø
, ùëé
1( ùëù, ùëé), ùëû
‚àà ùõø2( ùëù
) and
‚éß
‚é™
‚Ä≤
‚é™1
, if ùëñ = 1 and ùëù /
‚àà ùêπ ,
1
or ùëñ = 2 and ùëù ‚àà ùêπ2
ùëó = ‚é®
‚é™
‚é™2
, otherwise.

‚é©
Thus, B simulates A1 and A2 in its first and second state components. The
value ùëñ in the extra third component can be interpreted as B expecting to
eventually see an accepting state of Aùëñ. Whenever this has happened, the
value is flipped. So intuitively, in order to verify that both A1 and A2 have
accepting runs on a given word, B simulates them both stepwise in parallel
and verifies that there is an infinite sequence of alternating moments
between them in which they traverse accepting states of theirs respectively.
The size claim on B is obvious. It remains to be seen that we have ùêø(B) =
ùêø (A1) ‚à© ùêø(A2).
104
5 Automata on Infinite Words
"‚äá" Suppose ùë§ = ùëé ùëé . . .
0
1
‚àà ùêø(A1) ‚à© ùêø(A2), i.e. there are accepting runs
‚Ä≤
ùúå
= ùëù , ùëé , ùëù , ùëé , . . .
, ùëé
, ùëû
, ùëé
, . . .

0
0
1
1
and ùúå
= ùëû0
0
1
1
of A1, resp. A2 on ùë§. Let
ùúé ‚à∂= ( ùëù , ùëû , ùëê
,
, ùëû
, ùëê
, . . .
0
0
0), ùëé0 ( ùëù1
1
1), ùëé1

where ùëê0 ‚à∂= 1 and ùëêùëñ+1 is the unique value
that, given ùëù , ùëû , ùëê
, ùëû
, ùëê
, ùëû , ùëê
ùëñ
ùëñ
ùëñ , ensures that ( ùëùùëñ+1
ùëñ+1
ùëñ+1) ‚àà Œî(( ùëùùëñ
ùëñ
ùëñ ), ùëé ùëñ ). Note that
Œî is indeed deterministic in its third component, i.e. this component in a
successor state is uniquely determined by the previous state. Then ùúé is a run
of B on ùë§, and it clearly starts in B's initial state.
It is also an accepting run for the following reason. Starting with ùëê0 = 1,
there must be some ùëñ0 ‚â• 0 s.t. ùëùùëñ ‚àà ùêπ
0
1, because ùúå contains infinitely many accepting
states. Then we get ùëêùëñ
‚àà ùêπ

0 +1 = 2. Likewise, there must be some ùëñ1 > ùëñ0 s.t. ùëûùëñ1
2,
‚Ä≤
because ùúå contains infinitely many accepting states. Hence, we have ùëêùëñ1+1
= 1, and the argument can be iterated to construct an infinite sequence of
positions in the run ùúé, namely ùëñ , ùëñ , . . .
1
3
, at which a state from ùêπ1 √ó ùëÑ2 √ó {1}, i.e. an accepting state, is seen.
"‚äÜ" Analogously, the projection of an accepting run ùúé of B onto its first,
resp.
second component yields runs of A1, resp. A2 on the underlying word. Since
ùúé is accepting, so must both projected runs be. Otherwise suppose that one
of them would eventually not visit an accepting state from ùêπ1, resp. ùêπ2
anymore. Then the value in the third component of the states in ùúå will
eventually not flip anymore, and it will remain to be the index of the
underlying NBA whose run does not visit accepting states anymore. So ùúå
will eventually only visit states in (ùëÑ1 ‚àñ ùêπ1) √ó ùëÑ2 √ó {1} or in ùëÑ1 √ó (ùëÑ2 ‚àñ ùêπ2) √ó
{2}. Neither of them is accepting in B, though. Thus, if ùúå is accepting, so are
both the underlying runs in its components.
‚óª
An obvious question concerns the closure of ùúî-REG under complementation.
It is tempting to assume that the complement of an ùúî-regular language
should be ùúî-regular as well, simply because of what is known about regular
languages of finite words. This does not provide a sound mathematical
argument, though, and at closer sight it is not so clear whether
complementation closure holds as well. The following section investigates

deterministic B √ºchi automata, and shows that they are useless for the
question after the complementation closure of ùúî-REG: not only can they not
be complemented, it is not even the case that they accept all languages in ùúî-
REG. This is a surprising difference to the world of finite words, and it
shows that the step to infinite words did introduce some extra combinatorial
difficulty.
Nevertheless, ùúî-REG is indeed closed under complements, and this extra
difficulty becomes apparent when attempting to prove this. Because of this
extra difficulty involved, the presentation of this result is deferred to its own
section below, cf.
Sect. 5.5.
At last, some later constructions need homomorphism closure which holds
true for ùúî-regular languages as well. Here we state it in a slightly restricted
form, namely for non-deleting homomorphisms only. Note that the notion of
homomorphic image of a language of ùúî-words can become ill-defined in the
context of homomorphisms ùúî
ùúî
that may delete letters. For instance, if ‚Ñé(ùëé) = ùúÄ and ‚Ñé(ùëè) = ùëè, then ÀÜ
‚Ñé((ùëé ùëè)
) = ùëè
ùúî
but ÀÜ
‚Ñé(ùëé
) is no longer an infinite word. The proof of the following lemma is left as
an exercise.
5.4 Deterministic B √ºchi Automata

105
Lemma 5.18 Let Œ£, Œî be alphabets, ‚Ñé ‚à∂ Œ£ ‚Üí Œî+ , ùêø ‚äÜ Œ£ùúî . If ùêø ‚àà ùúî‚àí REG Œ£
then ÀÜ
‚Ñé(ùêø) ‚àà ùúî‚àí REG Œî .
5.4 Deterministic B ¬®
uchi Automata
As with NFA and DFA, we can impose the restriction of determinism onto a
B √ºchi automaton's transition relation.
Definition 5.19 A deterministic B√ºchi automaton (DBA) is an NBA A = (ùëÑ,
Œ£, ùëû , ùêº
ùõø, ùêπ ) s.t. ‚à£ùõø(ùëû, ùëé) ‚â§ 1‚à£ for all ùëû ‚àà ùëÑ, ùëé ‚àà Œ£, just as determinism is defined for
automata on finite words. Consequently, we call a language deterministic B
¬®
uchi-recognisable
or just DBA-recognisable, resp. -definable if it is the language of some
DBA.
Example 5.20
‚àó
ùúî
Reconsider the language ùêø
ùëè
1 = ùêø((ùëé
)

) from Ex. 5.8 and the NBA
A1 that recognises it. A1 is clearly not deterministic. The nondeterminism
on ùëè in state 0 is useless, though. There is no gain in taking the transition
(0, ùëè, 0). Hence, it can be removed. This already leads to a DBA
recognising ùêø1 as well. We give a slightly modified one.
ùëé
ùëè
ùëè
‚Ä≤
A1
0
1
ùëé
It is clearly deterministic as well. Additionally it has the property that any
run takes
‚Ä≤
A
into state 0 upon reading ùëé and into state 1 upon reading ùëè. A trivial
consequence 1
‚Ä≤
is that ùêø(A ) = ùêø
1

1; a run contains state 0 infinitely often iff the underlying word contains ùëè
infinitely often. Thus, ùêø1 is even DBA -recognisable.
‚àó
ùúî
Now consider ùêø
ùëé
3 ‚à∂= (ùëé + ùëè)
, i.e. the language of all words that contain ùëè only
finitely often. Clearly, we have ùêø3 = Œ£ùúî ‚àñ ùêø1. First we note that we do not
obtain a
‚Ä≤
DBA for ùêø2 by employing the complementation construction for DFA on A ,
namely 1
swapping accepting and non-accepting states. This results in a DBA that
recognises the language of all words which contain infinitely many symbols
ùëé. This is a genuine superset of ùêø3; every word containing only finitely
many symbols ùëè necessarily has to contain infinitely many symbols ùëé when
the underlying alphabet is {ùëé, ùëè}, but there are also words that contain both
letters infinitely often.
The fact that swapping accepting for non-accepting states in a DBA does
not produce a DBA for the complement language is not surprising at closer
inspection.
A DBA accepts a word ùë§ if the unique run on it traverses accepting states
infinitely often. Thus, a word is not accepted if the unique run on it
traverses accepting states only finitely often, and this is stronger than
visiting non-accepting states infinitely often.

Example 5.21 ùêø3 from Ex. 5.20 above is instead recognised by the
following NBA.
106
5 Automata on Infinite Words
ùëé, ùëè
ùëé
ùëé
A3
0
1
It makes proper use of nondeterminism. In order to confirm that the
underlying word ùë§ only has finitely many symbols ùëè, it reads an arbitrary
prefix, essentially ignoring its content by simply looping around in state 0.
This cannot be done forever, for such a run is clearly not accepting. Thus,
A3 must eventually move to state 1 upon reading of a letter ùëé. This can be
interpreted as guessing that there will be no more symbols ùëè in what
follows since A3 would get stuck in state 1 upon reading another ùëè.
The fact that A3 in this example is not a DBA but "only" an NBA for ùêø2 is
not a coincidence. ùêø2 is an example of a language that is not DBA-
recognisable, and this yields the first perhaps surprising deviation from the
results in the theory of regular languages of finite words where every NFA-
recognisable language is also DFA-recognisable. To prove this, we
introduce a topological construction on infinite words.
Definition 5.22 Let (ùë§ùëõ)ùëõ‚â•0 be an infinite sequence of ùúî-words. Its limit,
denoted lim
ùë§

ùëõ‚Üí‚àû
ùëõ if it exists, is the ùúî-word defined by
( lim ùë§
ùë§
ùëõ )(ùëñ )
‚à∂=
lim
ùëõ (ùëñ )
ùëõ‚Üí‚àû
ùëõ‚Üí‚àû
where lim
ùëé
ùëõ‚Üí‚àû
ùëõ = ùëé for an infinite sequence (ùëéùëõ )ùëõ‚â•0, iff there is ùëõ0 s.t. ùëéùëõ = ùëé for all ùëõ
‚â• ùëõ 0.
The limit of a sequence (ùë§ùëõ)ùëõ‚â•0 of words need not exist as the following
example shows.
Example 5.23 Consider the infinite sequence of words (ùë§ùëõ)ùëõ‚â•0 defined as
follows.
ùúî
ùë§

,
ùë§
,
ùë§
0
‚à∂= ùëé
2ùëõ+1 ‚à∂= ùëèùë§2ùëõ
2ùëõ+2 ‚à∂= ùëéùë§2ùëõ +1
for all ùëõ ‚â• 0. Then lim
ùë§
ùëõ‚Üí‚àû
ùëõ
does not exist. Take any position ùëñ. The sequence of
letters at position ùëñ in (ùë§ùëõ)ùëõ‚â•0 is
ùëé, . . . , ùëé, ùëè, ùëé, ùëè, ùëé, ùëè, ùëé, . . .
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùëñ+1
and clearly does not converge to a limit point, i.e. one single letter. Hence,
the letter at any position of the supposed limit of (ùë§ùëõ)ùëõ‚â•0 is undefined,
and therefore this limit does not exist.
‚Ä≤

‚Ä≤
Now consider the sequence (ùë§ )
‚à∂= ùë§
ùëõ
ùëõ‚â•0 defined by ùë§ ùëõ
2ùëõ, i.e. the subsequence
of the one above obtained by dropping every second word. It is not hard to
see that we
‚Ä≤
ùúî
‚Ä≤
‚Ä≤
‚Ä≤
ùëõ
ùúî
have ùë§ = ùëé
and ùë§
= ùëé ùëèùë§
= (ùëé ùëè) ùëé
. The limit of this sequence

0
ùëõ+1
ùëõ , hence, ùë§ ùëõ
‚Ä≤
ùúî
does indeed exist, and we have lim
ùë§
ùëõ‚Üí‚àû
= (ùëé ùëè)
ùëõ
.
‚Ä≤
Note that the limit of (ùë§ )
ùëõ
ùëõ‚â•0 contains infinitely many symbols ùëè even though
‚Ä≤
every ùë§ùëõ contains finitely many symbols ùëè only.
5.4 Deterministic B √ºchi Automata
107

Theorem 5.24 There are NBA-definable languages that are not DBA-
definable.
Proof
‚àó
ùúî
Take ùêø
ùëé
3 = (ùëé + ùëè)
from Ex. 5.20 above. Ex. 5.21 shows that it is NBA-
recognisable. Now suppose there was a DBA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) s.t. ùêø(A) = ùêø3.
Here we denote a run as an infinite sequence ùëû , ùëé , ùëû , ùëé , . . .
0
0
1
1
alternating between
states and letters.
ùúî

First consider the word ùë§0 ‚à∂= ùëèùëé . Since ùë§0 ‚àà ùêø2 there is an accepting
run ùúå
, ùëè, ùëû0 , ùëé, ùëû0 , ùëé, . . .
0 = ùëû0
of A on ùë§
0
1
2
0. Since it traverses accepting states infinitely
often, there must be some ùëñ0 > 0 s.t. ùëû0 ‚àà ùêπ
ùëñ
.
0
ùëñ
ùúî
Now consider the word ùë§
0 ‚àí1 ùëèùëé
1 ‚à∂= ùëèùëé
. Again, we have ùë§1 ‚àà ùêø3 and there must
be an accepting run ùúå

, ùëè, ùëû1 , ùëé, . . . , ùëé, ùëû1 , ùëè, ùëû1
, ùëé, . . .
1 = ùëû1
The crucial insight
0
1
ùëñ
ùëñ
0
0 +1
here now is that, not only do we have ùëû1 = ùëû0 because both runs ùúå
0
0
0 and ùúå1 start in
the unique starting state, but in fact ùëû1 = ùëû0
ùëó
ùëó
for all ùëó ‚â§ ùëñ0. This is a consequence
of A's determinism, namely that runs on two words that have a common
prefix of some length ùëö, have itself a common prefix of length ùëö + 1
(purely counting states).

Hence, we can drop the superscript indices and simply say that
0
ùúå
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëé, ùëû
, ùëé, . . .
,
0
= ùëû0
1
ùëñ0
ùëñ0+1
1
ùúå
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëè, ùëû
, ùëé, . . .
1

= ùëû0
1
ùëñ0
ùëñ0+1
Now this can be continued. Since ùúå1 is accepting, there must be some ùëñ1 >
ùëñ0 s.t.
ùëñ
ùëñ
ùúî
ùëû1
‚àà ùêπ
0 ‚àí1 ùëè 1‚àíùëñ0‚àí1 ùëé
ùëñ
, yielding ùë§2 ‚à∂= ùëèùëé
and an accepting run ùúå3 which, by the same
1
argument appealing to A's determinism, must share a prefix with ùúå2 up to ùëûùëñ
at 1
least. Continuing this yields the following sequence of runs.
0
ùúå

, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëé, ùëû
, . . .
0 = ùëû0
1
ùëñ0
ùëñ0+1
1
ùúå
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëé, ùëû
, . . .
1 = ùëû0
1
ùëñ
ùëñ

ùëñ
0
0 +1
1
ùëñ1+1
2
ùúå
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëé, ùëû
, . . .
2 = ùëû0
1
ùëñ
ùëñ
ùëñ

ùëñ
ùëñ
0
0 +1
1
1 +1
2
ùëñ2+1
ùúå
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëè, ùëû
, ùëé, . . . , ùëé, ùëû
, ùëè, ùëû
, . . .
3 = ùëû0
1
ùëñ

ùëñ
ùëñ
ùëñ
ùëñ
ùëñ
0
0 +1
1
1 +1
2
2 +1
‚ãÆ
Let ùúå ‚à∂= lim
ùúå
ùëõ‚Üí‚àû
ùëõ . Note that ùúå exists because the ùúåùëõ have growing common
prefixes with all subsequent ùúåùëö. Next we note that ùúå is a run of A on the w
ord ùëñ
ùëñ
ùëñ

ùë§
‚à∂= ùëèùëé 0‚àí1 ùëèùëé 1‚àíùëñ0‚àí1 ùëèùëé 2‚àíùëñ1‚àíùëñ0‚àí1 ùëè . . .
which contains infinitely many symbols ùëè. Thus, we have ùë§ /
‚àà ùêø3. However, ùúå is in
fact an accepting run because it hits the states ùëû , ùëû , ùëû , . . .
ùëñ
ùëñ
ùëñ
which are all accepting.
0
1
2
This contradicts the assumption that A is indeed a DBA for ùêø3.
‚óª
Corollary 5.25 The class of DBA-definable languages is not closed under
complementation.
Proof This is a direct consequence of the fact that the language ùêø2 which is
shown not to be DBA-definable in the proof of Thm. 5.24 is in fact the
complement of ùêø1
from Ex. 5.20 where this is shown to be DBA-definable.
‚óª

108
5 Automata on Infinite Words
5.5 Complementation Closure
As said before, the proof of complementation closure of the class of ùúî-
regular languages is combinatorially more involved than the corresponding
result for automata on finite words. One way of proving this uses a result
from infinite combinatorics.
5.5.1 Ramsey's Theorem
ùê¥
ùê¥
For a set ùê¥ we write ( ) to denote the set of subsets of ùê¥ of size 2, i.e. ( ) =
2
2
N
N
{{ùë•, ùë¶} ‚à£ ùë•, ùë¶ ‚àà ùê¥, ùë• ‚â† ùë¶}. We are particularly interested in ( ). In this case,
( ) can 2
2
be depicted as the set of edges in the following undirected graph.
. . .
0
1

2
3
4
5
6
. . .
ùê¥
Given sets ùê¥, ùê∂, a ùê∂- colouring of ùê¥ is a function ùëì ‚à∂ ( ) ‚Üí ùê∂. Usually we
assume 2
ùê∂ to be finite here. Intuitively, the elements of ùê∂ can be thought of as
colours, and then ùëì assigns a colour to each unordered pair of elements in
ùê¥. Such a colouring ùëì
‚Ä≤
‚Ä≤
ùê¥
is called constant if ùëì (ùëí) = ùëì (ùëí ) for all ùëí, ùëí ‚àà ( ).
2
Now let ùêµ ‚äÜ ùê¥. Then the restriction of ùëì to ùêµ, written ùëì ‚à£ ùêµ and simply
defined as ùêµ
ùëì ‚à£ùêµ(ùëí) = ùëì (ùëí) for any ùëí ‚àà ( ), is clearly a ùê∂-colouring of ùêµ. Note that, if ùêµ
‚äÜ ùê¥
2

ùêµ
ùê¥
then ( ) ‚äÜ ( ), and each ùê∂-colouring ùëì of ùê¥ uniquely determines a ùê∂-
colouring 2
2
ùëì ‚à£ùêµ of ùêµ.
The following combinatorial result is known as Ramsey's Theorem.
Theorem 5.26 Let ùê¥ be an infinite set, ùê∂ be a finite set and ùëì be a ùê∂ -
colouring of ùê¥ . Then there is an infinite subset ùêµ ‚äÜ ùê¥ such that ùëì ‚à£ùêµ is
cons tant.
Proof W.l.o.g. we assume ùê¥ to be countable. Otherwise one may restrict the
following to a countable subset of ùê¥ or rely on the axiom of choice. What is
needed is just that we can always pick a "next" element from ùê¥.
We construct a sequence (ùëé , ùê¥ , ùëê
, ùê¥ , ùëê
, ùê¥ , ùëê
0
0
0), (ùëé1
1
1), (ùëé2
2

2), . . . of triples from
ùê¥
ùê¥ √ó 2 √ó ùê∂ such that
(i) ùê¥ 0 ‚äá ùê¥ 1 ‚äá ùê¥ 2 ‚äá . . .,
(ii) ùëéùëñ ‚àà ùê¥ùëñ‚àí1 ‚àñ ùê¥ùëñ for all ùëñ ‚â• 1, and, thus, ùëé ùëó ‚â† ùëéùëñ for all ùëó > ùëñ, (iii) ‚à£ùê¥ùëñ‚à£ =
‚àû for all ùëñ ‚â• 0 and
(iv) ùëì ({ùëé , ùë•
ùëñ
}) = ùëêùëñ for all ùë• ‚àà ùê¥ ùëñ .
We choose ùëé0 arbitrarily and ùëê0 as a colour that colours infinitely many
pairs of the form {ùëé , ùë•
0
} for ùë• ‚àà ùê¥ ‚àñ {ùëé0}. By finiteness of ùê∂ and infiniteness of ùê¥ ‚àñ {ùëé0}, some
colour must be used infinitely often for sets containing ùëé0. We then put ùê¥0
‚à∂= {ùë• ‚à£
ùëì ({ùëé , ùë•
0
}) = ùëê0}. Note that ùëé0 /
‚àà ùê¥0.
5.5 Complementation Closure
109

Now suppose that the sequence has already been constructed up to the ùëõ-th
element such that the properties (i)-(iv) hold accordingly. Then we choose
ùëéùëõ+1
arbitrarily from ùê¥
, ùëê
ùëõ
and construct ùê¥ùëõ+1
ùëõ+1 as in the case ùëõ = 0: pick a color ùëêùëõ+1
s.t. ùëì ({ùëé
, ùë•
ùëõ+1
}) = ùëêùëõ+1 for infinitely many ùë• ‚àà ùê¥ùëõ. Note that here we restrict our
attention to ùê¥ùëõ rather than the full set ùê¥. Again, by finiteness of ùê∂ and
infiniteness of ùê¥
, ùë•
ùëõ , such a ùëêùëõ+1 must exist. Finally, let ùê¥ùëõ+1 ‚à∂= {ùë• ‚àà ùê¥ùëõ ‚à£ ùëì ({ùëéùëõ+1
}) = ùëêùëõ+1}.
Properties (i), (iii) and (iv) are satisfied for ùëõ + 1 by construction. Property
(ii) ùê¥
also holds for ùëõ + 1 as well: we have ùëéùëõ+1 /‚àà ùê¥ùëõ+1 because ùëì is only
defined on ( ) 2
ùê¥

and {ùëé
, ùëé
ùëõ+1
ùëõ+1} = {ùëéùëõ+1} /
‚àà ( ).
2
Now suppose that the infinite sequence (ùëé , ùê¥ , ùëê
, ùê¥ , ùëê
0
0
0), (ùëé1
1
1), . . . is given such
that properties (i)-(iv) hold. Again, because of finiteness of ùê∂, there must be
some ùëê ‚àà ùê∂ such that ùëêùëñ = ùëê for infinitely many ùëñ ‚àà N, i.e. there are ùëñ0 < ùëñ1
< . . . s.t. ùëêùëñ = ùëê
ùëó
for all ùëó ‚â• 0. Let ùêµ ‚à∂= {ùëéùëñ ‚à£ ùëó ‚â• 0}. We claim that ùêµ has the properties
required in ùëó
the theorem. Clearly, ‚à£ùêµ‚à£ = ‚àû because of the conclusion in property (ii). It
remains ùêµ

to be seen that ùëì ‚à£ùêµ is constant, in particular that ùëì ({ùë•, ùë¶}) = ùëê for any {ùë•,
ùë¶} ‚àà ( ).
2
ùêµ
Take some {ùë•, ùë¶} ‚àà ( ). By construction, there must be ùëó , ‚Ñé ‚àà N such that ùë•
= ùëéùëñ
2
ùëó
and ùë¶ = ùëéùëñ . W.l.o.g. we assume that ùëó < ‚Ñé and therefore ùëñ ùëó < ùëñ‚Ñé. Thus, we
have ‚Ñé
ùëé
, ùëé
ùëñ
‚àà ùê¥ùëñ
by property (i) and ùëì ({ùë•, ùë¶}) = ùëì ({ùëéùëñ
ùëñ
}) = ùëêùëñ
= ùëê by property (iv). ‚óª
‚Ñé
ùëó
‚Ñé

‚Ñé
ùëó
5.5.2 B ¬®
uchi's Complementation Construction
Fix an NBA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
). In the remainder of this section, ùëõ will always
denote the size of A, i.e. ùëõ = ‚à£ùëÑ‚à£.
The goal is to construct an NBA B such that ùêø(B) = ùêø(A). We define
relations ùë¢
ùë¢
√ê
‚Üí, √î
‚áí ‚äÜ ùëÑ √ó ùëÑ for any finite word ùë¢ ‚àà Œ£‚àó as f ollows.
‚Ä¢
ùë¢
‚Ä≤
‚Ä≤
We have ùëû √ê
‚Üí ùëû if it is possible to reach state ùëû from state ùëû in A while working ùë¢

‚Ä≤
off ùë¢. In other words, suppose that ùë¢ = ùëé . . . ùëé
0
ùëö‚àí1. Then ùëû √ê
‚Üí ùëû
iff there are
‚Ä≤
ùëû
, . . . , ùëû
, ùëé
0
ùëö ‚àà ùëÑ s.t. ùëû0 = ùëû, ùëûùëö = ùëû
and ùëûùëñ+1 ‚àà ùõø(ùëûùëñ
ùëñ ) for all ùëñ ‚àà [ùëö ].
ùë¢
ùë¢
‚Ä≤
‚Ä¢ The relation √î
‚áí is a refinement thereof. We have ùëû √î
‚áí ùëû

for ùë¢ = ùëé . . . ùëé
0
ùëö‚àí1 if
‚Ä≤
there are ùëû , . . . , ùëû
, ùëé
0
ùëö ‚àà ùëÑ s.t. ùëû0 = ùëû, ùëûùëö = ùëû
and ùëûùëñ+1 ‚àà ùõø(ùëûùëñ
ùëñ ) for all ùëñ ‚àà [ùëö],
and additionally ùëûùëñ ‚àà ùêπ for some ùëñ ‚àà {0, . . . , ùëö}.
The following properties are immediate from the definition of these two
relations. If ùë¢
ùë¢
ùë¢
ùë£
ùë¢ùë£
‚Ä≤
‚Ä≤
‚Ä≤

‚Ä≤
ùëû √î
‚áí ùëû
then ùëû √ê
‚Üí ùëû , too. If ùëû √ê
‚Üí ùëù and ùëù √ê
‚Üí ùëû
and ùëù ‚àà ùêπ then ùëû √î
‚áí ùëû .
We define an equivalence relation ‚àº ‚äÜ Œ£+ √ó Œ£+ on non-empty finite words
as follow s.
ùë¢
ùë£
ùë¢
ùë£
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤

ùë¢ ‚àº ùë£
iff
‚àÄùëû.‚àÄùëû .(ùëû √ê
‚Üí ùëû
‚áî ùëû √ê
‚Üí ùëû ) and (ùëû √î
‚áí ùëû
‚áî ùëû √î
‚áí ùëû )
In other words, two words are considered to be equivalent if they induce the
same reachability relation on A, and also the same reachability-via-an-
intermediate-
110
5 Automata on Infinite Words
accepting-state relation. Put even more intuitively, ùë¢ ‚àº ùë£ means that ùë¢ and
ùë£ cannot be distinguished by A when it only comes down to the question of
which state changes the reading of a finite word induces in an NB A.
The following lemma collects a few useful observations about the relation
‚àº.
Lemma 5.27
‚Ä≤
‚Ä≤

a) Let ùë¢ ‚àà Œ£‚àó , ùë§ ‚àà Œ£ ùúî and ùë£, ùë£ ‚àà Œ£+ s.t. ùë£ ‚àº ùë£ . If ùë¢ùë£ùë§ ‚àà ùêø(A) then
‚Ä≤
ùë¢ùë£ ùë§ ‚àà ùêø(A) .
2
ùëõ
b) The relation ‚àº is an equivalence relation of index at most 3
.
Proof (a) Left as an exercise. (b) It is straightforward to see that ‚àº is an
equivalence relation. For the estimation of its index, remember that ùëõ =
‚à£ùëÑ‚à£. Note that each equivalence class [ùë¢] = {ùë£ ‚à£ ùë£ ‚àº ùë¢} is uniquely
determined by the pair of relations ùë¢
ùë¢
2
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
ùëõ
{(ùëû, ùëû ) ‚à£ ùëû √ê
‚Üí ùëû } and {(ùëû, ùëû ) ‚à£ ùëû √î
‚áí ùëû }. Clearly, there are only 2

many
2
2
ùëõ
ùëõ
candidates for each such relations. This would result in (2
)2 = 4
many possible
ùë¢
ùë¢
pairs. However, since we have √î
‚áí ‚äÜ √ê
‚Üí for any ùë¢, there are only three possibilities
ùë¢
ùë¢
‚Ä≤
for any pair (ùëû, ùëû ): either it belongs to √î
‚áí (and therefore also to √ê
‚Üí), or it belongs
ùë¢

ùë¢
ùë¢
ùë¢
ùë¢
2
ùëõ
to √ê
‚Üí ‚àñ √î
‚áí, or it does not belong to √ê
‚Üí. Hence, ‚à£{(√ê
‚Üí, √î
‚áí) ‚à£ ùë¢ ‚àà Œ£+}‚à£ ‚â§ 3
. This is
ùë¢
ùë¢
ùë£
ùë£
then an upper bound on the index of ‚àº because ùë¢ ‚àº ùë£ iff (√ê
‚Üí, √î
‚áí) = (√ê

‚Üí, √î
‚áí).
‚óª
We write Œ£+/‚àº for the set of all equivalence classes of ‚àº, i.e. Œ£+/‚àº ‚à∂=
{[ùë¢] ‚à£ ùë¢ ‚àà
Œ£+}. We need a few observations about such classes ùëà, ùëâ ‚àà Œ£+/ ‚àº.
3
Lemma 5.28
O(ùëõ )
Let ùëà ‚àà Œ£+/‚àº . There is an NFA Aùëà of size 2
such that ùêø(Aùëà ) =
ùëà .
Proof
‚Ä≤
Recall that A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) and ùëõ = ‚à£ùëÑ‚à£. For states ùëû, ùëû ‚àà ùëÑ let ùêøùëû,ùëû‚Ä≤ ‚à∂=
ùë¢
ùë¢
‚Ä≤

F
‚Ä≤
{ùë¢ ‚à£ ùëû √ê
‚Üí ùëû } and ùêø
√î
‚áí ùëû }. Note that ùêø
ùëû , ùëû‚Ä≤
‚à∂= {ùë¢ ‚à£ ùëû
ùëû , ùëû‚Ä≤
is regular and recognisable
‚Ä≤
‚Ä≤
‚Ä≤
by an NFA of size at most ùëõ + 1: if ùëû ‚â† ùëû then ùêøùëû,ùëû‚Ä≤ = ùêø(ùëÑ, Œ£, ùëû, ùõø, {ùëû }).
If ùëû = ùëû
then we need an extra state to ensure that the NFA only accepts non-empty
words.
F
Regularity of ùêøùëû,ùëû‚Ä≤ follows from this because
‚éß
‚é™

‚Ä≤
‚Ä≤
F
‚é™{ùëé ‚àà Œ£ ‚à£ ùëû
‚àà ùõø(ùëû, ùëé)}
, if ùëû ‚àà ùêπ or ùëû ‚àà ùêπ ,
ùêø
ùêø
‚é®
ùëû , ùëû‚Ä≤
= ( ‚ãÉ
ùëû , ùëû‚Ä≤‚Ä≤ ùêø ùëû‚Ä≤‚Ä≤ , ùëû‚Ä≤ ) ‚à™
‚é™‚àÖ
,
ùëû‚Ä≤‚Ä≤ ‚ààùêπ
‚é™
otherwise.
‚é©
However, this may not lead to NFA of optimal size. It is possible, though, to
construct F

NFA for the languages ùêøùëû,ùëû‚Ä≤ of size 2ùëõ by extending the state space of the
NFA
‚Ä≤
(ùëÑ, Œ£, ùëû, ùõø, {ùëû }) with a 1-bit flag in order to remember whether a run has
traversed through an accepting state. Details are left as an exercise.
F
Since 2ùëõ ‚â• ùëõ + 1 for ùëõ ‚â• 1 we have that ùêøùëû,ùëû‚Ä≤ and ùêøùëû,ùëû‚Ä≤ are recognisable
by NFA of size at most 2ùëõ, and their complements are recognisable by NFA
of size at most 22ùëõ. Now the following equation holds for each ùë¢ ‚àà Œ£+.
5.5 Complementation Closure
111
F
F
[ùë¢]
= ( ‚ãÇ ùêø
ùêø
ùêø
ùêø
)
ùëû , ùëû‚Ä≤ )
‚à©
( ‚ãÇ

ùëû , ùëû‚Ä≤ )
‚à©
( ‚ãÇ
ùëû , ùëû‚Ä≤ )
‚à©
( ‚ãÇ
ùëû , ùëû‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
ùëû , ùëû ‚ààùëÑ
ùëû , ùëû ‚ààùëÑ
ùëû , ùëû ‚ààùëÑ
ùëû , ùëû ‚ààùëÑ
ùë¢
ùë¢
ùë¢
ùë¢
‚Ä≤

‚Ä≤
‚Ä≤
‚Ä≤
ùëû √ê
‚Üíùëû
ùëû √î
‚áíùëû
ùëû √ê
‚Üíùëû
/
ùëû √î
‚áíùëû
/
‚Ä≤
Let ùëÖ denote the right-hand side of this equation. Note that the statement
"ùë¢ ‚àà ùëÖ"
‚Ä≤
is merely a reformulation of the statement ùë¢ ‚àº ùë¢ . It is then possible to use
standard intersection constructions to obtain an NFA for [ùë¢]. Since the
maximal number of conjuncts in this equation is 4ùëõ2, it is possible to
construct an NFA of size 2
3

O(ùëõ )
(22ùëõ)4ùëõ = 2
for each equiv alence class.
‚óª
The key to the proof of complementation closure is the observation that
these equivalence classes must be well-behaved w.r.t. the language ùêø(A) of
infinite words.
ùúî
In particular, languages of the form ùëàùëâ
built from pairs of such equivalence classes
must either be contained in or disjoint from ùêø(A).
Lemma 5.29
ùúî
Let ùëà, ùëâ be equivalence classes of ‚àº and let ùë§ ‚àà ùëàùëâ
. If ùë§ ‚àà ùêø(A)
ùúî
then ùëàùëâ
‚äÜ ùêø (A) .
Proof We decompose ùë§ as ùë§ = ùë¢ùë£ ùë£ ùë£ . . .
0 1 2
with ùë¢ ‚àà ùëà and ùë£ùëñ ‚àà ùëâ for ùëñ ‚â• 0 and

consider an accepting run ùúå = ùëû , ùëû , . . .
0
1
of A on ùë§. This yields a sequence of states
ùë¢
ùë£ ùëó
(ùëûùëñ ) ùëó
√ê
‚Üí ùëûùëñ
and ùëûùëñ √ê‚Üí ùëûùëñ
ùëó
‚â•0 such that ùëû ùêº
0
ùëó
ùëó +1 for
ùëó ‚â• 0. Moreover, we must have
ùë£ ùëó
ùëûùëñ
√î
‚áí ùëûùëñ

ùëó
ùëó +1 for infinitely many ùëó .
‚Ä≤
ùúî
‚Ä≤
Now take some arbitrary ùë§ ‚àà ùëàùëâ
. It remains to be seen that ùë§ ‚àà ùêø(A). As
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
above, we decompose ùë§ into ùë¢ ùë£ ùë£ . . . s.t. ùë¢ ‚àà ùëà and ùë£ ‚àà ùëâ for all ùëñ ‚â• 0.
But 0 1
ùëñ
‚Ä≤
‚Ä≤
then we have ùë¢ ‚àº ùë¢ and ùë£ùëñ ‚àº ùë£ùëñ for all ùëñ ‚â• 0 because ùëà and ùëâ are
equivalence
‚Ä≤

‚Ä≤
ùë£
ùë¢
ùëó
classes of ‚àº. As a result, we have ùëûùêº √ê
‚Üí ùëûùëñ
and ùëûùëñ √ê‚Üí ùëûùëñ
0
ùëó
ùëó +1 for all
ùëó
‚â• 0 with,
‚Ä≤
ùë£ ùëó
aditionally, ùëûùëñ √î
‚áí ùëûùëñ
ùëó
ùëó +1 for infinitely many
ùëó . Hence, it is possible to construct a
‚Ä≤

‚Ä≤
run of A on ùë§ that starts in ùëûùêº and then passes through ùëûùëñ after reading ùë¢ ,
and so 0
on. The additional observation on the fact that infinitely many pairs (ùëû , ùëû
ùëñ
ùëñ
ùëó
ùëó +1 ) not
ùë£
ùë£
ùëó
ùëó
only belong to √ê‚Üí but even √î
‚áí for the respective indices ùëó , means that this run is
indeed accepting.
‚óª
Lemma 5.30
ùúî
ùúî
Let ùëà, ùëâ be classes of ‚àº and ùë§ ‚àà ùëàùëâ

. If ùë§ ‚àà ùêø(A) then ùëàùëâ
‚äÜ ùêø (A) .
Proof
‚Ä≤
ùúî
Suppose for the sake of contradiction that there is some ùë§ ‚àà ùëàùëâ
with
‚Ä≤
ùë§
‚àà ùêø(A). Lemma 5.29 then shows that ùë§ ‚àà ùêø(A), contradicting the
assumption.‚óª
The next and final statement about the properties of equivalence classes
may seem rather simple at first sight, stating that every ùúî-word belongs to
some language built from equivalence classes. It is reminiscent of the
decomposition of an ùúî-regular ùúî
language into parts of the form ùëàùëâ
for regular languages ùëà, ùëâ . Note, though, that
this lemma makes a stronger statement about all ùúî-words. Moreover, one
may be inclined to prove this via a standard decomposition of an infinite
run of A which must necessarily revisit some state ùëû infinitely often.
However, since the lemma makes
112
5 Automata on Infinite Words

an assertion about all words, not just those in ùêø(A), such runs need not
exist. And even if they exist, they would only yield a statement about the
possibility to reach ùë£ùëñ
that state from itself, i.e. that ùëû √ê
‚Üí ùëû for infinitely many ùë£ùëñ . This is not sufficient to
finally show that ùêø(A) can be written as a union of languages of the form
ùëà, ùëâ for some regular languages ùëà, ùëâ .
Lemma 5.31 Let ùë§ ‚àà Œ£ùúî . There exist equivalence classes ùëà, ùëâ of ‚àº such
that ùúî
ùë§ ‚àà ùëà ùëâ
.
Proof Clearly, each non-empty finite word ùë¢ ‚àà Œ£+ lies in some class,
namely its own class: ùë¢ ‚àà [ùë¢]. Now let ùë§ = ùëé ùëé . . .
0
1
be given. We consider the following colouring
N
ùëì
‚à∂ ( ) ‚Üí Œ£+/‚àº defined by ùëì ({ùëñ, ùëó }) ‚à∂= [ùëé . . . ùëé
ùëñ
ùëó
2

‚àí1] assuming, w.l.o.g., ùëñ < ùëó .
According to Thm. 5.26, there is some equivalence class ùëâ ‚àà Œ£+/‚àº and an
infinite ùêº ‚äÜ N such that ùëì ({ùëñ, ùëó }) = ùëâ for all ùëñ, ùëó ‚àà ùêº. Let ùëñ , ùëñ , ùëñ , . . .
0
1
2
be an enumeration of
ùêº in ascending order, i.e. ùëñ0 < ùëñ1 < . . . W.l.o.g. we can assume ùëñ0 > 0
because any infinite subsequence of ùêº is also sufficient for the rest of this
argument.
Clearly, we have ùë§ = ùëé . . . ùëé
ùëé
. . . ùëé
ùëé
. . .
0
ùëñ
ùëñ
ùëñ
ùëñ
and theref ore

0 ‚àí1
0
1 ‚àí1
1
ùë§ ‚àà [ùëé
. . . ùëé
. . . ùëé
. . . ùëé
. . . ùëé
. . .
0
ùëñ
[ùëéùëñ
ùëñ
[ùëéùëñ
ùëñ
[ùëéùëñ
ùëñ
0 ‚àí1 ]
0

1 ‚àí1 ]
1
2 ‚àí1 ]
2
3 ‚àí1 ]
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùëà
ùëâ
ùëâ
ùëâ
which determines a class ùëà in addition to the class ùëâ obtained above, and
shows that ùúî
ùë§ ‚àà ùëàùëâ
.
‚óª
The essential combined statement of these three lemmas is the following:
take an NBA A over some alphabet Œ£, and its associated equivalence
relation ‚àº on Œ£+.
ùúî
Then Œ£ ùúî is partitioned into segments of the form ùëàùëâ

for equivalence classes ùëà, ùëâ .
Moreover, the borderline between ùêø(A) and ùêø(A) runs along the edges of
such segments. Hence, both are unions of such segments, and finiteness of
the index of ‚àº
even guarantees that they are finite unions. This allows us to prove
complementation closure of the class of NBA-recognisable languag es.
Theorem 5.32 For every NBA A of size ùëõ there is an NBA B s.t. ùêø(B) =
ùêø(A) and 3
O(ùëõ )
‚à£B‚à£ = 2
.
Proof Suppose A is given. It induces the equivalence relation ‚àº and its
corresponding classes as studied above. We now claim that
ùúî
ùúî
ùêø (A)
= ‚ãÉ{ùëàùëâ
‚à£ ùëà , ùëâ ‚àà Œ£+/‚àº and ùëàùëâ
‚à© ùêø(A) = ‚àÖ} .
(5.2)
It should be clear that ùêø(A) then is ùúî-regular as a finite union of languages
of ùúî
the form ùëàùëâ

for languages ùëà, ùëâ which are regular according to Lemma 5.28.
Finiteness of this union is a consequence of Lemma 5.27 (b) stating that
there are 2
ùëõ
only finitely many equivalence classes, specifically at most 3
many, i.e. at most
2
32ùëõ many pairs of them. Using standard constructions for the union,
concatenation and ùúî-iteration on NFA (cf. Lemma 5.9, 5.10 and 5.11), we
obtain an NBA of size 2
3
3
O(ùëõ )
O(ùëõ )
32ùëõ ‚ãÖ 2 ‚ãÖ 2
= 2
for the expression in (5.2) above.
5.5 Complementation Closure
113
It remains to be seen that (5.2) is true. "‚äÜ" Suppose that ùë§ ‚àà ùêø(A).
According ùúî
to Lemma 5.31 there are equivalence classes ùëà, ùëâ s.t. ùë§ ‚àà ùëàùëâ

. According to
ùúî
ùúî
Lemma 5.30 we have ùëàùëâ
‚äÜ ùêø(A) and therefore ùëàùëâ
‚à© ùêø(A) = ‚àÖ.
ùúî
"‚äá" It suffices to show that ùëàùëâ
‚äÜ ùêø(A) for any pair of equivalence classes
ùúî
ùëà , ùëâ such that ùëàùëâ
‚à© ùêø(A) = ‚àÖ. Let ùëà, ùëâ be given with this property. Clearly, if
ùúî
ùëàùëâ
= ‚àÖ then the statement trivially holds true. Suppose therefore that there is
some ùúî
ùë§ ‚àà ùëàùëâ
and assume, for the sake of contradiction, that ùë§ /
‚àà ùêø(A), i.e. ùë§ ‚àà ùêø(A).
ùúî

According to Lemma 5.29, we then have ùëàùëâ
‚äÜ ùêø(A) contradicting the assumption
ùúî
ùúî
that ùëàùëâ
‚â† ‚àÖ and ùëàùëâ
‚äÜ ùêø (A).
‚óª
Example 5.33 Reconsider the language ùêø3 of all words over {ùëé, ùëè} that
contain finitely many symbols ùëè only, recognised for example by the 2-state
NBA A3 shown F
‚Ä≤
in Ex. 5.21. There are eight languages ùêøùëû,ùëû‚Ä≤ , resp. ùêø
‚àà {0, 1} as follows.
ùëû , ùëû‚Ä≤
for ùëû, ùëû
For brevity, we write ùêøùëûùëû‚Ä≤ instead of ùêøùëû,ùëû‚Ä≤ etc.
+
F
ùêø
ùêø

00
= (ùëé + ùëè)
= ‚àÖ
00
‚àó
+
F
ùêø
ùëé
ùêø
01
= (ùëé + ùëè)
= ùêø
01
01
F
ùêø 10 = ‚àÖ
ùêø
= ‚àÖ
10

+
F
ùêø
ùêø
11
= ùëé
=
ùêø
11
11
Note that only two of them are non-trivial, namely ùêø01 and ùêø11. Their
complements are as follows.
‚àó
‚àó
‚àó
ùêø
ùëè
ùêø
ùëè
01

‚à∂= (ùëé + ùëè)
11
‚à∂= (ùëé + ùëè)
(ùëé + ùëè )
Without the observation on the triviality of some of these languages, i.e.
them either
+
being ‚àÖ or {ùëé, ùëè} , we would have to consider 28 combinations of
intersections of F
F
these, namely one for each choice of either ùêø ùë• ùë¶ or ùêø ùë•ùë¶ , resp. ùêø ùë• ùë¶ or ùêø
ùë•ùë¶ . However, here we only need to consider four combinations.
+
ùêø 01 ‚à© ùêø11 = ùëé = [ùëé]
‚àó
‚àó
ùêø
ùëè
ùëé
01 ‚à© ùêø11
= (ùëé + ùëè)

(ùëé + ùëè)
= [ùëèùëé]
ùêø 01 ‚à© ùêø11 = ‚àÖ
‚àó
ùêø
ùëè
01 ‚à© ùêø11
= (ùëé + ùëè)
= [ùëè]
ùúî
Note that ùëàùëâ
‚à© ùêø3 = ‚àÖ for ùëà, ùëâ ‚àà {[ùëé], [ùëèùëé], [ùëè]} iff ùëâ = [ùëè] or ùëâ = [ùëèùëé]. We
therefore have
ùúî
ùúî
ùúî
ùúî
ùúî
ùúî
ùêø 3 = [ùëé][ùëè]

‚à™ [ùëé][ùëèùëé]
‚à™ [ùëè][ùëè]
‚à™ [ùëè][ùëèùëé]
‚à™ [ùëèùëé][ùëè]
‚à™ [ùëèùëé][ùëèùëé]
ùúî
ùúî
= [ùëè]
‚à™ [ùëèùëé]
.
because [ùëé][ùëè] ‚äÜ [ùëè], [ùëé][ùëèùëé] ‚äÜ [ùëèùëé], [ùëè][ùëèùëé] ‚äÜ [ùëèùëé] and [ùëèùëé][ùëè] ‚äÜ
[ùëè].
114
5 Automata on Infinite Words
‚àó
ùúî
According to this, ùêø
ùëè
3 consists of all word of the form ((ùëé + ùëè)
)

or ((ùëé +
‚àó
‚àó
ùúî
ùëè) ùëè(ùëé + ùëè) ùëé)
. Clearly, both contain infinitely many symbols ùëè, and it is even the
‚àó
‚àó
ùúî
‚àó
ùúî
‚àó
ùúî
case that ((ùëé + ùëè) ùëè(ùëé + ùëè) ùëé)
‚äÜ ((ùëé + ùëè) ùëè)
. Hence, ùêø
ùëè
3 = ((ùëé + ùëè)
)
, and

this is indeed pretty much the simplest ùúî-regular expression for the
complement of the language of all infinite words that contain finitely many
symbols ùëè only.
5.6 Monadic Second-Order Logic on Infinite Words
Remember that effective complementation of NFA (via DFA) was the key to
establishing decidability of MSO over finite words. Now we are in a similar
situation with respect to infinite words, i.e. we have an automaton model in
the form of NBA with effective procedures like complementation, that can
serve as the basis for decision procedures of logics interpreted over infinite
words.
We are mainly interested in Monadic Second-Order Logic (MSO) again. Its
syntax is the same as that of MSO over finite words:
ùúë
‚à∂‚à∂= ùë• < ùë¶ ‚à£ ùëã (ùë•) ‚à£ ùëé(ùë•) ‚à£ ùúë1 ‚à® ùúë2 ‚à£ ¬¨ùúë ‚à£ ‚àÉùë• ùúë ‚à£ ‚àÉ ùëã ùúë
where ùëé ‚àà Œ£, ùë•, ùë¶ ‚àà V1 are first-order variables, and ùëã ‚àà V2 is a second-
order variable.
Syntactic considerations like formula size, further operators as
abbreviations etc.
apply here as w ell.
Given a word ùë§ ‚àà Œ£ ùúî, a matching variable assignment is an ùêº ‚à∂ (V1 ‚Üí N)
‚à™ (V2 ‚Üí
2N) assigning arbitrary positions in ùë§ and sets thereof to the first-,
respectively second-order variables in an MSO formula. The satisfaction of
an MSO formula ùúë
by a word ùë§ and an assignment ùêº, written ùë§, ùêº ‚äß ùúë, is defined in exactly the
same way as for MSO over finite w ords.

Example 5.34 The difference in interpretation between finite and infinite
words is best revealed by the formula ‚àÉùë• ‚àÄùë¶ ùë¶ ‚â§ ùë• which is not only
satisfiable but in fact valid over finite words, but unsatisfiable over infinite
w ords.
Likewise, ùúë ‚à∂= ‚àÄùë• ‚àÉùë¶.ùë¶ ‚â• ùë• ‚àß ùëé(ùë¶) states that the underlying word has
infinitely ùúî
many symbols ùëé, i.e. we have ùêø(ùúë) = (Œ£‚àóùëé) . When interpreted over finite
words it is not unsatisfiable but it says nothing about infinite occurrences
which of course cannot happen on finite words anyway. There it only
describes the language Œ£‚àóùëé .
Formulas like
ùë• < ùë¶ ‚àß ‚àÉùëã . ùëã (ùë•) ‚àß ¬¨ùëã (ùë¶) ‚àß ‚àÄùëß. ùëã (ùëß) ‚Üî ¬¨ùëã ( succ(ùëß ))
however, express the same property - the distance between the positions ùë•
and ùë¶ is odd - regardless of whether they are interpreted over finite or
infinite words.
Henceforth, we will only speak of MSO instead of "MSO over infinite
words"
since this and the following chapters in Part II are concerned with infinite
words, and MSO over finite words will play no active role here anymore.
5.6 Monadic Second-Order Logic on Infinite Words
115
Decidability of MSO follows the same line as in the case of finite words. We
first observe that first-order variables can be eliminated by replacing them
with suitable second-order variables and normalising formulas to be built
from atomic formulas of the form sing(ùëã), ùëã ‚äÜ ùëå , ùëã ‚äÜ ùëé and ùëã < ùëå .
Next, a word ùë§ ‚àà Œ£ ùúî together with an interpretation of ùëò second-order
variables ùëò

ùúî
ùëã , . . . , ùëã
1
ùëò can again be regarded as a word ùë§ ùêº ‚àà (Œ£ √ó ({0, 1}) )
. It is then possible
to construct NBA for MSO formulas in the following sense.
Lemma 5.35 Let ùúë(ùëã , . . . , ùëã
1
ùëò ) be a normalised MSO formula for some ùëò ‚â• 0 . It
ùëò
is possible to effectively construct an NBA Aùúë over Œ£ √ó {0, 1} such that ùêø(Aùúë
) =
{ùë§ ùêº ‚à£ ùë§, ùêº ‚äß ùúë} .
The proof is left as an exercise; it is done in exactly the same way as the
translation from MSO over finite words into NFA. Here we rely on Thm.
5.32 to effectively handle negation in formulas by automata
complementation.
Lemma 5.35 states the existence of an effective translation from MSO into
NBA.
The converse translation, showing that ùúî-regular languages are MSO-
definable, is equally effective. It is done in the same way as for MSO over
finite words (cf.
Thm. 2.10). Details are left as an exercise.

Theorem 5.36 A language is MSO-definable iff it is ùúî -regular.
Decidability of MSO over infinite words is then obtained by combining
Thm. 5.15
and Lemma 5.35.
Theorem 5.37 The satisfiability problem for MSO is decidable.
It should be clear that MSO over infinite words cannot be significantly
easier to decide than MSO over finite words. Satisfiability of MSO over
finite words can easily be reduced to that over infinite words. Remember
that the non-elementary complexity of the satisfiability problem stems from
the depth of alternations between existential quantification and negations in
a formula. The translation presented in the proof of the following theorem
does not decrease this measure. Hence, satisfiability of MSO
over infinite words is also non-elementary.
Lemma 5.38 For every MSO formula ùúë over finite words there is an equi-
satisfiable
‚Ä≤
‚Ä≤
MSO formula ùúë over infinite words such that ‚à£ùúë ‚à£ = O(‚à£ùúë‚à£) .
Proof Let ùúë ‚àà MSO over finite words and ùëß be a first-order variable not
used in ùúë.
The trick is to let ùúì ask for some "maximal" position in an underlying word
in the sense that everything that ùúë demands, needs to take place before that
position. This can be done using quantifier relativisation. Let ùúì ‚à∂= ‚àÉùëß.ùúë‚Üìùëß
where
(‚àÉùë• ùúí)‚Üì
‚à∂= ‚àÉùë•.ùë• < ùëß ‚àß ùúí‚Üì

,
(‚àÉùëã ùúí)‚Üì
‚à∂= ‚àÉùëã .(‚àÄùë•. ùëã (ùë•) ‚Üí ùë• < ùëß) ‚àß ùúí‚Üì
ùëß
ùëß
ùëß
ùëß
and ‚ãÖ‚Üìùëß distributes over Boolean operators and does not change atomic
formulas.
Correctness of this construction is easily seen. Satisfiability of ùúë implies that
of
‚Ä≤
ùúë : for every ùë§ ‚àà Œ£‚àó and matching interpretation with ùë§, ùêº ‚äß ùúë we have ùë§ùë£,
ùêº[ùëß ‚Ü¶
‚Ä≤
‚à£ùë§‚à£] ‚äß ùúë for any ùë£ ‚àà Œ£ ùúî .
116
5 Automata on Infinite Words
The other direction holds because for every ùë§ = ùëé ùëé . . .
0
1

‚àà Œ£ ùúî and matching
‚Ä≤
‚Ä≤
‚Ä≤
interpretation ùêº such that ùë§, ùêº ‚äß ùúë we have ùëé . . . ùëé
, ùêº
0
‚äß ùúë
ùêº (ùëß)‚àí1
where ùêº agrees
‚Ä≤
with ùêº on the first-order variables and ùêº (ùëã) ‚à∂= ùêº(ùëã) ‚à© {0, . . . , ùêº(ùëß) ‚àí 1} for
all second-order variables ùëã .
‚óª
Thus, the coarse estimation that deciding an MSO formula is roughly ùëò -
fold exponential in the depths ùëò of alternations between existential
quantifications and negation, resp. universal quantifications, is true here as
well, both in terms of upper and lower bounds. The upper bound is obtained
by inspection of the decision procedure; as in the case of finite words, every
negation requires an exponential blowup.
Note that here, complementation is more difficult, albeit only in terms of a
higher polynomial degree inside an exponential.
Bibliographic Notes

B √ºchi automata were introduced - as the name suggests - by B √ºchi in
order to obtain decidability of the logic often known as S1S, Second-Order
Logic of One Successor [B √ºc62]. It can be understood as the variant of
WS1S, as introduced in Sect. 2.4, where the restriction that second-order
variables are interpreted as finite sets only, is lifted. Hence, an S1S formula
is interpreted over the natural numbers with the ordering relation as the
only binary predicate and arbitrary unary predicates, with first-order
quantifiers ranging over arbitrary natural numbers and second-order
quantifiers over arbitrary sets of natural numbers. This is easily seen to be
just what MSO over infinite words does where the letters in each position
can be seen as a combined interpretation of all unary predicates.
B √ºchi automata are such a natural, intuitive and computationally feasible
model of computation for properties of infinite words that their prevalence
in the literature is unsurprising. See for instance the handbook articles by
Thomas [Tho97, Tho90]
for an introduction into B √ºchi automata with a focus on their use in logical
decision procedures.
B √ºchi automata have also proved to be a valuable tool in program
verification, by providing - just as they do for MSO - a computational
counterpart for denotational specification formalisms like Linear-Time
Temporal Logic (LTL) [Pnu77]. This has been discovered and explored
widely by Vardi and others [VW94, Var96]. The connection between B √ºchi
automata and logics for infinite words is robust in the sense that extensions
of the basic logic LTL can either be handled with B √ºchi automata directly,
for instance general fixpoint quantifiers [BB89, Kai97], or B √ºchi automata
can be extended elegantly whilst retaining similar algorithmic properties, to
then capture the logic at hand. This is the case for the two-way extension
for example, that can move in both directions on an input word. It
corresponds nicely to temporal logics with past operators [Var88]. A
historical overview of the development in logics for program specification
and verification, together with its tight link to automata on infinite words, is
given by Vardi [Var08].
Exercises for Chapter 5

117
The complementation problem for B √ºchi automata is, notably, the
bottleneck for applications in which complementation is required in some
form or other. The proof presented here is based on B √ºchi's work [B √ºc62],
used to obtain decidability of S1S, making use of Thm. 5.26 - the
combinatorial result known as Ramsey's Theorem [Ram30]. It is worth
noting, though, that this is Ramsey's Theorem for infinite graphs, and the
term "Ramsey's Theorem" is also used for a combinatorial result on finite
graphs which is not of significant relevance to the work on automata and
logics presented here. This is why we simply refer to the result used by B
√ºchi as "Ramsey's Theorem".
Other applications of B √ºchi complementation with more practical
relevance have created a demand for better efficiency, and this has led to a
variety of contributions on the complementation problem. McNaughton
showed that ùúî-regular languages can be recognised by deterministic
automata using a richer acceptance condition
[McN66], see the following chapter, from which complementation closure
can be derived. Safra provided a solution using determinisation [Saf88]
which is discussed in detail in a later chapter. Klarlund found a procedure
that is based not on Ramsey's Theorem as the combinatorial backbone, but
on progress measures which are sophisticated counters used to track
combinations of infinite and finite behaviour
[Kla91]. Kupferman and Vardi went through alternating automata on
infinite words, based on work by Muller and Schupp [MS87, MSS88] and to
be studied in a later chapter, to obtain a complementation procedure
[KV01].
It is fair to summarise the situation as follows: complementation of B √ºchi
automata remains to be an inherently intricate problem, and no single
suggestion of a solution is commonly accepted to yield a satisfactory
procedure in practice.
The combinatorial difficulty is also made apparent by studying lower
bounds on the size of B √ºchi automata for the complements of given ùúî-

regular languages.
Michel was the first to provide an example which shows that B √ºchi
complementation ùëõ
requires a greater blowup of Œ©(ùëõ!) than the Œ©(2 )-blowup for NFA [Mic88].
A more detailed discussion on the history and state-of-the-art in the
asymptotic complexities of procedures for B √ºchi complementation is given
by Schewe [Sch09a], following an equal-directed earlier study by Friedgut
et al. [FKV06].
Exercises
Exercise 43 Let Œ£ = {0, 1}. Show that Œ£‚àó is countable but Œ£ùúî is
uncountable. Hint: Construct an injective function ùëì ‚à∂ [0, 1) ‚Üí Œ£ ùúî where [0,
1) = {ùë• ‚àà R ‚à£ 0 ‚â§ ùë• < 1}.
Simply for the purpose of interest and insight, try to construct ùëì such that it
is bijective. This is a bit harder, though.
Exercise 44
ùúî
ùúî
Let ùë¢ ‚àà Œ£+. Define ùë¢
formally in the form (ùë¢ )(ùëñ) = . . . for ùëñ ‚àà N.
Exercise 45
ùúî
Let ùëà ‚äÜ Œ£‚àó. Is it the case that every ùë§ ‚àà ùëà
has a unique representation
as ùë§ = ùë¢ ùë¢ . . .

0 1
with ùë¢ùëñ ‚àà ùëà for all ùëñ ‚àà N? If so, prove it. If not, work out a non-trivial
118
5 Automata on Infinite Words
property on such languages of finite words such that the proposition
becomes true at least for such languages ùëà that satisfy this property.
Exercise 46 Construct NBA for the following languages.
ùúî
a) {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚àÄùëõ ‚â• 0 ‚à∂ ùë§(3ùëõ) = ùëé}.
ùúî
b) {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚àÄùëõ ‚â• 0 ‚à∂ ùë§(ùëõ) = ùëé iff ùëõ ‚â° 0 mod 3}.
c) The set of all words over {ùëé, ùëè, ùëê} s.t. between every two positions that
carry a ùëè and have no further ùëè in between, there is an odd number of
occurrences of the symbol ùëê.
d) The set of all words over Œ£ùëò = [ùëò ] s.t. the largest number that occurs
infinitely often in this word is even.
e) The set of all ùúî-words over Œ£ that contain at least one occurrence of a
given word ùë¢ ‚àà Œ£+ .
f) The set of all ùúî-words over Œ£ that contain infinitely many occurrences of a
given word ùë¢ ‚àà Œ£+ .

g) The set of all ùúî-words over Œ£ that contain only finitely many occurrences
of a given word ùë¢ ‚àà Œ£+ .
Exercise 47 Formally define NBA with possibly more than one initial state
and show that they are equi-expressive to the model of NBA with a single
initial state.
Exercise 48 Let Œ£ = {+, ‚àí, 0, 1, .}. Note that an ùúî-word ùë§ over Œ£ that is of
the form
‚àó
ùúî
(+ ‚à™ ‚àí)(0 + 1(0 ‚à™ 1) ).(0 ‚à™ 1)
naturally represents a real number ùë•ùë§ as follows.
Let ùë§ = ùë†ùëë . . . ùëë . ùëì ùëì ùëì . . .
ùëõ
0
0 1 2
. Then
ùëõ
‚àû
‚Ä≤
ùëñ
‚àí(ùëñ+1)
ùë•

ùëë
ùëì
ùë§
‚à∂= ùë† ‚ãÖ ((‚àë
ùëñ ‚ãÖ 2 ) + (‚àë
ùëñ ‚ãÖ 2
) )
ùëñ=0
ùëñ=0
‚Ä≤
‚Ä≤
where ùë† = 1 if ùë† = + and ùë† = ‚àí1 if ùë† = ‚àí.
ùúî
For example,
3
ùë§ = ‚àí1010.1(110)
represents ‚àí10 13 because 13 = 1 +
. The
14
14

2
7
ùúî
contribution of the periodic part (110)
with its first digit stating the contribution
of 1 is 3 as the following calculation sho ws.
4
7
1
1
1
1
1
1
1 ‚ãÖ
+ 1 ‚ãÖ
+ 0 ‚ãÖ
+ 1 ‚ãÖ
+ 1 ‚ãÖ
+ 0 ‚ãÖ

+ 1 ‚ãÖ . . . =
4
8
16
32
64
128
‚àû
‚àû
1
3
3
3
1
1 ùëõ
8
3
+
+
+ . . .

= ‚àë 3 ‚ãÖ
= 3 ‚ãÖ ‚àë( )
= 3 ‚ãÖ
= 3 ‚ãÖ 8
=
8
64
512
23ùëõ
8
1
7 ‚ãÖ 8
7
ùëñ=1
ùëñ=1
1 ‚àí 8
Likewise, an ùúî-word over Œ£ùëò for some ùëò ‚â• 1 represents a ùëò -tuple of real
numbers; the representation of the ùëñ-th number in this tuple is given in the ùëñ-
th track of this ùëò
ùëò
‚àó

ùëò
ùëò
ùúî
word. We will only consider words of the form (+ ‚à™ ‚àí) ((0 ‚à™ 1) ) (.) ((0 ‚à™
1) ) , though, i.e. those where the decimal points are aligned (at the expense
of possible leading zeros in any of the tracks). Note that a language of such
ùëò -track words can be seen as a ùëò -ary relation on the reals.
Exercises for Chapter 5
119
a) Construct an NBA A2 add over Œ£3 that accepts a word iff it represents a
triple (ùë•, ùë¶, ùëß) s.t. ùë• + ùë¶ = ùëß. Hint: Consider the case of ùë§ starting with (+,
+, +) first.
Then determine which other tuples of sign symbols can occur at all, and
make use of equivalences like ùë• ‚àí ùë¶ = ùëß iff ùë• = ùë¶ + ùëß.
ùëò
b) Let ùëò > 2. Construct NBA Aadd over Œ£ùëò+1 that recognise the relation ùëò
{(ùë• , . . . , ùë• , ùë¶
ùë•
1
ùëò
) ‚à£ ùë¶ = ‚àëùëñ=1 ùëñ} in generalisation of part (a). Hint: Use product and
projection constructions on NBA.
ùëõ

c) Let ùëõ ‚â• 0. Construct an NBA Ashift that recognises the relation {(ùë•, ùë¶) ‚à£
ùë¶ =
ùëõ
ùëõ
ùë• ‚ãÖ 2 }. Hint: Multiplication of a number in binary representation by 2 is
simply realised by shifting the decimal point ùëõ positions to the left.
ùëù
d) Let ùëù ‚àà Z. Construct an NBA Aimult that recognises the relation {(ùë•, ùë¶) ‚à£
ùë¶ =
ùëù ‚ãÖ ùë•}. Hint: This can be realised by employing the construction in part (c)
several times. The key is to consider the binary representation of ùëù. In other
words, ùëù can be decomposed into a sum of powers of 2. By distributivity of
multiplication over addition, multiplication by ùëù can be realised by
successiv e additions of multiples of ùëù by powers of 2.
ùëû
e) Let ùëû ‚àà Q. Construct an NBA Armult that recognises the relation {(ùë•, ùë¶)
‚à£ ùë¶ =
ùëù
ùëû ‚ãÖ ùë•}. Hint: Each ùëû can be written as
with ùëù ‚àà Z and ùëõ ‚àà N ‚àñ {0}. Now note
ùëõ
that ùë¶ = ùëù ‚ãÖ ùë• iff ùëõ ‚ãÖ ùë¶ = ùëù ‚ãÖ ùë•. By using a product of two NBA from part (d)
it is ùëõ

possible to recognise the relation of quadruples (ùë•, ùë¶, ùëùùë•, ùëõùë¶). This
automaton then only needs to be intersected with one that checks for
equality in the third and fourth track, and by alphabet projection to the first
two tracks, we obtain an NBA for the target relation.
Exercise 49 Prove Lemma 5.9.
Exercise 50 Prove Lemma 5.10.
Exercise 51
a) Prove Lemma 5.18.
b) Let ‚Ñé ‚à∂ Œ£ ‚Üí Œî‚àó be a morphism that is potentially deleting. Provide a
well-defined notion of homomorphic image of a Œ£-language as a Œî-
language that preserves ùúî-regularity.
Exercise 52 Prove part (a) of Lemma 5.27, and show that ‚àº is indeed an
equivalence relation.
Exercise 53
‚Ä≤
Let A be some NBA with state set ùëÑ and ùëû, ùëû ‚àà ùëÑ. Construct an NFA F
for the language ùêøùëû,ùëû‚Ä≤ whose size does not exceed 2 ‚ãÖ ‚à£ùëÑ‚à£, cf. Lemma 5.28.
Exercise 54 Construct NBA for the complements of the following
languages, using B √ºchi's complementation construction along the lines of
Ex. 5.33.
ùúî
a) ùêø1 = (ùëéùëè)
over {ùëé, ùëè},
ùúî

b) ùêø2 = (ùëé(ùëé + ùëè))
over {ùëé, ùëè},
ùúî
c) ùêø3 = {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëè = ‚àû},
‚àó
ùúî
d) ùêø
ùëé ùëé
4 = (ùëé + ùëè)
(ùëé + ùëè)
over {ùëé, ùëè}.
Hint: Start by constructing NBA for these languages that lead to a smallest
number F
of languages ùêøùëû,ùëû‚Ä≤ , resp. ùêøùëû,ùëû‚Ä≤ .
120
5 Automata on Infinite Words
Exercise 55 Write down MSO formulas for the four languages specified in
Exc. 54.
Exercise 56 Prove Lemma 5.35.
Exercise 57 Prove the direction from right-to-left in Thm. 5.36.

Chapter 6
Acceptance Conditions
The acceptance condition leading to the notion of B √ºchi automaton -
traversing certain states infinitely many times - is a natural extension of the
acceptance of finite words by reaching an accepting state at the end of run.
It is by no means the only way to make a distinction between accepting and
non-accepting infinite runs.
In this chapter we study further acceptance conditions and the
expressiveness of the automata models that arise from these. As it turns out,
all of them give rise to the same class of languages, i.e. the so-called Rabin,
Streett, parity and Muller automata do not exceed ùúî-regularity in expressive
power. However, B √ºchi acceptance stands out as a weaker one in the sense
that the others allow determinisation which is studied in the following
chapter.
Moreover, remember that one of the reasons for why NBA cannot easily be
complemented via DBA is the fact that the B √ºchi acceptance condition is
not self-dual, i.e. the complement of a B √ºchi condition is not a B √ºchi
condition itself.
As we will see, there is sufficient self-duality in this respect amongst the
other acceptance conditions. At the end, we explicitly study the complement
of a B √ºchi acceptance condition - visiting designated states only finitely
often - as another separate acceptance condition leading to yet another
automaton model operating on infinite words. This one will turn out to be
strictly weaker in expressiveness, though.
6.1 Rabin- and Streett-Automata

Recall that, for an infinite sequence ùúå = ùëû , ùëû , . . .
0
1
of elements from a finite set, we
write Inf (ùúå) to denote the set of such elements that occur infinitely often in
ùúå, i.e.
Inf (ùúå) = {ùëû ‚à£ ‚àÄùëñ ‚àà N ‚àÉ ùëó ‚â• ùëñ s.t. ùëû ùëó = ùëû}. This was used in Def. 5.7 for
instance to define acceptance by an NBA. The additional acceptance
conditions discussed here and below will also refer to Inf (ùúå) for runs ùúå. The
reason simply is that any finitary condition like "reaching a designated
state after the first 1000 letters" can easily be encoded in the state set and
transition relation. Hence, the acceptance conditions should only be
concerned with infinite occurrences of states in a run.
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
121
M. Hofmann and M. Lange, Automata Theory and Logic,
https://doi.org/10.1007/978-3-662-72154-4_6
122
6 Acceptance Conditions
ùëûùëè
ùëè
ùëè

ùëé
ùëé
ùëûùëé
ùëê
ùëè
ùëê
ùëé
ùëûùëê
ùëê
Fig. 6.1 Transition function of a finite automaton that uses its state set to
only remember the letter from {ùëé, ùëè, ùëê} that has just been read.
Definition 6.1 A nondeterministic Rabin automaton (NRA) is an A = (ùëÑ, Œ£,
ùëû , ùõø, ùêº
F ) where ùëÑ, Œ£, ùëû , ùõø
ùêº
are the states, alphabet, initial state and transition relation just as in an
NBA. The acceptance condition is F = {(ùê∫ , ùêπ
, ùêπ
1
1), . . . , (ùê∫ ùëò
ùëò )}

where
ùê∫ , ùêπ
ùëñ
ùëñ
‚äÜ ùëÑ for some ùëò and all ùëñ = 1, . . . , ùëò .
As usual, a deterministic Rabin automaton (DRA) is an NRA such that ‚à£ùõø(ùëû,
ùëé)‚à£ ‚â§
1 for all ùëû ‚àà ùëÑ and ùëé ‚àà Œ£. Note that determinism is purely a property of
the transition function, not the acceptance condition.
A run of an NRA on a word ùë§ = ùëé ùëé . . .
0
1
is, as usual, an infinite sequence
ùúå = ùëû , ùëû , . . .
, ùëé
0
1
such that ùëû0 = ùëûùêº and ùëûùëñ+1 ‚àà ùõø(ùëûùëñ
ùëñ ) for all ùëñ ‚â• 0. It is accepting if
there is an ùëñ ‚àà {1, . . . , ùëò} such that Inf (ùúå) ‚à© ùê∫ùëñ ‚â† ‚àÖ and Inf (ùúå) ‚à© ùêπùëñ = ‚àÖ.
As before, we may sometimes denote a run on ùë§ as an alternating sequence
ùëû , ùëé , ùëû , ùëé , . . .

0
0
1
1
.
As usual, the language ùêø(A) of an NRA A is the set of all ùúî-words over Œ£
for which there is an accepting run. A language ùêø is called Rabin-
recognisable or NRA-recognisable if there is an NRA A such that ùêø(A) = ùêø.
DRA-recognisability is defined analogously .
The size of an NRA is measured, as with the other automata, as the size of
its state set: ‚à£A‚à£ ‚à∂= ‚à£ùëÑ‚à£. Note that this is not necessarily a complete
measure of the space needed to represent an NRA, notwithstanding the fact
that the transition function may be (quadratically) bigger than that. Here,
the acceptance condition F
may be unbounded in ‚à£ùëÑ‚à£, so we introduce a second measure. The index of
the NRA A = (ùëÑ, Œ£, ùëû , ùõø,
ùêº
F ) is ‚à£F ‚à£ .
Hence, Rabin automata syntactically differ from B √ºchi automata in that
their acceptance condition does not just designate a set of states that are to
be visited infinitely often. They provide several alternatives of pairs of state
sets with one component to be visited infinitely often, and the other one
consisting of states that, at the same time, must not be visited infinitely
often. Note that, for a so-called Rabin pair (ùê∫, ùêπ) from an NRA A's
acceptance condition and a run ùúå of A, we have Inf (ùúå) ‚à© ùê∫ ‚â† ‚àÖ iff some
state in ùê∫ is visited infinitely often, and Inf (ùúå) ‚à© ùêπ = ‚àÖ iff all states in ùêπ
are visited finitely often only.

Example 6.2 Let Œ£ = {ùëé, ùëè, ùëê} and consider the language ùêø ‚à∂= {ùë§ ‚àà Œ£ùúî ‚à£
‚à£ùë§‚à£ùëé =
‚àû ‚áí ‚à£ùë§‚à£ùëè = ‚àû}. The NRA in Fig. 6.1 simply remembers in its state what
the last
6.1 Rabin- and Streett-Automata
123
letter was that it read. The aim is to equip this automaton with a suitable
Rabin acceptance condition to turn it into an NRA accepting ùêø. For this, it
suffices to note that a word ùë§ belongs to ùêø iff ‚à£ùë§‚à£ùëé < ‚àû or ‚à£ùë§‚à£ùëè = ‚àû.
Hence, there are two possibilities for a word to be accepted: it contains
finitely many symbols ùëé or infinitely many symbols ùëè. This is captured
directly by two Rabin pairs, the former by ({ùëû , ùëû
ùëè
ùëê }, {ùëû ùëé }), the latter by ({ùëû ùëè }, ‚àÖ).
Hence, we have ùêø = ùêø(A) for the NRA A = ({ùëû , ùëû , ùëû
, ùõø ,
ùëé
ùëè
ùëê }, {ùëé , ùëè , ùëê}, ùëû ùëé
F )
where ùõø is as shown in Fig. 6.1 and F = {({ùëû , ùëû
ùëè
ùëê }, {ùëû ùëé }), ({ùëû ùëè }, ‚àÖ)}. A is in fact

even a DRA. Moreover, any of its states can be used as the initial state
because all three recognise the same language.
The fact that two states in an automaton operating on infinite words
recognise the same language does not mean that these can be collapsed into
a single state, as it is possible for NFA. It should be clear that no 1-state
NRA can recognise the language ùêø from the example above.
As with the B √ºchi condition whose lack of self-duality was mentioned
above, the Rabin acceptance condition also lacks (obvious) self-duality.
That is, the natural complement of the assertion "there is ùëñ such that Inf
(ùúå)‚à©ùê∫ùëñ ‚â† ‚àÖ and Inf (ùúå)‚à©ùêπùëñ = ‚àÖ"
is "for all ùëñ we have Inf (ùúå) ‚à© ùê∫ùëñ = ‚àÖ or Inf (ùúå) ‚à© ùêπùëñ ‚â† ‚àÖ." This can be
rephrased as
"for all ùëñ: if Inf (ùúå) ‚à© ùê∫ùëñ ‚â† ‚àÖ then Inf (ùúå) ‚à© ùêπùëñ ‚â† ‚àÖ."
First of all, it is unclear that this universal statement should be equivalent
to an existential one which the Rabin condition is. Later we will see that the
complement of a Rabin-recognisable language is also Rabin-recognisable,
but this generally involves a non-trivial blowup. Hence, it is possible to
rephrase "there is no ùëñ such
‚Ä≤
that Inf (ùúå) ‚à© ùê∫ùëñ ‚â† ‚àÖ and Inf (ùúå) ‚à© ùêπùëñ = ‚àÖ" as "there is ùëñ such that Inf (ùúå) ‚à©
ùê∫ ‚â† ‚àÖ
ùëñ
‚Ä≤
‚Ä≤
‚Ä≤
and Inf (ùúå) ‚à© ùêπ = ‚àÖ

, ùêπ )
ùëñ
" for a different set of Rabin pairs (ùê∫ùëñ
ùëñ
. In particular, when
the underlying NRA is in fact deterministic, we cannot simply invert the
acceptance condition in order to obtain a DRA for the complement
language. We can help ourselves, though, by simply introducing the
complement of a Rabin condition as an acceptance condition in its own
right.
Definition 6.3 A nondeterministic Streett automaton (NSA) is an A = (ùëÑ, Œ£,
ùëû , ùõø, ùêº
F ) just like an NRA. The notions of size, index and deterministic Street
automaton (DSA) are defined in the same way.
The only difference is in the interpretation of the acceptance condition F =
ùëÑ
ùëÑ
{(ùê∫ , ùêπ
, ùêπ
, ùëû
, . . .
1
1), . . . , (ùê∫ ùëò

ùëò )} ‚äÜ 2
√ó 2
as a Street-condition: a run ùúå = ùëû0
1
of
such an NSA is accepting if for all ùëñ = 1, . . . , ùëò we have that Inf (ùúå) ‚à© ùê∫ùëñ ‚â†
‚àÖ implies Inf (ùúå) ‚à© ùêπùëñ ‚â† ‚àÖ.
Again, the notions of language of an NSA, Streett-recognisability, etc. are
defined as usual.
Thus, the Streett-acceptance condition formalises dependencies of the form
that certain states need to be visited infinitely often if certain (other) states
are being visited infinitely often.
Example 6.4
ùúî
Reconsider the language ùêø = {ùë§ ‚àà {ùëé, ùëè, ùëê}
‚à£ ‚à£ùë§‚à£ùëé = ‚àû ‚áí ‚à£ùë§‚à£ùëè = ‚àû}
from Ex. 6.2. It is not only Rabin-recognisable but also Streett-recognisable
on the
124
6 Acceptance Conditions
basis of the same deterministic automaton shown in Fig. 6.1 that signals the
last seen letter in its state set. In particular, whenever it reads an ùëé it moves
to state ùëûùëé

from anywhere, and likewise for ùëè. Moreover, it moves out of state ùëûùëé, resp.
ùëûùëè upon reading a letter that is different to ùëé, resp. ùëè. Hence, it visits state
ùëûùëé infinitely often iff the word it reads contains infinitely many symbols ùëé
and likewise for ùëè. Then the condition in the definition of ùêø immediately
translates into a Streett-acceptance condition with a single Streett pair: F =
{({ùëûùëé}, {ùëûùëè})}.
A natural question to consider concerns the expressiveness of Rabin and
Streett automata in comparison to the class of ùúî-regular, i.e. B √ºchi-
recognisable languages.
It is not hard to see that Rabin- and Streett-recognisability is not weaker
than that.
Theorem 6.5 For every NBA A of size ùëõ there is an NRA, resp. NSA B of
size ùëõ and index 1 such that ùêø(B) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
). It is easy to see that the B √ºchi acceptance condition
ùêπ is equivalent to the Rabin-acceptance condition F = {(ùêπ, ‚àÖ)} and the
Streett-acceptance condition F = {(ùëÑ, ùêπ)}. Hence, ùêø(A) is recognisable by
an NRA or NSA with the same transition graph as A.
‚óª
The more interesting direction is the converse of this: are there non-regular
but Rabin- or Streett-recognisable languages, i.e. does the more elaborate
acceptance condition lead to greater expressiveness? The answer is no, but
we will continue to study further acceptance conditions including the so-
called Muller condition that the Rabin- and Streett conditions easily embed
into, and then show that these automata only recognise ùúî-regular
languages. This minimises the effort needed to study expressiveness, i.e. we
avoid comparing each two models of automata directly.

We do compare, though, the expressiveness of deterministic Rabin- and
Streett automata with each other because of the way that these conditions
have been introduced as dual ones.
Theorem 6.6 Let ùêø ‚äÜ Œ£ùúî . If ùêø is recognisable by a DRA, resp. DSA of size
ùëõ and index ùëò then Œ£ ùúî ‚àñ ùêø is recognisable by a DSA, resp. DRA of size ùëõ +
1 and index ùëò + 1 .
Proof This is based on the observation that a run ùúå is accepting w.r.t. the
Rabin-acceptance condition F iff it is rejecting w.r.t. the Streett-acceptance
condition F
for the very same F . The result then follows with the usual argument that
runs of deterministic automata on given words are unique. The blowup with
a possible extra state is needed in case the original DRA, resp. DSA is not
complete, i.e. there are words that do not have infinite runs. This can be
fixed with the usual trick of adding an extra state ùëû that acts as a trap for
those runs. When turning a DSA into a DRA for the complement language,
one extra Rabin pair ({ùëû}, ‚àÖ) is needed. When turning a DRA into a DSA,
the trap state ùëû needs to be added to every ùêπ in a Streett pair (ùê∫ , ùêπ ).
‚óª
Note that determinism is an important premise in this statement: one cannot
simply complement an NRA by declaring it to be an NSA. This fails because
NRA
6.2 Parity Automata
125
and NSA may have more than one run and thus complementation requires
the universal quantification over all runs to be rephrased as an existential
one. This is not possible without the aforementioned non-trivial blowup in
the state space.
6.2 Parity Automata

The lack of self-duality of each of the Rabin and Streett conditions, resp. the
fact that they are dual to each other, raises the question after the
construction of an acceptance condition that sits in-between the two and is
self-dual. This is what the parity condition, to be studied in this section, is
and does. It is more abstract than the two in the way that it is presented: it
does not directly make a requirement on the infinite occurrence of states.
Instead, each state gets assigned a natural number that we call its priority,
and then the parity condition makes an assertion on the infinite occurrence
of priorities.
6.2.1 Priorities for Acceptance and Rejection
Definition 6.7 Let Œ£ be an alphabet as usual. A nondeterministic parity
automaton (NPA) is an A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
, ùõø
ùêº
) where ùëÑ, Œ£, ùëûùêº
are as with NBA, NRA or NSA,
and the acceptance condition is given by the priority mapping Œ© ‚à∂ ùëÑ ‚Üí N
on states.
The size of an NPA is measured as the number of its states, as usual. The
index of A is ‚à£Œ©(ùëÑ)‚à£ where Œ©(ùëÑ) ‚à∂= {Œ©(ùëû) ‚à£ ùëû ‚àà ùëÑ}, i.e. the number of
different priorities assigned to its s tates.
For certain considerations on expressiveness, this measure is too coarse.
We therefore sometimes measure the index of an NPA as an interval, and say
that A is of index [ùëò , ùëö] for ùëò ‚â§ ùëö, if Œ©(ùëÑ) ‚äÜ [ùëò , ùëö] ‚à∂= {ùëò , . . . , ùëö}.
We use ‚â°
ùë¶

2 to denote equivalence modulo even/odd parity, i.e. ùë• ‚â°2
iff ùë• mod 2 =
ùë¶ mod 2 for ùë•, ùë¶ ‚àà N. A run ùúå = ùëû , ùëû , . . .
0
1
of the NPA A is accepting if max{Œ©(ùëû) ‚à£
ùëû ‚àà Inf (ùúå)} ‚â°2 0, i.e. it is e ven.
A deterministic parity automaton (DPA) is, as usual, an NPA with a
deterministic transition function.
The notions of language of an NPA, NPA-/DPA-recognisability, resp. -
definability are defined in the usual way.
Thus, NPA runs are accepting when the highest priority that is seen
infinitely often in the run is even. This seems arbitrary in two ways. The
reason for the fact that it is only the priorities that do or do not occur
infinitely often in a run that determine acceptance is as before: the effect of
a priority seen at some fixed ùëõ-th position in a run could easily be encoded
in the state space. Thus, the question is: why the largest, and why even?
There is in fact no particular reason for this convention. The expressiveness
of NPA models that accept through odd priorities or minimal ones is the
same. In fact, while there is general agreement in the literature that
evenness
126
6 Acceptance Conditions
should be associated with acceptance and consequently oddness with
rejection, one often sees NPA acceptance being defined by evenness of the
least priority seen infinitely often. As said before, this is purely a matter of

convention and makes no difference for the expressiveness. Sometimes,
these two variants of NPA are called max-parity and min-parity
respectively, but the only purpose of this distinction is to fix the definition of
acceptance. In this respect, we will be dealing with max-parity NPA
exclusively, and all the results can be transferred straightforwardly to min-
parity NPA.
Example 6.8 Let Œ£ = {ùëé, ùëè, ùëê}. Reconsider the language ùêø = {ùë§ ‚àà Œ£ùúî ‚à£
‚à£ùë§‚à£ùëé = ‚àû ‚áí
‚à£ùë§‚à£ùëè = ‚àû} of Ex. 6.2 above. The automaton shown in Fig. 6.1 that has
been equipped with a Rabin- and a Streett-condition in order to accept ùêø,
can also be equipped with a parity condition in order to accept ùêø .
The trick here is to note that the condition ‚à£ùë§‚à£ùëé = ‚àû ‚áí ‚à£ùë§‚à£ùëè = ‚àû can be
enforced by the automaton under consideration that remembers the last
seen letter in its state space, by signalling hierarchical values: seeing a ùëè is
obviously good in terms of this happening infinitely often because it makes
the condition satisfied. Seeing an ùëé
infinitely often is bad unless a ùëè is also seen infinitely often. Hence, it
should signal something good, i.e. an even value, when seeing a ùëè, and
something bad and less relevant, i.e. an odd and smaller value, when seeing
an ùëé. Finally, seeing a ùëê infinitely often is good for as long as no ùëé is seen
infinitely often. So seeing a letter ùëê should result in the signalling of a good
value that is even less relevant than the one for ùëé.
This leads to an NPA, in fact a DPA, for ùêø by equipping the automaton from
Fig. 6.2
with the parity acceptance condition Œ© ‚à∂ {ùëû , ùëé , ùëé
ùëé
ùëè
ùëê } ‚Üí [0, 2] where

Œ©(ùëûùëé) ‚à∂= 1 ,
Œ©(ùëûùëè) ‚à∂= 2 ,
Œ©(ùëûùëê) ‚à∂= 0 .
To see that this is correct, take a run ùúå = ùëû , ùëû
, ùëû
, . . .
ùë•
. . .
ùêº
ùë•
ùë•
on the word ùë§ = ùë•
0
1
0 1
and suppose that it is accepting, i.e. ùëö ‚à∂= max{Œ©(ùëû ùë• ) ‚à£ ùëñ ‚â• 0} is even.
Since ùëñ
Œ©({ùëû , ùëû , ùëû
ùëé
ùëè

ùëê }) = {0, 1, 2} there are only two possibilities.
‚Ä¢ Case ùëö = 2, i.e. ùëû
ùë§
ùëè ‚àà Inf ( ùúå) . Then ‚à£ùë§‚à£ ùëè = ‚àû and therefore
‚àà ùêø.
‚Ä¢ Case ùëö = 0, i.e. {ùëûùëê} = Inf (ùúå) because Œ©(ùëûùëé) > 0 and Œ©(ùëûùëè) > 0. But
then
‚àó
ùúî
‚à£ùë§‚à£
ùëê
ùëê = ‚àû and, moreover, ‚à£ùë§‚à£ùëé ‚â† ‚àû ‚â† ‚à£ùë§‚à£ùëè . Thus, ùë§ ‚àà (ùëé + ùëè + ùëê)
and, again,
ùë§ ‚àà ùêø.
The converse direction is shown in the same way. So we have that ùêø is
indeed recognisable by an NPA of index 3 or, more precisely, of index [0, 2].
Self-duality of the parity acceptance condition is a consequence of the fact
that max{Œ©(ùëû) ‚à£ ùëû ‚àà Inf (ùúå)} is unique for any run ùúå, and that it is even iff it
is not odd, and there is a simple way of transposing priorities to swap their
parity whilst keep their internal total order ing.
The next lemma formalises the intuitive idea that the absolute values of
states'

priorities are irrelevant; instead it is their relative ordering - being greater
or smaller
- and their parities - being even or odd - that is only relevant for
determining acceptance of a run.
6.2 Parity Automata
127
Lemma 6.9
‚Ä≤
A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
, ùõø, Œ©‚Ä≤
ùêº
) be an NPA and A = (ùëÑ, Œ£, ùëûùêº
) be an NPA
that differs from A at most in the priority assignment. Suppose we have
‚Ä≤
‚Ä≤
‚Ä≤
(i) Œ©(ùëû) ‚â§ Œ©(ùëû ) iff Œ©‚Ä≤(ùëû) ‚â§ Œ©‚Ä≤(ùëû ) for all ùëû, ùëû ‚àà ùëÑ , and (ii) Œ©(ùëû) ‚â°2 0 iff
Œ©‚Ä≤(ùëû) ‚â°2 0 for all ùëû ‚àà ùëÑ .
‚Ä≤
Then we have ùêø(A ) = ùêø(A) .

Proof
‚Ä≤
Suppose that ùúå is a run of A, resp. A on some word ùë§. We get that max{Œ©(ùëû) ‚à£
ùëû ‚àà Inf (ùúå)} is even iff max{Œ©‚Ä≤(ùëû) ‚à£ ùëû ‚àà Inf (ùúå)} is even; (i) ensures that it is
the same state ùëû ‚àà Inf (ùúå) that attains the maximal priority in the respective
set, and (ii) ensures that it is either even in both cases or odd in both. Thus,
an accepting run in
‚Ä≤
A is an accepting run in A and vice-versa.
‚óª
As a consequence, we can make some assumptions on the indices of NPA,
namely that the priorities are as small as possible, with the smallest being 0
or 1, and that they do not leave gaps. The formal proof, based on (possibly
multiple) applications of Lemma 6.9 is left as an exercise.
Corollary 6.10 Let ùêø ‚äÜ Œ£ùúî . Suppose that ùêø = ùêø(A) for an NPA A = (ùëÑ, Œ£,
ùëû , ùõø, Œ©
ùêº
)
‚Ä≤
‚Ä≤
with Œ© ‚à∂ ùëÑ ‚Üí [ùëò , ùëö] . Then ùêø = ùêø(A ) where A = (ùëÑ, Œ£, ùëû , ùõø, Œ©‚Ä≤
ùêº
) such that

Œ©‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚à∂ ùëÑ ‚Üí [ùëò , ùëö ] for some ùëò , ùëö ‚àà N , and the following two pr operties are
satisfied.
‚Ä≤
a) ùëò ‚àà {0, 1} ,
‚Ä≤
‚Ä≤
b) for every ùëù ‚àà [ùëò , ùëö ] there is some ùëû ‚àà ùëÑ such that Œ©‚Ä≤(ùëû) = ùëù .
It should be clear with Lemma 6.9 that shifting all priorities uniformly by
an even amount does not change the language of an NPA. Shifting them
uniformly by an odd amount does change the language in general, as it
turns an even maximal priority occurring infinitely often in a run into an
odd one and vice-versa. This simple construction can be used to
complement the language of a DPA.
Theorem 6.11 For every DPA A of size ùëõ and index [ùëò, ùëö] there is a DPA A
of size at most ùëõ + 1 and index [ùëò + 1, ùëö + 1] such that ùêø(A) = Œ£ ùúî ‚àñ ùêø(A)
.
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) be a DPA of size ùëõ and index [ùëò , ùëö]. By adding

at most one extra state we can make its transition function complete so that
every word has exactly one run. It can receive an arbitrary odd priority.
Then define A ‚à∂= (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) where, for any ùëû ‚àà ùëÑ, Œ©(ùëû) ‚à∂= Œ©(ùëû) + 1.
It should be clear that A is a DPA of size at most ùëõ + 1 and index [ùëò + 1, ùëö
+ 1].
For correctness of the construction take an arbitrary ùë§ ‚àà Œ£ ùúî and let ùúå be
A's unique run on ùë§. Note that ùúå is then also the unique run of A on ùë§. The
simple but key observation is that we have max{Œ©(ùëû) ‚à£ ùëû ‚àà Inf (ùúå)} ‚â°2 0 iff
max{Œ©(ùëû) ‚à£ ùëû ‚àà
Inf (ùúå)} ‚â°2 1. Thus, ùë§ ‚àà ùêø(A) iff ùë§ /
‚àà ùêø(A).
‚óª
Note that this simple complementation construction again heavily relies on
determinism, namely the fact that runs are unique.
128
6 Acceptance Conditions
6.2.2 Parity vs. B ¬®
uchi Acceptance
In accordance with the corresponding result for Rabin- and Streett-
automata it is not hard to see that parity automata are at least as expressive
as B √ºchi automata, i.e. they can recognise all ùúî-regular languages.

Theorem 6.12 For every NBA A of size ùëõ there is an NPA B of size ùëõ and
index
[1, 2] such that ùêø(B) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, ùõø, Œ©
ùêº
). Define B ‚à∂= (ùëÑ, Œ£, ùëûùêº
) with
‚éß
‚é™
‚é™2
, if ùëû ‚àà ùêπ,
Œ©(ùëû) ‚à∂= ‚é®
‚é™
‚é™1
, otherwise.
‚é©
The statements on the size and index of B are obviously satisfied.
For a run ùúå of A or, likewise, B on some ùë§ ‚àà Œ£ ùúî we then have Inf (ùúå) ‚à© ùêπ ‚â†
‚àÖ
iff max{Œ©(ùëû) ‚à£ ùëû ‚àà Inf (ùúå)} = 2. Hence, ùë§ ‚àà ùêø(A) iff ùë§ ‚àà ùêø (B).

‚óª
We remark that the construction preserves determinism, i.e. a DBA can
equally be seen as a DPA with priorities in [1, 2].
The simplicity of the constructions in Thm. 6.5 and 6.12 is not very
surprising, given that Rabin-, Streett- and parity automata clearly allow for
more elaborate conditions for determining acceptance. We now turn to the
more interesting part of the study of their expressiveness and show that
parity automata in fact only recognise ùúî-regular languages. We show how to
translate an NPA "back" into an NBA. This requires a slightly more
elaborate construction, though. In particular, this involves a blowup of the
state space in general.
The transformation makes use of the fact that the maximal priority
occurring in a run ùúå = ùëû , ùëû , . . .
0
1
of an NPA is even iff there is an even priority ùëù and some ‚Ñì ‚àà N, s.t. priority
ùëù is seen infinitely often in the suffix ùëû , ùëû
, . . .
‚Ñì
‚Ñì +1
and no greater priority
is seen at all. This is a simple consequence of the fact that all priorities
greater than ùëù
will only be seen finitely often, for otherwise ùëù would not be the greatest
that is being seen infinitely often. Seeing something infinitely often can be
formulated as a B √ºchi condition, and not seeing particular states at all can

be implemented in an NBA's transition function. The existential
quantification over finitely many even priorities can be realised by
essentially a union construction, and the existential quantification over the
moment ‚Ñì can be realised in the transition function again, both requiring
nondeterminism. Hence, the following construction does not preserve
determinism, and this is not a surprise, for otherwise it would contradict the
result that DBA are strictly weaker than NBA, cf. Thm. 5.24.
Theorem 6.13 For every NPA A of size ùëõ and index ùëò there is an NBA B of
size at ùëò
most ùëõ ‚ãÖ (‚åà ‚åâ + 1) such that ùêø(B) = ùêø(A) .
2
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
). According to Cor. 6.10 we can assume that A uses
‚Ä≤
ùëò
at most ùëò ‚â§ ‚åà ‚åâ many even priorities. Otherwise Œ©(ùëÑ) would contain two
even 2‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
priorities ùëù < ùëù s.t. ùëù
/

‚àà Œ©(ùëÑ) for all odd ùëù
with ùëù < ùëù
< ùëù .
6.2 Parity Automata
129
‚Ä≤
We construct an NBA B that intuitively works as follows. It has 1 + ùëò many
components. The first one is simply a copy of A as a B √ºchi automaton with
no accepting states. By traversing through this component, B can simulate
the reading of an arbitrary prefix of a word by A. It cannot accept the
underlying word by
‚Ä≤
continuing in this part since there are no accepting states. The other ùëò
components
- one for each even priority ùëù - also simulate A, but the one for ùëù has all
states of priority ùëù as accepting states, and all states of greater priority
than ùëù have been removed, resp. made inaccessible. From the first
component, when visiting a state with even priority ùëù, it is possible to
switch over to the component for ùëù in order to confirm that ùëù is indeed the
maximal priority that occurs infinitely often. From then on, no further
component change is possible anymore.
Formally, let ùëù , . . . , ùëù
1
ùëò ‚Ä≤
be the even priorities used in Œ©(ùëÑ). We define B ‚à∂=

(ùëÑ ‚à™ ùëÑ √ó { ùëù , . . . , ùëù
, Œî, ùêπ
1
ùëò ‚Ä≤ }, Œ£, ùëû ùêº
) where
‚éß
‚é™
‚Ä≤
‚Ä≤
‚é™{(ùëû , Œ©(ùëû)) ‚à£ ùëû
‚àà ùõø(ùëû, ùëé)}
, if Œ©(ùëû) ‚â°
Œî
2 0,
(ùëû, ùëé)
‚à∂= ùõø(ùëû, ùëé) ‚à™ ‚é®
‚é™
‚é™‚àÖ
, otherwise,
‚é©

for ùëû ‚àà ùëÑ and ùëé ‚àà Œ£ are the transitions within the component described
first as well as those used to switch over to another component for
confirming acceptance by some
‚Ä≤
priority ùëùùëñ. Then, for ùëñ ‚àà {1, . . . , ùëò },
Œî
‚Ä≤
‚Ä≤
‚Ä≤
((ùëû, ùëù
, ùëù
ùëñ ), ùëé )
‚à∂= {(ùëû
ùëñ ) ‚à£ ùëû
‚àà ùõø(ùëû, ùëé), Œ©(ùëû ) ‚â§ ùëùùëñ }
ùëÑ √ó { ùëù , . . . , ùëù ‚Ä≤ }
ùëé ‚àà Œ£
for states from
1
ùëò
, and

consists of the transitions inside the
component for ùëùùëñ.
‚Ä≤
ùëò
The set of accepting states is ùêπ ‚à∂= ‚ãÉ
{(ùëû, ùëù
ùëñ=1
ùëñ )
‚à£ Œ©(ùëû) = ùëùùëñ }. Thus, a run of
B is accepting if it visits states of priority ùëùùëñ in the respective component for
ùëùùëñ
infinitely often. The size estimation on B should be clear. It remains to be
seen that the construction is correct, i.e. that we have ùêø(B) = ùêø(A).
"‚äÜ" The key is the observation that a run will eventually get trapped in
either the component based on ùëÑ (but then it is not accepting) or in a
component based on ùëÑ √ó { ùëùùëñ } for some ùëñ, and then it is accepting iff it
visits states of priority ùëùùëñ infinitely often, and it cannot visit any state of
greater priority at all because no transition can lead to such a state in the
respective components.
So suppose that ùë§ = ùëé ùëé . . .
0
1
‚àà ùêø(B), i.e. there is an accepting run ùúå of B on ùë§.

By the aforementioned key observation, ùúå must be of the f orm
ùëû
, ùëé
, ùëû
, ùëé
, . . . , ùëû
, ùëé
,
, ùëù
,
, ùëù
0
0
1
1
‚Ñì
‚Ñì
(ùëû‚Ñì+1
ùëñ ), ùëé ‚Ñì +1 (ùëû‚Ñì+2
ùëñ ), . . .

with ùëû0 = ùëûùêº and some even priority ùëùùëñ. Moreover, by the construction of
Œî, we have ùëû
, ùëé
ùëó +1 ‚àà ùõø(ùëû ùëó
ùëó ) for all ùëó ‚â• 0. Thus,
‚Ä≤
ùúå
‚à∂= ùëû , ùëé , ùëû , . . . , ùëû , ùëé , ùëû
, ùëé
, ùëû
, . . .
0
0
1
‚Ñì
‚Ñì
‚Ñì +1
‚Ñì +1
‚Ñì +2
‚Ä≤

is a run of A on ùë§. We also have that max{Œ©(ùëû) ‚à£ ùëû ‚àà Inf (ùúå )} is even: we
have Inf (ùúå) ‚à© ùêπ ‚â† ‚àÖ because ùúå is accepting, but ùúå eventually contains only
states from
130
6 Acceptance Conditions
ùëè
ùëè
ùëè
ùëè
ùëè
ùëé
ùëé
ùëé
2
ùëê
ùëè
ùëè
ùëè
ùëê
ùëé
ùëé

ùëê
ùëé
ùëé
ùëé
ùëê
ùëê
ùëè
ùëè
ùëê
ùëê
ùëê
1
ùëé
ùëé
ùëê
0
ùëê
ùëê
ùëê

Fig. 6.2 DPA for the language from Ex. 6.2 and its translation into an NBA
according to Thm. 6.13.
ùëÑ √ó { ùëùùëñ }, and ùêπ ‚à© (ùëÑ √ó {ùëùùëñ }) contains only states of the form (ùëû, ùëùùëñ )
such that Œ©
‚Ä≤
(ùëû) = ùëùùëñ . Thus, there is at least some such state ùëû with ùëû ‚àà Inf (ùúå ), i.e. the
‚Ä≤
priority ùëùùëñ occurs infinitely often in ùúå . At last, no priority greater than ùëùùëñ
can
‚Ä≤
occur in ùúå infinitely often, for otherwise it would have to occur after the
transition from ùëû
, ùëù
‚Ñì
to (ùëû‚Ñì+1
ùëñ ) in ùúå, but this part does not contain transitions to states with priorities
greater than ùëùùëñ anymore, cf. the construction of Œî. Thus, we get that
‚Ä≤
‚Ä≤
max{Œ©(ùëû) ‚à£ ùëû ‚àà Inf (ùúå )} = ùëùùëñ which is even, and therefore ùúå is an accepting
run of A on ùë§ which yields ùë§ ‚àà ùêø (A).
"‚äá" Suppose that ùë§ = ùëé ùëé . . .
0

1
‚àà ùêø(A), i.e. there is an accepting run ùúå =
ùëû
, ùëé
, ùëû
, ùëé
, . . .
0
0
1
1
of A on ùë§, i.e. max{Œ©(ùëû) ‚à£ ùëû ‚àà Inf (ùúå)} is even. Thus, there is some ùëñ ‚àà {1, .
. . , ùëò} such that max{Œ©(ùëû) ‚à£ ùëû ‚àà Inf (ùúå)} = ùëùùëñ. Then there are ùëó0 < ùëó1 < . . .
such that Œ©(ùëû ùëó ) = ùëùùëñ for all ‚Ñé ‚â• 0 and Œ©(ùëû ùëó ) ‚â§ ùëùùëñ for all ùëó ‚â• ùëó
‚Ñé
0.
I.e. when priority ùëùùëñ is the one that determines whether ùúå is accepting or
not, then there must be some point after which no greater priority occurs at
all, and ùëù ùëñ occurs infinitely often. Then consider the run
ùëû
, ùëé
, ùëû

, . . . , ùëû
, ùëé
, ùëû
, ùëé
,
, ùëù
, ùëù
, ùëù
0
0
1
ùëó
ùëó
ùëó
ùëó
(ùëû ùëó
ùëñ ), . . . , (ùëû ùëó
ùëñ ), . . . , (ùëû ùëó
ùëñ ), . . .
0 ‚àí1

0
0
0 +1
0 +1
1
2
‚Ä≤
It can easily be checked that ùúå is indeed a run of B on ùë§ since all the
transitions are valid w.r.t. its transition function Œî. Moreover, it is accepting
because (ùëû
, ùëù
ùëó
ùëñ ) ‚àà ùêπ
‚Ñé
for all ‚Ñé ‚â• 0. Thus, ùë§ ‚àà ùêø(B ).
‚óª
Example 6.14 Reconsider the DPA A constructed in Ex. 6.8 for the
language ùêø =
ùúî
{ùë§ ‚àà {ùëé, ùëè, ùëê}
‚à£ ‚à£ùë§‚à£ùëé = ‚àû ‚áí ‚à£ùë§‚à£ùëè = ‚àû} from Ex. 6.2. It is shown again in

Fig. 6.2 on the left. The right-hand side shows the NBA B resulting from A
under the translation given in the proof of Thm. 6.13.
The three-component structure, arising from the fact that A uses two even
priorities, is marked and also clearly visible, as well as B's functionality
simulating A and guessing both the even maximal priority occurring
infinitely often as well as the moment after which no greater priority will be
seen anymore. The two components
6.2 Parity Automata
131
with accepting states quite clearly accept words that contain infinitely many
symbols ùëè, as well as those that eventually only contain the symbol ùëê.
It is easy to see that B obtained in this way is not optimal in terms of
minimal size, even though A was minimal as a DPA. A smaller NBA can be
obtained immediately by collapsing all three states in the left component
into one, and the two non-accepting states in the right upper component
into one as well, leading to the following NBA.
ùëé, ùëê
ùëé, ùëê
ùëé, ùëè, ùëê
ùëè
, ùëê
ùëè
ùëé
ùëè

ùëê
ùëê
It is still possible to reduce the size further, but this will destroy the three-
component structure still visible in this NBA where the left state is only used
to traverse a prefix of an input word, the transitions going out of it to the
right realise the guessing of a moment after which one can see symbols ùëê
only (state below right) or infinitely many symbols ùëè (states above right).
A similar principle can be used to translate an NRA A with acceptance
condition F = {(ùê∫ , ùêπ
, ùêπ
1
1), . . . , (ùê∫ ùëò
ùëò )} into an NBA B. Remember that Rabin acceptance is
an existential condition: for some ùëñ, some state in ùê∫ùëñ is seen infinitely often
while no state on ùêπùëñ is seen infinitely often. This can be simulated by B as
follows: it first reads off an arbitrary prefix whilst changing states as A
would. Then it guesses some ùëñ ‚àà {1, . . . , ùëò } and proceeds into a separate
component in which it verifies through its B √ºchi acceptance condition that
ùê∫ùëñ is visited infinitely often. Likewise, states from ùêπùëñ are removed or made
inaccessible to ensure that none of these is seen anymore.
Working out the formal details of this translation is left as an exercise.
Simulating an NSA with an NBA is more difficult because the acceptance
condition is universal. Here, the NBA cannot simply guess some part (ùê∫, ùêπ)
of the acceptance condition and verify this. It would have to keep track of
the infinite occurrence of states w.r.t. all such ùê∫ and ùêπ. The simulation is
still possible but it becomes conceptually much simpler when it takes the
detour via Muller automata which are studied in the next section.

6.2.3 Parity vs. Rabin and Streett Acceptance
While it is not a mystery that a B √ºchi condition can be translated directly
into a parity condition but the converse can only be done with a blowup in
the state space in general, it is not immediately clear whether there is a
similar relationship between the parity condition on one hand and the
Rabin or Streett condition on the other hand. The last theorem in this
section shows that the latter are the more general ones
132
6 Acceptance Conditions
in the sense that a parity condition can be expressed directly as a Rabin and
as a Streett condition.
Theorem 6.15 For every NPA A of size ùëõ and index ùëò there is an NRA B ,
resp. NSA
‚Ä≤
ùëò
‚Ä≤
B
of size ùëõ and index ‚åà ‚åâ such that ùêø(B) = ùêø(A) = ùêø(B ) .
2
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
). We construct an equivalent NRA with the required
properties first.

‚Ä≤
ùëò
Using Cor. 6.10 we can assume that there are at most ùëò ‚à∂= ‚åà ‚åâ many even
priorities 2
in Œ©(ùëÑ), and that these are ùëù , . . . , ùëù
1
ùëò ‚Ä≤ . Note that the following two conditions are
equivalent for a run ùúå.
(i) max{Œ©(ùëû) ‚à£ ùëû ‚àà Inf
(ùúå)}
2
‚â°
0,
‚Ä≤
(ii) there are ùëñ ‚àà {1, . . . , ùëò } and ùëû ‚àà ùëÑ with Œ©(ùëû) = ùëùùëñ such that ùëû ‚àà Inf
(ùúå) and
‚Ä≤
‚Ä≤
ùëû
/
‚àà Inf (ùúå) for every ùëû ‚àà ùëÑ with Œ©(ùëû ) > ùëùùëñ .

Condition (i) is of course just the well-known parity condition for Œ©.
Condition (ii) can be expressed as the Rabin condition F ‚à∂= {(ùê∫ , ùêπ
1
1), . . . , (ùê∫ ùëò‚Ä≤ , ùêπùëò‚Ä≤ } where
‚Ä≤
ùê∫ ùëñ ‚à∂= {ùëû ‚àà ùëÑ ‚à£ Œ©(ùëû) = ùëùùëñ } and ùêπùëñ ‚à∂= {ùëû ‚àà ùëÑ ‚à£ Œ©(ùëû) > ùëùùëñ } for ùëñ = 1, . . .
, ùëò . Hence, B ‚à∂= (ùëÑ, Œ£, ùëû , ùõø,
ùêº
F ) is an NRA with the required properties.
The construction of an NSA is analogous. With Cor. 6.10 we can equally
bound
‚Ä≤
‚Ä≤
‚Ä≤
the number of odd priorities to be at most ùëò . Suppose they are ùëù , . . . , ùëù
1
ùëò ‚Ä≤ .
We
then observe that there is a third formulation that is equivalent to (i) and (ii)
above, namely the following one.
‚Ä≤
‚Ä≤

(iii) for every ùëñ ‚àà {1, . . . , ùëò } and ùëû ‚àà ùëÑ with Œ©(ùëû) = ùëùùëñ and ùëû ‚àà Inf (ùúå)
there is
‚Ä≤
‚Ä≤
ùëû
‚àà Inf (ùúå) with Œ©(ùëû ) > ùëùùëñ .
I.e. the largest priority seen infinitely often is even iff for every odd priority
seen infinitely often there is a greater one that is also seen infinitely often.
One is tempted to require that the greater one needs to be even, but this is in
fact not necessary, and the formulation (iii) is then entirely dual to (ii). This
is also why it is easily
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
seen to be phrasable as the Streett condition F = {(ùê∫ , ùêπ ), . . . , (ùê∫
, ùêπ
1
1
ùëò ‚Ä≤
ùëò ‚Ä≤ )} where

‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
ùê∫
‚à∂= {ùëû ‚àà ùëÑ ‚à£ Œ©(ùëû) = ùëù }
‚à∂= {ùëû ‚àà ùëÑ ‚à£ Œ©(ùëû) > ùëù }
ùëñ
ùëñ
and ùêπùëñ
ùëñ
. This appears to be the
same as the Rabin condition F defined above but it is not because it is
based on the
‚Ä≤
‚Ä≤
‚Ä≤
odd priorities ùëù
‚à∂= (ùëÑ, Œ£, ùëû , ùõø, F )
ùëñ

rather than the even ones ùëùùëñ. Again, B
ùêº
is then
an NSA equivalent to A.
‚óª
Since the constructions in the proof above translate acceptance conditions
rather than automata, i.e. not blowing up state spaces, the corresponding
translation on automata that only exchange the acceptance condition
preserve determinism again.
Corollary 6.16 For every DPA A of size ùëõ and index ùëò there is a DRA B ,
resp. DSA
‚Ä≤
ùëò
‚Ä≤
B
of size ùëõ and index ‚åà ‚åâ such that ùêø(B) = ùêø(A) = ùêø(B ) .
2
The parity acceptance condition is also sometimes known as the Rabin
chain condition, and it may not be immediate that there are chains involved
in the construction above. However, reconsider the Rabin acceptance
condition F , where ùê∫ùëñ, resp. ùêπùëñ
consist of all states of priority ùëùùëñ, resp. of priority greater than ùëùùëñ. Clearly,
we have
6.3 Muller Automata

133
ùêπ1 ‚äá ùêπ2 ‚äá . . . ‚äá ùêπùëò‚Ä≤ , i.e. the second components do indeed form a
descending chain.
Moreover, one could equally define the ùê∫ùëñ as the sets of states that have
even priority at most ùëùùëñ . Then we get ùê∫1 ‚äÜ ùê∫2 ‚äÜ . . . ‚äÜ ùê∫ ùëò‚Ä≤ and the first
components form an ascending chain in the same order. By the same
reasoning, the translation into NSA can of course also be amended to yield
pairs that for m two opposing chains.
6.3 Muller Automata
The previous sections have studied three ways to significantly extend the B
√ºchi acceptance condition into Rabin-, Streett- and parity conditions. Yet,
finite automata accepting infinite words with either of them still only
recognise ùúî-regular languages.
For parity automata, this has been shown in Thm. 6.13, for Rabin automata
this is done in a very similar way, and Streett automata can also be
translated into NBA but this is more difficult to do directly, and it will
follow immediately from constructions in this section where we study the
question: is it possible at all to build an acceptance condition based on the
infinite occurrence of states such that the expressive power of the
corresponding automaton model exceeds that of ùúî-regularity? The answer is
no.
6.3.1 The Most General Acceptance Condition
Definition 6.17 A nondeterministic Muller automaton (NMA) is an A = (ùëÑ,
Œ£, ùëû , ùêº
ùõø, F ) where ùëÑ, Œ£, ùëû , ùõø
ùêº
are as with all the other finite automata studied before, and

ùëÑ
the acceptance condition F ‚äÜ 2
is a set of sets of s tates.
The notions of size, deterministic Muller automata (DMA), run, language,
NMA-
/DMA-recognisability etc. are defined as usual, the latter of course based
on the following definition. A run ùúå = ùëû , ùëû , . . .
0
1
of an NMA is accepting if Inf (ùúå) ‚àà F .
The index of A is ‚à£F ‚à£, i.e. the number of acceptance sets in the acceptance
condition.
So a Muller acceptance condition simply lists all the state sets which are
allowed to occur infinitely often for a run to be seen as accepting. In a
sense, this is a brute-force method of defining acceptance based on infinite
occurrences of states.
Example 6.18
ùúî
We consider, yet again, the language ùêø = {ùë§ ‚àà {ùëé, ùëè, ùëê}
‚à£ ‚à£ùë§‚à£ùëé =
‚àû ‚áí ‚à£ùë§‚à£ùëè = ‚àû} initially introduced in Ex. 6.2. Again, the three-state
deterministic automaton (skeleton) shown in Fig. 6.1 that simply records the
last seen letter in its state space, can be turned into an NMA recognising ùêø.
For this, we equip it with the Muller acceptance condition

{{ùëû
, ùëû
, ùëû
, ùëû
, ùëû
ùëè }, {ùëû ùëê }, {ùëû ùëé
ùëè }, {ùëû ùëè
ùëê }, {ùëû ùëé
ùëè
ùëê }} .
134
6 Acceptance Conditions
Note that this contains exactly those non-empty sets ùëÄ ‚äÜ {ùëû , ùëû , ùëé
ùëé
ùëè
ùëê } that satisfy: if
ùëû ùëé ‚àà ùëÄ then ùëûùëè ‚àà ùëÄ. I.e. the acceptance condition is obtained by a
straightforward translation from the predicate defining ùêø.
The empty set clearly also fulfills this condition but it can never cause
acceptance because every infinite run must contain at least some state
infinitely often.

The next goal is to justify the claim that the Muller condition is the most
general condition based on infinite occurrences of states. This is not
necessarily a statement about the expressive power of NMA, at least not a
statement about some increase in expressiveness. It merely says that the
other acceptance conditions can be seen as special cases of the Muller
condition, just as a B √ºchi condition is a special case of a parity condition
which is a special case of a Rabin and a Streett condition.
To formalise the claim we introduce a symbolic acceptance condition based
on propositional logic.
Definition 6.19 Let ùëÑ be the finite state set of some automaton. Acceptance
formulas over ùëÑ are given by the grammar
Œ¶ ‚à∂‚à∂= ùëû ‚à£ ¬¨Œ¶ ‚à£ Œ¶ ‚à® Œ¶
where ùëû ‚àà ùëÑ. The size ‚à£Œ¶‚à£ of an acceptance formula Œ¶ is inductively
defined b y
‚à£ùëû‚à£
‚à∂= 1
,
‚à£¬¨Œ¶‚à£
‚à∂= 1 + ‚à£Œ¶‚à£
,
‚à£Œ¶ ‚à® Œ®‚à£
‚à∂= 1 + ‚à£Œ¶‚à£ + ‚à£ Œ®‚à£ .
Other Boolean operators like ‚àß, ‚Üí, ‚Üî etc. are allowed as abbreviations
but we do not require them to be spelled out when measuring the size. For
example, ùëû1 ‚àß ùëû2

can be counted to have size 3 rather than size 6 via ¬¨(¬¨ùëû1 ‚à® ¬¨ùëû2).
A set ùëÄ ‚äÜ ùëÑ satisfies the acceptance formula Œ¶ or, simply, is accepting
w.r.t. Œ¶, if ùëÄ ‚äß Œ¶ holds according to the following straightforward
inductive definition.
ùëÄ ‚äß ùëû
iff
ùëû ‚àà ùëÄ
ùëÄ ‚äß ¬¨Œ¶
iff
ùëÄ /
‚äß Œ¶
ùëÄ ‚äß Œ¶ ‚à® Œ®
iff
ùëÄ ‚äß Œ¶ or ùëÄ ‚äß Œ®
A symbolic Muller automaton (sNMA) is an A = (ùëÑ, Œ£, ùëû , ùõø, Œ¶
ùêº
) as with all the
other finite automata, but Œ¶ is an acceptance formula over ùëÑ. Its size is ‚à£ùëÑ‚à£
as usual, and its index is ‚à£Œ¶‚à£. A run ùúå is accepting iff Inf (ùúå) ‚äß Œ¶.
All the acceptance conditions discussed so far can be rephrased in terms of
acceptance formulas.

Lemma 6.20 For every NBA / NPA / NRA / NSA A of size ùëõ and index ùëò
(where applicable) there is an sNMA B of size ùëõ and index O(ùëõ) / O(ùëõ2) /
O(ùëò ùëõ) such that ùêø (B) = ùêø(A) .
Proof All translations preserve the automaton's state space and transition
function.
Only the acceptance condition is changed.
6.3 Muller Automata
135
An NBA with acceptance condition ùêπ is an sNMA for Œ¶ùêπ ‚à∂= ‚ãÅùëû‚ààùêπ inf(ùëû).
Its index is O(ùëõ).
An NRA with acceptance condition F = {(ùê∫ , ùêπ
, ùêπ
1
1), . . . , (ùê∫ ùëò
ùëò )} is an sNMA
for the acceptance formula
ùëò
Œ¶
(
ùëû)
F
‚à∂= ‚ãÅ

‚ãÅ
‚àß ( ‚ãÄ ¬¨ùëû) .
ùëñ=1
ùëû‚ààùê∫
ùëû
ùëñ
‚ààùêπùëñ
Likewise, an NSA with this acceptance condition is an sNMA for
ùëò
Œ¶
(
ùëû) .
F
‚à∂= ‚ãÄ
‚ãÄ ¬¨ùëû) ‚à® ( ‚ãÅ
ùëñ=1
ùëû‚ààùê∫
ùëû
ùëñ
‚ààùêπùëñ

The sizes of these formulas are O(ùëò ùëõ) in both cases.
An NPA with state set ùëÑ and acceptance condition Œ© ‚à∂ ùëÑ ‚Üí N is an sNMA
for Œ¶
‚Ä≤
‚Ä≤
Œ©
‚à∂=
‚ãÅ
ùëû
‚àß
‚ãÄ
¬¨ùëû
or
Œ¶Œ© ‚à∂= ‚ãÄ ùëû ‚Üí ‚ãÅ ùëû
ùëû‚ààùëÑ
‚Ä≤
‚Ä≤
ùëû ‚ààùëÑ
ùëû‚ààùëÑ
ùëû ‚ààùëÑ

Œ©(ùëû) even Œ© ‚Ä≤
Œ©
‚Ä≤
(ùëû )>Œ©(ùëû)
(ùëû) odd Œ©(ùëû )>Œ©(ùëû)
whose sizes are O(ùëõ2).
‚óª
The following lemma shows why the Muller condition can be seen as most
general, as it covers any case of an acceptance formula.
Lemma 6.21 Let ùêø ‚äÜ Œ£ùúî .
a) If ùêø is recognisable by an NMA of size ùëõ and index ùëò then ùêø is
recognisable by an sNMA of size ùëõ and index at most 3 ‚ãÖ ùëò ‚ãÖ ùëõ .
b) If ùêø is recognisable by an sNMA of size ùëõ and index ùëò then ùêø is
recognisable by ùëõ
‚àí
an NMA of size ùëõ and index at most 22
1 .
Proof For both parts, the underlying automaton remains the same, in
particular its state set ùëÑ, just the acceptance condition gets translated.
(a) Let F be the NMA's acceptance condition. It is equivalent to the
acceptance formula
Œ¶

(
ùëû)
F
‚à∂=
‚ãÅ
‚ãÄ
‚àß ( ‚ãÄ ¬¨ùëû )
ùêπ ‚ààF
ùëû‚ààùêπ
ùëû /
‚ààùêπ
Each disjunct has size at most 3 ‚ãÖ ‚à£ùëÑ‚à£, hence the size of the entire formula
is bounded by ‚à£F ‚à£ ‚ãÖ 3 ‚ãÖ ‚à£ùëÑ‚à£. Moreover, we have Inf (ùúå) ‚äß Œ¶F iff Inf (ùúå) ‚àà F
which proves the lemma's statement.
(b) Let Œ¶ be the acceptance condition of the given sNMA. It is equivalent to
the NMA condition FŒ¶ ‚à∂= {ùëÄ ‚äÜ ùëÑ ‚à£ ùëÄ ‚â† ‚àÖ and ùëÄ ‚äß Œ¶}. Clearly, we
have
‚à£ùëÑ‚à£
ùëÑ
‚àí
F
1

Œ¶ ‚äÜ 2
‚àñ {‚àÖ} and therefore ‚à£F ‚à£ ‚â§ 22
. Again, we immediately have Inf (ùúå) ‚àà FŒ¶
iff Inf (ùúå) ‚äß Œ¶
‚óª
As an immediate consequence we obtain that B √ºchi-, Rabin-, Streett- and
parity conditions can directly be translated into Muller conditions.
136
6 Acceptance Conditions
Corollary 6.22 For every NBA, NRA, NSA, NPA A of size ùëõ there is an NMA
B of size ùëõ such that ùêø(B) = ùêø(A) .
Another consequence of Lemma 6.21 concerns closure properties. Closure
of Muller-recognisable languages under unions should be clear: because of
availability of nondeterminism, the disjoint union of two NMA A1 and A2 -
equipped with an additional single starting state that simulates both
original starting states - recognises the union of the two languages at hand.
The acceptance condition simply is the union of the two underlying
acceptance conditions F1 and F2. A more interesting question concerns the
closure under intersections for example.
Theorem 6.23 Let Aùëñ be NMA of size ùëõùëñ and index ùëòùëñ for ùëñ ‚àà {1, 2} . There
is an ùëõ
ùëõ
NMA B of size at most ùëõ
2 , ùëò

1
1 ‚ãÖ ùëõ2 and index at most min{ùëò 1 ‚ãÖ 2
2 ‚ãÖ 2
} such that
ùêø (B) = ùêø(A1) ‚à© ùêø(A2) .
Proof
ùëñ
Using Lemma 6.21 we can assume both A
, Œ£, ùëû , ùõø ,
ùëñ to be given as sNMA (ùëÑùëñ
ùêº
ùëñ
Œ¶ùëñ) such that ‚à£ùëÑùëñ‚à£ = ùëõùëñ for ùëñ ‚àà {1, 2}. We employ the usual product
construction to obtain an sNMA B = (ùëÑ
, Œ£,
, ùëû2
1 √ó ùëÑ2
(ùëû1
), Œî, Œ¶) where
ùêº

ùêº
Œî
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
((ùëû , ùëû
, ùëû
, ùëé
, ùëé
1
2), ùëé)
‚à∂= {(ùëû
) ‚à£ ùëû
‚àà ùõø
), ùëû
‚àà ùõø
)} .
1
2

1
1(ùëû1
2
2(ùëû2
The reason for taking the detour via the symbolically represented
acceptance conditions is that conjunctions are obviously available.
Intuitively, the acceptance formula Œ¶1 ‚àß Œ¶2 expresses that both A1 and A2
need to accept, but this obviously cannot work because this is not a formula
over B's state set ùëÑ1 √óùëÑ2. However, it can easily be turned into the right
one by taking Œ¶ ‚à∂= rlx 2(Œ¶1) ‚àß rlx 1(Œ¶2) where rlx ùëñ(Œ®) relaxes the
requirement Œ® on the infinite occurrences of states in ùëÑ3‚àíùëñ to the
corresponding set in ùëÑ1 √ó ùëÑ2. It can easily be defined inductively as
rlx
, ùëû
1(ùëû2)
‚à∂= ‚ãÅ (ùëû1
2)
rlx ùëñ (¬¨Œ®) ‚à∂= ¬¨ rlx ùëñ (Œ¶)
ùëû1‚ààùëÑùëñ
rlx
, ùëû
2(ùëû1)
‚à∂= ‚ãÅ (ùëû1

2)
rlx ùëñ (Œ®1 ‚à® Œ®2) ‚à∂= rlx ùëñ(Œ®1) ‚à® rlx ùëñ( Œ®2)
ùëû2‚ààùëÑùëñ
for ùëñ ‚àà {1, 2}.
Correctness of this follows from the observation that for any run ùúå = (ùëû1 , ùëû2
), 0
0
ùëñ
ùëñ
(ùëû1 , ùëû2 ), . . . and its projections onto the first and second components ùúå
, ùëû
, . . .
1
1
ùëñ
= ùëû0
1
for ùëñ ‚àà {1, 2} we have Inf (ùúå) ‚äß rlx 2(Œ¶1) ‚àß rlx 1(Œ¶2) iff Inf (ùúå1) ‚äß Œ¶1 and
Inf (ùúå2) ‚äß
Œ¶2.
ùëõ

‚ãÖùëõ
2 1 2 ‚àí1
Obviously, we have ‚à£B‚à£ ‚â§ ùëõ1 ‚ãÖùëõ2. Lemma 6.21 would only yield a bound of
2
on the index of B which is not optimal as it is simply the maximally possible
size of a Muller acceptance condition in an NMA with ùëõ1 ‚ãÖ ùëõ2 many states.
It is, however, possible to transfer the relaxation operation carried out on
formulas above onto sets via rlx
, ùëû
, ùëû
1(ùêπ2) ‚à∂= {(ùëû1
2) ‚à£ ùëû1 ‚àà ùëÑ1
2 ‚àà ùêπ2} for ùêπ2 ‚äÜ ùëÑ2 and likewise for rlx 2. Then
B's explicit acceptance condition can be given as
F
‚à∂= {ùêπ ‚äÜ ùëÑ
,
1 √ó ùëÑ2 ‚à£ ‚àÉùêπ1 ‚àà F1 ‚àÉùêπ2 ‚àà F2 s.t. rlx 2(ùêπ1) = ùêπ = rlx 1(ùêπ2)}
6.3 Muller Automata
137
with which B accepts exactly ùêø(A1) ‚à© ùêø(A2). Note that ‚à£F ‚à£ is naturally
bounded by ùëõ

ùëõ
ùëò
2
1
1 ‚ãÖ 2
and by ùëò2 ‚ãÖ 2 : every set ùêπ ‚àà F must be such that its projection onto the
first components of the state pairs in ùêπ yields some ùêπ1 ‚àà F2, and the
projection onto the second components yields some ùêπ2 ‚àà F2.
‚óª
6.3.2 Muller vs. B ¬®
uchi Acceptance
Nevertheless, despite this very general acceptance mechanism, Muller
automata still only recognise ùúî-regular languages. B √ºchi automata can
make up for their lack in elaborateness of their acceptance condition
through additional states in order to recognise Muller-definable languages.
The construction of an NBA that is equivalent to a given NMA is based on
the same idea underlying the translation of NPA or NRA to NBA: the NBA
guesses the moment after which all states that only occur finitely often will
not be seen anymore, as well as the acceptance set ùêπ ‚àà F that determines
acceptance. Now the construction becomes a little bit trickier because the
NBA has to verify that exactly those states in ùêπ occur infinitely often. The
key here is to take an arbitrary ordering of ùêπ, say
{ ùëì , . . . , ùëì
0

ùëö‚àí1}. Note that all states in ùêπ are seen infinitely often iff eventually ùëì0 is
seen, then eventually after this ùëì1 is seen, etc., until after ùëìùëö‚àí1 we require
to see ùëì0
again and so on. An NBA can check that this is the case by employing an
additional counter with values from [ùëö] that is increased by one when its
value is ùëñ and state ùëìùëñ is just being visited. At the end, when the value is ùëö ‚àí
1 and ùëìùëö‚àí1 is seen, it goes back to 0. Thus, any value in this extra
component, for instance 0, is seen infinitely often iff all states in ùêπ are
being visited infinitely often.
Theorem 6.24 For every NMA A of size ùëõ and of index ùëò there is an NBA B
of size at most ùëõ + ùëò ‚ãÖ ùëõ2 such that ùêø(B) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø,
, . . . , ùêπ
ùêº
F ) be an NMA such that ‚à£ùëÑ‚à£ = ùëõ and F = {ùêπ1
ùëò }.
‚Ä≤
Let B ‚à∂= (ùëÑ , Œ£, ùëû , Œî, ùêπ
ùêº
) with
ùëò
‚Ä≤
ùëÑ

‚à∂= ùëÑ
‚à™
‚ãÉ{ùëñ} √ó ùêπùëñ √ó {0, . . . , ‚à£ùêπùëñ ‚à£ ‚àí 1} .
ùëñ=1
There are three kinds of transitions. The component based on ùëÑ simulates A
and allows transitions into any component for an acceptance set ùêπùëñ,
recognisable by states
‚Ä≤
‚Ä≤
of the form (ùëñ, ùëû , ùëê) for some ùëû , ùëê, at any time. We have
Œî
‚Ä≤
‚Ä≤
(ùëû, ùëé)
‚à∂= ùõø(ùëû, ùëé) ‚à™ {(ùëñ, ùëû , 0) ‚à£ ùëñ ‚àà {1, . . . , ùëò }, ùëû ‚àà ùõø(ùëû, ùëé) ‚à© ùêπ ùëñ }
for every ùëû ‚àà ùëÑ and ùëé ‚àà Œ£ .
The third kind consists of transitions within each of these components. They
can be defined uniformly as follows. Fix ùëñ ‚àà {1, . . . , ùëò} and let ùëö ‚à∂= ‚à£ùêπùëñ‚à£
and ùêπùëñ =
{ ùëì , . . . , ùëì
0
ùëö‚àí1}. Then we have, for every ùëê, ùëó ‚àà [ùëö] and every ùëé ‚àà Œ£:

138
6 Acceptance Conditions
Œî
‚Ä≤
((ùëñ, ùëì , ùëê
, ùëê
, ùëé
ùëó
), ùëé)
‚à∂= {(ùëñ, ùëì‚Ñé
) ‚à£ ùëì‚Ñé ‚àà ùêπùëñ ‚à© ùõø( ùëì ùëó
)}
where, in each case,
‚éß
‚é™
‚é™ùëê +
‚Ä≤
1 mod ùëö
, if ùëó = ùëê,
ùëê

‚à∂= ‚é®
‚é™
‚é™ùëê
, otherwise.
‚é©
ùëñ
In order to define the B √ºchi acceptance condition, let ùëì denote the first
state in ùêπ
0
ùëñ
ùëñ
according to the total orders fixed above, for ùëñ = 1, . . . , ùëò. Then let ùêπ ‚à∂=
{(ùëñ, ùëì , 0) ‚à£
0
ùëñ ‚àà {1, . . . , ùëò }}.
It should be clear that the size of B is bounded by ùëõ + ùëò ‚ãÖ ùëõ ‚ãÖ ùëõ since ùëõ is a
bound on the size of each acceptance set ùêπùëñ. It remains to be seen that ùêø(B)
= ùêø(A).
"‚äá" Suppose that ùë§ = ùëé ùëé . . .
, ùëû
, . . .
0

1
‚àà ùêø(A), i.e. there is a run ùúå = ùëû0
1
on ùë§ such
that Inf (ùúå) ‚àà F , i.e. Inf (ùúå) = ùêπùëñ for some ùëñ ‚àà {1, . . . , ùëò}. Then there is
some ‚Ñì > 0
such that ùëû‚Ñé ‚àà ùêπùëñ for all ‚Ñé ‚â• ‚Ñì and, additionally, for every ùëû ‚àà ùêπùëñ there
are infinitely
‚Ä≤
many ‚Ñé such that ùëû‚Ñé = ùëû. We can construct a run ùúå of B on ùë§ as
ùëû
, ùëû
, . . . , ùëû
,
,
, ùëê
, ùëê
0
1
‚Ñì ‚àí1 (ùëñ, ùëû‚Ñì 0), (ùëñ, ùëû‚Ñì+1
‚Ñì +1), (ùëñ, ùëû‚Ñì+2

‚Ñì +2), . . .
Clearly, this is not fully specified yet since we have not given concrete
values ùëê
, ùëê
, . . .
‚Ñì +1
‚Ñì +2
. Note that Œî is deterministic in the first and third part of triples
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
making up states, i.e. in a transition from (ùëñ, ùëû, ùëê) to (ùëñ , ùëû , ùëê ), the values
of ùëñ and
‚Ä≤
ùëê
are uniquely determined by ùëñ, resp. by ùëû and ùëê. The former is irrelevant and
only stated for completeness, but the determination of the counter values
means that the
‚Ä≤
run ùúå as listed above is indeed fully specified because the counter value at
position ‚Ñì is set to 0, and the states at all positions are known, so all the
counter values at positions past ‚Ñì are also known.

‚Ä≤
What is important to note now is that for every ‚Ñé ‚â• ‚Ñì there is some ‚Ñé ‚â• ‚Ñé
such that ùëû‚Ñé‚Ä≤ = ùëìùëê where ùëìùëê is the ùëê‚Ñé-th state in ùêπùëñ according to some
enumeration of the ‚Ñé
‚Ñé
‚Ä≤
states therein. In other words, whenever at some moment ‚Ñé in ùúå the counter
value ùëê‚Ñé
names some particular state in ùêπùëñ, then at some point later this state will be
visited.
Consequently, the counter value will then point to the next state in the
underlying enumeration of ùêπùëñ, and the argument can be repeated.
Moreover, the counter is cyclic, i.e. once it reaches value ‚à£ùêπùëñ‚à£ ‚àí 1 and later
the last state in this enumeration is visited, the process restarts with counter
value 0 in the next step. Hence, the counter value
‚Ä≤
will be 0 infinitely often which means that ùúå visits accepting states infinitely
often.
Thus, ùë§ ‚àà ùêø (B).
"‚äÜ" This direction is analogous. In fact, the reasoning for the previous
direction can be reversed: whenever B visits a state of the form (ùëñ, ùëû, 0)
(apart from the first time), then the run must have contained all states from
ùêπùëñ since the last time that the counter value was 0. Hence, if the counter
value is 0 infinitely often, then all states from the corresponding ùêπùëñ must
have been visited infinitely often. A projection of an accepting run of B onto
the ùëÑ-components of the triple states therefore yields an accepting run of A
on the same word.

‚óª
6.3 Muller Automata
139
ùëè
ùëè
ùëè
ùëè
ùëé
ùëé
ùëé
ùëé
ùëê
ùëê
ùëê
ùëê
ùëè
ùëè
ùëè
ùëê
ùëê

ùëê
ùëè
ùëé
ùëê
ùëè
ùëè
ùëê
ùëê
ùëè
ùëè
ùëè
ùëé
ùëé
ùëé
Fig. 6.3 NBA resulting from the NMA in Ex. 6.18. See Ex. 6.25 for an
explanation regarding the transitions from the left component into those on
the right-hand side.
Example 6.25 Let Œ£ = {ùëé, ùëè, ùëê} and consider the DMA A constructed in Ex.
6.18
for the running example of the language ùêø = {ùë§ ‚àà Œ£ ùúî ‚à£ ‚à£ùë§‚à£ùëé = ‚àû ‚áí ‚à£ùë§‚à£ùëè =
‚àû}. It was obtained by equipping the deterministic automaton depicted in
Fig. 6.1 with the Muller condition

{{ùëû , ùëû , ùëû
, ùëû
, ùëû
ùëé
ùëè
ùëê }, {ùëû ùëè
ùëê }, {ùëû ùëè }, {ùëû ùëê }, {ùëû ùëé
ùëè }}
of index 5.
An NBA for this language is shown in Fig. 6.3. In order to avoid clutter,
transition labels and state names have been left out. Instead, the alphabet
symbols that are shown inside each state are the labels of the transitions
that lead into each such state.
The NBA's component structure that it received in the construction in the
proof of Thm. 6.24 is clearly visible. The component on the left does a
simulation of A only to read off a prefix of an input word. On the right, the
components, from top
140
6 Acceptance Conditions
to bottom, correspond to the acceptance sets given in the order above, and
accept words of the form
‚Ä¢ Œ£‚àó
‚àó

‚àó
‚àó
ùúî
(ùëé(ùëé + ùëê) ùëè(ùëé + ùëè) ùëê(ùëè + ùëê) )
, corresponding to the acceptance set
{ùëû , ùëû , ùëû
ùëé
ùëè
ùëê },
‚Ä¢ Œ£‚àó + + ùúî
(ùëè
ùëê
)
, corresponding to the acceptance set {ùëû , ùëû
ùëè
ùëê },
‚Ä¢ Œ£‚àó ùúî
ùëè
, corresponding to the acceptance set {ùëûùëè},
‚Ä¢ Œ£‚àó ùúî

ùëê
, corresponding to the acceptance set {ùëûùëê},
‚Ä¢ Œ£‚àó + + ùúî
(ùëé
ùëè
)
, corresponding to the acceptance set {ùëû , ùëû
ùëé
ùëè }.
Furthermore, the counter structure in each of the components on the right-
hand side has been made visible as well. Note how each component's
acceptance set ùêπ is divided into ‚à£ùêπ‚à£ + 1 parts, and transitions only remain
within each part (when the counter is not increased) or move over to the
next part (when it is increased). B √ºchi acceptance states are then seen to
be those in which the counter value is 0.
Note that the NBA shown in Fig. 6.3 is missing some transitions according
to the construction in the proof of Thm. 6.24. These would link states in the
left component with states at the beginning of each of the components on
the right, and they have omitted here to avoid cluttering, but also because
they can be left out without changing the NBA's language and intuitive
behaviour: it should be clear that, in general, the constructed NBA B need
not have the possibility to switch into any of the components checking
infinite occurrence of some acceptance set ùêπ at any time. Instead it suffices
to give it the possibility to do so ever again. In the general construction, it
is easier to implement this possibility at any time, leading to more
transitions. In a particular case, when the structure of the underlying NMA
can be inspected to see that having transitions at particular moments only
suffices to guarantee that switches into these components may eventually

occur, it may be easier to implement fewer transitions. This is what has
been done for the NBA in
‚Ä≤
Fig. 6.3: such component-switching transitions from some state ùëû to a state
(ùëñ, ùëû , 0) are only available for one particular state ùëû ‚àà ùêπùëñ, rather than all.
6.3.3 Muller vs. Parity Acceptance
The composition of the construction of Thm. 6.24, translating an NMA into
an NBA, and the rather trivial construction of Thm. 6.12, showing that an
NBA can be seen as an NPA, clearly yields a translation from NMA into
NPA. One may ask for a more direct way to get there because of the
following reason. While the translation in Thm. 6.12 preserves determinism,
since it only translates the B √ºchi condition into a parity condition, the one
in Thm. 6.24 genuinely introduces nondeterminism. Thus, even when
starting with a DMA, the route through these two theorems does not yield a
DPA in the end, but only an NPA in general.
On the other hand, the self-duality of the parity condition and its slightly
more abstract nature make it an ideal ground for further algorithmic
investigations, in particular later in Part III where we study automata
operating on infinite trees rather
6.3 Muller Automata
141
than words. We therefore give yet another translation. It sits halfway in
between being a translation purely on acceptance conditions and a
translation on automata: it does not simply translate a Muller condition
into a parity condition (which is also not possible in general) but it can be
realised with a factor, known as a latest appearance record, in an
automaton's state space that acts entirely deterministically. Hence, this
translation, formulated for nondeterministic automata below, preserves
determinism and therefore immediately yields a translation from DMA to
DPA as well.

Definition 6.26 Let ùëÑ = {ùëû , . . . , ùëû
0
ùëõ‚àí1} be a finite set of states of an automaton. A
‚àí
permutation of ùëÑ is a bijection ùúã ‚à∂ [ùëõ] ‚Üí ùëÑ. Note that its inverse ùúã 1 ‚à∂ ùëÑ ‚Üí
[ùëõ]
exists. We write ùëÑ! for the set of all permutations of ùëÑ.
A latest appearance record (LAR) is a pair (ùúã, ùëö) where ùúã is a permutation of
ùëÑ , and ùëö ‚àà [ùëõ] points to one position in this list. We write the LAR (ùúã, ùëö) also
as
[ùúã(0), . . . , ùúã(ùëö ‚àí 1), ùúã(ùëö), ùúã(ùëö + 1), . . . , ùúã(ùëõ ‚àí 1)]
‚àí
with the marker position ùëö underlined, starting at index 0. Note that ùúã 1(ùëû)
then denotes the unique position of state ùëû in this list.
The update of the LAR (ùúã, ùëö) w.r.t. some ùëû ‚àà ùëÑ is the LAR upd (ùúã, ùëö) ‚à∂=
ùëû
‚Ä≤
‚àí
(ùúã , ùúã 1(ùëû)) where
‚éß
‚é™ùëû
,

‚é™
if ùëñ = 0,
‚é™
‚é™
‚Ä≤
ùúã (ùëñ)
‚à∂= ‚é®ùúã(ùëñ ‚àí 1)
, if 0 < ùëñ ‚â§ ùúã(ùëû),
‚é™
‚é™
‚é™
‚é™ùúã
‚é©
(ùëñ )
, otherwise.
An LAR provides information about - as the name suggests - the
occurrences of states from ùëÑ in latest times. I.e. one should imagine an LAR
as being manipulated along the run of an underlying automaton. States at
the beginning in its list representation should be those that have been
visited more recently than those towards the end of that list.
The update upd (Œõ)
ùëû

of some LAR Œõ w.r.t. ùëû removes ùëû from the list and prepends
it to its beginning, consequently shifting all states that occurred before ùëû
further back by one position. Those that occurred after ùëû remain where they
were. Clearly, this preserves the property of being a permutation. The
appearance marker is set to the position from which ùëû was taken. Thus,
updating the LAR Œõ = [ùëû , . . . , ùëû , . . . , ùëû
1
ùëö
ùëõ ]
w.r.t. some state ùëû ùëó results in the LAR
upd
(Œõ)
‚à∂= [ùëû , ùëû , . . . , ùëû
, ùëû
, . . . , ùëû
ùëû
ùëó
1
ùëó ‚àí1
ùëó +1
ùëõ ] .
ùëó

Note that the position of the marker in the previous moment was irrelevant,
at least momentarily. However, when used consecutively, then this marker
serves an interesting purpose in the infinite.
Lemma 6.27 Let ùëÑ be a finite set of states and ùúå = ùëû , ùëû , . . .
0
1
be a run. Let
Œõ , Œõ , . . .
, ùëö
0
1
with Œõùëñ = (ùúãùëñ
ùëñ )
for all ùëñ ‚â• 0 be a sequence of LAR such that, for
142
6 Acceptance Conditions
all ùëñ ‚â• 1 , Œõùëñ ‚à∂= upd
(Œõ
ùëû
ùëñ‚àí1) . Let ùëö ‚à∂= lim sup (ùëöùëñ )ùëñ‚â•0 . Then Inf (ùúå) = {ùëû ‚àà ùëÑ ‚à£
ùëñ‚àí1

‚àí
lim sup (ùúã 1 (ùëû))
ùëñ
ùëñ‚â•0 ‚â§ ùëö} .
Proof First of all, we recall two properties of a value ùë• = lim sup (ùë•ùëñ)ùëñ‚â•0
for a sequence (ùë•ùëñ)ùëñ‚â•0 with ùë•ùëñ ‚àà [ùëõ] for some ùëõ and all ùëñ ‚â• 0. (i)
Eventually, ùë• is an upper bound for all ùë•ùëñ: there must be some ùëñ0 s.t. ùë•ùëñ ‚â§ ùë•
for all ùëñ ‚â• ùëñ0. (ii) The limes superior
‚Ä≤
is met infinitely often: for every ùëñ ‚â• 0 there is some ùëñ ‚â• ùëñ such that ùë•ùëñ‚Ä≤ = ùë•.
Now we proceed with the proof of the lemma's claim.
"‚äÜ" We make use of (i) for the sequence (ùëöùëñ)ùëñ‚â•0 to obtain some index ùëñ0
s.t. ùëö ‚â• ùëöùëñ
for all ùëñ ‚â• ùëñ0. Take some ùëû ‚àà Inf (ùúå) and suppose, for the sake of
contradiction, that
‚àí
‚àí
lim sup (ùúã 1 (ùëû))
1(ùëû))
ùëñ
ùëñ‚â•0 > ùëö. We make use of property (ii) for the sequence (ùúã
ùëñ‚â•0
‚Ä≤

‚àí
and ùëñ
1
0 to obtain some ùëñ
‚â• ùëñ0 s.t. ùúãùëñ‚Ä≤ (ùëû) > ùëö. Now consider the LAR at position
‚Ä≤
ùëñ
+ 1. We have Œõ
, ùëö
ùëñ‚Ä≤ +1 = (ùúãùëñ‚Ä≤+1
ùëñ‚Ä≤ +1) by assumption and Œõùëñ‚Ä≤+1 = upd (ùúã
ùëû
ùëñ‚Ä≤ , ùëö ùëñ‚Ä≤ ) =
‚àí
‚àí
(ùúã
, ùúã
1
1
ùëñ‚Ä≤ +1

ùëñ‚Ä≤
OceanofPDF.com

(ùëû)) by construction. Hence, we have ùëö ‚â• ùëöùëñ‚Ä≤+1 = ùúãùëñ‚Ä≤ ( ùëû) > ùëö which is
impossible.
‚àí
"‚äá" Take some ùëû /
‚àà Inf (ùúå). We will show that lim sup (ùúã 1 (ùëû))
ùëñ
ùëñ‚â•0 > ùëö. Take
some ùëñ
, ùëö
0 s.t. ùëûùëñ ‚â† ùëû for all ùëñ ‚â• ùëñ0. In a step from Œõùëñ = (ùúãùëñ
ùëñ ) to Œõùëñ+1 = upd
(Œõ
ùëû
ùëñ ) =
ùëñ
‚àí
‚Ä≤
‚àí
‚Ä≤
‚Ä≤

(ùúã
, ùëö
1
1
ùëñ+1
ùëñ+1), we have ùúã
(ùëû ) ‚â• ùúã
(ùëû ) for all ùëû ‚â† ùëû
ùëñ+1
ùëñ
ùëñ , and therefore in particular
for ùëû if ùëñ ‚â• ùëñ0. In other words, after moment ùëñ0, ùëû can only move further
towards the end of the LAR list.
‚àí
‚àí
Moreover, suppose there is some ùëñ ‚â• ùëñ
1
1
0 s.t. ùëöùëñ ‚â• ùúã
(ùëû)

(ùëû) >
ùëñ
. Then we have ùúãùëñ+1
‚àí
‚Ä≤
ùúã
1 (ùëû)
ùëñ
, i.e. if some update is done with respect to a state ùëû that resides behind ùëû
in the current LAR, then ùëû's position is shifted towards the end of the list.
Clearly, this cannot happen infinitely often. Thus, there must be some ùëñ1 ‚â•
ùëñ0 such that
‚àí
‚àí
ùëö
1
1
ùëñ
< ùúã
(ùëû)
(ùëû))

ùëñ
for all ùëñ ‚â• ùëñ1. But then lim sup (ùúãùëñ
ùëñ‚â•0 > lim sup (ùëöùëñ )ùëñ‚â•0 = ùëö
whic h proves the claim.
‚óª
Theorem 6.28 For every NMA A of size ùëõ there is an NPA B of size at most
ùëõ2 ‚ãÖ ùëõ!
and index at most 2ùëõ such that ùêø(B) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø,
ùêº
F ) be an NMA with ‚à£ùëÑ‚à£ = ùëõ. Pick an arbitrary per-
mutation ùúã
,
0 of ùëÑ and let Œõ0 ‚à∂= (ùúã0 0). We define the NPA B ‚à∂= (ùëÑ √ó (ùëÑ! √ó
[ùëõ]), Œ£, (ùëû , Œõ
ùêº
0), Œî, Œ©) where
Œî
‚Ä≤
‚Ä≤

((ùëû, Œõ), ùëé)
‚à∂= {(ùëû , upd (Œõ)) ‚à£ ùëû ‚àà ùõø(ùëû, ùëé)} .
ùëû
B
In other words,
runs a simulation of A in which it uses an LAR to track the
occurrences of states in any run. The claim on the size of B should be clear.
The parity acceptance condition remains to be defined. We set
‚éß
‚é™
‚é™2 ‚ãÖ ùëö + 2
, if {ùúã(0), . . . , ùúã(ùëö)} ‚àà F ,
Œ©(ùëû, (ùúã, ùëö)) ‚à∂= ‚é®
‚é™
‚é™2 ‚ãÖ ùëö + 1
, other wise.
‚é©
Hence, a state's priority solely depends on the LAR in that state. It is higher
with greater marker positions, and it is even whenever the set of states up to
and including the marker position forms a Muller acceptance set.
Otherwise it is odd. This reflects

6.4 Co-B √ºchi Automata
143
the fact that along some run, the marker position will eventually oscillate
below and up to its limes superior ùëö. The states that reside on positions up
to and including ùëö
are exactly those that are seen infinitely often.
For the claim on the index of B note that the minimal and maximal value for
the marker position are 0 and ùëõ ‚àí 1, respectively. Hence, minimal and
maximal priorities used in Œ© are 1 and 2(ùëõ ‚àí 1) + 2, respectively, and so
there are at most 2ùëõ many different ones.
It remains to be seen that we have ùêø(B) = ùêø(A).
"‚äá" Let ùúå = ùëû , ùëû , . . .
0
1
be an accepting run of A on some word ùë§ ‚àà Œ£ ùúî, i.e.
‚Ä≤
Inf (ùúå) ‚àà F . It gives rise to a run ùúå = (ùëû , Œõ
, Œõ
0
0), (ùëû1
1), . . . on the same ùë§ where
Œõ0 is as defined above and Œõùëñ+1 ‚à∂= upd (Œõ

ùëû
ùëñ ) for all ùëñ ‚â• 0. We need to show that the
ùëñ
‚Ä≤
maximal priority occurring infinitely often in ùúå is even.
Let Œõ
, ùëö
ùëñ
= (ùúãùëñ
ùëñ ) for all ùëñ ‚â• 0, and let ùëö ‚à∂= lim sup (ùëöùëñ )ùëñ‚â•0 be the limes superior of the
marker positions in the sequence of LAR constructed in this way. According
‚àí
to Lemma 6.27 we have Inf (ùúå) = {ùëû ‚àà ùëÑ ‚à£ lim sup (ùúã 1 (ùëû))
ùëñ
ùëñ‚â•0 ‚â§ ùëö}. Since Inf (ùúå)
is given, Lemma 6.27 dictates that there is some ùëñ0 such that for all ùëñ ‚â• ùëñ0
we have
‚àí
ùúã
1 (ùëû) ‚â§ ùëö
ùëñ

iff ùëû ‚àà Inf (ùúå). Moreover, there must be infinitely many ùëñ such that ùëöùëñ = ùëö.
Hence, the greatest priority occurring infinitely often must be 2ùëö + 2 or
‚àí
‚àí
2ùëö + 1, depending on the sets {ùúã 1 (
1 (ùëö)}
ùëñ
0), . . . , ùúãùëñ
at such positions ùëñ. Since this
equals Inf (ùúå), the exact priority is determined by the question of whether or
not Inf (ùúå) ‚àà F . Since this is the case by assumption, the maximal priority
occurring
‚Ä≤
infinitely often in ùúå is 2ùëö + 2 which is clearly even.
‚Ä≤
"‚äÜ" Now take a run ùúå = (ùëû , Œõ
, Œõ
0
0), (ùëû1
1), . . . on some ùë§ ‚àà Œ£ ùúî with Œõùëñ =
(ùúã , ùëö

, Œõ
ùëñ
ùëñ ) and suppose that it is accepting, i.e. lim sup (Œ©(ùëûùëñ
ùëñ ))ùëñ‚â•0 is even. Then it
must be of the form 2ùëö + 2, and this is because lim sup (ùëöùëñ)ùëñ‚â•0 = ùëö and
there are
‚àí
‚àí
infinitely many ùëñ such that {ùúã 1 (
1 (ùëö)} ‚àà F
ùëñ
0), . . . , ùúãùëñ
. By finiteness of F and the
‚àí
‚àí
pigeon hole principle, we even have some ùêπ ‚àà F such that {ùúã 1 (
1 (ùëö)} = ùêπ
ùëñ
0), . . . , ùúãùëñ
for all such ùëñ. We can then use Lemma 6.27 again to obtain that ùêπ = Inf (ùúå)
for the

‚Ä≤
projection ùúå of ùúå onto its first components. This is then not only a run of A
on ùë§
but in fact also an accepting one.
‚óª
Note that the initial LAR that the simulation of the NPA starts with, is
irrelevant.
This is of course not the same as letting the automaton choose some LAR
nondeterministically. This would not change the language but it would kill
the property that a DMA becomes a DPA under this construction which is
easily verified.
Corollary 6.29 For every DMA A of size ùëõ there is a DPA B of size at most
ùëõ2 ‚ãÖ ùëõ!
and index at most 2ùëõ such that ùêø(B) = ùêø(A) .
6.4 Co-B ¬®
uchi Automata
Cor. 6.22 and Thm. 6.24 show that, at least for the nondeterministic variant,
B √ºchi, Rabin, Streett, parity and Muller automata all have equal
expressiveness, recognising exactly the ùúî-regular languages. We already
know from Chp. 5 that, at least for B √ºchi
144
6 Acceptance Conditions
automata, the deterministic variant is less expressive. Chp. 7 will show that
this is not the case for the other models based on the richer Rabin, Streett,
parity and Muller acceptance conditions.

Moreover, we have seen that Rabin and Streett conditions are dual to each
other, while the parity and the Muller condition is self-dual in the sense that
an automaton of the respective type can easily be obtained for the
complement of the language of a deterministic automaton. For B √ºchi
automata this is not the case: the complement of a B √ºchi acceptance
condition "ùêπ infinitely often" is "ùëÑ ‚àñ ùêπ only finitely often". While this can
generally be expressed by a B √ºchi automaton, making use of
nondeterminism, it does not help for a simple complementation construction
on deterministic automata as we have seen based on the dualities
mentioned above. In order for this to work, we simply introduce the
complement of B √ºchi acceptance formally as yet another automaton model
for languages of ùúî-words and study its expressiveness.
Definition 6.30 A nondeterministic co-B√ºchi automaton (NcoBA) is an A =
(ùëÑ, Œ£, ùëû
, ùõø, ùêπ
ùêº
) just like an NBA. In particular, we have ùêπ ‚äÜ ùëÑ, and this is also said to be
the set of accepting states. The notion of size is as usual, and so is that of
determinism in the transition function, leading to the model of a
deterministic co-B ¬®
uchi automaton
(DcoB A).
An infinite run ùúå = ùëû , ùëû , . . .
0
1
of the NcoBA A is accepting if there is some

ùëñ ‚àà N such that ùëû ùëó ‚àà ùêπ for all ùëó ‚â• ùëñ. I.e. co-B √ºchi acceptance is equivalent
to seeing non-accepting states only finitely often.
The notions of language of an NcoBA, NcoBA-, resp. DcoBA-
recognisability, etc. are defined as usual.
It is important to state explicitly that accepting runs need to be of infinite
length, since the requirement of seeing non-accepting states only finitely
often would trivially apply to any finite run.
Sometimes, acceptance of an NcoBA is defined differently in the literature,
namely via Inf (ùúå) ‚äÜ ùëÑ ‚àñ ùêπ, i.e. the designated set of states ùêπ is not what
needs to be seen eventually only, but what should only be seen finitely often.
This is clearly not an essential difference, though, as the co-B √ºchi
acceptance condition in Def. 6.30
demands Inf (ùúå) ‚äÜ ùêπ. Hence, it is just a matter of taste whether the states in ùêπ
are seen as accepting or as non-accepting. We stick to the former view as it
fits better with the intuition behind the other acceptance conditions as
primarily demanding what needs to happen rather than what must not
happen.
Co-B √ºchi acceptance is of course made for languages that are specified via
finite occurrences of certain patterns in an ùúî-word only.
Example 6.31
ùúî
The following NcoBA A recognises the language ùêø = {ùë§ ‚àà {ùëé, ùëè}
‚à£
‚à£ùë§‚à£ùëè < ‚àû}.
ùëé, ùëè
ùëé

ùëé
6.4 Co-B √ºchi Automata
145
When interpreted as an NBA, its language is ùêø is as well. The reason is that
no non-accepting state is reachable from an accepting state. Hence, any
infinite run of such an automaton will visit accepting states infinitely often
iff it visits non-accepting states only finitely often.
The difference between B √ºchi acceptance and co-B √ºchi acceptance is
made apparent with the following automaton.
ùëé
ùëè
ùëè
ùëé
When regarded as an NcoBA its language is also ùêø. When regarded as an
NBA, its
‚Ä≤
ùúî
language is ùêø ‚à∂= {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëé = ‚àû}, though. Note that these two languages
differ on all words ùë§ such that ‚à£ùë§‚à£ùëé = ‚àû and ‚à£ùë§‚à£ùëè = ‚àû.
The language of an NBA is always a superset of the language of the same
automaton regarded as an NcoBA. This is a simple consequence of the fact
that any infinite run that eventually sees accepting states only, must visit

accepting states infinitely often. The converse is not true, as the previous
example shows.
The constructed duality between the B √ºchi and the co-B √ºchi acceptance
condition can then be used to easily complement deterministic automata
into those of the other type.
Theorem 6.32 For every DBA, resp. DcoBA A over Œ£ of size ùëõ there is a
DcoBA, resp. DBA B of size at most ùëõ + 1 such that ùêø(B) = Œ£ ùúî ‚àñ ùêø(A) .
Proof As usual, by potentially adding one extra non-accepting state that
acts like a trap it is possible to eliminate rejecting finite runs making sure
that every word has exactly one run and that is infinite. It is then easy to see
that the complement of the language of the DBA (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, ùõø, ùëÑ
ùêº
) is the language of the DcoBA (ùëÑ, Œ£, ùëûùêº
‚àñ
ùêπ ) and vice-versa.
‚óª
There is an essential combinatorial difference between B √ºchi and co-B
√ºchi acceptance that will show up in the next chapters: while
determinisation of B √ºchi automata requires an elaborate construction that
genuinely goes beyond the techniques used for automata on finite words
and has to result in automata with a richer acceptance condition,
determinisation of co-B √ºchi automata is possible with a surprisingly
simple and elegant extension of the well-known powerset construction.
Moreover, it turns an NcoBA into a DcoBA, i.e. it does not rely on richer
acceptance conditions.

We state determinisability of co-B √ºchi automata here without a proof and
remark that the very same construction used in the proof of Thm. 9.17 to
turn an alternating B √ºchi automaton into a nondeterministic one, can be
used here as well.
Proposition 6.33 For every NcoBA A of size ùëõ there is a DcoBA B of size at
most ùëõ
3 such that ùêø(B) = ùêø(A) .
146
6 Acceptance Conditions
At last, we study the expressive power of B √ºchi and co-B √ºchi automata. It
is not hard to see that co-B √ºchi automata, just like B √ºchi automata, are
special parity, Rabin and Streett automata. Formulating the corresponding
acceptance conditions is left as an exercise.
Thm. 6.32 may suggest that co-B √ºchi and B √ºchi automata are
incomparable in terms of expressiveness but this is immediately seen not to
be true. Thm. 6.32
states that the deterministic variants are linked through complements, i.e. ùêø
is DBA-recognisable iff ùêø is DcoBA-recognisable. We already know that
NBA recognise exactly the ùúî-regular languages and they are closed under
complements. Hence, if a language ùêø was NBA-recognisable iff its
complement ùêø was NcoBA-recognisable, then NcoBA would recognise all ùúî-
regular languages as well. It is not clear, though, ùúî
how an NcoBA could be built for a simple ùúî-regular language like {ùë§ ‚àà {ùëé,
ùëè}
‚à£
‚à£ùë§‚à£ùëè = ‚àû}, though. This suggests that NcoBA are weaker than NBA, and
this is in fact the case as the next two theorems show.

Theorem 6.34 For every NcoBA A of size ùëõ there is an NBA B of size at
most 2ùëõ
such that ùêø(B) = ùêø(A) .
Proof
‚Ä≤
‚Ä≤
‚Ä≤
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, Œ£,
,
ùêº
). Then B ‚à∂= (ùëÑ
(ùëû ùêº 0), Œî, ùêπ ) where ùëÑ = ùëÑ √ó
‚Ä≤
{0} ‚à™ ùêπ √ó {1} and ùêπ = ùêπ √ó {1}. Hence, B consists of two copies of A and
starts in the first one. The second one only consists of accepting states of A,
though, and these are also the accepting states of B. It is better to consider
this conversely: all non-accepting states in the second component have
been remo ved.
There are three kinds of transitions: B can simulate A in its first component,
it can nondeterministically move to its second component, and it can
continue to simulate A there, provided that it does not get stuck because of
lack of non-accepting states there. We have
Œî

‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
((ùëû, 0), ùëé) ‚à∂= {(ùëû , 0) ‚à£ ùëû ‚àà ùõø(ùëû, ùëé)} ‚à™ {(ùëû , 1) ‚à£ ùëû ‚àà ùõø(ùëû, ùëé) ‚à© ùêπ} , Œî
‚Ä≤
‚Ä≤
((ùëû, 1), ùëé) ‚à∂= {(ùëû , 1) ‚à£ ùëû ‚àà ùõø(ùëû, ùëé ) ‚à© ùêπ} .
It should be clear that B's size is at most 2ùëõ. It remains to be seen that it is
correct, i.e. that ùêø(B) = ùêø(A).
"‚äá" Suppose ùúå = ùëû , ùëû , . . .
0
1
is an accepting run of the NcoBA A on some ùë§ ‚àà Œ£ ùúî.
Thus, there is an ùëñ ‚â• 1 s.t. ùëû ùëó ‚àà ùêπ for all ùëó ‚â• ùëñ. Consider
‚Ä≤
ùúå
‚à∂= (ùëû ,
,
,

,
0 0), . . . , (ùëûùëñ‚àí1 0), (ùëûùëñ 1), (ùëûùëñ+1 1), . . .
which is easily seen to be a run of B on the same ùë§, even an accepting one.
Thus, ùë§ ‚àà ùêø(B).
Note that for this direction, no argument about the separate components is
needed.
This is because of the observation made above that co-B √ºchi acceptance
implies B √ºchi-acceptance but not vice-versa. Hence, the other direction
can be expected to make use of the two-component construction.
‚Ä≤
"‚äÜ" Suppose that ùë§ ‚àà ùêø(B), i.e. there is an accepting run ùúå = (ùëû , ùëñ
, ùëñ
0
0), (ùëû1
1), . . .
of B on ùë§. By inspection of Œî we see that ùëñ0 = 0 and ùëñ ùëó+1 ‚â• ùëñ ùëó for all ùëó ‚â• 0.
Since only states of the form (ùëû, 1) are accepting, the run is indeed of the
form
6.4 Co-B √ºchi Automata
147
‚Ä≤
ùúå
= (ùëû ,

,
,
,
0 0), . . . , (ùëûùëñ‚àí1 0), (ùëûùëñ 1), (ùëûùëñ+1 1), . . .
‚Ä≤
+
ùúî
for some ùëñ ‚â• 1, i.e. ùúå ‚àà (ùëÑ √ó {0}) (ùêπ √ó {1}) . But then we must have ùëû ùëó ‚àà ùêπ
for all ùëó ‚â• ùëñ. Hence, the projection ùúå = ùëû , ùëû , . . .
0
1
onto the first components is a run of
A on ùë§ that satisfies the co-B √ºchi acceptance condition ùêπ, and we have ùë§
‚àà A.
‚óª
The converse direction is not true; NBA are indeed more expressive than
NcoBA.
ùúî
The language ùêø = {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëè = ‚àû} mentioned just before Thm. 6.34 is an
example.

Theorem 6.35 There are ùúî -regular languages that cannot be recognised by
an NcoBA.
Proof
ùúî
Take the language ùêø = {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëè = ‚àû}. Clearly, it is ùúî-regular.
Suppose we had ùêø = ùêø(A) for some NcoBA A = (ùëÑ, {ùëé, ùëè}, ùëû , ùõø, ùêπ
ùêº
). Let ùëõ ‚à∂= ‚à£ùëÑ‚à£
ùëõ
ùúî
and consider the word ùë§ = (ùëé ùëè) . Obviously, ùë§ ‚àà ùêø so there is an
accepting run ùúå = ùëû , ùëû , . . .
0
1
of A on ùë§. According to co-B √ºchi acceptance, there is an ùëñ ‚àà N s.t.
ùëû ùëó ‚àà ùêπ for all ùëó ‚â• ùëñ.
W.l.o.g. we can assume that ùëñ = 1 + (ùëõ + 1) ‚ãÖ ùëò for some ùëò ; simply choose
ùëñ to be large enough. Thus, we have ùúå =
ùëû
, ùëé, ùëû

, . . . , ùëû
, ùëè, ùëû , ùëé, ùëû
, . . . , ùëû
, ùëé, ùëû
, ùëè, ùëû
, ùëé, ùëû
, . . .
0
1
ùëñ‚àí1
ùëñ
ùëñ+1
ùëñ+ùëõ‚àí1
ùëñ+ùëõ
ùëñ+ùëõ+1
ùëñ+ùëõ+2
Since (ùëñ + ùëõ) ‚àí ùëñ + 1 = ùëõ + 1 > ùëõ there must be ùëó , ‚Ñé such that ùëñ ‚â§ ùëó < ‚Ñé ‚â§ ùëñ
+ ùëõ and ùëû ùëó = ùëû‚Ñé. Since between ùëû ùëó and ùëû‚Ñé, A has only been reading
symbols ùëé, and all states are accepting by assumption, we can use a
pumping argument to construct an
‚Ä≤

accepting run ùúå =
ùúî
ùëû
, ùëé, ùëû
, . . . , ùëû
, ùëè, ùëû , . . . , ùëû
, . . . , ùëé, ùëû
0
1
ùëñ‚àí1
ùëñ
ùëó (, ùëé , ùëû ùëó +1
‚Ñé )
‚àó
ùúî
on a word of the form (ùëé + ùëè) ùëé , contradicting the assumption that ùêø(A) =
ùêø. ‚óª
There is also another argument for the claim in Thm. 6.35 that relies on the
stated, but yet formally unproven determinisability of NcoBA. Suppose that
ùêø =
ùúî

{ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëè = ‚àû} was NcoBA-recognisable. So it would also be DcoBA-
recognisable. According to Thm. 6.32, its complement would be DBA-
recognisable, ùúî
but the complement is ùêø = {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëè < ‚àû} and this is not DBA-
recognisable according to Thm. 5.24.
Since ùêø is clearly NcoBA-recognisable, the class of NcoBA-recognisable
languages is not closed under complements. Since it is defined via a
nondeterministic automaton model, it is easily seen to be closed under
unions. Closure under intersections also holds, and the construction is,
again, simpler than the corresponding one for NBA. The proof is left as an
exercise.
Theorem 6.36 Let Aùëñ be NcoBA of size ùëõùëñ for ùëñ ‚àà {1, 2} .
a) There is an NcoBA B
ùëõ
ùêø
1 of size at most
1+ùëõ 2+1 such that
(B1) = ùêø(A1)‚à™ùêø(A2) .
b) There is an NcoBA B2 of size at most ùëõ1 ‚ãÖ ùëõ2 such that ùêø(B2) = ùêø(A1) ‚à©
ùêø(A2) .
148

6 Acceptance Conditions
Sometimes it is worth considering closure properties for different kinds of
automata. Suppose some language ùêø was described as the intersection
between two
‚Ä≤
‚Ä≤‚Ä≤
languages ùêø and ùêø , and the task is to construct an automaton for ùêø.
Assume fur-
‚Ä≤‚Ä≤
thermore that ùêø
was easily seen to be co-B √ºchi-recognisable. With a result stating that the
intersection of a co-B √ºchi-recognisable language with a language of some
other type can be recognised by an automaton of that other type, we may be
able to construct an automaton for ùêø modularly.
This possibility is of course not restricted to co-B √ºchi automata, and a
properly exhaustive study would have to tell, for each (binary) Boolean
operation and each three automaton types, what the simplest construction is
for an automaton of the third type, given automata of the first and second
types.
Here we only consider one such case, namely that of the intersection of a
parity-recognisable language with a co-B √ºchi-recognisable one. The
reason simply is that this is needed later on in Chp. 13. Proof details are left
as an exercise.
Lemma 6.37 For every NPA A of size ùëõ and index ùëò and NcoBA B of size ùëö
there is an NPA C of size ùëõùëö and index at most ùëò + 1 such that ùêø(C) =
ùêø(A) ‚à© ùêø(B) .
6.5 Transition-Based Acceptance

A natural variant of acceptance by infinite occurrence is concerned with
transitions in runs rather than states. We briefly investigate automata
models that use such acceptance conditions to see that their expressive
power remains the same.
It is convenient to see the transition table of a finite automaton as a relation
ùëÑ
ùõø ‚äÜ ùëÑ √ó Œ£ √ó ùëÑ rather than a function ùõø ‚à∂ ùëÑ √ó Œ£ ‚Üí 2 . Mathematically, there is
of course no conceptual difference but the former allows us to easily speak
about sets of transitions, simply as subsets of the transition relation.
Definition 6.38 A nondeterministic B√ºchi-edge automaton (NBAe) is an A =
(ùëÑ, Œ£, ùëû
, ùõø, ùêπ
ùëé
. . .
ùêº
) just like an NBA but with ùêπ ‚äÜ ùõø. A run of an NBAe on a word ùë§ = ùëé0 1
‚àà
Œ£ùúî is an infinite sequence ùúå = ùëû , ùëé , ùëû , ùëé , . . .
0
0
1
1
as usual. We write Inf e(ùúå) for the

set of transitions being used infinitely often in ùúå, i.e.
Inf e(ùúå) ‚à∂= {(ùëû, ùëé, ùëù) ‚àà ùõø ‚à£ ‚àÄùëñ ‚â• 0‚àÉ ùëó ‚â• ùëñ.ùëû = ùëû , ùëé
, ùëù
ùëñ
= ùëéùëñ
= ùëû ùëñ+1} .
Such a run ùúå is accepting if Inf e(ùúå) ‚à© ùêπ ‚â† ‚àÖ.
The language of an NBAe is, as usual, the set of words for which there is an
accepting run. Other notions like size etc. apply here equally.
Example 6.39
ùúî
Consider the language ùêø = {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëé = ‚àû = ‚à£ùë§‚à£ùëè }. Note
that a word over {ùëé, ùëè} contains both ùëé and ùëè infinitely often iff it contains
infinitely many subwords of the form ùëéùëè or ùëèùëé. In fact, it suffices to
demand that only one of them occurs infinitely often. ùêø is accepted by the
NBAe
6.5 Transition-Based Acceptance
149
ùëé
ùëè
ùëè

0
1
ùëé
where double arrows are used to denote accepting transitions.
Ex. 6.39 shows a potential appeal of edge-based acceptance conditions. The
language ùêø from this example is recognised by an NBAe of size 2. This is
smaller than any NBA for this language.
There is of course no reason not to transfer all the other acceptance
conditions based to the setting in which the infinite occurrence of edges
determines whether or not a run is accepting. A nondeterministic co-B ¬®
uchi-edge automaton (NcoBAe)
is an A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, ùëé
, ùëû
, ùëé
, . . .
ùêº
) just like an NBAe, but a run ùúå = ùëû0
0
1
1
is

accepting if Inf e(ùúå) ‚äÜ ùêπ. A nondeterministic parity-edge automaton (NPAe)
is an A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) with Œ© ‚à∂ ùõø ‚Üí N, and accepting runs are those in which
max{Œ©(ùëí) ‚à£ ùëí ‚àà Inf e(ùúå)} is even. Nondeterministic Rabin-edge, Streett-edge
and Muller-edge automata (NRAe / NSAe / NMAe) and their accepting runs
are defined analogously. The index measures the size of the acceptance
condition again.
6.5.1 From States to Edges
Automata with edge-based acceptance conditions may be more succinct
than those with state-based acceptance conditions, but their expressiveness
does not exceed that of ùúî-regularity. In fact, there are conceptually simple
transformations between the two variants for each acceptance condition.
We start with the even simpler one, turning a state-based condition into an
edge-based on. It is based on the observation that in a finite automaton
over a finite alphabet, every state can only have a bounded number of
outgoing transitions. It is then possible to shift the acceptance condition
from states to edges going out of the respective states. It should be clear
that a run visiting some state ùëû infinitely often must necessarily see some
transition (ùëû, ùëé, ùëù) infinitely often for some ùëé ‚àà Œ£ and state ùëù. However, note
that it need not see all of them infinitely often.
Theorem 6.40 For every NcoBA / NBA / NPA / NRA / NSA A of size ùëõ and
index ùëò (where applicable) there is an NcoBA e / NBA e / NPA e / NRA e /
NSA e B of size ùëõ
and index ùëò such that ùêø(B) = ùêø(A) .
Proof We carry this out for the case of NRA and remark that the
construction, when restricted to NPA, NBA and NcoBA that can be seen as
special NRA, yields NPAe, resp. NBAe or NcoBAe. Moreover, the
construction for the dual model of NSA is done analogously.

Let A = (ùëÑ, Œ£, ùëû , ùõø,
, ùêπ
, ùêπ
ùêº
F ) be an NRA with F = {(ùê∫1
1), . . . , (ùê∫ ùëò
ùëò )}. Define
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
B ‚à∂= (ùëÑ, Œ£, ùëû , ùõø,
, ùêπ
, ùêπ
ùêº
F ) with F ‚à∂= {(ùê∫
), . . . , (ùê∫
)} and

1
1
ùëò
ùëò
150
6 Acceptance Conditions
‚Ä≤
ùê∫
‚à∂= {(ùëû, ùëé, ùëù) ‚àà ùõø ‚à£ ùëû ‚àà ùê∫
ùëñ
ùëñ } ,
‚Ä≤
ùêπ
‚à∂= {(ùëû, ùëé, ùëù) ‚àà ùõø ‚à£ ùëû ‚àà ùêπ
ùëñ
ùëñ } .
The claims on the size and index of B are clear. It remains to be seen that
we have ùêø (B) = ùêø(A).
"‚äá" Let ùúå = ùëû , ùëé , ùëû , ùëé , . . .
ùëé

. . .
0
0
1
1
be an accepting run of A on ùë§ = ùëé0 1
, i.e. there
is some ùëñ ‚àà {1, . . . , ùëò} such that Inf (ùúå) ‚à© ùê∫ùëñ ‚â† ‚àÖ and Inf (ùúå) ‚à© ùêπùëñ = ‚àÖ.
Hence, there is ùëû ‚àà ùê∫ùëñ such that ùëû ‚àà Inf (ùúå).
Clearly, ùúå is also a run of B on ùë§. Moreover, ‚à£{(ùëé, ùëù) ‚àà Œ£ √óùëÑ ‚à£ (ùëû, ùëé, ùëù) ‚àà ùõø}
‚à£ < ‚àû.
Thus, if ùëû = ùëû
, ùëé
, ùëû
ùëó for infinitely many ùëó then there must be ùëé, ùëù such that (ùëû ùëó
ùëó
ùëó +1) =
‚Ä≤
(ùëû, ùëé, ùëù) for infinitely many ùëó , i.e. (ùëû, ùëé, ùëù) ‚àà Inf e(ùúå), and (ùëû, ùëé, ùëù) ‚àà ùê∫ùëñ
by con-
‚Ä≤

struction. Hence, Inf e(ùúå) ‚à© ùê∫ ‚â† ‚àÖ
ùëñ
.
‚Ä≤
On the other hand, suppose there was some (ùëû, ùëé, ùëù) ‚àà ùêπ ‚à©
ùëñ
Inf e(ùúå). Then we
would have ùëû ‚àà Inf (ùúå) ‚à© ùêπùëñ. Hence, through the assumption Inf (ùúå) ‚à© ùêπùëñ =
‚àÖ we get
‚Ä≤
Inf e(ùúå) ‚à© ùêπ = ‚àÖ
ùëñ
which shows that ùúå is also an accepting run of B on ùë§.
"‚äÜ" Take a run ùúå = ùëû , ùëé , ùëû , ùëé , . . .
0
0
1
1
and suppose there is an ùëñ ‚àà {1, . . . , ùëò} such
‚Ä≤

‚Ä≤
that Inf e(ùúå) ‚à© ùê∫ ‚â† ‚àÖ
= ‚àÖ
ùëñ
and Inf e(ùúå) ‚à© ùêπùëñ
. Analogously to the part above, we get
that there must be some ùëû ‚àà Inf (ùúå) with ùëû ‚àà ùê∫ùëñ, and also Inf (ùúå) ‚à© ùêπùëñ = ‚àÖ,
showing that ùúå is also an accepting run of A on the same underlying word.
‚óª
Note that NMA were not mentioned in the previous theorem. It is not that
the corresponding result does not hold for Muller automata. We state it
separately simply because the construction does not preserve the
automaton's index.
Theorem 6.41 For every NMA A of size ùëõ there is an NMA e B of size ùëõ
such that ùêø (B) = ùêø(A) .
As stated above, infinite traversal of a state does not imply infinite traversal
of all its outgoing transitions. Remember that a Muller condition is not
necessarily closed under supersets or subsets. Hence, we may have to list
every possibility to traverse outgoing transitions from some state
separately. However, we can make use of the fact that a Muller-accepting
run will eventually only see transitions between states of the same
acceptance component. Details of a formal construction are left as an
exercise.
6.5.2 From Edges to States
So transition-based acceptance is at least as powerful as state-based
acceptance. We now turn to the other part of the expressiveness study,

showing that transition-based acceptance is not more powerful.
It should be clear that the na¬®ƒ±ve approach of splitting every transition into
two, inserting an intermediate state that is uniquely traversed by the two
halves of that transition, cannot work as this would require the automaton
with the state-based acceptance condition to simulate the transition-based
acceptance condition with
6.5 Transition-Based Acceptance
151
ùëé
ùëé
(0, ùëé, 0)
(1, ùëé, 0)
ùëé
ùëè
‚Ä≤
ùëû
ùëè
ùëé
ùêº
ùëé
ùëè
(

ùëè
0, ùëè, 1)
(1, ùëè, 1)
ùëè
Fig. 6.4 NBA obtained from an NBAe for the language described in Ex.
6.44.
unbounded delays. Instead, the trick is to shift transitions by one half,
regarding a run ùëû
, ùëé
, ùëû
, ùëé
, . . .
, ùëé
, ùëû
, ùëé
, ùëû
0
0
1
1
as an infinite sequence (ùëû0

0
1), (ùëû1
1
2), . . . of transitions.
Again, we formulate the corresponding translation result for one
acceptance condition, namely the Rabin one, and leave it as an exercise to
prove a corresponding statement for the other acceptance conditions.
Theorem 6.42 For every NRA e A of size ùëõ and index ùëò with ùëí many
transitions there is an NRA B of size ùëí + 1 and index ùëò such that ùêø(B) =
ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø,
, ùêπ
, ùêπ
ùêº
F ) be an NRAe with F = {(ùê∫1
1), . . . , (ùê∫ ùëò
ùëò )}
‚Ä≤
‚Ä≤
and ùê∫ , ùêπ
, Œî,
ùëñ

ùëñ
‚äÜ ùõø for all ùëñ = 1, . . . , ùëò . Let B ‚à∂= (ùõø ‚à™ {ùëû }, Œ£, ùëû
F ) where, for all
ùêº
ùêº
‚Ä≤
‚Ä≤
(ùëû, ùëé, ùëù), (ùëû , ùëè, ùëù ) ‚àà ùõø and ùëê ‚àà Œ£ w e have
‚Ä≤
‚Ä≤
‚Ä≤
((ùëû, ùëé, ùëù), ùëê, (ùëû , ùëè, ùëù )) ‚àà Œî
iff
ùëù = ùëû and ùëê = ùëè
‚Ä≤
, ùëé, ùëù) ‚àà
and for all (ùëûùêº
ùõø we have (ùëû , ùëé, (ùëû , ùëé, ùëù
ùêº
)) ‚àà Œî

ùêº
.
Correctness of this construction follows immediately from the observation
that ùúå = ùëû , ùëé , ùëû , . . .
ùëé
. . .
0
0
1
(with ùëû0 = ùëûùêº ) is an accepting run of A on ùë§ = ùëé0 1
iff
‚Ä≤
‚Ä≤
ùúå
= ùëû , ùëé , (ùëû , ùëé , ùëû
, (ùëû , ùëé , ùëû
ùêº
0
ùêº
0

1), ùëé1
1
2
2), . . .
‚Ä≤
is an accepting run of B on the same ùë§, because Inf (ùúå ) = Inf e(ùúå) and
therefore, for any ùëñ ‚àà {1, . . . , ùëò } we hav e
‚Ä≤
‚Ä≤
Inf e(ùúå) ‚à© ùê∫ùëñ ‚â† ‚àÖ and Inf e(ùúå) ‚à© ùêπùëñ = ‚àÖ iff Inf (ùúå ) ‚à© ùê∫ùëñ ‚â† ‚àÖ and Inf (ùúå ) ‚à© ùêπùëñ
= ‚àÖ .
The claims on size and index are obvious.
‚óª
Note that this construction preserves determinism, i.e. it turns a
deterministic automaton with a transition-based Rabin acceptance
condition into a deterministic Rabin automaton.
Corollary 6.43 For every deterministic NRA e A of size ùëõ and index ùëò with
ùëí many transitions there is a DRA B of size ùëí + 1 and index ùëò such that
ùêø(B) = ùêø(A) .
152
6 Acceptance Conditions
Example 6.44 Remember that a B√ºchi acceptance condition ùêπ is a Rabin
acceptance condition {(ùêπ, ‚àÖ)}, and this holds regardless of whether ùêπ is a
set of states or set of transitions. Hence, we can regard the NBAe from Ex.

6.39 as an NRAe and translate it into the NRA shown in Fig. 6.4 that
equally happens to be an NBA, recognising the language ùêø of all words
over {ùëé, ùëè} that contain both ùëé and ùëè infinitely often.
To see that this NBA correctly accepts the designated language note that
any path from any accepting state to itself needs to read both the letter ùëé
and the letter ùëè.
Hence, it can only accept words that contain infinitely many symbols ùëé and
infinitely many symbols ùëè. On the other hand, each state has an ùëé- and a ùëè-
successor. Hence, ùúî
every word from {ùëé, ùëè}
can fully be processed by this NBA, so it does not just
accept a subset of ùêø.
As the example suggests, the translation can be specialised to B √ºchi- and
parity automata. It can also be used to transform transition-based Streett-
automata into state-based ones, and it can be used to do the same for
Muller conditions as well.
Details are left as an exercise.
6.6 Expressiveness of Finite Automata on Infinite Words
The essence of this chapter can be summarised as follows: the class of ùúî-
regular languages is very robust under any choice of acceptance condition.
Any model of finite automata with an acceptance condition based on the
infinite occurrence of states (or in fact transitions) recognises the ùúî-regular
languages, with one exception: co-B √ºchi automata are strictly weaker. With
the respective results on the other automaton models we collectively obtain
the following equi-expressiveness result.
Corollary 6.45 Let ùêø ‚äÜ Œ£ùúî . The following statements are equiv alent.
a) ùêø is ùúî -regular.

g) ùêø is NBA e -recognisable.
b) ùêø is NBA-recognisable.
h) ùêø is NPA e -recognisable.
c) ùêø is NPA-recognisable.
i) ùêø is NRA e -recognisable.
d) ùêø is NRA-recognisable.
j) ùêø is NSA e -recognisable.
e) ùêø is NSA-recognisable.
k) ùêø is NMA e -recognisable.
f) ùêø is NMA-recognisable.
Equivalence between (a) and (b) was shown in Cor. 5.14. The way that
equivalence amongst these and the other statements is achieved is shown in
Fig. 6.5.
Bibliographic Notes
Clearly, three of the automata models discussed here - besides B √ºchi
automata - are also named after their inventors. Rabin needed a richer
acceptance condition than
Bibliographic Notes for Chapter 6
153
Exc. 73
Thm. 6.24
NMA

NMAe
Exc. 75
Cor
Ex
.
74
6.22
c.
. 6.22
c.
74
Cor
Ex
Thm.
Thm. 6.40
NSA
6.28
NRA
NRAe
NSAe

Thm. 6.42
Thm.
Ex
6.15
c.
74
6.15
74
c.
Ex
Thm.
Thm. 6.40
NPA
NPAe
Exc. 75
Thm.
Thm.
6.12
74
c.

Ex
6.13
Thm. 6.40
74
NBA
NBAe
c.
Ex
Exc. 75
Ex
70
c. 74
c.
6.34
Ex
Thm.
Thm. 6.40
NcoBA
NcoBAe
Exc. 75

Fig. 6.5 Expressiveness of models of finite automata on infinite words.
B √ºchi's in the context of finite automata accepting languages of trees
rather than words [Rab69]. As we will see later, Rabin automata are in fact
more expressive there than B √ºchi automata. The motivation came, as in B
√ºchi's case, from logic: Rabin proved complementation closure of Rabin
tree automata which was the key part in a decidability result for a version
of Monadic Second-Order Logic interpreted over trees.
Streett automata were also introduced as a tool for deciding formal logics
[Str82], but there the logic under foremost consideration was Propositional
Dynamic Logic (PDL). As it turns out, PDL [FL79] and related formalisms,
i.e. temporal logics like
‚àó
CTL [EC82] and CTL [EH86], or modal fixpoint logics like the modal ùúá-
calculus
[Koz83], used primarily for purposes of program specification and
verification, are (relatively) easily seen to be fragments of MSO interpreted
over trees, cf. Chp. 14.
Hence, it is not too surprising that Streett automata also fall into the
categories studied in this context.
The conceptual hierarchy given by the translations of one acceptance
condition into another suggests that the corresponding automata models
may have been introduced in the same chronological order, starting from
the simplest and most natural one and progressing on to richer ones. This is
not true, though. Muller automata were introduced before Rabin and Streett
automata, for example, in the context of specifications of the behaviour of
digital circuits [Mul63]. The relative richness of certain acceptance
conditions compared to others has been used and observed over the years,
though. For example, McNaughton showed that B √ºchi automata could
154

6 Acceptance Conditions
be determinised into Muller automata [McN66]. Determinisation will
explicitly be studied in the next chapter; we therefore also refer to the
bibliographic notes there, since the issue of determinisation is tightly linked
to questions concerning acceptance conditions.
There is also plenty of work that gives an overview of automata
constructions transforming between different models or studies them in
detail, cf. the corresponding chapter in the book by Esparza and Blondin
[EB23, Chp. 10], the handbook articles by Thomas [Tho97] and Kupferman
[Kup18], or overview articles by Farwer [Far02]
and Boker [Bok18].
Exercises
Exercise 58 Show that merging states of an NRA that recognise the same
language does not generally preserve the language of the NRA. Hint:
Consider the language ùêø
of all words over {ùëé, ùëè} that contain infinitely many symbols ùëè. It is easy to
construct a two-state NRA A such that ùêø(A) = ùêø, regardless of which one of
them is the initial state. Now suppose that these would be merged. List
possible Rabin pairs and analyse each possibility to build a Rabin
acceptance condition from them.
Exercise 59 Show how to translate an NRA directly into an NBA without
taking a detour via NMA. Hint: Amend the translation from NPA to NBA
accordingly.
Exercise 60 A min-parity automaton is an A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) just like a max-parity
NPA considered here. A run ùúå = ùëû , ùëû , . . .

0
1
of such a min-parity NPA is accepting if
min{Œ©(ùëû) ‚à£ ùëû ‚àà Inf (ùúå)} is e ven.
a) Show that a language is recognisable by a max-parity NPA of size ùëõ and
index ùëò iff it is recognisable by a min-parity NPA of size ùëõ and index ùëò .
b) Refine the statement of part (a) and prove it, so that it yields a bound on
the finer measure of indices as intervals [ùëò , ùëö]. I.e. if ùêø is accepted by a
max-parity NPA
‚Ä≤
‚Ä≤
of index [ùëò , ùëö], what can be said about the index [ùëò , ùëö ] of a min-parity
NPA recognising ùêø, and vice-versa?
Exercise 61 Prove Cor. 6.10 by making use of Lemma 6.9, possibly multiple
times.
Exercise 62 Construct a three-state NBA for the language ùêø used in Ex.
6.14 by collapsing states in the four-state NBA at the end of this example.
Explain why such a collapse is possible without changing the NBA's
language.
Exercise 63 Prove the converse of Lemma 6.21, i.e. show that any Muller
condition ùëÑ
F ‚äÜ 2
for some finite state set ùëÑ can be expressed as an acceptance formula Œ¶F .

Exercise 64 Reduce the state space of the NBA shown in Fig. 6.3 by
successively merging states. Argue in each case why this merging does not
change the language, even though merging states of NBA does not preserve
an NBA's language in general. As a second measurement, remove parts
whenever this only deletes redundant accepting paths.
Exercises for Chapter 6
155
Exercise 65 Let A be a DMA of size ùëõ and index ùëò recognising ùêø ‚äÜ Œ£ùúî.
Construct a DMA recognising Œ£ ùúî ‚àñ ùêø and state bounds on its size and inde
x.
Exercise 66 For ùëõ ‚â• 2 let Œ£
, . . . ùëé
, ùëè
, . . . , ùëè
ùëõ ‚à∂= {ùëé 1
ùëõ
1
ùëõ } and
ùëõ
ùëõ
ùêø ùëõ
‚à∂= {ùë§ ‚àà Œ£ ùúî ‚à£ ‚à£{ùëñ ‚à£ ùëé
‚åâ

‚åã} .
ùëõ
ùëñ
‚àà Inf (ùë§)}‚à£ = ‚åà
and ‚à£{ùëñ ‚à£ ùëèùëñ ‚àà Inf (ùë§)}‚à£ = ‚åä
2
2
a) Build an NMA for ùêø3 using the construction in the proof of Thm. 6.23.
Determine, in particular, its index.
b) Do the same for ùêøùëõ for arbitrary ùëõ ‚â• 2.
Exercise 67 Explain how to obtain an automaton recognising the
intersection of the languages of two given automata, for NPA, NRA and
NSA, respectively. Hint: Start with NSA for which this can be done similarly
to the construction for NMA. For NRA and NPA one may have to take a
detour through other models.
Exercise 68 Is the language of all words over {ùëé, ùëè} that contain the
subword ùëéùëè
infinitely often or contain the subword ùëèùëé infinitely often, NcoBA-
recgnisable? If so, construct a corresponding automaton. Otherwise prove
that this is impossible.
Exercise 69 Prove Thm. 6.36.
Exercise 70 Show how a co-B√ºchi acceptance condition can be seen as a
special case of each of a parity, Rabin, Streett and Muller condition. In
each case, determine the minimal index of the target model when
translating co-B √ºchi automata into it.

Exercise 71
a) Prove Lemma 6.37. Hint: A simple product construction suffices.
All that is needed is an assignment of priorities to state pairs which
essentially preserves the priorities of the underlying NPA but only makes
them count when the underlying NcoBA eventually only traverses through
accepting states.
b) Give a direct construction for the intersection of an NPA- and an NBA-
recgnisable language. Hint: A pure product construction does not suffices.
However, it can be extended in order to remember the greatest priority seen
by the underlying NPA on each segment of a word between accepting states
of the NBA.
c) Explain whether the constructions in (a) and (b) preserve determinism,
i.e. yield DPA when applied to a DPA and a DcoBA, resp. DBA.
Exercise 72
ùúî
Show that there is no NBA of size 2 that recognises ùêø = {ùë§ ‚àà {ùëé, ùëè}
‚à£
‚à£ùë§‚à£ùëé = ‚àû = ‚à£ùë§‚à£ùëè }.
Exercise 73 Prove Thm. 6.41, i.e. show how to translate an NMA into an
equivalent NMAe. Give an upper bound on the blowup in index.
Exercise 74 Prove that
a) every NcoBAe-recognisable language is NBAe-recognisable,
b) every NBAe- or NcoBAe-recognisable language is NPAe-recognisable,
156

6 Acceptance Conditions
c) every NPAe-recognisable language is both NRAe- and NSAe-
recognisable, and d) every NRAe- or NSAe-recognisable language is
NMAe-recognisable.
Hint: Simply check that the corresponding embeddings of the state-based
acceptance conditions can be reused for transition-based ones.
Exercise 75 Give translations from transition-based B√ºchi, co-B√ºchi,
parity, Streett and Muller automata into the corresponding state-based
ones, along the lines of Thm. 6.42. Estimate the incurring blowup in size
and index.
Chapter 7
Determinisation
This title's chapter may seem paradoxical in the context of Chapter 5 where
is was shown that deterministic B √ºchi automata are strictly weaker than
nondeterministic
‚àó
ùúî
ones. In particular, the language (ùëé + ùëè) ùëé
cannot be recognised by a DBA, cf.
Thm. 5.24. Thus, there is no determinisation procedure for NBA, at least
none that yields equivalent DBA. While equivalence of the resulting

automaton with regards to the original one is usually the entire purpose of
any transformation like a determinisation procedure, Chp. 6 provides us
with several other models of finite automata on infinite words for which the
example of the non-DBA-definable language
‚àó
ùúî
(ùëé + ùëè) ùëé
fails. It is easy to construct deterministic parity, Rabin, Streett and Muller
automata that recognise this language. Hence, it is reasonable to ask
whether determinisation for NBA may indeed be possible at the expense of
employing a richer acceptance condition on the deterministic side. The
answer is yes. This chapter presents a construction that is based on the
famous so-called Safra construction which solved the long-standing open
problem of NBA determinisation.
7.1 The Inadequacy of Powerset-Based Determinisation
‚àó
ùúî
Reconsider the example of the non-DBA-definable language (ùëé + ùëè) ùëé
mentioned
above. It is recognised by the NBA shown on the left below, and it may be
tempting, or at least informative, to simply "determinise" it via the
powerset construction into the finite-state automaton shown on the right
below.
ùëé, ùëè
ùëé

ùëè
ùëé
ùëé
ùëé
0
1
0
01
ùëè
It is obviously deterministic, and it should be clear that none of the four
possible
‚àó
ùúî
acceptance sets ‚àÖ, {0}, {01}, {0, 01} makes it accept (ùëé + ùëè) ùëé
as a DBA.
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
157
M. Hofmann and M. Lange, Automata Theory and Logic,
https://doi.org/10.1007/978-3-662-72154-4_7

158
7 Determinisation
{
ùëè
0}
‚àÖ
ùëé , ùëè
ùëé
0
1
ùëé , ùëè
ùëé
ùëé
ùëè
ùëè
{1}
{0, 1}
ùëé
ùëé
Fig. 7.1 NBA (left) and its powerset automaton (right).

However, it can be given a parity acceptance condition, for instance Œ©(0) =
1, Œ©(01) = 0 (and therefore also a Rabin or Muller condition) to accept this
language.
It is not even difficult to give it a Streett condition, namely {({0}, ‚àÖ)}, for
that purpose.
Can the powerset construction be refined by equipping it with a parity,
Rabin, Streett or Muller condition so that it yields equivalent deterministic
automata in general? Note that while automata with any of these
acceptance conditions can be turned into any others, and this even
preserves determinacy, it is only the transformations from parity into Rabin
or Streett, and from these into Muller automata that do not involve a
blowup in the state space. This is relevant for the question under
consideration here. For instance, perhaps it was possible to define a Rabin
acceptance condition on the basis of the pure powerset construction but not
a parity condition.
In other words, if the answer to this question was positive, the strongest
result would be given by a powerset-based translation from NBA to DPA.
But a negative answer is strongest in terms of a Muller condition. It is
indeed possible to answer this question to the negative in this form. We give
an example of an NBA such that no Muller condition on the powerset
automaton yields a DMA that is equivalent to the original NBA.
Consequently, there is also no way to equip this powerset automaton with a
parity, Rabin or Streett condition without changing its language.
Theorem 7.1 There is an NBA A such that for every DMA B whose state
space and transition graph results from A using the powerset construction,
we have ùêø(B) ‚â†
ùêø (A) .
Proof Consider the NBA A shown in Fig. 7.1 on the left. The part on the
right shows the automaton that is obtained from A via the powerset
construction. All that remains to be done is to see that no Muller condition,
in terms of a set of subsets of its state

{
‚àó
ùúî
space 2 0,1} yields a DMA that is equivalent to A. Note that ùêø(A) = (ùëé(ùëé +
ùëè) ùëé) consists only of words that contain the pattern ùëéùëé infinitely often.
So let B be a DMA with state space and transitions as shown in Fig. 7.1 on
the ùúî
right with a fictitious Muller acceptance set F . Now consider ùë§ = ùëé(ùëéùëéùëè) .
We have ùë§ ‚àà ùêø(A). Thus, B must have an accepting run on ùë§. Since it is
deterministic and complete, there is exactly one run of B on ùë§, and this one
visits states {1} and
7.1 The Inadequacy of Powerset-Based Determinisation
159
{0, 1} infinitely often. So we have {{1}, {0, 1}} ‚àà F . But then we would
also get ùúî
ùúî
ùëé(ùëé ùëè)
‚àà ùêø(B), even though ùëé(ùëéùëè)
/
‚àà ùêø(A).
‚óª
Thus, NBA not only cannot be transformed into DBA by the powerset
construction but such a transformation also fails for all other known
acceptance conditions.

While the example used in the previous theorem is sufficient to prove such a
strong statement, it does not exemplify well what the problem with the
powerset construction really is. In order to examine this closer we remark
that the powerset construction always yields an overapproximation to the
language of an NBA. Thus, it is complete but unsound in the sense that the
resulting automaton accepts all the words that need to be accepted but
possibly more. To analyse in more detail what is going wrong we consider
another example.
Example 7.2 Let A1 and A2 be NBA over the unary alphabet Œ£ = {ùëé} as
follows.
ùëé
ùëé
ùëé
ùëé
ùëé
A1
0
1
A2
0
1
ùúî
Obviously, we have ùêø(A1) = {ùëé } and ùêø(A2) = ‚àÖ since no run in A2 can see
accepting states infinitely often.

The key insight here is that both lead to the same automaton B under the
powerset construction, namely the following.
ùëé
{0}
{0, 1}
ùëé
In order to disambiguate language when speaking about states in an NBA
and in a corresponding powerset automaton, we also use the terms
microstate for states of the NBA and macrostate for states of the powerset
automaton.
When tracing the origins of each microstate through a sequence of
macrostates forming a run of the powerset automaton, it becomes apparent
that the powerset automaton is not refined enough to distinguish between
sequences of microstates ùúî
that form runs and those that do not. Clearly, there is only one run of B on
ùëé , and ùúî
it is {0}({0, 1}) . However, when revealing the structure of the macrostates
in this run in terms of the origins of each of the microstates contained in
them, we notice a difference. When the underlying NBA is A1 then this run
is the following, called ùúå1
for future reference.
0
0
0
0

0 ‚ãØ
1
1
1
1
1 ‚ãØ
If, however, the underlying NBA is A2 then there are fewer connections
between the microstates because now the only reason for microstate 1 to be
included in macrostate
{0, 1} is the fact that it is an ùëé-successor of microstate 0, whereas before it
was an ùëé-successor of both 0 and 1. This forms the following run ùúå2.
160
7 Determinisation
0
0
0
0
0 ‚ãØ
1
1
1

1
1 ‚ãØ
While ùúå1 and ùúå2 are the same run of B in terms of a sequence of
macrostates, their ùúî
difference is that ùúå2 contains only a single infinite run of microstates,
namely 0
and that is not accepting. On the other hand, ùúå1 contains infinitely many
runs of ùúî
ùëõ
ùúî
microstates, namely 0
(which is not accepting) and 0 1
for any ùëõ ‚â• 1 which are
all accepting.
This example, together with the observation stated above about the pure
powerset construction yielding on overapproximation to the language of the
underlying NBA, suggests that a determinisation procedure could be built
by refining the powerset construction in a way that reveals the inner
structure of connections between microstates.
In other words, macrostates must not simply be sets of microstates but be
built using some more advanced data structure which records the origins of
microstates in the deterministic automaton's transitions so that acceptance
in this automaton can be linked to the existence of an accepting run of
microstates through the corresponding sequence of macrostates. The key in
the Safra construction - to be presented next -

is exactly the choice of a suitable tree-like data structure that refines simple
sets of microstates accordingly.
7.2 Trees and KÀùonig's Lemma
7.2.1 A Formal Model of Trees
Trees will play an important role not only as the basis of a refinement of
sets in the forthcoming presentation of a determinisation construction for
NBA. In Part III of this book we study automata and logic on trees as
extensions of words. We therefore
‚àó
formalise the intuitive notion of a tree. For this, we write N
to denote the set of
all finite sequences of natural numbers, slightly abusing the notion of Œ£‚àó
for a finite alphabet Œ£. However, all we use it for is to conveniently speak
about sequences, prefixes, extensions, etc. We do not attempt to lift any
results from the theory of regular languages over finite alphabets to infinite
alphabets.
Definition 7.3
‚àó
An ordered tree is a ùëá ‚äÜ N that satisfies the following two proper ties.
‚Ä¢ Parent closure: For every ùë¢ùëñ ‚àà ùëá with ùë¢ ‚àà N
‚àó , ùëñ ‚àà N we have ùë¢ ‚àà ùëá.
‚Ä¢
‚àó

Left-sibling closure: For every ùë¢(ùëñ + 1) ‚àà ùëá with ùë¢ ‚àà N , ùëñ ‚àà N we have ùë¢ùëñ
‚àà ùëá .
Let Œõ be some set. A Œõ-labelled tree is a (ùëá , ùë°) such that ùëá is an ordered
tree and ùë° ‚à∂ ùëá ‚Üí Œõ labels the nodes with elements from Œõ.
In the following, trees are always ordered. Hence, we only speak of trees
rather than ordered trees.
7.2 Trees and K Àù
onig's Lemma
161
The intuition behind this definition of trees is the following. Each node in a
tree
‚àó
is identified by a sequence ùë¢ ‚àà N that encodes the unique path from the
root to node ùë¢. Hence, ùëá only contains the nodes, and the edges in the tree
are given implicitly .
The root is ùúÄ since there is no direction to be taken from the root to arrive at
the root. A node ùë¢ùëñ is the (ùëñ + 1)-th successor of node ùë¢, also known as the (ùëñ
+ 1)-th child of node ùë¢, where the first one is given direction 0, the second
one direction 1, etc. The necessity for the two closure properties is the
following.
‚Ä¢ Parent closure requires every node, apart from the root, to have a parent
in the tree, and the parent node is given by the maximal proper prefix of the
node itself.
‚Ä¢ Left-sibling closure simply states that every node which is not of the form
ùë¢0, i.e. which is not the first child of its parent but the (ùëñ + 1)-th for some ùëñ
‚â• 0, must have a left sibling which is the ùëñ-th child of the parent node. The

root node forms an exception since it has no parent, and it is therefore not
the ùëñ-th child of a node for any ùëñ .
Note that in this formalisation, resp. representation of trees, it is easy to
read off the levels of a tree ùëá : level 0 consists of the root node ùúÄ only, i.e.
all node names of length 0. Its children form level 1, and their names all
have length 1, and so on.
Likewise, paths (from the root node) also have natural representations.
Such a path can be given as a sequence of directions ùëñ , ùëñ , ùëñ , . . .
1
2
3
, and it traverses the nodes
ùúÄ, ùëñ , ùëñ ùëñ , ùëñ ùëñ ùëñ , . . .
1
1 2
1 2 3
This works both for finite and infinite paths. A finite path taking directions ùëñ
, . . . , ùëñ
ùëñ
. . . ùëñ
1
ùëõ goes from ùúÄ via ùëñ1, ùëñ1 2, etc. to ùëñ1
ùëõ , which shows clearly that

a node's name is simply given as the unique sequence of directions to be
taken from the root to that node.
We need a few more technical definitions about trees.
Definition 7.4 The length of a finite path from the root to node ùë£ in a tree ùëá
is ‚à£ùë£‚à£ + 1.
ùëá has paths of unbounded length if it has a path of length ùëõ for every ùëõ ‚àà N
.
A descendant of node ùë¢ is every node ùë£ that is either ùë¢ itself or a
descendant
‚àó
of one of its children. Hence, ùë£ is a descendant of ùë¢ iff there is a ùë§ ‚àà N
such that ùë£ = ùë¢ùë§. The branching degree of a node ùë¢ in ùëá is deg(ùë¢) ‚à∂=
sup{ùëñ ‚à£ ùë¢ùëñ ‚àà ùëá } where sup N = ‚àû. We say that ùëá has infinite branching if
there is some ùë¢ ‚àà ùëá such that deg(ùë¢) = ‚àû. Otherwise it is said to be finitely
branching. It has bounded branching if there is some ùëë ‚àà N such that
deg(ùë¢) ‚â§ ùëë for all nodes ùë¢ ‚àà dom(ùë°).
The branching degree of a tree simply measures how many children a node
in the tree has maximally. Note that nothing forbids a node to have infinitely
many children, hence the branching degree needs to be measured as a
supremum, not a maximum.
Example 7.5
‚àó
Fig. 7.2 shows three examples of (infinite) trees. We have ùëá0 = 0 , and
‚àó
it is easily seen from the regular expression for this language that 0 satisfies
parent and left-sibling closure, the latter trivially .

The entire set of nodes of ùëá1 is less obviously derived from the picture
showing only its first five levels. The picture suggests that ùëá1 also has paths
of unbounded length, but unlike ùëá1 these need not be extensions of each
other. For instance, a path of length 2 is ùúã2 = ùúÄ, 2, and a path of length 4 is
ùúã3 = ùúÄ, 0, 01. Clearly, it does not
162
7 Determinisation
ùëá
ùëá
ùëá
0
1
2
ùúÄ
ùúÄ
ùúÄ
‚ãØ
0
0
1
2
0

1
2
3
4
00
00
01
10
10
20
30
40
000
000
001
100
101
200
300
400

‚ãÆ
0010
1010
1011
3000 4000
‚ãÆ
‚ãÆ
40000
Fig. 7.2 Example trees with bounded or infinite branching, all with paths of
unbounded lengths.
extend ùúã2. On the other hand, each path of length ùëõ of course also defines
paths of
‚Ä≤
length ùëö for all ùëö < ùëõ. For example, ùúã = ùúÄ, 0 is a path of length 2, and it is
extended 2
by ùúã 3.
ùëó
ùëá2 has node set {ùúÄ}‚à™{ùëõ0 ‚à£ ùëõ ‚àà N, 0 ‚â§ ùëó ‚â§ ùëõ} which makes it the only
example here ùëõ
of infinite branching. It also has paths of unbounded length: ùúÄ, ùëõ, ùëõ0, ùëõ00, . .
. , ùëõ0 is a path of length ùëõ + 2 for example.
7.2.2 Infinite Paths in Trees

K Àù
onig's Lemma connects the existence of paths of unbounded length with that
of infinite paths. The trees ùëá1 and ùëá2 from the previous example present the
essential difference that finite vs. infinite branching degree makes: ùëá2 has
paths of unbounded length but no infinite path. ùëá1, however, when
imagined to be continued in the same spirit as shown on the first few levels,
in particular being of finite branching degree, will either have to stop at
some level in which case it does not have paths of unbounded length, or it
will have to have an infinite path.
Lemma 7.6 A tree ùëá with bounded branching has paths of unbounded
length iff
‚à£ùëá ‚à£ = ‚àû .
Proof "‚áí" This direction does not even need the requirement regarding
bounded branching. Suppose ùëá has paths of unbounded length. I.e. for
every ùëõ ‚àà N there is a path of length ùëõ. The end node on this path must be
some ùë¢ùëõ such that ‚à£ùë¢ùëõ‚à£ = ùëõ.
ùëõ
Hence, ùëá ‚à© N ‚â† ‚àÖ for every ùëõ ‚àà N, and therefore ‚à£ùëá ‚à£ = ‚àû.
ùëõ
"‚áê" We first show, by induction on ùëõ, that ‚à£ùëá ‚à© N ‚à£ < ‚àû for every ùëõ ‚àà N.
The claim is obvious for ùëõ = 0 because ‚à£ùëá ‚à© N0‚à£ = ‚à£{ùúÄ}‚à£ = 1.
ùëõ
Suppose ùëõ is given and ‚à£ùëá ‚à© N ‚à£ = ùëò < ‚àû, i.e. there are ùëò nodes on level ùëõ.
ùëõ
Let ùëö ‚à∂= max{ deg(ùë¢) ‚à£ ùë¢ ‚àà ùëá ‚à© N } be the maximal branching degree of
nodes on this level. Because of the assumption of ùëá having bounded

branching, ùëö exists.
Now, every node on level ùëõ + 1 is a successor of a node on level ùëõ, and the
ùëò
7.3 The Safra Construction
163
nodes on level ùëõ can have at most ùëò ‚ãÖ ùëö many successors. Otherwise one
would have to have more successors than the maximal branching degree on
that level. Thus, ùëõ+
‚à£ùëá ‚à© N
1‚à£ ‚â§ ùëò ‚ãÖ ùëö < ‚àû.
This proves the claim about each level having finitely many nodes only.
Now, ùëõ
ùëõ
since ùëá = ‚ãÉ
ùëá ‚à©
ùëõ‚â•0
N , and each ùëá ‚à© N is finite, there must be ùëõ0 < ùëõ1 < . . . such ùëõ
ùëõ
that ùëá ‚à© N ùëñ ‚â† ‚àÖ for every ùëñ ‚â• 0. Because of parent closure, we even have ùëá
‚à© N ‚â† ‚àÖ
for every ùëõ ‚â• 0. Each node ùë£ on level ùëõ defines a path of length ùëõ + 1,
namely the unique path from the root to ùë£. Thus, ùëá contains paths of
unbounded length.

‚óª
The following is then known as K Àù
onig's Lemma.
Theorem 7.7 Let ùëá be a tree of finite branching degree. If ùëá has paths of
unbounded length then it has an infinite path.
Proof Let ùëá be a tree of finite branching degree that has paths of
unbounded length.
According to Lemma 7.6, we have ‚à£ùëá ‚à£ = ‚àû. We will now construct two
sequences ùë£
, ùë£
, . . .
, ùëá , . . .
0
1
and ùëá0
1
such that
‚Ä¢ ùë£ , ùë£ , . . .
0
1
is an infinite path through ùëá ,

‚Ä¢ ùëáùëñ = {ùë£ ‚à£ ùë£ is a descendant of ùë£ùëñ} and ‚à£ùëáùëñ‚à£ = ‚àû for all ùëñ ‚â• 0.
We start with ùë£0 ‚à∂= ùúÄ and ùëá0 ‚à∂= ùëá . By the observation using Lemma 7.6 we
have
‚à£ùëá0‚à£ = ‚àû. Moreover, ùëá0 clearly consists of all descendants of the root node
ùë£ 0.
Now suppose that ùë£ùëñ and ùëáùëñ have been constructed already. Since ùëá is of
bounded branching, let ùëë ‚à∂= deg(ùë£ùëñ). By hypothesis, ‚à£ùëáùëñ‚à£ = ‚àû, i.e. there are
infinitely many nodes reachable from ùë£ùëñ, but it only has ùëë many children.
Hence, ùë£ùëñ must have some child node ùë¢ so that infinitely many descendants
of ùë£ùëñ are also descendants of ùë¢.
Then simply take ùë£ùëñ+1 ‚à∂= ùë¢ which guarantees that ‚à£ùëáùëñ+1‚à£ = ‚àû.
Since each ùë£
, ùë£
, . . .
ùëñ+1 was chosen as a child node to ùë£ùëñ , we have that ùë£0
1
forms a
path of infinite length through ùëá .
‚óª
K Àù
onig's Lemma is presented here because it is used in the combinatorics of
the correctness proof of the Safra construction for the determinisation of
NBA.

7.3 The Safra Construction
Fix an NBA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) for the rest of this section. W.l.o.g. we assume that
it is total in the sense that for every ùëû ‚àà ùëÑ and ùëé ‚àà Œ£ there is at least one ùëù
‚àà ùëÑ with (ùëû, ùëé, ùëù) ‚àà ùõø. It should be clear that it is always possible to
guarantee this by adding at mos t one state.
We discuss the general construction of a deterministic finite-state
automaton B
with respect to this NBA. We will use the terms microstate and macrostate
again to refer to the states of A, resp. B.
164
7 Determinisation
7.3.1 Refining the Powerset Construction
In the end, we will make use of the results of Chp. 6, in particular Cor. 6.43,
stating that a deterministic automaton with a transition-based Rabin
acceptance condition can easily be transformed into a deterministic Rabin
automaton, i.e. one that uses the more traditional state-based acceptance.
Hence, it suffices to construct B as a finite-state automaton with a
transition-based Rabin acceptance condition.
The states of B, i.e. the macrostates, are finite trees whose nodes are
labelled with sets of microstates from ùëÑ.
Definition 7.8 A history tree is a finite tree ùëá whose nodes are labelled by a
function ùëÑ
ùë° ‚à∂ ùëá ‚Üí 2

‚àñ {‚àÖ} with sets of states from ùëÑ such that the following conditions are met
for all ùë£ ‚àà ùëá :
‚Ä¢ ùë°(ùë£ùëñ) ‚à© ùë°(ùë£ ùëó) = ‚àÖ for all ùë£ùëñ, ùë£ ùëó ‚àà ùëá with ùëñ ‚â† ùëó,
‚Ä¢ ùëë‚àí1
‚ãÉ
ùë° (ùë£ùëñ) ‚ää ùë°(ùë£) where ùëë = deg(ùë£ ).
ùëñ=0
In the following, we will often identify a pair (ùëá , ùë°) consisting of a tree and
a labelling function ùë° simply with ùë°, since the tree ùëá can implicitly be
derived as the domain of ùë°.
So the nodes in a history cannot be labelled arbitrarily with sets of
microstates.
Instead, the label of any node gets distributed over its children (provided
there are any), with at least one microstate being left out. This also restricts
the number of possible history trees for a given ùëÑ.
A rather crude upper bound on the number of different possible history
trees for a set ùëÑ of ùëõ microstates can be obtained as follows. First observe
that the branching degree of every node in a history tree is at most ùëõ ‚àí 1:
the label of a node can contain at most ùëõ microstates, and the combined
label of all its children must form a genuine subset thereof. This also
restricts the possible depth of a history tree to ùëõ since the label of each
node must be a genuine subset of the label of its parent. At last, it should be
clear that there are only finitely many trees of branching degree at most ùëõ
and depth at most ùëõ, and then for each of them there are only finitely many
possibilities to attach labels as subsets of ùëõ states to its nodes. A better
estimation can be obtained as follows, though.
Lemma 7.9

O(ùëõ
There are at most 2
log ùëõ) many history trees for an NBA of size ùëõ .
Proof First note that a history tree ùë° defines, for each microstate ùëû ‚àà ùëÑ, a
unique deepest node ùë£ in ùë° such that ùëû ‚àà ùë°(ùë£). Any microstate contained in
the label of some node must also occur in the labels of its parent, the parent
of the parent, etc. up to the root. Since sibling nodes are required to have
disjoint labels, ùëû cannot occur on a second path in the tree. Hence, each
history tree can contain at most ùëõ nodes.
Now there is a one-to-one correspondence between finite trees with
arbitrary branching degree and ùëõ nodes on one hand, and binary trees with
ùëõ + 1 nodes on the other, known as the first-child-next-sibling encoding. It
actually suffices to consider the number of binary trees with ùëõ nodes only,
since one particular node - the right
7.3 The Safra Construction
165
child of the root - is always fixed in these encodings. The number of such
trees is 2ùëõ
ùëõ
ùëõ
O(ùëõ
given by the Catalan number ùê∂
log ùëõ)
ùëõ =

1
‚ãÖ (
) ‚â§ 2 ‚ãÖ ùëõ = 2
.
ùëõ+1
ùëõ
A history tree is then given by a pair of one of these trees plus an
assignment of microstates to its ùëõ nodes. The number of such assignments is
at most ùëõ! =
O(ùëõ
2
log ùëõ) which means that the number of different history trees can be
estimated O(ùëõ
O(ùëõ
as (2
log ùëõ))2 = 2
log ùëõ).
‚óª
Let H denote the set of all history trees for A. It will serve as the state set for
B. Its initial state is simply the history tree ùë°ùêº with dom(ùë°ùêº ) = {ùúÄ} and ùë°ùêº (ùúÄ)
= {ùëûùêº }. This is comparable to what is happening in the powerset
construction where the initial macrostate is given as the set containing the
initial microstate. Here, the data structure used to build macrostates is not

just a set but a history tree, so the initial macro state consists of the most
obvious history tree that contains the initial microstate.
Next we turn to the transition function Œî in B. Given an arbitrary history
tree, i.e. a macrostate ùë° ‚àà H, and some alphabet letter ùëé ‚àà Œ£, we need to
determine the macrostate Œî(ùë°, ùëé), i.e. the successor of ùë° under ùëé. This is
done in six steps: given ùë° and ùëé as required, we define a sequence of trees ùë°
, . . . , ùë°
, . . . , ùë°
1
6 in which ùë°1
5 are
generally not history trees but ùë°6 is. Moreover, we then have Œî(ùë°, ùëé) ‚à∂= ùë° 6.
Step 1, powerset construction: ùë°1 results from ùë° by replacing all labels by
their joint successors under the transition relation ùõø of A: we have dom(ùë°1)
= dom(ùë°) and ùë°1(ùë£) ‚à∂=
‚ãÉ
{ ùëù ‚à£ (ùëû, ùëé, ùëù) ‚àà ùõø } .
ùëû‚ààùë° (ùë£)
for any ùë£ ‚àà dom(ùë°1). Note that this may violate the conditions of being a
history tree: while it is guaranteed that the joint labels of a node's children
still form a subset of the parent's label, this may not be a proper subset an
ymore.
Step 2, spawning off accepting states: ùë°2 results from ùë°1 by potentially
adding new nodes. For every node ùë£ ‚àà dom(ùë°1) such that ùë°1(ùë£) ‚à© ùêπ ‚â† ‚àÖ,
add node ùë£ùëë to dom(ùë°2) where ùëë = deg(ùë£). Its label is ùë°2(ùë£) ‚à∂= ùë°1(ùë£) ‚à© ùêπ.
All other nodes retain their label from ùë°1.

In addition to the potential violations of the conditions for history trees that
may happen in step 1, this step may cause violations of the requirement on
siblings. It can create nodes with labels that contain microstates which are
already contained in older siblings. This could be avoided right away
because later steps clear this up anyway.
Step 3, horizontal cleaning: we write ùë¢ ‚åâ ùë£ if there is a node ùë§ ‚â† ùë¢ that is a
sibling of ùë¢ further right in the tree, and ùë£ is a descendant of ùë§. The case
of ùë§ = ùë£ is allowed in which case ùë¢ is simply a left sibling of ùë£. We then
have dom(ùë°3) = dom(ùë° 2) but ùë°3(ùë£) ‚à∂= {ùëû ‚àà ùë°2(ùë£) ‚à£ ‚àÄùë¢ ‚à∂ ùë¢ ‚åâ ùë£ ‚áí ùëû /
‚àà ùë°2(ùë¢ )} .
In other words, we delete all microstates from labels that already occur in
siblings further left, and also remove them from any descendants.
166
7 Determinisation
ùëé , ùëè
ùëé , ùëè
0
2
ùëé
4
ùëè
ùëé , ùëè
ùëé
ùëè

ùëé , ùëè
ùëè
ùëè
1
3
ùëè
5
ùëé , ùëè
ùëè
Fig. 7.3 NBA used to exemplify the construction of an equivalent
deterministic automaton.
While this trivially ensures the property of disjointness of children's labels
in a history tree, it may violate another condition, namely that of nodes
carrying nonempty labels.
Step 4, removal of empty nodes: simply let
dom(ùë°4) ‚à∂= {ùë£ ‚àà dom(ùë°3) ‚à£ ùë°3(ùë£) ‚â† ‚àÖ}
ùë£
ùë°
and ùë°4(ùë£) ‚à∂= ùë°3(ùë£) for all remaining nodes . Technically, 4 is not a tree
according to our definition because it does not satisfy left-sibling closure
anymore. We refrain from inventing a new name for such structures and
simply call it a tree for the moment since left-sibling closure is not relevant
for what happens here or in the next step.

The last step in this sequence will ensure that it is a proper tree ag ain.
Step 5, vertical cleaning: let
deg(ùë¢)‚àí1
‚àó
+
dom(ùë°
, ùë§
ùë°
5)
‚à∂= {ùë£ ‚àà dom(ùë°4) ‚à£ ‚àÄùë¢ ‚àà N
‚àà N ‚à∂ ùë£ = ùë¢ùë§ ‚áí ùë°4(ùë¢) ‚â† ‚ãÉ
4 (ùë¢ùëñ)}
ùëñ=0
and ùë°5(ùë£) ‚à∂= ùë°4(ùë£) for all remaining ùë£. Hence, in this step we remove the
children (and their descendants) of all nodes whose children have joint
labels that equal that of the parent node.
It should be clear that this recovers the potential violation on the
requirement that the label of a parent's node is always a genuine superset of
the labels of its children.
Step 6, left shifting: at last, we restore a proper tree structure by shifting
nodes further left. For as long as left-sibling closure is not satisfied, i.e.
there is a node ùë¢(ùëñ + 1)
‚àó

but no node ùë¢ùëñ for some ùë¢ ‚àà N , ùëñ ‚àà N, shift all nodes of the form ùë¢(ùëñ +
1)ùë§ to ùë¢ùëñùë§
‚àó
for any ùë§ ‚àà N , retaining their labels. When left-sibling closure is restored
entirely, the final tree ùë° 6 is obtained.
Example 7.10 Let A be the NFA over Œ£ = {ùëé, ùëè} from Fig. 7.3. It is not
complete but this does not invalidate the following considerations as we are
only constructing a particular successor of the following history tree ùë°.
7.3 The Safra Construction
167
{0, 1, 2, 3, 4, 5}ùúÄ
{1, 5}0
{2, 3}1
{4}2
{1}00
{3}10
For clarity, the nodes' names are shown as indices to the labels.
We show how to obtain Œî(ùë°, ùëè). First, we perform the powerset construction
in every node, obtaining ùë°1 as follows.
{0, 1, 2, 3, 4, 5}ùúÄ
{1, 5}0
{1, 2, 3}1

{5}2
{1}00
{1, 2, 3}10
It is noteworthy that all microstates 1, 2, 3 in node 1 are obtained as ùëè-
successors of microstate 3, whereas microstate 2 does not contribute
anything in this step.
The tree is clearly not a history tree. Next we need to spawn off new
children carrying accepting states. Theoretically, node ùúÄ would receive a
new child 3 with label {1, 3, 4} but microstates 1 and 3 are already included
in the labels of older siblings. So they would get removed in the next step
anyway. Hence, it suffices to introduce a new node 3 with label {4} only.
Similar considerations lead to the introduction of a new node 11 as a child
of node 1 with label {1} only. Likewise, node 00 has a single accepting state
in its label. Theoretically, we could add a new child 000 with the same
label, but this node would get deleted in the subsequent vertical clearance
step. This is why we only introduce new children when the parent contains
accepting states that are not contained in already existing children, and the
parent's label does not consist of accepting states only. This then yields the
following tree ùë°2.
{0, 1, 2, 3, 4, 5}ùúÄ
{1, 5}0
{1, 2, 3}1
{5}2
{4}3
{1}00 {1, 2, 3}10 {1, 3}11
{1, 3}100

Next we perform horizontal cleaning, i.e. we remove every microstate from
a label that is already contained in the label of a left (and therefore older,
resp. non-younger) sibling. This leads to the following tree ùë°3.
168
7 Determinisation
{0, 1, 2, 3, 4, 5}ùúÄ
{1, 5}
‚àÖ
0
{2, 3}1
2
{4}3
{1}
‚àÖ
00
{2, 3}10
11
{3}100
Microstate 1 gets removed from the label of node 100 even though this node
has no left siblings. But microstate 1 needs to be removed from the label of
node 1

because it is also contained in the label of node 0. It then also gets removed
from all descendants in order to eventually turn the tree into a history tree
again, in particular to ensure the invariant that the labels of children form a
subset of the parent's label.
In the next step we simply remove nodes with empty labels, resulting in the
following tree-like structure ùë°4.
{0, 1, 2, 3, 4, 5}ùúÄ
{1, 5}0
{2, 3}1
{4}3
{1}00
{2, 3}10
{3}100
Then we perform vertical cleaning. There is one node whose label is the
same as the joint labels of all its children, of which there is only one: nodes
1 and 10 both have the label {2, 3}. We therefore delete the child and all its
descendants, which results in the following tree ùë°5.
{0, 1, 2, 3, 4, 5}ùúÄ
{1, 5}0
{2, 3}1
{4}3
{1}00
This is not yet a history tree, simply because it is not a tree strictly speaking
since the deletion of node 2 has led to the violation of left-sibling closure.

This is then easily fixed in the last step which shifts nodes as far left as
possible, eliminating such gaps in the tree's domain. The result is the
following tree ùë°6 which is then also the successor of the original tree ùë°
under the letter ùëè in the transition function of the deterministic automaton
B.
7.3 The Safra Construction
169
{0, 1, 2, 3, 4, 5}ùúÄ
{1, 5}0
{2, 3}1
{4}2
{1}00
The entire deterministic finite-state automaton B, resulting from the NBA in
Fig. 7.3
is too big to be shown completely, but Fig. 7.4 shows an initial part of its
run on the word ùëéùëèùëèùëéùëèùëè . . .
Next we need to discuss the acceptance condition for the deterministic
automaton B. For this it is helpful to analyse the purpose of the nodes in a
history tree, and to remember the discussion above on the fundamental
problem with powerset-based constructions for the determinisation of B
√ºchi automata: it is an overapproximation in the sense that runs through the
microstates are contained in runs of the macrostates but a simple powerset
construction alone is too coarse to determine whether the sequence of
macrostates contains a run that traverses through accepting microstates
infinitely often. Note that node ùúÄ in all runs contains the sets of microstates
as one would obtain them through an ordinary powerset construction.

The interesting point is then the spawning off of new nodes that contain
accepting microstates only. This can be seen as a refinement of the powerset
construction in the sense that a special focus is being put on these accepting
microstates at the current point. Remember that in a sequence of
macrostates obtained by powerset construction, one knows that any
microstate can be traced back to some microstate in an earlier macrostate.
This is what happens in the root of the history trees: any of the microstates
0, 1, 2, 3, 4, 5 in node ùúÄ in ùë°6 of Fig. 7.4 can be traced back to microstate 0
in node ùúÄ in ùë°0 in the sense that there is a run in A on the underlying word
that starts in 0 and hits the desired microstate from the label of node ùúÄ in ùë°6.
Now consider node 1 in ùë°6 instead with its two microstates 2, 3. What
happens in a child node can be seen as the powerset construction
(happening in the parent node) with a special focus on some microstates. So
2, 3 can surely be traced back to microstates 2, 3 in node 1 of ùë°5 and also to
1, 3, 4 in node 1 in ùë°4. Remember that a new node is only every created with
a label consisting of accepting microstates only.
Hence, when we trace a microstate's origin back through some particular
(child) node, we eventually trace it back to an accepting state.
We cannot go back arbitrarily, though. It is wrong to assume that the
microstates 2, 3 in node 1 of ùë°6 could be traced back to microstate 4 in node
1 in ùë°2. The reason simply is that node 1 died out in the transition from ùë°2
to ùë°3, and has been recreated with a new label in the transition from ùë°3 to
ùë°4. So in determining whether the underlying nondeterministic automaton A
has a run that visits accepting microstates infinitely often we need to
consider the continuous evolution of particular nodes in the history trees.
This leads us to the notion of a node being stable in a particular transition,
to be defined precisely below.
Moreover, it is not sufficient to determine whether all microstates in a node
can be traced back to some accepting microstate. This needs to happen
infinitely often.
170
7 Determinisation

ùë°
ùë°
ùë°
ùë°
0
1
2
3
{
ùëé
ùëè
ùëè
0}
{
{
{
ùúÄ
0, 1, 4}ùúÄ
0, 1, 2, 4, 5}ùúÄ
0, 1, 2, 4, 5}ùúÄ

{1, 4}
{
{
{
0
1, 5}0
4}1
1, 5}0
{1}
{
00
1}00
ùëé
ùë°
ùë°
ùë°
6
5
4
{

ùëè
ùëè
0, 1, 2, 3, 4, 5}ùúÄ
{0, 1, 2, 3, 4, 5}ùúÄ
{0, 1, 2, 3, 4, 5}ùúÄ
{1, 5} {
{
0
2, 3}1
4}2
{1, 5} {
{
0
2, 3}1
4}2
{5} {
0
1, 3, 4}1
{1}00
{1}

{
00
3}10
Fig. 7.4 The history trees in a run of the deterministic automaton obtained
from the NBA in Fig. 7.3
with the underlying word being ùëéùëèùëèùëéùëèùëè . . .
And this is what the deletion of nodes in a history tree comes in for: take
node 10
in ùë°5 and note that it gets removed in a vertical cleaning step in ùë°6. The
reason is that label {3} in ùë°5 gets replaced by {1, 2, 3} in the powerset
construction step, then microstate 1 gets deleted because it is contained in a
left sibling of the parent node.
The remaining label {2, 3} is then the same as the label of the parent node
1. We can then not only conclude that both 2 and 3 (in node 1 of ùë°6) can be
traced back to any of 2 or 3 (in node 1 in ùë°5) but in fact more: since the
label {2, 3} of node 1 in ùë°6 equals the joint labels of all its children (here:
its only child), and the microstates in child nodes can always be traced back
to accepting microstates, we additionally know that both 2 and 3 can be
traced back to microstate 3. Thus, when this happens infinitely often, we
can conclude that there is indeed a run of A that traverses through
accepting microstates infinitely often. The key concept here is that of a node
being successful.
Definition 7.11
‚Ä≤
Let ùë°, ùë° be history trees of A such that there is some ùëé ‚àà Œ£ with
‚Ä≤

ùë°
= Œî(ùë°, ùëé). Let ùë£ be a node name. We say that ùë£ is stable in the transition
from
‚Ä≤
‚Ä≤
ùë° to ùë° if ùë£ ‚àà dom(ùë°), ùë£ ‚àà dom(ùë° ) and ùë£ did not get removed in steps 3
(horizontal cleaning), 4 (removal of empty nodes), 5 (vertical cleaning) and
did not get shifted
‚Ä≤
in step 6 of the construction of ùë° from ùë°.
‚Ä≤
We say that ùë£ is successful in the transition from ùë° to ùë° if all its children got
removed in step 5 (vertical cleaning).
This allows us to define an acceptance condition on B as a transition-based
Rabin condition: intuitively, a run of B is accepting if there is some node ùë£
that is eventually
7.3 The Safra Construction
171
stable and infinitely often successful. To see that this is indeed definable as
a Rabin condition, all we need is the observation that there are only finitely
many possible node names in a history tree for A. This is of course an
immediate consequence of the argumentation above that the depth and the
branching degree of a history tree are both bounded by the number of
microstates.
Formally, we therefore have B ‚à∂= (H, Œ£, ùë° , Œî,

ùêº
F ) where ùë°ùêº is the initial history
tree, Œî is the transition function as explained above and F ‚à∂= {(ùê∫ , ùêπ
ùë£
ùë£ ) ‚à£ ùë£ is a node
name } where
‚Ä≤
‚Ä≤
‚Ä≤
ùê∫ ùë£ ‚à∂= {(ùë°, ùëé, ùë° ) ‚à£ ùë°
= Œî(ùë°, ùëé) and ùë£ is successful in the transition from ùë° to ùë° },
‚Ä≤
‚Ä≤
‚Ä≤
ùêπùë£ ‚à∂= {(ùë°, ùëé, ùë° ) ‚à£ ùë°
= Œî(ùë°, ùëé) and ùë£ is unstable in the transition from ùë° to ùë° } .
This completes the construction of the DRAe B from the NBA A. It remains
to be seen that it accepts the same language.
7.3.2 Correctness of the Construction
We consider soundness and completeness separately in the following
lemmas.

Lemma 7.12 Let A be an NBA and B be the DRA e resulting from it
according to the construction above. Then we have ùêø(B) ‚äÜ ùêø(A) .
Proof Let ùë° , ùë° , . . .
ùëé
. . .
0
1
be an accepting run of B on some word ùë§ = ùëé0 1
‚àà Œ£ ùúî . There
must be some node name ùë£ and some ùëõ ‚àà N such that ùë£ is stable in the
transitions from ùë°
, ùëñ , . . .
ùëñ to ùë°ùëñ+1 for all ùëñ ‚â• ùëõ and infinitely often successful, i.e. there are ùëñ0
1
such
that, w.l.o.g. 0 < ùëõ = ùëñ0 < ùëñ1 < . . . and node ùë£ is successful in the transition
from ùë°ùëñùëó ‚àí1
to ùë°ùëñ for all ùëó ‚â• 1.
ùëó
We now construct a tree as follows. Its nodes are ùëÑ √ó {0, ùëñ , ùëñ , ùëñ , . . .
0

1
2
}. We distin-
guish two cases for the definition of the edges between them.
‚Ä¢ For each ùëû ‚àà ùëÑ that occurs in the label of node ùë£ in ùë°
,
ùëñ
, draw an edge from (ùëûùêº 0)
0
ùëé
... ùëé
0
ùëñ
‚àí
0
1
to (ùëû, ùëñ0). Note that ùëû also occurs in ùë°ùëñ 's root node and therefore ùëûùêº
√ê√ê√ê√ê√ê‚Üí ùëû
0
ùë£

in A where ùëù √ê
‚Üí ùëû for any ùëù, ùëû ‚àà ùëÑ and ùë£ ‚àà Œ£‚àó is used to denote the existence of a path
from ùëù to ùëû with edge labels forming the w ord ùë£.
‚Ä¢ For each ùëó > 0 and ùëû ‚àà ùëÑ that occurs in the label of node ùë£ in ùë°ùëñ , draw
an edge ùëó
‚Ä≤
‚Ä≤
from (ùëû , ùëñ ùëó‚àí1) to (ùëû, ùëñ ùëó ) for some ùëû in the label of node ùë£ in ùë°ùëñ
such that
ùëó ‚àí1
ùëé
... ùëé
ùëñ
ùëñ
‚àí
ùëó ‚àí
ùëó
1
‚Ä≤
1
‚Ä≤

ùëû
√ê√ê√ê√ê√ê√ê‚Üí ùëû in A. By stability of ùë£, such a ùëû must exist. Moreover, since
ùë£
is successful in the transition to ùë°ùëñ , we know that the partial run in A
witnessing ùëó
this can be chosen such that it traverses through a final state.
This structure is not a tree in general but a DAG. However, it can easily be
unfolded into a tree by introducing new copies of nodes that are successors
of multiple nodes in the DAG. In any case, this tree has paths of unbounded
length, because the labels of node ùë£ in each ùë°ùëñ are non-empty, i.e. on every
level there is a node that is connected ùëó
172
7 Determinisation
to a node on the previous level, which in turn is connected to a node on the
level before that, etc. Each such connection can be traced back to ùëûùêº on the
DAG's first level.
According to K Àù
onig's Lemma, we can also find an infinite path through this tree or DAG.
I.e. there is an infinite sequence of microstates ùëû , ùëû , . . .
ùëñ
ùëñ
such that
0
1

ùëé
... ùëé
ùëé
... ùëé
ùëé
... ùëé
0
ùëñ
‚àí
ùëñ
ùëñ
‚àí
ùëñ
ùëñ
‚àí
0
1
0
1
1

1
2
1
ùëû ùêº √ê
√ê√ê√ê√ê
‚Üí ùëûùëñ
√ê√ê√ê√ê√ê‚Üí ùëûùëñ
√ê√ê√ê√ê√ê‚Üí . . .
0
1
This forms a run of A on ùë§. Moreover, since each part between ùëûùëñ and ùëûùëñ
traverses
ùëó
ùëó +1
through an accepting state, the run is accepting, showing that ùë§ ‚àà ùêø(A).
‚óª
Lemma 7.13 Let A be an NBA and B be the DRA e resulting from it
according to the construction above. Then we have ùêø(B) ‚äá ùêø(A) .
Proof Let ùúå = ùëû , ùëû , ùëû , . . .
ùëé

. . .
0
1
2
be an accepting run of A on some word ùë§ = ùëé0 1
‚àà
Œ£ùúî. In particular, we have ùëûùëñ ‚àà ùêπ for infinitely many ùëñ. Since B is
deterministic, it has a unique run ùë° , ùë° , . . .
0
1
on ùë§.
We say that some history tree node ùë£ captures the run ùúå, if there is some ùëõ ‚â•
0 such that ùë£ is stable in the transition from ùë°ùëñ to ùë°ùëñ+1 and ùëûùëñ ‚àà ùë°ùëñ(ùë£) for all
ùëñ ‚â• ùëõ. Note that ùúÄ
captures ùúå. In other words, the run ùúå can be found within the sets ùë°0(ùúÄ), ùë°1(ùúÄ),
. . .
We now claim that the following is true: if node ùë£ captures ùúå but is not
successful
‚Ä≤
infinitely often, then it has a child ùë£ that captures ùúå. Once this is shown, the
statement of the lemma is proved: since history trees are of finite depth,
there must be a deepest node that captures ùúå and it must also be successful
infinitely often because it has no child that captures ùúå. Hence, the Rabin
acceptance condition is satisfied by the run ùë° , ùë° , . . .

0
1
and we therefore have ùë§ ‚àà ùêø(B).
To prove the claim suppose that ùë£ is a node that is eventually stable but
successful at most finitely often. Let ùëñ0 be such that ùëûùëñ ‚àà ùêπ but node ùë£ is
not successful in 0
a transition from ùë°
, ùëé
ùëñ
or afterwards. Since ùëûùëñ ‚àà ùõø(ùëûùëñ
ùëñ
0 ‚àí1 to ùë°ùëñ0
0
0 ‚àí1
0 ‚àí1 ), we get that
ùëûùëñ
is contained in the label of node ùë£ after step 1 (powerset construction) in
the 0
transition from ùë°ùëñ
. For simplicity we will simply refer to the resulting trees
0 ‚àí1 to ùë°ùëñ0

as ùë°ùëñ and explicitly mention the step of the construction we are considering.
Since 0
ùëûùëñ
‚àà ùë°ùëñ (ùë£) ‚à© ùêπ at this point, step 2 (spawning off accepting states) creates a
new 0
0
child for node ùë£ that contains ùëûùëñ . It is of course possible that ùëûùëñ is already
contained 0
0
in a child further to the left in which case this new child node gets deleted
in step 3
(horizontal cleaning). In either case, the child ùë£ ùëó containing ùëûùëñ does not
get removed 0
in steps 4 (removal of empty nodes) for trivial reasons. It also does not get
removed in step 5 (vertical cleaning) as this would cause ùë£ to be successful
in this step which it is not by assumption.
This argumentation can now be repeated to see that this node ùë£ ùëó persists. It
can of course be shifted to the left in subsequent steps 6 of the
constructions. But this can happen at most ùëó many times, so eventually there
is a stable node that is deeper in the tree than ùë£ and which captures the run
ùúå.
‚óª
The following is then obtained immediately from Lemma 7.9, 7.12 and 7.13.
7.3 The Safra Construction
173

1
Œ£ùëõ
Œ£
1
ùëõ
Œ£ùëõ
1
ùëûùêº
0
‚ãÆ
ùëõ
ùëõ
ùëõ
Œ£ùëõ
Fig. 7.5 NBA Aùëõ for a language whose complementation requires a blowup
of Œ©(ùëõ!).
Theorem 7.14
O(ùëõ
For every NBA A of size ùëõ there is a DRA
log ùëõ)

e B of size 2
and
index O(ùëõ) such that ùêø(B) = ùêø(A) .
Moreover, Cor. 6.43 states that deterministic automata with a transition
based Rabin acceptance condition can easily be converted into ordinary
deterministic Rabin automata. Cor. 6.22 states that Rabin automata are
special cases of Muller automata.
Combining these with Thm. 7.14 we easily obtain the possibility to
determinise nondeterministic B √ºchi automata into Rabin or Muller
automata.
Corollary 7.15
O(ùëõ
For every NBA A of size ùëõ there is a DRA of size 2
log ùëõ) and
index O(ùëõ) such that ùêø(B) = ùêø(A) .
7.3.3 A Lower Bound on Complementation and Determinisation
Determinisation yields an alternative approach to the decidability of MSO
over infinite words, since deterministic automata - in particular DMA - can
easily be complemented, and complementation is needed in an inductive
translation from MSO formulas into automata. However, existential
quantification then needs to be handled by alphabet projection which yields
nondeterministic automata again.
Conversely, we can use the determinisation construction to complement
NBA.
The following is a direct consequence of Cor. 7.15 and Thm. 6.24 showing
how to translate NMA (and therefore also DRA) into equivalent NBA at a

polynomial blowup only.
Corollary 7.16
O(ùëõ
For every NBA A of size ùëõ there is an NBA A of size 2
log ùëõ) such
that ùêø(A) = ùêø(A) .
This is asymptotically optimal. It is not possible to reduce the index and
number of states of the DRA resulting from an NBA significantly further so
that it leads to an asymptotically better procedure for complementing NBA.
In the following, we will create a family of ùúî-regular languages that require
such a blowup in complementation.
For ùëõ ‚â• 1 let Œ£
,
ùëõ ‚à∂= {#, 1, . . . , ùëõ}, Aùëõ be the NBA over state space {ùëû ùêº 0, 1, . . . , ùëõ}
shown in Fig. 7.5 and ùêøùëõ ‚à∂= ùêø(Aùëõ). Consider a word ùë§ ‚àà Œ£ ùúî
ùëõ . We say that it contains
174
7 Determinisation
a cycle if there is some ùëò ‚â• 1 and ùë• , . . . , ùë•
1
ùëò
‚àà {1, . . . , ùëõ} such that ùë§ has infinitely

many occurrences of the ùëò two-letter subwords ùë• ùë• , ùë• ùë• , . . . , ùë• ùë•
1 2
2 3
ùëò
1 .
Example 7.17
ùúî
Let ùëõ = 4 and consider (1423#2431#) . It contains a cycle, witnessed by the
occurrences of 14, 42, 24, 43, 31. Clearly, it also contains a shorter cycle as
ùúî
ùúî
well, namely 42, 24. On the other hand, neither (1423#)
nor (2431#)
contain
cycles. Note that between each two consecutive occurrences of # in these
words, there is the same fixed pattern of symbols that can be used to form
cycles. Moreover, these patterns only contain each symbol 1, . . . , 4 at most
once. Hence, every sequence ùë• ùë• , ùë• ùë• , . . .
1 2
2 3
of two-letter subword in those parts invariably would have to contain the
symbol # before the cycle can be closed. But this is forbidden according to
the definition of a cy cle.

The property of containing a cycle is exactly what defines ùêøùëõ.
Lemma 7.18 Let ùëõ ‚â• 1 and ùë§ ‚àà Œ£ùúî
ùëõ . Then ùë§ ‚àà ùêø ùëõ iff ùë§ contains a cycle.
Proof "‚áê" Suppose that ùë§ contains a cycle ùë• ùë• , . . . , ùë• ùë•
1 2
ùëò
1. It is easy to construct an
accepting run of Aùëõ on ùë§. It stays in state ùëûùêº whilst reading the prefix of ùë§
up to the last letter before the first occurrence of ùë• ùë•
1 2. With these two letters it moves to state
ùë•
ùë•
2 via state 0. It remains there up to the next occurrence of ùë•2 3. Upon
reading this two-letter subword, it moves to state ùë•3 via state 0. This is
continued ad infinitum.
The run is obviously accepting because it traverses state 0 infinitely often.
"‚áí" Suppose there is an accepting run ùúå of Aùëõ on ùë§. Clearly, ùúå must
eventually leave state ùëûùêº and move to some state ùëû1 ‚àà {1, . . . , ùëõ}. It cannot
stay there forever because these are not accepting. Hence, it must
eventually move to some state ùëû2 ‚àà {1, . . . , ùëõ} via state 0, and so on. Since
there are only ùëõ2 < ‚àû many pairs of such states, a two-step transition from
some state ùë•1 to some state ùë•2 must be taken infinitely often. Let (ùë• , ùë¶
, ùë¶

1
1), . . . , (ùë•ùëö
ùëö ) be all the pairs of states such that ùúå
contains infinitely many two-step transitions from ùë•ùëñ to ùë¶ùëñ. Note that ùë§
must contain the two-letter subwords ùë• ùë¶ , . . . , ùë• ùë¶
1 1
ùëö
ùëö infinitely often.
It remains to be seen that there is a cycle amongst these. W.l.o.g. we can
assume them to be chosen minimal, i.e. if there is a cycle amongst them then
all pairs participate in its formation. Note then that there is a cycle iff for
every ùëñ = 1, . . . , ùëö
there is a ùëó ‚àà {1, . . . , ùëö} such that ùë¶ùëñ = ùë• ùëó . So suppose that this was not
the case, i.e.
there is some ùë¶ùëñ that does not equal any ùë• ùëó . But then the run ùúå contains
infinitely many transitions from state ùë¶ùëñ to state 0 without infinitely many
transitions from state 0 to any state ùë• ùëó ‚àà {1, . . . , ùëõ}. This is clearly
impossible.
‚óª
Lemma 7.18 immediately gives us a characterisation of ùêøùëõ as the set of
words that do not contain a cycle. For the remainder of the argument it
suffices to spell out particular words with this property. Let ùëõ ‚â• 1 be given.
A word ùë¢ ‚àà Œ£ùëõ
ùëõ
is called a

permutation if it contains each symbol of {1, . . . , ùëõ} exactly once. Let Œ†ùëõ
be the set of all permutations. Clearly, we have ùëõ! = ‚à£Œ†ùëõ ‚à£.
The next lemma just generalises the observations made in the example
above.
Proof details are left as an exercise.
7.3 The Safra Construction
175
Lemma 7.19 Let ùëõ ‚â• 1 .
ùúî
a) For all ùë¢ ‚àà Œ†ùëõ we have (ùë¢#)
‚àà ùêø ùëõ .
b) For all ùë¢, ùë£ ‚àà Œ†ùëõ such that ùë¢ ‚â† ùë£ and all ùë§ ‚àà Œ£ ùúî
ùëõ
that contain both ùë¢ and ùë£
infinitely often we have ùë§ ‚àà ùêøùëõ .
We can then show that the complements of the languages ùêøùëõ do indeed
require NBA of size Œ©(ùëõ!).
Theorem 7.20 Let ùëõ ‚â• 1 be given and B be an NBA such that ùêø(B) = ùêøùëõ .
Then ùëõ! ‚â§ ‚à£B ‚à£ .
Proof Let B = (ùëÑ, Œ£ , ùëû , ùõø, ùêπ
ùëõ
ùêº

). Take any ùë¢ ‚àà Œ†ùëõ. According to Lemma 7.19 (a)
ùúî
ùúî
we have (ùë¢#)
‚àà ùêøùëõ = ùêø(B). Hence, there is a run of B on (ùë¢#)
that visits
accepting states infinitely often. In particular, there must be some state ùëìùë¢
‚àà ùêπ such Œ£‚àóùë¢Œ£‚àó
ùëõ
ùëõ
that ùëìùë¢ √ê√ê√ê‚Üí ùëìùë¢, i.e. ùëìùë¢ is reachable from itself under a word that
contains ùë¢. This ùúî
is simply a consequence of the fact that (ùë¢#)
contains infinitely many occurrences
of ùë¢, and the accepting run contains infinitely many occurrences of ùëìùë¢.
ùúî
Note that each such ùëìùë¢ need not be unique. An accepting run on (ùë¢#) may
of
course contain several accepting states infinitely often. Moreover, there can
be more than one accepting run. It suffices to pick an arbitrary ùëìùë¢ with the
required property for each ùë¢ ‚àà Œ†ùëõ .

Now suppose that, for the sake of contradiction, we have ùëõ! > ‚à£ùëÑ‚à£. We will
show that ùêø(B) ‚â† ùêøùëõ in this case.
Since ùêπ ‚äÜ ùëÑ but there are ùëõ! many permutations, there must be ùë¢, ùë£ ‚àà Œ†ùëõ
such ùúî
ùúî
that ùë¢ ‚â† ùë£ but ùëìùë¢ = ùëìùë£ =‚à∂ ùëì , i.e. some accepting runs on (ùë¢#) and on (ùë£#)
traverse
through a common accepting state infinitely often. Clearly, ùëì is reachable
from the initial state ùëûùêº under some word in Œ£‚àó
ùëõ . So w e have
Œ£‚àó
Œ£‚àóùë¢Œ£‚àó
Œ£‚àó ùë£Œ£‚àó
Œ£‚àóùë¢Œ£‚àó
Œ£‚àó ùë£Œ£‚àó
ùëõ
ùëõ
ùëõ
ùëõ
ùëõ
ùëõ

ùëõ
ùëõ
ùëõ
ùëû ùêº √ê‚Üí ùëì √ê√ê√ê‚Üí ùëì √ê√ê√ê‚Üí ùëì √ê√ê√ê‚Üí ùëì √ê√ê√ê‚Üí . . .
I.e. we get an accepting run of B on a word ùë§ that contains the two
different permutations ùë¢ and ùë£ infinitely often. According to Lemma 7.19
(b) we have ùë§ /
‚àà ùêøùëõ
which contradicts the assumption that ùêø(B) = ùêøùëõ .
‚óª
So we have indeed exposed a family of ùúî-regular languages that can be
recognised by NBA of linear size and whose complements require NBA of
size that asymptotically matches the upper bound we get through
determinisation via the Safra construction.
Corollary 7.21 There is a family of ùúî -regular languages (ùêøùëõ)ùëõ‚â•1 that are
recognisable by NBA of size O(ùëõ) such that every NBA recognising ùêøùëõ needs
to be of size ùëõ!
at least.
The lower bound on complementation then carries over to a lower bound
on determinisation. The next statement follows from the fact that DRA can
be complemented into DSA incurring no blowup, and these can be
translated into NBA at a polynomial
176
7 Determinisation

blowup only. So any determinisation procedure that is asymptotically better
than the one presented here would contradict the lower bound on
complementation in Cor. 7.21.
Corollary 7.22 There is a family (Aùëõ)ùëõ‚â•1 of NBA with O(ùëõ) many states
such that Œ©(ùëõ
every equivalent DRA must have 2
log ùëõ) many states and index Œ©(ùëõ) .
7.3.4 From NBA to DPA
Cor. 7.15 yields a deterministic counterpart to an arbitrary
nondeterministic B √ºchi automaton in the form of a Rabin or Muller
automaton. For algorithmic purposes it is sometimes more desirable,
though, to obtain a deterministic parity automaton.
This is achievable with the constructions seen so far:
a) From a given NBA A, construct a DMA using Cor. 7.15.
b) Turn the DMA into a DPA using the latest-appearance-record
construction of Thm. 6.28, observing that it preserves determinism, i.e. it
turns a DMA into a DPA.
O(ùëõ
This is not optimal, though. The blowup incurring in step (1) is 2
log ùëõ) in size;
the index is irrelevant for what follows. The construction of Thm. 6.28 turns
a DMA Œ©ùëõ
of size ùëõ into a DPA of size ùëõ2 ‚ãÖ ùëõ! in the worst case. Since ùëõ! ‚àà 2
we obtain a DPA

of doubly exponential size in this way .
It is possible, though, to obtain DPA of singly exponential size by
internalising the LAR construction. Again, we construct an automaton with
a transition-based acceptance condition and then refer to the general
construction to turn this into an automaton with a state-based acceptance
condition of the same kind, see Thm. 6.42
for how this is done in case of Rabin conditions. We need a small technical
definition.
Definition 7.23 Let ùë° be a history tree and ùë£ be one of its nodes. The
seniority ùë†(ùë£) of ùë£ (in ùë°) is the number of nodes ahead of ùë£ in a preorder
traversal of the tree, i.e.
the number of nodes that are above or further left of ùë£.
Example 7.24 Take the history tree ùë°5 shown in Fig. 7.4. A preorder
traversal of this tree yields the node list ùúÄ, 0, 00, 1, 10, 2, so the seniority
values of these nodes are ùë†(ùúÄ) = 0, ùë†(0) = 1, ùë†(00) = 2, ùë†(1) = 3, ùë†(10) = 4
and ùë† (2) = 5.
Theorem 7.25
O(ùëõ
For every NBA A of size ùëõ there is a DPA
log ùëõ)
e B of size 2
and
index O(ùëõ) such that ùêø(B) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ

, Œî,
ùêº
) be an NBA and B = (H, Œ£, ùë°ùêº
F ) be the corre-
sponding DRAe that accepts the same language according to Thm. 7.14. We
modify
‚Ä≤
this into a DPAe B ‚à∂= (H √ó L, Œ£, (ùë° , Œõ
ùêº
0), Œî‚Ä≤, Œ©) as follows, where L is the set of all
latest appearance records that contain the nodes of a history tree from H.
The initial LAR Œõ0 is ([ùúÄ], 0).
Bibliographic Notes for Chapter 7
177
The transition function Œî‚Ä≤ is obtained by extending Œî appropriately to
update the LARs as follows: Œî‚Ä≤((ùë°, Œõ), ùëé) ‚à∂= (Œî(ùë°, ùëé), Œõ‚Ä≤) where Œõ‚Ä≤ is
obtained from Œõ as
‚Ä≤
‚Ä≤
follows. Let Œõ = (ùúã, ùëö). Then Œõ‚Ä≤ ‚à∂= (ùúã , ùëö ) where
‚Ä¢ ‚Ä≤
ùúã

is obtained from ùúã by deleting those nodes that are unstable in the transition
‚Ä≤
from ùë° to ùë° , and then adding the (new names of these) unstable nodes as
well
‚Ä≤
as any new nodes created in the transition from ùë° to ùë° at the end of the
queue in some arbitrary but fixed order;
‚Ä¢ ‚Ä≤
ùëö
is the maximal length of a prefix of stable nodes in ùúã.
‚Ä≤
‚Ä≤
‚Ä≤
Then Œ© can assign a priority to every transition ((ùë°, (ùúã, ùëö)), ùëé, (ùë° , (ùúã , ùëö )))
‚àà Œî‚Ä≤
with ùúã = [ùë£ , . . . , ùë£
1
ùëò ] as follow s.
‚éß
‚é™
‚é™2 ‚ãÖ ùëö + 2,

if some ùë£ ùëó with ùëó ‚àà {1, . . . , ùëö} is
‚é™
‚é™
Œ©
‚Ä≤
‚Ä≤
((ùë° , Œõ), ùëé, (ùë° , Œõ‚Ä≤))
‚à∂= ‚é®
successful in the transition from ùë° to ùë° ,
‚é™
‚é™
‚é™
‚é™
‚é© 2 ‚ãÖ ùëö + 1,
otherwise .
We leave it as an exercise to argue for correctness of this construction and
for the
‚Ä≤
fact that this only yields a singly exponential blowup from A to B .
‚óª

As stated above, a DPAe can be turned into a DPA using the same
construction as in Thm. 6.42 which only incurs a mild blowup. This then
completes the argument that nondeterministic B √ºchi automata can be
determinised into parity automata.
Corollary 7.26
O(ùëõ
For every NBA A of size ùëõ there is a DPA B of size 2
log ùëõ) and
index O(ùëõ) such that ùêø(B) = ùêø(A) .
Bibliographic Notes
The problem of determinisation of a B √ºchi automaton clearly arose with
their introduction and was solved not too long afterwards by McNaughton
[McN66] who came up with a construction of a deterministic Muller
automaton of doubly exponential size compared to the original
nondeterministic B √ºchi automaton. The form of the Muller acceptance
condition used in this construction instigated the introduction of an
explicitly different and more specialised kind, later known as a Rabin
condition
[Rab69].
The doubly exponential blowup was seen as non-optimal which caused the
search for better determinisation procedures. Some alternatives were
suggested in the following years [Rab72, B √ºc73, TB73, Sch72, Cho74,
Eil74, Tho81] but none of them broke the doubly exponential barrier, some
were even triply exponential. A singly exponential construction was
eventually found by Safra in the late 80's only
[Saf88, Saf89] and was celebrated accordingly.
The construction in the form that is presented here, is - strictly speaking -

not Safra's, even though it is called "the Safra construction" here. Safra's
original construction yielded the essentials, in particular regarding the
refinement of the
178
7 Determinisation
powerset construction using a tree-like data structure. Safra did not use
history trees as they are called here. In his original work, nodes carry
names from a finite name space and have the ability to signal what we call
here being successful. Such minor differences in the underlying data
structures as well as the separation of the determinisation into automata
with a transition-based acceptance condition from the subsequent
transformation into a state-based one are of course not essential.
The details of the construction in the form presented here, including the use
of history trees, are due to Schewe [Sch09b]. His construction falls into a
line of work that examines possibilities to improve the original Safra
construction with the aim of O(ùëõ
closing the gap between lower and upper bounds in the area of ùëõ!, resp. 2
log ùëõ),
ùëõ
ùëõ
narrowing it down to the intersection of Œ©((1.64ùëõ) ) and ùëú((1.65ùëõ) )
[CZ09].
The lower bound on complementation presented here, giving also a lower
bound on the blowup needed in determinisation is from unpublished work
by Michel
[Mic88]. L √∂ding has provided further bounds on the transformations of
automata on infinite words [L √∂d99].

The determinisation of B √ºchi automata into parity automata, internalising
an otherwise non-optimal transformation of the Rabin condition into a
parity condition, is due to Piterman [Pit06]. Likewise, one may be
interested in the determinisation of other types of automata on ùúî-words,
even though they can be translated into NBA. This has extensively been
studied as well, for instance for generalised B √ºchi automata [SV12] but
most of all for Streett automata [Saf92, Sch02, Pit06, TWD20]
since they require a greater blowup when first translated into B √ºchi
automata.
It seems like Safra's original determinisation construction is without real
alternatives when it comes to an asymptotically optimal determinisation of
automata on ùúî-words in the sense that it yields the essential ingredients for
all subsequent constructions. Likewise, all subsequent constructions - even
for extensions of B √ºchi automata - can be seen as refinements and
optimisations of Safra's original construction. This is why we chose to stick
to the name "Safra construction" here even though the presented details
deviate slightly from the original construction.
Exercises
Exercise 76
ùëÑ
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, Œ£,
ùêº
) be an NBA and B = (2
{ùëû ùêº }, Œî, F ) be the
DBA resulting from it via the powerset construction, i.e. F = {ùëÜ ‚äÜ ùëÑ ‚à£ ùëÜ ‚à©
ùêπ ‚â† ‚àÖ}

and
Œî(ùëÜ, ùëé) ‚à∂= ‚ãÉ {ùëù ‚à£ (ùëû, ùëé, ùëù) ‚àà ùõø }
ùëû‚ààùëÜ
ùëÑ
for every ùëÜ ‚àà 2
and ùëé ‚àà Œ£. Show that ùêø(B) ‚äá ùêø( A).
Exercise 77 Construct the run of the deterministic automaton from Fig. 7.3
on the ùúî
word (ùëéùëèùëè)
up to the point where a loop is closed. Which nodes of the history trees
occurring in this run are stable on the looping part, which ones are
successful in which transitions?
Exercises for Chapter 7
179
Exercise 78 Prove Lemma 7.19.
Exercise 79 Complete the missing details of the proof of Thm. 7.25, i.e.
show that
‚Ä≤
O(ùëõ
a) ‚à£B ‚à£ ‚àà 2
log ùëõ) where ùëõ = ‚à£A‚à£, and
‚Ä≤

‚Ä≤
b) ùêø(B ) = ùêø(A). Hint: It suffices of course to show that ùêø(B ) = ùêø(B ).
Exercise 80 Construct the automaton obtained by applying the
determinisation construction to the NBA A3 from Fig. 7.5. It suffices to start
with the initial state and ùúî
only construct those states that are reachable in a run on the word ùë§ ‚à∂=
(123#) or
‚Ä≤
ùúî
ùë§
‚à∂= (123#132#) . Explain, using the notions of stable and successful
transitions,
‚Ä≤
why it accepts ùë§ but rejects ùë§.
Chapter 8
Decision Problems
Automata are used for an algorithmic approach to logical decision
problems, in particular the satisfiability problem: does a given ùúë have a
model? Other equally fundamental problems like the validity problem (is a
given formula ùúë true in all possible interpretations?) or the equivalence

problem (do two given formulas ùúë and ùúì express the same property?) can
easily be reduced to the satisfiability problem, at least when the logic
provides negation.
This chapter examines algorithmic problems for automata on infinite
words. First we address the non-emptiness problem: is ùêø(A) ‚â† ‚àÖ for a given
automaton A of some particular kind? It corresponds directly to the
satisfiability problem in logic when there is an automaton Aùúë for each
logical formula ùúë under consideration that accepts exactly the models of ùúë,
i.e. when there is an equivalence-preserving mapping from formulas to
automata. This is of course the case for MSO and NBA for example, as was
shown in Chp. 5, and also for MSO over finite words and NFA.
Chp. 10 will introduce linear-time temporal logic which can be seen as a
restriction of MSO with a perhaps more readable syntax. Its use in program
specification and verification heavily relies on such equivalence-preserving
translations from formulas into automata as well, and the non-emptiness
problem for NBA therefore plays an important role in the algorithmics of
program verification.
We also address the universality problem (is ùêø(A) = Œ£ ùúî for some given
automaton A over alphabet Œ£?) and its generalisation, the subsumption or
inclusion problem (is ùêø(A) ‚äÜ ùêø(B) for two given automata A, B?). It should
be clear that universality is the counterpart of logical validity on the
automata side, again assuming that formulas can be translated into
equivalent automata. The subsumption problem then corresponds directly to
an implication problem on the logical side: given ùúë, ùúì, is ùúë ‚Üí ùúì valid? Thus,
not surprisingly, it is closely related to universality, albeit more general, but
we will show how algorithms for universality can also be used to decide
subsumption. Moreover, subsumption covers equivalence: we have ùúë ‚â° ùúì
iff ùêø(Aùúë ) ‚äÜ ùêø(Aùúì) and ùêø(Aùúì) ‚äÜ ùêø(Aùúë ) where Aùúë and Aùúì are assumed to be
automata equivalent to the logical formulas ùúë and ùúì.
Thus, the decision problems on logics on one hand or automata on the other
fall into two groups: non-emptiness being one of them and universality,
subsumption

¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
181
https://doi.org/10.1007/978-3-662-72154-4_8
182
8 Decision Problems
and equivalence forming the other. The reason for the distinction is that,
whilst all of the latter can be reduced to the former, this requires
complementation. Even though we have complementation closure of ùúî-
regular languages and at least two explicit procedures for complementing
NBA, both incur an exponential blowup. This is why we address the
problems of the second group separately. This does not avoid the extra
complexity - non-emptiness for NBA is NLogSpace-complete, universality
etc. is PSpace-complete - but it can avoid the explicit construction of
exponentially large automata at the expense of applying an exponential
algorithm to small input rather than a polynomial algorithm to some input
that is exponentially larger.
8.1 Automata Non-Emptiness
The decidability of the non-emptiness problem for NBA has been discussed
in Chp. 5
already in the context of the decidability of satisfiability of MSO over
infinite words.
The basis was B √ºchi's characterisation of ùúî-regular languages as finite
unions of the ùëõ
ùúî

form ‚ãÉ
ùëà ùëâ
, ùëâ
ùëñ=1
ùëñ
ùëñ
for regular languages ùëàùëñ
ùëñ , cf. Thm. 5.13. This, together with the
observation that these languages of finite words are recognisable by NFA
obtained from the same transition graph as the ùúî-regular languages, led to
a simple algorithm for deciding NBA non-emptiness: find an accepting state
that is reachable from the initial state and that is on a non-trivial cycle.
These are in fact the two main concepts - reachability and cycles in
directed graphs - that are needed for deciding non-emptiness of various
kinds of automata over infinite words. We will briefly discuss them before
continuing to devise nonemptiness checks for other kinds of automata
besides NBA.
8.1.1 Graphs and Strongly Connected Components
We assume familiarity with the basics of directed graphs.
Definition 8.1 Let G = (ùëâ, ùê∏) with ùê∏ ‚äÜ ùëâ √ó ùëâ be a directed graph. The
reflexive-
‚àó
ùëñ
transitive closure of ùê∏ is defined as ùê∏

‚à∂= ‚ãÉ
ùê∏
ùëñ‚ààN
where
0
ùê∏
‚à∂= {(ùë£, ùë£) ‚à£ ùë£ ‚àà ùëâ }
ùëñ+1
ùëñ
ùê∏
‚à∂= {(ùë£, ùë§) ‚à£ ‚àÉùë¢ ‚àà ùëâ .(ùë£, ùë¢) ‚àà ùê∏
and (ùë¢, ùë§) ‚àà ùê∏ }
+
ùëñ
The transitive closure is the relation ùê∏
‚à∂= ‚ãÉ
ùê∏
ùëñ‚â•1
.
ùëñ

Note that the relation ùê∏ in a graph G consists of all pairs (ùë¢, ùë£) of nodes
for which there is a path from ùë¢ to ùë£ of length ùëñ. Here, the length of a path
is measured as the number of edges that make up the path. Hence, a path of
length 0 consists of a single node only that is both the start and the end of
the path.
8.1 Automata Non-Emptiness
183
‚àó
+
Then ùê∏ , resp. ùê∏
consist of all pairs (ùë¢, ùë£) for which there is a path of some
arbitrary length, resp. some arbitrary non-zero length from ùë¢ to ùë£. In other
words,
‚àó
(ùë¢, ùë£) ‚àà ùê∏
iff ùë£ is reachable from ùë¢ along the edges of the underlying graph.
+
Likewise, (ùë¢, ùë£) ‚àà ùê∏
iff ùë£ is reachable from ùë¢ along a path that takes at least one
edge. Note that this is does not entail ùë¢ ‚â† ùë£. Clearly, a node can be
reachable from itself on a path of non-zero length. This is exactly the case
when the underlying graph contains a cycle.
Definition 8.2 A strongly connected component (SCC) of a directed graph
G =

‚àó
(ùëâ , ùê∏ ) is a ùê∂ ‚äÜ ùëâ such that for all ùë£, ùë§ ‚àà ùê∂ we have (ùë£, ùë§) ‚àà ùê∏ . An
SCC ùê∂ is
‚Ä≤
‚Ä≤
‚Ä≤
maximal if for all ùê∂ with ùê∂ ‚ää ùê∂ ‚äÜ ùëâ we have that ùê∂ is not an SCC.
An SCC ùê∂ is called non-trivial if it contains at least one edge, i.e. if ùê∂ √óùê∂
‚à© ùê∏ ‚â† ‚àÖ.
Example 8.3 Consider the following directed graph G.
0
1
2
3
4
5
6
7
The set {0, 1} forms an SCC since both 0 and 1 clearly are reachable from
one another. Note that every node is always reachable from itself. Hence, in
order to
‚àó

determine whether ùê∂ is an SCC, it suffices to only check that (ùë¢, ùë£) ‚àà ùê∏
for all
ùë¢, ùë£ ‚àà ùê∂ with ùë¢ ‚â† ùë£.
Likewise, {3, 7} is an SCC for the same reason. However, while {0, 1} is a
maximal SCC, {3, 7} is not, because its superset {3, 6, 7} also has the
property that all nodes in it are reachable from one another. It is still not a
maximal one because
{2, 3, 6, 7} is also an SCC, and this one is maximal.
Both {4} and {5} are SCCs, even maximal ones. Here the difference is non-
triviality: while {4} is a non-trivial one because there is a path of length 1
from 4 to 4, {5} is a trivial one: 5 is only reachable from itself on a path of
length 0.
A fundamental and relatively simple result in graph theory states that every
directed graph can be decomposed uniquely into maximal SCCs. An SCC
decomposition of a graph G = (ùëâ , ùê∏ ) is a set of maximal SCCs {ùê∂ , . . . ,
ùê∂
1
ùëö }
such that
ùëö
‚ãÉ
ùê∂
ùëñ=1
ùëñ

= ùëâ . Necessarily we have ùê∂ùëñ ‚à© ùê∂ ùëó = ‚àÖ whenever ùëñ ‚â† ùëó because no node
can belong to two different maximal SCCs. An immediate consequence of
this is the fact that the decomposition of a directed graph into maximal
SCCs is unique.
Here and henceforth, when estimating complexities, we will stick to the
convention that ùëõ denotes the number of nodes in the graph, and ùëí denotes
its number of edges. We will also assume that ùëí ‚àà Œ©(ùëõ), i.e. there are
essentially not fewer edges than nodes. This excludes degenerate cases of
graphs with many isolated nodes.
Clearly, the SCC decomposition of a graph G = (ùëâ , ùê∏ ) can be computed
na¬®ƒ±vely
‚àó
by checking for each pair ùë¢, ùë£ ‚àà ùëâ whether {(ùë¢, ùë£), (ùë£, ùë¢)} ‚àà ùê∏
using two graph
searches. When this information is obtained for each pair, assembling the
maximal SCCs boils down to a simple lookup procedure on this
information.
184
8 Decision Problems
It is known that reachability of a node from another can be done in time
O(ùëí) using breadth-first or depth-first search for instance. This leads to an
overall time complexity of O(ùëõ2 ‚ãÖ ùëí) which can be estimated as O(ùëõ4) since
ùëí ‚â§ ùëõ2 in g eneral.
It should be clear that this is not optimal, though, as this na¬®ƒ±ve procedure
recalculates reachability information multiple times. Take the graph in Ex.
8.3 for instance.

Suppose we already know that 7 is reachable from 1. Then we do not need
to explore an entire path from 0 to 7 to work out whether 7 is also reachable
from 0. Instead, it suffices to see that there is a (short) path from 0 to 1.
This is a classic situation for employing so-called dynamic programming,
i.e. to compute and store the results of subtasks in order to use them
efficiently for the computation of supertasks. In this case, this simply boils
down to the question of
‚àó
whether the relation ùê∏
can be computed from ùê∏ . This is clearly possible but in
order to beat the bound of O(ùëõ4) in the end, this needs to be done in a
clever way.
Lemma 8.4
‚àó
Given a directed graph G = (ùëâ , ùê∏ ) , its reflexive-transitive closure ùê∏
can be computed in time O(ùëõ3) .
Proof We sketch an algorithm that maintains a queue ùëÑ and gradually
assembles
‚àó
‚àó
the edges in ùê∏ . At the beginning, ùê∏
is initialised to be {(ùë¢, ùë¢) ‚à£ ùë¢ ‚àà ùëâ }, and ùëÑ

contains all edges in an arbitrary order. We also assume that, given a node
ùë¢, we can obtain the list of all of its successors in constant time.
For as long as the queue ùëÑ is not empty, take the first edge (ùë¢, ùë£) from ùëÑ,
add it
‚àó
to ùê∏ , take the list ùë§ , . . . , ùë§
1
ùëò
of ùë£'s successors and add each (ùë¢, ùë§ùëñ) to the end of
‚àó
the queue for all ùëñ = 1, . . . , ùëò , unless it belongs to ùê∏
already .
It should be clear that this algorithm terminates because there are only
finitely many pairs (ùë¢, ùë£) ‚àà ùëâ 2 and none can be processed twice. It is also
easy to see that it
‚àó
is correct in the sense that it computes a set ùê∏
of pairs of nodes (ùë¢, ùë£) such that ùë£
is reachable from ùë¢ .
It is also complete in the sense that whenever ùë£ is reachable from ùë¢ then the
pair
‚àó

(ùë¢, ùë£) gets added to ùê∏
eventually. This can be shown by induction on the length ‚Ñì
of a shortest path from ùë¢ to ùë£. In case of ‚Ñì = 0 we have ùë£ = ùë¢ and (ùë¢, ùë¢) is
added to
‚àó
ùê∏
at the beginning. In case of ‚Ñì = 1 we have (ùë¢, ùë£) ‚àà ùê∏ and this edge is put
into
‚àó
ùëÑ at the beginning, so it will eventually be removed from there and added
to ùê∏ . If ‚Ñì > 1 then there is some node ùë§ such that ùë§ is reachable from ùë¢ in
‚Ñì ‚àí 1 steps. By
‚àó
induction, the pair (ùë¢, ùë§) gets added to ùê∏
eventually. But then it must have been
processed in the queue. At this point, since (ùë§, ùë£) ‚àà ùê∏ , the pair (ùë¢, ùë£) gets
added to
‚àó
the queue and then eventually ends up in ùê∏ .
At last, the complexity of this procedure remains to be analysed. There are
at most
‚àó
ùëõ2 potential edges in ùê∏

that get processed in the queue. Processing an edge (ùë¢, ùë£)
requires obtaining the list of successors of ùë£, assumed to be possible in
constant time, but then also traversing that list which may contain up to ùëõ
elements. Hence, processing a pair requires time O(ùëõ), leading to the
overall time complexity of O(ùëõ3).
‚óª
This is not the most efficient way to compute an SCC decomposition of a
directed graph, though. There is a clever algorithm known as Tarjan's
algorithm which does this in linear time.
8.1 Automata Non-Emptiness
185
Proposition 8.5 The SCC decomposition of a directed graph can be
computed in time O(ùëí) .
We refer to the literature for a proof, resp. an explanation of how this is
done using two depth-first searches on the graph and its transposed graph.
To be precise, time O(ùëí) is generally not sufficient to output an SCC
decomposition by stating for each pair of nodes whether they are mutually
connected or not. Tarjan's algorithm computes a value for each node, so
that two nodes belong to the same SCC iff they obtain the same value. These
values can be seen as a symbolic representation of the SCC decomposition
in the sense that from this data, we can decide in constant time whether two
nodes belong to the same maximal SCC.
In the light of the abstract graph-theoretic view on the algorithmic side of
decision problems on automata, we can rephrase the non-emptiness
problem for an NBA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) as follows. ùêø(A) ‚â† ‚àÖ iff there is a node ùëû ‚àà ùêπ in some

maximal, non-trivial SCC that is reachable from ùëûùêº in the graph GA = (ùëÑ,
ùê∏ ) where ùê∏ = {( ùëù, ùëû) ‚à£ ‚àÉùëé ‚àà Œ£ s.t. (ùëù, ùëé, ùëû) ‚àà ùõø}.
So the directed graph to be analysed for reachability and maximal SCCs is
just the transition graph of the automaton with transition labels being
ignored. This is justified because in order to decide non-emptiness we are
only interested in the existence of some word but not its exact letter
structure. Hence, the labels on the transitions become irrelevant for the
question whether some (here: ultimately periodic) word induces a run that
connects the initial state to some accepting state and this one back to itself
on a proper loop.
8.1.2 Rabin and Parity Automata
In line with the considerations above, when determining the complexity of
some procedure operating on an automaton we will use ùëõ to denote its
number of states, ùëí
to denote its number of transitions and, whenever applicable, ùëò to denote
its index, i.e. the number of Rabin / Streett pairs, the number of priorities
being used etc.
We begin with the non-emptiness problem for Rabin automata.
Theorem 8.6 The non-emptiness problem for NRA of size ùëõ and index ùëò is
solvable in time O(ùëõ2 ‚ãÖ ùëò ) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø,
, ùêπ
, ùêπ
ùêº
{(ùê∫ 1
1), . . . , (ùê∫ ùëò

ùëò )}) be an NRA and GA be the di-
rected graph obtained from it with states as nodes and edges as unlabelled
transitions, as done above for NBA.
We have ùêø(A) ‚â† ‚àÖ iff there is an ùëñ ‚àà {1, . . . , ùëò} and some ùëû ‚àà ùê∫ùëñ such that
ùëû
is reachable from ùëûùêº and reachable from itself on a non-empty path that
does not contain any node from ùêπùëñ .
To decide this condition we can proceed as follows. W.l.o.g. we can assume
that GA does not contain states that are unreachable from ùëûùêº . This can be
ensured using a simple reachability analysis in time O(ùëí). We then iterate
through all ùëñ = 1, . . . , ùëò, doing the following.
186
8 Decision Problems
ùëñ
1) Let G
result from G
A
A by removing all states from ùêπùëñ including their incident
edges. This can be done in time O(ùëí).
ùëñ
2) Compute the SCC decomposition of G
in time O(ùëí).
A

3) Check whether there is a state ùëû ‚àà ùê∫ùëñ that belongs to a non-trivial
maximal SCC.
This can be done in time O(ùëõ) simply by traversing through all states to
find one in ùê∫ùëñ. It then only remains to see whether it has a successor that
belongs to the same SCC. Altogether this requires time O(ùëõ2).
Since ùëí ‚â§ ùëõ2 we obtain an overall running time of O(ùëõ2 ‚ãÖ ùëò ).
Correctness of this procedure follows from the characterisation of non-
emptiness above. Suppose there is some ùëñ ‚àà {1, . . . , ùëò} and some ùëû ‚àà ùê∫ùëñ
that is reachable from ùëû ùêº and reachable from itself without seeing a state
in ùêπùëñ in between. It survives the removal of all states that are not reachable
from ùëûùêº . Conversely, after this step, every remaining state is reachable
from ùëûùêº so this does not need to be checked any further.
At last, if ùëû is reachable from itself on a path not visiting states from ùêπùëñ
then it must belong to a non-trivial SCC in the directed graph obtained
after removing all nodes from ùêπùëñ, and vice-versa.
‚óª
It is fair to ask whether this is in any way beneficial over the approach that
transforms an NRA into an equivalent NBA first, possibly regarding it as a
Muller automaton in between (Thm. 6.5 and 6.24). The detour via Muller
automata definitely creates an avoidable overhead. Instead, one can
translate an NRA directly into an NBA using the same principle as used in
the translation from Muller automata: the resulting NBA simulates the NRA
and guesses the Rabin pair (ùê∫, ùêπ) as well as the moment after which no
more states in ùêπ will be seen. This is realised by a separate component for
each such Rabin pair which is obtained as a copy of the NRA's transition
graph with states from ùêπ missing and states from ùê∫ being accepting.
Note that the translation from Rabin into Muller automata does not
preserve the index. In general the index of the Muller automaton is much
higher. This is why this direct translation into NBA that creates ùëò many

components, where ùëò is the index of the Rabin or Muller automaton, is
more efficient than going through Muller automata.
The second aspect to note here is that this sketched translation uses the
same principles as the algorithm in the proof of Thm. 8.6, most notably the
removal of states from the ùêπ-component of a Rabin pair. It is in fact true
that the algorithm from Thm. 8.6 is obtained from the algorithm for NBA
non-emptiness when run on the NBA translated from the input NRA in the
way sketched above. Hence, there is no time-efficiency gain in this
algorithm when compared to the method that reduces NRA non-emptiness to
NBA non-emptiness. However, the algorithm of Thm. 8.6
is more space efficient because it avoids the explicit construction of an
automaton that contains multiple copies, each of which is obtained from a
given automaton's transition graph with certain nodes missing.
The same principles can then be applied to obtain an algorithm for
deciding the non-emptiness problem for parity automata.
Corollary 8.7 The non-emptiness problem for NPA of size ùëõ and index ùëò is
solvable in time O(ùëõ2 ‚ãÖ ùëò ) .
8.1 Automata Non-Emptiness
187
Again, it is more space efficient to avoid the explicit construction of an NBA
from an NPA but to iterate through all even priorities, computing SCC
decompositions several times in order to find a node of that priority that
can reach itself on a path not traversing through nodes of greater odd
priority. We leave it as an exercise to devise a non-emptiness check for
Muller automata.
8.1.3 Streett Automata
While Streett automata are equi-expressive to Rabin automata, for instance
through a translation via Muller and then B √ºchi automata, this is not
advisable for a nonemptiness check for NSA as this involves two blowups:

the translation from Streett to Muller automata can be done on the same
transition graph but at a general increase in its index which can become
exponential in the size of the underlying automaton.
Then this Muller index becomes a factor in the subsequent translation into
B √ºchi automata.
Moreover, there is a conceptual difference between Streett and Rabin
automata which justifies considering the former separately as their non-
emptiness test is conceptually more difficult. The reason is that a Rabin
condition is a disjunction: an NRA accepts a word if it has a run that
satisfies some Rabin pair. Disjunctions are harmless for non-emptiness
checks because non-emptiness is an existential property.
A Streett condition, on the other hand, is conjunctive: a word is accepted by
an NSA if it has a run that satisfies all Streett pairs. It should be clear that
this excludes a simple handling of the Streett pairs by separate
consideration as it is done in the case of Rabin automata.
We need a technical observation in order to study the non-emptiness
problem for NSA.
Definition 8.8 Let A be an automaton over ùúî-words and ùúå = ùëû , ùëû , ùëû , . . .
0
1
2
be a run
of it on some word. The run is called ultimately periodic if there is some ùëñ ‚â•
0, ùëõ ‚â• 1
such that for all ùëó ‚â• ùëñ we have ùëû ùëó = ùëû ùëó+ùëõ. Thus, it eventually traverses a
particular loop f orever.

A fundamental result in the theory of ùúî-regular languages states that an
NBA accepts some word iff it has an ultimately periodic run. This is easily
seen to be an immediate consequence of Thm. 5.13: an ùúî-regular language
is of the form ùëõ
ùúî
‚ãÉ
ùëà ùëâ
, . . . , ùëà
, ùëâ , . . . , ùëâ
ùëñ=1
ùëñ
ùëñ
for regular languages of finite words ùëà1
ùëõ
1
ùëõ
such that
ùúî
ùúÄ /
‚àà ùëâùëñ for all ùëñ = 1, . . . , ùëõ. Hence, it must contain a word of the form ùë¢ùë£ ,
and this clearly has an ultimately periodic accepting run. Note that this
result has also been used in B √ºchi's proof of complementation closure for
ùúî-regular languag es.

Ultimate periodicity is a property of runs and therefore depends on the
underlying automaton. It is not a property of a language, for otherwise it
would be trivial to lift this to Streett-recognisable languages since they are
just the ùúî-regular ones.
However, it is also not very difficult to show that Streett automata have
ultimately periodic accepting runs as well.
188
8 Decision Problems
Algorithm 1 finding SCCs that contain a run satisfying all Streett pairs.
1: procedure StAux((G = (ùëâ , ùê∏), {(ùê∫ , ùêπ ), . . . , (ùê∫ , ùêπ )}) 1
1
ùëò
ùëò
)
2:
let ùê∂ , . . . , ùê∂
1
ùëö be the non-trivial, maximal SCCs of G
3:
if ‚àÉùëñ ‚àà {1, . . . , ùëö}.‚àÄ ùëó = 1, . . . , ùëò. ùê∂ ‚à© ùêπ ‚â† ‚àÖ then ùëñ
ùëó
4:

return true
5:
else
6:
for ùëñ = 1, . . . , ùëö do
7:
ùêΩ ‚Üê { ùëó ‚à£ ùê∂ ‚à© ùêπ = ‚àÖ}
ùëñ
ùëó
‚Ä≤
8:
ùëâ
‚Üê ùê∂ ‚àñ ‚ãÉ{ùê∫ ‚à£ ùëó ‚àà ùêΩ}
ùëñ
ùëó
‚Ä≤
‚Ä≤
‚Ä≤
9:
ùê∏

‚Üê ùê∏ ‚à© ùëâ √ó ùëâ
‚Ä≤
‚Ä≤
10:
G‚Ä≤ ‚Üê (ùëâ , ùê∏ )
11:
S‚Ä≤ ‚Üê {(ùê∫ , ùêπ ) ‚à£ ùëó /‚àà ùêΩ}
ùëó
ùëó
12:
if StAux(G‚Ä≤, S‚Ä≤) = true then
13:
return true
14:
return false
Lemma 8.9 Let A be an NSA. We have ùêø(A) ‚â† ‚àÖ iff there is an accepting,
ultimately periodic run in A .
Proof The direction "‚áê" is trivial. For the "‚áí"-direction let A = (ùëÑ, Œ£, ùëû ,
ùõø, ùêº
F )
with F = {(ùê∫ , ùêπ

, ùêπ
1
1), . . . , (ùê∫ ùëò
ùëò )}
and assume that ùë§ ‚àà ùêø(A). I.e. there is an
accepting run ùúå = ùëû , ùëû , . . .
0
1
of A on ùë§. By definition, we have inf ùúå ‚à© ùê∫ùëñ = ‚àÖ or
inf ùúå ‚à© ùêπùëñ ‚â† ‚àÖ for all ùëñ = 1, . . . , ùëò.
Since ‚à£ùëÑ‚à£ < ‚àû, there is an earliest and shortest infix ùëû , . . . , ùëû
ùëó
ùëö for some 0 ‚â§ ùëó < ùëö
such that ùëû
, . . . , ùëû
ùëö
= ùëû ùëó and for all ùëñ = 1, . . . , ùëò we have ùê∫ùëñ ‚à© {ùëû ùëó
ùëö‚àí1} = ‚àÖ or
ùêπ
, . . . , ùëû

ùëñ ‚à© {ùëû ùëó
ùëö‚àí1} ‚â† ‚àÖ. Note that ùëû ùëó is a successor or ùëûùëö ‚àí1. Hence,
‚Ä≤
ùúå
‚à∂= ùëû , . . . , ùëû
, ùëû
, . . . , ùëû
, ùëû
, . . . , ùëû
, . . .
0
ùëó ‚àí1
ùëó
ùëö‚àí1
ùëó
ùëö‚àí1
is clearly an ultimately periodic run of A. It is also accepting because, for
every ùëñ =
1, . . . , ùëò it either does not contain any state from ùê∫ùëñ anymore after the first
occurrence of ùëû ùëó , or it contains infinitely many occurrences of some state
in ùêπùëñ because ultimate periodicity entails that each state on the looping

part occurs infinitely often and those outside of the looping part only occur
finitely often.
‚óª
Given a directed graph G = (ùëâ , ùê∏ ), a maximal SCC ùê∂ ‚äÜ ùëâ and a set F =
{(ùê∫ , ùêπ
, ùêπ
1
1), . . . , (ùê∫ ùëò
ùëò )}
of pairs of sets of nodes, here also called a Streett
condition, we say that ùê∂ satisfies F if ùê∂ contains a path ùë£ , ùë£ , . . . , ùë£
0
1
ùëö
for some
ùëö ‚â• 0 such that
‚Ä¢
ùúî
(ùë£ , ùë£
, ùë£
, . . . , ùë£

ùëó
ùëó +1) ‚àà ùê∏ for all ùëó = 0, . . . , ùëö ‚àí 1, and (ùë£ ùëö
0) ‚àà ùê∏ , i.e. (ùë£0
ùëö )
is
an infinite periodic path within ùê∂,
‚Ä¢ for all ùëñ = 1, . . . , ùëò we have that ùê∫
, . . . , ùë£
, . . . , ùë£
ùëñ ‚à© {ùë£ 0
ùëö } = ‚àÖ or ùêπùëñ ‚à© {ùë£0
ùëö } ‚â† ‚àÖ.
Next we present an algorithm StAux that takes as input a directed graph G
= (ùëâ , ùê∏ ) and a Streett condition F and decides whether G contains a non-
trivial maximal SCC that satisfies F .
8.1 Automata Non-Emptiness
189
The algorithm works recursively over the number of Streett pairs as follows.
First we decompose the given graph into SCCs and discard the trivial ones.
If there is a non-trivial SCC ùê∂ such that ùê∂ ‚à© ùêπùëñ ‚â† ‚àÖ for all ùëñ = 1, . . . , ùëò
then we can return true, because in an SCC we can find paths from every
node to every other node. Hence, we can create a path that traverses nodes
from each ùêπùëñ in some arbitrary but fixed order all over again.

If this is not the case, then the graph G may still have an SCC containing
the looping part of an ultimately periodic path that satisfies all Streett
pairs. Suppose such an SCC ùê∂
, ùêπ
ùëñ
is disjoint from the set ùêπùëó in a Streett pair (ùê∫ ùëó
ùëó ). In this case
we need to check whether ùê∫ ùëó can be avoided inside this SCC whilst still
repeatedly hitting states from other Streett pairs. This is done by removing
all states from ùê∫ ùëó
for any Streett pair (ùê∫ , ùêπ
ùëó
ùëó ) for which ùêπ ùëó is disjoint from ùê∂ùëñ , and then calling the
algorithm recursively on the potentially reduced graph and the remaining
Streett pairs whose ùêπ-component still has an intersection with this SCC.
The second argument is then guaranteed to be smaller now.
Lemma 8.10 Algorithm StAux correctly decides for a graph G = (ùëâ, ùê∏) and
Streett condition F whether G contains a non-trivial SCC ùê∂ that satisfies F
.
Proof Correctness is argued for along the same lines as explained above: if
some recursion branch eventually yields true, then by successive SCC
decompositions a maximal SCC of the original graph has been found in
which a cyclic path can be constructed that either traverses ùêπ eventually or
avoids ùê∫ entirely for every original Streett pair (ùê∫, ùêπ). This SCC must
necessarily be non-trivial because trivial ones are not considered and do
not contribute to a return value true.

Likewise, if G contains a non-trivial SCC ùê∂ with the desired properties than
algorithm StAux wil eventually return true, depending on how ùê∂ fulfills all
Streett pairs. If it has a non-empty intersection will all Streett pairs then
algorithm StAux returns true immediately in line 4.
‚óª
Another interesting question concerns its running time.
Lemma 8.11 Algorithm StAux terminates on input (G, F) in time O(ùëíùëò2)
where ùëí
is the number of edges in G and ùëò = ‚à£F ‚à£ .
Proof Termination is guaranteed because the condition in line 3 is trivially
true when S = ‚àÖ, and in every iteration of the for-loop in lines 6ff, we have
ùêΩ ‚ää {1, . . . , ùëò } for otherwise the condition in line 3 would have been true
already. Hence, the recursion depth is limited by the number of Streett pairs
in the initial argument.
Estimating the running time requires a refined consideration. According to
Prop. 8.5 the SCC decomposition can be computed in time O(ùëí). We can
write a recurrence equation for the worst-case running time depending on
the number of nodes ùëõ, the number of edges ùëí and the size of the Streett
condition ùëò as follows.
ùëá (ùëõ, 0) = O(1)
ùëö
ùëá (ùëõ, ùëò )
= O(ùëí) + O(ùëò ‚ãÖ ùëõ) + ‚àë O(ùëí) + ùëá (‚à£ùê∂ùëñ ‚à£, ùëò ‚àí 1) ‚â§ O(ùëí ‚ãÖ ùëò ) + ùëá (ùëõ, ùëò ‚àí 1)
ùëñ=1
190
8 Decision Problems

The inequation holds because we can assume ùëõ ‚â§ ùëí and that ùëá (ùëõ, ùëò ) is at
least linear in its first argument. This is the case because otherwise it would
not have time to consider the graph given as its input. One can then check
that ùëá (ùëõ, ùëò ) = O(ùëíùëò 2) solves this recurrence.
‚óª
We can the use this auxiliary algorithm on plain directed graphs to solve
the non-emptiness problem for Streett automata.
Theorem 8.12 The non-emptiness problem for NSA with ùëí transitions and
index ùëò
is solvable in time O(ùëíùëò 2) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø,
ùêº
F ) be an NSA with ‚à£F ‚à£ = ùëò and ‚à£ùõø‚à£ = ùëí. According to
Lemma 8.9 it suffices to search for ultimately periodic runs that satisfy the
Streett condition F in order to decide whether ùêø(A) ‚â† ‚àÖ. Hence, we have
ùêø(A) ‚â† ‚àÖ iff there is an SCC ùê∂ ‚äÜ ùëÑ that is reachable from ùëûùêº and which
contains a cyclic path that satisfies F . According to Lemma 8.11 this can be
decided in time O(ùëíùëò 2) by running algorithm StAux on transition graph of
A with the Streett condition F after the removal of states that are not
reachable from ùëû ùêº .
‚óª
It is important not to apply algorithm StAux directly to the transition graph
of the NSA but to remove non-reachable states first, as StAux does not check
for reachability itself. In essence, algorithm StAux only determines the
existence of the looping part of an ultimately periodic run, and by ensuring
that it only operates on reachable states, this looping part can always be
extended with a prefix to form an ultimately periodic and accepting run
starting in the automaton's initial state.

8.2 Universality and Subsumption
As argued above, problems other than non-emptiness, in particular
universality, subsumption and equivalence, are different in their nature in
that they involve complementation when reduced to non-emptiness. Since
complementation is combinatorially not without certain difficulties, it is
worth considering direct approaches to these problems that avoid explicit
complementation.
8.2.1 From Subsumption to Universality
It should be clear that the subsumption problem is the most general problem
of the three mentioned above, in the sense that the others easily reduce to it.
Lemma 8.13 Any algorithm for the subsumption problem for NBA / NcoBA /
NPA /
NRA / NSA / NMA can be used to solve the universality and equivalence
problem for these kinds of automata as well.
8.2 Universality and Subsumption
191
Proof For the equivalence problem this simply follows from the fact that
ùêø(A) =
ùêø (B) iff ùêø(A) ‚äÜ ùêø(B) and ùêø(B) ‚äÜ ùêø(A). Thus, an equivalence checker can
be built from two calls to a subsumption check er.
For the universality problem this is a simple consequence of the fact that
the universal language Œ£ ùúî is recognisable with each of the mentioned
automata. In fact, a one-state automaton suffices in each case. Moreover,
we have ùêø(A) = Œ£ ùúî iff Œ£ùúî ‚äÜ ùêø(A). Hence, universality of automaton A can
be determined by checking for subsumption between an automaton
recognising Œ£ ùúî and A.
‚óª

Nevertheless, the universality problem is a little bit simpler to study from a
technical point of view, without missing any essentials that would be
necessary for subsumption. The question therefore arises whether
subsumption can be reduced to universality as well. The answer is yes, and
this follows from complexity-theoretic considerations already: both
subsumption and universality for NFA and therefore also all kinds of
automata over ùúî-words are PSpace-complete, so (polynomial-time)
reductions between them exist in either direction. However, this argument is
not immediately constructive, and even when considering this in detail, one
may end up with an NBA encoding runs of Turing Machines that solve the
subsumption problem for NBA for instance. So the question really is: is
there a direct reduction from subsumption to universality? The answer is
still yes, and the trick that is needed when constructing an NBA C from two
NBA A and B so that the language of C is universal iff ùêø(A) ‚äÜ ùêø(B), is to
allow C to work over a different alphabet than A and B.
Theorem 8.14 For all NBA A, B over some common alphabet Œ£ there is an
NBA C of size at most O(‚à£A‚à£ + ‚à£B‚à£) over an alphabet Œî such that ùêø(C) =
Œîùúî iff ùêø(A) ‚äÜ ùêø(B) .
Proof
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, Œ£, ùëû , ùõø , ùêπ
ùêº
) and B = (ùëÑ

). W.l.o.g. we can assume
ùêº
them to be total, i.e. runs are always infinite, and they never get stuck on
any letter.
ùúî
We have ùêø(A) ‚äÜ ùêø(B) iff for every word ùë§ ‚àà Œ£ ùúî and every accepting run ùúå
‚àà ùëÑ
‚Ä≤
of A on ùë§ there is an accepting run ùúå of B on ùë§. This can be reformulated
as follows.
ùúî
For every sequence ùúå ‚àà ùëÑ
one of three cases holds:
ùúî
(i) ùúå is not a run of A on some word in Œ£ ,
ùúî
(ii) ùúå is a run of A on some word in Œ£
but it is not an accepting run,
(iii) ùúå is a run of A on some word ùë§ ‚àà Œ£ ùúî and there is an accepting run of B
on ùë§ .
This reformulation with a universal quantification over all ùúî-sequences of
states is now what allows us to view this as a universality problem. The first

condition is even easier to check when we do not regard a run as a
sequence ùëû , ùëû , . . .
0
1
of states but
- as we have sometimes done before - as an alternating sequence ùëû , ùëé , ùëû ,
ùëé , . . .
0
0
1
1
of states and alphabet letters. This could mean choosing ùëÑ ‚à™ Œ£ as the
alphabet for the NBA C, and clearly not every sequence over this alphabet
is a run in this form.
Instead, we choose Œî ‚à∂= ùõø as the new alphabet and regard such a run as a
sequence of transitions (ùëû , ùëé , ùëû
, ùëé
, ùëû
0
0
1), (ùëû1
1

2), . . .
We can then build three NBA C ,
,
1 C2 C3 that check the three conditions respec-
tively. The desired NBA C is then obtained from these three via a standard
union construction, cf. Lemma 5.9.
192
8 Decision Problems
Note that a sequence (ùëû , ùëé , ùëù
, ùëé
, ùëù
0
0
0), (ùëû1
1
1), . . . is not a run of A if ùëû0 ‚â† ùëû ùêº or
ùëùùëñ ‚â† ùëûùëñ+1 for some ùëñ ‚â• 0. It is easy to construct an NBA, in fact a DBA, that
keeps remembering the third component of the last triple it read and accepts
as soon as this does not agree with the first component of the next triple.
The details of the construction of C1 are left as an e xercise.
Next, it is even easier to check that such a sequence (ùëû , ùëé , ùëù
, ùëé

, ùëù
0
0
0), (ùëû1
1
1), . . .
is not accepting since we do not need to check anymore whether it is a run
or not.
We only need to check that eventually none of the ùëûùëñ and ùëùùëñ are accepting
states, i.e.
that eventually we only ever see transitions from ((ùëÑ ‚àñ ùêπ) √ó Œ£ √ó (ùëÑ ‚àñ ùêπ))
‚à© ùõø. This can easily be done with a two-state DcoBA or a two-state NBA.
Again the details of the construction of C2 are left as an exercise.
At last, C
, ùëé
, ùëù
, ùëé
, ùëù
3 needs to simulate, given such a sequence ùúå = (ùëû0
0
0), (ùëû1
1

1),
. . ., an accepting run of B on ùúå. Again, we do not need to be concerned with
the question of whether ùúå is indeed a run or not. All that is relevant for C3
to be correct according to its specification, is the projection of ùúå onto Œ£, i.e.
the sequence ùëé , ùëé , . . .
0
1
forming the underlying word.
This can easily be done by extending B's transition relation as follows:
whenever B can take an ùëé-transition from ùëû to ùëù, we allow it to take a
transition from ùëû to
‚Ä≤
‚Ä≤
ùëù with any letter (ùëû , ùëé, ùëù ) of the new alphabet Œî whose second component
is still ùëé. Accepting states are exactly those that are accepting in B. This
way, C3 accepts such a sequence iff B accepts the Œ£-word embedded in this
sequence. Again, writing down the technical details of this construction is
left as an exercise.
‚óª
Hence, the subsumption problem for two NBA A, B can be solved by
constructing the NBA C as explained above, and then checking this one for
universality.
We finish this section with the observation, already mentioned above, that
the universality problem is decidable using a reduction to the emptiness
problem.

Corollary 8.15 The universality problem for NBA of size ùëõ is solvable in
time O(ùëõ
2
log ùëõ) .
Proof Let A be an NBA with ùëõ states over alphabet Œ£. According to Cor.
7.26 it can O(ùëõ
be translated into a DPA of size 2
log ùëõ) and index O(ùëõ). A close inspection shows
that the size of the resulting automaton is the dominating factor in the time
complexity here. DPA can easily be complemented at no blowup according
to Thm. 6.11. The O(ùëõ
resulting DPA can be turned into an equivalent NBA A of size O(ùëõ) ‚ãÖ 2
log ùëõ) =
O(ùëõ
2
log ùëõ) according to Thm. 6.13, so we have ùêø(A) = ùêø(A) = Œ£ùúî ‚àñ ùêø(A).
Now we can apply the usual reasoning for converting emptiness into
universality and vice-versa: we have ùêø(A) = Œ£ ùúî iff ùêø(A) = ùêø(A) = ‚àÖ.
Since non-emptiness can be decided in polynomial time, so can emptiness,
and O(ùëõ
so the worst-case time needed for this universality check is indeed 2
log ùëõ).
‚óª

The reason for stating this here explicitly is mainly to put it in contrast with
what comes next. We devise a conceptually simpler universality check that
turns out not to be asymptotically optimal. However, it avoids much of the
intrinsic combinatorial difficulties that arise with the use of the Safra
construction for complementation.
8.2 Universality and Subsumption
193
8.2.2 Universality as a Search Problem in Monoids
We study the universality of the language accepted by an NBA using an
abstract search problem in finite monoids. Recall that a monoid is a
structure M = (ùëÄ, ‚óã, ùëí) where ùëÄ is the set of elements of the monoid, and
‚óã ‚à∂ ùëÄ √ó ùëÄ ‚Üí ùëÄ is a binary function on it that is associative. At last, ùëí ‚àà
ùëÄ is neutral for ‚óã, i.e. we have ùëí ‚óã ùëö = ùëí = ùëö ‚óã ùëí
for all ùëö ‚àà ùëÄ.
This method for determining universality is based in B √ºchi's
complementation proof, especially the characterisation of non-universality
of A over Œ£ as the existence ùúî
of two words ùë¢ ‚àà Œ£‚àó, ùë£ ‚àà Œ£+ so that ùë¢ùë£
/
‚àà ùêø(A) and therefore two equivalence
ùúî
classes [ùë¢], [ùë£] such that [ùë¢][ùë£]
/
‚äÜ ùêø(A). It is the fact that there are only finitely

many such equivalence classes which allows this to be used in a decision
procedure.
So non-universality can therefore be checked in principle by computing all
equivalence classes and checking for each pair [ùë¢], [ùë£] of them whether
ùë¢ùë£ /
‚àà ùêø(A).
The main contribution of this section is then to introduce a data format for
such equivalence classes and a method to compute them without
enumerating words etc.
For the remainder of this section we fix an NBA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) and show
how its universality can be decided. Recall that for ùë¢, ùë£ ‚àà Œ£‚àó we hav e ùë¢
ùë£
ùë¢
ùë£
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
ùë¢ ‚àº ùë£

iff
‚àÄùëû.‚àÄùëû .(ùëû √ê
‚Üí ùëû
‚áî ùëû √ê
‚Üí ùëû ) and (ùëû √î
‚áí ùëû
‚áî ùëû √î
‚áí ùëû )
ùë¢
‚Ä≤
‚Ä≤
where ùëû √ê
‚Üí ùëû
if ùëû is reachable from ùëû in A's transition graph along some path ùë¢
‚Ä≤
labelled with ùë¢, and ùëû √î
‚áí ùëû
likewise but the path is additionally required to visit
some accepting state. As usual, we write [ùë§] for the equivalence class of ùë§
under ‚àº.

Given a word ùë§ ‚àà Œ£‚àó, we associate with it two sets of pairs of s tates:
‚Ä¢
ùë§
‚Ä≤
‚Ä≤
the set ùëÖùë§ of all pairs (ùëû, ùëû ) such that ùëû √ê
‚Üí ùëû , and
ùë§
‚Ä¢
F
‚Ä≤
‚Ä≤
the set ùëÖ
)
ùë§
of all pairs (ùëû, ùëû
such that ùëû √î
‚áí ùëû .
F
Note that ùëÖ , ùëÖ

ùë§
‚äÜ ùëÑ √ó ùëÑ
ùë§
for all ùë§ ‚àà Œ£‚àó, i.e. they are binary relations on the NBA's
state space ùëÑ. Recall the definition of the composition of relations ùëÖ, ùëÜ ‚äÜ
ùëÑ √ó ùëÑ via
‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
ùëÖ ‚óã ùëÜ
‚à∂= {(ùëû, ùëû ) ‚à£ ‚àÉùëû
‚àà ùëÑ with (ùëû, ùëû ) ‚àà ùëÖ and (ùëû , ùëû ) ‚àà ùëÜ} .
It should be clear that for two words ùë¢, ùë£ ‚àà Œ£‚àó with ùë¢ ‚àº ùë£ we have ùëÖùë¢ =
ùëÖùë£ and F
F
ùëÖ
= ùëÖ
ùë¢

ùë£ . Hence, these sets of pairs of states do not depend on the exact form of a
word ùë§ but only its equivalence class [ùë§], and we therefore denote them as
ùëÖ[ùë§]
F
and ùëÖ
instead.
[ùë§ ]
‚àó
So, while the equivalence class [ùë§] of a word, when seen as the set {ùë£ ‚àà Œ£
‚à£
ùë£ ‚àº ùë§}, is an infinite set and therefore not very useful for algorithmic
purposes, the F
pair (ùëÖ , ùëÖ
ùë§
)
ùë§
is a finite object (as there are only finitely many state pairs) and can
therefore serve as a data structure for the representation of such
equivalence classes.
F
2
ùëõ

Remember that ùëÖ
‚äÜ ùëÖ
ùë§
ùë§
for any ùë§ ‚àà Œ£‚àó which is why there are at most 3
many
different equivalence classes [ùë§] for an NBA with ùëõ states.
194
8 Decision Problems
ùëé , ùëè
ùëé
ùëè
0
1
2
ùëè
Fig. 8.1 Example NBA for the construction of boxes and the test for non-
universality.
F
The next lemma essentially states that ùëÖùë§ and ùëÖùë§ can be computed by
induction on the length of ùë§. The proof is left as an exercise.

Lemma 8.16 Let ùë¢, ùë£ ‚àà Œ£‚àó , ùëé ‚àà Œ£ . The following statements are true.
F
a) ùëÖ
= {(ùëû, ùëû) ‚à£ ùëû ‚àà ùëÑ}
= {(ùëû, ùëû) ‚à£ ùëû ‚àà ùêπ }
[ ùúÄ]
and ùëÖ
.
[ ùúÄ]
‚Ä≤
‚Ä≤
F
‚Ä≤
‚Ä≤
‚Ä≤
b) ùëÖ
= {(ùëû, ùëû ) ‚à£ ùëû
‚àà ùõø(ùëé, ùëû)}
= {(ùëû, ùëû ) ‚à£ ùëû
‚àà ùõø(ùëé, ùëû)

} ‚à©
[ùëé]
and ùëÖ
and {ùëû, ùëû
[ùëé]
ùêπ ‚â† ‚àÖ} .
F
F
F
c) ùëÖ
= ùëÖ
‚óã ùëÖ
= ùëÖ
‚óã ùëÖ
‚à™ ùëÖ
‚óã ùëÖ
[ùë¢ùë£]
[ùë¢]
[ùë£] and ùëÖ
.

[ùë¢ùë£]
[ùë¢]
[ùë£]
[ùë¢]
[ùë£]
Using the induction principle from this lemma it is possible to finitely
enumerate all equivalence classes [ùë§] for ùë§ ‚àà Œ£‚àó as follows, where
computing [ùë§] simply fin
means constructing ùëÖ[ùë§] and ùëÖ
.
[ùë§]
a) Construct [ùúÄ] and [ùëé] for ùëé ‚àà Œ£ directly from A's transition table.
b) Starting with the set of all [ùëé] for ùëé ‚àà Œ£, compute [ùë¢ùë£] for any
equivalence classes [ùë¢], [ùë£] already computed until no more new classes
can be f ound.
Before we carry this out on an example NBA we introduce a graphical
notion F
for such pairs of relations (ùëÖ , ùëÖ
ùë§
)
ùë§
which is nothing more than the straightforward

2
ùëÑ
interpretation of an object of type 3
. These can be regarded as boxes with inputs
(on the left) and outputs (on the right), one for each state ùëû ‚àà ùëÑ. Internally,
such a box
‚Ä≤
‚Ä≤
connects the input state ùëû with the output state ùëû if (ùëû, ùëû ) ‚àà ùëÖùë§ . This
connection is
‚Ä≤
F
marked if, additionally, (ùëû, ùëû ) ‚àà ùëÖ ùë§ .
Example 8.17 Consider the NBA shown in Fig. 8.1. The basic boxes arising
from its transition table are the following three.
0
0
0
0
0
0

[ùúÄ]
=
1
1
[ùëé]
=
1
1
[ùëè]
=
1
1
2
2
2
2
2
2
Since the states represented by an input or output port are given by the
numerical order of the states in this case we will drop the annotations in the
computation of further boxes.

We can then compute the equivalence classes [ùë¢] for words of length 2
using the composition principle from Lemma 8.16 and the boxes for
equivalence classes of words of length 1. The composition of two relations
represented as boxes can easily be obtained by putting them side-by-side
and merging them into one. For instance, we have
8.2 Universality and Subsumption
195
[ùëéùëé]
= [ùëé] ‚óã [ùëé] =
‚óã
=
=
‚Ä≤
In general, the box [ùë¢ùë£] has a line from input port ùëû to output port ùëû if a
line can be traced from input port ùëû in [ùë¢] to some output port, and from
the corresponding input
‚Ä≤
port in box [ùë£] to its output port ùëû . The resulting line is marked if one of
the two segments was marked. So likewise we get the following boxes for
other equivalence classes of words.
[ùëè ùëè] =
=
[ùëé ùëè] =
=

[ùëèùëé] =
=
[ùëèùëéùëé] =
=
The last equation shows that [ùëèùëéùëé] = [ùëéùëé]. An exhaustive search reveals
five more boxes, namely the following ones.
[ùëè ùëèùëé]
[ùëé ùëèùëé]
[ùëèùëé ùëè]
[ùëè ùëèùëé ùëè]
[ùëé ùëèùëé ùëè]
Composing one of these with any other one yields a box that has been
discovered already, for instance
[ùëèùëé] ‚óã [ùëé ùëèùëé ùëè]
=
‚óã
=
= [ùëèùëèùëéùëè]
which can also be obtained algebraically as
[ùëèùëé] ‚óã [ùëé ùëèùëé ùëè] = [ùëèùëé] ‚óã ([ùëé ùëè] ‚óã [ùëé ùëè]) = ([ùëèùëé] ‚óã [ùëé ùëè]) ‚óã [ùëé ùëè] = [ùëè
ùëè] ‚óã [ùëé ùëè]

= [ùëè ùëèùëé ùëè]
once we have established by direct calculation that [ùëèùëé] ‚óã [ùëéùëè] = [ùëèùëè].
The next theorem then establishes the use of equivalence classes in a
decision procedure for universality. Recall that a monoid element ùëö is
called idempotent if ùëö ‚óã ùëö = ùëö .
Theorem 8.18 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an NBA. We have ùêø(A) = Œ£ ùúî iff for all
ùë¢ ‚àà Œ£‚àó and ùë£ ‚àà Œ£+ such that [ùë£] is idempotent and [ùë¢ùë£] = [ùë¢] , there is
some ùëû ‚àà ùëÑ
F
such that (ùëû , ùëû
ùêº
) ‚àà ùëÖ[ùë¢] and (ùëû, ùëû) ‚àà ùëÖ
.
[ùë£]
Proof "‚áí" Assume that ùêø(A) = Œ£ùúî. Take two arbitrary equivalence classes
[ùë¢], [ùë£]
ùúî
such that ùë£ ‚â† ùúÄ, [ùë£ùë£] = [ùë£] and [ùë¢ùë£] = [ùë¢]. Since ùë£ ‚â† ùúÄ we have ùë¢ùë£
‚àà Œ£ ùúî . Since
ùúî

ùêø (A) = Œ£ ùúî there must be an accepting run of A on ùë¢ùë£ . For ùëñ ‚â• 0 let ùëûùëñ be
the
196
8 Decision Problems
0
ùë¢ùë£
ùëñ
state in this run that A reaches after reading ùë¢ùë£ . Hence, we have ùëûùêº √ê√ê‚Üí
ùëû0 and ùë£
ùëûùëñ‚àí1 √ê
‚Üí ùëûùëñ for all ùëñ ‚â• 1. Since ‚à£ùëÑ‚à£ < ‚àû there must be some ùëû ‚àà ùëÑ suc h that ùëö
ùëò
ùëò
ùë¢ùë£
ùë£
0
ùë£
1
ùëû ùêº √ê√ê‚Üí ùëû √ê
√ê
‚Üí ùëû √ê

√ê
‚Üí . . .
ùëö
for some ùëö ‚â• 0 and ùëò
, ùëû
ùëó
‚â• 1 for all ùëó ‚àà N. So we have (ùëûùêº
) ‚àà [ùë¢ùë£
]. If ùëö = 0 then
we trivially also get (ùëû , ùëû
ùêº
) ‚àà ùëÖ[ùë¢]. If ùëö > 0 then we make use of the fact that [ùë£] is
ùëö
ùëö
idempotent, so we have [ùë¢ùë£ ] = [ùë¢] ‚óã [ùë£]
= [ùë¢] ‚óã [ùë£] = [ùë¢] by assumption.
ùëò
Likewise, we have (ùëû, ùëû) ‚àà [ùë£ ùëó ] for all ùëó ‚àà N and since [ùë£] is idempotent
we also have (ùëû, ùëû) ‚àà ùëÖ[ùë£]. At last, since the run is accepting, it contains
infinitely many F
accepting states, so we have (ùëû, ùëû) ‚àà ùëÖ

in fact.
[ùë£]
"‚áê" Now assume that ùêø(A) ‚â† Œ£ ùúî, i.e. there is some ùë§ = ùëé ùëé . . .
0
1
‚àà Œ£ ùúî such
that all runs of A on ùë§ contain finitely many accepting states only. As in the
proof N
of Lemma 5.31 this determines a colouring ùëì of ( ) via ùëì (ùëñ, ùëó ) = [ùëé . . . ùëé
ùëñ
ùëó
2
‚àí1] with
a finite number of colours, and Ramsey's Theorem yields an infinite
sequence of indices ùëñ0 < ùëñ1 < . . . and a colour - in this case an equivalence
class - that is the same for all pairs of indices in this sequence. In other
words, it yields a class [ùë£]
such that not only [ùë£] = [ùëé
. . . ùëé
. . . ùëé
ùëñ
ùëñ

ùëñ
ùëó
ùëó +1 ‚àí1 ] for all ùëó ‚â• 0, but even [ùë£ ] = [ùëéùëñ ùëó
‚Ä≤ ‚àí1 ]
ùëó
‚Ä≤
for all 0 ‚â§ ùëó < ùëó . Since
[ùë£] = [ùëé
. . . ùëé
. . . ùëé
. . . ùëé
ùëñ
ùëñ
ùëñ
ùëñ
1
3 ‚àí1 ] = [ùëéùëñ1
2 ‚àí1 ] ‚óã [ùëéùëñ2
3 ‚àí1 ] = [ùë£ ] ‚óã [ùë£ ]
we have that [ùë£] is indeed idempotent.

It is tempting to choose ùë¢ ‚à∂= ùëé . . . ùëé
0
ùëñ0‚àí1 but then we do not necessarily have
‚Ä≤
[ùë¢ùë£] = [ùë¢]. So instead let ùë¢ ‚à∂= ùëé . . . ùëé
. . . ùëé
0
ùëñ
ùëñ
0 ‚àí1
and ùë¢ ‚à∂= ùëé0
1 ‚àí1 . Then we have
‚Ä≤
‚Ä≤
‚Ä≤
[ùë¢] = [ùë¢ ùë£] and therefore [ùë¢ùë£] ‚óã [ùë£] = [ùë¢ ùë£ùë£] = [ùë¢ ùë£] = [ùë¢] by
idempotency of [ùë£].
ùë¢
At last, take any ùëû ‚àà ùëÑ such that (ùëû , ùëû
ùêº

) ‚àà ùëÖ[ùë¢], i.e. ùëûùêº √ê
‚Üí ùëû. Suppose that also
F
ùúî
(ùëû, ùëû) ‚àà ùëÖ
. Then we have ùë¢ùë£
‚àà ùêø(A) because it is easy to construct an accepting
[ùë£]
ùúî
run of A on ùë¢ùë£
by concatenating a finite path from ùëûùêº to ùëû on ùë¢ with a looping path from ùëû
back to ùëû on ùë£ that visits an accepting state in between. However, since ùëé
. . . ùëé
. . . ùëé
0
ùëñ
ùëñ
1 ‚àí1 ‚àº ùë¢ and ùëéùëñ ùëó
ùëó +1 ‚àí1 ‚àº ùë£ for all ùëó ‚â• 1 we also have
ùëé

... ùëé
ùëé
... ùëé
ùëé
... ùëé
0
ùëñ
‚àí
ùëñ
ùëñ
‚àí1
ùëñ
ùëñ
‚àí1
1
1
1
2+1
2
3+1

ùëû ùêº √ê
√ê√ê√ê√ê
‚Üí ùëû √î√î√î√î√î‚áí ùëû √î√î√î√î√î‚áí . . .
which contradicts the assumption that ùë§ /
‚àà ùêø(A).
‚óª
Thm. 8.18 yields the basis for a simple algorithm that checks for
universality of a given NFA A: starting with the classes [ùëé] for every ùëé ‚àà Œ£,
represented as boxes, form classes [ùë¢] for ùë¢ ‚àà Œ£‚àó with ‚à£ùë¢‚à£ > 2 by
composing existing boxes. For every new box [ùë£] resulting in this way,
check whether it is idempotent and whether there is a class [ùë¢] such that
[ùë¢ùë£] = [ùë¢]. Once such a pair is found, we know that ùêø(A) ‚â† Œ£ ùúî.
Otherwise the search will terminate eventually when no more new boxes
arise, and we know that ùêø(A) = Œ£ ùúî.
8.2 Universality and Subsumption
197
Example 8.19 Reconsider the NBA from Fig. 8.1. Its language is not
universal. Its idempotent boxes are [ùëéùëé], [ùëèùëè], [ùëèùëé], [ùëèùëèùëé], [ùëèùëèùëéùëè] and
[ùëéùëèùëéùëè].
Now take, for instance, ùë£ ‚à∂= ùëéùëé and ùë¢ ‚à∂= ùëèùëéùëé. Then we have [ùë¢] = [ùë£]
according to the development in Ex. 8.17, and therefore [ùë¢ùë£] = [ùë¢]. At last,
there is only one F
state ùëû ‚àà {0, 1, 2} s.t. (0, ùëû) ‚àà ùëÖ[ùë¢], namely 0 itself. But then we have (0,
0) /
‚àà ùëÖ

,
[ùë£]
witnessing this NBA' s non-universality.
We remark that, in order to decide inclusion between the languages of two
NBA, there is a more direct way than laid out in the reduction from
subsumption to universality. It is possible to extend the algorithm for
universality to one for subsumption as follows.
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, Œ£, ùëû , ùõø , ùêπ
ùêº
) and B = (ùëÑ
) be given. A box is no longer an
OceanofPDF.com

ùêº
2
‚Ä≤ 2
‚Ä≤ 2
ùëÑ
ùëÑ
ùëÑ
object of type 3
, resp. 3
, but it is now an object of type ùëÑ2 √ó {0, 1} √ó 3
. This
can be seen as a box like the ones above that is additionally equipped with
an in-type and an out-type and a flag. Composition is only possible when
the out-type of the left box matches the in-type of the right box. The
operation on the flag in composition is just the maximum. Thus, we have,
for instance the following equalities where the additional flag is shown by a
dot on the top side of the box's rectangle.
1
0
0
2
1

2
1
0
0
2
1
2
‚óã
=
,
‚óã
=
On the other hand, we also have
0
1
0
2
‚óã
= ‚òá
because the out-type 1 of the left box does not match the in-type 0 of the
right box.

Remember that in the non-universality checks, a box represents an
equivalence class [ùë¢] for some word ùë¢ ‚àà Œ£‚àó which, again, can be seen as
the collected information of all the consecutive transitions that the
underlying NBA can do when reading ùë¢, especially with regards to the
visiting of accepting states. Now such an extended box does this for the
automaton B, and additionally carries information about the possibility to
go from the in-type state in A to the out-type state when reading ùë¢, on a
path that visits an accepting state there or not. This is what the additional
flag is for. It is then possible to characterise non-inclusion between the
languages of two NBA via the existence of a witnessing pair of extended
boxes as follow s.
Theorem 8.20 Let A, B be NBA over the same alphabet Œ£ . We have ùêø(A) /
‚äÜ ùêø(B) iff there is a pair of extended boxes [ùë¢], [ùë£] such that [ùë£] is
idempotent, [ùë¢] ‚óã [ùë£] = [ùë¢] ,
‚Ä≤
‚Ä≤
ùë£ ‚â† ùúÄ , the extra flag on [ùë£] is set, and all edges in [ùë£] of the form (ùëû , ùëû )
for some
‚Ä≤
‚Ä≤
‚Ä≤
of B 's states ùëû with (ùëû , ùëû ) ‚àà [ùë¢]
ùêº
are unmar ked.
Idempotency of [ùë£] implies that its in-type equals its out-type. Proof details
for this theorem are left as an exercise. Note that, if the condition stated in
this theorem

198
8 Decision Problems
ùúî
ùúî
is met, then there is an accepting run of A on ùë¢ùë£
but every run of B on ùë¢ùë£
does not traverse accepting states infinitely often. Not surprisingly, this
shows that non-subsumption between two NBA is also witnessed by an
ultimately periodic word.
8.3 An Application: Size-Change Termination
We consider an application of NBA subsumption (and therefore also
universality) from the area of termination analysis for recursive programs.
We assume the reader to be familiar with recursion in a standard
programming language, and the issue of termination that routinely arises
with it. The question under consideration is: does a given recursive
program terminate for all inputs? It should be clear that this is undecidable
in general but potentially decidable for restricted forms of recursion.
We do not develop a model of a programming language with data types and
a proper semantics but appeal to the intuitive understanding of termination
for recursive programs over natural numbers. This is to be seen as an
abstraction. Take for instance any well-known recursive sorting algorithm
like Mergesort. It operates on lists or arrays of ordered data, but in order to
argue that it terminates it typically suffices to regard the length of its
arguments only. This abstracts the problem into one for recursive programs
over natural numbers.
8.3.1 Recursive Programs
We define recursive programs abstractly as collections of functions.

Definition 8.21 Let ùêπ = { ùëì , ùëì , . . . , ùëì
1
2
ùëõ } be a finite set of function symbols, each of
which has an arity ar( ùëìùëñ).
A recursive program is a system of equations of the form
ùëì
, . . . , ùë•
1(ùë•1
ùëò
)
=
ùëì
(t
)
1
1,1(t1,1), . . . , ùëì1,ùëö1
1,ùëö1
‚ãÆ
ùëì

, . . . , ùë•
ùëõ (ùë•1
ùëò
)
=
ùëìùëõ,
(t
)
ùëõ
1(tùëõ,1), . . . , ùëìùëõ,ùëöùëõ
1,ùëöùëõ
where ùëì
, . . . , ùëì
1,1
ùëõ, ùëö
are function symbols from ùêπ, the ùë•ùëñ are parameter variables
ùëõ
so that ar( ùëìùëñ) = ùëòùëñ for all ùëñ = 1, . . . , ùëõ. Each tùëñ, ùëó is a vector of terms of the
form ùë•ùëñ,‚Ñé
or ùë•ùëñ,‚Ñé ‚àí 1 for some ‚Ñé ‚àà {1, . . . , ùëòùëñ}, so that ‚à£tùëñ, ùëó ‚à£ = ar( ùëìùëñ, ùëó ) for 1 ‚â§ ùëñ ‚â§
ùëõ, 1 ‚â§ ùëó ‚â§ ùëöùëñ.

Such programs abstract away from concrete recursive programs in the
following sense: the list of function applications to terms on the right-hand
side of the equation for ùëìùëñ contains all the recursive calls that have to be
made when executing ùëìùëñ on parameter values (ùë•
, . . . , ùë•
ùëñ ,1
ùëñ , ùëò ). The order of these recursive calls is irrelevant; a
ùëñ
function call terminates when all its recursive subcalls terminate.
8.3 An Application: Size-Change Termination
199
Each argument to a recursive call is either one of the parameter values of
the parent call, or it is such a value decreased by 1. Again, the exact
(positive) amount by which a value gets decreased is irrelevant when
considering the question of termination for all input values.
Example 8.22 Consider the following program for computing
multiplication recursively, written in (functional) pseudocode.
mult(ùë•, 0, ùëß) = ùëß
add(ùë•, 0) = ùë•
mult(ùë•, ùë¶, ùëß) = mult(ùë•, ùë¶ ‚àí 1, add(ùë•, ùëß))
add(ùë•, ùë¶) = add(ùë• + 1, ùë¶ ‚àí 1)
Here we generalised the problem slightly into a ternary operation mult(ùë•,
ùë¶, ùëß) that is supposed to compute ùë• ‚ãÖ ùë¶ + ùëß. This enables a tail-recursive
description of the algorithm.

This program can now be abstracted into the following, bearing in mind
that we are only interested in its termination. We simply consider recursive
calls on an argument that is zero to be terminating immediately. This allows
us to discard the first two clauses of the two functions, and we are left with
the following.
mult(ùë•, ùë¶, ùë¢) = add(ùë•, ùë¢), mult(ùë•, ùë¶ ‚àí 1, ùë¢)
add(ùë•, ùë¶) = add(ùë•, ùë¶ ‚àí 1)
Unlike above, the right-hand side of the equation does not contain a term
describing how to compute the return value, but it simply contains a list of
recursive calls.
So the symbol '=' does not denote equality of values but equality with
respect to termination, and the commas are conjunctions.
The call parameters are slightly changed in comparison to the original
function definition above. In function mult we replaced ùëß with ùë¢, simply
because the third parameter in the recursive call to mult may obtain an
arbitrarily high value. It should be clear that the introduction of the
parameter ùë¢ models this because we are interested in termination for all
parameter values, including those for ùë¢ that are that arbitrarily high.
Something similar is done with the first argument for add. Here we replaced
ùë• + 1 by ùë•. Again, since only the decreasing of values is what we consider
to lead to termination, the resulting program is termination-equivalent to
the original one.
Example 8.23 As a second example consider the Ackermann function,
known from recursion or computability theory. It can be modelled using a
ternary function symbol as follows.
ack(ùë•, ùë¶, ùë¢) = ack(ùë• ‚àí 1, ùë¢, ùë¢), ack(ùë•, ùë¶ ‚àí 1, ùë¢ )
The Ackermann function obtains its enormous growth rate from the clever
nesting of a recursive call in the argument position of a second recursive
call. This is not anything that can be modelled in the formalism introduced

here where recursive calls appear to be "flat". Again, for pure termination
considerations this suffices because non-termination is then given by some
non-terminating recursion path, and there is
200
8 Decision Problems
no relevance to how the non-existing return-values would be used in further
paths in the recursion tree.
Let ùëÉ be a recursive program over ùêπ = { ùëì , . . . , ùëì
1
ùëõ } with defining equations as in
Def. 8.21. It defines a set of ùëõ partial functions ùëìùëñ ‚à∂ N ar( ùëìùëñ) ‚Üí ùê∑ for some
arbitrary non-empty co-domain ùê∑. Note that recursive functions in the form
defined here do not specify return values. Hence, we can simply regard
them as partial functions of type ùëìùëñ ‚à∂ N ar( ùëìùëñ) ‚Üí {‚ä∫} or total functions of
type ùëìùëñ ‚à∂ N ar( ùëìùëñ) ‚Üí {‚ä∫, }. We do not distinguish notationally between a
function symbol ùëìùëñ ‚àà ùêπ and its associated function.
By definition, we say that ùëì
, . . . , ùë•
ùëñ (ùë•1
)
= ‚ä∫
ar( ùëì
if ùë•ùëñ = 0 for some ùëñ ‚àà

ùëñ )
{1, . . . , ar( ùëìùëñ )}. I.e. recursive calls are assumed to terminate when some
parameter has become zero.
For other parameter values the functions' return values are given by their
defining equations. We have
ùëì
.
ùëñ (x) = ‚ä∫
iff
ùëìùëñ, ùëó (tùëñ, ùëó ) = ‚ä∫ for all ùëó = 1, . . . , ùëöùëñ
This means that a call to function ùëìùëñ with parameter values x all different
from 0 does not terminate if some recursive call to one of the functions ùëìùëñ, ùëó
with corresponding parameter values tùëñ, ùëó does not terminate.
8.3.2 Termination Analysis as B ¬®
uchi Inclusion
Let ùëÉ be a recursive program of the form
ùëì
, . . . , ùë•
1(ùë•1
ùëò
)
=

ùëì
(t
)
1
1,1(t1,1), . . . , ùëì1,ùëö1
1,ùëö1
‚ãÆ
ùëì
, . . . , ùë•
ùëõ (ùë•1
ùëò
)
=
ùëìùëõ,
(t
)
ùëõ
1(tùëõ,1), . . . , ùëìùëõ,ùëöùëõ
1,ùëöùëõ
for function symbols from ùêπ = { ùëì , . . . , ùëì

1
ùëõ }. Let ùëö ‚à∂= max{ùëöùëñ ‚à£ 1 ‚â§ ùëñ ‚â§ ùëõ} be the
maximal number of recursive function calls in right-hand sides in ùëÉ.
We consider the alphabet Œ£ ‚à∂= ùêπ √ó {1, . . . , ùëö} and define the language of
ùúî-words ùêøcall ‚äÜ Œ£ ùúî to be the set of all possible call sequences. I.e. we have
ùëÉ
( ùëì , ùëë
, ùëë
, ùëë
0
0)( ùëì1
1)( ùëì2
2) . . . ‚àà ùêøcall iff ùëìùëñ+1 = ùëìùëñ,ùëë for all ùëñ ‚â• 0. For simplicity we omit ùëñ
parentheses and commas and simply write such a call sequence as ùëì ùëë ùëì ùëë .
. .
0
0 1
1
. The
following is v ery easy to see.
Lemma 8.24

ùëÉ
Let ùëÉ be a recursive program over ùêπ . Then ùêøcall can be recognised by a
DcoBA with ‚à£ùêπ‚à£ + 1 states.
ùëÉ
Clearly, ùêøcall is then also ùúî-regular for any ùëÉ.
Example 8.25 Let ùëÉ1 be the following recursive program over ternary
functions f, g, h, i, k, defined as follows.
8.3 An Application: Size-Change Termination
201
f(ùë•, ùë¶, ùëß) = g(ùë•, ùë•, ùë¶)
i(ùë•, ùë¶, ùëß) = k(ùë•, ùë¶ ‚àí 1, ùëß ‚àí 1)
g(ùë•, ùë¶, ùëß) = h(ùë•, ùë¶ ‚àí 1, ùëß ‚àí 1)
k(ùë•, ùë¶, ùëß) = f(ùë•, ùë¶ ‚àí 1, ùëß ‚àí 1)
h(ùë•, ùë¶, ùëß) = i(ùë•, ùë¶ ‚àí 1 , ùëß ‚àí 1)
ùëÉ
Then ùêø 1
call contains a few words only, namely the following five.
ùúî
ùë§ f
‚à∂= (f1g1h1i1k1)
ùë§ i

‚à∂= i1ùë§k
ùë§ g
‚à∂= g1ùë§h
ùë§ k
‚à∂= k1ùë§f
ùë§ h
‚à∂= h1ùë§i
There is no designated starting symbol in a recursive program, comparable
to a
"main" function. It is simply not necessary to single out one of these
symbols; we consider the program non-terminating when any of its
functions is non-terminating.
This is of course also the reason for the extra state needed in Lemma 8.24.
If, say, f was the designated entry point into the program in Ex. 8.25, and
we would only consider its termination, then a DcoBA with five states
would suffice to recognise ùëÉ
ùêø
1
call, and this language would contain a single word only. On the other
hand, this example shows nicely that termination of a particular function is
in general not different to termination of all functions.
Example 8.26 Let ùëÉ2 be the recursive program
t(ùë•, ùë¶, ùëß, ùë§) = t(ùë•, ùë•, ùëß, ùë§ ‚àí 1), t(ùë• ‚àí 1, ùëß, ùë§ ‚àí 1, ùë¶ ‚àí 1), t(ùëß, ùë• ‚àí 1, ùë¶, ùë§
‚àí 1) ùëÉ

ùúî
for the single function t of arity four. Then ùêø 2
call = (t1 + t2 + t3)
.
A call sequence is terminating if there is a parameter that gets decremented
over and over again in this sequence. In such a case, no matter what the
value of that parameter at the start was, it will eventually be reduced down
to zero, causing termination of this sequence. For termination of the entire
program to hold we need to demand termination of every call sequence in
this respect. Note that different parameters can be responsible for
termination of different call sequences. In order to address this formally we
define a second language associated with a recursive ùëÉ
program ùëÉ, namely the language ùêøterm of all call sequences that are
terminating in this sense.
Example 8.27 Take the recursive program ùëÉ modelling multiplication in Ex.
8.22.
ùúî
ùëÉ
We have (mult2)
‚àà ùêøterm since variable ùë¶ gets decremented over and over
again in recursive calls through function mult. Other call sequences of the
form
‚àó
ùúî
(mult2) mult1(add1)

are also terminating because of variable ùë¶ as well. This is a
different variable ùë¶, though. When control flow passes from mult to add, the
value of mult's parameter ùë¢ gets written into add's parameter ùë¶. Still, the
same reasoning applies here: regardless of what value this variable ùë¶ had,
either initially or finitely many steps later when the call sequence moves
into function add, it will eventually reach value zero.
202
8 Decision Problems
ùúî
ùëÉ
ùúî
Take the program ùëÉ
2
2 from Ex. 8.26. Here we have (t1)
‚àà ùêøterm, even (t1+t3)
‚äÜ
ùëÉ
ùúî
ùëÉ
ùêø
2
2

term. On the other hand, we have (t2t3t1t3t1t3)
/
‚àà ùêøt erm.
Termination, resp. non-termination is not always that easy to see, though.
Example 8.28 We write ùëì (x) ‚Üù ùëî(y) to indicate that a call to ùëì with
parameters x entails a call to function ùëî on parameters y. Reconsider the
recursive program ùëÉ1
from Ex. 8.25 now. We have
f(10, 10, 10) ‚Üù g(10, 10, 10) ‚Üù h(10, 9, 9) ‚Üù i(10, 8, 8) ‚Üù k(10, 7, 7) ‚Üù
f(10, 6, 6)
‚Üù g(10, 10, 6)
‚Üù h(10, 9, 5) ‚Üù i(10, 8, 4) ‚Üù k(10, 7, 3) ‚Üù
f(10, 6, 2)
‚Üù g(10, 10, 6)
‚Üù . . .
so f(10, 10, 10) is not defined, and neither is a call to f on larger parameter
values. On the other hand, it is possible to find smaller instances on which
the call terminates.
Analysing the termination behaviour of the recursive program ùëÉ2 from Ex.
8.26
reveals some combinatorial intricacies. We have
t(3, 10, 11, 4) ‚Üù t(2, 11, 3, 9) ‚Üù t(3, 1, 11, 8) ‚Üù t(3, 3, 11, 7) ‚Üù

t(11, 2, 3, 6) ‚Üù t(11, 11, 3, 5) ‚Üù t(3, 10, 11, 4) ‚Üù . . .
which shows that t(3, 10, 11, 4) is not defined. However, t(10, 10, 10, 10) is
defined.
The way that termination of recursive programs reduces to inclusion
checking between regular languages should slowly become visible:
program ùëÉ terminates ùëÉ
ùëÉ
iff ùêøcall ‚äÜ ùêøterm, i.e. all valid call sequences are terminating in the respect
above.
ùëÉ
It remains to be seen that ùêøterm is also ùúî-regular. The following lemma does
not ùëÉ
provide an NBA for ùêøterm but for an overapproximation of that language.
The reason is not that it is not ùúî-regular, but only that it is much simpler and
also sufficient to let the NBA also potentially accept non-valid call seq
uences.
Lemma 8.29 Let ùëÉ be a recursive program over ùêπ with ùëö ‚à∂= max{ ar( ùëì ) ‚à£
ùëì ‚àà ùêπ} .
ùëÉ
ùëÉ
ùëÉ
ùëÉ
There is an NBA Aterm with at most 2ùëö + 1 states such that ùêø(Aterm) ‚à©
ùêøcall = ùêøt erm .

Proof For simplicity we assume that ar( ùëì ) = ùëö for all ùëì ‚àà ùêπ, not just ar( ùëì
) ‚â§ ùëö.
This can be achieved for example by introducing dummy variables that
simply get passed through to recursive calls without decrements. So let ùêπ =
{ ùëì , . . . , ùëì
1
ùëõ } and
1
ùëö
ùëò
ùëò
ùëì
, . . . , ùë•
, . . . , ùë°
, . . . , ùë°
ùëñ (ùë•ùëñ ,1
ùëñ , ùëö ) = ùëîùëñ ,1(ùë°
), . . . , ùëî
)
ùëñ ,1
ùëñ ,1

ùëñ , ùëò (ùë°ùëñ ,1
ùëñ , ùëö
ùëë
be the definition for function symbol ùëìùëñ in ùëÉ for every ùëñ = 1, . . . , ùëõ where
each ùë°
is
ùëñ , ùëò
ùëë
ùëë
ùëë
either ùë¶
or ùë¶
‚àí 1 for some variable ùë¶
.
ùëñ , ùëò
ùëñ , ùëò
ùëñ , ùëò
ùëÉ
We construct an NBA A
‚à∂= (ùëÑ ‚à™ {ùëû

, ùõø, ùêπ
ùêº }, Œ£, ùëû ùêº
)
term
as follows. Its states, except
one, are pairs consisting of a parameter index and a flag: ùëÑ ‚à∂= ({1, . . . ,
ùëö} √ó {0, 1}) ‚à™
ùëÉ
{ùëû ùêº }. Intuitively, Aterm guesses a parameter (represented by an index
between 1 and ùëö) and then follows the evolution of values initially stored
in this parameter through a call sequence. Whenever it observes a
decrement operation, it signals this with its flag. Thus,
8.3 An Application: Size-Change Termination
203
ùëë
ùëë
ùõø(( ùëó , ùëè), ( ùëì , ùëë
ùëñ
))
‚à∂= {(‚Ñé, 0) ‚à£ ùë°
= ùë•
= ùë•

ùëñ , ‚Ñé
ùëñ , ùëó } ‚à™ {( ‚Ñé, 1) ‚à£ ùë°ùëñ,‚Ñé
ùëñ , ùëó ‚àí 1}
for any state ( ùëó , ùëè) and any alphabet symbol ( ùëì , ùëë
ùëñ
). Accepting states are traversed
whenever a decrement of the parameter that is followed has been
encountered: ùêπ ‚à∂= {1, . . . , ùëö} √ó {1}.
By a standard construction, ùëûùêº is given transitions to mimic the behaviour
of all other states, thus obtaining an NBA with a unique initial state that
uses its nondeterminism to guess, initially, the parameter that gets
decreased infinitely often.
Note that this is not the only form of nondeterminism used in ùõø. Each
parameter can ùëÉ
potentially be used multiple times in any recursive call, and Aterm can
guess which occurrence to follow.
ùëÉ
ùëÉ
It should be clear that Aterm accepts a valid call sequence from ùêøcall iff it
is possible to trace some parameter value through this call sequence whilst
seeing infinitely many decrement operations on this parameter, i.e. iff the
call sequence is terminating. Likewise, the statement on its size is easily
seen to be true as well.
‚óª

Example 8.30 Reconsider the recursive program ùëÉ from Ex. 8.22 modelling
multiplication. The corresponding NBA according to Lemma 8.29 has the
following transitions.
ùõø((1, ), (add, 1)) = {(1, 0)}
ùõø((2, ), (add, 1)) = {(2, 1)}
ùõø((1, ), (mult, 1)) = {(1, 0)}
ùõø((2, ), (mult, 1)) = ‚àÖ
ùõø((3, ), (mult, 1)) = {(2, 0)}
ùõø((1, ), (mult, 2)) = {(1, 0)}
ùõø((2, ), (mult, 2)) = {(2, 1)}
ùõø((3, ), (mult, 2) ) = {(3, 1)}
An immediate consequence of Lemma 8.24 and 8.29 is the decidability of
the size-change termination problem, i.e. the problem of deciding
termination for recursive programs of the simple form considered here.
Theorem 8.31 The size-change-termination problem is decidable in
exponential time.
Proof
ùëÉ
ùëÉ
Let ùëÉ be a recursive program ùëÉ, and A
,
call Aterm be the DcoBA, resp. NBA for

ùëÉ
ùëÉ
it according to Lemma 8.24 and 8.29. Then ùëÉ is terminating iff ùêø(Acall) ‚äÜ
ùêø(Aterm).
ùëÉ
ùëÉ
Note that this holds even though ùêø(Aterm) ‚äá ùêøterm in general.
Both automata are of size linear in ‚à£ùëÉ‚à£, and a DcoBA can easily be
transformed into an NBA under a linear blowup only. Hence, size-change
termination can be decided by a linear reduction to the subsumption
problem for NBA, which is decidable in exponential time: Thm. 8.14
reduces it polynomially to universality and Cor. 8.15
states that it is decidable in exponential time.
‚óª
The nature of the size-change termination problem allows a short-cut to be
taken.
For two ùúî-languages ùêø , ùêø
1
2 ‚äÜ Œ£ ùúî we do not only have ùêø1 ‚äÜ ùêø2 iff ùêø1 ‚à© ùêø2 = ‚àÖ
but also, by simple reasoning using deMorgan rules, ùêø1 ‚äÜ ùêø2 iff ùêø1 ‚à™ ùêø2
= Œ£ùúî.
ùëÉ

Now, in this particular case, ùêøcall is DcoBA-recognisable according to
Lemma 8.24.
Hence, its complement is DBA-recognisable according to Thm. 6.32 and
therefore
204
8 Decision Problems
clearly also NBA-recognisable. NBA-recognisable languages are closed
under unions according to Lemma 5.9. Thus, it is easy to obtain an NBA
directly for the language ùëÉ
ùëÉ
ùêø (Acall) ‚à™ ùêø(Aterm), and this can be checked for universality directly
instead of ùëÉ
ùëÉ
checking subsumption between ùêø(Acall) and ùêø(Aterm).
We finish with a remark on the applicability of finite automata on ùúî-words
for problems like size-change termination. Not only can simple program
termination questions be reduced to NBA subsumption, resp. universality.
Termination checking also arises in automatic theorem proving where
proofs are only valid when they are well-founded, i.e. they derive statements
from previously proved statements. Thus, a proof construction process
needs to be terminating in a very similar sense to the notion of program
termination studied here.
Bibliographic Notes
Decidability of emptiness for B √ºchi automata is a direct consequence of B
√ºchi's Theorem characterising ùúî-regular languages as finite unions of
concatenations between a regular language and the infinite iteration of a
regular language. It is easy to observe that emptiness of an NBA is

answered by two nested graph reachability analyses. Thus, decidability of
the NBA emptiness problem was answered in B √ºchi's seminal work within
the context of establishing decidability of S1S, the monadic theory of the
natural numbers with a successor relation [B √ºc62].
Basic algorithms on directed graphs starting from depth-first and breadth-
first search and also including algorithms to compute SCC decompositions
are routinely covered in courses and textbooks on algorithms and data
structures, cf. [CLRS22, SW11, AHU83]. Tarjan's algorithm [Tar72] is just
one example of a linear-time algorithm to compute an SCC decomposition.
Another one is Kosaraju-Sharir's algorithm [Sha81], using similar
observations about the use of the transposed graph for this purpose.
The textbook by Esparza and Blondin [EB23] sheds a light onto automata
theory from a particular algorithmic perspective and therefore considers
problems like non-emptiness for B √ºchi automata in a more in-depth way
than it is done here.
Universality and subsumption are of course the more interesting problems
from a computational perspective, and this is also reflected in the literature
containing work on these problems. The presentation in this chapter does
not follow the historical development. Decidability of these two problems
was of course established in theory by B √ºchi's proof of complementation
closure of ùúî-regular languages [B √ºc62], but it was not necessarily seen as
a practically viable procedure. Subsequent work on the determinisation
problem did not change this until Safra presented a determinisation 2
ùëú(ùëõ )
(and consequently complementation) procedure that runs in time 2
[Saf88]. Still,
it turned out not to be very practical and the search for other algorithms
continued.
Unlike it is presented here, size-change termination was not developed as
an application of NBA subsumption. The problem was considered

interesting in program analysis, and easily seen to be solvable by a
reduction to NBA subsumption, resp.
Exercises for Chapter 8
205
universality. However, at the time algorithms for the latter were only
considered to be of theoretical interest and not of practical viability. Jones
et al. then developed the method that is presented here for NBA universality
as an approach for program termination that avoids the use of B √ºchi
automata and explicit complementation thereof [LJBA01]. The method -
also often called Ramsey-based because of the use of Ramsey's Theorem in
the correctness proof - has only then become popular as a practical
approach for problems in the area of automata theory and logic that avoids
explicit complementation. Dax et al. [DHL06] were the first to use it in a
decision procedure for a temporal logic, namely the so-called linear-time ùúá-
calculus
[BB89, Var88]. It exceeds the expressiveness of the popular temporal logic
LTL (see Chp. 10) and is in fact expressively equivalent to B √ºchi automata.
Ramsey-based universality checking was then finally accepted as a
practically viable algorithmic approach to decision problems on B √ºchi
automata [FV10], its origin in the size-change termination problem was
duly noted [FV12], and its use
+
+
in universality and subsumption checking [ACC 10, ACC 11] as well as
explicit complementation [BLO12] was studied intensively. The Ramsey-
based method has also been extended to parity automata [FL12a] and even
to automata models beyond the expressiveness of ùúî-regular languages
[FKL15].

The success that Ramsey-based methods have had in universality and
subsumption checking may have put explicit complementation constructions
out of competition for good which are generally being avoided by modern
approaches [DGPR21, DGW24].
Another general method that has proven to be very useful in checking
language inclusion and related problems and which is not covered here, is
the so-called anti-chain method. It can be seen as an on-the-fly symbolic
powerset construction, and it is best understood as a method for NFA
universality testing [WDHR06, DR10]. Nevertheless, it has successfully
been extended to yield practically efficient algorithms for problems in
program verification that essentially boil down to B √ºchi automata
subsumption checking [WDMR08, DR09].
Exercises
Exercise 81 Let G = (ùëâ, ùê∏) be a directed graph.
‚Ä≤
‚Ä≤
‚Ä≤
a) Let ùê∂, ùê∂ be two maximal SCCs in G. Show that ùê∂ = ùê∂ or ùê∂ ‚à© ùê∂ = ‚àÖ.
b) Conclude from part (a) that the SCC decomposition of G is unique.
Exercise 82 Show how to compute the transitive closure of a directed graph
in time O(ùëõ3).
Exercise 83 Give an algorithm for deciding non-emptiness for NMA by
internalising the translation from an NMA into an NBA (cf. Thm. 6.24)
followed by a nonemptiness check for NBA.
Exercise 84 Explain how to solve the non-emptiness problem for
nondeterministic co-B √ºchi automata.
206

8 Decision Problems
ùëè
ùëé
ùëè
ùëé , ùëè
ùëé
ùëè
ùëè
ùëè
A
ùëé
A
ùëé , ùëè
1
0
1
ùëé
2
2
0

1
ùëè
2
ùëé , ùëè
ùëè
ùëé , ùëè
ùëé
ùëé
ùëé , ùëè
ùëè
A
ùëé , ùëè
A
ùëé , ùëè
3
0
1
ùëé
2
4

0
1
ùëè
2
Fig. 8.2 Four NBA to test for non-universality in Exc. 91.
Exercise 85 Complete the missing details in the proof of Thm. 8.14, i.e. give
the technical details of the construction of the NBA C ,
,
1 C2 C3.
Exercise 86 Explain what modifications are needed in the reduction from
the subsumption problem to the universality problem for NBA (proof of
Thm. 8.14) in order to obtain reductions from subsumption to universality
for NcoBA, NPA, NRA, NSA and NMA.
Exercise 87 Show that the universality problem for deterministic Streett
automata with ùëí many transitions and index ùëò can be solved in time O(ùëíùëò
). Hint: Use Thm. 8.6.
Exercise 1 Determine emptiness of the language of the following Streett
automaton with acceptance condition
F
= {({1}, {4, 5}), ({7, 8}, {2, 3}), ({4}, {6}) }
using the algorithm underlying Thm. 8.12.
0
2

4
6
8
1
3
5
7
9
Transition labels have been left out since they are not relevant for language
emptiness.
Exercise 88 Prove Lemma 8.16.
Exercise 89 Write down the entire multiplication table for the monoid of the
equivalence classes [ùë§] for the NBA shown in Fig. 8.1 that are listed in Ex.
8.17.
Exercise 90 Consider all idempotent boxes [ùë£] other than [ùëéùëé] in Ex. 8.19,
and determine for each of them whether there is a box [ùë¢] such that the
pair satisfies the conditions laid out in Thm. 8.18.
Exercises for Chapter 8
207
Exercise 91
ùúî
Use Thm. 8.18 to decide whether ùêø(Aùëñ) = {ùëé, ùëè}

for each of the NBA
Aùëñ , ùëñ = 1, . . . , 4, shown in Fig. 8.2. In each case, construct the finite set of
boxes arising as the composition closure of {[ùëé], [ùëè]} for this NBA, select
the idempotent ones and determine whether they can be used as a witness
for non-universality according to the characterisation in Thm. 8.18.
Exercise 92 Prove Thm. 8.20.
Exercise 93 Give a characterisation of universality for nondeterministic
parity automata as a search problem in a finite monoid along the lines of
Thm. 8.18. Hint: Extend the notion of a box as follows. A line from an in-
port to an out-port is not just unmarked or marked, but it carries a priority.
A line from ùëù to ùëû with label ùëö in the box [ùë§] is supposed to say that the
best priority that can be achieved (in terms of an accepting run) when
reading ùë§ in state ùëù and ending in state ùëû, is ùëö.
The composition of two such boxes needs to be explained in detail. In
particular,
‚Ä≤‚Ä≤
when composing two boxes there can be multiple paths from ùëû to ùëû
via different
‚Ä≤
intermediate states ùëû . Composition needs two different orders on
priorities: one is used to determine what the significant priority is when
composing two paths, the other is used to determine what the best
composed path is when there are several ones. In the case of NBA, both
operations degenerate to simple disjunctions: a path visits an accepting
state if one of its parts does, and amongst several paths from one state to
another the best is the one that visits an accepting state.
Exercise 94 Consider the recursive program of Ex. 8.25 and determine the
largest values for ùë•, ùë¶, und ùëß such that f(ùë•, ùë¶, ùëß) is defined.

Exercise 95 Consider the following recursive program ùëÉ over {f, g, h}.
f(ùë•, ùë¶, ùëß) = f(ùë•, ùë•, ùëß ‚àí 1), g(ùëß, ùë¶, ùë•)
g(ùë•, ùë¶, ùëß) = f(ùë•, ùë¶ ‚àí 1, ùëß), h(ùëß, ùë•, ùë¶)
h(ùë•, ùë¶, ùëß) = f(ùë• ‚àí 1, ùë¶ , ùëß)
ùëÉ
ùëÉ
ùëÉ
a) Construct a DcoBA Acall such that ùêø(Acall) = ùêøcall .
ùëÉ
ùëÉ
ùëÉ
ùëÉ
b) Construct an NBA Aterm such that ùêø(Aterm) ‚à© ùêøcall = ùêøterm.
ùëÉ
ùëÉ
ùëÉ
ùëÉ
c) Construct an NBA A
such that ùêø(A ) = ùêøcall ‚à™ ùêøterm.

d) Use the Ramsey-based method to determine whether ùëÉ terminates for all
values ùëÉ
of its parameters by checking ùêø(A ) for universality.
Exercise 96
a) Prove Lemma 8.24.
ùëÉ
b) Construct the DcoBA for the languages ùêøcall for the recursive programs
ùëÉ from Ex. 8.22, 8.23, 8.25 and 8.26.
Exercise 97 Reconsider the recursive program from Ex. 8.26. Show that the
value of t(3, 10, 11, 4) is defined, i.e. that all call sequences starting on this
call terminate.
Hint: Write a program that uses dynamic programming to answer this
question.
Exercise 98
ùëÉ
Construct the NBA A 1
term according to Lemma 8.29 for the recursive
program ùëÉ1 from Ex. 8.25.
Chapter 9

Alternating B ¬®
uchi Automata
In Chapter 3 we introduced alternating automata as an extension of
nondeterministic finite automata operating on finite words. They turned out
not to be more expressive than NFA but generally more succinct, i.e. there
are languages that can be recognised by AFA which are exponentially
smaller than the smallest equivalent NFA.
There is no reason why the concept of alternation with its two modes of
branching
- nondeterministic and universal - should be restricted to automata
operating on finite words only. In this chapter we consider alternating
automata operating on infinite words as an extension of B √ºchi automata
just in the same way as AFA extend NFA. An obvious question that arises
with this is that of expressiveness: do alternating B √ºchi automata exceed
the power of nondeterministic B √ºchi automata to recognise more than ùúî-
regular languages? The answer will be negative again. While the possibility
to translate NFA into DFA does not extend to B √ºchi automata, the
possibility to eliminate alternation does extend to B √ºchi automata.
However, the construction is a little bit more complicated than the simple
powerset construction turning AFA into NFA. On the other hand, it is much
simpler than the translation from NBA into DRA or DPA studied in Chp. 7.
This chapter is mainly concerned with alternating automata that recognise
words via the B √ºchi condition. Co-B √ºchi automata will also play a role as
they provide the means for simple complementation constructions. It is
possible to study alternating automata with any of the other acceptance
conditions introduced in Chapter 6, i.e.
alternating parity, Rabin, Streett and Muller automata. Details of such
investigations, in particular the possibility to eliminate alternation, are left
as exercises. Here we only remark that none of these combinations exceeds
the limits of ùúî-regularity in expressiveness either.
¬© The Author(s), under exclusive

license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
209
https://doi.org/10.1007/978-3-662-72154-4_9
210
9 Alternating B √ºchi Automata
9.1 Alternating Automata on Infinite Words
9.1.1 Syntax and Semantics
Just as NBA cannot be distinguished syntactically from NFA, alternating B
√ºchi automata are no different to AFA syntactically. In particular, their
transition functions map pairs of states and alphabet letters to positive
Boolean combinations of states.
Conjunctions in there can be interpreted again as the automaton reading
the rest of the word from multiple states in parallel. In order to facilitate
this, runs are trees again. However, these trees are now infinite in general,
since so are the underlying words.
Definition 9.1 An alternating B√ºchi automaton (ABA) is an A = (ùëÑ, Œ£, ùëû ,
ùõø, ùêπ
ùêº
)
+
just like an AFA. In particular, we have ùëûùêº ‚àà ùëÑ, ùõø ‚à∂ ùëÑ √ó Œ£ ‚Üí B (ùëÑ) and ùêπ
‚äÜ ùëÑ. The size of an ABA is measured in terms of the number of its states as
usual.

A run of the ABA A on a word ùë§ = ùëé ùëé . . .
0
1
‚àà Œ£ ùúî is an infinite ùëÑ-labelled tree ùúå
with the following properties.
‚Ä¢ The root node ùë£ 0 is labelled with the initial state: ùúå(ùë£ 0) = ùëû ùêº.
‚Ä¢ Let ùë£ be a node on level ùëñ (with the root node being on level 0), and let ùë£ ,
. . . , ùë£
1
ùëö
be all its successors (necessarily on level ùëñ + 1). Then we have
{ùúå(ùë£ùëñ ) ‚à£ ùëñ ‚àà {1, . . . , ùëö}} ‚äß ùõø(ùúå(ùë£), ùëéùëñ )
Such a run is accepting if for every (necessarily infinite) branch ùë£ , ùë£ , ùë£ , .
. .
0
1
2
there
are infinitely many ùëñ such that ùúå(ùë£ùëñ) ‚àà ùêπ .
As usual, the language of the ABA A is ùêø(A) ‚à∂= {ùë§ ‚àà Œ£ ùúî ‚à£ there is an
accepting run of A on ùë§} .

It is easy to see that ABA are at least as expressive as NBA. The proof of the
following theorem is left as an exercise.
Theorem 9.2 For every NBA A with ùëõ states there is an ABA B with at most
ùëõ + 1
states such that ùêø(B) = ùêø(A) .
The construction is entirely analogous to the one that embeds NFA into
AFA, cf.
Thm. 3.10, simply expressing nondeterminism in terms of disjunctions in
Boolean formulas in the transition table. The construction requires the
transition table of the underlying NBA to be total, i.e. there being at least
one successor for every state under any alphabet symbol. This could be
avoided if Boolean functions in an ABA's transition table were allowed to
include the constants true and false. Then getting stuck in an NBA could be
modelled using false. But then runs could have finite branches, and those
that end with a transition to true would have to count for acceptance as
well. For general simplicity in the constructions on alternating automata,
we omit these Boolean constants.
9.1 Alternating Automata on Infinite Words
211
ùëé
ùëè
ùëé , ùëè
ùëé
0
‚àß

1
2
ùëè
Fig. 9.1 ABA A for the language {ùë§ ‚àà {ùëé, ùëè}ùúî ‚à£ ‚à£ùë§‚à£ = ‚àû}
ùëé
.
Example 9.3
ùúî
Consider the ùúî-regular language ùêø = {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëé = ‚àû}. It
is a standard exercise to construct a two-state NBA recognising ùêø. With
Thm. 9.2
we immediately obtain an ABA for ùêø, too. This degenerate ABA - not
making use of proper alternation at all - does not shed any real insight into
the usefulness of alternation for recognising ùúî-regular languages, or onto
their conceptual difference to NBA.
It is possible, though, to construct a genuine ABA recognising ùêø, i.e. one
that makes use of universal branching. The underlying idea here is that in
linear structures,
"infinitely often" is the same as "always eventually", i.e. an ùúî-word
contains infinitely many symbols ùëé iff for every position ùëñ there is some
position ùëó ‚â• ùëñ such that ùë§( ùëó ) = ùëé .
We make use of this correspondence to construct an ABA for ùêø that works
as follows. It successively reads the next symbol from an input word ùë§. If it

is an ùëé
then the ABA can simply continue with the next letter. When it is not an ùëé,
then it employs universal branching. One part continues with the next letter,
the other part reads symbols until it has found an ùëé at some point in the
future.
The ABA A ‚à∂= ({0, 1, 2}, Œ£, 0, ùõø, {0, 2}) with
ùõø(0, ùëé) = 0
ùõø(1, ùëé) = 2
ùõø(2, ùë•) = 2 for ùë• ‚àà {ùëé, ùëè}
ùõø(0, ùëè) = 0 ‚àß 1
ùõø(1, ùëè) = 1
is shown in Fig. 9.1. We depict alternation in the transition function
naturally with intermediate nodes for universal (‚àß) or existential (‚à®)
branching.
ùúî
A run of A on the word (ùëéùëèùëè)
is shown in Fig. 9.2. The nodes' labels are
shown inside the nodes. The fact that it is an accepting run and, moreover,
that ùêø (A) = ùêø, can be seen as follows. On any word, each run will have a
branch of the form 0, 0, 0, . . . - here shown as the leftmost one. The ùëñ-th
node on this branch has a single child (which is necessarily labelled 0 as
well) if the ùëñ-th letter (starting from 0) of the underlying word is ùëé.
Otherwise, if it is ùëè, then this node has two children: one on this path with
all nodes labelled 0, and another starting a path with labels of
+

ùúî
ùúî
the form 1 2
or 1 . The number of occurrences of 1 on this path is determined by the
distance from position ùëñ to the next ùëé in the underlying w ord.
‚àó
ùúî
In particular, if the underlying word is of the form (ùëé + ùëè) ùëè , then the run
‚àó
ùúî
will have a branch of the form 0 1 , containing only finitely many accepting
states,
‚àó
ùúî
namely state 0. On the other hand, on a word of the form ((ùëé + ùëè) ùëé) , there
is one ùúî
branch of the form 0 , obviously containing infinitely many accepting states,
and
+
+
ùúî

all other branches are of the form 0 1 2 , and these also contain infinitely
many accepting states, namely state 2.
212
9 Alternating B √ºchi Automata
0
ùëé
0
ùëè
0
1
ùëè
0
1
1
ùëé
0
2
2
ùëè
‚ãÆ

‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
Fig. 9.2 Run of the ABA from Ex. 9.3 on the word (ùëéùëèùëè)ùúî.
The analysis of the general functionality of A from this example shows that
it would also accept the language of all words having infinitely many
symbols ùëé, if seen as an alternating co-B √ºchi automaton. Branches of any
run that contain infinitely many accepting states will necessarily eventually
see accepting states only.
It is reasonable to question the usefulness of ABA over NBA, based on this
example, where the "genuine" ABA recognising the given language is
larger than the standard NBA. However, it has an interesting structural
property that NBA do not possess: it is a weak alternating automaton. We
will study weakness in detail later on in Sect. 9.5. Here we remark that the
possibility to see A above as an alternating co-B √ºchi automaton without
changing its language is not a coincidence; instead, it is essentially what
weakness is: the irrelevance of a distinction between B √ºchi and co-B √ºchi
acceptance.
9.1.2 Memoryless Runs
A memoryless run is defined as it is for AFA: two nodes on the same level
that are labelled with the same state cannot be the roots of two different
subtrees. The run shown in Fig. 9.2 is memoryless. In fact, all runs of the
ABA A from Ex. 9.3 are always memoryless. This is a consequence of the
simplicity of this ABA: starting in any state, the run on any input word is
uniquely determined. This is a property of this particular ABA, though, and
not of ABA in general as the following example shows.
Example 9.4 Reconsider the language ùêø of words having infinitely many
symbols ùëé from Ex. 9.3. It is also recognised by the ABA B shown in Fig.

9.3. It differs from the ABA A from Ex. 9.3 in that, upon reading an ùëé in
state 1, it does not have to go
9.1 Alternating Automata on Infinite Words
213
ùëé
ùëè
ùëé , ùëè
0
‚àß
1
‚à®
2
ùëé
ùëè
Fig. 9.3 ABA B for the language {ùë§ ‚àà {ùëé, ùëè}ùúî ‚à£ ‚à£ùë§‚à£ = ‚àû}
ùëé
.
to state 2 but can choose to remain in state 1. This is done using a
nondeterministic choice which is depicted in Fig. 9.3 with an auxiliary ‚à®-
node.
The argument for why we have ùêø(B) = ùêø proceeds along the same lines as
for A ùúî

in Ex. 9.3: any accepting run will have one branch of the form 0 , some
branches
+
ùúî
of the form 0 1
on any word ùë§ /
‚àà ùêø, respectively all other branches of the form
+
+
ùúî
0 1 2
on words ùë§ ‚àà ùêø. Hence, all branches have infinitely many accepting states
iff the underlying word belongs to ùêø.
There is one minor difference to the analysis on branches in runs of A,
though: in ùëñ
ùëó
ùúî
a branch of the form 0 1 2 , ùëó is not determined anymore by the distance
from the ùëñ-th position to the next position carrying an ùëé. Instead, it is the
distance between the ùëñ-th position and some future position carrying an ùëé.
In other words, the purpose of state 1 in both A and B is to check for the
future occurrence of a letter ùëé which then leads to a transition into state 2.
Whilst A does this as soon as it is possible, B can choose to do so with any
future ùëé. Note that B also has non-accepting runs on words in ùêø that arise

from never taking the transition from 1 to 2 even though it would be
possible.
ùúî
A run of B on (ùëèùëé)
is shown in Fig. 9.4. It is not memoryless because different
branches that visit state 1 on the same level use different symbols ùëé to
transition into state 2.
Memoryless runs are the key to algorithmic properties of ABA since they
can be represented as DAGs of fixed width, namely the number of different
states of the underlying ABA. So we aim, again, for the result that
memoryless runs suffice in the sense that whenever a word is accepted by
an ABA then this is witnessed by the existence of a memoryless run. This
cannot be proved, though, as it was done for AFA on finite words. Runs are
infinite trees now, and these cannot be constructed by induction on their
height. Alternatively, the result for AFA can be shown by turning a non-
memoryless run into a memoryless one by successively replacing subtrees.
It is also not possible to simply argue for the existence of a memory-less run
that is obtained by successively replacing subtrees that violate
memorylessness, because the final result is only obtained in the limit of this
process and not after some final replacement. In this case, we additionally
need a measure for the progress made towards obtaining a memoryless run
when doing these successive replacements which allows us to argue that the
limit of this process has the desired property.
Definition 9.5 Let ùúå be a run of an ABA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) on a word ùë§ ‚àà Œ£ ùúî .
The rank of a node ùë£, written rk
, . . . , ùë£

ùë£ , is the maximal ùëò in a sequence ùë£0
ùëò
such
that
214
9 Alternating B √ºchi Automata
0
ùëè
0
1
ùëé
0
1
ùëè
0
1
1
ùëé
0
2

1
ùëè
0
1
2
1
ùëé
0
2
2
2
ùëè
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
Fig. 9.4 Non-memoryless run of the ABA from Ex. 9.4 on the word (ùëèùëé)ùúî.
‚Ä¢ ùë£ = ùë£ 0,

‚Ä¢
ùëñ
for all ùëñ ‚àà [ùëò ] we have: ùë£ +1
ùëñ
is a successor of ùë£ in ùúå,
‚Ä¢ ùúå(ùë£ùëò) ‚àà ùêπ and ùúå(ùë£ùëñ) /‚àà ùêπ for all ùëñ < ùëò.
In particular we have rk ùë£ = 0 if ùúå(ùë£) ‚àà ùêπ, and rk ùë£ = ‚àû if there is a path ùë£
through ùúå
starting in ùë£ that never visits an accepting state.
A level of the run ùúå is a maximal set of nodes that are all located at equal
distance from the root node. The rank of a level ùëâ is the maximal rank of all
its nodes: rk ùëâ ‚à∂= max{ rk ùë£ ‚à£ ùë£ ‚àà ùëâ }.
Lemma 9.6 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an ABA and ùúå be a run of A on some
ùë§ ‚àà Œ£ ùúî . Then ùúå is accepting iff every level in ùúå has finite r ank.
Proof We will show that indeed the following four statements are
equivalent, from which the lemma's claim follows immediately, since it
prescribes the equivalence of two of these.
a) Every node in ùúå has finite rank.
b) Every level in ùúå has finite rank.
c) Infinitely many levels have finite rank.

d) The run ùúå is accepting.
"(a) ‚áí (b)" This is a consequence of the fact that ùúå is a finitely-branching
tree.
Hence, if ùëâ is a level then ‚à£ùëâ ‚à£ < ‚àû and therefore max{ rk ùë£ ‚à£ ùë£ ‚àà ùëâ } < ‚àû if
rk ùë£ < ‚àû
for all ùë£ ‚àà ùëâ .
9.1 Alternating Automata on Infinite Words
215
"(b) ‚áí (c)" Trivial.
"(c) ‚áí (d)" By contradiction. Suppose that ùúå was not accepting. I.e. it
contains some path ùë£ , ùë£ , . . .
0
1
that visits accepting states only finitely often. Let ùëö ‚à∂= max{ùëñ ‚à£
ùúå(ùë£ùëñ ) ‚àà ùêπ }. By assumption, ùëö exists. Moreover, we have rk ùë£ = ‚àû for all ùëñ >
ùëö
ùëñ
as each such ùë£ùëñ is clearly the source of a path that does not visit accepting s
tates anymore.
Now let ùëâ , ùëâ , . . .
0
1

be the levels of ùúå in descending order. Note that ùë£ùëñ ‚àà ùëâùëñ for
all ùëñ ‚â• 0. Since the rank of a level can never be smaller than the rank of any
of its elements, we have rk ùëâ = ‚àû for all ùëñ > ùëö as well. This shows that
there can be at ùëñ
most finitely many levels with finite rank.
"(d) ‚áí (a)" By contradiction. Suppose there was some node ùë£ such that rk
ùë£ = ‚àû.
Then there would be a path ùë£ , ùë£ , . . .
0
1
starting in ùë£ that does not visit accepting
states. Since the distance of ùë£ to the root is finite, there can be at most
finitely many accepting states on the unique path starting in the root of ùúå,
traversing to ùë£ and then continuing along ùë£ , ùë£ , . . .
1
2
Hence, ùúå would contain a path that does not visit
accepting states infinitely often and, therefore, ùúå would not be accepting.
‚óª
We say that a run ùúå of A on ùë§ with levels ùëâ , ùëâ , . . .
0
1

is memoryless on level ùëñ if
‚Ä≤
‚Ä≤
there are no two nodes ùë£, ùë£ ‚àà ùëâùëñ such that ùúå(ùë£) = ùúå(ùë£ ) but the two subtrees
ùë° under
‚Ä≤
‚Ä≤
ùë£ and ùë° under ùë£ differ. Clearly, ùúå is memoryless if it is memoryless on all
levels ùëñ ‚â• 0.
Lemma 9.7 Let ùëõ ‚â• 1 , A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an ABA, ùë§ ‚àà Œ£ ùúî and ùúå be an
accepting run of A on ùë§ that is memoryless on levels 0, . . . , ùëõ ‚àí 1 . Then
there is a run 
ùúå of A on ùë§ that is memoryless on levels 0, . . . , ùëõ , and the rank of the ùëñ -th
level in 
ùúå is bounded by the rank of the ùëñ -th level in ùúå .
Proof Let ùë§ = ùëé ùëé . . .
, ùëâ , . . .
0
1
, and ùëâ0

1
be the levels of ùúå in descending order. If ùëâùëõ
does not contain two nodes that violate the property of being memoryless on
level
‚Ä≤
‚Ä≤
ùëõ, then simply take ÃÇ
ùúå ‚à∂= ùúå. Otherwise let ùë£, ùë£ ‚àà ùëâùëõ such that ùúå(ùë£) = ùúå(ùë£ ) but the
‚Ä≤
‚Ä≤
subtree ùë° rooted at ùë£ differs from the subtree ùë° rooted at ùë£. W.l.o.g. we
assume rk ùë£ ‚â§ r k ùë£‚Ä≤ .
‚Ä≤
‚Ä≤
‚Ä≤
Let ùúå result from ùúå by replacing the subtree ùë° rooted at ùë£ with the subtree
‚Ä≤
‚Ä≤
ùë° . We claim that ùúå is also an accepting run of A on ùë§. Since ùúå(ùë£ ) = ùúå(ùë£),
the fact that the labels of successor nodes form a model of the transition
function at
‚Ä≤‚Ä≤

‚Ä≤
the respective position, is not violated: let ùë£
be the parent node of ùë£ , residing on
level ùëâùëõ‚àí1, and let ùëÄ ‚äÜ ùëâùëõ be the set of its successor nodes. By
assumption we have
‚Ä≤‚Ä≤
{ùúå(ùë¢) ‚à£ ùë¢ ‚àà ùëÄ } ‚äß ùõø(ùúå(ùë£ ), ùëéùëõ‚àí1). Hence, we also have
‚Ä≤
‚Ä≤‚Ä≤
{ùúå(ùë¢) ‚à£ ùë¢ ‚àà (ùëÄ ‚àñ {ùë£ }) ‚à™ {ùë£}} ‚äß ùõø(ùúå(ùë£
), ùëéùëñ‚àí1) .
‚Ä≤
Thus, the replacement of ùë° by (a copy of) ùë° preserves the property of being a
run of A on ùë§. It should be clear that this operation cannot increase the
rank of any level
‚Ä≤
because the levels in ùúå are subsets of the respective levels in ùúå.
Since each level of a run is finite, in particular ‚à£ùëâùëõ‚à£ < ‚àû, this process can
be iterated with potentially other pairs of nodes on level ùëñ until one obtains
a run ÃÇ
ùúå that
216

9 Alternating B √ºchi Automata
is memoryless on level ùëõ as well. Since levels ùëâ , . . . , ùëâ
0
ùëõ‚àí1 are left untouched, ÃÇ
ùúå has
the properties demanded in the lemma's statement.
‚óª
This allows us now to prove that it suffices to consider memoryless runs
only for determining whether a given ABA accepts a given word.
Theorem 9.8 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an ABA and ùë§ ‚àà Œ£ ùúî . We have ùë§ ‚àà ùêø(A)
iff there is a memoryless accepting run of A on ùë§ .
Proof "‚áê" Trivial. "‚áí" Assume that ùúå is an accepting run of A on ùë§.
According to Lemma 9.6, all its ranks are finite. We now construct a
sequence ùúå , ùúå , . . .
0
1
of
runs of A on ùë§ as follows. Let ùúå0 ‚à∂= ùúå, and let ùúåùëñ ‚à∂= ÃÇ
ùúåùëñ‚àí1 for ùëñ > 0 according to

Lemma 9.7. Then the following holds for any ùëõ ‚â• 0:
a) ùúåùëõ is memoryless on levels 0, . . . , ùëõ. This is trivially true for ùúå0 since level
0 in a run cannot contain two different nodes, and it follows for ùëõ > 0 by
induction using Lemma 9.7.
b) ùúåùëõ is accepting. Again, this can be shown by induction. It is true for ùëõ = 0
by assumption. Suppose it is true for some ùëõ ‚â• 0. According to Lemma 9.6,
the ranks of all levels in ùúåùëõ are finite. According to Lemma 9.7, the ranks of
levels in ùúåùëõ+1 are bounded by the ranks of the respective levels in ùúåùëõ, so they
must be ùëõ
finite as well. Using Lemma 9.6 again, we get that ùúå +1 is accepting as w
ell.
c) Let ùëö > ùëõ. Then ùúåùëö and ùúåùëõ agree on levels 0, . . . , ùëö. In other words,
the construction of this sequence successively fixes the levels one-by -one.
‚àó
Because of property (b), this sequence has a limit ùúå which is defined level-
wise as follows: its ùëñ-th level is the ùëñ-th level of all ùúåùëõ for ùëõ ‚â• ùëñ. Note that this
is well-defined.
‚àó
An immediate consequence of this is that ùúå would be memoryless, provided
that it is a run, because each of its levels has undergone the construction
from Lemma 9.7
‚àó
that eliminates violations of memorylessness on that level. But, likewise, ùúå is
easily seen to be a run of A on ùë§. For this it suffices to consider an arbitrary
node ùë£ on some arbitrary level ùëõ. Since this node and its successors also
exists in all ùúåùëñ for
‚àó

ùëñ > ùëõ, the transition relation must be satisfied at node ùë£ in ùúå .
‚àó
It remains to be seen that ùúå is also accepting. According to Lemma 9.6 it
suffices, again, to show that all its levels have finite ranks. Note that this is
the case for each
‚àó
ùúå
, ùëâ , . . .
ùëõ , ùëõ ‚â• 0. Let ùëâ0
1
be the levels of ùúå , and let ùëõ ‚â• 0. We make use of part (c)
‚àó
of the observations above, namely the fact that the ùëõ-th level ùëâùëõ of ùúå
is also the
ùëõ-th level of all ùúåùëñ for ùëñ ‚â• ùëõ. Note that their ranks are all finite, even though
they may not be the same for all such ùëñ. However, since the ranks of levels
do not increase in the sequence ùúå , ùúå , . . .
0
1
, there is some ùëò such that rk ùëâ = ùëò in all but finitely many ùëõ
ùúåùëñ . Hence, this rank only depends on the ranks of nodes on the next ùëò levels.
In

‚àó
other words, levels ùëâ , . . . , ùëâ
ùëõ
ùëõ+ùëò of ùúå
agree with the respective levels in all ùúåùëñ for
‚àó
ùëñ ‚â• ùëõ + ùëò . Since the rank of ùëâùëõ in these is finite, so must be the rank of ùëâùëõ
in ùúå .
‚óª
As mentioned in Chp. 3 already, memoryless runs can be represented as
DAGs instead of trees, by simply sharing common subtrees on the same
level. Fig. 9.5
shows a DAG representation of a (memoryless) run of the ABA B from Ex.
9.4. A general bound on the width of such DAGs - the maximal size of a
level - in terms of
9.2 A Game-Theoretic Semantics
217
0
ùëé
0
1
ùëè

0
1
ùëé
0
1
2
ùëè
0
1
2
ùëé
0
1
2
ùëè
0
1
2
ùëé
0

1
2
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
Fig. 9.5 DAG representation of a memoryless run of the ABA from Ex. 9.4
on the word (ùëéùëè)ùúî.
the number of states of the underlying ABA is obtained immediately. We
therefore also identify a level as a set of nodes in a memoryless run with the
set of their labels.
9.2 A Game-Theoretic Semantics
As in the case of alternating automata on finite words, cf. Chp. 3, it is
possible to explain acceptance of a word by an ABA in terms of winning
strategies for one of two players in a game of perfect information. The role
of the two players is the same, given an ABA A and a word ùë§ ‚àà Œ£ ùúî: player
0's aim is to show that ùë§ ‚àà ùêø(A), and player 1 wants to show that ùë§ /
‚àà ùêø(A). The game progresses through the word, letter
by letter, and through A's state space. It should be clear that this cannot be
cast into the framework of reachability games anymore since, in general,
acceptance of a word is not determined by a finite prefix of the word only.
Hence, we need to extend the game-theoretic framework. We first introduce
B ¬®
uchi games as abstract two-player

games of infinite duration and then make use of them to explain acceptance
of a word by an ABA in terms of winning strategies in such games.
218
9 Alternating B √ºchi Automata
9.2.1 B ¬®
uchi Games
Much of the technical development for the theory of reachability games, as
introduced in Sect. 3.4, like the notions of players, arenas, plays, strategies,
etc. can be re-used here as well.
Definition 9.9 A B√ºchi game is a G = (ùëâ, ùëâ , ùëâ , ùë£ , ùê∏, ùêπ
0
1
ùêº
) s.t. (ùëâ , ùê∏ ) is a directed
graph with left-total and finitely-branching edge relation, ùëâ = ùëâ0 ‚äé ùëâ1 is
the partition of the node set into nodes owned by either of the two players,
ùë£ùêº ‚àà ùëâ is a designated initial node in the game, and ùêπ ‚äÜ ùëâ is a designated
set of accepting nodes.
The notions of plays, strategies, positional strategies and attractors are
defined in the same way as they are for reachability games. The only
difference lies in the interpretation of the winning condition, also given as a
set ùêπ of nodes: a play ùúå = ùë£ , ùë£ , . . .
0
1

is winning for player 0, if Inf (ùúå) ‚à© ùêπ ‚â† ‚àÖ, i.e. if it contains infinitely many
accepting nodes. Otherwise it is winning for player 1.
Remember that, given a game G = (ùëâ , ùëâ , ùëâ , ùë£ , ùê∏ , ùêπ
0
1
ùêº
), the attractor Attr (ùëá )
ùëù
of
a set ùëá ‚äÜ ùëâ is the set of all nodes from which player ùëù can force a play to
eventually reach ùëá . Recall that the construction of an attractor region, as
given in Def. 3.23, assumes the graph underlying the game to be finitely-
branching. This is the reason for the same requirement in Def. 9.9 above. It
is equally possible to consider B √ºchi games of infinite branching degree,
but then some of the technical developments, in particular the definition of
attractors, would have to be e xtended.
It is not a surprise that attractors played a major role for the question of
determining the winner in a reachability game. They seem less useful in B
√ºchi games. However, note that, while player 0 attempts to enforce the set ùêπ
to be reached in a reachability game, she needs to enforce repeated visits to
ùêπ in a B √ºchi game. This leads to the following definition.
Definition 9.10 Let G = (ùëâ, ùëâ , ùëâ , ùë£ , ùê∏, ùêπ
0
1
ùêº

) be a B √ºchi game and ùëá ‚äÜ ùëâ . We use the
abbreviations ‚óáùëá ‚à∂= {ùë£ ‚àà ùëâ ‚à£ ùë£ùê∏ ‚à© ùëá ‚â† ‚àÖ} and ‚óªùëá ‚à∂= {ùë£ ‚àà ùëâ ‚à£ ùë£ùê∏ ‚äÜ ùëá
}.
The repeated attractor of ùëá ‚äÜ ùëâ for player ùëù ‚àà {0, 1} is rAttr (ùëá ) ‚à∂=
ùëù
ùëò
0
‚ãÇ
(ùëá )
(ùëá ) ‚à∂= ùëâ
ùëò ‚ààN rAttr ùëù
where rAttr ùëù
and
ùëò +1
ùëò
ùëò
rAttr
(ùëá )
‚à∂=
(ùëá ‚à© ((ùëâ

(ùëá )) ‚à™ (ùëâ
(ùëá ))))
ùëù
Attr ùëù
ùëù ‚à© ‚óá rAttr ùëù
1‚àí ùëù ‚à© ‚óª rAttr ùëù
ùëò ‚â•
for
0.
ùëò
Thus, rAttr (ùëá )
ùëù
consists of all nodes from which player ùëù can enforce at least ùëò
repeated visits to set ùëá and, thus, rAttr (ùëá )
ùëù
is the set of all nodes from which player
ùëù can enforce infinitely many visits to ùëá .
We will use games to show that alternating B √ºchi automata can easily be
complemented into alternating co-B √ºchi automata by a conceptually
simple dualisation construction. Its correctness proof is not that simple,
though. It is the reason for introducing B √ºchi games in the first place, and
we need the fundamental result of determinacy again.

9.2 A Game-Theoretic Semantics
219
Theorem 9.11 Let G be a B√ºchi game, ùëù ‚àà {0, 1} .
a) Exactly one of the players has a winning strategy for G .
b) Player ùëù has a winning strategy for G iff player ùëù has a positional
winning strategy for G .
Proof Let G = (ùëâ, ùëâ , ùëâ , ùë£ , ùê∏, ùêπ
0
1
ùêº
) be a B √ºchi game. We will show the more general
statement that for every ùë£ ‚àà ùëâ , one of the players has a winning strategy
for the game (ùëâ , ùëâ , ùëâ , ùë£, ùê∏ , ùêπ
0
1
). Then surely one of the players must have a winning strategy for the game
started in ùë£ùêº . This then shows part (a) of the theorem, and part (b) follows
by inspection of the construction which is easily seen to yield positional s
trategies.
We claim that
‚Ä¢ player 0 has a positional winning strategy from all nodes in rAttr (ùêπ) 0
, and

‚Ä¢ player 1 has a positional winning strategy from all nodes in ùëâ ‚àñ rAttr (ùêπ)
0
.
ùëò
For the former, suppose that ùë£ ‚àà rAttr (ùêπ) =
(ùêπ )
0
‚ãÇùëò‚ààN rAttr 0
. Then, in particular, ùë£ ‚àà
Attr (ùêπ)
0
. Hence, player 0 can enforce any play starting in ùë£ to reach ùêπ. Moreover,
by ùëò
the definition of rAttr (ùêπ)
0
, she can then enforce such plays to progress to a node from
which she can do so again. Hence, this combination of attractor strategies
guarantees her to repeatedly visit nodes in ùêπ, and it is positional. The
crucial insight here is given by the following argument. Suppose that this
did not guarantee her to visit accepting nodes infinitely often. Then there
would be some play conforming to this strategy that contains only finitely,
say ùëò many accepting nodes. This then contradicts ùëò +1
the assumption that ùë£ ‚àà rAttr

(ùêπ )
0
which demands every play conforming to this
strategy to visit accepting nodes at least ùëò + 1 man y times.
Now for the second claim, take a node ùë£ ‚àà ùëâ ‚àñ rAttr (ùêπ)
0
. Player 1 has an
even simpler strategy, namely an avoidance strategy. Note that Attr (
(ùêπ )) ‚äÜ
0 rAttr 0
rAttr (ùêπ)
0
, and consider two cases: if ùë£ ‚àà ùëâ1 then there must be some ùë§ ‚àà ùë£ùê∏ such
that ùë§ /
‚àà Attr (
(ùêπ ))
(
(ùêπ ))
0 rAttr 0
, for otherwise if ùë£ùê∏ ‚äÜ Attr 0 rAttr 0

then we would
have ùë£ ‚àà Attr (
(ùêπ ))
(ùêπ )
0 rAttr 0
by the definition of an attractor and, hence, ùë£ ‚àà rAttr 0
.
In other words, when it is player 1's turn to move in a node outside of rAttr
(ùêπ) 0
, he
can always move to some node that is also outside of rAttr (ùêπ) 0
.
In the second case we have ùë£ ‚àà ùëâ0. By a similar argument, we must have
ùë£ùê∏ ‚äÜ
ùëâ ‚àñ Attr (
(ùêπ ))
(
(ùêπ ))
0 rAttr 0
for otherwise, if there was some ùë§ ‚àà ùë£ùê∏ ‚à© Attr 0 rAttr 0
we would have ùë£ ‚àà Attr (

(ùêπ )) ‚äÜ
(ùêπ )
0 rAttr 0
rAttr 0
. In other words, player 0 cannot
enforce a play to leave ùëâ ‚àñ rAttr (ùêπ)
0
.
This clearly defines a positional strategy ùúé1 for player 1: for every ùë£ ‚àà ùëâ1 ‚à©
(ùëâ ‚àñ
rAttr (ùêπ))
(ùêπ ))
0
pick an arbitrary ùë§ ‚àà ùë£ùê∏ ‚à© (ùëâ ‚àñ rAttr 0
. Whenever a play visits ùë£,
move to ùë§, i.e. ùúé1(ùë£) ‚à∂= ùë§.
It remains to be seen that this is indeed a winning strategy, i.e. that every
play conforming to this strategy is winning for player 1 or, equivalently,
only visits accepting states finitely often. Suppose that this was not the case,
i.e. there was a play ùúå = ùë£ , ùë£ , . . .
0
1

conforming to ùúé1 such that there are ùëñ0 < ùëñ1 < . . . with ùë£ùëñ ‚àà ùêπ
ùëó
for all ùëó ‚â• 0. This is not enough to obtain a contradiction right away
because we need to contradict the assumption that ùë£0 ‚àà ùëâ ‚àñ rAttr (ùêπ)
0
, i.e. we need to show that
ùë£ 0 ‚àà rAttr (ùêπ)
0
. But there may be other choices in G from the nodes in ùúå that lead to
220
9 Alternating B √ºchi Automata
different plays and that need to be considered in an argument about
attractors. We therefore assume that player 1's strategy ùúé1 is best in the
sense that choices other than those of the form ùë£ ‚Ü¶ ùúé1(ùë£) would lead to
earlier visits of accepting states in subsequent plays. Then we have ùë£0 ‚àà
Attr ({ùë£ })
‚àà ùêπ
0
ùëñ
for every ùëó ‚â• 0. Since ùë£ùëñ
for
ùëó

ùëó
all ùëó ‚â• 0, we get ùë£0 ‚àà rAttr (ùêπ)
0
, contradicting the assumption.
‚óª
Definition 9.12 A co-B√ºchi game is a G = (ùëâ, ùëâ , ùëâ , ùë£ , ùê∏, ùêπ
0
1
ùêº
) defined like a B √ºchi
game with the only difference that player 0 wins a play iff it eventually
traverses through accepting states only.
Given a B √ºchi, resp. co-B √ºchi game G = (ùëâ , ùëâ , ùëâ , ùë£ , ùê∏ , ùêπ
0
1
ùêº
), the dual game is
the co-B √ºchi, resp. B √ºchi game G ‚à∂= (ùëâ , ùëâ , ùëâ , ùë£ , ùê∏ , ùëâ
1
0

ùêº
‚àñ ùêπ ).
Hence, a game is dualised by swapping the players' choices and dualising
the winning condition. Note that a strategy ùúé for player ùëù in G becomes a
strategy for player 1 ‚àí ùëù in G because of the swapping of the roles.
Moreover, it is player 1's goal, for example, to enforce plays that eventually
only traverse through ùëâ ‚àñ ùêπ for the winning condition ùêπ in a B √ºchi game.
This is then exactly the winning condition in the dual co-B √ºchi game (for
player 0). The following theorem is therefore easy to prove.
Theorem 9.13 Let G be a B√ºchi or co-B√ºchi game. Player 0 wins G (with a
positional strategy) iff player 1 wins G (with a positional strategy).
A consequence of determinacy in Thm. 9.11 and this duality principle is the
following.
Corollary 9.14 Let G be a B√ºchi or co-B√ºchi game, ùëù ‚àà {0, 1} . Player ùëù
has a (positional) winning strategy for G iff ùëù does not have a winning
strategy for G .
9.2.2 Acceptance as a Game
As said above, the main purpose of the introduction of B √ºchi games is to
provide a game-theoretic characterisation of acceptance of a word by an
ABA, and then to use the determinacy result - which is most insightful in
this context of such abstract games - in subsequent developments regarding
ABA and their use for ùúî-regular languages, in particular an alternative
proof of complementation closure.
As in the case of finite words, we define the acceptance game as a product
of a given word with a given alternating automaton. However, we choose a
slightly different format for the nodes and edges in the game, simply
because it makes the link between dualisation of games (above) and of
automata (below) easier to form.

In these games, players closely follow the Boolean formulas of the ABA's
transition function. In contrast to this, the acceptance games for AFA and
finite words were more semantical in nature with their alternating moves
between player 0 choosing models of such formulas, and player 1 choosing
states in these models. There is no conceptual difference between these two
versions, and the reason for defining the
9.2 A Game-Theoretic Semantics
221
ABA acceptance games differently to the AFA acceptance games is just to
present both ways. We leave it as an exercise to define acceptance games
for ABA in which the players choose alternatingly.
Definition 9.15 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùëé
. . .
ùêº
) be an ABA and ùë§ = ùëé0 1
‚àà Œ£ ùúî . Let
Œ¶ ‚à∂= ùëÑ ‚à™ { ùëì ‚à£ ‚àÉùëû ‚àà ùëÑ, ùëé ‚àà Œ£ s.t. ùëì is a subformula of ùõø(ùëû, ùëé)}.
‚Ä≤
ùë§
ùëâ , ùëâ , ùëâ , ùë£
, ùê∏ , ùêπ
The acceptance game for A and

is the B √ºchi game GA,ùë§ = (
0
1
ùêº
)
where ùëâ ‚à∂= Œ¶ √ó N and ùëâ0 consists of all nodes of the form (ùëû, ùëñ) for ùëû ‚àà ùëÑ
and those of the form ( ùëì ‚à® ùëî, ùëñ) whereas ùëâ1 consists of all other nodes, i.e.
those of the form ( ùëì ‚àß ùëî, ùëñ). The edge relation in this game is giv en as
ùê∏
‚à∂= {(( ùëì
, ùëñ
, ùëñ
0 ‚à® ùëì1
), ( ùëì ùëó
)) ‚à£ ùëó ‚àà {0, 1}, ùëñ ‚â• 0}
‚à™ {(( ùëì
, ùëñ
, ùëñ
0 ‚àß ùëì1
), ( ùëì ùëó
)) ‚à£ ùëó ‚àà {0, 1}, ùëñ ‚â• 0}

‚à™ {((ùëû, ùëñ), (ùõø(ùëû, ùëéùëñ ), ùëñ + 1)) ‚à£ ùëû ‚àà ùëÑ, ùëñ ‚â• 0} .
‚Ä≤
The initial node is (ùëû ,
ùêº
0) and the winning condition is ùêπ ‚à∂= ùêπ √ó N .
The acceptance game GA,ùë§ can therefore be seen as both players moving
two tokens, one on the underlying ABA, the other on the word. Whenever
the automaton token is on a state ùëû, we read off the letter ùëé that the word
token is on, place the token at the root of the syntax tree of the positive
Boolean formula ùõø(ùëû, ùëé), and move the word token to the next letter. Note
that this move is deterministic. It has been assigned to player 0 for no
particular reason. Since there is no choice involved, one could equally
assign such moves to player 1. The cleanest solution would in fact be to
introduce deterministic nodes not belonging to either of the players. At least
this would fit best with dualisation. On the other hand, this would cause
extra work in arguing that these are still two-player games etc.
The other moves are pretty much self-explanatory. If the automaton token is
on a disjunction, then player 0, who wants to show that the underlying word
is accepted, needs to provide proof for that by proposing an appropriate
disjunct. Note that, instead of proposing a model of a formula, it suffices to
choose which disjunct will be satisfied by such a model. Likewise, if a
conjunction is reached, player 1 picks the conjunct that he believes would
not be satisfied subsequently.
The main result of this section then is the observation that the game-
theoretic semantics is equivalent to the semantics based on run trees.
Theorem 9.16 Let A be an ABA and ùë§ ‚àà Œ£ùúî . Player 0 wins GA,ùë§ iff ùë§ ‚àà
ùêø(A ) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ

ùëé
. . .
ùêº
) and ùë§ = ùëé0 1
‚àà Œ£ ùúî .
"‚áê" Suppose that ùë§ ‚àà ùêø(A), i.e. there is an accepting run ùúå of A on ùë§. In
particular, its root is labelled with ùëûùêº .
We (recursively) call a node ( ùëì , ùëñ) of GA,ùë§ true, if one of three cases
holds:
‚Ä¢ ùëì = ùëû for some ùëû ‚àà ùëÑ, and there is a node ùë£ on level ùëñ (starting with the
root at level 0) in ùúå labelled with ùëû;
‚Ä¢ ùëì = ùëî 1 ‚à® ùëî 2
ùëó
and (ùëî , ùëñ) is true for some ùëó ‚àà {1, 2};
‚Ä¢ ùëì = ùëî
, ùëñ
1 ‚àß ùëî2 and (ùëî ùëó
) is true for both ùëó ‚àà {1, 2}.
222
9 Alternating B √ºchi Automata
This allows us to define a simple strategy for player 0 in GA,ùë§ : she plays
to preserve truth. It remains to be seen that this is possible and that it is a

winning strategy.
For the former, suppose the play hits a node of the form (ùëû, ùëñ) and then
continues deterministically with ùõø(ùëû, ùëéùëñ). By truth of (ùëû, ùëñ) there is a node ùë£
on level ùëñ in ùúå
such that ùúå(ùë£) = ùëû. By construction of run trees, the set ùëÄ of successors of ùë£
on level ùëñ + 1 satisfies ùëÄ ‚äß ùõø(ùëû, ùëéùëñ). A simple induction on the structure of
positive Boolean formulas shows that (ùõø(ùëû, ùëéùëñ), ùëñ + 1) is then true as w ell.
The fact that player 0 can preserve truth in a move from a node of the form
( ùëì ‚à® ùëî, ùëñ), resp. player 1 has to preserve truth in a move from a node of the
form ( ùëì ‚àß ùëî, ùëñ) is in fact part of this induction.
Hence, this is a viable strategy for player 0, i.e. she can maintain the
invariant of moving to true nodes only. The fact that this is a winning
strategy is even easier to see: it should be clear that any play conforming to
this strategy is also a path through ùúå. Hence, it contains infinitely many
accepting states from ùêπ by assumption, and the play therefore satisfies the B
√ºchi winning condition.
"‚áí" Likewise, from a winning strategy ùúé for player 0 in the game GA,ùë§ we
can iteratively construct an accepting run of A on ùë§. First of all, because of
Thm. 9.11
we can assume ùúé to be positional.
We start with the root labelled with ùëûùêº at level 0. Whenever a path in this
partial run tree ends in a node ùë£ with label ùëûùëñ on level ùëñ, we extend the
construction of the tree at this node as follows. Note that node (ùëû , ùëñ
, ùëé
ùëñ
) has a unique successor (ùõø(ùëûùëñ
ùëñ ), ùëñ + 1)

in G
, ùëé
A, ùë§ . Moreover, ùõø(ùëûùëñ
ùëñ )
is a finite formula, and the game rules follow the
structure of this formula. Strategy ùúé resolves disjunctions in it. We collect
the set
‚Ä≤
‚Ä≤
ùëÄ of states ùëû that eventually occur in the form of a node (ùëû , ùëñ + 1) by
following all plays conforming to ùúé. Again, a straightforward induction on
the structure of
‚Ä≤
Boolean formulas shows that ùëÄ ‚äß ùõø(ùëû , ùëé
ùëñ
ùëñ ). For every node ùëû
‚àà ùëÄ we expand the
‚Ä≤
run tree construction with a node on level ùëñ + 1 labelled with ùëû .
This guarantees that the structure obtained in the limit of this process is a
complete run tree. The fact that it is also accepting follows again from the
observation that every path in this run tree corresponds to a play in GA,ùë§
conforming to ùúé. Thus, it also sees accepting states infinitely often.

‚óª
It should be clear that the entire construction could also be carried out for
alternating co-B √ºchi automata (AcoBA), defined syntactically like ABA,
but accepting a word only if there is a run such that eventually all paths of
the run traverse through accepting states only. Consequently, the
acceptance game of an AcoBA and a word becomes a co-B √ºchi game,
defined accordingly.
9.3 Expressiveness
We can use Thm. 9.8 to tackle the converse of Thm. 9.2, i.e. the question
after an upper bound on the expressive power of ABA. As mentioned earlier,
ABA do not exceed the expressivity of ùúî-regular languages. It is possible to
construct an NBA from an ABA that recognises the same language.
9.3 Expressiveness
223
9.3.1 Alternation Elimination
One may expect the translation of an alternating automaton into a
nondeterministic one to be similarly complex in terms of the involved
combinatorics as the construction of a deterministic automaton from a
nondeterministic one. This is not the case, though, at all. The step from an
ABA to an NBA can be realised with a relatively simple extension of the
well-known powerset construction.
Intuitively, the NBA guesses levels of a memoryless run of the underlying
ABA.
This is essentially a powerset construction. The next level in a memoryless
run consists of the union of models of the transition function applied to the
nodes of the previous level and the corresponding letter in the input word.
Since models of Boolean formulas are not necessarily unique, there can be
several possibilities for the node labels in the next level of such a run, and

nondeterminism is used to guess one that will eventually lead to an
accepting run.
Clearly, this is not sufficient to check for the existence of a memoryless
accepting run. The NBA also needs to ensure that every path in this run will
see accepting states infinitely often. This is surprisingly easy to do: with
each set of states forming the labels of a level in a memoryless run of the
underlying ABA, it also remembers a subset thereof, namely those state that
occur on paths which still need to visit an accepting state. At the beginning,
the subset is full, i.e. from all states on the current level we still need to see
accepting states. In other words: we still need to prove that all of them have
finite rank. Whenever any of these states, that are successively transformed
by the powerset construction into successors and successors of successors
etc., is an accepting state, it is eliminated from this subset. This leads to the
following effect. If a node has finite rank then eventually all its descendants
disappear from the subset. If it has infinite rank, i.e. there is a path from it
that never visits accepting states, then this subset never gets empty. So the
subset must become empty infinitely often when the underlying ABA run is
accepting. This provides the B √ºchi acceptance condition for the resulting
automaton. The construction presented in the following theorem is known
as the Miyano-Hayashi construction, named after its inventors.
Theorem 9.17
ùëõ
For every ABA A of size ùëõ there is an NBA B of size at most 3 such that
ùêø(B) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
). W.l.o.g. we assume that ùëûùêº /
‚àà ùêπ . We construct
ùëÑ

‚Ä≤
‚Ä≤
ùëÑ
B ‚à∂= (3 , Œ£, ùëû , Œî, ùêπ ) as follows. First of all, note that 3
‚âÉ {(ùëÜ, ùëá ) ‚à£ ùëÑ ‚äá ùëÜ ‚äá ùëá },
ùêº
and we can identify states of B as pairs (ùëÜ, ùëá ) of sets of states of A such
that the second is a subset of the first. In accordance with the intuitive
description above, let
‚Ä≤
ùëû
‚à∂= ({ùëû
ùêº
ùêº }, {ùëû ùêº }).
ùëÑ
Its transition relation is given as follows. Let (ùëÜ, ùëá ) ‚àà 3
and ùëé ‚àà Œ£ be given. We
‚Ä≤
‚Ä≤
have (ùëÜ , ùëá ) ‚àà Œî((ùëÜ, ùëá ), ùëé) iff the following holds.
‚Ä≤

a) ùëÜ is a minimal (w.r.t. '‚äÜ') model of ‚ãÄ
ùõø(ùëû, ùëé)
ùëû‚ààùëÜ
. In particular, for every ùëû ‚àà ùëÜ
‚Ä≤
‚Ä≤
‚Ä≤
there is some ùëÜ ‚äÜ ùëÜ
ùëû
such that ùëÜùëû is a minimal model of ùõø(ùëû, ùëé ).
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
b) ùëá ‚à∂= (‚ãÉ{ùëÜ ‚à£ ùëû ‚àà ùëá }) ‚àñ ùêπ
‚à∂= ùëÜ ‚àñ ùêπ
ùëû
if ùëá ‚â† ‚àÖ, and ùëá
otherwise.
224

9 Alternating B √ºchi Automata
ùëé
ùëé , ùëè
ùëé
ùëé , ùëè
ùëè
({
ùëè
ùëé
0}, ‚àÖ)
({0, 1}, {1})
({0, 2}, ‚àÖ)
({0, 1, 2}, {1})
ùëé
Fig. 9.6 NBA for {ùë§ ‚àà {ùëé, ùëè}ùúî ‚à£ ‚à£ùë§‚à£ = ‚àû}
ùëé
resulting from the ABA in Fig. 9.3.
‚Ä≤
ùëÑ
At last, let ùêπ ‚à∂= 2

√ó {‚àÖ}.
The claim on the size of B should be clear. It may take an extra state to
satisfy the assumption of ùëûùêº /
‚àà ùêπ . However, this does not need to be carried out explicitly. If
‚Ä≤
ùëû ùêº ‚àà ùêπ then simply let ùëû ‚à∂= ({ùëû
ùêº
ùêº }, ‚àÖ).
Correctness of this construction remains to be seen, i.e. that ùêø(B) = ùêø(A).
For this, it is useful to note that, in a run (ùëÜ , ùëá
, ùëá
0
0), (ùëÜ1
1), . . . of B on any word, each
ùëáùëñ+1 is uniquely determined by ùëÜùëñ+1 and ùëáùëñ. In particular, in order to
construct such a run, it suffices to construct the sequence ùëÜ , ùëÜ , . . .
0
1
and ùëá0.
"‚äá" Let ùë§ = ùëé ùëé . . .
0

1
‚àà ùêø(A). According to Thm. 9.8 there is a memoryless run
ùúå of A on ùë§. As observed above, ùúå can be represented as a DAG with each
level ùëÜ , ùëÜ , ùëÜ , . . .
0
1
2
forming a subset of ùëÑ. Clearly we have ùëÜ0 = {ùëûùêº }. Moreover, for all ùëñ ‚àà N
we have ùëÜ
ùõø
ùëñ+1 ‚äß ‚ãÄ
(ùëû, ùëé
ùëû‚ààùëÜ
ùëñ ).
ùëñ
Let ùëá0 ‚à∂= {ùëûùêº }. According to the remark above, this uniquely defines a run
‚Ä≤
‚Ä≤
ùúå
‚à∂= (ùëÜ , ùëá
, ùëá

0
0), (ùëÜ1
1), . . . of B on ùë§. It remains to be seen that ùúå
is accepting, i.e.
that ùëáùëñ = ‚àÖ for infinitely many ùëñ. We first observe that, for all ùëñ ‚â• 0 with ùëáùëñ
‚â† ‚àÖ we have rk ùëá
< rk ùëá because ùëáùëñ cannot contain accepting states. Moreover, we have ùëñ+1
ùëñ
rk ùëá
> rk ùëá only if ùëáùëñ = ‚àÖ. According to Lemma 9.6, the ranks of all ùëÜùëñ are
finite, ùëñ+1
ùëñ
and then so are the ranks of all ùëáùëñ, respectively the maxima of the ranks of
all the nodes in each of the ùëáùëñ. But then there must be infinitely many ùëñ such
that ùëáùëñ = ‚àÖ
‚Ä≤
‚Ä≤
which means that ùúå visits accepting states from ùêπ infinitely often and is
therefore accepting. Thus, ùë§ ‚àà ùêø (B).
"‚äÜ" Suppose that ùúå = (ùëÜ , ùëá
, ùëá
0

0), (ùëÜ1
1), . . . is an accepting run of B on ùë§ =
‚Ä≤
ùëé
ùëé
. . .
0
1
‚àà Œ£ ùúî . It is easy to construct a memoryless run ùúå of A on ùë§ by using ùëÜ , ùëÜ , . .
.
0
1
as its levels and connecting each node on level ùëñ to the corresponding nodes
on level ùëñ + 1 that form a model of the transition function at that node and
the corresponding input letter.
‚Ä≤
Again, it remains to be seen that ùúå is accepting, i.e. that every branch
through this memoryless run visits accepting states infinitely often. We do
this by contradiction.
‚Ä≤
‚Ä≤
Suppose there was a branch ùë£ , ùë£ , . . .

0
1
in ùúå such that ùúå (ùë£ùëñ) /
‚àà ùêπ for all but finitely
‚Ä≤
many ùëñ. Hence, there is a maximal ùëõ such that ùúå (ùë£) /
‚àà ùêπ for all ùëñ > ùëõ. On the other
hand, since ùúå is supposed to be accepting, there are infinitely many ùëñ such
that ùëáùëñ = ‚àÖ.
Take the least such ùëñ with ùëñ > ùëõ. Since ùë£ùëñ ‚àà ùëÜùëñ and ùë£ùëñ+1 ‚àà ùëÜùë£ ‚àñ ùêπ we have
ùë£ùëñ
ùëñ
+1 ‚àà ùëáùëñ+1.
This argument can now be iterated ad infinitum: since ùë£ùëñ+1 is a successor
of ùë£ùëñ, it is part of the corresponding ùëÜùë£ , so if ùë£ùëñ ‚àà ùëáùëñ then ùë£ùëñ
ùëñ
+1 ‚àà ùëáùëñ+1. But this contradicts the
assumption that eventually ùëáùëó = ‚àÖ for some ùëó > ùëñ again.
‚óª
9.3 Expressiveness
225

Example 9.18
ùúî
Take the ABA from Fig. 9.3 that recognises {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëé =
‚àû}. Applying the construction of Thm. 9.17 to it results in the NBA shown in
Fig. 9.6.
It is clearly not of optimal size. The rightmost two states form the typical
structure of an NBA for this language, especially when the ùëé-loop in the
non-accepting state on the right is removed. This transition does not add
anything to the recognised language since it is always more beneficial to
take the ùëé-transition into the accepting state to the left.
The initial state and its right neighbour can also clearly be removed, since
they ùúî
are only useful for recognising the special word ùëé
(which is also recognised by the
third state) and any prefix containing at least one ùëè, which would also be
taken care of by the third or fourth state from the left.
9.3.2 Universal and Deterministic Automata
It is worth noting that the cause for nondeterminism in the NBA resulting
from an ABA is the possibility of Boolean formulas to have several different
models, even minimal ones. This is only the case when these formulas
contain disjunctions. We make this formal, and in the same step also
consider alternating automata with the co-B √ºchi acceptance condition.
Definition 9.19 An alternating co-B√ºchi automaton (AcoBA) is defined
syntactically like an ABA, and runs on ùúî-words are also trees defined in the

same way, but they are accepting when each branch eventually traverses
through accepting states only.
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an ABA, resp. AcoBA such that ùõø(ùëû, ùëé) is a disjunction
of elements of ùëÑ. We regard this as a nondeterministic automaton (NBA /
NcoBA). If ùõø(ùëû, ùëé) consists of a pure conjunction of states in ùëÑ, then A is
said to be a universal automaton (UBA / UcoBA).
A closer inspection of the construction in Thm. 9.17 yields the following,
based on the observation that minimal models of purely conjunctive
formulas are unique.
OceanofPDF.com

The proof is left as an easy execise.
Lemma 9.20
+
Let ùëì ‚àà B (ùëÑ) be of the form ‚ãÄ
ùëû
ùëû‚ààùëÄ
for some ùëÄ ‚äÜ ùëÑ . Then ùëÄ ‚äß ùëÑ
and for every ùëÅ ‚äÜ ùëÑ with ùëÅ ‚äß ùëÑ we have ùëÄ ‚äÜ ùëÅ .
This means that ABA which happen to be universal get turned into
deterministic B √ºchi automata.
Corollary 9.21
ùëõ
For every UBA A of size ùëõ there is a DBA B of size at most 3 such that ùêø(B)
= ùêø(A) .
Next we want to show that alternating B √ºchi automata are easily
complemented into alternating co-B √ºchi automata by a simple dualisation
construction.
226
9 Alternating B √ºchi Automata
Definition 9.22
+

Let ùëÑ be a finite set and ùëì ‚àà B (ùëÑ). The dual formula to ùëì is ùëì , defined
inductively by
ùëû
‚à∂= ùëû ,
ùëì
,
ùëì
.
1 ‚àß ùëì2
‚à∂=
ùëì1 ‚à® ùëì2
1 ‚à® ùëì2
‚à∂=
ùëì1 ‚àß ùëì2
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an ABA, resp. AcoBA. The dual automaton to A is the AcoBA, resp.
ABA A ‚à∂= (ùëÑ, Œ£, ùëû , ùõø, ùëÑ
ùêº
‚àñ ùêπ ) where ùõø(ùëû, ùëé) ‚à∂= ùõø(ùëû, ùëé) for any ùëû ‚àà ùëÑ
and ùëé ‚àà Œ£.

Now we can make use of the fact that the acceptance games for ABA were
defined such that moves closely follow the structure of the Boolean
formulas. The duality between B √ºchi and co-B √ºchi automata lifts to the
duality between B √ºchi and co-B √ºchi acceptance games. A formal proof of
the following statement is omitted as it is fairly easy to see by unravelling
the definitions of dual games and dual automata.
Lemma 9.23 Let A be an ABA, resp. AcoBA. Then G
= G
A, ùë§
A, ùë§ .
Strictly speaking, the two games are not equal but winner-equivalent. There
is a slight subtlety arising from the fact that the acceptance game contains
deterministic moves which we arbitrarily assigned to player 0, and in the
dualisation construction for games, they become moves assigned to player
1. To obtain equality between G
and G
A, ùë§
A, ùë§ one would have to reassign these moves back to player 0. Since these
moves are deterministic, and the owner of these nodes is irrelevant to any
interesting question about such games, we simply keep the lemma's
statement as it is.
Lemma 9.23 can then be used to prove correctness of the complementation
construction on automata.
Theorem 9.24 For every ABA / NBA / NcoBA A of size ùëõ over alphabet Œ£
there is an AcoBA / UcoBA / UBA A of size at most ùëõ such that ùêø(A) = Œ£ ùúî
‚àñ ùêø(A) , and vice-ver sa.

Proof The construction of A from an ABA, resp. AcoBA A as the dual
automaton has been given above. It is not hard to see that it yields a UcoBA
from an NBA etc. Also, the claim on the size is immediately verified. It
remains to be seen that ùë§ ‚àà ùêø(A) iff ùë§ /
‚àà ùêø(A) for an arbitrary ùë§ ‚àà Œ£ ùúî . This is a consequence of previous results
as f ollows.
Thm. 9.16
Thm. 9.13
ùë§ ‚àà ùêø(A)
‚áê‚áí
player 0 wins G
‚áê‚áí
player 1 wins G
A, ùë§
A, ùë§
Lem. 9.23
‚áê‚áí
player 1 wins GA,ùë§
Thm. 9.11
Thm. 9.16
‚áê‚áí
player 0 does not win GA,ùë§

‚áê‚áí
ùë§ /
‚àà ùêø(A)
For the cases of A not being a general ABA or AcoBA, one only needs to
check that that corresponding dualisations specialise accordingly.
‚óª
One can observe that the Miyano-Hayashi construction, originally used to
transform an ABA into an NBA, can be used to transform an NcoBA into a
DcoBA.
This is not too surprising. Determinisation in this case means checking that
amongst
9.4 Complementation via Alternating Automata
227
ùëè
0
‚àß
1
‚à®
2
ùëé
ùëé
ùëé , ùëè

‚à®
‚à®
ùëè
‚à®
ùëé , ùëè
‚Ä≤
ùëè
ùëé
‚Ä≤
0
‚àß
2
ùëé , ùëè
Fig. 9.7 Result of an attempt to turn an AcoBA into an ABA by extending
the corresponding translation from NcoBA to NBA.
all runs of the NcoBA there is an accepting one, i.e. one that eventually
traverses accepting states only. This is exactly what is done in the
alternation-elimination procedure for ABA with the only difference that the
mechanism involving a second set of microstates is used to check for the
non-existence of a path eventually containing non-accepting states only.
The following theorem even shows that determinisation of co-B √ºchi
automata is a by-product of the developments so far.
Theorem 9.25

ùëõ+
For every NcoBA A of size ùëõ there is a DcoBA B of size at most 3
1
such that ùêø(B) = ùêø(A) .
Proof Take an NcoBA of size ùëõ. According to Thm. 9.24, it can be
complemented into a UBA of size at most ùëõ + 1. According to Cor. 9.21 this
can be determinised ùëõ+
directly into a DBA of size at most 3
1. But this can be complemented again into a
DcoBA of the same size recognising the language of the original NcoBA,
according to Thm. 6.32.
‚óª
9.4 Complementation via Alternating Automata
We revisit the problem of constructing, given an NBA for some language ùêø,
an NBA for its complement ùêø. Alternation may promise to be helpful for
this, given that alternating automata offer an easy complementation
mechanism via dualisation.
Unfortunately, unlike the case of automata on finite words, such
constructions are only very simple when the acceptance condition is
allowed to be dualised as well.
This is why Thm. 9.24 turns an ABA into an AcoBA and vice-versa. If there
was a way to mimic, say, a co-B √ºchi condition by a B √ºchi condition in an
alternating automaton, then this could open up the way for an alternative
complementation construction for B √ºchi automata. We first remark that the
simple construction of Thm. 6.34 that turns an NcoBA into an NBA by

guessing the moment after which no more non-accepting states are being
seen, cannot be used for alternating automata.
Example 9.26 Take the ABA A from Ex. 9.4 that is shown in Fig. 9.3 and
simply
‚àó
ùúî
regard it as an AcoBA. The language it recognises also happens to be (ùëè ùëé)
as
well, the same as its language regarded as an ABA.
228
9 Alternating B √ºchi Automata
If we were to attempt to transform it into an ABA using the same trick as for
‚Ä≤
nondeterministic automata, we would add a copy ùëû for every accepting
state ùëû, and give each original state the possibility to transition into those
new copies. It is not immediately clear what this means in the context of an
alternating automaton. The most sensible interpretation seems to be that
every state ùëù in the Boolean formula
‚Ä≤
ùõø(ùëû, ùëé) for any ùëû, ùëé is replaced by the disjunction between ùëù and the new copy
ùëù , if ùëù was accepting. Otherwise it simply remains to be ùëù.
‚Ä≤
The transitions for the new copy states ùëû are inherited from their origins ùëû.

However, only transitions into new states should be possible. This means
that any ùëù
‚Ä≤
‚Ä≤
‚Ä≤
in ùõø(ùëû , ùëé) for a new copy ùëû should be replaced by ùëù if ùëù was accepting, or by
false otherwise. We can mimic this Boolean value by one additional state
that accepts nothing. Executing this construction on B would result in the
ABA shown in Fig. 9.7.
‚àó
ùúî
ùúî
It does not accept (ùëè ùëé) . Specifically, consider the word (ùëéùëè)
that should be
accepted. In state 0 and upon reading ùëé it can choose to loop back to state
0 or to go
‚Ä≤
over into 0 . The latter is problematic because afterwards, it can only
successfully ùúî
ùúî
read ùëé
as any ùëè would take it into state . Thus, on (ùëéùëè)
it can never move into

‚Ä≤
0 . But it cannot always loop back to 0 either because this would clearly
create a path in a run that visits state 0 only and is therefore not accepting.
Instead, a more elaborate construction is needed. One of the key pieces here
is the fact that runs of alternating co-B √ºchi automata can also be assumed
to be memory-less. The proof is left as an exercise.
Lemma 9.27 Let A be an AcoBA and ùë§ ‚àà ùêø(A) . Then there is a
memoryless run of A on ùë§ .
In order to transform an AcoBA into an ABA we now equip memoryless
runs with additional information so that the co-B √ºchi acceptance condition
in the original run can be formulated as a B √ºchi acceptance condition in
the extended run. An ABA can then guess and verify that additional
information. It is given here in terms of a ranking of nodes in a run of an
AcoBA, and this is not the same as the ranking used for runs of ABA in Def.
9.5.
Definition 9.28 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an AcoBA of size ùëõ, ùë§ ‚àà Œ£ ùúî and ùúå be a
memoryless run of A on ùë§. Let ùëâ be the set of nodes underlying ùúå .
A ranking of ùúå is a function ‚Ñì ‚à∂ ùëâ ‚Üí {1, . . . , 2ùëõ}, satisfying the following for
all
‚Ä≤
ùë£ , ùë£
‚àà ùëâ , ùëû ‚àà ùëÑ .
‚Ä≤

‚Ä≤
(i) If ùë£ is a successor of ùë£ then ‚Ñì(ùë£ ) ‚â§ ‚Ñì(ùë£).
(ii) If ùúå(ùë£) = ùëû and ‚Ñì(ùë£) is odd then ùëû ‚àà ùêπ .
(iii) Every (necessarily infinite) path in ùúå contains infinitely many nodes ùë£
such that ‚Ñì(ùë£) is odd.
Rankings are witnesses of acceptance.
Theorem 9.29 If there is a ranking for a memoryless run ùúå of an AcoBA then
ùúå is accepting.
9.4 Complementation via Alternating Automata
229
Proof Let ùúå be a memoryless run and ‚Ñì be a ranking on it. Take an infinite
branch ùë£
, ùë£
, . . .
0
1
of ùúå. Condition (i) in the definition of a ranking states that ‚Ñì(ùë£0) ‚â• ‚Ñì(ùë£1) ‚â•
. . . Since ranking values are finite, there is some ùëõ ‚â• 0 and some ùëò such
that ‚Ñì(ùë£ùëñ ) = ùëò
for all ùëñ ‚â• ùëõ. According to condition (iii), ùëò must be odd because it is the
only value that occurs infinitely often on this branch. Because of condition
(ii), we have that ùúå(ùë£ùëñ ) is an accepting state for all ùëñ ‚â• ùëõ. Hence, this
branch, and therefore any branch, satisfies the co-B √ºchi condition.

‚óª
The converse holds as well but requires a bit more work. Fix an AcoBA A =
(ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) of size ùëõ and an accepting run ùúå of it on some word ùë§ ‚àà Œ£ ùúî . Let ùëâ
be the set of all nodes in ùúå .
‚Ä≤
‚Ä≤
‚àó
‚Ä≤
‚Ä≤
‚Ä≤
For two nodes ùë£, ùë£ ‚àà ùëâ we write ùë£ ‚Üí
ùë£
if ùë£ is a descendant of ùë£, i.e. ùë£ is
‚àó
located in the subtree of ùúå rooted at ùë£. Note that ùë£ ‚Üí ùë£ in particular for any
ùë£. We
‚Ä≤
‚Ä≤

write ùë£ ‚Üí ùë£ if ùë£ is a successor of ùë£ .
We inductively construct sets of nodes ùëÜ0 ‚äÜ ùëÜ1 ‚äÜ ùëÜ2 ‚äÜ . . . in a run ùúå as
follows.
Let ùëÜ0 ‚à∂= ‚àÖ and, for all ùëñ ‚â• 0:
‚Ä≤
‚àó
‚Ä≤
‚Ä≤
‚Ä≤
ùëÜ
ùë£
2ùëñ+1
‚à∂= {ùë£ ‚à£ for all ùë£ s.t. ùë£ ‚Üí
‚à∂ ùë£
‚àà ùëÜ2ùëñ or ùúå(ùë£ ) ‚àà ùêπ}
‚Ä≤
‚àó
‚Ä≤
‚Ä≤
‚Ä≤

ùëÜ
ùë£
2ùëñ+2
‚à∂= {ùë£ ‚à£ for all but finitely many ùë£ s.t. ùë£ ‚Üí
‚à∂ ùë£
‚àà ùëÜ2ùëñ or ùúå(ùë£ ) ‚àà ùêπ}
The following properties about these sets are easy to verify.
Lemma 9.30
‚Ä≤
For all ùëñ ‚â• 0 and nodes ùë£, ùë£ of an AcoBA run with associated sets ùëÜ , ùëÜ , . .
.
0
1
we hav e
a) ùëÜ2ùëñ ‚äÜ ùëÜ2ùëñ+1 ‚äÜ ùëÜ2ùëñ+2 .
‚àó
‚Ä≤
‚Ä≤
b) If ùë£ ‚Üí ùë£ and ùë£ ‚àà ùëÜùëñ then ùë£ ‚àà ùëÜ ùëñ .
Lemma 9.31 Let ùëâ be the set of all nodes of an accepting run ùúå of some
AcoBA, and ùëÜ , ùëÜ , . . .

0
1
be as constructed above. Let ùëñ > 0 such that ‚à£ùëâ ‚àñ ùëÜ2ùëñ‚à£ = ‚àû . Then ùëÜ2ùëñ+2 ‚äã
ùëÜ2 ùëñ .
Proof We have ùëÜ2ùëñ+2 ‚äá ùëÜ2ùëñ by Lemma 9.30 (a). Hence, all that remains to
be seen is that ùëÜ2ùëñ+2 ‚àñ ùëÜ2ùëñ ‚â† ‚àÖ.
Suppose this was not the case, i.e. ùëÜ2ùëñ+2 = ùëÜ2ùëñ. Then every node in ùëâ ‚àñ
ùëÜ2ùëñ would have infinitely many descendants that are not labelled with
accepting states and do not belong to ùëâ ‚àñ ùëÜ2ùëñ themselves. This allows us to
construct an infinite path violating the co-B √ºchi condition. We begin with
an arbitrary node ùë£0 ‚àà ùëâ ‚àñ ùëÜ2ùëñ. It must have some descendant ùë£1 ‚àà ùëâ ‚àñ
ùëÜ2ùëñ that is not labelled with an accepting state. This can be
‚àó
‚àó
continued to form a sequence ùë£ , ùë£ , . . .
ùë£
. . .
0
1
with ùë£0 ‚Üí
1 ‚Üí
, i.e. an infinite path

on which infinitely many non-accepting states occur, contradicting the
assumption that ùúå is accepting.
‚óª
Lemma 9.32 Let ùëÜ , ùëÜ , . . .
0
1
be as constructed above for some memory-less run ùúå of
an AcoBA with ùëõ states. Let 0 ‚â§ ùëñ ‚â§ ùëõ . There is an ùëöùëñ such that for every
ùëö ‚â• ùëöùëñ , the ùëö -th level of ùúå contains at most ùëõ ‚àí ùëñ nodes not belonging to
ùëÜ2ùëñ .
230
9 Alternating B √ºchi Automata
Proof We show this by induction on ùëñ. We assume that the run is given as a
DAG.
Then the claim is trivially true for ùëñ = 0 because the maximal width of a
memory-less run in a minimal DAG representation is ùëõ. We have ùëÜ0 = ‚àÖ,
so every node does not belong to ùëÜ0 but there are only ùëõ nodes, hence, at
most ùëõ ‚àí 0 = ùëõ many nodes do not belong to ùëÜ0 for every lev el.
So suppose the statement is true for some ùëñ < ùëõ. We show that it is also true
for ùëñ + 1. We distinguish two cases. Let ùëâ denote the set of all nodes in the
run ùúå .
Case 1, ‚à£ùëâ ‚àñ ùëÜ2ùëñ‚à£ < ‚àû. Then we immediately get ùëÜ2ùëñ+2 = ùëâ for the
following reason. If there are only finitely many nodes not belonging to ùëÜ2ùëñ
then the root node belongs to ùëÜ2ùëñ+2. According to Lemma 9.30 (b), every
node belongs to ùëÜ2ùëñ+2. Hence, every level contains 0 nodes not belonging

to ùëÜ2ùëñ+2, and therefore at most ùëõ ‚àí (ùëñ + 1) nodes. Thus, ùëöùëñ+1 ‚à∂= 0 proves
the claim in this case.
Case 2, ‚à£ùëâ ‚àñ ùëÜ2ùëñ‚à£ = ‚àû. According to Lemma 9.31 (a) we have ùëÜ2ùëñ+2 ‚äã
ùëÜ2ùëñ. Take some ùë£0 ‚àà ùëÜ2ùëñ+2 ‚àñ ùëÜ2ùëñ. We argue that there is a path through ùúå,
starting in ùë£0 such that all its nodes belong to ùëÜ2ùëñ+2 ‚àñ ùëÜ2ùëñ. For this it
suffices to show that every node
‚Ä≤
‚Ä≤‚Ä≤
ùë£
‚àà ùëÜ2ùëñ+2 ‚àñ ùëÜ2ùëñ must have some successor ùë£
that also belongs to ùëÜ2ùëñ+2 ‚àñ ùëÜ2ùëñ. Note
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
that ùë£
‚àà ùëÜ2ùëñ+2 holds even for all successors ùë£
of a node ùë£ ‚àà ùëÜ2ùëñ+2, according to
‚Ä≤
Lemma 9.30 (b). So suppose that all successors of ùë£ belonged to ùëÜ2ùëñ. Then,
again with Lemma 9.30 (b), all descendants belonged to ùëÜ2ùëñ as well, and so
all but finitely
‚Ä≤
‚Ä≤

many descendants of ùë£ would belong to ùëÜ2ùëñ and so would ùë£ as well.
Thus, there are nodes ùë£ , ùë£ , . . .
0
1
that form a path ùë£0 ‚Üí ùë£1 ‚Üí . . . with ùë£ ùëó ‚àà ùëÜ2ùëñ+2‚àñùëÜ2ùëñ
for all ùëó ‚â• 0. Then let ùëöùëñ+1 ‚à∂= max{‚Ñì, ùëöùëñ} where ‚Ñì is the level of node ùë£0.
By the induction hypothesis, all levels below ùëöùëñ contain at most ùëõ ‚àí ùëñ
nodes not belonging to ùëÜ2ùëñ. Moreover, there is a path starting on level
ùëöùëñ+1 or above that contains nodes in ùëÜ2ùëñ+2 ‚àñ ùëÜ2ùëñ. Hence, every level ùëö
‚â• ùëöùëñ+1 contains at most ùëõ ‚àí ùëñ ‚àí 1 = ùëõ ‚àí (ùëñ + 1) many nodes not
belonging to ùëÜ2ùëñ+2 = ùëÜ2(ùëñ+1).
‚óª
An immediate consequence of this is a bound on the length of the chain ùëÜ0
‚äÜ
ùëÜ1 ‚äÜ . . . ‚äÜ ùëÜ2ùëõ+2. From Lemma 9.32 for ùëñ = ùëõ we get some ùëöùëõ such
that all levels ùëö ‚â• ùëöùëõ contain at most ùëõ ‚àí ùëõ = 0 nodes not belonging to
ùëÜ2ùëõ. Hence, the entire DAG
contains only finitely many nodes not belonging to ùëÜ2ùëõ. Therefore, every
node must belongs to ùëÜ 2ùëõ+2.
With a little bit of further insight, we can get a slightly tighter bound.
Lemma 9.33 Let ùëÜ , ùëÜ , . . .
0
1
be as constructed above for some memoryless run ùúå of

an AcoBA A on some word ùë§ , and let ùëâ be the set of nodes in ùúå . Then ùëÜ2ùëõ
= ùëâ .
Proof With the reasoning above we already now that ùëÜ0 ‚äÜ . . . ‚äÜ ùëÜ2ùëõ ‚äÜ
ùëÜ2ùëõ+2 = ùëâ.
Also, if ùëÜ2ùëñ = ùëÜ2ùëñ+2 for some ùëñ then ùëÜ2ùëñ = ùëÜ2 ùëó for all ùëó ‚â• ùëñ. So suppose
that ùëÜ2ùëõ ‚â† ùëâ , i.e. ùëÜ2ùëõ+2 ‚àñ ùëÜ2ùëõ ‚â† ‚àÖ. Then w e must have
‚àÖ
= ùëÜ0 ‚ää ùëÜ2 ‚ää . . . ‚ää ùëÜ2ùëõ‚àí2 ‚ää ùëÜ2ùëõ ‚ää ùëÜ 2ùëõ+2 = ùëâ
which is only possible if, for all ùëñ = 1, . . . , ùëõ, there is some ùëöùëñ such that all
levels below ùëö contain exactly ùëõ ‚àí ùëñ nodes not belonging to ùëÜ2ùëñ. Now take
ùëñ = ùëõ ‚àí 1. All levels below ùëöùëñ‚àí1 contain exactly one node not belonging to
ùëÜ2ùëõ‚àí2. These necessarily form a path starting on level ùëöùëñ‚àí1. Since the
underlying run is accepting, this path
9.4 Complementation via Alternating Automata
231
3
0
3
0
3
2
0
1

3
2
2
0
1
1
3
1
1
0
2
2
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
Fig. 9.8 Run of an AcoBA with a ranking.
must satisfy the co-B √ºchi condition, i.e. it must eventually traverse through
accepting states only. But then it can contain only finitely many nodes not
belonging to ùëÜ2ùëõ‚àí2 or being labelled with an accepting state. Hence,
every node belongs to ùëÜ2ùëõ‚àí2+2 = ùëÜ2ùëõ

indeed.
‚óª
We are now in a position to prove the converse of Thm. 9.29.
Theorem 9.34 Let ùúå be a memoryless run of an AcoBA. If ùúå is accepting then
there is a ranking for ùúå .
Proof We construct the ranking ‚Ñì as follows. Let ùëâ be the set of nodes of ùúå.
For every ùë£ ‚àà ùëâ let ‚Ñì(ùë£) ‚à∂= min{ùëñ ‚à£ ùë£ ‚àà ùëÜ2ùëñ}. It remains to be seen that this
indeed defines a ranking. We check the three properties stated in Def. 9.28.
‚Ä≤
‚Ä≤
(i) Suppose ùë£ ‚Üí ùë£ . According to Lemma 9.30 (b) we have ùë£ ‚àà ùëÜ ùëó
whenever ùë£ ‚àà ùëÜ ùëó
‚Ä≤
for every ùëó ‚â• 0. Hence, ‚Ñì(ùë£ ) ‚â§ ‚Ñì (ùë£).
(ii) Suppose ‚Ñì(ùë£) is odd for some ùë£, i.e. ‚Ñì(ùë£) = 2ùëñ +1 for some ùëñ. Then all
descendants of ùë£ are labelled with accepting states or belong to ùëÜ2ùëñ. But
then ùúå(ùë£) must be an accepting state for otherwise we would have ‚Ñì (ùë£ ) ‚â§
2ùëñ.
(iii) Suppose that ùë£ , ùë£ , ùë£ , . . .
0
1
2
is an infinite path through ùúå. We need to show that

the sequence ‚Ñì(ùë£0), ‚Ñì(ùë£1), . . . contains infinitely many odd numbers. So
suppose that ‚Ñì(ùë£ ùëó ) was even for some ùëó ‚â• 0, i.e. ‚Ñì(ùë£ ùëó ) = 2ùëñ + 2 for some ùëñ.
Then all but finitely many descendants of ùë£ ùëó are labelled with accepting
states or belong to ùëÜ2ùëñ. Thus, there must be some ùëò ‚â• ùëó such that all
descendants of ùë£ùëò have this property. But then ‚Ñì(ùë£ùëò ) ‚â§ 2ùëñ + 1. Hence, each
even number in the sequence ‚Ñì(ùë£0), ‚Ñì(ùë£1), . . . must be followed by one that
is strictly smaller. So this sequence must contain infinitely many odd
numbers.
‚óª
232
9 Alternating B √ºchi Automata
Example 9.35 Reconsider the ABA A from Ex. 9.3, recognising the
language
‚àó
ùúî
(ùëè ùëé)
. We now regard it as an AcoBA. First we note that it accepts the same
language, and this is simply because every path in a run eventually cycles
through one of the three states 0, 1, 2, of which 0 and 2 are accepting. Thus,
such a path contains infinitely many accepting states iff it contains at most
finitely many non-accepting states.
Fig. 9.8 shows how the run of A that is also shown in Fig. 9.2 can be given
a ranking with the numbers 3, 2, 1. Rankings that only use the numbers 1
and 2, or even just the number 1 do not exist for this run. The reason for
this is the existence of nodes that have infinitely many descendants that are
not labelled with accepting states. Nevertheless, every path contains finitely
many non-accepting states only, and so the run is accepting.
We can now use rankings to construct, given an AcoBA, an equivalent ABA.

Theorem 9.36 For every AcoBA A of size ùëõ there is an ABA B of size at
most 2ùëõ2 + 1
such that ùêø(B) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) be an AcoBA. We construct the ABA B ‚à∂=
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
(ùëÑ , Œ£, ùëû , ùõø , ùêπ ) with ùëÑ ‚à∂= {} ‚à™ ùëÑ √ó {1, . . . , 2ùëõ}, ùëû ‚à∂= (ùëû , 2ùëõ), ùêπ ‚à∂= {(ùëû,
ùëñ) ‚à£ ùëñ
ùêº
ùêº
ùêº
is odd } and
ùõø(, ùëé)
‚à∂=

‚éß
‚é™
‚é™
, if ùëû /
‚àà ùêπ and ùëñ is odd
ùõø((ùëû, ùëñ), ùëé)
‚à∂= ‚é®
‚é™
‚é™ùõø(ùëû, ùëé)‚à£
,
ùëñ
otherwise
‚é©
where (ùúë ‚à® ùúì)‚à£ùëñ = ùúë‚à£ùëñ ‚à® ùúì‚à£ùëñ, (ùúë ‚àß ùúì)‚à£ùëñ = ùúë‚à£ùëñ ‚àß ùúì‚à£ùëñ and ùëû‚à£ùëñ = ‚ãÅ
(ùëû, ùëó )
ùëó ‚â§ùëñ
.
Intuitively, B guesses a ranking in the form of an additional number for
every node in a memoryless run of A on some ùë§. The transition relation
ensures properties of a ranking, namely that the numbers cannot increase
along a path in a run, and that odd numbers are only assigned to nodes
with accepting states.

The bound on the size of B is obvious. Correctness of the construction
follows from Thm. 9.29, 9.34 and Lemma 9.33. The two former show that a
ranking exists iff the underlying run is accepting, and the latter shows that
the individual numbers in a ranking can be restricted to {1, . . . , 2ùëõ}. It is
then easy to read off a run of A and a ranking from a run of B and,
conversely, construct a run of B from a run of A and a corresponding
ranking.
‚óª
While Thm. 9.36 is interesting in itself because it shows how alternation
interacts with the B √ºchi and co-B √ºchi acceptance conditions, its most
important application is in complementation for B √ºchi automata.
2
Corollary 9.37
+
For every NBA A of size ùëõ there is an NBA A of size at most 32ùëõ
4ùëõ+3
such that ùêø(A) = Œ£ ùúî ‚àñ ùêø(A) .
Proof Take an NBA with ùëõ states. This can be viewed as an ABA of size at
most ùëõ + 1. One extra state may be needed in order to make the transition
function total,
9.5 Weak Automata
233
as it is required for ABA. According to Thm. 9.24 this can easily be
complemented into an AcoBA of size ùëõ + 1. Using the construction of Thm.
9.36 we can turn this into an equivalent ABA of size at most 2(ùëõ + 1)2 + 1

= 2ùëõ2 + 4ùëõ + 3. At last, we can turn this into an NBA of the prescribed size
using Thm. 9.17.
‚óª
The complementation construction underlying Cor. 9.37 with an upper
bound 2
O(ùëõ )
O(ùëõ
of 2
on the involved blowup is asymptotically worse than the 2
log ùëõ) that
can be achieved with determinisation constructions. However, it is
conceptually and combinatorially simpler, and it can be implemented
symbolically for instance.
9.5 Weak Automata
Ex. 9.26 and 9.35 considered ABA that can equally be seen as AcoBA
without changing the accepted language. This is due to a structural
property called weakness that we examine closer in this section. An
interesting observation that we will study in more detail later on, is that the
ABA resulting from the construction in Thm. 9.36
always have this property.
9.5.1 Weak B ¬®
uchi and co-B ¬®
uchi Automata
We begin by formalising weakness.

Definition 9.38 An ABA, resp. AcoBA A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) is called weak, ab-
breviated then as a WABA, resp. WAcoBA, if its state set can be partitioned
into ùëÑ = ùëÑ1 ‚à™ . . . ‚à™ ùëÑùëõ for some ùëõ ‚â• 1 such that
‚Ä¢ for all ùëñ = 1, . . . , ùëõ: ùëÑùëñ ‚äÜ ùêπ or ùëÑùëñ ‚à© ùêπ = ‚àÖ,
‚Ä¢
‚Ä≤
there is a partial order ‚â• on the set {ùëÑ , . . . , ùëÑ
1
ùëõ }
such that for any ùëû, ùëû ‚àà ùëÑ,
‚Ä≤
‚Ä≤
ùëé ‚àà Œ£ and ùëñ, ùëó ‚àà {1, . . . , ùëõ} with ùëû ‚àà ùëÑùëñ and ùëû ‚àà ùëÑ ùëó the following holds:
if ùëû
occurs in ùõø(ùëû, ùëé) then ùëÑùëñ ‚â• ùëÑ ùëó .
There is another characterisation of weakness that is slightly easier to use.
The proof of the following lemma is left as an exercise.
Lemma 9.39 An ABA, resp. AcoBA is weak iff there is a function Œ¶ ‚à∂ ùëÑ ‚Üí N
such
‚Ä≤

that for all ùëû, ùëû ‚àà ùëÑ :
‚Ä¢
‚Ä≤
‚Ä≤
if Œ¶(ùëû) = Œ¶(ùëû ) then ùëû ‚àà ùêπ iff ùëû ‚àà ùêπ ,
‚Ä¢
‚Ä≤
‚Ä≤
if ùëû occurs in ùõø(ùëû, ùëé) for some ùëé ‚àà Œ£ then Œ¶(ùëû ) ‚â§ Œ¶(ùëû ) .
One can regard the function Œ¶ as a symbolic representation of the partition
that is demanded in the definition of weakness.
With this slightly alternative characterisation at hand we remark that any
ABA B
that results from an arbitrary AcoBA A via the construction in Thm. 9.36 is
indeed
234
9 Alternating B √ºchi Automata
weak. It is not hard to verify that the function Œ¶, defined by Œ¶(ùëû, ùëñ) = ùëñ and
Œ¶() = 0, satisfies the requirements in Lemma 9.39. Also note that the ABA
from Ex. 9.3 and 9.4 are weak: take Œ¶(ùëû) = 2 ‚àí ùëû for their states ùëû ‚àà {0, 1,
2} for example.
Next we observe that weakness is a strong requirement that makes the B
√ºchi and co-B √ºchi conditions collapse to a single acceptance condition.

Lemma 9.40 Let ùúå be a run of a WABA or WAcoBA and ùúã = ùëû , ùëû , . . .
0
1
be an infinite
path in ùúå . Then there are infinitely many accepting states in ùúã iff there are
finitely many non-accepting states in ùúã only .
Proof Let Œ¶ witness the weakness of the underlying automaton. Since ùúã is a
path in a run, each ùëû
, ùëé
ùëñ+1 obviously occurs in ùõø(ùëûùëñ
) for some ùëé. Hence, we must have
Œ¶(ùëû0) ‚â• Œ¶(ùëû1) ‚â• . . .. Since the range of Œ¶ is finite, there must be some ùëö
‚â• 0 such that Œ¶(ùëûùëñ) = Œ¶(ùëûùëö) for all ùëñ ‚â• ùëö. Thus, either all ùëûùëñ for ùëñ ‚â• ùëö
are accepting, or all of them are not accepting. In either case, ùúã satisfies
both the B √ºchi and the co-B √ºchi condition, or it does not satisfy either of
them.
‚óª
It is because of this observation that we drop the explicit consideration of
co-B √ºchi automata in the following and simply speak about WABA only,
knowing that every WAcoBA is in fact just a WABA.
An interesting consequence of this collapse to a single automaton model is
obtained for complementation. Remember that alternating automata are
easy to complement for as long as one accepts the dualisation of the
acceptance condition. However, as we have just seen: in the context of weak
automata, the dual of a B √ºchi condition is again a B √ºchi condition, and so

we get the following result of complementation as an immediate
consequence of Thm. 9.24 and Lemma 9.40.
Corollary 9.41 For every WABA A of size ùëõ over alphabet Œ£ there is a
WABA A of size at most ùëõ such that ùêø(A) = Œ£ ùúî ‚àñ ùêø(A) .
A follow-up consequence of this is the perhaps surprising result that weak
alternating B √ºchi automata are no weaker than arbitrary alternating B
√ºchi automata in terms of expressiveness.
Theorem 9.42 For every ABA A of size ùëõ there is a WABA B of size at most
2ùëõ2 + 1
such that ùêø(B) = ùêø(A) .
Proof Start with an ABA A of size ùëõ and dualise it into an AcoBA of size ùëõ
that recognises Œ£ ùúî ‚àñ ùêø(A) according to Thm. 9.24. Then apply the
construction from Thm. 9.36 to obtain a WABA of size at most 2ùëõ2 + 1 for
this complemented language.
Then apply Cor. 9.41 to complement the language again, obtaining a WABA
for ùêø(A) of this size.
‚óª
One may therefore question the choice of the term weakness which may
suggest that the corresponding class of automata should perhaps recognise
less than all ùúî-regular languages. The point to note here is that syntactic
weakness as a structural property of the transition functions in finite
automata is recovered by the stronger branching mode in alternating
automata. One can apply the definition of weakness to purely
nondeterministic automata, resulting in models like WNBA. It turns out that
these are in fact weaker than NBA and thus do not recognise all ùúî-regular
languages.
9.5 Weak Automata
235

Theorem 9.43
ùúî
There is no WNBA that recognises {ùë§ ‚àà {ùëé, ùëè}
‚à£ ‚à£ùë§‚à£ùëé = ‚àû} .
Proof By contradiction. Suppose there was a WNBA A = (ùëÑ, {ùëé, ùëè}, ùëû , ùõø, ùêπ
ùêº
) with
its weakness witnessed by some function Œ¶. Clearly, ‚à£{Œ¶(ùëû) ‚à£ ùëû ‚àà ùëÑ}‚à£ ‚â§
‚à£ùëÑ‚à£, i.e.
ùëõ
ùúî
there can be at most ‚à£ùëÑ‚à£ many Œ¶-values. Let ùëõ ‚à∂= ‚à£ùëÑ‚à£, ùë§ ‚à∂= (ùëéùëè )
‚àà ùêø and let
ùúå = ùëû , ùëû , . . .
0
1
be an accepting run of A on ùë§. Note that Œ¶(ùëû0) ‚â• Œ¶(ùëû1) ‚â• . . . by
assumption. Hence, there must be some ùëö ‚â• 0 such that Œ¶(ùëûùëñ) = Œ¶(ùëûùëö)
for all ùëñ ‚â• ùëö.
Most of all, since states with equal Œ¶-values need to have the same
acceptance type, i.e. both being accepting or both being non-accepting, and
ùúå contains infinitely many accepting states, we must have ùëûùëñ ‚àà ùêπ for all ùëñ ‚â• ùëö.
Now, since ùëõ = ‚à£ùëÑ‚à£, there must be some ùëñ, ùëó with ùëñ ‚â§ ùëö < ùëó ‚â§ ùëñ + ùëõ such that ùëû

, . . . , ùëû
ùëó
= ùëûùëñ and the part ùëûùëñ
ùëó
of ùúå only
contains ùëè-transitions. Note that ùúå continuously contains parts with ùëõ
consecutive ùëè-transitions, and each such part contains ùëõ + 1 states. Since
ùëû , . . . , ùëû
ùëñ
ùëó are all accepting
and the last state in this sequence equals the first, we can construct an
accepting run ùúî
ùëõ
‚àó
ùúî
of the form ùëû , ùëû , . . . ,
, . . . , ùëû
ùëé ùëè
0
1
(ùëûùëñ

ùëó ‚àí1)
on a word of the form (ùëé ùëè )
which
should not be accepted.
‚óª
9.5.2 Weak Parity Automata
We extend the concept of weakness to automata accepting with a parity
condition. A natural way to interpret the informal requirement that two
states, which are given the same value by a function Œ¶ witnessing
weakness, should have the same acceptance type, is for those states to have
the same priority. Then weakness boils down to the requirement that
transitions only ever lead to states that do not have a higher priority than
the one just visited.
Definition 9.44 An alternating parity automaton (APA) is a A = (ùëÑ, Œ£, ùëû , ùõø,
Œ©
ùêº
) as
+
usual, in particular with ùõø ‚à∂ ùëÑ √ó Œ£ ‚Üí B (ùëÑ), and Œ© ‚à∂ ùëÑ ‚Üí N.
Runs of APA are trees just like they are for ABA. Such a run ùúå is accepting if
the parity condition Œ© holds on every path ùúã through ùúå, i.e. max{Œ©(ùëû) ‚à£ ùëû ‚àà
Inf (ùúã)} is even. The notions of language and size of an APA are defined as
usual, respectively derived from this.
Such an APA is weak or a WAPA, if there is a function Œ¶ ‚à∂ ùëÑ ‚Üí N such that
for

‚Ä≤
all ùëû, ùëû ‚àà ùëÑ :
‚Ä¢
‚Ä≤
‚Ä≤
if Œ¶(ùëû) = Œ¶(ùëû ) then Œ©(ùëû) = Œ©(ùëû ),
‚Ä¢
‚Ä≤
‚Ä≤
if ùëû occurs in ùõø(ùëû, ùëé) for some ùëé ‚àà Œ£ then Œ¶(ùëû ) ‚â§ Œ¶(ùëû ).
There is, again, a slightly different characterisation of weakness that may
make reasoning about WAPA a bit easier. It rephrases parity acceptance in
the context of a weak structure of the underlying automaton in terms of
simple reachability of high priorities, not repeated reachability.
Lemma 9.45 Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) be a WAPA. There is a function Œ©‚Ä≤ ‚à∂ ùëÑ ‚Üí N
such that a run ùúå of A on any ùë§ ‚àà Œ£ ùúî is accepting iff max{Œ©‚Ä≤(ùëûùëñ ) ‚à£ ùëñ ‚â• 0} is
even for every path ùëû , ùëû , . . .
0
1
in ùúå .

236
9 Alternating B √ºchi Automata
Proof Let A be given as above with function Œ¶ witnessing its weakness.
W.l.o.g.
we can assume that Œ¶(ùëû) is even iff Œ©(ùëû) is even, for any ùëû ‚àà ùëÑ. This can
easily be achieved by successively increasing Œ¶-values, if necessary,
simultaneously for states of Œ©-priorities 0 or more, then 1 or more, etc.
Now let ùëö be an even upper bound to {Œ¶(ùëû) ‚à£ ùëû ‚àà ùëÑ}, and define Œ©‚Ä≤ ‚à∂ ùëÑ ‚Üí
N
via Œ©‚Ä≤(ùëû) = ùëö ‚àí Œ¶(ùëû). Clearly, we have Œ©‚Ä≤(ùëû0) ‚â§ Œ©‚Ä≤(ùëû1) ‚â§ . . . for any path
ùúã = ùëû , ùëû , . . .
0
1
of any run ùúå because Œ¶(ùëû0) ‚â• Œ¶(ùëû1) ‚â• . . . Hence, if ùúå is accepting, and the
greatest Œ©-priority ùëù seen infinitely often on any path ùúã in it is even then
weakness demands that Œ©(ùëûùëñ) = ùëù for all but finitely many ùëñ. By the
definition of weakness, Œ¶(ùëûùëñ) is also even for those ùëûùëñ, and by the
assumption on Œ¶ and Œ©‚Ä≤ made above, the sequence of Œ©‚Ä≤-values of ùúã is (not
necessarily strictly) monotonically increasing and reaches ùëù, i.e. max{Œ©‚Ä≤
(ùëûùëñ) ‚à£ ùëñ ‚â• 0} is even for such a path ùúã.
‚óª
It is because of this lemma that we consider the acceptance condition in
WAPA as a reachability condition. In a sense, one can just use the auxiliary
function Œ©‚Ä≤ as the acceptance condition. So we can consider WAPA to be of
the form (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº

)
just like an arbitrary APA, but a run is accepting when the highest priority
on every path is even. Note that this is a semantic rather than syntactic
condition and in fact not exactly a restriction but a redefinition of how
acceptance is defined.
One may be inclined to think that acceptance by simple reachability is too
weak to capture all ùúî-regular languages. On the other hand, we have seen
examples of such
‚àó
ùúî
languages that rely on repeated reachability like (ùëè ùëé)
and can be recognised by a
WABA. Now, as just pointed out, weakness in WABA is defined structurally
whereas for WAPA it is defined semantically. On the other hand, there are
clear connections: every path of a run of an alternating automaton must
eventually get trapped in a strongly connected component (SCC) of the
transition graph, and weakness implies that no two states in an SCC
contribute differently to acceptance. So intuitively, acceptance in a WABA is
also a reachability question, namely the question of reaching (and not
leaving anymore) an SCC with accepting states. The WABA of Ex. 9.3 can
directly be turned into a WAPA for the same language by giving it the weak
parity acceptance condition Œ©(ùëûùëñ) ‚à∂= ùëñ .
We show that this correspondence does not only hold intuitively for chosen
examples, but that WABA and WAPA can be translated into one another by
means of relatively simple constructions. The proof of the following theorem
follows the same lines as the construction in the proof of Lemma 9.45
above. It is left as an exercise.
Theorem 9.46 For every WABA A of size ùëõ there is a WAPA B of size at
most ùëõ such that ùêø(B) = ùêø(A) .

The converse is slightly more involved as the estimation in the blowup in
size suggests.
Theorem 9.47 For every WAPA A of size ùëõ there is a WABA C of size at
most ùëõ2
such that ùêø(C) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) be a WAPA with ‚à£ùëÑ‚à£ = ùëõ. Clearly, ‚à£{Œ©(ùëû) ‚à£ ùëû ‚àà ùëÑ}‚à£ ‚â§
ùëõ. Since acceptance is not determined by the actual values in Œ© but rather
by their
9.5 Weak Automata
237
relation to one another w.r.t. '‚â§', and by their parity, we can always
eliminate gaps in the range of Œ© or uniformly reduce all values by an even
number so that we have Œ© ‚à∂ ùëÑ ‚Üí {0, . . . , ùëõ ‚àí 1} or Œ© ‚à∂ ùëÑ ‚Üí {1, . . . , ùëõ}.
Then let ùëÄ ‚à∂= {Œ©(ùëû) ‚à£ ùëû ‚àà ùëÑ} be the set of occurring prior ities.
In an intermediate step we construct another WAPA B ‚à∂= (ùëÑ √ó ùëÄ, Œ£, (ùëû , Œ©
ùêº
(ùëû ùêº )),
‚Ä≤
‚Ä≤
ùõø , Œ©‚Ä≤) via ùõø ((ùëû, ùëñ), ùëé) = ùõø(ùëû, ùëé)‚à£ùëñ where
ùëû‚à£

,
ùëñ
= (ùëû, max{ùëñ, Œ©(ùëû)}) ,
( ùëì ‚à® ùëî)‚à£ùëñ = ùëì ‚à£ùëñ ‚à® ùëî‚à£ùëñ
( ùëì ‚àß ùëî)‚à£ùëñ = ùëì ‚à£ùëñ ‚àß ùëî‚à£ùëñ
ùëû ‚àà ùëÑ ùëñ ‚àà ùëÄ
Œ©‚Ä≤(ùëû, ùëñ) ‚à∂= ùëñ
(ùëû, ùëñ) ‚àà ùëÑ √ó ùëÄ
for all
,
. Moreover,
for all
.
Thus, B runs a simulation of A and records, in the second components of its
states, the maximum of all the priorities seen so far. It should be clear with
the considerations above on the possibility to compress priorities that the
size of B is bounded by ùëõ2. We claim that it is equivalent to A, i.e. that ùêø(B)
= ùêø(A).
We only consider the "‚äÜ"-part. The "‚äá"-part is analogous. Suppose there
is an accepting run ùúå of B on a word ùë§ ‚àà Œ£‚àó. By projection onto the first
components
‚Ä≤

of each state pair, we obtain a run ùúå of A on ùë§. To see that it is also an
accepting
‚Ä≤
‚Ä≤
one, take an arbitrary path ùúã = ùëû , ùëû , . . .
0
1
in ùúå that results from the projection of a
path ùúã = (ùëû , ùëñ
, ùëñ
0
0), (ùëû1
1), . . . in ùúå. It should be clear that we have ùëñ0 ‚â§ ùëñ1 ‚â§ . . . and that the
maximal priority ùëö occurring in this sequence is even. Since ùëñ0 = Œ©(ùëûùêº )
and ùëñ
, Œ©
ùëó +1 = max{ùëñ ùëó
(ùëû ùëó )} for any ùëó ‚â• 0, there must indeed be some ùëó ‚â• 0 such that Œ©
‚Ä≤
(ùëû ùëó ) = ùëö and Œ©(ùëûùëò ) ‚â§ ùëö for all ùëò ‚â† ùëó . Thus, the maximal priority
occurring in ùúã
is even, and so ùúå is also accepting.

The last step that is required to prove the theorem's statement is to turn B
into
‚Ä≤
an equal-sized WABA C ‚à∂= (ùëÑ √ó ùëÄ, Œ£, (ùëû , Œ©
, ùêπ
ùêº
(ùëû ùêº )), ùõø
) where ùêπ = {(ùëû, ùëñ) ‚à£ ùëñ
is even}. Weakness is witnessed by the function Œ¶ with Œ¶(ùëû, ùëñ) ‚à∂= ùëö ‚àí ùëñ
where ùëö
is the maximal Œ©-priority occurring in A. It does indeed satisfy the
requirements for weakness: its values are never increasing along transitions
because priorities are never decreasing. Clearly, two states with the same
Œ¶-value either both belong to ùêπ
or both belong to (ùëÑ √ó ùëÄ) ‚àñ ùêπ.
‚óª
At last, we remark that an analogous semantical weakening of the
acceptance condition into a simple reachability condition fails for weak
alternating B √ºchi automata.
I.e. if weakness in alternating B √ºchi automata was defined via the
reachability of an accepting state, rather than the reachability of an
accepting SCC and the ability to remain within, then the resulting class of
languages recognised by such automata would be strictly included in the
class of ùúî-regular languages.
A concrete example of a language that cannot be recognised in this way is ùúî

‚àó
ùúî
ùúî
ùêø = ùëé
‚à™ ùëé ùëè
. It needs to have an accepting run ùúå on ùë§ = ùëé . This run cannot have finite
paths of unbounded length that do not contain accepting states. By K Àù
onig's
Lemma (Thm. 7.7), it would also contain an infinite path with no accepting
states contradicting the assumption that ùúå is accepting. Thus, there must be
some level ùëò
in ùúå such that every path contains an accepting state on a level that is at
most ùëò .
It should be clear that any word which shares the same prefix with ùë§ of
length ùëõ
will also be accepted because a run can be constructed by extending ùúå after
ùëõ levels ùëõ
ùúî
accordingly. In particular, ùëé ùëèùëé
would be accepted but does not belong to ùêø.
238
9 Alternating B √ºchi Automata
Bibliographic Notes

See also the bibliographic notes on alternating finite automata on finite
words in Chp. 3, including some notes on alternation as a general
computational concept.
The study of alternation in the context of finite automata on infinite objects
was started by Muller and Schupp [MS87] in the wider context of automata
operating on infinite trees. Part III of this book studies automata and logics
over such structures.
It should be clear, though, that infinite words are simply special trees of
branching degree 1. Hence, a theory of alternating automata on infinite
trees immediately specialises to one of alternating automata on infinite
words.
More to the point, though, alternating automata on infinite words with their
runs being trees, bear connections to nondeterministic automata on infinite
trees, and these yield the key to decision procedure for logics an trees.
Kupferman and Vardi studied this connection in detail [KV98].
The powerset-like translation of an ABA into an NBA is also known as the
breakpoint construction or, named after its inventors, the Miyano-Hayashi
construction
[MH84]. It was originally formulated for exactly such purposes, namely for
alternating automata. The fact that the same construction can be used to
determinise nondeterministic co-B √ºchi automata appears to be folklore.
ùëõ
For a long time, it was not known whether the bound of 3 in the blowup
incurring ùëõ
in the Miyano-Hayashi construction was optimal. A lower bound of Œ©(2 ) is
of course easily inherited from corresponding results about automata on
finite words.
ùëõ

Boker, Kupferman and Rosenberg eventually managed to show that 3
is indeed
optimal [BKR10]. They also studied the problem of alternation removal
further, in particular with the aim of identifying subclasses of alternating
automata for which alternation could be removed more easily.
Weakness in alternating automata was introduced and studied by Muller,
Saoudi and Schupp [MSS88]. The translation from ABA to WABA via
AcoBA presented here, showing that weak alternating automata are
expressively complete with respect to ùúî-regular languages, is due to
Kupferman and Vardi [KV01]. Likewise, the result showing that memoryless
runs suffice for ABA is also due to them.
A lot more work on alternating automata can be found in the literature in
the context of program verification. See the bibliographic notes of Chp. 10
for pointers to such work.
A topic that is not covered in this chapter, and in fact not in this book at all,
is that of minimising alternating automata. Because of their use in program
verification, especially due to the ability to directly translate logics into
alternating automata -
studied in some detail in Chp. 10 - much attention has been paid to this
problem in the literature, cf. work by Wilke and others [FW02, FW05,
EWS05] and Mayr and Clemente [CM10, MC13].
K Àù
onig's Lemma, that is mentioned in the last section, is a classical result in
combinatorics which first appeared in a paper by K Àù
onig [K Àù
on27], see also the
bibliographic notes for Chp. 7.

Exercises for Chapter 9
239
Exercises
Exercise 99 Prove Thm. 9.2. Hint: Consider the proof of Thm. 3.10.
Exercise 100
ùúî
Take the ABA B from Ex. 9.4 and the word ùë§ = (ùëèùëé) .
a) Construct an accepting run ùúå of B with levels ùëâ , ùëâ , . . .
0
1
such that there are
ùëñ0 < ùëñ1 < . . . so that, for ùëó ‚â• 0, level ùëâùëñ contains at least ùëó many nodes of the
ùëó
same label that are at the roots of mutuall y different subtrees.
‚àó
b) Construct the memoryless run ùúå
that is obtained from ùúå of part (a) using the
construction of Thm. 9.8.
Exercise 101 Define acceptance games for ABA in which the players make
their moves alternately by player 0 choosing models of Boolean formulas,
and player 1

subsequently picking a state in the model to continue with.
Exercise 102 Show that ABA are exponentially more succinct than NBA:
construct a family (ùêøùëõ)ùëõ‚â•0 of languages over some alphabet Œ£ such that
there is a function ùëì ‚à∂ N ‚Üí N and
‚Ä¢ each ùêøùëõ is recognised by some ABA of size O( ùëì (ùëõ)), and
‚Ä¢
Œ©( ùëì (ùëõ))
the smallest NBA recognising ùêøùëõ requires size 2
.
Hint: Extend the proof of a similar result for AFA/NFA to the case of infinite
words.
Exercise 103 Prove Lemma 9.20.
Exercise 104 Is every ùúî-regular language recognisable by a universal B√ºchi
automaton? Prove or refute. In the latter case, give an example of a
language that divides the two classes.
Exercise 105 Prove Lemma 9.27. Hint: This is simpler than the
corresponding construction for alternating B √ºchi automata, cf. Thm. 9.8. It
does not necessarily require a limit construction but can almost be done
inductively.
Exercise 106 Prove Lemma 9.30.
Exercise 107 Prove Lemma 9.39.
Exercise 108 Prove Thm. 9.46.

Chapter 10
Linear-Time Temporal Logic
In this chapter we study another logic interpreted over infinite words. It
differs from MSO fundamentally in that there are no quantifiers for sets of
positions and consequently no variables either. Instead it obtains
reasonable expressiveness through the use of temporal operators which is
also where the name temporal logic derives from.
In linear-time temporal logics, an (infinite) word is intuitively seen as a
sequence of temporally ordered events, represented by letters of the
underlying finite alphabet.
A formula is interpreted in a single position of such a word. Intuitively this
can be seen as the present moment. The suffix after that position forms the
temporal future, and the prefix before that position forms the past. Here we
consider a future-only temporal logic, i.e. its temporal operators can only
be used to make assertions about something happening in the future or the
present moment. Despite this fundamentally different structure, the simple
temporal logic LTL considered here is easily seen to be embeddable into
MSO, even into FO.
The intuition of a temporally ordered sequence of events is reminiscent of
how automata can be seen to read a word stepwise. We study direct
translations of temporal formulas into equivalent B √ºchi automata that are
more efficient than those obtained through the embedding of LTL into FO
and then MSO.
The main use and purpose of temporal logics like LTL is found in program
specification and verification where a program is abstractly seen as a

collection of possible executions or runs that can be regarded as infinite
words over some finite alphabet. One of the most fundamental problems
there is the so-called model checking problem: given a finite abstract
description of a program ùëÉ and a formula ùúë of LTL specifying desired
program behaviour, decide whether all executions of ùëÉ satisfy ùúë. We will see
how B √ºchi automata can be used to solve this problem algorithmically.
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
241
https://doi.org/10.1007/978-3-662-72154-4_10
242
10 Linear-Time Temporal Logic
10.1 Syntax and Semantics
10.1.1 Alphabets of Atomic Propositions
We recall the translation of MSO formulas into NFA in Chapter 2. A
normalised MSO formula ùúë(ùëã , . . . , ùëã
1
ùëõ ) over alphabet Œ£ with no first-order and ùëõ free second-
ùëõ
order variables is being translated into an NFA Aùúë over the alphabet Œ£ √ó {0,
1} .
Hence, it operates on words over Œ£ with ùëõ additional tracks filled by
symbols 0 and 1.

Likewise, every position is equipped with a binary vector of length ùëõ,
encoding the information of which positions belong to the interpretation of
which second-order variable.
The considerations on finite automata in the previous chapters assumed
nothing of the underlying alphabet other than it being a finite set. This
clearly covers the case ùëõ
of alphabets of the form Œ£ √ó {0, 1} as well, and this is one of the reasons for
why the translation of MSO into finite automata, NFA or NBA, could be
done inductively.
Likewise, we should be able to make use of the developed automata theory
for ùëõ
alphabets of the form {0, 1} as well. Rather than seeing its elements as
vectors of the form (ùëè , . . . , ùëè
1
ùëõ )
encoding the interpretation of some second-order variables
{ùëã ,..., ùëã
ùëã , . . . , ùëã
1
ùëõ }
1
ùëõ
of a fixed order, one could equally use 2
as the underlying

alphabet, especially when it does not get changed in constructions (as it is
the case for modularly translating MSO formulas into NFA or NBA).
Moreover, for every finite alphabet Œ£ there is clearly some number ùëõ such
that ùëõ
‚à£Œ£‚à£ ‚â§ 2 , so that the elements of Œ£ can be encoded as subsets of {1, . . . , ùëõ}.
Thus, it should be possible to carry out the entire development of a theory
of finite automata over alphabets of that form as well. This is what we do
here for LTL, simply because it conforms to the way that LTL is
traditionally presented and also used in program verification. To allow for
even more flexibility, intuition and meaningfulness in writing program
specifications, we start with a finite set P = {ùëù, ùëû, . . .} of so-P
called atomic propositions from which we implicitly derive an alphabet 2 .
Thus, infinite words in this chapter are infinite sequences of sets of atomic
propositions, for instance {ùëù}, {ùëù, ùëû}, {ùëù, ùëû}, ‚àÖ, {ùëù}, . . .. Note that these
propositions are nothing but second-order variables. The only difference is
the fact that there is no quantification over these variables in LTL, and this
is why we use lowercase letters ùëù, ùëû, . . . that perhaps suggest a more static
interpretation than the one normally associated with quantifiable v
ariables.
Example 10.1 Let P = {g, y, r} modelling a green, a yellow and a red light.
Then P
ùúî
{ùë§ ‚àà (2 )
‚à£ ùë§(0) = {r} and ‚àÄùëñ ‚àà N ‚à∂ ùë§(ùëñ) ‚àà {{g}, {y}, {r}, {y, r}},
ùë§ (ùëñ) = {g} ‚áí ùë§(ùëñ + 1) ‚àà {{g}, {y}},
ùë§ (ùëñ) = {y} ‚áí ùë§(ùëñ + 1) ‚àà {{y}, {r}},
ùë§ (ùëñ) = {r} ‚áí ùë§(ùëñ + 1) ‚àà {{r}, {y, r}},

ùë§ (ùëñ) = {y, r} ‚áí ùë§(ùëñ + 1) = {g},
‚àÉ ùëó > ùëñ s.t. ùë§( ùëó ) ‚â† ùë§(ùëñ)}
10.1 Syntax and Semantics
243
{ùëû, ùëü}, {ùëü}
{ùëù}, {ùëù, ùëû, ùëü}
{ùëù, ùëû, ùëü}, {ùëù, ùëü}
0
1
‚àÖ, {ùëû, ùëü}
Fig. 10.1 NBA for the language defined in Ex. 10.2.
is the set of executions of a standard traffic light system in which the
yellow-red-phase only lasts for one time unit, the three other phases last for
an arbitrary non-zero and finite amount of time units and the traffic light
shows red at the beginning.
The fact that the derived alphabet is of exponential size in the number of
underlying propositions can be an inconvenience for constructing automata
with transition P
relations of type ùëÑ √ó 2
√ó ùëÑ for some state set ùëÑ.
Example 10.2 Let P = {ùëù, ùëû, ùëü} and consider the language of all words ùëé ùëé
. . .
0

1
‚àà
P
ùúî
(2 )
such that for all ùëñ ‚àà N we have ùëü ‚àà ùëéùëñ+1 iff ùëù ‚àà ùëéùëñ implies ùëû ‚àà ùëéùëñ+1. I.e.
at every moment ùëñ ‚â• 1, proposition ùëü signals whether ùëû at this moment has
correctly followed an occurrence of ùëù in the previous moment.
Fig. 10.1 shows an NBA for this language. It should be clear that it only
needs two states in order to remember whether ùëù occurred in the previous
moment or not.
The alphabet size is 8 leading to several transitions that share source and
target state.
We introduce a form of representation of automata, respectively their
transition relations, that is more suitable for such alphabets of sets of
atomic propositions. All it needs is to see that a propositional formula ùõº
over P represents a set of sets of atomic propositions, namely the set of all
its models, and this corresponds to a set of alphabet letters. Hence, we can
use propositional formulas to represent multiple transitions in such an
automaton.
Definition 10.3 Let P be a set of atomic proposition. A Boolean or
propositional formula over P is one that is built from elements of P using
Boolean connectives P
¬¨, ‚à®, ‚àß, ‚Üí, ‚Üî, . . . The satisfaction relation between an alphabet symbol ùëé
‚àà 2
and

such a formula ùëì , ùëé ‚äß ùëì , is defined in the usual way, i.e.
ùëé ‚äß ùëû
iff
ùëû ‚àà ùëé
ùëé ‚äß ¬¨ ùëì
iff
ùëé /
‚äß ùëì
ùëé ‚äß ùëì ‚à® ùëî
iff
ùëé ‚äß ùëì or ùëé ‚äß ùëî
ùëé ‚äß ùëì ‚àß ùëî
iff
ùëé ‚äß ùëì and ùëé ‚äß ùëî
ùëé ‚äß ùëì ‚Üí ùëî
iff
ùëé ‚äß ùëì implies ùëé ‚äß ùëî
ùëé ‚äß ùëì ‚Üî ùëî
iff
ùëé ‚äß ùëì iff ùëé ‚äß ùëî

etc. We write B(P ) for the set of Boolean formulas over P .
A symbolic NBA is an A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) just like an NBA but with ùõø being a
P
ùúî
finite subset of ùëÑ √ó B(P ) √ó ùëÑ. A run of A on a word ùëé ùëé . . .
0
1
‚àà (2 )
is a sequence
244
10 Linear-Time Temporal Logic
ùëû
, ùëû
, . . .
0
1
of states such that ùëû0 = ùëûùêº and for every ùëñ ‚àà N there is some ùëìùëñ ‚àà B(P) such
that (ùëû , ùëì , ùëû

ùëñ
ùëñ
ùëñ+1) ‚àà ùõø and ùëéùëñ ‚äß ùëìùëñ .
All other concepts like size, accepting run, recognised language, etc. are as
they are for ordinary NBA.
Note that being symbolic is a property that only affects the transition
relation of a finite automaton. It is not tied to NBA in particularly. We can
therefore assume that any kind of automaton can be represented
symbolically, regardless of their (state-based) acceptance condition.
Example 10.4 Reconsider the language defined in Ex. 10.2 with the NBA
show in Fig. 10.1. A symbolic NBA for the same language is the following.
¬¨ ùëù ‚àß ùëü
ùëù ‚àß (ùëû ‚Üî ùëü )
ùëù ‚àß (ùëû ‚Üí ùëü )
0
1
¬¨ ùëù ‚àß ùëû ‚àß ùëü
The use of propositional formulas enables a symbolic representation of the
labels on transitions with equal sources and targets. In this small example,
8 transitions collapse into 4. We leave it as an exercise to show that
symbolic NBA can have exponentially fewer transitions than those based on
explicit representations.
10.1.2 Formulas Built from Temporal Operators
We start by defining the syntax of the linear-time temporal logic LTL.

Definition 10.5 Let P be a set of propositions. Formulas of LTL over P are
given by the grammar
ùúë
‚à∂‚à∂= ùëù ‚à£ ùúë ‚à® ùúë ‚à£ ¬¨ùúë ‚à£ Xùúë ‚à£ ùúë U ùúë
where ùëù ‚àà P .
Besides the usual abbreviations of further Boolean operators, including tt
‚à∂=
ùëû ‚à® ¬¨ùëû for some ùëû ‚àà P and ff ‚à∂= ¬¨tt, we also use the following.
ùúë R ùúì ‚à∂= ¬¨(¬¨ùúë U ¬¨ùúì) ,
Fùúë ‚à∂= tt U ùúë ,
Gùúë ‚à∂= ¬¨F¬¨ùúë
We introduce the following convention about the precedence of operators:
unary ones bind stronger than binary ones, the temporal ones bind stronger
than Boolean ones, and the precedence between U and R needs to be made
explicit with parentheses.
The set Sub(ùúë) of subformulas of ùúë is inductively defined as follows.
Sub(ùëû) ‚à∂= {ùëû}
Sub(ùúë ‚à® ùúì) ‚à∂= {ùúë ‚à® ùúì} ‚à™ Sub(ùúë) ‚à™ Sub(ùúì)
Sub(¬¨ùúë) ‚à∂= {¬¨ùúë} ‚à™ Sub(ùúë)
Sub(ùúë U ùúì) ‚à∂= {ùúë U ùúì} ‚à™ Sub(ùúë) ‚à™ Sub(ùúì)
Sub(Xùúë) ‚à∂= {Xùúë} ‚à™ Sub(ùúë)
10.1 Syntax and Semantics

245
The size of ùúë is ‚à£ùúë‚à£ ‚à∂= ‚à£ Sub(ùúë)‚à£.
Note that the definition of the size of an LTL formula is a reasonable one.
It measures the space needed for a succinct representation that shares
common subformulas.
Example 10.6 Let ùúë0 ‚à∂= ùëû for some atomic proposition ùëû and ùúëùëõ+1 ‚à∂= X(ùúëùëõ
‚àß¬¨Xùúëùëõ).
Then ‚à£ùúëùëõ‚à£ = 1 + 4ùëõ, i.e. the size of formulas in the sequence (ùúëùëõ)ùëõ‚â•0 grows
linearly.
However, when writing them out fully, their string representations grow
exponentially because of the double occurrence of ùúëùëõ in ùúëùëõ+1, see for
instance ùúë3 which is ùúë
ùúë
2
2
¬≥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∑¬π
¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬µ
¬≥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∑¬π
¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬µ
X( X( X(ùëû ‚àß ¬¨Xùëû) ‚àß¬¨X X(ùëû ‚àß ¬¨Xùëû) ) ‚àß¬¨X X( X(ùëû ‚àß ¬¨Xùëû) ‚àß¬¨X X(ùëû ‚àß
¬¨Xùëû) ) ) .
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂

¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùúë
ùúë
ùúë
ùúë
1
1
1
1
The temporal operators U, X, R, F, G have particular meanings that are
being explained formally below. They are read as "until", "next",
"release", "finally" and
"generally", and these names already suggest what kind of temporal
connectives they represent in order to form statements about temporal
connections between occurrences of events in an infinite word.
Just as with MSO, which is in fact a family of logics, namely MSO over an
underlying alphabet Œ£, LTL is to be understood as LTL over a given set of
atomic propositions. Nevertheless, and as we did with MSO, we will simply
speak of LTL
and assume that the underlying set of atomic propositions P can be inferred
from the context. It is also not the case that the model-theoretic properties
of LTL heavily depend on P .
Formulas of LTL are interpreted over infinite words with an implicit
moment of reference.
Definition 10.7

P
Let P be given and Œ£ ‚à∂= 2 . The semantics of LTL is inductively
defined as follows. Let ùë§ = ùëé ùëé . . .
0
1
‚àà Œ£ ùúî and ùëñ ‚àà N.
ùë§ , ùëñ ‚äß ùëù
iff
ùëù ‚àà ùëéùëñ
ùë§ , ùëñ ‚äß ùúë ‚à® ùúì
iff
ùë§ , ùëñ ‚äß ùúë or ùë§, ùëñ ‚äß ùúì
ùë§ , ùëñ ‚äß ¬¨ùúë
iff
ùë§ , ùëñ /
‚äß ùúë
ùë§ , ùëñ ‚äß Xùúë
iff
ùë§ , ùëñ + 1 ‚äß ùúë
ùë§ , ùëñ ‚äß ùúë U ùúì

iff
there is ùëò ‚â• ùëñ, s.t. ùë§, ùëò ‚äß ùúì
and for all ùëó ‚à∂ ùëñ ‚â§ ùëó < ùëò implies ùë§ , ùëó ‚äß ùúë
Two LTL formulas ùúë and ùúì are equivalent, written ùúë ‚â° ùúì, if for all ùë§ ‚àà Œ£ ùúî and
all ùëñ ‚àà N we have ùë§, ùëñ ‚äß ùúë iff ùë§, ùëñ ‚äß ùúì.
The language of an LTL formula ùúë is ùêø(ùúë) ‚à∂= {ùë§ ‚àà Œ£ ùúî ‚à£ ùë§, 0 ‚äß ùúë}, thus
consisting of all words whose initial moment satisfies ùúë. We also write ùë§ ‚äß ùúë
as an abbreviation for ùë§, 0 ‚äß ùúë.
The semantics immediately explains why the operator X is read as "next"
or "at the next moment": an LTL formula ùúë holds in particular moments or
positions of
246
10 Linear-Time Temporal Logic
an infinite word, and the formula Xùúë holds at all those position that precede
one at which ùúë holds.
The formal semantics also suggests why the temporal operator U is read as
"until": let ùúë and ùúì be LTL formulas and consider the composed formula ùúë
U ùúì. It is true at a given position ùëñ iff there is some moment ùëò (later or the
same as ùëñ) at which ùúì holds, and all moments from ùëñ and up to ùëò need to
satisfy ùúë. Thus, ùúë U ùúì is true at those moments from which on ùúë holds until ùúì
holds eventually, as it is the case in the following picture for instance. We
depict an infinite word ùë§ = ùëé ùëé . . .
0
1
as an

infinite sequence of temporally ordered events, and write LTL formulas as
labels of a moment at which they are supposed to hold.
ùúë U ùúì
ùúë
ùúë
. . .
ùúë
ùúì
ùëé
ùëé
ùëé
ùëé
ùëé
0
1
. . .
ùëéùëñ
ùëñ+1
. . .
ùëé ùëò‚àí1

ùëò
ùëò +1
. . .
Note that ùëò = ùëñ is possible, and that the moment ùëò at which ùúì holds, must
indeed exist. I.e. the fact that ùúë holds for all ùëó ‚â• ùëñ is not sufficient to conclude
that ùúë U ùúì
holds at moment ùëñ .
Remember that Fùúì is just an abbreviation for tt U ùúì, i.e. a finally-formula is
just a special case of an until-formula. Since the left argument tt trivially
holds in any position of any word, all that Fùúì demands of a moment ùëñ is
therefore that there is some moment ùëò ‚â• ùëñ at which its argument ùúì holds, in
other words that ùúì holds finally or eventually, shown as follow s.
Fùúì
ùúì
ùëé
ùëé
ùëé
ùëé
ùëé
0
1
. . .
ùëéùëñ

ùëñ+1
. . .
ùëé ùëò‚àí1
ùëò
ùëò +1
. . .
Again, we can have ùëò = ùëñ. Thus, ùúì ‚Üí Fùúì is a tautology in LTL for example,
and so is ùúì ‚Üí ùúë U ùúì .
The operator G is dual to F in the sense of the abbreviation Gùúì = ¬¨F¬¨ùúì.
Thus, Gùúì
holds if it is not the case that some point in the future or present moment
does not satisfy ùúì, in other words if ùúì is satisfied henceforth or generally
from the current point in time.
Gùúì
ùúì
ùúì
ùúì
. . .
ùëé
ùëé
ùëé
ùëé

0
1
. . .
ùëéùëñ
ùëñ+1
ùëñ+2
. . .
In the same sense R is dual to U. Remember that ùúë R ùúì = ¬¨(¬¨ùúë U ¬¨ùúì). It is a
bit more difficult to depict, though, since there are two ways that a formula
of the form
¬¨ùúë U ¬¨ùúì can be unfulfilled. First, it could be that ¬¨ùúì never holds, i.e. all
moments into the future satisfy ùúì. Second, it could be the case that ¬¨ùúì holds
at some point in the future but it is not the case that ¬¨ùúë holds continuously
up to the first such
10.1 Syntax and Semantics
247
moment. Hence, we get the following two situations depicting typical cases
in which ùúë R ùúì holds. In the first one, ùúì holds generally.
ùúë R ùúì
ùúì
ùúì
ùúì
. . .

ùëé
ùëé
ùëé
ùëé
0
1
. . .
ùëéùëñ
ùëñ+1
ùëñ+2
. . .
In the second situation, ùúë has released the necessity of ùúì to hold
continuously.
ùúë R ùúì
ùúì
ùúì
. . .
ùúì
ùúì , ùúë
ùëé

ùëé
ùëé
ùëé
ùëé
0
1
. . .
ùëéùëñ
ùëñ+1
. . .
ùëé ùëò‚àí1
ùëò
ùëò +1
. . .
Example 10.8 It is possible to express "ùëû holds infinitely often" in LTL as
GFùëû. It literally says that at every point into the future there is a point
somewhere into the future where ùëû holds. In other words, "infinitely often"
is achieved by combining the operators G and F to "always eventually".
Strictly speaking, GFùëû says that ùëû holds infinitely often after the moment of
interpretation. Since there are only finitely many moments before any such
moment, we get that ùë§, ùëñ ‚äß GFùëû iff ùë§, 0 ‚äß GFùëû for any ùë§ ‚àà Œ£ ùúî and ùëñ ‚àà N.
This is also expressed by the equivalence FGFùúë ‚â° GF ùúë.

The language of all words in which infinitely many positions contain ùëû if
infinitely many positions contain ùëù can be defined in LTL by GFùëù ‚Üí GFùëù.
Example 10.9 We ask whether there is an LTL formula describing the
language ùêø
ùúî
that contains the single word (ùëéùëè)
only for some alphabet Œ£ = {ùëé, ùëè}. In general,
P
we of course assume that Œ£ = 2
for some set P of atomic propositions. In this case,
ùúî
it could just be P = {ùëû}, and ùêø could equally be described as ({ùëû} ‚àÖ) or,
more
ùúî
symbolically, as (ùëû ¬¨ùëû)
for ex ample.
P
In general, given an alphabet Œ£ = 2 , each letter ùëé ‚àà Œ£ induces a
characteristic f ormula
ùúí
ùëù
ùëé

‚à∂= ( ‚ãÄ
) ‚àß ( ‚ãÄ ¬¨ ùëù) .
ùëù‚ààùëé
ùëù /
‚ààùëé
Then the LTL formula
ùúíùëé ‚àß G(( ùúíùëé ‚Üí X ùúíùëè ) ‚àß ( ùúíùëè ‚Üí X ùúíùëé ))
ùúî
defines the language {(ùëéùëè) }.
Note that ùêø of the previous example can be regarded as the property of
seeing letter ùëé at position ùëñ iff ùëñ is even. We remark without proof that the
language of ùúî
words of the form (ùëé(ùëé + ùëè)) , i.e. the property of seeing letter ùëé at every
even position, is not LTL-definable. The reason is that LTL-definable
languages are also FO-definable, and we recall that the language of finite
words of even length is MSO-
248
10 Linear-Time Temporal Logic
but not FO-definable. The same principles that restrict the expressiveness of
FO on finite words also do so on infinite words. In particular, genuine
counting properties like "something holds at every ùëò -th position" for ùëò > 1
are not FO-e xpressible.
The fact that FO is an upper bound on the expressiveness of LTL is a direct
consequence of the fact that the semantics of LTL is essentially given in FO.

Theorem 10.10 Every LTL-definable language is FO-definable.
Proof Given an LTL formula ùúë, we inductively construct an FO formula tr
ùë•(ùúë) with a single free first-order variable ùë• such that for all words ùë§ ‚àà Œ£ ùúî,
all ùëñ ‚àà N and all first-order variables ùë• we ha ve
ùë§ , ùëñ ‚äß ùúë
iff
ùë§ , [ùë• ‚Ü¶ ùëñ] ‚äß tr ùë• (ùúë) .
The construction of tr ùë• (ùúë) for an arbitrary variable ùë• is straightforward.
The only technicality arises from the fact that in FO, we use atomic letters,
while LTL uses atomic propositions. Hence, we define
tr ùë• (ùëû) ‚à∂= ‚ãÅ{ùëé(ùë•) ‚à£ ùëé ‚àà Œ£, ùëû ‚àà ùëé}
tr ùë• (ùúë ‚à® ùúì) ‚à∂= tr ùë• (ùúë) ‚à® tr ùë• (ùúì)
tr ùë• (¬¨ùúë) ‚à∂= ¬¨ tr ùë• (ùúë)
tr ùë• (Xùúë) ‚à∂= tr ùë• (ùúë)[ succ(ùë•)/ùë•]
tr ùë• (ùúë U ùúì) ‚à∂= ‚àÉùë¶.ùë¶ ‚â• ùë• ‚àß tr ùë¶ (ùúì) ‚àß ‚àÄùëß.ùë• ‚â§ ùëß < ùë¶ ‚Üí tr ùëß (ùúë) where ùë¶, ùëß in
the last clause are fresh variables different from ùë•.
The theorem's claim is then established using the FO formula tr ùë• (ùúë)[0/ùë•]
for an LTL formula ùúë, i.e. first translating it for an arbitrary position
represented by some variable ùë•, and in the end fixing that position to be the
first in an underlying word.‚óª
10.1.3 Temporal Equivalences
When handling LTL formulas algorithmically it will be convenient to
assume them to be normalised, in particular with respect to occurrences of
the negation operator.

For this we promote some of the operators that were introduced as
abbreviations only, to first-class citizens.
Definition 10.11 An LTL formula over P is in negation normal form (NNF)
if it is built from literals of the form ùëû, ¬¨ùëû for some ùëû ‚àà P and constants tt,
ff using the connectives ‚à®, ‚àß, X, U and R.
This has an effect on the definition of the set of subformulas of a given LTL
formula ùúë.
Example 10.12 Let ùúë ‚à∂= G(ùëù ‚Üí Fùëû). When taking this as a formula in the
pure syntax given in Def. 10.5, it is to be seen as an abbreviation for
10.1 Syntax and Semantics
249
¬¨(¬¨(ùëû ‚à® ¬¨ùëû) U ¬¨(¬¨ ùëù ‚à® (ùëû ‚à® ¬¨ùëû) U ùëû))
tt
ùëû
ùëû
where we re-use ùëû in order to define
‚à∂=
‚à® ¬¨ . This formula then has 11 different
subformulas. When taking it as a formula in the syntax of negation normal
forms, it should be considered as an abbreviation f or
ff R (¬¨ùëù ‚à® tt U ùëû)
which has 8 subformulas.

It should be clear that, while the actual size of a formula may vary
depending on whether it is measured against negation normal form or the
original syntax, there can be at most a linear difference between the two
measures. Hence, we will be liberal about this difference and simply
continue to speak about the size of a formula.
Before we remark that every LTL formula can easily be normalised into
NNF, we list some useful LTL equivalences about temporal operators. All
can be proved by inspection of the semantics and some then follow easily
from others. Carrying out the proofs in detail is left as an exercise.
Lemma 10.13 For all ùúë, ùúì the following hold.
¬¨Xùúë
‚â° X¬¨ùúë
X(ùúë U ùúì) ‚â° Xùúë U Xùúì
¬¨(ùúë U ùúì)
‚â° ¬¨ùúë R ¬¨ùúì
X(ùúë R ùúì) ‚â° Xùúë R Xùúì
¬¨(ùúë R ùúì)
‚â° ¬¨ùúë U ¬¨ùúì
XFùúë ‚â° FXùúë
¬¨(ùúë U ùúì)
‚â° G¬¨ùúì ‚à® ¬¨ùúì U (¬¨ùúë ‚àß ¬¨ùúì)
XGùúë ‚â° GXùúë
Xtt ‚â° tt

Xff ‚â° ff
The relation '‚â°' on LTL formulas is not only an equivalence relation but in
fact also a congruence with respect to all logical operators in LTL in the
sense of the following lemma. It can easily be shown by induction on the
structure of ùúí, and this is left as an exercise again. By ùúí[ùúì/ùúë] we denote the
formula that arises from ùúí by uniformly replacing every occurrence of ùúë as a
subformula of ùúí by ùúì.
Lemma 10.14 For all LTL formulas ùúë, ùúì, ùúí with ùúë ‚â° ùúì we have ùúí ‚â° ùúí[ùúì/ùúë ] .
Being a congruence is not a particularly remarkable fact. It is used in many
reasoning steps, though, namely whenever an equivalence between
formulas is proved by replacing subformulas of it with equivalent ones, and
this is a reasoning step that is naturally assumed to be sound.
Corollary 10.15
‚Ä≤
For every LTL formula ùúë there is an LTL formula ùúë in NNF such
‚Ä≤
‚Ä≤
that ùúë ‚â° ùúë and ‚à£ùúë ‚à£ ‚â§ 2 ‚ãÖ ‚à£ùúë ‚à£ .
Proof Using the deMorgan laws ¬¨(ùúë‚à®ùúì) ‚â° ¬¨ùúë‚àß¬¨ùúì and ¬¨(ùúë‚àßùúì) ‚â° ¬¨ùúë‚à®¬¨ùúì,
double negation elimination ¬¨¬¨ùúë ‚â° ùúë, commutativity between negation and
the temporal next and the duality between U and R as stated in Lemma
10.13, we can push negation
250
10 Linear-Time Temporal Logic
successively inwards until it occurs at most in front of atomic propositions,
at the expense of possibly turning U-operators into R-operators.

The size estimation follows from the observation that multiple occurrences
of negated subformulas can be put into the same NNF, and that pushing
negation inwards preserves the structure of the syntax tree but may, in the
worst case, add an extra layer of formulas above the tree's leaves.
‚óª
10.1.4 Unfoldings of Temporal Operators
In the following we will consider translations of LTL formulas into B √ºchi
automata.
They rely on a characterisation of the temporal operators U and R known
as their unfoldings - a formula equivalent to ùúë U ùúì for instance that contains
ùúë U ùúì underneath a X-operator.
Lemma 10.16 For all ùúë, ùúì ‚àà LTL we hav e:
a) ùúë U ùúì ‚â° ùúì ‚à® (ùúë ‚àß X(ùúë U ùúì)) ,
b) ùúë R ùúì ‚â° ùúì ‚àß (ùúë ‚à® X(ùúë R ùúì )) .
Proof (a) We only show the "‚áí"-part. The "‚áê"-part is entirely analogous.
Suppose that ùë§, ùëñ ‚äß ùúë U ùúì. Then there is ùëò ‚â• ùëñ with ùë§, ùëò ‚äß ùúì and ùë§, ùëó ‚äß ùúë for
all ùëó with ùëñ ‚â§ ùëó < ùëò . We distinguish between tw o cases.
a) Case 1, ùëò = ùëñ. Then we clearly have ùë§, ùëñ ‚äß ùúì .
b) Case 2, ùëò > ùëñ. Then we have ùë§, ùëñ ‚äß ùúë. Consider position ùëñ + 1 in ùë§. Note
that ùëò ‚â• ùëñ + 1, ùë§, ùëò ‚äß ùúì and ùë§, ‚Ñé ‚äß ùúë for all ùëó with mit ùëñ ‚â§ ùëó < ùëò , so in
particular for all ùëó with ùëñ + 1 ‚â§ ùëó < ùëò . Hence, we have ùë§, ùëñ + 1 ‚äß ùúë U ùúì and
therefore ùë§ , ùëñ ‚äß X(ùúë U ùúì). Altogether we get that ùë§, ùëñ ‚äß ùúë ‚àß X(ùúë U ùúì).
Since one of both cases must be true for any such ùëñ, we get ùë§, ùëñ ‚äß ùúì ‚à® (ùúë ‚àß
X(ùúë U ùúì)).

(b) This then follows from (a) using standard reasoning about negation in
propositional logic (deMorgan laws, double negation
elimination/introduction) and some equivalences from Lemma 10.13. We
have
ùúë R ùúì
‚â° ¬¨¬¨(ùúë R ùúì)
‚â° ¬¨(¬¨ùúë U ¬¨ùúì)
‚â° ¬¨(¬¨ùúì ‚à® (¬¨ùúë ‚àß X(¬¨ùúë U ¬¨ùúì)))
‚â° ¬¨¬¨ùúì ‚àß ¬¨(¬¨ùúë ‚àß X(¬¨ùúë U ¬¨ùúì))
‚â° ¬¨¬¨ùúì ‚àß (¬¨¬¨ùúë ‚à® ¬¨X(¬¨ùúë U ¬¨ùúì))
‚â° ¬¨¬¨ùúì ‚àß (¬¨¬¨ùúë ‚à® X¬¨(¬¨ùúë U ¬¨ùúì))
‚â° ùúì ‚àß (ùúë ‚à® X(ùúë R ùúì))
which proves the claim.
‚óª
Lemma 10.16 suggests a method for checking whether a given word with
some position ùëñ satisfies a given LTL formula ùúë U ùúì: first, check whether
position ùëñ satisfies ùúì . If this is the case then return yes. Otherwise check
whether it satisfies ùúë. If this is not the case then return no. Otherwise move
to position ùëñ + 1 and repeat this procedure.
10.1 Syntax and Semantics
251
It should be clear that, if this procedure ever produces an answer yes or no,
then this is truly an answer to the question whether the original position ùëñ
satisfies ùúë U ùúì.

But what if this is deferred indefinitely? Then no position ùëò ‚â• ùëñ satisfies ùúì
but all of them satisfy ùúë. The latter is less relevant than the former for the
observation that then position ùëñ cannot satisfy ùúë U ùúì because this demands
the existence of some position ùëò ‚â• ùëñ satisfying ùúì. Hence, this intuitive
procedure, based on the unfolding of U-formulas according to Lemma
10.16 which prescribes conditions on what needs to hold locally, also
comes with a global condition: in order for ùúë U ùúì to hold, this recursion
needs to stop eventually and produce the answer yes because some position
has been found at which ùúì holds.
While this reasoning is quite high-level and leaves open questions after the
representation of an infinite word and how to check whether the
subformulas ùúë, ùúì hold at a given position, it shows that proper decision
procedures for LTL which handle U-formulas by unfolding need to take
such limit conditions into account.
A natural question that arises concerns the R-operator. Likewise, one may
imagine that in order to check whether a position ùëñ in a given word satisfies
ùúë R ùúì, one first checks whether it satisfies ùúì and returns no if it does not.
Otherwise one checks whether it satisfies ùúë and returns yes if it does, or
continues this procedure with the next position ùëñ + 1. Again, any answer
obtained in finite time correctly says whether ùúë R ùúì is satisfied at position ùëñ,
and the interesting question then is: what is the correct answer in case that
this procedure goes on forever? One may be tempted to also say that the
answer should be no, perhaps because it feels unnatural to derive a positive
answer from such non-well-founded reasoning. However, when looking
closer, we see that the answer should be yes. If this process never derives an
answer in finite time, then any position ùëò ‚â• ùëñ has passed the test for
satisfying ùúì. So position ùëñ
satisfies Gùúì and therefore ùúë R ùúì, regardless of the fact that no such position
satisfies ùúë (because this would have caused the check to terminate at some
point).
Another way of seeing that infinite deferral in checking ùúë R ùúì is a reason for
it to hold, is the duality between R and U. Remember that ùúë R ùúì ‚â° ¬¨(¬¨ùúë U
¬¨ùúì). The outer negation on the right-hand side can be interpreted as

inverting the answers yes/ no in a check for ¬¨ùúë U ¬¨ùúì. Hence, if the answer
is not derived in finite time but deferred to the limit, it is no by the
argumentation based on the semantics of U-formulas above, and
consequently it is inverted into a yes for the question whether the
corresponding R-formula holds.
The following two sections present translations of LTL formulas into B √ºchi
automata - nondeterministic and alternating ones. Both make use of the
unfoldings of U- and R-formulas. The global conditions - an U-formula
may only be unfolded finitely often while a R-formula can be unfolded
infinitely often - are ensured by the acceptance conditions.
252
10 Linear-Time Temporal Logic
10.2 Nondeterministic B ¬®
uchi Automata for LTL
We have of course already provided a way to translate LTL formulas into
equivalent B √ºchi automata: LTL can easily be translated into FO
according to Thm. 10.10; every FO formula is obviously also an MSO
formula; and MSO formulas can be translated into equivalent NBA via
Lemma 5.35. The problem with this approach is that, while the first two
steps incur no blowup at all, the last one from MSO to NBA incurs a non-
elementary blowup in general. The reason for this is the necessity of an
exponential blowup for every negation, and negation cannot be eliminated
from MSO formulas since there is no way to directly handle universal
quantification on the automata side.
Now, the quantification in LTL is only first-order and very restricted. For
instance, a formula of the form ùúë U ùúì translates into a quantification pattern
of the form
‚àÉ . . . ‚àÄ . . ., and a formula of the form ùúë R ùúì translates into one of the form
‚àÄ . . . ‚àÉ . . .

Thus, it is reasonable to assume that not one of them is more difficult than
the other in a possible translation into NBA, and using Cor. 10.15, we can
avoid successive complementation steps altogether. This is indeed the case,
but there is another small technicality to handle, and we do so by
introducing yet another automaton model for languages of infinite words.
10.2.1 Generalised B ¬®
uchi Automata
Remember the construction showing that the class of ùúî-regular languages is
closed under intersections, cf. Thm. 5.17. The technical challenge was to
come up with a single B √ºchi acceptance condition that realises acceptance
by two B √ºchi acceptance conditions simultaneously. This could have been
no problem at all if automata were equipped with multiple B √ºchi
acceptance conditions so that an accepting run needs to satisfy all of them.
This is exactly what happens in generalised B √ºchi automata, and it is not a
surprise that the construction showing that they do not exceed the
expressive power of NBA makes use of the same trick as is used in the proof
of Thm. 5.17 to show closure under intersections.
Definition 10.17 A generalised (nondeterministic) B√ºchi automaton
(GNBA) is an A = (ùëÑ, Œ£, ùêº , ùõø, F ) with ùëÑ, Œ£, ùõø as for an NBA, but with a set
of initial states ùêº ‚äÜ ùëÑ
ùëÑ
and a set F = {ùêπ , . . . , ùêπ
1
ùëò } ‚äÜ 2
of acceptance sets.
The size of the GNBA A is, as usual, ‚à£ùëÑ‚à£, and its index is ùëò .
A run ùúå of a GNBA on a word ùë§ = ùëé ùëé . . .

0
1
‚àà Œ£ ùúî is defined as for an NBA but
it is allowed to start in an arbitrary ùëû0 ‚àà ùêº. It is accepting if Inf (ùúå) ‚à© ùêπùëñ ‚â†
‚àÖ for all ùëñ = 1, . . . , ùëò .
Thus, the way that GNBA are presented here includes two generalisations:
having potentially multiple initial states and having potentially multiple
acceptance sets. We remark that the generalisation to multiple initial states
is only done for convenience, and that it is always possible to transform
such GNBA into ones that only have
10.2 Nondeterministic B √ºchi Automata for LTL
253
ùëê
ùëûùëê
ùëê
ùëé
ùëè
ùëê
ùëé
ùëû
ùëû
ùëè

ùëè
ùëé
ùëé
ùëè
Fig. 10.2 Transition function of the GNBA for the language of words
containing infinitely many symbols ùëé and infinitely many symbols ùëè.
a single initial state by introducing this as a new one which inherits its
outgoing transitions from all original initial states. The reason for calling
GNBA generalised is really the extension to potentially multiple acceptance
sets, i.e. the fact that a run needs to hit not just one but possibly many
different sets infinitely often.
Example 10.18 GNBA can be quite convenient, particularly to represent
languages that come as intersections of B √ºchi-recognisable languages. Let
ùêø ‚à∂= {ùë§ ‚àà
ùúî
{ùëé, ùëè, ùëê}
‚à£ ‚à£ùë§‚à£ùëé = ‚àû and ‚à£ùë§‚à£ùëè = ‚àû}. It is recognised by the GNBA shown in Fig.
10.2. It simply remembers in its state space the last letter that was read. Any
non-empty set of states can be used as initial states since all three recognise
the same language anyway, regardless of any accepting condition. With the
generalised B √ºchi condition {{ùëûùëé}, {ùëûùëè}} we ensure that both symbols ùëé
and ùëè need to be seen infinitely often in a word for it to be accepted.
It should be clear that GNBA can recognise every NBA-definable language;
an NBA with acceptance set ùêπ can be seen as a GNBA with a single
acceptance set
{ùêπ }. Given the statements above about the connection between GNBA and
the intersection closure of the class of ùúî-regular languages, it is not

surprising that the converse holds as well. Naturally, the construction is
reminiscent of the one proving intersection closure of the class of NBA-
recognisable languages (cf. Thm. 5.17). So the translation from GNBA to
NBA comes with a mild blowup.
Theorem 10.19 For every GNBA A of size ùëõ and index ùëò there is an NBA B
of size at most ùëõ ‚ãÖ ùëò + 1 such that ùêø(B) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùêº, ùõø, F) with F = {ùêπ , . . . , ùêπ
0
ùëò ‚àí1} be a GNBA. Take a new
state ùëûùêº and define the NBA B as
(ùëÑ √ó [ùëò ] ‚à™ {ùëû
, Œî, ùêπ
ùêº }, Œ£, ùëû ùêº
0 √ó {0})
where
‚éß
‚é™
‚é™ùëñ + 1 mod ùëò
, if ùëû ‚àà ùêπ ,
ùëñ
((ùëû, ùëñ), ùëé, ( ùëù, ùëó )) ‚àà Œî
iff

(ùëû, ùëé, ùëù) ‚àà ùõø and ùëó = ‚é®
‚é™
‚é™ùëñ
, otherwise,
‚é©
254
10 Linear-Time Temporal Logic
(ùëû , ùëé,
ùêº
( ùëù, 0)) ‚àà Œî
iff
there is ùëû ‚àà ùêº with (ùëû, ùëé, ùëù) ‚àà ùõø
for all ùëû, ùëù ‚àà ùëÑ, ùëñ, ùëó ‚àà [ùëò ], ùëé ‚àà Œ£.
So intuitively, A's state space is enriched with a counter that points to the
index of the next acceptance set from which a state needs to be seen. This is
based on the principle that in a run which sees states from all ùêπùëñ infinitely
often, there will be a first occurrence of a state from ùêπ0, eventually
followed by an occurrence of a state from ùêπ1, etc. Once a state from ùêπùëò‚àí1
has been seen in this order, we repeat the entire procedure from the
beginning. Formally, we have ùêø(B) = ùêø(A) because of the following
reasoning.
"‚äÜ" Let ùúå = ùëû ,
, ùëñ

, ùëñ
ùêº
(ùëû1 1), (ùëû2 2), . . . be an accepting run of B on a word ùë§ =
ùëé
ùëé
. . .
, ùëé
, ùëû
0
1
‚àà Œ£ ùúî . Then there must be some ùëû0 ‚àà ùêº such that (ùëû0
0
1) ‚àà ùõø. The
‚Ä≤
sequence ùúå = ùëû , ùëû , ùëû , . . .
0
1
2
then forms a run of A on ùë§.
Since ùúå is accepting, there must be infinitely many ùëó such that (ùëû , ùëñ

ùëó
ùëó ) ‚àà ùêπ0 √ó {0},
i.e. ùëñ ùëó = 0 and ùëû ùëó ‚àà ùêπ0. According to the definition of Œî, we have ùëñ ùëó+1 = 1
for every such ùëó . Since the second components of the states only ever
change from ‚Ñé to ‚Ñé + 1 mod ùëò when the first component is a member of
ùêπ‚Ñé, we get that between two occurrences of states from ùêπ0 √ó {0} we must
have seen states from ùêπ‚Ñé √ó {‚Ñé} for all
‚Ä≤
‚Ñé ‚àà [ùëò ]. Hence, ùúå is an accepting run of A on ùë§.
"‚äá" Let ùúå = ùëû , ùëû , . . .
ùëé
. . .
0
1
be an accepting run of A on a word ùë§ = ùëé0 1
‚àà Œ£ ùúî .
Hence, for every ‚Ñé ‚àà [ùëò ] and every ùëó ‚àà N there is ùëñ ‚â• ùëó with ùëûùëñ ‚àà ùêπ‚Ñé. We
call this the progression pr operty for the moment.
‚Ä≤
Now extend ùúå to a run ùúå ‚à∂= ùëû ,
, ùëñ
, ùëñ

ùêº
(ùëû1 1), (ùëû2 2), . . . of B as follows: let ùëñ1 ‚à∂= 0,
and whenever ùëñ ùëó is determined, then let ùëñ ùëó+1 be the unique value in [ùëò]
such that ((ùëû , ùëñ
,
, ùëñ
ùëó
ùëó ), ùëé ùëó
(ùëû ùëó+1
ùëó +1)) ‚àà Œî. By inspection of the construction of Œî we see that it exists uniq
uely.
Because of the progression property, the sequence ùëñ , ùëñ , . . .
1
2
is not eventually
+
+
+
ùúî
stable, but it forms a word from (0 1 . . . (ùëò ‚àí 1) ) . Hence, it contains
infinitely many symbols 0. Moreover, since it also contains infinitely many
transitions from

‚Ä≤
a 0 to a 1, ùúå must contain infinitely many states from ùêπ0 √ó {0} and is
therefore an accepting run on ùë§.
‚óª
10.2.2 From LTL to Generalised B ¬®
uchi Automata
In the following we assume that a given LTL formula has been normalised
into NNF
already. We give a direct translation from an LTL formula into an
equivalent GNBA which can then be composed with the construction in the
proof of Thm. 10.19 to obtain an NBA equivalent to the LTL formula. The
translation from LTL into GNBA is not modular, i.e. it does not proceed by
induction on the structure of the formula, as is the case for MSO for
instance. Instead it is monolithic, and for this we need a concept that
extends the definition of subformulas slightly.
Definition 10.20 Let ùúÉ be an LTL formula in NNF. The Fischer-Ladner
closure of ùúÉ is the smallest set FL(ùúÉ) that contains ùúÉ and satisfies the
following for all ùúë, ùúì.
10.2 Nondeterministic B √ºchi Automata for LTL
255
‚Ä¢ If ùúë ‚à® ùúì ‚àà FL
(ùúÉ) or ùúë ‚àß ùúì ‚àà FL
(ùúÉ) then {ùúë, ùúì} ‚äÜ FL
(ùúÉ),
‚Ä¢ if Xùúë ‚àà FL

(ùúÉ) then ùúë ‚àà FL
(ùúÉ ),
‚Ä¢ if ùúë U ùúì ‚àà FL
(ùúÉ) then {ùúë, ùúì, X(ùúë U ùúì)} ‚äÜ FL
(ùúÉ ),
‚Ä¢ if ùúë R ùúì ‚àà FL(ùúÉ) then {ùúë, ùúì, X(ùúë R ùúì)} ‚äÜ FL(ùúÉ) .
The following estimation on the size of the Fischer-Ladner closure of a
formula follows directly from the observation that the Fischer-Ladner
closure adds to the set of subformulas of a formula in NNF, at most one
more formula for each temporal U-or R-formula.
Lemma 10.21 Let ùúë be an LTL formula in NNF. Then ‚à£ FL(ùúë)‚à£ ‚â§ 2 ‚ãÖ ‚à£ùúë‚à£ .
The Fischer-Ladner closure of ùúë can be seen as the set of formulas that are
of interest when trying to establish whether ùúë holds at a particular position
of a given word, making use of the unfoldings of temporal formulas. Based
on this we introduce another concept, namely that of a Hintikka set. Such
sets can be seen as being closed under logical consequence. For instance,
suppose we say that ùúë ‚àß ùúì is true at some position ùëñ of a word ùë§. Then this
will also be true for ùúë and for ùúì. Likewise, if ùúë ‚à® ùúì
is true, then so must be one of the two disjuncts, etc.
Definition 10.22 Let ùúÉ be an LTL formula in NNF over P. A set ùëÄ ‚äÜ FL(ùúÉ) is
called a Hintikka set if it satisfies the following for all ùúë, ùúì .
‚Ä¢ If ùúë ‚à® ùúì ‚àà ùëÄ then ùúë ‚àà ùëÄ or ùúì ‚àà ùëÄ,
‚Ä¢ if ùúë ‚àß ùúì ‚àà ùëÄ then ùúë ‚àà ùëÄ and ùúì ‚àà ùëÄ,
‚Ä¢ if ùúë U ùúì ‚àà ùëÄ then ùúì ‚àà ùëÄ or {ùúë, X(ùúë U ùúì)} ‚äÜ ùëÄ,

‚Ä¢ if ùúë R ùúì ‚àà ùëÄ then {ùúì, ùúë} ‚äÜ ùëÄ or {ùúì, X(ùúë R ùúì)} ‚äÜ ùëÄ .
Such a Hintikka set ùëÄ is called propositionally consistent if ff /
‚àà ùëÄ and there is no
ùëù ‚àà P such that {ùëù, ¬¨ùëù} ‚äÜ ùëÄ .
We write H(ùúÉ) for the set of all propositionally consistent Hintikka sets for ùúÉ,
+
+
‚àí
P
(ùëÄ ) for the set of all positive literals in ùëÄ, i.e. P (ùëÄ) ‚à∂= ùëÄ ‚à© P , and P
(ùëÄ)
‚àí
for the set of all negative literals in ùëÄ, i.e. P (ùëÄ) ‚à∂= ùëÄ ‚à© {¬¨ùëù ‚à£ ùëù ‚àà P }.
Note that propositional consistency is not the same as consistency in the
standard logical sense or even satisfiability. For instance, {Xùëû, X¬¨ùëû} is
clearly unsatisfiable but it is propositionally consistent in the sense that it
has a propositional model that simply assigns true or false to each
proposition which is either an atomic one or a formula that begins with a X-
operator.
Since propositional consistency is the only concept of consistency we
consider here, we simply drop the qualification "propositional" and speak
of consistent sets.
Fix an LTL formula ùúÉ for the remainder of this section. The goal is to
construct a GNBA AùúÉ such that ùêø(AùúÉ ) = ùêø(ùúÉ) and ‚à£AùúÉ ‚à£ is elementary in ‚à£ùúÉ‚à£.

As states we use consistent Hintikka sets. Such states intuitively contain all
the subformulas of ùúÉ or, more precisely, all the elements of its Fischer-
Ladner closure that need to be satisfied at the current position ùëñ of a word
that is to be accepted from this state. Note that such sets need to be Hintikka
sets: if a conjunction is supposed to be satisfied by such a position, then
both conjuncts need to be as well, etc. Moreover,
256
10 Linear-Time Temporal Logic
it needs to be consistent since no position can satisfy ff or ùëû and ¬¨ùëû at the
same time.
However, propositional consistency suffices. It is perfectly fine to assume
that some position ùëñ satisfies Xùëû and X¬¨ùëû. The transition relation will
ensure that such hidden inconsistencies will eventually - here already after
one step - become propositional inconsistencies.
We can use nondeterminism to guess the set of formulas that need to hold in
the next position. Temporal operators are handled by their unfoldings where
U-formulas need special treatment through the acceptance condition in
order to ensure that every unfolding terminates eventually.
Let ùúë U ùúì , . . . , ùúë U ùúì
1
1
ùëò
ùëò
be an enumeration of all U-formulas in FL(ùúÉ). We
construct the GNBA AùúÉ as (H(ùúë), Œ£, ùêº, ùõø, F ) where ùêº ‚à∂= {ùëÄ ‚àà H(ùúÉ) ‚à£ ùúÉ ‚àà ùëÄ}
consists of all such states that contain ùúÉ .

The transition relation is given as follows. We have
‚Ä≤
‚Ä≤
(ùëÄ , ùëé, ùëÄ ) ‚àà ùõø
iff
for all Xùúì ‚àà ùëÄ ‚à∂ ùúì ‚àà ùëÄ
‚Ä≤
P
+
‚àí
for any ùëÄ, ùëÄ ‚àà H(ùëÄ), ùëé ‚àà 2
such that P (ùëÄ) ‚äÜ ùëé and {ùëû ‚à£ ¬¨ùëû ‚àà P (ùëÄ)}‚à©ùëé = ‚àÖ.
At last, there are ùëò acceptance sets, one for each U-formula in the Fischer-
Ladner closure of ùúÉ. We have F ‚à∂= {ùêπ , . . . , ùêπ
1
ùëò } where
ùêπ
U ùúì
ùëñ
‚à∂= {ùëÄ ‚à£ ùúëùëñ

ùëñ
/
‚àà ùëÄ or ùúìùëñ ‚àà ùëÄ}
for all ùëñ = 1, . . . , ùëò. Hence, the acceptance set associated with the ùëñ-th U-
formula consists of all states that contain its right argument whenever they
contain the formula itself. In other words, a good state in the sense of
ensuring termination of the unfolding process for the ùëñ-th U-formula ùúë U ùúì
ùëñ
ùëñ
is one that does not contain
ùúë
U ùúì
ùëñ
ùëñ in which case there is no termination needed to be guaranteed, or it
contains ùúìùëñ which is exactly what needs to happen for the unfolding not be
deferred to later moments an ymore.
There is no need to treat R-formulas in the acceptance condition. Their
satisfaction is guaranteed entirely locally through unfolding which can
either stop or go on ad infinitum.
Example 10.23 Let ùúÉ = G(ùëù ‚Üí XFùëû). Strictly speaking we would have to
transform ùúÉ into NNF, including the rewriting of G and F as R and U. It
should be clear, though, that the general construction could equally be
formulated for formulas including subformulas of such kind. We leave it as
an exercise to extend the general construction correspondingly. Here we
carry it out for a ùúÉ that is only normalised into G(¬¨ùëù ‚à®XFùëû).

The Fischer-Ladner closure of ùúÉ is
{G(¬¨ ùëù ‚à® XFùëû), XG(¬¨ ùëù ‚à® XFùëû), ¬¨ ùëù ‚à® XFùëû, ¬¨ ùëù, XFùëû, Fùëû, ùëû}
containing six elements.
There are way less than 26 = 64 subsets thereof which are consistent
Hintikka sets. Moreover, it suffices to construct the GNBA AùúÉ on-the-fly, i.e.
starting will all potential initial states and then only constructing the part
that is reachable from these.
10.2 Nondeterministic B √ºchi Automata for LTL
257
G(¬¨ ùëù ‚à® XFùëû),
G(¬¨ ùëù ‚à® XFùëû)
¬¨ùëù
,
¬¨ùëù
XG(¬¨ ùëù ‚à® XFùëû),
XG(¬¨ ùëù ‚à® XFùëû),
¬¨ ùëù ‚à® XFùëû , ¬¨ ùëù
¬¨ ùëù ‚à® XFùëû , XFùëû
tt
¬¨ùëù ‚àß ùëû
tt

tt
tt
tt
¬¨ùëù ‚àß ùëû
G(¬¨ ùëù ‚à® XFùëû),
G(¬¨ ùëù ‚à® XFùëû),
XG
tt
(¬¨ ùëù ‚à® XFùëû),
XG(¬¨ ùëù ‚à® XFùëû),
¬¨ ùëù ‚à® XFùëû , ¬¨ ùëù,
¬¨ ùëù ‚à® XFùëû,
Fùëû, ùëû
XFùëû, Fùëû
tt
¬¨
ùëû
tt
ùëù
¬¨

ùëû
ùëù
G(¬¨ ùëù ‚à® XFùëû),
ùëû
G(¬¨ ùëù ‚à® XFùëû),
XG(¬¨ ùëù ‚à® XFùëû),
XG(¬¨ ùëù ‚à® XFùëû),
¬¨ùëù
ùëû
¬¨ ùëù ‚à® XFùëû , ¬¨ ùëù,
¬¨ ùëù ‚à® XFùëû,
¬¨
F
ùëù
ùëû , XFùëû
XFùëû, Fùëû, ùëû
Fig. 10.3 GNBA with a single acceptance set, obtained for the LTL formula
G(ùëù ‚Üí XFùëû).
Moreover, it is sufficient to construct these Hintikka sets in a minimal way,
i.e. to only include what needs to be included according to Def. 10.22 and
the construction of the transition relation.

Note that any consistent Hintikka set containing ùúÉ = G(¬¨ùëù ‚à® XFùëû) also
needs to contain XùúÉ and ¬¨ùëù ‚à® XFùëû. Hence, there are two initial states for AùúÉ
, namel y ùëÄ0 ‚à∂= {G(¬¨ùëù ‚à® XFùëû), XG(¬¨ùëù ‚à® XFùëû), ¬¨ùëù ‚à® XFùëû, ¬¨ùëù} and
ùëÄ1 ‚à∂= {G(¬¨ùëù ‚à® XFùëû), XG(¬¨ùëù ‚à® XFùëû), ¬¨ùëù ‚à® XFùëû, XF ùëû}
We proceed to construct the GNBA as a symbolic automaton. For this it
suffices to note that, given a state ùëÄ, in order to find out its successors, we
do not need P
OceanofPDF.com

‚Ä≤
to iterate through all ùëé ‚àà 2
and all possible consistent Hintikka sets ùëÄ to check
‚Ä≤
whether (ùëÄ, ùëé, ùëÄ ) ‚àà ùõø. Instead, we can extract a symbolic representation
ùëì of all
+
‚àí
such ùëé from ùëÄ itself: simply take ùëì ‚à∂= ‚ãÄ(P (ùëÄ) ‚à™ P (ùëÄ)), i.e. conjoin all
literals occurring in ùëÄ conjunctivel y.
Likewise, the set of possible successors of ùëÄ is obtained by collecting all
formulas ùúí such that X ùúí ‚àà ùëÄ and then extending this to a consistent
Hintikka sets, for which there may be several possibilities in general.
For instance, take state ùëÄ0 as defined above. Its outgoing transitions can
symbolically be labelled with ¬¨ùëù, and each successor must contain ùúÉ.
Hence, ùëÄ0 and ùëÄ1
are the two successors of ùëÄ0.
Now consider ùëÄ1. It contains no literals. Hence, each outgoing transition
is labelled with ‚ãÄ ‚àÖ, i.e. tt. Its successors need to contain both ùúÉ and Fùëû,
and this leads
258
10 Linear-Time Temporal Logic
ùëÄ

ùëÄ
¬¨ùëù
ùëÄ
ùëÄ
0
1
tt
0
1
tt
tt
¬¨ùëù ‚àß ùëû
tt
tt
ùëÄ
ùëÄ
ùëÄ
ùëÄ
2
5

2
5
tt
ùëû
ùëÄ
ùëÄ
ùëÄ
ùëÄ
3
4
3
4
Fig. 10.4 Shape of accepting runs for two families of words described in Ex.
10.23.
to four more consistent Hintikka sets.
ùëÄ2 ‚à∂= {G(¬¨ùëù ‚à® XFùëû), XG(¬¨ùëù ‚à® XFùëû), ¬¨ùëù ‚à® XFùëû, ¬¨ùëù, Fùëû, ùëû}
ùëÄ3 ‚à∂= {G(¬¨ùëù ‚à® XFùëû), XG(¬¨ùëù ‚à® XFùëû), ¬¨ùëù ‚à® XFùëû, ¬¨ùëù, Fùëû, XFùëû}
ùëÄ4 ‚à∂= {G(¬¨ùëù ‚à® XFùëû), XG(¬¨ùëù ‚à® XFùëû), ¬¨ùëù ‚à® XFùëû, XFùëû, Fùëû, ùëû}
ùëÄ5 ‚à∂= {G(¬¨ùëù ‚à® XFùëû), XG(¬¨ùëù ‚à® XFùëû), ¬¨ùëù ‚à® XFùëû, XFùëû , Fùëû}
From these, we do not obtain any new states in this manner. The
automaton's entire transition relation is shown in Fig. 10.3 in a simplified

way. Note that every reachable consistent Hintikka set must contain ùúÉ, XùúÉ
and ¬¨ùëù ‚à® XFùëû, so their content is in fact entirely determined by the answers
to the following questions.
‚Ä¢ Is ¬¨ùëù included or XFùëû (or both)?
‚Ä¢ If Fùëû is included, is ùëû also included or XFùëû (or both)?
Due to the excessive use of nondeterminism and the use of symbolic
transition labels it is not easy to see that AùúÉ accepts exactly those words in
which every position containing ùëù is followed by a position containing ùëû.
One of the obstacles is the fact that ùëù only occurs negatively in the
transition labels. So take a word which only has finitely many positions
containing ùëù, and some position containing ùëû after the last position
containing ùëù. It is accepted by a run of the form that is shown on the left of
Fig. 10.4. As a second example, take a word that contains ùëù everywhere,
and ùëû at every even position. It is accepted by the run shown on the right of
that figure.
We need to show that this construction does not only work in this example.
Theorem 10.24 For every LTL formula ùúÉ in NNF with ùëò U -subformulas
there is a GNBA AùúÉ of size at most 22‚ãÖ‚à£ùúÉ‚à£ and index ùëò such that ùêø(AùúÉ ) = ùêø(ùúÉ)
.
Proof The construction of AùúÉ is shown above. The estimation on its index is
trivially seen to be true. The statement on its size is obtained using Lemma
10.21 stating that
‚à£ FL(ùúÉ)‚à£ ‚â§ 2 ‚ãÖ ‚à£ùúÉ‚à£ and the fact that a consistent Hintikka set is a subset of
FL(ùúÉ).
It remains to be seen that ùêø(A
U ùúì , . . . , ùúë U ùúì
ùúÉ ) = ùêø (ùúÉ ). Let ùúë1

1
ùëò
ùëò be an enumer-
ation of all U-formulas in FL(ùúÉ) in no particular order.
10.2 Nondeterministic B √ºchi Automata for LTL
259
"‚äá" Suppose that ùë§ = ùëé ùëé . . .
0
1
‚àà ùêø(ùúÉ), i.e. ùë§, 0 ‚äß ùúÉ. For every ùëñ ‚àà N we define the
set ùëÄùëñ ‚à∂= {ùúì ‚àà FL(ùúÉ) ‚à£ ùë§, ùëñ ‚äß ùúì}. Then we have ùúÉ ‚àà ùëÄ0 by assumption and
for every ùëñ ‚àà N the following hold.
(i) ùëÄùëñ ‚àà H(ùúÉ), i.e. each ùëÄùëñ is a consistent Hintikka set.
(ii) If Xùúì ‚àà ùëÄùëñ then ùúì ‚àà ùëÄùëñ+1.
+
‚àí
(iii) P (ùëÄùëñ) ‚äÜ ùëéùëñ and {ùëû ‚à£ ¬¨ùëû ‚àà P (ùëÄùëñ)} ‚à© ùëéùëñ = ‚àÖ.
‚Ä≤
(iv) For every ùëó ‚àà {1, . . . , ùëò} with ùúë Uùúì
ùëó

ùëó
‚àà ùëÄùëñ there is some ùëñ ‚â• ùëñ such that ùúì ùëó ‚àà ùëÄùëñ‚Ä≤ .
This is a consequence of the fact that every U-formula that holds
somewhere must be satisfied at a later moment, more specifically its right
argument must hold ev entually.
Because of (i) we have that ùëÄ , ùëÄ , . . .
0
1
is a sequence of states in AùúÉ . Aùúë . Because
of the observation that ùúÉ ‚àà ùëÄ0 this sequence begins in an initial state.
Because of (ii) and (iii) this sequence forms a valid run on ùë§. Because of (iv)
it is accepting.
Hence, ùë§ ‚àà ùêø(AùúÉ ).
"‚äÜ" Suppose that ùë§ = ùëé ùëé . . .
0
1
‚àà ùêø(A ùúÉ ), i.e. there is an accepting run ùúå =
ùëÄ , ùëÄ , . . .
0
1
of AùúÉ on ùë§. We will show by induction on the structure of LTL formulas that
for all ùúë ‚àà FL(ùúÉ) with ùúë ‚àà ùëÄùëñ we have ùë§, ùëñ ‚äß ùúë. It should be clear that then we
have ùë§, 0 ‚äß ùúÉ, i.e. ùë§ ‚àà ùêø(ùúÉ), in particular because ùëÄ0 must contain ùúÉ.

+
Case ùúë = ùëû for some ùëû ‚àà P . Suppose that ùëû ‚àà ùëÄùëñ. Note that then ùëû ‚àà P (ùëÄùëñ) in
particular. Since ùúå is accepting, it is infinite, and so it must take a transition
from ùëÄùëñ
to ùëÄùëñ+1 under the alphabet symbol ùëéùëñ. By construction of the transition
relation we
+
have P (ùëÄùëñ) ‚äÜ ùëéùëñ, i.e. in particular ùëû ‚àà ùëéùëñ and therefore ùë§, ùëñ ‚äß ùëû.
Case ùúë = ¬¨ùëû for some ùëû ‚àà P . By the same reasoning as in the previous case
we
‚àí
get that ùë§, ùëñ /
‚äß ùëû, resp. ùë§, ùëñ ‚äß ¬¨ùëû because ¬¨ùëû ‚àà P (ùëÄùëñ ) and, thus, ùëû /
‚àà ùëéùëñ .
Case ùúë = ùúì1 ‚à® ùúì2 or ùúë = ùúì1 ‚àß ùúì2. Here, ùë§, ùëñ ‚äß ùúë follows immediately from the
inductive hypothesis for either or both of ùúì , ùúì
1
2 and the fact that ùëÄùëñ is a Hintikka
set, i.e. it needs to contain both conjuncts of a conjunction, and one disjunct
of a disjunction.
Case ùúë = Xùúì. Suppose that ùúë ‚àà ùëÄùëñ. By the construction of the transition
relation we have ùúì ‚àà ùëÄùëñ+1. By the hypothesis, we get ùë§, ùëñ + 1 ‚äß ùúì, and so ùë§, ùëñ
‚äß ùúë.
Case ùúë = ùúì U ùúì

1
2. Note that there is some ‚Ñì ‚àà {1, . . . , ùëò } such that ùúë is the ‚Ñì-th U-formula
in the enumeration fixed above. Suppose now that ùúë ‚àà ùëÄùëñ . By the
definition of a Hintikka set and the transition relation, we have ùúì2 ‚àà ùëÄùëñ or
ùúì1 ‚àà ùëÄ1
and ùúë ‚àà ùëÄùëñ+1. The second option can be unrolled further: we have ùúì2 ‚àà
ùëÄùëñ+1 or ùúì
, ùëÄ
, ùëÄ
, . . .
1 ‚àà ùëÄùëñ+1 and ùúë ‚àà ùëÄùëñ+2, etc. Since ùúå is accepting, the sequence ùëÄùëñ
ùëñ+1
ùëñ+2
must eventually hit the acceptance set ùêπ‚Ñì , i.e. they cannot all contain ùúì1
and ùúë.
Instead, some state in this sequence, say ùëÄ ùëó for some ùëó ‚â• ùëñ, must contain
ùúì2. Let ùëó be chosen minimal. Then ùúì1 ‚àà ùëÄ‚Ñé for ùëñ ‚â§ ‚Ñé < ùëó . We can now
apply the hypothesis for ùúì1 and ùëÄ‚Ñé for such ‚Ñé, as well as to ùúì2 and ùëÄ ùëó ,
and get that ùë§, ùëó ‚äß ùúì2 and ùë§, ‚Ñé ‚äß ùúì1
for all ‚Ñé with ùëñ ‚â§ ‚Ñé < ùëó . Hence, ùë§, ùëñ ‚äß ùúë.
Case ùúë = ùúì R ùúì
, ùúì
1

2. Similar to the previous case we get that {ùúì1
2} ‚äÜ ùëÄùëñ or
ùúì2 ‚àà ùëÄùëñ and ùúë ‚àà ùëÄùëñ+1. Again, this can be unrolled but this time there is no
argument ensuring termination of this unrolling. Hence, either ùúì2 ‚àà ùëÄ‚Ñé for
all ‚Ñé ‚â• ùëñ, or there is some ùëó ‚â• ùëñ such that ùúì1 ‚àà ùëÄ ùëó , and ùúì2 ‚àà ùëÄ‚Ñé for all ‚Ñé
with ùëñ ‚â§ ‚Ñé ‚â§ ùëó . Applying the
260
10 Linear-Time Temporal Logic
hypothesis again to all ùúì1 and ùúì2 and the corresponding Hintikka sets, we
get that ùë§ , ùëñ ‚äß ùúì
R ùúì
1
2 in both these cases.
‚óª
Putting Cor. 10.15, Thm. 10.24 and 10.19 together, we obtain the goal of a
translation from LTL into NBA of elementary complexity.
Corollary 10.25
O(‚à£ ùúë‚à£)
For every LTL formula ùúë there is an NBA Aùúë of size 2
such
that ùêø(Aùúë ) = ùêø(ùúë) .
10.3 From LTL to Very Weak Alternating Automata

While alternation generally allows languages to be represented with
exponentially smaller automata then nondeterministic ones, and they are
arguable closer to logical formulas with Boolean conjunctions and
disjunctions, they do not provide a more efficient way to translate MSO into
automata. The problem there is that existential quantification over second-
order variables is handled by alphabet projection which is only sound for
nondeterministic automata.
It is reasonable to ask whether this is still an obstacle for a much weaker
logic like LTL, especially since LTL does not feature quantification over
variables, let alone second-order ones. The answer is no, i.e. alternating
automata provide a framework for a direct translation from LTL formulas
that results in smaller automata than the NBA obtained in the previous
section that are generally of exponential size.
As it turns out, the automata obtained from LTL formulas have a very
special form. They are not only weak in the sense of Sect. 9.5 but in fact
syntactically even more specialised which we call being very weak.
+
For a positive Boolean formula ùëì ‚àà B (ùëÑ) and some ùëû ‚àà ùëÑ we simply write
ùëû ‚àà ùëì
to state that ùëû occurs syntactically in ùëì .
Definition 10.26 Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
0
) be an ABA. It is called very weak
‚Ä≤
(VWABA) if there is a partial order '‚â§' on ùëÑ such that for all ùëé ‚àà Œ£ and all
ùëû, ùëû ‚àà ùëÑ
‚Ä≤

‚Ä≤
with ùëû ‚àà ùõø(ùëû, ùëé) we have ùëû ‚â§ ùëû.
Very weak alternating automata are also known as being counter-free. The
reason is that a loop of length ùëò through the transition table can be seen as
the automaton's ability to "count modulo ùëò ." Now the presence of a total
order with the requirement that transitions do not ascend in this order,
precludes the existence of loops of length greater than 1.
This is only a very crude intuitive explanation for what being counterfree
means.
It does not mean that a language which intuitively requires counting
modulo some ùëò
greater than 1 cannot be VWABA-definable.
Example 10.27
ùúî
ùúî
The language (ùëéùëè)
‚à™ (ùëèùëé)
is recognised by the ABA shown in
Fig. 10.5. It is easily seen to be very weak by employing any of the three
partial orders that satisfy 0 > 1 > 3 and 0 > 2 > 3. Then transitions in this
ABA only ever lead to states that are smaller or equal in this order.
10.3 From LTL to Very Weak Alternating Automata
261
ùëé

‚àß
1
ùëè
0
3
ùëé , ùëè
ùëé
ùëè
‚àß
2
Fig. 10.5 Very weak ABA recognising (ùëéùëè)ùúî ‚à™ (ùëèùëé)ùúî.
It should be clear that every VWABA is also a WABA, i.e. being very weak is
a restriction of the concept of being weak. Remember that a weak
alternating automaton is one whose state space can be partitioned such that
each part either consists of accepting states or of non-accepting states only,
and there is a partial order on the parts such transitions never lead to parts
that are greater in this order. A very weak automaton is then a weak
automaton in which every part of the partition is a singleton set only.
Unlike WABA, VWABA are less expressive than general ABA, i.e. their
expressiveness is genuinely below that of ùúî-regular languages. Ex. 10.27 is
slightly ùúî
misleading by suggesting that when recognising a word of the form (ùëéùëè) ,
one would do counting modulo 2. A language that cannot be recognised by
VWABA ùúî
is, for example {ùëé ùëé . . .

0
1
‚àà {ùëé, ùëè}
‚à£ ‚àÄùëñ ‚àà N ‚à∂ ùëé2ùëñ = ùëé}. This does indeed require
proper counting modulo 2 in order to know whether a letter is required to
be ùëé or ùúî
ùúî
nor, whereas no counting is needed to recognise (ùëéùëè)
‚à™ (ùëèùëé)
: one simply needs
to verify alternation between each two adjacent in put symbols.
A formal proof of this upper bound on the expressiveness of VWABA would
require a bit more machinery, for instance the introduction of Ehrenfeucht-
Fra¬®ƒ±ss√© games on infinite words, as well as showing that they capture
exactly the expressiveness of FO and LTL. While this is true, we will only
show equi-expressiveness between LTL and VWABA here. We begin with the
translation of formulas into automata. It essentially shows that an LTL
formula can directly be regarded as a VWABA.
Theorem 10.28 For every LTL formula ùúë there is a VWABA Aùúë of size
O(‚à£ùúë‚à£) such that ùêø(Aùúë ) = ùêø(ùúë) .
Proof According to Cor. 10.15 we can assume ùúë to be given in NNF. This
incurs a linear blowup only. We define the ABA Aùúë as
( Sub(ùúë) ‚à™ {tt, ff}, Œ£, ùúë, ùõø, ùêπ)
where Œ£ is the alphabet underlying ùúë. The state space consists of all
subformulas of ùúë with possibly additional formulas tt and ff that are needed

in order to ensure that the transition function can always assign a successor
state. It is defined inductively on the structure of ùúë for all ùëé ‚àà Œ£ as follow s.
ùõø(tt, ùëé)
‚à∂= tt
ùõø(ff, ùëé)
‚à∂= ff
262
10 Linear-Time Temporal Logic
‚éß
‚é™
‚é™tt
, if ùëù ‚àà ùëé
ùõø( ùëù, ùëé)
‚à∂= ‚é®
‚é™
‚é™ff
, otherwise
‚é©
‚éß
‚é™

‚é™ff
, if ùëù ‚àà ùëé
ùõø(¬¨ ùëù, ùëé)
‚à∂= ‚é®
‚é™
‚é™tt
, otherwise
‚é©
ùõø(ùúì
, ùëé
, ùëé
, ùëé
1 ‚à® ùúì2
)
‚à∂= ùõø(ùúì1
) ‚à® ùõø(ùúì2
)
ùõø(ùúì
, ùëé
, ùëé

, ùëé
1 ‚àß ùúì2
)
‚à∂= ùõø(ùúì1
) ‚àß ùõø(ùúì2
)
ùõø(Xùúì, ùëé)
‚à∂= ùúì
ùõø(ùúì
U ùúì , ùëé
, ùëé
, ùëé
U ùúì
1
2
)
‚à∂= ùõø(ùúì2
) ‚à® (ùõø(ùúì1
) ‚àß ùúì1
2)

ùõø(ùúì
R ùúì , ùëé
, ùëé
, ùëé
R ùúì
1
2
)
‚à∂= ùõø(ùúì2
) ‚àß (ùõø(ùúì1
) ‚à® ùúì1
2)
Note that this is well-defined in the sense that ùõø(ùúì, ùëé) can unambiguously be
written
‚Ä≤
‚Ä≤
down as soon as ùõø(ùúì , ùëé) is known for the maximal genuine subformulas ùúì of
ùúì.
Also note that in state ùúì1 ‚à® ùúì2 for example, Aùúë employs existential
branching, but it does not branch into ùúì1 or ùúì2, instead it branches into the
options provided as the successors of ùúì1 and ùúì2. The reason simply is that
an automaton progresses to the next position in a word in every step,
whereas disjunction in the logic intuitively remains in the current state.

Intuitively, Aùúë checks, when being in state ùúì, whether ùúì is satisfied in the
current position of the underlying word. Hence, it is not surprising that ùúë
itself is the initial state.
At last, let ùêπ ‚à∂= {tt} ‚à™ {ùúì R ùúì
R ùúì
1
2 ‚à£ ùúì1
2 ‚àà Sub(ùúë)}. Thus, the states in which
A ùúë is allowed to reside forever are given by the R-subformulas, besides the
special state tt. The reason for this becomes clearer when considering the
fact that the transitions from states which are not U- or R-subformulas
always lead to genuinely smaller formulas (apart from the two Boolean
constants tt and ff). Hence, the only states that can be seen infinitely often
on a path of a run are such subformulas or tt or ff .
Three properties of Aùúë need to be verified. (i) The statement about it being
of size linear in ‚à£ùúë‚à£ should be clear. (ii) Aùúë is indeed a VWABA. To witness
this, take the relation '‚â§' on its state space defined by
‚Ä≤
‚Ä≤
ùúì
‚â§ ùúì
iff
ùúì
‚àà {tt, ff} ‚à™ Sub(ùúì )

which is easily seen to be a partial order. Moreover, transitions never lead
to states that are greater in this order.
(iii) At last, it remains to be seen that Aùúë is correct, i.e. that ùêø(Aùúë ) = ùêø(ùúë).
"‚äÜ" We show that for every accepting run ùúå of A
ùëé
. . .
ùúë
on a word ùë§ = ùëé0 1
‚àà Œ£ ùúî
whose root is labelled with ùúì ‚àà Sub(ùúë) ‚à™ {tt} we have ùë§ ‚àà ùêø(ùúì). This can be
done by induction on the structure of ùúì. The case of ùúì = t t is trivial.
Suppose that ùúì = ùëû for some ùëû ‚àà P . According to the definition of Aùúë 's
transition function, the root node ùë£0 has a single successor ùë£1 (labelled tt).
This is only possible if ùëû ‚àà ùëé0. Hence, ùë§ ‚äß ùëû. The case of ùúì = ¬¨ùëû is done
analogously.
10.3 From LTL to Very Weak Alternating Automata
263
Suppose that ùúì = ùúì1 ‚à® ùúì2. By hypothesis, if there is an accepting run on ùë§
with root label ùúì
, ùëé
ùëñ
then ùë§ ‚äß ùúìùëñ for ùëñ ‚àà {1, 2}. Remember that ùõø(ùúì1 ‚à® ùúì2

0) =
ùõø(ùúì , ùëé
, ùëé
1
0) ‚à® ùõø(ùúì2
0), and that any model ùëÄ of a Boolean formula ùëì ‚à® ùëî is also a model of ùëì
or of ùëî. Hence, an accepting run of ùë§ with root label ùúì1 ‚à® ùúì2 can be turned
into an accepting run on ùë§ with root label ùúìùëñ for some ùëñ ‚àà {1, 2}. By the
hypothesis, we have ùë§ ‚äß ùúìùëñ, and therefore ùë§ ‚äß ùúì1 ‚à® ùúì2, i.e. ùë§ ‚àà ùêø(ùúì).
The case of ùúì = ùúì1 ‚àß ùúì2 is similar. An accepting run with root label ùúì1 ‚àß ùúì2
can be turned into accepting runs with root labels ùúì1 and ùúì2 by simply
changing the root label accordingly. This is possible because any model ùëÄ of
a positive Boolean formula ùëì ‚àß ùëî is also one of ùëì and of ùëî. The induction
hypothesis then yields ùë§ ‚äß ùúìùëñ
for both ùëñ ‚àà {1, 2} and, thus, ùë§ ‚àà ùêø(ùúì ).
‚Ä≤
Suppose that ùúì = Xùúì . Note that the root of an accepting run with root label ùúì
has
‚Ä≤
a single successor labelled ùúì , and the subtree rooted there is an accepting
run on
‚Ä≤
‚Ä≤
ùë£ = ùëé ùëé

. . .
1
2
By the hypothesis we have ùë£ ‚äß ùúì and therefore ùë§ ‚äß Xùúì , i.e. ùë§ ‚àà ùêø(ùúì ).
This leaves only the cases of the two temporal operators U and R open.
These are certainly the most interesting ones.
Suppose that ùúì = ùúì U ùúì
, ùëé
, ùëé
1
2. Remember that ùõø(ùúì, ùëé0) = ùõø(ùúì2
0) ‚à® (ùõø(ùúì1
0) ‚àß ùúì).
Hence, there are two possibilities for the shape of an accepting run on ùë§
with root label ùúì.
‚Ä¢ The successors of the root node form a model of ùõø(ùúì , ùëé
2
0). In this case, we
can change the root label to ùúì2 and the result is still an accepting run. By
the hypothesis we get ùë§ ‚äß ùúì 2 and therefore ùë§ ‚äß ùúì U ùúì
1

2, i.e. ùë§ ‚àà ùêø(ùúì).
‚Ä¢ The successors of the root node form a model of ùõø(ùúì , ùëé
1
0) ‚àß ùúì. Since ùúì1 is
a genuine subformula of ùúì, the latter cannot occur in ùõø(ùúì , ùëé
1
0). Hence, the
successors of the root node can be split as follows: one is labelled ùúì, and the
others form a model of ùõø(ùúì , ùëé
1
0). Now, ùúì is clearly not smaller than ùúì itself
so we cannot apply the induction hypothesis to it. However, we can observe
that ùúì, being an U-formula, is not an accepting state. Moreover, the
reasoning about the shape of the run at the top labelled ùúì can be applied to
the node labelled ùúì on level 1 as well. This way, we obtain a path through ùúå
of nodes all labelled ùúì. Since ùúì is non-accepting, this cannot be an infinite
path. Hence, it must eventually end with some node on some level ùëò ,
labelled ùúì such that its successors form a model of ùõø(ùúì , ùëé
2
ùëò ). We can apply the induction hypothesis
here to obtain ùëé . . .
ùëò
‚äß ùúì2. We can also apply it to all previous nodes on this path

and similar reasoning to the case of conjunctions above to obtain ùëé ùëé
. . .
ùëó
ùëó +1
‚äß ùúì1
for all ùëó ‚àà [ùëò ]. But then ùë§ ‚äß ùúì U ùúì
1
2, i.e. ùë§ ‚àà ùêø(ùúì).
At last, suppose that ùúì = ùúì R ùúì
1
2. This is done similarly to the previous case. The
only difference is the observation that here state ùúì is accepting. So the run ùúå
contains a path that is either infinite and contains nodes labelled ùúì only. In
this case we can decompose the transition function for R-formulas and see
that ùëé ùëé
. . .
ùëó
ùëó +1
‚äß ùúì2 for
all ùëó ‚â• 0. Or this path is finite in which case it ends on some level ùëò , and
with similar reasoning as above we also obtain ùëé ùëé
. . .

R ùúì
ùëò
ùëò +1
‚äß ùúì1. In either case we get ùë§ ‚äß ùúì1
2,
i.e. ùë§ ‚àà ùêø(ùúì).
264
10 Linear-Time Temporal Logic
"‚äá" Suppose that ùë§ = ùëé ùëé . . .
0
1
‚àà ùêø(ùúë), i.e. ùë§ ‚äß ùúë. We can construct, by induction
on the structure of ùúë, an accepting run ùúåùúë of Aùúë .
If ùúë = tt then simply let ùúåùúë consist of a single path with all nodes labelled tt.
The case of ùúë = ff is impossible because ùë§ /
‚äß ff. The cases of ùúë = ùúì1 ‚à® ùúì2 and
ùúë = ùúì1 ‚àß ùúì2 are handled as above using the observation that models of
disjuncts are also models of disjunctions, etc. Thus, an accepting run ùúåùúì
with root label ùúìùëñ can ùëñ
be turned into an accepting run ùúåùúì
simply by relabelling the root node.

1 ‚à® ùúì2
If ùúë = Xùúì than simply add a new node above the root of ùúåùúì on ùë§ and label it
Xùúì
to obtain an accepting run witnessing that ùëéùë§ ‚äß Xùúì for any ùëé ‚àà Œ£ .
If ùúë = ùúì U ùúì
. . .
. . .
1
2, then take ùëò such that ùëé ùëò
‚äß ùúì2 and ùëé ùëó
‚äß ùúì1 for all ùëó < ùëò.
We can now create a sequence of accepting runs ùúå , . . . , ùúå
ùëò
0 as follows. Let ùúåùëò be an
accepting run witnessing ùëé . . .
ùëò
‚äß ùúì2 which exists according to the hypothesis for
ùúì
. . .
2. Change its root label to ùúë. Note that this is sound because if ùëé ùëò

‚äß ùúì2 then
ùëé
. . .
ùëò
‚äß ùúë.
Now suppose that ùúå ùëó has been constructed already. To obtain ùúå ùëó‚àí1, take a
new root node with label ùúë and two kinds of successors: one successor that
is the root of ùúå ùëó , the others obtained as the successors of the root node in
an accepting run witnessing ùëé
. . .
ùëó ‚àí1
‚äß ùúì1. By the construction of the transition function, in particular the fact
that ùëÄ ‚à™ {ùúë} is a model of ùõø(ùúë, ùëé
, ùëé
ùëó ‚àí1) if ùëÄ is a model of ùõø(ùúì1
ùëó ‚àí1), the
obtained tree ùúå
ùëé
. . .
ùëó ‚àí1 is a run on ùëé ùëó‚àí1
ùëó
It is accepting because every infinite path

is also an infinite path in one of the subtrees that are being glued together
in this construction. Thus, we can take ùúåùúë as ùúå0 obtained in this way.
As last, if ùúë = ùúì R ùúì
1
2, then ùúå ùúë is constructed in a similar way. Note that, if ùë§ ‚äß ùúë
then ùë§ ‚äß ùúì U
2
(ùúì1 ‚àß ùúì2) or ùë§ ‚äß Gùúì2. In the first case, ùúåùúë can be constructed as in the
general case for U-formulas. In the second case, to take an infinite path of
nodes all labelled ùúë, and each of them receives, as additional successors,
the successors of the root node of ùúåùúë which exists by hypothesis. Again, the
result is an accepting 2
run ùúåùúë with root labelled ùúë because its infinite paths are either those that
have a suffix in one of the accepting runs that are obtained by induction, or
it is the single extra infinite path which is labelled ùúë all along and, ùúë being a
R-formula, consists of accepting states only.
‚óª
The converse of Thm. 10.28 is in fact true as well: VWABA capture exactly
the expressive power of LTL. The following lemma formulates a key
observation used in the proof of that result.
Lemma 10.29
P
Let ùúë, ùúì ‚àà LTL over P , and ùêø ‚äÜ Œ£ ùúî where Œ£ = 2 .
a) If ùêø is the least language such that ùêø = ùêø(ùúì) ‚à™ (ùêø(ùúë) ‚à© Œ£ùêø) then ùêø = ùêø(ùúë
U ùúì) .

b) If ùêø is the greatest language such that ùêø = ùêø(ùúì)‚à©(ùêø(ùúë)‚à™Œ£ùêø) then ùêø =
ùêø(ùúëRùúì) .
Proof Here, least and greatest is said in reference to the partial order '‚äÜ'
on languages. In both cases, it is easy to see, because of the equivalences ùúë
U ùúì
‚â° ùúì ‚à® (ùúë ‚àß X(ùúë U ùúì))
ùúë R ùúì
‚â° ùúì ‚àß (ùúë ‚à® X(ùúë R ùúì))
10.3 From LTL to Very Weak Alternating Automata
265
that ùêø(ùúë U ùúì), resp. ùêø(ùúë R ùúì) is a solution to the corresponding equation. It
remains to be seen that it is the least solution in case of the U-formula and
the greatest in the other case.
(a) Suppose ùêø is such that ùêø = ùêø(ùúì) ‚à™ (ùêø(ùúë) ‚à© Œ£ùêø). We need to show that ùêø
(ùúë U ùúì) ‚äÜ ùêø. Take some ùë§ ‚àà ùêø(ùúë U ùúì), i.e. there is a ùëò ‚àà N s.t. ùë§, ùëò ‚äß ùúì and
ùë§ , ùëó ‚äß ùúë for all ùëó < ùëò . For ùëñ ‚àà N let ùë§ùëñ denote the ùëñ-th suffix of ùë§ with ùë§0
= ùë§ . Then we have
ùë§ ùëò
‚àà ùêø(ùúì)
‚äÜ ùêø(ùúì) ‚à™ (ùêø(ùúë) ‚à© Œ£ ùêø)
=
ùêø .
Moreover, for every ùëñ > 0 with ùë§ùëñ ‚àà ùêø we ha ve

ùë§ ùëñ‚àí1 ‚àà ùêø(ùúë) ‚à© Œ£ùêø ‚äÜ ùêø(ùúì) ‚à™ (ùêø(ùúë) ‚à© Œ£ùêø) = ùêø .
Thus, we have ùë§0 = ùë§ ‚àà ùêø which was to be shown.
(b) Suppose here that ùêø = ùêø(ùúì) ‚à© (ùêø(ùúë) ‚à™ Œ£ùêø). The claim is that ùêø(ùúë R ùúì) is
the greatest solution to the corresponding equation, so we need to show that
ùêø ‚äÜ ùêø(ùúë R ùúì). Take some ùë§ ‚àà ùêø. Again, let ùë§ùëñ denote its ùëñ-th suffix for ùëñ ‚àà
N. W e have
ùë§ 0 = ùë§ ‚àà ùêø = ùêø(ùúì) ‚à© (ùêø(ùúë) ‚à™ Œ£ùêø)
and therefore ùë§, 0 ‚äß ùúì and, additionally, ùë§, 0 ‚äß ùúë or ùë§1 ‚àà ùêø. Applying the
same reasoning to ùë§1 yields ùë§, 1 ‚äß ùúì, and ùë§, 1 ‚äß ùúë or ùë§, 2 ‚àà ùêø. Thus,
either there is some ùëò such that ùë§, ùëñ ‚äß ùúì for all ùëñ ‚â§ ùëò and ùë§, ùëò ‚äß ùúë. Or there
is no such ùëò and we have ùë§ , ùëñ ‚äß ùúì for all ùëñ ‚àà N. In both cases we have ùë§, 0
‚äß ùúë R ùúì, i.e. ùë§ ‚àà ùêø(ùúë R ùúì) which was to be shown.
‚óª
The distinction between least and greatest solutions is necessary. For
example, Lemma 10.29 states that ùêø(ùëù U ùëû) is the least ùêø such that ùêø =
ùêø(ùëû) ‚à™ (ùêø(ùëù) ‚à© Œ£ùêø).
This equation has another solution, namely ùêø(ùëù U ùëû ‚à® Gùëù). It is not hard
to verify that
ùêø ( ùëù U ùëû ‚à® G ùëù)
= ùêø(ùëû) ‚à™ (ùêø( ùëù) ‚à© Œ£ ùêø( ùëù U ùëû ‚à® G ùëù)) .
Moreover, we clearly have ùêø(ùëù U ùëû ‚à® Gùëù) ‚äá ùêø(ùúë U ùúì), so this second
solution is indeed greater-or-eq ual.
Finding a non-greatest solution to the corresponding equation for R-
formulas is left as an exercise.
We use this lemma to show that the language of a VWABA is LTL-definable.

In the following theorem, we assume the alphabet size, resp. number of
atomic propositions to be fixed. Otherwise the size estimation becomes
more complicated.
Theorem 10.30
O(‚à£A‚à£)
For every VWABA A there is an LTL formula ùúëA of size 2
such that ùêø(ùúëA) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, . . . , ùëû
ùêº
) be a VWABA with ùëÑ = {ùëû0
ùëõ‚àí1}. W.l.o.g. we
assume that the partial order '‚â§' witnessing that A is indeed a VWABA,
satisfies ùëûùëñ > ùëû ùëó for all 0 ‚â§ ùëñ < ùëó < ùëõ. This means in particular that all
states must be reachable from the initial state which is of course a
reasonable assumption, and that ùëûùêº = ùëû0.
266
10 Linear-Time Temporal Logic
For ùëñ ‚àà [ùëõ] let ùêø
, ùõø, ùêπ
ùëñ
‚à∂= ùêø(ùëÑ, Œ£, ùëûùëñ

) consist of all words that are accepted by A
when started in state ùëûùëñ. We construct, for each ùëñ = ùëõ ‚àí 1, . . . , 0, an LTL
formula ùúëùëñ
such that ùêø(ùúëùëñ) = ùêøùëñ. When constructing ùúëùëñ we can assume ùúë ùëó to be
constructed already for any ùëó > ùëñ. It should be clear that ùúëA ‚à∂= ùúë0 is then a
formula correctly describing the language of A.
In each step, we obtain ùúëùëñ as a solution to a recursive description of ùêøùëñ. The
construction distinguishes two cases.
Case 1, ùëûùëñ /
‚àà ùêπ . The language ùêøùëñ of all words accepted by A when started in state ùëûùëñ
is the least solution of the eq uation
ùêø
, ùëé
ùëñ
= ‚ãÉ tr ùëé(ùõø(ùëûùëñ
))
(10.1)
ùëé‚ààŒ£
where tr ùëé(ùúì1 ‚à® ùúì2) ‚à∂= tr ùëé(ùúì1) ‚à™ tr ùëé(ùúì2), tr ùëé(ùúì1 ‚àß ùúì2) ‚à∂= tr ùëé(ùúì1) ‚à© tr
ùëé(ùúì2) and tr ùëé(ùëû ùëó ) ‚à∂= {ùëé}Œ£ ùúî ‚à© Œ£ùêø ùëó .
Note that ùõø(ùëû , ùëé
ùëñ

) cannot contain any state ùëû ùëó with ùëó < ùëñ, and for all ùëó > ùëñ, ùêø ùëó is already
described by an LTL formula ùúë ùëó . The right-hand side of (10.1) is a positive
Boolean combination of terms of the form {ùëé}Œ£ ùúî for some ùëé ‚àà Œ£, and terms
Œ£ùêø ùëó
for some ùëó ‚â• ùëñ. The entire expression can be rewritten into disjunctive
normal form, i.e. a union of intersections, and divided into those
intersections that contain Œ£ùêøùëñ
and those that do not. Hence, we have
ùëõ
ùëö
ùëõ
ùëö
1
1, ùëó
2
2, ùëó
ùêø
ùõº
ùõΩ
ùëñ
= ( ‚ãÉ ‚ãÇ
ùëó , ‚Ñé )

‚à™
(( ‚ãÉ ‚ãÇ
ùëó , ‚Ñé ) ‚à© Œ£ ùêø ùëñ )
(10.2)
ùëó =1 ‚Ñé=1
ùëó =1 ‚Ñé=1
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùõº
ùõΩ
where all ùõº ùëó,‚Ñé and ùõΩ ùëó,‚Ñé are terms of the form {ùëé}Œ£ ùúî for some ùëé ‚àà Œ£ or Œ£ùêø
ùëó for some ùëó > ùëñ. The part on the right of the top-level union additionally
uses the distributivity law for ‚à™ and ‚à© to extract the common factor Œ£ùêøùëñ
from all the conjunctions that contain it.
Next we observe that the two languages ùõº and ùõΩ are definable in LTL by
formulas ùúë ùõº and ùúëùõΩ respectively, simply as Boolean combinations of
formulas of the form ùúíùëé
for language terms {ùëé}Œ£ ùúî, and Xùúë ùëó for language terms Œ£ùêø ùëó .
The last step is then given by the observation that ùêøùëñ is, as the least solution
to the equation ùêø
U ùúë
ùëñ
= ùõº ‚à™ (ùõΩ ‚à© Œ£ ùëã ), expressible in LTL as ùúëùëñ ‚à∂= ùúëùõΩ

ùõº
according to
Lemma 10.29.
Case 2, ùëûùëñ ‚àà ùêπ. This is done in the same way, but here we derive an
equation in conjunctive normal form as ùêøùëñ = ùõº ‚à© (ùõΩ ‚à™ Œ£ùêøùëñ) with the terms ùõº
and ùõΩ not containing Œ£ùêøùëñ itself. Also, we are now interested in the greatest
solution to this equation because an accepting run can contain a path that
cycles through ùëû ùëñ.
According to Lemma 10.29, ùêø
R ùúë
ùëñ is then described by ùúëùëñ ‚à∂= ùúëùõΩ
ùõº where ùúë ùõº and
ùúë ùõΩ are, as in the previous case, LTL formulas for the languages expressed
by ùõº and ùõΩ respectively .
While correctness of ùúëA follows immediately from this construction, we need
to verify the claim on its size. The construction only creates linearly many
formulas of
10.3 From LTL to Very Weak Alternating Automata
267
the form ùúëùëñ, namely one for each state of A, and each step relies on the
transformation of a Boolean formula into disjunctive or conjunctive normal
form. The blowup involved in this is at most exponential: a formula in
disjunctive or conjunctive normal form over ‚à£Œ£‚à£ + ‚à£ùëÑ‚à£ elementary
formulas can be seen as a set of sets of these ùëõ
ùëõ

ùëõ formulas. Hence, there are at most 22 of them but each is of size O(2 ) at
most.
Note that these exponential blowups do not get iterated: in the construction
for ùúëùëñ, all ùúë ùëó with ùëó > ùëñ can be seen as fixed and elementary for the
conversion into disjunctive and conjunctive normal forms.
‚óª
Example 10.31 Take the VWABA A from Fig. 10.5 over Œ£ = {ùëé, ùëè}. The
partial order witnessing its very weakness is already compatible with the
state names.
I.e. in order to derive an LTL formula for ùêø(A), we can proceed by
successively constructing ùúë , ùúë , ùúë , ùúë
3
2
1
0 in this order.
We have ùêø(ùúë3) = Œ£ùúî, i.e. we can simply take ùúë3 ‚à∂= tt. We could also carry
out the construction and compute the largest solution to the equation
ùëã
= {ùëé}ùëã ‚à™ {ùëè}ùëã
= {ùëé, ùëè}ùëã
= Œ£ ùúî ‚à© (‚àÖ ‚à™ Œ£ ùëã )
as ff R tt. Note that ùêø(ff) = ‚àÖ and ùêø(tt) = Œ£ ùúî. Since ff R tt ‚â° Gtt ‚â° tt, we
obtain the same ùúë3 in this case.
Next we compute ùúë2. The corresponding equation is

ùëã
= {ùëé}ùêø(ùúë3) = {ùëé}ùêø(ùúë3) ‚à™ (‚àÖ ‚à© Œ£ ùëã)
with corresponding solution ff U ( ùúíùëé ‚àß Xùúë3) ‚â° ùúíùëé ‚àß Xtt ‚â° ùúíùëé =‚à∂ ùúë2.
We equally obtain ùúë1 as ùúíùëè. Since there is no recursion in the equations in
these two cases we obtain unique solutions, i.e. least and greatest solutions
coincide.
Strictly speaking, we were looking for the least solution because states 1
and 2 are non-accepting. The fact that we could equally have chosen the
greatest solutions since they are the same, is reflected by the fact that the
language of A remains unchanged when these two states or one of them is
made accepting.
At last, the equation for obtaining ùúë0 is
ùëã
= {ùëé}(ùêø(ùúë1) ‚à© ùëã) ‚à™ {ùëè}(ùêø(ùúë2) ‚à© ùëã)
= ({ùëé}ùêø(ùúë1) ‚à© {ùëé}ùëã) ‚à™ ({ùëè}ùêø(ùúë2) ‚à© {ùëè}ùëã)
= ({ùëé}ùêø(ùúë1) ‚à© Œ£ùëã) ‚à™ ({ùëè}ùêø(ùúë2) ‚à© Œ£ùëã)
= ({ùëé}ùêø(ùúë1) ‚à™ {ùëè}ùêø(ùúë2)) ‚à© Œ£ùëã = ({ùëé}ùêø(ùúë1) ‚à™ {ùëè}ùêø(ùúë2)) ‚à© ( ‚àÖ ‚à™ Œ£ùëã)
whose greatest solution is described by
ff R ((ùúíùëé ‚àß Xùúë1) ‚à® (ùúíùëè ‚àß Xùúë2)) ‚â° G((ùúíùëé ‚àß Xùúíùëè) ‚à® (ùúíùëè ‚àß Xùúíùëé)) =‚à∂ ùúë0
ùúî
ùúî
which is indeed an LTL formula describing (ùëéùëè)
‚à™ (ùëèùëé)

.
P
We remark that, when dealing with alphabets of the form Œ£ = 2 , it is useful
to work with a slightly different format for the transition function as it leads
to smaller Boolean expressions in general. Note that
268
10 Linear-Time Temporal Logic
P
+
P
+
ùëÑ √ó 2
‚Üí B (ùëÑ)
‚âÉ ùëÑ ‚Üí (2
‚Üí B (ùëÑ ))
P
+
for a state set ùëÑ in general. Moreover, the type 2
‚Üí B (ùëÑ) can be internalised
when allowing positive Boolean formulas over states and literals of
propositions, i.e.

ùúî
possibly negated propositions. Reconsider the VWABA for the language
(ùëéùëè)
‚à™
ùúî
(ùëèùëé)
from Fig. 10.5. Suppose that the underlying alphabet {ùëé, ùëè} has arisen from
a singleton set of propositions P = {ùëù}, and ùëé = {ùëù}, ùëè = ‚àÖ. Then the
transition
+
‚àí
function of that VWABA can be written as a function of type ùëÑ ‚Üí B (ùëÑ ‚à™ P
‚à™ P )
‚àí
where P
‚à∂= {¬¨ùëû ‚à£ ùëû ‚àà P } as follows.
ùëû
ùõø(ùëû)
0
0 ‚àß ((ùëù ‚àß 1) ‚à® (¬¨ùëù ‚àß 2))
1
¬¨ ùëù ‚àß 3

2
ùëù ‚àß 3
3
3
10.4 An Application: Formal Verification
An important application of LTL is its use as a formal specification
language for properties of dynamic systems with discrete state spaces. Such
systems arise from hardware or software, and "dynamic" here simply
indicates that such systems evolve in time by experiencing state changes.
This happens for instance for hardware circuits that compute, in a sequence
of cycles, values in registers depending on changing input signals. It also
occurs with software: executing a program is typically done in a sequence
of atomic steps that change the underlying memory which gives rise to a
natural notion of state of a program.
Both hardware and software are often modelled to be nondeterministic. For
instance, the states that a circuit goes through will depend on the values of
the (un-known) input signals. The same happens for software whose
concrete behaviour is determined by user input. There are other reasons for
modelling such systems nondeterministically. For example programs with
components working in parallel may be executed in a number of
interleaving ways.
We focus our attention on non-terminating programs like components of an
operating systems, sensors continuously delivering data, etc. This is not a
restrictive view but rather a more general one since terminating programs
can always be seen as non-terminating ones that eventually reside in a
specific state of termination. On the other hand, there is no similarly simple
way to model non-terminating behaviour using terminating programs.
We introduce a simple, intuitive model of such dynamic systems, called
labelled transition systems. It is very reminiscent of finite automata, and
this is in fact what allows formal specifications of program behaviour to be

formally verified. In this setup, an LTS specifies program behaviour in
terms of all the possible sequences of states changes it can do in its
execution. A formal specification given as an LTL
formula determines desired or undesired program behaviour. Checking the
overall
10.4 An Application: Formal Verification
269
ùëù , ùëû
0
1
2
3
4
5
ùëù
ùëù
Fig. 10.6 Example of a transition system modelling a program with six
states.
behaviour against it then decides whether the program is correct with
respect to this specification or contains an error. Such a check is done using
an automaton, specifically an NBA, that is equivalent to the given LTL
formula.
10.4.1 Labelled Transition Systems and Traces

Definition 10.32 Let P be a finite set of propositions. A labelled transition
system (LTS) over P is a T = (ùëÜ, √ê‚Üí, ùêº, ùúÜ) where (ùëÜ, √ê‚Üí) is a finite,
directed graph with node set ùëÜ and edge relation "√ê‚Üí" that is assumed to
be left-total, i.e. for every ùë† ‚àà ùëÜ
there is some ùë° ‚àà ùëÜ such that ùë† √ê‚Üí ùë°. Furthermore, ùêº ‚äÜ ùëÜ is a set of
designated initial P
states, and ùúÜ ‚à∂ ùëÜ ‚Üí 2
labels states with sets of propositions.
The size of the LTS T is measured in terms of the number of its states: ‚à£T ‚à£
‚à∂= ‚à£ùëÜ‚à£, even though the number of transitions can be quadratic in that.
An LTS naturally represents the behaviour of a state-based program in time.
Each maximal path through the underlying graph is a possible execution of
the modelled system. Initial states can be used to restrict the executions'
starts. This is very natural for programs that are run starting at particular
lines of code and with assumed initial values for their variables.
Example 10.33 An example of an LTS is shown in Fig. 10.6. It represents
an abstract program that can assume six different states, and the valid state
changes are given by the edge relation in this graph. The model of this
program is nondeterministic, there is no unique successor state in states 0
and 5.
The states' labels represent atomic propositions that hold true in the
respective states. In a concrete example, this could represent some truth
value like "the green light is on" etc.
One may wonder where to see the program in a more traditional form in
this LTS.
This is a somehow meaningless quest: the LTS is the program. It is given a
very simple semantics: the finite graph represents possibly infinitely many
infinite paths starting in its initial states. This is nothing more than a

language of ùúî-words over the alphabet induced by the powerset of the
underlying set of propositions.
270
10 Linear-Time Temporal Logic
However, not all examples need to be as abstracted away from programs in
a more traditional form.
Example 10.34 Consider a system of three components running in parallel,
one of which is a producer that adds items to a queue ùëÑ for as long as it
has not reached its maximal capacity. The other two are consumers that
remove items when ùëÑ is non-empty. Their behaviour is given in pseudocode
as follows.
1: procedure Producer
1: procedure Consumer
2:
while true do
2:
while true do
3:
if ¬¨ùëÑ. full then
3:
if ¬¨ùëÑ. empty then
4:
ùëÑ . addItem

4:
ùëÑ . removeItem
Fig. 10.7 shows an LTS modelling the system in wich each step of the entire
system consists of a single step of one of its components. Here we assume
that the capacity of the shared queue ùëÑ is 2. The states of the entire system
can be described as a quadruple (ùëê , ùëù, ùëê , ùëû
1
2
) where ùëù, ùëêùëñ ‚àà {3, 4} point to the line in the code that is to be executed
next in the producer and the two consumers, and ùëû ‚àà {0, 1, 2} represents
the number of items currently held by ùëÑ. We ignore the outer while loops
and start the system in state (3, 3, 3, 0). Note that each component has
transitions from line 3
to either 3 and 4, and from line 4 back to line 3 again. For brevity, we write
3330
instead of (3, 3, 3, 0) etc.
The acute reader may have noticed that, besides the described states, the
system can also enter an error state in two different ways. This is modelled
by the addition of states undr and over representing failures because of
queue under-, resp. overflows.
While it may not be imminent to see from the pure source code how a queue
underflow can occur for instance, Fig. 10.7 reveals what the problem is.
Simply take any path from the initial state 3330 to the failure state undr, for
example 3330 ‚Üí 3430 ‚Üí 3331 ‚Üí 4331 ‚Üí 4341 ‚Üí 4330 ‚Üí undr .
Note that a transition from ùëê
ùëû

ùëû
13ùëê2
to ùëê14ùëê2
means that the producer has checked
that the queue is not full and gets ready to insert another item. A transition
from 3ùëùùëê ùëû
ùëû
2
to 4ùëùùëê2 means that the first consumer has checked that the queue is not
empty and is getting ready to remove the next item. The same holds for the
second consumer and a change from state ùëê ùëù
ùëù
1
3ùëû to ùëê1 4ùëû. Hence, the path above corresponds to the
following program execution, starting with the empty queue:
a) Producer checks for non-fullness and inserts. Queue now holds one item.
b) Consumer 1 checks for non-emptiness and gets ready to remove but does
not remove yet. Queue still holds one item.
c) Consumer 2 checks for non-emptiness and removes the item. Queue now
is empty.
d) Consumer 1 executes the action to remove one item which fails.
As mentioned above, there is an implicit formal semantics to LTS as models
of programs via the set of executions.

10.4 An Application: Formal Verification
271
3330
3331
3332
4330
3430
3340
4331
3431
3341
4332
3432
3342
4430
4340
3440
4431
4341
3441

4432
4342
3442
undr
4440
4441
4442
over
fail
fail
Fig. 10.7 Labelled transition system modelling the global behaviour of a
producer and two consumers interacting via a queue of bounded capacity.
Definition 10.35 Let T = (ùëÜ, √ê‚Üí, ùêº, ùúÜ) be an LTS over P. A path (in T ) is
an infinite ùúî
sequence ùúã = ùë† , ùë† , . . .
0
1
‚àà ùëÜ
such that ùë†0 ‚àà ùêº and ùë†ùëñ √ê‚Üí ùë†ùëñ+1 for all ùëñ ‚àà N.
The path ùúã = ùë† , ùë† , . . .
0

1
induces the trace ùúÜ(ùë†0), ùúÜ(ùë†1), . . . in T . We write ùêø(T ) for the set of all traces
induced by some path in T .
P
Note that ùêø(T ) is a language of ùúî-words over 2 . It is not hard to see that it
is ùúî-regular, at least for the LTS as they are defined here, namely based on
finite state spaces. We remark that LTS can of course also be defined to be
of possibly infinite size, and then their languages exceed ùúî-regularity in
general. This also raises questions about finite representability etc. which
are beyond the scope of this short introduction to LTS and their use in
program specification and verification.
We recall the concept of weakness of an automaton which we studied
predom-inantly with regards to alternating automata. The concept can
equally be used for nondeterministic automata, though. Remember that an
automaton is weak if its state set can be partitioned such that each part
consists entirely of accepting or of non-accepting states only, and each
cycle of transitions remains within a single part.
Theorem 10.36 Let T be a (finite) LTS. There is a WNBA AT of size ‚à£T ‚à£ +
1 such that ùêø(AT ) = ùêø(T ) .
Proof Let T = (ùëÜ, √ê‚Üí, ùêº, ùêπ) be an LTS over P. Take a new state ùë†ùêº such
that ùë†ùêº /‚àà ùëÜ.
P
We construct the NBA A
, ùõø, ùëÜ
T
as (ùëÜ ‚à™ {ùë†ùêº }, Œ£, ùë†ùêº

‚à™ {ùë†ùêº }) where Œ£ = 2
as usual
and, for all ùë†, ùë° ‚àà ùëÜ and ùëé ‚àà Œ£:
(ùë†, ùëé, ùë° ) ‚àà ùõø
iff
ùë† √ê‚Üí ùë° and ùëé = ùúÜ(ùë° ) .
Additionally, we have (ùë† , ùúÜ
ùêº
(ùë° ), ùë° ) ‚àà ùõø for every ùë° ‚àà ùêº .
The claim on the size of AT is easily seen to be true. It is equally easy to see
that AT is indeed weak since all its states are final.
At last, we have ùêø(AT ) = ùêø(T ) because of the following consideration.
First note that every run in AT is an accepting one since there are no non-
accepting
272
10 Linear-Time Temporal Logic
states. Then a path ùúã = ùë† , ùë† , . . .
0
1
with corresponding trace ùë§ = ùúÜ(ùë†0), ùúÜ(ùë†1), . . .
induces a necessarily accepting run ùúå = ùë† , ùúÜ

, ùúÜ
, . . .
ùêº
(ùë†0), ùë†0
(ùë†1), ùë†1
through AT on
ùë§ . Conversely, the projection of an accepting run to the underlying word is
a trace in T .
‚óª
10.4.2 Model Checking
The model checking problem for LTL is: given a finite LTS T and an LTL
formula ùúë, do all traces of T satisfy the specification ùúë, i.e. is ùêø(T ) ‚äÜ ùêø(ùúë)?
This formalises the following task: given a model T of a dynamic state-
based system and a specification ùúë of correct runtime behaviour, do all
possible executions of the system adhere to this specification? Note the
implicit universal quantification over all traces. So in this setting which is
also called the linear-time framework vs. the so-called branching-time
framework, a program is identified with the set of its possible runs, and
correctness means that all possible runs are correct w.r.t. a specification
about their behaviour in time which is modelled as an infinite sequence of
moments. Likewise, a program is correct w.r.t. ùúë if it does not have a run
that does not satisfy ùúë .
The model checking problem for LTL can be solved algorithmically using
the translation from LTL into NBA (Cor. 10.25), together with the view of an
LTS as an NBA of at most exponential size accepting all its traces (Thm.
10.36). Hence, model checking for LTL reduces (via an exponential-time
reduction) to the inclusion problem for NBA which itself requires

exponential time to solve, leading to a decision procedure that is doubly
exponential in the size of the formula. This is not optimal, though.
First, we have
ùêø (T ) ‚äÜ ùêø(ùúë)
iff
ùêø (T ) ‚à© ùêø(ùúë) = ‚àÖ
iff
ùêø (T ) ‚à© ùêø(¬¨ùúë) = ‚àÖ
i.e. by making use of the fact that LTL is closed under negation we can
reduce the model checking problem to the problem of emptiness of the
intersection of two ùúî-regular languages. Since negating an LTL formula
incurs at most a linear blowup by adding a negation symbol on top and
turning the result into NNF, required for further procedures, while
complementing an NBA incurs an exponential blowup, we have saved one
exponential and reduced the complexity of model checking to singly
exponential time.
Second, while ùúî-regular languages are closed under intersections (Thm.
5.17), the construction with an extra counter in the product NBA is
unnecessarily complex for the purposes here. According to Cor. 10.25, ùêø(¬¨ùúë)
can be expressed by an NBA A¬¨ùúë , and according to Thm. 10.36, ùêø(T ) can
be expressed by a WNBA AT , so we have
ùêø (T ) ‚à© ùêø(¬¨ùúë) = ‚àÖ
iff
ùêø (AT ) ‚à© ùêø(A¬¨ùúë ) = ‚àÖ .
Hence, model checking LTL reduces to the emptiness problem for the
intersection of an NBA- and a WNBA-definable language. We observe that

such an intersection
10.4 An Application: Formal Verification
273
can be recognised by a simpler NBA than the one that is obtained via the
general construction for the intersection of two NBA-definable languages.
Theorem 10.37 Let A be an NBA and B be a WNBA. There is an NBA C of
size at most ‚à£A‚à£ ‚ãÖ ‚à£B‚à£ such that ùêø(C) = ùêø(A) ‚à© ùêø(B) .
Proof
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
Let A = (ùëÑ, Œ£, ùëû , ùõø, ùêπ
, Œ£, ùëû , ùõø , ùêπ
ùêº
) and B = (ùëÑ
). We construct C via a
ùêº
‚Ä≤
‚Ä≤
‚Ä≤

straightforward product construction as (ùëÑ √ó ùëÑ , Œ£, (ùëû , ùëû
ùêº
), Œî, ùêπ √ó ùêπ ) with
ùêº
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
((ùëû, ùëû ), ùëé, ( ùëù, ùëù )) ‚àà Œî
iff
(ùëû, ùëé, ùëù) ‚àà ùõø and (ùëû , ùëé, ùëù ) ‚àà ùõø .
on the size of C is obvious. It remains to be seen that ùêø(C) = ùêø(A) The
claim
‚à© ùêø(B).
The key insight here is, not surprisingly, that a run ùúå in C defines a run ùúå1 in
A and a run ùúå2 in B on the same word by projection onto the first, resp.
second component in the visited states. Likewise, two such runs ùúå1 in A and
ùúå2 in B on the same word ùë§ can be fused into a run ùúå on ùë§ in C.
"‚äá" So suppose that ùúå1 and ùúå2 are accepting, i.e. Inf (ùúå1) ‚à© ùêπ ‚â† ‚àÖ and Inf
(ùúå2) ‚à©
‚Ä≤

‚Ä≤
ùêπ
‚â† ‚àÖ. Since B is a WNBA, ùúå2 eventually traverses through accepting states
from ùêπ
‚Ä≤
only. Now consider the fused run ùúå. It eventually traverses through states
from ùëÑ √ó ùêπ
‚Ä≤
‚Ä≤
only, and it contains infinitely many states from ùêπ √ó ùëÑ . Hence, Inf (ùúå) ‚à© ùêπ
√ó ùêπ ‚â† ‚àÖ
and it is therefore accepting as well.
"‚äá" This is even simpler and does not use that fact that B is a WNBA.
Suppose
‚Ä≤
‚Ä≤
that Inf (ùúå) ‚à© ùêπ √ó ùêπ ‚â† ‚àÖ. Then clearly Inf (ùúå1) ‚à© ùêπ ‚â† ‚àÖ and Inf (ùúå2) ‚à© ùêπ ‚â† ‚àÖ
since ùúå1 and ùúå2 are obtained as projections of ùúå. So these are both accepting
and the underlying word therefore belongs to the languages of both A and
B.
‚óª
This yields all the ingredients needed to solve the model checking problem
for LTL.

Theorem 10.38 The model checking problem for LTL formulas ùúë over finite
LTS T
O(‚à£ ùúë‚à£)
can be solved in time ‚à£T ‚à£ ‚ãÖ 2
and polynomial space.
Proof Let T and ùúë be given. Deciding whether ùêø(T ) ‚äÜ ùêø(ùúë) is done by
constructing
‚Ä¢
O(
the WNBA A
1)
T
of size O(‚à£T ‚à£) in time ‚à£T ‚à£
using Thm. 10.36,
‚Ä¢
O(‚à£ ùúë‚à£)
O(‚à£ ùúë‚à£)
the NBA A¬¨ùúë of size 2
in time 2
using Cor. 10.25,
‚Ä¢

O(‚à£ ùúë‚à£)
an NBA for ùêø(AT ) ‚à© ùêø(A¬¨ùúë ) of size ‚à£T ‚à£ ‚ãÖ 2
and checking its language for emptiness in time that is polynomial in its
size.
The claim on the lower space consumption of this procedure uses the
observation that the product automaton can be built on-the-fly and that
emptiness of an NBA can be checking in nondeterministic logarithmic space
in the size of the automaton which is exponential in the size of the input ‚à£T
‚à£+‚à£ùúë‚à£. This leads to a nondeterministic, polynomial-space procedure, and a
result known as Savitch's Theorem states that it can then also be done in
deterministic polynomial space.
‚óª
274
10 Linear-Time Temporal Logic
Bibliographic Notes
Temporal logics have arisen from work in philosophy, especially the
development of tense logic by Prior [Pri57] for the formalisation of
temporal statements. LTL in its current form was then introduced to
computer science by Pnueli [Pnu77] for the purposes discussed here,
namely the specification of program behaviour and, in a slightly weaker
form, also by Kr √∂ger [Kr √∂77, Kr √∂87].
The automata-theoretic approach to LTL, in particular via nondeterministic
B √ºchi automata, was then developed primarily by Vardi and Wolper
[VW94, Var96]. The direct and relatively straightforward correspondence
between LTL and very weak alternating B √ºchi automata has been observed
by L √∂ding and Thomas [LT00]. The use of automata corresponding to LTL
formulas in program verification also led to many attempts to improve such
constructions in practice, e.g. [GPVW95, GO01].

There is more to the theory of LTL-definable languages than what is
contained in this chapter, and is only hinted at with Thm. 10.10 stating that
LTL-definable languages are FO-definable. The converse holds as well, but
it is conceptually and combinatorially a lot more complex and also does not
necessarily involve finite automata. The result is usually known as Kamp's
Theorem [Kam68] but it was proved for a version of LTL that also includes
past-time operators, i.e. symmetric versions of U and R that regard previous
rather than succeeding positions in a word. A step that completes the result
that every FO-definable language is also LTL-definable is then given by
Gabbay's Separation Theorem [Gab89] which states that every LTL
formula with future- and past-time operators is equivalent over ùúî-words to
one with future-time operators only. The combinatorial intricacies involved
in the proof of Kamp's Theorem have called for attempts to provide simpler
translations from FO
into LTL, cf. [GPSS80, HR07, Rab14].
As with languages of finite words, first-order logic defines a robust subclass
of the class of ùúî-regular languages. The concept of star-freeness can be
extended to infinite words as well so that it corresponds exactly to FO-,
resp. LTL-definability. This has mainly been explored by Thomas [Tho79].
Wilke has characterised this class in terms of a structural property of NBA
known as counter-freeness [Wil99a], and this corresponds closely to an
algebraic characterisation of this class via aperiodic monoids. The equi-
expressiveness of these and first-order logic is a classic result by Sch
√ºtzenberger [Sch65]. Diekert and Gastin [DG08] present a rather full
picture of the different models that all define this class, including temporal
logic LTL.
The standard translation from LTL into first-order logic can be made to use
only three variables. Combined with a translation back from first-order
logic into LTL, cf. Gabbay et al. [GPSS80], one obtains that every star-free,
resp. FO-definable property of ùúî-words is already definable in FO using
three variables only. Etessami at al. showed that the two-variable fragment
of FO corresponds exactly to the fragment of LTL using only the unary
temporal operators Next, Finally and Generally.

LTL has traditionally been used for specifying infinite runs of systems, i.e.
in the world of ùúî-words. It is not hard to define an interpretation over finite
words only, essentially introducing two versions of the next-time operator.
The resulting logic, often called LTL ùëì [GV13], is said to have interesting
applications in areas of
Exercises for Chapter 10
275
artificial intelligence like planning, and has therefore gained a lot of
separate interest in recent years.
For many purposes in program specification, LTL is considered to be too
weak, but MSO is considered to be too impractical as it requires to much
expertise to be used correctly. This calls for extensions of LTL with
increased expressiveness but similarly pragmatic interface in terms of
temporal operators. Several attempts have been made at creating such
specification languages. The temporal operator U can be enhanced with
regular expressions refining it to only allow particular future moments at
which it gets fulfilled. This idea is taken from Dynamic Logic [HKT00] and
leads to an extension of LTL that can express all ùúî-regular properties
[HT99]. The Linear-Time ùúá-Calculus [BB89, Var88] employs fixpoint
quantifiers to explicitly express least and greatest recursively defined sets of
positions in a word, just as U and R do in a very restricted form. This also
makes it reach ùúî-regular expressiveness but it suffers from similar disdain
as a language usable in practice for program verification.
The Property Specification Language (PSL) [EF06] has emerged from an
attempt to standardise temporal logic used in program verification making
use of regular expressions similar to Dynamic Logic mentioned earlier. A
commonality between the three extensions is not only ùúî-regular
expressiveness, it is also the case that the automata-theoretic approach to
LTL, either via nondeterministic or alternating automata can typically be
extended to richer formalisms like these, cf. [Var08], in case of Dynamic
Linear-Time Temporal Logic [HT99] and PSL [BFH05] more easily than
for the Linear-Time ùúá-Calculus [Kai97].

At last, LTL is a de facto standard for temporal logics and is therefore
routinely discussed in overview work on temporal logic in general (which
spans a lot more than just LTL) [Eme90, HR07] as well as textbooks on
(temporal) logic and/or automata
+
[HR04, DGL16, EB23] or on program verification techniques [BK08, CGK
18].
Savitch's Theorem, used in the proof of Thm. 10.38 to estimate the
complexity of LTL's model checking problem, is a result in computational
complexity stating that nondeterministic Turing machines can be simulated
by deterministic ones at a quadratic blowup in space [Sav70]. Hence, any
nondeterministic space-complexity class equals its deterministic
counterpart if the resource bound is closed under squaring. In particular,
NPSpace equals PSpace.
Exercises
Exercise 109 Construct LTL formulas that define the following languages
over the
{ ùëù,ùëû}
alphabet Œ£ = 2
where ùëé = ‚àÖ, ùëè = {ùëù}, ùëê = {ùëû} and ùëë = {ùëù, ùëû}.
‚àó
‚àó
‚àó
a) ùëé ùëè ùëê Œ£ ùúî
+

+
+
+
ùúî
b) (ùëé ùëè ùëê ùëë )
c) {ùë§ ‚àà Œ£ ùúî ‚à£ ‚à£ùë§‚à£ùëé = ‚àû ‚áí ‚à£ùë§‚à£ùëè = ‚àû}
ùúî
d) (Œ£‚àóùëéŒ£‚àóùëèŒ£‚àóùëê)
e) {ùë§ ‚àà Œ£ ùúî ‚à£ between each two symbols ùëë in ùë§ there is at least one ùëê}
276
10 Linear-Time Temporal Logic
Exercise 110 Let ùúë be an LTL formula over a finite set P of propositions.
The
‚Ä≤
formula ùúë results from ùúë by replacing every occurrence of a proposition ùëù in
it by the characteristic formula ùúí{ùëù}. Prove or refute the following
statements.
‚Ä≤
a) If ùúë is satisfiable then so is ùúë .
‚Ä≤
b) If ùúë is unsatisfiable then so is ùúë .

Exercise 111 For ùëõ ‚â• 1 let P
, . . . , ùëû
ùëé
. . .
ùëõ
‚à∂= {ùëû1
ùëõ } and ùêø ùëõ ‚à∂= {ùëé0
1
‚à£ ‚àÄùëñ = 1, . . . , ùëõ ‚à∂
‚àÉ ùëó ‚àà N with ùëûùëñ ‚àà ùëé ùëó }.
ùëõ
ùëõ
ùëõ
a) Construct LTL formulas ùúë of size O(ùëõ) such that ùêø(ùúë ) = ùêø .
b) Construct NBA Aùëõ such that ùêø(Aùëõ) = ùêøùëõ.
ùëõ
c) Show that every NBA Bùëõ for ùêøùëõ needs to have at least 2 many states.
ùëõ
Hint: Construct 2
many different words ùë§ , . . . , ùë§

1
2ùëõ that all belong to ùêø ùëõ so
that Bùëõ needs to reach pairwise different states after some fixed number of
steps when reading these ùë§ùëñ in an accepting run. This can be achieved such
that otherwise, two of these runs could be combined to an accepting run on
a word from ùêøùëõ.
Exercise 112 Show that, for any LTL formulas ùúë, ùúì we have ùúë ‚â° ùúì iff ùêø(ùúë) =
ùêø(ùúì).
Hint: This may seem obvious, and it is certainly the case that the "only if"-
direction follows immediately from the definitions. But the "if"-direction
needs an additional argument.
Exercise 113 Prove Lemma 10.13.
Exercise 114 Which of the following LTL formulas are tautologies, i.e. are
satisfied by any ùúî-word of the underlying alphabet? Explain why. For those
bi-implications that are not tautologies, explain which of the two
implicational directions fails.
a) Gùúë ‚àß Gùúì ‚Üî G(ùúë ‚àß ùúì)
f) GFGùúë ‚Üî FFGùúë
b) FGùúë ‚Üî GFùúë
g) Fùúë ‚àß Fùúì ‚Üî F(ùúë ‚àß ùúì)
c) Fùúë ‚à® Fùúì ‚Üî F(ùúë ‚à® ùúì)
h) X(ùúì U (ùúë ‚àß ùúì)) ‚à® GXùúì ‚Üî (Xùúë) R (Xùúì)
d) GFGùúë ‚Üî FGFùúë
i) (Gùúë ‚Üí Fùúì) ‚Üî ùúë U (ùúì ‚à® ¬¨ùúë)

e) Gùúë ‚à® Gùúì ‚Üî G(ùúë ‚à® ùúì)
j) (ùúëUùúì)U ùúí ‚Üî ùúí‚à®((ùúë‚à®ùúì)U(ùúì‚àßX ùúí))
Exercise 115 Prove the following statement in analogy to Lemma 10.16,
without using the definition of G as a special case of an R or via U and
negations: for all ùúë we have Gùúë ‚â° ùúë ‚àß XGùúë .
Exercise 116 Find LTL formulas ùúë, ùúì and a language ùêø over alphabet Œ£ such
that ùêø = ùêø(ùúì) ‚à© (ùêø(ùúë) ‚à™ Œ£ ùêø) but ùêø ‚â† ùêø(ùúë R ùúì). Verify that indeed ùêø ‚ää ùêø(ùúë R
ùúì) holds.
Exercise 117 Construct LTL formulas formalising the following statements
as well as NBA recognising the language of ùúî-words that satisfy these
statements.
a) Proposition ùëù holds at the next moment at which ùëû holds.
b) Proposition ùëù holds for as long as ùëû holds.
c) Whenever ùëû holds somewhere then ùëù must have held somewhere before
that.
Exercises for Chapter 10
277
d) Proposition ùëû is true at finitely many moments only.
Exercise 118 Construct an accepting run of the GNBA that is obtained by
the con-ùúî
struction of Thm. 10.24 for the LTL formula G(ùëù U ¬¨ùëù) on the word
ùëèùëèùëé(ùëéùëè) where ùëé = {ùëù}, ùëè = ‚àÖ.
Exercise 1 Construct the GNBA for the LTL formula ùúë = G((FXùëû) U ¬¨ùëû)
according to the description in the proof of Thm. 10.24.

Hint: To simplify this, it is possible to restrict attention to minimal Hintikka
sets, i.e. those that contain the formulas that must be contained and then are
closed under the rules for Hintikka sets but do not contain any further
additional formulas.
Exercise 119 Let P = {ùëù, ùëû}. Construct VWABA for the languages defined
by the following LTL formulas.
a) Gùëù ‚àß Fùëû
b) G(ùëù U ùëû)
Exercise 120 Design a direct translation from VWABA into equivalent
GNBA. Hint: Use the principles presented in the translations from VWABA
to LTL and from LTL
to GNBA.
Exercise 121 Find a path from state 3330 to state over in the LTS of Fig.
10.7 and explain what behaviour causes the queue overflow in terms of
interleaving steps of the three components in the underlying programs.
Explain, similarly, why state 3432 is unreachable from the initial state while
the somehow "dual" state 4340 is reachable.
Part III
Trees
Chapter 11
Automata on Finite Trees

Words are used to model computational phenomena like linear sequences of
events or signals, runs of a deterministic program, etc. A natural
generalisation of a word is a tree. Not only do trees play a significant role
in computer science as data structures, for instance in binary search trees,
they also naturally generalise the model of a sequence of events with a
designated starting point and a unique successor at each moment, to a
model of runs of nondeterministic programs for instance: instead of a
unique next moment there may be several possible next moments.
Reasoning about the entirety of the behaviour of such a program - instead
of all its single runs only -
then requires it to be viewed as a tree.
The three chapters of this part present an automata theory over trees, again
with a particular focus on its applicability to logics. So, as with the cases of
finite and infinite words, we develop some machinery that allows us to
translate reasoning problems over trees into computational problems. It
turns out that the very generic formalism of Monadic Second-Order Logic,
which also has a natural interpretation over trees, retains decidability of its
main decision problems like satisfiability and validity. Again, a rich theory
of automata operating on trees, including fundamental results like effective
complementability, is the key ingredient. This then opens up the possibility
to automatically reason about the behaviour of certain nondeterministic
programs, namely those with finite state-spaces for instance.
The step from words to trees or, equivalently, the extension of such
sequences of events to having multiple successors, yet again comes with a
price in terms of the involved combinatorics, as it was the case with the
transition from finite to infinite words. We therefore consider the case of
finite trees first. It can be seen as a warm-up for the more intricate case of
infinite trees, to be dealt with in the next chapter, but it is also useful in its
own right because of the ubiquitous use of finite trees as data structures in
computer science besides the search trees mentioned above.
Other examples include parse trees for context-free languages, abstract
data types and XML documents. We will discuss selected applications of an
automata theory over finite trees at the end of this chapter.

¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
281
https://doi.org/10.1007/978-3-662-72154-4_11
282
11 Automata on Finite Trees
ùúÄ
0
1
00
01
10
010
100
101
1000
Fig. 11.1 A finite, ordered tree.
11.1 Finite Trees
11.1.1 Trees and Tree Languages

While it is intuitively clear what a tree is, a formal definition is certainly
needed in order to explain further concepts like an automaton's run on a
tree, etc. Such a definition has been given already, though, namely as Def.
7.3 in the context of using finite trees to refine the powerset construction for
the determinisation of B √ºchi automata. Again, we consider ordered trees
here which means that there is a total order on the children of each node,
i.e. amongst these there is a leftmost and every other has a designated left
sibling.
‚àó
We recall that a finite tree is then a finite set ùëá ‚äÜ N which satisfies parent
closure and left-sibling closure, i.e. the following two proper ties.
‚Ä¢
‚àó
Whenever ùë£ùëñ ‚àà ùëá for some ùë£ ‚àà N and ùëñ ‚àà N then ùë£ ‚àà ùëá .
‚Ä¢
‚àó
Whenever ùë£ùëñ ‚àà ùëá for some ùë£ ‚àà N and ùëñ ‚â• 1 then ùë£(ùëñ ‚àí 1) ‚àà ùëá .
Recall that the first condition (parent closure) ensures that each node in the
tree has a parent node, apart from the root. The second condition (left-
sibling closure) ensures that for every node in the tree that is a child but not
the leftmost child of another node, its left sibling is also an element of the
tree. It also means that the children of node ùë£ are numbered ùë£0, ùë£1, ùë£2, . . .
from left to right.
The name of each node encodes its position in the tree by listing the
directions one has to take starting at the root node ùúÄ. For instance, node 3
19 0 2 is located at the position that one reaches when starting at the root,
then moving on to its fourth child (i.e. the one with number 3), then to the

twentieth child of that node, then to the first of that one and then to the
third.
Example 11.1 Fig. 11.1 shows the graphical and perhaps more familiar
representation of the tree {ùúÄ, 0, 00, 01, 010, 1, 10, 100, 1000, 101}.
11.1 Finite Trees
283
‚à®
‚àß
¬¨
1
¬¨
‚àß
1
¬¨
0
0
Fig. 11.2 A Boolean expression as a tree over the ranked alphabet of
Boolean constants and operators.
The trees we consider as objects generalising words are not only ordered
but also ranked. This means that the underlying alphabet Œ£, still considered
to be a finite set of symbols, comes with a ranking function rk Œ£ ‚à∂ Œ£ ‚Üí N
that assigns a rank or arity to each alphabet symbol. Œ£ is then called a
ranked alphabet in this case. We will not consider unranked trees, hence
whenever we speak of an alphabet Œ£ we will mean a ranked alphabet, and

we will write rk Œ£ for the corresponding ranking function. We will also
write Œ£ùëë for the set {ùëé ‚àà Œ£ ‚à£ rk Œ£(ùëé) = ùëë} of symbols of rank ùëë. Hence, Œ£
= Œ£0 ‚à™ Œ£1 ‚à™ . . . ‚à™ Œ£ùëö for some maximal rank ùëö ‚àà N.
Definition 11.2 Let Œ£ be a ranked alphabet and ùëá be a finite tree in the
above sense.
A Œ£ -tree with domain ùëá is a mapping ùë° ‚à∂ ùëá ‚Üí Œ£ such that for all ùë£ ‚àà ùëá and
all ùëé ‚àà Œ£
‚àó
with ùë°(ùë£) = ùëé we have: rk Œ£(ùëé) = ‚à£{ùëñ ‚àà N ‚à£ ùë£ùëñ ‚àà ùëá }‚à£. Let TŒ£ denote the set
of all finite Œ£-trees with arbitrary domain.
We will simply speak of a tree ùë° instead of a Œ£-tree over domain ùëá since the
domain can usually be inferred and the underlying alphabet is usually given
by the
‚àó
context. Note that TŒ£ adopts the role of Œ£‚àó from the world of finite words
in the world of finite trees. The notation for the set of all trees is different
because it is slightly more tedious (but not impossible) to define the set of
all ranked ordered trees as the result of an iterative process just like the
notion Œ£‚àó suggests.
An immediate consequence of Def. 11.2 is the fact that two nodes in a
ranked tree that carry the same alphabet symbol also must have the same
number of children.
Moreover, ranked trees are finitely-branching, i.e. each node has at most
finitely many children. The number is even bounded, not only because
nodes are finite, but also because alphabets are finite, so some symbol must
have maximal rank.
Recall that a language was, so far, just a (possibly infinite) set of words.
Likewise

‚àó
we will refer to a set of trees ùêø ‚äÜ TŒ£ as a tree language or simply as a
language since trees are our main objects of interest from now on.
Languages of words will only play very specific roles in this, and then we
will use the terms word language and tree language to distinguish between
these two kinds when in danger of confusion.
Example 11.3 Let Œ£ = {0, 1, ¬¨, ‚àß, ‚à®} with
284
11 Automata on Finite Trees
rk Œ£(0) = rk Œ£(1) ‚à∂= 0
,
rk Œ£(¬¨) ‚à∂= 1
,
rk Œ£(‚àß) = rk Œ£(‚à®) ‚à∂= 2 .
A ranked, ordered tree over this alphabet naturally represents a Boolean
expression over the constants 0 and 1 and the operators of negation,
conjunction and disjunction.
For example, the expression (1 ‚àß ¬¨1) ‚à® ¬¨(¬¨0 ‚àß 0) represents the Œ£-tree
shown in Fig. 11.2 whose domain is exactly the finite ordered tree shown in
Fig. 11.1.
An example of a tree language is therefore the language of all
(representations) of Boolean expressions in this sense. This is a trivial
example though, as it simply
‚àó

is TŒ£ for this ranked alphabet Œ£. Note that not only can every Boolean
expression over these operators be represented as a Œ£-tree as done above;
but every Œ£-tree also represents such a Boolean expression.
A non-trivial language of Œ£-trees for this Œ£ is the set of all Boolean
expressions that evaluate to 1 under the usual evaluation rules for the
Boolean operators. The tree shown in Fig. 11.2 belongs to this language,
but the tree obtained from it by replacing the symbol 0 with the symbol 1 at
node 101 does not belong to it.
The connection between terms and trees brought out in the previous
example is not coincidental. Not only do terms naturally have tree
representations, but each tree can also be represented as a term. The infix
notation used in the example above is more readable for terms that contain
familiar binary operators like Boolean or arithmetical ones. Prefix notation
is more natural for abstract alphabets. For example, the tree ùëé
ùëè
ùëé
ùëè
ùëè
over the ranked alphabet Œ£ = Œ£0 ‚à™ Œ£2 with Œ£0 = {ùëè}, Œ£2 = {ùëé}, would be
written as the term ùëé(ùëè, ùëé(ùëè, ùëè)) using prefix notation.
It is worth pointing out explicitly that the ranking of an alphabet implicitly
partitions its symbols into those that can occur at leaves, namely those
whose rank is zero, and those that can occur at genuine inner nodes,
namely those whose rank is strictly greater than zero.
11.1.2 Two Different Directions
We will consider two kinds of finite automata operating on finite, ranked
and ordered trees. Both are generalisations of the model of an NFA
operating on finite words.

The distinction of the two models is owed to the special structure of trees.
Note that an NFA is intuitively seen as reading a word from left to right.
Regular languages are closed under reversals, though, so one could also
consider them as operating from right to left. In fact, a run of an NFA on a
finite word ùëé ùëé . . . ùëé
0
1
ùëõ‚àí1 of length ùëõ is just
a labelling of each symbol with matching pairs of states: the one that the
automaton is in before reading the letter and the one that it is in afterwards.
The latter of course needs to coincide with the one that it is in before
reading the letter to the right. So
11.1 Finite Trees
285
forming a run of an NFA on a word of length ùëõ can be seen as filling the
positions between each two letters and before the first and after the last
with states in a way that respects the transition table as follows.
ùëé
ùëé
ùëé
ùëé
0
1
2

ùëõ‚àí1
ùëû
ùëû
ùëû
ùëû
. . .
ùëû
ùëû
0
1
1
2
ùëõ‚àí1
ùëõ
If we tried to lift this construction to trees we would be placing the
automaton's states between the tree's nodes, in particular in places between
the tree's levels. This is not impossible but a more natural approach would
perhaps be to label the tree's nodes with states in a run, for instance like
this:
ùë£
ùëû
ùëé

ùëû
ùëû
0
ùëë‚àí1
. . .
ùë£
ùëè
0
ùëè
ùë£
0
ùëë‚àí1
(ùëë ‚àí 1)
Here we see a node with name ùë£ and its children with names ùë£0, . . . , ùë£(ùëë
‚àí 1).
The parent node is labelled with the symbol ùëé, and its children carry
symbols ùëè
, . . . , ùëè
0
ùëë‚àí1. The nodes are additionally labelled with states, namely ùëû at the
parent node and ùëû , . . . , ùëû

0
ùëë‚àí1 at the children as part of a potential run.
To see the potential for two types of automata in this picture, re-consider
the picture for runs of NFA on finite words, in particular one such triple like
(ùëû , ùëé , ùëû
1
1
2). The
intuitive understanding of the NFA reading the word from left to right is
reflected in the mathematical dependency that the state ùëû2 in this case is
determined from the combination of ùëû1 and ùëé1. However, one could equally
define NFA to be reading words from right to left, meaning that the
combination of ùëû2 on the right and the letter ùëé1 determines which states
are allowed to be written down on the left like ùëû1. Either way ultimately
results in the same class of languages accepted by such automata, namely
the regular ones. Closure under reversal, respectively the way that it is
proved, shows that there is no conceptual difference between the two modes
reading from left to right or right to left.
However, for trees there is a conceptual difference. First note that because
of the way that we drew trees as growing downwards, the directions from-
left-to-right and from-right-to-left now correspond to top-down and bottom-
up. This is just a representational difference, though, not a conceptual one.
However, in top-down mode, the automaton is supposed to be in state ùëû
before it reads the node label ùëé, and then it moves to the combination of
states (ùëû , . . . , ùëû
0
ùëë‚àí1). In bottom-up mode,
it determines the state ùëû from the combination of the tuple (ùëû , . . . , ùëû

0
ùëë‚àí1) and the
symbol ùëé. This makes a conceptual difference because a tuple like (ùëû , . . . ,
ùëû
0
ùëë‚àí1) can
encode more information than a single state. So in top-down mode, the
automaton would have to determine the next states from the information
that is given by the letter being read and a single state, in bottom-up mode
it has more information available to determine the next state.
286
11 Automata on Finite Trees
We will make these intuitive explanations formal in the following. In
particular, top-down and bottom-up tree automata are distinguished by the
type of their transition tables. Before we get to these definitions we need to
point out a perhaps strange effect of the choice that runs should be
labellings of the tree's nodes with states. Then a run has exactly as many
levels as the underlying tree which would correspond to a situation in the
world of words where runs are exactly as long as the underlying words. It is
not hard to see that an automaton model with initial and final states would
then only accept languages that are either invariant in the first or the last
letter, i.e.
languages of the form Œ£ùêø, resp. ùêøŒ£ for some regular language ùêø. This can
be fixed by not starting in a fixed initial state but in a state that depends on
the first letter of the word. Likewise one could replace accepting states by
an accepting mode that takes the currently read letter into consideration.
This then needs to be done for tree automata as well, and it turns out that
such initial or final assignments can simply be incorporated into the
transition table. This is why top-down automata for example will have

initial states but no final ones as their usual function is provided by the
transition table. Likewise, bottom-up automata will have final states but no
initial ones.
11.2 Direction Bottom-Up
11.2.1 Bottom-Up Tree Automata
Definition 11.4 A (nondeterministic) bottom-up tree automaton (NbuTA) is
an A =
(ùëÑ, Œ£, ùõø, ùêπ ) where
‚Ä¢ ùëÑ is a finite set of states,
‚Ä¢ Œ£ is a ranked alphabet with corresponding ranking function rk Œ£ and some
maximal rank ùëö ‚à∂= max{ rk Œ£(ùëé) ‚à£ ùëé ‚àà Œ£},
‚Ä¢ the transition table is a collection ùõø = ùõø0 ‚à™ . . . ‚à™ ùõøùëö of separate transition
tables ùëë
for each possible rank ùëë with ùõø
ùëë
, . . . , ùëö
ùëë
‚äÜ ùëÑ
√ó Œ£ ùëë √ó ùëÑ for all
= 0
,
‚Ä¢ ùêπ ‚äÜ ùëÑ is a set of designated accepting s tates.

As usual, the size of the NbuTA A is ‚à£ùëÑ‚à£.
The partitioning of the transition table into transition relations for each
rank is only done in order to precisely give the type of these relations, but
these are dependent: the length of the tuple of states that the automaton is
in - more precisely: that label the children of a node - depends on the rank
of the alphabet letter that is being read next.
ùëë
As usual, we sometimes regard a relation of type ùëÑ √ó Œ£ùëë √óùëÑ as a function
of type ùëë
ùëÑ
ùëÑ
√ó Œ£
, . . . , ùëû
, . . . , ùëû
ùëë
‚Üí 2
and write ùëû ‚àà ùõø((ùëû0
ùëë‚àí1), ùëé) instead of ((ùëû0
ùëë‚àí1), ùëé, ùëû) ‚àà
ùõø. This is also needed to meaningfully define a deterministic variant of an
NbuTA.
11.2 Direction Bottom-Up
287

Definition 11.5 A deterministic bottom-up tree automaton (DbuTA) is an A
=
ùëë
(ùëÑ, Œ£, ùõø, ùêπ ) like an NbuTA except that ùõø is a collection of functions ùõøùëë ‚à∂ ùëÑ
√óŒ£ùëë ‚Üí ùëÑ
for each possible rank ùëë = 0, . . . , max{ rk Œ£(ùëé) ‚à£ ùëé ‚àà Œ£ }.
We extend the flexibility introduced above in regarding the transition table
of an NbuTA as relations or as functions, whatever is more convenient, to
the point ùëë
where we regard a function of type ùëÑ
√ó Œ£ùëë ‚Üí ùëÑ as a special function of type
ùëë
ùëÑ
ùëÑ
√ó Œ£ùëë ‚Üí 2
that returns, on every input, a singleton state. Then every DbuTA can
immediately be regarded as an NbuTA, and their difference intuitively is
that, once children of a node in a tree are labelled with states, these and the
node's alphabet symbol label determine either several possibilities or a
unique possibility to extend the state labelling to the node itself.
These considerations have already appealed to an intuitive notion of a run
of an NbuTA on a finite, ranked and ordered Œ£-tree as a labelling of the
tree's nodes with states. It is time to formalise this properly.
Definition 11.6

‚àó
Let A = (ùëÑ, Œ£, ùõø, ùêπ) be an NbuTA, and ùë° ‚àà TŒ£ . A run of A on ùë° is a mapping
ùúå ‚à∂ dom(ùë°) ‚Üí ùëÑ satisfying
ùúå(ùë£) ‚àà ùõøùëë ((ùúå(ùë£0), . . . , ùúå(ùë£(ùëë ‚àí 1))), ùë°(ùë£ ))
for all ùë£ ‚àà dom(ùë°) where ùëë = rk Œ£(ùë°(ùë£ )).
Such a run ùúå is called accepting if ùúå(ùúÄ) ‚àà ùêπ. The (tree) language accepted by
A
‚àó
is, as usual, ùêø(A) ‚à∂= {ùë° ‚àà TŒ£ ‚à£ there is an accepting run of A on ùë°}.
So a run of A on ùë° is indeed just a labelling of ùë°'s nodes with states of A that
respects the transition relations in the sense that each tuple ((ùëû , . . . , ùëû
0
ùëë‚àí1), ùëé, ùëû)
of children's label (ùëû , . . . , ùëû
0
ùëë‚àí1) and parent's symbol ùëé and state label ùëû must be
a legal combination according to the finitely many combinations prescribed
by the transition relations.
A perhaps more interesting question regards the seemingly disappeared
initial states. An NbuTA does not have initial states, so one may perhaps
think that runs cannot be formed in a bottom-up style because there is no
beginning for this process.

Or perhaps the labelling could be started in an arbitrary state. Neither
interpretation is correct, and the correct one is seen by carefully analysing
the definitions of an NbuTA and its runs. Note that the transition function ùõø
is composed of one for each ùëÑ
rank, in particular there is a transition function ùõø0 ‚à∂ ùëÑ0 √ó Œ£0 ‚Üí 2
for alphabet
symbols of rank 0. As stated further above, these are exactly the symbols
that can occur in leaf positions of a Œ£-tree. Moreover, ùëÑ0 = {()} =‚à∂ 1, and a
function of ùëÑ
ùëÑ
type 1 √ó Œ£0 ‚Üí 2
can easily be seen as a function of type Œ£0 ‚Üí 2 . Note that an argument to a
function whose values are drawn from a singleton domain does not allow
any variation in the function's values, hence it can be ignored. We will also
do this and consider the special case of the transition function for rank 0 to
be some ùëÑ
ùõø0 ‚à∂ Œ£0 ‚Üí 2 . And this is in fact where the initial states are hiding.
Remember that a run on a tree with ùëò levels also has ùëò levels, and this is
why we cannot have fixed initial and final states but one type has to depend
on the symbols read at the beginning or end. So NbuTA do not have initial
states but an initial assignment ùõø0
288
11 Automata on Finite Trees
that (nondeterministically) selects states as labels of leaf nodes depending
on the alphabet symbols at these leaves.
Accordingly, a DbuTA should assign a unique state to a leaf node, but this
can also depend on the symbol at the leaf.

We also simplify the notation for the transition functions of rank 1 and write
ùëû ‚àà ùõø( ùëù, ùëé) instead of ùëû ‚àà ùõø((ùëù), ùëé) for example. I.e. we identify tuples of
length ùëÑ
1 with their content or, likewise, consider ùõø1 to be of type ùëÑ √ó Œ£1 ‚Üí 2
instead of
ùëÑ
ùëÑ 1 √ó Œ£1 ‚Üí 2 .
Example 11.7 Reconsider the example of the tree language of all Boolean
expressions that evaluate to 1, modelled as trees over the ranked alphabet Œ£
defined in Ex. 11.3. It is recognisable by a DbuTA, namely A ‚à∂= ({0, 1}, Œ£, ùõø,
{1}) with the three transition functions for ranks 0, 1 and 2 given as follows.
ùõø
ùõø0
2
ùëé
ùõø
, ùëû
, ùëû
0(ùëé)
(ùëû0
1) ùëé ùõø2((ùëû0
1), ùëé)

0
0
(0, 0) ‚àß
0
1
1
(0, 1) ‚àß
0
(1, 0) ‚àß
0
(1, 1) ‚àß
1
ùõø1
(0, 0) ‚à®
0
ùëû ùëé
ùõø1(ùëû, ùëé)
(0, 1) ‚à®
1
0 ¬¨

1
(1, 0) ‚à®
1
1 ¬¨
0
(1, 1) ‚à®
1
Note that in the expression ùõø0(0) = 0, each of the three occurrences of the
symbol 0 has a different meaning. The 0 in the index refers to the rank, i.e.
the table for ùõø0
lists the initial assignments that depend on the symbol at a leaf node. These
symbols can be 0 or 1, and the 0 in the argument position of ùõø0(0) refers of
course to the alphabet symbol 0 of rank 0. Finally, the 0 on the right-hand
side refers to the state that A enters in a leaf node labelled with the alphabet
symbol 0.
The choice of states as 0 and 1, equal to the alphabet symbols or rank 0, is
not made to be deliberately confusing. The DbuTA formalises the usual
bottom-up evaluation of a Boolean expression over constants 0 and 1. This
assigns a Boolean value of 0 or 1 to each subexpression. The value of
subexpressions 0 and 1 is 0, respectively 1, and the value of a composed
subexpression depends on the value of its maximal subexpressions and the
rules for evaluating the Boolean operator at the top of the subexpression.
This is exactly what is formalised in terms of a run of this DbuTA: each
node in an underlying Œ£-tree represents a subexpression, and the state
assigned to a node in a run of A is exactly the value of that subexpression.
Hence, it is fair to say that A formalises the usual bottom-up evaluation of
Boolean expressions. It should also be clear that state 1 is the only

accepting state: a Boolean expression evaluates to 1 iff the state reached at
its root is 1.
A run of A on the tree representing the Boolean expression (1 ‚àß ¬¨1) ‚à®
¬¨(¬¨0 ‚àß 0) as shown in Fig. 11.2 is shown in Fig. 11.3. The states 0 and 1
are shown as labels near the tree's nodes. It is easy to confirm that they
equal the value of the
11.2 Direction Bottom-Up
289
1
‚à®
0
1
‚àß
¬¨
1
0
0
1
¬¨
‚àß
1
1

0
1
¬¨
0
0
0
Fig. 11.3 Run of the DbuTA A from Ex. 11.7 on the tree from Fig. 11.2.
corresponding subexpression represented by the subtree rooted at each such
node.
The areas enclosed with a dashed line represent the transitions; they can all
be found in the tables above. At last, the run is accepting since the root is
labelled with the accepting state 1.
11.2.2 Determinisation
As with automata on words, an interesting question arising with the general
models of nondeterministic and the special model of deterministic bottom-
up tree automata is: does the deterministic variant have the same expressive
power as the nondeterministic one? In other words: can NbuTA be
transformed into DbuTA? The answer is positive: one can technically adjust
the well-known powerset construction for NFA in order to obtain such a
translation.
Theorem 11.8
ùëõ
For every NbuTA A of size ùëõ there is a DbuTA B of size at most 2
such that ùêø(B) = ùêø(A) .

Proof
ùëÑ
‚Ä≤
Let A = (ùëÑ, Œ£, ùõø, ùêπ). We construct the DbuTA B ‚à∂= (2 , Œ£, Œî, ùêπ ) with
‚Ä≤
ùêπ
‚à∂= {ùëÜ ‚äÜ ùëÑ ‚à£ ùëÜ ‚à© ùêπ = ‚àÖ} and transition function Œî giv en rankwise via Œî
, . . . , ùëÜ
. . .
ùëë ((ùëÜ0
ùëë‚àí1), ùëé)
‚à∂= {ùëû ‚à£ ‚àÉùëû0 ‚àà ùëÜ0
‚àÉùëû ùëë‚àí1 ‚àà ùëÜùëë‚àí1 s.t.
ùëû ‚àà ùõø((ùëû , . . . , ùëû
0
ùëë‚àí1), ùëé)} .
The claim on the size of B is obvious. It remains to be seen that ùêø(B) =
ùêø(A).
"‚äá" Suppose that ùë° ‚àà ùêø(A), i.e. there is an accepting run ùúå of A on ùë°. Since
B is
‚Ä≤

a DbuTA, it has a unique run ùúå on ùë°, and all that remains to be done is to
check that it is accepting. This is the case because the following invariant
holds for all nodes
‚Ä≤
‚Ä≤
ùë£ of ùë°: ùúå(ùë£) ‚àà ùúå (ùë£). This is easily seen to be the case for leaves ùë£ since ùúå
labels
290
11 Automata on Finite Trees
these with the set of all states that could possibly occur at this node in a run
of A, in particular the run ùúå, and therefore it includes ùúå(ùë£).
For inner nodes this invariant is maintained because of the construction of
Œî: take some node ùë£ with children ùë£0, . . . , ùë£(ùëë ‚àí 1). By the hypothesis we
have ùúå(ùë£ùëñ) ‚àà
‚Ä≤
ùúå (ùë£ùëñ) for all ùëñ = 0, . . . , ùëë ‚àí 1. Since ùúå is a run of A it must respect the
transition relation ùõø, so we have ùúå(ùë£) ‚àà ùõø((ùúå(ùë£0), . . . , ùúå(ùë£(ùëë ‚àí 1))), ùëé) and
therefore ùúå(ùë£) ‚àà
Œî((ùëÜ , . . . , ùëÜ
, . . . , ùëÜ
0
ùëë‚àí1), ùëé) for any sets ùëÜ0
ùëë‚àí1 containing ùúå(ùë£0), . . . , ùúå(ùë£(ùëë ‚àí 1 ))
componentwise.

‚Ä≤
Iterating this invariant eventually yields ùúå(ùúÄ) ‚àà ùúå (ùúÄ). Since ùúå is accepting we
‚Ä≤
‚Ä≤
have ùúå(ùúÄ) ‚àà ùêπ, i.e. ùúå(ùúÄ) ‚àà ùêπ ‚à© ùúå (ùúÄ) which shows that ùúå (ùúÄ) is an accepting
state of
‚Ä≤
B and so ùúå is accepting, too.
‚Ä≤
"‚äÜ" Let ùúå be an accepting run of B on some tree ùë°. We claim that we can
extract an accepting run ùúå of A on ùë° from it. We do this in a top-down
manner.
‚Ä≤
‚Ä≤
At first, consider the root ùúÄ of ùë°. We have ùúå (ùúÄ) ‚à© ùêπ ‚â† ‚àÖ, so ùúå (ùúÄ) must contain
some state, say, ùëû ùúÄ ‚àà ùêπ. If there are several ones, pick an arbitrary one and
let
‚Ä≤
ùúå(ùúÄ) ‚à∂= ùëû ùúÄ . Now remember that ùúå is a run of B that must adhere to the
transition
‚Ä≤
‚Ä≤

function Œî, i.e. we have ùëû ùúÄ ‚àà Œî((ùúå (0), . . . , ùúå (ùëë ‚àí 1)), ùë°(ùúÄ)) where ùëë is the
rank of
‚Ä≤
the symbol ùë°(ùúÄ). Hence, there must be states ùëû , . . . , ùëû
0
ùëë‚àí1 of A such that ùëûùëñ ‚àà ùúå (ùëñ)
for all ùëñ = 0, . . . , ùëë ‚àí 1 and ùëû
, . . . , ùëû
, . . . , ùëû
ùúÄ
‚àà ùõø((ùëû0
ùëë‚àí1), ùë° (ùúÄ)). The states ùëû0
ùëë‚àí1
‚Ä≤
‚Ä≤
therefore witness the inclusion of ùëû ùúÄ in ùúå (ùúÄ), and they all belong to ùúå (ùëñ) for
the corresponding children 0, . . . , ùëë ‚àí 1 of ùë°'s root. So this yields states at
the level below the root that can be used to extend ùúå: let ùúå(ùëñ) ‚à∂= ùëûùëñ for ùëñ = 0,
. . . , ùëë ‚àí 1.
It should be clear that this one-step construction of selecting nodes in the
labels
‚Ä≤

of the run ùúå that are connected via ùõø is not restricted to the root and can be
‚Ä≤
continued at every other node down to the leaves, picking a state ùëûùë£ from ùúå
(ùë£) for any node ùë£. At the leaves we then selected nodes that the initial
assignment in ùúå
could nondeterministically choose, hence, ùúå is indeed a run of A on ùë°. It is
accepting because ùúå(ùúÄ) was chosen to belong to ùêπ.
‚óª
11.2.3 Closure Properties
An immediate consequence of determinisability is closure of the class of
NbuTA-recognisable languages under complements. As with automata on
finite words, the deterministic variant yields a simple complementation
procedure.
Theorem 11.9 For every DbuTA A of size ùëõ over some ranked alphabet Œ£
there is a
‚àó
DbuTA A of size ùëõ such that ùêø(A) = TŒ£ ‚àñ ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùõø, ùêπ). Simply define A as (ùëÑ, Œ£, ùõø, ùëÑ ‚àñ ùêπ). Determinism
of A clearly carries over to A, so on any tree they both have a unique run ùúå
only (which is necessarily the same run). Since ùúå(ùúÄ) /
‚àà ùêπ iff ùúå(ùúÄ) ‚àà ùëÑ ‚àñ ùêπ we have that ùúå is
accepting for A iff it is not accepting for A and vice-v ersa.
‚óª
Putting the previous two theorems together yields closure of the class of
NbuTA-recognisable languages under complements.

11.2 Direction Bottom-Up
291
Corollary 11.10 For every NbuTA A of size ùëõ over some ranked alphabet Œ£
there is ùëõ
‚àó
an NbuTA A of size at most 2 such that ùêø(A) = TŒ£ ‚àñ ùêø(A) .
It is not too hard to see that this class is also closed under unions since
nondeterminism is available. Closure under intersections is then an
immediate consequence of this using the deMorgan laws. A more efficient
construction is obtained by lifting the product construction used for NFA to
NbuTA. Details are left as an exercise.
Theorem 11.11 For every NbuTA A ,
1 A2 of sizes ùëõ1 and ùëõ2 respectively there is an NbuTA B of size at most . . .
a) ùëõ 1 + ùëõ
ùêø
2 such that
(B) = ùêø(A1) ‚à™ ùêø(A2) ,
b) ùëõ1 ‚ãÖ ùëõ2 such that ùêø(B) = ùêø(A1) ‚à© ùêø(A2) .
Recall the definition of the class of regular languages of finite words as the
closure of finite languages under unions, concatenations and Kleene
iterations. This raises the question after the closure of the class of NbuTA-
recognisable languages (as a candidate for a tree analogue to the class of
regular word languages) under concatenations and iterations. We remark
that such closure results also hold, but we do not investigate this in detail
here. The reason simply is that the concatenation of two tree languages -

based on the concatenation of two trees - is a bit more cumbersome to
define as there is not a unique way to extend a tree ùë°1 "at its end" by
another tree ùë°2, especially not in the ranked setting. One way to do this is to
invent a special symbol, say ‚óØ, of rank 0, and tree concatenation of ùë°1 with
ùë°2 is then performed by replacing one of ùë°1's leaves that carries the "hole"
symbol ‚óØ with ùë°2.
This process can also naturally be iterated.
It is not hard to imagine that two NbuTA A1 and A2 can be combined so
that the result accepts a tree iff it is the concatenation of some tree from
ùêø(A1) with one from ùêø (A2). This requires a bit more bookkeeping than the
concatenation construction on words since the tree resulting from the
concatenation of ùë°1 and ùë°2 then has some leaves from ùë°1 and others from
ùë°2, etc. It may also be more convenient to perform this construction for top-
down tree automata, to be studied next, which of course immediately raises
the question after their effective equi-expressiveness.
Before we study this next automaton model, we briefly mention another
important closure result, namely that for homomorphisms. Again, the richer
structure of trees compared to words requires a few more technicalities.
Recall that a (word) homomorphism ÀÜ
‚Ñé was the natural extension of a morphism ‚Ñé ‚à∂ Œ£ ‚Üí Œî‚àó for some alphabets
Œ£, Œî, to a mapping of type Œ£‚àó ‚Üí Œî‚àó. This cannot be directly lifted to
ranked trees.
Definition 11.12 Let Œ£, Œî be ranked alphabets. A rank-preserving morphism
is a mapping ‚Ñé ‚à∂ Œ£ ‚Üí Œî such that rk Œî(‚Ñé(ùëé)) = rk Œ£(ùëé) for all ùëé ‚àà Œ£.
‚àó
‚àó
It naturally induces a (rank-preserving) tree homomorphism ÀÜ
‚Ñé ‚à∂ TŒ£ ‚Üí TŒî via

ÀÜ
‚àó
‚Ñé(ùë° )(ùë£) = ‚Ñé(ùë£) for any ùë° ‚àà TŒ£ and any ùë£ ‚àà dom(ùë° ).
Note that dom( ÀÜ
‚Ñé(ùë° )) = dom(ùë°) for any ùë° and any rank-preserving tree homomorphism ‚Ñé,
i.e. tree homomorphisms are defined in a way that they do not alter the
structure of a tree. This is not the most general definition that is possible,
but it suffices for our purposes.
292
11 Automata on Finite Trees
Not too surprising, the image of an NbuTA-recognisable languages under a
rank-preserving tree homomorphism is also NbuTA-recognisable. The proof
is left as an exercise.
Lemma 11.13 Let Œ£, Œî be tree alphabets and ‚Ñé ‚à∂ Œ£ ‚Üí Œî be rank-preserving.
For every NbuTA A of size ùëõ there is an NbuTA B of size at most ùëõ such that
ùêø(B) =
ÀÜ
‚Ñé(ùêø(A)) .
We may refer to this result also sloppily by saying that NbuTA-recognisable
languages are closed under rank-preserving tree homomorphisms. This is
either not meaningful or too weak, strictly speaking, since there is not just
one class of NbuTA-recognisable languages, but one such class for every
ranked alphabet.
11.3 Direction Top-Down

We develop a second automaton model that, intuitively, traverses trees
starting from the root down to their leaves. As discussed at length above,
though, this is really just an intuition rather than a mathematical fact. We
will see that top-down and bottom-up automata are essentially the same, at
least in their nondeterministic variant.
11.3.1 Top-Down Tree Automata
Definition 11.14 Let Œ£ be a ranked alphabet as above and ùëö ‚à∂= max{ rk
Œ£(ùëé) ‚à£ ùëé ‚àà Œ£}.
A nondeterministic top-down tree automata (NtdTA) is an A = (ùëÑ, Œ£, ùëû , ùõø
ùêº
) suc h
that
‚Ä¢ ùëÑ is a finite set of states,
‚Ä¢ ùëû
ùëÑ
ùêº
‚àà
is a designated initial state,
‚Ä¢ the transition table is a collection ùõø = ùõø0 ‚à™ ùõø1 ‚à™ . . . ‚à™ ùõøùëö of transition
relations, ùëë
one for each rank, such that ùõøùëë ‚äÜ ùëÑ √ó Œ£ùëë √ó ùëÑ
for each ùëë = 0, . . . , ùëö.
ùëë

ùëÑ
As usual, we may use such a ùõøùëë as a function of type ùëÑ √ó Œ£ùëë ‚Üí 2
and write
(ùëû , . . . , ùëû
1
ùëë ) ‚àà ùõø(ùëû , ùëé) for ins tance.
A deterministic top-down tree automaton (DtdTA) is such an NtdTA where
‚à£ùõø(ùëû, ùëé)‚à£ ‚â§ 1 for every ùëû ‚àà ùëÑ, ùëé ‚àà Œ£.
As with bottom-up automata, alphabet symbols of rank 0 and 1 introduce a
little bit of notational clutter which we can avoid. We identify ùëÑ1 and ùëÑ
again and write
OceanofPDF.com

‚Ä≤
‚Ä≤
ùëû
‚àà ùõø(ùëû, ùëé) instead of (ùëû ) ‚àà ùõø(ùëû, ùëé) when ùëé ‚àà Œ£ 1.
0
ùëÑ
For the case of rank 0 note that 2
= {‚àÖ, {()}}. Hence, a relation of type
0
ùëÑ
ùëÑ √ó Œ£0 √ó ùëÑ0, resp. a function of type ùëÑ √ó Œ£0 ‚Üí 2
can be seen as returning, for
any state ùëû and any alphabet symbol of rank 0, one of two answers: either
‚àÖ or
{()}. These can be interpreted as false and true, and this interpretation is
not far
11.3 Direction Top-Down
293
fetched: the set ùõø(ùëû, ùëé) contains the possibilities to label the children of some
tree node ùë£ that carries the symbol ùëé, with tuples of states. Hence, for a leaf
node ùë£

carrying an ùëé, ùõø(ùëû, ùëé) = ‚àÖ means that there is no possibility to continue the
labelling past ùë£ in a run; and ùõø(ùëû, ùëé) = {()} means there is exactly one
possibility to label ùë£ 's zero children, namely with the empty tuple of states.
This defines, in a natural way, an acceptance condition: we write , resp. ‚ä∫
instead of ‚àÖ, resp. {()}, and then ùõø(ùëû, ùëé) = means unsuccessful finishing of
a branch in a run, and ùõø(ùëû, ùëé) = ‚ä∫ means successful finishing. In this way,
NtdTA, that do not have explicit accepting or final states, do indeed have a
final assignment in terms of ùõø0, just like NbuTA have an initial assignment.
Definition 11.15 A run of an NtdTA A = (ùëÑ, Œ£, ùëû , ùõø
ùêº
) on a Œ£-tree ùë° is a ùúå ‚à∂ dom(ùë°) ‚Üí
ùëÑ that satisfies the following.
‚Ä¢ ùúå(ùúÄ) = ùëû ùêº,
‚Ä¢ (ùúå(ùë£0), . . . , ùúå(ùë£(ùëë ‚àí 1))) ‚àà ùõøùëë(ùúå(ùë£), ùë°(ùë£)) for all ranks ùëë ‚â• 1, all ùëé ‚àà Œ£ùëë and
all ùë£ ‚àà dom(ùë°) such that ùë°(ùë£) = ùëé.
Such a run ùúå is accepting if ùõø(ùúå(ùë£), ùë°(ùë£)) = ‚ä∫ for all leaf nodes ùë£ ‚àà dom(ùë°).
The language of the NtdTA A is, as usual, ùêø(A) ‚à∂= {ùë° ‚à£ there is an accepting
run of A on ùë°}.
We remark that there is a slightly shorter way to define an accepting run:
simply demand the statement in the second bullet not just for all ùëë ‚â• 1 but
for all ùëë ‚â• 0. The case of ùëë = 0 is exactly what is stated in the additional
requirement above for a run to be accepting. Hence, if the requirements on
a run were formulated for all ùëë ‚â• 0, then all runs would be accepting. This
would not render non-accepting runs suddenly as accepting. It just means
that non-accepting runs would not be classified as runs at all anymore, and
the class of NtdTA-recognisable languages remains ex actly the same.
Example 11.16 Let Œ£ = {ùëé, ùëè, ùëê} with rk Œ£(ùëé) = rk Œ£(ùëè) = 2, and rk Œ£(ùëê) =
0.

The language of all Œ£-trees that contain at least one occurrence of the letter
ùëè is
‚àí
+
‚àí
NtdTA-recognisable, for instance by the automaton A ‚à∂= ({ùëû , ùëû }, Œ£, ùëû , ùõø)
with the following transitions.
‚àí
‚àí
+
+
‚àí
+
+
+
ùõø(ùëû , ùëé) = {(ùëû , ùëû ), (ùëû , ùëû )}
ùõø(ùëû , ùëé) = {(ùëû , ùëû )}
‚àí
+
+
+

+
+
ùõø(ùëû , ùëè) = {(ùëû , ùëû )}
ùõø(ùëû , ùëè) = {(ùëû , ùëû )}
‚àí
+
ùõø(ùëû , ùëê) =
ùõø(ùëû , ùëê) = ‚ä∫
‚àí
A uses its state ùëû
to signal, at any node ùë£, that the subtree under ùë£ is still required
‚àí
to contain some ùëè. Clearly this is what is needed for the root node; hence,
ùëû
is the
+
starting state. The state ùëû is used to signal that no requirement holds
anymore. This
‚àí
+
is why A moves from state ùëû

to ùëû
at both children when seeing a ùëè for instance.
At last, the entire tree contains some ùëè if no more requirement to see a ùëè is
signalled at any leaf node.
‚àí
Nondeterminism is used in the transition out of state ùëû
with the symbol ùëé. So A
effectively guesses the position at which to find a symbol ùëè in the
underlying tree.
294
11 Automata on Finite Trees
ùõø
ùõø
0
2
ùëû ùëé
ùõø (ùëû, ùëé)
ùõø
ùëû ùëé
ùõø
1

(ùëû, ùëé)
0
2
0 0
‚ä∫
ùëû ùëé
ùõø (ùëû, ùëé)
1
0 ‚àß {(0, 0), (0, 1), (1, 0)}
1 0
0 ¬¨
1
1 ‚àß
{(1, 1)}
0 1
1 ¬¨
0
0 ‚à®
{(0, 0)}
1 1

‚ä∫
1 ‚à® {(0, 1), (1, 0), (1, 1)}
Fig. 11.4 Transition table of an NtdTA recognising Boolean expressions that
evaluate to 1.
We consider a second example which can be used to compare top-down
with bottom-up tree automata.
Example 11.17 Recall the language of all Boolean expressions that
evaluates to 1, modelled as trees over the ranked alphabet Œ£ = Œ£0 ‚à™ Œ£1 ‚à™
Œ£2 with Œ£0 = {0, 1}, Œ£1 = {¬¨} and Œ£2 = {‚àß, ‚à®}.
A NtdTA recognising this language is ({0, 1}, Œ£, 1, ùõø) with transition table ùõø
shown in Fig. 11.4. Intuitively, it guesses the value at each subexpression
that this evaluates to, using its two states 0, 1. Surely, it has to start with
state 1 at the root as the entire expression is supposed to evaluate to 1.
When encountering a negation symbol, the state is flipped. At a conjunction,
for instance, in state 1 there is only one possibility that this could be the
value of that subexpression, namely when both its subexpressions evaluate
to 1 as well. This is why there is only one transition to (1, 1). There are
three possibilities, though, for the value to become 0, namely when one or
both its subexpressions evaluate to 0. The NtdTA uses nondeterminism to
guess which of these is the case and continues to confirm its guess.
The behaviour at leaf nodes is then clear: the value of a subexpression at a
leaf node is its label, so the NtdTA simply confirms that the state reached at
that leaf node equals its label.
There are obvious differences between the top-down automaton in this
example and the bottom-up automaton in Ex. 11.7, most notably the fact
that the bottom-up automaton is deterministic while it is unclear how to
avoid nondeterminism in the top-down variant for this language. On the
other hand, there are also notable commonalities, in particular the
transition table of the NtdTA in Fig. 11.4 seems to be obtainable from the
DbuTA's in Ex. 11.7 simply by mirroring the tuples in the transition relation.

11.3.2 Expressiveness
Not only does the introduction of this second automaton model, but also this
example in particular, raise two questions: is the deterministic variant of
top-down automata also as expressive as the nondeterministic one, as it is
the case for bottom-up automata? And how does the expressive power of
top-down automata relate to the bottom-up ones? The answer to the first
question is negative in fact, so DtdTA
11.3 Direction Top-Down
295
are in fact weaker than NtdTA in expressiveness. And the answer to the
second question is: in their nondeterministic variant, top-down and bottom-
up automata are equi-expressive.
We will prove the equi-expressiveness result first. The size estimations in the
following two lemmas already suggest that the translations between these
two models are simple.
Lemma 11.18 For every NtdTA A of size ùëõ there is an NbuTA B of size ùëõ
such that ùêø (B) = ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø
ùêº
)
be an NtdTA. We construct the NbuTA B as
‚Ä≤
(ùëÑ, Œ£, ùõø , {ùëû ùêº }) where
‚Ä≤
ùëû ‚àà ùõø ((ùëû , . . . , ùëû

, . . . , ùëû
1
ùëë ), ùëé )
iff
(ùëû1
ùëë ) ‚àà ùõø(ùëû , ùëé)
for any ùëû ‚àà Œ£ùëë and any rank ùëë .
The size estimation on B is obvious, and the fact that it accepts the same
language as A is a direct consequence of the fact that a run ùúå of A on some
tree ùë° is a run of B on ùë° and vice-versa. Moreover, it is accepting for A iff it
is accepting for B since ùúå(ùúÄ) = ùëû ùêº in both cases, and we have ùõø(ùúå(ùë£), ùë°(ùë£)) = ‚ä∫
iff ùúå(ùë£) ‚àà ùõø(ùë°(ùë£)) for every leaf node ùë£. Hence, ùúå is in the initial state for A on
ùúÄ, resp. in the only accepting state for B; the assignment of states to leaf
nodes is a final assignment for A and an initial assignment for B.
‚óª
The proof already suggests that the converse direction is equally simple: an
NbuTA can equally be regarded as an NtdTA. There is only a tiny technical
difference, though: while in the direction above the NtdTA's initial state
becomes the single accepting state of the NbuTA, an NbuTA may in general
have several accepting states but the corresponding NtdTA is required to
have a single initial state. We can employ the usual trick of adding a new
state that nondeterministically mimics the top-down behaviour of any of
NbuTA's accepting states. This is standard procedure, so a formal proof for
this direction is omitted.
Lemma 11.19 For every NbuTA A of size ùëõ there is an NtdTA B of size at
most ùëõ + 1
such that ùêø(B) = ùêø(A) .

Putting these two lemmas together we obtain equi-expressiveness of the two
tree automaton models.
Theorem 11.20 A tree language is NtdTA-recognisable iff it is NbuTA-
recognisable.
Equi-expressiveness only holds because of the availability of
nondeterminism which allows an NtdTA in a state ùëû at some node ùë£ to
guess the tuple of states (ùëû , . . . , ùëû
1
ùëë ) at ùë£'s children that an NbuTA came from when it entered ùëû and vice-
versa. Note that we do not only have equi-expressiveness but basically
equality of the models. It makes use of the fact that
ùëë
ùëë
ùëÑ √ó Œ£ùëë √ó ùëÑ
‚âÉ ùëÑ
√ó Œ£ùëë √ó ùëÑ
296
11 Automata on Finite Trees
for any ùëë ‚â• 0. Coming back to the proposition that a word automaton does
not really read a word from left to right and a tree automaton does not
really read a tree from top to bottom or from bottom to top but only provides
- in the form of its transition table - local rules for labelling a tree with
states, it is not surprising that a NtdTA can directly be seen as an NbuTA
and vice-versa. The transition table of either model provides rules that
declare certain combinations of a state at a node, an alphabet symbol at
that node, and states at the node's children to be valid in a r un.

The equivalence between NtdTA and NbuTA is a strong argument for
considering this model to be a rightful extension of the NFA model to trees.
We will therefore allow ourselves to speak of a (nondeterministic) tree
automaton (NTA) and use the bottom-up or top-down mode, whatever is
more convenient in that situation. We also call a tree language regular
when it is recognised by some NTA.
With NtdTA, NbuTA and DbuTA sharing the same exressiveness, it may be
tempting to assume that DtdTA also recognise the same class of languages.
This is not the case, though, and the counterexample shows that
nondeterminism is sometimes needed in top-down mode when a decision
needs to be made about which of several subtrees should possess certain
properties.
Theorem 11.21 There are regular tree languages that cannot be recognised
by a DtdTA.
Proof Let Œ£ = {ùëé, ùëè, ùëê} with rk Œ£(ùëé) = 2 and rk Œ£(ùëè) = rk Œ£(ùëê) = 0.
Consider the simple tree language ùêø ‚à∂= {ùë° , ùë°
1
2} with ùë°1 ‚à∂= ùëé(ùëè, ùëê) and ùë°2 ‚à∂= ùëé(ùëê, ùëè). It is not hard
to see that it can be recognised by an NTA, for instance ({ùëû , ùëû , ùëû
, ùõø
ùëé
ùëè
ùëê }, Œ£, ùëû ùëé
) with
ùõø(ùëû , ùëé

, ùëû
, ùëû
, ùëè
, ùëê
ùëé
) = {(ùëûùëè
ùëê ), (ùëû ùëê
ùëè )} ,
ùõø(ùëûùëè
) = ‚ä∫ ,
ùõø(ùëûùëê
) = ‚ä∫
and ùõø(ùëû, ùë•) = ‚àÖ, resp. ùõø(ùëû, ùë•) = in all other cases.
Now suppse that A = (ùëÑ, Œ£, ùëû , ùõø
ùêº
) is a DtdBA such that ùêø(A) = ùêø. Since
ùë°1 ‚àà ùêø(A) there is an accepting run ùúå1 of A on ùë°1. So there are states ùëû1 ‚à∂=
ùúå
, ùëû
, ùëé

1(0) and ùëû2 ‚à∂= ùúå1(1) with (ùëû1
2) ‚àà ùõø(ùëû ùêº
). Since A is deterministic, we even
have ùõø(ùëû , ùëé
, ùëû
, ùëè
, ùëê
ùêº
) = {(ùëû1
2)}. Moreover, we have ùõø(ùëû1
) = ‚ä∫ and ùõø(ùëû2
) = ‚ä∫, for
otherwise ùúå1 would not be an accepting run.
Now consider A's behaviour on ùë°2. Note that ùë°2(ùúÄ) = ùëé = ùë°1(ùúÄ), so any run
ùúå2
of A on ùë°2 must satisfy ùúå2(ùúÄ) = ùëûùêº , ùúå2(0) = ùëû1 and ùúå2(1) = ùëû2, for
otherwise A would not be deterministic. Moreover, since ùúå2 is also
accepting, we must have ùõø(ùëû , ùëê
, ùëè
1
) = ‚ä∫ = ùõø(ùëû2

).
Now consider the tree ùë°3 ‚à∂= ùëé(ùëè, ùëè). Clearly, ùë°3 /‚àà ùêø. We can construct a
run ùúå3 of A on ùë°3: we naturally have ùúå3(ùúÄ) = ùëûùêº . Since ùë°3(ùúÄ) = ùëé we can
apply the transition from ùëû
, ùëû
ùêº
via ùëé to (ùëû1
2) and get ùúå3(0) = ùëû1, ùúå3(1) = ùëû2. Now note
that ùë°
, ùëè
3(0) = ùëè and ùúå3(0) = ùëû1 and, as worked out above, ùõø(ùëû1
) = ‚ä∫. Likewise,
ùë°
, ùëè
3(1) = ùëè, ùúå3(1) = ùëû2 and ùõø(ùëû2
) = ‚ä∫. Thus, ùúå3 is an accepting run of A on ùë°3,
contradicting the assumption that ùêø(A) = ùêø.
‚óª
11.3 Direction Top-Down
297
11.3.3 Decision Problems

As with automata on words, automata on trees will serve as the
computational backbone for deciding logics interpreted over trees. This of
course requires the corresponding problems on the automata side, most of
all the non-emptiness problem, to be decidable. It is not hard to see that this
is the case for NTA.
One possibility to determine whether ùêø(A) ‚â† ‚àÖ for some given NTA A =
(ùëÑ, Œ£, ùõø, ùêπ ), here regarded as an NbuTA, is to compute the set of
productive states in a saturation process. Then every state ùëû ‚àà ùëÑ such that
ùõø(ùëû, ùëé) = ‚ä∫ for some ùëé ‚àà Œ£0
is productive in the sense that there is a run on some tree whose root label
is ùëû. The tree simply consists of a single node labelled with that symbol ùëé,
which is both leaf and root. Moreover, suppose that ùëÉ ‚äÜ ùëÑ is a set of states
that are already confirmed to be productive in this sense, and ùëû ‚àà ùëÑ ‚àñ ùëÉ. If
there is some ùëé ‚àà Œ£ùëë , ùëë > 0, such that ùëû ‚àà ùõø((ùëû , . . . , ùëû
, . . . , ùëû
1
ùëë ), ùëé ) for some ùëû1
ùëë
‚àà ùëÉ, then ùëû can also be marked as
productive. A tree that has a run of A ending in ùëû at its root can be
constructed by putting corresponding trees for ùëû , . . . , ùëû
1
ùëë
under a new root labelled ùëé.

It should be clear that the set of productive symbols can be computed in a
terminating process, even in time that is polynomial in the size of A. This
requires the alphabet to be fixed, though. Moreover, it is not hard to show
that this is a sound and complete characterisation of non-emptiness in the
sense that ùêø(A) ‚â† ‚àÖ iff some ùëû ‚àà ùêπ is marked as productive during this
process. This then establishes decidability of the non-emptiness problem for
NbuTA, and therefore also for NtdBA as they can be transformed into one
another easily. We give a different proof, though, making use of the
reachability games introduced in Chp. 3. This serves as a link and
preparation for the material in the following chapter which studies
automata on infinite trees, and it should be clear that such inductive
reasoning about productive states cannot be applied there anymore because
infinite trees are not inductive data str uctures.
Theorem 11.22 The non-emptiness problem for NTA is decidable in
polynomial time.
Proof We show that non-emptiness of an NtdBA (and therefore also an
NbuTA) can be characterised as a reachability game. Let A = (ùëÑ, Œ£, ùëû , ùõø
ùêº
) be an NtdTA with
Œ£ = Œ£0 ‚à™ . . . ‚à™ Œ£ùëö, i.e. ùëö is the maximal rank of a symbol in Œ£. A induces
the reachability game G
, ùëâ , ùë£
, ùê∏ , ùêπ
A = (ùëâ , ùëâ0
1
ùêº
) with the following components.

‚Ä¢
ùëö
ùëñ
The node set is ùëâ ‚à∂= (ùëÑ √ó{0})‚à™(‚ãÉ
ùëÑ √ó {1}), i.e. nodes are either pairs (ùëû, 0)
ùëñ=0
with some automaton state ùëû, or are pairs ((ùëû , . . . , ùëû
1
ùëë ), 1) for some ùëë-tuple of
automaton states. In fact, it suffices to restrict ourselves to those tuples that
occur in the image of some transition of A, as all other tuples will not be
reachable in G A from the initial node anyway.
‚Ä¢ The partition into nodes belonging to player 0 and those belonging to
player 1 is encoded into the nodes themselves: we have ùëâ0 ‚à∂= ùëÑ √ó {0} and
ùëâ1 then consists of the remaining nodes. Hence, player 0 makes a choice
when given an automaton state, player 1 makes a choice when given a tuple
of states that could be used to label the children of a node.
298
11 Automata on Finite Trees
‚Ä¢
ùêº
The initial node is (ùëû , 0), i.e. player 0 begins.
‚Ä¢ The game's edges are given as follows.

ùëö
ùê∏
‚à∂= ‚ãÉ ( ‚ãÉ {((ùëû, 0), ((ùëû , . . . , ùëû
, . . . , ùëû
1
ùëë ), 1)) ‚à£ (ùëû1
ùëë ) ‚àà ùõø(ùëû , ùëé )}
ùëë=1
ùëé‚ààŒ£
‚à™ {(((ùëû , . . . , ùëû
,
1
ùëë ), 1), (ùëûùëñ 0)) ‚à£ ùëñ ‚àà {1, . . . , ùëë}} )
Thus, whenever it is player 0's turn in a state ùëû, she chooses a transition
from ùëû to some tuple (ùëû , . . . , ùëû
1
ùëë )
via some ùëë-ary symbol. Player 1 then responds
by picking one of the states in this tuple. These games are therefore strictly
turn-based.

‚Ä¢ The winning condition for player 0 in the form of a set of game nodes to
be reached is ùêπ ‚à∂= {(ùëû, 0) ‚à£ ‚àÉùëé ‚àà Œ£0 s.t. ùõø(ùëû, ùëé) = ‚ä∫}. I.e. it consists of all
states that can label a leaf in an accepting run of A on some tree.
It should be clear that the size of GA is polynomial in the size of A. The
degree of the polynomial may depend on the maximal rank in Œ£, hence for
the theorem's statement to be true we need to require Œ£ to be fixed. By Thm.
3.26, reachability games can be solved in polynomial time. This
immediately establishes a polynomial bound on the time complexity of the
non-emptiness problem for NTA.
It remains to be seen that GA correctly characterises non-emptiness for A,
i.e.
that player 0 has a winning strategy for GA iff ùêø(A) ‚â† ‚àÖ.
"‚áê" Suppose ùë° ‚àà ùêø(A) and ùúå is an accepting run of A on ùë°. We define a
strategy ùúé0 for player 0 as follows. Note that, in general, such a strategy is
a function of
‚àó
type ùëâ ùëâ0 ‚Üí ùëâ . Since these games are strictly turn-based, it suffices to
define ùúé0
for histories of even length. Moreover, the second component in each game
node, that only signals whose turn it is, is irrelevant for this, and so we can
represent the history of a game as a sequence ùêª = ùëû , q
, q
, q
, ùëû
0
0, ùëû1

1, . . . , ùëûùëõ‚àí1
ùëõ‚àí1
ùëõ such that ùëûùëñ is
an element of the tuple qùëñ‚àí1 for all ùëñ = 1, . . . , ùëõ ‚àí 1. Note that ùêª defines a
unique node ùë£ (ùêª) in ùë° via ùë£(ùëû
, ùëû
0) ‚à∂= ùúÄ, and ùë£(ùêª, qùëõ‚àí1
ùëõ ) ‚à∂= ùë£ (ùêª )ùëë where ùëû ùëõ occurs in position
ùëë in qùëõ‚àí1 (starting with 0).
This can be seen as player 0 tracing a path through ùë° in order to guide her
choices.
Then let ùúé0(ùêª) ‚à∂= (q, 1) such that the children of ùë£(ùêª) are labelled with q in
ùúå.
In other words, player 0 does not just trace the play as a branch through ùë°.
She also performs her choices according to the state labelling in ùúå.
Meanwhile, player 1
responds by picking one particular state and therefore implicitly selects a
child node.
Note that several children could be labelled with the same state but player 1
can only choose the state, not the exact direction. This state then determines
the extension of the branch that player 0 follows by one more level. If the
selected state ùëû occurs multiple times then she simply extends the branch in
any of the matching directions.
It is easy to see that this is indeed a winning strategy for player 0 because
eventually the constructed branch in ùë° will have to hit a leaf node ùë£, and by

the assumption that ùúå is an accepting run, we have ùúå(ùë£) ‚àà ùêπ, i.e. the play
has reached a final node.
"‚áí" Suppose that player 0 has a winning strategy for GA. According to
Thm. 3.25
she has a positional strategy ùúé0. This can be used to iteratively construct a
tree ùë°
with an accepting run ùúå. Let ùúå(ùúÄ) ‚à∂= ùëûùêº . The root label ùë°(ùúÄ) of ùë° is obtained
from
11.3 Direction Top-Down
299
((0), 1)
(1, 0)
((0, 1), 1)
((1, 1), 1)
((1), 1)
(0, 0)
((1, 0), 1)
((0, 0), 1)
Fig. 11.5 Non-emptiness as a reachability game, here for the NTA from Ex.
11.7.
ùúé
,

0(ùëû ùêº 0). Since ùúé0 is a winning strategy, there must be some ùëé ‚àà Œ£ùëë for
some ùëë
such that ùúé
,
, ùëé
0(ùëû ùêº 0) = (q, 1) and q ‚àà ùõø(ùëû ùêº
). Then set ùë°(ùúÄ) ‚à∂= ùëé. If ùëë = 0 then we
are finished, otherwise continue the process with the ùëë children 0, . . . , ùëë ‚àí
1 and the s tates in q.
Since ùúé0 is a winning strategy, every play must eventually reach ùêπ which
ensures that the construction on every branch eventually terminates with
some state ùëû and symbol ùëé ‚àà Œ£0 such that ùõø(ùëû, ùëé) = ‚ä∫. This means that ùúå is in
fact accepting.
‚óª
Example 11.23 The reachability game GA for the NTA A of Ex. 11.7,
recognising the set of all Boolean expressions that evaluate to true, is
shown in Fig. 11.5.
It is trivially seen to be won by player 0 because the starting node (1, 0),
corresponding to state 1 and marking player 0's turn next, is the
reachability target. The reason for this is the existence of a very small tree
representing a Boolean expression that evaluates to 1, namely the constant
1 itself. The corresponding run marks it with state 1, and this is why this
node is part of the winning condition.
The moves player 0 can make from her two states to the left correspond to
the choice of the symbol ¬¨. It changes the state accordingly; player 1 has
not real choice here. The moves to the four states on the right correspond to
choices of transitions under the symbols ‚àß and ‚à®.

Every Boolean expression that evaluates to 1 induces a winning strategy for
player 0 in this game. Take for instance the expression ¬¨1 ‚à® (1 ‚àß ¬¨0). The
strategy that is induced by it is best shown as a tree itself, namely the one in
Fig. 11.6. It shows, when read from top to bottom, a move for player 0 in
response to all possible player-1
moves occurring in such a play. The branching on the right to two nodes of
the form (1, 0) can be interpreted as two different ways that player 1 can
choose to continue with state 1 after being given the transition into (1, 1).
Interestingly, while every tree in L(A) induces a strategy in GA for player 0,
not every strategy corresponds uniquely to a tree. For example, the Boolean
expression
¬¨1 ‚à® (1 ‚à® ¬¨0) gives rise to the same strategy. The reason is the fact that
the strategy
300
11 Automata on Finite Trees
(1, 0)
1 ‚à®
((0, 1), 1)
0
1
¬¨
‚àß
(0, 0)
(1, 0)

1
1
1
((
((
1
1
¬¨
1), 1)
1, 1), 1)
0
(
(
0
1, 0)
1, 0)
(1, 0)
((0), 0
(0, 0)
Fig. 11.6 Every tree in the language of an NTA A induces a winning
strategy for player 0 in the non-emptiness game GA, here for the NTA from

Ex. 11.7 and the tree shown on the left with a corresponding accepting run.
only depends on the structure of the tree and the accepting run on it, but not
directly on the tree's alphabet symbols.
Decidability of non-emptiness, together with effective closure properties, in
particular closure under complements (Cor. 11.10) and intersections (Thm.
11.11) yields decidability of the other standard decision problems as well.
Since complementation incurs an exponential blowup, we obtain
decidability in exponential time for these other problems.
Corollary 11.24 The universality, subsumption and equivalence problems
for NTA are decidable in exponential time.
11.4 Monadic Second-Order Logic on Finite Trees
An important application of decidability of non-emptiness for tree automata
is, again, decidability of the satisfiability problem for logics that can
effectively be translated into NTA. A natural candidate for such a logic is
Monadic Second-Order Logic interpreted over trees. At close inspection,
one sees that a formal definition of such a logic in analogy to MSO over
(finite) words requires a few technical adjustments.
As usual, first-order variables should be interpreted as positions in a tree,
and second-order variables as sets of positions. While a formula like ùë• < ùë¶
has a very natural interpretation on words with their total order on
positions, one could allow
11.4 Monadic Second-Order Logic on Finite Trees
301
formulas like these in the syntax and interpret the symbol '<' as the
(generator of the) partial order given by the positions in the tree with the
root being the minimal element. This would be oblivious to the order on
children, though. For example, the trees ùëé(ùëè, ùëê) and ùëé(ùëê, ùëè) would be
indistinguishable.

In order to remedy this, we can recall that in the presence of second-order
quantification, '<' on words was expressible using the successor function.
This gives rise to an extension of the word logic MSO[ succ] to a tree logic:
we introduce several successor functions succ ùëñ that map each node to its ùëñ-
th child (if it exists). One just has to be aware of potential conflicts with the
alphabet ranks. For instance, the formula
ùúì1
ùúì2
¬≥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∑¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π
¬π¬π¬π¬π¬π¬µ
¬≥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∑¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π
¬π¬µ
‚Ä≤
‚Ä≤
‚àÉùë•‚àÉùë¶‚àÉùëß. (¬¨‚àÉùë• . succ
, ùë•
ùëé
0(ùë•
)) ‚àß
(ùë•) ‚àß ùëè(ùë¶) ‚àß ùëê(ùëß) ‚àß
succ 0(ùë•, ùë¶) ‚àß succ 1(ùë•, ùëß) ‚àß ¬¨‚àÉùë£. succ 0(ùë¶, ùë£) ‚à® succ 0(ùëß, ùë£)
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π
¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂

¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π
¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùúì
ùúì
3
4
is then satisfied by exactly the tree ùëé(ùëè, ùëê). It demands the existence of
three nodes ùë• , ùë¶, ùëß such that
a) ùë• has no predecessor, i.e. no parent, so it must be the root node (ùúì 1), b)
ùë•, ùë¶ and ùëß are labelled with ùëé, ùëè and ùëê accordingly (ùúì 2),
c) ùë¶ is the first child of ùë• and ùëß is the second (ùúì 3),
d) neither ùë¶ nor ùëß have a first successor, so no successor at all, i.e. they are
leaves (ùúì4).
On the other hand, the formula
2
ùúë(ùë•)
‚à∂= ‚àÉùë•
.ùëé
0‚àÉùë•1‚àÉùë•2
(ùë•) ‚àß ‚ãÄ succ ùëñ (ùë•, ùë•ùëñ )
ùëñ=0

is satisfied by a node ùë£ in a tree when it is labelled with ùëé and has at least
three successors. This is of course not possible over a ranked alphabet
which gives the letter ùëé the rank 2.
There are several possibilities to overcome this small technical issue. A
restrictive option is to define this variant of MSO only for particular
alphabets, for instance to demand that every rank is either 0 or 2. But even
then one would have to be able to see whether a formula demands some
node to have two or zero children, and this essentially boils down to
deciding satisfiability again. So we refrain from trying to solve the problem
syntactically and simply accept that there are formulas like ùúë(ùë•) above that
are unsatisfiable because of a mismatch in demands on the ranks of certain
nodes.
Definition 11.25 Let Œ£ be a ranked alphabet and ùëö ‚à∂= max{ rk Œ£(ùëé) ‚à£ ùëé ‚àà
Œ£}. Again, we fix two countable and disjoint sets V1 = {ùë•, ùë¶, . . .} of first-
order variables and V2 = {ùëã, ùëå , . . .} of second-order variables. Formulas
of Monadic Second-Order Logic (MSO) are given by the following
grammar.
302
11 Automata on Finite Trees
ùúë
‚à∂‚à∂= succ ùëñ (ùë•, ùë¶) ‚à£ ùëã (ùë•) ‚à£ ùëé(ùë•) ‚à£ ùúë1 ‚à® ùúë2 ‚à£ ¬¨ùúë ‚à£ ‚àÉùë• ùúë ‚à£ ‚àÉùëã ùúë
where ùëé ‚àà Œ£, ùë•, ùë¶ ‚àà V1, ùëã ‚àà V2 and 0 ‚â§ ùëñ < ùëö.
All the syntactical concepts like formula size, set of subformulas, free and
bound variables, first-order formulas, etc. carry over from MSO over words
to this logic straightforwardly.
We will also use the acronym MSO for Monadic Second-Order Logic over
trees since it will always be clear from the context whether we consider the
variant interpreted over words or the one interpreted over trees. We will of

course also use other logical symbols like ‚àß, ‚Üí etc. which can be
introduced via the standard abbreviations.
The interpretation of an MSO formula over a Œ£-tree is also
straightforwardly extended from words.
Definition 11.26
‚àó
Let Œ£ be a ranked alphabet, ùë° ‚àà TŒ£ , and ùêº ‚à∂ (V1 ‚Üí dom(ùë°)) + (V2 ‚Üí
2 dom(ùë°)) be an assignment of the first-order variables by nodes in ùë° and
the second-order variables by sets of such nodes, resp. positions.
We say that the interpretation of ùë° and ùêº satisfies the MSO formula ùúë, if ùë°, ùêº
‚äß ùúë
holds according to the following rules.
ùë° , ùêº ‚äß succ ùëñ (ùë•, ùë¶)
iff
ùêº (ùë¶) = ùë£ùëñ whenever ùêº(ùë•) = ùë£
ùë° , ùêº ‚äß ùëã (ùë•)
iff
ùêº (ùë•) ‚àà ùêº (ùëã )
ùë° , ùêº ‚äß ùëé(ùë•)
iff
ùë° (ùêº (ùë•)) = ùëé
ùë° , ùêº ‚äß ùúë ‚à® ùúì

iff
ùë° , ùêº ‚äß ùúë or ùë°, ùêº ‚äß ùúì
ùë° , ùêº ‚äß ¬¨ùúë
iff
ùë° , ùêº /
‚äß ùúë
ùë° , ùêº ‚äß ‚àÉùë• ùúë
iff
there is ùë£ ‚àà dom(ùë°) such that ùë§, ùêº[ùë• ‚Ü¶ ùë£] ‚äß ùúë
ùë° , ùêº ‚äß ‚àÉùëã ùúë
iff
there is ùëÄ ‚äÜ dom(ùë°) such that ùë§, ùêº[ ùëã ‚Ü¶ ùëÄ] ‚äß ùúë
Semantical notions like equivalence between two formulas etc., are defined
as they are for formulas interpreted over words. Again, the interpretation of
a formula ùúë
without free variables in a tree is independent of any variable assignment,
in which case we also simply write ùë° ‚äß ùúë instead of ùë°, ùêº ‚äß ùúë for some
arbitrary ùêº. Then such a
‚àó
sentence defines a tree language in the usual way via ùêø(ùúë) ‚à∂= {ùë° ‚àà TŒ£ ‚à£ ùë° ‚äß
ùúë}.
The root of a tree is obviously definable using a first-order formula, and so
are all children of a node. We make use of this and introduce the following

abbreviations for arbitrary formulas ùúì(ùë•), first-order variables ùë¶ and
directions ùëñ.
ùúì (ùúÄ)
‚à∂= ‚àÉùë•.(¬¨‚àÉùë¶. succ 0(ùë¶, ùë•)) ‚àß ùúì(ùë•)
ùúì ( succ ùëñ (ùë¶)) ‚à∂= ‚àÉùë•. succ ùëñ (ùë¶, ùë•) ‚àß ùúì( ùë•)
Example 11.27 Reconsider the example representing Boolean expressions
as trees over the ranked alphabet {0, 1, ¬¨, ‚àß, ‚à®}. The aim is to exemplify
the use of MSO
by defining the set of all such Boolean expressions that evaluate to 1 in
MSO. In order to avoid an awkward look of the formula arising from the
use of ¬¨, ‚àß, ‚à® both as alphabet symbols and as logical symbols in the
formula, we use ùëé¬¨, ùëé‚àß and ùëé‚à® to denote the alphabet symbols of ranks 1
and 2.
11.4 Monadic Second-Order Logic on Finite Trees
303
Then the language of all such expressions that evaluate to 1 is defined by
the following sentence.
‚àÉùëá ‚àÉùêπ .(‚àÄùë£ .ùëá (ùë£) ‚Üî ¬¨ùêπ (ùë£)) ‚àß ùëá (ùúÄ) ‚àß
‚àÄùë£ .(ùëá (ùë£) ‚Üí (¬¨0(ùë£) ‚àß (ùëé¬¨(ùë£) ‚Üí ùêπ( succ 0(ùë£))) ‚àß
(ùëé‚àß(ùë£) ‚Üí ùëá ( succ 0(ùë£)) ‚àß ùëá ( succ 1(ùë£))) ‚àß
(ùëé‚à®(ùë£) ‚Üí ùëá ( succ 0(ùë£)) ‚à® ùëá ( succ 1(ùë£))))) ‚àß
(ùêπ (ùë£) ‚Üí (¬¨1(ùë£) ‚àß (ùëé¬¨(ùë£) ‚Üí ùëá ( succ 0(ùë£))) ‚àß
(ùëé‚àß(ùë£) ‚Üí ùêπ( succ 0(ùë£)) ‚à® ùêπ( succ 1(ùë£))) ‚àß
(ùëé‚à®(ùë£) ‚Üí ùêπ( succ 0(ùë£)) ‚àß ùêπ( succ 1(ùë£)))))

It states that the nodes of a given Œ£-tree can be labelled with predicates ùëá ,
ùêπ so that they form a partition on the nodes, the root belongs to ùëá and the
classification follows the usual evaluation rules for Boolean operators so
that a node ùë£ belongs to the interpretation of ùëá iff the subexpression at this
node evaluates to 1, and likewise for ùêπ and 0.
We can use the same automata-theoretic approach to MSO over finite trees
as used for MSO of finite or infinite words: an MSO formula over finite
trees can be normalised to only contain second-order variables, and then
we can inductively translate it into an NTA over an extended alphabet that
is used to encode a valuation of the free second-order variables in the
formula. Details are left as an exercise.
Theorem 11.28 For every MSO sentence ùúë over some ranked alphabet Œ£
there is an NTA Aùúë such that ùêø(Aùúë ) = ùêø(ùúë) .
The fact that Aùúë is effectively constructible from ùúë and non-emptiness for
NTA was established to be decidable in Thm. 11.22 then immediately yields
decidability for MSO again.
Corollary 11.29 The satisfiability problem for MSO over finite trees is
decidable.
Since MSO features negation, problems like validity of a formula or
equivalence between two formulas can immediately be reduced to the
satisfiability problem.
Corollary 11.30 The validity and equivalence problem for MSO over finite
trees is decidable.
It should be clear that the lower bounds established for MSO over words
immediately carry over to the world of trees since every word over an
alphabet Œ£ can be encoded as tree over an alphabet Œ£‚Ä≤ ‚à∂= Œ£ ‚à™ {#} with all
letters from Œ£ seen as unary
304
11 Automata on Finite Trees

symbols and one extra symbol # of rank 0 to mark the end of a word with an
extra leaf node. Since ùêø is regular iff ùêø# is regular, this does not change the
fact that lower bounds on the satisfiability of MSO over words immediately
carry over to MSO over trees. In particular, satisfiability is not decidable in
elementary time.
One could argue that satisfiability for MSO over ranked alphabets other
than those in which one letter has rank 0 and all others have rank 1, is not
covered by this argument. So perhaps MSO over ranked alphabets with all
letters having rank either 2 or 0 could be easier to decide. It is not difficult,
though, to refute this by encoding words as trees in a different way, for
instance by degenerate trees in which every node has two successors, of
which at least one is a leaf.
Not surprisingly, MSO over finite trees is also strong enough to express the
existence of a run of an NTA on a given tree. Spelling this out is also left as
an exercise.
Theorem 11.31 For every NTA A there is an MSO formula ùúëA of size
polynomial in ‚à£A‚à£ such that ùêø(ùúëA) = ùêø(A) .
Hence, MSO over finite trees, NbuTA, NtdTA and DbuTA all have the same
expressive power, and that of DtdBA is weaker.
11.5 Applications
We study two applications of automata over finite trees. The first one
considers the question of equality of two terms of a simply typed ùúÜ-calculus
under certain congruences. The second one shows that tree automata can
be used in database querying, namely for semi-structured data, i.e. XML
documents. We assume some basic familiarity with the concepts of XML and
the ùúÜ-calculus.
11.5.1 Higher-Order Matching
The simply typed ùúÜ-calculus can be seen as an abstract programming
language with types and no recursion. Types ùúè are defined inductively via

ùúè
‚à∂‚à∂= o ‚à£ ùúè , . . . , ùúè
1
ùëõ ‚Üí ùúè
where o is some base type. The type constructor ‚Üí is used to build types of
functions with arguments. For instance, the type
o, (o, o ‚Üí o) ‚Üí (o ‚Üí o)
describes functions that take two arguments and return a function. The first
argument is a value of the base type, and the second argument is a binary
function on the basetype. The return value is a unary function on the base
type. An example of a
11.5 Applications
305
function of this type is the specialisation function sp ‚à∂ (ùë•, ùëì ) ‚Ü¶ ùëìùë• where ùëìùë•
(ùë¶) =
ùëì (ùë•, ùë¶).
The order of a type describes the nesting depth of functions in arguments. It
is defined via
ord(o) ‚à∂= 0 ,
ord(ùúè , . . . , ùúè
1
ùëõ ‚Üí ùúè ) ‚à∂= max ({ ord(ùúè)}‚à™{1+ ord(ùúèùëñ ) ‚à£ ùëñ = 1, . . . , ùëõ }) ùëÜ
We assume a set

of constants and function symbols, each associated with a type,
and a set ùëã of variable names. The set of terms of ùëÜ is then given by the
following grammar.
ùë° , ùë°
, . . . , ùë•
.ùë°
, . . . , ùë°
ùëñ
‚à∂‚à∂=
ùëì ‚à£ ùë• ‚à£ ùúÜùë•1
ùëõ
‚à£ ùë° (ùë°1
ùëõ )
where ùëì ‚àà ùëÜ, ùë• ‚àà ùëã .
This grammar also allows non-well-typed terms. We restrict attention to
well-typed terms. A stringent definition requires the introduction of a simple
typing system. Here we introduce this on a less formal level since the
concept is quite intuitive: every function symbol ùëì has a type ùúè by
assumption which we write as ùëì
‚à∂ ùúè. Variables ùë• need to be given types as well. If ùë•1 ‚à∂ ùúè1, . . . , ùë•ùëõ ‚à∂ ùúèùëõ and ùë° ‚à∂ ùúè,
then the term ùúÜùë• , . . . , ùë• .ùë°
, . . . , ùúè
1

ùëõ
has type ùúè1
ùëõ ‚Üí ùúè . At last, if ùë°1 ‚à∂ ùúè1, . . . , ùë°ùëõ ‚à∂ ùúèùëõ and
ùë° ‚à∂ ùúè , . . . , ùúè
, . . . , ùë°
1
ùëõ ‚Üí ùúè , then ùë° (ùë°1
ùëõ ) ‚à∂ ùúè .
ùúè
A well-typed term then has a unique type
, which gives terms an order as well
via ord(ùë°) ‚à∂= ùëõ if ùë° ‚à∂ ùúè and ord(ùúè) = ùëõ .
Now suppose that the set of functions and constants is finite and only
contains ùëõ
‚Ä≤
objects with types of the form oùëõ ‚Üí o where ùúè ‚Üí ùúè is an abbreviation for
‚Ä≤
ùúè, . . . , ùúè ‚Üí ùúè
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùëõ times

‚Ä≤
‚Ä≤
and ùúè0 ‚Üí ùúè is just ùúè .
Such a finite set ùëÜ induces a ranked tree alphabet Œ£ where rk Œ£( ùëì ) = ùëõ if ùëì
‚à∂ oùëõ ‚Üí o.
In particular, constant symbols have rank 0 and may occur at leaf nodes in
trees representing terms of such types.
We are interested in solving third-order matching equations. These are
equations of the form
ùë• (ùë† , ùë† , . . . , ùë†
1
2
ùëõ )
‚âà ùë°
for terms ùë†ùëñ of type ùúèùëñ = oùëõùëñ ‚Üí o for some ùëõùëñ that contain no free variables,
and ùë° is a variable-free term of type o. The variable ùë• therefore must have
type ùúè , . . . , ùúè
1
ùëõ ‚Üí o.
‚Ä≤
Solving such an equation means computing a term ùë° that makes the
equation above true when substituted in for the variable ùë•. This would be a
rather trivial problem if '‚âà' denoted syntactical equality. It is used to denote

so-called ùõΩùúÇ-equality which is the congruence that is obtained by allowing
(sub)terms to be rewritten according to the rules
(ùõΩ)
(ùúÜùë• , . . . , ùë• .ùë°
, . . . , ùë°
, . . . , ùë°
1
ùëõ
)(ùë°1
ùëõ )
‚âà ùë°[ùë°1/ùë•1
ùëõ /ùë• ùëõ ]
(ùúÇ)
ùúÜùë• , . . . , ùë•
.ùë°
, . . . , ùë•
, . . . , ùë•
1
ùëõ
(ùë•1

ùëõ )
‚âà ùë°
if ùë•1
ùëõ do not occur in ùë°
306
11 Automata on Finite Trees
ùúÜ ùë• , ùë•
1
2
ùë•1
ùë•2
ùë°3
‚ãÆ
ùë•1
ùë•1
ùë°2
‚ãÆ
ùëê
ùë°1
‚ãÆ

Fig. 11.7 A ùúÜ-term as a tree over a ranked alphabet.
where ùë°[ùë°
, . . . , ùë°
1/ùë•1
ùëõ /ùë• ùëõ ]
denotes the term that results from ùë° by simultaneously
replacing each free occurrence of the variable ùë•ùëñ with the term ùë°ùëñ.
Example 11.32 Let ùëÜ = {ùëê, ùëì } with ùëê ‚à∂ o and ùëì ‚à∂ o, o ‚Üí o. Consider the
equation ùë• ((ùúÜ ùë¶ , ùë¶ .ùë¶
. ùëì
, ùë¶
1
2
1), (ùúÜ ùë¶3
(ùë¶3
3)))
‚âà
ùëì (ùëê, ùëê) .
(11.1)
ùë• = ùúÜùë• , ùë• .ùë• (ùëê)

A possible solution is
1
2
2
since
(ùúÜùë• , ùë• .ùë•
, ùë¶
. ùë¶
. ùëì
, ùë¶
. ùëì
, ùë¶
1
2
2(ùëê))((ùúÜ ùë¶1
2
1), (ùúÜ ùë¶3
(ùë¶3
3)))
‚âà (ùúÜùë¶3

(ùë¶3
3))(ùëê)
‚âà
ùëì (ùëê, ùëê )
by two applications of the ùõΩ-rule.
Another possible solution is ùë• = ùúÜùë• , ùë• .ùë•
1
2
1( ùëì (ùëê, ùëê), ùëê) since, equally ,
(ùúÜùë• , ùë• .ùë•
, ùë¶
. ùë¶
. ùëì
, ùë¶
1
2
1( ùëì (ùëê, ùëê), ùëê))((ùúÜ ùë¶1
2
1), (ùúÜ ùë¶3
(ùë¶3

3)))
‚âà (ùúÜùë¶ , ùë¶ .ùë¶
1
2
1)( ùëì (ùëê, ùëê), ùëê)
‚âà
ùëì (ùëê, ùëê) .
Also, any term of the form ùúÜùë• , ùë• .ùë•
, ùë° , ùë°
1
2
1(ùë•2(ùë•1(ùë•1(ùëê, ùë°1), ùë°2)), ùë°3) for arbitrary ùë°1
2
3
is a solution of that equation.
Not only can so-called ground terms like ùëì (ùëê, ùëê) with no ùúÜ-abstractions be
represented as trees over an alphabet that is naturally ranked by the types
of the involved symbols. Even terms with ùúÜ-abstractions can be seen as trees
simply by additionally regarding the operator of the ùúÜ-abstraction as a
unary symbol. The tree representation of ùúÜùë• , ùë• .ùë•
1
2

1(ùë•2(ùë•1(ùë•1(ùëê, ùë°1), ùë°2)), ùë°3) for example is shown in Fig. 11.7.
Example 11.33 We continue the previous example. The goal is now to
construct a DbuTA A that recognises exactly the solutions to equation (11.1)
above. In addition to the symbols ùëê of rank 0, ùë•
, ùë•
2 and ùúÜùë•1
2 of rank 1, and ùë•1 and ùëì of rank 2 we
11.5 Applications
307
q
ùúÜ ùë• , ùë•
fin
1
2
q
ùë•
ùëì
1
q ùëì
ùëì
#

q#
qùëê
ùëê
ùëê
qùëê
Fig. 11.8 Accepting run of the DbuTA from Ex. 11.33 for the term ùúÜùë• , ùë• .ùë• ( ùëì
(ùëé, ùëé), 1
2
1
#).
use another symbol # that should be read as a placeholder for an arbitrary
term.
Naturally, its rank is 0, i.e. it is used as a leaf in a tree representation of a
term.
The DbuTA will have four states q , q , q , q
ùëê
ùëì
#
fin. The first two correspond to
subterms of the right-hand side of (11.1). Recall that the goal is not to
recognise terms syntactically but to recognise terms which equal some
given term modulo ùõΩùúÇ-congruence. This is why state q ùëì for instance may
occur in a run at some node whose subtree is not ùëì (ùëê, ùëê).

The state q# is used to recognise arbitrary subterms represented by the
symbol #, and the state q fin is used to signal the successful completion of a
run, i.e. it is the only final state.
The transitions table ùõø is given as follows.
ùõø2
ùõø
ùõø
0
1
(ùëû , ùëû
, ùëû
1
2) ùëé
ùõø2((ùëû1
2), ùëé)
ùëé
ùõø
ùëû
ùëé
ùõø
0(ùëé)

1(ùëû, ùëé)
(q , q
ùëê
ùëê )
ùëì
q ùëì
ùëê
q
q
ùë•
q
ùëê
ùëì
2
ùëì
(q , q
q
ùëê
#) ùë•1
ùëê

#
q
q ùúÜùë• , ùë•
q
#
ùëì
1
2
fin
(q , q
q
ùëì
#) ùë•1
ùëì
Consider, for instance, the term ùúÜùë• , ùë• .ùë•
1
2
1( ùëì (ùëê, ùëê), #). An accepting run on its tree
representation can be constructed easily and is shown in Fig. 11.8. One can
equally show that ùúÜùë• , ùë• .ùë•

1
2
1(ùë•2(ùë•1(ùë•1(ùëê, #), #)), #) is being accepted. On the other hand,
ùúÜùë• , ùë•
.ùë•
1
2
2(ùë•1( ùëì (ùëê, ùëê), #)) is not being accepted since A gets stuck on it.
A's functionality can be explained as follows. A term ùë° with two variables
ùë•1
and ùë•2 should possess a run of A with label qùëê, resp. q ùëì at the root node iff
ùë°[ùë•1 ‚à∂=
ùúÜ ùë¶
, ùë¶
. ùë¶
, ùë•
. ùëì
, ùë¶
1
2
1

2 ‚à∂= ùúÜ ùë¶3
(ùë¶3
3)] reduces to ùëê, resp.
ùëì (ùëê, ùëê) under ùõΩùúÇ-rewritings.
Moreover, the run on ùë° should assign q
, ùë•
# to the root node iff ùë°[ùë•1 ‚à∂= ùë†1
2 ‚à∂= ùë†2]
reduces to #. This can be shown by induction on the height of ùë°, assuming
ùõΩùúÇ-normal form of ùë°.
This example can be generalised to solve arbitrary matching equations of
the same form as Eq. 11.1.
308
11 Automata on Finite Trees
Theorem 11.34 For every third-order matching equation E one can
construct a DbuTA of polynomial size that recognises exactly the solutions
to E .
Proof Let E be of the form ùë•(ùë† , ùë† , . . . , ùë†
1
2
ùëõ )
‚âà ùë° for a variable-free term ùë° of type

o and closed terms ùë† , . . . , ùë†
1
ùëõ
of types oùëõùëñ ‚Üí o. We construct the desired DbuTA
as AE ‚à∂= (ùëÑ, Œ£, ùõø, ùêπ) where Œ£ and the rankings of its symbols are naturally
given through the function symbols, variables and ùúÜ-abstraction operations
occurring in ùë† , . . . , ùë†
, ùë°
1
ùëõ
with an additional symbol # as a placeholder for arbitrary subter ms.
The state set is ùëÑ ‚à∂= {q
, q
ùë¢ ‚à£ ùë¢ is a subterm of ùë° } ‚à™ {q#
fin}. There is only one final
state: ùêπ ‚à∂= {q fin}.
The transition rules are given as follows. We have
ùõø
, ùúÜùë• , . . . , ùë•
1(ùëûùë°
1

ùëõ )
= q fin
to mark the successful parsing of a tree. As in the previous example, state
q# is used to mark subterms that are irrelevant for the solution, using the
following transition rule.
ùõø(#) = q #
For every subterm ùë£ = ùëì (ùë¢ , . . . , ùë¢
1
ùëö ) of the right-hand side ùë° of E with ùë£ ‚â† # ‚â† ùë¢ùëñ
for all ùëñ = 1, . . . , ùëö, w e add the transition
ùõø((q
, . . . , q
.
ùë¢
ùë¢
), ùëì )
= qùë£
1
ùëö
If ùë†
, . . . , ùë¢

ùëñ (ùë¢ 1
ùëõ ) ‚âà ùë£ under ùõΩùúÇ-equivalence such that ùë£ ‚â† # (while ùë¢ùëñ = # is allowed), we
also add the rule
ùõø((q
, . . . , q
.
ùë¢
ùë¢
), ùë•ùëñ )
= qùë£
1
ùëõ
The size estimation on AE is obvious. For correctness one shows by
induction on the height of a tree ùë° that A
, . . . , ùë†
E has a run on ùë° with the root label qùë¢ iff ùë° (ùë†1
ùëõ ) ‚âà
ùë¢ from which the claim immediately follows that AE recognises exactly the
tree representations of solutions to E . Details are left as an exercise.
‚óª
11.5.2 Tree Automata for XML Data Processing

Tree automata play an important role for semi-structured data, i.e. data
recorded in XML documents. Tree automata can be used for type checking
of XML documents, also known as XML schema checking, and
transformation scripts. XML document, traditionally represented as a string
with nested opening and closing tags, is in fact tree-shaped which each
section from opening to closing tags forming a subtree. The principle can
be seen in Fig. 11.9. The tag names then become tree alphabet symbols.
The example in Fig. 11.9 shows a potential technical mismatch: in an XML
document there is no guarantee that sections with equal tags always have
the same number of included subsections, so that the tag can have a well-
defined rank as a tree alphabet symbol. We will not go into the details of
how to fix this. For the relatively
11.5 Applications
309
<document>
<section>
document
. . .
</section>
section
section
<section>
. . .
</section>

‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
</document>
Fig. 11.9 XML document in traditional representation and when regarded
as a tree.
shallow treatment of XML as an application domain for automata on finite
trees it suffices to assume that XML documents have been modified to have
this property, either by using different symbols for tags of different ranks, or
by reshaping the tree into a binary one, etc.
For transformation scripts that are written in a functional style, a
combination of type checking (in a programming language) and tree
automata can be used to obtain an approximative XML type checking in the
following sense. Suppose schemas, i.e.
descriptions of XML-documents of a particular structure, In and Out are
given, as well as a program ùëÉ that is supposed to transform XML
documents of the form described by In into documents of a form described
by Out. If type checking of ùëÉ
confirms that this program has the type In ‚Üí Out then it is guaranteed that
documents of type In are always transformed into documents of type Out.
However, it is only approximative in the sense that there may be programs
which do this but are not found to have type In ‚Üí Out. The advantage of
this approach is simplicity and efficiency of the type checking method whilst
using a general-purpose programming language.

Alternatively it is possible to obtain an exact type checking analysis based
on transducers, i.e. automata with output. Transducers are not discussed
here any further.
As a concrete example we consider the transformation language XDuce, a
functional programming language for manipulating XML documents. XML
data can be used both as input or output of a function in XDuce. It
possesses standard data types like Float, String, etc. For XML data there
are user-defined types that basically correspond to XML schemas.
An XDuce type definition defines potentially several types by mutual
recursion.
Each type definition names an XML tag and the content of the section
enclosed in the corresponding opening and closing tags in terms of the
types of its subsections.
It uses intuitive regular expression notation to describe valid lists of
subsections that can occur within a section.
Example 11.35 The following is an XDuce type definition.
type Addrbook = addrbook[Person*]
type Person = person[(Name,Tel?,Email*)]
type Name = name[String]
type Tel = tel[String]
310
11 Automata on Finite Trees
addrbook
person
entries

name
details
person
person
<string> email
email
name
details
name
email
<string> <string>
<string>
tel
email
<string> <string>
<number> <string>
Fig. 11.10 Encoding of an XML document as a tree using additional
alphabet symbols to guarantee unique ranks.
type Email = email[String]
It hierarchically defines five types of XML documents. By convention, the
first type listed is the type of an entire document, and the others are used as

types of subdocuments corresponding to subtrees in a tree representation.
The type Person for example defines subtrees that start with the symbol
person and have at least one child node of type Name with one optional
next child of type Tel and then arbitrarily many further children of type
Email.
An example XML document of type Addrbook is the following.
<addrbook>
<person>
<name>Haruo Hosoya</name>
<email>hahosoya@xduce.jp</email>
<email>haruo@xduce.jp</email>
</person>
<person>
<name>Jerome Vouillon</name>
<tel>123-456-789</tel>
<email>vouillon@xduce.fr</email>
</person>
<person>
<name>Benjamin Pierce</name>
<email>pierce@xduce.edu</email>
</person>
</addrbook>

A possible representation as a ranked tree is shown in Fig. 11.10. It
abstracts away from the actual values of the name, address, telephone
number and email sections.
These values are represented by the symbols <string> and number of rank
0.
The representation uses additional symbols of rank 2 in order to produce a
ranked tree. For instance, entries is used to model a list of more than two
person nodes,
Bibliographic Notes for Chapter 11
311
and details is used similarly to cope with cases in which, in addition to a
name, there is more than one email address or one phone number in that
person's record.
It is not hard to construct a tree automaton recognising the language of all
trees that represent XML documents of type Addrbook, once an encoding of
such documents as ranked trees is fixed. XDuce encodes XML documents
internally using ranked trees.
Bibliographic Notes
The study of finite automata on finite trees goes back to work by Doner
[Don70]
and by Thatcher and Wright [TW68] who generalised the notion of finite
automata operating on words, seen as finite monadic algebras, to finite
algebras with operations of higher arity. This way, an automaton can be
seen as classifying terms, and words are just special terms in which all
function symbols have arity 1. They observed that the theory of finite
automata on words can essentially be lifted to a theory of automata on trees
and therefore a theory of regular tree languages with all essential results
being preserved, like determinisability, decidability, closure properties, etc.

The main driving force was - following the work of B √ºchi, Elgot and
Trakhtenbrot
[BE58, Tra61] - the establishing of decidability results for logics like MSO
on finite trees or WS2S, the Weak Monadic Logic of Two Successors.
A notable difference shows up in computational complexity. The
membership problem for word languages can be solved in nondeterministic
logarithmic space, whereas it is hard for polynomial time for tree automata.
Such results are often folklore and cannot necessarily be traced back to a
particular piece of work in the literature. The universality problem for
automata on words is complete for the class PSpace [MS73] whereas for
words it is complete for ExpTime [Sei90] and therefore presumably harder.
+
There is an online book project started in 2007 by Comon et al. [CDG 07]
which is dedicated to the study of tree automata and their applications. It
naturally contains many more references and of course also a far deeper
study of this topic than this chapter here can provide.
Matching problems, as presented in the first application in this chapter,
occur in many applications, for instance in compilation of pattern matching
expression as they are traditionally used in functional programming
languages like ML and Haskell, but also increasingly introduced into
object-oriented languages like Scala or C#. To clarify terminology: a
matching equation is one in which the variables for which a solution is to
be found, only occur on one side. If variables occur on both sides, then the
problem is known as unification.
For a general introduction into the topic of unification see the handbook
article by Baader and Snyder [BS01a]. An introduction into higher-order
unification and matching problems in particular is given by Dowek in the
same handbook [Dow01].
The description of higher-order objects needs a formalism like the ùúÜ-
calculus, invented by Church through a series of papers ending in the
introduction of the typed

312
11 Automata on Finite Trees
ùúÜ-calculus [Chu40]. The literature contains a lot of material dedicated to
this subject and useful as an introduction, for instance the textbooks by
Barendregt [Bar85] and Hankin [Han04].
The algorithm presented here for third-order matching is due to Comon and
Jurski
[CJ97] and can be extended up to order five. Decidability of the matching
problem for arbitrary orders had been open for a long time until Stirling
finally showed that it is indeed decidable [Sti09]. This is only true for
equality modulo ùõΩùúÇ-reductions.
The problem becomes undecidable when only ùõΩ-reductions are considered
[Loa03].
The XML querying and processing language XDuce was developed by
Pierce und Hosoya [HP03]. Hosoya has also written a comprehensive book
on the foundations of XML querying and processing using tree automata
[Hos10]. There is also an overview article by Schwentick on this topic
[Sch07b]. Both provide not only further references but also a much deeper
introduction and study of this connection. This includes, first of all, the
lifting of the technical concept of tree automata to unranked trees which are
more suitable to model XML documents than ranked trees, as the examples
above suggest. This has led to the study of different kinds of tree automata
operating on unranked trees, i.e. trees in which nodes can have arbitrarily
many children regardless of the node's label. Such include stepwise tree
automata [CNT04]
and tree-walking automata [AU71], introduced originally for parsing of
context-free languages long before XML was invented. These then became a
popular domain of application for tree automata.
Such a theory of querying languages for unranked trees would be
incomplete without the study of suitable logics to express their properties.

An overview of such logics based on First-Order and Monadic Second-
Order Logic is given by Libkin
[Lib06].
Transducers, as briefly mentioned in Sect. 11.5.2 but not studied in any kind
of detail here, are finite automata with output. They therefore realise
functions, for instance from trees to trees. For a general introduction to
transducers see the textbook by Berstel [Ber79] for instance. For a closer
look at tree transducers see the
+
corresponding chapter in the book by Comon et al. [CDG 07]. For a
specific look at tree transducers for XML processing see the book by
Hosoya [Hos10] for instance.
Exercises
Exercise 122 Find a ranked alphabet that can be used to model Boolean
expressions over the constants 0, 1 and over variables ùë• , ùë• , . . .
0
1
with the typical Boolean op-
erators. Hint: Since it may be cumbersome to differentiate between
subscript and ordinary symbols, it may be helpful to work with a
representation of these variables that does not rely on subscript symbols,
for instance ùë•(0), ùë•(1), ùë•(2), . . . using decimal representations of numbers.
This causes a little problem, though, as the index 0 clashes with the
constant 0. Could this be alleviated by allowing alphabets to be finite
multisets, so that one symbol can have several ranks? Perhaps it is easier to
use different symbols for the Boolean constants then.
Exercises for Chapter 11

313
Exercise 123 Let Œ£ = {ùëé, ùëè, ùëê, ùëë} with rk Œ£(ùëé) = rk Œ£(ùëè) = 2 and rk Œ£(ùëê) =
rk Œ£(ùëë) =
0. Determine, for each of the following languages, whether they can be
recognised by a nondeterministic or even a deterministic top-down tree
automaton. In the positive case, construct such an automaton, in the
negative case give an argument for why the language is not regular.
‚àó
a) ùêø1 ‚à∂= {ùë° ‚àà TŒ£ ‚à£ the path ùúÄ, 0, 01, 010, 0101, 01010, . . . in ùë° contains an
even number of occurrences of the symbol ùëé},
‚àó
b) ùêø2 ‚à∂= {ùë° ‚àà TŒ£ ‚à£ ùë° is not balanced },
‚àó
c) ùêø3 ‚à∂= {ùë° ‚àà TŒ£ ‚à£ there are two leaves ùë¢, ùë£ in ùë° such that ùë°(ùë¢) = ùëê, ùë°(ùë£) =
ùëë and ùë¢
is further to the left of ùë£},
‚àó
d) ùêø4 ‚à∂= {ùë° ‚àà TŒ£ ‚à£ ùë° contains exactly 239 leaves that are labelled with ùëê}.
Exercise 124 Let Œ£ ‚à∂= {0, 1, ¬¨, ‚àß, ‚à®, ùë•, ùë¶, ùëß} be the extension of the ranked
alphabet from Ex. 11.3 used to model Boolean expressions over the
constants 0 and 1, by symbols ùë•, ùë¶, ùëß of rank 0. This way we can represent
Boolean expressions that contain the variables ùë•, ùë¶ and ùëß, like (¬¨ùë• ‚à® (1 ‚àß
ùëß)) ‚àß ¬¨(ùë¶ ‚àß ¬¨ùëß).
Construct NbuTA over Œ£ for the following languages.

a) The set of all expressions in negation normal form, i.e. expressions that
are built from the literals 0, 1, ùë•, ùë¶, ùëß, ¬¨ùë•, ¬¨ùë¶, ¬¨ùëß using only the operators
‚àß and ‚à®.
b) The set of all monotonic expressions where an expression is said to be
monotonic if the number of negation symbols on every path of its syntax
tree that ends in a variable is even.
c) The set of expressions in disjunctive normal form, i.e. expressions of the
form ùëõ
ùëöùëñ
‚ãÅ
‚ãÄ
‚Ñì
, . . . , ùëö
ùëñ=1
ùëñ , ùëó
for some ùëõ, ùëö
ùëõ
‚â• 0 such that each ‚Ñìùëñ, ùëó is a literal in the
ùëó =1
1
sense of part (a).
d) The set of all expressions that evaluate to 1 under any valuation of the
variables ùë• , ùë¶, ùëß.

e) The set of all expressions that contain at most ùëõ¬¨ occurrences of
negation symbols, at most ùëõ‚àß subexpressions that are conjunctions and at
most ùëõ‚à® subexpressions that are disjunctions, for some arbitrary but fixed
ùëõ , ùëõ , ùëõ
¬¨
‚àß
‚à® ‚àà N.
f) Similar to the previous language but now the numbers of occurrences of
the symbols ¬¨, ‚àß, ‚à® should each be some given ùëõ , ùëõ , ùëõ
¬¨
‚àß
‚à®
modulo some given
ùëö
, ùëö
, ùëö
¬¨
‚àß
‚à® ‚â• 1.
Exercise 125 Show that the set of all parse trees of a context-free language
is a regular tree language. Hint: You may assume that the grammar has
been normalised such that all rules are of the form ùê¥ ‚Üí ùêµùê∂ or ùê∑ ‚Üí ùëé for
some nonterminal symbols ùê¥, ùêµ, ùê∂ , ùê∑ and a some terminal symbol ùëé (ùúÄ-

free Chomsky normal form), and that additionally, whenever there is a rule
of the form ùê¥ ‚Üí ùêµùê∂ then there is no rule of the form ùê¥ ‚Üí ùëé for the same
nonterminal ùê¥.
Exercise 126 Prove Thm. 11.11.
Exercise 127 Prove Lemma 11.13.
314
11 Automata on Finite Trees
Exercise 128 Let A = (ùëÑ, Œ£, ùõø, ùêπ) be an NbuTA. Define a sequence of sets of
states ùëÉùëñ ‚äÜ ùëÑ for ùëñ = 0, . . . as follows. We have ùëÉ0 ‚à∂= ‚àÖ and
ùëÉ
, . . . , ùëû
, . . . , ùëû
ùëñ
‚à∂= ‚ãÉ
‚ãÉ ‚ãÉ{ùõøùëë ((ùëû1
ùëõ ), ùëé ) ‚à£ ùëû 1
ùëë
‚àà ùëÉùëñ‚àí 1}
ùëë‚â•0 ùëé‚ààŒ£ùëë
‚àó
for each ùëñ ‚â• 1. Finally, let ùëÉ ‚à∂= ‚ãÉ

ùëÉ
ùëñ‚â•0
ùëñ .
a) Show that ùëÉùëñ ‚äÜ ùëÉùëñ+1 for all ùëñ ‚â• 0. Hint: Use induction on ùëñ.
‚àó
b) Show that there is an ùëõ such that ùëÉ = ùëÉ ùëõ.
c) Show that the following holds for any ùëû ‚àà ùëÑ and any ùëñ ‚àà N: we have ùëû
‚àà ùëÉ ùëñ iff there is a tree ùë° of height at most ùëñ such that ùë° ‚àà ùêø(Aùëû) where Aùëû
‚à∂= (ùëÑ, Œ£, ùõø, {ùëû}).
d) Conclude that the non-emptiness problem for NTA is decidable in
polynomial time.
e) Derive a small model theorem for NTA, i.e. give a function ùëì ‚à∂ N ‚Üí N that
grows as gently as possible such that for every NTA A of size ùëõ either ùêø(A)
= ‚àÖ
or there is a tree ùë° ‚àà ùêø(A) of size at most ùëì (ùëõ).
Exercise 129 Write an FO formula that defines the set of all Boolean
expressions in conjunctive normal form over a fixed set of variables ùëâ ‚à∂= {ùë•
, . . . , ùë•
1
ùëò }, i.e.
ùëõ
ùëöùëñ
expressions of the form ‚ãÄ

‚ãÅ
‚Ñì
where each ‚Ñì
is either ùë•
ùëñ=1
ùëñ , ùëó
ùëñ , ùëó
‚Ñé or ¬¨ùë• ‚Ñé for some
ùëó
ùëñ
ùëñ
ùëñ =1
‚Ñé ‚àà {1, . . . , ùëò }. The ranked alphabet is given as Œ£0 = ùëâ , Œ£1 = {¬¨} and
Œ£2 = {‚àß, ‚à®}.
Exercise 130 Prove Thm. 11.28 and 11.31 along the lines of the proofs of
Thm. 2.10
and 2.16.
Exercise 131 Show that MSO over an alphabet Œ£ = Œ£0 ‚à™ Œ£2 is not
elementarily decidable. Hint: Show how to transform a formula ùúë of MSO
over words into an
‚Ä≤
‚Ä≤

equi-satisfiable MSO tree formula ùúë over this alphabet such that ùúë only has
models in which every non-leaf node has at least one child that is a leaf
node. Such degenerate trees are essentially one path from the root to a node
with two leaf children, and this path can easily encode a w ord.
Exercise 132 Show that ùúÜùë• , ùë• .ùë•
, ùë° , ùë°
1
2
1(ùë•2(ùë•1(ùë•1(ùëé, ùë°1), ùë°2)), ùë°3), for any terms ùë°1
2
3,
is a solution for the equation
ùë• ((ùúÜ ùë¶ , ùë¶ .ùë¶
. ùëì
, ùë¶
1
2
1), (ùúÜ ùë¶3
(ùë¶3
3)))
‚âà

ùëì (ùëé, ùëé)
where ùëé ‚à∂ o, ùëì ‚à∂ o, o ‚Üí o.
Exercise 133
a) Construct an accepting run of the DbuTA from Ex. 11.33 on the term ùúÜùë• ,
ùë• .ùë•
1
2
1(ùë• 2(ùë• 1(ùë• 1(ùëé, #), #)), #).
b) Show that ùúÜùë• , ùë• .ùë•
1
2
2(ùë•1( ùëì (ùëé, ùëé), #)) is not being accepted by this DbuTA.
Exercise 134 Complete the details that are left out in the proof of Thm.
11.34.
Exercise 135 Construct an NTA that recognises exactly the tree
representations like the one given in Fig. 11.10 of those XML documents
that have the type Addrbook as defined in Ex. 11.35. Hint: Rewrite the
XDuce type definition of addrbook first using the additional symbols from
Fig. 11.10 like details etc., so that each type refers to a binary symbol.

Chapter 12
Parity Games
The automata-logic correspondence, starting with automata on finite
words, whose fundamentals are presented in Chp. 2, has been extended in
two directions: Chp. 5
considers infinite words, and Chp. 11 considers finite trees. In all three
cases, Monadic Second-Order Logic has been shown to be equi-expressive
to a natural model of finite automata over the respective word or tree
structures.
A natural question to ask concerns the unification of both extensions: is
there also a similar automata-logic correspondence over infinite trees? The
answer is yes and will be studied in detail in Chp. 13. However, remember
that both extensions - to infinite words and to finite trees - separately
introduced some additional combinatorial difficulty, so a theory of finite
automata over infinite trees can be expected not only to inherit both but
perhaps even introduce further technical obstacles.
These combinatorial difficulties usually arise from the combination of two
necessities: something that objects against easy complementation
constructions like nondeterminism or the branching structure in trees, and
complementation closure as a must in order to handle logical negation in a
translation from formulas to automata.
The central combinatorial result used to obtain complementation closure
for finite automata over infinite trees is positional determinacy of parity
games.
Parity games can be seen as extensions of B √ºchi games as studied in Chp.
9, and determinacy again describes the phenomenon of there always being
one player who has a winning strategy for a given game. Positional
determinacy means that these winning strategies can even be assumed to be
positional, resp. memoryless.

This chapter introduces parity games, proves positional determinacy and
presents an algorithmic solution to the main problem of solving, i.e. to
determine the winner in a given game.
12.1 Games, Plays and Strategies
Parity games are two-player games of infinite duration in which player 0's
winning plays satisfy a given parity condition. Just like reachability games,
parity games
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
315
https://doi.org/10.1007/978-3-662-72154-4_12
316
12 Parity Games
are played on directed graphs whose node set is partitioned into nodes
belonging to players 0 and 1, respectively. The main difference to
reachability games is the fact that, in a reachability game, player 0 wins a
play after a finite amount of time.
Player 1's wins are determined after infinitely many steps only, namely
when the target set has not been reached. But determinacy of reachability
games allows us to compute the winning region for one player only in order
to automatically obtain the winning region for the other player as well. And
the winning region for the player who wins plays after finitely many steps
can easily be characterised and computed using attractors.
The winner of a play in a parity game is not determined after finitely many
steps, and this is true for both players. The nodes in a parity game are
equipped with priorities (from a finite set of natural numbers), and player 0

wins a play if the highest priority seen infinitely often is even. Likewise,
player 1 wins all other plays, and by demanding that plays are always of
infinite duration, these are exactly the plays in which the highest priority
seen infinitely often is odd. Hence, there is no way to determine the winner
of a play by looking at a finite prefix only.
Most of the concepts associated with the formal study of two-player games
on directed graphs can simply be copied verbatim from reachability games
to parity games.
Definition 12.1 A parity game is a G = (ùëâ, ùëâ , ùëâ , ùë£ , ùê∏, Œ©
0
1
ùêº
) where ùëâ is a set of nodes
partitioned into nodes ùëâ0 owned by player 0 and nodes ùëâ1 owned by
player 1, ùë£ùêº ‚àà ùëâ
is a designated starting node, and ùê∏ ‚äÜ ùëâ √ó ùëâ is a left-total and finitely
branching relation determining possible moves in the game. The winning
condition for plays is given as a parity condition Œ© ‚à∂ ùëâ ‚Üí N which is
required to have a finite range, i.e.
‚à£{Œ©(ùë£) ‚à£ ùë£ ‚àà ùë£}‚à£ < ‚àû.
A play is an infinite sequence ùúã = ùë£ , ùë£ , . . .
, ùë£
0
1

such that ùë£0 = ùë£ùêº and (ùë£ùëñ
ùëñ +1) ‚àà ùê∏
for all ùëó ‚â• 0. Such a play ùúã is winning for player 0 if lim sup Œ©(ùë£
ùëñ‚Üí‚àû
ùëñ ) ‚â° 0 mod 2,
i.e. the maximal priority occurring infinitely often in ùúã is even. Player 1
wins the play if this is odd.
‚àó
A strategy for player ùëñ is a function ùúé
ùëâ
ùëñ
‚à∂ ùëâ
ùëñ
‚Üí ùëâ that respects the edge relation,
‚àó
i.e. (ùúãùë¢, ùúãùë¢ùúéùëñ(ùúãùë¢)) ‚àà ùê∏ for all finite plays ùúã ‚àà ùëâ and all nodes ùë¢ ‚àà ùëâùëñ. It is a
winning strategy if player ùëñ is the winner for any play ùúã = ùë£ , ùë£ , . . .
0
1
that conforms to this
strategy in the sense that for all ùëó ‚â• 0 such that ùë£

. . . ùë£
ùëó
‚àà ùëâùëñ we have ùë£ ùëó+1 = ùúéùëñ(ùë£0
ùëó ).
‚Ä≤
‚Ä≤
‚àó
The strategy ùúé
ùë¢
ùëñ is positional if ùúéùëñ (ùúãùë¢) = ùúéùëñ (ùúã
) for all ùúã, ùúã ‚àà ùëâ
and all ùë¢ ‚àà ùëâùëñ,
i.e. the choices that it describes are only dependent on the current position
in a play, not its history. A positional strategy is usually given as a function
ùúéùëñ ‚à∂ ùëâùëñ ‚Üí ùëâ .
We will often be concerned with finite parity games only, especially when
considering the problem of algorithmically solving a game, i.e. determining
the existence of winning strategies for either of the players. Finite parity
games are clearly finitely branching. For infinite parity games, the
requirement of being finitely branching is included just because it simplifies
some technical constructions slightly, in particular that of an attractor
region and strategy which will also play a significant role here.
Nevertheless, all results on parity games developed here also hold for
infinite games with infinite branching degree.

12.2 Basic Properties
317
On the other hand, the requirement of there being only finitely many
priorities in a game is a genuine restriction. Equivalently, it requires some
node in the game to have maximal priority. This is needed for the winner of
a play to be determined, and subsequently for positional determinacy to
hold, as the following example shows.
We also restrict our attention to infinite parity games of at most countable
size. This will avoid the need to reason using the axiom of choice in some
parts.
Example 12.2 Consider the infinite game
. . .
0
1
2
3
4
5
6
with nodes' priorities shown inside the nodes. As usual, we depict nodes
owned by player 0 with diamond shapes (possibly stretched horizontally)
and nodes owned by player 1 as squares (or rectangles).
We refrain from calling this game a parity game because it violates the
property of having a maximal priority. Clearly, there is only one play in this
game, and it would not be won by any of the player because lim sup

ùëñ
ùëñ
does not exist and is
‚Üí‚àû
therefore neither even nor odd.
Moreover, no player can have a winning strategy. While both players
clearly have exactly one strategy, it is not winning since there are no
winning plays for either player. One could argue that both players have a
non-losing strategy which is a concept that becomes relevant in games
which allow draws between the players.
Here we stick to games in which every play has a unique winner, though.
12.2 Basic Properties
12.2.1 Games with no Particular Initial Node
Sometimes it is convenient to take on a more global view onto a parity game
by not fixing a particular starting node and consider parity games of the
form G = (ùëâ , ùëâ , ùëâ , ùê∏ , Œ©
, ùëâ , ùê∏
0
1
) with ùëâ , ùëâ0
1
and Œ© as above. In this case, a play may start

in any node, not just a designated starting node, and a winning strategy is
then one for a player and a particular node ùë£ ‚àà ùëâ , guaranteeing her or
him to win any play that starts in ùë£. This leads to the notion of a winning
region for player ùëù, usually denoted ùëä ùëù , of all nodes ùë£ such that player ùëù
has a winning strategy for the game starting in node ùë£. We will also say that
player ùëù wins node ùë£ if ùë£ ‚àà ùëä ùëù.
Determinacy of a parity game G with node set ùëâ is then simply the property
of ùëä0 ‚à™ ùëä1 = ùëâ . Note that ùëä0 ‚à© ùëä1 = ‚àÖ is trivially always the case
since no node can be won by both players at the same time. Hence,
determinacy can be seen as the ability to partition the node set of a game
into two parts, each of them won by one of the players. Positional
determinacy refers to the property that additionally, each node in the
winning region ùëäùëù is won by player ùëù with a positional strategy.
318
12 Parity Games
3
3
1
0
ùë£
ùë£
ùë£
ùë£
0
1

2
3
4
ùë£4
ùë£
ùë£
ùë£
ùë£
5
6
7
8
4
1
2
3
Fig. 12.1 A parity game with nine nodes and priorities 0, . . . , 4.
Example 12.3 Fig. 12.1 shows a finite parity game with node set ùëâ = {ùë£ , . .
. , ùë£
0

8}.
The priorities are given as labels to the nodes. They are drawn from the
range
{0, . . . , 4} in this case.
One can easily check that positional determinacy is given for this particular
game. The winning regions are ùëä
, ùë£
, ùë£
, ùë£
, ùë£
, ùë£
, ùë£
, ùë£
0 = {ùë£0
1
5
6
7} and ùëä1 = {ùë£2
3
4
8}. A

positional winning strategy for player 0 to win node ùë£0 for example is given
as ùúé
, ùë£
0 ‚à∂ {ùë£1 ‚Ü¶ ùë£5
5 ‚Ü¶ ùë£0}
with arbitrary values on the other nodes ùë£3 and ùë£7 owned by player 0. It is
also a strategy to win nodes ùë£1 and ùë£5. Note that all plays conforming to
this strategy and ùúî
starting in node ùë£
ùë£
0 are of the form (ùë£0(ùë£5 + ùë£1 5))
. Hence, the greatest priority
occurring infinitely often in them is always 4.
A positional strategy for player 0 to win from node ùë£7 is
‚Ä≤
ùúé
‚à∂ {ùë£
, ùë£
, ùë£
0
1 ‚Ü¶ ùë£5

5 ‚Ü¶ ùë£0
7 ‚Ü¶ ùë£6}
with the value on ùë£3 being arbitrary. It induces two kinds of plays that
conform to it: those that eventually loop within {ùë£ , ùë£ , ùë£
0
1
5} as above and are won by player 0
ùúî
because of priority 4, and those of the form (ùë£ ùë£
7 6)
that are won by her because of
‚Ä≤
priority 2. Likewise, ùúé also wins node ùë£
0
6 for player 0.
In this particular example it is easy to see that there is also a positional
winning
‚Ä≤
strategy with which player 0 uniformly wins her entire winning region.
Strategy ùúé0
‚Ä≤

extends ùúé0 in a way that was said to be allowed for ùúé0. So ùúé is not only
winning for 0
nodes ùë£
, ùë£
6 and ùë£7 but also for nodes ùë£0
1 and ùë£5. In fact, it would be more precise to
‚Ä≤
say that ùúé can be extended to a positional winning strategy for all nodes in ùëä
0
0 by
giving it an arbitrary value on ùë£3.
12.2 Basic Properties
319
12.2.2 Uniform Winning Strategies
The previous example raises the question after the possibility to generalise
the observation on uniformity: given a winning region ùëäùëù for player ùëù, i.e.
winning strategies ùúéùë£ for player ùëù to win node ùë£ ‚àà ùëäùëñ, is there also one
strategy ùúé that wins all nodes in ùëäùëù? And is it positional provided that all
ùúéùë£ are positional? The answer is yes to both questions. We will concentrate
on the case of positional strategies only.
The case for general strategies is analogous and only requires a notational
extension in the reasoning below .
The crucial observation for the ability to conjoin strategies into uniform
ones is formalised in the next lemma. Its proof is left as an exercise. To be

able to state it succinctly, we introduce the following notation for nodes ùë£,
ùë¢ of a parity game ùúé
G = (ùëâ , ùëâ , ùëâ , ùê∏ , Œ©
0
1
) and a positional strategy ùúé for some player ùëù. We write ùë£ ‚Üù ùë¢
if ùë¢ occurs in some play starting in ùë£ that conforms to ùúé. It can formally be
defined inductively via
‚Ä¢
ùúé
ùë£ ‚Üù ùë£ for any ùë£, ùúé.
‚Ä¢
ùúé
ùúé
‚Ä≤
‚Ä≤
ùë£ ‚Üù ùë¢ if ùë¢ ‚â† ùë£ and there is a ùë¢ ‚àà ùëâ such that ùë£ ‚Üù ùë¢ and
‚Ä≤
‚Ä≤
- ùë¢ ‚àà ùëâùëù and ùë¢ = ùúé(ùë¢ ), or
‚Ä≤

- ùë¢ ‚àà ùëâ1 ‚àíùëù.
Lemma 12.4 Let ùëù ‚àà {0, 1} , G be a parity game with node set ùëâ , ùë£ ‚àà ùëâ
and ùúé be a
‚Ä≤
positional strategy that guarantees player ùëù to win ùë£ . Then ùúé also wins any
node ùë£
ùúé
‚Ä≤
for player ùëù such that ùë£ ‚Üù ùë£ .
With this we can prove the aforementioned existence of uniform strategies
that win all nodes of a winning region. The trick here is the following.
Suppose we have a set ùëä of nodes that are won by player ùëù in a game G
and positional winning strategies ùúéùë£ for any node ùë£ ‚àà ùëä . Since the node
set of the underlying game G is assumed to be countable, we can enumerate
ùëä as ùë£ , ùë£ , . . .
0
1
Note that ùëä does not necessarily need
to be infinite; the case of a finite ùëä is simply subsumed in the following
reasoning.
We write ùúéùëñ instead of ùúéùë£ .
ùëñ
‚Ä≤

Consider ùúé0. It guarantees player ùëù to win node ùë£0, but also all nodes ùë£ such
ùúé
ùúé
0
‚Ä≤
‚Ä≤
0
‚Ä≤
that ùë£0 ‚Üù ùë£ , according to Lemma 12.4. Let ùëä0 ‚à∂= {ùë£ ‚à£ ùë£0 ‚Üù ùë£ }. If ùëä0 ‚äá
ùëä then we have obviously already found the required strategy. Otherwise
there is a smallest ùúé0
ùëó such that ùë£ ùëó ‚àà ùëä ‚àñ ùëä0, i.e. we do not have ùë£0 ‚Üù ùë£ ùëó . More generally,
there is a smallest ùëó such that ùúé0 does not guarantee winning ùë£ ùëó .
Intuitively, we may try to construct a strategy that guarantees winning ùëä0
‚à™ {ùë£ ùëó }
as follows: when visiting a node in ùëä0, play according to ùúé0; otherwise, in
node ùë£ ùëó , play according to ùúéùëó . This is not a complete description of a
strategy in general, though, because it may be the case that a play starting
in ùë£ ùëó leads to some node ùë¢ ‚àà ùëâùëù ‚àñ (ùëä0 ‚à™ {ùë£ ùëó }), and this strategy does
not prescribe a choice in ùë¢. This seems ùúé ùëó
‚Ä≤
‚Ä≤
to be easily fixed by considering the set ùëä ùëó ‚à∂= {ùë£ ‚à£ ùë£ ùëó ‚Üù ùë£ } instead of just
{ùë£ ùëó }.

This causes another problem, though: we may have ùëä0 ‚à© ùëä ùëó ‚â† ‚àÖ, i.e.
some node
320
12 Parity Games
ùë¢ may be reachable from both ùë£0 and ùë£ ùëó with the corresponding strategies,
and ùúé0(ùë¢) ‚â† ùúéùëó (ùë¢) may be possible. So we may have to determine explicitly
how player ùëù should choose in ùë¢ .
This can be done, though, with another simple observation, namely that no
finite prefix of a play is determines the winner of a play. In other words, a
player can play according to some arbitrary strategy for any finite amount
of time and then start using a winning strategy, and this will still be a
winning strategy provided that the strategy that is used to form a prefix of a
play does not leave the player's winning
‚Ä≤
‚Ä≤
region. This principle can even be iterated: let ùúé , . . . , ùúé
be strategies for player
0
ùëõ‚àí1
‚Ä≤
ùëù, not necessarily winning. Construct a new strategy ùúé that asks player ùëù to
play
‚Ä≤
‚Ä≤

‚Ä≤
according to ùúé for a while, then according to ùúé for a while, etc. until ùúé
is used.
0
1
ùëõ‚àí1
Now suppose this reaches some node ùë¢ from which player ùëù has a winning
strategy
‚Ä≤
‚Ä≤
ùúéùëõ, and there she continues using ùúéùëõ. Then this overall strategy is a winning
strategy
‚Ä≤
for each node in which she could start to use strategy ùúé and so on in this
way.
0
This allows us to construct a strategy with which player ùëù uniformly wins
ùëä0 ‚à™ùëä ùëó : on nodes for which both prescribe a choice, follow strategy ùúé0.
Equally, one could follow strategy ùúéùëó and dismiss the choices prescribed by
ùúé0 instead. However, when merging infinitely many strategies into a single
one, order matters because we need to ensure that the resulting strategy
only ever requires player ùëù to swap the underlying strategy finitely many
times or, equally, to eventually stick to one of these strategies.
Lemma 12.5 Let G be a parity game with node set ùëâ , ùëù ‚àà {0, 1} be a
player and ùëä

‚äÜ ùëâ a set of positions such that there are positional winning strategies ùúéùë£
for player ùëù to win any node ùë£ ‚àà ùëä . Then there is also a positional
strategy ùúé that is winning any node ùë£ ‚àà ùëä for play er ùëù .
Proof Let G = (ùëâ, ùëâ , ùëâ , ùê∏, Œ©
0
1
), ùëù ‚àà {0, 1} and ùëä ‚äÜ ùëâ be given, as well as positional
winning strategies ùúéùë£ for player ùëù to win any node ùë£ ‚àà ùëä . Let ùëä be
enumerated ùúé
‚Ä≤
ùëñ
‚Ä≤
‚Ä≤
‚àû
as ùë£ , ùë£ , . . .
ùëä
0
1
and define ùëäùëñ ‚à∂= {ùë£ ‚à£ ùë£ùëñ ‚Üù ùë£ }, as well as ùëä ‚à∂= ‚ãÉùëñ=0
ùëñ . We have
‚Ä≤

ùëä
‚äá ùëä , so it suffices to define a positional strategy ùúé that uniformly wins all
nodes
‚Ä≤
in ùëä for player ùëù. We define it via ùúé(ùë£) ‚à∂= ùúéùëö(ùë£) where ùëö ‚à∂= min{ùëñ ‚à£ ùë£ ‚àà
ùëäùëñ}.
‚Ä≤
Clearly, this is a positional strategy for all nodes in ùëä . It remains to be
seen that it is winning for player ùëù f or any such node.
Let ùúã = ùë¢ , ùë¢ , ùë¢ , . . .
0
1
2
be a play that conforms to strategy ùúé. By definition of the
sets ùëäùëñ, we have for all ùëñ, ùëó ‚â• 0: if ùë¢ ùëó ‚àà ùëäùëñ then ùë¢ ùëó+1 ‚àà ùëäùëñ. Hence, the
sequence ùëö
, ùëö
, . . .
0
1
with ùëö ùëó ‚à∂= min{ùëñ ‚à£ ùë¢ ùëó ‚àà ùëäùëñ} is monotonically decreasing. Since ùëö0 ‚àà N,
the set {ùëö , ùëö , . . .

0
1
} is finite which means that there is an ùëõ ‚â• 0 such that ùëö ùëó =
ùëö
, ùë¢
, . . .
ùëõ
for all ùëó ‚â• ùëõ. In other words, the play ùë¢ùëõ
ùëõ+1
conforms to strategy ùúéùëõ
and is therefore winning for player ùëù, i.e. lim sup
Œ©(ùë¢
ùëñ‚Üí‚àû
OceanofPDF.com

ùëõ+ùëñ ) ‚â° ùëù mod 2. Since
the limes superior of a sequence is invariant under adding prefixes we have
that lim sup
Œ©(ùë¢
ùëñ‚Üí‚àû
ùëñ )
‚â° ùëù mod 2 as well which shows that ùúã is indeed winning for
player ùëù, and ùúé is therefore a winning strategy for player ùëù.
‚óª
Example 12.6 Consider the infinite parity game shown in Fig. 12.2. It is
easy to see that the positional strategy ùúéùëñ defined via
12.2 Basic Properties
321
1
1
1
1
1
1
ùë£

ùë£
ùë£
ùë£
ùë£
ùë£
. . .
0
1
2
3
4
5
ùë¢
0
Fig. 12.2 An infinite parity game showing that winning strategies need to
be merged in a well-founded way to obtain a uniform winning strategy.
‚éß
‚é™
‚é™ùë¢
, if ùëó = ùëñ

ùúéùëñ (ùë£ ùëó )
‚à∂= ‚é®
‚é™
‚é™ùë£
,
ùëó +
otherwise
‚é©
1
is winning all nodes ùë£ ùëó for player ùëù such that ùëó ‚â§ ùëñ, by successively moving
right towards ùë£ùëñ and then down to ùë¢ where the play ultimately loops and
priority 0 makes player 0 the winner .
So the winning region for player 0 is the entire node set. A uniform strategy
for player 0 to win all nodes is obtained by means of the construction in
Lemma 12.5
for instance by taking the natural order ùë£ , ùë£ , . . .
0
1
as an enumeration for the relevant
part of the node set. The strategy obtained from this order is ùúé defined by ùúé(ùë£
ùëó ) = ùë¢
for any ùëó ‚àà N, i.e. it makes player 0 move directly down to node ùë¢.

The need for a well-founded order on the winning strategies is shown by
considering a non-well-founded way to merge them, i.e. to make player
change strategies
‚Ä≤
‚Ä≤
infinitely often. Let ùúé be defined by ùúé (ùë£ ùëó ) ‚à∂= ùúéùëó+1(ùë£ ùëó ). Hence, when
playing
‚Ä≤
according to ùúé and starting in ùë£0, player 0 first moves to ùë£1 since ùúé1 requires
her to do so. There she swaps over to strategy ùúé2 which takes her to ùë£2, and
so on. This is clearly not a winning strategy for her because it results in the
play ùë£ , ùë£ , ùë£ , . . .
0
1
2
that
is won by player 1.
12.2.3 Priority Compression
We state the rather obvious observation that priorities in a parity game can
uniformly be shifted by an even amount without changing the winning
regions and associated strategies. The same principle has also been
observed to apply to NPA, yielding a language-preserving transformation
there, cf. Lemma 6.9. The construction is even sound if priorities are not
shifted uniformly but in a way that preserves their parities and their order.
The proof is left as an exercise.
Lemma 12.7 Let G = (ùëâ, ùëâ , ùëâ , ùê∏, Œ©

0
1
) be a parity game and Œ©‚Ä≤ ‚à∂ ùëâ ‚Üí N such that
‚Ä¢ (
Œ© ùë£) ‚â§
(
Œ© ùë¢) iff Œ©‚Ä≤ (ùë£) ‚â§ Œ©‚Ä≤ (ùë¢) for all ùë£, ùë¢ ‚àà ùëâ ,
‚Ä¢ Œ©(ùë£) ‚â° Œ©‚Ä≤(ùë£) mod 2 for all ùë£ ‚àà ùëâ .
322
12 Parity Games
‚Ä≤
Let G ‚à∂= (ùëâ , ùëâ , ùëâ , ùê∏ , Œ©‚Ä≤
0
1
) . Then any winning strategy ùúé for player ùëù in G is also a
‚Ä≤
winning strategy for player ùëù and the same nodes in G and vice-versa.
Consequently, such transformations on the priorities do not change the
winning regions in a parity game.
12.3 Winning Parity Games

Again, positional determinacy of parity games means that any node of any
parity game is won by exactly one of the players. While it is easy to see that
every node is won by at most one of the players 0 and 1 - assuming both
have a winning strategy, there is a unique play that conforms to both these
strategies and the highest priority occurring infinitely often in this play
would therefore have to be both even and odd at the same time - the tricky
part is to show that every node is won by at least one of the players. Why
should player 1‚àíùëù have a winning strategy for the game starting in some
node ùë£, simply because player ùëù does not?
12.3.1 Subgames
In order to prove the result formally we need the construction of a subgame.
Definition 12.8 Let G = (ùëâ, ùëâ , ùëâ , ùê∏, Œ©
0
1
) be a parity game and ùëà ‚äÜ ùëâ . We abbreviate
ùëâ ‚àñ ùëà as ùëà. The subgame of G resulting from the removal of ùëà is G ‚àñ ùëà
‚à∂= (ùëâ ‚àñ
ùëà , ùëâ0 ‚à© ùëà, ùëâ1 ‚à© ùëà, ùê∏ ‚à© (ùëà √ó ùëà), Œ©‚à£ ) with Œ©‚à£ (ùë£) = Œ©(ùë£) for all ùë£ ‚àà
ùëà.
ùëà
ùëà
Note that G ‚àñ ùëà is in general not a parity game, and calling it a subgame is
at least questionable. The removal of nodes from ùëà can leave nodes in G ‚àñ
ùëà that do not have successors. Take for instance the parity game G in Fig.
12.2. Then G ‚àñ {ùë¢}
is a parity game and so is G ‚àñ {ùë£

, ùë¢
ùëñ
‚à£ ùëñ is odd }. However, G ‚àñ {ùë£1
} is not a parity
game anymore since it leaves node ùë£0 with no successor.
The reason why we still speak of a subgame G ‚àñ ùëà is that we will only use
this construction for particular sets ùëà which satisfy a condition that is
sufficient for G ‚àñùëà
to be a parity game. For this we recall the definition of an attractor (cf.
Sect. 3.4.2) -
i.e. the set of all nodes from which a player can enforce a visit to a
particular region in the underlying graph. More specifically, the attractor of
a set of nodes ùëà for player ùëù is
ùëñ
Attr (ùëà) ‚à∂=
(ùëà )
ùëù
‚ãÉ Attr ùëù
ùëñ‚ààN
0
where Attr (ùëà) ‚à∂= ùëà
ùëù

and
ùëñ+1
ùëñ
ùëñ
Attr
(ùëà )
‚à∂=
(ùëà ) ‚à™ {ùë£ ‚àà ùëâ
(ùëà ) ‚â† ‚àÖ}
ùëù
Attr ùëù
ùëù ‚à£ ùë£ ùê∏ ‚à© Attr ùëù
ùëñ
‚à™ {ùë£ ‚àà ùëâ1‚àíùëù ‚à£ ùë£ùê∏ ‚äÜ Attr (ùëà)} .
ùëù
12.3 Winning Parity Games
323
An attractor strategy for player ùëù is a positional strategy to win the
reachability ùëñ
game with such a target ùëà: on a node ùë£ ‚àà Attr (ùëà)

ùëù
for ùëñ > 0 move to a successor ùë¢
ùëó
such that ùë¢ ‚àà Attr (ùëà)
ùëù
for some ùëó < ùëñ.
Lemma 12.9 Let G = (ùëâ, ùëâ , ùëâ , ùê∏, Œ©
0
1
) be a parity game, ùëà ‚äÜ ùëâ , and ùëù ‚àà {0, 1} .
Then G ‚àñ Attr (ùëà)
ùëù
is a parity g ame.
Proof All that remains to be seen is that the edge relation in G ‚àñ Attr (ùëà) ùëù
is left-
total. So take a node ùë£ ‚àà ùëâ ‚àñ Attr (ùëà)
ùëù
and assume, for the sake of contradiction, that
ùë£ ùê∏ ‚äÜ Attr (ùëà)
(ùëà )

ùëù
. But then ùë£ ‚àà Attr ùëù
by the definition of an attractor as well, so
ùë£ /
‚àà ùëâ ‚àñ Attr (ùëà)
ùëù
.
‚óª
Henceforth, when we speak of a subgame G ‚àñ ùëà for some node set ùëà we
assume that it is indeed a parity game, for instance because ùëà is attractor-
closed. We need two technical observations regarding subgames and
attractor-closures.
Lemma 12.10 Let G be a parity game with node set ùëâ , ùëù ‚àà {0, 1} , ùëà ‚äÜ ùëâ
such that Attr (ùëà) ‚äÜ ùëà
ùëù
and G ‚àñ ùëà the subgame induced by ùëà . Suppose ùúé is a strategy for player ùëù
‚à∂= 1 ‚àí ùëù with which she wins some node ùë£ in G ‚àñ ùëà . Then she also wins ùë£
with ùúé in G .
Proof This is a simple consequence of the fact that any play in G that
conforms to ùúé and starts in node ùë£ is a play within G ‚àñ ùëà. Note that, by
following ùúé, player ùëù
will never make a move out of ùëâ ‚àñ ùëà for otherwise ùúé would not be a
strategy for her in G ‚àñ ùëà. On the other hand, since Attr (ùëà) ‚äÜ ùëà

ùëù
by assumption, and therefore
Attr (ùëà) = ùëà
ùëù
in fact, player ùëù cannot make a move in G from some node in ùë£ ‚àà ùëâùëù ‚àñùëà
to some some in ùëà for otherwise we would have ùë£ ‚àà Attr (ùëà) ‚äÜ ùëà
ùëù
contradicting the
assumption that ùë£ /
‚àà ùëà .
‚óª
Lemma 12.11 Let G be a parity game, ùëù ‚àà {0, 1} and ùëäùëù be the set of all
nodes for which player ùëù has a (positional) winning strategy. Then Attr (ùëä
ùëù
ùëù ) ‚äÜ ùëä ùëù .
Proof Suppose there was some node ùë£ ‚àà Attr (ùëä
ùëù
ùëù ) ‚àñ ùëä ùëù . It is possible to construct
a winning strategy for player ùëù and node ùë£ as follows: play according to
the attractor strategy for as long as a play visits nodes in Attr (ùëä
ùëù

ùëù ) ‚àñ ùëä ùëù ; once it reaches
ùëä ùëù , continue playing according to the winning strategy that exists by
assumption.
If the latter is positional then so is this combined strategy. Also, since
following the attractor strategy guarantees a visit to ùëäùëù eventually, the
winning of any play conforming to this combined strategy is solely
determined by the greatest priority occurring infinitely often after a visit to
ùëäùëù, i.e. the play is winning for player ùëù. ‚óª
12.3.2 Positional Determinacy
With the considerations above we can finally prove positional determinacy.
324
12 Parity Games
Theorem 12.12 Let G be a parity game with node set ùëâ and ùëä , ùëä
0
1 be the set of
nodes that are won by either of the players respectively. Then we have ùëä0
‚à™ ùëä1 = ùëâ .
Moreover, for both ùëù ‚àà {0, 1} there is a positional winning strategy ùúéùëù with
which player ùëù wins all the nodes in ùëäùëù .
Proof Let G = (ùëâ, ùëâ , ùëâ , ùê∏, Œ©
0
1
) and ùëò ‚à∂= max{Œ©(ùë£) ‚à£ ùë£ ‚àà ùëâ }. Remember that ùëò is

assumed to exist. We prove the claim by induction on ùëò . The base case is
given by ùëò = 0, i.e. all nodes have priority 0. It should be clear that in this
case ùëä0 = ùëâ and ùëä1 = ‚àÖ, and therefore ùëä0 ‚à™ ùëä1 = ùëâ . Moreover, any
positional strategy for player 0 is a winning strategy since any play only
ever sees priority 0. At last, it should be clear that positional strategies
always exist since the graphs underlying parity games are assumed to be
left-total, i.e. every node has a successor, and every function assigning
arbitrary successors to nodes is a positional strategy.
Now let ùëò > 0. W.l.o.g. we assume ùëò to be even. The case of an odd ùëò is
entirely symmetric with only the roles of players 0 and 1 swapped. Let ùëä0
be the set of nodes which are won by player 0 with some positional strategy.
According to Lemma 12.5, player 0 also has a positional strategy ùúé0 with
which she uniformly wins all nodes in ùëä0 .
It remains to be seen that player 1 has a positional strategy with which he
wins all nodes in ùëâ ‚àñ ùëä0. Using Lemma 12.5 it suffices to show that he has
positional winning strategies for any node ùë£ ‚àà ùëâ ‚àñ ùëä0 .
‚Ä≤
According to Lemma 12.9 and 12.11 we have Attr (ùëä
‚à∂= G ‚àñùëä
0
0) ‚äÜ ùëä0 and that G
0
is indeed a parity game. Its node set is obviously ùëâ ‚àñ ùëä0. We now
distinguish two
‚Ä≤
cases depending on whether or not the highest priority ùëò from G occurs in
G .

(i) Suppose first that ùëò does not occur in ùëâ ‚àñ ùëä0. Then the induction
hypothesis
‚Ä≤
‚Ä≤
yields a partition of the node set of the game G ‚àñ ùëä0 into winning regions
ùëä and ùëä
0
1
‚Ä≤
‚Ä≤
together with positional winning strategies ùúé , ùúé such that player ùëù wins
every node 0
1
‚Ä≤
‚Ä≤
in ùëäùëù with strategy ùúéùëù. According to Lemma 12.10, player 1 wins all the
nodes in
‚Ä≤
‚Ä≤
‚Ä≤
ùëä

with his strategy ùúé in G as well. We now claim that ùëä = ‚àÖ which then yields
1
1
0
‚Ä≤
ùëä
= ùëâ ‚àñ ùëä
1
0 showing that player 1 has a positional winning strategy for all the nodes
which are not won by player 0 with a positional strategy .
‚Ä≤
‚Ä≤
So suppose there was some ùë£ ‚àà ùëä , i.e. player 0 wins ùë£ with strategy ùúé in G
‚àñùëä
0
0
0.
Then consider the following combined strategy for player 0 and the game G
starting
‚Ä≤
in ùë£: on nodes in ùëâ ‚àñ ùëä0 play according to strategy ùúé , and on nodes in ùëä
0

0 play
according to strategy ùúé0. This is indeed a winning strategy for her because
there are only two kinds of plays that conform to this strategy: those that
stay entirely within ùëâ ‚àñ ùëä0, and those that eventually move into ùëä0 and
remain there forever because player 1 cannot leave ùëä0, and player 0 does
not leave ùëä0 by following a winning strategy. So the greatest priority
occurring infinitely often in any of these plays must be even as well, and
this combined strategy is a winning strategy for player 0 in G, showing that
indeed ùë£ ‚àà ùëä0 in the first place and therefore ùë£ /‚àà ùëâ ‚àñ ùëä0.
(ii) In the second case we have that priority ùëò occurs somewhere in ùëâ ‚àñ
ùëä0. Let ùêæ ‚à∂= {ùë£ ‚àà ùëâ ‚àñ ùëä0 ‚à£ Œ©(ùë£) = ùëò}. We consider ùê¥ ‚à∂= Attr (ùêæ)
0
, i.e. the set of all positions
‚Ä≤
in G from which player 0 can enforce a visit to ùêæ. According to Lemma
12.9,
‚Ä≤‚Ä≤
‚Ä≤
G
‚à∂= G ‚àñ ùê¥ = (G ‚àñ ùëä0) ‚àñ ùê¥ is a parity game. Clearly, the highest priority
occurring in it is strictly less than ùëò , so the induction hypothesis yields a
partitioning of
12.3 Winning Parity Games
325
G

‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
ùëä
ùëä
ùëä
= ‚àÖ
0
1
0
G‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
ùúé1
ùúé0
ùê¥
‚Ä≤
ùúé1
ùêæ
G‚Ä≤
Fig. 12.3 The situation in part (ii) of the proof of Thm. 12.12.
‚Ä≤‚Ä≤

‚Ä≤‚Ä≤
ùëâ ‚àñ (ùëä0 ‚à™ ùê¥) into winning regions ùëä
and ùëä , together with positional strategies
0
1
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
ùúé
, ùúé
for the two players to win the nodes in ùëä
and ùëä
respectively.
0
1
0
1
The situation is shown in Fig. 12.3. The right side consists of ùëä0 - the set
of nodes for which player 0 has a positional winning strategy. The left side
is then the

‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
subgame G = G ‚àñ ùëä0, and the upper part of this is its subgame G
= G
‚àñ ùê¥. It is
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
partitioned into ùëä
and ùëä . We need to argue for each of the regions ùëä , ùëä , ùê¥ ‚àñ ùêæ
0
1
0
1
and ùêæ that either player 1 has a positional winning strategy in G for the
nodes in these regions or the regions are in fact empty (because player 0
has a positional winning strategy for any node assumed to be in it, in which
case it is in fact already included in ùëä0).
‚Ä≤‚Ä≤

The easiest part is ùëä . Note that it is the winning region of player 1, i.e.
player 1
0's opponent, in a subgame induced by the attractor for player 0. Hence,
according
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
to Lemma 12.10, player 1 wins all nodes in ùëä
not only in G
but also in G.
1
Next consider ùê¥ ‚àñ ùêæ. By the definition of an attractor, all edges from nodes
in ùëâ1 ‚à©(ùê¥ ‚àñ ùêæ) do not lead to nodes outside of ùê¥ ‚àñ ùêæ. In the supergame G,
there could be additional edges into ùëä0, though. Such edges are not
beneficial to player 1 because player 0 wins any play taking such an edge
with her strategy ùúé0. Since player 1 not only cannot escape region ùê¥ but
also cannot prevent a play from ultimately reaching ùêæ , it suffices to
consider region ùêæ, and the same findings apply to region ùê¥ ‚àñ ùêæ as well.
ùëó
First we observe that there can be no node ùë£ ‚àà ùêæ such that ùë£ ‚àà Attr ({ùë£})
for 0
some ùëó > 0. In other words, there is no node in ùêæ that player 0 can
repeatedly enforce to visit. If this was the case, then this node would belong
to ùëä0 because any play within ùê¥ that visits some node in ùêæ infinitely often
is winning for player 0. This gives a positional strategy for player 1 on ùê¥:
let ùë£ , ùë£ , . . .
1

2
be an enumeration of the
nodes in ùêæ such that for all ùëñ, ùëó with 1 ‚â§ ùëñ < ùëó : if ùë£ùëñ /
‚àà Attr ({ùë£
0
ùëó }). Then on any node
ùë£ ‚àà ùê¥ ‚à© ùëâ1, player 1 moves to the successor ùë¢ ‚àà ùë£ùê∏ that belongs to Attr
({ùë£
0
ùëó }) for
the least ùëó if it exists. Note that it may not exist because edges from nodes in
ùêæ do
326
12 Parity Games
not necessarily have to lead into ùê¥. However, they cannot lead into ùëä0
because then
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
such nodes would belong to ùëä0. Hence, they must lead into ùëä
or ùëä .
0

1
‚Ä≤
This defines a positional strategy ùúé for player 1 on ùê¥ = (ùê¥ ‚àñ ùêæ) ‚à™ ùêæ which
leaves 1
‚Ä≤‚Ä≤
the region ùëä
to be considered: in a node ùë£ ‚àà ùëâ
0
1, move to the successor that belongs
‚Ä≤‚Ä≤
‚Ä≤
to Attr ({ùë£
0
ùëó }) for the smallest ùëó if it exists. Otherwise move into G
. Note that ùúé1
is not necessarily a winning strategy; it is only winning if it eventually leads
into
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
ùëä

and not ùëä . We complete the two cases by arguing that ùëä
= ‚àÖ. We cannot use
1
0
0
‚Ä≤‚Ä≤
Lemma 12.10 to reason here because G
is obtained as a subgame of G induced by
removing regions ùëä0 and ùê¥ that are attractor-closed for player 0, not
necessarily for her opponent.
‚Ä≤‚Ä≤
So suppose that ùëä
‚â† ‚àÖ, i.e. there is some node in ùëâ ‚àñ (ùëä
0
0 ‚à™ ùê¥) that is won by
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
player 0 with a winning strategy ùúé
in G . Consider the effect of using ùúé

in G.
0
0
‚Ä≤‚Ä≤
Upon visiting a node in ùëâ0, player 0 makes her choices according to ùúé
and stays
0
‚Ä≤‚Ä≤
within ùëä . However, when visiting a node ùë£ ‚àà ùëâ
0
1, player 1 could now make use of
‚Ä≤‚Ä≤
edges that are additionally available to him by leading out of ùëä . They
cannot lead 0
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
into ùëä , though, for otherwise ùë£ would belong to ùëä
already. Likewise, they cannot
1
1

lead into ùê¥ because - using the argument above - the play would ultimately
end up
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
in ùëä , so ùë£ would also belong to ùëä
then. At last, player 1 would not make use of
1
1
additional edges that lead into ùëä0 since player 0 wins there. So any play
starting in
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
a node ùë£ ‚àà ùëä
and conforming to ùúé
that is winning for player 0 in G will either
0
0
‚Ä≤‚Ä≤
eventually lead into ùëä0 or stay within ùëä
forever. But then ùë£ is won by player 0 in G
0

‚Ä≤‚Ä≤
and therefore we already have ùë£ ‚àà ùëä0 which contradicts the assumption
that ùëä
‚â† ‚àÖ.
0
Thus, we get that ùëâ ‚àñ ùëä0 = ùëä1 where ùëä1 is the set of nodes that are won
by player 1 in G, and a positional strategy for player 1 is obtained as the
combination of
‚Ä≤
‚Ä≤‚Ä≤
the two positional strategies ùúé and ùúé
with every play conforming to ùúé
1
1
1 eventually
‚Ä≤‚Ä≤
conforming to ùúé
and therefore being winning for player 1.
‚óª
1
The proof of Thm. 12.12 shows that (positional) winning strategies in parity
games can be obtained by consecutively merging attractor strategies. We

remark that the proof in its form above needs to be slightly extended for
infinite games in which nodes may have infinitely many successors. For
games played on finitely-branching graphs, the definition of an attractor
via an iteration over all natural numbers suffices.
For infinitely-branching graphs, it needs to be extended to an iteration
indexed by ordinal numbers.
Example 12.13 Reconsider the parity game shown in Fig. 12.1. It is easy to
check that player 1 has a positional strategy to win the nodes in ùëä
, ùë£
, ùë£
, ùë£
1 = {ùë£2
3
4
8}.
To show that his opponent, i.e. player 0, has a positional winning strategy
for the remaining nodes {ùë£ , ùë£ , ùë£ , ùë£ , ùë£
0
1
5
6
7}, we first determine the highest priority in this

region which needs to be good for her. Otherwise we would have had to
start with the other player's winning region.
Here the highest priority is 4, and the set of nodes with the priority is {ùë£5}.
Its attractor for player 0 is {ùë£ , ùë£ , ùë£
5
0
1}. The subgame obtained by removing this
attractor only contains nodes {ùë£ , ùë£
6
7}. The induction hypothesis divides this node
set into winning regions for players 0 and 1. In fact, both nodes are won by
player 0
12.4 Solving Parity Games
327
ùúî
ùúî
because there are only two plays in this subgame: (ùë£ ùë£
ùë£
5 6)
and (ùë£6 5) . Both are
clearly won by player 0.

By composing this with the attractor strategy for player 0 to reach {ùë£5} we
obtain the following positional winning strategy for her on {ùë£ , ùë£ , ùë£ , ùë£ , ùë£
0
1
5
6
7}.
‚Ä¢ The attractor strategy demands her to move from ùë£ 1 to ùë£ 5.
‚Ä¢ The induction hypothesis yields the move from ùë£ 7 to ùë£ 6.
‚Ä¢ The move back from a node with highest priority into its own attractor is
realised by going from ùë£5 to ùë£0.
12.4 Solving Parity Games
The proof of Thm. 12.12 is not constructive, not even for finite parity
games, since it assumes the winning region for one player to be given
already. Thus, it does not immediately yield an algorithm for solving parity
games, i.e. for the following problem.
given: a finite parity game G
compute: the sets ùëä , ùëä
0
1 of winning regions together with winning
strategies for each of the players
We restrict our attention to finite parity games in order to safely keep the
problem computable. We will not strictly distinguish this problem from the

associated decision problem which asks, given a parity game G and a node
ùë£, whether ùë£ belongs to ùëä0 or ùëä1. Likewise one could turn the
computation of a winning strategy into a decision problem by asking, given
a finite path ùë£ , . . . , ùë£
ùê∏
1
ùëõ
through G and some ùë¢ ‚àà ùë£ùëõ ,
whether a winning strategy for player ùëù exists to win node ùë£
, . . . , ùë£
1 that maps ùë£1
ùëõ
to ùë¢ .
12.4.1 Theoretical Complexity
With Thm. 12.12 we can of course restrict our attention to positional
strategies only.
This yields the first result on the complexity of solving parity games.
Theorem 12.14 The problem of solving a parity game belongs to NP ‚à© co-
NP.
Proof Inclusion in NP is shown using the usual guess-and-verify technique:
given G = (ùëâ , ùëâ , ùëâ , ùê∏ , Œ©
, ùúé
0

1
), guess positional strategies ùúé0
1 for both of the players. Note
that these are objects of the form ùëâ ‚Üí ùëâ , i.e. we only need to guess one
successor node for each node in the game. This can obviously be done in
time O(‚à£ùê∏ ‚à£).
In order to verify that each ùúéùëù is a winning strategy for player ùëù we construct
the subgame
G ùëù
‚à∂= G ‚àñ (ùëâ ‚àñ (‚ãÉ{ùë£ ùê∏ ‚à£ ùë£ ‚àà ùëâ1‚àíùëù} ‚à™ {ùúéùëù(ùë£) ‚à£ ùë£ ‚àà ùëâùëù})) .
328
12 Parity Games
It is obtained by removing all successors of a ùëù-node that player ùëù does not
ever move to when conforming to strategy ùúéùëù. The graph underlying Gùëù
then contains exactly those plays that conform to ùúéùëù. Thus, in order to
verify that ùúéùëù is a winning strategy, it suffices to check that the highest
priority on every simple loop in Gùëù is good for player ùëù. This can be done
as follows for example. Say we need to verify that there is no simple cycle
on which the highest priority is odd, i.e. we consider G0. We iterate through
all odd priorities ùëü occurring in G0, remove all nodes with priorities
greater than ùëü and compute an SCC decomposition of the remaining graph.
If it contains a non-trivial SCC, i.e. one with at least one edge, and a node
of priority ùëü , then such a cycle is found. The entire verification can
therefore be done in time O(ùëò ‚ãÖ ‚à£ùê∏ ‚à£) where ùëò is the index of G, i.e. the
number of different priorities used in it.
Inclusion in co-NP is then a simple consequence of the symmetric nature of
positional determinacy for parity games: in order to decide that ùë£ does not

belong to ùëä ùëù it suffices to decide that it belongs to ùëä1‚àíùëù which can be
done in the same way as above.
‚óª
12.4.2 A Recursive Algorithm
A deterministic algorithm can be based on the principles used in the proof
of positional determinacy. Of course, an algorithm cannot simply assume
that the winning region ùëä0 (and winning strategy ùúé0) for player 0 is
already given and then only construct a winning strategy on ùëä1. However,
the principle of induction over the number of priorities can be used equally
to compute the division into ùëä0 and ùëä1. It works as follows.
Let G = (ùëâ , ùëâ , ùëâ , ùê∏ , Œ©
0
1
) be a finite parity game and ùêæ be the set of nodes whose
priority is maximal. W.l.o.g. we assume this priority to be even; otherwise
the players need to be swapped in the following reasoning.
First we compute the attractor ùê¥0 ‚à∂= Attr (ùêæ)
0
, i.e. the set of positions from
which player 0 can enforce a single visit of a node with highest (and even)
priority.
According to Lemma 12.9, G ‚àñ ùê¥0 is a parity game. Clearly the number of
priorities in G ‚àñ ùê¥0 is strictly smaller than that in G since ùêæ ‚äÜ ùê¥ 0.
‚Ä≤

‚Ä≤
So we can recursively solve the subgame G‚àñ ùê¥
, ùëä
0 and obtain winning regions ùëä0
1
‚Ä≤
‚Ä≤
with associated positional winning strategies ùúé , ùúé . According to Lemma
12.10, 0
1
‚Ä≤
ùúé
is not only a winning strategy for player 1 in the subgame G ‚àñ ùê¥
1
0 but also in the
‚Ä≤
supergame G. Thus, ùëä is at least part of the winning region ùëä
1
1 for player 1 in G .
‚Ä≤

If ùëä = ‚àÖ then player 0's winning region in G is the entire node set because
every 1
play in G must either eventually be trapped in G ‚àñ ùê¥0 (and therefore won
by player 0), or visit ùêæ infinitely often which also makes her the winner
because nodes in ùêæ
have highest and even priority.
‚Ä≤
However, if ùëä ‚â† ‚àÖ then the winning region for player 1 in G could
encompass 1
‚Ä≤
more than just ùëä . For instance, there may be nodes in player 0's attractor
ùê¥
1
0 for ùêæ
from which on player 0 is of course able to enforce one visit to ùêæ, but
perhaps not
‚Ä≤
repeatedly, i.e. in the long run player 1 may be able to enforce a visit to ùëä .
1
12.4 Solving Parity Games
329
1
0

3
3
ùë£
ùë£
ùë£
ùë£
2
3
0
1
ùë£
ùë£
ùë£
ùë£
8
5
6
7
3
4

1
2
Fig. 12.4 Subgames to be considered when solving the parity game in Fig.
12.1.
‚Ä≤
We therefore then compute ùê¥1 ‚à∂= Attr (ùëä )
1
. It should be clear that player 1 does
1
‚Ä≤
‚Ä≤
not only win G on ùëä but in fact on ùê¥
. The subgame G ‚àñ ùê¥
1
1 which includes ùëä1
1 may
contain nodes that are won by either player 0 or player 1 in G: for instance,
player 0
may win a node by repeatedly enforcing a visit to ùêæ from there. On the
other hand, player 1 may win a node because he can enforce a play that
visits ùêæ only finitely often but a lower odd priority infinitely often that then
determines the winner. Such a

‚Ä≤
node is not necessarily included in ùëä because of some potential
preliminary visits 1
to ùêæ .
Now remember that the division of G ‚àñ ùê¥1 into nodes won by each of the
players is
‚Ä≤
only necessary when ùëä ‚â† ‚àÖ and therefore ùê¥
1
1 ‚â† ‚àÖ. Hence, G ‚àñ ùê¥1 is strictly smaller
than G.
This gives us an algorithm for solving finite parity games which handles the
solving of subgames by recursion. It is well-founded because the game
passed to the recursive calls is strictly smaller than the original one. In the
first case, even the number of priorities is strictly smaller. So all that
remains is to explain how to solve the base cases which are games with only
a single priority or only a single node.
Clearly, games with a single node can only have one priority, so the former
case suffices in fact as a base case.
Solving games with a single priority is of course trivial since that priority's
parity determines the winner for all nodes in the game, and any strategy is
a winning strategy. In particular, positional winning strategies always exist.
Example 12.15 Reconsider the game G shown in Fig. 12.1. The set of nodes
with highest priority is {ùë£ , ùë£
4

5}, and their priority is 4. Hence, we need to calculate its
0-attractor ùê¥
, ùë£
, ùë£
, ùë£
, ùë£
, ùë£
, ùë£
0 ‚à∂= Attr ({ùë£
0
4
5}) = {ùë£0
1
4
5
6
7}. The subgame G ‚àñ ùê¥0 is
shown in Fig. 12.4 on the left. It contains three nodes with priorities 0, 1, 3.
At this point we can employ Lemma 12.7 and squeeze the number of
priorities by changing node ùë£8's priority from 3 to 1. Since this preserves
all parities and the order amongst all nodes' priorities, winning regions and
strategies are also preserved in this s tep.

Normally, we would continue recursively but it is not hard to see what the
solution to the subgame with these three nodes needs to be. So we partition
them directly into winning regions for players 0 and 1. Player 1 can win all
three nodes with any of
330
12 Parity Games
Algorithm 2 A recursive algorithm for solving finite parity games.
1: procedure SolveGame(G = (ùëâ , ùëâ , ùëâ , ùê∏ , Œ©)
0
1
)
2:
ùëò ‚Üê max{Œ©(ùë£) ‚à£ ùë£ ‚àà ùëâ }
3:
if ùëò is even then ùëù ‚Üê 0 else ùëù ‚Üê 1
4:
ùêæ ‚Üê {ùë£ ‚àà ùëâ ‚à£ Œ©(ùë£) = ùëò}
5:
if ùêæ = ùëâ then
‚ñ∑ only one priority left in the game
6:

ùëä
‚Üê ùëâ
‚Üê ‚àÖ
ùëù
; ùëä1‚àíùëù
7:
let ùúéùëù be an arbitrary positional strategy on ùëâ , ùúé1‚àíùëù be undefined
everywhere 8:
else
9:
ùê¥
‚Üê
(ùêæ)
ùëù
Attr ùëù
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
10:

(ùëä , ùëä , ùúé , ùúé ) ‚Üê SolveGame(G ‚àñ ùê¥ )
ùëù
0
1
0
1
‚Ä≤
11:
if ùëä
= ‚àÖ then
1‚àí ùëù
12:
ùëä
‚Üê ùëâ
‚Üê ‚àÖ
ùëù
; ùëä1‚àíùëù ‚Ä≤
13:
let ùúé
(ùë£)

ùëù
extend ùúéùëù
by an attractor strategy on ùê¥ùëù and arbitrary choices on ùêæ
14:
let ùúé1‚àíùëù be undefined everywhere
15:
else
‚Ä≤
16:
ùê¥
‚Üê
(ùëä
)
1‚àí ùëù
Attr 1‚àíùëù
1‚àí ùëù
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤

17:
(ùëä , ùëä , ùúé , ùúé ) ‚Üê SolveGame(G ‚àñ ùê¥
)
0
1
0
1
1‚àí ùëù
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
18:
ùëä
‚Üê ùëä
‚Üê ùëä
‚à™ ùê¥
ùëù
ùëù ; ùëä1‚àí ùëù
1‚àí ùëù
1‚àí ùëù
‚Ä≤‚Ä≤

19:
ùúé
‚Üê ùúé
ùëù
ùëù
‚Ä≤
‚Ä≤‚Ä≤
20:
let ùúé
‚à™ ùúé
1‚àí ùëù extend ùúé
by an attractor strategy on ùê¥
1‚àí ùëù
1‚àí ùëù
1‚àí ùëù
21:
return (ùëä , ùëä , ùúé , ùúé )
0
1
0

1
‚Ä≤
his two positional strategies, for example ùúé = {ùë£
, ùë£
1
2 ‚Ü¶ ùë£3
8 ‚Ü¶ ùë£2}. Thus, we have
‚Ä≤
‚Ä≤
ùëä
= {ùë£ , ùë£ , ùë£
= ‚àÖ.
1
2
3
8} and ùëä0
‚Ä≤
We now need to consider player 1's attractor for ùëä
in G which is ùê¥
1

1
‚à∂=
‚Ä≤
Attr (ùëä ) = {ùë£ , ùë£ , ùë£ , ùë£
1
1
2
3
4
8} as well as the subgame G ‚àñ ùê¥1. It is shown in Fig. 12.4
on the right.
We would now have to solve this recursively by considering the set of nodes
with highest priority, which is {ùë£
, ùë£
, ùë£
, ùë£
, ùë£
5}, and its 0-attractor {ùë£0
1
5

6
7} since the
priority of node {ùë£5} is even again. The removal of this region results in the
empty game. In other words, player 0 has a positional winning strategy on
all nodes of this subgame simply by playing the attractor strategy and
extending this with an arbitrary choice for a move in the target ùë£5 of this
attractor strategy, for instance
‚Ä≤‚Ä≤
ùúé
= {ùë£
, ùë£
, ùë£
0
1 ‚Ü¶ ùë£5
5 ‚Ü¶ ùë£0
7 ‚Ü¶ ùë£6}. This can be arbitrary here (within the subgame)
since the attractor comprises the entire subgame, so after reaching node ùë£5
and then moving to an arbitrary successor, player 0 can repeatedly enforce
a visit to node ùë£5.
On the other hand, node ùë£5 only has a single successor, so there are no
options other than to move to node ùë£0 anyway.
This solves the entire game G: player 1's winning region is ùëä
, ùë£

, ùë£
, ùë£
1 = {ùë£2
3
4
8},
resulting as the union of ùê¥1 - the 1-attractor of the winning region of the
subgame in the first recursive call - with his winning region from the
second recursive call
‚Ä≤
which is empty. His positional winning strategy is therefore just ùúé1 ‚à∂= ùúé .
1
Player 0's winning region is ùëä
, ùë£
, ùë£
, ùë£
, ùë£
0 = {ùë£0
1
5
6

7}, resulting from the second
‚Ä≤‚Ä≤
recursive call. Her positional winning strategy is ùúé0 ‚à∂= ùúé .
0
12.4 Solving Parity Games
331
The recursive algorithm described above is given in pseudocode in Alg. 2.
Given a finite parity game G with node set ùëä , it computes a quadruple (ùëä
, ùëä , ùúé , ùúé
0
1
0
1)
such that ùëä , ùëä
0
1 is a partition of ùëâ into the winning regions for players 0 and 1, and each
ùúéùëù is a positional winning strategy for player ùëù defined on the domain ùëäùëù
for ùëù ‚àà {0, 1}.
The two recursive calls are the reason for an exponential running time. It is
the game's size that decreases genuinely in both calls, despite of the
algorithm's focus on the number of priorities. It is therefore fair to estimate
its runtime as being exponential in the number of nodes. On the other hand,
the number of priorities decreases in one of these recursive calls, and while
this number can clearly never exceed the number of nodes, it is often much

smaller. A more accurate estimation of the algorithm's runtime is therefore
achieved by considering these two parameters separately.
Theorem 12.16 Alg. 2 solves parity games with ùëõ nodes, ùëò priorities and ùëí
edges in ùëò
time O(ùëí ‚ãÖ ùëõ ) .
Proof Termination of the algorithm has been argued above by pointing out
that the size of the games in the recursive calls is always genuinely smaller
than that of the original game. For correctness we refer to the algorithm's
description above which essentially argues why nodes in the returned sets
ùëä , ùëä
0
1 are won by the respective
players with the returned strategies ùúé , ùúé
0
1. We focus on the estimation of an upper
bound on its runtime.
We argue that there is a constant ùëê such that Alg. 2's runtime can be
bounded by ùëò
ùëê ‚ãÖ ùëí ‚ãÖ ùëõ . To see this we describe the runtime ùëá (ùëõ, ùëò , ùëí) via the
recurrence ùëá (1, ùëò , ùëí) = O(ùëí)
ùëá (ùëõ, 1, ùëí) = O(ùëí)
ùëá (ùëõ, ùëò , ùëí)
= ùëá (ùëõ ‚àí 1, ùëò ‚àí 1, ùëí) + ùëá (ùëõ ‚àí 1, ùëò , ùëí) + O(ùëí)
for ùëõ, ùëò ‚â• 2 .

The first two terms on the right-hand side of the last clause describe the
time needed in the recursive calls; the summand O(ùëí) comes from the need
to compute attractors which can be done using breadth-first search on the
inverse of the underlying graph and is therefore possible in time O(ùëí). Any
other steps like the evaluation of the conditions in if-statements or the
composition of strategies and winning regions is subsumed by this. This
also holds for the bases cases in the two first clauses. More precisely, we
can assume that the algorithm takes at most ùëê ‚ãÖ ùëí steps for some constant ùëê
in each call, not counting steps taken in recursive subcalls.
ùëò
We show that ùëá (ùëõ, ùëò , ùëí) ‚â§ ùëê ‚ãÖ ùëí ‚ãÖ ùëõ from which the theorem's claim on the
worst-case runtime follows immediately. It is obviously true for ùëõ = 1 or ùëò
= 1. So assume that ùëõ, ùëò ‚â• 2. We first observe that then we get
ùëò ‚àí1
ùëò
ùëò
ùëò
(ùëõ ‚àí 1)
+ (ùëõ ‚àí 1) + 1 ‚â§ 2 ‚ãÖ (ùëõ ‚àí 1) + 1 ‚â§ ùëõ .
(12.1)
Then consider the third clause in the recurrence for ùëá (ùëõ, ùëò , ùëí) above. We
verify the runtime estimation as follows.
332
12 Parity Games
ùëá (ùëõ, ùëò , ùëí)

= ùëá (ùëõ ‚àí 1, ùëò ‚àí 1, ùëí) + ùëá (ùëõ ‚àí 1, ùëò , ùëí) + ùëê ‚ãÖ ùëí
ùëò ‚àí1
ùëò
‚â§ ùëê ‚ãÖ ùëí ‚ãÖ (ùëõ ‚àí 1)
+ ùëê ‚ãÖ ùëí ‚ãÖ (ùëõ ‚àí 1) + ùëê ‚ãÖ ùëí
ùëò ‚àí1
ùëò
ùëò
= ùëê ‚ãÖ ùëí ‚ãÖ ((ùëõ ‚àí 1)
+ (ùëõ ‚àí 1) + 1) ‚â§ ùëê ‚ãÖ ùëí ‚ãÖ ùëõ
using
1).
(12.
‚óª
Bibliographic Notes
Two-player games with a parity condition as a winning condition were first
studied by Mostowski [Mos91]. They remain probably the most well-
researched concept amongst those that appear in this book. The reason
seems to be that on one hand, they come with a very natural definition and
an elegant game theory, in particular the fact that they are positionally
determined [EJ91]. On the other hand, this is, to this day, unmatched on the
complexity-theoretical side.

Their membership in NP ‚à©co-NP already makes them a rare object of study
since not many natural problems are known to belong to this class without
also belonging to P. It also makes solving parity games very unlikely to be
NP-complete since this would clearly yield NP =co-NP. Instead,
membership in NP ‚à©co-NP is often seen as an indication that a problem
should really belong to P but a polynomial deterministic algorithm simply
has not been found yet. This belief may even be supported by the fact that
solving parity games even belongs to UP‚à©coUP [Jur98], i.e. it has
algorithms for solving from the point of both players with unique
nondeterministic choices that lead to success.
The fact that no deterministic polynomial-time algorithm has been found yet
for solving parity games is not due to lack of trying. The algorithm
presented here is due to Zielonka [Zie98], based on an algorithm by
McNaughton for solving Muller games [McN93]. The following years saw a
multitude of - conceptually often very different - algorithms proposed for
solving parity games, all with worst-case running times that are
asymptotically at least exponential in the number of priorities. It is ùëò
usually possible to reduce the dependency on the index ùëò to
, an effect that had
2 +
also been observed in fixpoint evaluation algorithms [Sei96, BCJ 97].
One of the first parity game solving algorithms with such running time is
Jurdzinski's Small Progress Measures algorithm [Jur00]. It also provides
the guiding idea for a reduction to the satisfiability problem for
propositional logic [HKLN12], opening up the possibility to leverage the
power of SAT solvers for parity game solving.
The observation of a close connection between parity games and the model
checking problem for the modal ùúá-calculus [EJS01, Sti95], an important
specification language for program verification, has opened up the
possibility to use model checking technology for solving parity games (and
vice-versa), for instance Stevens and Stirling's model checking games

[SS98], Cleaveland's tableaux [Cle90] or fixpoint iteration [BFL14,
vDR19].
Bibliographic Notes for Chapter 12
333
The first major break-through in the search for a polynomial-time algorithm
was made by Jurdzinski et al. with the Dominion Decomposition algorithm
of genuine
‚àö
subexponential running time, depending exponentially on
ùëõ only for games of size
ùëõ [JPZ08]. Randomised algorithms with similar expected subexponential
running times had already been found before by Vorobyov et al. [PV01,
BSV03]
Another interesting speed-up in asymptotic running time was achieved by
Schewe's Big-Step algorithm [Sch17] which replaces the base cases in
Zielonka's recursive algorithm and carefully balances the recursion tree to
achieve a running ùëò
ùëò
time that is exponential in a puzzling
instead of the much more natural
.
3
2

For a long time, strategy improvement - more of a class of algorithms than
a single algorithm - had been believed to be a polynomial algorithm,
simply lacking a runtime analysis that is careful enough to reveal this. This
was based on the fact that its instances like Jurdzinski and V √∂ge's for
example [VJ00] were only ever observed to perform linearly many steps
(with each of them taking low polynomial time) on any benchmark. In much
celebrated work, Friedmann was finally able to handcraft games revealing
an exponential lower bound on its worst-case runtime
[Fri09]. Lower bounds in terms of specific families of games that are hard
to solve had been known for certain other algorithms before, e.g. [Jur00].
Friedmann and others subsequently crushed hopes that some other variant
of strategy improvement
[Fea10, FHZ11, Fri11d, Fri13, AF17, DFH23] as well as the Stevens-
Stirling [Fri10]
or the Zielonka algorithm [Fri11c] would have polynomial running time, cf.
[Fri11b].
Strategy improvement is typically formulated as a global algorithm
determining the winner for all nodes in a game. There are, however, also
on-the-fly versions that determine the winner for a designated initial node
only [FL12b] which is often more useful in practical applications.
One may argue that this only leads to a never ending game, taking turns in
improving an algorithm and providing a lower bound for that improvement.
Some effort has also gone into the design of families of games that are hard
for several (strategy improvement) algorithms [Fri11a] or are even
universally hard for conceptually different algorithms [BDM20].
Meanwhile, more progress has been made on upper bounds. Another much
celebrated result was the first deterministic algorithm that runs in quasi-
polynomial time, i.e. depending exponentially only on log ùëõ for games of
size ùëõ (with a non-
+

constant base), by Calude et al. [CJK 17]. The main idea used there to
lower the complexity is the use of so-called universal trees as very succinct
representations for relevant data like set of nodes. These have subsequently
been used to improve existing algorithms [JL17, Par19, LPSW22, JMT22]
and invent new
+
ones [Leh18, CDHS18, FJdK 19, Par20, ANP21, PW23] that also achieve
quasipolynomial running time.
One may hope that a polynomial runtime is just one step ahead, but this
hope is not justified as shown by Czerwinski et al. who give lower bounds of
quasi-polynomial time for solving parity games based on techniques as they
are used in the listed
+
algorithms [CDF 19].
A different direction of research into solving parity games is motivated by
their use (without really any viable alternatives) in decision procedures for
logics, in
334
12 Parity Games
particular over infinite trees, and in program verification in general. Some
effort has gone into creating tools that solve parity games efficiently in
practice like PGSolver
[FL09] and Oink [vD18], often based on the use of heuristics rather than
algorithms with best asymptotic worst-case behaviour, e.g. [SMPS21].
There are close connections between parity games and other two-player
games of perfect information, in particular pay-off games and stochastic
games [HK66, ZP96].

This relationship was used for example in the development of strategy
improvement as an approach to solving parity games. The algorithm by
Jurdzi ≈Ñski and V √∂ge is based on a strategy improvement algorithm for
mean pay-off games by Puri
[Pur95] which in turn is based on an algorithm for stochastic games by
Hoffman and Karp [HK66]. The latter is reminiscent of the simplex
algorithm for solving linear programs [Dan60], which is another example
of an algorithmic problem that has escaped a polynomial solution for a
long time [Kha80] and for which algorithms are still being studied.
The second parity game shown in Fig. 12.5 and referred to in Exc. 140 is
due to Buhrke et al. [BLV96].
Exercises
Exercise 136 Let G be a two-player game of perfect information and
infinite duration (i.e. all plays are infinite) played on a directed graph with
node set ùëâ such that its set of plays is partitioned into two sets of plays,
namely those won by player 0 and those won by player 1. Let ùëä0 and ùëä1
be the sets of nodes from which player 0, resp.
player 1 has a winning strategy. Show that ùëä0 ‚à© ùëä1 = ‚àÖ.
Exercise 137 Determine winning strategies for player 1 for each of the
nodes ùë£ , ùë£
2
4
and ùë£8 in the parity game shown in Fig. 12.1.
Exercise 138 Prove Lemma 12.4.
Exercise 139 Prove Lemma 12.7.

Exercise 140 Solve the two parity games shown in Fig. 12.5 using the
Zielonka algorithm (Alg. 2). The nodes have not been given explicit names;
instead it is the nodes' priorities that are shown inside the nodes. As usual,
player-0 nodes are drawn as diamonds, player-1 nodes as boxes.
Exercises for Chapter 12
335
0
0
1
0
0
2
2
1
0
1
2
3
4
5
6

7
0
1
2
3
4
5
6
7
Fig. 12.5 Games to solve using Alg. 2.
Chapter 13
Automata on Infinite Trees
A natural question that arises with the study of finite automata operating on
finite words and the two extensions to infinite words and finite trees,
concerns their combination. Consequently, in this chapter we will study
finite automata operating on infinite trees. Any tree whose underlying node
set is infinite can of course be called infinite, but we consider only finitely-
branching trees in which every node has finitely many successors only.
Hence, there are only finitely many nodes on each level, and such infinite
trees are indeed infinitely deep. We continue to demand that trees are

ordered and ranked, i.e. there is always an implicit total order on the
children of any node, and the node's label determines the number of its
children.
It should be clear that a conceptually much different extension to the
models introduced in the previous chapter would be needed in order to
study automata operating on infinitely-branching trees. Hence, finitely-
branching but otherwise infinite trees should allow us to combine the
extensions seen in Chp. 11 concerning the transition relations in tree
automata, and in Chp. 5 and 6 regarding acceptance conditions, leading
rather straightforwardly to an automaton model operating on infinite trees.
For simplicity, we also demand not only that some path in such infinite trees
is infinite but that in fact all paths are infinite. In other words, such infinite
trees have no leaves. For applications that may require leaf nodes in infinite
trees it is always possible to extend finite paths ad infinitum by introducing
a new symbol of arbitrary non-zero arity that marks an ending of a path in
the application's sense, yet the technical demand of all paths being infinite
is fulfilled.
It should be clear that only top-down tree automata can meaningfully be
extended to operate on infinite trees since there are no leaves that bottom-
up automata could start in. On the other hand, the distinction between
nondeterministic bottom-up and top-down tree automata is an artificial one
only made for intuitive purposes.
Again, a tree automaton operating on infinite trees is nothing more than a
finite set of rules that describes locally legal possibilities to label the tree's
nodes with certain combinations of states, taking a node's label from the
underlying alphabet into account, together with a global condition known
as the acceptance condition.
This way, one could equally argue that a tree automaton is neither top-
down nor bottom-up, or both at the same time.
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025

M. Hofmann and M. Lange, Automata Theory and Logic,
337
https://doi.org/10.1007/978-3-662-72154-4_13
338
13 Automata on Infinite Trees
The distinction was important when studying deterministic variants,
showing that top-down determinism is weaker than bottom-up determinism.
Now, on infinite trees one can rightfully argue that bottom-up determinism
is a meaningless concept because, if there are no leaves to deterministically
start a run on, then it is useless to be able to continue the construction of
such a run deterministically afterwards.
So we have that deterministic automata on infinite words are weaker (than
their nondeterministic variants), at least for the B √ºchi acceptance
condition, and that deterministic top-down tree automata are weaker. It
should be clear that top-down deterministic B √ºchi tree automata do not
have the full expressive power of their nondeterministic variants since the
counterexamples and proofs for infinite words and finite trees can trivially
be extended to infinite trees.
This is not the only way to lose expressiveness, though. It turns out that
there is even a gap between the B √ºchi acceptance condition and others
with regards to expressiveness. This is why we define tree automata
operating on infinite trees with one of the richer conditions and study the
expressiveness of the B √ºchi condition as a fragment thereof. We will mostly
stick to the parity acceptance condition since the use of Rabin, Streett or
Muller conditions does not yield greater expressiveness, but algorithmic
approaches offered by parity automata turn out to be a bit nicer than those
for the other models.
An immediate question that arises with any of these conditions that are
properties of infinite, linear sequences is how to apply them to runs of tree
automata that are trees. A natural way is to demand the acceptance

condition to be fulfilled on all paths of a run. This raises some fundamental
questions. For instance, complementability is unclear, even for
deterministic automata, since the negation of all paths in a run satisfying a
parity condition is an existential property, and it is not immediate to see
that this should be expressible as an acceptance condition with universal
path quantification again. In fact, complementation of tree automata
requires some deeper combinatorial insights.
13.1 Parity Tree Automata
13.1.1 Infinite Trees and Tree Languages
Infinite trees over a ranked alphabet Œ£ with ranking function rk Œ£ are
defined like
‚àó
finite trees, just as infinite sets ùë° ‚äÜ N satisfying parent- and left-sibling
closure, as
‚àó
well as ranks: if ùë°(ùë£) = ùëé for some ùë£ ‚àà N and ùëé ‚àà Œ£, then ùë£(ùëë ‚àí 1) ‚àà ùë° but
ùë£ùëë /
‚àà ùë° for
ùëë = rk Œ£(ùëé). As before, we write Œ£ùëë for the set of symbols from Œ£ of rank ùëë.
We also ùúî
let TŒ£ denote the set of all infinite trees over Œ£.
A simple way to ensure infiniteness of ùë° is to demand that all symbols ùëé ‚àà Œ£
have positive rank: rk Œ£(ùëé) > 0 for all ùëé ‚àà Œ£. A path in such infinite trees is
then an infinite sequence ùúÄ, ùëë , ùëë ùëë , ùëë ùëë ùëë , . . .
1

1
2
1
2
3
of nodes in this tree, sometimes also more
conveniently denoted as the ùúî-word ùëë ùëë ùëë . . .
1
2
3
13.1 Parity Tree Automata
339
We define parity tree automata by combining the definitions of a tree
automaton for the transition table and a parity (word) automaton for the
acceptance condition.
Definition 13.1 A nondeterministic parity tree automaton (NPTA) is an A =
(ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) where ùëÑ is a finite set of states, Œ£ is a ranked alphabet with implicit
ranking function rk Œ£ and no symbols of rank 0, and ùëûùêº ‚àà ùëÑ is a designated
initial state. The transition relation ùõø is a collection ùõø = ùõø1 ‚à™ ùõø2 ‚à™ . . . ‚à™
ùõøùëö where ùëö ‚à∂= max{ rk Œ£(ùëé) ‚à£ ùëé ‚àà Œ£ }, and

ùëë
ùõøùëë
‚äÜ ùëÑ √ó Œ£ùëë √ó ùëÑ
for all ùëë = 1, . . . , ùëö .
The size of an NPTA is, as usual, measured as the number of its states. Its
index is, as with NPA, ‚à£Œ©(ùëÑ)‚à£ where Œ©(ùëÑ) ‚à∂= {Œ©(ùëû) ‚à£ ùëû ‚àà ùëÑ} .
ùëë
As before, we make use of the fact that a relation of type ùëÑ √ó Œ£ùëë √ó ùëÑ can
be seen ùëë
ùëÑ
as a function of type ùëÑ √ó Œ£
, . . . , ùëû
ùëë
‚Üí 2
and write (ùëû1
ùëë ) ‚àà ùõø(ùëû , ùëé) for instance
instead of (ùëû, ùëé, (ùëû , . . . , ùëû
1
ùëë )) ‚àà ùõø.
NPTA operate on infinite trees. The notions of runs, accepting runs and tree
languages are obtained by straightforwardly combining the concepts for
tree automata and parity word automata.

Definition 13.2 A run of an NPTA A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) on an infinite Œ£-tree ùë° is a
function ùúå ‚à∂ dom(ùë°) ‚Üí ùëÑ such that ùúå(ùúÄ) = ùëûùêº and for all ùë£ ‚àà dom(ùë°), all ùëë ‚â• 1
and all ùëé ‚àà Œ£ w e have
(ùúå(ùë£0), . . . , ùúå(ùë£(ùëë ‚àí 1))) ‚àà ùõøùëë (ùúå(ùë£), ùëé )
whenever rk Œ£(ùëé) = ùëë and ùë°(ùë£) = ùëé.
Such a run is accepting if for all paths ùúã = ùë£ , ùë£ , ùë£ , . . .
0
1
2
in ùë° we have that
max{Œ©(ùúå(ùë£)) ‚à£ ùë£ ‚àà Inf (ùúã)} is even where Inf (ùúã) denotes the set of all nodes
that occur infinitely often in the sequence ùúã.
As usual, ùêø(A) is said to be the (tree) language of the NPTA A, and it simply
consists of all trees on which A has some accepting run.
We do not introduce an algebraic definition of languages of infinite trees as
it was done for finite and infinite words, leading to the notion of (ùúî-)regular
word languages.
We simply call a language of infinite trees regular if it is NPTA-
recognisable.
Example 13.3 Let Œ£ = {ùëé, ùëè, ùëê} with rk Œ£(ùëé) = rk Œ£(ùëè) = rk Œ£(ùëê) = 2. The
set ùêø1 of all (necessarily full binary) trees over Œ£ in which every path that

contains infinitely many symbols ùëè also contains infinitely many symbols ùëê
is NPTA-recognisable.
It is recognised by the NPTA A
, ùëû
, ùëû
, ùõø, Œ©
1 = ({ùëû ùëé
ùëè
ùëê }, Œ£, ùëû ùëé
) where ùõø(ùëû, ùë•) =
{(ùëû , ùëû
ùë•
ùë• )} for all ùë• ‚àà Œ£. The acceptance condition is given as Œ©(ùëû ùëé ) = 0, Œ©(ùëû ùëè
) = 1
and Œ©(ùëûùëê) = 2.
A run of A1 on a tree ùë° essentially shifts a node label ùë• to both children as a
label with state ùëû ùë• . The parity condition is the one also seen for detecting
word properties
340
13 Automata on Infinite Trees
of the form of an implication between two conditions on the infinite
occurrences of letters, cf. Ex. 6.8. Seeing a symbol ùëè is potentially bad or
has to be remedied by seeing a symbol ùëê. This is why seeing a ùëè triggers the

visit of a state with on odd priority, namely 1. Seeing a ùëê remedies this in
the sense that the priority 2, which occurs then, is greater and even. At last,
seeing an ùëé is harmless in the sense of the tree property, so it triggers the
lowest even priority 0.
The NPTA A1 is essentially obtained from the standard NPA for the
language ùêø of all ùúî-words over {ùëé, ùëè, ùëê} that have infinitely many symbols
ùëê unless they have finitely many symbols ùëè only. The tree language ùêø1 in
this example is of course obtained by a straightforward extension of the
word language ùêø with universal quantification over paths. Likewise, the
NPTA A1 is obtained by a straightforward extension of the standard DPA
for ùêø, simply by turning a successor state in a transition into a tuple of
matching arity of duplicates of that successor state. It is worth noting that
this construction only works in general for deterministic word automata. We
will examine the connection between tree languages of the form "all paths .
. . " and word languages in more detail in the context of complementation
later on.
Example 13.4 Let Œ£ be as in the previous example and ùêø2 be the set of all
trees on which some path contains infinitely many symbols ùëè but only
finitely many symbols ùëê. It is also NPTA-recognisable, namely by the NPTA
A2 =
({ùëû , ùëû , ùëû , ùëû
, ùõø, Œ©
0
ùëé
ùëè
ùëê }, Œ£, ùëû ùëé
) with
Œ©(ùëû0) = 0 , Œ©(ùëûùëé) = 1 , Œ©(ùëûùëè) = 2 , Œ©(ùëûùëê ) = 3

and the transitions
ùõø(ùëû , ùë•
, ùëû
, ùëû
, ùë•
, ùëû
ùë¶
)
‚à∂= {(ùëû ùë•
0), (ùëû0
ùë• )}
,
ùõø(ùëû0
)
‚à∂= {(ùëû0
0)}
for any ùë•, ùë¶ ‚àà Œ£.
A2 uses nondeterminism to guess a path through an underlying tree and
verifies using the states ùëû , ùëû , ùëû
ùëé

ùëè
ùëê
and their priorities 1, 2, 3, that this path indeed contains
infinitely many symbols ùëè but only finitely many symbols ùëê.
The NPTA A
, ùëû
, ùëû
, ùõø, Œ©
3 = ({ùëû0
ùëé
ùëè }, Œ£, ùëû ùëé
) with Œ© and ùõø defined as above, but
only for ùëû , ùëû , ùëû
0
ùëé
ùëè then recognises the set of all trees over {ùëé, ùëè} only in which some path
contains infinitely many symbols ùëè. Its index is three since it uses priorities
0, 1, 2. It is possible to reduce its index to two, namely priorities 1 and 2,
though.
State ùëû0 can be given priority 2 because any path of a run that visits state
ùëû0 then stays in state ùëû0 forever. Hence, once this state occurs on a path
with the original priority 0, no priority 1 can occur below this, and one can

safely lift all these priorities to 2 without making more branches of the run
satisfy the parity condition, and so the language is preserved.
The NPTA A1 in Ex. 13.3 does not use nondeterminism; it is deterministic in
the usual sense.
Definition 13.5 An NPTA A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) is said to be deterministic (DPTA),
if ‚à£ùõø(ùëû, ùëé)‚à£ ‚â§ 1 for all ùëû ‚àà ùëÑ and all ùëé ‚àà Œ£.
13.1 Parity Tree Automata
341
It is not hard to see that DPTA are weaker in expressiveness than NPTA.
The example that separates the expressive power of DtdTA from NTA in
Thm. 11.21
can easily be extended to one on infinite trees. Spelling out the details is left
as an exercise.
Theorem 13.6 a) There are NPTA-recognisable tree languages that are not
DPTA-recognisable.
b) The class of DPTA-recognisable languages is not closed under
complementation.
Part (b) of this theorem is hinted at by the two examples above. Note that
ùêø2 is in fact the complement of the language ùêø1. The fact that A2 is not a
DPTA is of course no proof for the claim that ùêø2 is not DPTA-recognisable.
But it is possible to carry out the proof of part (a) with ùêø2 as an example.
Likewise, the principles used in the proof of Thm. 11.21 can also be applied
to show that ùêø2 is not DPTA-recognisable.

Thm. 13.6 highlights an important difference in the automata theory of
infinite trees compared to that on infinite words: while the parity condition
is strong enough to enable determinisation of word automata, a simple
dualisation construction does not work for tree deterministic parity
automata anymore. It is also pointless to try to determinise tree automata
into those with a Muller condition, because a tree automaton with a Muller
condition could easily be transformed into a parity tree automaton using
the LAR construction of Thm. 6.28, and this preserves determinism.
13.1.2 B ¬®
uchi Tree Automata
It is fair to ask why we introduced tree automata with a parity acceptance
condition straight away rather than to start with B √ºchi automata which
may perhaps seem to be reasonable given the exposition in Chp. 5 and Chp.
6 for ùúî-words. The answer is that, unlike the case for words, B √ºchi tree
automata are strictly weaker in expressiveness than parity tree automata.
They also do not enjoy closure under complements. Thus, they are not a
good model for a theory of regular languages of infinite trees. Instead we
call a language of infinite trees regular iff it is NPTA-recognisable.
A nondeterministic B ¬®
uchi tree automaton (NBTA) is defined straightforwardly,
just like an NPTA but with a set of accepting states, and a run on a tree is
accepting when every branch visits accepting states infinitely often.
Alternatively, an NPTA of index 2 with a smaller odd and a greater even
priority, for example 1 and 2, can be called an NBTA.
We aim to show that there are regular languages of infinite trees that cannot
be recognised by NBTA. An example of such a language ùêø0 can be
constructed over the ranked alphabet Œ£ = {ùëé, ùëè} with rk Œ£(ùëé) = rk Œ£(ùëè) =
2. ùêø0 consists of all Œ£-trees such that every path contains finitely many
symbols ùëè onl y.

It is not hard to see that ùêø0 is regular. An NPTA, even a DPTA recognising
it can easily be constructed. Details are left as an exercise.
Lemma 13.7 The language ùêø0 is regular.
342
13 Automata on Infinite Trees
We use a pumping argument to show the expressive weakness of NBTA. As
usual, the first key step is to construct a sequence of pumpable candidates,
here in the form of (necessarily binary) Œ£-trees ùë°ùëõ, defined for ùëõ ‚â• 0 b y
‚éß
‚é™
‚àó
‚â§ùëõ
‚é™ùëè
, if ùë£ ‚àà (0 1)
and ùë£ ‚â† ùúÄ ,
ùë°ùëõ(ùë£)
‚à∂= ‚é®
‚é™
‚é™ùëé
, otherwise.
‚é©

For example, ùë°0 is the tree that is labelled with symbols ùëé only; ùë°1 is the
tree in which
‚àó
only nodes of the form 0 1 are labelled ùëè, i.e. only the right children of a
node on the leftmost path from the root. Slightly abusing term
representation we get that ùë°
, ùëè
, ùë°
ùëõ
= ùëé(ùë°ùëõ
(ùë°ùëõ‚àí1 ùëõ‚àí1 ))
for all ùëõ > 0.
A crucial observation is the following. It may be tempting to try to prove it
by induction on ùëõ, but this is not possible since ùë°ùëõ contains itself as a
genuine subtree.
Lemma 13.8 For all ùëõ ‚â• 0 we have ùë°ùëõ ‚àà ùêø 0 .
Proof Fix ùëõ ‚â• 0 and suppose that ùë°ùëõ /‚àà ùêø0, i.e. ùë°ùëõ contains an infinite path
ùúã with infinitely many symbols ùëè. Such a path can be represented as an ùúî-
word ùëë ùëë ùëë . . .
0
1
2
‚àà

ùúî
{0, 1} .
‚àó
ùúî
We distinguish two cases. First suppose that ùúã is of the form (0 + 1) 0 . Then
it has only finitely many occurrences of 1, i.e. it forks to the right only
finitely many times. But a letter ùëè is only found at a node that is the right
child of its parent. Hence, this path cannot contain infinitely many symbols
ùëè.
‚àó
ùúî
Suppose therefore that ùúã is of the form (0 1) , i.e. it forks to the right
infinitely often. Now we make use of the fact that not every right child of a
node is labelled with ùëè. Instead this is only the case if the unique path from
the root to that child encounters at most ùëõ forks to the right. But this is
obviously only true for the first ùëõ nodes that are right children of their
parents on ùúã. Hence, such a path ùúã cannot contain infinitely many symbols ùëè
either.
‚óª
We also need an unravelling construction on trees. We define it for binary
trees only since this suffices for our purposes here. The construction can
easily be applied to trees with nodes of arbitrary branching degrees, but it
is more tedious to define formally when there are nodes of differing
branching degrees.
‚àó
For two words ùë¢, ùë£ ‚àà {0, 1} we write ùë¢ ‚™Ø ùë£ if ùë¢ is a prefix of ùë£. When
taken as nodes in a tree, ùë¢ ‚™Ø ùë£ means that ùë¢ occurs on the unique finite

path from ùë°'s root to ùë£.
‚àó
+
Let ùë° be an infinite binary tree, ùë¢ ‚àà {0, 1} and ùë£ ‚àà {0, 1} . The unravelling
of ùë°
w.r.t. ùë¢ and ùë¢ùë£ is the tree ùë°[ùë¢‚Üêùë£] that is intuitively obtained by removing
the subtree under node ùë¢ùë£ and instead pasting an infinite repetition of the
subtree under ùë¢ in there. Fig. 13.1 depicts this construction schematically.
Formally, we have
‚éß
‚é™
+
‚é™ùë° (ùë¢ ùëß)
, if ùë§ is of the form ùë¢ùë£ ùëß for some ùëß s.t. ùë£ /
‚™Ø ùëß
ùë° [ùë¢‚Üêùë£](ùë§)
‚à∂= ‚é®
‚é™
‚é™ùë° (ùë§)
, otherwise
‚é©
13.1 Parity Tree Automata

343
ùë¢
ùë¢
ùë£
ùë£
ùë£
ùë£
Fig. 13.1 The unravelling (right) of a tree (left) with respect to nodes ùë¢ and
ùë¢ùë£.
‚àó
for any ùë§ ‚àà {0, 1} .
Lemma 13.9
‚àó
+
Let ùë° be a binary Œ£ -tree, ùë¢ ‚àà {0, 1} , ùë£ ‚àà {0, 1}
and ùëé ‚àà Œ£ such that
ùë° (ùë¢ùë§) = ùëé for some ùë§ ‚â∫ ùë£ . Then ùë°[ùë¢‚Üêùë£] contains a path on which ùëé
occurs infinitely often.
Theorem 13.10 There are regular languages of infinite trees that are not
NBTA-recognisable.
Proof Take the language ùêø0 of binary {ùëé, ùëè}-trees on which every path
contains finitely many symbols ùëè only, as constructed above. According to

Lemma 13.7 it is regular. It remains to be seen that it is not NBTA-
recognisable.
Suppose, for the sake of contradiction, that ùêø0 = ùêø(A) for some NBTA A =
(ùëÑ, Œ£, ùëû , ùõø, ùêπ
ùêº
) with ùêπ ‚äÜ ùëÑ. Let ùëõ ‚à∂= ‚à£ùêπ‚à£ and consider ùë°ùëõ. According to Lemma 13.8, we
have ùë°ùëõ ‚àà ùêø0, so there must be an accepting run ùúå of A on ùë°ùëõ. In particular,
every path of the run tree ùúå contains infinitely many nodes from ùêπ.
Next we construct a sequence of paths ùúãùëñ, numbers ùëöùëñ and states ùëìùëñ for ùëñ = 0,
. . . , ùëõ
ùúî
as follows. Start with ùúã0 ‚à∂= 0 . Since ùúå contains infinitely many accepting
states ùëö
on ùúã
0
0 there must be some ùëö0 such that ùëì0 ‚à∂= ùúå(0
) ‚àà ùêπ . Next consider the path
ùëö
ùúî
ùúã
0
1 ‚à∂= 0

10 . Again, it must contain infinitely many accepting states. Hence, there ùëö
ùëö
is some ùëö
0
1
, . . . , ùëö
1 ‚àà N and ùëì1 ‚àà ùêπ such that ùúå(0
10
) = ùëì1. In general, when ùëö0
ùëñ
ùëö
ùëö
ùëö
ùúî
have been found, let ùúã
0
1
ùëñ
ùëñ+1 ‚à∂= 0
10

1 . . . 10
10 . Then use the fact that ùúå must
assign accepting states to infinitely many states on this path, in particular
to some ùúî
state that occurs on the suffix of the form 0 . This defines ùëö ùëñ+1 and ùëìùëñ+1.
Now remember that ùëõ = ‚à£ùêπ‚à£, hence there must be some ùëñ, ùëó with 0 ‚â§ ùëñ < ùëó ‚â§
ùëõ such ùëö
ùëö
ùëö
ùëö
that ùëì
0
ùëñ
ùëñ+1
ùëó
ùëñ
= ùëì ùëó . Let ùë¢ ‚à∂= 0
1 . . . 10
and ùë£ ‚à∂= 10
1 . . . 10
. Note that the symbol

ùëè occurs somewhere on the path from ùë¢ to ùë¢ùë£ in ùë°ùëõ, namely at node ùë¢1
because
‚àó
ùëñ < ùëõ. According to Lemma 13.9, ùë°
‚à∂= ùë°ùëõ[ùë¢‚Üêùë£] contains a path with infinitely many
‚àó
symbols ùëè, so we have ùë°
/
‚àà ùêø0.
344
13 Automata on Infinite Trees
‚àó
‚àó
On the other hand, one can construct an accepting run ùúå of A on ùë° . It is
obtained
‚àó
by lifting the unravelling construction from ùë°ùëõ to ùë°
to ùúå. This is locally sound, i.e.
‚àó
ùúå

is only composed of transitions that are valid according to ùõø because they
all occur in ùúå and ùúå(ùë¢) = ùúå(ùë¢ùë£).
‚àó
‚àó
Now there are two types of paths in ùúå
or, equally, in ùë° : almost every path
ùúî
eventually proceeds like a path in ùúå, namely as soon as it deviates from ùë¢ùë£ .
The suffix after the deviation point is the suffix of some path in ùúå, hence it
contains ùúî
infinitely many accepting states. But the only remaining path ùë¢ùë£
also contains
infinitely many accepting states because ùë¢ and ùë£ were constructed in a way
that guarantees that some accepting state is seen between ùë¢ and ùë¢ùë£.
‚àó
Hence, this unravelling or pumping has created a tree ùë° that is also
accepted by A but does not belong to ùêø0. Thus, we have ùêø(A) ‚â† ùêø0
contradicting the assumption. ‚óª
The second weakness of NBTA mentioned above is then just a consequence
of this.
Corollary 13.11 The class of NBTA-recognisable language is not closed
under complements.
Proof This follows immediately from the previous result by observing that
the complement ùêø of the language ùêø used in the proof of Thm. 13.10 above,

is in fact NBTA-recognisable. Note that ùêø consists of all trees that have a
path with infinitely many symbols ùëè. An NBTA for this language is given at
the end of Ex. 13.4.
‚óª
13.1.3 Closure Properties
The main goal is, as before, to show that the class of languages of infinite
trees that are recognised by NPTA, is closed under complements. This bears
the combined difficulties of several similar tasks: we have seen in Chp. 5
that complementation on infinite words involves some combinatorial
difficulties; clearly these are implicitly present for infinite trees as well.
Complementation closure was given for finite trees, but it needed
deterministic bottom-up tree automata. On the other hand, only
deterministic top-down automata can meaningfully be constructed for
infinite trees.
Deterministic top-down automata were not helpful in achieving
complementation closure for finite trees; so clearly they will not be helpful
here either. In addition, we have just seen that we cannot work restrict
attention to the simple B √ºchi condition, so working with parity tree
automata may induce further complications.
In the end, complementation closure for NPTA-recognisable languages, i.e.
regular languages of infinite trees, does hold indeed. The construction will
need some other closure properties which we discuss here. The first one -
closure under unions
- is imminent due to the presence of nondeterminism in the automaton
model.
Lemma 13.12 For every NPTA A ,
, ùëò
1 A2 of sizes ùëõ1 , ùëõ2 and indices ùëò 1

2 there is
an NPTA B of size at most ùëõ
, ùëò
1 + ùëõ2 + 1 and index at most max{ùëò 1
2} such that
ùêø (B) = ùêø(A1) ‚à™ ùêø(A2) .
13.1 Parity Tree Automata
345
Closure under intersections is also given, but it requires a little bit more
thought.
It either follows from complementation closure using the deMorgan laws, or
one can attempt to directly construct an NPTA via a product construction
that simulates two given NPTA on a tree. This is problematic, though,
because the resulting acceptance condition is naturally a conjunction of two
parity conditions, and it is not that easy to express it as a parity condition
again. One possibility is to regard it as a Muller condition and translate it
back into a parity condition using the LAR construction.
This leads to the following estimation. Details are left as an exercise.
Lemma 13.13 For every NPTA A ,
, ùëò
1 A2 of sizes ùëõ1 , ùëõ2 and indices ùëò 1
2 there
is an NPTA B of size O((ùëõ1 ‚ãÖ ùëõ2) ‚ãÖ (ùëò1 ‚ãÖ ùëò2)!) and index O(ùëò1 ‚ãÖ ùëò2) such
that ùêø (B) = ùêø(A1) ‚à© ùêø(A2) .

The next construction is that of a homomorphism. Recall that the class of
regular languages of finite words is closed under homomorphisms based on
arbitrary morphisms ‚Ñé ‚à∂ Œ£ ‚Üí Œî‚àó for two alphabets Œ£ and Œî. It would of
course be more precise to say that homomorphisms preserve regularity,
given that there is not just one class of regular languages on which
homomorphisms act as a mapping, but they transform languages over one
alphabet into languages over another.
Lifting this to the world of infinite words already required a restriction to be
imposed, namely closure under non-deleting homomorphisms, i.e. those that
are based on a morphism of type Œ£ ‚Üí Œî+ for two alphabets Œ£, Œî. This
guarantees that the image of an infinite word is an infinite word again.
Lifting it to tree languages required a further restriction, namely that of
being rank-preserving (cf. Def. 11.12).
It is not hard to see that without this construction the homomorphic image
of a tree is either not well-defined, or a na¬®ƒ±ve attempt at making it well-
defined, for instance by copying subtrees in order to satisfy rank conditions,
will break regularity of homomorphic images.
So as with finite trees, we will consider homomorphisms on infinite trees
only when they are based on rank-preserving morphisms ‚Ñé ‚à∂ Œ£ ‚Üí Œî, i.e.
when rk Œî(‚Ñé(ùëé)) =
ùúî
ùúî
rk Œ£(ùëé) for every ùëé ‚àà Œ£. This then induces a homomorphism ÀÜ
‚Ñé ‚à∂ TŒ£ ‚Üí TŒî naturally
via ÀÜ
‚Ñé(ùë° )(ùë£) = ‚Ñé(ùë° (ùë£)) for every ùë£ ‚àà dom(ùë°). Moreover, this is lifted to tree
languages via ÀÜ
‚Ñé(ùêø) ‚à∂= { ÀÜ

‚Ñé(ùë° ) ‚à£ ùë° ‚àà ùêø }.
We then have that homomorphisms based on rank-preserving morphisms
preserve regularity of languages of infinite trees. The proof is left as an
exercise.
Lemma 13.14 For every NPTA A of size at most ùëõ over some ranked
alphabet Œ£
and every rank-preserving morphism ‚Ñé ‚à∂ Œ£ ‚Üí Œî there is an NPTA B of size
at most ùëõ such that ùêø(B) = ÀÜ
‚Ñé(ùêø(A)) .
We will apply Lemma 13.14 mainly for rank-preserving projections which
are special morphisms operating on alphabets of the form Œ£ùëò for some ùëò ‚â•
1 by deleting certain elements of these tuples. While this is not a concept
particularly linked to trees - see for instance the use of projections in the
construction of NFA from MSO
formulas over finite words (Thm. 2.16) - the next construction is trivial for
word languages and only interesting for genuine tree languages.
346
13 Automata on Infinite Trees
Definition 13.15 Let Œ£ be a ranked alphabet, ùëö ‚à∂= max{ rk Œ£(ùëé) ‚à£ ùëé ‚àà Œ£}
and ùê∑ ‚à∂=
ùúî
{0, . . . , ùëö ‚àí 1}. A tree ùë° ‚àà TŒ£ determines a set Tr(ùë°) of guided traces as
words over Œ£ √ó ùê∑ as follows. We ha ve
(ùëé , ùëë
, ùëë

, ùëë
. . . ùëë
0
0), (ùëé1
1), (ùëé2
2), . . . ‚àà Tr(ùë°)
iff
ùëéùëñ = ùë°(ùëë0
ùëñ‚àí1) for all ùëñ ‚â• 0 .
ùúî
‚ñ≥
Now let ùêø ‚äÜ (Œ£ √ó ùê∑)
be a language of infinite Œ£-words. The language ùêø
is
‚ñ≥
the language of infinite trees whose guided traces all belong to ùêø, i.e. ùë° ‚àà ùêø
iff
Tr(ùë°) ‚äÜ ùêø .
‚ñ≥
It is helpful to intuitively consider the construction of ùêø

as follows: given a
ùúî
language of words ùêø ‚äÜ (Œ£ √ó ùê∑) . Each of them can be seen as a trace, i.e.
the concatenated labels of a path, in a tree. The second components
determine the path in the tree that this trace comes from.
Example 13.16 Let Œ£ = {ùëé, ùëè} with rk Œ£(ùëé) = rk Œ£(ùëè) = 2. Consider the
language ùúî
ùúî
‚àó
ùêø
‚à∂= (ùëé, 0)
+ (ùëé, 0) (ùëé, 1)((ùëè, 0) + (ùëè, 1))
‚ñ≥
of guided traces. Then ùêø
contains exactly one tree, namely the binary tree whose
root is labelled ùëé, and in which
‚Ä¢ the left child of an ùëé-node is an ùëé-node again,
‚Ä¢ the right child of an ùëé-node is a ùëè-node and
‚Ä¢ both children of a ùëè-node are ùëè-nodes.
Consider, on the other hand, the guided-trace languages ùêøùëõ for ùëõ ‚â• 0
defined b y ùúî
ùêø

, ùëë
, ùëë
ùëõ
‚à∂= {(ùë•0
0), (ùë•1
1), . . . ‚àà ({ùëé, ùëè} √ó {0, 1})
‚à£ ‚à£{ùëñ ‚à£ ùë•ùëñ = ùëè}‚à£ ‚â§ ùëõ } .
‚ñ≥
Then ùêøùëõ consists of exactly those Œ£-trees such that every path contains at
most ùëõ
occurrences of the symbol ùëè.
‚ñ≥
Clearly, it is possible to have ùêø
= ‚àÖ even though ùêø ‚â† ‚àÖ, simply when ùêø does not
ùúî
‚àó
contain enough guided traces. For instance, let ùêø = (ùëé, 0) (ùëé, 1)((ùëè, 0) +
(ùëè, 1)) .
‚ñ≥
ùúî
Then ùêø

= ‚àÖ because ùêø does not contain a trace for the path 0 , even though the
labels of that path could be considered to be entirely determined by the
information given for other paths.
Lemma 13.17 For every DPA A of size ùëõ and index ùëò recognising a
language of
‚ñ≥
guided traces, there is a DPTA B of size ùëõ and index ùëò such that ùêø(B) =
ùêø(A) .
Proof Let a ranked alphabet Œ£ be given with its associated set of directions
ùê∑, and A = (ùëÑ, Œ£ √ó ùê∑, ùëû , ùõø, Œ©
ùêº
) be a DPA over Œ£ √ó ùê∑ with ùëõ = ‚à£ùëÑ‚à£ and ùëò = ‚à£{Œ©(ùëû) ‚à£ ùëû ‚àà ùëÑ}‚à£.
‚Ä≤
We construct the DPTA B ‚à∂= (ùëÑ, Œ£, ùëû , ùõø , Œ©
ùêº
) under demand via
‚Ä≤
ùõø (ùëû, ùëé)
‚à∂= (ùõø(ùëû, (ùëé, 0)), ùõø(ùëû, (ùëé, 1)), . . . , ùõø(ùëû, (ùëé, ùëë ‚àí 1)) )
for every ùëû ‚àà ùëÑ, ùëé ‚àà Œ£ and ùëë = rk Œ£(ùëé). Note that B is in fact
deterministic.
13.1 Parity Tree Automata
347

‚ñ≥
The claim on the size of B is clear. It remains to be seen that ùêø(B) = ùêø(A) .
For the direction "‚äÜ" it suffices to check that an accepting run of B on
some tree ùë° can be decomposed into all paths occurring in this run, and
each of them belongs to ùêø(A), making use of the fact that the parity
condition of an NPTA applies to all paths in an accepting run. Hence, the
set of all guided traces of ùë° is included in ùêø(A) and so
‚ñ≥
ùë° ‚àà ùêø(A)
.
The direction "‚äá" is seen in the same way. However, here we need the
requirement of A being deterministic. Then we have that each two guided
traces ùúè , ùúè
1
2 that are
accepted by A, have accepting runs that share a common prefix which is at
least as long as the longest common prefix of ùúè1 and ùúè2. This is why it is
possible to assemble an accepting run of B on ùë° from accepting runs of A on
all guided traces from ùë°. ‚óª
It is not possible to carry out the construction using a nondeterministic B
√ºchi or parity automaton for the language of guided traces, even when
allowing the resulting tree automaton to be nondeterministic.
Example 13.18 Take the ranked alphabet Œ£ = {ùëé, ùëè} with both symbols
having rank
‚àó
ùúî

‚ñ≥
2, and consider ùêø = (Œ£ √ó ùê∑) ({ùëé} √ó ùê∑)
where ùê∑ = {0, 1}. The language ùêø
consists of all trees such that every path only contains finitely many symbols
ùëè.
Take the most obvious NBA for ùêø, for example the following.
Œ£
{ùëé} √ó ùê∑
√ó ùê∑
{ùëé} √ó ùê∑
ùëû
ùëû
0
1
‚ñ≥
An attempt to construct an NPTA for ùêø
along the lines of the proof of Lemma 13.17
above yields the NBTA ({ùëû , ùëû
, ùõø,
0

1}, Œ£, ùëû0
{ùëû1}) with
ùõø(ùëû , ùëé
, ùëè
, ùëû
, ùëû
, ùëû
, ùëû
0
)
= ùõø(ùëû0
)
= {(ùëû0
0), (ùëû0
1), (ùëû1
0), (ùëû1
1)} ,
ùõø(ùëû , ùëé
, ùëû
1

)
= {(ùëû1
1)} ,
ùõø(ùëû , ùëè
1
)
=
‚àÖ .
This tree automaton does not accept the tree ùë° given by
‚éß
‚é™
‚àó
‚é™ùëè
, if ùë£ ‚àà 0 1 ,
ùë° (ùë£)
= ‚é®
‚é™
‚é™ùëé
, otherwise
‚é©

‚ñ≥
even though it belongs to ùêø . The reason for this is the fact that an
accepting run ùúî
would have to eventually contain the accepting state ùëû1 on the path 0 , but
then no node label ùëè could be processed in the subtree under this node. On
the other hand, ùúî
every node on the path 0
has one child labelled ùëè.
348
13 Automata on Infinite Trees
13.2 Complementation Closure
Positional determinacy of parity games is the combinatorial result which
allows us to prove closure of the class of languages recognised by NPTA
under complements.
Remember that complementation of automata comes with several obstacles
in general: for a start, we do not face the same problems of those
introduced by a B √ºchi condition since the parity condition lends itself to an
easy dualisation. However, NPTA are nondeterministic, so simply dualising
the acceptance condition does not work. Additionally, NPTA are tree
automata, so even if they were deterministic a simple dualisation procedure
would not be sufficient because the acceptance condition with its universal
quantification over paths in a tree would be dualised into an existential
quantification over paths.
Despite these obstacles, complementation closure for NPTA holds indeed.
In order to use positional determinacy of parity games we need to link them
to the acceptance of trees by NPTA.
13.2.1 Acceptance as a Parity Game

We define, given an NPTA A and a tree ùë° over the same ranked alphabet Œ£,
a parity game that is won by player 0 iff ùë° ‚àà ùêø(A). Intuitively, the game is
played by moving two tokens around, one residing on a state in A and the
other on a node in ùë°. Initially, they are placed in A's initial state and on ùë°'s
root node.
The game proceeds in rounds. In each round with the tokens on a state ùëû
and a node ùë£, first player 0 selects a tuple from the transition table. More
specifically, let ùëé = ùë°(ùë£) be the symbol at the tree's marked node and ùëë ‚à∂=
rk Œ£(ùëé). Then player 0 chooses a tuple (ùëû , . . . , ùëû
0
ùëë‚àí1) ‚àà ùõø(ùëû, ùëé). Player 1 then responds by choosing a
number ùëñ ‚àà [ùëë], after which the token in the NPTA is moved to ùëûùëñ and the
tree token is moved to node ùë£ùëñ.
Because of their roles, specifically where they perform their choices in this
turn-based game, the players are often also referred to as Automaton
(player 0) and Pathfinder (player 1). Here we stick to the names 0 and 1 to
remain consistent with the game terminology used so far.
We give a more formal definition of this acceptance game for NPTA.
Definition 13.19 Let Œ£ be a ranked alphabet, ùëö ‚à∂= max{ rk Œ£(ùëé) ‚à£ ùëé ‚àà Œ£},
A =
ùúî
(ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) be an NPTA over Œ£ and ùë° ‚àà TŒ£ . The acceptance game for A and ùë°
is the parity game G

, ùëâ , ùë£
, ùê∏ , Œ©‚Ä≤
A,ùë° ‚à∂= (ùëâ , ùëâ0
1
ùêº
) defined as follo ws.
‚Ä¢ There are two kinds of positions in this game. The distinction coincides
with the partition of positions belonging to either of the players. As usual, ùëâ
is the disjoint union of ùëâ0 and ùëâ1 which are defined as follows.
- The first kind consists of pairs of automaton states and tree nodes. These
belong to player 0: ùëâ0 ‚à∂= ùëÑ √ó dom(ùë°).
13.2 Complementation Closure
349
- Player-1 positions are pairs of automaton state tuples from the transition
table and tree nodes:
ùëö
ùëâ
ùõø
1
‚à∂= ( ‚ãÉ ‚ãÉ
‚ãÉ
ùëë (ùëû , ùëé )) √ó dom(ùë° )

ùëû‚ààùëÑ ùëë=1 ùëé‚ààŒ£ùëë
Note that some confusion may arise with alphabet symbols of rank 1 unless
we carefully distinguish a single state from the singleton tuple containing
that state.
In other words, the player-0 position (ùëû, ùë£) should be distinguished from
the player-1 position ((ùëû), ùë£).
‚Ä¢
ùêº
ùêº
The initial position in the game is ùë£ ‚à∂= (ùëû , ùúÄ).
‚Ä¢ The game is strictly turn-based, i.e. we have ùê∏ ‚äÜ ùëâ0 √ó ùëâ1 ‚à™ ùëâ1 √ó ùëâ0.
Specifically, we hav e
ùê∏
‚à∂= {((ùëû, ùë£), ((ùëû , . . . , ùëû
, . . . , ùëû
0
ùëë‚àí1), ùë£)) ‚à£ (ùëû0
ùëë‚àí1) ‚àà ùõøùëë (ùëû, ùë° (ùë£))}
‚à™ {((ùëû , . . . , ùëû
, ùë£ùëñ
0
ùëë‚àí1), ùë£), (ùëûùëñ

)) ‚à£ ùëñ ‚àà {0, . . . , ùëë ‚àí 1 }} .
‚Ä¢ The winning condition in this game is given by inheritance of the
priorities from the automaton's acceptance condition:
Œ©‚Ä≤(ùëû, ùë£) ‚à∂= Œ©(ùëû)
and
Œ©‚Ä≤((ùëû , . . . , ùëû
0
ùëë‚àí1), ùë£) ‚à∂= 0
ùëö
for all ùëë ‚â§
.
Theorem 13.20
ùúî
Let A be an NPTA over some ranked alphabet Œ£ and ùë° ‚àà TŒ£ . Player 0 wins
the acceptance game GA,ùë° iff ùë° ‚àà ùêø(A) .
Proof
ùúî
Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) and ùë° ‚àà TŒ£ be given.

"‚áê" Suppose there is an accepting run ùúå of A on ùë°. It can immediately be
regarded as a representation of a positional winning strategy ùúé0 for player
0 in GA,ùë° . Note that ùúå(ùúÄ) = ùëû
, ùúÄ
ùêº . Hence, the initial position (ùëû ùêº
) of GA,ùë° is a pair (ùëû, ùë£) such that
ùëû = ùúå(ùë£). By ensuring that this is an invariant under the players' choices, it
suffices to define ùúé0 on pairs (ùëû, ùë£) that satisfy this proper ty.
So suppose some (ùëû, ùë£) is given such that ùúå(ùë£) = ùëû. Let ùëé ‚à∂= ùë°(ùë£) and ùëë ‚à∂=
rk Œ£(ùëé).
By definition, ùë£ has ùëë many ordered children ùë£0, . . . , ùë£(ùëë ‚àí1), and ùúå labels
them with states ùëû , . . . , ùëû
, . . . , ùëû
0
ùëë‚àí1 respectively, such that (ùëû0
ùëë‚àí1) ‚àà ùõøùëë (ùëû, ùëé). This determines
player 0's choice: ùúé
, . . . , ùëû
0(ùëû, ùë£) ‚à∂= ((ùëû0
ùëë‚àí1), ùë£). Note that, no matter which ùëñ ‚àà [ùëë]
player 1 chooses subsequently, the resulting position in the game is (ùëû , ùë£ùëñ
ùëñ

), and the
invariant still holds because ùúå(ùë£ùëñ) = ùëûùëñ for all such ùëñ.
Finally, it remains to be seen that ùúé0 is indeed a winning strategy. Take any
play ùúã
= (ùëû , ùë£
,
,
, ùë£
,
,
, ùë£
,
, . . .
0
0) ((. . .), ùë£0) (ùëû1
1) ((. . .), ùë£1) (ùëû2
2) ((. . .), ùë£2)
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂ ¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂ ¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂ ¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
‚Ä≤

‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
ùë£
ùë£
ùë£
ùë£
ùë£
ùë£
0
1
2
3
4
5
conforming to ùúé0. Then
‚Ä≤
‚Ä≤

lim sup Œ©‚Ä≤(ùë£ ) =
Œ©‚Ä≤(ùë£ ) =
Œ©(ùëû
ùëñ
lim sup
2ùëñ
lim sup
ùëñ ) .
ùëñ‚Üí‚àû
ùëñ‚Üí‚àû
ùëñ‚Üí‚àû
350
13 Automata on Infinite Trees
‚Ä≤
‚Ä≤
The former equality holds because the positions ùë£ , ùë£ , . . . with odd indices
all have 1
3
priority 0, so they do not contribute to the limes superior in this sequence.
The second equation simply uses the definition of Œ©‚Ä≤. Now note that for such
a play ùúã, the sequence ùë£ , ùë£ , . . .

, ùëû
, . . .
0
1
forms a path through ùë°, and so ùëû0
1
is a sequence of
state labels in ùúå along a path in ùë°. By the assumption that ùúå is an accepting
run, lim sup
Œ©(ùëû
ùëñ‚Üí‚àû
ùëñ ) is even, and then so is the maximal priority occurring infinitely often in ùúã
which makes it winning for player 0. Hence, ùúé0 is indeed a winning strategy.
"‚áí" Suppose that player 0 has a winning strategy ùúé0 for the acceptance
game GA,ùë° . We use this to construct an accepting run ùúå of A on ùë°. All we
need to do for this is to define a state label ùúå(ùë£) for every ùë£ ‚àà dom(ùë°) such
that the greatest priority of the sequence of states along any path through ùë°
is even. It is not strictly necessary but simplifies the construction when we
assume that ùúé0 is indeed positional. This is a valid assumption according to
Thm. 12.12.
We start with the root label ùúå(ùúÄ) ‚à∂= ùëûùêº . Now suppose that for some node ùë£ ‚àà
dom(ùë°), ùúå(ùë£) is already defined. We use this to define ùúå(ùë£ùëñ) for all successors
ùë£ùëñ of ùë£ . Simply consult ùúé0(ùúå(ùë£), ùë£). Note that for ùë£ = ùúÄ, ùúé0 must provide a
choice. Similar to the other direction in the proof above we will maintain

this invariant, so we can assume that ùúé0 does indeed provide a choice in the
player-0 position (ùúå(ùë£), ùë£). We have ùúé
, . . . , ùëû
, . . . , ùëû
0(ùúå(ùë£), ùë£) = (ùëû0
ùëë‚àí1) for some ùëë and ùëû0
ùëë‚àí1. Then let ùúå(ùë£ùëñ) ‚à∂= ùëûùëñ
for ùëñ ‚àà [ùëë ].
The limit of this process provides a complete labelling ùúå of ùë°'s nodes with
automaton states. This forms a run of A on ùë°, and the run starts in A's initial
state.
It therefore just remains to be seen that it is accepting. Very much as in the
other direction of the proof above, every path in ùúå corresponds to a play
conforming to ùúé0. Since such plays are winning for player 0, and this can
only be determined by the priorities on the player-0 nodes (since the others
all have priority 0), the greatest priority seen infinitely often along any path
in ùúå is also even, and ùúå is therefore accepting.
‚óª
Without the assumption in the second half of this proof that ùúé0 is positional,
the construction of ùúå-labels of successor nodes in ùë° would simply have to
consult what ùúé0 prescribes not just in a position (ùëû, ùë£) but after playing
through a history (ùëû , ùë£
, ùë£
, . . . , ùë£
0

0), . . . , (ùëûùëõ
ùëõ ) (with appropriate player-1 nodes in between) where ùë£0
ùëõ
form a finite path from the root in ùë°.
An immediate consequence of determinacy of parity games (Thm. 12.12)
and Thm. 13.20 is the following.
Corollary 13.21
ùúî
Let A be an NPTA over some ranked alphabet Œ£ and ùë° ‚àà TŒ£ . Player 1 has a
positional winning strategy for the acceptance game GA,ùë° iff ùë° /
‚àà ùêø(A) .
13.2 Complementation Closure
351
13.2.2 The Complementation Construction
We will make use of Cor. 13.21 to construct, given an NPTA A, an NPTA A
that accepts the complement of A's language. The underlying idea is the
following.
1. A (positional) winning strategy for player 1 in the acceptance game for A
and some tree ùë°, witnessing the fact that ùë° /
‚àà ùêø(A), can be regarded as a labelling of
ùë° 's nodes over an extended, yet finite alphabet.
2. The language of guided traces of such annotated trees is ùúî-regular, hence
recognisable by a deterministic parity word automaton. This can be turned

into a deterministic parity tree automaton recognising the language of trees
annotated in this way.
3. A simple projection construction yields the language of trees on which
player 1
has a winning strategy for the corresponding acceptance game, i.e. ùêø(A).
For the remainder of this section, we fix an NPTA A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) and carry
out the complementation construction with respect to A. Likewise, this fixes
the underlying alphabet Œ£. Let ùëö ‚à∂= max{ rk Œ£(ùëé) ‚à£ ùëé ‚àà Œ£} and ùê∑ ‚à∂= [ùëö ].
In order to grasp the intuition behind the construction of the complement
NPTA ùúî
A, it is helpful to imagine an arbitrary tree ùë° ‚àà TŒ£ to be given, in particular
one that satisfies ùë° /
‚àà ùêø(A), and then to consider the requirements on A in terms of the
acceptance game GA,ùë° .
According to Cor. 13.21, player 1 has a positional winning strategy ùúé1 for
GA,ùë° .
It tells player 1 which direction to move to in any situation when it is his
turn, i.e.
‚â§ùëö
in a position of the form ((ùëû , . . . , ùëû
, . . . , ùëû
0

ùëë‚àí1), ùë£) for some tuple (ùëû0
ùëë‚àí1) ‚àà ùëÑ
occurring in the image of the transition function ùõø, and some node ùë£ ‚àà
dom(ùë°). So
‚â§ùëö
ùúé1 can be seen as a function of type dom(ùë°) √ó ùëÑ
‚Üí ùê∑ . This can be reformulated
using the following observation - also known as (Un-)Currying - where ‚âÉ
is used to denote the existence of an isomorphism betw een function spaces.
Lemma 13.22 For all sets ùê¥, ùêµ, ùê∂ we have ùê¥ √ó ùêµ ‚Üí ùê∂ ‚âÉ ùê¥ ‚Üí (ùêµ ‚Üí ùê∂) .
‚â§ùëö
Now let S ‚à∂= ùëÑ
‚Üí ùê∑ . Using Lemma 13.22, ùúé1 can be seen as having type
dom(ùë°) ‚Üí S. Note that S is finite and independent of ùë°. In fact, it only
depends on A's state space and the underlying alphabet Œ£ .
ùúî
This opens up the possibility to construct an NPTA that, given an arbitrary ùë°
‚àà TŒ£ , checks whether ùë° /
‚àà ùêø(A) by guessing an element from S at every node in ùë°, and
verifying that the consecutive guesses comprise a winning strategy for
player 1.
In order to do so, we construct a new ranked alphabet Œ£ √ó S where rk Œ£√óS
(ùëé, ùëÜ) ‚à∂=

rk Œ£(ùëé) for all ùëé ‚àà Œ£ and ùëÜ ‚àà S. We will use the projection functions proj ,
1 proj 2
defined b y
proj (ùëé, ùëÜ) ‚à∂= ùëé
(ùëé, ùëÜ)
‚à∂=
ùúé
1
and
proj 2
ùúî
and the former's extension as a rank-preserving homomorphism ÃÇ
proj
‚à∂ T
‚Üí
1
Œ£√óS
ùúî
TŒ£
on trees as well as its natural extension to tree languages. This allows us to
characterise non-membership of a tree ùë° in the language of the NPTA A by

the existence of a labelling on that tree that represents such a winning
strategy for player
352
13 Automata on Infinite Trees
1. Equivalently, it is characterised by the existence of a pre-image with this
property under the homomorphism ÃÇ
proj 1. The next observation follows immediately from
Cor. 13.21 and Lemma 13.22.
Lemma 13.23
ùúî
‚Ä≤
ùúî
Let ùë° ‚àà TŒ£ . We have ùë° /
‚àà ùêø(A) iff there is a tree ùë° ‚àà TŒ£
such t hat
√óS
‚Ä≤
(i) 
proj (ùë° ) = ùë°
1
and

‚â§ùëö
(ii) the function ùúé1 ‚à∂ ùëÑ
√ó dom(ùë°) ‚Üí ùê∑ , defined by
‚Ä≤
ùúé1(q, ùë£) ‚à∂= proj (ùë° (ùë£))(q )
2
is a positional winning strategy for player 1 in the acceptance game GA,ùë° .
‚Ä≤
‚Ä≤
ùúî
Now let ùêø
be the set of all trees ùë°
‚àà TŒ£
that satisfy condition (ii) in
√óS
Lemma 13.23, i.e. the set of all trees extending a tree ùë° over Œ£ by node
labels that conjunctively represent a positional winning strategy for player
1 in the acceptance game for A and ùë°. This gives us a simple
characterisation of the complement of A's languag e.
Lemma 13.24
ùúî

‚Ä≤
We have TŒ£ ‚àñ ùêø(A) = ÃÇ
proj (ùêø )
1
.
This follows immediately from Lemma 13.23. The more important point to
make ùúî
here, though, is that this lemma reduces the construction of an NPTA for TŒ£
to
‚Ä≤
an NPTA for ùêø . According to Lemma 13.14, NPTA-recognisability is
preserved
‚Ä≤
by rank-preserving homomorphisms. Hence, if ùêø is NPTA-recognisable then
so is ùúî
TŒ£ ‚àñ ùêø(A).
So we need to study the possibility to construct an NPTA over Œ£ √ó S that
checks condition (ii) from Lemma 13.23. In order to do so, we need to
analyse what makes
‚â§ùëö
a labelling of nodes in a tree ùë° with elements of S = ùëÑ
‚Üí ùê∑ a winning strategy

for player 1. Note that an element ùëÜ ‚àà S can essentially be seen as a table
telling player 1 how to react to a previous move by player 0 in the
acceptance game GA,ùë° , when the automaton token was on a state ùëû and the
tree token is on a node ùë£, and player 0 has chosen some (ùëû , . . . , ùëû
0
ùëë‚àí1) ‚àà ùõø(ùëû, ùë£). More specifically, ùëÜ can be seen
as telling player 1 which direction to choose in each case that player 0
chooses some state tuple q. We therefore also call such an ùëÜ ‚àà S a local
strategy profile .
When actually playing the game, player 1 would therefore make the choice
prescribed by this strategy, i.e. choose to continue the play in the direction
ùëÜ(q). This has a particular consequence regarding the view onto ùë° with
local strategy profiles ùëÜ
ùúî
as additional node labels. Take some node ùë£ ‚àà dom(ùë°) for some tree ùë° ‚àà TŒ£
, and a local strategy profile ùëÜ. Suppose that player 0 has chosen some
state tuple q. Then ùëÜ(q) determines a direction in which player 1 - the
Pathfinder - wants the play to pursue. Say rk Œ£(ùë°(ùë£)) = ùëë for some ùëë ‚àà N,
so we can assume 0 ‚â§ ùëÜ(q) < ùëë. Node ùë£
has ùëë children ùë£0, . . . , ùë£(ùëë ‚àí 1), with local strategy profiles ùëÜ , . . . , ùëÜ
0
ùëë‚àí1 associated
with them, for instance as explicit labels. Only one of them is interesting for
player 1, namely ùëÜùëñ for ùëñ = ùëÜ(q). By choosing direction ùëñ - more precisely
by following the choice ùëñ that is prescribed by his strategy - the ùëñ-th state ùëûùëñ
in q is selected, and in the next round player 0 continues with a choice of
another tuple q‚Ä≤ ‚àà ùõø(ùëû , ùë°

ùëñ
(ùë£ùëñ)).
13.2 Complementation Closure
353
‚Ä≤
In the end, we need to construct an NPTA over Œ£ √ó S for the language ùêø . In
ùúî
order to do so we take a path-based view onto trees in TŒ£
. Remember that we can
√óS
construct tree languages from languages of guided traces, i.e. infinite words
over an alphabet that extends the (unranked version of the) tree alphabet
with directions.
‚Ä≤
Hence, a natural candidate for describing trees in ùêø via guided traces is Œ£
√ó S √ó ùê∑.
Consider the condition laid out in the following lemma that determines
whether a
‚Ä≤
guided trace over this alphabet is part of a tree in ùêø . It follows immediately
from Lemma 13.23 as it only reformulates that statement from a point of
view onto guided traces.
Lemma 13.25

‚Ä≤
ùúî
Let ùë° ‚àà T
, ùëÜ , ùëë
, ùëÜ , ùëë
Œ£
‚àñ ùêø(A) . A ùúå = (ùëé
√óS
0
0
0), (ùëé1
1
1), . . . ‚àà (Œ£ √ó S √ó
ùúî
‚Ä≤
ùúî
ùê∑ )
is a guided trace of ùë° iff for all sequences ùëû , ùëû , . . .
, q , . . .
0

1
‚àà ùëÑ
and q0
1
‚àà
‚â§ùëö
ùúî
(ùëÑ
)
the following holds. If
(i) ùëû0 = ùëûùêº and
(ii) for all ùëñ ‚â• 1 we have ùëû
, . . . , ùëù
ùëñ
= ùëùùëë where ùëë = ùëÜùëñ‚àí1(qùëñ‚àí1) and qi‚àí1 = (ùëù0
ùëü ) ‚àà
ùõø(ùëû
, ùëé
ùëñ‚àí1
ùëñ‚àí1) for some ùëü < ùëö ,

then
(iii) lim sup
Œ©(ùëû
ùëñ‚Üí‚àû
ùëñ ) is odd.
At this point, the proof of complementability of an NPTA-recognisable
language is essentially finished because conditions (i)-(iii) in Lemma 13.25
are easily seen to
‚Ä≤
be MSO-definable. Thus, the set of guided traces of trees in ùêø is ùúî-regular,
and we can build a DPA recognising it which can be used to build a parity
tree automaton
‚Ä≤
for ùêø , even a deterministic one. Using homomorphism closure we also
obtain an NPTA for ùê¥.
This approach has one disadvantage, though. Writing down condition (ii)
from Lemma 13.25 in MSO results in a formula of exponential size as it has
to address all
‚â§ùëö
O(1)
‚à£ùëÑ
‚à£
ùëõ

ùëÜ ‚àà S for instance, and ‚à£S‚à£ = ‚à£ùê∑‚à£
‚àà 2
since ‚à£ùê∑‚à£ and ùëö only depend on the
original alphabet Œ£. Determinisation introduces another exponential,
resulting in a doubly exponential complementation procedure for NPTA
only. A better complexity bound is obtained by constructing automata
checking the conditions in Lemma 13.25
directly. For this, we extend the underlying alphabet even further to Œî
‚â§ ùëö
‚à∂= Œ£ √ó S √ó ùê∑ √ó ùëÑ √ó ùëÑ
ùúî
so that a word in Œîùúî represents a guided trace of a tree in TŒ£
, together with two
√óS
infinite sequences, one of states, and the other of state tuples from A's
transition table. To see why this is advantageous, we reformulate Lemma
13.25 as follows, only using standard transformations between universal
and existential quantification, as well as between implications and
conjunctions involving negations.
Lemma 13.26
‚Ä≤
ùúî
Let ùë° ‚àà T

, ùëÜ , ùëë
, ùëÜ , ùëë
Œ£
‚àñ ùêø(A) . A ùúå = (ùëé
√óS
0
0
0), (ùëé1
1
1), . . . ‚àà (Œ£ √ó
ùúî
‚Ä≤
S √ó ùê∑ )
is a guided trace of ùë°
iff it is not the case that there are sequences
ùúî
‚â§ùëö
ùúî
ùëû
, ùëû

, . . .
, q , . . .
0
1
‚àà ùëÑ
and q0
1
‚àà (ùëÑ
)
such that
(i) ùëû0 = ùëûùêº and
354
13 Automata on Infinite Trees
(ii) for all ùëñ ‚â• 1 we have ùëû
, . . . , ùëù
ùëñ
= ùëùùëë where ùëë = ùëÜùëñ‚àí1(qùëñ‚àí1) and qi‚àí1 = (ùëù0
ùëü ) ‚àà
ùõø(ùëû
, ùëé

ùëñ‚àí1
ùëñ‚àí1) for some ùëü < ùëö , and
(iii) lim sup
Œ©(ùëû
ùëñ‚Üí‚àû
ùëñ ) is even.
Next we consider the possibility to recognise such words in Œîùúî by NPA.
Lemma 13.27 Let ùë§ = (ùëé , ùëÜ , ùëë , ùëû , q
, ùëÜ , ùëë , q
0
0
0
0
0), (ùëé1
1
1
1), . . . ‚àà Œî ùúî . There is a
a) DPA of size ùëò + 1 and index ùëò that accepts ùë§ iff ùëû
Œ©
0 = ùëû ùêº and lim sup

(ùëû
ùëñ‚Üí‚àû
ùëñ )
is even,
b) DcoBA of size ùëõ that accepts ùë§ iff for all ùëñ ‚â• 1 we have ùëûùëñ = ùëùùëë where ùëë
=
ùëÜ
, . . . , ùëù
, ùëé
ùëñ‚àí1(qùëñ‚àí1) and qi‚àí1 = ( ùëù0
ùëü ) ‚àà ùõø(ùëû ùëñ‚àí1
ùëñ‚àí1) for some ùëü < ùëö .
Proof (a) The DPA contains one state ùëù of priority ùëù itself, for each priority
occurring in A. It deterministically moves to state Œ©(ùëû) upon reading any
symbol (ùëé, ùëÜ, ùëë, ùëû, q) ‚àà Œî. One additional state is needed to check that the
first alphabet symbol contains the initial state ùëûùêº in its fourth component.
(b) The DcoBA contains one state per ùëû ‚àà ùëÑ to remember the last state in
the state
‚Ä≤
sequence. It naturally starts with ùëû
, q
ùêº . Upon reading the alphabet symbol (ùëé, ùëÜ, ùëë , ùëû

)
‚Ä≤
‚Ä≤
in state ùëû it proceeds deterministically to state ùëû if q ‚àà ùõø(ùëû, ùëé) and ùëû is the ùëë-
th component of ùëÜ(q). Otherwise, it just stops. All states are accepting, i.e. it
only rejects a word by s topping.
‚óª
This allows us to formulate complementation closure for NPTA-
recognisable languages with an optimal singly exponential blowup only.
Theorem 13.28 Let A by an NPTA of size ùëõ and index ùëò . There is an NPTA
A of 2
O(ùëõùëò
ùúî
size at most 2
log ùëõùëò) and index O(ùëõùëò2) such that ùêø(A) = TŒ£ ‚àñ ùêø(A) .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) be an NPTA. The construction of an NPTA for the
complement language is outlined above in consecutive steps. With Lemma
13.27 we can construct a DPA of size ùëò + 1 and index ùëò , as well as a
DcoBA of size ùëõ such that the intersection of their languages is exactly the
set of all words ùë§ ‚àà Œîùúî that
‚Ä≤

represent a guided trace from ùêø , extended with sequences of states and
state tuples representing possible choices by player 0 in an acceptance
game on A, such that ùë§
satisfies conditions (i)-(iii) of Lemma 13.26.
According to Lemma 6.37, this intersection can be recognised by an NPA of
size O(ùëò ‚ãÖ ùëõ) and index ùëò + 1 and therefore by an NBA B of size O(ùëò 2 ‚ãÖ ùëõ).
Using the standard projection construction onto the alphabet Œ£ √ó S √ó ùê∑,
we obtain an NBA of
‚Ä≤
the same size that accepts a guided trace of a tree in ùêø iff there are
accompanying sequences of states and state tuples that extend it to a word
accepted by B. Using 2
2
2
O(ùëò ‚ãÖùëõ‚ãÖ
‚ãÖùëõ))
O(ùëõùëò
Cor. 7.26 we obtain an equivalent DPA of size 2
log(ùëò
= 2
log ùëõùëò) and
index O(ùëõùëò 2).
Complementation of DPA is possible without an additional blowup, cf. Thm.
6.11.

Hence we get a DPA of the same size and index that accepts exactly the
guided traces
‚Ä≤
of trees in the language ùêø , according to Lemma 13.26. With Lemma 13.17,
there is
‚ñ≥
‚Ä≤
a DPTA of the same size and index that recognises ùêø(B) , i.e. ùêø . Note that it
is a
13.2 Complementation Closure
355
‚â§ùëö
tree language over Œ£ √ó S where S = ùëÑ
‚Üí ùê∑ , and Lemma 13.24 establishes that its
homomorphic projection onto Œ£ is exactly ùêø(A). An NPTA for it can be
obtained using Lemma 13.14 which also does not incur any further blowup
in size or index. ‚óª
We carry out the complementation construction for a small example that is
not entirely trivial. Even this induces intermediate steps of significant
complexity to be done manually. We therefore simplify steps wherever
possible.
Example 13.29 Let Œ£ = {ùëé, ùëè} with rk Œ£(ùëé) = rk Œ£(ùëè) = 2. Consider the
language ùúî
ùêø

= {ùë° ‚àà TŒ£ ‚à£ there is a path in ùë° that contains only symbols ùëé} .
It is recognised by the NPTA A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
, ùëû
1
) where ùëÑ = {ùëûùëé
‚àó }, Œ©(ùëû ùëé ) =
0 = Œ©(ùëû‚àó) and
ùõø(ùëû , ùëé
, ùëû
, ùëû
ùëé
)
‚à∂= {(ùëû ùëé
‚àó ), (ùëû‚àó
ùëé )} ,
ùõø(ùëû , ùëè
ùëé
)
‚à∂= ‚àÖ ,
ùõø(ùëû , ùë•

, ùëû
‚àó
)
‚à∂= {(ùëû‚àó
‚àó )}
for all ùë• ‚àà Œ£ .
ùúî
The goal is to construct an NPTA recognising TŒ£ ‚àñ ùêø, i.e. those trees in
which every path contains at least one ùëè. It is of course an easy exercise to
construct an NPTA for this language directly, even an NBTA. However, we
will show that a methodological construction along the lines of the proof of
Thm. 13.28 will also arrive at a tree automaton for the complement of ùêø.
This is made easier in parts by the fact that A's acceptance condition is very
simple with a single priority only.
First note that there are three state pairs in the image of ùõø. Let Œ† ‚à∂= {(ùëû , ùëû
ùëé
‚àó ),
(ùëû , ùëû
, ùëû
‚àó
ùëé ), (ùëû ‚àó
‚àó )}. Hence, the set of local strategy profiles S could be seen as the finite
function space Œ† ‚Üí {0, 1} resulting in 8 local strategy profiles instead of 16

of type ùëÑ2 ‚Üí {0, 1}. However, not every state pair from Œ† occurs in ùõø(ùëû, ùë•)
for any ùëû ‚àà ùëÑ and ùë• ‚àà Œ£. So we can restrict our attention to the relevant
pairs, i.e. those choices in an acceptance game on A that are feasible in the
sense that they give a response for player 1 to any state pair that player 0
can choose but no response to state pairs that player 0 cannot choose. This
gives us a reduced set S ‚à∂= {ùëÜ0 , ùëÜ1 , ùëÜ00 , ùëÜ01 , ùëÜ10 , ùëÜ11 }
‚àó
‚àó
ùëé
ùëé
ùëé
ùëé
of 6 local s trategy profiles.
The naming convention is the following: the subscript index denotes the
state from which player 0 chooses a transition. There is only one choice in
state ùëû‚àó and two choices in state ùëûùëé. This gives two possibilities for player
1 to react in the former case - either go left or right - and four possibilities
to react in the latter case, encoded by directions ùëë ùëë
1
2 in the superscript meaning that the strategy tells player 1 to go into
direction ùëë1 in response to the first state pair and direction ùëë2 in response
to the second. Spelled out as partial functions they are as follows.
ùëÜ0
ùëÜ1
ùëÜ00

ùëÜ01
ùëÜ10
ùëÜ11
‚àó
‚àó
ùëé
ùëé
ùëé
ùëé
(ùëû , ùëû
, ùëû
, ùëû
, ùëû
, ùëû
, ùëû
‚àó
‚àó ) 0
(ùëû‚àó
‚àó ) 1
(ùëû ùëé

‚àó ) 0
(ùëû ùëé
‚àó ) 0
(ùëû ùëé
‚àó ) 1
(ùëû ùëé
‚àó ) 1
(ùëû , ùëû
, ùëû
, ùëû
, ùëû
‚àó
ùëé ) 0
(ùëû‚àó
ùëé ) 1
(ùëû‚àó
ùëé ) 0
(ùëû‚àó
ùëé ) 1
Next we need to construct an NPA over the alphabet

356
13 Automata on Infinite Trees
‚Ä≤
‚Ä≤
ùëá
‚à™ ùëá
Œ£ √ó S √ó {
ùëá
ùëá
‚àó
0, 1}
ùëé
‚àó
ùëé
ùëá‚àó
‚Ä≤
‚Ä≤
‚Ä≤
ùëá
‚àñ (ùëá ‚à™ ùëá

ùëé
‚àó)
ùëá
0
1
ùëé
Œî ‚àñ (ùëá ‚à™ ùëá
Œî ‚àñ (ùëá ‚à™ ùëá
ùëé
‚àó)
ùëé
‚àó)
Œî
Fig. 13.2 Word automata used in the complementation construction in Ex.
13.29, with the right one obtained from the left one by projection,
determinisation and complementation.
Œî ‚à∂= Œ£ √ó S √ó {0, 1} √ó ùëÑ √ó Œ†
that recognises words satisfying the conditions (i)-(iii) of Lemma 13.26.
According to Lemma 13.27 this can be done modularly by constructing a
DPA that checks conditions (i) and (iii) and then intersecting it with a
DcoBA that checks condition (ii).
The DPA for condition (iii) in this case is trivial: it only has a single state
with priority 0 and a transition looping on this state with any symbol from

Œî. The reason is that it only checks that the states in the third components of
all symbols in a word over Œî satisfy the parity condition, but the priorities
of all states are 0 anyway and so condition (iii) boils down to the universal
language.
Hence, it suffices to construct an automaton checking conditions (i) and (ii).
The DcoBA B shown on the left in Fig. 13.2 does this. Note that ‚à£Œî‚à£ = 144,
so spelling out all transition labels is already infeasible in this small
example. The important
‚Ä≤
ones are those tuples (ùë•, ùëÜ, ùëë, ùëû, (ùëû , ùëû
, ùëû
, ùë•
0
1)) for which we have (ùëû1
2) ‚àà ùõø(ùëû
) for
‚Ä≤
some ùëû and ùëû = ùëûùëÜ(ùëû ,ùëû
0
1 ) . This is satisfied by the follo wing 20 tuples.
(ùëé, ùëÜ00 ,
, (ùëû , ùëû
,

, (ùëû , ùëû
ùëé
0, ùëûùëé
ùëé
‚àó )),
(ùëé, ùëÜ10
ùëé
0, ùëû‚àó
ùëé
‚àó )),
(ùëé, ùëÜ00 ,
, (ùëû , ùëû
,
, (ùëû , ùëû
ùëé
1, ùëûùëé
ùëé
‚àó )),
(ùëé, ùëÜ10
ùëé

1, ùëû‚àó
ùëé
‚àó )),
(ùëé, ùëÜ00 ,
, (ùëû , ùëû
,
, (ùëû , ùëû
ùëé
0, ùëû‚àó
ùëé
‚àó )),
(ùëé, ùëÜ10
ùëé
0, ùëû‚àó
ùëé
‚àó )),
(ùëé, ùëÜ00 ,
, (ùëû , ùëû
,
, (ùëû , ùëû

ùëé
1, ùëû‚àó
ùëé
‚àó )),
(ùëé, ùëÜ10
ùëé
1, ùëû‚àó
ùëé
‚àó )),
ùëáùëé
(ùëé, ùëÜ01 ,
, (ùëû , ùëû
,
, (ùëû , ùëû
ùëé
0, ùëûùëé
ùëé
‚àó )),
(ùëé, ùëÜ11
ùëé

0, ùëû‚àó
ùëé
‚àó )),
(ùëé, ùëÜ01 ,
, (ùëû , ùëû
,
, (ùëû , ùëû
ùëé
1, ùëûùëé
ùëé
‚àó )),
(ùëé, ùëÜ11
ùëé
1, ùëû‚àó
ùëé
‚àó )),
(ùëé, ùëÜ01 ,
, (ùëû , ùëû
,
, (ùëû , ùëû

ùëé
0, ùëûùëé
ùëé
‚àó )),
(ùëé, ùëÜ11
ùëé
0, ùëûùëé
ùëé
‚àó )),
(ùëé, ùëÜ01 ,
, (ùëû , ùëû
,
, (ùëû , ùëû
ùëé
1, ùëûùëé
ùëé
‚àó )),
(ùëé, ùëÜ11
ùëé
1, ùëûùëé

ùëé
‚àó )),
(ùëè, ùëÜ0 ,
, (ùëû , ùëû
,
, (ùëû , ùëû
‚àó
0, ùëû‚àó
‚àó
‚àó )),
(ùëè, ùëÜ1
‚àó
0, ùëû‚àó
‚àó
‚àó )),
ùëá‚àó
(ùëè, ùëÜ0 ,
, (ùëû , ùëû
,
, (ùëû , ùëû

‚àó
1, ùëû‚àó
‚àó
‚àó )),
(ùëè, ùëÜ1
‚àó
1, ùëû‚àó
‚àó
‚àó ))
Next we need to project its language onto Œ£ √ó S √ó {0, 1} and then construct
a DPA
‚Ä≤
for it. The projection introduces nondeterminism in general. Let ùëá
‚à∂= {(ùë•, ùëÜ, ùëë) ‚à£
ùëé
13.2 Complementation Closure
357
‚Ä≤
‚àÉùëû, ùëû , ùëû
, ùëû

0
1 s.t. (ùë•, ùëÜ, ùëë, ùëû, (ùëû0
1)) ‚àà ùëáùëé } and likewise for ùëá‚àó. This is unproblematic
‚Ä≤
‚Ä≤
because ùëá ‚à© ùëá
= ‚àÖ
ùëé
‚àó
. Hence, this particular projection preserves the determinism
between the two accepting states in B. However, projecting the labels from
Œî ‚àñ (ùëáùëé ‚à™
‚Ä≤
‚Ä≤
‚Ä≤
ùëá‚àó) yields triples that are also included in ùëá
‚à∂= {(ùë•, ùëÜ, ùëë) ‚à£
ùëé or ùëá‚àó . To be precise, let ùëá
‚àÉùëû, ùëû , ùëû
, ùëû

0
1 s.t. (ùë•, ùëÜ, ùëë, ùëû, (ùëû0
1)) /
‚àà ùëáùëé ‚à™ ùëá‚àó}. Then we ha ve
‚Ä≤
00
01
10
11
ùëá
‚à∂= {ùëé} √ó {ùëÜ
, ùëÜ
, ùëÜ
, ùëÜ
} √ó {
ùëé
ùëé
ùëé
ùëé
ùëé

0, 1}
‚Ä≤
0
1
ùëá
‚à∂= {ùëè} √ó {ùëÜ , ùëÜ } √ó {
‚àó
‚àó
‚àó
0, 1}
‚Ä≤
0
1
00
01
10
11
‚Ä≤
‚Ä≤
ùëá

‚à∂= {ùëé} √ó {ùëÜ , ùëÜ } √ó {
, ùëÜ
, ùëÜ
, ùëÜ
} √ó {
‚à™ ùëá
‚àó
‚àó
0, 1} ‚à™ {ùëè} √ó {ùëÜùëé
ùëé
ùëé
ùëé
0, 1} ‚à™ ùëáùëé
‚àó
so the overlap between the projected transitions in B is very pristine: any
transition from an accepting state to an accepting state can also be taken to
the non-accepting state. A small deterministic automaton for the
complement of B's language after projection is then obtained by
observation of two facts: (i) the two accepting states recognise the same
language and can be merged; (ii) moving to the non-accepting state is
never helpful since it is a trap. Hence, determinism can be achieved simply
by deleting those transitions into the non-accepting state whose label can
also lead to an accepting one. Since the automaton (after projection and
removal of useless transitions) is deterministic and weak, it can easily be

complemented by swapping the status of accepting and non-accepting
states. The resulting DPA ùêµ is shown in Fig. 13.2 on the right. Note that it
is in fact already a DcoBA.
Next we interpret its language as a set of guided traces in trees over Œ£ √ó S
and
‚ñ≥
construct a DPTA recognising ùêø(B)
according to Lemma 13.17. Its complete
transition table has 2 ‚ãÖ 2 ‚ãÖ 6 = 24 entries - one for each combination of a
state in B
and an alphabet symbol from Œ£ √ó S - but many transitions lead to the same
target, so it can be presented succinctly as
‚Ä≤
‚Ä≤
‚Ä≤
ùõø (0, (ùëé, ùëÜ)) = (0, 0) ,
ùõø (0, (ùëè, ùëÜ)) = (1, 1) ,
ùõø (1, (ùëè, ùëÜ)) = (1, 1)
for any ùëÜ ‚àà S in all cases. The acceptance condition is inherited from B,
here just a co-B √ºchi condition with 1 as the only accepting state.
At last, we obtain the desired complemented NPTA A by a final projection
onto the alphabet Œ£ which is particularly easy in this case, leading to the
tree automaton
‚Ä≤‚Ä≤

A ‚à∂= ({0, 1}, Œ£, 0, ùõø , Œ©‚Ä≤) where
‚Ä≤‚Ä≤
‚Ä≤
‚Ä≤
ùõø
(0, ùëé) = (0, 0) ,
ùõø (0, ùëè) = (1, 1) ,
ùõø (1, ùëè) = (1, 1)
ùúî
and Œ©‚Ä≤(0) = 1, Œ©‚Ä≤(1) = 0. It should be clear that ùêø(A) = TŒ£ ‚àñ ùêø(A).
358
13 Automata on Infinite Trees
13.3 Decision Problems
In order to use NPTA for logical decision problems we need to study
decidability and complexity of the corresponding decision problems on the
automata side, in particular the (non-)emptiness problem.
13.3.1 Non-Emptiness via Parity Games
Non-emptiness turns out to be decidable, using essentially the same
techniques as those employed for automata on infinite words. First, for non-
emptiness the exact labelling of a tree in the automaton's language with
alphabet symbols is irrelevant. Second, finiteness of the automaton's state
space and the nature of the parity acceptance condition guarantee the
existence of finitely representable trees in each non-empty language of an
NPTA.

Independence on the exact alphabet symbols is shown using a
transformation into an NPTA whose transitions do not depend on the
symbol read in one step. This essentially amounts to the use of
homomorphism closure for a morphism that maps all symbols of the
underlying alphabet to a single one. While this is very easily done for word
automata, it requires a little bit more technical care for tree automata
because such a homomorphism would generally not be rank-preserving.
Definition 13.30 Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) be an NPTA and ùëö ‚à∂= max{ rk Œ£(ùëé) ‚à£ ùëé ‚àà
Œ£}. Let Œ£‚àí ‚à∂= {ùëé} for some alphabet symbol ùëé ‚àà Œ£ such that rk Œ£(ùëé) = ùëö.
By finiteness of Œ£, such an ùëé exists.
‚àí
‚àí
Define an NPTA A as (ùëÑ, Œ£‚àí, ùëû , ùõø , Œ©
ùêº
) where
‚àí
ùõø
(ùëû, ùëé) = {(ùëû , . . . , ùëû
, . . . , ùëû
0
ùëë‚àí1

ùëë‚àí1) ‚à£ ‚àÉùëè ‚àà Œ£, rk Œ£ (ùëè) = ùëë and
¬¥¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∏¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π
¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬π¬∂
ùëö
(ùëû , . . . , ùëû
0
ùëë‚àí1) ‚àà ùõø(ùëû , ùëè)}
for all ùëû ‚àà ùëÑ .
‚àí
Intuitively, A recognises a tree ùë° iff it is possible to relabel and reduce it to a
tree recognised by A by removing subtrees in order to adjust the ranks for
the original symbols in Œ£. The exact construction is given in the proof of the
following lemma,
‚àí
making the statement of A 's language formal.
Lemma 13.31
‚àí
Let A be an NPTA over some alphabet Œ£ and A be the NPTA
‚àí
obtained from it according to Def. 13.30. We have ùêø(A) ‚â† ‚àÖ iff ùêø(A ) ‚â† ‚àÖ .
Proof
‚àí

Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
), Œ£‚àí = {ùëé} be the singleton alphabet underlying A ,
and ùëö the maximal rank of a symbol in Œ£.
ùúî
‚Ä≤
"‚áí" Suppose ùë° ‚àà ùêø(A) for some ùë° ‚àà TŒ£ . Let ùë° be the complete ùëö-
branching tree
‚Ä≤
‚àó
‚Ä≤
‚àí
with ùë° (ùë£) = ùëé for all ùë£ ‚àà [ùëö] . We claim that ùë° ‚àà ùêø(A ). This is seen most
easily
‚Ä≤
by realising that ùë° can be obtained from ùë° by
13.3 Decision Problems
359
‚Ä¢ changing the label at every node to ùëé, and
‚Ä¢ successively, in a top-down way starting with the root level, adding copies
of the right-most subtree under each node for as long as it has less than ùëö
children.

Note that this corresponds exactly to the construction on the transition
function in
‚Ä≤
Def. 13.30. Thus, an accepting run ùúå on ùë° can be turned into an accepting
run ùúå on
‚Ä≤
ùë°
via
‚éß
‚é™
‚Ä≤
‚Ä≤
‚é™ùúå(ùë£ )
,
‚àà
‚Ä≤
‚Ä≤
if ùë£
dom(ùë°),
ùúå (ùë£ )
‚à∂= ‚é®

‚é™
‚Ä≤
‚é™ùúå(ùë£)
, otherwise where ùë£ resulted as a copy of ùë£ ‚àà dom (ùë°)
‚é©
‚Ä≤
‚àó
for any ùë£ ‚àà [ùëö] . The crucial insight here is that any path ùëû , ùëû , . . .
0
1
through the
‚Ä≤
run ùúå is also a path through the run ùúå. Since that is an accepting one, the
greatest
‚Ä≤
priority seen infinitely often on all such paths is even, and so ùúå is also
accepting.
‚Ä≤
‚àí
"‚áê" Suppose that ùë° ‚àà ùêø(A ). Since the underlying alphabet Œ£‚àí is a
singleton,

‚Ä≤
ùë°
is even unique, namely it is the ùëö-branching tree with all nodes labelled ùëé,
as the
‚Ä≤
‚àí
‚Ä≤
previous part of the proof noted. Let ùúå be an accepting run of A on ùë° . We
can
turn this successively - again in a level-by-level way starting at the root -
into a tree ùúî
ùë° ‚àà TŒ£ with an accepting run ùúå of A on it.
‚Ä≤
‚Ä≤
Take a node ùë£ ‚àà dom(ùë° ) on the currently considered level of ùë° , i.e. the root
node
‚Ä≤
at the very beginning of this process. Let ùúå (ùë£) = ùëû for some ùëû ‚àà ùëÑ. So there is
some
‚Ä≤
‚Ä≤
(ùëû , . . . , ùëû

0
ùëö‚àí1) ‚àà ùõø (ùëû, ùëé) such that ùúå (ùë£ùëñ) = ùëûùëñ for ùëñ ‚àà [ùëö]. By the construction of
‚àí
A , there is some ùëè ‚àà Œ£ such that (ùëû , . . . , ùëû
0
ùëë‚àí1) ‚àà ùõø(ùëû, ùëè) where ùëë = rk Œ£ (ùëè), and
‚Ä≤
ùëû ùëó = ùëûùëë‚àí1 for all ùëó = ùëë, . . . , ùëö ‚àí1. Then remove all nodes ùë£ ùëó for ùëó > ùëë
from ùë° , change the label at ùë£ to ùëè, and continue the process with all
(finitely many) remaining nodes on the same level as ùë£, resp. the next lev el
when level ‚à£ùë£‚à£ is completed.
‚Ä≤
This turns ùë° consecutively into the desired tree ùë°. The run ùúå on it is simply
given
‚Ä≤
‚Ä≤
as the restriction of ùúå to dom(ùë°). Hence, every path in ùúå is also a path in ùúå ,
and so ùúå is accepting.
‚óª
Lemma 13.31 does not only remove the distinction between different
alphabet symbols in a non-emptiness check, it reduces non-emptiness to the
membership problem for a fixed tree ùë°ùëé, namely the full ùëö-branching tree
with uniform node labels where ùëö depends only on the original alphabet.
This is a simple consequence

‚àí
of the fact that the language of such an NPTA A is either ‚àÖ or {ùë°ùëé}, since
no other trees over the underlying alphabet Œ£‚àí exist.
This immediately opens up the route for a decision procedure for non-
emptiness: according to Thm. 13.20, membership of a given tree in the
language of an NPTA can be expressed in terms of a parity game. This,
together with Lemma 13.31 therefore yields the following characterisation
of NPTA non-emptiness.
Corollary 13.32 Let A be an NPTA over some alphabet Œ£ , ùëö the maximal
rank in Œ£
‚àí
, A the reduct of A according to Def. 13.30 and ùë°ùëé the full ùëö -branching
tree over
‚àí
the alphabet of A . Then ùêø(A) ‚â† ‚àÖ iff player 0 wins the acceptance game
GA‚àí,ùë° .
ùëé
While finite parity games can be solved algorithmically, Thm. 13.20 only
yields infinite parity games in general. The reason, though, lies solely in the
underlying
360
13 Automata on Infinite Trees
tree, and here the fixed tree ùë°ùëé obviously has a very small finite
representation. This is enough to bound the size of the acceptance game
GA‚àí,ùë° as a finite one and obtain ùëé

decidability of the non-emptiness problem for NPTA.
Theorem 13.33 The non-emptiness problem for NPTA with ùëõ states, ùëí
edges and ùëò
ùëò +
priorities can be solved in time O(ùëí
2) for any fixed underlying alphabet, provided
that ùëõ ‚â§ ùëí .
Proof Let A = (ùëÑ, Œ£, ùëû , ùõø, Œ©
ùêº
) be given, and ùëö ‚à∂= max{ rk Œ£(ùëé) ‚à£ ùëé ‚àà Œ£}, ùëõ = ‚à£ùëÑ‚à£,
ùëò = ‚à£{Œ©(ùëû) ‚à£ ùëû ‚àà ùëÑ}‚à£, and ùëí = ‚à£ùõø‚à£ ‚ãÖ ùëö. According to Cor. 13.32 it suffices
to analyse
‚àí
‚Ä≤
the size of G
, ùõø , Œ©
A‚àí ,ùë°
where A
= (ùëÑ, {ùëé}, ùëû ùêº
) is the singleton-alphabet NPTA
ùëé

‚àí
resulting from A according to Def. 13.30. In particular, A agrees with A in
terms of number of states, transitions and their index.
‚Ä≤
The crucial insight now is the existence of a finite parity game G that is
equivalent to the infinite acceptance game GA‚àí,ùë°
because of a one-to-one correspondence
ùëé
between the plays in the two games, and a matching between their nodes
that respects
‚Ä≤
the ownership and the priorities. We define G as (ùëâ , ùëâ , ùëâ , ùë£ , ùê∏ , Œ©‚Ä≤
0
1
ùêº
) where
‚Ä¢
‚Ä≤
ùëâ
‚à∂= ùëÑ, ùëâ ‚à∂= { q ‚à£ ‚àÉùëû ‚àà ùëÑ s.t. q
0

1
‚àà ùõø (ùëû, ùëé)}, ùëâ ‚à∂= ùëâ 0 ‚à™ ùëâ 1
ùêº
ùêº
as usual, and ùë£ = ùëû ,
‚Ä¢
‚Ä≤
ùê∏ = {(ùëû, q) ‚à£ ùëû ‚àà ùëÑ, q ‚àà ùõø (ùëû, ùëé)} ‚à™ {((ùëû , . . . , ùëû
1
ùëö ), ùëû ùëñ ) ‚à£ ùëñ ‚àà {1, . . . , ùëö}},
‚Ä≤
‚Ä≤
‚Ä¢ Œ© (ùëû) = Œ©(ùëû) for ùëû ‚àà ùëâ0 and Œ© (q) = 0 for q ‚àà ùëâ1.
‚Ä≤
A winning strategy for player 0 in G then immediately carries over to a
winning strategy for player 0 in GA‚àí,ùë° , even a positional one, such that
node ùëû is won by ùëé
‚Ä≤
‚àó
player 0 in G iff node (ùëû, ùë£) is won by player 0 in GA‚àí,ùë° for arbitrary ùë£ ‚àà
[ùëö] . In ùëé

particular, player 0 either wins the initial nodes of both games or none of
them.
A winning strategy for player 0 in GA‚àí,ùë° does not immediately carry over
to a ùëé
‚Ä≤
winning strategy for player 0 in G , not even when it is positional. The
reason is that a positional strategy in GA‚àí,ùë° may technically predict
different choices in nodes of ùëé
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
the form (ùëû, ùë£) and (ùëû, ùë£ ) for ùë£, ùë£ ‚àà dom(ùë°ùëé) with ùë£ ‚â† ùë£ , but G treats ùë£
and ùë£ as the same because the subtrees under both of them are isomorphic.
In other words: ùë°ùëé
‚Ä≤
has a finite representation using a single tree node only, and G is
constructed as the
‚àí
product of the NPTA A , not with the infinite tree ùë°ùëé itself but with its single-
node representation.
However, determinacy of parity games (Thm. 12.12) comes in handy here:
instead

‚Ä≤
of transforming a winning strategy for player 0 in GA‚àí,ùë°
into one for her in G it
ùëé
‚Ä≤
suffices to argue that the existence of a winning strategy for player 1 in G
implies the existence of one for him in GA‚àí,ùë° . This is done in exactly the
same way as for ùëé
player 0.
Thus, in order to check A for non-emptiness it suffices to solve the parity
game G with (ùëõ + ùëí) nodes, ùëò priorities and at most ùëõ ‚ãÖ ùëö ‚ãÖ ùëí edges,
which can be done - cf.
ùëò
ùëò +
Thm. 12.16 - in time O(ùëõùëöùëí(ùëõ + ùëí) ) = O(ùëí
2) since ùëö is constant and we can
assume w.l.o.g. that ùëõ ‚â§ ùëí.
‚óª
13.3 Decision Problems
361
13.3.2 Complexity, Expressiveness and Consequences

Recall that non-emptiness for automata on finite words is a simple
reachability problem that can be solved in non-deterministic logarithmic
space, and this is still true when considering infinite words and their
automaton models like B √ºchi and parity automata. For trees, the situation
is slightly different. Non-emptiness for languages of finite trees can be
checked in polynomial time, but the step to infinite trees probably incurs
higher complexity: so far, it is only known to be polynomially solvable for
NPTA with a bounded number of priorities, for instance for B √ºchi tree
automata. This immediately raises the question after a fixed bound ùëò on the
number of priorities such that NPTA of index ùëò accept all regular
languages of infinite trees.
This is not the case, as the following theorem states. A proof would require
a few more technical developments and is not presented here.
Theorem 13.34 Let Œ£ be an arbitrary alphabet such that ‚à£Œ£‚à£ ‚â• 2 . For
every ùëò ‚â• 1
‚Ä≤
ùúî
‚Ä≤
there is some ùëò ‚â• ùëò and an ùêø ‚äÜ TŒ£ that is recognisable by an NPTA of
index ùëò but not recognisable by any NPTA of index ùëò .
One may think that it is the inherent refusal of parity games to admit a
polynomial-time algorithm because of which one should attempt to find a
direct solution for the non-emptiness problem for NPTA instead. This does
not make things easier, though.
A polynomial-time algorithm for NPTA emptiness would imply a
polynomial-time algorithm for solving parity games. The proof is left as an
exercise.
An immediate consequence of the combination of decidability of non-
emptiness (Thm. 13.33) and the effective closure under complements (Thm.

13.28) is the decidability of the other standard decision problems
associated with types of automata.
Corollary 13.35 The universality, subsumption and equivalence problems
for NPTA are solvable in exponential time.
13.3.3 Finitely Representable Trees
Often one is not only interested in the answer to the question of non-
emptiness of the language of a given tree automaton, but additionally needs
to have a witness in terms of some tree in the language in case that it is
non-empty. This is the natural extension of the decision problem to a
computation problem, and such witnesses play an important role in
applications in program verification for instance, where such a tree may
encode the part of the set of runs of a program that violates some
correctness specification.
Trees are infinite objects in this setting, and one cannot expect an arbitrary
infinite tree to be constructible in finite time. So it is not immediately clear
that the decidable decision problem of non-emptiness gives rise to a
computable computation problem.
It hinges on the fact that every non-empty language that is recognised by an
NPTA
362
13 Automata on Infinite Trees
contains a tree that can be finitely represented. This also merits the use of
the term
"regular" for languages recognised by NPTA.
Note that this is comparable to the corresponding problem for automata on
infinite words. By B √ºchi's Theorem, every non-empty ùúî-regular language
over an alphabet Œ£
ùúî

contains a word of the form ùë¢ùë£
for some ùë¢ ‚àà Œ£‚àó, ùë£ ‚àà Œ£+. The only difference is
the lack (so far) of a language like ùúî-regular expressions which provides a
formal notion of finite representability for infinite trees.
Definition 13.36
ùúî
Let Œ£ be a ranked alphabet. A tree ùë° ‚àà TŒ£ is called finitely representable if
it contains only finitely many mutually non-isomorphic subtrees. The size of
ùë° is the number of such subtrees.
A natural representation of a tree is a system of equations
ùë°
, . . . , ùë°
1
= ùëé1(ùë°ùëñ
ùëñ
)
1,1
1, ùúé(ùëé )
1
‚ãÆ
ùë°

, . . . , ùë°
ùëõ
= ùëéùëõ(ùë°ùëñ
ùëñ
)
ùëõ,1
ùëõ, ùúé (ùëéùëõ )
ùúî
over variables ùë° , . . . , ùë°
1
ùëõ for trees in TŒ£ , and each right-hand side being a term of the form ùëé(ùë° , . .
. , ùë°
1
ùëë ) with ùëë = rk Œ£ (ùëé). It represents a tree whose root node is labelled ùëé
and whose ùëë children are, successively, the trees represented by the right-
hand sides of the equations for ùë° , . . . , ùë°
1
ùëë .
In fact, every infinite tree is represented by an infinite system of such
equations with one equation for each node in the tree. Here we restrict our
attention to finite systems of equations which can be seen as several nodes
in the tree sharing the same description, i.e. the subtrees rooted at these

nodes being isomorphic. Thus, finite systems of ùëõ equations represent
exactly the finitely representable trees of size ùëõ.
Example 13.37 The tree ùë°ùëé used in the proof of Thm. 13.33 - the full tree of
branching degree ùëö for some ùëö with all nodes labelled ùëé for some symbol
ùëé -
is finitely representable and of size 1. It contains exactly one isomorphism
class of subtrees, namely ùë°ùëé itself, since the subtrees at the children of its
root are all isomorphic to ùë°
, . . . , ùë°
ùëé . It is therefore represented by the equation system ùë° ùëé = ùëé(ùë° ùëé
ùëé ).
Let ùëõ ‚â• 0. The tree ùë°ùëõ over Œ£ = {ùëé, ùëè} with rk Œ£(ùëé) = rk Œ£(ùëè) = 2 defined
by
‚éß
‚é™
‚àó
ùëõ
‚é™ùëè
, if ùë£ ‚àà ùêø((0 1) ),
ùë° (ùë£)
= ‚é®
‚é™

‚é™ùëé
, otherwise
‚é©
is finitely representable. Note that it contains a ùëè at every node that is
reached on a path which takes a turn to the right at most ùëõ times.
Every tree ùë°ùëõ is finitely representable and of size 2ùëõ + 1. There is an
infinite system of equations representing them all uniformly, namely
13.3 Decision Problems
363
‚ãÆ
‚ãÆ
lft
lft
rgt
rgt
lft
rgt
ùë°
= ùëé(ùë°
, ùë°
, ùë°

)
ùëõ
ùëõ
ùëõ
)
ùë°ùëõ
= ùëè(ùë°ùëõ‚àí1 ùëõ‚àí1
‚ãÆ
‚ãÆ
lft
rgt
ùë°
= ùëé(ùë° , ùë°
= ùëè(ùë° , ùë°
1
0
0)
ùë°1
0
0)

ùë°
, ùë°
0
= ùëé(ùë° 0 0)
for every ùëõ ‚â• 2. Note that each tree with index ùëõ only depends on the 2ùëõ +
1 trees lft
with indices at most ùëõ. Hence, each ùë°ùëõ ‚à∂= ùë°ùëõ is indeed represented by a
finite system of eq uations.
A detailed analysis of the proof of Thm. 13.33 yields the desired result about
finitely representable witnesses for non-emptiness of NPTA-recognisable
languages.
Theorem 13.38 Let A be an NPTA of size ùëõ . We have ùêø(A) ‚â† ‚àÖ iff there is a
finitely representable tree ùë° of size at most ùëõ such that ùë° ‚àà ùêø(A) .
Proof The direction "‚áê" is obvious. For the direction "‚áí" let A = (ùëÑ, Œ£, ùëû
, ùõø, Œ©
ùêº
)
and assume that ùêø(A) ‚â† ‚àÖ. So player 0 has a positional winning strategy ùúé0
for
‚àí
‚àí
the game G(A , ùë°ùëé) where A
results from A with the construction of Def. 13.30

changing its alphabet to a singleton Œ£‚Ä≤ = {ùëé}.
ùëö
This strategy has type ùëÑ√ó dom(ùë°ùëé) ‚Üí ùëÑ
where ùëö = rk Œ£‚Ä≤ (ùëé). Since ‚à£ dom(ùë°ùëé)‚à£ = 1
ùëö
we can in fact assume that the type of ùúé0 is ùëÑ ‚Üí ùëÑ .
We now use ùúé0 to create a finitely representable tree, represented by the
variable ùë°ùëû
in the system that contains one equation
ùêº
ùë°
, . . . , ùë°
ùëû
= ùëè(ùë°ùëû
ùëû
)
ùëñ
ùëñ
1
ùëë

ùëö
for each ùëû ‚àà ùëÑ where ùúé
, . . . , ùëû
, . . . , ùëû
, . . . , ùëû
0(ùëû) = (ùëûùëñ
ùëñ
ùëñ
) ‚àà ùëÑ
with (ùëûùëñ
ùëñ
) ‚àà
1
ùëë
ùëë
1
ùëë
ùõø(ùëû, ùëè) for ùëè ‚àà Œ£ and rk Œ£(ùëè) = ùëë. Note that this incorporates a partial
reversal of the
‚àí

simplification construction that turns A into A : we consider the positional
strategy
‚àí
ùúé0 in the acceptance game for A
(and ùë°ùëé) because ùë°ùëé gives us a negligible set of
tree nodes, and A is defined over a different alphabet than ùë°ùëé, but we
ultimately need
‚àí
a representation of a tree in ùêø(A), not ùêø(A ).
This system of equations is well-defined. By assumption, ùúé0(ùëûùêº ) is defined,
for otherwise player 0 would not win the node (ùëû , ùë°
ùêº
ùëé ) and therefore not the game itself.
Here we write (ùëû , ùë°
, ùúÄ
ùêº
ùëé ) instead of (ùëû ùêº
) for the root node ùúÄ of ùë°ùëé. The reason will
be clear in a moment.
Since player 1 controls the directions in the acceptance game, ùúé0 must be
defined for every player-0 position that can be reached next, namely every
position of the form (ùëû , ùë°

, ùë°
, . . . , ùëû
ùëñ
ùëé ) for all ùëñ = 1, . . . , ùëë, where ùúé0(ùëû ùêº
ùëé ) = (ùëû 1
ùëë ). Here, we identify
a subtree with its root node and write ùë°ùëé for the root of any subtree that is
isomorphic to the tree ùë°ùëé. This also proves the point that ùúé0 can be assumed
to only depend on ùëÑ , and not on dom(ùë°ùëé).
So consider the tree ùë°ùëû represented by this system of equations. Clearly, it
has ùêº
size at most ùëõ. It remains to be seen that ùë°ùëû ‚àà ùêø(A). It is not hard to see
that there is ùêº
a run of A on ùë°ùëû . It labels the root of each node represented by ùë°ùëû with the
state ùëû. It ùêº
is even accepting because ùúé0 is a winning strategy, and every sequence of
states that
364
13 Automata on Infinite Trees
‚àí
forms a path in this run on ùë°
, ùë°

ùëû
is a subsequence of a play in G(A
ùëé ) conforming
ùêº
to ùúé0, namely the subsequence of player-0 nodes. They are interleaved with
player-1
nodes, but these all have priority 0, so the greatest priority occurring
infinitely often on the subsequence of player-0 nodes is the greatest priority
occurring infinitely often in the play, and this must be even by assumption.
‚óª
Bibliographic Notes
Automata recognising languages of infinite trees are studies in detail in the
book
+
on tree automata by Comon et al. [CDG 07], unpublished but available
online.
Automata on infinite trees also do feature in other textbooks on automata in
a more general setting, for instance [KN10, PP04], as well as Thomas'
articles in the Handbook of Theoretical Computer Science [Tho90] and the
Handbook of Languages, Automata and Logic [Tho97]. The topic also
plays a role in a broader framework in parts in Thomas' Festschrift
[FGW08], and in a collection edited by Gr√§del, Thomas and Wilke
[GTW02].
A chapter by L √∂ding of the Handbook of Automata Theory is also devoted
to the theory of infinite trees [L √∂d21]. This chapter also contains a detailed
exposition of the complementation closure result for tree automata. It

introduces and uses alternating tree automata which are easier to
complement, and a simulation construction for them by nondeterministic
ones. This does not make an essential but rather a notational difference
only to the construction presented here because acceptance of a tree by an
alternating automaton can equally be seen as a game, and simulation of an
alternating automaton by a nondeterministic one is essentially the
construction of an automaton recognising a winning strategy for one of the
players.
Alternating automata on infinite trees have first been studied by Muller and
Schupp [MS87, MS95], in particular with regards to their use for proving
closure under complements for regular languages of infinite trees, as well
as by Saoudi
[SMS90, Sao91].
Vardi, Wolper et al. studied automata operating on infinite trees, mainly for
the purpose of obtaining complexity-theoretically optimal decision
procedures for branching-time temporal logics [VW86, CVW86, KVW00].
Complementation closure for regular languages of infinite trees is a much
celebrated result known as Rabin's Theorem [Rab69]. It answered a natural
question arising with B √ºchi's decidability proof for Second-Order Logic of
One Successor (S1S), namely concerning the decidability of Second-Order
Logic with monadic predicates over structures that provide more than one
successor function, so-called SnS. While the high-level structure of this
result as it is presented here, cf. Thm. 13.28, is in line with Rabin's original
construction, it has to be said that much of the elegance is owed to
positional determinacy of parity games which was not available to Rabin at
the time. The path via parity automata and games, as it is presented here, is
due to Gurevich and Harrington [GH82].
Exercises for Chapter 13
365
Since B √ºchi tree automata are expressively too weak [Rab70], Rabin first
had to introduce a stronger acceptance condition, nowadays known as the

Rabin condition.
This introduces a bit more technical difficulty compared to the use of parity
tree automata because, due to their lack of symmetry, Rabin games do not
enjoy positional determinacy. They are determined, but only player 0 has
positional strategies in general, cf. [KK91]. Player 1 can only be assumed
to have finite-memory strategies which is sufficient, though, for the
construction of tree automata for complement languages in the end.
The relative weakness of B √ºchi tree automata, in particular their lack of
complementation closure, called for further studies into their
expressiveness, in particular possible correspondences to logics over trees
[Kai95, Sku02].
B √ºchi tree automata are clearly parity tree automata, using only the
priorities 1
and 2. So a natural question asks whether there is any fixed set of priorities
that suffices to recognise all regular languages of infinite trees. The answer
is negative and has first been given in terms of the need for unbounded
nestings of fixpoints in the modal ùúá-calculus, cf. [Koz83], the so-called
strictness of the alternation hierarchy
[Bra98a, Len96, Bra98b]. This result also holds for ranked trees [Bra99,
Arn99].
Since formulas of the modal ùúá-calculus are essentially alternating parity
tree automata (APTA), this hierarchy immediately implies a strict hierarchy
of expressiveness for APTA w.r.t. their indices. It is even the case that
increasing the index by 1 strictly increases their expressive power. The
proof relies on complementation closure which can easily be done for APTA
without an increase in index. For nondeterministic automata, this involves
an increase though, in general. Hence, the stratification w.r.t. their indices
also yields a strict hierarchy of expressiveness for NPTA, but higher
expressiveness is not necessarily already achieved by increasing the index
by 1 but may require more than one additional priority.

The existence of finitely representable infinite trees witnessing non-
emptiness of the language of a tree automaton not necessarily with a parity
condition but with others like Rabin or Muller, was shown by Hossley and
Rackoff [HR72] who gave a decision procedure for non-emptiness by a
reduction to the non-emptiness problem for automata on finite trees.
Exercises
Exercise 141 Construct NPTA for the following languages over Œ£ = {ùëé, ùëè,
ùëê} where rk Œ£(ùë•) = 2 for all ùë• ‚àà Œ£ .
ùúî
a) ùêø1 = {ùë° ‚àà TŒ£ ‚à£ ùë° = ùëé(ùëè(ùë°, ùë°), ùëè(ùë°, ùë°))},
ùúî
b) ùêø2 = {ùë° ‚àà TŒ£ ‚à£ ùë°(ùúÄ) = ùëé and ‚àÄùë£ ‚à∂ if ùë°(ùë£) = ùëé then ùë°(ùë£110) = ùëé = ùë°(ùë£
001)}, ùúî
c) ùêø3 = {ùë° ‚àà TŒ£ ‚à£ for all paths ùë§ of ùë° we have that ‚à£ùë§‚à£ùëé = ‚àû implies ‚à£ùë§‚à£ùëè
= ‚àû}, ùúî
d) ùêø5 = {ùë° ‚àà TŒ£ ‚à£ ùë° has a path with infinitely many symbols ùëé, and it has a
path with infinitely many symbols ùëè }.
366
13 Automata on Infinite Trees
In each case, explain whether the language is also recognisable by a DPTA,
an NBTA or even a DBTA.
Exercise 142 Prove Thm. 13.6.
Exercise 143 Prove Lemma 13.7.
Exercise 144 Prove Lemma 13.12 and 13.13.

OceanofPDF.com

Exercise 145 Prove Lemma 13.14.
Exercise 146
ùúî
Let ùêø ‚äÜ TŒ£ for some ranked alphabet Œ£ with associated set of direc-ùúî
tions ùê∑. Define Tr(ùêø) ‚à∂= ‚ãÉ{ Tr(ùë°) ‚à£ ùë° ‚àà ùêø} ‚äÜ (Œ£ √ó ùê∑)
to be the set of all guided
traces of trees from ùêø .
a) Show that Tr(ùêø) is ùúî-regular if ùêø is a regular tree language.
b) Consider the following attempt at a determinisation procedure for NPTA.
Given an NPTA A, use part (a) to compute an NBA for Tr(ùêø(A)). Then use
‚ñ≥
Lemma 13.17 to compute a DPTA for Tr(ùêø(A)) . Why does this not yield a
DPTA for ùêø(A)?
Exercise 147 Prove Lemma 13.22.
Exercise 148 Consider the NPTA A = (ùëÑ, Œ£, 0, ùõø, Œ©) where Œ£ = {ùëé, ùëè} with
rk Œ£(ùëé) = rk Œ£(ùëè) = 2 and ùëÑ = {0, 1, ‚óè}, Œ©(0) = Œ©(1) = 1, Œ©(‚óè) = 0 and
the following transitions.
ùõø(0, ùëé) = {(0, 1), (1, 0)}
ùõø(0, ùëè) = {(0, 0), (1, 1), (‚óè, ‚óè)}
ùõø(1, ùëé) = {(0, 0), (1, 1)}
ùõø(1, ùëè) = {(0, 1), (1, 0)}

ùõø(‚óè, ùëé)
= ‚àÖ
ùõø(‚óè, ùëè)
= {(‚óè, ‚óè)}
a) Determine ùêø(A).
ùúî
b) Consider the tree ùë° ‚àà TŒ£ , finitely represented by the following system of
equations.
ùë°
= ùëè(ùëé(ùëè(ùëé(ùë° , ùëé
, ùë°
, ùë°
, ùë°
ùëè
(ùë°ùëè
ùëè )), ùëé (ùë° ùëè
ùëè )), ùëé (ùë° ùëè
ùëè )), ùë° ùëè )
ùë°
, ùë°

ùëè
= ùëè(ùë°ùëè
ùëè )
‚Ä≤
ùúî
We have ùë° /
‚àà ùêø(A). Construct a tree ùë° ‚àà TŒ£
for S ‚à∂= ùëÑ2 ‚Üí {0, 1} such that
√óS
ÃÇ
‚Ä≤
‚Ä≤
proj (ùë° ) = ùë°
(ùë° )
1
and ÃÇ
proj 2
defines a positional winning strategy for player 1 in
the game GA ,ùë° .

Exercise 149 Consider the NPTA A = ({0, 1}, Œ£, 0, ùõø, Œ©) with Œ£ = {ùëé, ùëè}, rk
Œ£(ùëé) =
rk Œ£(ùëè) = 2, Œ©(0) = 1, Œ©(1) = 2 and
ùõø(0, ùëé) = {(0, 0)} ,
ùõø(0, ùëè) = {(1, 1)} ,
ùõø(1, ùë•) = {(1 , 1)}
for ùë• ‚àà Œ£.
Exercises for Chapter 13
367
a) Determine ùêø(A).
ùúî
b) Let ùúå be a guided trace of a tree in TŒ£ ‚àñ ùêø(A). Explain why ùúå must be of
the form (ùë• , ùëÜ , ùëë
, ùëÜ , ùëë
0
0
0), (ùë•1
1
1), . . . with ùë•ùëñ ‚àà Œ£, ùëÜùëñ ‚àà {0, 1}2 ‚Üí {0, 1}, ùëëùëñ ‚àà {0, 1}
for all ùëñ ‚â• 0 suc h that
(‚àÄùëõ.ùë•ùëõ = ùëé) ‚à®

(‚àÉùëö .(ùë•ùëö = ùëè)
‚àß
(‚àÄùëõ < ùëö .ùë•ùëõ = ùëé) ‚àß
‚àÉùëõ.(ùëõ ‚â§ ùëö ‚àß ùëÜùëõ(0, 0) ‚â† ùëëùëõ) ‚à® (ùëõ > ùëö ‚àß ùëÜùëõ(1, 1) ‚â† ùëëùëõ))
is satisfied.
ùúî
c) Construct an NPTA A that recognises T
‚àñ ùêø(A).
A
Exercise 150 Let G be a parity game with ùëõ nodes, ùëí many edges and of
index ùëò.
a) Construct an NPTA A
ùêø
G such that
(A) ‚â† ‚àÖ iff G is won by player 0.
b) Argue that a polynomial-time algorithm for NPTA non-emptiness would
entail a polynomial-time algorithm for solving parity games, by checking
that AG is small enough to transfer polynomial-time bounds between the
algorithms.

Chapter 14
Logics on Infinite Trees
As with automata on infinite words and finite trees, automata as studied in
the previous chapter provide a relatively simple computational model for
specifying properties of infinite trees. Such trees can be seen as abstractions
of runs of reactive programs for instance, for which the exact next step is
not predetermined (as in infinite words) but may depend on some external
input.
While automata open up the path to decidability for the main decision
problems in the background, they can be cumbersome as specification
formalisms in the fore-ground. For example, programs are typically only
considered to be correct when they satisfy several specifications, i.e.
correctness is often expressed as a conjunction. While the class of NPTA is
closed under intersections, and an NPTA for the intersection of finitely
many NPTA-definable languages can be constructed effectively, it is barely
possible to find the automata for the single parts in the structure of the
resulting automaton for the intersection. This can make debugging difficult.
ùëõ
Suppose that ‚ãÇ
ùêø (A
, . . . , A
ùëñ=1

ùëñ )
for some NPTA A1
ùëõ
describes the branching
runs of a program that are seen to be correct, and a decision procedure
determines this language to be empty. It is then difficult to attribute this
directly to one or several involved NPTA.
One step to alleviate this - at least on the side of a user interface - is the
use of logical specification languages because specifications for tree
languages can be built more modularly using formulas rather than
automata directly. The price to pay is of course the fact that formulas are
tougher to handle algorithmically, and this is where automatic translations
into automata come into play again. So using formulas instead of automata
directly does not solve all problems, but they can provide a sometimes more
usable interface for specifying such languages.
A natural logic to consider is of course Monadic Second-Order Logic over
infinite trees. We adopt the few small syntactic modifications implemented
in Sect. 11.4 in order to obtain an MSO logic whose formulas can speak
about (finite) trees, compared to MSO over words. The extension to infinite
trees is then purely semantical and straightforward. We are of course
mainly interested in the satisfiability problem for this logic, and it is, again,
complementation closure for a corresponding automaton model - here:
NPTA - that provides the key to its decidability.
¬© The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
369

https://doi.org/10.1007/978-3-662-72154-4_14
370
14 Logics on Infinite Trees
One might rightfully argue that MSO is perhaps not the most suitable
specification language for applications in the specification and verification
of reactive programs and systems, as it requires some deeper familiarity
with formal logic. Moreover, its expressive power can sometimes be seen as
too high for particular purposes.
This is the reason why more application-targeted specification formalisms
like the linear-time temporal logic LTL discussed in Chp. 10 have been
invented and studied.
Temporal logic can also be interpreted over trees. It only requires an
adjustment in the notion of time, as already hinted at above. In (discrete)
linear-time temporal logics the future is considered to be determined in the
sense that for every moment there is a unique future moment. A temporal
model then naturally is a word: a linear sequence of moments, each of
which comes with some particular properties, here abstracted away into a
single alphabet symbol.
One may equally consider the future not to be predetermined in the sense
that for every moment, there are several possible future moments, and the
exact moment that is taken in some run is chosen by some uncontrollable
principle like the external environment of a computer system, user input,
randomness etc. The time model underlying this view is known as
branching time. Note that our task is not to determine the answer to the
perhaps philosophical question of whether linear or branching time is the
right interpretation of the world. In computer science, both have their right
to exist, and it is the requirements imposed by an application that determine
which is the correct one to use.
After briefly studying MSO on infinite trees, following the standard recipe
of the automata-logic connection for obtaining decidability, we turn our

attention to two temporal logics interpreted over infinite trees: the so-called
full branching-time
‚àó
temporal logic CTL can be seen as a natural extension of the linear-time
temporal logic LTL from Chp. 10 to tree models. The modal ùúá -calculus Lùúá
extends a very small fragment of First-Order Logic (interpreted in tree
structures) by so called fixpoint quantifiers. They can be seen as restricted
versions of the generally more powerful second-order quantifiers.
Decidability of satisfiability for both logics is everything but obvious.
However, it immediately follows from translations into MSO.
14.1 Monadic Second-Order Logic
14.1.1 Syntax and Semantics
The syntax of MSO, interpreted over infinite trees over some ranked
alphabet Œ£, is exactly the same as the one for MSO over finite Œ£-trees, see
Def. 11.25. For convenience, we repeat it here.
ùúë
‚à∂‚à∂= succ ùëñ (ùë•, ùë¶) ‚à£ ùëã (ùë•) ‚à£ ùëé(ùë•) ‚à£ ùúë1 ‚à® ùúë2 ‚à£ ¬¨ùúë ‚à£ ‚àÉùë• ùúë ‚à£ ‚àÉùëã ùúë
As usual, ùë•, ùë¶ are first-order variables, ùëã is a second-order variable from
some underlying countable set of variables V = V1 ‚à™ V2, ùëé ‚àà Œ£ and ùëñ ‚àà N.
The formula
14.1 Monadic Second-Order Logic
371
ùë¶
ùëß
‚ãÆ

‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
Fig. 14.1 Binary tree with variable assignment for first-order variables ùë¶, ùëß
and some second-order variable.
succ ùëñ (ùë•, ùë¶) is used to state that the node in a tree that is referred to with ùë¶
is the ùëñ-th successor of the node referred to by ùë•, starting from ùëñ = 0.
Other logical operators like conjunctions, universal quantification etc. are
introduced as abbreviations in the usual way. All the other syntactical

concepts like formula size, the first-order fragment, etc. apply here as well
of course.
ùúî
The interpretation of a formula in a tree ùë° ‚àà TŒ£ , together with a variable
assignment ùêº ‚à∂ (V1 ‚Üí dom(ùë°)) + (V2 ‚Üí 2 dom(ùë°)) is defined as usual, cf.
Def. 11.26.
Naturally, second-order quantification now ranges over finite and infinite
sets of nodes in a tree.
The usual semantical concepts like equivalence, satisfiability and language
ùêø(ùúë) of a sentence ùúë are defined in the usual way.
Equality is not explicitly introduced in the syntax of MSO. As with
(monadic) second-order logics in general, equality is definable via ùë• = ùë¶ ‚à∂=
‚àÄùëã .ùëã(ùë•) ‚Üî ùëã(ùë¶) .
14.1.2 Capturing Paths
Remember that over words, equality is equally definable using pure
Boolean operators via ùë• = ùë¶ ‚à∂= ¬¨(ùë• < ùë¶) ‚àß ¬¨(ùë¶ < ùë•). This does of course
require the relation '<' to be available, and MSO above has been
introduced without it. It will be convenient to have, though. Before we show
how to obtain it as an abbreviation, we need to remark that '<' on words is
interpreted by the total order of all the positions in the word. A natural way
to interpret such a symbol in a tree is the partial order obtained via ùë¢ < ùë£
+
iff there is a ùë§ ‚àà N such that ùë£ = ùë¢ùë§, i.e. if ùë£ is located somewhere
"underneath" ùë¢
in the underlying tree.
Example 14.1 We aim to construct an MSO formula ùúë<(ùë¶, ùëß) that is true in a
tree ùë°

under some variable assignment ùêº iff ùêº(ùë•) < ùêº(ùë¶) via the partial-order
interpretation of '<' described abov e.
It is tempting to say that ùëß is located underneath ùë¶ if it is possible to start a
path from ùë¶ that eventually hits ùëß, i.e. if there is a set ùëã of nodes that
contains ùë¶, also
372
14 Logics on Infinite Trees
contains some successor of every node in it, and also contains ùë¶. This bears
several problems, though.
First of all, this informal construction recipe is clearly symmetric in ùë¶ and
ùëß.
Hence, a formalisation in MSO - which is clearly possible - could not
define ùúë< as desired because it would not distinguish the case of ùëß located
underneath ùë¶ from the case in which ùë¶ is located underneath ùëß. In fact, it
would not even distinguish these from the case in which both are equal. This
could easily be fixed though. Instead of demanding that ùëã contains ùë¶, we
demand that ùëã contains some successor of ùë¶.
However, there is a much more profound problem with this attempt.
Consider the situation depicted in Fig. 14.1. It shows a binary tree and an
assignment ùêº of two first-order variables ùë¶, ùëß such that ùêº(ùë¶) = 0 and ùêº(ùëß) =
11, as well as of a second-order variable ùëã. Its interpretation is shown in
black circles, i.e. we have ùêº (ùëã ) = {00, 11, 001, 100, 111, . . . }.
Clearly, 0 /
< 11. Hence, ùúë< should not be satisfied under this assignment ùêº.
However, ùêº(ùëã) contains some successor of ùêº(ùë¶), contains ùêº(ùëß) and is closed
under successors. At least it is easy to imagine that the interpretation of ùëã

extends further down the tree so that every black circle node has one
successor that is also a black circle node.
Fig. 14.1 shows why the characterisation of '<' via the three properties
above is insufficient: it does not require that ùë¶ and ùëß are ultimately
connected via ùëã. In fact, the monotonic use of ùëã in this description means
that it can be interpreted as a set of paths rather than a single path, and it
suffices for some path in this set to contain a successor of ùë¶ and another to
contain ùëß.
It may then be tempting to turn the construction around and demand that
there is a set which contains ùëß, is closed under predecessors and contains
some successor of
‚Ä≤
ùë¶. However, logically this is exactly the same. Note that succ ùëñ (ùë•, ùë• ) does
not only
‚Ä≤
state that ùë• is the ùëñ-th successor or ùë• but equally that ùë• is the (unique)
predecessor
‚Ä≤
of ùë• .
In the end, it is helpful, though, to think in terms of an ascending path from
ùëß to ùë¶, but we need to exclude the possibility of a second-order variable to
be interpretable by multiple paths or path-like sets. We first define
ùúë‚â§(ùë¶, ùëß)
‚à∂= ‚àÄùëã .(ùëã (ùëß) ‚àß preds(ùëã ) ‚àß nomerge(ùëã )) ‚Üí ùëã (ùë¶ )
where

ùëë‚àí1
‚Ä≤
‚Ä≤
succ(ùë• , ùë•) ‚à∂= ‚ãÅ succ
, ùë•
ùëñ (ùë•
)
ùëñ=0
‚Ä≤
‚Ä≤
preds(ùëã) ‚à∂= ‚àÄùë•.ùëã(ùë•) ‚Üí (‚àÄùë• . succ(ùë• , ùë•) ‚Üí ùëã (ùë•))
ùëë‚àí2 ùëë‚àí1
‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
‚Ä≤‚Ä≤
nomerge(ùëã) ‚à∂= ‚àÄùë•. ‚ãÄ
‚ãÄ
‚àÄùë• ‚àÄùë•
. succ ùëñ (ùë•, ùë• ) ‚àß succ ùëó (ùë•, ùë• ) ‚Üí

ùëñ=0 ùëó=ùëñ+1
‚Ä≤
‚Ä≤‚Ä≤
¬¨(ùëã (ùë• ) ‚àß ùëã (ùë•
))
14.1 Monadic Second-Order Logic
373
and ùëë is the maximal rank of symbols in the underlying alphabet. It states
that every set ùëã which contains ùëß and is closed under predecessors, and
additionally never contains two different successors of some node, also
contains ùë¶. The only sets that satisfy the first two conditions are paths from
the root to ùëß and perhaps beyond. Now, that fact that every such set must
contain ùë¶ means that it must be located on the unique path from the root to
ùëß. Hence, we have ùë°, ùêº ‚äß ùúë‚â§(ùë¶, ùëß) iff ùêº(ùë¶) ‚â§ ùêº(ùëß) in the partial order induced
by reachability in ùë° .
Then we can simply define ùúë<(ùë¶, ùëß) ‚à∂= ùúë‚â§(ùë¶, ùëß) ‚àß ¬¨(ùë¶ = ùëß). For this, it is of
course necessary to define equality via second-order quantification as done
above, not via
'< ' itself.
We allow ourselves to simply write ùë¶ < ùëß and ùë¶ ‚â§ ùëß instead of ùúë<(ùë¶, ùëß) and
ùúë‚â§(ùë¶, ùëß) just as we do with ùë¶ = ùëß f or instance.
In the following section on temporal logic we will need MSO's ability to
quantify over paths, i.e. to express that some second-order variable
evaluates to a path starting in a particular node.
Lemma 14.2 Let Œ£ be given. There is an MSO formula Path(ùëã, ùëß) such that
for ùúî

every ùë° ‚àà TŒ£ and every variable assignment ùêº in ùë° we have ùë°, ùêº ‚äß Path(ùëã, ùëß)
iff ùêº(ùëã) forms a single path through ùë° starting in ùêº(ùëß) .
Proof It suffices to observe that a path in a tree starting in some node ùë£ is a
set ùëã of nodes that contains ùë£, contains some successor for every node in it,
and additionally has two properties: It does not contain any ancestor of ùëß,
and each two nodes in ùëã
are comparable w.r.t. '‚â§'. Thus, we can construct the formula under
demand as Path(ùëã, ùëß) ‚à∂= ùëã(ùëß) ‚àß (‚àÄùë¶.ùëã(ùë¶) ‚Üí ‚àÉùë•. succ(ùë¶, ùë•) ‚àß ùëã(ùë•)) ‚àß
(‚àÄùë¶.ùë¶ < ùëß ‚Üí ¬¨ùëã (ùë¶)) ‚àß (‚àÄùë•‚àÄùë¶. ùëã (ùë•) ‚àß ùëã (ùë¶) ‚Üí ùë• ‚â§ ùë¶ ‚à® ùë¶ ‚â§ ùë•)
where succ(ùë¶, ùë•) is defined as in Ex. 14.1.
‚óª
One may wonder why Œ£ needs to be given. Note that subformulas like ùë¶ ‚â§ ùë•
depend on some maximal rank of symbols in the underlying alphabet.
14.1.3 Decidability
The main decision problems for MSO over infinite trees are decidable, as
they are for MSO over finite and infinite words, and over finite trees. The
backbone of a decision procedure is, again, the effective ability to translate
formulas into equivalent automata, in this case NPTA. For this to work
inductively, the same tricks can be applied as before.
First, we adopt a special syntax of MSO that only contains second-order
variables and a special predicate Sing(ùëã) which is true under some
variable assignment ùêº iff
374
14 Logics on Infinite Trees

‚à£ùêº (ùëã )‚à£ = 1. This allows us to express first-order quantification as
relativised second-order quantification. Similar adjustments have to be
made to replace the formula construct succ ùëñ(ùë•, ùë¶) by some Succ ùëñ(ùëã, ùëå )
operating on second-order var iables.
Once first-order variables are eliminated, an interpretation (ùë°, ùêº) with ùë°
being a tree over a ranked alphabet Œ£ and ùêº ‚à∂ {ùëã , . . . , ùëã
1
ùëõ }
‚Üí 2 dom(ùë°), can be regarded as
ùëõ
a tree over the alphabet Œ£ √ó {0, 1}
in the natural way with the ùëó -th component
of the additional vector of binary values at a node ùë£ determining whether or
not ùúî
ùúî
ùë£ ‚àà ùêº (ùëã ùëó ). Thus, if ùë° ‚àà TŒ£
then ùë°ùêº ‚àà TŒ£
ùëõ
where ùë°ùêº is the natural represen-
√ó{0,1}
tation of ùë° and ùêº in this sense. For this to be well-defined, we need to set
ranks as rk Œ£
ùëõ (ùëé, ùëè

, . . . , ùëè
√ó{0,1}
1
ùëõ )
= rk Œ£(ùëé). As a consequence, any projection of type
Œ£
ùëõ
ùëö
√ó {0, 1}
‚Üí Œ£ √ó {0, 1}
for any 0 ‚â§ ùëö < ùëõ that erases the same ùëõ ‚àí ùëö symbols
from each ùëõ-tuple of binary values, induces a rank -preserving
homomorphism.
Then again, it is possible to construct NPTA for atomic MSO formulas in
this specialised syntax, and effective closure under unions (Lemma 13.12),
rank-preserving homomorphisms (Lemma 13.14) and complements (Thm.
13.28) can be used to build automata inductively for larger formulas
possibly containing free variables.
Spelling out the details of this construction is left as an exercise.
Theorem 14.3 For every MSO sentence ùúë over a ranked alphabet Œ£ there is
an NPTA Aùúë such that ùêø(Aùúë ) = ùêø(ùúë) .
Thus, satisfiability of MSO over infinite trees also reduces to non-emptiness
for NPTA which is decidable according to Thm. 13.33.

Corollary 14.4 Satisfiability for MSO over infinite trees is decidable.
Note that Thm. 14.3 only states the existence of equivalent NPTA for MSO
sentences. However, the considerations above clearly show that such NPTA
are also effectively computable. Cor. 14.4 states decidability of satisfiability
for arbitrary formulas, even though Thm. 14.3 is only formulated for
sentences. One can either extend the statement in Thm. 14.3 accordingly as
it needs to be done for an inductive proof, but then one has to inject the
notion of representation of a variable valuation by a node label extension
into the notion of equivalence. Alternatively, one can easily see that
satisfiability of an arbitrary formula ùúë(ùëã , . . . , ùëã , ùë• , . . . , ùë•
1
ùëõ
1
ùëõ )
reduces to
satisfiability of a sentence, namely in this case the one for
‚àÉùëã
. . .
. . .
ùúë
, . . . , ùëã
, ùë• , . . . , ùë•
1

‚àÉùëãùëõ‚àÉùë•1
‚àÉùë•ùëõ
(ùëã1
ùëõ
1
ùëõ ) .
Likewise, decidability of satisfiability carries over to the other main logical
decision problems, and this can either be shown by making the step from,
say, equivalence to emptiness on the automata side, constructing an NPTA
whose language is empty iff two given ones define the same language. Or it
can be seen on the logical side with ùúë ‚â° ùúì iff ¬¨(ùúë ‚Üî ùúì) is unsatisfiable.
Corollary 14.5 Validity and equivalence for MSO over infinite trees are
decidable.
14.2 Full Branching-Time Logic
375
14.2 Full Branching-Time Logic
‚àó
The so-called full branching time temporal logic CTL
extends the linear-time
temporal logic LTL by quantifiers for paths so that its formulas can
naturally be interpreted in nodes of a tree.
14.2.1 Syntax and Semantics

We recall the syntax of LTL which is built from atomic propositions using
Boolean operators and the temporal operators X ( Next) and U ( Until) with
several derived operators like F ( Finally), G ( Generally) and R ( Release).
P
Formulas were said to be interpreted in ùúî-words over the alphabet 2 , but
actually they are interpreted in a position in a word, namely the first, as the
standard translation into FO shows. Since every ùúî-word clearly has a
unique first position, it is fair to say that LTL formulas are interpreted in
words.
‚àó
CTL extends LTL by two additional operators E ("there is a path") and A
("for all paths"). This makes formulas interpretable in nodes of a tree, at
least some formulas.
Take, for instance, the LTL formula ùúë = Xùëù that does not make use of the
new operators, stating "ùëù holds in the next moment." It is meaningless to
ask whether P
node 010 for instance, in a binary 2 -labelled tree, satisfies ùúë because node
010
does not have a single successor which could be probed for satisfying ùëù.
Instead, it has two: 0100 and 0101.
‚àó
‚Ä≤
On the other hand, the CTL
formula ùúë ‚à∂= Aùúë could be satisfied by this node.
It states that ùëù holds on all paths (starting in the node under consideration).
This is clearly possible for a tree ùë°, namely when ùëù ‚àà ùë°(0100) and ùëù ‚àà

ùë°(0101).
‚àó
In order to avoid pitfalls with uninterpretable formulas, the syntax of CTL
contains two types of formulas, namely state formulas and path formulas.
They are built by mutual recursion. A state formula is interpretable in a
node of a tree, so it is what we are interested in after all. A path formula is
interpretable on a path in a tree. Path formulas are essentially just LTL
formulas over propositions and state formulas, and path quantifiers turn
path into state formulas.
Before we can define the syntax formally, we need to briefly address the
issue
‚àó
of the underlying alphabet. As with LTL, CTL is mainly used for the
specification of runs of programs, and for modelling purposes it is more
handy to assume an underlying set of propositions P of which multiple ones
or none can hold in a state.
This is not in line with the model of Œ£-trees for a ranked alphabet Œ£ where
every node is labelled with exactly one alphabet symbol. A simple way to
overcome this is, as done for LTL, to associate, with a finite set of
propositions P , the alphabet Œ£
P
= 2 . This was not a problem in the case of LTL, leading to ùúî-words over an
alphabet which is of exponential size in the number of underlying
propositions but of course still finite. In the case of trees, we need a ranked
alphabet, though, and explicitly fixing the rank of each symbol ùëé ‚äÜ P
defeats the purpose of working with propositions instead of the associated
and generally much larger set of alphabet
376

14 Logics on Infinite Trees
symbols. For simplicity, we assume a fixed rank ùëë > 1 such that rk 2P (ùëé) =
ùëë for all ùëé ‚äÜ P . This will allow us to appeal to results for MSO and NPTA,
interpreted in trees over a rank ed alphabet.
The case of ùëë = 1 does not have to be excluded, but 1-ary trees are of
course just ùúî-words, and one can easily check - with the semantics given
below - that the state formulas Eùúì and Aùúì are satisfied by a node in a 1-ary
tree, i.e. an ùúî-word, iff the unique path starting in this node satisfies the path
formula ùúì. Hence, in case of ùëë = 1,
‚àó
the extension by path quantifiers adds no extra expressive power, and CTL
is just the same as LTL. This is why we generally assume ùëë ‚â• 1 but
implicitly understand that only the cases ùëë > 1 are reall y interesting.
Definition 14.6 Let P be a set of atomic propositions. State (ùúë) and path (ùúì)
formulas
‚àó
of the full branching-time temporal logic CTL are given by the grammar ùúë
‚à∂= ùëù ‚à£ ùúë ‚à® ùúë ‚à£ ¬¨ùúë ‚à£ Eùúì
ùúì
‚à∂= ùúë ‚à£ ùúì ‚à® ùúì ‚à£ ¬¨ùúì ‚à£ Xùúì ‚à£ ùúì U ùúì
where ùëù ‚àà P .
Other Boolean connectives are introduced as abbreviations in the usual
way. The same holds for other temporal operators that make up path
formulas, as they were introduced within LTL. At last, we abbreviate ¬¨E¬¨ùúë
as Aùúë.

‚àó
The size ‚à£ùúë‚à£ of a CTL
formula ùúë is the number of distinct subformulas it has.
‚àó
These can be state or path formulas. When we speak of a CTL formula we
usually
‚àó
mean a CTL state formula.
‚àó
As said above, CTL state formulas are interpreted in nodes of a tree. Def.
14.6
allows formulas to be built over an infinite set of atomic propositions.
Clearly, if P
P
‚à£P ‚à£ = ‚àû then ‚à£2 ‚à£ = ‚àû, and it seems that we cannot use 2
as an alphabet for
labelling the nodes in trees, at least not in the context of recognising trees
using
‚àó
finite automata. However, every CTL
formula can clearly only contain finitely
‚àó

many atomic propositions, and this also holds for a finite set of CTL
formulas.
‚àó
When studying infinite families of CTL formulas, we assume them to be
built over
‚àó
the same finite set of atomic propositions, even though the set of all CTL
formulas may not satisfy this property.
Definition 14.7
P
Let ùëë ‚â• 1, P be a finite set of propositions, Œ£ ‚à∂= 2
with rk Œ£(ùëé) ‚à∂= ùëë
ùúî
for all ùëé ‚äÜ P , and ùë° ‚àà TŒ£ . We write Œ†ùë° (ùë£) for the set of paths through ùë°
that start in node ùë£, i.e. ùúã ‚àà Œ†
, ùë£ùëñ ùëñ , . . .
, ùëñ , . . .
ùë° (ùë£ ) iff ùúã = ùë£, ùë£ùëñ1
1 2
for some ùëñ1 2
with 0 ‚â§ ùëñ ùëó < ùëë for

all ùëó ‚àà N.
‚àó
‚àó
The interpretation of a CTL state formula ùúë in a node ùë£ ‚àà dom(ùë°) and of a
CTL
path formula ùúì on a path ùúã through ùë° is explained by simultaneous induction
on the structure of ùúë and ùúì .
ùë° , ùë£ ‚äß ùëù
iff
ùëù ‚àà ùë°(ùë£)
ùë° , ùë£ ‚äß ùúë1 ‚à® ùúë2
iff
ùë° , ùë£ ‚äß ùúë1 or ùë°, ùë£ ‚äß ùúë2
ùë° , ùë£ ‚äß ¬¨ùúë
iff
ùë° , ùë£ /
‚äß ùúë
14.2 Full Branching-Time Logic
377
ùëù
ùëù

ùëû
ùëû
ùëû
ùëù
ùëù
ùëù
ùëù
ùëù
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
ùëû
ùëù
ùëù
ùëù
ùëû
‚ãÆ
‚ãÆ
‚ãÆ

‚ãÆ
‚ãÆ
ùëû
ùëù
ùëù
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
‚ãÆ
Fig. 14.2
‚àó
Two finitely representable trees used to separate CTL formulas in Ex. 14.8.
ùë° , ùë£ ‚äß Eùúì
iff
there is ùúã ‚àà Œ†ùë° (ùë£) s.t. ùë°, ùúã ‚äß ùúì
ùë° , ùúã ‚äß ùúë
iff
ùë° , ùë£ 0 ‚äß ùúë

ùë° , ùúã ‚äß ùúì1 ‚à® ùúì2
iff
ùë° , ùúã ‚äß ùúì1 or ùë°, ùúã ‚äß ùúì2
ùë° , ùúã ‚äß ¬¨ùúì
iff
ùë° , ùúã /
‚äß ùúì
1
ùë° , ùúã ‚äß Xùúì
iff
ùë° , ùúã
‚äß ùúì
ùëò
ùëö
ùë° , ùúã ‚äß ùúì
U ùúì
1
2
iff
there is ùëò ‚â• 0 with ùë°, ùúã ‚äß ùúì2 and for all ùëö < ùëò ‚à∂ ùë°, ùúã

‚äß ùúì1
ùëò
where ùúã(0) = ùë£
, ùë£
, . . .
, ùë£
, . . .
0 and ùúã
= ùë£ ùëò
ùëò +1
for any ùëò ‚â• 0 if ùúã = ùë£0
1
We say that a tree ùë° is a model of a state formula ùúë, written ùë° ‚äß ùúë for short, if
ùúî
ùë° , ùúÄ ‚äß ùúë. The language ùêø(ùúë) ‚äÜ TŒ£ consists of all models of ùúë. Two state
formulas
‚Ä≤
‚Ä≤
‚Ä≤
ùúë, ùúë
are equivalent, written ùúë ‚â° ùúë as usual, if ùêø(ùúë) = ùêø(ùúë ). A formula ùúë is valid, ùúî

written ‚äß ùúë, if ùêø(ùúë) = TŒ£ .
‚àó
Note that there is a slight ambiguity in the definition of the language of a
CTL
‚àó
formula. Since there is no obligation to use up all propositions in a formula,
a CTL
‚àó
‚Ä≤
‚Ä≤
formula over P is also a CTL formula over P whenever P ‚äÜ P . We assume
that the underlying set of propositions is always fixed. If it is not given
explicitly, then it is safe to assume it to be smallest in the sense that it only
contains those propositions that occur in a given formula, resp. set of
formulas.
Example 14.8 Let P = {ùëù, ùëû}. A tree node that satisfies a proposition ùëù may
also be called a ùëù-node, and likewise for ùëû. Remember that a proposition
holds at some node in a tree when it is included in the label of that node
which is a set of propositions.
The formula ùúë1 ‚à∂= E(GFùëù ‚àß FG¬¨ùëû) states that on some path in a given tree,
there are infinitely many ùëù-nodes but only finitely many ùëû -nodes.
‚Ä≤
P
Consider the following two finitely representable binary trees ùë° , ùë°
1

over 2
where
1
ùëé ùëù = { ùëù}, ùëéùëû = {ùëû} and ùëè = ‚àÖ.
‚Ä≤
‚Ä≤
‚Ä≤
ùë°
, ùë°
, ùë°
1
= ùëé ùëù (ùë°2 3)
ùë°
= ùëé
)
1
ùëù (ùë°2
3
‚Ä≤
‚Ä≤

‚Ä≤
ùë°
, ùë°
, ùë°
2
= ùëè(ùë°2 3)
ùë°
= ùëè(ùë°
)
2
2
1
378
14 Logics on Infinite Trees
‚Ä≤
‚Ä≤
‚Ä≤
ùë°
, ùë°
, ùë°

3
= ùëéùëû (ùë°1 1)
ùë°
= ùëé
)
3
ùëû (ùë°1
1
‚Ä≤
They are unfolded to a few levels in Fig. 14.2 with ùë°1 on the left and ùë° on
the right.
1
We have ùë°1 /
‚äß ùúë1 because between two ùëù-nodes in ùë°1, there is a ùëû-node. Hence, every
path that contains infinitely many ùëù-nodes must also contain infinitely many
ùëû-nodes, and so no path can contain infinitely many ùëù-nodes but only finitely
many ùëû-nodes.
‚Ä≤
On the other hand, ùë° ‚äß ùúë
1
1 because it clearly contains paths with repeating parts

without any ùëû-nodes but containing ùëù-nodes. Hence, there is such a path
under ùúî
question, for example the path (01) .
‚àó
Now consider the CTL
formula ùúë2 ‚à∂= AGFùëù ‚àß EFG¬¨ùëû. It states that all paths
contain ùëù-nodes infinitely often and some path contains only finitely many
ùëû-nodes.
This is not the same as ùúë1. A witness for the distinction between these two
formulas is
‚Ä≤
‚Ä≤
‚Ä≤
ùë°
because ùë° /
‚äß ùúë
contains infinitely
1
1
2. This is easily seen because not every path in ùë°1
ùúî

‚Ä≤
many ùëù-nodes, for example 0 , so the first conjunct of ùúë2 is already violated
by ùë° .
1
Likewise, we have ùë°1 /
‚äß ùúë2 for the same reason. A slightly more complicated
argument uses the observation that ùúë1 is weaker than ùúë2 in the sense that the
P
implication ùúë2 ‚Üí ùúë1 is valid. This is not difficult to see: let ùë° be a given tree
over 2 , and suppose that ùë° ‚äß ùúë2. Then all its paths contain infinitely many ùëù-
nodes and some path ùúã contains finitely many ùëû-nodes only. So there is a
path, namely ùúã, that contains infinitely many ùëù-nodes and finitely many ùëû-
nodes only. Hence, ùë° ‚äß ùúë1 which proves that ‚äß ùúë2 ‚Üí ùúë1. By pure Boolean
reasoning we also have ‚äß ¬¨ùúë1 ‚Üí ¬¨ùúë2. In other words, if a tree does not
satisfy ùúë1 it also cannot satisfy ùúë2. Since ùë°1 does not satisfy ùúë1 as established
above, we also have ùë°1 /
‚äß ùúë2.
At last, consider ùúë3 ‚à∂= EF(ùëù ‚àß EG¬¨ùëû). It simply states that a given tree has
a ùëù-node from which a path can be started that does not contain any ùëû-node.
This
‚Ä≤
is clearly the case for both ùë°1 and ùë° , witnessed by the root node in both
cases. So 1
‚Ä≤
ùë°1 ‚äß ùúë3 and ùë° ‚äß ùúë

1
3 .
The latter is also a consequence of the fact that ‚äß ùúë1 ‚Üí ùúë3, i.e. ùúë3 is weaker
than
‚Ä≤
ùúë1, together with the fact established above that ùë° ‚äß ùúë
1
1.
To see that the implication ùúë1 ‚Üí ùúë3 is indeed valid, consider an arbitrary
tree ùë°
P
over 2
that satisfies ùúë
, ùë£
, . . .
1, i.e. it contains a path ùúã = ùë£0
1
with infinitely many
ùëù-nodes and finally many ùëû-nodes only. There must be a last ùëû-node on this
path in the sense that there is a ùëò ‚àà N such that ùë£ , ùë£
, . . .

ùëò
ùëò +1
all are not ùëû-nodes. Of course it
is possible that there is not a single ùëû-node on the path, but the important
point to ùëò
note here is that it is always possible to find some suffix ùúã = ùë£ , ùë£
, . . .
ùëò
ùëò +1
of ùúã that
does not contain ùëû-nodes at all. Now ùë£ùëò is clearly reachable from ùë°'s root,
and it is ùëò
the first node on a path, namely ùúã , with no ùëû-nodes. Hence, ùë° ‚äß ùúë3.
We have that ùúë1 and ùúë3 are not equivalent either. The two properties are
separated ùúî
by ùë°1 as we have ùë°1 ‚äß ùúë3, witnessed by the root node and the path 0 , but ùë°1
/
‚äß ùúë1 as
established above. So we have /
‚äß ùúë3 ‚Üí ùúë1.
‚àó

We develop a second example which shows how CTL is useful as a
specification language for reactive systems.
14.2 Full Branching-Time Logic
379
Example 14.9 Consider a system made up of ùëõ consumer processes ùê∂ , . . .
, ùê∂
0
ùëõ‚àí1.
They may signal requests (for some resource), using atomic propositions ùëüùëñ
for ùëñ ‚àà [ùëõ]. A scheduler, also part of the system, is used to keep track of
requests and grant requests on a particular basis. Granting a request for
process ùê∂ùëñ is signalled by
‚àó
an atomic proposition ùëîùëñ for ùëñ ‚àà [ùëõ]. The CTL formula
ùëõ‚àí1
ùúë
AGFùëü
0
‚à∂= ‚ãÄ
ùëñ
ùëñ=0
states that every process issues requests over and over again.

The scheduler maintains a FIFO buffer in which it stores requests. Thus,
reaching an ùëüùëñ-state can be seen as adding process ùê∂ùëñ's request to the
buffer unless the buffer already contains a request from this process in
which case the new request is simply
‚àó
discarded. The CTL formula
ùëõ‚àí1 ùëõ‚àí1
ùúë
A
U
U ùëî
1
‚à∂= ‚ãÄ ‚ãÄ
¬¨(ùëüùëñ ‚àß X(¬¨ùëîùëñ
(ùëü ùëó ‚àß ¬¨ùëîùëñ ‚àß X(¬¨ùëîùëñ
ùëó )) ))
ùëñ=0 ùëó=0
ùëó ‚â†ùëñ
states that the requests are granted in the same order in which they are
issued (without the discarded ones).
A desirable property is so-called starvation freedom - the fact that every
request is eventually granted. This is expressed by the following formula.

ùëõ‚àí1
ùúë2 ‚à∂= AG ‚ãÄ (ùëüùëñ ‚Üí AFùëîùëñ )
ùëñ=0
The conjunction ùúë0 ‚àß ùúë1 ‚àß ùúë2 of these three properties is then satisfiable iff
this specification of a scheduling system is viable.
The aim of the next section is to establish decidability of the main logical
decision
‚àó
problems for CTL , in particular the satisfiability problem. For this, it is
useful to
‚àó
observe that CTL formulas are essentially nestings of LTL formulas,
preceded by path quantifiers.
Lemma 14.10
‚àó
Let ùúë be a CTL
state formula over P . There are some ùëõ ‚àà N ,
propositions ùëì , . . . , ùëì
, . . . , ùúì
1
ùëõ‚àí1 all not belonging to P , LTL formulas ùúì1
ùëõ

and
‚àó
CTL state formulas ùúë , . . . , ùúë
1
ùëõ such t hat
‚Ä¢ ùúì
ùëñ
ùëñ
is an LTL formula over P ‚à™ { ùëì , . . . , ùëì
1
ùëñ‚àí1} for all
= 1, . . . , ùëõ ,
‚Ä¢ ùúë
, . . . , ùúì
ùëñ
= Eùúìùëñ [ùúìùëñ‚àí1/ ùëìùëñ‚àí1
1/ ùëì1] for all ùëñ = 1, . . . , ùëõ ,
‚Ä¢ ùúë is a Boolean combination of ùúë , . . . , ùúë
1
ùëõ .

Proof Let ùúë be given. Take ùëõ to be the number of existential path quantifiers
in ùúë, i.e. the number of distinct subformula of the form Eùúì. According to Def.
14.6, ùúë is a Boolean combination of such formulas, and each such ùúì is a
path formula, i.e. an LTL
formula over the original propositions or smaller state formulas. A
straightforward decomposition and introduction of new propositions to
abbreviate such smaller state formulas yields the desired ùúìùëñ and ùúëùëñ.
‚óª
380
14 Logics on Infinite Trees
14.2.2 Decidability
With the tools worked out so far, in particular decidability of satisfiability
for MSO
over Œ£-trees for a given Œ£ via the construction and analysis of NPTA, it is
not difficult
‚àó
to see that the satisfiability problem for CTL is also decidable. This can be
shown by
‚àó
embedding CTL effectively into MSO. And it is not a surprise that this is
possible:
‚àó
according to Lemma 14.10, CTL formulas are just nestings of path
quantified LTL

formulas. LTL can easily be translated into FO, and MSO is expressive
enough to quantify over sets and state that they must form a path. All that
needs to be done is to relativise the FO formulas obtained from the LTL
subformulas to the corresponding paths.
Theorem 14.11
‚àó
Let ùúë ‚àà CTL over some finite P . There is an MSO formula Œ¶ over P
the alphabet 2
such that ùêø(Œ¶) = ùêø(ùúë) and ‚à£Œ¶‚à£ = O(‚à£ùúë ‚à£) .
Proof
‚Ä≤
First we define a function tr
that translates an LTL formula into an MSO
ùëã , ùëß
formula over infinite trees with two free variables: a second-order variable
ùëã and a first-order variable ùëß. The resulting MSO formula cannot be
equivalent to the LTL
formula in a strict sense since they are interpreted over different kinds of
structures.
P
Instead, the following holds. Let ùë° be a tree over some alphabet 2
for some suitable
P

P , and ùëë be the uniform rank for all symbols in 2 . For a path ùúã = ùë£ , ùë£ , . .
.
0
1
and an
LTL formula ùúì we hav e
‚Ä≤
ùúã, ùëñ ‚äß ùúì
iff
ùë° , [ùëã ‚Ü¶ ùëÉ, ùëß ‚Ü¶ ùë£ùëñ ] ‚äß tr
(ùúì)
ùëã , ùëß
where ùëÉ ‚à∂= {ùë£ , ùë£ , . . .
0
1
}. Note that the satisfaction relation on the right-hand side is
the one for MSO over infinite trees, on the left it is the one for LTL where
the path P
ùúã is naturally interpreted as an ùúî-word over 2 .
In other words, if the second-order variable ùëã denotes a path, and ùëß
denotes a

‚Ä≤
node on this path, then tr
(ùúì) should express that the remaining part of this path
ùëã , ùëß
starting in ùëß satisfies ùúì. Before we can formulate the details of this
translation, we need an auxiliary predicate. We write ùëß ‚â§
ùë¶
ùëã
to say that the node addressed by ùë¶ is
further down the tree on the path ùëã than the node ùëß. This strict order
induced by the path ùëã is expressible in MSO as follows. Node ùë¶ is further
down the ùëã-path than ùëß if every set that contains the (necessarily unique)
successor of ùëß that belongs to ùëã, and is closed under successors that belong
to ùëã, must also contain ùë¶. This is formalised in MSO straightforwardly as
follows.
ùëë‚àí1
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
ùëß <
ùë¶
.

ùëã
‚à∂= ‚àÄùëç .( ‚ãÄ ‚àÄùëß succ ùëñ (ùëß, ùëß ) ‚àß ùëã (ùëß ) ‚Üí ùëç (ùëß )) ‚àß
ùëñ=0
ùëë‚àí1
‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤
‚Ä≤‚Ä≤
‚Ä≤‚Ä≤
(‚àÄùëß ‚àÄùëß
. ùëç (ùëß ) ‚àß ùëã (ùëß ) ‚àß ‚ãÅ succ
, ùëß
ùëñ (ùëß
) ‚Üí ùëç (ùëß
)) ‚Üí ùëç (ùë¶ )
ùëñ=0
Likewise, we can define the non-strict version of this order predicate by ùëß ‚â§
ùë¶

ùëã
‚à∂=
ùëß = ùë¶ ‚à® ùëß <
ùë¶
ùëã
.
14.2 Full Branching-Time Logic
381
With this, we can formulate the semantics of LTL in MSO, relativised to a
path ùëã straightforwardly as follows.
‚Ä≤
tr
(ùëû)
‚à∂=
ùëé(ùë•)
ùëã , ùëß
‚ãÅ
if ùëû ‚àà P
ùëé‚äÜP
ùëû‚ààùëé

‚Ä≤
‚Ä≤
‚Ä≤
tr
(ùúì
(ùúì
(ùúì
ùëã , ùëß
1 ‚à® ùúì2)
‚à∂= tr ùëã,ùëß
1) ‚à® tr ùëã, ùëß
2)
‚Ä≤
‚Ä≤
tr
(¬¨ùúì)
‚à∂= ¬¨
(ùúì)
ùëã , ùëß
tr ùëã,ùëß

ùëë‚àí1
‚Ä≤
‚Ä≤
tr
(Xùúì)
‚à∂= ‚àÉùë¶.
(ùúì)
ùëã , ùëß
‚ãÅ succ ùëñ (ùëß, ùë¶) ‚àß ùëã (ùë¶) ‚àß tr ùëã,ùë¶
ùëñ=0
‚Ä≤
‚Ä≤
tr
(ùúì
U ùúì
ùë¶ ‚àß ùëã (ùë¶) ‚àß
(ùúì
ùëã , ùëß
1
2)

‚à∂= ‚àÉùë¶.ùëß ‚â§ùëã
tr ùëã,ùë¶
2) ‚àß
‚Ä≤
‚àÄùë• .ùëß ‚â§
ùë•
ùë¶
ùëã
‚àß ùë• <ùëã
‚Üí tr
(ùúì
ùëã , ùë•
1)
‚Ä≤
We have ‚à£ tr
(ùúì)‚à£ = O(‚à£ùúì‚à£), at least if P is assumed to be fixed. Moreover, the ùëã , ùëß
branching degree ùëë is fixed as well.
‚àó
Building on this, we can devise a translation tr ùëß from CTL formulas into
MSO

formulas over infinite trees that are equivalent in the following sense. The
resulting P
formula tr ùëß (ùúë) contains a free first-order variable ùëß. For every tree ùë° over
2
we
have ùë° ‚àà ùêø(ùúë) iff ùë°, [ùëß ‚Ü¶ ùúÄ] ‚äß tr ùëß (ùúë). This is of course not strong enough to
be used inductively because the evaluation of temporal operators shifts the
point of reference further down in a tree, so we need a more general
correctness statement that takes arbitrary nodes into account for it to be
suitable as an inductive invariant. Indeed, we have that ùë°[ùë£] ‚äß ùúë iff ùë°, [ùëß ‚Ü¶
ùë£] ‚äß tr ùëß (ùúë) for any tree ùë° and node ùë£ ‚àà dom(ùë°) where ùë° [ùë£] is used to
denote the subtree rooted at node ùë£. Then we ha ve tr
ùëé
ùëß (ùëû )
‚à∂=
‚ãÅ
(ùë•)
ùëé‚äÜP
ùëû‚ààùëé
tr ùëß (ùúë1 ‚à® ùúë2) ‚à∂= tr ùëß(ùúë1) ‚à® tr ùëß(ùúë2)
tr ùëß (¬¨ùúë) ‚à∂= ¬¨ tr ùëß (ùúë)
‚Ä≤
tr ùëß (Eùúì) ‚à∂= ‚àÉùëã . Path(ùëã , ùëß) ‚àß tr

(ùúì)
ùëã , ùëß
where Path(ùëã, ùëß) states that ùëã is a path starting in node ùë•. Lemma 14.2
shows that this is expressible in MSO.
‚Ä≤
So the functions tr
allow us to translate a genuine LTL formula, and the
ùëã , ùëß
‚àó
functions tr ùëß then allow us to translate a CTL state formula whose path
subformulas
‚àó
are pure LTL formulas. At last, we make use of the decomposition property
for CTL
‚Ä≤
formulas laid out in Lemma 14.10 by extending the translation functions tr
,
ùëã , ùëß
defined for LTL formulas over P , to LTL formulas over the original
propositions in
‚àó

P and new auxiliary propositions ùëì that are being replaced by CTL state
formulas via
‚Ä≤
tr
( ùëì )[ùúë/ ùëì ]
‚à∂=
ùëã , ùëß
tr ùëß (ùúë )
‚àó
to obtain a translation for arbitrary CTL
formulas into MSO over infinite trees.
Correctness follows immediately from the observation that the requirements
on how
382
14 Logics on Infinite Trees
the two translation functions yield equivalent formulas in a particular
sense, are in fact induction invariants. The claim on the size of the resulting
MSO formula is also easily verified, provided that - as said above - the set
of underlying propositions and the branching degree of the underlying trees
are considered to be fixed.
In a final step, we need to fix the interpretation of the free variable ùëß in tr ùëß
(ùúë)
‚àó

for a CTL
formula ùúë, to the root of an underlying tree. So the MSO sentence Œ¶,
demanded by the theorem's statement, can be obtained as
ùëë‚àí1
Œ¶ ‚à∂= ‚àÉùëß.(¬¨‚àÉùë¶ ‚ãÅ succ ùëñ(ùë¶, ùëß)) ‚àß tr ùëß(ùúë )
ùëñ=0
which does not exceed the size bounds either and clearly fixes the
interpretation of ùëß to the root node.
‚óª
‚àó
An immediate consequence of this effective translation from CTL into
equivalent MSO sentences and Cor. 14.4 and 14.5 is decidability of the
satisfiability problem
‚àó
as well as other associated decision problems for CTL .
Corollary 14.12
‚àó
The satisfiability, validity and equivalence problems for CTL over ùëë -ary
trees are decidable.
The decision procedure obtained in this way is not optimal from a
complexity-theoretic point of view. Remember that satisfiability for MSO
over finite words cannot be solved in elementary time, and this of course
carries over to infinite words, finite and infinite trees since finite words can
easily be encoded in them or are special cases anyway. The height of the
tower of exponentials in the worst-case time complexity is due to the

alternations between existential and universal (second-order)
quantifications in an MSO formula or, equivalently, existential
quantification
‚àó
and negation. The translation from CTL
into MSO constructed in the proof of
Thm. 14.11 does not create formulas of bounded quantifier alternation
depth. Hence, it is not just due to the lack of a better worst-case runtime
analysis because of which
‚àó
we only get a non-elementary decision procedure for CTL this way.
By a direct translation into tree automata, or - very much related - a direct
formulation of the satisfiability problem as a parity game solving problem,
one can obtain a better complexity bound.
Proposition 14.13
‚àó
The satisfiability, validity and equivalence problems for CTL
are decidable in doubly exponential time.
This is optimal; these problems are indeed complete for 2ExpTime.
14.2.3 Expressiveness
Note that Prop. 14.13 does not only improve on Cor. 14.12 in terms of a
significantly better complexity bound. It is also more general in that it
makes a statement about
14.2 Full Branching-Time Logic

383
satisfiability over the class of trees of arbitrary (even infinite) branching
degree whereas the automata-theoretic method leading to Cor. 14.12
requires the underlying alphabet to be ranked first and thus only decides
these problems for a class of trees with fixed, and in particular bounded
branching degrees.
So one question that arises immediately with this is: is there a bound on the
‚àó
branching degree necessary to satisfy a satisfiable CTL formula? If this was
not the
‚àó
case, then Cor. 14.12 would only yield a semi-decision procedure for
general CTL
satisfiability without further involvement. However, such a bound does
indeed exist.
We state it here without a proof either since it requires a much deeper study
of the theory of temporal logics.
Proposition 14.14
‚àó
Let ùúë be a CTL formula with at most ùëõ distinct subformulas of the form Eùúì .
If ùúë is satisfiable then it is satisfied by a tree of branching-degree at most ùëõ
+ 1 .
Together with this result, Cor. 14.12 then also yields decidability over the
class of all trees.
Another question that arises with Thm. 14.11 is of course the one after the

‚àó
converse direction: is every MSO-definable property of infinite trees
already CTL -
‚àó
definable? The answer is no. CTL -definable properties are bisimulation-
invariant which, intuitively and on infinite trees not necessarily of the same
branching-degree,
‚Ä≤
can be explained as follows. Let ùë° be a tree and ùë° result from it by
successively
‚Ä¢ re-ordering the children under some node, including the subtrees under
them, and
‚Ä¢ duplicating subtrees or removing duplicates of subtrees.
‚Ä≤
‚àó
Then ùë° and ùë° cannot be distinguished by any CTL
formula. On the other hand,
MSO is able to count numbers of children to some degree, and is also
generally aware of the order in which the children of some node are given.
Hence, MSO is not bisimulation-invariant.
Example 14.15 Let Œ£ = {ùëé, ùëè, ùëê} with rk Œ£(ùëé) = 3, rk Œ£(ùëè) = rk Œ£(ùëê) = 1.
Consider
‚Ä≤
the two trees ùë° and ùë° defined by

‚Ä≤
ùë° = ùëé(ùë° , ùë° , ùë°
, ùë°
, ùë°
ùëè
ùëè
ùëê )
,
ùë°
= ùëé(ùë°ùëè
ùëê
ùëê )
,
ùë°ùëè = ùëè(ùë°ùëè ) ,
ùë°ùëê = ùëê( ùë°ùëê ) .
‚Ä≤
Then ùë° and ùë° are distinguished by the MSO formula
2
‚àÉùëü .(¬¨‚àÉùë¶ ‚ãÅ succ ùëñ (ùë¶, ùëü)) ‚àß ‚àÉùë•. succ 1(ùëü, ùë•) ‚àß ùëè(ùë•)
ùëñ=0

which is in fact already an FO formula. On the other hand, one can show
by induction
‚àó
‚Ä≤
on the structure of CTL formulas that ùë° ‚äß ùúë iff ùë° ‚äß ùúë for all ùúë.
384
14 Logics on Infinite Trees
14.3 The Modal ùùÅ-Calculus
We consider a second prominent logic for program specification purposes
that can be interpreted over infinite trees. The modal ùúá-calculus extends
modal logic with fixpoint quantifiers. Modal logic can be seen as what
remains of FO when it is restricted to the specification of bisimulation-
invariant properties, see the brief discussion on
‚àó
the expressive power of CTL above. There is, of course, a much simpler
approach via a very intuitive syntax, and bisimulation-invariance is then a
result following from the semantics rather than an imposition.
14.3.1 Modal Logic
Models of formulas continue to be trees, and for pragmatic purposes we
continue to define logical formulas on the basis of atomic propositions from
some set P from P
which we derive a tree alphabet 2 , at least when ‚à£P ‚à£ is finite. For
simplicity we assume that all alphabet symbols have some fixed rank ùëë ‚â• 1.
Again, the case of ùëë = 1 boils down to words and is only included as it is
not harmful.

Definition 14.16 Let P be a set of atomic propositions. Formulas of modal
logic (ML) over P are given by the grammar
ùúë
‚à∂‚à∂= ùëû ‚à£ ùúë ‚à® ùúë ‚à£ ¬¨ùúë ‚à£ ‚óá ùúë
where ùëû ‚àà P .
Besides the usual Boolean operators we introduce one more abbreviation:
‚óªùúë ‚à∂=
¬¨‚óá¬¨ùúë.
The size of an ML formula is given as the number of distinct subformulas in
it.
The operators ‚óá and ‚óª are read as "there is a successor", resp. "for all
successors."
They can be seen as versions of the operators succ ùëñ(ùë•, ùë¶) in FO/MSO,
restricted in two ways:
‚Ä¢ The order amongst the children of a node is irrelevant. There is no ùëñ-th
successor anymore, at least not for the logic. There is only some successor.
Of course some successor will reside at a particular position amongst the
children of a node, but the logic has no means to distinguish their indices
anymore.
‚Ä¢
‚àó
As with temporal logics like CTL , formulas are interpreted in a node of a
tree.
This takes over the role of the variable ùë• in succ ùëñ(ùë•, ùë¶), and then ùë¶ is not
needed either because the interpretation of a formula of the form ‚óáùúë in an

implicitly given node ùë• entails the interpretation of ùúë in a successor node ùë¶
which is now the implicitly given nameless node. This is why ML does not
contain any (first-order) variables, but this is of course not new as the same
mechanism is used in
‚àó
CTL .
14.3 The Modal ùúá-Calculus
385
‚àó
ML can also be obtained as the fragment of CTL that forbids the use of the
operator U, at least with some simple syntactical equivalence-preserving
transformations.
‚àó
Then ‚óá and ‚óª are nothing more than EX and AX in CTL .
Formulas of ML are interpreted in a node of a tree, very much in the same
way
‚àó
as it is done for CTL .
Definition 14.17
P
Let P be a finite set of propositions and Œ£ ‚à∂= 2
with rk Œ£(ùëé) = ùëë
ùúî

for all ùëé ‚äÜ P and some ùëë ‚â• 1. The satisfaction relation between a tree ùë° ‚àà
TŒ£ and a node ùë£ ‚àà dom(ùë°) on one side and an ML formula ùúë on the other is
explained inductively as follows.
ùë° , ùë£ ‚äß ùëû
iff
ùëû ‚àà ùë°(ùë£)
ùë° , ùë£ ‚äß ùúë ‚à® ùúì
iff
ùë° , ùë£ ‚äß ùúë or ùë°, ùë£ ‚äß ùúì
ùë° , ùë£ ‚äß ¬¨ùúë
iff
ùë° , ùë£ /
‚äß ùúë
ùë° , ùë£ ‚äß ‚óáùúë
iff
there is ùëñ < ùëë s.t. ùë°, ùë£ùëñ ‚äß ùúë
A tree ùë° satisfies an ML formula ùúë, written ùë° ‚äß ùúë, if ùë°, ùúÄ ‚äß ùúë. The language of
an ML formula ùúë is, as usual, ùêø(ùúë) ‚à∂= {ùë° ‚à£ ùë° ‚äß ùúë}. Other semantical concepts
like equivalence between formulas etc. are defined in the usual way.
It is not hard to see that ML can be embedded straightforwardly into FO
over trees, simply because the semantics of an ML formula is pretty much
given as an FO

formula over trees, and the root of a tree can be addressed in FO. We omit a
formal proof as it would only repeat those two observations.
Theorem 14.18
‚Ä≤
P
For every ùúë ‚àà ML over P there is a ùúë ‚àà FO over 2
such that
‚Ä≤
‚Ä≤
ùêø (ùúë ) = ùêø(ùúë) and ‚à£ùúë ‚à£ = O(‚à£ ùúë‚à£) .
It should not be surprising to hear that ML is not as expressive as FO,
exactly for the lack of ability to distinguish bisimilar trees, i.e. those that
only differ from each other through the order and multiplicities of subtrees
at every node. Ex. 14.15,
‚àó
giving two trees that are distinguishable in FO but not in CTL , covers ML
as well.
‚àó
This is also not a surprise as ML can equally easily be embedded into CTL .
Theorem 14.19
‚Ä≤
‚àó

For every ùúë ‚àà ML over P there is a ùúë ‚àà CTL
over P such that
‚Ä≤
‚Ä≤
ùêø (ùúë ) = ùêø(ùúë) and ‚à£ùúë ‚à£ = O(‚à£ ùúë‚à£) .
The proof details are left as an exercise. Again, a natural question asks
about
‚àó
the converse direction. CTL is strictly more expressive than ML, though.
The key observation for a proof of the following theorem is: any given ùúë ‚àà
ML contains a finite number of modal operators only. In fact, it has a finite
modal depth md(ùúë) which is the maximal number of modal operators
occurring on any path in the syntax tree of ùúë .
Theorem 14.20
P
Suppose that ‚à£P ‚à£ ‚â• 1 . There are tree languages over 2
that are
‚àó
definable in CTL which are not definable in ML.
386
14 Logics on Infinite Trees
Proof Let P = {ùëù, . . .}. Consider the language ùêø of trees containing a ùëù-
node some-

‚àó
where. We have ùêø = ùêø(EFùëù), so this language is CTL -definable. A
straightforward
‚Ä≤
induction on the structure of ML formulas ùúë shows: let ùë°, ùë° be two ùëë-ary trees
such
‚Ä≤
‚àó
‚Ä≤
that ùë°(ùë£) = ùë° (ùë£) for all ùë£ ‚àà [ùëë] with ‚à£ùë£‚à£ ‚â§ md(ùúë) + 1. Then ùë° ‚äß ùúë iff ùë° ‚äß ùúë.
Now suppose there was an ML formula ùúë such that ùêø(ùúë) = ùêø. Then it must
have
‚Ä≤
some modal depth ùëò ‚à∂= md(ùúë). Consider the two trees ùë° , ùë°
ùëò
with
ùëò
‚éß
‚é™
‚é™‚àÖ
, if ‚à£ùë£‚à£ ‚â§ ùëò

ùë° ùëò (ùë£)
‚à∂= ‚é®
‚é™
‚é™{ ùëù}
, otherwise
‚é©
‚Ä≤
‚àó
‚Ä≤
and ùë° (ùë£) = ‚àÖ for all ùë£ ‚àà [ùëë] . Clearly, we have ùë° ‚àà ùêø and ùë° /
‚àà ùêø. On the other
ùëò
‚Ä≤
hand, the previous induction shows that ùë°ùëò ‚àà ùêø(ùúë) iff ùë°
‚àà ùêø(ùúë). Thus, ùêø(ùúë) ‚â† ùêø
ùëò
contradicting the assumption.
‚óª
14.3.2 Fixpoint Quantifiers

The previous theorem shows that it is debatable whether ML should be
considered as a logic for infinite trees since every formula can only assess
the first ùëò levels of a tree for some fixed ùëò . One may argue that ML is
therefore rather a logic for finite trees, especially since the interpretation of
the modal operators goes well with trees that appear to be too shallow: a
formula ‚óáùúë, interpreted in a node with no children, would simply evaluate
to false, and consequently ‚óªùúë would evaluate to true in this case regardless
of ùúë.
However, modal logic is not our primary goal here; that is its extension by
fixpoint quantifiers, resulting in the logic known as the modal ùúá-calculus. It
is capable of expressing such properties like the one used in the proof of
Thm. 14.20, i.e. fixpoint quantifiers must provide a mechanism for
accessing nodes at arbitrary depth in a tree. And then infinite trees are of
course a suitable model for the interpretation of such formulas.
In other words, we are searching for a method to extend ML in a generic
way so that properties like EFùëù become definable. By generic we mean the
addition of a small and certainly finite set of operators in order to not just
express EFùëù but all sorts of other properties that may be useful for program
specification purposes. The
‚àó
next fair question is: why not simply take CTL
which is an extension of ML, cf.
‚àó
Thm. 14.19? One could say that CTL results from ML by the addition of an
infinite set of operators, namely Eùúì for any path formula ùúì. Of course some
regularity in the syntax is given since path formulas themselves are only
built from finitely many
‚àó

operators. However, in the strict sense, it is correct to say that CTL
achieves higher expressive power through infinitely many operators on the
level of formulas that are interpreted in a node of a tree.
The modal ùúá-calculus, to be introduced in the following, does in fact provide
such an extension using only a single operator (and its dual version). It
looks like we also have to introduce second-order variables, which could be
argued to be an extension
14.3 The Modal ùúá-Calculus
387
by infinitely many operators, but they are in fact already there. They are
just not that visible. Take an ML formula ùúë over some propositions P = {ùëù , .
. . , ùëù
1
ùëõ }. A model
is a tree whose nodes are labelled with subsets of P or, equivalently, with
vectors ùëõ
from {0, 1} representing subsets of such ordered sets.
This can also be seen as a tree over a singleton alphabet {‚óè} whose nodes
are additionally labelled with such subsets. We also simply write 1 for such
an alphabet with an anonymous symbol in it. And this change of perspective
is of course something that has occurred several times before, in particular
when translating MSO
formulas with free second-order variables into automata over an extended
alphabet, ùúî
cf. Sect. 2.2.2 for example. So an interpretation ùë° ‚àà T2P for an ML formula
over ùúî

P is nothing more than an interpretation consisting of a tree ùë°0 ‚àà T1 ,
namely the tree that is obtained from ùë° by removing all labels, together with
an assignment ùêº ‚à∂ P ‚Üí 2 dom(ùë°0). Hence, propositions are nothing more
than second-order variables.
It is merely a matter of taste that distinguishes them, namely whether they
should by interpreted by the labels in the tree, or by additional labels on the
tree. This is no structural difference, though, just one of notation.
Moreover, there is no need to restrict ourselves to the two extremes, i.e. to
either regard them all as atomic propositions or all as second-order
variables. It is perfectly possible to regard some as propositions and others
as variables. In the end, they all have to be interpreted by a set of nodes in
a tree for a formula to evaluate to true or false. This is why we extend the
syntax of ML by second-order variables from some set V2 = {ùëã, ùëå , . . .}
that are treated syntactically just like propositions, i.e. ‚óá(ùëù ‚àß ‚óªùëã) is an
ML formula for example. Note that these variables are in fact monadic
second-order variables, even though they look like they are 0-ary. But this is
only the appearance resulting from the fact that in modal logic, there is
always a single anonymous point of reference.
The distinction between propositions ùëù and second-order variables ùëã is
only made so that it is clear what interpretation an underlying tree needs to
provide, namely values for the propositions ùëù. The interpretation for
variables ùëã is supposed to be obtained during the evaluation process,
namely through (fixpoint) quantifiers.
We extend the semantics accordingly. A formula ùúë with second-order vari-ùúî
ables ùëã , . . . , ùëã
1
ùëõ
is interpreted in a tree ùë° ‚àà T2P with the aid of an assignment
ùêº ‚à∂ {ùëã , . . . , ùëã

1
ùëõ } ‚Üí 2 dom(ùë° ) in the usual way :
ùë° , ùêº , ùë£ ‚äß ùëã
iff
ùë£ ‚àà ùêº (ùëã )
Def. 14.17 can easily be rewritten accordingly by passing ùêº recursively
through the clauses for subformulas.
The next necessary shift in perspective reveals such formulas with free
variables to represent functions on the powerset of the domain of a tree.
Definition 14.21
ùúî
Let ùúë be an ML formula over P and V2, ùëã ‚àà V2, ùë° ‚àà T2P and
ùë°
ùêº ‚à∂ V2 ‚Üí 2 dom(ùë°). This induces a mapping [[ùúë]] ‚à∂ 2 dom(ùë°) ‚Üí 2 dom(ùë°) via
ùêº
ùë°
[[ùúë]] (ùëà )
‚à∂= {ùë£ ‚àà dom(ùë°) ‚à£ ùë°, ùêº[ùëã ‚Ü¶ ùëà], ùë£ ‚äß ùúë}
ùêº
388
14 Logics on Infinite Trees

where ùêº[ùëã ‚Ü¶ ùëà] is the update of ùêº at position ùëã with ùëà, i.e.
‚éß
‚é™
‚é™ùëà
, if ùëå = ùëã ,
ùêº [ùëã ‚Ü¶ ùëà ](ùëå )
‚à∂= ‚é®
‚é™
‚é™ùêº (ùëå )
, otherwise
‚é©
for all ùëå ‚àà V2. ùë°
Thus, [[ùúë]] returns, given a set ùëà, the set of all nodes ùë£ in ùë° that satisfy ùúë,
provided ùêº
that the variable ùëã is interpreted as ùëà. We also write the result of this
function, when ùë°
applied to ùëà, as [[ùúë]]
.
ùêº [ùëã‚Ü¶ùëà]
‚Ä≤
ùë°

ùëà , ùëà
‚äÜ
(ùë° )
Such a function is monotonic on
if for all
dom
, we have
‚Ä≤
ùë°
ùë°
ùëà ‚äÜ ùëà
implies
[[ùúë]]
‚äÜ [[ùúë]]
.
ùêº [ùëã‚Ü¶ùëà]
ùêº [ùëã‚Ü¶ùëà‚Ä≤ ]
ML formulas define monotonic mappings in this respect, at least when the
use of the negation symbol is restricted. We say that ùúë is positive in ùëã if all
occurrences of ùëã are under an even number of negation symbols in the
syntax tree of ùúë. The proof of the following lemma is by a straightforward
induction on the structure of ML formulas. Details are left as an exercise.

Lemma 14.22
ùúî
Let ùúë be an ML formula over P and V2 , ùëã ‚àà V2 , ùë° ‚àà T2P and ùë°
ùêº ‚à∂ V2 ‚Üí 2 dom(ùë°) . If ùúë is positive in ùëã then ùëà ‚Ü¶ [[ùúë]]
is monotonic.
ùêº [ùëã‚Ü¶ùëà]
In order to let an ML formula ùúë with a second-order variable ùëã - or rather
its ùë°
associated mapping ùëà ‚Ü¶ [[ùúë]]
- define properties of nodes in a tree ùë°, such
ùêº [ùëã‚Ü¶ùëà]
mappings need to give us particular values in terms of some designated set
of nodes in a tree. A natural way to obtain a set of nodes from such a
mapping is given by ùë°
fixpoints: consider the mapping ùëà ‚Ü¶ [[ùúë]]
as an equation
ùêº [ùëã‚Ü¶ùëà]
ùë°
ùëà
= [[ùúë]]
(14.1)

ùêº [ùëã‚Ü¶ùëà]
for given ùúë, ùë°, ùêº and ùëã, i.e. as the definition of a set ùëà ‚äÜ dom(ùë°) that equals ùë°
[[ùúë]]
. This immediately raises further questions: do such sets exists? If they ùêº
[ùëã‚Ü¶ùëà]
are not guaranteed to exist at least for a syntactically definable class of
formulas then this mechanism is not good as an extension of ML because it
would lead to formulas with undefined truth values. Moreover, even if such
values always exist, are they unique? If they can be guaranteed to exist in
any case and be unique then this does indeed provide a mechanism for
extending ML with certain expressive power as the following example
shows. If they exist but are not necessarily unique, then we may have to
refine the selection of such values, i.e. let the semantics of these new
operators choose certain solutions to equation (14.1).
Example 14.23 Let P = {ùëù} and ùúë(ùëã, ùëå ) = (ùëù‚àß‚óáùëã)‚à®‚óáùëå . Let ùë° be an
arbitrary tree P
over Œ£ = 2 . For simplicity, we assume its branching degree to be 2. The
argument for other values is exactly the same, though.
There are two second-order variables in ùúë, giving us the two equations ùë°
ùëà
= [[( ùëù ‚àß ‚óáùëã ) ‚à® ‚óáùëå ]]
(14.2)
ùêº [ùëã‚Ü¶ùëà]
14.3 The Modal ùúá-Calculus
389

ùë°
ùëà
= [[( ùëù ‚àß ‚óáùëã ) ‚à® ‚óáùëå ]]
(14.3)
ùêº [ùëå ‚Ü¶ùëà]
for any given mapping ùêº ‚à∂ {ùëã, ùëå } ‚Üí 2 dom(ùë°). In the first case, it is of
course sufficient for ùêº to provide a value for ùëå but not necessarily for ùëã,
and vice-versa in the second case.
We consider the second equation first. We claim that the set
+
ùëåmin
‚à∂= {ùë£ ‚àà dom(ùë°) ‚à£ ‚àÉùë§ùëñ ‚àà {0, 1} s.t. ùëù ‚àà ùë°(ùë£ùë§) and ùë£ùë§ùëñ ‚àà ùêº(ùëã )}
ting
consis
of all ancestors of a node that is labelled ùëù and which has a successor
belonging to ùëã is in fact a solution to equation (14.3). For this we need to
show ùë°
that ùëåmin = [[(ùëù ‚àß ‚óáùëã) ‚à® ‚óáùëå ]]
. For the direction from left to right take
ùêº [ùëå ‚Ü¶ùëåmin]
+
a node ùë£ and a suffix ùë§ùëñ ‚àà {0, 1}

witnessing that ùë£ ‚àà ùëå0. We then have ùë£ ‚àà
ùë°
[[( ùëù ‚àß ‚óáùëã ) ‚à® ‚óáùëå ]]
by induction on the length of ùë§. The opposite direction
ùêº [ùëå ‚Ü¶ùëåmin]
is shown in the same wa y.
The set ùëåmin is not the only solution to equation (14.3), though. The set
ùëåmax ‚à∂=
dom(ùë°) is also a solution. There are many more; any solution is obtained as
the union of ùëåmin with an arbitrary set of full paths starting in the root of
the underlying tree.
So the names ùëåmin and ùëåmax are not chosen coincidentally. These are in
fact the least and greatest solutions in 2 dom(ùë°) with sets of nodes partially
ordered by the subsumption relation '‚äÜ', i.e. they are the least and greatest
fixpoints of this equation, depending on ùêº of course. Out of all fixpoints,
ùëåmin stands out as a perhaps particularly interesting one, as it defines
exactly the set of nodes which can reach a ùëù-node that has a successor in
ùëã. This set is not ML-definable. The property ùëåmax is of course just the
universal property that is already ML-definable by the formula tt.
Now say that equation (14.3) defines the set ùëåmin, still depending on a
value for ùëã
of course. Consider equation (14.2). The way that ùëã is used in ùúë is not too
dissimilar to the way that ùëå is used. Hence, the reasoning for finding
fixpoints of (14.2) is similar. The smallest fixpoint ùëãmin consists of nodes
from which there is a finite path through ùëù-nodes (including the starting
node) to an immediate predecessor of a node in ùëå . The greatest fixpoint is
obtained by adding all nodes that lie on a path through ùëù-nodes only.

The solutions to (14.3) depend on a value for ùëã which is supposedly fixed
as a solution to (14.2) which depends on a value of ùëå that, in turn, is getting
fixed through equation (14.3). So in order to let formula ùúë denote a well-
defined value, we need not only choose which kind of fixpoint is supposed to
be defined for each variable. We also need to impose an order between
these two equations. One way of doing so is to take the greatest fixpoint of
(14.2) and give this equation priority over (14.3) which is supposed to give
a least fixpoint. The largest set ùëãmax that ùë°
equals [[(ùëù ‚àß ‚óáùëã) ‚à® ‚óáùëå ]]
where ùëåmin is the least set that equals
[ùëã‚Ü¶ùëãmax ,ùëå ‚Ü¶ùëåmin]
ùë°
[[( ùëù ‚àß ‚óáùëã ) ‚à® ‚óáùëå ]]
for any given value of ùëã, is the set of all nodes from
ùêº [ùëå ‚Ü¶ùëåmin]
which there is a path that visits ùëù-nodes infinitely often.
In order to comprehend the final conclusion in this example, some more
fixpoint theory may be needed. The theory of fixpoint approximations is
particularly helpful.
It states that least fixpoints can be obtained as limits of an iterative process
starting
390
14 Logics on Infinite Trees
from the least set ‚àÖ, and greatest fixpoints can dually be obtained by
iterating from above, starting with dom(ùë°). So in order to determine this set

defined by a greatest solution for ùëã and a least solution for ùëå depending on
ùëã, one can fix ùêº(ùëã) = dom(ùë°) and determine the least solution ùëå 1
min of (14.3) under this ùêº . It consists of all nodes
that are ancestors of a ùëù-node. Then let ùêº(ùëã) ‚à∂= ùëå 1
min and determine the least solution
of (14.3) again. This yields the set ùëå 2
min of all nodes from which there is a path
visiting at least two ùëù-nodes. The ùëñ-th iteration defines the set of all nodes
from which there is a path visiting at least ùëñ ùëù-nodes. Note that this forms a
descending chain of sets of nodes, i.e. every iteration potentially removes
nodes. The theory of fixpoint approximations states that the greatest fixpoint
of the underlying equation is the limit of this chain, i.e. the set of all nodes
that do not get removed in any iteration which is exactly the set of all nodes
from which there is a path containing an infinite number of ùëù-nodes.
The example provides some questions to be answered when designing the
syntax of an extension of ML by operators for fixpoints of modal equations:
we need to state the kinds of fixpoints that are to be selected in each case,
and when using multiple second-order variables, the order in which they
depend on each other needs to be fixed. Neither is particularly problematic:
we introduce two operators ùúá and ùúà that syntactically act as quantifiers for
second-order variables and provide the distinction between least and
greatest fixpoints. The second point is naturally addressed by the
subformula order, as it is the case with quantification in MSO for instance:
inner quantifiers depend on the values for variables quantified further
outside in a formula.
The formula ùúà ùëã .ùúáùëå .(ùëù ‚àß ‚óáùëã) ‚à® ‚óáùëå then states "there is a path on which ùëù
occurs infinitely often."
14.3.3 Syntax and Semantics

We are using the terms "the least" and "the greatest fixpoint" as if they
were always unique. This is in fact the case but it requires a little bit more
insight, needed to provide a well-defined semantics for the extension of ML
by such quantifiers. We introduce the syntax first as it makes it easier to
reason about semantical issues like uniqueness afterwards.
Definition 14.24 Let P be a set of atomic propositions and V2 be a set of
second-order variables. Formulas of the modal ùúá -calculus Lùúá are given by ùúë
‚à∂‚à∂= ùëû ‚à£ ùëã ‚à£ ùúë ‚à® ùúë ‚à£ ¬¨ùúë ‚à£ ‚óáùúë ‚à£ ùúá ùëã . ùúë
where ùëû ‚àà P and ùëã ‚àà V2. Additionally, every formula ùúë must satisfy the
positivity requirement: take any subformula ùúá ùëã .ùúì of ùúë. Then every
occurrence of the variable ùëã must be under an even number of negation
symbols inside of ùúì.
Apart from the usual other Boolean connectives and the modal operator ‚óª
we introduce the abbreviation ùúà ùëã .ùúë ‚à∂= ¬¨ùúá ùëã .¬¨ùúë[¬¨ùëã/ùëã] where ùúë[¬¨ùëã/ùëã] is the
formula
14.3 The Modal ùúá-Calculus
391
that results from ùúë by replacing every free occurrence of ùëã by ¬¨ùëã. Here, ùúá ùëã
acts as a binder for the variable ùëã, i.e. occurrences of ùëã under this operator
are not free.
It is not strictly necessary but good practice to require that every variable
gets bound at most once in a formula.
Example 14.25 Consider
ùúë1 ‚à∂= ¬¨ùúáùëã .¬¨ùúáùëå .¬¨(¬¨ùëù ‚à® ¬¨‚óá¬¨ùëã) ‚à® ‚óáùëå .
It is well-formed in that it satisfies the positivity requirement. However, ùúë2
‚à∂=

¬¨ùúá ùëã .¬¨ùúá ùëã .¬¨(¬¨ ùëù ‚à® ¬¨‚óá¬¨ ùëã ) ‚à® ‚óáùëã does not, even though it results from ùúë1
by a simple renaming of ùëå to ùëã. This introduces a new variable capturing,
though, and now there are three negation symbols in the syntax tree
between the occurrence of ùëã in the left disjunct and the binding operator
which is the inner ùúá ùëã. In ùúë1, the corresponding binding operator is the outer
one, and there are four negation symbols on the corresponding part in the
syntax tree, i.e. an even number.
One has to be a bit careful with the introduced abbreviations. First, by
using the equivalences ùúë ‚àß ùúì ‚â° ¬¨(¬¨ùúë ‚à® ¬¨ùúì), ‚óªùúë ‚â° ¬¨‚óá¬¨ùúë and ùúà ùëã .ùúë ‚â° ¬¨ùúá ùëã
.¬¨ùúë[¬¨ùëã/ùëã]
to rewrite formulas, one only introduces or removes an even number of
negation symbols on every syntax path between a variable and its binder.
Hence, it does not matter whether the positivity requirement is demanded
within the original syntax
‚Ä≤
or in the extended syntax with abbreviations. Take, for instance, ùúë ‚à∂= ùúà ùëã .ùúáùëå .
(ùëù ‚àß
1
‚óáùëã ) ‚à® ‚óáùëå which results from ùúë1 by strict introduction of the abbreviations
ùúà and ‚àß
wherever possible. It clearly satisfies the positivity requirement because it
does not contain any negation symbols at all. When rewriting ùúë2 in the same
way we obtain
‚Ä≤
ùúë
‚à∂= ùúà ùëã . ùúá ùëã .( ùëù ‚àß ‚óá¬¨ùëã ) ‚à® ‚óáùëã which does not satisfy the positivity
requirement 2

because it contains one negation symbol on a path between a variable and
its binder.
Likewise, one must not discount hidden negations in abbreviations like '‚Üí
'.
The reason for the positivity requirement is monotonicity of the semantic
function associated with a formula containing a free variable. In order to
formulate this precisely, we need to give semantics to formulas of Lùúá, and in
order to appeal to the rather vague statement of ùúá ùëã .ùúë denoting "the least
set of nodes that solves the equation ùëã = ùúë(ùëã)" (which would somehow rely
on the introduction of the mentioned function) we present a fundamental
result in fixpoint theory known as the Knaster-Tarski Theorem (Prop. 14.27
below). It allows us to specify least and greatest solutions of such equations
concisely .
Recall that a lattice is a partial order (ùëÄ, ‚â§) in which infima ùë• ‚äì ùë¶ and
suprema ùë• ‚äî ùë¶ exist for all ùë•, ùë¶ ‚àà ùëÄ. By associativity, distributivity and
idempotence of ‚äì
and ‚äî, infima ‚äì ùëÅ and suprema ‚äì ùëÅ exist for all finite ùëÅ ‚äÜ ùëÄ. The
lattice (ùëÄ, ‚â§) is complete if infima and suprema also exist for arbitrary
subsets, in particular infinite ones. It is a standard exercise to show that
powersets form complete lattices.
Lemma 14.26
ùëÄ
Let ùëÄ be an arbitrary set. Then (2
, ‚äÜ) is a complete lattice with
infima and suprema given by ‚à© and ‚à™ , resp. ‚ãÇ and ‚ãÉ .
392
14 Logics on Infinite Trees

An example of an incomplete lattice is the set of all finite subsets of an
infinite set. Let 2N
,
fin ‚à∂= {ùëÅ ‚äÜ N ‚à£ ‚à£ùëÅ ‚à£ < ‚àû}. Then (2N
fin ‚äÜ) is a lattice but it is not complete.
The following proposition is known as the Knaster-Tarski Theorem .
Proposition 14.27 Let (ùëÄ, ‚â§) be a complete lattice, ùëì ‚à∂ ùëÄ ‚Üí ùëÄ be
monotonic, i.e.
ùëì (ùë•) ‚â§ ùëì (ùë¶) whenever ùë• ‚â§ ùë¶ for arbitrary ùë•, ùë¶ ‚àà ùëÄ .
a) ùëì has a unique least fixpoint ùúá ùëì and a unique greatest fixpoint ùúà ùëì .
b) We have ùúá ùëì = ‚äì{ùë• ‚àà ùëÄ ‚à£ ùëì (ùë•) ‚â§ ùë•} and ùúà ùëì = ‚äî{ùë• ‚àà ùëÄ ‚à£ ùë• ‚â§ ùëì (ùë•)} .
We can now use Lemma 14.26 and Prop. 14.27 in order to give formulas of
Lùúá
ùúî
a well-defined meaning when interpreted in nodes of a tree ùë° ‚àà TŒ£
for a ranked
P
alphabet Œ£ of the form 2 . The set giving rise to a powerset lattice according
to Lemma 14.26 is just dom(ùë°).
Definition 14.28
P
Let P be given and Œ£ ‚à∂= 2

be ranked with ùëë = rk Œ£(ùëé) for all
ùúî
ùë°
ùëé ‚äÜ P . Let ùë° ‚àà TŒ£ . The denotation [[ùúë]] of an L
ùêº
ùúá
formula ùúë over P and some V2
in ùë° under a variable assignment ùêº ‚à∂ V2 ‚Üí 2 dom(ùë°) is defined inductively
as follo ws.
ùë°
[[ùëû]]
‚à∂= {ùë£ ‚àà dom(ùë°) ‚à£ ùëû ‚àà ùë°(ùë£)}
ùêº
ùë°
[[ùëã ]]
‚à∂= ùêº (ùëã )
ùêº
ùë°
ùë°
ùë°

[[ùúë ‚à® ùúì]]
‚à∂= [[ùúë]] ‚à™ [[ùúì]]
ùêº
ùêº
ùêº
ùë°
ùë°
[[¬¨ùúë]]
‚à∂= dom(ùë°) ‚àñ [[ùúë]]
ùêº
ùêº
ùë°
ùë°
[[‚óáùúë]]
‚à∂= {ùë£ ‚àà dom(ùë°) ‚à£ ‚àÉùëñ < ùëë s.t. ùë£ùëñ ‚àà [[ùúë]] }
ùêº
ùêº
ùë°
ùë°
[[ùúá ùëã .ùúë]]

‚à∂= ‚ãÇ{ùëâ ‚äÜ dom(ùë°) ‚à£ [[ùúë]]
‚äÜ ùëâ }
ùêº
ùêº [ùëã‚Ü¶ùëâ ]
Here, ùêº[ùëã ‚Ü¶ ùëâ ] denotes the variable interpretation that maps ùëã to ùëâ and
ùëå to ùêº(ùëå ) for any ùëå ‚â† ùëã.
ùë°
ùë°
We also write ùë°, ùë£, ùêº ‚äß ùúë if ùë£ ‚àà [[ùúë]] . Since [[ùúë]] only depends on the ùêº-
values of ùêº
ùêº
the free variables in ùúë, we also simply write ùë°, ùë£ ‚äß ùúë instead of ùë°, ùë£, [] ‚äß ùúë for
closed formulas ùúë.
While the path to a semantics for Lùúá via the Knaster-Tarski Theorem avoids
problems with ill-defined formulas, it does not provide a way to easily grasp
the meaning of such formulas. An easier grasp of intuition is obtained when
defining the semantics via parity games, as it is done with the acceptance
games for tree automata.
The two ways are equivalent, i.e. formulas denote the same sets of nodes
under both semantics. The game-theoretic semantics, however, comes with
an increased difficulty to argue that satisfiability is decidable which is
almost trivial for the denotational semantics, see below. This is why we stick
to the denotational semantics and aid the intuition for reading formulas by
stating that least fixpoints should be read as necessarily terminating
recursion, and greatest fixpoints as potentially infinite recursion. This is
also reflected in another general theorem from the theory of fixpoints,
known as Kleene's Fixpoint Theorem.

A chain in a partial order (ùëÄ, ‚â§) is a sequence ùë•0 < ùë•1 < ùë•2 < . . . of
elements from ùëÄ. Its length is measured using ordinal numbers in general.
The height of
14.3 The Modal ùúá-Calculus
393
a lattice is the supremum of the length of any chain in it. The Kleene
Fixpoint Theorem then entails that the least fixpoint of a monotone function
ùëì ‚à∂ ùëÄ ‚Üí ùëÄ on a complete lattice of height at most ùúî can be obtained as the
limit of the sequence
, ùëì (), ùëì ( ùëì ()), . . . where is the least element of ùëÄ.
Proposition 14.29 Let (ùëÄ, ‚â§) be a complete lattice of height at most ùúî , ùëì ‚à∂
ùëÄ ‚Üí
ùëñ
ùëÄ
monotonic. Then ‚äî
ùëì
()
ùëñ‚â•0
is the least fixpoint of ùëì where ùëì 0() ‚à∂= and ùëñ+
ùëñ
ùëì
1() ‚à∂= ùëì ( ùëì ()) .
ùúî

The scenario that we are in does not strictly meet these criteria: for a tree ùë°
‚àà TŒ£ , the height of the complete lattice (2 dom(ùë°), ‚äÜ) is generally more
than ùúî. However, one can show that, for any Lùúá formula ùúë(ùëã) with a free
variable ùëã and every finitely branching tree ùë°, the limit of the chain ùëâ0 ‚äÜ
ùëâ1 ‚äÜ ùëâ2 ‚äÜ . . . of length at ùë°
most ùúî, where ùëâ0 ‚à∂= ‚àÖ and ùëâùëñ+1 ‚à∂= [[ùúë]]
, is the least fixpoint of the mapping
ùêº [ùëã‚Ü¶ùëâùëñ ]
ùë°
ùëâ ‚Ü¶ [[ùúë]]
. The ùëñ-th element of this chain is also known as the ùëñ-th approximant ùêº
[ùëã‚Ü¶ùëâ ]
of the fixpoint at the limit.
This iterative approach can be used to understand the meaning of formulas.
Example 14.30 Let P = {ùëû, . . .}. The language of all trees that contain a ùëû-
node is definable in Lùúá via ùúá ùëã .ùëû ‚à® ‚óáùëã. To see that this is indeed the case,
consider an P
arbitrary tree ùë° over 2
and the approximants ùëâ , ùëâ , . . .
0
1
for this fixpoint formula. We
ùë°

ùë°
have ùëâ0 = ‚àÖ by definition and then ùëâ1 ‚à∂= [[ùëû ‚à® ‚óáùëã]]
= [[ùëû ‚à® ‚óáff]]
. Since
[ùëã‚Ü¶‚àÖ]
[]
‚óáff ‚â° ff and ùëû ‚à® ff ‚â° ùëû we get that ùëâ1 consists of exactly the set of ùëû-nodes
in dom(ùë°).
ùë°
Then consider ùëâ2 ‚à∂= [[ùëû ‚à® ‚óáùëã]]
. Since ùëâ
[ùëã‚Ü¶ùëâ
1 is clearly defined by the formula
1 ]
ùë°
ùëû, we also have ùëâ2 = [[ùëû ‚à® ‚óáùëû]] , so ùëâ
[]
2 consists of all nodes that satisfy ùëû or have an
immediate successor that satisfies ùëû. We write [] for the empty variable
assignment which is clearly sufficient to interpret formulas with no free
variables. Note also that ùë°

ùëâ2 = ùëâ1 ‚à™ [[‚óáùëû]]
which is not a surprise since the approximants are bound to form
[]
an ascending c hain.
This can be iterated to reveal that ùëâùëñ consists of all nodes which satisfy ùëû
or have a successor which satisfies ùëû or itself has a successor, and so on.
Likewise, ùëâùëñ extends ùëâùëñ+1 by those nodes which reside ùëñ ‚àí 1 levels above a
ùëû-node. In other words, ùëâùëñ
consists of those nodes from which a ùëû-node can be reached in at most ùëñ ‚àí
1 steps.
‚àó
The limit of the chain ùëâ
ùëâ
0 ‚äÜ ùëâ1 ‚äÜ ùëâ2 ‚äÜ . . . is ùëâ
‚à∂= ‚ãÉùëñ‚â•0 ùëñ, consisting of all nodes
in ùë° from which a ùëû-node is reachable. According to the Kleene Fixpoint
Theorem, it ùë°
coincides with [[ùúá ùëã .ùëû ‚à® ‚óáùëã]] . Hence, when interpreted in the root of ùë°, ùúá ùëã
.ùëû ‚à®‚óáùëã
[]
states that some node in ùë° must be a ùëû-node.
Now consider ùúà ùëã .ùëû‚à®‚óáùëã. Greatest fixpoints can equally be approximated,
starting from the lattice's top element and forming a descending chain. So

here we start with ùë°
ùë°
OceanofPDF.com

ùëâ0 ‚à∂= dom(ùë°). Then ùëâ1 ‚à∂= [[ùëû ‚à® ‚óáùëã]]
= [[ùëû ‚à® ‚óátt]]
. So ùëâ
[ùëã‚Ü¶ dom(ùë° )]
[]
1 consists of
all nodes that satisfy ùëû or have a successor. Since every node in an infinite
tree
- at least according to the tree model considered here - has a successor, we
have
‚óátt ‚â° tt over the class of ranked trees with non-zero ranks, and ùëû ‚à® tt ‚â° tt
anyway, so ùëâ1 = dom(ùë°) = ùëâ0, and the greatest fixpoint is reached with the
0-th approximant already. In other words, ùúà ùëã .ùëû ‚à® ‚óáùëã ‚â° tt.
394
14 Logics on Infinite Trees
A non-trivial property is expressed by ùúà ùëã .ùëû ‚àß ‚óáùëã. We start with ùëâ0 =
dom(ùë°).
ùë°
ùë°
Then ùëâ1 = [[ùëû ‚àß ‚óáùëã]]
= [[ùëû]]
, i.e. ùëâ

[ùëã‚Ü¶ùëâ
1 consists of all ùëû-nodes as well, as in the
0 ]
[]
case of the approximation for ùúá ùëã .ùëû ‚à® ‚óáùëã. However, the next approximant
already ùë°
ùë°
differs. We have ùëâ2 = [[ùëû ‚àß ‚óáùëã]]
= [[ùëû ‚àß ‚óáùëû]]
consisting of all ùëû-nodes that
[ùëã‚Ü¶ùëâ1]
[]
have a ùëû-successor. Iterating this reveals that ùëâùëñ consists of all nodes from
which there is a path of ùëñ + 1 successive ùëû-nodes. The limit here is the
infimum over all
‚àó
approximants, i.e. ùëâ
‚à∂= ‚ãÇ
ùëâ
ùëñ‚â•0
ùëñ , and it should be clear that exactly the nodes from

which there is an infinite path of ùëû-nodes, belong to all ùëâùëñ, i.e. to the
greatest fixpoint.
Hence, ùúà ùëã .ùëû ‚àß ‚óáùëã states "there is an infinite path of ùëû -nodes."
The formulas considered in the previous example are simple in the sense
that they only contain a single fixpoint operator. The principles can equally
be applied to form approximants for fixpoint subformulas in a formula
containing potentially several fixpoint operators. This requires a bit more
bookkeeping, though, which does not necessarily help the acquisition of the
correct intuition about what properties are expressed by which formulas.
Especially when fixpoint alternation comes into play - the nesting of
fixpoints of different kinds - this gets trickier, not only from a pragmatic
point of view but also algorithmically.
Take for instance a formula ùúë(ùëã, ùëå ) with two free variables. Then ùúà ùëã .ùúáùëå .ùúë(ùëã,
ùëå ) and ùúá ùëã .ùúàùëå .ùúë(ùëã, ùëå ) do not express the same property in general, see also
Ex. 14.23.
Take ùúà ùëã .ùúáùëå .ùúë(ùëã, ùëå ). The way to build approximants for the fixpoints is then
to start with the initial value for the variable ùëã of the outer fixpoint, carry
out a whole iteration for the inner fixpoint with ùëå , starting from its initial
value ‚àÖ. The limit then determines the first approximant for the outer ùëã.
With this new value for ùëã, one has to carry out a whole fixpoint iteration for
the inner one again.
Example 14.31 Reconsider the formula ùúë ‚à∂= ùúàùëã.ùúáùëå .(ùëû ‚àß‚óáùëã)‚à®‚óáùëå from Ex.
14.23, proclaiming the existence of a path with infinitely many ùëû -nodes.
The first inner iteration for ùëå with a fixed interpretation of ùëã as tt yields the
set of all nodes which can reach a ùëû-node. Note that (ùëû ‚àß ‚óátt) ‚à® ‚óáùëå ‚â° ùëû ‚à®
‚óáùëå over models in which every node has a successor. In the second
iteration, we recompute the inner least fixpoint with a value of ùëã fixed to
that set. This yields the set of all nodes from which a ùëû-node is reachable
that has a successor belonging to the set constructed in the previous
iteration. I.e. we get the set of all nodes from which there is a path

containing two ùëû-nodes. The limit of this construction then yields the set of
all nodes from which there is a path containing infinitely many ùëû -nodes.
A result known as the Bekiƒá Lemma gives a shortcut through such a nested
iteration when the fixpoints are of the same kind. This does not carry over
to alternations between least and greatest fixpoints for which these
iterations need to be nested.
One can also regard this iterative process as running through the formula
recursively. A greatest fixpoint variable can be seen infinitely often, but the
recursion through a least fixpoint variable needs to terminate at some point.
However, when checking whether a given node in a given tree satisfies a
formula like ùúà ùëã . ùúáùëå .(ùëû ‚àß ‚óáùëã ) ‚à® ‚óáùëå by tracing which parts are satisfied and
forming a path stepwise, one ultimately recurses through ùëã and ùëå infinitely
often in general. It is then
14.3 The Modal ùúá-Calculus
395
the outermost fixpoint variable that determines whether the formula is
satisfied or not. The reason simply is that the recursion of the outermost one
corresponds to one fixpoint iteration, whereas the infinitely many
occurrences of the inner one, inter-rupted infinitely often by the outer one,
correspond to infinitely many terminating fixpoint iterations for the inner
one.
This intuition is reminiscent of a parity condition. In fact, it is possible to
define acceptance games, also known as model checking games, for
determining whether a given tree satisfies a given Lùúá formula. These games
are special parity games.
14.3.4 Decidability
Decidability of the satisfiability problem for Lùúá is less obvious without some
deeper insights provided by the theory of fixpoints, in particular the
Knaster-Tarski Theorem.

It enables the formulation of the semantics of Lùúá formulas like ùúá ùëã .ùúë as
second-order properties. Note that a formulation along the lines of "node ùë£
belongs to the least fixpoint of the function derived from ùúë" is not a
(monadic) second-order property because it quantifies over functions.
Theorem 14.32
P
Let P be given and Œ£ ‚à∂= 2 . For every Lùúá formula ùúë over P there is an MSO
formula Œ¶ over Œ£ such that ùêø(Œ¶) = ùêø(ùúë) and ‚à£Œ¶‚à£ = O‚à£ùúë ‚à£ .
Proof
‚àó
As in the case of the temporal logic CTL , whose formulas are also
interpreted in given nodes in a tree, we first translate every Lùúá formula ùúë
into an MSO formula tr ùë• (ùúë) with a free variable ùë• such that ùë°, ùë£, ùêº ‚äß ùúë iff ùë°,
ùêº[ùë• ‚Ü¶ ùë£] ‚äß tr ùë• (ùúë) for ùúî
any ùë° ‚àà TŒ£ , and ùë£ ‚àà dom(ùë°) and any assignment ùêº ‚à∂ V2 ‚Üí 2 dom(ùë°).
Hence, the MSO formula tr ùë• (ùúë) uses the same second-order variables as ùúë.
It uses additional first-order variables of which exactly one is free.
tr
ùëé
ùë• (ùëû )
‚à∂=
‚ãÅ
(ùë•)
ùëé‚äÜP

ùëû‚ààùëé
tr ùë• (ùëã) ‚à∂= ùëã(ùë•)
tr ùë• (ùúë ‚à® ùúì) ‚à∂= tr ùë• (ùúë) ‚à® tr ùë• (ùúì)
tr ùë• (¬¨ùúë) ‚à∂= ¬¨ tr ùë• (ùúë)
ùëë‚àí1
tr ùë• (‚óáùúë) ‚à∂= ‚àÉùë¶. ‚ãÅ succ ùëñ (ùë•, ùë¶) ‚àß tr ùë¶ (ùúë)
ùëñ=0
tr ùë• (ùúá ùëã .ùúë) ‚à∂= ‚àÄùëã .(‚àÄùë¶. tr ùë¶ (ùúë) ‚Üí ùëã(ùë¶)) ‚Üí ùëã (ùë•)
(ùúë)
The fact that tr ùë•
is correct according to the requirement outlined above, is
immediate since the translation tr ùë• only formulates the semantics of an Lùúá
formula in MSO. The last clause makes use of Prop. 14.27. Moreover, for a
fixed set P , the translation also clearly incurs a linear blowup only.
‚óª
Consequently, decidability for MSO over trees carries over to Lùúá.
396
14 Logics on Infinite Trees
Corollary 14.33 The satisfiability, validity and equivalence problems for Lùúá
are decidable.
‚àó

As with CTL , the embedding into MSO does not yield an optimal decision
procedure. Formulas of Lùúá with nested least and greatest fixpoints clearly
lead to MSO formulas with unbounded nestings between universal
quantifiers and negation or, equivalently, universal and existential
quantifiers, leading to a non-elementary upper bound only. However,
satisfiability (and the other problems) for Lùúá can in fact be decided in singly
exponential time. This requires some deeper insights, though, for instance
on the automata side via alternating tree automata.
Proposition 14.34 The satisfiability, validity and equivalence problems for
Lùúá are decidable in exponential time.
Again, this is optimal; these problems are complete for ExpTime.
Bibliographic Notes
For reference to work on MSO over trees, also known as SnS - the Second-
Order Logic of ùëõ Successor Relations - see the bibliographic notes of the
previous chapter since work on MSO is tightly linked to tree automata. In
particular, Rabin's celebrated decidability proof for this logic [Rab69] is
one of the cornerstones of the automata-logic connection.
‚àó
The full branching-time temporal logic CTL
was proposed by Emerson and
Halpern [EH86] as a means to unify two kinds of temporal logics with
incomparable expressiveness and different complexities: the linear-time
temporal logic LTL with PSpace-complete model checking and satisfiability
checking problems
[SC85, LP00] on one hand, capable of expressing fairness properties for
example; and Clarke and Emerson's branching-time temporal logic CTL on
the other hand with polynomial-time model checking [EC82, CES86] but an
ExpTime-complete satisfiability problem and without the ability to express
fairness [EH85].

‚àó
The fact that satisfiability for CTL
is decidable was readily seen. It is an easy
‚àó
exercise to show that CTL has the tree model property and that it can be
embedded into the decidable logic MSO over trees. However, this only gives
a non-elementary decision procedure. An optimal, doubly exponential one
was found by Emerson and Sistla [EJ00] using a direct translation into tree
automata. Prop. 14.14 was proved by them to establish correctness of such
a translation.
‚àó
The search for an elementary decision procedure for CTL
did not arrive at an
optimal one straight away. At that time, only McNaughton's doubly
exponential determinisation procedure for B √ºchi automata was available
[McN66]. Emerson und Sistla showed that the particular automata needed
in a decision procedure for
‚àó
CTL could be determinised at a singly exponential blowup only, leading to
a triply
‚àó
exponential decision procedure for CTL [ES84b]. An improved emptiness
test for tree automata [EJ00] then results in a doubly exponential procedure
only.
Bibliographic Notes for Chapter 14

397
It is possible to replace the perhaps sometimes too rigid framework of tree
au-
‚àó
tomata in a decision procedure for a logic like CTL
by more flexible tableaux
[FLL10], or to formulate the satisfiability problem directly in terms of two-
player games [FLL13]. Both approaches still rely on determinisation for ùúî-
word automata, though, and do not differ in essence from a direct approach
via tree automata.
Doubly exponential time had been established as a lower bound by Vardi
and Stockmeyer earlier already [VS85], showing that the integration of the
entire linear-time temporal logic LTL into CTL does genuinely increase the
latter's complexity.
This is perhaps not too surprising, but the lower bound already holds for
the fragment
+
known as CTL [JL03] which disallows immediate nestings of temporal
operators.
+
This is in fact surprising because the expressive power of CTL does not
exceed that
‚àó
of CTL [EH85], unlike the case of CTL . So the increase in complexity from
the

‚àó
branching-time temporal logic CTL to the full branching-time temporal
logic CTL is not owed to an increase in expressiveness but an exponential
increase in succinctness, i.e. the need for exponentially sized formulas
expressing certain properties in CTL
+
that can be expressed in CTL using formulas of (low) polynomial size. The
literature
+
contains at least three different proofs for the succinctness gap between
CTL
and
CTL [Wil99b, Lan08, AI03].
‚àó
Temporal logics, including CTL , are also extensively covered, regarding
questions of computational complexity, expressive power and their model
theory, in a handbook article by Emerson [Eme90], and in textbooks on
model checking
+
[CGK 18, BK08] or solely on temporal logics themselves with branching-
time temporal logics either featured extensively [DGL16] or just briefly
[KM08].
The modal ùúá-calculus in the form presented here was proposed by Kozen
[Koz83]
under the name propositional ùúá -calculus, building on earlier proposals by
Park

[Par70] and de Bakker and de Roever [dBdR72]. The different terminology
is simply used, then, to distinguish it from logics over non-finite data like
arithmetic for example, whereas the name "modal ùúá-calculus" emphasises
the extension of modal logic in it.
The Knaster-Tarski Theorem (Prop. 14.27) was first proved by Knaster
[Kna28] for the special case of powerset lattices only, and then later by
Tarski [Tar55] for general complete lattices. A proof can be found in
Winskel's textbook on programming language semantics for example
[Win93].
Kleene proved his Fixpoint Theorem in a more general form than stated
here for complete lattices and monotone functions (Prop. 14.29), namely for
complete partial orders and Scott-continuous functions. The exact origin in
the literature amongst Kleene's work is hard to trace. A precise formulation
and proof can be found in a textbook on domain theory for example
[SLG94].
A formulation and proof of the Bekiƒá Lemma can be found in a collection of
Bekiƒá's work [Bek84].
The parity games that characterise the model checking, resp. acceptance
problem for Lùúá were formulated by Stirling [Sti95].
Decidability of the satisfiability problem for the modal ùúá-calculus over trees
was easily seen, precisely for the simple translation into MSO due to the
Knaster-
‚àó
Tarski characterisation of fixpoints. As with CTL , this is not optimal as it
yields
398
14 Logics on Infinite Trees

a non-elementary decision procedure only. Again, an optimal upper bound
had been found after some intermediate progress [SE89, KP83], by
Emerson and Jutla
[EJ00] with an automata-theoretic decision procedure that runs in singly
exponential time. It is based on alternating tree automata [MS87] which
have not been covered here explicitly. The concept of alternation can
straightforwardly be lifted to tree automata, though. Formulas of the modal
ùúá-calculus can also straightforwardly be translated into alternating tree
automata. The core of a decision procedure then lies in a translation into
nondeterministic tree automata [MS95] for which non-emptiness can be
decided, cf. Thm. 13.33. The key is to limit the blowup in the translation to
an at most exponential one [EJ00] which then results in a singly
exponential procedure overall. This is optimal. The satisfiability problem
for Propositional Dynamic Logic
[FL79, HKT00], which can easily be embedded linearly into Lùúá, was shown
to be hard for the class ExpTime by Fischer and Ladner [FL79].
The translation from ùúá-calculus formulas into alternating tree automata is
not reversible. This is simply due to the fact that tree automata can see the
order and multiplicity of successor nodes. A restriction of tree automata
that is oblivious to this and then corresponds exactly to Lùúá in expressive
power is given by so-called symmetric tree automata [Wil01]. The technical
term for the equivalence relation behind this is bisimilarity, a formal
concept of program equivalence studied by Milner [Mil80]. A celebrated
result on the expressive power of Lùúá states that every MSO property which
is bisimulation-invariant can be expressed in Lùúá, shown by Janin and
Walukiewicz [JW96]. This lifts a result known as the van Benthem-Rosen-
Theorem [vB76, Ros97] for the first-order world, stating ML captures
exactly the bisimulation-invariant properties definable in FO, see also some
overview articles on this topic [vB84, GO07].
For a further view onto the connection between the modal ùúá-calculus and
tree automata see also the corresponding chapter [Zap02] in the collection
[GTW02].

The concept of fixpoint alternation has been studied at great depth. The
most accepted way to measure the entanglement between fixpoints is the
one proposed by Niwi ≈Ñski [Niw97], but there is also the weaker one by
Emerson and Lei [EL86].
Bradfield has shown that the alternation hierarchy is strict [Bra98a], i.e.
more fixpoint alternation properly gives higher expressive power. This also
holds over trees [Arn99, Bra99]. See also the bibliographic notes for Chp.
13 which contains a few more references and explanations.
The modal ùúá-calculus is also studied in detail in two handbook articles by
Bradfield and Stirling [BS01b, BS07], a survey by Lenzi [Len05], a
textbook on the logic itself by Arnold and Niwi ≈Ñski [AN01], and chapters in
textbooks on temporal logics
+
[DGL16], reactive systems [GM14] or model checking [CGK 18].
‚àó
A question that may arise with the introduction of two logics, CTL
and Lùúá,
that can both be embedded into MSO over infinite trees, is concerned with
their expressive power relative to one another. An immediate consequence
of the fact that
‚àó
CTL -definable properties are bisimulation-invariant and the Janin-
Walukiewicz
‚àó
result mentioned above, is the fact that CTL
can be embedded into Lùúá. A direct

and effective translation has been given by Dam for instance [Dam94].
Exercises for Chapter 14
399
Exercises
Exercise 151 Write down an MSO formula ùúë(ùëã) over an arbitrary ranked
alphabet Œ£ and with a free second-order variable ùëã such that ùë°, ùêº ‚äß ùúë iff
‚à£I(ùëã)‚à£ is finite and even, for an arbitrary Œ£-tree ùë°.
Exercise 152 Write down MSO formulas with suitable free variables that
formalise the following properties.
a) Node ùë¶ is right of node ùë•, i.e. it has an ancestor that is a sibling to the
right of ùë•.
b) Every path contains finitely many symbols ùëé only.
Exercise 153 Prove Thm. 14.3.
Exercise 154
‚àó
Determine for each pair of the following four CTL
formulas over
propositions ùëù , . . . , ùëù
1
ùëõ
whether or not they are equivalent. In case they are not,

construct a tree that separates them in the sense that it is a model of one but
not the other, and determine whether one of them implies the other, i.e.
whether an implication either way is valid.
ùëõ
ùëõ
ùëõ
ùëõ
‚ãÄ AGF ùëù
,
A
GFùëù
,
AG
Fùëù
,
AGF
ùëù
ùëñ
‚ãÄ
ùëñ
‚ãÄ

ùëñ
‚ãÄ
ùëñ
ùëñ=1
ùëñ=1
ùëñ=1
ùëñ=1
Exercise 155
‚Ä≤
‚Ä≤
Consider the two trees ùë°, ùë° from Ex. 14.15. Show that ùë° ‚äß ùúë iff ùë° ‚äß ùúë
‚àó
for all CTL state formulas ùúë. Hint: This can be done by induction on the
structure of formulas but the statement needs to be generalised. Find a
relation ùëÖ ‚äÜ dom(ùë°) √ó
‚Ä≤
‚Ä≤
‚Ä≤
‚Ä≤
dom(ùë° ) such that whenever (ùë£, ùë£ ) ‚àà ùëÖ then ùë°[ùë£] ‚äß ùúë iff ùë° [ùë£ ] ‚äß ùúë for an
arbitrary state formula ùúë where ùë°[ùë£] denotes the subtree of ùë° rooted at ùë£ etc.
Generalise this suitably for path formulas as well.

Exercise 156 Let ùë° be a tree over some Œ£, ùë£ ‚àà dom(ùë°), ùëë ‚à∂= rk Œ£(ùë°(ùë£)) > 1
and ùúé ‚à∂ [ùëë] ‚Üí [ùëë] be a permutation such that the subtrees ùë°[ùë£ùëñ] and ùë°[ùë£ùúé(ùëñ)]
are not isomorphic for at least some ùëñ ‚àà [ùëë].
‚Ä≤
Let ùë° result from ùë° by applying the permutation ùúé to the children of node ùë£,
i.e.
‚Ä≤
dom(ùë° ) = dom(ùë°) but
‚éß
‚é™
‚àó
‚é™ùë° (ùë¢ùúé(ùëñ)ùë§)
,
‚Ä≤
if ùë¢ = ùë£ùëñùë§ for some ùëñ ‚àà [ùëë], ùë§ ‚àà N
ùë° (ùë¢)
= ‚é®
‚é™
‚é™ùë° (ùë¢)
, otherwise
‚é©

‚Ä≤
for all ùë¢ ‚àà dom(ùë° ).
‚Ä≤
Construct an MSO sentence ùúë such that ùë° ‚äß ùúë and ùë° /
‚äß ùúë or vice-versa. Can ùúë be
formalised in FO already?
Hint: First show that for every pair of non-isomorphic trees there is a
formula ùúì (ùë•) that distinguishes the two when ùë• is mapped to their respective
root nodes.
Exercise 157 Is the formula ùúë0 ‚àßùúë1 ‚àßùúë2 given in Ex. 14.9 satisfiable? If so,
construct a model for it.
400
14 Logics on Infinite Trees
Exercise 158
‚àó
Prove or refute the following statements for CTL , resp. Lùúá formulas ùúë and ùëë
‚àà N .
a) If ùúë is satisfiable in the class of trees of branching degree ùëë then it is also
satisfiable in the class of trees of branching-degree ùëë + 1.
b) If ùúë is satisfiable in the class of trees of branching degree ùëë + 1 then it is
also satisfiable in the class of trees of branching-degree ùëë.
Exercise 159 Prove Thm. 14.19.
Exercise 160 Prove Lemma 14.22.

Exercise 161
a) Prove Lemma 14.26.
b) Show that (2N ,
fin ‚äÜ) is incomplete as a lattice.
Exercise 162 Show that ùúàùëã.ùúë does indeed define the greatest fixpoint of the
mapping induced by ùúë(ùëã), i.e. show that
ùë°
ùë°
[[ùúà ùëã .ùúë]]
= ‚ãÉ{ùëâ ‚äÜ dom(ùë°) ‚à£ ùëâ ‚äÜ [[ùúë]] }
ùêº
ùêº
for any tree ùë° and any variable assignment ùêº.
Exercise 163 What properties of nodes are being expressed by the following
Lùúá
formulas?
a) ùúá ùëã .ùëã
b) ùúà ùëã .ùëã
c) ùúá ùëã . ‚óá ùëã
d) ùúá ùëã .ùëû ‚à® ‚óªùëã
Index

algorithm
generalised B √ºchi, 252
Tarjan, 184
Muller, 133
alphabet, 3, 7
parity, 125
ranked, 283
parity-edge, 149
approximant, 393
Rabin, 122
assignment
Streett, 123
initial, 287
product, 9
variable, 22, 302
Rabin chain, 132
atomic proposition, 242
symbolic
attractor, 60, 322
B √ºchi, 243

repeated, 218
Muller, 134
automaton
universal, 225
alternating
weak, 212, 233
B √ºchi, 210
co-B √ºchi, 225
bisimulation, 398
finite, 48
invariance, 383
parity, 235
branching
very weak, 260
bounded, 161
weak parity, 235
degree, 161
counter-free, 260
finite, 60, 161
deterministic

infinite, 161
B √ºchi, 105
universal, 47
co-B √ºchi, 144
finite, 12
calculus
Muller, 133
modal ùúá-, 370, 390
parity, 125
propositional ùúá-, 397
Rabin, 122
chain, 392
Streett, 123
child, 161
dual, 55, 226
closure, 5
max-parity, 126
Fischer-Ladner, 254
min-parity, 126, 154
Kleene, 3

nondeterministic
left-sibling, 160, 282
B √ºchi-edge, 148
parent, 160, 282
B √ºchi, 98
reflexive-transitive, 182
co-B √ºchi, 144
transitive, 182
co-B √ºchi-edge, 149
colouring, 108
finite, 7
complement, 3
¬© The Editor(s) (if applicable) and The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
M. Hofmann and M. Lange, Automata Theory and Logic,
401
https://doi.org/10.1007/978-3-662-72154-4
402
Index
concatenation, 3

homomorphism, 5
construction
inverse, 18
breakpoint, 238
tree, 291
Miyano-Hayashi, 223, 238
powerset, 13
idempotency, 195
Safra, 157
index, 81, 122, 125, 133, 149, 252, 339
indistinguishability, 75
definability, 22, 98, 105
interpretation, 22, 302
descendant, 161, 229
determinacy, 60, 72, 317
labelled transition system, 269
positional, 317
language, 3, 26, 94, 96, 98, 148, 245, 377
difference, 18
ùúî-regular, 95, 96

directed acyclic graph, 52
accepted, 7
duplicator, 72
generalised, 82
regular, 4
equivalence, 7, 22, 245
star-free, 79
expression
tree, 283, 339
ùúî-regular, 96
latest appearance record, 141
regular, 4
lattice, 391
star-free, 79
complete, 391
height, 392
fixpoint, 388
lemma
greatest, 389
Arden, 10, 17

least, 389
Bekiƒá, 394
formula
K Àù
onig, 163
acceptance, 134
level, 49, 214
Boolean, 243
limit, 106
characteristic, 247
logic
closed, 21
branching-time, 370
dual, 226
dyadic second-order, 46
normalised, 27
first-order, 20, 69
path, 375
linear-time temporal, 241
positive, 388

modal, 384
positive Boolean, 48
monadic second-order, 19, 301
propositional, 243
temporal, 244
state, 375
tense, 274
game
macrostate, 159, 163
acceptance, 64, 221, 348
matching, 311
B √ºchi, 218
method
co-B √ºchi, 220
antichain, 205
configuration, 72
Ramsey-based, 205
dual, 220
microstate, 159, 163
Ehrenfeucht-Fra¬®ƒ±ss√©, 71

modal depth, 385
generalised Ehrenfeucht-Fra¬®ƒ±ss√©, 72
model, 23, 49, 377
model checking, 395
minimal, 67
parity, 316
monotonicity, 388
perfect information, 60
morphism, 5
reachability, 59
rank-preserving, 291
solving, 63, 327
zero-sum, 60
negation normal form, 71, 248
node, 160, 282
Hintikka set, 255
rank, 213
history, 51
seniority, 176
Index

403
stable, 169, 170
spoiler, 71
successful, 170
state, 7
accepting , 7
partial isomorphism, 72
final, 7
path, 271, 338
initial, 7, 269
length, 161
strategy, 59, 72, 316
unbounded length, 161
attractor, 60, 323
permutation, 141
history-fr ee, 59
play, 59, 316
memoryl ess, 59
conforming, 59
non-losin g, 317

winning, 218
positiona l, 59, 316
positivity, 390
winning, 60, 316
priority, 125
strategy pro file
problem
local, 35 2
emptiness, 14
strongly co nnected component, 183
equivalence, 15, 23, 181
decompo sition, 183
inclusion, 14, 181
subformula, 24, 244
membership, 14
subgame, 3 22
model checking, 45, 241, 272
non-emptiness, 15, 181
temporal op erator, 245
non-inclusion, 15

theorem
non-universality, 15
B √ºchi, 10 1
satisfiability, 15, 23, 181
Ehrenfeu cht-Fra¬®ƒ±ss√©, 75
subsumption, 14, 181
Gabbay, 274
universality, 14, 181
Kamp, 2 74
validity, 181
Kleene, 1 7, 392
word, 14, 45
Knaster-Tarski, 391, 392
projection, 29, 345
Myhill-N erode, 87
propositional consistency, 255
Rabin, 3 64
Ramsey, 108, 117
quantifier, 21
Savitch, 17

depth, 70
van-Bent hem-Rosen, 398
fixpoint, 370
trace, 271
guided, 3 46
ranking, 228
transducer, 309
reachability, 183
transition
recognisability, 7, 98, 105, 122
function, 7
recursive program, 198
relation, 7
regular tree language, 296, 339
tree, 160, 2 83
reversal, 18
finite, 28 2
run, 7, 49, 98, 122, 123, 287, 293, 339
finite rep resentation, 362
accepting, 7, 49, 98, 122, 123, 125, 133, 144,

finitely b ranching, 393
148, 149, 210, 235, 252, 287, 293, 339
history, 1 64
history-free, 50
ordered, 49, 282
memoryless, 50, 212, 215
ranked, 2 83
ultimately periodic, 187
universal, 333
unordere d, 49
satisfaction, 22, 48, 134, 302
tree automa ton, 296
satisfiability, 23
determini stic
equi-, 23
bottom-up, 287
sentence, 21
parity, 340
shuffle product, 18
top-do wn, 292

size, 7, 23, 24, 98, 122, 134, 245, 252, 286,
nondeter ministic
339, 362
B √ºchi, 341
404
Index
bottom-up, 286
bound, 21
parity, 339
first-order, 19, 301
top-down, 292
free, 21
symmetric, 398
second-order, 19, 301
unfolding, 250
unification, 311
winning region, 317
unravelling, 342
word
unsatisfiability, 23

empty, 3
update, 141
finite, 3
infinite, 94
validity, 23, 377
length, 3
variable
well-formed, 85
References
[AB00]
A. Ayari and D. Basin. Bounded model construction for monadic second-
order logics.
In Proc. 12th Conf. on Computer Aided Verification, CAV'00, volume 1855
of Lect.
Notes in Comp. Sci. , pages 99-112. Springer, 2000.
+
[ACC 10]
P. A. Abdulla, Y.-F. Chen, L. Clemente, L. Hol¬¥ƒ±k, C.-D. Hong, R. Mayr, and
T. Vojnar.
Simulation subsumption in Ramsey-based B √ºchi automata universality and
inclusion testing. In Proc. 22nd Conf. on Computer Aided Verification,
CAV'10, volume 6174

of Lect. Notes in Comp. Sci. , pages 132-147. Springer, 2010.
+
[ACC 11]
P. A. Abdulla, Y.-F. Chen, L. Clemente, L. Hol¬¥ƒ±k, C.-D. Hong, R. Mayr, and
T. Vojnar.
Advanced Ramsey-based B √ºchi automata inclusion testing. In Proc. 22nd
Conf. on Concurrency Theory, CONCUR'11, volume 6901 of Lect. Notes in
Comp. Sci. , pages 187-202. Springer, 2011.
[AF17]
D. Avis and O. Friedmann. An exponential lower bound for Cunningham's
rule. Math.
Progr. , 161(1-2):271-305, 2017.
[AHU83]
A. V. Aho, J. E. Hopcroft, and J. D. Ullman. Data Structures and
Algorithms. Comp.
Sci. and Inform. Proc. Addison-Wesley, 1st edition, 1983.
[AI01]
M. Adler and N. Immerman. An ùëõ! lower bound on formula size. In Proc.
16th Symp.
on Logic in Computer Science, LICS'01, pages 197-208. IEEE, 2001.
[AI03]
M. Adler and N. Immerman. An ùëõ! lower bound on formula size. ACM
Trans. Comput.

Logic, 4(3):296-314, 2003. Cf. [AI01].
[AN01]
A. Arnold and D. Niwi ≈Ñski. Rudiments of ùúá -calculus, volume 146 of Studies
in Logic and the Foundations of Mathematics. North-Holland, 2001.
[ANP21]
A. Arnold, D. Niwinski, and P. Parys. A quasi-polynomial black-box
algorithm for fixed point evaluation. In Proc. 29th Conf. on Computer
Science Logic, CSL'21, volume 183 of LIPIcs, pages 9:1-9:23. Schloss
Dagstuhl - Leibniz-Zentrum f √ºr Informatik, 2021.
[Ard60]
D. N. Arden. Delayed logic and finite state machines. In Theory of
Computing Machine Design, pages 1-35. U. of Michigan Press, Ann Arbor,
1960.
[Arn99]
A. Arnold. The modal ùúá-calculus alternation hierarchy is strict on binary
trees. RAIRO
Theor. Inform. Appl. , 33:329-339, 1999.
[AU71]
A.V. Aho and J.D. Ullman. Translations on a context free grammar. Inform.
Control, 19(5):439-475, 1971.
[Bar85]
H. P. Barendregt. The ùúÜ -calculus - its syntax and semantics, volume 103 of
Studies in logic and the foundations of mathematics. North-Holland, 1985.
[BB89]

B. Banieqbal and H. Barringer. Temporal logic with fixed points. In Proc.
Coll.
on Temporal Logic in Specification, volume 398 of Lect. Notes in Comp.
Sci. , pages 62-73. Springer, 1989.
¬© The Editor(s) (if applicable) and The Author(s), under exclusive
license to Springer-Verlag GmbH, DE, part of Springer Nature 2025
405
M. Hofmann and M. Lange, Automata Theory and Logic,
https://doi.org/10.1007/978-3-662-72154-4
406
References
+
[BCJ 97]
A. Browne, E. M. Clarke, S. Jha, D. E. Long, and W. Marrero. An improved
algorithm for the evaluation of fixpoint expressions. Theor. Comp. Sci. ,
178(1-2):237-255, 1997.
+
Cf. [LBC 94].
[BDM20]
M. Benerecetti, D. Dell'Erba, and F. Mogavero. Robust worst cases for
parity games algorithms. Inform. Comp. , 272:104501, 2020.
[BE58]

J. B √ºchi and C. C. Elgot. Decision problems of weak second order
arithmetics and finite automata, Part I. Notices Amer. Math. Soc. , 5:834,
1958.
[Bek84]
H. Bekiƒá. Programming Languages and Their Definition, Selected Papers,
volume 177 of LNCS. Springer, 1984.
[Ber79]
J. Berstel. Transductions and context-free languages. Teubner, Stuttgart,
1979.
[Ber80]
L. Berman. The complexity of logical theories. Theor. Comp. Sci. ,
11(1):71-77, 1980.
[BFH05]
D. Bustan, D. Fisman, and J. Havlicek. Automata constructions for PSL.
Technical Report MCS05-04, The Weizmann Inst. of Science, 2005.
[BFL14]
F. Bruse, M. Falk, and M. Lange. The fixpoint-iteration algorithm for parity
games. In Proc. 5th Symp. on Games, Automata, Logics and Formal
Verification, GandALF'14, volume 161 of EPTCS, pages 116-130, 2014.
[BG00]
A. Blumensath and E. Gr√§del. Automatic structures. In Proc. 15th Symp. on
Logic in Computer Science, LICS'00, pages 51-62. IEEE, 2000.
[BK08]
C. Baier and J.-P. Katoen. Principles of Model Checking. MIT Press, 2008.

[BKR10]
U. Boker, O. Kupferman, and A. Rosenberg. Alternation removal in B √ºchi
automata.
In Proc. 37th Coll. on Automata, Languages and Programming, ICALP'10,
volume 6199 of Lect. Notes in Comp. Sci. , pages 76-87. Springer, 2010.
[BLO12]
S. Breuers, C. L √∂ding, and J. Olschewski. Improved Ramsey-based B √ºchi
complementation. In Proc. 15th Conf. on Foundations of Software Science
and Computational Structures, FOSSACS'12, volume 7213 of Lect. Notes in
Comp. Sci. , pages 150-164.
Springer, 2012.
[BLV96]
N. Buhrke, H. Lescow, and J. V √∂ge. Strategy construction in infinite games
with Streett and Rabin chain winning conditions. In Proc. 2nd Workshop on
Tools and Algorithms for Construction and Analysis of Systems, TACAS'96,
volume 1055 of Lect. Notes in Comp. Sci. , pages 207-224. Springer, 1996.
[Bok18]
U. Boker. Why these automata types? In Proc. 22nd Conf. on Logic for
Programming, A.I. and Reasoning, LPAR'18, volume 57 of EPiC Series in
Comp. , pages 143-163.
EasyChair, 2018.
[Bra96]
J. C. Bradfield. The modal ùúá-calculus alternation hierarchy is strict. In
Proc. 7th Conf. on Concurrency Theory, CONCUR'96, volume 1119 of Lect.
Notes in Comp.
Sci. , pages 233-246. Springer, 1996.

[Bra98a]
J. C. Bradfield. The modal ùúá-calculus alternation hierarchy is strict. Theor.
Comput.
Sci. , 195(2):133-153, 1998. Cf. [Bra96].
[Bra98b]
J. C. Bradfield. Simplifying the modal ùúá-calculus alternation hierarchy. In
Proc. 15th Symp. on Theoretical Aspects of Computer Science, STACS'98,
volume 1373 of Lect.
Notes in Comp. Sci. , pages 39-49. Springer, 1998.
[Bra99]
J. C. Bradfield. Fixpoint alternation: Arithmetic, transition systems, and the
binary tree. RAIRO Theor. Inform. Appl. , 33(4/5):341-356, 1999.
[BS01a]
F. Baader and W. Snyder. Unification theory. In Handbook of Automated
Reasoning, pages 445-532. Elsevier and MIT Press, 2001.
[BS01b]
J. Bradfield and C. Stirling. Modal logics and ùúá-calculi: an introduction. In
J. Bergstra, A. Ponse, and S. Smolka, editors, Handbook of Process
Algebra, pages 293-330.
Elsevier, 2001.
[BS07]
J. Bradfield and C. Stirling. Modal ùúá-calculi. In P. Blackburn, J. van
Benthem, and F. Wolter, editors, Handbook of Modal Logic: Studies in
Logic and Practical Reasoning Volume 3, pages 721-756. Elsevier, 2007.

[BSV03]
H. Bj √∂rklund, S. Sandberg, and S. G. Vorobyov. A discrete subexponential
algorithm for parity games. In Proc. 20th Symp. on Theoretical Aspects of
Computer Science, STACS'03, volume 2607 of Lect. Notes in Comp. Sci. ,
pages 663-674. Springer, 2003.
References
407
[B √ºc60]
J. B √ºchi. Weak second order logic and finite automata. Z. Math. Logik,
Grundlag.
Math. , 5:66-62, 1960.
[B √ºc62]
J. R. B √ºchi. On a decision method in restricted second order arithmetic. In
Proc.
Congress on Logic, Method, and Philosophy of Science, pages 1-12,
Stanford, CA, USA, 1962. Stanford Univ. Press.
[B √ºc73]
J. R. B √ºchi. The monadic second order theory of ùúî1. In G. H. M√ºller and D.
Siefkes, editors, Decidable Theories II: The Monadic Second Order Theory
of All Countable Ordinals, pages 1-127. Springer, 1973.
[BVW94]
O. Bernholtz, M. Y. Vardi, and P. Wolper.
An automata-theoretic approach to

branching-time model checking. In Proc. 6th Conf. on Computer Aided
Verification, CAV'94, volume 818 of Lect. Notes in Comp. Sci. , pages 142-
155. Springer, 1994.
+
[CDF 19]
W. Czerwinski, L. Daviaud, N. Fijalkow, M. Jurdzinski, R. Lazic, and P.
Parys. Universal trees grow inside separating automata: Quasi-polynomial
lower bounds for parity games. In Proc. 30th Symp. on Discrete Algorithms,
SODA'19, pages 2333-2349.
SIAM, 2019.
+
[CDG 07] H. Comon, M. Dauchet, R. Gilleron, C. L √∂ding, F. Jacquemard,
D. Lugiez, S. Ti-son, and M. Tommasi. Tree automata techniques and
applications. Available on: https://inria.hal.science/hal-03367725, 2007.
release October, 12th 2007.
[CDHS18] K. Chatterjee, W. Dvor√°k, M. Henzinger, and A. Svozil.
Quasipolynomial set-based symbolic algorithms for parity games. In Proc.
22nd Conf. on Logic for Programming, Artificial Intelligence and
Reasoning, LPAR-22, volume 57 of EPiC Series in Computing, pages 233-
253. EasyChair, 2018.
[CE81]
E. M. Clarke and E. A. Emerson. Design and synthesis of synchronization
skeletons using branching-time temporal logic. In Proc. Workshop on
Logics of Programs, volume 131 of LNCS, pages 52-71. Springer, 1981.
[CES83]
E. M. Clarke, E. A. Emerson, and A. P. Sistla. Automatic verification of
finite state concurrent systems using temporal logic specifications. In Proc.

10th Symp. on Principles of Programming Languages, POPL'83, pages
117-126. ACM, 1983.
[CES86]
E. M. Clarke, E. A. Emerson, and A. P. Sistla. Automatic verification of
finite-state concurrent systems using temporal logic specifications. ACM
Trans. Program. Lang.
Sys. , 8(2):244-263, 1986. Cf. [CES83].
+
[CGK 18] E. M. Clarke, O. Grumberg, D. Kroening, D. A. Peled, and H.
Veith. Model checking.
MIT Press, 2nd edition, 2018.
[Cho74]
Y. Choueka. Theories of automata on omega-tapes: A simplified approach.
J. Comp.
Sys. Sci. , 8(2):117-141, 1974.
[Chu40]
A. Church. A formulation of the simple theory of types. J. Symb. Log. ,
5(2):56-68, 1940.
[CJ97]
H. Comon and Y. Jurski. Higher-order matching and tree automata. In
Proc. 11th Conf. on Computer Science Logic, CSL'97, volume 1414 of Lect.
Notes in Comp. Sci. , pages 157-176. Springer, 1997.
+
[CJK 17]

C. S. Calude, S. Jain, B. Khoussainov, W. Li, and F. Stephan. Deciding
parity games in quasipolynomial time. In Proc. 49th Symp. on Theory of
Computing, STOC'17, pages 252-263. ACM, 2017.
[CKS81]
A. K. Chandra, D. C. Kozen, and L. J. Stockmeyer. Alternation. J. Assoc.
Comp.
Mach. , 28(1):114-133, 1981. Cf. [Koz76, CS76].
[Cle90]
R. Cleaveland. Tableau-based model checking in the propositional ùúá-
calculus. Acta Inform. , 27(8):725-748, 1990.
[CLRS22]
T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to
algorithms.
MIT Press, 4th edition, 2022.
[CM10]
L. Clemente and R. Mayr. Multipebble simulations for alternating automata
(extended abstract). In Proc. 21th Conf. on Concurrency Theory,
CONCUR'10, volume 6269 of Lect. Notes in Comp. Sci. , pages 297-312.
Springer, 2010.
408
References
[CNT04]
J. Carme, J. Niehren, and M. Tommasi. Querying unranked trees with
stepwise tree automata. In Proc. 15th Conf. on Rewriting Techniques and

Applications, RTA'04, volume 3091 of Lect. Notes in Comp. Sci. , pages
105-118. Springer, 2004.
[CS76]
A. K. Chandra and L. J. Stockmeyer. Alternation. In Proc. 17th Symp. on
Foundations of Computer Science, FOCS'76, pages 98-108. IEEE, 1976.
[CVW86]
C. Courcoubetis, M. Y. Vardi, and P. Wolper. Reasoning about fair
concurrent programs. In Proc. 18th Symp. on Theory of Computing,
STOC'86, pages 283-294. ACM, 1986.
[CZ09]
T. Colcombet and K. Zdanowski. A tight lower bound for determinization of
transition labeled B √ºchi automata. In Proc. 36th Coll. on Automata,
Languages and Programming, ICALP'09, volume 5556 of Lect. Notes in
Comp. Sci. , pages 151-162. Springer, 2009.
‚àó
‚àó
[Dam92]
M. Dam. CTL and ECTL as fragments of the modal ùúá-calculus. In Proc.
17th Coll.
on Trees in Algebra and Programming, CAAP'92, volume 581 of Lect.
Notes in Comp.
Sci. , pages 145-164. Springer, 1992.
‚àó
‚àó

[Dam94]
M. Dam. CTL and ECTL as fragments of the modal ùúá-calculus. Theor.
Comp. Sci. , 126(1):77-96, 1994. Cf. [Dam92].
[Dan60]
G. B. Dantzig. Inductive proof of the simplex method. IBM J. Res. Dev. ,
4(5):505-506, 1960.
[dBdR72]
J. W. de Bakker and W. P. de Roever. A calculus for recursive program
schemes. In M. Nivat, editor, Proc. IRIA Symp. on Automata, Formal
Languages and Programming.
North-Holland, 1972.
[DFH23]
Y. Disser, O. Friedmann, and A. V. Hopp. An exponential lower bound for
Zadeh's pivot rule. Math. Progr. , 199(1):865-936, 2023. Cf. [Fri11d].
[DG08]
V. Diekert and P. Gastin. First-order definable languages. In J. Flum, E.
Gr√§del, and T. Wilke, editors, Logic and Automata: History and
Perspectives, Texts in Logic and Games, pages 261-306. Amsterdam Univ.
Press, 2008.
[DGL16]
S. Demri, V. Goranko, and M. Lange. Temporal Logics in Computer
Science. Cambridge Tracts in Theoretical Computer Science. Cambridge
Univ. Press, 2016.
[DGPR21] K. Doveri, P. Ganty, F. Parolini, and F. Ranzato. Inclusion
testing of B √ºchi automata based on well-quasiorders. In Proc. 32nd Conf.

on Concurrency Theory, CONCUR'21, volume 203 of LIPIcs, pages 3:1-
3:22. Schloss Dagstuhl - Leibniz-Zentrum f √ºr Informatik, 2021.
[DGW24]
K. Doveri, P. Ganty, and C. Weil-Kennedy. A uniform framework for
language inclusion problems. In Taming the Infinities of Concurrency -
Essays Dedicated to Javier Esparza on the Occasion of his 60th Birthday,
volume 14660 of Lect. Notes in Comp. Sci. , pages 155-171. Springer, 2024.
[DHL06]
C. Dax, M. Hofmann, and M. Lange. A proof system for the linear time ùúá-
calculus. In Proc. 26th Conf. on Foundations of Software Technology and
Theoretical Computer Science, FSTTCS'06, volume 4337 of Lect. Notes in
Comp. Sci. , pages 274-285.
Springer, 2006.
[Don70]
J. Doner. Tree acceptors and some of their applications. J. Comp. Sys. Sci. ,
4(5):406-
451, 1970.
[Dow01]
G. Dowek. Higher-order unification and matching. In Handbook of
Automated Reasoning, pages 1009-1062. Elsevier and MIT Press, 2001.
[DR09]
L. Doyen and J.-F. Raskin. Antichains for the automata-based approach to
model-checking. Log. Meth. Comp. Sci. , 5(1), 2009.
[DR10]

L. Doyen and J.-F. Raskin. Antichain algorithms for finite automata. In
Proc. 16th Conf. on Tools and Algorithms for the Construction and Analysis
of Systems, TACAS'10, volume 6015 of Lect. Notes in Comp. Sci. , pages 2-
22. Springer, 2010.
[EB23]
J. Esparza and M. Blondin. Automata Theory - An Algorithmic Approach.
MIT Press, 2023.
[EC82]
E. A. Emerson and E. M. Clarke. Using branching time temporal logic to
synthesize synchronization skeletons. Sci. Comp. Progr. , 2(3):241-266,
1982. Cf. [CE81].
References
409
[EF06]
C. Eisner and D. Fisman. A Practical Introduction to PSL. Series on
Integrated Circuits and Systems. Springer, 2006.
[EH82]
E. A. Emerson and J. Y. Halpern. Decision procedures and expressiveness
in the temporal logic of branching time. In Proc. 14th Symp. on Theory of
Computing, STOC'82, pages 169-180. ACM, 1982.
[EH83]
E. A. Emerson and J. Y. Halpern. "Sometimes" and "Not never" revisited:
On branching versus linear time. In Proc. 10th Symp. on Principles of
Programming Languages, POPL'83, pages 127-140. ACM, 1983.
[EH85]

E. A. Emerson and J. Y. Halpern. Decision procedures and expressiveness
in the temporal logic of branching time. J. Comp. Sys. Sci. , 30:1-24, 1985.
Cf. [EH82].
[EH86]
E. A. Emerson and J. Y. Halpern. "Sometimes" and "Not never" revisited:
On branching versus linear time temporal logic. J. Assoc. Comp. Mach. ,
33(1):151-178, 1986. Cf.
[EH83].
[Ehr61]
A. Ehrenfeucht. An application of games to the completeness problem for
formalized theories. Fund. Math. , 49:129-141, 1961.
[Eil74]
S. Eilenberg. Automata, languages, and machines. A. Pure and Applied
Math. Aca-demic Press, 1974.
[EJ88]
E. A. Emerson and C. S. Jutla.
The complexity of tree automata and logics of
programs (extended abstract).
In Proc. 29th Symp. on Foundations of Computer
Science, FOCS'88, pages 328-337. IEEE, 1988.
[EJ91]
E. A. Emerson and C. S. Jutla. Tree automata, ùúá-calculus and determinacy.
In Proc.

32nd Symp. on Foundations of Computer Science, pages 368-377, San
Juan, Puerto Rico, 1991. IEEE.
[EJ00]
E. A. Emerson and C. S. Jutla. The complexity of tree automata and logics
of programs.
SIAM J. Comp. , 29(1):132-158, 2000. Cf. [EJ88].
[EJS93]
E. A. Emerson, C. S. Jutla, and A. P. Sistla. On model-checking for
fragments of ùúá-calculus. In Proc. 5th Conf. on Computer Aided Verification,
CAV'93, volume 697
of Lect. Notes in Comp. Sci. , pages 385-396. Springer, 1993.
[EJS01]
E. A. Emerson, C. S. Jutla, and A. P. Sistla. On model checking for the ùúá-
calculus and its fragments. Theor. Comp. Sci. , 258(1-3):491-522, 2001.
Cf. [EJS93].
[EL86]
E. A. Emerson and C. L. Lei. Efficient model checking in fragments of the
propositional ùúá-calculus. In Symposion on Logic in Computer Science,
pages 267-278, Washington, D.C., USA, 1986. IEEE.
[Elg61]
C. C. Elgot. Decision problems of finite automata design and related
arithmetics.
Trans. Amer. Math. Soc. , 98:21-52, 1961.
[Eme90]

E. A. Emerson. Temporal and modal logic. In J. van Leeuwen, editor,
Handbook of Theor. Comp. Sci. , volume B: Formal Models and Semantics,
chapter 16, pages 996-1072. Elsevier and MIT Press, 1990.
[ES83]
E. A. Emerson and A. P. Sistla. Deciding branching time logic: A triple
exponential
‚àó
decision procedure for CTL . In Proc. Workshop on Logics of Programs,
volume 164
of LNCS, pages 176-192. Springer, 1983.
[ES84a]
E. A. Emerson and A. P. Sistla. Deciding branching time logic. In Proc.
16th Symp.
on Theory of Computing, STOC'84, pages 14-24. ACM, 1984.
[ES84b]
E. A. Emerson and A. P. Sistla. Deciding full branching time logic. Inform.
Control, 61(3):175-201, 1984. Cf. [ES83, ES84a].
[EWS05]
K. Etessami, T. Wilke, and R. A. Schuller. Fair simulation relations, parity
games, and state space reduction for B √ºchi automata. SIAM J. Comp. ,
34(5), 2005.
[Far02]
B. Farwer. ùúî-Automata. In E. Gr√§del, W. Thomas, and Th. Wilke, editors,
Automata, Logics, and Infinite Games, volume 2500 of Lect. Notes in
Comp. Sci. , pages 3-21.

Springer, 2002.
[Fea10]
J. Fearnley. Exponential lower bounds for policy iteration. In Proc. 37th
Coll. on Automata, Languages and Programming, ICALP'10, volume 6199
of Lect. Notes in Comp. Sci. , pages 551-562. Springer, 2010.
410
References
[FGW08]
J. Flum, E. Gr√§del, and T. Wilke, editors. Logic and Automata: History and
Perspectives [in Honor of Wolfgang Thomas], volume 2 of Texts in Logic
and Games.
Amsterdam Univ. Press, 2008.
+
[FHJ 17]
T. Fiedor, L. Hol¬¥ƒ±k, P. Jank, O. Leng√°l, and T. Vojnar. Lazy automata
techniques for WS1S. In Proc. 23rd Conf. on Tools and Algorithms for the
Construction and Analysis of Systems, TACAS'17, volume 10205 of Lect.
Notes in Comp. Sci. , page 407-425.
Springer, 2017.
[FHZ11]
O. Friedmann, T. D. Hansen, and U. Zwick. Subexponential lower bounds
for randomized pivoting rules for the simplex algorithm. In Proc. 43rd
Symp. on Theory of Computing, STOC'11, pages 283-292. ACM, 2011.
+

[FJdK 19] J. Fearnley, S. Jain, B. de Keijzer, S. Schewe, F. Stephan, and D.
Wojtczak. An ordered approach to solving parity games in quasi-polynomial
time and quasi-linear space. J.
+
Softw. Tools Technol. Transf. , 21(3):325-349, 2019. Cf. [FJS 17].
+
[FJS 17]
J. Fearnley, S. Jain, S. Schewe, F. Stephan, and D. Wojtczak. An ordered
approach to solving parity games in quasi polynomial time and quasi linear
space. In Proc. 24th Symp. on Model Checking of Software, SPIN'17, pages
112-121. ACM, 2017.
[FJY90]
A. Fellah, H. J √ºrgensen, and S. Yu. Constructions for alternating finite
automata. Int.
J. Comput. Math. , 35(1-4):117-132, 1990.
[FKL13]
O. Friedmann, F. Klaedtke, and M. Lange. Ramsey goes visibly pushdown.
In Proc.
40th Coll. on Automata, Languages, and Programming, ICALP'13, volume
7966 of Lect. Notes in Comp. Sci. , pages 224-237. Springer, 2013.
[FKL15]
O. Friedmann, F. Klaedtke, and M. Lange. Ramsey-based inclusion
checking for visibly pushdown automata. ACM Trans. Comput. Log. ,
16(4):34, 2015. Cf. [FKL13].
[FKV04]

E. Friedgut, O. Kupferman, and M. Y. Vardi. B √ºchi complementation made
tighter.
In Proc. 2nd Conf. on Automated Technology for Verification and Analysis,
ATVA'04, volume 3299 of Lect. Notes in Comp. Sci. , pages 64-78.
Springer, 2004.
[FKV06]
E. Friedgut, O. Kupferman, and M. Y. Vardi. B √ºchi complementation made
tighter. J.
Found. Comp. Sci. , 17(4):851-868, 2006. Cf. [FKV04].
[FL77]
M. J. Fischer and R. E. Ladner. Propositional modal logic of programs
(extended abstract). In Proc. 9th Symp. on Theory of Computing, STOC'77,
pages 286-294.
ACM, 1977.
[FL79]
M. J. Fischer and R. E. Ladner. Propositional dynamic logic of regular
programs. J.
Comp. Sys. Sci. , 18(2):194-211, 1979. Cf. [FL77].
[FL09]
O. Friedmann and M. Lange. Solving parity games in practice. In Proc. 7th
Symp. on Automated Technology for Verification and Analysis, ATVA'09,
volume 5799 of Lect.
Notes in Comp. Sci. , pages 182-196, 2009.
[FL10]

O. Friedmann and M. Lange. Local strategy improvement for parity game
solving. In Proc. 1st Symp. on Games, Automata, Logic, and Formal
Verification, GandALF'10, volume 25 of Elect. Proc. in Theor. Comp. Sci. ,
pages 118-131, 2010.
[FL12a]
O. Friedmann and M. Lange. Ramsey-based analysis of parity automata. In
Proc.
18th Conf. on Tools and Algorithms for the Construction and Analysis of
Systems, TACAS'12, volume 7214 of Lect. Notes in Comp. Sci. , pages 64-
78. Springer, 2012.
[FL12b]
O. Friedmann and M. Lange. Two local strategy improvement schemes for
parity game solving. J. Found. of Comp. Sci. , 23(3):669-685, 2012. Cf.
[FL10].
‚àó
[FLL10]
O. Friedmann, M. Latte, and M. Lange. A decision procedure for CTL
based on
tableaux and automata. In Proc. 5th Joint Conf. on Automated Reasoning,
IJCAR'10, volume 6173 of Lect. Notes in Comp. Sci. , pages 331-345.
Springer, 2010.
[FLL13]
O. Friedmann, M. Latte, and M. Lange. Satisfiability games for branching-
time logics.
Log. Meth. Comp. Sci. , 9(4), 2013. Cf. [FLL10].

[FR74]
M. J. Fischer and M. O. Rabin. Super-exponential complexity of Presburger
arithmetic. In R. M. Karp, editor, Complexity of computation, volume 7 of
SIAM-AMS
Proceedings, page 27-41. AMS, 1974. Cf. [FR98].
[FR79]
J. Ferrante and C. W. Rackoff. The computational complexity of logical
theories, volume 718 of Lect. Notes in Math. Springer, 1979.
References
411
[FR98]
M. J. Fischer and M. O. Rabin. Super-exponential complexity of Presburger
arithmetic. In Quantifier Elimination and Cylindrical Algebraic
Decomposition, Texts and Monographs in Symb. Comp., pages 122-135.
Springer, 1998.
[Fra54]
R. Fra¬®ƒ±ss√©. Sur quelques classifications des syst√®mes de relations. Publ.
Sci. Univ.
Alger. S√©r. A, 1:35-182, 1954.
[Fri09]
O. Friedmann. An exponential lower bound for the parity game strategy
improvement algorithm as we know it. In Proc. 24th Symp. on Logic in
Computer Science, LICS'09, pages 145-156. IEEE, 2009.
[Fri10]

O. Friedmann. The Stevens-Stirling-algorithm for solving parity games
locally requires exponential time. J. Found. Comp. Sci. , 21(3):277-287,
2010.
[Fri11a]
O. Friedmann. An exponential lower bound for the latest deterministic
strategy iteration algorithms. Log. Meth. Comput. Sci. , 7(3), 2011.
[Fri11b]
O. Friedmann. Exponential Lower Bounds for Solving Infinitary Payoff
Games and Linear Programs. PhD thesis, LMU Munich, 2011.
[Fri11c]
O. Friedmann. Recursive algorithm for parity games requires exponential
time. RAIRO
Theor. Inform. Appl. , 45(4):449-457, 2011.
[Fri11d]
O. Friedmann. A subexponential lower bound for Zadeh's pivoting rule for
solving linear programs and games. In Proc. 15th Conf. on Integer
Programming and Combinatoral Optimization, IPCO'11, volume 6655 of
Lect. Notes in Comp. Sci. , pages 192-206. Springer, 2011.
[Fri13]
O. Friedmann. A superpolynomial lower bound for strategy iteration based
on snare memorization. Discr. Appl. Math. , 161(10-11):1317-1337, 2013.
[FV10]
S. Fogarty and M. Y. Vardi. Efficient B √ºchi universality checking. In Proc.
16th Conf.

on Tools and Algorithms for the Construction and Analysis of Systems,
TACAS'10, volume 6015 of Lect. Notes in Comp. Sci. , pages 205-220,
2010.
[FV12]
S. Fogarty and M. Y. Vardi. B √ºchi complementation and size-change
termination.
Log. Meth. Comp. Sci. , 8(1), 2012.
[FW02]
C. Fritz and T. Wilke. State space reductions for alternating B √ºchi
automata. In Proc. 22nd Conf. on Foundations of Software Technology and
Theoretical Computer Science, FSTTCS'02, volume 2556 of Lect. Notes in
Comp. Sci. , pages 157-168, 2002.
[FW05]
C. Fritz and T. Wilke. Simulation relations for alternating B √ºchi automata.
Theor.
Comp. Sci. , 338(1-3):275-314, 2005.
[Gab89]
D. Gabbay. The declarative past and imperative future: Executable
temporal logic for interactive systems. In Proc. Conf. on Temporal Logic in
Specification, volume 398 of Lect. Notes in Comp. Sci. , pages 409-448.
Springer, 1989.
[GH82]
Y. Gurevich and L. Harrington. Trees, automata, and games. In Proc. 14th
Symp. on Theory of Computing, STOC'82, pages 60-65. ACM, 1982.
+

[GKL 07] E. Gr√§del, P. G. Kolaitis, L. Libkin, M. Marx, J. Spencer, M. Y.
Vardi, Y. Venema, and S. Weinstein. Finite model theory and its
applications. Springer, 2007.
[GM14]
J. F. Groote and M. R. Mousavi. Modeling and Analysis of Communicating
Systems.
MIT Press, 2014.
[GO01]
P. Gastin and D. Oddoux. Fast LTL to B √ºchi automata translation. In Proc.
13th Conf.
on Computer Aided Verification, CAV'01, volume 2102 of Lect. Notes in
Comp. Sci. , pages 53-65. Springer, 2001.
[GO07]
V. Goranko and M. Otto. Model theory of modal logic. In P. Blackburn, J. F.
A. K.
van Benthem, and F. Wolter, editors, Handbook of Modal Logic, volume 3 of
Studies in Log. and Pract. Reason. , pages 249-329. North-Holland, 2007.
[G √∂d31]
K. G √∂del.
√úber formal unentscheidbare S√§tze der Principia Mathematica und ver-
wandter Systeme I. Monatshefte f ¬®
ur Mathematik und Physik, 38(1):173-198, 1931.
[GPSS80]

D. Gabbay, A. Pnueli, S. Shelah, and J. Stavi. The temporal analysis of
fairness. In Proc. 7th Symp. on Principles of Programming Languages,
POPL'80, pages 163-173.
ACM, 1980.
[GPVW95] R. Gerth, D. Peled, M. Vardi, and P. Wolper. Simple on-the-fly
automatic verification of linear temporal logic. In Proc. Symp. on Protocol
Specification Testing and Verification, PSTV'95, pages 3-18. Chapman &
Hall, 1995.
412
References
[GS53]
D. Gale and F. M. Stewart. Infinite Games with Perfect Information, pages
245-266.
Princeton Univ. Press, 1953.
[GTW02]
E. Gr√§del, W. Thomas, and T. Wilke, editors. Automata, Logics, and Infinite
Games: A Guide to Current Research, volume 2500 of Lect. Notes in Comp.
Sci. Springer, 2002.
[GV13]
G. De Giacomo and M. Y. Vardi. Linear temporal logic and linear dynamic
logic on finite traces. In Proc. 23rd Joint Conf. on A.I., IJCAI'13, pages
854-860. IJCAI/AAAI, 2013.
[Haa18]
C. Haase. A survival guide to Presburger arithmetic. ACM SIGLOG News,
5(3):67-82, 2018.

[Han04]
C. Hankin. An introduction to ùúÜ -calculi for computer scientists, volume 2 of
Texts in Computing. King's College Publ., 2004.
[Har78]
M. A. Harrison. Introduction to Formal Language Theory. Addison-Wesley,
1978.
[HK66]
A. Hoffman and R. M. Karp. On nonterminating stochastic games.
Management Sci. , 12:359-370, 1966.
[HKLN12] K. Heljanko, M. Kein√§nen, M. Lange, and I. Niemel√§. Solving
parity games by a reduction to SAT. J. Comp. Sys. Sci. , 78:430-440, 2012.
Cf. [Lan05].
[HKT00]
D. Harel, D. Kozen, and J. Tiuryn. Dynamic Logic. MIT Press, 2000.
[HMU01]
J. E. Hopcroft, R. Motwani, and J. D. Ullman. Introduction to Automata
Theory, Languages, and Computation. Addison-Wesley, 3 edition, 2001.
[Hos10]
H. Hosoya. Foundations of XML Processing: The Tree-Automata Approach.
Cambridge Univ. Press, 2010.
[HP03]
H. Hosoya and B. C. Pierce. XDuce: A statically typed XML processing
language.
ACM Trans. Internet Techn. , 3(2):117-148, 2003.

[HR72]
R. Hossley and C. Rackoff. The emptiness problem for automata on infinite
trees.
In Proc. 13th Symp. on Switching and Automata Theory, SWAT'72, pages
121-124.
IEEE, 1972.
[HR04]
M. Huth and M. D. Ryan. Logic in computer science - modelling and
reasoning about systems. Cambridge Univ. Press, 2 edition, 2004.
[HR07]
I. Hodkinson and M. Reynolds. Temporal logic. In P. Blackburn, J. Van
Benthem, and F. Wolter, editors, Handbook of Modal Logic, volume 3 of
Studies in Logic and Practical Reasoning, pages 655-720. Elsevier, 2007.
[Hro84]
J. Hromkoviƒç. On the power of alternation in finite automata. In Proc. 11th
Symp.
on Mathematical Foundations of Computer Science, MFCS'84, volume 176
of Lect.
Notes in Comp. Sci. , pages 322-329. Springer, 1984.
[Hro85]
J. Hromkoviƒç. On the power of alternation in automata theory. J. Comp.
Sys. Sci. , 31(1):28-39, 1985. Cf. [Hro84].
[HT99]

J. G. Henriksen and P. S. Thiagarajan. Dynamic linear time temporal logic.
Annals Pure Appl. Logic, 96(1-3):187-207, 1999.
[HU80]
J. Hopcroft and J. Ullman. Introduction to Automata Theory, Languages,
and Computation. Addison-Wesley, N. Reading, MA, 1980.
[IJW92]
O. H. Ibarra, T. Jiang, and H. Wang. A characterization of exponential-time
languages by alternating context-free grammars. Theor. Comp. Sci. ,
99(2):301-315, 1992.
[Imm9 9]
N. Immerman. Descriptive Complexity. Springer, New York, 1999.
+
[JL03]
J. Johannsen and M. Lange. CTL
is complete for double exponential time. In Proc.
30th Coll. on Automata, Logics and Programming, ICALP'03, volume 2719
of LNCS, pages 767 - 775. Springer, 2003.
[JL17]
M. Jurdzinski and R. Lazic. Succinct progress measures for solving parity
games. In Proc. 32nd Symp. on Logic in Computer Science, LICS'17, pages
1-9. IEEE, 2017.
[JMT22]
M. Jurdzinski, R. Morvan, and K. S. Thejaswini. Universal algorithms for
parity games and nested fixpoints. In Principles of Systems Design - Essays

Dedicated to Thomas A. Henzinger on the Occasion of His 60th Birthday,
volume 13660 of Lect. Notes in Comp. Sci. , pages 252-271. Springer, 2022.
[JPZ06]
M. Jurdzi ≈Ñski, M. Paterson, and U. Zwick. A deterministic subexponential
algorithm for solving parity games. In Proc. 17th Symp. on Discrete
Algorithms, SODA'06, pages 114-123. ACM/SIAM, 2006.
References
413
[JPZ08]
M. Jurdzinski, M. Paterson, and U. Zwick. A deterministic subexponential
algorithm for solving parity games. SIAM J. Comput. , 38(4):1519-1532,
2008. Cf. [JPZ06].
[Jur98]
M. Jurdzi ≈Ñski. Deciding the winner in parity games is in UP‚à©co-UP. Inf.
Process.
Lett. , 68(3):119-124, 1998.
[Jur00]
M. Jurdzi ≈Ñski. Small progress measures for solving parity games. In Proc.
17th Symp.
on Theoretical Aspects of Computer Science, STACS'00, volume 1770 of
Lect. Notes in Comp. Sci. , pages 290-301. Springer, 2000.
[JW96]
D. Janin and I. Walukiewicz. On the expressive completeness of the
propositional ùúá-calculus with respect to monadic second order logic. In

Proc. 7th Conf. on Concurrency Theory, CONCUR'96, volume 1119 of
LNCS, pages 263-277. Springer, 1996.
[Kai95]
R. Kaivola.
On modal ùúá-calculus and B √ºchi tree automata.
Inform. Proc. Lett. ,
54(1):17-22, 1995.
[Kai97]
R. Kaivola. Using Automata to Characterise Fixed Point Temporal Logics.
PhD thesis, LFCS, Div. of Inform., The Univ. of Edinburgh, 1997. Tech.
Rep. ECS-LFCS-97-356.
[Kam68]
H. W. Kamp. On tense logic and the theory of order. PhD thesis, Univ. of
California, 1968.
[Kha80]
L.G. Khachiyan. Polynomial algorithms in linear programming. USSR
Comp. Math.
and Math. Physics, 20(1):53-72, 1980.
[Kin81]
K. N. King. Alternating multihead finite automata (extended abstract). In
Proc. 8th Coll. on Automata, Languages and Programming, ICALP'81,
volume 115 of Lect.
Notes in Comp. Sci. , pages 506-520. Springer, 1981.

[Kin88]
K. N. King. Alternating multihead finite automata. Theor. Comp. Sci. ,
61:149-174, 1988. Cf. [Kin81].
[KK91]
N. Klarlund and D. Kozen. Rabin measures and their applications to
fairness and automata theory. In Proc. 6th Symp. on Logic in Computer
Science, LICS'91, pages 256-265. IEEE, 1991.
[Kla91]
N. Klarlund. Progress measures for complementation of ùúî-automata with
applications to temporal logic. In Proc. 32nd Symp. on Foundations of
Computer Science, FOCS'91, pages 358-367. IEEE, 1991.
[Kla99]
N. Klarlund. A theory of restrictions for logics and automata. In Proc. 11th
Conf.
on Computer Aided Verification, CAV'99, volume 1633 of Lect. Notes in
Comp. Sci. , pages 406-417. Springer, 1999.
[Kla04]
F. Klaedtke. On the automata size for Presburger arithmetic. In Proc. 19th
Symp. on Logic in Computer Science, LICS'04, pages 110-119. IEEE, 2004.
[Kla08]
F. Klaedtke. Bounds on the automata size for Presburger Arithmetic. ACM
Trans.
Comput. Logic, 9(2), 2008. Cf. [Kla04].
[Kle43]

S. C. Kleene. Recursive predicates and quantifiers. Trans. Amer. Math. Soc.
, 53(1):41-
73, 1943.
[Kle56]
S. C. Kleene. Representation of events in nerve nets and finite automata. In
C. E.
Shannon and J. McCarthy, editors, Automata Studies, pages 3-42.
Princeton Univ.
Press, Princeton, N.J., 1956.
[KM08]
F. Kr √∂ger and S. Merz. Temporal Logic and State Systems. Texts in Theor.
Comp. Sci.
An EATCS Series. Springer, 2008.
[KN10]
B. Khoussainov and A. Nerode. Automata theory and its applications.
Springer, 2010.
[Kna28]
B. Knaster. Un th√©or√®m sur les fonctions d'ensembles. Annals Soc. Pol.
Math, 6:133-
134, 1928.
[Kol07]
P. G. Kolaitis. On the expressive power of logics on finite models. In Finite
Model Theory and Its Applications, pages 27-123. Springer, 2007.

[K Àù
on27]
D. K Àù
onig. √úber eine Schlussweise aus dem Endlichen ins Unendliche. Acta
litterarum ac scientiarum Regiae universitatis Hungaricae Francisco-
Josephinae. Sectio: Acta scientiarum mathematicarum, 3:121-130, 1927.
[Koz76]
D. Kozen. On parallelism in Turing machines. In Proc. 17th Symp. on
Foundations of Computer Science, FOCS'76, pages 89-97. IEEE, 1976.
414
References
[Koz82]
D. Kozen. Results on the propositional ùúá-calculus. In Proc. 9th Coll. on
Automata, Languages and Programming, ICALP'82, volume 140 of LNCS,
pages 348-359. Springer, 1982.
[Koz83]
D. Kozen. Results on the propositional ùúá-calculus. Theor. Comp. Sci. ,
27:333-354, 1983. Cf. [Koz82].
[KP83]
D. Kozen and R. Parikh. A decision procedure for the propositional ùúá-
calculus. In Proc. Workshop on Logics of Programs, volume 164 of Lect.
Notes in Comp. Sci. , pages 313-325. Springer, 1983.
[Kr √∂77]

F. Kr √∂ger. LAR: A logic of algorithmic reasoning. Acta Inform. , 8:243-
266, 1977.
[Kr √∂87]
F. Kr √∂ger. Temporal Logic of Programs. Springer, 1987.
[Kup18]
O. Kupferman. Automata theory and model checking. In Handbook of
Model Checking, pages 107-151. Springer, 2018.
[KV97]
O. Kupferman and M. Y. Vardi. Weak alternating automata are not that
weak. In Proc.
5th Israel Symp. on Theory of Computing and Systems, ISTCS'97, pages
147-158.
IEEE, 1997.
[KV98]
O. Kupferman and M. Y. Vardi. Weak alternating automata and tree
automata emptiness. In Proc. 30th Symp. on Theory of Computing,
STOC'98, pages 224-233. ACM, 1998.
[KV01]
O. Kupferman and M. Y. Vardi. Weak alternating automata are not that
weak. ACM
Trans. Comput. Logic, 2(3):408-429, 2001. Cf. [KV97].
[KVW00]
O. Kupferman, M. Y. Vardi, and P. Wolper.

An automata-theoretic approach to
branching-time model checking. J. Assoc. Comp. Mach. , 47(2):312-360,
2000. Cf.
[BVW94].
[Lad77]
R. E. Ladner. Application of model theoretic games to discrete linear orders
and finite automata. Inform. Control, 33(4):281-303, 1977.
[Lan05]
M. Lange. Solving parity games by a reduction to SAT. In Proc. Workshop
on Games in Design and Verification, GDV'05, 2005.
[Lan08]
M. Lange. A purely model-theoretic proof of the exponential succinctness
gap between
+
CTL
and CTL. Inform. Proc. Lett. , 108:308-312, 2008.
+
[LBC 94]
D. E. Long, A. Browne, E. M. Clarke, S. Jha, and W. R. Marrero. An
improved algorithm for the evaluation of fixpoint expressions. In Proc. 6th
Conf. on Computer Aided Verification, CAV'94, volume 818 of Lect. Notes
in Comp. Sci. , pages 338-350.
Springer, 1994.

[Leh18]
K. Lehtinen. A modal ùúá perspective on solving parity games in quasi-
polynomial time. In Proc. 33rd Symp. on Logic in Computer Science,
LICS'18, pages 639-648.
ACM, 2018.
[Len96]
G. Lenzi. A hierarchy theorem for the ùúá-calculus. In Proc. 23rd Coll. on
Automata, Languages and Programming, ICALP'96, volume 1099 of Lect.
Notes in Comp. Sci. , pages 87-97. Springer, 1996.
[Len05]
G. Lenzi. The modal ùúá -calculus: a survey. Task Quarterly, 9(3):293-316,
2005.
[Lib06]
L. Libkin. Logics for unranked trees: An overview. Log. Meth. Comput. Sci.
, 2(3), 2006.
[LJBA01]
C. S. Lee, Neil D. Jones, and A. M. Ben-Amram. The size-change principle
for program termination. In Proc. 28th Symp. on Principles of
Programming Languages, POPL'01, pages 81-92. ACM, 2001.
[LLS78]
R. E. Ladner, R. J. Lipton, and L. J. Stockmeyer. Alternating pushdown
automata (preliminary report).
In Proc. 19th Symp. on Foundations of Computer Science,
FOCS'78, pages 92-106. IEEE, 1978.

[LLS84]
R. E. Ladner, R. J. Lipton, and L. J. Stockmeyer. Alternating pushdown and
stack automata. SIAM J. Comp. , 13(1):135-155, 1984. Cf. [LLS78].
[Loa03]
R. Loader. Higher order beta matching is undecidable. Logic J. IGPL,
11(1):51-68, 2003.
[L √∂d99]
C. L √∂ding. Optimal bounds for transformations of omega-automata. In
Proc. 19th Conf. on Foundations of Software Technology and Theoretical
Computer Science, FSTTCS'99, volume 1738 of Lect. Notes in Comp. Sci. ,
pages 97-109. Springer, 1999.
References
415
[L √∂d21]
C. L √∂ding. Automata on infinite trees. In J.-E. Pin, editor, Handbook of
Automata Theory, pages 265-302. Europ. Math. Society Publ. House, 2021.
[LP00]
O. Lichtenstein and A. Pnueli. Propositional temporal logics: Decidability
and completeness. Logic J. IGPL, 8(1):55-85, 2000.
[LPSW22] K. Lehtinen, P. Parys, S. Schewe, and D. Wojtczak. A recursive
approach to solving parity games in quasipolynomial time. Log. Meth.
Comp. Sci. , 18(1), 2022.
[LSL84]
R. E. Ladner, L. J. Stockmeyer, and R. J. Lipton.

Alternation bounded auxiliary
pushdown automata. Inform. Control, 62(2/3):93-108, 1984.
[LT00]
C. L √∂ding and W. Thomas. Alternating automata and logics over infinite
words. In Proc. 1st Conf. on Theoretical Computer Science, TCS'00,
volume 1872 of Lect. Notes in Comp. Sci. , pages 521-535. Springer, 2000.
[Mar75]
D. A. Martin. Borel determinacy. Ann. Math. , 102:363-371, 1975.
[MC13]
R. Mayr and L. Clemente. Advanced automata minimization. In Proc. 40th
Symp. on Principles of Programming Languages, POPL'13, pages 63-74.
ACM, 2013.
[McN66]
R. McNaughton. Testing and generating infinite sequences by a finite
automaton.
Inform. Control, 9(5):521-530, 1966.
[McN93]
R. McNaughton. Infinite games played on finite graphs. Annals Pure Appl.
Logic, 65(2):149-184, 1993.
[MH84]
S. Miyano and T. Hayashi. Alternating finite automata on omega-words.
Theor. Comp.
Sci. , 32(3):321-330, 1984.

[Mic88]
M. Michel. Complementation is more difficult with automata on infinite
words. Technical Report 15, Centre national d'√©tudes des
t√©l√©communications, Paris, 1988.
[Mil80]
R. Milner. A Calculus of Communicating Systems, volume 94 of Lect. Notes
in Comp.
Sci. Springer, 1980.
[Mos91]
A. W. Mostowski. Games with forbidden positions. Technical report, Univ.
of Gda ≈Ñsk, 1991.
[MP71]
R. McNaughton and S. Papert. Counter-Free Automata. MIT Press,
Cambridge, Mass., 1971.
[MS72]
A. R. Meyer and L. J. Stockmeyer. The equivalence problem for regular
expressions with squaring requires exponential space.
In Proc. 13th Symp. on Switching and
Automata Theory, pages 125-129. IEEE, 1972.
[MS73]
A. R. Meyer and L. J. Stockmeyer. Word problems requiring exponential
time. In Proc.
5th Symp. on Theory of Computing, STOC'73, pages 1-9, New York, 1973.
ACM.

[MS84]
D. Muller and P. Schupp.
Alternating automata on infinite objects: determinacy
and Rabin's theorem. In Proc. Ecole de Printemps d'Informatique
Th√©oretique on Automata on Infinite Words, volume 192 of Lect. Notes in
Comp. Sci. , pages 100-107.
Springer, 1984.
[MS87]
D. E. Muller and P. E. Schupp. Alternating automata on infinite trees.
Theor. Comp.
Sci. , 54(2-3):267-276, 1987. Cf. [MS84].
[MS95]
D. E. Muller and P. E. Schupp. Simulating alternating tree automata by
nondeterministic automata: New results and new proofs of the theorems of
Rabin, McNaughton and Safra. Theor. Comp. Sci. , 141(1-2):69-107, 1995.
[MSS88]
D. E. Muller, A. Saoudi, and P. E. Schupp. Weak alternating automata give
a simple explanation of why most temporal and dynamic logics are
decidable in exponential time. In Proc. 3rd Symp. on Logic in Computer
Science, LICS'88, pages 422-427.
IEEE, 1988.
[Mul63]
D. E. Muller. Infinite sequences and finite machines. In Proc. 4th Symp. on
Switching Circuit Theory and Logical Design, pages 3-16. IEEE, 1963.

[Ner58]
A. Nerode. Linear automaton transformations. Proc. Amer. Math. Soc. ,
9(4):541-544, 1958.
[Niw97]
D. Niwi ≈Ñski. Fixed point characterization of infinite behavior of finite-state
systems.
Theor. Comp. Sci. , 189(1-2):1-69, 1997.
ùëù ùëõ
2
[Opp78]
D. C. Oppen. A 22
upper bound on the complexity of Presburger arithmetic. J.
Comp. Sys. Sci. , 16:323-332, 1978.
416
References
[Par70]
D. Park. Fixpoint induction and proof of program semantics. In Machine
Intelligence, volume 5, pages 59-78. Edinburgh Univ. Press, 1970.
[Par19]
P. Parys. Parity games: Zielonka's algorithm in quasi-polynomial time. In
Proc. 44th Symp. on Mathematical Foundations of Computer Science,
MFCS'19, volume 138 of LIPIcs, pages 10:1-10:13. Schloss Dagstuhl -
Leibniz-Zentrum f √ºr Informatik, 2019.

[Par20]
P. Parys. Parity games: Another view on Lehtinen's algorithm. In Proc.
28th Conf. on Computer Science Logic, CSL'20, volume 152 of LIPIcs,
pages 32:1-32:15. Schloss Dagstuhl - Leibniz-Zentrum f √ºr Informatik,
2020.
[Pit06]
N. Piterman. From nondeterministic B √ºchi and Streett automata to
deterministic parity automata. In Proc. 21st Symp. on Logic in Computer
Science, LICS'06, pages 255-264.
IEEE Computer Society, 2006.
[Pnu77]
A. Pnueli. The temporal logic of programs. In Proc. 18th Symp. on
Foundations of Computer Science, FOCS'77, pages 46-57, Providence, RI,
USA, 1977. IEEE.
[PP86]
D. Perrin and J.-E. Pin.
First-order logic and star-free sets.
J. Comp. Sys. Sci. ,
32(3):393-406, 1986.
[PP04]
D. Perrin and J.-E. Pin. Infinite words - automata, semigroups, logic and
games, volume 141 of Pure and applied mathematics series. Elsevier, 2004.
[Pre27]

M. Presburger. √úber die Vollst√§ndigkeit eines gewissen Systems der
Arithmetik ganzer Zahlen, in welchen die Addition als einzige Operation
hervortritt. In Comptes Rendus du Premier Congr√®s des Math√©maticienes
des Pays Slaves, pages 92-101, 395, Warsaw, 1927.
[Pri57]
A. N. Prior. Time and modality. Oxford Univ. Press, Oxford, UK, 1957.
[Pur95]
A. Puri. Theory of hybrid systems and discrete event systems. PhD thesis,
Univ. of California, Berkeley, 1995.
[PV01]
V. Petersson and S. Vorobyov. A randomized subexponential algorithm for
parity games. Nordic J. Computing, 8(3):324-345, 2001.
[PW23]
P. Parys and A. Wiacek. Improved complexity analysis of quasi-polynomial
algorithms solving parity games. In Proc. 19th Conf. on Computability in
Europe, CiE'23, volume 13967 of Lect. Notes in Comp. Sci. , pages 275-
286. Springer, 2023.
[Rab69]
M. O. Rabin. Decidability of second-order theories and automata on
infinite trees.
Trans. Amer. Math. Soc. , 141(5):1-35, Jul. 1969.
[Rab70]
M. O. Rabin. Weakly definable relations and special automata. In Proc.
Coll. on Mathematical Logic and Foundations of Set Theory, volume 59 of
Studies in Logic and the Found. of Math. , pages 1-23. Elsevier, 1970.

[Rab72]
M. O. Rabin. Automata on Infinite Objects and Church's Problem. AMS,
1972.
[Rab14]
A. Rabinovich. A proof of Kamp's theorem. Log. Meth. Comp. Sci. , 10(1),
2014.
[Ram30]
F. P. Ramsey. On a problem in formal logic. Proc. London Math. Soc. (3),
30:264-286, 1930.
[Ros97]
E. Rosen. Modal logic over finite structures. J. Log. Lang. Inf. , 6(4):427-
439, 1997.
[RS59]
M. O. Rabin and D. Scott. Finite automata and their decision problems.
IBM J.
Research and Dev. , 3:114-125, 1959.
[Saf88]
S. Safra. On the complexity of ùúî-automata. In Proc. 29th Symp. on
Foundations of Computer Science, FOCS'88, pages 319-327. IEEE, 1988.
[Saf89]
S. Safra. Complexity of automata on infinite objects. PhD thesis, Weizmann
Inst. of Sci., Rehovot, Israel, 1989.
[Saf92]

S. Safra. Exponential determinization for ùúî-automata with strong-fairness
acceptance condition (extended abstract).
In Proc. 24th Symp. on the Theory of Computing,
STOC'92, pages 275-282. ACM, 1992.
[Sao91]
A. Saoudi. Generalized automata on infinite trees and Muller-
McNaughton's theorem.
Theor. Comp. Sci. , 84(2):165-177, 1991.
[Sav69]
W. J. Savitch. Deterministic simulation of nondeterministic Turing
Machines. In Proc.
1st Symp. on Theory of Computing, STOC'69, pages 247-248. ACM, 1969.
[Sav70]
W. J. Savitch. Relationships between nondeterministic and deterministic
tape complexities. J. Comp. Sys. Sci. , 4:177-192, 1970. Cf. [Sav69].
References
417
[SC82]
A. P. Sistla and E. M. Clarke. The complexity of propositional linear
temporal logics.
In Proc. 14th Symp. on Theory of Computing, STOC'82, pages 159-168.
ACM, 1982.
[SC85]

A. P. Sistla and E. M. Clarke. The complexity of propositional linear
temporal logics.
J. Assoc. Comp. Mach. , 32(3):733-749, 1985. Cf. [SC82].
[Sch65]
M. P. Sch √ºtzenberger.
On finite monoids having only trivial subgroups.
Inform.
Control, 8(2):190-194, 1965.
[Sch72]
M. P. Sch √ºtzenberger. A propos du relation rationelles fonctionnelles. In
Proc. Coll. on Automata, Languages and Programming, ICALP'72, pages
103-114. North-Holland, 1972.
[Sch02]
S. Schwoon. Determinization and complementation of Streett automata. In
E. Gr√§del, W. Thomas, and T. Wilke, editors, Automata Logics, and Infinite
Games: A Guide to Current Research, volume 2500 of Lect. Notes in Comp.
Sci. , pages 79-91. Springer, 2002.
[Sch07a]
S. Schewe. Solving parity games in big steps. In Proc. 27th Conf. on
Foundations of Software Technology and Theoretical Computer Science,
FSTTCS'07, volume 4855 of Lect. Notes in Comp. Sci. , pages 449-460.
Springer, 2007.
[Sch07b]
T. Schwentick. Automata for XML - a survey. J. Comp. Sys. Sci. , 73(3):289-
315, 2007.

[Sch09a]
S. Schewe. B √ºchi complementation made tight. In Proc. 26th Symp. on
Theoretical Aspects of Computer Science, STACS'09, volume 3 of LIPIcs,
pages 661-672. Schloss Dagstuhl - Leibniz-Zentrum f √ºr Informatik, 2009.
[Sch09b]
S. Schewe. Tighter bounds for the determinisation of B √ºchi automata. In
Proc. 12th Conf. on Foundations of Software Science and Computation
Structures, FOSSACS'09, volume 5504 of Lect. Notes in Comp. Sci. , pages
167-181. Springer, 2009.
[Sch17]
S. Schewe. Solving parity games in big steps. J. Comp. Sys. Sci. , 84:243-
262, 2017.
Cf. [Sch07a].
[SE84]
R. S. Streett and E. A. Emerson. The propositional ùúá-calculus is elementary.
In Proc.
11th Coll. on Automata, Languages, and Programming, ICALP'84, volume
172 of Lect. Notes in Comp. Sci. , pages 465-472. Springer, 1984.
[SE89]
R. S. Streett and E. A. Emerson. An automata theoretic decision procedure
for the propositional ùúá -calculus. Inform. Comp. , 81(3):249-264, 1989. Cf.
[SE84].
[Sei89]
H. Seidl. Deciding equivalence of finite tree automata. In Proc. 6th Symp.
on Theoretical Aspects of Computer Science, STACS'89, volume 349 of
Lect. Notes in Comp.

Sci. , pages 480-492. Springer, 1989.
[Sei90]
H. Seidl. Deciding equivalence of finite tree automata. SIAM J. Comp. ,
19(3):424-437, 1990. Cf. [Sei89].
[Sei96]
H. Seidl. Fast and simple nested fixpoints. Inform. Proc. Lett. , 59(6):303-
308, 1996.
[Sha81]
M. Sharir. A strong-connectivity algorithm and its applications in data flow
analysis.
Comp. Math. Appl. , 7(1):67-72, 1981.
[Sip13]
M. Sipser. Introduction to the Theory of Computation. Course Technology,
3rd edition, 2013.
[Sku02]
J. Skurczynski. A characterization of B √ºchi tree automata. Inform. Process.
Lett. , 81(1):29-33, 2002.
[SLG94]
V. Stoltenberg-Hansen, I. Lindstr √∂m, and E. R. Griffor. Mathematical
theory of domains, volume 22 of Cambridge Tracts in Theor. Comp. Sci.
Cambridge Univ. Press, 1994.
[SMPS21]
A. Di Stasio, A. Murano, V. Prignano, and L. Sorrentino. Improving parity
games in practice. Ann. Math. Artif. Intell. , 89(5-6):551-574, 2021.

[SMS90]
A. Saoudi, D. E. Muller, and P. E. Schupp. Recognizable infinite tree sets
and their complexity. In Proc. 10th Conf. on Foundations of Software
Technology and Theor.
Comp. Sci., FSTTCS'90, volume 472 of Lect. Notes in Comp. Sci. , pages
91-103.
Springer, 1990.
[SS98]
P. Stevens and C. Stirling. Practical model-checking using games. In Proc.
4th Conf.
on Tools and Algorithms for the Construction and Analysis of Systems,
TACAS'98, volume 1384 of Lect. Notes in Comp. Sci. , pages 85-101.
Springer, 1998.
418
References
[Sti95]
C. Stirling. Local model checking games. In Proc. 6th Conf. on
Concurrency Theory, CONCUR'95, volume 962 of Lect. Notes in Comp.
Sci. , pages 1-11. Springer, 1995.
[Sti06]
C. Stirling. A game-theoretic approach to deciding higher-order matching.
In Proc.
33rd Coll. on Automata, Languages and Programming, ICALP'06, volume
4052 of Lect. Notes in Comp. Sci. , pages 348-359. Springer, 2006.
[Sti09]

C. Stirling. Decidability of higher-order matching. Log. Meth. Comp. Sci. ,
5(3), 2009.
Cf. [Sti06].
[Sto74]
L. J. Stockmeyer. The complexity of decision problems in automata theory
and logic.
PhD thesis, MIT, 1974.
[Str82]
R. S. Streett. Propositional dynamic logic of looping and converse is
elementarily decidable. Inform. Control, 54(1/2):121-141, 1982.
[Str94]
H. Straubing. Finite Automata, Formal Logic, and Circuit Complexity.
Birkh√§user, 1994.
[SV12]
S. Schewe and T. Varghese. Tight bounds for the determinisation and
complementation of generalised B √ºchi automata. In Proc. 10th Symp. on
Automated Technology for Verification and Analysis, ATVA'12, volume
7561 of Lect. Notes in Comp. Sci. , pages 42-56. Springer, 2012.
[SVW83]
A. P. Sistla, M. Y. Vardi, and P. Wolper. Reasoning about infinite
computation paths.
In Proc. 24th Symp. on Foundations of Computer Science, FOCS'83, pages
185-194.
IEEE, 1983.

[SW11]
R. Sedgewick and K. Wayne. Algorithms. Addison-Wesley, 4th edition, 2011.
[SY00]
K. Salomaa and S. Yu. Alternating finite automata and star-free languages.
Theor.
Comput. Sci. , 234(1-2):167-176, 2000.
[Tar55]
A. Tarski. A lattice-theoretical fixpoint theorem and its application. Pac. J.
Math. , 5:285-309, 1955.
[Tar72]
R. E. Tarjan. Depth-first search and linear graph algorithms. SIAM J.
Comp. , 1:146-
160, 1972.
[TB73]
B. A. Trakhtenbrot and J. M. Barzdin. Finite automata. Fundamental
studies in computer science. North-Holland, 1973.
[Tho79]
W. Thomas. Star-free regular sets of ùúî-sequences. Inform. Control,
42(2):148-156, 1979.
[Tho81]
W. Thomas. A combinatorial approach to the theory of ùúî-automata. Inform.
Control, 48:261-283, 1981.
[Tho90]

W. Thomas. Automata on infinite objects. In J. van Leeuwen, editor,
Handbook of Theor. Comp. Sci. Volume B: Formal Models and Semantics,
pages 133-191. Elsevier and MIT Press, 1990.
[Tho97]
W. Thomas. Languages, automata, and logic. In G. Rozenberg and A.
Salomaa, editors, Handbook of Formal Languages, Vol. 3: Beyond Words,
pages 389-455. Springer, 1997.
[Tra61]
B. A. Trakhtenbrot. Finite automata and logic of monadic predicates (in
Russian).
Doklady Akademii Nauk SSSR, 140:326-329, 1961.
[TW68]
J. W. Thatcher and J. B. Wright. Generalized finite automata theory with an
application to a decision problem of second-order logic. Math. Sys. Theory,
2(1):57-81, 1968.
[TWD20]
C. Tian, W. Wang, and Z. Duan. Making Streett determinization tight. In
Proc. 35th Symp. on Logic in Computer Science, LICS'20, pages 859-872.
ACM, 2020.
[Var88]
M. Y. Vardi. A temporal fixpoint calculus. In Proc. Conf. on Principles of
Programming Languages, POPL'88, pages 250-259. ACM, 1988.
[Var96]
M. Y. Vardi. An Automata-Theoretic Approach to Linear Temporal Logic,
volume 1043 of Lect. Notes in Comp. Sci. , pages 238-266. Springer, 1996.

[Var08]
M. Y. Vardi. From Church and Prior to PSL. In 25 Years of Model Checking
- History, Achievements, Perspectives, volume 5000 of Lect. Notes in
Comp. Sci. , pages 150-171.
Springer, 2008.
[vB76]
J. van Benthem. Modal Correspondence Theory. PhD thesis, Univ. of
Amsterdam, 1976.
References
419
[vB84]
J. van Benthem. Correspondence theory. In D. Gabbay and F. Guenthner,
editors, Handbook of Philosophical Logic, Volume II: Extensions of
Classical Logic, pages 167-247. D. Reidel, 1984.
[vD18]
T. van Dijk. Oink: An implementation and evaluation of modern parity
game solvers.
In Proc. 24th Conf. on Tools and Algorithms for the Construction and
Analysis of Systems, TACAS'18, volume 10805 of Lect. Notes in Comp. Sci.
, pages 291-308.
Springer, 2018.
[vDR19]
T. van Dijk and B. Rubbens. Simple fixpoint iteration to solve parity games.
In Proc.

10th Symp. on Games, Automata, Logics, and Formal Verification,
GandALF'19, volume 305 of EPTCS, pages 123-139, 2019.
[VJ00]
J. V √∂ge and M. Jurdzi ≈Ñski. A discrete strategy improvement algorithm for
solving parity games. In Proc. 12th Conf. on Computer Aided Verification,
CAV'00, volume 1855 of Lect. Notes in Comp. Sci. , pages 202-215.
Springer, 2000.
[VS85]
M. Y. Vardi and L. Stockmeyer. Improved upper and lower bounds for modal
logics of programs. In Proc. 17th Symp. on Theory of Computing, STOC'85,
pages 240-251, Baltimore, USA, 1985. ACM.
[VW84]
M. Y. Vardi and P. Wolper. Automata-theoretic techniques for modal logics
of programs (extended abstract). In Proc. 16th Symp. on Theory of
Computing, STOC'84, pages 446-456. ACM, 1984.
[VW86]
M. Y. Vardi and P. Wolper. Automata-theoretic techniques for modal logic of
programs.
J. Comp. Sys. Sci. , 32:183-221, 1986. Cf. [VW84].
[VW94]
M. Y. Vardi and P. Wolper. Reasoning about infinite computations. Inform.
Comp. , 115(1):1-37, 1994. Cf. [SVW83].
[WDHR06] M. De Wulf, L. Doyen, T. A. Henzinger, and J.-F. Raskin.
Antichains: A new algorithm for checking universality of finite automata. In
Proc. 18th Conf. on Computer Aided Verification, CAV'06, volume 4144 of
Lect. Notes in Comp. Sci. , pages 17-30. Springer, 2006.

[WDMR08] M. De Wulf, L. Doyen, N. Maquet, and J.-F. Raskin.
Antichains: Alternative algorithms for LTL satisfiability and model-
checking. In Proc. 14th Conf. on Tools and Algorithms for the Construction
and Analysis of Systems, TACAS'08, volume 4963 of Lect. Notes in Comp.
Sci. , pages 63-77. Springer, 2008.
[Wil99a]
T. Wilke. Classifying discrete temporal properties. In Proc. 16th Symp. on
Theoretical Aspects of Computer Science, STACS'99, volume 1563 of Lect.
Notes in Comp. Sci. , pages 32-46. Springer, 1999.
+
[Wil99b]
T. Wilke. CTL
is exponentially more succinct than CTL. In Proc. 19th Conf. on
Foundations of Software Technology and Theoretical Computer Science,
FSTTCS'99, volume 1738 of LNCS, pages 110-121. Springer, 1999.
[Wil01]
T. Wilke. Alternating tree automata, parity games, and modal ùúá-calculus.
Bull. Belgian Math. Soc. , 8(2):359-391, 2001.
[Win93]
G. Winskel. The Formal Semantics of Programming Languages: An
Introduction.
MIT Press, 1993.
[Zap02]
J. Zappe. Modal ùúá-calculus and alternating tree automata. In E. Gr√§del, W.
Thomas, and T. Wilke, editors, Automata Logics, and Infinite Games: A

Guide to Current Research, volume 2500 of Lect. Notes in Comp. Sci. ,
pages 171-184. Springer, 2002.
[Zie98]
W. Zielonka. Infinite games on finitely coloured graphs with applications to
automata on infinite trees. Theor. Comp. Sci. , 200(1-2):135-183, 1998.
[ZP95]
U. Zwick and M. Paterson. The complexity of mean payoff games. In Proc.
1st Conf.
on Computing and Combinatorics, COCOON'95, volume 959 of Lect.
Notes in Comp.
Sci. , pages 1-10. Springer, 1995.
[ZP96]
U. Zwick and M. Paterson. The complexity of mean payoff games on
graphs. Theor.
Comp. Sci. , 158(1-2):343-359, 1996. Cf. [ZP95].
OceanofPDF.com

Document Outline
Preface
Contents
Acronyms
Part I Finite Words
Chapter 1 Regular Languages
1.1 Regular Expressions
1.2 Nondeterministic Finite Automata
1.3 Deterministic Finite Automata
1.4 Decidability and Complexity
Bibliographic Notes
Exercises
Chapter 2 Monadic Second-Order Logic
2.1 Syntax and Semantics
2.2 MSO-Definability and Regularity
2.2.1 From Automata to Formulas
2.2.2 From Formulas to Automata
2.2.3 Consequences of the Translations
2.3 The Complexity of MSO
2.4 Weak Second-Order Logic of One Successor
2.5 Presburger Arithmetic
Bibliographic Notes
Exercises
Chapter 3 Alternating Finite Automata
3.1 Run Trees
3.2 Expressiveness and Succinctness
3.3 Closure Properties
3.4 Reachability Games
3.4.1 Games, Plays and Strategies
3.4.2 Attractors
3.4.3 Determinacy
3.4.4 Polynomial-Time Solvability
3.5 A Game-Theoretic Semantics
Bibliographic Notes

Exercises
Chapter 4 Star-Free Languages
4.1 First-Order Logic
4.2 Ehrenfeucht-Fra√Øss√© Games
4.2.1 Word-Comparison Games
4.2.2 Indistinguishability through First-Order Formulas
4.3 Star-Free Expressions
4.4 First-Order Equals Star-Freeness
4.4.1 From Expressions to Formulas
4.4.2 From Formulas to Expressions
Bibliographic Notes
Exercises
Part II Infinite Words
Chapter 5 Automata on Infinite Words
5.1 Regular Languages of Infinite Words
5.1.1 InfiniteWords
5.1.2 ùùé-Regular Expressions
5.2 Nondeterministic B√ºchi Automata
5.3 Closure Properties
5.3.1 Unions, Left-Concatenations and ùùé-Iterations
5.3.2 Intersections and Homomorphisms
5.4 Deterministic B√ºchi Automata
5.5 Complementation Closure
5.5.1 Ramsey's Theorem
5.5.2 B√ºchi's Complementation Construction
5.6 Monadic Second-Order Logic on Infinite Words
Bibliographic Notes
Exercises
Chapter 6 Acceptance Conditions
6.1 Rabin- and Streett-Automata
6.2 Parity Automata
6.2.1 Priorities for Acceptance and Rejection
6.2.2 Parity vs. B√ºchi Acceptance
6.2.3 Parity vs. Rabin and Streett Acceptance
6.3 Muller Automata
6.3.1 The Most General Acceptance Condition
6.3.2 Muller vs. B√ºchi Acceptance

6.3.3 Muller vs. Parity Acceptance
6.4 Co-B√ºchi Automata
6.5 Transition-Based Acceptance
6.5.1 From States to Edges
6.5.2 From Edges to States
6.6 Expressiveness of Finite Automata on Infinite Words
Bibliographic Notes
Exercises
Chapter 7 Determinisation
7.1 The Inadequacy of Powerset-Based Determinisation
7.2 Trees and Konig's Lemma
7.2.1 A Formal Model of Trees
7.2.2 Infinite Paths in Trees
7.3 The Safra Construction
7.3.1 Refining the Powerset Construction
7.3.2 Correctness of the Construction
7.3.3 A Lower Bound on Complementation and
Determinisation
7.3.4 From NBA to DPA
Bibliographic Notes
Exercises
Chapter 8 Decision Problems
8.1 Automata Non-Emptiness
8.1.1 Graphs and Strongly Connected Components
8.1.2 Rabin and Parity Automata
8.1.3 Streett Automata
8.2 Universality and Subsumption
8.2.1 From Subsumption to Universality
8.2.2 Universality as a Search Problem in Monoids
8.3 An Application: Size-Change Termination
8.3.1 Recursive Programs
8.3.2 Termination Analysis as B√ºchi Inclusion
Bibliographic Notes
Exercises
Chapter 9 Alternating B√ºchi Automata
9.1 Alternating Automata on Infinite Words
9.1.1 Syntax and Semantics

9.1.2 Memoryless Runs
9.2 A Game-Theoretic Semantics
9.2.1 B√ºchi Games
9.2.2 Acceptance as a Game
9.3 Expressiveness
9.3.1 Alternation Elimination
9.3.2 Universal and Deterministic Automata
9.4 Complementation via Alternating Automata
9.5 Weak Automata
9.5.1 Weak B√ºchi and co-B√ºchi Automata
9.5.2 Weak Parity Automata
Bibliographic Notes
Exercises
Chapter 10 Linear-Time Temporal Logic
10.1 Syntax and Semantics
10.1.1 Alphabets of Atomic Propositions
10.1.2 Formulas Built from Temporal Operators
10.1.3 Temporal Equivalences
10.1.4 Unfoldings of Temporal Operators
10.2 Nondeterministic B√ºchi Automata for LTL
10.2.1 Generalised B√ºchi Automata
10.2.2 From LTL to Generalised B√ºchi Automata
10.3 From LTL to Very Weak Alternating Automata
10.4 An Application: Formal Verification
10.4.1 Labelled Transition Systems and Traces
10.4.2 Model Checking
Bibliographic Notes
Exercises
Part III Trees
Chapter 11 Automata on Finite Trees
11.1 Finite Trees
11.1.1 Trees and Tree Languages
11.1.2 Two Different Directions
11.2 Direction Bottom-Up
11.2.1 Bottom-Up Tree Automata
11.2.2 Determinisation
11.2.3 Closure Properties

11.3 Direction Top-Down
11.3.1 Top-Down Tree Automata
11.3.2 Expressiveness
11.3.3 Decision Problems
11.4 Monadic Second-Order Logic on Finite Trees
11.5 Applications
11.5.1 Higher-Order Matching
11.5.2 Tree Automata for XML Data Processing
Bibliographic Notes
Exercises
Chapter 12 Parity Games
12.1 Games, Plays and Strategies
12.2 Basic Properties
12.2.1 Games with no Particular Initial Node
12.2.2 UniformWinning Strategies
12.2.3 Priority Compression
12.3 Winning Parity Games
12.3.1 Subgames
12.3.2 Positional Determinacy
12.4 Solving Parity Games
12.4.1 Theoretical Complexity
12.4.2 A Recursive Algorithm
Bibliographic Notes
Exercises
Chapter 13 Automata on Infinite Trees
13.1 Parity Tree Automata
13.1.1 Infinite Trees and Tree Languages
13.1.2 B√ºchi Tree Automata
13.1.3 Closure Properties
13.2 Complementation Closure
13.2.1 Acceptance as a Parity Game
13.2.2 The Complementation Construction
13.3 Decision Problems
13.3.1 Non-Emptiness via Parity Games
13.3.2 Complexity, Expressiveness and Consequences
13.3.3 Finitely Representable Trees
Bibliographic Notes

Exercises
Chapter 14 Logics on Infinite Trees
14.1 Monadic Second-Order Logic
14.1.1 Syntax and Semantics
14.1.2 Capturing Paths
14.1.3 Decidability
14.2 Full Branching-Time Logic
14.2.1 Syntax and Semantics
14.2.2 Decidability
14.2.3 Expressiveness
14.3 The Modal ùùÅ-Calculus
14.3.1 Modal Logic
14.3.2 Fixpoint Quantifiers
14.3.3 Syntax and Semantics
14.3.4 Decidability
Bibliographic Notes
Exercises
Index
References
OceanofPDF.com

