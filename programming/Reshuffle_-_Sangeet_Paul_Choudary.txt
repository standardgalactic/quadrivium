

OceanofPDF.com

Copyright Â© 2025 by Sangeet Paul Choudary
All rights reserved. No part of this book may be reproduced, stored in a retrieval system, or
transmitted in any form or by any means, whether electronic, mechanical, photocopying, recording,
or otherwise, without prior written permission of the author, except for brief quotations used in
reviews, academic work, or critical analysis.
The unauthorized scanning, uploading, and distribution of this book is a violation of the author's
intellectual property. If you would like permission to use material from the book (beyond review
purposes), please contact liz@platformthinkinglabs.com.
First Edition: July 2025
OceanofPDF.com

For my gentle daughter, Amaryah...
for teaching me how to reimagine the world through building blocks. 
OceanofPDF.com

ABOUT THE AUTHOR
Sangeet Paul Choudary is the author/co-author of multiple books, including the international best-
seller Platform Revolution, and has advised CEOs at more than 40 Fortune 500 firms on the topics of
AI and platform/ecosystem economics. He has been recognized as a Young Global Leader by the
World Economic Forum, and his writing has been featured four times in the Harvard Business
Review Top 10 Must Reads compilations.
Sangeet is currently a Senior Fellow at the University of California, Berkeley, a Scholar at Dartmouth
College, and was formerly the co-chair of the MIT Platform Strategy Summit. He has served on the
advisory boards of the ING Group, the Standard Bank Group, the Monetary Authority of Singapore's
AFIN, and Grupo Pao De Acucar. Sangeet is a member of the Ministerial Advisory Committee at the
Ministry of Housing and Urban Affairs, Government of India. 
Sangeet has also served as a thought leader for Microsoft, AT&T, SAP, Oracle, and several other
leading technology brands. As a frequent keynote speaker, Sangeet has presented at leading global
forums, including the G20 Summit, the World50 Summit, and the World Economic Forum.
OceanofPDF.com

TABLE OF CONTENTS
INTRODUCTION
SECTION 1 - AI AND THE SYSTEM
1. BEYOND AUTOMATION
What if we've been getting AI all wrong
2. THE WRONG FRAME
What if our fixation on job loss blinds us to the real impact of AI
3. NEW POWER, NEW TENSIONS
Why tools that promise progress also concentrate control
SECTION 2 - WORK AND ORGANIZATIONS
4. AI UNBUNDLES THE JOB
Why the future of work takes a lot more than just staying skilled
5. REBUNDLING THE JOB
Why reskilling is a losing game in a system that's already changed
6. REBUNDLING THE ORGANIZATION
What if AI wasn't your next hire but your next reorg
7. REBUNDLING THE VALUE CHAIN
New building blocks, new economic logic
SECTION 3 - COMPETITIVE ADVANTAGE
8. THE TOOL INTEGRATION TRAP
The hidden irony of AI-driven business advantage
9. THE SOLUTION ADVANTAGE
Why AI value capture is less about technology and more about managing risk
10. DESIGNING FOR INDECISION
How companies turn customer confusion into competitive moats in the age of AI
11. CONTROL WITHOUT CONSENSUS
How AI rewrites ecosystem power
12. YOU DON'T NEED AN AI STRATEGY
Where to play, how to win
Glossary
Acknowledgments
What Next
Upcoming Books By The Author
OceanofPDF.com

INTRODUCTION
WHY UNINTELLIGENT AI MATTERS
In the late spring of 2021, Singapore was the envy of the world. It had
seemingly outwitted COVID-19 with virus-tight borders and near-obsessive
contact tracing. And now, it had a vaccine stockpile and rollout plan in
place, which would ensure the country was Covid-free. In a world buckling
under the weight of the pandemic, Singapore was the exception.
That's precisely when things went wrong. Even as the first few rounds of
vaccine rollout started, Singapore found itself grappling with an unexpected
surge in COVID-19 cases. Restrictions returned. Streets emptied. This was
not supposed to happen.
How did a nation with near-total control lose its grip on the pandemic?
Singapore's infamous KTV lounges - adult entertainment venues not to be
confused with the sing-your-heart-out bars with off-key singing - are the
kind of places you didn't talk about in polite company. In these private
rooms, deals are made over expensive whiskey and in the company of
hostesses. The hostesses - known colloquially as 'butterflies' - flit from
room to room at a KTV lounge, entertaining men with smiles, small talk,
and more.
In this instance, as it turned out, a lot more than they had bargained for.

Patient Zero was one such 'butterfly'. She had entered the country using the
Familial Ties Lane - the only visa for which the borders remained open to
reunite family members - but was illegally working as a hostess, moving
between rooms carrying the virus along. With masks off in an intimate
setting, the virus moved freely between clients and hostesses. The lounges,
desperate to keep their discretion-loving clientele comfortable, ignored
contact-tracing. The men visiting these lounges didn't stay put either,
hopping from one KTV lounge to another through the course of the night,
silently planting the virus across the city.
In the morning, they returned home to their families and workplaces, the
virus in tow.
As the second wave broke out, the KTV clientele - well-heeled men with
reputations to protect - weren't exactly eager to step into the spotlight for
contact tracing. This further thwarted any efforts to rein in the virus with a
solution reliant on contact tracing.
Singapore was the poster child for COVID-19 response in the spring of
2021. By the summer, though, it had buckled under the strain of the second
wave. Its approach, rooted in technological solutionism and policy
precision, hadn't accounted for the blind spots in the system within which
the solution was to be deployed. The tools designed to control the pandemic
were based on the assumptions of compliance and visibility, but the real
system behaved differently. The use of the Familial Ties Lane, created an
invisible entry point, bypassing the tightly controlled border narrative. Once
inside, the virus moved through KTV lounges - spaces that actively avoided
compliance with contact tracing. Finally, as the outbreak unfolded, shame
and reputational risk discouraged the infected from stepping forward for
testing.
Singapore's second wave is a parable of the limits of technological
solutionism. It wasn't undone by a failed vaccine or flawed contact tracing,
but by a system whose hidden fault lines and interdependencies couldn't be
managed, even with the most accurate technologies or the most precise
policies.

In our obsession with AI's capabilities - its intelligence, its ability to write
essays, diagnose diseases, or master complex games - we're fixated on the
technology. We keep asking, "How smart is it?" or "What can it do?" The
techno-optimists point to AGI, the skeptics dismiss even that which already
works well. The real story, though, isn't in technology. It's in the system
within which the technology is deployed.
The intelligence distraction
Through much of the latter half of the twentieth century, artificial
intelligence was the brilliant child that never quite lived up to expectations.
Progress was slow, which kept expectations low. Even the more optimistic
researchers believed that without the ability to think like us, machines were
unlikely to replace us. The real world was too complex and ambiguous for
machines to navigate. Tasks requiring judgment, intuition, or creativity
were thought to be inherently human.
Many of those assumptions no longer hold as rigidly. Even though
machines haven't become more intelligent in a human sense, they've
become increasingly capable and performant in specific, economically
valuable ways. And with that, they offer adequate substitutes for human
performance, even if they may not replicate human thought.
The AI tools shaping today's economy don't rely on intuition or common
sense the way humans do, nor can they construct meaning. Instead, they
solve problems through very different means: by processing vast quantities
of data and identifying statistical patterns rather than applying reason.
Paradoxically, even tasks that appear to require comprehension, like
interpreting language, recognizing objects in images, or generating realistic
pictures, are all performed using the same underlying mechanism: pattern
prediction. A language model like ChatGPT has a powerful way of
'understanding' language by turning words into patterns that represent
meaning and context, even though it doesn't understand meaning and
context the same way humans do. Its approach to reasoning, by predicting

the next likely word from countless possibilities, is nothing like how
humans use language.
Yet when people discuss AI, the conversation often veers toward the wrong
questions, concerns such as consciousness, creativity, or whether machines
will replace human minds, fueled by polarizing debates and speculative
extremes. On the one hand, AI skeptics point to troubling evidence - AI
produces hallucinations, amplifies biases from its training data, and often
misclassifies information. It fails at simple tasks and is inconsistent at best.
On the other hand, some of the most prominent voices in AI promise a brain
as flexible and capable as ours that could understand and do anything a
human can, within a matter of years, sometimes even months. Those
timelines keep shifting, further encouraging AI skeptics to veer to the other
extreme and reject other applications of AI or its effects on our economy.
People often assume that for machines to match or surpass humans, they
must think the way we do. That flawed reasoning causes us to overlook how
powerful machines can be when they adopt a completely different
approach. The fundamental mistake is judging AI by how human it seems,
rather than by what it can do. This 'intelligence distraction', constantly
searching for human-like traits in AI, keeps us from focusing on the
economic and systemic implications of its actual capabilities. It prevents us
from asking the right question: Is it effective at what it's supposed to do?
What really matters is performance. AI is better understood as a focused,
practical utility that integrates into workflows and reshapes how decisions
are made. With that, it changes the structure of the system into which it is
introduced. Consider how GPS navigation has transformed the way we
navigate our cities and the overall driving experience, while taking over a
function that previously relied on our navigational judgment or a 'co-pilot'
with a paper map sitting beside the driver. Navigation tools like Google
Maps may not seem as impressive as AI tools like ChatGPT, but both
perform the same five core functions: they sense the environment, create a
working model of the world around them, reason and act based on this
model, while constantly learning and updating the model. For Google
Maps, the model is a simplified map of physical space that helps it predict

the next turn; for ChatGPT, it's a dynamic map of language patterns that
enables it to predict the following sequence of words.
AI tools may not understand meaning in the same way humans do, but they
learn by recognizing patterns and familiar structures in language. What sets
modern AI apart from older software is its ability to pay selective attention
to what matters in the moment, using memory to guide that focus. Think of
the difference between being stuck in a call center chatbot that keeps
looping back because it can't interpret your request, versus a conversation
with ChatGPT, where the system remembers your earlier questions,
understands the context, and adjusts its answers accordingly. By drawing on
past interactions, it prioritizes the right details and predicts what comes next
with surprising fluency. This ability to recognize patterns, pay selective
attention, and learn over time doesn't make AI intelligent in a human sense.
However, it creates something more practical and powerful: the ability to
adapt to complexity and perform reliably in unpredictable situations.
The case of GPS-based navigation also illustrates the role constraints play
in delivering performance. Google Maps is optimized to do one thing well:
dependable navigation. To achieve this, it limits itself to sensing reliable
inputs, keeps its world model simple, and adheres to fixed reasoning rules.
These constraints aren't limitations that weaken the tool. Instead, they are
deliberate design choices that make it reliable and performant.
AI's impact is often framed in narrow terms - what work it replaces, what
jobs it threatens, and how it boosts productivity. However, the real impact of
AI comes not from how it performs a task, but from how it restructures the
entire system around that task. Google Maps has made driving easier for
individuals, but it has also redefined urban mobility, transformed logistics,
and enabled entire industries, such as ride-hailing, to emerge.
Unless we understand the opportunities and challenges created by the
system that AI transforms, we risk missing the most important effects of the
technology in changing organizational structures, redefining business
models, and transforming the nature of industry competition. When AI
enters a system, it alters the economic logic of that system. It changes how
value is created and who gets to capture it.

It's not the technology, it's the system
The economic impact of AI is determined less by the complexity of the
tasks it performs and more by how it transforms the systems in which it
operates. Even though we measure progress in terms of AI's ability to meet
performance benchmarks on increasingly complex tasks, larger changes in
our organizations can be triggered by the transformation of even the most
mundane tasks.
For instance, consider the example of note-taking with AI. You might have
attended an online Zoom meeting where an AI note-taker transcribes the
conversation and sends out meeting notes and summaries right after. On the
surface, this appears to be the most mundane use of technology, hardly the
stuff of high-level knowledge work. However, that simple act of note-
taking, or audio transcription, illustrates AI's ability to convert unstructured
audio input into actionable, structured formats.
Consider the example of analyzing customer support calls, a task that would
take humans weeks of listening and note-taking to extract key insights. AI
can rapidly process hours of audio in minutes, identify common pain points
of customers, summarize key insights, and deliver clear takeaways to the
right teams. Instead of scattered audio logs that are rarely accessed,
everyone works with the right insights, helping them align quickly around
customer needs.
This matters because much of an organization's most valuable knowledge is
tacit, buried in meetings, emails, and conversations, inaccessible and
unshared. AI helps convert such tacit knowledge into explicit, actionable
insights that can be utilized across an organization. Tacit knowledge has
historically been difficult to scale or transfer, often remaining siloed within
individuals or teams. By making this knowledge explicit, AI not only
preserves it but also makes it widely accessible and actionable.
Shifting our view from thinking in terms of tasks to thinking in terms of
systems opens the door to reimagining how we structure work, workflows,
and organizations, not around human substitution, but around new

capabilities, sometimes as 'clerical' as audio transcription. It helps us focus
on building systems that leverage the capabilities enabled by AI, rather than
getting stuck on where it falls short in replicating human advantages.
Alongside the 'intelligence distraction', we also misunderstand the impact
of AI because of our inability to comprehend how technological
deployments transform the system in ways far beyond what anyone expects.
For instance, recommendation systems on YouTube and Amazon might
appear little more than helpful guides on the user interface, but wield
significant social and economic power by steering our attention, shaping
our preferences, and determining which content gets seen and which gets
buried. Generative AI models extend this logic into the workplace. When
used to manage knowledge across an organization, these technologies
determine which priorities appear in meeting notes and other internal
communication and, accordingly, influence how decisions are made. The
humble note-taking AI assistant joining one of your Zoom meetings shapes
the context in which decisions are made by determining what information
gets summarized and shared into further workflows. As these tools improve,
their suggestions carry more weight. AI, then, doesn't just perform tasks. It
changes how decisions are made and where we direct our attention. Even
small interventions in a system can produce large, unintended shifts in how
work is coordinated.
Despite the hype and resources devoted to improving AI, we've barely
begun to address how our systems should be reimagined to harness their
current performance levels. Even less 'intelligent' AI far outpaces our
systems' ability to understand its potential. We focus on whether the tool is
accurate, creative, or fair, without realizing that the bottlenecks holding us
back are our institutions, governance models, and workflows.
A better frame
As we employ different forms of AI in our daily lives, from the Tiktok
recommendations that keep us hooked to the generative AI tools we use to
summarize and synthesize our work, AI is becoming an institutional

infrastructure of sorts that shapes how organizations manage knowledge
and allocate attention, and - with that - how they make decisions. The more
relevant question, then, is not whether AI can think the way we do, but how
it changes the way we think, decide, and coordinate.
We've looked at Google Maps' navigation abilities to illustrate the power of
technology, but let's, for a moment, shift our attention to the underlying
map - a far simpler technology that has shaped the history of the world over
centuries. Maps are used for navigation, but also for governance. When the
British Empire charted its colonies, lines on a map became borders that
fueled decades of conflict. In 20th-century America, banks and insurers
used redlining maps that claimed to show credit risk but actually reinforced
racial and class-based segregation. Today, when Google Maps reroutes
traffic from busy highways into quiet neighborhood streets, it transforms
those neighborhoods without consent.
Most of us view maps as a means to interpret the spaces around us. We
often miss how maps transform those very spaces. Like maps, AI tools may
help us analyze and make sense of our work, but they hold far more power
in reconfiguring the systems within which that work is performed. Much
like recommendation algorithms on YouTube or TikTok ultimately shape
culture and influence elections, AI tools shape and change how economic
and social systems are structured and how they operate. Instead of asking
How smart is the machine?, we should shift our frame to ask What do our
systems look like once they adopt this new logic of the machine?
Today, you're probably using the least performant AI capabilities that will
ever exist. AI performance will most likely continue to improve in ways we
cannot entirely predict. But the future of AI will not be defined by that one
moment when it gets to general intelligence. It will be defined by how it
steadily reconfigures how our systems work.
Why unintelligent AI matters

Since the early 2010s, I've advised senior executives across a wide range of
industries on how technology transforms competitive advantage, not just by
enabling new capabilities, but by fundamentally changing how those
systems function. Competitive edge no longer comes from owning or
adopting the best tool, but from understanding how that tool restructures the
entire playing field. In my previous books, Platform Revolution and
Platform Scale, I explored how the rise of digital platforms prompted
companies to rethink their structure, shifting from operating like assembly
lines to functioning more like enablers of ecosystems. That broader lesson
goes beyond platforms. To understand the true impact of any new
technology on an economy, an organization, or society at large, we must
first examine how it alters the fundamental interactions within the system.
Yet despite this, many executives still start with the technology itself. They
focus on its features, bolt it onto existing systems, and hope for advantage.
Sustainable advantage, however, doesn't come from chasing capabilities or
layering new technology onto old assumptions. It comes from starting with
the system, understanding its moving parts, constraints, and logic, and then
asking how the new technology changes those foundations to unlock
outsized effect.
When we remain distracted by debates over whether AI is intelligent,
creative, or conscious, we not only lose the opportunity to harness the
transformative potential it already offers but also risk ending up on the
wrong side of the new power structures being shaped by those who do
understand these dynamics. The goal of this book is to bridge this gap and
to shift the conversation from speculative debates about AI's consciousness
to the many ways it can restructure value creation and shift power within
our economy.
This is why unintelligent AI matters. Instead of dwelling on AI's
technological advancements, this book focuses on the systems into which
AI is introduced - jobs, customer journeys, workflows, organizations, and
even entire competitive ecosystems - and how they must evolve to exploit
AI's capabilities fully. Central to this approach is the framework of
unbundling and rebundling: breaking down existing systems into their
components and reassembling them in new ways to create value.

To explore this transformation, the book is structured in three sections that
follow the arc of AI's impact, from how we think about it, to how it changes
how we work, to how it restructures competitive advantage and power.
We begin by reframing the mental models through which we understand AI.
The chapters in Section 1 demonstrate that AI is not merely a tool of
automation or substitution, but a force that transforms the economic logic of
any system by changing how value is created and distributed, and how these
changes reallocate power.
In Section 2, we zoom in on the world of work and the opportunities and
limitations introduced with AI. We look at how AI restructures
organizations and the roles and workflows within them. We also examine
the opportunities it creates, not in terms of new jobs, but in terms of new
value. Many tasks that once commanded high value may decline in
relevance, while new points of leverage emerge elsewhere in the system. In
a system that's constantly shifting, it's a mistake to keep looking for the
next job title once old ones no longer apply. The real opportunity for
workers is to track where value is headed and position themselves in its
path.
Finally, we scale out to the level of ecosystems and economies. In this
section, we examine how AI restructures competitive advantage, how it
elevates new winners and eliminates previous ones, how it changes
erstwhile partners to competitors and makes friends out of yesterday's foes,
and how it changes the very logic of an industry.
AI doesn't merely offer a better way to play the same old game. It offers an
opportunity to reimagine the playing field in your favor.
This is not a book about technology. By the time you read this, the
technology will likely have evolved significantly from what exists today, as
of the time of writing. There are many ways to discuss technology, but
writing a static book that tries to capture the specifics of a rapidly changing
field isn't the most helpful approach.

Instead, this book focuses on something far more enduring. It examines
how technology shapes the systems around us and changes who wins and
who loses every time a significant technological shift occurs. By tracing
this arc, from how we frame AI to how we reimagine work and rethink
power, I aim to offer a practical lens for understanding how AI changes
economic systems as a whole, irrespective of which specific technologies
improve or fade. These principles hold across sectors and time because they
are not built around any single tool or technology.
This is the foundation of this book. While it applies these ideas to AI as we
know it today, the goal of this book is to provide frameworks and insights
that remain relevant even as AI continues to advance, explaining how it
restacks the knowledge economy and reshuffles the balance of power.
OceanofPDF.com

SECTION 1 - AI AND THE SYSTEM
OCEANOFPDF.COM


OceanofPDF.com


OceanofPDF.com

S
1
BEYOND AUTOMATION
WHAT IF WE'VE BEEN GETTING AI ALL WRONG
ingapore's Changi Airport doesn't feel like an airport at all. It feels more
like a botanical garden that just happens to have departure gates, lush
with indoor waterfalls, butterfly enclosures, and canopy walks. A world
apart from the flickering vending machines and scuffed linoleum of the
average terminal. Outside, the city tells a similar story with its sleekly
architectural skyline and spotless streets. Singapore's success is hard to
miss. What isn't quite as visible is how this tiny island nation, once a
struggling port with limited resources, transformed itself into one of the
wealthiest places on earth.
Ask around, and you'll hear familiar answers about financial innovation and
the relentless hard work of the 'pioneer' generation, about government
foresight and the vision of a much-revered founding statesman. These
things are all true, in the same way that a three-star Michelin restaurant's
menu describes the dish, but doesn't quite explain how it is cooked.
Stand on top of the Marina Bay Sands right around sunset, sipping some of
the most overpriced espresso money can buy, and take in the city: the
financial district's glass-and-steel skyline, the architectural marvels
surrounding the bay, the high-speed driverless trains. The city glows with a
quiet brilliance, its skyscrapers and bustling streets offering possible clues
to its extraordinary ascent.

But then turn your back on that dazzling city and look out over to the sea on
the other side - to that endless flow of ships on the horizon. Follow one of
those ships - watch it glide past Sentosa, through the narrow channel, and
into the waiting arms of a port that never sleeps. The true story of
Singapore's rise doesn't start in a bank or a boardroom. It starts right there,
with one of the most overlooked pieces of technology in modern history.
A steel box.
The usual story of Singapore's rise credits its policies, its leadership, its
culture of hard work, and even its geographical location. All of that is true,
in that its location as a port was serendipitously strategic. What really set
Singapore apart, though, was its ability to act on a structural economic shift
before almost anyone else. In the 1960s, Singapore was a struggling port
city with limited natural resources and a tenuous future. Its strategic
location meant little without the infrastructure to leverage it. Singapore
owes its meteoric rise ever since to a deceptively simple invention: the
shipping container.
In the 1960s, back in the early days of containerization, Singapore made a
bold bet on the potential of that unassuming steel box. It built deepwater
terminals to handle containerized cargo, drafted customs regulations to
expedite trade, and linked its port to global supply chains via land and sea.
The entire economy reoriented around a simple steel box, transforming
Singapore into one of the world's busiest and most efficient ports. Today,
it's impossible to imagine Singapore without the container - deceptively
simple in design, yet powerful enough to transform not just the port, but the
nation's destiny.
A steel box restructures the world
At the dawn of the shipping container era, the world still operated under a
trade model that had been in place for centuries. Cargo moved in wooden
crates and barrels, loaded onto ships by armies of dockworkers. Ports were
slow, expensive bottlenecks where goods sat idle for days, sometimes

weeks. High shipping costs kept manufacturing close to consumers, and
supply chains were largely local.
Then came the container, and the logic of the global economy changed with
it.
The speed of shipping increased dramatically as cranes could accomplish in
hours what would have taken days with the manual effort of dockworkers.
Factories no longer needed to be near customers. An Italian fashion brand
could have garments stitched in Indonesia. The barriers to global trade
collapsed, and entire industries got restructured as a result. Manufacturers
relocated production offshore to capitalize on low labor costs. Retailers,
once constrained by regional supply chains, expanded globally. Reliable
shipping eliminated the need for stockpiled inventory as a buffer against
unexpected supply shocks. Factory towns like Detroit and Manchester
witnessed the decline of industries as companies sought lower costs abroad.
Ports that modernized thrived; those that didn't watched their fortunes
reverse.
Control of key shipping routes became the new source of power. Prosperity
was no longer based on resources or trade routes. Singapore, sitting at the
crossroads of East and West, capitalized on this shift. This great economic
reshuffle conferred power on those who mastered logistics, built
infrastructure, and plugged into global supply chains.
In an age now where the world obsesses over large language models and
self-driving cars, containerization feels embarrassingly low-tech. And yet,
without it, Singapore would have likely remained yet another struggling
port city. The city's wealth, its influence, its identity - none of it happens
without those silent, colored boxes stacking up in its ports.
When I first arrived in Singapore, I lived in an apartment on Mt Faber,
across the road from the Tanjong Pagar terminal, and every night, through
my window, I watched the port at work. Cranes moved with an almost
metronomic rhythm, hoisting containers from ships and slotting them onto
waiting trucks. By the time I left Singapore, I had moved to Sentosa Cove,
just across the water, where I'd watch the ships on their way in and out of
port every day. My life had changed through the course of that decade, and

so had Singapore. But the hum of the port remained constant, ever moving
the world forward one container at a time. For all the mechanical cranes and
stacked crates, the bustle of the port felt quite personal. Whatever these
ships carried - car parts, smartphones, lithium-ion batteries, half the world's
furniture - would, in a few days, be sitting on shelves, in homes, in
someone's pocket. Every object I touched, every object you touched, had
likely passed through this port.
Singaporeans walk around their city with the quiet confidence of a people
who have pulled off an impossible trick. In the span of a single generation,
they turned a swampy, resource-starved island into one of the wealthiest
places on earth. What many rarely stop to consider is that this ascent wasn't
fueled by the control of oil reserves or some breakthrough technological
wizardry, but by something almost absurdly simple: a steel box.
Containerization as coordination
The clue to containerization's impact isn't hidden inside the box - that only
comes into focus when you zoom out, past the many rows of neatly stacked
boxes, to the larger ecosystem it transformed.
At first glance, it's easy to mistake the revolution for automation: a
hardware upgrade to get to faster cranes and bigger ships. Port automation
certainly played a role. Break-bulk shipping was notoriously slow and
expensive - cargo sat idle for days, as armies of dockworkers manually
hauled crates. However, if speed were the whole story, the revolution would
have stopped at the docks. It didn't. That's because the real problem wasn't
just speed; it was unreliability. And unreliability is expensive.
Every shipment had to be renegotiated at each step - truck, train, ship - each
with its own contracts, pricing, and handling standards. Cargo sat idle for
days in ports, waiting for workers to load and unload manually, a process
riddled with delays, misplaced goods, and endless paperwork. Moving
goods from New York to Manchester was a fumbling relay race of

negotiations and paperwork, with no guarantee that the baton would be
passed on cleanly to the next player.
In short, shipping was unreliable, and businesses bore the cost of this
unreliability by overstocking warehouses, paying inflated insurance
premiums, and losing revenue to delayed shipments. The true cost of
shipping wasn't in the port fees. It was in the inability to predict what
would happen next.
This is where coordination becomes essential. Coordination is the ability to
align the actions and decisions of multiple independent agents, whether
people or institutions, so they can collectively achieve an outcome they
couldn't achieve alone. Coordination enables different players, with varying
incentives and operating across diverse locations, to work in harmony
towards a common goal. Before containerization, global shipping lacked
such coordination. Each step operated in isolation, creating a fragmented
and unpredictable system where the left hand rarely knew what the right
was doing.
It's tempting to see containerization as the triumph of superior hardware
and efficient automation: faster unloading through cranes, larger ships
moving between larger ports, and sturdier boxes that could be uniformly
stacked. If the story of containerization were just about speed and
automation, then the revolution would have ended right there at the port.
But it didn't.
Instead, the real revolution was that containers forced an entirely new form
of coordination, making shipping more reliable and predictable in the
process.
The first breakthrough was the single, integrated contract that came with the
container. The dawn of commercial container shipping can be traced back to
Malcolm McLean's 1956 shipment of 58 standardized containers aboard a
converted World War II tanker. McLean, a trucking entrepreneur who
revolutionized global shipping, recognized that the existing break-bulk
system was inefficient and costly. He started redesigning cargo vessels to
carry standardized containers that could be loaded directly from trucks.
Among McLean's many innovations, the most important one was arguably

his introduction of a single bill of lading, meaning shippers no longer had to
negotiate separate agreements for trucking, rail, and shipping. They could
work with a single bill of lading, making door-to-door delivery possible.
A unified contract enabled coordination across different modes of
transportation. Coordination, though, wasn't just about contracts.
Containers also needed to move physically across ships, trucks, and trains
without ever being unpacked. That required standard sizes, and
standardization didn't come easily.
Up until then, each industry designed containers according to its individual
constraints - shipping lines around vessel sizes, railroads around domestic
tracks, and trucking firms according to highway regulations. European rail
containers didn't fit in American trucks. Some companies had already
invested millions in proprietary designs, and changing them to fit a new
standard would be expensive. Without common dimensions, the very
coordination that containerization promised could never be achieved due to
this widespread incompatibility.
The breakthrough came when McLean, relentless as ever, pushed for
standardization during the Vietnam War. This conflict created a unique
testing ground for containerization as the U.S. military faced unprecedented
logistical challenges. The U.S. military required a method to transport
massive amounts of supplies to prevent shortages, and containerization
proved to be essential. The military's adoption of standardized shipping
containers for wartime logistics demonstrated its effectiveness at scale and
accelerated industry-wide acceptance. Governments and international
standards bodies soon stepped in, pushing for uniformity. Compliance with
standardized container sizes soon became the price of entry into global
trade. Those who resisted found themselves locked out.
As global trade accelerated, containerization demanded precise tracking of
cargo, far beyond the limits of manual record-keeping. Improvements in
computing and operations research provided a solution. With a single
contract, standardized containers, and digital tracking, businesses no longer
had to plan for failure. Shipping became predictable. Transit times, once
unpredictable, became reliable and calculable.

This was the triumph of coordination. Now that businesses could rely on
shipping schedules, they stopped stockpiling inventory. Just-in-time
manufacturing, where parts arrive exactly when needed, became the
dominant model. Supply chains stretched across continents, linking
factories in one country to assembly lines in another and customers in a
third. With that, investment poured in. Ports, railroads, and trucking fleets
all had to modernize to plug into this new system of trade.
Modernizing your port is one thing. Positioning it strategically in a new
global trade system is something entirely different. Before standardized
containers, a port's value was determined largely by its efficiency and
speed. After containerization, a port's value increasingly came from its role
in coordinating global trade flows. Singapore's leadership grasped this
economic shift well ahead of its competitors. While neighboring ports
focused on automating cargo movement, Singapore invested in ensuring
reliability across the entire logistics network.
Singapore integrated its customs and clearance process to eliminate other
bottlenecks that were slowing down the movement of goods. Unlike other
ports, which positioned themselves as an endpoint in the shipping journey,
Singapore built out an integrated transport network across road, rail, and air
to create a unified transit hub. The country positioned itself as a neutral,
well-governed trade hub, building legal and diplomatic frameworks to
attract major shipping alliances and multinational firms. More than
anything, Singapore made reliability the product it sold to the world.
Shippers knew that cargo passing through the port would move on schedule,
with minimal disruption. Singapore knew that in an age of containerized
coordination, reliability, not speed, would determine power.
Coordination involves creating systems where all parts move together
reliably. Singapore placed a bet on the coordination that was about to
unfold across global trade and positioned itself accordingly. Automation
helped Singapore's port load and unload goods faster, which is useful, but
not transformative. Coordination, on the other hand, made it indispensable
in the new system of global trade. This explains why Singapore, a tiny
island with no natural resources, developed so rapidly after adopting
containerization. The real leverage in connected systems doesn't come from

optimizing individual components, but from coordinating them. A system is
defined by how well its components interact and work together to create
value. A container port in Singapore created value only because rail yards in
Germany, trucking fleets in the U.S., and customs agencies in China worked
with the same standards. Coordination unlocks value far beyond what each
part can deliver on its own. It was Singapore's positioning as a coordination
hub, rather than merely a modernized port, that transformed it from a
regional shipping stop into a global economic powerhouse.
The box didn't change the world on its own, and neither did port
automation. It was necessary, but it remains a small footnote in the history
of global trade. The real revolution was the coordination that the box forced
upon the world.
A new form of coordination
I arrived in Singapore in the early 2010s and was instantly captivated by the
machinery behind the modern economy. I don't mean the rows of cranes
lifting containers at the port that I could see from my apartment. What
mattered more was the invisible infrastructure - the agreements, rules, and
standards that allowed the world's goods to move without friction,
coordinated across multiple players. I wasn't working in shipping; I was
working on explaining the new digital business models that were emerging
at the time. As I spent my days analyzing the internet economy, I kept
seeing the same mechanics. Everywhere I looked, industries were grappling
with the same fundamental challenge: coordination. It was increasingly
clear that the same forces that had reshaped global trade were now
reorienting the digital economy.
Take Airbnb, the online marketplace that lets hosts rent out their homes
directly to travelers. Before Airbnb, the accommodation market was
dominated by hotels and professional bed-and-breakfasts, and the idea of
staying at a stranger's house would have seemed absurd, if not outright
dangerous. Hotels were predictable; the experience was standardized. Yet,
somehow, Airbnb had made the unpredictable predictable. It had created a

reputation system, supported by reviews and verified identity, that allowed
total strangers to trust each other enough to stay in each other's homes.
Trust was no longer based on mutual relationships; it was managed through
a central reputation system, enabling coordination and economic exchange
among strangers on that basis.
Stripe was another such interesting business. If you've ever run a business,
you know that accepting payments is a headache. Before Stripe, setting up
credit card payments required hiring entire finance and compliance teams to
handle complex regulations and payments infrastructure. Stripe turned that
complexity into a simple software interface - an application programming
interface (API) that let software systems communicate with each other.
With that, accepting payments was as easy as writing a few lines of code.
By offering a straightforward API, it enabled software systems and the
people and institutions behind them to coordinate complex financial flows
instantly. Businesses would no longer worry about payment logistics. They
simply plugged in to a standard interface, and Stripe handled the rest.
Airbnb and Stripe had organized fragmented systems and unlocked
coordination at scale. A few years on, Tesla did something similar for
electric vehicles (EVs). While known for sleek design and performance, its
real breakthrough was solving a coordination problem that had held back
EV adoption, particularly in North America. EV charging was unreliable,
and finding compatible charging stations was a problem. Tesla's
Supercharger network removed this uncertainty. When you drive a Tesla,
the car itself guides you to available chargers, displays the exact amount of
charge remaining, and handles payment through your Tesla account. This
predictability transformed the ownership experience, and by 2024, the rest
of the EV industry in the US had adopted its charging standard.
This wasn't software eating the world - it was coordination eating
complexity. Airbnb won by standardizing trust, Stripe by simplifying
financial complexity, and Tesla by eliminating charging uncertainty. The
most transformative companies don't just build better tools; they solve
coordination problems that unlock new forms of economic activity.
Technology only helped you play the game, but solving the coordination
problem helped you win it.

Coordination is the central driver of value in today's economy, but this
wasn't always the case. Economic power was historically tied to ownership.
Ownership of land in the agrarian era, of factories in the industrial age, and
of patents or brands in the 20th century. Today, it increasingly comes from
orchestrating what you don't own: aligning a larger system of economic
activity around yourself. That's coordination.
With the rise of global trade, coordination emerged as a significant value
driver. The ability to source, produce, and distribute goods globally meant
that companies no longer needed to own their own production facilities.
Nike, for instance, designed sneakers in Beaverton, Oregon, while
manufacturing them in factories across Asia. Value was no longer in making
a product but in coordinating its creation. However, coordination across
outsourcing partners still required heavy manual oversight - managers
traveled globally to inspect production lines and enforce quality standards.
Nike once relied on manual oversight for coordination. Shein, the Chinese
fast-fashion juggernaut, achieves that oversight using algorithms.
Algorithms are the mechanisms that enable machines to read signals from
the world around them, make predictions, and take actions based on those
predictions. Shein captures data from social media and other digital sources,
using this data to predict what customers are likely to purchase next. Based
on this prediction about future demand, Shein creates production orders and
routes micro-orders to thousands of garment factories. A designer in Los
Angeles can upload a new clothing concept in the morning, and by night,
suppliers in Guangzhou are already stitching it together. Algorithms, here,
are the invisible managers, coordinating production better than a team of
managers ever could.
In moving from Nike to Shein, we moved from managerial oversight to
algorithmic coordination. Algorithmic coordination, in this case, also
enabled an entirely new logic for creating value. Traditional companies,
such as Nike, would operate on long planning cycles, forecasting trends
months in advance and placing large manufacturing orders with overseas
factories. If those forecasts failed or styles flopped, excess inventory would
get discounted or wasted. Shein, instead, creates small test batches,
sometimes as few as 100 items. If a style sells well, Shein instantly reorders

and scales up production. If it doesn't, it's dropped. From trend detection to
design, manufacturing, and delivery, algorithms manage the entire flow,
acting as invisible supply chain managers that adjust production schedules
based on live feedback.
Three major shifts have made such algorithmic coordination increasingly
important in modern business.
The first major shift is the ability to collect and use data to manage
economic activity. In the past, businesses exercised control through
ownership or physical presence. Today, software and sensors track what's
happening in real-time - whether products are selling out at an online store
or whether the delivery truck has delivered the product to a home - and
algorithms use all this data to detect patterns or predict issues, continuously
adjusting operations based on that information. This makes coordination
more proactive and reliable. Instead of reacting after problems arise,
businesses can structure systems to respond in advance. Control no longer
depends on ownership or presence, allowing economic activity to be
organized in new ways, as exemplified by Shein. As they learn from data
over time, they continually improve their operations.
Second, the growing adoption of smartphones and mobile-based internet
connectivity has eliminated many of the traditional constraints on trade. In
Nike's world, production and consumption were separated by months. In
Shein's world, the moment customers scroll past a trend, its supplier
network gets activated in response. On the demand side, every smartphone
interaction - browsing, shopping, scrolling - feeds Shein's algorithms. On
the supply side, these algorithms manage work allocation across its network
of connected garment factories.
Finally, the rise of cloud-based services enables companies to access
specialized operational capabilities as needed. Instead of building all
capabilities internally, businesses can now access specialized capabilities,
such as managing payments or customer support, from highly specialized
providers who often excel in that service through specialization. If you've
ever used an app like Uber or Lyft to get a ride, you've probably received
messages that tell you when your driver is arriving. Uber and Lyft didn't

build that messaging system themselves; they 'rent' those capabilities from
providers like Twilio, which specialize in communication between software
and users. Twilio offers this capability as a cloud-based service that other
companies can easily integrate into their systems. This model, where
companies plug in ready-to-use digital tools, lets them move faster without
the challenge of building everything from scratch.
To understand why coordination matters more than ever today, we need to
examine the changes that occurred when smartphones, data, and cloud
services converged. That convergence did more than just connect people; it
restructured how economic activity is organized and expanded the scope of
who could participate in such activity. Anyone with a smartphone could
participate 
directly 
in 
global 
markets, 
receiving 
personalized
recommendations based on the data they generated. Any business could
plug into cloud services. A solo entrepreneur in Rwanda could conduct
business with a factory in China. Every TikTok influencer, Lyft driver, or
Shopify store owner could now plug in and operate relatively
independently, without formal top-down organizational structures.
This growth in economic participation also introduced a new kind of
fragmentation. New types of businesses emerged, each operating with
different incentives and workflows. The very technologies that enabled
richer interaction also made the system harder to coordinate. However, this
growing fragmentation also brought a new opportunity: coordination. The
more fragmented the system and the more diverse the incentives of the
players, the greater the value in aligning them to work together.
Coordination, once a deadbeat managerial function, is now the most
valuable function in the modern economy.
This is why the most valuable businesses today are no longer those that own
production, but those that coordinate it. Companies like Shein build
economic power not through direct ownership or oversight but through
managing coordination at scale, allocating resources, and making decisions
across suppliers, trends, and purchase cycles using algorithms. These three
factors - data-driven remote management, a globally connected market, and
access to specialized capabilities on demand - have transformed the nature
of economic power.

The coordination gap - and why AI matters
Shein's automated supply chain and Stripe's frictionless payments operate
like clockwork because they function within well-defined arenas, where
players follow shared rules and work with clean, structured information,
leaving little room for ambiguity. Shein's algorithmic coordination works
because product trends can be precisely quantified and because the factories
it works with agree to follow standardized procedures. It identifies what
people want to wear and sends small batches of clothes to factories that
already know how to make them. Coordination is made possible because all
participants operate within a shared framework.
This logic mirrors the success of containerization. The shipping container
worked because ports, shipping lines, and customs authorities all agreed to
adopt a shared standard. Once the format of the box and the rules for
handling it were fixed, every player could plug into the system and perform
reliably. Consensus, structure, and predictability made global coordination
scalable.
Most of the economy, however, doesn't work that way. Coordination often
breaks down in ambiguous environments where the rules aren't fixed. An
API might automate a payment between companies, but it won't help two
procurement teams renegotiate a supplier contract in the middle of a supply
shock. A logistics platform might assign drivers efficiently, but it can't
resolve a dispute between two regional managers with conflicting priorities.
These systems falter when coordination depends not on clear rules but on
judgment and interpretation. Much of that still lives in human minds as tacit
knowledge that resists codification.
Today's platforms excel when coordination can be reduced to clean inputs
and repeatable actions, but break down when coordination gets more
complex. Building a new airport involves the alignment of architects,
engineers, regulators, and contractors, each adjusting plans in response to
changing requirements. In developing a new drug, scientists and regulatory
experts must interpret ambiguous trial data and navigate complex approval
pathways to secure approval. In the F1 pit, mechanics and drivers

coordinate in real-time to adapt the race strategy in response to shifting
track conditions. All of this coordination still relies on old-world methods,
like meetings and document revisions, because the knowledge involved is
tacit, and even when information exists, it's not easily standardized.
This is the coordination gap - a divide between what today's coordination
mechanisms manage well and what most economic activity actually
requires. While excellent at managing structured, repeatable processes, they
struggle with coordinating activities that require consensus in uncertain
environments.
This is precisely why artificial intelligence (AI) matters - not so much as a
tool for improving productivity through automation, but as a mechanism for
coordinating what has so far remained uncoordinated. As we noted in the
introduction, AI is better understood not as an alternative to human
intelligence, but as a relatively narrow yet powerful and practical tool that
integrates into our workflows and restructures how we make decisions and
act. Viewed as a narrow, practical utility, AI works through five essential
steps: it observes the world, creates a working model of it, reasons through
possible choices based on that model, acts on those decisions, and learns
from the outcomes to improve over time. These five functions, primarily
based on the ability to observe the world and create a working model of it,
make AI particularly well-suited to solve coordination problems.
To understand the power of these five functions with a relatively more
familiar example, consider how GPS-based navigation applications like
Google Maps have transformed the way we interact with the world around
us. Google Maps solves a key coordination problem: it helps millions of
individual drivers, each acting independently, make personal decisions that
work together on a shared road network.
Google Maps achieves this by first observing the world, focusing on your
location and the road layouts and traffic around it. Next, it builds a model, a
representation of the world, to make sense of what it sees - roads,
intersections, speed-checking radars, and live traffic congestion. It then
applies simple rules to reason based on this model: take the fastest route,
avoid tolls, and minimize turns. You get a route that's efficient and easy to

follow. It then proceeds to act on its reasoning, translating the overall route
into actionable steps that you can follow. What really makes Google Maps
so powerful is the final component - learning. Learning helps it improve
over time, as it continually updates its view of the world by observing the
behavior of all drivers using its navigation instructions.
We often get distracted by discussions about intelligence, looking for
evidence of human-like intelligence in AI. A better way to understand AI's
true potential is to look at how these five functions - sense, model, reason,
act, learn - help it bridge the gap between structured systems that already
are well coordinated and the vast unstructured processes and workflows
that rely on tacit knowledge, which form the backbone of today's economy.
Coordination depends on developing shared understanding, making timely
decisions, and executing consistently across fragmented actors. AI's ability
to model a domain and align intent and action reliably with that model
makes it particularly well-suited for coordination.
What makes AI truly transformative is not its performance on benchmarks
of intelligence but rather its ability to model, mediate, and move fragmented
systems toward alignment. The real promise and potential of AI lies in
whether it can extend coordination into thus-far uncoordinated segments of
the economy. In this sense, AI's real power lies not in automating individual
tasks but in coordinating entire systems.
AI as coordination
Both the hype and skepticism surrounding AI often stem from the same
flawed approach: judging the technology by how well it performs a specific
task, rather than by how it transforms the broader economic system that it
enters. This narrow focus keeps us chasing performance benchmarks, which
are typically easy to measure but often miss the point. Benchmarks, such as
exams or coding tests, indicate how an AI technology performs under
controlled conditions, but they reveal little about its performance in
unpredictable, real-world environments. Benchmarks often measure what's

convenient rather than what's consequential. This leads us to misjudge both
the speed and the nature of AI's impact.
To understand how AI might truly transform the economy, we need to ask
better questions. How does the economic system change when AI is
introduced? Which constraints on the system are removed, and which new
ones emerge? Where do new risks show up, and who manages them?
Benchmarks demonstrate what AI can achieve in controlled environments,
but only systems thinking shows what AI will change in the real world. AI's
ability to identify patterns, make predictions based on them, and continually
learn from outcomes may not create human-like intelligence, but it creates
something arguably more valuable and practical: the ability to adapt in
response to uncertainty. It learns from feedback, adjusts to changing inputs,
and continues to function even in noisy environments. When dealing with
incomplete information, this kind of pattern recognition and iterative
response turns out to be far more valuable than perfect reasoning.
"AI" is a catch-all term that often obscures more than it clarifies. It covers
everything from a recommendation system tweaking your Netflix feed to a
model generating legal contracts or driving a car. The many technologies
that fall under the AI umbrella, including machine learning, deep learning,
generative models, neural networks, and others, have distinct definitions,
strengths, and limitations. Lumping them together under a single term
might seem counterproductive, as it obscures the technical nuance
associated with each term.
Yet, to shift our lens from the technology to understanding how the
technology transforms the economic systems - the institutions, workflows,
and value chains - into which it is deployed, lumping these technologies
under the umbrella term 'AI' has an often-overlooked benefit: despite their
technical differences, their underlying economics are remarkably similar.
The shared economic logic of these technologies rests on two key
principles: their ability to dramatically increase the capacity for performing
knowledge work, and their ability to simplify the coordination of such work
towards greater, better, and more novel output. Whether it's an algorithm
forecasting demand or a model summarizing legal contracts, the economic
impact stems from the same two forces - amplification of the capacity for

cognitive labor and decision-making, and reduction in coordination friction
between actors and their activities.
Two factors contribute to how AI enhances both the capacity and
coordination required for knowledge work. First, AI reduces the cost of task
execution. Tasks that once required expensive experts can now be
performed more efficiently, at a lower price, and at scale.
Equally important, but far less discussed, is AI's potential to lower
coordination costs: the hidden friction that arises when people and
resources need to be aligned to get something done. In most knowledge
work today, that alignment is a struggle. Information lives in a dozen places
at once, across emails, chat threads, spreadsheets, and specialized tools.
That fragmentation keeps work from getting done, as the people or teams
involved must constantly align their activities to ensure effective
collaboration. This problem compounds as more people and more
organizations get involved. When work spans departments or crosses
company boundaries, the costs of coordination multiply, as we spend
increasing amounts of time making sure everyone is navigating with the
same map. This coordination problem becomes even more pronounced
when multiple companies must coordinate as part of a larger ecosystem.
AI can help bridge this gap by making sense of the unstructured
information each player holds, building a shared model across them, and
delivering the right insights to the right people at the right time. In a multi-
team sales process, AI can consolidate conversations and contracts across
numerous tools to ensure that everyone, from the salesperson to the CFO, is
working off the same assumptions. Alternatively, when a supplier changes
delivery timelines, AI can detect the change in one system and
automatically update forecasts, procurement schedules, and downstream
planning 
across 
partner 
companies, 
avoiding 
a 
cascade 
of
miscommunication. In doing so, it reduces the need for slow, manual
coordination and helps teams and even companies move faster, with greater
alignment.

Table 1.1: AI as a means of automation vs. AI as a means of
coordination
We often overestimate AI's potential for automation, applying it to tasks
where it performs poorly and fueling cycles of hype and disillusionment. At
the same time, we consistently underestimate its potential for coordination.
With this framing error, we chase narrow performance benchmarks and, in
the process, overlook AI's true economic potential in restructuring how
people, teams, and companies coordinate to create value. We fixate on

individual tasks and job substitution, rather than asking which coordination
failures AI can resolve and what new forms of economic activity get
unlocked once those coordination frictions are eliminated.
AI's real potential lies not in automating tasks, but in reconfiguring how
systems operate. It's easy to mistake the rise of AI as a story of more
'intelligent' tools, just as many once saw containerization as a story of
faster and more efficient port operations. The container's impact, however,
extended far beyond the port to the design of the entire system of trade
surrounding it. Singapore modernized its docks, but its success stemmed
from recognizing the need for a new coordination logic for global trade and
restructuring itself accordingly. Firms chasing automation may unlock
short-term gains, but those using AI to orchestrate complex systems will
unlock entirely new forms of value, creating competitive advantage.
When coordination gets complex
Back in 1995, planning a trip involved flipping through a glossy brochure at
a travel agency, while the travel agent would handle the rest. Today, that
simple process is fragmented across a dozen disconnected steps. You start
dreaming about your next destination on TikTok, work through TripAdvisor
reviews, head over to Expedia or Airbnb, and create a spreadsheet to
manage the many moving parts. Before you know it, you're juggling 27
open tabs on your browser.
The internet opened up choice; consumers were no longer stuck with the
limited options that travel agents peddled. But with choice came
fragmentation. Travelers now face a greater challenge: coordinating across
every aspect of a fragmented trip. Unlike Shein's closed and tightly
coordinated supply chain, where every factory speaks the same digital
language and follows standardized instructions, the travel industry is an
open, adversarial, multi-sided ecosystem; a patchwork of loosely connected
providers, each operating with different, often misaligned, incentives. That
fragmentation creates three key coordination challenges for the traveler.

First, the players involved can't always communicate effectively with each
other, resulting in a translation problem. Your airline app doesn't talk to
your hotel app, so when your flight is delayed, you may be at risk of losing
your hotel room due to late arrival. You become the go-between, relaying
updates between applications that were never designed to connect. In
Shein's world, a change in demand instantly adjusts production across
thousands of factories. In travel, you're stuck playing dispatcher to get the
trip back on track.
The second coordination challenge in travel involves managing ambiguity.
A hotel review website like TripAdvisor is designed to help you choose a
hotel, but browsing 384 conflicting reviews may often overwhelm you,
instead of simplifying the decision. Shein's system constantly learns and
filters signals to determine which signals are truly indicative of demand. In
travel, the burden of finding a review that best addresses your concerns
about the hotel falls squarely on you, the travel planner.
Finally, there's the problem of reliable execution. Even if your apps could
talk, and you found a well-reviewed alternate hotel, someone still needs to
reschedule everything when your flight is delayed. Sharing information
between different players isn't enough - you would still have to rebook, call
support, update your transportation, and possibly cancel a prepaid tour. In
Shein's model, once a trend is detected, factories act instantly. In travel, you
still have to make the calls to get the disconnected parts of the trip onto the
new plan.
With improvements in AI, though, this travel coordination problem may
finally look solvable. AI assistants - AI-powered interactive solutions that
understand your intent and take action on your behalf - now offer a single
interface to help plan and manage travel. Instead of juggling 27 tabs, the
traveler can now interact with one trusted assistant.
For a traveler, the one-stop interface is the most noticeable change, but
ironically, it is also the least significant. The real problem behind those 27
open tabs lies far deeper, in the fragmentation of the travel value chain,
where each provider operates with its own data format and pricing logic. AI
offers a way through this translation tangle. Rather than forcing every

player to speak the same language, it observes information across them and
generates a shared layer of understanding. If this translation layer works,
the traveler no longer needs to scan twenty tabs or reconcile conflicting
advice. If this translation layer works, the traveler no longer needs to
reconcile advice across tabs. An AI assistant can now assemble a complete
itinerary, choosing the right hotel not only by price, but by sentiment,
location, itinerary fit, and loyalty perks, coordinating across providers that
were never organized to communicate with one another.
Stitching together the plan is just the start. To truly coordinate the trip, an
AI solution must also execute, handling bookings, adapting itineraries, and
resolving disruptions as they happen. That requires agentic execution: a
property of AI that enables it to pursue defined goals on your behalf, rather
than just following instructions. An AI agent evaluates a situation like a
travel disruption, evaluates and selects from alternative options, and adjusts
strategies in response to stay aligned with your objective of ensuring trip
continuity. Unlike traditional automation, which operates on fixed logic and
can't operate in the midst of ambiguity, agentic systems pursue outcomes,
continuously recalibrating their approach to meet those goals.
An AI travel assistant powered by agentic execution can monitor for
disruptions, rebook flights, and bring the trip back on schedule, while
preserving your travel preferences. This kind of agentic execution assumes
the AI has access to the necessary tools, systems, and permissions across all
the different players involved. That's a big assumption, and in many cases,
it's not yet true. Two forces are closing the gap: improvements in
technology continue to expand agents' access and capabilities, and as AI-
powered coordination proves helpful, it creates a pull for others to open
their systems as well. Value creates gravity, and gravity drives further
coordination.
Such a solution solves the three coordination problems we encountered
earlier in this section. First, AI solves the translation problem by integrating
disconnected providers into a shared logic layer, allowing a delayed flight
to trigger hotel rescheduling automatically. Second, it solves the ambiguity
problem by narrowing down overwhelming choices based on your intent
and history. Finally, it solves the execution problem by using agentic

execution to handle the follow-through and manage the end-to-end trip on
behalf of the traveler. A food blogger caught in Tokyo's rain, no longer able
to explore street food, can have her AI assistant instantly book a sushi-
making class, notify her content team, and adapt the day's logistics and the
content publishing schedule accordingly. It even accounts for her shellfish
allergy and negotiates a media discount at the class, based on her audience
reach. Meanwhile, the same underlying system ensures a corporate traveler
lands in a pre-approved hotel, on a compliant flight, with expenses logged
before check-in.
From the traveler's perspective, this translates into greater convenience, but
it involves a larger shift in the entire underlying architecture. Behind that
friendly interface lies a newly reconfigured system, constantly evolving as
it learns how to herd a dozen uncooperative players - airlines, hotels, and
booking engines - into acting as one. The travel assistant is an early
blueprint for a solution that coordinates fragmented players with competing
incentives and disconnected data to achieve a single outcome. We would
miss the point if we viewed this solely in terms of AI-driven personalization
or productivity for the traveler. The real breakthrough is the emergence of a
new system logic, designed to enable successful coordination across an
otherwise fragmented ecosystem.
AI's superpower - Coordination without consensus
Successful coordination involves many moving parts, but five factors
matter most. We've examined the first three factors of representation,
decision, and execution, which are presented as solutions to the problems
that fragment travel planning and execution: the challenges of translating
across players, managing ambiguity, and executing reliably. AI resolves
translation issues through unified representation across players, enhances
decision-making to reduce ambiguity, and facilitates execution, thereby
improving reliability.
First, all coordination requires unified representation, a common way of
perceiving the environment. A self-driving car operates very differently

from a travel-planning voice assistant and utilizes very different
technologies. Yet, both rely on AI's ability to observe and construct a
working model of the environment by taking in different types of
information and creating a unified, structured view of the environment. This
ability to make a shared structured representation establishes the basis for
coordination.
Without unified representation, ecosystems involving multiple actors often
fail to coordinate effectively, as the participating actors interpret the
situation differently, and their actions become misaligned. In practical
terms, shared representation involves having a common language and
shared standards that everyone can work with. Container shipping works so
well because everyone agrees on a standard box and a unified contract.
Achieving such agreement is a challenge across the travel ecosystem,
though, where every actor, from airlines to hotels to local guides, works
with their own formats and standards. AI plays a crucial role in this process
by translating fragmented information across disconnected players to create
a unified representation.
What makes AI powerful is its ability to coordinate without upfront
consensus. Unlike container shipping or Shein, where coordination follows
consensus, AI-driven coordination can take root without such consensus.
Over time, increasing value draws players in, and consensus emerges over
time.
The second requirement for effective coordination is better decision-
making. Once different stakeholders start working with a common
representation, they are better placed to make aligned decisions. Shared
information alone isn't enough, as effective decision-making involves
weighing trade-offs. Travelers constantly face trade-offs where they lack
perfect information: should they pick the cheaper hotel or the one with
better reviews? Is it worth staying further away from the city center for a
quieter experience? AI, again, plays a critical role. It helps process a wide
variety of information, recognizes patterns across them, and can convert
conflicting signals into clear, usable decision aids. For example, instead of
forcing a traveler to sort through hundreds of reviews, AI can summarize
trade-offs based on the preferences of similar travelers in similar situations.

Better decisions resolve ambiguity but also align execution across all parts
of the system, the third requirement for effective coordination. AI plays a
central role here, both by supporting higher-quality decision-making and by
enabling more effective follow-through execution. It does this in two ways.
First, through assistive execution, where AI supports human decisions with
better data, suggestions, and workflows. Second, through agentic execution,
where AI takes autonomous action, for instance, when a trip encounters
unexpected disruptions and flights and connecting transfers need to be
rebooked, by acting with its understanding of the traveler's goals and the
constraints imposed by the available options. Improved decisions and
execution lead to better coordination by ensuring that all parts of the system
act on the same priorities and are aligned around shared goals.

Fig. 1.1: The Architecture of Coordination

This brings us to the final two factors that shape effective coordination:
composition and governance. Composition refers to how different players
connect and participate in shared workflows across the system. It defines
the structure of the system and how its parts fit together. When coordination
is built on consensus, composition is relatively simple: every participating
actor defines clear interfaces and specifies the information others must
provide. In container shipping, ports, shippers, and customs agree on
standardized container sizes. In software development, APIs establish clear
rules for data exchange, allowing services to plug into shared workflows.
However, without consensus, bringing diverse participants together can be
chaotic.
AI offers a practical solution: instead of forcing everyone to agree on
standards, it learns to understand each player and helps them interconnect
anyway. Imagine a tour guide who manages bookings through WhatsApp,
keeps schedules in a notebook, and sends proposals to customers as scanned
images. Or a small hotel that updates availability by phone and stores
reservations in a spreadsheet. These providers all work in different ways,
using tools that weren't designed to connect. AI can bridge these gaps by
reading messages, extracting key details such as times, prices, and
locations, and automatically turning them into a structured itinerary that
aligns across other providers. It can take a voice note describing a new tour
and turn it into a formatted listing with a title, price, and availability, ready
to be shared on booking platforms. In doing so, AI identifies the
connections between fragmented pieces of information and helps everyone
plug into a shared system, enabling coordination without requiring
everyone to use the same tools or agree on standards upfront.
Finally, effective coordination requires governance, learning, and
adaptation. Governance defines how the system evolves by determining
what behaviors are encouraged or restricted and how actors are nudged
toward the right behaviors. In the past, this required central rules or manual
oversight. With AI, though, governance can emerge from observation and
feedback, rather than control. Imagine a platform coordinating local tour
operators. One operator often cancels at the last minute, while another
consistently receives excellent reviews for punctuality. AI can track these

patterns over time and can start nudging travelers toward more reliable
operators, even if no one explicitly sets that rule. In this way, AI enables the
system to learn what works and adapt accordingly without requiring every
participant to agree on rules beforehand.
Coordination is often described in vague terms - alignment, timing, a
method to madness - but in practice, it's built on these five specific levers:
who sees what, who decides, who acts, how parts connect, and who writes
the rules of participation. Together, these five factors - representation,
decision, execution, composition, and governance - establish the basis for
effective coordination. We may be dazzled by the promise of agentic
execution, the idea that an intelligent assistant and a swarm of specialized
agents can act continuously on your behalf. But that's not the most
transformative shift AI brings. The real breakthrough lies in something far
more fundamental: the ability to enable coordination without consensus. In
the past, coordination typically required one of two things. A dominant
player, such as Shein or Amazon, would impose structure from the top
down through their ability to control access to demand and accordingly
dictate the terms of participation across their partners. Alternatively,
coordination required all participants to agree on standards upfront in the
form of shared protocols or rules of engagement before any collaboration
could begin, as was the case with containerization.
What makes AI-powered coordination different is that it doesn't need
consensus to begin. By recognizing patterns in unstructured data, AI bridges
gaps between systems that were never built to connect. AI can observe
fragmented, unstructured inputs from multiple parties and create a unified
understanding across them, even if those parties never agreed on a common
language. This enables action across fragmented systems without waiting
for standardization to occur. Over time, as the benefits of this AI-mediated
coordination become clear, the other players in the ecosystem move to
converge on shared practices, not through enforced mandates, but in
response to the accumulation of value. AI doesn't just automate tasks. It
restructures how ecosystems evolve, starting with translation, enabling
action, and eventually guiding fragmented actors toward alignment without
requiring them to agree first.

Economic progress increasingly hinges not on improving component
performance through automation, but on improving system-level
coordination across ambiguity and fragmentation. This is why coordination
is indispensable. The more fragmented the system, the more power flows to
whoever can organize it back into a cohesive whole. From logistics to
services, and eventually, to experiences, the primary constraint in unlocking
economic activity is not production or distribution but coordination. AI, in
this context, offers a new architecture for coordination - the ability to
coordinate across a highly fragmented ecosystem without requiring
consensus.
Spotting NFL quarterbacks
NFL teams spend millions analyzing quarterback talent - measuring arm
strength, speed, mental toughness. They run the numbers and work through
hours of play footage. And yet, in the 2000 NFL Draft, they all made the
same mistake. They passed on Tom Brady.
Brady, now considered one of the greatest quarterbacks in history, was
drafted 199th overall, behind six quarterbacks who were supposed to be the
future of the league. Teams had all the data in the world, but they still got it
wrong.
This is the great paradox of talent evaluation. Talent is mispriced because
NFL teams focus on isolated individual performance rather than how
players fit together as a team. The NFL has spent decades refining its
evaluation, teams spend millions trying to find the right players, but
championships are won by finding the right players that fit together. This is
the difference between individual excellence and system-wide coordination.
The right player in the wrong system fails. The overlooked player in the
right system becomes a legend.
NFL talent evaluation may appear to be a sports problem, but it's more of a
systems problem. The same blind spots that lead NFL teams to miss a future
legend also plague simplistic economic models looking to predict the

effects of AI without accounting for complex systemic interactions. Great
players alone don't guarantee success in teams, or for that matter, in
systems. Success requires coordination so that all components work
together to enhance the system's overall performance.
Solving coordination unlocks economic activity in ways that are not always
obvious. This is why the importance of coordination in driving economic
growth isn't always fully appreciated. We close this chapter with two
surprising stories of global trade - overlooked, perhaps, because they defy
conventional wisdom.
In any economic system, the most significant economic breakthroughs don't
come from making individual parts move faster. Before containerization,
factories increased output through automation, railroads improved their
tracks, trucks reduced delivery times, and retailers enhanced their
procurement processes. Each step pushed its industry forward, but none of
these unlocked global trade. True transformation occurs when everything
moves in harmony. The shipping container forced every link in the supply
chain to synchronize. With coordination, every player had a reason to
maximize output. A factory could produce more if it knew shipments would
arrive on time. A trucking company could invest in more trucks if loading
schedules were predictable. The entire system scaled, not just the individual
parts.
This is the difference between making components better and making them
work better together. Both matter, but the most important advances come
from coordination.
The first untold story of global trade is that better coordination not only
improves the system but also enhances the performance of individual
components within it. This might sound counterintuitive, as we have thus
far viewed component enhancement and system-level coordination as trade-
offs. However, effective coordination enhances both the system and its
constituent components, resolving this trade-off.
Before containerization, firms remained vertically integrated because
coordinating with external suppliers was costly and unreliable. However,
once containerization lowered those coordination costs, the logic of doing

everything in-house broke down. Companies could now source globally,
swap suppliers easily, and restructure production based on price and quality.
This shift pushed suppliers to specialize and compete, which improved the
components they produced. And as those components improved, so did the
final products built from them. The more firms specialized, the more they
relied on tighter coordination to keep supply chains functioning.
This is a self-reinforcing flywheel. Improved coordination across
components drives higher performance of every component through
specialization, and deeper specialization demands further coordination. This
flywheel - coordination driving specialization, specialization driving
fragmentation, and fragmentation demanding even better coordination - is
what fuels economic growth.
Fig. 1.2: The flywheel of economic growth
Coordination drives specialization. It sounds paradoxical, but like a magic
trick explained, it seems obvious in hindsight. Containerization drove the

specialization of components, which eventually gave rise to the personal
computing industry, where motherboards, memory, processors, and
peripherals could all be sourced from different suppliers. Without the
capacity for reliable trade, such specialization and modularity would not
have been possible. This modularity enabled faster innovation, as each
component could be improved independently without requiring the entire
system to be redesigned.
This is why coordination is transformational. Once coordination costs drop,
innovation no longer depends on a single firm doing everything; it
accelerates through a distributed ecosystem. Specialization flourishes,
competition increases, and entirely new industries can emerge from the
recombination of parts. This is the true superpower of AI. AI's greatest
impact won't come from automating tasks but from lowering coordination
costs so dramatically that innovation can scale effectively without central
control.
The coordination paradox
For all its promise, AI can also make coordination worse if we
misunderstand it as a technology for mere automation or optimization. You
might expect that misunderstanding AI's role in coordination isn't a big deal
- you still get more efficient with automation, and only miss some
coordination benefits. The problem, though, is different - instead of just
failing to improve coordination, you end up making it worse. Automation
and optimization speed up individual parts, while coordination ensures that
those parts work together. An overemphasis on optimization, paradoxically,
can actively break down whatever coordination exists today, making the
entire system less reliable.
This is evident in the example of containerization. The first-order effects of
containerization appeared as faster, automated ports. But if it had stopped
there, it would have made things worse, not better. Containers would have
moved faster off the ship, only to be piled up at ports as railroads and trucks
continued to operate as before. Ports would have seen investment in

automation fail to deliver returns because the rest of the supply chain wasn't
keeping pace. Worse, it would have created an imbalance - shipping
between major ports would become extraordinarily reliable, while inland
transport remained unreliable, making its shortcomings even more visible
and increasing inequality between cities. At best, port cities might have
benefited, but only marginally. Without the system-wide coordination
enabled by standardized containers and contracts, all the port automation in
the world wouldn't have mattered.
We face the same paradox with AI today. Viewed as an automation tool,
some parts of the organization, with the necessary resources and urgency,
improve their workflows and decision-making, while other parts, seeing
less immediate returns on investment, continue to operate on outdated
assumptions. This may seem like a fair trade-off with an automation lens.
But the moment the two have to coordinate, cracks begin to show. One team
makes decisions using sophisticated forecasting tools, while the other is still
working off last quarter's reports. One team understands customer
sentiment in granular detail, the other continues to rely on gut instinct.
Just as uncoordinated container adoption would have made ports more
efficient but supply chains more dysfunctional, uncoordinated AI adoption
threatens to make some teams hyper-efficient while making the overall
organization more fragile. An organization is more than the sum of its parts.
Workflows are interdependent and depend on predictable handoffs.
Deploying AI only in select areas disrupts that predictability, breaking down
whatever coordination existed.
This is the coordination paradox. Fixating on automation and optimization
doesn't simply lead to missing coordination benefits; it also breaks down
whatever coordination may exist today.
Understanding exponential technologies but
misunderstanding exponential systems

There's a second untold story of global trade. We live in an era shaped by
what everyone calls exponential technologies. The challenge, pundits say, is
that most of us struggle to grasp exponential effects because we tend to
think in straight lines. We expect change to be gradual and predictable.
To illustrate this, a parable commonly used is that of a farmer who
approaches a king, asking for a single grain of rice, doubled on each square
of a chessboard - just 64 squares. The king, amused, agrees. The request
seems modest - one grain for the first square, two for the next, then four,
then eight. Even after 20 squares, it's barely a sack. But soon, the numbers
start to balloon. By the end of the board, the total exceeds all the rice in the
kingdom.
This story is often used to illustrate the power of exponential growth: slow
and deceptive at first, then overwhelming. The magic is attributed to
compounding. Small gains stack up fast; then suddenly, you're buried in
riches.
Compounding is an easy story to tell. It's why the most common parable of
exponential growth involves nothing more than a simple doubling pattern: a
story of grains of rice on a chessboard and a king who didn't do the math.
And yet, when we look at how economic systems actually evolve,
compounding turns out to be a surprisingly incomplete explanation.
Compounding might explain how technologies evolve - faster chips,
improving models, and more data. However, economic and social systems
don't scale simply because things become bigger or faster. They scale
because things start working together in fundamentally new ways. This is
the second untold story of global trade.
At first, the impact of containerization seemed obvious. Ports got more
efficient, ships spent less time waiting, and dock work declined. But these
were only first-order effects - the initial incremental gains you'd expect
from a compounding model.
The real transformation came later, not through scale, but through scope.
Standardized containers and standardized contracts enabled intermodal
transport. With that, freight became faster, cheaper, and more reliable. And

that reliability broke the logic of vertical integration. Firms could specialize
and outsource. And as companies specialized, components improved.
Improving components led to greater product innovation. And the cascade
continued. High-knowledge work was separated from high-efficiency
production, inventory management changed, and trade accelerated. This
didn't happen because of compounding. It happened because of cascading
effects - one solved coordination problem, unlocking the next layer of
opportunity.
This is the secret to exponential system change: not compounding acceleration, but
cascading coordination.
Compounding is about scale; cascading effects drive scope expansion. The
first breakthrough may look like cost savings, but the second creates new
industries. By the time the third breakthrough materializes, all economic
activity is restructured. With each solved coordination problem, new layers
of activity are unlocked and the system's scope expands.
This is the second untold story of global trade, and it's the real story of AI.
AI might follow a compounding trajectory in terms of raw capability, but its
true impact will come from how well systems coordinate to harness it. The
idea that AI will suddenly leap into superintelligence distracts us from the
real work of evolving our systems to keep up with today's capabilities.
What matters isn't the scale of processing power. What really matters are
the cascading effects that emerge when coordination unlocks entirely new
possibilities.
OceanofPDF.com


OceanofPDF.com


OceanofPDF.com

I
2
THE WRONG FRAME
WHAT IF OUR FIXATION ON JOB LOSS BLINDS US TO THE REAL IMPACT OF
AI
n the years following World War I, the trauma of trench warfare - the
mud, the gas, and the staggering loss of life - still lingered in the national
psyche. France sought to prevent a repeat of the war that had devastated
Europe, focusing its efforts on building a system that would make such a
conflict impossible. During the 1930s, France constructed the Maginot
Line, a 450-mile-long chain of fortified bunkers, turrets, and underground
infrastructure that spanned its eastern border with Germany.
It was, by all technical measures, a masterpiece. Unbreachable in the event
of such an attack, it was well-designed, heavily reinforced, and difficult to
penetrate.
It was, by all accounts, a perfect answer to the wrong question.
Because in May 1940, German forces launched a blitzkrieg, altogether
avoiding the fortified zones along the Maginot Line, and moved in through
the lightly defended Ardennes Forest, which the French had considered
impassable.
The blitzkrieg was a new system of combat that integrated mechanized
infantry, tank divisions, and dive bombers, all of which were coordinated
through two-way radio communication. Each unit operated semi-
independently but with coordinated intent, through shared objectives and

live two-way communication. France's defense system, built to withstand
centralized and linear conflict, was bypassed before it could be tested.
The Maginot Line stood tall through the attack. Unconquered and
unbreached, but also utterly useless. It was built for a version of warfare
that no longer existed. It had succeeded as an impenetrable engineering
solution but failed as a strategic response to a reconfigured system of
warfare. France, seemingly invulnerable in its fortifications, was vulnerable
in its framing of the problem it was trying to solve.
Framing the problem
That kind of framing error - a tendency to solve for a world whose
underlying logic has already changed - shows up far beyond military
history. It's especially evident in how we talk about artificial intelligence.
AI is often seen as just another tool - something that enhances or replaces
human effort without altering the fundamental structure of how knowledge,
decision-making, or economic activity is organized. More powerful than
any other tool in that it can also learn and self-correct. But still, it's just a
tool.
Executives view AI as a cost-cutting tool that can help them reduce
headcount and improve profits. Regulators fixate on job loss and job
creation as the central issue, reducing every AI discussion to a machine vs
human debate. Economists, for their part, attempt to resolve this debate by
analyzing past waves of automation to predict the future.
Across all these, AI is framed as a new way to play the same old game. The
only question is who wins - AI or humans using AI?
One phrase, in particular, gained traction during the rise of generative AI
between 2023 and 2025: "AI won't take your job, but someone using AI
will." It became a management mantra, repeated across conference panels
and LinkedIn posts. Learn the tool, the logic went, and you'll stay ahead.

The impact of AI had been reduced to a yes-or-no question, and the internet
had already settled on an answer. Most assumed the game remained
unchanged - only now, you could either play it better with AI or be replaced
by it. Most discussions did not consider the possibility that AI could
fundamentally change the playing field itself and, with that, the very game
you play.
On the surface, the statement appears reasonable, even empowering. It
acknowledges disruption while offering agency. It suggests that success in
the AI era will depend on adopting new tools and improving productivity.
Like the Maginot Line, it offers reassurance based on a seemingly sound
logic.
However, like the Maginot Line, the phrase is also built on an increasingly
outdated framework. It assumes that jobs are stable units of work and that
the primary effect of AI will be task-level substitution or enhancement. In
short, it treats AI as a personal productivity tool, not as a force that can
reconfigure the system of work.
What exactly is a system of work? It's the architecture that determines how
tasks are divided, how decisions are made, how responsibilities are
coordinated, and how roles are defined within an organization or an
economy, all in pursuit of achieving an overall goal. A restaurant kitchen is
a system of work structured around who chops, who sautÃ©s, when to fire a
dish, and how the various chefs communicate under pressure, to co-create a
dish to serve the customer. If you change the way orders flow in or the way
chefs communicate, the entire system responds accordingly.
Suppose orders that the head chef previously shouted out are now displayed
on digital screens in the kitchen. In that case, individual chefs start timing
their work themselves, instead of waiting for instructions from the head
chef. If diners directly order via tablets and the orders are displayed in the
kitchen in the order of how long a particular preparation takes, the
sequencing of what gets cooked and when also changes. Every change in
the coordination mechanism alters the overall system of work.
What France failed to grasp back in 1940 was that Germany had developed
a new mechanism for coordination, and, with that, had created a new

system of warfare.
Blitzkrieg, often translated as lightning war, is commonly misunderstood as
simply a faster form of attack - an optimized version of the old format.
Instead, the lightning attack of Blitzkrieg was an outcome of superior
coordination. Mechanized infantry, tank columns, and dive bombers were
not new in and of themselves. What had changed, though, was how they
were coordinated to operate in sync through the widespread deployment of
two-way radios. Every unit, from frontline tanks to reconnaissance aircraft,
had access to live communication channels. With this connective layer in
place, German forces could coordinate faster than their opponents, and with
greater precision and adaptability.
This was an entirely new system of warfare and a sharp departure from
World War I, where coordination was centralized and slow, and updates
moved up and down rigid chains of command. With the arrival of real-time
radio-based coordination, warfare became distributed and responsive.
That shift changed the logic of how advantage was gained. Air support
could be summoned at any time. Infantry units could be redirected without
waiting for centralized updates to be issued. The result was a lightning war
that allowed the Germans to advance through the Ardennes at a pace the
French hadn't planned for. The individual weapons had stayed the same.
The way these weapons were coordinated had changed.
That was the architectural shift that made Blitzkrieg so effective, enabling a
surprise attack through the Ardennes Forest and rendering the Maginot Line
useless. The Germans won with a better system, one where technology had
restructured how the components interacted, not just how they performed
individually.
When new technologies change how people coordinate, they also change
how work is organized. Take the example of restaurant kitchens again,
where every chef specializes in a specific dish, and the kitchen responds in
real-time to customer orders. Contrast that with a 'cloud kitchen', which
exclusively serves home delivery and utilizes AI to predict what customers
are likely to order on a specific day, based on past data. Staff start prepping
those meals before any orders are placed. At the same time, the app can

gently nudge customers toward those predicted items. As the ability to
influence customer behavior improves, the predictability of orders
increases, and food waste decreases, the kitchen's procurement and stocking
processes also change. Better coordination reshapes everything from
preparation to procurement.
When you change the mechanism of coordination, you change the entire
system of work.
This is why the story of the Maginot Line remains so relevant to
understanding the impact of AI on work. Blitzkrieg succeeded by turning
disconnected units into a synchronized system of warfare. AI does
something similar, reconfiguring how work is coordinated, not just
replacing or enhancing individual jobs.
Like the Maginot Line, the phrase "AI won't take your job, but someone
using AI will" offers a false sense of agency, but it's built on assumptions
that no longer hold. The problem with this framing is that, although it
sounds seemingly right, it directs attention to the wrong level of analysis.
People often think AI will either help them do their job better or replace
them outright, but that binary framing misses the bigger point. AI doesn't
just augment or automate tasks; it changes how work is organized. Your job
exists because the current system of work needs someone to handle certain
tasks and responsibilities in a specific way. But if the system of work itself
changes, that set of tasks and responsibilities may no longer hold the same
value in the new system.
To truly understand how AI affects jobs, we must look beyond individual
tasks to comprehend AI's impact on our workflows and organizations. In
order to understand how AI changes organizations, we need to understand
how AI changes the very basis of competition for companies - and, with
that, the reason those organizations exist in the first place.
To do that, we need to shift our lens from focusing on whether AI can
perform a task to understanding how AI changes the entire system that
gives that task its purpose and value.

Moving beyond the jobs narrative
When people think about the impact of AI, their first instinct is to ask: What
does this mean for my job? That's where the threat feels most personal, and
the loss most tangible. Our brains are wired to look out for such threats.
Even culturally, the future is framed as a contest between you and someone
who learns how to use AI. Media headlines, training programs, and panel
discussions rarely step back to question the frame itself. As a result, we
fixate on tasks we know and identify with - coding, writing, designing - and
wonder if AI will take over those tasks. What we rarely ask is how the job
itself might be redefined or rendered irrelevant when the larger system
around it changes. Systemic change feels abstract and is harder to visualize.
Yet, that's what we should be looking at.
This narrative that AI either replaces or augments your tasks is based on the
framing that jobs are bundles of tasks, and that the impact of technology on
a job can be understood by analyzing its impact on its constituent tasks.
This framing, however, reduces AI's impact to two narrow questions:
Which tasks can machines perform faster or more cost-effectively, and how
can humans remain relevant by working alongside them? Lines like "AI
won't take your job, but someone using AI will" simply echo this
automation vs. augmentation binary, but this view is incomplete. This view
overlooks how AI alters the very system that lends meaning to those tasks
in the first place.
Think back on the impact of containerization on ports. Ports invested in
cranes to automate the handling of cargo. Viewed from the lens of how
ports operated, the effect could have been misunderstood as port
automation. But port automation was a small part of a much larger
restructuring of the overall economic logic of trade. Standardized shipping
across trucks, trains, and ships, thanks to the intermodal container, made it
faster and cheaper to move goods globally, changing how supply chains
were organized and influencing the rise or decline of certain cities. This
new logic rendered some ports, such as Liverpool, irrelevant and altered the
fortunes of others, like Singapore. A dockworker who might have worried

about cranes taking his job would have suddenly realized that the entire port
had lost out. Task automation didn't matter. What really played out was a
new logic of which ports made sense in the new system of trade and which
ones didn't.
The German Blitzkrieg also illustrates this point. The French believed the
task of military defense required fortifications. The Germans recognized
that victory now required a new form of coordination between tanks and air
support, utilizing radio communication to disorient the enemy.
The problem had been reframed, and a new system was architected in
response. The container had changed the system of trade, and blitzkrieg had
changed the system of warfare. AI, today, is similarly changing the entire
system of knowledge work.
Task-based thinking fails to adequately explain how AI transforms jobs
because it doesn't account for changes to the overall system of work. It
treats jobs as stable bundles of tasks, which evolve as the constituent tasks
are gradually replaced or enhanced over time. It focuses on whether AI can
perform the task more efficiently or at a lower cost.
In contrast, system-based thinking doesn't see jobs as fixed roles. It sees
them as temporary groupings of tasks that make sense in a specific system
of work. When AI changes the system, the job bundle gets unbundled, and
the constituent tasks are reassembled in new forms. The same tasks may
still exist, but they may no longer hold value in the new system. And even
those that do will be rebundled into fundamentally new job bundles and
roles. These new roles emerge in response to a new system. The impact of
AI on jobs is, then, determined not just by AI's impact on the job's
constituent tasks but by AI's impact on the larger system of work.
We can make this shift easier to understand with a lesson from basketball,
even if you're not a sports fan. The game was traditionally organized
around five fixed player positions: point guard, shooting guard, small
forward, power forward, and center. Each position came with a well-defined
set of responsibilities: the point guard would direct plays, while the center,
typically a taller player, would defend near the basket and take close-range
shots. These roles were designed for a particular system of play, where each

player occupied a specific zone on the court and stuck to it. The better you
were at your assigned slice of the court, the more valuable you were to the
team.
The introduction of analytics changed how the game was played. It became
clear that taking more three-point shots was a smarter strategy than relying
on mid-range shots, and that spreading players across the court improved
offense. What mattered most wasn't your position but how the team moved
as a unit. With this new evidence, the logic behind the traditional roles
began to break down. Players were now valued less for their position and
more for their ability to contribute across multiple areas, such as shooting,
defending, and playmaking, regardless of their position.
Fig. 2.1: How basketball changed - Tasks, roles and workflows get
reshuffled
Importantly, the rules of the game didn't change, and the skills required to
play it remained the same. However, the logic of the game, or the system of
play that defined roles and valued them, had changed. Teams began
rewarding capabilities that cut across traditional roles: shooting, switching,
spacing, and agility. With that, some players who were highly effective

under the old model became less valuable, while others, who could adapt
across roles, gained importance.
The roles we associate with, in basketball or at work, make sense within a
particular system. In basketball, the constituent tasks of dribbling, passing,
or defending didn't disappear; they were instead rebundled towards a
different system of play. Jobs, similarly, are artifacts of organizational
design. A job exists because a system needs someone to manage a specific
set of tasks, decisions, and dependencies.
When the system itself changes due to the effects of AI, the logic of the job
can collapse, even if the underlying tasks remain intact. Constituent tasks
get rebundled into new roles that make sense in the logic of the new system.
Of course, unlike basketball, the rules of play, or how companies stay
competitive, do not remain fixed, which further determines what the new
job bundles look like.
The right unit of analysis, then, isn't the tool or the task but the system that
gives it purpose.
Task-centric vs system-centric
People often assume their jobs are safe because the tasks involved seem
resistant to automation. But what if that's not enough? If we look beyond
individual tasks and consider the broader system that makes a role
necessary, we find that a role can vanish, even while the tasks it once
involved continue.
Consider what happened to typists in the late twentieth century. Before the
advent of word processors, workflows were designed around typists. Entire
teams coordinated with typing pools to produce and revise written content.
System constraints made the role indispensable. Errors were expensive and
required retyping entire documents while managing revisions manually.
Formatting had to be done within the physical limitations of the typewriter.
The typist's role bundled input, formatting, error correction, and revision

because their accuracy, speed, and formatting skills were vital to workflow
execution.
Then the word processor arrived.
At first glance, it seemed like a productivity tool that would speed up the
work of typists. But word processors collapsed the costs that had once
justified the typist role. The cost of fixing errors dropped to zero. Revisions
could be made instantly, and formatting could be automated.
Typing didn't disappear, but the job of the typist did. The role had been
justified by the high cost of managing errors and revisions. Once word
processors eliminated those costs, the job bundle lost its economic
rationale. Typing became a distributed task, absorbed into the broader
workflows of knowledge work. Typists weren't outperformed by better
typists equipped with new tools; they were displaced by a system in which
typing no longer required a dedicated role.
The task-centric view sees AI as a tool that enhances the performance of
individual tasks. Work remains structurally unchanged. AI is simply layered
on top to improve speed or lower costs. In this framing, the main risk is that
a smarter tool might replace the person doing the task. The proposed
solution is straightforward: people should learn to use the tool to stay
relevant and keep their jobs.
The system-centric view, on the other hand, examines how AI transforms
the organization of work itself. It focuses on how tasks fit into broader
workflows and how the logic of the overall system determines their value.
In this view, even if tasks persist, the rationale for grouping them into a
particular job, or even performing them within the company, may no longer
hold once AI changes the system's structure.
From a task-centric perspective, typists shouldn't have lost their jobs. The
task of typing that gave the role its name was still being performed, and if
anything, typists were still more effective at typing than the average
knowledge worker. A system-centric perspective tells a different story. It
starts by recognizing that the typist role had emerged as a response to
managing the costs of expensive editing. When those costs decreased and

typing no longer required centralized or specialized resources, the
architecture of the workflow changed. No amount of reskilling or
adaptation would have helped the typist retain their job when the system no
longer required a role organized around that task.
The typist's case isn't unique and illustrates why a task-centric view of
evaluating the impact of AI can prove insufficient. Many companies
misunderstand the real impact of AI because they fail to distinguish
between task-level and system-level changes. In the early stages of
adoption, both task-centric and system-centric approaches seem to deliver
results. Both show productivity gains and improve local metrics.
Table 2.1: Task-centric view vs. system-centric view of AI

Task-centric firms move fast. They integrate AI into specific parts of their
business to accelerate processes. A factory might use AI to spot defects on
the assembly line, scan contracts, or sort through emails. These upgrades
initially appear promising, as costs decrease and output increases, but
nothing fundamental changes. Firms may automate the inspection process
on the assembly line, but the decisions of what to inspect and why, still
move through the same old silos and gatekeepers.
System-centric firms, unlike task-oriented ones, don't just look for places to
plug in AI for local efficiency gains. Instead, they revisit the underlying
architecture of how work is coordinated, and decisions are made. The
aircraft 
manufacturer Airbus 
utilizes AI 
to 
optimize 
individual
manufacturing steps. But far more importantly, it reorients the entire
manufacturing system by creating a live 'digital twin' - a live, virtual copy
of the entire aircraft production process.
This digital twin continuously pulls in data from machines on the factory
floor and uses AI to simulate aircraft design and construction models,
learning with every iteration. Rather than optimizing isolated tasks, it
enables superior coordination across the entire system by identifying
bottlenecks and testing alternate workflow configurations. Workflows adapt
in response, and roles shift accordingly. Where task-oriented AI enhances
performance within existing work structures, the digital twin allows Airbus
to redesign the structure of work based on a constantly evolving view of the
whole system.
Over time, task-centric firms face diminishing returns. All firms use the
same tools, as a result of which productivity on those tasks is soon
commoditized, and margins shrink. Meanwhile, system-centric firms are
playing a different game. They've changed how their business is wired.
Workflows have been redesigned, and the organization may often unlock
entirely new forms of value creation, not just greater productivity on
existing tasks.
The shift from task-centric to system-centric thinking enables us to
understand not only how AI affects individual roles but also how it reshapes

entire firms and the logic through which firms collaborate and compete with
one another.
Kiva and the automation vs augmentation fallacy
The limits of the task-based framing become especially clear when you look
at Amazon's adoption of Kiva robots in its warehouses. Kiva robots
autonomously navigate Amazon's warehouses, bringing entire shelves of
products to stationary warehouse workers. Using a task-based lens, one
might explain this as a case of robots introduced to assist workers in picking
and packing tasks. That interpretation would sound right and yet completely
miss what's really happening.
To understand how AI transforms work, imagine three concentric circles. At
the center are the tasks that workers perform. A job is a bundle of such
tasks. Surrounding these tasks is the organizational system, or the
workflows, teams, and structures that coordinate how those tasks come
together to create value. And around that lies the competitive ecosystem -
the broader market environment that determines what forms of work create
value and give an organization competitive advantage. Most conversations
about AI and the future of work begin at the center of the system - the job
and its constituent tasks - and often remain stuck there. We ask whether AI
can do a task faster or cheaper but fail to consider how the system of work
around that task is changing.

Fig. 2.2: Amazon's system of work
At Amazon's warehouses, workers work alongside robots to keep
warehouse operations running, but the warehouse itself is just one node in a
much larger fulfillment system. That broader system, in turn, is a key driver
of Amazon's overall competitive advantage. Together, the warehouse
workers, Kiva robots, and logistics infrastructure form a tightly integrated
system of work. At the level of the competitive ecosystem, Amazon's
commitment to two-day delivery, anchored by the Amazon Prime
membership program, gives it an advantage over competitors who can't
offer the same promise. Fast shipping keeps Prime customers engaged: they
shop more frequently, spend more per visit, and rarely look elsewhere.
Seen through this system-based lens, Amazon's use of robots was never
about augmenting warehouse workers. It is in service of powering the
fulfillment system that reinforces Amazon's strategic position. Amazon's
fulfillment system, meanwhile, is a tightly coordinated organizational
system - the middle circle - that performs by minimizing delays and

maximizing throughput. To guarantee those service levels, Amazon needs to
minimize human variability. Algorithms now play the role that people once
did, deciding what to ship and when, across every warehouse and truck.
As the system learns, not just within each warehouse but across the entire
fulfillment network, it continues to reorient workflows and reorganize labor.
The more Amazon's system learns, the less it resembles a collection of
independent tasks being individually optimized by AI, and the more it
works as a coordinated system, constantly adjusting the role of workers and
robots in service of system performance. In this light, workers and robots
are mere components inside a fulfillment system that continually
restructures workflows and reduces human discretion to drive greater
consistency and predictability across the fulfillment chain.
The story of Kiva robots shows that when AI reorganizes the logic of the
system, workers may continue to perform tasks, but their roles are
continually transformed around what the system needs, and not around
preserving human discretion or craft. In this kind of system, the focus is no
longer on using tools to help workers perform better at their original tasks.
It is on reconfiguring tasks so that they better serve the evolving priorities
of the system itself.
Automation versus augmentation, then, is no longer a helpful distinction.
Training on the tacit: How AI rewrites
professional services
As AI improves, this logic of system transformation plays out in other parts
of the knowledge economy as well, even impacting jobs that were
traditionally 
considered 
immune 
to 
technological 
advancements.
Knowledge work, unlike standardized picking and packing tasks in a
warehouse, relies on tacit knowledge and context held in people's minds.
For 
instance, 
junior 
lawyers 
traditionally 
advanced 
through 
an
apprenticeship model, learning the trade by reviewing contracts line by line.
It was slow, detailed work, but it was how future partners were trained. AI

tools can now scan thousands of contracts in seconds to identify anomalies
and compare contract clauses against those in prior deals. The knowledge
and judgment required for contract review are increasingly available in AI
models trained on vast amounts of legal data.
This indicates a bigger shift in how AI helps companies manage their
internal knowledge. In the past, certain kinds of expertise only existed in
people's heads. You had to ask the right person or dig through old forgotten
emails and chat threads to find it. AI, today, can learn from those
unstructured sources, including call recordings, old contracts, and chat
threads, and make that knowledge available across the organization. In
other words, AI makes tacit knowledge explicit, as previously buried or
unspoken expertise now becomes searchable and reusable. A partner at a
law firm might remember that a specific clause caused problems in a deal
five years ago, but unless you knew to ask them, that insight would stay
hidden. An AI tool trained on thousands of past contracts and negotiation
notes can automatically identify that clause, highlight how it has been
handled in similar cases, and propose better alternatives.
In this manner, AI takes what was once uniquely human, replicates it
through trained models, and distributes it across the organization, making it
widely accessible. When AI can be used to perform certain forms of
knowledge work, the usual constraints of access to trained workers and
their limited availability no longer apply. That expertise can now be
accessed easily, and the associated task can be performed instantly. This
creates a new division of labor between workers and tools.
Organizations, then, reconfigure around this new capability, and the
worker's role changes. A law firm may now accomplish a lot more while
hiring fewer junior lawyers. Senior lawyers, meanwhile, may spend more
time on strategy and litigation. The pyramid structure of these firms, where
junior lawyers worked their way up through grunt work, is already under
strain. Workflows also change, as AI coordinates activities in new ways.
The workflow no longer needs layers of assistants, reviewers, and
managers. Tasks that once required meetings or intermediaries can now be
coordinated instantly using AI. AI models, constantly trained on
organizational knowledge, enable different parts of the organization to

coordinate around the same shared understanding. With expertise more
accessible and teams better coordinated, the organizational structure
changes as smaller, specialized teams can now handle bigger workloads.
Fig. 2.3: A legal firm's system of work
As more firms across the ecosystem adopt these tools, the basis of
competition begins to shift. Traditional pricing models, built around
assigning more lawyers or billing by the hour, start to break down as task
performance is no longer the bottleneck holding things back. At the same
time, new competitors emerge as providers of 'legal technology' become
advanced enough to offer services directly to clients, bypassing the
professional services firms they once supported. These shifts in
competition, in turn, push traditional firms to reorganize, restructuring their
internal structures and the roles of their workers. As the basis of
competition changes, the workflows supporting it, and eventually the jobs
that get valued, change as well.

Whether on the warehouse floor or in a law firm boardroom, AI
reconfigures the entire system of work from the outside in. We often frame
the impact of AI on work as a battle between humans and machines over
who performs tasks better. In practice, however, AI isn't deployed to
replace or assist workers but to make firms more competitive. As a result,
roles are reshaped to match the logic of a new system of work, and the
value of the role now depends not just on how AI affects its constituent
tasks but on how well the role aligns with the new rules of competition.
How systems change - unbundling and rebundling
To understand the impact of AI on our jobs, our organizations, and the
nature of competition between firms, we need to understand how systems
change when acted upon by new technological forces. To understand this,
consider how music consumption has changed since the rise of digital
technologies.
Traditionally, music was distributed as albums - a bundle of songs sold
together, regardless of whether the buyer wanted each individual song. The
album was structured around the constraints of physical distribution. The
cost of pressing, packaging, and shelving an album in a retail store was the
same whether it contained one song or ten. The bundle made sense because
it supported a higher price that could match the cost structure of physical
distribution.
When digital distribution arrived, that constraint collapsed. The marginal
cost of distributing a single track fell to near zero. With that, the economic
logic of the album no longer made sense. Songs could now travel
independently.
As a result, the album was unbundled. Consumers no longer needed to buy
the complete package to get the one song they liked. But the shift didn't end
there. With millions of tracks now unbundled and available, finding music
became the new constraint.

Fig. 2.4: Unbundling and rebundling - From albums to playlists
In response, a new form of bundling emerged, this time in the form of
playlists, as players like Spotify took over digital distribution and
rebundled 
music 
through 
curated 
playlists 
and 
algorithmic
recommendations. Unlike the album, these new bundles were not created
with production or distribution constraints in mind. They were structured
around consumption preferences; what listeners were listening to or
searching for. Algorithmic coordination managed the creation of these new
bundles.
This shift from unbundling through collapsing constraints to rebundling around a new
coordination logic is not unique to the music industry. It's indicative of a broader
cycle through which most systems are transformed.
Systems are structured around managing constraints, much like the album
was set up as a bundle of songs because the cost of distributing individual
songs was too high. The shift from albums to playlists illustrates how the
structure of a system evolves when technological advancements alter the
constraints that previously dictated its design.
Albums and playlists bundle songs based on artist, genre, mood, or listener
preferences, but the songs themselves are independent and don't rely on one
another to perform a larger function as a whole. In contrast, economic
systems are much more complex because their components are deeply
interconnected. A supply chain links production, inventory, and logistics in

tightly sequenced steps. An operating room procedure combines specialized
roles, tools, and activities that must be coordinated precisely. A university
curriculum connects courses, faculty, and resources across disciplines into
structured learning paths. Despite these differences, we can still understand
how large economic systems change by looking at the same basic dynamic:
forces that pull components apart (unbundling) and forces that reorganize
them into new configurations (rebundling).
Take shipping containers, for example. They transformed global trade by
removing the constraint of unreliable shipping and introducing a new
method for coordinating across firms. Before the advent of containers,
companies had to control the entire manufacturing process themselves, as
shipping delays made outsourcing too risky. Once containers made shipping
fast and predictable, firms could break up production across the globe. The
old model of vertically integrated manufacturing was unbundled and then
rebundled around the logic of the container. This unbundling and
rebundling played out across the entire system of trade, transforming ports,
restructuring value chains, and changing how companies and countries
compete.
Systems evolve when old constraints are removed, and new ways of
coordinating emerge. Once a constraint disappears, systems built around it
tend to break apart into their core components - they unbundle. When a new
coordination method takes hold, those components are reassembled in new
ways - they rebundle.
The words unbundling and rebundling come from economics, where they
carry very specific, technical meanings. But in the world of business,
they've caught on primarily because of the vivid images they evoke: a
system coming apart into its constituent components, then being put back
together in a new way. Depending on what kind of system we're talking
about, other terms, like decoupling, reconfiguration, composability, or
assembly, might be more precise. Still, to keep things simple and avoid the
kind of jargon that can make big ideas harder to follow, I'll stick with the
terms 'unbundling' and 'rebundling' throughout this book. These terms
aren't perfect, but they offer a straightforward way to visualize how systems
evolve. More importantly, while we aim for clarity, we won't lose nuance.

As we explore how this pattern unfolds across jobs, workflows, companies,
products, and customer journeys, we'll also pause to examine the subtleties
involved in each case.
Shein and the changing system of work
The examples of the Maginot Line, basketball positions, and law firms help
us understand the theoretical foundation of how systems reorganize when
coordination mechanisms change. However, to see this transformation in
vivid detail, we need to examine a case that embodies this shift at every
level, from individual roles to industry-wide competition.
Shein, our example in the opening chapter, appears to be yet another low-
cost, fast-growing Chinese fashion player, flooding the internet with endless
knockoffs and capitalizing on the long tail of e-commerce. It's also a
polarizing example whose model raises important ethical, environmental,
and labor concerns. Yet, despite this, it offers one of the clearest illustrations
of how AI and algorithmic coordination can restructure entire systems, from
jobs and workflows to organizational design and industry logic.
The fashion industry has traditionally relied on designers, merchandisers,
buyers, and forecasters performing highly specialized jobs that require
creative discretion. A creative director in a sleek office would sketch next
season's trends. Buyers would fly to Milan or Tokyo to spot new trends.
Forecasting trends was a craft. Fashion, in that world, was a bundled system
of interlocking specialties. Each job was shaped by constraints of creativity
and time.
Shein unbundles these roles. Instead of trying to guess what customers
might want months in advance, Shein relies on the firehose of social media
as its algorithms scrape TikTok and Instagram for emerging trends. Instead
of using moodboards to parse which silhouettes, colors, or cuts are gaining
traction, Shein relies on engagement metrics. Those signals are then
dispatched across a global network of freelance designers who work project
by project, often anonymously, each receiving a specific brief and a tight

turnaround. The designer's role isn't eliminated, but a previously cohesive
job is unbundled into its component tasks, which are then rebundled
algorithmically into something closer to a gig role, with significantly
reduced creative discretion and a greater emphasis on speed and
responsiveness. The buyers who travel the world to negotiate orders and
place seasonal bets are replaced by algorithms, which predict demand and
trigger micro-batches of production. The rebundled role is no longer that of
a buyer, but more of a supply chain orchestrator.
The bigger shift, though, is seen not at the level of individual jobs, but at
the level of how the organization itself is structured. Traditional fashion
companies relied on hierarchy to manage risk. Multiple layers of approval,
seasonal calendars, and merchandising meetings were used as buffers to
manage uncertainties associated with a long production cycle. Shein
unbundles the organization by removing these slow coordination layers.
With trend detection, design, and production orchestrated algorithmically,
the very logic of coordination is inverted. There are no long meetings. No
calendar resets. No handoffs from one silo to the next. Manufacturing,
marketing, and merchandising are orchestrated in response to changes in
demand. The rebundled organization operates without the constraints of
traditional fashion.

Fig. 2.5: Shein's system of work
Most importantly, the competitive ecosystem itself changes as the basis of
coordination changes. Zara, the pioneer in fast fashion, had perfected an
advantage around speed-to-store, with faster restocks and the ability to
constantly adjust its offerings based on what sold. However, that system
worked as long as retail foot traffic remained the primary indicator of
demand. With the rise of TikTok and Instagram, and the superior ability to
capture data digitally, Shein's algorithms could react faster than the very
pioneers of fast fashion. Manufacturers became on-demand partners, not
locked into seasonal contracts but flexible and reactive, ready to produce
micro-runs based on what was trending in a particular week. Social media
influencers became de facto merchandisers, nudging their followers toward
specific SKUs and participating in live sales experiments.
Shein's rise is the inevitable outcome of a system where the old constraints
of slow data, long lead times, and centralized decision-making have
collapsed. In traditional firms, control is established through a hierarchical

structure. Product lines are reviewed, budgets are approved, and layers of
human gatekeepers enforce brand guidelines. Shein, instead, operates a
decentralized ecosystem under centralized logic.
Shein's speed of execution, when understood through a task-centric view,
would be interpreted as a story of automation. But as we've noted all
through, Shein's speed is really an outcome of a fundamentally different
architecture, which in turn, is built around a new mechanism of
coordination.
After exploring a wide range of examples to illustrate the world we're
moving toward, I chose to focus on Shein, not because it is the most
obvious or the most celebrated case, but because it embodies the whole arc
of what becomes possible when old constraints disappear and new forms of
coordination emerge. Shein's story is instructive and illustrative as a case
study for system change, but it is also a cautionary tale. It shows, in vivid
detail, how removing friction from a system can unlock astonishing new
capabilities, but also how it can change the values and assumptions that
once gave that system meaning.
Systems change when constraints are removed. However, not all constraints
create negative friction. Some constraints are essential to create positive
friction that makes economic activity meaningful. Human judgment and
intuition might be slower to react than algorithms, but they are valuable and
will only increase in value in a world of rapid execution. Shein's approach
deconstructs judgment into metrics and outsources intuition to engagement
data. Using task-centric framing, this might appear efficient. However, with
a system-centric framing, we also realize that something valuable is lost. As
fashion evolves, it is shaped by eccentric designers and regional aesthetics.
Shein's algorithms, though, crawl the same platforms for the same signals.
Style is no longer curated as it once was. Algorithms track what sells, and
what they track gets made further. Traditional fashion would sell an identity,
a lifestyle. Whether Shein does that is debatable; it seems more focused on
hooking people into an infinite scroll.
I returned to Shein in this chapter, just as I did in the previous one, because
it crystallizes both the transformative power of AI and the unintended

consequences that result when we treat optimization as the end goal rather
than one of many choices in system design. Shein's example illustrates both
the value that can be unlocked using AI and the value that can be lost in that
process. Algorithms speed up market feedback but can also collapse the
diversity of thought and perspective that makes today's industries resilient.
Shein's case illustrates not only what can be achieved through optimization
but also what can be lost when we no longer pause to ask what's worth
preserving. The challenge, then, is about structuring tomorrow's systems so
that they retain room for interpretation and deviation. Long-term advantage
won't come from AI-aided automation and coordination alone, but from the
clarity to separate what should be optimized from what must remain rooted
in human imagination and intuition.
OceanofPDF.com


OceanofPDF.com


OceanofPDF.com

T
3
NEW POWER, NEW TENSIONS
WHY TOOLS THAT PROMISE PROGRESS ALSO CONCENTRATE CONTROL
o most shoppers in the 1970s, barcodes looked like modern-day
hieroglyphics - abstract black stripes with no clear meaning. Few
realized they were staring at the future of retail.
Store managers thought they were getting faster checkout lanes and less
room for cashier error as the new technology efficiently identified products
by code. What the barcode really offered, though, was a way to turn every
product into a data point. Every scan created a data trail, and that trail
would eventually transform how decisions were made and who got to make
them.
Two giants, Walmart and Kmart, jumped in early to adopt this new
technology. Both had sprawling store networks and access to the same
technology. Yet, only one of them used barcodes to build a data-driven
empire. The other started down a long, slow path into irrelevance. The
difference wasn't the barcode itself, but the architecture each company built
around it.
Barcodes might have looked like checkout tools, but they were actually the
basis of a new form of coordination. Walmart used the barcode alongside
other complementary technologies it had been investing in. Barcode scans
at checkout created data signals that aligned factories, warehouses, and

stores into a single responsive system. Walmart's private satellite-based
information systems utilized this data to provide suppliers with direct
access to store-level sales, enabling them to restock shelves proactively in
response to the data. Walmart could now see precisely when, where, and
how fast products were sold. This visibility restructured how decisions were
made.
Before barcodes, store managers made restocking decisions based on
weekly reports and gut instinct. Decisions were inconsistent and imprecise.
Without reliable data, retailers couldn't manage stock efficiently or
negotiate from a position of strength. This lack of visibility limited their
ability to coordinate with suppliers.
Barcodes changed this. Retailers could now optimize shelf layouts and
reorder automatically. What really mattered, though, was the power shift
that unfolded as data created new leverage for retailers, helping them
restructure their supplier relationships. Walmart, more than anyone else,
used this data to pressure suppliers to meet tighter delivery windows,
standardize packaging, and integrate with its logistics infrastructure.
Control shifted from suppliers to retailers. The supply chain, no longer a
fragmented sequence of handoffs, became a centrally coordinated system.
The old tensions between suppliers and retailers, originating from a lack of
visibility, gave way to new tensions, where retailers like Walmart now
called the shots.
Data improved operations, but far more importantly, it enabled new
innovation in retail. Retailers could now test pricing, promotions, and
product placement because they could track changes in product sales with
every new test. They could influence and steer consumer behavior, not just
respond to it. Retailers adjusted layouts and offers based on consumer
response. As retailers gained more influence over consumer behavior, the
traditional dominance of upstream brands went down. Brands could no
longer dictate shelf presence based on marketing or distribution power and
had to prove performance with every scan. The customer interface had now
become the most valuable control point. This shift in value favored
consumer-facing firms that controlled shelf space and checkout, rather than
upstream manufacturers.

The first-order effects of barcode technology played out in terms of
efficiency, resulting in faster scans at checkout and lower labor costs. The
second-order effects created greater leverage over suppliers and customers.
The third-order effects, though, transformed retail forever.
The barcode solved the fragmentation of decision-making across large retail
networks. Before the advent of barcodes, retail chains were structured as
loose federations of independent stores. Each location made its own
decisions - an architecture from an earlier era, when retail networks had
grown through replication. This placed hard limits on the advantages of
scale. Without a centralized view, a chain operating hundreds of stores
couldn't act like a single, coordinated entity. More importantly, without that
coordination, it couldn't extract leverage from suppliers or shape consumer
behavior consistently across its store footprint.
The barcode enabled a new form of coordination, allowing inventory
planning and supplier negotiations to be orchestrated from a central system.
This shift introduced a new architecture for retail, one where the entire
network of stores could make coordinated decisions and benefit from
economies of scale as a result. Yet, most retailers continued to follow the
dominant logic of decentralized decision-making and fragmented systems
that they had inherited from an era before barcodes. They implemented
barcodes for faster checkouts and celebrated shorter queues and lower labor
costs, but left the rest of the architecture intact.
Walmart did the opposite. It built a 'barcode-native' architecture for retail,
designed for centralized coordination and control. With barcode scan data
flowing through an integrated logistics network, Walmart transformed
retail. Walmart built a satellite-based information system to track sales from
checkout to warehouse to supplier. It used that live data not only to reorder
stock but also to renegotiate supplier relationships. Kmart, by contrast,
continued operating with the architecture of a previous era. Technology
didn't create an advantage. Coordination did.
This created a surprising divergence in the fates of the two companies, and
indeed, a divergence between barcode-native architectures and older retail
architectures. On paper, both Walmart and Kmart had scale; they both

operated vast store networks. But only one of them turned that scale into
power.
Scale creates power when the various components of the system reinforce
each other. Walmart's scale was coordinated as data from across stores fed a
central information system. Every new store was integrated into the same
infrastructure, benefiting from centralized decision-making and negotiation
with suppliers. As the company grew, each additional unit strengthened the
whole, increasing this leverage over suppliers as well as improving
forecasting accuracy. Kmart had size but didn't benefit from scale. It
expanded store count and captured the same data, but didn't change how it
made decisions. Purchasing remained fragmented, and the addition of new
stores only increased overhead with little additional leverage. From a
distance, Kmart appeared just as large as Walmart. However, beneath the
surface, it lacked the architecture to harness scale as power.
As barcodes reshaped retail, the broader ecosystem aligned in response.
Suppliers had to standardize product SKUs. Store workers and managers
were now required to follow stricter protocols and watched their roles get
narrower and more constrained. Decisions that relied on human judgment
could now be coded as logic into information systems, leaving no space for
discretion at the edge. Barcodes standardized how products were described
and processed, reducing each item to a standardized data packet. This
standardization reorganized the supply chain. Product suppliers that once
differentiated themselves through unique packaging, stocking, or logistics
practices, to secure better terms, now had to conform to retailer-enforced
standards. 
With 
increasing 
standardization, 
suppliers 
became
interchangeable, and power began to shift.

Fig. 3.1: Walmart's system of work, following the adoption of barcodes
The difference between Walmart and Kmart is often chalked up to vague
notions like better execution. That, however, oversimplifies what actually
happened. Walmart didn't just move faster; it rearchitected the entire system
and changed the power relationships within it. It wasn't execution that made
the difference. It was a fundamental shift in coordination power.
Coordination grows the pie, but it also changes who gets to keep which slice of it.
Walmart's adoption of barcodes expanded the total value of the retail
industry. Before barcodes, inventory was managed by guesswork, and
stockouts were a common occurrence. Barcodes enabled faster restocking
and greater product variety. Stores could serve more needs, and the entire
supplier ecosystem was reconfigured to help serve that. But even as the
system grew, Walmart captured an outsized share. Its central role in
coordination, deciding what would sell and how it would be presented,

made suppliers increasingly interchangeable. Competitors without system-
wide visibility fell behind. The barcode made control over coordination the
key to capturing value.
A bigger economy doesn't mean shared prosperity
The conversation around AI tends to polarize quickly. On one side, there's
the anxious chorus of doomsayers, warning that automation will eliminate
jobs and render people obsolete. On the other side, the techno-optimists
appear, brushing off the fear and proclaiming that innovation is a tide that
lifts all boats. History, they'll remind you, is full of moral panics about
machines replacing people, and yet, look around, the economy's bigger than
ever.
There's a problem with this polarized debate - both sides are having the
wrong conversation. They're locked in a tug-of-war over whether the pie
grows or shrinks while missing what's really happening: AI, like many
other technological breakthroughs before it, grows the pie, but the growing
pie isn't sliced in a way that everyone gets their fair share. When
technology shifts, it doesn't merely add value; it also reorders the balance
of power.
We tend to treat economic growth and inequality as separate issues, as if
one belongs to macroeconomics and the other to ethics. But they're deeply
intertwined. A growing system does not mean shared prosperity. In fact,
growth and inequality often rise together, because the very mechanisms that
expand the pie also determine how it's divided.
Today's polarized debate on AI is rooted in task-centric framing. It frames
the problem in terms of job loss or productivity gains, but overlooks the
more significant shift. AI doesn't just change what we do. It changes how
systems are restructured and who has control over them. To clarify this, let's
map the landscape, not as two opposing viewpoints, but as four distinct
positions based on how the pie grows and how it's sliced.

Fig. 3.2: Different schools of thought on value distribution
The Luddite fallacy of machines taking over jobs in a fixed system sits at
the bottom-left. It's a fear that's easy to mock in hindsight, but it persists
because even with system shifts, people do lose out. Entire communities
built around a specific skill or workflow can vanish in a generation.
Scoot over to the bottom-right, and you have the techno-optimist fantasy
that innovation will expand the pie for everyone. The myth that AI will only
make the world a better place for all is hyped incessantly by startups selling
a vision of future productivity. However, a closer look reveals rising
evidence of wage stagnation, power concentration, and growing inequality,
which tells a different story.

In the top-left quadrant, we find task-based misdirection. People sense that
work is changing, but still treat the pie as fixed. They believe jobs will look
different because AI will take over tasks, not because the system itself is
changing. In this view, humans govern and supervise AI while it executes at
scale, but the underlying architecture of value creation stays the same. It's a
comforting simplification, but also a trap.
This brings us to what's really happening: the pie is growing, but not
everyone will benefit from the gains. This is the quadrant of rebundling,
where entire industries are being rebuilt around new logic. All three other
quadrants still run with the task-centric framing. Only in this quadrant is AI
seen as the engine for a new system.
In this world, success is no longer determined by getting better at playing
yesterday's game using AI. It's defined by whether you're playing the right
game. Former giants collapse, not because they didn't adopt the tools, but
because they adopted them into old systems. Kodak went digital, and
Barnes and Noble had a website and an e-reader. In the end, it didn't really
matter.
Most debates about AI still live in the bottom half of the grid: Will jobs
vanish? Will productivity rise? The real question is up and to the right: Who
defines the new rules? Who captures the upside? And who's holding the
knife when the new pie gets sliced? The growing pie doesn't get shared
equally. It gets divided by those who control the means of coordination.
The Walmart vs. Kmart example also illustrates this point. Both retailers
gained access to the same technology: the barcode. Both had the
opportunity to improve operations. However, only Walmart built the system
architecture to turn that operational visibility into competitive advantage.
This, in turn, moved power away from fragmented suppliers and store
managers to Walmart. As more value was created, Walmart captured a
disproportionately larger share of the growing pie. Suppliers, store
managers, and brands lost autonomy and influence.
This is the fundamental idea of a reshuffle. New winners and losers emerge, not
despite a growing pie, but precisely because of it.

New forms of value emerge, but so do new forms of inequality. To make
sense of this, we need a sharper framework that explains both how
rebundling creates new value and how it simultaneously restructures who
captures that value.
Coordination as power - Designing systems that
define the slice
Economic systems are complex systems. They don't behave like simple
machines with predictable cause-and-effect relationships. Instead, they are
shaped by numerous interdependent components, encompassing people,
firms, institutions, technologies, and behaviors, which continually interact
and evolve in response to one another. In such complex systems, slicing the
pie - deciding who gets what, when, and how - is more a matter of
managing the system's structure than of simple math.
That's why attempts to slice the pie through top-down control can often
lead to unintended consequences. The Soviet Union's Gosplan, its state
planning committee, was designed to slice economic output through five-
year plans. These top-down planners, however, lacked local information
and failed to account for the system's interdependencies. Nail factories were
told to meet production targets by weight, so they made huge, heavy nails
that no one could actually use, just to hit the number. When targets switched
to counting units, they made tiny, flimsy nails instead. Shoe factories faced
the same problem. They were told to produce a certain number of shoes, so
they made only one size to simplify production, even if it didn't fit anyone.
Though exaggerated, these stories reflect why value in a complex system
cannot be distributed by drawing precise boundaries using top-down policy.
While the metaphor of 'slicing the pie' may visually look like an act of
drawing precise lines that partition value, it's really an act of designing and
managing relationships and interdependencies that still function after those
lines are drawn. That's where the Soviet planning model failed.

Now, contrast that with a system built on coordination, rather than
command and control.
The British Empire ruled the Indian subcontinent by carefully redesigning
how the vast and diverse territory was organized. The British figured out
how to extract value from a fragmented, diverse system by transforming it
into a centrally coordinated structure, which made it easier to allocate
resources to the Empire while maintaining the appearance of local rulers
being in charge.
While Britain's dominance is often explained through the 'better tools'
fallacy - the idea that superior weapons or infrastructure ensured success -
Britain's real advantage lay in how it reorganized the Indian subcontinent to
suit its goals. Rather than imposing orders from the top, the British worked
on rebundling the system in order to divide it.
Rebundling involves designing how fragmented parts of a system fit
together into a new whole, structured around a specific goal. Britain's goal
of extracting resources from colonial India required a new form of
coordination. Top-down control over land or people would not have been
effective when managing a distant and fragmented land. Instead, Britain had
to architect the entire structure: defining how the Indian subcontinent and
its people were represented, centralizing decisions in London while
enabling local execution, and designing how the system's fragmented parts
stayed connected and governed through rules and incentives. Through these
five levers of coordination, the British Empire transformed a diverse,
decentralized region into a unified machinery that reliably funneled value to
the imperial core while maintaining the appearance of local autonomy.
First, the British realized that in complex systems, nothing can be managed
unless it is accurately represented. The Great Trigonometrical Survey of
India transformed a complex network of locally governed kingdoms into
something that could be centrally governed from London. Cartographers
turned land into standardized, taxable units, drawing economic and
administrative borders. Through tools like the census and ethnographic
surveys, the British reframed caste, religion, and territory into fixed
categories that could be governed.

Even in a deeply fragmented system like Colonial India, marked by
linguistic, religious, and political tensions, the ability to impose a structured
representation of the whole became the foundation for effectively dividing
the system and taxing it. Before any laws were passed or railroads were
laid, the Empire first built a map of the territory. This created a standardized
frame through which decisions could be made at scale.
With representation in place, they instituted a new logic of centralized
decision-making with distributed execution. A small elite, trained in British
systems and values, enforced policies designed in London across India. This
was formalized in Macaulay's vision for education: to create a class of
Indians who looked local but thought like the British. These Brown
Englishmen helped extend British logic without increasing British presence.
Local rulers remained in place but operated as extensions of colonial
authority.
New institutional structures, such as the Indian Civil Service, helped
establish a shared decision-making logic and coordinate execution. With
this in place, the Empire could determine who was included or excluded,
and under what terms different groups were allowed to participate. That's
how the Empire reshaped the system to serve British interests.
Infrastructure also became a tool for coordination, as it redefined how
different regions connected with each other. Railways allowed troops and
goods to move quickly, while ports ensured that resource-rich areas were
connected to imperial trade flows. Ultimately, the Empire maintained its
power through a divide-and-rule strategy that pitted local kingdoms against
one another. Colonization was sustained not through better tools but
through superior governance. The resulting coordination enabled the
Empire to take control while maintaining stability within the system.

Fig. 3.3: British India's control of provinces through coordination
power

These five factors of coordination-based power - representation, decision-
making, execution, composition, and governance - allowed the British
Empire to slice the pie not by enforcing control at every point, but by
designing the system so that value flowed predictably to the center, while
managing tensions within the system's various parts. The British Empire's
ruthless, and almost technocratic, leverage of these five forms of power
illustrates how complex systems are sliced and value distributed.
The British Empire demonstrated that controlling the entire system is not
necessary to slice the pie; it can be achieved by controlling the mechanisms
of coordination: representation, decision-making, execution, composition,
and governance. When managed effectively, they create the means to grow
and slice a complex system, while managing the inherent tensions across its
parts.
This is also illustrated by Walmart's transformation through the adoption of
barcodes. Before Walmart, manufacturers controlled the story about what
customers wanted and what retailers should stock. Retailers depended on
manufacturer reports to determine what to stock. That meant representation
power, or the power to define what is seen and measured, rested with
suppliers. With the advent of barcodes, Walmart changed that. Using
barcode scanning at checkout, it built a live, store-level view of what was
selling. It now had the clearest picture of demand; its own map of reality.

Fig. 3.4: WaImart's control of suppliers through coordination power

This shift in visibility gave it decision-making power, the ability to choose
what happens. In Walmart's case, barcode-based data capture at scale gave
it the decision power to decide what gets ordered, stocked, or promoted.
Instead of letting suppliers push products into stores using incentives or
promotions, Walmart instituted a reordering system based on actual sales
data.
With decision power, Walmart also captured execution power, the right to
determine who carries out what action. Walmart's private satellite network
and just-in-time distribution hubs created a tightly coordinated hub-and-
spoke system. If a store ran low on stock, replenishment was triggered
automatically from the nearest hub. This tight coupling between decision-
making and execution, built on a proprietary representation, gave Walmart
immense power. Unlike Kmart, whose stores operated independently,
Walmart functioned as a single, unified system. This system-wide
coordination unlocked real economies of scale, not just in purchasing, but
also in logistics, forecasting, and replenishment.
With scale, Walmart exercised composition power and governance power,
standardizing how suppliers interfaced with its operations. Every supplier
had to conform to Walmart's protocols for transmitting inventory data and
responding 
to 
replenishment 
orders. This 
turned 
suppliers 
into
interchangeable plug-ins in Walmart's retail engine, where they participated
based on Walmart's terms and rules.
Walmart transformed retail from a fragmented, supplier-driven model into a
tightly 
coordinated, 
data-centric 
system. 
Before 
Walmart, 
large
manufacturers, who controlled production, determined how value was
distributed. In Walmart's world, the distribution of value was determined by
whoever coordinated the new system.
OceanofPDF.com

AI flips the power playbook over
Walmart could bend entire supply chains to its will because it had the
leverage to demand barcode compliance and visibility into inventory. This
approach worked because Walmart's market power made compliance
mandatory. Vendors who failed to meet the technical requirements lost
access to Walmart's customer base.
But what if you're not Walmart? What if you're trying to orchestrate a
fragmented, chaotic industry where no one agrees on standards, tools don't
talk to each other, and everyone guards their data like a trade secret? Most
market participants lack Walmart's leverage. Mid-sized manufacturers
cannot dictate terms to suppliers. Even large companies often lack the
concentrated market position necessary for forced standardization. How do
you then align ecosystem behavior without traditional control mechanisms?
As we noted in the opening chapter, AI offers a new path to coordination,
one that requires neither consensus among market participants nor the
market power to enforce compliance. Traditional coordination models relied
on either consensus-driven standardization, as in the case of the shipping
container, or on tightly enforced integration, as in the case of Walmart's
suppliers agreeing to data integration around the barcode, to align behavior
across actors. These approaches assumed that coordination required prior
agreement and conformity.
AI is unique in its ability to enable coordination without requiring
consensus or enforced integration of systems. Representation is the starting
point for effective coordination, because systems can only act on what they
can see. As more of the world around us is captured as data, whether
through sensors in physical environments or AI models that extract
structure from text, images, and speech, we expand the space of what can
be seen and tracked. With every leap in AI capability, the boundaries of
what can be represented get redrawn. With the advent of large language
models, for instance, knowledge that was once tacit and resistant to digital

capture, trapped in unstructured discussions, complex 90-page contracts,
Slack threads, and customer complaints on Reddit, can now be structured
and represented. This enables coordination without upfront agreement.
AI-enabled coordination is also unique in its ability to attract the
participation of other players. While Walmart required upfront integration
and contractual compliance, AI-enabled coordination delivers initial value
to players without requiring any integration, then gradually unlocks more
value as participants opt in. Ecosystem alignment grows as more actors
join, because the system becomes too valuable to avoid.
Consider how modern agriculture has changed through data capture and AI.
The Climate Corporation (also Climate Corp or Climate) began as a
weather prediction startup for farmers. Before Climate Corp, farmers relied
on intuition, local knowledge, and personal experience to manage their
farms. Climate Corp changed that by creating a digital representation of the
farm, using data across satellite imagery, weather patterns, soil moisture,
and yield history.
On one hand, this digital representation of the farm initially proved
invaluable for farmers. Climate's diagnostic tools could help them identify
nutrient deficiencies and disease risk, and modify fertilizer or irrigation
strategies in response. This representation of the farm also gave Climate the
power to define farm performance on its terms. Smallholders and traditional
cooperatives without access to this platform were at a disadvantage.
Meanwhile, larger insurers and other platform partners who could act on
this new map gained. When Monsanto (now Bayer) acquired Climate, it
used this power to slice the pie in its own favor, by aligning the platform's
recommendations more tightly with its own product portfolio and selling
more of its products to farmers. Through the years that followed, seed
suppliers, insurers, and equipment providers increasingly started building to
Climate's standards. The more players plugged in, the more irreplaceable
the platform became. Perhaps most importantly, Climate's AI capabilities
enable it to predict droughts and crop yields months in advance, thereby
managing risk more effectively. This gives it the power to help set prices for
agricultural insurance. Climate Corp has shifted from its initial position as a
tool for making farming decisions to a system that now determines what

constitutes good farming practices. In this manner, AI allows firms to
achieve coordination and exert control even in the absence of traditional
market power..
When AI restructures power without touching the
task
Understanding how AI transforms systems through coordination also helps
us better comprehend one of the central questions posed in the previous
chapter: why some workers win and others lose in the age of AI.
Take truckers in the U.S., especially independent drivers, who used to work
with a high degree of autonomy. They found and negotiated loads through
informal networks, navigated cross-country routing decisions based on fuel
prices, weather, and regulations, and managed delivery schedules by
flexibly coordinating across shippers (or customers). During delays or
breakdowns, they made real-time judgment calls to keep shipments moving.
A reliable trucker could earn premium rates and get first call on high-value
loads for ensuring reliability in an unpredictable system.
Platforms like Uber Freight have changed that. Much like Uber drivers,
who receive their assignments through an app, truckers now find jobs
through similar logistics platforms, such as Uber Freight. When we think
about AI and trucking, we focus on the possibility of self-driving trucks
automating driving. But even before that materializes, today's platforms
have already hollowed out the most valuable parts of the trucking job,
which were less about driving anyway and more about coordination. Using
our five-part framework, it's easy to understand why truckers lose pricing
power and autonomy over decisions in such a system.

Fig. 3.5: Trucking platforms' control over truckers through
coordination power

In a system like Uber Freight, a task only counts if it can be tracked; it
needs to have a representation. Platforms reward what they can see, such as
job acceptance rates and delivery times, and overlook what they cannot, like
a driver's reliability under pressure or their care in handling cargo.
Representation determines reward. If the platform can't measure it, it
doesn't get compensated.
These platforms also centralize pricing, routing, and load management
decisions. Decision power moves away from the trucker as algorithms can
now set priorities and resolve uncertainty at speed and scale. In the past,
experienced truckers chose routes that helped them save time and cut costs.
This knowledge helped them differentiate themselves from inexperienced
truckers and helped build long-term trust with their customers. Now, the
platform picks the route, and the driver just follows it. Experienced truckers
no longer have that pricing power. The platform absorbed the intelligence
involved in the job, leaving the worker to simply execute.
The platform also determines the new composition of the trucker's job,
including the tasks involved and how they fit together. The traditional
trucker job was a bundle: part dispatcher, part negotiator, part problem-
solver. With AI-driven coordination, that job gets unbundled and hollowed
out into just one narrow task of driving. All other tasks are rebundled in a
new workflow.
Finally, platforms exercise their governance power to decide what counts as
good performance. Metrics such as acceptance rate and on-time delivery are
tracked relentlessly, while factors like customer satisfaction and flexibility
are often overlooked. If the system doesn't measure it, it's not part of the
driver's success.
In this algorithmically managed system, the driver, once valued for
judgment and relationships, is now valued only for driving, and is easily
substitutable by another driver. Large fleet operators may benefit from this,
as it drives greater efficiency, but independent truckers and small operators,
who have built their businesses on trust and local knowledge, often lose out.
A similar divergence also plays out with their customers, the shippers.

While large shippers benefit from logistical consistency, smaller shippers
may lose the flexibility they once enjoyed with trusted drivers.
The trucker's original job gets unbundled, but this unbundling isn't
accidental. It reveals what algorithmic coordination prioritizes and what it
overlooks. When AI platforms rebundle work, they prioritize tasks that can
be represented and govern the ecosystem based on that far-from-complete
representation. Alongside changing the job, this also restructures power
relationships across entire industries.
The tensions that slice the pie
The examples of Climate Corp and of trucking platforms illustrate how AI
constantly reshuffles power in economic systems. Every technological
reshuffle changes the system in a way that introduces fundamentally new
tensions. We observed this with the barcode, as well as with
containerization.
Some tensions were easy to spot: container-ready ports pulled global trade
routes toward themselves. However, less obvious new tensions emerged
through the reshuffling of global trade that followed. Landlocked nations
faced higher shipping costs. Retailers, capitalizing on just-in-time access to
inventory, began bypassing wholesalers. Even trade imbalances became
expensive, as import-heavy countries had to now pay to ship empty
containers home. Containerization went beyond expanding global trade; it
changed who got what.
Similar tensions continually emerge as AI improves its ability to transform
systems of work, particularly as it extends far beyond trucks and tractors
into domains of knowledge once considered immune to automation.
These tensions emerge across a system of work at three levels: the task
level, the organizational system level, and the competitive ecosystem level.

Fig. 3.6: The tensions introduced by AI in the system of work
Tensions between workers and their tools
Much of knowledge work relies on expertise and tacit knowledge that
cannot be easily codified. However, AI is improving at capturing this kind
of hidden knowledge and converting previously tacit knowledge into inputs
that machines can utilize to perform similar tasks. This creates an obvious
tension between workers and AI tools. In some situations, tools could
replace workers, but more commonly, as seen in the trucking example
above, they reduce their autonomy and their ability to stand out based on
skill.
Tensions in the organizational system
As AI learns and improves, it can change the location of power within an
organization.

In some cases, AI decentralizes decision-making and pushes power to the
edges of the organization. Traditionally, sales forecasting was the job of
analysts at headquarters, who produced quarterly reports based on historical
trends. Today, AI tools pull live customer data from internal software tools,
competitor websites, and even online customer reviews. With these insights
aggregated, frontline sales teams can be constantly empowered to make
faster, more informed decisions without waiting for top-down directives.
Decision-making moves closer to where the action is.
In other cases, AI centralizes power. Consider the impact of predictive
pricing tools on global retail chains. In the past, local store managers
adjusted prices based on their knowledge of regional demand. But today's
predictive pricing tools learn from patterns across the entire industry. They
can analyze local factors across hundreds of locations simultaneously. As a
result, pricing decisions increasingly shift to the center, where AI tools set
prices at scale. Power consolidates at headquarters, and local autonomy
goes down.
These shifts in decision-making power - whether toward the edges, back to
the center, across teams, or even within teams - create new tensions within
organizations. As AI gets deployed across an organization, it changes whose
judgment is still valued over the tool's intelligence. It also determines
whose goals get prioritized and whose role is diminished or elevated.
Tensions in the competitive ecosystem
Looking beyond workers and the organizations within which work is
organized, the most important tensions often arise in the competitive
ecosystem, as AI shifts the balance of power between different actors.
One of the clearest tensions arises between companies that utilize AI
capabilities and those that provide them. To understand this tension, let's
consider the case of Uber. In the early years following its launch, this
popular ride-hailing solution heavily relied on Google Maps for its mapping
capabilities, including routing and estimating arrival times. If Maps got the
route wrong, the user blamed Uber. Meanwhile, Google (and its parent
company, Alphabet) was learning from data generated by Uber and other

customers of its mapping capabilities. Alphabet eventually launched
competing ride-hailing services through its subsidiary Waymo, directly
competing with Uber. This pattern, where tool providers gain leverage and
move up the value chain, is now repeating in knowledge work. AI tools that
once supported accounting, consulting, or legal firms are becoming
sophisticated enough to bypass these professional services firms entirely,
offering services directly to end customers.
A less obvious competitive tension arises between businesses and their
customers. On the one hand, AI-enabled products can delight customers by
anticipating their needs and reducing friction in use. On a construction site,
an AI-enabled helmet could monitor safety and identify compliance risks.
At a grocery store, an intelligent shopping cart could conversationally guide
shoppers towards healthier options while scanning the items in their cart.
Producers who embed intelligence into products can gain strategic control
over the customer relationship. However, the same tools can also be used to
manipulate, overloading users with options or misinformation to steer
choices that benefit the producer, not the consumer. In such cases, AI shifts
from serving the consumer to serving the firm's agenda, turning the very
tools meant to improve experience into mechanisms of control.
AI adoption restructures not just individual firms but the entire competitive
landscape. On one side, it makes the powerful even stronger. Large
platforms, such as Amazon and YouTube, utilize AI to manage content
visibility, thereby further consolidating their control over video creators and
online merchants. But AI also helps small firms and even individuals punch
above their weight. A lone writer or video creator can now use AI to create,
edit, and publish more and better content, acting like their own media
company. These individuals can access scalable labor and expertise that was
previously only available to well-capitalized firms. They don't need to join
an organization to scale; they access advanced capabilities on demand. This
creates a new tension: between traditional capitalists, who built power by
organizing labor and capital, and a new class of AI-empowered individuals
who scale without either. As AI lowers the cost of execution, it blurs the
line between worker and owner, contractor and firm, and challenges long-

standing structures of economic power. AI may help the big get bigger, but
also lets the small act bigger than ever before.
These tensions, between workers and tools, between centralization and
decentralization within firms, and between competing players across
ecosystems, are the defining features of AI's impact. AI, as a technology of
coordination, reshuffles power across the system of work and changes who
loses and who wins.
Resolving the tensions
AI is similar to the container or the barcode, in that it changes the logic of
incumbent systems and rebundles or restructures them on new logic.
However, it's also very different in that it's not static or passive; it
constantly learns from the system. The more it is used, the more it learns.
And the more it learns, the more it transforms the system it serves.
A simple way to understand the difference between AI and traditional
coordination mechanisms, such as barcodes or containers, is to think of the
distinction between conventional paper maps and GPS-based navigation
applications like Google Maps. A paper map is a fixed representation: the
map presents information that the user interprets and acts upon. Whether or
not the user follows its suggestions, the map remains unchanged. Barcodes,
similarly, record fixed information about a product. Obvious as this sounds,
barcodes don't learn or adjust the information based on how the product is
being used or handled.
In contrast to paper maps, Google Maps' navigation capability constantly
learns from how people use it. Every time someone drives somewhere, it
collects data, such as the route taken and the time it takes to get there. It
uses this information to change what it shows to the next person. Over time,
the more people use it, the more the tool adjusts to their driving habits. It
learns and updates itself continuously. As users navigate, their actions
generate data on routes and delays. The navigation algorithm uses this data
to update suggested routes and estimate arrival times accordingly. If you

think of all the cars on the road using Google Maps, the navigation
algorithm is constantly learning from traffic patterns and, in turn,
continually influencing those patterns.
Fig. 3.7: How learning loops work
This learning loop makes AI fundamentally different. While all
coordination mechanisms leverage the five factors of coordination
discussed in this chapter, AI-based coordination additionally benefits from
the ability to learn continuously at every level. The mapping example
illustrates how paper maps operate with a static representation, whereas
GPS-based navigation relies on a representation that is constantly learning
and changing. Alongside the constantly evolving representation, AI also
constantly improves decision-making power through similar learning loops,

and by tightly coupling decisions with downstream actions, execution
power improves through learning as well.
The effects of AI, then, manifest at three different levels:
The first-order effects of automation,
The cascading effects of coordination, and
The accelerating effects of learning, where AI shapes the system's
behavior and the system's changing behavior further trains AI.
Conclusion
This book doesn't try to predict the evolution of AI or promise a roadmap of
what changes when. Predicting exactly what will change when is ultimately
futile - a fool's game - by the time you read this, the landscape will have
shifted from today as I write this. Instead, the goal of this book is to provide
a framework for thinking about those changes - a framework that remains
valid even as the technology continues to evolve. These principles provide a
mental model that can be applied to new scenarios, regardless of how
technology evolves. Through these first three chapters, we've set the basis
for such a framework.
Much of our current thinking is dominated by task-centric framing, or a
simplistic "workers versus tools" view. However, we overlook the
numerous other tensions that AI introduces when considering tasks alone.
Policymakers want to protect jobs. Tech firms want to move up the value
chain. Companies aim to reduce costs and increase profits. Different
concerns, conflicting motivations. Focusing solely on labor policy
overlooks how profits will be distributed. Chasing profits alone risks cutting
costs while compromising customer value. And prioritizing customer
delight can come at the expense of worker welfare. By expanding our view
across the entire system, we gain a better understanding of the competitive
tensions ahead. This view reframes workers' roles through the lens of
consumer value, offering more nuanced responses than those achieved
through simply focusing on labor policy or corporate profits. To address the

dilemmas that AI presents, we must consider the entire system and use that
perspective to craft solutions that balance conflicting interests.
OceanofPDF.com


OceanofPDF.com

SECTION 2 - WORK AND ORGANIZATIONS
OCEANOFPDF.COM


OceanofPDF.com


OceanofPDF.com

"W
4
AI UNBUNDLES THE JOB
WHY THE FUTURE OF WORK TAKES A LOT MORE THAN JUST STAYING
SKILLED
ill AI take my job?"
It's the question everyone asks, both instinctive and urgent, but almost
always framed as a binary. Does it replace me, or does it make me better?
It's a comforting frame, not because the answers are reassuring, but because
the question feels clear. Simple questions invite simple answers. And simple
answers, even when wrong, offer a false sense of security as they seem
more straightforward to act on.
The problem with this question lies in the unstated assumptions behind it:
that jobs are stable units, that tasks are the core building blocks of those
jobs, and that if we hold onto the right tasks and back them up with the right
skills, the job survives. In this chapter, we challenge all three assumptions.
This isn't the first time, though, that we've sacrificed nuance for simplicity.
Whenever transformative technologies emerge, we instinctively try to make
sense of them by reducing complexity to a single, familiar dimension. This
way of thinking, however, is dangerously incomplete, because jobs don't
exist in isolation. Every job plays a specific role within a larger
organizational system, which itself is structured to help a firm effectively
compete and establish advantage. AI changes not only the tasks within a job
but also the way work is organized and how companies compete. These

changes across all three levels of the tasks, the organizational system, and
the competitive ecosystem, constantly alter the nature of the job and the
value associated with it.
Fig. 4.1:  AI transforms jobs by transforming the system of work
In this chapter, we deconstruct the binary question of whether AI will take
your job or help you get better at it. We trace the origins of this kind of
thinking, explore how it narrows our perspective, and explain why quick
fixes, such as reskilling, remain ineffective. To understand what's changing,
we need to stop looking at skills alone and start understanding the systems
in which those skills hold value.
From looms to LLMs - from skills to the system
In the late 1500s, English clergyman William Lee invented a mechanical
knitting machine that significantly increased textile productivity. Queen

Elizabeth I, however, refused to grant a patent to the invention, fearing it
would displace manual knitters. Long before formal economic theories
emerged, the tension between technology and labor was already evident.
With the Industrial Revolution, this tension came to the forefront. In
Britain's textile towns, skilled artisans, soon to be labeled Luddites,
smashed the new mechanized looms that threatened their livelihoods.
Though often portrayed as anti-technology, they were really protesting the
way it was being deployed to undermine their economic role. The machines
devalued the intricate skills that had long anchored stable, respected jobs.
Around this time, the economist David Ricardo, initially an advocate of
machinery, revised his view to propose that technological progress could be
economically beneficial in aggregate while harming specific classes of
workers. The pie could grow bigger, yes, but it wouldn't be evenly sliced.
By the time the telephone replaced the telegraph, the idea that technology
would wipe out entire jobs had become strikingly real. Telegraphy, once a
respected and highly skilled profession, vanished almost overnight from
civilian life. With the rise of voice calls, there was no longer a need for
people trained to send and decode Morse code. An entire job category
vanished due to a technological shift.
Despite recurring stories of job loss, most economists remained optimistic
throughout the 20th century. Employment and output continued to rise, and
three forces helped explain why. First, new tools made workers more
productive. Second, technology helped grow the economy, which increased
demand for goods and services, and hence for labor. Third, even as old
industries declined, technology gave rise to new ones, providing workers
with new opportunities. These effects explained why fears of mass
unemployment rarely materialized, even as technology continued to
advance.
As technology advanced, a new idea took hold: the more education you
had, the more you were likely to benefit. This became known as the skill-
biased view of change. It argued that technology boosted the productivity
and value of highly educated workers more than others, creating an ever-
widening gap between skilled and unskilled labor. As this theory gained

traction, reskilling was established as the primary safeguard against job
loss: if workers reskill fast enough, they remain valuable. This view was
popular with policymakers. It offered a simple solution to a contentious
issue. Some jobs would disappear, and those workers would need to be
reskilled to transition into new ones. As this idea gained traction among
policymakers, it further reinforced the belief that technology replaces the
entire job, not just parts of it.
But by the late 1990s, labor markets were changing in ways the skill-biased
model could not fully explain. Employment was rising at both ends of the
wage distribution, among low-paid service roles and high-paid professional
work. However, middle-income roles, such as administrative assistants and
clerks, were losing out. This didn't align with the idea that education alone
determines job security. Instead, it pointed to something else: the kinds of
tasks people did mattered more than just their level of education.
This shift led to the development of the task-based framing of jobs, most
notably in the work of economists David Autor, Frank Levy, and Richard
Murnane. The task-based framing suggests that jobs are bundles of tasks,
some of which are more susceptible to automation than others. The key
determinant of automation risk wasn't the job title or education level, but
whether the tasks performed were routine or non-routine. Routine tasks,
whether manual or cognitive, could be codified and automated. Non-routine
tasks involved judgment, interpersonal interaction, or tacit knowledge, all
of which were more resistant to automation. This framework proved
immediately helpful. It explained why computerization didn't eliminate all
clerical jobs, but rather those that were based on routine processes. It
clarified why employment for janitors and caregivers rose even as
manufacturing employment fell. It suggested a path forward: augmenting
the human in the loop.
This framing shifted the unit of analysis from the job to the task. It garnered
support for the idea of task-based complementarity, the notion that when
humans and machines collaborate, each handling the tasks at which they
excel, the combined performance often exceeds what either could achieve
alone. This task-based view also demonstrated that once routine tasks are
automated, humans could shift focus toward activities that require

contextual judgment and tacit knowledge. The introduction of radar in
aviation demonstrates how air traffic controllers transitioned from manually
tracking aircraft to concentrating on higher-value tasks, such as handling
exceptions and rerouting flights during weather disruptions. As radar took
over routine tracking, their original job was unbundled, removing low-value
tasks and rebundling the role around higher-value responsibilities.
This shift in thinking changed the conversation about the future of work.
Instead of fearing displacement, the new message was one of reimagining
your job, or rebundling a new set of tasks. Workers had to adapt by teaming
up with technology, not avoiding it. Policymakers promoted lifelong
learning, and schools were instructed to prioritize creativity, problem-
solving, and communication skills, deemed less susceptible to automation.
As task-based thinking gained traction, its limitations began to show,
particularly with the rise of AI. The idea that machines would only take
over repetitive tasks proved to be, at bes,t a comforting illusion. With the
improvement of AI capabilities, tasks involving tacit knowledge, once
considered safe, are no longer off-limits. AI tools, for instance, were meant
to assist junior lawyers with document review and other 'grunt work'.
Instead, they progressively moved beyond assistance and started
outperforming humans at specific tasks. The kind of work junior associates
used to cut their teeth on is now increasingly done by machines, prompting
law firms to question if they still need large entry-level teams.
The rise of AI challenges the reassuring idea of augmentation, the belief
that humans can simply reimagine their roles to work alongside machines.
As AI continues to learn and improve, it begins to take over tasks that were
once considered safe. The issue isn't the worker's lack of skill. It's that, in
many cases, keeping a human in the loop becomes too expensive when AI
can do the job faster and cheaper. And if only a few tasks are left for
humans, or if full automation is more efficient, there may not be enough
meaningful human work left to sustain a new role at all, once AI unbundles
the older one.
But there's a second, far more important reason why task-based framing
breaks down with AI. Earlier waves of automation worked to replace one

cog in a larger 'machine.' The task would change, but the system of work -
the larger 'machine' around it - stayed the same. AI, as a technology of
coordination, changes the entire 'machine'. It transforms both the individual
tasks and how these tasks are coordinated in workflows and organizations.
As a result, the survival of individual tasks offers little in the way of
absolute security. The tasks may persist, but the logic that once bundled
them into jobs and provided the economic justification for a person to
perform them may vanish entirely. A lawyer, a translator, or even a
physician may still have vital skills. However, if the architecture of work
shifts around them, the profession is likely to be impacted.
To understand AI's true impact, we need to move our frame beyond the
microscopic view of tasks and zoom out to the system that gives those tasks
meaning.
The flawed logic of job survival
When people discuss the impact of AI, they often start with jobs. Jobs are
how we earn a living and how many of us express our identity and define
our ambitions. That makes job loss personal. So when a new technology
arrives, especially one as abstract and fast-moving as AI, we look for a
stable anchor. Job titles serve as focal points that make this complexity feel
manageable.
However, the focus on jobs, while understandable, tends to oversimplify
what is truly changing. Using the task-based framing that has dominated
much of economic thinking on jobs, it is tempting to think that if tasks
associated with a job survive, so does the job, and if the job continues, so
does the income associated with it. However, that logic no longer holds.
First, a task can continue to exist even after the job that was previously
responsible for performing that task disappears. We've noted earlier how
the word processor made typists redundant. The arrival of word processors
didn't eliminate the task of typing; people, instead, began typing more than
ever. But the role of the typist became redundant. That job wasn't just about

typing; it was set up to manage document editing, which was time-
consuming and expensive. Once word processors removed that constraint,
the need for a dedicated role to manage it vanished.
There are two additional reasons why this focus on task or job survival is
not sensible. First, even if the job still exists, workers may no longer be able
to differentiate themselves or earn as much from it. If people continue to
work at the job but lose the higher pay that once came with it, that's not a
desirable outcome. Second, as AI increasingly coordinates entire
workflows, it takes agency away from human workers. This migration of
agency, where workers no longer direct the system but are directed by it, is
evident in the earlier example of how the roles of Amazon warehouse
workers and Uber Freight truckers constantly change in service of the
system's goals.
To understand how AI changes work, it is no longer sufficient to examine
jobs in isolation or based on the tasks they involve. While this framing was
useful in earlier technological cycles, it doesn't account for the possibility
that valuable tasks may persist but lose their relevance within a restructured
system. Conversely, a low-value task may become high-value in the future
if the surrounding workflow changes.
This distinction matters.
Much of the value associated with a job is not derived from the task alone but also
from the system within which the task is executed.
The real issue isn't whether a job still exists. It's whether the work still
holds value, and whether the person doing it still has control or agency.
When people worry about jobs, they're really asking two things:
Will I still be paid well? And will I still have control over what I do and how
I grow?
These questions are particularly important because AI changes both how
value is created and who retains power within the system of work.

Value determines who gets paid, how much they get paid, and for what kind
of output. Power determines who can make decisions and who is obligated
to act according to those decisions. If a task loses value, it loses income. If
it loses power, it loses agency. Either outcome makes the job fundamentally
different, even if the job title stays the same. By shifting our focus from job
titles to value and agency, we uncover how technology redistributes power
and rewards as it transforms the way work is done.
Why some tasks matter more than others
To understand why AI impacts some tasks but not others, we need to
understand what makes tasks valuable in the first place. A task can have
great meaning or require significant skill, but still be economically
worthless. Flawless mental arithmetic is impressive, but calculators have
made it economically irrelevant outside game shows. Conversely, a task
might seem trivial but carry immense leverage in the right system.
Approving a transaction in a risk dashboard might seem clerical, but it
determines the release of funds or credit. To understand how AI impacts our
jobs, we need to distinguish between intrinsic value, economic value, and
contextual value - the three forms of value associated with every task we
perform.
The intrinsic value of a task refers to the value it creates. It is often
subjective and rooted in meaning. Economic value, on the other hand, refers
to how much someone is willing to pay for the task to be performed.
Oxygen is vital to life. Its intrinsic value is infinite. However, because it's
abundant, it has little to no economic value in most cases. Economic value
requires scarcity of supply. Only when oxygen is scarce - underwater, at
high altitude, or in medical emergencies - does it hold economic value.
Economic value is a measure of what gets traded. Scarcity is central to
understanding the origin of economic value. Something has economic value
when it is both desired and scarce. Hence, it also requires relevance to
demand. A soldier at war carries a locket with a photo of his family. To him,
that locket is priceless. It reminds him why he's fighting. It has infinite

intrinsic value to him. But on the open market, the locket might be worth
almost nothing, just a piece of metal. If he lost it, no amount of money
might substitute its value to him, but to others, its economic value is low.
In our jobs, we often perform tasks that feel meaningful, like word-smithing
a thoughtful email, or refining a design until we feel it is just right. These
tasks carry high intrinsic value. But many of them may not have economic
value. On the other hand, issuing a building occupancy certificate is a
straightforward task. Still, because only licensed officials can perform it,
and projects cannot proceed without it, it carries significant economic value
despite its relatively low intrinsic complexity.
The third dimension of value, contextual value, refers to the value a task
holds within a specific system of work. A task may have high intrinsic value
but still low contextual value if the surrounding system doesn't need it or
has other ways to achieve the same outcome. Contextual value is not a
measure of how difficult the task is or how much it pays. It is more a
measure of how pivotal it is to enabling outcomes or influencing system
performance.
That's why some of the most meaningful work can go unpaid while some of
the most mundane tasks get rewarded. When AI changes work, it's not
enough for our work to feel meaningful. It must also remain scarce, relevant
to the new system, or ideally, both. Understanding AI's impact on the
economic value and contextual value of a task is the first step in
determining whether it will still matter and whether you will still be
compensated for it.
Some tasks may have very low intrinsic value and still command high
economic and contextual value. For instance, a notary service for real estate
closings is a low-skill task that involves witnessing signatures and affixing
a stamp to documents. Yet, it involves high contextual value as it's a legal
requirement for closing the deal, and it also commands high economic
value as these providers sit at a critical legal choke point. Similarly, a night
shift security guard at a high-security facility may perform passive
monitoring tasks with low intrinsic value. However, the high contextual

value conferred by the importance of what they are guarding also helps
them command high economic value.
This simple framework reveals some surprising effects. Tasks that look
similar on the surface often carry different kinds of value. Take image
labeling for machine learning. It's a simple task, often performed by low-
paid workers with little training, so its intrinsic value is low. However, it
plays a crucial role in training AI models, making its contextual value high.
A single mistake can propagate errors through the system. Despite high
contextual value, its economic value is low because the labor required to
perform it is commoditized and easily outsourced at scale. On the other
hand, consider the work involved in creating investor pitch decks for startup
fundraising. It requires considerable skill in framing and storytelling.
Alongside high intrinsic value, it also commands high contextual value as it
determines eventual access to capital. Finally, the best pitch-makers are in
high demand, making this a task of high economic value.
This framework helps us understand the case of typists when word
processors came in. The task of typing retained its intrinsic value, but its
contextual value collapsed in a system where edits and revisions were no
longer expensive. With access to easy editing, less-trained workers -
practically anyone - could now perform the task of typing, and the
economic value associated with the task collapsed as well. As a result, the
specialized role of the typist lost its unique position in the workflow.
Understanding the distinction between these three sources of value also
helps us understand issues with more nuance. Human translators still
perform the same core task, converting one language into another. It is a
task with high skill. Despite its intrinsic value, the economic value of
human translators has declined as AI tools now perform translations quite
well, driving down the fees human translators can charge. However, in
international political negotiations that require careful management of tone,
intent, and cultural nuance, and where misunderstanding can be very costly,
the contextual value of a human translator rises sharply. In these moments,
the translator becomes a trusted bridge between parties. So, even though the
task looks the same, its contextual value increases, and so does the
economic value associated with it.

A task's visibility, complexity, or even prestige are not reliable indicators of
its future value. What matters is how it scores across the dimensions of
economic value and contextual value, and, more importantly, how those
scores change as AI continues to improve.
AI affects these two types of value associated with a task in different ways.
When used for automation, AI reduces the economic value of tasks by
performing those tasks more efficiently and at a lower cost. The scarcity
that once made specific skills valuable, because only a few people had
mastered them, disappears. As a result, the task's economic value collapses.
But AI is also a tool for coordination. It alters how tasks interconnect within
larger systems, which can alter the contextual value of a task. Some tasks
become more central; others lose importance, not because the task itself
changed, but because the system around it did.
Economic value - Why 'good enough' takes the
expert's job
Economic value, unlike intrinsic or contextual value, is a transactional
concept. It determines how much someone is willing to pay for a task to be
performed. In markets, price is a function of scarcity. When AI eliminates
the scarcity associated with performing a task, its economic value declines,
even if the task still requires intelligence or craftsmanship. This is one of
the core ways in which AI undermines the economic foundations of
knowledge work.
Organizations often paid a skill premium, reflecting the underlying
economic value, not just for the quality of the output, but also for the
scarcity of people who could produce it. Analysts who could distill reports,
lawyers who could draft contracts, and consultants who could synthesize
insights all commanded high pay, not necessarily because each output had
high intrinsic value, but because only a few could produce them reliably.
That premium rested on economic scarcity. With an AI model trained to
perform that task, that scarcity is no longer a concern, as the task can now

be performed at near-zero marginal cost. The intrinsic value of these tasks
remains the same, but the ability to charge for them decreases. A task that
would have taken hours of effort from a trained professional is now a well-
crafted prompt away. What was once scarce is now abundant and has lost
economic value.
In fact, in many instances, human-generated outputs still carry greater
intrinsic value than those generated by AI. They may be more elegant and
nuanced, and even more insightful. But markets don't always reward
elegance; they reward sufficiency at scale. If the machine-generated answer
is 'good enough,' it wins economically. The collapse of economic value in
knowledge work is less about quality and more about substitutability. As a
result, the gap between the top-tier expert and the average worker shrinks.
When working with the same tools, their outputs, in many instances, may
be substitutable, even if the top-tier expert brings greater nuance. If that
nuance isn't valued, it won't command a skill premium, reflecting a loss of
economic value.
When the economic value of a task goes down, it loses its ability to charge a
skill premium - the premium it would have charged on account of the skill's
scarcity. We like to tell ourselves that the premium associated with our
skills stems from their intrinsic value, and that we earn more because what
we do requires greater effort or involves more training and learning;
however, that premium really stems from economic value in the market.
What drives our engagement with our careers is the ability to own scarce
and specialized skills that grant us a skill premium. AI might not take your
job, but it can take away what makes your skills special, or at least reduce
the gap between you and someone else who's less skilled but has access to
AI tools. When that happens, your ability to charge more for your work -
the skill premium - shrinks.
There are two primary sources of the skill premium: the premium
associated with the scarcity of the skill itself and the ability to defend and
grow that premium through continuous learning and improvement.
Previous generations of tools have also had a direct impact on the skill
premium by changing the scarcity associated with the skill. Before the rise

of chainsaws, logging was a highly skilled job that required years of
practiced technique. The chainsaw helped low-skill loggers dramatically
increase their productivity, but it didn't benefit high-skilled loggers quite as
much. Over time, this led to a decline in the skill premium, as more
workers, armed with chainsaws, entered the field. When technology levels
the playing field, it often reduces the skill premium by making workers
more interchangeable with one another. The intrinsic value of logging
remained unchanged, but its economic value had collapsed.
GPS-based navigation had the same effect on taxi drivers as the chainsaw
did on loggers. Any amateur could compete with the city navigation skills
of a seasoned cabbie. When apps like Uber created a market for GPS-aided
drivers, more drivers entered the market, further reducing the scarcity of
supply and erasing the skill premium that taxi drivers once earned.
Much like navigation apps offer assistance on skills that once needed years
of experience, today's AI tools perform tasks that previously required
highly skilled workers. Recent studies involving knowledge workers,
including consultants, customer service agents, law students, and writers,
have reached similar conclusions. For instance, a Harvard Business School
study on AI augmentation at a top consulting firm revealed that the
performance gap between low-performers and high-performers dropped
from over 20% when not using AI to just 4% when augmented with AI,
showing how AI narrows the difference between average and exceptional
workers. These studies on the effects of a technology that's constantly
changing come with obvious caveats - chief among them is the fact that
results based on today's AI may look very different when the same tests are
run with tomorrow's more advanced models. Still, such studies increasingly
demonstrate that AI augmentation makes high-skilled knowledge workers
less scarce, as it helps low-skilled workers increasingly substitute for high-
skilled workers. The task doesn't get automated. Workers continue to
perform it, but its skill premium collapses.

Fig. 4.2: The skill absorption flywheel
Unlike earlier technologies, however, AI changes the economic value of
tasks and the skill premium that accompanies them in another important
way: it learns. AI can learn directly from the workers who use it. Every time
a worker uses an AI tool, they're also training it. Over time, more of the
skill required to perform the task is absorbed into the tool itself. This
gradually unbundles more of the task performance from the worker and
moves it into the tool. This unbundling of skill from the worker and its
rebundling into the tool also shifts value away from the worker and toward
the tool provider. Take customer support, for example. Experienced agents
know how to handle difficult conversations, read a customer's tone, and
choose the proper response. As AI tools are trained on these interactions,
they learn what works best in each situation. Eventually, the AI tool can
suggest more effective replies or reach a point where it effectively handles
the entire conversation. With these abilities available in the tool, less

experienced agents can perform like pros. However, even as their
performance improves, these workers fail to capture the skill premium
associated with the task. The economic value associated with the task
moves away from the worker and toward the tool provider.
Earlier technologies, like chainsaws for logging or GPS for navigation, had
a one-time leveling effect. They enabled low-skill workers to perform at the
same level as high-skill ones, but then the labor market stabilized. AI, on
the other hand, continually learns and improves, becoming progressively
better at handling existing tasks with greater accuracy and also expanding
its capabilities to take on additional tasks. Every time it's used, it gathers
feedback and improves its accuracy.
And because these tools learn from everyone who uses them, the more
widely they are used, the better they get, and the more rapidly they displace
the skill premium once attached to human expertise. In this way, economic
value doesn't just decline once; it keeps going down.
So far, a common argument against the idea that workers are losing
economic value is that as technology makes human labor cheaper,
businesses find new ways to utilize that labor, keeping people economically
employed by assigning them new kinds of work. This logic worked with
earlier technological revolutions because humans retained a learning
advantage, which enabled them to learn new skills for the new tasks that
emerged. However, this logic has its limitations when applied to AI.
Machines now have a learning advantage that, in some cases, far exceeds
the learning advantages of humans. Hence, even if new tasks emerge, there
is a growing possibility that many of them will be performed with greater
effectiveness by ever-learning AI tools than by the workers who are
displaced. Eventually, there may not be enough new tasks left where human
effort still matters.
This doesn't, by any account, imply that humans will be left with no work
to do. That kind of black-and-white thinking fuels much of the confusion in
today's debates about AI and jobs. It does, however, clarify that defining the
jobs of the future based on tasks AI can't yet do is fundamentally flawed.
Instead, as we'll explore in the next chapter, the clues to understanding the

jobs of the future may lie elsewhere, not in the tasks that make up the job,
but in the design of the new system that emerges.
This collapse of economic value doesn't mean the task is useless. It may
often mean that the system itself has changed. And as we'll now explore,
the value of a task increasingly depends not just on how scarce it is, but on
where it sits in the larger system of work.
Contextual value - When the expert ceases to
matter
Contextual value is the value of a task based on the context in which it is
performed. The same task may have vastly different value in a different
context. For instance, a student taking notes in a classroom is doing it for
personal learning. However, a chief of staff taking notes in a strategy
meeting captures key decisions that shape follow-up and accountability
across the organization. The two tasks may look similar, but their contextual
value is vastly different.
Contextual value refers to the value of a task within a specific workflow,
role, or organization, as well as the level of leverage it provides. What
creates leverage in one context may not in another. Remove a task from its
context, and it may lose all value. When AI reconfigures how tasks are
organized within broader workflows, tasks that once played a pivotal role
may become less relevant. The result is not always job elimination, but a
loss of relevance. The task remains, but it loses its importance within the
system of work.
Conversely, tasks that previously held little value may gain in contextual
value when the workflow changes. Consider how the role of cashiers has
evolved in response to the rise of self-checkout kiosks and mobile payment
systems. While their role previously bundled bagging and payment
handling, those tasks are now increasingly unbundled from the human role.
It has lost economic value and is more easily performed by machines. But
new tasks emerge with higher contextual value - tasks that would have had

no value in previous workflows but become valuable as the workflow
changes. With self-checkout kiosks, new tasks, such as troubleshooting
checkout errors or, more importantly, upselling items at self-checkout,
emerge. These tasks have greater contextual value in the new workflow and,
when combined with other tasks, deliver greater value to the cashier's role,
even as the original tasks of payments and bagging are eliminated.
The true risk of AI is not just automation and job loss, but being anchored to a task
whose value has moved elsewhere.
When AI changes not just individual tasks but larger workflows and
organizational forms, your relevance changes based on how your work
aligns with what is valued in the new system. When the standardized
shipping container made cargo easier to handle, it broke the old link
between shipping and local port labor. The dockworker lost relevance in the
new system. New roles, like intermodal logistics planners, emerged, which
held higher contextual value in the new system.
Systems, not skills, determine your fate
AI, as a technology of automation, collapses economic value by making the
execution of individual tasks cheaper and faster. And as a technology of
coordination, it reshuffles contextual value by reorganizing entire
workflows and organizations and reassigning roles within them. Together,
these forces constantly change the value of a task. However, the unit of
analysis is no longer the task but the system in which it resides.
As we've seen, AI's ability to continually learn over time alters the
economic value of many tasks. However, what is less apparent is how it can
also alter the contextual value of those same tasks. In healthcare, for
example, AI tools are helping less experienced doctors, as well as nurses
and caregivers, perform tasks that previously required years of training.
This lowers the economic value of expert knowledge because the
performance of that task is no longer scarce. If more people can do it with

AI, it becomes cheaper and easier to access, and experts can't charge the
same premium as before.
But that's only half the story. The contextual value of the task also changes.
Some tasks that were once central to a doctor's job, such as diagnosing a
condition or recommending treatment, can now be handled by other roles
within the care team. These tasks shift away from the doctor, not because
they've been eliminated, but because they've been redistributed across a
new AI-assisted workflow. This changes not just the roles but the entire
system. For example, instead of paying per doctor consultation, a clinic
might offer a subscription-style service. Patients get ongoing care from AI-
augmented caregivers and only see a doctor when truly necessary. In this
model, the doctor is no longer the main point of contact. The doctor's skills
haven't changed, but their place in the system has. The economic value of
their work declines, and the contextual value of their role goes down,
because the system is no longer built around them. Meanwhile, the
contextual value shifts to the caregiver, who owns the relationship, and,
more specifically, to the membership provider, who coordinates the flow of
care and maintains the ongoing patient relationship.
In short, AI not only lowers the economic value of specific skills by
reducing scarcity, but it also lowers the contextual value of specific roles by
changing how the system is structured around them. As AI capabilities
improve, our jobs and systems of work will constantly unbundle and
rebundle in ways we haven't seen before. Some roles may disappear not
just because AI changes their economic value, but also because it alters
their contextual value. This means jobs change not just because people lack
the right skills, but because the structure of work is changing. This is not a
skill problem, and reskilling alone won't fix it. Our greatest challenge is not
automation replacing skills, but a combination of automation and
coordination continuously changing job architecture.
Do you work above or below the algorithm?

The impact of AI on how work is coordinated becomes clearer when we
examine algorithmically managed markets. These markets centralize
market-making and job assignment using algorithmic coordination.
Ride-hailing platforms, such as Uber, operate as algorithmic marketplaces
that connect GPS-equipped drivers with riders. They manage pricing
centrally through algorithms that adjust fares based on real-time supply and
demand. These systems determine the market-clearing price, the lowest
price at which a ride will still take place, thereby compressing the economic
value of the task to its minimum viable level. Curiously, drivers also lose
contextual value. When cabs are hailed off the road, a cabbie may benefit
from some contextual value by being at the right place at the right time and
may charge a premium for that in less-regulated markets. However, with
algorithmic market-making, that is no longer the case.
Beyond pricing, algorithmic job assignment further drives down economic
value for drivers. They must either accept rides at the platform's rates or
forgo access to demand entirely. By controlling demand on one side and job
assignment on the other, these platforms drive down drivers' negotiating
power. They're now required to accept jobs without knowing the
destination and are subject to metrics like acceptance and cancellation rates.
Drivers lose value when they are unable to set their own prices. However,
they also lose power and agency, as they are no longer free to choose which
jobs to accept and which ones to reject.
Both ride-hailing and food delivery markets demonstrate that once jobs
become entirely interchangeable, with no distinction left between workers,
the workers themselves are entirely substitutable. Drivers and delivery
workers are assigned based solely on proximity to the location, with no
regard for individual skill or experience.
Algorithmic market-making and job discovery are not inherently harmful.
In domains where workers are differentiated, such as hiring a specialized
chef, they can improve matching efficiency and unlock new forms of value
for both workers and customers.
The problem arises when a particular job loses its differentiation and ability
to capture a skill premium. Centralized algorithms that control both access

to demand and assignment of jobs squeeze out any last remaining source of
premium that workers could have hoped to extract from their skills. These
algorithms continually drive down economic value as they manage the
entire market. And they drive down contextual value as the task is reduced
to its bare minimum, making the worker entirely substitutable.
Given the increasing role of algorithmic management in shaping work, the
impact of AI on jobs can't be fully understood without examining the
relationship between workers and the algorithms that govern these systems.
In any algorithmically managed system of work, workers occupy one of
two positions: above-the-algorithm or below-the-algorithm. Above-the-
algorithm workers leverage the power of algorithms to gain outsized returns
on their efforts. This includes engineers, designers, and data scientists who
design and operate algorithmic coordination systems. This also includes any
worker who can exploit the coordination logic to gain higher returns on
their efforts. In contrast, below-the-algorithm workers are those whose tasks
and productivity are primarily managed by algorithms. Rather than using
algorithms to enhance their own output, these workers are allocated to jobs
and managed and guided through algorithmic systems. Their work typically
leaves little room for personal differentiation.
The more standardized, routine, and easily replicable a task is, the more
amenable it is to algorithmic management. Algorithms not only manage the
workers' productive output but also govern their access to opportunities,
wage levels, and determine the conditions of their overall work
environment.
The difference between an above-the-algorithm worker and a below-the-
algorithm worker is best demonstrated in the context of ride-sharing: the
Uber data scientist designs the algorithms that optimize routes and match
riders with drivers, while the Uber driver works within those rules,
performing tasks that are increasingly narrowed and standardized.
Below-the-algorithm workers don't operate for their own mastery or
advancement. Their tasks are parceled out and managed in service of the
overall system of work. We noted this earlier with the example of Amazon,
whose warehouse workers and the robots they are 'augmented' with, are

constantly reorganized around the demands of the fulfillment system.
Similarly, even though Uber drivers and delivery workers are 'augmented'
with navigation apps, the premium for faster deliveries is captured almost
entirely by the delivery companies managing these workers in the form of
brand value and customer retention.
In an algorithmically managed system, the higher value of technological
augmentation is captured almost entirely by the owners and designers of the
algorithm rather than by the workers operating below the algorithm. The
automation vs augmentation distinction ceases to make sense when
augmentation preserves the jobs, or even creates new jobs, but the worker
doesn't adequately capture the resultant value.
This distinction between above-the-algorithm and below-the-algorithm
workers is especially important in the context of the ever-widening gap
between capital and labor in today's economy.
Those operating above the algorithm are more closely aligned with capital.
A significant portion of the Uber data scientist's compensation includes
company stock, thereby tying their earnings directly to the company's value.
Their rewards are derived not only from their labor but also from the
growth and success of the systems they design and operate, achieved
through close alignment with capital. The Uber driver, on the other hand, is
part of a labor pool whose rates are constantly driven down.
This shifts the traditional boundary between labor and capital. In the past,
workers were viewed as part of the labor force, producing value through
their efforts, while capitalists profited from owning assets. Today, the divide
isn't just between investors and employees; it increasingly depends on
whether one operates above or below the algorithm.
The distinction between operating above or below the algorithm may seem
similar to the old divide between white-collar and blue-collar jobs or
knowledge work and physical labor. Yet, as we noted earlier in this chapter,
AI's ability to constantly learn and unbundle expertise from knowledge
workers, thereby absorbing it into tools, poses similar threats to knowledge
work.

As we discussed earlier, AI tools can make knowledge workers more
interchangeable. When everyone uses the same tools and performs tasks at a
similar level, individual contributions begin to blur. This paves the way for
algorithmic control to step in, deciding how work is assigned, evaluated, or
priced. We observed this with delivery drivers: once GPS provided
everyone with the same navigation edge, the role became standardized and
substitutable. Likewise, knowledge workers who initially work above the
algorithm can eventually be pushed into roles below the algorithm as their
contributions alongside AI tools become increasingly substitutable.
Fashion designers, for instance, do high-value knowledge work. They make
creative calls and shape seasonal collections based on taste and cultural
insight. Yet, as we noted earlier, a system like Shein can push fashion
designers below the algorithm. The algorithm now utilizes social media
signals and rapidly prototypes micro-trends to rank designs, rendering
human designers mere cogs in a reactive production system. Their unique
creative judgment is not valued by the system, which prompts them to
execute designs around templates.
Skilled copywriters, similarly, once distinguished themselves with voice
and style. However, AI tools can generate content at scale while
maintaining a consistent voice and style. Much of the copywriting function
is rebundled into tools, and human effort is required only to prompt or
lightly polish the output. Such effort itself further shrinks over time, as
already evident in the decline of one of the hottest new jobs in the post-
ChatGPT world - the role of the prompt engineer. Eventually, content farms
start managing such jobs using algorithmic assignment.
As AI capabilities advance, more types of knowledge work are at risk of
becoming commoditized. As that happens, the workers performing these
tasks become more interchangeable, and algorithms increasingly manage
their roles. In such systems, the "humans in the loop" may no longer guide
the AI; more often, they are guided by it.

Operation Mincemeat and system interventions
Even in the most controlled systems, humans seek weak points of
intervention where the system can be compromised and through which
human agency can be restored. Sometimes, they succeed by bending the
system's logic for a moment.
In 1943, British intelligence faced a daunting challenge: how to defend
Sicily from an expected German counterattack. But instead of simply
sending more troops, they took a different approach. They studied the
wartime information system, through which the German military gathered
intelligence, confirmed its beliefs, and adjusted its strategy. The goal wasn't
to confront the enemy's strength head-on but to intervene in the enemy's
system and use the knowledge of that system to their own advantage.
They found their opening. British agents planted a corpse off the coast of
Spain, carrying fake invasion plans pointing to Greece. When German
agents discovered the body and the documents, they trusted the information,
and their existing intel didn't contradict it. Believing the deception, the
Germans diverted defenses away from Sicily, allowing the Allies to land
with remarkably little resistance. The British had prevailed by intervening
in the German system and using it to their own advantage.
Dubbed Operation Mincemeat, this ploy worked because the British
understood how the German intelligence system made decisions. They
identified a weak spot in the system and exploited it to plant a false signal, a
subtle move with a significant impact.
Today's algorithmically coordinated work systems are vulnerable in much
the same way. And below-the-algorithm workers looking to restore agency
often look for creative ways to intervene in the system.
Uber drivers have, at various points, discovered that surge pricing
algorithms respond to temporary imbalances between supply and demand.
By coordinating brief logoffs in targeted areas, drivers manufacture
artificial scarcity to trigger higher fares, applying the principles of
Operation Mincemeat to confuse the algorithm.

Call center agents who are tracked using sentiment analysis tools also use
similar tactics. They may often resort to overusing specific phrases that the
algorithm recognizes as positive, improving their performance evaluations
without materially changing service quality.
Opportunities like these, where workers can identify weaknesses in the
system and leverage them to their advantage, provide a means to regain
some control in the absence of traditional protections, such as those offered
through unions or formal negotiations. Workers have learned how to work
around the system's rules, and, in doing so, reassert a kind of collective
bargaining power by changing how the system itself behaves.
Intervening in the system's logic seems clever. But it's a constant race
against the system, which itself continuously identifies and learns from such
anomalies. You win as long as you stay one step ahead of a system that was
never designed to reward you. Gaming a system's blind spots might help in
the short term, but it's not a reliable way to rebuild value or agency. In fact,
it often pulls us further from our goals. What we need instead is a smarter
strategy that works with the system's logic rather than against it. Workers
who manage to realign themselves with the new system of work and its
rules and incentives often find that the system starts to work in their favor.
The real opportunity, then, is to design your role so that the system naturally
elevates you.
Will such an opportunity be available to everyone? Probably not. But we
must understand how to recognize it and how to build toward it. That's what
we look at in the next chapter.
Why we need a new lens with AI
The comforting assumption that as workers become more productive, their
wages would rise no longer holds. For most of the twentieth century, this
might have been the case. However, starting in the 1980s, productivity
continued its steady climb while real wages for most workers remained flat
or even declined. The economy grew, but the rewards were increasingly

captured at the top. It wasn't enough to grow the pie. How the pie was
sliced and distributed mattered just as much.
With AI, these issues take center stage as three distinct forces converge to
push us beyond task-centric framing toward a system-centric approach.
First, AI is not just a helpful assistant. If we don't rethink how we work,
'simply working with the tool' may eventually lead to a gradual loss of
value and power. Second, as algorithms are increasingly used to manage
and assign work, not just on gig platforms like Uber and TaskRabbit, but
also in knowledge work, the rules of work are no longer set by people.
Instead, how your work is valued and rewarded may be decided by an
algorithm that doesn't understand the full complexity of your job. It
measures you only on how well you perform narrow, specific tasks,
ignoring everything else that makes the work meaningful or difficult.
Finally, institutions such as unions or licensing bodies, which once
protected workers, are losing their power. They simply can't keep up with
the pace and complexity of algorithmic systems, leaving workers more
exposed to sudden changes and without the protections they once had.
That's why economic growth can exist alongside personal disempowerment.
This chapter may leave us on a somber note, but the goal isn't to deliver a
gloomy forecast about how AI will reshape jobs or steadily remove our
sense of agency. Instead, it's to offer a more precise diagnosis of what's
actually changing so we can respond more strategically. To find real
solutions, we must first understand the nature of the problem. That means
moving beyond the familiar framing of jobs and tasks. This chapter
introduced a more useful distinction between economic value and
contextual value. To navigate this shifting landscape, we must stop asking
only whether a certain task can be automated. Instead, we should ask
whether AI changes the economic value of the task even without replacing
the worker. We must constantly evaluate and understand changes in the
larger system of work to understand how we can move to positions of
higher leverage. And finally, we must stay aware of the learning loops
we're part of because the more AI learns from us, the more likely it is to
absorb what makes our work valuable in the first place.

Now that we have this lens, the next chapter turns to the question that
matters most: how do we act? How can we adapt alongside ever-improving
AI capabilities in a way that not only maintains our position but also
enhances our value, regains our agency, and shapes the system in our favor?
OceanofPDF.com


OceanofPDF.com


OceanofPDF.com

A
5
REBUNDLING THE JOB
WHY RESKILLING IS A LOSING GAME IN A SYSTEM THAT'S ALREADY
CHANGED
bottle of wine sells for $80 in stores. The restaurant charges $400.
It still sells, and people go back for more. The sommelier tells them a
story about the vineyard, about a sixth-generation family continuing a
tradition. Some of it might be true. It doesn't matter. The wine tastes better
now.
The diners think they're paying for wine. What they're actually buying is
the sommelier; his vibe, his wit, his ability to make them feel like
connoisseurs. There's something oddly anachronistic about the sommelier.
Their 'skill premium' presents a puzzle.
In an age when anyone with a smartphone can pull up tasting notes and
obscure vineyard histories, the idea of relying on a suited professional to
recommend a bottle seems almost quaint. Their role should have been
among the first casualties of the commoditization of information. If
information about wine is no longer scarce, what function remains for the
sommelier?
The sommelier isn't in the business of dishing information about wine.
They're in the curation business.

As access to information and knowledge becomes increasingly
commoditized in the age of AI, the question that arises most often is which
jobs are likely to disappear and how we can protect them. However, this
distracts us from the more important question: where does value move when
knowledge becomes abundant?
Sommeliers rose to command greater value in a world where the product
(wine) and the knowledge about it were getting commoditized. The
sommelier is not an exception. They are an early signal of how work gets
restructured and how we can still proactively redesign for relevance when
the traditional basis of our authority has been flattened.
What the sommeliers figured out, before the rest of us eventually do, is that
value is not in giving people more information. It's in giving them
confidence in a moment of uncertainty, making them feel like connoisseurs
even if this is the first sip they've ever had.
In the previous chapter, we traced how AI transforms jobs by changing the
economic and contextual value of the constituent tasks. But we stopped
short of answering the more hopeful question: what happens next? What
does the sommelier see that others don't? And how can that insight guide us
as we rethink our roles and the very architecture of work in a knowledge-
abundant economy?
Fortunately, the same framework that helped us understand the threat also
offers a map to navigate these changes. It tells us exactly where value used
to sit and, by extension, where it might be hiding now. If value no longer
lives in knowledge scarcity, where does it move? The answer lies in
understanding constraints. The sommelier, it turns out, isn't clinging to a
dying profession. He's living in the future. We just haven't caught up yet.
From tasks to constraints
We often think of jobs in terms of the tasks people perform, not least
because the roles we're familiar with - teacher, designer, plumber - are
themselves descriptive of the tasks they are associated with.

A task-based view of work often leads us to ask which tasks will lose value
once AI can perform them more efficiently and cost-effectively. In
response, we try to shift toward other tasks that AI hasn't yet mastered,
hoping that they will still hold economic value and command a skill
premium. However, this mindset puts us in a constant race against the
machine, always chasing the next task that AI can't take over.
Our jobs, however, don't exist solely around the performance of certain
tasks. Jobs, instead, are part of a larger system of work and are structured to
resolve constraints in that system. When that constraint collapses, the logic
for the role no longer holds.
Every system of work has limiting factors that determine its overall
performance. These limiting factors, referred to as constraints in systems
theory, refer to the part of the system that determines how quickly or
effectively the rest of the system can operate. The greater the limiting power
of a constraint, the higher the value associated with managing it.
Accordingly, the contextual value of a role is determined by its ability to
resolve constraints in the larger system of work.
For much of the 20th century, access to specialized knowledge was the
dominant constraint. Professions like law, medicine, and consulting were
built around managing this constraint. Those who knew the right facts and
frameworks and could apply them to solve a problem held an advantage.
However, as information becomes not only increasingly accessible but also
more easily applicable with the aid of AI, that constraint disappears. As
constraints are removed, the value of the roles structured around managing
them also collapses.
Constraints, however, aren't simply eliminated from a system - they
typically move to other parts of the system. As a constraint moves, the
location of value shifts with it. Instead of focusing solely on tasks, we
should ask: What new constraints appear in the system when AI eliminates
older ones? If we can identify and address these new constraints, we gain
contextual value in the new system, not just by executing tasks but by
ensuring the system functions effectively.

When constraints shift, roles, institutions, and business models that were
previously central may lose contextual value. In contrast, new ones rise to
prominence, not because they perform tasks better or cheaper, but because
they address the system's new constraints. To determine which roles will
hold value, we need to identify the new constraints that emerge when
technology, markets, or regulations shift.
Understanding constraints
To understand how value shifts within an organization or across the larger
economy, we first need to comprehend the various types of constraints that
emerge in a system. Constraints can be categorized into three types:
scarcity-based, risk-based, and coordination-based.
Scarcity-based constraints arise when something essential is also limited in
supply or not readily accessible. This may apply to a physical resource,
specialized knowledge, or access to infrastructure. In systems where
scarcity dominates, value accrues to those who control or allocate the scarce
resource.
In the early 20th century, maritime safety depended heavily on one scarce
resource: timely information. Before satellites and GPS, ships at sea
couldn't be constantly tracked. In the event of a storm or mechanical
failure, their only link to the outside world was the radio operator. These
professionals were trained to send and receive Morse code over long-range
radio, maintaining contact with port authorities, other ships, and emergency
services. Their value came from controlling the flow of scarce and critical
information. When disaster struck, it was the radio operator who determined
whether help could be summoned in time.
Over time, as communications infrastructure improved, this scarcity was
removed. Today's ships are equipped with automated systems that
continuously handle communication, largely without human intervention.
As the constraint disappeared, so did the value associated with the role that
was meant to manage it.

Constraints also emerge in response to risk. Risk-based constraints emerge
in environments where actions carry significant consequences. Value here
accrues to roles that can reliably manage uncertainty, minimize errors, or
take accountability for outcomes with serious consequences.
In a surgical environment, the surgeon often takes center stage. However, it
is the anesthesiologist who manages the most critical risk associated with
keeping the patient alive and stable throughout the procedure. The margin
for error is razor-thin. Administer too little anesthesia, and the patient may
regain consciousness mid-surgery; too much, and vital systems may shut
down. Every patient responds differently, and even minor misjudgments can
have life-threatening consequences within seconds. What makes the
anesthesiologist's role so critical is not just technical knowledge, but the
ability to continuously interpret the context of every specific patient and
procedure and make decisions under uncertainty.
When we think of the anaesthesiologist's role, the presence or absence of
automation is irrelevant. Their value comes not from how the task is
performed but from holding responsibility for the system's most
consequential risk. Even with advancements in monitoring equipment, this
risk-based constraint remains, and so does the value associated with the
role. The anesthesiologist remains indispensable not because of what they
do but because of what could go wrong if they didn't do it perfectly.
Finally, coordination-based constraints are seen when many moving parts
must align for the system to function effectively. These are especially
common in large-scale operations or ecosystems with multiple stakeholders
and interdependencies. When coordination is the bottleneck, value flows to
those who can provide a solution.
A movie set is one of the most intricate coordination environments in the
modern economy. Directors, cinematographers, set designers, actors, script
supervisors, financiers, unions, distributors, and marketing teams must all
align under tight deadlines and, often, fluctuating budgets. The producer is
the role that holds the system together. They don't write the script or
operate the camera. Their job is to coordinate the moving parts: securing
funding, assembling the right team, managing logistics, and ensuring the

film gets completed and delivered. If they fail, the entire project collapses,
no matter how brilliant the director or how talented the cast.
Understanding roles in terms of constraints rather than skills or tasks helps
us comprehend why specific roles gain or lose value as a system of work
evolves.
When constraints shift because technology removes scarcity, manages risk,
or simplifies coordination, those who spot the new constraint first and
rebundle their skills and tasks around it are usually the ones who capture the
next wave of value.
The story of the sommelier illustrates the central message of this chapter:
Work is not simply a bundle of tasks but a response to constraints in a larger system,
and when constraints shift, the value of work migrates with them.
The sommelier's story is interesting, not because their original role
remained untouched, but because it transformed to resolve the new
constraint. The sommelier, standing tableside in an era where anyone can
Google vineyard origins and flavor profiles, should have faded into
irrelevance. Using a task-centric lens, their work of recommending wine
should have lost all economic value when that information is now available
for free. Paradoxically, the sommelier's value has only increased alongside
the availability of cheaper substitutes to their knowledge. That puzzle now
makes sense.
The sommelier's rising value coincided with three shifts that commoditized
the wine market and made wine knowledge more accessible. Each of these
shifts removed an old scarcity-based constraint and, in doing so, revealed
new ones: emotional risk and the need for coordination in context. Instead
of becoming obsolete, the sommelier became more indispensable by
resolving these emerging constraints.
First, the wine market, once a niche industry, exploded in the mid-1900s as
wines from California, Australia, Chile, and South Africa flooded the
shelves. With this abundance came confusion for diners, who now had to

choose from dozens of obscure vineyards and unfamiliar blends. The old
constraint of access to rare wine had been removed, but a new constraint
had come up: navigating overwhelming choice in a world of abundance.
The sommelier stepped in to manage that friction, emerging as a trusted
curator resolving the risk associated with choosing an incorrect pairing.
Even when knowledge is abundant, people often lack the confidence to act
on it. The sommelier steps in to curate the relevant information and provide
assurance.
Second, the nature of fine dining began to change. Restaurants were serving
not just food but a carefully curated experience. The sommelier became a
central character in this performance as the simple transaction of ordering a
bottle gave way to a carefully coordinated experience built on the
sommelier's storytelling and performance.
Finally, knowledge itself was restructured. The rise of elite credentialing
bodies like the Court of Master Sommeliers turned the sommelier's
expertise into a visible, scarce signal. The difficulty of passing the exam
and the mystique surrounding those who did created artificial scarcity. The
diner was no longer just buying a bottle; they were buying into the
sommelier's taste.
Fig. 5.1: The sommelier rebundles valuable complements around the
new constraint
As wine became commoditized and the old scarcity constraint disappeared,
value migrated to its complements: managing the context, curating the
selection, instilling confidence in customers, and even creating new
scarcity. These complementary capabilities now hold economic value. The

sommelier reimagined their role in the new system by stepping forward to
manage the new constraints and rebundling these higher-value
complementary capabilities as part of their new role.
Don't chase the skill, follow the constraint
What happened to the sommelier is now happening across the entire
knowledge economy as AI transforms knowledge work. As AI improves,
skills and capabilities that would require years of training or teams of
specialists can now be accessed in seconds. What was once rare is now
readily accessible. When previously scarce skills can be easily accessed, the
economic value associated with those skills goes down. The loss of
economic value takes away the skill premium associated with the job.
This shift triggers a predictable response as workers get onto a constant
treadmill looking to reskill themselves. Workers are urged to constantly
acquire new skills, pivot faster, stay agile, and skate to where the puck is
moving. In principle, that advice isn't wrong. Learning is critical. But if
you're only tracking the skills and not the constraints, you're skating
without a map.
The assumption baked into most reskilling narratives is that skills are a
scarce resource. But in reality, skills are only valuable in relation to the
constraint they resolve. If the constraint moves and you chase new skills
without understanding what friction you're trying to solve, you risk
becoming very good at something that no longer matters.
The more strategic move is to begin not with the skill, but with the system.
Look for the new constraint. Identify what is now scarce, risk-prone, or
hard to coordinate. Once you've located that, you can evaluate your current
capabilities against it and identify new skills that you must acquire in order
to effectively structure a role around that constraint. The sommelier
repackaged their deep knowledge of wine around a new constraint: helping
people feel confident in a moment of uncertainty. More importantly, once
they understood the new constraint, they also rebundled new higher-value

skills and capabilities around this new position. That's the difference
between reacting to change and reinventing strategically. One keeps you
running towards new skills, the other helps you run the right race.
Rebundling jobs around new constraints
We often miss the importance of constraints in our obsession with thinking
of jobs in terms of tasks alone. British computer scientist Geoffrey Hinton,
often dubbed the "Godfather of AI" famously predicted in 2016 that AI
would soon replace radiologists. Much of the job involves interpreting
medical images, a task that lends itself well to machine learning.
Algorithms, trained on vast image datasets, can detect patterns of disease
with remarkable precision. Yet, nearly a decade down, radiology hasn't
disappeared; it has flourished. What's striking is that at most tasks in
radiology, AI already outperforms humans. So why are radiologists still in
demand?
When we define jobs purely in terms of tasks, we risk overlooking the
constraints that jobs are designed to manage. These very constraints - the
context within which those tasks are performed, the coordination required
to sequence tasks to get actual work done, and the risk that needs to be
managed if something goes wrong - hold jobs together. Ask someone to
explain away their own work as simply a set of discrete tasks, and they'll
likely resist, insisting that it's a lot more than just that. But ask them to
break down someone else's job, especially one they don't understand well,
and the task model starts to feel plausible. That's the trap - believing other
people's work is just a bundle of tasks, because you don't see the
constraints their role resolves.
With the improvement of technology, radiologists have progressively
expanded their role to manage new constraints and now place greater
emphasis on contextualizing their findings within a case, working alongside
clinicians to determine next steps. A shadow on a lung is a signal that is
interpreted differently depending on the patient's history, lifestyle, and other
symptoms. As AI takes over more routine image analysis, radiologists

constantly rebundle their role by incorporating new activities. Some take on
important roles on tumor boards - multidisciplinary teams of medical
specialists who review the diagnosis and treatment options for complex
cancer cases - where they debate treatment paths with oncologists and
surgeons. They have redefined their role in response to gaps in the new
system of work. Machine learning can recognize patterns in scans, but it
cannot evaluate the right trade-offs and deliberate across domains on new
edge cases. These radiologists understand that when the scan gets
commoditized, value migrates to complementary activities that can be
rebundled into new roles. AI may excel at benchmark tasks, but if the job's
real value lies in managing the constraints of coordination and risk that hold
those tasks together and get work executed, then benchmarks aren't going
to be very useful, and reskilling around specific tasks won't save us from
any effects that AI may have on our jobs.
Constraints do not disappear; they shift. Remove one constraint, and
pressure builds somewhere else. When the constraint shifts, roles that once
held economic and strategic significance begin to disintegrate into isolated
components. Tasks that needed to be performed together no longer need to
coexist in the same role. This unbundling, as noted in the previous chapter,
affects workers not so much in terms of headcount reduction as in the loss
of autonomy and differentiation. Workers lose tasks, but more importantly,
they lose the pricing power, decision-making autonomy, and trust that came
with the old role's structure. But this shift also creates new opportunities as
workers migrate to performing new tasks. As we noted in the previous
chapter, the rise of automated checkout systems unbundled the tasks of
payment and bagging from the cashier's role. Cashiers, in turn, migrated to
other tasks, such as troubleshooting customer checkouts or upselling items.
The role as a bundle of co-dependent attributes fell apart and had to be
restructured.
New roles emerge when workers rebundle a new set of capabilities to
resolve a new constraint. We see these new roles in terms of new tasks and
capabilities, but what matters is identifying the new constraint that needs
resolution. The rise of the telegraph revolutionized how news was
delivered. Reporters could send updates across long distances almost

instantly, but what arrived on the other end was a flood of disjointed
messages. The constraint had shifted. Editors were no longer constrained by
how fast news arrived, but by how to filter, prioritize, and make sense of all
the incoming information. Some telegraph operators recognized an
opportunity. Instead of just transmitting messages, they began curating
them, deciding which updates were essential to be passed along to
newspapers. They had moved their role from a technical function to an
editorial one.
Rebundling doesn't try to resist the shift and preserve the job bundle as it
originally existed. That would be meaningless. It rebuilds the role forward,
exploiting blind spots in the new system of work. Workers who can
recombine overlooked, undervalued tasks into new job bundles gain
leverage in the new system of work.
We've seen this in the transformation of journalism, where the rise of social
media commoditized traditional reporting, valuing engagement metrics
above editorial discretion. But some journalists recognized the system's
blind spots and repositioned themselves as curators and explainers, who
gained the trust of the audience through narrative framing. Others adapted
by developing personal brands and launching reader-funded newsletters, not
only to regain control but also to end up with greater agency than in the
past.
When we apply this lens to the impact of AI on work, we note that AI
removes constraints associated with the availability and accessibility of
skilled labor. However, as these scarcities fall away, two new constraints
emerge in their place: risk and coordination. New roles that emerge need to
be structured around managing these new constraints.
To understand how rebundling works in practice, you have to look not just
at how individual tasks gain or lose value, but also at how the larger system
surrounding those tasks is changing.
Rebundling starts with asking four questions:
1. What is getting unbundled?

2. What constraints does that create that the new system of work
doesn't effectively manage?
3. How can workers reconfigure their roles to manage those
constraints?
4. And which complementary capabilities can they rebundle to
ensure their work holds value?
Fig. 5.2: How jobs unbundle and rebundle
If you're asking what the future of work looks like, don't keep looking for
what AI can't yet do. Instead, ask what it breaks in the system. That's where
new constraints emerge. This may or may not require you to acquire new
skills. But gaining skills alone will not guarantee value and relevance in
your role. Instead, you need to identify the new constraint and rebundle
relevant skills around managing it. Constraints related to risk and
coordination are of particular interest, and that's what we look at next.
Rebundling around risk-based constraints
Much like the sommelier, a licensed fugu chef occupies a unique economic
role that doesn't easily make sense at first glance. Preparing the pufferfish
requires years of training and certification, not because it's hard to cook, but

because it can kill you. The dish contains a lethal neurotoxin, and eating it
carries the perceived risk of fatal poisoning. You'd expect that a meal with
such risk wouldn't attract any takers. Yet, the meat commands a premium.
This is the paradox of fugu. People pay a premium not despite the risk but
precisely because of it. The chef's role is less about culinary creativity and
more about the ability to execute without error. Only chefs who have
undergone years of training and earned a special license are allowed to
serve the dish. Eating fugu might signal bravery, but more importantly, it
signals access to a rare culinary experience, served exclusively by the most
highly trained of chefs. It's tempting to treat this as one of Japan's many
cultural quirks, but it's really a story of how roles change when scarcity-
based constraints are removed.
Traditionally, seafood's value was tied to supply-based scarcity. The harder
it was to source a fish, the more expensive it was. Logistics and ecology
were constraints that made certain seafood a luxury. This changed with the
arrival of cold chain logistics. Global refrigeration and reliable transport
normalized access to previously rare fish, collapsing the old constraint.
Eating seafood no longer signaled luxury because seafood itself was no
longer scarce.
As the economic value of seafood itself declined, something interesting
happened. Fugu - carefully-prepared seafood, which would otherwise be
fatal - rose in value. Most luxury foods are defined by scarcity of supply,
but fugu's scarcity lies in the scarce access to highly trained chefs who can
manage the risk associated with eating the fish. You don't eat fugu because
the fish itself is rare. The ability to reliably prepare the dangerous pufferfish
is the new constraint that gives fugu its value.
As constraints on production or consumption are lifted, market activity
accelerates. This acceleration often reduces control and increases risk.
Airbnb lets anyone run an accommodation business, without the usual
constraints associated with hotel ownership. As market activity exploded, it
also brought in new risks related to unsafe properties and unruly guests.
Value shifted to managing risk in this new system, through ratings and
reviews, guarantees, and insurance. When technology removes scarcity-

based constraints, it often introduces new risk-based constraints. Those who
step in to manage the new constraint get to capture the value associated
with it.
Containerization has made shipping cheaper and more reliable, but it has
also introduced new risks associated with managing far-flung supply chains,
including non-compliant vendors, fluctuating tariffs, and even geopolitical
shocks. The new roles of supply chain risk managers, vendor compliance
officers, and logistics planners emerged to manage these constraints. Value
shifted from moving goods fast to managing the risks associated with that
movement.
In complex systems, removing one bottleneck often exposes others. While
you can see what's become simpler or faster, it's far more challenging to see
what's become riskier. As a new system takes off, activity within that
system accelerates, and the interdependencies between its parts increase,
leading to more potential points of failure. The system's success no longer
hinges on how fast or how much it can produce, but on how reliably it can
operate under uncertainty. Accordingly, managing risk in a rapidly growing
system is of high value.
When new technologies are adopted, our instinct is often to look for risks
within the technology itself. In the case of AI, this typically involves
concerns about model accuracy and cybersecurity threats. History teaches
us, though, that the most enduring and valuable risk-management roles
don't emerge from inadequate technology but from disruptions in the
system. The introduction of refrigeration transformed food supply chains, as
the old constraint of spoilage seemed to have been conquered. However,
this abundance introduced a new risk: assessing contamination in
refrigerated food as it traveled great distances without any visible signs of
decay. Governments established food safety labs and inspection roles to
manage this risk-based constraint. The invention of elevators, similarly,
removed the constraint of walkable height and enabled the vertical
expansion of cities, but also came with new risks, including fire hazards and
structural failures in high-rises. The roles of building code authorities,
safety engineers, and city inspectors were set up to manage that risk.
Refrigeration and elevators didn't fail as technologies. They worked so well

that they transformed the larger systems around them, introducing new risks
in food safety and urban design.
Every time a constraint is removed, the need for reliability and the
ownership of liability shift to a different point in the system. Identifying and
managing this as the new constraint is crucial to making the new system
work and capturing value from it.
When AI is deployed, it introduces a new class of risk-based constraints as
well. AI tools are inherently probabilistic. They predict what's likely, not
what's certain. However, when companies treat those predictions as truths
and optimize blindly around them, they introduce new risks in the system.
First, when organizations optimize too narrowly around AI-based
recommendations, they can misallocate resources. A healthcare algorithm
widely used in U.S. hospitals to allocate care management resources
predicted which patients were likely to need more attention based on
historical healthcare spending. However, because Black patients have
historically had less access to care, and thus lower spending, even those
with serious chronic conditions were often ranked as lower priority. The
system was optimizing for spend, not needs. Instead of solving the
constraint of access to a scarce resource, it reinforced that scarcity. Second,
such effects can be amplified owing to feedback loops. In one infamous
example, two Amazon sellers locked in a pricing duel sent a fruit fly
biology textbook spiraling to $23.7 million. Each seller's pricing agent was
set to adjust its price based on the others. One nudged slightly above, the
other slightly below, and the loop escalated until the book cost more than a
Manhattan penthouse. Each step was logical within the local rule set, but
disastrous when compounded. Third, AI deployment often creates
accountability 
gaps, 
especially 
during 
periods 
of 
organizational
transformation. As decisions shift from people to tools, as seen in the
examples above, it becomes unclear who is responsible when something
goes wrong. No single actor wholly owns the risk, even though the
consequences of compounding bias and runaway automation are very real.
These three factors lead to the emergence of risk-based constraints,
elevating the importance of judgment as a countermechanism to manage
that risk. Judgment is the ability to make the final call, weighing all pros

and cons, and effectively bearing all risk associated with the outcome.
Judgment is not simply intuition; it is the capacity to act under uncertainty,
fully aware that you're accountable for the outcome. Judgment is why the
anaesthesiologist still commands a skill premium even as related
administering and monitoring equipment improve in capability.
Judgment becomes crucial in unstable and uncertain environments.
Judgment becomes important when AI-generated predictions and plausible
answers are no longer sufficient to achieve the final level of clarity, where a
decision must be made despite conflicting facts and incentives. When
dealing with unanticipated outcomes, as in the case of the healthcare
algorithm, judgment allows a human to step back, question the frame, and
ask whether the solution is aimed at solving the right problem. In situations
that create accountability gaps, judgment helps to reassert ownership.
Judgment becomes the mechanism through which action is made amid
uncertainty. You don't rely on someone's judgment because it's infallible,
nor do you trust it because it can be measured or scored. You rely on it
because you believe, based on past experience and social signaling, that
their assessment of risk is trustworthy. Judgment is developed over time
through making hundreds of irreversible decisions in unpredictable
environments at financial and reputational risk.
Judgment is a human advantage in the age of AI, made valuable by the
emergence of risk-based constraints and by the trust others place in your
ability to bear it well. As risk-based constraints emerge, new roles will
emerge to navigate ambiguity and absorb the risks and consequences
associated with AI deployment. These roles will command value not for the
tasks they perform but for the liability they assume or help manage.
Rebundling around coordination-based
constraints
In the early 15th century, the city of Florence faced a daunting challenge.
The city had begun building a massive cathedral, but no one knew how to

construct the dome due to the design constraints involved. The usual
methods wouldn't work: the design rules prohibited flying buttresses, and
the region lacked enough timber to construct the traditional wooden
scaffolding needed to support the dome during construction. At the time, no
known engineering solution could span such a vast space at such a great
height under these constraints. The breakthrough came from an unlikely
figure, Filippo Brunelleschi, a goldsmith and sculptor with no formal
training as an architect. He designed the dome's shape but also invented the
logistics to build it. He created new hoisting systems and scaffolding
procedures and even planned the delivery and scheduling of stone, timber,
and labor across a multi-decade project. Brunelleschi used his skills to solve
the design problem, but the real breakthrough came when he recognized
and managed the constraints needed to turn that design into reality.
Your skills are essential, but they gain contextual value only when they
resolve a constraint in the system. We've looked at risk-based constraints;
we now turn our attention to coordination-based constraints. Coordination-
based constraints may emerge operationally, at the level of a specific
process, or may appear systemically, to reveal cracks in the architecture of
the entire system.
At the process level, coordination-based constraints arise when multiple
tasks or tools need to work together, but no one is responsible for making
sure they do. Consider the emergence of Revenue Operations, or RevOps,
following the rise of cloud-hosted software. Cloud-hosted software
unlocked a wave of specialized tools, CRMs for sales, automated outreach
for marketing, and dashboards for customer success. These tools made data
more accessible and execution faster, removing old constraints of slow
manual execution. A task-based view would suggest that each team now
needed better analysts or tool admins to optimize their local workflows.
However, removing execution constraints exposed new coordination
constraints. Sales, marketing, and customer success teams began optimizing
in silos, each with its own tools and metrics. Execution became faster, but
coordination became harder. Forecasts didn't add up across teams, and
customer journey handoffs broke down. A different department owned each

part of the customer journey, yet no one was accountable or liable for
managing revenue across the entire journey.
The growing friction between teams created a coordination gap and a
broken workflow. The role of RevOps emerged to address this gap. RevOps
professionals understood the tools but, more importantly, took on the
responsibility of managing coordination across them, asking questions no
single tool could answer. Why were high-quality leads getting dropped?
Why was the forecast always off? Why were customers churning after fast
sales cycles?
RevOps professionals rebundled a new role around these process-level
constraints. As task execution was automated and grew increasingly
commoditized, cross-silo coordination became strategic instead.
Fig. 5.3: The RevOps role rebundles across coordination gaps
Viewed from traditional lenses of front-office and back-office work,
RevOps looked like back-office work, far removed from the customer. Yet,
RevOps was more strategic than any of these conventional front-office
functions directly serving the customer. Power is determined not by
proximity to the customer but by the ability to resolve the system's
constraints and coordinate across the system.
Process-level coordination aligns the disjointed parts of a broken workflow,
while system-level coordination rearchitects how the system operates. At
the process level, your value lies in ensuring work progresses well across
teams and nothing falls through the cracks. At the system level, your value
lies in reimagining workflows, so those cracks never exist to begin with.
During the early days of the pandemic, firms realized new constraints had

emerged across their supply chains as demand shocks hit and production
came to a halt. These constraints couldn't be addressed through better
dashboards or better meetings, or even through creating new process
management roles. The roles that became most valuable were those that
focused on reimagining the system, such as redesigning fulfillment logic or
building supply buffers in your supply chain. Operational roles were stuck
managing the chaos, but system-level roles worked on eliminating the
conditions that had led to the chaos.
A single architectural decision in how data flows or how feedback is
captured can create leverage across thousands of future executions. That's
why a role that is structured to manage system-level coordination
constraints commands the highest economic value. We see this particularly
in the compensation of product heads and technical architects at large
platform businesses, who focus on solving constraints for ecosystems
involving hundreds of millions of users. A product head for seller
experience at Amazon, who defines how millions of sellers interact with the
marketplace, or a technical architect at Meta, who designs APIs for product
teams across the company to build interoperable experiences, occupy such
system-level coordination roles.
As different parts of an organization adopt AI at different rates, without
pausing to coordinate efforts across the organization, new coordination-
based constraints appear. Instead of chasing new skills to work alongside
AI, workers will need to rethink what new constraints emerge as AI is
adopted and which skills can best be leveraged to manage those constraints.
We see such opportunities emerge whenever organizations reorient their
workflows around a new technology. Consider the evolution of nursing as
hospitals adopt digital technologies. When hospitals began digitizing patient
care through the use of electronic health records (EHRs) and billing
automation, the patient experience started to deteriorate. Doctors had
detailed data, and administrators had better billing, but no one was tracking
the patient's journey across it all. The patient experience, which was once
coordinated informally through memory and conversation, was now
scattered across different screens and tools. New technology had unbundled
care into its constituent tasks and optimized the individual tasks, but it had

also created a fragmented patient experience, both emotionally and
logistically.
The coordination gap, particularly in chronic care, led some nurses to
rebundle their role to become nurse navigators. These nurse navigators
stepped in to guide patients through a maze of appointments and
departments. They translated complex care plans into simple language and
resolved operational issues that prevented patients from accessing care.
Addressing constraints that were invisible to EHRs and care algorithms, this
role helped improve the patient experience while also reducing hospital
readmissions and enhancing adherence to treatments. The rebundled role
had earned influence despite not fitting cleanly into any traditional
department.
As hospitals roll out AI tools for radiology, diagnostics, and patient
monitoring, these roles now also ensure that insights from AI-driven scans
trigger the right follow-up and facilitate timely interventions. As AI speeds
up individual tasks, these nurse navigators ensure that the entire patient
experience remains coordinated. Their nursing skills matter, but what
matters more is their ability to manage workflow continuity across the silos
that emerge on account of AI adoption.
The lesson from Brunelleschi still holds. Designing the dome was not the
hard part. Making it stand by solving for the supply chain, the labor flow,
and the hoisting mechanisms was the real breakthrough. Your skills matter,
but they matter most when applied to manage the constraints in the system.
When broad humans beat narrow AI
The case of the nurse navigator illustrates the challenge posed by AI's
narrow advantages in optimization and automation. By making execution
more efficient in silos, AI-driven optimization unintentionally creates new
constraints in cross-functional coordination. Each department, from
radiology to oncology, now operates more efficiently with its own AI tools;

however, they're not aligned. Narrow AI ultimately relies on broad human
capabilities to address these constraints.
We also observe this pattern with the rise of claims advocates in the
insurance industry. As the industry digitized the claims process, the
adoption of chatbots and automated workflows ironically took away human
support from distressed customers who needed it most. Simple claims were
resolved faster. However, resolving complex claims became even more
stressful. In response, claims advocates, who combine legal guidance with
emotional support, emerged as a new role to help policyholders understand
unclear denials and navigate the appeals process.
The nurse navigator and the claims advocate illustrate how AI improves
individual tasks, but unintentionally creates new coordination gaps across
them. Narrow AI accelerates the parts, but broad human intelligence holds
the whole together. This plays out at both the process and system levels. At
the system level, such rebundled roles do more than simply hold tasks
together; they create value by exercising judgment.
In the early days of stock trading, fortunes were made by those who could
out-shout or out-signal the competition on the floor of the New York Stock
Exchange. However, as digital infrastructure matured and algorithmic
trading emerged, machines began to outperform human traders. Traders
who had once thrived on reflexes now found themselves redundant. In their
place, new roles of algorithmic strategists and behavioral signal analysts
came up. The tasks of buying and selling were still central to the system,
but the human role had transformed from performing the trade to
interpreting the market system and identifying second-order patterns the
models couldn't see.
Judgment becomes more valuable in a world of frictionless execution. This
is why misplaced prophecies about radiologists losing their jobs and
becoming redundant due to AI don't actually come to pass. Radiologists
who were paid to examine scans and identify anomalies realized they had a
new role when AI could identify tumors better than they could. Their role
had shifted to judgment, deciding what the scan meant in a clinical context
and what the appropriate next steps should be, given the larger context of

the patient. Machines are better than radiologists at image classification.
However, radiologists now hold high contextual value in the new system,
thanks to their clinical judgment and understanding of the broader patient
context.
These are examples of role migration where the new role has both high
contextual value and high economic value, which is the ideal outcome you
want to achieve. And you don't get there through 'reskilling.' You
accomplish this by understanding what the AI cannot understand - the
larger, complex system within which it operates. Value lies in understanding
broader contexts that narrowly efficient AI systems struggle to comprehend.
Shifting our lens
Reflecting on the story of the nurse navigator, a task-centric lens might
suggest that the arrival of digitized workflows and AI tools would sideline
nurses, or move them to primarily focus on more 'human' tasks that
technology can't automate - those involving empathy and patient education.
While nurse navigators do perform some of those tasks, describing their
work in terms of those tasks completely misunderstands their role in the
new system.
If we continue to analyze AI's impact on work through a task-centric lens,
we risk asking the wrong questions and drawing incorrect conclusions. We
start chasing skills that AI can't substitute and remain locked in a race
against the machine.
This framing is inadequate - it centers on tasks and skills, not on systems
and how constraints shift within them.
When we examine work through a system-oriented lens, the key question is
not what AI can or cannot do, but what AI breaks or changes within the
system. Even if AI brings down the economic value of specific individual
tasks, it also introduces new constraints in the system, which become the
new centers of value. Once we identify them, we can anchor our position
accordingly. That's how we restore value to our roles - by solving the

problems the new system now struggles with. This is how roles gain
contextual value and relevance in the new system.
The role of nurse navigators emerged to resolve three key constraints. First,
digitization and automated scheduling made individual processes faster, but
fragmented responsibility for the overall patient journey. Second, with
specialists optimizing execution within their respective domains, someone
needed to ensure the entire treatment pathway remained coherent. Third,
patients' needs varied widely, ranging from transportation to insurance
issues. Nurse navigators stepped in to manage all these constraints. Having
established contextual value in the new system, the role then combined new
complementary capabilities in logistics management, advisory, and patient
advocacy to carry clear economic value.
Fig. 5.4: The nurse navigator rebundles across a fragmented patient
journey
This is the core move that restores economic value: not just solving a
constraint, but rebundling complementary capabilities around that
constraint in ways that increase differentiation, deepen trust, and tie the role
closer to outcomes. This represents a shift in frame: from protecting tasks to
managing constraints, and from accumulating one-off skills to strategically
identifying the needs of the new system.

If you want to redefine your role, start by targeting the new constraint and rebundle
capabilities that generate economic value into that position.
There's one final ingredient in our quest to reinstate economic value in the
new role: visibility. Solving for a constraint only creates durable value
when others can recognize it. A role may have high contextual value, but it
is only rewarded when it becomes economically visible. The redesigned
role must be visible within the system, clearly distinct from what AI
automates, and positioned close to where decisions are made or transactions
occur so it can participate in capturing that value.
When broad humans are invisible to narrow
algorithms
Over centuries, caravans have moved salt across the Sahara. The salt itself
is abundantly available, extracted from mines in the north and traded for
goods in the south, but moving that salt is a system constraint. Navigating
the shifting dunes of the Sahara, with its invisible hazards and its vanishing
waypoints, and where GPS-based navigation fails to make sense of a
landscape that is always in motion, is far from trivial.
Tuareg guides made these trade routes viable. These nomads navigate by
memory and intuition, aided by generations of ecological awareness of the
region. For centuries, they've held the keys to navigation. The Tuareg's role
carried high contextual value, but contextual value alone is not enough. You
don't get paid for being essential. You get paid for being recognized as
essential. Despite the immense value created by their skill in resolving the
key constraint in the salt trade, their economic value remained limited.
That's because resolving a constraint isn't enough to give your work
economic value. For it to hold value, four other factors must also be in
place.
First, it must be visible, meaning the system must be able to see and
recognize the value you create. Second, it must be scarce in that the

capability must be hard to substitute or replicate. Third, it must have
leverage. The actors performing the work must be able to negotiate their
value. Finally, the work must be performed close to the point where pricing
decisions or transactions are made.
The Tuareg operated within a system where they couldn't effectively
coordinate. Their activities were fragmented across unconnected
individuals, rather than centralized through institutions that would have
given them the power of labor unions. They had no access to institutional
bargaining, which would have helped that rare skill command its market
price. Furthermore, the value they created in the salt trade was not captured
at their point in the value chain; it was instead captured further downstream
by markets and middlemen, far removed from the Tuareg navigators
themselves. They were neither visible nor coordinated, nor close to value
capture. The Tuareg remind us that contextual value is essential, but it does
not guarantee economic reward.
As AI takes over system-wide coordination, local actors like the Tuareg
play an increasingly important role in making the system work, yet they
remain invisible to the system. Logistics platforms like Uber Freight may
manage trucking routes and job pricing, but when a truck gets stuck behind
a blocked alley or needs to resolve a broken gate code, it's the driver who
resolves it, without receiving additional compensation. In AI-enabled
warehouses, robots do the heavy lifting, but human pickers still address
issues such as mislabeled bins or damaged items. As AI-enabled execution
scales, these exceptions and issues only multiply.
The role of such local actors is critical to making the system work by filling
in the broken gaps. They coordinate between machine execution and the
complexity of the environment in which machines operate. What makes
these roles valuable is not that they do what AI cannot, but that they adapt
to unforeseen scenarios in ways that AI cannot anticipate or predict. Yet,
despite their criticality, these actors often remain economically undervalued.
Like the Tuareg guides of Saharan salt caravans, whose deep knowledge of
the terrain was essential for navigation but whose pay was disconnected
from the value of the trade they made possible, today's warehouse workers,

delivery drivers, and field technicians hold roles rich in contextual value but
low in control. They resolve breakdowns and absorb variability, yet they do
so in ways that are fragmented and informal, and, hence, largely invisible to
the system's central intelligence. The algorithm tracks GPS pings and
swipe-in/swipe-out events at the warehouse, but not the hundreds of
judgment calls a human would make to counter unexpected scenarios. The
Uber Freight driver is paid for the route completed, not for the improvised
workaround to a failed delivery instruction.
The challenge of staying visible to the algorithm isn't limited to warehouse
workers and delivery drivers. As societies age, the demand for care work is
set to rise dramatically. The platforms that coordinate this expanding market
for care primarily compensate caregivers based on measurable metrics.
Imagine a platform for on-demand elderly care where workers are matched
to households, clocked in, and assigned a set of standardized tasks. The
platform pays based on time logged and tasks completed. The actual value
of care, however, lies in what can't be easily measured - the caregiver's
ability to sense emotional shifts, respond gently to unpredictable behavior,
or modify a routine because the patient's energy level has shifted that day.
Care is becoming more essential, yet its most essential qualities remain
economically invisible. As with the Tuareg, care workers will perform work
that has high contextual value. Yet, they may fail to command economic
value. And so, care, arguably one of the most critical forms of work over
the coming decades, risks being trapped in the same logic that has
undervalued essential roles across the algorithmic economy. It will be
treated as interchangeable and transactional, and we will continue to ask
care workers to do more while rewarding them less.
To build more inclusive systems of work, whether in traditional firms or on
gig platforms, we must value tasks appropriately. If we want workers to
reimagine and rebundle their roles meaningfully, the system must also be
able to recognize and reward the unique value those roles bring.

Looking for the new scarcity
In this chapter and the previous one, we've explored how the erosion of
scarcity in certain skills drives down the economic value of specific forms
of knowledge work. When AI makes it easier to generate predictions as well
as answers to questions, and improves access to expertise on that basis, the
scarcity around those capabilities disappears, and so does the premium once
attached to them. However, that doesn't mean that scarcity vanishes
altogether. Instead, new scarcities emerge.
Alongside looking for risk-based and coordination-based constraints in the
new system of work, we should also look out for new scarcity-based
constraints. Where will value migrate next, and what kinds of expertise will
command a premium in a world where expertise and skilled work suddenly
become cheap and easily accessible?
The invention of the camera offers an early lesson in what happens when
previously scarce work suddenly becomes cheap and easily accessible. In
19th-century Paris, the AcadÃ©mie des Beaux-Arts dictated what counted as
real art. Realism was the gold standard. It emphasized painstaking
precision, visual fidelity, and alignment with accepted technique. Artists
weren't rewarded for experimentation that departed from these norms; they
were rewarded for consistency. The invention of photography, however,
began to challenge this established view.
At first, photography seemed like a threat to painters. If a machine could
capture reality more accurately, and in mere minutes, than a painter could in
weeks, what was left for painters to do? Early cameras were less
sophisticated, but as technology improved, some feared that the craft of
painting might be rendered obsolete. That moment eventually passed. Art
evolved alongside the rise of photography, freeing painting from its
representational obligations. Painters no longer had to compete with the
camera in representing reality. Instead, they could turn their attention to
what the camera still missed: the play of light on water, the texture of
shadows, and the subtle meaning in color and tone. Impressionists such as
Monet and Degas began experimenting with the subjective experiences of

color and light. Instead of representing reality, which the camera could do
with far less effort, they started interpreting it.
Without the camera, painting would likely have continued, at least for some
time, on its predictable path toward better technique and tighter detail. More
answers to the same question: How can we better capture reality?
Photography collapsed the cost of answering that question. And in doing so,
it made the question irrelevant. The Impressionists responded not by
offering better answers but by changing the question. What if art wasn't
about capturing reality but about interpreting it?
This shift reframed the primary role of the artist, from skilled representation
to subjective interpretation. When representation was scarce, skill was
highly valued. However, when replication became cheap, value migrated to
the act of interpretation. The Impressionists were responding to a new
constraint by reimagining their craft.
As AI dramatically increases the supply of specific types of skilled work,
the economic value of that work declines, not because its intrinsic value has
changed, but because it's no longer scarce. As a result, economic value
shifts to the complementary capabilities that sit upstream and downstream
of that work. When it's easier than ever to generate answers and insights,
value migrates to the upstream work of framing the right inquiry and the
downstream work of choosing which answers are worth acting upon.
Curiosity, the ability to frame the right question before seeking answers,
and curation, the discernment to elevate the most relevant answers for
further action, become increasingly valuable as the ability to generate
answers becomes commoditized by AI.
Curiosity and curation - human advantages in the
age of AI
We often overvalue answers and undervalue the framing of questions. In a
world where AI generates abundant answers, this bias can be costly. We

continue to reward knowledge holders, even when the value has shifted to
those who can define the problem in the first place.
Curiosity is not random inquiry. It is the disciplined ability to identify
performance bottlenecks and to frame the right question before chasing an
answer. In the early 1900s, many tinkerers were racing to build flying
machines. Most of them worked on making engines powerful enough to
launch heavier-than-air vehicles. The Wright brothers, instead, were curious
about solving for control and stability before focusing on speed and power.
This focus on controlled flight rather than brute force propulsion helped
them achieve better results with cheaper and faster iterations, ultimately
leading to the first successful powered flight.
When generating answers is no longer expensive, the cost of exploration
declines, and the opportunity cost of misdirected exploration rises. In other
words, the economic value of curiosity increases because a well-framed
inquiry helps concentrate resources on high-leverage targets. During the
Manhattan Project, scientists had two competing paths to a nuclear bomb:
either through uranium enrichment or through plutonium-based implosion.
Instead of asking, "Which material will reach critical mass faster?" they
asked, "What pathways minimize unknown failure modes under time
pressure?" This well-framed inquiry helped them redirect exploration and
reallocate their focus, maximizing the chances of success. The better the
initial inquiry, the lower the probability of burning resources chasing
irrelevant possibilities.
Conversely, if you haven't crafted the right path of inquiry, you could sit
with an AI tool and waste time and resources wandering through plausible
answers without a clear destination. Without the right path of inquiry,
abundance can flip from an asset to a liability. An organization's scarce
cognitive resources are wasted in evaluating irrelevant options.
Curiosity, then, has a dual economic function. It amplifies upside by
focusing exploration where breakthroughs are more likely to occur. It
protects downside by cutting short wasted exploration and eliminating
dead-end pursuits early.

Curiosity can help us narrow down the solution space, but even within this
compressed solution space, we still need to identify what is most relevant.
This is where curation comes in.
We often associate curation with organizing and categorizing, putting
things in order so that they can easily be browsed. But curation is more
about deciding what to elevate and what to exclude. A museum curator's job
is to choose what matters. To pick a few pieces out of thousands and frame
them in a way that tells a story. And, more importantly, to deliberately leave
out everything that would dilute or confuse the experience. Good curation
filters noise and focuses attention.
Algorithms also curate - Amazon's recommendations and Instagram's feeds
already decide what to elevate and what to exclude - but algorithmic
curation only controls the visibility of information. Curation that commands
economic value is less focused on controlling the visibility of information
and more on exercising narrative control. Narrative control holds economic
value because it directs attention and influences what people act on, not just
what they see. As data analytics gained momentum in the early 2010s,
storytelling gained value. Data scientists who could tell good stories walked
onto the TED stage. Analytics was abundant, but good storytelling - the art
of curating which correlations to elevate and which ones to exclude - was
scarce. In the age of AI, narrative control through curation will be more
valuable than ever, preserving a distinctly human advantage.
Curation creates power through another important mechanism: it lets
workers reimagine which parts of their job to elevate or discard. It becomes
a tool for proactive unbundling by shedding tasks that are losing value and
rebundling by defining and claiming new, higher-value responsibilities.
Before the rise of the internet, a magician was as good as his ability to
protect his secrets. A master illusionist could spend years perfecting a
sleight of hand and, if they protected it, live off that secret for life. Magic
followed a simple economic rule: hard to learn, easy to sell.
Magicians thrive on secrecy. A well-guarded trick could sustain a career.
With the internet, a whole new category of 'deconstructors' emerged, who
specialize in breaking down magic tricks. Tricks now lose value faster, even

though mastering them still takes years. Magicians could try to outpace the
deconstructors, forever learning new tricks, but that's a losing game, much
like endlessly reskilling to stay ahead of AI.
Economic value moves, instead, to curating a performance around the trick.
Magicians today rebundle old illusions with new stories and glitzy spectacle
in ways that continue to surprise the audience. These magicians exercise
narrative control through curation. They decide which elements of
performance hold value and innovate by combining familiar elements in
new stories. In creating elaborate performances, their real trick isn't the
illusion, as much as the large-scale misdirection where they distract
audiences through storytelling and dramatic spectacle. When a trick still
takes years to master but loses its value as soon as it is deconstructed, it's
far more effective to invest in rebundling than in reskilling or learning new
tricks.
You might think magic has little to do with modern work, but the
economics are strikingly similar. As knowledge becomes commoditized,
individuals who pride themselves on carefully acquired skills will see the
economic value of those skills decline. The ability to identify new
constraints, curate complementary capabilities, and rebundle them with
narrative control will serve as the basis of new advantage.
Rebundling the economy
The sommelier's role wasn't saved by skill. It was reinvented to manage
shifting constraints. When AI unbundles your job and offers cheaper
substitutes for skilled tasks that previously held high economic value, value
doesn't come from chasing the next skill AI can't yet master, or from
endlessly reskilling in the hope that relevance can be preserved. That's a
race without a finish line. Value now comes from identifying the new
constraint that emerges in the system and rebundling capabilities around it
in ways that restore coherence and trust.

The logic we've used to understand how individual jobs are restructured in
response to shifting constraints applies just as powerfully to entire firms.
Just as workers must rebundle their capabilities around new constraints to
stay relevant, companies must rebundle their workflows, offerings, and
ecosystems around the new friction points that emerge as technology
collapses old ones. When AI removes a scarcity, reduces execution cost, or
simplifies access, the firms that thrive aren't the ones that double down on
what they used to do best. The firms that thrive, instead, proactively
reposition themselves to manage the new constraints introduced by
abundance. The sommelier thrived by owning the customer's moment of
uncertainty. The same principle can guide us in reimagining business
models in the age of AI: follow the constraint, and rebundle around it. This
strategy plays out at every level of the system of work - at the level of jobs,
yes, but also at the level of workflows, organizations, and business models.
The transformation of the music industry illustrates how new business
models emerge in response to addressing new constraints. With the rise of
piracy, recording studios that had primarily seen themselves as sellers of
album bundles watched their margins erode, powerless to stop the flood.
Music became unbundled, abundant, cheap, and easily copied. The old
scarcity of physical access to music had collapsed, but that didn't eliminate
constraints; it just introduced new ones.
In many ways, the iPod was the biggest winner of the music piracy era. But
it was an unlikely success. It was a late entrant in a market that usually
favored early movers. While competitors focused on the device, Apple
focused on the constraints introduced by music piracy.
At the time, digital music was abundant, often pirated and free. Despite this
abundance, accessing, owning, and managing music was broken and
fragmented. Finding, downloading, and transferring songs to a music player
was a cumbersome and disjointed process, with no player addressing the
coordination gaps. Piracy was heavily litigated, introducing new risks
associated with consuming pirated music. iTunes changed that by offering a
catalog of over 200,000 songs at $0.99 each and tightly integrating it with
the iPod's interface. Piracy made music free, but Apple removed the
friction, eliminating the hassle and risk associated with pirated music. The

real value wasn't in the songs but in the rebundling of discovery, access,
and playback into one integrated system. Apple rebundled the entire digital
music experience around the user. The abundance of music introduced new
constraints of risk and coordination, and the iPod resolved these new risks
and coordination breakdowns.
Fig. 5.5: Apple rebundled discovery, access, and playback into one
integrated system
Apple's rebundling improved the user experience, and more importantly, it
redefined the business model. In a value chain where recorded music had
become commoditized, Apple sidestepped the collapsing margins of the
music industry and captured value elsewhere. By turning songs into cheap
complements, Apple positioned the iPod as the premium product, the
anchor of the ecosystem, and the solution to most of its constraints. Each
99-cent song deepened the customer's commitment to Apple's platform,
locking users into the ecosystem and enabling Apple to charge a premium
that no other MP3 player could match.
Apple had shifted the basis of competition. Other music players or MP3
stores were competing based on the size of their catalog or download speed.
Apple's competitive advantage was built on an astute understanding of
which components were losing value and which ones were harnessing it.
The iPod's hardware and its proprietary integration with the iTunes store

and song catalog created a frictionless, integrated experience for users.
Industry boundaries had given way. Value created in the traditional music
industry and made available through the iTunes store was driving value
capture in the consumer electronics industry.
The rise of AI presents opportunities to reimagine the system of work at
every level, not just in terms of jobs, but also at the level of entire business
models. The workflows that organize those tasks towards creating value and
the organizations that organize those workflows towards creating value for
the firm reorganize and rebundle as well. That's where we turn our attention
next.
OceanofPDF.com


OceanofPDF.com


OceanofPDF.com

I
6
REBUNDLING THE ORGANIZATION
WHAT IF AI WASN'T YOUR NEXT HIRE BUT YOUR NEXT REORG
n the mid-2000s, soccer club Real Madrid had assembled what many
called the greatest team ever assembled, boasting the likes of Zidane,
Ronaldo, Beckham, and Figo. The team was unstoppable on paper, with
every player capable of winning games on their own. The sports media
referred to them as GalÃ¡cticos, or "galactic beings," to describe this
assembly of stars. Yet, the team repeatedly faltered and struggled against
lesser teams operating on a fraction of their payroll. The most expensive
experiment in football history produced results that ranged from merely
adequate to genuinely disappointing. Football theorists and fans were left
scrambling for explanations to account for the bizarre disconnect between
the promise of the individual capabilities of these players and the reality of
their collective performance.
Real Madrid's GalÃ¡cticos were built around superstar talent, each given
freedom to play their own game. Despite this autonomy, the team lacked
coordination. There was no clear defensive plan. Possession looked aimless.
Players overlapped in roles on the field, everyone optimizing their
individual play. Yet, without structure and coordination, no one was
optimizing the team's performance. The most talented team in the world
failed to deliver results.

Organizations often fall prey to the dangerous fallacy that freedom and
structure represent opposing forces and that more of one means less of the
other. 
This 
illusion 
cost 
Real 
Madrid's 
GalÃ¡cticos 
years 
of
underperformance despite assembling generational talents in Zidane,
Beckham, Ronaldo, and Figo.
Barcelona, meanwhile, under Guardiola's stewardship, demonstrated that
the very opposite was, in fact, true. Structure, when thoughtfully designed,
doesn't constrain freedom but dramatically expands it. Structure,
paradoxically, unlocks team-level brilliance even in the absence of
individual stars.
Guardiola's Barcelona gave immense tactical freedom to players like Messi
and Iniesta but enforced strict coordination through the concept of
positional play - a system of play where players have freedom on the ball
but must maintain precise spacing off it to ensure constant team balance and
structure. Guardiola's system emphasized spatial coordination across the
field, dividing it into zones where players operated with positional
discipline, ensuring the team constantly maintained optimal spacing.
Players were trained on where to pass and where to stand when they didn't
have the ball. Every player had autonomy within their zone, but their
overall play was coordinated through a shared structure. Coordination
didn't constrain autonomy as many commonly think; it amplified it.
Barcelona's success through positional play reveals a universal property of
complex systems: coordination doesn't hold back individual performance;
it's the precondition for collective performance. And yet, most organizations
fail to design for it. That's because we tend to think of coordination as a set
of explicit rituals - meetings, communication, and processes - that distract
us from getting actual work done. But in complex systems, coordination is
largely invisible and implicit. Coordination is not just how players pass the
ball or how teams communicate. It's the shared mental model of the field,
where everyone knows where they will be when the ball is passed.
The more specialized and autonomous each part of the system becomes, the
more challenging coordination becomes. Everyone does their job, but the
system still fails to function well. This is the paradox of talent in complex

systems: systems fail despite individual excellence. Real Madrid failed not
because its players lacked skill but because they lacked a shared framework
for coordination. Barcelona succeeded by incorporating coordination into
the design of the game itself.
This principle extends far beyond sports to all forms of organizational work.
Like star players who don't pass the ball, expert teams can focus on their
own goals and end up pulling the organization in different directions. They
create islands of excellence but make the larger organization less effective.
When organizations pay for coordination failure
Sports teams struggle when coordination breaks down within the team.
Organizations, however, must contend with coordination failures at two
levels: failures within the team and failures in coordination across teams
that comprise the organization.
When someone on a team underperforms, it's easy to detect and manage
that through hiring or performance reviews. However, coordination failures
between teams are often harder to detect, and the consequences can be
huge. Perhaps no example illustrates this more dramatically than NASA's
Mars Climate Orbiter mission, where the world's most sophisticated
engineering organization discovered that a coordination gap between expert
teams can compromise the entire mission.
At around 9:00 AM on September 23, 1999, a small group of engineers
huddled in NASA's Pasadena laboratory, tracking the trajectory of the Mars
Climate Orbiter. The spacecraft was executing its final maneuver as it
approached Mars. This was meant to be routine; no real drama expected.
Then, without warning, the signal went dead.
The engineers waited for the screen to spring back to life - perhaps the
signal was temporarily lost due to Mars' atmospheric interference. But it
never came back. The $125 million spacecraft had disintegrated in Mars'
thin atmosphere.

This wasn't the kind of failure you'd expect from NASA, an organization
that'd planned for every contingency and simulated every scenario. The
Mars Climate Orbiter used small thrusters to adjust its orientation in space.
Every time these thrusters fired, they nudged the spacecraft slightly, helping
it stay on course. Two teams were involved in managing this: Lockheed
Martin, the aerospace contractor on the project, calculated the amount of
force these firings produced, and NASA's Jet Propulsion Laboratory (JPL),
the group in charge of navigating the spacecraft through space, used that
data to adjust the spacecraft's course.
The problem, though, was that the Lockheed team had done the math in
pound-force. The JPL team assumed that it was in Newtons. The numbers
were off by a factor of 4.45, but because the discrepancy wasn't glaring,
both figures sat comfortably in the same ballpark - nothing seemed out of
place. Each team trusted the other's competence. After all, these were
experts working with experts.
However, over millions of miles, even tiny errors add up. With each
adjustment, the spacecraft drifted slightly off course. By the time it neared
Mars, the navigation system believed it was in the right position. In reality,
it was way too close. When it tried to enter orbit, it hit the planet's thin
atmosphere and disintegrated. Lockheed Martin and NASA's JPL each
performed their roles effectively. But they worked in isolation, each focused
on their individual segment of the mission. The teams didn't align on a
fundamental assumption, and that lack of coordination brought the entire
project down.
NASA paid for coordination with $125 million. The stakes may not always
be that high, but coordination is the reason that great products fail and
complex systems collapse. When coordination fails, no amount of expertise
can bridge the gap. Talent addresses complexity within teams. Coordination
solves the complexity between them.
Even the most talented teams can fail without the right coordination. But in
the age of AI, we might finally have the tools to solve this problem for
good.

Like two pizzas in a pod
At the time of the Climate Orbiter disaster, Jeff Bezos hadn't yet started
sending spaceships to Mars. Amazon was still a scrappy startup of sorts,
and Bezos was busy advocating what is now widely referred to as the two-
pizza team rule. Internal teams at Amazon would always try to be small
enough that two pizzas could feed everyone.
To anyone who's worked in a large organization, the advantage of small
teams is obvious - less time wasted deliberating and negotiating, and more
time spent getting actual work done.
In theory, smaller teams have another advantage. Because they can't do
everything themselves, they're forced to specialize. This focus forces them
to be more modular and set up their work in a way that integrates easily into
larger organizational workflows. To build anything meaningful, they have
to coordinate with other teams. If you get that coordination right, small
teams become powerful engines for scaling. And if that coordination
mechanism scales, the organization can scale by multiplying the number of
small, autonomous teams it has. Amazon seems to have achieved this
through deliberate effort. By the 2010s, the gospel of small teams had
spread far beyond Seattle. Companies chasing faster innovation - Spotify's
'squads' or Coinbase's pods - all bet on smaller, autonomous teams to drive
speed and focus.
However, many of these companies would soon realize that autonomy
doesn't come without a cost. It introduces a trade-off.
The autonomy-coordination trade-off
The more autonomy you give to teams, the harder it becomes to coordinate
across them. When Spotify was small, team autonomy worked well.
However, as the company expanded and the number of independent teams
increased, keeping them all coordinated became a greater challenge.

An organization, whether a traditional hierarchy, a loose network of
collaborators, or something in between, creates value by aligning the efforts
of its teams toward a common goal. Every organization needs to manage
this tension between autonomy and coordination. Autonomy helps teams
move fast. They make decisions without waiting for approvals. However,
when teams have too much autonomy, they often optimize for their
individual goals and struggle to coordinate effectively. Productivity looks
good on paper, but the organization struggles because team outputs don't
align. If every team prioritizes its individual autonomy, coordination
problems arise, as seen in the case of Spotify. While the organizational
headcount grows linearly, the complexity of coordinating these disjointed
teams escalates exponentially. Teams may achieve their individual goals,
but the organization as a whole struggles to do so. On the other hand,
excessive coordination kills innovation and agility. Teams spend more time
aligning and reporting than actually doing the work.
To get work done, organizations need to achieve two things:
Get work done within teams (achieve team-level output through
autonomy), and
Get work done across teams (achieve organization-level output
through coordination).
Managing the autonomy-coordination trade-off has always felt like riding a
seesaw. Lean too far in one direction, and you lose your footing on the
other. Even the constant effort to find the perfect balance keeps you trapped
within the confines of the trade-off itself - gain here, lose there.

Fig. 6.1: The autonomy-coordination trade-off
AI offers us a way out of this old problem. Instead of trying to balance the
seesaw, as past efforts have, it removes the trade-off altogether. When an
organization uses AI as a technology of coordination, greater autonomy
drives better coordination, and effective coordination, in turn, enhances
autonomy, creating a self-reinforcing flywheel. This chapter examines this
powerful yet poorly understood impact of AI on organizations, particularly
those focused on knowledge work. Two breakthroughs are especially
important: the ability of AI models to extract structured information from
unstructured sources, and the ability to use that intelligence for agentic
execution. Together, these capabilities demonstrate early signs of how AI
transforms the way teams work internally and how those teams connect
with other teams across organizations.
Coordination - Getting work done across teams
To truly understand how AI transforms coordination, we must examine how
organizations have historically managed internal knowledge to facilitate
effective coordination of work.

When we think of technologies that have shaped the rise of modern
knowledge work organizations, our minds often jump to computers and
information technology. Yet one invention is frequently overlooked: the
vertical filing cabinet. Born in the 1890s, this relatively 'dumb' technology
revolutionized organizational information management long before the
digital age. Yet, much like the container or the barcode, the filing cabinet
doesn't always get its due.
The genius of the filing cabinet was its ability to turn unorganized, scattered
piles of paper into an organized system. By letting these papers stand
upright and eventually organizing them through files and folders, it made it
easy to find and retrieve what was needed. This storage and retrieval system
is the basis of all modern information processing, including the computer,
which itself continues to employ the files and folders terminology from the
days of the filing cabinet.
The importance of managing organizational knowledge cannot be
emphasized 
enough. 
Organizational 
knowledge 
is 
the 
collective
understanding and expertise distributed across teams that, when effectively
synthesized, enables these different teams to work together effectively, even
when they're focused on different things. Think of organizational
knowledge as the shared brainpower of a company, the insights and know-
how scattered across different teams that need to be connected to make
smart decisions. Take a software company building a new product. The
engineering team builds the core features, the customer support team hears
daily complaints, and marketing runs tests to drive demand. However, if
each team keeps its knowledge to itself, engineers might build features that
no one asked for, marketing might overpromise, and support might continue
to address the same problems reactively instead of getting engineering to fix
them proactively. When teams don't share what they know, they end up
solving problems in isolation and can't effectively build off each other's
insights. Efforts get duplicated, and the entire organization slows down.
However, when organizational knowledge is effectively managed, everyone
pulls in the same direction.

Organizational coordination and knowledge
management
If you've ever worked in a large organization, you know the real challenge
isn't finding information - it's finding the right information at the right time.
It's the report buried under "Final_Draft_3," the key insight trapped in
someone's head, or the brilliant idea lost in a Slack thread. The challenge
isn't a lack of information; it's the ability to access the right information at
the right time so that you can act on it.
In many ways, the vertical filing cabinet solved this problem. It stored and
managed institutional memory. But it also created a powerful division of
knowledge work in the organization. On one side were the knowledge
workers - the engineers, executives, and analysts - tasked with solving
problems and generating value. On the other side were the clerical and
administrative staff, who made sure those records and decisions were
captured, filed, and retrievable when needed. This separation enabled the
organization to scale effectively, as highly skilled workers could focus on
their areas of expertise while the clerical staff ensured that the information
infrastructure remained intact and operational. The clerical roles weren't
glamorous, but they were essential. They ensured that knowledge didn't
stay locked in a lost file in someone's desk drawer and that the right
information could be found at the right time.
We've come a long way from the vertical filing cabinet. As information
grew in volume and complexity, we upgraded from metal drawers to
databases, spreadsheets, and a host of productivity solutions. Yet, despite
access to more shiny tools, organizational knowledge management remains
stuck in the dark ages. And that inefficiency imposes hidden costs on the
organization. To coordinate, teams need to constantly spend time in
redundant meetings, invest effort in chasing down documents, and drain
mental bandwidth just trying to stay 'in the loop.' This is the coordination
tax: the silent cost that grows exponentially as organizations scale. The
larger the company, and the less effectively its internal knowledge is
managed, the higher the tax. Every meeting to 'get everyone on the same

page,' every email thread clarifying decisions that should have been
obvious - that's the coordination tax collecting its dues.
To understand how the coordination tax accumulates in an organization, it's
essential to identify the three distinct types of activities involved in
knowledge management: encoding knowledge, organizing it, and deploying
it. Every step imposes a different form of internal cost on the organization.
First, knowledge management starts with encoding knowledge by
documenting processes and capturing lessons learned. It's the side hustle of
every highly paid knowledge worker, done alongside their real job. A
programmer writes code, but also documents it so others can build on their
work. A consultant solves a client's problem, but also packages the process
into templates, so the firm doesn't lose the method behind the solution. All
of this, while necessary, imposes an opportunity cost, pulling smart people
away from other high-value work that they could work on.
Next, there's the act of organizing that knowledge. Until recently, most
'knowledge management tools' were just digital filing cabinets with better
search functions. They could store mountains of data and help you find a
lost report, but they couldn't do the hard part of making sense of the
scattered charts, forgotten emails, and contracts and turning them into
something useful - a clear, shared understanding that helps people work
together. You couldn't just query this knowledge like you would a database.
This is where so-called bullshit jobs - as coined by anthropologist David
Graeber - take on unexpected importance. Often dismissed as mere 'paper-
pushers,' many clerical and administrative roles are the unsung heroes of
organizing and synthesizing knowledge. They help categorize and organize
fragmented information, enabling easy retrieval and access. This imposes a
separate coordination tax on the organization, which must now hire armies
of workers to manage knowledge through slow and imperfect processes.
Finally, the third and most important aspect of deploying knowledge
involves making sense of internal knowledge to drive decision-making.
Organizations rely on a range of mechanisms to deploy knowledge today -
endless meetings, chats, emails - all to recreate lost context. In early 2023,
Shopify made headlines by canceling all recurring meetings with more than

two people, eliminating 76,500 hours of meetings in one stroke. It sounds
like a bold move, but it risks attacking a symptom rather than solving the
underlying coordination problem. You can't eliminate the coordination tax
by eliminating meetings. Pre-scheduled meetings, even if repetitive, act as
insurance 
against 
collaboration 
breakdowns 
and 
ensure 
forced
accountability between teams. When knowledge isn't properly managed
and deployed, organizations rely on meetings as a crutch to rebuild shared
context. Until organizations address this issue of knowledge management,
the coordination tax will always find a way to collect, even without
meetings.
Eliminating the coordination tax using AI
Today, AI offers the first scalable antidote to the coordination tax. Unlike
older technologies that could only manage and work with structured
information, AI doesn't care if your data is neatly labeled or buried in a
Zoom recording. Generative AI's ability to convert unstructured
information into structured knowledge transforms how organizations create,
store, and use knowledge. Feed it a software program, architectural
drawing, or past analyst reports, and it automatically generates
documentation, templates, and methodologies. AI can help transform
unstructured inputs, such as voice notes or phone calls, into searchable
insights. Insights that would have previously been lost in casual
conversations or remained locked in individual minds are added to
institutional memory.
In doing this, AI helps codify previously tacit knowledge and makes it
usable across the organization. This eliminates much of the clerical burden
that knowledge workers face. Instead of spending time documenting and
codifying best practices, they can focus on analysis, judgment, and
problem-solving. With models trained on internal data, knowledge becomes
easily accessible, often one well-crafted prompt away, and can be
proactively served into relevant workflows even when not explicitly
requested by workers. Most importantly, AI tackles the most challenging
part of knowledge work: the synthesis and deployment of organization-wide

knowledge. It integrates scattered data, tacit understanding, and formal
documentation into actionable insights.
Trained on organizational information, AI can learn the unique language,
patterns, and preferences of a firm - how the firm frames decisions and
weighs trade-offs. Because of its ability to summarize and generate insights,
generative AI is more suited to managing organizational knowledge than it
is to out-competing Shakespeare or Tarantino. And it is this very property
that makes it so effective at dismantling the coordination tax.
In 2024, Google's NotebookLM - an AI tool aimed at serving writers -
launched a feature that could turn any text into a podcast. With one click,
users could upload text and generate entire conversations between two
voices, sounding as natural as a real podcast. Content creators rushed to
transform their work, and internet pundits declared it a revolution in content
creation. But all this excitement about AI-generated podcasts masks its
more strategic benefit in organizing and interpreting institutional
knowledge.
Ramp, a finance automation provider that helps businesses automate
expense categorization, invoice negotiations, and bill payments using AI,
illustrates how this works. Ramp's customer support teams handle
thousands of hours of conversations every week. They capture valuable
customer insights, which often remain trapped in audio files. With AI's
ability to convert unstructured data into engaging podcasts, Ramp started
creating auto-generated five-minute podcasts that distilled the most
important things customers are saying. Any team across engineering,
product, or marketing could instantly tune into the authentic voice of the
customer, without waiting for filtered reports. AI-generated summaries can
be fine-tuned to focus on a specific customer segment, a persona, or a
recurring theme. An AI analyzing angry customer calls could create a fun
podcast to discuss customer complaints without targeting blame at specific
teams. Autonomous podcast generation may capture the fancy of internet
pundits for an entirely other reason, but at Ramp, it helps employees across
the organization access the voice of the customer during their morning
commute.

These are some ways in which AI can eliminate the coordination tax.
Previous technologies would do this by making existing processes faster.
With constantly improving AI capabilities, our ability to reimagine how
work is organized is only limited by our ingenuity. We've treated the
coordination tax as inevitable - a cost of doing business in large
organizations, but it's not. The coordination tax might have finally met its
match.
Getting work done within teams
Ramp is best known for transforming how its customers' finance teams
operate, but what's less visible is how it restructured the way its own teams
work internally.
In the early days at Ramp, long before it began auto-generating podcasts of
complaining customers, the company was seeking ways to close more deals
and grow its business. Curiously, one sales representative, in particular, was
booking meetings at a rate far higher than his peers - double, sometimes
triple, the average. Ramp's leadership watched in awe but also with
growing frustration - they wanted everyone else on the sales team to
perform at the same level. Rather than shrugging it off as raw talent, they
pulled a few engineers off their regular work and had them shadow this
super-sales-rep and observe his craft. He'd start by scanning for companies
that'd just raised funding and look for job changes on LinkedIn, picking up
signals of potential customers who might be interested in buying their
product. He'd then spend hours manually hunting down email addresses and
testing different message variations. The engineers discovered something
surprising. The sales rep's genius wasn't in what he did but in how much of
it he was willing to do alone. Thousands of small tasks, executed
relentlessly, helped him outwork the others.
The team didn't try to replicate the rep's behavior. They tried to develop a
workflow that would achieve the same goal of finding high-quality
prospects. But instead of relying on manual execution, the engineers could
scale the rep's work through agentic execution. The engineers created AI

agents to monitor funding news, wrote scripts to extract email addresses,
and automated tests to refine message templates. However, instead of
relying on a human to pull these levers, they connected all the parts into a
workflow that could run autonomously. This is the concept of an agentic
workflow - a goal-oriented system comprising multiple AI agents and tools
that execute a chain of decisions and actions semi-autonomously, without
requiring human input at each step.
Agentic execution changes how work gets done within teams. Complex
knowledge work once relied on humans to set goals and allocate resources
to accomplish them. While automation would help execute individual tasks,
moving all those tasks forward to achieve the goal still required human
oversight. Agentic execution promises to address that. That said, it's
important not to overlook the value of assistive execution, where AI tools
improve coordination by reducing cognitive load and improving decision-
making. In practice, both assistive and agentic modes can work together.
Assistive tools enhance decision support and may alter where and how
decisions are made within the organization; agentic execution, on the other
hand, completely restructures how work is done. Before diving too deep
into the promise of agentic execution, it's also worth pausing to separate
signal from hype. Not every AI tool that claims to be agentic truly is. Many
tools automate discrete tasks but still depend heavily on human
coordination. Even if they're sold as 'agentic' solutions, they fail the test of
agentic execution.
Goal orientation is key to agentic execution and the fundamental property
that sets it apart from traditional automation. Let's illustrate the idea of goal
orientation with a simple example. If you're planning a trip through an
unfamiliar city, you have two options. You could follow a detailed itinerary
with every stop and turn mapped out, or navigate with just a destination in
mind, making decisions as you go based on traffic, weather, and interesting
discoveries along the way. Most automation works like the former, using
pre-defined logic. Agentic execution, by contrast, can observe changes in
context, adapt actions in response, evaluate results, and decide what to do
next - all the while remaining focused on the destination, the end goal.

This difference between traditional automation and agentic execution is also
illustrated by the difference in how Google Search used to work in the past
and how ChatGPT's Deep Research works today. With Google Search, you
ask a question and get a list of links. You still have to read through the
results, figure out what's useful, connect the dots, and decide what to do
next. You're doing all the coordination by jumping between tabs, comparing
sources, and pulling everything together. ChatGPT's Deep Research is
different. You give it a goal, and once it understands the details, it takes
over from there. It breaks down the problem, gathers information in the
background, summarizes key ideas, identifies what's missing, and updates
the output constantly. Google Search's assistive execution still leaves
workflow coordination gaps with the worker. Deep Research's agentic
execution eliminates those coordination gaps.
Ramp's growth exploded with agentic execution, as its sales reps could now
book meetings at a pace that competitors couldn't easily match. Their
competitors never saw it coming. While they were busy hiring more sales
representatives and refining their sales playbooks, Ramp was developing an
alternative system of work through agentic execution. As agents get better
at understanding and acting on knowledge, they allow organizations to
restructure themselves around faster, more modular decision-making. This
shift reduces the need for traditional hierarchies and changes how teams
organize around these agentic workflows.
Today, Ramp uses similar agentic workflows at other departments across
the company. Ramp's procurement division, for instance, uses AI to help
with vendor selection as well. Vendors are evaluated by AI agents, not just
based on their current capabilities, but based on their growth trajectory -
how quickly they're improving and where they'll be in another two years.
This mindset prevents the company from getting stuck with outdated tools
that seem like the safe choice today but become a liability in the future.
Ramp's most effective play at agentic execution, though, is not within its
own organization but in how it transforms its customers' workflows.
Managing expenses at most companies is a slow, manual process.
Employees file expense reports, upload receipts, categorize purchases, and
await approvals. Finance teams spend hours chasing missing documentation

and manually reconciling accounts. Ramp transforms these workflows with
agentic execution. Expense management is now a one-click process: AI
pulls 
receipts 
directly 
from 
employee 
inboxes, 
auto-categorizes
transactions, and routes approvals instantly. Employees no longer file
expense reports. Finance teams, once bogged down in administrative work,
now focus on strategic decisions.
To understand how transformative this is, consider the user's journey with
Ramp: an employee makes a purchase with a Ramp card, and with that, the
system takes over. Behind the scenes, Ramp's AI pulls the receipt from their
inbox, categorizes the expense, and routes it for approval. On the other
hand, the finance team receives live updates, automated reconciliations, and
alerts on spend anomalies, allowing them to focus on strategic priorities
instead of chasing paperwork.
The new organization of work
For much of the history of the modern corporation, the structure of
organizations has been defined by the cost of coordination. When
coordination is complex and expensive, firms tend to grow larger, thereby
internalizing more functions. But as new technologies simplify
coordination, those boundaries shift. The telephone made multinational
corporations feasible. Email and ERPs played a significant role in driving
outsourcing and the expansion of global supply chains. The rise of digital
platforms enabled work to be more effectively performed outside firm
boundaries, leveraging armies of freelancers.
Yet, even as new technologies improved our ability to coordinate work
beyond the boundaries of the firm, the way we managed organizational
knowledge internally remained largely unchanged. We've come a long way
from the vertical filing cabinet, but the basic structure of managing
organizational knowledge has stayed the same, whether it was a physical
cabinet or a digital one: someone created a document, someone else decided
where it should be stored, and people had to remember how to find it. Even
as companies moved from paper to spreadsheets and databases, and on to

the cloud, they were still working within the same architecture -
information stored in silos, managed manually, and accessed by people who
knew where to look.
AI changes this. It unbundles organizational knowledge from the roles and
teams in which it is created, and makes it available as a shared asset across
the organization. As knowledge is no longer confined to the roles and teams
that originated it, it is now available to be repurposed into fundamentally
new workflows. With this, the need for traditional management structures
goes down. To illustrate how this works, consider the case of Palantir, a
software company that uses AI to manage large-scale organizational
knowledge for governments and enterprises. Palantir's AI system, Foundry,
pulls information from across the organization - from emails and contracts
to sensors in the field - unbundling this unstructured information from the
systems and people who created it, and making it available as a structured
and commonly usable resource.
With structured knowledge in place, Foundry helps turn it into action by
rebundling it into new workflows. It does this by mapping the connections
between different pieces of information. For example, Foundry understands
how supply chain delays affect financial forecasts, so users don't have to
dig through folders to figure that out themselves. They can simply ask,
"How does this supplier's delay impact our quarterly revenue?" and
Foundry generates a contextual answer on the spot. This is Foundry's
assistive execution, supporting workers in making better decisions.
However, it also extends to agentic execution: once a decision is made,
Foundry can automatically manage follow-up actions, such as reallocating
inventory or adjusting production schedules, thereby reducing the need for
human intervention.
AI tools like Foundry constantly learn and enable a new system of decision-
making and execution, where the overall 'organizational brain' is
continually thinking and learning alongside individual users, and where
agentic execution fills the gaps where things would have typically slowed
down. In many ways, AI works like a brain implant for the organization. A
brain implant doesn't physically grow like a living organ, but over time, it
can feel like it does. While the device itself stays the same, its software

learns and becomes more powerful the more it interacts with the brain. In
response, the brain can also begin to change, forming new pathways to
work more smoothly with the implant. Together, they create a system that
keeps improving as an 'integrated brain'. AI, similarly, starts as a tool to
improve coordination, but gradually becomes the central engine powering
how the organization thinks, makes decisions, and runs.

Table 6.1: The AI-rebundled organizational system
From see-saws to flywheels
This chapter started with the challenge of balancing autonomy and
coordination. How can small autonomous teams more effectively
coordinate across larger organizational structures?
When AI is used to manage organizational knowledge, it can deliver the
most relevant insight directly into each team's workflow. This keeps teams
aligned without constant check-ins. As coordination improves, teams gain
the freedom to redesign their operations, structuring internal work around
agentic execution while staying connected to broader organizational goals.
These shifts lead to new team structures and workflows. And with each
change, fresh coordination challenges emerge. But because AI learns
continuously from the system it's introduced into, it can adapt and scale its
coordination in response.

Fig. 6.2: The autonomy-coordination flywheel - Better coordination
enables greater autonomy and vice versa
Three capabilities drive this transformation:
1. A shared representation of organizational knowledge across teams

2. The ability to serve the right insight to the right team at the right
time
3. The use of agentic execution to get more done within teams
Together, these capabilities create a system that enables teams to work more
effectively and efficiently over time. The benefits go well beyond what
simple automation can deliver. Most importantly, AI resolves the old
tension between autonomy and coordination. With AI-enabled coordination,
teams can stay autonomous while also being well-coordinated.
The coordination paradox
AI promises to reduce the coordination tax, but if implemented too
narrowly, it can have the opposite effect. When companies deploy AI for
isolated task automation rather than organization-wide coordination, they
introduce a paradox: the very technology meant to improve coordination
fragments the organization and increases coordination costs.
Organizations that adopt AI to improve existing processes within isolated
functions without altering how work is coordinated across these functions
may benefit from local optimization; however, the overall system remains
fragmented. The tools evolve, but the system remains disjointed.

Fig. 6.3: Al-as-automation increases the 'coordination tax'
When AI is used to enhance some functions but not others, organizations
develop uneven capabilities. Demand forecasting can operate with AI-
driven precision, while inventory management often relies on manual
processes and intuition. The faster, more reliable AI-enabled units cannot
easily synchronize with their slower, error-prone counterparts. This
increases coordination efforts as superior performance in one part of the
organization is hamstrung by bottlenecks in other parts. High-performing,
AI-enabled functions may grow impatient with slower teams. The
coordination tax increases as the organization must manage not just its
original coordination challenges, but also the new tensions created by
asymmetries in AI adoption. The resultant rise in coordination costs can
often exceed any efficiency gains derived from automation itself.
To realize AI's full potential in organizational coordination, organizations
must move beyond task automation and start leveraging AI as a

foundational infrastructure for coordination. AI's power lies not in making
individual tasks more efficient, but in making the entire system more
intelligently coordinated.
The coordinated organization
The dream of the autonomous organization - AI effortlessly running the
show - is rooted in our fascination with self-driving cars and robots. It
reflects an industrial-age obsession with efficiency, assuming that AI will
automate knowledge work in the same way machines revolutionized
factories. We've taken the logic of factory automation - faster, cheaper,
more efficient - and slapped it onto knowledge work.
As AI starts executing complex workflows autonomously, it's tempting to
believe that improvements in AI capabilities will eventually let entire
organizations operate autonomously. This is the story AI tool providers
increasingly sell us: that AI will revolutionize knowledge work the way
industrial automation revolutionized manufacturing. But there's a problem:
knowledge work isn't like factory work.

Fig. 6.4: Al-as-coordination eliminates the 'coordination tax'
Organizations aren't just collections of workflows waiting to be executed
by AI agents. They exist to help different teams with interdependencies
work together effectively, even when they have different goals or move at
different speeds. The real problem in knowledge work isn't inefficient
execution; it's coordination. The real opportunity for AI, accordingly, lies in
reducing those coordination costs, freeing cognitive capacity, and enabling
faster, better decision-making.
We misunderstand speed for progress, and automation for transformation.
But the hardest, most human problem in organizations isn't task execution,
it's coordination. AI's real promise lies in enabling new formats for
organizing work. Freed from the constraints of the past, tomorrow's
organizations will take on entirely new forms. The autonomous
organization might promise efficiency, but the coordinated organization
achieves what truly matters: better decisions and execution, alongside
tighter coordination towards a shared goal.

OceanofPDF.com


OceanofPDF.com


OceanofPDF.com

Y
7
REBUNDLING THE VALUE CHAIN
NEW BUILDING BLOCKS, NEW ECONOMIC LOGIC
ou might not have heard of Jimmy Donaldson, but you've probably
heard of MrBeast. In June 2024, his YouTube channel became the most-
followed in the world, making him one of the most influential media figures
of his generation. When he gives away a Lamborghini or reenacts Squid
Game in real life, the spectacle attracts hundreds of millions of views. So
when he announced a burger chain, few doubted it would succeed. He
already had an audience of over 100 million, and a brand that had shown it
could sell almost anything. The burgers were secondary.
Most fast-food chains spend years expanding. MrBeast Burger sidestepped
the old constraints of restaurant chains. It had no corporate kitchens, no
full-time staff, and no physical storefronts. Instead, it operated through a
network of 'ghost kitchens' - underutilized restaurant kitchens cooking food
under the MrBeast brand - and relied on third-party services for food
delivery. The business launched in 300 U.S. locations overnight. Orders
came in at a pace few restaurant chains had ever experienced, as the launch
video trended at #1 on YouTube. Locations quickly ran out of food on the
opening day, with some making as much as $7,000 on the day it launched.
Three months on, it had already sold more than a million burgers.
MrBeast had set up a business using a set of building blocks. One block for
getting orders in the door, one for cooking the food, and a third for

delivering it. MrBeast's brand, which commands one of the largest online
audiences, helped him secure the first block. The second block was offered
by Virtual Dining Concepts, which handled the ghost kitchen network,
coordinating hundreds of independent restaurants to prepare the food. The
final piece clicked into place with on-demand delivery services. Each piece
was available as a rentable capability.
Building blocks on rent
MrBeast's overnight burger empire shows that building a business today
doesn't require starting from scratch. You can assemble it from pre-made
building blocks.
Starting a business used to involve upfront investment in buying servers,
hiring teams to manage payments and support, or setting up your own
delivery network. That changed with the rise of cloud computing. Instead of
owning expensive infrastructure, businesses could now rent capabilities on
demand. Cloud services, including computing capacity and storage, were
now unbundled from the underlying infrastructure and available as building
blocks that could be used to build a business. You no longer had to own
servers, hire a payments team, or manage a fleet of drivers. You could use a
computing building block from Amazon Web Services, a payments block
from Stripe, and one for delivery from Uber. Each of these building blocks
could now be rented and recombined into new businesses.
What MrBeast did with burgers is part of a much broader pattern that
defines the modern economy. When something is unbundled, it doesn't just
break apart - it transforms into modular units that can be recombined and
rebundled. Songs unbundled from albums were rebundled as playlists.
News unbundled from publications was rebundled into article feeds.
Similarly, when capabilities are unbundled from their underlying assets and
are accessible as building blocks, they can be rebundled to create new
business models. Value shifts from owning the underlying assets to
rebundling such building blocks towards solving customer problems.
Companies like Shopify, Uber, and Lyft scaled rapidly not by building

everything in-house, but by 'renting' such building blocks, and using them
as components to assemble a new solution. The example of MrBeast Burger
demonstrates that this unbundling principle extends far beyond technology
startups. The burger chain's innovation was not in the individual modular
building blocks but in how they were recombined to create something new.
Fig. 7.1: Innovation through 'rebundling' in the 'building blocks'
economy
Cloud services provide operational capabilities as building blocks. AI is
now doing the same to many forms of expertise.
Historically, expertise and specialized knowledge were tightly bundled with
human labor - to access expertise, you had to hire, train, and manage
workers. As a result, organizations paid a premium to access knowledge,
and hit bottlenecks when they tried to scale it. AI changes this. It unbundles
expertise from the expert, turning knowledge into a capital asset rather than
a labor input. Instead of hiring someone to perform a task, you can now rent
the associated capability. A freelancer doesn't need a lawyer to draft every
contract, when an AI legal tool could help out in most cases. You don't need
a full-time writer when tools like Claude or ChatGPT generate content
instantly. The associated capabilities are now available as independent
building blocks, no longer tied to human labor.
When knowledge is unbundled from human labor and becomes accessible
as capital, it gains three essential traits. It becomes rentable, as you can

access it without long-term commitments. It becomes recombinable, since
different forms of expertise can be recombined without the overhead of
coordinating across siloed teams. And it becomes scalable: once a solution
is built, it can be deployed repeatedly at near-zero marginal cost, unlike
human labor, which scales linearly with cost.
The availability of expertise as building blocks changes productivity, but more
importantly, it changes power.
Knowledge workers who once sold their labor can now package and deploy
it as a building block. On the other hand, solopreneurs and creators gain
leverage by combining these building blocks into new businesses, as
MrBeast did. The nature of competition also changes as a result.
Capabilities bundled with underlying assets were confined to the boundaries
of a specific industry. However, as building blocks, they are now available
to be leveraged across various industries. Industry boundaries don't matter
anymore when a YouTuber can get into the restaurant business overnight by
'renting' building blocks of food preparation and food delivery.
Competition, instead, plays out in connected ecosystems where these
building blocks are now available across industry boundaries, and success is
determined not by what you own but by how well you assemble and
coordinate the building blocks that others provide.
As MrBeast demonstrated with burgers, entrepreneurship now is less about
building everything from scratch and more about recombining and
rebundling available building blocks to create a novel and differentiated
solution to a customer's problem.
This is the architecture of the building blocks economy: rentable
capabilities, recombinable systems, and scalable knowledge. Power comes
not from owning infrastructure or employing large teams, but from knowing
how to rebundle modular components into something coherent and
valuable. The boundaries between industries blur as building blocks become
universally accessible and reusable. Value shifts from production to
combination. And it also shifts from labor to leverage.

Leverage in the new economy
What differentiates Jimmy Donaldson from the average YouTuber is his
network capital - the ability to influence and mobilize a connected audience
at scale. MrBeast combines this network capital with an understanding of
online platforms; he knows what content is best suited for virality. He then
pairs this with access to building blocks, such as restaurant kitchens and
delivery, to launch entirely new businesses overnight. This playbook - the
ability to build network capital, tame the platform, and rapidly build new
businesses using available building blocks - creates a new form of leverage
for individuals, enabling the rise of solopreneurs, or one-person companies.
AI adds two new ingredients to the solopreneur's toolkit. First, it allows
individuals to leverage knowledge at scale without personally producing it.
Specific forms of expertise are now available as building blocks, and it's
easier than ever to recombine easily accessible expertise from across
domains and create something new. Second, AI enables agentic execution,
making the execution of knowledge-intensive workflows also available as a
building block. Individuals can now achieve with a swarm of agents what
only large organizations did in the past. Consider a solo-consultant
managing a pipeline of 100 different client prospects. Agents research the
context of each client, review past emails, call transcripts, and contracts,
and determine and draft the next steps to advance the project in the sales
pipeline. Agentic execution enables individuals to 'rent' execution capacity,
ranging from customer support to lead generation to video editing, and run
knowledge-intensive processes at scale without a traditional workforce.
The case of Michael Smith, although controversial for overstepping legal
boundaries, illustrates the nature of leverage created when AI-based
production and agentic execution intersect with network capital and the
workings of online platforms.
Michael Smith, an aspiring musician uploading his songs on Spotify,
recognized that Spotify's algorithms cared more about play counts than
about music quality. Royalties were paid based on streams, so more plays

across more songs meant more revenue. Smith realized that if a musician
could game the system, they could make a fortune.
Smith built an army of bots, or fake streaming accounts, using thousands of
email addresses bought in bulk. These fake accounts played his songs on
repeat, but he faced a limitation: he couldn't produce new music fast
enough. In 2018, he partnered with an AI music company to create
thousands of machine-generated songs. Rather than getting one song played
billions of times, which would trigger Spotify's fraud detection, he created
libraries of low-traffic songs, each streamed just enough to stay under the
radar. At its peak, Smith's network was generating 661,440 fake streams per
day. By the time the FBI got involved, Smith had raked in over $10 million.
Smith had exploited Spotify's algorithmically managed market. His bots
manufactured initial demand, and eventually, real listeners unknowingly
streamed his AI-generated tracks as Spotify's algorithms started
recommending the songs to them. Like MrBeast, Smith didn't build the
components; he understood the reward mechanics and designed a system to
exploit them. The leverage came not from traditional assets but from
understanding how digital platforms allocate rewards.
Dismissing Smith's grift as fraud misses the larger point: Smith
demonstrates the importance of algorithmic awareness, understanding how
algorithms operate, and leveraging the rules of the system to one's
advantage. If an algorithm rewards engagement, agentic execution - or as in
Smith's case, even unsophisticated bots - can generate that engagement.
Smith saw Spotify for what it was - a market running on numbers rather
than on taste. He created demand, using bots, and supply, utilizing AI-
generated music, to establish an entire market of activity. Curiously, Smith
manipulated a market where both demand and supply were available as
building blocks. Smith crossed legal lines, but many others will play the
same game within the rules, because today, leverage is a free-for-all. The
means of production - modular knowledge, automated workflows, scalable
digital execution - are available to anyone. And when algorithms dictate
distribution, advantage belongs to those who understand what the system
rewards.

In the old knowledge economy, expertise was the moat, and the harder it
was to acquire, the more defensible it made your business. AI severs that
link, making knowledge easy to access and hard to protect. The new moat is
leverage: the ability to deploy, recombine, and scale knowledge in ways
others can't.
Smith is an unlikely example and might polarize many. However, as AI and
algorithms increasingly influence economic activity, the lesson Smith
leaves us is that the intersection of a networked economy and a new form of
intelligence provides entirely new forms of leverage. Yet, most people may
not understand the nature of this leverage. The common mistake, then, is to
see AI merely as a tool for efficiency and use it to cut costs by reducing
headcount.
The real opportunity lies in using AI as a force multiplier that unlocks new business
models and eliminates competition altogether.
Capital vs labor
Entrepreneurial leverage comes not just from combining available building
blocks into new configurations but also from creating building blocks of
your own, by turning your unique skills into reusable components that
others can leverage. The ability to utilize AI to make various forms of
creative and knowledge work accessible in this manner introduces a new
tension: between those who gain leverage by converting their skills into
scalable assets and those who watch their skills being extracted and
commoditized by others.
One person may license their expertise as a productized service; another
may watch a platform replicate it without compensation. Two people with
similar skills can face opposite outcomes. One might lose leverage as AI
makes similar skills available as generic components anyone can use. The
other may harness the same shift to package and scale their skill, building a
business around it. It's not about how 'uniquely human' your talent is as
much as it is about whether you can shape it into a differentiated building

block that commands a premium. AI may reduce one worker to an
interchangeable input while turning another, similarly skilled worker, into a
successful entrepreneur. The difference lies in whether the worker controls
the creation of the capability, the ability to direct its use, or neither of these.
The 2023 SAG-AFTRA Union strikes by actors in the United States provide
us with further clues. Studios see AI as a tool to gain leverage in
production. Background actors feel it's more of an eviction notice. The
tried-and-tested economic model, where actors perform and get paid, no
longer stands. Studios are increasingly scanning background actors,
capturing their faces and movements to create digital replicas. A single
body scan - hands up, hands down, scared face, surprised face - can be
turned into a digital double. The actor's likeness is now available as a
building block that replicates their presence and can be infinitely replicated
across all future scenes without additional pay.
This ability to commoditize an actor, and more broadly, any worker, creates
a classic tension between capital and labor. The ability to unbundle the
actor's likeness from the actor, transform it into a separate building block,
and replicate it infinitely through generative means allows studios to create
output that would have traditionally required the actor's labor. Once
scanned, an actor's likeness can be deployed across an infinite number of
scenes without residuals or rehiring costs - infinite extras, zero payroll.
Why pay for a reshoot when AI can generate an adjusted performance?
Acting, a uniquely human advantage, becomes a commodity owned by
studios, not by the artists themselves. What matters then is the leverage that
the background actor has on how these building blocks of their likeness are
used. Are they appropriately compensated every time it's used? Or do the
studios simply capture it once and use it at will?
This tension has already declared winners and losers in another corner of
the industry: voice acting. Unlike background actors, who at least need to
be scanned and can negotiate at that moment, voice actors often have no
such leverage. They don't need to show up at all. With just a few minutes of
audio, AI tools can now replicate voices with stunning accuracy. Gayanne
Potter, one of Britain's most recognizable voices, learnt to her dismay that
ScotRail's AI-generated announcements were trained on her voice, without

her permission. Curiouser still, the rights to use her voice for training AI
had been signed off several years earlier as part of an unrelated project with
a Swedish company, ReadSpeaker. Once trained, a synthetic voice can read
complete scripts, convey emotional nuance, and adjust tone mid-sentence,
all without the actor's involvement, as Potter figured to her dismay.
The skills of background and voice actors have been turned into building
blocks - rented, remixed, and reused by the studios that once employed
them. The voice, like the face, becomes an asset detached from the
performer. Without rights, residuals, or control, the worker becomes a one-
time input in a machine that runs indefinitely. Their fate is shaped less by
talent and more by their power. Without a strong personal brand or network
capital, their income had traditionally been tied to the fact that their skills
had to be delivered in person. Once AI unbundles that dependency, their
leverage disappears.
Contrast that with the case of 'actors' whose leverage is primarily
determined by their network capital. An unlikely example that illustrates
this rather colorfully is the case of the OnlyFans model. OnlyFans is a
subscription-based platform where actors and other content creators share
exclusive content directly with paying fans. The most successful social
media platform since TikTok, its core appeal lies in the personalized,
interactive connection between creators and their audience. Often
associated with hosting adult content, OnlyFans also hosts other creators,
including celebrities like DJ Khaled, Drea De Matteo, and several Olympic
medalists.
As AI-generated avatars become more lifelike, OnlyFans creators face the
same question confronting many workers: will AI amplify their value or
replace them? Unlike background actors, OnlyFans creators have network
capital in the relationships they've built with fans across various platforms.
That gives them an advantage, but it doesn't guarantee success. To utilize
AI for leverage, they must distinguish between where they use their
likeness and where they use their real persona, separating routine
interactions and generic content that can be commoditized from premium
interactions that remain personal and involve the creator's presence. Done
right, AI avatars become complements, not threats, that scale the creator's

reach without eating into the value associated with their presence. OnlyFans
models already utilize other sources of fan engagement to complement their
own activities, a trend that can be further extended with lifelike AI avatars.
According to an exposÃ© in Wired Magazine, many creators outsource their
chats with paying fans to chat specialists. Unlike background actors, whose
likeness becomes a studio-owned asset, successful creators can design
systems that allow their AI-generated likeness to still point back to them.
Combining network capital with the ability to multiply access to your skills
allows individuals to scale in new ways. If the background actor is scanned
once and left behind, the OnlyFans creator who succeeds will be the one
who designs the system so that the scanned avatar always points back to
them.
A theory of advantage
With business capabilities available as building blocks, the advantage lies in
three broad areas -
1. How well you rebundle these components to create new solutions,
2. How well you scale these solutions using the leverage offered by
the underlying capabilities, and
3. How well you understand the logic of the platforms and markets
you operate within and use them to your advantage.
MrBeast's burger chain exemplifies the first aspect, leveraging kitchens and
delivery services as commodity components and rebundling them into a
new offering. Yet, as we'll shortly see, rebundling involves not just
assembling components but also ensuring that the new system created as a
result performs well.
The second factor - scaling through leverage - is best illustrated by
OnlyFans creators, who operate like micro-firms, outsourcing interactions
today and possibly deploying AI avatars in the future. AI-enabled
solopreneurs, armed with tools for content creation, outreach, and analytics,

can also similarly build high-output operations without relying on
traditional infrastructure.
Finally, understanding how a system allocates visibility and rewards
activity, and leveraging that to your advantage, is key. Michael Smith's
exploitation of Spotify focused on what the algorithm measured and
reverse-engineered a strategy towards it. Reading the system and designing
with it rather than against it is key to outmaneuvering others who may have
superior skills but lack algorithmic awareness.
Together, these three forms of advantage constitute a playbook for
entrepreneurship in the economy of building blocks. But none of them
function without a fourth element: management of constraints.
While it's easy to assemble something new using building blocks, its
performance depends on a few critical constraints. If these constraints aren't
identified and managed, the system may break down, often without anyone
being held accountable for the failure. The ease of assembling building
blocks blinds us to the fact that the new system can fail even if the
individual parts work correctly.
Failure to manage constraints
The story of MrBeast Burger doesn't end with its launch. Despite his viral
launch and massive audience, cracks began to show in the MrBeast Burger
story. The same ghost kitchens that allowed him to scale overnight soon
became the source of his biggest headache. Customers across the U.S.
began to complain: the burgers were cold and the fries soggy. One reviewer
posted a video comparing burgers from three different locations, and none
of them looked alike. MrBeast sued Virtual Dining Concepts, the restaurant
operator, claiming they had tarnished his brand.
MrBeast Burger had bundled demand generation, operations, and logistics
into a fully formed solution. However, such rebundling is successful only if
the new solution is effective. Plugging together various pieces isn't enough
- the performance of the new solution depends on how the pieces fit and

how well the solution as a whole is managed. The more you rely on external
pieces, the more critical it is to manage the constraints that determine the
performance of the new solution.
A constraint is the limiting factor in a system - the point where the system's
performance breaks down or its quality deteriorates if not actively managed.
When business capabilities, and now even knowledge, can be rented like
building blocks, the real advantage no longer comes from owning the parts.
It comes from how well you put them together to create cohesive solutions.
In such rebundled businesses built from rented capabilities, a constraint is
often the weakest link between components, not any of the components
themselves.
In MrBeast's burger venture, access to demand wasn't the core constraint;
he had that in spades. The weak link was consistency and quality control.
He could generate thousands of orders overnight, but the food was made by
ghost kitchens that he didn't manage directly. Without oversight, there was
no way to ensure consistency and quality, resulting in a poor customer
experience. Some kitchens got it right, while others didn't, and MrBeast had
no mechanism in place to catch or fix the problems in response.
We often think of constraints as a bad thing - something that holds a system
back or limits its performance. This is the idea of negative constraints:
hidden bottlenecks or blind spots that weaken the system and only become
visible when things go wrong. They appear by accident, often due to a lack
of ownership or because the system grows without ensuring that all its parts
work together. MrBeast's ghost kitchen partnership failed not because of the
failure of a specific modular kitchen, but due to a lack of quality control
across the system. There were no clear standards, no means to enforce
them, and no process in place to address problems based on customer
feedback.
This illustrates a key principle of the building-block economy: rebundling
determines what is possible, but constraint management determines what is
viable. New solutions built from modular capabilities are only as strong as
their weakest link. The more you rely on rented components, the more

critical it is to anticipate where the system could break and design around
that risk. What matters is how well you manage these constraints.
Every system has constraints. To grow, you must identify these constraints
and manage them effectively. However, not all constraints are accidental or
harmful. Some of the most resilient systems are built by choosing the right
constraints in advance.
Fig. 7.2: Rebundling building blocks around positive constraints
Our overt focus on negative constraints may often blind us to the idea of
positive constraints - the deliberately chosen design limitations or
boundaries that define the system's performance by shaping its behavior
proactively. Unlike negative constraints, which emerge from neglect,
positive constraints are designed in advance. Designing the system around
positive constraints is particularly important when operational capabilities,
knowledge, and the ability to scale execution become relatively easily
accessible.
During the early years of e-commerce, website development and digital
marketing could be scaled easily, but fulfillment could not. Warehouses and
last-mile delivery were the choke points breaking down the system's
performance. Amazon's success was an outcome of solving that constraint
by building a warehouse network and a fulfillment system designed for
home delivery. Nearly three decades down, the constraints in e-commerce
haven't changed. Many direct-to-consumer e-commerce brands rent online
store infrastructure from Shopify, payment capabilities from Stripe, and
marketing services from Meta. The weak link often lies in fulfillment
consistency, as evidenced by missed shipments or slow returns, which can

erode customer trust. When assembling commoditized components, success
depends on how well the whole system holds together.
MrBeast's experience offers vital lessons for anyone looking to leverage
newly available capabilities to build new businesses. As AI makes highly
knowledge-intensive and creative capabilities available 'on rent', and
deployable at the push of a button, it offers opportunities to create entirely
new types of businesses without the need for high upfront investment. But
when capabilities become commoditized, and execution becomes easy, it's
not enough to rent the pieces. You need to understand what limits the
system and design your solution accounting for those limits.
Differentiating in a world of commoditized
expertise
Positive constraints can help shape a unique, defensible business, even
when the underlying components and execution capabilities are widely
available and commoditized. Paradoxically, in a world where everyone can
access the same tools, infrastructure, or AI capabilities, what becomes hard
to replicate is not what a business uses for execution but how it constrains
its execution. Competitors may have access to the same building blocks yet
struggle to compete because they can't replicate the logic or discipline
around which your system is designed.
This becomes especially important as we transition into an AI-enabled
economy, where knowledge and expertise, once rare sources of advantage,
are increasingly becoming commoditized and universally accessible.
Companies that once competed on proprietary knowledge will scramble to
find new ways to differentiate as their expertise becomes increasingly
commoditized and available as building blocks. Designing around positive
constraints becomes more strategic than ever. Even when the parts are
generic, the system you build from them can be uniquely differentiated and
defensible. Paradoxically, despite access to the same capabilities, your
competitors may struggle to compete simply because they can't replicate
those constraints.

Consider the case of Japanese retailer Muji and how it responded to a
market flooded with low-cost consumer goods. By the mid-1990s, the rise
of global supply chains and access to cheap manufacturing had changed the
economics of production. Factories in East and Southeast Asia could
produce endless variations of everyday items at increasingly lower marginal
costs. Production itself was no longer a constraint; it had become a
commoditized, rentable capability, a building block accessible to any brand.
This leveled the playing field, as everyone had access to the same
production capabilities, packaging options, supply networks, and
distribution systems.
As a result, companies could no longer differentiate based on
manufacturing access or even on design quality. Instead, with access to
cheap manufacturing, most brands started competing by simply offering
more - more SKUs, more colors, more features - under the assumption that
greater variety would help capture more demand. But this abundance
created a new kind of friction: customers were overwhelmed by choice and
unsure of what to trust. In a world of easy execution and infinite variation,
doing more didn't help.
With manufacturing becoming increasingly commoditized, it was no longer
sufficient to differentiate products solely on the basis of their function.
Brands began to compete through louder signals, using bold logos, bright
packaging, and aggressive messaging. With execution commoditized,
attention became the new battleground, and brands started banking on
visual noise to stand out on crowded shelves.
The Japanese brand Muji emerged in response to these excesses of
branding. Short for Mujirushi Ryohin (no-brand quality goods), Muji stands
out through its minimalist branding. Its products - pens, notebooks,
furniture, household items - feature no visual embellishments. To the casual
observer, it may seem like an aesthetic decision: a minimalist style that
stands in stark contrast to the visual clutter of the time. However, if you
stopped right there, you would miss what Muji was really doing; it was
structuring a differentiated business model around a system of constraints.

Muji's choice of minimalist branding established a system of constraints
that determined the architecture of its overall business model. First, the
absence of brand names, while distinctive from the branded noise that filled
retail shelves, also required Muji to build direct sourcing relationships with
manufacturers willing to produce without brand attribution. This constraint
helped Muji establish a private-label supply chain that could maintain
quality while eliminating the markup and complexity associated with
branded goods.
Next, its plain packaging, standardized across categories with uniform font
usage and precise dimensions, wasn't just for visual effect. That one choice
simplified procurement, reduced production costs, and ensured visual
consistency across the store. The store layout itself mirrors the editorial
logic of a well-curated magazine: categories flow logically into each other,
and shelf space is treated more with the aesthetics of interior design than as
advertising real estate. Muji also limits product variety by design, offering a
curated selection of essentials rather than an endless array of options. This
constraint reduces choice overload for consumers and instills trust in the
brand's curation and editorial control.
These constraints give Muji a unique supply chain design that other loud
brands simply can't copy. Muji's model essentially created a form of soft
integration; not complete vertical control like a traditional manufacturer,
but enough ownership of upstream and downstream decisions to enforce
consistency. The supply chain became an extension of the brand, and vice
versa.
Muji's unique supply chain architecture makes it unusually resilient to the
pricing pressures of non-branded commoditized categories. Its margins are
paradoxical, comparable to those of premium brands, yet achieved not
through traditional brand markups, but through a disciplined system of
constraints. Muji's choice of constraints shaped its operating logic, which in
turn shaped sourcing, design, packaging, and merchandising. With these
constraints systematized, the brand could scale without diluting its identity.
Stores in Tokyo, London, and New York carry different products depending
on local needs, but the spatial and aesthetic structure remains unmistakably
Muji.

Muji shows how a clearly defined system of constraints can sharpen
decision-making across an organization. These constraints ensure a more
consistent customer experience while also aligning all parts of the system.
Most importantly, they create defensibility, turning otherwise generic
components into a business that others can't easily copy.
The vibe coding paradox
Muji may seem like an unlikely role model in today's AI-accelerated
economy. It doesn't boast the latest technology and doesn't rely on
proprietary innovation. Yet that's precisely why its story matters. As we
rush to deploy AI and reassemble businesses from off-the-shelf
components, we risk confusing speed with strategy and risk jumping into
execution simply because it's easier than ever to do so. Muji shows that
long-term advantage doesn't come from quick execution but from carefully
choosing the constraints that will define what you build.
In early 2025, computer scientist Andrej Karpathy coined the term vibe
coding to describe a growing execution bias in the age of AI, the tendency
to prioritize outputs that feel impressive, even when they lack clear logic or
functional coherence. Though originally used to critique AI-generated code,
the term applies more broadly to any form of execution that AI makes easier
or more accessible. The paradox of vibe coding is that the simpler the
execution becomes, the more meaningless it risks becoming. Meaning isn't
in the output itself, but in the constraints that guide what gets built.
Constraints shape what you build but also determine how defensible it is. If
your solution is just a thin layer on top of existing building blocks without a
distinct logic or architecture of its own, you risk being replaced by the
providers of the underlying building blocks. We've already seen this play
out with the wave of startups that created 'wrappers' - lightweight
applications that package and resell the capabilities of foundational AI
models like OpenAI's ChatGPT, with minimal added logic or
differentiation. Ranging from productivity tools to writing assistants, and
even customer support bots, many of these startups added little beyond a

thin user interface and a set of prompts on top of the model. As OpenAI
observed usage patterns, it began incorporating similar features directly into
its own products. Over time, AI providers learn from what works, absorb
those patterns, and build vertically integrated offerings that compete with,
and often outpace, the very businesses built on top of them.
Building new value around constraints acts as a form of architectural
defense against this. It gives your business a logic, identity, and structure
that isn't easily replicable by your suppliers or competitors. These
constraints shape what you do and what you don't do. By building a system
that is not just composed of tools but defined by a distinct architecture of
constraints, you avoid becoming a generic layer in someone else's stack. In
the chapters that follow, we examine how these tensions unfold and how
managing constraints helps mitigate them.
OceanofPDF.com


OceanofPDF.com

SECTION 3 - COMPETITIVE ADVANTAGE
OCEANOFPDF.COM


OceanofPDF.com


OceanofPDF.com

A
8
THE TOOL INTEGRATION TRAP
THE HIDDEN IRONY OF AI-DRIVEN BUSINESS ADVANTAGE
t the 2005 Bahrain Grand Prix, Fernando Alonso, driving for Renault,
was up against a Ferrari team that had dominated Formula 1 for half a
decade. Michael Schumacher and his red machine had been untouchable,
winning five straight world titles. Ferrari had a better engine and a larger
budget. Renault's Fernando Alonso shouldn't have stood a chance. Yet,
under the brutal Bahraini sun, as trackside thermometers nudged past 40Â°C,
Schumacher's tires began to blister. Lap after lap, the car struggled to find
grip, overheating and burning through rubber. Schumacher pushed harder to
compensate, only worsening the problem. Midway through the race, his
Ferrari faltered - a rare engine failure under conditions it wasn't built to
endure. Alonso pulled ahead, unchallenged, and never looked back. Renault
had moved from contenders to world champions.
The paddock was stunned. Renault didn't have the biggest engine budget.
They didn't have Ferrari's legacy or brute power. But they had a hidden ace
up their sleeve.
Most F1 teams at the time thought about performance as a list of factors to
be optimized - the engine, the tires, the aerodynamics. Renault thought
differently. Renault built their car from the ground up as an integrated
system around the engine. The chassis was engineered to maximize
everything from aerodynamics to the way the tires degraded over a race

distance. The gearbox was designed in direct coordination with the engine's
power curve, ensuring that the car was fast, but more importantly, fast in a
way that worked over two hours of intense driving conditions. The
afternoon of the Bahrain Grand Prix recorded the highest temperature ever
experienced at a Grand Prix up to that point. Schumacher's Ferrari -
traditionally unbeatable - hadn't accounted for some of these environmental
factors. Alonso's Renault was better positioned for system performance,
resulting in lower tire temperatures, higher fuel efficiency, and more
consistent grip.
Alonso's victory was a milestone for Renault and its fans, but its enduring
significance lies in how it restructured the competitive landscape of the
sport. Until then, the sport had been built around accessing the best
components from engines to tires and assembling them into high-
performance cars. Renault, however, had proven that high component
performance didn't automatically translate to superior system performance.
From that moment on, winning teams stopped chasing the best components
and started looking for the best alignment between car design, engine
performance, tire wear, race strategy, and the driving style of their number-
one driver. They were thinking like system designers, where every element
was designed to work in perfect harmony.
Ask a casual fan what makes an F1 car fast, and they'll point to the engine.
Ask an F1 engineer, and they'll talk about how that engine works with the
rest of the car. In Formula 1, the difference between victory and defeat is
measured in hundredths of a second. That edge doesn't come purely from
technological horsepower. Engine horsepower helps, but only to the extent
that the engine integrates well with the rest of the system, encompassing
aerodynamics, suspension, and even the analytics teams that optimize race
performance on the tracks. Every component of the system needs to work
together, down to the molecular level of tire grip and fuel burn. Today, F1 is
won by teams that function through systems thinking, not by teams that
contract the best engine supplier or sign up the best racecar driver.
Performance, as we've seen in the previous chapter, is more than the sum of
the parts; it's based on the constraints that determine how those parts work

together.
The most dominant F1 teams today - Mercedes, Red Bull, and Ferrari -
work hand-in-hand with their engine suppliers because they are their own
engine suppliers. The difference between an engine that wins
championships and one that finishes fifth is how well that engine integrates
with the car's aerodynamics, how efficiently it deploys power over a race
stint, and how it reacts to the subtle changes in driving style demanded by
different circuits. Teams that rely on third-party engines can only get so far.
They can buy engines from the best manufacturers and hire top-tier drivers,
but they will always be one step behind the teams that own their engine
destiny.
Alonso's win marked the end of an era for F1 teams that saw themselves as
customers of engine suppliers. The winners would not be the ones who
assembled the best building blocks or the best tools but those who built
deeply integrated high-performance systems around them. This lesson, as
we'll see, lies at the heart of how AI is changing the nature of competitive
advantage today.
Tools vs. engines
Just as teams in Formula 1 must choose between buying the best
components and building the car around their own engine, companies today
face a similar choice.
Will companies keep using AI tools at arm's length, or will they rebuild their
systems around AI as the engine of new value creation?
A tool performs a useful but often isolated function within a larger system.
It might speed up specific tasks or automate parts of a process, but it
doesn't determine the performance of the overall system. You can usually
swap one tool for another without needing to change how everything else
works. For example, a company can replace its customer support chatbot
without needing to redesign its entire support function. A tool may boost
productivity, but it rarely builds an advantage because its value lies in

utility, not in helping a company differentiate against competition. If you're
using AI to automate a peripheral activity in your business, you're probably
employing AI as a tool.
What separates the champions from the rest in Formula 1 isn't just the
power of the engine - it's how well that engine works with everything
around it. This is also true for the most successful AI transformations. The
real power of AI is revealed when it serves as the engine that powers the
entire system. An engine is the performance-driving component that defines
how fast, how far, and how hard the rest of the system can go. The rest of
the system is structured around its capabilities and constraints. A Formula 1
team doesn't design a championship-winning car without first knowing the
specifications of its engine. Similarly, a company that uses AI as an engine
and is truly AI-native doesn't simply plug AI into existing structures. It
redesigns the entire business model around it.
The performance of any AI-enabled business depends on two factors. First,
the raw capability of the AI itself, much like the technical specifications of
an F1 power unit. Second, and far more critical, is how deeply those AI
capabilities are integrated with the broader system. A powerful AI model
might be impressive on its own, but its actual performance can be unlocked
only when it's deeply integrated into the workings of the system it supports.
Tools can be bolted on; engines require integration. A high-performance
engine won't deliver an advantage unless it is tuned to work in harmony
with the F1 car's chassis, transmission, and aerodynamics. Similarly, even
the most advanced AI capabilities provide limited value to a company
unless it reimagines its business model in light of those capabilities. This
distinction between tools and engines is important because it changes the
basis on which a company differentiates itself from competitors.
A company that utilizes AI as a tool may improve efficiency, but it still competes on
the same basis.
A company that treats AI as an engine unlocks entirely new levels of performance and
changes the basis of how it competes.

This distinction is best illustrated through the spectacular rise of TikTok
during a time when dominant social networks like Instagram and Facebook
were widely considered untouchable. These dominant social networks were
structured around your relationships and connections - your social graph.
Your content feed was shaped by who you followed or connected with.
Moving to a new network meant starting over without friends or followers.
Until your connections followed, the experience felt empty. For over a
decade, this was considered an unbreakable competitive moat that protected
established social networks.
TikTok turned this theory on its head. Its feed was driven not by who you
knew but by what you watched. It didn't ask you to build your social graph,
one connection at a time. Instead, it used AI to create something entirely
different: a behavior graph. Every swipe, pause, and replay would generate
signals about a user's interest in various types of content. Those signals
trained TikTok's recommendation engine. From the moment you opened the
app, the recommendation engine was learning. It didn't care about who you
knew; it only cared about what held your attention. Using AI as an engine,
TikTok built a social network that doesn't require a user's social graph.
Meanwhile, the dominant social networks of the time, including Facebook,
Instagram, and YouTube, also utilized AI primarily as a tool to enhance
their social-graph-based architecture. They used AI to improve users' feeds,
highlighting essential posts and automatically tagging friends in photos.
These changes improved the user experience but didn't change the nature of
the social network. The social graph still determined what you saw. AI just
made the ranking smarter. The success of these networks was still defined
by their ability to connect users to friends and followers and build out their
social graph.
TikTok didn't need to bootstrap a social graph like the other social networks
had done before it. Instead, it inferred a behavior graph from scratch, one
interaction at a time.
This shift from a social-graph-based network to a behavior-graph-based
network removed one of the most significant barriers to content creation on
social networks. On YouTube or Instagram, content creators need an

audience before they get distribution. This would discourage new content
creators from joining the platform. On TikTok, a good video could go viral
on its own, as the platform utilized AI to recommend engaging content,
regardless of who created it. The platform didn't care if a creator had a
million followers or zero as long as viewers engaged with their content.
TikTok also understood the constraints within which this new social
network would have to operate and designed for them. To train its model to
predict user preferences, it was necessary to capture a high volume of user
interactions with content. To achieve this, TikTok imposed a hard rule: no
video could be longer than 60 seconds. Far from a limitation, this cap on
video length acted as a positive constraint that did two critical things. First,
it forced creators to deliver value fast with tight storytelling and instant
hooks. Second, it changed viewing habits as users could watch dozens of
short videos in a row. With a shorter video format, TikTok could capture
viewer data with high precision, and far faster than traditional platforms. It
didn't need years of your viewing history. It only needed to know whether
you watched a video to the end, skipped it, liked it, paused it, or replayed it.
Since users were watching more videos on TikTok than on other platforms,
the platform captured more data, and these tight feedback loops helped train
the algorithm quickly.
Most analysts and experts believed that Facebook and Instagram had
unassailable network effects because of the size of their social graphs.
TikTok proved them wrong by making the social graph irrelevant. TikTok
reimagined social networking with AI as the engine to discover unexpected
connections by elevating content based on behavior rather than
relationships. Eventually, every competitor realized that this had changed
the basis of competition and implemented some version of the behavior
graph for their platform as well. But not before TikTok had asserted its
dominance.

Table 8.1: AI as tool vs. AI as engine
Over time, once TikTok had amassed enough users and a well-trained
algorithm, the 60-second constraint no longer served its original purpose,
and the platform began allowing longer videos. The original constraint had
done its job, and longer videos now helped move a successful platform in
new directions for deeper storytelling, education, and new forms of branded
content. TikTok still retains its core advantage as a social network built
around AI as an engine and structured around its capabilities.
When AI is a tool, it makes your business smarter. It can help improve the
user experience and engage users more effectively. It can help compete
better in the existing game. But with AI as the engine, the business no
longer competes on the same old terms. It wins by changing the rules of
competition.

Tool providers vs solution providers
TikTok's rise demonstrates that AI has the power to redefine how
companies compete. However, that transformation only occurs when AI
moves from the margins to the core, from a tool that supports the business
to the engine that powers it. We now see two paths by which firms can
leverage AI to build and deliver solutions for their customers. On one path
are firms like TikTok, which structure their entire model around AI as the
engine, reimagining the solution using its capabilities. On the other hand,
more traditional players use AI primarily to optimize existing offerings
rather than rethink them.
These paths aren't mutually exclusive. Many solution providers begin by
using AI as a simple tool, but that relationship doesn't remain static for
long. As the tool's capabilities improve and you start seeing real business
impact, your perspective shifts. You start rethinking how your products
work, how your services are delivered, and how value is created. This
gradually moves AI from a peripheral add-on to the central engine powering
your solution. For many businesses, this evolution unlocks entirely new
levels of performance and differentiation.
However, when the underlying AI tool that now powers your business is
owned by a third-party provider, a new tension shows up. The tighter you
integrate the capabilities of the underlying AI tool into your solution, the
more deeply you become dependent on the external tool provider. Control
starts to shift, creating one of the most powerful structural tensions in the
age of AI: the growing imbalance between those who build foundational
tools and those who build businesses on top of them.
Building around AI creates an advantage unless the AI belongs to someone
else. In that case, it creates lock-in. The more you rely on someone else's AI
tool to power your business, the more control you hand over to the provider
behind it.
This tension is a natural outcome of the structure of digital value chains,
where individual capabilities are available as modular building blocks, as

discussed in the previous chapter. Once a business begins to assemble its
solutions using third-party building blocks, the risk of dependence is always
present, especially when the performance of those solutions is directly tied
to the performance of the underlying external capability.
Google Maps, for instance, provides the mapping, location intelligence, and
routing capabilities that power countless applications, from delivery
tracking to ride-hailing. But Google Maps is only a tool provider in these
relationships; it doesn't book your ride or deliver your food. That's the job
of solution providers like Uber or DoorDash, who use Google's mapping
engine to build and deliver customer-facing services. These solution
providers own the user experience, the brand, and the customer's trust.
However, their performance increasingly depends on the capabilities of the
mapping tool underneath. For several years, the reliability of Uber's pickup
times, routing, and fare estimates was defined by how well Google Maps
performed. Uber controlled the app and the customer relationship, but the
intelligence behind the routing came from a tool they didn't own.
A tool provider competes based on the functional performance of their
specific tools, such as navigation accuracy and global mapping coverage, in
the case of Google Maps. A solution provider, on the other hand, competes
based on their ability to serve the customer, leveraging three advantages in
particular: a deep understanding of customer needs, domain expertise, and
the ability to pull together different components (including third-party
tools) into a product or service - a solution to the customer's problem.

Fig. 8.1: Competitive tensions between tool providers and solution
providers
Competitive tensions often mar the relationship between tool providers and
solution providers. Short-term gains from using underlying tools can
quickly turn into long-term dependence and lock-in if the tool provider
becomes too central to the performance of your business. The more the
solution provider relies on the tool, the more leverage the tool provider

gains. And as that dependency grows, so does the tool provider's ability to
extract value from the solution provider.
In its early years, Uber built its customer experience and brand on top of
Google's mapping capabilities, relying on these maps for routing, pickup
locations, and estimated arrival times. Over time, however, it became clear
that Uber's performance was, in large part, dependent on the quality and
constraints of Google Maps. If Maps miscalculated travel time or provided
an incorrect customer location pin, the user blamed Uber, not Google. The
mapping engine shaped customer experience, and its limitations defined the
boundaries of Uber's solution.
OceanofPDF.com

OceanofPDF.com

Table 8.2: Tool providers vs. solution providers
When a tool's performance determines the overall performance of the final
product or service, the tool provider gains leverage over the solution
provider. At that point, the tool becomes an engine, and the solution
provider's performance is directly influenced by it. When a component
becomes so essential that it defines how the solution performs, it naturally
begins to demand a larger share of value.
Initially, Uber relied heavily on Google Maps. However, over time, it
became clear that the mapping layer was influencing the entire business's
operations. As early as 2016, Uber began investing in its own mapping
capabilities and hired the former product head of Google Maps to lead
Uber's product team. Despite acknowledging the centrality of mapping to
its business, its uneasy relationship with Google Maps as a tool provider
persists. At the time of its IPO in 2019, it was still paying a significant sum
to Google Maps.
As tool providers' capabilities improve, they constantly look to make
solution providers more dependent on them. Solution providers, on the
other hand, continually push back to reduce dependence on specific tools.
Uber continually seeks alternatives as well to reduce its reliance on Google.
These include Uber's failed attempt to acquire Nokia's digital mapping
services and its subsequent partnerships with alternative mapping providers,
such as TomTom and HERE Technologies.

Fig. 8.2: Competitive tensions between Uber and Google 
Uber's relationship with Google Maps illustrates the competitive tensions
that emerge between tool providers and solution providers. Uber might have
started as just another customer, but it was evident quite soon that Maps
was central to Uber's customer experience. Meanwhile, Google was
simultaneously serving other solution providers across ride-hailing,
transportation, logistics, and delivery businesses. Every trip across these
players was a learning opportunity. Data on pickup accuracy, route

deviations, and traffic patterns flowed back to Google. Uber only learned
from its own operations, while Google learned from the entire ecosystem.
As seen in the example of Google Maps, the tool provider gains two critical
advantages: first, direct access to performance data that reveals which
solution attributes are effective in the market, and second, training on those
solution attributes across multiple solution providers. While individual
solution providers see only their own customers' outcomes, a tool provider
that gains widespread adoption can observe success patterns across the
entire ecosystem. This learning advantage creates a further threat beyond
the threat of dependence and tool lock-in.
As the underlying tool improves through learning, the tool provider may
move directly into the solution provider's business. Tool providers,
leveraging insights gained from their entire customer base, may be uniquely
poised to enter solution markets with offerings that draw on the experiences
of the industry's most successful practitioners. The very tools that enhance a
solution provider's current competitiveness may be simultaneously
preparing their replacement.
Alongside Google's mapping tools that power Uber's ride-hailing solution,
both companies have engaged in another competitive arena where the lines
separating them become even less clear. Google, the provider of mapping
tools, has also made significant investments in self-driving AI technologies.
Waymo, a self-driving technology startup that emerged from Google in
2016 and is owned by its parent company, Alphabet, began testing its self-
driving technology as early as 2009, a year before Uber's launch.
Uber, the solution provider, well aware of Alphabet's self-driving
ambitions, moved back into tool creation itself by launching an autonomous
driving division, pouring billions into R&D, and even acquiring Otto, a
self-driving truck startup launched by a former Waymo engineer. The
acquisition only served to highlight the complexity of the tensions between
the two firms as Waymo sued Uber, alleging theft of trade secrets by Otto.
In 2020, Uber shut down its autonomous division and sold it off, effectively
conceding the race.

The uneasy relationship between Waymo and Uber continues, as Waymo
now acts as both a solution provider, running its own mobility services, and
a tool provider to Uber, providing its autonomous fleet for booking through
Uber's service. This is the strategic risk confronting solution providers.
Uber stays on the surface, but Waymo controls the intelligence and
infrastructure that determine the solution's performance. The more Waymo
learns from Uber's users, the more competitive tensions flare up further
between the two. These tensions between Uber and Google/Waymo reflect
the structural conflict in AI-era value chains. When the tool a company uses
to build its solution becomes so central that it defines the solution itself, the
balance of power shifts, and the tool provider moves from being an enabler
to becoming a rival.
These tensions are the central focus of this chapter - the growing power
struggle between solution providers, who deliver value to end customers,
and tool providers, who initially enable them but increasingly expand to
dictate not just how solutions perform but also how entire industries
operate.
Tool providers secure power through unbundling
and rebundling
The tensions between Uber and Google, and later Waymo, offer a preview
of the competitive dilemmas that confront companies building their
businesses on top of increasingly intelligent tools. As Google captured data
from the transportation and logistics service providers using its mapping
capabilities, it improved the routing intelligence that would eventually help
it offer mobility services through Waymo. When companies deploy
intelligent tools, especially those that learn across environments, they may
unknowingly train their own future competitors.
As AI-enabled tools are deployed across industries, tool providers are no
longer passive vendors sitting back. They start moving into the solution
provider's business by progressively unbundling the solution provider's

capabilities and absorbing them into their tools. Let's look at two ways tool
providers achieve this.
First, AI tools can absorb operational knowledge, particularly in
manufacturing and process-intensive settings where machines equipped
with sensors capture operational data. As these machines stream data back
to their manufacturers, the manufacturers (the tool providers) can identify
issues early, enabling remote repairs and predicting when maintenance is
needed. However, over time, tool providers begin to notice industry-wide
patterns across many factories and machines. They capture system-level
operational knowledge - when to make adjustments, how to avoid
breakdowns, and how to handle unusual situations.
Second, AI tools may also absorb tacit knowledge and expertise that is held
in the minds of skilled professionals or acquired through decades of
practice. For instance, AI tools can synthesize clinical reasoning by training
across millions of case reports and research papers or improve legal
analysis by training on a vast corpus of case law and internal firm
documents. Once this domain-specific knowledge is absorbed, the collective
memory of an industry can be repackaged into tools.
This absorption of domain knowledge into tools is most clearly visible in
agriculture. Farmers were once the custodians of local domain knowledge
on soils, weather patterns, and planting schedules, which they acquired
through hands-on experience and expertise. Today, companies like John
Deere unbundle that knowledge from farmers and absorb it into their tools,
subsequently bundling larger systems of operational coordination around
these intelligent tools. At first glance, John Deere, whose tractors are
familiar icons of agricultural work, looks more like a legacy tool provider
rather than one using AI. But Deere has moved far beyond its initial
business of selling tractors. Today, it offers a bundled farming solution that
collects data from sensors embedded across its equipment and delivers
prescriptive advice via proprietary software.
Deere began by incorporating GPS and telematics into its equipment to
enhance fuel efficiency and minimize downtime. However, this also laid the
groundwork for capturing data across farming operations. Each pass of a

tractor over a field generated data on soil conditions and planting practices.
Over time, that data allowed Deere to move beyond monitoring machine
performance alone to modeling how farmers made local decisions based on
weather, timing, and their own experience. The one-size-fits-all tool
provider now had deep contextual knowledge of each farm and its
operations.
With the John Deere Operations Center, Deere has developed a digital
system that enables farmers to manage all aspects of their farms, including
soil conditions, planting schedules, and even government paperwork. This
infrastructure to coordinate farm operations has helped John Deere
transition from a tool provider that supports farming to one that structures
how farming is planned and executed. AI-driven prescription farming tools
now make recommendations on what to plant and how to sequence
operations. Its autonomous equipment helps to execute such plans.
This transition reveals an important distinction that lies at the heart of this
chapter: tools can evolve in two powerful but distinct directions. A tool
becomes an engine when it starts to determine the performance of a system.
A tool becomes an infrastructure when it starts to structure system-wide
operations and behavior, shaping how work is done and how decisions get
made.
In John Deere's case, we see both paths playing out. Deere's autonomous
machinery and AI-driven prescription systems act as an engine that drives
farm productivity, directly determining its performance by optimizing its
yield. The more farms rely on this 'engine,' the more John Deere gains
competitive leverage. Alongside this engine, the John Deere Operations
Center serves as a coordination and control infrastructure. It structures how
farms operate internally and how external requirements around compliance
and reporting are managed. It becomes the infrastructure on which the
farm's activities are managed. Farms no longer merely use Deere's tools;
they build their operations around Deere's infrastructure.
These two movements are distinct but reinforcing. The engine governs
performance; the infrastructure regulates behavior. One determines how
well the system runs; the other determines how the system is run. Together,

they shift power decisively in favor of the tool provider. The tool provider is
no longer just a vendor; it is the architect of how an entire industry operates.
As Deere absorbs more feedback across crops, geographies, and seasons, its
models improve faster than any individual farm or third-party vendor can
replicate. The system continues to improve, while the institutions using it -
actors across the agricultural value chain -- remain constrained by annual
planning cycles and limited data visibility. Over time, the locus of learning
and improvement shifts from these institutions to the tool provider.
History offers engaging lessons on how tool providers can exercise such
infrastructural control over an entire industry. In the early 20th century, the
humble shoe workshop witnessed such tensions play out as the United Shoe
Machinery Corporation (USMC), a manufacturer of industrial machinery
for the shoemaking industry, began to shape the entire industry's structure.
Before the USMC, shoemaking was a decentralized craft. Shoe
manufacturers purchased tools such as stitching machines and sole pressers
and then determined how to utilize them to produce shoes. USMC changed
that. Instead of selling machines, the USMC leased them. However, the
lease also included strict conditions that required manufacturers to adhere to
the USMC's production methods. Shoe manufacturers now had to structure
their entire operation around the USMC's system. If they wanted to benefit
from the productivity gains offered by mechanization, they had to adopt its
production methods and effectively become dependent on it. They no
longer had the freedom to experiment with processes or train workers in
their own methods. A shoemaker could no longer differentiate himself on
his craft when all shoemakers were forced to follow the same production
methods.
By the 1910s, the USMC controlled over 85% of the shoe machinery
market. Their tools were no longer interchangeable components. They had
become the organizing logic of the industry. Their bundled leasing system
meant that using one USMC machine obligated manufacturers to utilize the
company's entire operating infrastructure, including their equipment suite,
best practices, and production methods. By the 1920s, the USMC had
expanded into the shoe retail industry, developing store concepts and
merchandising systems that it offered directly to shoe retailers. A

manufacturer who had produced shoes using USMC equipment would find
their products displayed in stores according to the USMC's recommended
arrangements. This created unprecedented tension. Shoe manufacturers,
once independent businesses with their own expertise and market
relationships, further lost their ability to differentiate products as both
production and retail presentation increasingly fell under the USMC's
influence.
The USMC's playbook of offering the infrastructure for an entire industry
holds essential lessons for the tensions between tool providers and solution
providers in the age of AI. If anything, this tension, as we shortly note, is far
more pronounced because of AI's ability to learn from the system into
which it is introduced and because of the rapid pace of improvement of AI
capabilities, in general. Both scenarios - of a tool improving to become an
engine or expanding to become an infrastructure - pose threats to solution
providers. In the first case, the solution provider loses control over the
solution's differentiation. In the second, it loses control over how the
solution is created and delivered. Recognizing that solution providers rely
on them, tool providers continually seek ways to increase their influence.
The changing nature of control
The USMC mandated the adoption of its infrastructure by enforcing
contracts - the lease terms required the use of its entire suite of machinery
together. Shoemakers didn't have much choice as the USMC's system was
dramatically more productive than their traditional craft-based approach. If
they resisted, they would operate with lower output and higher costs and
would quickly lose ground to competitors who had adopted the new system.
Once early adopters proved it worked, everyone else was forced to follow,
even if it meant losing control.
USMC was explicit in imposing its structure and policies onto an entire
industry, but using AI, today's tool providers, as in the case of John Deere,
can execute similar encroachment while being much less explicit about
control. As AI tools deliver better performance, solution providers initially

optimize for the tool and then begin to depend on it. Soon enough, they
can't walk away. AI tools learn and improve rapidly to become the
gravitational centers of their industries - as engines, infrastructures, or both.
Solution providers, in their pursuit of better outcomes, begin to revolve
around these engines and get increasingly locked into these infrastructures.
The examples of both John Deere and the USMC illustrate how tool
providers can gain significant leverage over solution providers. At first
glance, both examples might seem cherry-picked from industries where
solution providers, such as shoe manufacturers in the case of USMC or
individual farms in the case of Deere, could not build such sophisticated
tools themselves. A fragmented or under-resourced industry is more
vulnerable to a large, well-capitalized tool provider. Yet, solution provider
fragmentation is not the only, or even the primary, source of leverage for
tool providers. Even in industries where solution providers are large, well-
funded, and technically capable, tool providers still have an advantage.
Three structural advantages consistently work in their favor, driving this
increasing control.
The first is a learning advantage. Each use of the tool generates data that
feeds back into its improvement. This creates a learning effect where tools
continuously learn from the market. Moreover, this learning effect enables
tools to learn from multiple customers simultaneously. No single solution
provider can benefit from industry-wide learning. Where such industry-
wide learning creates a greater performance advantage than deep training
on a particular company's knowledge base, tool providers gain a stronger
hand.
The second factor that explains the growing leverage of tool providers is
scope expansion, which happens through two distinct movements:
horizontal rebundling and vertical encroachment. Horizontal expansion
occurs when a tool provider broadens its capabilities to capture adjacent
tasks. Tools that start out as a narrow utility gradually extend to rebundle
adjacent capabilities, allowing the tool provider to capture a larger share of
the solution provider's workflows. The solution provider's operating model
becomes tightly coupled to the tool's design and roadmap. This leads to
infrastructural control, where the tool is no longer just a component but the

foundation on which the solution provider's operations are built. Vertical
encroachment involves going deeper into the solution provider's business
by continuously absorbing data, learning from use across a broad set of
customers, and integrating those learnings into the core tool. These
movements drive scope expansion, making tools more potent over time at
the expense of solution providers.
Fig. 8.3: Horizontal and vertical movements by tool providers
Finally, the third and least appreciated factor is clockspeed - the relative rate
at which different parts of a value chain evolve. Tool providers often
innovate faster than solution providers. The surge in AI investment enables
underlying AI tools to innovate and improve their capabilities faster. Even if

a tool isn't constantly learning from its customers, it can still improve
rapidly if it attracts greater investment and plugs into underlying models
that are themselves rapidly improving. Meanwhile, solution providers,
bogged down by human workflows and organizational inertia, can't keep
up. This growing speed gap further tilts the performance advantage in favor
of the tool provider with each upgrade.
When these three factors align - compounding intelligence, expanding
scope, and the underlying speed of innovation - the tool stops being just a
component. The farm still runs on seasonal planning cycles. The software it
uses, meanwhile, improves every week, integrating feedback from
thousands of farms across the country.
The irony of dependence
As AI tools rapidly improve, solution providers redesign their businesses to
tap into the performance gains these tools offer. At first glance, this appears
to be a win-win: the tool does its job, the solution becomes sharper, and
customers are happier. However, the solution increasingly becomes
dependent on an engine that the solution provider doesn't control. The
solution provider, once in control of the end-to-end offering, now finds that
key parts of their value proposition are controlled elsewhere. Worse, those
parts are improving at a clockspeed they can't match. The pace of
innovation at the tool layer begins to outstrip the pace of innovation at the
solution layer. Every improvement in the engine delivers an improvement in
the solution, creating a new kind of performance-based lock-in. Each
improvement in the tool lifts your product. But each lift tightens the grip.
The engine helps you compete better, yes, but it also determines whether
you get to play at all.
At this point, the tool becomes the performance layer of the industry. Power
no longer lies in who owns the customer relationship; it lies in who owns
the system that delivers the performance the customer expects. To keep
translating engine performance into solution performance, solution
providers start building their workflows, and even business models, around

the evolving engine, much like Formula 1 teams design their cars around
the engine for maximum performance. The AI engine becomes the
performance layer, and the solution provider becomes the delivery shell
wrapped around it.
As solution providers align their business around the engine, they lose their
ability to stand out. Internal processes that once created differentiation now
only add complexity. So they abandon them, making the problem worse.
Instead of building unique capabilities, they plug into what the engine
offers. As more of the industry adopts this posture, the entire industry is
shaped even more so by the engine at its center.
When the solution provider becomes so closely oriented around the engine
that its performance improvements are no longer self-generated but instead
absorbed from the engine underneath, the balance of power shifts. The
business no longer competes on its own capabilities. It competes on how
well it integrates with someone else's capabilities. And the more it
optimizes for the engine, the harder it becomes to walk away. At this point,
the dependence is no longer created through contractual lock-in or the cost
of change management; it's created through performance-based lock-in.
The solution becomes so reliant on the superior performance of an external
engine that leaving it would mean falling behind the rest of the industry.
Over time, the line between what the business does and what the engine
enables becomes increasingly blurred. Customers aren't buying the
company's unique expertise - they're buying an experience powered by the
same engine that now underlies dozens of other players in the industry. The
company may still look like a solution provider, but it has become a
wrapper - a pejorative reference to an interface wrapped around someone
else's performance layer.

Table 8.3: The three stages of the integration trap
The tension here, ironically, isn't created by tool providers barging into the
solution provider's business. It's created by solution providers marching
downward into the tool, hoping to gain its benefits to compete better in the
short term. As the capabilities of the underlying AI improve, the solution
provider further reorients its operations to leverage these improvements and
enhance solution performance. Performance improvements continue, but
this dependence does not arise from external pressure or contractual lock-in.
It arises from a well-intentioned desire to grow your business by utilizing
every ounce of performance the underlying tool delivers.
This is the long arc of how these tensions play out. First, tools commoditize
execution. Then, they absorb expertise. Then, they become the gravitational
center around which solution providers reorganize themselves until the
distinction between the two is no longer clear. And finally, they restructure
not just the individual business but the entire ecosystem around themselves.
Shifting pricing power
So far, we've examined how tool providers move into solution
provisioning. Yet, even if a tool provider doesn't explicitly enter a solution's
market, it may still capture most of its profits. The most powerful form of
encroachment comes not from replacing what solution providers do but

from shifting where value accumulates in the value chain. When tools
evolve into engines that drive an industry, they stop being mere enablers
and become chokepoints. These chokepoints often do more to transfer value
from solution providers to tool providers than any direct move into the
solution space ever could.
This shift in value explains why solution providers struggle to capture the
long-term productivity gains resulting from the adoption of new technology.
In Poor Charlie's Almanack, ace investor Charlie Munger recounts a story
about how productivity gains from new technology typically do not accrue
to those adopting the new technology; instead, they accrue either to the
technology providers or to the end customers. During their time in the
textile business, Munger recalls an instance when Warren Buffett reacted to
news of a new loom capable of doubling efficiency by remarking that its
success would likely lead to the mill's closure. Buffett understood that in a
commodity market, the benefits of increased productivity would primarily
accrue to the end customers or the tool providers, rather than to the
producers or solution providers in between. While the cost savings were
real, the profits bypassed the solutions that adopted the technology.
AI introduces this same dynamic to knowledge work. When the cost of
executing knowledge work collapses, and what used to take a team of
analysts now takes a single prompt, companies that adopt these tools might
gain short-term efficiency but risk losing long-term control. Much like the
shoemakers adopting USMC's machinery, everyone becomes faster and
cheaper, but no one stays differentiated. And the provider of the AI tool
captures the surplus.
To understand this with a familiar example, let's say you're in the restaurant
business, running a wildly popular spot in a prime location. Your success
draws crowds, but when it's time to renew your lease, the landlord demands
a massive rent increase. Suddenly, the very space that helped build your
brand feels like a trap.
You have two options: agree to the higher rent or buy out the land.
If you decide to do the latter, you're now in the real estate business. You
need to consider whether all the investments you've made in your current

location, and its location advantage, justify the premium you pay for it, or
whether you're better off finding an alternative, cheaper location and
rebuilding your brand there. This is because the gains from improved
restaurant performance, even if not attributable to the area, can flow to the
owner of the location.
Netflix faced a similar challenge when it transitioned to streaming. If it
licensed all its shows, it was stuck being a distributor in a business where
pricing power is held almost entirely by the movie studios. Acquiring and
retaining online users is expensive and challenging. And yet, if Netflix
improved its user acquisition and retention, studios would likely increase
licensing fees, thereby preventing Netflix from retaining profits. Netflix
was left with no choice but to create its own content. The same risk applies
to knowledge firms built around third-party AI. Today's productivity gain is
tomorrow's margin erosion. The more the firm depends on the underlying
engine to perform its core functions, the more pricing power shifts to the
engine.
Solution providers often don't see this coming - they are naturally
incentivized to build around the engine. Their instinct is to translate the
improving performance of the underlying engine into superior solutions in
the hope of charging higher and improving margins. Ironically, those gains
never materialize. Instead of expanding margins, solution providers see
their existing margins contracting.
The tool provider captures most of the value in two key ways. First, once a
tool becomes central to solution performance, the tool provider can extract
more value by adjusting pricing or usage terms or by instituting
performance-based fees. This was the risk that pushed Netflix to create its
own content. The more central the underlying capabilities to the solution's
performance, the less control the solution provider has over its own
margins. Second, as more companies adopt the same engine, any advantage
the tool offers becomes a commodity available to the entire industry. The
tool provider absorbs expertise and repackages it as a utility available to the
entire industry. Now, anyone can access the same capabilities for a fee. That
levels the playing field, but it also drives down differentiation, increases
competition, and compresses margins across the board. Even if a solution

provider adds value, it often can't keep that value. The engine ends up
capturing it. The more everyone uses the same engine, the more it learns
and the more power it holds across the value chain. Pricing power shifts
away from the solution and toward the provider of a critical input
determining the solution's performance.
Fig. 8.4: How tool providers gain leverage
When confronted with the possibility of AI tool providers eating into their
margins, senior leaders in knowledge-intensive industries often push back:
"We'll just out-innovate our way out of this." But history suggests
otherwise. The rate of improvement at the AI tooling layer - especially
when it can benefit from learning effects and raise billions of dollars in

capital - is typically orders of magnitude higher than what's possible at the
solutions layer, where innovation must contend with organizational inertia,
regulatory drag, and delivery complexity. This difference in industry
clockspeed between the two layers serves only to increase further the
dependence of solution providers on the underlying engines.
When a fast-moving component enters a system, the entire system is forced
to adapt to the clockspeed of the fastest layer. That's exactly what's
happening today with generative AI. It introduces a high-clock-speed layer
into otherwise slow-moving industries, such as law, consulting, medicine,
and education. These are sectors built on tradition, trust, and deeply
entrenched workflows, which often resist rapid change. But once AI enters
the system, learning faster and releasing new capabilities every few weeks,
it resets the clockspeed for everyone else. Solution providers may still own
the client relationship, but they no longer control the pace or direction of
progress. Instead, they begin to integrate further into the layer that moves
fastest - the engine.
Resolving the solution providers' dilemma
If you're building a solution where performance is fundamentally dictated
by the tools you rely on, you need to think very seriously about taking
ownership of those tools. Otherwise, you risk becoming hostage to the
performance, pricing, and priorities of a third party.
To understand when to integrate back into tools and when not to, we need to
distinguish between tools that enhance product or solution performance and
those that improve a process. If a tool merely supports an internal process,
like automating back-office tasks, outsourcing may carry little strategic risk.
But if your solution's value proposition is directly dependent on the
performance of that tool, the threat of dependence is higher.
Yet, the distinction between process and performance may not always be
straightforward. Amazon's warehousing operations offer a fascinating
example. At first glance, warehouse robotics may appear to be a process-

level enhancement; robots move shelves to reduce labor costs and boost
throughput. However, these robots don't just make operations smoother;
they underpin Amazon's promise of two-day or same-day delivery. That
promise is central to Amazon's retail dominance. If that capability had
remained in the hands of a third-party vendor, Amazon would have been at
the mercy of someone else's roadmap, pricing, and priorities. That's why it
acquired Kiva Systems and brought the robotics layer in-house. Amazon
wasn't cutting costs; it was capturing the engine behind its most valuable
customer promise.
If a tool affects solution performance in a way that directly shapes customer
experience and competitive advantage, it's no longer merely an operational
concern; it's a strategic one. Integration becomes critical. Owning the tool
can protect your advantage and even amplify it. Amazon's advantage in
fulfillment stems from how its overall warehousing system, comprising
warehouse assets and processes, is orchestrated and constantly reconfigured
based on demand data and improving AI capabilities. Early integration of
robotics helps control this feedback loop, which constantly improves and is
difficult for competitors to replicate overnight.
Pharma companies, similarly, leverage AI into their R&D pipelines, not so
much to digitize workflows but to generate new clinical trial strategies
using models trained on years of drug trial data. DeepMind's AlphaGo
stunned the world by playing moves no human had ever imagined.
Similarly, in drug discovery, AI models are revealing pathways no chemist
would intuit on their own. The once-tacit, experience-based process is
absorbed into AI tools, which learn and iterate faster, thereby compounding
value over time.
The real opportunity in integrating back into tools, then, is not just to
defend your current performance but to accelerate the advantages of future
learning by owning the highest clockspeed layer. Of course, not every tool
must be owned. If the market for a particular tool is competitive, with
multiple providers offering similar capabilities, then relying on third parties
can be a perfectly rational approach, particularly if switching costs are low
and no single provider gains enough leverage to dictate terms.

The 'every company will be an AI company'
oversimplification
The idea that "every company will become an AI company" has become a
kind of gospel in the tech world; a rallying cry that implies the only way to
survive the next decade is to embed AI into every facet of your business.
But like many seductive narratives, it's dangerously oversimplified. The
real question isn't whether a company uses AI but how. If AI is central to
the performance of your solution, then you may need to integrate it deeply.
But if AI is simply one of many components you use to deliver outcomes,
then adopting best-in-class tools might be the smarter move.
In some markets, power will reside with the tool provider, while in others, it
will be held by the solution provider, which controls the outcome and the
customer relationship. Different industries will see power concentrated in
different places. If switching tools is easy, tool providers lack power. If it's
difficult, solution providers lose control. If customers choose one solution
over another based on the underlying technology, tool providers win. If
customers value the reliability offered by the solution provider over the
performance of the underlying tools, the solution provider wins. If the tool
provider's learning compounds across many customers while the solution
provider only learns from their own, the tool provider gains a structural
advantage. But if a solution provider's proprietary knowledge matters more,
then the solution provider wins.
The most unexpected trap is that the right decision today might be the
wrong one tomorrow. Using third-party AI tools can help you move fast,
but if those tools become central to your customer value proposition, you
may wake up to find that you've outsourced your competitive advantage.
The decision to build versus buy AI capabilities often comes down to a
single question: What happens if you lose access to this tool? If your
business is merely inconvenienced, then buying makes sense. If it gets
crippled, you need to own it.

The solution provider's advantage
One of the most enduring advantages solution providers hold over most tool
providers is their ability to guarantee not just performance but reliability to
customers. Customers don't just buy functionality; they buy certainty. They
expect things to work as claimed, outcomes to be delivered, and someone to
be accountable when things go wrong. That accountability is what gives
solution providers control over pricing, packaging, and the customer
relationship.
The extent to which tool providers move into solution provisioning is often
determined by their ability to assume risk and liability, in addition to
delivering performance. If an AI tool merely assists a doctor or a driver, the
liability remains with the human. However, if the tool becomes the deciding
factor in diagnosing patients and navigating roads, then it also inherits the
responsibility.
This is the trade-off that confronts tool providers as they move closer to the
customer; becoming indispensable means being held to a higher standard.
With control, margin, and ecosystem lock-in comes regulatory scrutiny and
the burden of liability. This is what we explore in the next chapter. Much as
we've talked about the power of tool providers in this chapter, we look at
how solution providers can create unique advantages that keep tool
providers at bay in the next one.
OceanofPDF.com


OceanofPDF.com


OceanofPDF.com

R
9
THE SOLUTION ADVANTAGE
WHY AI VALUE CAPTURE IS LESS ABOUT TECHNOLOGY AND MORE ABOUT
MANAGING RISK
obots were supposed to deliver on the grand promise of transforming
the factory floor. They would replace dangerous, repetitive labor and
unlock a new era of frictionless productivity. Machines would handle the
drudgery. Humans would shift to higher-value work. This was the classic
promise of automation: to shift human labor from muscle to mind. In
practice, this promise of automation hasn't really played out. This is
because a technology's potential is only realized when someone solves the
constraints that surround its use.
This is what separates tools from solutions: tools work in ideal conditions;
solutions work in the real world. A robot might meet performance
benchmarks in tests but fail in the hands of a customer. It takes more than
robots to deliver on the promise of automation.
The story of robots in manufacturing is yet to unfold as a tale of machines
replacing humans; it has so far been a story about the yawning gap between
tools and solutions. Technology alone doesn't deliver impact. A robotic arm
can perform a task with unmatched precision. But unless it fits into broader
workflows and processes, it remains just a tool, not a solution. What drives
adoption isn't the tool's sophistication; it's the ability to manage the
constraints in the system around it.

While tools provide isolated capabilities, solutions integrate these
capabilities into workflows, ultimately solving customers' problems.
Solutions work because they solve for cost, complexity, and change. The
issues plaguing the adoption of robotics in manufacturing can be traced
back to an inability to address these three factors. Introducing a new robotic
arm disrupts workflows and forces managers to reassess everything from
staffing to supply chains. Robots need human oversight to handle
exceptions or unexpected situations. It turns out that robots don't simply
replace workers - they, ironically, end up requiring an entirely new kind of
workforce: specialized workers who can maintain and reprogram them. Far
from reducing complexity, tools often externalize it, passing the burden
onto the customer.
History reinforces the idea that a technology's potential is realized only
when someone solves the surrounding constraints. In his study of
electrification, historian Thomas Hughes introduced the concept of the
system builder - the person or organization that doesn't just build better
tools, but reengineers the system around them to remove adoption barriers.
Electricity generation improved rapidly, but its impact was limited until
systems for transmission and end-use were also upgraded. When electricity
couldn't travel far due to transmission limits, the effort shifted from
generating more power to solving the constraint of distribution.
Likewise, in the 2010s, residential solar technology had become efficient
and affordable. Yet adoption remained low because homeowners couldn't
finance the upfront costs. Much like factory owners evaluating robots,
homeowners were deterred by the steep upfront cost of installing solar
panels. Banks viewed solar installations as risky due to their novelty and
uncertain long-term returns. This lack of financing became a key constraint,
holding back adoption despite the technical readiness of the panels.
The breakthrough came not through better panels, but through better
financing. Leasing agreements let homeowners install panels with little to
no upfront cost, paying a fixed monthly fee instead. Power Purchase
Agreements (PPAs) took it further, allowing customers to pay only for the
energy generated, often at rates lower than their utility bills. Companies
handling financing also took on responsibility for system maintenance and

performance. For these firms, the financing models provided a stable, long-
term revenue stream linked directly to energy production, aligning their
success with the sustained performance of the installations. These financial
innovations dismantled the core constraint.
In each of these cases, adoption was unlocked by solving the system's
constraints, not by improving the tool's performance.
Solving the financing constraint moved residential solar power from a
powerful tool to a practical solution. One of the recurring patterns in the
history of innovation is that we often confuse tools with solutions. Tools
offer capability and functionality. Solutions deliver reliability and
performance in the hands of the customer. This distinction proves crucial
for understanding why some innovations succeed while others, often
technically superior ones, languish or fail entirely.
Well-designed solutions have three essential traits. First, they're accessible;
easy to find, adopt, and integrate without requiring specialized expertise.
Second, they're usable; easy to incorporate into real workflows, and
frictionless enough to drive consistent use. And third, they're reliable; they
work when it matters, consistently delivering the results they promised.
Robots, for all their technological sophistication, do not tick these boxes.
First, they aren't easily accessible. Robots require a significant upfront
investment, unlike human labor, which is paid by the hour. Even if the
lifetime cost is lower, the initial capital requirement makes robots
unaffordable for many factories. Next, they aren't naturally usable; they
disrupt existing workflows and cannot be easily reconfigured to meet new
needs. Installing a robot often requires redesigning workflows, retraining
staff, and even assuming new types of risk. Robots are far from the "plug-
and-play" solutions they're made out to be. Robots are also not as adaptable
as humans. When tasks change, reconfiguring a robot is a slow and
expensive process. Factory workers, on the other hand, can be easily
accessed on demand, without incurring such high upfront costs, and are
much more easily redeployed to new tasks. Finally, they aren't always
reliable; when a robot breaks down, productivity grinds to a halt unless
someone with the right skills comes around to fix it. Most factories lack the

in-house expertise to keep robots running reliably, and skilled technicians
are in short supply. As a result, even the most advanced robots may not get
adopted on the factory floor.
In the early phase of every transformative technology, from electricity to
robotics to AI, progress depends on resolving adoption constraints, not just
improving tool performance. Every new tool introduces new friction in
skills to learn, costs to manage, and workflows to change. Once these are
solved, the system gains momentum. That's why the early system builders
who solve for constraints rather than just deploying tools capture the lion's
share of the long-term benefits. These system builders shape the conditions
that turn tools into solutions.
Solving the 'robots problem'
The robotics industry has started to recognize this. To move from tool to
solution, robot manufacturers are no longer just building better machines;
they're trying to make them more accessible. One common approach is to
remove the upfront cost by offering robots through leasing models. Much
like human labor, robots can be paid for by the hour or by the job, reducing
the capital burden on factories. This is not entirely new in the machine
manufacturing industry, where equipment financing has been used to make
expensive tools more accessible in the past.
Leasing robots helps to solve the accessibility problem, but it is only one
part of the equation. For a robotic workforce to be deployed effectively, it
must come bundled with the software and services that enable the robots to
integrate into workflows. This helps to translate the robots' capabilities into
actual productivity. Many manufacturers, while brilliant at building robots,
often struggle to deliver such capabilities that will make the robots more
usable.
This is where the idea of the system builder is key. In the language of
Hughes, a system builder orchestrates the entire architecture needed for that

tool to function. They solve constraints across financing, operations,
software, and services.
A promising approach to solving the robotic deployment challenge is to
treat the deployment of a robotic workforce in a manner similar to
traditional labor staffing. Just as consulting firms like Accenture or
Cognizant provide ready-to-go teams and manage entire projects for their
clients, this shift from selling robots as tools to offering complete solutions
would involve handling everything, from setup to day-to-day management
of robots. This makes them usable and helps them perform reliably in a
customer's context.
Formic, one of the companies pioneering this approach, starts with gaining
a deep understanding of how each factory operates. One of the biggest
challenges in using robots is integrating them into a factory's operations.
This process starts with the factory sharing a detailed scan of their
workspace. Then, using its own specialized software, Formic designs a
custom robot setup for that specific environment. This requires not only
selecting the right robots (tools) for the tasks but also integrating
complementary capabilities, such as computer vision, gripping mechanisms,
pneumatic components, and other elements, required to deliver a complete
solution. Once the configuration is set, the robotic workforce provider
determines the best robots for the task, not just what any one vendor can
supply. If the factory leases robots directly from the manufacturer, it would
be stuck choosing from the manufacturer's robots only. Formic offers robots
from multiple manufacturers, so factories get the right tool for the job.
These robots are then integrated with Formic's proprietary software, which
enables Formic to manage the entire installation centrally and remotely,
from tracking the robots' activities to identifying potential problems early
and resolving issues remotely. Formic charges for robots by the hour, much
like the traditional pricing model for human labor. Its revenue depends on
the productivity of the robots it has deployed. It is in Formic's best interests
to keep the robots operational and running. Essentially, Formic, as a
solution provider, has taken the risk of robot downtime or failure away from
the customer and absorbed it. If robots don't work, they don't get paid.

Robots are incredible tools, but what the factory needs isn't more tools - it
needs solutions.
Tools amplify performance, but solutions absorb risk. And it is that absorption of risk
that assures a customer of the solution's viability.
Formic's focus on absorbing risk away from the customer goes further.
Deploying robots is expensive and carries uncertainty about their long-term
productivity. Traditionally, a customer had to manage the risk associated
with buying robots and then redeploying them if factory workflows
changed. Formic's financial model absorbs both risks. Instead of requiring
customers to invest heavily upfront, Formic uses long-term customer
contracts as a financial instrument. These contracts are not tied to a specific
robot or configuration but represent a commitment to using a robotic
workforce. This flexibility allows Formic to adapt and update
configurations as customer needs evolve. If a customer's needs change, it is
Formic's responsibility to ensure the robotic deployment changes in
response. Formic bears the burden of both the upfront capital expenditure
and the responsibility to ensure its robotic deployments remain productive
and adaptable over time.
Shifting all the risk onto the solution provider - in this case, Formic - might
help the customer, but it would typically make the solution provider's
business model unviable. Here again, Formic innovates to manage this
financial risk by using customer contracts as collateral to fund the upfront
capital expenditure that it needs to take on. With customer contracts in
hand, Formic secures loans from banks to cover the upfront capital
expenditure required for deployments. As customers pay for productivity on
a usage-based model, Formic allocates part of the monthly revenue to cover
service and maintenance costs, and another portion to make monthly loan
repayments. As a solution provider, Formic has effectively allocated risk,
shifting it away from the customer while maintaining the viability of the
solution provider's business model.

Fig. 9.1: Formic's flywheel
More than viability, the business model becomes increasingly attractive
over time. Once the loan is fully repaid, Formic's margins begin to expand,
as ongoing customer payments directly contribute to profitability. Happy
customers renew contracts, and contract renewals drive further profits. As
Formic serves more factories, it learns and constantly improves its
deployments in future projects. This learning also helps renew contracts, as
its installation at a specific customer's factory improves through ongoing
learning.
This model aligns Formic's success with its customers' productivity. By
continuously integrating into customers' operations and improving its
offerings, Formic creates a sustainable business that evolves alongside the
needs of the manufacturing sector. This combination of custom
configurations and financial innovation addresses most of the constraints
hampering robotic adoption.

Managing constraints and complements - what
separates tools from solutions
In the early 1800s, transporting a barrel of flour from the Midwest to New
York City took over three weeks and involved crossing a dozen disjointed
transportation systems. Roads washed out in the rain, rivers frozen in the
winter. A different provider managed every step of the journey - each
controlling a fragment of the route, each optimizing for their own piece, and
none responsible for the whole. Stagecoach lines, wagon builders, toll road
operators, barge owners - they were all tool providers, each indispensable
but none accountable. What was missing was someone willing to manage
the entire system.
The New York State government's solution, the Erie Canal, reengineered
the entire economic infrastructure. The canal guaranteed predictable, year-
round transport, slashing time and cost by more than 90 percent. However,
it only achieved this by identifying and managing every critical constraint
in the system, whether geographic, financial, technical, or operational.
From standardized boat designs to 24-hour lock operations, from public
financing to trained maintenance crews, the canal worked because it
addressed every single constraint in the system.
Formic's shift from selling robots to delivering outcomes shows what real
solutions require: identifying constraints, managing them over time, and
taking responsibility for performance in the real world.
In the previous chapter, we explored how specific tools evolve into engines;
components so central that they begin to determine solution performance.
An engine can throttle performance, and in doing so, hold the rest of the
system hostage. Tool providers who control the engine can squeeze solution
providers by managing that key dependency.
However, controlling performance is not the same as guaranteeing
outcomes. To truly become a solution provider who can not just throttle
performance but guarantee it, you need to move beyond the engine to think
through other constraints that determine performance. It involves taking

responsibility for the outcome as a whole. Managing tool performance is
necessary but not sufficient. You must actively manage all relevant
constraints to ensure that system performance aligns with customer
expectations.
There are many ways to define a solution. We've described it above using
the three attributes of accessibility, usability, and reliability. However, more
than these individual attributes, the test of a solution lies in what it
guarantees: the ability to deliver predictable performance in unpredictable
environments. It guarantees outcomes not by optimizing a single
performance driver, but by addressing all constraints that hinder real-world
performance.
This shift - from shipping tools to delivering guaranteed outcomes - only
becomes possible when you stop treating automation as a product problem
and start treating it as a constraint problem. What's stopping the robot from
guaranteeing value in a real environment? That's what matters. Formic's
insight was that the obstacles weren't in the hardware or the software - they
were in the constraints that surrounded its deployment.
As we've noted before, every system faces negative constraints that limit its
overall performance and growth. Positive constraints, in contrast, enable,
guide, and amplify performance. The key to understanding high-performing
systems lies in resolving negative constraints and managing positive
constraints.
Formic's approach demonstrates that transitioning from tools to solutions
involves building a comprehensive solution bundle and managing all the
surrounding elements that enable real-world performance. This includes
solving across the entire network of interdependent constraints: making the
product easier to purchase, integrate, and operate reliably. Managing this
bundle requires actively identifying negative constraints, such as cost,
complexity, and operational disruption, and introducing positive constraints
that shape how the system performs.
In addition to managing constraints, tool providers who want to become
solution providers also need to manage complements that make their tools
accessible, usable, and reliable. A robot requires vision systems, gripping

mechanisms, software integration, retraining services, and remote support
to function effectively. This act of managing complements makes a tool
accessible, usable, and reliable. When a powerful tool isn't widely used, it's
usually not because the tool doesn't work. The problem, quite often, can be
traced back to the absence of useful complements, which are either missing
entirely or not well integrated with the tool. Tool providers that transition
successfully to becoming solution providers innovate by actively
developing, integrating, and even subsidizing these complements, to
remove adoption barriers. They further innovate by introducing positive
constraints, such as standard interfaces, governance systems, or
performance contracts, that help coordinate the solution at scale.
A tool becomes a solution only when its provider identifies and resolves
negative constraints and proactively manages positive constraints and
complements. In managing constraints and complements that help it
transition from robotic tools to factory automation solutions, Formic
manages an entire solution bundle by addressing constraints that others
offload and integrating complements that others overlook. It brings together
an entire system of robots, enabling technologies, support services, and
financial contracts - all of which work together to deliver outcomes
reliably.
Work, results, outcomes - the business models of
solution providers
When a company stops selling tools and starts guaranteeing results, it starts
managing risk. The shift from tools to solutions involves taking
responsibility for performance and absorbing the risk when things go
wrong. However, as Formic's case shows, this shift only makes sense if the
solution provider can redesign its business model to manage both the risk
and the profit associated with assuming it.
Accordingly, companies that undertake varying levels of risk tend to
employ different types of business models. Some companies charge for the
work they perform, others for the results they deliver to their customers,

and a few go even further, tying their success to the customer's ultimate
outcome. These three models - work-as-a-service, results-as-a-service, and
outcome-as-a-service - each come with a different level of commitment,
risk, and reward. They also determine which companies become trusted
partners for their customers and which ones remain commodity suppliers.
Winterhalter, a German company specializing in commercial kitchen
warewashing, offers a comprehensive solution bundle to keep dishes
spotless, encompassing everything from dishwashers and detergents to
water treatment supplies. Instead of simply charging a fee for access to the
system, Winterhalter charges on a Pay per Wash model, letting customers
pay only for the washes they use. And in return, Winterhalter guarantees
that each wash meets a high standard. Behind the scenes, it ensures that the
machines operate properly, the detergent is mixed correctly, and the water is
clean.
Winterhalter charges for Work-as-a-Service, where the company gets paid
not for owning the equipment, but for keeping it running smoothly and
delivering results. Rolls-Royce uses a similar approach with airplane
engines. Instead of selling engines outright, it charges airlines a set fee for
every hour an engine is in use. To make that work, Rolls-Royce builds a
complete support system of complements - adding sensors, remote
monitoring, and global repair teams - so it can predict and prevent failures
before they happen. In both cases, the companies take full responsibility for
the performance of the machines. The better the machines perform, the
more they earn. That's the key idea behind Work-as-a-Service: the provider
takes on more risk, but also builds deeper trust by tying its success to the
customer's actual results.
To move from selling tools to selling work, providers must track actual
performance, as Winterhalter and Rolls-Royce do. However, transitioning
from providing work-as-a-service to guaranteeing results-as-a-service
necessitates more than reliable monitoring; it requires deep integration into
customers' workflows and specialized domain expertise to deliver tailored,
customer-centric solutions. This is where most solution providers
distinguish themselves further from tool providers.

Orica, one of the world's largest providers of commercial explosives,
illustrates the concept of results-as-a-service. Orica realized that mining
companies don't actually care about explosives; they care about the cost
and ease of extracting value from blasted rock. Smaller, uniform rock
fragments - created through good blast techniques, accounting for the nature
of the rock - are easier and cheaper to handle, crush, and transport. Poorly
executed blasts, by contrast, introduce new issues and can account for up to
80% of total mine processing costs.
A 'tool provider' would have sold explosives (the 'tool') or might have
charged per explosion for the work. Orica charges for results.
Under its Rock-on-Ground contracts, Orica charges not for explosives or
'work', but for the quality of the blast outcome: rock fragmented to an
optimal size that reduces downstream processing costs for mining
companies. Traditionally, mining companies absorbed the risk associated
with poorly executed blasts, but Orica now takes direct responsibility for
the outcome.
Orica designs the blast, selects the explosives, manages the execution, and
guarantees the result. Orica's BlastIQ platform collects and integrates data
across the entire drill-and-blast process, constantly improving blast
performance based on that data. This allows Orica to offer a guaranteed
result: rock fragmented to specification. Now, the company invests
obsessively in improving blast accuracy and efficiency, because each
improvement directly translates into higher profits.
In all the examples so far - Formic, Winterhalter, Rolls-Royce, or Orica -
the shift from selling tools to delivering solutions that guarantee
performance comes down to one thing: the ability to manage the risk
associated with that guarantee. Managing risk comes down to the ability to
capture and monitor data from the environment where the solution is used.
This kind of visibility didn't exist in the past. Once a product left the
factory, the provider had very little insight into how it performed in the
customer's hands. That made it difficult, if not impossible, for companies to
assume responsibility for outcomes. With the rise of sensors, connectivity,

and continuous data capture, however, that has changed. Solution providers
can now monitor performance and take on risk with confidence.
If we apply our five-part coordination framework, we observe that this shift
is primarily a result of improved representation. The solution provider
builds a live model of the customer's environment by capturing data on how
the tool performs in the customer's actual context. That representation
enables more informed decisions about how to manage the solution's
performance. It helps to improve execution by responding promptly to
issues that arise. The ability to take on more responsibility and deliver
reliable outcomes - the essence of becoming a trustworthy solution
provider - begins with the ability to see clearly. Once you can map and
measure the environment into which the solution is deployed, you can
manage risk, guarantee results, and design the solution bundle around the
customer's needs.

Fig. 9.2 : How solution providers gain power through coordination

Some companies that can manage risk effectively can eventually move to
offering outcomes-as-a-service, tying their profitability directly to specific
strategic outcomes crucial to the customer's business. Healthcare and
pharmaceuticals offer some early examples of outcome-based models.
Traditionally, drug companies priced medications uniformly - one pill, one
price. Pharmaceutical companies like Roche have tested Personal
Reimbursement Models (PRMs), where the cost of a medication isn't fixed;
rather, it varies according to the specific patient's condition, treatment
combinations, and the actual therapeutic response. Under PRMs, the same
drug can carry multiple price points, each explicitly tied to how well it
performs in the context of a patient. Every deployment of the drug is done
in a different solution bundle - a different combination of treatments - and
the pricing logic aligns less with the drug as a component and more with the
overall solution bundle guaranteeing the outcome. To truly put this into
action, companies would need to move from pricing drugs alone to charging
for the whole care experience, or the overall solution bundle. To do this,
drug utilization data can help pharmaceutical companies precisely measure
performance. This visibility, in turn, could guide them on the composition
and governance of the solution bundle; which combination of treatments
works best alongside the drug in a specific context.
These pharmaceutical arrangements aren't truly outcomes-as-a-service,
though, as they often operate within a model where risk initially shifts to
customers, who make upfront payments, and needs to be shifted back to
solution providers through insurance if those outcomes aren't achieved.
Customers still face upfront payments and carry uncertainty about potential
refunds.

Table 9.1: Comparison of AI revenue models
AI tool providers have a unique opportunity to move into solution
provisioning and capture more value. Traditional software firms have long
focused on delivering efficiency through modular tools that improve
productivity without requiring a deep understanding of the customer's
context. However, AI tool providers can capture customer context to move
into solution provisioning. Instead of just selling generic tools, AI providers
can learn how customers use them and start charging based on outcomes. In
traditional tool pricing models, the value of the tool is measured in terms of
throughput, in terms of queries answered or images labeled. In outcome-
based pricing models, the value is determined by the solution's ability to
produce meaningful, measurable outcomes for end customers. For example,

an AI solution for managing energy in commercial buildings might not be
priced by the number of sensors it monitors, but by the energy savings or
emissions reductions it helps achieve. To achieve this, it must manage not
only the tool's workings but also its integration into the building's existing
systems and the behavior of building occupants. An AI solution in
healthcare might be priced not by the number of diagnostic scans it
processes, but by how effectively it contributes to faster treatment pathways
or improved recovery rates. The same underlying model, when used in
different solution bundles, across clinics, with varying care protocols, will
generate different levels of value. Outcome pricing reflects this reality.
Moving from work and results to outcomes doesn't come easily, though,
and carries a significant assumption of liability. The work-as-a-service
model thrives when highly standardized and measurable performance
indicators are involved, such as propulsion hours or wash cycles. The
results-as-a-service model, as in the case of Orica, suits situations where
measurable business improvement matters more than mere operational
execution. Here, providers need to integrate closely into customer
processes, as Orica did. The outcomes-as-a-service model, however,
requires 
deep 
domain 
expertise 
and 
sophisticated 
accountability
mechanisms, making it best suited to high-value environments, where the
high value associated with guaranteeing the outcome justifies the liability
and risk associated with it. However, guaranteeing actual outcomes,
particularly when you do not control all the components involved in the
solution bundle, remains a challenge. This progression from work to results
to outcomes involves a shift in what companies promise and how they
manage the risk associated with that promise. Going the full haul to
guarantee outcomes may sound lucrative, but it requires companies to take
full ownership of performance, or risk failing both financially and
reputationally.
Managing liability is the new moat
Applying the work-to-outcomes framework to knowledge work introduces
us to one final tension between tool providers and solution providers.

Cognitive tasks, such as legal analysis, medical diagnosis, or strategic
planning, are not easily quantifiable or measurable in the way that
operational tasks are. An engine runs or it doesn't, but outcomes in
knowledge work involve subjective judgment and interpretation. This
changes how businesses manage risk and liability.
First, there's the ambiguity in measuring the results of knowledge work. In
operational tasks, success is clear-cut, defined by uptime or throughput.
Unlike uptime or blast fragmentation, there is no objective measure of a
good contract or a sound legal opinion. Accountability becomes more
complex owing to this ambiguity.
Moreover, many professional services firms aren't hired to only perform
work or deliver results. Consulting, accounting, and legal firms are often
hired because they take responsibility for the outcome and tie that
responsibility to their reputation. Clients hire these firms for the assurance
and accountability tied directly to eventual outcomes. If something goes
wrong, these firms absorb some of the liability, reinforcing their role as
trusted partners.
This distinction between performing specialized work and absorbing
liability associated with it may not be clear-cut today. Most professional
services firms will still tell you they're in the business of delivering
expertise. However, when AI tools start performing these specialized tasks,
the line between task execution and outcome ownership starts to sharpen.
AI tools often handle specific tasks with speed and accuracy that rival
human experts. Yet, these tools don't address the fallout if something goes
wrong. In effect, they unbundle the performance of these tasks from the
assumption of liability associated with the outcomes. The firms still have to
take on the risk, even though they didn't fully produce the work. If AI
performs more of the underlying work, but the firm continues to carry the
full burden of accountability, the economics and operating model of
professional services will come under pressure.
If a professional services firm is valuable mainly because it takes on the risk
associated with its advice, and not so much because it performs specialized
work, then why couldn't an insurance company handle that risk instead?

Insurers, after all, are already experts at pricing and managing risk. In such
a situation, power and profits would shift away from traditional firms and
toward insurance companies or other specialized players focused entirely on
risk management.
If professional service firms hand off specialized work to AI tools and risk
management to insurers, they end up getting squeezed from both sides - by
AI tools that unbundle skilled work and insurers that unbundle liability
management from them. Furthermore, if insurers and AI tool providers
collaborate more closely, they could, in certain situations, capture all the
power and profit associated with the work. Tool providers capture data on
work performance at industry scale, while insurers working with industry-
wide data can price risk more effectively.

Fig. 9.3: Sandwiching of professional services firms by AI tool
providers and insurers
This scenario of AI tool providers and insurers working at an industry-wide
scale comes with many caveats and may not apply to many forms of
specialized work anytime soon. Yet, it's essential to understand the
conditions under which such a scenario becomes more likely.
First, insurers gain more power when the work in a field becomes
standardized and easier to measure. With better data captured in partnership
with AI tools, insurers can price risk more accurately. With this, the
economic value associated with taking on liability moves away from
solution providers to insurers. Evidence from fields where such
standardization has already played out illustrates how insurers use
proprietary data to wrest control away from solution providers.
In farming, companies like John Deere have experimented with combining
their tools with insurance products, leveraging farming data from tractors
and other sensors to precisely price crop insurance premiums based on
actual field-level risk. Traditional agricultural consultants, who previously
offered expertise and managed relationships between farmers and insurers,
have seen their role shrink in response. Farmers now receive risk
management and insurance solutions bundled directly into data-driven
precision farming platforms. When insurers and tool providers collaborate
closely, traditional intermediaries lose their ability to capture value through
proprietary knowledge or relationship-driven advice.
Standardized knowledge work is relatively rare, though, and professional
services firms still hold key advantages, in longstanding client trust, deep
industry relationships, and domain expertise that tools can't yet replicate.
Clients may be hesitant to shift liability to insurers or AI tool providers that
lack this depth and history. The real risk, then, depends on two factors: the
level of specialization in the work and the degree of risk associated with it.
Work that is both simple and low-risk is most vulnerable to a shift in value
towards AI or insurers. For instance, a simple competitive analysis across
products can be easily performed using tools and carries a lower risk.

Advising a CEO on their capital allocation strategy is far more complex and
comes with significant assumption of risk.
Instead of taking one of two extreme positions on the future of professional
services - that they remain unchanged simply because 'AI won't have the
human touch' or that they get fully replaced by AI, we need to look for
these key factors - the ability of tools to standardize the work involved and
the ability of insurers to price the risk involved.
How far should tool providers climb?
Solution providers, as we've noted through this chapter, exert influence by
managing outcomes, contracts, trust, and liability. If the tool provider wants
to move closer to the customer and capture greater value, it also needs to
accept liability and promise outcomes.
The tool provider, then, faces a trade-off: How far up do you climb?
Too far, and you inherit all the complexities that solution providers live with
- client demands, integration problems, regulatory exposure, and delivery
risk. Not far enough, and you're stuck as a component in someone else's
machine. The art lies in finding the altitude where you capture enough
value, while offloading just enough of the operational complexity and
liability to continue scaling as a tool provider. Meanwhile, solution
providers don't stay silent as tool providers try to inch their way up.
Integrating forward into solution provisioning can trigger unintended
effects.
Specifically, four factors determine the extent to which tool providers
should move into the territory of solution providers. First, does the tool
provider already have an advantageous position that helps it guarantee
results or outcomes? If the tool provider already owns critical assets -
market access or essential user data - then it may be well-positioned to
move into solution provisioning. Second, how aggressively will the solution
provider respond? If solution providers can effectively counter these efforts,
either through competition, litigation, or by switching to alternative tool

providers, the tool provider's expansion may lead to backlash rather than
dominance. Third, does the move raise regulatory scrutiny? Industries such
as finance or healthcare, which are already sensitive to control and liability,
can quickly create compliance headaches. Finally, what's the real strategic
cost of owning customer outcomes? Tool providers, who are focused more
on delivering performance than on ensuring the reliability of outcomes,
might underestimate the burden of client demands, integration complexities,
and the assumption of operational risks and liability.
To evaluate how tool providers navigate these considerations, let's examine
the mining industry, which, at first glance, appears worlds apart from the
knowledge economy, yet offers valuable insights into the trade-offs that
often confront AI tool providers.
Mining is a physical, capital-intensive, and ancient activity as old as human
civilization. Yet today, mining is more important than ever to our
technology-driven future. Electric vehicles, energy grids, batteries, and
solar panels; every pillar of tomorrow's infrastructure depends on critical
metals like lithium, cobalt, and gallium. However, while demand for these
critical metals has surged, new discoveries of accessible deposits have
slowed down dramatically since the mid-2010s. Exploration has become
riskier, more costly, and more challenging. Traditional methods, reliant on
geologists' intuition and expensive, often fruitless drilling, run into steeply
diminishing returns.
Exploration is the first step in identifying potential mining sites. Once
promising targets are identified, drilling commences to confirm whether the
deposits beneath the surface justify the investment required to establish an
operational mine. When successful, these mines can produce output reliably
for 20 to 30 years, generating extraordinary returns for their owners. Yet the
path to this lucrative endpoint is fraught with risk and uncertainty.
Exploration is an expensive, hit-or-miss venture, a business defined more
by failure than success. Easy-to-find deposits have largely been exhausted,
and each new discovery requires increasingly sophisticated and expensive
methods with deep geological analysis and extensive drilling. This
combination of rising costs and high uncertainty drives diminishing returns.

With AI, however, the economics of mineral exploration improve
dramatically, as it enhances the accuracy of finding deposits. By analyzing
vast datasets and identifying patterns in geology, AI reduces the costs and
risks of exploration. Recognizing this potential, an entire range of AI tool
providers has emerged. Tool providers, such as OreFox and SensOre, offer
software that predicts the location, grade, and depth of mineral deposits,
enabling geologists to identify potential mineral deposits more efficiently.
On paper, this is revolutionary, replacing what was so far human guesswork
with machine analysis. However, selling predictive tools alone presents
significant challenges - many geologists still adhere to traditional, old-
school methods and are slow to adopt new tools. These tool providers
confront the same strategic dilemma. Selling predictive AI tools
horizontally across the industry seems promising, but the stubborn inertia of
the customers of these tools - the geologists themselves - limits their
market potential. It turns out that for AI tool providers, simply handing
better maps to traditional miners isn't enough. To truly unlock AI's value,
these tool providers need to explore and verify drill-ready mineral deposits
that can be mined profitably.
If tool providers were to do this, it would create tension with solution-
providing incumbents, the established mining companies, who are
themselves best positioned to explore and verify deposits. Established
mining giants like Rio Tinto recognize the potential of AI, especially when
paired with their strategic advantage: over 150 years of proprietary
geological data and a rich history of drilling results and production metrics.
They utilize this internal knowledge to train AI models that enable
geologists to maximize output from their existing mines. However, because
the return on investment is lower and the risk much higher, Rio Tinto avoids
exploring entirely new, unproven deposits. Instead, it focuses on using AI to
primarily uncover additional resources within known sites. As a result, new
AI tool providers rarely lock horns with incumbent mining firms. As
incumbents like Rio Tinto shy away from new exploration, new AI tool
providers are stepping in to fill that gap. However, to do this effectively,
tool providers must also undertake additional activities, such as verifying

deposits, managing drilling workflows, and ultimately owning the mineral
rights themselves.
Mining is a great example because it has a clear answer to the question of
how far tool providers should move into solution provisioning: as far as it
takes to own rights to mineral deposits profitably.
VerAI Discoveries, another tool provider, illustrates this strategy. Rather
than selling AI tools to explorers, VerAI leverages AI internally to build a
proprietary portfolio of drill-ready targets. Its technology identifies high-
probability mineral deposits hidden beneath the surface, and proactively
partners with exploration companies. When new discoveries are made,
VerAI monetizes its ownership stakes through equity or royalty streams,
aligning its financial incentives directly with successful outcomes. By
moving vertically and integrating prediction with the ownership of mineral
rights, VerAI sidesteps the limitations of slow industry adoption of tools and
also captures far greater value from each successful discovery.
Earth AI, a young mining-tech company, goes even further. It not only
predicts where valuable minerals might be found but also drills and verifies
those sites itself. Instead of waiting on large mining companies or outside
contractors, Earth AI utilizes its own drilling rigs and operates an integrated
workflow from discovery through verification of deposits. By drilling and
verifying deposits, Earth AI identifies deposits with higher accuracy and
validates them quickly at a significantly lower cost than traditional drilling
methods.
This vertical integration across every critical step - AI-based geological
insight, drilling, rapid verification, and ownership of validated mineral
deposits - creates a powerful, self-reinforcing effect. Each successful
discovery feeds new data back into Earth AI's predictive models, improving
their accuracy for future predictions. With each iteration, drilling becomes
faster and cheaper, further reducing costs and increasing efficiency. Over
time, these reinforcing loops accelerate further, allowing Earth AI to rapidly
scale its operations and build an ever-growing portfolio of mineral rights.

Fig. 9.4: The mining industry - How far should tool providers
climb up the solutioning stack
By owning mineral rights, Earth AI can generate revenue either by
operating mines itself or by selling those rights to established mining
companies. These recurring revenue streams are then reinvested in
exploration, additional drilling capacity, and improvements to its AI
capabilities, further accelerating its growth and profitability.
Earth AI's push to transition from a tool that predicts potential deposits to a
solution that offers verified deposits to mining companies is particularly
lucrative because it avoids the typical tension between tool providers and
solution providers. Incumbent solution providers - those who already own
functioning mines - are not incentivized to push back because they prefer to
focus on extracting more from their existing mines rather than taking the
risks associated with exploring brand-new sites. That leaves Earth AI with a
clear opportunity to lead in a space others are avoiding.
The contrast between VerAI Discoveries and Earth AI offers powerful
lessons on how far tool providers should go in solution provisioning. VerAI
Discoveries uses AI to identify potential mineral targets and waits for others
to extract value. However, in a market characterized by slow cycles and risk
aversion, this leaves VerAI in a weak strategic position, where superior
predictions do not necessarily translate into better outcomes. Earth AI's
advantage lies in combining software, geology expertise, and drilling
capabilities into a single integrated solution. It utilizes AI to identify

promising mineral sites and then drills them itself to verify the presence of
minerals. If Earth AI had chosen to operate only as a tool provider, its
effectiveness would have been severely limited. Relying on external
contractors to drill would slow things down, as those contractors might not
prioritize Earth AI's sites. Having great drilling equipment without
sufficient quality sites to explore would simply result in the drilling rig
lying idle most of the time.
AI predictions alone aren't enough - they only create value when combined
with fast, cost-effective drilling that proves the site is worth mining. This
ability to combine prediction with proof in a single, tightly integrated
solution helps Earth AI establish a superior position.
When deciding whether to move further up the stack into solution
provisioning, every tool provider faces the dilemma of how far up to
advance. Four key factors inform this choice. The first is the tool provider's
ability to establish a viable business model as a solution provider. Earth
AI's integration, across AI-driven exploration and rapid verification through
drilling, positions it uniquely to own the asset that matters for establishing a
viable business model - the rights to the mineral deposit. The second is the
ecosystem's response to such a positioning by the tool provider. As we
noted earlier, mining incumbents are either too slow to move or
disincentivized from engaging in greenfield exploration. The third is the
potential for regulatory scrutiny when a tool provider enters the solution
provider's industry. Earth AI's use of AI in exploration helps reduce risk
and environmental impact by improving precision and minimizing
unnecessary drilling, aligning Earth AI's approach positively with
regulatory priorities. A final factor to consider is the operational cost of
owning outcomes. Traditionally, exploring and verifying deposits was
complex and resource-intensive. However, AI enables exploration to be
faster, cheaper, and more accurate. Instead of adding risk and complexity,
AI reduces them, making the move into solution provisioning far more
attractive. Earth AI expands beyond being a mere tool provider, moving far
enough to shape outcomes and tie value to results, but not so far that it has
to run the drills or manage boots on the ground.

Despite starting as a tool provider, Earth AI occupies a strategically
important position in the value chain. It instructs exploration firms where to
drill and guides capital allocation. Because it owns mineral rights, it can
license drill-ready targets on its own terms, acting as a gatekeeper to
verified mineral deposits. Earth AI captures the most important parts of the
value chain in prediction, verification, and licensing, even if others execute
the drilling. As the system scales, each deployment refines its models and
sharpens its predictions, further strengthening this position.
Tool providers don't need to own everything to become solution providers.
They just need to climb high enough to shape outcomes and own just
enough of the system to guarantee results.
The tug-of-war between tool providers and
solution providers
Across this chapter and the previous one, we've explored two key sources
of leverage that define the tension between tool providers and solution
providers. Tool providers try to gain power by controlling the parts of the
system that drive performance. Solution providers, on the other hand, build
influence by guaranteeing reliability and often take on the risk if things go
wrong. The difference between these two sources of leverage - performance
and reliability - is perhaps best illustrated through the contrasting fates of
electric vehicle (EV) manufacturers in North America.
Most EV manufacturers focus on performance. They design better engines
and optimize battery range. But once the vehicle is sold, reliability is
fragmented. The charging experience, which determines the reliability of an
EV as a mobility solution, is handed off to third-party charging networks.
Drivers are confronted with availability issues and unreliable charging
stations. Tesla, by contrast, owns both sources of leverage. On the one hand,
it integrates software and battery management to optimize range and
vehicle performance continuously. On the other hand, it owns the entire
charging infrastructure - the Supercharger network - to guarantee the
ability to charge the vehicle, helping cover longer distances reliably.

Tesla is a rare example of a company that vertically integrates across nearly
every layer of the value chain - a strategy that emerged in response to the
relative immaturity of the electric vehicle industry when Tesla entered. In
most mature industries, however, companies operate within complex,
connected ecosystems where no single player controls the entire end-to-end
solution. Solution providers, accordingly, must navigate a network of
interdependent partners, each contributing a slice of the overall experience.
In connected ecosystems, delivering reliable performance takes more than
just technical excellence or a focus on outcomes. It also requires the ability
to align partners, who may have different priorities. Accordingly, in
connected ecosystems, we see two additional thorny tensions emerge,
which we explore next: the constant jostling among various players to
secure the right to serve the customer and the tension between those who
orchestrate the ecosystem to serve the customer and those who participate
in it.
OceanofPDF.com


OceanofPDF.com


OceanofPDF.com

I
10
DESIGNING FOR INDECISION
HOW COMPANIES TURN CUSTOMER CONFUSION INTO COMPETITIVE
MOATS IN THE AGE OF AI
n the summer of 2020, as part of my work as a strategic advisor to
companies on digital competition, I received a call from the dean of a
prominent university. He was losing sleep over a problem he couldn't
shake. Millions had lost jobs overnight, replaced by a wave of online
courses promising reinvention. The dean saw this as a glimpse of an AI-
driven future, where jobs vanish abruptly, and learning must be continuous.
But education wasn't ready. Universities still bundled skills and credibility
into four-year degrees, clinging to a model built for a different era.
"All this has always been bundled," the dean said. "But the future will be
unbundled." Unbundled jobs. Unbundled skills. Unbundled credentials.
This wasn't a world that today's universities were built to handle. And yet,
the dean believed, it was precisely where education needed to go.
There was, however, a problem with all this unbundling. A traditional career
followed a predictable path. With unbundled learning and unbundled work,
everyone had to chart their path. Learners were overwhelmed by choice.
Employers struggled to assess fragmented credentials.
The more complex challenge, as you would have figured by now, was
rebundling all this in a way that made sense for people navigating careers
that were likely to change a dozen times over. No single actor had the

visibility or authority to coordinate across learning opportunities and career
opportunities.
To the dean, this was a problem about the future of education, but it's really
a problem that shows up across all forms of consumption. As learning,
work, and indeed all consumption become increasingly unbounded, people
face a paradox. There is far greater individual choice in every dimension,
but with that, there is also more confusion. The more options we have, the
harder it becomes to make decisions that we feel confident about and that
are aligned with our goals.
AI offers a powerful solution by simplifying decision-making. It can absorb
the nuance of our context - our goals, preferences, and constraints - and
evaluate countless options on our behalf. In doing so, it delivers
personalized, context-aware guidance we can trust, helping us make more
informed decisions with less effort.
In a world of endless choices, companies win customer loyalty by helping
people make informed decisions with confidence. Decision support is a
powerful source of competitive advantage.
In a crowded ecosystem of competing providers, AI offers a way to reduce decision
friction and guide customers through journeys that build trust at every step.
Nowhere is this clearer than in the electronics retail industry, where the
diverging fates of Best Buy and Circuit City in the age of e-commerce
illustrate how decision support can become a powerful source of
competitive advantage.
Decision support delivers competitive advantage
By the late 2000s, Circuit City had already collapsed following the rise of
Amazon's growing dominance over retail. Best Buy seemed next in line.
Amazon was rising fast, undercutting prices on every product. Retailer
margins were shrinking, and a new phenomenon called "showrooming" was

wreaking havoc. Customers would visit physical stores to browse and test
products but then make their purchases online, often at a lower price. The
store had become a free showroom for someone else's sale.
Circuit City attempted to compete by cutting costs, only to collapse under
shrinking margins and declare bankruptcy in 2008. By 2012, Best Buy's
performance was no different - it lost $1.7 billion in a single quarter. Yet,
over the next 8 years, its stock price grew nearly 10x from its 2012 lows.
How did Best Buy buck the trend?
Best Buy saw what others missed: that, despite their convenience, e-
commerce giants like Amazon didn't help customers make confident,
informed decisions. Consumer electronics purchase, in particular, requires
evaluation and comparison. Choosing the right product takes time, effort,
and expertise - it is knowledge work performed by the consumer. The
average shopper often struggles to determine which OLED TV has the best
refresh rate or which smart home system will integrate seamlessly across
their existing gadgets. They're overwhelmed and unsure.
Best Buy realized that whoever helped customers with these decisions
would win the right to serve them. While other retailers entered a price war
with Amazon, Best Buy focused on the one problem e-commerce couldn't
solve: informing overwhelmed consumers on complex, high-value
purchases.
Best Buy sensed an opportunity to turn its stores into more than just
expensive shelf space. Its stores could be decision-support hubs - spaces
where customers could ask questions and make informed choices. To
become that hub, Best Buy doubled down on employee training and turned
its sales staff into knowledgeable advisors. It trained its store staff to help
customers make informed decisions about products with complex
specifications or confusing installation choices, such as home theater
systems or smart appliances. Circuit City and RadioShack, in their rush to
cut costs, had replaced experienced workers with cheaper, less
knowledgeable employees. But that only made the in-store experience
worse. Best Buy's staff, in contrast, were problem solvers, guiding
overwhelmed customers through their choices.

By eliminating this friction for customers, Best Buy earned their trust.
Customers now came to tinker and learn about the products so that they felt
confident about their choices.
Best Buy had transformed showrooming from a threat into an advantage.
But this model could have been prohibitively expensive. Best Buy,
however, didn't shoulder the full cost of this strategy alone. It invited
brands to create immersive in-store experiences, transforming its locations
into places where customers could evaluate and understand products in
ways that no algorithm or e-commerce listing could replicate. Its brand
partners, companies like Apple and Samsung, seeing value in Best Buy's
trusted in-store experience, began subsidizing training for their products.
This created a virtuous cycle where better-trained staff led to improved
customer experiences, driving increased foot traffic and further
strengthening brand partnerships.
Best Buy's success reveals a key insight - in a world of abundant choice, the
real advantage lies in simplifying decisions. Best Buy absorbed the
customer's decision friction, earning the right to serve them in a way
Amazon couldn't.
Simplify decisions to build loyalty
Companies that help customers navigate decisions effectively win the right
to serve them. But winning that right isn't quite straightforward, especially
when your competitors look nothing like you.
Think of the last time you were deciding where to eat on a Friday night.
You could ask your friends or look at Yelp reviews. Or tap into Google
Maps, as eating out is as much about where to eat as it is about how to get
there. Or order in using Doordash or Deliveroo to avoid that traffic problem
altogether. Every customer journey, even something as run-of-the-mill as
eating out, is a competitive battlefield of players fighting to simplify
choices for you, the customer. And in this battlefield, everyone's looking to
earn the most valuable - and most contested - prize: the right to serve you.

Whichever party wins the right to serve the customer eventually
disintermediates all other relationships within the ecosystem. If customers
make dining choices on Google Maps, restaurants need to manage their
listings there and cough up ad dollars into Google's ad engine as well. The
right to serve starts with the ability to simplify. The company that helps
customers make informed decisions is the one they return to repeatedly. By
reducing friction and clarifying choices, companies earn the right to build
lasting relationships with their customers.
Decision-making is just the tip of the iceberg, though. Every step in the
customer journey, from discovery to purchase, setup, and even
troubleshooting, demands cognitive effort. Before the internet and later the
smartphone, customer journeys were linear and straightforward. You could
ask a friend, browse a catalog, or visit a store. The rise of the smartphone
has fragmented decision-making across a wide range of channels. Today,
buying a simple blender might involve scrolling through Amazon reviews,
watching YouTube unboxing videos, and getting influenced by that one
viral TikTok video. Such unbundling of the customer journey further
intensifies the competition for the customer.
Best Buy had cracked one of the most challenging problems in modern
retail: how to reassemble a broken customer experience. Recognizing that
choice is abundant but guidance is scarce, it gained an initial foothold in the
customer journey by turning its stores into decision-support hubs. That
initial foothold, in helping customers decide, gave Best Buy the right to
rebundle by integrating across other steps in the customer journey,
spanning product selection, installation, ongoing usage, and customer
support.
What about showrooming? Wasn't that still a risk? Couldn't customers just
try out a product in-store, then order it at a cheaper price on Amazon?
Now that Best Buy had a foothold in the customer journey, it had a solution
to this problem. Once a customer came into the store, Best Buy guaranteed
price parity with Amazon. No undercutting, no price wars, just a guarantee
that if you made your decision here, you wouldn't pay any more than you

would elsewhere. The hard part of getting the customer in the door was
already done. Moving them to purchase came at almost zero extra cost.
Other retailers were locked in a race to the bottom, constantly slashing
prices to compete with Amazon's algorithm. Best Buy avoided that trap.
Customers were coming for better decisions, not for better deals. Once
inside, all Best Buy needed was parity. Price competition is what you reach
for when you're locked out of the customer journey. It is a desperate
attempt to get into the customer journey. When you don't yet have the
customer's trust or mindshare, a lower price becomes your only lever.
However, that comes at a cost: it trains customers to view you as a
commodity.
Price parity, on the other hand, is how you extract more value from the
journey you're already in. You're not trying to win the transaction; you're
trying to strengthen the relationship you've already established with the
customer. And that's how Best Buy turned its biggest threat, showrooming,
into a durable advantage.
The right to rebundle
Best Buy's success highlights three key principles for securing a shifting
competitive landscape in your favor.
First, Best Buy simplified decisions for customers who were overwhelmed.
When shoppers couldn't tell which TV or laptop was right for them, Best
Buy's trained staff guided them to confident choices. But this alone
wouldn't have saved it from Amazon's onslaught. Simplifying decisions
gives you the right to play. It doesn't grant you the right to win.
Second, what transformed Best Buy's helpful service into market
dominance was its ability to establish a strategic control point in the
customer journey. By owning the high-anxiety moment when customers
evaluate complex products, Best Buy made its stores the go-to decision
hubs - something Amazon's algorithms couldn't replicate.

A control point is created by solving a high-friction decision in the
customer journey, where reducing complexity earns trust, locks in
customers, and creates leverage over adjacent players. It anchors the
ecosystem around you, making your advantage durable and difficult to
replicate. Best Buy first became indispensable to customers by guiding
complex decisions; then, using that position, it became indispensable to
partners who sought to access those customers. It established its store
footprint as a platform where brands could showcase products and influence
choices in ways that Amazon and other online rivals couldn't match.
Fig. 10.1: Using a control point in the customer journey to rebundle the
ecosystem

Winning one step of the customer journey isn't enough, though. The real
power comes from creating a unified customer journey.
This brings us to the third principle: leverage the control point to rebundle
the ecosystem. Rebundling involves using your control point over the
customer to reorganize complementary services and capabilities to serve the
customer. Amazon started as an e-commerce retailer that established a
control point over the customer relationship by offering two-day delivery
and free returns through Amazon Prime. It then used that control point to
rebundle the entire retail ecosystem around itself, by bringing third-party
sellers onto its marketplace to create a one-stop shop.
Best Buy didn't build a marketplace - its path to rebundling was built
around its unique control point in in-store decision support. First, it
leveraged price parity to ensure that customers didn't just use the stores to
make decisions and then shop online - they bought in-store. With this ability
to control both the decision and the transaction, brands were now dependent
on it if they wanted to influence customers towards in-store sales. Brands
like Samsung couldn't reach certain customers, particularly those needing
hands-on guidance, without Best Buy's in-store advisory infrastructure. This
allowed Best Buy to set the rules of engagement for these brands. It
determined how products were displayed, explained, and sold in their
stores, standardizing the customer experience while reinforcing its position
as the trusted advisor. With this position established, Best Buy could now
tax its partners, through premium placement fees, revenue sharing, and
training subsidies, precisely because brands needed access to Best Buy's
influence over customer decisions. When other retailers failed to establish
these same mechanisms, brands saw little reason to invest in their
struggling stores. Best Buy's example demonstrates that whoever owns the
control point gets to shape the ecosystem on their terms.
In a fragmented, high-choice world, competitive advantage goes to those who build
trust by simplifying decisions, establish control points on that basis, and use that
leverage to rebundle the ecosystem around themselves.

From customer journeys to integrated experiences
If you listen to brands talk about their customers, you'd think customers
move through a structured, step-by-step journey - from awareness to
decision to purchase - as if they were following very specific steps. But real
people don't follow steps; they respond to impulses and frustrations in
unpredictable ways. That's where rebundling often goes wrong: companies
try to stitch together discrete steps in a 'customer journey' instead of
designing environments where the desired actions happen naturally. The
paradox of customer journey rebundling is that it works best when it doesn't
feel engineered at all. Over-optimizing and improving individual steps
while failing to create an experience people want to return to might
backfire.
Sephora understands the importance of deep, connected, engaging
experiences. The beauty industry is increasingly fragmented - TikTok
influencers dictate trends, Amazon undercuts prices, and high-end salons
provide personalized service that no retailer can match. Yet, Sephora
understands that winning the right to serve the customer doesn't stop with
dominating individual steps across the journey; it requires orchestrating the
entire experience.
Sephora's approach to rebundling the customer journey began with a simple
observation: that the makeup buying experience was broken. Customers
were frustrated, spending hundreds of dollars on makeup foundations that
ended up abandoned in bathroom drawers, victims of poor color matching
and confusing application techniques. Much like Best Buy, Sephora
recognized that helping customers make better choices was more valuable
than simply offering more options.
Sephora's solution to this problem involves a simple entry point: a handheld
scanner that reads skin tone and assigns a unique Color IQ code. With a few
quick questions about the customer's preferences, the system recommends
foundations from multiple brands tailored to the customer's tone and style.
This one decision becomes Sephora's entry point into the customer journey.
By solving a high-friction choice, Sephora builds trust and gathers data to

guide future interactions. Over time, it has incorporated more advanced AI
capabilities into the original Color IQ and added new entry points into the
customer journey. It uses these entry points to create a foothold in the
customer journey and rebundle related services, ranging from product
tutorials to virtual try-ons. Its digital ecosystem, featuring online
communities and makeup tools, helps customers discover, test, and learn at
every stage of their beauty journey.
What made Sephora's strategy so effective was its ability to connect the
dots across the customer journey. A customer might discover a product on
Sephora's TikTok channel, try it virtually on the Sephora app, read reviews
online, get a personalized match in-store, and make the final purchase from
her phone, all while staying within the Sephora ecosystem. A young woman
walking into Sephora for a foundation match no longer leaves with just a
bottle of foundation or makeup matched to her skin tone. She leaves with a
Sephora-guided path through the beauty industry.
From competition to control
I first started looking into Sephora's impact on beauty retail when a leading
European beauty brand invited me to speak to their board, to help them
make sense of a problem that was becoming increasingly difficult to ignore.
Brand power once dominated the beauty industry, with loyalty tied to
names like EstÃ©e Lauder or L'OrÃ©al. Brand building was expensive, and few
could afford it. Yet, once built, it was a powerful moat. But that was
changing. With social media, unknown brands could scale overnight,
propelled by influencer hype and viral trends, bypassing traditional
gatekeepers.
At least, that was the prevailing narrative with which my client began
examining the problem. But as they interviewed their target market, they
figured that the challenge was more complex. Influencers could help drive
demand, but that wasn't enough. Paradoxically, the path to success for
brands was still controlled by a traditional gatekeeper - Sephora.

Sephora was no longer just a powerful retailer; it had become a kingmaker.
If your product made it onto its shelves, your brand had a future. If not, the
road ahead was steep. Power had shifted away from brand loyalty toward
owning the customer's choices, and Sephora was leading that shift, making
it nearly impossible for brands to bypass its influence. Sephora follows a
three-part playbook to manage this restructuring of power: helping
customers make key decisions, locking them into its ecosystem, and earning
money from the brands that want access to those customers. First, tools like
Color IQ capture customers early by guiding purchase decisions. Second,
loyalty programs, in-store exclusives, and digital engagement keep them
coming back. And third, brands pay a premium for access to this highly
engaged customer base.
For all these years, beauty brands had worried about competition from other
brands. Now, they were worried about control. Control no longer comes
from simply selling products; it comes from owning the customer's decision
and attention. And any company, like Sephora, that meets the customer at
their moment of need gains outsize power, turning once-independent brands
into dependent players in its ecosystem.
Direct vs derived demand
The power shift from beauty brands to beauty retailers can be traced back to
understanding the difference between what customers buy and what they
actually want.
Think about it this way: nobody wakes up wanting foundation or lipstick
for its own sake. What they want is beauty, confidence, and self-expression.
The product is just a means to that end. Economists have a term for this:
beauty brands compete in derived demand, selling products that derive their
value from satisfying more fundamental human needs. Beauty brands
played this game well. Through powerful branding, they escaped
commodity competition by associating their lipsticks and serums with
aspirational feelings rather than just functional benefits. L'OrÃ©al wasn't
selling moisturizer; it was selling beauty and confidence.

But Sephora had introduced a different game. It was selling beauty and
confidence, not merely through branding exercises, but by positioning itself
as the customer's trusted advisor. It addressed the direct demand - the
primary, emotional, and aspirational needs that drove consumers to seek
beauty products - and it did so by creating an immersive ecosystem that
guided and engaged the customer.
Irrespective of your industry, the conflict between direct demand and
derived demand plays a big role in determining control and power today.
Companies that own direct demand inevitably dictate terms to those that
compete in derived demand. Homebuyers, for instance, dream of houses,
not mortgages. Real estate search platforms like Zillow capture direct
demand by guiding buyers through their decisions, while banks are often
reduced to commodity players, forced into price wars.
Sephora understood the importance of controlling direct demand, and with
that, gained the right to dominate derived demand. If a customer's beauty
journey began with Sephora, it had the power to decide which brands
showed up on its shelves and in its recommendation systems.
Owning direct demand is now the strongest position in any ecosystem, and
Sephora saw this earlier than most. It built an immersive platform around
the customer's goals. But the brand I was advising had misunderstood
Sephora's strategy. Instead of recognizing the power of serving primary
demand and building an ecosystem around the right to serve the customer,
they misread Sephora's success as a channel play. Their instinct,
accordingly, was to go direct-to-consumer (D2C) themselves and own their
destiny. Inspired by D2C brand Glossier, they believed they could bypass
Sephora, build a community on social media, and own the customer
relationship directly. A consulting firm had validated this with a 136-page
dossier. Glossier, after all, had scaled its business without relying on
traditional retail to build a cult-like following. The 'Glossier dossier' had
now become a bible of sorts internally. By building their own sales channel,
they could retain more margin and exert greater control over their brand
experience.

I told them what they didn't want to hear: no single brand could outcompete
an ecosystem. Sephora already controlled key decision-making moments
and combined immersive engagement with the convenience of a one-stop
shop. My client, limited to its own products, would spend heavily on
customer acquisition, only to offer a narrower, less compelling experience.
Instead, I urged them to organize a partner ecosystem by activating their
biggest untapped asset: their network of high-end salons and beauty
professionals. Instead of trying to claw back control through direct sales,
they could more cohesively organize their existing ecosystem of trusted
beauty professionals, helping consumers make more confident decisions.
The board members nodded politely, but remained unconvinced. It was
2019, and D2C was booming.
By 2022, though, the cracks had started to show. D2C didn't scale well, and
customer acquisition costs had skyrocketed. By 2023, Glossier, which had
once shunned retail, now desperately needed Sephora. The dream of pure
D2C dominance had faded. Within months of getting on Sephora's shelves,
sales were back up for Glossier. A bottle of Glossier You was selling every
47 seconds.
Meanwhile, my client had built its direct-to-consumer channel but found
itself stuck in an expensive loop, constantly spending on ads just to attract
new customers. With the benefit of hindsight, the strategy I proposed back
in 2019 now made a lot more sense. When they brought me back in 2023,
they were ready for a new approach.
Building trust in AI assistance
When I returned to work with my client in early 2023, the timing was
perfect. ChatGPT had just gone mainstream, and generative AI now offered
a practical way to revive the strategy I had proposed years earlier: turning
their network of salon professionals into a decision-support infrastructure.
By training AI on their proprietary knowledge, brands could now build
highly effective AI assistance to support customer decisions.

AI assistance, however, carries risk. If not managed carefully, AI assistance
can expose brands to reputation damage and even create liability
nightmares. Whether it's beauty products or mortgages, the challenge for
customers isn't a lack of choice, but managing uncertainty about which
one's right for them. An AI assistant needs to provide answers that are
trusted, accurate, and legally defensible.
My client had two options: either to let customers use the AI directly or to
have experts utilize AI to guide customers better. The better strategy, here,
was to embed AI assistance within their network of salon professionals and
beauty influencers, who already played a key role in guiding consumers but
lacked formal assistance. With AI assistance, experts can make more
informed recommendations while still exercising their judgment.
This choice came with a clear trade-off. When AI supports professionals
behind the scenes, it doesn't need to be perfect - experts can step in, correct
errors, and guide the customer. Liability for the final recommendation also
shifts from the brand providing AI assistance to the expert using it. This
reduces brand risk and allows the AI to improve over time. Once mature,
the AI can be used directly with customers. Until then, the human layer
ensures safe, trusted decisions.
Deploying AI directly to consumers is far riskier. With no expert to catch
mistakes, errors go straight to the customer, and the fallout is immediate
and, worse still, unintentionally viral. Trust, once lost, is difficult to regain.
Deploying AI through intermediaries, such as salon professionals,
influencers, and channel partners, is different. Intermediaries have built-in
trust and can compensate for AI's weaknesses by filtering out bad
suggestions before they reach the consumer.
For my client, the decision came down to balancing two factors:
complexity and risk. AI is excellent at handling complex choices - exactly
what we needed to build trust in the beauty space. But how safely we could
deploy it depended on the risk of getting a recommendation wrong. When
decisions are complex but low-risk, like choosing a recipe, AI can assist
directly, even if it occasionally makes mistakes. However, for higher-risk
decisions, like planning your finances or diagnosing a health issue,

accuracy matters a lot more. A wrong answer comes with serious
consequences.
That's why industries dealing with high-risk decisions rarely give AI tools
directly to consumers. Instead, they integrate AI into expert workflows. A
carmaker, for instance, won't ask drivers to diagnose engine issues using
AI, but it will equip mechanics with those tools. The mechanic's judgment
serves as a safety net, catching mistakes before they reach the customer.
The brand still benefits from AI's scale and speed, without risking its
reputation.
Once companies assess the risk and deploy AI wisely, they can use that
foothold to create new control points in the customer journey, or, more
powerfully, to wrest control from established incumbents.
Using AI to capture the control point
Technological shifts, like AI, create rare opportunities to disrupt incumbents
and shift power. Google became dominant by owning a control point: it sat
between users and the information they needed. However, generative AI
tools like ChatGPT introduced a new control point by addressing those
same needs in a new way. In every industry, control points determine who
holds power, and those who redefine them get to capture power from
incumbents.
Sephora became a gatekeeper, controlling access between brands and
customers. I urged my client to work on creating its own control point
within the customer journey, shifting power from retailers to the brand.
Three types of control points can be established in the customer journey.
First, there are relationship-based control points. My client's salon network
was already strong here. Their stylists had deep, trust-based relationships
with customers that beauty retailers or e-commerce platforms could not
easily replicate. It's the same advantage local car dealers hold over auto
manufacturers: they know their customers and understand the local context.
Second, there are workflow-based control points, where companies

integrate themselves into critical processes, much like how design software
provider Figma has made itself indispensable to design teams by owning
their collaboration workflow. What AI offered my client was the chance to
establish a third type: an intelligence-based control point. Platforms like
Google Maps and TripAdvisor hold such a significant control point in
shaping travel decisions through ratings and recommendations, which
grants them leverage in the travel ecosystem. Our AI solution could
establish a similar control point in the customer journey by guiding beauty
choices based on personalized data and expert insights.
AI doesn't just create new control points - it can also dismantle those
currently held by others. In traditional manufacturer-reseller models,
resellers control two things: product knowledge and local customer insight.
But manufacturers can challenge this by introducing AI sales assistants
trained on their proprietary product information. Initially, the AI supports
resellers, particularly those with less experience. But over time, it acts like a
Trojan horse. The more resellers use it, the more customer data it collects,
making the AI smarter and gradually shifting control back to the
manufacturer. Eventually, manufacturers bypass resellers entirely, either by
directly engaging customers with a customer-facing AI assistant or by
commoditizing the reseller's role and thereby reducing their margins. The
reseller's relationship advantage diminishes, and the manufacturer's
intelligence advantage prevails.

Fig. 10.2 : How AI helps usurp relationship-based control points
At the next board meeting, I explained how our AI deployment would play
out similarly. Initially, the AI assistance would support salon professionals,
acting as a helpful assistant. However, as it improved and the risk of
deployment decreased, it could be served directly to consumers. While a top
beauty consultant can help a few clients a day, a consumer-facing AI
assistant can assist millions.
As accuracy and reliability increased, we could also expand beyond our
core salon network, offering the AI assistance to a broader set of beauty
professionals, including many who had never worked with us before. This
would significantly grow our ecosystem, drawing in more professionals,

more customers, and most importantly, more data. The boardroom buzzed
with energy. Everyone could see the feedback loop taking shape: more
usage meant better recommendations, which in turn attracted more users.
This compounded advantage made the system more accurate over time, also
making it harder to displace.
Over time, control in the ecosystem would shift from a fragmented network
of salon-to-customer relationships toward a centralized, intelligence-based
control point. Salon professionals would still play an important role, but the
power to influence decisions would now sit with the platform.
As this AI decision-support system matured, it would also open a path to
transform entire salon operations. Integrated into salon management
software, the AI could help salon owners track which recommendations
drove repeat visits, which products led to retention, and which stylists
delivered the best outcomes. We could go beyond helping stylists one-on-
one and start supporting entire salon chains. As more salons came on board,
the AI assistant would become smarter. Better data would drive better
recommendations, which in turn would attract even more users, a classic
network effect.

Fig. 10.3: How AI helps usurp workflow-based control points
The real shift, though, was in power. Helping customers make better
decisions is essential, but power comes from what happens next. The real
goal of supporting stylists with AI was to reposition the brand at the center
of the ecosystem. It was a subtle path towards shifting control in a
fragmented industry, from a loose network of human relationships to a
centralized, intelligence-driven platform.
The beauty salon industry is highly fragmented. A brand's product-mix
decisions are typically based on broad sales trends rather than the specific
needs of each salon. By gathering intelligence across salons, our AI solution
would also identify industry-wide trends, which would help forecast
demand and manage product mix decisions in response to changing demand

patterns. Think of the shift in visibility Walmart had with the rise of
barcodes, or Shein has in contrast to Zara. With this strategy, we would
create similar visibility into salon operations.
This visibility into demand would give us gatekeeping power over other
brands. As the AI improved, trained on individual choices across thousands
of salons, it gained greater visibility across the entire ecosystem. This is
how ecosystems get reorganized by moving away from competing on
features, to repositioning around a new control point. Brands that guide
customer decisions at scale and insert themselves into important workflows
move from being participants to orchestrators. That's how they earn the
right to rebundle.
This brings us back to the puzzle with which we opened this chapter: how
can AI help us rebundle one of the most complex ecosystems - education?
Not only is it becoming increasingly fragmented with new types of learning
opportunities and a rapidly changing work landscape transformed by AI, but
it is also a lifelong customer journey.
Rebundling lifelong learning
For over a century, education has involved one simple transaction: four
years of college for a lifetime of job security. But when jobs evolve faster
than the degrees designed to prepare us for them, the traditional degree no
longer suffices. Today's work doesn't look like yesterday's - it includes one-
off gigs, specialized projects, network collaborations, and entrepreneurial
ventures.
Micro-credentials - certifications that recognize smaller, specific skill sets
or educational experiences - promise a way forward. They offer flexibility,
letting people collect skills piece by piece. However, these credentials don't
always align neatly with work opportunities, especially as new roles emerge
constantly.
The dean's central question was essentially this: How do we organize
fragmented credentials to meet the demands of a fast-changing job market?

Yes, this involves helping learners decide which credentials to pursue and
when to pursue them. But that's only the visible layer masking the more
complex coordination problem underneath: how to align a fragmented
supply of learning options with a constantly shifting demand for skills, and
how to map both to each learner's journey.
The dean's challenge highlights a core theme of this book: unbundling
outdated systems and rebundling them through smarter coordination. In this
case, the coordination problem involved two parts: aligning learning
opportunities with relevant skills, and aligning those skills with real work
opportunities. Without that alignment, people earn credentials that don't
open doors and pursue learning paths that no longer match market needs.
This is where AI assistants and agentic execution offer a path forward. AI
can ease decision fatigue by helping learners navigate a growing landscape
of work and education options. Agentic execution can help connect past
learning to future opportunities, guiding learners along personalized
learning paths that are tailored to their needs. Digital wallets make this
possible by storing work and learning records in one place, allowing
individuals to carry their credentials across jobs and platforms. The tools of
AI assistance, micro-credentials, agentic execution, and credential wallets
already exist. What's missing is the system to coordinate across people,
skills, and opportunities.
Fig. 10.4: Rebundling the lifelong learning ecosystem
To understand how these components work together to rebundle a learner's
learning experience, let's consider the case of Tia, who represents millions

of young professionals navigating today's fragmented learning landscape.
Her credentials are scattered across platforms, her freelance reviews locked
on freelancing platforms like UpWork, with no easy way to signal her
evolving capabilities to potential employers. Our solution would rebundle
Tia's learning journey around her career aspirations.
To start with, Tia's AI assistant scans her profile - skills, past work, current
learning - and deploys an army of AI agents to work behind the scenes. For
Tia, this is a simple conversation with her AI assistant. But at the backend,
there's an entire agentic system that needs to be designed. And for this to
work, there must be trust, both from Tia and the employers she hopes to
engage. That's where her credential wallet comes in. This digital wallet
stores her micro-credentials, project outcomes, and milestones in one
portable and secure location. She decides when, where, and how to share
that information with employers or learning providers. It's her learning
history, on her terms. Lifelong learning becomes possible when learners
own their data and AI agents act on their behalf. This future isn't limited by
technology; it's held back only by legacy systems that haven't reorganized
around AI. For this vision to work, coordination is essential.
The solution to the dean's problem reveals one final powerful lesson about
organizing ecosystems and establishing control. Through this chapter,
we've focused on addressing the customer's decision as the way to earn
trust, reduce friction, and guide action in a fragmented landscape. But
decision support is only an entry point. Beneath every decision lies a tangle
of fragmented actors, misaligned incentives, and missing connections.
Unless we address that underlying coordination problem, even the smartest
AI assistant is navigating with a broken map. To truly transform
ecosystems, we need more than decision support. That's what we explore
next: the architecture of coordination that makes these decisions reliable
and scalable even when dependent on an ecosystem of fragmented, non-
cooperating actors.
OceanofPDF.com


OceanofPDF.com


OceanofPDF.com

I
11
CONTROL WITHOUT CONSENSUS
HOW AI REWRITES ECOSYSTEM POWER
n late 2022, Amazon announced the largest layoff in its history up to that
point. It was letting go of 10,000 employees. What was surprising,
though, was that a large part of the announced layoff came from its Alexa
division, long celebrated as the vanguard of voice assistants and a bold bet
on the future of the smart home. Alexa was Amazon's story of 'skate to
where the puck is going". Having missed the smartphone revolution and
ceded dominance to Apple and Google, Amazon saw voice interfaces as its
second chance to own the gateway to consumer intent. Apple's Siri may
have been first, but Amazon quickly dominated the smart speaker market.
Why would Amazon choose to downsize such a vital segment?
Alexa, Amazon's AI-powered voice assistant, was positioned as a voice-
activated control system for the smart home. In the early 2010s, device
manufacturers like GE and Honeywell were looking to create smart home
device hubs around their sensor-equipped devices. However, no single
smart device, whether a thermostat, light bulb, or refrigerator, was central
enough to anchor the entire home around itself. But a voice assistant that
could interpret user intent and coordinate all devices? That could become
the default interface for daily life.
Amazon's ambition for Alexa, though, was more than a smart home hub;
Alexa would be the universal translator between household needs and an

ecosystem of partners waiting to serve them. Amazon already had a head
start in serving household needs through its e-commerce business, and it
leveraged those customers, particularly users of its membership service
Amazon Prime, to drive adoption of Alexa. Users would no longer have to
go through multiple clicks on a website; they could simply order items from
Amazon's online marketplace using voice commands.
Amazon started selling Alexa-equipped Echo speakers and set up Alexa as a
platform that partners could plug into and build services for customers.
Partners would develop Alexa skills - voice-activated capabilities that
allowed users to interact with their services or devices through voice
commands. With the Alexa Skills Kit, partners could create new voice-
activated functions, much like third-party apps on the iPhone app store. For
instance, the Uber 'skill' allowed users to request Uber rides using Alexa's
voice commands. Amazon even set aside $100 million as the Alexa Fund to
support innovation in this ecosystem. By 2019, nearly 100,000 skills had
been developed for the Alexa platform.
On the surface, Alexa seemed to have achieved the dream of platform
dominance. It sat at a privileged moment in the customer journey - voice-
based interaction and decision support - and had attracted a vast ecosystem
of complementary capabilities in Alexa skills. More capabilities, more
partners, more things it could do - at least on paper. But by 2022, cracks had
begun to show. Despite the expanding library of skills, the dominant use
cases for Alexa remained embarrassingly basic: weather, music, and timers.
The bold vision of voice-driven commerce and rich developer experiences
never materialized.
By all accounts, Amazon had a strong position in the customer journey. It
was the dominant e-commerce business; it had a flourishing membership
service in Amazon Prime, its forays into movies and music had been
successful, engaging users further, and its Alexa-enabled Echo speakers
now sat on countertops waiting for your command. If there was ever a
company that had established control points in the customer journey, it was
this one. Yet, Alexa never quite delivered what it had set out to. What went
wrong?

Voice interfaces live or die by their ability to interpret user needs and
respond with the right information or service. A voice interface needs to
understand ambiguous requests, map them to relevant capabilities, resolve
conflicts between options, and execute transactions with minimal back-and-
forth communication. Alexa never got there. A user might ask Alexa to
"order a pizza," only to be told they needed to enable a specific skill set up
by Domino's, link their Domino's account to use it, or use a precise
command like "ask Domino's to place a guest order." Once inside the skill,
they had to remember how to exit the skill and couldn't easily ask follow-
up questions or transition to other skills. Even when developers complied
with the design requirements of the platform, Alexa's AI failed to deliver a
simple user experience.
Alexa's much hyped AI had failed to stand the test of coordination. It didn't
carry enough user context. It needed users to follow painfully exact syntax.
It couldn't handle composite tasks or chain intent across skills. Instead of
absorbing complexity on behalf of the user, it moved the complexity back
to them.
Control isn't established just by owning the interface. It's established by resolving the
coordination burden that stands between users and the outcomes they seek.
Without a powerful coordination mechanism, skills became trapped behind
an unreliable interface. Alexa expected users to know the name of the skill,
remember the required phrasing, and manually manage transitions between
one skill and the next. Worse, many skills required setup in a separate app.
In practice, it was often easier to just use a smartphone.
Amazon's ecosystem vision could not be faulted. But it had scaled the
ecosystem around an engine that didn't work. The system's performance
depended on the performance of Alexa's AI. Meanwhile, newer AI
platforms - especially those powered by large language models (LLMs) -
began to show what a more capable coordination layer might look like.
Tools like ChatGPT, despite their limitations, demonstrated the ability to
understand composite queries, tease out intent, and chain actions, all of
which were skills that Alexa had promised but never delivered.

Amazon has since worked on improving Alexa's AI, but its story, leading
up to 2022, illustrates one of the most important lessons in serving AI into
complex ecosystems. Ecosystems often fail not because of their inability to
organize the visible requirements but because of their inability to manage
the invisible ones. The complementary capabilities around your core
solution are the visible parts of the ecosystem - apps on a smartphone,
listings on an online marketplace, or drivers on a ride-hailing service. Yet,
the presence of complementary capabilities from partners isn't enough.
Setting up partnerships doesn't grant you the right to manage an ecosystem.
You need to coordinate those partners, and more importantly, you need to
have a mechanism to establish control over ecosystem activity without
exercising direct control over it. Alexa failed not for lack of ambition or
adoption, but because it never earned the right to control the system.
We often describe the most powerful companies in an ecosystem - Google
in online search, Meta in social networking, Amazon in e-commerce - as
gatekeepers. This language suggests that their dominance stems from
owning a critical control point in the customer journey. With that framing,
Alexa was very well positioned, given Amazon's existing dominance in e-
commerce.
However, Alexa failed on two counts. First, it was unable to extend
Amazon's demand-side control in e-commerce and Prime into a comparable
control point around the usage of its voice-based interface. More
importantly, it lacked a supply-side control point. In e-commerce, Amazon's
fulfillment system addresses a key coordination problem by bundling
storage, shipping, and delivery, allowing merchants to offer Prime-level
speed and reliability without building their own infrastructure. In contrast,
Alexa never solved the hardest coordination problem in its ecosystem: how
to unify a fragmented set of device makers, service providers, and
developers into a coordinated experience for the user. Thermostat makers,
ride-hailing services, food delivery companies, and home security vendors
all built Alexa skills. However, these partners remained fragmented, unable
to coordinate effectively because Alexa failed to provide the connective
capabilities - namely, the integration logic, contextual intelligence, and

resolution of competing intents - that would enable them to function like
parts of a unified system.
To lead an ecosystem, you must organize fragmented partners by resolving
the frictions that prevent them from coordinating to solve the customer's
problem. Alexa never did. It asked partners to build, but it didn't equip them
to work together. Developers built individual skills in isolation. But there
was no reliable way to chain one partner's service to another. The result was
a chaotic experience hidden behind a smooth, reassuring voice.
Although Amazon had scale and distribution, partners had little reason to
rely on Alexa as their primary channel. The platform didn't make their
services more valuable or more usable; in fact, in many cases, as with the
pizza ordering example above, it made them harder to access. In the
absence of real coordination, many partners abandoned or deprioritized
Alexa, and users followed.
Control points aren't created through dominance but through dependence.
Alexa couldn't anchor the ecosystem because no one truly depended on it to
deliver value. In ecosystems, control comes from solving the coordination
problem that no one else can solve. Alexa never earned the right to control
the system because it failed to solve the one problem others needed it to
solve.
Control points
Throughout the preceding chapters, we've explored the competitive
tensions that arise in ecosystems in the context of AI adoption. All these
tensions can be traced back to a single source - a relentless jostling for
power in the value chain.
Tool providers look to gain power by establishing themselves as the engine
that drives solution performance. Solution providers, by contrast, aim to
guarantee outcomes and own the customer relationship. But ultimately, both
are competing for the same prize: control.

Control, in this context, refers to more than just customer access. It involves
owning a strategic position in the ecosystem - a point that others must work
through to deliver value.
The player that owns key control points is uniquely positioned to shape how the entire
system functions, and just as importantly, to manage the competitive tensions that
arise when every participant wants to capture more value.
Control points aren't new. Even in the industrial economy, companies built
power by capturing control points over production inputs, supply chains, or
distribution networks. Consider the case of the Minnetonka Corporation's
Softsoap - the first mass-market liquid hand soap packaged in a convenient
pump bottle for home use. Concerned that giants like Procter & Gamble and
Unilever could copy the formula and crush them on shelf space,
Minnetonka bought up the world's supply of plastic pumps - a key
component needed for dispensing liquid soap. Without pumps, the big
players couldn't launch a competing product, at least not for another year.
This gave Minnetonka just enough time to saturate the market, build brand
recognition, and lock in key retail relationships. The pump wasn't part of
their core value proposition, but it was a control point - a bottleneck in the
supply chain that let them shape the competitive landscape. This was
industrial-era power: a valve in the system that, if you squeezed it tight
enough, kept your competitors at bay.
But the nature of control has fundamentally changed for two reasons. First,
industrial-era control was achieved by owning scarce assets to create
physical bottlenecks. Control meant exclusion: keeping rivals out, pushing
suppliers down, and pulling margins up. Second, traditional control
involved exercising power unilaterally over other actors through contracts,
pricing, or by locking out key components.
In digital ecosystems, however, control works differently. Value is co-
created with partners who provide complementary capabilities. You can't
solve the customer problem alone. You depend on other players - often
independent, sometimes competing - to complete the experience.

Control in an ecosystem, as we noted with Alexa's example, is achieved not
through dominance but by creating dependence. It isn't enforced through
traditional scarcity; it's earned by solving the hardest coordination problem
for other players. When you absorb complexity and make coordination
effortless, you become indispensable to your partners. Owning a demand-
side control point creates some of that dependence as partners need to go
through you to access the customer. However, true control is established
when partners depend on you, not just for customer access but also for
coordination.
Once established, a control point offers leverage, allowing you to mediate
the ecosystem on your terms. It helps you manage competitive tensions
among partners in your ecosystem, helping you guide their behavior or
resolve conflicts, without micromanaging them. It ensures that you stay
indispensable.
Establishing control through coordination
You've probably heard of Alexa before. But you may not have heard of
CCC Intelligent Solutions, a company that most US-based auto insurers and
repair shops depend on. Auto insurance claims are notoriously slow, not
because of complex paperwork, but because no one's really in charge of
coordinating the claims process across a fragmented ecosystem of insurers,
repair shops, parts suppliers, and regulatory constraints.
When a driver starts the claims process after an accident, they first notify
their insurer, explaining when and how the accident occurred, and
describing the damage and loss. This triggers a series of decision points.
Where should the settlement be directed? Should the vehicle be repaired, or
is it a total loss? Are there injuries to address? These decisions about
whether to repair or total a vehicle, where to source parts, and how to route
settlement depend on factors like the queue of pending repairs at a shop or
the stock of available parts, or even labor costs. All of these factors vary
significantly from one repair shop to another.

Insurers must determine the appropriate repair facility and parts supplier,
considering local regulations and rates. Meanwhile, auto repair shops must
select the right parts from suppliers and execute the necessary restoration
work on the vehicle. Prior to CCC, these decisions were made in isolation
by insurers, shops, and suppliers, all working in siloed systems with limited
visibility into each others' information. This fragmentation led to broken
coordination, resulting in lengthy processing times and, in some cases,
inadequate resolutions.
CCC set out to solve this coordination problem across insurers, repair
shops, parts suppliers, and the drivers making claims. However, to persuade
large insurers and repair shops to adopt its coordination rules, it first needed
to establish a control point.
CCC began with addressing the primary concern of the central stakeholder
in the claims ecosystem, the insurer that ultimately approves the claims. It
helped insurers with their most important question: What is the value of the
damaged vehicle? It started estimating this valuation using field
assessments and market research to benchmark vehicle value. As its data
improved, so did trust in the accuracy of its valuation.
CCC then moved to further assist both insurers and repair shops with a
second important decision: How much will the repair cost? Determining
vehicle value was the first crucial decision; estimating repair costs became
the next key step in owning the control point. Using historical data, CCC
can accurately forecast repair costs. Based on this estimate, insurers decide
payment amounts, repair shops order parts, and policyholders accept or
dispute settlements.
CCC increasingly uses AI to accurately predict both the value of the
damaged vehicle and the repair costs involved. But accurate AI estimates
only matter if insurers and repair shops act upon them. In order to achieve
this, CCC's AI estimates work within insurer-specified rules on one side,
while CCC works with its repair shop network on the other side to generate
damage estimates that reflect actual repair needs. By aligning the interests
of both sides of the transaction, CCC meets the requirements of both
insurers and repair shops, ensuring further action.

Supporting individual decisions is important, but to truly solve the
coordination problem, CCC needed something more. It needed to create an
accurate digital representation of the damaged vehicle, ensuring that all
stakeholders constantly work off the same information and coordinate their
activities around it. This is a dynamic data model that constantly updates all
relevant details of the accident, the extent of damage, and the repair
requirements. This vehicle damage model serves as the shared source of
truth that every actor in the claims process can align around and act upon.
The digital representation, sometimes also referred to as a digital twin, is a
key requirement for solving coordination problems in any ecosystem.
Aligning all stakeholders on a shared source of truth solves the
fragmentation across the actors that would traditionally impeded
coordination. Performance is no longer driven solely by how quickly a
repair shop orders parts or how promptly an insurer responds to a claim, but
by the quality of coordination between them. A repair shop doesn't need to
second-guess the insurer's guidance. A parts supplier can fulfill orders with
confidence that the estimate reflects real needs. An insurer can settle claims
faster as a result.
CCC subsequently onboarded repair shops onto a shop management system
that helps them manage new repair jobs as well as order relevant parts.
Parts suppliers were integrated into the procurement workflows of repair
shops. CCC specified how all parties would interact and what data they
needed to share.
In the U.S. auto insurance ecosystem, CCC sits at the center of the claims
process and coordinates an ecosystem spanning more than 30,000
stakeholders across insurers, repair shops, auto companies, parts suppliers,
and financial institutions. CCC's control points are not based on customer
lock-in; they are based on setting up the most reliable coordination anchor
for partners. Demand-side control points, as explored in the previous
chapter, are earned by helping customers make their most important
decisions along the customer journey. Supply-side control points, as in
CCC's case, are established by helping ecosystem partners make the critical
decisions that allow them to coordinate effectively and deliver on the
customer's needs.

Fig. 11.1: Coordinating fragmented actors and activities across an
ecosystem
CCC's control points span three interconnected layers, which together
determine the performance or reliability of the entire system. The first is
unified representation, achieved by creating a shared digital representation
of the damaged vehicle, giving everyone a common view that they can
coordinate around. Second, it enables unified decision by using the details
on the damaged vehicle to help insurers and repair shops align on a key
decision: what the repair should cost. This earns CCC the right to
coordinate downstream actions like repair approvals and parts procurement.
Third, it enables unified execution by integrating workflows across shops
and parts suppliers to act on that decision reliably. CCC predicts vehicle
damage and repair cost, but more importantly, it makes those predictions
actionable by aligning them with insurer rules and repair workflows. These
three control points - unified representation, decision, and execution -
ensure that everyone works off the same source of truth and that their
decisions and actions do not conflict.
Coordination without consensus
Advancements in generative AI have further strengthened CCC's ability to
generate accurate repair estimates by extracting structured information from
vehicle photos to help inform the extent of damage involved. At first
glance, this might look like a strong example of AI-driven coordination in a
fragmented ecosystem. However, in reality, CCC is utilizing AI to optimize
an existing coordination mechanism that it had already established. The true

potential of AI, however, lies not just in improving coordination where it
already exists but in enabling coordination where it was previously
impossible.
CCC's coordination model is built on consensus, where all participants
agree to use the same standardized language to describe vehicle damage.
Before any decision can be made, each dent and scratch on the vehicle is
first tagged using CCC's predefined codes. This creates a unified
representation, a common way to describe damage that everyone in the
ecosystem can understand and act on. Once this shared vocabulary is in
place, decisions like estimating repair costs or approving claims can be
made quickly and reliably. Repair shops use CCC's shop management
system, insurers process claims based on CCC-standard codes, and parts
suppliers and rental agencies align their operations to match. Because
everyone structures their operations around CCC's shared vocabulary, the
entire process runs smoothly. CCC earns this consensus by offering clarity:
it reduces ambiguity in a system where misinterpretation can be slow and
often expensive.
CCC's power ultimately is based on explicit agreements and voluntary
compliance with its standards - hallmarks of consensus-based coordination.
CCC has much in common with other examples of coordination we've
noted through this book, ranging from container shipping to Walmart and
beyond. In all these instances, coordination is achieved through consensus.
Participants agree (or are forced to agree) on standard data formats and
interfaces before they can see the benefits of coordination. The success of
this approach depends on the ability to define and enforce shared rules.
However, as noted earlier in this book, AI opens the door to a different
model: coordination without consensus. It allows independent participants
to act in concert, even without agreeing in advance on a common structure
or set of standards.
Where CCC relies on structured inputs and upfront agreements, AI-driven
claims management solutions like Tractable take a radically different
approach. Tractable, a UK-based competitor of CCC, targets the same
control point of repair estimates but does so without requiring structured
inputs or adherence to standardized codes. Instead, Tractable uses AI

trained on millions of historical claims to analyze unstructured smartphone
photos and generate repair estimates with near-human-level accuracy.
Tractable's AI identifies damage patterns, affected components, and
associated labor and parts costs directly from raw visual data without
requiring predefined codes or taxonomies. The output it generates plays the
same coordinating role as CCC's estimates, aligning insurers with repair
shops, but without requiring the same level of consensus or upfront
agreement. This enables a form of unified representation without consensus.
Instead of asking every participant to label damage using the same
predefined codes, Tractable's AI analyzes photos of the damaged car, in
much the same way a human adjuster would and automatically figures out
what parts were hit, how badly they were damaged, and what repairs are
needed. It extracts structured information and creates a unified
representation of the damage, which further drives unified decision-making.
It then proposes repair strategies and cost estimates based on patterns
learned from millions of past claims. These decisions are not hardcoded as
in the case of CCC; they're learned from data, allowing the platform to
adapt across insurers, geographies, and repair networks without requiring
new integrations or rulebooks.
Fig. 11.2: Tractable's coordination without consensus vs. CCC's
consensus-based coordination

Finally, this drives unified execution. Repair shops can upload photos using
their existing documentation practices. Insurers can process claims without
needing to interpret codes manually or retrain staff. Each party continues to
use its individual tools while participating in a coordinated process. Where
CCC requires participants to align on a common process and language
before an estimate can be generated, Tractable produces the estimate
without requiring prior consensus on data formats or standards. This
approach doesn't eliminate the role of standards - it makes them implicit
rather than explicit. Tractable's AI learns from millions of past repair
decisions, absorbing the collective judgment of adjusters, mechanics, and
market behavior. These learned patterns effectively become implicit
standards, without requiring anyone to formally agree to them.
In short, CCC coordinates through standardization, such that everyone
speaks the same language because they agreed to use the same codes.
Tractable coordinates through interpretation, where every actor still speaks
their own language, but AI translates across them. One model enforces
structure to create order; the other learns structure from disorder. Both
enable unified execution, but they differ significantly in how that
coordination is achieved.

Table 11.1: Coordination with consensus vs. coordination without
consensus

This shift from coordination with consensus to coordination without
consensus enables the coordination of systems that have thus far remained
uncoordinated, simply because such consensus wasn't practical.
AI-driven rebundling enables coordination
without consensus
Tractable illustrates the opportunity for coordination in fragmented business
ecosystems where establishing consensus can be very difficult. Instead of
requiring consensus, Tractable embraces the ecosystem's fragmentation and
reorganizes it using AI-driven rebundling of work across multiple actors.
AI-driven rebundling is the process by which AI unifies fragmented
information, decisions, and execution across tools, teams, and workflows,
without requiring shared standards or centralized control. It transforms
scattered data into a unified representation, guides decisions across
disconnected actors, and coordinates actions across incompatible systems.
This allows ecosystems to function as if they were integrated, even when
they're not.
AI-driven rebundling involves three key elements. The first is the ability to
create a unified representation by extracting structure from fragmented
sources. The second is to achieve unified decision-making by utilizing this
shared representation. Finally, AI enables unified execution, often using
agents to act on that representation autonomously, coordinating actions
across teams and tools constantly.
With this, AI offers an opportunity for coordination in fragmented business
ecosystems, where establishing consensus can be particularly challenging.
The architecture and construction industry is one such example.
Construction projects are typically highly fragmented as they involve
multiple highly specialized professionals - architects, engineers, and
contractors - each working with specialized tools specific to their
discipline. Architects care about spatial relationships and aesthetics.
Structural engineers focus on safety factors. Contractors prioritize project

management. Each discipline has a tool that is dedicated to delivering
performance for that discipline, but not always designed to deliver superior
outcomes across the overall construction project.
Coordination is desperately needed. Poor design choices discovered during
construction can result in significant costs. Construction projects often
deviate from their original specifications, and poor coordination between
teams frequently leads to rework and performance issues in buildings.
Efforts to get these diverse stakeholders to abandon their specialized tools
and adopt a unified platform have repeatedly failed.
Fig. 11.3: From fragmented execution to ecosystem-wide coordination
AI offers a powerful solution to this problem: the ability to achieve
coordination without consensus. Instead of requiring every team to adopt
the same tools, formats, or standards, AI works with the reality of
fragmentation. It pulls information from the tools that teams already use.
The architect and structural engineer continue to work in their respective

specialized tools. The construction project manager still maintains a
schedule in Excel, while project approvals are scattered across long email
threads and annotated PDFs. Each of these tools captures a different slice of
the project in its own format, for its own purpose. AI extracts design
requirements and project dependencies from all these fragmented sources
and rebundles them into a unified representation of the entire project that
integrates spatial, structural, and operational logic of the project across
stakeholders.
This unified representation gives project managers oversight of a
fragmented construction process, even as each team continues using its own
specialized tools. It enables unified decision-making without the need for
constant meetings and approvals, as all teams operate from a shared, central
view of the project. Previously, decisions were made in silos, often based on
conflicting assumptions. With a common representation, AI-guided
decisions can now resolve trade-offs across disciplines.
This transforms the nature of coordination between fragmented actors as AI
acts as a hidden glue, linking their decisions and actions together. Execution
is synchronized, not because everyone agreed on common standards, but
because AI connects the dots across the teams' fragmented efforts. If the
architect moves a stairwell, the AI solution can automatically identify how
that change impacts the structural beam layout and notify the structural
engineer accordingly. If the project inspector rejects a portion of the work
due to non-compliance, AI can instantly inform the relevant design team
and suggest corrective actions. Or consider a scenario where the faÃ§ade
design is altered for aesthetic reasons. In that case, the AI solution can alert
the energy consultant to insulation performance risks and the structural
engineer to structural concerns regarding the cladding system. No one needs
to adopt a new tool or agree on a shared format in advance. AI acts as the
bridge, translating across teams and their tools to keep everyone aligned
around the same evolving project reality. Rather than enforcing top-down
compliance, AI enables bottom-up coordination. It respects the autonomy of
each team while still ensuring everyone sees and acts on the same shared
truth.

Unlike in the CCC example, where all players had to adopt the same
system, teams here retain full autonomy. Architects, engineers, and
contractors continue to use their preferred tools, but thanks to AI, their work
is constantly coordinated,, even in a fragmented environment.
Coordination doesn't start with consensus but emerges through AI's ability
to rebundle fragmented information across the various actors and processes
involved. AI-driven rebundling turns fragmented ecosystems into
functionally integrated systems, by learning from the mess, extracting
structure from it, and using that structure to coordinate behavior across the
ecosystem. AI transforms coordination from a governance problem into a
learning problem and, in this manner, helps secure a new form of ecosystem
control.
Rebundling fragmented workflows through
agentic execution
Construction provides a vivid metaphor for what happens when fragmented
teams, using disconnected tools and workflows, try to collaborate on a
complex project. Architects work with one tool, engineers with another, and
contractors with a third. Not only are these tools different, they're also in
conflict with each other, with little incentive to cooperate. Design tools try
to push downstream into construction, while construction tools try to move
upstream into design. The result is overlapping functionality, turf wars over
who owns the user and the data, and ultimately, broken workflows and
disjointed execution.
It's easy to assume this is a problem unique to the construction industry. But
in reality, this is the norm across all modern work. Most complex projects
rely on cross-functional teams using siloed tools, and most tool providers
have little incentive to cooperate or share data to facilitate easier
coordination.
The core challenge is the same everywhere: how do you achieve reliable
outcomes when there's no shared system, no agreed-upon standards, and no

single player with complete visibility or control?
This is where AI's real potential comes in as a coordination engine. By
creating a unified representation across fragmented systems, AI can enable
aligned decisions and synchronized execution across disconnected actors
and workflows. Ironically, this is the opposite of how AI is often framed -
as a better way to perform individual tasks. Instead, AI's true impact on
modern work is realized through its ability to reconnect the work that has
been pulled apart.
AI's ability to rebundle fragmented data into a unified representation isn't
limited to construction. It applies just as powerfully to enterprise sales and
customer relationship management (CRM). In most companies, customer
information is scattered across various tools, including CRM tools, email
threads, spreadsheets, call logs, support tickets, and marketing platforms.
Each team works with its own specialized tool and sees only a slice of the
customer, but no one sees the whole journey. No single tool controls it, and
no one person truly owns it. This is where AI steps in, connecting the dots
across disconnected systems to create a unified customer view.
Rox is one such AI tool. It pulls in data from across departments, such as
what a customer recently bought or how engaged they are to build a unified
representation of the customer's journey. It then delivers those insights to
the right team at the right time, allowing them to take action quickly and
confidently. With Rox, sales teams no longer need to dig through
spreadsheets or scroll through old emails to determine their next steps.
Rox's AI brings everything together, highlighting which deals are heating
up and which ones are going cold. Outreach is accordingly automated in
response, and workflows are reorganized based on the data. Tasks that used
to take hours of manual effort now happen in the background.
AI enables rebundling of work across a fragmented landscape at three levels - by
creating a unified representation across fragmented information, enabling unified
decision-making across teams, and enabling unified execution across disconnected
workflows.

Rox addresses data and workflow fragmentation in enterprise sales. First, it
solves the data fragmentation problem by consolidating customer
information from across the company, ensuring that every decision reflects
the complete picture of a customer's journey. More importantly, AI also
helps solve the workflow fragmentation problem through agentic execution,
which involves goal-driven AI agents that continuously monitor behavior,
detect intent, and act without waiting for human triggers. Rox's AI agents
constantly scan for engagement signals. Who's showing buying intent?
Who's losing interest? Which competitors are swooping in? These goal-
driven agents then automate workflows by activating personalized follow-
ups and perfectly timed sales emails without getting slowed down by
manual execution. Such tools also detect early signals of customers
churning away and identify new upsell opportunities before customers even
ask.
Fig. 11.4: From fragmented sales execution to organization-wide
coordination

AI, in this manner, creates new control points by its ability to not just
inform decisions but to govern workflows. Rox is a lot more than a better
dashboard - it works like a smart sales assistant to the salesperson. As a
smart teammate, Rox helps run the workflow and keeps getting smarter,
learning from a growing base of customer interactions and salesperson
decisions. The more a company uses Rox, the more data it feeds in and the
more Rox learns. This makes it harder for competitors to catch up.
This is the ultimate promise of AI-driven rebundling. Instead of just linking
tools together, AI makes sense of all the insights it gathers across emails,
sales calls, contracts, and financial data, and weaves them into a coherent
narrative. It connects the dots but also figures out what the picture is
supposed to be and fills in the missing details.
Agentic execution reinforces coordination without consensus. Once AI has
rebundled fragmented information into a shared representation, agents can
act on that representation autonomously, triggering follow-ups, updating
tasks, or escalating risks, without waiting for human execution. In this
manner, unified representation enables unified decision and execution,
which in turn enables coordination. Coordination, in turn, gives rise to
control. The more teams depend on the AI layer to see, decide, and act, the
more gravity that layer holds in the ecosystem.
Agentic execution creates a powerful new control point. In fragmented
environments where no single actor has complete visibility or authority,
agentic execution makes true coordination without consensus finally
possible.
AI-driven rebundling in knowledge work
Some of the fastest sprinters in the world often struggle in the 4x100m
relay. The issue isn't individual performance - these athletes are the fastest
in the world. The issue is workflow constraints. They are just not good at
passing the baton and lose vital micro-seconds in those 3 transitions. To win

the 4x100m relay, being fast at sprinting is necessary but not sufficient. You
also need to manage the key constraint - the time taken to move the baton.
This is the key to AI-driven rebundling. The biggest constraint in
knowledge work isn't the speed of individual tools; it's the way work gets
organized and executed across them. Faster tools won't help if the way work
moves across tools breaks down. What matters is how this constraint is
managed.
Henry Ford didn't invent the automobile, but he did invent or advocate an
entirely new way of manufacturing vehicles at scale, the moving assembly
line. At the time, automobile production was slow and expensive. Skilled
workers would walk around stationary vehicles, assembling each car piece
by piece. Ford realized he needed to manage these constraints in
production.
Ford had an insight - what if, instead of workers moving to the work, the
work moved to the workers? Slaughterhouses had long utilized conveyor
belts to move carcasses through various stages of processing. Ford's team
implemented a similar moving assembly line where the car was pulled
down a track, step by step, with each worker adding a single component
before it moved on to the next station. Twelve hours of work could now be
accomplished in just ninety minutes. Ford's innovation didn't change the
product or the tools required to produce it. It changed the one thing that
mattered most, the workflow.
AI-driven rebundling has a similar effect on knowledge work in enterprises.
Since the rise of modern computing, knowledge work within organizations
has been structured around software tools, each designed for a specific task.
Employees switch between tools to complete workflows, much like early
factory workers who walked from station to station instead of having the
work come to them. As more specialized tools emerged and were adopted,
workflows became increasingly fragmented.
AI-driven rebundling offers a solution that traditional integration efforts do
not. Instead of requiring workers to navigate between tools, AI moves the
work closer to them. Traditional software required employees to manually
stitch workflows together, pushing tasks from one tool to another. APIs

allowed basic integration of tools, but they lacked the intelligence to move
work forward across them. AI agents fill this coordination gap. They act on
behalf of the user, sequencing, delegating, and executing tasks across tools,
without needing human intervention. Instead of tools waiting for people to
drive them, AI now drives the tools. AI agents pull in relevant data and
execute tasks so that continuity is maintained across fragmented workflows.
What Ford's moving assembly line did for car production, AI-powered
systems are now doing for knowledge workflows, coordinating activity
around the user rather than forcing the user to coordinate activity.
AI might create smarter tools, but its real value lies in the ability to
reimagine workflows entirely. Rox, the example we examined earlier,
illustrates how this works in practice. Initially, Rox speeds up customer
research and makes customer outreach more targeted. However, as it
becomes more widely used, it becomes central to how the business
operates. Instead of sales reps logging notes or digging through dashboards,
they can just upload emails, calls, and Slack messages, and Rox extracts
key insights automatically.
Rather than clicking through endless reports, teams can ask simple
questions, such as 'Which deals are at risk?' and receive actionable
answers. The workflow starts to rebundle around the salesperson's actual
decisions, not around the software's limitations. As Rox sees more data, it
becomes smarter, learning how the business operates and refining its
recommendations over time. The more AI learns about how the company
operates, the less manual oversight is needed. This means AI dynamically
adjusts sales playbooks based on market conditions and personalizes
outbound messaging in response. It continuously learns from closed deals to
improve the forecasting and execution of future ones.
Rox's AI-driven rebundling spans multiple functions, including marketing,
sales, finance, and HR. This delivers economies of scale, as coordinated
workflows lead to higher productivity, attracting more users, which in turn
generates more data to improve the workflow further. But AI's unseen
advantage lies in economies of scope. Every new function it incorporates,
whether sales forecasting, customer support automation, or employee
onboarding, makes the software stickier, more essential, and much harder to

replace. The more workflows it bundles together, the stronger the
gravitational pull to attract other workflows. This is where AI is uniquely
powerful, both in the enterprise and in fragmented industries like
construction.
Ramp, the corporate card company we examined earlier in the book,
illustrates this well. At first glance, Ramp appears to be a sleek, modern
alternative to the traditional American Express corporate card. However, for
employees and finance teams alike, Ramp is more than just a card.
Say you're a team lead ordering software for your department. You swipe
the Ramp card, expecting a routine charge, but behind the scenes, AI is
already checking whether someone else in the company has purchased the
same tool recently. If it detects a duplicate subscription, it alerts you before
the purchase is completed. Or if the software exceeds your team's monthly
budget, it alerts you right away rather than letting you overspend and clean
up the mess later. Meanwhile, a vendor you work with sends a new
contract. Ramp recognizes the vendor, analyzes your payment history with
them, and might automatically suggest that you negotiate a longer-term
discount based on volume.
When a company uses Ramp, it gains visibility into how money is being
used across every team, vendor, and employee. And with that visibility,
Ramp starts actively influencing how that money gets spent. AI sits at the
heart of this system, automating tasks that finance teams previously
performed manually. With this, Ramp establishes a control point across
financial workflows, guiding unified financial decision-making across the
enterprise. Before Ramp, a company might have used separate tools for
corporate cards, bill payments, expense tracking, procurement, and
budgeting. Each came with its individual login, manual reconciliation, and
endless paper trails.

Fig. 11.5: From reactive finance plagued by fragmentation to proactive
finance built off coordination
With Ramp owning the core workflow, those functions collapse into a
single, coordinated system. Employees swipe their cards, and AI takes care
of the rest, enforcing policies to determine whether a purchase is approved
and categorizing transactions autonomously. Finance teams get to focus on
strategy instead of chasing employees for receipts. Across all financial
workflows in the enterprise, Ramp becomes the layer where decisions get
made. In doing so, it replaces tools that did little more than log transactions
in individual silos while requiring users to stitch a consolidated picture
across them. With AI, you go beyond linking underlying tools to replacing
their need altogether.
AI-driven rebundling follows a clear playbook. First, create a unified
representation across fragmented systems, then enable unified decisions
across fragmented actors. With that, enable unified execution across
fragmented workflows. From there, expand outward to increasingly expand
across more workflows.

AI and the unfair advantage in kickstarting
ecosystem coordination
Most ecosystems face a frustrating paradox: everyone wants the benefits of
coordination, but no one wants to be the first to initiate it. This is the cold
start problem. In fragmented industries, where dozens or even hundreds of
players must collaborate, coordination often stalls before it even begins.
Each participant is waiting to see value before committing to new
standards. However, that value only becomes apparent after enough people
commit. It's a vicious cycle: no adoption means no value, and no value
means no adoption.
Why is consensus so hard to get to? This happens because agreeing to
common rules means giving something up. When you adopt shared
standards, you sacrifice the freedom to work in your own way, on your own
terms. And unless the upside is obvious and immediate, most players won't
make that trade.
In some industries, consensus can be enforced. Containers changed global
trade because standard sizes were enforced. Walmart forced suppliers to
adopt barcodes and EDI systems by making compliance a condition of
doing business. However, in most fragmented ecosystems, such a consensus
is not feasible. This is especially true in complex, slow-moving domains
like auto claims or architecture and construction, where large incumbents
have deeply entrenched workflows. For these players, the cost of switching
to new standards is high, and unless there's an obvious, immediate upside,
they won't make the leap.
So far, there's been no easy solution to this cold start problem. However, AI
introduces a new advantage by enabling coordination without consensus.
Instead of waiting for everyone to align, AI can begin coordinating
activities by interpreting existing behaviors and translating between
incompatible systems. In construction, for instance, AI can identify
common design issues across thousands of PDFs without requiring every
architect and contractor to agree on a standard template. That means

platforms can start creating value without waiting for consensus. An AI tool
might alert a team to potential regulatory violations, even if no one has
manually identified those risks. Participants start participating passively
while maintaining their current workflows and see immediate value from
coordination, which creates momentum for deeper engagement. A
contractor can continue using their current site photos or reports, as AI
makes sense of them without requiring new formats. Each interaction trains
the AI, enhances coordination, and improves the platform. This creates a
flywheel where AI-driven coordination attracts more participants, which
generates even more data to train the AI towards improved coordination.
For all its advantages, coordination without consensus has limits.
Participants may be aligned in action, but they aren't contractually bound.
When something goes wrong, it's difficult to assign liability. As an
ecosystem matures, this gap must be addressed through clear accountability.
And that requires consensus, or agreement among participants on who is
responsible for what.
The most successful ecosystems start with AI-driven coordination to unlock
early value, even without formal agreement. However, as the ecosystem
grows and coordination becomes more valuable, the ecosystem leader
gradually introduces formal rules and agreements. Over time, consensus
becomes the foundation for accountability, even if it wasn't needed to get
coordination off the ground.
Smart ecosystems beat smart tools
The technologist's instinct is to use new technology to build smarter tools.
With AI, we have a technology that's improving rapidly, and the natural
move is to apply it to make individual tools faster, more accurate, and more
powerful. However, if our imagination stops at smarter tools, we miss the
larger opportunity of AI in its ability to integrate fragmented systems and
coordinate them without consensus.

The problem with building smarter tools is that most industries and
enterprises are already fragmented. Improving one tool may enhance a
single task or part of the workflow, but it doesn't improve the system as a
whole. The rest of the workflow remains stuck in outdated processes. And
so, the potential of that tool remains stuck as well. The older, slower tools
around it constrain its ability to execute and deliver outcomes.
Without the shipping container as a shared unit that railroads, ports, and
trucking companies could all work with, ports would have modernized.
However, trucks and railroads working independently would still have
slowed freight down, and global supply chains would never have
materialized. Without integration across the supply chain, Walmart would
have benefited from faster checkouts, similar to Kmart, but never
fundamentally changed its power relationship with brands.
Ironically, whenever a new technology is unevenly adopted, whether within
a company or across a partner ecosystem, it can make coordination harder,
not easier. This creates two kinds of problems. First, it limits the gains from
the improved tool because the surrounding processes can't keep up. Second,
it increases friction as newer tools start behaving in ways older ones can't
interpret or respond to. As long as we use AI to build smarter tools in
isolation, we remain trapped in this cycle. The tool's performance, and even
the tool provider's ability to charge for it, isn't determined by what the tool
can do but by what the system around it allows it to do.
This is the problem with building smarter tools without aiming for smarter,
well-coordinated ecosystems. To move forward, we must break from the
illusion of technological solutionism, or the belief that better tools alone
will solve systemic problems. The true opportunity with AI isn't in smarter
tools but in smarter ecosystems, leveraging its ability to coordinate without
consensus.
What AI can do in isolation to improve task performance might appear
dazzling and make for viral headlines, but those gains don't confer
competitive advantage. What really matters is how we redesign the playing
field and redefine the game using the properties of AI as a technology of
coordination. This requires asking the two questions that matter most:

where to play? - or which parts of the system we choose to reshape - and
how to win? - or how we reconfigure the rules, roles, and relationships to
create an enduring advantage. AI offers us the means to rebundle
fragmented workflows and rewire how entire industries operate. However,
until we step back from tool obsession and approach AI as a strategic
technology of coordination, we'll continue to solve local problems while
losing sight of the larger game.
OceanofPDF.com


OceanofPDF.com


OceanofPDF.com

W
12
YOU DON'T NEED AN AI STRATEGY
WHERE TO PLAY, HOW TO WIN
e began this book with two stories from Singapore. The first tells of
the city-state's unexpected second COVID wave, which unfolded
despite near-flawless execution and deployment of advanced technology.
It's a reminder that having the right tools isn't enough if we overlook the
complexity of the systems in which those tools are deployed. The second
story offers a contrast. This time, Singapore looked beyond port automation
and placed a bold bet on a new model of trade. It sensed a shift in the
system before others did, and redefined its role to meet that future.
Together, these stories frame the central argument of this book: real
advantage doesn't come from better tools, but from better systems, and
from the ability to anticipate where the system is heading before everyone
else does.
Yet, shifting our focus from tools and task-level improvements to the
broader system, and how it is being transformed, is far from easy.
Technological solutionism is seductive; it offers quick fixes and makes for
attention-grabbing headlines as companies claim to cut headcount and
deliver process improvements using AI. In fast-moving environments, it
creates the comforting illusion of control and innovation. In contrast,
betting on the new system, as Singapore, Walmart, and others did, requires
something different: the foresight to recognize structural changes, the

discipline to look beyond immediate gains, and the ability to anticipate
second-order effects while others chase first-order wins.
Most organizations today approach AI with a tool-oriented mindset, using it
to enhance productivity within their existing model of work. Their first
instinct is to view AI as a sharper blade that helps them cut through tasks
faster, cheaper, and possibly even better. In this frame, the system of work
remains largely intact. The fundamental mistake most leaders make today is
starting from the inside out when thinking about deploying AI to solve
problems. They begin at the task level and ask: "What are we doing now,
and how can AI automate it?" This seems simple and efficient, but it's
deeply misguided. AI is applied to optimize what exists, rather than to
design what should be.
In the years following the publication of my book Platform Revolution, I
found myself called into boardrooms from Silicon Valley to Seoul, to
answer one single question - "What is our platform strategy?" It was the
mid-2010s. The Big Tech - Apple, Amazon, Google, and Facebook - had
reached staggering valuations, and conventional wisdom suggested that
every company needed to build a platform to keep up. Yet, as every
conversation progressed, it became clear that most of my clients didn't need
to build a platform. What they were grappling with were the two
foundational questions at the heart of all strategy: where to play and how to
win.
Today, most organizations make the same mistake with AI. They ask for an
'AI strategy', very often looking for a plan to unlock AI-powered
productivity gains without revisiting the system in which that productivity
sits. What they really need is not an AI strategy, but clarity on where to play
and how to win in response to the conditions created by AI.
Consider the two stories from Singapore again. The COVID misstep reveals
what happens when we focus solely on tools and execution without
stepping back to ask: Where are the hidden fault lines in the system? What
constraints haven't we accounted for? It's a failure not of technology, but of
misreading the system - the larger playing field. If we don't understand
where we play, we risk losing even if we play well. In contrast, Singapore's

port strategy shows what it means to first choose where to play, by betting
on a changing system of trade, and then decide how to win, by redesigning
that system to its advantage.
AI, like any powerful tool, multiplies force. However, force applied in the
wrong direction only accelerates failure. The real question isn't how to
move faster or build smarter. What matters instead is carefully choosing
where to play when the playing field itself changes.
Misunderstanding strategy
On the face of it, the answers to the questions of where to play and how to
win seem fairly straightforward. You determine where to play by picking
the market or arena in which to compete, defining it in terms of customer
segments, geographies, or product categories. You then decide how to win
by identifying the unique approach or advantage that will allow your firm to
succeed in the chosen arena, typically through superior capabilities, lower
cost, or a differentiated offering.
This approach is closely tied to the classical model of competitive
advantage, which involves competition within a relatively stable industry,
where strategy is primarily an exercise in positioning. It's a model built on
identifying the right market and developing internal capabilities that confer
a distinctive advantage in serving them. Success, in this view, comes from
making deliberate trade-offs, focusing on what you do best, and picking the
right place to do it.
However, in an environment undergoing rapid technological change, the
assumptions of stable industry boundaries and static rules of competition no
longer hold. On one hand, industry boundaries are constantly shifting,
making it easier to borrow capabilities from other sectors. This creates new
opportunities to innovate by combining capabilities from different
industries. Insurers can price health insurance using data from fitness
tracking applications, while fitness tracking applications can cross-sell
therapist sessions and nutritional meal-prep kits; neither adheres to playing

within their traditionally defined industry boundaries. However, when
capabilities cross industry boundaries, competitors do so as well. A startup
from another sector can become your fiercest rival, while yesterday's
competitors may turn into collaborators. Profit pools evaporate quickly, and
new ones appear in unfamiliar places, often captured by others before
you've even noticed the shift. A convergence of forces drives this constant
churn: rapidly evolving technologies, shifting consumer behavior, and
sudden geopolitical or market disruptions. Together, these forces restructure
not just what customers need, but how value is created, delivered, and
competed for, making both where to play and how to win moving targets.
The shifting fortunes of Chegg, an education technology company, offer a
vivid example of how a constantly evolving playing field can turn market
leaders into casualties almost overnight. Chegg began life as a messaging
board, evolved into a textbook rental service, and ultimately found success
providing online homework help in the form of pre-written answers to
frequently asked homework questions. It hired thousands of contractors,
primarily in India, to answer questions posted by students, offering this on-
demand homework help as a subscription-based service. By the traditional
definitions of where to play and how to win, Chegg had constantly
reinvented itself to identify new markets and use cases, while building new
capabilities to serve them adequately. In an uncertain environment,
however, identifying new markets and building capabilities is no longer
enough. Traditional strategy can't keep up when the very nature of the
playing field is in constant flux.
With the onset of COVID-19, the playing field tilted sharply in Chegg's
favor. With schools shut down and remote learning becoming the norm,
demand for online homework help exploded. Chegg's user base and
revenues surged as the company found itself seemingly in the right place at
the right time. However, the ground didn't stay still for long. As the
pandemic's tailwinds faded, another shift hit Chegg, this time much harder.
The launch of ChatGPT and the meteoric rise of generative AI tools gave
students instant, free academic assistance, rendering Chegg's paid model
increasingly obsolete. In less than two years, Chegg's market value
collapsed by more than 99%. Chegg wasn't entirely responsible for its rise,

nor solely to blame for its fall. Chegg's story is less about AI eating its
lunch and more about the nature of today's playing field. When the playing
field keeps shifting, often without warning, the classic questions of strategy
- of where to play and how to win - have no fixed answers. What worked
yesterday won't hold tomorrow, not because the company failed to evolve,
but because the system around it evolved faster.
Such flux can be deeply disorienting. Companies have long viewed strategy
through the classical lens of positional advantage in a stable playing field.
However, when the ground keeps shifting beneath your feet, even the most
finely tuned positioning can feel irrelevant.
Faced with growing instability, many firms swing to the opposite extreme
and fall into three common traps. The first is abandoning the idea of durable
advantage altogether, believing that in a world of constant disruption, the
best they can do is chase short-term wins. In this mode, AI is applied to
obvious use cases for quick efficiency gains or surface-level differentiation.
However, transient wins don't compound, as seen in Chegg's example.
They often evaporate when the playing field shifts again, locking the
company in a cycle of constantly changing the next source of transient
advantage.
A second common trap is the belief that when both "where to play" and
"how to win" are in constant flux, strategy ceases to matter, and the only
viable response is to execute faster and smarter than everyone else. In this
mindset, firms double down on innovation labs, agile methods, and rapid
sprints, assuming speed and responsiveness will keep them ahead. While
these initiatives build executional fitness, they often remain anchored to the
logic of the current system. AI is deployed to optimize today's tasks, not to
reimagine the system those tasks belong to.
Ironically, these companies become faster at solving the wrong problems.
Yahoo's story makes this painfully clear. Once an early internet giant,
Yahoo was also among the first major technology firms to embrace agile
methods at scale. It trained thousands of engineers in Scrum and extended
agile practices beyond software into marketing and strategy. By all

measures, it had built the muscle to move quickly in uncertain
environments.
Speed, however, isn't the same as direction. Yahoo misread the structural
shift unfolding around it. It bet on editorial curation to organize the web,
just as the internet was beginning to grow at a pace that would soon outstrip
the ability of human editors to keep up. At the same time, Google's
algorithmic search and Facebook's social feeds were redefining how people
discovered content. Yahoo didn't fail due to a lack of agility. It failed
because it raced ahead, but in the wrong direction. Building executional
agility is irrelevant if firms misread the playing field.
The instinct to build executional muscle often stems from a traditional view
of strategy that assumes advantage comes from internal capabilities,
deployed within a stable playing field. However, neither is the playing field
static any longer, nor are capabilities durable sources of differentiation. As
AI continues to improve and commoditize formal expertise, the capabilities
that once defined a firm's moat in the knowledge economy are increasingly
available off the shelf. At the same time, the boundaries of markets are
becoming fluid and contested. Executional muscle has its place, but without
a clear view of the playing field, it can lie unused or wasted.
An overemphasis on transient advantage and executional agility may also
lead companies into a third trap: a perpetual cycle of experimentation,
driven by the belief that in a shifting environment, constant testing is the
only way to stay relevant. If positional advantage no longer seems durable,
the impulse is to keep placing new bets and running new experiments
without ever committing to a clear strategic direction.
Each of these three traps is designed to improve the odds of success within
the current system. However, when the system itself changes, these moves
don't help you reposition. Instead, they tether you to the logic of the old
system.
Companies seeking to transform themselves with AI often fall into these
traps, all rooted in a fundamental misframing: they view AI as a toolkit for
faster execution of familiar tasks rather than a catalyst for reimagining the

larger system of work. This task-centric mindset keeps them focused on
better tools rather than a better strategy.
Most AI efforts begin where change feels most tangible: at the level of
individual tasks. Companies automate workflows, test new business
models, and chase incremental gains, hoping that, over time, these scattered
experiments will add up to a coherent strategy. But this logic is backwards.
Optimizing tasks in isolation rarely leads to meaningful transformation.
Starting with execution and assuming that strategy will emerge later is like
assembling puzzle pieces without knowing what picture you're trying to
form.
True strategic advantage in the age of AI doesn't come from doing old
things faster. It comes from seeing how the system itself is changing, and
then deliberately reshaping it to your advantage. Motion is not the same as
direction. Unless you start with the system in mind, even the best tools will
take you nowhere new.
Fig. 12.1: Getting AI-driven business transformation wrong

Asking for an "AI strategy" - a plan to unlock AI-powered productivity
gains - is like requesting a prescription before understanding the diagnosis.
True strategy does not begin by asking how to improve current tasks with
the most advanced technology at your disposal - it begins by revisiting
those two timeless strategic questions: where to play and how to win.
When the playing field is in constant flux, choosing where to play means
betting not just on new playing positions, but on a new structure of the
playing field - a new system. Determining how to win isn't straightforward
either when the rules of the game keep changing. How to win is less about
internal excellence in capabilities and more about establishing control
points in the external playing field.
The key to strategy in times of uncertainty is to zoom out, evaluate the entire system of
work, then work your way back in towards the centre.
Don't start by asking what AI can automate. Start by asking whether the
competitive landscape itself has changed. Has the basis of value creation
moved? Does your business model still make sense? From there, work
inward: What new capabilities does this new game require? What roles and
workflows still matter in the new system, and which ones have lost their
edge? Only once that new system is clear should you turn to AI, no longer
as a tool to improve the old game, but as a way to win the new one.

Fig. 12.2: Getting AI-driven business transformation right
Coordination determines where to play
How do you answer the questions of where to play and how to win when
the playing field itself is shifting, and the rules of the game along with it?
The answer lies in understanding that technological shifts - whether the
container, the barcode, or AI - don't just hand you better tools, they also
change two foundational elements that determine competitive advantage:
coordination and control.
Coordination changes where you play. It is the central mechanism that
shapes the structure and boundaries of economic activity. New technologies
enable new forms of coordination and unlock entirely new ways for players
to work together.
Consider the story of containerization that we started this book with. Before
containerization, international trade was fragmented and local. Each port
had its own loading practices. Cargo was packed and unpacked manually.

There was minimal coordination between ships, ports, trucks, and trains.
Moving goods across regions was so expensive that most firms didn't even
try. You only played where you had deep roots and local relationships.
The standardized shipping container changed the playing field. It
transformed trade by enabling intermodal transportation. With that, ships,
trucks, and railroads were no longer operating in fragmented silos; they
were stitched together into intermodal trade routes thanks to the
standardization enforced by the container. The playing field expanded from
regional networks to global supply chains.
This newfound coordination changed the playing field as the global
economy reorganized itself around the usage of the container. First, this
shift changed who could participate, allowing even small firms to tap into
international markets. Far more importantly, it dramatically expanded the
scope of economic activity in the playing field. With coordination costs
significantly reduced, global production became modular. Manufacturing no
longer had to happen in one place; it could be unbundled, with different
firms specializing in individual components that could be reliably shipped
globally. Supply chains grew longer, not because of new demand, but
because coordination made them manageable. New strategic positions
become viable that didn't exist before. Players that once competed in
national markets found themselves part of sprawling global ecosystems. In
this new playing field, entire countries rose and fell - their fortunes
determined by the new geography traced by the course of the container.
Today, the race to deploy AI capabilities is often a race to optimize the
familiar, even as the terrain underneath is being restructured. Instead of
asking How can we use AI to improve the tasks we already perform?,
companies should ask: What system is emerging, and what role can we play
at its center? When a new technology of coordination, like AI, takes hold, it
redraws the map of viable business models. It reconfigures which parts of
the value chain remain attractive and which become commoditized. When
companies misread where to play, anchoring themselves in a system that's
fading, they inevitably misread how to win within it. Entire categories of
firms may find themselves obsolete, not because they failed to innovate, but
because the game they optimized for no longer exists.

This is why firms must stop looking inward, focusing narrowly on what AI
can automate within their existing processes, and start looking outward,
toward how the broader system is evolving. Without a clear view of this
shifting landscape, of what AI makes newly valuable or newly replaceable,
it's easy to misread the game that is being played. When that happens, even
the best-executed AI strategy will be directionless at best, and dangerously
misaligned at worst.
AI also redefines how to win. It introduces new ways to create value
internally and new forms of power externally. In effect, it changes both the
playing field and the rules of the game, just as the container once did.
Singapore emerged as one of the key winners in the new playing field
shaped by the container. Yet for those unfamiliar with the broader
transformation the container unleashed, Singapore's rise is often reduced to
a story of location. It sits astride one of the world's busiest shipping lanes,
and this geographical positioning is frequently cited as the reason for its
success.
However, that narrative misreads both the playing field and Singapore's
advantage within it. According to this view, Singapore's where to play was
the Strait of Malacca, and its how to win was building the best port on the
map. That interpretation, however, is rooted in the old playing field.
Singapore's real where to play was the emerging landscape of reliable,
cross-border trade made possible by containerization. Containerization had
solved the coordination challenges of a previously fragmented industry, and
Singapore was positioning itself at the forefront of this transformation.
Control determines how to win
Attributing Singapore's success primarily to its geographic location reflects
an older way of thinking about competitive advantage, rooted in the
industrial economy. In that world, advantage came from controlling scarce
physical resources, such as oil fields, mineral deposits, manufacturing
capacity, or access to key trade routes. Scarcity defined value, and owning
what others couldn't easily access or replicate became the basis for

winning. That same logic was carried into the knowledge economy. Here,
scarcity took the form of specialized expertise; skills that were hard to
acquire, expensive to scale, and difficult to replicate.
These factors still matter, but they no longer fully explain how you win.
Technology, especially AI, tends to commoditize what was once scarce.
Previously defensible expertise can now be reproduced at scale, at near-zero
marginal cost. As AI makes specialized knowledge widely accessible, the
traditional scarcity-based explanation of advantage starts to break down.
Companies built on differentiated knowledge work now face a fundamental
challenge. As AI erodes the value of their core expertise, where do they find
new positions of strength? The instinctive response is twofold: adopt the
latest tools to stay ahead, or retreat to activities that AI hasn't yet
commoditized. However, both are reactive strategies that trap firms in a
losing game, forcing them to react to the shifting boundaries of what
machines can and cannot do. As more companies pursue the same tools and
the same ever-shrinking pockets of tasks that AI hasn't yet commoditized,
the returns diminish and competition intensifies. Hence, relying on the
scarcity lens to think through how to win doesn't help.
Singapore's rise is similarly explained as a classic case of exploiting
geographic scarcity. However, scarcity alone doesn't guarantee success.
What made Singapore different was that it didn't stop at leveraging its
obvious advantage. Instead, it looked ahead to the constraints that would
need to be resolved in the new system of trade.
When a new system takes shape, it creates new opportunities, but also
creates new constraints. It brings fresh challenges in managing
interdependencies and resolving friction between actors. The key to
answering the question of how to win is identifying these emerging
constraints and building the capacity to resolve them better than anyone
else. When others rely on you to make the system function smoothly, your
position becomes indispensable. Winning, in this context, doesn't come
from owning what's scarce, but from coordinating what's stuck.
Singapore anticipated the coordination gaps that would emerge in the new
system of trade. Reliable cross-border trade didn't stop at shipping; it

required coordination across the fragmented logistics of air, sea, road, and
rail. Rather than treating its port as a standalone entity, Singapore
reimagined it as part of a tightly integrated logistics hub with
interconnected air freight, road, and warehousing, thereby establishing a
control point in intermodal transportation. It invested in synchronized
scheduling across all modes of transport, along with integrated customs and
clearance processes, positioning itself as the linchpin of intermodal trade in
the region.
Addressing coordination gaps wasn't enough, though. To succeed in the
new landscape of reliable cross-border trade, Singapore also had to confront
and resolve a second-order constraint: risk. At the peak of global trade
expansion, companies were concerned about corruption, delays, regulatory
uncertainty, and a weak rule of law. Singapore's location in a region fraught
with geopolitical uncertainty was actually a liability and a disadvantage,
something that is often overlooked in retrospective accounts of its success.
Left unaddressed, this risk could have erased any advantage conferred by its
locational scarcity.
Singapore's most important move was to establish predictable governance
by investing in institutions that strengthened trust. Transparent customs,
strict anti-corruption measures, rule-based dispute resolution, and pro-
business regulatory clarity made Singapore the trust layer for trade in the
region.

Fig. 12.3: Establishing control by resolving constraints in the system of
trade
Singapore's control point was not just based on its initial locational
advantage but on its ability to combine that with investments in intermodal
transport coordination and trade risk management. It won, not by leaning on
the initial advantage it had, but by proactively solving what others in the
system struggled with. In a new system, sustainable advantage comes not
just from exploiting yesterday's scarcities, but from addressing today's
constraints. This combination of leveraging scarcity, orchestrating
coordination, and managing risk created a control point that extended well
beyond geography, enabling Singapore to shape the evolving global trade
system to its advantage.
Had Singapore relied exclusively on the two factors that are most often
used to explain its success - its locational scarcity and its early adoption of

new technology - it would have automated its ports for shipping containers,
demonstrated superior turnaround times, and congratulated itself on the
productivity gains achieved. It would, however, have lost out on the larger
opportunity that would be created as the overall system of trade changed in
response to the arrival of the container.
Ironically, that's precisely what today's AI implementations risk repeating.
They focus on the task, looking to speed up some tasks, automate others,
and reduce friction across the board. While those gains may feel like
progress, they blind us to the larger transformation underway. If your
strategy begins and ends with efficiency, you don't get a shot at winning in
the new playing field. To play the winning game, you must first step outside
the task, observe the new system forming, and then determine how you
manage the constraints within the new system to establish a central control
point.
In this sense, companies don't need an AI strategy. They need a strategy for
the conditions that AI creates.
As we noted earlier in the book, TikTok's entry into social networking
blindsided incumbents like Facebook and Instagram, not because it used AI
more efficiently, but because it utilized AI in a different way. It won by
using AI to address a key constraint in the old model of social networking:
the cold start problem.
Legacy social networks were built on the social graph - who you connect
with determines what you see. This created friction: unless your friends
joined and posted content, your feed was empty. TikTok saw that constraint
and designed around it. It used AI to build a behavior graph - what you
engage with determines what you see, regardless of your connections.
Facebook needed your friends to join before your feed came alive. TikTok
needed only your first few swipes.
TikTok, like Singapore, recognized that real power lies in solving the
constraints the system hasn't yet resolved. It changed where to play by
shifting the foundation of social networking from relationships to
algorithmic discovery. And it changed how to win by rendering the social
graph, once a powerful moat, irrelevant. The size of the network didn't

matter. The ability to correctly predict engagement, even when the network
had a small number of users, was what made the difference.
TikTok flipped the logic of competition by identifying where the system
was breaking and repositioning itself as the answer, leveraging the
capabilities offered by AI. In doing so, it became indispensable to the
restructured system. This is the most powerful opportunity that AI offers
companies today - to change the rules of the game, and even tilt the playing
field in your favor.
Not every company will recognize this opportunity, though. AI gives every
company the same toolset, but the difference lies in what you choose to
build with it: an efficiency play, a better game, or an entirely new playing
field.
Tilting the playing field
Wayne Gretzky's quote has become the boardroom's favorite proverb for
dealing with uncertainty. "I skate to where the puck is going, not where it
has been," he said, a line that now appears more often in corporate strategy
decks than in hockey arenas. It's a compelling metaphor. It suggests that
success depends on anticipating change and positioning yourself ahead of it.
Gretzky, considered one of the greatest ice hockey players in history, wasn't
the fastest skater or the most physically imposing. What set him apart was
his ability to read the entire system of play - the relationships between
players, the momentum of the game, the likely chain of events - and to act
before others even saw the opening. He positioned himself not where the
puck was, but where it would be.
Gretzky didn't change the rules of the game or the dimensions of the rink,
but read the current game more intelligently than his peers. That's one way
to beat the competition during periods of rapid change. The frequency with
which Gretzky's quote shows up in boardroom presentations, though, may
make you believe that's the only way.

When companies are confronted with a volatile competitive landscape as
they are today in the age of AI, there is a tendency to frame winners and
losers in terms of those who skate to where the puck is going and those who
skate to where the puck has been. This makes a distinction between those
who react and those who anticipate. In this framing, the average player is
slow and reactive, while the Gretzky-like player reads the shifts and moves
early. However, both of these responses, reactive and proactive, assume that
the logic of the game remains the same. The assumptions about what game
is being played and what it takes to win remain intact.
What we often overlook is that what matters more than how we anticipate
today's game is how we shape the game for other players going forward. In
a rapidly changing environment, success depends on mastering shifts to the
playing field rather than simply adapting to existing structures. Incumbents
who focus too much on anticipating the next move in today's game risk
being blindsided by newcomers who change the rules of the game.
Despite Gretzky's celebrated quote, we can find better clues for
transformation in how Steph Curry, an American professional basketball
player for the Golden State Warriors, transformed the way modern
basketball is played. Historically, the three-point shot in basketball was
considered a high-risk option and used only sparingly. Curry, through
extraordinary accuracy and rapid-release shooting, made it the central
strategy. This forced defense positions in opposing teams to adapt in
response and opened up new passing lanes on the playing field. As we
noted in Chapter 2, this changed the entire logic of the game as traditional
playing positions ceased to matter in the new system of play. Curry changed
the way the game was played, ultimately influencing team structures,
recruitment, and youth training in basketball.
When the playing field constantly shifts, the more important distinction is
not just who moves first, but whether they move with the same logic or use
the shift in the new system to change the logic of the game. The real
opportunity lies not in anticipating change better than others, but in
structuring new organizational systems to exploit that change.

The most powerful position, however, goes not to those who merely change
the logic of the game, but to those who force a shift in the structure of the
playing field itself. Changing the logic of the game can enable you to
design the game around your strengths, but shaping the playing field can
give you the dominance to control the rules by which everyone else plays.
In the late 1990s and early 2000s, Tiger Woods' dominance in golf changed
the game to an extent that it literally shifted the structure of the playing
field itself. When Tiger started winning majors by margins that made
everyone else look like amateurs, tournament organizers did something
unprecedented: they redesigned golf courses. Fairways were narrowed and
holes were lengthened. So complete was his dominance that Tiger-proofing
of golf courses - the changes golf courses made to contain Tiger Woods'
dominance - transformed both the playing field and the rules of the game.
Tiger had reshaped the physics of the course. He wasn't skating to the puck.
He was dragging the entire rink behind him.
Fig. 12.4: Strategic postures to flux in the playing field

When looking to transform using AI, companies today adopt one of four
postures, each of which can be briefly illustrated by how players in the
agricultural sector have leveraged AI to transform farm yield and improve
agricultural output. Agricultural output or farm yield can be dramatically
improved by enabling better decisions about how and when to use key farm
inputs, such as water, fertilizer, and seeds. AI promises to improve this, but
how companies apply it varies widely.
At one end, companies may optimize reactively, using AI to speed up
today's tasks without questioning if they're still valuable. Traditional
agribusinesses using AI to better predict farm yield operate in this manner.
They improve productivity at the task level but leave the broader supply
chain and decision-making structures unchanged.
In contrast, anticipators - the 'Gretzkys' of AI-aided transformation - may
sense the next move before others and skate to where the puck is going.
However, without reimagining the game, the advantage they gain is limited.
Precision agriculture companies recognized early on that utilizing soil and
weather data could help farmers use water, fertilizer, and seeds as farm
inputs more efficiently. They went beyond predicting better to directly
improving yields by applying farm inputs better. However, they simply sold
these analytical solutions a layer of insight on top of older workflows,
without reimagining how farming decisions were made or how the farm
inputs supply chain was structured. Anticipators identify value migration
early and can move to seize it, but remain stuck playing the old game and
only benefit from incremental value capture.
Further along the spectrum are the logic shifters. These 'Currys' of AI-aided
transformation sense that AI offers an opportunity to change the game,
forcing a shift not just in tasks but in the way organizational systems are
structured. John Deere's use of AI and robotics in its machinery enables its
tractors to distinguish individual plants and apply farm inputs like fertilizer
or herbicide with precision to improve yield. Unlike the precision
agriculture service providers mentioned above, Deere doesn't stop at
improving decisions regarding farm inputs within today's workflows;
instead, it changes where and how farming decisions are made. By moving
decision-making away from the farmer and into the machine, Deere alters

the logic of value creation and, consequently, the organizational system of
the farm. In doing so, it shifts power from the farmer to the tool, as we've
noted earlier in the book.
Finally, the firms that have the most transformative impact in the age of AI
are those that restructure the entire playing field - the field reshapers.
Climate Corp, an example we examined earlier, collects granular field data
from thousands of farms and integrates it into a platform that connects seed
selection, input purchasing, risk management, and even emerging carbon
markets. Climate Corp transforms not just the organizational system of the
farm, but also the larger competitive ecosystem, to transform yields across
the agricultural system as a whole.
In all four cases, the goal is the same: improve yield. However, the
approach and the impact differ dramatically. Reactive optimizers speed up
existing work. Anticipators spot new opportunities but remain trapped in
old structures. Logic shifters rewire who makes decisions and how they are
made. And field reshapers reorganize the entire system, coordinating
multiple players to unlock system-wide value. The deeper the reimagining
of coordination, the greater the shift in who holds power, and the more
enduring the advantage that follows.

Table 12.1: The four strategic postures for companies leveraging AI
All four types of companies have access to the same technology and
recognize the potential of transforming farming through data and AI. Yet,
their impact is remarkably different. Skating fast enough or skating to
where the puck is headed is no longer enough when the playing field is
constantly in flux. What matters is whether you are changing the game or
just trying to keep up with the one that someone else is defining for you.
Reshuffle... or get reshuffled
The magician's reshuffle is a paradox: it looks like disorder but conceals a
plan. To the untrained eye, the magician's reshuffle looks like randomness.
Cards scatter unpredictably, and outcomes seem left to chance. Yet beneath
this apparent randomness, there's a controlled and meticulous arrangement
guiding fate's hand.
Today, as technological, market, and geopolitical forces converge, the same
illusion persists. Industries churn as yesterday's winners stumble and new
players emerge from unexpected places. The deck keeps getting reshuffled.
It's tempting to believe we're simply at the mercy of change.
However, that chaos is not without structure. If we understand the new
mechanisms of coordination, we gain the power to set the playing field for
others. The same forces that seem to upend the game can be harnessed to
redesign the playing field itself, tilting it in our favor.
The real promise of AI is not in surviving the reshuffle but in mastering it in our favor.
OceanofPDF.com


OceanofPDF.com

GLOSSARY
A
Above-the-Algorithm vs. Below-the-Algorithm Above-the-algorithm
workers use or build algorithmic systems to increase their leverage. Below-
the-algorithm workers are managed by these systems, with limited
autonomy or differentiation.
Accessibility How easy it is for a customer to adopt and pay for a solution.
Agentic Execution The use of autonomous, goal-driven AI agents that
continuously monitor systems, detect intent, and act across workflows
without human prompting.
Agentic Workflow/System A system where AI agents pursue a goal by
coordinating multiple tasks without human input at each step. Unlike
traditional automation, which follows rigid rules, agentic systems adapt,
make decisions, and respond to changing contexts.
AI as a Tool AI is used to optimize or automate tasks within an existing
business model. It improves efficiency but doesn't change the basis of
competition.

AI as an Engine AI drives core system performance and defines how the
business operates. This requires rethinking workflows, models, and the
value proposition itself.
AI as Coordination Infrastructure (Strategic Context) AI's most
transformational role isn't automation, but extending coordination into
previously uncoordinated domains by structuring ambiguity and translating
tacit cues. AI as the central nervous system managing team alignment,
context flow, and shared understanding. 
AI Assistant A context-aware system that supports human decision-making
by evaluating options based on goals, preferences, and constraints.
AI Commoditization The process by which previously scarce expertise
becomes widely available and interchangeable, eroding traditional moats.
AI-Driven Rebundling The process of using AI to pull together
fragmented data, decisions, and execution into a coherent system, even
when underlying systems are not standardized or integrated.
AI-Enabled Coordination Using AI to manage how teams align and work
together by transforming unstructured data into structured, actionable
insights. This turns coordination from a cost center into a performance
driver.
AI-Native Firm An organization designed from the ground up to integrate
AI into core workflows, decision-making, and knowledge distributionâ
unlike incumbents layering AI atop old systems.
Algorithmic Coordination The use of algorithms to dynamically manage
tasks, workflows, or supply chains, replacing traditional human-based
coordination systems.
Algorithmic Management The use of algorithms to allocate, supervise,
and evaluate work. It compresses wages, standardizes output, and removes
decision-making control from workers.
Assistive Execution AI-supported workflows where humans still make the
final decisions, but AI provides help such as summaries and

recommendations. This bridges current knowledge work and more
advanced agentic workflows.
Automation vs. Coordination Automation reduces the cost of executing
tasks, collapsing their economic value. Coordination restructures
workflows, changing the context in which tasks are performed and altering
their relevance or importance.
Autonomy-Coordination Trade-off The classic organizational tension
between giving teams freedom to move fast and keeping them aligned with
others. Traditional structures treat this as a zero-sum game; more autonomy
means less coordination, and vice versa.
B
Barcode-Native Architecture An organizational system designed to fully
leverage barcode data for centralized coordination and control. Walmart
exemplified this, turning data into leverage.
Behavior Graph A model built by observing user actions to infer
preferences. Replaces the traditional social graph in AI-native experiences.
Building Block A discrete, modular capability that can be rented, reused,
and recombined to create a larger system. Examples include cloud
computing, ghost kitchens, or AI-driven legal tools.
Building Block Economy An economy structured around rentable, modular
capabilities. Success depends on how well you rebundle these parts and
manage the constraints between them.
C
Clockspeed The relative pace of innovation in different parts of the value
chain. AI tools often evolve faster than the businesses that adopt them,
creating strategic tension.

Cold Start Problem The chicken-and-egg problem of getting an ecosystem
going: participants won't join unless value is visible, but value doesn't
emerge until they join.
Collapse of Differentiation When AI tools make everyone's output look
the same, individual expertise no longer stands out. This erases the basis for
earning more based on skill or nuance.
Commoditization of Task-Level AI The diminishing returns from plug-
and-play AI tools when all firms use similar task automations, leading to a
flattening of competitive differentiation.
Composable Business A business model that assembles third-party
capabilities rather than building them in-house. It's agile, asset-light, and
scalable.
Composition Power Control over how different actors or components plug
into the system. In Walmart's case, suppliers had to conform to defined
protocols to be part of the network.
Compounding vs Cascading Effects Compounding explains technological
scale (faster chips), but cascading coordination explains economic
transformation (outsourcing, supply chain reconfig).
Constraint Management The strategic practice of identifying and actively
designing around system limits to ensure consistent performance and
defensibility.
Constraints System-level bottlenecks that limit performance. These can be
scarcity-based (lack of access), risk-based (uncertainty and accountability),
or coordination-based (difficulty aligning multiple parts).
Contextual Value The value a role holds in a specific system because it
resolves a critical constraint. Unlike skill-based value, contextual value
depends on where friction appears in the system.
Control Point A strategic chokehold in a system or ecosystem through
which other participants must operate to create or deliver value. Control

points create power not by owning customers directly but by becoming
indispensable to others' operations.
Coordination The act of aligning independent agents toward a shared
outcome, especially under conditions of fragmentation, ambiguity, or
misaligned incentives.
Coordination Gap The space between what current algorithms can
coordinate (structured, codified workflows) and what economic activity
actually requires (judgment, context, tacit knowledge).
Coordination Paradox When AI is used narrowly for local automation, it
fragments the organization and raises, not lowers, coordination costs.
Coordination Problem The challenge of getting fragmented actors - tools,
teams, or firms - to work together toward a shared goal, especially when
incentives, data formats, and workflows are misaligned.
Coordination Tax The hidden cost organizations pay to keep teams
aligned, through meetings, messaging, document searches, and manual
processes. This cost grows exponentially as organizations scale and is often
invisible but highly draining.
Coordination Technology Technologies that align fragmented parts of a
system to work together efficiently. Historically includes barcodes and
containerization; today, AI enables coordination at scale without requiring
consensus.
Coordination Without Consensus A new coordination model enabled by
AI, where actors work together without prior agreement on data formats or
rules. AI interprets diverse inputs, builds a shared understanding, and drives
aligned actions.
Coordination-Based Constraints Constraints that arise when multiple
moving parts, tools, or actors must align. Roles like RevOps managers or
nurse navigators gain value by resolving these across workflows.
Coordination Advantage The strategic edge gained when a firm designs
superior coordination systems, not just better tools or products.

Curation The act of discerning and elevating the most relevant signals
from noise. Goes beyond filtering content to shaping context and narrative,
increasing in value as information becomes commoditized.
Curiosity The disciplined ability to frame high-leverage questions and
performance bottlenecks. Becomes a key economic asset when generating
answers is cheap and abundant.
Customer Journey Fragmentation The unbundling of traditional purchase
journeys into disconnected steps (e.g., research, reviews, trial, purchase),
often across platforms and formats.
Customer Journey Rebundling Reassembling fragmented steps in the
customer journey into a seamless, trust-driven experience.
D
Data Flywheel The self-reinforcing loop where increased usage generates
more data, which in turn improves the system, attracting even more usage.
Decision Friction The cognitive burden or uncertainty that prevents
customers from making confident choices.
Decision Power The authority to make choices based on system data. In
AI-coordinated systems, decision power often shifts to those who design or
control the models and data flows.
Decision Support The act of helping users make informed, confident
choices in environments of overwhelming options. It simplifies complexity
and earns trust.
Demand-Side Control Point Power gained by controlling key decisions
customers make (e.g., buying, choosing, searching).
Dependence vs. Dominance Ecosystem control is no longer about
dominance (ownership or lock-in) but about becoming so useful that others
depend on you to function efficiently.

Digital Twin A live, data-driven simulation of a physical system (e.g.,
aircraft production) used to continuously optimize workflows and decision-
making.
E
Economic Collapse of the Task When a task loses its market value because
AI makes it easy or cheap to perform. The task still gets done, but it no
longer commands a premium.
Economic Visibility The extent to which a role's contribution is recognized
and rewarded by the system. Contextual value must be made economically
visible to be captured.
Economic vs. Contextual Displacement A task may become cheaper to
perform (economic displacement) or lose its importance in the workflow
(contextual displacement). Either outcome makes the job less valuable.
Ecosystem Control The ability to influence or direct the behavior of
independent ecosystem participants, often without owning them, by
resolving the key coordination problems they face.
Ecosystem Flywheel A reinforcing loop where AI-driven coordination
attracts more participants, generating more data, which improves
coordination, attracting even more users.
Engine A core component that determines overall system performance. It's
not replaceable without re-architecting the system.
Execution Bias The tendency to act quickly because execution is easy,
often at the expense of strategic intent. Made more dangerous in the AI era.
Execution Power The capacity to direct actions and workflows once a
decision is made. AI tightens the link between decision and execution, often
removing human discretion.
Exponential Systems Systems where one coordination breakthrough (e.g.,
containers, APIs) triggers layers of new capabilities, restructuring

industries, not just accelerating outputs.
F
Fragmentation A state where tools, workflows, or actors operate
independently and lack shared standards, making coordination and data
flow difficult.
Framing Error A cognitive mistake where one tries to solve a problem
using an obsolete mental model or system logic, ignoring changes in the
underlying structure.
G
Governance Power The ability to set and enforce rules for participation in
a system. AI platforms increasingly define performance metrics and
behavioral norms.
H
Human-in-the-Loop Illusion The belief that humans remain central by
guiding AI. In reality, workers may be reduced to supporting roles within
systems that make most of the key decisions.
I
Intrinsic, Economic, and Contextual Value Tasks can have meaning
(intrinsic), command payment (economic), or matter within a specific
workflow (contextual). A task may feel meaningful but still be
economically or systemically irrelevant.

J
Judgment The human capacity to make accountable decisions under
uncertainty. Judgment gains value as AI introduces probabilistic outputs and
accountability gaps.
K
Knowledge as Capital When knowledge becomes a rentable capability -
scalable, recombinable, and accessible on demand - rather than something
tied to individual labor.
Knowledge Management Infrastructure The tools and systems used to
store, organize, and retrieve knowledge. Most organizations still rely on
outdated digital filing cabinets, unable to support fast, modular work.
L
Learning Flywheel The self-reinforcing loop where more deployments
generate more data, improving performance, customer satisfaction, and
profitability over time.
Learning Loop AI's capacity to continuously improve through feedback
from use. Unlike static coordination tools like barcodes, AI adjusts the
system as it learns from it.
Leverage The ability to amplify output without a proportional increase in
input. In this context, it comes from renting capabilities, deploying AI, and
orchestrating platforms.
Local Optimization, Systemic Fragility When some parts of a system
improve in isolation (e.g., AI-enhanced sales forecasting) but others lag
(e.g., legacy supply chain ops), misalignment increases.

M
Modular Team Structure Small, focused teams that plug into a larger
organization like building blocks. This works only if coordination
mechanisms keep them aligned.
Modularity The design principle of creating discrete, interchangeable
components that can be combined and recombined to build larger systems.
N
Narrative Control The power to shape meaning and action through
storytelling and curation. Especially valuable in the age of AI where the
abundance of answers increases the need for good framing.
Negative Constraint A bottleneck or failure point in a system that reduces
system performance and often emerges due to neglect.
Network Capital The influence, attention, or reach an individual or brand
has with a distributed online audience. It enables outsized impact without
physical infrastructure.
O
Organizational Rebundling Reconfiguring how teams, tools, and
workflows are structured by AI, creating new, adaptive organizational
forms. AI unbundles knowledge from where it lives and rebundles it into
intelligent, flexible systems.
Outcomes-as-a-Service The provider is paid based on customer-specific
strategic outcomes, often requiring end-to-end control, high liability, and
advanced performance monitoring.

Ownership of Outcomes Taking responsibility for outcomes means
accepting liability, which requires visibility (representation), integration
(decision-making), and execution (service delivery).
P
Performance Leverage Tool providers gain leverage by delivering superior
performance or control over a critical component ("engine") of the solution.
Performance-Based Lock-In Dependence created not by contracts, but by
the superior performance of a component (like an AI engine). The better it
performs, the harder it is to walk away from.
Pie-Slicing vs. Pie-Growing Technologies grow the economic pie but also
reshape who gets to slice it. AI intensifies these inequalities by
concentrating coordination power.
Platform Tax Fees or concessions charged by an orchestrator to ecosystem
participants for access to decision moments or customers.
Positive Constraint (System Context) A structuring mechanism (standard
interface, SLA, governance rule) that enables better coordination,
performance, or scale.
Positive Constraint A deliberately chosen boundary or design rule that
shapes system performance and creates strategic differentiation. Positive
constraints preserve meaning, judgment, or diversity within a system, often
sacrificed when optimizing purely for speed or scale.
Process-Level Coordination The alignment of teams, tools, and handoffs
within a bounded workflow. Essential in ensuring that automated or
specialized tools don't fragment the system.
R

Rebundling (Multiple Contexts) The process of restructuring a role by
assembling new combinations of tasks and capabilities to manage emerging
constraints after the unbundling of traditional roles by AI or other
technologies.
Rebundling (Building Block Context) The act of combining multiple
building blocks into a coherent system or solution. The value lies not in the
components themselves, but in how effectively they are assembled and
coordinated.
Rebundling (Structural Context) The process of reorganizing tasks and
capabilities into new system architectures. AI enables rebundling not just of
workflows, but of entire industries.
Rebundling (System Context) The reassembly of tasks or components into
new roles, workflows, or organizational structures, driven by new
constraints or coordination mechanisms (e.g., AI, platforms).
Rebundled Role A new role created by combining human capabilities
around an emerging constraint, often gaining leverage, trust, and relevance
in the new system of work.
Reliability How consistently a solution performs its intended function in
the field, under real-world constraints.
Reliability Leverage Solution providers gain leverage by taking
responsibility for delivering consistent outcomes in unpredictable
environments.
Representation Power The ability to define what is visible and measurable
in a system. Whoever controls representation sets the frame for decisions.
AI extends representation by turning unstructured data into structured
inputs.
Reskilling Fallacy The flawed belief that learning new skills is sufficient
protection. When the system no longer needs human execution of a task,
reskilling alone won't preserve the job's value.

Results-as-a-Service The provider is paid for achieving specific
measurable outcomes (e.g., fragmenting rock to spec), requiring deeper
integration and domain expertise.
Right to Coordinate The earned ability to organize an ecosystem by
reducing friction in both decision-making and execution, requires deep
integration, not just UI simplification.
Risk Absorption When a solution provider internalizes the risk of failure,
technical, financial, or operational, so the customer doesn't bear it.
Risk-Based Constraints Constraints that emerge in systems where small
errors have high consequences. Value accrues to roles that can absorb
uncertainty and exercise trusted judgment, like anesthesiologists or fugu
chefs.
S
Scarcity-Based Constraints Constraints that arise when critical resources
in knowledge, tools, or access are limited. Historically, professions like law,
medicine, and consulting thrived by managing these constraints.
Scope Expansion True economic transformation comes not from doing
more of the same faster, but from enabling new forms of interaction and
value creation at scale.
Shared Organizational Knowledge The collective know-how, insights,
and context distributed across an organization's teams. When structured
well, it lets teams work independently while staying aligned.
Showrooming Customers explore products in-store but buy online.
Skill Premium Extra income earned because a skill is rare or difficult to
perform. This premium shrinks when AI enables less-skilled workers to
achieve similar results, reducing the scarcity that justified the higher pay.
Skill-Biased Technological Change The belief that technology rewards
highly educated or skilled workers more than others, used to justify

reskilling policies. This no longer holds when AI narrows the performance
gap between high- and low-skilled workers.
Solution A complete offering that delivers reliable outcomes in real-world
conditions by managing surrounding constraints, integrating complements,
and absorbing risk.
Solution Bundle The full stack of tools, services, financing, and guarantees
that together enable predictable performance in complex environments.
Solution Provider A business that integrates tools and services to deliver
outcomes. Holds the customer relationship and is accountable for results,
but is increasingly vulnerable to tool provider lock-in.
Solopreneur An individual who builds and scales a business without a
team, using modular capabilities, AI tools, and network capital to achieve
leverage.
Standardization (Strategic Context) The enforcement of uniform formats
(e.g., container sizes, contracts) that enables plug-and-play coordination
across disconnected systems.
Standardization Risk The more standardized and measurable the work, the
easier it is for tools and insurers to absorb performance and liability,
undermining traditional solution providers.
Supply-Side Control Point Power gained by coordinating how other
ecosystem participants (e.g., vendors, developers, contractors) deliver their
services in a reliable, scalable way.
System Builder A firm or actor that goes beyond improving tool
performance to reengineering the broader system around the tool, solving
constraints across financing, operations, integration, and risk.
System Integration The degree to which components of a system are
designed to function together. Integration turns a set of parts into a
competitive system.
System of Work (Multiple Contexts) The underlying architecture of roles,
workflows, technologies, and decision rights within an organization or

industry. AI transforms this system, altering how tasks are valued and
coordinated.
System Performance Performance that emerges from how well all
components work together, not how powerful any one part is.
System-Aware Adaptation The act of tracking how constraints move as
systems evolve and aligning one's role to solve new frictions, rather than
chasing skills or reacting to automation.
System-Centric View A broader view that focuses not on individual jobs or
skills but on how systems of work evolve. It analyzes how technology
reshapes the architecture and logic of work systems, often reorganizing or
eliminating jobs even if individual tasks persist.
System-Level Coordination The ability to design and govern workflows,
incentives, and interfaces across an entire organization or platform.
Commands the highest economic value due to its leverage.
T
Tacit Knowledge Expertise embedded in human intuition or past
experience, not easily extracted, codified, or taughtâbut essential for
decision-making under uncertainty.
Task-Based Framing The idea that jobs are made up of tasks, and that the
risk of automation depends on whether those tasks are routine or non-
routine. This framing breaks down when AI can learn tacit, judgment-based
tasks once considered safe.
Task-Centric View A perspective that sees jobs as bundles of tasks and
evaluates technology by how it enhances or replaces those tasks
individually, assuming system structure is stable.
The Coordinated Organization A new model of work where AI reduces
friction between teams, integrates decision-making, and keeps everyone
aligned without slowing them down. 

Three-Circle Model A layered view of work where the task-level job is
nested inside the organizational system, which itself operates within a
competitive ecosystemâall of which AI can reshape.
Tool A technology or product that delivers a specific function but requires
the user to manage integration, context, and risk. Tools amplify
performance but do not guarantee outcomes.
Tool Provider An entity that provides functional components (e.g., AI
models, mapping APIs). Initially an enabler, but can gain power and control
by becoming essential to system performance.
Typist Effect A case of job obsolescence not due to task automation, but
due to system redesign, where the logic that justified the job disappears
even though the task remains.
U
Unbundled Expertise The separation of know-how from the human expert.
AI turns this into a reusable capital asset rather than a labor input.
Unbundling (Role/Workflow Context) The disintegration of roles or
workflows into discrete tasks due to technological change, which often
reduces pricing power, differentiation, and decision-making autonomy. The
process by which a job, product, or workflow breaks into its component
parts when old constraints (e.g., cost, coordination, time) are removed. The
separation of tightly coupled capabilities (e.g., expertise from labor, songs
from albums), enabling them to be repurposed independently.
Unbundling and Rebundling of Jobs AI breaks jobs into smaller tasks
(unbundling) and recombines them into new configurations (rebundling).
This reshapes roles and alters who performs which parts of the job.
Unified Decision AI-guided decision-making based on shared context.
Different actors make aligned decisions without constant back-and-forth.

Unified Execution Seamless, AI-coordinated follow-through on decisions
across different tools or teams, even if those tools don't integrate directly.
Unified Representation A shared, AI-generated view of a system or object
(e.g., a damaged car, a construction project) that actors can coordinate
around, even if they use different tools or formats.
Unstructured to Structured Data AI's ability to extract insight from
messy sources like voice calls or Slack threads and turn them into useful
knowledge. This reduces the need for humans to manually encode and
organize information.
Usability How well a tool fits into the customer's workflow without
requiring major change or retraining.
V
Vertical Encroachment A tool provider moves deeper into the solution
layer, absorbing knowledge and delivering more of the end customer
experience directly.
Vibe Coding A term coined by Andrej Karpathy to describe AI-generated
outputs that feel impressive but lack logic or rigor. It reflects a broader
trend toward performative execution.
W
Work-as-a-Service The provider is paid for consistent delivery of
operational work (e.g., propulsion hours, wash cycles), and takes
responsibility for tool performance.
Wrapper A solution provider that is reduced to an interface over someone
else's engine. It controls appearance but not substance.

OceanofPDF.com

ACKNOWLEDGMENTS
This book is the product of many minds and moments, some actively
involved in its creation, others cheering from the sidelines, and still others
offering fuel for its arguments without ever intending to. I'm grateful to all
of them.
I begin with Nir Eyal, whose thoughtful remark during a casual
conversation planted the idea for this book. That brief exchange became the
spark that set this journey in motion.
I'm especially grateful to Sridhar Dhulipala for leading the design of this
book and bringing clarity to its visual expression, overseeing its execution
with care and precision. Under his guidance, a talented design team helped
bring the final product to life: Lakshmi V.J. and Mayank Saxena, who
brought the layout and illustrations to life, and Kirti Vardhan Rathore,
whose work on the cover helped frame the book's identity.
To the collaborators and co-thinkers who have shaped my intellectual path
over the years: thank you. Bowman Heiden, for recognizing the relevance
of my work on competitive advantage and championing it early. Geoffrey
Parker, for his unwavering support and enduring intellectual generosity.
Marshall Van Alstyne, for always pushing for precision and clarity. 
To the many clients who have offered a real-world proving ground for these
ideas: your challenges, questions, and constraints have tested and sharpened
this work. I'm grateful to all, but especially to a few whose consistent
support and belief in this work have stood out: Nandan Nilekani, Lindsey
Argalas, and Scott Beck.
To the beta readers of early drafts, thank you for your honesty and your
patience. You helped me see just how far those drafts had to go.

To my wife, Devika, thank you for your relentless push to sharpen the
thinking, simplify the message, and find better stories to make abstract
concepts more accessible. This book carries your imprint throughout.
To the readers of my Substack newsletter (platforms.substack.com): your
enthusiasm, thoughtful critiques, and evangelistic enthusiasm have played
an essential role in shaping these ideas over time and taking them to the
world. 
And finally, perhaps unexpectedly, thanks to all those who hype AI or
dismiss it with misplaced confidence, armed with first-order thinking and
logical fallacies. If not for those confident misreadings, this book might
never have needed to be written.
Thank you all.
OceanofPDF.com

T
WHAT NEXT
Continue the Reshuffle journey
hank you for reading Reshuffle. If these ideas sparked something in you,
a strategic shift, a systems insight, or a desire to reframe how you think
about the future, there are several ways to keep engaging:
BOOKS AND MORE
Get a bonus chapter 
If you enjoyed the book, I'd be grateful if you left a review on Amazon. 
As a thank you, please reach out to tripta@platformthinkinglabs.com with a
link/screenshot of the review, and we'll send you an exclusive bonus
chapter from the book on agentic competition.
Stay in the conversation
Subscribe to my newsletterplatforms.substack.com, where I publish the
latest thinking not just from Reshuffle, but also from the upcoming books

Unfair Advantage and Platform Domination. The newsletter combines
strategic insights with evolving case studies, diagnostics, and mental
models to help you better navigate the strategic dilemmas confronting us
today.
The Reshuffle Companion Guide
A companion study guide to Reshuffle will launch in Dec 2025. It will
include provocative prompts, mental framing and deframing exercises, and
structured diagnostics to help you apply the ideas in your context. Look out
for the announcement via the newsletter.
ENGAGE FURTHER
Bring the ideas of Reshuffle to your organization
If you're navigating strategic inflection points, driven by AI, shifting
ecosystems, or structural change, I work with leadership teams to reframe
strategic dilemmas and rethink competitive advantage. To engage further
through a keynote, executive retreat, or a strategic advisory engagement,
please contact Liz at liz@platformthinkinglabs.com.
For podcasts and media appearances to discuss these themes, please contact
Tripta at tripta@platformthinkinglabs.com. 
For more information on the above, visit www.platformthinkinglabs.com
and reshufflebook.com  to explore further.
OceanofPDF.com

W
UPCOMING BOOKS BY THE AUTHOR
Unfair Advantage
hen markets are stable, strategy is a path to winning the existing game.
But when the structure of markets is up for grabs, the most enduring
advantage comes from flipping the playing field in your favor. 
Unfair Advantage redefines strategy for an era of structural change.
Drawing on vivid case studies of companies that have repeatedly reshaped
the economics of entrenched industries, this book reveals why some firms
stumble, while others reinvent the rules and redefine the game.
Unfair Advantage challenges traditional strategy by showing how modern
power is constructed through system design, not just competitive strength.
The book unpacks five foundational dilemmas, each a fork in the road that
determines whether a company becomes just another player or the central
hub everyone else depends on. 
This is a book about the future of competition, but it is not a book about
competing better. It's about designing the system to make competition
irrelevant.

Platform Domination
Platforms have become the infrastructure of the modern economy, not by
owning assets, but by coordinating them. From shopping to speech, and
mobility to media, platforms now decide what gets seen and who gets paid.
Platforms also determine what constitutes truth, who gets to participate in a
market, and which behaviors are rewarded or suppressed. Yet we're still
trying to regulate them like railroads or telecom carriers, relying on policy
frameworks that misunderstand the new structure of power.
Platform Domination is a bold rethinking of the digital economy by the
authors of Platform Revolution. This book reveals how platforms create
value not just through scale, but through coordination, by structuring how
users, data, incentives, and decisions flow. And it shows how that
coordination translates to power. 
Platform Domination reframes platforms as private systems that govern
public life. It argues that we need new tools, not just to regulate
competition, but to understand and govern the underlying architectures that
now coordinate our economies and societies.
For regulators, founders, and citizens alike, this is the essential guide to the
most important economic shift of our time: from execution to coordination,
from visible infrastructure to invisible control.
OceanofPDF.com

