THE LOGIC MANUAL
for Introduction to Logic
2008/2009
Volker Halbach
Oxford
8th August 2008
Tis text is to be used by candidates
in their ﬁrst year in 2008/2009. Te
set text for Literae Humaniores stu-
dents sitting Moderations in 2009 is
Hodges's Logic.

Content
1
Sets, Relations, and Arguments 5
1.1 Sets 5
1.2 Binary Relations 7
1.3 Functions 13
1.4 Non-Binary Relations 15
1.5 Arguments, Validity and Contradiction 16
1.6 Syntax, Semantics and Pragmatics 24
2
Syntax and Semantics of Propositional Logic 26
2.1 Quotation 26
2.2 Te Syntax of the Language of Propositional Logic 28
2.3 Rules for Dropping Brackets 30
2.4 Te Semantics of Propositional Logic 33
3
Formalisation in Propositional Logic 50
3.1 Truth-Functionality 51
3.2 Logical Form 55
3.3 From Logical Form to Formal Language 60
3.4 Ambiguity 62
3.5 Te Standard Connectives 64
3.6 Natural Language and Propositional Logic 66
4
Te Syntax of Predicate Logic 73
4.1 Predicates and Quantiﬁcation 73
4.2 Te Sentences of L2 81
4.3 Free and Bound Occurrences of Variables 84
© Volker Halbach
2008/2009

4.4 Notational Conventions 86
4.5 Formalisation 87
5
Te Semantics of Predicate Logic 93
5.1 Structures 94
5.2 Truth 99
5.3 Validity, Logical Truths, and Contradictions 107
5.4 Counterexamples 108
6
Natural Deduction 114
6.1 Propositional Logic 116
6.2 Predicate Logic 128
7
Formalisation in Predicate Logic 141
7.1 Adequacy 141
7.2 Ambiguity 145
7.3 Extensionality 150
7.4 Predicate Logic and Arguments in English 156
8
Identity and Deﬁnite Descriptions 165
8.1 Qualitative and Numerical Identity 165
8.2 Te Syntax of L= 166
8.3 Semantics 167
8.4 Proof Rules for Identity 170
8.5 Uses of identity 173
8.6 Identity as a Logical Constant 182
Natural Deduction Rules 185

preface
Te Logic Manual is a relatively brief introduction to logic. I have tried to
focus on the core topics and have neglected some issues that are covered
in more comprehensive books such as Forbes (1994), Guttenplan (1997),
Hodges (2001), Smith (2003), and Tennant (1990). In particular, I have
tried not to include material that is inessential to Preliminary Examina-
tions and Moderations in Oxford. For various topics, I could not resist
adding footnotes oﬀering extra information to the curious reader.
Logic is usually taught in one term. Consequently, I have divided the
text into eight chapters:
1. Sets, Relations, and Arguments
2. Syntax and Semantics of Propositional Logic
3. Formalisation in Propositional Logic
4. Te Syntax of Predicate Logic
5. Te Semantics of Predicate Logic
6. Natural Deduction
7. Formalisation in Predicate Logic
8. Identity and Deﬁnite Descriptions
If the reader wishes to read selectively, chapters 1-3 constitute a self-con-
tained part, to which Section 6.1 (Natural Deduction for propositional
logic) can be added; and chapters 1-7 yield an introduction to predicate
logic without identity.
I have set the core deﬁnitions, explanations, and results in italics like
this. Tis might be useful for revision and for ﬁnding important passages
more quickly.
In some cases, the end of an example or a proof is marked by a square
◻. Te word 'iﬀ' is short for 'if and only if'.
I have written an Exercises Booklet that can be used in conjunction
with this Logic Manual. It is available from WebLearn. Tere also some
additional teaching materials may be found such as further examples of
proofs in the system of Natural Deduction.
I am indebted to colleagues for discussions and comments on previous

versions of the text. In particular, I would like to thank Stephen Blamey,
Paolo Crivelli, Geoﬀrey Ferrari, Lindsay Judson, Ofra Magidor, David
McCarty, Peter Millican, Alexander Paseau, Annamaria Schiaparelli, Se-
bastian Sequoiah-Grayson, Mark Takkar, Gabriel Uzquiano, and David
Wiggins. I am especially grateful to Jane Friedman and Christopher von
Bülow for their help in preparing the ﬁnal version of the Manual.

1 Sets, Relations, and Arguments
1.1 sets
Set theory is employed in many disciplines. As such, some acquaintance
with the most basic notions of set theory will be useful not only in logic,
but also in other areas that rely on formal methods. Set theory is a vast
area of mathematical research and of signiﬁcant philosophical interest.
For the purposes of this book, the reader only needs to know a fragment
of the fundamentals of set theory.1
A set is a collection of objects. Tese objects may be concrete objects
such as persons, cars and planets or mathematical objects such as numbers
or other sets.
Sets are identical if and only if they have the same members. Terefore,
the set of all animals with kidneys and the set of all animals with a heart
are identical, because exactly those animals that have kidneys also have
a heart and vice versa.2 In contrast, the property of having a heart is
usually distinguished from the property of having kidneys, although both
properties apply to the same objects.
Tat a is an element of the set M can be expressed symbolically by
1 Tere are various mathematical introductions to set theory such as Devlin (1993),
Moschovakis (1994) or the more elementary Halmos (1960). In contrast to rigorous
expositions of set theory, I will not proceed axiomatically here.
2 I have added this footnote because there are regularly protests with respect to this
example. For this example, only complete and healthy animals are being considered. I
have been told that planarians (a type of ﬂatworms) are an exception to the heart-kidney
rule, so, for the sake of the example, I should exclude them as well.
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
6
writing 'a ∈M'. If a is an element of M, one also says that a is in M or
that M contains a.
Tere is exactly one set that contains no elements, namely, the empty
set ∅. Obviously, there is only one empty set, because all sets containing
no elements contain the same elements, namely none.
Tere are various ways to denote sets.
One can write down names of the elements, or other designations of
the elements, and enclose this list in curly brackets.
Te set {London, Munich}, for instance, has exactly two cities as its
elements. Te set {Munich, London} has the same elements. Terefore,
the sets are identical, that is:
{London, Munich} = {Munich, London}.
Tus, if a set is speciﬁed by including names for the elements in curly
brackets, the order of the names between the brackets does not matter.
Te set {the capital of England, Munich} is again the same set be-
cause 'the capital of England' is just another way of designating London.
{London, Munich, the capital of England} is still the same set: adding
another name for London, namely, 'the capital of England', does not add
a further element to {London, Munich}.
Tis method of designating sets has its limitations: sometimes one
lacks names for the elements. Te method will also fail for sets with
inﬁnitely many or even just impractically many elements.
Above I have designated a set by the phrase 'the set of all animals
with a heart'. One can also use the following semi-formal expression to
designate this set:
{ x ∶x is an animal with a heart}
Tis is read as 'the set of all animals with a heart'. Similarly, { x ∶x is a
natural number bigger than 3} is the set of natural numbers bigger than 3,
and { x ∶x is blue all over or x is red all over} is the set of all objects that
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
7
are blue all over and all objects that are red all over.3
1.2 binary relations
Te expression 'is a tiger' applies to some objects, but not to others. Tere
is a set of all objects to which it applies, namely the set { x ∶x is a tiger}
containing all tigers and no other objects. Te expression 'is a bigger city
than', in contrast, does not apply to single objects; rather it relates two
objects. It applies to London and Munich (in this order), for instance,
because London is a bigger city than Munich. One can also say that the
expression 'is a bigger city than' applies to pairs of objects. Te set of all
pairs to which the expression 'is a bigger city than' applies is called 'the
binary relation of being a bigger city than' or simply 'the relation of being
a bigger city than'.4 Tis relation contains all pairs with objects d and e
such that d is a bigger city than e.5
However, these pairs cannot be understood simply as the sets {d, e},
such that d is a bigger city than e, because elements of a set are not ordered
by the set: as pointed out above, the set {London, Munich} is the same
set as {Munich, London}. So a set with two elements does not have a
ﬁrst or second element. Since London is bigger than Munich, but not
vice versa, only the pair with London as ﬁrst component and Munich as
3 Te assumption that any description of this kind actually describes a set is problematic.
Te so-called Russell paradox imposes some limitations on what sets one can postulate.
See Exercise 7.6.
4 By the qualiﬁcation 'binary' one distinguishes relations applying to pairs from relations
applying to triples and strings of more objects. I will return to non-binary relations in
Section 1.4.
5 Ofen philosophers do not identify relations with sets of pairs. On their terminology
relations need to be distinguished from sets of ordered pairs in the same way properties
need to be distinguished from sets (see footnote 2). In set theory, however, it is common
to refer to sets of ordered pairs as binary relations and I shall follow this usage here.
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
8
second component should be in the relation of being a bigger city than,
but not the pair with Munich as ﬁrst component and London as second
component.
Terefore, so-called ordered-pairs are used in set theory. Tey are
diﬀerent from sets with two elements. Ordered pairs, in contrast to sets
with two elements, have a ﬁrst and a second component (and no further
components). Te ordered pair ⟨London, Munich⟩has London as its ﬁrst
component and Munich as its second. ⟨Munich, London⟩is a diﬀerent
ordered pair, because the two ordered pairs diﬀer in both their ﬁrst and
second components.6 More formally, an ordered pair ⟨d, e⟩is identical
with ⟨f , g⟩if and only if d = f and e = g. Te ordered pair ⟨the largest
city in Bavaria, the largest city in the UK⟩is the same ordered pair as
⟨Munich, London⟩, because they coincide in their ﬁrst and in their second
component. An ordered pair can have the same object as ﬁrst and second
component: ⟨London, London⟩, for instance, has London as its ﬁrst and
second component. ⟨Munich, London⟩and ⟨London, London⟩are two
diﬀerent ordered pairs, because they diﬀer in their ﬁrst components. Since
I will not be dealing with other pairs, I will ofen drop the qualiﬁcation
'ordered' from 'ordered pair'.
definition 1.1. A set is a binary relation if and only if it contains only
ordered pairs.
According to the deﬁnition, a set is a binary relation if it does not
contain anything that is not an ordered pair. Since the empty set ∅does
not contain anything, it does not contain anything that is not an ordered
pair. Terefore, the empty set is a binary relation.
Te binary relation of being a bigger city than, that is, the relation
that is satisﬁed by objects d and e if and only if d is a bigger city than e is
the following set:
6 Using a nice trick, one can dispense with ordered pairs by deﬁning the ordered pair
⟨d, e⟩as {{d}, {d, e}}. Te trick will not be used here.
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
9
{⟨London, Munich⟩, ⟨London, Oxford⟩, ⟨Munich, Oxford⟩,
⟨Paris, Munich⟩, ...}
In the following deﬁnition I will classify binary relations. Later, I shall
illustrate the deﬁnitions by examples. Here, and in the following, I shall
use 'iﬀ' as an abbreviation for 'if and only if '.
definition 1.2. A binary relation R is
(i) reﬂexive on a set S iﬀfor all d in S the pair ⟨d, d⟩is an element of R;
(ii) symmetric iﬀfor all d, e: if ⟨d, e⟩∈R then ⟨e, d⟩∈R;
(iii) asymmetric iﬀfor no d, e: ⟨d, e⟩∈R and ⟨e, d⟩∈R;
(iv) antisymmetric iﬀfor no two distinct d, e: ⟨d, e⟩∈R and ⟨e, d⟩∈R;
(v) transitive iﬀfor all d, e, f : if ⟨d, e⟩∈R and ⟨e, f ⟩∈R, then also
⟨d, f ⟩∈R;
(vi) an equivalence relation on S iﬀR is reﬂexive on S, symmetric and
transitive.
In the following I shall occasionally drop the qualiﬁcation 'binary'.
As long as they are not too complicated, relations and their properties
- such as reﬂexivity and symmetry - can be visualised by diagrams. For
every component of an ordered pair in the relation, one writes exactly
one name (or other designation) in the diagram. Te ordered pairs in the
relation are then represented by arrows. For instance, the relation
{⟨France, Italy⟩, ⟨Italy, Austria⟩, ⟨France, France⟩,
⟨Italy, Italy⟩, ⟨Austria, Austria⟩}
has the following diagram:
France
$I
I
I
I
I
I
I
I
I

Austria

Italy
:u
u
u
u
u
u
u
u
u
V
Te arrow from 'France' to 'Italy' corresponds to the pair ⟨France,
Italy⟩, and the arrow from 'Italy' to 'Austria' corresponds to the pair ⟨Italy,
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
10
Austria⟨. Te three loops in the diagram correspond to the three pairs
⟨France, France⟩, ⟨Italy, Italy⟩, ⟨Austria, Austria⟩.
Since 'France', 'Italy' and 'Austria' all have such a loop attached to
them, the relation is reﬂexive on the set {France, Italy, Austria}. Te
relation is not reﬂexive on the set {France, Italy, Austria, Spain}, because
the pair ⟨Spain, Spain⟩is not in the relation.
Te relation is not transitive. For transitivity it is required that if there
is an arrow from a point d to a point e and one from e to f in the diagram,
then there must be a 'shortcut', that is, a (direct) arrow from d to f . In the
diagram above there is an arrow from 'France' to 'Italy' and an arrow from
'Italy' to 'Austria', but there is no arrow from 'France' to 'Austria'. Hence
the relation is not transitive. If the additional pair ⟨France, Austria⟩were
added to the relation, then a transitive relation would be obtained.
If a relation is symmetric, then there are no 'one-way' arrows. Tat
is, if there is an arrow from d to e, then there must be an arrow back to
d from e. Te relation above is not symmetric. For instance, the pair
⟨France, Italy⟩is in the relation, but not the pair ⟨Italy, France⟩. Tat is,
in the diagram there is an arrow from 'France' to 'Italy' but no arrow back
from 'Italy' to 'France'.
Te relation is also not asymmetric. If a relation is asymmetric and
⟨d, e⟩is in the relation, then ⟨e, d⟩cannot be in the relation. Te pair
⟨France, France⟩is in the relation, but the pair with its elements reversed,
that is, ⟨France, France⟩(which happens to be the same ordered pair
again), is in the relation as well, thereby violating the condition for asym-
metry.
Generally, in the diagram of an asymmetric relation there are only
'one-way' arrows: there is never an arrow from an object d to an object e
and then an arrow back from e to d. Tis implies that in the diagram of
an asymmetric relation there cannot be any loops, because if there is an
arrow from d to d, there is also, trivially, an arrow 'back' from d to d: the
very same arrow.
Te relation in the diagram on page 9 is antisymmetric: in an anti-
symmetric relation there must not be two diﬀerent objects with arrows
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
11
in both directions between them. Tus, antisymmetry is the same as
asymmetry except that in an antisymmetric relation elements may have
loops attached to them. In the above diagram there are objects with loops,
but no two diﬀerent objects with arrows in both directions between them.
Terefore, the relation is antisymmetric.
I turn to another example, a relation with the following diagram:
Mars


Pluto

Venus

v
Mercury
V
^
5
Tis relation is reﬂexive on the set {Mars, Pluto, Venus, Mercury}; it is
also symmetric. It fails to be transitive since direct arrows are missing,
for instance, from Mars to Venus. Te relation is not asymmetric or
antisymmetric since there are pairs of objects - such as Mars and Mercury
- that have arrows going back and forth between them .
Both relations discussed so far are not equivalence relations, as they
are not transitive.
Te relation ∅has some peculiar properties: its diagram is empty. It is
reﬂexive on the empty set ∅, but on no other set. It is symmetric, as there
is no arrow for which there is not any arrow in the opposite direction.
But it is also asymmetric and antisymmetric because there is no arrow
for which there is an arrow in the opposite direction. ∅is also transitive.
Consequently, ∅is an equivalence relation on ∅.
Te relation with the diagram below is not reﬂexive on the set with
the two elements Ponte Vecchio and Eiﬀel Tower, because there is no loop
attached to 'Eiﬀel Tower'.
Eiﬀel Tower
. Ponte Vecchio

m
Te relation is symmetric, but not asymmetric or antisymmetric. It is
also not transitive: there is an arrow from 'Eiﬀel Tower' to 'Ponte Vecchio'
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
12
and an arrow back from 'Ponte Vecchio' to 'Eiﬀel Tower', but there is no
shortcut from 'Eiﬀel Tower' directly to 'Eiﬀel Tower', that is, there is no
loop attached to 'Eiﬀel Tower'.
Now I turn to a relation that cannot easily be described by a diagram
or by listing the pairs in the relation, namely to the relation that obtains
between persons d and e if and only if d is at least as tall as e, that is, the
relation that contains exactly those pairs ⟨d, e⟩such that d is at least as
tall as e. Tis relation is reﬂexive on the set of all persons because every
person is at least as tall as themselves. Te relation is not symmetric: I am
taller than my brother, so I am at least as tall as he is, but he is not at least
as tall as I am. Tus the pair ⟨Volker Halbach, Volker Halbach's brother⟩
is an element of the relation, while ⟨Volker Halbach's brother, Volker
Halbach⟩is not an element of the relation. Te relation is transitive: if d
is at least as tall as e and e is at least as tall as f , then surely d is at least
as tall as f . Since the relation is not symmetric it is not an equivalence
relation.
Te relation of loving contains exactly those ordered pairs ⟨d, e⟩such
that d loves e. Tis relation is presumably not reﬂexive on the set of all
persons: some people do not love themselves. Much grief is caused by the
fact that this relation is not symmetric, and the fortunate cases of mutual
love show that the relation is also not asymmetric or antisymmetric. It
clearly fails to be transitive: there are many cases in which d loves e and
e loves f , but in many cases d does not love his or her rival f .
Te relation of not having the same hair colour is the set containing
exactly those pairs ⟨d, e⟩such that d does not have the same hair colour
as e. Tis relation is surely not reﬂexive on the set of all persons, but
it is symmetric: if d's hair colour is diﬀerent from e's hair colour, then
surely e's hair colour is diﬀerent from d's hair colour. Te relation fails to
be transitive: my hair colour is diﬀerent from my brother's hair colour
and his hair colour is diﬀerent from mine. If the relation were transitive,
then I would have a hair colour that diﬀers from my own hair colour.
More formally, the pairs ⟨Volker Halbach, Volker Halbach's brother⟩and
⟨Volker Halbach's brother, Volker Halbach⟩are in the relation, while
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
13
⟨Volker Halbach, Volker Halbach⟩is not. Tis example illustrates again
that in the deﬁnition of transitivity it is not presupposed that d must be
diﬀerent from f .
Te relation of being born on the same day is reﬂexive on the set of
all persons; it is also symmetric and transitive. Tus it is an equivalence
relation on the set of all persons.
I will now turn to another very important kind of relation. It is so
important that it deserves a section of its own.
1.3 functions
definition 1.3. A binary relation R is a function iﬀfor all d, e, f : if
⟨d, e⟩∈R and ⟨d, f ⟩∈R then e = f .
Tus a relation is a function if for every d there is at most one e such
that ⟨d, e⟩is in the relation.
In the diagram of a function there is at most one arrow leaving from
any point in the diagram. In order to illustrate this, I will consider the
function with the following ordered pairs as its elements: ⟨France, Paris⟩,
⟨Italy, Rome⟩, ⟨England, London⟩, and ⟨the United Kingdom, London⟩.
Te function has the following diagram:
France
/ Paris
Italy
/ Rome
England
/ London
the United Kingdom
4i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
In this diagram, there are arrows from 'France', 'Italy', 'England', and
'the United Kingdom'. Te set containing France, Italy, England and the
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
14
United Kingdom is called 'the domain' of the function. Te names of the
three cities receive arrows; the set of these three cities is called 'the range'
of the function.
definition 1.4.
(i) Te domain of a function R is the set { d: there is an e such that
⟨d, e⟩∈R }.
(ii) Te range of a function R is the set {e: there is a d such that ⟨d, e⟩∈
R }.
(iii) R is a function into the set M if and only if all elements of the range
of the function are in M.
Te elements of the domain serve as 'inputs' or 'arguments' of the
function; the elements of the range are 'outputs' or 'values'.
In the above example the set containing France, Italy, England and the
United Kingdom is the domain of the function, while the set with Paris,
Rome and London as its elements is the range. According to (iii) of the
above deﬁnition, the function is a function into the set of all European
cities, for instance.
definition 1.5. If d is in the domain of a function R one writes R(d) for
the unique object e such that ⟨d, e⟩is in R.
Te relation containing all pairs ⟨d, e⟩such that d has e as a biological
mother is a function: if d has e as biological mother and d has f as
biological mother, then e and f must be identical. Its domain is the set
of all people and animals, its range the set of all female animals with
oﬀspring.
In contrast, the relation containing all pairs ⟨d, e⟩such that d is the
biological mother of e is not a function: my brother and I have the same
biological mother, yet we are not identical.
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
15
1.4 non-binary relations
Te relations I have considered so far are binary; they contain only ordered
pairs. Expressions such as 'd loves e' express binary relations; the expres-
sion 'd loves e' expresses the relation that contains exactly those ordered
pairs ⟨d, e⟩such that d loves e. In contrast, the expression 'd prefers e
over f ' expresses a ternary (3-place) relation rather than a binary one. In
order to deal with ternary relations, ordered triples (or 'triples' for short)
are used. Triples are very much like ordered pairs.
A triple ⟨d, e, f ⟩is identical with a triple ⟨g, h, i⟩if and only if they
agree in the ﬁrst, second and third component, respectively, that is, if and
only if d = g, e = h and f = i.7
Ternary relations are sets containing only triples.
Besides ordered pairs and triples there are also quadruples and so on.
Tis can be generalised to even higher 'arities' n: an n-tuple ⟨d1, d2, . . . , dn⟩
has n components. An n-tuple ⟨d1, d2, . . . , dn⟩and an n-tuple ⟨e1, e2, . . . , en⟩
are identical if and only if d1 = e1 and d2 = e2 and so on up to dn = en.
Now n-tuples allow one to deal with n-place relations:
An n-place relation is a set containing only n-tuples. An n-place rela-
tion is called a relation of arity n.
For instance, there is the relation that contains exactly those 5-tuples
⟨d, e, f , g, h⟩such that d killed e with f in g with the help of h. Tis is
a 5-ary relation, which, for instance, contains among others the 5-tuple
⟨Brutus, Caesar, Brutus' knife, Rome, Cassius⟩.
I also allow 1-tuples as a special case. I stipulate that ⟨d⟩is simply
d itself. Tus a 1-place or unary relation is just some set.
7 As has been remarked in footnote 6 above, one can deﬁne ordered pairs as certain sets.
Similarly one can deﬁne the triple ⟨d, e, f ⟩using ordered pairs as ⟨⟨d, e⟩, f ⟩. So in the
end only sets are needed.
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
16
1.5 arguments, validity and contradiction
In logic usually sentences are taken as the objects that can be true or false.
Of course not every sentence of English can be true or false: a command
or a question is neither true nor false.
Sentences that are true or false are called declarative sentences. In what
follows I will focus exclusively on declarative sentences. I will ofen drop
the restriction 'declarative', because I will be concerned exclusively with
declarative sentences.
Whether a sentence is true or not may depend on who is uttering the
sentence, who is addressed, where it is said and various other factors. Te
sentence 'I am Volker Halbach' is true when I say it, but the same sentence
is false when uttered by you, the reader. 'It is raining' might be true in
Oxford but false in Los Angeles at the same time. So the truth of the
sentence depends partly on the context, that is, on the speaker, the place,
the addressee and so on. Dealing with contexts is tricky and logicians
have developed theories about how the context relates to the truth of a
sentence. I will try to use examples where the context of utterance does
not really matter, but for some examples the context will matter. Even in
those cases, what I am going to say will be correct as long as the context
does not shif during the discussion of an example. Tis will guarantee
that a true sentence cannot become false from one line to the other.
We ofen draw conclusions from certain sentences, and a sentence
is ofen said to follow from or to be a consequence of certain sentences.
Words like 'therefore', 'so', or 'hence', or phrases such as 'it follows that'
ofen mark a sentence that is supposed to follow from one or more sen-
tences. Te sentences from which one concludes a sentence are called
'premisses', the sentence, which is claimed to be supported by the pre-
misses is called 'conclusion'. Together premisses and conclusion form an
argument.
definition 1.6. An argument consists of a set of declarative sentences (the
premisses) and a declarative sentence (the conclusion) marked as the con-
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
17
cluded sentence.
Tere is no restriction on how the conclusion is marked as such.
Expressions like 'therefore' or 'so' may be used for marking the conclusion.
Ofen the conclusion is found at the end of an argument. Te conclusion,
however, may also be stated at the beginning of an argument and the
premisses, preceded by phrases such as 'this follows from' or 'for', follow
the conclusion.
In an argument there is always exactly one conclusion, but there may
be arbitrarily many premisses; there may be even only one premiss or no
premiss at all.
Te following is an argument with the single premiss 'Zeno is a tor-
toise' and the conclusion 'Zeno is toothless'.
Zeno is a tortoise. Terefore Zeno is toothless.
A biologist will probably accept that the conclusion follows from the pre-
miss 'Zeno is a tortoise', as he will know that tortoises do not have teeth.
Tat the conclusion follows from the premiss depends on a certain biolog-
ical fact. Tis assumption can be made explicit by adding the premiss that
tortoises are toothless. Tis will make the argument convincing not only
to biologists but also to people with no biological knowledge at all. Te
biologist, if prompted for a more explicit version of the argument, would
probably restate the argument with the additional premiss on which he
may have implicity relied all along:
Zeno is a tortoise. All tortoises are toothless. Terefore Zeno
is toothless.
Now no special knowledge of the subject matter is required to see that
the conclusion follows from the premisses. Te conclusion follows from
the two premisses purely formally or logically: the conclusion is a conse-
quence of the premisses independently of any subject-speciﬁc assump-
tions. It does not matter who Zeno is, what tortoises are, what being
toothless is, or which objects the argument is thought to be about.
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
18
In this argument the conclusion follows from the premisses indepen-
dently of what the premisses and conclusion are about. Whatever they
are taken to be about, in whatever way the subject-speciﬁc terms are
(re-)interpreted, the conclusion will be true if the premisses are. Argu-
ments of this kind are called 'logically valid' or 'formally valid'. Tus
in a logically valid argument the conclusion follows from the premisses
independently of the subject matter.
characterisation 1.7 (logical validity). An argument is logically
valid if and only if there is no interpretation under which the premisses are
all true and the conclusion is false.8
In particular, if all terms are interpreted in the standard way, then,
according to Characterisation 1.7, the conclusion is true if the premisses
are true. Tus the conclusion of a logically valid argument is true if the
premisses are true.
Te notion of an interpretation employed in Characterisation 1.7
needs some clariﬁcation: An interpretation will assign meanings to the
subject-speciﬁc terms such as 'Zeno', 'tortoise', and 'iridium'. It will also
determine which objects the argument is taken to be about. Te logical
terms, that is, the subject-independent terms, such as 'all' are not subject
to any (re-)interpretation. Tese logical terms belong to the form of the
argument and they are not aﬀected by interpretations.
In later chapters I shall provide an exact deﬁnition of interpretations
or 'structures', as I shall call them in the case of formal languages. Tese
formal accounts of logical validity can also be seen as attempts to elucidate
the notion of logical validity in natural languages such as English at least
for those parts of English that can be translated into the formal languages.
According to the above characterisation of logical validity, the mean-
ings of the subject-speciﬁc terms do not matter for the logical validity
of the argument. Tus, one can replace these terms by other terms and
8 A precise and informative deﬁnition of the logical validity of an argument is not so easy
to give. Sainsbury (2001, chapter 1) provides an critical introductory discussion.
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
19
thereby obtain a logically valid argument again. Te following argument
has been obtained from the argument about Zeno by such a substitution
of nonlogical, that is, subject-speciﬁc terms:
Iridium is a metal. All metals are chemical elements. Tere-
fore iridium is a chemical element.
Both the argument about Zeno and the argument about iridium have the
same pattern; they share the same form. Te conclusion follows from the
premisses solely in virtue of the form of the argument. Tis is the reason
for calling such arguments 'formally valid'.
Te notion of logical or formal validity is occasionally contrasted with
other, less strict notions of validity, under which more arguments come
out as valid. Some arguments in which the truth of the premisses does
guarantee the truth of the conclusion are not formally valid. Here is an
example:
Hagen is a bachelor. Terefore Hagen is not married.
In this argument the conclusion is bound to be true if the premiss is true,
but it is not logically or formally valid, that is, valid in virtue of its form.
'Hagen is not married' follows from 'Hagen is a bachelor' in virtue of the
meaning of the word 'bachelor', which is subject-speciﬁc.
Also, arguments in which the premisses do not guarantee the truth of
the conclusion are ofen called valid. Here is an example:
All emeralds observed so far have been green. Terefore all
emeralds are green.
Te premiss may support the conclusion in some sense, but it does not
guarantee the truth of the conclusion. Such arguments as the argument
above are said to be inductively valid. In logically valid arguments, in
contrast, the truth of the premisses guarantees the truth of the conclusion.
Logically valid arguments, are also called 'deductively valid'.
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
20
In this book I will focus on logical validity and not consider other, less
stringent kinds of validity. Terefore, I shall ofen drop the speciﬁcation
'logical' or 'formal': validity will always be understood as logical validity.
Tere are good reasons to focus on logically valid arguments. Philoso-
phers ofen suppress premisses in arguments because they think that
these premisses are too obvious to state. However, one philosopher's
obvious premiss can be another philosopher's very contentious premiss.
Trying to make an argument logically valid forces one to make all hidden
assumptions explicit. Tis may unearth premisses that are not obvious
and uncontroversial at all. Also, there is usually not a unique way to
add premisses to render an argument logically valid, and it may remain
controversial which premisses were implicitly assumed by the original
author, or whether he relied on any implicit premisses at all. At any rate,
if an argument is formally valid, then the validity does not rely on any
potentially controversial subject-speciﬁc assumptions: all the assump-
tions needed to establish the conclusion will be explicitly laid out for
inspection.
Tis is not to say that logical validity is always obvious: all required
premisses may have been made explicit, but it might not be obvious that
the conclusion follows from the premisses, that is, one might not be able
to see easily that the argument is logically valid. Characterisation 1.7 of
logical validity does not demand an obvious connection between the
premisses and the conclusion that is easy to grasp. Almost all of the
examples of logically valid arguments considered in this book are toy
examples where it will be fairly obvious that they are logically valid, but
showing that an argument is logically valid can be extremely diﬃcult.
Mathematicians, for instance, are mainly concerned with establishing
that certain sentences (theorems) follow from certain premisses (axioms),
that is, with showing that certain arguments are logically valid. Of course
one can try to break up valid arguments into chains of short and obvious
steps. In Chapter 6 this task is taken up and a formal notion of proof is
developed.
A valid argument need not have a true conclusion. In the following
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
21
example the non-logical terms of the logically valid argument about Zeno
(or iridium) have been replaced in such a way as to make the conclusion
false:
Water is a metal. All metals are chemical elements. Terefore
water is a chemical element.
Although the conclusion 'Water is a chemical element' is false, the argu-
ment is logically valid: the conclusion still follows from the premisses.
In a logically valid argument the conclusion may be false as long as at
least one premiss is false. In this case 'Water is a metal' is false. Terefore,
one cannot refute the validity of an argument by merely pointing out a
false conclusion. If the conclusion of an argument is false, then either at
least one of the premisses is false or the argument is not logically valid
(or both).
So far I have used only one argument form (argument pattern) in my
examples. Here is an argument of a diﬀerent pattern:
Either CO2-emissions are cut or there will be more ﬂoods. It
is not the case that CO2-emissions are cut. Terefore there
will be more ﬂoods.
Te argument is logically valid according to Characterisation 1.7 of logi-
cally valid arguments since the validity of the argument does not depend
on the subject-speciﬁc terms such as 'CO2-emissions' and 'ﬂoods'. Te
validity of the argument depends on the logical terms 'either ... or ...'
and 'it is not the case that ...'.
In the argument about Zeno I could replace various terms, but not
complete sentences. In the present example one can replace entire sen-
tences. In this case the argument will still be valid afer replacing the
sentences 'CO2-emissions are cut' and 'Tere will be more ﬂoods' with
some other sentences. Te pattern of the valid argument is a pattern of
whole sentences. Valid arguments of this kind are said to be proposi-
tionally valid. Tus an argument is propositionally valid if and only if
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
22
there is no (re-)interpretation of the sentences in the argument such that
all premisses are true and yet the conclusion is false. Tese patterns of
propositionally valid arguments are studied in sentential or propositional
logic. Propositional validity will be treated in Chapters 2 and 3.
Te argument about Zeno can be adequately analysed in predicate
logic only, and not in propositional logic. Predicate logic is based on
propositional logic; from the technical point of view it is a reﬁnement of
propositional logic. Tus I shall start with propositional logic and then
move on to predicate logic.
Te notion of consistency is closely related to the notion of validity.
characterisation 1.8 (consistency). A set of sentences is consistent if
and only if there is a least one interpretation under which all sentences of
the set are true.
Te negation of a sentence is obtained by writing 'It is not the case
that' in front of the sentence (in English there are various stylistically
more elegant ways to express negation). A sentence is false if and only if
its negation is true.
For a valid argument there is no interpretation under which the pre-
misses are all true and the conclusion is false. Tus, for a valid argument
there is no interpretation under which the premisses are all true and the
negation of the conclusion is also true. Tus, if an argument is valid, the
set obtained by adding the negation of the conclusion to the premisses is
inconsistent; and if the set obtained by adding the negation of the conclu-
sion to the premisses is inconsistent, then there is no interpretation under
which all sentences of that set are true, and, consequently, there is no
interpretation under which all the premisses are true and the conclusion
is false. Hence one can deﬁne validity in terms of consistency:
An argument is valid if and only if the set obtained by adding
the negation of the conclusion to the premisses is inconsis-
tent.
I have not imposed any restrictions on the number of premisses in
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
23
an argument. In particular, there may be no premisses at all. Arguments
with no premisses may still be logically valid. Te following argument
does not have any premisses but only a conclusion:
All metaphysicians are metaphysicians.
Te sentence is true, and it is true for any interpretation of 'metaphysician',
which is the only non-logical, subject-speciﬁc term in the sentence. Tere-
fore, there is no interpretation under which all premisses are true (there
is none) and the conclusion is false. Terefore, the argument is logically
valid. Te conclusion of a logically valid argument with no premisses is
also called 'logically true' or 'logically valid'.
characterisation 1.9 (logical truth). A sentence is logically true if
and only if it is true under any interpretation.
Tere are also sentences that cannot be made true by any interpreta-
tion. Tese sentences are called 'logically false'. Tey are called 'contra-
dictions'.
characterisation 1.10 (contradiction). A sentence is a contradiction
if and only if it is false under any interpretation.
If a sentence A follows logically from a sentence B and B follows
logically from A, that is, if the argument with A as its only premiss and
B as conclusion, and the argument with B as premiss and A as conclusion,
are logically valid, then the sentences A and B are logically equivalent.
According to Characterisation 1.7, the argument with A as premiss and B
as conclusion and the argument with B as premiss and A as conclusion
are both logically valid if and only if A and B are true under the same
interpretations:
characterisation 1.11 (logical equivalence). Sentences are logically
equivalent if and only if they are true under exactly the same interpreta-
tions.
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
24
1.6 syntax, semantics and pragmatics
In the following chapters I will examine formal languages. Tese lan-
guages are in many respects much less complicated than natural languages
such as English or German. Tey are intended to mirror certain prop-
erties of natural languages. Some philosophers conceive of these formal
languages as models for natural languages.
Usually, in analysing either natural or formal languages one distin-
guishes three aspects of a language: syntax, semantics and pragmatics.9
In order to use a language competently, one must master all three aspects
of it.
Syntax is concerned with the expressions of a language bare of their
meanings. In the syntax of a language it is speciﬁed what the words or
sentences of the language are. In general, the grammar of a language
belongs to the syntax of that language, and ofen syntax is identiﬁed with
grammar. In order to use the language competently, one must know the
grammar of the language. In particular, one must know how to form
sentences in the language.
Semanticssemantics may be described as the study of the meanings
of the expressions of a language. Clearly, to use a language one must not
only know what the words and the sentences of the language are; one
must also know what they mean.
Te expression 'Im Mondschein hockt auf den Gräbern eine wild
gespenstische Gestalt' is a well-formed German declarative sentence. In
a syntactic analysis of that sentence one may remark that 'hockt' is a verb
in present tense, and so on. All this is merely syntactic information; it
does not tell one anything about the meaning of that sentence. In order
to understand the sentence, you need information about meaning. For
instance, it is a semantic fact of German that 'im Mondschein' means 'in
the moonlight'.
9 Te trichotomy was introduced by Morris (1938).
© Volker Halbach
2008/2009

1 Sets, Relations, and Arguments
25
Te third component, pragmatics, will not be studied here. Pragmatics
is, roughly speaking, the study of language in use. Assume John calls
Mary and asks her whether she wants to come along to the cinema. She
replies, 'I am ill.' Obviously, John should not expect Mary to come along,
but the sentence 'I am ill' does not mean the same thing as 'I don't want
to come along to the cinema'; the former sentence only says something
about Mary's health. But uttered by Mary in this particular situation, the
sentence 'I am ill', spoken by Mary, conveys the information that she will
not join John. Tus, John needs pragmatics in order to understand that
Mary is not going to come along. Pure semantics would not tell him.
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
In this section I shall introduce the language of propositional logic. All
other formal languages that will be discussed in this manual are based on
the language of propositional logic.
Before introducing the syntax of this language I will brieﬂy outline a
method for talking eﬃciently about the expressions of a language and for
describing the syntax of a language. Te method is by no means speciﬁc
to the language of propositional logic.
2.1 quotation
By enclosing an expression in quotation marks one can talk about that
expression. Using quotation marks one can say, for instance, that 'A' is
the ﬁrst letter of the alphabet and that 'Gli enigmi sono tre' is an Italian
sentence. Te quotation of an expression is that very expression enclosed
in quotation marks.1
Quotation marks allow one to designate single expressions. Describ-
ing the syntax of a language usually makes it necessary to talk about a
large or inﬁnite number of expressions. For instance, one would like to
be able to state that one can construct new sentences in English by com-
bining sentences using 'and' (ignoring capitalisation and punctuation).
1 Cappelen and LePore (Spring 2007) provide an overview of the intricacies of quotation
and of proposed theories. A classical text on quotation is Quine (1940).
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
27
Logicians would express that general claim by saying the following:
(and) If ϕ and ψ are English sentences then 'ϕ and ψ' is an
English sentence.
'It is raining' is an English sentence. If one takes 'It is raining' as both
ϕ and ψ in the above rule, then the rule says that 'It is raining and it is
raining' is also an English sentence (again we ignore the absence of the
full stop and the missing capitalisation). One can then use 'It is raining
and it is raining' as ϕ again and 'It is raining' as ψ to conclude from the
rule that also 'It is raining and it is raining and it is raining' is an English
sentence. In this way one can construct longer and longer sentences and
there is no limit to the iterations.
I think that (and) is fairly straightforward and should be easy to
understand. Tere is, however, something puzzling about it as well: the
part of (and) claiming that 'ϕ and ψ' is an English sentence is decidedly
not about the expression in quotation marks. Te letters ϕ and ψ are
Greek letters, and the expression with 'ϕ' as ﬁrst symbol, followed by a
space, followed by 'and' and another space, followed by 'ψ', is deﬁnitely
not an English sentence. Only once 'ϕ' and 'ψ' are replaced by English
sentences does 'ϕ and ψ' become an English sentence.
Te Greek letters used in this way are metavariables or metalinguistic
variables.
Tus, the above rule may also be expressed in the following way:
An English sentence followed by 'and' (in spaces) and another
or the same English sentence is also an English sentence.
Tis way of rephrasing (and) does not rely on quotation marks but on
talking about expressions following one another. Tis method is perhaps
safer than using (and) with its quotation marks and metavariables, but it
is also more cumbersome when applied to intricate grammatical rules.
Tus, I will present deﬁnitions in the style of (and) rather than talking
about expressions following one another.
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
28
Logicians hardly ever use the expressions of formal languages in
the way they use the expressions of their mother tongue, but they ofen
talk and write about the expressions of these formal languages. Since
the expressions of the formal languages they are concerned with diﬀer
from expressions of English, logicians usually drop the quotation marks.
Instead of saying
'(P →(Q∧R))' is a sentence of the language of propositional
logic
they say,
(P →(Q ∧R)) is a sentence of the language of propositional
logic.
I will follow this convention and usually drop quotation marks around
the expressions of formal languages in this manual. Tis also applies to
expressions containing metavariables.
2.2 the syntax of the language of propositional logic
Now I can describe the syntax of the language L1 of propositional logic.
definition 2.1 (sentence letters). P, Q, R, P1, Q1, R1, P2, Q2, R2, P3,
Q3, R3, and so on are sentence letters.
Using metavariables I will deﬁne the notion of a sentence of the lan-
guage L1 of propositional logic.
definition 2.2 (sentence of L1).
(i) All sentence letters are sentences of L1.
(ii) If ϕ and ψ are sentences of L1, then ¬ϕ, (ϕ ∧ψ), (ϕ ∨ψ), (ϕ →ψ)
and (ϕ ↔ψ) are sentences of L1.
(iii) Nothing else is a sentence of L1.
Given what I have said about metavariables, (ii) implies that '(ϕ ∧ψ)'
becomes a sentence of the language of propositional logic when the Greek
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
29
letters 'ϕ' and 'ψ' have been replaced by sentences of the language of
propositional logic. Te Greek letters 'ϕ' and 'ψ' themselves are not
expressions of the language L1.
As I explained on page 27, I could have formulated part (ii) of Deﬁni-
tion 2.2 without using the metavariables 'ϕ' and 'ψ' by expressing (ii) in
the following way:
Te negation symbol followed by a sentence of L1 is again a
sentence of L1. Te symbol '(' followed by a sentence of L1,
followed by the symbol '∨' (or '∧', '→', '↔'), followed by a
sentence (not necessarily distinct from the ﬁrst one), followed
by the symbol ')', is a sentence of L1.
I hope that (ii) is not only shorter but also easier to grasp.
Te last clause in Deﬁnition 2.2 says that only expressions one can
obtain by using clauses (i) and (ii) are sentences. Very ofen this last clause
is omitted and the clauses (i) and (ii) are implicitly taken to be the only
means of arriving at sentences. At various points in this manual I will
provide deﬁnitions that are similar to Deﬁnition 2.2. In those cases I will
drop the analogues of clause (iii) for the sake of simplicity.
Logicians also say 'the negation of ϕ' rather than '¬ϕ'. In this termi-
nology, ¬ϕ is the negation of ϕ, and similarly (ϕ ∧ψ) is the conjunction of
ϕ and ψ, and ϕ ∨ψ is the disjunction of ϕ and ψ. Te sentence ¬(P →Q),
for instance, is the negation of (P →Q).
example 2.3. Te following expressions are sentences of the language L1:
((P →P) ∧Q456),
¬(R ∨(P ∨(P3 ∨¬Q4))),
((¬P ∧Q4) →P).
In the next example I show how to prove that the last sentence above
is indeed a sentence of L1.
example 2.4. By Deﬁnition 2.2(i), P is a sentence of L1. Tus, by (ii),
¬P is also a sentence of L1. By (i) again, Q4 is a sentence of L1. By (ii) and
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
30
by what has been said so far, (¬P ∧Q4) is a sentence, and by (ii) again and
by what has been said so far, ((¬P ∧Q4) →P) is also a sentence of L1.
Te symbols ¬, ∧, ∨, →, ↔are called 'connectives'. Tey roughly cor-
respond to the English expressions 'not', 'and', 'or', 'if ..., then ...' and 'if
and only if', respectively.
name
in English
symbol
alternative
used here
symbols
conjunction
and
∧
., &
disjunction
or
∨
+, v
negation
it is not the
¬
-, ∼
case that
arrow
if ... then
→
⊃, ⇒
(material
implication,
conditional)
double arrow,
if and only if
↔
≡, ⇔
(biconditional
material
equivalence)
Te names in brackets and the symbols in the rightmost column are used
by some other authors; they will not be used here.
Te expressions in the 'in English' column indicate how the connec-
tives are commonly read, rather than their precise meanings.
2.3 rules for dropping brackets
A sentence with many brackets can be confusing. For convenience I shall
employ certain rules for dropping brackets. Tese rules are not revisions
of the deﬁnition of a sentence and they do not form part of the oﬃcial
syntax of the language L1 of propositional logic. Tese rules are mere
conventions that allow one to write down abbreviations of sentences
instead of the sentences themselves in their oﬃcial form.
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
31
Most logicians employ at least some of these rules. For instance, hardly
anyone writes (P ∧Q) instead of P ∧Q. Tis, then, is the ﬁrst rule:
bracketing convention 1. Te outer brackets may be omitted from a
sentence that is not part of another sentence.
For instance, one may write P →(Q ∨P) instead of (P →(Q ∨P)).
However, this convention does not allow one to drop any brackets from
¬(P →(Q ∨P)), because the sentence (P →(Q ∨P)) is written here as
a part of the sentence ¬(P →(Q ∨P)).
Here a warning is in order: Te syntactic deﬁnitions in Section 2.2
apply to L2-sentences but not to their abbreviations. For instance, I have
deﬁned the negation of the sentence ϕ as ¬ϕ. Now one might think that
¬P ∧Q is the negation of P ∧Q. Tis is not the case, however. P ∧Q is
short for (P ∧Q) according to Convention 1; and the negation of (P ∧Q)
is ¬(P ∧Q) and not ¬P ∧Q, which is short for (¬P ∧Q).
bracketing convention 2. Te inner set of brackets may be omitted
from a sentence of the form ((ϕ∧ψ)∧χ). An analogous convention applies
to ∨.
One may abbreviate ((P ∧Q2) ∧P2) as (P ∧Q2) ∧P2 by Conven-
tion 1, and then one may also drop the remaining pair of brackets by
Convention 2; so P ∧Q2 ∧P2 is short for ((P ∧Q2) ∧P2).
((ϕ ∧ψ) ∧χ) may be part of a larger sentence. So, using Conventions
1 and 2, one can abbreviate the sentence
((((P2 ∧P3) ∧Q) ∧R) →((P2 ∨¬P3) ∨Q))
with the following expression:
(P2 ∧P3 ∧Q ∧R) →(P2 ∨¬P3 ∨Q).
In arithmetic one may write 3 × 5 + 4 instead of (3 × 5) + 4, because
the symbol × for multiplication binds more strongly than the symbol +
for addition. Analogously, there are conventions for ordering logical
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
32
operations: ∧and ∨bind more strongly than →or ↔. And just as in the
case of arithmetic, this yields further conventions for dropping brackets.
For instance, the sentence P ↔Q ∧R is in abbreviated form. In order
to decide whether the sentence is an abbreviation of ((P ↔Q) ∧R) or
of (P ↔(Q ∧R)), imagine that the connectives ↔and ∧'compete' for
the sentence letter Q. Since ∧binds more strongly than ↔, ∧gains the
upper hand and (P ↔(Q ∧R)) is the correct reading.
In more abstract terms, this rule for dropping brackets can be ex-
pressed as follows:
bracketing convention 3. Assume ϕ, ψ, and χ are sentences of L1, ●is
either ∧or ∨, and ○is either →or ↔. Ten, if (ϕ○(ψ●χ)) or ((ϕ●ψ)○χ)
occurs as part of the sentence that is to be abbreviated, the inner set of
brackets may be omitted.
Afer dropping the outer brackets from ((P ∧Q) →R) according
to Convention 1, one may shorten the sentence further to P ∧Q →R
since ∧binds more strongly than →. Similarly ¬(P →((Q ∧P3) ∨R))
may be abbreviated as ¬(P →(Q ∧P3) ∨R). In (¬(P ∨Q) ↔Q)
only the outer brackets can be omitted in virtue of Convention 1, so
that ¬(P ∨Q) ↔Q is obtained as an abbreviation. One cannot use
Convention 3 to obtain ¬P ∨Q ↔Q, because the original sentence does
not contain ((P ∨Q) ↔Q) as a part. Intuitively, in ¬P ∨Q ↔Q the
negation symbol ¬ refers only to P and not to the sentence (P ∨Q) as it
does in the original sentence.
Tere is no deeper reason for the choice of these three conventions.
It is never incorrect to use the unabbreviated sentences of L1 with all
their brackets rather than their abbreviations. In situations where the
application of the bracketing conventions can give rise to confusions,
it is better not to use them. Also it is perfectly legitimate to apply the
rules selectively. For instance, one may apply only Convention 1, but not
Convention 3, and write (P ∧Q) →R for ((P ∧Q) →R). I will apply
these conventions extensively.
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
33
2.4 the semantics of propositional logic
In Section 1.5 I gave a characterisation of the logical validity of arguments
in English. In this section I will deﬁne validity for arguments in the
language L1 of propositional logic. Te informal Characterisation 1.7
of validity for English arguments will be adapted to the language L1 of
propositional logic and thereby be transformed into a precise deﬁnition.
In order to deﬁne logical validity for the language L1, the notion of
an interpretation for the language L1 needs to be made precise. First, I
need to say which expressions can be interpreted in diﬀerent ways and
which are always interpreted in the same way. Te connectives are logical
symbols, the brackets merely auxiliary symbols; logical and auxiliary
symbols cannot be re-interpreted (insofar as one can speak of auxiliary
symbols' being interpreted at all). Te sentence letters are the only non-
logical symbols of L1; they can be interpreted in diﬀerent ways.
Te interpretations of the sentence letters will be provided by so-called
L1-structures. Tese L1-structures need only provide enough information
to determine whether a sentence is true or false. Now, under which
conditions is the sentence P ∧Q true? If the connective ∧functions
like 'and' in English, then both P and Q must be true for P ∧Q to be
true; otherwise P ∧Q will be false. Similarly, since ¬ works like 'not', the
sentence ¬R is true if and only if R is false. As ∨corresponds to 'or', the
sentence P ∨Q is true if and only if P or Q is true (or both are true).
Te arrow →corresponds roughly to the English 'if ... then', but the
latter has a rather complicated semantics. Te L1-sentence P →Q is false
if and only if P is true and Q is false; otherwise it is true. Te phrase 'if ...
then', which corresponds to the arrow, does not always behave like this.
How the arrow →is related to 'if ... then' will be discussed in Section 3.1.
Generally, in L1, the truth or falsity of a sentence of L1 depends only
on the truth or falsity of the sentence letters occurring in the sentence;
any further information is not relevant. Terefore, L1-structures need
only determine the truth and falsity of all sentence letters.
Instead of saying that a sentence is true, logicians say that the sentence
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
34
has the truth-value True. Tis sounds like a philosophically profound
move since new objects are required: truth-values. However, truth-values
are hardly mysterious objects. Some more mathematically minded logi-
cians use the number 1 for the truth-value True and 0 for the truth-value
False. In the end it matters only that True and False are distinct. It is
possible, although not very customary and technically less convenient,
to develop the semantics of L1 without truth-values by saying that a sen-
tence is true (or false) instead of saying that it has the truth-value True (or
False). I shall use the letter 'T' as a name for the truth-value True and 'F'
for the truth-value False.
Tus an L1-structure provides interpretations of all sentence letters
by assigning to every sentence letter exactly one truth-value, T or F.
definition 2.5 (L1-structure). An L1-structure is an assignment of ex-
actly one truth-value (T or F) to every sentence letter of the language L1.2
One may think of an L1-structure as an inﬁnite list that provides a
value T or F for every sentence letter. Te beginning of such a list could
look like this:
P
Q
R
P1
Q1
R1
P2
Q2
R2
T
F
F
F
T
F
T
T
F
⋯
Starting from the truth-values assigned to the sentence letters by an
L1-structure A, one can work out the truth-values for sentences con-
taining connectives in the following way. Te shortest sentences are the
sentence letters; their respective truth-values are ﬁxed directly by the
L1-structure A. For instance, P could be assigned the truth-value T and
R could be assigned the same truth-value. In this case P∧R would receive
the truth-value T, too. If P1 is given the truth-value F by A, the sentence
P1 ∨(P ∧R) gets the truth-value T, because P ∧R is true; and ψ's being
true is suﬃcient to make a sentence ϕ ∨ψ true.
2 In more mathematical terms, an L1-structure is a function into the set {T, F} with the
set of all sentence letters of L1 as its domain.
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
35
Tus, the truth-values of the shortest sentences, that is, of the sentence
letters, are ﬁxed by the L1-structure A, and then the truth-values for longer
sentences are determined successively by the truth-values of the sentences
they are made up from.
I will write ∣ϕ∣A for the truth-value of ϕ that is obtained on the basis
of A; it is determined by A in the following way:
definition 2.6 (truth in an L1-structure). Let A be some L1-structure.
Ten ∣. . . ∣A assigns to every sentence of L1 either T or F in the following
way:3
(i) If ϕ is a sentence letter, ∣ϕ∣A is the truth-value assigned to ϕ by the
L1-structure A.
(ii) ∣¬ϕ∣A = T if and only if ∣ϕ∣A = F.
(iii) ∣ϕ ∧ψ∣A = T if and only if ∣ϕ∣A = T and ∣ψ∣A = T.
(iv) ∣ϕ ∨ψ∣A = T if and only if ∣ϕ∣A = T or ∣ψ∣A = T.
(v) ∣ϕ →ψ∣A = T if and only if ∣ϕ∣A = F or ∣ψ∣A = T.
(vi) ∣ϕ ↔ψ∣A = T if and only if ∣ϕ∣A = ∣ψ∣A.
Instead of writing ∣ϕ∣A = T, I will sometimes write that ϕ is true in A
or that T is the truth-value of ϕ in A.
Te deﬁnition of ∣. . . ∣A does not say explicitly when a sentence has the
truth-value F in A. Nonetheless, extra clauses for falsity are not required,
since a sentence has the truth-value F (in A) if and only if it does not have
the truth-value T. In particular, a sentence letter has the truth-value F if
and only if it is not true in A. Similarly, for negation the following falsity
clause follows from Deﬁnition 2.6:
∣¬ϕ∣A = F if and only if ∣ϕ∣A = T.
Deﬁnition 2.6 also implies the following claim for conjunction (and simi-
larly for the other connectives):
3 More formally, ∣. . . ∣A is a function with the set of all L1-sentences as its domain into
the set {T, F}. It properly extends the L1-structure A, that is, it contains all the ordered
pairs that the function A contains and more besides them.
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
36
∣ϕ ∧ψ∣A = F if and only if ∣ϕ∣A = F or ∣ψ∣A = F.
Tus, Deﬁnition 2.6 also says whether a sentence is false in a given struc-
ture). For example, consider the sentence (¬(P →Q) →(P ∧Q)) and a
structure B that assigns T to the sentence letter P and F to the sentence
letter Q. I want to determine the truth-value ∣¬(P →Q) →(P ∧Q)∣B.
Using the various clauses of Deﬁnition 2.6, one can calculate that its truth-
value by calculating the truth-values of the sentences that were used in
building it up according to the syntactic rules (Deﬁnition 2.2) for forming
L1-sentences. Here is how:
1. ∣P∣B = T by assumption and Deﬁnition 2.6(i)
2. ∣Q∣B = F by assumption and Deﬁnition 2.6(i)
3. ∣P →Q∣B = F by 1, 2, and Deﬁnition 2.6(v)
4. ∣¬(P →Q)∣B = T by 3 and Deﬁnition 2.6(ii)
5. ∣P ∧Q∣B = F by 1, 2, and Deﬁnition 2.6(iii)
6. ∣¬(P →Q) →(P ∧Q)∣B = F by 4, 5, and Deﬁnition 2.6(v)
Terefore, ¬(P →Q) →(P ∧Q) is not true in B.
Te clauses (ii)-(vi) of Deﬁnition 2.6 can be neatly expressed by truth
tables. According to (ii), for instance, a sentence ¬ϕ has truth-value T if
and only if ϕ has truth-value F. Tus if ∣ϕ∣A = F, we have ∣¬ϕ∣A = T; and
if ∣ϕ∣A = T, we have ∣¬ϕ∣A = F. Tis is expressed in the following table:
ϕ
¬ϕ
T
F
F
T
Te clauses (iii)-(vi) correspond to the following tables respectively:
ϕ
ψ
(ϕ ∧ψ)
T
T
T
T
F
F
F
T
F
F
F
F
ϕ
ψ
(ϕ ∨ψ)
T
T
T
T
F
T
F
T
T
F
F
F
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
37
ϕ
ψ
(ϕ →ψ)
T
T
T
T
F
F
F
T
T
F
F
T
ϕ
ψ
(ϕ ↔ψ)
T
T
T
T
F
F
F
T
F
F
F
T
Truth tables are also useful for calculating the truth-values of sen-
tences with more than one connective. I will use the same example as
above to show how this can be done. Te ﬁrst step is to write below each
sentence letter the truth-value assigned to it by the L1-structure A:
P
Q
¬ (P →Q) →(P ∧Q)
T
F
T
F
T
F
Te next step is to calculate the truth-values of sentences directly built up
from sentence letters according to the truth tables (in this case the tables
for →and ∧are needed):
P
Q
¬ (P →Q) →(P ∧Q)
T
F
T F F
T F F
Ten one can go on to determine the truth-values for more and more
complex sentences:
P
Q
¬ (P →Q) →(P ∧Q)
T
F
T T F F
T F F
Finally, one will obtain the truth-value for the entire sentence (here high-
lighted in using boldface):
P
Q
¬ (P →Q) →(P ∧Q)
T
F
T T F F F T F F
One can also use a (multi-line) truth table to work out the truth-values
of a given sentence for all L1-structures.
In a truth table one can also work out the truth-value of the sentence
¬(P →Q) →(P ∧Q) in any given L1-structure. I employ again the
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
38
sentence ¬(P →Q) →(P ∧Q) as an example; it contains two sentence
letters. In a given structure, P can be true or false, and Q can be true or
false. Tus there are four possibilities: in any given L1-structure, either
both P and Q are true, or P is true and Q is false, or P is false and Q is true,
or both sentence letters are false. Tese four possibilities are captured in
the two lefmost columns of the truth table below. Now one can calculate
the truth-values of the sentence for all four possibilities, and, thereby, for
all L1-structures:
P
Q
¬ (P →Q) →(P ∧Q)
T
T
F T T T T T T T
T
F
T T F F F T F F
F
T
F F T T T F F T
F
F
F F T F T F F F
Again, the column with the truth-value of the entire sentence is in boldface
letters. I will call this column the main column.
Clearly, if there are only T's in the main column of a sentence the
sentence is true in all L1-structures; if there are only F's in the main
column the sentence is false in all L1-structures. Tus one can use truth
tables to determine whether a sentence is always true, or whether it is
always false, or whether it is true in some structures and false in others.
Te notion of an L1-structure corresponds to that of an interpretation
of an English sentence in Section 1.5. In that section I also used the
notion of an English sentence being true under an interpretation; this
corresponds to the notion of an L1-sentence being true in a structure. Te
deﬁnitions of logical validity in English (Characterisation 1.7), of logical
truth in English (Characterisation 1.9), and so on, can be adapted to the
language L1 of propositional logic. Te deﬁnitions are the same for L1
as for English, except that the informal notion of an interpretation from
Section 1.5 is replaced by the technical notion of an L1-structure.
definition 2.7.
(i) A sentence ϕ of L1 is logically true if and only if ϕ is true in all L1-
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
39
structures.
(ii) A sentence ϕ of L1 is a contradiction if and only if ϕ is not true in
any L1-structure.
(iii) A sentence ϕ and a sentence ψ are logically equivalent if ϕ and ψ are
true in exactly the same L1-structures.
Logically true sentences are also called 'tautologies'.
Logical truths, contradictions and logically equivalent sentences of L1
can also be characterised in terms of truth tables. In what follows, truth
tables are always understood as full truth tables with lines for all possible
combinations of truth-values of all the sentence letters in the sentence.
theorem 2.8.
(i) A sentence of L1 is logically true (or a tautology) if and only if there
are only T's in the main column of its truth table.
(ii) A sentence is a contradiction if and only if there are only F's in the
main column of its truth table.
(iii) A sentence ϕ and a sentence ψ are logically equivalent if they agree
on the truth-values in their main columns.
One of the main purposes of developing semantics for L1 was to
deﬁne the notion of a valid argument in L1 that would be analogous to
Characterisation 1.7 of validity for arguments in English.
definition 2.9. Let Γ be a set of sentences of L1 and ϕ a sentence of L1.
Te argument with all sentences in Γ as premisses and ϕ as conclusion is
valid if and only if there is no L1-structure in which all sentences in Γ are
true and ϕ is false.
Te phrase 'Te argument with all sentences in Γ as premisses and
ϕ as conclusion is valid' will be abbreviated by 'Γ ⊧ϕ'; this is also ofen
read as 'ϕ follows from Γ' or as 'Γ (logically) implies ϕ'. Tus Γ ⊧ϕ if and
only if the following holds for all L1-structures A:
If ∣ψ∣A = T for all ψ ∈Γ, then ∣ϕ∣A = T.
Tus an L1-argument is not valid iﬀthere is a structure that makes all
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
40
premisses true and the conclusion false:
definition 2.10. An L1-structure is a counterexample to the argument
with Γ as the set of premisses and ϕ as conclusion if and only if ∣ψ∣A = T
for all ψ ∈Γ and ∣ϕ∣A = F.
Terefore, an argument in L1 is valid if and only if it does not have a coun-
terexample.
Following the pattern of the Deﬁnition 1.8 of consistency for sets of
sentences in English I will deﬁne consistency for sets of L1-sentences:
definition 2.11 (semantic consistency). A set Γ of L1-sentences is
semantically consistent if and only if there is an L1-structure A such that
∣ϕ∣A = T for all sentences ϕ of Γ. Semantic inconsistency is just the opposite
of semantic consistency: a set Γ of L1-sentences is semantically inconsistent
if and only if Γ is not consistent.4
Afer Deﬁnition 1.8 I argued that an argument is valid if and only if
the set obtained by adding the negation of the conclusion to the premisses
is inconsistent. Te argument carries over to L1:
theorem 2.12. If ϕ and all elements of Γ are L1-sentences, then the fol-
lowing obtains:
Γ ⊧ϕ if and only if the set containing all sentences in Γ and ¬ϕ
is semantically inconsistent.
Tus, for an argument with, say, two premisses ϕ and ψ and a con-
clusion χ, this means that ϕ, ψ ⊧χ if and only if the set {ϕ, ψ, ¬χ} is
semantically inconsistent. Te proof of the theorem is lef to the reader.
Logicians usually allow inﬁnite sets of premisses, but such inﬁnite
sets of premisses will not play an important role here. One can actually
prove that if a sentence ϕ of L1 follows from a set Γ of sentences, then
4 Tere is an alternative way of deﬁning the consistency of sets of L1-sentences, which is
known as 'syntactic consistency'. Although the deﬁnition looks very diﬀerent, both no-
tions of consistency coincide. Syntactic consistency will be introduced in Deﬁnition 7.5.
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
41
ϕ already follows from a ﬁnite set of sentences in Γ. Tis result is known
as the Compactness Teorem of propositional logic.
Te set Γ of premisses may also be empty. A sentence follows from the
empty set of premisses if and only if it is a tautology (that is, iﬀit is logically
true). Tis is fairly obvious; it is also a special case of Teorem 2.14 below.
If Γ has only ﬁnitely many elements, one can use truth tables to check
whether Γ ⊧ϕ. I will show how to answer the question whether Γ ⊧ϕ by
means of an example.
example 2.13. {P →¬Q, Q} ⊧¬P.
Claims like the one above may be abbreviated by dropping the curly
brackets around the premisses.Generally, 'ψ1, . . . , ψn ⊧ϕ', where ψ1, ...,
ψn and ϕ are L1-sentences, is short for '{ψ1, . . . , ψn} ⊧ϕ'. So the claim of
Example 2.13 may be written P →¬Q, Q ⊧¬P.
First I draw a truth table for the premisses and the conclusion in the
following way:
P
Q
P →¬ Q
Q
¬ P
T
T
T F F T
T
F T
T
F
T T T F
F
F T
F
T
F T F T
T
T F
F
F
F T T F
F
T F
(2.1)
Now I will check whether there is any line in which the entries in the
main columns of the premisses all have T's, while the conclusion has an F.
In the ﬁrst line of truth-values the ﬁrst premiss receives an F, the second
a T, and the conclusion an F. Te second and fourth lines also have F's
for one premiss. Te third line has T's for both premisses, but also a T for
the conclusion. Tus, there is no line where all premisses receive T's and
the conclusion an F. Terefore, the argument is valid, that is, ¬P follows
from {P →¬Q, Q} or, formally, P →¬Q, Q ⊧¬P.
For ﬁnite sets Γ of premisses, one can reduce the problem of checking
whether Γ ⊧ϕ to the problem of checking whether a single sentence is
logically true. To do this one combines all of the premisses, that is, all
sentences in Γ, using ∧, and then one puts the resulting conjunction in
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
42
front of an arrow followed by the conclusion. Te resulting sentence is
logically true if and only if the argument is valid. Tis can be expressed
more succinctly as follows:
theorem 2.14. ψ1, . . . , ψn ⊧ϕ if and only if ψ1∧. . .∧ψn →ϕ is a tautology
(that is, iﬀψ1 ∧. . . ∧ψn →ϕ is logically true).
I do not give a proof of this theorem here.
I will apply Teorem 2.14 to the example above: First, the two pre-
misses are combined into (P →¬Q) ∧Q. It is necessary to reintroduce
the brackets around P →¬Q because otherwise the result would be an
abbreviation for P →(¬Q ∧Q) as ∧binds more strongly than →. Next,
the arrow is put between this conjunction and the conclusion. Tis yields
((P →¬Q) ∧Q) →¬P. Te brackets around the conjunction of the two
premisses are not really necessary since ∧binds more strongly than →,
but they might make the sentence easier to read. Te truth table for this
long sentence looks like this:
P
Q
((P →¬ Q) ∧Q) →¬ P
T
T
T F F T
F T
T F T
T
F
T T T F
F F
T F T
F
T
F T F T
T T
T T F
F
F
F T T F
F F
T T F
(2.2)
Tus, the sentence ((P →¬Q)∧Q) →¬P is valid, that is, it is a tautology.
By Teorem 2.14, it follows that P →¬Q, Q ⊧¬P. Of course, we know
this already from truth table (2.1).
Drawing truth tables for arguments or sentences with many sentence
letters is cumbersome: every new sentence letter doubles the number of
lines of the truth table, because for any already given line two possibilities
must be considered: the new sentence letter can have truth-value T or F.
Tus, a sentence or argument with 1 sentence letter requires only 2 lines,
one with 2 diﬀerent sentence letters requires 4, one with 3 requires 8 lines,
and so on. Generally, the truth table for a sentence or argument with n dif-
ferent sentence letters will have 2n lines of truth-values. In Exercise 3.6
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
43
there will be an argument in L1 with 7 sentence letters. Tus, writing
down the corresponding truth table would require 27 = 128 lines.
To show that an L1-sentence is a tautology, one does not need to draw
a complete truth table. One only needs to show that there cannot be a
line in the truth table that yields an F in the main column. In order to
refute the existence of such a line for Example 2.13, the best strategy is to
start with the assumption that the value in the main column is F:
P
Q
((P →¬ Q) ∧Q) →¬ P
F
A sentence of the form ϕ →ψ has the truth-value F only if ϕ has truth-
value T and ψ has truth-value F. Tus, I must have:
P
Q
((P →¬ Q) ∧Q) →¬ P
T
F F
I can continue to calculate truth-values 'backwards':
P
Q
((P →¬ Q) ∧Q) →¬ P
T
T T
F F T
I write the calculated truth-values also under the ﬁrst two occurrences of
P and Q:
P
Q
((P →¬ Q) ∧Q) →¬ P
T T ? T
T T
F F T
But now there is no way to continue. Te slot marked with a question
mark cannot be ﬁlled with a truth-value: there should be an F under the
negation symbol ¬, as Q has truth-value T, but there should also be a T,
because (P →¬Q) and P have T's. It follows that there cannot be a line
with an F in the main column. Terefore, in the full truth table with all
the lines, all truth-values in the main column are T's. Tis proves again
that ((P →¬Q) ∧Q) →¬P is a tautology.
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
44
Since it is not easy (for an examination marker, for instance) to recon-
struct how the truth-values have been calculated, it is useful to record the
order in which the values were obtained:
P
Q
((P →¬ Q) ∧Q) →¬ P
T6 T3 ? T7 T1 T4 F F2 T5
Of course I could have written down the truth-values in a diﬀerent order.
For instance, afer arriving at F2, I could have calculated the value in the
last column and only then have turned to the part preceding →.
Now I will use the same method to show that (P →¬Q) →¬P is not
a tautology. As before, an F is written in the main column:
P
Q
(P →¬ Q) →¬ P
F
Te following table results from the ﬁrst backwards-calculation:
P
Q
(P →¬ Q) →¬ P
T
F F
Tus, P must receive the truth-value T:
P
Q
(P →¬ Q) →¬ P
T
F F T
Tus one can also write a T under the ﬁrst occurrence of P:
P
Q
(P →¬ Q) →¬ P
T T
F F T
Since P →¬Q has the truth-value T and P also has the truth-value T, the
sentence ¬Q receives a T, and Q, accordingly, an F. Hence, the line can
be completed as follows (I will also insert the obligatory indices):
P
Q
(P →¬ Q) →¬ P
T
F
T4 T1 T5 F6 F F2 T3
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
45
At any rate, when one has arrived at a 'possible' line one should cal-
culate the truth-values from bottom to top (starting from the truth-values
that have been obtained for the sentence letters) to ensure that one has not
missed a column that cannot given a unique truth-value. Only once this
ﬁnal check has been carried out, one knows that the line obtained is a
possible line in a truth table.
Te above backwards-calculations shows that the sentence (P →
¬Q) →¬P has truth-value F if P has the truth-value T and Q has the
truth-value F.
Technically speaking, if A(P) = T and A(Q) = F for a structure A,
then (P →¬Q) →¬P is false in A. So, by Deﬁnition 2.7(i), (P →¬Q) →
¬P is not logically valid, that is, it is not a tautology.
Sometimes this method of calculating truth-values backwards re-
quires more than one line. Tis is the case in the following example:
P
Q
(P ∨¬ Q) ↔(Q →P)
F
If a sentence ϕ ↔ψ is false, there are two possibilities: ϕ could have
truth-value T and ψ truth-value F, or, ϕ could have F and ψcould have
truth-value T. As such, one has to take these two possibilities into account:
P
Q
(P ∨¬ Q) ↔(Q →P)
1
T
F
F
2
F
F
T
I have underlined the truth-values that cannot be uniquely determined,
and so more than one possibility (line) needs to be checked.
Te rest is routine. Te indices in the table below indicate the order
in which I arrived at the truth-values. Te order in which the values
are calculated does not really matter, but the indexing makes it easier to
follow the reasoning.
P
Q
(P ∨¬ Q) ↔(Q →P)
1
F5 T1 ? T6 F T3 F2 F4
2
F3 F1 F4 T5
F T6 T2 ?
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
46
Neither of the two lines can be completed. Tis shows that (P ∨¬Q) ↔
(Q →P) is a tautology.
Of course it can happen that more lines are required and that diﬀerent
cases under consideration have to be split up into further subcases.
Te method of backwards-calculation can also be applied in order to
check whether an argument is valid or not. To show that an argument
is not valid, one has to ﬁnd a line (that is, a structure) where all of the
premisses are true and the conclusion is false. If there is no such line,
the argument is valid. Here is an example of how to use the method to
determine whether an argument is valid. I have picked an example that
forces me to consider several diﬀerent cases. So, I want to determine
whether
P →Q, ¬(P1 →Q) ∨(P ∧P1) ⊧(P ↔Q) ∧P1.
I will start by writing the two premisses and the conclusion in one table.
I have to check whether there can be a line in the table where the two
premisses come out as true while the conclusion is false. As such, I should
start by writing T's in the main columns of the premisses and an F in the
main column of the conclusion:
P
Q
P1
P →Q
¬(P1 →Q) ∨(P ∧P1)
(P ↔Q) ∧P1
T
T
F
Now I have to make a case distinction: the ﬁrst sentence could be true
because P is false or because Q is true. Similarly, in the case of the other
sentences, there is no unique way to continue. Given that I can make a
case distinction with respect to any of the three sentences, it is not clear
how to proceed. But some ways of proceeding can make the calculations
quicker and less complicated. It is useful to avoid as much as possible
picking a sentence that will require a new case distinction in the next
step.Ultimately though, so long as all possible cases are systematically
checked, the order in which one proceeds will not aﬀect the end result.
At this stage in the calculation, a case distinction cannot be avoided,
and so I will pick the last sentence: (P ↔Q) ∧P1 can be false either
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
47
because P ↔Q is false or because P1 is false. I will try to complete the
line for the latter case and leave the former for later:
P
Q
P1
P →Q
¬(P1 →Q) ∨(P ∧P1)
(P ↔Q) ∧P1
1
T
T
F1
F
2
T
F5 F2 T4
T
? F3
F F1
Te second line of the table cannot be completed: the second premiss
must be true, but it follows from my assumption that both ¬(P1 →Q)
and P ∧P1 must be false. Tis means that the rules tell me to write an F
in the slot marked by ?, because P1 is false, but they also tell me to write
a T for ?, because the entire sentence ¬(P1 →Q) ∨(P ∧P1) is true and
¬(P1 →Q) is already false.
Line 1 is more complicated, because P ↔Q can be false for two
reasons: ﬁrst, P can be true while Q is false or, second, P can be false while
Q is true. Tus, I need to distinguish the subcases marked 1.1 and 1.2:
P
Q
P1
P →Q
¬(P1 →Q) ∨(P ∧P1)
(P ↔Q) ∧P1
1.1
T5 T ?
T T4
T2 F1 F3 F
2
T
F5 F2 T4
T
? F3
F F1
1.2
T
T
F2 F1 T3 F
Since P is true and P →Q is true, Q has to be true as well. But according
to the assumption, Q is false. Terefore, line 1.1 cannot be completed.
Only case 1.2 remains:
P
Q
P1
P →Q
¬(P1 →Q) ∨(P ∧P1)
(P ↔Q) ∧P1
1.1
T5 T ?
T T4
T2 F1 F3 F
2
T
F5 F2 T4
T
? F3
F F1
1.2
T
F7
T6 T5 T F4 ?
F2 F1 T3 F
Since the second premiss is true and ¬(P1 →Q) is false, P ∧P1 ought to
be true. But this cannot be the case, because P is false. So line 1.2 cannot
be completed either. Since this exhausts the possible ways of refuting the
argument, the following claim has been established:
P →Q, ¬(P1 →Q) ∨(P ∧P1) ⊧(P ↔Q) ∧P1.
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
48
Generally the entries in a table where one calculates truth-values 'back-
wards' should be indexed by numbers that show the order in which the
values were obtained. Te assumptions in the diﬀerent cases should be
indicated by underlining the respective truth-values. Subcases should be
marked as such (in the way I have done this above). A proof without in-
dices for the truth-values will be considered to be incomplete. Tese
conventions merely serve the purpose of making the calculations easier
to reconstruct: otherwise the calculations of truth-values can be very
diﬃcult to follow.
Afer having developed semantics for the language L1, I will now
look at alternatives. One might wonder why the connectives ¬, ∧, ∨, →
and ↔have been chosen. Tese connectives are used in many logic texts,
and they more or less correspond to expressions in English. However,
there are also other English phrases for connecting sentences. Te phrase
'neither ... nor ...' is an example. Te sentence
Neither Jones nor Brown is in Barcelona
will be true if and only if Jones is not in Barcelona and Brown is not
in Barcelona. In L1 there is no connective that directly corresponds to
'neither ... nor ...'. If one added a connective for the phrase 'neither ...
nor ...', it would have the following truth table:
ϕ
ψ
ϕ ↓ψ
T
T
F
T
F
F
F
T
F
F
F
T
However, the connective ↓for 'neither ... nor ...' is not really needed
because one can generate the same truth table using the old connectives
of L1. 'Neither ... nor ...' can be re-expressed in English as 'It is not the
case that ..., and it is not the case that ...'. In L1 one can also deﬁne ↓in
© Volker Halbach
2008/2009

2 Syntax and Semantics of Propositional Logic
49
terms of ¬ and ∧in the following way:
ϕ ψ
¬ ϕ ∧¬ ψ
T T
F
F F
T F
F
F T
F T
T
F F
F F
T
T T
Alternatively, one can re-express or deﬁne ϕ↓ψ as ¬(ϕ∨ψ). Tus, adding ↓
to the language L1 would not increase the expressive power of L1. Te
connective ↓would only allow one to abbreviate some sentences. Tere
are many more truth tables for which L1 does not have connectives. So
far I have looked only at binary connectives (connectives conjoining two
sentences) such as ∧, ∨, →, ↔and ↓, but there are also unary connectives
(connectives taking one sentence) other than ¬; and there are ternary
connectives (connectives taking three sentences), and so on. Can all these
connectives be expressed with the connectives of L1, that is, with ¬, ∧, ∨,
→, and ↔? Te answer is 'yes': all truth tables can be produced with the
old connectives of L1. Tis fact is called the truth-functional completeness
of L1. In fact, ¬ and ∧together without any further connectives are
suﬃcient for expressing all other connectives. And even ↓on its own
would do the trick. At any rate, adding more connectives to L1 than those
used here is not really necessary and would not increase the expressive
power of L1. I will not prove these results here.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
In the previous chapter I focused on the formal language L1. Te con-
nectives ∧, ∨, →, and ↔of L1 can be used to combine sentences of L1 to
form new compound sentences; the connective ¬ can be added in front
of a sentence of L1 to build a new sentence.
English sentences can also be combined and modiﬁed with many
diﬀerent connectives to form new sentences. For instance, one can write
the word 'and' between two English sentences to obtain a new sentence.
'Or', 'because', 'although', 'but', 'while', 'if' and many others can be used
in the same way. An expression that connects sentences can also be
more complex: the expression 'due to the fact that' between two English
sentences yields a new English sentence. Other expressions, such as 'if ...,
then', connect sentences even though they are not written between two
sentences.
Other expressions do not combine sentences, but rather modify a
sentence, as is the case with 'not', 'as is well known', 'John strongly be-
lieves that', and 'regrettably'. 'Not' is special insofar as it ofen cannot be
simply inserted into a sentence, but rather requires the introduction of
the auxiliary verb 'to do': the introduction of 'not' into 'Alan went to
London' yields 'Alan did not go to London'. In this respect 'not' is more
complicated than an adverb such as 'regrettably' or the connective ¬ of
L1.
In the previous chapter I deﬁned the notion of a connective; now I
will apply it to English as well: Expressions that can be used to combine or
modify English sentences are connectives. Tis deﬁnition is far from being
precise, but an exact deﬁnition of the notion of a connective of English
is not easy to give because sometimes the connectives are not simply
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
51
plugged into or written between sentences. Occasionally the sentences
themselves have to be modiﬁed, for instance, by introducing auxiliary
verbs, as the above examples of 'not' shows.
3.1 truth-functionality
Te connectives of L1, that is, ¬, ∧, ∨, →and ↔, correspond to connectives
in English. Te semantics of the connectives of L1 is very simple; it is
encompassed in their truth tables. In contrast, many connectives of
English function in a much more intricate way.
As an example I will consider the connective 'because'. Imagine that I
drop my laptop computer on the street. It's had it: the screen is broken.
So my laptop computer does not work. Te sentence
My computer does not work because I dropped my computer
is also true: the laptop would still be functional if I had not dropped it.
Moreover, it is true that the computer does not work and it is true that I
dropped it. Tus, 'because' connects the two true sentences 'My computer
does not work' and 'I dropped my computer' together forming a new true
sentence. In this respect it seems similar to 'and'.
In other cases, however, one can use 'because' to connect two true
English sentences A and B and end up with a false sentence. Afer picking
up my broken laptop, I consider the following sentence:
My laptop computer does not work because it is not plugged
in.
In the situation I just described, it is true that my computer does not work,
and it is true that it is not plugged in as I am standing in the street with
my broken laptop. Nevertheless the sentence that my laptop computer
does not work because it is not plugged in is false: it would work if I had
not dropped it. Even if it were now plugged in, it would not work. It does
not work because I dropped it, not because it is not plugged in. So this
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
52
is a case in which using 'because' to connect two true sentences yields a
false sentence.
Nevertheless, the truth of 'A because B' is not completely independent
of the truth and falsity of the English sentences A and B. If A or B (or
both) are false, then 'A because B' is also false. Tese dependencies can
be summarised in the following truth table for the English connective
'because', where A and B are declarative sentences of English:
A
B
A because B
T
T
?
T
F
F
F
T
F
F
F
F
Te question mark indicates that in this case the truth-value of 'A be-
cause B' depends not only on the truth-values of the direct subsentences,
that is, on the truth-values of the sentences Aand B that 'because' connects.
Tis means that when 'because' is used to connect two true sentences,
sometimes the resulting sentence is true and sometimes the resulting
sentence is false; so the truth-value of the compound sentence is not de-
termined by the truth-values of the sentences connected by 'because'. In
this respect 'because' diﬀers from 'and'. If the truth-value of the compound
sentence is determined by the truth-value of the connected sentences,
as is the case with 'and', then the connective is called 'truth-functional'.
Connectives like 'because' are not truth-functional.
Te following is a general, less than precise characterisation of truth-
functionality :
characterisation 3.1 (truth-functionality). A connective is truth-
functional if and only if the truth-value of the compound sentence cannot
be changed by replacing a direct subsentence with another sentence having
the same truth-value.
For instance, 'because' is not truth-functional: replacing the true
sentence 'I dropped my computer' with the equally true sentence 'the
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
53
computer is not plugged in' does change the truth-value of the compound
sentence
My computer does not work because I dropped my computer
from True to False.
Tus, the deﬁnition of truth-functionality of an English connective
can be paraphrased in terms of truth tables: a connective is truth-functional
if and only if its truth table does not contain any question marks.
'If ... then' is usually translated as the arrow →. Some of its occur-
rences, however, are deﬁnitely not truth-functional. A sentence ϕ →ψ
is true if ϕ is false or ψ is true. In the following sentence, 'if ... then'
functions diﬀerently:
If Giovanni hadn't gone to England, he would not have caught
a cold in Cambridge.
Assume that Giovanni really did go to England, but did not catch a cold
in Cambridge. In this case one may hesitate to assign a truth-value to
the sentence: some people would say that the sentence is neither true
nor false; others would say that it is false. At any rate, in that case the
sentence is not true. But if the whole sentence is not true, then this is a
case in which the ﬁrst subsentence following 'if' is false, but the whole
sentence is also false. But according to the truth table for →a sentence
with a false antecedent is true. Tis means that the arrow →cannot be
used to formalise the sentence correctly.
'If'-sentences describing what would have happened under circum-
stances that are not actual are called 'subjunctives' or 'counterfactuals'.
In these sentences 'if' does not function like the arrow →and cannot
be translated as the arrow. Te proper treatment of counterfactuals is
beyond the scope of this book.1
Indicative conditionals such as
1 Lewis (1973) is a classic text on counterfactuals.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
54
If Jones gets to the airport an hour late, his plane will wait
for him
are ofen formalised using the arrow →, but it is somewhat questionable
whether →really is appropriate.
Assume, for instance, that Jones arrives at the airport early and he
easily catches the plane. Suppose also that Jones is not a VIP and so the
airline would not have waited for him. Using the arrow for 'if' one can
try to translate this sentence as P →Q with the following dictionary:
P:
Jones gets to the airport an hour late,
Q:
Jones's plane will wait for Jones.
If ∣P∣A = F, that is, if P is false in the structure A, then P →Q is true
in A, that is, ∣P →Q∣A = T by Deﬁnition 2.6 or by the truth table of →on
page 37. According to the assumptions, 'Jones gets to the airport an hour
late' is actually false. Tus, if the formalisation is correct, the displayed
English 'if'-sentence should be true. But it is highly questionable whether
it is true: one may hold that 'If Jones gets to the airport an hour late, his
plane will wait for him' is simply false, even if Jones gets there on time.
Tere is an extensive literature on the treatment of 'if'-sentences. Te
treatment of 'if'-sentences, including counterfactuals, has interesting
philosophical implications. I shall not go further into the details of this
discussion here. Te above example should be suﬃcient to show that
formalising 'if' by the arrow is problematic even in the case of indicative
conditionals. For most purposes, however, the arrow is considered to
be close enough to the 'if ... then ...' of English, with the exception of
counterfactuals.
Te deﬁnition of truth-functionality also applies to unary connectives:
a unary connective is truth-functional if and only if the truth-value of the
sentence with the connective cannot be changed by replacing the direct sub-
sentence with a sentence with the same truth-value.
'It is necessarily the case that A' or 'It is necessary that' is a unary
connective that is not truth-functional. If A is a false English sentence,
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
55
then 'It is necessary that A' is false, but if A is true, 'It is necessary that A'
may be either true or false:
It is necessary that all trees are trees.
Tis sentence is true: 'all trees are trees' is logically true and thus necessary.
But, if the true sentence 'All trees are trees' is replaced by the true sentence
'Volker has ten coins in his pocket' then the resulting sentence
It is necessary that Volker has ten coins in his pocket
is not true, because I could easily had only nine coins in my pocket.
Generally if A is only accidentally true, 'It is necessary that A' will be false.
Tus the corresponding truth table looks like this:
A
it is necessary that A
T
?
F
F
Some other connectives - like'Bill believes that ...' - have nothing but
question marks in their truth tables. In contrast, 'Bill knows that ...' has
the same truth table as 'it is necessary that'.2
3.2 logical form
In this section and the next I will show how to translate English sentences
into L1 sentences. Tese translations are carried out in two steps: First
the sentence is brought into a standardised form, which is called the
'(propositional) logical form'.3 In the second step the English expressions
2 A more comprehensive account of truth-functionality is given by Sainsbury (2001,
Chapter 2).
3 In this chapter I will usually drop the speciﬁcation 'propositional' from 'propositional
logical form' since I will not deal with any other kind of logical form for now. Tere is
also a more complex predicate logical form of an English sentence. Te predicate logical
form will be studied in Chapter 7.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
56
are replaced by symbols. Obtaining the logical form is the non-trivial
part; the step from the logical form to a sentence of the language L1 of
propositional logic is simple and purely mechanical.
Here I shall sketch a practical procedure for bringing an English
sentence into its logical form. Te procedure is to be applied to the
sentence, reapplied to its sentences from which the main sentence is built
up, and then repeated until the subsentences cannot be further analysed
by the means of propositional logic.
I have broken down this procedure into ﬁve steps. In practice they are
all carried out at the same time. Te ﬁrst step is the diﬃcult one: in this
step it is checked whether the sentence can be broken down into a truth-
functional connective and one or more subsentences, that is, whether the
sentence is built up from one or more sentences with a truth-functional
connective.
For instance, the sentence
Te car doesn't start because the battery is ﬂat or there is no
petrol in the tank.
is not built up from other sentences with a truth-functional connective:
it is built up from the sentence 'Te car doesn't start' and the sentence
'Te battery is ﬂat or there is no petrol in the tank.' with the connec-
tive 'because', which is not truth-functional. Te connective 'or' is truth-
functional, but it only connects 'Te battery is ﬂat' and 'Tere is no
petrol in the tank.'; so only the subsentence 'Te battery is ﬂat or there
is no petrol in the tank.' is built up from other sentences with the truth-
functional connective 'or', but not the entire sentence.
To put it in a diﬀerent way, one identiﬁes the 'topmost' or 'main' con-
nective and checks whether it is truth-functional. It is permissible to
reformulate the sentence slightly to put into a form such that it is built
up with a truth functional connective. Te truth-functional connectives
should be taken from a ﬁxed list of truth-functional connectives; this
restriction will enable one to formalise the connectives as the ﬁves con-
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
57
nectives of the formal language L1, respectively. Finally, one reapplies the
procedure to the sentence(s) from which the main sentence is built up.
I give now the ﬁve steps of the procedure and then show how it works
by means of some examples:
1. Check if the sentence can be reformulated in a natural way as a sen-
tence built up from one or more sentences with a truth-functional
connective. If this is not possible, then the sentence should be put in
brackets and not analysed any further.
2. If the sentence can be reformulated in a natural way as a sentence
built up from one or more sentences with a truth-functional connec-
tive, do so.
3. If that truth-functional connective is not one of the standard con-
nectives in Table 3.2, reformulate the sentence using the standard
connectives.
4. Enclose the whole sentence in brackets, unless it is a negated sen-
tence, that is, a sentence starting with 'it is not the case that'.
5. Apply the procedure, starting back at 1., to the next subsentence(s)
(that is, to the sentence(s) without the standard connective of step 3).
name
standard connective
some other formulations
conjunction
and
but, although
, [a comma
between sentences]
disjunction
or, unless
negation
it is not the case that
not, none, never
arrow
if ... then
given that, ...
double arrow
if and only if
exactly if,
precisely if
Table 3.1: standard connectives
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
58
Tere is no need to memorise this description of the procedure; the
point is to learn how to apply it. Tus instead of describing the procedure
in more detail, which would be fairly diﬃcult, I'll illustrate the procedure
with several examples:
example 3.2. Rob and Tim will laugh, if the tutor can't pronounce Siob-
han's name.
Te sentence is built from 'Rob and Tim will laugh' and 'Te tutor
can't pronounce Siobhan's name' with the connective '..., if ...'. As such,
there is no need for the sort of reformulation called for in 2. But '...,
if...' is not a standard connective. So, in accordance with step 3 I will
reformulate the sentence with the standard connective 'if ... then ...':
If the tutor can't pronounce Siobhan's name, then Rob and
Tim will laugh.
In step 4 the entire sentence is enclosed by brackets:
(If the tutor can't pronounce Siobhan's name, then Rob and
Tim will laugh)
Step 5 sends me back again to step 1. Te two subsentences to which step 1
is applied are:
Te tutor can't pronounce Siobhan's name,
Rob and Tim will laugh.
Te ﬁrst sentence contains a negation and so I will reformulate it with the
standard connective 'it is not the case that ...':
It is not the case that the tutor can pronounce Siobhan's name
According to step 4, the sentence does not need to be put in brackets
since it starts with 'it is not the case that'.
I still have to apply the procedure to the second sentence. 'Rob and
Tim will laugh' is not a sentence built up using a truth-functional connec-
tive, but it can be reformulated in accordance with step 2 as a sentence
with a truth-functional connective in the following way:
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
59
Rob will laugh and Tim will laugh,
since '... and ...' is already a standard connective, there is no need for the
sort of reformulation described in step 3. Afer applying step 4 I obtain
the following expression:
(Rob will laugh and Tim will laugh).
Tus the whole sentence now reads as follows:
(If it is not the case that the tutor can pronounce Siobhan's
name, then (Rob will laugh and Tim will laugh)).
Now I have to start again with step 1. Te sentence 'the tutor can pro-
nounce Siobhan's name' cannot be reformulated in a natural way as a
sentence built up with a truth-functional connective. Tus it is put in
brackets according to step 1:
(If it is not the case that (the tutor can pronounce Siobhan's
name), then (Rob will laugh and Tim will laugh)).
Next, neither 'Rob will laugh' nor 'Tim will laugh' can be reformulated as
a sentence built with a truth-functional connective, so they are each put
into brackets as required by step 1:
(If it is not the case that (the tutor can pronounce Siobhan's
name), then ((Rob will laugh) and (Tim will laugh))).
Now this is the (propositional) logical form of the sentence.
example 3.3. Unless the ignition is turned on and there is petrol in the
tank, the engine will not start and I'll not be able to arrive in time.
I can skip steps 1 and 2 because the sentence is already built up with
a truth-functional connective, though not by a standard one. Next, I
replace 'unless' by the standard connective 'or' in accordance with step 3;
then I apply step 4 and enclose the entire sentence in brackets.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
60
(Te ignition is turned on and there is petrol in the tank, or
the engine will not start and I'll not be able to arrive in time).
Since 'and' is already a standard connective, step 4 is applied twice more.
((Te ignition is turned on and there is petrol in the tank),
or (the engine will not start and I'll not be able to arrive in
time)).
Next, I turn to the part of the sentence afer 'or'. Tere are two sentences
containing 'not'. According to step 3, they are to be reformulated with the
corresponding standard connective.
((Te ignition is turned on and there is petrol in the tank),
or (it is not the case that the engine will start and it is not the
case that I'll be able to arrive in time)).
Now step 1 is applied four times:
(((Te ignition is turned on) and (there is petrol in the tank)),
or (it is not the case that (the engine will start) and it is not
the case that (I'll be able to arrive in time))).
Te process terminates here since the remaining sentences not containing
brackets, that is, 'Te ignition is turned on' and so on cannot be further
analysed.
3.3 from logical form to formal language
Once the logical form of a sentence has been determined, the translation
into the language L1 of propositional logic is simple.
In order to translate the logical form of an English sentence into L1
apply the following procedure:
1. Replace standard connectives by their respective symbols in accor-
dance with the following list:
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
61
standard connective
symbol
and
∧
or
∨
it is not the case that
¬
if ... then ...
→
if and only if
↔
2. Replace every English sentence by a sentence letter and delete the
brackets surrounding the sentence letter.4 Use diﬀerent sentence let-
ters for distinct sentences and the same sentence letter for multiple
occurrences of the same sentence.
3. Give a list (the 'dictionary') of all sentence letters in the resulting L1-
sentence together with the respective sentences they have replaced.
I shall carry out this procedure on Example 3.2. Te logical form of
that sentence is
(If it is not the case that (the tutor can pronounce Siobhan's
name), then ((Rob will laugh) and (Tim will laugh))).
To translate this into L1 I ﬁrst replace all standard connectives by the
respective symbols, as required by step 1:
(¬ (the tutor can pronounce Siobhan's name) →((Rob will
laugh) ∧(Tim will laugh))).
According to step 2 the sentences are to be replaced by sentence letters:
(¬P →(Q ∧R)).
I complete the formalisation by adding the dictionary required in step 3:
P:
Te tutor can pronounce Siobhan's name.
Q:
Rob will laugh.
R:
Tim will laugh.
4 English sentences usually do not contain any L1 connectives or brackets. Tus, one will
replace with sentence letters exactly those English sentences that could not be further
analysed in accordance with step 1 of the procedure on page 57.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
62
Tis was the logical form of the English sentence from the second
example:
(((Te ignition is turned on) and (there is petrol in the tank)),
or (it is not the case that (the engine will start) and it is not
the case that (I'll be able to arrive in time))).
Its formalisation is the sentence ((P ∧Q) ∨(¬R ∧¬P1)), or, using the
bracketing conventions, (P ∧Q) ∨(¬R ∧¬P1). Te dictionary is obvious:
P:
Te ignition is turned on.
Q:
Tere is petrol in the tank.
R:
Te engine will start.
P1:
I'll be able to arrive in time.
In both examples, I used the sentence letter P to formalise the ﬁrst
sentence, and Q to formalise the next and so on. Tis is not obligatory. It
would have been equally correct (but awkward) to employ the sentence
letter R473 instead of P.
3.4 ambiguity
Determining the logical form of an English sentence can be tricky. Some-
times there is no unique solution.
Brown is in Barcelona and Jones owns a Ford or Smith owns
a Ford.
Tis sentence is ambiguous: 'and' could have been used to connect the two
claims 'Brown is in Barcelona' and 'Jones owns a Ford or Smith owns a
Ford'. It could equally well be used to express that there are the following
two possibilities: ﬁrst, Brown is in Barcelona and Jones owns a Ford;
second, Smith owns a Ford.
Corresponding to these two possible readings there are at least two
possible formalisations of this sentence:
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
63
(i) P ∧(Q ∨R)
(ii) (P ∧Q) ∨R
Te dictionary is as follows:
P:
Brown is in Barcelona
Q:
Jones owns a Ford
R:
Smith owns a Ford
Te formalisations (i) and (ii) correspond to the two readings of the
original English sentence. In a given situation it may be clear which
reading is intended, and thus which formalisation is preferable. Without
further hints, however, one cannot decide between (i) and (ii).
Ambiguities like the one above are called 'scope ambiguities'. Roughly
speaking, the scope of an occurrence of a connective in a sentence is
that part of the sentence to which the connective applies. In (i) the
connective ∧applies to the entire sentence, as it connects P and (Q ∨R),
while in (ii) the scope of ∧is only (P ∧Q).
definition 3.4 (scope of a connective). Te scope of an occurrence of
a connective in a sentence ϕ is (the occurrence of) the smallest subsentence
of ϕ that contains this occurrence of the connective.
By 'subsentence of ϕ' I mean any sentence that is part of ϕ.
In the sentence
((P →(P ∨Q))
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
→(¬P ∧Q))
the scope of the second occurrence of the arrow →is the entire sentence;
the scope of the ﬁrst occurrence of →is the underbraced part of the
sentence.
Te deﬁnition of the scope of an occurrence of a connective refers
to the sentence, not to any of its abbreviations. So, the scope of the ﬁrst
occurrence of the arrow in
(P →P ∨Q)
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
→(¬P ∧Q)
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
64
is still the underbraced part, because P →P is not a part (subsentence) of
the real sentence.
Te problem of scope ambiguity highlights a general diﬀerence be-
tween natural languages such as English and formal languages like L1:
while sentences of English are ofen ambiguous in their structure, sen-
tences of L1 are never structurally ambiguous. Tus, there is no chance
of translating the ambiguous English sentence into an equally ambiguous
sentence of L1. Tis will mean that one might have to choose between
diﬀerent possible formalisations of an English sentence.
Tere are also two possibilities of formalising the following sentence:
Brown is in Barcelona and Jones owns a Ford and Smith owns
a Ford.
Te sentence may be formalised as P ∧Q ∧R, which is short for the
sentence ((P ∧Q) ∧R), or, alternatively as the sentence P ∧(Q ∧R).
Tese are two diﬀerent sentences of the language L1. But they are logically
equivalent: the two L1-sentences have the same truth table. Tus, it is
does not matter for the purpose of checking validities of arguments etc
which formalisation is used.
3.5 the standard connectives
Te syntax of the connectives of L1 is very simple: ¬ is written in front
of a sentence, and the sentence that results from writing ¬ in front of a
sentence is the negation of that original sentence Te other connectives
are written between sentences, and the entire string of expressions is
surrounded by brackets. Te syntax of the corresponding expressions in
English is far more complicated.
Te grammar of 'not' is a bit complicated: usually one cannot simply
insert 'not' into a sentence to obtain the negation of the sentence. Ofen
the sentence is reformulated with the auxiliary verb 'to do'. 'Bill does not
write an essay' is the negation of 'Bill writes an essay'. But there are more
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
65
ways to express negation: one could also say 'Bill writes no essay'; in this
case the negation is expressed by 'no'.
'And' and its counterpart ∧seem less problematic. In some cases 'and'
does not connect complete sentences:
Liz and Anne are mountaineers.
Here 'and' combines two proper names. Te sentence, however, can be
seen as an abbreviation of a sentence in which 'and' does connect two
sentences:
Liz is a mountaineer and Anne is a mountaineer.
Tis sentence can then be formalised with the help of ∧. But the trick
does not always work. Te sentence
Liz and Anne are friends
can hardly be rephrased as
Liz is a friend and Anne is a friend.
Some English sentences can be reformulated in a way that introduces
'and':
Liz is an Australian mountaineer
can be rephrased as
Liz is Australian and Liz is a mountaineer.
However, the sentence
Liz is an avid mountaineer
does not mean the same as
Liz is avid and that Liz is a mountaineer.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
66
Similarly,
Kentaro is a slim sumo-wrestler
cannot be rewritten as
Kentaro is slim and Kentaro is a sumo-wrestler.
For a slim sumo-wrestler might not be slim at all, but only slim for a
sumo-wrestler.
Te connective 'but' and similar words are ofen translated as ∧, al-
though 'but' ofen indicates a contrast between the two sentences that are
combined.
'Or' is fairly straightforward. 'Unless' is in many uses very similar to
'or' and may then be translated by ∨. Ofen 'either ... or ...' is assumed
to be exclusive, that is, 'Either A or B' is taken to be false, if A and B are
both true. As a rule of thumb this is correct, but sometimes 'either ... or
...' may be equivalent to the simple 'or', and in some cases, with some
emphasis, the simple 'or' may be exclusive.
3.6 natural language and propositional logic
In the previous sections I have shown how to translate English sentences
into sentences of the language L1 of propositional logic. Te concepts of
Section 2.4 can now be applied to the sentences that have been obtained
as translations.
Te sentence of L1 that is obtained by translating an English sentence
into the language of propositional logic is the formalisation of that sentence.
I will ofen speak of 'the formalisation' of an English sentence as if
there were always exactly one (best) formalisation. Of course one always
has the choice of diﬀerent sentence letters, and when one is translating
a phrase like the exclusive 'either ... or ...', for which there is no direct
equivalent in L1, one has a choice between diﬀerent ways of rendering
this phrase.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
67
Although these diﬀerent possibilities show already that there cannot
be only a single best formalisation, the diﬀerences between these for-
malisations do not really matter, because these diﬀerences do not aﬀect
the properties of L1-sentences I am interested in. In particular, one can
replace sentence letters in a tautology, that is, in a logically true sentence
of L1 and one will obtain a tautology again as long the same letter is in-
serted for all occurrences of a given sentence letter. Tus it does not matter
with respect to the property of being logically true which sentence letters
are used in a translation. Also, how exactly a connective such as 'either
... or ...' is translated does not matter for the property of being logical
truth, being valid etc.: whether 'Either it rains or it snows', for instance, is
formalised as (P ∨Q) ∧¬(P ∧Q), or as P ↔¬Q, or as ¬P ↔Q 8with
the obvious dictionary) does not matter for the validity of an argument
in which these formalisations are used, as all these formalisations are
logically equivalent.
In some cases, however, there are equally correct formalisations of
a sentence that diﬀer in their relevant properties: one of them may be
logically true while the other is not, for instance. Ambiguous sentences
may have more than one formalisation in L1. In such cases one should
be more precise and talk about the formalisation of a sentence under a
certain reading of that sentence. In what follows I will be less precise and
mostly ignore problems of ambiguity.
Te notions of Deﬁnition 2.7 will now be applied to formalisations of
English sentences, and the English sentences will be categorised accord-
ingly.
definition 3.5.
(i) An English sentence is a tautology if and only if its formalisation in
propositional logic is logically true (that is, iﬀit is a tautology).
(ii) An English sentence is a propositional contradiction if and only if its
formalisation in propositional logic is a contradiction.
(iii) A set of English sentences is propositionally consistent if the set of all
their formalisations in propositional logic is semantically consistent.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
68
Instead of saying that a sentence is a tautology one can also describe it
as propositionally valid or propositionally true.
Te following sentence is a tautology:
Unless Alfred is an eminent logician, it is not the case that
both Kurt and Alfred are eminent logicians.
'Unless A, B' can be rephrased as 'if not A, then B' or simply as 'Aor B'. Te
other steps in the translation are routine, and the following L1-sentence
is obtained as a translation:
P ∨¬(P ∧Q).
Te dictionary is as follows:
P:
Alfred is an eminent logician.
Q:
Kurt is an eminent logician.
Te truth table shows that P ∨¬(P ∧Q) is a tautology by Teorem 2.8 (i):
P
Q
P ∨¬ (P ∧Q)
T
T
T T F T T T
T
F
T T T T F F
F
T
F T T
F F T
F
F
F T T
F F F
Terefore, by Deﬁnition 3.5 (i), the sentence 'Unless Alfred is an eminent
logician, it is not the case that both Kurt and Alfred are eminent logicians'
is a tautology.
In the formal language L1 of propositional logic, the logically true
sentences are exactly the tautologies. In contrast, in English there are
logically true sentences that are not tautologies. Te sentence 'All logi-
cians are logicians' is logically true but it is not a tautology, because the
formalisation in propositional logic is a single sentence letter. A single
sentence letter never is logically true, that is, it never is a tautology.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
69
Similarly, an English sentence can be contradiction without being a
propositional contradiction: Te sentence 'Tere is an oak that is not an
oak.' is an example.
A set of sentences may be propositionally consistent without being
consistent. Te inconsistent set containing the three sentences 'All birds
can ﬂy', 'Tweety is a bird', 'Tweety can't ﬂy', for instance, is propositionally
consistent.
I turn now to the formalisation of entire arguments. Te formalisation
of an argument in English is that argument in L1 that has as its premisses
all the formalisations of the premisses of the English argument, and has
as its conclusion the formalisation of the English conclusion.
definition 3.6. An argument in English is propositionally valid if and
only if its formalisation in L1 is valid.
Every propositionally valid argument is also valid, but not every valid
argument is propositionally valid (for an example see the argument about
Zeno on page1.5).
Deﬁnition 3.6 is a more formal elaboration of the notion of proposi-
tional validity mentioned on page 21. Using the methods developed one
can check arguments in English for their propositional validity.
I will consider some examples.
Jones owns a Ford or Brown is in Barcelona. If Brown is
in Barcelona, Smith is in Barcelona too. But Smith isn't in
Barcelona. Terefore, Jones owns a Ford.
Te premisses of this argument are translated as the following sentences:
P ∨Q
Q →R
¬R
Te conclusion is then formalised as the sentence P. Te sentence letters
stand for the following English sentences:
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
70
P:
Jones owns a Ford.
Q:
Brown is in Barcelona.
R:
Smith is in Barcelona.
By Deﬁnition 3.6 the English argument is propositionally valid if and
only if P ∨Q, Q →R, ¬R ⊧P. Te claim that P ∨Q, Q →R, ¬R ⊧P can
be established, according to Teorem 2.14, by showing that the sentence
(P ∨Q) ∧(Q →R) ∧¬R →P
is a tautology:
P
Q
R
((P ∨Q) ∧(Q →R)) ∧¬ R →P
T
T
T
T T T
T
T T T
F F T T T
T
T
F
T T T
F
T F F
F T F T T
T
F
T
T T F
T
F T T
F F T T T
T
F
F
T T F
T
F T F
T T F T T
F
T
T
F T T
T
T T T
F F T T F
F
T
F
F T T
F
T F F
F T F T F
F
F
T
F F F
F
F T T
F F T T F
F
F
F
F F F
F
F T F
F T F T F
Tus the English argument is propositionally valid.
Te following argument might look puzzling and too optimistic with
respect to my ﬁnances:
Jones has ten coins in his pocket; and it is not the case
that Jones has ten coins in his pocket. Terefore there are
£ 100 000 in my bank account.
Te premiss can be formalised as P ∧¬P, and the conclusion as Q, with
the obvious dictionary:
P:
Jones has ten coins in his pocket.
Q:
Tere are £ 100 000 in my bank account.
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
71
By the truth-table method one can easily establish P ∧¬P ⊧Q (see
Exercise 6.9). Terefore the argument is propositionally valid.
Te argument looks so puzzling because there is no 'connection' be-
tween the premiss and the conclusion: the premiss does not seem to
say anything about my bank account. But Characterisation 1.7 of a valid
argument does not say that the premisses of a valid argument need to be
relevant in this way to the conclusion. In this case, the premiss of the
argument is a (propositional) contradiction; thus there is no interpreta-
tion that would make the premiss true (and the conclusion false); and,
therefore, the argument is propositionally valid. Tis principle, that any
argument with a contradiction as premiss is called 'ex falso quodlibet',
which is Latin for 'From something false everything (follows)'.
Blocking this kind of argument might seem desirable, but it is not a
simple task since abandoning the ex falso quodlibet principle will require
abandoning rules that are ofen applied in reasoning. Only such simple
rules are applied in the following argumentation, which starts from 'Jones
has ten coins in his pocket' and 'it is not the case that Jones has ten coins
in his pocket', and arrives at the conclusion that there is £ 100 000 in my
bank account.
Jones has ten coins in his pocket. So Jones has ten coins in
his pocket or there is £ 100 000 in my bank account. But
Jones does not have ten coins in his pocket. Terefore there
is £ 100 000 in my bank account.
Te reasoning may sound odd, but it is hard to tell where things go wrong.
If a claim 'A' is true, surely the weaker claim 'A or B' must be true as
well. And from an alternative 'A or B' and the negation 'not-A' or the
ﬁrst alternative, one usually concludes 'B'. If these steps may be used to
establish he validity of an argument, then the above argument is valid
Blocking the ex falso quodlibet principle would involve the rejection of
one of those steps.
Usually when one hits upon a contradiction, one does not carry on
reasoning but rather starts to doubt the premisses. Te ex falso quodlibet
© Volker Halbach
2008/2009

3 Formalisation in Propositional Logic
72
principle shows that it is pointless to reason on the basis contradictory
premisses, because from such premisses everything follows.
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
Many arguments in English are valid without being propositionally valid.
Tat is, these arguments are valid but when they are translated into the
language L1 of propositional logic the resulting argument in L1 is not
valid. An example of a valid argument that is not propositionally valid is
the example from page 17:
Zeno is a tortoise. All tortoises are toothless. Terefore Zeno
is toothless.
Te argument is not propositionally valid because each of the premisses
and the conclusion have to be translated into diﬀerent sentence letters.
Tis means that in the language of propositional logic the argument will
look like this: P, Q ⊧R. It is certainly not the case that P, Q ⊧R. Te
English argument, however, served as an example of a valid argument
in Section 1.5. In order to capture the validity of arguments like this one
about Zeno, a formal language more powerful and more sophisticated
than the language L1 of propositional logic is required.
4.1 predicates and quantification
In this section I shall motivate and introduce the basic elements of the
syntax of the language L2 of predicate logic; the precise deﬁnition of a
sentence of L2 will be given in Section 4.2.
For its analysis in predicate logic, a simple sentence like 'Tom loves
Mary' must be broken down into its constituents: the sentence contains
two designators, 'Tom' and 'Mary', that is, two expressions intended to
denote a single object. Te expression 'loves' is is a 'predicate expression'
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
74
or 'predicate', for short: it connects the two designators and expresses that
a certain relation obtains between Tom and Mary.1 Te predicate 'loves'
can take two designators. I indicate the slots where the singular terms
can be put by dots: Replacing the two strings of dots in the predicate
expression '... loves ...' by designators, respectively, yields a declarative
English sentence.
Here are further examples of other sentences built from predicate
expressions and designators:
Te lecture
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
designator
is boring
´¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¶
predicate
.
Leon
±
designator
sees
°
predicate
the Eiﬀel Tower
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
designator
.
Te tallest student in Oxford
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
designator
gives
±
predicate
his friend
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
designator
the CD
´¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¶
designator
.
Te tallest student in Oxford
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
designator
gives
±
ﬁrst part
of predicate
the CD
´¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¶
designator
to
®
second
part of
predicate
his friend
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
designator
.
Te engineer
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
designator
loosens
´¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¶
ﬁrst part
of predicate
the nut
´¹¹¹¹¹¹¸¹¹¹¹¹¹¹¶
designator
with
±
second
part of
predicate
the wrench
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
designator
.
Te predicates can be simple and consist in just one word, as is '...
sees ...' in the second sentence and '... gives ... ...' in the third; or they
can be formed from two or more words, as is '... is boring' in the ﬁrst
sentence, '... gives ... to ...' in the fourth, and '... loosens ... with ...'
in the last.
1 Te terminology in logic diﬀers here from traditional grammar, where 'loves Mary'
would be the predicate.
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
75
In predicate logic predicate expressions are translated into predicate let-
ters. Tese predicates have an upper index that corresponds to the number
of designators the corresponding English predicate expression can take.
For instance, '... is boring', which can take one designator, is translated
into a predicate letter with upper index 1: P1, for instance, is such a predi-
cate letter. Te predicate '... sees ...' can be translated as Q2 since it can
take two designators, and '... gives ... ...' can be translated as R3 because
it can take three designators. Te upper index (1, 2, 3 here) is called the
predicate letter's 'arity-index'. A predicate letter with upper index n is
called an 'n-place predicate letter'. 1-place predicate letters are also called
'unary', 2-place 'binary' and 3-place 'ternary'. So, the predicate expression
'... loosens ... with ...', for instance, is translated into a ternary predicate
letter.
It is not hard to ﬁnd English sentences that require 4- or 5-place
predicate letters for their formalisation. Tus, I will include predicate
letters with arity-indices for any n in the language L2 of predicate logic
to make sure that there is always a suﬃcient stock of predicate letters
available for the various English predicates.
I will also include 0-place predicate letters in the language L2. Tey
are useful for formalising English sentences like 'It is raining'. It just seems
to be a quirk of the English language that the pronoun 'it' in this sentence
is required; 'it' does not serve the same purpose as the designators in
the sentences I have considered so far; other languages such as Italian
have dispensed with the pronoun in the corresponding sentence. Tus, I
will formalise the sentence 'It is raining' and similar sentences as 0-place
predicate letters. Tis provides the reason for including 0-place predicate
letters in the language L2.
Now that I have dealt with predicates, I will turn to the formalisation
of designators. In the easiest cases the designators are proper names like
'Tom', 'the Eiﬀel Tower', or 'the United Kingdom of Great Britain and
Northern Ireland'; other types of designators will be discussed later. Cor-
responding to the proper names of English, the language L2 of predicate
logic features constants, namely a, b, c, a1, b1, c1, and so on.
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
76
Te example sentence 'Tom loves Mary' from the beginning of the
section can now be translated into the language L2 as
P2ab.
In such sentences, the predicate letter is always put a the beginning of
the sentence. Te predicate letter and the two constants are translated as
follows:
P2:
... loves ...
a:
Tom
b:
Mary
Te order of the constants in P2ab is crucial: P2ba is a formalisation of
'Mary loves Tom', which says something diﬀerent from what 'Tom loves
Mary' says.
In the dictionary, the entry for 'loves' contains two strings of dots.
Tey stand for the places that are taken in the sentence by the designators
'Tom' and 'Mary'. In the corresponding formal sentence P2ab the ﬁrst
place of the binary predicate letter P2 is taken by a, and the second place
is taken by b. Now the ﬁrst string of dots in '... loves ...' corresponds
to the ﬁrst place of P2 and the second string of dots corresponds to the
second place of P2. In order to emphasise this correlation, one can attach
subscripts to the dots:
P2:
. . . 1 loves . . . 2
Tis is tantamount to the translation for P2 given above.
If there are subscripts in the dictionary, the string of dots marked 1 al-
ways corresponds to the ﬁrst place of the predicate letter, the string marked 2
corresponds to the second place of the predicate letter, and so on. Te num-
ber of strings of dots must always correspond to the arity-index of the pred-
icate letter.
Terefore, if I had used
P2:
. . . 2 loves . . . 1
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
77
as the entry for P2, while keeping the entries for a and b unchanged, the
proper translation of 'Tom loves Mary'would be P2ba.
As my next example I consider a sentence with a slightly more com-
plicated predicate: Te sentence
Ebenezer is a scrooge
can be translated into L2 as the sentence R1c, with the following transla-
tion of the predicate letter and the constant:
R1:
... is a scrooge
c:
Ebenezer
Te noun 'scrooge' is not translated separately but forms part of the
predicate '... is a scrooge', which is translated as the predicate letter R1.
Typically, phrases of the form 'is a ...' are translated as predicate letters.
One way to see why '... is a scrooge' can be translated as a simple predicate
letter only, is to observe that instead of 'is a scrooge' one could say 'is
stingy', which obviously can be translated as a unary predicate letter.
Generally, in the language L2 an n-place predicate letter followed by
n constants yields a sentence. Hence, P2ab, that is, a binary predicate
letter followed by two constants, and R1c, that is, a unary predicate letter
followed by one constant, are sentences of L2. 0-place predicate letters
form a sentence without any further symbol: each 0-place predicate letter
is already a sentence. Tus, they behave in the same way as the sentence
letters of the language L1 of propositional logic. In fact, I will identify
the 0-place predicate letters with sentence letters; sentence letters are,
therefore, merely a certain sort of predicate letters.
One can build sentences of the language L2 using connectives in
the same way as in the language L1 of propositional logic. For instance,
(P2ab ∧R1c) is the translation of the following sentence of L2:
Tom loves Mary and Ebenezer is a scrooge.
Te dictionary is the same as above:
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
78
P2:
... loves ...
a:
Tom
b:
Mary
R1:
... is a scrooge
c:
Ebenezer
Te techniques for translation into propositional logic carry over to
predicate logic (see page 65): 'Liz is an Australian mountaineer' can be
rephrased as 'Liz is Australian and Liz is a mountaineer'. Te caveats
explained there also apply to predicate logic.
With the techniques developed so far, certain occurrences of personal
pronouns can be readily translated.
Caesar came, he saw, he won.
Tis can be paraphrased as the following sentence:
Caesar came and Caesar saw and Caesar won.
Te pronouns (or rather their occurrences) in this example are known
as 'lazy' pronouns.2 Using 'he' here saves one the eﬀort of repeating the
name 'Caesar'. Lazy pronouns can easily be eliminated by repeating the
name (or whatever they refer back to), and thus their formalisations do
not pose any special problems.
Tere are other uses of pronouns that cannot easily be dispensed with.
If a politician speaks the truth, he won't be elected.
In this sentence the pronoun 'he' cannot be replaced by 'a politician'. Te
sentence
If a politician speaks the truth, a politician won't be elected
has a diﬀerent meaning; it says that some politician will not be elected if
some politician (not necessarily the same one) speaks the truth. In fact,
the original sentence is equivalent to
2 Tis terminology comes from Geach (1962).
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
79
All politicians speaking the truth are not elected.
In the original sentence 'If a politician speaks the truth, he won't be
elected' the pronoun is used to express a generalisation. Uses of pronouns
for the purpose of generalisation (and some similar purposes) are called
'quantiﬁcational' uses. Quantiﬁcation can be expressed in many diﬀerent
ways in English. Sometimes pronouns are used, and sometimes quantiﬁ-
cation can be expressed without pronouns, as is the case with the sentence
'All politicians speaking the truth are not elected'.
At any rate, the translation of quantiﬁcational uses of pronouns re-
quires additional resources in L2 beyond the ones I have mentioned so
far. Personal pronouns in English come in diﬀerent genders ('he', 'she',
'it'), in diﬀerent cases ('he', 'him', and so on). Tese diﬀerent forms help
to disambiguate sentences. Here is a somewhat tricky case:
If a visitor wants to borrow a book from the library, she is
required to complete the form for it, which must then be
submitted to a librarian, who can grant her permission to
check it out, if it looks satisfactory to him.
In order to make the reference of the various occurrences of the personal
pronouns clearer, one can attach indices to them:
If a visitor1 wants to borrow a book2 from the library, she1 is
required to complete the form3 for it2, which3 must then be
submitted to a librarian4, who can grant her1 permission to
check it2 out, if it3 looks satisfactory to him4.
It is natural to assume that the ﬁrst and second occurrences of 'it' refer
back to 'book', while the third occurrence refers back to 'the form'. Tis
assumption is made explicit by using subscripts. Natural languages oﬀer
other resources for disambiguation, but indexing is a straightforward
method. Since the help of gender etc. is no longer required, when the ref-
erence is made clear by indexing, one can dispense with English pronouns
and replace them with what logicians call variables:
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
80
If a visitor x1 wants to borrow a book x2from the library, x1 is
required to complete the form x3 for x2, which3 must then
be submitted to a librarian x4, who can grant x1 permission
to check x2 out, if x3 looks satisfactory to x4.
In the sentence variables refer back to such phrases as 'a visitor' and 'some
book'. One could introduce expressions corresponding to these phrases
into the formal language. Logicians have found a method to simplify
the language further and to manage with just one additional expression:
Te purpose of expressions such as 'a visitor' is to restrict the focus to
visitors; the above sentence makes a general claim about visitors. But one
can replace this with a general claim about all things (whether they are
persons, animals or inanimate objects). Instead of saying
Every visitor is a classicist,
one can say
If something is a visitor, then it is a classicist
or
For everything1: if it1 is a visitor, then it1 is a classicist.
By substituting variables one obtains:
For all x1, if x1 is a visitor, then x1 is a classicist.
Te last formulation is basically the analysis of typical quantiﬁed state-
ments. 'For all' is translated as the symbol ∀(a rotated 'A' reminding one
of 'all').
'Is a visitor' is a predicate that is translated as P1, while 'is a classicist'
is translated as Q1. So 'x1 is a visitor' is translated as P1x1, and 'x1 is a
classicist' becomes Q1x1. 'If ..., then ...' becomes the arrow, so 'if x1 is a
visitor, then x1 is a classicist' becomes (P1x1 →Q1x1). Tus the sentence
'Every visitor is a classicist' translates into the following L2-sentence:
∀x1(P1x1 →Q1x1).
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
81
In addition to ∀logicians also use the symbol ∃. In the following
sentence an existence claim is made:
At least one visitor is a classicist.
If this is rewritten with variables, then the following expression is ob-
tained:
For at least one x1, x1 is a visitor and x1 is a classicist.
Tis is then formalised as ∃x1(P1x1 ∧Q1x1).
Later, formalisation in predicate logic will be discussed in more detail,
but I have now motivated all elements of the syntax of predicate logic that
will be introduced in the formal deﬁnition of a sentence of L2.
4.2 the sentences of L2
In this section the syntax of L2 is introduced in a formally precise way.
First I turn to predicate letters.
Te language L2 of predicate logic contains 0-place predicate letters.
For simplicity, they do not have an arity-index, that is, an upper index;
they are the sentence letters P, Q, R, P1, Q1, and so on. L2 also contains
predicate letters with arbitrary arity-index 1, 2, 3, and so on. Having only
one binary, that is, 2-place, predicate letter will not suﬃce. In order to
formalise a sentence containing the predicate expressions '... hates ...'
and '... loves ...', one will need two distinct binary predicate letters; and
of course one might also need a third and even more binary predicate
letters. In order to make sure that there is always a suﬃcient stock of
binary predicate letters, I include inﬁnitely many binary predicate letters
in L2, namely the expressions P2, Q2, R2, P2
1 , Q2
1 , R2
1, P2
2, and so on. Tis
applies not only to binary predicate letters but also to predicate letters
with other arity-indices. Tus, the general deﬁnition of predicate letters
looks like this:
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
82
definition 4.1 (predicate letters). All expressions of the form Pk
n, Qk
n,
or Rk
n are sentence letters, where k and n are either missing (no symbol) or
a numeral '1', '2', '3', ...
So the letter P with or without numerals '1', '2', and so on as upper
and/or lower indices is a predicate letter, and similarly for Q and R. Te
sentence letters P, Q, R, P1, Q1, ... are also predicate letters, according to
this deﬁnition. Furthermore, P1, Q1, R1, P1
1, Q1
1, R1
1, P1
2, Q1
2, R1
2, ..., P2
1 , Q2
1 ,
R2
1, P2
2, Q2
2, R2
2, and so on, are predicate letters. Tis deﬁnition ensures
that L2 contains inﬁnitely many n-place predicate letters for any n. Using
only predicate letters with P, but not Q or R, would suﬃce, but having a
choice between letters enables me to generate more readable formulae.
0-place predicate letters (sentence letters) have arity 0; 1-place predi-
cate letters have arity 1, and so on:
definition 4.2. Te value of the upper index of a predicate letter is called
its arity. If a predicate letter does not have an upper index its arity is 0.
Te predicate letter P3
4, for example, has arity 3.
Te language L2 contains constants, which will be used to translate
English proper names and some similar expressions.
definition 4.3 (constants). a, b, c, a1, b1, c1, a2, b2, c2, a3, ...are con-
stants.
Moreover, L2 contains inﬁnitely many variables.
definition 4.4 (variables). x, y, z, x1, y1, z1, x2, ...are variables.
Now the notion of an atomic L2-formula can be deﬁned:
definition 4.5 (atomic formulae of L2). If Z is a predicate letter of
arity n and each of t1, ..., tn is a variable or a constant, then Zt1 . . . tn is
an atomic formula of L2.
In this deﬁnition, the upper case letter Z serves as a metavariable for
predicate letters, that is, for P, R2
45, Q1, and the like. According to this
deﬁnition, Q1x, P2cy, P3
5 x31c4y, and R2xx are examples of atomic formu-
lae. Deﬁnition 4.5 allows for the case in which n = 0. Tis means that all
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
83
sentence letters, that is, P, Q, R, P1, and so on, are also atomic formulae.
definition 4.6. A quantiﬁer is an expression ∀v or ∃v where v is a vari-
able.
Tus, ∀x348 and ∃z are quantiﬁers.3
definition 4.7 (formulae of L2).
(i) All atomic formulae of L2 are formulae of L2.
(ii) If ϕ and ψ are formulae of L2, then ¬ϕ, (ϕ ∧ψ), (ϕ ∨ψ), (ϕ →ψ)
and (ϕ ↔ψ) are formulae of L2.
(iii) If v is a variable and ϕ is a formula, then ∀v ϕ and ∃v ϕ are formulae
of L2.
Examples of formulae of the language L2 of predicate logic are:
∀x (P2xa →Q1x),
∀z77 ¬∃y3 ∃z45(P2xy →∃x2(R4
3z77c3xz77 ∧Q)),
(∃x P1x ↔¬∃y ∃y Q2yy),
∀x ∃z R2az.
Tere is no point in trying to understand these formulae; the point
here is that they all classify as L2-formulae. In order to show that a given
expression is a formula of L2, one can build up the formula step by step
according to the rules laid down in Deﬁnition 4.7. As an example I will
show that the last formula, (∃xP1x ↔¬∃y∃yQ2yy), is a formula of L2:
1. P1 is a predicate letter by Deﬁnition 4.1 with arity 1 (Deﬁnition 4.2),
and x is a variable by Deﬁnition 4.4.
2. Terefore, by Deﬁnition 4.5, P1x is an atomic formula.
3. ∃x P1x is thus a formula of L2 by Deﬁnition 4.7(iii).
4. Similarly, Q2yy is an atomic formula (I will not go through the
tedious reasoning of 1. and 2. again).
3 Tere are alternative symbols for ∀and ∃, which will not be used here: ⋀v, Πv and (v)
are sometimes used instead of ∀v, and ⋁v and Σv instead of ∃v.
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
84
5. ∃y Q2yy is a formula of L2 by 4.7(iii).
6. ∃y ∃y Q2yy is a formula of L2 by 4.7(iii).
7. ¬∃y ∃y Q2yy is a formula of L2 by 4.7(ii).
8. (∃x P1x ↔¬∃y ∃y Q2yy) is a formula of L2 by 4.7(ii). Tis follows
from the previous item and 3.
In cases like this, one will be able to see without a long proof whether an
expression is a formula, and so it will not be necessary to go through all of
these steps. Te above proof of the claim that (∃x P1x ↔¬∃y ∃y Q2yy)
is a formula only shows how exactly the deﬁnition of L2-formulae works.
4.3 free and bound occurrences of variables
In the formula ∀x (P1x →Q1x) the last two occurrences of x refer back
to or depend on the quantiﬁer ∀x. In the formula P1x →Q1x, by contrast,
there is no quantiﬁer to which they can refer back; they occur freely, as
logicians say. In the next deﬁnition this notion of a free occurrence of a
variable is made precise.
definition 4.8.
(i) All occurrences of variables in atomic formulae are free.
(ii) Te occurrences of a variable that are free in ϕ and ψ are also free in
¬ϕ, ϕ ∧ψ, ϕ ∨ψ, ϕ →ψ and ϕ ↔ψ.
(iii) In a formula ∀v ϕ no occurrence of the variable v is free; all occur-
rences of variables other than v that are free in ϕ are also free in
∀v ϕ.
An occurrence of a variable is bound in a formula if and only if it is not
free.
Less formally speaking, occurrences of variables are free as long as
they are not 'caught' by a quantiﬁer. For instance, in the atomic formulae
R2xx or P1x all occurrences of x are free according to clause (i) of the
deﬁnition, and so, according to clause (ii), all occurrences of x are free in
(R2xx∨¬P1x) and in ¬(P1x ↔R2aa). Similarly, all occurrences of x1 are
free in (P1x1 →Q1x1), but, according to clause (iii) of Deﬁnition 4.8, all
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
85
occurrences of x1 are bound in ∀x1 (P1x1 →Q1x1). In ∀y (P1x1 →Q1x1)
all occurrences of the variable x1 are free because y is a variable diﬀerent
from x1.
In ¬(Q1z∧∃z R2zz) the ﬁrst occurrence of the variable z is free, while
the remaining occurrences are bound. In ∀x (R2xy →R2xa) ↔R2ax all
but the last occurrence of x are bound.
definition 4.9. A variable occurs freely in a formula if and only if there
is at least one free occurrence of the variable in the formula.
As pointed out on page 80, ∀x1 (P1x1 →Q1x1) is the formalisation of
the sentence 'Every visitor is a classicist' with the following logical form:
For everything1: if it1 is a visitor, then it1 is a classicist.
Te sentence can be true or false depending on the circumstances. Te
formula (P1x1 →Q1x1) corresponds to
(F) if it1 is a visitor, then it1 is a classicist.
On its own (F) is not a sentence that is true or false: Tere is no quantifying
phrase like 'for everything1' the pronoun 'it1' can refer back to; also, 'it1' is
not a lazy pronoun referring back to a certain designator. Tus, (F) does
not have a truth-value. One can only assign a truth-value to (F), if one
makes an arbitrary choice and takes 'it1' to stand for a particular thing.
But without such an arbitrary choice (F) cannot be assigned a truth-value.
Te L2-formulae behave similarly: only formulae without free occur-
rences of variables are sentences; and only sentences will be assigned
truth-values by L2-structures, which will be introduced in the follow-
ing chapter. Also, sentences but not formulae with free occurrences of
variables will be used as premisses and conclusions in arguments.
definition 4.10 (sentence of L2). A formula of L2 is a sentence of L2
if and only if no variable occurs freely in the formula.
Again informally speaking, in a sentence of L2 all occurrences of
variables are 'caught' by some quantiﬁer. Te following are examples of
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
86
L2-sentences:
∀x (P1x →(Q2
29xa ∨∃x R3xax))
(P2ab ∧∃y(P2by ∧∀x ¬P2xy))
4.4 notational conventions
In Section 2.3 I introduced some conventions for dropping brackets from
sentence of L1. Tese rules did not form part of the oﬃcial syntax of L1;
they merely allow one to abbreviate sentences.
In this section I will specify some rules for abbreviating formulae
of L2. Again, they do not form part of the oﬃcial syntax. Applying the
rules does not yield L2-sentences but rather only abbreviations of L2-
sentences. Like the rules for dropping brackets in L1, the conventions
do not have to be applied: one can always write down the full formula
instead of the abbreviated form.
Te Bracketing Conventions 1-3 apply also to formulae of L2. Te
quantiﬁers have to be taken into account: In the sentence ∃x(P1x ∧Q1x)
the brackets are not outer brackets, so they cannot be dropped. Te
expression ∃x P1x ∧Q1x is an abbreviation of the formula (∃x P1x ∧Q1x),
which is not a sentence, because the second occurrence of x is free.
As a further example I will consider the following L2-sentence:
∀x ((P1x ∧R2
5xa) →∃y2((R2
5xy2 ∧Q1x) ∧P1y2))
(4.1)
Tis sentence may be abbreviated in the following ways:
∀x (P1x ∧R2
5xa →∃y2((R2
5xy2 ∧Q1x) ∧P1y2))
∀x ((P1x ∧R2
5xa) →∃y2(R2
5xy2 ∧Q1x ∧P1y2))
∀x (P1x ∧R2
5xa →∃y2(R2
5xy2 ∧Q1x ∧P1y2))
In the ﬁrst line, Bracketing Convention 3 is applied, in the second Brack-
eting Convention 2, and in the third both conventions are applied. Tere
are no further ways of saving brackets.
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
87
Very ofen the upper index of predicate letters, that is, their arity-
index, is also omitted. Tis is due to the fact that there is only one way to
add these upper indices to the predicate letters of an expression that is
supposed to abbreviate a formula. Terefore, sentence (4.1) also has
∀x ((Px ∧R5xa) →∃y2((R5xy2 ∧Qx) ∧Py2))
as an abbreviation. So, combined with the rules for dropping brackets,
the most economical form of (4.1) is the following abbreviation:
∀x (Px ∧R5xa →∃y2(R5xy2 ∧Qx ∧Py2))
Tus, when the arity-index is missing, this does not necessarily mean
that the predicate letter is a sentence letter: it could be an abbreviation of
another predicate letter from which the arity-index has been omitted.
Abbreviations of formulae that have been obtained by omitting arity-
indices can be misleading: one might think that ∀x ∀y (Px ↔Pxy)
abbreviates an L2-sentence that contains the same predicate letter twice.
Inserting the missing indices, however, shows that the sentence contains
two diﬀerent predicate letters, P1 and P2:
∀x ∀y (P1x ↔P2xy)
Terefore, there is only one occurrence of P1 in the formula and only
one occurrence of P2. Te abbreviation ∀x ∀y (Px ↔Pxy) is correct
according to the above conventions, but in such cases it may be helpful
to retain the arity-indices.
4.5 formalisation
Te basic strategy for obtaining the logical form of an English sentence in
predicate logic is the same as in propositional logic (cf Sections 3.2 and 3.3):
a given sentence is analysed from top to bottom. Tat is, one starts with the
entire sentence and works one's way deeper and deeper into the sentence.
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
88
In contrast to propositional logic, one does not have to stop at quantiﬁed
sentences; one can analyse them in the way outlined in Section 4.1. In
particular, the logical form of universal sentences is obtained in the way
sketched on page 80.
Rather than going over the general rules again, I will show how the
method works by way of some examples. I have already dealt with simple
sentences like 'Tom loves Mary' on page 76, so here I will focus on complex
sentences.
Te following sentence is an example of a universally quantiﬁed sen-
tence, that is, a sentence making a claim about all objects of a certain
sort:
All frogs are amphibians.
First, I will determine its logical form. It is clearly a universal claim that
is to be parsed as outlined on page 80:
For all x (if x is a frog, then x is an amphibian).
Te expression in brackets contains the standard connective 'if ..., then
...', so it can be further parsed as follows:
For all x (if (x is a frog), then (x is an amphibian)).
Both 'x is a frog' and 'x is an amphibian' are enclosed in brackets; they
contain no connectives and are not quantiﬁed. 'Is a frog' and 'is an
amphibian' are then formalised by two distinct predicate letters P1 and Q1,
respectively. So '(x is a frog)' becomes Px (omitting the arity-index);
and 'x is an amphibian' becomes Qx. Te expression 'for all' becomes
the universal quantiﬁer ∀, and 'if ..., then ...', the arrow →. So, the
formalisation is
∀x (Px →Qx),
with the following dictionary:
P:
... is a frog
Q:
... is an amphibian
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
89
Generally, universal claims can be formalised this way. Completely
unrestricted universal claims are rare, but philosophers occasionally do
make claims like the following, that are meant to be completely general:
Everything is material.
Tis sentence can be formalised as ∀x Rx, where R stands for 'is material'.
Existential claims are usually formalised by the existential quanti-
ﬁer; restrictions to a certain kind of objects is expressed by conjunction.
Terefore, 'Tere are poisonous frogs' has the following logical form:
(R) Tere is at least one x ((x is a frog) and (x is poisonous))
Te formalisation is
∃x(Px ∧Q1x)
with the following dictionary:
P:
... is a frog,
Q1:
... is poisonous.
Te English phrase 'No ...is ....' can be taken to be a negated existen-
tial quantiﬁcation. Te sentence
No frog is poisonous.
can be rephrased as
It is not the case that there are poisonous frogs.
'It is not the case that' is a standard connective and it is formalised as ¬. I
have already shown how to go about formalising 'Tere are poisonous
frogs'. So the sentence 'No frog is poisonous' is formalised as the following
sentence, with the same dictionary as above:
¬∃x (Px ∧Q1x)
(4.2)
Alternatively, one could have rephrased the original sentence 'No frog is
poisonous' as the following sentence:
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
90
All frogs are non-poisonous.
Tis formalises into ∀x (Px →¬Q1x). Tis sentence and the alternative
formalisation (4.2) are logically equivalent under the semantics I will
expound in Chapter 5. Both formalisations are equally sound.
Te formalisation of the following sentence requires two quantiﬁers:
Every student has a computer.
Tis is clearly a universal claim; so in the ﬁrst step one obtains:
For all x (if x is a student, then x has a computer).
Tis is not yet the full logical form of the sentence: 'x has a computer'
contains an existential claim and can be further analysed as
there is at least one y (x has y and y is a computer).
Now 'x has y' and 'y is a computer' cannot be further analysed and so
they are put in brackets:
there is at least one y ((x has y) and (y is a computer)).
Tus the full logical form of 'Every student has a computer' is
For all x (if (x is a student), then there is at least one y
((x has y) and (y is a computer))).
Te formalisation is now straightforward:
∀x (Px →∃y(Rxy ∧Qy))
Te dictionary is speciﬁed in the following way:
P:
... is a student
Q:
... is a computer
R:
... has ...
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
91
Generally, the dictionary must provide translations of all sentence letters,
predicate letters and constants occurring in the formalisation. However,
the dictionary must not contain translations for the variables. Variables in
sentences never refer to particular objects; they are only used for making
universal or existence claims.
Here is a somewhat more complicated example:
If it's raining, then Bill reads a book or a newspaper.
(If (it's raining), then there is at least one x ((Bill reads x)
and ((x is a book) or (x is a newspaper))).
Te proper name 'Bill' is translated as a constant; the sentence 'It's raining'
is translated as a sentence letter:
P →∃x (P2ax ∧(Qx ∨Rx)).
I have dropped the outer brackets according to Bracketing Convention 1.
In the dictionary I have restored all arity-indices. In particular, one must
avoid any confusions between the sentence letter (0-place predicate letter)
P and the 2-place predicate letter P2.
P:
it's raining,
Q1:
... is a book,
R1:
... is a newpaper,
P2:
... reads ...
Ternary predicate letters are needed for formalising sentences such as
the following:
Tere is a country between Spain and France.
Te logical form of this sentence is
Tere is at least one x ((x is a country) and (x is between
Spain and France)).
© Volker Halbach
2008/2009

4 Te Syntax of Predicate Logic
92
By formalising this, one obtains the following sentence of predicate logic:
∃x (Px ∧Qxbc).
Te dictionary is as follows:
P:
... is a country
Q:
... is between ... and ...
b:
Spain
c:
France
Using the techniques outlined so far, one can formalise fairly com-
plicated sentences. Tere are, however, some problem cases. Before
discussing more intricate problems of formalisation in Chapter 7, I shall
introduce the semantics of predicate logic. Without having discussed
the semantics of L2 ﬁrst, it would be diﬃcult to judge the soundness of
translations between English and the language L2.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
Discussions in metaphysics and in other areas in philosophy have been
spurred by investigations into semantics. Whereas the semantics of the
language L1 of propositional logic is somewhat crude and philosophically
not very exciting, the semantics of the language L2 of predicate logic
touches upon questions that are at the core of old debates in metaphysics.
In this chapter I shall conﬁne myself to the technical core of the se-
mantics of L2. Te philosophical issues will resurface in later discussions
about translating English sentences into sentences of L2. Te technical
account that I am going to present can be traced back to Tarski (1936) and
subsequent work by Tarski, although I will deviate from Tarski's original
approach in many details and in my notation. Tarski's deﬁnition of truth
had a profound inﬂuence on many areas not only in philosophy, but also
in mathematical logic, linguistics and computer science.
In English, phrases such as 'Paris' or 'Julius Caesar', which are usually
formalised as constants, and predicate expressions such as 'is tired' or
'loves', have ﬁxed meanings. In the language L2 of predicate logic, the
constants and predicate letters will not be assigned ﬁxed meanings. Tis
is not because it is not possible to assign ﬁxed meanings to them, but
rather because the validity of arguments or the property of being logically
true do not depend on the particular meanings of constants and predicate
letters. A sentence of the language L2 will be deﬁned to be logically
true, for instance, if and only if it is true under any interpretation of the
constants and predicate letters. Tus any particular interpretations of
constants and predicate letters do not matter for logical truth. A similar
remark applies to validity: an argument in L2 will be deﬁned to be valid
if and only if there is no interpretation under which the premisses are all
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
94
true and the conclusion is false. Tus, again, the validity of an argument
does not depend on any speciﬁc interpretation we could assign to the
constants and predicate letters.
As in the case of propositional logic, the notion of an interpretation
from Characterisation 1.7 will be made precise by the notion of a structure:
structures provide interpretations for the non-logical, subject-speciﬁc
vocabulary, that is, for predicate letters and constants. Te interpretation
that is assigned to a symbols by a structure is called the 'semantic value'
or the 'extension' of the symbol in the structure.
5.1 structures
Te semantics of the language L2 will be given in the few deﬁnitions
in italics in this chapter. Te bulk of the chapter is only an attempt to
motivate and elucidate these deﬁnitions.
I start by looking back at the semantics of the language L1 of proposi-
tional logic: whether a sentence of the language L1 is true depends on the
truth or falsity of the sentence letters in that sentence. Te truth-values of
all the sentence letters are given by an L1-structure. Ten the truth tables
of the connectives allow one to calculate the truth-values of sentences
formed with connectives.
Structures for predicate logic are more complicated: L2-structures
need to determine more than merely the truth-values of sentence letters
because the language L2 contains also other symbols, namely predicate
letters and constants. L2-structures assign semantic values to these sym-
bols as well. Sentence letters will receive truth-values as their semantic
values in the same way as in propositional logic, but predicate letters will
be assigned semantic values of a diﬀerent kind.
Whether a sentence of L2 is true or false does not only depend on the
semantic values of the constants and the sentence and predicate letters, but
also over which objects the quantiﬁers are taken to range. Tis situation
is similar to English: the truth-value of the English sentence 'All glasses
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
95
are empty' depends in part on whether the expression 'all glasses' is taken
to range only over the glasses on a particular table or in a particular room
or over all glasses in the world. Te sentence is usually uttered when one
is talking about particular glasses.
Tus, one of the things that an L2-structure does is specify a domain
of discourse, which is just some non-empty set of objects. Tere are
no restrictions on the domain of discourse except that it must not be
empty.1 If A is an L2-structure, I will write DA for the structure's domain
of discourse.
In the language L2, constants play a role comparable to proper names
in English, and in English proper names refer to objects: the English
proper name 'Rome' refers to (or 'denotes') the capital of Italy, 'Volker
Halbach' refers to Volker Halbach, and so on. Tus, an L2-structure
assigns elements of the domain of discourse to the constants as their
semantic values.
Sentence letters are treated as in propositional logic: they receive
truth-values, that is, either T or F, as semantic values in an L2-structure.
Hence, an L2-structure contains also an L1-structure.
Unary (1-place) predicate letters correspond to English expressions
such as 'is green', 'walks', or 'is a philosopher'. Unary predicate letters
have sets as their semantic values. Te predicate letter P1, for instance,
can have as its semantic value the set of all green objects (or the set of
all walking objects, or the set of all philosophers, or the empty set). On
page 15, sets were conceived of as unary relations; so predicate letters
have unary relations as semantic values, and an L2-structure must assign
unary relations to unary predicate letters.
1 Empty domains are not allowed in the traditional accounts of semantics for predicate
logic. Admitting the empty domain would make the semantics for L2 more clumsy, but it
is perfectly possible to admit them. From a philosophical point of view it would probably
be more satisfying to admit the empty domain, but I want to avoid the additional
technical complications, and I shall therefore follow the traditional account. Te eﬀects
of the exclusion of the empty domain will be explained below by means of examples.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
96
Binary predicate letters correspond to expressions such as 'loves' or
'is bigger than'. Binary predicate letters are interpreted by binary relations,
that is, by sets of ordered pairs. Te predicate letter P2, for instance, can
have the relation of loving, that is, the set of all ordered pairs ⟨d, e⟩such
that d loves e, as its semantic value. Tus, an L2-structure must assign
binary relations to binary predicate letters as their semantic values.
Analogously, 3-place predicate letters are interpreted by 3-place rela-
tions, that is, sets of triples, and generally predicate letters with arity n
are assigned n-ary relations (see Section 1.4).
In the following list I summarise which objects are assigned to expres-
sions of L2 by an L2-structure as their semantic values or 'extensions'.
L2-expression
semantic value
constant
object
sentence letter
truth-value
unary predicate letter
set, unary relation
binary predicate letter
binary relation
(= set of ordered pairs)
predicate letter of arity 3
3-place relation
(= set of triples)
⋮
⋮
In sum, an L2-structure speciﬁes a non-empty set as domain of dis-
course, it assigns elements of the domain to constants, it assigns a truth-
value to every sentence letter, and it assigns an n-ary relation to every
predicate letter.
Te deﬁnition of an L2-structure can be spelled out more precisely
in technical terms. I mention this deﬁnition only for the sake of those
readers who want the full story. I shall not make use of this deﬁnition in
what follows.
definition 5.1 (L2-structure). An L2-structure is an ordered pair ⟨D, I⟩
where D is some non-empty set and I is a function from the set of all con-
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
97
stants, sentence letters and predicate letters such that the value of every con-
stant is an element of D, the value of every sentence letter is a truth-value
T or F, and the value of every n-ary predicate letter is an n-ary relation.
One might wonder why variables are not mentioned in the deﬁnition
of an L2-structure. But just as 'he' does not stand for a particular object
in the general claim 'If a reader is perplexed, he stops reading', a bound
variable does not stand for a particular object in a sentence of L2. For this
reason, L2-structures do not assign semantic values to variables.
For technical reasons, however, it is convenient to have semantic
values not only for sentences but also for formulae with occurrences of
free variables. Formulae with occurrences of free variables will also be
assigned truth-values as semantic values. Whether a formula like P1x
with an occurrence of a free variable will receive the truth-value T or F
depends on what the variables stand for in the same way 'He stops reading'
is true or false for some persons but not for others. More than one variable
may occur freely in a formula of L2: whether the formula R2xy ∧R1z
receives the truth-value T or F depends on what the variables x, y, and
z stand for. In addition to L2-structures, I therefore introduce a list that
assigns an object to every variable of L2. Tis list aﬀects only the truth or
falsity of formulae with occurrences of free variables, but it does not aﬀect
the truth or falsity of sentences (that is, formulae with no free variables).
A variable assignment over an L2-structure A assigns to each variable
an element of the domain DA of A.2 Occasionally I will drop the speciﬁ-
cation 'over the L2-structure A', when it is clear from the context which
L2-structure is meant.
One may think of a variable assignment as a table with two lines
that has all variables as entries in the ﬁrst line line, and elements of the
domain of discourse as entries in the other line. For instance, there is a
variable assignment α over an L2-structure with the set of all European
2 More formally, one can take a variable assignment over D to be a function from the set
of all variables into D.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
98
cities as domain, that assigns Rome to x, y1, and z1, Paris to y, Berlin to
z, London to x1, Oslo to x2. Te assignment α assigns elements to all
further variables, but of course I cannot specify an inﬁnite list here. Te
beginning of the variable assignment α may be visualised as follows:
x
y
z
x1
y1
z1
x2
Rome
Paris
Berlin
London
Rome
Rome
Oslo ⋯
An L2-structure A and a variable assignment over A together assign
semantic values to every variable, constant, sentence letter, and predicate
letter. I will write ∣e∣α
A for the semantic value of the expression e in the
L2-structure A under the variable assignment α over A. Tus, for any L2-
structure A and any variable assignment α over A the semantic values of
the respective L2-expressions are as follows:
(i) For any constant t, ∣t∣α
A is the object in the domain DA of A assigned
to t by A.
(ii) For any variable v, ∣v∣α
A is the object in DA assigned to the variable v
by the variable assignment α.
(iii) For any sentence letter Φ, ∣Φ∣α
A is the truth-value (either T or F)
assigned to Φ by A.
(iv) For any unary predicate letter Φ, ∣Φ∣α
A is the unary relation, that is,
the set, assigned to Φ by A.
(v) For any binary predicate letter Φ, ∣Φ∣α
A is the binary relation, that
is, the set of ordered pairs, assigned to Φ by A.
(vi) For any 3-ary predicate letter Φ, ∣Φ∣α
A is the 3-ary relation, that is,
the set of ordered triples, assigned to Φ by A.
And so on for predicate letters of higher arity.3
3 Terefore, if A is the ordered pair ⟨D, I⟩, then for all constants, and sentence and
predicate letters Φ, ∣Φ∣α
A = I(Φ). Tis is what is expressed by (i) and (iii)-(vi).
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
99
5.2 truth
Te function ∣. . . ∣α
A gives semantic values for all variables, constants, sen-
tence letters, and predicate letters. In this section, ∣. . . ∣α
A will be extended
to cover complex formulae as well, that is, formulae that are not mere
sentence letters.
Te deﬁnition in which truth values are assigned to formulae with
connectives and quantiﬁers will be inductive. Tat is, ﬁrst I shall de-
ﬁne ∣. . . ∣α
A for atomic formulae (Deﬁnition 4.5), and then I shall deﬁne
the semantic values of formulae containing connectives and quantiﬁers.
Any formula of L2 is either true or false in an L2-structure A under a
variable assignment α over the L2-structure A. Tus, for any formula ϕ
either ∣ϕ∣α
A = T or ∣ϕ∣α
A = F obtains (but not both). ∣ϕ∣α
A = T is ofen read
as 'α satisﬁes ϕ in A'.4 Tis use of the term 'satisﬁes' is motivated by its
use in ﬁgures of speech like 'the property of being red is satisﬁed by the
apple' or 'the equation x2 = y is satisﬁed by 3 and 9'; the only diﬀerence
is that α is not a single object but rather an entire sequence of objects
providing semantic values for all variables.
Te truth-value of atomic formulae, that is, of sentences such as P1b or
R2xc, is deﬁned in the following way: P1b, for instance, is true if and only
if the object assigned to b is in the extension (semantic value) of P1, that
is, if ∣b∣α
A is an element of the set ∣P1∣α
A. Similarly, R2xc is true if and only
if the ordered pair ⟨∣x∣α
A, ∣c∣α
A⟩, that is, the ordered pair with the value of x
as its ﬁrst component and the extension of c as its second component,
is in the extension of R2, that is, in the relation ∣R2∣A. Terefore, the
variable assignment α impinges on the truth-values of formulae with
free occurrences of variables, such as R2xc, because ∣x∣α
A is given by the
variable assignment α.
In the sentence P1a the unary predicate letter P1 receives a unary
relation, that is, some set, as its extension (semantic value). I shall assume
4 Many authors prefer to write A ⊧ϕ[α] or something similar to express that α satisﬁes
the formula ϕ in A.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
100
that ∣P1∣α
A is the set {Rome, London, Paris} and ∣a∣α
A is Rome. On that
assumption, P1a is true because Rome is in the set {Rome, London, Paris},
that is, ∣a∣α
A ∈∣P1∣α
A. Te case of unary predicate letters is covered by
the following clause because ∣a∣α
A is the same as ⟨∣a∣α
A⟩according to the
assumption on page 15 where it has been stipulated that d and ⟨d⟩are the
same for any object d.
(i) ∣Φt1 . . . tn∣α
A = T if and only if ⟨∣t1∣α
A, . . . , ∣tn∣α
A⟩∈∣Φ∣α
A, where Φ is an
n-ary predicate letter (n must be 1 or higher), and each of t1, ..., tn
is either a variable or a constant.
Tus, this clause determines whether a variable assignment satisﬁes a
formula like P1a, P1x, R2xy, or Q3xcy in a structure.
If a formula is built up by means of connectives from other sentences,
then truth-values can be assigned to this formula in the style of the De-
ﬁnition 2.6 of truth in an L1-structure: for instance, if the L2-formulae
ϕ and ψ both have semantic value T, then the formula ϕ ∧ψ should also
have truth-value T; otherwise it should have F as its extension (semantic
value). Tus, a variable assignment α satisﬁes the formula ϕ ∧ψ in an
L2-structure, if and only if α satisﬁes ϕ and ψ in that structure. Similarly
a variable assignment α satisﬁes a formula ¬ϕ in an L2-structure, if and
only if α does not satisfy ϕ itself in the structure. Tis can be expressed
more formally by the following two deﬁnitional clauses:
(ii) ∣¬ϕ∣α
A = T if and only if ∣ϕ∣α
A = F.
(iii) ∣ϕ ∧ψ∣α
A = T if and only if ∣ϕ∣α
A = T and ∣ψ∣α
A = T.
Te clauses (iv)-(vi) for the remaining three connectives ∨, →, and ↔are
similar and will be listed below.
It remains to deﬁne the semantic value, that is, the truth-value, of
quantiﬁed formulae from the semantic values of shorter formulae. Tat
is, I want to ﬁnd clauses analogous to (i) and (ii) for quantiﬁers. As an
example I consider the following L2-sentence:
∃x Rxy
When should a variable assignment α satisfy this formula in a structure A?
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
101
Assume, for instance, that the variable assignment α looks like this:
x
y
z
x1
y1
z1
x2
Rome
Paris
Berlin
London
Rome
Rome
Oslo ⋯
In this case ∣y∣α
A is Paris.
Assuming that R is translated as '... is smaller than ...', the formula
∃x Rxy corresponds to the English phrase 'Tere is something smaller
than it'. Te pronoun 'it' plays the role of the variable y that occurs freely
in ∃x Rxy. Now 'Tere is something smaller than it' is satisﬁed by Rome
(which is assigned to y by α) if there is something smaller than Rome,
that is, if there is something (for 'it1') satisfying 'it1 is smaller than it2'
when 'it2' is taken to stand for Rome.
One can express this more precisely and perspicuously in terms of
variable assignments for the formal language L2: the variable assignment
α satisﬁes ∃x Rxy if and only if there is a variable assignment β satisfying
Rxy that diﬀers from α at most in what is assigned to x. Tere is such
a variable assignment β, assuming that ∣R∣α
A is a relation containing the
pair ⟨Oslo, Rome⟩:
x
y
z
x1
y1
z1
x2
Oslo
Paris
Berlin
London
Rome
Rome
Oslo ⋯
Tis variable assignment diﬀers from α only in the entry for x. Since
there is such a variable assignment, α satisﬁes the formulae ∃xRxy (in a
structure A where ⟨Oslo, Rome⟩is an element of the extension ∣R∣α
A of
R).
Of course the variable assignment β must not diﬀer in the entry for
y, as the question is whether the variable assignment α satisﬁes ∃xRxy,
that is, whether ∃xRxy is true when y is taken to stand for Rome.
Generally, a variable assignment α satisﬁes a formula ∃xϕ if and only
if there is a variable assignment β satisfying ϕ that diﬀers from α only
in the entry for x. ϕ may have free occurrences of other variables than
y; for this reason β must agree with α on all variables with the possible
exception of x.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
102
So I deﬁne for all variables v and formulae ϕ:
(viii) ∣∃v ϕ∣α
A = T if and only if ∣ϕ∣β
A = T for at least one variable assign-
ment β over A diﬀering from α in v at most.
By saying that α diﬀers from β in v at most, I mean that ∣u∣α
A = ∣u∣β
A
for all variables u with the possible exception of v. Hence, in terms of
tables, a variable assignment α and a variable assignment β diﬀer in a
given variable v at most, if the they agree in all columns with the possible
exception of the column for the variable v. Te two tables above are an
example of two variable assignments diﬀering in x.
Universal quantiﬁers can be treated in a similar way. When should
one say, for instance, that a variable assignment α satisﬁes the formula
∀y (Rxy ∧Ryz) in a structure A? Tat is, when should the following
obtain?
∣∀y (Rxy ∧Ryz)∣α
A = T
∀y expresses generality. α will satisfy ∀y (Rxy ∧Ryz) in A if and only
if everything in the domain of A will make Rxy ∧Ryz true if it is taken
to stand for y (with the values of x and z unchanged from α). Tus, α
satisﬁes ∀y (Rxy ∧Ryz) in A if and only if every β that diﬀers from α
only in y satisﬁes Rxy ∧Ryz in A.
Tis can be generalised to all variables v and L2-formulae ϕ: a variable
assignment α satisﬁes a formula ∀vϕ in a structure A if and only if every
variable assignment β that diﬀers from α at most in v satisﬁes ϕ. Of course,
only variable assignments over A are considered: the variable assignments
can only assign objects from the domain of A to the variables.
Te general clause can now be stated as follows:
(vii) ∣∀v ϕ∣α
A = T if and only if ∣ϕ∣β
A = T for all variable assignments β
over A diﬀering from α in v at most.
I will now collect the diﬀerent clauses into a deﬁnition of satisfaction.
Given an L2-structure, this deﬁnition determines for any variable assign-
ment α and any L2-formula whether α satisﬁes ϕ in A, that is, whether
∣ϕ∣α
A = T or ∣ϕ∣α
A = F.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
103
definition 5.2 (satisfaction). Assume A is an L2-structure, α is a vari-
able assignment over A, ϕ and ψ are formulae of L2, and v is a variable.
For a formula ϕ either ∣ϕ∣α
A = T or ∣ϕ∣α
A = F obtains. Formulae other than
sentence letters then receive the following semantic values:
(i) ∣Φt1 . . . tn∣α
A = T if and only if ⟨∣t1∣α
A, . . . , ∣tn∣α
A⟩∈∣Φ∣α
A, where Φ is a
n-ary predicate letter (n must be 1 or higher), and each of t1, ..., tn
is either a variable or a constant.
(ii) ∣¬ϕ∣α
A = T if and only if ∣ϕ∣α
A = F.
(iii) ∣ϕ ∧ψ∣α
A = T if and only if ∣ϕ∣α
A = T and ∣ψ∣α
A = T.
(iv) ∣ϕ ∨ψ∣α
A = T if and only if ∣ϕ∣α
A = T or ∣ψ∣α
A = T.
(v) ∣ϕ →ψ∣α
A = T if and only if ∣ϕ∣α
A = F or ∣ψ∣α
A = T.
(vi) ∣ϕ ↔ψ∣α
A = T if and only if ∣ϕ∣α
A = ∣ψ∣α
A.
(vii) ∣∀v ϕ∣α
A = T if and only if ∣ϕ∣β
A = T for all variable assignments β
over A diﬀering from α in v at most.
(viii) ∣∃v ϕ∣α
A = T if and only if ∣ϕ∣β
A = T for at least one variable assign-
ment β over A diﬀering from α in v at most.
In general, what α assigns to variables not occurring freely in a formula
ϕ does not impinge on whether α satisﬁes ϕ in A. So, if ∣ϕ∣α
A = T, and if
β is a variable assignment diﬀering from α only in variables that do not
occur freely in ϕ, then also ∣ϕ∣β
A = T. In particular, the variable v does
not occur freely in a formula of the form ∃v ψ. Tus, α satisﬁes ∃v ψ in
A independently of what α assigns to the variable v. A similar remark
applies to formulae with a universal quantiﬁer.
If ϕ is a sentence, that is, if no variable occurs freely in ϕ then ∣ϕ∣α
A
does not depend on the variable assignment α at all at all. Hence, if
ϕ is a sentence, then ∣ϕ∣α
A is the same truth value as ∣ϕ∣β
A for all variable
assignments β over A.
In order to simplify the notation one may drop the index for the
variable assignment and write ∣ϕ∣A if ϕ is a sentence. In general, one can
drop the variable assignment when the semantic value is the same for
all variable-assignments. Tis is the case for constants, sentence letters,
predicate letters, and sentences.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
104
Truth in an L2-structure is now deﬁned in terms of satisfaction:
definition 5.3 (truth). A sentence ϕ is true in an L2-structure A if and
only if ∣ϕ∣α
A = T for all variable assignments α over A.
As pointed out above, the truth-value of a sentence in a structure is the
same for all variable assignments. Terefore, if a sentence is satisﬁed (in a
structure) by some variable assignment, it will be satisﬁed by all variable
assignments. Consequently, a sentence ϕ is true in an L2-structure A if
and only if ∣ϕ∣α
A = T for at least one variable assignment α over A.
Te Deﬁnition 5.3 of truth has generated and continues to generate
extensive discussion. Te views on its philosophical value diﬀer wildly.
At any rate, Deﬁnition 5.3 has been a big success as a tool in philosophy,
mathematics, computer science and linguistics. Te extent to which this
deﬁnition can also be adapted to natural languages such as English is also
a matter of some controversy.
As an example I will consider a speciﬁc L2-structure, which I call E.
Its domain of discourse is the set of all European cities. It assigns the
set {Florence, Stockholm, Barcelona} to Q1, the relation of being smaller
than to R2, Florence to a, and London to b. Tis information can be
displayed in the following way:
∣Q1∣E = {Florence, Stockholm, Barcelona},
∣R2∣E = {⟨d, e⟩∶d is smaller than e },
∣a∣E = Florence,
∣b∣E = London.
Tus, ∣R2∣E is the set {⟨Florence, London⟩, ⟨Florence, Birmingham⟩,...}.
I have dropped the index for the variable assignment and written ∣Q1∣E
rather than ∣Q1∣α
E since variable assignments do not aﬀect the semantic
values of predicate letters and constants.5
example 5.4. Te sentence R2ab is true in E.
5 What is assigned to other constants, sentence and predicate letters is irrelevant for the
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
105
Proof. Since Florence is smaller than London, the pair ⟨Florence, London⟩
is an element of the relation of being smaller than, and I can reason as
follows (the comments to the right explain what justiﬁes the proof step
on the lef):
⟨Florence, London⟩∈{⟨d, e⟩∶d is smaller than e }
⟨∣a∣E, ∣b∣E⟩∈∣R2∣E
deﬁnition of E
∣R2ab∣E = T
Deﬁnition 5.2(i)
Tis shows that R2ab is true in E.
example 5.5. Te sentence ∀x (Q1x →R2xb) is true in E.
Proof. Let α be an arbitrary variable assignment. I distinguish two cases.
First case: ∣x∣α
E is in ∣Q1∣E, that is, ∣x∣α
E is either Florence, Stockholm, or
Barcelona. As all three cities are smaller than London, and ∣b∣E is London,
one has the following:
⟨∣x∣α
E, ∣b∣E⟩∈∣R2∣E
∣R2xb∣α
E = T
Deﬁnition 5.2(i)
∣Q1x →R2xb∣α
E = T
Deﬁnition 5.2(v)
Second case: ∣x∣α
E is not in ∣Q1∣E. In this case one can proceed as
follows:
∣x∣α
E is not in ∣Q1∣E
∣Q1x∣α
E = F
Deﬁnition 5.2(i)
∣Q1x →R2xb∣α
E = T
Deﬁnition 5.2(v)
following. For the sake of deﬁniteness, I could stipulate that E assigns the empty set
as extension to all predicate letters other than Q1 and R2, T to all sentence letters, and
Rome to all constants other than a and b.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
106
Terefore, in both cases, that is, for every variable assignment α over E,
the following obtains:
∣Q1x →R2xb∣α
E = T.
Consequently, according to Deﬁnition 5.2(vii), ∣∀x (Q1x →R2xb)∣β
E = T
for every variable assignment β. Hence, by Deﬁnition 5.3, the sentence
∀x (Q1x →R2xb) is true in E.
Te ﬁnal example sentence contains two quantiﬁers.
example 5.6. Te sentence ∀x ∃y (R2xy ∨R2yx) is true in E.
Proof. Let α be an arbitrary variable assignment over E.
First case: ∣x∣α
E is not London (the largest city in Europe). Ten change
the entry for y into London (if it is not already London) and call the
resulting variable assignment β. By deﬁnition, β diﬀers from α in y at
most. Since every European city except London itself is smaller than
London, one has the following:
⟨∣x∣β
E, ∣y∣β
E⟩∈∣R2∣E
∣R2xy∣β
E = T
Deﬁnition 5.2(i)
∣R2xy ∨R2yx∣β
E = T
Deﬁnition 5.2(iv)
∣∃y (R2xy ∨R2yx)∣α
E = T
Deﬁnition 5.2(viii)
Te last line holds because β diﬀers from α at most in y.
Second case: ∣x∣α
E is London. Change the entry for y in α into Florence
(or any other European city smaller than London), and call this variable
assignment β; it diﬀers from α only in y. Te ﬁrst of the following lines
holds because ∣y∣β
E is Florence, which is smaller than ∣x∣α
E, that is, London:
⟨∣y∣β
E, ∣x∣β
E⟩∈∣R2∣E
∣R2yx∣β
E = T
Deﬁnition 5.2(i)
∣R2xy ∨R2yx∣β
E = T
Deﬁnition 5.2(iv)
∣∃y (R2xy ∨R2yx)∣α
E = T
Deﬁnition 5.2(viii)
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
107
Te last line holds, because α diﬀers from β in y at most.
Terefore, I have proved that ∣∃y(R2xy∨R2yx)∣α
E = T for any variable
assignment α over E. According to Deﬁnition 5.2(vii) this implies by that
∣∀x∃y (R2xy ∨R2yx)∣E = T,
which shows that the sentence is true in E.
In practice hardly anyone will go through all these steps explicitly.
Te foregoing examples should have illustrated how the semantics for
the language of predicate logic works and how the truth or falsity of all
sentences is determined by an L2-structure.
5.3 validity, logical truths, and contradictions
With the deﬁnition of truth in hand one can now deﬁne such notions as
logical truth, contradiction, the validity of an argument, and so on. Te
following deﬁnition is analogous to Deﬁnition 2.7 for propositional logic.
definition 5.7.
(i) A sentence ϕ of L2 is logically true if and only if ϕ is true in all L2-
structures.
(ii) A sentence ϕ of L2 is a contradiction if and only if ϕ is not true in
any L2-structure.
(iii) A sentence ϕ and a sentence ψ are logically equivalent if both are
true in exactly the same L2-structures.
(iv) A set Γ of L2-sentences is semantically consistent if and only if there
is an L2-structure A in which all sentences in Γ are true. As in propo-
sitional logic, a set of L2-sentences is semantically inconsistent if and
only if it is not semantically consistent.
Also, the deﬁnition of validity of an argument in L2 follows the pattern
set out in the deﬁnition of validity of an argument in propositional logic,
that is, in Deﬁnition 2.9.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
108
definition 5.8. Let Γ be a set of sentences of L2 and ϕ a sentence of L2.
Te argument with all sentences in Γ as premisses and ϕ as conclusion is
valid if and only if there is no L2-structure in which all sentences in Γ are
true and ϕ is false.
Tis just captures the intuitive idea that an argument is valid if and
only if any L2-structure that makes the premisses true also makes the
conclusion true.
Tat the argument with all sentences in Γ as premisses and ϕ as con-
clusion is valid, is abbreviated as Γ ⊧ϕ. Instead of Γ ⊧ϕ one can also say
'ϕ follows from Γ'. Te symbol ⊭is the negation of ⊧; so, it is deﬁned as
follows: Γ ⊭ϕ if and only if not Γ ⊧ϕ.
I have not excluded the possibility that there is not premiss at all in
an argument. So, Γ may be the empty set. If Γ is the empty set and Γ ⊧ϕ,
one may also simply write ⊧ϕ. As I have said above, Γ ⊧ϕ means that
ϕ is true in all L2-structures in which all sentences in Γ are true. Now if
there are no sentences in Γ, one has Γ ⊧ϕ if and only if ϕ is true in all
structures. Consequently, ⊧ϕ means that ϕ is true in all L2-structures
tout court; that is, it means that ϕ is logically true.
I introduce a further notational convention, already adopted for propo-
sitional logic: When the sentences in Γ are written out explicitly, the set
brackets around the sentences may be dropped: For instance, one may
write
∀x Qx, ∀x (Qx →Rx) ⊧∃x Rx
rather than the following:
{∀x Qx, ∀x (Qx →Rx)} ⊧∃x Rx.
5.4 counterexamples
How can one show that an argument in is valid? And how can one show
that it is not valid?
For the language L1 of propositional logic, these question are usually
easily answered (if there are not too many or too long sentences involved):
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
109
One can check out whether an argument in L1 is valid by means of a truth
table.
Generally, in the language L2, it is much harder to show that an
argument is valid or not. Tere is not a ﬁnite set of possibilities one
can check out in order to ﬁnd out whether an argument is valid or not.
Tere are inﬁnitely many domains of discourse, and even a single binary
predicate letter can be interpreted by inﬁnitely many binary relations.
Showing that an L2-argument is valid by proving that the conclusion is
true in all L2-structures in which all the premisses are true is, therefore,
usually a diﬃcult task. A more eﬃcient and elegant way of establishing
that an argument in L2 is valid will be introduced in the next chapter.
In order to show that an argument is not valid, however, one does
not have to prove something about all L2-structures; one has only to ﬁnd
an L2-structure in which all premisses of the argument are true and its
conclusion is false. Such L2-structures are called counterexamples. In
this section I will explain how to use counterexamples to disprove the
validity of arguments.
An L2-structure A is a counterexample to an argument if and only if
all premisses of the argument are true in A and the conclusion is false in A.
As explained above, a sentence is logically valid if and only if the
argument with no premisses and the sentence as its conclusion is valid.
Tus, one can use counterexamples to show that a sentence is not logically
true:
An L2-structure is a counterexample to an L2-sentence if the sentence
is not true in it. An L2-sentence is logically true if and only if there are no
counterexamples to it.
I will prove the following claim by means of a counterexample.
example 5.9. Te sentence Qb →∀x Qx is not logically true.
In order to ﬁnd a counterexample to this sentence, one could reason
informally as follows: b could satisfy Q, but other objects might not
satisfy Q and thus ∀x Qx would be false. One can turn this into a proof.
First, an L2-structure with a domain of discourse containing at least two
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
110
objects is required. And then, the object that is the semantic value of b
needs to be in the set that is the semantic value of Q, while one of the
other objects is not in this set. Now this can be turned into a proper proof
of the claim that Qb →∀x Qx is not logically true:
Proof. Let B be an L2-structure with the set {1, 2} as its domain of dis-
course and the following semantic values for Q and b:6
∣Q∣B = {1},
∣b∣B = 1.
I will now show that Qb →∀x Qx receives the semantic value F
in this L2-structure. Let α be the variable assignment that assigns 2 to
every variable, so ∣x∣α
B = 2. Now one can reason as follows, using ∉as an
abbreviation for 'is not an element of':
2 /∈{1}
∣x∣α
B /∈∣Q∣B
deﬁnition of α and B
∣Qx∣α
B = F
Deﬁnition 5.2(i)
∣∀x Qx∣α
B = F
Deﬁnition 5.2(vii)
1 ∈{1}
∣b∣B ∈∣Q∣B
deﬁnition of B
∣Qb∣α
B = T
Deﬁnition 5.2(i)
∣Qb →∀x Qx∣α
B = F
Deﬁnition 5.2(v)
By the Deﬁnition 5.3 of truth, Qb →∀x Qx is not true in B and thus,
according to Deﬁnition 5.7(i), Qb →∀x Qx is not logically true.
6 For the sake of deﬁniteness I should specify also the value of other constants, sentence
and predicate letters. But as they do not make a diﬀerence to the truth-values of sentences,
I will not specify them in this and the following examples.
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
111
In order to show that Qb →∀x Qx is not logically true, I could have
employed objects other than the numbers 1 and 2. Te two numbers are
convenient because of their short names. Tere is no need to use more
fancy objects. Generally, it is sensible to keep things simple by choosing
small domains of discourse. In some cases, however, it may be necessary
to use large domains; there are even cases where the domain has to be
inﬁnite.
Next I will turn to an argument.
example 5.10. ∀x ∃y Rxy ⊭∃y ∀x Rxy.
Te premiss could be the translation of a sentence such as 'For every-
thing there is something with the same mass'; the conclusion would then
be the translation of 'Tere is something that has the same mass as any
object'. If there are exactly two things diﬀering in mass, then 'For every-
thing there is something with the same mass' is true, because every object
agrees with itself in its mass, and the conclusion is false, because the mass
of neither of the two objects matches the mass of the other object. Hence,
one can use an L2-structure with a domain containing exactly two objects.
R needs to have a relation as extension that relates every object to itself
but not to the other object in the domain.
Proof. Te L2-structure C is deﬁned as follows:
DC = {the sun, the moon},
∣R∣C = {⟨the sun, the sun⟩, ⟨the moon, the moon⟩}.
First I will show that the premiss is true in the L2-structure C. Let α be
an arbitrary variable assignment over C. Ten change the value of x so
that the values of x and y are the same, that is, change the entry for x into
the sun if ∣y∣α
C is the sun and into the moon if ∣y∣α
C is the moon; call the
resulting variable assignment β. Te ﬁrst line in the following proof, then,
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
112
holds in virtue of the deﬁnition of ∣R∣C, and because ∣x∣β
C = ∣y∣β
C.
⟨∣x∣β
C, ∣y∣β
C⟩∈∣R∣C
∣Rxy∣β
C = T
Deﬁnition 5.2(i)
∣∃y Rxy∣β
C = T
Deﬁnition 5.2(viii)
∣∀x ∃y Rxy∣α
C = T
Deﬁnition 5.2(vii)
Te last line holds because the foregoing reasoning applies to all variable
assignments α. Hence, the premiss is true in C.
It remains to show that the conclusion is false in C. Assume to the
contrary that ∃y ∀x Rxy is true in C. Ten, by Deﬁnition 5.2(viii), there
is a variable assignment α such that the following holds:
∣∀x Rxy∣α
C = T.
Tus, by Deﬁnition 5.2(vii),
∣Rxy∣β
C = T
for every variable assignment β that diﬀers from α at most in x. But this
is not the case since one can choose a variable assignment β such that
∣x∣β
C is diﬀerent from ∣y∣β
C and so ⟨∣x∣β
C, ∣y∣β
C⟩is not in ∣R∣C.
Since the premiss is true in C and the conclusion is false in C, the
argument is not valid.
example 5.11. ∀x (Px →Qx ∨Rx), Pa ⊭Ra.
To motivate the counterexample below one can reason as follows: Te
premiss Pa must be true in the counterexample, call it D, so ∣a∣D must
be in ∣P∣D. Te premiss ∀x(Px →Qx ∨Rx) therefore implies that ∣a∣D is
either in ∣Q∣D or in ∣R∣D. So if the premiss is to be true at least one of the
latter must be the case. As the conclusion Ra must be false, ∣a∣D must
not be in ∣R∣D, and, therefore, ∣a∣D must be an element of ∣Q∣D. So, one
can employ a counterexample with a single object in its domain, where
that object is in the extensions of P and Q while the extension of R is the
empty set:
© Volker Halbach
2008/2009

5 Te Semantics of Predicate Logic
113
Proof. Te following L2-structure is a counterexample:
DD = {1},
∣a∣D = 1,
∣P∣D = {1},
∣Q∣D = {1},
∣R∣D = ∅.
Tere is only one variable assignment over D because its domain DD
contains only one object and every variable is assigned the number 1.
Terefore, ∣x∣α
D = 1 for all variable assignments α. To show that the ﬁrst
premiss is true, one can reason as follows:
1 ∈{1}
∣x∣α
D ∈∣Q∣D
deﬁnitions of α and D
∣Qx∣α
D = T
Deﬁnition 5.2(i)
∣Qx ∨Rx∣α
D = T
Deﬁnition 5.2(iv)
∣Px →Qx ∨Rx∣α
D = T
Deﬁnition 5.2(v)
Since this holds for all variable assignments over D, as α is the only such
variable assignment, ∀x (Px →Qx ∨Rx) is true in D.
Te second premiss is also true in D:
1 ∈{1}
∣a∣D ∈∣P∣D
deﬁnitions of D
∣Pa∣D = T
Deﬁnition 5.2(i)
Te conclusion, however, is false in D:
1 ∉∅
∣a∣D ∉∣R∣D
deﬁnitions of D
∣Ra∣D = F
Deﬁnition 5.2(i)
Tis shows that both premisses are true and that the conclusion is false in
D. Terefore, the argument is not valid.
© Volker Halbach
2008/2009

6 Natural Deduction
A valid argument need not be obviously valid. One can establish the
validity of such an argument by breaking it into smaller arguments and by
showing that one can pass from the premisses to the conclusion through
a sequence of small and obvious steps. Tat is, one proves the conclusion
from the premisses via intermediate conclusions: the original premisses
are used to derive obvious conclusions, which in turn are employed in the
next step as premisses to derive further conclusions, and so on, until the
original conclusion is obtained. Such a sequence of obvious arguments is
called a 'proof'.
Whether a step is obvious depends on the perspective. However,
one might try to show that there is a ﬁxed list of simple proof rules
that are suﬃcient for establishing the validity of any valid argument.
Te rules should be formulated in a way that makes it easy to check
whether any given step in a proof conforms to one of these rules. If a set
rules that can be used in proofs is ﬁxed, then there cannot be a serious
disagreement about the admissibility of any given step in a proof, and
there is an objective notion of proof.
For the languages L1 and L2 of propositional and of predicate logic
one can provide such a list of admissible rules that legitimate steps in a
proof.
It is obvious for which arguments there should be proofs: ﬁrst, there
should be proofs for valid arguments only. Formally speaking, it must not
be possible to pass from the premisses in a set Γ to a sentence ϕ, if it is not
the case that Γ ⊧ϕ. Te rules must be sound in this sense. Second, the
proof rules should be complete in the sense that there should be proofs
for all valid arguments: if Γ ⊧ϕ, then it should be possible to reach ϕ
© Volker Halbach
2008/2009

6 Natural Deduction
115
from the premisses in Γ by going through proof steps that conform to the
rules for proofs.
In order to show that Γ ⊧ϕ, one can then simply give a proof rather
than argue using L2-structures as in the previous chapter. Tis will greatly
facilitate establishing the validity of arguments in predicate logic.
Logicians have devised various proof systems for diﬀerent purposes:
some systems are easy to implement on computers, others are very easy
to state (but hard to work in), still others facilitate general investigations
into the notion of provability. I will employ a system that enables one to
use proof steps that are not dissimilar to the steps people take in everyday
reasoning. Te the rules I will specify should be intuitively plausible, but
not every intuitively sound step is a permissible rule in the system: the
system has not been designed to be as eﬃcient as possible. It is devised
to show that any proof can be broken down into simple and elementary
steps of very few types. If the objective were a very eﬃcient proof system,
more rules would have to be added.
Because the proof rules are fairly close to proof steps used in informal
proofs, systems of the kind described in this chapter are called Natural
Deduction systems. Tey were introduced independently by Jaśkowski
(1934) and Gentzen (1935). Te system I am going to present is a variation
of Gentzen's version.
Proofs in Natural Deduction start with an assumption. Any sentence
can be assumed:
assumption rule
Te occurrence of a sentence ϕ with no sen-
tence above it is an assumption. An assumption of ϕ is a proof
of ϕ.
It may seem somewhat odd that the solitary occurrence of a sentence
is already a proof, but it is convenient to consider a line with a single
sentence ϕ as a proof of ϕ from the assumption ϕ, because this makes the
following deﬁnitions more straightforward.
Every proof begins with assumptions. Te further rules for proofs
show how to extend a proof, that is, how to form longer and longer
© Volker Halbach
2008/2009

6 Natural Deduction
116
proofs by adding further sentences. When stating the rules I will talk
about 'appending' sentences to already existing proofs. By this I mean the
following: one appends a sentence ϕ to a proof by drawing a horizontal
line under the proof and then writing ϕ under this line. One appends
a sentence ϕ to two (or three) proofs by writing the proofs side by side,
then drawing a single line under all of these proofs, and then writing
ϕ under that single line.
All the rules enable one to append only a single sentence in a given
step. Tus, in every proof there is always a single sentence ϕ at the bottom
(or the 'root') of the proof. Te proof is a proof of this sentence ϕ. Proofs
have therefore the shape of (upward-branching) trees.
For each connective and quantiﬁer there is an introduction rule and
an elimination rule. I shall use abbreviations: for instance, '∧Intro' is
short for '∧-introduction rule'.
6.1 propositional logic
For the sake of those who are concentrating just on propositional logic, I
shall only use examples in L1 in this section. Nonetheless, the rules apply
equally to predicate logic.
I will start with the rules for conjunction:
∧Intro
Te result of appending ϕ ∧ψ to a proof of ϕ and a
proof of ψ is a proof of ϕ ∧ψ.
Graphically, this rule allows one to write a proof ending with ϕ and a
proof ending with ψ side by side, to draw a horizontal line below both,
and to write ϕ ∧ψ under this line. Tus an application of the rule will
have the following shape:
⋮
ϕ
⋮
ψ
∧Intro
ϕ ∧ψ
© Volker Halbach
2008/2009

6 Natural Deduction
117
Te assumptions in the proof of ϕ∧ψ are all the assumptions in the proofs
of ϕ and ψ, respectively, because any assumption in the proof of ϕ or ψ,
that is, any sentence with no other formula above it in the proofs of ϕ or
ψ, will also be an assumption in the proof of ϕ ∧ψ, that is, it will not have
a sentence above it in the proof of ϕ ∧ψ.
Te order of the proofs of ϕ and ψ does not matter. Te rule does
not require that the proof of ϕ is written to the lef. So an application of
∧Intro can also look like this:
⋮
ψ
⋮
ϕ
∧Intro
ϕ ∧ψ
Te same applies to other rules: in rules where a sentence is appended to
two (or in one case three) proofs, the rules allow one to write down the
proofs in any order.
For ∧there are two elimination rules:
∧Elim1
Te result of appending ϕ to a proof of ϕ ∧ψ is a proof
of ϕ.
Te other rule allows one to keep ψ:
∧Elim2
Te result of appending ψ to a proof of ϕ∧ψ is a proof
of ψ.
Te two rules can be depicted as follows:
⋮
ϕ ∧ψ
∧Elim1
ϕ
⋮
ϕ ∧ψ
∧Elim2
ψ
Te ﬁrst rule allows one to drop the second part of the conjunction, the
second rule allows one to drop the ﬁrst part.
With these rules in hand I can already construct a proof. First, I will
assume (P ∧Q) ∧R. Te rule ∧Elim1 allows me to append P ∧Q to the
proof, and ∧Elim2 allows me to append Q to the resulting proof. So I can
obtain a proof of Q under the assumption (P ∧Q) ∧R:
© Volker Halbach
2008/2009

6 Natural Deduction
118
(P ∧Q) ∧R
∧Elim1
P ∧Q ∧Elim2
Q
Te labels '∧Elim1' and '∧Elim2' do not belong to the proof; they are
mere comments that are intended to help the reader to grasp the proof.
Occasionally, when I think that the labels will facilitate understanding, I
will add them.
Next I shall specify rules for the arrow →. In order to motivate the
introduction rule for the arrow, I will look at how one might establish
and 'if ..., then ...' like the following:
(A) If CO2-emissions are not cut, temperatures will rise globally.
To derive the conclusion, one will use additional assumptions about cli-
mate change, the greenhouse eﬀect and so on, which I will not specify
here. Using these additional assumptions, one could argue as follows for
(A):
Assume that CO2-emissions are not cut. Ten the CO2-level
in the atmosphere ...[now one uses the additional assump-
tion, probably talking about the greenhouse eﬀect, and con-
cludes:] so temperatures will rise globally. Terefore, if CO2-
emissions are not cut, temperatures will rise globally.
One makes the assumption that CO2-emissions are not cut only in order
to show that in that case temperatures will rise globally. Tis assumption is
made only for the sake of the argument and once (A) has been concluded,
one is no longer assuming that CO2-emissions are not cut. Te proof of
(A) is based only on the additional assumptions about climate change etc,
but not on the assumption that CO2-emissions are not cut. Tus, when
one concludes (A), one does not make the assumption anymore that
CO2-emissions are not cut; one claims only that temperatures will rise if
CO2-emissions are not cut without assuming anything about whether the
emissions are cut or not. Logicians describe this by saying that, when one
© Volker Halbach
2008/2009

6 Natural Deduction
119
concludes (A), one has 'discharged' the assumption that CO2-emissions
are not cut.
Generally, one can argue for a claim of the form 'If A, then B' by
proving B from the assumption A.
in the following way: one proves B by assuming A; then one concludes
'If A, then B' without assuming A anymore.
In Natural Deduction the rule for introducing the arrow works in the
same way: one assumes a sentence ϕ, derives a sentence ψ from it, and
then the rule allows one to conclude ϕ →ψ and to get rid of or 'discharge'
the assumption of ϕ.
In formal proofs one indicates that an assumption has been discharged
by enclosing that assumption in square brackets:
In formal proofs, assumptions are discharged by surrounding them with
square brackets. Of course one must only discharge assumptions in accor-
dance with the rules.
Te proof technique used in the above informal proofs is captured by
the introduction rule for →:
→Intro
Te result of appending ϕ →ψ to a proof of ψ and
discharging all assumptions of ϕ in the proof of ψ is a proof of
ϕ →ψ.
So one may add ϕ →ψ to a proof with ψ at the root and then enclose all
assumptions of ϕ (that is, all occurrences of ϕ with no line above them)
in the proof of ψ in square brackets.
Te graphical representation looks like this:
[ϕ]
⋮
ψ
→Intro
ϕ →ψ
Tis rule does not require that the proof of ψ actually contains an assump-
tion of ϕ. Only if there are any assumptions of ϕ in the proof of ψ, they
must be discharged.
© Volker Halbach
2008/2009

6 Natural Deduction
120
Te rule for eliminating →is straightforward:
→Elim
Te result of appending ψ to a proof of ϕ and a proof
of ϕ →ψ is a proof of ψ.
Tis rule is graphically represented as follows:
⋮
ϕ
⋮
ϕ →ψ
→Elim
ψ
Tis rule is also called the 'cut rule', because the sentence ϕ is 'cut oﬀ'
from ϕ →ψ.
Before giving some examples, I will introduce a new piece of notation:
definition 6.1. Te formula ϕ is provable from Γ (where Γ is a set of L2-
sentences) if and only if there is a proof of ϕ with only sentences in Γ as
non-discharged assumptions. Te phrase 'ϕ is provable from Γ' is abbrevi-
ated as Γ ⊢ϕ. If Γ is empty, Γ ⊢ϕ is abbreviated as ⊢ϕ. If Γ contains
exactly the sentences ψ1, ..., ψn, one may write ψ1, . . . , ψn ⊢ϕ instead of
{ψ1, . . . , ψn} ⊢ϕ.
example 6.2. ⊢P ∧Q →P.
Proof. I show step by step how to establish this claim. First, P ∧Q is
assumed:
P ∧Q
Applying ∧Elim1 yields the following:
P ∧Q ∧Elim1
P
Te rule →Intro allows one to add P ∧Q →P and to discharge P ∧Q:
[P ∧Q]
∧Elim1
P
→Intro
P ∧Q →P
© Volker Halbach
2008/2009

6 Natural Deduction
121
All assumptions in this proof have been discharged. Tus, P ∧Q →P is
provable from the empty set of premisses, that is, ⊢P ∧Q →P.
Tis is a typical proof of a sentence of the form ϕ →ψ: usually one
assumes ϕ, arrives through some steps at ψ, and then uses →Intro to
derive ϕ →ψ and to discharge any assumptions of ϕ.
Te introduction rules for disjunction are as follows:
∨Intro1
Te result of appending a sentence ϕ ∨ψ to a proof
of ϕ is a proof of ϕ ∨ψ.
As in the case for the elimination rules for ∧, there is also another intro-
duction rule for ∨:
∨Intro2
Te result of appending a sentence ϕ ∨ψ to a proof
of ψ is a proof of ϕ ∨ψ.
Te graphical representations are as follows:
⋮
ϕ
∨Intro1
ϕ ∨ψ
⋮
ψ
∨Intro2
ϕ ∨ψ
Te elimination rule for ∨is somewhat tricky. It corresponds to the
following informal proof strategy:
Assume 'Aor B' is given. Ten one can try to prove C by mak-
ing a case distinction: First, one tries to derive C assuming
A; then one tries to derive C assuming B. If C can be derived
in both cases, then (given 'A or B') one may conclude C.
Tis type of reasoning - reasoning by drawing the same conclusion from
both parts of a disjunction - is captured in the following rule:
∨Elim
Te result of appending χ to a proof of ϕ∨ψ, a proof of χ
and another proof of χ, and of discharging all assumptions
of ϕ in the ﬁrst proof of χ and of discharging all assumptions
of ψ in the second proof of χ, is a proof of χ.
© Volker Halbach
2008/2009

6 Natural Deduction
122
An application of ∨Elim looks like this:
⋮
ϕ ∨ψ
[ϕ]
⋮
χ
[ψ]
⋮
χ
∨Elim
χ
In the ﬁrst proof of χ only assumptions of ϕ are discharged; one must
not discharge assumptions of ψ in this proof when applying the rule. Of
course, this remark applies analogously to the second proof of χ. Te
rule may look somewhat awkward because from two proofs of χ one
only obtains another, longer proof of χ. Te point of the rule is that the
assumptions of ϕ and ψ can be discharged, so that χ now follows from
ϕ ∨ψ without assuming ϕ or ψ.
In an actual proof one would proceed as follows: assume one has a
proof of ϕ ∨ψ. Ten, one will start a new branch by assuming ϕ and
another new branch by assuming ψ. Afer obtaining χ on both branches,
one can discharge all assumptions of ϕ in the ﬁrst proof of χ, and all
assumptions of ψ in the second proof of χ, and append χ to the three
proofs.
I will illustrate the use of ∨Elim with the following example.
example 6.3. P ∨Q, P →R ⊢R ∨Q.
Proof.
P ∨Q
[P]
P →R
→Elim
R
∨Intro1
R ∨Q
[Q]
∨Intro2
R ∨Q ∨Elim
R ∨Q
In the last step - an application of ∨Elim - the assumptions P and Q are
discharged.
Te introduction rule for negation is another rule that allows one
to discharge assumptions. Te underlying strategy is as follows: If one
© Volker Halbach
2008/2009

6 Natural Deduction
123
can derive a contradiction from an assumption of A, then one may con-
clude: 'It is not the case that A.' Tis rule is called 'reductio ad absurdum'
(reduction to an absurdity).
¬Intro
Te result of appending a sentence ¬ϕ to a proof of ψ
and a proof of ¬ψ and of discharging all assumptions of ϕ in
both proofs is a proof of ¬ϕ.
Schematically, the rule for ¬-introduction has the following shape:
[ϕ]
⋮
ψ
[ϕ]
⋮
¬ψ
¬Intro
¬ϕ
I will demonstrate the use of the rule with an example:
example 6.4. ¬(P →Q) ⊢¬Q.
Proof. In order to arrive at a conclusion of the form ¬ϕ, it is ofen useful to
assume ϕ and to try to derive a contradiction. In this case I will assume Q
and try to obtain a contradiction with the only premiss, viz, ¬(P →Q).
[Q]
→Intro
P →Q
¬(P →Q)
¬Intro
¬Q
In the lef branch of the proof I have applied →Intro even though there is
no assumption of P. Tis is in accordance with the formulation of →Intro:
nothing in →Intro actually requires that there is actually an assumption
of P; only if there are any, they must be discharged.
Te rule of negation elimination allows one to discharge assumptions
of negated sentences:1
1 Tis rule allows for nonconstructive indirect proofs. For instance, the formula ϕ could
© Volker Halbach
2008/2009

6 Natural Deduction
124
¬Elim
Te result of appending as sentence ϕ to a proof of ψ
and a proof of ¬ψ and of discharging all assumptions of ¬ϕ
in both proofs is a proof of ϕ.
Graphically an application of the rule looks like this:
[¬ϕ]
⋮
ψ
[¬ϕ]
⋮
¬ψ
¬Elim
ϕ
Here is an example showing how the negation elimination rule can be
used:
example 6.5. ¬P →Q, ¬Q ⊢P.
[¬P]
¬P →Q
→Elim
Q
¬Q ¬Elim
P
Negation elimination can be used to prove the law of excluded middle:
example 6.6. ⊢P ∨¬P.
be an existence claim. Negation elimination allows one to conclude the existence of an
object with a certain property from the inconsistency of the assumption that there isn't
any object with that property. Tus one will be able to prove that an object satisfying
a certain property exists, without being able to show directly, of any particular object,
that it has this property. If one is interested in constructive proofs, that is, proofs
that require one to exhibit a particular example of an object that demonstrably has
the property in question in order to prove the relevant existence claim, then the rule
for negation elimination has to be dropped. Te resulting system, which diﬀers from
classical Natural Deduction, is called 'intuitionistic logic'. Te law of the excluded middle,
ϕ ∨¬ϕ (Example 6.5), and the law of double negation elimination, ¬¬ϕ →ϕ, are some
of the principles that are theorems of classical logic, which is the logic studied here, but
not of intuitionistic logic. Tennant (1990) provides an introduction to intuitionistic
logic with a proof system that is similar to the version of Natural Deduction used here.
© Volker Halbach
2008/2009

6 Natural Deduction
125
Te proof is surprisingly awkward. One cannot prove one of the sen-
tences P or ¬P (without assumptions) and then apply ∨Intro1 or ∨Intro2.
Rather one proves P ∨¬P indirectly by assuming ¬(P ∨¬P), which is
then shown to lead to a contradiction. Tis makes it possible to apply the
negation elimination rule.
Proof. First I assume P and apply ∨Intro1:
P
∨Intro1
P ∨¬P
In the next step, I assume ¬(P∨¬P), which is the negation of the sentence
that is to be proved.
[P]
∨Intro1
P ∨¬P
¬(P ∨¬P)
¬Intro
¬P
Now ∨Intro2 can be used:
[P]
∨Intro1
P ∨¬P
¬(P ∨¬P)
¬Intro
¬P
∨Intro2
P ∨¬P
Now ¬(P ∨¬P) is assumed again, so that ¬Intro can be applied once
more. Tis time ¬Intro is used to discharge the assumption ¬(P ∨¬P),
which occurs twice.
[P]
∨Intro1
P ∨¬P
[¬(P ∨¬P)]
¬Intro
¬P
∨Intro2
P ∨¬P
[¬(P ∨¬P)]
¬Elim
P ∨¬P
Te rules for the double arrow are as follows:
© Volker Halbach
2008/2009

6 Natural Deduction
126
↔Intro
Te result of appending ϕ ↔ψ to a proof of ϕ →ψ
and a proof of ψ →ϕ is a proof of ϕ ↔ψ.
↔Elim1
Te result of appending ϕ →ψ to a proof of ϕ ↔ψ is
a proof of ϕ →ψ.
↔Elim2
Te result of appending ψ →ϕ to a proof of ϕ ↔ψ
is a proof of ψ →ϕ.
Te graphical representations of the rules are as follows:
⋮
ϕ →ψ
⋮
ψ →ϕ
↔Intro
ϕ ↔ψ
⋮
ϕ ↔ψ
↔Elim1
ϕ →ψ
⋮
ϕ ↔ψ
↔Elim2
ψ →ϕ
In the following proof I will illustrate the use of the rules for the double
arrow.
example 6.7. ⊢(P →Q) ↔(¬Q →¬P).
Proof.
[P →Q]
[P]
Q
[¬Q]
¬P
¬Q →¬P
(P →Q) →(¬Q →¬P)
[¬Q →¬P]
[¬Q]
¬P
[P]
Q
P →Q
(¬Q →¬P) →(P →Q)
(P →Q) ↔(¬Q →¬P)
For the last line ↔Intro is used.
In cases like the following it is ofen useful to start from the root and to
consider how one might have obtained the sentence that is to be proved.
© Volker Halbach
2008/2009

6 Natural Deduction
127
example 6.8. ¬(Q ∧¬R) ⊢Q →R.
Proof.
¬(Q ∧¬R)
[Q]
[¬R]
Q ∧¬R
R
Q →R
Te assumption ¬(Q∧¬R) is not bracketed; it remains as an undischarged
assumption. Tus, ¬(Q ∧¬R) ⊢Q →R is established.
Finally, here is a proof of a variant of the 'ex falso quodlibet'-principle:
example 6.9. P, ¬P ⊢Q.
Proof. Te following proof contains a strange application of ¬Elim. Te
formula Q is introduced although ¬Q has never be assumed. ¬Elim
allows one to introduce ϕ and to discharge all assumptions of ¬ϕ even if
there are not any.
P
¬P ¬Elim
Q
Tis application of ¬Elim complies with ¬Elim, as it is not a requirement
that there actually be assumptions of ¬ϕ.
Te following result says that the rules for Natural Deduction have
been chosen in such a way that there are proofs for exactly those argu-
ments in L1 that are valid.
theorem 6.10 (adequacy for propositional logic). Assume that
ϕ and all elements of Γ are L1-sentences. Ten Γ ⊢ϕ if and only if Γ ⊧ϕ.
I will not prove this theorem here.
In particular, if a sentence of L1 is a tautology (logically true), then
there is a proof of that sentence without undischarged assumptions.
Te adequacy result says that the rules given here are suﬃcient for
proving a conclusion from premisses if the argument is valid. Any rule
© Volker Halbach
2008/2009

6 Natural Deduction
128
that can be added is either not sound, that is, it allows one to prove
sentences that are not logically true, or it is dispensable (but it may provide
a shortcut). I shall return to adequacy in more detail in Section 7.1; there
adequacy will be discussed with respect to predicate logic.
6.2 predicate logic
Te proof rules of propositional logic, which were expounded in the
previous section, apply to all sentences including the sentences of L2.
Te following example contains sentences of the language L2 that are not
in L1; but the proof requires only rules from propositional logic, that is,
introduction and elimination rules for connectives.
example 6.11. ⊢¬(∀x Px ∨∃y Py) →¬∀x Px.
Proof. Since one wants to prove a sentence of the form ϕ →ψ, the ϕ,
which corresponds to ¬(∀x Px ∨∃y Py) in the present example, is as-
sumed. From this assumption one tries to arrive at ¬∀x Px. Since this is
a negated sentence, one may hope to get it by using ¬Intro; so ∀x Px is
assumed. Tat is almost a contradiction: applying ∨Intro1 to ∀x Px gives
∀x Px ∨∃y Py, and the contradiction is obtained:
¬(∀x Px ∨∃y Py)
∀x Px
∨Intro1
∀x Px ∨∃y Py
Now ¬Intro is applied by appending ¬∀x Px to the two proofs and dis-
charging the assumption ∀x Px:
¬(∀x Px ∨∃y Py)
[∀x Px]
∨Intro1
∀x Px ∨∃y Py
¬Intro
¬∀x Px
One ﬁnishes the proof by applying →Intro:
© Volker Halbach
2008/2009

6 Natural Deduction
129
[¬(∀x Px ∨∃y Py)]
[∀x Px]
∨Intro1
∀x Px ∨∃y Py
¬Intro
¬∀x Px
→Intro
¬(∀x Px ∨∃y Py) →¬∀x Px
All assumptions are discharged, so the claim is established.
I will now turn to the rules for ∀and ∃. First, I will explain the rule
for eliminating ∀, which may be motivated by considering the following
argument:
If some person has made more than ten mistakes then that
person won't pass. Terefore, if Ben has made more than ten
mistakes he won't pass.
Here one is going from a universal claim to a claim about a speciﬁc in-
stance. Te rule for eliminating ∀, which is also known as 'universal
instantiation'-rule, allows one to pass from a universally quantiﬁed sen-
tence to a special instance. For instance, the rule licenses the step from the
universally quantiﬁed sentence ∀x (Px →Qx) to the instance Pa →Qa.
In order to give a general formulation of ∀Elim I employ the following
deﬁnition:
definition 6.12. Assumev is a variable, t a constant, and ϕ an L2-formula
with at most v occurring freely. Ten ϕ[t/v] is the sentence obtained by re-
placing all free occurrences of v in ϕ by t.
For instance, Px [b2/x] is Pb2; and ∀y (Pxy →∃x Rxy)[b/x]is the
sentence ∀y(Pby →∃x Rxy). In the second case only the ﬁrst occurrence
of x has been replaced because the other two are bound occurrences.
Te rule for eliminating the universal quantiﬁer can now be stated as
follows:
∀Elim
Te result of appending ϕ[t/v] to a proof of ∀v ϕ is a
proof of ϕ[t/v].
In this rule it is assumed that t is a constant, v a variable, and ∀v ϕ is a
sentence (so that only v can occur freely in ϕ).
Tus an application of this rule has the following form:
© Volker Halbach
2008/2009

6 Natural Deduction
130
⋮
∀v ϕ
∀Elim
ϕ[t/v]
Here, ϕ is an L2-formula in which only the variable v occurs freely; t is a
constant.
Tus the rule allows one to drop the quantiﬁer ∀v at the beginning of
a sentence and to replace all free occurrences of v in the resulting formula
with the constant t.
Te following example explains why only free occurrences of the
variable are replaced:
∀y (Py ∧∃y Qy)
∀Elim
Pb5 ∧∃y Qy
If one were allowed to replace also the last occurrence of y, which is
bound, one would to get to Pb5 ∧∃yQb5, which is logically equivalent to
Pb5 ∧Qb5. Tis step is clearly not sound: from ∀y(Py ∧∃y Qy) it does
not follow that b5 is Q. Intuitively speaking, only occurrences of y in
∀y (Py ∧∃y Qy) that are 'caught' by the universal quantiﬁer ∀y can be
replaced by the constant; the last occurrence of y belongs to the existential
quantiﬁer and must be lef alone.
Te introduction rule for the universal quantiﬁer is more diﬃcult to
state. In order to argue for the general claim that every traveller's journey
from London to Munich in 2007 took over two hours, one could reason
as follows:
Assume somebody travelled from London to Munich in 2007.
Call him John Doe. If he took the train ... [now each means
of transport is taken into account, and it is argued in every
case that the journey must have taken more than two hours.]
Terefore John Doe's journey took over two hours. Terefore,
since John Doe is an arbitrary person, every traveller's jour-
ney from London to Munich in 2007 took over two hours.
© Volker Halbach
2008/2009

6 Natural Deduction
131
Te idea here is that one talks about a nondescript particular instance as
an example using a name. In the story above, this nondescript instance is
a person who is dubbed 'John Doe'. Te name 'John Doe' is not used to
name a speciﬁc real person. Ten one carries out the argumentation for
this instance, and concludes that this argument applies to every instance
because the chosen instance was just used as an example. For the validity
of the argument it is important that the chosen person is arbitrary and
that one did not bring in any speciﬁc information about that person or
object (if there is such a person or object at all).
Te rule for introducing the universal quantiﬁer in Natural Deduction
works in a similar way: ⊢∀x(Px →Px) will be established by taking an
arbitrary constant, say, c (corresponding to the use of a name 'John Doe'
above), and arguing as follows:
[Pc]
→Intro
Pc →Pc
Since c was chosen to name a nondescript instance as an example, the
claim also holds for every object. Now, one substitutes the variable x for
the constant c in Pc →Pc and preﬁxes the universal quantiﬁer ∀x to the
formula. Ten one can add this sentence to the proof, in accordance with
the rule for introducing ∀:
[Pc]
→Intro
Pc →Pc
∀Intro
∀x(Px →Px)
In formulating the general rule ∀Intro, however, one must exercise
caution. One might think that ∀Intro can be formulated in the following
way: given a proof of a sentence ϕ, one replaces a constant in the sentence
by a variable v, writes ∀v in front of the sentence, and then appends the
resulting sentence to the proof. However, such a rule would allow one to
derive false conclusions from true premisses for three reasons.
first problem. I will illustrate the problem by considering the fol-
lowing attempted proof:
© Volker Halbach
2008/2009

6 Natural Deduction
132
(P)
∀y (Py →∃x Ryx)
∀Elim
Pa →∃x Rax
incorrect ∀-introduction
∀x (Px →∃x Rxx)
If (P) were a correct proof one could derive ∀x (Px →∃xRxx) from
∀y (Py →∃x Ryx). So (P) cannot be a correct proof: it would allow one
to go from the formalisation of 'Every student sees something' to the
formalisation of 'For every student there is something that sees itself.' Te
ﬁrst sentence is true while the latter is false if there is at least one student
and nothing can see itself.2
It should be obvious what went wrong. When the constant a was
replaced by x in the sentence Pa →∃x Rax, the x replacing the last
occurrence of a got 'caught' by the quantiﬁer ∃x:
∀x (Px →∃x Rx
±
actual binding
x)
Of course the 'intention' was that the penultimate occurrence of x should
refer back to the universal quantiﬁer ∀x and not to the existential quanti-
ﬁer:
∀x (Px →∃x Rx
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
intended binding
x)
Te problem can be avoided in the following way: when one adds
a sentence ∀v ϕ to a proof by applying the rule for introducing ∀then
the preceding sentence must be ϕ with all free occurrences of the vari-
able v replaced by the constant t. In other words, the rule allows one to
continue a proof ending with ϕ[t/v] by adding the sentence ∀v ϕ. So the
rule for introducing ∀will take the following form (with some additional
restrictions on occurrences of the constant t speciﬁed below):
⋮
ϕ[t/v]
∀v ϕ
2 Te proof that there is a counterexample to the argument with ∀y (Py →∃x Ryx) as
premiss and ∀x (Px →∃xRxx) as conclusion is the content of Exercise 5.2(ii).
© Volker Halbach
2008/2009

6 Natural Deduction
133
In the above attempted proof (P), I passed from Pa →∃x Rax to
∀x (Px →∃x Rxx). But this step is not covered by the rule that licenses
only the step from ϕ[t/v] to ∀v ϕ: Te result (Px →∃x Rxx)[a/x] of
replacing all free occurrences of x by a is the sentence Pa →∃x Rxx, not
Pa →∃x Rax. Only going from Pa →∃x Rxx to ∀x (Px →∃x Rxx)
would be covered by the rule.
second problem. Assume one starts a proof by assuming Qb and
then generalises in the following way:
Qb
incorrect ∀-introduction
∀x Qx
Tis is not correct. If it were correct, one could apply →Intro in the next
step:
[Qb]
incorrect ∀-introduction
∀x Qx
→Intro
Qb →∀x Qx
Tus, one would have proved that ⊢Qb →∀x Qx; but Qb →∀x Qx is
certainly not logically true, as has been shown in Example 5.9.
For this reason, one must make sure that one is not using any speciﬁc
assumptions containing the constant that is used as an 'arbitary exam-
ple' over which one can generalise. So when ∀Intro is applied by going
from ϕ[t/v] to ∀v ϕ, the constant t must not occur in any undischarged
assumption. In the discussion of the example of John Doe I said that it is
important that the person chosen as an example (John Doe) is arbitrary.
Te restriction that the constant must not occur in any undischarged as-
sumption is the formal counterpart of the requirement that John Doe is an
'arbitrary' person about whom one does not have any speciﬁc information.
In the earlier, correct proof of ∀x (Px →Px) the constant c occurred
in the assumption Pc, but that assumption had been discharged by the
time ∀Intro was applied. So this proof meets the restriction that c must
not occur in any undischarged premiss when the universal quantiﬁer is
introduced.
© Volker Halbach
2008/2009

6 Natural Deduction
134
third problem. Te following attempted proof meets all conditions
that were imposed on applications of ∀Intro to avoid the ﬁrst and second
problem:
∀y Ryy
Raa
∀x Rax
However, the argument with ∀y Ryy as premiss and ∀x Rax as its con-
clusion is not valid: it would alow one to go from the formalisation of
'Everthing is self-identical' to the formalisation of 'John is identical to
everything.'3 Tus, some condition must be imposed on the rule ∀Intro
that blocks the step from Raa to ∀x Rax. Tis can be done by disallow-
ing one to keep some occurrences of a in the sentence that is added in
accordance with the rule. Only passing from Raa to ∀x Rxx would be
admissible. Tus, since an application of ∀Intro is a step from ϕ[t/v]
to ∀v ϕ, the rule ∀Intro can be applied only if ϕ (that is, the formula
following the universal quantiﬁer) does not contain the constant t, that
is, if no occurrence of t is retained when ∀Intro is applied.
In the following formulation of the rule for introducing the universal
quantiﬁer all three problems are avoided:
∀Intro
Assume that ϕ is a formula with at most v occurring
freely and that ϕ does not contain the constant t. Assume fur-
ther that there is a proof of ϕ[t/v] in which t does not occur
in any undischarged assumption. Ten the result of append-
ing ∀v ϕ to that proof is a proof of ∀v ϕ.
Te rule can be represented as follows:
⋮
ϕ[t/v]
∀Intro
∀v ϕ
provided the constant t does not
occur in ϕ or in any undischarged
assumption in the proof of ϕ[t/v].
3 Te proof of ∀y Ryy ⊭∀x Rax is Exercise 5.2(iii).
© Volker Halbach
2008/2009

6 Natural Deduction
135
In less formal terms, the restrictions on ∀Intro can be summed up in
two points: First, one must make sure that one is not generalising over a
constant that occurs in an undischarged assumption or that is still in the
sentence one tries to obtain. Second, in an application of the rule, one
has to make sure that the variable of the newly introduced quantiﬁer is
not caught by a quantiﬁer that is already in the formula.
In the case of the existential quantiﬁer the introduction rule is the
easy one:
∃Intro
Te result of appending ∃v ϕ to a proof of ϕ[t/v] is a
proof of ∃v ϕ.
ϕ[t/v]
∃Intro
∃v ϕ
Of course t is a constant, v a variable, and ∃v ϕ is an L2-sentence.
Te rule for eliminating the existential quantiﬁer is the most compli-
cated rule. Consider the following argument:
Tere is at least one epistemologist. All epistemologists are
philosophers. Terefore, there is at least one philosopher.
Te two premisses have ∃x Px and ∀x (Px →Qx) as their respective for-
malisations; the formalisation of the conclusion is ∃x Qx. Te dictionary
has the following two entries:
P:
... is an epistemologist
Q:
... is a philosopher
Te corresponding argument in L2 is valid. Te question is how one
can prove the conclusion from the two premisses. If one could in some
way get Pc from the ﬁrst premiss ∃x Px, the rest of the proof would be
obvious:
© Volker Halbach
2008/2009

6 Natural Deduction
136
⋮
Pc
∀x (Px →Qx)
∀Elim
Pc →Qc →Elim
Qc
∃Intro
∃x Qx
Te problem is that Pc does not follow from ∃x Px. Te premiss ∃x Px
just states that there is some epistemologist; it does not give one a speciﬁc
epistemologist and, in particular, it does not give one a particular name c
for an epistemologist.
Te conclusion ∃x Qx does not say anything speciﬁc about c. In
the proof I could have used any other constant in place of c. So one
might apply the following proof strategy: one may assume Pc. Tis is
tantamount to picking an arbitrary name like 'John Doe' and assuming
that John Doe is an epistemologist. Once a sentence not containing c is
proved, one can discharge the assumption Pc using the premiss ∃x Px:
the conclusion does not depend any more on the assumption that c is
one of the P's.
∃x Px
[Pc]
∀x (Px →Qx)
∀Elim
Pc →Qc
→Elim
Qc
∃Intro
∃x Qx
∃x Qx
Te point in the last step of the proof is that the premiss Pc can be dis-
charged, so one has now proved the conclusion from the existence claim
∃x Px rather than from the speciﬁc instance Pc. Informally speaking, the
conclusion that there is a philosopher does not depend on the assumption
that there is an epistemologist called 'John Doe'.
When making an assumption such as Pc one must not choose a con-
stant about which one already has speciﬁc information: the constant
acts as an 'arbitrary example' in the same way as in ∀Intro. Te precise
statement of the elimination rule for ∃is so convoluted because the re-
strictions on the constant must ensure that the constant can play its role
as an arbitrary label.
© Volker Halbach
2008/2009

6 Natural Deduction
137
∃Elim
Assume that ϕ is a formula with at most v occurring
freely and that the constant t does not occur in ϕ. Assume
further that there is a proof of the sentence ψ in which t does
not occur in any undischarged assumption other than ϕ[t/v].
Ten the result of appending ψ to a proof of ∃v ϕ and the proof
of ψ and of discharging all assumptions of ϕ[t/v] in the proof
of ψ is a proof of ψ.
As before, ϕ[t/v] is just ϕ with all free (and only free) occurrences of v
replaced with t.
An application of the rule looks like this:
⋮
∃v ϕ
[ϕ[t/v]]
⋮
ψ
∃Elim
ψ
provided the constant t does not
occur in ∃v ϕ, or in ψ, or in any
undischarged assumption other
than ϕ[t/v] in the proof of ψ.
In practice, ∃Elim is applied in the following way: Assume that one
has proved ∃v ϕ. Ten one picks a constant that has not been used yet and
that does not occur in any premisses one has, and assumes ϕ[t/v]. Once
one has proved a sentence ψ not containing t, all assumptions of ϕ[t/v]
are discharged and one writes ψ under the proof of ∃v ϕ and the proof
of ψ. Here I have recommended using a constant t that is completely
'new' to the proof; this is not really necessary or forced by the rule, but by
using a new variable one can make sure that the conditions on t in the
rule are satisﬁed. Also, by using a constant that is not new one does not
gain anything.
Tis rule concludes the description of the system of Natural Deduc-
tion. A list of all the rules may be found in Appendix 8.6.
I will give some examples of proofs in which the quantiﬁer rules are
used.
example 6.13. ∀x ¬Px ⊢¬∃x Px
Proof. First one assumes ∀x ¬Px and applies ∀Elim:
© Volker Halbach
2008/2009

6 Natural Deduction
138
∀x ¬Px ∀Elim
¬Pa
In order to be able to apply ∃Elim, one assumes Pa and continues with
¬Intro:
Pa
[∀x ¬Px]
∀Elim
¬Pa ¬Intro
¬∀x ¬Px
With the additional assumption ∃x Px one can apply ∃Elim and dis-
charge Pa:
∃x Px
[Pa]
[∀x ¬Px]
∀Elim
¬Pa
¬Intro
¬∀x ¬Px ∃Elim
¬∀x ¬Px
Now ∀x ¬Px is assumed again to produce a contradiction that allows one
to apply ¬Intro:
∀x ¬Px
[∃x Px]
[Pa]
[∀x ¬Px]
∀Elim
¬Pa
¬Intro
¬∀x ¬Px
∃Elim
¬∀x ¬Px ¬Intro
¬∃x Px
∃x Px can be discharged according to ¬Intro. Te only assumption that is
not discharged is the lefmost occurrence of ∀x ¬Px, which is the premiss.
Te next example is the converse of the previous one.
example 6.14. ¬∃x Px ⊢∀x ¬Px.
Proof. ∀x ¬Px, which is to be derived, can be obtained by ∀Intro from ¬Pa.
Tis in its turn can be obtained by ¬Intro. So Pa is assumed and ∃Intro
is applied:
© Volker Halbach
2008/2009

6 Natural Deduction
139
Pa
∃Intro
∃x Px
Now the assumption ¬∃x Px is added and ¬Intro is applied:
¬∃x Px
[Pa]
∃Intro
∃x Px ¬Intro
¬Pa
Because Pa is now discharged, ∀Intro can be applied:
¬∃x Px
[Pa]
∃Intro
∃x Px ¬Intro
¬Pa
∀Intro
∀x ¬Px
All assumptions with exception of the premiss are discharged.
In the following example, ∃Intro is applied in a cunning way.
example 6.15. ∀x Rxx ⊢∀y ∃z Ryz.
Proof.
∀x Rxx ∀Elim
Raa
∃Intro
∃z Raz
∀Intro
∀y ∃z Ryz
Te application of ∃Intro is legitimate: nothing in the formulation of
the rule forces one to replace all occurrences of a by the variable z. Te
formula Raz is a formula with only one variable occurring freely; thus
ϕ[t/v] is Raz[a/z], which is the formula Raa. ∃v ϕ is then ∃z Raz.
In Example 5.10 on page 111, I refuted ∀x ∃y Rxy ⊧∃y ∀x Rxy by
means of a counterexample. Now I can establish the converse direction
∃y ∀x Rxy ⊢∀x ∃y Rxy.
example 6.16. ∃y ∀x Rxy ⊢∀x ∃y Rxy.
Proof.
© Volker Halbach
2008/2009

6 Natural Deduction
140
∃y ∀x Rxy
[∀x Rxb]
∀Elim
Rab
∃Intro
∃y Ray
∃Elim
∃y Ray
∀Intro
∀x ∃y Rxy
Te assumption ∀x Rxb has been discharged in the penultimate step by
applying ∃Elim.
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
In this chapter I shall bring three strands together: the semantics of
the language L2 of predicate logic, the system of Natural Deduction,
and arguments in English. First I will turn to the relation between the
semantics of L2 and proofs in Natural Deduction.
7.1 adequacy
Te rules of Natural Deduction have been chosen so as to guarantee
that, if a sentence is provable (with no undischarged premisses), it is
logically true; and if a sentence is provable from certain premisses, the
corresponding argument is valid. Tis way, formal proofs allow one to
establish that certain arguments in L2 are valid (and that certain sentences
are logically true). In the following lemma, it is assumed that ϕ and all
elements of Γ are sentences of L2.
lemma 7.1 (soundness). If Γ ⊢ϕ, then Γ ⊧ϕ.
I will not give a proof of this claim here, but I have tried to present
the rules of Natural Deduction in such a way that their soundness ought
to be plausible, if not obvious.
While the soundness of the rules of Natural Deduction is fairly plau-
sible, it is much harder to see whether one can actually prove ϕ from
premisses in Γ whenever Γ ⊧ϕ, and whether one can prove all logical
truths of L2. In fact, the rules of Natural Deduction are suﬃcient for this
purpose:
theorem 7.2 (completeness). If Γ ⊧ϕ, then Γ ⊢ϕ.
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
142
As before, ϕ and all elements of Γ are L2-sentences here.
Te fact that the proof system of Natural Deduction is sound sound-
ness and complete completeness is ofen expressed by saying that it is
adequate for the semantics introduced in Chapter 5. More formally, this
can be expressed in the following way:
theorem 7.3 (adequacy). Assume that ϕ and all elements of Γ are L2-
sentences. Ten Γ ⊢ϕ if and only if Γ ⊧ϕ.
Tus, ⊧and ⊢coincide even though they have been deﬁned in com-
pletely diﬀerent terms. I have deﬁned ⊧in semantic terms, that is, in
terms of L2-structures, while ⊢has been deﬁned in purely syntactic terms,
that is, in terms of rules for manipulating sentences of L2.
For the special case where Γ is empty, the Adequacy Teorem 7.3
means that ϕ is logically true if and only if ϕ is provable (with all assump-
tions discharged). Tis can be expressed more formally in the following
way:
⊢ϕ if and only if ⊧ϕ
In practice, if one wants to show that ϕ follows from sentences in Γ,
that is, if one wants to show that Γ ⊧ϕ, one will usually try to construct a
proof in the system of Natural Deduction because this is in most cases
easier than a proof directly establishing that ϕ is true in all L2-structures
in which all sentences in Γ are also true.
In contrast, if one wants to prove that ϕ does not follow from Γ, that
is, that Γ ⊧ϕ is not the case, or Γ ⊭ϕ for short, one will usually be better
oﬀconstructing a counterexample, that is, an L2-structure in which all
sentences of Γ are true and ϕ is not true. Tis is usually easier than
showing that there is no proof of ϕ with sentences from Γ as the only
undischarged assumptions.
In Section 5.3 I have deﬁned further semantic properties of sentences
of L2. Tese properties can be deﬁned also in terms of provability. Ten
the Adequacy Teorem 7.3 can be used to show that the syntactic deﬁni-
tions (in terms of provability) and the semantic deﬁnitions (in terms of
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
143
L2-structures) coincide. Here consistency will serve as an example. First,
consistency is deﬁned in terms of proofs:
definition 7.4 (syntactic consistency). A set Γ of L2-sentences is
syntactically consistent if and only if there is a sentence ϕ such that Γ /⊢ϕ.
Here Γ /⊢ϕ means that it is not the case that Γ ⊢ϕ. Terefore, a
set Γ of sentences is syntactically consistent if and only if it is not the
case that any sentence whatsoever can be proved from premisses in Γ (as
nondischarged assumptions).
Inconsistency is the opposite of consistency: a set of sentences is
syntactically inconsistent if and only if it is not syntactically consistent.
Tus, a set Γ of sentences is inconsistent if and only if from premisses in
Γ every L2-sentence can be proved. Tat is, Γ is inconsistent if and only
if Γ ⊢ϕ for every L2-sentence ϕ.
According to Deﬁnition 5.7, a set Γ of L2-sentences is semantically
consistent if and only if there is an L2-structure A in which all sentences
in Γ are true. Now the Adequacy Teorem can be used to show that
semantic and syntactic consistency coincide:
theorem 7.5. A set Γ of L2-sentences is semantically consistent if and only
if Γ is syntactically consistent.
Proof. Assume that the set Γ is semantically consistent. Ten by Deﬁni-
tion 5.7(iv) there is an L2-structure A in which all sentences in Γ are true.
Choose a sentence ϕ which is false in that structure. Ten Γ ⊭ϕ, and by
the Soundness Lemma 7.1, Γ ⊬ϕ. So Γ is syntactically consistent.
To see the converse, assume that Γ is not semantically consistent.
Ten there is no L2-structure A in which all sentences in Γ are true.
Consequently, any sentence ϕ will be true in all L2-structures in which all
sentences of Γ are true (because there are no such structures). So Γ ⊧ϕ
for all sentences ϕ of L2, and by Teorem 7.2, Γ ⊢ϕ for all sentences ϕ.
So there is no sentence ϕ that is not provable from premisses in Γ, and,
therefore, Γ is not syntactically consistent.
So far all the premiss sets used in examples contained only a few simple
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
144
sentences. A premiss set, however, may also be very complicated. For
example, a premiss set could contain all of the sentences a certain person
believes, or the axioms of some theory in philosophy or mathematics
or medicine or any other area. A theory here is nothing more than a
premiss set, that is, a set of sentences. Some theories can be logically very
powerful. For instance, all of mathematics (with some possible minor
exceptions) can be developed in set theory, and the axioms of set theory
can be written down as L2-sentences.
When considering a theory, one would like to know whether it is (syn-
tactically or semantically) consistent. Teorem 7.5 shows why consistency
is such an important property of a theory: if a theory is inconsistent, any-
thing can be proved from it. Tus, in order to show that a set of sentences
is not useless as a theory (because anything can be proved from it), one
has to show that the set is consistent. Tis can be achieved by establishing
that there is an L2-structure in which all the sentences of the theory are
true. In that case the set is semantically consistent, and by Teorem 7.5
also syntactically consistent. Te tools of logic have ofen been used to
show that theories are consistent.
Tese tools can be used to prove not only that theories are consistent
and that sentences follow logically from certain premisses; they can also
be used to investigate much more general problems about consistency,
validity, and so on. I will sketch some general results of this kind here.
It would be convenient to have a general method for determining
whether an arbitrary argument is valid or whether a given sentence is
logically true. If ϕ is a sentence of the language L1 of propositional logic,
there is a method for deciding whether ϕ is logically true or not: one can
use the truth table method. In propositional logic, one can also use the
truth table method to decide whether an argument with ﬁnitely many
premisses is valid or not. Te situation with L2 is diﬀerent: one can use
the system of Natural Deduction to show that a sentence is logically true,
but it hardly can be used to prove that a sentence is not logically true. If
one does not hit upon a proof in a reasonable amount of time, this does
not mean that there is no proof; one could simply have not yet found
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
145
the proof: Te maximal possible length of a proof cannot be read oﬀ
the sentence. So the system of Natural Deduction does not deliver a
systematic method for deciding whether a sentence is logically true.
Church (1936) showed, using Kurt Gödel's famous Incompleteness
Teorems, that there cannot be a procedure for deciding whether a sen-
tence of L2 is logically true. In particular, no computer program can, given
an arbitrary sentence as input, tell one infallibly whether the sentence
is logically true or not, or whether a given sentence can be proved from
sentences in a given theory. Tis holds even if there are no restrictions
imposed on the computing time, computer memory, and so on. Church's
result shows that, given certain sentences as input, the program will keep
on calculating forever (or return an incorrect result). Te precise formu-
lation of this result is beyond the scope of this text, but it explains why
the system of Natural Deduction (or any other system for predicate logic)
cannot be transformed into a method that, like the truth-table method
for L1, takes a sentence of L2 as input and then returns in any case afer
ﬁnitely many steps an answer to the question of whether the sentence is
logically true or not.
Church's result also shows that there are no simple checks for the
consistency of a set of assumptions: there is no systematic method - a
method that could be implemented on a computer - for deciding whether
a given ﬁnite set of sentences is consistent or not. Of course, one may
try to ﬁnd an L2-structure in which all sentences in the set are true, but
there is again no systematic method that tells one whether there is such
an L2-structure. Tus, proving the consistency of sets of sentences of L2
is a highly non-trivial aﬀair.
7.2 ambiguity
As I said at the beginning of the chapter, I want to bring together three
strands: the semantics of L2, the system of Natural Deduction, and ar-
guments in English. Te relation between the former two has now been
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
146
clariﬁed by Teorem 7.3: the semantics of L2 and the proof system of
Natural Deduction match up, that is, ⊧and ⊢coincide. Now I will turn
to natural language and how to compare arguments in English to those
in L2.
Te connection between arguments in English and in L2 is established
by translating between the two languages. So I will turn now to such
translations.
In Section 4.5 I provided a sketch of how to go about translating from
English into the language L2. In the ﬁrst step the English sentence is
brought into a regimented form: its logical form. In the second step the
standard connectives are replaced by the respective symbols: 'there is
at least one x' is replaced by ∃x, 'for all x' is replaced by ∀x, names are
replaced by constants, predicate expressions are replaced by predicate
letters, and so on. Most diﬃculties occur in the ﬁrst step, while in the
second step English expressions are merely mechanically replaced by
corresponding symbols.
Some diﬃculties arise from a discrepancy between predicate expres-
sions in English and the predicate letters of L2: in English the number
of designators a predicate takes can vary from sentence to sentence. Te
following English sentences are all well formed:
In his garage the engineer loosens the nut with the wrench.
Te engineer loosens the nut with the wrench.
Te engineer loosens the nut.
In the ﬁrst sentence one would like to formalise the predicate 'loosens' as
a 4-place predicate letter, in the second as a ternary predicate letter, and
in the last sentence as a binary predicate letter. Te language L2, however,
does not have predicate letters with a variable number of places. If an
argument contains two of the sentences above one would like to formalise
the predicate 'loosens' as the same predicate letter in both sentences,
and there are some tricks that can help. For instance, one might try to
reformulate the second sentence as 'In some place the engineer loosens
the nut with the wrench,' thereby making it amenable to formalisation by
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
147
a 4-place predicate letter; then 'loosens' can be formalised by this 4-place
predicate letter in the ﬁrst and second sentence. Te strategy, however,
does not easily generalise, and philosophers and logicians have proposed
other strategies to solve the problem of variable arity. Te discussion of
these proposals, however, goes beyond the scope of this text.
Te problem of variable arity I have just outlined does not arise from
an ambiguity in English; rather it highlights diﬀerences in the grammars
of English and L2. In Section 3.4 I have already mentioned certain am-
biguities that can lead to two diﬀerent formalisations in propositional
logic. In particular, I have discussed ambiguities concerning the scope
of connectives. Of course, a sentence displaying such an ambiguity has
diﬀerent formalisations also in L2 because the connectives work in L2 in
the same way as in L1.
I will now browse through some other kinds of ambiguities, begin-
ning with lexical ambiguities. Te word 'bank', for instance, is lexically
ambiguous. It can mean the edge of a river or a ﬁnancial institution. One
can analyse lexical ambiguities by formalising 'is a bank' as two diﬀerent
unary predicate letters, where one predicate letter stands for '... is a bank
(ﬁnancial institution)' and the other for '... is a (river) bank'. Tus, a sen-
tence containing lexically ambiguous vocabulary may have two diﬀerent
formalisations that are not logically equivalent.
More interestingly, there are also ambiguities that can be analysed in
predicate logic by using two diﬀerent sentences that do not only disagree
in their predicate letters of constants but also in their structures. Usually,
the indeﬁnite article 'a' indicates existential quantiﬁcation, as, for instance,
in the following sentences:
Every student owns a computer.
A house has been damaged by a meteorite.
In some cases, however, the indeﬁnite article is used to make a general
statement that must be formalised by a universal quantiﬁer. Te following
sentences are most naturally understood as general claims that are to be
formalised by sentences with a universal quantiﬁer:
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
148
A politician will never admit that he has made a mistake.
An electron is negatively charged.
Occasionally, the indeﬁnite article is ambiguous. Ofen one reading will
be more plausible given the context of the sentence, but sometimes it
may be very hard to reach a decision about the appropriate reading. For
instance, it may be diﬃcult to decide in which way the following sentence
should be understood:
A Labour MP will not agree to this proposal.
Te sentence could be taken to express that at least one Labour MP will
not agree or as expressing that, in general, no Labour MP will agree. Of
course, such ambiguities can be made explicit with formalisations. Te
two readings yield the following two (respective) formalisations:
∃x (Px ∧¬Qxa)
∀x (Px →¬Qxa)
I have used the following dictionary in this formalisation:
P:
... is a Labour MP
Q:
... agrees to ...
a:
this proposal
In the next example the indeﬁnite article expresses existential quan-
tiﬁcation without ambiguity, but the sentence is ambiguous for another
reason:
A mistake was made by every student.
In a ﬁrst attempt to parse the sentence one could start as follows:
Tere is at least one x (x is a mistake and (every student
made x))
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
149
Of course one would then go on and analyse 'every student made x' as
'for all y (if (y is a student), then (y made x))'. According to this analysis,
there is at least one mistake that was made by every student; so every
student made the same mistake (and possibly more). On this reading the
logical form would be as follows:
Tere is at least one x ((x is a mistake) and for all y (if (y is a
student), then (y made x)))
Using the dictionary below, this yields the following L2-sentence:
∃x(Qx ∧∀y (Py →Ryx))
(7.1)
P:
... is a student
Q:
... is a mistake
R:
... made ...
Tere is, however, an alternative reading. Te original sentence may be
taken to say what would be more naturally expressed by the following
sentence:
Every student made a mistake,
where it is understood that it could well be the case that each student
made diﬀerent mistakes, and there is no one mistake that was made by
all students. Tis reading results in the following logical form:
For all x (if (x is a student), then there is at least one y ((y is
a mistake) and (x made y)))
Te formalisation is obviously diﬀerent from (7.1):
∀x (Px →∃y (Qy ∧Rxy))
(7.2)
Without additional information, one cannot decide which of the two
readings is the correct one. Te original sentence is ambiguous.
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
150
Tis kind of ambiguity is akin to the scope ambiguities in proposi-
tional logic discussed on page 63. Tere the 'grouping' of connectives
was not uniquely determined by the original English sentence, which
resulted in two diﬀerent formalisations, P ∧(Q ∨R) and (P ∧Q) ∨R.
In that example it was not clear whether ∨should be in the scope of ∧
(as in the ﬁrst sentence) or ∧should be in the scope of ∨. In the present
case, on the ﬁrst reading (7.1), the existential quantiﬁer comes ﬁrst so that
the universal quantiﬁer 'falls under' the existential one, while the order is
reversed in the second formalisation (7.2). Te deﬁnition of the scope of
(an occurrence of) a quantiﬁer is similar to the deﬁnition of the scope of
a connective on page 63:
definition 7.6 (scope of a quantifier). Te scope of an occurrence of
a quantiﬁer in a sentence ϕ is (the occurrence of ) the smallest L2-sentence
that contains that quantiﬁer and is part of ϕ.
Tus, in (7.1) the entire sentence, including the occurrence of ∀y, is
the scope of (the single occurrence of) the existential quantiﬁer. Te
scope of the occurrence of the universal quantiﬁer ∀y is the underbraced
part:
∃x(Qx ∧∀y(Py →Ryx)
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
scope of ∀y
)
So the above ambiguity is another case of scope ambiguity because the
original sentence 'Every student made a mistake' leaves it open whether
the universal quantiﬁer is in the scope of the existential quantiﬁer or vice
versa.
7.3 extensionality
If the constants a and b have the same extension in an L2-structure A,
that is, if a and b denote the same object, then replacing a by b in a true
sentence will yield a true sentence. For instance, if a and b both denote
Rome in some L2-structure A, that is, if ∣a∣A and ∣b∣A are both Rome, then,
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
151
for example, Pa will be true if and only if Pb is true. Tis is easily seen
from Deﬁnition 5.2 of satisfaction: assume Pa is true, that is, ∣Pa∣A = T
and reason as follows:
∣Pa∣A = T
assumption
∣a∣A ∈∣P∣A
Deﬁnition 5.2(i)
∣b∣A ∈∣P∣A
by assumption ∣a∣A = ∣b∣A
∣Pb∣A = T
Deﬁnition 5.2(i)
In the third line I used the assumption that a and b have the same ex-
tension, that is, that ∣a∣A = ∣b∣A. Tis shows that if Pa is true in A, so
is Pb.
Te argument generalises to more complex sentences: as long as a
and b have the same extension, they can be replaced in any sentence by
one another without changing the truth-value of that sentence.
Generally, if constants, sentence letters, and predicate letters are re-
placed in an L2-sentence by other constants, sentence letters, and predicate
letters (respectively) that have the same extension in a given L2-structure,
then the truth-value of the sentence in that L2-structure does not change.
I will not prove the general claim that all sentence letters, predicate
letters, and constants with the same extensions respectively can be substi-
tuted 'salva veritate' (Latin shorthand for 'without making a true sentence
false'), but the above example of the sentence Pa should make the gen-
eral claim plausible. Languages in which these substitutions are possible
are called 'extensional': in extensional languages a sentence's truth-value
depends only on the semantical values of the non-logical symbols that is,
on the extensions of the names, on the relations that are the extensions of
predicate expressions, and so on.
In English it is ofen possible to substitute designators denoting the
same object for one another. For instance, the designator 'Qomolangma'
is just the oﬃcial Tibetan name for Mount Everest. Tus 'Qomolangma'
and 'Mount Everest' denote the same mountain. So if the sentence
Mount Everest is 8 850 metres high.
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
152
is true, then
Qomolangma is 8 850 metres high.
must be true. Clearly whether I use 'Mount Everest' or 'Qomolangma'
to denote the highest mountain, the truth-value of the sentence will be
the same. I could even replace 'Mount Everest' by the description 'the
mountain Edmund Hillary climbed on 29th May 1953' without aﬀecting
the sentence's truth-value:
Te mountain Edmund Hillary climbed on 29th May 1953 is
8 850 metres high.
So here English behaves very much like L2: I can replace designators
designating the same object by one another without changing the truth-
value of this sentence in the same way I have been able to substitute b
for a in the sentence Pa without changing its truth-value in A (assuming
that ∣a∣A = ∣b∣A).
English, however, is not extensional. Tere are also sentences such
that substituting designators denoting the same object can change their
truth-value.
Assume that the following sentence is true:
Tom believes that Mount Everest is 8 850 metres high.
If Tom does not believe that Qomolangma is Mount Everest if he believes,
for instance, that it is a small mountain in the Alps, then the following
sentence is presumably false:
Tom believes that Qomolangma is 8850 metres high.
And the sentence
Tom believes that the mountain Edmund Hillary climbed on
29th May 1953 is 8 850 metres high
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
153
might also be false, although 'Mount Everest', 'Qomolangma', and 'the
mountain Edmund Hillary climbed on 29th May 1953' all denote the same
object. Tom might have no idea whether Hillary claimed a mountain on
29th May 1953 and, if so, which mountain Hillary climbed on that day.
Tis example shows that English is not an extensional language.
A similar point can be made about predicate expressions. Assuming
again that the animals with kidneys are exactly the animals with hearts,
the following substitution may transform the true ﬁrst sentence into a
false sentence:1
Tom believes that all snails have hearts.
Tom believes that all snails have kidneys.
Tom might believe that all snails have hearts, but he might not have a
view on whether they also have kidneys. He may even believe that they
lack kidneys.
Another example of the failure of extensionality is the following pair
of sentences:
It is logically true that all animals with hearts have hearts.
It is logically true that all animals with hearts have kidneys.
Te ﬁrst sentence is true, while the second is false: it is not logically true
that all animals with hearts have kidneys.
In the above examples, 'that'-sentences have been used to produce
counterexamples to the extensionality of English. Te problematic sub-
stitutions were made afer such phrases as 'Tom believes that' or 'It is
logically true that'. Tere are also cases of simpler sentences, without 'that',
where extensionality fails:
Oedipus is looking for his mother.
1 Te qualiﬁcations from footnote 2, page 5 footnote 2 apply.
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
154
Tis sentence may well be true since Oedipus was abandoned as a baby.
Now he is married to and lives with Jocasta who, unbeknownst to him, is
his mother. So the following sentence might be false at the same time:
Oedipus is looking for Jocasta.
She might actually be sitting right next to him. Since 'Jocasta' and 'Oedi-
pus' mother' denote the same person, the example provides another case
of the failure of extensionality.
Te failure of extensionality of English imposes certain restrictions
on the formalisations of English sentences in the language of predicate
logic. In the above example, one might be tempted to formalise
Oedipus is looking for Jocasta
as P2ab with the following dictionary:
P2:
... is looking for ...
a:
Oedipus
b:
Jocasta
Tis translation is not correct: '... is looking for ...' does not express
a relation, that is, a set of ordered pairs. If it did, it would express the
set (relation) of all pairs ⟨d, e⟩such that d is looking for e; and if the
pair ⟨Oedipus, Oedipus' mother⟩is in that set, then ⟨Oedipus, Jocasta⟩is
necessarily also in that set since it is the same ordered pair: ordered pairs
are identical if they agree in the their ﬁrst and second components, and
Oedipus' mother and Jocasta are the same object. So it would be true that
Oedipus is looking for Jocasta, which is not the case. Tus, '... is looking
for ...' cannot be formalised as a binary predicate letter, because this is
assigned a binary relation as its extension in any L2-structure.
However, one might still formalise '... is looking for Oedipus' mother'
by a unary predicate letter. Te English predicate expression '... is looking
for Oedipus' mother' does express a unary relation, that is, a set: the
designator 'Oedipus' may be replaced by any other designator for Oedipus
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
155
without changing the truth-value of the sentence. Generally, whenever
one has a designator t such that 't is looking for Oedipus' mother' is true
and some designator s refers to the same object as t, the sentence 's is
looking for Oedipus' mother' is true as well.
By a similar argument one can show that the predicate expression
'... believes that ... is high' must not be formalised as a binary predicate
letter. Tis can be done by considering the following example again:
Tom believes that Mount Everest is high.
Te formalisation by the sentence R2a1b1 with the following dictionary is
not correct:
R2:
... believes that ... is high
a1:
Tom
b1:
Mount Everest
Assume that '...believes that ...is high' is formalised as a binary predicate
letter; then the following problem arises: If B is an L2-structure and the
pair ⟨Tom, Mount Everest⟩is an element of the semantical value of R2,
that is, of the relation ∣R2∣B, then ⟨Tom, Qomolangma⟩is by necessity
also an element of that relation. Tis is due to the fact that ⟨Tom, Mount
Everest⟩and ⟨Tom, Qomolangma⟩are the same ordered pair with Tom
as ﬁrst component and the highest mountain on earth as the second. But
the sentence
Tom believes that Qomolangma is high
may be false. So '... believes that ... is high' cannot be formalised as a
binary predicate letter.
Te best formalisation with the tools available might be Q1a, where
Q1 is translated as '... believes that Mount Everest is high'.
Generally one can only use a predicate letter for English predicates if
they express relations.
Tis also includes unary predicate letters, which denote unary rela-
tions, that is, sets (see the end of Section 1.4).
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
156
7.4 predicate logic and arguments in english
Many remarks about, and deﬁnitions of, formalisations carry over from
propositional logic to predicate logic. In particular, Deﬁnition 3.5 can be
reformulated for predicate logic in the obvious way:
definition 7.7.
(i) An English sentence is logically true in predicate logic if and only if
its formalisation in predicate logic is logically true.
(ii) An English sentence is a contradiction in predicate logic if and only
if its formalisation in predicate logic is a contradiction.
(iii) A set of English sentences is consistent in predicate logic if and only if
the set of their formalisations in predicate logic is semantically con-
sistent.2
Similarly, the deﬁnition of validity of English arguments in predicate
logic is analogous to Deﬁnition 3.6:
definition 7.8. An argument in English is valid in predicate logic if and
only if its formalisation in the language L2 of predicate logic is valid.
Of course, an argument in English is valid if it is valid in predicate
logic, that is, if its formalisation in L2 is valid. So an argument in English
is valid, if its formalisation in L2 is a valid argument. However, on the
view of many logicians, there are valid arguments in English that are not
valid in predicate logic. I will return to the question whether there are
such English arguments later.
As in the case of propositional logic, talking about the formalisation
of a sentence in L2 is not unproblematic since there may be more than
one formalisation (see Section 3): if a sentence is ambiguous and has two
or more formalisations, the sentence may be logically true in predicate
logic on one reading, but not on another.
2 I could have used the notion of syntactic consistency, which is the same as semantic
consistency by Teorem 7.5.
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
157
To illustrate how the methods of predicate logic can be used to analyse
arguments in English, I will now go through some examples, starting
with a simple and famous example:
All men are mortal. Socrates is a man. Terefore, Socrates is
mortal.
Clearly, the argument is valid. In order to establish its validity formally, I
will formalise the premisses as ∀x(Px →Qx) and Pc and the conclusion
as Qc with the following dictionary:
P:
... is a man
Q:
... is mortal
c:
Socrates
Te resulting argument in L2 is valid:
example 7.9. ∀x(Px →Qx), Pc ⊢Qc
Proof. A proof in Natural Deduction looks like this:
Pc
∀x(Px →Qx)
∀Elim
Pc →Qc →Elim
Qc
Te formalisation and the proof show that the English argument is
valid in predicate logic and, thus, formally valid.
Next I will turn to an example that was analysed on page 68 in the
chapter on propositional logic:
Unless Alfred is an eminent logician, it is not the case that
both Kurt and Alfred are eminent logicians.
Te sentence has the formalisation
Pa ∨¬(Pa ∧Pb)
with the following dictionary:
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
158
P:
... is an eminent logician
a:
Alfred
b:
Kurt
Te claim ⊢Pa ∨¬(Pa ∧Pb) can be established by the following proof:
[¬(Pa ∧Pb)]
Pa ∨¬(Pa ∧Pb)
[¬(Pa ∨¬(Pa ∧Pb))]
¬Elim
Pa ∧Pb
Pa
∨Intro1 Pa ∨¬(Pa ∧Pb)
[¬(Pa ∨¬(Pa ∧Pb))]
¬Elim
Pa ∨¬(Pa ∧Pb)
Hence, the English sentence is logically true in predicate logic. An inspec-
tion of the proof shows that I have only used rules from propositional
logic: the formalisation of the designator 'Alfred' as a constant and of
'... is an eminent logician' as a predicate letter has not been used at all.
Te parsing of the sentence 'Alfred is an eminent logician' into a predicate
expression and a designator is not really needed in order to see that the
sentence is logically true: if I had formalised the sentences 'Alfred is an
eminent logician' and 'Kurt is an eminent logician' just with two sentence
letters, I would also have obtained a logically true L2-sentence (which is
also a tautology). In fact, on page 68 I already showed that the sentence
is logically true in propositional logic, that is, it is a tautology. Tus, I did
not need to use the more detailed formalisation in order to establish that
the English sentence is a tautology. Tis observation can be generalised:
If a partial formalisation of an English sentence is logically true, then
that English sentence is logically true in predicate logic. Similarly, if a par-
tial formalisation of an English argument is valid, then that English argu-
ment is valid in predicate logic.
By a partial formalisation of a sentence I mean here a translation of
that sentence into the formal language (L1 or L2) that has been obtained
according to the rules for translating, but that has not reached its full
formalisation. Tus, in order to show that an argument is valid, one does
not always have to give a full formalisation. Of course it is not wrong to
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
159
give the full formalisation, but giving merely a partial formalisation will
be less laborious.
I will illustrate this point with the following argument:
Every student has a computer. Wilma doesn't have a com-
puter. Terefore Wilma isn't a student.
I have already formalised the ﬁrst premiss on page 90. Tis time I will
formalise the expression 'has a computer' as a unary predicate letter, that
is, I will not formalise the existential quantiﬁer contained in '... has a
computer' as on page 90.
P:
... is a student
P1:
... has a computer
a:
Wilma
With this dictionary the formalisation of the ﬁrst premiss is ∀x(Px →
P1x), the formalisation of the second premiss is ¬P1a, and the formalisa-
tion of the conclusion is ¬Pa. Tis yields a valid argument in predicate
logic: ∀x(Px →P1x), ¬P1a ⊢¬Pa (see Exercise 6.3(i)). Tus, the English
argument is valid in predicate logic. Tis has been established without
giving the full formalisation of the ﬁrst premiss as on page 90, that is,
∀x(Px →∃y(Rxy ∧Qy)).
Te next argument (or at least a similar one) has played a role in the
development of logic.3
(H) Horses are animals. Terefore every head of a horse is the head of
an animal.
3 Te dominating form of logic since antiquity was Aristotle's syllogistics. But by the 19th
century some shortcomings of syllogistics had become clear. Syllogistics is not incorrect,
and it is not in conﬂict with modern logic, but it is weaker than predicate logic. In the
19th century various logicians argued that syllogistics cannot cope with arguments of
certain types. An argument similar to the one above was used by De Morgan (1847,
pages 114-115) to demonstrate the insuﬃciency of syllogistics because its validity cannot
be shown in syllogistic logic.
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
160
Here is the logical form of the premiss:
for all x: (if (x is a horse) then (x is an animal))
Tus the premiss can be formalised as ∀x(Px →Qx).
Te logical form of the conclusion of (H) is more diﬃcult to determine.
Te ﬁrst step should be clear, however:
for all x (if x is the head of a horse then x is the head of an
animal)
Te expression 'x is the head of a horse' need not be further analysed for
showing the validity of the argument. Te following logical form of the
conclusion will suﬃce:
for all x (if there is a y: ((y is a horse) and (x is the head of
y)) then there is a y: ((y is an animal) and (x is the head of
y)))
Tus, the conclusion can be formalised as the following L2-sentence:
∀x(∃y(Py ∧Rxy) →∃y(Qy ∧Rxy))
I have used the following dictionary:
P:
... is a horse
Q:
... is an animal
R:
... is the head of ...
Te resulting L2-argument is valid:
example 7.10. ∀x(Px →Qx) ⊢∀x(∃y(Py ∧Rxy) →∃y(Qy ∧Rxy))
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
161
Proof.
[∃y(Py ∧Ray)]
[Pb ∧Rab]
Pb
∀x(Px →Qx)
Pb →Qb
Qb
[Pb ∧Rab]
Rab
Qb ∧Rab
∃Intro
∃y(Qy ∧Ray)
∃Elim
∃y(Qy ∧Ray)
→Intro
∃y(Py ∧Ray) →∃y(Qy ∧Ray)
∀Intro
∀x(∃y(Py ∧Rxy) →∃y(Qy ∧Rxy))
Terefore, argument (H) is valid in predicate logic and, therefore,
logically (formally) valid.
One does need to use a full formalisation in order to show that the
next argument is valid.
Tere is not a single moral person. Terefore all persons are
immoral.
If 'immoral' is understood as 'not moral', the argument can be formalised
as follows:
¬∃x(Px ∧Qx) ⊢∀y(Py →¬Qy)
(7.3)
Te dictionary is obvious:
P:
... is a person
Q:
... is moral
Claim (7.3) can be proved as follows:
¬∃x(Px ∧Qx)
[Pa ∧Qa]
∃Intro
∃x(Px ∧Qx)
¬Intro
¬(Pa ∧Qa)
[Pa]
[Qa]
Pa ∧Qa
¬Intro
¬Qa
→Intro
Pa →¬Qa
∀Intro
∀y(Py →¬Qy)
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
162
Te arguments considered so far in this section have all been valid. I
will now consider an argument in English that is not valid:
All lottery tickets are winners or losers. Terefore all tickets
are winners.
Using this trivial example I shall explain in some detail how the semantics
of L2 can be employed to show that this argument is not valid in predicate
logic.
First I will formalise the argument. Te premiss becomes
∀x(Px →Qx ∨Rx),
and the conclusion
∀x(Px →Qx).
Te dictionary should be obvious:
P:
... is a lottery ticket
Q:
... is a winner
R:
... is a loser
I want to disprove the validity of the resulting L2-argument, that is, I want
to show the following:
∀x(Px →Qx ∨Rx) ⊭∀x(Px →Qx)
(7.4)
Tis can be achieved by means of a counterexample, that is, by means of
an L2-structure in which the premiss is true and the conclusion is false.
Te L2-structure F constitutes such a counterexample; it has a domain
with only the number 1 in it:
DF = {1}
∣P∣F = {1}
∣Q∣F = ∅
∣R∣F = {1}
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
163
Te semantical values for the other constants, sentence letters, and predi-
cate letters do not matter, and I will not specify them.
Next, I will show that the premiss is true in F. Over the domain DF
there is only a single variable assignment α, because there is only one
object in the domain and for any variable v, α(v) must be 1, so ∣x∣α
F = 1.
Now one can reason as follows:
∣x∣α
F ∈∣R∣F
deﬁnition of F
∣Rx∣α
F = T
Deﬁnition 5.2(i)
∣Rx ∨Qx∣α
F = T
Deﬁnition 5.2(iv)
∣Px →Rx ∨Qx∣α
F = T
Deﬁnition 5.2(v)
∣∀x(Px →Rx ∨Qx)∣F = T
Deﬁnition 5.2(vii)
Te last line holds because there is only one variable assignment over DF.
Tus, the premiss is indded true in the L2-structure F.
It remains to show that the conclusion is false in F:
∣x∣α
F is not in ∣Q∣F
deﬁnition of F
∣Qx∣α
F = F
Deﬁnition 5.2(i)
∣x∣α
F ∈∣P∣F
deﬁnition of F
∣Px∣α
F = T
Deﬁnition 5.2(i)
∣Px →Qx∣α
F = F
Deﬁnition 5.2(v)
∣∀x(Px →Qx)∣F = F
Deﬁnition 5.2(vii)
Te last line shows that the conclusion is not true in F, and thus the claim
7.4 is established. Consequently, the English argument is not valid in
predicate logic.
Generally, in order to show that an English argument is not valid in
predicate logic, one will formalise the argument and provide a counterex-
ample to the resulting L2-argument.
I have said that one can show that an English argument is valid by
providing a partial formalisation that is a valid L2-argument. In order to
© Volker Halbach
2008/2009

7 Formalisation in Predicate Logic
164
refute the validity of an English argument, merely partial formalisations
cannot be used: usually an English argument that is valid in predicate
logic will have some L2-formalisation that is not valid. Tus, in order to
show that an English argument is not valid in predicate logic, one needs
to consider its full formalisation.
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
In this chapter I will introduce a third formal language. Tis new language
L= is the language of predicate logic with identity; it is only a small
reﬁnement of the language L2 of predicate logic: L= is just L2 with the
addition of the new symbol = for identity.
8.1 qualitative and numerical identity
Philosophers have distinguished two diﬀerent notions of identity: quali-
tative identity and numerical identity. In the following example I present
a case of qualitative identity.
Tere is a fountain pen in my teaching room and another
fountain pen in my study at home. Tey are the same model,
the same colour, and both are still in pristine condition. Tus,
I have two identical fountain pens.
Tere are two pens, and they are qualitatively identical because they are
in all relevant aspects very similar.
To explain numerical identity, I will expand the example a little bit:
A fountain pen expert sees my pen at home afer having
seen the pen in my teaching room the day before. He may
wonder whether I have taken the pen home and ask: 'Is this
the same pen as the pen in your teaching room?' or 'Is this
pen identical to the pen I saw yesterday?'
He knows all the ways that the pen at my home and the pen in my teaching
room are similar, and so he is not asking whether they are the same colour
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
166
or are of the same brand etc; rather he wants to know whether it is the
same pen, that is, whether he has seen two (qualitatively identical) pens
or whether he has seen one and the same pen. So in his question identity
has to be understood numerically. In the numerical sense the pen in my
teaching room is not identical with the pen in my study at home, that is,
there are two pens.
Occasionally it is not clear which kind of identity is at issue in a given
sentence. Te claim
Robin saw the same tree years later in the garden
might be taken to express that Robin saw one and the same tree in the
garden years later, or that he saw a tree of the same kind in the garden
years later.
Qualitative identity may be formalised by a binary predicate letter
of L2. Its treatment in predicate logic with identity does not diﬀer from
the treatment of most other binary predicates.
Numerical identity, in contrast, is given a special status. In what fol-
lows I shall talk exclusively about numerical identity. Numerical identity
is formalised by a new, special predicate letter.
8.2 the syntax of L=
All formulae of L2 are also formulae of L=. But L= also includes a new
kind of atomic formula.
definition 8.1 (atomic formulae of L=). All atomic formulae of L2 are
atomic formulae of L=. Furthermore, if t1 and t2 are variables or constants,
then t1=t2 is an atomic formula of L=.
Examples of atomic formulae of L= are x = x, x = z56, a = y, and
a34=c22, and atomic formulae of L2 such as P3
5 xxc3. Otherwise, there are
no deviations from the syntax of L2, and one can build complex formulae
using connectives and quantiﬁers as in L2 in accordance with Deﬁnition
4.7 of a formula of L2. Of course, now one must also allow for =. Te new
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
167
symbol = behaves exactly like a binary predicate letter, with the exception
that = is written between the variables or constants. Writing the identity
symbol like other predicate letters as the ﬁrst symbol in atomic formulae
would look odd, as we are used to writing x = y rather than =xy, but that
is the only reason for writing x = y rather than =xy.
Te formulae of L= are deﬁned in the same way as the formulae of L2
in Deﬁnition 4.7, with the only exception that the new atomic formulae
can be used.
definition 8.2 (formulae of L=).
(i) All atomic formulae of L= are formulae of L=.
(ii) If ϕ and ψ are formulae of L=, then ¬ϕ, (ϕ ∧ψ), (ϕ ∨ψ), (ϕ →ψ)
and (ϕ ↔ψ) are formulae of L=.
(iii) If v is a variable and ϕ is a formula of L= then ∀v ϕ and ∃v ϕ are
formulae of L=.
For instance, ¬ x = y and ∀x(Rxy2 →y2=x) are formulae of L=.
All other deﬁnitions from Section 4.2 carry over as well. Sentences
of L= are deﬁned as those formulae in which no variable occurs freely.
Also, the bracketing conventions are the same as for L2.
8.3 semantics
Te semantics for L= is just a small variation on the semantics for L2, and
so it is not necessary to introduce a new kind of structure: L2-structures
are used for the semantics of L=.
Only Deﬁnition 5.2 needs to be amended by adding the following
additional clause to (i)-(viii), where A is an L2-structure, s is a variable
or constant, and t is a variable or constant:
(ix) ∣s=t∣α
A = T if and only if ∣s∣α
A = ∣t∣α
A.
Tus, in the semantics for L=, the symbol = is always interpreted as nu-
merical identity. In (ix) the symbol = is used in two diﬀerent ways: its ﬁrst
occurrence is a symbol of the formal language L=; the two subsequent
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
168
occurrences belong to the language we are using to describe L=. In order
to avoid this ambiguity some authors put a dot under the symbol of the
formal language, but this convention has not really caught on. Alterna-
tively, one could avoid the use of = outside the formal language L= by
reformulating (ix) in the following way:
(ix) Te variable assignment α satisﬁes s=t in A if and only if ∣s∣α
A and
∣t∣α
A are the same object.
In the following I will not try to avoid the use of = in these two diﬀerent
roles: it should be clear for every occurrence of the symbol whether it
is used as a symbol of L= or as a symbol of our everyday mathematical
language.
It follows from clause (ix) that for any L2-structure A, ∣a = a∣A = T
and for any variable assignment α over A, ∣x =x∣α
A = T, because, trivially,
∣x∣α
A is the same object as ∣x∣α
A, and ∣a∣A is the same object as ∣a∣A. Of
course, the same applies to variables other than x and to constants other
than a.
Te deﬁnitions of validity of arguments, of semantic consistency, of log-
ically true sentences, and so on, carry over from Deﬁnitions 5.7 and 5.8.
Te method of counterexamples can be applied in the same way as it
was for the language L2. As an example I will show that ∃x ∃y¬ x = y does
not follow in predicate logic with identity from the premiss ∃x Px∧∃y Py.
example 8.3. ∃x Px ∧∃y Py ⊭∃x ∃y ¬ x = y
Te argument could be a formalisation of the following English argu-
ment:
Tere is a painting and there is a painting. Terefore there
are at least two things.
A more literal translation of the conclusion ∃x ∃y ¬ x = y would be 'there
is a thing such that there is a thing that is not identical to the ﬁrst'; but
that is just a longwinded way of saying that there are at least two things.
Te premiss just makes the same claim twice, namely that there is a
painting. Te use of the two variables x and y does not imply that there
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
169
are two diﬀerent paintings. Tis yields the idea for the following proof.
Proof. Let B be an L2-structure with (the painting of) Mona Lisa as the
only element in its domain of discourse, and {the Mona Lisa } as the
extension of P.
DB = { the Mona Lisa }
∣P∣B = { the Mona Lisa }
First I will show that the premiss is true in this structure.
Tere is exactly one variable assignment α over B: it assigns the Mona
Lisa to all variables, so ∣x∣α
A is the Mona Lisa.
the Mona Lisa ∈{the Mona Lisa}
∣x∣α
B ∈∣P∣B
∣Px∣α
B = T
Deﬁnition 5.2(i)
∣∃x Px∣B = T
Deﬁnition 5.2(viii)
Since α assigns the Mona Lisa to y as well, the same reasoning can be
applied to y:
∣y∣α
B ∈∣P∣B
∣Py∣α
B = T
Deﬁnition 5.2(i)
∣∃y Py∣B = T
Deﬁnition 5.2(viii)
Taking the last lines together, one can infer the following by Deﬁnition
5.2(iii):
∣∃x Px ∧∃y Py∣B = T
So the premiss is true in B, and it remains to show that the conclusion is
not true in B.
Assume to the contrary that the conclusion is true in B, that is, assume
that ∣∃x ∃y ¬x = y∣B = T. Ten, by Deﬁnition 5.2(viii), for at least one
variable assignment the following must obtain:
∣∃y ¬x = y∣α
B = T
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
170
Applying Deﬁnition 5.2(viii) again, one can conclude that there is a vari-
able assignment β over B, diﬀering from α in y at most, such that the
following obtains:
∣¬ x = y∣β
B = T
(In fact, there is only one variable assignment over B and therefore α and
β are the same variable assignment, but I do not make use of this fact
here.)
By Deﬁnition 5.2(ii) it follows that
∣x = y∣β
B = F.
(8.1)
Since there is only one object in the domain of B, namely the Mona Lisa,
∣x∣β
B and ∣y∣β
B are the same object. Tus, ∣x∣β
B = ∣y∣β
B, which implies the
following by the above special supplementary clause (ix) for Deﬁnition 5.2:
∣x = y∣β
B = T
Tis contradicts (8.1), which followed from the assumption that the con-
clusion ∃x ∃y ¬x = y is true in B. Tus, the conclusion is not true in B,
and it has been shown that ∃x ∃y ¬x = y does not follow from the premiss
∃x Px ∧∃y Py.
8.4 proof rules for identity
In order to obtain a proof system that is sound and complete with respect
to the semantics for L=, the system of Natural Deduction needs to be
expanded so as to include an introduction and an elimination rule for
identity.
Te introduction rule allows one to assume a=a (and similarly for
all other constants) and to discharge a=a immediately:
=Intro
Any assumption of the form t =t where t is a constant
can and must be discharged.
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
171
Hence, a proof with an application of =Intro looks like this:
[t=t]
⋮
To motivate the elimination rule I will look at the following infor-
mal way of reasoning: if one has established that Mount Everest is Qo-
molangma and that Mount Everest is in Asia, then one can conclude that
Qomolangma is in Asia. Te elimination rule for identity is the formal
counterpart of the general principle legitimating this substitution. In this
rule ϕ is a formula of L= with at most one variable v occurring freely.
=Elim
If s and t are constants, the result of appending ϕ[t/v]
to a proof of ϕ[s/v] and a proof of s = t or t = s is a proof of
ϕ[t/v].
Te graphical representation of the rule looks as follows:
⋮
ϕ[s/v]
⋮
s=t
=Elim
ϕ[t/v]
⋮
ϕ[s/v]
⋮
t=s
=Elim
ϕ[t/v]
Strictly speaking, only one of the versions is needed, as from s=t one can
always obtain t=s using only one of the rules, as will be shown in Example
8.5. Having both versions available is, however, more convenient.
I give some examples illustrating the use of these rules.
example 8.4. ⊢∀x x =x
Proof. Te proof is very short:
[a=a]
∀x x =x
First a=a is assumed and immediately discharged by =Intro. Ten ∀Intro
can be applied without violating the restriction on constants.
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
172
example 8.5. ⊢∀x ∀y (x = y →y=x)
Proof.
[a=a]
[a=b]
=Elim
b=a
→Intro
a=b →b=a
∀Intro
∀y (a= y →y=a)
∀Intro
∀x∀y (x = y →y=x)
Tis proof shows that =Elim does not demand that one replace all the
occurrences of a by b in the step from the ﬁrst to the second line. Tis
step is licensed by the rule =Elim, taking ϕ to be the formula x =a.
example 8.6. ⊢∀x ∀y ∀z (x = y ∧y=z →x =z)
Proof.
[a=b ∧b=c]
∧Elim1
a=b
[a=b ∧b=c]
∧Elim2
b=c =Elim
a=c
→Intro
a=b ∧b=c →a=c
∀Intro
∀z (a=b ∧b=z →a=z)
∀Intro
∀y∀z (a= y ∧y=z →a=z)
∀Intro
∀x∀y∀z (x = y ∧y=z →x =z)
Tis proof system, like those of propositional and predicate logic, is
adequate:
theorem 8.7 (adequacy). Assume that ϕ and all elements of Γ are L=-
sentences. Ten Γ ⊢ϕ if and only if Γ ⊧ϕ.
As in the case of propositional and predicate logic, I will not prove
the Adequacy Teorem here.
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
173
8.5 uses of identity
Te word 'is' can play various rôles. It can be used to express predication,
as in 'Snow is white' or 'Jane is a classicist'. In these cases 'is' forms part of
the predicate. Te phrase 'is a classicist' is formalised as a unary predicate
letter as it does not refer to a speciﬁc classicist.
In other cases 'is' is used to express identity as in 'Ratzinger is Bene-
dict XVI.' or 'St Mary College of Winchester is New College.' In these
cases, 'is' combines two designators and expresses (numerical) identity.
Tus, 'St Mary College of Winchester is New College' is formalised as
a=b with the obvious dictionary:
a:
St Mary College of Winchester
b:
New College
Te identity symbol is useful not only for formalising overt identity
statements, as in the above examples. One can also use the identity symbol
to express that there is a certain number of objects of some kind. Assume
that the predicate letter Px has the following entry in the dictionary:
P:
... is a Wagner opera
Ten the claim that there is at least one Wagner opera can be expressed by
existential quantiﬁcation as ∃xPx. If one wants to say that there are at least
two Wagner operas, however, it does not suﬃce to say ∃x∃y (Px ∧Py) or
∃x Px ∧∃y Py, because these two sentences say merely that something
is a Wagner opera and something is a Wagner opera; it does not say that
something is a Wagner opera and something else is a Wagner opera. But
the latter can be expressed using =:
∃x ∃y (Px ∧Py ∧¬ x = y)
(8.2)
Tis sentence of L= says that there are at least two Wagner operas. Of
course the trick also works with three:
∃x ∃y ∃z (Px ∧Py ∧Pz ∧¬x = y ∧¬x =z ∧¬y=z)
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
174
Tis sentence says that there are at least three Wagner operas.
By using identity one can also express that there is at most one Wagner
opera by saying that, if x and y are Wagner operas, then x and y are
identical:
∀x ∀y (Px ∧Py →x = y)
(8.3)
Again this also works for 'at most two', 'at most three', and so on.
'Tere are at most two Wagner operas' can be formalised as
∀x ∀y ∀z (Px ∧Py ∧Pz →x = y ∨y=z ∨x =z).
(8.4)
'Tere is exactly one Wagner opera' can now be rephrased as 'Tere is
at least one Wagner opera and there is at most one Wagner opera', and I
have already shown how to express the two parts of that claim: ∃x Px says
that there is at least one such opera, and the second part, beginning with
'at most', has (8.3) as its formalisation. So 'Tere is exactly one Wagner
opera' can be formalised by the following L=-sentence:
∃x Px ∧∀x ∀y (Px ∧Py →x = y)
(8.5)
Tis can also be expressed by the following logically equivalent formula:
∃x(Px ∧∀y(Py →x = y))
(8.6)
Tis sentence says that there is a Wagner opera and it is the only one, that
is, any Wagner opera is identical to it. A still more concise version is the
sentence ∃x ∀y(Py ↔x = y).1
Similarly, one can express in L= that there are exactly two Wagner
operas by combining (8.2) with (8.4):
∃x ∃y(Px ∧Py∧¬x = y)∧∀x ∀y ∀z (Px ∧Py∧Pz →x = y∨y=z∨x =z)
By this method one can express, in the language L=, that there are
exactly 13 Wagner operas, although this L=-sentence will be painfully long.
1 Te equivalence to (8.5) follows from Exercise 8.5.
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
175
One might think that the claim that there are 13 Wagner operas involves
also a claim about a mathematical object, namely the number 13. However,
the claim can be formalised without using a predicate letter or constant
for numbers. Terefore, one can dispense with numbers when claiming,
for instance, that there are exactly 13 Wagner operas. Some philosophers
have tried to dispense with numbers and other mathematical objects
completely, and the examples of this section show that identity can be
used to express certain claims without reference to numbers, even if these
claims seem to be about numbers at ﬁrst glance.
With these tricks at one's disposal one can tackle a problem with the
formalisation of designators such as 'the king of France', 'Claudia's garden',
'the tallest tutor of New College who can speak Latin but does not own a
car', or 'the car owned by Tim'. Designators of this kind are called 'deﬁnite
descriptions'. Deﬁnite descriptions cannot be adequately formalised as
constants. Te following argument is logically valid:
(T) Te car owned by Tim is red. Terefore there is a red car.
Formalising the deﬁnite description by a constant yields Pa for the pre-
miss and ∃x(Px ∧Qx) for the conclusion, with the obvious dictionary:
a:
the car owned by Tim
P:
... is red
Q:
... is a car
Clearly, the argument in L2 corresponding to the English argument (T)
is not valid, that is, Pa ⊭∃x(Px ∧Qx).2 By formalising a deﬁnite de-
scription as a constant one loses all the information contained in the
deﬁnite description. As the examples above show, a deﬁnite description
can contain a lot of information, and condensing 'the tallest tutor of New
College who can speak Latin but does not own a car' into a single constant
is bound to be inadequate.
2 See Exercise 5.2(i).
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
176
If Tim did not own a car at all, the premiss 'Te car owned by Tim is
red' would not be true; if Tim owned two or more cars the premiss would
also be not true, as there would not be any car that is the car owned by
Tim would not exist. Te premiss implies that Tim owns exactly one car.
In fact, the premiss can be rephrased as follows:3
Tim owns exactly one car and it is red.
From the above it is clear how to express the claim that there is exactly
one car owned by Tim. So the sentence can be rephrased in the following
way:
Tere is a car owned by Tim, and it's his only car (that is,
every car Tim owns is identical to it), and it is red.
Following the pattern of (8.6), the premiss of (T) is formalised as follows:
∃x ((Qx ∧Rbx) ∧∀y(Qy ∧Rby →x = y) ∧Px)
(8.7)
For this formalisation the dictionary needs to be extended to cover b
and R:
b:
Tim
R:
... owns ...
When the deﬁnite description 'the car owned by Tim' was formalised
as a constant, the validity of (T) could not be captured by the validity of
its formalisation. Tis was the motive for seeking a more reﬁned analysis
of the deﬁnite description. I still have to show that the new, more detailed
analysis actually allows me to show the validity of (T) by establishing
the validity of its translation. Te premiss now is formalised as (8.7) and
the conclusion as before by ∃x(Px ∧Qx). With this formalisation the
argument is valid in predicate logic with identity:
3 Te following is Russell's (1905) theory of deﬁnite descriptions. For a criticism of Russell's
theory see (Strawson, 1950).
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
177
example 8.8.
∃x((Qx ∧Rbx) ∧∀y(Qy ∧Rby →x = y) ∧Px) ⊢∃x(Px ∧Qx)
Te proof is on the next page.
In some cases it may not be so easy to see that a sentence contains
a deﬁnite description. Especially identity statements involving deﬁnite
descriptions may be confusing. Consider the following two sentences:
(i) Jane is a classicist.
(ii) Jane is the classicist.
In the ﬁrst sentence 'is' expresses predication. Sentence (ii), however, is
an identity statement: 'Jane' is a proper name, while 'the classicist' is a
deﬁnite description. If '... is a classicist' is translated as Q1 and 'Jane' as
c1, sentence (i) becomes Q1c1, while (ii) becomes the following formula,
when formalised in the style of 8.7:
∃x(Q1x ∧∀y(Q1y →y=x) ∧c1=x)
Tis sentence is logically equivalent to
Q1c1 ∧∀y(Q1y →y=c1),
which says that Jane and only Jane is a classicist.4
Te following example of a sentence containing a deﬁnite description
is due to Russell (1905):
Te king of France is bald.
By 'the king of France' I mean 'the present king of France'. Tus, this
deﬁnite description does not refer to any object because France is a re-
public, not a monarchy. Applying the strategy above, one can rephrase
this sentence as follows:
4 Someone might could retort that (i) can be analysed as an identity statement as well,
because it says that Jane is identical to some classicist. See Exercise 8.3 for this analysis.
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
178
∃x((Qx ∧Rbx) ∧∀y(Qy ∧Rby →x = y) ∧Px)
[((Qc ∧Rbc) ∧∀y(Qy ∧Rby →c= y)) ∧Pc]
Pc
[((Qc ∧Rbc) ∧∀y(Qy ∧Rby →c= y)) ∧Pc]
(Qc ∧Rbc) ∧∀y(Qy ∧Rby →c= y)
Qc ∧Rbc
Qc
Pc ∧Qc
∃Intro
∃x(Px ∧Qx)
∃Elim
∃x(Px ∧Qx)
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
179
Tere is exactly one king of France, and he is bald.
Tis English sentence can be formalised as a sentence expressing that
there is a king of France, he is the only king of France, and he is bald:
∃x(Rxc ∧∀y(Ryc →y=x) ∧Px)
R:
... is the king of ...
c:
France
P:
... is bald
Since France is a republic, the sentence 'Te king of France is bald' is
false. However, the sentence
Te king of France is not bald
(8.8)
is also false under at least one reading: it seems to say that there is exactly
one king of France and that he is not bald, which is also not true since
there is no king of France.
Te following sentence, in contrast, is true:
It is not the case (for whatever reason) that the king of France is bald.
(8.9)
Here the claim that the king of France is bald is rejected: it leaves open
whether there is a king of France who is not bald or whether there is no
king of France at all, or, perhaps, whether there is more than one king, so
that there is nothing that is the king of France.
Sentence (8.8) is most naturally formalised by the following sentence:
∃x(Rxc ∧∀y(Ryc →y=x) ∧¬Px)
(8.10)
Tis says that there is a king of France, that he is the only king of France,
and that he is not bald. So only the baldness is denied, not that there is
exactly one king of France.
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
180
Whereas in 8.10 the negation symbol directly precedes Px, in the
formalisation of (8.9) it is at the beginning:
¬∃x(Rxc ∧∀y(Ryc →y=x) ∧Px)
(8.11)
Tis expresses that it is not the case (for whatever reason) that there is a
king of France, who is the only one, and who is bald.
If these formalisations are correct, then (8.8) and (8.9) have diﬀerent
meanings. But especially the formalisation of (8.8) is not uncontrover-
sial, and there may be another reading of (8.8) that results in a diﬀerent
formalisation. Te following claim is a valid argument only if (8.8) is
understood as expressing the same as (8.9):
Te king of France is not bald; for there is no king of France.
Te ﬁrst sentence is the conclusion, the second sentence is the premiss of
the argument. It can be formalised as a valid argument in L2 only if (8.8)
is formalised like (8.9) as (8.11). Tus, depending on the reading, there
are two formalisations of (8.8) in L= that are not logically equivalent,
namely (8.10) and (8.11). If an English sentence has two non-equivalent
formalisations, it is ambiguous. By comparing (8.10) and (8.11), one can
see that this is a case of a scope ambiguity again. In formalisation (8.10)
the occurrence of ¬ has a 'narrow' scope; its scope is only ¬Px. In for-
malisation (8.11) the negation symbol has a 'wide' scope: its scope is the
entire sentence. Which formalisation is better has to be decided from
case to case, depending on the context.
Te analysis of deﬁnite descriptions just sketched allows one to treat
the expression 'the king of France' as an expression that does not refer to
an object in any case. Tis is an advantage, compared to a formalisation
of 'the king of France' as a constant: a constant has exactly one object as
it semantic value in any given L2-structure; a constant refers to an object
in any L2-structure. If a constant is used, the following argument comes
out as valid in L=:
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
181
It is not the case that the king of France is bald. Terefore
something is not bald.
Let the constant a stand for 'the king of France'. Ten ¬Pa ⊢∃x ¬Px
can be established by a single application of the rule ∃Intro. However, the
English argument clearly is not valid. Te formalisation is valid, while the
English argument is not, because the semantics of constants in L2 and of
deﬁnite descriptions in English are diﬀerent: in L2 constants always refer
to some object, while in English deﬁnite descriptions such as 'the king of
France' may fail to refer to an object.
If the premiss 'It is not the case that the king of France is bald' is
formalised as (8.11)
¬∃x(Rxc ∧∀y(Ryc →y=x) ∧Px),
in accordance with the above proposed analysis of deﬁnite descriptions,
then its formalisation correctly comes out as not valid. Tis example
shows that, at least in some cases, the proposed theory of deﬁnite de-
scriptions can be used to handle English designators that do not denote
anything.
So far I have formalised proper names as constants. In the light of
what has just been said, one may doubt the universal adequacy of this
formalisation of proper names: a proper name such as 'Pegasus' does not
seem to refer to an object (existing now or in the past). One proposal for
dealing with this problem is to formalise proper names in the same way
as deﬁnite descriptions. But doing so requires a predicate that singles
out Pegasus, such that Pegasus, if he existed, would be the one and only
object satisfying this predicate. Logicians have also played with alternative
semantics, where constants may fail to refer to an object. All of these
proposals are beyond the scope of this text.
Tis discussion of deﬁnite descriptions shows that the identity symbol
of L= is used for more than just formalising overt identity statements
in English. Many more sentences and arguments can be analysed using
identity. So formalisations in L= capture more details than formalisations
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
182
in L2. Consequently, there are English arguments that can be shown to
be valid in predicate logic with identity but not in predicate logic without
identity. Te argument (T) above is such an argument.
Of course, strictly speaking I still have to explain what I mean by
validity of an argument in predicate logic with identity, but the explanation
should be obvious:
Validity of English arguments (and logical truth etc) in predicate logic
with identity is deﬁned analogously to validity of arguments in proposi-
tional and predicate logic in Deﬁnitions 3.6, 7.8, 3.5 and 7.7.
8.6 identity as a logical constant
Prima facie identity seems to be merely another binary predicate in Eng-
lish. In the semantics of L=, however, the identity symbol is always in-
terpreted as numerical identity, while other binary predicate letters can
be interpreted as arbitrary binary relations. Why does identity receive
this special treatment? Why is there not a predicate logic with special
treatment for other binary predicates such as 'is smaller than' or 'loves'?
One could come up with a special symbol for any of those binary predi-
cates and invent a semantics in which they are always interpreted in the
same way. Why is identity singled out as a logical predicate, while others
are not? I shall illustrate the diﬀerent treatment of identity and other
relations by considering two examples.
In predicate logic with identity the following argument is valid:
Te morning star is the evening star. Te morning star is a
planet. Hence the evening star is a planet.
In L= the premisses can be formalised as a=b and Pa and the conclusion
as Pb. Te claim a = b, Pa ⊧Pb can easily be established by a proof in
Natural Deduction.
In predicate logic without identity, the best possible formalisation
of the premisses is Rab, Pa and of the conclusion Pb, with an entry in
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
183
the dictionary for Rxy as '... is identical to ...'. But, by specifying an
L2-structure in which Rab and Pa are true, and Pb is not, Rab, Pa ⊧Pb
can easily be refuted. Tus, the above argument is valid in predicate logic
with identity but not in predicate logic without identity. Te reason is
that in L= the interpretation of = is ﬁxed, while in L2 the binary predicate
letter R may be interpreted as any arbitrary binary relation.
Te argument can be compared with the following argument:
Te evening star is smaller than Uranus. Uranus is smaller
than Saturn. Terefore the evening star is smaller than Sat-
urn.
Tis argument is not valid in predicate without identity or in predicate
logic with identity. If the interpretation of 'smaller than' were ﬁxed in the
way the interpretation of identity is ﬁxed in L=, that is, if the predicate
letter for '... is smaller than ...' were always interpreted as the smaller-
than relation, the argument would come out as valid. Generally, ﬁxing the
interpretation of further predicates, such as 'is smaller than', will make
more arguments valid and more sentences logically true, but it is doubtful
whether such notions of validity still capture logical validity and logical
truth.
In Characterisation 1.7 of valid arguments in Section 1.5 I stipulated
that an argument is valid if and only if there is no interpretation under
which the premisses are all true and the conclusion is false. In interpreta-
tions, only the vocabulary that is non-logical can be reinterpreted. Logical
vocabulary has been characterised as not subject-speciﬁc. Te predicate
expression 'is smaller than' is arguably subject-speciﬁc because it can
only be sensibly applied to objects with spatial extension (and perhaps to
numbers); at least it is not so clear whether it can be applied to objects
such as thoughts, properties, laws, or functions. Identity, in contrast, is
not speciﬁc to any subject. Tus, it cannot be reinterpreted. Logicians say
that identity is a logical constant. Tis way of distinguishing logical from
non-logical vocabulary is far from being clear and precise, and the dis-
© Volker Halbach
2008/2009

8 Identity and Deﬁnite Descriptions
184
tinction and the possibility of such a distinction are controversial issues
in the philosophy of logic.
Of course there could still be expressions in English that, while not
contained as logical symbols in L=, are yet logical expressions. In fact,
many logicians believe that the language L= ought to be extended so as to
include additional logical symbols expressing, for instance, 'it is necessary
that ...' Consequently, they think that there are valid arguments in English
that are not valid in predicate logic with identity. Other philosophers
think that any valid argument of English can be formalised as a valid
argument in L=, so long as certain formalisation tricks are allowed. Tese
controversies are not only crucial for the philosophy of logic and language,
they also impinge on ontology and other core disciplines of philosophy.
At any rate, L2 and L= are very powerful languages. Many logicians,
mathematicians, and philosophers believe that L= is suﬃcient for formal-
ising very comprehensive parts, if not all, of mathematical and scientiﬁc
discourse. If the language of mathematics and science can indeed be
handled in the language of predicate logic with identity, there is hope that
it can even capture large parts of philosophy.
© Volker Halbach
2008/2009

Natural Deduction Rules
propositional logic
⋮
ϕ
⋮
ψ
∧Intro
ϕ ∧ψ
⋮
ϕ ∧ψ
∧Elim1
ϕ
⋮
ϕ ∧ψ
∧Elim2
ψ
[ϕ]
⋮
ψ
→Intro
ϕ →ψ
⋮
ϕ
⋮
ϕ →ψ
→Elim
ψ
⋮
ϕ
∨Intro1
ϕ ∨ψ
⋮
ψ
∨Intro2
ϕ ∨ψ
⋮
ϕ ∨ψ
[ϕ]
⋮
χ
[ψ]
⋮
χ
∨Elim
χ
© Volker Halbach
2008/2009

Natural Deduction rules
186
[ϕ]
⋮
ψ
[ϕ]
⋮
¬ψ
¬Intro
¬ϕ
[¬ϕ]
⋮
ψ
[¬ϕ]
⋮
¬ψ
¬Elim
ϕ
⋮
ϕ →ψ
⋮
ψ →ϕ
↔Intro
ϕ ↔ψ
⋮
ϕ ↔ψ
↔Elim1
ϕ →ψ
⋮
ϕ ↔ψ
↔Elim2
ψ →ϕ
predicate logic
⋮
ϕ[t/v]
∀Intro
∀vϕ
provided the constant t does not
occur in ϕ or in any undischarged
assumption in the proof of ϕ[t/v].
⋮
∀vϕ
∀Elim
ϕ[t/v]
ϕ[t/v]
∃Intro
∃vϕ
⋮
∃vϕ
[ϕ[t/v]]
⋮
ψ
∃Elim
ψ
provided the constant t does not
occur in ∃v ϕ, or in ψ, or in any
undischarged assumption other
than ϕ[t/v] in the proof of ψ.
identity
[t = t]
⋮
⋮
ϕ[s/v]
⋮
s = t
=Elim
ϕ[t/v]
⋮
ϕ[s/v]
⋮
t = s
=Elim
ϕ[t/v]
© Volker Halbach
2008/2009

Bibliography
Cappelen, Herman and Ernest LePore (Spring 2007), Quotation, in
E. N.Zalta, ed., 'Te Stanford Encyclopedia of Philosophy'.
URL: http://plato.stanford.edu/archives/spr2007/entries/quotation/
Church, Alonzo (1936), 'A note on the Entscheidungsproblem', Journal of
Symbolic Logic 1, 40-41.
De Morgan, Augustus (1847), Formal Logic, Taylor & Walton, London.
Devlin, Keith (1993), Fundamentals of Contemporary Set Teory, second
edn, Springer-Verlag, New York.
Forbes, Graeme (1994), Modern Logic, Oxford University Press, Oxford.
Geach, Peter (1962), Reference and Generality, Cornell University Press,
Ithaca.
Gentzen, Gerhard (1935), 'Untersuchungen über das natürliche Schließen',
Mathematische Zeitschrif 39, 176-210, 405-565.
Guttenplan, Samuel (1997), Te Languages of Logic, second edn, Blackwell,
Malden.
Halmos, Paul R. (1960), Naive Set Teory, D. Van Nostrand Company,
Princeton. Reprinted, Springer-Verlag, New York, NY, 1974.
Hodges, Wilfrid (2001), Logic: An Introduction to Elementary Logic, sec-
ond edn, Penguin Books, London.
© Volker Halbach
2008/2009

Index
188
Jaśkowski, Stanislaw (1934), 'On the rules of supposition in formal
logic', Nakładem Seminarium Filozoﬁcznego Wydzialu Matematyczno-
Przyrodniczego Uniwersytetu Warszawskiego .
Lewis, David (1973), Counterfactuals, Harvard University Press, Cam-
bridge MA. reissued in 2001 by Blackwell, London.
Morris, Charles (1938), Foundations of the Teory of Signs, University of
Chicago Press, Chicago.
Moschovakis, Yiannis (1994), Notes on Set Teory, Undergraduate texts
in mathematics, second edn, Springer, New York.
Quine, Willard O. V. (1940), Mathematical Logic, Norton, New York.
Neuauﬂage 1951 von Harvard University Press (Cambridge, M.A.).
Russell, Bertrand (1905), 'On denoting', Mind 14, 479-493.
Sainsbury, Mark (2001), Logical Forms, second edn, Blackwell, Oxford.
Smith, Peter (2003), An Introduction to Formal Logic, Cambridge Univer-
sity Press, Cambridge.
Strawson, Peter F. (1950), 'On referring', Mind 59, 320-344.
Tarski, Alfred (1936), 'Der Wahrheitsbegriﬀin den formalisierten
Sprachen', Studia Philosophica Commentarii Societatis Philosophicae
Polonorum 1.
Tennant, Neil (1990), Natural Logic, 2nd edn, Edinburgh University Press,
Edinburgh.
Troelstra, Arne S. and Helmut Schwichtenberg (1996), Basic Proof Teory,
number 43 in 'Cambridge Tracts in Teoretical Computer Science',
Cambridge University Press, Cambridge.
© Volker Halbach
2008/2009

Index
adequacy, 143, 173
for predicate logic, 143
for propositional logic, 128
ambiguity, 63-65, 148
lexical, 148
of scope, 181
antisymmetric, 10
argument, 17, 115
of a function, 15
arity, 83
arity-index, 76, 88
assignment, 98-114
assumption, 116
asymmetric, 10
atomic formulae, 100
of L2, 83
binary relation, 9, 16
bound occurrence of a variable,
85
Compactness Teorem of propo-
sitional logic, 42
completeness, 115, 142, 143
conclusion, 17
conditionals
counterfactual, 54
indicative, 54
subjunctive, 54
conjunction
of sentences, 30
connectives, 34, 51-56
in L1, 31
in L1, 95
in English, 51
main, 57
consistency, 68
in predicate logic, 157
semantic, 157
semantic in L2, 108
in English, 23
semantic, 144, 145
semantic in L1, 41
syntactic, 144, 145
constants, 76, 83, 95, 96
context, 17
contradiction, 24, 40, 68, 108, 157
contradictory, 40
counterexamples
in L=, 169
in predicate logic, 109-114
in propositional logic, 41
counterfactual
conditionals, 54
cut rule, 121
© Volker Halbach
2008/2009

Index
190
declarative sentence, 17
deductive validity, 20
deﬁnite descriptions, 176
designators, 74, 76, 147, 152, 174
dictionary, 62
disjunction, 122
of sentences, 30
domain
of a function, 15
domains
of discourse, 96
double arrow, 126
double negation elimination, 125
empty set, 7
equivalence
logical, 24, 40, 68, 108
equivalence relation, 10
ex falso quodlibet, 72, 128
extensional, 152
extensionality, 152
extensions, 95, 151
falsity
logical, 24
formal validity, 19
formulae
atomic, 100, 167
of L=, 168
of L2, 84
free occurrence of a variable, 85
function, 14
generalisation, 80
heart, 6
identity
numerical, 166-167
qualitative, 166-167
iﬀ, 10
inconsistency
semantic in L1, 41
syntactic, 144
indicative conditionals, 54
induction, 100
inductive validity, 20
intuitionistic logic, 125
kidney, 6
languages
extensional, 152
letters
propositional, 29
predicate, 76, 83
logical equivalence, 24, 40, 68,
108
logical falsity, 24
logical form, 147
propositional logic, 56
logical terms, 24
logical truth, 24
logical validity, 19, 24, 34
logically true, 108, 110
main column, 39, 40
main columns, 42
main connective, 57
© Volker Halbach
2008/2009

Index
191
metalinguistic variable, 28
metavariables, 27-29
Natural Deduction, 116
negation
of sentences, 30
ordered pair, 9
pair
ordered, 9
partial formalisation, 159
pragmatics, 26
predicate letters, 76, 83, 95, 96
predicate logic, 23
premiss, 17
proof, 21, 115
proper names, 96
property, 6
propositional consistency, 68
propositional contradiction, 68
propositional logic, 23
propositionally valid, 70, 74
provable, 121
quadruple, 16
quotation, 27-29
range
of a function, 15
reductio ad absurdum, 124
reﬂexive, 10
relation, 9
binary, 97
root, 117
satisfaction, 100
scope
of a quantiﬁer, 151
of a connective, 64
scope ambiguity, 64, 151, 181
semantic inconsistency
in L1, 41
semantic consistency, 144, 145
in L1, 41
in L2, 108
semantic values, 95
semantics, 25, 143
sentence letters, 29, 34, 78, 95, 96
sentences
of L2, 86
of L1, 29, 30
of L=, 168
sentential logic, 23
sets, 6-8
soundness, 115, 142, 143
structures, 19, 143
in L1, 35
in L=, 168
in L2, 95-114
subjunctive conditionals, 54
syllogistics, 160
symmetric, 10
symmetry, 11
syntactic consistency, 144, 145
syntactic inconsistency, 144
syntax, 25, 143
© Volker Halbach
2008/2009

Index
192
tautology, 40, 68
ternary, 76
ternary relation, 16
transitive, 10
triple, 16
truth
in an L1-structure, 36
in an L2-structure, 105
logical, 24
truth, logical, 108, 110
truth-functional, 53
truth-functional completeness, 50
truth-values, 53, 95, 98
universal quantiﬁer, 89, 131
valid, 157
valid argument, 72
validity, 19
deductive, 20
inductive, 20
logical, 24, 34
of an argument, 19-24
propositional, 22
value
of a function, 15
values
semantic, 95
variable assignment, 98-114
variables
in L2, 83
metalinguistic, 28
© Volker Halbach
2008/2009

