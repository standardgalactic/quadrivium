
Graduate Texts in Mathematics 
Editorial Board 
S. Axler 
F.W. Gehring 
K.A. Ribet 

BOOKS OF RELATED INTEREST BY SERGE LANG 
Math Talks for Undergraduates 
1999, ISBN 0-387-98749-5 
Linear Algebra, Third Edition 
1987, ISBN 0-387-96412-6 
Undergraduate Algebra, Second Edition 
1990, ISBN 0-387-97279-X 
Undergraduate Analysis, Second Edition 
1997, ISBN 0-387-94841-4 
Complex Analysis, Third Edition 
1993, ISBN 0-387-97886 
Real and Functional Analysis, Third Edition 
1993, ISBN 0-387-94001-4 
Algebraic Number Theory, Second Edition 
1994, ISBN 0-387-94225-4 
OTHER BOOKS BY LANG PUBLISHED BY 
SPRINGER-VERLAG 
Introduction to Arakelov Theory • Riemann-Roch Algebra (with William Fulton) • 
Complex Multiplication • Introduction to Modular Forms • Modular Units 
(with Daniel Kubert) • Fundamentals of Diophantine Geometry • Elliptic 
Functions • Number Theory III • Survey of Diophantine Geometry • Fundamentals 
of Differential Geometry • Cyclotomic Fields I and II • SL 2(R) • Abelian Varieties • 
Introduction to Algebraic and Abelian Functions • Introduction to Diophantine 
Approximations • Elliptic Curves: Diophantine Analysis • Introduction to Linear 
Algebra • Calculus of Several Variables • First Course in Calculus • Basic 
Mathematics • Geometry: A High School Course (with Gene Murrow) • Math! 
Encounters with High School Students • The Beauty of Doing Mathematics • THE 
FILE • CHALLENGES 

Serge Lang 
Algebra 
Revised Third Edition 
Springer 

Serge Lang 
Department of Mathematics 
Yale University 
New Haven, CT 96520 
USA 
Editorial Board 
S. Axler 
Mathematics Department 
San Francisco State 
University 
San Francisco, CA 94132 
USA 
axler@sfsu.edu 
F.W. Gehring 
Mathematics Department 
East Hall 
University of Michigan 
Ann Arbor, MI 48109 
USA 
fgehring@math.Isa. 
umich.edu 
K.A. Ribet 
Mathematics Department 
University of California, 
Berkeley 
Berkeley, CA 94720-3840 
USA 
ribet@math.berkeley.edu 
Mathematics Subject Classification (2000): 13-01, 15-01, 16-01, 20-01 
Library of Congress Cataloging-in-Publication Data 
Algebra /Serge Lang.—Rev. 3rd ed. 
p. cm.—(Graduate texts in mathematics; 211) 
Includes bibliographical references and index. 
ISBN 978-1-4612-6551-1 
ISBN 978-1-4613-0041-0 (eBook) 
DOI 10.1007/978-1-4613-0041-0 
1. Algebra. I. Title. II. Series. 
QA154.3.L3 2002 
512—dc21 
2001054916 
ISBN 978-1-4612-6551-1 
Printed on acid-free paper. 
This title was previously published by Addison-Wesley, Reading, MA 1993. 
© 2002 Springer Science+Business Media New York 
Originally published by Springer Science+Business Media LLC in 2002 
Softcover reprint of the hardcover 3rd edition 2002 
All rights reserved. This work may not be translated or copied in whole or in part without 
the written permission of the publisher (Springer Science+Business Media, LLC), except for 
brief excerpts in connection with reviews or scholarly analysis. Use in connection with any 
form of information storage and retrieval, electronic adaptation, computer software, or by 
similar or dissimilar methodology now known or hereafter developed is forbidden. 
The use of general descriptive names, trade names, trademarks, etc., in this publication, even if the 
former are not especially identified, is not to be taken as a sign that such names, as understood by 
the Trade Marks and Merchandise Marks Act, may accordingly be used freely by anyone. 
9 8 
(corrected printing 2005) 
springer.com 

FOREWORD
The present book is meant as a basic text for a one-year course in algebra,
at the graduate level .
A perspective on algebra
As I see it, the graduate course in algebra must primarily prepare students
to handle the algebra which they will meet in all of mathematics: topology,
partial differential equations, differential geometry, algebraic geometry, analysis,
and representation theory, not to speak of algebra itself and algebraic number
theory with all its ramifications. Hence I have inserted throughout references to
papers and books which have appeared during the last decades , to indicate some
of the directions in which the algebraic foundations provided by this book are
used; I have accompanied these references with some motivating comments, to
explain how the topics of the present book fit into the mathematics that is to
come subsequently in various fields; and I have also mentioned some unsolved
problems of mathematics in algebra and number theory . The abc conjecture is
perhaps the most spectacular of these.
Often when such comments and examples occur out of the logical order,
especially with examples from other branches of mathematics, of necessity some
terms may not be defined , or may be defined only later in the book . I have tried
to help the reader not only by making cross-references within the book, but also
by referring to other books or papers which I mention explicitly.
I have also added a number of exercises. On the whole, I have tried to make
the exercises complement the examples, and to give them aesthetic appeal. I
have tried to use the exercises also to drive readers toward variations and appli-
cations of the main text , as well as toward working out special cases, and as
openings toward applications beyond this book .
Organization
Unfortunately, a book must be projected in a totally ordered way on the page
axis, but that's not the way mathematics "is", so readers have to make choices
how to reset certain topics in parallel for themselves, rather than in succession.
v

vi
FOREWORD
I have inserted cross-references to help them do this , but different people will
make different choices at different times depending on different circumstances.
The book splits naturally into several parts. The first part introduces the basic
notions of algebra. After these basic notions, the book splits in two major
directions: the direction of algebraic equations including the Galois theory in
Part II; and the direction of linear and multilinear algebra in Parts III and IV.
There is some sporadic feedback between them, but their unification takes place
at the next level of mathematics, which is suggested, for instance, in §15 of
Chapter VI. Indeed, the study of algebraic extensions of the rationals can be
carried out from two points of view which are complementary and interrelated:
representing the Galois group of the algebraic closure in groups of matrices (the
linear approach), and giving an explicit determination of the irrationalities gen-
erating algebraic extensions (the equations approach) . At the moment, repre-
sentations in GL2 are at the center of attention from various quarters, and readers
will see GL2 appear several times throughout the book . For instance, I have
found it appropriate to add a section describing all irreducible characters of
GL2(F) when F is a finite field. Ultimately, GL2 will appear as the simplest but
typical case of groups of Lie types, occurring both in a differential context and
over finite fields or more general arithmetic rings for arithmetic applications.
After almost a decade since the second edition, I find that the basic topics
of algebra have become stable, with one exception. I have added two sections
on elimination theory, complementing the existing section on the resultant.
Algebraic geometry having progressed in many ways, it is now sometimes return-
ing to older and harder problems, such as searching for the effective construction
of polynomials vanishing on certain algebraic sets, and the older elimination
procedures of last century serve as an introduction to those problems.
Except for this addition, the main topics of the book are unchanged from the
second edition, but I have tried to improve the book in several ways.
First, some topics have been reordered. I was informed by readers and review-
ers of the tension existing between having a textbook usable for relatively inex-
perienced students, and a reference book where results could easily be found in
a systematic arrangement. I have tried to reduce this tension by moving all the
homological algebra to a fourth part, and by integrating the commutative algebra
with the chapter on algebraic sets and elimination theory, thus giving an intro-
duction to different points of view leading toward algebraic geometry.
The book as a text and a reference
In teaching the course, one might wish to push into the study of algebraic
equations through Part II, or one may choose to go first into the linear algebra
of Parts III and IV. One semester could be devoted to each, for instance. The
chapters have been so written as to allow maximal flexibility in this respect, and
I have frequently committed the crime of lese-Bourbaki by repeating short argu-
ments or definitions to make certain sections or chapters logically independent
of each other.

FOREWORD
vii
Granting the material which under no circumstances can be omitted from a
basic course, there exist several options for leading the course in various direc-
tions. It is impossible to treat all of them with the same degree of thoroughness.
The precise point at which one is willing to stop in any given direction will
depend on time , place, and mood . However, any book with the aims of the
present one must include a choice of topics, pushing ahead-in deeper waters,
while stopping short of full involvement.
There can be no universal agreement on these matters, not even between the
author and himself. Thus the concrete decisions as to what to include and what
not to include are finally taken on ground s of general coherence and aesthetic
balance. Anyone teaching the course will want to impress their own personality
on the material, and may push certain topics with more vigor than I have, at the
expense of others . Nothing in the present book is meant to inhibit this.
Unfortunately, the goal to present a fairly comprehensive perspective on
algebra required a substantial increase in size from the first to the second edition,
and a moderate increase in this third edition. These increases require some
decisions as to what to omit in a given course.
Many shortcuts can be taken in the presentation of the topics, which
admits many variations. For instance, one can proceed into field theory and
Galois theory immediately after giving the basic definit ions for groups, rings,
fields, polynomials in one variable, and vector spaces. Since the Galois theory
gives very quickly an impression of depth, this is very satisfactory in many
respects.
It is appropriate here to recall my original indebtedness to Artin, who first
taught me algebra. The treatment of the basics of Galois theory is much
influenced by the presentation in his own monograph.
Audience and background
As I already stated in the forewords of previous editions, the present book
is meant for the graduate level, and I expect most of those coming to it to have
had suitable exposure to some algebra in an undergraduate course, or to have
appropriate mathematical maturity. I expect students taking a graduate course
to have had some exposure to vector spaces, linear maps, matrices, and they
will no doubt have seen polynomials at the very least in calculus courses.
My books Undergraduate Algebra and Linear Algebra provide more than
enough background for a graduate course. Such elementary texts bring out in
parallel the two basic aspects of algebra, and are organized differently from the
present book , where both aspects are deepened. Of course, some aspects of the
linear algebra in Part III of the present book are more "elementary" than some
aspects of Part II, which deals with Galois theory and the theory of polynomial
equations in several variables. Because Part II has gone deeper into the study
of algebraic equations, of necessity the parallel linear algebra occurs only later
in the total ordering of the book . Readers should view both parts as running
simultaneously.

viii
FOREWORD
Unfortunately, the amount of algebra which one should ideally absorb during
this first year in order to have a proper background (irrespective of the subject
in which one eventually specializes) exceeds the amount which can be covered
physically by a lecturer during a one-year course. Hence more material must be
included than can actually be handled in class. I find it essential to bring this
material to the attention of graduate students.
I hope that the various additions and changes make the book easier to use as
a text. By these additions, I have tried to expand the general mathematical
perspective of the reader, insofar as algebra relates to other parts of mathematics.
Acknowledgements
I am indebted to many people who have contributed comments and criticisms
for the previous editions, but especially to Daniel Bump, Steven Krantz, and
Diane Meuser, who provided extensive comments as editorial reviewers for
Addison-Wesley . I found their comments very stimulating and valuable in pre-
paring this third edition. I am much indebted to Barbara Holland for obtaining
these reviews when she was editor. I am also indebted to Karl Matsumoto who
supervised production under very trying circumstances. I thank the many peo-
ple who have made suggestions and corrections, especially George Bergman
and students in his class, Chee-Whye Chin, Ki-Bong Nam, David Wasserman,
Randy Scott, Thomas Shiple, Paul Vojta, Bjorn Poonen and his class, in partic-
ular Michael Manapat.
For the 2002 and beyond Springer printings
From now on, Algebra appears with Springer-Verlag, like the rest of my
books. With this change, I considered the possibility of a new edition, but de-
cided against it. I view the book as very stable . The only addition which I
would make , if starting from scratch, would be some of the algebraic properties
of SLn and GLn (over R or C), beyond the proof of simplicity in Chapter XIII.
As things stood, I just inserted some exercises concerning some aspects which
everybody should know . The material actually is now inserted in a new edition
of Undergraduate Algebra, where it properly belongs. The algebra appears as a
supporting tool for doing analysis on Lie groups, cf. for instance Jorgenson/
Lang Spherical Inversion on SLn(R), Springer Verlag 2001.
I thank specifically Tom von Foerster, Ina Lindemann and Mark Spencer
for their editorial support at Springer, as well as Terry Kornak and Brian
Howe who have taken care of production.
Serge Lang
New Haven 2004

Logical Prerequisites
We assume that the reader is familiar with sets, and with the symbols n, U,
~ , C, E. If A , B are sets, we use the symbol A C B to mean that A is contained
in B but may be equal to B . Similarly for A ~ B .
If f :A -> B is a mapping of one set into another, we write
X 1---+ f(x)
to denote the effect of f on an element x of A. We distinguish between the
arrows -> and 1---+. We denote by f(A) the set of all elementsf(x), with x E A.
Let f :A -> B be a mapping (also called a map). We say that f is injective
if x # y implies f(x) # f(y). We say f is surjective if given b e B there exists
a E A such that f(a) = b. We say that f is bijective if it is both surjective and
injective.
A subset A of a set B is said to be proper ifA # B.
Let f :A -> B be a map, and A' a subset of A. The restriction of f to A' is
a map of A' into B denoted by fIA '.
Iff :A -> Band 9 : B -> C are maps, then we have a composite map 9
0 f
such that (g 0 f)(x) = g(f(x» for all x E A.
Letf: A -> B be a map, and B' a subset of B. Byf- 1(B') we mean the subset
of A consisting of all x E A such that f(x) E B'. We call it the inverse image of
B'. We call f(A) the image off.
A diagram
C
is said to be commutative if g of = h. Similarly, a diagram
A~B
•j
j.
C---->D
'"
ix

X
LOGICAL PREREQUISITES
is said to be commutative if 9
0 f = lj; 0 sp,
We deal sometimes with more
complicated diagrams, consisting of arrows between various objects.
Such
diagrams are called commutati ve if, whenever it is possible to go from one
object to another by means of two sequences of arrow s, say
A
II
A
h
I.-I
A
1~
2~
"
'~n
and
A
91
B
92
9m-1
B
A
l~
2 ~
"
' ~
m=
n '
then
In-l
0
• ••
0 II = 9m- 1 0
• •• °9b
in other words, the composite maps are equal.
Most of our diagrams are
composed of triangles or squares as above, and to verify that a diagram con-
sisting of triangles or squares is commutative, it suffices to verify that each
triangle and square in it is commutative.
We assume that the reader is acquainted with the integers and rational
numbers, denoted respectively by Z and Q. For many of our examples, we also
assume that the reader knows the real and complex numbers, denoted by R
and C.
Let A and I be two sets. By a family of elements of A, indexed by I, one
means a map f: I-A. Thus for each i E I we are given an element f (i) E A.
Alth ough a family does not differ from a map, we think of it as determining a
collection of objects from A, and write it often as
or
writing a, instead of f(i). We call I the indexing set.
We assume that the reader knows what an equivalence relation is. Let A
be a set with an equivalence relation, let E be an equ ivalence class of elements
of A. We sometimes try to define a map of the equivalence classes into some
set B. To define such a map f on the class E, we sometimes first give its value
on an element x E E (called a representative of E), and then show that it is
independent of the choice of representative x E E. In that case we say that f
is welldefined.
We have products of sets, say finite products A x B, or A I X .. . x An' and
products of families of sets.
We shall use Zorn's lemma, which we describe in Appendix 2.
We let # (S) denote the number of elements of a set S, also called the
cardinality of S. The notation is usually employed when S is finite. We also
write # (S) = card (S).

CONTENTS
Part One
The Basic Objects of Algebra
3
36
42
25
49
13
Groups
3
Chapter I
1. Monoids
2. Groups
7
3. Normal subgroups
4. Cyclic groups
23
5. Operations of a group on a set
6. Sylow subgroups
33
7. Direct sums and free abelian groups
8. Finitely generated abelian groups
9. The dual group
46
10. Inverse limit and completion
11. Categories and functors
53
12. Free groups
66
Chapter II
Rings
I. Rings and homomorphisms
83
2. Commutative rings
92
3. Polynomials and group rings
97
4. Localization
107
5. Principal and factorial rings
111
83
Chapter III
Modules
1. Basic definitions
117
2. The group of homomorphisms
122
3. Direct products and sums of modules
127
4. Free modules
135
5. Vector spaces
139
6. The dual space and dual module
142
7. Modules over principal rings
146
8. Euler-Poincare maps
155
9. The snake lemma
157
10. Direct and inverse limits
159
117
xi

xii
CONTENTS
Chapter IV
Polynomials
1. Basic properties for polynomials in one variable
2. Polynomials over a factorial ring
180
3. Criteria for irreducibility
183
4. Hilbert's theorem
186
5. Partial fractions
187
6. Symmetric polynomials
190
7. Mason-Stothers theorem and the abc conjecture
8. The resultant
199
9. Power series
205
173
194
173
Part Two
Algebraic Equations
Chapter V
Algebraic Extensions
1. Finite and algebraic extensions
225
2. Algebraic closure
229
3. Splitting fields and normal extensions
236
4. Separable extensions
239
5. Finite fields
244
6. Inseparable extensions
247
Chapter VI
Galois Theory
1. Galois extensions
261
2. Examples and applications
269
3. Roots of unity
276
4. Linear independence of characters
282
5. The norm and trace
284
6. Cyclic extensions
288
7. Solvable and radical extensions
291
8. Abelian Kummer theory
293
9. The equation X" -
a = 0
297
10. Galois cohomology
302
11. Non-abelian Kummer extensions
304
12. Algebraic independence of homomorphisms
13. The normal basis theorem
312
14. Infinite Galois extensions
313
15. The modular connection
315
Chapter VII
Extensions of Rings
1. Integral ring extensions
333
2. Integral Galois extensions
340
3. Extension of homomorphisms
346
308
223
261
333

CONTENTS
xiii
Chapter VIII
Transcendental Extensions
355
I. Transcendence bases
355
2. Noether normalization theorem
357
3. Linearly disjoint extensions
360
4. Separable and regular extensions
363
5. Derivations
368
Chapter IX
Algebraic Spaces
I. Hilbert's Nullstellensatz
378
2. Algebraic sets, spaces and varieties
3. Projections and elimination
388
4. Resultant systems
401
5. Spec of a ring
405
381
377
Chapter X
Noetherian Rings and Modules
I . Basic criteria
413
2. Associated primes
416
3. Primary decomposition
421
4. Nakayama's lemma
424
5. Filtered and graded modules
426
6. The Hilbert polynomial
431
7. Indecomposable modules
439
413
Chapter XI
Real Fields
I . Ordered fields
449
2. Real fields
451
3. Real zeros and homomorphisms
457
449
Chapter XII
Absolute Values
I. Definitions, dependence, and independence
465
2. Completions
468
3. Finite extensions
476
4. Valuations
480
5. Completions and valuations
486
6. Discrete valuations
487
7. Zeros of polynomials in complete fields
491
465
Part Three
Linear Algebra and Representations
Chapter XIII
Matrices and Linear Maps
1. Matrices
503
2. The rank of a matrix
506
503

xiv
CONTENTS
3. Matrices and linear maps
507
4. Determinants
511
5. Duality
522
6. Matrices and bilinear forms
527
7. Sesquilinear duality
531
8. The simplicity of SL2(F)/±I
536
9. The group SLn(F), n 2: 3
540
Chapter XIV
Representation of One Endomorphism
553
1. Representations
553
2. Decomposition over one endomorphism
556
3. The characteristic polynomial
561
Chapter XV
Structure of Bilinear Forms
571
1. Preliminaries, orthogonal sums
571
2. Quadratic maps
574
3. Symmetric forms, orthogonal bases
575
4. Symmetric forms over ordered fields
577
5. Hermitian forms
579
6. The spectral theorem (hermitian case)
581
7. The spectral theorem (symmetric case)
584
8. Alternating forms
586
9. The Pfaffian
588
10. Witt's theorem
589
11. The Witt group
594
Chapter XVI
The Tensor Product
601
1. Tensor product
601
2. Basic properties
607
3. Flat modules
612
4. Extension of the base
623
5. Some functorial isomorphisms
625
6. Tensor product of algebras
629
7. The tensor algebra of a module
632
8. Symmetric products
635
Chapter XVII
Semisimplicity
641
1. Matrices and linear maps over non-commutative rings
641
2. Conditions defining semisimplicity
645
3. The density theorem
646
4. Semisimple rings
651
5. Simple rings
654
6. The Jacobson radical, base change, and tensor products
657
7. Balanced modules
660

CONTENTS
XV
Chapter XVIII
Representations of Finite Groups
663
1. Representations and semisimplicity
663
2. Characters
667
3. I-d imensional representations
671
4. The space of class function s
673
5. Orthogonality relations
677
6. Induced characters
686
7. Induced representations
688
8. Positive decomposition of the regular character
699
9. Supersolvable groups
702
10. Brauer's theorem
704
11. Field of definition of a representation
710
12. Example: GL2 over a finite field
712
Chapter XIX
The Alternating Product
1. Definition and basic properties
731
2. Fitting ideals
738
3. Universal derivations and the de Rham complex
4. The Clifford algebra
749
746
731
Part Four
Homological Algebra
Chapter XX
General Homology Theory
1. Complexes
761
2. Homology sequence
767
3. Euler characteristic and the Grothendieck group
769
4. Injective modules
782
5. Homotopies of morphisms of complexes
787
6. Derived functors
790
7. Delta-functors
799
8. Bifunctors
806
9. Spectral sequences
814
Chapter XXI
Finite Free Resolutions
1. Special complexes
835
2. Finite free resolutions
839
3. Unimodular polynomial vectors
846
4. The Koszul complex
850
761
835
Appendix 1
Appendix 2
Bibliography
Index
The Transcendence of e and Tt
Some Set Theory
867
875
895
903

Part One
THE BASIC
OBJECTS OF
ALGEBRA
This part introduces the basic notions of algebra, and the main difficulty
for the beginner is to absorb a reasonable vocabulary in a short time. None
of the concepts is difficult, but there is an accumulation of new concepts which
may sometimes seem heavy.
To understand the next parts of the book, the reader needs to know
essentially only the basic definitions of this first part.
Of course, a theorem
may be used later for some specific and isolated applications, but on the
whole, we have avoided making long logical chains of interdependence.

CHAPTER I
Groups
§1.
MONOIDS
Let S be a set. A mapping
SxS-+S
is sometimes called a law of composition (of S into itself). If x, yare elements of
S, the image of the pair (x, y) under this mapping is also called their product
under the law of composition, and will be denoted by xy. (Sometimes, we also
write x . y, and in many cases it is also convenient to use an additive notation,
and thus to write x + y. In that case, we call this element the sum of x and y.
It is customary to use the notation x + y only when the relation x + y =
Y + x holds.)
Let S be a set with a law of composition. Ifx, y, z are elements of S, then we
may form their product in two ways : (xy)z and x(yz). If (xy)z = x(yz) for all
x, y. z in S then we say that the law of composition is associative.
An element e of S such that ex = x = xe for all XES is called a unit
element. (When the law of composition is written additively, the unit element
is denoted by 0, and is called a zero element.) A unit element is unique, for if
e' is another unit element, we have
e = ee' = e'
by assumption. In most cases, the unit element is written simply 1(instead of e).
For most of this chapter, however, we shall write e so as to avoid confusion in
proving the most basic properties.
A monoid is a set G, with a law of composition which is associative, and
having a unit element (so that in particular, G is not empty).
3
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

4
GROUPS
I, §1
Let G be a monoid, and xI' . , . , x, elements of G (where n is an integer > I).
We define their product inductively:
n
TIxv = XI " 'Xn= (xI · ··Xn-l)xn·
v= I
We then have thefollowing rule:
m
n
m+n
TI xI" TI X m + v = TI XV'
1'=1
v=1
v=1
which essentially asserts that we can insert parentheses in any manner in our
productwithout changing Its value. The proof is easy by induction, and we shall
leave it as an exercise.
One also writes
and we define
m+ n
TI x,
instead of
m+l
o
TI x, = e.
v= 1
n
TI Xm + v
v= I
As a matter of convention, we agree also that the empty product is equal
to the unit element.
It would be possible to define more general laws of composition, i.e. maps
SI x S2 -+ S3 using arbitrary sets. One can then express associativity and
commutativity in any setting for which they make sense. For instance, for
commutativity we need a law of composition
f:S x S -+ T
where the two sets of departure are the same.
Commutativity then means
f(x, y) = f(y, x), or xy = yx if we omit the mapping j from the notation. For
associativity, we leave it to the reader to formulate the most general combination
of sets under which it will work. We shall meet special cases later, for instance
arising from maps
S x S -+ Sand
S x T -+ T.
Then a product (xy)z makes sense with XES, YES, and z E T. The product
x(yz) also makes sense for such elements x, y, z and thus it makes sense to say
that our law of composition is associative, namely to say that for all x, y, z as
above we have (xy)z = x(yz).
If the law of composition of G is commutative, we also say that G is com-
mutative (or abelian).

I, §1
MONOIDS
5
Let G be a commutative monoid, and XI' . . . , x, elements of G. Let t/J be a
bijection of the set of integers (I , .. . , n) onto itself.
Then
n
n
Il xl/J(v) = Il x.;
v= I
v = I
We prove this by induction, it being obvious for n = 1. We assume it for
n - 1. Let k be an integer such that t/J(k) = n. Then
n
k-I
n-k
n xl/J(v) = n xl/J( v) • XI/J(k)' nxl/J(k+ v)
I
I
I
k -I
n-rk
= nxl/J(v)' n X I/J(k + v) • XI/J(k) '
I
I
Define a map cp of (1, . . , , n -
1) into itself by the rule
Then
cp(v) = t/J(v)
cp(v) = t/J(v + 1)
if
v < k,
if
v ~ k.
n
k -I
n-k
n xl/J( v) = n xq>(v)n Xq>(k - I + v) • x,
I
I
I
n-1
= n xq>(v) ' x, ,
I
which, by induction, is equal to XI .. . Xn , as desired.
Let G be a commutative monoid, let I be a set, and let f :1 ..... G be a
mapping such that !(i) = e for almost all i E I. (Here and thereafter, almost
all will mean all but a finite number.) Let 10 be the subset of I consisting of
those i such thatf(i) ::/= e. By
nf(i)
i e l
we shall mean the product
n f(i)
ie 10
taken in any order (the value does not depend on the order, according to the
preceding remark). It is understood that the empty product is equal to e.
When G is written additively, then instead of a product sign, we write the
sum sign L.
There are a number of formal rules for dealing with products which it would
be tedious to list completely. We give one example. Let 1, J be two sets, and

6
GROUPS
I, §1
f:1
X J --+ G a mapping into a commutative monoid which takes the value e
for almost all pairs (i, j). Then
We leave the proof as an exercise.
As a matter of notation, we sometimes write fl f(i), omitting the signs
i E I, if the reference to the indexing set is clear.
Let x be an element of a monoid G. For every integer n ~ 0 we define x"
to be
"Il x,
I
so that in particular we have X O = e,x ' = x, x 2 = xx, . ... We obviously have
x("+m) = x"x m and (x")" = x?".
Furthermore, from our preceding rules of
associativity and commutativity, if x, yare elements of G such that xy = yx,
then (xy)" = x"y". We leave the formal proof as an exercise.
If S, S' are two subsets of a monoid G, then we define SS' to be the subset
consisting of all elements xy, with XES and YES'. Inductively, we can define
the product of a finite number of subsets, and we have associativity. For in-
stance, if S, S', S" are subsets of G,then (SS')S" = S(S'S"). Observe that GG = G
(because G has a unit element). If x E G, then we define xS to be {x}S, where
{x} is the set consisting of the single element x. Thus xS consists of all elements
xy, with yES.
By a submonoid of G, we shall mean a subset H of G containing the unit
element e, and such that, if x, y E H then xy E H (we say that H is closed under
the law of composition). It is then clear that H is itself a monoid, under the law
of composition induced by that of G.
If x is an element of a monoid G, then the subset of powers x" (n = 0, 1,. ..)
is a submonoid of G.
The set of integers ~ 0 under addition is a monoid.
Later we shall define rings. If R is a commutative ring, we shall deal with
multiplicative subsets S, that is subsets containing the unit element, and such
that if x, yES then xy E S. Such subsets are monoids.
A routine example.
Let N be the natural numbers, i.e. the integers ~ O.
Then N is an additive monoid. In some applications, it is useful to deal with a
multiplicative version . See the definition of polynomials in Chapter II, §3, where
a higher-dimensional version is also used for polynomials in several variables.
An interesting example.
We assume that the reader is familiar with the
terminology of elementary topology. Let M be the set of homeomorphism
classes of compact (connected) surfaces. We shall define an addition in M.
Let S, S' be compact surfaces. Let D be a small disc in S, and D' a small disc in
S'. Let C, C' be the circles which form the boundaries of D and D' respectively.
Let Do, D~ be the interiors of D and D' respectively, and glue S-Doto S ' -D~ by
identifying C with C. It can be shown that the resulting surface is independent,

I. §2
GROUPS
7
up to homeomorphism, of the various choices made in the preceding construc-
tion. If (1 ,
(1 ' den ote the homeomorphism classes of S and S' respectively, we
define
(1 + (1 ' to be the class of the surface obtained by the preceding gluing
process. It can be shown that this addition defines a monoid structure on M,
whose unit element is the class of the ordinary 2-sphere. Furthermore, if T
denotes the class of the torus, and ·n denotes the class of the projective plane,
then every element (1 of M has a unique expression of the form
(1 = nT + mn
where n is an integer ~°and m = 0, I, or 2. We have 3n = T + n.
(The reasons for inserting the preceding example are twofold : First to
relieve the essential dullness of the section. Second to show the reader that
monoids exist in nature. Needless to say, the example will not be used in any
way throughout the rest of the book .)
Still other examples.
At the end of Chapter III , §4, we shall remark that
isomorphism classes of module s over a ring form a monoid under the direct sum .
In Chapter XV, §I, we shall consider a monoid consisting of equivalence classes
of quadratic forms .
§2.
GROUPS
A group G is a mon oid, such that for every element x E G there exists an
element y E G such th at xy = yx = e. Such an element y is called an inverse for
x. Such an inverse is unique, because if y' is also an inverse for x, then
y' = y'e = y'(xy) = (y'x )y = ey = y.
We denote this inverse by x " I (or by -x when the law of composition is
written additively).
For any positive integer n, we let x " " = (X-I)". Then the usual rules for
exponentiation hold for all integers, not only for integers ~°(as we pointed out
for monoids in §I). The tri vial proofs are left to the reader.
In the definitions of unit elements and inverses, we could also define left
units and left inverses (in the obvious way). One can easily prove that these
are also units and inverses respectively under suitable conditions. Namely:
Let G be a set with an associative law of composition, let e be a left unit for
that law, and assume that every element has a left inverse. Then e is a unit,
and each left inverse is also an inverse. In particular, G is a group.
To prove this, let a E G and let bEG be such that ba = e. Then
bab = eb = b.
Multiplying on the left by a left inverse for b yields
ab = e,
or in other words, b is also a right inverse for a. One sees also th at a is a left

8
GROUPS
I, §2
inverse for b. Furthermore,
ae = aba = ea = a,
whence e is a right unit.
Example.
Let G be a group and S a nonempty set. The set of maps M(S, G)
is itself a group; namely for two maps f , g of S into G we define fg to be the
map such that
(fg)(x) = f(x)g(x),
and we define f - I to be the map such that f -I(X) = f(x) - I. It is then trivial
to verify that M(S, G) is a group. If G is commutative, so is M(S, G), and when
the law of composition in G is written additively, so is the law of composition
in M(S, G), so that we would write f + g instead of fg, and - f instead of f - I.
Example.
Let S be a non-empty set. Let G be the set of bijective mappings
of S onto itself. Then G is a group, the law of composition being ordinary com-
position of mappings. The unit element of G is the identity map of S, and the
other group properties are trivially verified. The elements of G are called
permutations of S. We also denote G by Perm(S). For more information on
Perm(S) when S is finite, see §5 below.
Example.
Let us assume here the basic notions of linear algebra . Let k be
a field and V a vector space over k. Let GL(Y) denote the set of invertible k-
linear maps of V onto itself. Then GL(Y) is a group under composition of
mappings. Similarly, let k be a field and let GL(n, k) be the set of invertible
n x n matrices with components in k. Then GL(n, k) is a group under the
multiplication of matrices . For n ~ 2, this group is not commutative.
Example.
The group of automorphisms.
We recommend that the reader
now refer immediately to §II, where the notion of a category is defined, and
where several examples are given. For any object A in a category, its auto-
morphisms form a group denoted by Aut(A). Permutations of a set and the linear
automorphisms of a vector space are merely examples of this more general
structure.
Example.
The set of rational numbers forms a group under addition. The
set of non-zero rational numbers forms a group under multiplication. Similar
statements hold for the real and complex numbers.
Example.
Cyclic groups.
The integers Z form an additive group . A group
is defined to be cyclic if there exists an element a E G such that every element
of G (written multiplicatively) is of the form an for some integer n, If G is written
additively, then every element of a cyclic group is of the form na. One calls a
a cyclic generator. Thus Z is an additive cyclic group with generator 1, and
also with generator -I. There are no other generators. Given a positive integer
n, the n-th roots of unity in the complex numbers form a cyclic group of order
n. In terms of the usual notation, e 2 7Ti/ n is a generator for this group . So is e27Tir /n

1,§2
GROUPS
9
with r E Z and r prime to n. A generator for this group is called a primitive
n-th root of unity.
Example.
The direct product.
Let G" G2 be groups. Let G, x G2 be
the direct product as sets, so G, X G2 is the set of all pairs (x"
X2) with
x, E Gj • We define the law of composition componentwise by
(X" x2)(YI, Y2) = (XI YI, x2Y2)'
Then G. x G2 is a group, whose unit element is (el' e2) (where e, is the unit
element of Gj ) . Similarly, for n groups we define GI X
• • , x G; to be the set
of n-tuples with x, E G, (i = I, .. . , n), and componentwise multiplication.
Even more generally, let I be a set, and for each i E I, let G, be a group. Let
G = n G, be the set-theoretic product of the sets Gj • Then G is the set of all
families (Xj)jeI with Xj E Gj • We can define a group structure on G by compo-
nentwise multiplication, namely, if (Xj)jeI and (Yj)jeI are two elements of G, we
define their product to be (x;)'j )jeI ' We define the inverse of (Xj)jeI to be (xi I )jeI'
It is then obvious that G is a group called the direct product of the family.
Let G be a group. A subgroup H of G is a subset of G containing the unit
element, and such that H is closed under the law of composition and inverse
(i.e. it is a submonoid, such that if x E H then x" 1 E H). A subgroup is called
trivial if it consists of the unit element alone. The intersection of an arbitrary
non-empty family of subgroups is a subgroup (trivial verification).
Let G be a group and Sa subset of G. We shall say that S generates G,
or that S is a set of generatorsfor G, if every element of G can be expressed as a
product of elements of S or inverses of elements of S, i.e. as a product XI' .• x;
where each x, or Xj- 1 is in S. It is clear that the set of all such products is a
subgroup of G (the empty product is the unit element), and is the smallest sub-
group of Gcontaining S. Thus S generates G if and only if the smallest subgroup
of G containing S is G itself. If G is generated by S, then we write G = (S). By
definition, a cyclic group is a group which has one generator. Given elements
XI' . . . , x; E G, these elements generate a subgroup (XI' . . . , xn) , namely the
set of all elements of G of the form
xfi ... xf:
with
kl , . . . , krE Z.
A single element X E G generates a cyclic subgroup.
Example.
There are two non-abelian groups of order 8. One is the group
of symmetries of the square, generated by two elements a, " such that
0.4 = ,,2 = e
and
"u,,-I = a3.
The other is the quaternion group, generated by two elements, i , j such that
if we put k = ij and m = i 2 , then
i 4 = j4 = k4 = e,
i 2 = P = k2 = m,
ij = mji.
After you know enough facts about groups, you can easily do Exercise 35.

10
GROUPS
I, §2
Let G, G' be monoids. A monoid-homomorphism(or simply homomorphism)
of G into G' is a mappingf:G --+ G' such thatf(xy) = f(x)f(y) for all x, y E G,
and mapping the unit element of G into that of G'. If G, G' are groups, a group-
homomorphism of G into G' is simply a monoid-homomorphism.
We sometimes say: "Let f: G --+ G' be a group-homomorphism" to mean:
"Let G, G' be groups, and letfbe a homomorphism from G into G'."
Letf: G --+ G' be a group-homomorphism. Then
f(x- I ) = f(X)-1
because if e, e' are the unit elements of G, G' respectively, then
e' = f(e) = f(xx- I ) = f(x)f(x- I ) .
Furthermore, if G, G' are groups andf: G --+ G' is a map such that
f(xy) = f(x)f(y)
for all x, y in G, then f(e) = e' because f(ee) = f(e) and also
= f(e)f(e).
Multiplying by the inverse off(e) shows thatf(e) = e'.
Let G, G' be monoids. A homomorphismf: G --+ G' is called an isomorphism
if there exists a homomorphism g: G' --+ G such that f og and 9
0 f are the
identity mappings (in G' and G respectively). It is trivially verified that f is
an isomorphism if and only if f is bijective. The existence of an isomorphism
between two groups G and G' is sometimes denoted by G ~ G'. If G = G',
we say that isomorphism is an automorphism. A homomorphism of G into
itself is also called an endomorphism.
Example.
Let G be a monoid and x an element of G. Let N denote the
(additive) monoid of integers ~ O. Then the map f :N --+ G such thatf(n) = x"
is a homomorphism. If G is a group, we can extendfto a homomorphism of Z
into G (x" is defined for all nEZ, as pointed out previously). The trivial proofs
are left to the reader.
Let n be a fixed integer and let G be a commutativegroup. Then one verifies
easily that the map
x~xn
from G into itself is a homomorphism. So is the map x ~ X-I. The map
x ~ x" is called the n-th power map.
Example.
Let I = {i}be an indexing set, and let {GJ be a family of groups.
Let G = TI G, be their direct product. Let
Pi: G~Gi
be the projection on the i-th factor. Then Pi is a homomorphism.
Let G be a group, S a set of generators for G, and G' another group. Let
f: S --+ G' be a map. If there exists a homomorphismJ of G into G' whose
restriction to S isf, then there is only one.

I, §2
GROUPS
11
In other words, f has at most one extension to a homomorphism of G
into G'. This is obvious, but will be used many times in the sequel.
Let f :G -+ G' and g : G' -+ G" be two group-homomorphisms. Then the
composite map g of is a group-homomorphism, Iff, g are isomorphisms then
so is g 0f
Furthermore f - 1 : G' -+ G is also an isomorphism. In particular,
the set of all automorphisms of G is itself a group, denoted by Aut(G).
Let f: G -+ G' be a gro up-homomorphism. Let e, e' be the respective unit
elements of G, G'. We define the kernel off to be the subset of G consisting
of all x such that f(x) = e', From the definitions, it follows at once that the
kernel H off is a subgroup of G. (Let us prove for instance that H is closed
under the inverse mapping. Let x E H . Then
f(x - I)f (x) = f (e) = e'.
Since f (x) = e', we have f(x - I) = e', whence X-I E H. We leave the other
verifications to the reader. )
Let f: G -+ G' be a group-homomorphism again . Let H' be the image off
Then H' is a subgroup of G', because it contains e', and iff (x),f(y) E H', then
f (xy) = f(x) f(y) lies also in H'. Furthermore. j'(x" ') = f (X)- 1 is in H', and
hence H' is a subgroup of G'.
The kernel and image off are sometimes denoted by Ker fand Im f
A homomorphism f: G -+ G' which establishes an isomorphism between
G and its image in G' will also be called an embedding.
A homomorphism whose kernel is trivial is injective.
To prove this, suppose that the kernel offis trivial, and letf (x) = f (y) for
some x, y E G. Multiplying byf(y- I) we obtain
f(xy -I) = f(x)f(y-I) = e'.
Hence xy - 1 lies in the kernel, hence xy- I = e, and x = y. If in particular f is
also surjective, then f is an isomorphism. Thus a surjective homomorphism
whose kernel is trivial must be an isomorphism. We note that an injective
homomorphism is an embedding.
An injective homomorphism is often denoted by a special arrow, such as
t .« ~c ' .
There is a useful criterion for a group to be a direct product ofsubgroups:
Proposition 2.1. Let G be a group and let H, K be two subgroups such that
H n K = e, HK = G, and such that xy = yx for all x E H and y E K. Then
the map
H xK-+G
such that (x, y) 1---+ xy is an isomorphism.
Proof
It is obviously a homomorphism, which is surjective since HK = G.

12
GROUPS
I, §2
If (x, y) is in its kernel, then x = y-l, whence x lies in both Hand K, and x = e,
so that y = e also, and our map is an isomorphism.
We observe that Proposition 2. I generalizes by induction to a finite number
of subgroups HI' . . . , Hn whose elements commute with each other, such that
HI '" H; = G,
and such that
Hi+ 1 n (HI'"
Hi) = e.
In that case, G is isomorphic to the direct product
HI x . . . x Hn •
Let G be a group and H a subgroup. A left coset of H in G is a subset of
G of type aH, for some element a of G. An element of aH is called a coset
representative of aH.
The map x H ax induces a bijection of H onto aH.
Hence any two left cosets have the same cardinality.
Observe that if a, b are elements of G and aH, bH are cosets having one
element in common, then they are equal.
Indeed, let ax = by with x, y E H.
Then a = byx" ',
But yx- 1EH.
Hence aH = b(yx-1)H = bH, because for
any ZEH we have zH = H.
We conclude that G is the disjoint union of the left cosets of H. A similar
remark applies to right cosets (i.e. subsets of G of type Ha). The number of left
cosets of H in G is denoted by (G : H), and is called the (left) index of H in G.
The index of the trivial subgroup is called the order of G and is written (G: I).
From the above conclusion, we get :
Proposition 2.2.
Let G be a group and H a subgroup. Then
(G : H)(H : I) = (G : I),
in the sense that if two of these indices are finite, so is the third and equality
holds as stated. If(G: I) isfinite, the order ofH divides the order ofG.
More generally, let H, K be subgroups ofG and let H ::> K. Let {xJ be a
set of(left) coset representatives ofKin H and let {y) be a set ofcoset repre-
sentatives ofH in G. Then we contend that {YjXi} is a set ofcoset representa-
tives of K in G.
Proof
Note that
(disjoint),
(disjoint).
Hence
G = UYjXiK.
i.j
We must show that this union is disjoint, i.e. that the YjXi represent distinct
cosets. Suppose

I, §3
NORMAL SUBGROUPS
13
YjXiK = Yr xi,K
for a pair of indices (j, i) and (j', i'), Multiplying by H on the right, and noting
that Xi ' Xi' are in H, we get
yj H = Yr H ,
whence Yj = Yr'
From this it follows that
Xi K =
Xi' K and therefore that
Xi =
Xi ' , as was to be shown.
The formula of Proposition 2.2 may therefore be generalized by writing
(G : K) = (G : H)(H : K),
with the understanding that if two of the three indices appearing in this formula
are finite, then so is the third and the formula holds .
The above results are concerned systematically with left cosets. For the right
cosets, see Exercise 10,
Example.
A group of prime order is cyclic. Indeed, let G have order p and
let a E G, a * e. Let H be the subgroup generated by a. Then #(H) divides p
and is * 1, so #(H) = p and so H = G, which is therefore cyclic.
Example.
Let In = {I , . "
, n}. Let S; be the group of permutations of
In. We define a transposition to be a permutation
T such that there exist
two elements r * s in In for which T(r) = S, T(S) = r , and T(k) = k for all
k* r, s. Note that the transpositions generate Sn- Indeed , say (T is a permutation,
(T(n) = k * n. Let T be the transposition interchanging k, n. Then T(T leaves n
fixed, and by induction, we can write T(T as a product of transpositions in
Perm(Jn- I), thus proving that transpositions generate Sn-
Next we note that #(Sn) = n!. Indeed , let H be the subgroup of S; consisting
of those elements which leave n fixed. Then H may be identified with Sn-I ' If
(T; (i = 1, . . . , n) is an element of Sn such that (T;(n) = i , then it is immediately
verified that (TI, .. . , (Tn are coset representatives of H , Hence by induction
(Sn : 1) = n(H : 1) = n!.
Observe that for (T; we could have taken the transposition T; , which interchanges
i and n (except for i = n, where we could take (Tn to be the identity).
§3.
NORMAL SUBGROUPS
We have already observed that the kernel of a group-homomorphism is a
subgroup. We now wish to characterize such subgroups.
Let j :G -> G' be a group-homomorphism, and let H be its kernel. If X is an
element of G, then xH = Hx, because both are equal to j-l(f(X» . We can
also rewrite this relation as xHx- 1 = H.

14
GROUPS
I, §3
Conversely, let G be a group, and let H be a subgroup. Assume that for all
elements x of G we have xH c Hx (or equivalently, xHx- I c H). If we
write X-I instead of x, we get H c xHx- I , whence xHx- I = H. Thus our
condition is equivalent to the condition xllx"? = H for all x E G. A subgroup
H satisfying this condition will be called normal. We shall now see that a normal
subgroup is the kernel of a homomorphism.
Let G' be the set of cosets of H. (By assumption, a leftcoset is equal to a right
coset, so we need not distinguish between them.) If xH and yH are cosets, then
their product (xH)(yH) is also a coset, because
xHyH = xyHH = xyH.
By means of this product, we have therefore defined a law of composition on G'
which is associative. It is clear that the coset H itself is a unit element for this
law of composition, and that x" I H is an inverse for the coset xH. Hence G' is a
group.
Let f :G -. G' be the mapping such that f(x) is the coset xH. Then f is
clearly a homomorphism, and (the subgroup) H is contained in its kernel. If
f(x) = H, then xH = H. Since H contains the unit element, it follows that
x E H. Thus H is equal to the kernel, and we have obtained our desired homo-
morphism.
The group of cosets of a normal subgroup H is denoted by G/H (which we
read G modulo H, or G mod H). The mapfof G onto G/H constructed above
is called the canonical map, and G/H is called the factor group of G by H.
Remarks
1. Let {HJ i€1 be a family of normal subgroups of G. Then the subgroup
H= nHi
i e I
is a normal subgroup. Indeed, if y E H, and x E G, then xyx- I lies in each Hi'
whence in H.
2. Let S be a subset of G and let N = Ns be the set of all elements x E G
such that xSx- 1 = S. Then N is obviously a subgroup of G, called the
normalizer of S. If S consists of one element a, then N is also called the
centralizer of a. More generally, let Zs be the set ofall elements x E G such that
xyx- I = y for all yES. Then Zs is called the centralizer of S. The centralizer
of G itself is called the center of G. It is the subgroup of G consisting of all
elements of G commuting with all other elements, and is obviously a normal
subgroup of G.
Examples. We shall give more examples of normal subgroups later when
we have more theorems to prove the normality . Here we give only two examples .
First, from linear algebra, note that the determinant is a homomorphism from
the multiplicative group of square matrices into the multiplicative group of a
field. The kernel is called the special linear group, and is normal.

I, §3
NORMAL SUBGROUPS
15
Second,
let
G
be
the
set
of
all
maps
Ta,b:
R -
R
such
that
Ta,b(X) = ax + b, with a*0 and b arbitrary, Then G is a group under composition
of mappings . Let A be the multiplicative group of maps of the form Ta,o (iso-
morphic to R*,the non-zero elements of R), and let N be the group of translations
Tl ,b with b E R. Then the reader will verify at once that Ta.b 1-+ a is a homo-
morphism of G onto the multiplicative group, whose kernel is the group of
translations, which is therefore normal. Furthermore, we have G = AN = NA ,
and N n A = {id}. In the terminology of Exercise 12, G is the semidirect
product of A and N .
Let H be a subgroup of G. Then H is obviously a normal subgroup of its
normalizer N H' We leave the following statements as exercises:
If K is any subgroup of G containing H and such that H is normal in K, then
KcN H •
If K is a subgroup of NH ' then KH is a groupand H is normalin KH.
The normalizer of H is the largest subgroup of G in which H is normal.
Let G be a group and H a normal subgroup. Let x, y E G. We shall write
x == y
(mod H)
if x and y lie in the same coset of H, or equivalently if xy-I (or y - IX) lie in H.
We read this relation" x and y are congruent modulo H."
When G is an additive group, then
x == 0
(mod H)
means that x lies in H, and
x == y
(mod H)
means that x - y (or y - x) lies in H . This notation of congruence is used
mostly for additive groups.
Let
G'1. G s: G"
be a sequence of homomorphisms. We shall say that this sequence is exact if
Im j" = Ker g. For example , if H is a normal subgroup of G then the sequence
H.:!.. G!!. G/H
is exact (where j = inclusion and qJ = canonical map). A sequence of homo-
morphisms having more than one term, like
G It G 12 G
/" -1 G
1-+
2-+
3-+ "
'-----"
n'
is called exact if it is exact at each joint, i.e. if for each i = 1, ... ,n - 2,
1mfi = Ker fi+l.
For example letting 0 be the trivial group, to say that
o-+ G' 1. G s; G" -+ 0

16
GROUPS
I, §3
is exact means that! is injective, that Im j"= Ker g, and that 9 is surjective. If
H = Ker 9 then this sequence is essentially the same as the exact sequence
o~ H ~ G -+ G/H -+ O.
More precisely, there exists a commutative diagram
O~G'~G~G"~O
j
j
j
O~H~G~G/H~O
in which the vertical maps are isomorphisms, and the rows are exact.
Next we describe some homomorphisms, all of which are called canonical.
(i) Let G, G' be groups and f: G ~ G' a homomorphism whose kernel
is H.
Let tp : G -+ G/H be the canonical map.
Then there exists a unique
hornomorphism f, : G/H ~ G' such that! =!*
0 <p, and j, is injective.
To define j',, let xH be a coset of H. Since !(xy) = !(x) for all y E H, we
define !*(xH) to be !(x). This value is independent of the choice of coset
representative x, and it is then trivially verified that j, is a homomorphism, is
injective, and is the unique homomorphism satisfying our requirements. We
shall say that j, is induced by[.
Our hornomorphism j, induces an isomorphism
A.: G/H -+ Imj'
of G/H onto the image off, and thus!can be factored into the following succes-
sion of homomorphisms :
G s. G/H ~ 1m!.!... G'.
Here, j is the inclusion of Im j" in G'.
(ii) Let G be a group and H a subgroup. Let N be the intersection of all
normal subgroups containing H. Then N is normal, and hence is the smallest
normal subgroup of G containing H. Letj" : G -+ G' be a homomorphism whose
kernel contains H. Then the kernel of! contains N, and there exists a unique
homomorphism j, : G/N -+ G', said to be induced by f, making the following
diagram commutative:
G~G'
\ J.
GIN
As before, <p is the canonical map.
We can define f, as in (1) by the rule
This is well defined, and is trivially verified to satisfy all our requirements.

I, §3
NORMAL SUBGROUPS
17
(iii) Let G be group and H ::> K two normal subgroups of G. Then K is normal
in H, and we can define a map of G/ K onto G/H by associating with each coset
xK the coset xH . It is immediately verified that this map is a homomorphism,
and that its kernel consists of all cosets xK such that x E H . Thus we have a
canonical isomorphism
I (GjK)j(HjK) ~ GjH. I
One could also describe this isomorphism using (i) and (ii). We leave it to the
reader to show that we have a commutative diagram
o ---+ H ---+
G ---+ GjH ---+ 0
1
can
j~"
l;,
0---+ HjK ---+ GjK ---+ GjH ---+ 0
where the rows are exact.
(iv) Let G be a group and let H, K be two subgroups.
Assume that H
is contained in the normalizer of K . Then H n K is obviously a normal
subgroup of H, and equally obviously HK = KH is a subgroup of G. There
is a surjective homomorphism
H -+ HK jK
associating with each x E H the coset xK of K in the group HK. The reader
will verify at once that the kernel of this homomorphism is exactly H n K.
Thus we have a canonical isomorphism
I Hj(H n K) ~ HK jK. I
(v) Let f : G -+ G' be a group homomorphism, let H' be a normal sub-
group of G', and let H = f-I(H').
G
• G'
I
I
f -I(H') ---+ H'
Thenf-I(H') is normal in G. [Proof:IfxE G,thenf(xHx- l ) =f(x)f(H)f(x)-1
is contained in H', so xHx- 1 C H.] We then obtain a homomorphism
G -+ G' -+ G'jH'
composingf with the canonical map of G' onto G'jH', and the kernel of this
composite is H. Hence we get an injective homomorphism
J:GjH -+ G'jH'

18
GROUPS
I, §3
again called canonical, giving rise to the commutative diagram
0----+ H ----+ G ----+ GIH ----+ 0
j
jl
jl
0----+ H' ----+ G' ----+ G'IH' ----+ O.
If'j'is surjective, then j'is an isomorphism.
We shall now describe some applications of our homomorphism statements.
Let G be a group. A sequence of subgroups
G = Go => GI => Gz => . • • => Gm
is called a tower of subgroups. The tower is said to be normal if each G i; I is
normal in G, (i = 0, ... , m -
I). It is said to be abelian (resp. cyclic) if it is
normal and if each factor group Gj/Gj + I is abelian (resp. cyclic).
Letf:G -. G' be a homomorphism and let
G' = Go => G'I => ••• => G~
be a normal tower in G'. Let G, = f-'(G;). Then the Gj (i = 0, . . . , m) form a
normal tower. If the Gi form an abelian tower (resp. cyclic tower) then the G,
form an abelian tower (resp. cyclic tower), because we have an injective homo-
morphism
GJGj+ I -. GilGi+ I
for each i, and because a subgroup of an abelian group (resp. a cyclic group) is
abelian (resp. cyclic).
A refinement of a tower
G = Go => GI => •. . => Gm
is a tower which can be obtained by inserting a finite number of subgroups in
the given tower. A group is said to be solvable if it has an abelian tower, whose
last element is the trivial subgroup (i.e. Gm = {e} in the above notation).
Proposition 3.1. Let G be a finite group. An abelian tower of G admits a
cyclic refinement. Let G be a finite solvable group. Then G admits a cyclic
tower whose last elementis {e}.
Proof
The second assertion is an immediate consequence of the first, and
it clearly suffices to prove that if G is finite, abelian, then G admits a cyclic
tower ending with {e}. We use induction on the order of G. Let x be an ele-
ment of G. We may assume that x i= e. Let X be the cyclic group generated by
x. Let G' = G/X. By induction, we can find a cyclic tower in G', and its in-
verse image is a cyclic tower in G whose last element is X. If we refine this
tower by inserting {e} at the end, we obtain the desired cyclic tower.
Example.
In Theorem 6.5 it will be proved that a group whose order is a
prime power is solvable.

I, §3
NORMAL SUBGROUPS
19
T ~ D
given by
A ~ diag(A).
Example.
One of the major results of group theory is the Feit-Thompson
theorem that all finite groups of odd order are solvable. Cf. [Go 68] .
Example.
Solvable groups will occur in field theory as the Galois groups
of solvable extensions. See Chapter VI, Theorem 7.2.
Example.
We assume the reader knows the basic notions of linear algebra.
Let k be a field. Let G = GL(n , k) be the group of invertible n X n matrices in
k. Let T = Tin, k) be the upper triangular group ; that is, the subgroup of matrices
which are 0 below the diagonal. Let D be the diagonal group of diagonal matrices
with non-zero components on the diagonal. LetN be the additive group of matrices
which are 0 on and below the diagonal, and let V = I + N, where I is the unit
n X n matrix . Then V is a subgroup of G. (Note that N consists of nilpotent
matrices, i.e. matrices A such that Am = 0 for some positive integer m, Then
(l- A)-I = I + A + A2 + .. . + Am-I is computed using the geometric series.)
Given a matrix A E T, let diag(A) be the diagonal matrix which has the same
diagonal components as A. Then the reader will verify that we get a surjective
homomorphism
The kernel of this homomorphism is precisely V . More generally, observe that
for r ~ 2, the set Nr-I consists of all matrices of the form
0
0
0
air
a In
0
0
0
0
a2.r+1
a2n
M =
0
0
.... .. ... ... ... .
an-r+I ,n
0
0
... .. .... .. .....
0
0
0
... .. .. ... .. ....
0
Let U, = I + N', Then VI = V and U, :J V r + t- Furthermore, Ui; I is normal
in U'; and the factor group is isomorphic to the additive group (!) k"- ', under the
the mapping which sends 1+ M to the n - r-tuple (alr+I' . . . , an-r,n) E p-r.
This n -
r-tuple could be called the r-th upper diagonal. Thus we obtain an
abelian tower
T:J V = VI :::) V 2 :J .. . :J U; = {I}.
Theorem 3.2.
Let G be a group and H a normal subgroup. Then G is solvable
if and only if Hand G/ H are solvable.
Proof.
We
prove
that
G solvable
implies
that
H
is
solvable.
Let
G = Go :J G I :J .. . :J Gr = {e} be a tower of groups with Gi+1 normal in Gi
and such that G;/Gi+l is abelian. Let Hi = H n Gi . Then Hi+ 1 is normal in Hi'
and we have an embedding H;/Hi+ 1 ~ G;/Gi + l , whence H;/Hi+ 1 is abelian,
whence proving that H is solvable. We leave the proofs of the other statements
to the reader.

20
GROUPS
I, §3
Let G be a group. A commutator in G is a group element of the formxyx -1y -l
with x, y E G. Let GC be the subgroup of G generated by the commutators. We
call GCthe commutator subgroup of G. As an exercise, prove that GC is normal
in G, and that every homomorphism f: G ~ G' into a commutative group G'
contains GCin its kernel, and consequently factors through the factor commutator
group GIGc. Observe that GIGc itself is commutative. Indeed, if i denotes the
image of x
in GIGc, then
by definition we have ijii-1y-l
= e,
so i
and ji commute. In light of the definition of solvability, it is clear that the
commutator group is at the heart of solvability and non-solvability problems.
A group G is said to be simple if it is non-trivial, and has no normal subgroups
other than {e} and G itself.
Examples.
An abelian group is simple if and only if it is cyclic of prime
order. Indeed, suppose A abelian and non-trivial. Let a E A, a * e. If a generates
an infinite cyclic group, then a2 generates a proper subgroup and so A is not
simple. If a has finite period, and A is simple, then A = (a) . Let n be the period
and suppose n not prime. Write n = rs with r, s > 1. Then a'
=1= e and a'
generates a proper subgroup, contradicting the simplicity of A, so a has prime
period and A is cyclic of order p.
Examples.
Using commutators, we shall give examples of simple groups
in Theorem 5.5 (the alternating group), and in Theorem 9.2 of Chapter XIII
(PSLn(F), a group of matrices to be defined in that chapter). Since a non-cyclic
simple group is not solvable, we get thereby examples of non-solvable groups.
A major program of finite group theory is the classification of all finite
simple groups.
Essentially most of them (if not all) have natural representa-
tions as subgroups of linear maps of suitable vector spaces over suitable fields,
in a suitably natural way. See [Go 82], [Go 86], [Sol 01] for surveys. Gaps in
purported proofs have been found. As of 2001, these are still incomplete.
Next we are concerned with towers of subgroups such that the factor groups
c.tc.;I are simple. The next lemma is for use in the proof of the Jordan-Holder
and Schreier theorems.
Lemma 3.3.
(Butterfly Lemma.)
(Zassenhaus)
Let U, V be subgroups
of a group. Let u, v be normal subgroups of U and V, respectively. Then
u(U n v)
is normal in
u(U n V),
(u n V)v
is normal in
(U n V)v,
and the factor groups are isomorphic, i.e.
u(U n V)/u(U n v) ~ (U n V)v/(u n V)v.
Proof
The combination of groups and factor groups becomes clear if
one visualizes the following diagram of subgroups (which gives its name to the
lemma):

I, §3
NORMAL SUBGROUPS
21
U
v
u(U n V)
u
v
un V
un v
In this diagram, we are given U, U, V, v. All the other points in the diagram
correspond to certain groups which can be determined as follows. The inter-
section of two line segments going downwards represents the intersection of
groups. Two lines going upwards meet in a point which represents the product
of two subgroups (i.e. the smallest subgroup containing both of them).
We consider the two parallelograms representing the wings of the butterfly ,
and we shall give isomorphisms of the factor groups as follows:
unv
(u n V) (U n v)
u(U n V) =
= (U n V) v
u(U n v)
(u n V)v .
In fact, the vertical side common to both parallelograms has U n V as its
top end point, and (u n V)(U n v) as its bottom end point. We have an iso-
morphism
(U n V)/(u n V)(U n v) ;::::: u(U n V)/u( U n v).
This is obtained from the isomorphism theorem
H/(H n N) ;::::: HN/N
by setting H = U n V and N = u(U n v ). This gives us the isomorphism on
the left. By symmetry we obtain the corresponding isomorphism on the right,
which proves the Butterfly lemma .
Let G be a group, and let
G = Gt :::l G2 :::l . , . :::l G, = {e},
G=H t:::lH2:::l "':::lHs= {e}
be normal towers of subgroups, ending with the trivial group. We shall say
that these towers are equivalent if r = s and if there exists a permutation of the

22
GROUPS
indices i = 1, . . . , r -
1, written i ~ i', such that
I, §3
Gi/Gj+, ::::; Hi/H j.+ i-
In other words, the sequences of factor groups in our two towers are the same,
up to isomorphisms, and a permut ation of the indices.
Theorem 3.4.
(Schreier)
LetG bea group. Twonormaltowers of subgroups
ending with the trivial group have equivalent refinements.
Proof
Let the two towers be as abo ve. For each i = 1, . .. , r - 1 and
j = 1, ... , s we define
Gij = Gj + ,(Hj n GJ
Then Gis = Gi+" and we have a refinement of the first tower:
G = G"
::J G'2 ::J
• •• ::J G" S-I
::J G2
= G2 1 ::J G2 2 ::J
"
' ::J Gr-I,I
::J ••• ::J Gr-I,S-I
::J {e}.
Similarly, we define
n, = H j + I(Gj n H),
for j = 1, .. . , s - 1 and i = 1, . , . , r. This yields a refinement of the second
tower. By the butterfly lemma, for i = 1, ... , r - 1 and j = 1, . . . , s -
1 we
have isomorphisms
Gii/Gj,j+I
::::; HjHj.i+I '
We view each one of our refined towers as having (r -
I)(s -
I) + 1elements,
namely Gij (i = 1, . .. , r - l;j = 1, . . . , s -
1) and {e} in the first case, H ji and
{e} in the second case. The preceding isomorphism for each pair of indices
(i,j) shows that our refined towers are equivalent, as was to be proved.
A group G is said to be simple if it is non-trivial, and has no normal sub-
groups other than {e} and G itself.
Theorem 3.5.
(Jordan-Holder)
Let G be a group, and let
G = GI ::J G2 ::J
• • • ::J Gr = {e}
be a normal tower such that each group Gi/Gi+ I is simple, and G, ¥- Gi+ I
for i = 1, .. . , r -
I. Then any other normaltower ofG havingthe sameprop-
erties is equivalentto this one.
Proof
Given any refinement {Gij} as before for our tower, we observe
that for each i, there exists precisely one indexj such that Gi/Gj + I = Gii/Gi,j+I'
Thus the sequence of non-trivial factors for the original tower, or the refined
tower, is the same. This proves our theorem.

I, §4
Bibliography
CYCLIC GROUPS
23
[Go 68]
D. GORENSTEIN, Finite groups, Harper and Row, 1968
[Go 82]
D. GORENSTEIN , Finite simple groups, Plenum Press, 1982
[Go 83]
D. GORENSTEIN, The Classification of Finite Simple Groups , Plenum Press,
1983
[Go 86]
D. GORENSTEIN, Classifying the finite simple groups, Bull . AMS 14 No. I
(1986), pp. 1-98
[So OIl
R. SOLOMON, A brief history of the classification of the finite simple groups,
Bull. AMS 38,3 (2001) pp. 315-352
§4.
CYCLIC GROUPS
The integers Z form an additive group. We shall determine its subgroups.
Let H be a subgroup of Z. IfH is not trivial, let a be the smallest positive integer
in H. We contend that H consists of all elements na, with n E Z. To prove this,
let y E H. There exist integers n, r with°~ r < a such that
y = na + r.
Since H is a subgroup and r = y - na, we have r E H, whence r = 0, and our
assertion follows.
Let G be a group. We shall say that G is cyclic if there exists an element
a of G such that every element x of G can be written in the form an for some
n E Z (in other words, if the map f :Z -+ G such that f(n) = an is surjective).
Such an element a of G is then called a generator of G.
Let G be a group and a E G. The subset of all elements an (n E Z) is
obviously a cyclic subgroup of G. If m is an integer such that am = e and m > 0
then we shall call m an exponent of a. We shall say that m > 0 is an exponent of
G if x..m = e for all x E G.
Let G be a group and a E G. Let f: Z -+ G be the homomorphism such that
fen) = an and let H be the kernel off Two cases arise:
1. The kernel is trivial. Thenj'is an isomorphism of Z onto the cyclic subgroup
of G generated by a, and this subgroup is infinite cyclic. If a generates G, then
G is cyclic . We also say that a has infinite period.
2. The kernel is not trivial. Let d be the smallest positive integer in the
kernel. Then d is called the period of a. If m is an integer such that am = e then
m = ds for some integer s. We observe that the elements e, a, . . . , ad - \ are

24
GROUPS
I, §4
distinct. Indeed, if ar = as with 0 ~ r, s ~ d -
1, and say r ~ s, then a"? =
e. Since 0 ~ s - r < d we must have s - r = O. The cyclic subgroup generated
by a has order d. Hence by Proposition 2.2:
Proposition 4.1.
Let G be a finite group oforder n > 1. Let a be an element
ofG, a '* e. Then the period ofa divides n. If the order ofG is a prime number
p, then G is cyclic and the period of any generator is equal to p.
Furthermore:
Proposition 4.2.
Let G be a cyclic group . Then every subgroup ofG is cyclic.
Iff is a homomorphism of G, then the image off is cyclic .
Proof.
If G is infinite cyclic, it is isomorphic to Z, and we determined above
all subgroups of Z, finding that they are all cyclic. Iff: G ~ G' is a homo-
morphism, and a is a generator of G, thenf(a) is obviously a generator off(G),
which is therefore cyclic, so the image off is cyclic. Next let H be a subgroup
of G. We want to show H cyclic. Let a be a generator of G. Then we have a
surjective homomorphism f: Z ~ G such that f(n) = an. The inverse image
f-I(H) is a subgroup of Z , and therefore equal to mZ for some positive integer
m. Since f is surjective, we also have a surjective homomorphism mZ ~ H.
Since mZ is cyclic (generated additively by m), it follows that H is cyclic, thus
proving the proposition.
We observe that two cyclic groups of the same order m are isomorphic.
Indeed, if G is cyclic of order m with generator a, then we have a surjective
homomorphism f : Z ~ G such that f(n)
=
an, and if kZ is the kernel,
with k positive, then we have an isomorphism Z/kZ =
G, so k
=
m.
If u : G I ~ Z/mZ and v: G2 ~ Z/mZ are isomorphisms of two cyclic groups
with Z/mZ , then V-IoU: G I ~ G2 is an isomorphism.
Proposition 4.3.
(i) An infinite cyclic group has exactly two generators (ifa is a generator, then
a-I is the only other generator).
(ii) Let G be afinite cyclic group oforder n, and let x be a generator. The set
ofgenerators ofG consists ofthose powers x" ojx such that v is relatively
prime to n.
(iii) Let G be a cyclic group, and let a, b be two generators. Then there exists
an automorphism ofG mapping a onto b. Conversely, any automorphism
ojG maps a on some generator ojG.
(iv) Let G be a cyclic group of order n, Let d be a positive integer dividing n.
Then there exists a unique subgroup of G of order d.
(v) Let G1, G2 be cyclic of orders m, n respectively. If m, n are relatively
prime then GI X G2 is cyclic .

I, §5
OPERATIONS OF A GROUP ON A SET
25
(vi) Let G be ajinite abelian group .lfG is not cyclic. then there exists a prime
p and a subgroup of G isomorphic to C x C. where C is cyclic of order
p.
Proof.
We leave the first three statements to the reader, and prove the others.
(iv) Let d ln. Let m = n/ d. Let f : Z ~ G be a surjective homomorphism .
Th en f (mZ ) is a subgroup of G, and from the isomorphism Z /mZ = G/f (mZ)
we conclude that f(mZ) has index m in G, whencef(mZ) has order d. Conversely,
let H be a subgroup of order d. Then f- t(H) = mZ for some positive integer
m , so H = f(mZ ), ZlmZ = GIH , so n = md, m = nld and H is uniquely
determined.
(v) Let A = (a) and B = (b) be cyclic groups of orders m , n , relatively prime.
Consider the homomorphism Z ~ A x B such that k ~ (a k , bk ) . An element
in its kernel must be divi sible both by m and n, hence by their product since m ,
n are relatively prime. Conversely , it is clear that mnZ is contained in the kernel ,
so the kernel is mnZ. The image of Z ~ A x B is surjective by the Chinese
remainder theorem. This proves (v) . (A reader who does not know the Chinese
remainder theorem can see a proof in the more general context of Chapter II,
Theorem 2.2 .)
(vi) This characterization of cyclic groups is an immediate con sequence of
the structure theorem which will be proved in §8, because if G is not cyclic,
then by Theorem 8.1 and (v) we are reduced to the case when G is a p-group ,
and by Theorem 8.2 there are at least two factors in the direct product (or sum)
decomposition , and each contains a cyclic subgroup oforder p , whence G contains
their direct product (or sum). Statement (vi) is, of course, easier to prove than
the full structure theorem, and it is a good exercise for the reader to formulate
the simpler arguments which yield (vi) directly.
Note.
For the group of automorphisms of a cyclic group, see the end of
Chapter II, §2.
§5.
OPERATIONS OF A GROUP ON A SET
Let G be a group and let S be a set. An operation or an action of G on S
is a homomorphism
1T : G ~ Perm(S)
of G into the group of permutations of S. We then call SaG-set. We denote
the permutation associated with an element x E G by 1Tr Thu s the homomorphism
is denoted by x ~ 1Tx . Given s E S, the image of s under the permutation 1Tx is
1Tx(S ). From such an operation we obtain a mapping
G x s-« S,

26
GROUPS
I, §5
which to each pair (x, s) with x E G and s E S associates the element 7Tx(S). We
often abbreviate the notation and write simply xs instead of 7TxCs) . With the
simpler notation, we have the two properties:
For all .r, y E G and s E S, we have x(ys) = (xy)s.
If e is the unit eLement of G, then es = sfor all s E S.
Conversely, if we are given a mapping G x S ~ S, denoted by (x, s) M
xs,
satisfying these two properties, then for each x E G the map s t-+ xs is a permu-
tation of S, which we then denote by nx(s). Then x t-+ nx is a homomorphism
of G into Perm(S). So an operation of G on S could also bedefined as a map-
ping G x S --+ S satisfying the above two properties. The most important ex-
amples of representations of G as a group of permutations are the following.
1. Conjugation.
For each x E G, let cx: G --+ G be the map such that
cx(y) = xyx- I • Then it is immediately verified that the association x t-+ cx is a
homomorphism G --+ Aut( G), and so this map gives an operation of G on itself,
called conjugation. The kernel of the homomorphism x t-+ Cx is a normal sub-
group of G, which consists of all x E G such that xyx- l = y for all y E G, i.e. all
x E G which commute with every element of G. This kernel is called the center
of G. Automorphisms of G of the form c, are called inner.
To avoid confusion about the operation on the left, we don't write xy for
cx(y). Sometimes, one writes
CX-I (y) = x-1yx = yx,
i.e. one uses an exponential notation. so that we have the rules
y(xz) = (yxy
and
ye = y
for all x , y , Z E G. Similarly, xy = xyx- l and z(Xy) = zXy .
We note that G also operates by conjugation on the set of subsets of G.
Indeed, let S be the set of subsets of G, and let A E S be a subset of G. Then
xAx- 1 is also a subset of G which may be denoted by cx(A), and one verifies
trivially that the map
(x, A) H xAx- 1
of G x S -+ S is an operation of G on S. We note in addition that if A is a sub-
group of G then xAx- I is also a subgroup, so that G operates on the set of
subgroups by conjugation.
If A, B are two subsets of G, we say that they are conjugate if there exists
x E G such that B = xAx- l .
2. Translation.
For each x E G we define the translation Tx : G ~ G by
Tx(Y) = xy. Then the map
(x, Y) H
xy = 'Tx(y)
defines an operation of Gon itself. Warning: 'Tx is not a group-homomorphism!
Only a permutation of G.

I, §5
OPERATIONS OF A GROUP ON A SET
27
Similarly, G operates by translation on the set of subsets, for if A is a
subset of G, then xA = TiA) is also a subset. If H is a subgroup of G, then
TxCH) = xH is in general not a subgroup but a coset of H, and hence we see
that G operates by translation on the set of cosets of H . We denote the set of
left cosets of H by G/H. Thus even though H need not be normal, G/H is a
G-set. It has become customary to denote the set of right cosets by H\G.
The above two representations of G as a group of permutations will be used
frequently in the sequel. In particular, the representation by conjugation will be
used throughout the next section , in the proof of the Sylow theorems.
3. Example from linear algebra.
We assume the reader knows basic
notions of linear algebra. Let k be a field and let V be a vector space over k. Let
G = GL(V) be the group of linear automorphisms of V. For A
E G and
v E V, the map (A , v) ~ Av defines an operation of G on V. Of course , G is
a subgroup of the group of permutations Perm(V). Similarly, let V = k" be the
vector space of (vertical) n-tuples of elements of k, and let G be the group of
invertible n x n matrices with components in k. Then G operates on k" by
(A , X) ~ AX for A E G and X E k" ,
Let S, S' be two G-sets, and f : S -
S' a map. We say thatfis a morphism
of G-sets, or a G-map, if
f(xs) = xf(s)
for all x E G and s E S. (We shall soon define categories, and see that G-sets form
a category.)
We now return to the general situation, and consider a group operating on
a set S. Let s E S. The set of elements x E G such that xs = s is obviously a sub-
group of G, called the isotropy group of s in G, and denoted by Gs •
When G operates on itself by conjugation, then the isotropy group of an
element is none other than the normalizer of this element. Similarly, when G
operates on the set of subgroups by conjugation, the isotropy group of a sub-
group is again its normalizer.
Let G operate on a set S. Let s, s' be elements of S, and y an element of G
such that ys = s', Then
Indeed,
one sees at once that yGsy- I leaves s'
fixed. Conversely, if
x's' = s' then x'ys = ys, so y-1x'y E G, and x' EyGsy-l . Thus the isotropy
groups of s and s' are conjugate.
Let K be the kernel of the representation G -
Perm(S) . Then directly from
the definitions , we obtain that
K = n G, = intersection of all isotropy groups .
S E S

28
GROUPS
I, §5
An action or operation of G is said to be faithful if K = {e}; that is, the kernel
of G ~ Perm(S) is trivial. A fixed point of G is an element s E S such that
xs = s for all x E G or in other words, G = Gs.
Let G operate on a set S. Let s E S. The subset of S consisting of all elements
xs (with x E G) is denoted by Gs, and is called the orbit of sunder G. If x and y
are in the same coset of the subgroup H = Gs ' then xs = ys, and conversely
(obvious). In this manner, we get a mapping
f:G/H-+S
given by f(xH) = xs, and it is clear that this map is a morphism of G-sets. In
fact, one sees at once that it induces a bijection of G/H onto the orbit Gs.
Consequently:
Proposition 5.1.
IfG is a group operating on a set S, and s E S, then the order
ofthe orbit Gs is equal to the index (G: Gs).
In particular, when G operates by conjugation on the set of subgroups, and
H is a subgroup, then :
Proposition 5.2.
The number of conjugate subgroups to H is equal to the
index ofthe normalizer of H.
Example.
Let Gbe a group and H a subgroup of index 2. Then H is normal
in G.
Proof
Note that H is contained in its normalizer NH' so the index of N H
in G is I or 2. Ifit is I, then we are done. Suppose it is 2. Let G operate by con-
jugation on the set of subgroups. The orbit of H has 2 elements, and G operates
on this orbit. In this way we get a homomorphism of G into the group of
permutations of 2 elements. Since there is one conjugate of H unequal to H,
then the kernel of our homomorphism is normal, of index 2, hence equal to H,
which is normal, a contradiction which concludes the proof.
For a generalization and other examples, see Lemma 6.7 .
In general, an operation of G on S is said to be transitive if there is only
one orbit.
Examples.
The symmetric group Sn operates transitively on {I, 2, . . . ,n}.
(See p. 30.) In Proposition 2.1 of Chapter VII, we shall see a non-trivial exam-
ple of transitive action of a Galois group operating on the primes lying above a
given prime in the ground ring. In topology, suppose we have a universal cov-
ering space p : X' -. X , where X is connected. Given x E X , the fundamental
group 7l'1 (X) operates transitively on the inverse image p-l (x).

I, §5
OPERATIONS OF A GROUP ON A SET
29
Example.
Let ~ be the upper half-plane; that is, the set of complex numbers
z = x + iy such that y > O. Let G = SL2(R) (2 x 2 matrices with determinant
1). For
(
a b)
az + b
a =
c
d
E G, we let az = cz + d"
Readers will verify by brute force that this defines an operation of G on ~ . The
isotropy group of i is the group of matrices
(
COS 8 sin 8)
with 8 real.
- sin 8
cos 8
This group is usually denoted by K. The group G operates transitively. You can
verify all these statements as easy exercises.
Let G operate on a set S. Then two orbits of G are either disjo int or are
equal. Indeed, if GS t and Gs; are two orbits with an element s in common,
thens = xs.for some x e Gi and hence Gs = Gxst = Gst . Similarly,Gs = Gsz.
Hence S is the disjoint union of the distinct orbits, and we can write
S = UGSi
ie [
(disjoint),
also denoted S = U c.;
iel
where I is some indexing set, and the s, are elements of distinct orbits. If S is
finite, this gives a decomposition of the order of S as a sum of orders of orbits,
which we call the orbit decomposition formula, namely
card(S) = L (G : Gs).
i E [
Let x, y be elements of a group (or monoid) G. They are said to commute
if xy = YX. If G is a group, the set of all elements x E G which commute with all
elements of G is a subgroup of G which we called the center of G. Let G act on
itself by conjugation. Then x is in the center if and only if the orbit of x is x
itself, and thus has one element. In general, the order of the orbit of x is equal
to the index of the normalizer of x. Thus when G is a finite group, the above
formula reads
(G : 1) = L(G : Gx)
XEC
where C is a set of representatives for the distinct conjugacy classes, and the
sum is taken over all x E C. This formula is also called the class formula.

30
GROUPS
I, §5
The class formula and the orbit decomposition formula will be used systematically
in the next section on Sylow groups, which may be viewed as pro viding examples
for these formulas.
Readers interested in Sylow groups may jump immediately to the next section.
The rest of this section deals with special properties of the symmetric group.
which may serve as examples of the general notions we have developed.
The symmetric group.
Let S; be the group of permutations of a set
with
n
elements.
Thi s
set
may
be
taken
to
be
the
set
of
integers
i n = {I , 2, . .. , n}. Given any 0' E Sn' and any integer i , I ~ i ~ n, we may
form the orbit of i under the cyclic group generated by 0'. Such an orbit is called
a cycle for 0', and may be written
Then {I, . .. , n} may be decomposed into a disjoint union of orbits for the cyclic
group generated by 0', and therefore into disjoint cycles. Thus the effect of 0'
on {I , ... , n} is repre sented by a product of disjoint cycles.
Example.
The cycle [132] represents the permutation 0' such that
0"(1) = 3,
0"(3) = 2,
and
0"(2) = I.
We have 0"2(1) = 2,0"3(1) = I. Thus {I, 3, 2} is the orbit of 1 under the cyclic
group generated by 0".
Example.
In Exerci se 38, one will see how to generate S; by special type s
of generators. Perhaps the most important part of that exercise is that if n is
prime, 0' is an n-cycle and T is a transposition, then 0', T generate Sn- As an
application in Galois theory, if one tries to prove that a Galois group is all
of Sn (as a group of permutations of the roots), it suffices to prove that the
Galois group contains an n-cycle and a transposition. See Example 6 of
Chapter VI, §2.
We want to associate a sign ± I to each permutation. We do this in the
standard way. Let f be a function of n variables , say f: Z" ~ Z, so we can
evaluate f(x], . . . , xn). Let 0' be a permutation of in- We define the function
7T(O')f by
7T(O')f(xl> . . . , xn) = f(Xrr(I)' . .. , X<T(n»'
Then for 0', T E S; we have 7T(O'T) =
7T(O')7T(T). Indeed, we use the definition
applied to the function g =
7T(T)f to get
7T(0')7T(T)f(X" . . . , XII) = (7T(T)f)(X<T(I)' . . .• X<T(II»
=f (xOT(I)' .. . , xOT(n»
= 7T(O'T)f(Xl" . . , x n)·

I, §5
OPERATIONS OF A GROUP ON A SET
31
Since the identity in Sn operates as the identity on functions, it follows that we
have obtained an operation of S; on the set of functions. We shall write more
simply of instead of 1T'(u)f. It is immediately verified that for two functionsf ,
9 we have
u(f + g) = of + ug
and
u (fg) = (uf)( ug).
If e is constant, then u (ef) = catf ).
Proposition 5.3.
There exists a unique homomorphism s: S; ~ {± I} such
that for every transposition T we have £(T) = - 1.
Proof.
Let Li be the function
Li(x l , · .. , xn ) = TI<. (Xj -
Xi )'
I
}
the product being taken for all pairs of integers i , j satisfying 1 ~ i < j
~ n.
Let T be a transposition, interchanging the two integers rand s. Say r < s. We
wish to determine
For one factor involving j = s, i = r, we see that
T changes the factor
(x, - x,) to - (xs - x, ). All other factors can be con sidered in pairs as follows:
(Xk - Xs)(Xk - .r,)
if k > s,
(r, -
Xk)(Xk - x,)
if r < k < s,
(r, - xk)(x, - xk)
if k < r.
Each one of these pairs remains unchanged when we appl y T. Hence we see that
TLi = -Li.
Let e( 0-) be the sign I or - I such that o-Li =
e( o-)Li for a permutation 0-.
Since 1T'(UT) = 1T'(U)1T'(T), it follows at once that s is a homomorphism, and the
proposition is proved.
In particular, if a =
TI
• ••
Tm is a product of transpositions , then
£( rr) = (- l)". As a matter of terminology, we call a even if £(rr) = 1, and odd
if £(u) = -1 . The even permutations constitute the kernel of e, which is called
the alternating group An-
Theorem 5.4.
If n ~ 5 then S; is not solvable.
Proof.
We shall first prove that if H , N are two subgroups of Sn such that
N CHand N is normal in H, if H contains every 3-cycle, and if H/N is abelian,
then N contains every 3-cycle. To see this, let i .], k, r, s be five distinct integers
in I n' and let a = [ijk] and
T = [krs] . Then a direct computation gives their
commutator

32
GROUPS
I, §5
Since the choice of i , j , k, r, s was arbitrary, we see that the cycles [rki] all lie
in N for all choices of distinct r, k, i, thereby proving what we wanted.
Now suppose that we have a tower of subgroups
such that H; is normal in HV - I for v = I, . .. , m, and Hv/Hv- I is abelian. Since
S; contains every 3-cycle, we conclude that HI contains every 3-cycle. By
induction, we conclude that Hm = {e}contains every 3-cycle, which is impossible,
thus proving the theorem.
Remark concerning the sign e(u).
A priori, we defined the sign for a
given n, so we should write cn(O") . However, suppose n < m. Then the restriction
of Cm to S; (viewed as a permutation of in leaving the elements of i m not in in
fixed) gives a homomorphism satisfying the conditions of Proposition 5.3, so
this restriction is equal to cn' Thus Am n S; = An.
Next we prove some properties of the alternating group.
(a) An is generatedby the 3-cycles. Proof" Consider the product of two trans-
positions [ij][rs] . If they have an element in common, the product is either the
identity or a 3-cycle. If they have no element in common, then
[ij][rs] = [ijr]UrsJ,
so the product of two transpositions is also a product of 3-cycles. Since an even
permutation is a product of an even number of transpositions, we are done.
(b) If n ~ 5, all 3-cycles are conjugate in An' Proof: If y is a permutation,
then for a cycle [i I
. . . im] we have
y[i l . . . im]y-I = [y(i)
. . . y(i m) ].
Given 3-cycles [ijk] and [i'j'k'] there is a permutation y such that y(i) = i';
y(j) = j', and y(k) = k': Thus two 3-cycles are conjugate in S; by some element
y. If y is even, we are done . Otherwise, by assumption n ~ 5 there exist r, s
not equal to anyone of the three elements i , j, k. Then [rs] commutes with [ijkJ,
and we replace y by y[rs] to prove (b) .
Theorem 5.5.
If n ~ 5 then the alternating group An is simple.
Proof.
Let N be a non-trivial normal subgroup of An' We prove that N
contains some 3-cycle, whence the theorem follows by (b). Let 0" EN, 0" *" id,
be an element which has the maximal number of fixed points; that is, integers
i such that O"(i) = i. It will suffice to prove that 0" is a 3-cycle or the identity.
Decompose in into disjoint orbits of (O").Then some orbits have more than one
element. Suppose all orbits have 2 elements (except for the fixed points). Since
0" is even, there are at least two such orbits. On their union,
(T is represented as

I, §6
SYLOW SUBGROUPS
33
a product of two transposition s [ij][rs]. Let k # i,i. r, s. Let T = [rsk]. Let
a' = TaT- I a -I. Then a' is a product of a conjugate of a and a -I , so a' E N.
But a' leaves i, j fixed, and any element t E l ; t # i,i. r. s, k left fixed by a
is also fixed by a', so a' has more fixed points than a, contradicting our
hypothe sis.
So we are reduced to the case when at least one orbit of (a) has ~3 elements,
say i , j , k, . . . . If a is not the 3-cycle [ijkJ, then a must move at least two other
elements of Jn' otherwise a is an odd permutation [ijkr] for some r E Jn' which
is impossible . Then let a move r, s other than i, j, k, and let T = [krs] . Let a'
be the commutator as before. Then a ' EN and a '(i ) = i , and all fixed points
of a are also fixed points of a' whence a' has more fixed points than a , a
contradiction which proves the theorem .
Example.
For n = 4, the group A 4 is not simple. As an exercise, show
that A 4 contains a unique subgroup of order 4, which is not cyclic, and which
is normal. This subgroup is also normal in S4' Write down explicitly its elements
as products of transpositions.
§6.
SYLOW SUBGROUPS
Let p be a prime number.
By a p-group, we mean a finite group whose
order is a power of p (i.e. p" for some integer n ~ 0). Let G be a finite group
and H a subgroup. We call Hap-subgroup of G if H is a p-group. We call H
a p-Sylow subgroup if the order of H is p" and if p" is the highest power of p
divid ing the order of G. We shall prove below that such subgroups always
exist. For this we need a lemma.
Lemma 6.1.
Let G be a finite abelian group of order m, let p be a prime
number dividing m. Then G has a subgroup oforder p.
Proof.
We first prove by induction that if G has exponent n then the
order of G divides some power of n. Let bEG, b i= 1, and let H be the cyclic
subgroup generated by b. Then the order of H divides n since b" = 1, and n
is an exponent for G/H.
Hence the order of G/H divides a power of n by
induction, and consequently so does the order of G because
(G : 1) = (G : H)( H : I).
Let G have order divisible by p. By what we have just seen, there exists an
element x in G whose period is divisible by p. Let this period be ps for some
integer s. Then X
S i= 1 and obviously X
S has period p, and generates a subgroup
of order p, as was to be shown.

34
GROUPS
I, §6
Theorem 6.2.
Let G be a finite group and p a prime number dividing the
order of G. Then there exists a p-Sylow subgroup ofG.
Proof.
By induction on the order of G. If the order of G is prime, our
assertion is obvious. We now assume given a finite group G, and assume the
theorem proved for all groups of order smaller than that of G. If there exists a
proper subgroup H of G whose index is prime to p, then a p-Sylow subgroup of
H willalso be one of G,and our assertion follows by induction. We may therefore
assume that every proper subgroup has an index divisible by p. We now let G
act on itself by conjugation. From the class formula we obtain
(G : 1) = (Z : 1) + L (G : Gx),
Here, Z is the center of G, and the term (Z: 1) corresponds to the orbits having
one element, namely the elements of Z. The sum on the right is taken over the
other orbits, and each index (G: Gx) is then> 1, hence divisible by p. Since p
divides the order of G, it follows that p divides the order of Z, hence in particular
that G has a non-trivial center.
Let a be an element of order p in Z, and let H be the cyclic group generated
bya. Since H is contained in Z, it is normal. Letj":G ~ G/H be the canonical
map. Let pn be the highest power of p dividing (G: I). Then pn-l divides the
order of G/H. Let K ' be a p-Sylow subgroup of G/H (by induction) and let
K = f - l(K'). Then K
:::> Hand f maps K onto K'. Hence we have an iso-
morphism K/H ~ K '. Hence K has order pn- 1p = p", as desired.
For the rest of the theorems, we systematically use the notion of a fixed point.
Let G be a group operating on a set S. Recall that a fixed point s of G in S is
an element s of S such that xs == s for all x E G.
Lemma 6.3.
Let H be a p-group acting on a finite set S. Then:
(a) The number offixed points ofHis := #(S) mod p.
(b) If H has exactly one fixed point. then #(S) := I mod p.
(e) Ifp I #(S), then the number offixed points ofHis := 0 mod p .
Proof.
We repeatedly use the orbit formula
#(S) == 2: (H : Hs) .
For each fixed point
si we have HSi
== H . For
Si not fixed, the index
(H : Hs) is divisible by p, so (a) follows at once. Parts (b) and (c) are special
cases of (a), thus proving the lemma.
Remark.
In Lemma 6.3(c), if H has one fixed point, then H has at least p
fixed points .
Theorem 6.4.
Let G be a finite group.
(i) IfH is a p-subgroup ofG. then H is contained in some p-Sylow subgroup.

I, §6
SYLOW SUBGROUPS
35
(ii) All p-Sylow subgroups are conjugate.
(iii) The number ofp-Sylow subgroups of G is = I mod p.
Proof.
Let P be a p-Sylow subgroup of G. Suppose first that H is contained
in the normalizer of P. We prove that H C P. Indeed, HP is then a subgroup
of the normalizer, and P is normal in HP. But
(HP : P) = (H : H n P),
so if HP *" P, then HP has order a power of p, and the order is larger than #(P),
contradicting the hypothesis that P is a Sylow group . Hence HP = P and
H CPo
Next , let 5 be the set of all conjugates of P in G. Then G operates on 5 by
conjugation. Since the normalizer of P contains P, and has therefore index prime
to p ; it follow s that #(5) is not divisible by p. Now let H be any p-subgroup.
Then H also acts on S by conjugation. By Lemma 6.3(a), we know that H cannot
have 0 fixed points. Let Q be a fixed point. By definition this means that H is
contained in the normalizer of Q, and hence by the first part of the proof, that
H C Q, which proves the first part of the theorem. The second part follows
immediately by taking H to be a p-Sylow group , so #(H) = #(Q), whence
H = Q. In particular, when H is a p-Sylow group, we see that H has only one
fixed point, so that (iii) follows from Lemma 6.3(b) . This proves the theorem.
Theorem 6.5.
Let G be a finite p-group. Then G is solvable. If its order is
> I, then G has a non-trivial center.
Proof
The first assertion follows from the second, since if G has center
Z, and we have an abelian tower for G/Z by induction, we can lift this abelian
tower to G to show that G is solvable. To prove the second assertion, we use
the class equation
(G : I) = card(Z) + L(G : Gx)'
the sum being taken over certain x for which (G : Gx )
=1= I. Then p divides
(G : I) and also divides every term in the sum, so that p divides the order of the
center, as was to be shown.
Corollary 6.6.
Let G be a p-qroup which is not of order I.
Then there
exists a sequence ofsubgroups
{e} = Go c G1 C Gz c .. . c G; = G
such that G; is normal in G and Gi + dGi is cyclic oforder p.
Proof
Since G has a non-trivial center, there exists an element a =1= e in
the center of G, and such that a has order p. Let H be the cyclic group generated
by a. By induction, if G =1= H, we can find a sequence of subgroups as stated
above in the factor group G/H. Taking the inverse image of this tower in G
gives us the desired sequence in G.

36
GROUPS
I, §7
We now give some examples to show how to put some of the group theory
together.
Lemma 6.7.
Let G be a finite group and let p be the smallest prime dividing
the order of G. Let H be a subgroup of index p . Then H is normal.
Proof.
Let N(H) = N be the normalizer of H . Then N = G or N = H . If
N = G we are done . Suppose N = H . Then the orbit of H under conjugation
has p = (G : H) elements, and the representation of G on this orbit gives a
homomorphism of G into the symmetric group on p elements, whose order is
p!. Let K be the kernel. Then K is the intersection of the isotropy groups, and
the isotropy group of His H by assumption, so K C H. If K
=1= H, then from
(G : K) = (G : H)(H : K) = p(H : K),
and the fact that only the first power of p divides p! , we conclude that some
prime dividing (p -
I)! also divides (H : K), which contradicts the assumption
that p is the smallest prime dividing the order of G, and proves the lemma.
Proposition 6.8.
Let p, q be distinct primes and let G be a group of order
pq. Then G is solvable.
Proof.
Say p < q. Let Qbe a Sylow subgroup of order q. Then Qhas index
p, so by the lemma, Q is normal and the factor group has order p. But a group
of prime order is cyclic , whence the proposition follows .
Example.
Let G be a group of order 35. We claim that G is cyclic.
Proof.
Let H7 be the Sylow subgroup of order 7. Then H7 is normal by
Lemma 6.7. Let Hs be a 5-Sylow subgroup, which is of order 5. Then Hs
operates by conjugation on H7 , so we get a homomorphism Hs ~ Aut(H7) . But
Aut(H7) is cycli c of order 6, so Hs ~ Aut(H7 ) is trivial , so every element of
Hscommutes with elements of H7 . LetHs = (x) andH7 = (y), Then x, y commute
with each other and with themselves, so G is abelian, and so G is cyclic by
Proposition 4.3(v).
Example.
The techniques which have been developed are sufficient to treat
many cases of the above types . For instance every group of order < 60 is solvable,
as you will prove in Exercise 27.
§7.
DIRECT SUMS AND FREE ABELIAN GROUPS
Let {AJiel be a family of abelian groups. We define their direct sum
A = EEl Ai
ie l
to be the subset of the direct product TI Ai consisting of all families (Xi)iel with

I, §7
DIRECT SUMS AND FREE ABELIAN GROUPS
37
Xi E A i such that Xi = 0 for all but a finite number of indices i . Then it is clear
that A is a subgroup of the product. For each index j E J, we map
by letting Ai x) be the element whose j-th component is x, and having all other
components equal to O. Then Ai is an injective homomorphism.
Proposition 7.1.
Let {fi: A i ~ B} be a family of homomorphisms into an
abelian group B. Let A = EB A i' There exists a unique homomorphism
f:A~B
such that f
0 Aj = !J for all j .
Proof.
We can define a map f: A ~ B by the rule
f«XJiEI) = L j;(xJ,
iEi
The sum on the right is actually finite since all but a finite number of terms are O.
It is immediately verified that our map f is a homomorphism. Furthermore,
we clearly have f
0 Aj(x) = fj(x ) for each j and each x E Aj . Thus f has the
desired commutativity property. It is also clear that the map f is uniquely
determined, as was to be shown.
The property expressed in Propo sition 7.1 is called the universal property
of the direct sum. Cf. §II .
Example.
Let A be an abelian group, and let {A iLel be a family of sub-
groups. Then we get a homomorphism
EB Ai ~ A
such that
(Xi) ~ L Xi'
iel
Theorem 8. 1 will provide an important specific application.
Let A be an abelian group and B, C subgroups. If B + C
B n C = {O} then the map
A and
B xC->A
given by (x, y) ~ x + y is an isomorphism (as we already noted in the non-
commutative case). Instead of writing A = B x C we shall write
A=Btj3C
and say that A is the direct sum of Band C. We use a similar notation for the
direct sum of a finite number of subgroups Bl ' . . . , B; such that
B1 + ... + B; = A
and
Bi+.n (B. + ... + BJ = O.

38
GROUPS
In that case we write
I, §7
Let A be an abelian group . Let [e.] (i E l) be a family of elements of A. We
say that this family is a basis for A if the family is not empty, and if every
element of A has a unique expression as a linear combination
with Xi E Z and almost all Xi = O. Thus the sum is actually a finite sum. An
abelian group is said to be free ifit has a basis. If that is the case, it is immediate
that if we let Z, = Z for all i, then A is isomorphic to the direct sum
A"'" EBZi '
iE!
Next let S be a set. We shall define the free abelian group generated by S as
follows. Let Z(S) be the set of all maps cp : S ~ Z such that cp(x) = 0 for almost
all XES . Then Z(S) is an abelian group (addition being the usual addition of
maps). If k is an integer and X is an element of S, we denote by k . x the map
cp such that cp(x) = k and cp(y) = 0 if y *" x. Then it is obvious that every element
cp of Z(S) can be written in the form
for some integers ki and elements Xi E S (i = 1, . . . , n), all the Xi being distinct.
Furthermore, qJadmits a unique such expression, because if we have
qJ = L kx . X = L k~ . X
XES
XES
then
o = L (kx -
k~) . x,
X ES
whence k'; = kx for all XES.
We map S into Z<S > by the map Is = I such that I(x) = 1 . x. It is
then clear that I is injective, and that I(S) generates Z<S>. If g :S ~ B is a
mapping of S into some abelian group B, then we can define a map
such that
This map is a homomorphism (trivial) and we have 9* 0 f = 9 (also trivial) . It
is the only homomorphism which has this property, for any such homomorphism
9* must be such that 9*(1 . x) = 9(x) .

I, §7
DIRECT SUMS AND FREE ABELIAN GROUPS
39
It is customary to identify S in Z<S), and we sometimes omit the dot when
we write kxx or a sum Lkxx.
IJ A. :S -+ S' is a mapping ojsets, there is a uniquehomomorphism 1makingthe
Jollowing diagram commutative:
S~Z <S )
Al
Ix
S'~Z<S ' )
In fact, 1 is none other than Us' 0 A.)*, with the notation of the preceding para-
graph. The proof of this statement is left as a trivial exercise.
We shall denote Z(S) also by Fab(S) , and call Fab(S) the free abelian group
generated by S. We call elements of S its free generators.
As an exercise, show that every abelian group A is isomorphic to a factor
group of a free abelian group F . If A is finitely generated, show that one can
select F to be finitely generated also.
If the set S above consists of n elements, then we say that the free abelian
group Fab(S) is the free abelian group on n generators. If S is the set of n
letters XI"'"
x n , we say that Fab(S) is the free abelian group with free
generators X I' . •. , xn •
An abelian group is free if and only if it is isomorphic to a free abelian group
Fab(S) for some set S. Let A be an abelian group, and let S be a basis for A.
Then it is clear that A is isomorphic to the free abelian group Fab(S).
As a matter of notation, if A is an abelian group and T a subset of elements
of A, we denote by (T) the subgroup generated by the elements of T, i.e., the
smallest subgroup of A containing T.
Example.
The Grothendieck group.
Let M be a commutative monoid,
written additively. There exists a commutative group K(M) and a monoid-
homomorphism
y: M --+ K(M)
having the following universal property. Iff: M ~ A is a homomorphism into
an abelian group A, then there exists a unique homomorphism f* : K(M) ~ A
making the following diagram commutative:
M~K(M)
~\}.
Proof
Let Fab(M) be the free abelian group generated by M. We denote
the generator of Fab(M) corresponding to an element X E M by [x]. Let B be
the subgroup generated by all elements of type
[x + y] - [x] - [y]

40
GROUPS
I, §7
where x, y EM. We let K(M) = Fab(M)/B, and let
y : M --. K(M)
be the map obtained by composing the injection of Minto Fab(M) given by
x 1-+ [x], and the canonical map
Fab(M) --. Fab(M)/B.
It is then clear that y is a homomorphism, and satisfies the desired universal
property.
The universal group K(M) is called the Grothendieck group.
We shall say that the cancellation law holds in M if, whenever x, y, Z EM,
and x + Z = Y + Z, we have x = y.
We then have an important criterion when the universal map y above is
injective :
If the cancellation law holds in M, then the canonical map y of M into its
Grothendieck group is injective.
Proof
This is essentially the same proof as when one constructs the
integers from the natural numbers. We consider pairs (x, y) with x, y E M
and say that (x, y) is equivalent to (x' ,y') if y + x' = x + y'. We define addi-
tion of pairs componentwise. Then the equivalence classes of pairs form a
group, whose °element is the class of (0,0) [or the class of (x,x) for any
x EM]. The negative of an element (x, y) is (y, x). We have a homomorphism
x 1-+ class of (0, x)
which is injective, as one sees immediately by applying the cancellation law.
Thus we have constructed a homomorphism of M into a group, which is
injective. It follows that the universal homomorphism must also be injective.
Examples.
See the example of projective modules in Chapter III, §4. For
a relatively fancy context, see: K. KATO, Logarithmic structures of Fontaine-
Illusie, Algebraic Geometry, Analysis and Number Theory, Proc. JAM! Confer-
ence, J. Igusa (Ed.), Johns Hopkins Press (1989) pp. 195-224.
Given an abelian group A and a subgroup B, it is sometimes desirable to
find a subgroup C such that A = B E9 C. The next lemma gives us a condition
under which this is true.
Lemma7.2.
Let A ~ A' be a surjective homomorphism of abelian groups,
and assume that A' is free. Let B be the kernel of f . Then there exists a
subgroup C of A such that the restriction of f to C induces an isomorphism
ofC with A', and such that A = B E9 C.
Proof. Let {X;};eI be a basis of A', and for each i E I, let Xi be an element of
A such that j'(x.) = x;. Let C be the subgroup of A generated by all elements
Xi' i EI . If we have a relation
LniXi =°
ieI

I, §7
DIRECT SUMS AND FREE ABELIAN GROUPS
41
with integers nj , almost all of which are equal to 0, then applying f yields
o= LnJ (xj) = LnjX;,
jel
jel
whence all nj = O. Hence our family {xjL el is a basis of C. Similarly, one sees
that if Z E C and f(z) = 0 then z = O.
Hence B n C = O. Let x E A. Since
f(x) E A' there exist integers n;. i E I, such that
f (x ) = LnjX;'
j e 1
Applying f to x - L n.x., we find that this element lies in the kernel of f ,
i E I
say
x - LnjXj = b EB.
jel
From this we see that x E B + C, and hence finally that A = B EB C is a direct
sum, as contended.
Theorem 7.3.
Let A be afree abelian group, and let B be a subgroup. Then
B is also a free abelian group, and the cardinality of a basis of B is ~ the
cardinality ofa basisfor A. Any two bases ofB have the same cardinality.
Proof
We shall give the proof only when A is finitely generated, say by a
basis {XI" ' " x n } (n ~ I), and give the proof by induction on n. We have an
expression of A as direct sum :
A = ZX I EB ... EB Zxn•
Let f :A --> Zx I be the projection, i.e. the homomorphism such that
[im, », + ... + mnxn) = ml x I
whenever mj E Z. Let B I be the kernel offl B. Then B I is contained in the free
subgroup ( x 2, . .. , xn ) . By induction, B I is free and has a basis with
~ n -
1
elements. By the lemma, there exists a subgroup C I isomorphic to a subgroup
of ZX1 (namely the image offlB) such that
B = B 1 EB C I ·
Since f(B) is either 0 or infinite cyclic, i.e. free on one generator, this proves
that B is free.
(When A is not finitely generated, one can use a similar transfinite argument.
See Appendix 2, §2, the example after Zorn's Lemma.)
We also observe that our proof shows that there exists at least one basis
of B whose cardinality is ~ n. We shalJ therefore be finished when we prove
the last statement, that any two bases of B have the same cardinality. Let S
be one basis, with a finite number of elements m. Let T be another basis, and
suppose that T has at least r elements. It will suffice to prove that r ~ m (one

42
GROUPS
I, §8
can then use symmetry). Let p be a prime number.
Then B/pB is a direct
sum of cyclic groups of order p, with m terms in the sum.
Hence its order
is p". Using the basis T instead of S, we conclude that B/pB contains an r-fold
product of cyclic groups of order p, whence p' ~ v". and r ~ m, as was to
be shown. (Note that we did not assume a priori that T was finite.)
The number of elements in a basis of a free abelian group A will be called
the rank of A.
§8.
FINITELY GENERATED ABELIAN GROUPS
The groups referred to in the title of this section occur so frequently that it is
worth while to state a theorem which describes their structure completely.
Throughout this section we write our abelian groups additively.
Let A be an abelian group. An element a E A is said to be a torsion element
if it has finite period. The subset of all torsion elements of A is a subgroup of A
called the torsion subgroup of A. (If a has period m and b has period n then,
writing the group law additively, we see that a ± b has a period dividing mn.)
The torsion subgroup of A is denoted by Atop or simply A"
An abelian
group is called a torsion group if A = Atop that is all elements of A are of finite
order.
A finitely generated torsion abelian group is obviously finite. We shall begin
by studying torsion abelian groups . IfA is an abelian group andp a prime number,
we denote by A(p) the subgroup of all elements x E A whose period is a power
of p. Then A(p) is a torsion group , and is a p-group if it is finite.
Theorem 8.1
Let A be a torsion abelian group. Then A is the direct sum of
its subgroups A(p) for all primes p such that A(p) "* O.
Proof.
There is a homomorphism
EB A(p) ~ A
p
which to each element (xp) in the direct sum associates the element L xp in A.
We prove that this homomorphism is both surjective and injective. Suppose x
is in the kernel, so 2: xp = O. Let q be a prime . Then
xq = L (-xp ) '
p*q
Let m be the least common multiple of the periods of elements xp on the right-
hand side, with x q "* 0 and p "* q. Then mXq = O. But also qrXq = 0 for some
positive integer r. If d is the greatest common divisor of m, q' then dXq = 0,
but d = I, so xq = O. Hence the kernel is trivial, and the homomorphism is
injective.

I, §8
FINITELY GENERATED ABELIAN GROUPS
43
As for the surjectivity, for each positive integer m, denote by Am the kernel
of multiplication by m, i.e . the subgroup of x E A such that mx = O. We prove:
If m = rs with r, s positive relative prime integers, then Am = Ar + As'
Indeed, there exist integers u, v such that ur + vs = 1. Then x = urx + vsx,
and urx E As while vsx E An and our assertion is proved. Repeating this process
inductively, we conclude:
If m = npe(p) then Am = 2: Ape(Pl.
plm
plm
Hence the map EB A(p) ~ A is surjective, and the theorem is proved.
Example.
Let A = Q/Z. Then Q/Z is a torsion abelian group, isomorphic
to the direct sum of its subgroups (Q /Z)(p) . Each (Q/Z)(p) consists of those
elements which can be represented by a rational number afp" with a E Z and k
some positive integer, i.e. a rational number having only a p-power in the
denominator. See also Chapter IV, Theorem 5.1.
In what follows we shall deal with finite abelian groups, so only a finite
number of primes (dividing the order of the group) will come into play. In this
case, the direct sum is "the same as" the direct product.
Our next task is to describe the structure of finite abelian p-groups. Let
r1 , ••• , rs be integers ~ I. A finite p-group A is said to be of type (pr"
,pro)
if A is isomorphic to the product of cyclic groups of orders p" (i = 1,
, s).
We shall need the following remark .
Remark.
Let A be a finite abelian p-group. Let b be an element of
A, b '* 0. Let k be an integer ~ °such that pkb '* 0, and let pm be the period
of p'b , Then b has period pk+m. [Proof We certainly have pk+mb = 0, and if
pnb = 0 then first n ~ k, and second n ~ k +m , otherwise the period of pkb
would be smaller than pm.]
Theorem 8.2.
Every finite abelian p-group is isomorphic to a product of
cyclic p-groups. If it is of type (pr l , • •• , prs) with
then the sequence of integers (rl' .. . , rs) is uniquely determined.
Proof.
We shall prove the existence of the desired product by induction.
Let al E A be an element of maximal period . We may assume without loss of
generality that A is not cyclic. Let Al be the cyclic subgroup generated by ai'
say of period p'», We need a lemma.
Lemma 8.3.
Let fj be an element ofA/AI' ofperiod proThen there exists a
representative a of fj in A which also has period pro

44
GROUPS
I, §8
Proof
Let b be any representative of 5 in A. Then prb lies in Al' say
p'b = na1 with some integer n ~ O. We note that the period of 5 is ~ the period
of b. If n = 0 we are done. Otherwise write n = pkJL where JL is prime to p.
Then JLQI is also a generator of AI' and hence has period p'». We may assume
k ~ rl ' Then pkJLQI has period p,.-k. By our previous remarks, the element b
has period
whence by hypothesis, r + r1 -
k ~ r1 and r ~ k. This proves that there exists
an element C E A 1 such that p'b = p'c. Let a = b - c. Then a is a representative
for 5 in A and p'a = O. Since period (a) ~ p' we conclude that a has period
equal to p'.
We return to the main proof. By induction, the factor group AlAI has a
product expression
AlAI = A2 X • . . x As
into cyclic subgroups of orders p'2, . . . , p's respectively, and we may assume
t z ~ . . . ~ rs.
Let lli be a generator for Ai (i = 2, . . . , s) and let a, be a
representative in A of the same period as lli' Let Ai be the cyclic subgroup
generated by a.. We contend that A is the direct sum of AI> . .. , As'
Given x E A, let x denote its residue class in AIA i-
There exist integers
mi ~ 0 (i = 2, . .. , s) such that
Hence x - m2a2 - . . . - msas lies in AI, and there exists an integer ml ~ 0
such that
x = mla l + m2a2 + ... + msas.
Hence Al + ... + As = A.
Conversely, suppose that mI , . .. , ms are integers ~ 0 such that
0= mial + ... + msas.
Since ai has period p" (i = 1, .. . , s), we may suppose that mi < p". Putting
a bar on this equation yields
0= m2ii2 + ... + m.ii;
Since AlAI is a direct product of A2, . . . , As we conclude that each mi = 0 for
i = 2, . .. , s. But then mI = 0 also, and hence all mi = 0 (i = 1, . . . , s). From
this it follows at once that
(AI + ... + Ai)nAi+ I = 0
for each i ~ 1, and hence that A is the direct product of AI"", As, as desired.
We prove uniqueness , by induction. Suppose that A is written in two ways
as a direct sum of cyclic groups, say of type
(p", . .. ,p's)
and
(pm" . . . , pmk)

I, §8
FINITELY GENERATED ABELIAN GROUPS
45
with r l
~ . • • ~ r. ~ 1 and ml ~ .. . ~ mk ~ 1. Then pA is also a p-group,
of order strictly less than the order of A, and is of type
(pr,-I, . .. ,pr.-I)
and
(pm,-I, . .. ,pmk-I),
it being understood that if some exponent r j or mj is equal to 1, then the factor
corresponding to
in pA is simply the trivial group 0. By induction, the subsequence of
(rl -
1,00.,r. -
1)
consisting of those integers
~ 1 is uniquely determined, and is the same as
the corresponding subsequence of
(ml - 1, .. . , mk -
1).
In other words, we have r, -
1 = mj -
1 for all those integers i such that
rj -
1 or mj -
1 ~ 1. Hence r, = mj for all these integers i, and the two se-
quences
( "
r.)
and
(m,
mk)
p , oo.,p
p
, oo .,p
can differ only in their last components which can be equal to p. These cor-
respond to factors of type (p, . . . , p) occurring say v times in the first sequences
and J1. times in the second sequence. Thus for some integer n, A is of type
(pr" . . . , prn, p, .. . ,p)
and
'--v-'
v times
Thus the order of A is equal to
(p", . . . , prn, p, . . . , p).
"-r--'
1J times
prl+ "'+rnp' = pr'+'''+rnpl',
whence v =
J1., and our theorem is proved .
A group G is said to be torsion free, or without torsion, if whenever an
element x of G has finite period, then x is the unit element.
Theorem 8.4.
Let A be ajinitely generated torsion-free abelian group . Then
A is free .
Proof
Assume A =1= 0. Let S be a finite set of generators, and let x I' . . . , x,
be a maximal subset of S having the property that whenever VI' . . . , Vn are
integers such that
VIXI + ... + VnX n = 0,
then vj = °for all j. (Note that n ~ 1 since A
=1= 0). Let B be the subgroup
generated by Xl, . .. , xn. Then B is free. Given yES there exist integers
ml, . . . , mn , m not all zero such that
my + mlx l + ... + mnXn = 0,

46
GROUPS
I, §9
by the assumption of maximality on XI"
'" x. : Furthermore, m =1= 0; other-
wise all mj = O. Hence my lies in B. This is true for everyone of a finite set of
generators y of A, whence there exists an integer m =1= 0 such that mA c B.
The map
X t-> mx
of A into itself is a homomorphism, having trivial kernel since A is torsion free.
Hence it is an isomorphism of A onto a subgroup of B. By Theorem7.3 of the
preceding section, we conclude that mA is free, whence A is free.
Theorem 8.5.
Let A be a finitely generated abelian group, and let Alor be
the subgroup consisting of all elements ofA having finite period. Then Alor is
finite , and AIAtor isfree. There exists afree subgroup B ofA such that A is the
direct sum ofAtor and B.
Proof
We recall that a finitely generated torsion abelian group is obviously
finite. Let A be finitely generated by n elements, and let F be the free abelian
group on n generators. By the universal property, there exists a surjective
homomorphism
of F onto A. The subgroup ip-l(Ator) of F is finitely generated by Theorem 7.3.
Hence Ator itself is finitely generated, hence finite.
Next, we prove that AIAtor has no torsion. Let i be an element of AIAtor
such that mi = 0 for some integer m '* O. Then for any representative of x of
i in A, we have mx E Atop whence qmx = 0 for some integer q '* O. Then
x E Atop so i = 0, and AIAtor is torsion free . By Theorem 8.4, AIAtor is free .
We now use the lemma of Theorem 7.3 to conclude the proof.
The rank of AIAtor is also called the rank of A.
For other contexts concerning Theorem 8.5, see the structure theorem for
modules over principal rings in Chapter III, §7, and Exercises 5, 6, and 7 of
Chapter III.
§9.
THE DUAL GROUP
Let A be an abelian group of exponent m ~ 1. This means that for each
element x E A we have mx = O. Let Zm be a cyclic group of order m, We denote
by A/\ , or Hom(A, Zm) the group of homomorphisms of A into Zm' and call it
the dual ofA .
Letf: A ~ B be a homomorphism of abelian groups, and assume both have
exponent m. Then f induces a homomorphism
f /\
:B /\~A /\ .

I, §9
THE DUAL GROUP
47
Namely, for each e E B II we define j!I( "') = '" 0 f. It is trivially verified that j"
is a homomorphism. The properties
id/' = id
and
(f 0 g) 1I = gil
0 j!I
are trivially verified .
Theorem 9.1.
If A is a finite abelian group, expressed as a product
A = B X C. then A II is isomorphic to BII X CII (under the mapping described
below). A finite abelian group is isomorphic to its own dual.
Proof
Consider the two projections
BxC
;/~
B
C
of B x C on its two components. We get homomorphisms
(B X C) II
:/~
CII
and we contend that these homomorphisms induce an isomorphism of BII X CII
onto (B X C)II.
In fact , let "'I' "'Z be in Hom(B, Zm) and Hom(C, Zm) respectively. Then
("'I> "'z) E B II X CII , and we have a corresponding element of (B
X C)II by
defining
("'I' "'z)(x, y) = "'I(X) + "'z(y),
for (x, y) E B x C. In this way we get a homomorphism
B II X CII ~ (B X C) II.
Conversely, let'" E (B
X C) II . Then
"'(x, y) = "'(x,O) + "'(0, y).
The function "'Ion B such that "'I(X)
= "'(x,O) is in BII, and similarly the
function "'z on C such that "'z(y) = "'(0, y) is in CII. Thus we get a homomorphism
(B x C) II ~ B II X CII,
which is obviously inverse to the one we defined previously. Hence we obtain
an isomorphism, thereby proving the first assertion in our theorem.
We can write any finite abelian group as a product of cyclic groups. Thus
to prove the second assertion, it will suffice to deal with a cyclic group.
Let A be cyclic, generated by one element x of period n. Then nIm, and Zm
has precisely one subgroup of order n, Zn, which is cyclic (Proposition 4.3(iv)).

48
GROUPS
I, §9
If l/J : A ~ Zm is a homomorphi sm, and x is a generator for A, then the period
of x is an exponent for l/J(x) , so that l/J(x), and hence l/J(A), is contained in Zn-
Let y be a generator for Zn- We have an isomorphi sm
l/JI :A --+ Z;
such that l/Jl(X) = y. For each integer k with 0 ~ k < n we have the homo-
morphism kl/J 1 such that
In this way we get a cyclic subgroup of Ar; consisting of the n elements kl/JI
(0 ~ k < n). Conversely, any element l/J of A f\ is uniquely determined by its
effect on the generator x,
and must map x on one of the n elements
kx (0 ~ k < n) of Zn' Hence l/J is equal to one of the maps kl/J\. These maps
constitute the full group A f\ , which is therefore cyclic of order n, generated by
l/J\. This proves our theorem .
In considering the dual group, we take various cyclic groups Zm . There are
many applications where such groups occur, for instance the group of m-th roots
of unity in the complex numbers, the subgroup of order m of QjZ, etc.
Let A, A' be two abelian groups. A bilinear map of A x A' into an abelian
group C is a map
A x A' --+ C
denoted by
(x, x') ....... <x, x')
having the following property.
For each x E A the function
X' ....... <x, x')
is a homomorphism, and similarly for each x' E A' the function x ....... <x, x') is a
homomorphism.
As a special case of a bilinear map, we have the one given by
A x Hom(A, C) -+ C
which to each pair (x,f) with x E A and f E Hom(A, C) associates the element
f(x) in C.
A bilinear map is also called a pairing.
An element x E A is said to be orthogonal (or perpendicular) to a subset S'
of A' if (x, x') = 0 for all x' E S'. It is clear that the set of x E A orthogonal to S'
is a subgroup of A. We make similar definitions for elements of A', orthogonal
to subsets of A.
The kernel of our bilinear map on the left is the subgroup of A which is
orthogonal to all of A'. We define its kernel on the right similarly.
Given a bilinear map A x A' -+ C, let B, B' be the respective kernels of our
bilinear map on the left and right. An element x' of A' gives rise to an element of
Hom(A, C) given by x ....... (x, x'), which we shall denote by l/Jx"
Since l/Jx'
vanishes on B we see that l/Jx' is in fact a homomorphism of AjB into C.

I, §10
INVERSE LIMIT AND COMPLETION
49
Furthermore, IjJx' = ljJy' if x', y' are elements of A' such that
x' == y'
(mod B').
Hence IjJ is in fact a homomorphism
0-+ A'jB' -+ Hom(A jB, C),
which is injective since we defined B' to be the group orthogonal to A.
Similarly, we get an injective homomorphism
0-+ AjB -+ Hom(A'jB', C).
Assume that C is cyclic of order m. Then for any x' E A' we have
mljJx' = IjJmx' = 0,
whence A'jB' has exponent m. Similarly, AjB has exponent m.
Theorem 9.2.
Let A X A' ~ C be a bilinear map oftwo abelian groups into
a cyclic group C of order m. Let B, B' be its respective kernels on the left and
right. Assume that A' /B' is finite. Then A/B is finite, and A'/B' is isomorphic
to the dual group ofA/B (under our map 1jJ).
Proof
The injection of AjB into Hom(A'jB', C) shows that AjB is finite.
Furthermore, we get the inequalities
ordA/B ~ ord(A '/B') " = ordA'/B'
and
ord A'/B' ~ ord(A /B)" = ord A/B.
From this it follows that our map IjJ is bijective, hence an isomorphism.
Corollary 9.3.
Let A be a finite abelian group, B a subgroup , A" the dual
group, and Bi- the set of tp E A/\ such that CP(B) = O. Then we have a natural
isomorphism ofA"/Bi- with B" .
Proof.
This is a special case of Theorem 9.2.
§10.
INVERSE LIMIT AND COMPLETION
Consider a sequence of groups {Gn } (n = 0, 1, 2, . . .), and suppose given
for all n ~ 1 homomorphisms
L; G; ~ Gn- I •
Suppose first that these homomorphisms are surjective. We form infinite
sequences

50
GROUPS
I, §10
By the assumption of surjectivity, given Xn E G; we can always lift Xn to Gn+ 1
via/n+ l ' so such infinite sequences exist, projecting to any given xo' We can
define multiplication of such sequences componentwise, and it is then imme-
diately verified that the set of sequences is a group, called the inverse limit
of the family {(Gn,fn)} . We denote the inverse limit by ill!! (Gn,fn), or simply
lim Gn if the reference to in is clear.
Example.
Let A be an additive abelian group. Let p be a prime number.
Let PA : A -
A denote multiplication by p. We say that A is p-divisible if PA is
surjective. We may then form the inverse limit by taking An = A for all n, and
In = PA for all n, The inverse limit is denoted by Vp(A). We let Tp(A) be the
subset of ViA) consisting of those infinite sequences as above such that
Xo = O. Let A[pn ] be the kernel of p~
. Then
Tp(A) = l~ A[p n+I ] .
The group Tp(A) is called the Tate group associated with the p-divisible group
A. It arose in fairly sophisticated contexts of algebraic geometry due to Deuring
and Weil, in the theory of elliptic curves and abelian varieties developed in the
1940s, which are far afield from this book. Interested readers can consult books
on those subjects.
The most common p-divisible groups are obtained as follows . First, let A be
the subgroup of Q/Z consisting of those rational numbers (mod Z) which can
be expressed in the form alp" with some positive integer k, and a E Z . Then A
is p-divisible.
Second, let ....[pn] be the group of pn-th roots of unity in the complex numbers.
Let ....[pOO] be the union of all ....[pn] for all n. Then ....[pOO] is p-divisible, and
isomorphic to the group A of the preceding paragraph. Thus
Tp(Jl) = l~ Jl[pn] .
These groups are quite important in number theory and algebraic geometry. We
shall make further comments about them in Chapter 1II, §10, in a broader context.
Example.
Suppose given a group G. Let {Hn } be a sequence of normal
subgroups such that n, ~ H n+ 1 for all n. Let
in : G/Hn-
G/Hn- 1
be the canonical homomorphisms. Then we may form the inverse limitill!! G/ Hn:
Observe that G has a natural homomorphism
g : G -
ill!! G/Hn ,
which sends an element x to the sequence (. .. , Xn' .. . ) , where xn = image of
x in G/Hn .
Example.
Let G; = Z/pn+lZ for each n ~ O. Let
in : Z/pn+lZ -
Z/pnz
be the canonical homomorphism. Then in is surjective, and the limit is called

I, §10
INVERSE LIMIT AND COMPLETION
51
the group of p-adic integers, denoted by Zp. We return to this in Chapter III,
§10, where we shall see that Zp is also a ring.
After these examples, we want to consider the more general situation when
one deals not with a sequence but with a more general type of family of groups,
which may not be commutative. We therefore define inverse limits of groups in
general.
Let I be a set of indices. Suppose given a relation of partial ordering in I,
namely for some pairs (i,j) we have a relation i ~ j satisfying the conditions:
For all i,i, k in I, we have i ~ i; if i ~ j and j ~ k then i ~ k; if i ~ j and j ~ i
then i = j. We say that I is directed if given i, j E I, there exists k such that
i ~ k and j ~ k. Assume that I is directed. By an inversely directed family
of groups, we mean a family {GJieI and for each pair i ~ j a homomorphism
I{: Gr~ c,
such that, whenever k ~ i ~ j we have
I~ 011 =I{
and Ii = id.
Let G = f1 Gi be the product of the family . Let r be the subset of G consisting
of all elements (Xi) with Xi E Gi such that for all i and j ~ i we have
I{(x) = Xi'
Then r contains the unit element, and is immediately verified to be a subgroup
of G. We call r the inverse limit of the family, and write
r = lim Gi ·
Example.
Let G be a group . Let fT be the family of normal subgroups of
finite index . If H, K are normal of finite index, then so is H n K, so fT is a
directed family. We may then form the inverse limit lim G/ H with HEfT. There
is a variation on this theme . Instead of :J, let p be a prime number, and let :Jp
be the family of normal subgroups of finite index equal to a power of p . Then
the inverse limit with respect to subgroups HEfT p can also be taken. (Verify
that if H, K are normal of finite p-power index, so is their intersection.)
A group which is an inverse limit of finite groups is called profinite.
Example from applications.
Such inverse limits arise in Galois theory.
Let k be a field and let A be an infinite Galois extension. For example, k = Q
and A is an algebraic closure of Q. Let G be the Galois group; that is, the group
of automorphisms of A over k. Then G is the inverse limit of the factor groups
G/H, where H ranges over the Galois groups of A over K, with K ranging over
all finite extensions of k contained in A. See the Shafarevich conjecture in the
chapter on Galois theory, Conjecture 14.2 of Chapter VI.
Similarly, consider a compact Riemann surface X of genus
~ 2. Let
p : X' -+ X be the universal covering space. Let C(X) = F and C(X') = F' be
the function fields. Then there is an embedding
7r1 (X) '---+ Gal(F'/ F). It is
shown in complex analysis that 7r1 (X) is a free group with one commutator

52
GROUPS
I, §10
relation. The full Galois group of F'IF is the inverse limit with respect to the
subgroups of finite index, as in the above general situation.
Completion of a group
Suppose now that we are given a group G, and first, for simplicity, suppose
given a sequence of normal subgroups {Hr} with H, ::> Hr+I for all r, and such
that these subgroups have finite index. A sequence {xn } in G will be called a
Cauchy sequence if given H, there exists N such that for all m, n ~ N we have
xnx;;; I E Hr. We say that {xn} is a null sequence if given r there exists N such
that for all n ~ N we have xn E Hr. As an exercise, prove that the Cauchy
sequences form a group under termwise product, and that the null sequences
form a normal subgroup. The factor group is called the completion of G (with
respect to the sequence of normal subgroups).
Observe that there is a natural homomorphism of G into its completion;
namely, an element x E G maps to the sequence (x,
X,
X, • . .) modulo null
sequences. The kernel of this homomorphism is the intersection nH" so if this
intersection is the unit element of G, then the map of G into its completion is
an embedding.
Theorem 10.1.
The completion and the inverse limit lim GIHrare isomorphic
under natural mappings.
Proof.
We give the maps. Let x = {x n } be a Cauchy sequence. Given r,
for all n sufficiently large, by the definition of Cauchy sequence, the class of xn
mod H; is independent of n.
Let this class be x(r) . Then the sequence
(x(l), x(2), . . .) defines an element of the inverse-limit. Conversely, given an
element (xl' X2"
. .) in the inverse limit, with xn E GIHn, let xnbe a representa-
tive in G. Then the sequence {xn } is Cauchy. We leave to the reader to verify
that the Cauchy sequence {xn } is well-defined modulo null sequences, and that
the maps we have defined are'inverse isomorphisms between the completion and
the inverse limit.
We used sequences and denumerability to make the analogy with the con-
struction of the real numbers clearer. In general, given the family !'t, by a
Cauchy family we mean a family {XjheJ indexed by an arbitrary directed set
J, such that for every HE!'t there exists j E J such that for all k, k' ~ j we
have XkXk,1 E H. In practice, one can work with sequences, because groups
that arise naturally are such that the set of subgroups of finite index is denumer-
able. This occurs when the group G is finitely generated.
More generally, a family {H;} of normal subgroups c !'t is called cofinal in
!'tif given H E!'t there exists i such that H; c H. Suppose that there exists such
a family which is denumerable; that is, i = 1, 2, . .. ranges over the positive in-
tegers. Then it is an exercise to show that there is an isomorphism
limGIH; = lim GIH,
;
HefJ

I, §11
CATEGORIES AND FUNCTORS
53
or equivalently, that the completion of G with respect to the sequence {H;} is
"the same" as the completion with respect to the full family ~
. We leave this
verification to the reader.
The process of completion is frequent in mathematics. For instance, we shall
mention completions of rings in Chapter III, §10; and in Chapter XII we shall
deal with completions of fields.
§11.
CATEGORIES AND FUNCTORS
Before proceeding further, it will now be convenient to introduce some new
terminology. We have met already several kinds of objects: sets, monoids,
groups. We shall meet many more, and for each such kind of objects we define
special kinds of maps between them (e.g. homomorphisms). Some formal
behavior will be common to all of these, namely the existence of identity maps
of an object onto itself, and the associativity of maps when such maps occur in
succession. We introduce the notion of category to give a general setting for all
of these.
A category CI consists of a collection of objects Ob(CI); and for two objects
A, BE Ob(CI) a set Mor(A, B) called the set of morphisms of A into B ; and for
three objects A, B, C E Ob(CI) a law of composition (i.e. a map)
Mor(B, C) x Mor(A, B) -. Mor(A, C)
satisfying the following axioms :
CAT 1.
Two sets Mor(A, B) and Mor(A', B') are disjoint unless A = A'
and B = B', in which case they are equal.
CAT 2.
For each object A of CI there is a morphism id, E Mor(A, A)
which acts as right and left identity for the elements of Mor(A, B) and
Mor(B, A) respectively, for all objects BE Ob(CI).
CAT 3.
The law of composition is associative (when defined), i.e. given
fE Mor(A, B), g·EMor(B, C) and h e Mor(C, D) then
(h 0 g) of = h 0 (g of),
for all objects A, B, C, D of CI.
Here we write the composition of an element g in Mor(B, C) and an element
fin Mor(A, B) as g of, to suggest composition of mappings. In practice, in this
book we shall see that most of our morphisms are actually mappings, or closely
related to mappings.
The collection of all morphisms in a category CI will be denoted by Ar(CI)
("arrows of CI "). We shall sometimes use the symbols "fe Ar(CI)" to mean

54
GROUPS
I, §11
that f is a morphism of Q, i.e. an element of some set Mor(A, B) for some
A, BEOb(Q).
By abuse of language, we sometimes refer to the collection of objects as the
category itself, if it is clear what the morphisms are meant to be.
An element j s Mor(A , B) is also writtenf:A -+ B or
A.!.B.
A morphism f is called an isomorphism if there exists a morphism g : B -+ A
such that g of and f og are the identities in Mor(A, A) and Mor(B, B) respec-
tively. If A = B, then we also say that the isomorphism is an automorphism .
A morphism of an object A into itself is called an endomorphism. The set of
endomorphisms of A is denoted by End(A). It follows at once from our axioms
that End(A) is a monoid.
Let A be an object of a category Q. We denote by Aut(A) the set of auto-
morphisms of A. This set is in fact a group, because all of our definitions are
so adjusted so as to see immediately that the group axioms are satisfied (associa-
tivity, unit element, and existence of inverse). Thus we now begin to see some
feedback between abstract categories and more concrete ones.
Examples.
Let S be the category whose objects are sets, and whose
morphisms are maps between sets. We say simply that S is the category of sets.
The three axioms CAT 1, 2, 3 are trivially satisfied.
Let Grp be the category ofgroups, i.e. the category whose objects are groups
and whose morphisms are group-homomorphisms. Here again the three axioms
are trivially satisfied. Similarly, we have a category of monoids, denoted by
Mon.
Later, when we define rings and modules, it will be clear that rings form a
category, and so do modules over a ring.
It is important to emphasize here that there are categories for which the set
of morphisms is not an abelian group . Some of the most important examples
are:
The category ev, whose objects are open sets in R n and whose morphisms
are continuous maps.
The category eoo with the same objects, but whose morphisms are the Coo
maps.
The category Hoi, whose objects are open sets in C", and whose morphisms
are holomorphic maps. In each case the axioms of a category are verified, because
for instance for Hoi, the composite of holomorphic maps is holomorphic, and
similarly for the other types of maps. Thus a CO-isomorphism is a continuous
mapf : U -
V which has a continuous inverse g: V -
U. Note that a map may
be a CO-isomorphism but not a COO-isomorphism. For instance, x ~ x 3 is a Co-
automorphism of R, but its inverse is not differentiable.
In mathematics one studies manifolds in anyone of the above categories.
The determination of the group of automorphisms in each category is one of the
basic problems of the area of mathematics concerned with that category. In

I, §11
CATEGORIES AND FUNCTORS
55
complex analysis, one determines early the group of holomorphic automorphisms
of the unit disc as the group of all maps
.
c -
z
z~e'O_-_
I -
cz
with () real and c E C, lei < 1.
Next we consider the notion of operation in categories. First, observe that
if G is a group, then the G-sets form a category, whose morphisms are the maps
f : 5 -7 5' such that f(xs) = xf(s) for x E G and s E 5.
More generally, we can now define the notion of an operation of a group G
on an object in any category. Indeed, let Q be a category and A E Ob(Q).
By an operation of G on A we shall mean a homomorphism of G into the group
Aut(A). In practice, an object A is a set with elements, and an automorphism
in Aut(A) operates on A as a set, i.e. induces a permutation of A. Thus, if we
have a homomorphism
p : G -7 Aut(A) ,
then for each x E G we have an automorphism p(x) of A which is a permutation
of A.
An operation of a group G on an object A is also called a representation of
G on A, and one then says that G is represented as a group of automorphisms
of A .
Examples.
One meets representations in many contexts. In this book, we
shall encounter representations of a group on finite-dimensional vector spaces,
with the theory pushed to some depth in Chapter XVIII. We shall also deal with
representations of a group on modules over a ring. In topology and differential
geometry, one represents groups as acting on various topological spaces, for
instance spheres. Thus if X is a differential manifold, or a topological manifold,
and G is a group , one considers all possible homomorphims of G into Aut(X),
where Aut refers to whatever category is being dealt with. Thus G may be
represented in the group of CO-automorphims, or Coo-automorphisms, or analytic
automorphisms. Such topological theories are not independent of the algebraic
theories, because by functoriality, an action of G on the manifold induces an
action on various algebraic functors (homology, K-functor, whatever), so that
topological or differential problems are to some extent analyzable by the functorial
action on the associated groups , vector spaces, or modules .
Let A, B be objects of a category Q. Let Iso(A, B) be the set of isomorphisms
of A with B. Then the group Aut(B) operates on Iso(A, B) by composition;
namely, ifu E Iso(A , B) and v E Aut(B), then (v, u) ~ v o u gives the operation.
If Uo is one element of Iso(A , B), then the orbit of Uo is all of Iso(A, B), so
v ~ v 0 Uo is a bijection Aut(B) -7 Iso(A, B) . The inverse mapping is given by
u f-+ U ° u(jl. This trivial formalism is very basic, and is applied constantly to
each one of the classical categories mentioned above. Of course, we also have

56
GROUPS
I, §11
a similar bijection on the other side, but the group Aut(A) operates on the right
of Iso(A , B) by composition. Furthermore, if u: A ~ B is an isomorphism, then
Aut(A) and Aut(B) are isomorphic under conjugation, namely
w ~ uwu- I
is an isomorphism
Aut(A) ~ Aut(B).
Two such isomorphisms differ by an inner automorphism. One may visualize
this system via the following commutative diagram.
A ----+B
u
Let p : G ~ Aut(A) and p' : G ~ Aut(A') be representations of a group G
on two objects A and A I in the same category. A morphism of p into p' is a
morphism h: A ~ A I such that the following diagram is commutative for all
x E G:
h
A ----+ A'
~X)/
/p'(X)
A ----+ A'
h
It is then clear that representations of a group G in the objects of a category (1
themselves form a category. An isomorphism of representations is then an
isomorphism h : A ~ A I making the above diagram commutative. An isomor-
phism of representations is often called an equivalence, but I don 't like to tamper
with the general system of categorical terminology. Note that if h is an isomor-
phism of representations, then instead of the above commutative diagram, we
let [h] be conjugation by h, and we may use the equivalent diagram
yAut(A)
G
P
j1h1
»:
Aut(A')
Consider next the case where a is the category of abelian groups, which we
may denote by Ab. Let A be an abelian group and G a group. Given an operation
of G on the abelian group A, i.e. a homomorphism
p : G ~ Aut(A),
let us denote by x . a the element px(a). Then we see that for all x, y E G, a,
b e A, we have:

I, §11
x . (y . a) = (xy) . a,
e
r a = a,
CATEGORIES AND FUNCTORS
57
x ·(a + b) = x·a + x -b,
x -O = o.
We observe that when a group G operates on itself by conjugation, then not
only does G operate on itself as a set but also operates on itself as an object in the
category of groups, i.e. the permutations induced by the operation are actually
group-automorphisms.
Similarly, we shall introduce later other categories (rings, modules, fields)
and we have given a general definition of what it means for a group to operate
on an object in anyone of these categories.
Let a be a category. We may take as objects of a new category e the
morphisms of a. If f :A ---. Band 1': A' ---. B' are two morphisms in a (and
thus objects of e), then we define a morphismf ---.l' (in e) to be a pair of
morphisms (<p, tj;) in a making the following diagram commutative :
A~B
~j
j~
A'----.+ B'
r
In that way, it is clear that e is a category. Strictly speaking, as with maps of
sets, we should index (<p, tj;) by f and l' (otherwise CAT 1 is not necessarily
satisfied), but such indexing is omitted in practice.
There are man y variations on this example. For instance, we could restrict
our attention to morphisms in a which have a fixed object of departure, or those
which have a fixed object of arrival.
Thus let A be an object of a, and let aA be the category whose objects are
morphisms
f: X ---. A
in a, having A as object of arrival. A morphism in aA from f: X ---. A to
g: Y ---. A is simply a morphism
h :X---.Y
in a such that the diagram is commutative:
X~Y
l\ }
Universal objects
Let e be a category. An object P of e is called universally attracting if there
exists a unique morphism of each object of e into P, and is called universally
repelling if for every object of e there exists a unique morphism of P into this
object.

58
GROUPS
I, §11
When the context makes our meaning clear, we shall call objects P as above
universal. Since a universal object P admits the identity morphism into itself,
it is clear that if P, P' are two universal objects in e, then there exists a unique
isomorphism between them.
Examples.
Note that the trivial group consisting only of one element is
universal (repelling and attracting) in the category of groups. Similarly, in
Chapter II on rings, you will see that the integers Z are universal in the category
of rings (universally repelling).
Next let S be a set. Let e be the category whose objects are mapsJ: S -. A
of S into abelian groups, and whose morphisms are the obvious ones : If
J: S -. A and J' :S -. A' are two maps into abelian groups, then a morphism
of J into J' is a (group) homomorphism 9 : A -. A' such that the usual dia-
gram is commutative, namely go J =J'. Then the free abelian group generated
by S is universal in this category. This is a reformulation of the properties we
have proved about this group.
Let M be a commutative monoid and let y : M ~ K(M) be the canonical
homomorphism of M into its Grothendieck group. Then y is universal in the
category of homomorphisms of M into abelian groups.
Throughout this book in numerous situations, we define universal objects.
Aside from products and coproducts which come immediately after these exam-
ples, we have direct and inverse limits; the tensor,product in Chapter XVI, §1;
the alternating product in Chapter XIX, §1; Clifford algebras in Chapter XIX,
§4; ad lib.
We now turn to the notion of product in an arbitrary category .
Products and coproducts
Let a be a category and let A, B be objects of a. By a product of A, B in a
one means a triple (P,f, g) consisting of an object P in a and two morphisms
P
/~
A
B
satisfying the following condition : Given two morphisms
qJ: C -. A
and
t/J : C -. B
in a, there exists a unique morphism h: C -. P which makes the following
diagram commutative:
In other words, qJ = Jo hand t/J = g oh.

I, §11
CATEGORIES AND FUNCTORS
59
More generally, given a family of objects {AiLEl in <1, a product for this
family consists of (P, {};Ll), where P is an object in
<1 and {};};El is a
family of morphisms
satisfying the following condition: Given a family of morphisms
there exists a unique morphism h : C -. P such that}; 0 h = gi for all i.
Example.
Let <1 be the category of sets, and let {AJiEI be a family of sets.
Let A = flAi be their cartesian product, and let Pi: A -
Ai be the projection
iEI
on the i -th factor. Then (A , {pJ) clearly satisfies the requirements of a product
in the category of sets .
As a matter of notation, we shall usually write A x B for the product of two
objects in a category, and n Ai for the product of an arbitrary family in a
iEI
category, following the same notation as in the category of sets.
Example.
Let {G;}iEI be afamity of groups, and let G = fl G; be their direct
product . Let Pi: G -
G, be the projection homomorphism. Then these constitute
a product of the family in the category of groups.
Indeed, if {gi:G' -. GJ iEl is a family of homomorphisms, there is a unique
homomorphism 9 : G' -. n G,which makes the required diagram commutative.
It is the homomorphism such that g(x'); = g;(x') for x' E G' and each i E I,
Let A, B be objects of a category <1. We note that the product of A, B is
universal
in the
category whose objects consist of pairs of morphisms
f : C -
A and g : C -
B in a, and whose morphisms are described as follows .
Let l' : C' -
A and g' : C' -
B be another pair. Then a morphism from the
first pair to the second is a morphism h: C -
C' in a, making the following
diagram commutative:
C
/l~
A...-r ---g:- B
The situation is similar for the product of a family {AJiEi'
We shall also meet the dual notion: Let {AJ iEI be a family of objects in a
category a.
By their coproduct one means a pair (5, {f;};El) consisting of an
object S and a family of morphisms
{};: Ai -. S},
satisfying the following property. Given a family of morphisms {gi: A;-. C},
there exists a unique morphism h : S -. C such that h 0 j; = gi for all i.

60
GROUPS
I, §11
In the product and coproduct, the morphism h will be said to be the
morphism induced by the family {gJ .
Examples.
Let S be the category of sets. Then coproducts exist, i.e. every
family of objects has a coproduct. For instance, let S, S' be sets. Let T be
a set having the same cardinality as S' and disjoint from S. Let ii : S -4 S
be the identity, and fi : S' -4 T be a bijection. Let U be the union of Sand
T. Then (U,J\,fi) is a coproduct for S, S' , viewingii, fi as maps into U.
Let So be the category of pointed sets. Its objects consist of pairs (S,x)
where S is a set and x is an element of S. A morphism of (S, x) into (S', x') in this
category is a map g : S -. S' such that g(x) = x'. Then the coproduct of (S, x)
and (S', x') exists in this category, and can be constructed as follows. Let T be
a set whose cardinality is the same as that of S', and such that T n S = [x].
Let V = S U T, and let
fl : (S, x) -. (V, x)
be the map which induces the identity on S. Let
12: (S', x') -. (U, x)
be a map sending x' to x and inducing a bijection of S' -
{x'} on T -
{x} .
Then the triple «V, x),f\,h) is a coproduct for (S, x) and (S', x') in the category
of pointed sets.
Similar constructions can be made for the coproduct of arbitrary families
of sets or pointed sets. The category of pointed sets is especially important in
homotopy theory.
Coproducts are universal objects. Indeed, let a be a category, and let {A;}
be a family of objects in a. We now definee. We let objects of e be the families
of morphisms {fi: A; -
Bhel and given two such families,
{};: Ai -. B}
and
U; :Ai -. B'},
wedefine a morphism from the first into the second to be a morphism qJ : B -. B'
in a such that qJo}; = f; for all i. Then a coproduct of {Ai} is simply a universal
object in e.
The coproduct of {A;} will be denoted by
UA i •
iel
The coproduct of two objects A, B will also be denoted by A II B.
By the general uniqueness statement, we see that it is uniquely determined, up
to a unique isomorphism. See the comment, top of p. 58.
Example.
Let R be the category of commutative rings. Given two such
rings A, B one may form the tensor product, and there are natural ring-homo-
morphisms A -
A ® Band B -
A ® B such that
a ~ a ® I and b ~ 1 ® b for a E A and b E B.
Then the tensor product is a coproduct in the category of commutative rings.

I, §11
CATEGORIES AND FUNCTORS
61
Fiber products and coproducts
Pull-backs and push-outs
Let e be a category. Let Z be an object of e. Then we have a new category,
that of objects over Z, denoted by ez. The objects of ez are morphisms:
f : X --+ Z in e
A morphism from f to 9 : Y --+ Z in ez is merely a morphism h : X --+ Y in e
which makes the following diagram commutative.
X~Y
\1
Z
A product in ez is called the fiber product of f and g in e and is denoted
by X x zY, together with its natural morphisms on X, Y over Z, which are
sometimes not denoted by anything, but which we denote by PI ' P2'
X
X z Y
7 ~
X
Y
~/
Z
Fibered products and coproducts exist in' the category ofabelian groups
The fibered product of two homomorphismsf : X ~ Z and g : Y ~ Z is the
subgroup of X x Y consisting of all pairs (x , y) such that
f(x) = g(y).
The coproduct of two homomorphisms f :Z --+ X and g : Z --+ Y is the
factor group (X EB Y)/W where W is the subgroup of X EB Y consisting of all
elements (f(z), -g(z)) with z E Z.
We leave the simple verification to the reader (see Exercises 50-56).
In the fiber product diagram, one also calls PI the pull.back of g byf , and
P2 the pull-back of f by g . The fiber product satisfies the following universal
mapping property:
Given any object T in e and morphisms making the following diagram
commutative:

62
GROUPS
I, §11
there exists a unique morphism T ~ X X Z Y making the following diagram
commutative:
)1\
x __ T---.y
Dually, we have the notion ofcoproduct in the category ofmorphismsj: Z -+ X
with a fixed object Z as the object of departure of the morphisms. This category
could be denoted by ez. We reverse the arrows in the preceding discussion.
Given two objects j and g: Z -+ Y in this category, we have the notion of their
coproduct. It is denoted by X liz Y, with morphisms ql' q2' as in the following
commutative diagram:
satisfying the dual universal property of the fiber product. We call it the fibered
coproduct. We call ql the push-out of g by f, and q2 the push-out off by g.
Example.
Let S be the category of sets. Given two maps j, 9 as above,
their product is the set of all pairs (x, y) E X X Y such thatf(x) = g(y).
Functors
Let (1, <B be categories. A covariant functor F of (1 into <B is a rule which
to each object A in (1 associates an object F(A) in <B, and to each morphism
j: A -+ B associates a morphism F(f) : F(A) -+ F(B) such that :
FUN 1.
For all A in (1 we have F(id A) = idF(A)'
FUN 2.
Ifj :A -+ Band g : B -+ C are two morphisms of (1 then
F(g of) = F(g) 0 F(f).
Example .
If to each group G we associate its set (stripped of the group
structure) we obtain a functor from the category of groups into the category of
sets, provided that we associate with each group-homomorphism itself, viewed
only as a set-theoretic map. Such a functor is called a stripping functor or
forgetful functor.
We observe that a functor transforms isomorphisms into isomorphisms,
because j og = id implies F(f) 0 F(g) = id also.
We can define the not ion of a contravariant functor from (1 into <B by using
essentially the same definition, but reversing all arrows F(!), i.e. to each morph-
ism f : A -+ B the contravariant functor associates a morphism

I, §11
CATEGORIES AND FUNCTORS
63
F(f) : F(B) -+ F(A)
(going in the opposite direction), such that, if
f :A -+ Band
9 : B -+ C
are morphisms in <1, then
F(g of) = F(f)
0 F(g).
Sometimes a functor is denoted by writing f* instead of F(f) in the case
of a covariant functor, and by writing f* in the case of a contravariant
functor.
Example.
The association S ~ Fab(S) is a covariant functor from the
category of sets to the category of abelian groups.
Example.
The association which to each group associates its completion
with respect to the family of subgroups of finite index is a functor from the
category of groups to the category of groups.
Example.
Let p be a prime number. Let e be the category of p-divisible
abelian groups. The association A ~ Tp(A) is a covariant functor of e into
abelian groups (actually Zp-modules) .
Example .
Exerc ise 49 will show you an example of the group of auto-
morphisms of a forgetful functor.
Example.
Let Man be the category of compact manifolds. Then the homol-
ogy is a covariant functor from Man into graded abelian groups. The cohomology
is a contravariant functor into the category of graded algebras (over the ring of
coeffic ients). The product is the cup product. If the cohomology is taken with
coefficients in a field of characteristic 0 (for simpl icity), then the cohomology
commutes with products. Since cohomology is contravariant, this means that the
cohomology of a product is the coproduct of the cohomology of the factors . It
turns out that the coproduct is the tensor product, with the graded product, which
also gives an example of the use of tensor products. See M. GREENBERG and
J. HARPER , Algebraic Topology (Benjamin-Addison-Wesley) , 1981, Chapter 29.
Example.
Let e be the category of pointed topological spaces (satisfying
some mild conditions), i.e. pairs (X, xo) consisting of a space X and a point xo.
In topology one defines the connected sum of such spaces (X, xo) and (Y, Yo),
glueing X, Y together at the selected point. This connected sum is a coproduct
in the category of such pairs, where the morphisms are the continuous maps
f : X ~ Y such that f(xo) = Yo. Let
7T( denote the fundamental group. Then
(X, xo) ~ 7Tl(X, xo) is a covariant functor from e into the category of groups,
commuting with coproducts. (The existence of coproducts in the category of
groups will be proved in §12.)

64
GROUPS
I, §11
Example.
Suppose we have a morphismj: X ~ Y in a category e. By a
section of j , one means a morphism g: Y ~ X such that 9
0 j = id. Suppose
there exists a covariant functor H from this category to groups such that
H(Y) = {e} and H(X) '* {e}. Then there is no section of f. This is immediate
from the formula H(g 0 f) = id, and H(f) = trivial homomorphism. In topology
one uses the homology functor to show, for instance , that the unit circle X is
not a retract of the closed unit disc with respect to the inclusion mapping f.
(Topologists use the word "retract" instead of "section".)
Example.
Let <tbe a category and A a fixed object in <to Then we obtain a
covariant functor
MA :<t--+S
by letting MA(X) = Mor(A , X) for any object X of <to If qJ: X --+ X' is a mor-
phism, we let
MA(qJ): Mor(A, X) --+ Mor(A, X')
be the map given by the rule
for any 9 E Mor(A, X),
A ~X~X' .
The axioms FUN 1 and FUN 2 are trivially verified.
Similarly, for each object B of <t, we have a contravariant functor
M B : (1 --+ S
such that MB(Y) = Mor(Y, B). If ljJ: Y' --+ Y is a morphism, then
MB(ljJ) : Mor( Y, B) --+ Mor( y', B)
is the map given by the rule
for any jE Mor(Y, B),
Y' s: Y 1. B.
The preceding two functors are called the representation functors.
Example.
Let <t be the category of abelian groups. Fix an abelian group
A. The association X ~ Hom(A , X) is a covariant functor from <t into itself.
The association X ~ Hom(X, A) is a contravariant functor of <t into itself.
Example.
We assume you know about the tensor product. Let A be a
commutative ring. Let M be an A-module . The association X ~ M 0 X is a
covariant functor from the category of A-modules into itself.
Observe that products and coproducts were defined in a way compatible with
the representation functor into the category of sets . Indeed , given a product P

I, §11
CATEGOR IES AND FUNCTORS
65
of two objects A and B , then for every object X the set Mor(X, P) is a produ ct
of the sets Mor(X, A) and Mor(X, B ) in the category of sets. This is merely a
reformulation of the defining property of products in arbitrary cate gories. The
system really works.
Let (1, (B be two categories. The functors of (1 into (B (say covariant, and
in one variable) can be viewed as the objects of a category, whose morphisms
are defined as follows. Let L, M be two such functors. A morphism H : L -. M
(also called a natural transformation) is a rule which to each object X of (1
associates a morphism
H x:L(X) -. M(X)
such that for any morphism f: X -. Y the following diagram is commutative :
L(X)~M(X)
WIl
lWI
L( Y) -------.M ( Y)
By
We can therefore speak of isomorphisms of functors. A functor is representable
if it is isomorphic to a representation functor as above.
As Grothendieck pointed out, one can use the representation functor to
transport the notions of certain structures on sets to arbitrary categories. For
instance, let (1 be a category and G an object of (1. We say that G is a group
object in (1 if for each object X of (1 we are given a group structure on the set
Mor(X, G) in such a way that the association
X f--+ Mor(X, G)
is functorial (i.e. is a functor from (1 into the category of groups). One some-
times denotes the set Mor(X, G) by G(X), and thinks of it as the set of points of
G in X . To justify this terminology, the reader is referred to Chapter IX, §2.
Example.
Let Var be the category of projective non-singular varieties over
the complex numbers. To each object X in Var one can associate various groups,
e.g. Pic(X) (the group of divisor classes for rational equivalence), which is a
contravariant functor into the category of abelian groups. Let Pico(X) be the
subgroup of classes algebraically equivalent to O. Then Pic., is representable.
In the fifties and sixties Grothendieck was the one who emphasized the
importance of the representation functors, and the possibility of transposing to
any category notions from more standard categories by meansofthe representation
functors. He himself proved that a number of important functors in algebraic
geometry are representable.

66
GROUPS
§12.
FREE GROUPS
I, §12
We now turn to the coproduct in the category of groups. First a remark. Let
G = II G; be a direct product of groups .
We observe that each G, admits an injective homomorphism into the
product, on the j-th component, namely the map
)'j : Gj -. n G; such that
;
for x in Gj , the i-th component of A/ x) is the unit element of G; if i i=i. and
is equal to x itself if i = j. This embedding will be called the canonical one .
But we still don't have a coproduct of the family, because the factors commute
with each other. To get a coproduct one has to work somewhat harder.
Let G be a group and S a subset of G. We recall that G is generated by S
ifevery element of G can be written as a finite product of elements of S and their
inverses (the empty product being always taken as the unit element of G).
Elements of S are then called generators. If there exists a finite set of generators
for G we call G finitely generated. If S is a set and cp :S -. G is a map, we say
that cp generates G if its image generates G.
Let S be a set, and f :S -+ F a map into a group. Let 9 : S -+ G be another
map. Iff(S) (or as we also say,!) generates F, then it is obvious that there exists
at most one homomorphism t/J of F into G which makes the following diagram
commutative:
\)
G
We now consider the category e whose objects are the maps of S into
groups. Iff:S -+ G and l' :S -+ G' are two objects in this category, we define
a morphism fromftol' to be a homomorphism tp : G -+ G/such that cp 0 f =1',
i.e. the diagram is commutative:
G
s7)'I'
<.
G'
By a free group determined by S, we shall mean a universal element in this
category.
Proposition 12.1.
Let S be a set. Then there exists a free group (F, f)
determined by S. Furthermore . f is injective. and F is generated by the image
off.
Proof
(lowe this proof to J. Tits.) We begin with a lemma.

I, §12
FREE GROUPS
67
Lemma 12.2.
There exists a set I and a family of groups {GJiEl such that,
if g : S ~ G is a map of S into a group G, and 9 generates G, then G is
isomorphic to some Gi .
Proof
This is a simple exercise in cardinalities, which we carry out. If 5
is finite, then G is finite or denumerable. If5 is infinite, then the cardinality of G
is ~ the cardinality of 5 because G consists of finite products of elements of g(5).
Let T be a set which is infinite denumerable if5 isfinite, and has the same cardin-
ality as 5 if 5 is infinite. For each non-empty subset H of T, let r H be the set of
group structures on H. For each y E r H, let H y be the set H, together with the
group structure y. Then the family {Hy} for y E r Hand H ranging over subsets
of T is the desired family.
We return to the proof of the proposition. For each i E I we let M, be the
set of mappings of 5 into Gj. For each map cp E Mi, we let Gi,'i' be the set-
theoretic product of G, and the set with one element {e}, so that Gi,'i' is the
"same" group as Gi indexed by cp. We let
r; = Il Il c.;
jEI'i'EM;
be the Cartesian product of the groups Gi,'i"
We define a map
I«: 5 --+ F 0
by sending 5 on the factor Gi,'i' by means of cp itself. We contend that given a
map g : S ~ G of S into a group G, there exists a homomorphism "'*: F0 ~ G
making the usual diagram commutative:
Fo
7]
S
"'.
~
G
That is, "'*
0 fo = g. To prove this, we may assume that 9 generates G, simply
by restricting our attention to the subgroup of G generated by the image of g.
By the lemma, there exists an isomorphism A. :G --+ G, for some i, and
A. 0 9
is an element IjJ of M j • We let 1ri.'" be the projection on the (i, 1jJ) factor, and we
let IjJ* = A.- 1 0 1ri. ",. Then the map
IjJ* makes the following diagram com-
mutative.
We let F be the subgroup of F0 generated by the image offo, and we letf
simply be equal to fo , viewed as a map of 5 into F. We let g* be the restriction
ofljJ* to F. In this way, we see at once that the map g* is the unique one making

68
GROUPS
I, §12
our diagram commutative, and thus that (F,j) is the required free group.
Furthermore, it is clear thatfis injective.
For each set S we select one free group determined by S, and denote it
by (F(S),fs) or briefly by F(S). It is generated by the image of fs. One may
view S as contained in F(S), and the elements of S are called free generators
of F(S). Ifg :S --+ G is a map, we denote by g*: F(S) --+ G the homomorphism
realizing the universality of our free group F(S).
If A:S --+ S' is a map of one set into another, we let F(A) :F(S) --+ F(S') be
the map Us' 0 A)* .
S~F(S)
,j~ j.. ~F("
S'~F(S ')
Is'
Then we may regard F as a functor from the category of sets to the category of
groups (the functorial properties are trivially verified, and will be left to the
reader).
If A is surjective, then F(A) is also surjective.
We again leave the proof to the reader.
If two sets S, S' have the same cardinality, then they are isomorphic in the
category of sets (an isomorphism being in this case a bijection !), and hence
F(S) is isomorphic to F(S'). If S has n elements, we call F(S) the free group
on n generators.
Let G be a group, and let S be the same set as G(i.e. G viewed as a set, without
group structure). We have the identity map 9 : S --+ G, and hence a surjective
homomorphism
g* : F(S) --+ G
which will be called canonical. Thus every group is a factor group of a free
group.
One can also construct groups by what is called generators and relations. Let
S be a set, and F(S) the free group.
We assume that f :S --+ F(S) is an in-
clusion. Let R be a set of elements of F(S). Each element of R can be written
as a finite product
nIl x,
v = 1
where each x, is an element of S or an inverse of an element of S. Let N be the
smallest normal subgroup of F(S) containing R, i.e. the intersection of all normal
subgroups of F(S) containing R. Then F(S)/N will be called the group deter-
mined by the generators S and the relations R.

I, §12
FREE GROUPS
69
Example.
One shows easily that the group determined by one generator
a, and the relation {a2 } , has order 2.
The canonical homomorphism tp : F(S) ~ F(S)/ N satisfies the universal map-
ping property for homomorphisms t/J of F(S) into groups G such that t/J(x) = e
for all x E R. In view of this, one sometimes calls the group F(S)/N the group
determined by the generators S, and the relations x = e (for all x E R) . For
instance, the group in the preceding example would be called the group determined
by the generator a, and the relation a2 = e.
Let G be a group generated by a finite number of elements, and satisfying
the relation x 2 = e for all x E G. What does G look like? It is easy to show that
G is commutative. Then one can view G as a vector space over Z/2Z, so G is
determined by its cardinality, up to isomorphism.
In Exercises 34 and 35, you will prove that there exist certain groups satisfying
certain relations and with a given order, so that the group presented with these
generators and relations can be completely determined. A priori , it is not even
clear if a group given by generators and relations is finite . Even if it is finite ,
one does not know its order a priori. To show that a group of certain order
exists, one has to use variou s means , a common means being to represent the
group as a group of automorphisms of some object, for instance the symmetries
of a geometric object. This will be the method suggested forthe groups in Exercises
34 and 35, mentioned above.
Example.
Let G be a group . For x , y E G define [x , y] = xyx- 1y- l (the
commutator) and xy = xyx- t (the conjugate) . Then one has the cocycle relation
[x , yz] = [x , y]y [x , z].
Furthermore, suppose x, y, Z E G and
[x , y] = y,
[y , z] = z,
[z, x] = x.
Then x = y = z = e. It is an exercise to prove these assertions, but one sees
that certain relations imply that a group generated by x , y , z subject to those
relations is necessarily trivial.
Next we give a somewhat more sophisticated example. We assume that the
reader knows the basic terminology of fields and matrices as in Chapter XIII,
but applied only to 2 x 2 matrices. Thus SL2(F) denotes the group of 2 x 2
matri ces with components in a field F and determinant equal to 1.
Example. SL2(F). Let F be a field. For b E F and a E F , a '* 0, we let
U(b)=(~
~) ,
s(a) = (~
~-l)'
and W=(_~
~) .

70
GROUPS
Then it is immediately verified that:
SL O. s( a) = wu(a-1)wu(a)wu(a - I ) .
SL 1. u is an additive homomorphism.
SL 2. s is a multiplicative homomorphism.
SL 3. wZ = s( - I) .
SL 4. s( a)u(b)s(a- 1) = u(baz).
I, §12
Now , conversely, suppose that G is an arbitrary group with generators u(b)
(b E F ) and w, such that if we define s(a) for a*'O by SL 0, then the relations
SL 1 through SL 4 are satisfied. Then SL 3 and SL 4 show that s(-I ) is in the
center, and w4 = e. In addition, one verifies that:
SL 5. ws(a) = s(a- 1)w.
Furthermore, one has the theorem:
Let G be the free group with generators u(b), wand relations SL 1 through
SL 4, defining s(a) as in SL O. Then the natural homomorphism
G ~ SLz(F)
is an isomorphism.
Proofs of all the above statements will be found in my SL2(R), Springer Verlag,
reprint of Addison-Wesley, 1975, Chapter XI, §2. It takes about a page to carry
out the proof.
If F = Qp is the field of p-adic numbers, then Ihara [lh 66] proved that every
discrete torsion free subgroup of SLz(Qp) is free . Serre put this theorem in the
context of a general theory concerning groups acting on trees [Se 80].
[Ih 66]
Y. IHARA, On discrete subgroups of the two by two projective linear group over
p-adic fields, J . Math . Soc. Japan 18 (1966) pp. 219- 235
[Se 80]
J.-P. SERRE, Trees, Springer Verlag 1980
Further examples.
For further examples of free group constructions, see
Exercises 54 and 56. For examples of free groups occurring (possibly conjec-
turally) in Galois theory, see Chapter VI, §2, Example 9, and the end of
Chapter VI, §14.
Proposition 12.3.
Coproducts exist in the category of groups.
Proof
Let {GJi EI be a family of groups. We let e be the category whose
objects are families of group-homomorphisms
{gi: o, -+ GL EI

I, §12
FREE GROUPS
71
and whose morphisms are the obvious ones. We must find a universal element
in this category. For each index i, we let S, be the same set as Gi if Gj is infinite,
and we let S, be denumerable if Gi is finite. We let S be a set having the same
cardinality as the set-theoretic disjoint union of the sets S,(i.e. their coproduct
in the category of sets). We let r be the set of group structures on S, and for
each y E r, we let <l>ybe the set of all families of homomorphisms
Each pair (Sy, cp), where cp E <l>y, is then a group, using cp merely as an index.
We let
F 0 = TI TI (Sy, cp),
y e r
q>e4!l y
and for each i, we define a homomorphism L: G, --+ F 0 by prescribing the
component of j; on each factor (Sy, cp) to be the same as that of cp;.
Let now 9 = {gi :Gi --+ G} be a family of homomorphisms. Replacing G
if necessary by the subgroup generated by the images of the gi, we see that
card(G) ~ card(S), because each element of G is a fin ite product of elements
in these images . Embedding G as a factor in a product G x Soy for some 'Y, we
may assume that card(G) = card(S). There exists a homomorphism g.: Fa --+ G
such that
for all i. Indeed, we may assume without loss of generality that G = S, for some
y and that 9 = t/J for some t/J E <l>y. We let g. be the projection of F0 on the
factor (Sy, t/J).
Let F be the subgroup of F 0 generated by the union of the images of
the maps j; for all i. The restriction of g. to F is the unique homomorphism
satisfying j;
0 g. = gj for all i, and we have thus constructed our universal
object.
Example.
Let Gz be a cyclic group of order 2 and let G3 be a cyclic group
of order 3. What is the coproduct? The answer is neat. It can be shown that
Gz U G3 is the group generated by two elements S, T with relations SZ = 1,
(Sn3 = 1. The groups Gz and G3 are embedded in Gz U G3 by sending Gz on
the cyclic group generated by S and sending G3 on the cyclic group generated
by ST. The group can be represented as follows. Let

72
GROUPS
I, §12
As we have seen in an example of §5, the group G operates on the upper half-
plane S). Let S, T be the maps given by
S(z) = -liz
and
T(z) = z + 1.
Thus Sand T are represented by the matrices
S = (~
-~)
and
T = (~
~) ,
and satisfy the relations S2 = 1, (Sn3 = 1. Readers will find a proof of several
properties of S, Tin Serre's Course in Arithmetic (Springer Verlag, 1973, Chapter
VII, §1), including the fact that S, T generate G. It is an exercise from there to
show that G is the coproduct of G2 and G3 as asserted.
Observe that these procedures go directly from the universal definition and
construction in the proofs of Proposition 12.1 and Proposition 12.3 to the more
explicit representation of the free group or the coproduct as the case may be.
One relies on the following proposition.
Proposition 12.4.
Let G be a group and {GJiEI a family of subgroups.
Assume:
(a) Thefamily generates G.
(b) If
x = XiI • • • Xin
with Xiv E Giv, Xiv *' e and i; *' iv+1for all v,
then X*' e.
Then the natural homomorphism of the coproduct of the family into G sending
G, on itself by the identity mapping is an isomorphism. In other words. simply
put , G is the coproduct of the family of subgroups.
Proof.
The homomorphism from the coproduct into G is surjective by the
assumption that the family generates G. Suppose an element is in the kernel.
Then such an element has a representation
X·
• •• X ·
11
'n
as in (b), mapping to the identity in G, so all Xiv = e and the element itself is
equal to e, whence the homomorphism from the coproduct into G is injective,
thereby proving the proposition.
Exercises 54 and 56 mentioned above give one illustration of the way Prop-
osition 12.4 can be used. We now show another way, which we carry out for
two subgroups. I am indebted to Eilenberg for the neat arrangement of the proof
of the next proposition.

I, §12
FREE GROUPS
73
Proposition 12.5.
Let A, B be two groups whose set-theoreticintersectionis
{I} . There exists a group A
0 B containing A, B as subgroups. such that
A n B = {I}, and having thefollowing property. Every element* I ofA
0 B
has a unique expression as a product
(n ~ I, aj =I 1 all i)
with a, E A or a, E B, and such that if a, E A then aj+ 1 E B and if ajE B then
aj+l EA .
Proof
Let A 0 B be the set of sequences
(n ~ 0)
such that either n = 0, and the sequence is empty or n ~ 1, and then elements
in the sequence belong to A or B, are =I 1,and two consecutive elements of the
sequence do not belong both to A or both to B. If b = (b1, . . . , bm), we define
the product ab to be the sequence
(a1, · · ·, an , b1,·· ·, bm)
if
anEA,b1EB
or
anEB,b1EA,
(ai' .. . , anbl , · · · , bm)
if
an,b, E A
or
an,b, E B,
and
a.b, =I 1,
(aI' .. . , an- 1)(b 2 , . .. , bm)
by induction,
if
an, b, E A
or
an,», E Band
a.b, = 1.
The case when n = 0 or m = 0 is included in the first case, and the empty
sequence is the unit element of A
0 B. Clearly,
(a l , •• • , an)(a;; 1, . .. , all) = unit element,
so only associativity need be proved. Let c = (c., .. . , c.),
First consider the case m = 0, i.e. b is empty. Then clearly (ab)c = a(bc)
and similarly if n = 0 or r = O. Next consider the case m = 1. Let b = (x)
with x E A, x =I 1. We then verify in each possible case that (ab)c = a(bc).
These cases are as follows:
(a1,· · ·, an' x, Clo . . . , c.)
if
anEB
and
CI EB,
(al" '" anx, c l , · · · , c.)
if
an E A, anx =I 1, C1 E B,
(alo " " an, XC1' ... , c.)
if
an E B, Cl E A, xC1=I I,
(a1,· ··, an- 1)(Clo ""
c.)
if
an = x - 1
and
C1 E B,

74
GROUPS
- I
CI = X
,
I, §12
if
an,c1EA,anxc l =f. 1,
if
an' CI E A
and
anxc 1 = 1.
If m > 1, then we proceed by induction. Write b = b'b" with b' and b"
shorter. Then
(ab)c = (a(b'b"))c = «ab')b")c = (ab')(b"c),
a(bc) = a«b'b")c) = a(b'(b"c)) = (ab')(b"c)
as was to be shown.
We have obvious injections of A and B into A
0 B, and identifying A , B
with their images in A
0 B we obtain a proof of our proposition.
We can prove the similar result for several factors. In particular, we get the
following corollary for the free group.
Corollary 12.6.
Let F(S) be the free group on a set S, and let XI>
, Xn be
distinct elements of S. Let VI"
. • , v, be integers "* 0 and let ii'
, i, be
integers,
1 ~ i. . . . . , i, ~ n
such that ij =f. ij + 1 for j = 1,. . . , r -
1. Then
Proof
Let G1, • . . , Gn be the cyclic groups generated by XI> . . . , X n. Let
G = G1 0
• • • 0 Gn' Let
F(S) --+ G
be the homomorphism sending each Xi on X;, and all other elements of S on the
unit element of G. Our assertion follows at once.
Corollary 12.7.
Let S be a set with n elements Xl' . . . , Xn, n ~ 1. Let G1,
. . . , Gn be the infinite cyclic groups generated by these elements. Then the map
F(S) --+ G1 0
"
• 0 Gn
sending each Xi on itself is an isomorphism.
Proof
It is obviously surjective and injective.
Corollary 12.8.
Let G\, . .. , G; be groups with G; n G, = {I} if i "* i.
The homomorphism
G1 U . . . U G, --+ G1 0
· · · 0 G;
of their
coproduct
into
G1 0
'
"
0 G; induced
by
the
natural inclusion
Gj --+ G1 0 ••• 0 Gnis an isomorphism.
Proof
Again, it is obviously injective and surjective.

I, Ex
EXERCISES
EXERCISES
75
I. Show that every group of order ~ 5 is abelian .
2. Show that there are two non-isomorphic groups of order 4, namely the cyclic one,
and the product of two cyclic groups of order 2.
3. Let G be a group . A commutator in G is an element of the form aba-1b-1 with a,
bEG. Let GCbe the subgroup generated by the commutators. Then GC is called the
commutator subgroup. Show that GCis normal. Show that any homomorphism of
G into an abelian group factors through G/G c.
4. Let H , K be subgroups of a finite group G with K C NH . Show that
#(H)#(K)
#(HK) = #(H n K) .
5. Goursat'sLemma.
Let G, G' be groups,and let Hbea subgroupofG x G' such that the
two projections PI : H ...... G and pz :H ...... G' are surjective. Let N be the kernel of P2
and N' be the kernel of PI' One can identify N as a normal subgroup of G,and N' as a
normal subgroup of G'. Show that the image of H in G/N x G'/N ' is the graph of an
isomorphism
G/N ~ G'/N'.
6. Prove that the group of inner automorphisms of a group G is normal in Aut(G).
7. Let G be a group such that Aut(G) is cyclic. Prove that G is abelian.
8. Let G be a group and let H, H ' be subgroups . By a double coset of H , H' one means
a subset of G of the form HxH' .
(a) Show that G is a disjoint union of double cosets.
(b) Let {c} be a family of representatives for the double cosets . For each
a E G denote by [a]H' the conjugate all'a-I of H' . For each c we have a
decomposition into ordinary cosets
H = U xc(H n [c]H'),
C
where {xc} is a family of elements of H, depending on c. Show that the
elements {x,c} form a family of left coset representatives for H ' in G; that
is,
and the union is disjoint. (Double cosets will not emerge further until Chapter
XVIII.)
9. (a) Let G be a group and H a subgroup of finite index . Show that there exists a
normal subgroup N of G contained in H and also of finite index . [Hint: If
(G : H) = n, find a homomorphism of G into Sn whose kernel is contained in
H.]
(b) Let G be a group and let HI' H 2 be subgroups of finite index . Prove that
HI n Hz has finite index.
10. Let G be a group and let H be a subgroup of finite index . Prove that there is only a
finite number of right cosets of H, and that the number of right cosets is equal to the
number of left cosets.

76
GROUPS
I, Ex
II. Let G be a group, and A a normal abelian subgroup. Show that GIA operates on A
by conjugation , and in this manner get a homomorphism of GIA into Aut(A).
Semidirect product
12. Let G be a group and let H, N be subgroups with N normal. Let 'Yx be conjugation
by an element x E G.
(a) Show that x ~ 'Yx induces a homomorphism j": H ~ Aut(N).
(b) If H n N = {e}, show that the map H X N -
HN given by (x, y) ~ xy is
a bijection, and that this map is an isomorphism if and only if! is trivial,
i.e. !(x) = idN for all.x E H .
We define G to be the semidirect product of Hand N if G = NH and H n N = {e}.
(c) Conversely, let N, H be groups, and let t/J : H -
Aut(N) be a given homo-
morphism. Construct a semidirect product as follows. Let G be the set of
pairs (x, h) with x E Nand h E H . Define the composition law
(xl,ht)(X2,h2) = (xlt/J(ht}X2,hlh2)'
Show that this is a group law, and yields a semidirect product of Nand H,
identifying N with the set of elements (x, 1) and H with the set of elements
(l, h).
13. (a) Let H, N be normal subgroups of a finite group G. Assume that the orders of H,
N are relatively prime. Prove that xy = yx for all x E Hand yEN, and that
H X N""'HN.
(b) Let HI' . .. , H; be normal subgroups of G such that the order of Hi is relatively
prime to the order of Hj for i *" j . Prove that
HI x . . . x H, "'" HI ... Hr.
Example.
If the Sylow subgroups of a finite group are normal, then G is the
direct product of its Sylow subgroups.
14. Let G be a finite group and let N be a normal subgroup such that N and GIN have
relatively prime orders.
(a) Let H be a subgroup of G having the same order as GIN. Prove that
G = HN.
(b) Let g be an automorphism of G. Prove that g(N) = N .
Some operations
15. Let G be a finite group operating on a finite set S with #(S) ~ 2. Assume that there
is only one orbit. Prove that there exists an element x E G which has no fixed point,
i.e. xs *" s for all s E S.
16. Let H be a proper subgroup of a finite group G. Show that G is not the union of all
the conjugates of H . (But see Exercise 23 of Chapter XIII.)
17. Let X, Y be finite sets and let C be a subset of X x Y. For x E X let rp(x) = number
of elements y E Y such that (x, y) E C. Verify that
#(C) = 2: rp(x).
xe X

I, Ex
EXERCISES
77
Remark .
A subset C as in the above exercise is often called a correspondence, and
q/(x) is the number of elements in Y which correspond to a given element x E X.
18. Let S, T be finite sets. Show that # Map(S, T) = (#T)#(S) .
19. Let G be a finite group operating on a finite set S.
(a) For each s E S show that
L_I _
=
1.
(EGs#(Gt)
(b) For each x E G define f(x) = number of elements S E S such that xs = s.
Prove that the number of orbits of G in S is equal to
Throughout, p is a prime number.
20. Let P be a p-group. Let A be a normal subgroup of order p . Prove that A is contained
in the center of P.
21. Let G be a finite group and H a subgroup. Let PH be a p-Sylow subgroup of H. Prove
that there exists a p-Sylow subgroup P of G such that PH = P n H.
22. Let H be a normal subgroup of a finite group G and assume that #(H) = p. Prove
that H is contained in every p-Sylow subgroup of G.
23. Let P, P' be p-Sylow subgroups of a finite group G.
(a) If P ' C N(P) (normalizer of P), then P' = P .
(b) If N(P') = N(P) , then P' = P .
(c) We have N(N(P»
= N(P) .
Explicit determination of groups
24. Let p be a prime number. Show that a group of order p2 is abelian, and that there are
only two such groups up to isomorphism.
25. Let G be a group of order p3, where p is prime, and G is not abelian. Let Z be its center.
Let C be a cyclic group of order p.
(a) Show that Z ::::: C and G/Z ::::: C x C.
(b) Every subgroup of G of order p2 contains Z and is normal.
(c) Suppose x" = I for all x E G. Show that G contains a normal subgroup
H:::::C xC.
26. (a) Let G be a group of order pq , where p, q are primes and p < q. Assume that
q '4= I mod p. Prove that G is cyclic .
(b) Show that every group of order 15 is cyclic .
27. Show that every group of order < 60 is solvable.
28. Let p, q be distinct primes . Prove that a group of order p2q is solvable, and that one
of its Sylow subgroups is normal.
29. Let p, q be odd primes. Prove that a group of order 2pq is solvable .

78
GROUPS
I, Ex
30. (a) Prove that one of the Sylow subgroups of a group of order 40 is normal.
(b) Prove that one of the Sylow subgroups of a group of order 12 is normal.
31. Determine all groups of order ~ IO up to isomorphism. In particular, show that a
non-abelian group of order 6 is isomorphic to S3'
32. Let Sobe the permutation group on n elements.
Determine the p-Sylow subgroups of
S3, S4, Ss for p = 2 and p = 3.
33. Let a be a permutation of a finite set I having n elements. Define e(a) to be (- l)"
where
m = n - number of orbits of (J .
If I" .. . , I, are the orbits of (J , then m is also equal to the sum
m = L [card(lv) -
I].
v e I
If T is a transposition, show that e(aT) = -e(a) be considering the two cases when
i , j lie in the same orbit of a , or lie in different orbits. In the first case , trr has one
more orbit and in the second case one less orbit than a. In particular, the sign of a
transposition is -I. Prove that e(a) = 10(0') is the sign of the permutation.
34. (a) Let n be an even positive integer. Show that there exists a group of order 2n,
generated by two elements a , T such that an = e = T2, and trt = Tan-I . (Draw
a picture of a regular n-gon , number the vertices, and use the picture as an
inspiration to get a , T.) This group is called the dihedral group.
(b) Let n be an odd positive integer. Let D4n be the group generated by the matrices
(01
-01)
(Y
and
~
where' is a primitive n-th root of unity. Show that D4n has order 4n , and give
the commutation relations between the above generators.
35. Show that there are exactly two non-isomorphic non-abelian groups of order 8. (One
of them is given by generators (J , T with the relations
The other is the quaternion group.)
36. Let a = [123 ... n] in Sn' Show that the conjugacy class of a has (n -
I)! elements.
Show that the centralizer of a is the cyclic group generated by a.
37. (a) Let a =
[i I .. . iml be a cycle . Let y E SO" Show that yay-I is the cycle
[y(i.) . . . y(im)) '
(b) Suppose that a permutation
(J in So can be written as a product of r disjoint
cycles, and let d, ... , d, be the number of elements in each cycle, in increasing
order.
Let
T be another permutation which can be written as a product of
disjoint cycles, whose cardinalities are
d~, . . . , d~ in increasing order.
Prove
that
(J is conjugate to T in So if and only if r = sand d, = di for all i = I, . . . , r.
38. (a) Show that S; is generated by the transpositions [12), [13), .. . , [In].
(b) Show that S, is generated by the transpositions [12), [23), [34), . . . , [n -
I , nl.

I, Ex
EXERCISES
79
(c) Show that Sn is generated by the cycles [12] and [123 . . . n] .
(d) Assume that n is prime . Let a = [123 . . . n] and let T = [rs] be any transposition.
Show that a, T generate Sn'
Let G be a finite group operating on a set S. Then G operates in a natural way on
the Cartesian product s» for each positive integer n. We define the operation on S
to be n-transitive if given n distinct elements (Sl' . . . , sn) and n distinct elements
(s;, .. . , s~) of S, there exists a E G such that os, = s; for all i = 1, .. . , n.
39. Show that the action of the alternating group An on {I , . . . , n} is (n - 2)-transitive.
40 . Let An be the alternating group of even permutations of {I, . .. , n}. For j = I , . .. , n
let Hj be the subgroup of An fixingj, so Hj = An-I, and (An : Hj ) = n for n ~ 3.
Let n ~ 3 and let H be a subgroup of index n in An-
(a) Show that the action of An on cosets of H by left translation gives an iso-
morphism An with the alternating group of permutations of Ani H .
(b) Show that there exists an automorphism of An mapping HI on H, and that
such an automorphism is induced by an inner automorphism of Sn if and only
if H = Hi for some i .
41. Let H be a simple group of order 60.
(a) Show that the action of H by conjugation on the set of its Sylow subgroups
gives an imbedding H ~ A6 .
(b) Using the preceding exerc ise, show that H = As.
(c) Show that A6 has an automorphism which is not induced by an inner auto-
morphism of S6'
Abelian groups
42. Viewing Z. Q as additive groups. show that Q/Z is a torsion group, which has one and
only one subgroup of order n for each integer n ~ 1, and that this subgroup is cyclic.
43. Let H be a subgroup of a finite abelian group G. Show that G has a subgroup that is
isomorphic to Glll.
44. Let f :A ..... A' be a homomorphism of abelian groups.
Let B be a subgroup of A.
Denote by AI and AI the image and kernel of'jin A respectively, and similarly for BI
and BI ' Show that (A : B) = (AI: BI)(AI : BI)' in the sense that if two of these three
indices are finite, so is the third, and the stated equality holds.
45. Let G be a finite cyclic group of order n, generated by an element a. Assume that G
operates on an abelian group A, and letf, g : A ..... A be the endomorphisms of A given by
f(x) = ax - x
and
g(x) = x + ax + ... + an-Ix.
Define the Herbrand quotient by the expression q(A) = (AI :Ag)/(A g:AI), provided
both indices are finite. Assume now that B is a subgroup of A such that GB c B.
(a) Define in a natural wayan operation of G on A/B.
(b) Prove that
q(A) = q(B)q(A/B)
in the sense that iftwo of these quotients are finite, so is the third, and the stated
equality holds .
(c) If A is finite, show that q(A) = I.

80
GROUPS
I, Ex
(This exercise is a special case of the general theory of Euler characteristics discussed
in Chapter XX, Theorem 3.1. After reading this, the present exerc ise becomes trivial.
Why?)
Primitive groups
46. Let G operate on a set S. Let S = US,be a partition of S into disjoint subsets. We say
that the partition is stable under G if G maps each S, onto Sj for some j, and hence G
induces a permutation of the sets of the partition among themselves. There are two
partitions of S which are obviously stable: the partition consisting of S itself, and the
partition consisting of the subsets with one element. Assume that Goperates transitively,
and that S has more than one element.
Prove that the following two conditions are
equivalent :
PRIM 1.
The only partitions of S which are stable are the two partitions mentioned
above.
PRIM 2.
If H is the isotropy group of an element of S, then H is a maximal subgroup
ofG.
These two conditions define what is known as a primitive group, or more accurately, a
primitive operation of G on S.
Instead of saying that the operation of a group G is 2-transitive, one also says that it is
doubly transitive.
47. Let a finite group G operate transitively and faithfully on a set S with at least 2
elements and let H be the isotropy group of some element s of S. (All the other
isotropy group s are conjugates of H. ) Prove the following:
(a) G is doubly transitive if and only if H acts transitively on the complement
of s in S.
(b) G is doubly transitive if and only if G = HTH. where T is a subgroup of G
of order 2 not contained in H.
(c) If G is doubly transitive. and (G : H) = n, then
#(G) = den -
I)n,
where d is the order of the subgroup fixing two elements. Furthermore, H
is a maximal subgroup of G, i.e. G is primitive.
48. Let G be a group acting transitively on a set S with at least 2 elements. For each
x E G letf(x) = number of clements of S fixed by x. Prove :
(a) 2: f(x) = #(G).
XEG
(b) G is doubly transitive if and only if
2: f(X)2 = 2 #(G).
XE G
49. A group as an automorphism group. Let G be a group and let Set(G) be the category
of G-sets (i.e. sets with a G-operation). Let F :Set (G) -+ Set be the forgetful functor,
which to each G-set assigns the set itself. Show that Aut(F ) is naturally isomorphic
to G.

I, Ex
EXERCISES
81
Fiber products and coproducts
Pull-backs and push-outs
50. (a) Show that fiber products exist in the category of abelian groups. In fact, if X, Y
are abelian groups with homomorphisms f : X -+ Z and g: Y-+ Z show that
X x z Y is the set of all pairs (x, y) with x E X and y E Ysuch that f(x) = g(y).
The maps PI' P2 are the projections on the first and second factor respectively.
(b) Show that the pull-back of a surjective homomorphism is surjective.
51. (a) Show that fiber products exist in the category of sets.
(b) In any category e, consider the category ez of objects over Z. Let h: T -+ Z
be a fixed object in this category. Let F be the functor such that
F(X) = Morz(T, X) ,
where X is an object over Z, and Mor, denotes morphisms over Z. Show that
F transforms fiber products over Z into products in the category of sets. (Actu-
ally, once you have understood the definitions, this is tautological.)
52. (a) Show that push-outs (i.e. fiber coproducts) exist in the category of abelian groups.
In this case the fiber coproduct of two homomorphisms f, 9 as above is denoted
by X Ef>z Y. Show that it is the factor group
X Ef>z Y = (X Ef> y)/W,
where W is the subgroup consisting of all elements (f(z), -g(z» with z E Z.
(b) Show that the push-out of an injective homomorphism is injective.
Remark.
After you have read about modules over rings, you should note that the
above two exercises apply to modules as well as to abelian groups.
53. Let H, G, G' be groups, and let
f :H -+ G,
g : H -+ G'
be two homomorphisms. Define the notion of coproduct of these two homomor-
phisms over H , and show that it exists.
54. (Tits). Let G be a group and let {G;};el be a family of subgroups generating G.
Suppose G operates on a set S. For each i E /, suppose given a subset S; of S, and
let s be a point of S - U Sj. Assume that for each 9 E Gj - {e}, we have
I
gSj C S; for allj * i ,
and
g(s) E S; for all i.
Prove that G is the coproduct of the family {G;};e/' (Hint: Suppose a product
g\ . . . gm = id on S. Apply this product to s, and use Proposition 12.4.)
55. Let ME GL2(C) (2 x 2 complex matrices with non-zero determinant) . We let
(
a b)
az + b
M =
ed' and for z E C we let M(z) = ez + d'
If z = -die (e * 0) then we put M(z) = 00. Then you can verify (and you should
have seen something like this in a course in complex analysis) that GL2(C) thus
operates on C U {oo}. Let A, A' be the eigenvalues of M viewed as a linear map on
C2. Let W, W' be the corresponding eigenvectors,

82
GROUPS
I, Ex
By a fixed point of M on C we mean a complex number z such that M(z) = z. Assume
that M has two distinctfixed points =F
00 .
(a) Show that there cannot be more than two fixed points and that these fixed
points are W = WdW2 and w' = W;lW2' In fact one may take
W = '(w, 1), W' = '(w', 1).
(b) Assume that IAI < IA'I. Given z =F w, show that
lim Mk(z) = w' .
k_ao
[Hint: Let S = (W, W') and consider S-IMkS(Z) = exkz where ex = AIA'.]
56. (Tits) Let MI , • • • , Mr E GL2(C) be a finite number of matrices. Let Ai' A;be the
eigenvalues of Mi' Assume that each Mi has two distinct complex fixed points, and
that IAiI < IA;I. Also assume that the fixed points for M I' . . . , Mr are all distinct
from each other. Prove that there exists a positive integer k such that Mt, . . . , M~
are the free generators of a free subgroup of GL2(C). [Hint: Let Wi' W; be the fixed
points of Mi' Let U, be a small disc centered at Wi and U; a small disc centered at
wi. Let S, = U, U U; . Let s be a complex number which does not lie in any Si' Let
Gi =
(M~) . Show that the conditions of Exercise 54 are satisfied for k sufficiently
large.].
se
(D
W:
u'I
57. Let G be a group acting on a set X. Let Y be a subset of X. Let G» be the subset of
G consisting of those elements g such that gY n Y is not empty. Let Gy be the
subgroup of G generated by Gy. Then GyY and (G -
Gy)Y are disjoint. [Hint:
Suppose that there exist gl E Gy and g2 E G but g2 El: Gy, and elements YI' Y2' E Y
such that g2Y1 = g2Y2' Then g2"lgtYI = h, so g2" 'gl E Gy whence g2 E Gy, contrary
to assumption.]
Application.
Suppose that X = GY, but that Xcannot be expressed as a disjoint
union as above unless one of the two sets is empty. Then we conclude that G - Gy
is empty, and therefore G; generates G.
Example1.
Suppose X is a connected topological space, Y is open, and G acts
continuously. Then all translates of Yare open, so G is generated by Gy.
Example2.
Suppose G is a discrete group acting continuously and discretely
on X . Again suppose X connected and Y closed, and that any union of translates of
Y by elements of G is closed, so again G - Gy is empty, and Gy generates G.

CHAPTER II
Rings
§1.
RINGS AND HOMOMORPHISMS
A ring A is a set, together with two laws of composition called multiplica-
tion and addition respectively, and written as a product and as a sum respec-
tively, satisfying the following conditions:
RI 1.
With respect to addition, A is a commutative group.
RI 2.
The multiplication is associative, and has a unit element.
RI3.
For all x, y, Z E A we have
z(x + y) = zx + zy.
and
(x + y)z = xz + yz
(This is called distributivity.)
As usual, we denote the unit element for addition by 0, and the unit
element for multiplication by 1. We do not assume that I "#O. We observe
that Ox = 0 for all x E A.
Proof :
We have Ox + x = (0 + I)x = lx = x.
Hence Ox = O. In particular, if I = 0, then A consists of 0 alone.
For any x, yEA we have (-x)y = -(xy). Proof:
We have
xy + (-x)y = (x+ (-x))y = Oy= 0,
so (-x)y is the additive inverse of xy.
Other standard laws relating addition and multiplication are easily proved,
for instance (- x)( - y) = xy. We leave these as exercises.
Let A be a ring, and let V be the set of elements of A which have both a
right and left inverse. Then V is a multiplicative group. Indeed, if a has a
83
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

84
RINGS
II. §1
right inverse b, so that ab = 1, and a left inverse c, so that ca = 1, then
cab = b, whence c = b, and we see that c (or b) is a two-sided inverse, and
that c itself has a two-sided inverse, namely a. Therefore U satisfies all the
axioms of a multiplicative group, and is called the group of units of A. It is
sometimes denoted by A*, and is also called the group of invertible elements
of A. A ring A such that 1 # 0, and such that every non-zero element is
invertible is called a division ring.
Note.
The elements of a ring which are left invertible do not necessarily
form a group.
Example.
(The Shift Operator).
Let E be the set of all sequences
a = (a1, a2 , a3" ")
of integers. One can define addition componentwise. Let R be the set of all
mappings f :E -. E of E into itself such that f(a + b) = f(a) + f(b). The law
of composition is defined to be composition of mappings. Then R is a ring.
(Proof?) Let
Verify that T is left invertible but not right invertible.
A ring A is said to be commutative if xy = yx for all x, yEA. A commu-
tative division ring is called a field.
We observe that by definition, a field
contains at least two elements, namely 0 and 1.
A subset B of a ring A is called a subring if it is an additive subgroup, if
it contains the multiplicative unit, and if x, y E B implies xy E B. If that is
the case, then B itself is a ring, the laws of operation in B being the same as
the laws of operation in A.
For example, the center of a ring A is the subset of A consisting of all
elements a E A such that ax = xa for all x E A. One sees immediately that
the center of A is a subring.
Just as we proved general associativity from the associativity for three
factors, one can prove general distributivity. If x, Yl ' ... , Yn are elements of a
ring A, then by induction one sees that
X(Y1 + ...+ Yn) = XYI + ...+ XYn'
If Xi (i = 1, ... , n) and Yj (j = 1, .. ., m) are elements of A, then it is also easily
proved that
Furthermore, distributivity holds for subtraction, e.g.
X(Y1 - Y2) = XYI -
XY2'
We leave all the proofs to the reader.

II, §1
RINGS AND HOMOMORPHISMS
85
Examples.
Let S be a set and A a ring. Let Map(S, A) be the set of map-
pings of S into A. Then Map(S, A) is a ring if for f, g E Map(S, A) we define
(fg)(x) = f(x)g(x)
and
(f + g)(x) = f(x) + g(x)
for all XES. The multiplicative unit is the constant map whose value is the
multiplicative unit of A. The additive unit is the constant map whose value
is the additive unit of A, namely O. The verification that Map(S, A) is a ring
under the above laws of composition is trivial and left to the reader.
Let M be an additive abelian group, and let A be the set End(M) of
group-homomorphisms of M into itself. We define addition in A to be the
addition of mappings, and we define multiplication to be composition of
mappings. Then it is trivially verified that A is a ring. Its unit element is of
course the identity mapping. In general, A is not commutative.
Readers have no doubt met polynomials over a field previously. These pro-
vide a basic example of a ring, and will be defined officially for this book in §3.
Let K be a field. The set of n x n matrices with components in K is a
ring. Its units consist of those matrices which are invertible, or equivalently
have a non-zero determinant.
Let S be a set and R the set of real-valued functions on S. Then R is a
commutative ring. Its units consist of those functions which are nowhere O.
This is a special case of the ring Map(S, A) considered above.
The convolution product.
We shall now give examples of rings whose
product is given by what is called convolution. Let G be a group and let K
be a field.
Denote by K[G] the set of all formal linear combinations
IX = Laxx with x E G and ax E K, such that all but a finite number of ax are
equal to O. (See §3, and also Chapter III, §4.) If fJ = Lbxx E K [G], then one
can define the product
IXfJ = L L axbyxy = L (L axby) z.
xeG yeG
zeG
xy=z
With this product, the group ring K [G] is a ring, which will be studied
extensively in Chapter XVIII when G is a finite group.
Note that K[G] is
commutative if and only if G is commutative. The second sum on the right
above defines what is called a convolution product. If f, g are two functions
on a group G, we define their convolutionf *g by
(f *g)(z) = L f(x)g(y).
xy=z
Of course this must make sense. If G is infinite, one may restrict this
definition to functions which are 0 except at a finite number of elements.
Exercise 12 will give an example (actually on a monoid) when another type
of restriction allows for a finite sum on the right.
Example from analysis.
In analysis one considers a situation as follows.
Let L 1 = L 1(R) be the space of functions which are absolutely integrable.

86
RINGS
II, §1
Given functions f, gEL1, one defines their convolution product f *g by
(f *g)(x) = fa f(x - y)g(y) dy.
Then this product satisfies all the axioms of a ring, except that there is no
unit element. In the case of the group ring or the convolution of Exercise 12,
there is a unit element. (What is it?) Note that the convolution product in
the case of U(R) is commutative, basically because R is a commutative
additive group.
More generally, let G be a locally compact group with a
Haar measure
J1. Then the convolution product is defined by the similar
formula
(f *g)(x) =t f(xy-l )g(y) dJ1(Y)·
After these examples, we return to the general theory of rings.
A left ideal a in a ring A is a subset of A which is a subgroup of the
additive group of A, such that Aa c a (and hence Aa = a since A contains
1). To define a right ideal, we require aA = a, and a two-sided ideal is a
subset which is both a left and a right ideal.
A two-sided ideal is called
simply an ideal in this section. Note that (0) and A itself are ideals.
If A is a ring and a E A, then Aa is a left ideal, called principal. We say
that a is a generator of a (over A). Similarly, AaA is a principal two-sided
ideal if we define AaA to be the set of all sums LXiaYi with Xi' Yi E A. Cf.
below the definition of the product of ideals. More generally, let a1 , ••• , an
be elements of A. We denote by (ai' ... , an) the set of elements of A which
can be written in the form
with
Xi E A.
Then this set of elements is immediately verified to be a left ideal, and
a1 , ••• , an are called generators of the left ideal.
If {ai} ieI is a family of ideals, then their intersection
nai
ieI
is also an ideal. Similarly for left ideals. Readers will easily verify that if
a = (a1, •• • , an)' then a is the intersection of all left ideals containing the
elements a1 , ••• , an'
A ring A is said to be commutative if xy = yx for all X, YEA.
In that
case, every left or right ideal is two-sided.
A commutative ring such that every ideal is principal and such that 1 =1= 0
is called a principal ring.
Examples.
The integers Z form a ring, which is commutative. Let a be
an ideal
=1= Z and
=1= O. If n E a, then - n E a. Let d be the smallest integer
> 0 lying in a. If n E a then there exist integers q, r with 0 ~ r < d such that
n = dq + r.

II, §1
RINGS AND HOMOMORPHISMS
87
Since a is an ideal, it follows that r lies in a, hence r = 0. Hence a consists of
all multiples qd of d, with q E Z, and Z is a principal ring.
A similar example is the ring of polynomials in one variable over a field,
as will be proved in Chapter IV, also using the Euclidean algorithm.
Let R be the ring of algebraic integers in a number field K.
(For
definitions, see Chapter VII.) Then R is not necessarily principal, but let p
be a prime ideal, and let R p be the ring of all elements alb with a, b e Rand
b r/: p. Then in algebraic number theory, it is shown that R; is principal, with
one prime ideal m, consisting of all elements alb as above but with a E p.
See Exercises 15, 16, and 17.
An example from analysis.
Let A be the set of entire functions on the
complex plane. Then A is a commutative ring, and every finitely generated
ideal is principal. Given a discrete set of complex numbers {z.} and integers
m, ~ 0, there exists an entire function I having zeros at z, of multiplicity m,
and no other zeros. Every principal ideal is of the form AI for some such f.
The group of units A* in A consists of the functions which have no zeros. It
is a nice exercise in analysis to prove the above statements (using the
Weierstrass factorization theorem).
We now return to general notions. Let a, b be ideals of A. We define ab
to be the set of all sums
XlYl + ...+ XnYn
with Xi E a and Yi E b. Then one verifies immediately that ab is an ideal, and
that the set of ideals forms a multiplicative monoid, the unit element being
the ring itself. This unit element is called the unit ideal, and is often written (1).
If a, b are left ideals, we define their product ab as above. It is also a left ideal,
and if a, b, c are left ideals, then we again have associativity: (ab)c = a(bc).
If a, b are left ideals of A, then a + b (the sum being taken as additive
subgroup of A) is obviously a left ideal. Similarly for right and two-sided
ideals.
Thus ideals also form a monoid under addition.
We also have
distributivity : If al' .. . , an' b are ideals of A, then clearly
b(a l + ...+ an) = be, + ... + ban'
and similarly on the other side. (However, the set of ideals does not form a
ring!)
Let a be a left ideal. Define aA to be the set of all sums alxl + ... + anXn
with a, E a and Xi E A. Then aA is an ideal (two-sided).
Suppose that A is commutative. Let a, b be ideals. Then trivially
ab can b,
but equality does not necessarily hold. However, as an exercise, prove that if
a + b = A then ab = a n b.
As should be known to the reader, the integers Z satisfy another property
besides every ideal being principal, namely unique factorization into primes.

88
RINGS
II. §1
We shall discuss the general phenomenon in §4. Be it noted here only that if
a ring A has the property of unique factorization into prime elements, and p
is a prime element, then the ideal (p) is prime, and the ring R(p) (defined as
above) is principal. See Exercise 6. Thus principal rings may be obtained in
a natural way from rings which are not principal.
As Dedekind found out, some form of unique factorization can be re-
covered in some cases, replacing unique factorization into prime elements by
unique factorization of (non-zero) ideals into prime ideals.
Example.
There are cases when the non-zero ideals give rise to a group.
Let 0 be a subring of a field K such that every element of K is a quotient of
elements of 0; that is, of the form alb with a, b E 0 and b i= O. By a fractional
ideal a we mean a non-zero additive subgroup of K such that oa c a (and
therefore oa = a since 0 contains the unit element); and such that there exists
an element CEO, C i= 0, such that ca c o. We might say that a fractional
ideal has bounded denominator. A Dedekind ring is a ring 0 as above such
that the fractional ideals form a group under multiplication.: As proved in
books on algebraic number theory, the ring of algebraic integers in a number
field is a Dedekind ring. Do Exercise 14 to get the property of unique
factorization into prime ideals. See Exercise 7 of Chapter VII for a sketch of
this proof.
If a E K, a i= 0, then oa is a fractional ideal, and such ideals are called
principal. The principal fractional ideals form a subgroup. The factor group
is called the ideal class group, or Picard group of 0, and is denoted by Pic(o).
See Exercises 13-19 for some elementary facts about Dedekind rings. It is
a basic problem to determine Pic(o) for various Dedekind rings arising in
algebraic number theory and function theory. See my book Algebraic Num-
ber Theory for the beginnings of the theory in number fields. In the case of
function theory, one is led to questions in algebraic geometry, notably the
study of groups of divisor classes on algebraic varieties and all that this
entails.
The property that the fractional ideals form a group is essentially
associated with the ring having "dimension 1" (which we do not define
here). In general one is led into the study of modules under various equiva-
lence relations; see for instance the comments at the end of Chapter III, §4.
We return to the general theory of rings.
By a ring-homomorphism one means a mapping f : A -. B where A, Bare
rings, and such that f is a monoid-homomorphism for the multiplicative
structures on A and B, and also a monoid-homomorphism for the additive
structure. In other words, f must satisfy:
f(a + a') = f(a) + f(a'),
f(l) = 1,
f(aa') = f(a)f(a'),
f(O) = 0,
for all a, a' E A. Its kernel is defined to be the kernel of f viewed as additive
homomorphism.

II, §1
RINGS AND HOMOMORPHISMS
89
The kernel of a ring-homomorphism f : A ~ B is an ideal of A, as one
verifies at once.
Conversely, let a be an ideal of the ring A. We can construct the factor
ring A/a as follows. Viewing A and a as additive groups, let A/a be the
factor group.
We define a multiplicative law of composition on A/a:
If
x + a and y + a are two cosets of a, we define (x + a)(y + a) to be the coset
(xy + a). This coset is well defined, for if Xl' Y1 are in the same coset as x, y
respectively, then one verifies at once that X1Yl is in the same coset as xy.
Our multiplicative law of composition is then obviously associative, has a
unit element, namely the coset 1 + a, and the distributive law is satisfied
since it is satisfied for coset representatives. We have therefore defined a ring
structure on A/a, and the canonical map
f: A ~A/a
is then clearly a ring-homomorphism.
If g: A ~ A' is a ring-homomorphism whose kernel contains a, then there
exists a unique ring-homomorphism g.: A/a ~ A' making the following dia-
gram commutative :
A~A'
\/
A/a
Indeed, viewing f, g as group-homomorphisms (for the additive struc-
tures), there is a unique group-homomorphism g. making our diagram
commutative.
We contend that g. is in fact a ring-homomorphism.
We
could leave the trivial proof to the reader, but we carry it out in full. If
x E A, then g(x) = g.f(x). Hence for x, YEA,
g.(f(x)f(Y)) = g.(f(xy)) = g(xy) = g(x)g(y)
= g.f(x)g.f(y)·
Given
~ , 11 E A/a, there exist x, yEA such that
~ = f(x) and 11 = f(y). Since
f(l) = 1, we get g.f(l) = g(l) = 1, and hence the two conditions that g. be a
multiplicative monoid-homomorphism are satisfied, as was to be shown.
The statement we have just proved is equivalent to saying that the
canonical map f: A ~ A/a is universal in the category of homomorphisms
whose kernel contains a.
Let A be a ring, and denote its unit element by e for the moment.
The
map
A.: Z ~ A
such that ..l.(n) = ne is a ring-homomorphism (obvious), and its kernel is an
ideal (n), generated by an integer n ~ O. We have a canonical injective homo-
morphism Z/nZ ~ A, which is a (ring) isomorphism between Z/nZ and a

90
RINGS
II, §1
subring of A . If nZ is a prime ideal, then n = °or n = p for some prime number
p. In the first case, A contains as a subring a ring which is isomorphic to Z, and
which is often identified with Z. In that case, we say that A has characteristic
0. If on the other hand n = p , then we say that A has characteristic p, and A
contains (an isomorphic image of) Z/pZ as a subring . We abbreviate Z/pZ by
Fp .
If K is a field, then K has characteristic°or p > 0. In the first case, K
contains as a subfield an isomorphic image of the rational numbers, and in
the second case, it contains an isomorphic image of Fp • In either case, this
subfield will be called the prime field (contained in K) . Since this prime field
is the smallest subfield of K containing 1 and has no automorphism except
the identity, it is customary to identify it with Q or F, as the case may be.
By the prime ring (in K) we shall mean either the integers Z if K has
characteristic 0, or F, if K has characteristic p.
Let A be a subring of a ring B. Let 8 be a subset of B commuting with
A; in other words we have as = sa for all a E A and s E 8. We denote by
A [8] the set of all elements
L a
Si, ... s in
i ·· ·i
1
n ,
I
n
the sum ranging over a finite number of n-tuples (il ' ... , in) of integers ;;; 0,
and
a il " 'in E A, s. , ... , s, E 8.
If B = A[8], we say that 8 is a set of
generators (or more precisely, ring generators) for B over A, or that B is
generated by 8 over A. If 8 is finite, we say that B is finitely generated
as a ring over A. One might say that A[8] consists of all not-necessarily-
commutative polynomials in elements of 8 with coefficients in A. Note that
elements of S may not commute with each other.
Example.
The ring of matrices over a field is finitely generated over that
field, but matrices don't necessarily commute.
As with groups, we observe that a homomorphism is uniquely determined
by its effect on generators.
In other words, let
f : A -+ A' be a ring-
homomorphism, and let B = A [8] as above. Then there exists at most one
extension of f to a ring-homomorphism of B having prescribed values on 8.
Let A be a ring, a an ideal, and 8 a subset of A. We write
8 =° (mod a)
if 8 c a. If x, YEA, we write
x = y
(mod a)
if x - Y E a. If a is principal, equal to (a), then we also write
x =y
(mod a).
If f : A -+ A/a is the canonical homomorphism, then x =y (mod a) means
that f(x) = f(y). The congruence notation is sometimes convenient when we
want to avoid writing explicitly the canonical map f

II, §1
RINGS AND HOMOMORPHISMS
91
The factor ring A/a is also called a residue class ring. Cosets of a in A
are called residue classes modulo a, and if x E A, then the coset x + a is
called the residue class of x modulo a.
We have defined the notion of an isomorphism in any category, and so a
ring-isomorphism is a ring-homomorphism which has a two-sided inverse.
As usual we have the criterion:
A/a -> A']«.
The trivial proof is left to the reader.
A ring-homomorphism f : A -> B which is bijective is an isomorphism.
Indeed, there exists a set-theoretic inverse g: B -> A, and it is trivial to verify
that g is a ring-homomorphism.
Instead
of saying "ring-homomorphism"
we sometimes
say
simply
"homomorphism" if the reference to rings is clear. We note that rings form
a category (the morphisms being the homomorphisms).
Let f : A -> B be a ring-homomorphism.
Then the image f(A) of f is a
subring of B. Proof obvious.
It is clear that an injective ring-homomorphism f : A -> B establishes a
ring-isomorphism between A and its image. Such a homomorphism will be
called an embedding (of rings).
Let f : A -> A' be a ring-homomorphism, and let a' be an ideal of A'.
Then r:(a') is an ideal a in A, and we have an induced injective homo-
morphism
Proposition 1.1.
Products exist in the category of rings.
In fact, let {Ai}ieI be a family of rings, and let A = nAi be their product
as additive abelian groups . We define a multiplication in A in the obvious
way: If (x.),e I and (Y;)i e [ are two elements of A, we define their product to
be (XiY;)ieI' i.e. we define multiplication componentwise, just as we did for
addition. The multiplicative unit is simply the element of the product whose
i-th component is the unit element of Ai' It is then clear that we obtain a
ring structure on A, and that the projection on the i-th factor is a ring-
homomorphism.
Furthermore, A together with these projections clearly
satisfies the required universal property.
Note that the usual inclusion of Ai on the i-th factor is not a ring-
homomorphism because it does not map the unit element e, of Ai on the unit
element of A.
Indeed, it maps e, on the element of A having e, as i-th
component, and °(= 0;) as all other components.
Let A be a ring. Elements x, Y of A are said to be zero divisors if x #- 0,
Y #- 0, and xy = 0. Most of the rings without zero divisors which we con-
sider will be commutative. In view of this, we define a ring A to be entire if
I #- 0, if A is commutative, and if there are no zero divisors in the ring.
(Entire rings are also called integral domains. However, linguistically, I feel

92
RINGS
II, §2
the need for an adjective. "Integral" would do, except that in English,
"integral" has been used for" integral over a ring" as in Chapter VII, §1. In
French, as in English, two words exist with similar roots: "integral" and
"entire". The French have used both words. Why not do the same in
English? There is a slight psychological impediment, in that it would have
been better if the use of "integral" and "entire" were reversed to fit the
long-standing French use. I don't know what to do about this.)
Examples.
The ring of integers Z is without zero divisors, and is there-
fore entire. If S is a set with at least 2 elements, and A is a ring with I =1= 0, then
the ring of mappings Map(S,A) has zero divisors. (Proof?)
Let m be a positive integer
=1= 1. The ring Z/mZ has zero divisors if and
only if m is not a prime number. (Proof left as an exercise.) The ring of
n x n matrices over a field has zero divisors if n ~ 2. (Proof?)
The next criterion is used very frequently.
Let A be an entire ring, and let a, b be non·zero elements of A. Then a, b
generate the same ideal if and only if there exists a unit u of A such that
b = au.
Proof
If such a unit exists we have Ab = Aua = Aa.
Conversely,
assume Aa = Ab. Then we can write a = be and b = ad with some elements
c, d e A. Hence a = adc, whence a(l - de) = 0, and therefore de = 1. Hence
c is a unit.
§2.
COMMUTATIVE RINGS
Throughout this section, we let A denote a commutative ring.
A prime ideal in A is an ideal V =1= A such that A/V is entire. Equiva-
lently, we could say that it is an ideal V =1= A such that, whenever x, yEA
and xy E p, then x EV or YEp. A prime ideal is often called simply a prime.
Let m be an ideal. We say that m is a maximal ideal if m =1= A and if
there is no ideal a =1= A containing m and
=1= m.
Every maximal ideal is prime.
Proof
Let m be maximal and let x, yEA be such that xy E m. Suppose
x ¢ m. Then m + Ax is an ideal properly containing m, hence equal to A.
Hence we can write
l=u+ax
with u E m and a E A. Multiplying by y we find

II, §2
COMMUTATIVE RINGS
93
y = yu + axy,
whence y E m and m is therefore prime.
Let a be an ideal # A. Then a is contained in some maximal ideal m.
Proof.
The set of ideals containing a and # A is inductively ordered by
ascending inclusion. Indeed, if {b.} is a totally ordered set of such ideals,
then I ¢ b, for any i, and hence 1 does not lie in the ideal b = Ubi' which
dominates all bi' If m is a maximal element in our set, then m # A and m is
a maximal ideal, as desired.
The ideal {O} is a prime ideal of A if and only if A is entire.
(Proof obvious.)
We defined a field K to be a commutative ring such that 1 '* 0, and such
that the multiplicative monoid of non-zero elements of K is a group (i.e. such
that whenever x E K and x '* 0 then there exists an inverse for x). We note that
the only ideals of a field K are K and the zero ideal.
If m is a maximal ideal of A, then A/m is a field .
Proof.
If x E A, we denote by x its residue class mod m. Since m # A
we note that A/m has a unit element # O. Any non-zero element of A/m can
be written as x for some x E A, x ¢ m. To find its inverse, note that m + Ax
is an ideal of A # m and hence equal to A. Hence we can write
1 = u + yx
with u E m and YEA. This means that yx = 1 (i.e. = I) and hence that x has
an inverse, as desired.
Conversely, we leave it as an exercise to the reader to prove that :
If m is an ideal of A such that A/m is a field, then m is maximal.
Let f : A ~ A' be a homomorphism of commutative rings. Let pi be a prime
ideal of A', and let p = f- 1(p'), Then p is prime.
To prove this, let x, YEA, and xy E p. Suppose x ¢ p. Then f(x) ¢ p',
But f(x)f(y) = f(xy) E p'. Hence f(y) E p', as desired.
As an exercise, prove that if f is surjective, and if m' is maximal in A',
then f- 1(m') is maximal in A.
Example.
Let Z be the ring of integers. Since an ideal is also an additive
subgroup of Z, every ideal '* {O} is principal, of the form nZ for some integer
n > 0 (uniquely determined by the ideal). Let p be a prime ideal '* {O},
p = nZ. Then n must be a prime number, as follows essentially directly from
the definition of a prime ideal. Conversely, if p is a prime number , then pZ is
a prime ideal (trivial exercise) . Furthermore, pZ is a maximal ideal. Indeed,
suppose pZ contained in some ideal nZ. Thenp = nm for some integer m, whence
n = p or n = I, thereby proving pZ maximal.

94
RINGS
II, §2
If n is an integer, the factor ring Z/nZ
IS called the ring of integers
modulo n. We also denote
Z/nZ = Z(n).
If n is a prime number p, then the ring of integers modulo p is in fact a field,
denoted by Fp-
In particular, the multiplicative group of F, is called the
group of non-zero integers modulo p.
From the elementary properties of
groups, we get a standard fact of elementary number theory: If x is an
integer
=1= 0 (mod p), then xv-t == 1 (mod p). (For simplicity, it is customary
to write mod p instead of mod pZ, and similarly to write mod n instead of
mod nZ for any integer n.) Similarly, given an integer n > 1, the units in the
ring Z/nZ consist of those residue classes mod nZ which are represented by
integers m =I 0 and prime to n. The order of the group of units in Z/nZ is
called by definition cp(n) (where
cp is known as the Euler phi-function).
Consequently, if x is an integer prime to n, then x'P(n) == 1 (mod n).
Theorem 2.1.
(Chinese Remainder Theorem).
Let at,
, an be ideals of
A such that ai + aj = A for all i =Ij. Given elements xt,
, x, E A, there
exists x E A such that x == Xi (mod ai) for all i.
Proof.
If n = 2, we have an expression
1 = at + a2
for some elements a, E ai' and we let x = X2at + XI a2.
For each i ~ 2 we can find elements a, E at and b, E o, such that
a, + b, = 1,
i ~ 2.
n
The product Il (ai + b;) is equal to 1, and lies in
i= 2
i.e. in at + a2 ... an' Hence
n
at + Il ai = A.
i=2
By the theorem for n = 2, we can find an element Yt E A such that
Yt == 1
(mod at),
Yi = 0
(modlJaJ
We find similarly elements Yz, .. ., Yn such that
and
for i =Ij.
Then x = XtYt + ...+ XnYn satisfies our requirements.

II, §2
COMMUTATIVE RINGS
95
In the same vein as above, we observe that if a I ' ... , a. are ideals of a
ring A such that
a l + ... + a. = A,
and if VI ' ... , V. are positive integers, then
The proof is trivial, and is left as an exercise.
Corollary 2.2.
Let a i' ... , a. be ideals of A. Assume that o, + aj = A for
i #-j . Let
•
f : A --+ TI Al«, = (A/ad x .. . x (A/a. )
i= 1
be the map of A into the product induced by the canonical map of A onto
•
A/a; for each factor. Then the kernel of f is nc., and f is surjective,
thus giving an isomorphism
;= 1
Proof.
That the kernel of f
is what we said it is, is obvious.
The
surjectivity follows from the theorem.
The theorem and its corollary are frequently applied to the ring of
integers Z and to distinct prime ideals (PI ), ... , (P.).
These satisfy the
hypothesis of the theorem since they are maximal. Similarly, one could take
integers ml ' . . . , m. which are relatively prime in pairs, and apply the theorem
to the principal ideals (ml ) = ml Z, .. ., (m. ) = m.Z. This is the ultraclassical
case of the Chinese remainder theorem.
In particular, let m be an integer > 1, and let
be a factorization of m into primes, with exponents ri ~ 1. Then we have a
ring-isomorphism:
Z/mZ ~ TI Z/p[iZ.
;
If A is a ring, we denote as usual by A* the multiplicative group of invertible
elements of A. We leave the following assertions as exercises:
The preceding ring-isomorphism of Z/mZ onto the product induces a group-
isomorphism
(Z/mZ)* ~ TI (Z/p~iZ)*.
;
In view of our isomorphism, we have
cp(m) = TI cp(p[i).
;

96
RINGS
II, §2
If p is a prime number and r an integer ~ 1, then
q>(pr) = (p _ l)pr-l.
One proves this last formula by induction. If r = 1, then Z/pZ is a field, and
the multiplicative group of that field has order p - 1. Let r be
~ 1, and
consider the canonical ring-homomorphism
Z/pr+l Z ~ Z/prz,
arising from the inclusion of ideals (pr+1) C (p"). We get an induced group-
homomorphism
A.: (Z/pr+lZ)* ~ (Z/prz)*,
which is surjective because any integer a which represents an element of
Z/prz and is prime to p will represent an element of (Z/pr+1 Z)*. Let a be an
integer representing an element of (Z/pr+1 Z)*, such that A.(a) = 1. Then
a == 1
(mod prz),
and hence we can write
a == 1 + xp'
(mod pr+l Z)
for some x E Z. Letting x = 0, 1, ... , p - 1 gives rise to p distinct elements of
(Z/pr+l Z)*, all of which are in the kernel of A.. Furthermore, the element x
above can be selected to be one of these p integers because every integer is
congruent to one of these p integers modulo (p). Hence the kernel of A. has
order p, and our formula is proved.
Note that the kernel of A. is isomorphic to Z/pZ. (Proof?)
Application:
The ring of endomorphisms of a cyclic group.
One of the
first examples of a ring is the ring of endomorphisms of an abelian group.
In
the case of a cyclic group, we have the following complete determination.
Theorem 2.3.
Let A be a cyclic group of order n. For each k E Z let
fk: A -
A be the endomorphism x ~ kx (writing A additively). Then k ~ fk
induces a ring isomorphism Z/nZ = End(A) , and a group isomorphism
(Z/nZ)* = Aut(A).
Proof
Recall that the additive group structure on End(A) is simply
addition of mappings, and the multiplication is composition of mappings.
The fact that k ~ fk is a ring-homomorphism is then a restatement of the
formulas
la = a,
(k + k')a = ka + k'a,
and
(kk')a = k(k'a)
for k, k' E Z and a E A. If a is a generator of A, then ka = °if and only if
k ==°mod n, so Z/nZ is embedded in End(A).
On the other hand, let
f : A ~ A be an endomorphism. Again for a generator a, we have f(a) = ka

II, §3
POLYNOMIALS AND GROUP RINGS
97
for some k, whence f = fk since every x E A is of the form ma for some
m e Z, and
f(x) = f(ma) = mf(a) = mka = kma = kx.
This proves the isomorphism Z/nZ ~ End(A).
Furthermore, if k E (Z/nZ)*
then there exists k' such that kk' == 1 mod n, so f" has the inverse fk' and fk is
an automorphism. Conversely, given any automorphism f with inverse g, we
know from the first part of the proof that f = fb g = gk' for some k, k', and
f og = id means that kk' == 1 mod n, so k , k' E (Z/nZ) *. This proves the
isomorphism (Z/nZ) * = Aut(A).
Note that if A is written as a multiplicative group C, then the map fk is
given by x H x k• For instance, let Jln be the group of n-th roots of unity in C.
Then all automorphisms of Jln are given by
with
k E (Z/nZ)*.
§3.
POLYNOMIALS AND GROUP RINGS
Although all readers will have met polynomial functions, this section lays
the ground work for polynomials in general.
One needs polynomials over
arbitrary rings in many contexts. For one thing, there are polynomials over
a finite field which cannot be identified with polynomial functions in that
field.
One needs polynomials with integer coefficients, and one needs to
reduce these polynomials mod p for primes p. One needs polynomials over
arbitrary commutative rings, both in algebraic geometry and in analysis, for
instance the ring of polynomial differential operators. We also have seen the
example of a ring B = A [S] generated by a set of elements over a ring A.
We now give a systematic account of the basic definitions of polynomials
over a commutative ring A.
We want to give a meaning to an expression such as
ao + a1X + ... +anXn,
where a, E A and X is a "variable". There are several devices for doing so,
and we pick one of them . (I picked another in my Undergraduate Algebra.)
Consider an infinite cyclic group generated by an element X. We let S be the
subset consisting of powers X' with r ~ O. Then S is a monoid. We define
the set of polynomials A[X] to be the set of functions S -. A which are equal
to 0 except for a finite number of elements of S. For each element a E A we
denote by aXn the function which has the value a on X" and the value 0 for
all other elements of S.
Then it is immediate that a polynomial can be
written uniquely as a finite sum

98
RINGS
II, §3
aoXo + ...+ anXn
for some integer n E Nand a, E A. Such a polynomial is denoted by f(X).
The elements a, E A are called the coefficients of f
We define the product
according to the convolution rule. Thus, given polynomials
n
f(X) = L aiX i
i=O
we define the product to be
and
m
g(X) = L bjXj
j=O
f(X)g(X) = ~~ (+~k aibj) x».
It is immediately verified that this product is associative and distributive.
We shall give the details of associativity in the more general context of a
monoid ring below.
Observe that there is a unit element, namely lXo.
There is also an embedding
A --+ A [X]
given by
One usually does not distinguish a from its image in A[X], and one writes a
instead ofaXo. Note that for C E A we have then cf(x) = Lca.X'.
Observe that by our definition, we have an equality of polynomials
L aiXi = L biX i
if and only if a, = b, for all i.
Let A be a subring of a commutative ring B. Let x E B. Iff E A [X] is a
polynomial, we may then define the associated polynomial function
by letting
Given an element b E B, directly from the definition of multiplication of
polynomials, we find:
The association
is a ring homomorphism of A [X] into B.
This homomorphism is called the evaluation homomorphism, and is also said
to be obtained by substituting b for X in the polynomial.
(Cf. Proposition
3.1 below.)
Let x E B. We now see that the subring A [x] of B generated by x over A
is the ring of all polynomial values f(x), for f E A [X]. If the evaluation map
fl--+ f(x) gives an isomorphism of A[X] with A [x], then we say that x is

II, §3
POLYNOMIALS AND GROUP RINGS
99
transcendental over A, or that x is a variable over A. In particular, X is a
variable over A.
Example.
Let et = J2. Then the set of all real numbers of the form
a + bet, with a, b e Z, is a subring of the real numbers, generated by J2.
Note that et is not transcendental over Z, because the polynomial X 2 -
2 lies
in the kernel of the evaluation map JHJ(J2). On the other hand, it can be
shown that e = 2.718.. . and n are transcendental over Q. See Appendix 1.
Example.
Let p be a prime number and let K = Z/pZ.
Then K is a
field. Let J(X) = XP - X E K[X]. Then J is not the zero polynomial. But
JK is the zero function. Indeed, JK(O) = O. If x E K, x =F 0, then since the
multiplicative group of K has order p - 1, it follows that Xp-l = 1, whence
x" = x, so J(x) = O.
Thus a non-zero polynomial gives rise to the zero
function on K.
There is another homomorphism of the polynomial ring having to do
with the coefficients. Let
cp: A ~B
be a homomorphism of commutative rings.
Then there is an associated
homomorphism of the polynomial rings A [X] ~ B[X], such that
The verification that this mapping is a homomorphism is immediate, and
further details will be given below in Proposition 3.2, in a more general
context. We call JH CPJ the reduction map.
Examples.
In some applications the map
cp may be an isomorphism.
For instance, if J(X) has complex coefficients, then its complex conju-
gate ](X) = L£liXi is obtained by applying complex conjugation to its
coefficients.
Let p be a prime ideal of A.
Let cp: A ~ At be the canonical homo-
morphism of A onto A/p. If J(X) is a polynomial in A [X], then CPJ will
sometimes be called the reduction offmodulo p,
For example, taking A = Z and p = (p) where p is a prime number, we
can speak of the polynomial 3X 4 -
X + 2 as a polynomial mod 5, viewing
the coefficients 3, - 1, 2 as integers mod 5, i.e. elements of Z/5Z.
We may now combine the evaluation map and the reduction map to
generalize the evaluation map.
Let '1': A ~ B be a homomorphism of commutative rings.
Let x E B. There is a unique homomorphism extending <p
such that
XHX,

100
RINGS
II. §3
The homomorphism of the above statement may be viewed as the composite
A[X] --+ B[X] ~ B
where the first map applies qJ to the coefficients of a polynomial, and the
second map is the evaluation at x previously discussed.
Example.
In Chapter IX, §2 and §3, we shall discuss such a situation in
several variables, when (qJJ)(x) = 0, in which case x is called a zero of the
polynomial f
n
When writing a polynomial f(X) = L a;X;, if an =1=°then we define n
;=0
to be the degree of [.
Thus the degree of J is the smallest integer n such
that a, = °for r > n. If J = °(i.e. J is the zero polynomial), then by con-
vention we define the degree of J to be -00 . We agree to the convention
that
-00 + -00 = -00,
-00 + n = -00,
-00 < n,
for all nEZ, and no other operation with -00 is defined. A polynomial of
degree 1 is also called a linear polynomial. If J =1=°and degJ = n, then we
call an the leading coefficient of J. We call ao its constant term.
Let
be a polynomial in A[X], of degree m, and assume g =1= 0. Then
J(X)g(X) = aobo + ... + anbmXm+n.
Therefore:
IJ we assume that at least one oj the leading coefficients an or bmis not a
divisor oj 0 in A, then
deg(Jg) = deg J + deg g
and the leading coefficient ojJg is anbm. This holds in particular when an or
bm is a unit in A, or when A is entire. Consequently, when A is entire,
A[X] is also entire.
IfJ or g = 0, then we still have
deg(Jg) = deg J + deg g
if we agree that -00 + m = -00 for any integer m.
One verifies trivially that for any polynomials f, g E A[X] we have
deg(J + g) ~ max(deg J, deg g),
again agreeing that -00 < m for every integer m.

1I,§3
POLYNOMIALS AND GROUP RINGS
101
Polynomials in several variables
We now go to polynomials in several variables. Let A be a subring of
a commutative ring B.
Let Xl"' " x, E B.
For each n-tuple of integers
(VI' ... , Vn ) = (V) E N", we use vector notation, letting (x) = (Xl' ... , xn ), and
M(.)(x) = x;' '"
x;n.
The
set of such
elements forms
a monoid
under multiplication.
Let
A[x]=A[xl, .. .,xn ] be the subring of B generated by XI""'Xn over A.
Then every element of A [x] can be written as a finite sum
L a(.)M(.)(x)
with
a(.) E A.
Using the construction of polynomials in one variable repeatedly, we may
form the ring
A[XI , ... , X n] = A[XI ] [X2 ] ... [Xn] ,
selecting X; to be a variable over A[X1, ••• , X n - 1]. Then every element f of
A [Xl' ... , Xn] = A [X] has a unique expression as a finite sum
Therefore by induction we can write f uniquely as a sum
f = t( L
a.,·-vvn X ; ' ... X::i') x:n
vPI-Q
Vt. · · · .vn-l
= L a(.)M(.)(X) = L a(.)X;' ... x:n
with elements a(.) E A, which are called the coefficients of f
The products
M(.)(X) = X;' ... x:n
will be called primitive monomials. Elements of A [X] are called polynomials
(in n variables). We call a(v) its coefficients.
Just as in the one-variable case, we have an evaluation map. Given (x) =
(x l' . . . , xn) and f as above, we define
f(x) = La(.)M(v)(x) = La(.)x;' ... x;n.
Then the evaluation map
ev(x): A[X] ~ R
such that
fH f(x)
is a ring-homomorphism. It may be viewed as the composite of the suc-
cessive evaluation maps in one variable Xi H
Xi for i = n, ... , 1, because
A[X] c R[X].
Just as for one variable, if f(X) E A [X] is a polynomial in n variables,
then we obtain a function

102
RINGS
by
(x) 1-+ J (x).
II, §3
We say that J(x) is obtained by substituting (x) for (X ) in J, or by specializing
(X) to (x). As for one variable, if K is a finite field, and J E K[X] one may
have J =1= 0 but JK = O. Cf. Chapter IV, Theorem 1.4 and its corollaries.
Next let tp: A ....B be a homomorphism of commutative rings. Then we
have the reduction map (generalized in Proposition 3.2 below)
We can also compose the evaluation and reduction. An element (x) E B" is
called a zero of J if (q>J)(x) = O. Such zeros will be studied in Chapter IX.
Go back to A as a subring of B.
Elements
Xl"' " x; E B are called
algebraically independent over A if the evaluation map
JI-+J(x)
is injective. Equivalently, we could say that if f E A[X] is a polynomial and
f(x) = 0, then f = 0; in other words, there are no non-trivial polynomial
relations among Xl, • . • , Xn over A.
Example.
It is not known if e and
7! are algebraically independent over
the rationals. It is not even known if e + 7! is rational.
We now come to the notion of degree for several variables. By the degree
of a primitive monomial
M
(X) = X VI .. . X v"
(v)
1
n
we shall mean the integer lvl = vl + ... + Vn (which is ~ 0).
A polynomial
(a E A)
will be called a monomial (not necessarily primitive).
If J(X) is a polynomial in A[X] written as
J (X ) = L a(V)X~ ' ... X;",
then either J = 0, in which case we say that its degree is - 00 , or J =1= 0, and
then we define the degree of J to be the maximum of the degrees of the
monomials M(v)(X) such that a(v) =1= O. (Such monomials are said to occur in
the polynomial.) We note that the degree of J is 0 if and only if
J(X) = aoX? ... X no
for some ao E A, ao =1= O. We also write this polynomial simply f(X) = ao, i.e.
writing 1 instead of
in other words, we identify the polynomial with the constant ao'

II, §3
POLYNOMIALS AND GROUP RINGS
103
Note that a polynomial f(X l' ... , Xn) in n variables can be viewed as a
polynomial in X; with coefficients in A[X1, ... , Xn-1J (if n ~ 2). Indeed, we
can write
d.
f(X) = L h(X1 ,·..,Xn-dXj,
j=O
where h is an element of A[X1 , ... , Xn-1 ]. By the degree of/in X; we shall
mean its degree when viewed as a polynomial in X; with coefficients in
A[X1, ... , Xn-1]. One sees easily that if this degree is d, then d is the largest
integer occurring as an exponent of X; in a monomial
with
a(v) # 0.
Similarly, we define
the degree of f
in each variable Xi
(i = 1,.. ., n).
The degree of f in each variable is of course usually different from its
degree (which is sometimes called the total degree if there is need to prevent
ambiguity). For instance,
has total degree 4, and has degree 3 in Xl and 2 in X 2'
As a matter of notation, we shall often abbreviate" degree" by "deg."
For each integer d ~ 0, given a polynomial f, let pd) be the sum of all
monomials occurring in f and having degree d. Then
Suppose f # 0. We say that f is homogeneous of degree d if f =i'", thus f
can be written in the form
f(X ) = "a
Xv, .. . Xv.
£....,
(v)
1
n
with
if
a(v) # 0.
We shall leave it as an exercise to prove that a non-zero polynomial f in n
variables over A is homogeneous of degree d if and only if, for every set of
n + 1 algebraically independent elements u, tl'
, tn over A we have
f(ut 1 , .. . , utn) = udf(t 1 ,
, tn)'
We note that if f, g are homogeneous of degree d, e respectively, and
fg # 0, then fg is homogeneous of degree d + e. If d = e and f + g # 0, then
f + g is homogeneous of degree d.
Remark.
In view of the isomorphism
A[X1, ... , XnJ::::; A[t1 , ... , tnJ
between the polynomial ring in n variables and a ring generated over A by n

104
RINGS
II. §3
algebraically independent elements, we can apply all the terminology we have
defined for polynomials, to elements of A [tl' ... , tn]. Thus we can speak of
the degree of an element in A [t], and the rules for the degree of a product or
sum hold.
In fact, we shall also call elements of A[t] polynomials in (t).
Algebraically independent elements will also be called variables (or indepen-
dent variables), and any distinction which we make between A[X] and A[t]
is more psychological than mathematical.
Suppose next that A is entire. By what we know of polynomials in one
variable and induction, it follows that A [X l ' ... , X n ] is entire. In particular,
suppose f has degree d and g has degree e. Write
f = pdl + terms of lower degree,
g = e'"+ terms of lower degree.
Then fg = pdlg(el + terms of lower degree, and if fg i= 0 then pdlg(el i= O.
Thus we find:
deg(fg) = deg f + deg g,
deg(f + g) ~ max(deg I. deg g).
We are now finished with the basic terminology of polynomials. We end
this section by indicating how the construction of polynomials is actually a
special case of another construction which is used in other contexts.
Inter-
ested readers can skip immediately to Chapter IV, giving further important
properties of polynomials. See also Exercise 33 of Chapter XIII for har-
monic polynomials.
The group ring or monoid ring
Let A be a commutative ring. Let G be a monoid, written multiplica-
tively.
Let A[G] be the set of all maps a: G -+ A such that a(x) = 0 for almost
all x E G. We define addition in A[G] to be the ordinary addition of
mappings into an abelian (additive) group. If a, PE A[G], we define their
product ap by the rule
(aPHz) = L a(x)p(y).
xy=z
The sum is taken over all pairs (x, y) with x, Y E G such that xy = z. This
sum is actually finite, because there is only a finite number of pairs of
elements (x, y) E G x G such that a(x)p( y) i= O. We also see that (aPHt) = 0
for almost all t, and thus belongs to our set A[G].
The axioms for a ring are trivially verified. We shall carry out the proof
of associativity as an example. Let a, P, y E A[G]. Then

II, §3
POLYNOMIALS AND GROUP RINGS
105
((IX{3)y)(z) = I
(1X{3)(x)y(y)
xy=z
x~z [u~x IX(U){3(V)] y(y)
= x~z L~x IX(U){3(V)y(y)]
= I
IX(U){3(V)Y(Y),
(U, v, y)
uvy=z
this last sum being taken over all triples (u v, y) whose product is z. This
last sum is now symmetric, and if we had computed (a(j3y»(z), we would
have found this sum also . This proves associativity.
The unit element of A [G] is the function
<5 such that
<5(e) = 1 and
<5(x) = 0 for all x E G, x '" e. It is trivial to verify that IX =
<51X =
1X<5 for all
IX E A[G].
We shall now adopt a notation which will make the structure of A[G]
clearer. Let a E A and x E G. We denote by a' x (and sometimes also by ax)
the function whose value at x is a, and whose value at y is 0 if y '" x. Then
an element IX E A[G] can be written as a sum
IX = I
IX(X)' X.
xe G
Indeed, if {ax}xeGis a set of elements of A almost all of which are 0, and we
set
then for any y E G we have {3(y) = ay (directly from the definitions). This also
shows that a given element IX admits a unique expression as a sum I ax.x.
With our present notation, multiplication can be written
and addition can be written
I
ax'x + L bx'x = I
(ax+ bJ ·x,
xeG
xeG
xeG
which looks the way we want it to look. Note that the unit element of A[G]
is simply 1.e.
We shall now see that we can embed both A and G in a natural way in
A[G].
Let qJo: G -+ A[G] be the map given by qJo(x) = 1·x. It is immediately
verified that
qJo is a multiplicative monoid-homomorphism, and is in fact
injective, i.e. an embedding.
Let fo: A -+ A [G] be the map given by
fo(a) = a·e.

106
RINGS
II, §3
It is immediately verified that fo is a ring-homomorphism, and is also an
embedding.
Thus we view A as a subring of A[G]. One calls A[G] the
monoid ring or monoid algebra of G over A, or the group algebra if G is a
group.
Examples.
When G is a finite group and A = k is a field, then the group
ring k[G] will be studied in Chapter XVIII.
Polynomial rings are special cases of the above construction. In n vari-
ables, consider a multiplicative free abelian group of rank n. Let Xl ' .. ., X;
be generators.
Let G be the multiplicative subset consisting of elements
X;' ... x:nwith Vi ~ 0 for all i. Then G is a monoid, and the reader can
verify at once that A [G] is just A [X I' . . . , X n].
As a matter of notation we usually omit the dot in writing an element of
the ring A[G], so we write simply L axx for such an element.
More generally, let I = {i} be an infinite family of indices, and let S be
the free abelian group with free generators X i' written multiplicatively. Then we
can form the polynomial ring A [X] by taking the monoid to consist of products
M(v)(X) = Il xt:
i e 1
where of course all but a finite number of exponents Vi are equal to O. If A is
a subring of the commutative ring B, and S is a subset of B, then we shall
also use the following notation. Let v: S --+ N be a mapping which is 0 except
for a finite number of elements of S. We write
M(v)(S) = Il xv(x).
xeS
Thus we get polynomials in infinitely many variables. One interesting exam-
ple of the use of such polynomials will occur in Artin's proof of the existence
of the algebraic closure of a field, cf. Chapter V, Theorem 2.5.
We now consider the evaluation and reduction homomorphisms in the
present context of monoids.
Proposition 3.1.
Let
cp: G --+ G' be a homomorphism of monoids.
Then
there exists a unique homomorphism h: A[G] --+ A[G'] such that h(x) =
cp(x) for all x E G and h(a) = a for all a EA .
Proof
In fact, let a = L axx E A [G]. Define
h(a) = Laxcp(x).
Then h is immediately verified to be a homomorphism of abelian groups, and
h(x) = cp(x). Let f3 = L byY. Then
h(af3) = ~ C~z axby) cp(z).
We get h(af3) = h(a)h(f3) immediately from the hypothesis that cp(xy) =

II. §4
LOCALIZATION
107
cp(x)cp(y). If e is the unit element of G, then by definition cp(e) = e', so
Proposition 3.1 follows.
Proposition 3.2.
Let G be a monoid and let f: A ~ B be a homomorphism
of commutative rings. Then there is a unique homomorphism
such that
h: A[G] ~ B[G]
h(L axx) =
L
f(ax)x.
x eG
xeG
Proof.
Since every element of A[G] has a unique expression as a sum
Laxx, the formula giving h gives a well-defined map from A[G] into B[G].
This map is obviously a homomorphism of abelian groups. As for multipli-
cation, let
and
Then
h(ap) = JGfC~Z axby)z
=
L L f(ax)f(by)z
ze G xy=z
= h(a)h(p).
We have trivially h(l) = 1, so h is a ring-homomorphism, as was to be
shown.
Observe that viewing A as a subring of A[G], the restriction of h to A is
the homomorphism f itself. In other words, if e is the unit element of G,
then
h(ae) = f(a)e.
§4.
LOCALIZATION
We continue to let A be a commutative ring.
By a multiplicative subset of A we shall mean a submonoid of A (viewed
as a multiplicative monoid according to RI 2). In other words, it is a subset
S containing 1, and such that, if x, YES, then xy E S.
We shall now construct the quotient ring of A by S, also known as the
ring of fractions of A by S.
We consider pairs (a, s) with a E A and s E S. We define a relation
(a, s) '" (a', s')
between such pairs, by the condition that there exists an element SI E S such

108
RINGS
that
II, §4
sl(s'a - sa') = 0.
It is then trivially verified that this is an equivalence relation, and the
equivalence class containing a pair (a, s) is denoted by also The set of
equivalence classes is denoted by s:'A.
Note that if°E S, then s:'A has precisely one element, namely 0/1.
We define a multiplication in s:'A by the rule
(a/sHa'/s') = aa'[ss'.
It is trivially verified that this is well defined . This multiplication has a unit
element, namely 1/1, and is clearly associative.
We define an addition in s:'A by the rule
a
a'
s'a + sa'
- + - = ------,--
s
s'
ss'
It is trivially verified that this is well defined.
As an example, we give the
proof in detail. Let a1/s 1 = ajs, and let a;/s; = a'[s'. We must show that
(s;a1+ sla;)/sls; = (s'a + sa')/ss'.
There exist S2' S3 E S such that
s2(sa1- sla) = 0,
S3(S'a; - s; a') = 0.
We multiply the first equation by S3S'S; and the second by S2SS1 '
We then
add, and obtain
S2S3[s's;(sa1 - sla) + sSl(s'a; - s;a')] = 0.
By definition, this amounts to what we want to show, namely that there
exists an element of S (e.g. S2S3) which when multiplied with
yields 0.
We observe that given a E A and s, s' E S we have
als = s'als's.
Thus this aspect of the elementary properties of fractions still remains true in
our present general context.
Finally, it is also trivially verified that our two laws of composition on
s:'A define a ring structure.
We let
qJs: A ~ S-lA
be the map such that cps(a) = a/I. Then one sees at once that
CPs is a

II, §4
LOCALIZATION
109
ring-homomorphism.
Furthermore, every element of qJs(S) is invertible
In
S-1A (the inverse of s/l is lis).
Let e be the category whose objects are ring-homomorphisms
f : A -+ B
such that for every s E S, the element f(s) is invertible in B. If f: A -+ Band
1': A -+ B' are two objects of e, a morphism 9 of f
into I' is a homo-
morphism
g: B -+ B'
making the diagram commutative:
A~B
\/
B'
We contend that qJs is a universal object in this category e.
Proof
Suppose that ajs = a'[s', or in other words that the pairs (a,s)
and (a', s') are equivalent. There exists S1 E S such that
s1(s'a - sa') = O.
Let f : A -+ B be an object of e. Then
f(sd[f(s')f(a) - f(s)f(a')] = O.
Multiplying by f(S1r 1, and then by f(sT1 and f(sr 1, we obtain
f(a)f(sr1 = f(a ')f(sT1.
Consequently, we can define a map
h: S-1A -+ B
such that h(a/s) = f(a)f(s)-1, for all ats E S-1A. It is trivially verified that h
is a homomorphism, and makes the usual diagram commutative. It is also
trivially verified that such a map h is unique, and hence that qJs is the
required universal object.
Let A be an entire ring, and let S be a multiplicative subset which does not
contain O. Then
is injective.
Indeed, by definition, if a/I = 0 then there exists s E S such that sa = 0,
and hence a = O.
The most important cases of a multiplicative set S are the following:
1. Let A be a commutative ring, and let S be the set of invertible
elements of A (i.e. the set of units). Then S is obviously multiplicative, and is

110
RINGS
II, §4
denoted frequently by A*. If A is a field, then A* is the multiplicative group
of non-zero elements of A. In that case, s:'A is simply A itself.
2. Let A be an entire ring, and let S be the set of non-zero elements of A.
Then S is a multiplicative set, and s:'A is then a field, called the quotient
field or the field of fractions, of A. It is then customary to identify A as a
subset of s:'A, and we can write
als = S- l a
for a E A and s E S.
We have seen in §3 that when A is an entire ring, then A [X l ' ... , X n ] is
also entire. If K is the quotient field of A, the quotient field of A [Xl' .. . , X n ]
is denoted by K(X1 , .. . , X n). An element of K(X 1 , ... , X n) is called a rational
function. A rational function can be written as a quotient f(X)lg(X) where
f, 9 are polynomials. If (h1, ••• , hn) is in x» , and a rational function admits
an expression as a quotient f ig such that g(h) =1= 0, then we say that the
rational function is defined at (h).
From general localization properties, we
see that when this is the case, we can substitute (h) in the rational function to
get a value f(h)/g(h).
3. A ring A is called a local ring if it is commutative and has a unique
maximal ideal. If A is a local ring and m is its maximal ideal, and x E A,
x ¢ m, then x is a unit (otherwise x generates a proper ideal, not contained in m,
which is impossible). Let A be a ring and p a prime ideal. Let S be the com-
plement of pin A. Then S is a multiplicative subset of A, and S-l A is denoted
by Ap • It is a local ring (cf. Exercise 3) and is called the local ring of A at p. Cf.
the examples of principal rings, and Exercises 15, 16.
Let S be a multiplicative subset of A. Denote by J(A) the set of ideals of
A. Then we can define a map
t/Js: J(A) --+ J(S-lA) ;
namely we let t/Js(a) = s:'a be the subset of s: A consisting of all fractions
als with a E a and s E S.
The reader will easily verify that s:'a is an
s:'A-ideal, and that
t/Js is a homomorphism for both the additive and
multiplicative monoid structures on the set of ideals J(A).
Furthermore, t/Js
also preserves intersections and inclusions; in other words, for ideals a, b of
A we have :
S-l(a + b) = S-l a + S-lb,
S-l(ab) = (S-l a)(S-lb),
S-l(a n b) = s:'an s:'b.
As an example, we prove this last relation. Let x E an b. Then xis is in
s:'a and also in s:'b, so the inclusion is trivial.
Conversely, suppose we
have an element of s:'A which can be written as als = his' with a E a, b e b,
and s, s' E S. Then there exists Sl E S such that

II. §5
PRINCIPAL AND FACTORIAL RINGS
111
and this element lies in both a and b. Hence
ajs = sls'a/sls's
lies in S- I(a n b), as was to be shown.
§5.
PRINCIPAL AND FACTORIAL RINGS
Let A be an entire ring. An element a1'O is called irreducible if it is not a
unit, and if whenever one can write a = be with b e A and e E A then b or e
is a unit.
Let a1'O be an element of A and assume that the principal ideal (a) is
prime. Then a is irreducible. Indeed, if we write a = be, then b or e lies in
(a), say b. Then we can write b = ad with some d E A, and hence a = aed.
Since A is entire, it follows that cd = 1, in other words, that e is a unit.
The converse of the preceding assertion is not always true.
We shall
discuss under which conditions it is true. An element a E A, a l' 0, is said to
have a unique factorization into irreducible elements if there exists a unit u
and there exist irreducible elements Pi (i = 1, ... , r) in A such that
r
a = u 11 Pi'
i= 1
and if given two factorizations into irreducible elements,
r
s
a = u 11 Pi = U' 11 qj'
i=1
j=1
we have r = s, and after a permutation of the indices i, we have p j = U jq j for
some unit U j in A, i = 1, ..., r.
We note that if p is irreducible and
U is a unit, then up is also irreducible,
so we must allow multiplication by units in a factorization.
In the ring
of integers Z, the ordering allows us to select a representative irreducible
element (a prime number) out of two possible ones differing by a unit,
namely ±p, by selecting the positive one. This is, of course, impossible in
more general rings.
Taking r = 0 above, we adopt the convention that a unit of A has a
factorization into irreducible elements.
A ring is called factorial (or a unique factorization ring) if it is entire and if
every element l' 0 has a unique factorization into irreducible elements. We
shall pro ve below that a principal entire ring is factorial.
Let A be an entire ring and a, bE A, ab l' O. We say that a divides band
write alb if there exists e E A such that ae = b. We say that d e A, d l' 0, is a
greatest common divisor (g.c.d.) of a and b if dla, dlb, and if any element e
of A , e 4= 0, which divides both a and b also divides d.

112
RINGS
II,§5
Proposition 5.1.
Let A be a principal entire ring and a, b E A, a, b =1= O.
Let (a) + (b) = (c). Then c is a greatestcommon divisor ofa and b.
Proof
Since b lies in the ideal (c), we can write b = xc for some x E A,
so that clb.
Similarly, cia.
Let d divide both a and b, and write a = dy,
b = dz with y, z E A. Since c lies in (a, b) we can write
c = wa + tb
with some w, tEA. Then c = w dy + t dz = d(wy + tz), whence dlc, and our
proposition is proved.
Theorem 5.2.
Let A be a principal entire ring. Then A is factorial.
Proof
We first prove that every non-zero element of A has a factoriza-
tion into irreducible elements. Let S be the set of principal ideals
=1= 0 whose
generators do not have a factorization into irreducible elements, and suppose
S is not empty. Let (ad be in S. Consider an ascending chain
(ad ~ (az) ~ . .. ~ (an) ~ ...
of ideals in S. We contend that such a chain cannot be infinite. Indeed, the
union of such a chain is an ideal of A, which is principal, say equal to (a).
The generator a must already lie in some element of the chain, say (an), and
then we see that (an) c: (a) c: (all), whence the chain stops at (an). Hence S is
inductively ordered, and has a maximal element (a). Therefore any ideal of A
containing (a) and =;6 (a) has a generator admitting a factorization.
We note that a cannot be irreducible (otherwise it has a factorization) ,
and hence we can write a = be with neither b nor c equal to a unit. But then
(b) =;6 (a) and (c) =;6 (a) and hence both b, c admit factorizations into irreducible
elements . The product of these factorizations is a factorization for a, contra-
dicting the assumption that S is not empty.
To prove uniqueness, we first remark that if p is an irreducible element of
A and a, b e A, plab, then pia or plb. Proof:
If p ~ a, then the g.c.d. of p, a
is 1 and hence we can write
1 = xp + ya
with some x, YEA. Then b = bxp + yab, and since plab we conclude that
plb.
Suppose that a has two factorizations
a = PI ... p, = ql ... q.
into irreducible elements. Since PI divides the product farthest to the right,
PI divides one of the factors, which we may assume to be ql after renum-
bering these factors. Then there exists a unit
U I such that ql = UIPI'
We
can now cancel PI from both factorizations and get

II. §5
PRINCIPAL AND FACTORIAL RINGS
113
P2 ... p, = UI q2 .. . q•.
The argument is completed by induction.
We could call two elements a, b e A equivalent if there exists a unit U
such that a = bu.
Let us select one irreducible element p out of each
equivalence class belonging to such an irreducible element, and let us denote
by P the set of such representatives. Let a E A, a =F O. Then there exists a
unit u and integers v(p) ~ 0, equal to 0 for almost all pEP such that
a = u n p,(P).
peP
Furthermore, the unit u and the integers v(p) are uniquely determined by a.
We call v(p) the order of a at p, also written ord, a.
If A is a factorial ring, then an irreducible element p generates a prime
ideal (p). Thus in a factorial ring, an irreducible element will also be called a
prime element, or simply a prime.
We observe that one can define the notion of least common multiple
(I.c.m.) of a finite number of non-zero elements of A in the usual manner: If
aI' ... , an E A
are such elements, we define a l.c.m. for these elements to be any C E A such
that for all primes p of A we have
ord, C = max ord, a..
j
This element C is well defined up to a unit.
If a,b E A are non-zero elements, we say that a, b are relatively prime if
the g.c.d. of a and b is a unit.
Example.
The ring of integers Z is factorial. Its group of units consists
of 1 and - 1. It is natural to take as representative prime element the
positive prime element (what is called a prime number) p from the two
possible choices p and - p. Similarly, we shall show later that the ring of
polynomials in one variable over a field is factorial, and one selects represen-
tatives for the prime elements to be the irreducible polynomials with leading
coefficient 1.
Examples.
It will be proved in Chapter IV that if R is a factorial ring,
then the polynomial ring R [XI' • . . , Xn] in n variables is factorial. In partic-
ular, if k is a field, then the polynomial ring k[XI' ... , Xn] is factorial. Note
that k[XI ] is a principal ring, but for n ~ 2, the ring k[XI , .. . , Xn] is not
principal.
In Exercise 5 you will prove that the localization of a factorial ring is
factorial.
In
Chapter
IV,
§9 we
shall
prove
that
the
power
series
ring
k[[XI , .. . , Xn] ] is factorial. This result is a special case of the more general
statement that a regular local ring is factorial, but we do not define regular
local rings in this book. You can look them up in books on commutative

114
RINGS
II, Ex
algebra. I recommend :
H. MATSUMURA, Commutative Algebra, second edition, Benjamin-Cummings, New
York, 1980
H.
MATSUMURA, Commutative Rings, Cambridge University Press, Cambridge,
UK, 1986
Examples from algebraic and complex geometry.
Roughly speaking, reg-
ular local rings arise in the following context of algebraic or complex geom-
etry.
Consider the ring of regular functions in the neighborhood of some
point on a complex or algebraic manifold. This ring is regular. A typical
example is the ring of convergent power series in a neighborhood of 0 in C .
In Chapter IV, we shall prove some results on power series which give some
algebraic background for those analytic theories, and which are used in
proving the factoriality of rings of power series, convergent or not.
Conversely to the above examples, singularities in geometric theories may
give rise to examples of non-factoriality.
We give examples using notions
which are sufficiently basic so that readers should have encountered them in
more elementary courses.
Examples of non-factorial rings.
Let k be a field, and let x be a variable
over k. Let R = k[x 2, x 3 ]. Then R is not factorial (proof?). The ring R may
be viewed as the ring of regular functions on the curve y2 = x 3, which has a
singularity at the origin, as you can see by drawing its real graph.
Let R be the set of all numbers of the form a + bj=5, where a, b E Z.
Then the only units of Rare ± 1, and the elements 3, 2 + j=5, 2 - j=5
are irreducible elements, giving rise to a non-unique factorization
32 = (2 + j=5)(2 - j=5).
(Do Exercise 10.) Here the non-factoriality is not due to singularities but
due to a non-trivial ideal class group of R, which is a Dedekind ring. For a
definition see the exercises of Chapter III, or go straight to my book
Algebraic Number Theory, for instance.
As Trotter once pointed out (Math. Monthly, April 1988), the relation
sin? x = (1 + cos x)(l - cos x)
may be viewed as a non-unique factorization in the ring of trigonometric
polynomials R[sin x, cos x], generated over R by the functions sin x and
cos x. This ring is a subring of the ring of all functions, or of all differenti-
able functions. See Exercise 11.
EXERCISES
We let A denote a commutative ring.
1. Suppose that 1 #-0 in A. Let S be a multiplicative subset of A not containing O.
Let p be a maximal element in the set of ideals of A whose intersection with S is
empty. Show that p is prime.

II, Ex
EXERCISES
115
2. Let I :A -+ A' be a surjective homomorphism of rings, and assume that A is local,
A' # O. Show that A' is local.
3. Let p be a prime ideal of A. Show that A p has a unique maximal ideal, consisting
of all elements ajs with a e p and s ¢ p.
4. Let A be a principal ring and S a multiplicative subset with 0 ¢ S. Show that S-I A is
principal.
5. Let A be a factorial ring and S a multiplicative subset with 0 ¢ S. Show that S-I A is
factorial, and that the prime elements of S-l A are of the form up with primes p of A
such that (p) n S is empty, and units u in S-I A.
6. Let A be a factorial ring and p a prime element. Show that the local ring AlP) is
principal.
7. Let
A
be a
principal
ring
and
al , • •• , an
non-zero
elements
of
A.
Let
(ai' ... , an) = (d).
Show
that
d is a
greatest
common
divisor
for
the aj
(i = 1,..., n).
8. Let p be a prime number, and let A be the ring Z/p'Z (r = integer ~ 1). Let G be
the group of units in A, i.e. the group of integers prime to p, modulo p', Show
that G is cyclic, except in the case when
p = 2,
r ~ 3,
in which case it is of type (2,2'-2). [Hint:
In the general case, show that G is
the product of a cyclic group generated by 1 + p, and a cyclic group of order
p - 1. In the exceptional case, show that G is the product of the group {± 1}
with the cyclic group generated by the residue class of 5 mod 2'.]
9. Let i be the complex number J=1. Show that the ring Z[i] is principal, and
hence factorial. What are the units?
10. Let D be an integer ~ I, and let R be the set of all elements a + b~ with
a, be Z.
(a) Show that R is a ring.
(b) Using the fact that complex conjugation is an automorphism of C, show
that complex conjugation induces an automorphism of R.
(c) Show that if D ~ 2 then the only units in Rare ±1.
(d) Show that 3, 2 + p, 2 - P
are irreducible elements in Z[Pl
11. Let R be the ring of trigonometric polynomials as defined in the text. Show that
R consists of all functions I on R which have an expression of the form
n
I(x) = ao + L: (am cos mx + bmsin mx),
m=1
where ao, am' bmare real numbers. Define the trigonometric degree degt,(f) to be
the maximum of the integers r, s such that a" b, # O. Prove that
Deduce from this that R has no divisors of 0, and also deduce that the functions
sin x and 1 - cos x are irreducible elements in that ring.

116
RINGS
II, Ex
12. Let P be the set of positive integers and R the set of functions defined on P with
values in a commutative ring K. Define the sum in R to be the ordinary addition
of functions, and define the convolution product by the formula
(f*g)(m) = L f(x)g(y),
.xy=m
where the sum is taken over all pairs (x, y) of positive integers such that xy = m.
(a) Show that R is a commutative ring, whose unit element is the function lJ such
that lJ(I)= 1 and lJ(x)= 0 if x oF 1.
(b) A function f is said to be multiplicative if f(mn) = f(m)f(n) whenever m, n are
relatively prime. Iff, 9 are multiplicative, show that f *9 is multiplicative.
(c) Let p. be the Mobius function such that p.(I)= 1, P.(PI ... p,) =(-If if PI' ... , P,
are distinct primes, and p.(m) =0 if m is divisible by p2 for some prime p.
Show that p.* qJI = lJ, where qJI denotes the constant function having value
1.
[Hint:
Show first that p. is multiplicative, and then prove the assertion
for prime powers.]
The Mobius inversion formula of elementary number
theory is then nothing else but the relation u» qJI *f = f.
Dedekind rings
Prove the following statements about a Dedekind ring o. To simplify terminology,
by an ideal we shall mean non-zero ideal unless otherwise specified. We let K
denote the quotient field of o,
13. Every ideal is finitely generated. [Hint:
Given an ideal a, let b be the fractional
ideal such that ab = o.
Write 1 = Lalhl with ai E a and hi E b.
Show that
a = (ai' ... , an)']
14. Every ideal has a factorization as a product of prime ideals, uniquely determined
up to permutation.
15. Suppose 0 has only one prime ideal p. Let t E P and t ¢ p2. Then p = (t) is
principal.
16. Let 0 be any Dedekind ring. Let p be a prime ideal. Let op be the local ring at
p. Then op is Dedekind and has only one prime ideal.
17. As for the integers, we say that alb (a divides b) if there exists an ideal c such that
b = ac, Prove :
(a) alb if and only if b c a.
(b) Let a, b be ideals. Then a + b is their greatest common divisor. In particular,
a, b are relatively prime if and only if a + b = o.
18. Every prime ideal p is maximal. (Remember, p oF 0 by convention.) In particular,
if PI' .. ., Pn are distinct primes, then the Chinese remainder theorem applies to
their powers p~', .. ., p:". Use this to prove:
19. Let a, b be ideals. Show that there exists an element c E K (the quotient field of
0) such that ca is an ideal relatively prime to b. In particular, every ideal class in
Pic(o) contains representative ideals prime to a given ideal.
For a continuation, see Exercise7 of Chapter VII; Chapter III, Exercise 11-13 .

CHAPTER III
Modules
Although this chapteris logicall y self-contained and prepares for future topics,
in practice readers will have had some acquaintance with vector spaces over a
field. We generalize this notion here to modules over rings. It is a standard fact
(to be reproved) that a vector space has a basis, but for modules this is not always
the case . Sometimes they do; most often they do not. We shall look into cases
where they do.
For examples of modules and their relations to those which have a basis, the
reader should look at the comments made at the end of §4.
§1.
BASIC DEFINITIONS
Let A be a ring. A left module over A, or a left A-module M is an abelian
group, usually written additively, together with an operation of A on M (viewing
A as a multiplicative monoid by RI 2), such that, for all a, b E A and x, y E M
we have
(a + b)x = ax + bx
and
a(x + y) = ax + ay.
We leave it as an exercise to prove that a(- x) =
- (ax) and that Ox = O.. By
definition of an operation, we have lx = x.
In a similar way, one defines a right A-module. We shall deal only with left
A-modules, unless otherwise specified, and hence call these simply A-modules,
or even modules if the reference is clear.
117
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

118
MODULES
III, §1
Let M be an A-module. By a submodule N of M we mean an additive sub-
group such that AN c N. Then N is a module (with the operation induced by
that of A on M).
Examples
We note that A is a module over itself.
Any commutative group is a Z-module.
An additive group consisting of 0 alone is a module over any ring.
Any left ideal of A is a module over A.
Let J be a two-sided ideal of A. Then the factor ring AIJ is actually a module
over A. If a E A and x + J is a coset of J in A, then one defines the operation
to be a(x + J) = ax + J. The reader can verify at once that this defines a module
structure on AIJ. More general, if M is a module and N a submodule, we shall
define the factor module below. Thus if L is a left ideal of A , then AlLis also
a module. For more examples in this vein , see §4.
A module over a field is called a vector space. Even starting with vector
spaces, one is led to consider modules over rings . Indeed, let V be a vector space
over the field K. The reader no doubt already knows about linear maps (which
will be recalled below systematically). Let R be the ring of all linear maps of V
into itself. Then V is a module over R. Similarly, if V = K" denotes the vector
space of (vertical) n-tuples of elements of K , and R is the ring of n x n matrices
with components in K , then V is a module over R. For more comments along
these lines, see the examples at the end of §2.
Let S be a non-empty set and M an A-module. Then the set of maps
Map(S , M) is an A-module . We have already noted previously that it is a com-
mutative group, and for f
E Map(S, M ), a E A we define af to be the map
such that (af>(s) = af(s). The axioms for a module are then trivially verified.
For further examples, see the end of this section.
For the rest of this section, we deal with a fixed ring A, and hence may omit
the prefix A-.
Let A be an entire ring and let M be an A-module. We define the torsion
submodule Mtor to be the subset of elements x E M such that there exists
a E A, a '* 0 such that ax = O.It is immediately verified that Mtor is a submodule.
Its structure in an important case will be determined in §7.
Let a be a left ideal, and M a module. We define aM to be the set of all
elements
with a, E a and Xi E M. It is obviously a submodule of M . If a, b are left ideals,
then we have associativity, namely
a(bM) = (ab)M.

III, §1
BASIC DEFINITIONS
119
We also have some obvio us distributivities, like (a + b)M = aM + bM. If
N, N' are submodules of M , then a(N + N') = aN + «N'.
Let M be an A-module, and N a submodule. We shall define a module
structure on the factor group MIN (for the additive group structure). Let
x + N be a coset of N in M, and let a E A. We define a(x + N) to be the
coset ax + N. It is trivial to verify that this is well defined (i.e. if y is in the
same coset as x, then aJ' is in the same coset as ax), and that this is an opera-
tion of A on MIN satisfying the required condition, making MIN into a
module, called the factor module of M by N.
By a module-homomorphism one means a map
f :M -+ M'
of one module into another (over the same ring A), which is an additive group-
homomorphism, and such that
f(ax) = af(x)
for all a E A and x E M. It is then clear that the collection of A-modules is a
category, whose morphisms are the module-homomorphisms usually also
called homomorphisms for simplicity, if no confu sion is possible. If we wish
to refer to the ring A, we also say that f is an A-homomorphism, or also that
it is an A-linear map.
If M is a module, then the identity map is a homomorphism. For any
module M', the map ( : M -+ M' such that ( x) = 0 for all x E M is a homo-
morphism, called zero.
In the next section, we shall discuss the homomorphisms of a module into
itself, and as a result we shall give further examples of modules which arise in
practice. Here we continue to tabulate the translation ofbasic properties of groups
to modules.
Let M be a module and N a submodule. We have the canonical additive
group-homomorphism
f :M -+ MIN
and one verifies trivially that it is a module-homomorphism.
Equally trivially, one verifies that f is universal in the category of homo-
morphisms of M whose kernel contains N.
If f :M -+ M' is a module-homomorphism, then its kernel and image are
submodules ofM and M' respectively (trivial verification).
Letf: M ~ M ' be a homomorphism. By the cokernel offwe mean the factor
module M,/Imf = M'/fCM). One may also mean the canonical homomorphism

120
MODULES
III, §1
M' ~ M,/f(M) rather than the module itself. The context should make clear
which is meant. Thus the cokernel is a factor module of M' .
Canonical homomorphisms discussed in Chapter I, §3 apply to modules
mutatis mutandis. For the convenience of the reader, we summarise these
homomorphisms:
Let N, N' be two submodules of a module M . Then N + N' is also a sub-
module, and we havean isomorphism
NI(N n N') ~ (N + N')IN'.
IfM
:::::> M' :::::> Mil are modules, then
(MIM")/(M'IM") ~ MIM'.
Iff :M --+ M ' is a module-homomorphism, and N' is a submodule of M', then
f - '(N') isa submodule ofM andwehavea canonical injective homomorphism
! :Mlf-'(N') --+ M'IN'.
Iffis surjective, then!is a module-isomorphism.
The proofs are obtained by verifying that all homomorphisms which ap-
peared when dealing with abelian groups are now A-homomorphisms of
modules. We leave the verification to the reader.
As with groups, we observe that a module-homomorphism which is bijective
is a module-isomorphism. Here again, the proof is the same as for groups,
adding only the observation that the inverse map, which we know is a group-
isomorphism, actually is a module-isomorphism. Again, we leave the verifica-
tion to the reader.
As with abelian groups, we define a sequence of module-homomorphisms
M' £ M.!!. Mil
to be exact if Imf = Ker g. We have an exact sequence associated with a
submodule N of a module M, namely
0--+ N --+ M --+ MIN --+ 0,
the map of N into M being the inclusion, and the subsequent map being the
canonical map. The notion of exactness is due to Eilenberg-Steenrod.
If a homomorphism u: N --+ M is such that
O--+N~M
is exact, then we also say that u is a monomorphism or an embedding. Dually,
if
is exact, we say that u is an epimorphism.

III, §1
Algebras
BASIC DEFINITIONS
121
There are some things in mathematics which satisfy all the axioms of a ring
except for the existence of a unit element. We gave the example of LI(R) in
Chapter II, §1. There are also some things which do not satisfy associativity,
but satisfy distributivity. For instance let R be a ring, and for x, y E R define
the bracket product
[x, y] = xy -
yx .
Then this bracket product is not associative in most cases when R is not com-
mutative, but it satisfies the distributive law.
Examples.
A typical example is the ring of differential operators with C '
coefficients, operating on the ring of Coo functions on an open set in R ". The
bracket product
[D1, D2] = D 1 0 D2 -
D2 0 D 1
of two differential operators is again a differential operator. Inthe theory of Lie
groups, the tangent space at the origin also has such a bracket product.
Such considerations lead us to define a more general notion than a ring. Let
A be a commutative ring . Let E, F be modules. By a bilinear map
g: E x E~ F
we mean a map such that given x E E, the map y ~ g(x, y) is A-linear, and
given y E E, the map x ~ g(x, y) is A-linear. By an A-algebra we mean a
module together with a bilinear map g : E x E ~ E. We view such a map as a
law of composition on E. But in this book, unless otherwise specified, we shall
assume that our algebras are associative and have a unit element.
Aside from the examples already mentioned, we note that the group ring
A[G] (or monoid ring when G is a monoid) is an A-algebra, also called the group
(or monoid) algebra . Actually the group algebra can be viewed as a special
case of the following situation.
Let I : A ~ B be a ring-homomorphism such that I(A) is contained in the
center of B , i.e .,j(a) commutes with every element of B for every a EA . Then
we may view B as an A-module, defining the operation of A on B by the map
(a, b) ~ I(a)b
for all a E A and b E B. The axioms for a module are trivially satisfied, and the
multiplicative law of composition B x B ~ B is clearly bilinear (i.e., A-bilinear) .
In this book, unless otherwise specified, by an algebra over A, we shall always
mean a ring-homomorphism as above . We say that the algebra is finitely gen-
erated if B is finitely generated as a ring over I(A) .
Several examples of modules over a polynomial algebra or a group algebra
will be given in the next section, where we also establish the language of
representations.

122
MODULES
§2.
THE GROUP OF HOMOMORPHISMS
III, §2
Let A be a ring, and let X, X' be A-modules. We denote by HomA(X', X)
the set of A-homomorphisms of X' into X. Then HomA(X', X) is an abelian
group, the law of addition being that of addition for mappings into an abelian
group.
If A is commutative then we can make HomA(X', X) into an A-module, by
defining affor a E A and j s HomA(X', X) to be the map such that
(af)(x) = af(x).
The verification that the axioms for an A-module are satisfied is trivial. However,
if A is not commutative, then we view HomA(X', X) simply as an abelian group.
We also view HomAas a functor. It is actually a functor of two variables,
contravariant in the first and covariant in the second. Indeed, let Y be an
A-module, and let
be an A-homomorphism. Then we get an induced homomorphism
Homif, Y) :HomA(X, Y) -+ HomA(X', Y)
(reversing the arrow!) given by
This is illustrated by the following sequence of maps :
X'1. X s. Y.
The fact that HomA(f, Y) is a homomorphism is simply a rephrasing of the
property (gl + g2) 0 f = gl
0 f + g2 0 f, which is trivially verified. If f = id,
then composition withfacts as an identity mapping on g, i.e. g 0 id = g.
If we have a sequence of A-homomorphisms
X' -+ X -+ X",
then we get an induced sequence
HomA(X', Y) +- HomA(X, Y) +- HomA(X", Y).
Proposition 2.1.
A sequence
X' ~ X -+ X" -+ 0
is exact if and only if the sequence
HomA(X', Y) +- HomA(X, Y) +- HomA(X", Y) +- 0
is exact for all Y.

III, §2
THE GROUP OF HOMOMORPHISMS
123
Proof
This is an important fact, whose proof is easy.
For instance,
suppose the first sequence is exact. If 9 : X" -> Y is an A-homomorphism, its
image in HomA(X, Y) is obtained by composing 9 with the surjective map of
X on X". If this composition is 0, it follows that 9 = 0 because X -> X" is
surjective. As another example, consider a homomorphism g : X -> Y such
that the composition
X' ~X.!!..Y
is O. Then 9 vanishes on the image of A. Hence we can factor 9 through the
factor module,
Since X -> X" is surjective, we have an isomorphism
X/1m A+-+ X" .
Hence we can factor 9 through X", thereby showing that the kernel of
HomA(X', Y) +- HomA(X, Y)
is contained in the image of
The other conditions needed to verify exactness are left to the reader. So is the
converse.
We have a similar situation with respect to the second variable, but then
the functor is covariant. Thus if X is fixed, and we have a sequence of A-
homomorphisms
Y' -> Y -> Y",
then we get an induced sequence
Proposition 2.2.
A sequence
0-> Y' -> Y -> Y",
is exact ifand only if
0-> HomA(X, r") -> HomA(X, Y) -> HomA(X, Y")
is exact for all X.

124
MODULES
III, §2
The verification will be left to the reader. It follows at once from the defini-
tions.
We note that to say that
0-+ y ' -+ Y
is exact means that Y' is embedded in Y, i.e. is isomorphic to a submodule of
Y. A homomorphism into Y' can be viewed as a homomorphism into Y if we
have Y' c Y. This corresponds to the injection
0-+ HomA(X, y') -+ HomA(X, Y).
Let Mod(A) and Mod(B) be the categories of modules over rings A and B,
and let F : Mod(A) -+ Mod(B) be a functor.
One says that F is exact if F
transforms exact sequences into exact sequences.
We see that the Hom
functor in either variable need not be exact if the other variable is kept fixed.
In a later section, we define conditions under which exactness is preserved.
Endomorphisms.
Let M be an A-module. From the relations
and its analogue on the right, namely
and the fact that there is an identity for composition, namely idM , we conclude
that HomA(M, M) is a ring, the multiplication being defined as composition
of mappings. If n is an integer
~ 1, we can write [ " to mean the iteration
of f with itself n times, and define r to be id. According to the general
definition of endomorphisms in a category, we also write End, (M) instead of
HomA(M , M) , and we call EndA(M ) the ring of endomorphisms.
Since an A-module M is an abelian group, we see that Homz(M, M) (= set
of group-homomorphisms of M into itself) is a ring, and that we could have
defined an operation of A on M to be a ring-homomorphism A -+ Homz(M, M).
Let A be commutative. Then M is a module over EndA(M). If R is a subring
of End;(M) then M is a fortiori a module over R. More generally, let R be a
ring and let p: R ~ EndA(M) be a ring homomorphism. Then p is called a
representation of Ron M . This occurs especially if A = K is a field. The linear
algebra of representations of a ring will be discussed in Part III, in several
contexts, mostly finite-dimensional . Infinite-dimensional examples occur in anal-
ysis, but then the representation theory mixes algebra with analysis, and thus
goes beyond the level of this course.
Example.
Let K be a field and let V be a vector space over K. Let
D:
V ~
V be an endomorphism (K-linear map) . For every polynomial
P(X) E K[X] , P(X) = La;X; with a; E K , we can define

III, §2
THE GROUP OF HOMOMORPHISMS
125
P(D ) = La;Di: V~ V
as an endomorphism of V. The association P(X ) ~ P(D ) gives a representation
p: K[ X] ~ EndK(V),
which makes V into a K[X]-module. It will be shown in Chapter IV that K[X]
is a principal ring . In §7 we shall give a general structure theorem for modules
over principal rings, which will be applied to the above example in the context
of linear algebra for finite-dimensional vector space s in Chapter XIV , §3. Readers
acquainted with basic linear algebra from an undergraduate course may wish to
read Chapter XIV alread y at this point.
Examples for infinite-dimensional vector spaces occur in analysis. For
instance, let V be the vector space of complex-valued CCfunctions on R . Let
D = d/dt be the derivative (if t is the variable). Then D : V ~ V is a linear map ,
and C[X] has the repre sentation p: C[X] ~ EndC<V) given by P ~ P(D) . A
similar situation exists in several variables , when we let V be the vector space
of Coo functions in n variables on an open set of R ". Then we let D, = a/ati be
the partial derivative with respect to the i-th variable (i = I, .. . , n) . We obtain
a representation
such that p(Xi ) = Di .
Example. Let H be a Hilbert space and let A be a bounded hermitian oper-
ator on A. Then one considers the homomorphism R[X] ~ R[A] C End(H ),
from the polynomial ring into the algebra of endomorphisms of H , and one
extends this homomorphism to the algebra of continuous functions on the spec-
trum of A . C/. my Real and Functional Analysis, Springer Verlag, 1993.
Representations form a category as follow s. We define a morphism of a
repre sentation p: R ~ EndA(M ) into a representation p' : R ~ EndA(M ' ), or in
other words a homomorphism of one representation of R to another, to be
an A-module homomorphism h: M ~ M' such that the following diagram is
commutative for every a E R:
M~M '
P<Cl»
)P'<Cl>
M ------;;-- M'
In the case when h is an isomorphism, then we may replace the above diagram
by the commutative diagram

126
MODULES
III, §2
where the symbol [h] denotes conjugation by h, i.e. for / E EndA(M ) we have
[h]f= h
%
h- I .
Representations: from a monoid to the monoid algebra.
Let G be a
monoid. By a representation of G on an A-module M, we mean a homomor-
phism p: G ~ EndA(M) of G into the multiplicative monoid of EndA(M). Then
we may extend p to a homomorphism of the monoid algebra
A[G] ~ EndA(M),
by letting
p( 2: axx) = 2: axp(x).
xeG
xeG
Itis immediately verified that this extension of ptoA[G] is a ring homomorphism,
coinciding with the given p on elements of G.
Examples: modules over a group ring.
The next examples will follow a
certain pattern associated with groups of automorphisms. Quite generally, sup-
pose we have some category of objects , and to each object K there is associated
an abelian group F(K) , functorially with respect to isomorphisms. This means
that if a : K ~ K' is an isomorphism, then there is an associated isomorphism
F(a): F(K) ---+ F(K') such that F(idK ) = idK , and F(ar) = F(a)
0 F(r). Then
the group of automorphisms Aut(K) of an object operates on F(K); that is,
we have a natural homomorphism
Aut(K) ~ Aut(F(K)) given by
a H
F(a).
Let G = Aut(K). Then F(K) (written additively) can be made into a module
over the group ring Z[G] as above . Given an element a = 2: aua E Z[G], with
au E Z, and an element x E F(K), we define
ax = 2: auF(a)x.
The conditions defining a module are trivially satisfied. We list several concrete
cases from mathematics at large, so there are no holds barred on the terminology.
Let K be a number field (i.e. a finite extension of the rational numbers). Let
G be its group of automorphisms. Associated with K we have the following
objects:
the ring of algebraic integers
OK ;
the group of units ok;
the group of ideal classes C(K);
the group of roots of unity fL(K).
Then G operates on each of those objects, and one problem is to determine the
structure of these objects as Z[G]-modules. Already for cyclotomic fields this

III, §3
DIRECT PRODUCTS AND SUMS OF MODULES
127
determination gives rise to substantial theories and to a number of unsolved
problems.
Suppose that K is a Galois extension of k with Galois group G (see Chapter
VI). Then we may view K itself as a module over the group ring k[ G] . In Chapter
VI, §13 we shall prove that K is isomorphic to k[G] as module over k[G] itself.
In topology, one considers a spaceX; and a finite coveringX. Then Aut(X/Xo)
operates on the homology of X, so this homology is a module over the group
ring.
With more structure , suppose that X is a projective non-singular variety , say
over the complex numbers. Then to X we can associate:
the group of divisor classes (Picard group) Pic(X);
in a given dimension , the group of cycle classes or Chow group CHP(X);
the ordinary homology of X;
the sheaf cohomology in general.
If X is defined over a field K finitely generated over the rationals , we can
associate a fancier cohomology defined algebraically by Grothendieck, and func-
torial with respect to the operation of Galois groups.
Then again all these objects can be viewed as modules over the group ring
of automorphism groups, and major problems of mathematics consist in deter-
mining their structure. I direct the reader here to two surveys, which contain
extensive bibliographies.
[CCFT 91]
P. CAssou-NoGUES, T. CHINBURG,
A.
FROHLICH, M. J. TAYLOR,
L-functions and Galois modules, in L-functions and Arithmetic 1. Coates
and M. J. Taylor (eds.), Proceedings ofthe Durham Symposium July 1989,
London Math, Soc. Lecture Note Series 153, Cambridge University Press
(1991), pp. 75-139
[La 821
S. LANG, Units andclass groups in number theory and algebraic geometry,
Bull . AMS Vol. 6 No.3 (1982), pp. 253-316
§3.
DIRECT PRODUCTS AND
SUMS OF MODULES
Let A be a ring. Let {MiLE! be a family of modules. We defined their direct
product as abelian groups in Chapter I, §9. Given an element (Xi)iEl of the direct
product, and a E A, we define a(xi) = (axi) ' In other words, we multiply by an
element a componentwise. Then the direct product f1M i is an A-module. The
reader will verify at once that it is also a direct product in the category of
A-modules.

128
MODULES
Similarly, let
M = EBMi
ieI
III, §3
be their direct sum as abelian groups. We define on M a structure of A-module:
If (XJi eI is an element of M, i.e. a family of elements Xi E M, such that Xi = 0
for almost all i, and if a E A, then we define
that is we define multiplication by a componentwise. It is trivially verified that
this is an operation of A on M which makes M into an A-module. If one refers
back to the proofgiven for the existence of direct sums in the category of abelian
groups, one sees immediately that this proof now extends in the same way to
show that M is a direct sum of the family {MiLe I as A-modules. (For instance,
the map
Aj: Mj -+ M
such that Aix) has j-th component equal to X and i-th component equal to 0
for i #- j is now seen to be an A-homomorphism.)
This direct sum is a coproduct in the category of A-modules. Indeed,
the reader can verify at once that given a family of A-homomorphisms
{fi : M, -7 N}, the mapf defined as in the proof for abelian groups is also an A-
isomorphism and has the required properties. See Proposition 7.1 of Chapter I.
When I is a finite set, there is °a useful criterion for a module to be a direct
product.
Proposition 3.1.
Let M be an A-module and n an integer
~ 1. For each
i = 1, ... , n let ({Ji : M -+ M be an A-homomorphism such that
nL ({Ji = id
and
({Ji a ({Jj = 0
i = 1
ifi #- j .
Then ({Jf = <pdorall i. Let M , =
({Ji(M), and let ({J: M -+ TI M, be such that
({J(x) = (({Jl(X), • .• , ({In(x)).
Then ({J is an A-isomorphism ofM onto the direct product TI Mi'
Proof
For eachj, we have
n
({Jj = ({Jjaid = ({Jja L ({Ji = ({Jj 0 ({Jj = ({Jt,
i= 1
thereby proving the first assertion. It is clear that ({J is an A-homomorphism.
Let X be in its kernel. Since
n
X = id(x) = L ({Ji(X)
i = 1

III, §3
DIRECT PRODUCTS AND SUMS OF MODULES
129
we conclude that x = 0, so cp is injective.
Given elements Yi E M, for each
i = 1, . . . , n, let x = Yl + ... + Yn'
We obviously have CPiYi) = 0 if i =1= j.
Hence
for eachj = I, .. . , n. This proves that cp is surjective, and concludes the proof
of our proposition.
We observe that when I is a finite set, the direct sum and the direct product
are equal.
Just as with abelian groups, we use the symbol EEl to denote direct sum.
Let M be a module over a ring A and let S be a subset of M. By a linear
combination of elements of S (with coefficients in A) one means a sum
where {ax} is a set of elements of A, almost all of which are equal to O. These
elements ax are called the coefficients of the linear combination.
Let N be
the set of all linear combinations of elements of S. Then N is a submodule of
M, for if
are two linear combinations, then their sum is equal to
L(ax + bJx,
x eS
and if C E A, then
and these elements are again linear combinations of elements of S. We shall call
N the submodule generated by S, and we call S a set of generators for N. We
sometimes write N = A<S). IfSconsists of one element x, the module generated
by x is also written Ax, or simply (x), and sometimes we say that (x) is a principal
module.
A module M is said to be finitely generated, or of finite type, or finite over
A, if it has a finite number of generators.
A subset S of a module M is said to be linearly independent (over A) if when-
ever we have a linear combination

130
MODULES
III, §3
which is equal to 0, then ax = °for all XES. If S is linearly independent and if
two linear combinations
are equal, then ax = b, for all XES. Indeed, subtracting one from the other
yields L (ax - bx)x = 0, whence ax - b, =°for all x. If S is linearly indepen-
dent we shall also say that its elements are linearly independent. Similarly, a
family {xiLeI of elements of M is said to be linearly independent if whenever we
have a linear combination
LaiXi = 0,
i e l
then a, = °for all i. A subset S (resp. a family {Xi}) is called linearly dependent
if it is not linearly independent, i.e. if there exists a relation
La.» = ° resp.
xeS
LaiXi = °
i e l
with not all ax (resp. a;) = 0. Warning. Let x be a single element of M which
is linearly independent. Then the family {xiL=l ,....n such that Xi = x for all i
is linearly dependent if n > 1, but the set consisting of x itself is linearly inde-
pendent.
Let M be an A-module, and let {MJieI be a family of submodules. Since
we have inclusion-homomorphisms
we have an induced homomorphism
which is such that for any family of elements (X;)ieI , all but a finite number of
which are 0, we have
,1AX;)) = LXi'
i e I
If ,1* is an isomorphism, then we say that the family {MiLeI is a direct sum
decomposition of M. This is obviously equivalent to saying that every element
of M has a unique expression as a sum
with Xi EM;, and almost all Xi = 0. By abuse of notation, we also write
M = EBM;
in this case.

III, §3
DIRECT PRODUCTS AND SUMS OF MODULES
131
If the family {MJ is such that every element of M has some expression as a
sum LXi (not necessarily unique), then we write M = LMi' In any case, if
{MJ is an arbitrary family of submodules, the image of the homomorphism ,1*
above is a submodule of M, which will be denoted by LMi'
If M is a module and N , N' are two submodules such that N + N' = M
and N n N' = 0, then we have a module-isomorphism
M;:::: N EEl N',
just as with abelian groups, and similarly with a finite number of submodules.
We note, of course, that our discussion of abelian groups is a special case
of our discussion of modules, simply by viewing abelian groups as modules
over Z. However, it seems usually desirable (albeit inefficient) to develop first
some statements for abelian groups, and then point out that they are valid
(obviously) for modules in general.
Let M, M', N be modules. Then we have an isomorphism of abelian groups
and similarly
The first one is obtained as follows. Iff: M EEl M' --> N is a homomorphism,
thenfinduces a homomorphismj', : M --> N and a homomorphismj, : M' --> N
by composing f with the injections of M and M' into their direct sum re-
spectively:
M --> M EEl {O} c M EEl M' ~ N,
M' --> {O} EEl M' c M EEl M' ~ N.
We leave it to the reader to verify that the association
gives an isomorphism as in the first box. The isomorphism in the second box
is obtained in a similar way. Given homomorphisms
and
L: N --> M'

132
MODULES
we have a homomorphism f : N --+ M x M' defined by
f(x) = Ul(X),fz(X)).
It is trivial to verify that the association
III, §3
gives an isomorphism as in the second box.
Of course, the direct sum and direct product of two modules are isomorphic,
but we distinguished them in the notation for the sake of functoriality , and to
fit the infinite case, see Exercise 22.
Proposition 3.2.
Let 0 --+ M' .!.. M .J4 M" --+ 0 be an exact sequence of
modules. The following conditions are equivalent:
1. There exists a homomorphism <p : M" --+ M such that g 0 tp = id.
2. There exists a homomorphism t/J: M --+ M' such that t/J of = id.
If these conditions are satisfied, then we have isomorphisms :
M = 1mfEEl Ker t/J,
M = Ker g EEl 1m <p,
M ~ M'EElM".
Proof.
Let us write the homomorphisms on the right:
M #. M " --+ O.
'"
Let x E M. Then
x -
<p(g(x))
is in the kernel of g, and hence M = Ker g + 1m <po
This sum is direct, for if
x= y+ z
with y E Ker g and z E 1m <p, z = <pew) with WE M", and applying g yields
g(x) = w. Thus w is uniquely determined by x, and therefore z is uniquely
determined by x. Hence so is y, thereby proving the sum is direct.
The arguments concerning the other side of the sequence are similar and
will be left as exercises, as well as the equivalence between our conditions. When
these conditions are satisfied, the exact sequence of Proposition 3.2 is said to
split. One also says that !/J splitsf and cp splits g.

III, §3
Abelian categories
DIRECT PRODUCTS AND SUMS OF MODULES
133
Much in the theory of modules over a ring is arrow-theoretic. In fact, one
needs only the notion of kernel and cokernel (factor modules). One can axi-
omatize the special not ion of a category in which many of the arguments are
valid, especially the arguments used in this chapter. Thus we give this axi-
omatization now, although for concreteness, at the beginning of the chapter,
we continue to use the language of modules. Readers should strike their own
balance when they want to slide into the more general framework.
Consider first a category Q such that Mor(E, F) is an abelian group for
each pair of objects E, F of Q, satisfying the following two conditions:
AB 1.
The law of composition of morphisms is bilinear, and there exists
a zero object 0, i.e.such that Mor(O, E) and Mor(E, 0) have precisely
one element for each object E.
AB 2.
Finite products and finite coproducts exist in the category.
Then we say that Q is an additive category.
Given a morphism E .!... F in Q, we define a kernel off to be a morphism
E' --+ E such that for all objects X in the category, the following sequence is
exact :
0--+ Mor(X, E') --+ Mor(X, E) --+ Mor(X, F).
We define a cokernel for fto be a morphism F --+ F" such that for all objects X
in the category, the following sequence is exact :
o~ Mor(F", X) ~ Mor(F, X) ~ Mor(E, X) .
It is immediately verified that kernels and cokernels are universal in a suitable
category, and hence uniquely determined up to a unique isomorphism if they
exist.
AB 3.
Kernels and cokernels exist.
AB 4.
Iff: E --+ F is a morphism whose kernel is 0, thenf is the kernel
of its cokernel. If.r : E --+ F is a morphism whose cokernel is 0,
then f is the cokernel of its kernel.
A morphism whose kernel
and cokernel are 0 is an isomorphism.
A category Q satisfying the above four axioms is called an abelian category.
In an abelian caegory, the group of morphisms is usually denoted by Hom,
so for two objects E, F we write
Mor(E, F) = Hom(E, F).
The morphisms are usually called homomorphisms. Given an exact sequence
0--+ M' --+ M,

134
MODULES
III, §3
we say that M ' is a subobject of M , or that the homomorphism of M ' into M is a
monomorphism . Dually, in an exact sequence
M ...... M" ...... O,
we say that M " is a quotient object of M , or that the homomorphism of M to
M" is an epimorphism, instead of saying that it is surjective as in the category of
modules. Although it is convenient to think of modules and abelian groups to
construct proofs, usually such proofs will invol ve onl y arrow-theoretic argu-
ments, and will therefore apply to any abelian category. However, all the abelian
categories we shall meet in this book will have elements, and the kernels and
cokernels will be defined in a natural fashion , close to those for modules , so
readers may restrict their attention to these concrete cases.
Examples of abelian categories. Of course, modules over a ring form an
abelian category, the most common one. Finitely generated modules over a
Noetherian ring form an abelian category, to be studied in Chapter X.
Let k be a field. We consider pairs (V, A) consisting of a finite-dimensional
vector space V over k, and an endomorphism A: V ~ V. By a homomorphism
(morphism) of such pairs j: (V , A) ~ (W, B) we mean a k-homomorphism
j: V ~ W such that the following diagram is commutative:
V ----+ W
f
It is routinely verified that such pairs and the above defined morphisms form an
abelian category. Its elements will be studied in Chapter XIV .
Let k be a field and let G be a group. Let Modk(G) be the category of finite-
dimensional vector spaces V over k, with an operation of G on V, i.e. a homo-
morphism G ~ Autk(V). A homomorphism (morphism) in that category is a k-
homomorphismj: V ~ W such thatj(ax) = aj(x) for all x E V and a E G. It
is immediate that Modk(G) is an abelian category. This category will be studied
especially in Chapter XVIII.
In Chapter XX, §I we shall consider the category of complexes of modules
over a ring . This category of complexes is an abelian category.
In topology and differential geometry, the category of vector bundles over
a topological space is an abelian category.
Sheaves of abelian groups over a topological space form an abelian category,
which will be defined in Chapter XX, §6.

III, §4
§4.
FREE MODULES
FREE MODULES
135
Let M be a module over a ring A and let S be a subset of M. We shall say that
S is a basisof M if S is not empty, ifS generates M, and ifS is linearly independent.
If S is a basis of M, then in particular M i= {O} if A i= {O} and every element of
M has a unique expression as a linear combination of elements of S. Similarly,
let {XJie1 be a non-empty family of elements of M. We say that it is a basisof
M if it is linearly independent and generates M.
If A is a ring, then as a module over itself, A admits a basis, consisting of the
unit element I.
Let I be a non-empty set, and for each i E I, let Ai = A, viewed as an A-
module. Let
Then F admits a basis, which consists of the elements e, of F whose i-th com-
ponent is the unit element of Ajo and having all other components equal to O.
By a free module we shall mean a module which admits a basis, or the zero
module.
Theorem4.1.
Let A be a ringand M a module over A. Let I be a non-empty
set, and let {XJiel be a basis of M. Let N be an A-module, and let {yJiel
be a family of elements of N. Then there exists a unique homomorphism
f :M -> N such that f(xJ = Yi for all i.
Proof
Let x be an element of M. There exists a unique family {aiLel of
elements of A such that
We define
It is then clear that f is a homomorphism satisfying our requirements, and
that it is the unique SUCh, because we must have
f(x) = LaJ(xJ
Corollary 4.2.
Let the notation be as in the theorem, andassume that {yJiel
is a basis of N. Then the homomorphism f is an isomorphism, i.e. a module-
isomorphism.
Proof
By symmetry, there exists a unique homomorphism
g :N->M

136
MODULES
III, §4
such that g(y;) = Xi for all i, and f og and g ofare the respective identity map-
pings.
Corollary 4.3.
Two modules having bases whose cardinalities are equalare
isomorphic.
Proof
Clear.
We shall leave the proofs of the following statements as exercises.
Let M be a free module over A, with basis {xiLe f ' so that
M = EBAxi'
iel
Let a be a two sided ideal of A. Then aM is a submodule of M. Each nr, is a
submodule of AXi' We have an isomorphism (of A-modules)
M/aM :::::: EB Axi/axi'
i e I
Furthermore, each Axfax, is isomorphic to A/a, as A-module.
Supposein addition that A is commutative. Then A/a is a ring. Furthermore
M/aM is afree moduleover A/a, andeachAxi/axi isfree overA/a. IfXi is the
imageofXi under the canonical homomorphism
then the singleelement Xi is a basis of Ax.kxx, over A/a.
All of these statements should be easily verified by the reader. Now let A be
an arbitrary commutative ring. A module M is called principal if there exists
an element X E M such that M = Ax. The map
a H
ax (for a E A)
is an A-module homomorphism of A onto M, whose kernel is a left ideal a, and
inducing an isomorphism of A-modules
A/a = M.
Let M be a finitely generated module, with generators {VI"' " vn } . Let F
be a free module with basis {e., ... , en}. Then there is a unique surjective
homomorphismf: F~ M such that j'(e.) = Vi' The kernel offis a submodule
MI ' Under certain conditions, M1 is finitely generated (ef. Chapter X, §l on
Noetherian rings), and the process can be continued. The systematic study of
this process will be carried out in the chapters on resolutions of modules and
homology.

III, §4
FREE MODULES
137
Of course, even if M is not finitely generated, one can carry out a similar
construction, by using an arbitrary indexing set. Indeed, let {v;} (i E l) be a family
of generators. For each i , let F,be free with basis consisting of a single element
e., so F, = A. Let F be the direct sum of the modules F, (i E l) , as in Proposi-
tion 3. I . Then we obtain a surjective homomorphism f : F ~ M such that
f(ej) = Vj' Thus every module is a factor module of a free module.
Just as we did for abelian groups in Chapter I, §7, we can also define the
free module over a ring A generated by a non-empty set S. We let A(S) be the
set of functions <p : S ~ A such that <p(x) = 0 for almost all XES. If a E A and
XES , we denote by ax the map <p such that <p(x) = a and <p(y) = 0 for y "* x .
Then as for abelian groups, given
<p E A(S) there exist elements aj E A and
x, E S such that
<p = a,xI + . .. + anxw
It is immediately verified that the family of functions {8x } (x E S) such that
8x<x) = I and 8xCY) = 0 for y "* x form a basis for A(S). In other words, the ex-
pression of
<p as 2: a.x, above is unique. This construction can be applied
when S is a group or a monoid G, and gives rise to the group algebra as in
Chapter II, §5.
Projective modules
There exists another important type of module closely related to free modules,
which we now discuss .
Let A be a ring and P a module. The following properties are equivalent,
and define what it means for P to be a projective module .
PI.
Given a homomorphism f : P --> M" and surjective homomorphism
g : M --> M", there exists a homomorphism h :P --> M making the
following diagram commutative.
P 2.
Every exact sequence 0 --> M' --> M" --> P --> 0 splits.
P 3.
There exists a module M such that P EB M is free, or in words, P is a
direct summand of a free module.
P 4.
The functor M f--> HomACP, M) is exact.
We prove the equivalence of the four conditions.

138
MODULES
III, §4
Assume P I. Given the exact sequence of P 2, we consider the map f = id
in the diagram
p
;/ j'"
M"~P~O
Then h gives the desired splitting of the sequence.
Assume P 2. Then represent P as a quotient of a free module (cf. Exercise 1)
F -+ P -+ 0, and apply P 2 to this sequence to get the desired splitting, which
represents F as a direct sum of P and some module.
Assume
P 3.
Since
HomA(X EB Y, M) = HomA(X, M) EB HomA(Y, M),
and since M ~ HomA(F, M) is an exact functor if F is free, it follows that
HomA(P, M) is exact when P is a direct summand ofa free module, which proves
P4.
Assume P 4. The proof of P 1 will be left as an exercise.
Examples.
It will be proved in the next section that a vector space over a
field is always free, i.e . has a basis. Under certain circumstances, it is a theorem
that projective modules are free . In §7 we shall prove that a finitely generated
projective module over a principal ring is free. In Chapter X, Theorem 4.4 we
shall prove that such a module over a local ring is free; in Chapter XVI, Theo-
rem 3.8 we shall prove that a finite fiat module over a local ring is free; and in
Chapter XXI , Theorem 3.7, we shall prove the Quillen-Suslin theorem that
if A = k[X\, ... , Xn] is the polynomial ring over a field k, then every finite pro-
jective module over A is free .
Projective modules give rise to the Grothendieck group. Let A be a ring.
Isomorphism classes of finite projective modules form a monoid. Indeed, if P
is finite projective, let [P] denote its isomorphism class. We define
[P] + [Q] = [P EB Q].
This sum is independent of the choice of representatives P, Q in their class. The
conditions defining a monoid are immediately verified. The corresponding Groth-
endieck group is denoted by K(A).
We can impose a further equivalence relation that P is equivalent to pi if
there exist finite free modules F and F' such that P EB F is isomorphic to
pi EB F'. Under this equivalence relation we obtain another group denoted by
Ko(A) . If A is a Dedekind ring (Chapter II, §I and Exercises 13-19) it can be
shown that this group is isomorphic in a natural way with the group of ideal
classes Pic(A) (defined in Chapter II, §I). See Exercises II , 12, 13. It is also a

III, §5
VECTOR SPACES
139
problem to determine Ko(A) for as many rings as possible, as explicitly as pos-
sible. Algebraic number theory is concerned with Ko(A) when A is the ring of
algebraic integers of a number field. The Quillen-Suslin theorem shows if A is
the polynomial ring as above, then Ko(A) is trivial.
Of course one can carry out a similar construction with all finite modules.
Let [M] denote the isomorphism class of a finite module M . We define the sum
to be the direct sum. Then the isomorphism classes of modules over the ring
form a monoid, and we can associate to this monoid its Grothendieck group.
This construction is applied especiall y when the ring is commutative. There are
many variations on this theme. See for instance the book by Bass, Algebraic
K-theory, Benjamin, 1968.
There is a variation of the definition of Grothendieck group as follows. Let
F be the free abelian group generated by isomorphism clas ses of finite modu les
over a ring R , or of modules of bounded cardinality so that we deal with sets .
In this free abelian group we let I' be the subgroup generated by all elements
[M] -
[M '] -
[M il]
for which there exists an exact sequence 0 ~ M' ~ M ~ Mil ~ O. The factor
group FIf is called the Grothendieck group K(R) . We shall meet this group
again in §8, and in Chapter XX, §3. Note that we may form a similar Grothendieck
group with any family of modules such that M is in the family if and only if M'
and M il are in the famil y. Taking for the family finite projective modules , one
sees easily that the two possible definitions of the Grothendieck group coincide
in that case.
§5.
VECTOR SPACES
A module over a field is called a vector space.
Theorem 5.1.
Let V be a vector space over a fi eld K, and assume that
V =t- {O}. Let r be a set ofgenerators of V over K and let S be a subset ofr
which is linearly independent. Then there exists a basis <B of V such that
S c <B cr.
Proof
Let Z be the set whose elements are subsets T of r which contain S
and are linearly independent. Then T is not empty (it contains S), and we
contend that ::r is inductively ordered. Indeed, if {'Ii} is a totally ordered subset

140
MODULES
III, §5
of 1: (by ascending inclusion), then U7; is again linearly independent and con-
tains S. By Zorn's lemma, let <:B be a maximal element of 1:. Then <:B is linearly
independent. Let W be the subspace of V generated by <:B. If W i= V, there
exists some element x E r such that x ¢ W. Then <:B u {x} is linearly inde-
pendent, for given a linear combination
we must have b = 0, otherwise we get
x = - Lb-IayYEW.
yE<ll
By construction, we now see that ay =°for all Y E <:B, thereby proving that
<:B u {x} is linearly independent, and contradicting the maximality of <:B. It
follows that W = V, and furthermore that <:B is not empty since V i= {a}. This
proves our theorem.
If V is a vector space i= {a}, then in particular, we see that every set of
linearly independent elements of V can be extended to a basis, and that a basis
may be selected from a given set of generators.
Theorem 5.2.
Let V be a vector space over a field K. Then two basesof V
over K have the same cardinality.
Proof.
Let us first assume that there exists a basis of V with a finite
number of elements, say {VI' . •. , Vm }, m ~ 1. We shall prove that any other
basis must also have m elements. For this it will suffice to prove: If WI' • • • , w,
are elements of V which are linearly independent over K, then n ~ m (for
we can then use symmetry). We proceed by induction. There exist elements
cl , . . . , c; of K such that
(1)
and some c., say CI , is not equal to 0. Then VI lies in the space generated
by WI' V2,""
Vm over K, and this space must therefore be equal to V itself.
Furthermore, WI' V2 , .•• , Vm are linearly independent, for suppose b l , • • • , bm
are elements of K such that
If b l i= 0, divide by b, and express WI as a linear combination of V2' • • . , Vm •
Subtracting from (1) would yield a relation of linear dependence among the
Vi> which is impossible.
Hence b l = 0, and again we must have all b, = °
because the Vi are linearly independent.

III, §5
VECTOR SPACES
141
Suppose inductively that after a suitable renumbering of the Vi ' we have
found WI> .. . , w, (r < n) such that
is a basis of V. We express Wr+ 1 as a linear combination
with Ci E K. The coefficients of the Vi in this relation cannot all be 0; otherwise
there would be a linear dependence among the Wj ' Say Cr+ 1 =1= O. Using an
argument similar to that used above, we can replace vr + 1 by wr + 1 and still have
a basis of V. This means that we can repeat the procedure until r = n, and
therefore that n ~ m, thereby proving our theorem.
We shall leave the general case of an infinite basis as an exercise to the
reader. [Hint:
Use the fact that a finite number of elements in one basis is
contained in the space generated by a finite number of elements in another basis.]
Ifa vector space V adm its one basis with a finite number of elements, say m,
then we shall say that V is finite dimensional and that m is its dimension. In
view of Theorem 5.2, we see that m is the number of elements in any basis
of V. If V = {O}, then we define its dimension to be 0, and say that V is
O-dimensional.
We abbreviate ..dimension" by ..dim" or ..dirnj," if the
reference to K is needed for clarity.
When dealing with vector spaces over a field, we use the words subspace
and factor space instead of submodule and factor module.
Theorem 5.3.
Let V bea vectorspace overafield K, andlet W bea subspace.
Then
dirnj, V = dim K W + dimj, V/W.
Iff: V --+ U is a homomorphismof vector spaces over K , then
dim V = dim Ker f + dim Imj.
Proof.
The first statement is a special case of the second, taking for f the
canonical map.
Let {UdiEl be a basis of 1m f, and let {wj}jEJ be a basis of
Ker f.
Let {Vd iel be a family of elements of V such that f(vJ = Ui for each
i E I . We contend that
is a basis for V. This will obviously prove our assertion.

142
MODULES
III, §6
Let x be an element of V. Then there exist elements {aJj E/ of K almost
all of which are 0 such that
f(x) = L ajUj .
jE/
is in the kernel off, and there exist elements {bj}jEJ of K almost all of which are
osuch that
From this we see that x = L ajVi + L bjwj, and that {Vi'Wj} generates V.
It remains to be shown that the family {vj, wJ is linearly independent. Suppose
that there exist elements c., dj such that
Applyingfyields
0= L cJ (vJ = L c.u.,
whence all Cj = O. From this we conclude at once that all dj = 0, and hence that
our family {vj, Wj} is a basis for V over K, as was to be shown.
Corollary 5.4.
Let V be a vector space and W a subspace. Then
dim W
~ dim V.
If V isfinite dimensional and dim W = dim V then W = V.
Proof
Clear.
§6.
THE DUAL SPACE AND DUAL MODULE
Let E be a free module over a commutative ring A . We view A as a free
module of rank lover itself. By the dual module E V of E we shall mean the
module Hom(E, A) . Its elements will be called functionals. Thus a functional
on E is an A-linear map f : E ~ A. If x E E and j" E E V , we sometimes denote
I(x) by (x,f) . Keeping x fixed, we see that the symbol (x,f) as a function of
IE E V is A-linear in its second argument, and hence that x induces a linear map
on EV, which is 0 if and only if x = O. Hence we get an injection E ~ E VV
which is not always a surjection.

III. §6
THE DUAL SPACE AND DUAL MODULE
143
Let {XJ iEI be a basis of E. For each i E l ieif, be the unique functional such
thatJi(xj) = Dij (in other words , I if i = j and 0 if i * j). Such a linear map
exists by general properties of bases (Theorem 4. 1).
Theorem 6.1.
Let E be a finite free module over the commutative ring A .
offinite dimension n. Then EV is also f ree. and dim E V = n. If {xl . · · · . xn}
is a basis for E. and fi is the fun ctional such that fi(xj) = Dij. then {fl' . . . . fn}
is a basis fo r E V •
Proof.
Let f E E V and let a, = f (Xi) (i = 1, . .. , n). We have
f(CIXI + ... + c"xn) = cd(xl) + ... + c"f(xn)·
Hencef = o-J, + ... + «J; and we see that the fi generate E V • Furthermore,
they are linearl y independent , for if
bdl + ... + bnfn = 0
with b, E K , then evaluating the left-hand side on Xi yields
bJi(xi) = 0,
whence b, = 0 for all i . This proves our theorem.
Given a basis {xJ (i = I , . .. , n) as in the theorem , we call the basis {fJ
the dual basis. In term s of these bases, we can express an element A of E with
coordinates (al' . . . • an), and an element B of E v with coordinates (bl , .. . , bn),
such that
B = bdl + . .. + bn!,,·
Then in term s of these coordinates, we see that
(A, B ) = a. b , + .. . + anb" = A . B
is the usual dot product of n-tuples.
Corollary 6.2.
When E is free finite dimensional. then the map E ~ E V V
which to each x E V associates thef unctionalf ~ (r, f) on E V is an isomorphism
of E onto E V V •
Proof.
Note that since {II' .. . , f,,} is a basis for E V , it follows from the
definitions that {XI"
' " x,,} is the dual basis in E , so E = E Vv.
Theorem 6.3.
Let U, V, W be finite f ree modules over the commutative ring
A. and let
A
'"
O ~ W~ V~ U ~ O
be an exact sequence of A-homomorphisms . Then the induced sequence

144
MODULES
i.e.
is also exact.
III, §6
Proof
This is a consequence of P2, because a free module is projective.
We now consider properties which have specifically to do with vector spaces,
because we are going to take factor spaces. So we assume that we deal with
vector spaces over a field K.
Let V, V' be two vector spaces, and suppose given a mapping
V x V' --+ K
denoted by
(x, x') 1---+ ( x, x' )
for x E V and x' E V'. We call the mapping bilinear if for each x E V the function
x' 1---+ ( x, x') is linear, and similarly for each x' E V' the function x 1---+ ( x, x') is
linear. An element x E V is said to be orthogonal (or perpendicular) to a subset
S' of V' if ( x, x') = 0 for all x' E S'. We make a similar definition in the
opposite direction. It is clear that the set of x E V orthogonal to S' is a sub-
space of V.
We define the kernel of the bilinear map on the left to be the subspace of V
which is orthogonal to V', and similarly for the kernel on the right.
Given a bilinear map as above,
V x V' --+ K ,
let W' be its kernel on the right and let W be its kernel on the left. Let x' be
an element of V'. Then x' gives rise to a functional on V, by the rule x 1---+ ( x, x' ),
and this functional obviously depends only on the coset of x' modulo W' ; in
other words, if x', == x~ (mod W'), then the functionals x 1---+ ( x, x', ) and
x 1---+ ( x, x ~ ) are equal. Hence we get a homomorphism
V' ~ V V
whose kernel is precisely W' by definition, whence an injective homomorphism
o~ V'/W' ~ VV.
Since all the functionals arising from elements of V' vanish on W , we can view
them as functionals on V/W, i.e. as elements of (V/W)v. So we actually get an
injective homomorphism
o~ V'/W' ~ (V/ W) v.
One could give a name to the homomorphism
g : V' ~ VV

III, §6
such that
THE DUAL SPACE AND DUAL MODULE
145
( x, x') = <x, g(X'»
for all x E V and x' E V'. However, it will usually be possible to describe it by an
arrow and call it the induced map, or the natural map.
Giving a name to it
would tend to make the terminology heavier than necessary.
Theorem 6.4.
Let V x V' ~ K be a bilinear map, let W, W' be its kernels
on the left and right respectively, and assume that V' /W' is finite dimensional.
Then the induced homomorphism V' /W' ~ (V/W)v is an isomorphism .
Proof.
By symmetry, we have an induced homomorphism
V/W ~ (V'/W')v
which is injective. Since
dim(VI/W')v = dim V'/W'
it follows that V/W is finite dimensional. From the above injective homomor-
phism and the other, namely
o~ V'/W' ~ (V/W)v,
we get the inequalities
dim V/W ~ dim V'/W '
and
dim V'/W' ~ dim V/W,
whence an equality of dimensions. Hence our homomorphisms are surjective
and inverse to each other, thereby proving the theorem.
Remark 1.
Theorem 6.4 is the analogue for vector spaces of the duality
Theorem 9.2 of Chapter 1.
Remark 2.
Let A be a commutative ring and let E be an A-module . Then
we may form two types of dual:
E" = Hom(E, Q/Z), viewing E as an abelian group;
EV = HomA(E, A), viewing E as an A-module .
Both are called dual, and they usually are applied in different contexts. For
instance, EV will be considered in Chapter Xlll, while E" will be considered in
the theory of injective modules, Chapter XX, §4. For an example of dual module
EV see Exercise 11. If by any chance the two duals arise together and there is
need to distinguish between them, then we may call E" the Pontrjagin dual.

146
MODULES
III, §7
Indeed, in the theory of topological groups G, the group of continuous homo-
morphisms of G into R/Z is the classical Pontrjagin dual , and is classically
denoted by GA, so I find the preservation of that terminology appropriate.
Instead of R/Z one may take other natural groups isomorphic to R/Z . The
most common such group is the group of complex numbers of absolute value 1,
which we denote by 8) . The isomorphism with R/Z is given by the map
Remark 3.
A bilinear map V x V ~ K for which V' == V is called a bilinear
form. We say that the form is non-singular if the corresponding maps
V' ~ VV and
V ~ (V')v
are isomorphisms. Bilinear maps and bilinear forms will be studied at greater
length in Chapter XV. See also Exercise 33 of Chapter XIII for a nice example.
§7.
MODULES OVER PRINCIPAL RINGS
Throughout this section, we assume that R is a principal entire ring. All modules
are over R, and homomorphisms are R-homomorphisms, unless otherwise specified.
The theorems will generalize those proved in Chapter I for abelian groups.
We shall also point out how the proofs of Chapter I can be adjusted with sub-
stitutions of terminology so as to yield proofs in the present case.
Let F be a free module over R, with a basis {XJiEI ' Then the cardinality of
I is uniquely determined, and is called the dimension of F. We recall that this
is proved, say by taking a prime element p in R, and observing that F/ pF is a
vector space over the field R/pR, whose dimension is precisely the cardinality
of I. We may therefore speak of the dimension of a free module over R.
Theorem 7.1.
Let F be afree module, and M a submodule. Then M isfree,
and its dimension is less than or equal to the dimension ofF.
Proof
For simplicity, we give the proof when F has a finite basis {Xi}'
i == 1, . . . , n. Let M, be the intersection of M with (x), .. . , x.), the module
generated by XI' . . . , x.. Then M I == M n (XI) is a submodule of (XI), and is
therefore of type (alxl) with some al ER. Hence M I is either 0 or free, of di-
mension 1. Assume inductively that M, is free of dirnension js r.
Let a be
the set consisting of all elements a E R such that there exists an element X E M
which can be written

III, §7
MODULES OVER PRINCIPAL RINGS
147
with b,E R. Then a is obviously an ideal, and is principal, generated say by an
element ar + i - Ifar + 1 = 0, then M r + 1 = M, and we are done with the inductive
step.
If ar + 1 #- 0, let WE M r + 1 be such that the coefficient of W with respect
to x, + 1 is a,+ I' If x E M r + 1 then the coefficient of x with respect to x, + 1 is
divisible by ar+ 1, and hence there exists c E R such that x - cw lies in Mr.
Hence
On the other hand, it is clear that Mr n (w) is 0, and hence that this sum is direct,
thereby proving our theorem. (For the infinite case, see Appendix 2, §2.)
Corollary 7.2.
Let E be a finitely generated module and E' a submodule.
Then E' is finitely generated.
Proof
We can represent E as a factor module of a free module F with a
finite number of generators : If VI' • •• , Vn are generators of E, we take a free
module F with basis {x 1> ' . • ,xn } and map Xi on Vi ' The inverse image of E' in F
is a submodule, which is free, and finitely generated, by the theorem. Hence
E' is finitely generated. The assertion also follows using simple properties of
Noetherian rings and modules.
If one wants to translate the proofs of Chapter I, then one makes the
following definitions. A free I-dimensional module over R is called infinite
cyclic. An infinite cyclic module is isomorphic to R, viewed as module over
itself. Thus every non-zero submodule of an infinite cyclic module is infinite
cyclic. The proof given in Chapter I for the analogue of Theorem 7.1 applies
without further change.
Let E be a module. We say that E is a torsion module if given x E E, there
exists a E R, a #- 0, such that ax = 0. The generalization of finite abelian group
is finitely generated torsion module. An element x of E is called a torsion element
if there exists a E R, a #- 0, such that ax = 0.
Let E be a module. We denote by Etor the submodule consisting of all torsion
elements of E, and call it the torsion submodule of E. If Etor = 0, we say that
E is torsion free .
Theorem 7.3.
Let E be finitely generated. Then E/ Etor is free . There exists
a free submodule F of E such that E is a direct sum
E = Etor E9 F .
The dimension of such a submodule F is uniquely determined .
Proof.
We first prove that E/Etor is torsion free . If x E E, let i denote its
residue class mod Etor' Let b E R, b *°be such that bi = 0. Then bx E Etop
and hence there exists c E R, c * 0, such that cbx = 0. Hence x E Etor and
i
= 0, thereby proving that E/Etor is torsion free . It is also finitely generated.

148
MODULES
III, §7
Assume now that M is a torsion free module which is finitely generated. Let
{VI' . . . , vn } be a maximal set of elements of M among a given finite set of
generators {YI' .. . , Ym} such that {VI' ... , Vn} is linearly independent. If Y is
one of the generators, there exist elements a, b l , • . . , bn E R not all 0, such that
ay + biv i + ... + b;»; = 0.
Then a =1=°(otherwise we contradict the linear independence of VI' . .. , vn) .
Hence ay lies in (VI' . . . ,vn). Thus for each j = 1,
, m we can find aj E R,
aj =1= 0, such that ajYj lies in (VI"
' " vn) . Let a = a l
am be the product. Then
aM is contained in (VI"", vn) , and a =1= 0. The map
X 1--+ax
is an injective homomorphism, whose image is contained in a free module.
This image is isomorphic to M , and we conclude from Theorem 7.1 that M is
free, as desired .
To get the submodule F we need a lemma.
Lemma 7.4.
Let E, E' be modules, and assumethat E' isfree. Let f :E ~ E'
be a surjectivehomomorphism. Then there exists afree submodule F ofE such
that the restrictionoffto F induces an isomorphism ofF with E', and such that
E = F ED Kerf.
Proof.
Let {x;Ler be a basis of E'. For each i, let x, be an element of E such
that j'(x.) = x;. Let F be the submodule of E generated by all the elements Xi'
i E I. Then one sees at once that the family of elements {Xj}jel is linearly inde-
pendent, and therefore that F is free. Given x E E, there exist elements a, E R
such that
Then x - La.x, lies in the kernel off, and therefore E = Kerf + F. It is clear
that Kerf(\ F = 0, and hence that the sum is direct, thereby proving the lemma.
We apply the lemma to the homomorphism E ~ E/Etor in Theorem 7.3 to
get our decomposition E = Etor E9 F . The dimension of F is uniquely determined,
because F is isomorphic to E/Etor for any decomposition of E into a direct sum
as stated in the theorem .
The dimension of the free module F in Theorem 7.3 is called the rank of E.
In order to get the structure theorem for finitely generated modules over R,
one can proceed exactly as for abelian groups. We shall describe the dictionary
which allows us to transport the proofs essentially without change.
Let E be a module over R. Let x E E. The map a 1--+ax is a homomorphism
of R onto the submodule generated by x, and the kernel is an ideal, which is
principal, generated by an element mER. We say that m is a period of x. We

III, §7
MODULES OVER PRINCIPAL RINGS
149
note that m is determined up to multiplication by a unit (if m =1= 0). An element
c E R, c =1= 0, is said to be an exponent for E (resp. for x) if cE = 0 (resp. cx = 0).
Let p be a prime element. We denote by E(P) the submodule of E consisting
of all elements x having an exponent which is a power pr(r ~ 1). Ap-submodule
of E is a submodule contained in E(p).
We select once and for all a system of representatives for the prime elements
of R (modulo units). For instance, ifR is a polynomial ring in one variable over
a field, we take as representatives the irreducible polynomials with leading
coefficient 1.
Let mER,m =1= O. We denote by Em the kernel ofthe map x H mx. It consists
of all elements of E having exponent m.
A module E is said to be cyclic if it is isomorphic to RI(a) for some element
a E R. Without loss of generality ifa =1= 0, one may assume that a is a product of
primes in our system of representatives, and then we could say that ais the order
of the module.
Let r I ' . . . , rs be integers ~ 1. A p-module E is said to be of type
(P'I, ... , prs )
if it is isomorphic to the product of cyclic modules RI(pri ) (i = 1, .. . , s). If p
is fixed, then one could say that the module is of type (r l , ... , rs) (relative to p).
All the proofs of Chapter I, §8 now go over without change. Whenever we
argue on the size of a positive integer m, we have a similar argument on the
number of prime factors appearing in its prime factorization. If we deal with a
prime power r'. we can view the order as being determined by r, The reader
can now check that the proofs of Chapter I, §8 are applicable.
However, we shall develop the theory once again without assuming any
knowledge of Chapter I, §8. Thus our treatment is self-contained.
Theorem 7.5.
Let E be a finitely generated torsion module
=1= O. Then E is
the direct sum
E = EB E(p),
p
taken overall primespsuch that E(p) =1= 0. Each E(p) canbe written as a direct
sum
E(p) = RI(pVI) EEl .. . EEl RI(pVs )
with 1 ~ VI ~ ••• ~ VS ' The sequence VI' • •• , Vs is uniquely determined.
Proof
Let a be an exponent for E,and suppose that a = bewith (b, c) = (1).
Let x, y E R be such that
1 = xb + yc.

150
MODULES
III, §7
We contend that E = Eb EB Ec• Our first assertion then follows by induction,
expressing a as a product of prime powers. Let VEE. Then
v = xbv + ycv.
Then xbv E E, because cxbv = xav = 0. Similarly, ycv E Eb • Finally Eb n E, = 0,
as one sees immediately. Hence E is the direct sum of Eb and Ec•
We must now prove that E(p) is a direct sum as stated. If YI' .. . , Ym are
elements of a module, we shall say that they are independent if whenever we have
a relation
alYI + ... + amYm = 0
with ai E R, then we must have aiYi = 0 for all i. (Observe that independent
does not mean linearly independent.) We see at once that YI' . . . , Ym are inde-
pendent if and only if the module (y I' . . . , Ym) has the direct sum decomposition
in terms of the cyclic modules (Yi), i = 1, . . . , m.
We now have an analogue of Lemma 7.4 for modules having a prime power
exponent.
Lemma 7.6.
Let E be a torsion moduleojexponent p' (r ~ 1)Jorsome prime
element p. Let XI E E be an element oj period pro
Let E = E/(x l). Let
jil" ' " jim be independentelements ojE. Then for each i there exists a repre-
sentative Yi E E ofYb such that the period ofYi is the same as the period ofYi'
The elements XI> YI, "" Ymare independent.
Proof
Let yE Ehave period pn for some n ~ 1. Let Y be a representative of
yin E. Then pny E (XI)' and hence
cER, p{c,
for some s ~ r. If s = r, we see that Y has the same period as Y. If s < r, then
p'cx, has period p'-s, and hence Y has period pn+,-s. We must have
n + r - s ~ r,
because p' is an exponent for E. Thus we obtain n ~ s, and we see that
is a representative for y, whose period is p".
Let Yi be a representative for Yi having the same period. We prove that
XI' YI,' . . , Ym are independent. Suppose that a, al, ' . . , am E R are elements such
that
aXI + alYI + ... + amYm = O.

III, §7
Then
MODULES OVER PRINCIPAL RINGS
151
alYI + ... + amYm = O.
By hypothesis, we must have ajYi = 0 for each i. If prjis the period of Yi, then
prj divides a.. We then conclude that ajYi = 0 for each i, and hence finally
that ax I = 0, thereby proving the desired independence.
To get the direct sum decomposition of E(p), we first note that E(p) is
finitely generated. We may assume without loss of generality that E = E(p).
Let XI be an element of E whose period pr, is such that r l is maximal. Let
E = E/(x I)' We contend that dim n, as vector space over R/pR is strictly less
than dim Ep • Indeed, if YI' . . . , Ym are linearly independent elements of Ep
over R/pR , then Lemma 7.6 implies that dim Ep ~ m + 1 because we can always
find an element of (XI) having period p, independent of YI, . . . , Ym' Hence
dim Ep < dim Ep • We can prove the direct sum decomposition by induction.
IfE #- 0, there exist elements x2 , •• • , X. having periods pr2, • •• , pr, respectively,
such that r2 ~ .. . ~ rs• By Lemma 7.6, there exist representatives x2, . . . , x;
in E such that x, has period prjand XI " .. , x, are independent. Since pr, is such
that r l is maximal, we have r l
~ r2 , and our decomposition is achieved.
The uniqueness will be a consequence of a more general uniqueness theorem,
which we state next.
Theorem 7.7.
Let E be a finitely generated torsion module, E #- O. Then
E is isomorphic to a direct sum ofnon-zerofactors
R/(ql) \!3 .. . \!3 R/(qr),
where q\,.. . ,qr are non-zero non-units of R, and q\ 1q21.. · 1qr. The se-
quence ofideals (q\),.. . , (qr) is uniquelydeterminedby the aboveconditions.
Proof.
Using Theorem 7.5 , decompose E into a direct sum ofp-submodules,
say E(PI) EB . . . EB E(p,), and then decompose each E(P i) into a direct sum of
cyclic submodules of periods pili. We visualize these symbolically as described
by the following diagram :
E(p,) :
r /l
~ r/ 2 ~ . ..
A horizontal row describes the type of the.module with respect to the prime at
the left. The exponents rij are arranged in increasing order for each fixed
i = 1, . .. , I. We let ql' ... , q, correspond to the columns of the matrix of
exponents, in other words

152
MODULES
III, §7
The direct sum of the cyclic modules represented by the first column is then
isomorphic to Rj(ql), because, as with abelian groups, the direct sum of cyclic
modules whose periods are relatively prime is also cyclic. We have a similar
remark for each column, and we observe that our proof actually orders the qj
by increasing divisibility, as was to be shown.
Now for uniqueness. Let p be any prime, and suppose that E = Rj(pb) for
some b e R, b =f:. O. Then Ep is the submodule bRj(pb), as follows at once from
unique factorization in R. But the kernel of the composite map
R --. bR --. bRj(pb)
is precisely (p). Thus we have an isomorphism
Rj(p) ;:::: bRj(pb).
Let now E be expressed as in the theorem, as a direct sum of r terms. An
element
is in Ep if and only if PVi = 0 for all i. Hence Ep is the direct sum of the kernel of
multiplication by p in each term. But Ep is a vector space over Rj(p), and its
dimension is therefore equal to the number of terms Rj(q;) such that p divides qi'
Suppose that p is a prime dividing ql ' and hence qi for each i = 1,.. . , r. Let
E have a direct sum decomposition into d terms satisfying the conditions of the
theorem, say
E = Rj(q'l) EB ... EB Rj(q ~).
Then p must divide at least r of the elements qj, whence r ~ s. By symmetry,
r = s, and p divides qj for all j.
Consider the module pE. By a preceding remark, if we write qi = pbi' then
pE ;:::: Rj(b l) EB ... EB Rj(b r ) ,
and bll·· · Ibr • Some of the b, may be units, but those which are not units
determine their principal ideal uniquely, by induction. Hence if
but (bj + 1) =f:. (1), then the sequence of ideals

III, §7
MODULES OVER PRINCIPAL RINGS
153
is uniquely determined . This proves our uniqueness statement, and concludes
the proof of Theorem 7.7 .
The ideals (ql), . . . , (qr) are called the invariants of E .
For one of the main applications ofTheorem 7.7 to linear algebra, see Chapter
XV, §2.
The next theorem is included for completeness. It is called the elementary
divisors theorem.
Theorem 7.8.
Let F be afree module over R, and let M be afinitely generated
submodule * O. Then there exists a basis <B of F, elements el' .. . , em in this
basis, and non-zero elements ai' . .. . am E R such that :
(i) The elements ale" .. . , amemform a basis of Mover R.
(ii) We have ailaHtfor i = 1, . . . , m -
l.
The sequence of ideals (al) ' . .. • (am) is uniquely determined by the preceding
conditions.
Proof.
Write a finite set of generators for M as linear combination of a finite
number of elements in a basis for F. These elements generate a free submodule
of finite rank, and thus it suffices to prove the theorem when F has finite rank,
which we now assume. We let n = rank(F).
The uniqueness is a corollary of Theorem 7.7 . Suppose we have a basis as
in the theorem. Say at,
, as are unit s, and so can be taken to be = 1, and
as+j = qj with ql lq21
I qr non-units. Observe that F/M = F is a finitely
generated module over R, having the direct sum expression
r
F/ M = F = EB (R/ qjR)ej EB free module of rank n - (r + s)
j= I
where a bar denotes the class of an element of F mod M . Thus the direct sum
over j = 1, . .. , r is the torsion submodule of P, whence the elements ql' . .. ,
qr are uniquely determined by Theorem 7.7. We have r + s = m, so the rank
of F/M is n -
m, which determines m uniquely. Then s = m -
r is uniquely
determined as the number of units among ai ' ... , am' This proves the uniqueness
part of the theorem. Next we prove existence.
Let A be a functional on F, in other words, an element of HomR(F, R). We
let J A = A(M) . Then h is an ideal of R. Select AI such that AI(M) is maximal
in the set of ideals {JA}, that is to say , there is no properly larger ideal in the
set {h}.
Let AI(M) = (a l). Then al i= 0, because there exists a non-zero element of
M , and expressing this element in terms of some basis for F over R, with some
non-zero coordinate, we take the projection on this coordinate to get a func-
tional whose value on M is not 0. Let XI EM be such that AI(X1) = al ' For
any functional g we must have g(x 1) E (a 1) [immediate from the maximality of

154
MODULES
III, §7
Al(M)]. Writing x I in terms of any basis of F, we see that its coefficients must
all be divisible by al. (If some coefficient is not divisible by aI' project on this
coefficient to get an impossible functional.) Therefore we can write X I = aIel
with some element e. E F.
Next we prove that F is a direct sum
F = ReI EEl Ker AI '
Since AI(el) = 1, it is clear that ReI n Ker Al = O. Furthermore, given X EF
we note that X -
AI(x)el is in the kernel of ~I ' Hence F is the sum of the in-
dicated submodules, and therefore the direct sum.
We note that Ker Al is free , being a submodule of a free module (Theorem
7.1). We let
F) = Ker A)
and
MI = M n Ker A).
We see at once that
M = RXI EEl M).
Thus M) is a submodule of F J and its dimension is one less than the dimension
of M. From the maximality condition on AI(M), it follows at once that for any
functional A. onF), the image A.(M)will be contained in A)(M) (because otherwise,
a suitable linear combination of functionals would yield an ideal larger than
(a)). We can therefore complete the existence proof by induction.
In Theorem 7.8, we call the ideals (a,), . . . , (am) the invariants of Min F.
For another characterization of these invariants, see Chapter XIII , Proposition
4.20 .
Example.
First, see examples of situations similar to those of Theorem 7.8
in Exerci ses 5, 7, and 8, and for Dedekind rings in Exercise 13.
Example.
Another way to obtain a module M as in Theorem 7.8 is as
a module of relations. Let W be a finitely generated module over R, with genera-
tors w., ..., Wno By a relation among {wI' • •• ,
Wn} we mean an element
(ai ' . . . , an) E R" such that L aiwi = O. The set of such relations is a sub-
module of R", to which Theorem 7.8 may be applied.
It is also possible to formulate a proof of Theorem 7.8 by considering M as
a submodule of R", and applying the method of row and column operations to
get a desired basis. In this context, we make some further comments which may
serve to illustrate Theorem 7.8. We assume that the reader is acquainted with
matrices over a ring. By row operations we mean: interchanging two rows;
adding a multiple of one row to another; multiplying a row by a unit in the ring.
We define column operations similarly. These row and column operations
correspond to multiplication with the so-called elementary matrices in the ring.
Theorem 7.9.
Assume that the elementary matrices in R generate GLn(R).
Let (xij) be a non-zero matrix with components in R. Then with a finite
number of row and column operations, it is possible to bring the matrix to
the form

III, §8
o
o
o
with al . .. am "" 0 and al la21... Ia.;
o
EULER-POINCARE MAPS
155
o
o
o
o
o
We leave the proof for the reader. Either Theorem 7.9 can be viewed as
equivalent to Theorem 7.8, or a direct proof may be given . In any case, Theorem
7.9 can be used in the following context. Consider a system of linear equations
with coefficients in R . Let F be the submodule of R n generated by the vectors
X = (x,, .. . , xn ) which are solutions of this system. By Theorem 7.1, we know
that F is free of dimension
~ n. Theorem 7.9 can be viewed as providing a
normalized basis for F in line with Theorem 7.8.
Further example.
As pointed out by Paul Cohen, the row and column
method can be applied to module s over a power serie s ring o[[X]], where 0 is
a complete discrete valuation ring . Cf. Theorem 3.1 of Chapter 5 in my Cyclo-
tomic Fields I and II (Springer Verlag, 1990). For instance, one could pick 0 it-
self to be a power serie s ring k[[T]] in one variable over a field k, but in the
theory of cyclotomic fields in the above reference, 0 is taken to be the ring of
p-adic integers. On the other hand, George Bergman has drawn my attention to
P. M. Cohn's "On the structure of G~ of a ring, " IHES Publ. Math. No. 30
(1966), giving examples of principal rings where one cannot use row and column
operations in Theorem 7.9.
§8.
EULER-POINCARE MAPS
The present section may be viewed as providing an example and application
of the Jordan-Holder theorem for modules. But as pointed out in the examples
and references below , it also provides an introduction for further theories.
Again let A be a ring. We continue to consider A-modules. Let r be an
abelian group, written additively. Let
cp be a rule which to certain modules
associates an element of I', subject to the following condition:

156
MODULES
III, §8
IfO -+ M' -+ M -+ M" -+ 0 is exact, then qJ(M) is defined ifandonly if qJ(M')
and qJ(M") are defined, and in that case,we have
qJ(M) = qJ(M') + qJ(M").
Furthermore qJ(O) is defined and equal to O.
Such a rule qJ will be called an Euler-Poincare mapping on the category of
A-modules. If M' is isomorphic to M , then from the exact sequence
o-+ M' -+ M -+ 0 -+ 0
we conclude that qJ(M') is defined if qJ(M) is defined, and that qJ(M') = qJ(M).
Thus if qJ(M) is defined for a module M, qJ is defined on every submodule and
factor module of M. In particular, if we have an exact sequence of modules
M' -+ M -+ M"
and if qJ(M') and qJ(M") are defined, then so is qJ(M), as one sees at once by
considering the kernel and image of our two maps, and using the definition.
Examples.
We could let A = Z, and let qJ be defined for all finite abelian
groups, and be equal to the order of the group. The value of qJ is in the multi-
plicative group of positive rational numbers.
As another example, we consider the category of vector spaces over a field k.
We let qJ be defined for finite dimensional spaces, and be equal to the dimension.
The values of cp are then in the additive group of integers.
In Chapter XV we shall see that the characteristic polynomial may be con-
sidered as an Euler-Poincare map.
Observe that the natural map of a finite module into its image in the Groth-
endieck group defined at the end of §4 is a universal Euler-Poincare mapping.
We shall develop a more extensive theory of this mapping in Chapter XX, §3.
If M is a module (over a ring A), then a sequence of submodules
is also called a finite filtration, and we call r the length of the filtration. A module
M is said to be simple if it does not contain any submodule other than 0 and M
itself, and if M :F O. A filtration is said to besimple if each MdM,+ 1 is simple.
The Jordan-HOlder theorem asserts that two simplefiltrations of a module are
equivalent.
A module M is said to be of finite length if it is 0 or if it admits a simple
(finite) filtration . By the Jordan-Holder theorem for modules (proved the same
way as for groups), the length of such a simple filtration is uniquely deter-
mined, and is called the length of the module. In the language of Euler charac-
teristics, the Jordan-Holder theorem can be reformulated as follows:

III, §9
THE SNAKE LEMMA
157
Theorem 8.1.
Let ip be a rule which to each simple module associates an
element oja commutativegroup r,and such that if M ~ M' then
cp(M) = cp(M').
Then cp has a unique extension to an Euler-Poincare mapping defined on all
modules oJfinite length.
Proof
Given a simple filtration
we define
r - 1
cp(M) = Lcp(MJM i + I}'
i = 1
The Jordan-Holder theorem shows immediately that this is well-defined, and
that this extension of cp is an Euler-Poincare map.
In particular, we see that the length function is the Euler-Poincare map
taking its values in the additive group of integers, and having the value 1for any
simple module.
§9.
THE SNAKE LEMMA
This section gives a very general lemma, which will be used many times ,
so we extract it here . The reader may skip it until it is encountered, but already
we give some exercises which show how it is applied: the five lemma in Exercise
15 and also Exercise 26. Other substantial applications in this book will occur
in Chapter XVI , §3 in connection with the tensor product, and in Chapter XX
in connection with complexes, resolutions, and derived functors.
We begin with routine comments. Consider a commutative diagram of homo-
morphisms of modules.
N'---,;-+ N
Then f induces a homomorphism
Ker d' ~ Ker d.
Indeed, suppose d'x' = O. Then df (x' } = 0 because df (x' } = hd'(x'} = o.

158
MODULES
III, §9
Similarly, h induces a homomorphism
Coker d' ~ Coker d
in a natural way as follows. Let y' E N' represent an element of N' / d' M'. Then
hy' mod dM does not depend on the choice of y' representing the given element,
because if y" = y' + d'x', then
hy" = hy ' + hd'x' = hy' + dfx' == hy' mod dM.
Thus we get a map
h* : N' /d'M' = Coker d' ~ N/dM = Coker d,
which is immediately verified to be a homomorphism.
In practice, given a commutative diagram as above , one sometimes writes f
instead of h, so one writes f for the horizontal maps both above and below the
diagram . This simplifies the notation , and is not so incorrect: we may view
M', N' as the two components of a direct sum, and similarly for M, N . Thenf
is merely a homomorphism defined on the direct sum M' E9 N' into M E9 N .
The snake lemma concerns a commutative and exact diagram called a snake
diagram:
o-----+ N' -----+ N -----+ Nil
f
9
Let Z" E Ker d', We can construct elements of N' as follows. Since 9 is
surjective, there exists an element z E M such that gz = Z" . We now move
vertically down by d , and take dz . The commutativity (/'g = gd shows that
gdz = 0 whence dz is in the kernel of 9 in N. By exactness, there exists an
element z' EN' such thatfz' = dz. In brief, we write
Of course, z' is not well defined because of the choices made when taking inverse
images. However, the snake lemma will state exactly what goes on.
Lemma 9.1.
(Snake Lemma).
Given a snake diagram as above, the map
J : Ker d" ~ Coker d'
inducedby oz" = / -1
0 d o«' z" is well defined, and we have an exact sequence
Ker d' -
Ker d -
Ker d" ~ Coker d' -
Coker d -
Coker d"
where the maps besides c5 are the natural ones.

III, §10
DIRECT AND INVERSE LIMITS
159
Proof .
It is a routine verification that the class of z' mod Irn d' is in-
dep end ent of the choices made when taking inverse images, whence defining
the map 6. The proof of the exactness of the sequence is then routine, and
consists in chasing around diagram s. It should be carried out in full detail
by the reader who wishes to acquire a feeling for this type of trivialit y. As an
example, we shall prove that
Ker 0 C Im 9*
where g* is the indu ced map on kernels. Suppose the image of z" is 0 in Coker
d', By definition, there exists u' E M' such that Z' = d' u'. Then
dz = fZI = fd'u' = dfu'
by commutativity. Hence
d(z - fu') = 0,
and z - [u' is in the kernel ofd. But g(z - fu') = gz = z", This means that z" is
in the image of g*, as desired . All the remaining cases of exactness will be left
to the reader.
The original snake diagram may be completed by writing in the kernels
and cokernels as follows (whence the name of the lemma) :
o
Ker d"
Coker d
Coker d
Ker d'
-----+
Ker d
Co er d
-----+
j
j
I
M '
-----+
M
-----+
M"- --+
N'
-----+
N
-----+
N"
I
I
I
k
' -----+
-----+
"
o
§10.
DIRECT AND INVERSE LIMITS
We return to limits, which we considered for groups in Chapter 1. We now
consider limits in other categories (rings, modules), and we point out that limits
satisfy a universal property, in line with Chapter I, §11.
Let I = {i} be a directed system of indices, defined in Chapter I, §lO. Let
a be a category, and {AJ a family of objects in a. For each pair i , j such that

160
MODULES
i ~ j assume given a morphism
f ):Ai --+ Aj
such that, whenever i ~ j ~ k, we have
h
0f ) = f~
and f: = id.
III, §10
Such a family will be called a directed family of morphisms. A direct limit
for the family {f)} is a universal object in the following category e . Ob(e)
consists of pairs (A, (fi» where A E Ob(Ci) and (l) is a family of morphisms
l :Ai --+ A, i E I, such that for all i ~ j the following diagram is commutative:
(Universal of course means universally repelling.)
Thus if (A,u» is the direct limit, and if (B, (gi» is any object in the above
category, then there exists a unique morphism tp : A --+ B which makes the
following diagram commutative:
For simplicity, one usually writes
omitting the f )from the notation.
Theorem 10.1.
Direct limits exist in the categoryofabelian groups, or more
generally in the category ofmodules over a ring.
Proof
Let {MJ be a directed system of modules over a ring. Let M be
their direct sum. Let N be the submodule generated by all elements
xi) = (. . . ,0, x, 0, . . . , -fj(x), 0, .. .)

III, §10
DIRECT AND INVERSE LIMITS
161
where, for a given pair of indices (i,j) with j f; i, Xij has component x in M;.
J)(x) in M j , and component 0 elsewhere. Then we leave to the reader the veri-
fication that the factor module MIN is a direct limit, where the maps of M; into
MIN are the natural ones arising from the composite homomorphism
Example.
Let X be a topological space, and let x E X. The open neigh-
borhoods of x form a directed system, by inclusion. Indeed, given two open
neighborhoods U and V, then U n V is also an open neighborhood contained in
both U and V. In sheaf theory, one assigns to each U an abelian group A(U) and
to each pair U => V a homomorphism h~ : A (U) -t A(V) such that if U => V => W
then hw o h~ = hI(,. Then the family of such homomorphisms is a directed family.
The direct limit
lim A(U)
U
is called the stalk at the point x. We shall give the formal definition of a sheaf
of abelian groups in Chapter XX, §6. For further reading, I recommend at least
two references. First, the self-contained short version of ChapterII in Hartshorne's
Algebraic Geometry, Springer Verlag, 1977. (Do all the exercises of that section,
concerning sheaves .) The section is only five pages long. Second, I recommend
the treatment in Gunning's Introduction to Holomorphic Functions of Several
Variables, Wadsworth and Brooks/Cole, 1990.
We now reverse the arrows to define inverse limits. We are again given a
directed set I and a family of objects Ai' Ifj f; i we are now given a morphism
satisfying the relations
Ji
0 J{= Jland Ji = id,
if j f; i and i f; k. As in the direct case, we can define a category of objects
(A, /;) with /;: A -+ Ai such that for all i, j the following diagram is com-
mutative:
A universal object in this category is called an inverse limit of the system (A i,J)).

162
MODULES
As before, we often say that
A = limA ;
i
is the inverse limit, omitting the f~ from the notation.
III, §10
Theorem 10.2.
Inverse limits exist in the category ofgroups. in the category
of modules over a ring, and also in the category of rings.
Proof.
Let {GJ be a directed family of groups, for instance, and let r be
their inverse limit as defined in Chapter I, §10. Let Pi: r -
G, be the projection
(defined as the restriction from the projection of the direct product. since r is
a subgroup of I1 Gi ) . It is routine to verify that these data give an inverse limit
in the category of groups. The same construction also applies to the category of
rings and modules.
Example.
LetPbe aprime number. For n ~ mwe have acanonical surjective
ring homomorphism
f::' : Z/pnZ -
Z/pmz.
The projective limit is called the ring of p-adic integers, and is denoted by Zp-
For a consideration of this ring as a complete discrete valuation ring, see Exercise
17 and Chapter XII.
Let k be a field. The power series ring k[[T]] in one variable may be viewed
as the inverse limit of the factor polynomial rings k[T]/(Tn), where for n ~ m
we have the canonical ring homomorphism
A similar remark applies to power series in several variables .
More generally, let R be a commutative ring and let J be a proper ideal. If
n ~ m we have the canonical ring homomorphism
f::': R/r - R/Jm.
Let RJ = lim R/In be the inverse limit. Then R has a natural homomorphism
into RJ • If R is a Noetherian local ring, then by Krull's theorem (Theorem 5.6
of Chapter X), one knows that nJ n = {OJ, and so the natural homorphism of R
in its completion is an embedding. This construction is applied especially when
J is the maximal ideal. It gives an algebraic version of the notion of holomorphic
functions for the following reason .
Let R be a commutative ring and J a proper ideal. Define a J-Cauchy se-
quence {xn } to be a sequence of elements of R satisfying the following condition.
Given a positive integer k there exists N such that for all n, m ~ N we have
Xn -
Xm E r, Define a null sequence to be a sequence for which given k there
exists N such that for all n ~ N we have Xn E r, Define addition and multipli-

III, §10
DIRECT AND INVERSE LIMITS
163
cation of sequences termwise. Then the Cauchy sequences form a ring e, the
null sequences form an ideal X, and the factor ring e/x is called the J-adic
completionof R. Prove these statements as an exercise, and also prove that there
is a natural isomorphism
e/x "" lim st)».
Thus the inverse limit limR/r is also called theJ-adic completion. See Chapter
XII for the completion in the context of absolute values on fields.
Examples.
In certain situations one wants to determine whether there exist
solutions of a system of a polynomial equationf(Xl ' .. . ,Xn ) =0 with coefficients
in a power series ring k[[T]], say in one variable. One method is to consider the
ring mod (TN), in which case this equation amounts to a finite number of equations
in the coefficients. A solution of f(X) = 0 is then viewed as an inverse limit of
truncated solutions. For an early example of this method see [La 52], and for
an extension to several variables [Ar 68].
[La 52)
S. LANG, On quasi algebraic closure , Ann of Math . 55 (1952), pp. 373-390
[Ar 68)
M. ARTlN, On the solutions of analytic equations, Invent . Math. 5 (1968) , pp.
277-291
See also Chapter XII, §7.
In Iwasawa theory , one considers a sequence of Galois cyclic extensions K;
over a number field k of degree v" with p prime , and with K; C Kn+ l • Let G;
be the Galois group of K; over k. Then one takes the inverse limit of the group
rings (Z/pnZ )[Gn], following Iwasawa and Serre . Cf. my Cyclotomic Fields ,
Chapter 5. In such towers of fields, one can also consider the projective limits
of the modules mentioned as examples at the end of §1. Specifically, consider
the group of pn-th roots of unity IJ.pn , and let K; = Q(lJ.pn+I), with Ko = Q(lJ.p)'
We let
Tp(lJ.) = lim IJ.pn
under the homomorphisms IJ.pn+\ ~ IJ.pn given by ,~ (f' . Then Tp(lJ.) becomes
a module for the projective limits of the group rings. Similarly, one can consider
inverse limits for each one of the modules given in the examples at the end of
§1. (See Exercise 18.) The determination of the structure of these inverse limits
leads to fundamental problems in number theory and algebraic geometry.
After such examples from real life after basic algebra, we return to some
general considerations about inverse limits .
Let (Ai' I{) = (Ai) and (B io g{) = (Bi) be two inverse systems of abelian
groups indexed by the same indexing set. A homomorphism (Ai) -+ (B i) is the
obvious thing, namely a family of homomorphisms

164
MODULES
for each i which commute with the maps of the inverse systems :
A sequence
III, §10
is said to be exact if the corresponding sequence of groups is exact for each i.
Let (An) be an inverse system of sets, indexed for simplicity by the positive
integers, with connecting maps
We say that this system satisfies the Mittag-Lefller condition ML if for each n,
the decreasing sequence um,n(Am) (m ~ n) stabilizes, i.e. is constant for m
sufficiently large . This condition is satisfied when um,n is surjective for all m,
n.
We note that trivially, the inverse limit functor is left exact, in the sense that
given an exact sequence
then
is exact.
Proposition 10.3.
Assume that (An) satisfies ML. Given an exact sequence
ofinverse systems, then
is exact.
Proof
The only point is to prove the surjectivity on the right. Let (en) be
an element of the inverse limit. Then each inverse image g-l(Cn) is a coset of
An, so in bijection with An. These inverse images form an inverse system, and
the ML condition on (An) implies ML on (g-l(Cn». Let S; be the stable subset
s, = nu~ .n<g-l(cm»
'
m~n

III, Ex
EXERCISES
165
Then the connecting maps in the inverse system (Sn) are surjective, and so there
is an element (bn) in the inverse limit. It is immediate that 9 maps this element
on the given (c.), thereby concluding the proof of the Proposition.
Proposition 10.4.
Let (Cn) be an inverse system ofabelian groups satisfying
ML, and let (um,n) be the system of connecting maps. Then we have an exact
sequence
TI
I-uTI
o-+ lim C, -+
C, ---+
C, -+ O.
Proof.
For each positive integer N we have an exact sequence with a finite
product
N
N
o-+
lim c, -+ TI c, .:=.: TI c, -+ O.
l~n~N
n=1
n=1
The map u is the natural one, whose effect on a vector is
(0, . . .,0, cm, 0, .. . , 0) f-+ (0, . . . , 0, um ,m -Icm , 0, . . . ,0).
One sees immediately that the sequence is exact. The infinite products are in-
verse limits taken over N. The hypothesis implies at once that ML is satisfied
for the inverse limit on the left, and we can therefore apply Proposition 10.3 to
conclude the proof.
EXERCISES
1. Let V be a vector space over a field K , and let U, W be subspaces. Show that
dim U + dim W = dim(U + W) + dim(U n W).
2. Generalize the dimension statement of Theorem 5.2 to free modules over a non zero
commutative ring. [Hint:
Recall how an analogous statement was proved for free
abelian groups, and use a maximal ideal instead ofa prime number.]
3. Let R be an entire ring containing a field k as a subring. Suppose that R is a finite
dimensional vector space over k under the ring multiplication. Show that R is a field.
4. Direct sums.
(a) Prove in detail that the conditions given in Proposition 3.2 for a sequence to
split are equivalent. Show that a sequence 0 ~ M' -4 M ~ M" ~ 0 splits if
and only if there exists a submodule N of M such that M is equal to the direct
sum Im fE9 N, and that if this is the case, then N is isomorphic to M". Complete
all the details of the proof of Proposition 3.2.

166
MODULES
III, Ex
(b) Let E and E;(i = I, ... , m) be modules over a ring. Let 'Pi: E, ~ E and
r/J;: E ~ E; be homomorphisms having the following properties:
r/Jjo (fJj = id,
mI
(fJj 0 I/Ij = id.
i=J
if i oF j,
Show that the map x H
(r/JIJC,• •• , I/Imx) is an isomorphism of E onto the direct product
of the E, (i = I, .. . , m), and that the map
is an isomorphism of this direct product onto E.
Conversely , if E is equal to a direct product (or direct sum) of submodules
E; (i = I, .. . , m) , if we let 'P; be the inclusion of E, in E, and r/J; the projection of
Eon E;, then these maps satisfy the above-mentioned properties.
5. Let A be an additive subgroup of Euclidean space R",and assume that in every bounded
region of space, there is only a finite number of elements of A. Show that A is a free
abelian group on
~ n generators. [Hint:
Induction on the maximal number of
linearly independent elements of A over R. Let VI ' . . . , Vm be a maximal set of such
elements, and let Ao be the subgroup of A contained in the R-space generated by
VI>• •• ,Vm-I' By induction, one may assume that any element of Ao is a linear integral
combination of VI ' "
' ' Vm-I'
Let S be the subset of elements V E A of the form
V = aivi + ...+ amVm with real coefficients aj satisfying
o ~ a, < 1
O~am~l.
if i = 1,. . . , m - 1
Ifv;"is an element of S with the smallest am oF 0, show that {VI> ••• , Vm _ I' v;,,} is a basis
of A over Z.]
Note. The above exercise is applied in algebraic number theory to show that the
group of units in the ring of integers of a number field modulo torsion is isomorphic
to a lattice in a Euclidean space. See Exercise 4 of Chapter VII.
6. (Artin-Tate). Let G be a finite group operating on a finite set S. For w E S, denote
1 . w by [w], so that we have the direct sum
Z(S) = L: Z[w] .
weS
Define an action of G on Z(S) by defining CT[W] = [CTW] (for wE S), and extending
CT to Z(S) by linearity. Let M be a subgroup of Z(S) of rank #[S] . Show that M has
a Z-basis {YW}WES such that UYw = Yow for all WE S. (Cf. my Algebraic Number
Theory, Chapter IX, §4, Theorem I.)
7. Let M be a finitely generated abelian group. By a seminorm on M we mean a real-
valued function v H IvIsatisfying the following properties:

III, Ex
EXERCISES
167
Ivl ~ 0 for all v E M;
Invl = Inl Ivl for n E Z;
Iv + WI ~ IvI + IWI for all v, W EM.
By the kernel of the seminorm we mean the subset of elements v such that IvI = O.
(a) Let Mo be the kernel. Show that Mo is a subgroup. If Mo = {O}, then the
seminorm is called a norm.
(b) Assume that M has rank r. Let VI "
' "
vr E M be linearly independent over
Z mod Mo. Prove that there exists a basis {WI"
'"
Wr} of MIMo such that
;
Iw;1 ~ ~ IvJ
j ~
1
[Hint : An explicit version of the proof of Theorem 7.8 gives the result.
Without loss of generality, we can asume Mo = {O}. Let MI = (VI "
'"
vr) .
Let d be the exponent of MIMI ' Then dM has a finite index in MI ' Let nj.j
be the smallest positive integer such that there exist integers nj ,I ' . . . , nj.j_1
satisfying
Without loss ofgenerality we may assume 0 ~ nj .k ~ d - I . Then the elements
WI "
' "
W r form the desired basis.]
8. Consider the multiplicative group Q* of non-zero rational numbers. For a non-zero
rational number x = alb with a, b E Z and (a, b) = I, define the height
h(x) = log max(]«] , Ibi).
(a) Show that h defines a seminorm on Q*, whose kernel cons ists of ± 1 (the
torsion group).
(b) Let M I be a finitely generated subgroup of Q*, generated by rational numbers
XI ' • •• , xm . Let M be the subgroup of Q* consisting of those elements X such
that X S E M 1 for some positive integer s. Show that M is finitely generated,
and using Exercise 7, find a bound for the seminorm of a set of generators
of M in terms of the seminorms of x I ' . . . , xm .
Note. The above two exerci ses are applied in questions of diophantine
approximation. See my Diophantine approximation on toruses, Am. J. Math.
86 (1964) , pp. 521-533 , and the discussion and references 1 give in Ency-
clopedia ofMathematical Sciences, Number Theory III, Springer Verlag, 1991,
pp. 240-243 .
Localization
9. (a) Let A be a commutative ring and let M be an A-module . Let S be a multiplicative
subset of A. Define S-I M in a manner analogous to the one we used to define
S-IA, and show that S-IM is an S-IA-module.
(b) If 0 ~ M' ~ M ~ M il ~ 0 is an exact sequence, show that the sequence
o~ S-IM' ~ S-IM ~ S-IM" ~ 0 is exact.

168
MODULES
III, Ex
to. (a) If p is a prime ideal, and S = A - p is the complement of p in the ring A, then
s-tM is denoted by M p- Show that the natural map
M~ TI u,
of a module M into the direct product of all localizations Mpwhere p ranges over
all maximal ideals, is injective .
(b) Show that a sequence 0 ~ M' ~ M ~ M" ~ 0 is exact if and only if the sequence
o~ M~ ~ Mp ~ M"p ~ 0 is exact for all primes p .
(c) Let A be an entire ring and let M be a torsion-free module. For each prime p of
A show that the natural map M ~ Mp is injective. In particular A ~ Ap is injective,
but you can see that directly from the imbedding of A in its quotient field K .
Projective modules over Dedekind rings
For the next exercise we assume you have done the exercises on Dedekind rings in
the preceding chapter. We shall see that for such rings, some parts of their module theory
can be reduced to the case of principal rings by localization . We let 0 be a Dedekind ring
and K its quotient field.
I I . Let M be a finitely generated torsion-free module over o. Prove that M is projective.
[Hint : Given a prime ideal p, the localized module Mp is finitely generated torsion-
free over op, which is principal. Then Mp is projective, so if F is finite free over 0,
and f : F ~ M is a surjective homomorphism, then fp: Fp ~ Mp has a splitting
gp: Mp ~ Fp, such thatfp
0 gp = idMp' There exists cp Eo such that cp rf. p and
cpgp(M) C F. The family {cp} generates the unit ideal 0 (why?), so there is a finite
number of elements cPi and elements Xj Eo such that LXjcPi = I. Let
9 = L XjCP,gp,·
Then show that g : M ~ F gives a homomorphism such that fo 9 = idM . ]
12. (a) Let a,b be ideals. Show that there is an isomorphism of o-rnodules
a$b~ o$ab
[Hint: First do this when a, b are relatively prime. Consider the homomorphism
a $ b ~ a + b , and use Exercise to. Reduce the general case to the relatively
prime case by using Exercise 19 of Chapter II.]
(b) Let a, b be fractional ideals, and letf: a ~ b be an isomorphism (of o-rnodules ,
of course). Thenfhas an extension to a K-linear maPA : K ~ K. Let c = A(l).
Show that b = ca and thatf is given by the mapping me: x ~ cx (multiplication
by c).
(c) Let a be a fractional ideal. For each b E a-I the map mb: a ~ 0 is an element
of the dual a v. Show that 0 -] = a v = Homo( a, 0) under this map, and so
oVv = u ,
13. (a) Let M be a projective finite module over the Dedekind ring o. Show that there
exist free modules F and F' such that F :> M :> F', and F, F' have the same
rank, which is called the rank of M .
(b) Prove that there exists a basis {et , . . . , en} of F and ideals OJ , ••• , an such that
M = ate, + .. . + 0nen' or in other words, M = $
OJ'

III, Ex
EXERCISES
169
(c) Prove that M = 0 n -) Ell a for some ideal a, and that the association M 1--+ a
induces an isomorphism of Ko(o) with the group of ideal classes Pic(o) . (The
group Ko(o) is the group of equivalence classes of projective modules defined at
the end of §4.)
A few snakes
14. Consider a commutative diagram of R-modules and homomorphisms such that each
row is exact :
M ' -----+ M -----+ M" -----+ 0
Ij
oj
1-]
o-----+ N' -----+ N -----+ N"
Prove:
(a) Iff, hare monomorphisms then g is a monomorphism.
(b) Iff, h are surjective, then g is surjective.
(c) Assume in addition that 0 -+ M' -+ M is exact and that N -+ N" -+ 0 is exact.
Prove that if any two off, g, h are isomorphisms, then so is the third . [Hint:
Use the snake lemma.]
15. Thefive lemma.
Consider a commutative diagram of R-modules and homomorph-
isms such that each row is exact :
M 1 -----+ M 2 -----+ M 3 -----+ M 4 -----+ M 5
1 1
~
~
~
N I -----+ N 2 -----+ N 3 -----+ N 4 -----+ N 5
Prove :
(a) 1f!1 is surjective and!2,/4 are rnonomorphisms, then j, is a monomorphism.
(b) If!5 is a monomorphism and!2,/4 are surjective, then j, is surjective. [Hint:
Use the snake lemma.]
Inverse limits
16. Prove that the inverse limit of a system of simple groups in which the homomorphisms
are surjective is either the trivial group , or a simple group .
17. (a) Let n range over the positive integers and let p be a prime number. Show that
the abelian groups An = Z/pnz form an inverse system under the canonical ho-
momorphism if n ~ m. Let Zp be its inverse limit. Show that Zp maps surjec-
tively on each Z/pnZ; that Zp has no divisors of 0, and has a unique maximal
ideal generated by p. Show that Zp is factorial, with only one prime, namely p
itself.

170
MODULES
III, Ex
(b) Next consider all non zero ideals of Z as forming a directed system, by divisibil-
ity. Prove that
~ Z/(a) = fl z.;
(0)
p
where the limit is taken over all non zero ideals (a), and the product is taken
over all primes p.
18. (a) Let {An} be an inversely directed sequence of commutative rings, and let {Mn}
be an inversely directed sequence of modules, Mn being a module over An such
that the following diagram is commutative:
The vertical maps are the homomorphisms of the directed sequence, and the
horizontal maps give the operation of the ring on the module. Show that ~ M n
is a module over ~ An.
(b) Let M be a p-divisible group. Show that Tp(A) is a module over Zp.
(c) Let M, N be p-divisible groups. Show that TpCM $
N) = Tp(M) $
Tp(N), as
modules over Zp.
Direct limits
19. Let (A j,f~) be a directed family of modules. Let ak E Ak for some k, and suppose that
the image of ak in the direct limit A is O. Show that there exists some indexj ;;:; k such
that f'(ak) = O. In other words. whether some element in some group Ai vanishes
in the direct limit can already be seen within the original data. One way to see this
is to use the construction of Theorem 10.1.
20. Let I. J be two directed sets. and give the product I x J the obvious ordering that
(i,j) ~ (i'.j') if i ~ i' and j ~ j'.
Let Aij be a family of abelian groups. with homo-
morphisms indexed by I x J, and forming a directed family. Show that the direct
limits
lim limA jj
and lim limA jj
i
j
j
exist and are isomorphic in a natural way. State and prove the same result for inverse
limits.
21. Let (Mi,f~), (M;, g~) be directed systems of modules over a ring. Bya homomorphism
one means a family of homomorphisms U j : Mi -+ M, for each i which commute with
thef~, g~ . Suppose we are given an exact sequence
of directed systems, meaning that for each i, the sequence

III, Ex
is exact. Show that the direct limit preserves exactness, that is
0-+ lim M', -+ lim M, -+ lim M " -+ 0
is exact.
EXERCISES
171
22. (a) Let {Mil be a family of modules over a ring. For any module N show that
Hom(EJj u, N) = Il Hom(M;, N)
(b) Show that
Hom(N, Il M;) = nHom(N, MJ
23. Let {MJ be a directed family of modules over a ring. For any module N show that
lim Hom( N , M i ) = Hom(N, lim M;)
24. Show that any module is a direct limit of finitely generated submodules.
A module M is called finitely presented if there is an exact sequence
where F0' Fl are free with finite bases. The image of F 1 in F0 issaid to be the submodule
of relations, among the free basis elements of Fo-
25. Show that any module is a direct limit of finitely presented modules (not necessarily
submodules). In other words, given M, there exists a directed system {M i , fJ} with M;
finitely presented for all i such that
[Hint:
Any finitely generated submodule is such a direct limit, since an infinitely
generated module of relations can be viewed as a limit of finitely generated modules of
relations. Make this precise to get a proof.]
26. Let E be a module over a ring. Let {MJ be a directed family of modules. If E is finitely
generated, show that the natural homomorphism
lim Hom(E, M;) -+ Hom(E, lim M;)
is injective. If E is finitely presented, show that this homomorphism is an isomorphism.
Hint:
First prove the statements when E is free with finite basis. Then, say E is
finitely presented by an exact sequence F 1 -+ F 0 -+ E -+ O. Consider the diagram :
o~ lim Hom(E, M;)~ lim Hom(F0 , M;) ~ lim Hom(F l ' M;)
I
I
I
o~ Hom(E, lim M i) ~ Hom(F 0 , lim M i) ~ Hom(F t- lim M i)

172
MODULES
Graded Algebras
III, Ex
Let A be an algebra over a field k. By a filtration of A we mean a sequence of k-
vector spaces A; (i = 0, I, .. .) such that
Ao cAl c A2 c ...
and
UA; = A,
and A;Aj c Ai+j for all i, j
~ O. We then call A a filtered algebra. Let R be an
algebra. We say that R is graded if R is a direct sum R = EB R; of subspaces such that
R;Rj c Ri+j for all i, j ~ o.
27. Let A be a filtered algebra. Define R; for i ~ 0 by R; = AdA;_I. By definition,
A_I = {OJ. Let R = EBR;, and R; = gr;(A). Define a natural product on R making
R into a graded algebra, denoted by gr(A), and called the associated graded algebra.
28. Let A, B befiltered algebras, A = UA; and B = UB;. Let L: A -> B be a k-linear
map preserving the filtration, that is L(A;) c B; for all i, and L(ca) = L(c)L(a) for
c E k and a E A; for all i.
(a) Show that L induces a k-linear map
gr;(L): gr;(A) -> gr;(B)
for all i.
(b) Suppose that gr;(L) is an isomorphism for all i. Show that L is a k-linear
isomorphism.
29. Suppose k has characteristic O. Let n be the set of all strictly upper triangular ma-
trices of a given size n x n over k.
(a) For a given matrix X E n, let D,(X), . .. ,Dn(X) be its diagonals, so Dl =
D, (X) is the main diagonal, and is 0 by the definition of n. Let n; be the
subset of n consisting of those matrices whose diagonals D, , . . . ,Dn- ; are O.
Thus no = {OJ, nl consists of all matrices whose components are 0 except
possibly for Xnn; n2 consists of all matrices whose components are 0 except
possibly those in the last two diagonals; and so forth. Show that each n, is
an algebra, and its elements are nilpotent (in fact the (i + I )-th power of its
elements is 0).
(b) Let U be the set of elements I + X with X E n. Show that U is a multi-
plicative group.
(c) Let exp be the exponential series defined as usual. Show that exp defines a
polynomial function on n (all but a finite number of terms are 0 when eval-
uated on a nilpotent matrix), and establishes a bijection
exp: n -> U.
Show that the inverse is given by the standard log series.

CHAPTER IV
Polynomials
This chapter provides a continuation of Chapter II, §3. We prove stan-
dard properties of polynomials. Most readers will be acquainted with some
of these properties, especially at the beginning for polynomials in one vari-
able. However, one of our purposes is to show that some of these properties
also hold over a commutative ring when properly formulated.
The Gauss
lemma and the reduction criterion for irreducibility will show the importance
of working over rings. Chapter IX will give examples of the importance of
working over the integers Z themselves to get universal relations. It happens
that certain statements of algebra are universally true. To prove them, one
proves them first for elements of a polynomial ring over Z, and then one
obtains the statement in arbitrary fields (or commutative rings as the case
may be) by specialization.
The Cayley-Hamilton theorem of Chapter XV,
for instance, can be proved in that way.
The last section on power series shows that the basic properties of
polynomial rings can be formulated so as to hold for power series rings. I
conclude this section with several examples showing the importance of power
series in various parts of mathematics.
§1.
BASIC PROPERTIES FOR POLYNOMIALS
IN ONE VARIABLE
We start with the Euclidean algorithm.
Theorem 1.1.
Let A be a commutative ring, let f, g E A[X] be poly-
nomials in one variable, of degrees
~ 0, and assume that the leading
173
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

174
POLYNOMIALS
IV, §1
coefficient of 9 is a unit in A.
Then there exist unique polynomials
q, r E A [X] such that
f = gq + r
and deg r < deg g.
Proof
Write
f(X) = anXn+
+ ao,
g(X) = bdxd+
+ bo,
where n = deg J, d = deg 9 so that an, bd =J 0 and bd is a unit in A. We use
induction on n.
If n = 0, and deg 9 > deg J, we let q = 0, r = [. If deg 9 = deg f = 0, then
we let r = 0 and q = anbi 1•
Assume the theorem proved for polynomials of degree < n (with n > 0).
We may assume deg 9 ;:£ degf (otherwise, take q = 0 and r =f). Then
where f1(X) has degree < n. By induction, we can find ql' r such that
and deg r < deg g. Then we let
to conclude the proof of existence for q, r.
As for uniqueness, suppose that
with deg r1 < deg 9 and deg rz < deg g. Subtracting yields
Since the leading coefficient of 9 is assumed to be a unit, we have
deg(ql - qz)g = deg(q1 - qz) + deg g.
Since deg(rz - rd < deg g, this relation can hold only if q1 - qz = 0, i.e.
q1 = qz, and hence finally r1 = rz as was to be shown.
Theorem 1.2.
Let k be a field. Then the polynomial ring in one variable
k[X] is principal.

IV, §1
BASIC PROPERTIES FOR POLYNOMIALS IN ONE VARIABLE
175
Proof.
Let a be an ideal of k[X], and assume a =I- O.
Let 9 be an
element of a of smallest degree
~ O.
Let f be any element of a such that
f =I- O. By the Euclidean algorithm we can find q, r E k[X] such that
f = qg + r
and deg r < deg g. But r = f - qg, whence r is in a. Since g had minimal
degree
~ 0 it follows that r = 0, hence that a consists of all polynomials qg
(with q E k[X]). This proves our theorem. By Theorem 5.2 of Chapter II we
get :
Corollary 1.3.
The ring k[X] is factorial.
If k is a field then every non-zero element of k is a unit in k, and one sees
immediately that the units of k[X] are simply the units of k. (No polyno-
mial of degree
~ 1 can be a unit because of the addition formula for the
degree of a product.)
A polynomial f (X ) E k[X] is called irreducible if it has degree ~ 1, and if
one cannot write f(X) as a product
f(X) = g(X)h(X)
with g, h E k[X], and both g, h rt:. k. Elements of k are usually called constant
polynomials, so we can also say that in such a factorization, one of g or h must
be constant. A polynomial is called monic if it has leading coefficient 1.
Let A be a commutative ring and f(X) a polynomial in A[X]. Let A be
a subring of B.
An element b E B is called a root or a zero of f in B if
f(b) = O. Similarly, if (X) is an n-tuple of variables, an n-tuple (b) is called a
zero of f if f(b) = O.
Theorem 1.4.
Let k be a field and f a polynomial in one variable X in
k[X], of degree n ~ O. Then f has at most n roots in k, and if a is a root
of f in k, then X - a divides f(X).
Proof.
Suppose f(a) = O. Find q, r such that
f(X) = q(X)(X - a) + r(X)
and deg r < 1. Then
o= f(a) = r(a).
Since r = 0 or r is a non-zero constant, we must have r = 0, whence X - a
divides f(X). If a1, • •• , am are distinct roots of f in k, then inductively we see
that the product

176
POLYNOMIALS
IV, §1
divides f(X), whence m ~ n, thereby proving the theorem. The next corollaries
give applications of Theorem 1.4 to polynomial functions.
Corollary 1.5.
Let k be a field and T an infinite subset of k.
Let
f(X) E k[X] be a polynomial in one variable. If f(a) = 0 for all a E T, then
f = 0, i.e. f induces the zero function.
Corollary 1.6.
Let k be a field, and let Sl' ... , S; be infinite subsets of k.
Let f(X 1, .. . , Xn ) be a polynomial in n variables over k. If f(a 1, ... , an) = 0
for all a, E S, (i = 1,... , n), then f =o.
Proof
By induction.
We have just seen the result is true for one
variable. Let n ~ 2, and write
f(X1, ... , Xn) = Lh(Xt, ... ,xn-dxj
j
as a polynomial in K; with coefficients in k[X1 , .. . , Xn- t ]. Ifthere exists
such that for some j we have h(bl , • • • ,bn- I ) # 0, then
is a non-zero polynomial in k[Xn] which takes on the value 0 for the infinite
set of elements Sn' This is impossible. Hence Jj induces the zero function on
S, x ... X Sn-l for all j, and by induction we have Jj = 0 for all j . Hence
f = 0, as was to be shown.
Corollary 1.7.
Let k be an infinite field and f a polynomial in n variables
over k. Iff induces the zero function on kIn), then f = o.
We shall now consider the case of finite fields. Let k be a finite field with
q elements. Let f(X 1, .. . , Xn) be a polynomial in n variables over k. Write
If a(y) # 0, we recall that the monomial M(v)(X) occurs in f
Suppose this is
the case, and that in this monomial M(v)(X), some variable Xi occurs with an
exponent Vi ~ q. We can write
jJ. = integer ~ O.
If we now replace XiV, by Xr+ 1 in this monomial, then we obtain a new
polynomial which gives rise to the same function as f
The degree of this
new polynomial is at most equal to the degree off

IV, §1
BASIC PROPERTIES FOR POLYNOMIALS IN ONE VARIABLE
177
Performing the above operation a finite number of times, for all the
monomials occurring in f and all the variables Xl' ... , X; we obtain some
polynomial f* giving rise to the same function as J, but whose degree in
each variable is < q.
Corollary 1.8.
Let k be a finite field with q elements.
Let f
be a
polynomial in n variables over k such that the degree of f in each variable
is < q. Iff induces the zero function on kIn), then f = o.
Proof.
By induction. If n = 1, then the degree of f is < q, and hence f
cannot have q roots unless it is O. The inductive step is carried out just as
we did for the proof of Corollary 1.6 above.
Let rbe a polynomial in n variables over the finite field k. A polynomial
g whose degree in each variable is < q will be said to be reduced. We have
shown above that there exists a reduced polynomial f* which gives the same
function as f on kIn). Theorem 1.8 now shows that this reduced polynomial is
unique. Indeed, if gl' g2 are reduced polynomials giving the same function,
then gl - gz is reduced and gives the zero function . Hence gl - gz = 0 and
gl = gz·
We shall give one more application of Theorem 1.4. Let k be a field. By
a multiplicative subgroup of k we shall mean a subgroup of the group k*
(non-zero elements of k).
Theorem 1.9.
Let k be a field and let U be a finite multiplicative sub-
group of k. Then U is cyclic.
Proof.
Write U as a product of subgroups U(p) for each prime p, where
U(p) is a p-group. By Proposition 4.3(v) of Chapter I, it will suffice to prove
that U(p) is cyclic for each p. Let a be an element of U(p) of maximal period
pr for some integer r. Then xpr = 1 for every element x E U(p), and hence all
elements of U(p) are roots of the polynomial
Xpr - 1.
The cyclic group generated by a has p" elements. If this cyclic group is not
equal to U(p), then our polynomial has more than pr roots, which is
impossible. Hence a generates U(p), and our theorem is proved.
Corollary 1.10. If k is a finite field, then k* is cyclic.
An element ( in a field k such that there exists an integer n ~ 1 such that
(n = 1 is called a root of unity, or more precisely an n-th root of unity. Thus
the set of n-th roots of unity is the set of roots of the polynomial X" - 1.
There are at most n such roots, and they obviously form a group, which is

178
POLYNOMIALS
IV, §1
cyclic by Theorem 1.9.
We shall study roots of unity in greater detail
later.
A generator for the group of n-th roots of unity is called a primitive
n-th root of unity. For example, in the complex numbers, e2ni/n is a primi-
tive n-th root of unity, and the n-th roots of unity are of type e2ni. /n with
1 ~ vs n.
The group of roots of unity is denoted by u, The group of roots of unity
in a field K is denoted by Jl(K).
A field k is said to be algebraically closed if every polynomial in k[X] of
degree ;;; 1 has a root in k. In books on analysis, it is proved that the
complex numbers are algebraically closed. In Chapter V we shall prove that
a field k is always contained in some algebraically closed field. If k is
algebraically closed then the irreducible polynomials in k[X] are the poly-
nomials of degree 1. In such a case, the unique factorization of a polynomial
f of degree ;;; 0 can be written in the form
r
f(X) = c TI (X -
lXi)m i
i=1
with c e k, c#O and distinct roots lX1, .. . ,lXr • We next develop a test when
m.:» 1.
Let A be a commutative ring. We define a map
D: A[X] --+ A [X]
of the polynomial ring into itself. If f(X) = a.X" + ...+ ao with a, E A, we
define the derivative
n
Df(X) = f'(X) = L va.X·-1 = nanX
n- 1 + ...+ a1 •
.=1
One verifies easily that if f, g are polynomials in A[X], then
and if a E A, then
(f + g)' = I' + g',
(fg), = f'g + fg',
(af), = af'.
Let K be a field and f a non-zero polynomial in K[X]. Let a be a root
of fin K. We can write
f(X) = (X - a)mg(x)
with some polynomial g(X) relatively prime to X - a (and hence such that
g(a) # 0). We call m the multiplicity of a in J, and say that a is a multiple
root if m > 1.

IV, §1
BASIC PROPERTIES FOR POLYNOMIALS IN ONE VARIABLE
179
Proposition 1.11.
Let K, J be as above. The element a oj K is a multiple
root ofJ if and only if it is a root and j'(a) = 0.
Proof.
Factoring J as above, we get
j'(X) = (X - a)mg,(X) + m(X - a)m-lg(X).
If m > 1, then obviously j'(a) = 0. Conversely, if m = 1 then
j'(X) = (X - a)g'(X) + g(X),
whence j'(a) = g(a) =I: 0. Hence if j'(a) =°we must have m > 1, as desired.
Proposition 1.12.
Let J E K[X].
IJ K has characteristic 0, and J has
degree
~ 1, then I' =I: 0. Let K have characteristic p >°and J have
degree
~ 1. Then j' = °if and only if, in the expression for J(X) given
by
n
J(X) = L a.X',
v=O
p divides each integer v such that a. =I: O.
Proof. If K has characteristic 0, then the derivative of a monomial a.X"
such that v ~ 1 and a. =I:°is not zero since it is va.X·-1•
If K has
characteristic p > 0, then the derivative of such a monomial is°if and only if
plv, as contended.
Let K have characteristic p > 0, and let J be written as above, and be
such that j'(X) = 0. Then one can write
d
f(X) = L bp.XpP.
jl =O
with bp. E K.
Since the binomial coefficients (~) are divisible by p for 1 :;;; v :;;; p - 1 we
see that if K has characteristic p, then for a, b E K we have
Since obviously (ab)P = arb", the map
is a homomorphism of K into itself, which has trivial kernel, hence is
injective. Iterating, we conclude that for each integer r ~ 1, the map x H xP"

180
POLYNOMIALS
IV, §2
is an endomorphism of K, called the Frobenius endomorphism. Inductively, if
C\ , • •• , Cn are elements of K , then
Applying these remarks to polynomials, we see that for any element a E K
we have
If C E K and the polynomial
has one root a in K, then apr = C and
xr - C = (X - a)P'.
Hence our polynomial has precisely one root, of multiplicity pro
For in-
stance, (X -
1)P' = xr -
1.
§2.
POLYNOMIALS OVER A FACTORIAL RING
Let A be a factorial ring, and K its quotient field. Let a E K , a "# o. We
can write a as a quotient of elements in A, having no prime factor in
common. If p is a prime element of A, then we can write
a = p'b,
where b E K, r is an integer, and p does not divide the numerator or
denominator of b. Using the unique factorization in A, we see at once that r
is uniquely determined by a, and we call r the order of a at p (and write
r = ord, a). If a = 0, we define its order at p to be 00 .
If a, a' E K and aa' "# 0, then
This is obvious.
Let J(X) E K[X] be a polynomial in one variable, written
J(X) = ao + a\X + ... + anXn.
If J = 0, we define ord, J to be 00 . If J "# 0, we define ord, J to be

IV, §2
POLYNOMIALS OVER A FACTORIAL RING
181
ord, f = min ord, ai'
the minimum being taken over all those i such that a, #- 0.
If r = ord, f, we call up' a p-content for f, if u is any unit of A. We define
the content of f to be the product.
the product being taken over all p such that ord, f #-0, or any multiple of
this
product by a unit of A.
Thus the content is well defined up
to
multiplication by a unit of A. We abbreviate content by cont.
If b E K, b #- 0, then cont(bf) = b cont(f). This is clear. Hence we can
write
where c = cont(f), and fl (X) has content 1. In particular, all coefficients of
fl lie in A, and their g.c.d. is 1. We define a polynomial with content 1 to be
a primitive polynomial.
Theorem 2.1.
(Gauss Lemma).
Let A be a factorial ring, and let K be
its quotient field. Let f, g E K[X] be polynomials in one variable. Then
cont(fg) = cont(f) cont(g).
Proof.
Writing f = Cf I and g = dq, where c = cont(f) and d = cont(g),
we see that it suffices to prove : If f, g have content 1, then fg also has
content 1, and for this, it suffices to prove that for each prime p, ordp(fg)= 0.
Let
f(X) = anXn+
+ ao,
g(X) = bmXm+
+ bo,
be polynomials of content 1. Let p be a prime of A. It will suffice to prove
that p does not divide all coefficients of fg. Let r be the largest integer such
that °~ r ~ n, a, #- 0, and p does not divide a..
Similarly, let b, be the
coefficient of g farthest to the left, bs #- 0, such that p does not divide b.,
Consider the coefficient of xr+s in f(X)g(X). This coefficient is equal to
c = arbs + ar+1 bs-I + .
+ ar - I bS +1 + .
and p %arbs. However, p divides every other non-zero term in this sum since
in each term there will be some coefficient a, to the left of a, or some
coefficient bj to the left of b.. Hence p does not divide c, and our lemma is
proved.

182
POLYNOMIALS
IV, §2
We shall now give another proof for the key step in the above argument,
namely the statement:
Iff, g E A [X] are primitive (i.e. have content 1) then fg is primitive.
Proof
We have to prove that a given prime p does not divide all the
coefficients of fg.
Consider reduction mod p, namely the canonical homo-
morphism A ---t A/(p) = A. Denote the image of a polynomial by a bar, so
f f---+J and g f---+ g under the reduction homomorphism. Then
JiJ =]g.
By hypothesis, J=I0 and g =I O. Since it is entire, it follows that JiJ =I 0, as
was to be shown.
Corollary 2.2.
Let f(X) E A[X] have a factorization f(X) = g(X)h(X) in
K[X]. If cg = cont(g), Ch = cont(h), and g = cggt, h = chht, then
f(X) = cgchgt (X)h t(X),
and CgCh is an element of A. In particular, if [, g E A [X] have content 1,
then h e A [X] also.
Proof
The only thing to be proved is CgCh E A. But
cont(f) = CgCh cont(gtht) = CgCh'
whence our assertion follows.
Theorem 2.3.
Let A be a factorial ring. Then the polynomial ring A [X]
in one variable is factorial. Its prime elements are the primes of A and poly-
nomials in A[X] which are irreducible in K[X] and have content 1.
Proof
Let fEA[X], f#O.
Using the unique factorization in K[X]
and the preceding corollary, we can find a factorization
f(X) = c· Pt(X) .. . p,(X)
where C E A, and Pt, ... , p, are polynomials in A[X] which are irreducible in
K[X]. Extracting their contents, we may assume without loss of generality
that the content of Pi is I for each i, Then C = cont(f) by the Gauss lemma.
This gives us the existence of the factorization. It follows that each Pi(X) is
irreducible in A[X]. If we have another such factorization, say
f(X) = d'qt(X) '" qs(X),
then from the unique factorization in K[X] we conclude that r = s, and after
a permutation of the factors we have

IV, §3
CRITERIA FOR IRREDUCIBILITY
183
with elements a, E K. Since both Pi' qi are assumed to have content 1, it
follows that a, in fact lies in A and is a unit. This proves our theorem.
Corollary 2.4.
Let A be a factorial ring. Then the ring of polynomials in
n variables A[X1 , .. . , Xn] is factorial. Its units are precisely the units of
A, and its prime elements are either primes of A or polynomials which are
irreducible in K [X] and have content 1.
Proof
Induction.
In view of Theorem 2.3, when we deal with polynomials over a factorial
ring and having content 1, it is not necessary to specify whether such
polynomials are irreducible over A or over the quotient field K.
The two
notions are equivalent.
Remark 1.
The polynomial ring K[X 1 , .. . , Xn] over a field K is not
principal when n ~ 2. For instance, the ideal generated by Xl' ... , X; is not
principal (trivial proof).
Remark 2.
It is usually not too easy to decide when a given polynomial
(say in one variable) is irreducible.
For instance, the polynomial X 4 + 4 is
reducible over the rational numbers, because
X 4 + 4 = (X 2 - 2X + 2)(X 2 + 2X + 2).
Later in this book we shall give a precise criterion when a polynomial
X" - a is irreducible. Other criteria are given in the next section.
§3.
CRITERIA FOR IRREDUCIBILITY
The first criterion is:
Theorem 3.1.
(Eisenstein's Criterion).
Let A be a factorial ring. Let K
be its quotient field. Let f(X) = anXn+ ... + ao be a polynomial of degree
n ~ 1 in A[X]. Let p be a primeof A, and assume:
an =1= 0
(mod p),
ai == 0
(mod p)
ao =1= 0
(mod p2).
Then f(X) is irreducible in K[X].
for all
i < n,

184
POLYNOMIALS
IV, §3
1 ~ v ~ p - 1,
Proof
Extracting a g.c.d. for the coefficients of f,
we may assume
without loss of generality that the content of f
is 1. If there exists a
factorization into factors of degree
~ 1 in K[X], then by the corollary of
Gauss' lemma there exists a factorization in A [X], say f(X) = g(X)h(X),
g(X) = bdXd+
+ bo,
h(X) = cmxm+
+ co,
with d, m ~ 1 and bdcm =I- O. Since boco = ao is divisible by p but not p2, it
follows that one of bo, Co is not divisible by p, say boo Then plco. Since
cmbd = an is not divisible by p, it follows that p does not divide Cm' Let c, be
the coefficient of h furthest to the right such that c, ¥= 0 (mod p). Then
Since p, bocr but p divides every other term in this sum, we conclude that
p,a" a contradiction which proves our theorem.
Example.
Let a be a non-zero square-free integer
=I- ± 1. Then for any
integer n ~ 1, the polynomial X" - a is irreducible over Q. The polynomials
3Xs - 15 and 2X 10 -
21 are irreducible over Q.
There are some cases in which a polynomial does not satisfy Eisenstein's
criterion, but a simple transform of it does.
Example.
Let p be a prime number. Then the polynomial
f(X) = X p-l + ... + 1
is irreducible over Q.
Proof
It will suffice to prove that the polynomial f(X + 1) is irreducible
over Q. We note that the binomial coefficients
(~) = v!(:~ v)!'
are divisible by p (because the numerator is divisible by p and the denomina-
tor is not, and the coefficient is an integer). We have
(X + l)P - 1
X p + pXp-l + ...+ pX
f(X + 1) = (X + 1) _ 1 =
X
from which one sees that f(X + I) satisfies Eisenstein's criterion.
Example.
Let E be a field and t an element of some field containing E such
that
t
is transcendental over
E.
Let K
be the quotient field of
E[ r].

IV, §3
CRITERIA FOR IRREDUCIBILITY
185
For any integer n ~ 1 the polynomial X" - t is irreducible in K[X].
This
comes from the fact that the ring A = E[t] is factorial and that t is a prime
in it.
Theorem 3.2.
(Reduction Criterion).
Let A, B be entire rings, and let
cp: A --+ B
be a homomorphism. Let K, L be the quotient fields of A and B respec-
tively.
Let f E A [X] be such that cpf*0 and deg cpf= deg [.
If cpf is
irreducible in L[X], then f does not have a factorization f(X) = g(X)h(X)
with
g,hEA[X]
and
deg g, deg h ~ 1.
Proof.
Suppose f has such a factorization.
Then cpf= (cpg)(cph). Since
deg cpg ~ deg 9 and deg cph ~ deg h, our hypothesis implies that we must
have equality in these degree relations.
Hence from the irreducibility in
L[X] we conclude that 9 or h is an element of A, as desired.
In the preceding criterion, suppose that A is a local ring, i.e. a ring having
a unique maximal ideal p, and that p is the kernel of cp.
Then from the
irreducibility of cpf in L[X] we conclude the irreducibility of f in A[X].
Indeed, any element of A which does not lie in p must be a unit in A, so our
last conclusion in the proof can be strengthened to the statement that 9 or h
is a unit in A.
One can also apply the criterion when A is factorial, and in that case
deduce the irreducibility of f in K[X].
Example.
Let p be a prime
number.
It will be shown later that
XP - X- I is irreducible over the field Z /pZ. Hence XP - X-I is irreduc-
ible over Q. Similarly,
X 5 -
5X4 -
6X - 1
is irreducible over Q.
There is also a routine elementary school test whether a polynomial has a
root or not.
Proposition 3.3.
(Integral Root Test).
Let A be a factorial ring and K
its quotient field. Let
f(X) = a.X" + ... + ao E A [X].
Let a E K be a root of f, with rx = bid expressed with b, d E A and b, d
relatively prime. Then blao and dian. In particular, if the leading coefficient
an is I, then a root rx must lie in A and divides ao.

186
POLYNOMIALS
IV. §4
We leave the proof to the reader, who should be used to this one from way
back. As an irreducibility test, the test is useful especially for a polynomial of
degree 2 or 3, when reducibility is equivalent with the existence of a root in
the given field.
§4.
HILBERT'S THEOREM
This section proves a basic theorem of Hilbert concerning the ideals of a
polynomial ring. We define a commutative ring A to be Noetherian if every
ideal is finitely generated.
Theorem 4.1.
Let A be a commutative Noetherian ring. Then the polyno-
mial ring A[X] is also Noetherian.
Proof
Let ~ be an ideal of A[X]. Let OJ consist of°and the set of ele-
ments a E A appearing as leading coefficient in some polynomial
ao+ a1X + ...+ aX
j
lying in 21. Then it is clear that OJ is an ideal. (If a, b are in 0 ;, then a ± b is
in
OJ as one sees by taking the sum and difference of the corresponding
polynomials.
If x E A, then xa E OJ as one sees by multiplying the corre-
sponding polynomial by x.) Furthermore we have
in other words, our sequence of ideals {c.} is increasing. Indeed, to see this
multiply the above polynomial by X to see that a E 0i+l'
By criterion (2) of Chapter X, §1, the sequence of ideals {c.} stops, say at
00 C
01 C
02 C
. , . C
Or = 0r+l = ....
Let
aOl' • •• , a Ono
be generators for
00'
ar1, ••• , arn,
be generators for
or'
For each i = 0, ... , rand j = 1, .. ., n, let hj be a polynomial in 21, of degree
i, with leading coefficient aij' We contend that the polynomials hj are a set
of generators for 21.
Let f be a polynomial of degree d in 21. We shall prove that f is in the
ideal generated by the hj' by induction on d. Say d ~ 0. If d > r, then we

IV, §5
note that the leading coefficients of
X d-'j,
Xd -'j,
rl' ... ,
rnr
PARTIAL FRACTIONS
187
generate
ad'
Hence
there
exist
elements
cl' . .. , Cnr E A
such
that
the
polynomial
f -
C Xd-'j,
- ' " -
C Xd-'j,
1
rl
"r
rnr
has degree < d, and this polynomial also lies in 21. If d ~ r, we can subtract
a linear combination
to get a polynomial of degree
< d, also lying in 21.
We note that the
polynomial we have subtracted from f lies in the ideal generated by the fij'
By induction, we can subtract a polynomial g in the ideal generated by the
fu such that f - g = 0, thereby proving our theorem.
We note that if tp: A ~ B is a surjective homomorphism of commutative
rings and A is Noetherian, so is B. Indeed, let b be an ideal of B, so q>-l(b)
is an ideal of A. Then there is a finite number of generators (a" . . . , an) for
q>-l(b), and it follows since q> is surjective that b = q>(q>-l(b)) is generated by
q>(a 1 ), ••• , q>(an ), as desired. As an application, we obtain:
Corollary 4.2.
Let A be a Noetherian commutative ring, and let B =
A[x), . .. , xm ] be a commutative ring finitely generated over A. Then B is
Noetherian.
Proof.
Use Theorem 4.1 and the preceding remark, representing B as a
factor ring of a polynomial ring.
Ideals in polynomial rings will be studied more deeply in Chapter IX.
The theory of Noetherian rings and modules will be developed in Chapter X.
§5.
PARTIAL FRACTIONS
In this section, we analyze the quotient field of a principal ring, using the
factoriality of the ring .
Theorem 5.1.
Let A be a principal entire ring, and let P be a set of
representatives for its irreducible elements.
Let K be the quotient field of
A, and let
CI. E K . For each pEP there exists an element
Cl.p E A and an
integer j(p) ~ 0, such that j(p) = °for almost all PEP,
Cl.p and pj(p) are

188
POLYNOMIALS
relatively prime, and
IV, §5
If we have another such expression
IX = L p~rp),
peP
then j(p) = i(p) for all p, and IXp == (3p mod pj(P) for all p.
Proof.
We first prove existence, in a special case. Let a, b be rela-
tively prime non-zero elements of A. Then there exists x, yEA such that
xa + yb = 1. Hence
1
x
Y
-= -+-
ab
b
a'
Hence any fraction clab with c E A can be decomposed into a sum of two
fractions (namely cxfb and cy/a) whose denominators divide b and a respec-
tively. By induction, it now follows that any
IX E K has an expression as
stated in the theorem, except possibly for the fact that p may divide
IXp '
Canceling the greatest common divisor yields an expression satisfying all the
desired conditions.
As for uniqueness, suppose that IX has two expressions as stated in the
theorem. Let q be a fixed prime in P. Then
IXq
{3q
,,(3p
IXp
qj(q) -
qi(q) = /;:q pi(P) - pj(P)'
If j(q) = i(q) = 0, our conditions concerning q are satisfied. Suppose one of
j(q) or i(q) > 0, say j(q), and say j(q) ~ i(q). Let d be a least common multiple
for all powers pj(P) and pi(p) such that p 1= q. Multiply the above equation by
dqj(q). We get
for some (3 E A.
Furthermore, q does not divide d. If i(q) < j(q) then q
divides IXq , which is impossible.
Hence i(q) = j(q).
We now see that qj(q)
divides IXq -
(3q, thereby proving the theorem.
We apply Theorem 5.1 to the polynomial ring k[X] over a field k. We
let P be the set of irreducible polynomials, normalized so as to have leading
coefficient equal to 1. Then P is a set of representatives for all the irreduc-
ible elements of k[X]. In the expression given for IX in Theorem 5.1, we can
now divide IXp by pj(P), i.e. use the Euclidean algorithm, if deg IXp ~ deg pj(P).
We denote the quotient field of k[X] by k(X), and call its elements rational
functions.

IV, §5
PARTIAL FRACTIONS
189
Theorem 5.2.
Let A = k[X] be the polynomial ring in one variable over a
field k. Let P be the set of irreducible polynomials in k[X] with leading
coefficient 1. Then any element f of k(X) has a unique expression
/P(X)
f(X) = L
(XV(p) + g(X),
p e P P
J
where /p, 9 are polynomials, /p = 0 if j(p) = 0, /p is relatively prime to p if
j(p) > 0, and deg /p < deg pj(p) if j(p) > O.
Proof
The existence follows at once from our previous remarks. The
uniqueness follows from
the fact that if we have two expressions, with
elements /p and
CfJp respectively, and polynomials g, h, then pj(p) divides
/p -
CfJp' whence /p -
CfJp = 0, and therefore /p =
CfJp, 9 = h.
One can further decompose the term /P/pj(p) by expanding /p according to
powers of p. One can in fact do something more general.
Theorem 5.3.
Let k be a field and k[X] the polynomial ring in one
variable. Let J, 9 E k[X], and assume deg 9 f; 1. Then there exist unique
polynomials
such that deg /; < deg 9 and such that
Proof
We first prove existence. If deg 9 > deg f, then we take fo = f
and /; = 0 for i > O.
Suppose deg 9 ~ deg f
We can find polynomials q, r
with deg r < deg 9 such that
f = qg + r,
and since deg 9 f; 1 we have deg q < deg f
Inductively, there exist polyno-
mials ho, hl , . .. , hs such that
q = ho + hlg + ... + hsg
S
,
and hence
f = r + hog + ... + hsg
S +1 ,
thereby proving existence.
As for uniqueness, let
be two expressions satisfying the conditions of the theorem. Adding terms

190
POLYNOMIALS
IV, §6
equal to 0 to either side, we may assume that m = d. Subtracting, we get
Hence g divides 10 - <Po, and since deg(Jo -
<Po) < deg g we see that 10 = <Po·
Inductively, take the smallest integer i such that Ii # <Pi (if such i exists).
Dividing the above expression by o' we find that g divides Ii -
<Pi and hence
that such i cannot exist. This proves uniqueness.
We shall call the expression for 1 in terms of g in Theorem 5.3 the g-adic
expansion of f
If g(X) = X, then the g-adic expansion is the usual expres-
sion of 1 as a polynomial.
Remark.
In some sense, Theorem 5.2 redoes what was done in Theorem
8.1 of Chapter I for Q/Z; that is, express explicitly an element of K /A as a
direct sum of its p-components.
§6.
SYMMETRIC POLYNOMIALS
Let A be a commutative ring and let t l, ... , tn be algebraically indepen-
dent elements over A. Let X be a variable over A[t l , .. . , tnJ. We form the
polynomial
F(X) = (X - td ... (X - tn )
= x n - Slxn-l + ...+ (-ltsn'
where each s, = Si(tl ' . . . , tn) is a polynomial in tl, . . . , tn' Then for instance
and
The polynomials S l , ... , s; are called the elementary symmetric polynomials
oft1, · .. , tn•
We leave it as an easy exercise to verify that s, is homogeneous of degree i
in r., .. · , tn •
Let
(J be a permutation of the integers (1, ..., n). Given a polynomial
l(t) E A[t] = A[tt, . .. , tn], we define alto be
If a, T are two permutations, then aTI = a(Tf) and hence the symmetric group
G on n letters operates on the polynomial ring A[t] . A polynomial is called
symmetric if af = I for all a
E G. It is clear that the set of symmetric
polynomials is a subring of A[t], which contains the constant polynomials

IV, §6
SYMMETRIC POLYNOMIALS
191
(i.e. A itself) and also contains the elementary symmetric polynomials sl' .. . , sn'
We shall see below that A[Sl' ... , snJ is the ring of symmetric polynomials.
Let Xl' ... , X; be variables. We define the weight ofa monomial
to
be
Vl + 2v2 + ... + nvn•
We
define
the
weight
of
a
polynomial
g(X1, ... , Xn) to be the maximum of the weights of the monomials occurring
in g.
Theorem 6.1.
Let f(t) E A[tl,
, tnJ be symmetric of degree d.
Then
there exists a polynomial g(X i -
, Xn) of weight ~ d such that
f(t) = g(Sl' ... , sn)'
If f is homogeneous of degree d, then every monomial occurring in g has
weight d.
Proof.
By induction on n. The theorem is obvious if n = 1, because
Sl = tl. Assume the theorem proved for polynomials in n - 1 variables.
If we substitute t; = 0 in the expression for F(X), we find
where (Sj)o is the expression obtained by substituting tn = 0 in Sj' We see
that (Sl)O"'" (sn-do are precisely the elementary symmetric polynomials in
t l , . .. , tn- l ·
We now carry out induction on d. If d = 0, our assertion is trivial.
Assume d > 0, and assume our assertion proved for polynomials of degree
< d.
Let
f(t l' .. . , tn )
have
degree
d.
There
exists
a
polynomial
gl (Xl' ... , Xn-d of weight ~ d such that
f(t l, .. ., tn-l, 0) = gl«(Sl)O, .. ., (sn-do).
We note that gl(Sl , .. ., sn-d has degree ~ d in tl, ... , tn' The polynomial
has degree ~ d (in t l ' ... , tn ) and is symmetric. We have
Hence fl is divisible by tn' i.e. contains t, as a factor. Since fl is symmetric,
it contains t 1 •• • tn as a factor. Hence
fl = Sn/2(tl, ... , tn)
for some polynomial f2' which must be symmetric, and whose degree is

192
POLYNOMIALS
IV, §6
~ d - n < d. By induction, there exists a polynomial gz in n variables and
weight ~ d - n such that
We obtain
and each term on the right has weight ~ d. This proves our theorem, except for
the last statement which will be left to the reader.
We shall now prove that the elementary symmetric polynomials s l ' .. . , Sn
are algebraically independent over A.
If they are not, take a polynomial f(X l' ... , Xn) E A [X] of least degree
and not equal to 0 such that
Write f as a polynomial in X; with coefficients in A[Xl , · · · , X n - l ] ,
Then fo =1= O. Otherwise, we can write
f(X) = Xn",(X)
with some polynomial "', and hence Sn"'(Sl' ... , sn) = O. From this it follows
that "'(Sl, .. ., sn) = 0, and'" has degree smaller than the degree off .
We substitute Si for Xi in the above relation, and get
o= fO(Sl' ... , sn-d + ...+ fisp .. ., sn-ds~ .
This is a relation in A [t l' . . • , tn] , and we substitute 0 for t; in this relation.
Then all terms become 0 except the first one, which gives
using the same notation as in the proof of Theorem 6.1. This is a non-trivial
relation between the elementary symmetric polynomials in t l , ... , tn- l , a
contradiction.
Example.
(The Discriminant).
Let f(X) = (X - td ... (X - tn).
Con-
sider the product
For any permutation (J of (1, ... , n) we see at once that
ocr(t) = ±o(t).

IV, §6
SYMMETRIC POLYNOMIALS
193
Hence c5(t)2 is symmetric, and we call it the discriminant:
D, = D(SI' ... , sn) = n(ti -
t)2.
i<j
We thus view the discriminant as a polynomial in the elementary symmetric
functions. For a continuation of the general theory, see §8. We shall now
consider special cases.
Quadratic case.
You should verify that for a quadratic polynomial
f(X) = X 2 + bX + c, one has
D = b2 - 4c.
Cubic case.
Consider f(X) = X 3 + aX + b. We wish to prove that
D = -4a3 - 27b2•
Observe first that D is homogeneous of degree 6 in t 1, t2 • Furthermore, a is
homogeneous of degree 2 and b is homogeneous of degree 3. By Theorem
6.1 we know that there exists some polynomial g(X2 , X 3 ) of weight 6 such
that D = g(a, b).
The only monomials
XTX~ of weight 6, i.e. such that
2m+ 3n = 6 with integers m, n ~ 0, are those for which m = 3, n = 0, or
m = °and n = 2. Hence
where v, ware integers which must now be determined.
Observe that the integers v, ware universal, in the sense that for any
special polynomial with special values of a, b its discriminant will be given
by g(a, b) = va3 + wb".
Consider the polynomial
fl(X) = X(X -
I)(X + 1) = X 3 -
X.
Then a = -1, b = 0, and
D = va3 = -v.
But also D = 4 by using the
definition of the discriminant of the product of the differences of the roots,
squared. Hence we get v = -4. Next consider the polynomial
Then a = 0, b = -1, and D = wb2 = W. But the three roots of fi are the
cube roots of unity, namely
-1+)=3 -1-)=3
1,
2
'
2
.
Using the definition of the discriminant we find the value D = - 27. Hence
we get w = - 27. This concludes the proof of the formula for the dis-
criminant of the cubic when there is no X 2 term.

194
POLYNOMIALS
In general, consider a cubic polynomial
IV, §7
We find the value of the discriminant by reducing this case to the simpler
case when there is no X 2 term. We make a translation, and let
Then f(X) becomes
f(X) = f*(Y) = y 3 + aY + b = (Y -
ud(Y -
U2)(Y -
u 3),
where
a = U1U 2 + U2U 3 + U1U 3 and
b = -U 1U 2U3, while
U 1 + U2 + U3 = 0.
We have
for
i = 1, 2, 3,
and u, ~ uj = t, - tj for all i # j, so the discriminant is unchanged, and you
can easily get the formula in general. Do Exercise 12(b).
§7.
MASON-STOTHERS THEOREM AND THE
abc CONJECTURE
In the early 80s a new trend of thought about polynomials started with the
discovery of an entirely new relation . Let J(t) be a polynomial in one variable
over the complex numbers if you wish (an algebraically closed field of charac-
teristic°would do). We define
no(f) = number of distinct roots of f.
Thus no(f) counts the zeros of f by giving each of them multiplicity 1, and
no(f) can be small even though deg f is large.
Theorem 7.1 (Mason-Stothers, [Mas 841, [Sto 81)).
Let aCt), bet), e(t) be
relatively prime polynomials sueh that a + b = e. Then
maxdeg{a,b ,e} ~ no(abe)-1.
Proof
(Mason) Dividing bye, and letting f = al e, g = ble we have
f + g = 1,
where f, g are rational functions.
Differentiating we get f' + g' = 0, which
we rewrite as

IV, §7
so that
MASON'S THEOREM AND THE abc CONJECTURE
195
b
g
!'I!
.rr: -g'lg '
Let
a(t) = c 1 TI (t - a;)mi ,
Then by calculus algebraicized in Exercise 11(c), we get
b
!'I!
a
e'le
A common denominator for !'I! and g'lg is given by the product
No = TI (t - a;) TI (t - P) TI (t - Yk),
whose degree is no(abc). Observe that No!'l! and Nog'lg are both polyno-
mials of degrees at most no(abc) -
1. From the relation
b
No!'l!
a- - Nog'lg'
and the fact that a, b are assumed relatively prime, we deduce the inequality
in the theorem,
As an application, let us prove Fermat's theorem for polynomials. Thus
let x(t), y(t), z(t) be relatively prime polynomials such that one of them has
degree f; 1, and such that
x(t)" + y(t)" = z(t)".
We want to prove that n ;;::; 2. By the Mason-Stothers theorem, we get
n deg x = deg x(t)" ;;::; deg x(t) + deg y(t) + deg z(t) - 1,
and similarly replacing x by y and z on the left-hand side. Adding, we find
n(deg x + deg y + deg z) ;;::; 3(deg x + deg y + deg z) - 3.
This yields a contradiction if n f; 3.
As another application in the same vein, one has :
Davenport's theorem.
Let!, g be non-constant polynomials such that
!3 _ g2 =F O. Then
See Exercise 13.

196
POLYNOMIALS
IV, §7
One of the most fruitful analogies in mathematics is that between the
integers Z and the ring of polynomials F[tJ over a field F. Evolving from
the insights of Mason [Ma 84J, Frey [Fr 87J, Szpiro, and others, Masser and
Oesterle formulated the abe conjecture for integers as follows. Let m be a
non-zero integer. Define the radical of m to be
No(m) = TI p,
plm
i.e. the product of all the primes dividing m, taken with multiplicity 1.
The abc conjecture.
Given s > 0, there exists a positive number C(e) having
the following property. For any non-zero relative prime integers a, b, e
sueh that a + b = e, we have
maxt]c], Ibl, leI) ~ C(e)No(abe)l+<.
Observe that the inequality says that many prime factors of a, b, e occur to
the first power, and that if "small" primes occur to high powers, then they
have to be compensated by "large" primes occurring to the first power. For
instance, one might consider the equation
2n ± 1 = m.
For m large, the abe conjecture would state that m has to be divisible by
large primes to the first power. This phenomenon can be seen in the tables
of [BLSTW 83].
Stewart- Tijdeman [ST 86] have shown that it is necessary to have the E in
the formulation of the conjecture. Subsequent examples were communicated to
me by Wojtek Jastrzebowski and Dan Spielman as follows.
We have to give examples such that for all C > 0 there exist natural
numbers a, b, e relatively prime such that a + b = e and lal > CNo(abe). But
trivially,
We consider the relations an + b; = en given by
32" -
1 = en'
It is clear that these relations provide the desired examples. Other examples
can be constructed similarly, since the role of 3 and 2 can be played by other
integers. Replace 2 by some prime, and 3 by an integer == 1 mod p.
The abe conjecture implies what we shall call the
Asymptotic Fermat Theorem.
For all n sufficiently large, the equation
has no solution in relatively prime integers =f:. O.

IV, §7
MASON'S THEOREM AND THE abc CONJECTURE
197
The proof follows exactly the same pattern as for polynomials, except
that we write things down multiplicatively, and there is a 1 + s floating
around. The extent to which the abc conjecture will be proved with an
explicit constant C(e) (or say C(1) to fix ideas) yields the corresponding
explicit determination of the bound for n in the application. We now go into
other applications.
Hall's conjecture [Ha 71].
If u, v are relatively prime non-zero integers
such that u3 - v2 #- 0, then
lu3 - v2 1»luI 1/2 - E•
The symbol » means that the left-hand side is ~ the right-hand side times a
constant depending only on e. Again the proof is immediate from the abc
conjecture.
Actually, the hypothesis that u, v are relatively prime is not
necessary; the general case can be reduced to the relatively prime case by
extracting common factors, and Hall stated his conjecture in this more
general way. However, he also stated it without the epsilon in the exponent,
and that does not work, as was realized later. As in the polynomial case,
Hall's conjecture describes how small Iu3 - v2 1 can be, and the answer is not
too small, as described by the right-hand side.
The Hall conjecture can also be interpreted as giving a bound for integral
relatively prime solutions of
v2 = u3 + b
with integral b.
Then we find
More generally, in line with conjectured inequalities from Lang-Waldschmidt
[La 78], let us fix non-zero integers A, B and let u, v, k, m, n be variable,
with u, v relatively prime and mv > m + n. Put
Au m + Bo" = k.
By the abc conjecture, one derives easily that
(1)
lui « No(k)mn-i'm+nPH)
and
Ivl « No(k)mn-rm+np+e).
From this one gets
Ikl «No(k)mn '(:+np+El.
The Hall conjecture is a special case after we replace No(k) with Ikl, because
No(k)s Ikl·
Next take m = 3 and n = 2, but take A = 4 and B = - 27. In this case
we write

198
POLYNOMIALS
and we get
IV, §7
(2)
and
These inequalities are supposed to hold at first for u, v relatively prime.
Suppose we allow u, v to have some bounded common factor, say d. Write
u = u'd
and
v = v'd
with u', v' relatively prime. Then
D = 4d3u ,3 - 27d2v ,2.
Now we can apply inequality (1) with A = 4d3 and B = - 27d2, and we find
the same inequalities (2), with the constant implicit in the sign « depending
also on d, or on some fixed bound for such a common factor. Under these
circumstances, we call inequalities (2) the generalized Szpiro conjecture.
The original Szpiro conjecture was stated in a more sophisticated situa-
tion, cr. [La 90] for an exposition, and Szpiro's inequality was stated in the
form
IDI « N(D)6+t,
where N(D) is a more subtle invariant, but for our purposes, it is sufficient
and much easier to use the radical No(D).
The point of D is that it occurs as a discriminant. The trend of thoughts
in the direction we are discussing was started by Frey [Fr 87], who asso-
ciated with each solution of a + b = c the polynomial
x(x -
a)(x + b),
which we call the Frey polynomial.
(Actually Frey associated the curve
defined by the equation y2 = x(x -
a)(x + b), for much deeper reasons, but
only the polynomial on the right-hand side will be needed here.)
The
discriminant of the polynomial is the product of the differences of the roots
squared, and so
We make a translation
b-a
~=x+ -­
3
to get rid of the x2-term, so that our polynomial can be rewritten
~3_Y2~- Y3 '
where Y2' Y3 are homogeneous in a, b of appropriate weight.
The dis-
criminant does not change because the roots of the polynomial in
~ are

IV, §7
MASON'S THEOREM AND THE abc CONJECTURE
199
translations of the roots of the polynomial in x. Then
D = 4}'~ -
27}'~.
The translation with (b - a)/3 introduces a small denominator.
One may
avoid this denominator by using the polynomial x(x - 3a)(x - 3b), so that
}'2' }'3 then come out to be integers, and one can apply the generalized Szpiro
conjecture to the discriminant, which then has an extra factor D = 36(abc)2.
It
is immediately seen
that the
generalized Szpiro conjecture implies
asymptotic Fermat. Conversely :
Generalized Szpiro implies the abc conjecture.
Indeed, the correspondence (a, b)-(}'2' }'3) is invertible, and has the "right"
weight. A simple algebraic manipulation shows that the generalized Szpiro
estimates on }'2' }'3 imply the desired estimates on lal, Ibl. (Do Exercise 14.)
From the equivalence between abc and generalized Szpiro, one can use the
examples given earlier to show that the epsilon is needed in the Szpiro
conjecture.
Finally, note that the pol ynomial case of the Mason-Stothers theorem and
the case of integers are not independent, or specifically the Davenport theorem
and Hall's conjecture are related. Examples in the polynomial case parametrize
cases with integers when we substitute integers for the variables. Such examples
are given in [BCHS 65], one of them (due to Birch) being
f(t) = t6 + 4t4 + 10t2 + 6
and
g(t) = t9 + 6t7 + 21t5 + 35t3 + 6lt,
whence
deg(f(t)3 - g(t)2) = t deg f + 1.
This example shows that Davenport's inequality is best possible, because the
degree attains the
lowest possible value permissible under the
theorem.
Substituting large integral values of t == 2 mod 4 gives examples of similarly
low values for x3 -
y2. For other connections of all these matters, cr. [La 90].
Bibliography
[BCHS 65]
B. BIRCH, S. CHOWLA, M. HALL, and A. SCHINZEL, On the difference
x 3 - y2, Norske Vid. Selsk. Forrh . 38 (1965) pp. 65-69
[BLSTW 83]
1. BRILLHART, D. H. LEHMER, 1. L. SELFRIDGE, B. TUCKERMAN, and S.
WAGSTAFF Jr., Factorization of b" ± 1, b = 2, 3, 5, 6, 7, 10, 11 up to
high powers, Contemporary Mathematics Vol. 22, AMS, Providence,
RI, 1983
[Dav 65]
H. DAVENPORT, On f3 (t) - g2(t), Norske Vid. Selsk. Forrh. 38 (1965)
pp. 86- 87
[Fr 87]
G. FREY, Links between solutions of A -
B = C and elliptic curves,
Number Theory , Lecture Notes 1380, Springer-Verlag, New York, 1989
pp. 31-62

200
POLYNOMIALS
IV, §8
[Ha 71]
[La 90]
[Ma 84a]
[Ma 84b]
[Ma 84c]
[Si 88]
[ST 86]
M. HALL, The diophantine equation x 3 - i
= k, Computers and
Number Theory, ed. by A. O. L. Atkin and B. Birch, Academic
Press, London 1971 pp. 173-198
S. LANG, Old and new conjectured diophantine inequalities, Bull.
AMS Vol. 23 No.1 (1990) pp. 37-75
R. C. MASON, Equations over function fields, Springer Lecture Notes
1068 (1984), pp. 149-157 ; in Number Theory, Proceedings of the
Noordwijkerhout, 1983
R. C. MASON, Diophantine equations over function fields, London
Math . Soc. Lecture Note Series Vol. 96, Cambridge University
Press, Cambridge, 1984
R. C. MASON, The hyperelliptic equation over function fields, Math.
Proc. Cambridge Phi/os. Soc. 93 (1983) pp. 219-230
1. SILVERMAN, Wieferich's criterion and the abc conjecture, Journal of
Number Theory 30 (1988) pp. 226-237
C. L. STEWART and R. TIJDEMAN, On the Oesterle-Masser Conjecture,
Mon . Math . 102 (1986) pp . 251-257
See additional references at the end of the chapter.
§8.
THE RESULTANT
In this section, we assume that the reader is familiar with determinants.
The theory of determinants will be covered later. The section can be viewed
as giving further examples of symmetric functions.
Let A be a commutative ring and let
Vo, " " Vn,
Wo, " " Wm be alge-
braically independent over A. We form two polynomials:
i v(X) = vox n+
+ Vn,
gw(X) = woX m +
+ wm•
We define the resultant of (v, w), or of i v' gw' to be the determinant
VOV1 . .. Vn
VOV1 ... Vn
VOV1 .. . Vn
WOW 1 • • • Wm
WOW 1 ... Wm
y
m+n
The blank spaces are supposed to be filled with zeros.

IV, §8
THE RESULTANT
201
If we substitute elements (a) = (ao, ... , an) and (b) = (bo, ... , bm) in A for
(v) and (w) respectively in the coefficients of fv and gw' then we obtain
polynomials fa and gb with coefficients in A, and we define their resultant to
be the determinant obtained by substituting (a) for (v) and (b) for (w) in the
determinant. We shall write the resultant of fv' gw in the form
Res(fv,gw)
or
R(v, w).
The resultant Res(fa, gb) is then obtained by substitution of (a), (b) for (v), (w)
respectively.
We observe that R(v, w) is a polynomial with integer coefficients, i.e. we
may take A = Z. If z is a variable, then
R(zv, w) = zmR(v, w)
and
R(v, zw) = znR(v, w)
as one sees immediately by factoring out z from the first m rows (resp. the
last n rows) in the determinant. Thus R is homogeneous of degree m in its
first set of variables, and homogeneous of degree n in its second set of
variables. Furthermore, R(v, w) contains the monomial
vow~
with coefficient 1, when expressed as a sum of monomials.
If we substitute 0 for Vo and Wo in the resultant, we obtain 0, because the
first column of the determinant vanishes.
Let us work over the integers Z. We consider the linear equations
vox n + ...
Let C be the column vector on the left-hand side, and let
be the column vectors of coefficients. Our equations can be written
C = xn+m-1Co + ...+ I· Cm+n.
By Cramer's rule, applied to the last coefficient which is = 1,
R(v, w) = det(Co, .. . , Cm+n ) = det(Co, .. . , Cm+n- 1 ' C).

202
POLYNOMIALS
IV, §8
From this we see that there exist polynomials <Pv.w and I/Jv.w in Z[v, w][X]
such that
({}.v.wfv + l/Jv.wgw = R(v,w) = Res(fv,fw)'
Note that R(v, w) E Z[v, w] but that the polynomials on the left-hand side
involve the variable X .
If ),: Z[v, w] -. A is a homomorphism into a commutative ring A and we
let ),(v) = (a), J1.(w) = (b), then
<Pa.da + I/Ja,bgb = R(a, b) = Res(fa, fb)'
Thus from the universal relation of the resultant over Z we obtain a similar
relation for every pair of polynomials, in any commutative ring A.
Proposition 8.1.
Let K be a subfield of a field L, and let fa, gb be
polynomials in K[X] having a common root ~ in L. Then R(a, b) = O.
Proof
If fa(~) =
gb(~) = 0, then we substitute
~ for X in the expression
obtained for R(a, b) and find R(a, b) = O.
Next, we shall investigate the relationship between the resultant and the
roots of our polynomials fv' gw. We need a lemma.
Lemma 8.2.
Let h(Xl' ... ,Xn) be a polynomial in n variables over the
integers Z. If h has the value 0 when we substitute Xl for X 2 and leave
the other Xi fixed (i #- 2), then h(X l , . .. , Xn) is divisible by Xl - X 2 in
Z[Xl , ... , Xn].
Proof
Exercise for the reader.
Let vo, t i - ... , tn' WO' Ul , . .. , Urn be algebraically independent over Z and
form the polynomials
fv = vo(X - t l )
(X - tn) = voX n+ ... + vn,
gw = wo(X - ud
(X - urn) = woXrn + ... + wrn·
Thus we let
and
We leave to the reader the easy verification that
are algebraically independent over Z.
Proposition 8.3.
Notation being as above, we have
n
rn
Res(fv, gw) = vowonn (ti - uJ
i ~ l
j~l

IV, §8
THE RESULTANT
203
Proof
Let S be the expression on the right-hand side of the equality in
the statement of the proposition.
Since R(v, w) is homogeneous of degree m in its first variables, and
homogeneous of degree n in its second variables, it follows that
R =
v~wo h ( t, u)
where h(t, u) E Z[t, U].
By Proposition 8.1, the resultant vanishes when we
substitute t, for uj (i = 1,... , nand j = 1,... , m), whence by the lemma, view-
ing R as an element of Z[vo, wo, t, u] it follows that R is divisible by t, -
Uj
for each pair (i,j). Hence S divides R in Z[vo, wo, t, u], because t, - uj is
obviously a prime in that ring, and different pairs (i,j) give rise to different
primes.
From the product expression for S, namely
(1)
we obtain
whence
(2)
Similarly,
(3)
n
m
S =
v~wo fl fl (ti - uj ),
i = 1 j=1
n
n
m
fl g(t;) = Wofl fl (ti - uj ),
i = 1
i=1 j=1
n
S = v~ fl g(tJ
i=1
m
S = (_l)nmwofl f(uJ
j=l
From (2) we see that S is homogeneous and of degree n in (w), and from (3)
we see that S is homogeneous and of degree m in (v). Since R has exactly the
same homogeneity properties, and is divisible by S, it follows that R = cS for
some integer c. Since both Rand S have a monomial
v~w.:: occurring in
them with coefficient 1, it follows that c = 1, and our proposition is proved.
We also note that the three expressions found for S above now give us a
factorization of R. We also get a converse for Proposition 8.1.
Corollary 8.4.
Let fa' gb be polynomials with coefficients in a field K, such
that aobo =F 0, and such that fa, gb split in factors of degree 1 in K[X].
Then Res(fa, gb) =°if and only if fa and gb have a root in common.
Proof
Assume that the resultant is 0. If
fa = ao(X - (XI)
(X -
(Xn),
gb = bo(X - fJd
(X - fJn)'
is the factorization of fa, gb' then we have a homomorphism

204
POLYNOMIALS
Z[vo, t, wo, u] --+K
such that Vo1-+ ao, Wo 1-+ bo, t, 1-+ CX j , and uj 1-+ {3j for all i, j. Then
o= Res(fa' gb) =
a:;'b~ TI TI (cx j
-
{3j),
j
j
IV, §8
whence fa, Ib have a root in common.
The converse has already been
proved.
We deduce one more relation for the resultant in a special case. Let Iv be
as above,
Iv(X) = voX · + ... + v. = vo(X - t1 ) •• • (X - t.).
From (2) we know that ifI: is the derivative of lv' then
(4)
Res(fv' I:) = V~-l TI f'(tJ
j
Using the product rule for differentiation, we find :
~
I:(X) = Lvo(X - td ... (X - tj) ... (X - t.),
j
~
I:(tJ = vo(tj - t1) ... (tj - tJ .. . (tj
-
t.),
where a roof over a term means that this term is to be omitted.
We define the discriminant of Iv to be
D(fv) = D(v) = (_1).(.- 1l/2 V~·-2 TI (tj - t).
j"' j
Proposition 8.5.
Let Iv be as above and have algebraically independent
coefficients over Z. Then
(5)
Res(fv,/J = V~· - l TI (t j
- t) = (-1)·(·- 1l/2voD(fv)'
j ",j
Proof
One substitutes the expression obtained for I:(tj) into the prod-
uct (4). The result follows at once.
When we substitute 1 for Vo, we find that the discriminant as we defined
it in the preceding section coincides with the present definition. In particular,
we find an explicit formula for the discriminant. The formulas in the special
case of polynomials of degree 2 and 3 will be given as exercises.
Note that the discriminant can also be written as the product
D(fv) =
V~· -2 TI (tj - t)2.
i« ]
Serre once pointed out to me that the sign (_1)·(·-1)/2 was missing in the
first edition of this book, and that this sign error is quite common in the
literature, occurring as it does in van der Waerden, Samuel, and Hilbert (but
not in his collected works, corrected by Olga Taussky) ; on the other hand
the sign is correctly given in Weber's Algebra, Vol. I, 50.
For a continuation of this section, see Chapter IX, §3 and §4.

IV, §9
§9.
POWER SERIES
POWER SERIES
205
Let X be a letter, and let G be the monoid of functions from the set {X}
to the natural numbers. If v E N, we denote by X" the function whose value
at X is v. Then G is a multiplicative monoid, already encountered when we
discussed polynomials. Its elements are Xo, Xl, X 2, •• • , Xv, ... .
Let A be a commutative ring, and let A [eXJ] be the set of functions
from G into A, without any restriction. Then an element of A[[XJ] may be
viewed as assigning to each monomial X " a coefficient av E A. We denote
this element by
00L avX v.
v=o
The summation symbol is not a sum, of course, but we shall write the above
expression also in the form
aoXo + alX I + ...
and we call it a formal power series with coefficients in A, in one variable.
We call ao, aI' ... its coefficients.
Given two elements of A[[XJ], say
00L «x:
and
v=o
we define their product to be
where
Just as with polynomials, one defines their sum to be
00L (av +ssx:
v=o
Then we see that the power series form a ring, the proof being the same as
for polynomials.
One
can
also
construct the
power
series ring in several variables
A[[Xl , • .• , XnJ] in which every element can be expressed in the form
La(V)X;' .. . X;" = La(v)M(v)(XI , ••• , Xn)
(v)
with unrestricted coefficients a(v) in bijection with the n-tuples of integers
(VI' ... , vn ) such that Vi ~ 0 for all i. It is then easy to show that there is an
isomorphism between A[[XI , .•• , XnJ] and the repeated power series ring
A[[XlJ] ... [[XnJ]. We leave this as an exercise for the reader.

206
POLYNOMIALS
IV, §9
The next theorem will give an analogue of the Euclidean algorithm for
power series. However, instead of dealing with power series over a field, it is
important to have somewhat more general coefficients for certain applica-
tions, so we have to introduce a little more terminology.
Let A be a ring and I an ideal. We assume that
00nt: = {O}.
v= l
We can view the powers P as defining neighborhoods of 0 in A, and we can
transpose the usual definition of Cauchy sequence in analysis to this situation,
namely: we define a sequence {an} in A to be Cauchy if given some power P
there exists an integer N such that for all m, n ~ N we have
am - an EP.
Thus P
corresponds to the given
E of analysis. Then we have the usual
notion of convergence of a sequence to an element of A. One says that A is
complete in the I-adic topology if every Cauchy sequence converges.
Perhaps the most important example of this situation is when A is a local
ring and I = m is its maximal ideal.
By a complete local ring, one always
means a local ring which is complete in the m-adic topology.
Let k be a field. Then the power series ring
R = k[eX1 , • • • , XnJJ
in n variables is such a complete local ring.
Indeed, let m be the ideal
generated by the variables Xl' .. ., Xn• Then Rim is naturally isomorphic to
the field k itself, so m is a maximal ideal. Furthermore, any power series of
the form
f(X) = Co - f1(X)
with Co E k, Co =f 0 and f1(X) E m is invertible. To prove this, one may first
assume without loss of generality that Co = 1. Then
(1 - f1(X))-1 = 1 + f1(X) + f1(X)2 + f1(X)3 + ...
gives the inverse. Thus we see that m is the unique maximal ideal and R is
local. It is immediately verified that R is complete in the sense we have just
defined. The same argument shows that if k is not a field but Co is invertible
in k, then again f(X) is invertible.'
Again let A be a ring. We may view the power series ring in n variables
(n > 1) as the ring of power series in one variable X; over the ring of power
series in n - 1 variables, that is we have a natural identification
A[eX1, .• • , XnJJ = A[eX1 , . • • , Xn-1J] [eXnJ].
If A = k is a field, the ring k[[X1 , •• • , Xn- 1JJ is then a complete local
ring. More generally, if 0 is a complete local ring, then the power series ring
o[eXJ] is a complete local ring, whose maximal ideal is (m, X) where m is
the maximal ideal of o. Indeed, if a power series L: a.X" has unit constant

IV, §9
POWER SERIES
207
term ao E 0*, then the power series is a unit in 0 [[X]], because first, without
loss of generality, we may assume that ao = 1, and then we may invert 1 + h
with h E (m, X) by the geometric series 1 - h + h1 - h3 + ....
In a number of problems, it is useful to reduce certain questions about
power series in several variables over a field to questions about power series
in one variable over the more complicated ring as above.
We shall now
apply this decomposition to the Euclidean algorithm for power series.
Theorem 9.1.
Let 0 be a complete local ring with maximal ideal m. Let
00
f(X) = L aiX i
i=O
be a power series in o[[X]] (one variable), such that not all a, lie in m.
Say ao, ... , an-1 Em, and an E 0* is a unit. Given g E o[[X]] we can solve
the equation
g=qf+r
uniquely with q E o[[X]], r E o[X], and deg r ~ n - 1.
Proof
(Manin).
Let a and r be the projections on the beginning and
tail end of the series, given by
n-1
a:L biXiH L biX i = bo + b1X + ... + bn_1Xn-1,
i= O
00
r: LbiXiH L biX i-n= b; + s.;» + bn+1X1 + ... .
i=n
Note that r(hX n) = h for any h « o[[X]] ; and h is a polynomial of degree
< n if and only if r(h) = O.
The existence of q, r is equivalent with the condition that there exists q
such that
r(g) = r(qf).
Hence our problem is equivalent with solving
r(g) = r(qa(f)) + r(qr(f)Xn) = r(qa(f)) + qr(f).
Note that r(f) is invertible.
Put Z = qr(f). Then the above equation is
equivalent with
(
a(f))
(
a(f))
r(g) = r
Z r(f) + Z =
I + r 0 r(f)
Z.
Note that
a(f)
r 0 r(f) : o[[X]] -+ mo[[X]],
because a(f)/r(f) E mo [[X]]. We can therefore invert to find Z, namely

208
POLYNOMIALS
(
1X(f»)-1
Z =
I + r 0 r(f)
r(g),
which proves both existence and uniqueness and concludes the proof.
IV, §9
Theorem 9.2. (Weierstrass Preparation).
The power seriesJ in the pre-
vious theorem can be written uniquely in the form
J(X) = (xn + bn_1Xn-l + .. . + bo)u,
where b, E m, and u is a unit in o[[X]].
Proof
Write uniquely
X" = qJ + r,
by the Euclidean algorithm. Then q is invertible, because
q = Co + clX + "',
J = ... + anXn+...,
so that
1 == coan
(mod m),
and therefore Co is a unit in o. We obtain qJ = X" - r, and
J = q-l(X n - r),
with r == 0 (mod m). This proves the existence. Uniqueness is immediate.
The integer n in Theorems 9.1 and 9.2 is called the Weierstrass degree of f,
and is denoted by degwf . We see that a power series not all of whose coeffi-
cients lie in m can be expressed as a product of a polynomial having the given
Weierstrass degree, times a unit in the power series ring. Furthermore, all
the coefficients of the polynomial except the leading one lie in the maximal
ideal. Such a polynomial is called distinguished, or a Weierstrass polynomial.
Remark.
I rather like the use of the Euclidean algorithm in the proof of
the Weierstrass Preparation theorem.
However, one can also give a direct
proof exhibiting explicitly the recursion relations which solve for the coeffi-
cients of u, as follows.
Write u = LCiX i•
Then we have to solve the
equations
boco = ao,
bOcl + blCo = al ,
bOcn- l + .,.+ bn- l Co = an- l ,
bocn+
+ Co = an'
bOcn+l +
+ Cl = an+l ,

IV, §9
POWER SERIES
209
In fact, the system of equations has a unique solution mod m" for each
positive integer r, after selecting
Co to be a unit, say
Co = 1. Indeed, from
the first n equations (from °to n - 1) we see that bo,"" bn- 1 are uniquely
determined to
be ° mod m.
Then
Cn' Cn+1 ' • .• are
uniquely determined
mod m by the subsequent equations.
Now inductively, suppose we have
shown that the coefficients b.; cj are uniquely determined mod m'. Then one
sees immediately that from the conditions ao, .. ., an- 1 ==°mod m the first n
equations define
b, uniquely mod m,+l because all b, ==°mod m.
Then
the subsequent equations define cj mod m,+l uniquely from the values of
b, mod m,+l and cj mod m'. The unique system of solutions mod m' for each
r then defines a solution in the projective limit, which is the complete local
ring.
We now have all the tools to deal with unique factorization in one important
case.
Theorem 9.3.
Let k be afield. Then k[[XI , ... , Xnll is factorial.
Proof.
Letf(x) =f(X I> ... , Xn ) E k[[X]] be =1= 0. After making a sufficiently
general linear change of variables (when k is infinite)
Xi = L cijYj
with
Cij E k,
we may assume without loss of generality thatf(O, . .. , 0, xn )
=1= 0. (When k is
finite, one has to make a non-linear change, cf. Theorem 2.1 of Chapter VIII .)
Indeed , if we write f(X) = fd(X) + higher terms, where fiX) is a homogeneous
polynomial of degree d ~ 0, then changing the variables as above preserves the
degree of each homogeneous component of f, and since k is assumed infinite,
the coefficients Cij can be taken so that in fact each power Y1 (i = I, . .. , n)
occurs with non-zero coefficient.
We now proceed by induction on n. Let R; = k[[XI> . . . , Xnll be the power
series in n variables, and assume by induction that Rn- 1 is factorial. By Theorem
9.2, writef= gu where u is a unit and 9 is a Weierstrass polynomial in Rn - I[Xn] .
By Theorem 2.3, Rn-I[Xn] is factorial, and so we can write 9 as a product of
irreducible elements gl' . . . , gr E Rn- I[Xn], sof = gl ... gru, where the factors
giare uniquely determined up to multiplication by units . This proves the existence
of a factorization. As to uniqueness, suppose f is expressed as a product of
irreducible elements in Rn , f = fl ... fs· Then fiO, . . . , 0, xn )
=1= °for each
q = I, . . . , s, so we can writefq = hqu~ where u~ is a unit and hq is a Weierstrass
polynomial, necessarily irreducible in Rn-I[Xn]. Then f = gu= nhqnu~
with 9 and all hq Weierstrass polynomials. By Theorem 9.2, we must have
9 = n hq , and since s.: dXn] is factorial, it follows that the polynomials hq
are the same as the polynomials gi' up to units. This proves uniqueness.
Remark.
As was pointed out to me by Dan Anderson, I incorrectly stated
in a previous printing that if .,0 is a factorial complete local ring, then cuxn
is also factorial. This assertion is false, as shown by the example
k(t)[[Xl' X2, X3]]/(X? + xi + x j)

210
POLYNOMIALS
IV, §9
due to P. Salmon, Su un problema posto da P. Samuel, Atti Acad. Naz. Lincei
Rend. Cl. Sc. Fis. Matern. 40(8) (1966) pp. 801-803. It is true that if c is a
regular local ring in addition to being complete, then ()[[X]] is factorial, but this
is a deeper theorem. The simple proof I gave for the power series over a field
is classical. I chose the exposition in [GrH 78].
Theorem 9.4.
If A is Noetherian, then A[[X]] is also Noetherian.
Proof
Our argument will be a modification of the argument used in the
proof of Hilbert's theorem for polynomials. We shall consider elements of
lowest degree instead of elements of highest degree.
Let ~ be an ideal of A [[X]]. We let aj be the set of elements a E A such
that a is the coefficient of x' in a power series
aX i + terms of higher degree
lying in~. Then ai is an ideal of A, and ai C Qi+l (the proof of this assertion
being the same as for polynomials). The ascending chain of ideals stops:
As before, let aij (i = 0, ... , rand j = 1, ... , n;) be generators for the ideals
aj , and let hj be power series in A having
aij as beginning coefficient.
Given f E~, starting with a term of degree d, say d ~ r, we can find
elements C1 1 ••
•
I cnd E A such that
f - Cildl -
•• • - cnJdnd
starts with a term of degree
~ d + 1. Proceeding inductively, we may as-
sume that d > r. We then use a linear combination
f -
C(d)Xd-rf,
- '" -
C(d)xd-rf,
1
r1
ftr
rn,.
to get a power series starting with a term of degree
~ d + 1. In this way, if
we start with a power series of degree d > r, then it can be expressed as a
linear combination of frl' . . . ,fmr by means of the coefficients
<Xl
<Xl
gl(X) = L civ)xv-r, .. ., gnJX) = L ct)xv-r,
v=d
v=d
and we see that the hj generate our ideal ~, as was to be shown.
Corollary 9.5. If A is a Noetherian commutative ring, or a field , then
A[[Xl , • • . , XnJ] is Noetherian.
Examples.
Power series in one variable are at the core of the theory of
functions of one complex variable, and similarly for power series in several
variables in the higher-dimensional case. See for instance [Gu 90].
Weierstrass polynomials occur in several contexts. First, they can be used
to reduce questions about power series to questions about polynomials, in
studying analytic sets. See for instance [GrH 78], Chapter O. In a number-

IV, §9
POWER SERIES
211
theoretic context, such polynomials occur as characteristic polynomials in
the Iwasawa theory of cyclotomic fields. Cf. [La 90J, starting with Chapter
5.
Power series can also be used as generating functions.
Suppose that to
each positive integer n we associate a number a(n). Then the generating
function is the power series L a(nW. In significant cases, it turns out that
this function represents a rational function , and it may be a major result to
prove that this is so.
For instance in Chapter X, §6 we shall consider a Poincare series,
associated with the length of modules.
Similarly, in topology, consider a
topological space X such that its homology groups (say) are finite dimen-
sional over a field k of coefficients. Let h; = dim Hn(X, k), where H; is the
n-th homology group. The Poincare series is defined to be the generating
series
Examples arise in the theory of dynamical systems.
One considers a
mapping T: X --+ X from a space X into itself, and we let N; be the number
of fixed points of the n-th iterate T" = T oT 0
• •• 0 T (n times). The generat-
ing function is LNntn. Because of the number of references I give here, I
list them systematically at the end of the section. See first Artin-Mazur
[ArM 65J; a proof by Manning of a conjecture of Smale [Ma 71J; and
Shub's book [Sh 87J, especially Chapter 10, Corollary 10.42 (Manning's
theorem).
For an example in algebraic geometry, let V be an algebraic variety
defined over a finite field k. Let K; be the extension of k of degree n (in a
given algebraic closure). Let N; be the number of points of V in Kn • One
defines the zeta function Z(t) as the power series such that Z(O) = I and
00
Z' /Z(t) = L Nntn-l .
n=l
Then Z(t) is a rational function (F. K. Schmidt when the dimension of V is 1,
and Dwork in higher dimensions) . For a discussion and references to the
literature, see Appendix C of Hartshorne [Ha 77].
Finally we mention the partition function p(n), which is the number of
ways a positive integer can be expressed as a sum of positive integers. The
generating function was determined by Euler to be
00
00
I + L p(n)tn= TI (I - tnr l •
n=l
n=l
See for instance Hardy and Wright [HardW 71J, Chapter XIX. The generat-
ing series for the partition function is related to the power series usually
expressed in terms of a variable q, namely

212
POLYNOMIALS
00
00
~ = q TI (1 -
qn)24 = L r(n)qn,
n=l
n=l
IV,§9
which is the generating series for the Ramanujan function r(n). The power
series for
~ is also the expansion of a function in the theory of modular
functions. For an introduction, see Serre's book ESe 73], last chapter, and
books on elliptic functions, e.g. mine. We shall mention one application of
the power series for ~ in the Galois theory chapter.
Generating power series also occur in K-theory, topological and algebraic
geometric, as in Hirzebruch's formalism for the Riemann-Roch theorem and
its extension by Grothendieck. See Atiyah [At 67], Hirzebruch [Hi 66], and
[FuL 86]. I have extracted some formal elementary aspects having directly
to do with power series in Exercises 21-27, which can be viewed as basic
examples. See also Exercises 31-34 of the next chapter.
Bibliography
[ArM 65]
[At 67]
[FuL 85]
[GrH 78]
[Gu 90]
[HardW 71]
[Hart 77]
[Hi 66]
[La 90]
[Ma 71]
[Se 73]
[Sh 87]
M. ARTIN and B. MAZUR, On periodic points, Ann. Math. (2) 81 (1965)
pp. 89-99
M. ATiYAH, K-Theory, Addison-Wesley 1991 (reprinted from the Ben-
jamin Lecture Notes, 1967)
W. FULTON and S. LANG, Riemann-Rock Algebra, Springer-Verlag,
New York, 1985
P. GRIFFITHS and J. HARRIS, Principles of Algebraic Geometry, Wiley-
Interscience, New York, 1978
R. GUNNING, Introduct ion to Holomorphic Functions of Several Vari-
ables, Vol. II : Local Theory, Wadsworth and Brooks/Cole, 1990
G. H. HARDY and E. M. WRIGHT, An Introduction to the Theory of
Numbers, Oxford University Press, Oxford, UK, 1938-1971 (several
editions)
R.
HARTSHORNE, Algebraic
Geometry, Springer-Verlag,
New
York,
1977
F. HIRZEBRUCH, Topological Method s in Algebraic Geometry, Springer-
Verlag, New York, 1966 (translated and expanded from the original
German, 1956)
S. LANG, Cyclotomic Fields, I and II, Springer-Verlag, New York, 1990,
combined edition of the original editions, 1978, 1980
A. MANNING, Axiom A diffeomorphisms have rational zeta functions,
Bull. Lond. Math. Soc. 3 (1971) pp. 215-220
J. P. SERRE, A Course in Arithmetic, Springer-Verlag, New York, 1973
M. SHUB, Global Stability of Dynamical Systems, Springer-Verlag, New
York, 1987

IV, Ex
EXERCISES
EXERCISES
213
1. Let k be a field and f(X) E k[X] a non-zero polynomial. Show that the following
conditions are equivalent:
(a) The ideal U(X)) is prime.
(b) The ideal U(X)) is maximal.
(c) f(X) is irreducible.
2. (a) State and prove the analogue of Theorem 5.2 for the rational numbers.
(b) State and prove the analogue of Theorem 5.3 for positive integers.
3. Let f be a polynomial in one variable over a field k. Let X, Y be two variables.
Show that in k[X, Y] we have a "Taylor series" expansion
n
f(X + Y) = f(X) + L q>i(X) y i,
i = 1
where q>i(X) is a polynomial in X with coefficients in k. If k has characteristic 0,
show that
D'i(X)
q>i(X) =- .-,- .
1.
4. Generalize the preceding exercise to polynomials in several variables (introduce
partial derivatives and show that a finite Taylor expansion exists for a polynomial
in several variables).
5. (a) Show that the polynomials X4 + 1 and X6 + X3 + 1 are irreducible over the
rational numbers.
(b) Show that a polynomial of degree 3 over a field is either irreducible or has a
root in the field. Is X3 - 5X 2 + 1 irreducible over the rational numbers?
(c) Show that the polynomial in two variables X2 + y 2 -
1 is irreducible over
the rational numbers. Is it irreducible over the complex numbers?
6. Prove the integral root test of §3.
7. (a) Let k be a finite field with q = r" elements. Let f (XI , . . . , Xn ) be a polynomial
in k[X] of degree d and assume f (O, . . . ,0) = O. An element (al , .. . ,an) E k(n)
such that f (a) = 0 is called a zero of f . If n > d, show that f has at least one
other zero in k(n). [Hint: Assume the contrary, and compare the degrees of the
reduced polynomial belonging to
1 - f(X)q-l
and (1 - Xr1) ... (1 - X:-1). The theorem is due to Chevalley.]
(b) Refine the above results by proving that the number N of zeros of f in kIn) is
;: 0 (mod p), arguing as follows. Let i be an integer ~ 1. Show that
L X i = {q - 1 = -1
ifq- 1 divides i,
"'ek
0
otherwise.
Denote the preceding function of i by "'(i). Show that

214
POLYNOMIALS
N= L (l- / (x)q- I)
xe l C"1
and for each n-tuple (iI' . .., i. ) of integers f:; 0 that
L X:' ... X~" = "'(iIl ... "'(i.).
xe kf" '
IV, Ex
Show that both terms in the sum for N above yield 0 mod p. (The above
argument is due to Warning.)
(e) Extend Chevalley's theorem to r polynomials II ' ... ,f, of degrees dl , • •• , d,
respectively, in n variables. If they have no constant term and n > Ldj , show
that they have a non-trivial common zero.
(d) Show that an arbitrary function I: k(·) -> k can be represented by a poly-
nomial. (As before, k is a finite field.)
8. Let A be a commutative entire ring and X a variable over A. Let a, b E A and
assume that a is a unit in A. Show that the map X 1-+ aX + b extends to a
unique automorphism of A[X] inducing the identity on A. What is the inverse
automorphism?
9. Show that every automorphism of A[X] inducing the identity on A is of the type
described in Exercise 8.
10. Let K be a field, and K(X) the quotient field of K[X]. Show that every automorphism
of K(X) which induces the identity on K is of type
aX +b
X 1-+---
eX +d
with a, b, e, d e K such that (aX + bl/(eX + d) is not an element of K , or
equivalently, ad - be i= O.
11. Let A be a commutative entire ring and let K be its quotient field. We show here
that some formulas from calculus have a purely algebraic setting. Let D: A -> A
be a derivation, that is an additive homomorphism satisfying the rule for the
derivative of a product, namely
D(xy) = xDy + yDx
for
x, yEA.
(a) Prove that D has a unique extension to a derivation of K into itself, and that
this extension satisfies the rule
/
yDx - xDy
D(x y) =
2
Y
for x, yEA and y i= O. [Define the extension by this formula, prove that it is
independent of the choice of x, y to write the fraction x/y, and show that it
is a derivation having the original value on elements of A.]
(b) Let L(x) = Dxlx for x E K*.
Show that
L(xy) = L(x) + L(y).
The homo-
morphism L is called the logarithmic derivative.
(c) Let D be the standard derivative in the polynomial ring k[X] over a field k.
Let R(X) =en (X -
IXJm, with IXj E k,eE k, and mj E Z, so R(X) is a rational

IV, Ex
function. Show that
m·
R'/R=I -'- ·
X- Cl j
EXERCISES
215
12. (a) If f(X) = aX2 + bX + c, show that the discriminant of f is b2 - 4ac.
(b) If f (X ) = aoX3+ alX2 + a2X + a3, show that the discriminant of f is
a fa ~ -
4aoa~ -
4a ~a 3 -
27a6a~ + 18aoa,a2a3·
(c) Let f( X) = (X - t I) ... (X - tn)' Show that
n
Df = (_1)n(n- l l/2 Il f'(tJ
i=1
13. Polynomials will be taken over an algebraically closed field of characteristic O.
(a) Pro ve
Davenport's theorem.
Let f (t), g(t) be polynomials such that f3 - g2 f:. O. Then
deg(f3 - g2) ~ t degf + I.
Or put another way, let h = f3 - g2 and assume h f:. O. Then
degf
~ 2 deg h - 2.
To do this, first assume f, 9 relatively prime and apply Mason's theorem. In
general, proceed as follows.
(b) Let A, B, f , 9 be polynomials such that Af, Bg are relatively prime f:. O. Let
h = AJ3 + Bg2. Then
deg f ~ deg A + deg B + 2 deg h - 2.
This follows directly from Mason 's theorem.
Then starting with f, 9 not
necessarily relatively prime, start factoring out common
factors until no
longer possible, to effect the desired reduction. When I did it, I needed to do
this step three times, so don't stop until you get it.
(c) Generalize (b) to the case of Jm- q" for arbit rary positive integer exponents
m and n.
14. Prove that the generalized Szpiro conjecture implies the abc conjecture.
15. Prove that the abc conjecture implies the following conjecture : There are infinitely
many primes p such that 2 p-1 ¥= 1 mod p2. [Cf. the reference [Sil 88] and [La 90]
at the end of §7.]
16. Let w be a complex number, and let c = max(l, [wl),
Let F, G be non-zero
polynomials in one variable with complex coefficients, of degrees d and d' respec-
tively, such that In IGI ~ 1. Let R be their resultant. Then
IRI ~ Cd+d' [ IF(w)1+ IG(w)l] \F ld'IGld(d + d,)d+d'.
(We denote by IFI the maximum of the absolute values of the coefficients of F.)
17. Let d be an integer
~ 3. Pro ve the existence of an irreducible polynomial of
degree dover Q, having precisely d - 2 real roots, and a pair of complex
conjugate roots.
Use the following construction.
Let b,
.. ., bd- 2 be distinct

216
POLYNOMIALS
integers, and let a be an integer > O. Let
g(X) = (X2+ a)(X - bI) · · · (X - bd- 2) = X d+ Cd_IX d- 1+...+ co.
Observe that Cj E Z for all i. Let p be a prime number, and let
IV, Ex
so that g. converges to 9 (i.e, the coefficients of g. converge to the coefficients
of g).
(a) Prove that g. has precisely d - 2 real roots for n sufficiently large. (You may
use a bit of calculus, or use whatever method you want.)
(b) Prove that g. is irreducible over Q.
Integral-valued polynomials
18. Let P(X) E Q[XJ be a polynomial in one variable with rational coefficients. It
may happen that P(n) E Z for all sufficientlylarge integers n without necessarily P
having integer coefficients.
(a) Give an example of this.
(b) Assume that P has the above property.
Prove that there are integers
Co, C1, .. . , c, such that
P(X) = co(~) + Cl (,:1) + ...+ C"
where
(X)=.!-X(X _ 1)... (X - r + 1)
r
r!
is the binomial coefficient function. In particular, P(n) E Z for all n. Thus we
may call P integral valued.
(c) Let f : Z -+ Z be a function. Assume that there exists an integral valued
polynomial Q such that the differencefunction I1f defined by
(l1f)(n) = f(n) - f(n - 1)
is equal to Q(n) for all n sufficiently large positive. Show that there exists an
integral-valued polynomial P such that f(n) = P(n) for all n sufficiently large.
Exercises on symmetricfunctions
19. (a) Let XI'" '' X. be variables. Show that any homogeneous polynomial in
Z[X1, .. . , X.J of degree> n(n - 1) lies in the ideal generated by the elemen-
tary symmetric functions sl' . .. , s•.
(b) With the same notation show that Z[X1, . .. ,X.J is a free Z[SI, .. .,S.J
module with basis the monomials
Xlr ) = X~1 ... X;"
with 0 :;;; rj
:;;; n -
i.

IV, Ex
EXERCISES
217
(c) Let XI' " ', Xn and
f l , .,. , fm be two independent sets of variables.
Let
sI ' • , • , Sn be the elementary symmetric functions of X and
s~, ..., s~ the
elementary symmetric functions of f (using vector vector notation). Show
that Z[X, Y] is free over Z[s, s'] with basis X(rlf(q), and the exponents (r), (q)
satisfying inequalities as in (b).
(d) Let I be an ideal in Z[s, s'].
Let J be the ideal generated by I in Z[X, Y].
Show that
J II Z[s, s'] = I .
20. Let A be a commutative ring. Let t be a variable. Let
m
f(t) = I a/
i=O
and
n
g(t) = I b/
i=O
be polynomials whose constant terms are ao = bo = 1. If
f(t)g(t) = 1,
show that there exists an integer N (= (m + n)(m + n - 1)) such that any mono-
mial
with Ijrj > N is equal to O. [Hint :
Replace the a's and b's by variables. Use
Exercise 19(b) to show that any monomial M(a) of weight> N lies in the ideal I
generated by the elements
k
Ck = I
aibk- i
i=O
(letting ao = bo = 1). Note that
Ck is the k-th elementary symmetric function of
the m + n variables (X, f).]
[Note :
For
some
interesting
contexts
involving
symmetric
functions,
see
Cartier's talk at the Bourbaki Seminar, 1982-1983.]
.A.-rings
The following exercises start a train of thought which will be pursued in Exercise
33 of Chapter V; Exercises 22-24 of Chapter XVIII; and Chapter XX, §3. These
originated to a large extent in Hirzebruch's Riemann-Roch theorem and its extension
by Grothendieck who defined l -rings in general.
Let K be a commutative ring. By A.-operations we mean a family of mappings
li:K-+K
for each integer i ~ 0 satisfying the relations for all x E K :
and for all integers n ~ 0, and x, y E K,
n
In(x + y) = I
l i(X)ln-i (y).
i=O

218
POLYNOMIALS
IV, Ex
The reader will meet examples of such operations in the chapter on the alternat-
ing and symmetric products, but the formalism of such operations depends only
on the above relations, and so can be developed here in the context of formal
power series. Given a A-operation, in which case we also say that K is a loring,
we define the power series
00
A,(x)= L }8x)ti.
i: O
Prove the following statements.
21. The map x,-d,(x) is a homomorphism from the additive group of K into the
multiplicative group of power series I + tK[[t]] whose constant term is equal to
1. Conversely, any such homomorphism such that A.,(x) = 1 + xt + higher terms
gives rise to A.-operations.
22. Let s = at + higher terms be a power series in K[[t]] such that a is a unit in K.
Show that there is a power series
with
biE K.
Show that any power series f(t) E K[[t]] can be written in the form h(s)for some
other power series with coefficients in K.
Given a ).-operation on K, define the corresponding Grothendieck power series
y,(x) = A.t/(l -')(x) = A.s(x)
where s = t/(I - r), Then the map
X f-+ y,(x)
is a homomorphism as before. We define 'l'i(X) by the relation
y,(x) = L: 'l'i(X)ti.
Show that l' satisfies the following properties.
23. (a) For every integer n ~ 0 we have
"
'l'"(x + Y) = L yi(X)y"- i(y).
i=O
(b) 1',(1) = 1/(1 - t).
(c) 1',(-1) = 1 -
1.
24. Assume that A.iU= 0 for i > 1. Show :
(a) y,(u - 1) = 1 + (u - l)t.
00
(b) 1',(1 - u) = L (1 - U)iti.
i = O
25. Bernoulli numbers. Define the Bernoulli numbers Bk as the coefficients in the
power series
t
00
t k
F(t) = -,- = L Bk k f •
e - I
k:O
•

IV, Ex
EXERCISES
219
Of course, e' = I t"In! is the standard power series with rational coefficients lin!.
Prove :
(a) Bo = I, BI = -!, B2 =!.
(b) F(-t) = t + F(t), and Bk = 0 if k is odd #-1.
26. Bernoulli polynomials.
Define the Bernoul1i polynomials Bk(X) by the power
series expansion
te'X
00
tk
F(t, X) = -,- = I
Bk(X) -ki '
e - I
k=O
.
It is clear that Bk = Bk(O), so the Bernoul1i numbers are the constant terms of the
Bernoul1i polynomials. Prove :
(a) Bo(X) = I, BI(X) = X -1, B2(X) = x 2 -
X +i.
(b) For each positive integer N,
N-l
(X +a)
Bk(X) = N k- I I
B, -
-
.
0=0
N
(c) Bk(X) = x k-1kXk-1 + lower terms.
tk
(d) F(t, X + I) - F(t, X) = te" = tI x:k!'
(e) Bk(X + I) - Bk(X) = kXk-1 for k ~ 1.
27. Let N be a positive integer and let f be a function on ZINZ. Form the power
series
N-I
te(O+X),
FAt, X) = I
f(a) -N-'-
.
0=0
e
- I
Following Leopoldt, define the generalized Bernoulli polynomials relative to the
function f by
In particular, the constant term of Bk.j(X) is defined to be the generalized
Bernoulli number
Bk.j = Bk,f(O) introduced by Leopoldt in cyclotomic fields.
Prove:
(a) Fj(t, X + k) = ek'Fj(t, X).
(b) Fj(t, X + N) - Fj(t, X) = (eN' - I)Fj(t, X) .
I
N-I
(c) k[Bk,f(X + N) - Bk.j(X)] =
o~o f(a)(a + X)k-1.
(d) Bk.j(X) =
i~ G) Bi,jX
n
-
i
= Bk,f + kBk-l,fX + ...+ kBl,jXk-1 + BO,fXk.
Note.
The exercises on Bernoulli numbers and polynomials are designed not
only to give examples for the material in the text, but to show how this material
leads into major areas of mathematics : in topology and algebraic geometry centering

220
POLYNOMIALS
IV, Ex
around Riemann-Roch theorems; analytic and algebraic number theory, as in the
theory of the zeta functions and the theory of modular forms, cf. my Introduction
to Modular Forms, Springer-Verlag, New York, 1976, Chapters XIV and XV; my
Cyclotomic Fields, I and II, Springer-Verlag, New York, 1990, Chapter 2, §2; Kubert-
Lang's Modular Units, Springer-Verlag, New York, 1981 ; etc.
Further Comments, 1996-2001. I was informed by Umberto Zannier that what has
been called Mason's theorem was proved three years earlier by Stothers [Sto 81], Theo-
rem 1.1. Zannier himself has published some results on Davenport's theorem [Za 95],
without knowing of the paper by Stothers, using a method similar to that of Stothers,
and rediscovering some of Stothers' results, but also going beyond. Indeed, Stothers uses
the "Belyi method" belonging to algebraic geometry, and increasingly appearing as a
fundamental tool. Mason gave a very elementary proof, accessible at the basic level of
algebra. An even shorter and very elegant proof of the Mason-Stothers theorem was
given by Noah Snyder [Sny 00]. I am much indebted to Snyder for showing me that
proof before publication, and I reproduced it in [La 99b]. But I recommend looking at
Snyder's version.
[La 99b] S. LANG, Math Talksfor Undergraduates, Springer Verlag 1999
[Sny 00] N. SNYDER, An alternate proof of Mason's theorem, Elemente der Math. 55
(2000) pp. 93-94
[Sto 81] W. STOTHERS, Polynomial identities and hauptmoduln, Quart. 1. Math. Oxford
(2) 32 (1981) pp. 349- 370
[Za 95]
U. ZANNIER, On Davenport's bound for the degree of/3 - g 2 and Riemann's
existence theorem, Acta Arithm. LXXI.2 (1995) pp. 107-137

Part Two
ALGEBRAIC
EQUATIONS
This part is concerned with the solutions of algebraic equations, in one
or several variables.
This is the recurrent theme in every chapter of this
part, and we lay the foundations for all further studies concerning such
equations.
Given a subring A of a ring B, and a finite number of polynomials
f1' ... , fn in A[X1, ... , XnJ, we are concerned with the n-tuples
(b 1, .. . , bn) E B(n)
such that
for i = 1, .. ., r. For suitable choices of A and B, this includes the general
problem of diophantine analysis when A, B have an "arithmetic" structure.
We shall study various cases. We begin by studying roots of one polyno-
mial in one variable over a field. We prove the existence of an algebraic
closure, and emphasize the role of irreducibility.
Next we study the group of automorphisms of algebraic extensions of a
field, both intrinsically and as a group of permutations of the roots of a
polynomial.
We shall mention some major unsolved problems along the
way.
It is also necessary to discuss extensions of a ring, to give the possibil-
ity of analyzing families of extensions. The ground work is laid in Chapter
VII.
In Chapter IX, we come to the zeros of polynomials in several variables,
essentially over algebraically closed fields. But again, it is advantageous to
221

222
ALGEBRAIC EQUATIONS
PART TWO
consider polynomials over rings, especially Z, since in projective space, the
conditions that homogeneous polynomials have a non-trivial common zero
can be given universally over Z in terms of their coefficients.
Finally we impose additional structures like those of reality, or metric
structures given by absolute values. Each one of these structures gives rise to
certain theorems describing the structure of the solutions of equations as
above, and especially proving the existence of solutions in important cases.

CHAPTER V
Algebraic Extensions
In this first chapter concerning polynomial equations, we show that given
a polynomial over a field, there always exists some extension of the field
where the polynomial has a root, and we prove the existence of an algebraic
closure.
We make a preliminary study of such extensions, including the
automorphisms, and we give algebraic extensions of finite fields as examples.
§1.
FINITE AND ALGEBRAIC EXTENSIONS
Let F be a field. If F is a subfield of a field E, then we also say that E is
an extension field of F. We may view E as a vector space over F, and we say
that E is a finite or infinite extension of F according as the dimension of this
vector space is finite or infinite.
Let F be a subfield of a field E. An element
(I( of E is said to be algebraic
over F if there exist elements ao, ... , an (n ~ 1) of F, not all equal to 0, such
that
If (I( ¥- 0, and
(I( is algebraic, then we can always find elements a, as above
such that ao ¥-°(factoring out a suitable power of (I().
Let X be a variable over F. We can also say that (I( is algebraic over F if
the homomorphism
F[X] -. E
223
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

224
ALGEBRAIC EXTENSIONS
V, §1
which is the identity on F and maps X on ex has a non-zero kernel. In that
case the kernel is an ideal which is principal, generated by a single polyno-
mial p(X), which we may assume has leading coefficient 1. We then have an
isomorphism
F[X]/(p(X)) ~ F[ex],
and since F[ex] is entire, it follows that p(X) is irreducible. Having normal-
ized p(X) so that its leading coefficient is 1, we see that p(X) is uniquely
determined by ex and will be called THE irreducible polynomial of ex over F.
We sometimes denote it by Irr(ex, F, X).
An extension E of F is said to be algebraic if every element of E is
algebraic over F.
Proposition 1.1.
Let E be a finite extension of F.
Then E is algebraic
over F.
Proof.
Let ex E E, ex ¥= 0. The powers of ex,
cannot be linearly independent over F for all positive integers n, otherwise
the dimension of E over F would be infinite. A linear relation between these
powers shows that ex is algebraic over F.
Note that the converse of Proposition 1.1 is not true; there exist infinite
algebraic extensions. We shall see later that the subfield of the complex
numbers consisting of all algebraic numbers over Q is an infinite extension
ofQ.
If E is an extension of F, we denote by
[E:F]
the dimension of E as vector space over F. It may be infinite.
Proposition 1.2.
Let k be a field and FeE extension fields of k. Then
[E :k] = [E :F] [F :k].
If {Xi}iel is a basis for F over k and {Yj}jeJ is a basis for E over F, then
{XiYj}(i.j)el xJ is a basis for E over k.
Proof.
Let Z E E. By hypothesis there exist elements exj E F, almost all
exj = 0, such that
For each j E J there exist elements bji E k, almost all of which are equal to 0,
such that

V, §1
and hence
FINITE AND ALGEBRAIC EXTENSIONS
225
This shows that {XiYj} is a family of generators for E over k. We must show
that it is linearly independent. Let {ciJ be a family of elements of k, almost
all of which are 0, such that
Then for each j,
because the elements Yj are linearly independent over F, Finally cij = 0 for
each i because {x.] is a basis of F over k, thereby proving our proposition.
Corollary 1.3.
The extension E of k is finite if and only if E is finite over
F and F is finite over k.
As with groups, we define a tower of fields to be a sequence
r,
C F2 C
' "
C t;
of extension fields. The tower is called finite if and only if each step is finite.
Let k be a field, E an extension field, and a E E. We denote by k(a) the
smallest subfield of E containing both k and a. It consists of all quotients
f(a)/g(a), where f, 9 are polynomials with coefficients in k and g(a) i= O.
Proposition 1.4.
Let a be algebraic over k. Then k(a) = k[a], and k(a) is
finite over k. The degree [k(a): k] is equal to the degree of Irrt«, k, X).
Proof.
Let p(X) = Irr(a, k, X). Let f(X) E k[X] be such that f(a) i= O.
Then p(X) does not divide f(X), and hence there exist polynomials g(X),
h(X) E k[X] such that
g(X)p(X) + h(X)f(X) = 1.
From this we get h(a)f(a) = 1, and we see that f(a) is invertible in k[a].
Hence k[a] is not only a ring but a field, and must therefore be equal to
k(a). Let d = deg p(X). The powers
1, a, ... , a d - l
are linearly independent over k, for otherwise suppose
ao + ala + ... + ad_lad-l = 0

226
ALGEBRAIC EXTENSIONS
V, §1
with a, E k, not all a, = O. Let g(X) = ao + ... + ad-I X d-I. Then g =F 0 and
g(lX) = O.
Hence p(X) divides g(X), contradiction.
Finally, let f(lX) E k[IX],
where f(X) E k[X].
There exist polynomials q(X), r(X) E k[X] such that
deg r < d and
f(X) = q(X)p(X) + r(X).
Then f(lX) = r(IX), and we see that 1, IX, • ••, IXd-1 generate k[lX] as a vector space
over k. This proves our proposition.
Let E, F be extensions of a field k. If E and F are contained in some field
L then we denote by EF the smallest subfield of L containing both E and
F, and call it the compositum of E and F, in L. If E, F are not given as
embedded in a common field L, then we cannot define the compositum.
Let k be a subfield of E and let lXI ' .. ., IXn be elements of E. We denote
by
k(IXI, ... , IXn)
the smallest subfield of E containing k and lXI' ... , IXn' Its elements consist of
all quotients
f(IX I,
, IXn)
g(IXI ,
, IXn)
where f, g are polynomials in n variables with coefficients in k, and
Indeed, the set of such quotients forms a field containing k and
IXI,···, IXn'
Conversely, any field containing k and
must contain these quotients.
We observe that
E is the union of all its subfields
k(IXI, .. . , IXn) as
(IXI , ••• , IXn) ranges over finite subfamilies of elements of E. We could define
the compositum of an arbitrary subfamily of subfields of a field L as the
smallest subfield containing all fields in the family. We say that E is finitely
generated over k if there is a finite family of elements
IXI, ••• , IXn of E such
that
E = k(IXI, ... , IXn)'
We see that E is the compositum of all its finitely generated subfields over k.
Proposition 1.5.
Let E be a finite extension of k.
Then E is finitely
generated.
Proof
Let
{IXI' ... , IXn} be a basis of E as vector space over k. Then
certainly

V, §1
FINITE AND ALGEBRAIC EXTENSIONS
227
If E = k(a), ... , an) is finitely generated, and F is an extension of k, both
F, E contained in L, then
and EF is finitely generated over F. We often draw the following picture:
EF
/~F
E~/
k
Lines slanting up indicate an inclusion relation between fields. We also call
the extension EF of F the translation of E to F, or also the lifting of E to
F.
Let a be algebraic over the field k. Let F be an extension of k, and
assume k(a), F both contained in some field L. Then a is algebraic over F.
Indeed, the irreducible polynomial for a over k has a fortiori coefficients in
F, and gives a linear relation for the powers of a over F.
Suppose that we have a tower of fields:
each one generated from the preceding field by a single element. Assume that
each ai is algebraic over k, i = 1, ... , n. As a special case of our preceding
remark, we note that ai+) is algebraic over k(a), ... , a;). Hence each step of
the tower is algebraic.
Proposition 1.6.
Let E = k(a), ... , an) be a finitely generated extension of
a field k, and assume «, algebraic over k for each i = 1, ... , n. Then E is
finite algebraic over k.
Proof.
From the above remarks, we know that E can be obtained as the
end of a tower each of whose steps is generated by one algebraic element,
and is therefore finite by Proposition 1.4. We conclude that E is finite over k
by Corollary 1.3, and that it is algebraic by Proposition 1.1.
Let e be a certain class of extension fields FeE. We shall say that e is
distinguished if it satisfies the following conditions:
(1) Let k cz F c E be a tower of fields. The extension k c E is in e if and
only if keF is in e and FeE is in e.
(2) If k c E is in e, if F is any extension of k, and E, F are both
contained in some field, then F c EF is in e.
(3) If k cz F and k c E are in e and F, E are subfields of a common field,
then k c FE is in e.

228
ALGEBRAIC EXTENSIONS
The diagrams illustrating our properties are as follows:
V. §1
E
I
F
I
k
(1)
EF
/~
E
F
~/
k
(3)
These lattice diagrams of fields are extremely suggestive in handling exten-
sion fields.
We observe that (3) follows formally from the first two conditions.
Indeed, one views EF over k as a tower with steps keF c EF.
As a matter of notation, it is convenient to write ElF instead of FeE to
denote an extension. There can be no confusion with factor groups since we
shall never use the notation ElF to denote such a factor group when E is an
extension field of F.
Proposition 1.7.
The class of algebraic extensions is distinguished, and so
is the class of finite extensions.
Proof
Consider first the class of finite extensions. We have already
proved condition (1). As for (2), assume that Elk is finite, and let F be any
extension of k. By Proposition 1.5 there exist elements (Xl"
'"
(Xn E E such
that E = k((Xl' . .. , (Xn)' Then EF = F((Xl' ... , (Xn), and hence EFIF is finitely
generated by algebraic elements. Using Proposition 1.6 we conclude that
EFIF is finite.
Consider next the class of algebraic extensions, and let
kcFcE
be a tower.
Assume that
E is algebraic over k.
Then a fortiori, F is
algebraic over k and E is algebraic over F. Conversely, assume each step in
the tower to be algebraic. Let (X E E. Then
(X satisfies an equation
an(Xn + ...+ ao = 0
with a, E F, not all a, = O. Let Fo = k(an,... ,ao)' Then Fo is finite over k by
Proposition 1.6, and
(X is algebraic over Fo. From the tower
k c Fo = k(an,.. ., ao) c Fo((X)
and the fact that each step in this tower is finite, we conclude that Fo((X) is
finite over k, whence (X is algebraic over k, thereby proving that E is algebraic
over k and proving condition (1) for algebraic extensions. Condition (2) has
already been observed to hold, i.e. an element remains algebraic under lifting,
and hence so does an extension.

V, §2
ALGEBRAIC CLOSURE
229
Remark.
It is true that finitely generated extensions form a distinguished
class, but one argument needed to prove part of (1) can be carried out only
with more machinery than we have at present. Cf. the chapter on transcen-
dental extensions,
§2.
ALGEBRAIC CLOSURE
In this and the next section we shall deal with embeddings of a field into
another. We therefore define some terminology.
Let E be an extension of a field F and let
CT: F -. L
be an embedding (i.e. an injective homomorphism) of F into L.
Then
CT
induces an isomorphism of F with its image CTF, which is sometimes written
Fa. An embedding r of E in L will be said to be over CT if the restriction of r
to F is equal to a. We also say that r extends
CT. If CT is the identity then we
say that r is an embedding of E over F.
These definitions could be made in more general categories, since they
depend only on diagrams to make sense:
E--:'-L
m\i
F
We shall use exponential notation (to avoid parentheses), so we write F U
instead of CTF, and fU instead of CTf for a polynomial f, applying (J to the coef-
ficients. cr. Chapter II, §5.
Remark.
Let f(X) E F[X] be a polynomial, and let a be a root of f in
E. Say f(X) = ao + ...+ a.X". Then
o =f(a) = ao + ala + ... + anan.
If r extends (J as above, then we see that ra is a root of fa because
0= r(j(a)) = ag + af(ra) + ...+ a:(ra)".
In our study of embeddings it will also be useful to have a lemma
concerning embeddings of algebraic extensions into themselves. For this we
note that if CT: E -. L is an embedding over k (i.e. inducing the identity on k),
then
CT can be viewed as a k-homomorphism of vector spaces, because both
E, L can be viewed as vector spaces over k. Furthermore CT is injective.

230
ALGEBRAIC EXTENSIONS
V, §2
Lemma 2.1.
Let E be an algebraic extension of k, and let CT: E --+ E be an
embedding of E into itself over k. Then CT is an automorphism.
Proof
Since CT is injective, it will suffice to prove that CT is surjective. Let
IY. be an element of E, let p(X) be its irreducible polynomial over k, and let E'
be the subfield of E generated by all the roots of p(X) which lie in E. Then
E' is finitely generated, hence is a finite extension of k. Furthermore, CT must
map a root of p(X) on a root of p(X), and hence CT maps E' into itself. We
can view CT as a k-homomorphism of vector spaces because
CT induces the
identity on k. Since CT is injective, its image CT(E') is a subspace of E' having
the same dimension [E' : k]. Hence (J"(E') = E' . Since a E E', it follows that
a is in the image of (J", and our lemma is proved.
Let E, F be extensions of a field k, contained in some bigger field L. We
can form the ring E[F] generated by the elements of F over E. then E[F] =
F[E], and EF is the quotient field of this ring. It is clear that the elements of
E[F] can be written in the form
a.b, + ...+ a.b;
with aj E E and b, E F. Hence EF is the field of quotients of these elements.
Lemma 2.2.
Let E i - E2 be extensions of a field k, contained in some
bigger field E, and let CT be an embedding of E in some field L. Then
CT(E 1E2 ) = CT(E 1)CT(E2 )·
Proof
We apply CT to a quotient of elements of the above type, say
(
a1b1 +
+ anbn)
afbf +
+ a~b~
CT
a~ b; +
+ a~b~
= a~ub~u +
+ a;:b;:'
and see that the image is an element of CT(E 1 )CT(E2 ). It is clear that the image
CT(E 1E2 ) is CT(E 1)CT(E2 ).
Let k be a field, f(X) a polynomial of degree
~ 1 in k[X]. We consider
the problem of finding an extension E of k in which f has a root. If p(X) is
an irreducible polynomial in k[X] which divides f(X), then any root of p(X)
will also be a root of f(X), so we may restrict ourselves to irreducible
polynomials.
Let p(X) be irreducible, and consider the canonical homomorphism
CT: k[X] --+k[X]/(p(X)).
Then
CT induces a homomorphism on k, whose kernel is 0, because every
nonzero element of k is invertible in k, generates the unit ideal, and 1 does
not lie in the kernel. Let ebe the image of X under CT, i.e. e= CT(X) is the
residue class of X mod p(X). Then
pU(e) = pU(XU) = (p(X))u = 0.

V. §2
ALGEBRAIC CLOSURE
231
Hence
~ is a root of p", and as such is algebraic over ak.
We have now
found an extension of ok, namely
uk(~) in which p" has a root.
With a minor set-theoretic argument, we shall have:
Proposition 2.3.
Let k be a field and f a polynomial in k[X] of degree
f; 1. Then there exists an extension E of k in which f has a root.
Proof.
We may assume that f = p is irreducible. We have shown that
there exists a field F and an embedding
rr: k --+F
such that p" has a root
~ in F. Let S be a set whose cardinality is the same
as that of F - ak (= the complement of ok in F) and which is disjoint from
k. Let E = k u S. We can extend rr: k --+F to a bijection of Eon F. We now
define a field structure on E. If x, Y E E we define
xy = u-1(u(x)u(y)),
x + Y = u- 1(u(x) + u(y)).
Restricted to k, our addition and multiplication coincide with the given
addition and multiplication of our original field k, and it is clear that k is a
subfield of E. We let
o: = u- 1 (~) .
Then it is also clear that p(rx) = 0, as
desired.
Corollary 2.4.
Let k be a field and let fl' .. ., In be polynomials in k[X]
of degrees f; 1. Then there exists an extension E of k in which each /; has
a root, i = 1, ... , n.
Proof.
Let E 1 be an extension in which fl has a root. We may view f2
as a polynomial over Ei - Let E2 be an extension of E1 in which f2 has a
root. Proceeding inductively, our corollary follows at once.
We define a field L to be algebraically closed if every polynomial in L[X]
of degree f; 1 has a root in L.
Theorem 2.5.
Let k be afield. Then there exists an algebraically closedfield
containing k as a subfield.
Proof.
We first construct an extension E1 of k in which every polyno-
mial in k[X] of degree f; 1 has a root. One can proceed as follows (Artin).
To each polynomial f in k[X] of degree f; 1 we associate a letter Xf and we
let S be the set of all such letters Xf (so that S is in bijection with the set of
polynomials in k[X] of degree f; 1). We form the polynomial ring k[S], and
contend that the ideal generated by all the polynomials f(Xf ) in k[S] is not
the unit ideal. If it is, then there is a finite combination of elements in our
ideal which is equal to 1:
gt!l(Xf) + ... + gnfn(XfJ = 1

232
ALGEBRAIC EXTENSIONS
V,§2
with gj E k[S].
For simplicity, write X, instead of Xfi'
The polynomials gj
will involve actually only a finite number of variables, say XI' ... , XN (with
N ~ n). Our relation then reads
nL gj(X I , · .. ,XN}};(XJ = 1.
i=1
Let F be a finite extension in which each polynomial JI'...,In has a root,
say a, is a root of }; in F, for i = 1, ... , n. Let a, = 0 for i > n. Substitute «,
for Xi in our relation. We get 0 = 1, contradiction.
Let m be a maximal ideal containing the ideal generated by all polyno-
mials J(Xf } in k[S]. Then k[S]/m is a field, and we have a canonical map
u:k[S] -. k[S]/m.
For any polynomial J E k[X] of degree ~ 1, the polynomial f" has a root in
k[S]/m, which is an extension of ak. Using the same type of set-theoretic
argument as in Proposition 2.3, we conclude that there exists an extension
EI of k in which every polynomial J E k[X] of degree ~ 1 has a root in EI •
Inductively, we can form a sequence of fields
E I c E2 C E3 C ... c En ...
such that every polynomial in En[X] of degree ~ 1 has a root in En+1 ' Let E
be the union of all fields En' n = 1, 2, ... . Then E is naturally a field, for if
x, y E E then there exists some n such that x, y E En' and we can take the
product or sum xy or x + y in En. This is obviously independent of the
choice of n such that x, y E En, and defines a field structure on E. Every
polynomial in E[X] has its coefficients in some subfield En, hence a root in
En +1 , hence a root in E, as desired.
Corollary 2.6.
Let k be a field.
There exists an extension ka which is
algebraic over k and algebraically closed.
Proof
Let E be an extension of k which is algebraically closed and let
ka be the union of all subextensions of E, which are algebraic over k. Then
ka is algebraic over k. If rx E E and a is algebraic over ka then rx is algebraic
over k by Proposition 1.7. If J is a polynomial of degree ~ 1 in ka[X], then
J has a root rx in E, and rx is algebraic over k". Hence a is in k: and ka is
algebraically closed.
We observe that if L is an algebraically closed field, and J E L[X] has
degree ~ 1, then there exists c ELand rx l , ... , rxn E L such that
J(X} = c(X - rxt> ... (X -
rxn) .
Indeed, J has a root rx l in L, so there exists g(X} EL[X] such that
J(X) = (X - rxt>g(X).
If deg g ~ 1, we can repeat this argument inductively, and express J as a

V,§2
ALGEBRAIC CLOSURE
233
product of terms (X - oej) (i = 1, ... , n) and an element c E L. Note that c is
the leading coefficient of f, i.e.
f(X) = cxn + terms of lower degree.
Hence if the coefficients of f lie in a subfield k of L, then c E k.
Let k be a field and
0': k --.L an embedding of k into an algebraically
closed field L. We are interested in analyzing the extensions of 0' to algebraic
extensions E of k. We begin by considering the special case when E is
generated by one element.
Let E = k(oe) where oe is algebraic over k. Let
p(X) = Irrte, k, X).
Let P be a root of v" in L. Given an element of k(oe) = k[oe], we can write it
in the form f(oe) with some polynomial f(X) E k[X]. We define an extension
of 0' by mapping
f(oe) 1-4 j"W).
This is in fact well defined, i.e. independent of the choice of polynomial f(X)
used to express our element in k[oe]. Indeed, if g(X) is in k[X] and such that
g(oe) = f(oe), then (g - f)(oe) = 0, whence p(X) divides g(X) - f(X).
Hence
p"(X) divides g"(X) - j"(X), and thus g"(P) = j"(P). It is now clear that our
map is a ·homomorphism inducing 0' on k, and that it is an extension of 0' to
k(oe). Hence we get:
Proposition 2.7.
The number ofpossible extensions of 0' to k(rx.) is ~deg p,
and is equal to the number ofdistinct roots of p in k",
This is an important fact, which we shall analyze more closely later. For
the moment, we are interested in extensions of
0' to arbitrary algebraic
extensions of k. We get them by using Zorn's lemma.
Theorem 2.8.
Let k be a field, E an algebraic extension of k, and
0': k --.L an embedding of k into an algebraically closed field L.
Then
there exists an extension of
0' to an embedding of E in L.
If E is
algebraically closed and L is algebraic over ak, then any such extension of
0' is an isomorphism of E onto L.
Proof.
Let S be the set of all pairs (F, r) where F is a subfield of E
containing k, and r is an extension of 0' to an embedding of F in L. If (F, r)
and (F', r') are such pairs, we write (F, r) ~ (F', r') if Fe F' and -r'IF = r,
Note that S is not empty [it contains (k, 0')], and is inductively ordered: If
{(Fj, -rj)} is a totally ordered subset, we let F = UFj and define r on F to be
equal to t j on each Fj. Then (F, r) is an upper bound for the totally ordered
subset. Using Zorn's lemma, let (K, A.) be a maximal element in S. Then A. is
an extension of 0', and we contend that K = E. Otherwise, there exists oe E E,

234
ALGEBRAIC EXTENSIONS
V,§2
ex ¢ K. By what we saw above, our embedding Ie has an extension to K(ex),
thereby contradicting the maximality of (K, ),). This proves that there exists
an extension of a to E. We denote this extension again by a.
If E is algebraically closed, and L is algebraic over ok, then aE is
algebraically closed and L is algebraic over ali, hence L = ali.
As a corollary, we have a certain uniqueness for an "algebraic closure" of
a field k.
Corollary 2.9.
Let k be a field and let E, E' be algebraic extensions oj k.
Assume that E, E' are algebraically closed.
Then there exists an iso-
morphism
r :E~E'
oj E onto E' inducing the identity on k.
Proof
Extend the identity mapping on k to an embedding of E into E'
and apply the theorem.
We see that an algebraically closed and algebraic extension of k is
determined up to an isomorphism.
Such an extension will be called an
algebraic closure of k, and we frequently denote it by k". In fact, unless
otherwise specified, we use the symbol ka only to denote algebraic closure.
It is now worth while to recall the general situation of isomorphisms and
automorphisms in general categories.
Let (i be a category, and A, B objects in (1. We denote by Iso(A, B) the
set of isomorphisms of A on B.
Suppose there exists at least one such
isomorphism a: A ~ B, with inverse a-I : B ~ A. If qJ is an automorphism of
A, then a 0 tp: A ~ B is again an isomorphism. If ljJ is an automorphism of
B, then
ljJ 0 a: A ~ B is again an isomorphism.
Furthermore, the groups
of automorphisms Aut(A) and Aut(B) are isomorphic, under the mappings
qJ1-+ a 0 qJ 0 a-I,
a-I 0 ljJ 0 a +-IljJ,
which are inverse to each other.
The isomorphism a 0 qJ 0 a-I is the one
which makes the following diagram commutative:
A----+ B
o
We have a similar diagram for a-I 0 ljJ 0 a.
Let r: A ~ B be another isomorphism. Then r- I 0 a is an automorphism
of A, and r 0 a-I is an automorphism of B. Thus two isomorphisms differ by
an automorphism (of A or B). We see that the group Aut(B) operates on the

V. §3
SPLITTING FIELDS AND NORMAL EXTENSIONS
235
set Iso(A, B) on the left, and Aut(A) operates on the set Iso(A, B) on the
right.
We also see that Aut(A) is determined up to a mapping analogous to a
conjugation.
This is quite different from the type of uniqueness given by
universal objects in a category. Such objects have only the identity auto-
morphism, and hence are determined up to a unique isomorphism.
This is not the case with the algebraic closure of a field, which usually
has a large amount of automorphisms. Most of this chapter and the next is
devoted to the study of such automorphisms.
Examples.
It will be proved later in this book that the complex numbers
are algebraically closed.
Complex conjugation is an automorphism of C.
There are many more automorphisms, but the other automorphisms *" id. are
not continuous. We shall discuss other possible automorphisms in the chapter
on transcendental extensions. The subfield of C consisting of all numbers which
are algebraic over Q is an algebraic closure Qa of Q. It is easy to see that Qa
is denumerable. In fact, prove the following as an exercise:
If k is a field which is not finite, then any algebraic extension of k has the
same cardinality as k.
If k is denumerable, one can first enumerate all polynomials in k, then
enumerate finite extensions by their degree, and finally enumerate the cardi-
nality of an arbitrary algebraic extension. We leave the counting details as
exercises.
In particular, Qa #- C. If R is the field of real numbers, then R" = C.
If k is a finite field, then algebraic closure ka of k is denumerable.
We
shall in fact describe in great detail the nature of algebraic extensions of
finite fields later in this chapter.
Not all interesting fields are subfields of the complex numbers.
For
instance, one wants to investigate the algebraic extensions of a field C(X)
where X is a variable over C. The study of these extensions amounts to the
study of ramified coverings of the sphere (viewed as a Riemann surface), and
in fact one has precise information concerning the nature of such extensions,
because one knows the fundamental group of the sphere from which a finite
number of points has been deleted.
We shall mention this example again
later when we discuss Galois groups.
§3.
SPLITTING FIELDS AND
NORMAL EXTENSIONS
Let k be a field and let f be a polynomial in k[X] of degree
~ 1. By a
splitting field K of f we shall mean an extension K of k such that f splits
into linear factors in K, i.e.

236
ALGEBRAIC EXTENSIONS
f(X} = c(X -
IXd • • • (X -
IXn)
V, §3
with a, E K, i = 1, .. ., n, and such that K = k(1X1,... , IXn} is generated by all
the roots of f
Theorem 3.1.
Let K be a splitting field of the polynomial f(X} E k[X]. If
E is another splitting field of f, then there exists an isomorphism u:E -+ K
inducing the identity on k. If k eKe k", where ka is an algebraic closure
of k, then any embedding of E in k!" inducing the identity on k must be an
isomorphism of E onto K.
Proof
Let K" be an algebraic closure of K. Then K" is algebraic over
k, hence is an algebraic closure of k.
By Theorem 2.8 there exists an
embedding
inducing the identity on k. We have a factorization
f(X} = c(X - PI} ... (X - Pn)
with Pi E E, i = 1, ... , n. The leading coefficient c lies in k. We obtain
f(X} = j"(X} = c(X - UP1} ... (X - uPn).
We have unique factorization in Ka[X]. Since f has a factorization
f(X} = c(X -
1X1} • • • (X -
IXn )
in K[X], it follows that (UP1' ..., uPn) differs from ((1(1' •. ., (l(n) by a permuta-
tion.
From this we conclude that UPi E K for i = 1, ... , n and hence that
uE c K. But K = k(1X1,... , (l(n) = k(UP1' .. ., uPn), and hence uE = K, because
E = k(P1'.. ., Pn}·
This proves our theorem.
We note that a polynomial f(X} E k[X] always has a splitting field,
namely the field generated by its roots in a given algebraic closure ka of k.
Let I be a set of indices and let {};}ieI be a family of polynomials in
k[X], of degrees
~ 1. By a splitting field for this family we shall mean an
extension K of k such that every}; splits in linear factors in K[X], and K is
generated by all the roots of all the polynomials Ii, i E I.
In most applica-
tions we deal with a finite indexing set I, but it is becoming increasingly
important to consider infinite algebraic extensions, and so we shall deal with
them fairly systematically. One should also observe that the proofs we shall
give for various statements would not be simpler if we restricted ourselves to
the finite case.
Let ka be an algebraic closure of k, and let K, be a splitting field of }; in
k".
Then the compositum of the K, is a splitting field for our family,

V. §3
SPUTIING FIELDS AND NORMAL EXTENSIONS
237
since the two conditions defining a splitting field are immediately satisfied.
Furthermore Theorem 3.1 extends at once to the infinite case :
Corollary 3.2.
Let K be a splitting field for the family {I;};el and let E
be another splitting field.
Any embedding of E into K3 inducing the
identity on k gives an isomorphism of E onto K.
Proof.
Let the notation be as above.
Note that E contains a unique
splitting field E; of I; and K contains a unique splitting field K; of 1;. Any
embedding (J of E into K
3 must map E; onto K; by Theorem 3.1, and hence
maps E into K. Since K is the compositum of the fields K j , our map (J must
send E onto K and hence induces an isomorphism of E onto K.
Remark.
If I is finite, and our polynomials are f1, ... , fn, then a split-
ting field for them is a splitting field for the single polynomial f(X) =
f1(X) .. . fn(X) obtained by taking the product. However, even when dealing
with finite extensions only, it is convenient to deal simultaneously with sets
of polynomials rather than a single one.
Theorem 3.3.
Let K be an algebraic extension of k, contained in an
algebraic closure k' of k. Then the following conditions are equivalent:
NOR 1.
Every embedding of Kin k3 over k induces an automorphism of K.
NOR 2.
K is the splitting field of a family of polynomials in k[X].
NOR 3.
Every irreducible polynomial of k[X] which has a root in K
splits into linear factors in K.
Proof.
Assume NOR 1. Let a be an element of K and let Pa(X) be its
irreducible polynomial over k. Let f3 be a root of Pa in k', There exists an
isomorphism of k(O() on k(fJ) over k, mapping
0( on
{1.
Extend this iso-
morphism to an embedding of K in k". This extension is an automorphism (J
of K by hypothesis, hence (JO( = {11ies in K. Hence every root of Pa lies in K,
and Pa splits in linear factors in K[X].
Hence K is the splitting field of the
family {Pa}aeK as a ranges over all elements of K, and NOR 2 is satisfied.
Conversely, assume NOR 2, and let {I;};el be the family of polynomials
of which K is the splitting field. If a is a root of some I; in K , then for any
embedding
(J of K in k
3 over k we know that a« is a root of 1;. Since K is
generated by the roots of all the polynomials 1;, it follows that
(J maps K
into itself. We now apply Lemma 2.1 to conclude that
(J is an automorphism.
Our proof that NOR 1 implies NOR 2 also shows that NOR 3 is
satisfied.
Conversely, assume NOR 3.
Let
(J be an embedding of K in k
3
over k. Let a E K and let p(X) be its irreducible polynomial over k. If (J is
an embedding of K in k
3 over k then
(J maps a on a root f3 of p(X), and by
hypothesis f3 lies in K.
Hence a« lies in K, and
(J maps K into itself. By
Lemma 2.1, it follows that (J is an automorphism.

238
ALGEBRAIC EXTENSIONS
V, §3
An extension K of k satisfying the hypotheses NOR 1, NOR 2, NOR 3
will be said to be normal. It is not true that the class of normal extensions is
distinguished, For instance, it is easily shown that an extension of degree 2
is normal, but the extension Q(,y2) of the rational numbers is not normal
(the complex roots of X4 -
2 are not in it), and yet this extension is obtained
by successive extensions of degree 2, namely
E = Q(,y2) ::::> F ::::> Q,
where
F = Q(a),
a = J2
and
E = F(fi)·
Thus a tower of normal extensions is not necessarily normal.
However, we
still have some of the properties:
Theorem
3.4.
Normal
extensions remain
normal
under
lifting.
If
K
::::> E ::::> k and K is normal over k, then K is normal over E. If K I' K 2
are normal over k and are contained in some field L, then K I K 2 is normal
over k, and so is K] II K 2 •
Proof
For our first assertion, let K be normal over k, let F be any
extension of k, and assume K, F are contained in some bigger field. Let a be
an embedding of KF over F (in P). Then o induces the identity on F, hence
on k, and by hypothesis its restriction to K maps K into itself. We get
(KF)l1 = Kl1pa = KF whence KF is normal over F.
Assume that K::::> E ::::> k and that K is normal over k.
Let a be an
embedding of Kover E. Then a is also an embedding of Kover k, and
our assertion follows by definition.
Finally, if K I' K 2 are normal over k, then for any embedding o of K I K 2
over k we have
and our assertion again follows from the hypothesis. The assertion concern-
ing the intersection is true because
u(K I II K 2 ) = u(Kd II u(K2 ).
We observe that if K is a finitely generated normal extension of k, say
K = k(a l , •• • , an),
and PJ, ... ,Pn are the respective irreducible polynomials of al, ... ,an over
k then K is already the splitting field of the finite family PI" ' " Pn'
We
shall investigate later when K is the splitting field of a single irreducible
polynomial.

V, §4
§4.
SEPARABLE EXTENSIONS
SEPARABLE EXTENSIONS
239
Let E be an algebraic extension of a field F and let
a:F ..... L
be an embedding of F in an algebraically closed field L. We investigate more
closely extensions of a to E. Any such extension of a maps E on a subfield
of L which is algebraic over «I: Hence for our purposes, we shall assume
that L is algebraic over aF, hence is equal to an algebraic closure of ol'.
Let S(J be the set of extensions of a to an embedding of E in L.
Let L' be another algebraically closed field, and let r: F ..... L' be an
embedding.
We assume as before that L: is an algebraic closure of tF.
By Theorem 2.8, there exists an isomorphism A:L ..... L' extending the map
t o a-I applied to the field oF, This is illustrated in the following diagram :
L'
+-l------ L
a*
+---- E ------+
I
t F +---- F ------+ aF
r
a
We let S, be the set of embeddings of E in L: extending r.
If a" E S(J is an extension of a to an embedding of E in L, then A0 a" is
an extension of r to an embedding of E into L', because for the restriction to
F we have
A 0 a* =
t
0 a-l oa = r.
Thus I. induces a mapping from
S(J into S;
It is clear that the inverse
mapping is induced by ).- 1, and hence that S(J' S, are in bijection under the
mapping
a*H A 0 a*.
In particular, the cardinality of S(J' S, is the same. Thus this cardinality
depends only on the extension E/F, and will be denoted by
[E :FJs'
We shall call it the separable degree of E over F. It is mostly interesting
when E/F is finite.
Theorem 4.1.
Let E ::::> F ::::> k be a tower. Then
[E: kJs = [E : FJs[F : kJs'
Furthermore, if E is finite over k, then [E :kJs is finite and

240
ALGEBRAIC EXTENSIONS
[E: kJ. ~ [E: k].
V. §4
The separable degree is at most equal to the degree.
Proof
Let <1: k ~ L be an embedding of k in an algebraically closed field
L. Let {<1;} i e I be the family of distinct extensions of <1 to F, and for each i, let
{tij} be the family of distinct extensions of a, to E. By what we saw before,
each a, has precisely [E :F]s extensions to embeddings of E in L. The set of
embeddings {tij} contains precisely
[E: F]s[F: k]s
elements. Any embedding of E into Lover <1 must be one of the t ij' and thus
we see that the first formula holds, i.e, we have multiplicativity in towers.
As to the second, let us assume that Elk is finite. Then we can obtain E
as a tower of extensions, each step being generated by one element:
k c k(IX 1) C k(IX 1, IX2) c . . . C k(IX 1, ..• , IX,) = E.
lf we define inductively FV +1 = Fv(IXv+1) then by Proposition 2.7,
U;'(IXv+tl: Fv]s ~ U;'(IXv+ 1 ) : F.].
Thus our inequality is true in each step of the tower. By multiplicativity, it
follows that the inequality is true for the extension Elk, as was to be shown.
Corollary 4.2.
Let E be finite over k, and E ::J F ::J k. The equality
[E :k]s = [E: k]
holds if and only if the corresponding equality holds in each step of the
tower, i.e. for ElF and Ffk.
Proof
Clear.
It will be shown later (and it is not difficult to show) that [E : k]s divides
the degree [E :k] when E is finite over k.
We define [E :k]i to be the
quotient, so that
[E : k]s[E : k]i = [E : k].
It then follows from the multiplicativity of the separable degree and of the
degree in towers that the symbol [E : k]i is also multiplicative in towers. We
shall deal with it at greater length in §6.
Let E be a finite extension of k. We shall say that E is separable over k if
[E : k]s = [E :k].
An element IX algebraic over k is said to be separable over k if k(IX) is
separable over k. We see that this condition is equivalent to saying that the
irreducible polynomial Irr(IX, k, X) has no multiple roots.
A polynomial f(X) E k[X] is called separable if it has no multiple roots.

V, §4
SEPARABLE EXTENSIONS
241
If IX is a root of a separable polynomial g(X) E k[X] then the irreducible
polynomial of IX over k divides g and hence IX is separable over k.
We note that if keF C K and a E K is separable over k, then a is separable
over F. Indeed, iffis a separable polynomial in k[X] such thatf(a) = 0, then
f also has coefficients in F, and thus a is separable over F . (We may say that a
separable element remains separable under lifting.)
Theorem 4.3.
Let E be a finite extension of k. Then E is separable over k
if and only if each element of E is separable over k.
Proof
Assume E is separable over k and let IXE E.
We consider the
tower
k c k(lX) c E.
By Corollary 4.2, we must have [k(a) :k] = [k(a) :k]s whence a is separable
over k. Conversely, assume that each element of E is separable over k. We
can write E = k(a\, ... , an) where each ai is separable over k. We consider
the tower
Since each a, is separable over k, each lXi is separable over k(1X1, ••• , lXi-i) for
i ~ 2. Hence by the tower theorem, it follows that E is separable over k.
We observe that our last argument shows: If E is generated by a finite
number of elements, each of which is separable over k, then E is separable
over k.
Let E be an arbitrary algebraic extension of k. We define E to be
separable over k if every finitely generated subextension is separable over
k, i.e., if every
extension
k(1X1, •• • , IXn)
with
1X1, ••• , IXn E E
is separable
over k.
Theorem 4.4.
Let E be an algebraic extension of k, generated by a
family of elements
{lXi }ieI'
If each a, is separable over k then E is
separable over k.
Proof
Every element of E lies in some finitely generated subfield
and as we remarked above, each such subfield is separable over k. Hence
every element of E is separable over k by Theorem 4.3, and this concludes
the proof.
Theorem 4.5.
Separable extensions form a distinguished class of exten-
sions.

242
ALGEBRAIC EXTENSIONS
V, §4
Proof
Assume that E is separable over k and let E ~ F ~ k.
Every
element of E is separable over F, and every element of F is an element of E,
so separable over k. Hence each step in the tower is separable. Conversely,
assume that E ~ F ~ k is some extension such that ElF is separable and Flk
is separable . If E is finite over k, then we can use Corollary 4.2 . Namely, we
have an equality of the separable degree and the degree in each step of the tower,
whence an equality for E over k by multiplicativity.
If E is infinite, let a E E. Then a is a root of a separable polynomial f(X)
with coefficients in F.
Let
these coefficients be
an, " " ao.
Let
Fo =
k(an,... , ao)' Then Fo is separable over k, and a is separable over Fo. We
now deal with the finite tower
k c Fo c Fo(a)
and we therefore conclude that Fo(a) is separable over k, hence that a
is
separable
over
k.
This
proves
condition
(1) in
the
definition
of
" distinguished."
Let E be separable over k. Let F be any extension of k, and assume that
E, F are both subfields of some field. Every element of E is separable over k,
whence separable over F. Since EF is generated over F by all the elements
of E, it follows that EF is separable over F, by Theorem 4.4. This proves
condition (2) in the definition of "distinguished," and concludes the proof of
our theorem.
Let E be a finite extension of k. The intersection of all normal extensions
K of k (in an algebraic closure E") containing E is a normal extension of k
which contains E, and is obviously the smallest normal extension of k
containing E. If O"t, ..., a; are the distinct embeddings of E in E", then the
extension
which is the compositum of all these embeddings, is a normal extension of k,
because for any embedding of it, say r, we can apply r to each extension
O"iE. Then (rO"t, .. ., rO"n) is a permutation of (O"t, .. ., O"n) and thus r maps K
into itself. Any normal extension of k containing E must contain
O"iE for
each i, and thus the smallest normal extension of k containing E is precisely
equal to the compositum
If E is separable over k, then from Theorem 4.5 and induction we
conclude that the smallest normal extension of k containing E is also separ-
able over k.
Similar results hold for an infinite algebraic extension E of k, taking an
infinite compositum.

V,§4
SEPARABLE EXTENSIONS
243
In light of Theorem 4,5, the compositum of all separable extensions of a
field k in a given algebraic closure ka is a separable extension, which will be
denoted by k
S or ksep, and will be called the separable closure of k. As a
matter of terminology, if E is an algebraic extension of k, and a any
embedding of E in k' over k, then we call aE a conjugate of E in k' . We can
say that the smallest normal extension of k containing E is the compositum of
all the conjugates of E in P.
Let a be algebraic over k. If ai'
, a, are the distinct embeddings of k(a)
into ka over k, then we call a1a,
, a.« the conjugates of a in k", These
elements are simply the distinct roots of the irreducible polynomial of a over
k. The smallest normal extension of k containing one of these conjugates is
simply k(a1a, ... , ara).
Theorem 4.6.
(Primitive Element Theorem).
Let E be a finite extension
of a field k. There exists an element a E E such that E = k(a) if and only
if there exists only a finite number of fields F such that k cz F c E. If E
is separable over k, then there exists such an element a.
Proof
If k is finite, then we know that the multiplicative group of E is
generated by one element, which will therefore also generate E over k. We
assume that k is infinite.
Assume that there is only a finite number of fields, intermediate between
k and E. Let a, 13 E E. As c ranges over elements of k, we can only have
a finite number of fields of type k(a + cf3).
Hence there exist elements c1 ,
C2 E k with C1 "# C2 such that
k(a + c1 f3 ) = k(a + C2f3).
Note that a + c1 f3 and a + C2f3 are in the same field, whence so is (c1 -
C2)f3,
and hence so is 13. Thus a is also in that field, and we see that k(a, 13) can be
generated by one element.
Proceeding inductively, if E = k(a 1, ... , an) then there will exist elements
c2 , ••• , Cn E k such that
E = k(~)
where
~ = a1 + C2a2 + ... + cnan. This proves half of our theorem.
Conversely, assume that E = k(a) for some a, and let f(X) = Irr(a, k, X).
Let k cz F c E. Let gF(X) = Irr(«, F, X). Then gF divides f. We have unique
factorization in E[X], and any polynomial in E[X] which has leading
coefficient 1 and divides f(X) is equal to a product of factors (X - ail where
a\, . . . , an are the roots off in a fixed algebraic closure. Hence there is only a
finite number of such polynomials . Thus we get a mapping
F f--+ gF
from the set of intermediate fields into a finite set of polynomials.
Let Fo be

244
ALGEBRAIC EXTENSIONS
V.§5
the subfield of F generated over k by the coefficients of gF(X), Then gF has
coefficients in Fo and is irreducible over Fo since it is irreducible over F.
Hence the degree of a. over Fo is the same as the degree of a. over F. Hence
F = Fo. Thus our field F is uniquely determined by its associated poly-
nomials gF' and our mapping is therefore injective. This proves the first
assertion of the theorem.
As to the statement concerning separable extensions, using induction,
we may assume without loss of generality that E = k(a., P) where a., pare
separable over k. Let CT1, ••• , CTn be the distinct embeddings of k(a., P) in ka
over k. Let
P(X) = n (CTia. + X CTjp -
CTja. - X CTjP).
ii'j
Then P(X) is not the zero polynomial, and hence there exists C E k such
that P(c) =j:. O. Then the elements CTj(a. + cP) (i = I, ..., n) are distinct, whence
k(a. + cP) has degree at least n over k. But n = [k(a., p) : k], and hence
k(a., P) = k(a. + cP),
as desired.
If E = k(a.), then we say that a. is a primitive element of E (over k).
§5.
FINITE FIELDS
We have developed enough general theorems to describe the structure of
finite fields. This is interesting for its own sake, and also gives us examples
for the general theory.
Let F be a finite field with q elements. As we have noted previously, we
have a homomorphism
Z~F
sending 1 on 1, whose kernel cannot be 0, and hence is a principal ideal
generated by a prime number p since Z/pZ is embedded in F and F has no
divisors of zero. Thus F has characteristic p, and contains a field isomorphic
to Z/pZ.
We remark that Z/pZ has no automorphisms other than the identity.
Indeed, any automorphism must map 1 on 1, hence leaves every element
fixed because 1 generates Z/pZ additively. We identify Z/pZ with its image
in F. Then F is a vector space over Z/pZ, and this vector space must be

V, §5
FINITE FIELDS
245
finite since F is finite. Let its degree be n. Let W1, . . . , co; be a basis for F
over Z/pZ. Every element of F has a unique expression of the form
with a, E Z/pZ. Hence q = p".
The multiplicative group F* of F has order q - 1. Every IXE F* satisfies
the equation Xq-l = 1. Hence every element of F satisfies the equation
f(X) = X" - X = 0.
This implies that the polynomial f(X) has q distinct roots in F, namely all
elements of F. Hence f splits into factors of degree 1 in F, namely
X" -
X = TI (X -
IX).
~EF
In particular, F is a splitting field for f.
But a splitting field is uniquely
determined up to an isomorphism. Hence if a finite field of order pn exists, it
is uniquely determined, up to an isomorphism, as the splitting field of
XP" - X over Z/pZ.
As a matter of notation, we denote Z/pZ by Fp • Let n be an integer ~ 1
and consider the splitting field of
xr - X = f(X)
in an algebraic closure F; . We contend that this splitting field is the set of
roots of f(X) in F;. Indeed, let IX, f3 be roots. Then
(IX + f3)P" - (IX + f3) = IX P" + f3P" -
IX -
f3 = 0,
whence IX+ f3 is a root. Also,
(1Xf3)P" -
1Xf3 = IXP"f3P" -
1Xf3 = 1Xf3 -
1Xf3 = 0,
and 1Xf3 is a root. Note that 0, 1 are roots of f(X). If f3 =F°then
(P-l)P" - f3-1 = (f3P"r1 - p-l =°
so that f3-1 is a root. Finally,
(- f3)P" - (- f3) = (-l)P"f3P" + f3.
If p is odd, then (-l)P" = -1 and we see that - f3 is a root. If p is even then
-1 = 1 (in Z/2Z) and hence - f3 = f3 is a root. This proves our contention.
The derivative of f(X) is
f' (X ) = pnXP"-l - 1 = -1.
Hence f(X) has no multiple roots, and therefore has pn distinct roots in
F;. Hence its splitting field has exactly pn elements. We summarize our
results:

246
ALGEBRAIC EXTENSIONS
V, §5
Theorem 5.1.
For each prime p and each integer n ~ 1 there exists a finite
field of order p" denoted by Fpn, uniquely determined as a subfield of an
algebraic closure F;. It is the splitting field of the polynomial
Xpn - X,
and its elements are the roots of this polynomial.
Every finite field is
isomorphic to exactly one field Fpn.
We usually write p" = q and F, instead of Fpn.
Corollary 5.2.
Let F, be a finite field. Let n be an integer ~ 1. Ina
given algebraic closure F;, there exists one and only one extension of F, of
degree n, and this extension is the field Fqn.
Proof
Let q = p", Then q" = pm".
The splitting field of X qn- X is
precisely Fpmn and has degree mn over Z/pZ.
Since F, has degree mover
Z/pZ, it follows that Fqn has degree n over Fq. Conversely, any extension of
degree n over F, has degree mn over F, and hence must be Fpmn. This proves
our corollary.
Theorem 5.3.
The multiplicative group of a finite field is cyclic.
Proof
This has already been proved in Chapter IV, Theorem 1.9.
We shall determine all automorphisms of a finite field.
Let q = v: and let F, be the finite field with q elements. We consider the
Frobenius mapping
cp: F, --+ F,
such that cp(x) = x". Then cp is a homomorphism, and its kernel is 0 since Fq
is a field.
Hence
cp is injective.
Since F, is finite, it follows that
cp is
surjective, and hence that cp is an isomorphism.
We note that it leaves F,
fixed.
Theorem 5.4.
The group of automorphisms of Fq is cyclic of degree n,
generated by cp.
Proof
Let G be the group generated by cp.
We note that cp" = id
because q>"(x) = x'" = x for all x E Fq• Hence n is an exponent for cp. Let d
be the period of cp, so d ~ 1. We have cpd(X) = x Pd for all x E Fq• Hence each
x E Fq is a root of the equation
XPd -
X = O.
This equation has at most v' roots. It follows that d ~ n, whence d = n.
There remains to be proved that G is the group of all automorphisms of
Fq •
Any automorphism of F, must leave F, fixed.
Hence it is an auto-

V, §6
INSEPARABLE EXTENSIONS
247
morphism of F, over Fp •
By Theorem 4.1, the number of such auto-
morphisms is
~ n. Hence F, cannot have any other automorphisms except
for those of G.
Theorem 5.5.
Let m, n be integers ~ 1. Then in any algebraic closure of
Fp' the subfield Fpn is contained in Fpm if and only if n divides m. If that is the
case, let q = v". and let m = nd. Then Fpm is normal and separable over Fq,
and the group ofautomorphisms ofFpm over Fq is cyclic oforder d. generated
by cp".
Proof
All the statements are trivial consequences of what has already been
proved and will be left to the reader.
§6.
INSEPARABLE EXTENSIONS
This section is of a fairly technical nature, and can be omitted without
impairing the understanding of most of the rest of the book.
We begin with some remarks supplementing those of Proposition 2.7.
Let f(X) = (X - a)mg(x) be a polynomial in k[X], and assume X - a
does not divide g(X). We recall that m is called the multiplicity of a in f.
We say that a is a multiple root of f if m > 1. Otherwise, we say that a is a
simple root.
Proposition 6.1.
Let a be algebraic over k, a E k', and let
f(X) = Irrt«, k, X).
If char k = 0, then all roots off have multiplicity 1 (f is separable). If
char k = p > 0,
then there exists an integer J1 ~°such that every root of f has multiplicity
pit. We have
[k(a) : k] = pit[k(a) : kJ.,
and a P' is separable over k.
Proof.
Let a l , ... , a, be the distinct roots of f in ka and let a = a l . Let
m be the multiplicity of a in f. Given 1 ~ i ~ r, there exists an isomorphism
a: k(a) --+ k(ai )
over k such that a« = ai' Extend a to an automorphism of ka and denote

248
ALGEBRAIC EXTENSIONS
V, §6
this extension also by CT. Since f has coefficients in k we have f" = f. We
note that
r
!(X) = f1 (X-
aUj)mj
j=!
if mj is the multiplicity of aj in f. By unique factorization, we conclude that
m, = m1 and hence that all m, are equal to the same integer m.
Consider the derivative f'(X). Iff and f' have a root in common, then a
is a root of a polynomial of lower degree than degf.
This is impossible
unless deg f' = -00, in other words, f' is identically O. If the characteristic
is 0, this cannot happen. Hence iff has multiple roots, we are in characteris-
tic p, and f(X) = g(XP) for some polynomial g(X) E k[X]. Therefore aPis a
root of a polynomial g whose degree is < degf. Proceeding inductively, we
take the smallest integer
IJ. ~ 0 such that aP" is the root of a separable
polynomial in k[X], namely the polynomial h such that
f(X) = h(X P").
Comparing the degree of f and g, we conclude that
[k(a): k(aP)] = p.
Inductively, we find
[k(a): k(aP")] = p".
Since h has roots of multiplicity 1, we know that
[k(aP"): kJ. = [k(aP"): k],
and comparing the degree of f and the degree of h, we see that the num-
ber of distinct roots of f is equal to the number of distinct roots of h.
Hence
[k(a): k]s = [k(aP") : k]s.
From this our formula for the degree follows by multiplicativity, and our
proposition is proved. We note that the roots of hare
p"
p"
a1 , • •• , a, .
Corollary 6.2.
For any finite extension E of k, the separable degree
[E : k]s divides the degree [E :k]. The quotient is 1 if the characteristic is
0, and a power of p if the characteristic is p > O.
Proof.
We decompose Elk into a tower, each step being generated by
one element, and apply Proposition 6.1, together with the multiplicativity of
our indices in towers.
If ElK is finite, we call the quotient

V, §6
[E : k]
[E: kJ.
INSEPARABLE EXTENSIONS
249
the inseparable degree (or degree of inseparability), and denote it by [E: kJi as
in §4. We have
[E: kJ.[E : kJi = [E: k].
Corollary 6.3.
A finite extension is separable if and only if [E :kJi = 1.
Proof
By definition.
Corollary 6.4
If E ::::> F ::::> k are two finite extensions, then
Proof.
Immediate by Theorem 4.1.
We now assume throughout that k is a field of characteristic p > O.
An element r:x algebraic over k is said to be purely inseparable over k if
there exists an integer n ~ 0 such that r:x P" lies in k.
Let E be an algebraic extension of k. We contend that the following
conditions are equivalent:
P. Ins. 1.
We have [E: kJ. = 1.
P. Ins. 2.
Every element r:x of E is purely inseparable over k.
P. Ins. 3.
For every r:x E E, the irreducible equation of r:x over k is of type
X p" - a = 0 with some n ~ 0 and a E k.
P. Ins. 4.
There exists a set of generators {r:xJieI of E over k such that
each
(Xi is purely inseparable over k.
To prove the equivalence, assume P. Ins. 1. Let r:x E E. By Theorem 4.1,
we conclude that [k(r:x) :kJ. = 1. Let f(X) = Irrt«, k, X). Then f has only one
root since
[k(r:x) : k].
is equal to the number of distinct roots of f(X).
Let m = [k(r:x) : k]. Then
deg f = m, and the factorization of f over k(r:x) is f(X) = (X - r:xr. Write
m = pnr where r is an integer prime to p. Then
f(X) = (X p" -
r:xP"),
= xr: -
rr:xP"Xp"(r-l)+ lower terms.
Since the coefficients of f(X) lie in k, it follows that

250
ALGEBRAIC EXTENSIONS
V,§6
lies in k, and since r # 0 (in k), then rx P" lies in k. Let a = «", Then
rx is
a root of the polynomial
X r: - a, which divides f(X).
It follows that
f(X) = XP" - a.
Essentially the same argument as the preceding one shows that P. Ins. 2
implies P. Ins. 3. It is trivial that the third condition implies the fourth.
Finally, assume P. Ins. 4. Let E be an extension generated by purely
inseparable elements a, (i E I). Any embedding of E over k maps rxi on a root
of
/;(X) = Irr(rxi' k, X).
But /;(X) divides some polynomial XP" - a, which has only one root. Hence
any embedding of E over k is the identity on each rxi' whence the identity on
E, and we conclude that [E: kJ. = 1, as desired.
An extension satisfying the above four properties will be called purely
inseparable.
Proposition 6.5.
Purely inseparable extensions form a distinguished class
of extensions.
Proof.
The tower theorem is clear from Theorem 4.1, and the lifting
property is clear from condition P. Ins. 4.
Proposition 6.6.
Let E be an algebraic extension of k. Let Eo be the
compositum of all subfields F of E such that F::> k and F is separable
over k. Then Eo is separable over k, and E is purely inseparable over
e;
Proof.
Since separable extensions form a distinguished class, we know
that Eo is separable over k. In fact, Eo consists of all elements of E which
are separable over k. By Proposition 6.1, given rx E E there exists a power of
p, say v: such that rx P" is separable over k. Hence E is purely inseparable
over Eo, as was to be shown.
Corollary 6.7.
If an algebraic extension E of k is both separable and
purely inseparable, then E = k.
Proof.
Obvious.
Corollary 6.8.
Let K be normal over k and let Ko be its maximal separa-
ble subextension. Then Ko is also normal over k.
Proof.
Let a be an embedding of Ko in K" over k and extend a to an
embedding of K.
Then a is an automorphism of K. Furthermore, aKo is
separable over k, hence is contained in K o, since K o is the maximal separa-
ble subfield. Hence aKo = Ko, as contended.

V. §6
INSEPARABLE EXTENSIONS
251
Corollary 6.9.
Let E, F be two finite extensions of k, and assume that
Elk is separable, F[k is purely inseparable. Assume E. Fare subfields of a
common field.
Th en
[EF :F] = [E : k] = [EF : k]s'
[EF : E] = [F: k] = [EF : k];.
Proof.
The picture is as follows:
EF
P.y
~
E
F
~k~s,
The proof is a trivial juggling of indices, using the corollaries of Proposition
6.1. We leave it as an exercise.
Corollary 6.10.
Let £P denote the field of all elements x", x E E. Let E
be a finite extension of k. If £Pk = E, then E is separable over k. If E is
separable over k, then £p"k = E for all n ~ 1.
Proof
Let Eo be the maximal separable subfield of E. Assume £Pk = E.
Let E = k(a. 1 , • • • , a.n).
Since E is purely inseparable over Eo there exists m
such that a.r E Eo for each i = I, . . ., n.
Hence Ep
m c Eo.
But er«= E
whence E = Eo is separable over k. Conversely, assume that E is separable
over k. Then E is separable over EPk. Since E is also purely inseparable over
EPk we conclude that E = EPk. Similarly we get E = EP"k for n ~ I , as was
to be shown.
Proposition 6.6 shows that any algebraic extension can be decomposed
into a tower consisting of a maximal separable subextension and a purely
inseparable step above it.
Usually, one cannot reverse the order of the
tower. However, there is an important case when it can be done.
Proposition 6.11.
Let K be normal over k. LetGbe its group ofautomorphisms
over k. Let J<G be the fixed field of G (see Chapter VI, §1). Then KG is purely
inseparable over k, and K is separable over K G. If Ko is the maximal separa-
ble subextension of K, then K = K GKo and Kon K G = k.
Proof
Let a. E K G.
Let r be an embedding of k(a.) over k in K" and
extend r to an embedding of K , which we denote also by t.
Then r is an
automorphism of K because K is normal over k. By definition, ra. = a. and
hence r is the identity on k(a.).
Hence [k(a.): k]s = I and a. is purely in-
separable.
Thus KG is purely inseparable over k. The intersection of Ko

252
ALGEBRAIC EXTENSIONS
V, §6
and KG is both separable and purely inseparable over k, and hence is equal
to k.
To prove that K is separable over K G, assume first that K is finite over
k, and hence that G is finite, by Theorem 4.1. Let a E K. Let CT1, ... , CT, be a
maximal subset of elements of G such that the elements
are distinct, and such that CT) is the identity, and a is a root of the polynomial
,
f(X) = TI (X -
CTia).
i=1
For any rEG we note that r = f because r permutes the roots. We note
that f is separable, and that its coefficients are in the fixed field KG. Hence a
is separable over KG. The reduction of the infinite case to the finite case is
done by observing that every a E K is contained in some finite normal
subextension of K . We leave the details to the reader.
We now have the following picture :
K
K KG
/
° <,
Ko
"'KG
~
~.
Ko nK G = k
By Proposition 6.6, K is purely inseparable over K o, hence purely insepara-
ble over KoKG. Furthermore, K is separable over KG, hence separable over
KoKG. Hence K = KoK G, thereby proving our proposition.
We see that every normal extension decomposes into a compositum of
a purely inseparable and a separable extension. We shall define a Galois ex-
tension in the next chapter to be a normal separable extension. Then K o
is Galois over k and the normal extension is decomposed into a Galois and a
purely inseparable extension. The group G is called the Galois group of the
extension Klk.
A field k is called perfect if kP = k. (Every field of characteristic zero is
also called perfect.)
Corollary 6.12.
If k is perfect, then every algebraic extension of k is
separable, and every algebraic extension of k is perfect.
Proof
Every finite algebraic extension is contained in a normal exten-
sion, and we apply Proposition 6.11 to get what we want.

V, Ex
EXERCISES
1. Let E = Q((X), where (X is a root of the equation
Express ((X2 + (X + 1)((X2 + (X) and ((X - If· in the form
EXERCISES
253
with a, b, CEQ.
2. Let E = F((X) where (X is algebraic over F, of odd degree. Show that E = F((X2).
3. Let (X and Pbe two elements which are algebraic over F. Let f(X) = Irrt«, F, X)
and g(X) = Irr(p, F, X). Suppose that deg f and deg g are relatively prime. Show
that g is irreducible in the polynomial ring F((X) [X].
4. Let
(X be the real positive fourth root of 2. Find all intermediate fields in the
extension Q((X) of Q.
5. If (X is a complex root of X6 + X3 + 1, find all homomorphisms a:Q((X) -+ C.
[Hint :
The polynomial is a factor of X 9 -
1.]
6. Show that j2 + J3 is algebraic over Q, of degree 4.
7. Let E, F be two finite extensions of a field k, contained in a larger field K. Show
that
[EF: k] ~ [E: k] [F :k].
If [E : k] and [F : k] are relatively prime, show that one has an equality sign in
the above relation.
8. Let !(X) E k[X] be a polynomial of degree n. Let K be its splitting field. Show
that [K :k] divides n!
9. Find the splitting field of XP8 -
lover the field ZJpZ.
10. Let (X be a real number such that (X4 = 5.
(a) Show that Q(i(X2) is normal over Q.
(b) Show that Q((X + i(X) is normal over Q(i(X2).
(c) Show that Q((X + i(X) is not normal over Q.
11. Describe the splitting fields of the following polynomials over Q, and find the
degree of each such splitting field.
(a) X 2 -
2
(b) X 2 -
1
(c) X 3 - 2
(d) (X 3 -
2j(X 2 -
2)
(e) X 2 + X + 1
(f) X 6 + X 3 + 1
(g) X 5-7
12. Let K be a finite field with p' elements. Show that every element of K has a
unique p-th root in K .

254
ALGEBRAIC EXTENSIONS
V, Ex
13. If the roots of a monic polynomial f(X) E k[Xj in some splitting field are distinct,
and form a field, then char k = p and f(X) = xr - X for some n ~ 1.
14. Let char K = p. Let L be a finite extension of K, and suppose [L : K] prime to
p. Show that L is separable over K.
15. Suppose char K = p. Let a E K . If a has no p-th root in K, show that Xt" - a is
irreducible in K[X] for all positive integers n.
16. Let char K = p. Let a. be algebraic over K. Show that a. is separable if and only
if K(a.) = K(a. pn) for all positive integers n.
17. Prove that the following two properties are equivalent:
(a) Every algebraic extension of K is separable.
(b) Either char K = 0, or char K = p and every element of K has a p-th root in
K.
18. Show that every element of a finite field can be written as a sum of two squares
in that field.
19. Let E be an algebraic extension of F. Show that every subring of E which
contains F is actually a field. Is this necessarily true if E is not algebraic over F?
Prove or give a counterexample.
20. (a) Let E = F(x) where x is transcendental over F. Let K 'i' F be a subfield of E
which contains F. Show that x is algebraic over K .
(b) Let E = F(x). Let y = f(x) fg(x) be a rational function, with relatively prime
polynomials f, g E F[x].
Let n = max(deg f, deg g). Suppose n ~ 1. Prove
that
[F(x) : F(y)] = n.
21. Let Z+ be the set of positive integers, and A an additive abelian group.
Let
f : Z+ -> A and g: Z+ -> A be maps. Suppose that for all n,
f(n) = L g(d).
dl'
Let J.l be the Mobius function (cf. Exercise 12 of Chapter II). Prove that
g(n) = L J.l(nfd)f(d).
dl'
22. Let k be a finite field with q elements. Let f(X) E k[X] be irreducible. Show that
f(X) divides xqn - X if and only if deg f divides n. Show the multiplication
formula
xr - X = TI TI fAX),
dl' fdirr
where the inner product is over all irreducible polynomials of degree d with
leading coefficient 1. Counting degrees, show that
q' = L d"'(d),
dl'
where "'(d) is the number of irreducible polynomials of degree d.
Invert by

V, Ex
Exercise 21 and find that
m/J(n) = I f1(d)qn1d.
din
EXERCISES
255
for
m -+ 00 .
23. (a) Let k be a finite field with q elements. Define the zeta function
Z(t) = (1 -
tj-I TI (1 -
t deg pf l,
P
where p ranges over all irreducible polynomials p = p(X) in k[X] with leading
coefficient 1. Prove that Z(t) is a rational function and determine this rational
function,
(b) Let 1tq(n) be the number of primes p as in (a) of degree
~ n. Prove that
q
qm
1t (m)- -
- -
q
q -
1 m
Remark.
This is the analogue of the prime number theorem in number theory,
but it is essentially trivial in the present case, because the Riemann hypothesis is
trivially verified. Things get more interesting fast after this case.
Consider an
equation
yZ = x 3 + ax + b over a finite field F, of characteristic *2, 3, and
having q elements. Assume -4a3 - 27bz*0, in which case the curve defined by
this equation is called an elliptic curve. Define N; by
N; - 1 = number of points (x, y) satisfying the above equation with
x, y E Fqn
(the extension of F, of degree n).
Define the zeta function Z(t) to be the unique rational function such that Z(O) = 1
and
A famous theorem of Hasse asserts that Z(t) is a rational function of the form
(1 -
IXt)(1 -
iXt)
Z(t) =
,
(1 - t)(I - qt)
where
IX is an imaginary quadratic number (not real, quadratic over Q), iX is its
complex conjugate, and lXiX = q, so IIXI = q1/2. See Hasse, ..Abstrakte Bergrundung
der
komplexen Multiplikation und
Riemannsche Vermutung in
Funktionen-
korpern," Abh. Math. Sem. Univ. Hamburg 10 (1934) pp. 325-348.
24. Let k be a field of characteristic p and let t, u be algebraically independent over
k. Prove the following :
(a) k(t, u) has degree pZ over kit", uP).
(b) There exist infinitely many extensions between k(t, u) and k(t P, uP).
25. Let E be a finite extension of k and let p' = [E :k]i'
We assume that the
characteristic is p > O. Assume that there is no exponent v' with s < r such that
EP'k is separable over k (i.e., such that IXP' is separable over k for each
IX in E).
Show that E can be generated by one element over k. [Hint:
Assume first that
E is purely inseparable.]

256
ALGEBRAIC EXTENSIONS
V, Ex
26. Let k be a field,f(X) an irreducible polynomial in k[Xj, and let K be a finite normal
extension of k. If g, h are monic irreducible factors of!(X) in K[X], show that there
exists an automorphism a of Kover k such that 9 = h", Give an example when this
conclusion is not valid if K is not normal over k.
27. Let x I' . . . , x, be algebraically independent over a field k. Let y be algebraic over
k(x) = k(x l , • •• , x.). Let P(X.+d be the irreducible polynomial of y over k(x).
Let qJ(x) be the least common multiple of the denominators of the coefficients of
P. Then the coefficients of qJ(x)P are elements of k[x]. Show that the polynomial
!(XI , . .. , X.+l) = qJ(XI , .. . , X.)P(X.+d
is irreducible over k, as a polynomial in n + I variables.
Conversely, let f(XI' . . . , X.+ I ) be an irreducible polynomial over k.
Let
x I ' . • •, x. be algebraically independent over k. Show that
is irreducible over k(x l ' . . . , x.).
If f is a polynomial in n variables, and (b) = (bl , .. . , b.) is an n-tuple of
elements such that f(b) = 0, then we say that (b) is a zero of [. We say that (b) is
non-trivial if not all coordinates b, are equal to O.
28. Let f(XI' •• • , X.) be a homogeneous polynomial of degree 2 (resp. 3) over a field
k. Show that if f has a non-trivial zero in an extension of odd degree (resp.
degree 2) over k, then f has a non-trivial zero in k.
29. Let f(X, Y) be an irreducible polynomial in two variables over a field k. Let t be
transcendental over k, and assume that there exist integers m, n "#0 and elements
a, b E k, ab "#0, such that [tat", bt m ) = O. Show that after inverting possibly X or
Y, and up to a constant factor, f is of type
Xmy' -
C
with some C E k.
The answer to the following exercise is not known.
30. (Artin conjecture).
Let f be a homogeneous polynomial of degree d in n vari-
ables, with rational coefficients. If n > d, show that there exists a root of unity (,
and elements
XI ' .. . , x, E Q[O
not all 0 such that f(x I' .•• , x.) = O.
31. Difference equations.
Let uI , .. . , Ud be elements of a field K . We want to solve
for infinite vectors (xo, xI' .. . , x., ...) satisfying
for
n ~ d.
Define the characteristic polynomial of the system to be

V, Ex
EXERCISES
257
Suppose IX is a root of [.
(a) Show that x, = IX· (n ~ 0) is a solution of (.).
(b) Show that the set of solutions of (.) is a vector space of dimension d.
(c) Assume that the characteristic polynomial has d distinct roots
IXI, •.. , IXd•
Show that the solutions (IXl), . • . , (IX;) form a basis for the space of solutions.
(d) Let x, = b l IXI + ...+ bdIX; for n ~ 0, show how to solve for b., ..., bd in terms
of lXI' .. • , IXd and xo, ..., X d- I • (Use the Vandermonde determinant.)
(e) Under the conditions of (d), let F(T) = ~>.T·.
Show that F(T) represents a
rational function, and give its partial fraction decomposition.
32. Let d = 2 for simplicity. Given ao, aI' u, v, W, t e K, we want to find the solutions
of the system
for
n ~ 2.
Let lXI, IX2 be the roots of the characteristic polynomial, that is
Assume that lXI' IX2 are distinct, and also distinct from t. Let
00
F(X) = L a.X·.
• =0
(a) Show that there exist elements A, B, C of K such that
ABC
F(X) =
+
+--.
l-lXtX
l-IX2X
I-tX
(b) Show that there is a unique solution to the difference equation given by
for
n ~ O.
(To see an application of this formalism to modular forms, as in the work of
Manin, Mazur, and Swinnerton-Dyer, cf. my Introduction to Modular Forms,
Springer-Verlag, New York, 1976, Chapter XII, §2.)
33. Let R be a ring which we assume entire for simplicity. Let
g(T) = Td- ad-ITd- I - ... - ao
be a polynomial in R[T], and consider the equation
Td= ao + a l T + ... + ad-ITd-I.
Let x be a root of g(T).
(a) For any integer n ~ d there is a relation
with coefficients ai•j in Z[ao, ..., ad-I] C R.
(b) Let F(T) e R[T] be a polynomial. Then
F(x) = ao(F) + al (F)x + ... + ad-! (F)Xd-1
where the coefficients aj(F) lie in R and depend linearly on F.

258
ALGEBRAIC EXTENSIONS
(c) Let the Vandermonde determinant be
= n(xj-xJ
i <j
V, Ex
Suppose that the equation g(T) = 0 has d roots and that there is a factoriza-
tion
d
g(T) = n(T - x.).
i=1
Substituting Xj for x with i = I, ... , d and using Cramer's rule on the resulting
system of linear equations, yields
~aiF) =
~j(F)
where ~ is the Vandermonde determinant, and
~j(F) is obtained by replacing
the j-th column by '(F(xtl, ..., F(x d»), so
XI
F(xtl
d-I
XI
X2
F(X2)
d-I
~j(F) =
X2
Xd
F(xd)
d-I
Xd
If ~ i= 0 then we can write
aiF) =
~j(F}/~.
Remark.
If F(T) is a power series in R[[T]J and if R is a complete local ring,
with XI ' . . . , Xd in the maximal ideal, and X = Xj for some i, then we can evaluate
F(x) because the series converges. The above formula for the coefficients aj(F)
remains valid.
34. Let Xl' . . . , X d be independent variables, and let A be the ring
d
Q[[x 1, • •• , Xd]J [T]/n (T - xJ
i=1
Substituting some x, for T induces a natural homomorphism CfJj of A onto
and the map Z I-> (CfJdz), ... , CfJd(Z») gives an embedding of A into the product of R
with itself d times.
Let k be an integer, and consider the formal power series
d (T
) t - »
d
F(T) = ekT n ; ~j e
• = ekT nh(T - xJ
j;l
e
•- 1
j;l
where h(t)=te'/(et-I). It is a formal power series in T, T-x l , ... , T-xd •
Under substitution of some xj for T it becomes a power series in xj and xj - Xj,
and thus converges in Q[[x 1, .. . , xd ] ],

V, Ex
(a) Verify that
EXERCISES
259
d
F(T) == ao(F)+ ... + ad_tlF)Td-1mod TI (T -
Xi)
i= l
where ao(F), ... , ad-tlF)eQ[[x1" " , XdJ], and that the formula given in the
preceding exercise for these coefficients in terms of Vandermonde determi-
nants is valid.
(b) Show that ad-tlF) = 0 if -(d - 1) ~ k < 0 and ad-1(F) = 1 if k = 0,
Remark.
The assertion in (a) is a simple limit. The assertion in (b) is a fact
which has been used in the proof of the Hirzebruch -Grothendieck-Riemann-
Roch theorem and as far as I know there was no simple known proof until Roger
Howe pointed out that it could be done by the formula of the preceding exercise
as follows. We have
V(X1,..., x.)ad-1(F) =
Furthermore,
We use the inductive relation of Vandermonde determinants
V(X1, ···, xd) = V(x1, ... , Xj" '" xd)(_l)d- j TI (Xj - x.) .
• ",j
We expand the determinant for ad-l (F) according to the last column to get
d
1
a _ (F) =
"
e(k+d-1lXj TI
.
d
1
~
x ·
x
j=l
."'je J
- e "
Using the inductive relation backward, and replacing Xi by eX' which we denote
by Yi for typographical reasons, we get
Yd
y: - 2
y~ +d -l
If k of- 0 then two columns on the right are the same, so the determinant is O. If
k = 0 then we get the Vandermonde determinant on the right, so ad - 1(F) = 1.
This proves the desired value.

CHAPTER VI
Galois Theory
This chapter contains the core of Galoi s theory . We study the group of
automorphisms of a finite (and sometimes infinite) Galois extension at length,
and give examples, such as cyclotomic extensions, abelian extensions, and even
non-abelian ones, leading into the study of matrix representations of the Galois
group and their classifications. We shall mention a number of fundamental
unsolved problems, the most notable of which is whether given a finite group
G, there exists a Galois extension of Q having this group as Galois group. Three
surveys give recent points of view on those questions and sizeable bibliographies:
B. MATZAT, Konstruktive Galoistheorie, Springer Lecture Notes 1284, 1987
B. MATZAT , Uberdas Umkehrproblem derGaloisschen Theorie,lahrsbericht Deutsch.
Mat.-Verein. 90 (1988), pp. 155-183
J. P. SERRE, Topics in Galois theory, course at Harvard, 1989 , Jones and Bartlett,
Boston 1992
More specific references will be given in the text at the appropriate moment
concerning this problem and the problem of determining Galois groups over
specific fields, especially the rational numbers.
§1.
GALOIS EXTENSIONS
Let K be a field and let G be a group of automorphisms of K . We denote
by KG the subset of K consisting of all elements x E K such that x" = x for all
(J E G. It is also called the fixed field of G. It is a field because if x, y E KG then
(x + y)a = x" + ya =
X + Y
261
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

262
GALOIS THEORY
VI, §1
for all
(J E G, and similarly, one verifies that K is closed under multiplication,
subtraction, and multiplicative inverse. Furthermore, KG contains 0 and 1,
hence contains the prime field.
An algebraic extension K of a field k is called Galois if it is normal and
separable. We consider K as embedded in an algebraic closure. The group of
automorphisms of Kover k is called the Galois group of Kover k, and is denoted
by G(K/k), GK/b Gal(K/k), or simply G. It coincides with the set of embeddings
of Kin 10 over k.
For the convenience of the reader, we shall now state the main result of the
Galois theory for finite Galois extensions.
Theorem 1.1.
Let K be afinite Galois extension of k, with Galois group G.
There is a bijection between the set ofsubfields E of K containing k, and the
set ofsubgroups H ofG, given by E = K H • Thefield E is Galois overk ifand
only if H is normalin G, andif that is the case, then the map (J H
(J IE induces
an isomorphism ofGIH onto the Galois groupofE overk.
We shall give the proofs step by step, and as far as possible, we give them for
infinite extensions.
Theorem 1.2.
Let K be a Galois extension of k. Let G be its Galois group.
Then k = KG. If F is an intermediate field, k cz F c K, then K is Galois over
F. The map
FH G(KIF)
from the set ofintermediate fields into the set of subgroups of G is injective.
Proof
Let o: E KG. Let
(J be any embedding of k(r:x.) in K", inducing the
identity on k. Extend (J to an embedding of K into K", and call this extension (J
also. Then (J is an automorphism of Kover k, hence is an element of G. By
assumption, (J leaves !X fixed. Therefore
[k(r:x.) :k]s = 1.
Since r:x. is separable over k, we have k(r:x.) = k and r:x. is an element of k. This proves
our first assertion.
Let F be an intermediate field. Then K is normal and separable over F by
Theorem 3.4 and Theorem 4.5 of Chapter V. Hence K is Galois over F. IfH =
G(K/F) then by what we proved above we conclude that F = KH. If F, F' are
intermediate fields, and H = G(K/F), H' = G(K/F'), then
F = KH
and
F' = KH'.
If H = H' we conclude that F = F', whence our map
FH G(KIF)
is injective, thereby proving our theorem.

VI, §1
GALOIS EXTENSIONS
263
We shall sometimes call the gro up G(K/F)of an interm ediate field the group
associated with F. We say that a subgroup H of G belongs to an intermediate
field F if H = G(K/F ).
Corollary 1.3.
Let Klk be Galois with group G. Let F, F' be two inter-
mediatefields, and let H, H' be the subgroups of G belonging to F, P respec-
tively. Then H n H ' belongs to FF'.
Proof
Every element of H n H' leaves FP fixed, and every element of G
which leaves FF' fixed also leaves F and P fixed and hence lies in H n H'.
This proves our assertio n.
Corollary 104.
Let the notation be as in Corollary 1.3. Thefixedfield ofthe
smallest subgroup of G containing H, H' is F n P .
Proof
Obvious.
Corollary 1.5.
Let the notation be as in Corollary 1.3. Then F c P if
and only if H' c H.
Proof
If F c F' and
(J E H' leaves P fixed then (J leaves F fixed, so (J lies
in H. Co nversely, if H' c H then the fixed field of H is contained in the fixed
field of H', so Fe P .
Corollary 1.6.
Let E be a finite separable extension of a field k. Let K be
the smallest normalextension ofk containing E. Then K is finite Galois over
k. There is only afinite numberofintermediatefields F suchthat k cz F c E.
Proof
We know that K is normal and separable, and K is finite over k
since we saw that it is the finite compositum of the finite number of conjugates
of E. The Galois group of K lk has only a finite number of subgroups. Hence
there is only a finite number of subfields of K containing k, whence afortiori a
finite number of subfields of E containing k.
Of course, the last assertion of Corollary 1.6 has been proved in the preceding
chapter, but we get another proof here from another point of view.
Lemma 1.7.
Let E be an algebraic separable extension of k. Assume that
there is an integern ~ I suchthat every element r:x of E is of degree ~ n overk.
Then E is finite over k and [E :k] ~ n.
Proof
Let r:x be an element of E such that the degree [k(r:x): k] is maximal,
say m ~ n. We contend that k(r:x) = E. If this is not true, then there exists an
element fJ E E such that fJ ~ k(r:x), and by the primitive element theorem, there
exists an element y E k(r:x, fJ) such that k(r:x, fJ) = k(y). But from the tower
k c k(r:x) c ki«, fJ)
we see that [k(r:x, fJ) :k] > m whence y has degree> mover k, contradiction.

264
GALOIS THEORY
VI, §1
Theorem 1.8.
(Artin).
Let K be afield and let G be afinite group of auto-
morphisms of K, of order n. Let k = KG be thefixed field. Then K is afinite
Galois extension ofk, and its Galois groupis G. We have[K :k] = n.
Proof
Let IY. E K and let al' . . . , ar be a maximal set of elements of G such
that allY., . .. , a,« are distinct.
If r E G then (tallY., . .. , ro,«) differs from
(allY., . . . , arlY.) by a permutation, because r is injective, and every ta,« is among
the set {allY., . .. , e,«} ; otherwise this set is not maximal. Hence
IY. is a root of
the polynomial
r
f(X) = Il (X -
ajlY.),
j= 1
and for any r E G,f' = f. Hence the coefficients of f lie in KG = k. Further-
more, f is separable. Hence every element
IY. of K is a root of a separable
polynomial of degree
~n with coefficients in k.
Furthermore, this poly-
nomial splits in linear factors in K . Hence K is separable over k, is normal
over k, hence Galois over k. By Lemma 1.7, we have [K :k] ~ n. The Galois
group of Kover k has order ~[K:k] (by Theorem 4.1 of Chapter V), and hence
G must be the full Galois group. This proves all our assertions.
Corollary 1.9.
Let K be afinite Galois extensionof k and let G be its Galois
group.
Then every subgroup of G belongs to some subfield F such that
k c F c K.
Proof
Let H be a subgroup of G and let F = K H• By Artin's theorem we
know that K is Galois over F with group H .
Remark.
When K is an infinite Galois extension of k, then the preceding
corollary is not true any more. This shows that some counting argument
must be used in the proof of the finite case. In the present treatment, we have
used an old-fashioned argument. The reader can look up Artin's own proof in
his book Galois Theory. In the infinite case, one defines the Krull topology on
the Galois group G (cf. exercises 43-45), and G becomes a compact totally
disconnected group. The subgroups which belong to the intermediate fields are
the closed subgroups. The reader may disregard the infinite case entirely through-
out our discussions without impairing understanding. The proofs in the infinite
case are usually identical with those in the finite case.
The notions of a Galois extension and a Galois group are defined completely
algebraically. Hence they behave formally under isomorphisms the way one
expects from objects in any category. We describe this behavior more explicitly
in the present case.
Let K be a Galois extension of k. Let
A:K -> AK

VI, §1
GALOIS EXTENSIONS
265
be an isomorphism. Then AK is a Galois extension of Ak.
K ~AK
I
I
k~Ak
Let G be the Galois group of Kover k. Then the map
gives a homomorphism of G into the Galois group of AK over sk, whose inverse
is given by
A-l or 0 A<-I r.
Hence G(AK/Ak) is isomorphic to G(K/k) under the above map . We may write
G(AK/Ak)A = G(K/k)
or
G(AK/Ak) = AG(K/k)A- 1,
where the exponent Ais " conjugation,"
a )' = A-I
Q a
Q A.
There is no avoiding the contravariance if we wish to preserve the rule
when we compose mappings Aand w.
In particular, let F be an intermediate field, keF c K, and let A:F --+ AF
be an embedding of F in K , which we assume is extended to an automorphism
of K. Then AK = K. Hence
G(K/AF»)' = G(K/F)
and
G(K/AF) = AG(K/F)A- 1•
Theorem 1.10.
Let K be a Galois extension of k with group G. Let F be a
subfield, k cz F c K, and let H = G(K/F). Then F is normal over k if and
onlyifH isnormalin G. IfF is normaloverk, thenthe restrictionmapa I----> aIF

266
GALOIS THEORY
VI, §1
is a homomorphism ofG onto the Galois groupof F over k, whose kernel is H.
We thus have G(Fjk) ::::: GjH.
Proof
Assume F is normal over k, and let G' be its Galois group. The
restriction map (J -> (JIF maps G into G', and by definition, its kernel is H .
Hence H is normal in G. Furthermore, any element rEG' extends to an em-
bedding of K in K', which must be an automorphism of K, so the restriction
map is surjective. This proves the last statement. Finally, assume that F is not
normal over k. Then there exists an embedding Aof F in Kover k which is not
an automorphism, i.e. AF =I F. Extend A to an automorphism of Kover k.
The Galois groups G(KjAF) and G(KjF) are conjugate, and they belong to
distinct subfields, hence cannot be equal. Hence H is not normal in G.
A Galois extension Kjk is said to beabelian (resp.cyclic) ifits Galois group G
is abelian (resp. cyclic).
Corollary 1.11.
Let Kjk be abelian (resp. cyclic). If F is an intermediate
field, keF c K, then F is Galois over k and abelian (resp. cyclic).
Proof
This follows at once from the fact that a subgroup of an abelian
group is normal, and a factor group of an abelian (resp. cyclic) group is abelian
(resp. cyclic) .
Theorem 1.12.
Let K be a Galois extension ofk, let F be an arbitrary exten-
sionandassumethat K, Fare subfields ofsomeotherfield. Then KF is Galois
over F, and K is Galois over K n F. Let H be the GaloisgroupofKF overF,
and G the Galois groupof Kover k. If (J E H then the restriction of (J to K is
in G, and the map
(JI---> (JIK
gives an isomorphism ofH on the Galois groupofKover K n F.
Proof
Let (J E H. The restriction of (J to K is an embedding of Kover k,
whence an element of G since K is normal over k. The map (J I--->(J IK is clearly a
homomorphism. If (JIK is the identity, then (J must be the identity of KF
(since every element of KF can be expressed as a combination of sums, products,
and quotients of elements in K and F). Hence our homomorphism (J I--->(J IK is
injective. Let H' be its image. Then H' leaves K n F fixed, and conversely, if an
element a E K is fixed under H', we see that a is also fixed under H, whence
a E F and a E K n F. Therefore K n F is the fixed field. If K is finite over k,
or even KF finite over F, then by Theorem 1.8, we know that H' is the Galois
group of Kover K n F, and the theorem is proved in that case.
(In the infinite case, one must add the remark that for the Krull topology,
our map a I---> aJ K is continuous, whence its image is closed since H is compact.
See Theorem 14.1; Chapter 1, Theorem 10.1; and Exercise 43.)

VI, §1
GALOIS EXTENSIONS
267
The diagram illustrating Theorem 1.12 is as follows :
KF
/
~F
K~
/
KnF
k
It is suggestive to think of the opposite sides of a parallelogram as being equal.
Corollary 1.13.
Let K beafinite Galois extensionoJk. Let F beanarbitrary
extension ojk. Then [KF :F] divides [K :k].
Proof
Notation being as above, we know that the order of H divides the
order of G, so our assertion follows.
Warning.
The assertion of the corollary is not usually valid if K is not
Galois over k. For instance, let lJ. = J'2 be the real cube root of 2, let ( be a
cube root of 1, ( =t I, say
( = - 1 + )=3
- ---2-0--,
and let {j = Lo: Let E = Q(fj) . Since {j is complex and rx real, we have
Q(fJ) =t Q(lJ.).
Let F = Q(lJ.). Then En F is a subfield of E whose degree over Q divides 3.
Hence this degree is 3 or 1, and must be 1 since E =t F . But
EF = Q(rx, fj) = Q(rx, 0 = Q(rx, )=3).
Hence EF has degree 2 over F.
Theorem 1.14.
Let K 1 and K 2 be Galois extensions oj afield k, with Galois
groups G1 and Gz respectively. Assume K I' K 2 are subfields oj somefield.
Then K lK 2 is Galois over k. Let G be its Galois group. Map G --+ G1 X G2
by restriction, namely
ITH(ITIK 1, ITIK2 ) ·
This map is injective. IfKin K2 = k then the map is an isomorphism.

268
GALOIS THEORY
VI, §1
Proof
Normality and separability are preserved in taking the compositum
of two fields, so K [K 2 is Galois over k. Our map is obviously a homomorphism
of G into GI x G2 • If an element a E G induces the identity on K I and K 2
then it induces the identity on their compositum, so our map is injective. Assume
that Kin K 2 = k. According to Theorem 1.12, given an element alEG I there
exists an element a of the Galois group of K IK 2 over K 2 which induces a1 on
K I • This a is afortiori in G, and induces the identity on K2. Hence GI x {e2}
is contained in the image of our homomorphism (where e2 is the un it element of
G2 ) . Similarly, red x G2 is contained in th is image. Hence their product is
contained in the image, and their product is precisely GI x G2 • This proves
Theorem 1.14.
KIK 2
/
~
K 1
K 2
~
/
K'r
k
Corollary 1.15.
Let K 1, . . . .K; be Galois extensions of k with Galois
groups
G I , .. . , Gn .
Assume
that
K i + I II (K 1 . . . KJ = k
for
each
i = 1, . .. , n -
1. Then the Galois group of K 1 ••• K; is isomorphic to the
product G1 x ... x G; in the natural way.
Proof
Induction.
Corollary 1.16.
Let K be a finite Galois extension of k with group G, and
assume that G can be written as a direct product G = G1 X . . . x Gn • Let
K i be thefixed field of
G[ x .. . x {l} x ... x Gn
wherethe groupwith 1elementoccursin the i-th place. Then K, isGalois over
k, and K i+ I n (K I ••• K j ) = k. Furthermore K = K 1 • • • K n •
Proof
By Corollary 1.3, the compositum of all K i belongs to the intersection
of their corresponding groups, which is clearly the identity. Hence the composi-
tum is equal to K. Each factor of G is normal in G, so K, is Galois over k. By
Corollary lA, the intersection of normal extensions belongs to the product of
their Galois groups, and it is then clear that K s; 1 n (K 1 . . . KJ = k.

VI, §2
EXAMPLES AND APPLICATIONS
269
Theorem 1.17.
Assume allfields contained in some common field.
(i) If K, L areabelian overk, so is the composite KL.
(ii) IfK isabelian overk andEisanyextension ofk, thenKE is abelian overE.
(iii) IfK isabelian overk andK ::> E ::> k where E is anintermediatefield,then
E is abelian overk and K is abelian overE.
Proof
Immediate from Theorems 1.12 and 1.14.
If k is a field, the compositum of all abelian extensions of k in a given alge-
braic closure k" is called the maximum abelian extension of k, and is denoted
by kab.
Remark onnotation.
We have used systematically the notation:
ka == algebraic closure of k;
k
S == separable closure of k;
kab == abelian closure of k == maximal abelian extension.
We have replaced other people's notation k (and mine as well in the first edition)
with k" in order to make the notation functorial with respect to the ideas.
§2.
EXAMPLES AND APPLICATIONS
Let k be a field andf(X) a separable polynomial of degree ~ I in k[Xl Let
f(X) == (X -
(Xl ) .. . (X -
(Xn)
be its factorization in a splitting field Kover k. Let G be the Galois group of K
over k. We call G the Galois group offover k. Then the elements of G permute
the roots off Thus we have an injective homomorphism ofG into the symmetric
group S; on n elements. Not every permutation need be given by an element
of G. We shall discuss examples below.
Example 1.
Quadratic extensions.
Let k be a field and a E k. If a is not
a square in k, then the polynomial X2 -
a has no root in k and is therefore
irreducible. Assume char k '* 2. Then the polynomial is separable (because
2 '* 0), and if 0' is a root, then k(O') is the splitting field, is Galois, and its
Galois group is cyclic of order 2.
Conversely, given an extension K of k of degree 2, there existsa E k such that
K == k(O') and 0'2 == a. This comes from completing the square and the quadratic
formula as in elementary school. The formula is valid as long as the characteristic
of k is '* 2.

270
GALOIS THEORY
VI, §2
Example 2.
Cubic extensions.
Let k be a field of characteristic *" 2 or
3. Let
f(X) = X 3 + aX + b.
Any polynomial of degree 3 can be brought into this form by completing the
cube. Assume thatfhas no root in k. Thenfis irreducible because any factoriza-
tion must have a factor of degree 1. Let a be a root of f(X) . Then
[k(a) : k] = 3.
Let K be the splitting field. Since char k *" 2, 3, f is separable. Let G be the
Galois group. Then G has order 3 or 6 since G is a subgroup of the symmetric
group S3' In the second case, k(a) is not normal over k.
There is an easy way to test whether the Galois group is the full symmetric
group. We consider the discriminant.
If :;(1' a2, a3 are the distinct roots of
f(X), we let
15 = (a l -
(2)(a2 -
:;(3)(a1 -
(3)
and
~ = 152.
If G is the Galois group and a E G then a(15) = ±15. Hence a leaves ~ fixed.
Thus il is in the ground field k, and in Chapter IV, §6, we have seen that
il = -4a3 -
27b2.
The set of a in G which leave (5 fixed is precisely the set of even permutations.
Thus G is the symmetric group if and only if il is not a square in k. We may
summarize the above remarks as follows .
Let f(X) be a cubic polynomial in k[X], and assume char k *" 2, 3. Then:
(a) f is irreducible over k if and only iff has no root in k,
(b) Assume f irreducible. Then the Galois group off is S3 if and only if the
discriminant off is not a square in k. If the discriminant is a square, then
the Galois group is cyclic oforder 3, equal to the alternating group A3 as
a permutation of the roots off.
For instance, consider
f(X) = x 3 -
X + 1
over the rational numbers. Any rational root must be 1 or -1, and so f(X) is
irreducible over Q. The discriminant is - 23, and is not a square. Hence the
Galois group is the symmetricgroup. The splitting field contains a subfield of
degree 2, namely k«(5) = keVil).
On the other hand, letf(X) = X3 - 3X + 1. Thenfhas no root in Z, whence
no root in Q, sof is irreducible. The discriminant is 81, which is a square, so
the Galois group is cyclic of order 3.
Example 3.
We
consider
the
polynomial f(X) = X 4
-
2
over
the
rationals Q. It is irreducible by Eisenstein's criterion. Let a be a real root.

VI, §2
EXAMPLES AND APPLICATIONS
271
Let i == j=l. Then ±a and ±ill. are the four roots of j(X), and
[Q(a) : Q] == 4.
Hence the splitting field ofj(X) is
K == Q(lI., i).
The field Q(lI.) II Q(i) has degree 1or 2 over Q. The degree cannot be 2 otherwise
i E Q(lI.), which is impossible since a is real. Hence the degree is 1. Hence i has
degree 2 over Q(lI.) and therefore [K : Q] == 8. The Galois group ofj(X) has
order 8.
There exists an automorphism, of K leaving Q(lI.) fixed, sending i to - i,
because K is Galois over Q(lI.), of degree 2. Then ,2 == id.
Q(lI., i) == K
y~
Q(lI.)
Q(i)
~/
Q
By the multiplicativity of degrees in towers, we see that the degrees are as
indicated in the diagram. Thus X 4
-
2 is irreducible over Q(i). Also, K is
normal over Q(i). There exists an automorphism o of Kover Q(i) mapping the
root a of X4 -
2 to the root ia. Then one verifies at once that 1, a, cr, a3 are
distinct and rr4 == id. Thus a generates a cyclic group of order 4. We denote it
by <rr). Since, ¢ <rr) it follows that G == <rr, ,) is generated by a and, because
<rr) has index 2. Furthermore, one verifies directly that
because this relation is true when applied to a and i which generate Kover Q.
This gives us the structure of G. It is then easy to verify that the lattice of sub-
groups is as follows :

272
GALOIS THEORY
VI, §2
Example 4.
Let k be a field and let tI' .. . , t, be algebraically independent
over k. Let K = k(t I'
,tn). The symmetric group G on n letters operates on
K by permuting (t I'
, tn) and its fixed field is the field of symmetric functions,
by definition the field of those elements of K fixed under G. Let SI"'" s;be the
elementary symmetric polynomials, and let
n
j(X) = TI(X - tJ
i= I
Up to a sign, the coefficients ofjare SI"'" s. , We let F = KG. We contend
that F = k(sl' . .. ,sn)' Indeed,
k(sl' . . . , sn) c F.
On the other hand, K is the splitting field ofj(X), and its degree over F is n!'
Its degree over k(s I' . . . , sn)is ~ n! and hence we have equality, F = k(sI' .. . ,sn)'
The polynomial j(X) above is called the general polynomial of degree n.
We have just constructed a Galois extension whose Galois group is the sym-
metric group.
Using the Hilbert irreducibility theorem, one can construct a Galois extension
of Q whose Galois group is the symmetric group. (Cf. Chapter VII, end of §2,
and [La 83], Chapter IX.) It is unknown whether given a finite group G, there
exists a Galois extension of Q whose Galois group is G. By specializing para-
meters, Emmy Noether remarked that one could prove this if one knew that every
field E such that
Q(SI " ' " sn) c
E C Q(tl"
' " tn)
is isomorphic to a field generated by n algebraically independent elements.
However, matters are not so simple, because Swan proved that the fixed field
of a cyclic subgroup of the symmetric group is not necessarily generated by
algebraically independent elements over k [Sw 69], [Sw 83].
Example 5.
We shall prove that the complex numbers are algebraically
closed. This will illustrate almost all the theorems we have proved previously.
We use the following properties of the real numbers R: It is an ordered field,
every positive element is a square, and every polynomial of odd degree in R[X]
has a root in R. We shall discuss ordered fields in general later, and our argu-
ments apply to any ordered field having the above properties.
Let i = j=1 (in other words a root of X 2 + 1). Every element in R(i)
has a square root. If a + bi E R(i), a, b e R, then the square root is given by
c + di, where
Each element on the right of our equalities is positive and hence has a square root
in R. It is then trivial to determine the sign of c and d so that (c + di)2 = a + bi.

VI, §2
EXAMPLES AND APPLICATIONS
273
Since R has characteristic 0, every finite extension is separa ble. Every finite
extension of R(i) is contained in an extension K which is finite and Galois over
R. We must show that K = R(i). Let G be the Galois group over R and let H
be a 2-Sylow subgroup of G. Let F be its fixed field. Counting degrees and
orders, we find that the degree of F over R is odd.
By the primitive element
theorem, there exists an element a E F such that F = R(a). Then a is the root of
an irreducible polynomial in R[X] of odd degree. This can happen only if this
degree is I. Hence G = H is a 2-group.
We now see that K is Galois over R(i). Let G1 be its Galois group. Since G1
is a p-group (with p = 2), if G1 is not the trivial group, then G1 has a subgroup
G2 of index 2. Let F be the fixed field of G2 . Then F is of degree 2 over R(i); it
is a quadratic extension. But we saw that every element of R(i) has a square
root, and hence that R(i) has no extensions of degree 2. It follow s that G1 is the
trivial group and K = R(i), which is what we wanted.
(The basic ideas of the above proof were already in Gauss. The variation
of the ideas which we have selected, making a particularly efficient use of the
Sylow group, is due to Artin.)
Example 6.
Let f(X ) be an irreducible polynomial over the field k, and
assume that f is separable. Then the Galois group G of the splitting field is
represented as a group of permutations of the n roots, where n = degf When-
ever one has a criterion for this group to be the full symmetric group Sn, then
one can see if it applies to this representation of G. For example, it is an easy
exercise (cf. Chapter I, Exercise 38) that for p prime, Sp is generated by
[123 . .. p] and any transposition. We then have the following result.
Letf (X) be an irreducible polynomial with rationalcoefficients andofdegree
p prime. If f has precisely two nonreal roots in the complex numbers, then the
Galois group of f is s..
Proof
The order of G is divisible by p, and hence by Sylow's theorem, G
contains an element of order p. Since G is a subgroup of Sp which has order p!,
it follows that an element of order p can be represented by a p-cycle [123 ... p]
after a suitable ordering of the roots, because any smaller cycle has order less
than p, so relatively prime to p. But the pair of complex conjugate roots shows
that complex conjugation induces a transposition in G. Hence the group is all
of Sp .
A specific case is easily given. Drawing the graph of
f (X ) = X 5 -
4X + 2
shows thatfhas exactly three real roots , so exactly two complex conjugate roots.
Furthermorefis irreducible over Q by Eisenstein's criterion, so we can apply
the general statement proved above to conclude that the Galois group of f
over Q is S5' See also Exercise 17 of Chapter IV.

274
GALOIS THEORY
VI, §2
Example 7.
The preceding example determines a Galois group by finding
some subgroups passing to an extension field of the ground field. There are
other possible extensions of Q rather than the reals, for instance p-adic fields
which will be discussed later in this book. However, instead of passing to an
extension field, it is possible to use reduction mod p. For our purposes here, we
assume the following statement, which will be proved in Chapter VII, theorem
2.9.
Let f(X) E Z[X] be a polynomial with integral coefficients, and leading
coefficient 1. Let p be a prime number. Let !(X) = f(X) mod p be the
polynomial obtained by reducing the coefficients mod p. Assume that! has
no multiple roots in an algebraic closure ofFp • Then thereexists a bijection
of the rootsoffonto thoseofJ, andan embedding of the Galois group of!as a
subgroup of the Galois group off, which givesan isomorphism of the action of
thosegroups on the set of roots.
The embedding will be made precise in Chapter VII, but here we just want to
use this result to compute Galois groups .
For instance, consider X 5 - X-lover Z. Reducing mod 5 shows that
this polynomial is irreducible. Reducing mod 2 gives the irreducible factors
(X 2 + X + 1)(X3 + X 2 + 1)
(mod 2).
Hence the Galois group over the rationals contains a 5-cycle and a product of a
2-cycle and a 3-cycle. The third power of the product of the 2-cycle and 3-cycle
is a 2-cycle, which is a transposition. Hence the Galois group contains a trans-
position and the cycle [123451, which generate 85 (cf. the exercises of Chapter I
on the symmetric group). Thus the Galois group of X 5 - X-I is 85.
Example 8.
The technique of reducing mod primes to get lots of elements
in a Galois group was used by Schur to determine the Galois groups of classical
polynomials [Schur 31]. For instance, Schur proves that the Galois group over
Q of the following polynomials over Q is the symmetric group:
n
(a) !(X) = 2: Xm/m! (in other words, the truncated exponential series), if
m=O
n is not divisible by 4. If n is divisible by 4, he gets the alternating group .
(b) Let
Hm(X) = (_l)meX2/ 2 :;m(e-X 2/ 2)
be the m-th Hermite polynomial. Put
H2n(X) = K~O)(X2)
and
H2n +1(X) = XK~1)(X2) .
Then the Galois group of ~j)(X) over Q is the symmetric group Sn for i = 0,
1, provided n > 12. The remaining cases were settled in [Schulz 37].

VI, §2
EXAMPLES AND APPLICATIONS
275
Example 9. This example is addressed to those who know something
about Riemann surfaces and coverings. Let t be transcendental over the com-
plex numbers C, and let k = C(t). The values of tin C, or 00, correspond to the
points of the Gauss sphere S, viewed as a Riemann surface. Let P1>•• • , Pn+1 be
distinct points of S. The finite coverings of S - {PI, .. . , Pn+l } are in bijection
with certain finite extensions of C(t), those which are unramified outside
PI, . . . ,Pn+1• Let K be the union of all these extension fields corresponding to
such coverings, and let n\n) be the fundamental group of
S -
{P1, ... ,Pn+d·
Then it is known that n\n) is a free group on n generators, and has an embedding
in the Galois group of Kover C(t), such that the finite subfields of Kover
C(t) are in bijection with the subgroups of n\nl which are of finite index. Given a
finite group G generated by n elements aI' ... , an we can find a surjective
homomorphism n\nJ -t G mapping the generators of n\n) on aI, . .. , an' Let H
be the kernel. Then H belongs to a subfield K H of K which is normal over C(t)
and whose Galois group is G. In the language of coverings, H belongs to a
finite covering of
Over the field C(t) one can use analytic techniques to determine the Galois
group.
The Galois group is the completion of a free group, as proved by
Douady [Dou 64]. For extensions to characteristicp, see [Pop 95]. A funda-
mental problem is to determine the Galois group over Q(t), which requires
much deeper insight into the number theoretic nature of this field. Basic con-
tributions were made by Belyi [Be 80], [Be 83], who also considered the field
Q(Il)(t), where Q(Il)
is the field obtained by adjoining all roots of unity to the
rationals. Belyi proved that over this latter field, essentially all the classical fi-
nite groups occur as Galois groups. See also Conjecture 14.2 below.
For Galois groups over Q(t), see the survey [Se 88], which contains a
bibliography. One method is called the rigidity method, first applied by Shih
[Shi 74], which I summarize because it gives examples of various notions defined
throughout this book. The problem is to descend extensions of C(t) with a given
Galois group G to extensions ofQ(t) with the same Galois group. Ifthis extension
is Kover Q(t), one also wants the extension to be regular over Q (see the
definition in Chapter VIII, §4). To give a sufficient condition, we need some
definitions. Let G be a finite group with trivial center. Let CI' C2, C3 be conjugacy
classes . Let P = P( CI' C2, C3) be the set of elements
(gl' g2' g3) E CI X C2 X C3
such that glg2g3 = 1. Let P' be the subset of P consisting of all elements
(gl' g2' g3) E P such that G is generated by gl' g2' g3' We say that the family
(CI , C2 , C3) is rigid if G operates transitively on P'; and P' is not empty.

276
GALOIS THEORY
VI, §3
We define a conjugacy class C of G to be rational if given g E C and a
positive integer s relatively prime to the order of g, then gS E C. (Assuming that
the reader knows the terminology of characters defined in Chapter XVIII , this
condition of rationality is equivalent to the condition that every character X of
G has values in the rational numbers Q.) One then has the following theorem,
which is contained in the works of Shih, Fried, Belyi, Matzat and Thompson.
Rigidity theorem.
Let G be a finite group with trivial center, and let
CI> Cz, C3 be conjugacy classes which are rational, and such that the family
(CI> CZ, C3) is rigid. Then there exists a Galois extension ofQ(t) with Galois
group G (and such that the extension is regular over Q).
Bibliography
[Be 80]
[Be 83]
[Dou 64]
[La 83]
[Pop 95]
[Se 88]
[Shi 74]
[Sw 69]
[Sw 83]
G. BELYI, Galois extensions of the maximal cyclotomic field, lzv. Akad.
Nauk SSR 43 (1979) pp. 267-276 (= Math. USSR Izv. 14 (1980) , pp.
247-256
G. BELYI, On extensions of the maximal cyclotomic field having a given
classical Galois group, J. reine angew . Math . 341 (1983) , pp. 147-156
A. DOUADY, Determination d'un groupe de Galois, CR. Acad. Sci. 258
(1964), pp. 5305-5308
S. LANG, Fundamentals ofDiophantine Geometry. Springer Verlag 1983
F. POP, Etale Galois covers of affine smooth curves, Invent. Math. 120
(1995), pp. 555-578
I. -P..
SERRE, Groupes de Galois sur Q, Seminaire Bourbaki, 1987-1988
Asterisque 161-162 , pp. 73-85
R.-Y. SHIH, On the construction of Galois extensions of function fields and
number fields, Math. Ann. 207 (1974) , pp. 99-120
R. SWAN, Invariant rational functions and a problem of Steenrod, Invent .
Math. 7 (1969), pp. 148-158
R. SWAN, Noether's problem in Galois theory, Emmy Noether in Bryn Mawr,
1. D. Sally and B. Srinivasan, eds., Springer Verlag, 1983, pp. 40
§3.
ROOTS OF UNITY
Let k be a field.
By a root of unity (in k) we shall mean an element ' E k
such that '" = I for some integer n ~ 1. If the characteristic of k is p, then the
equation
has only one root, namely 1, and hence there is no prn_th root of unity except 1.

VI, §3
ROOTS OF UNITY
277
Let n be an integer> 1and not divisible by the characteristic. The polynomial
Xn -
1
is separable because its derivative is nX n - 1 =i' 0, and the only root of the deriva-
tive is 0, so there is no common root. Hence in ka the polynomial x n -
1 has n
distinct roots, which are roots of unity. They obviously form a group, and we
know that every finite multiplicative group in a field is cyclic (Chapter IV,
Theorem 1.9). Thus the group of n-th roots of unity is cyclic . A generator for
this group is called a primitive n-th root of unity.
If Jln denotes the group of all n-th roots of unity in k" and m, n are relatively
prime integers, then
Jlmn ::::; Jlm x Jln '
This follows because Jlm' u, cannot have any element in common except 1,
and because JlmJln consequently has mn elements, each of which is an mn-th
root of unity. Hence JlmJln = Jlmn' and the decomposition is that of a direct
product.
As a matter of notation , to avoid double indices, especially in the prime
power case, we write J.L[n] for J.Ln- So if p is a prime, J.L[pr] is the group of
p"-th roots of unity. Then
J.L[p"'] denotes the union of all J.L[pr] for all
positive integers r. See the comments in §14.
Let k be any field. Let n be not divisible by the characteristic p. Let C=
Cn be a primitive n-th root of unity in k", Let 0" be an embedding of k«) in k'
over k. Then
so that a( is an n-th root of unity also. Hence a( = (i for some integer i = i(a),
uniquely determined mod n. It follows that a maps k(O into itself, and hence
that k(O is normal over k. If r is another automorphism of k(O over k then
Since a and rare automorphisms, it follows that i(a) and i(r) are prime to n
(otherwise, a( would have a period smaller than n). In this way we get a homo-
morphism of the Galois group G of k(O over k into the multiplicative group
(ZjnZ)* of integers prime to n, mod n. Our homomorphism is clearly injective
since i(a) is uniquely determined by a mod n, and the effect of a on k«) is
determined by its effect on (. We conclude that k«) is abelian over k.
We know that the order of (ZjnZ)* is cp(n).
Hence the degree [k«) :k]
divides cp(n).
For a specific field k, the question arises whether the image of Gk(O/k in
(Z/nZ) * is all of (Z/nZ) *. Looking at k = R or C, one sees that this is not
always the case. We now give an important example when it is the case.

278
GALOIS THEORY
Theorem 3.1.
Let ( be a primitive n-th root ofunity. Then
[Q(O : Q] = q>(n),
VI, §3
where cp is the Eulerfunction. The map a H
i(cr) gives an isomorphism
GQW 1Q ~ (Z/nZ)*.
Proof.
Let f(X) be the irreducible polynomial of ( over Q. Then f(X)
divides xn - 1,say xn- I = f(X)h(X), where bothf, h have leading coefficient
1. By the Gauss lemma, it follows thatf, h have integral coefficients. We shall
now prove that if p is a prime number not dividing n, then (Pis also a root off
Since (Pis also a primitive n-th root of unity, and since any primitive n-th root of
unity can be obtained by raising ( to a succession of prime powers, with primes
not dividing n, this will imply that all the primitive n-th roots of unity are roots
off, which must therefore have degree
~ q>(n), and hence precisely q>(n).
Suppose (P is not a root off Then (P is a root of h, and ( itself is a root
of h(XP). Hencef(X) divides h(XP), and we can write
h(XP) = f(X)g(X).
Since f has integral coefficients and leading coefficient 1, we see that 9 has
integral coefficients. Since aP== a (mod p) for any integer a, we conclude that
h(XP) == h(X)P
(mod p),
and hence
h(X)P == f(X)g(X)
(mod p).
In particular, if we denote by .fand Ii the polynomials in Z/pZ obtained by
reducing f and h respectively mod p, we see that .f and Ii are not relatively
prime, i.e. have a factor in common. But xn - T= .f(X)n(X), and hence
X" - T has multiple roots. This is impossible, as one sees by taking the de-
rivative, and our theorem is proved.
Corollary 3.2.
If n, m are relative prime integers ~ I, then
Proof
We note that (n and (mare both contained in Q«(mn) since (::'n is a
primitive m-th root of unity. Furthermore, (m(n is a primitive mn-th root of
unity. Hence
Our assertion follows from the multiplicativity q>(mn) = q>(m)q>(n).
Suppose that n is a prime number p (having nothing to do with the character-
istic). Then
XP -
I = (X -
I)(XP-l + ... + I).

VI, §3
ROOTS OF UNITY
279
Any primitive p-th root of unity is a root of the second factor on the right of th is
equa tion. Since there are exactly p -
I primitive p-th roots of unity, we con-
clude that the se root s are precisely the ro ot s of
XP-I + ... + 1.
We saw in Chapter IV, §3 that this polynomial could be transformed into
an Eisenstein polynomial over the rationals. This gives another proof that
[Q«(p) : Q] = p -
1.
We investigate more closely the factorization of X" -
I, and suppose that
we are in characteristic 0 for simplicity.
We ha ve
X" -
1 = n(X -
(),
[
where the product is taken over all n-th roots of unity. Collect together all terms
belonging to roots of unity having the same period. Let
<l>d(X ) =
n
(X -
()
period [= d
Then
We see that <l>1(X) = X-I , and that
xn - 1
n <l>iX)
d in
d<n
From this we can compute <I> (X) recursively , and we see that <l>n(X ) is a polynomial
in Q[X] because we divide recursively by polynomials having coefficients in Q .
All our polynomials have leading coeffi cient 1, so that in fact <l>n(X) has integer
coefficients by Theorem 1.1 of Chapter IV. Thus our construction is essentially
universal and would hold over any field (whose characteristic does not divide
n) .
We call <l>n(X) the n-th cyclotomic polynomial.
The roots of <l>n are precisely the primitive n-th root s of unity, and hence
deg <l>n = cp(n ).
From Theorem 3.J we conclude that <I>n is irreducible over Q , and hence

280
GALOIS THEORY
We leave the proofs of the following recursion formulas as exercises:
1. If p is a prime number, then
<PiX) = Xp-I + xr:: + . .. + I,
and for an integer r ~ 1,
VI, §3
-
V- I
<Ppr(X) -
<Pp(X
).
2. Let n =
p~' ... p~s be a positive integer with its prime factorization. Then
<Pn(X) = <PP 1
· · ·Ps(XP~I-l ...p~ . -I).
3. If n is odd> I, then <PZn(X) = <Pn(- X).
4. If p is a prime number, not dividing n, then
_ <Pn(XP)
<Ppn(X) -
<Pn(X)'
On the other hand, if pin, then <Ppn(X) = <Pn(XP).
5. We have
<Pn(X) = n(X nld -
l)1l(d ).
din
As usual, J1 is the Mobius function:
{
o
if n is divisible by p2 for some prime p,
J1(n) =
(- IY
if n = PI . .. p, is a product of distinct primes,
1
if n = I.
As an exercise, show that
~JL(d) = {I
if n = I,
din
° if n > 1.
Example.
In light of Exercise 21 of Chapter V, we note that the association
n ~ <Pn(X) can be viewed as a function from the positive integers into the
multiplicative group of non-zero rational functions. The multiplication formula
X" -
1 = fl <PiX) can therefore be inverted by the general formalism of
convolutions. Computations of a number of cyclotomic polynomials show that
for low values of n, they have coefficients equal to °or ± I. However, I am
indebted to Keith Conrad for bringing to my attention an extensive literature on
the subject, starting with Bang in 1895. I include only the first and last items:
A. S. BANG, Om Ligningen l1>m(X) = 0, Nyt Tidsskriftfor Matematik (B) 6 (1895),
pp. 6-12
H. L. MONTGOMERY and R. C. VAUGHN , The order of magnitude of the m-th coef-
ficients of cyclotomic polynomials, Glasgow Math. J. 27 (1985), pp. 143-159

VI, §3
ROOTS OF UNITY
281
In particular, if <I>n(X) = '2-anjXj, define L(j) = log max,IanjI. Then Montgomery
and Vaughn prove that
where the sign «
means that the left-hand side is at most a positive constant
times the right-hand side for j ~
00 . Bang also points out that <l>lOS(X) is a
cyclotomic polynomial of smallest degree having coefficients
=1= 0 or ± 1: the
coefficient of X7 and X4 1 is -2 (all others are 0 or ± 1).
If' is an n-th root of unity and '
=1= 1, then
I -
, n
1
r
rn- I
0
-- =
+.,+ ... +.,
= .
1 - ,
This is trivial, but useful.
Let F, be the finite field with q elements, q equal to a power of the odd prime
number p. Then F; has q - 1 elements and is a cyclic group. Hence we have
the index
(F; :F;l) = 2.
If v is a non-zero integer not divisible by p, let
if v == X l
if v =1= X l
(mod p) for some x,
(mod p) for all x.
This is known as the quadratic symbol, and depends only on the residue class
of v mod p.
From our preceding remark, we see that there are as many quadratic residues
as there are non-residues mod p.
Theorem 3.3.
Let ' be a primitive p-th root ofunity, and let
the sum being taken over non-zero residue classes mod p. Then
Every quadratic extension olQ is contained in a cyclotomic extension.
Proof.
The last statement follows at once from the explicit expression of
±pas a square in Q(O, because the square root of an integer is contained in the

282
GALOIS THEORY
VI, §4
field obt ained by adjoining the square root of the prime factors in its factoriza-
tion, and also J=1. Furthermore, for the prime 2, we have (1 + i)2 = 2i. We
now prove our assertion concerning S2. We have
As v ranges over non-zero residue classes, so does Vj1 for any fixed u, and hence
replacing v by Vj1 yields
But 1 + , + ... +,r-)= 0, and the sum on the right over j1 consequently
yields - 1. Hence
S2 = (~)(p - 1) + (- I) L
(~)
p
v* - ) P
= p( pI) - ~ (;)
= p( pI),
as desired.
We see that Q(JP) is contained in Q«(, J=1)or Q(O, depending on the
sign of the quadratic symbol with - 1. An extension of a field is said to be
cyclotomic if it is contained in a field obtained by adjoining roots of unity.
We have shown above that quadratic extensions of Q are cyclotomic. A
theorem of Kronecker asserts that every abelian extension of Q is cyclotomic,
but the proof needs techniques which cannot be covered in this book.
§4.
LINEAR INDEPENDENCE OF
CHARACTERS
Let G be a monoid and K a field. Bya character of G in K (in this chapter),
we shall mean a homomorphism
x.G -> K*
of G into the multiplicative group of K. The trivial character is the homo-

VI, §4
LINEAR INDEPENDENCE OF CHARACTERS
283
morphism taking the constant value I. Functions Ii :G -> K are called linearly
independent over K if whenever we have a relation
with ai E K, then all a, = O.
Examples.
Characters will occur in various contexts in this book. First,
the various conjugate embeddings of an extension field in an algebraic closure
can be viewed as characters. These are the characters which most concern us in
this chapter. Second, we shall meet characters in Chapter XVlll, when we shall
extend the next theorem to a more general kind of character in connection with
group representations.
Next , one meets characters in analysis. For instance, given an integer m, the
functionf : R/Z ~ C* such thatf(x) = e27Timx is a character on R/Z . It can be
shown that all continuous homomorphisms of R/Z into C* are of this type .
Similarly, given a real number y, the function x ~ e27Tixy is a continuous character
on R, and it is shown in Fourier analysis that all continuous characters of absolute
value I on R are of this type .
Further, let X be a compact space and let R be the ring of continuous complex-
valued functions on X. Let R* be the group of units of R . Then given x E X the
evaluation map f ~ f(x) is a character of R* into C* . (Actually, this evaluation
map is a ring homomorphism of R onto C .)
Artin found a neat way of expressing a linear independence property which
covers all these cases, as well as others, in the following theorem [Ar 44].
Theorem 4.1.
(Artin).
Let G be a monoid and K a field. Let Xl" . . , Xn
be distinct characters of G in K. Then they are linearly independent over K.
Proof
One character is obviously linearly independent. Suppose that we
have a relation
alXI + ... + anXn = 0
with ai E K, not all O. Take such a relation with n as small as possible. Then
n ~ 2, and no a, is equal to O. Since XI' Xl are distinct, there exists Z E G such
that XI(Z) i= xiz). For all x E G we have
aIXI(xz) + ... + anXn(xz) = 0,
and since Xi is a character,
aIXI(z)x1 + ... + anxnCz)Xn = O.
Divide by £I(Z) and subtract from our first relation. The term alXI cancels, and
we get a relation
(
£z(z)
)
az-- - az Xz + ... = O.
Xl(Z)

284
GALOIS THEORY
VI, §5
The first coefficient is not 0, and this is a relation of smaller length than our first
relation, contradiction.
As an application of Artin 's theorem, one can consider the case when K is a
finite normal extension of a field k, and when the characters are distinct auto-
morphisms at> .. . , an of Kover k, viewed as homomorphisms of K* into K*.
This special case had already been considered by Dedekind, who, however,
expressed the theorem in a somewhat different way,considering the determinant
constructed from a jwj where w j is a suitable set of elements of K , and proving in
a more complicated way the fact that this determinant is not 0. The formulation
given above and its particularly elegant proof are due to Artin.
As another application, we have :
Corollary 4.2.
Let o:/> ... , «; be distinct non-zero elements ofafield K. If
aI' . . . , an are elements of K such that for all integers v ~°we have
alO:~ + ... + anO:~ = °
then a, = °for all i.
Proof
We apply the theorem to the distinct homomorphisms
of Z ~O into K*.
Another interesting application will be given as an exercise (relative in-
variants).
§5.
THE NORM AND TRACE
Let E be a finite extension of k. Let [E :kJs = r, and let
pI' = [E :kl
if the characteristic is p > 0, and 1 otherwise. Let at, .. . , ar be the distinct
embeddings of E in an algebraic closure ka of k. If 0: is an element of E, we
define its norm from E to k to be
r
(
r
)IE:kI;
NE1k(a) = Nf(o:) = }]tav O:PI' =
}]tav O:
.
Similarly, we define the trace
r
TrE/k(a) = Trf{o:) = [E: k] j L o;«.
v=t
The trace is equal to °if [E: kl > 1, in other words, if Elk is not separable.

VI, §5
Thus if E is separable over k, we have
Nt(a) = TI aa
THE NORM AND TRACE
285
where the product is tak en over the distinct embeddings of E in k" over k.
Similarly, if Elk is separable, then
Trt (a) = L: a«.
(J
Theorem 5.1.
Let Elk be a finite extension. Then the norm Nt is a multi-
plicative homomorphism oj E* into k* and the trace is an additive homo-
morphism oj E into k. IJE ::::l F ::::l k is a towerojfields, then the two mapsare
transitive, in other words,
Nt = N[
0 N:
and
Trt = Tr[ 0 Tr:.
IJ E = k(a), andJ(X) = Irrt«, k, X) = X" + an _IXn - 1+ ... + ao, then
N~ (2 )(a) = (-l)"ao
and
Tr~(2 )(a) = -an-I'
Proof
For the first assertion, we note that aP" is separable over k if
pJl = [E : kJi' On the other hand, the product
,
TI
pI'
(J\.a
v = 1
is left fixed und er any isomorphism into ka because applying such an iso-
morphism simply permutes the factors. Hence this product must lie in k since
aP" is separable over k. A similar reason ing applies to the trace.
For the second assertion, let {IJ be the family of distin ct embeddings of F
into ka over k.
Extend each I j to an automorphism of P , and denote this
exten sion by Ij also. Let {(JJ be the family of embeddings of E in k' over F.
(Without loss of generality, we may assume that E c ka.) If (J is an embedding
of E over k in k", then for some j , Ij-I (J leaves F fixed, and hence I] 1(J = a, for
some i. Hence (J = I j(J j and consequently the family {I j (JJ gives all distinct
embeddings of E into k" over k. Since the inseparability degree is multiplicative
in towers, our assertion concerning the transitivity of the norm and trace is
obvious, because we have already shown that N: maps E into F, and similarly
for the trace.
Suppose now that E = k(a). We have
J (X) = « X -
al ) . . . (X -
a,))[£:k Ji
if a l , • • • , a, are the distinct roots off Looking at the constant term ofJgives us
the expression for the norm , and looking at the next to highest term gives us the
expression for the trace.
We observe that the trace is a k-linear map of E into k, namely
Trf(ca) = c Trf(a)

286
GALOIS THEORY
VI, §5
for all a E E and c E k. This is clear since c is fixed under every embedding of
E over k. Thus the trace is a k-linear functional of E into k. For simplicity,
we write Tr = Trt.
Theorem 5.2.
Let E be afinite separable extension ofk. Then Tr : E -+ k is
a non-zerofunctional. The map
(x, y) H Tr(xy)
ofE x E -+ k is bilinear, and identifiesE with its dual space.
Proof
That Tr is non-zero follows from the theorem on linear indepen-
dence of characters. For each x E E, the map
Trx : E -+ k
such that Trx(Y) = Tr(x y) is obviously a k-linear map, and the map
is a k-homomorphism of E into its dual space E
V
• (We don't write E* for the
dual space because we use the star to denote the multiplicative group of E.)
If Trx is the zero map, then Tr(xE) = O.
If x i: 0 then xE = E. Hence the
kernel of x H Trx is O. Hence we get an injective homomorphism of E into
the dual space E
V
• Since these spaces have the same finite dimension, it follows
that we get an isomorphism. This proves our theorem.
Corollary 5.3.
Let co1> . . . , co" be a basis of E over k. Then there exists a
basis co'1> . . . , co~ ofE over k such that Tr(wicoj) = bij'
Proof
The basis CO't, ..• ,
co~ is none other than the dual basis which we
defined when we considered the dual space of an arbitrary vector space.
Corollary 5.4.
Let E be afinite separable extension of k, and let (J' I' .. . , (J'"
be the distinct embeddings ofE into k a overk. Let WI , ... , Wn be elementsof
E. Then the vectors
are linearlyindependent over E ijw l , . .. , wnform a basisofE over k.
Proof
Assume that WI' .. • , W" form a basis of Elk. Let (XI' • •. , (X" be ele-
ments of E such that
Then we see that

VI, §5
THE NORM AND TRACE
287
applied to eac h one of WI "
' "
~\'n gives the value 0. But (1 1"
' "
(In are linearl y
independent as cha racters of the multiplicati ve group E* into k:", It follows that
a, =°for i = I, . . . , n, and our vectors are linearl y independent.
Remark.
In characteristic 0, one sees much more trivially that the trace is
not identica lly 0. Indeed, if e E k and e "# 0, then Tr(e) = ne where n = [E: kJ,
and n "# 0. This argument also hold s in characteristic p when n is prime to p.
Proposition 5.5.
Let E = k(lX) be a separable extension. Let
f(X) = Irrt«, k, X) ,
and letf'(X) be its derivative. Let
f(X)
P.
R X
R
X"" I
(X _ IX) = P O + P I
+ ... + Pn - I
with ~i E E. Then the dual basis of 1, (I., ••• , IXn- I is
flo
fln - I
f'(a) , . .. , f'(a)'
Proof
Let lX I' • • • , IXn be the distinct roots off
Th en
for °~ r ~ n -
1.
f(X)
C(~
(X -
IX;) f'(lX;)
To see this, let g(X) be the difference of the left- and right-hand side of this
equa lity. Then g has degree ~ n - 1, and has n roots lX I' • • • , IXn' Hence g is
identically zero.
The polynomials
are all conjugate to each other. If we define the tr ace of a polynomial with
coefficients in E to be the polynomial obtained by applying the trace to the
coefficients, then
[
f( X)
(l.r ]
Tr (X _
IX) f'(IX)
= X',
Looking at the coefficients of each power of X in this equation, we see that
(
i J!.L) _
Tr
IX f'(lX)
- bij ,
thereby proving our proposition.
Finall y we establish a connection with determinants, whose basic properties
we now assume. Let E be a finite extension of k, which we view as a finite
dimensional vector space over k. For each
Q' E E we have the k-linear map

288
GALOIS THEORY
multiplication by a,
VI, §6
ma: E -
E
such that
ma(x) = ax.
Then we have the determinant det(ma ) , which can be computed as the determinant
of the matrix Ma representing ma with respect to a basis. Similarly we have the
trace Tr(ma), which is the sum of the diagonal elements of the matrix Ma.
Proposition 5.6.
Let E be a finite extension of k and let a E E. Then
det(ma ) = NE1k(a)
and
Tr(ma) = TrE/k(a).
Proof.
Let F = k(a) . If [F : k] = d, then 1, a, . . . , ad-I is a basis
for F over k. Let {wJo " "
wr } be a basis for E over F.
Then {aiwj}
(i = 0, . . . , d -
I; j = 1, ... , r) is a basis for E over k. Let
f(X) = Xd + ad_IXd-1 + . . . + ao
be the irreducible polynomial of a over k. Then Nm(a) = (-1 )dao, and by the
transitivity of the norm, we have
NE1k(a) = Nm(aY.
The reader can verify directly on the above basis that NF/k(a) is the determinant
ofmrx on F , and then that NF/k(a)' is the determinant ofmrx on E, thus conclud-
ing the proof for the determinant. The trace is handled exactly in the same way,
except that TrElk(a) = r : TrFlk(a) . The trace of the matrix for ma on F is equal
to -ad-I ' From this the statement identifying the two traces is immediate, as it
was for the norm.
§6.
CYCLIC EXTENSIONS
We recall that a finite extension is said to be cyclic if it is Galois and its
Galois group is cyclic. The determination of cyclic extensions when enough roots
of unity are in the ground field is based on the following fact.
Theorem 6.1.
(Hilbert's Theorem 90).
Let Klk be cyclic of degree n
with Galois group G. Let a be a generator of G. Let PE K.
The norm
Nf(f3) = N(f3) is equal to I if and only if there exists an element a ::f:. 0 in K
such that p = «[a«.
Proof
Assume such an element a exists. Taking the norm of Pwe get
N(a)/N(ua). But the norm isthe product over all automorphisms in G. Inserting
a just permutes these automorphisms. Hence the norm is equal to 1.
It will be convenient to use an exponential notation as follows. If r, r' E G
and
~ E K we write

VI, §6
CYCLIC EXTENSIONS
289
By Artin's theorem on characters, the map given by
on K is not identically zero. Hence there exists () E K such that the element
is not equal to O. It is then clear that fJa(f = a using the fact that N(fJ) = 1,and
hence that when we apply fJa to the last term in the sum, we obtain e. We divide
by a(f to conclude the proof.
Theorem 6.2.
Let k be a field, n an integer > 0 prime to the characteristic
ofk (if not 0), and assume that there is a primitive n-th root ofunity in k.
(i) Let K bea cyclic extensionofdegree n. Then there exists a E K such that
K = k(a), and a satisfiesan equation X" - a = 0for some a E k.
(ii) Conversely, let a E k. Let a be a root ofX" - a. Then k(a) is cyclicover
k, ofdegree d, din, and ad is an elementofk.
Proof
Let ( be a primitive n-th root of unity in k, and let Klk be cyclic with
groupG. Let abe a generator ofG. We have N(C 1) = (C1)n = 1. By Hilbert's
theorem 90, there exists a E K such that a« = (a. Since ( is in k, we have
o'« = (ia for i = 1, . .. , n. Hence the elements (ia are n distinct conjugates of a
over k, whence [k(a): k] is at least equal to n. Since [K : k] = n, it follows that
K = k(a). Furthermore,
a(an) = a(at = ((at = an.
Hence an is fixed under a, hence is fixed under each power of a, hence is fixed
under G. Therefore an is an element of k, and we let a = an. This proves the
first part of the theorem.
Conversely, let a E k. Let a be a root of X" - a. Then a(i is also a root for
each i = 1, . .. , n, and hence all roots lie in k(a) which is therefore normal over
k. All the roots are distinct so k(a) is Galois over k. Let G be the Galois group.
If a is an automorphism of k(a)/k then aa is also a root of x n -
a. Hence
ao: = co;« where co; is an n-th root of unity, not necessarily primitive. The map
a ~ co; is obviously a homomorphism of G into the group of n-th roots of unity,
and is injective. Since a subgroup of a cyclic group is cyclic, we conclude that
G is cyclic, of order d, and din. The image of G is a cyclic group of order d.
If (T is a generator of G, then WIT is a primitive dth root of unity . Now we get
Hence ad is fixed under a, and therefore fixed under G. It is an element of k, and
our theorem is proved.

290
GALOIS THEORY
VI, §6
We now pass to the analogue of Hilbert's theorem 90 in characteristic p for
cyclic extensions of degree p.
Theorem 6.3.
(Hilbert's Theorem 90, Additive Form).
Let k be afield and
K lk a cyclic extension of degree n with group G. Let 0 be a generator of G.
Let fJ E K . The trace TrNfJ) is equal to 0 ifand only if there exists an element
IX E K such that fJ =
IX -
ao:
Proof
If such an element IX exists, then we see that the trace is 0 because
the trace is equal to the sum taken over all elements of G, and applying a per-
mutes these elements.
Conversely, assume Tr(fJ) = O. There exists an element 0 E K such that
Tr(e) =/:. O. Let
From this it follows at once that fJ = IX -
a«.
Theorem 6.4.
(Artin-Schreier)
Let k he afield ofcharacteristic p.
(i) Let K be a cyclic extensionof k of degreep. Then there exists IX E K such
that K = k(lX) and IX satisfies an equation XP - X - a = 0 with some
a E k.
(ii) Conversely, given a E k, the polynomialf (X ) = XP -
X - a either has
one root in k, in which case all its roots are in k, or it is irreducible. In
this latter case,if IX is a root then k(lX) is cyclic ofdegree p over k.
Proof
Let Klk be cyclic of degree p. Then Tr:( -1) = 0 (it is just the sum
of - 1 with itself p times). Let a be a generator of the Galois group. By the
additive form of Hilbert's theorem 90, there exists IX E K such that a« -
IX = 1,
or in other words, a« =
IX + 1. Hence o'« =
IX + i for all integers i = 1, .. . , p
and IX has p distinct conjugates. Hence [k(lX) : k] ~ p. It follows that K = k(IX).
We note that
a(IXP-
IX) = a(lX)p -
a(lX) = (IX + 1)P -
(IX + 1) =
IXP -
IX.
Hence IXP -
IX is fixed under a, hence it is fixed under the powers of a, and
therefore under G. It lies in the fixed field k. If we let a =
IXP -
IX we see that
our first assertion is proved.
Conversely, let a E k. If IX is a root of XP -
X - a then
IX + i is also a
root for i = 1, ... ,p. Thus f(X) has p distinct roots. If one root lies in k
then all roots lie in k. Assume that no root lies in k. We contend that the

VI, §7
SOLVABLE AND RADICAL EXTENSIONS
291
pol ynomial is irreducible. Suppose that
f(X) = g(X)h(X)
with g, hE k[X] and 1 ~ deg 9 < p. Since
p
f(X) = n(X - a -
i)
i = 1
we see that g(X) is a product over certain integers i. Let d = deg g. The co-
efficient of Xd- 1 in 9 is a sum of terms - (ex + i) taken over precisely d integers
i , Hence it is equal to -dex + j for some integer j. But d
=1= 0 in k, and hence
ex lies in k, because the coefficients of9 lie in k, contradiction. We know therefore
that j'(X) is irreducible. All roots lie in k(ex) , which is therefore normal over k.
Since f(X) ha s no multiple roots, it follows that k(rJ.) is Galois over k. There
exists an automorphism a of k(rJ.) over k such that aa =
rJ. + 1 (because rJ. + 1
is also a root). Hence the powers o' of a give o'« = rJ. + i for i = 1,. . . , p and
are distinct.
Hence the Galois group consists of these powers and is cyclic,
thereby proving the theorem.
For cyclic extensions of degree p", see the exercises on Witt vectors and the
bibliography at the end of §8.
§7.
SOLVABLE AND RADICAL EXTENSIONS
A finite extension Elk (which we shall assume separable for convenience) is
said to be solvable if the Galois group of the smallest Galois extension K of k
containing E is a solvable group. This is equivalent to saying that there exists a
solvable Galois extension L of k such that k c EeL.
Indeed, we have
k c E eKe Land G(Klk) is a homomorphic image of G(Llk).
Proposition 7.1.
Solvableextensionsform a distinguished class ofextensions.
Proof
Let Elk be solvable. Let F be a field containing k and assume E, F
are subfields of some algebraically closed field. Let K be Galois solvable over k,
and E c K. Then KF is Galois over F and G(KFIF) is a subgroup of G(Klk)
by Theorem 1.12. Hence EFIF is solvable. It is clear that a subextension of a
solvable extension is solvable. Let E => F => k be a tower, and assume that Ell'
is solvable and FIk is solvable. Let K be a finite solvable Galois extension of k
containing F. We just saw that EK IK is solvable. Let L be a solvable Galois
extension of K containing EK . If o is any embedding of Lover k in a given
algebraic closure, then aK = K and hence al. is a solvable extension of K. We
let M be the compositum of all extensions al: for all embeddings a of Lover k.

292
GALOIS THEORY
VI, §7
Then M is Galois over k, and is therefore Galois over K. The Galois group of
Mover K is a subgroup of the product
fl G(aLIK)
by Theorem 1.14. Hence it is solvable. We have a surjective homomorphism
G(Mlk) -+ G(Klk) by Theorem 1.10. Hence the Galois group of Mlk has a
solvable normal subgroup whose factor group is solvable.
It is therefore
solvable. Since E c M, our proof is complete.
EK
/1
I/K
F
1
k
A finite extension F of k is said to be solvable byradicals if it is separable and
if there exists a finite extension E of k containing F, and admitting a tower
decomposition
k = Eo C E1 C E2 C
.. . C Em = E
such that each step Ej+ tlEj is one of the following types:
1. It is obtained by adjoining a root of unity.
2. It is obtained by adjoining a root of a polynomial X" - a with a E E, and
n prime to the characteristic.
3. It is obtained by adjoining a root of an equation XP - X -
a with
a E E, if p is the characteristic > O.
One can see at once that the class of extensions which are solvable by
radicals is a distinguished class.
Theorem 7.2.
Let E be a separable extension of k. Then E is solvable by
radicals ifand only if Elk is solvable.
Proof
Assume that Elk is solvable, and let K be a finite solvable Galois
extension of k containing E. Let m be the product of all primes unequal to the
characteristic dividing the degree [K : k] , and let F = k(() where' is a primitive
m-th root of unity. Then Flk is abelian. We lift Kover F. Then KF is solvable
over F. There is a tower of subfields between F and KF such that each step is
cyclic of prime order, because every solvable group admits a tower of sub-

VI, §8
ABELIAN KUMMER THEORY
293
groups of the same type, and we can use Theorem 1.10. By Theorems 6.2 and
6.4, we conclude that KF is solvable by radicals over F, and hence is solvable
by radicals over k. This proves that Elk is solvable by radicals.
Conversely, assume that Elk is solvable by radicals. For any embedding a
of E in Ea over k, the extension aElk is also solvable by radicals. Hence the
smallest Galois extension K of E containing k, which is a composite of E and
its conjugates is solvable by radicals. Let mbe the product of all primes unequal
to the characteristic dividing the degree [K : k] and again let F = k(O where'
is a primitive m-th root of unity. It will sufficeto prove that KF is solvable over
F,because it follows then that KF issolvable over k and hence G(Klk) is solvable
because it is a homomorphic image of G(KFlk). But KFIF can be decomposed
into a tower of extensions, such that each step is of prime degree and of the type
described in Theorem 6.2 or Theorem 6.4, and the corresponding root of unity
is in the field F. Hence KFIF is solvable, and our theorem is proved.
Remark.
One could modify our preceding discussion by not assuming
separability. Then one must deal with normal extensions instead of Galois
extensions, and one must allow equations XP - a in the solvability by radicals,
with pequal to the characteristic. Then we still have the theorem corresponding
to Theorem 7.2. The proof is clear in view of Chapter V, §6.
For a proof that every solvable group is a Galois group over the rationals, I
refer to Shafarevich [Sh 54], as well as contributions of Iwasawa [lw 53] .
[Iw 53]
K. IWAsAwA, On solvable extension of algebraic number fields, Ann. ofMath.
58 (1953), pp. 548-572
[Sh 54]
I. SHAFAREVICH, Construction of fields of algebraic numbers with given solvable
Galois group, lzv . Akad. Nauk SSSR 18 (1954), pp. 525-578 (Amer. Math.
Soc. Transl. 4 (1956), pp. 185-237)
§8.
ABELIAN KUMMER THEORY
In this section we shall carry out a generalization of the theorem concerning
cyclic extensions when the ground field contains enough roots of unity.
Let k be a field and m a positive integer. A Galois extension K of k with
group G is said to be of exponent m if am = I for all a E G.

294
GALOIS THEORY
VI, §8
We shall investigate abelian extensions of exponent m. We first assume
that m is not a multiple of the characteristic of k (if not 0), and that k contains
the group of m-th roots of unity which we denote by Jim' We assume that all
our algebraic extensions in this section are contained in a fixed algebraic closure
k ",
Let a E k. The symbol a' !" (or .,ia) is not well defined. If rxm = a and ( is
an m-th root of unity, then ((rxr = a also. We shall use the symbol a'!" to
denote any such element rx, which will be called an m-th root of a. Since the
roots of unity are in the ground field, we observe that the field k(rx) is the same
no matter which m-th root rx of a we select. We denote this field by k(a1/m).
We denote by k*m the subgroup of k* consisting of all m-th powers of non-
zero elements of k. It is the image of k* under the homomorphism x 1-+ x",
Let B be a subgroup of k* containing k*m. We denote by k(B 1/m) or K B the
composite of all fields k(a1/m) with a E B. It is uniquely determined by B as a
subfield of k'.
Let a E B and let a be an m-th root of a. The polynomial X" - a splits into
linear factors in K B , and thus K B is Galois over k, because this holds for all
a E B. Let G be the Galois group. Let a E G. Then a« = wlIrx for some m-th
root of unity WlI E Jim C k*. The map
is obviously a homomorphism of G into Pm' i.e. for r, a E G we have
We may write W lI = aal«. This root of unity co; is independent of the choice
of m-th root of a, for if (x ' is another m-th root, then (I.' = ((I. for some (E Pm'
whence
arx'/(I.' = (arxj(rx = aa]«.
We denote WlI by <a, a). The map
(a, a) 1-+ <a, a)
gives us a map
G x B --+ Pm'
If a, b e Band rxm = a, pm = b then (rxp)m = ab and
a(rxp)/(l.p = (arx/rx)(aP/p).
We conclude that the map above is bilinear. Furthermore, if a E k*m it follows
that <a, a) = 1.
Theorem 8.1.
Let k be afield, m an integer>°prime to the characteristic of
k (ifnot 0). We assume that k contains Pm' Let B be a subgroup ofk" con-
taining k'!" and let KB = k(B1jm). Then KB is Galois, and abelian of expo-
nent m. Let G be its Galois group. We have a bilinear map
G x B --+ Pm
given by
(a, a) 1-+ <a, a).

VI, §8
ABELIAN KUMMER THEORY
295
If(J E G and a E B, and am = a then <(J, a) = (JlI./lI.. The kernel on the left is I
and the kernel on the right is k*m. The extension K B/k isfinite if and only if
(B : k*m) is finite. If that is the case, then
B/k*m = GA,
and in particular we have the equality
Proof
Let (J E G. Suppose <(J, a) = I for all a E B. Then for every gener-
ator a of KBsuch that am = a E B we have (Ja = a. Hence (J induces the identity
on KBand the kernel on the left is 1. Let a E B and suppose <(J, a) = I for all
(J E G. Consider the subfield k(a l /rn) of K B. If a l /mis not in k, there exists an
automorphism of k(a l /m) over k which is not the identity. Extend this auto-
morphism to K B, and call this extension (J.
Then clearly <(J, a) i= 1. This
proves our contention.
By the duality theorem of Chapter 1, §9 we see that G is finite if and only
if B/ k*m is finite, and in that case we have the isomorphism as stated, so that
in particular the order of G is equal to (B : k*m), thereby proving the theorem.
Theorem 8.2.
Notation being as in Theorem 8.1, the map B H KBgives a
bijectionofthe set ofsubgroupsofk* containing k*rn and the abelianextensions
ofk ofexponent m.
Proof
Let B I , B2 be subgroups of k* containing k*rn. If B I
C B2 then
k(Bl /m) C k(B1/m).
Conversely, assume that k(Bl /m) c k(Byrn). We wish to
prove BI c B2 • Let bE B I • Then k(b l /rn) c k(Bym) and k(b l /m) is contained in
a finitely generated subextension of k(B1/rn). Thus we may assume without loss
of generality that B1/k*m is finitely generated, hence finite. Let B3 be the sub-
group of k* generated by B2 and b. Then k(B1/m) =
k(B~ /rn) and from what we
saw above, the degree of this field over k is precisely
(B 2 : k*rn)
or
(B 3 : k*m).
Thus these two indices are equal, and B2 = B3 ' This proves that B I c B2 .
We now have obtained an injection of our set of groups B into the set of
abelian extensions of k of exponent m. Assume finally that K is an abelian
extension of k of exponent m. Any finite subextension is a composite of cyclic
extensions of exponent m because any finite abelian group is a product of
cyclic groups, and we can apply Corollary 1.16. By Theorem 6.2, every cyclic
extension can be obtained by adjoining an m-th root. Hence K can be obtained
by adjoining a family of m-th roots, say m-th roots of elements {bj}jEJ with
b, E k*. Let B be the subgroup of k* generated by all b, and k:". If b' = bam
with a, bE k then obviously
Hence k(B I /m) = K, as desired.

296
GALOIS THEORY
VI, §8
When we deal with abelian extensions of exponent p equal to the char-
acteristic, then we have to develop an additive theory, which bears the same
relationship to Theorems 8.1 and 8.2 as Theorem 6.4 bears to Theorem 6.2.
If k is a field, we define the operator tJ by
tJ(x) = xP -
x
for x E k. Then tJ is an additive homomorphism of k into itself. The subgroup
tJ(k) plays the same role as the subgroup k*m in the multiplicative theory,
whenever m is a prime number. The theory concerning a power of p is slightly
more elaborate and is due to Witt.
We now assume k has characteristic p. A root of the polynomial XP - X - a
with a E k will be denoted by tJ - la. If B is a subgroup of k containing tJk
we let K B = k(tJ - IB) be the field obtained by adjoining tJ - Ia to k for all a E B.
We emphasize the fact that B is an additive subgroup of k.
Theorem 8.3.
Let k be a field of characteristic p. The map B H k(tJ - I B)
is a bijectionbetweensubgroups ofk containing tJk and abelian extensions of
k of exponent p. Let K = K B = k(tJ - I B), and let G be its Galois group.
If a E Ganda E B, and tJCt.. = a, let <a, a) = a« - a. Then wehavea bilinear
map
G x B -+ Z/pZ
given by
(a, a) -+ <a, a) .
The kernel on the left is 1 and the kernel on the right is tJk. The extension
KB/k is finite if and only if (B: tJk) is finite and if that is the case, then
[K B : k] = (B : tJk).
Proof.
The proof is entirely similar to the proof of Theorems 8.1 and 8.2.
It can be obtained by replacing multiplication by addition, and using the " tJ-th
root" instead of an m-th root. Otherwise, there is no change in the wording of
the proof.
The analogous theorem for abelian extensions of exponent p" requires
Witt vectors, and will be developed in the exercises.
Bibliography
[Wi 35]
E. WITI, Der Existenzsatz fur abelsche Funktionenkorper, J. reine angew.
Math . 173 (1935), pp. 43-51
[Wi 36]
E. WITT, Konstruktion von galoisschen Korpern der Charakteristik p mit
vorgegebener Gruppe der Ordung pi, J. reine angew. Math. 174 (1936), pp.
237-245
[Wi 37]
E. WITT, Zyklische Kerper und Aigebren der Charakteristik p vom Grad p" ,
Struktur diskret bewerteter perfekter Korper mit vollkommenem Restklas-
senkorper der Charakteristik p, J. reine angew. Math. 176 (1937), pp. 126-
140

VI, §9
§9.
THE EQUATION Xn -
B = 0
THE EQUATION Xn - a = 0
297
When the roots of unity are not in the ground field, the equation X" - a = 0
is still interesting but a little more subtle to treat.
Theorem9.1.
Let k beafield andnan integer ~ 2. Let a E k, a "# O. Assume
that for all prime numbers p such that pin we have a ¢ kP, and if 41 n then
a ¢ -4e. Then X" - a is irreducible in k[X].
Proof
Our first assumption means that a is not a p-th power in k. We
shall reduce our theorem to the case when n is a prime power, by induction.
Write n = prm with p prime to m, and p odd. Let
m
X" - a = fl (X -
IXv)
v= 1
be the factorization of xm - a into linear factors, and say IX =
1X1• Substituting
Xp
r for X we get
m
X" - a = xr» - a = fl (XP
r
-
IXv) '
v e 1
We may assume inductively that X" - a is irreducible in k[X]. We contend
that IX is not a p-th power in k(IX). Otherwise, IX = pP, fJ Ek(IX). Let N be the
norm from k(lX) to k. Then
If m is odd, a is a p-th power, which is impossible. Similarly, if m is even and p
is odd, we also get a contradiction. This proves our contention, because m is
prime to p. If we know our theorem for prime powers, then we conclude that
xr -
IX is irreducible over k(IX). If A is a root of Xp
r
-
IX then k c k(lX) c k(A)
gives a tower, of which the bottom step has degree m and the top step has degree
pro It follows that A has degree n over k and hence that X" - a is irreducible.
We now suppose that n = pris a prime power.
If p is the characteristic, let IX be a p-th root of a. Then XP - a = (X -
IX)P
and hence Xr" -
a = (XP
r
- I
-
IX)P if r ~ 2. By an argument even more trivial
than before, we see that a is not a p-th power in k(a), hence inductively
xP
r
-
1
-
a is irreducible over k(a) . HencexP
r
-
a is irreducible over k,
.
Suppose that p is not the characteristic. We work inductively again, and
let IX be a root of XP - a.
Suppose a is not a p-th power in k. We claim that XP -
a is irreducible.
Otherwise a root a of XP -
a generates an extension k(a) of degree d < P
and aP = a. Taking the norm from k(a) to k we get N(a)P = ad. Since d is
prime to p, it follows that a is a p-th power in k, contradiction.

298
GALOIS THEORY
Let r ~ 2. We let ':I. =
':1. 1, We have
P
X P- a = n(X - av)
,.=1
and
p
)(P' -
a = fI co:' - ex,,).
"=1
VI, §9
Assume that a is not a p-th power in k(rx). Let A be a root of xr:
I
-
a. If p
is odd then by induction, A has degree p' - lover k(rx), hence has degree p' over
k and we are done. If p = 2, suppose o: = -4134 with 13 E k(rx). Let N be the
norm from k(ex) to k. Then r:a = N(ex) = 16N(f3)4, so -a is a square in k. Since
p = 2 we get v=I E k( ex) and ex = (v=I 2(32)2, a contradiction. Hence again
by induction, we find that A has degree p' over k. We therefore assume that
ex = f3P with some (3 E k(ex) , and derive the consequences.
Taking the norm from k(rx) to k we find
-a = (-I)PN(rx) = (-I)PN(f3P) = (-I)PN{fW.
If p is odd, then a is a p-th power in k, contradiction. Hence p = 2, and
is a square in k. Write - a = b2 with be k. Since a is not a square in k we con-
clude that - 1is not a square in k. Let i 2 = - I. Over k{i) we have the factoriza-
tion
Each factor is of degree 2'- I and we argue inductively. If X 2' - I ± ib is reducible
over k(i) then ±ib is a square in k{i) or lies in - 4(k{i)4. In either case, ±ib is a
square in k{i), say
±ib = (e + di)2 = c2 + 2edi - d2
with c, d e k. We conclude that e2 = d2 or e = ±d, and ±ib = 2edi = ±2c2i.
Squaring gives a contradiction, namely
We now conclude by unique factorization that X 2' + b2 cannot factor in
k[X], thereby proving our theorem.
The conditions of our theorem are necessary because
If n = 4m and a E -4e then X" - a is reducible.

VI, §9
THE EQUATION Xn - a = 0
299
Corollary 9.2. Let k be a field and assume that a E k, a =1= 0, and that a is not
a p-th powerfor some primep. If p is equal to the characteristic, or if p is odd,
thenfor every integer r ~ 1the polynomial XP' - a is irreducible over k.
Proof
The assertion is logically weaker than the assertion of the theorem.
Corollary 9.3.
Let k be afield and assume that the algebraic closure k: ofk
is of finite degree > lover k. Then k
3 = k(i) where i 2 = -1 , and k has
characteristic 0.
Proof.
We note that J(i is normal over k. If J(i is not separable over k, so
char k = p > 0, then J(i is purely inseparable over some subfield of degree>
I (by Chapter V, §6), and hence there is a subfield E containing k, and an element
a E E such that XP - a is irreducible over E. By Corollary 9.2, J(i cannot be of
finite degree over E. (The reader may restrict his or her attention to characteristic
°if Chapter V, §6 was omitted.)
We may therefore assume that k
3 is Galois over k. Let k, = k(i). Then k
3
is also Galois over k 1• Let G be the Galois group of k
3/k 1• Suppose that there
is a prime number p dividing the order of G, and let H be a subgroup of order p.
Let F be its fixed field. Then [k
3
: F] = p. If p is the characteristic, then Exercise
29 at the end of the chapter will give the contradiction. We may assume that p
is not the characteristic. The p-th roots of unity
=1= 1 are the roots of a poly-
nomial of degree ;£ p -
I (namely XP- 1 + ... + 1), and hence must lie in F.
By Theorem 6.2, it follows that k" is the splitting field of some polynomial
XP - a with a E F. The polynomial Xp
2
-
a is necessarily reducible. By the
theorem, we must have p = 2 and a = -4b4 with b « F. This implies
k' = F(a 1/ 2) = F(i).
But we assumed i E kl ' contradiction.
Thus we have proved po = k(i) . It remains to prove that char k = 0, and for
this I use an argument shown to me by Keith Conrad. We first show that a sum
of squares in k is a square. It suffices to prove this for a sum of two squares,
and in this case we write an element x + iy E kU) = po as a square.
.
(
. )2
k
X + ly =
U + IV
,
X , y, u, V E
,
and then x2 + y2 = (u2 + v2) 2. Then to prove k has characteristic 0, we merely
observe that if the characteristic is > 0, then -I is a finite sum I + ... + I,
whence a square by what we have just shown , but po = k(i), so this concludes
the proof.
Corollary 9.3 is due to Artin; see [Ar 24], given at the end of Chapter XI.
In that chapter, much more will be proved about the field k.
Example l.
Let k = Q and let GQ = G(Qa/Q). Then the only non-trivial
torsion elements in GQ have order 2. It follows from Artin's theory (as given
in Chapter XI) that all such torsion elements are conjugate in GQ. One uses
Chapter XI, Theorems 2.2, 2.4, and 2.9 .)

300
GALOIS THEORY
VI, §9
Example 2.
Let k be a field of characteristic not dividing n. Let a E k,
a*"O
and let K be the splitting field of X" - a. Let a be one root of
X" - a, and let (be a primitive n-th root of unity. Then
K = k(a, () = k(a, fLn)'
We assume the reader is acquainted with matrices over a commutative ring . Let
a E GK1k • Then (ua)n = a, so there exists some integer b = b(u) uniquely
determined mod n, such that
u(a) = a{j'(u).
Since a induces an automorphism of the cyclic group fLn , there exists an integer
d(u) relatively prime to n and uniquely determined mod n such that u(O
(d(u). Let G(n) be the subgroup of GL2(Z/nZ) consisting of all matrices
(I 0) .
M =
b
d
with b E Z/nZ
and
d e (Z/nZ)*.
Observe that #G(n) = ncp(n). We obtain an injective map
a H> M(u) = (b/U)
d(:))
of GK1k ~ G(n),
which is immediately verified to be an injective homomorphism. The question
arises, when is it an isomorphism? The next theorem gives an answer over some
fields, applicable especially to the rational numbers.
Theorem 9.4.
Let k be afield. Let n be an odd positive integer prime to the
characteristic, and assume that [k(fLn) : k] = cp(n). Let a E k, and suppose that
for each prime pin the element a is not a p-th power in k. Let K be the splitting
field of X" -
a over k. Then the above homomorphism a H> M(u) is an
isomorphism of GK1k with G(n). The commutator group is Gal(K/k(fLn))' so
k(fLn) is the maximal abelian subextension of K.
Proof.
This is a special case of the general theory of §11, and Exercise 39,
taking into account the representation of GK1k in the group of matrices. One need
only use the fact that the order of GKlk is ncp(n), according to that exercise, and
so #(GK1k) = #G(n), so GKIk = G(n). However, we shall given an independent
proof as an example of techniques of Galois theory . We prove the theorem by
induction.
Suppose first n = p is prime . Since [k(fLp) : k] = p -
I is prime to p, it
follows that if a is a root of XP
-
a, then k(a) n k(fLp) = k because
[k(a) : k] = p. Hence [K : k] = p(p -
1), so GK1k = G(p) .
A direct computation of a commutator of elements in G(n) for arbitrary n
shows that the commutator subgroup is contained in the group of matrices
G~), b E Z/nZ,

VI, §9
THE EQUATION Xn - a = 0
301
and so must be that subgroup because its factor group is isomorphic to (Z/nZ) *
under the projection on the diagonal. This proves the theorem when n = p .
Now letpln and write n = pm. Then [k(J1m) : k] = cp(m), immediately from
the hypothesis that [k(J1n) : k]
=
cp(n) . Let a be a root of Xn -
a, and let
{3 = a!' , Then (3 is a root of xm - a, and by induction we can apply the theorem
to Xm -
a. The field diagram is as follows.
Since a has degree pm over k, it follows that a cannot have lower degree than
p over k({3), so [k(a) : k({3)] = p and XP -
(3 is irreducible over k({3). We apply
the first part of the proof to XP -
(3 over k({3). The property concerning the
maximal abelian subextension of the splitting field shows that
k(a) n k({3, J1n) = k({3).
Hence [k(a, J1n) : k({3, J1n )] = p. By induction, [k({3, J1n) : k(J1n)] = m, again
because of the maximal abelian subextension of the splitting field of Xm -
a
over k. This proves that [K : k] = ncp(n), whence GK1k = G(n), and the commutator
statement has already been proved. This concludes the proof of Theorem 9.4.
Remarks.
When n is even , there are some complications, because for
instance Q(Y2) is contained in Q(J1g), so there are dependence relations among
the fields in question. The non-abelian extensions, as in Theorem 9.4, are of
intrinsic interest because they constitute the first examples of such extensions
that come to mind , but they arose in other important contexts. For instance,
Artin used them to give a probabilistic model for the den sity of primes p such
that 2 (say ) is a primitive root mod p (that is, 2 generates the cyclic group
(Z/pZ)*. Inst~ad of 2 he took any non-square integer *" ± I. At first, Artin did
not realize explicitly the above type of dependence, and so came to an answer
that was off by some factor in some cases. Lehmer discovered the discrepancy
by computations. As Artin then said, one has to multiply by the "obvious" factor
which reflects the field dependencies. Artin never published his conjecture, but
the matter is discussed in detail by Lang-Tate in the introduction to his collected
papers (Addison-Wesley, Springer Verlag).
Similar conjectural probabilistic models were constructed by Lang-Trotter in
connection with elliptic curves, and more generally with certain p-adic repre-
sentations of the Galois group, in "Primitive points on elliptic curves" , Bull.
AMS 83 No.2 (1977 ), pp. 289-292; and [LaT 75] (end of §14).
For further comments on the p-adic repre sentations of Galois groups, see §14
and §15.

302
GALOIS THEORY
§10.
GALOIS COHOMOLOGY
VI, §10
Let G be a group and A an abelian group which we write additively for the
general remarks which we make, preceding our theorems. Let us assume that
G operates on A, by means of a homomorphism G --> Aut(A). Bya 1-cocycle of
Gin A one means a family of elements {(XU}UEG with (Xu E A,satisfying the relations
for all a, , E G. If {(Xu}UE G and {f3u}UE G are I-cocycles, then we can add them to
get a l-cocycle {«, + f3U}UEG ' It is then clear that I-cocycles form a group,
denoted by Zl(G, A). Bya 1-coboundary of G in A one means a family of ele-
ments {iY.U} I1EG such that there exists an element f3EA for which (Xu = af3 -
f3
for all a E G. It is then clear that a l-coboundary is a l-cocycle, and that the
l-coboundaries form a group, denoted by B1(G, A). The factor group
is called the first cohomology group of G in A and is denoted by H1(G, A) .
Remarks.
Suppose G is cyclic. Let
TrG: A ~ A be the homomorphism a ~ L £T(a) .
lTEG
Let y be a generator of G. Let (1 -
y)A be the subgroup of A consisting of all
elements a -
yea) with a E A . Then (l -
y)A is contained in ker TrG' The
reader will verify as an exercise that there is an isomorphism
ker Trd(l -
y)A = H1(G, A) .
Then the next theorem for a cyclic group is just Hilbert's Theorem 90 of §6.
Cf. also the cohomology of groups, Chapter XX, Exercise 4, for an even more
general context.
Theorem 10.1.
Let Klk: be a finite Galois extension with Galois group G.
Then for the operation of G on K* we have H 1(G, K*) = I, and for the
operation of G on the additive group of K we have H1(G, K) = O. In other
words, the first cohomology group is trivial in both cases.
Proof
Let {(XU}UEG be a l-cocycle of G in K*. The multiplicative cocycle
relation reads

VI, §10
GALOIS COHOLOLOGY
303
By the linear independence of characters, there exists () E K such that the element
is "# O. Then
(1p = L ~~(1r« ()
= L r.J."rr.J.;
I (1r«()
reG
r e G
= r.J.; I Lr.J."r(1r«()
=
r.J.,,- I p.
re G
We get a; = P/(1P, and using p- I instead of pgives what we want.
For the additive part of the theorem, we find an element () E K such that the
trace Tr«() is not equal to O. Given a l-cocyc1e {r.J.,,} in the additive group of K ,
we let
It follows at once that c, = P- (1p, as desired.
The next lemma wi11 be applied to the non-abelian Kummer theory of the
next section.
Lemma 10.2. (Sah).
Let Gbe a groupand let E be a G-module. Let r be in
the center of G. Then H'(G, E) is annihilated by the map x 1-+ TX -
X on E.
In particular, if this map is an automorphism ofE, then H'(G, E) = O.
Proof:
Let f be a l-cocyc1e of G in E. Then
f( (1) = f( m r- ') = fe r) + r(f((1r- 1) )
= f(r) + r[f«(1) + (1f(r- l )].
Therefore
rf«(1) - f«(1) = -(1rf(r- ') - f(r).
Butf(1) = f(l) + f(l) impliesf(l) = 0, and
o=f(1) =f(rr- ') =f(r) + rf(r- ').
This shows that (r - 1)/((1) = ((1 - l )f (r), so (r - l )f is a coboundary. This
proves the lemma.

304
GALOIS THEORY
§11.
NON-ABELIAN KUMMER EXTENSIONS
VI, §11
We are interested in the splitting fields of equations X" - a = 0 when the
n-th roots of unity are not contained in the ground field. More generally, we
want to know roughly (or as precisely as possible) the Galois group of simul-
taneous equations of this type. For this purpose, we axiomatize the pattern
of proof to an additive notation, which in fact makes it easier to see what is
going on.
We fix an integer N > I, and we let M range over positive integers divid-
ing N. We let P be the set of primes dividing N. We let G be a group, and let:
A = G-module such that the isotropy group of any element of A is of finite
index in G. We also assume that A is divisible by the primes piN,
that is
pA = A
for all pEP.
r = finitely generated subgroup of A such that r is pointwise fixed by G.
We assume that AN is finite. Then ~ r is also finitely generated. Note that
Example.
For our purposes here, the above situation summarizes the
properties which hold in the following situation. Let K be a finitely generated
field over the rational numbers, or even a finite extension of the rational numbers.
We let A be the multiplicative group of the algebraic closure K", We let G = GK
be the Galois group Gal(KajK). We let r be a finitely generated subgroup of
the multiplicative group K* . Then all the above properties are satisfied. We
see that AN = JiN is the group of N-th roots of unity. The group written ~ r
in additive notation is written r 1/N in multiplicative notation.
Next we define the appropriate groups analogous to the Galois groups of
Kummer theory, as follows. For any G-submodule B of A, we let:
G(E) = image of Gin Aut(B),
G(N) = G(A N) = image of Gin Aut(A N) ,
H(N) = subgroup of G leaving AN pointwise fixed,
Hr(M, N) (for MIN) = image of H(N) in Aut(~ r}

VI, §11
Then we have an exact sequence:
NON-ABELIAN KUMMER EXTENSIONS
305
o~ Br(M, N) ~ G(~ I' + AN) ~ G(N) ~ O.
Example.
In the concrete case mentioned above, the reader will easily
recognize these various groups as Galois groups. For instance, let A be the
multiplicative group. Then we have the following lattice of field extensions
with corresponding Galois groups :
J
KC
[1 1M)}
liN,
B (M N)
I
r
,
G([I /MIlN)
K(liN)1
}G(N)
In applications, we want to know how much degeneracy there is when we trans-
late K(IlM ' [1 1M) over K(IlN) with MIN. This is the reason we play with the
pair M, N rather than a single N.
Let us return to a general Kummer representation as above. We are in-
terested especially in that part of (Z/NZ)* contained in G(N), namely the group
of integers n (mod N ) such that there is an element en] in G(N) such that
[n]a = na
for all a E AN'
Such elements are always contained in the center of G(N), and are called
homotheties.
Write
N = Il pntPJ
Let S be a subset of P. We want to make some non-degeneracy assumptions
about G(N). We call S the special set.
There is a product decomposition
(Z/NZ)* = IT (Z/pn(p)z)*.
piN
If 21 N we suppose that 2 E S. For each pES we suppose that there is an integer
c(p) = pf(p) withf(p) ~ 1 such that
G(A)
IT V
IT(Z/pn(p)z )*,
N::J
c(p) X
peS
p~S
where Vc(p) is the subgroup of Z(pn(p» consisting of those elements == 1 mod c(p).

306
GALOIS THEORY
VI, §11
The product decomposition on the right is relative to the direct sum decom-
position
The above assumption will be called the non-degeneracy assumption. The
integers c(p) measure the extent to which G(A N ) is degenerate.
Under this assumption, we observe that
[2J E G(AM )
if
MIN and M is not divisible by primes of S;
[1 + cJ E G(A M )
if
MIN and M is divisible only by primes of S,
where
c = c(S) = I1 c(p).
peS
We can then use [2J - [IJ = [IJ and [1 + cJ - [IJ = [cJ in the context of
Lemma 10.2, since [IJ and [cJ are in the center of G.
For any M we define
c(M) = I1 c(p).
plM
peS
Define
and the exponent
e(f'If) = smallest positive integer e such that ef' c f.
It is clear that degeneracy in the Galois group H reM, N) defined above can
arise from lots of roots of unity in the ground field, or at least degeneracy in
the Galois group of roots of unity ; and also if we look at an equation
X M
- a = 0,
from the fact that a is already highly divisible in K . This second degeneracy
would arise from the exponent e(f'/f), as can be seen by looking at the Galois
group of the divisions of f. The next theorem shows that these are the only
sources of degeneracy.
We have the abelian Kummer pairing for MIN,
Hr(M, N) x f /Mf ~ AM
given by
(r, x) 1---+ ry - y,
where y is any element such that My = x. The value of the pairing is indepen-

VI, §11
NON-ABELIAN KUMMER EXTENSIONS
307
dent of the choice of y. Thus for x E I", we have a homomorphism
such that
(,Ox('r) = ,y - y,
where My = x.
Theorem 11.1.
Let MIN. Let (,0 be the homomorphism
(,0 : I' --+ Hom(Hr(M, N), AM)
and let fq> be its kernel. Let eM(f) = g.c.d. (e(f'/f), M). Under the non-
degeneracy assumption, we have
c(M)eM(f)fq> eMf.
Proof
Let x E f and suppose (,OX = 0. Let My = x. For a E G let
y" = ay - y.
Then {y,,} is a l-cocycle of G in AM' and by the hypothesis that (,OX = 0, this
cocycle depends only on the class of a modulo the subgroup of G leaving the
elements of ANfixed. In other words, we may view {y,,} as a cocycle of G(N) in
AM' Let c = c(N). By Lemma 10.2, it follows that {cy,,} splits as a cocycle of
G(N) in AM ' In other words, there exists toE AM such that
and this equation in fact holds for a E G. Let t be such that ct = to. Then
cay - cy = act - cy,
whence c(y - t) is fixed by all a E G, and therefore lies in ~ f. Therefore
e(f'/r)c(y - r) E f .
We multiply both sides by M and observe that cM(y - t) = cMy = cx. This
shows that
c(N)e(f'/r)fq> eMf.
Since f /Mf has exponent M, we may replace e(f'/f) by the greatest common
divisor as stated in the theorem, and we can replace c(N) by c(M) to conclude
the proof.
Corollary 11.2.
Assume that M is prime to 2(f' : I") and is not divisible by
any primesofthe special set S. Then we have an injection
(,0: f /Mf --+ Hom(Hr<M, N), AM.).

308
GALOIS THEORY
VI, §12
Ifinaddition f isfree withbasis{a" . . . ,ar}, andwe let <f>i = <f>a;, then the map
Hr(M, N) -+ A<;l
given by
r -+ (<f>,(r), .. . , <f>r(r»
is injective. If AM is cyclic oforder M, this map is an isomorphism.
Proof
Under the hypotheses of the corollary, we have c(M) = 1 and
cM(f ) = 1 in the theorem.
Example.
Consider the case of Galois theory when A is the multiplicative
group of K". Let ai' . . . , a, be elements of K* which are multiplicatively inde-
pendent. They generate a group as in the corollary. Furthermore, AM = JIM
is cyclic, so the corollary applies. If M is prime to 2(f' : F) and is not divisible
by any primes of the special set S, we have an isomorphism
<f> : f /Mf -+ Hom(Hr(M, N), JIM)'
§12.
ALGEBRAIC INDEPENDENCE OF
HOMOMORPHISMS
Let A be an additive group, and let K be a field. Let AI' ... , An: A -+ K be
additive homomorphisms.
We shall say that A"
.. ., An are algebraically
dependent
(over
K)
if
there
exists
a
polynomial
f(X" .. . , Xn)
in
K[XI , .• . ,Xn] such that for all x E A we have
but such that f does not induce the zero function on «» , i.e. on the direct
product of K with itself n times. We know that with each polynomial we can
associate a unique reduced polynomial giving the same function.
If K is
infinite, the reduced polynomial is equal to f itself. In our definition of de-
pendence, we could as well assume that f is reduced.
A polynomialf(X I"' " X n) will be called additive if it induces an additive
homomorphism of
K(n) into K.
Let (Y) = (Y" . .. , y,,) be variables inde-
pendent from (X). Let
g(X, Y) = f(X + Y) - f(X) - f(Y)
where X + Y is the componentwise vector addition. Then the total degree of
g viewed as a polynomial in (X) with coefficients in K[Y] is strictly less than
the total degree off, and similarly, its degree in each Xi is strictly less than the
degree off in each Xi' One sees this easily by considering the difference of
monomials,

VI, §12
ALGEBRAIC INDEPENDENCE OF HOMOMORPHISMS
309
M(v)(X + Y) - M(v)(X) - M(v)( Y)
= (Xl + y)r'· ··(X n+ y")"n - XI' .. · X~n - n' ... y~n.
A similar assertion holds for g viewed as a polynomial in (Y) with coefficients in
K[X].
Iff is reduced, it follows that g is reduced. Hence iff is additive, it follows
that g is the zero polynomial.
Example.
Let K have characteristic p. Then in one variable, the map
for a E K and m ~ 1 is additive, and given by the additive polynomial oX!",
We shall see later that this is a typical example.
Theorem 12.1.
(Art in).
Let A), ... , An: A -+ K be additive homomorph-
isms of an additive group into a field. If these homomorphisms are alge-
braicallydependent over K, then there exists an additive polynomial
in K[X] such that
for all x E A.
Proof
Let f(X) = f(X], . .. , Xn) E K[X] be a reduced polynomial of
lowest possible degree such that f =I- 0 but for all x E A, f(i\(x» = 0, where
i\(x) is the vector (A](x), . . . , An(x». We shall prove thatfis additive.
Let g(X, Y) = f(X + Y) - f(X) - f(Y). Then
g(A(x), i\(y» = f(i\(x + y» - f(i\(x» - f(i\(y» = 0
for all x, YEA . We shall prove that g induces the zero function on K(n)
X x».
Assume otherwise. We have two cases.
Case 1.
We
have
g(~, A(y»
= 0 for
all
~ E K(n)
and
all YEA.
By
hypothesis, there exists
~' E K'" such that
g(~' , Y) is not identically O.
Let
P(Y) =
g(~', Y). Since the degree of gin (Y) is strictly smaller than the degree
of f, we have a contradiction.
Case 2. There exist
~ ' E K'" and y' E A such that
g(~', A(y'»
=I- O.
Let
P(X) = g(X, A(y'» . Then P is not the zero polynomial, but P(A(x» = 0 for all
x E A, again a contradiction .

310
GALOIS THEORY
VI, §12
We conclude that 9 induces the zero function on K'"
X x» ,which proves
what we wanted, namely thatfis additive.
We now consider additive polynomials more closely.
Letfbe an additive polynomial in n variables over K, and assume thatfis
reduced. Let
j;(X i) = f(O, . . . , Xi' . . . ,0)
with X i in the i-th place, and zeros in the other components. By additivity, it
follows that
because the difference of the right -hand side and left-hand side is a reduced
polynomial taking the value 0 on
K (n).
Furthermore, each Ii is an additive
polynomial in one variable. We now study such polynomials.
Let f(X) be a reduced polynomial in one variable, which induces a linear
map of K into itself. Suppose that there occurs a monomial a.X' in f with
coefficient a, =1= O. Then the monomials of degree r in
g(X , Y) = f(X + Y) - f(X) - fey)
are given by
a,(X + Y)' - a.X' - a, yr.
We have already seen that 9 is identically O. Hence the above expression is
identically O. Hence the polynomial
(X + Y)' - X' _ Y'
is the zero polynomial. It contains the term rX'" 1 Y. Hence if r > 1, our field
must have characteristic p and r is divisible by p. Write r = pnls where s is
prime to p. Then
0= (X + Y)' _ X' _ Y' = (Xpm+ pm)' _ (Xpm)s _ (pm)'.
Arguing as before, we conclude that s = 1.
Hence iffis an additive polynomial in one variable, we have
m
f(X) = L «xr ,
v=o
with av E K. In characteristic 0, the only additive polynomials in one variable
are of type aX with a E K.
As expected, we define AI," " An to be algebraically independent if, whenever
fis a reduced polynomial such thatf(A(x» = 0 for all x E K, thenfis the zero
polynomial.

VI, §12
ALGEBRAIC INDEPENDENCE OF HOMOMORPHISMS
311
We shall apply Theorem 12.1 to the case when AI,. . ., An are automorphisms
of a field, and combine Theorem 12.1 with the theorem on the linear indepen-
dence of characters.
Theorem 12.2.
Let K be an infinitefield, and let (TI"' " o; be the distinct
elements ofa finite group ofautomorphisms of K. Then (T I' . . . , a; are alge-
braically independent over K .
Proof
(Artin).
In characteristic 0, Theorem 12.1 and the linear inde-
pendence of characters show that our assertion is true. Let the characteristic
be p > 0, and assume that (T I ' . . . , a; are algebraically dependent.
There exists an additive polynomial f(X 1"'" X n) in K[X] which is
reduced, f "# 0, and such that
f«(TI(x), . . . , (Tn(x»
= °
for all x E K. By what we saw above, we can write this relation in the form
n
m
L L ajr(Tlxyr = °
i = I r= I
for all x E K , and with not all coefficients a., equal to 0. Therefore by the linear
independence of characters, the automorphisms
{" PI: }
. h
.
1
d
1
v
WIt
I = , .. ., n
an
r = , ... , m
cannot be all distinct. Hence we have
with either i "# j or r "# s. Say r ;;;; s. For all x E K we have
Extracting p-th roots in characteristic p is unique. Hence
(
)
(
) ps _ r
(
ps -r)
a, X = (Tj X
= (Tj X
for all x s K. Let(T= (Tjhj • Then
o(x) = x ps -
r
for all x E K . Taking a" = id shows that
P" (s - ,.)
x=x
for all x E K. Since K is infinite, this can hold only if s = r. But in that case,
a, = (Tj' contradicting the fact that we started with distinct automorphisms.

312
GALOIS THEORY
§13.
THE NORMAL BASIS THEOREM
VI, §13
Theorem 13.1.
Let K lk be afinite Galois extension ofdegree n. Let al"'" an
be the elements of the Galois group G. Then there exists an element WE K
such that a 1w, . . . , an W form a basis of Kover k.
Proof
We prove this here only when k is infinite. The case when k is
finite can be proved later by methods of linear algebra, as an exercise.
ForeachaEG,letXabeavariable,andletta,t = Xa -It. Let X, = X<1; ' Let
f(X I, · · ·, X n) = det(ta;.<1).
Thenf is not identically 0, as one sees by substituting 1 for Xid and 0 for X; if
a =1= id. Since k is infinite,fis reduced. Hence the determinant will not be 0 for
all x EK if we substitute ai(x) for Xi inf Hence there exists WEK such that
Suppose at, .. . , an Ek are such that
Apply aj- 1 to this relation for each i = 1, .. . , n. Since aj Ek we get a system of
linear equations, regarding the aj as unknowns. Since the determinant of the
coefficients is
=1= 0, it follows that
for
j = 1, . . . , n
and hence that Wis the desired element.
Remark.
In terms of representations as in Chapters III and XVIII, the
normal basis theorem says that the representation of the Galois group on the
additive group of the field is the regular representation. One may also say that
K is free of dimension lover the group ring k[G] . Such a result may be viewed
as the first step in much more subtle investigations having to do with algebraic
number theory . Let K be a number field (finite extension of Q) and let
0 K be
its ring of algebraic integers, which will be defined in Chapter VII, §1. Then
one may ask for a description of
OK as a Z[G] module, which is a much more
difficult problem. For fundamental work about this problem, see A. Frohlich,
Galois Module Structures of Algebraic Integers, Ergebnisse der Math. 3 Folge
Vol. 1, Springer Verlag (1983) . See also the reference [CCFT 91] given at the
end of Chapter III, §1.

VI, §14
INFINITE GALOIS EXTENSIONS
313
§14.
INFINITE GALOIS EXTENSIONS
Although we have already given some of the basic theorems of Galois theory
already for possibly infinite extensions, the non-finiteness did not really appear
in a substantial way . We now want to discuss its role more extensively.
Let K/k be a Galois extension with group G. For each finite Galois subex-
tension F,
we have
the Galois groups GKIF and GFik.
Put H = GK1F .
Then H has finite index , equal to #(GFJk) = [F : k]. This just comes as a special
case of the general Galois theory. We have a canonical homomorphism
G ~ G/H = GFJk.
Therefore by
the
universal
property of
the
inverse limit,
we
obtain a
homomorphism
G~ limG/H,
HEff
where the limit is taken for H in the family ff of Galois groups GK1F as above.
Theorem 14.1.
The homomorphism G ~ lim G/H is an isomorphism.
Proof.
First the kernel is trivial, because if (Tisin the kernel, then (Trestricted
to every finite subextension of K is trivial, and so is trivial on K. Recall that an
element of the inverse limit is a family {(TH} with (TH E G/ H, satisfying a certain
compatibility condition. This compatibility condition means that we may define
an element (T of G as follows . Let 0: E K. Then 0: is contained in some finite
Galois extension Fe K. Let H = Gal(K/F). Let (TO: = (THO:' The compatibility
condition means that (THO: is independent of the choice of F . Then it is immediately
verified that (T is an automorphism of Kover k, which maps to each (TH in the
canonical map of G into G/ H . Hence the map G ~ lim. G/ H is surjective, thereby
proving the theorem.
Remark.
For the topological interpretation, see Chapter I, Theorem 10. I,
and Exercise 43.
Example.
Let f1.[pX] be the union of all groups of roots of unity f1.[pn],
where p is a prime and n =
I, 2, . .. ranges over the positive integers. Let
K = Q(f1.[pX]). Then K is an abelian infinite extension of Q. Let Zp be the ring
of p-adic integers, and Z; the group of units. From §3, we know that (Z/pnz)*
is isomorphic to Gal(Q(f1.[pn]/Q» . These isomorphisms are compatible in the
tower of p-th roots of unity, so we obtain an isomorphism
Z; ~ Gal(Q(f1.[pX]/Q» .

314
GALOIS THEORY
VI, §14
Towers of cyclotomic fields have been extensively studied by Iwasawa. Cf.
a systematic exposition and bibliography in [La 90] .
For other types of representations in a group GL 2(Zp), see Serre [Se 68],
[Se 72], Shimura [Shi 71], and Lang-Trotter [LaT 75]. One general framework
in which the representation of Galois groups on roots of unity can be seen has
to do with commutative algebraic groups, starting with elliptic curves. Specif-
ically, consider an equation
y2 = 4x3 -
g2x -
g3
with g2' g3 E Q and non-zero discriminant: Ll = g~ -
27g~ *- O. The set of
solutions together with a point at infinity is denoted by E. From complex analysis
(or by purely algebraic means), one sees that if K is an extension of Q, then the
set of solutions E(K) with x, y E K and
00 form a group, called the group of
rational points of E in K . One is interested in the torsion group, say E(Qa)tor of
points in the algebraic closure, or for a given prime p, in the group E(Qa)[pT]
and E(Qa)[p"'] . As an abelian group, there is an isomorphism
E(Qa)[pT] = (Z/pTZ) X (Z/pTZ) ,
so the Galois group operates on the points of order p" via a representation in
GL2(Z/pTZ), rather than GL\(Z/pTZ) = (Z/pTZ)* in the case of roots of unity .
Passing to the inverse limit, one obtains a representation of Gal(Qa/Q) = GQ
in GL2(Zp)' One of Serre's theorems is that the image of GQ in GL2(Zp) is a
subgroup of finite index, equal to GL 2(Zp) for all but a finite number of primes
p, if End C (E) = Z.
More generally, using freely the language of algebraic geometry, when A is
a commutative algebraic group, say with coefficients in Q, then one may consider
its group of points A(Qa)tof' and the representation of GQ in a similar way .
Developing the notions to deal with these situations leads into algebraic geometry.
Instead of considering cyclotomic extensions of a ground field, one may also
consider extensions of cyclotomic fields. The following conjecture is due to
Shafarevich. See the references at the end of §7.
Conjecture 14.2.
Let ko = Q(p.) be the compositum ofall cyclotomic exten-
sions of Q in a given algebraic closure Qa. Let k be a finite extension of ko.
Let Gk = Gal(Qa/k). Then Gk is isomorphic to the completion of a free group
on countably many generators .
If G is the free group, then we recall that the completion is the inverse limit
lim G/ H, taken over all normal subgroups H of finite index . Readers should
view this conjecture as being in analogy to the situation with Riemann surfaces,
as mentioned in Example 9 of §2. It would be interesting to investigate the extent
to which the conjecture remains valid if Q(p.) is replaced by Q(A(Qa)tor), where
A is an elliptic curve . For some results about free groups occurring as Galois
groups, see also Wingberg [Wi 91] .

VI, §15
[La 90)
[LaT 75)
[Se 68)
[Se 72]
[Shi 71)
[Wi 91)
§1 5.
THE MODULAR CONNECTION
315
Bibliography
S. LANG, Cyclotomic Fields I and II, Second Edition, Springer Verlag, 1990
(Combined edition from the first editions, 1978, 1980)
S. LANGand H. TROTTER, Distribution ofFrobenius Elements in GL2-Extensions
of the Rational Numbers, Springer Lecture Notes 504 (1975)
1.-P. SERRE, Abelian l-adic Representations and Elliptic Curves, Benjamin, 1968
l. -P. SERRE, Proprietes galoisiennes des points d'ordre fini des courbes ellip-
tiques, Invent. Math. 15 (1972), pp. 259-33 1
G. SHIMURA, Introduction to the arithmetic theory of Automorphic Functions,
Iwanami Shoten and Princeton University Press, 1971
K. WINGBERG, On Galois groups of p-ciosed algebraic number fields with
restricted ramification, I, J. reine angew. Math. 400 (1989), pp. 185-202;
and II, ibid., 416 (1 991), pp. 187-194
THE MODULAR CONNECTION
This final section gives a major connection between Galois theory and the
theory of modular form s, which has arisen since the 1960s.
One fundamental question is whether given a finite group G, there exi sts a
Galo is extension K of Q whose Galois group is G. In Exercise 23 you will prove
this when G is abelian.
Already in the nineteenth century, number theorists real ized the big difference
bet ween abelian and non-abelian extension s, and started understanding abelian
extension s. Kronecker stated and gave what are today con sidered incomplete
arguments that every finite abelian extension ofQ is contained in some extension
Q({ ), where { is a root of unity . The difficulty lay in the peculiarities of the
prime 2. The trouble was fixed by Weber at the end of the nineteenth century.
Note that the trouble with 2 has been systematic since then. It arose in Artin's
conjecture about den sities of primitive roots as mentioned in the remarks after
Theorem 9.4. It arose in the Grunwald theorem of class field theory (corrected
by Wang, cf. Artin-Tate [ArT 68], Chapter 10). It arose in Shafarevich's proof
that given a solvable group, there exi sts a Galois extension of Q having that
group as Galois group, mentioned at the end of §7.
Abelian extension s of a number field F are harder to describe than over the
rationals , and the fundamental theory giving a description of such extensions is
ca lled class field theory (see the abo ve reference). I shall give one significant
example exhibiting the flavor. Let RF be the ring of algebraic integers in F. It
can be show n that RF is a Dedekind ring . (Cf. [La 70], Chapter I, §6, Theorem
2.) Let P be a prime ideal of RF . Then P n z = (p) for some prime number p .

316
GALOIS THEORY
VI, §15
Furthermore, RF / P is a finite field with q elements. Let K be a finite Galois
extension of F. It will be shown in Chapter VII that there exists a prime Q of
RK such that Q n RF = P. Furthermore, there exists an element
FrQ E G = Gal(K/F)
such that FrQ(Q) = Q and for all a E RK we have
FrQa == a'I mod Q.
We call FrQ a Frobenius element in the Galois group G associated with Q. (See
Chapter VII, Theorem 2.9.) Furthermore, for all but a finite number of Q, two
such elements are conjugate to each other in G. We denote any of them by Frp.
If G is abelian, then there is only one element Frp in the Galois group.
Theorem 15.1.
There exists a unique finite abelian extension K ofF having
the
following
property.
If
PI'
Pz
are
prime
ideals
of
RF ,
then
Frp) = Frp2if and only if there is an element a of K such that aPt = Pz.
In a similar but more complicated manner, one can characterize all abelian
extensions of F. This theory is known as class field theory, developed by Kro-
necker, Weber, Hilbert, Takagi, and Artin . The main statement concerning the
Frobenius automorphism as above is Artin's Reciprocity Law. Artin-Tate's notes
give a cohomological account of class field theory. My Algebraic Number Theory
gives an account following Artin's first proof dating back to 1927, with later
simplifications by Artin himself. Both techniques are valuable to know.
Cyclotomic extensions should be viewed in the light of Theorem 15. 1. Indeed,
let K = Q(O, where
~ is a primitive n-th root of unity. For a prime p,fn, we
have the Frobenius automorphism Frp' whose effect on (is Frp(O = (P. Then
Frp1= Frp2
if and only if
PI == pz mod n.
To encompass both Theorem 15.1 and the cyclotomic case in one framework,
one has to formulate the result of class field theory for generalized ideal classes,
not just the ordinary ones when two ideals are equivalent if and only if they
differ multiplicatively by a non-zero field element. See my Algebraic Number
Theory for a description of these generalized ideal classes.
The non-abelian case is much more difficult. I shall indicate briefly a special
case which gives some of the flavor of what goes on . The problem is to do for
non-abelian extensions what Artin did for abelian extensions. Artin went as far
as saying that the problem was not to give proofs but to formulate what was to
be proved. The insight of Langlands and others in the sixties shows that actually
Artin was mistaken. The problem lies in both . Shimura made several computations
in this direction involving "modular forms" [Sh 66]. Langlands gave a number
of conjectures relating Galois groups with "automorphic forms", which showed
that the answer lay in deeper theories, whose formulations , let alone their proofs,
were difficult. Great progress was made in the seventies by Serre and Deligne,
who proved a first case of Langland's conjecture [DeS 74] .

VI, §15
THE MODULAR CONNECTION
317
The study of non-abelian Galois groups occurs via their linear "representa-
tions" . For instance, let I be a prime number. We can ask whether GLn(F/) , or
GL2(F/), or PGL2(F/) occurs as a Galois group over Q, and "how" . The problem
is to find natural objects on which the Galois group operates as a linear map,
such that we get in a natural wayan isomorphism of this Galois group with one
of the above linear groups. The theories which indicate in which direction to
find such objects are much beyond the level of this course, and lie in the theory
of modular functions, involving both analysis and algebra, which form a back-
ground for the number theoretic applications. Again I pick a special case to give
the flavor.
Let K be a finite Galois extension of Q, with Galois group
G = Gal(K/Q) .
Let
p: G ~ GL2(F/)
be a homomorphism of G into the group of 2 X 2 matrices over the finite field
F/ for some prime I. Such a homomorphism is called a representation of G.
From elementary linear algebra, if
is a 2 x 2 matrix, we have its trace and determinant defined by
tr(M) = a + d
and
det M = ad -
be,
Thus we can take the trace and determinant tr p( 0-) and det p( 0-) for 0- E G.
Consider the infinite product with a variable q:
-x:
oc
Ll(q) = q n(l -
qn)24 = 2: anq n.
n =l
n=l
The coefficients an are integers, and al = I.
Theorem 15.2.
For each prime I there exists a unique Galois extension K of
Q, with Galois group G, and an injective homomorphism
p : G ~ GL2(F/)
having the following property. For all but a finite number ofprimes p , if ap is
the coefficient of qP in Ll(q), then we have
tr p(Frp) = ap mod I
and
det p(Frp) = pll mod I.
Furthermore, for all primes I ::1= 2, 3, 5, 7, 23, 691, the image p(G) in GL2(F/)
consists of those matrices M E GL2(F/) such that det M is an eleventh power
in Fr.

318
GALOIS THEORY
VI, §15
The above theorem was conjectured by Serre in 1968 [Se 68] . A proof of
the existence as in the first statement was given by Deligne [De 68] . The second
statement, describing how big the Galois group actually is in the group of matrices
GL2(F,) is due to Serre and Swinnerton-Dyer [Se 72], [SwD 73].
The point of Ll(q) is that if we put q = e21Tiz, where Z is a variable in the
upper half-plane, then Ll is a modular form of weight 12. For definitions and an
introduction, see the last chapter of [Se 73], [La 73], [La 76], and the following
comments. The general result behind Theorem 15.2 for modular forms of weight
~ 2 was given by Deligne [De 73]. For weight 1, it is due to Deligne-Serre
[DeS 74] . We summarize the situation as follows.
Let N be a positive integer. To N we associate the subgroups
feN) C fl(N) C fo(N)
of SL2(Z) defined by the conditions for a matrix a = (: ;) E SL2(Z):
a E feN) if and only if a == d == 1 mod Nand b == e == 0 mod N;
a E fl(N) if and only if a == d == I mod Nand c == 0 mod N;
a E fo(N) if and only if e == 0 mod N.
Let f be a function on the upper half-plane ~ = {z E C, Im(z) > O}. Let k
be an integer. For
l' = (:
~) E SL2(R),
define f
0 [1'h (an operation on the right) by
fo [1']k(Z) = (ez + d) -,,!(1'z)
where
az + b
1'Z = cz + d'
Let I' be a subgroup of SL2(Z ) containing I'(N). We define f to be modular of
weight k on r if:
M k 1. f is holomorphic on ~;
Mk 2. f is holomorphic at the cusps, meaning that for all a E SL2(Z), the
function f
0 [ah has a power series expansion
Mk 3. We have j' > [1']k = ffor all l' E f .
One says thatf is cuspidal if in Mk 2 the power series has a zero ; that is, the
power starts with n ~ 1.

VI, §15
THE MODULAR CONNECTION
319
Suppose thatfis modular of weight k on f eN). Then fi s modular on fl(N)
if and only if f ez + I) = f ez), or equivalently f has an expansion of the form
Thi s power series is called the q-expansion of f.
Suppose f has weight k on I'I(N). If Y E I'o(N) and Y is the above written
matrix , then f
0 [Yh depends only on the image of d in (Z/ NZ)*, and we then
denote f
0 [Yh byf
0 [dh- Let
s: (Z / NZ) * ~ c-
be a homomorphism (also called a Dirichlet character). One says that e is odd
if e( -I ) = -1, and even if e( -1) = 1. One says that f is modular of type
(k, e) on fo(N) iffhas weight k on fl (N), and
f
0 [dh = e(d )f
for all
d e (Z/NZ)* .
It is possible to define an algebra of operators on the space of modular form s
of given type . This requires more extensive background, and I refer the reader
to [La 76] for a systematic expo sition . Among all such form s, it is then possible
to distinguish some of them which are eigenvectors for this Heeke algebra, or ,
as one says, eigenfunctions for this algebra. One may then state the Deligne-
Serre theorem as follow s.
Let f '1= 0 be a modularform of type (I, e) on I'o(N), so f has weight I . Assume
that e is odd. Assume that f is an eigenf unction of the Heeke algebra , with q-
expansion f x = L a.q", normalized so that at = I . Then there exists a unique
finite Galois extension K of Q with Galois group G, and a representation
p: G ~ GL2(C ) (actually an injective homomorphism), such that for all
primes p .:rN the characteristic polynomial of p(Frp) is
X2 -
apX + e(p) .
The representation p is irreducible if and only iff is cuspidal.
Note that the representation p has values in GL 2(C ). For extensive work of Serre
and his conjectures concerning repre sentations of Galois groups in GL 2(F ) when
F is a finite field, see [Se 87] . Roughly speaking, the general philosophy started
by a conjecture of Taniyama-Shimura and the Langlands conjectures is that
everything in sight is "modular". Theorem 15.2 and the Deligne-Serre theorem
are prototypes of results in thisdirection. For "modular" representationsin GL 2(F),
when F is a finite field, Serre's conjectures have been proved, mostly by Ribet
[Ri 90]. As a result, following an idea of Frey, Ribet also showed how the
Taniyama-Shimura conjecture implies Fermat's last theorem [Ri 90b] . Note that
Serre's conjectures that certain representations in GL 2(F ) are modular impl y the
Taniyama-Shimura conjecture.

320
GALOIS THEORY
Bibliography
VI, Ex
[ArT 68]
[De 68]
[De 73]
[DeS 74]
[La 70]
[La 73]
[La 76]
[Ri 90a]
[Ri 90b]
[Se 68]
[Se 72]
[Se 73]
[Se 87]
[Shi 66]
[Shi 71]
[SwD 73]
E. ARTIN and 1. TATE,Class Field Theory, Benjamin-Addison-Wesley, 1968
(reprinted by Addison-Wesley, 1991)
P. DELIGNE, Formes modulaires et representations l-adiques, Seminaire Bour-
baki 1968-1969, exp oNo. 355
P. DELIGNE, Formes modulaires et representations de GL(2) , Springer Lecture
Notes 349 (1973), pp. 55-105
P. DELIGNE and J. P. SERRE, Formes modulaires de poids 1, Ann . Sci. ENS
7 (1974), pp. 507-530
S. LANG, Algebraic Number Theory , Springer Verlag , reprinted from Addison-
Wesley (1970)
S. LANG, Elliptic fun ctions, Springer Verlag , 1973
S. LANG, Introduction to modular forms, Springer Verlag, 1976
K. RIBET, On modular representations of Gal(Q/Q) arising from modular
forms , Invent . Math . 100 (1990), pp. 431-476
K. RIBET, From the Taniyama-Shimura conjecture to Fermat's last theorem,
Annales de la Fac. des Sci. Toulouse (1990), pp. 116-139
I .-P . SERRE, Une interpretation des congruences relatives a la fonction de
Ramanujan, Seminaire Delanqe-Pisot-Poitou, 1967-1968
I .-P . SERRE, Congruences et formes modulaires (d'apres Swinnerton-Dyer),
Seminaire Bourbaki, 1971-1972
J.-P. SERRE, A course in arithmetic , Springer Verlag, 1973
J.-P. SERRE, Sur les representations modulaires de degre 2 de Gal(Q/Q) ,
Duke Math . J. 54 (1987), pp. 179-230
G. SHIMURA, A reciprocity law in non-solvable extensions, J. reine anqew,
Math . 221 (1966), pp. 209-220
G. SHIMURA, Introduction to the arithmetic theory of automorphic functions ,
Iwanami Shoten and Princeton University Press, 1971
H. P. SWINNERTON-DYER, On l-adic repre sentations and congruences for
coefficients of modular forms, (Antwerp conference) Springer Lecture Notes
350 (1973)
EXERCISES
I . What is the Galois group of the following polynomials?
(a) X 3 - X-lover Q.
(b) X 3 -
10 over Q.
(c) X 3 -
10 over Q(J2).
(d) X 3 -
10 over Q(J=3).
(e) X 3 -
X -
lover Q(J"=23).
(f) X4
-
5 over Q, Q(J5), Q(j=5), Q(i).
(g) X4
- a where a is any integer # 0, # ± I and is square free. Over Q.

VI, §Ex
EXERCISES
321
(h) X3 - a where a is any square-free integer ~ 2. Over Q.
(i) X4 + 2 over Q, Q(i).
(j) (X 2 -
2)(X 2 -
3)(X 2 - 5)(X 2 -
7) over Q.
(k) Let PI' .. . , Pn be distinct prime numbers. What is the Galois group of
(X 2 -
PI) ' " (X 2 -
Pn)over Q ?
(I) (X 3 -
2)(X 3 -
3)(X 2 -
2) over Q(J -3).
(m) x n -
t, where t is transcendental over the complex numbers C and n is a
positive integer. Over C(t).
(n) X 4
-
t, where t is as before. Over Ru),
2. Find the Galois groups over Q of the following polynomials.
(a) X 3 + X + 1
(b) X 3 -
X + 1
(g) X3 + X2 -
2X -
1
(c) X 3 + 2X + 1
(d) X 3 -
2X + 1
(e) X 3 - X-I
(f) X3 -
12X + 8
3. Let k = C(t) be the field of rational functions in one variable. Find the Galois group
over k of the following polynomials:
(a) X 3 + X + t
(b) X 3 -
X + t
(c) X 3 + tX + I
(d) X 3 -
2tX + t
(e) X 3 -
X - t
(f) X 3 + t2X - t3
4. Let k be a field of characteristic "* 2. Let c E k, c ¢:. k2• Let F = k(YC). Let
a = a + b YC with a , b E k and not both a, b = O. Let E = F(~) . Prove that
the following conditions are equivalent.
(I) E is Galois over k.
(2) E = F(W), where a' = a - bYC.
(3) Either aa' = a2 -
cb2 E k2 or caa' E k2.
Show that when these conditions are satisfied, then E is cyclic over k of degree 4 if
and only if caa' E F .
5. Let k be a field of characteristic "* 2, 3. Let I(X), g(X) = X2 -
c be irreducible
polynomials over k, of degree 3 and 2 respectively. Let D be the discriminant of f.
Assume that
[k(DI /2) : k] = 2
and
k(Dl /2) * k(C I/2).
Let a be a root of I and {3 a root of g in an algebraic closure. Prove :
(a) The splitting field of Ig over k has degree 12.
(b) Let y = a + {3. Then [k(y) : k] = 6.
6. (a) Let K be cyclic over k of degree 4, and of characteristic "* 2. Let GK1k = (a).
Let E be the unique subfield of K of degree 2 over k. Since [K : E] = 2, there
exists a E K such that a2 =
y E E and K = E(a) . Prove that there exists
z E E such that
zaz = -I,
ira = za ,
z2 = ay/y.
(b) Conversely, let E be a quadratic extension of k and let GElk = (T). Let z E E
be an element such that
ZTZ =
- I. Prove that there exists y E E such that
Z2 = tvt». Then E = key) . Let a2 = y, and let K = k(a) . Show that K is
Galois, cyclic of degree 4 over k. Let a be an extension of T to K . Show that
a is an automorphism of K which generates GK1k> satisfying a 2a = -a and
aa =
±za. Replac ing z by - z originally if necessary, one can then have
aa = za.

322
GALOIS THEORY
VI, Ex
7. (a) Let K = Q(~) where a E Z, a < O. Show that K cannot be embedded in a
cyclic extension whose degree over Q is divisible by 4.
(b) Let/(X) = X4 + 30X2 + 45. Let a be a root of F. Prove that Q(a) is cyclic of
degree 4 over Q.
(c) Let /(X) = X 4 + 4X 2 + 2. Prove that /
is irreducible over Q and that the
Galois group is cyclic.
8. Let/(X) = X 4 + aX 2 + b be an irreducible polynomial over Q,with roots ± a, ± p,
and splitting field K.
(a) Show that Gal(K/Q) is isomorphic to a subgroup of Ds (the non-abelian group
oforder 8other than the quaternion group), and thus is isomorphic to one ofthe
following:
(i) Z/4Z
(ii) Z/2Z x Z/2Z
(iii) o;
(b) Show that the first case happens if and only if
a
f3
73 - ~ E Q.
Case (ii) happens if and only if af3 E Q or a2 -
f32 E Q. Case (iii) happens
otherwise. (Actually, in (ii), the case a2 - f32 E Qcannot occur. It corresponds
to a subgroup of Dg c 84 which is isomorphic to Z/2Z x Z /2Z, but is not
transitive on {I , 2, 3,4}).
(c) Find the splitting field Kin C of the polynomial
X 4 - 4X 2 -
I.
Determine the Galois group of this splitting field over Q, and describe fully
the lattices of subfields and of subgroups of the Galois group.
9. Let K be a finite separable extension of a field k, of prime degree p. Let 0 E K be
such that K = k(O), and let 01, ••• , O. be the conjugates of 0 over k in some algebraic
closure. Let 0 = 0r- If O2 E k(O), show that K is Galois and in fact cyclic over k.
10. Let/(X) E Q[XJ be a polynomial of degree n, and let K be a splitting field of/over Q.
Suppose that Gal(K/Q) is the symmetric group Sn with n > 2.
(a) Show that/is irreducible over Q.
(b) If a is a root off, show that the only automorphism of Q(a) is the identity.
(c) If n f; 4, show that a" ¢ Q.
II. A polynomial/(X) is said to be reciprocal if whenever ~ is a root. then
I /~ is also a
root. We suppose that / has coefficients in a subfield k eRe C. If / is irreducible
over k, and has a nonreal root of absolute value I, show that / is reciprocal of even
degree.
12. What is the Galois group over the rationals of X S -
4X + 2?
13. What is the Galois group over the rationals of the following polynomials :
(a) X 4 + 2X 2 + X + 3
(b) X 4 + 3X 3 -
3X - 2
(c) X 6 + 22X s - 9X 4 + 12X 3 - 37X 2 - 29X - 15
[Hint:
Reduce mod 2, 3, 5.J
14. Prove that given a symmetric group S., there exists a polynomial j'(X) E Z[XJ with
leading coefficient 1 whose Galois group over Q is S•. [Hint:
Reducing mod 2, 3, 5,
show that there exists a polynomial whose reductions are such that the Galois group

VI, §Ex
EXERCISES
323
contains enough cycles to generate SOl ' Use the Chinese remainder theorem, also to
be able to apply Eisenstein's criterion.]
15. Let K/k be a Galois extension, and let F be an intermediate field between k and K .
Let H be the subgroup of Gal(K/k) mapping F into itself. Show that H is the normal-
izer of Gal(K/F) in Gal(K/k).
16. Let K /k be a finite Galois extension with group G. Let a E K be such that
{ua} <TEG is a normal basis. For each subset S of G let Sea) = L <TESua . Let H be a
subgroup of G and let F be the fixed field of H. Show that there exists a basis of F
over k consisting of elements of the form Sea).
Cyclotomic fields
17. (a) Let k be a field of characteristic 12n, for some odd integer n ~ 1, and let (be
a primitive n-th root of unity, in k. Show that k also contains a primitive 2n-th
root of unity.
(b) Let k be a finite extension of the rationals . Show that there is only a finite number
of roots of unity in k.
18. (a) Determine which roots of unity lie in the following fields: Q(i), Q(vC"2),
Q(V2), Q(v=3), Q(v3), Q(v=5).
(b) For which integers m does a primitive m-th root of unity have degree 2 over Q?
19. Let (be a primitive n-th root of unity. Let K = Q(O.
(a) If n = p r (r ~ 1) is a prime power, show that NK1Q(l - 0 = p.
(b) If n is composite (divisible by at least two primes) then NKIQ( 1 - 0 = 1.
20. Let f(X) E Z[X] be a non-constant polynomial with integer coefficients. Show that
the values f(a) with a E Z+ are divisible by infinitely many primes.
Note: This is trivial. A much deeper question is whether there are infinitely many
a such thatf(a) is prime. There are three necessary conditions:
The leading coefficient off is positive.
The polynomial is irreducible.
The set of values j'(Z") has no common divisor> 1.
A conjecture of Bouniakowski [Bo 1854] states that these conditions are sufficient.
The conjecture was rediscovered later and generalized to several polynomials by
Schinzel [Sch 58]. A special ease is the conjecture that X2 + 1 represents infinitely
many primes. For a discussion of the general conjecture and a quantitative version
giving a conjectured asymptotic estimate, see Bateman and Horn [BaH 62]. Also see
the comments in [HaR 74]. More precisely, letfl , . .. ,fr be polynomials with integer
coefficients satisfying the first two conditions (positive leading coefficient, irre-
ducible). Let
be their product, and assume thatf satisfies the third condition. Define:
7T(j)(X) = number of positive integers n ;a x such thatfl(n), . . . ,fr(n) are all primes.
(We ignore the finite number of values of n for which some/;(n) is negative.) The

324
GALOIS THEORY
Bateman-Horn conjecture is that
.r
7T(f)(X) -
(d l ••• dr)-IC(f) J(I0~ t)' dt,
o
where
VI, Ex
the product being taken over all primes p, and N/p) is the number of solutions of
the congruence
f(n) ==°mod p .
Bateman and Horn show that the product converges absolutely. When r =
I and
f(n) = an + b with a, b relatively prime integers, a > 0, then one gets Dirichlet's
theorem that there are infinitely many primes in an arithmetic progression, together
with the Dirichlet density of such primes .
[BaH 62)
P. T. BATEMAN and R. HORN, A heuristic asymptotic formula concerning
the distribution of prime numbers, Math . Comp o16(1962) pp. 363-367
[Bo 1854) V. BOUNIAKOWSKY, Sur les diviseurs numeriques invariables des fonc-
tions rationnelles entieres, Memoires sc, math . et phys. T. VI (1854-
1855) pp. 307-329
[HaR 74)
H. HALBERSTAM and H.-E. RICHERT, Sieve methods, Academic Press,
1974
[Sch 58)
A. SCHINZEL and W. SIERPINSKI, Sur certaines hypotheses concernant
les nombres premiers, Acta Arith. 4 (1958) pp. 185-208
21. (a) Let a be a non-zero integer, p a prime , n a positive integer, and p'" n. Prove
that p i <1>n(a) if and only if a has period n in (Z/pZ)*.
(b) Again assume p,( n Prove that p I <1>n(a) for some a E Z if and only if p == I
mod n. Deduce from this that there are infinitely many primes == I mod n, a
special case of Dirichlet's theorem for the existence of primes in an arithmetic
progression.
22. Let F = F, be the prime field of characteristic p . Let K be the field obtained from
F by adjoining all primitive l-th roots of unity, for all prime numbers I "* p. Prove
that K is algebraically closed. [Hint:
Show that if q is a prime number, and r an
integer ~ I, there exists a prime I such that the period of p mod I is q", by using
the following old trick of Van der Waerden: Let I be a prime dividing the number
pqr _ 1
r-'
_ 1
r-'
_2
b=
r-'
=(pq
-I)q
+q(pq
-I)q
+"'+q.
pq
-
I
If{does not dividev: - I, we are done. Otherwise, { = q. But in that case q2 does
not divide b, and hence there exists a prime ( =I q such that I divides b. Then the degree
of F«(,) over F is q",so K contains subfields of arbitrary degree over F.]
23. (a) Let G be a finite abelian group . Prove that there exists an abelian extension of
Q whose Galois group is G.

VI, §Ex
EXERCISES
325
(b) Let k be a finite extension of Q, and G #- {l} a finite abelian group. Prove that
there exist infinitely many abelian extensions of k whose Galois group is G.
24. Prove that there are infinitely many non-zero relatively prime integers a, b such that
-4a3 -
27b2 is a square in Z.
25. Let k be a field such that every finite extension is cyclic . Show that there exists an
automorphism a of k" over k such that k is the fixed field of a.
26. Let Qa be a fixed algebraic closure of Q. Let E be a maximal subfield of Qa not
containing V2 (such a subfield exists by Zorn's lemma) . Show that every finite
extension of E is cyclic . (Your proof should work taking any algebraic irrational
number instead of V2.)
27. Let k be a field, ka an algebraic closure , and a an automorphism of k" leaving k
fixed. Let F be the fixed field of a. Show that every finite extension of F is cyclic.
(The above two problems are examples of Artin, showing how to dig holes in an
algebraically closed field.)
28. Let E be an algebraic extension of k such that every non-constant polynomial f(X)
in k[X] has at least one root in E. Prove that E is algebraically closed. [Hint:
Discuss
the separable and purely inseparable cases separately, and use the primitive element
theorem .]
29. (a) Let K be a cyclic extension of a fieldF, with Galois group Ggenerated by a. Assume
that the characteristic is p, and that [K : F] = pm-1 for some integer m ~ 2.
Let Pbe an element of K such that Tr:(p) = 1. Show that there exists an element
IX in K such that
UIX -
IX = W- p.
(b) Prove that the polynomial XP - X -
IX is irreducible in K[X].
(c) If 0 is a root of this polynomial, prove that F(O) is a Galois, cyclic extension of
degree pm of F, and that its Galois group is generated by an extension u* of a
such that
30. Let A be an abelian group and let G be a finite cyclic group operating on A [by means
of a homomorphism G --+ Aut(A)]. Let a be a generator of G. We define the trace
Tr G = Tr on A by Tr(x) = L rx, Let ATr denote the kernel of the trace, and let
r eG
(1 -
u)A denote the subgroup of A consisting of all elements of type y -
uy. Show that
H1(G, A)
::::;0 ATr/(l -
u)A.
31. Let F be a finite field and K a finite extension of F. Show that the norm N~ and the
trace Tr~ are surjective (as maps from K into F).
32. Let E be a finite separable extension of k, of degree n. Let W = (w I ' .. . , wn) be elements
of E. Let aI' . . . , a; be the distinct embeddings of E in ka over k. Define the dis-
criminant of W to be
Prove:
(a) If V = (V I' .. . , vn) is another set of elements of E and C = (Cij) is a matrix
of elements of k such that Wi = 2: cijvj , then
DE1k(W) = det(C)2DE1k(V).

326
GALOIS THEORY
VI, Ex
(b) The discriminant is an element of k.
(c) Let E = k(Ct.) and let f(X) = Irrt«, k, X) . Let Ct." . . . , Ct.n be the roots off and
say Ct. =
Ct. 1• Then
f'(Ct.) = f1 (Ct. -
Ct.).
j =2
Show that
DE/k(l, a, ... , an-I) = (_l)n(n- ll/2NfU'(a».
(d) Let the notation be as in (a). Show that det(Tr(wjw)
= (det(ajw)2. [Hint:
Let A be the matrix (ajw). Show that 'AA is the matrix (Tr(wjw) .]
Rational functions
33. Let K = C(x) where x is transcendental over C, and let ( be a primitive cube root of
unity in C. Let a be the automorphism of Kover C such that ax = (x . Let t be the
automorphism of Kover C such that rx = X-I. Show that
Show that the group of automorphisms G generated by
(J" and T has order 6 and the
subfield F of K fixed by G is the field C(y) where y = x 3 + x- 3•
34. Give an example of a field K which is of degree 2 over two distinct subfields E and F
respectively, but such that K is not algebraic over E (\ F.
35. Let k be a field and X a variable over k. Let
(X ) = f(X)
cP
g(X)
be a rational function in k(X), expressed as a quotient of two polynomials f, 9 which
are relatively prime . Define the degree of cp to be max(degf, deg g). Let Y = cp(X).
(a) Show that the degree of cp is equal to the degree of the field extension k(X) over k( Y)
(assuming Y rI= k). (b) Show that every automorphism of k(X) over k can be represented
by a rational function cp of degree 1, and is therefore induced by a map
aX + b
XH -
-
-
eX + d
with a, b, c, d e k and ad - be #- O. (c) Let G be the group of automorphisms of k(X)
over k. Show that G is generated by the following automorphisms:
aa:X H aX
(a #- 0),
with a, b E k.
36. Let k be a finite field with qelements. Let K = k(X) be the rational field in one variable.
Let G be the group of automorphisms of K obtained by the mappings
aX + b
XH -
-
-
eX + d

VI, §Ex
EXERCISES
327
with a, b, c, d in k and ad - be #- O. Pro ve the following statements:
(a) The order of G is q3 - q.
(b) The fixed field of G is equal to k( Y) where
(c) Let H I be the subgroup of G consisting of the mappings X f-+ aX + b with
a #- O. The fixed field of HI is k(T) where T = (xq -
X)q- I .
(d) Let Hz be the subgroup of HI consisting of the mappings X --+ X + b with
b e k. The fixed field of Hz is equal to k(Z) where Z = X" - X.
Some aspects of Kummer theory
37. Let k be a field of characteristic O. Assume that for each finite extension E of k, the
index (E* : E*") is finite for every positive integer n. Show that for each positive integer
n, there exists only a finite number of abelian extensions of k of degree n.
38. Let a #- 0, #- ± I be a square-free integer.
For each prime number p, let K; be
the splitt ing field of the polynomial XP - a over Q. Show that [K p : Q] = PeP - 1).
For each square-free integer m > 0, let
be the compositum of all fields K; for plm. Let d.; = [Km : Q] be the degree of K m
over Q. Show that if m is odd then dm = n dp , and if m is even, m = 2n then dz n = d;
plm
or 2dn according as ~ is or is not in the field of m-th roots of unity Q«(m)'
39. Let K be a field of characteristic 0 for simplicity. Let r be a finitely generated subgroup
of K*. Let N be an odd positive integer. Assume that for each prime piN we have
r = tvrr;«.
and also that Gal(K(Il N)/K) ~ Z(N)*. Prove the following.
(a) r/fN = r /(f n K*N) = fK*N /K*N.
(b) Let K N =
K(~N)' Then
[Hint:
Ifthese two groups are not equal, then for some prime piN there exists
an element a E r such that
a = b"
with
bEKN
but
b¢K.
In other words , a is not a p-th power in K but becomes a p-th power in KN • The
equation x" - a is irreducible over K . Show that b has degree p over K(ll p) ,
and that K(ll p , al /P) is not abelian over K, so al /p has degree paver K(ll p).
Finish the proof yourself.]

328
GALOIS THEORY
(c) Conclude that the natural Kummer map
VI, Ex
is an isomorphism.
(d) Let Gr<N) = Gal(K(f l /N, JlN)/K). Then the commutator subgroup of Gr<N)
is Hr<N), and in particular Gal(KN/K) is the maximal abelian quotient of
Gr<N).
40. Let K be a field and p a prime number not equal to the characteristic of K. Let F be a
finitely generated subgroup of K*, and assume that I' is equal to its own p-division
group in K, that is if Z E K and zP E I", then z E r. If p is odd, assume that Jlp c K , and
if p = 2, assume that Jl4 c K. Let
Show that fl iP is its own p-division group in K(fl lp), and
for all positive integers m.
41. Relative invariants (Sato),
Let k be a field and K an extension of k. Let G be a group
of automorphisms of Kover k, and assume that k is the fixed field of G. (We do not
assume that K is algebraic over k.) By a relative invariant of G in K we shall mean an
element P E K, P # 0, such that for each U E G there exists an element X(u)E k for
which P" = X(u)P. Since o is an automorphism, we have X(u) E k*. We say that the
map X: G -+ k* belongs to P, and call it a character. Prove the following statements:
(a) The map Xabove is a homomorphism.
(b) If the same character X belongs to relative invariants P and Q then there
exists C E k* such that P = cQ.
(c) The relative invariants form a multiplicative group, which we denote by I .
Elements PI' . . . , Pm of I are called multiplicatively independent mod k* if
their images in the factor group I/k* are multiplicatively independent, i.e. if
given integers VI' •• • , Vm such that
PI' .., p~m = c e k",
then VI = ... = Vm = O.
(d) If PI> ' .. , Pm are multiplicatively independent mod k* prove that they are
algebraically independent over k. [Hint :
Use Artin's theorem on characters.]
(e) Assume that K = k(X I' • . . , X.) is the quotient field of the polynomial ring
k[X 1>"
" X.] = k[X], and assume that G induces an automorphism of the
polynomial ring. Prove :IfF I (X) and F2(X) are relativeinvariant polynomials,
then their g.c.d. is relative invariant. If P(X) = F I (X)/F2(X) is a relative
invariant, and is the quotient of two relatively prime polynomials, then F I (X)
and F2(X) are relative invariants. Prove that the relative invariant poly-
nomials generate llk", Let S be the set of relative invariant polynomials which
cannot be factored into a product of two relative invariant polynomials of
degrees G 1. Show that the elements of Sfk" are multiplicatively independent,
and hence that l lk" is a free abelian group. [If you know about transcendence
degree, then using (d) you can conclude that this group is finitely generated .]

VI, §Ex
EXERCISES
329
42. Let fez) be a rational function with coefficients in a finite extension of the rationals.
Assume that there are infinitely many roots of unity ' such thatf(O is a root of unity.
Show that there exists an integer n such thatf(z) = cz' for some constant c (which is in
fact a root of unity).
This exercise can be generalized as follows: Let robe a finitely generated multi-
plicative group of complex numbers. Let r be the group of all complex numbers I'
such that I'm lies in r 0 for some integer m i:- O. Let fez) be a rational function with
complex coefficients such that there exist infinitely many I' E r for whichf(y) lies in r .
Then again,f(z) = cz' for some c and n. (Cf. Fundamentals of Diophantine Geometry.)
43. Let K/k be a Galois extension. We define the Krull topology on the group
G(K/k) = G by defining a base for open sets to consist of all sets oii where a E G
and H = G(K/F) for some finite extension F of k contained in K .
(a) Show that if one takes only those sets oii for which F is finite Galois over
k then one obtains another base for the same topology.
(b) The projective limit lim G/H is embedded in the direct product
lim G/H ~ f1 G/H.
II
H
Give the direct product the product topology . By Tychonoff's theorem in
elementary point set topology, the direct product is compact because it is a
direct product of finite groups , which are compact (and of course also discrete) .
Show that the inverse limit li.!!!. G/H is closed in the product, and is therefore
compact.
(c) Conclude that G(K/k) is compact.
(d) Show that every closed subgroup of finite index in G(K/k) is open.
(e) Show that the closed subgroups of G(K/k) are precisely those subgroups
which are of the form G(K/F) for some extension F of k contained in K .
(f)
Let H be an arbitrary subgroup of G and let F be the fixed field of H. Show
that G(K / F) is the closure of H in G.
44. Let k be a field such that every finite extension is cyclic, and having one extension of
degree n for each integer n. Show that the Galois group G = G(kajk) is the inverse limit
lim ZjmZ, as mZ ranges over all ideals of Z, ordered by inclusion. Show that this limit
is isomorphic to the direct product of the limits
taken over all prime numbers p, in other words, it is isomorphic to the product of all
p-adic integers.
45. Let k be a perfect field and ka its algebraic closure. Let a E G(ka/k) be an element
of infinite order, and suppose k is the fixed field of o: For each prime p, let Kp be
the composite of all cyclic extensions of k of degree a power of p.
(a) Prove that ka is the composite of all extensions Kp •
(b) Prove that either Kp = k, or Kp is infinite cyclic over k. In other words, Kp
cannot be finite cyclic over k and "* k.
(c) Suppose k" = Kp for some prime p, so ka is an infinite cyclic tower of
p-extensions. Let u be a p-adic unit, U E Z; such that u does not represent
a rational number. Define a", and prove that a, U
U are linearly independent

330
GALOIS THEORY
VI, Ex
over Z, i.e. the group generated by a and o" is free abelian of rank 2. In
particul ar {a} and {a, aU} have the same fixed field k.
Witt vectors
46. Let XI' Xl ' . . . be a sequence of algebraically independent elements over the integers
Z. For each integer n ~ 1 define
Xln) = L: dX~/d.
din
Show that x, can be expressed in terms of X (d) for din, with rational coefficients.
Using vector notation, we call (XI' X2"
") the Witt components of the vector X,
and call (x(l), x(2), .. .) its ghost components. We call X a Witt vector.
Define the power series
fx(t) = n(l - xnt")·
n ~l
Show that
d
- t -
10gfxCt) = L: x(n)tn.
dt
n~ I
[By ~ logf(t) we meanf'(t)jf(t) iff(t) is a power series, and the derivativef'(t) is taken
dt
formally.]
If x, yare two Witt vectors, define their sum and product componentwise with
respect to the ghost components, i.e.
What is (x + Y)n? Well, show that
fx(t)f/t) = TIo + (x + Y)ntn) = fx+yCt).
Hence (x + Y)n is a polynomial with integer coefficients in x I ' Yl ' . . . ,xn,Yn' Also show
that
fxy(t) = Il (l - x'd/dy,;/etm)de/m
d . e~ 1
where m is the least common multiple of d, e and d, e range over all integers ~ 1. Thus
(xY)n is also a polynomial in XI ' YI . . . , xn, Yn with integer coefficients. The above
arguments are due to Witt (oral communication) and differ from those of his original
paper.
If A is a commutative ring, then taking a homomorphic image of the polynomial
ring over Z into A, we see that we can define addition and multiplication of Witt
vectors with components in A, and that these Witt vectors form a ring W(A). Show
that W is a functor, i.e. that any ring homomorphism ep of A into a commutative ring A'
induces a homomorphism W(ep) : W(A) --+ W(A ').

VI, §Ex
EXERCISES
331
47. Let p be a prime number , and consider the projection of W(A ) on vectors whose
components are indexed by a power of p. Now use the log to the base p to index
these components, so that we write Xn instead of x p. ' For instance, Xo now denotes
what was Xl previously. For a Witt vector X = (xo, X I'
• . • , Xn'
. . .) define
Vx = (0, Xo, X I" ")
and
Fx = (xt, x ~ , .. .).
Thu s V is a shifting operator. We have V 0 F = F 0 V. Show that
(Vx)ln) = pX(·- I)
and
Xl.) = (Fx)l· -l) + p'x•.
Also from the definition, we have
x(n) = xs" + pXf -1+ ... + P~n '
48. Let k be a fieldofcharacteristic p,and consider W(k ). Then V is an add itive endomorph-
ism of W(k),and F is a ring homomorphism of W(k) into itself. Furthermore,ifx E W(k)
then
px = VFx.
If X, y E W(k), then (Vix)( vjy) =
Vi+j(pjX·piy). For a e k denote by {a} the Witt
vector (a, 0, 0, . . .). Then we can write symbolically
X = I
Vi{x.},
i =O
Show that if X E W(k) and Xo #- 0 then X is a unit in W(k). Hint : One has
and then
00
x{xo l } I (vYY = (1- vY) I(Vy)i = 1.
o
0
49. Let n be an integer ~ 1and p a prime number again. Let k be a field of characteristic p.
Let Wik) be the ring of trun cated Witt vecto rs (xo, " " x. _ I ) with components in k.
We view l¥,,(k) as an additive group. IfX E l¥,,(k), define p(x) = Fx - x. Then p is a
homomorphism. If K is a Galois extension of k, and a E G(K/k) , and X E Wn(K) we
can define ax to have component (axo," " ax. _ I ) . Prove the analogue of Hilbert's
Theorem 90 for Witt vectors, and prove that the first cohomology group is trivial. (One
takes a vector whose trace is not 0, and finds a coboundary the same way as in the proof
of Theorem 10.1).
50. Ifx E l¥,,(k), show that there exists ~ E l¥,,(k) such that p ( ~ ) = x. Do this inducti vely,
solving first for the first component, and then showing that a vector (0, (Xl "
' "
(X._ I ) is
in the image of p if and only if «(XI' . • • , (X. _ I ) is in the image of p . Prove inductivel y
that if ~ , r E l¥,,(k') for some extension k' of k and if p ~ =
p~ ' then
~ -
~' is a vector
with components in the prime field. Hence the solutions of p~ = x for given x E l¥,,(k)
all differ by the vectors with components in the prime field, and there are pn such
vectors. We define

332
GALOIS THEORY
or symbolically,
VI, Ex
Prove that it is a Galois extension of k, and show that the cyclic extensions of k, of
degree p", are precisely those of type k(f.J - 1x) with a vector x such that Xo ¢ f.Jk.
51. Develop the Kummer theory for abelian extensions of k of exponent p" by using f-Y,,(k).
In other words, show that there is a bijection between subgroups B of f-Y,,(k) containing
f.J f-Y,,(k) and abelian extensions as above, given by
B 1-+ K B
where KB = k(f.J-1B) . All of this is due to Witt, cf. the references at the end of §8,
especially [Wi 37]. The proofs are the same , mutatis mutandis, as those given for
the Kummer theory in the text.
Further Progress and directions
Major progress was made in the 90s concerning some problems mentioned in the
chapter. Foremost was Wiles's proof of enough of the Shimura-Taniyama conjecture to
imply Fermat's Last Theorem [WiI95], [TaW 95].
[TaW 95] R. TAYLOR and A. WILES, Ring-theoretic properties or certain Heeke alge-
bras, Annals of Math. 141 (1995) pp. 553-572
[Wil 95]
A. WILES, Modular elliptic curves and Fermat's last theorem, Annals. of
Math. 141 (1995) pp. 443-551
Then a proof of the complete Shimura-Taniyama conjecture was given in [BrCDT 01].
[BrCDT 0I] C. BREUIL, B. CONRAD, F. DIAMOND, R. TAYLOR, On the modularity of el-
liptic curves over Q: Wild 3-adic exercises, 1. Amer. Math. Soc. 14 (2001)
pp. 843-839
In a quite different direction, Neukirch started the characterization of number fields
by their absolute Galois groups [Ne 68], [Ne 69a], [Ne 69b], and proved it for Galois
extensions of Q. His results were extended and his subsequent conjectures were proved
by Ikeda and Uchida [Ik 77], [Uch 77], [Uch 79], [Uch 81]. These results were extended
to finitely generated extensions of Q (function fields) by Pop [Pop 94], who has a more
extensive bibliography on these and related questions of algebraic geometry. For these
references, see the bibliography at the end of the book.

CHAPTER VII
Extensions of Rings
It is not always desirable to deal only with field extensions. Sometimes one
wants to obtain a field extension by reducing a ring extension modulo a prime
ideal. This procedure occurs in several contexts, and so we are led to give the
basic theory of Galois automorphisms over rings , looking especially at how the
Galois automorphisms operate on prime ideals or the residue class fields. The
two examples given after Theorem 2.9 show the importance of working over
rings, to get families of extensions in two very different contexts.
Throughout this chapter, A, B, C will denote commutative rings.
§1.
INTEGRAL RING EXTENSIONS
In Chapters V and VI we have studied algebraic extensions of fields. For a
number of reasons, it is desirable to study algebraic extensions of rings .
For instance, given a polynomial with integer coefficients, say X 5 - X-I,
one can reduce this polynomial mod p for any prime p, and thus get a poly-
nomial with coefficients in a finite field. As another example, consider the
polynomial
where Sn-l' . . . , So are algebraically independent over a field k. This poly-
nomial has coefficients in k[so, . . . , Sn-l] and by substituting elements of k for
So, . . . , Sn-l one obtains a polynomial with coefficients in k. One can then get
333
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

334
EXTENSION OF RINGS
VII, §1
information about polynomials by taking a homomorphism of the ring in
which they have their coefficients. This chapter is devoted to a brief description
of the basic facts concerning polynomials over rings .
Let M be an A-module. We say that M is faithful if, whenever a E A is such
that aM = 0, then a = O. We note that A is a faithful module over itself since
A contains a unit element. Furthermore, if A *" 0, then a faithful module over
A cannot be the O-module.
Let A be a subring of B. Let a E B. The following conditions are equivalent:
(NT I.
The element a is a root of a polynomial
X" + (/,, _I X,,-1 + ... + (/ 0
with coefficients aj E A, and degree n ~ I. (The essential thing here
is that the leading coefficient is equal to I.)
(NT 2.
The subring ALa] is a finitely generated A-module.
(NT 3.
There exists a faithful module over A[a] which is a finitely gener-
ated A-module.
We prove the equivalence. Assume (NT I.
Let g(X) be a polynomial
in A[X] of degree ~ I with leading coefficient
I such that g(a) = O. If
I(X) E A[X] then
I (X ) = q(X)g(X) + reX)
with q, r E A [ X ] and deg r < deg g.
Hence I (a) = rea), and we see that if
deg g = II, then I , a, . . . , r:x,,- I are generators of A[ex] as a module over A .
An equation g(X) = 0 with g as above, such that g(a) = 0 is called an
integral equation for a over A.
Assume (NT 2. We let the module be A[a] itself.
Assume (NT 3, and let M be the faithful module over A[ex] which is finitely
generated over A, say by elements WI ' . .. , Wno Since «M c M there exist ele-
ments aij E A such that
Transposing «wI' . . . , exlV" to the right-hand side of these equations, we con-
clude that the determinant
ex - all
(J. -
(/ 22
-aij
d=

VII, §1
INTEGRAL RING EXTENSIONS
335
is such that dM = O. (This will be proved in the chapter when we deal with
determinants.) Since M is faithful, we must have d = O. Hence IY. is a root of
the polynomial
det(X ();) - a;),
which gives an integral equation for
!Y. over A.
An element
IY. satisfying the three conditions INT I, 2, 3 is called integral
over A.
Proposition 1.1.
Let A be an entire ring and K its quotient field . Let IY. be
algebraic over K . Then there exists an element c =F 0 ill A such that CIY. is
integral over A.
Proof.
There exists an equation
with aj E A and an =F O. Multiply it by a~ - I. Then
(«,«)" + ... + aoa~ - 1 = 0
is an integral equation for a;« over A. This proves the proposition.
Let A C B be subrings of a commutative ring C, and let a E C. If a is integral
over A then a is a fortiori integral over B. Thus integrality is preserved under
lifting. In particular, a is integral over any ring which is intermediate between
A and B .
Let B contain A as a subring. We shall say that B is integral over A if every
element of B is integral over A .
Proposition 1.2.
IfB is integral over A andfinitely generated as an A-algebra,
then B is finitely generated as an A-module.
Proof.
We may prove this by induction on the number of ring generators,
and thus we may assume that B = A[IY.] for some element IY. integral over A, by
considering a tower
But we have already seen that our assertion is true in that case, this being part
of the definition of integrality.
Just as we did for extension fields, one may define a class e of extension
rings A c B to be distinguished if it satisfies the analogous properties, namely :
(1) Let A c
B c C be a tower of rings.
The extension A c C is in e if
and only if A c B is in e and B c C is in e.
(2) If A c B is in e, if C is any extension ring of A, and if B, C are both
subrings of some ring, then C c B[C]
is in e.
(We
note that
B[C] = C[B] is the smallest ring containing both B and C.)

336
EXTENSION OF RINGS
VII, §1
As with fields, we find formally as a consequence of (1) and (2) that (3) holds,
namely :
(3) If A c B and A c C are in e, and B, Care subrings of some ring,
then A c B[C] is in e.
Proposition 1.3.
Integral ring extensionsform a distinguished class.
Proof.
Let A C B C C be a tower of rings. If C is integral over A, then it
is clear that B is integral over A and C is integral over B. Conversely, assume
that each step in the tower is integral. Let a E C. Then a satisfies an integral
equation
an + bn_Ian- 1 + ... + bo = 0
with b.e B. Let B I = A[bo, .. . ,bn _ l ].
Then B I is a finitely generated A-
module by Proposition 1.2, and is obviously faithful. Then BI[a] is finite over
B I , hence over A, and hence a is integral over A. Hence C is integral over A.
Finally let B, C be extension rings of A and assume B integral over A. Assume
that B, Care subrings of some ring. Then C[B] is generated by elements of
B over C, and each element of B is integral over C. That C[B] is integral over
C will follow immediately from our next proposition.
Proposition 1.4.
Let A be a subring of C. Then the elements of C which are
integral over A form a subring ofc.
Proof.
Let a, pE C be integral over A. Let M = A[a] and N = A[PJ.
Then M N contains 1, and is therefore faithful as an A-module. Funhermore,
aM c M and pN c N.
Hence MN is mapped into itself by multiplication
with a ± Pand ap. Furthermore M N is finitely generated over A (if {wJ are
generators of M and {Vj} are generators of N then {wjVj} are generators of
MN). This proves our proposition.
In Proposition 1.4, the set of elements of C which are integral over A is
called the Integral closure of A in C
Example.
Consider the integers Z . Let K be a finite extension of Q. We
call K a number field . The integral closure of Z in K is called the ring of
algebraic integers of K . This is the most classical example.
In algebraic geometry, one considers a finitely generated entire ring Rover
Z or over a field k. Let F be the quotient field of R . One then considers the
integral closure of R in F, which is proved to be finite over R. If K is a finite
extension of F, one also considers the integral closure of R in K.
Proposition 1.5.
Let A c B be an extension ring, and let B be integral
over A. Let a be a homomorphism of B. Then a(B) is integral over a(A).
Proof.
Let a E B, and let
an+ an_lan-I + ... + ao = 0

VII, §1
INTEGRAL RING EXTENSIONS
337
be an integral equation for a over A. Applying (J yields
c(«)" + (J(an _1)(J(a)n-l + ... + (J(ao) = 0,
thereby proving our assertion.
Corollary 1.6.
Let A be an entire ring, k its quotient field, and E a finite
extension of k. Let a E E be integral over A. Then the norm and trace of a
(from E to k) are integral over A, and so are the coefficients ofthe irreducible
polynomial satisfied by a over k.
Proof.
For each embedding (J of E over k, a« is integral over A. Since the
norm is the product of (Ja over all such (J (raised to a power of the characteristic),
it follows that the norm is integral over A. Similarly for the trace, and similarly
for the coefficients of Irrt«, k, X), which are elementary symmetric functions of
the roots.
Let A be an entire ring and k its quotient field. We say that A is integrally
closed if it is equal to its integral closure in k.
Proposition 1.7.
Let A be entire andfactorial. Then A is integrally closed.
Proof.
Suppose that there exists a quotient alb with a, b E A which is
integral over A, and a prime element p in A which divides b but not a. We have ,
for some integer n ~ 1, and a, E A,
(a/b)n + an_l(a/br - 1+ ... + ao =°
whence
an + an _ 1ban- 1 + ... + aobn = 0.
Since p divides b, it must divide an, and hence must divide a, contradiction.
Let f :A -> B be a ring-homomorphism (A, B being commutative rings).
We recall that such a homomorphism is also called an A-algebra. We may
view B as an A-module. We say that B is integral over A (for this ring-homo-
morphism f) if B is integral over f(A). This extension of our definition of
integrality is useful because there are applications when certain collapsings take
place, and we still wish to speak of integrality. Strictly speaking we should
not say that B is integral over A, but that f is an integral ring-homomorphism,
or simply that f is integral. We shall use this terminology frequently.
Some of our preceding propositions have immediate consequences for
integral ring-homomorphisms; for instance, if f :A -> Band g : B -> Care
integral, then g
0 f :A -> C is integral. However, it is not necessarily true that
if g 0 f is integral, so isf.
Let f :A -> B be integral, and let S be a multiplicative subset of A. Then
we get a homomorphism
S-If : S- IA -> S-IB,
where strictly speaking, s: B = (f(S))-1 B, and s:'] is defined by
(S- If)(X/S) = f(x)/f(s).

338
EXTENSION OF RINGS
VII, §1
It is trivially verified that this is a homomorphism. We have a commutative
diagram
B -----> S-IB
f[
IS-'f
A -----> S-I A
the horizontal maps being the canonical ones: x -+ x/I.
Proposition 1.8.
Let f: A -+ B be integral, and let S be a multiplicative
subset of A. Then S- If: S" IA -+ S- IB is integral.
Proof.
If a E B is integral over f(A), then writing ap instead off(a)p,for
a E A and pE B we have
with aj E A. Taking the canonical image in S-I A and S-IB respectively, we
see that this relation proves the integrality of a/lover S-! A, the coefficients
being now aj/l.
Proposition 1.9.
Let A be entire and integrally closed. Let S be a multipli-
cative subset of A, 0 ¢ S. Then S-I A is integrally closed.
Proof.
Let a be an element of the quotient field, integral over S-IA. We
have an equation
n
an -
!
n-I
ao
0
a + - -a
+ '''+ -=,
Sn-I
So
ai E A and s, E S. Let s be the product Sn-I . . . so. Then it is clear that sa is
integral over A, whence in A. Hence a lies in S-IA, and S-! A is integrally
closed.
Let p be a prime ideal of a ring A and let S be the complement of p in A.
We write S = A - p. Iff :A -+ B is an A-algebra (i.e. a ring-homomorphism),
we shall write Bp instead of S-IB. We can view Bp as an Ap = S-IA-module.
Let A be a subring of B. Let p be a prime ideal of A and let 'lJ be a prime
ideal of B. We say that 'lJ lies above p if'lJ (l A = p. If that is the case, then
the injection A -+ B induces an injection of the factor rings
A/p -+ B/'lJ,
and in fact we have a commutative diagram:
B -----> B/'lJ
[
[
A -----> A/p

VII, §1
INTEGRAL RING EXTENSIONS
339
the horizontal arrows being the canonical homomorphisms, and the vertical
arrows being injections.
If B is integral over A, then B/~ is integral over Alp by Proposition 1.5.
Proposition 1.10.
Let A be a subrinq oj B, let p be a prime ideal oj A, and
assume B integral over A. Then pB '" B and there exists a prime ideal ~ oj
B lying above p.
Proof.
We know that Bp is integral over Ap and that Ap is a local ring
with max imal ideal m p = S-lp, where S = A - p. Since we obviously have
pBp = pApBp = mpBp,
it will suffice to prove our first assertion when A is a local ring. (Note that the
existence of a prime ideal p implies that 1 '" 0, and pB = B if and only if 1 E pB.)
In that case, if pB = B, then 1 has an expression as a finite linear combination
of elements of B with coefficients in p,
1 = albl + ... + a.b,
with a, E p and b, E B. We shall now use notation as if Ap c Bp • We leave it
to the reader as an exercise to verify that our arguments are valid when we
deal only with a canonical homomorphism Ap -+ Bp • Let Bo = A[b l , .. . , bnl
Then pBo = Bo and Bo is a finite A-module by Proposition 1.2. Hence Bo =°
by Nakayama's lemma, contradiction. (See Lemma 4.1 of Chapter X.)
To prove our second assertion, note the following commutative diagram:
A----> A p
We have just proved mpBp '" Bp • Hence mpBpis contained in a maximal ideal
9Jl of Bp • Taking inverse images, we see that the inverse image of 9Jl in Ap is an
ideal containing mp (in the case of an inclusion Ap C Bp the inverse image is
9Jl (\ Ap). Since mp is maximal, we have 9Jl (\ Ap = mp' Let ~ be the inverse
image of 9Jl in B (in the case of inclusion, ~ = 9Jl (\ B). Then ~ is a prime
ideal of B. The inverse image of m, in A is simply p, Taking the inverse image
of 9Jl going around both ways in the diagram, we find that
~ (\ A = o,
as was to be shown.
Proposition 1.11.
Let A be a subring oj B, and assume that B is integral
over A. Let ~ be a prime idealof B lying over a primeideal p ojA. Then ~
is maximal if and only if p is maximal.

340
EXTENSION OF RINGS
VII, §2
Proof.
Assume p maximal in A. Then A/p is a field, and B/~ is an entire
ring, integral over A/p. If a E B/~, then a is algebraic over A/ p, and we know
that A/p[a] is a field. Hence every non-zero element of B/~ is invertible in
B/~ , which is therefore a field. Con versely, assume that ~ is maximal in B.
Then B/~ is a field, which is integral over the entire ring A/p . If A /p is not a
field, it has a non-zero maximal ideal m. By Proposition 1.10, there exists a
prime ideal IDl of B/~ lying above m, IDl =1= 0,contradiction.
§2.
INTEGRAL GALOIS EXTENSIONS
We shall now investigate the relationship between the Galois theory of a
polynomial, and the Galois theory of this same polynomial reduced modulo a
prime ideal.
Proposition 2.1.
Let A be an entire ring, integrally closed in its quotient
field K . Let L be a finite Galois extension of K with group G. Let p be a
maximal ideal of A, and let ~, 0 be prime ideals of the integral closure B of
A in L lying above p. Then there exists a E G such that a~ = 0 .
Proof.
Suppose that 0
=1= a~ for any a E G. Then TO =1= a~ for any pair
of elements a, T E G. There exists an element x E B such that
x ==° (mod a~) ,
x == I
(mod aO),
all a E G
alI a E G
(use the Chinese remainder theorem). The norm
N~(x) = Il ax
a e G
lies in B n K = A (because A is integrally closed), and lies in ~ n A = p.
But x rt aO for all a E G, so that ax rt 0 for all a E G. This contradicts the fact
that the norm of x lies in p = 0 n A.
If one localizes, one can eliminate the hypothesis that p is maximal; just
assume that p is prime.
Corollary 2.2
Let A be integrally closed in its quotient field K. Let E be a
finite separable extension of K, and B the integral closure ofA in E. Let p be
a maximal ideal ofA . Then there exists only a finite number ofprime ideals of
B lying above p.
Proof.
Let L be the smallest Galois extension of K containing E. If 0 1,
O 2 are two distinct prime ideals of B lying above p, and ~I ' ~2 are two prime
ideals of the integral closure of A in L lying above 0 1 and O 2 respectively, then
~ I
=1= ~ 2 ' This argument reduces our assertion to the case that E is Galois
over K, and it then becomes an immediate consequence of the proposition.

VII, §2
INTEGRAL GALOIS EXTENSIONS
341
Let A be integrally closed in its quotient field K, and let B be its integral
closure in a finite Galois extension L, with group G. Then aB = B for every
a E G. Let p be a maximal ideal of A, and ~ a maximal ideal of B lying above p,
We denote by G'll the subgroup of G consisting of those automorphisms such
that a~ =~ . Then G'll operates in a natural way on the residue class field
B/~ , and leaves A/p fixed. To each a E G'll we can associate an automorphism
ii of B/~ over A/p, and the map given by
induces a homomorphism of G'll into the group of automorphisms of B/~
over A/p.
The group G'll will be called the decomposition group of~.
Its fixed field
will be denoted by tr-, and wi11 be called the decomposition field of~ . Let
B dec be the integral closure of A in Ldec, and 0 = ~ II B dec. By Proposition 2.1,
we know that ~ is the only prime of B lying above 0.
Let G = UajG'll be a coset decomposition of G'll in G. Then the prime
ideals aj ~ are precisely the distinct primes of B lying above p. Indeed, for two
elements a, rEG we have a~ = r~ if and only if r -la~ = ~, i.e. r -1a lies in
G'll' Thus r, a lie in the same coset mod G'll'
It is then immediately clear that the decomposition group of a prime a~
is aG'lla -l.
Proposition 2.3.
The field Ldec is the smallest subfie ld E of L containing
K such that ~ is the only prime of B lying above ~ II E (which is prime in
B II E).
Proof.
Let E be as above, and let H be the Galois group of Lover E. Let
q = ~ II E. By Proposition 2.1, all primes of B lying above q are conjugate by
elements of H. Since there is only one prime, namely 'l3, it means that H leaves
'l3 invariant.
Hence G c G'll and E
::::J Ldec. We have alread y observed that
L dec has the required property.
Proposition 2.4.
Notation being as above, we have A/p = Bdec/o (under
the canonical injection A/p --+ Bdec/O) .
Proof.
If a is an element of G, not in G'll' then a~ i= ~ and a -I~ i= ~ .
Let
Then 0/1 i= O. Let x be an element of B dec. There exists an element y of B dec
such that
y == x
(mod 0)
y == 1
(mod 0(1)

342
EXTENSION OF RINGS
for each a in G, but not in G'll ' Hence in particular,
y == x
(mod ill)
y == 1
(mod a -I~)
for each a not in G'll ' This second congruence yields
ay == 1
(mod B)
VII, §2
for all a ¢ G$' The norm of y from Ldec to K is a product of y and other factors
ay with a ¢ G$' Thus we obtain
But the norm lies in K , and even in A, since it is a product of elements integral
over A. This last congruence holds mod .0, since both x and the norm lie in
Bdec. This is precisely the meaning of the assertion in our proposition.
If x is an element of B, we shall denote by x its image under the homo-
morphism B -+ B/~. Then ii is the automorphism of B/~ satisfying the relation
iix = (ax) .
If f(X) is a polynomial with coefficients in B, we denote by J(X) its natural
image under the above homomorphism. Thus, if
then
Proposition 2.5.
Let A be integrally closed in its quotient field K, and let
B be its integral closure in a finite Galois extension L of K, with group G.
Let p be a maximal ideal of A, and ~ a maximal ideal of B lying above p,
Then B/~ is a normal extension of All', and the map a ~ ii induces a homo-
morphism of G'll onto the Galoisgroup of B/~ over Alp.
Proof.
Let B = B/~ and it = Alp. Any element of B can be written as
xfor some x E B. Let xgenerate a separable subextension of B over it, and let
f be the irreducible polynomial for x over K . The coefficients of f lie in A
because x is integral over A, and all the roots offare integral over A. Thus
m
f(X) = n (X - xJ
i = I

VII, §2
splits into linear factors in B. Since
INTEGRAL GALOIS EXTENSIONS
343
m
J(X) = L (X -
Xi)
j ;
I
and all the Xi lie in 13, it follows thatJsplits into linear factors in 13. We observe
that f(x) = 0 implies f(x) = O. Hence 13 is normal over A, and
[A(x) : A] ~ [K(x) : K] ~ [L: K].
This implies that the maximal separable subextension of A in 13 is of finite
degree over A (using the primitive element theorem of elementary field theory).
This degree is in fact bounded by [L : K].
There remains to prove that the map a H a gives a surjective homo-
morphism of G'.Il onto the Galois group of 13 over A. To do this, we shall give
an argument which reduces our problem to the case when ~ is the only prime
ideal of B lying above p. Indeed, by Proposition 2.4, the residue class fields of
the ground ring and the ring Bdec in the decomposition field are the same.
This means that to prove our surjectivity, we may take Ldec as ground field.
This is the desired reduction, and we can assume K = Ldec, G = G'.Il'
This being the case, take a generator of the maximal separable subextension
of 13 over A, and let it be .x, for some element x in B. Let f be the irreducible
polynomial of x over K. Any automorphism of 13 is determined by its effect
on X, and maps .x on some root off. Suppose that x = x I' Given any root Xi
off, there exists an element a of G = G'll such that ax = X i ' Hence ax = Xi'
Hence the automorphisms of 13 over A induced by elements of G operate
transitively on the roots of f. Hence they give us all automorphisms of the
residue class field, as was to be shown.
Corollary 2.6.
Let A be integrally closed in its quotient field K. Let L be a
finite Galois extension of K, and B the integral closure of A in L. Let p be a
maximal ideal ofA. Let tp : A -
Alp be the canonical homomorphism, and let
l/J}. l/J2 be two homomorphisms of B extending tp in a given algebraic closure
of Alp, Then there exists an automorphism
(T of Lover K such that
l/J I = ljJ20 a.
Proof.
The kernels of ljJ I' ljJ 2 are prime ideals of B which are conjugate
by Proposition 2.1. Hence there exists an element r of the Galois group G
such that ljJI, ljJ2
0 r have the same kernel. Without loss of generality, we may
therefore assume that ljJ 1, ljJ 2 have the same kernel B. Hence there exists an
automorphism to of ljJ I(B) onto ljJ iB) such that w
0 ljJ 1 = ljJ 2' There exists an
element a of G'll such that w
0 ljJ I = ljJ l oa, by the preceding proposition. This
proves what we wanted.

344
EXTENSION OF RINGS
VII, §2
Remark.
In all the above propositions, we could assume p prime instead
of maximal. In that case, one has to localize at p to be able to apply our proofs.
In the above discussions , the kernel of the map
is called the inertia group of 'lJ. It consists of tho se automorphisms of G'4l
which induce the trivial automorphism on the residue class field. Its fixed field
is called the inertia field. and is denoted by Lin.
Corollary 2.7.
Let the assumptions be as in Corollary 2.6 and assume that
'lJ is the only prime of B lying above p. Let f(X) be a polynomial in A[X]
with leading coefficient 1. Assume that f is irreducible in K[X], and has a
root a in B. Then the reduced polynomialJ is a powerofan irreducible poly-
nomial in A[Xl
Proof.
By Corollary 2.6, we know that any two roots ofJare conjugate
under some isomorphism of Bover A, and hence thatj'cannot split into relative
prime polynomials. Therefore,1is a power of an irreducible polynomial.
Proposition 2.8.
Let A be an entire ring, integrally closed in its quotient
field K. Let L be a finite Galois extension of K. Let L = K(r:x), where r:x is
integral over A, and let
be the irreducible polynomial of r:x over k, with aj EA. Let p be a maximal
ideal in A, let 'lJ be a primeideal of the integral closure B of A in L, 'lJ lying
above p. Let J(X) be the reduced polynomial with coefficients in A/p. Let
G'4l be the decomposition group. If J has no multiple roots, then the map
a 1-+ (i has trivial kernel,and is an isomorphism of G'4l on the Galoisgroupof
lover A/p.
Proof.
Let
f(X) = TI (X - x.)
be the factorization of fin L. We know that all Xi E B. If a E G'4l' then we
denote by (i the homomorphic image of a in the group G'4l' as before. We
have
l eX ) = TI (X - xJ
Suppose that (ixi = Xi for all i. Since (axJ = (ixi , and since j'has no multiple
roots, it follows that a is also the identity. Hence our map is inject ive, the in-
ertia group is trivial. The field A[x l , • • • , Xn] is a subfield of B and any auto-

VII, §2
INTEGRAL GALOIS EXTENSIONS
345
morphism of 13 over A which restricts to the identity on this subfield must be
the identity, because the map G'lJ -+ G'lJ is onto the Galois group of 13 over A.
Hence 13 is purely inseparable over A[xb
. . . , xn] and therefore G'lJ is iso-
morphic to the Galois group ofJover if.
Proposition 2.8 is only a special case of the more-general situation when
the root of a polynomial does not necessarily generate a Galois extension. We
state a version useful to compute Galois groups.
Theorem 2.9.
Let A be an entire ring, integrallyclosed in its quotientfield
K.
Let f(X) E A[X] have leading coefficient 1 and be irreducible over K
(or A, it's the samething). Let p bea maximalidealofA andletJ = f mod p.
Suppose that J has no multiple roots in an algebraic closure of A/p. Let
L be a splittingfield for f over K, and let B be the integral closure of A in
L. Let ~ be any prime of B above p and let a bar denote reduction mod p.
Then the map
G'lJ-+ G'lJ
is an isomorphism of G'lJ with the Galois groupofJ overif.
Proof.
Let (IXl' .. . , IXn) be the roots off in B and let (iil' .. . , iin) be their
reductions mod B. Since
n
f(X) = n (X -
IX;),
i = 1
it follows that
n
J(x) = n (X - iiJ
i= 1
Any element of G is determined by its effect as a permutation of the roots, and
for (J E G'lJ' we have
Hence if if = id then (J = id, so the map G'lJ -+ G'lJ is injective. It is surjective
by Proposition 2.5, so the theorem is proved.
This theorem justifies the statement used to compute Galois groups in Chapter
VI, §2.
Theorem 2.9 gives a very efficient tool for analyzing polynomials over a
nng.
Example.
Consider the" generic" polynomial

346
EXTENSION OF RINGS
VII, §3
where wo, . .. , Wn - \ are algebraically independent over a field k . We know that
the Galoi s group of this polynomial over the field K = k(wo , . . . , wn- \ ) is the
symmetric group . Let f l , .. . , fn be the roots . Let a be a generator of the splitting
field L ; that is, L = K(a) . Without loss of generality, we can select a to be
integral over the ring k[wo, . .. , Wn- I ](multiply any given generator by a suitably
chosen polynomial and use Proposition 1.1) . Let 9w(X) be the irreducible poly-
nomial of a over k(wo, . .. , Wn -I) ' The coefficients of 9 are polynomials in (w) .
If we can substitute values (a) for (w) with ao, . . . , an-j E k such that 9a remains
irreducible, then by Proposition 2.8 we conclude at once that the Galois group
of 9a is the symmetric group also . Similarly, if a finite Galois extension of
k(wo, . . . , wn- \ ) has Galois group G, then we can do a similar substitution to
get a Galois extension of k having Galoi s group G, provided the special polynomial
9a remains irreducible.
Example.
Let K be a number field; that is, a finite extension of Q. Let 0
be the ring of algebraic integers. Let L be a finite Galois extension of K and 0
the algebraic integers in L. Let p be a prime of 0 and ~ a prime of 0 lying above
p. Then o/p is a finite field, say with q elements. Then O/~ is a finite~xtension
of «[», and by the theory of finite fields, there is a unique element in G'll' called
the Frobenius element Fr'll' such that Fr'll(i) = i q for i E D/'.J3. The conditions
of Theorem 2.9 are satisfied for all but a finite number of primes p, and for such
primes, there is a unique element Fr'll E G'll such that Fr'll(x) == ~ mod ~ for all
x EO . We call Fr'll the Frobenius element in G'll ' Cf. Chapter VI, §15, where
some of the significance of the Frobenius element is explained.
§3.
EXTENSION OF HOMOMORPHISMS
When we first discussed the process of localization, we considered very
briefly the extension of a homomorphism to a local ring. In our discussion of
field theory, we also described an extension theorem for embeddings of one
field into another. We shall now treat the extension question in full generality.
First we recall the case of a local ring . Let A be a commutative ring and p
a prime ideal. We know that the local ring Ap is the set of all fractions x/y, with
x, yEA and y ¢; p. Its maximal ideal consists of those fractions with x E p. Let
L be a field and let cp: A ~ L be a homomorphism whose kernel is p. Then we
can extend cp to a homomorphism of Ap into L by letting
<p(xjy) = <p(x)j<p(y)
if xjy is an element of A p as above.
Second, we have integral ring extensions. Let 0 be a local ring with maximal
ideal m, let B be integral over 0, and let <p : 0 -> L be a homomorphism of 0

VII, §3
EXTENSION OF HOMOMORPHISMS
347
into an algebraically closed field L. We assume that the kernel of cp is m. By
Proposition 1.10,we know that there exists a maximal ideal 9Jl of B lying above
m, i.e. such that Wl n 0 = m. Then B/'JR is a field, which is an algebraic exten-
sion of o/m, and o/m is isomorphic to the subfield cp(0) of L because the kernel
of cp is m.
We can find an isomorphism of o/m onto cp(o) such that the composite
homomorphism
0-+ o/m -+ L
is equal to ip. We now embed B/Wl into L so as to make the following diagram
commutative :
B ----------> B/9Jl
1
1 ~
o ----------> 0/m ----------> L
and in this way get a homomorphism of B into L which extends cp.
Proposition 3.1.
Let A be a subring of B and assume that B is integral over
A. Let cp :A -+ L be a homomorphism into a field L which is algebraically
closed. Then cp has an extension to a homomorphism of B into L.
Proof.
Let p be the kernel of cp and let S be the complement of p in A.
Then we have a commutative diagram
and cp can be factored through the canonical homomorphism of A into S- 1A.
Furthermore, S-I B is integral over S-I A. This reduces the question to the
case when we deal with a local ring, which has just been discussed above.
Theorem 3.2.
Let A be a subrinq of a field K and let x E K, x i= 0. Let
cp :A -+ L be a homomorphism of A into an algebraically closed field L.
Then cp has an extension to a homomorphism of A[x] or A[x- I ] into L.
Proof'.
We may first extend cp to a homomorphism of the local ring AI"
where p is the kernel of cp. Thus without loss of generality, we may assume that
A is a local ring with maximal ideal m. Suppose that

348
EXTENSION OF RINGS
Then we can write
VII, §3
with a, E m. Multiplying by x" we obtain
(1 - ao)x" + b"_tx"-t + .., + bo = °
with suitable elements b, E A. Since ao E m, it follows that 1 - ao ¢ m and
hence I - ao is a unit in A because A is assumed to be a local ring. Dividing
by I -
ao we see that x is integral over A, and hence that our homomorphism
has an extension to A[x ] by Proposition 3.1.
If on the other hand we have
mA[x - l ]
=1= A[x- I ]
then mA[[ I] is contained in some maximal ideal IlJ of A[x - I] and IlJ (') A
contains m. Since m is maximal, we must have IlJ (') A = m. Since qJ and the
canonical map A --+ A/m have the same kernel, namely m, we can find an
embedding IjJ of A/m into L such that the composite map
A --+ A/m !. L
is equal to qJ.
We note that A/m is canonically embedded in B/1lJ where
B = A[x- I ] , and extend IjJ to a homomorphism of B/1lJ into L, which we can
do whether the image of x" I in B/1lJ is transcendental or algebraic over A/m .
The composite B --+ B/1lJ --+ L gives us what we want.
Corollary 3.3.
Let A be a subring of a field K and let L be an algebraically
closed fie ld. Let tp : A --+ L be a homomorphism. Let B be a maximal subring
of K to which qJ has an ex tension homomorphism into L. Th en B is a local
ring and if x E K , x
=1= 0, then x E B or X - I E B.
Proof .
Let S be the set of pairs (C, 1jJ) where C is a subring of K and
1jJ : C --+ L is a homomorphism extending ip. Then S is not empty (containing
(A, qJ)], and is partially ordered by ascending inclusion and restriction.
In
other words, (C, 1jJ) ~ (C', 1jJ') if C c C' and the restriction of 1jJ' to C is equal
to 1jJ. It is clear that S is inductively ordered, and by Zorn's lemma there exists
a maximal element, say (B, ljJo)' Then first B is a local ring, otherwise ljJoextends
to the local ring arising from the kernel, and second, B has the desired property
according to Theorem 3.2.
Let B be a subring of a field K having the property that given x E K , x
=1= 0,
then x E B or x-I E B. Then we call B a valuation ring in K. We shall study
such rings in greater detail in Chapter XII. However, we shall also give some
applications in the next chapter, so we make some more comments here.

VII, §3
EXTENSION OF HOMOMORPHISMS
349
Let F be a field. We let the symbol 00 satisfy the usual algebraic rules. If
a E F, we define
a ± 00 = 00,
a · oo= oo
if
a
¥ 0,
1
and
1
00 ' 00 = 00,
- = 00
-
= 0.
0
00
The expressions 00 ± 00, 0· 00, 0/0, and 00/00 are not defined.
A place qJ of a field K into a field F is a mapping
qJ : K --+ {F, oo}
of K into the set consisting of F and 00 satisfying the usual rules for a homo-
morphism, namely
qJ(a + b) = qJ(a) + qJ(b),
qJ(ab) = qJ(a)qJ(b)
whenever the expressions on the right-hand side of these formulas are defined,
and such that qJ(l) = 1. We shall also say that the place is F-valued. The
elements of K which are not mapped into 00 will be called finite under the place,
and the others will be called infinite.
The reader will verify at once that the set 0 of elements of K which are
finite under a place is a valuation ring of K. The maximal ideal consists of those
elements x such that qJ(x) = O. Conversely, if 0 is a valuation ring of K with
maximal ideal m, we let qJ : 0 --+ o/m be the canonical homomorphism, and
define qJ(x) = 00 for x E K, x ~ o. Then it is trivially verified that qJ is a place.
If qJI : K --+ {FI' oo} and qJ2 : K --+ {F2' 00} are places of K, we take their
restrictions to their images. We may therefore assume that they are surjective.
We shall say that they are equivalent if there exists an isomorphism A. : F 1 --+ F 2
such that lfJ2 = lfJI
0 A..
(We put ,1,(00) = 00.) One sees that two places are
equivalent if and only if they have the same valuation ring. It is clear that there
is a bijection between equivalence classes of places of K, and valuation rings of
K. A place is called trivial if it is injective. The valuation ring of the trivial place
is simply K itself.
As with homomorphisms, we observe that the composite of two places is also
a place (trivial verification).
It is often convenient to deal with places instead of valuation rings, just as it is
convenient to deal with homomorphisms and not always with canonical homo-
morphisms or a ring modulo an ideal.
The general theory of valuations and valuation rings is due to Krull , All-
gemeine Bewertungstheorie, J. reine angew. Math . 167 (1932) , pp. 169-196.
However, the extension theory of homomorphisms as above was realized only
around 1945 by Chevalley and Zariski.

350
EXTENSION OF RINGS
VII, §3
We shall now give some examples of places and valuation rings .
Example 1.
Let p be a prime number. Let Z(p) be the ring of all rational
numbers whose denominator is not divisible by p . Then Z(p) is a valuation ring.
The maximal ideal consists ofthose rational numbers whose numerator is divisible
by p .
Example 2.
Let k be a field and R = k[X] the polynomial ring in one
variable. Let p = p(X) be an irreducible polynomial . Let 0 be the ring of rational
functions whose denominator is not divisible by p. Then 0 is a valuation ring ,
similar to that of Example I .
Example 3.
Let R be the ring of power series k[[X]] in one variable. Then
R is a valuation ring , whose maximal ideal consists of those power series divi sible
by X. The residue class field is k itself.
Example 4.
Let R = krrXI , ... , Xn]] be the ring of power series in several
variables. Then R is not a valuation ring, butR is imbedded in the field ofrepeated
power series k«Xl»«X2»
. .. «Xn»= Kn- By Example 3, there is a place of
K; which is Kn_l-valued. By induction and composition, we can define a
k-valued place of Kn- Since the field of rational functions k(X l' .. . , Xn ) is
contained in Kn , the restriction of this place to k(X l , •• . , Xn ) gives a k-valued
place of the field of rational functions in n variables.
Example 5.
In Chapter XI we shall consider the notion of ordered field .
Let k be an ordered subfield of an ordered field K. Let 0 be the subset of elements
of K which are not infinitely large with respect to k. Let m be the subset of
elements of 0 which are infinitely small with respect to k. Then 0 is a valuation
ring in K and m is its maximal ideal.
The following property of places will be used in connection with projective
space in the next chapter.
Proposition 3.4.
Let <p : K ~ {L, oc} be an L-valued place of K. Given a
finite number of non-zero elements x I' ... , Xn E K there exists an index j such
that <p is finite on xJx.for i = I, . . . , n.
Proof.
Let B be the valuation ring of the place. Define Xi 2 Xj to mean that
x.]Xj E B. Then the relation 2 is transitive, that is if Xi 2
Xj and Xj 2 x, then
Xi 2 x.. Furthermore, by the property of a valuation ring, we always have
Xi 2
Xj or xj 2
Xi for all pairs of indices i , j. Hence we may order our ele-
ments, and we select the index j such that Xi 2
Xj for all i. This index j
satisfies the requirement of the proposition.
We can obtain a characterization of integral elements by means of val-
uation rings. We shall use the following term inology. If 0, D are local
rings with maximal ideals m, 9Jl respectively, we shall say that D lies above 0
if 0 c D and 9Jl (') 0 = m. We then have a canonical injection o/rn -> Dj9Jl.

VII, §3
EXTENSION OF HOMOMORPHISMS
351
Proposition 3.5.
Let 0 be a local ring contained in a fie ld L. An element x of
L is integral over 0 if and only if x lies in every valuation ring .0 of L lying
above o.
Proof
Assume that x is not integral over o. Let m be the maximal ideal of o.
Then the ideal (m, I/x) of o[l/x] cannot be the entire ring, otherwise we can
write
- I = an(l /x)" + ... + al (l /x) + y
with y E m and a, E o. From this we get
(I + y)x n + ... + an = O.
But I + y is not in rn, hence is a unit of o. We divide the equation by I + Y to
conclude that x is integral over 0, contrary to our hypothesis. Thus (m, I/x) is
not the entire ring, and is contained in a maximal ideal ~ , whose intersection
with 0 contains m and hence must be equal to m. Extending the canonical homo-
morphism o[l/x] ..... o[l /x]/~ to a homomorphism of a valuation ring D of L,
we see that the image of I/x is 0 and hence that x cannot be in this valuation ring.
Conversely, assume that x is integral over 0 , and let
be an integral equation for x with coefficients in o. Let £:) be any valuation ring
of L lying above o. Suppose x ¢. D. Let 'P be the place given by the canonical
homomorphism of .0 modulo its maximal ideal. Then 'P(x ) =
00 so 'PO / x) = O.
Divide the above equation by x", and apply 'P. Then each term except the first
maps to 0 under 'P. so we get 'PO ) = 0, a contradiction which proves the
proposition ..
Proposition 3.6.
Let A be a ring contained in a field L. An element x of L
is integral over A if and only if x lies in every valuation ring £:) of L containing
A. In terms ofplaces, x is integral over A if and only if every place of L finite
on A is finite on x.
Proof.
Assume that every place finite on A is finite on x . We may assume
x
=1= O. If I/x is a unit in A[I / x] then we can write
with c, E A and some n. Multiplying by x n- I we conclude that x is integral over
A . If 1/x is not a unit in A [ I/ x ], then 1/ x generates a proper principal ideal.
By Zorn 's lemma this ideal is contained in a maximal idealWl. The homomorphism
A [1/x1~ A[1/xl/Wl can be extended to a place which is a finite on A but maps

352
EXTENSION OF RINGS
VII, Ex
1/ x on 0, so x on 00, which contradicts the possibility that 1/ x is not a unit in
A[l/.r] and proves that x is integral over A . The converse implication is proved
just as in the second part of Proposition 3.5.
Remark.
Let K be a subfield of L and let x E L. Then x is integral over
K if and only if x is algebraic over K. So if a place tp of L is finite on K, and x
is algebraic over K, then cp is finite on K(x). Of course this is a trivial case of
the integrality criterion which can be seen directly. Let
be the irreducible equation for x over K. Suppose x
=1= 0. Then ao =1= 0. Hence
cp(x)
=1= °immediately from the equation, so cp is an isomorphism of K(x) on its
image.
The next result is a generalization whose technique of proof can also be used
in Exercise 1 of Chapter IX (the Hilbert-Zariski theorem).
Theorem 3.7.
General Integrality Criterion.
Let A be an entire ring.
Let z" . .. , Zm be elementsofsome extensionfield ofits quotientfield K. Assume
that each Zs (s = 1, . .. , m) satisfies a polynomial relation
where gS<Z" . . . , Zm) E A[Z" . . . , Zml is a polynomial of total degree < d.,
and that any pure power ofZ, occuring with non-zero coefficient in gs occurs
with a power strictly less than d.. Then z" ... , Zm are integral over A.
Proof.
We apply Proposition 3.6. Suppose some Zs is not integral over A.
There exists a place cp of K, finite on A, such that cp(zs) = 00 for some s. By
Proposition 3.4 we can pick an index s such that cp(z/zs)
=1=
00 for all j. We
divide the polynomial relation of the hypothesis in the lemma by z'}s and apply
the place. By the hypothesis on gs' it follows that cp(gs(z)/z'}s) = 0, whence we
get 1 = 0, a contradiction which proves the theorem.
EXERCISES
I. Let K be a Galois extension of the rationals Q, with group G. Let B be the integral
closure of Z in K, and let IJ. E B be such that K = Q(IJ.). Letf(X) = Irr(IJ., Q, X). Let
p be a prime number, and assume that f remains irreducible mod p over Z/pZ. What
can you say about the Galois group G? (Artin asked this question to Tate on his qualify-
ing exam.)
2. Let A be an entire ring and K its quotient field. Let t be transcendental over K . If A
is integrally closed, show that A[t] is integrally closed.

VII, Ex
For the fo llowing exercises, you can use §l of Chapter X.
EXERCISES
353
3. Let A be an entire ring, integrally closed in its quotient field K. Let L bea finite separable
extension of K , and let B be the integral closu re of A in L. If A is Noetherian, show that
B is a finite A-module. [ Hillt:
Let {WI"
' " w. } be a basis of L over K.
Mult iplying
all elements of this basis by a suitable element of A, we may assume without loss of
generality that all co, are integral over A. Let {W'I' . . . , w~ } be the dual basis relative to
the trace, so that Tr(wiwj) = bij ' Write an element C1. of L integral over A in the form
C1. = b1w'l + ... + b. w~
with bj E K . Taking the trace Tr(aw;), for i = I, . .. , n , conclude that B is contained
in the finite module Aw; + .. . + A w~ . ] Hence B is Noetherian.
4. The preceding exercise applies to the case when A = Z and k = Q. Let L be a finite
extension of Q and let °L be the ring of algebraic integers in L. Let ai ' . . . , an be
the distinct embeddings of L into the complex numbers. Embedded 0L into a Euclidean
space by the map
a H
(a la, . . . , a. a ).
Show that in any bounded region of space, there is only a finite number of elements
of 0L' [H im : The coefficients in an integral equation for a are elementary symmetric
functions of the conjugates of a and thus are bounded integers.] Use Exercise 5 of
Chapter III to conclude that 0L is a free Z-module of dimension ~ n. In fact, show
that the dimension is n, a basis of 0L over Z also being a basis of Lover Q.
5. Let E be a finite extension of Q, and let 0E be the ring of algebraic integers of E. Let
U be the group of units of °E' Let at , .. . , an be the distinct embeddings of E into
C . Map U into a Euclidean space, by the map
Show that l(U) is a free abelia n gro up, finitely generated, by showing that in any finite
region of space, there is on ly a finite number of elements of l( U) . Show that the kernel
of I is a finite gro up, and is therefore the gro up of roo ts of unity in E. Thus U itself is a
finitely genera ted abelian group.
6. Generalize the results of ~2 to infinite Ga lois extensions, especially Propositions 2.1
and 2.5, using Zorn's lemma.
7. Dedekind rings.
Let ° be an entire ring which is Noetherian, integrally closed, and
, such that every
non-zero prime ideal is maximal. Define a fractional ideal a to be an
°-submodule '* 0 of the quotient field K such that there exists c E O, c '* 0 for which
c a Co. Prove that the
fractional ideals form a group under multiplication. Hint
followi ng van der Waerden: Prove the following statements in order:
(a) Given an ideal a '* 0 in 0 , there exists a product of prime ideals
VI ' "V r C a .
(b) Every maximal ideal V is invertible, i.e. if we let V- I be the set of elements
x E K such that x VCo , then V- )V = o.
(c) Every non-zero ideal is invertible, by a fractional ideal. (Use the Noetherian
property that if this is not true, there exists a maximal non-invertible ideal
a, and get a contradiction.)

354
EXTENSION OF RINGS
VII, Ex
8. Using prime ideals instead of prime numbers for a Dedekind ring A, define the notion
of content as in the Gauss lemma, and prove that if/ (X), g(X ) E A[XI are polynomials
of degree ~ 0 with coefficients in A, then cont(fg) = cont(j)cont(g). Also if K is
the quotient field of A , prove the same statement for /, 9 E K[X) .
9. Let A be an entire ring, integrally closed. Let B be entire, integral over A . Let QI '
Qz be prime ideals of B with QI :J Qz but Q. *' Qz. Let P; = Q; n A. Show that
PI *' Pz·
10. Let n be a positive integer and let (, (' be primitive n-th roots of unity.
(a) Show that (I -
()/ (l - n is an algebraic integer.
(b) If n ~ 6 is divisible by at least two primes, show that I - (is a unit in the
ring Z[(l .
II . Let p be a prime and ( a primitive p-th root of unity . Show that there is a principal
ideal J in Z[Cl such that Jp-I = (p) (the principal ideal generated by p).
Symmetric Polynomials
12. Let F be a field of characteristic O. Let tl ,. . . ,t, be algebraically independent over F.
Let SI, . . . .s; be the element ary symmetric functions. Then R = F [tl ' . .. ,tn ] is an
integral extension of S = F[SI ,.. . ,sIll, and actually is its integral closure in the
rational field F (tl ," " tn ) . Let W be the group of permutation of the variables
tl ,. .. , t".
(a) Show that S = R IV is the fixed subring of R under W.
(b) Show that the elements
t ~ ' .. ·t;'" with 0 ~ r, ~ II - i form a basis of Rover
S, so in part icular. R is free over S.
I am told that the above basis is due to Kronecker. There is a much more interesting
basis. which can be defined as follows.
Let 01, . . . ,0" be the partial derivatives with respect to II, . .. . t.: so 0; = 0/ Oti. Let
P E F [t] = F [II ,.. . ,tn ]. Substituting OJ for tt (i = I, . . . , II ) gives a partial differential
operator P(0) = P(01, .. . ,On) on R. An element of S can also be viewed as an element of
R. Let Q E R. We say that Q is W-harmonic if P(o)Q = 0 for all symmetric polynomials
P E S with 0 constant term. It can be shown that the W-harm onic polynomials form a
finite dimensional space. Furthermore, if {HI ,. . . , HN} is a basis for this space over F,
then it is also a basis for R over S. This is a special case of a general theorem of Che-
valley. See [La 99b], where the special case is worked out in detail.

CHAPTER VIII
Transcendental Extensions
Both for their own sake and for applications to the case of finite exten-
sions of the rational numbers, one is led to deal with ground fields which are
function fields, i.e. finitely generated over some field k, possibly by elements
which are not algebraic. This chapter gives some basic properties of such
fields.
§1.
TRANSCENDENCE BASES
Let K be an extension field of a field k. Let S be a subset of K . We
recall that S (or the elements of S) is said to be algebraically independent
over k, if whenever we have a relation
with coefficients Q(v) E k, almost all Q(v) = 0, then we must necessarily have all
Q(v) = 0.
We can introduce an ordering among algebraically independent subsets of
K, by ascending inclusion. These subsets are obviously inductively ordered,
and thus there exist maximal elements. If S is a subset of K which is
algebraically independent over k, and if the cardinality of S is greatest among
all such subsets, then we call this cardinality the transcendence degree or
dimension of Kover k. Actually, we shall need to distinguish only between
finite transcendence degree or infinite transcendence degree. We observe that
355
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

356
TRANSCENDENTAL EXTENSIONS
VIII , §1
the notion of transcendence degree bears to the notion of algebraic indepen-
dence the same relation as the notion of dimension bears to the notion of
linear independence.
We frequently deal with families of elements of K, say a family {Xd iel>
and say that such a family is algebraically independent over k if its elements
are distinct (in other words, Xi =F Xj if i =F j) and if the set consisting of the
elements in this family is algebraically independent over k.
A subset S of K which is algebraically independent over k and is maximal
with respect to the inclusion ordering will be called a transcendence base of
Kover k. From the maximality, it is clear that if S is a transcendence base
of Kover k, then K is algebraic over k(S).
Theorem 1.1.
Let K be an extension of a field k. Any two transcendence
bases of Kover k have the same cardinality. If r is a subset of K such that
K is algebraic over k(f), and S is a subset ofr which is algebraically indepen-
dent over k, then there exists a transcendence base CB of Kover k such that
S C CB Cr.
Proof.
We shall prove that if there exists one finite transcendence base, say
{x I> • • • ,xm} , m ~ 1, m minimal, then any other transcendence base must also
have m elements. For this it will suffice to prove: If WI' ••. , Wn are elements
of K which are algebraically independent over k then n ~ m (for we can then
use symmetry). By assumption, there exists a non-zero irreducible polynomial
fl in m + 1 variables with coefficients in k such that
fl(wl' XI ' • . • , xm) = O.
After renumbering x I ' • .• , Xm we may write fl = ~ giWI ' X2' . . . , xm) x1 with
some gN "* 0 with some N
~ 1. No irreducible factor of gN vanishes on
(wI' X2' . .. ,xn) , otherwise WI would be a root of two distinct irreducible polyno-
mials over k(XI' ... ,xm) . Hence XI is algebraic over k(wl' x2' .. . , xm) and
WI' X2' . .. , xm are algebraically independent over k, otherwise the minimal-
ity of m would be contradicted . Suppose inductively that after a suitable re-
numbering of x2' . . . ' Xm we have found WI' • • . , w, (r < n) such that K is
algebraic over k(wl> .. . , Wr' xr+I' .. . , xm) . Then there exists a non-zero
polynomial f in m + I variables with coefficients in k such that
Since the w's are algebraically independent over k, itfollows bythe same argument
as in the first step that some Xj' say xr+ I> is algebraic over k(wl' . . . , wr+ I>
xr+2' . .. , xm) . Since a tower of algebraic extensions is algebraic, it follows
that K is algebraic over k(wl' . . . , Wr+!' Xr+2' . .. , xm) . We can repeat the
procedure, and if n ~ m we can replace all the x's by w's , to see that K is
algebraic over k(WI ' . . . , wm) . This shows that n ~ m implies n = m, as desired .

VIII. §2
NOETHER NORMALIZATION THEOREM
357
We have now proved: Either the transcendence degree is finite, and is
equal to the cardinality of any transcendence base, or it is infinite, and every
transcendence base is infinite. The cardinality statement in the infinite case
will be left as an exercise. We shall also leave as an exercise the statement
that a set of algebraically independent elements can be completed to a
transcendence base, selected from a given set r such that K is algebraic over
k(f). (The reader will note the complete analogy of our statements with those
concerning linear bases.)
Note.
The preceding section is the only one used in the next chapter. The
remaining sections are more technical, especially §3 and §4 which will not be
used in the rest of the book. Even §2 and §5 will only be mentioned a
couple of times, and so the reader may omit them until they are referred to
again.
§2.
NOETHER NORMALIZATION THEOREM
Theorem 2.1.
Let k[xl, ... , xnJ = k[xJ be a finitely generated entire ring
over a field k, and assume that k(x) has transcendence degree r. Then there
exist elementsYl, .. ., Yr in k[xJ such that k[xJ is integral over
k[yJ = k[Yl' ... , Yr].
Proof.
If (x.; ... , xn ) are already algebraically independent over k, we
are done. If not, there is a non-trivial relation
La(j)x{l .. . x~n = 0
with each coefficient a(j) E k and a(j) #- O.
The sum is taken over a finite
number of distinct n-tuples of integers (jl' ... ,jn), i. ~ O.
Let mz, ... , mn be
positive integers, and put
Yz = Xz -
x~\ ... , Yn = x, -
x~n .
Substitute
Xi = Yi + X~ i (i = 2,
, n) in the above equation.
Using vector
notation, we put (m) = (1, mz,
, mn) and use the dot product (j). (m) to
denote i, + mzjz + ...+ mnjn' If we expand the relation after making the
above substitution, we get
Lc(j)xyHm) + f(x l, Yz, ... , Yn) = 0
where f is a polynomial in which no pure power of Xl appears. We now
select d to be a large integer [say greater than any component of a vector (j)
such that c(j) #- OJ and take
(m) = (1, d, dZ, •• • , dn ).

358
TRANSCENDENTAL EXTENSIONS
VIII. §2
Then all (j) .(m) are distinct for those (j) such that c(j) =1= O. In this way we
obtain an integral equation for Xl over k[Y2"'" Yn].
Since each Xi (i> 1)
is integral
over k[x l, Y2" '" Yn], it follows that k[x]
is integral
over
k[Y2, ... , Yn].
We can now proceed inductively, using the transitivity of
integral extensions to shrink the number of y's until we reach an alge-
braically independent set of y's.
The advantage of the proof of Theorem 2.1 is that it is applicable when k
is a finite field. The disadvantage is that it is not linear in x. , ... , X n• We
now deal with another technique which leads into certain aspects of algebraic
geometry on which we shall comment after the next theorem.
We start again with k[x l, .. ., xn] finitely generated over k and entire.
Let (Ui) (i, j = 1,..., n) be algebraically independent elements over k(x), and
let k; = k(u) = k(Ui).ll i.j' Put
n
Yi = L uijXj'
j=l
This amounts to a generic linear change of coordinates in n-space, to use
geometric terminology.
Again we let r be the transcendence degree of k(x)
over k.
Theorem
2.2.
With
the
above
notation,
ku[x]
is
integral
over
kU[Yl' .. ., Yr].
Proof
Suppose some Xi is not integral over kU[Yl' .. ., Yr]. Then there
exists a place q> of ku(Y) finite on kU[Yl" ' " Yr] but taking the value
00 on
some Xi' Using Proposition 3.4 of Chapter VII, and renumbering the indices
if necessary, say q>(xj/xn) is finite for all i. Let zj = q>(x)xn) for j = 1, ..., n.
Then dividing the equations Yi = LuijXj by x, (for i = 1,..., r) and applying
the place, we get
The transcendence degree of k(z') over k cannot be r, for otherwise, the place
qJ would be an isomorphism of k(x) on its image. [Indeed, if, say, z~, ..., z;
are algebraically independent and z, = xdx n , then zl'
. . . , z, are also alge-
braically independent, and so form a transcendence base for k(x) over k.
Then the place is an isomorphism from k(Zl" '" zr) to
k(z~ , ... , z;), and
hence is an isomorphism from k(x) to its image.] We then conclude that
with
i = 1, ... , r ;
j = 1, .. ., n -
1.
Hence the transcendence degree of k(u) over k would be ~ rn - 1, which is a
contradiction, proving the theorem.

VIII , §2
NOETHER NORMALIZATION THEOREM
359
Corollary 2.3.
Let k be a field, and let k(x) be a finitely generated
extension of transcendence degree r.
There exists a polynomial P(u) =
P(uij) E k[uJ such that if (c) = (c ij) is a family of elements cij E k satisfying
P(c) =F 0, and we let Y; = L cij Xj' then k[xJ is integral over k[y~, ... , y;J.
Proof.
By Theorem 2.2, each
Xi is integral over kU[Yl"'" YrJ.
The
coefficients of an integral equation are rational functions in ku• We let P(u)
be a common denominator for these rational functions. If P(c) =F 0, then
there is a homomorphism
<p: k(x) [u, p(U)-l] --+ k(x)
such that <p(u) = (c), and such that <p is the identity on k(x). We can apply <p
to an integral equation for Xi over ku[yJ to get an integral equation for Xi
over k[y'J, thus concluding the proof.
Remark.
After Corollary 2.3, there remains the problem of finding ex-
plicitly integral equations for X1' '' ''Xn (or Yr+l, ... ,Yn) over kU[Yl, ... ,YrJ.
This is an elimination problem, and I have decided to refrain from further
involvement in algebraic geometry at this point.
But it may be useful to
describe the geometric language used to interpret Theorem 2.2 and further
results in that line. After the generic change of coordinates, the map
(Yl' ... , Yn)t-+(Yl ' .. ., Yr)
is the generic projection of the variety whose coordinate ring is k[x] on
affine r-space. This projection is finite, and in particular, the inverse image of
a point on affine r-space is finite. Furthermore, if k(x) is separable over k (a
notion which will be defined in §4), then the extension ku(Y) is finite separable
over kU(Yl' ... , Yr) (in the sense of Chapter V). To determine the degree of
this finite extension is essentially Bezout's theorem.
Cf. [La 58], Chapter
VIII, §6.
The above techniques were created by van der Waerden and Zariski, cf.,
for instance, also Exercises 5 and 6. These techniques have unfortunately not
been completely absorbed in some more recent expositions of algebraic
geometry.
To give a concrete example : When Hartshorne considers the
intersection of a variety and a sufficiently general hyperplane, he does not
discuss the "generic" hyperplane (that is, with algebraically independent
coefficients over a given ground field), and he assumes that the variety is
non-singular from the start (see his Theorem 8.18 of Chapter 8, [Ha 77J).
But the description of the intersection can be done without simplicity as-
sumptions, as in Theorem 7 of [La 58J, Chapter VII, §6, and the corre-
sponding lemma.
Something was lost in discarding the technique of the
algebraically independent (uij)'
After two decades when the methods illustrated in Chapter X have been
prevalent, there is a return to the more explicit methods of generic construc-
tions using the algebraically independent (uij) and similar ones for some

360
TRANSCENDENTAL EXTENSIONS
VIII, §3
applications because part of algebraic geometry and number theory are
returning to some problems asking for explicit or effective constructions, with
bounds on the degrees of solutions of algebraic equations. See, for instance,
[Ph 91-95], [So 90], and the bibliography at the end of Chapter X, §6. Return-
ing to some techniques, however, does not mean abandoning others; it
means only expanding available tools.
Bibliography
[Ha 77]
[La 58]
[Ph 91-
95]
[So 90]
R. HARTSHORNE, Algebraic Geometry, Springer-Verlag, New York, 1977
S. LANG, Introduction to Algebraic
Geometry, Wiley-Interscience, New
York, 1958
P. PHILIPPON, Sur des hauteursalternatives, I Math. Ann. 289 (1991) pp. 255-283 ;
II Ann. Inst. Fourier 44 (1994) pp. 1043-1065; IIIJ. Math. Pures Appl. 74 (1995)
pp. 345-365
C. SOULE, Geometric d'Arakelovet theoriedes nombres transccndants, Asterisque
198-200 (1991) pp. 355-371
§3.
LINEARLY DISJOINT EXTENSIONS
In this section we discuss the way in which two extensions K and L of a
field k behave with respect to each other. We assume that all the fields
involved are contained in one field n, assumed algebraically closed.
K is said to be linearly disjoint from Lover k if every finite set of
elements of K that is linearly independent over k is still such over L.
The definition is unsymmetric, but we prove right away that the property
of being linearly disjoint is actually symmetric for K and L.
Assume K
linearly disjoint from Lover k.
Let Y1' .. .,Yn be elements of L linearly
independent over k. Suppose there is a non-trivial relation of linear depen-
dence over K,
(1)
Say Xl' ... , x, are linearly independent over k, and X,+l' ... , x; are linear
r
combinations Xi = L ai/lx/l' i = r + 1, ... , n. We can write the relation (1) as
/l=1
follows:
and collecting terms, after inverting the second sum, we get
J1 (Y/l + i=t1 (ai/lYi))X/l = O.

VIII , §3
LINEARLY DISJOINT EXTENSIONS
361
The y's are linearly independent over k, so the coefficients of x/l are #- 0.
This contradicts the linear disjointness of K and Lover k.
We now give two criteria for linear disjointness.
Criterion 1.
Suppose that K is the quotient field of a ring Rand L the
quotient field of a ring S. To test whether Land K are linearly disjoint, it
suffices to show that if elements Yl , ..., Yn of S are linearly independent over
k, then there is no linear relation among the Y's with coefficients in R.
Indeed, if elements Yl " ' " Yn of L are linearly independent over k, and if
there is a relation XlYI + ... + XnYn = °with Xi E K, then we can select Y in
S and
X in R such that xy #- 0, YYi E S for all i, and
XXi E R for all i.
Multiplying the relation by xy gives a linear dependence between elements of
Rand S. However, the YYi are obviously linearly independent over k, and
this proves our criterion.
Criterion 2.
Again let R be a subring of K such that K is its quotient
field and R is a vector space over k. Let {ua } be a basis of R considered as a
vector space over k. To prove K and L linearly disjoint over k, it suffices to
show that the elements {ua } of this basis remain linearly independent over L.
Indeed, suppose this is the case.
Let Xl "'" xm be elements of R linearly
independent ovetk. They lie in a finite dimension vector space generated by
some of the
Ua, say
U l , .. . , Un'
They can be completed to a basis for this
space over k.
Lifting this vector space of dimension n over L, it must
conserve its dimension because the u's remain linearly independent by hy-
pothesis, and hence the x's must also remain linearly independent.
Proposition 3.1.
Let K
be a field containing another field k, and let
L :J E be two oth er extensions of k.
Then K and L are linearly disjoint
over k if and only if K and E are linearly disjoint over k and KE, L are
linearly disjoint over E.
KL/\
KE
L
/ \ /
K\ /E
k

362
TRANSCENDENTAL EXTENSIONS
VIII. §3
Proof
Assume first that K, E are linearly disjoint over k, and KE, L are
linearly disjoint over E. Let {K} be a basis of K as vector space over k (we
use the elements of this basis as their own indexing set), and let {a} be a
basis of E over k. Let {A} be a basis of Lover E. Then {al.} is a basis of L
over k. If K and L are not linearly disjoint over k, then there exists a
relation
with some CKAa # 0, CKAa E k.
Changing the order of summation gives
contradicting the linear disjointness of Land KE over E.
Conversely, assume that K and L are linearly disjoint over k. Then a
fortiori, K and E are also linearly disjoint over k, and the field KE is the
quotient field of the ring E[K] generated over E by all elements of K. This
ring is a vector space over E, and a basis for Kover k is also a basis for this
ring E[K] over E. With this remark, and the criteria for linear disjointness,
we see that it suffices to prove that the elements of such a basis remain
linearly independent over L. At this point we see that the arguments given
in the first part of the proof are reversible. We leave the formalism to the
reader.
We introduce another notion concerning two extensions K and L of a
field k. We shall say that K is free from Lover k if every finite set of
elements of K algebraically independent over k remains such over L. If (x)
and (Y) are two sets of elements in il, we say that they are free over k (or
independent over k)if k(x) and k(y) are free over k.
Just as with linear disjointness, our definition is unsymmetric, and we
prove that the relationship expressed therein is actually symmetric. Assume
therefore that K is free from Lover k. Let YI ' " ' ' Yn be elements of L,
algebraically independent over k. Suppose they become dependent over K.
They become so in a subfield F of K finitely generated over k, say of
transcendence degree rover k. Computing the transcendence degree of F(y)
over k in two ways gives a contradiction (cf. Exercise 5).
F(y)
/"\
F""
k(y)
r"" /
k

VIII. §4
SEPARABLE AND REGULAR EXTENSIONS
363
Proposition 3.2.
If K and L are linearly disjoint over k, then they are free
over k.
Proof.
Let XI' . .. , x; be elements of K algebraically independent over k.
Suppose they become algebraically dependent over L. We get a relation
LYaMa(x) = 0
between monomials Ma(x) with coefficients Ya in L.
This gives a linear
relation among the Ma(x). But these are linearly independent over k because
the x's are assumed algebraically independent over k. This is a contradiction.
Proposition 3.3.
Let L be an extension of k, and let (u) = (ul , . . . , ur ) be a
set of quantities algebraically independent over L.
Then the field k(u) is
linearly disjoint from Lover k.
Proof.
According to the criteria for linear disjointness, it suffices to
prove that the elements of a basis for the ring k[u] that are linearly indepen-
dent over k remain so over L. In fact the monomials M(u) give a basis of
k[u] over k.
They must remain linearly independent over L, because as
we have seen, a linear relation gives an algebraic relation. This proves our
proposition.
Note finally that the property that two extensions K and L of a field k
are linearly disjoint or free is of finite type.
To prove that they have either
property, it suffices to do
it for
all subfields Ko and Lo of K and L
respectively which are finitely generated over k. This comes from the fact
that the definitions involve only a finite number of quantities at a time.
§4.
SEPARABLE AND REGULAR EXTENSIONS
Let K be a finitely generated extension of k, K = k(x). We shall say that
it is separably generated if we can find a transcendence basis «.....,tr ) of
Klk such that K is separably algebraic over k(t). Such a transcendence base
is said to be a separating transcendence base for Kover k.
We always denote by p the characteristic if it is not O. The field obtained
from k by adjoining all pm_th roots of all elements of k will be denoted by
kl/p'". The compositum of all such fields for m = 1, 2, ... , is denoted by kl/p"'.
Proposition 4.1.
The following conditions concerning an extension field K
of k are equivalent:
(i) K is linearly disjoint from kl/p"'.
(ii) K is linearly disjoint from kl/p'" for some m.

364
TRANSCENDENTAL EXTENSIONS
VIII. §4
(iii) Every subfield of K containing k and finitely generated over k is
separably generated.
Proof.
It is obvious that (i) implies (ii).
In order to prove that (ii)
implies (iii), we may clearly assume that K is finitely generated over k, say
K = k(x) = k(x l , ••• , xn ).
Let the transcendence degree of this extension be r. If r = n, the proof is
complete. Otherwise, say Xl"'" x, is a transcendence base. Then
Xr+ l is
algebraic over k(x l , . • • , x.). Let f(X l , • • . , Xr +l ) be a polynomial of lowest
degree such that
f(x l , • • • , xr+d = O.
Then f is irreducible. We contend that not all Xi (i = 1,... , r + 1) appear to
the p-th power throughout. If they did, we could write f(X) = LcaMa(X)P
where Ma(X) are monomials in Xl' ... , X r+ l and
Ca E k. This would imply
that the Ma(x) are linearly dependent over kl /p (taking the p-th root of the
equation LcaMa(x)P = 0). However, the Ma(x) are linearly independent over
k (otherwise we would get an equation for x., ... , X r +1 of lower degree) and
we thus get a contradiction to the linear disjointness of k(x) and k'!". Say
Xl does not appear to the p-th power throughout, but actually appears in
f(X). We know that f(X) is irreducible in k[X l , . . . ,Xr+lJ and hence f(x) =0
is an irreducible equation for Xl over k(X2' ... , xr+l ).
Since Xl does not
appear to the p-th power throughout, this equation is a separable equation
for Xl over k(x 2 , .... , xr+l ), in other words, Xl is separable algebraic over
k(x 2 , •• • , xr+d.
From this it follows that it is separable algebraic over
k(x 2 , • • • , xn ). If (x 2 , •• • , xn ) is a transcendence base, the proof is complete. If
not, say that X2 is separable over k(X3' ..., xn). Then k(x) is separable over
k(x3, ..., xn ).
Proceeding inductively, we see that the procedure can be
continued until we get down to a transcendence base. This proves that (ii)
implies (iii). It also proves that a separating transcendence base for k(x) over
k can be selected from the given set of generators (x).
To prove that (iii) implies (i) we may assume that K is finitely generated
over k. Let (u) be a transcendence base for Kover k. Then K is separably
algebraic over k(u). By Proposition 3.3, k(u) and kIll'''' are linearly disjoint.
Let L = kl/fl".
Then k(u)L is purely inseparable over k(u), and hence is
linearly disjoint from Kover k(u) by the elementary theory of finite algebraic
extensions.
Using Proposition 3.1, we conclude that K is linearly disjoint
from Lover k, thereby proving our theorem.
An extension K of k satisfying the conditions of Proposition 4.1 is called
separable. This definition is compatible with the use of the word for alge-
braic extensions.
The first condition of our theorem is known as MacLane's criterion. It
has the following immediate corollaries.

VIII , §4
SEPARABLE AND REGULAR EXTENSIONS
365
Corollary 4.2.
If K is separable over k, and E is a subfield of K contain-
ing k, then E is separable over k.
Corollary 4.3.
Let E be a separable extension of k, and K a separable
extension of E. Then K is a separable extension of k.
Proof
Apply Proposition 3.1 and the definition of separability.
Corollary 4.4.
If k is perfect, every extension of k is separable.
Corollary 4.5.
Let K be a separable extension of k, and free from an
extension L of k. Then KL is a separable extension of L.
Proof
An element of KL has an expression in terms of a finite number
of elements of K and L.
Hence any finitely generated subfield of KL
containing L is contained in a composite field FL, where F is a subfield of K
finitely generated over k. By Corollary 4.2, we may assume that K is finitely
generated over k. Let (t) be a transcendence base of Kover k, so K is
separable algebraic over k(t). By hypothesis, (t) is a transcendence base of
KL over L, and since every element of K is separable algebraic over k(t), it
is also separable over L(t). Hence KL is separably generated over L. This
proves the corollary.
Corollary 4.6.
Let K and L be two separable extensions of k, free from
each other over k. Then KL is separable over k.
Proof
Use Corollaries 4.5 and 4.3.
Corollary 4.7.
Let K, L be two extensions of k, linearly disjoint over k.
Then K is separable over k if and only if KL is separable over L.
Proof
If K is not separable over k, it is not linearly disjoint from k1/p
over k, and hence a fortiori it is not linearly disjoint from Lk 1/p over k. By
Proposition 4.1, this implies that KL is not linearly disjoint from Lk 1/p over
L, and hence that KL is not separable over L. The converse is a special case
of Corollary 4.5, taking into account that linearly disjoint fields are free.
We conclude our discussion of separability with two results. The first one
has already been proved in the first part of Proposition 4.1, but we state it
here explicitly.
Proposition 4.8.
If K is a separable extension of k, and is finitely gener-
ated, then a separating transcendence base can be selected from a given set
of generators.
To state the second result we denote by K p'" the field obtained from K
by raising all elements of K to the pm-th power.

366
TRANSCENDENTAL EXTENSIONS
VIII. §4
Proposition 4.9.
Let K be a finitely generated extension of a field k. If
xr» = K for some m, then K is separably algebraic over k. Conversely, if
K is separably algebraic over k, then K pmk = K for all m.
Proof
If Klk is separably algebraic, then the conclusion follows from
the elementary theory of finite algebraic extensions.
Conversely, if Kfk is
finite algebraic but not separable, then the maximal separable extension of k
in K cannot be all of K, and hence K"k cannot be equal to K. Finally, if
there exists an element t of K transcendental over k, then k(t l /pm) has degree
pm over k(t), and hence there exists a t such that t l /
p m does not lie in K. This
proves our proposition.
There is a class of extensions which behave particularly well from the
point of view of changing the ground field, and are especially useful in
algebraic geometry. We put some results together to deal with such exten-
sions.
Let K be an extension of a field k, with algebraic closure K".
We
claim that the following two conditions are equivalent:
REG 1.
k is algebraically closed in K (i.e. every element of K algebraic
over k lies in k), and K is separable over k.
REG 2.
K is linearly disjoint from ka over k.
We show the equivalence. Assume REG 2. By Proposition 4.1, we know that
K is separably generated over k. It is obvious that k must be algebraically
closed in K. Hence REG 2 implies REG 1. To prove the converse we need
a lemma.
Lemma 4.10.
Let k be algebraically closed in extension K. Let x be
some element of an extension of K, but algebraic over k. Then k(x) and K
are linearly disjoint over k, and [k(x): k] = [K(x) :K].
Proof
Let f(X) be the irreducible polynomial for x over k. Then f
remains irreducible over K; otherwise, its factors would have coefficients
algebraic over k, hence in k. Powers of x form a basis of k(x) over k, hence
the same powers form a basis of K(x) over K. This proves the lemma.
To prove REG 2 from REG 1, we may assume without loss of generality
that K is finitely generated over k, and it suffices to prove that K is linearly
disjoint from an arbitrary finite algebraic extension L of k. If L is separable
algebraic over k, then it can be generated by one primitive element, and we
can apply Lemma 4.10.
More generally, let E be the maximal separable subfield of L containing
k. By Proposition 3.1, we see that it suffices to prove that KE and L are
linearly disjoint over E.
Let (r) be a separating transcendence base for K
over k. Then K is separably algebraic over k(t). Furthermore, (t) is also a
separating transcendence base for KE over E, and KE is separable algebraic

VIII . §4
SEPARABLE AND REGULAR EXTENSIONS
367
over E(t). Thus KE is separable over E, and by definition KE is linearly
disjoint from Lover K becau se L is purely inseparable over E. This proves
that REG 1 implies REG 2.
Thus we can define an extension K of k to be regular if it satisfies either
one of the equi valent conditions REG 1 or REG 2.
Proposition 4.11.
(a) Let K be a regular extension of k, and let E be a subfield of K containing
k. Then E is regular over k.
(b) Let E be a regular extension oj
k, and K a regular extension oj E.
Then K is a regular ex tension oj k.
(c) IJ k is algebraically closed, then every extension oj k is regular.
ProoJ.
Each assertion is immediate from the definition conditions REG
1 and REG 2.
Theorem 4.12.
Let K be a regular extension oj k, let L be an arbitrary
ex tension oj k, both contained in some larger field , and assume that K, L
are fre e over k. Then K, L are linearly disjoint over k.
ProoJ
(Artin).
Without loss of generality, we may assume that K is
finitely generated over k. Let x I ' ... , x, be elements of K linearly indepen-
dent over k. Suppose we have a relation of linear dependence
X1YI + ...+ XnYn = 0
with Yi E L.
Let
q> be a P -valued place of Lover k. Let (t) be a transcen-
dence base of Kover k.
By hypothesis, the elements of (r) remain alge-
braically independent over L, and hence q> can be extended to a place of KL
which is identity on k(t). This place must then be an isomorphism of K on
its image, because K is a finite algebraic extension of k(t) (remark at the
end of Chapter VII, §3). After a suitable isomorphism, we may take a place
equivalent to q> which is the identity on K. Say q>(yJYn) is finite for all i (use
Proposition 3.4 of Chapter VII). We divide the relation of linear dependence
by Yn and apply
q> to get l>iq>(YJYn) = 0, which gives a linear relation
among the
Xi with coefficients in k", contradicting the linear disjointness.
This proves the theorem.
Theorem 4.13.
Let K be a regular extension of k, Jree Jrom an extension
L oj k over k. Then KL is a regular ex tension oj L.
Proof.
From the hypothesis, we deduce that K is free from the algebraic
closure L" of Lover k. By Theorem 4.12, K is linearly disjoint from La over
k. By Proposition 3.1, KL is linearly disjoint from La over L, and hence KL
is regular over L.

368
TRANSCENDENTAL EXTENSIONS
VIII, §4
Corollary 4.14.
Let K, L be regular extensions of k, free from each other
over k. Then KL is a regular extension of k.
Proof
Use Corollary 4.13 and Proposition 4.11(b).
Theorem 4.13 is one of the main reasons for emphasizing the class of
regular extensions: they remain regular under arbitrary base change of the
ground field k. Furthermore, Theorem 4.12 in the background is important
in the study of polynomial ideals as in the next section, and
we add
some remarks here on its implications. We now assume that the reader is
acquainted with the most basic properties of the tensor product (Chapter
XVI, §1 and §2).
Corollary 4.15.
Let K = k(x) be a finitely generated regular extension,
free from an extension L of k, and both contained in some larger field.
Then the natural k-algebra homomorphism
L ®k k[x] --+ L[x]
is an isomorphism.
Proof.
By Theorem 4.12 the homomorphism is injective, and it is obvi-
ously surjective, whence the corollary follows.
Corollary 4.16.
Let k(x) be a finitely generated regular extension, and let
p be the prime ideal in k[X] vanishing on (x), that is, consisting of all
polynomials f(X) E k[X] such that f(x) = O. Let L be an extension of k,
free from k(x) over k. Let PL be the prime ideal in L[X] vanishing on (x).
Then PL = pL[X], that is PL is the ideal generated by P in L[X], and in
particular, this ideal is prime.
Proof
Consider the exact sequence
0--+P --+ k[X] --+ k[x] --+ O.
Since we are dealing with vector spaces over a field, the sequence remains
exact when tensored with any k-space, so we get an exact sequence
0--+ L ®k P --+ L[X] --+ L ®k k[x] --+ O.
By Corollary 4.15, we know that L ®k k[x] = L[x], and the image of L ®k P
in L[X] is pL[X], so the lemma is proved.
Corollary 4.16 shows another aspect whereby regular extensions behave
well under extension of the base field, namely the way the prime ideal P
remains prime under such extensions.

VIII, §5
§5.
DERIVATIONS
DERIVATIONS
369
A derivation D of a ring R is a mapping D: R -+ R of R into itself which is
linear and satisfies the ordinary rule for derivatives, i.e.,
D(x + y) = Dx + Dy
and
D(xy) = xDy + yDx.
As an example of derivations, consider the polynomial ring k[X] over a field
k.
For each variable Xi' the partial derivative %Xi taken in the usual
manner is a derivation of k[X].
Let R be an entire ring and let K be its quotient field. Let D: R -+ R be a
derivation. Then D extends uniquely to a derivation of K, by defining
( / )
vDu - uDv
Duv =
2
•
V
It is immediately verified that the expression on the right-hand side is
independent of the way we represent an element of K as ul» (u, v E R), and
satisfies the conditions defining a derivation.
Note.
In this section, we shall discuss derivations of fields. For deriva-
tions in the context of rings and modules, see Chapter XIX, §3.
A derivation of a field K is trivial if Dx = 0 for all x E K. It is trivial over
a subfieId k of K if Dx = 0 for all x E k. A derivation is always trivial over
the prime field: One sees that
D(l) = D(1 . 1) = 2D(1),
whence D(1) = O.
We now consider the problem of extending derivations. Let
L = K(x) = K(x 1 , ••• , xn )
be a finitely generated extension.
If f E K[X], we denote by of/ox i the
polynomials of/oXi evaluated at (x). Given a derivation D on K, does there
exist a derivation D* on L coinciding with D on K ? If f(X) E K[X] is a
polynomial vanishing on (x), then any such D* must satisfy
(1)
o= D*f(x) = fD(X) +L(of/ox;)D*Xi'
where fD denotes the polynomial obtained by applying D to all coefficients
of f. Note that if relation (1) is satisfied for every element in a finite set of
generators of the ideal in K[X] vanishing on (x), then (1) is satisfied by every
polynomial of this ideal. This is an immediate consequence of the rules for
derivations. The preceding ideal will also be called the ideal determined by
(x) in K[X].

370
TRANSCENDENTAL EXTENSIONS
VIII, §5
og
D*g(x) = gD(X) +L ;;-uj ,
UXj
*( /h) = hD*g- gD*h
D 9
h2
'
The above necessary condition for the existence of a D* turns out to be
sufficient.
Theorem 5.1.
Let D be a derivation of a field K. Let
(x) = (Xl' ... , xn )
be a finite family of elements in an extension of K. Let {fa(X)} be a set of
generators for the ideal determined by (x) in K[X]. Then, if (u) is any set
of elements of K(x) satisfying the equations
o= faD(x) + L (ofa/oxJUj,
there is one and only one derivation D* of K(x) coinciding with D on K,
and such that D*xj = Uj for every i.
Proof.
The necessity has been shown above. Conversely, if g(x), h(x) are
in K[x], and h(x) =1= 0, one verifies immediately that the mapping D* defined
by the formulas
is well defined and is a derivation of K(x).
Consider the special case where (x) consists of one element x. Let D be a
given derivation on K .
Case 1.
x is separable algebraic over K. Let f(X) be the irreducible
polynomial satisfied by x over K. Then f'(x) =1= O. We have
0= fD(x) + f'(x)u,
whence U= -fD(x)/f'(x). Hence D extends to K(x) uniquely. If D is trivial
on K, then D is trivial on K(x).
Case 2.
x is transcendental over K.
Then D extends, and U can be
selected arbitrarily in K(x).
Case 3.
x is purely inseparable over K, so x" - a = 0, with a E K. Then
D extends to K(x) if and only if Da = O. In particular if D is trivial on K,
then U can be selected arbitrarily.
Proposition 5.2.
A finitely generated extension K(x) over K is separable
algebraic if and only if every derivation D of K(x) which is trivial on K is
trivial on K(x).
Proof
If K(x) is separable algebraic over K, this is Case 1. Conversely,
if it is not, we can make a tower of extensions between K and K(x), such

VIII , §5
DERIVATIONS
371
that each step is covered by one of the three above cases. At least one step
will be covered by Case 2 or 3. Taking the uppermost step of this latter
type, one sees immediately how to construct a derivation trivial on the
bottom and nontrivial on top of the tower.
Proposition 5.3.
Given K and elements (x) = (x l' ... , xn ) in some extension
field, assume that there exist n polynomials}; E K[X] such that:
(i) };(x) = 0, and
(ii) det(o};/8xj ) "# 0.
Then (x) is separably algebraic over K.
Proof.
Let D be a derivation on K(x), trivial on K. Having };(x) = °we
must have D};(x) = 0, whence the DXi satisfy n linear equations such that the
coefficient matrix has non-zero determinant. Hence DXi = 0, so D is trivial
on K(x). Hence K(x) is separable algebraic over K by Proposition 5.2.
The following proposition will follow directly from Cases 1 and 2.
Proposition 5.4.
Let K = k(x) be a finitely generated extension of k. An
element z of K is in K"k if and only if every derivation D of Kover k is
such that Dz = 0.
Proof.
If z is in K "k, then it is obvious that every derivation D of K
over k vanishes on z. Conversely, if z ¢ K"k, then z is purely inseparable
over K "k, and by Case 3 of the extension theorem, we can find a derivation
D trivial on K"k such that Dz = 1. This derivation is at first defined on the
field K Pk(z). One can extend it to K as follows. Suppose there is an element
WE K such that W ¢ KPk(z). Then wPE KPk, and D vanishes on wp• We can
then again apply Case 3 to extend D from KPk(z) to Krki», w).
Proceeding
stepwise, we finally reach K, thus proving our proposition.
The derivations D of a field K form a vector space over K if we define zD
for z E K by (zD)(x) = zDx.
Let K be a finitely generated extension of k, of dimension rover k. We
denote by :D the K-vector space of derivations D of Kover k (derivations of
K which are trivial on k). For each Z E K , we have a pairing
(D, z)~Dz
of (:D, K) into K.
Each element z of K gives therefore a K-linear functional
of :D. This functional is denoted by dz. We have
d(yz) = y dz + z dy,
d(y + z) = dy + dz.
These linear functionals form a subspace
~ of the dual space of :D, if we
define y dz by (D,Y dz)~ yDz.

372
TRANSCENDENTAL EXTENSIONS
VIII, §5
Proposition 5.5.
Assume that K is a separably generated and finitely
generated extension of k of transcendence degree r. Then the vector space
D (over K) of derivations of Kover k has dimension r. Elements t1, .. . , t,
of K from a separating transcendence base of Kover k if and only if
dtl ' .. . , dt, form a basis of the dual space of Dover K.
Proof
If tl' .. . , t, is a separating transcendence base for Kover k, then
we can find derivations D1, •• • , Dr of Kover k such that Ditj = Jij, by Cases
1 and 2 of the extension theorem.
Given DE D, let Wi = Dt.. Then clearly
D = LWiDi, and so the D, form a basis for Dover K, and the dti form the
dual basis. Conversely, if dtl' ... , dt, is a basis for rr: over K, and if K is not
separably generated over k(t), then by Cases 2 and 3 we can find a derivation
D which is trivial on k(t) but nontrivial on K. If D1, • • • , Dr is the dual basis
of dt1 , ... , dt, (so Ditj = Ji)
then D, D1 , ... , Dr would be linearly independent
over K, contradicting the first part of the theorem.
Corollary 5.6.
Let K be a finitely generated and separably generated
extension of k. Let z be an element of K transcendental over k. Then K is
separable over k(z) if and only if there exists a derivation D of Kover k
such that Dz =F O.
Proof
If K is separable over k(z), then z can be completed to a separat-
ing base of Kover k and we can apply the proposition. If Dz =F 0, then
dz =F 0, and we can complete dz to a basis of rr: over K.
Again from the
proposition, it follows that K will be separable over k(z).
Note.
Here we have discussed derivations of fields.
For derivations in
the context of rings and modules, see Chapter XVI.
As an application, we prove :
Theorem 5.7.
(Zariski-Matsusaka).
Let K be a finitely generated sepa-
rable extension of a field k. Let y, z E K and z rf= K"k if the characteristic
is p > O. Let u be transcendental over K, and put ku= k(u), K; = K(u).
(a) For all except possibly one value of c E k, K is a separable extension of
k(y + cz). Furthermore, K; is separable over ku(Y + uz).
(b) Assume that K is regular over k, and that its transcendence degree is at
least 2. Then for all but a finite number of elements c E k, K is
a regular extension of k(y + cz).
Furthermore, K; is regular over
ku(Y + uz).
Proof
We shall use throughout the fact that a subfield of a finitely
generated extension is also finitely generated (see Exercise 4).
If W is an element of K, and if there exists a derivation D of Kover
k such that Dw =F 0, then K is separable over k(w), by Corollary 5.6. Also
by Corollary 5.6, there exists D such that Dz =F O.
Then for all elements
c E k, except possibly one,
we have D(y + cz) = Dy + cDz =F O.
Also
we
may extend D to K; over ku by putting Du = 0, and then one sees that

VIII. §5
DERIVATIONS
373
D(y +uz)= Dy + uDz # 0, so K is separable over k(y + cz) except possibly
for one value of c, and K; is separable over ku(Y + uz). In what follows,
we assume that the constants c1, c2 , ••• are different from the exceptional
constant, and hence that K is separable over k(y + c.z) for i = 1, 2.
Assume next that K is regular over k and that the transcendence degree
is at least 2. Let E, = k(y + CiZ) (i = 1,2) and let E; be the algebraic closure
of E, in K.
We must show that E; = E, for all but a finite number of
constants. Note that k(y, z) = E1E2 is the compositum of E1 and E2, and
that k(y, z) has transcendence degree 2 over k. Hence
E~ and E; are free
over k. Being subfields of a regular extension of k, they are regular over k,
and are therefore linearly disjoint by Theorem 4.12.
K
I
/L~
E',(y, z)
E~(y, z)
/
"'-k(Y,/ ~
E'.",-
/
~
/E;
k(y + c1z)
k(y + C2Z)
<>
By construction, E; and E; are finite separable algebraic extensions of E 1
and E 2 respectively. Let L be the separable algebraic closure of k(y, z) in K.
There is only a finite number of intermediate fields between k(y, z) and L.
Furthermore, by Proposition 3.1 the fields E~ (y, z) and E; (y, z) are linearly
disjoint over k(y, z). Let C1 range over the finite number of constants which
will exhaust the intermediate extensions between Land k(y, z) obtainable by
lifting over k(y, z) a field of type E;. If C2 is now chosen different from any
one of these constants Cl' then the only way in which the condition of linear
disjointness mentioned above can be compatible with our choice of C2 is that
E;(y, z) = k(y, z), i.e. that E; = k(y + C2Z).
This means that k(y + C2Z) is
algebraically closed in K, and hence that K is regular over k(y + c2z).
As for K u, let u1 , u2 , •• • be infinitely many elements algebraically indepen-
dent over K.
Let k'=k(U 1,U2, .. .) and K'=K(U 1,U2, " ') be the fields
obtained by adjoining these elements to k and K respectively. By what has
already been proved, we know that K ' is regular over k'(u + UiZ) for all
but a finite number of integers i, say for i = 1. Our assertion (a) is then
a consequence of Corollary 4.14. This concludes the proof of Theorem 5.7.

374
TRANSCENDENTAL EXTENSIONS
VIII, Ex
Theorem 5.8.
Let K = k(x1,..., xn) = k(x) be a finitely generated regular
extension of a field k. Let
U1, .. . , Un be algebraically independent over
k(x). Let
and let ku= k(u1,.. ., Un' un+1). Then ku(x) is separable over ku' and if the
transcendence degree of k(x) over k is ~ 2, then ku(x) is regular over ku'
Proof
By the separability of k(x) over k, some Xi does not lie in K"k,
say x, ¢ K"k. Then we take
and
so that Un+1 = Y + Unz, and we apply Theorem 5.7 to conclude the proof.
Remark.
In the geometric language of the next chapter, Theorem 5.8
asserts that the intersection of a k-variety with a generic hyperplane
U1X1+"'+unXn-un+1=0
is a ku-variety, if the dimension of the k-variety is
~ 2. In any case, the
extension ku(x) is separable over ku'
EXERCISES
1. Prove that the complex numbers have infinitely many automorphisms. [Hint :
Use transcendence bases.] Describe all automorphisms and their cardinality.
2. A subfield k of a field K is said to be algebraically closed in K if every element of
K which is algebraic over k is contained in k. Prove: If k is algebraically closed
in K, and K, L are free over k, and L is separable over k or K is separable over
k, then L is algebraically closed in KL.
3. Let k c E c K be extension fields. Show that
tr. deg. (Klk) = tr. deg. (KIE) + tr. deg. (Elk).
If {x;} is a transcendence base of Elk, and {Yj} is a transcendence base of KIE,
then {Xi' Yj} is a transcendence base of Kfk .
4. Let Klk be a finitely generated extension, and let K ::::J E ::::Jk be a subextension.
Show that Elk is finitely generated.
5. Let k
be a field and k(x 1, • •• , xn) = k(x) a finite separable extension.
Let
U I ' . . . , Un be algebraically independent over k. Let
Let ku = k(ul' ... , un)' Show that ku(w) = ku(x).

VIII, Ex
EXERCISES
375
6. Let k(x) = k(x I ' .. . , x") be a separable extension of transcendence degree r ~ 1.
Let uij (i = 1, ..., r; j = 1,... , n) be algebraically independent over k(x). Let
"
Yi = I
UijXj '
j=1
Let k; = k(Uij).U t.r
(a) Show that ku(x) is separable algebraic over ku(YI,... ,Yr)'
(b) Show that there exists a polynomial P(u)E k[u] having the following prop-
erty. Let (e) = (eij) be elements of k such that Pte) # O. Let
"
Y; = I
eijxj.
j =1
Then k(x) is separable algebraic over k(y').
7. Let k be a field and k[xI' .. . , x"] = R a finitely generated entire ring over k with
quotient field k(x). Let L be a finite extension of k(x).
Let I be the integral
closure of R in L. Show that I is a finite R-module. [Use Noether normalization,
and deal with the inseparability problem and the separable case in two steps.]
8. Let D be a derivation of a field K. Then D":K --+ K is a linear map.
Let
1'" = Ker D", so p" is an additive subgroup of K. An element x E K is called a
logarithmic derivative (in K) if there exists y E K such that x = Dyly. Prove:
(a) An element x E K is the logarithmic derivative of an element yEP" but
Y If: 1',,-1 (n > 0) if and only if
(D + x)"(I) = 0
and
(b) Assume that K = Up", i.e. given x E K then x E 1'" for some n > O. Let F be
a subfield of K such that DF c F. Prove that x is a logarithmic derivative in
F if and only if x is a logarithmic derivative in K. [Hint:
If x = Dyly then
(D + x) = y-I D 0 Y and conversely.]
9. Let k be a field of characteristic 0, and let zI' .. . , z, be algebraically independent
over k. Let (eij), i = 1, ..., m and j = 1, ..., r be a matrix of integers with r ~ m,
and assume that this matrix has rank m. Let
for
i = 1, .. ., m.
Show that WI' ... , Wm are algebraically independent over k. [Hint:
Consider the
K-homomorphism mapping the K-space of derivations of Kfk into K(') given by
D f--+ (Dz d zI ' ... , Dz,lz,),
and derive a linear condition for those D vanishing on k(wl , • •• , wm ).]
10. Let k, (z) be as in Exercise 9. Show that if P is a rational function then
d(P(z)) = grad P(z)'dz,
using vector notation, i.e. dz = (dzI ' ... , dz,) and grad P = (DI P, .. ., D,P). Define
d log P and express it in terms of coordinates. If P, Q are rational functions in
k(z) show that
d 10g(PQ) = d log P + d log Q.

CHAPTER IX
Algebraic Spaces
This chapter gives the basic results concerning solutions of polynomial equa-
tions in several variables over a field k. First it will be proved that if such
equations have a common zero in some field, then they have a common zero in
the algebraic closure of k, and such a zero can be obtained by the process known
as specialization. However, it is useful to deal with transcendental extensions
of k as welL Indeed, if p is a prime ideal in k[X]
== k[XJ, ... , Xn], then
k[X]/p is a finitely generated ring over k, and the images Xi of Xi in this ring
may be transcendental over k, so we are led to consider such rings.
Even if we want to deal only with polynomial equations over a field, we are
led in a natural way to deal with equations over the integers Z. Indeed, if the
equations are homogeneous in the variables, then we shall prove in §3 and §4
that there are universal polynomials in their coefficients which determine whether
these equations have a common zero or not. "Universal" means that the coef-
ficients are integers, and any given special case comes from specializing these
universal polynomials to the special case.
Being led to consider polynomial equations over Z, we then consider ideals
a in Z[X]. The zeros of such an ideal form what is called an algebraic space. If
p is a prime ideal , the zeros of p form what is called an arithmetic variety. We
shall meet the first example in the discussion of elimination theory, for which
I follow van der Waerden's treatment in the first two editions of his Moderne
Algebra , Chapter XI.
However, when taking the polynomial ring Z[X]/a for some ideal a, it usually
happens that such a factor ring has divisors of zero, or even nilpotent elements.
Thus it is also natural to consider arbitrary commutative rings, and to lay the
foundations of algebraic geometry over arbitrary commutative rings as did Groth-
endieck. We give some basic definitions for this purpose in §5. Whereas the
present chapter gives the flavor of algebraic geometry dealing with specific
polynomial ideals , the next chapter gives the flavor of geometry developing from
commutative algebra, and its systematic application to the more general cases
just mentioned.
377
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

378
ALGEBRAIC SPACES
IX, §1
The present chapter and the next will also serve the purpose of giving the
reader an introduction to books on algebraic geometry, notably Hartshorne's
systematic basic account. For instance , I have included those results which are
needed for Hartshorne's Chapter I and II.
§1 .
HILBERT'S NULLSTELLENSATZ
The Nullstellensatz has to do with a special case of the extension theorem
for homomorphisms, applied to finitely generated rings over fields.
Theorem 1.1.
Let k be a field, and let k[x] = k[x l, . . . , xn] be a finitely
generated ring over k. Let tp : k --+ L be an embedding of k into an alge-
braically closed field L.
Then there exists an extension of cp to a homo-
morphism of k[x] into L.
Proof.
Let 9Jl be a maximal ideal of k[x].
Let a be the canonical homo-
morphism a :k[x] --+ k[x]j9Jl. Then ak[axl, . . ., axn] is a field, and is in fact
an exten sion field of ak. If we can prove our theorem when the finitely generated
ring is in fact a field, then we apply cp 0 a- 1 on ak and extend this to a homo-
morphism of ak[ax l, .. . , axn] into L to get what we want.
Without loss of generalit y, we therefore assume that k[x] is a field. If it is
algebraic over k, we are done (by the known result for algebraic extensions).
Otherwise, let t l ' . . . . t, be a transcendence basis, r ~ l.
Without loss of
generality, we may assume that cp is the identity on k. Each element X I' . . . , x,
is algebraic over k(tI' . . . . r.). If we multiply the irreducible polynomial
Irr[x. , k(t), X ) by a suitable non- zero element of k[t] , then we get a pol ynomial
all of whose coefficients lie in k[t]. Let al(t), . . . , an(t) be the set of the lead ing
coefficients of these polynomials, and let a(t) be their product,
Since a(t)
=1= 0, there exist elements t l,..., t~ E k" such that a(t')
=1= 0, and
hence ai(t')
=1= °for any i. Each Xi is integral over the ring
k[t I ' ... , t. , al~t)' ... , ar~t)l
Consider the homomorphism
such that cp is the identity on k, and cp(t) = ti . Let p be its kernel. Then a(t) rt p.

IX, §1
HILBERT'S NULLSTELLENSATZ
379
Our homomorphism qJ extends un iqu ely to the local ring k[t]p and by the
preceding remarks, it extends to a hom omorphism of
into k", using Proposition 3.1 of Chapter VII . This proves what we wanted.
Corollary 1.2.
Let k be a field and k[x l , • • • , XII] a finitely generated ex-
tension ring of k. If k[x] is afield, then k[x] is algebraic over k.
Proof .
All homomorphisms of a field are isomorphisms (onto the image),
and there exist s a homomorphism of k[x] over k into the algebra ic closure of k.
Corollary 1.3.
Let k[x l ' .. . ,x,,] be a finitely generated entire ring over a
field k, and let YI' . . . , Ymbe non-zero elementsof this ring. Then there exists
a homomorphism
over k such that ljJ(y) =f. 0 for all j = 1, . . . , m.
Proof.
Consider
the
ring k[XI, .. . , X II, y ~ I , .. ., y';; l]
and
apply the
theorem to this ring.
Let S be a set of polynom ials in the pol ynomial ring k[X 1, . . . , XII] in n
variables. Let L be an extension field of k . By a zero of S in L one means an
n-tuple of elements (c l , . . . , c,,) in L such that
f(c l,·· · ,c,,) = O
for allf E S. If S consists of one polynomial j, then we also say that (c) is a zero
off
The set of all zeros of S is called an algebraic set in L (or more accurately
in L(II) . Let a be the ideal generated by all elements of S. Since S ea it is clear
that every zero of a is also a zero of S. However, the converse obviously holds,
namely every zero of S is also a zero of a because every element of a is of type
with Jj E Sand gi E k[X].
Thus when considering zeros of a set S, we may
just consider zeros of an ideal. We note parenthetically that every ideal is
finitel y generated, and so every algebraic set is the set of zero s of a finite number
of polynomials. As another corollary of Theorem 1.1 , we get :
Theorem 1.4.
Let a be an ideal in k[X] = k[X I> . • . , XII]. Then either
a = k[X] or a has a zero in k".

380
ALGEBRAIC SPACES
IX, §1
Proof.
Suppose 0 #- k[X].
Then 0 is contained in some maximal ideal
m, and k[X]/m is a field, which is a finitely generated extension of k, because
it is generated by the images of X I ' . . . , X n mod m. By Corollary 2.2, this
field is algebraic over k, and can therefore be embedded in the algebraic closure
k". The homomorphism on k[X] obtained by the composition of the canonical
map mod rn, followed by this embedded gives the desired zero of 0, and con-
cludes the proof of the theorem.
In §3 we shall consider conditions on a family of polynomials to have a
common zero. Theorem 1.4 implies that if they have a common zero in some
field, then they have a common zero in the algebraic closure of the field generated
by their coefficients over the prime field.
Theorem 1.5.
(Hilbert's Nullstellensatz).
Let 0 be an ideal in k[X]. Let
fbeapolynomialink[X]suchthatf(c) = ofor every zero (c) = (c., . . . ,cn)
of 0 in k". Then there exists an integer m > 0 such thatf" E o.
Proof.
We may assume that f #- O.
We use the Rabinowitsch trick of
introducing a new variable Y, and of considering the ideal 0' generated by
c and 1 -
Yf in k[X, Y].
By Theorem 1.4, and the current assumption, the
ideal 0 ' must be the whole polynomial ring k[X, Y], so there exist polynomials
giE k[X, Y] and hi E 0 such that
1 = go(1 -
Yf) + glhl + ... + g,h,.
We substitute t:' for Yand multiply by an appropriate power fm of f to
clear denominators on the right-hand side. This concludes the proof.
For questions involving how effective the Nullstellensatz can be made, see
the following references also related to the discussion of elimination theory
discussed later in this chapter.
Bibliography
[BeY 91]
C. BERENSTEIN and A. YGER, Effective Bezout identities in Q[z I' ... , znl.
Acta Math. 166 (1991), pp. 69-120
[Br 87]
D. BROWNAWELL, Bounds for the degree in Nullstellensatz, Ann . of Math.
126 (1987), pp. 577-592
[Br 88]
D. BROWNAWELL, Local diophantine nullstellen inequalities, J. Amer. Math.
Soc. 1 (1988), pp. 311-322
[Br 89]
D. BROWNAWELL, Applications of Cayley-Chow forms, Springer Lecture
Notes 1380: Number Theory, Vim 1987, H. P. Schlickewei and E. Wirsing
(cds.), pp. 1-18
[Ko 88]
J. KOLLAR, Sharp effective nullstellensatz, J. Amer. Math. Soc. 1 No. 4
(1988), pp. 963-975

IX, §2
ALGEBRAIC SETS, SPACES AND VARIETIES
381
§2.
ALGEBRAIC SETS, SPACES AND VARIETIES
We shall make some very elementary remarks on algebraic sets. Let k be a
field, and let A be an algebraic set of zeros in some fixed algebraically closed
extension field of k. The set of all polynomialsf
E k[ Xl ' . . . , X n] such that
f(x) = 0 for all (x) E A is obviously an ideal a in k[X], and is determined by
A. We shall call it the ideal belonging to A, or say that it is associated with A.
If A is the set of zeros of a set S of polynomials, then Sea, but a may be bigger
than S. On the other hand, we observe that A is also the set of zeros of a.
Let A, B be algebraic sets, and a, b their associated ideals. Then it is clear
that A c B if and only if a :=J b. Hence A = B if and only if a = b. This has an
important consequence.
Since the polynomial ring k[X] is Noetherian, it
follows that algebraic sets satisfy the dual property, namely every descending
sequence of algebraic sets
must be such that Am = Am+ 1 = ... for some integer m, i.e. all Avare equal for
v ~ m. Furthermore, dually to another property characterizing the Noetherian
condition, we conclude that every non-empty set of algebraic sets contains a
minimal element.
Theorem 2.1.
The finite union and the fin ite intersection of algebraic sets
are algebraic sets. If A, B are the algebraic sets ofzeros ofideals a, b, respec-
tively, then A u B is the set ofzeros ofa n b and A n B is the set ofzeros of
(a, b).
Proof.
We first consider A u B.
Let (x) E A u B.
Then (x) is a zero
of a n b. Conversely, let (x) be a zero of a n b, and suppose (x) ¢: A. There
exists a polynomial f
E 0 such that f(x) # O.
But ub c o n b and hence
(fg)(x) = 0 for all g E b, whence g(x) = 0 for all g E b. Hence (x) lies in B, and
A u B is an algebraic set of zeros of a n b.
To prove that A n B is an algebraic set, let (x) E A r. B. Then (x) is a zero
of (a, b). Conversely, let (x) be a zero of (0, b). Then obviously (x) E A n B, as
desired . This proves our theorem.
An algebraic set V is called k-irreducible if it cannot be expressed as a union
V = A u B of algebraic sets A, B with A, B distinct from V. We also say ir-
reducible instead of k-irreducible.
Theorem 2.2.
Let A be an algebraic set.
(i) Then A can be expressed as a finite union of irreducible algebraic sets
A = ~ U . . . U yr.
(ii) If there is no inclusion relation among the "I. i.e. if V; et \:i for i =t= j. then
the representation is unique.

382
ALGEBRAIC SPACES
(iii) Let W, VJ..... v,. be irreducible algebraic sets such that
WCVJU ... Uv,..
IX, §2
Then W C V; for some i.
Proof.
We first show existence.
Suppose the set of algebraic sets which
cannot be represented as a finite union of irreducible ones is not empty. Let
V be a minimal element in its. Then V cannot be irreducible, and we can write
V = A u B where A, B are algebraic sets, but A =I V and B =I V. Since each
one of A, B is strictly smaller than V, we can express A, B as finite unions of
irreducible algebraic sets, and thus get an expression for V, contradiction.
The uniqueness will follow from (iii), which we prove next. Let W be con-
tained in the union VI U ... U v,.. Then
W = (W n VI) U . .. U (W n v,.).
Since each W n V; is an algebraic set, by the irreducibility of W we must have
W = W n Vi for some i . Hence W C Vi for some i, thus proving (iii) .
Now to prove (ii), apply (iii) to each Hj. Then for each j there is some i such
that Hj C Vi. Similarly for each i there exists
II such that Vi C Wv- Since there
is no inclusion relation among the Hj's, we must have Hj = Vi = WI" This proves
that each Hj appears among the Vj's and each V; appears among the Hj's, and
proves the uniqueness of the representation. It also concludes the proof of Theo-
rem 2.2.
Theorem 2.3
An algebraic set is irreducible if and only if its associated ideal
is prime.
Proof.
Let V be irreducible and let p be its associated ideal. If p is not
prime , we can find two polynomials f, 9 E k[X] such that f ¢. p , 9 ¢. p , but
fg E p , Let a = (p, f) and b = (p, g) . Let A be the algebraic set of zeros of a,
and B the algebraic set of zeros of b. Then A C V, A
=1= V and B C V, B
=1= V.
Furthermore A U B = V. Indeed , A U B C V trivially. Conversely, let (x) E V.
Then (fg)(x) = 0 implies f(x) or g(x) = O. Hence (x) E A or (x) E B, proving
V = A U B, and V is not irreducible. Conversely, let V be the algebraic set
of zeros of a prime ideal p. Suppose V = A U B with A
=1= V and B
=1= V.
Let a, b be the ideals associated with A and B respectively. There exist poly-
nomials f E a, f ¢. p and 9 E b, 9 ¢. p. Butfg vanishes on A U B and hence lies
in p, contradiction which proves the theorem .
Warning.
Given a field k and a prime ideal pin k[X], it may be that the
ideal generated by p in ka[X] is not prime, and the algebraic set defined over k"
by pka[X] has more than one component, and so is not irreducible. Hence the
prefix referring to k is really necessary.
It is also useful to extend the terminology of algebraic sets as follows . Given
an ideal a C k[X] , to each field K containing k we can associate to a the set

IX, §2
ALGEBRAIC SETS, SPACES AND VARIETIES
383
?La(K) consisting of the zeros of a in K. Thu s ?La is an association
?La: K ~ ?La(K) C K(n).
We shall speak of ?La itself as an algebraic space, so that ?La is not a set , but
to each field K associates the set ?La(K). Thus ?La is a functor from extensions
K of k to sets (functorial with respect to field isomorphisms) . By a k-variety we
mean the algebraic space associated with a prime ideal p.
The notion of associated ideal appl ies also to such ?La' and the associated
ideal of ?La is also rad(a). We shall omit the subscript a and write simply ?L for
this generalized notion of algebraic space. Of course we have
?La = ?L radto ) :
We say that ?La(K) is the set of points of ?Lain K. By the Hilbert Nullstellensatz,
Theorem 1.1 , it follows that if K C K' are two algebraically closed fields
containing k, then the ideals associated with ?La(K) and ?La(K' ) are equal to each
other, and also equal to rad(a) . Thus the smallest algebraically closed field ka
containing k already determines these ideals. Howe ver, it is also useful to consider
larger fields which contain transcendental elements, as we shall see.
As another example, consider the polynomial ring k[X\, . . . , Xn] = k[X] .
Let An denote the algebraic space associated with the zero ideal. Then An
is called affine n-space. Let K be a field containing k. For each n-tuple
(c ., . . . , cn) E K(n) we get a homomorphism
ip: k[X 1, • • · , Xn ] -
K
such that cp(Xi ) = c, for all i , Thu s points in An(K) correspond bijectively to
homomorphisms of k(X) into K.
More generally, let V be a k-variety with associated prime ideal p. Then
k[X]/p is entire. Denote by ~i the image ofXi under the canonical homomorphism
k[X] -
k[X] /p. We call (g) the generic point of V over k. On the other hand ,
let (x) be a point of V in some field K . Then p vanishes on (x) , so the homomor-
phism cp : k[X] -
k[x] sending X i ~ Xi factors through k[X] /p = k[g], when ce
we obtain a natural homomorphism klg] -
k[x]. If this homomorphism is an
isomorphism, then we call (x) a generic point of V in K .
Given two points (x) E An(K) and (x') E An(K' ), we say that (x ' ) is a
specialization of (x) (over k) if the map xi ~ xi is induced by a homomorphism
k[x] -
k[x'] . From the definition of a generic point of a variety, it is then
immediate that :
A variety V is the set of specializations of its generic point , or of a generic
point.
In other words, V(K) is the set of spec ializations of W in K for every field K
containing k.
Let us look at the converse construction of algebraic sets. Let
(x) =
(x l ' . . . , x n ) be an n-tuple with coordinates Xi E K for some extension field
K of k. Let p be the ideal in k[X] consisting of all polynomials f(X) such that

384
ALGEBRAIC SPACES
IX, §2
f(x) = O. We call p the ideal vanishing on (x) . Then p is prime, becau se if
f g e p sof(x)g(x) = 0, then j' e p or 9 Ep since K has no divisors ofO. Hence
~p is a k-variety V, and (x) is a generic point of V over k because k[X]/ p= k[x].
For future use, we state the next result for the polynomial ring over a factorial
ring rather than over a field .
Theorem 2.4.
Let R be afactorial ring, and let~ • . . . • Wmbe m independent
variables over its quotient field k. Let k(wt. . . . , wm) be an extension of tran-
scendence degree m -
I . Then the ideal in R[W] vanishing on (w) is principal.
Proof.
By hypothesis there is some polynomial P(W) E R[W] of degree
~ I vanishing on (w), and after taking an irreducible factor we may assume
that this polynomial is irreducible, and so is a prime element in the factorial ring
R[W]. Let G(W) E R[Wj vani sh on (w). To prove that P divides G, after selecting
some irreducible factor of G vanishing on (w) if necessary, we may assume
without loss of generality that G is a prime element in R[W]. One of the variables
lV; occurs in P(W) , say Wm, so that Wm is algebraic over k(w\, . .. , Wm - l)' Then
( w I> . . • , wm-l ) are algebraically independent, and hence Wm also occurs in
G. Furthermore, P(WI> . •. ,
Wm- I> Wm) is irreducible as a polynomial in
k(w l, . . . , Wm-t)[Wm] by the Gauss lemma as in Chapter IV, Theorem 2.3 .
Hence there exists a polynomial H(Wm) E k(wl' .. . , wm- l)[Wm] such that
G(W) = H(Wm)P(W)·
Let R' = R[wl"' "
wm-d . Then P, G have content 1 as polynomials in
R'[Wml. By Chapter IV Corollary 2.2 we conclude that H E R'[Wm] = R[W],
which proves Theorem 2.4.
Next we consider homogeneous ideals and projective space. A polynomial
f(X) E k[Xj can be written as a linear combination
with monomials M ( v)(X ) =
X~l . .. x~n and c ( v) E
k . We denote the degree of
M ( v) by
Ivi = deg M (v) = 2: Vi '
If in this expression for f the degrees of the monomials Xi v) are all the same
(whenever the coefficient c( v) is * 0), then we say thatfis a form , or also that
f is a homogeneous (of that degree). An arbitrary polynomial f (X ) in K[X] can
also be written
f(X ) = "Lj<dl(X ),
where each j<dl is a form of degree d (which may be 0). We call j<dl the
homogeneous part off of degree d.
An ideal a of k[X] is called homogeneous if whenever f
E a then each
homogeneous part Idl also lies in a .

IX, §2
ALGEBRAIC SETS, SPACES AND VARIETIES
385
Proposition 2.5.
An ideal a is homogeneous if and only if a has a set of
generators over k[X] consisting offorms.
Proof.
Suppose a is homogeneous and that fl' . . . , fr are generators. By
hypothesis, for each integer d ~ 0 the homogeneous componentsjv" also lie in
a, and the set of suchfi(d) (for all i, d) form a set of homogeneous generators.
Conversely, let f be a homogeneous element in a and let g E K[X] be arbitrary.
For each d , g(d)f lies in a, and g(d)f is homogeneous, so all the homogeneous
components of gf also lie in a. Applying this remark to the case whenf ranges
over a set of homogeneous generators for a shows that a is homogeneous, and
concludes the proof of the proposition.
An algebraic space '!t is called homogeneous if for every point (x) E ?£ and
t transcencental over k(x), the point (tx) also lies in '!t . If t, u are transcendental
over k(x), then there is an isomorphism
k[x , t) ~ k[x, u]
which sends t on u and restricts to the identity on k[x], so to verify the above
condition, it suffices to verify it for some transcendental t over k(x) .
Proposition 2.6.
An algebraic space '!t is homogeneous if and only if its
associated ideal a is homogeneous.
Proof.
Suppose?£ is homogeneous . Letf(X) E k[X] vanish on '!t. For each
(x)
E ?£ and t transcendental over k(x) we have
o = f(x) = fCtx) = 2: tdf(d)(x).
d
Thereforef(d)(x) = 0 for all d, whencejv" E a for all d . Hence a is homogeneous .
Conversely, suppose a homogeneous. By the Hilbert Nullstellensatz, we know
that '!t consists of the zeros of a , and hence consists of the zeros of a set of
homogeneous generators for a . But iff is one of those homogeneous generators
of degree d, and (x) is a point of ?£, then for t transcendental over k(x) we have
o = f(x) = tdf(x) = f(tx) ,
so (tx) is also a zero of a. Hence ?£is homogeneous, thus proving the proposition.
Proposition 2.7.
Let?£ be a homogeneous algebraic space. Then each irre-
ducible component V of '!t is also homogeneous.
Proof.
Let V = VI" . . , Vr be the irreducible components of '!t, without
inclusion relation. By Remark 3.3 we know that VI et V2 U . .. U v,., so there
is a point (x) E ~ such that (x) ¢. VI for i = 2, . . . , r. By hypothesis, for t transcen-
dental over k(x) it follows that (tx) E '!t so (tx) E Vi for some i , Specializing to
t =
I, we conclude that (x) E Vi, so i =
I, which proves that VI is homoge-
neous, as was to be shown.
Let V be a variety defined over k by a prime ideal pin k[X] . Let (x) be a
generic point of V over k. We say that (x) is homogeneous (over k) if for t

386
ALGEBRAIC SPACES
IX, §2
transcendental over k(x), the point (tx) is also a point of V, or in other words,
(zr) is a specialization of (x) . If this is the case , then we have an isomorphism
k[x). .. . , x n] = k[tx). .. . , tx n],
which is the identity on k and sends xi on tx.. It then follows from the preceding
propositions that the following conditions are equivalent for a variety V over k:
V is homogeneous.
The prime ideal of V in k[X] is homogeneous.
A generic point of V over k is homogeneous.
A homogeneous ideal always has a zero, namely the origin (0) , which will
be called the trivial zero. We shall want to know when a homogeneous algebraic
set has a non-trivial zero (in some algebraically closed field) . For this we introduce
the terminology of projective space as follows . Let (x) be some point in An and
A an element of some field containing k(x). Then we denote by (Ax) the point
(Ax) , .. . , Axn). Two points (x), (y) E An(K) for some field K are called equivalent
if not all their coordinates are 0, and there exists some element A E K, A* 0,
such that (Ax) = (y). The equivalence classes of such points in An(K) are called
the points of projective space in K. We denote this projective space by pn -),
and the set of points of projective space in K by pn-\ (K) . We define an algebraic
space in projective space to be the non-trivial zeros of a homogeneous ideal,
with two zeros identified if they differ by a common non-zero factor.
Algebraic spaces over rings
As we shall see in the next section, it is not sufficient to look only at ideals
in k[X] for some field k. Sometimes, even often, one wants to deal with polynomial
equations over the integers Z, for several reasons. In the example of the next
sections, we shall find universal conditions over Z on the coefficients of a system
of forms so that these forms have a non-trivial common zero. Furthermore, in
number theory-diophantine questions-one wants to consider systems of equa-
tions with integer coefficients, and to determine solutions of these equations in
the integers or in the rational numbers, or solutions obtained by reducing mod
p for a prime p . Thus one is led to extend the notions of algebraic space and
variety as follows . Even though the applications of the next section will be over
Z, we shall now give general definitions over an arbitrary commutative ring R.
Letf(X) E R[X] = R[X), . . . , Xn] be a polynomial with coefficients in R.
Let R -.,> A be an R-algebra, by which for the rest of this chapter we mean a
homomorphism of commutative rings. We obtain a corresponding homomorphism
R[X]
-.,> A[X]
on the polynomial rings, denoted by f ~ fA whereby the coefficients of fA are
the images of the coefficients off under the homomorphism R -.,> A . By a zero
of f in A we mean a zero of fA in A . Similarly, let S be a set of polynomials in
R[X] . By a zero of S in A we mean a common zero in A of all polynomials
f E S. Let a be the ideal generated by S in R[X] . Then a zero of S in A is also

IX, §2
ALGEBRAIC SETS, SPACES AND VARIETIES
387
a zero of a in A. We denote the set of zeros of S in A by ;Xs(A) , so that we have
We call ;Xa(A) an algebraic set over R. Thus we have an association
;Xa : A M
;Xa(A)
which to each R-algebra associates the set of zeros of a in that algebra. We note
that R-algebras form a category, whereby a morphism is a ring homomorphism
<p : A ~ A' making the following diagram commutative:
Then it is immediately verified that ;Xa is a functor from the category of R-
algebras to the category of sets . Again we call ;Xa an algebraic space over R.
If R is Noetherian, then R[X] is also Noetherian (Chapter IV, Theorem 4.1),
and so if a is an ideal , then there is always some finite set of polynomials S
generating the ideal, so ;Xs = ;Xa'
The notion of radical of a is again defined as the set of polynomials
h e R[X] such that hN E a for some positive integer N. Then the following state-
ment is immediate:
Suppose that R is entire. Then for every R-algebra R ~ K with a field K, we
have
We can define affine space An over R. Its points consist of all n-tuples
(x\> .. . , xn) = (x) with Xi in some R-algebra A . Thus An is again an association
A M
An(A)
from
R-algebras
to
sets
of
points.
Such
points
are
in
bijection
with
homormorphisms
R[X] ~ A
from the polynomial ring overR into A. In the next section we shall limit ourselves
to the case when A = K is a field, and we shall consider only the functor
K M
An(K) for fields K . Furthermore, we shall deal especially with the case
when R = Z, so Z has a unique homomorphism into a field K . Thus a field K
can always be viewed as a Z-algebra.
Suppose finally thatR is entire (for simplicity). We can also considerprojective
space over R. Let a be an ideal in R[X] . We define a to be homogeneous just as
before. Then a homogeneous ideal in R[X] can be viewed as defining an algebraic
subset in projective space pn(K) for each field K (as an R-algebra). If R = Z ,

388
ALGEBRAIC SPACES
IX, §3
then a defines an algebraic subset in pn(K) for every field K. Similarly, one can
define the notion of a homogeneous algebraic space ?I over R, and over the
integers Z a fortiori . Propositions 2.6 and 2.7 and their proofs are also valid in
this more general case, viewing ?I = ?Ia as a functor from fields K to sets pn(K) .
If a is a prime ideal P, then we call ?Ip an R-variety V. If R is Noetherian,
so R[X] is Noetherian, it follows as before that an algebraic space ?I over R is
a finite union of R-varieties without inclusion relations. We shall carry this out
in §5, in the very general context of commutative rings. Just as we did over a
field, we may form the factor ring Z[X]/p and the image (x) of (X) in this factor
ring is called a generic point of V.
§3.
PROJECTIONS AND ELIMINATION
Let (W) = (",\, .. . , Wm) and (X) = (XI' . .. ,Xn ) be two sets of independent
variables. Then ideals in k[W, X] define algebraic spaces in the product space
Am+n. Let a be an ideal in k[W, X]. Let al = a n k[W] . Let ?I be the algebraic
space of zeros of a and let ?I I be the algebraic space of zeros of a I' We have
the projection
which maps a point (w , x) to its first set of coordinates (w). It is clear that
pr?I C ?I I' In general it is not true that pr?I = ?I I ' For example, the ideal p gen-
erated by the single polynomial Wy - W2XI = 0 is prime. Its intersection with
k[",\, W2] is the zero ideal. But it is not true that every point in the affine
(",\, W2)-space is the projection of a point in the variety ?Ip • For instance, the
point (I, 0) is not the projection of any zero of p. One says in such a case that
the projection is incomplete. We shall now consider a situation when such a
phenomenon doe s not occur.
In the first place, let p be a prime ideal in k[W, X] and let V be its variety
of zeros . Let (w, x) be a generic point of V. Let PI = Pn k[W] . Then (w) is a
generic point of the variety VI which is the algebraic space zeros of PI' This is
immediate from the canonical injective homomorphism
k[W]/pI ~ k[W, Xl/po
Thus the generic point (w) of VI is the projection of the generic point (w, x ) of
V. The question is whether a special point (w') of VI is the projection of a point
of V.
In the subsequent applications, we shall consider ideals which are homo-
geneous only in the X-variables, and similarly algebraic subsets which are homo-
geneous in the second set of variables in An.

IX, §3
PROJECTIONS AND ELIMINATION
389
An ideal a in k[W, X] which is homogeneous in (X) defines an algebraic space
in Am X p n-I . If V is an irreducible component of the algebraic set defined by
a, then we may view V as a subvariety of Am X pn-I . Let P be the prime ideal
associated with V. Then P is homogeneous in (X ). Let PI = P n k[W]. We shall
see that the situation of an incomplete projection mentioned previously is elim-
inated when we deal with projective space.
We can also consider the product Am X P" , defined by the zero ideal over
Z. For each field K , the set of points of Am X P" in K is Am(K) X pn(K) . An
ideal a in Z[W, X], homogeneous in (X), defines an algebraic space
~ = ~Q in
Am X P" . We may form its projection ~ \ on the first factor. This applies in
particular when a is a prime ideal P, in which case we call
~Q an arithmetic
subvariety of Am
X P", Its projection VI is an arithmetic subvariety of Am,
associated with the prime ideal PI = Pn Z[W].
Theorem 3.1.
Let (W) = (WI' ... , Wm) and (X) = (XI' .. . , Xn ) be indepen-
dent families of variables. Let P be a prime ideal in k[W, X] (resp . Z[W, Xl)
and assume P is homogeneous in (X). Let V be the corresponding irreducible
algebraic space in Am X pn-I . Let PI = Pn k[W] (resp. P n Z[W]), and let
Vi be the projection of V on the first factor. Then VI is the algebraic space
of zeros of PI in Am.
Proof.
Let V have generic point (w, x). We have to prove that every zero
(w' ) of PI in a field is the projection of some zero (w', x') of P such that not all
the coordinates of (x') are equal to O. By assumption, not all the coordinates of
(x) are equal to 0, since we viewed Vas a subset of Am X pn-I. For definiteness,
say we are dealing with the case of a field k. By Chapter VII , Proposition 3.3 ,
the homomorphism k[w] ~ k[w'] can be extended to a place cp of k(w, x ) .
By Proposition 3.4 of Chapter VII,
there is some coordinate Xj such that
cp(x;/x) 4= 00 for all i = I, . . . , n. We let xi = cp(x;/x) for all i to conclude the
proof. The proof is similar when dealing with algebraic spaces over Z, replacing
k by Z.
Remarks.
Given the point (w') E Am, the point (w', x') in Am X pn-\ may
of course not lie in k(w') . The coordinates (x ') could even be transcendental
over k(x') . By anyone of the form s of the Hilbert Nullstellensatz, say Corollary
1.3 of Theorem 1.1, we do know that (x') could be found algebraic over k(w'),
however. In light of the various versions of the Nullstellensatz, if a set of forms
has a non-trivial common zero in some field, then it has a non-trivial common
zero in the algebraic closure of the field generated by the coefficients of the
forms over the prime field. In a theorem such as Theorem I .2 below, the conditions
on the coefficients for the forms to have a non-trivial common zero (or a zero
in projective space) are therefore also conditions for the forms to have such a
zero in that algebraic closure.
We shall apply Theorem 3.1 to show that given a finite family of homogeneous
polynomials, the property that they have a non-trivial common zero in some

390
ALGEBRAIC SPACES
IX, §3
algebraically closed field can be expressed in terms of a finite number of universal
polynomial equations in their coefficients. We make this more precise as follows .
Consider a finite set of forms (f) = (fl" .. , f r)' Let d., . . . , d; be their
degrees. We assume d, ~ I for i = I, .. . , r. Eachfi can be written
(I)
/; = 2: wi,(v)M(v)(X)
where M(v)(X) is a monomial in (X) of degree d. , and wi,(v) is a coefficient. We
shall say that (f) has a non-trivial zero (x) if (x)
=1= (0) andI.(x) = 0 for all i ,
We let (w) = (w)j be the point obtained by arranging the coefficients wi ,(V) of
the forms in some definite order, and we consider this point as a point in some
affine space Am, where m is the number of such coefficients. This integer m is
determined by the given degrees d., .. . , d.. In other words, given such degrees,
the set of all forms (f) = (fl' . .. , fr) with these degrees is in bijection with
the points of Am.
Theorem 3.2. (Fundamental theorem of elimination theory.)
Given
degrees d., ... , d., the set of all forms (fl ' . . . ,fr) in n variables having a
non-trivial common zero is un algebraic subspace of Am over Z.
Proof.
Let (W) = (Wi,(V» be a family of variables independent of (X) . Let
(F) = (FI , .• • , Fr) be the family of polynomials in Z[W, Xl given by
(2)
Fi(W, X) = 2: Wi ,(v)M( v)(X)
where M( v)(X) ranges over all monomials in (X) of degree d., so (W) = (W)F'
We call FI , . • • , F; generic forms . Let
a = ideal in Z[W, X] generated by F1, • • • , Fr.
Then a is homogeneous in (X) . Thus we are in the situation of Theorem 3.1,
with a defining an algebraic space a in Am X pn-l . Note that(w) is a specialization
of (W), or, as we also say, (f) is a specialization of (F) . As in Theorem 3.1,
let a l be the projection of a on the first factor . Then directly from the definitions,
(f) has a non-trivial zero if and only if (w)j lies in aI' so Theorem 3.2 is a
special case of Theorem 3.1.
Corollary 3.3.
Let (f) be a family of n forms in n variables, and assume
that (w)j is a generic point of Am, i.e. that the coefficients of these forms are
algebraically independent . Then (f) does not have a non-trivial zero.
Proof.
There exists a specialization of (f) which has only the trivial zero ,
namelyfl = x11, • • •
, f~ = X~n.
Next we follow van der Waerden in showing that a and hence aI are irreducible.
Theorem 3.4.
The algebraic space aI offorms having a non-trivial common
zero in Theorem 3.2 is actually a Z-variety, i.e. it is irreducible . The prime ideal

IX, §3
PROJECTIONS AND ELIMINATION
391
p in Z[W, Xl associated with a consists of all polynomials G(W, X ) E Z[W, X]
such that f or some index j there is an integer s ;;; 0 satisfying
(*)j
XJG(W, X) :; 0 mod (F1, • •• , Fr); that is, XJG(W, X) EO .
If relation (*) holds fo r one index j, then it holds fo r every j = I , . . . , n. (Of
course, the integer s depends on j .)
Proof.
We con struct a generic point of a.We select anyone ofthe variables,
say Xq , and rewrite the form s F, as follows:
Fi(W , X ) = n + ZiX~i
where Ft is the sum of all monomials except the monomial containing X~j .
The coefficients (W) are thereby split into two famili es, which we denote by (Y)
and (Z ), where (Z)
=
(ZI"'"
Zr) are the coefficients of (X~I , .. . , X~r)in
(F1, • • • , Fr), and (Y) is the remaining family of coefficients of F f, . . . , F~ .
We have (W) = (Y, Z), and we may write the polynomials F, in the form
Fi(W, X) = Fi (Y, Z, X) = F r(y, X) + ZiX~j.
Corresponding to the variables (Y, X) we choose quantities (y, x) algebraically
independent over Z . We let
(3)
Zi =
-n(y ,X)/X~i = -n(y, x/xq ) .
We shall pro ve that (y, Z, x) is a generic point of a .
From our construction, it is immediately clear that Fi(y , z, x) = 0 for all i ,
and consequently if G(W, X) E Z[W, Xl satisfies (*), then G(y , z, x) = O.
Con versely, let G(Y, Z, X) E Z[Y, Z, Xl = Z[W, Xl satisfy G(y , z, x) = O.
From Taylor's formula in seve ral variables we obtain
G(Y, Z, X ) = G(Y, .. . , -FrlX~i + Z, + n / Xgi, . .. , X )
= G(Y, -FrlX~j , X) + 2: rz, + FrlX~j)l-'iHl-'j(Y' Z, X ),
where the sum is taken over term s having one factor (Z, + F r /X~i) to some
power JLi > 0, and some factor HI-'i in Z[Y, Z, X], From the way (y, z, x) was
con structed, and the fact that G(y , z, x) = 0, we see that the first term vanishes ,
and hence
G(Y, Z, X) = 2: rz, + FrlX~i)l-'iHl-'j(Y' Z, X).
Clearing denominators of Xq , for some integer s we get
X~G (Y, Z, X) :; 0 mod (Fi, . . . , Fr),
or in other word s, (*)q is satisfied. Thi s concludes the proof of the theorem .
Remark,
Of course the same statement and proof as in Theorem 3.4
hold s with Z replaced by a field k. In that case , we denote by Ok the ideal in
k[W, Xl generated by the generic form s, and similarly by Pk the associated prime

392
ALGEBRAIC SPACES
ideal. Then
Ok,! = o k n k[W]
and
Pk,l = p, n k[W] .
IX, §3
The ideal P in Theorem 3.4 will be called the prime associated with the
ideal of generic forms. The intersection PI = Pn Z[W] will be called the prime
elimination ideal of these forms. If a denotes as before the zeros of P (or of
0), and aI is its projection on the first factor, then PI is the prime associated
with al . The same terminology will be used if instead of Z we work over a
field k. (Note : homogeneous elements of PI have been called inertia forms in
the classical literature, following Hurwitz . I am avoiding this terminology be-
cause the word "inertia" is now used in a standard way for inertia groups as in
Chapter VII, §2.) The variety of zeros of PI will be called the resultant vari-
ety . It is determined by the given degrees dI ' . . . , dn , so we could denote it
byal(dl, ·· ·,dn)·
Exercise.
Show that if P is the prime associated with the ideal of generic
forms , then P n Z = (0) is the zero ideal.
Theorem 3.5.
Assume r = n, so we deal with nforms in n variables. Then
PI is principal, generated by a single polynomial, so a) is what one calls a
hypersurface./f(w) is a generic point of a l over afield k, then the transcen-
dence degree of k(w) over k is m -
I .
Proof.
We prove the second statement first, and use the same notation as in
the proof of Theorem 3.4 . Let Uj = x/xn- Then un = I and (y), (UI"
' " Un-I)
are algebraically independent. By (3), we have Zi = -Fr(y, u), so
k(w) = key, z) C key, u),
and so the transcendence degree of k(w) over k is ~ m -
1. We claim that this
transcendence degree is m -
I. It will suffice to prove that UI' . . . , un-I are
algebraic over k(w) = key, z). Suppose this is not the case . Then there exists a
place cp of k(w, u), which is the identity on k(w) and maps some Uj on 00. Select
an index q such that cp(u;/uq) is finite for all i = I, . . . , n -
1. Let Vi = u;/uq
and v; = cp(u;/uq). Denote by liq the coefficient of X~i in F, and let y* denote
the variables (Y) from which }]q, . . . , Ynq are deleted. By (3) we have for
i = I , .. . , n:
o= y. Udi + z. + F'!'*(y* u)
tq
q
I
I
,
= Yiq + Z;/ugi + F'{*(y*, u/uq).
Applying the place yields
o= Yiq + Fr*(y*, v') .
In particular, Yiq E k(y*, v') for each i = I, . . . , n. But the transcendence degree
of k(v') over k is at most n -
I, while the elements (Ylq, . . . , Ynq' y*) are
algebraically independent over k, which gives a contradiction proving the
theorem.

IX, §3
PROJECTIONS AND ELIMINATION
393
Remark.
There is a result (I learned it from [10 80]) which is more precise
than Theorem 3.5. Indeed, let (1 as in Theorem 3.5 be the variety of zeros of
P, and (11 its projection. Then this projection is birational in the following sense.
Using the notation of the proof of Theorem 3.5, the result is not only that k(w)
has transcendence degree m -
lover k, but actually we have
Q( y, z) = Q(w) = Q(y, u) .
Proof.
Let PI = (R) , so R is the resultant, generating the principal ideal
PI' We shall need the following lemma.
Lemma 3.6.
There is a positive integer s with the following properties. Fix
an index i with 1 ~ i ~ n -
1. For each pair of n-tuples of integers ~ 0
(a) = (0'1' ... ,an)
and
({3) = ({3\o ... , (3n)
with 10'1 = I(31 = d., we have
To see this, we use the fact from Theorem 3.4 that for some s,
X~R(W) = QIF( + . .. + QnFn with Qj E Z[W, X] .
Differentiating with respect to lV;,(,B) we get
X~ a:
R
== QiM(,B)(X) mod (FI, . . . , Fn),
i,(,B)
and similarly
We multiply the first congruence by M(a)(X) and the second by M(,B)(X) , and we
subtract to get our lemma.
From the above we conclude that
aR
aR
M(a)(X) aw- - M(,B)(X) aw-
i,(,B)
i,(a)
vanishes on (1, i.e. on the point (w, u) , after we put Xn = 1. Then we select
M (a)(X) = Xfi
and
M(,B)(X) = Xfi- IXn for i = 1, ... , n -
1,
and we see that we have the rational expression
U · = aRjaw;,(,B) I
for /' =
I
aRjaW
'
1, ... , n -
1,
i,(a)
(w) =(w)
thus showing that Q(u) C Q(w) , as asserted.

394
ALGEBRAIC SPACES
IX, §3
We note that the argument also works over the prime field of characteristic
p. The only additional remark to be made is that there is some partial derivative
aR/a~,(a) which does not vanish on (w) . This is a minor technical matter, which
we leave to the reader.
The above argument is taken from [lo 80], Proposition 3.3.1 . Jouanolou links
old-time results as in Macaulay [Ma 16) with more recent techniques of com-
mutative algebra, including the Koszul complex (which will be discussed in
Chapter XXI). See also his monographs [Jo 90], [Jo 91].
Still following van der Waerden, we shall now give a fairly explicit deter-
mination of the polynomial generating the ideal in Theorem 3.5. We deal with
the generic forms Fi(W, X) (i = 1, . .. , n) . According to Theorem 3.5 , the ideal
VI is generated by a single element. Because the units in Z[W] consist only of
± I, it follows that this element is well defined up to a sign . Let
be one choice of this element. Later we shall see how to pick in a canonical way
one of these two possible choices. We shall prove various properties of this
element, which will be called the resultant of F(, . . . , Fn-
For each i = 1, . . . , n we let D, be the product of the degrees with d, omitted;
that is,
/I
Di = d l •• • d, ... dn-
We let d be the positive integer such that d -
1 = 2: (di -
I).
Lemma 3.7.
Given one of the indices , say n, there is an element Rn(W) lying
in VI ' satisfying the following properties.
(a) For each i, Rn(W)x 1 == 0 mod (F( , . . . , Fn) in Z[lv, X].
(b) For each i, Rn(W) is homogeneous in the set of variables (~ , ( v), and is of
degree D; in (\¥",(v) , i.e. in the coefficient of Fn-
(c) As a polynomial in Z[W], Rn(W) has content 1, i.e. is primitive.
Proof.
The polynomial Rn(W) will actually be explicitly constructed. Let
M u(X ) denote the monomials of degree 10'1 = d. We partition the indexing set
S = {O'} into disjoint subsets as follows .
Let SI = {O'Il be the set of indices such that Mul(X) is divisible by x11 •
Let Sz = {O'z} be the set of indices such that MU2(X) is divisible by X~2 but
not by x11•
Let S; = {O'n} be the set of indices such that Mun(X) is divisible by X~n but
not by x11, •• • , X~ '!--II .

IX, §3
PROJECTIONS AND ELIMINATION
395
Then 5 is the disjoint union of 51> . .. , 5n- Write each monomial as follows:
M CT1(X ) = HCT1(X )X11
so
deg H CT1= d - d,
M CTI(X ) = H CTn(X)X~ n
so
deg HCTn = d - d.;
Then the number of polynomials
HCT1F1, · · · , HCTnFn (with 0'\ E 5\ , . . . , O'n E 5n)
is precisely equal to the numb er of monomials of degree d. We let R; be the
determinant of the coefficients of these polynomials, viewed as form s in (X) with
coefficients in Z[W). Then R; = Rn(W) E Z[W). We claim that Rn(W) satisfies
the properties of the lemma.
First we note that if O'n E 5n, then H CTn(X) is divisible by a power of Xi at
most d, -
I, for i = I, . . . , n -
I. On the other hand, the degree of HCTn(X) in
Xn is determined by the condition that the total degree is d -
d.; Hence S; has
exactly D; elements. It follows at once that Rn(W) is homogeneous of degree D;
in the coefficients of Fn, i.e. in (Wn.(V))' From the construction it also follows
that R; is homogeneous in each set of variables (l¥;,(V)) for each i = I, ... ,
n -
1.
If we specialize the form s F, (i = I, . . . , n) to Xii, then R; specializes to I ,
and hence R; *- 0 and R; is primitive. For each o, we can write
where M CT(X ) ( 0' E 5) ranges over all monomials of degree d in (X) , and CCT.CTi(W)
is one of the variables (W) . Then by definition
where 0'\ E 5 I ' . .. , O'n E 5" indexes the columns, and 0' indexes the rows. Let
B = C be the matri x with components in Z[W, X) such that
BC = det(C)1 = Rnl .
(See Chapter XIII , Corollary 4.17 .) Then for each 0', we have
Given i, we take for 0' the index such that MCT(X) = xi in order to obtain the
first relation in Lemma 3.7 . By Theorem 3.4, we conclude that R,,(W) E Pl' Thi s
concludes the proof of the lemma.
Of course , we picked an index n to fix ideas. For each i one has a polynomial
R, sati sfying the analogous prop erties, and in particular homogeneous of degree
D, in the variables (Wi,(v) ) which are the coefficients of the form F;.

396
ALGEBRAIC SPACES
IX, §3
Theorem 3.8.
Let R be the resultant of the n generic forms F; over Z, in n
variables. Then R satisfies the following properties.
(a) R is the greatest common divisor in Z[W] of the polynomials R I , . .• , Rw
(b) R is homogeneous of degree D; in the coefficients of F;.
(c) Let F; = ... + ~ , (di)Xfi , so ~ .(di) is the coefficient ofXfi. Then R contains
the monomial
n
+ Il WD ·
-
;(d)'
;=1
.
I
Proof.
The idea will be to specialize the forms FI , .• . , F; to products of
generic linear forms, where we can tell what is going on. For that we need a
lemma of a more general property eventually to be proved. We shall use the
following notation. If fl' .. . ,fn are forms with coefficients (w) , then we write
R(f(, . . . ,In) = R(w).
Lemma 3.9.
Let G. H be generic independent forms with deg(GH) = dl .
Then R(GH, F2, • • • , Fn) is divisible by R(G, F2, • • • , Fn)R(H, F2, • • • , Fn).
Proof.
By Theorem 3.5, there is an expression
X~R(Fb
' .. , Fn) = Q1Fl + ... + QnFn with Q; E Z[W, X].
Let We, WH , WF2' • . . , WFn be the coefficients of G, H , F2 , . . . , F; respectively,
and let (w) be the coefficients of GH, F2, • •• , Fw Then
R(w) = R(GH, F2 , .•. , Fn ) ,
and we obtain
Hence R(GH, F2, • . . , Fn) belongs to the elimination ideal of G, F2, • . • , Fn in
the ring Z[Wc , WH , WF2"
•• , WFn], and similarly with H instead of G. Since
WH is a family of independent variables over Z[Wc, WF2' • . . , WFn], it follow s
that R(G, F2, . . . ,Fn) divides R(GH, F2, . . • ,Fn) in that ring, and similarly for
R(H, F2, . •• , Fn ) . But (We) and (WH) are independent sets of variables, and so
R(G, F2, . . • , Fn), R(H, F2, . . . ,Fn) are distinct prime elements in that ring, so
their product divides R(GH, F2 , . .. , Fn) as stated, thus proving the lemma.
Lemma 3.9 applies to any specialized family of polynomials g, h, fl' ... ,
fn with coefficients in a field k. Observe that for a system of n linear forms in
n variables, the resultant is simply the determinant of the coefficients. Thus if
L I , . • • , L; are generically independent linear forms in the variables Xl' . .. ,Xn ,
then their resultant R(L 1, • • • , Ln ) is homogeneous of degree 1 in the coefficients
of L; for each i. We apply Lemma 3.9 to the case of forms fl' . .. ,fn-I, which
are products of generically independent linear forms . By Lemma 3.9 we conclude
that for this specialized family of form, their resultant has degree at least D; in

IX, §3
PROJECTIONS AND ELIMINATION
397
the coefficients of Fn , so for the generic forms F1, •• • , F; their resultant has
degree at least D; in the coefficients of Fw Similarly R(Fl , ••• , Fn) has degree
at least D; in the coefficients of F; for each i. But R divides the n elements
R 1(W), . .. , Rn(W) constructed in Lemma 3.7. Therefore we conclude that R has
degree exactly D; in the coefficients of F;. By Theorem 3.5, we know that R
divides each R;. Let G be the greatest common divisor of RJ' . • . , R; in Z[W].
Then R divides G and has the same degree in each set of variables ("i.(V») for
i = 1, . . . , n. Hence there exists c E Z such that G = cR . We must have
c = ±l, because, say, R; is primitive in Z[W] . This proves (a) and (b) of the
theorem.
As to the third part, we specialize the forms tofi = Xf;, i = 1, . . . , n. Then
R; specializes to 1, and since R divides R; it follows that R itself specializes to
± 1. Since all coefficients of the forms specialize to 0 except those which we
denoted by "i.(d;) ' it follows that R(W) contains the monomial which is the product
of these variables to the power D;, up to the sign ± 1. This proves (c), and
concludes the proof of Theorem 3.8.
We can now normalize the resultant by choosing the sign such that R contains
the monomial
n
M - Il WD;
-
;(d)'
;=1
'
I
with coefficient +1. This condition determines R uniquely, and we then denote
R also by
R = Res(F\, . . . , Fn).
Given forms fl' . .. .t, with coefficients (w) in a field K (actually any commu-
tative ring), we can then define their resultant
Res(f\, . . . ,In) = R(w)
with the normalized polynomial R. With this normalization, we then have a
stronger result than Lemma 3.9 .
Theorem 3.10.
Let j, = gh be a product offorms such that deg(gh) = d l .
Let f2' . ..• fn be arbitrary forms of degrees d2, . . . . d; Then
Res(gh,f20 ' . . ,fn) = Res(g,f2' . . . ,fn)Res(h, 12, .. . ,fn)'
Proof.
From the fact that the degrees have to add in a product of polynomials,
together with Theorem 3.8(a) and (b), we now see in Lemma 3.9 that we must
have the precise equality in what was only a divisibility before we knew the
precise degree of R in each set of variables.
Theorem 3. lOis very useful in proving further properties of the determinant,
because it allows a reduction to simple cases under factorization of polynomials.

398
ALGEBRAIC SPACES
For instance one has:
IX, §3
Theorem 3.11.
Let Fl' .. . . F; be the generic forms in n variables. and let
FI , .• •• t; be the forms obtained by substituting Xn = 0, so that Fl' . . . , Fn- I
are the generic forms in n -
1 variables. Let n ~ 2. Then
Res(FJ, . . . , Fn-J, X~n) = Res(FJ, . . . , Fn_l)dn.
Proof.
By Theorem 3.10 it suffices to prove the assertion when d; = 1. By
Theorem 3.4, for each i = I, . .. , n -
1 we have an expression
with Qj E Z[W, X] (depending on the choice of i). The left-hand side can be
written as a polynomial in the coefficients of FI , • •• , Fn - I with the notation
thus in the generic linear form in XI' . . . , X; we have specialized all the coef-
ficients to°except the coefficient of Xn , which we have specialized to I. Sub-
stitute Xn = °in the right side of (*) . By Theorem 3.4, we conclude that
p(w(n-I ») lies
in
the
resultant
ideal
of
F 1, • • • ,
Fn- I,
and
therefore
Res(FI, . . . ,
Fn- I )
divides
p(w(n-I »).
By Theorem
3.8
we
know
that
p(w(n-I») has the same homogeneity degree in Wp
(i = I, . . . , n -
I)
_
_
I
as Res(F1, ..• , Fn- I ) . Hence there is c E Z such that
One finds c = 1 by specializing FI , • • • , Fn- I to x11, •• • , X~~i respectively,
thus concluding the proof.
The next basic lemma is stated for the generic case, for instance in Macaulay
[Ma 16], and is taken up again in [Jo 90], Lemma 5.6.
Lemma 3.12.
Let A be a commutative ring . Let fl ' ... . fn. g], . . . • gn be
homogeneous polynomials in A[XI' .. . , Xn]. Assume that
as ideals in A[X]. Then
Res(jJ, . . . ,fn) divides Res(gl" .. , gn) in A .
Proof.
Express each gj = 2: hijJj with hij homogeneous in A [X]. By spe-
cialization, we may then assume that s, = 2: HijFj where Hij and Fj have alge-
braically independent coefficients over Z. By Theorem 3.4, for each i we have
a relation

IX, §3
PROJECTIONS AND ELIMINAT ION
399
where WH , WF denote the independ ent variable coefficient s of the pol ynomials
Hi} and Fj respectively. In part icul ar ,
Note that Res(g l> . .. , gn) = P(WH , WF )
EO Z[WH , WF ] is a pol ynomial with
integer coefficients . If (wF) is a generic point of the resultant variety (11 over
Z , then P(WH, wF) = 0 by (*) . Hence Res(FI , . .. , F,,) divides P(WH, WF), thu s
proving the lemma.
Theorem 3.13.
Let A be a commutative ring and let d,• . . . • d" be integers
~ I as usual. Let ], be homogeneous of degree d, in A[X] = A[XI>' . . , Xn] .
Let d be an integer ~ I , and let g;, . .. , gn be homogeneous of degree d in
A[X]. Then
t, 0 g = !i(gl, ... , gn)
is homogeneous of degree dd.. and
Proof.
We start with the standard relation of Theorem 3.4:
(*)
XfRes(FI ' ... , Fn) = 0 mod (FI ' ... , F" )Z[WF , X].
We let G I' . .. , Gn be independent generic pol ynomials of degree d, and let We
denote thei r independent variable coefficients. Substituting G; for X; in (*), we
find
Abbreviate Res(F1, • • • , Fn) by R(F), and let g; = GfR(F ). By Lemma 3.12, it
follows that
Res(fl
0 G, . . . , F" 0 G) divides Re s (G~R(F) , . . . , G~R(F »
in Z[WF , We] .
By Theorem 3.10 and the homogeneity of Theorem 3.8(b) we find that
with integers M, N ~ O. Since Res(G I ' . . . , Gn) and Res(F1, • • • , F,, ) are distinct
prime elements in Z[We , WF] (distinct because they involve independent vari-
ables), it follows that
with integers a, b ~ 0 and to =
I or - I. Finally, we specialize F; to lV;Xfi and
we specialize G; to V;X f , with independent variables (WI' . . . , W", VI ' .. . , Vn)'

400
ALGEBRAIC SPACES
Substituting in (**), we obtain
IX, §3
Res(W]U1Ix1dl, . . . , WnU~nX~d n)
= e Res(U,X1, . . . , UnX~)a Res(W,X11, • • • , WnX~n)b .
By the homogeneity of Theorem 3.8(b) we get
ITov;Udi)dl...di...dndn-1 = eITUf-laITw1 1...d;...dnb.
i
i
j
From this we get at once e = 1 and a, b are what they are stated to be in the
theorem.
Corollary 3.14.
Let C = (Cjj) be a square matrix with coefficients in A. Let
/;(X) = Fj(CX) (where CX is multiplicationofmatrices. viewing X as a column
vector). Then
Res(f], . . . ,fn) = det(C)dl ...s; Res(F) , . .. , Fn)·
Proof.
This is the case when d = 1 and gj is a linear form for each i.
Theorem 3.15.
Let f" . . . , fn be homogeneous in A[X], and suppose
dn ~ d.for all i. Let h, be homogeneous of degree d; - d, in A[X]. Then
n-'
Res(f]> .. . ,fn-],fn + ? hJ) = Res(f" ... ,fn) in A.
J=]
Proof.
We may assume j. = F, are the generic forms , Hi are forms generic
independent from F] , . . . , Fn, and A = Z[WF , WH ], where (WF) and (WH )
are the coefficients of the respective polynomials. We note that the ideals
(F" . . . , Fn) and (F" . . . , Fn + .2: HjFj) are equal. From Lemma 3.12 we
J ~n
conclude that the two resultants in the statement of the theorem differ by a factor
of 1 or -1 . We may now specialize Hij to 0 to determine that the factor is + 1,
thus concluding the proof.
Theorem 3.16.
Let 1T be a permutation of {I, . . . , n}, and let e(1T) be its
sign. Then
Res(F1T(l )' • • • , F1T(n») = e(1T)dl • • •d; Res(F]> ... , Fn).
Proof.
Again
using
Lemma
3.12
with
the
ideals
(F" . . . , Fn) and
(F1T(l )' .. • , F1T(n»), which are equal , we conclude the desired equality up to a
factor ± 1, in Z[WF ] . We determine this sign by specializing F, to x«, and using
the multiplicativity of Theorem 3.10. We are then reduced to the case when
F, = Xi' so a linear form ; and we can apply Corollary 3.14 to conclude the proof.
The next theorem was an exercise in van der Waerden's Moderne Algebra.

IX, §3
PROJECTIONS AND ELIMINATION
401
Theorem 3.17.
Let LI • .. . • Ln- I , F be generic fo rms in n variables, such
that L1•• •• • Ln - I are of degree I, and F has degree d = dn- Let
dN = I, ... , n)
be (_l)n - j times the j-th minor determinant of the coefficient matrix of the
form s (L t. . . . . Ln- I ) . Then
Res(LI> . . . , Ln- 1, F) = F(d l> . . . , d n ) .
Proof.
We first claim that for all j = I, . . . , n we have the congruence
where as usual, (W) are the coefficients of the forms L\> .. . , L n - I , F. To see
this, we consider the system of linear equations
If C = (Cl , ... , c n-I ) is a square matrix with columns ci. then a solution of
a system of linear equations CX = C" satisfies Cramer' s rule
Xjdet(C I, . . . , cn-I) = det(C', . . . , C", . .. , cn-I) .
Using the fact that the determinant is linear in each column, (*) falls out.
Then from the congruence (*) it follows that
whence
Hence by Theorem 3.4 and the fact that Res(LI> " " L n - I> F) = R(W) generates
the elimination ideal, it follows that there exists c E Z[W] such that
Since the left side is homogeneous of degree I in the coefficients WF and homo-
geneous of degree d in the coefficients WLi for each i = I, .. . , n -
I, it follows
from Theorem 3.8 that C E Z. Specializing L, toXiand F to X~ makes dj specialize
to 0 if j
=1= nand d ll specializes to I. Hence the left side specializes to l , and
so does the right side, whence c = I. This concludes the proof.

402
ALGEBRAIC SPACES
Bibliography
IX, §4
[10 80]
1. P. Joux xoi.ou, Ideaux resultants, Advances in Mathematics 37 No.3 (1980 ),
pp.212-238
[1090]
1. P. Jouxxot.ou, Le formalisme du resultant, Advances in Mathematics 90
No.2 (1991) pp. 117-263
[1091]
1. P. Jouxxor.ou, Aspects invariants de l'elimination, Department de Math-
ernatiques, Universite Louis Pasteur, Strasbourg , France (1991)
[Ma 16]
F. MACAULAY, The algebraic theory ofmodular systems, Cambridge University
Press , 1916
§4.
RESULTANT SYSTEMS
The projection argument used to prove Theorem 3.4 has the advantage of
constructing a generic point in a very explicit way. On the other hand, no explicit,
or even effective, formula was given to construct a system of forms defining
al . We shall now reformulate a version of Theorem 3.4 over Z and we shall
prove it using a completely different technique which constructs effectively a
system of generators for an ideal of definition of the arithmetic variety
(11 in
Theorem 3.2 .
Theorem 4.1.
Given degrees d., ... , d, ~ I, and positive integers m, n. Let
(W) = (l¥;,(v» be the variables as in §3, (2) viewed as algebraically independent
elements over the integers Z. There exists an effectively determinable finite
number ofpolynomials Rp(W) E Z[W] having the following property. Let (f)
be as in (1), a system offorms of the given degrees with coefficients (w) in
some field k. Then (f) has a non-trivial common zero if and only if Rp(w) = 0
for all p.
A finite family {Rp} having the property stated in Theorem 4.1 will be called
a resultant system for the given degrees. According to van der Waerden
(Moderne Algebra, first and second edition, §80), the following technique of
proof using resultants goes back to Kronecker elimination, and to a paper of
Kapferer COber Resultanten und Resultantensysteme, Sitzungsber. Bayer. Akad.
Miinchen 1929, pp. 179-200). The family of polynomials {Rp(W)} is called a
resultant system, because of the way they are constructed. They form a set of
generators for an ideal hi such that the arithmetic variety (1 I is the set of zeros
of hi' I don't know how close the system constructed below is to being a set of
generators for the prime ideal PI in Z[W] associated with
(1 I' Actually we shall
not need the whole theory of Chapter IV, §10; we need only one of the char-
acterizing properties of resultants.

IX. §4
Let p , q be positive integers. Let
RESULTANT SYSTEMS
403
fv = voXif + v\Xif - lX2 +
+ vpX~
9w = woX[ + wlXi -lX2 +
+ WqX~
be two generic homogeneous polynomials in Z[v, W, Xl> X2] = Z[v, w][X] . In
Chapter IV, §10 we defined their resultant Res(fv, 9w) in case X2 = I, but we
find it now more appropriate to work with homogeneous polynomials. For our
purposes here , we need only the fact that the resultant R(v, w) is characterized
by the following property. If we have a specialization (a, b) of (v, w) in a field
K , and if fa ' f b have a factorization
P
f a = ao n (XI -
ai X2)
i= l
q
9b = bo n (Xl -
(3jX2)
j = 1
then we have the symmetric expression s in terms of the roots:
R(a, b) = Res(fa' fb) = aZbgn(ai -
(3j)
l .J
= aZn 9b(ai' 1) = (-I)P%{; nfa({3j, 1).
I
J
From the general theory of symmetric polynomials, it is a priori clear that
R(v, w) lies in Z[v, w], and Chapter IV, §1O gives an explicit representation
where fPv ,w and l/Jv ,w E Z[ v, w, X] . This representation will not be needed. The
next property will provide the basic inductive step for elimination.
Proposition 4.2.
Let fa. 9b be homogeneous polynomials with coefficients in
a fi eld K . Then Rta , b) = 0 if and only if the system of equations
has a non-trivial zero in some extension of K (whi ch can be taken to befinite).
If ao = 0 then a zero of 9b is also a zero of f a; and if bo = 0 then a zero of f a
is also a zero of 9b' If aobo * 0 then from the expression of the resultant as a
product of the difference of root s (ai -
(3j) the proposition follow s at once.
We shall now prove Theorem 4.1 by using resultants. We do this by induction
on n.

404
ALGEBRAIC SPACES
IX, §4
If n = 1, the theorem is obvious.
If n = 2, r = 1, the theorem is again obvious, taking the empty set for (Rp) .
If n = 2, r = 2, then the theorem amounts to Proposition 4.2.
Assume now n = 2 and r > 2, so we have a system of homogeneous equations
o = fl (X) = h eX) = ... = fr(X)
with (X) = (XI> X2 ) . Let d, be the degree oi], and let d = max d.. We replace
the family {fj(X)} by the family of all polynomials
fi(X)X1- d;
and
fi(X)X~ -d;, i = 1, . . . , r.
These two families have the same sets of non-trivial zeros, so to prove Theorem
4.1 we may assume without loss of generality that all the polynomials fl , ... ,
fr have the same degree d.
With n = 2, consider the generic system of forms of degree d in (X):
(4)
Fi(\¥, X) = 0 with i = 1,... , r, in two variables (X) = (XI' X2) ,
where the coefficients of F, are Wi,a, ... , \V;,d so that
(W) = (WI,a ,· · "
WI ,d"' "
\¥",a, ·· · , \¥",d)'
The next proposition is a special case of Theorem 4.1, but gives the first step
of an induction showing how to get the analogue of Proposition 4.2 for such a
larger system, Let TI> .. . , T, and VI> . .. , U, be independent variables over
Z[W, X). Let F I , •. . , F; be the generic forms of §3 , (2). Let
f = FI(\¥, X)TI +
+ Fr(W, X)Tr
9 = FI(\¥, X)V I +
+ Fr(W, X)Vr
so I, 9 E Z[W , T, V][X). Then f , 9 are polynomials in (X) with coefficients in
Z[W, T, V). We may form their resultant
Res(f, g) E Z[W, T, V).
Thus Res(f, g) is a polynomial in the variables (T, V) with coefficients in Z[W].
We let (QJL(W»
be the family of coefficients of this polynomial.
Proposition 4.3.
The system {QJL(W)} just constructed satisfies the property
of Theorem 4.1. i.e. it is a resultant system for r forms of the same degree d.
Proof.
Suppose that there is a non-trivial solution of a special system
Fj(W, X) = 0 with (w) in some field k. Then (w , T, V) is a common non-trivial
zero off, g, so Res(f, g) = 0 and therefore Qiw) = 0 for all JL. Conversely,
suppose that QJL(w) = 0 for all JL. Let /;(X) = Fi(w, X) . We want to show
that/;(X) for i = 1, .. . , r have a common non-trivial zero in some extension of

IX, §4
RESULTANT SYSTEMS
405
k. If all fi are 0 in k[X\, X2] then they have a common non-trivial zero . If, say ,
fl * 0 in k[X], then specializing T2 , . .. , T; to 0 and T\ to I in the resultant
Res(j, g) , we see that
as a polynomial in k[U 2, •• • , Ur ] . After making a finite extension of k if neces-
sary, we may assume that I, (X) splits into linear factors . Let {aJ be the roots
of fl(X\, 1). Then some (ai' I) must also be a zero of f2U2 + .. . + frUn
which implies that (ai' I) is a common zero of f,, · . . ,fr since U2, . . . , U,
are algebraically independent over k. This proves Proposition 4.3.
We are now ready to do the inductive step with n > 2. Again, let
fi(X) = Fi(w, X) for j = I, . . . , r
be polynomials with coefficients (w) in some fields k.
Remark 4.4.
There exists a non-trivial zero of the system
fi = 0 (i = 1, ... , r)
in some extension of k if and only if there exist
(x" .. . , Xn-t) * (0, . . . , 0) and (xn, t) * (0, 0)
in some extension of k such that
fi(tXI " ' " tXn-l' xn) = 0 for i = 1, .. . , r.
So we may now construct the system (Rp ) inductively as follows .
Let T be a new variable, and let x(n-I ) = (X" . . . , Xn - 1) . Let
Then gi is homogeneous in the two variables (Xn , Tv . By the theorem for two
variables, there is a system of polynomials (Q/L) in Z[W, x(n-I)] having the
property: if(w. .tn-I) is a point in afield K. then
gi(W. x(n-I) . Xn. T) have a non-trivial common zero for i = 1, .. . , r.
~ Q/L(w, x(n- I») = 0 for all J.L.
Viewing each Q/L as a polynomial in the variables (x(n-I)), we decompose each
Q/L as a sum of its homogeneous terms, and we let (HA(l¥, x(n-I))) be the fam-
ily of these polynomials,
homogeneous in o«n-I)). From the homogeneity
property of the forms Fj in (X),
it follows that if t is transcendental over K
and gi(w, x(n- l), Xn, T) have a non-trivial common zero for j = I, . . . , r
then gi(w, tx(n -l), Xn, n also have a non-trivial common zero. Therefore

406
ALGEBRAIC SPACES
IX, §4
Q/i(W, tX(n-l)) == 0 for all /-L, and so HA(w, x(n-I)) == O. Therefore we may use the
family of polynomials (HA) instead of the family (Q/i)' and we obtain the property:
if(w, x(n-l)) is a point in afield K. then
gj(W, x(n-I), Xn, T) have a non-trivial common zerofor i == 1, . . . , r
<=>HA(w,x(n-l)) == ofor all A.
By induction on n, there exists a family (Rp(W)) of polynomials in Z[W]
(actually homogeneous), having the property: if (w) is a point in a field K, then
HA(w, x(n-l)) have a non-trivial common zero for all A
<=> Rp(w) == 0 for all p,
In light of Remark 4.4, this concludes the proof of Theorem 4.1 by the resultant
method .
§5.
SPEC OF A RING
We shall extend the notions of §2 to arbitrary commutative rings.
Let A be a commutative ring. By spec(A) we mean the set of all prime ideals
of A . An element of spec(A) is also called a point of spec(A) .
Iff E A, we view the set of prime ideals p of spec(A) containing f as the set
of zeros off
Indeed, it is the set of p such that the image off in the canonical
homomorphism
A -+ All'
is O. Let 0 be an ideal, and let ~ (0) (the set of zeros of 0) be the set of all
primes of A containing c. Let 0 , b be ideals. Then we have:
Proposition 5.1.
(i)
~(ob) == ~ (0) U
~ (b).
(ii) If{oJ is a family of ideals. then ~(2:0j) == n ~(Oj).
(iii) We have ~ (0) C
~(b) if and only if radtc) :J rad(b), where radtu), the
radical of 0, is the set of all elements x E A such that x" E 0 for some
positive integer n.
Proof.
Exercise. See Corollary 2.3 of Chapter X.
A subset C of spec(A) is said to be closed if there exists an ideal 0 of A such
that C consists of those prime ideals p such that 0 C p, The complement of a
closed subset of spec(A) is called an open subset of spec(A). The following
statements are then very easy to verify, and will be left to the reader.

IX, §5
SPEC OF A RING
407
Proposition 5.2.
The union of a finite number of closedsets is closed. The
intersectionofan arbitraryfamily of closed sets is closed.
The intersection ofa finite number ofopen sets is open. The union ofan
arbitraryfamily ofopen sets is open.
The empty set and spec(A) itself are both open andclosed.
If S is a subset of A, then the set of prime ideals P E spec(A) such that S c: P
coincides with the set of prime ideals p containing the ideal generated by S.
The collection of open sets as in Proposition 5.2 is said to be a topology on
spec(A) , called the Zariski topology .
Remark.
In analysis, one considers a compact Hausdorff space S. "Haus-
dorff" means that given two points P, Q there exists disjoint open sets Up, UQ
containing P and Q respectively. In the present algebraic context, the topology
is not Hausdorff. In the analytic context, let R be the ring of complex valued
continuous functions on S. Then the maximal ideals of R are in bijection with
the points of S (Gelfand-Naimark theorem). To each point PES, we associate
the ideal Mp of functions f such that f(P)
= O. The association P ~ Mp
gives the bijection. There are analogous results in the complex analytic case.
For a non-trivial example, see Exercise 19 of Chapter XII .
Let A, B be commutative rings and cp : A ~ B a homomorphism. Then cp
induces a map
<p* = specre) = <p -l : spec(B) -> spec(A)
by
Indeed, it is immediately verified that <p - '(p) is a prime ideal of A. Note however
that the inverse image of a maximal ideal of B is not necessarily a maximal ideal
of A. Example ? The reader will verify at once that specto) is continuous, in the
sense that if U is open in spec(B), then <p -l(U) is open in spec(A).
We can then view spec as a contravariant functor from the category of
commutative rings to the category of topological spaces.
By a point of spec(A) in a field L one means a mapping
spec/e) : spec(L) -> spec(A)
induced by a homomorphism <p: A -> L of A into L.
For example, for each prime number p, we get a point of spec(Z), namely
the point arising from the reduction map
Z -> Z/pZ.

408
ALGEBRAIC SPACES
The corresponding point is given by the reversed arrow,
spec(Z) .- spec(ZjpZ).
IX, §5
As another example, consider the polynomial ring k[X I' .. . , Xn] over a
field k. For each n-tuple (c., . . . , cn) in ka(n) we get a homomorphism
such that cp is the identity on k, and cp(Xj ) = c, for all i. The corresponding
point is given by the reversed arrow
spec k[X] .- specte").
Thus we may identify the points in n-space ka(n) with the points of spec k[X]
(over k) in k' ,
However, one does not want to take points only in the algebraic closure of
k, and of course one may deal with the case of an arbitrary variety V over k
rather than all of affine n-space. Thus let k[XI' . .. , xn ] be a finitely generated
entire ring over k with a chosen family of generators. Let V = spec k[x] . Let A
be a commutative k-algebra, corresponding to a homomorphism k ~ A . Then a
point of V in A may be described either as a homomorphism
or as the reversed arrow
spec(A) --> spec(k[x])
corresponding to this homomorphism. If we put c, = CP(xi), then one may call
(c) = (cI, .. . , Cn) the coordinates of the point in A . By a generic point of V
in a field K we mean a point such that the map cp:k[x] ~ K is injective, i.e . an
isomorphism of k[x] with some subring of K.
Let A be a commutative Noetherian ring. We leave it as an exercise to
verify the following assertions, which translate the Noetherian condition into
properties of closed sets in the Zariski topology.
Closed subsets of spec(A) satisfy the descending chain condition, i.e., if
is a descending chain of closed sets, then we have C, = Cn + I for all sufficiently
large n. Equivalently, let {C;}ieI be a family of closed sets. Then there exists a
relatively minimal element of this family, that is a closed set Cio in the family
such that for all i, if C, c
Cio then C, = Cio. The proof follows at once from
the corresponding properties of ideals, and the simple formalism relating
unions and intersections of closed sets with products and sums of ideals.

IX, §5
SPEC OF A RING
409
A closed set C is said to be irreducible if it cannot be expressed as the union
of two closed sets
with C 1 i= C and C2 i= C.
Theorem 5.3.
Let A be a Noetherian commutative ring. Then every closed
set C can be expressed as a finite union of irreducible closed sets, and this
expression is unique if in the union
C = C 1 u .. · U C,
of irreducible closed sets, we have C, ¢ Cj if i i= j .
Proof.
We give the proof as an example to show how the version of Theorem
2.2 has an immediate translation in the more general context of spec(A). Suppose
the family of closed sets which cannot be represented as a finite union of irreducible
ones is not empty. Translating the Noetherian hypothesis in this case shows that
there exists a minimal such set C. Then C cannot be irreducible, and we can
write C as a union of closed sets
C = C' u C",
with C' i= C and en i= C. Since C' and en are strictly smaller than C, then we
can express C' and en as finite unions of irreducible closed sets, thus getting a
similar expression for C, and a contradiction which proves existence.
As to uniqueness, let
C = C1 U ... U C, = ZI U ... u Z,
be an expression of C as union of irreducible closed sets, without inclusion
relations. For each Zj we can write
Z, = (Z, n C I) U . . . u (Z, nCr)'
Since each Z, n C j is a closed set, we must have Zj = Z, n C, for some i. Hence
Zj = Cj for some i. Similarly, Cj is contained in some Zk' Since there is no
inclusion relation among the Z/s, we must have Zj = Cj = Zk' This argument
can be carried out for each Z, and each Cj • This proves that each Zj appears
among the C/s and each Cj appears among the Z/s, and proves the uniqueness
of our representation. This proves the theorem.
Proposition 5.4.
Let C be a closed subset of spec(A). Then C is irreducible
if and only if C = ~(p) for some prime ideal p.
Proof.
Exercise.
More properties at the same basic level will be given in Exercises 14-19.

410
ALGEBRAIC SPACES
EXERCISES
IX, Ex
Integrality
I. (Hilbert-Zariski) Let k be a field and let V be a homogeneous variety with generic
point (x) over k. Let ?1 be the algebraic set of zeros in k" of a homogeneous ideal in
k[X] generated by forms II ' . .. .I. in k[X] . Prove that V n ?1 has only the trivial
zero if and only if each Xi is integral over the ring k[f(x)] = k[fI(X), . . . ,lrCx)].
(Compare with Theorem 3.7 of Chapter VII.)
2. Let II ' . .. , Ir be forms in n variables and suppose n > r. Prove that these forms
have a non-trivial common zero.
3. Let R be an entire ring. Prove that R is integrally closed if and only if the local ring
Rp is integrally closed for each' prime ideal p.
4. Let R be an entire ring with quotient field K . Let t be transcendental over K . Let
I(t) = 2,a;ti E K[t] . Prove:
(a) IfIU) is integral over R[t], then all a, are integral over R.
(b) If R is integrally closed, then R[t] is integrally closed.
For the next exercises, we let R = k[x] = k[X]/p, where p is a homogeneous prime
ideal. Then (x) is a homogeneous generic point for a k-variety V. We let I be the integral
closure of R in k(x) . We assume for simplicity that k(x) is a regular extension of k.
5. Let z = 2,c.x, with c, E k, and z *- O. If k[x) is integrally closed , prove that k[x/z]
is integrally closed .
6. Define an element IE k(x) to be homogeneous iflUx) = tdl(x) for t transcendental
over k(x) and some integer d. Let I E I. Show that I can be written in the form
1= L/;where each/; is homogeneous of degree i ;;; 0, and where also /; E I . (Some
/; may be 0, of course .)
We let Rm denote the set of elements of R which are homogeneous of degree m.
Similarly for 1m• We note that Rm and 1m are vector spaces over k, and that R (resp. l)
is the direct sum of all spaces Rm (resp. 1m) for m = 0, I, . . . This is obvious for R, and
it is true for I because of Exercise 6.
7. Prove that I can be written as a sum 1= Rz, + ... + Rz; where each z, is homoge-
neous of some degree d..
8. Define an integer m ~ I to be well behaved if I'ln = Iqm for all integers q ~ I. If
R = I, then all m are well behaved . In Exercise 7, suppose m ~ max d.. Show that
m is well behaved .
9. (a) Prove that 1m is a finite dimensional vector space over k. Let wo,.. . , WM be a
basis for 1mover k. Then k[lm] = k[w].
(b) If m is well behaved, show that k[lm] is integrally closed .
(c) Denote by k«x» the field generated over k by all quotients x.fx, with xj *- 0,
and similarly for k«w» . Show that k«x»
= k«w» .
(If you want to see Exercises 4-9 worked out, see my Introduction to Algebraic
Geometry, Interscience 1958, Chapter V.)

IX, Ex
Resultants
EXERCISES
411
10. Prove that the resultant defined for n forms in n variables in §3 actually coincides
with the resultant of Chapter IV, or §4 when n = 2.
II . Let a = (f" . . . , fr) be a homogeneous ideal in k[X" . .. , Xn) (with k algebraically
closed). Assume that the only zeros of a consist of a finite number of point s
(x(l », . . . , (X(d» in projective space pn- ' , so the coordinates of each x U ) can be
taken in k. Let uI' . . . , lin be independent variables and let
Lu(X) = ulX , + . .. + unXn·
Let R,(u), .. . , R,(u ) E k[ul be a resultant system for f" . . . ,fr' Lu.
(a) Show that the common non-trivial zeros of the system Ri(u) (i = I , . . . , s)
in k are the zeros of the polynomial
f1 Lu(x(j)
E k[IIl.
j
(b) Let D(u) be the greatest common divisor of R,(u) , . . . , R,(II) in k[ul . Show
that there exist integers mj ~ I such that (up to a factor in k)
d
D(u) = f1 Lu(x(j »mj.
r-,
[See van der Waerden , Moderne Algebra, Second Edition , Volume II , §79.l
12. For forms in 2 variables, prove directly from the definition used in §4 that one has
Res(fg, h) = Res(f, h) Res(g, h)
Res(f, g) = (-1 )(deg!>( degg)Res(g, f) .
13. Let k be a field and let Z ---'> k be the canonical homomorph ism. If FE Z [W, XL we
denote by F the image of F in k[W, X] under this homomorphi sm. Thus we get R,
the image of the resultant R.
(a) Show that R is a generator of the prime ideal Pk.I of Theorem 3.5 over the
field k. Thus we may denote R by Rk •
(b) Show that R is absolutely irreducible , and so is Rk • In other words, R, is
irreducibl e over the algebraic closure of k.
Spec of a ring
14. Let A be a commutative ring. Define spec(A ) to be connecte d if spec(A) is not the
union of two disjoint non-empty closed sets (or equivalently, spec(A) is not the union
of two disjoint, non-empty open sets).
(a) Suppo se that there are idempotents el' e2 in A (that is ey = el and e~ = e2),
'* 0, I , such that e,e2 = 0 and el + e2 = 1. Show that spec(A) is not
connected.
(b) Con versely, if spec(A) is not connected, show that there exist idempotents
as in part (a).
In either case, the existence of the idempotents is equivalent with the fact that the
ring A is a produ ct of two non-ze ro rings, A = A , X A2.

412
ALGEBRAIC SPACES
IX, Ex
15. Prove that the Zariski topology is compact , in other words: let {V J iEl be a family of
open sets such that
UVi = spec(A).
i
Show that there is a finite number of open sets Vi" .. . , V i. whose union is spec(A).
[Hint:
Use closed sets, and use the fact that if a sum of ideals is the unit ideal, then I
can be written as a finite sum of elements.]
16. Let f be an element of A. Let S be the multiplicative subset {I,J, F ,J3 , . . .} con-
sisting of the powers of f. We denote by Af the ring S-IA as in Chapter II, §3.
From
the
natural
homomorphism A -
Af
one gets the corresponding
map
spec(Af ) -
spec(A) .
(a) Show that spec(Af ) maps on the open set of points in spec(A) which are not
zeros off.
(b) Given a point p E spec(A), and an open set V containing p, show that there
exists f such that p E spec(Af ) C V .
I7 . Let Vi = spec(Afi) be a finite family of open subsets of spec(A) covering spec(A).
For each i, let aJ/; E Ali' Assume that as functions on Vi n U, we have aJ/; = a/h
for all pairs i, j . Show that there exists a unique element a E A such that a = aJ/;
in Af, for all i.
18. Let k be a field and let k[x l , • .. , xnl = A C K be a finitely generated subring of
some extension field K. Assume that k(x" . . . , xn) has transcendence degree r. Show
that every maximal chain of prime ideals
A :J PI :J Pz :J ... :J r; :J {O},
with PI
oF- A , Pi oF- Pi+ l , Pm oF- {O}, must have m = r.
19. Let A = Z[x" . . . , xnl be a finitely generated entire ring over Z. Show that every
maximal chain of prime ideals as in Exercise 18 must have m = r + 1. Here, r =
transcendence degree of Q(x l , .. • , xn ) over Q.

CHAPTER X
Noetherian Rings and
Modules
This chapter may serve as an introduction to the methodsof algebraic geometry
rooted in commutative algebra and the theory of modules, mostly over a Noeth-
erian ring .
§1.
BASIC CRITERIA
Let A be a ring and M a module (i.e., a left A-module). We shall say that
M is Noetherian if it satisfies anyone of the following three conditions:
(1) Every submodule of M is finitely generated.
(2) Every ascending sequence of submodules of M,
such that M, =I: M j + I is finite.
(3) Every non-empty set S of submodules of M has a maximal element
(i.e., a submodule M 0 such that for any element N of S which contains
Mo we have N = Mo).
We shall now prove that the above three conditions are equivalent.
(I) = (2) Suppose we have an ascending sequence of submodules of M as
above. Let N be the union of all the M, (i = 1,2, ...). Then N is finitely gen-
erated, say by elements XI"
' " X" and each generator is in some M j • Hence
there exists an index j such that
413
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

414
NOETHERIAN RINGS AND MODULES
Then
X, §1
whence equality holds and our implication is proved.
(2) = (3) Let No be an element of S. If No is not max imal, it is properly
contained in a submodule N i- If N, is not maximal, it is properly contained in
a submodule N 2 ' Inductively, if we have found N, which is not maximal, it is
contained properly in a submodule N i + , . In this way we could construct an
infinite chain, which is impossible.
(3) = (1) Let N be a submodule of M. Let ao E N. If N # <ao>, then
there exists an element a, EN which does not lie in <ao)' Proceeding induc-
tively, we can find an ascending sequence of submodules of N, namely
where the inclusion each time is proper. The set of these submodules has a
maximal element, say a submodule <ao, a" ... , ar ) , and it is then clear that
this finitely generated submodule must be equal to N, as was to be shown.
Proposition 1.1. Let M be a Noetherian A-module. Then every submodule
and every factor module of M is Noetherian.
Proof.
Our assertion is clear for submodules (say from the first condi-
tion).
For the factor module, let N be a submodule and f: M ---+ MIN the
canonical homomorphism. Let M , c M 2 C .. . be an ascending chain of sub-
modules of MIN and let M, = f- ' (M;). Then M , c M 2 C
. . . is an ascending
chain of submodules of M, which must have a maximal element, say M" so
that M, = M, for r ~ i. Then f(M ;) = M, and our assertion follows.
Proposition 1.2.
Let M be a module, N a submodule. Assume that Nand
MIN are Noetherian. Then M is Noetherian.
Proof.
With every submodule L of M we associate the pair of modules
L f---+(L r. N, (L + N)IN).
We contend : If E c F are two submodules of M such that their associated
pairs are equal, then E = F. To see this, let x E F. By the hypothesis that
(E + N)IN = (F + N)IN there exist elements u, v E Nand y E E such that
y + u = x + v. Then
x - y = u -
V E F (') N = E (') N.
Since y E E, it follows the x E E and our contention is proved. If we have an
ascending sequence

X, §1
BASIC CRITERIA
415
then the associated pairs form an ascending sequence of submodules of Nand
MIN
respectively, and these sequences must stop.
Hence our sequence
£1 c £2 ' " also stops, by our preceding contention.
Propositions 1.1 and 1.2 may be summarized by saying that in an exact
sequence°--> M' --> M --> M " --> 0, M is Noetherian if and only if M' and M"
are Noetherian.
Corollary 1.3.
Let M be a module, and let N , N ' be submodules.
If
M = N + N ' and if both N, N ' are Noetherian, then M is Noetherian. A
finite direct sum of Noetherian modules is Noetherian.
Proof.
We first observe that the direct product N x N' is Noetherian
since it contains N as a submodule whose factor module is isomorphic to N',
and Proposition 1.2 applies. We have a surjective homomorphism
N x N' --> M
such that the pair (x, x') with x E N and x' EN' maps on x + x'. By Prop-
osition 1.1, it follows that M is Noetherian. Finite products (or sums) follow
by induction.
A ring A is called Noetherian if it is Noetherian as a left module over itself.
This means that every left ideal is finitely generated.
Proposition 1.4.
Let A be a Noetherian ring and let M be afinitely generated
module. Then M is Noetherian.
Proof.
Let Xl"
' " x, be generators of M. There exists a homomorphism
f :A x A x .. . x A --> M
of the product of A with itself n times such that
This homomorphism is surjective. By the corollary ofthe preceding proposition,
the product is Noetherian, and hence M is Noetherian by Proposition 1.1.
Proposition 1.5.
Let A be a ring which is Noetherian, and let qJ : A --> B be
a surjective ring-homomorphism. Then B is Noetherian.
Proof.
Let b 1 C
. .. c b, c . .. be an ascending chain of left ideals of B
and let u, =
qJ - I(bi) . Then the ai form an ascending chain of left ideals of A
which must stop, say at c.. Since qJ(aJ = b, for all i, our proposition is proved.
Proposition
1.6.
Let A be a commutative Noetherian ring, and let S be a
multiplicative subset of A. Then S-I A is Noetherian.
Proof.
We leave the proof as an exercise.

416
NOETHERIAN RINGS AND MODULES
X, §2
Examples.
In Chapter IV, we gave the fundamental examples of Noeth-
erian rings, namely polynomial rings and rings of power series. The above
propositions show how to construct other examples from these, by taking factor
rings or modules, or submodules.
We have already mentioned that for applications to algebraic geometry, it is
valuable to consider factor rings of type k[X]/a , where a is an arbitrary ideal.
For this and similar reasons, it has been found that the foundations should be
laid in terms of modules, not just ideals or factor rings. Notably, we shall first
see that the prime ideal associated with an irreducible algebraic set has an analogue
in terms of modules. We shall also see that the decomposition of an algebraic
set into irreducibles has a natural formulation in terms of modules, namely by
expressing a submodule as an intersection or primary modules.
In §6 we shall apply some general notions to get the Hilbert polynomial of
a module of finite length, and we shall make comments on how this can be
interpreted in terms of geometric notions. Thus the present chapter is partly
intended to provide a bridge between basic algebra and algebraic geometry.
§2.
ASSOCIATED PRIMES
Throughout this section, we let A be a commutative ring. Modules and homo-
morphisms are A-modules and A-homomorphisms unless otherwise specified.
Proposition 2.1.
Let S be a multiplicative subset of A, and assume that S
does not contain O. Then there exists an ideal of A which is maximal in the
set of ideals not intersecting S, and any such ideal is prime.
Proof.
The existence of such an ideal p follows from Zorn's lemma (the
set of ideals not meeting S is not empty, because it contains the zero ideal, and is
clearly inductively ordered). Let p be maximal in the set. Let a, b E A, ab E p,
but a i p and b i p. By hypothesis, the ideals (a, p) and (b, p) generated by a
and p (or band p respectively) meet S, and there exist therefore elements
s, s' E S, C, c', x, x' E A, p, p' E P such that
s = ca + xp
and
s' = c'b + x'p'.
Multiplying these two expressions, we obtain
ss' = cc'ab + p"
with some p" E p, whence we see that ss' lies in p. This contradicts the fact
that p does not intersect S, and proves that p is prime.
An element a of A is said to be nilpotent if there exists an integer n ~ 1 such
that an = O.

X, §2
ASSOCIATED PRIMES
417
Corollary 2.2.
An element a of A is nilpotent if and only if it lies in every
prime ideal of A.
Proof.
If an = 0, then an E p for every prime p, and hence a E p. If an =I- 0
for any positive integer n, we let S be the multiplicative subset of powers of a,
namely {l, a, a' , .. .},and find a prime ideal as in the proposition to prove the
converse.
Let a be an ideal of A. The radical of a is the set of all a E A such that an E a
for some integer n ~ 1, (or equi valently, it is the set of elements a E A whose
image in the factor ring Ala is nilpotent). We observe that the radical of a is an
ideal, for if an = 0 and b" = 0 then (a + W= 0 if k is sufficiently large : In the
binomial expansion, either a or b will appear with a power at least equal to
nor m.
Corollary 2.3.
An element a of A lies in the radical ofan ideal a if and only
if it lies in every prime ideal containing a.
Proof.
Corollary 2.3 is equivalent to Corollary 2.2 applied to the ring AIa.
We shall extend Corollary 2.2 to modules. We first make some remarks on
localization. Let S be a multiplicative subset of A. If M is a module, we can
define S- I M in the same way that we defined S- I A. We con sider equivalence
classes of pairs (x, s) with x E M and s E S, two pairs (x, s) and (x', s') being
equivalent if there exists S l E S such that S I(S'X -
sx') = O.
We denote the
equ ivalence class of (x, s) by xis, and verify at once that the set of equivalence
classes is an additive group (unde r the obvious operations). It is in fact an
A-module, under the operation
(a, xis) 1--+axis.
We shall denote this module of equivalence classes by S- 1M. (We note that
S- I M could also be viewed as an S- I A-module.)
If p is a prime ideal of A, and S is the complement of p in A, then S- I M is
also denoted by M P'
It follows trivially from the definitions that if N --> M is an injective homo-
morphism, then we have a natural injection S- 1N --> S- 1M. In other words, if
N is a submodule of M, then S-1 N can be viewed as a submodule of S-1 M.
If x E Nand s E S, then the fraction xis can be viewed as an element of S-1 N
or S-1 M. If xis = 0 in S-I M, then there exists Sl E S such that SIX = 0, and
this means that xis is also 0 in S- I N. Thus if p is a prime ideal and N is a sub-
module of M, we have a natural inclusion of N; in M p • We shall in fact identify
N p as a submodule of M p ' In particular, we see that M p is the sum of its sub-
modules (Ax)p, for x E M (but of course not the direct sum).
Let x E M.
The annihilator a of x is the ideal consisting of all elements
a E A such that ax = O. We ha ve an isomorphism (of modules)
Ala =. Ax

418
NOETHERIAN RINGS AND MODULES
under the map
a --+ ax .
X,§2
Lemma 2.4.
Let x be an element of a module M, and let a be its annihilator.
Let p be a prime ideal of A. Then (Ax)p
=1= 0 if and only if p contains a.
Proof.
The lemma is an immediate consequence of the definitions, and
will be left to the reader.
Let a be an element of A. Let M be a module. The homomorphism
X f--> ax ,
xEM
will be called the principal homomorphism associated with a, and will be de-
noted by aM' We shall say that aM is locally nilpotent if for each x E M there
exists an integer n(x) f; I such that an(x)x = O. This condition implies that
for every finitely generated submodule N of M, there exists an integer n f; 1
such that a'N = 0: We take for n the largest power of a annihilating a finite
set of generators of N. Therefore, if M is finitely generated, aM is locally
nilpotent if and only if it is nilpotent.
Proposition 2.5.
Let M be a module, a E A. Then aM is locally nilpotent
if and only if a lies in every prime ideal p such that Mp
=1= O.
Proof.
Assume that aM is locally nilpotent. Let p be a prime of A such
that M p
=1= O. Then there exists x E M such that (Ax)p
=1= O. Let n be a positive
integer such that a'x = O. Let a be the annihilator of x. Then an E a, and hence
we can apply the lemma, and Corollary 4.3 to conclude that a lies in every prime
p such that M p
=1= O. Conversely, suppose aM is not locally nilpotent, so there
exists x E M such that anx = 0 for all n ~ O. Let S = {I, a, a2, •• • } , and
using Proposition 2.1 let p be a prime not intersecting S. Then (Ax), oF 0, so
Mp oF 0 and a¢' p, as desired .
Let M be a module. A prime ideal p of A will be said to be associated with
M if there exists an element x E M such that p is the annihilator of x. In par-
ticular, since p =1= A, we must have x
=1= O.
Proposition 2.6.
Let M be a module
=1= O. Let p be a maximal element in the
set ofideals which are annihilators of elements x E M, x
=1= O. Then p is prime.
Proof.
Let p be the annihilator of the element x
=1= O. Then p =1= A. Let
a, b e A, ab E p, a ¢ p. Then ax
=1= O. But the ideal (b, p) annihilates ax, and
contains p. Since p is maximal, it follows that b E p, and hence p is prime.
Corollary 2.7.
IfA is Noetherian and M is a module oF 0, then there exists
a prime associated with M.
Proof.
The set of ideals as in Proposition 2.6 is not empty since M oF 0,
and has a maximal element because A is Noetherian.

X, §2
ASSOCIATED PRIMES
419
Coroilary 2.8.
Assume that both A and M are Noetherian, M =I O. Then
there exists a sequence of submodules
M = M 1 => M 2 => . .. => M r = 0
such that each factor module M;/Mi + 1 is isomorphic to A/Pi for some
prime Pi'
Proof.
Consider the set of submodules having the property described in
the corollary. It is not empty, since there exists an associated prime P of M,
and if P is the annihilator of x, then Ax ~ A/p . Let N be a maximal element in
the set. If N =I M, then by the preceding argument applied to M/N, there exists
a submodule N' of M containing N such that N '/N is isomorphic to A/p for
some p, and this contradicts the maximality of N.
Proposition 2.9.
Let A be Noetherian, and a E A. Let M be a module.
Then aM is injective if and only if a does not lie in any associated prime of M.
Proof.
Assume that aM is not injective, so that ax = 0 for some x E M,
x oF O. By Corollary 2.7, there exists an associated prime p of Ax, and a is an
element of p. Conversely, if aM is injective, then a cannot lie in any associated
prime because a does not annihilate any non-zero element of M.
Proposition 2.10.
Let A be Noetherian, and let M be a module. Let a E A.
T he following conditions are equivalent :
(i) aM is locally nilpotent.
(ii) a lies in every associated prime of M.
(iii) a lies in every prime p such that M" =I O.
If P is a prime such that M"
oF 0, then p contains an associated prime of M .
Proof.
The fact that (i) implies (ii) is obvious from the definitions, and
does not need the hypothesis that A is Noetherian. Neither does the fact that
(iii) implies (i), which has been proved in Proposition 2.5 . We must therefore
prove that (ii) implies (iii) which is actually implied by the last statement. The
latter is proved as follows . Let p be a prime such that M" oF O. Then there exists
x E M such that (Ax)" oF O. By Corollary 2.7, there exists an associated prime
q of (Ax)" in A . Hence there exists an element y/ s of (Ax)" , with y E Ax ,
s ¢: p , and y/ s oF 0, such that q is the annihilator of y/ s. It follows that q c p,
for otherwise, there exists b E q, b ¢: p, and 0 = by]«, whence y/s = 0 , contra-
diction . Let b l , . . . , b; be generators for q. For each i , there exists Si E A,
si ¢: p , such that sib iY = 0 because biy/ s = O. Let t = s, ... sn' Then it is
trivially verified that q is the annihilator of ty in A. Hence q c p, as desired.
Let us define the support of M by
supp(M) = set of primes p such that M" =I O.

420
NOETHERIAN RINGS AND MODULES
We also have the annihilator of M,
ann(M) = set of elements a E A such that aM = O.
We use the notation
ass(M) = set of associated primes of M .
For any ideal a we have its radical,
X, §2
rad(a) = set of elements a E A such that an E a for some integer n ~ 1.
Then for finitely generated M, we can reformulate Proposition 2.10 by the
following formula:
rad(ann(M»
= n
p = n p.
P Esupp(M)
P Eass(M)
Corollary 2.11.
Let A be Noetherian,and let M be a module. Thefollowing
conditions are equivalent :
(i) There exists only one associated primeof M .
(ii) We have M # 0, andfor every a E A, the homomorphism aM is injective,
or locallynilpotent.
If these conditions are satisfied, then the set of elements a E A such that aM
is locallynilpotent is equalto the associated primeof M .
Proof.
Immediate consequence of Propositions 2.9 and 2.10.
Proposition 2.12.
Let N be a submodule of M. Every associated prime of
N is associated with M also. An associated prime of M is associatedwith N
or with MIN.
Proof.
The first assertion is obvious. Let p be an associated prime of M,
and say p is the annihilator of the element x # O. If Ax n N = 0, then Ax is
isomorphic to a sub module ofM/N, and hence p is associated with M/N. Suppose
Ax n N *' O. Let y = ax E N with a E A and y *' O. Then p annihilates y.
We claim p = ann(y). Let b E A and by = O. Then ba E p but a ¢= p, so
b E p. Hence p is the annihilator of y in A, and therefore
is associated with
N , as was to be shown.

X, §3
§3.
PRIMARY DECOMPOSITION
PRIMARY DECOMPOSITION
421
We continue to assume that A is a commutative ring, and that modules(resp.
homomorphisms) are A-modules (resp. A-homomorphisms), unless otherwise
specified.
Let M be a module. A submodule Qof M is said to be primary if Q =1= M,
and if given a E A, the homomorphism aM/Q is either injective or nilpotent.
Viewing A as a module over itself, we see that an ideal q is primary if and only
if it satisfies the following condition :
Given a, b E A, ab E q and a ~ q, then b" E q for some n ~ 1.
Let Q be primary.
Let p be the ideal of elements a E A such that aM/Q is
nilpotent. Then p is prime. Indeed, suppose that a, b E A, ab E p and a ~ p.
Then aM/Q is injective, and consequently a~/Q is injective for all n ~ 1. Since
(ab)M/Q is nilpotent, it follows that bM/Qmust be nilpotent, and hence that b E p,
proving that p is prime. We shall call p the prime belonging to Q, and also say
that Q is p-primary.
We note the corresponding property for a primary module Q with prime p:
Let b e A and x E M be such that bx E Q. If x ¢. Q then b E p,
Examples.
Let m be a maximal ideal of A and let q be an ideal of A such
that mk C q for some positive integer k. Then q is primary, and m belongs to
q. We leave the proof to the reader.
The above conclusion is not always true if m is replaced by some prime ideal
p. For instance, let R be a factorial ring with a prime element t. Let A be the
subring of polynomials !CX) E R[X] such that
!(X) = Go + a tX + .. .
with a\ divisible by t. Let p = (tX,X2,X3) . Then p is prime but
p2 = (t2X2, tX3, X 4)
is not primary, as one sees because X 2 ~ p2 but tk ~ p2 for all k ~ 1, yet
t2X 2 E p2.
Proposition 3.1.
Let M be a module, and QI'
, Qrsubmoduleswhichare
p-primary for the same prime p. Then QI n
n Qr is also p-primary.
Proof.
Let Q = QI n ... n Qr' Let a E p, Let n, be such that (aM/Q)"; =°
for each i = 1, . . . , r and let n be the maximum of nt , . .. , nr • Then a~/Q = 0,
so that aM/Q is nilpotent.
Conversely, suppose a ~ p. Let x E M, x ~ Qj for
some j.
Then a"x ~ Qj for all positive integers n, and consequently aM/Q is
injective. This proves our proposition.

422
NOETHERIAN RINGS AND MODULES
X, §3
Let N be a submodule of M . When N is written as a finite intersection of
primary submodules, say
we shall call this a primary decomposition of N.
Using Proposition 3.1, we
see that by grouping the Qi according to their primes, we can always obtain
from a given primary decomposition another one such that the primes belonging
to the primary ideals are all distinct. A primary decomposition as above such
that the prime ideals PI' . . . , P, belonging to Ql ' .. . ' Q, respectively are distinct,
and such that N cannot be expressed as an intersection of a proper subfamily
of the primary ideals {QI ' . .. , Q,} will be said to be reduced. By deleting some
of the primary modules appearing in a given decomposition, we see that if N
admits some primary decomposition, then it admits a reduced one.
We shall
prove a result giving certain uniqueness properties of a reduced primary
decomposition.
Let N be a submodule of M and let x ~ i be the canonical homomorphism.
Let Qbe a submodule of M = M / N and let Q be its inverse image in M . Then
directly from the definition, one sees that Qis primary if and only if Qis primary;
and if they are primary, then the prime belonging to Q is also the prime belonging
to Q. Furthermore, if N = QI n ... n Qr is a primary decomposition of N in
M, then
(0) = QI n ... n Qr
is a primary decomposition of (0) in M , as the reader will verify at once from
the definitions . In addition , the decomposition of N is reduced if and only if the
decomposition of (0) is reduced since the primes belonging to one are the same
as the primes belonging to the other.
Let QI n . .. n Q, = N be a reduced primary decomposition , and let Pi
belong to Qi. If Pi does not contain Pi (j =I i) then we say that Pi is isolated.
The isolated primes are therefore those primes which are minimal in the set
of primes belonging to the primary modules Qi.
Theorem 3.2.
Let N be a submodule of M, and let
N = QIn · . . n Qr = Q'I n .. . n
Q ~
be a reduced primary decomposition of N. Then r = s. The set of primes
belonging to QI' . . . , Q, and Q'l' .. . ' Q~ is the same. If {PI'···' Pm} is the
set of isolated primes belonging to these decompositions, then Qi = Q; for
i = 1,... , m, in other words, the primary modules corresponding to isolated
primes are uniquelydetermined.
Proof.
The uniqueness of the number of terms in a reduced decomposition
and the uniqueness of the family of primes belonging to the primary components
will be a consequence of Theorem 3.5 below.

X, §3
PRIMARY DECOMPOSITION
423
There remains to pro ve the uniqueness of the primary module belonging
to an isolated prime, say PI' By definition, for each j = 2, . .. , r there exists
aj E Pj and aj ¢ PI ' Let a = a2 .•. ar be the product. Then a E Pj for allj > 1,
but a ¢ P I' We can find an integer n ~ 1 such that aM/Qj = 0 for j = 2, . .. , r.
Let
N I = set of x E M such that a"x E N.
We contend that QI = N I ' This will prove the desired uniqueness. Let x E Qi-
Then a"x E QI n·· · n Qr = N, so
X E N I •
Conversely, let x E N I , so that
a'x E N, and in particular a'x E Qi - Since a ¢ PI ' we know by definition that
aM/Q, is injective. Hence x E QI' thereby proving our theorem.
Theorem 3.3.
Let M be a Noetherian module. Let N be a submodule of
M. Then N admits a primary decomposition.
Proof.
We consider the set of submodules of M which do not admit a
primary decomposition. If this set is not empty, then it has a maximal element
because M is Noetherian. Let N be this maximal element. Then N is not
primary, and there exists a E A such that aM/Nis neither injective nor nilpotent.
The increasing sequence of modules
Ker aM/N c Ker a~ /N c Ker a1 /N c
. ..
stops, say at
a~ /N '
Let tp : MIN --+ MIN be the endomorphism cp =
a~/N '
Then Ker cp2 = Ker cpo Hence 0 = Ker cp n Im cp in MIN, and neither the
kernel nor the image of cp is O. Taking the inverse image in M, we see that N is
the intersection of two submodules of M, unequal to N. We conclude from the
maximality of N that each one of these submodules admits a primary de-
composition, and therefore that N admits one also, contradiction.
We shall conclude our discussion by relating the primes belonging to a
primary decomposition with the associated primes discussed in the previous
section.
Proposition 3.4.
Let A and M be Noetherian. A submodule Q of M is
primary if and only if MIQ has exactly one associated prime P, and in that
case, P belongs to Q, i.e. Q is p-primary.
Proof.
Immediate consequence of the definitions, and Corollary 2.11 .
Theorem 3.5.
Let A and M be Noetherian. The associated primes of M
are precisely the primes which belong to the primary modules in a reduced
primary decomposition of 0 in M. In particular, the set of associated primes
of M is finite.
Proof .
Let
0= Q I n·· · n Qr

424
NOETHERIAN RINGS AND MODULES
X, §4
be a reduced primary decomposition of 0 in M. We have an injective homo-
morphism
r
M --> EBM/Qj'
j= I
By Proposition 2.12 and Proposition 3.4, we conclude that every associated
prime of M belongs to some Qj. Conversely, let N = Q2 n ... n Qr' Then
N#-O because our decomposition is reduced. We have
Hence N is isomorphic to a submodule of M/QI' and consequently has an
associated prime which can be none other than the prime PI belonging to QI'
This proves our theorem.
Theorem3.6.
Let A be a Noetherian ring. Then the set of divisors of zero
in A is the set-theoretic union of all primes belonging to primary ideals in a
reduced primary decomposition of O.
Proof.
An element of a E A is a divisor of 0 if and only if aA is not injective.
According to Proposition 2.9, this is equivalent to a lying in some associated
prime of A (viewed as module over itself). Applying Theorem 3.5 concludes the
proof.
§4.
NAKAYAMA'S LEMMA
We let A denote a commutative ring, but not necessarily Noetherian.
When dealing with modules over a ring, many properties can be obtained
first by localizing, thus reducing problems to modules over local rings. Inpractice,
as in the present section, such modules will be finitely generated. This section
shows that some aspects can be reduced to vector spaces over a field by reducing
modulo the maximal ideal of the local ring. Over a field, a module always has
a basis. We extend this property as far as we can to modules finite over a local
ring. The first three statements which follow are known as Nakayama's lemma .
Lemma 4.1.
Let a be an ideal ofA which is contained in every maximal ideal
of A. Let E be a finitely generated A-module. Suppose that aE = E. Then
E = {OJ.

X,§4
NAKAYAMA'S LEMMA
425
Proof.
Induction on the number of generators of E. Let XI"' "
Xs be
generators of E. By hypothesis, there exist elements ai ' .. . , as E a such that
so there is an element a (namely as) in a such that (l + a)xs lies in the module
generated by the first s - 1 generators. Furthermore 1 + a is a unit in A,
otherwise 1 + a is contained in some maximal ideal, and since a lies in all
maximal ideals, we conclude that 1lies in a maximal ideal, which is not possible.
Hence X s itself lies in the module generated by s - 1 generators, and the proof
is complete by induction.
Lemma 4.1 applies in particular to the case when A is a local ring, and
a = m is its maximal ideal.
Lemma 4.2.
Let A be a local ring, let E be afinitely generated A-module, and
F a submodule. If E = F + mE, then E = F.
Proof.
Apply Lemma 4.1 to ElF.
Lemma 4.3.
Let A be a local ring. Let E be a finitely generated A-module.
If XI, . . . , Xn are generators for E mod mE, then they are generators for E.
Proof.
Take F to be the submodule generated by XI "
' "
Xn •
Theorem4.4.
Let A be a local ring and E a finite projective A-module.
Then E is free. In fact, if X I' . . . , Xn are elements of E whose residue classes
XI "'" xn are a basis of ElmE over Aim, then XI"
' " x, are a basis of E
over A. If XI"'" x, are such that XI"' " X, are linearly independent over
A/m, then they can be completed to a basis ofE over A.
Proof
I am indebted to George Bergman for the following proof of the
first statement. Let F be a free module with basis el> .. . , em and letf: F ~ E
be the homomorphism mapping e, to Xi' We want to prove thatfis an isomor-
phism. By Lemma 4.3, f is surjective. Since E is projective, it follows that f
splits, i.e. we can write F = Po EB PI, where Po = Ker f
and PI is mapped
isomorphically onto E by f, Now the linear independence of XI> .. • , Xn mod
mE shows that
Po emF = mPo EB mP!.
Hence Po c mPo. Also, as a direct summand in a finitely generated module, Po
is finitely generated. So by Lemma 4.3, Po = (0) and f is an isomorphism, as
was to be proved.
As to the second statement, it is immediate since we can complete a given

426
NOETHERIAN RINGS AND MODULES
X.§5
sequence xl>
, x, with Xl> . . . , xr linearly independent over Aim , to a
sequence XI ,
,Xn with Xl , . . . ,xn linearly independent over Aim, and then
we can apply the first part of the proof. This concludes the proof of the theorem.
Let E be a module over a local ring A with maximal ideal m. We let
E(m) = ElmE. If f: E -+ F is a homomorphism, then f induces a homo-
morphism
hm):E(m) -+ F(m).
Iff is surjective, then it follows trivially that !em) is surjective.
Proposition 4.5.
Let f: E -+ F be a homomorphism of modules, finite over a
local ring A. Then :
(i) Ifhm) is surjective, so is f.
(ii) Assume f is injective. Ifhm) is surjective, then f is an isomorphism.
(iii) Assume that E, F are free . Ifhm) is injective (resp. an isomorphism) then
f is injective (resp. an isomorphism).
Proof.
The proofs are immediate consequences of Nakayama's lemma and
will be left to the reader. For instance, in the first statement, consider the exact
sequence
E -+ F -+ Fllmf -+ 0
and apply Nakayama to the term on the right. In (iii), use the lifting of bases
as in Theorem 4.4.
§5.
FILTERED AND GRADED MODULES
Let A be a commutative ring and E a module. By a filtration of E one means
a sequence of submodules
Strictly speaking, this should be called a descending filtration. We don't
consider any other.
Example.
Let a be an ideal of a ring A, and E an A-module. Let
Then the sequence of submodules {En} is a filtration.
More generally, let {En} be any filtration of a module E. We say that it is
an a-filtration if aEn c En + 1 for all n. The preceding example is an a-filtration.

X, §5
FILTERED AND GRADED MODULES
427
We say that an a-filtr ation is a-stable, or stable if we have aEn = En+ 1 for all n
sufficiently large.
Proposition 5.1.
Let {En} and
{ E~} be stable a-filtrations of E. Then there
ex ists a positive integer d such that
for all n ~ O.
Proof.
It
suffices to
prove
the
proposition
when
E~ = anE.
Since
aEn c En+ 1 for all n, we have anE c En. By the stability hypothesis, there
exists d such that
En +d = «e, canE,
which proves the proposition.
A ring A is called graded (by the natural numbers) if one can write A as a
direct sum (as abelian group),
such that for all integers m, n ~ 0 we have AnA m c An+ m • It follows in par-
ticular that Ao is a subring, and that each component An is an Ao-module.
Let A be a graded ring. A module E is called a graded module if E can be
expressed as a direct sum (as abelian group)
such that AnE m c En+ m • In particular, Enis an Ao-module. Elements of Enare
then called homogeneous of degree n. By definition, any element of E can be
written uniquely as a finite sum of homogeneous elements.
Example.
Let k be a field, and let X 0 , ... , X r be independent variables.
The polynomial ring A = k[X 0, .. . , Xr] is a graded algebra, with k = Ao.
The homogeneous elements of degree n are the polynomials generated by the
monomials in X 0 ' . .. , X r of degree n, that is
r
x1f' ... X~r
with
I. d, = n.
i =O
An ideal I of A is called homogeneous if it is graded, as an A-module. If this
is the case, then the factor ring AII is also a graded ring.
Proposition 5.2.
Let A be a graded ring. Then A is Noetherian if and only
if Ao is Noetherian, and A is finitely generated as Ao-algebra.

428
NOETHERIAN RINGS AND MODULES
X, §5
Proof.
A finitely generated algebra over a Noetherian ring is Noetherian,
because it is a homomorphic image of the polynomial ring in finitely many
variables, and we can apply Hilbert's theorem.
Conversely, suppose that A is Noetherian. The sum
is an ideal of A, whose residue class ring is Ao, which is thus a homomorphic
image of A, and is therefore Noetherian. Furthermore, A + has a finite number
of generators x I' . .. , Xs by hypothesis. Expressing each generator as a sum of
homogeneous elements, we may assume without loss of generality that these
generators are homogeneous, say of degrees dI' . . . ,ds respectively, with all
d, > O. Let B be the subring of A generated over Ao by XI"' "
Xs' We claim
that An C B for all n. This is certainly true for n = O. Let n > O. Let X be
homogeneous of degree n. Then there exist elements a, E An - d, such that
s
X =
Lajxj.
i= I
Since d, > 0 by induction, each a, is in Ao[x l , • •• , x.] = B, so this shows x E B
also, and concludes the proof.
We shall now see two ways of constructing graded rings from filtrations.
First, let A be a ring and a an ideal. We view A as a filtered ring, by the
powers an. We define the first associated graded ring to be
00
Sa(A) = S = EB an.
n=O
Similarly, if E is an A-module, and E is filtered by an a-filtration, we define
Then it is immediately verified that Es is a graded S-module.
Observe that if A is Noetherian, and a is generated by elements Xl"
' " x,
then S is generated as an A-algebra also by XI"'" x.. and is therefore also
Noetherian.
Lemma 5.3.
Let A be a Noetherian ring, and E afinitely generated module,
with an a-filtration. Then Es is finite over S if and only if the filtration of E
is a-stable.
Proof.
Let
n
F; = EBE j ,
i=O

X, §5
and let
FILTERED AND GRADED MODULES
429
Then G; is an S-submodule of Es , and is finite over S since F; is finite over A.
We have
Since S is Noetherian, we get :
Es is finite over S ¢> Es = GN for some N
-ee-EN+m= amEN for all m ~ 0
¢> the filtration of E is a-stable.
This proves the lemma.
Theorem 5.4.
(Artin-Rees).
Let A be a Noetherian ring, a an ideal, E a
finite A-module with a stable a-filtration. Let F be a submodule, and let
F; = F n En . Then {Fn} is a stable a-filtration of F.
Proof.
We have
a(F n En) C aF n «E; c F n En + l '
so {F n } is an a-filtration of F. We can then form the associated graded S-module
Fs, which is a submodule of Es , and is finite over S since S is Noetherian. We
apply Lemma 5.3 to conclude the proof.
We reformulate the Artin-Rees theorem in its original form as follow s.
Corollary 5.5.
Let A be a Noetherian ring, E a finite A-module, and F a
submodule. Let a be an ideal. There exists an integer s such that for all
integers n ~ s we have
anE n F = an - "(aSE n F).
Proof.
Special case of Theorem 5.4 and the definitions .
Theorem 5.6.
(Krull).
Let A be a Noetherian ring, and let a be an ideal
contained in every maximal ideal of A. Let E be a finite A-module. Then
ccnanE = O.
n =1
Proof.
Let F = nanE and apply Nakayama's lemma to conclude the
proof.

430
NOETHERIAN RINGS AND MODULES
X, §5
Corollary 5.7.
Lee0 be a local Noetherian ring with maximalidealm. Then
00nm" = O.
"=1
Proof.
Special case of Theorem 5.6 when E = A.
The second way of forming a graded ring or module is done as follows. Let
A be a ring and a an ideal of A. We define the second associated graded ring
00
gro(A) = EB a"/a" + 1.
"=0
Multiplication is defined in the obvious way. Let a E a" and let a denote its
residue class mod n"" 1. Let b e o" and let 5 denote its residue class mod am + 1.
We define the product aD to be the residue class of ab mod am+" + 1. It is easily
verified that this definition is independent of the choices of representatives and
defines a multiplication on gro(A) which makes gro(A) into a graded ring.
Let E be a filtered A-module. We define
00
gr(E) = EB En/En + i-
n=O
If the filtration is an a-filtration, then gr(E) is a graded gro(A)-module.
Proposition 5.8.
Assume that A is Noetherian, and let a be an ideal of A.
Then gra<A) is Noetherian. If E is afinite A-modulewitha stable a-filtration,
then gr(E) is afinite gra<A)-module.
Proof.
Let Xl' .. . , Xs be generators of a. Let Xi be the residue class of Xi
in a/a 2• Then
is Noetherian, thus proving the first assertion. For the second assertion, we
have for some d,
for all m ~ O.
Hence gr(E) is generated by the finite direct sum
gr(E)O EEl •.• EEl gr(E)d'
But each gr(E)n = En/En + 1 is finitely generated over A, and annihilated by a,
so is a finite A/a-module. Hence the above finite direct sum is a finite A/a-
module, so gr(E) is a finite gro(A)-module, thus concluding the proof of the
proposition.

X, §6
§6.
THE HILBERT POLYNOMIAL
THE HILBERT POLYNOMIAL
431
The main point of this section is to study the lengths of certain filtered
modules over local rings, and to show that they are polynomials in appropriate
cases.
However, we first look at graded modules, and then relate filtered
modules to graded ones by using the construction at the end of the preceding
section.
We start with a graded Noetherian ring together with a finite graded A-module
E, so
and
E = EB En-
n=O
We have seen in Proposition 5.2 that Ao is Noetherian, and that A is a finitely
generated Ao-algebra . The same type of argument shows that E has a finite number
of homogeneous generators, and En is a finite Ao-module for all n ?; O.
Let
<p be an Euler-Poincare Z-vaiued function on the class of all finite
Ao-moduies, as in Chapter III, §8. We define the Poincare series with respect
to <p to be the power series
00
Prp(E, t) = L <p(En)tnE Z[[t]].
n=O
We write P(E, t) instead of Prp(E, t) for simplicity.
Theorem 6.1.
(Hilbert-Serre).
Let s be the number of generators of A as
Ao-algebra. Then P(E, t) is a rational function of type
P(E, t) =
s
f(t)
TI (l -
td,)
i = 1
with suitable positive integers d., and f(t) E Z[t].
Proof.
Induction on s. For s = 0 the assertion is trivially true . Let s ?; 1.
Let A = Aolx J> . . . , xs ], deg . Xi = d, ?; I. Multiplication by Xs on E gives rise
to an exact sequence
Let
K = EBKn
and
L = EBLn •

432
NOETHERIAN RINGS AND MODULES
X, §6
for all n ~ m.
Then K, L are finite A-modules (being submodules and factor modules of E),
and are annihilated by XS ' so are in fact graded Ao[x(, ... , xs_d-modules . By
definition of an Euler-Poincare function, we get
Multiplying by tn +dsand summing over n, we get
(l -
tds)P(E, t) = P(L, t) - r-ro; t) + g(t),
where g(t) is a polynomial in Z[t] . The theorem follows by induction.
Remark.
In Theorem 6.1, if A = Ao[Xl' . .. , xs] then d, = deg Xi as shown
in the proof. The next result shows what happens when all the degrees are
equal to 1.
Theorem 6.2.
Assumethat A is generated as an Ao-algebra by homogeneous
elementsofdegree 1. Let d be the orderofthe poleofP(E, t) at t = 1. Then
for all sufficiently large n, cp(En) is a polynomial in n of degree d - 1. (For
this statement, the zero polynomial is assumed to havedegree -1.)
Proof.
By Theorem 6.1, cp(En ) is the coefficient of t" in the rational function
P(E, t) = f(t)j(1 - ty.
Cancelling powers of I - t, we write P(E, t) = h(t)j(1 - t)d, and h(l) i= 0, with
h(t) E Z[t]' Let
m
h(t) = L aktk.
k=O
We have the binomial expansion
(l -
t)-d = Jo (d : : ~ 1)tk.
For convenience we let (_~) = °for n ~°and (_~) = 1 for n = -1. We
then get
m
(d + n - k- 1)
cp(En) = Joak
d -
1
The sum on the right-hand side is a polynomial in n with leading term
This proves the theorem.

X, §6
THE HILBERT POLYNOMIAL
433
The polynomial of Theorem 6.2 is called the Hilbert polynomial of the
graded module E, with respect to ep.
We now put together a number ofresults ofthis chapter, and give an application
of Theorem 6.2 to certain filtered modules.
Let A be a Noetherian local ring with maximal ideal rn, Let q be an m-
primary ideal. Then A/q is also Noetherian and local. Since some power of m
is contained in q, it follows that A/q has only one associated prime, viewed as
module over itself, namely m/q itself. Similarly, if M is a finite A/q-module,
then M ha s only one associated prime, and the only simple A/q-module is in
fact an A/m-module which is one-dimensional. Again since some power of m
is contained in q, it follows that A/q has finite length, and M also has finite
length.
We now use the length function as an Euler-Poincare function in
applying Theorem 6.2.
Theorem 6.3.
Let A be a Noetherian local ring with maximal ideal m.
Let q be an m-primary ideal, and let E be a finitely generated A-module, with
a stable q-filtration. Then :
(i) E/En hasfinite lengthfor n ~ O.
(ii) For all sufficiently large n, this length is a polynomialg(n) of degree ~ s,
where s is the least number of generators ofq.
(iii) The degreeand leading coefficient ofg(n) dependonly on E and q, but not
on the chosenfiltration.
Proof.
Let
Then gr(E) = E8 En/En+ 1 is a graded G-module, and Go = A/q. By Proposition
5.8, G is Noetherian and gr(E) is a finite G-module. By the remarks preceding
the theorem, E/Enhas finite length, and if cp denotes the length, then
n
cp(E/En) = L cp(Ej _ I/E).
j= 1
If x., . .. , X s generate q, then the images XI' . . . , Xs in q/q2 generate G as A/q-
algebra, and each Xi has degree 1. By Theorem 6.2 we see that
is a polynomial in n of degree ~ s -
I for sufficiently large n. Since
it follows by Lemma 6.4 below that ep(EI En) is a pol ynomial g(n) of degree
~ s for all large n. The last statement concerning the independence of the degree

434
NOETHERIAN RINGS AND MODULES
X, §6
(1)
of 9 and its leading coefficient from the chosen filtration follows immediately
from Proposition 5.1, and will be left to the reader. This concludes the proof.
From the theorem, we see that there is a polynomial XE,q such that
for all sufficiently large n. IfE = A, then XA,q is usually called the characteristic
polynomial of q. In particular, we see that
for all sufficiently large n.
For a continuation of these topics into dimension theory, see [AtM 69] and
[Mat 80].
We shall now study a particularly important special case having to do with
polynomial ideal s. Let k be a field, and let
A = k[Xo, . . . , XN ]
be the polynomial ring in N + I variable. Then A is graded, the elements of
degree n being the homogeneous polynomials of degree n. We let a be a homo-
geneous ideal of A, and for an integer n ~ a we define :
cp(n) = dim, An
cp(n, a) = dim, an
x(n, a) = dim, An/an = dim, An - dim, an =
cp(n) -
cp(n, a) .
As earlier in this section, An denotes the k-space of homogeneous elements of
degree n in A, and similarly for aw Then we have
(
N + n)
cp(n) =
N
.
We shall consider the binomial polynomial
(J - T(T -
1) ... (T - d + 1) _ Td
-
d'
-
d' + lower terms.
d
.
.
If f is a function , we define the difference function fJ.fby
fJ.f(T) = f(T + 1) - f(T) .
Then one verifies directly that
(2)

X, §6
THE HILBERT POLYNOMIAL
435
Lemma 6.4.
Let P E Q[T] be a polynomial of degree d with rational
coefficients.
(a) If Pen) E Z for all sufficiently large integers n, then there exist integers
co' ... , Cd such that
In particular, Pen) E Zfor all integers n.
(b) Iff: Z -7 Z is anyfunction, and if there exists a polynomial Q(T) E Q[T]
such that Q(Z) C Z and /If(n) = Q(n) for all n sufficiently large, then
thereexistsa polynomialP as in (a) such thatf(n) = P(n)for all n sufficiently
large.
Proof.
We prove (a) by induction. If the degree of Pis 0 , then the assertion
is obvious. Suppose deg P ;;; 1. By (1) there exist rational numbers co' . .. , cd
such that peT) has the expression given in (a) . But /lP has degree strictly smaller
than deg P. Using (2) and induction, we conclude that co' . . . , cd-I must be
integers. Finally Cd is an integer because Pen) E Z for n sufficiently large . This
proves (a) .
As for (b), using (a) , we can write
Q(T) = co(
T
) + . .. + Cd-I
d -
I
with integers co' . .. , Cd- I' Let PI be the "integral" of Q, that is
Then 1J..(f - PI)(n) =°for all n sufficiently large . Hence (f - P1)(n) is equal
to a constant Cd for all n sufficiently large, so we let P = PI + Cd to conclude
the proof.
Proposition 6.5.
Let a, b be homogeneous ideals in A. Then
<pen, a + b) = <pen, a) + <pen, b) -
<pen, a n b)
x(n, a + b) = x(n, a) + x(n, b) - x(n , an b) .
Proof.
The first is immediate, and the second follows from the definition
of X.

436
NOETHERIAN RINGS AND MODULES
X. §6
Theorem 6.6.
Let F be a homogeneous polynomial ofdegree d. Assume that
F is not a divisor of zero mod a. that is : if G EA . FG Ea . then G Ea . Then
x(n, a + (F)) = x(n, a) - x(n - d, a).
Proof.
First observe that trivially
'P(n, (F» = 'P(n - d) ,
because the degree of a product is the sum of the degrees. Next , using the
hypothesis that F is not divisor of 0 mod a, we conclude immediately
'P(n, an (F)) = 'P(n - d, a).
Finally, by Proposition 6.5 (the formula for X), we obtain :
x(n, a + (F) = x(n, a) + x(n, (F)) - x(n, a n (F))
= x(n, a) + 'P(n) -
'P(n, (F)
-
'P(n) + 'P(n, a n (F)
= x(n, a) -
'P(n - d) + 'P(n - d, a)
= x(n, a) - x(n - d, a)
thus proving the theorem.
We denote by m the maximal ideal m = (Xo, . . . , XN ) in A. We call m the
irrelevant prime ideal. An ideal is called irrelevant if some positive power of
m is contained in the ideal. In particular, a primary ideal q is irrelevant if and
only if m belongs to q. Note that by the Hilbert nullstellensatz, the condition
that some power of m is contained in a is equivalent with the condition that the
only zero of a (in some algebraically closed field containing k) is the trivial zero .
Proposition 6.7.
Let a be a homogeneous ideal.
(a) If a is irrelevant. then x(n. a) = 0 for n sufficiently large .
(b) In general. there is an expression a = qIn ... n q s as a reduced primary
decomposition such that all qi are homogeneous.
(c) If an irrelevant primary ideal occurs in the decomposition . let b be the
intersection of all other primary ideals. Then
x(n, a) = x(n. b)
for all n sufficiently large.
Proof.
For (a), by assumption we have An = an for n sufficiently large, so
the assertion (a) is obvious. We leave (b) as an exercise. As to (c), say qs is
irrelevant, and let b = qIn ... n qs-(' By Proposition 6.5, we have
x(n, b + qs) = x(n, b) + x(n , qs) - x(n, a) .
But b + qs is irrelevant, so (c) follows from (a), thus concluding the proof.

X, §6
THE HILBERT POLYNOMIAL
437
We now want to see that for any homogeneous ideal a the function f such
that
f (n) = x (n, a)
satisfies the conditions of Lemma 6.4(b). First, we observe that if we change
the ground field from k to an algebraicall y closed field K containing k, and we
let AK = K[Xo, .. . , XN ], aK = Ka, then
and
Hence we can assume that k is algebraically clo sed .
Second, we shall need a geometric notion , that of dimension. Let V be a
variety over k, say affine , with generic point (x) = (Xl> .. . , XN )' We define its
dimension to be the transcendence degree of k(x) over k. For a projective variety,
defined by a homogeneous prime ideal p, we define its dimension to be the
dimension of the homogeneous variety defined by p minus 1.
We now need the following lemma.
Lemma 6.8.
Let V, W be varieties over a field k.
[fV::J Wand dim V = dim W, then V = W.
Proof.
Say V, Ware in affine space AN. Let Pv and Pw be the respective
prime ideals of V and Win k[X]. Then we have a canonical homomorphism
k[X] /p v ~ k[x] -
k[y] ~ k[X]/p w
from the affine coordinate ring of V onto the affine coordinate ring of W. If the
transcendence degree of k(x) is the same as that of k( y ), and say YI' . .. , Yr form
a tran scendence basis of k( y ) over k , then X l ' . . . , .r, is a tran scendence basis
of k(x) over k, the homomorphism k[x] -
k[y] induces an isomorphism
and hence an isomorphism on the finite extension k[x] to k[y], as desired.
Theorem 6.9.
Let a be a homogeneous ideal in A. Let r be the maximum
dimension of the irreducible components of the algebraic space in projective
space defined by a. Then there exists a polynomial P E Q[T] of degree ~ r,
such that P(Z) C Z , and such that
P(n) = x(n, a)
for all n sufficiently large.

438
NOETHERIAN RINGS AND MODULES
X,§6
Proof.
By Proposition 6.7(c), we may assume that no primary component
in the primary decomposition of a is irrelevant. Let Z be the algebraic space of
zeros of a in projective space. We may assume k algebraically clo sed as noted
previously. Then there exists a homogeneous polynomial L E k[X] of degree I
(a linear form) which does not lie in any of the prime ideals belonging to the
primary ideals in the given decomposition. In particular, L is not a divisor of
zero mod a. Then the components of the algebraic space of zeros of a + (L)
must have dimension ~ r -
1. By induction and Theorem 6.6 , we conclude
that the difference
x(n, a) -
x(n -
I , 0)
satisfies the conditions of Lemma 6.4(b) , which concludes the proof.
The polynomial in Theorem 6.9 is called the Hilbert polynomial of the
ideal u,
Remark.
The above results give an introduction for Hartshorne's [Ha 77],
Chapter I, especially §7. If Z is not empty, and if we write
nr
x(n, a) =c, + lower terms,
r.
then c > 0 and c can be interpreted as the degree of Z, or in geometric terms,
the number of points of intersection of Z with a sufficiently general linear variety
of complementary dimension (counting the points with certain multiplicities) .
For explanations and details, see [Ha 77], Chapter I, Proposition 7.6 and Theorem
7.7; van der Waerden [vdW 29] which does the same thing for multihomogeneous
polynomial ideals; [La 58], referred to at the end of Chapter VIII , §2; and the
papers [MaW 85], [Ph 86], making the link with van der Waerden some six
decades before.
Bibliography
[AtM 69]
[Ha 77]
[MaW 85]
[Mat 80]
[Ph 86]
[vdW 29]
M. ATiYAH and I. MACDONALD, Introduction to commutative algebra,
Addison-Wesley, 1969
R. HARTSHORNE, Algebraic Geometry, Springer Verlag, 1977
D. MASSER and G. WOSTHOLZ, Zero estimates on group varieties II, Invent.
Math. 80 (1985), pp. 233-267
H.
MATSUMURA,
Commutative
algebra,
Second
Edition,
Benjamin-
Cummings, 1980
P. PHILIPPON, Lemmes de zeros dans les groupes algebriques commutatifs,
Bull. Soc. Math. France 114 (1986), pp. 355-383
B. L. VAN DER WAERDEN, On Hilbert's function, series of composition of
ideals and a generalization of the theorem of Bezout, Proc. R. Soc. Amster-
dam 31 (1929), pp. 749-770

X, §7
INDECOMPOSABLE MODULES
439
§7.
INDECOMPOSABLE MODULES
Let A be a ring, not necessarily commutative, and E an A-module. We
say that E is Artinian if E satisfies the descending chain condition on sub-
modules, that is a sequence
must stabilize: there exists an integer N such that if n ~ N then En = En + i -
Example 1.
If k is a field, A is a k-algebra, and E is a finite-dimensional
vector space over k which is also an A-module, then E is Artinian as well as
Noetherian.
Example 2.
Let A be a commutative Noetherian local ring with maximal
ideal m, and let q be an m-primary ideal. Then for every positive integer n,
Alqn is Artinian. Indeed, Alqn has a Jordan-Holder filtration in which each
factor is a finite dimensional vector space over the field Aim, and is a module
of finite length. See Proposition 7.2 .
Conversely, suppose that A is a local ring which is both Noetherian and
Artinian. Let m be the maximal ideal. Then there exists some positive integer
n such that m" = 0. Indeed, the descending sequence m" stabilizes,
and
Nakayama's lemma implies our assertion.
It then also follows that every
primary ideal is nilpotent.
As with Noetherian rings and modules, it is easy to verify the following
statements :
Proposition 7.1.
Let A be a ring, and let
°-> E' -> E -> E" -> 0
be an exact sequence of A-modules. Then E is Artinian if and only if E' and
E" are Artinian.
We leave the proofto the reader. The proof is the same as in the Noetherian
case, revers ing the inclusion relations between modules.
Proposition 7.2.
A module E has a finite simple filtration if and only if E
is both Noetherian and Artinian.
Proof.
A simple module is generated by one element, and so is Noetherian.
Since it contains no proper submodule
=1= 0, it is also Artinian. Proposition 7.2
is then immediate from Proposition 7. I.
A module E is called decomposable if E can be written as a direct sum

440
NOETHERIAN RINGS AND MODULES
X,§7
with E1 =1= E and E2 =1= E.
Otherwise, E is called indecomposable. If E is
decomposable as above, let e l
be the projection on the first factor, and
e2 = 1 - e l the projection on the second factor. Then e l , e2 are idempotents
such that
Conversely, if such idempotents exist in End(E) for some module E, then E is
decomposable, and ej is the projection on the submodule e.E,
Let u : E -. E be an endomorphism of some module E. We can form the
descending sequence
1m u ::::l 1m u2 ::::l 1m u3 ::::l • • •
If E is Artinian, this sequence stabilizes, and we have
for all sufficiently large n.
We call this submodule uOO(E), or 1m U OO.
Similarly, we have an ascending sequence
Ker u c Ker u2 c Ker u3 c . ..
which stabilizes if E is Noetherian, and in this case we write
Ker U
OO = Ker u"
for n sufficiently large.
Proposition 7.3.
(Fitting's Lemma).
Assume that E is Noetherian and
Artinian. Let u E End(E). Then E has a direct sum decomposition
E = 1m U
OO EB Ker u" ,
Furthermore, the restriction ofu to 1m U
OO is an automorphism,and the restric-
tion of u to Ker U
OO is nilpotent.
Proof.
Choose n such that 1m U
OO = 1m u" and Ker
U
OO = Ker u". We
have
1m U
OO 11 Ker U
OO = {O},
for if x lies in the intersection, then x = un(y) for some y E E, and then
o= un(x) = u2n(y). So y E Ker u2n = Ker u", whence x = un(y) = O.
Secondly, let x E E. Then for some y E un(E) we have

X, §7
Then we can write
INDECOMPOSABLE MODULES
441
x = x -
Un(y) + Un(y),
which shows that E = 1m u" + Ker u",
Combined with the first step of the
proof, this shows that E is a direct sum as stated.
The final assertion is immediate, since the restriction of u to 1m u" is sur-
jective, and its kernel is 0 by the first part of the proof. The restriction of u to
Ker u" is nilpotent because Ker u" = Ker u". This concludes the proof of the
proposition.
We now generalize the notion of a local ring to a non-commutative ring.
A ring A is called local if the set of non-units is a two-sided ideal.
Proposition 7.4.
Let E be an indecomposable module over the ring A. Assume
E Noetherian and Artinian. Any endomorphism of E is either nilpotent or an
automorphism. Furthermore End(E) is local.
Proof.
By Fitting's lemma, we know that for any endomorphism u, we
have E = 1m u" or E = Ker u" , So we have to prove that End(E) is local.
Let u be an endomorphism which is not a unit, so u is nilpotent. For any
endomorphism v it follows that uv and vu are not surjective or injective respec-
tively, so are not automorphisms. Let u1, U2 be endomorphisms which are not
units. We have to show
U 1 + U2 is not a unit. If it is a unit in End(E), let
Vi =
Ui(U I + U2)-1 . Then V I + V2 = 1. Furthermore, VI = 1 -
V2 is invertible
by the geometric series since V2 is nilpotent. But V1 is not a unit by the first part
of the proof, contradiction. This concludes the proof.
Theorem 7.5.
(Krull-Remak-Schmidt).
Let E i= 0 be a module which is
both Noetherian and Artinian. Then E is afinite direct sum ofindecomposable
modules.
Up to a permutation, the indecomposable components in such a
direct sum are uniquely determined up to isomorphism.
Proof.
The existence of a direct sum decomposition into indecomposable
modules follows from the Artinian condition. If first E = E 1 EB E2 , then either
E 1, E2 are indecomposable, and we are done ; or, say, E I is decomposable.
Repeating the argument, we see that we cannot continue this decomposition
indefinitely without contradicting the Artinian assumption.
There remains to prove uniqueness. Suppose
where Ei> Fj are indecomposable. We have to show that r = s and after some
permutation, E, ~ F j • Let ei be the projection of E on Ei> and let uj be the
projection of Eon F j , relative to the above direct sum decompositions. Let:

442
NOETHERIAN RINGS AND MODULES
Then I
Uj = idE implies that
sI VjWj lEI = idE"
j= I
X, §7
By Proposition 7.4, End(E I ) is local, and therefore some VjWj is an automor-
phism of EI. After renumbering, we may assume that VIWI is an automorphism
of E I'
We claim that V I and
WI induce isomorphisms between El and F I'
This follows from a lemma.
Lemma 7.6.
Let M, N be modules, and assume N indecomposable. Let
u :M -. N and v :N -. M be such that vu is an automorphism. Then u, v
are isomorphisms.
Proof.
Let e = U(VU)-IV. Then e2 = e is an idempotent, lying in End(N),
and therefore equal to 0 or 1 since N is assumed indecomposable. But e =1= 0
because idM
=1= 0 and
So e = idN • Then u is injective because vu is an automorphism; v is injective
because e = id; is injective ; u is surjective because e = idN ; and v is surjective
because vu is an automorphism. This concludes the proof of the lemma.
Returning to the theorem, we now see that
E = F I EB (E 2 EB . . . EB E.).
Indeed, eI induces an isomorphism from FI to EI' and since the kernel of eI
is E2 EB ... EB E. it follows that
F I 1\ (E2 EB .. . EB E.) = O.
But also, F I == EI (mod E2 EB .. . EB E.), so E is the sum of F I and E2 EB· . . EB E.,
whence E is the direct sum, as claimed. But then
The proof is then completed by induction.
We apply the preceding results to a commutative ring A. We note that an
idempotent in A as a ring is the same thing as an idempotent as an element of
End(A), viewing A as module over itself. Furthermore End(A) :::::: A. Therefore,
we-find the special cases:
Theorem 7.7.
Let A be a Noetherian and Artinian commutative ring.

X, Ex
EXERCISES
443
(i) If A is indecomposable as a ring, then A is local.
(ii) In general, A is a direct product of local rings, which are Artinian and
Noetherian.
Another way of deriving this theorem will be given in the exercises.
EXERCISES
I. Let A be a commutative ring.
Let M be a module, and N a submodule.
Let
N = QI n
n Qr be a primary decomposition of N.
Let Qi = QJN . Show that
0= QI n
n Qr is a primary decomposition of 0 in MIN. State and prove the
converse.
2. Let V be a prime ideal, and a, b ideals of A. If ab c V, show that a c V or b c V.
3. Let q be a primary ideal. Let a, b be ideals, and assume ab c q. Assume that b is
finitely generated. Show that a c q or there exists some positive integer n such that
b" c q.
4. Let A be Noetherian, and let q be a p-primary ideal. Show that there exists some n ;;;; 1
such that V" c q.
5. Let A be an arbitrary commutative ring and let S be a multiplicative subset.
Let V
be a prime ideal and let q be a p-primary ideal. Then V intersects S if and only if q
intersects S. Furthermore, if q does not intersect S, then S-Iq is S-Iv-primary in
S-IA.
6. If a is an ideal of A, let as = S- Ia. If Ips : A --+ S- IA is the canonical map, abbreviate
Ips I(as) by as n A, even though Ips is not injective. Show that there is a bijection
between the prime ideals of A which do not intersect S and the prime ideals of S- IA,
given by
Prove a similar statement for primary ideals instead of prime ideals.
7. Let a = qIn · . . n q, be a reduced primary decomposition of an ideal. Assume that
q. , .. . , q; do not intersect S, but that qj intersects S for j > i. Show that
is a reduced primary decomposition of as.
8. Let A be a local ring. Show that any idempotent # 0 in A is necessarily the unit
element. (An idempotent is an element e E A such that el = e.)
9. Let A be an Artinian commutative ring. Prove :
(a) All prime ideals are maximal. [Hint : Given a prime ideal V, let x E A, x(V) = O.
Consider the descending chain (x)
::::> (Xl) ::::> (x' ) ::::> ••• •]

444
NOETHERIAN RINGS AND MODULES
X, Ex
(b) There is only a finite number of prime, or maximal , ideals. [Hint: Among all
finite intersections of maximal ideals, pick a minimal one.]
(c) The ideal N of nilpotent elements in A is nilpotent, that is there exists a positive
integer k such that N~ = (0). [Him :
Let k be such that N~ = Nk' '. Let 0 = N~.
Let b be a minimal ideal t= 0 such that bo t= O. Then b is principal and bo = b.]
(d) A is Noetherian.
(e) There exists an integer r such that
A = nAIrn'
where the product is taken over all maximal ideals.
(0 We have
where again the product is taken over all prime ideals p.
10. Let A, B be local rings with maximal ideals m,; mB , respectively. Let j': A --+ B be a
homomorphism. We say thatjis local ifj -l(mB) = rnA' Suppose this is the case.
Assume A, B Noetherian, and assume that :
I. A/I1I A --+ B/I1I H is an isomorphism :
2. m,
--+ mH/rn~ is surjective :
3. B is a finite A-module, via f.
Prove thatj" is surjective. [Hint :
Apply Nakayama twice.]
For an ideal a, recall from Chapter IX, §5 that ?1 (a) is the set of primes containing a.
II . Let A be a commutative ring and M an A-module. Define the support of M by
supp(M) = {pEspec(A) :Mp"l= O}.
IfM is finite over A, show that supp(M) = ?1 (ann(M», where ann(M) is the annihilator
of M in A, that is the set of elements a E A such that aM = O.
12. Let A be a Noetherian ring and M a finite A-module. Let I be an ideal of A such that
supp(M) C ?1 (I) . Then PM = 0 for some n > O.
13. Let A be any commutative ring, and M, N modules over A. If M is finitely presented,
and S is a multiplicative subset of A, show that
This is usually applied when A is Noetherian and M finitely generated, in which case
M is also finitely presented since the module of relations is a submodule of a finitely
generated free module.
14. (a) Prove Proposition 6.7(b).
(b) Prove that the degree of the polynomial P in Theorem 6.9 is exactly r.
Locally constant dimensions
15. Let A be a Noetherian local ring. Let E be a finite A-module. Assume that A has no
nilpotent clements. For each prime ideal p of A, let k(p) be the residue class field. If
dim~(p, Ep/pEp is constant for all p, show that E is free. [Hint:
Let XI"
' "
X, E A be

X, Ex
EXERCISES
445
such that the residue classes mod the maximal ideal form a basis for ElmE over k(m ).
We get a surjective homomorphism
A' -+ E -+ O.
Let J be the kernel. Show that J. c
m. A~ for all p so J c p for all p and J = 0.]
16. Let A be a Noetherian local ring without nilpotent element s. Let j": E -+ F be a homo-
morphism of A-modules, and suppose E, F are finite free. For each prime p of A let
/ ;. , : E. /pEp-+ Fp/pFp
be the corresponding k(p)-homomorphism, where k(p ) = Ap/p Ap is the residue class
field at p. Assume that
is constant.
(a) Pro ve that Film ! and Im j" are free, and that there is an isomorphism
F;::: Im!® (Film f).
[Hint :
Use Exercise 15.]
(b) Prove that Ker f is free and E ;::: (Ker f) ® (1m f). [Hint:
Use that finite
projective is free.]
The next exercises depend on the notion of a complex, which we have not yet formally
defined . A (finite) complex E is a sequence of homomorphisms of module s
d O
d '
d n
o~ EO~ E' ~ . . . ~ En ~ 0
and homorphisms d' : Ei ~ E' " I such that d' -t I
0 d' = 0 for all i. Thus Im(di) C Ker (d i + 1).
The homology H i of the complex is defined to be
H i = Ker(di+I)/lm(di).
By definition, H O= EOand H" = En/ l m(dn). You may want to look at the first section
of Chapter XX, because all we use here is the basic notion , and the following property,
which you can easily prove. Let E, F be two complexes. By a homomorphismj': E ~ F
we mean a sequence of homomorphisms
Ii: Ei ~ F i
making the diagram commutative for all i:
di
Ei~Ei +1
!il
l!i+1
Fi~F
i +l
d}:
Show that such a homomorphism! induces a homomorphism H(f) : H(E ) ~ H (F ) on the
homology; that is, for each i we have an induced homomorphism

446
NOETHERIAN RINGS AND MODULES
X, Ex
The following exercises are inspired from applications to algebraic geometry, as for
instance in Hartshorne, Algebraic Geometry, Chapter III, Theorem 12.8. See also Chapter
XXI, §I to see how one can construct complexes such as those considered in the next
exercises in order to compute the homology with respect to less tractable complexes.
Reduction of a complex mod p
17. Let 0 -> KO -> K 1 -> . . . -> K" -> 0 be a complex of finite free modules over a local
Noetherian ring A without nilpotent elements. For each prime p of A and module E,
let E(p) = Ep/pEp, and similarly let K(p) be the complex localized and reduced mod p.
For a given integer i, assume that
is constant, where Hi is the i-th homology of the reduced complex. Show that Hi(K)
is free and that we have a natural isomorphism
[Hint:
First write dIp) for the map induced by di on Ki(p). Write
dimklP) Ker dIp) = dimk(p) Ki(p) - dimk(p) Im dIp) .
Then show that the dimensions dimk1p) Irn dIp) and dimklP) 1m d;;;1 must be constant.
Then apply Exercise 12.]
Comparison of homology at the special point
18. Let A be a Noetherian local ring. Let K be a finite complex, as follows :
o-> KO -> . . . -> Kn -> 0,
such that K i isfinite free for all i. For some index i assume that
is surjective. Prove :
(a) This map is an isomorphism.
(b) The following exact sequences split:
(c) Every term in these sequences is free.
19. Let A be a Noetherian local ring. Let K be a complex as in the previous exercise. For
some i assume that
is surjective (or equivalently is an isomorphism by the previous exercise). Prove that

X, Ex
EXERCISES
447
the following conditions are equivalent :
(a) H i - I(K)(m) -> H i - 1(K(m)) is surjective.
(b) H i - 1(K)(m) -> H i - 1(K(m)) is an isomorphism.
(c) Hi(K) is free.
[Hint:
Lift bases until you are blue in the face.]
(d) If these conditions hold, then each one of the two inclusions
splits, and each one of these modules is free. Reducing mod m yields the
corresponding inclusions
and induce the isomorphism on cohomology as stated in (b). [Hint:
Apply
the preceding exercise.]

CHAPTER XI
Real Fields
§1 .
ORDERED FIELDS
Let K be a field. An ordering of K is a subset P of K having the following
properties:
ORO 1.
Given x E K, we have either x E P, or x = 0, or - x E P, and these
three possibilities are mutually exclusive. In other words, K is the
disjoint union of P, {O}, and - P.
ORO 2.
If x, Y EP, then x + y and xy E P.
We shall also say that K is ordered by P, and we call P the set of positive
elements.
Let us assu me that K is ordered by P. Since 1 #- 0 and 1 = 12 = ( _ 1)2
we see that 1 E P. By ORO 2, it follows that 1 + ... + 1 E P, whence K has
characteristic O. If x E P, and x #- 0, the n xx " 1 = 1 E P imp lies that x " 1 E P.
Let x, y E K . We define x < y (or y > x) to mean that y - x E P. If x < 0
we say that x is negative. Th is means that - x is positive. One verifies trivially
the usual relation s for inequ alities, for instance :
x<y
and
y <z
implies
x < z,
x<y
and
z> o
implies
xz < yz,
implies
1
1
x< y
and
x, y > 0
- < - .
y
x
We define x ~ y to mean x < y or x = y. Then x ~ y and y ~ x imply x = y.
If K is ordered and x E K , x #- 0, then x 2 is positive because x 2 = ( _X)2
and either x E P or - x E P. Thus a sum of squares is positive, or O.
Let E be a fie ld. Then a product of sums ofsquares in E is a sum ofsquares.
If a, bEE are sums of squares and b #- 0 then alb is a sum ofsquares.
449
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

450
REAL FIELDS
XI, §1
The first assertion is obvious, and the second also, from the expression
alb = ab(b- I)2.
If E has characteristic =I 2, and - 1 is a sum of squares in E, then every
element a E E is a sum of squares, because 4a = (1 + a)2 - (1 - a)2.
If K is a field with an ordering P, and F is a subfield, then obviously, P (') F
defines an ordering of F, which is called the induced ordering.
We observe that our two axioms ORD 1 and ORD 2 apply to a ring. If
A is an ordered ring, with 1 =I 0, then clearly A cannot have divisors of 0, and
one can extend the ordering of A to the quotient field in the obvious way: A
faction is called positive if it can be written in the form alb with a, b E A and
a, b > O. One verifies trivially that this defines an ordering on the quotient
field.
Example.
We define an ordering on the polynomial ring R[t] over the
real numbers. A polynomial
with an =I 0 is defined to be positive if an > O. The two axioms are then trivially
verified. We note that t > a for all a E R. Thus t is infinitely large with respect
to R. The existence of infinitely large (or infinitely small) elements in an ordered
field is the main aspect in which such a field differs from a subfield of the real
numbers.
We shall now make some comment on this behavior, i.e. the existence of
infinitely large elements.
Let K be an ordered field and let F be a subfield with the induced ordering.
As usual, we put [x] = x ifx > 0 and [xI = -x ifx < O. We say that an element
ex in K is infinitely largeover F ifIexI ~ x for all x E F. We say that it is infinitely
smallover F if0 ~ IexI < Ix Ifor all x E F, x =I O. We see that ex is infinitely large
if and only if ex- 1 is infinitely small. We say that K is archimedean over F if K
has no elements which are infinitely large over F. An intermediate field F I '
K ~ F1 ~ F, is maximal archimedean over F in K if it is archimedean over F,
and no other intermediate field containing F] is archimedean over F. If FI is
archimedean over F and F2 is archimedean over F] then F2 is archimedean over
F. Hence by Zorn 's lemma there always exists a maximal archimedean subfield
F} of Kover F. We say that F is maximal archimedean in K if it is maximal
archimedean over itself in K.
Let K be an ordered field and F a subfield. Let 0 be the set of elements of K
which are not infinitely large over F. Then it is clear that 0 is a ring, and that for
any ex E K, we have ex or ex- 1 EO. Hence 0 is what is called a valuation ring,
containing F. Let m be the ideal of all ex E K which are infinitely small over F.
Then m is the unique maximal ideal of 0, because any element in 0 which is not
in m has an inverse in o. We call 0 the valuation ring determined by the ordering
of KIF.

XI, §2
REAL FIELDS
451
Proposition 1.1.
Let K be all ordered field and F a subfield. Let 0 be the
taluation rinq determined by the orderinq of KIF, and let m be its maximal
ideal. Theil o/m is a realfield.
Proof
Otherwise, we could write
-1 = L IY.f + a
with
(Xi E 0 and a E m. Since L r:x f is positive and a is infinitel y small, such a
relation is clearly impossible.
§2.
REAL FIELDS
A field K is said to be real if - 1 is not a sum of squares in K. A field K is
said to be real closed if it is real, and if any algebraic extension of K which is real
must be equal to K. In other words, K is maximal with respect to the property
of reality in an algebraic closure .
Proposition 2.1.
Let K be a realfield.
(i) If a E K, then K(fi ) or K(~) is real. If a is a sum of squares in K ,
then K(v7i) is real. If K(v7i) is not real, then -a is a sum of squares
in K.
(ii) Iff is an irreducible polynomial ofodddegree n in K[X] and if IY. is a root
of f , then K(IY.) is real.
Proof
Let a E K. Ifa is a square in K, then K (fi) = K and hence is real by
assumption. Assume that a is not a square in K. If K( fi) is not real, then there
exist hi, c, E K such that
-1 = L (hi + cifi)2
= L (bf + 2cjbi fi + cfa).
Since fi is of degree 2 over K , it follows that
- 1 = Lbf + a Lcf·
If a is a sum of squares in K , this yields a contradiction. In any case, we con-
clude that
1 + Ibf
-a =
" 2
L.. Ci
is a quotient of sums of squares, and by a previous remark, that - a is a sum of
squares. Hence K(v7i) is real, thereby proving our first assertion.

452
REAL FIELDS
As to the second, suppose K(ex) is not real. Then we can write
XI, §2
with polynomials gj in K[X] of degree
~ n -
I. There exists a polynomial h
in K[X] such that
- 1 = L gj(X? + h(X)f(X).
The sum of gj(X)2 has even degree, and this degree must be > 0, otherwise -1
is a sum of squares in K. This degree is ~ 2n - 2. Since f has odd degree n, it
follows that h has odd degree ~ n - 2. If fJ is a root of h then we see that - 1
is a sum of squares in K(fJ). Since deg h < deg f, our proof is finished by
induction.
Let K be a real field. By a real closure we shall mean a real closed field L
which is algebraic over K.
Theorem 2.2.
Let K be a real field.
Then there exists a real closure of K.
If R is real closed, then R has a unique ordering.
The positive elements are
the squares ofR. Every positive element is a square, and every polynomial of
odd degree in R[X] has a root in R. We have R3 = R(v=I).
Proof
By Zorn's lemma, our field K is contained in some real closed field
algebraic over K. Now let R be a real closed field. Let P be the set of non-zero
elements of R which are sums of squares. Then P is closed under addition and
multiplication. By Proposition 2.1,every element of P is a square in R, and given
a E R, a # 0, we must have a E P or -a E P. Thus P defines an ordering. Again
by Proposition 2.1 , every polynomial of odd degree over R has a root in R. Our
assertion follows by Example 5 of Chapter VI, §2.
Coronary 2.3.
Let K be a real field and a an element of K which is not a
sum ofsquares. Th en there exists an ordering of K in which a is negative.
Proof
The field K(;=:;;) is real by Proposition 1.1 and hence has an
ordering as a subfield of a real closure. In this ordering, - a > 0 and hence a is
negative.
Proposition 2.4.
Let R be afield such that R # W but Ra = R(J=T). Then
R is real and hence real closed .
Proof
Let P be the set of elements of R which are squares and # O. We
contend that P is an ordering of R. Let a E R , a # O. Suppose that a is not a
square in R. Let ex be a root of X 2 - a = O. Then R(ex) = R(.j=l), and hence
there exist c, d E R such that ex = c + dJ=1. Then
ex2 = c2 + 2cdJ=1 - d2.

XI, §2
REAL FIELDS
453
Since 1, j=1 are linearly independent over R, it follows that c = 0 (because
a ~ R2), and hence - a is a square.
We shall now prove that a sum of squares is a square. For simplicity, write
i = j=1. Since R(i) is algebraically closed, given a, b E R we can find c, d E R
such that (c + di? = a + bi. Then a = c2 -
d2 and b = 2cd. Hence
a2 + b2 = (c2 + d2 )2 ,
as was to be shown.
If a E R, a #- 0, then not both a and - a can be squares in R. Hence P is an
ordering and our proposition is proved.
Theorem 2.5.
Let R be a real closedfield, and f(X) a polynomial in R[X].
Let a, bE R and assume that f(a) < 0 and feb) > O. Then there exists c
betweena and b such that fCc) = o.
.
Proof
Since R(J=1) is algebraically closed, it follows that f splits into a
product of irreducible factor s of degree 1 or 2. If X 2 + «X + Pis irreducible
(«, PER) then it is a sum of squares, namely
and we must have 4P > rx2 since our factor is assumed irreducible. Hence the
change of sign off must be due to the change of sign of a linear factor, which is
trivially verified to be a root lying between a and b.
Lemma 2.6.
Let K be a subfieldof an ordered field E. Let rx E E be algebraic
over K, and a root ofthe polynomial
f(X) = xn + an_IXn- 1 + ... + aD
with coefficientsin K . Then Iell ~ 1 + lan-II + ... + lao I.
Proof
If [«] ~ 1, the assertion is obvious. If Irxl > 1, we express [«]" in
terms of the terms of lower degree, divide by I«]"- I, and get a proof for our
lemma.
Note that the lemma implies that an element which is algebraic over an
ordered field cannot be infinitely large with respect to that field.
Let f(X) be a polynomial with coefficients in a real closed field R, and
assume that f has no multiple roots. Let u < v be elements of R. By a Sturm
sequence for f over the interval [u, v] we shall mean a sequence of polynomials
having the following properties :

454
REAL FIELDS
XI, §2
ST 1.
The last polynomial fm is a non-zero constant.
ST 2.
There is no point x E [u, v] such that Jj(x) = Jj+ I(X) = 0 for any
value 0 ~ j ~ m - 1.
ST 3.
If x E [u, v] and Jj(x) = 0 for some j = 1,.. . , m - 1, then Jj_I(X)
and Jj+ I(X) have opposite signs.
ST 4.
We have Jj(u) =1= 0 and fiv)
=1= 0 for allj = 0, . . . , m.
For any x E [u, v] which is not a root of any polynomial Ii we denote by
ltS(x) the number of sign changes in the sequence
{f(X),I,(x), . . . ,fm(x)},
and call ltS(x) the variation of signs in the sequence.
Theorem 2.7. (Sturm's Theorem).
The numberofroots off betweenu and v
is equal to Ws(u) - Ws(v)for any Sturm sequenceS.
Proof
We observe that if OC I < OC2 <
< OCr is the ordered sequence of
roots of the polynomials Jj in [u, v] (j = 0,
, m - 1), then Ws(x) is constant
on the open intervals between these roots, by Theorem 2.5. Hence it will suffice
to prove that if there is precisely one element oc such that u < o: < v and oc is a
root of some Jj , then Ws(u) - Ws(v) = 1 if o: is a root of f, and 0 otherwise.
Suppose that oc is a root of some Jj, for 1 ~ j ~ m - 1. Then Jj_ 1(«), Jj+ I(«)
have opposite signs by ST 3, and these signs do not change when we replace oc
by u or v. Hence the variation of signs in
is the same, namely equal to 2. If a is not a root of f, we conclude that
ltS(u) = ltS(v).
If oc is a root of [, then f(u) and f(v) have opposite signs, but j'(u) and j'(v)
have the same sign, namely, the sign of j'(oc). Hence in this case,
ltS(u) = Ws(v) + 1.
This proves our theorem.
It is easy to construct a Sturm sequence for a polynomial without multiple
roots. We use the Euclidean algorithm, writing
f = e.I' - f2'
f2 = g2fl - Is,

XI, §2
REAL FIELDS
455
using!, = fl ' Sincef,!' have no common factor, the last term of this sequence
is non-zero constant. The other properties of a Sturm sequence are trivially
verified, because if two successive polynomials of the sequence have a com-
mon zero, then they must all be 0, contradicting the fact that the last one is not.
Corollary 2.8.
Let K be an ordered field, f an irreducible polynomial of
degree ~ loverK. The numberofrootsoff in tworealclosures ofK inducing
the givenordering on K is the same.
Proof
We can take v sufficiently large positive and u sufficiently large
negative in K so that all roots off and all roots of the polynomials in the Sturm
sequence lie between u and v, using Lemma 2.6. Then Ws(u) - Ws(v) is the
total number of roots off in any real closure of K inducing the given ordering.
Theorem 2.9.
Let K be an ordered field, and let R, R' be real closures of K,
whose orderings induce the given ordering on K. Then there exists a unique
isomorphism (J: R -> R' over K, and this isomorphism is order-preserving.
Proof
We first show that given a finite subextension E of Rover K, there
exists an embedding of E into R' over K. Let E = K(rx), and let
f(X) = Irrt«, K, X) .
Then f(rx) = 0 and the corollary of Sturm's Theorem (Corollary 2.8) shows that
f has a root 13 in R'. Thus there exists an isomorphism of K(rx) on K(f3) over K,
mapping rx on 13.
Let rx l , . . . , «; be the distinct roots of fin R, and let 131,... , 13m be the distinct
roots of fin R'. Say
rx I <
< «;
in the ordering of R,
131 <
< 13m
in the ordering of R'.
We contend that m = n and that we can select an embedding (J of K(rx l , . .. , rxn)
into R' such that aa, = f3j for i = 1, . . . , n. Indeed, let Yi be an element of R
such that
yf = rxj+ I
-
a,
for
i = 1, . . . , n -
1
and let EI = K(rx l , .. . , rxn ' YI' . . . , Yn-I )' By what we have seen, there exists
an embedding (J of E I into R', and then aa, +I
-
a«, is a square in R'. Hence
This proves that m ~ n. By symmetry, it follows that m = n. Furthermore,
the condition that aa, = f3i for i = I , . .. , n determines the effect of (J on

456
REAL FIELDS
XI, §2
K(rtj, . . . , rtn) . We contend that a is order-preserving. Let yE K(rtl , .. · , rtn)
and 0 < y. Let y E R be such that y2 = y. There exists an embedding of
K(rtj, . . . , rtn , YI" '" Yn- j, y)
into R' over K which must induce a on K(rt l , •• • , rtn) and is such that ay is a
square, hence > 0, as contended.
Using Zorn's lemma, it is now clear that we get an isomorphism of R onto R'
over K.
This isomorphism is order-preserving because it maps squares on
squares, thereby proving our theorem.
Proposition 2.10.
Let K be an orderedfield, K' anextension suchthat there is
no relation
n
-1 = I,airt;
j = I
with aj E K,a, > 0,and«, E K'. Let L bethefield obtainedfrom K' by adjoining
the square roots ofall positive elements ofK. Then L is real.
Proof
If not, there exists a relation of type
n
-1 = I,airt;
i = I
with a, E K, a, > 0, and a, E L. (We can take a, = 1.) Let r be the smallest
integer such that we can write such a relation with a, in a subfield of L, of type
K'(ft";, . . . , fir)
with b, E K , b, > 0. Write
with Xi' Yi E K'(vrz;;, . .. , ~) . Then
-1 = I, ai(Xj + Yijb;)2
= I, aj(x; + 2XiYjjb; + lb,).
By hypothesis, jb; is not in K'(b j , ••• , ~). Hence
contradicting the minimality of r.
Theorem 2.11.
Let K be an orderedfield. There exists a real closureR ofK
inducing the given orderingon K.

XI, §3
REAL ZEROS AND HOMOMORPHISMS
457
Proof
Take K' = K in Proposition 2.10. Then L is real, and is contained
in a real closure. Our assertion is clear.
Corollary 2.12.
Let K beanorderedfield,andK' anextensionfield. In order
that there exist an ordering on K' inducing the given ordering of K, it is
necessary and sufficient that there is no relation of type
n
-1 = L ajIXf
i= 1
with a, E K, a, > 0, and (Xj E K'.
Proof
If there is no such relation, then Proposition 2.10 states that L is
contained in a real closure, whose ordering induces an ordering on K ', and the
given ordering on K, as desired. The converse is clear.
Example.
Let Qa be the field of algebraic numbers. One sees at once that
Q admits only one ordering, the ordinary one. Hence any two real closures of Q
in Qaare isomorphic, by means of a unique isomorphism. The real closures of Q
in Qa are precisely those subfields of Qa which are of finite degree under Q".
Let K be a finite real extension of Q, contained in Qa. An element IX of K is a
sum of squares in K if and only if every conjugate of (X in the real numbers is
positive, or equivalently, if and only if every conjugate of IX in one of the real
closures of Q in Qa is positive.
Note.
The theory developed in this and the preceding section is due to Artin-
Schreier. See the bibliography at the end of the chapter.
§3.
REAL ZEROS AND HOMOMORPHISMS
Just as we developed a theory of extension of homomorphisms into an
algebraically closed field, and Hilbert's Nullstellensatz for zeros in an alge-
braically closed field, we wish to develop the theory for values in a real closed
field. One of the main theorems is the following:
Theorem 3.1.
Let k be a field, K = k(Xl" '"
xn) a finitely generated
extension. Assume that K is ordered. Let Rk be a real closure of k inducing
the sameordering on k as K. Then there exists a homomorphism
over k.

458
REAL FIELDS
As applications of Theorem 3.1, one gets :
XI, §3
Corollary 3.2.
Notation being as in the theorem, let YI" ' " Ym E k[x] and
assume
YI < Yz < .. . < Ym
is the givenordering ofK. Then one can choose qJ such that
qJYI < ... < qJYm'
Proof
Let Yi E K
3 be such that yf = Yi+ I - Yi' Then K(YI" '" Yn-I)
has an ordering inducing the given ordering on K. We apply the theorem to the
ring
Corollary 3.3.
(Artin).
Let k be a realfield admitting only one ordering.
Let f(X I' . . . , X n) E k(X) be a rationalfunction having the property that for
all (a) = (ai' . . . , an) E R~n) such that f(a) is defined, we havef(a) ~ O. Then
f(X) is a sum ofsquares in k(X).
Proof
Assume that our conclusion is false. By Corollary 2.3, there exists
an ordering of k(X) in which f is negative. Apply Corollary 3.2 to the ring
k[X I, .. . , X n, h(X)-I]
where h(X) is a polynomial denominator for f(X). We can find a homo-
morphism qJ of this ring into Rk (inducing the identity on k) such that qJ(f) < O.
But
contradiction. We let a, = qJ(XJ to conclude the proof.
Corollary 3.3 was a Hilbert problem. The proof which we shall describe for
Theorem 3.1 differs from Artin's proof of the corollary in several technical
aspects.
We shall first see how one can reduce Theorem 3.1 to the case when K has
transcendence degree lover k, and k is real closed.
Lemma 3.4.
Let R be a real closedfield and let Ro be a subfield which is
algebraically closed in R (i.e. such that every element of R not in Ro is tran-
scendental over Ro). Then Ro is real closed.
Proof
Let f(X) be an irreducible polynomial over Ro. It splits in R into
linear and quadratic factors. Its coefficients in R are algebraic over Ro, and
hence must lie in Ro. Hence f(X) is linear itself,or quadratic irreducible already
over R o. By the intermediate value theorem, we may assume that f is positive

XI, §3
REAL ZEROS AND HOMOMORPHISMS
459
definite, i.e. f(a) > 0 for all aERo. Without loss of generality, we may assume
that f (X) = X 2 + b2 for some b e Ro. Any root of thi s polynomial will bring
J=1 with it and therefore the only algebraic extension of Ro is Ro(J=l).
This proves that Ro is real clo sed.
Let RK be a real closure of K inducing the given ordering on K.
Let Ro be
the algebraic closure of kin R K • By the lemma, Ro is real clo sed.
We consider the field Ro(;'( I' . . . , xn). If we can prove our theorem for the
ring Ro[x b
. . . , xnJ, and find a homomorphism
then we let (J : Ro -> RK be an isomorphism over k (it exists by Theorem 2.9), and
we let qJ = (J
0 ljJ to solve our problem over k. This reduces our theorem to the
case when k is real closed.
Next, let F be an intermediate field, K
::::> F ::::> k, such that K is of tran-
scendence degree lover F. Again let RK be a real closure of K preserving the
ordering, and let RF be the real closure of F contained in RK • If we know our
theorem for extensions of dimension 1, then we can find a homomorphism
We note that the field k(ljJx" . . . , ljJxn) has transcendence degree
~ n -
1,
and is real , because it is contained in R F • Thus we are reduced inductively to
the case when K has dimension 1, and as we saw above, when k is real closed.
One can interpret our statement geometrically as follows. We can write
K = R(x , y) with x transcendental over R, and (x, y) satisfying some irreducible
polynomial f(X, Y) = 0 in R[X, V]. What we essentially want to prove is that
there are infinitely many points on the curve f (X, Y) = 0, with coordinates
lying in R, i.e. infinitely many real points.
The main idea is that we find some point (a, b) E R(21such that f(a, b) = 0
but D 2 f (a, b) # O. We can then use the intermediate value theorem. We see
that f(a, b + h) changes sign as h changes from a small positive to a small
negative element of R. Ifwe take a' E R close to a, then [ta', b + h) also changes
sign for small h, and hence [to', Y) ha s a zero in R for all a' sufficiently close to a.
In this way we get infinitely many zeros.
To find our point, we consider the polynomialf(x, Y)as a polynomial in one
variable Y with coefficients in R(x). Without loss of generality we may assume
that this polynomial has leading coefficient 1. We construct a Sturm sequence
for this polynomial, say
{f(x, Y), I, (x, Y), .. . , f m(x, Y)}.
Let d = deg f. If we denote by A(x) = (ad -I(x), . .. , ao(x» the coefficients of
f(x , Y), then from the Euclidean alogrithm, we see that the coefficients of the

460
REAL FIELDS
XI, §3
polynomials in the Sturm sequence can be expressed as rational functions
{GiA(x» }
in terms of ad-I(x), ... , ao(x).
Let
v(x) = 1 ± ad_l(x) ± ... ± ao(x) + s,
where s is a positive integer, and the signs are selected so that each term in this
sum gives a positive contribution. We let u(x) =
- v(x), and select s so that
neither u nor v is a root of any polynomial in the Sturm sequence for J. Now
we need a lemma.
Lemma 3.5.
Let R be a real closedfield, and {hj(x)} a finite set ofrational
functions in one variable with coefficients in R. Suppose the rational field
R(x) ordered in some way, so that each hj(x) has a sign attached to it. Then
there exist infinitely many special values c of x in R such that hj(c) is defined
and has the same sign as hj(x),for all i.
Proof.
Considering the numerators and denominators of the rational
functions, we may assume without loss of generality that the hiare polynomials.
We then write
hj(x) = an(x - A)np(x),
where the first product is extended over all roots Aof hi in R, and the second
product is over positive definite quadratic factors over R. For any ~ E R, p(~) is
positive. It suffices therefore to show that the signs of (x -
A)can be preserved
for all Aby substituting infinitely many values a for x. We order all values of A
and of x and obtain
. .. < AI < X < A2 < . ..
where possibly AI or A2 is omitted if x is larger or smaller than any A. Any value
a of x in R selected between AI and A2 will then satisfy the requirements of our
lemma.
To apply the lemma to the existence of our point, we let the rational functions
{hl(x)} consist of all coefficients ad_l(x), . . . , ao(x), all rational functions
Gv(A(x», and all values !/x, u(x», !j(x, »(x) whose variation in signs satisfied
Sturm's theorem. We then find infinitely many special values a of x in R which
preserve the signs of these rational functions. Then the polynomials f (a, Y)have
roots in R, and for all but a finite number of a, these roots have multiplicity 1.
It is then a matter of simple technique to see that for all but a finite number of
points on the curve, the elements x I ' . .. , x, lie in the local ring of the homo-
morphism R[x, y] --+ R mapping (x, y) on (a, b) such that f (a, b) = 0 but

XI, Ex
EXERCISES
461
D2f(a, b) -=f. O. (Cf. for instance the example at the end of §4, Chapter XII, and
Exercise 18 of that chapter.) One could also give direct proofs here. In this
way, we obtain homomorphisms
thereby proving Theorem 3.1 .
Theorem 3.6.
Let k be a real field, K = k(x l , • • • , xn , y) = k(x , y) a
finitely generated extension such that XI ' . . . , x, are algebraically independent
over k, and y is algebraic over k(x). Let f(X , Y) be the irreducible polynomial
in k[X, Y] such that f (x, y) = O. Let R be a real closed field containing k,
and assume that there exists (a, b) E R (n+ I) such that f (a, b) = 0 but
Then K is real.
Proof
Let t I' .. . , i, be algebraically independent over R. Inductively, we
can put an ordering on R(tl " ' " tn) such that each t j is infinitely small with
respect to R, (cf. the example in §l). Let R' be a real closure of R(t!> . . . , tn)
preserving the ordering. Let U j = a j + i, for each i = I, . . . , n . Thenf(u, b + h)
changes sign for small h positive and negative in R, and hence feu, Y) has a
root in R', say v. Since f is irreducible, the isomorphism of k(x) on k(u) sending
x, on U j extends to an embedding of k(x, y) into R', and hence K is real, as was to
be shown.
In the language of algebraic geom etr y, Theorems 3.1 and 3.6 state that the
function field of a variety over a real field k is real if and only if the variety has a
simple point in some real closure of k.
EXERCISES
I. Let rJ. be algebraic over Q and assume that Q(rJ.) is a real field. Prove that rJ. is a sum of
squares in Q(rJ.) if and only if for every embedding (J of Q(rJ.) in R we have (JrJ. > O.
2. Let F be a finite extension of Q. Let tp : F ...... Q be a Q-linear functional such that
cp(x 2) > 0 for all x E F,x =f. O. Let rJ. E F, rJ. =f. O. If cp(rJ.x 2) ~ 0 for allx E F,show that rJ. is
a sum ofsquares in F,and that F is totally real, i.e.everyembedding of F in the complex
numbers is contained in the real numbers. [Hint: Use the fact that the trace gives an
identification of F with its dual space over Q, and use the approximation theorem of
Chapter XII, §l.]

462
REAL FIELDS
XI, Ex
3. Let a ~ I ~ IIbe a real interval, and letJ(I) be a real polynomial which is positive on this
interval. Show that J(I) can be written in the form
where Q2denotes a square, and c ~ O. Hint : Split the polynomial, and use the identity :
(
(fJ
(I -
a)2(fJ - t) + (I - a)(fJ - 1)2
1 -
a)
-
t) = ---
-
-
-
-
- ---
fJ-a
Remark.
The above seemingly innocuous result is a key step in developing the
spectral theorem for bounded hermitian operators on Hilbert space. See the appendix
of [La 72] and also [La 85].
4. Show that the field of real numbers has only the identity automorphism. [Hint :Show
that an automorphism preserves the ordering.]
Real places
For the next exercises, cf. Krull [Kr 32] and Lang [La 53]. These exercises form a
connected sequence, and solutions will be found in [La 53).
5. Let K be a field and suppose that there exists a real place of K; that is, a place cp
with values in a real field L. Show that K is real.
6. Let K be an ordered real field and let F be a subfield which is maximal archimedean
in K. Show that the canonical place of K with respect to F is algebraic over F (i.e.
if II is the valuation ring of elements of K which are not infinitely large over F, and
m is its maximal ideal, then o/m is algebraic over F) .
7. Let K be an ordered field and let F be a subfield which is maximal archimedean in
K. Let K' be the real closure of K (preserving the ordering), and let F' be the real
closure of F contained in K'. Let cp be the canonical place of K' with respect to F'.
Show that cp(K') is F' -valued, and that the restriction of cp to K is equivalent to the
canonical place of Kover F.
8. Define a real field K to be quadratically closed if for all a E K either V; or
~ lies in K . The ordering of a quadratically closed real field K is then uniquely
determined, and so is the real closure of such a field, up to an isomorphism over K .
Suppose that K is quadratically closed . Let F be a subfield of K and suppose that
F is maximal archimedean in K. Let cp be a place of Kover F, with values in a
field which is algebraic over F. Show that cp is equivalent to the canonical place of
Kover F.
9. Let K be a quadratically closed real field. Let cp be a real place of K, taking its values
in a real closed field R. Let F be a maximal subfield of K such that cp is an isomorphism
on F, and identify F with cp(F). Show that such F exists and is maximal archimedean
in K. Show that the image of cp is algebraic over F, and that cp is induced by the
canonical place of Kover F .
lO. Let K be a real field and let cp be a real place of K, taking its values in a real closed
field R. Show that there is an extension of cp to an R-valued place of a real closure
of K . [Hint: first extend cp to a quadratic closure of K. Then use Exercise 5.]

XI, Ex
EXERCISES
463
II . Let K C K, C Kz be real closed fields. Suppose that K is maximal archimedean in
K I and K I is maximal archimedean in Kz. Show that K is maximal archimedean in
«;
12. Let K be a real closed field. Show that there exists a real closed field R containing
K and having arbitrarily large transcendence degree over K, and such that K is maximal
archimedean in R.
13. Let R be a real closed field. Let f l, . . . , I, be homogeneous polynomials of odd
degrees in n variables over R. If n > r, show that these polynomials have a non-
trivial common zero in R. (Comments :If the forms are generic (in the sense of Chapter
IX) , and n = r + I, it is a theorem of Bezout that in the algebraic closure Ra the
forms have exactly d, .. . dm common zeros , where d, is the degree of I; You may
assume this to prove the result as stated . If you want to see this worked out , see
[La 53), Theorem 15. Compare with Exercise 3 of Chapter IX.)
Bibliography
[Ar 24]
E. ARTIN, Kennzeichnung des Korpers der reellen algebraischen Zahlen, Abh .
Math. Sem. Hansischen Univ. 3 (1924), pp. 319-323
[Ar 27]
E. ARTIN . Uber die Zerlegung definiter Funktionen in Quadrate, Abh . Math.
Sem. Hansischen Univ. 5 (1927) , pp. 100-115
[ArS 27)
E. ARTIN and E. SCHREIER, Algebraische Konstruktion reeller Korper, Abh .
Math. Sem. Hansischen Univ. 5 (1927), pp. 85-99
[Kr 32]
W. KRULL, Allgemeine Bewertungstheorie, J. reine angew . Math . (1932),
pp. 169-196
[La 53]
S. LANG, The theory of real places , Ann . Math . 57 No.2 (1953) , pp. 378-
391
[La 72]
S. LANG, Differential manifolds, Addison-Wesley, 1972; reprinted by Springer
Verlag, 1985; superceded by [La 99a].
[La 85]
S. LANG, Real and functional analysis. Third edition, Springer Verlag,
1993
[La 99a]
S. LANG, Fundamentals of Differential Geometry, Springer Verlag, 1999

CHAPTER XII
Absolute Values
§1.
DEFINITIONS, DEPENDENCE, AND
INDEPENDENCE
Let K be a field. An absolute value v on K is a real-valued function x f---+ Ix Iv
on K satisfying the following three properties :
AV 1.
We have Ixl v ~ 0 for all x EK , and [x], = 0 if and only if x = o.
AV 2.
For all x, yE K, we have Ixylv= Ixlv lylv'
AV 3.
For all x, yE K , we have [x + ylv~ [x] , + IYlv'
If instead of AV 3 the absolute value satisfies the stronger condition
AV 4.
[x + ylv~ max(lxlv, Iylv)
then we shall say that it is a valuation, or that it is non-archimedean.
The absolute value which is such that Ix], = 1 for all x
=1= 0 is called trivial.
We shall write Ix Iinstead of Ix Ivif we deal with just one fixed absolute value .
We also refer to v as the absolute value.
An absolute value of K defines a metric. The distance between two elements
x, y of K in this metric is Ix - y I. Thus an absolute value defines a topology on
K . Two absolute values are called dependent if they define the same topology.
If they do not , they are called independent.
We observe that III = 11 21 = I(-1)2 1= 111 2 whence
111=1-11=1.
Also, I- x I = Ix Ifor all x EK, and IX- I I = Ix 1- 1 for x
=1= o.
465
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

466
ABSOLUTE VALUES
XII, §1
Proposition 1.1.
Let I II and I 12be non-trivialabsolute values on afield K.
They are dependent if and only if the relation
implies Ix 12 < 1. If they are dependent, then there exists a number A > 0
such that [x], =
I xl~ for a ll x E K.
Proof
If the two absolute values are dependent, then our condition is
satisfied, because the set of x E K such that Ix I, < I is the same as the set such
that lim x" = 0 for n -+ co. Conversely, assume the condition satisfied. Then
[xI, > I implies [x Iz > I since Ix-'I, < 1. By hypothesis, there exists an
element xoEK such that IXo/1> 1. Let a = IXo/ I and b = IXoI2 . Let
A= log b.
log a
Let x E K, x # o. Then IxI, = IXoI~ for some number IX. Ifm,nare integers such
that min> IXand n > 0, we have
Ixll > IXoIT/
n
whence
and thus
Ix
nlxO'I2 < 1.
This implies that Ix 12 < IXoli/n. Hence
Similarly, one proves the reverse inequality, and thus one gets
for all x E K, x # o. The assertion of the proposition is now obvious, i.e.
Ixl2 = Ix11·
We shall give some examples of absolute values.
Consider first the rational numbers. We have the ordinary absolute value
such that 1m 1 = m for any positive integer m.
For each prime number p,we have the p-adic absolute value vp , defined by the
formula
Ip'mlnlp = lip'

XII, §1
DEFINITIONS, DEPENDENCE, AND INDEPENDENCE
467
where r is an integer, and m, II are integers i= 0, not divisible by p. One sees at
once that the p-adic absolute value is non-archimedean.
One can give a similar definition of a valuation for any field K which is the
quotient field of a principal ring. For instance, let K = k(t) where k is a field
and t is a variable over k. We have a valuation vp for each irreducible polynomial
p(t) in k[t] ,defined as for the rational numbers, but there is no way of normalizing
it in a natural way. Thus we select a number c with 0 < c < I and for any
rational function p'fto where J, g are polynomials not divisible by p, we define
Ip'f/g Ip = cr.
The various choices of the constant c give rise to dependent valuations.
Any subfield of the complex numbers (or real numbers) has an absolute
value, induced by the ordinary absolute value on the complex numbers. We shall
see later how to obtain absolute values on certain fields by embedding them into
others which are already endowed with natural absolute values.
Suppose that we have all absolute value 011 a field which is bounded on the
prime ring (i.e. the integers Z ifthe characteristic is 0, or the integers mod p if
the characteristicis p). Then the absolute valueisnecessarilynon-archimedean.
Proof
For any elements x, y and any positive integer n, we have
j(x + y)" 1~ L IC)xvy"- Vl ~ ne maxt]x ], lyl)"·
Taking n-th roots and letting n go to infinity proves our assertion. We note that
this is always the case in characteristic> 0 because the prime ring is finite!
If the absolute value is archimedean, then we refer the reader to any other
book in which there is a discussion of absolute values for a proof of the fact that
it is dependent on the ordinary absolute value. This fact is essentially useless
(and is never used in the sequel), because we always start with a concretely given
set of absolute values on fields which interest us.
In Proposition 1.1 we derived a strong condition on dependent absolute
values. We shall now derive a condition on independent ones.
Theorem 1.2.
(Approximation Theorem).
(Artin-Whaples).
Let K be
afield and I 11,"" I Is non-trivial pairwiseindependentabsolute valueson K.
Let XI' . . . , Xs be elements ofK, and e > O. Then there exists X E K such that
Jor all i.

468
ABSOLUTE VALUES
XII, §2
Proof
Consider first two of our absolute values, say VI and V2 . By hypo-
thesis we can find IX E K such that IIX II < I and IIXIs ~ 1. Similarly, we can find
PE K such that IPII ~ 1and IPls< 1. Put y = pjIX. Then lyll > 1and Iy ls < 1.
We shall now prove that there exists zE K such that IzII > 1 and IzIj < 1
for j = 2, .. . , s. We prove this by induction, the case s = 2 having just been
pro ved. Suppose we have found z E K satisfying
[z], > 1
and
Izlj < 1
for
j = 2, .. . , s -
1.
If [z ], ~ 1 then the element zny for large n will satisfy our requirements.
If IzIs> 1, then the sequence
zn
t
= --
n
1 + z"
tends to 1at V I and VS' and tends to 0at vj (j = 2, . .. , s - 1). For large n,it is then
clear that tny satisfies our requirements.
Using the element z that we have just constructed, we see that the sequence
znj{l + z") tends to 1 at VI and to 0 at Vj for j = 2, .. . , s. For each i = 1, . .. , s
we can therefore construct an element z, which is very close to 1 at Vj and very
close to 0 at Vj (j -j16 i). The element
then satisfies the requirement of the theorem.
§2.
COMPLETIONS
Let K be a field with a non-trivial absolute value v, which will remain fixed
throughout this section. One can then define in the usual manner the notion of a
Cauchy sequence. It is a sequence {xn} of elements in K such that, given e > 0,
there exists an integer N such that for all n, m > N we have
We say that K is complete if every Cauchy sequence converges.
Proposition 2.1.
There exists a pair (K v ' i) consisting ofafield K v ' complete
under an absolute value, and an embedding i: K -+ K ; such that the absolute
value on K is induced by that ofK ; (i.e. Ix Iv= IixIfor x E K), and such that iK
is dense in K v • If (K~ , i') is another such pair, then there ex ists a unique

XII, §2
COMPLETIONS
469
isomorphism sp :K; -+ K~ preserving the absolute values, and making the
following diagram commutative :
\1
K
Proof
The uniqueness is obvious. One proves the existence in the well-
known manner, which we shall now recall briefly, leaving the details to the reader.
The Cauchy sequences form a ring, addition and multiplication being taken
componentwise.
One defines a null sequence to be a sequence {x n} such that lim x; = O. The
null sequences form an ideal in the ring of Cauchy sequences, and in fact form a
maximal ideal. (If a Cauchy sequence is not a null sequence, then it stays away
from 0 for all n sufficiently large, and one can then take the inverse of almost all
its terms. Up to a finite number of terms, one then gets again a Cauchy sequence.)
The residue class field of Cauchy sequences modulo null sequences is the
field K v • We embed K in K; " on the diagonal", i.e. send x E K on the sequence
(x, x, X, . • .).
We extend the absolute value of K to K; by continuity. If {x n} is a Cauchy
sequence, representing an element ~ in K v, we define I~ I = limIx, I. It is easily
proved that this yields an absolute value (independent of the choice of repre-
sentative sequence {xn } for ~ ), and this absolute value induces the given one on K.
Finally, one proves that K; is complete. Let
{ ~n} be a Cauchy sequence in
K v • For each n, we can find an element x, E K such that I~ n - x, I < l in. Then
one verifies immediately that {xn } is a Cauchy sequence in K. We let ~ be its
limit in K v. By a three-s argument, one sees that
{~n} converges to
~, thus
proving the completeness.
A pair (K v , i) as in Proposition 2.1 may be called a completion of K . The
standard pair obtained by the preceding construction could be called the
completion of K .
Let K have a non-trivial archimedean absolute value v. Ifone knows that the
restriction of v to the rationals is dependent on the ordinary absolute value, then
the completion K ; is a complete field, containing the completion of Q as a
closed subfield, i.e. containing the real numbers R as a closed subfield. It will be
worthwhile to state the theorem of Gelfand-Mazur concerning the structure of
such fields. First we define the notion of normed vector space.
Let K be a field with a non-trivial absolute value, and let E be a vector space
over K. By a norm on E (compatible with the absolute value of K) we shall
mean a function ~ -+ I~ Iof E into the real numbers such that:
NO 1. I~ I ~ 0 for all ~ E E, and = 0 if and only if ~ = O.

470
ABSOLUTE VALUES
NO 2.
For all x E K and ~ E E we have
Ix~ 1
Ixll~l .
NO 3.
If ~ , ~' E E then I~ + ~'I ~ I~ I +
I ~ ' I·
XII, §2
Two norms I II and I b are called equivalent if there exist numbers CI, C2 > 0
such that for all ~ E E we have
Suppose that E is finite dimensional, and let W I' .. . , £On be a basis of E
over K . If we write an element
in terms of this basis, with Xi E K, then we can define a norm by putting
I ~I = maxlx.].
i
The three properties defining a norm are trivially satisfied.
Proposition 2.2.
Let K be a complete field under a non-trivial absolute value,
and let E be a fin ite-dimensional space over K.
Th en any two norms on E
(compatible with the given absolute value on K) are equivalent.
Proof
We shall first prove that the topology on E is that of a product space,
i.e. if W I' . . . , co; is a basis of E over K , then a sequence
x!V) EK,
is a Cauch y sequence in E only if each one of the n sequences xlV) is a Cauchy
sequence in K . We do this by induction on n. It is obvious for n = 1. Assume
n ~ 2. We consider a sequence as above, and without loss of generality, we may
assume that it converges to O. (If necessary, consider ¢(V) -
¢(Jl) for v, f1 -> 00.)
We must then show that the sequences of the coefficients converge to 0 also.
If this is not the case, then there exists a number a > 0 such that we have for
some j, say j = 1,
Ix<Y>1 > a
for arbitrarily large v. Thus for a subsequence of (v), ¢(V)/x\V)converges to 0, and
we can write
We let 11(V) be the right-hand side of this equation. Then the subsequence 11(V)
converges (according to the left-hand side of our equation). By induction, we

XII, §2
COMPLETIONS
471
conclude that its coefficients in terms of wz, .. ., co; also converge in K , say to
Yz, ""
Yn' Taking the limit, we get
contradicting the linear independence of the W i '
We must finally see that two norms inducing the same topology are equivalent.
Let I II and 1 Iz be these norms. There exists a number C > °such that for any
~ E E we have
I ~II ~ C
implies
1~lz ~ 1.
Let a E K be such that°<
1a 1 < 1. For every ~ E E there exists a unique integer
s such that
Clal <
las~11 s c.
Hence IaS~ Iz ~ 1 whence we get at once
The other inequality follows by symmetry, with a similar constant.
Theorem 2.3.
(Gelfand-Mazur) . Let A be a commutative algebra over the
real numbers, and assume that A contains an element j such that j2 = -1 . Let
C = R + Rj. Assume that A is normed (as a vector space over R), and that
Ixyl ~ IxllYI for all x, YEA . Given Xo E A, Xo =1= 0, there exists an element
c E C such that Xo - c is not invertible in A.
Proof
(Tornheim).
Assume that
Xo -
z is invertible for
all
z E C.
Consider the mapping f :C --+ A defined by
It is easily verified (as usual) that taking inverses is a continuous operation.
Hence j is continuous, and for z #-°we have
j(z) = Z-I(XOZ- 1 _
1)-1 = ~(_1_).
z
Xo _ 1
z
From this we see thatj(z) approaches°when z goes to infinity (in C). Hence the
map z ~ /j(z)/ is a continuous map ofC into the real numbers ~ 0, is bounded,
and is small outside some large circle. Hence it has a maximum, say M. Let D

472
ABSOLUTE VALUES
XII, §2
be the set of elements Z E C such that If(z)1 = M. Then D is not empty; D is
bounded and closed. We shall prove that D is open, hence a contradiction.
Let Co be a point of D, which, after a translation, we may assume to be the
origin. We shall see that ifr is real> 0 and small, then all points on the circle of
radius r lie in D. Indeed, consider the sum
1
n
1
Sen) = - L
k
n k = 1 Xo - w r
where to is a primitive n-th root of unity. Taking formally the logarithmic
n
derivative of X" - r" = TI (X - wkr) shows that
k=1
nxn-I
n
1
Xn -
rn = k~1 X - wkr'
and hence, dividing by n, and by X"" I, and substituting Xo for X; we obtain
1
Sen) = Xo _ r(r/xo)" I'
If r is small (say Ir/xo I < 1), then we see that
lim IS(n)I = I~I = M.
n- 00
Xo
Suppose that there exists a complex number Aof absolute value 1 such that
I
1 I<M.
Xo -
Ar
Then there exists an interval on the unit circle near A, and there exists E > 0 such
that for all roots of unity' lying in this interval, we have
I
1 , 1< M -
E.
Xo -
r
(This is true by continuity.) Let us take n very large. Let b; be the number of
n-th roots of unity lying in our interval. Then b.fn is approximately equal to the
length of the interval (times 2n): We can express Sen) as a sum
1[1
1 ]
Sen) = - LI
k + Ln
k'
n
Xo -
co r
Xo -
to r

XII, §2
COMPLETIONS
473
the first sum LI being taken over those roots of unity (J} lying in our interval, and
the second sum being taken over the others. Each term in the second sum has
norm ~ M because M is a maximum. Hence we obtain the estimate
1
IS(n)1 ~ - [ILd + ILul]
n
1
~ - (bn(M - E) + (n - bn)M)
n
bn
::;M- -
L
-
n
This contradicts the fact that the limit of IS(n)1 is equal to M.
Corollary 2.4.
Let K be a field, which is an extension oj R, and has an
absolute value extending the ordinary absolute value on R. Then K = R or
K=C.
Proof
Assume first that K contains C. Then the assumption that K is a
field and Theorem 2.3 imply that K = C.
If K does not contain C, in other words, does not contain a square root of
-1, we let L = K(j) where/ = -1. We define a norm on L (as an R-space) by
putting
Ix + yjI = IxI + IyI
for x, y E K. This clearly makes L into a normed R-space. Furthermore, if
z = x + yj and Z' = x' + y'j are in L, then
1=='1 = [xx' - yy' ! + [xy' + x'y]
~ [xx'] + !yy'l + [xj.'] + Ix'YI
~ IxIIx'I + Iy II y' I + IxIIy'I + Ix'II yI
~ (IxI + IyI)(Ix'I + Iy'I)
~ 1=11='1,
and we can therefore apply Theorem 2.3 again to conclude the proof.
As an important application of Proposition 2.2, we have :
Proposition 2.5.
Let K be complete with respect to a nontrivial absolute
value v. IJE is any algebraic extension ojK, then v hasa unique extensionto
E. IJ E isfinite over K, then E is complete.
Proof
In the archimedean case, the existence is obvious since we deal
with the real and complex numbers. In the non-archimedean case, we postpone

474
ABSOLUTE VALUES
XII, §2
the existence proof to a later section. It uses entirely different ideas from the
present ones. As to uniqueness, we may assume that E is finite over K.
By
Proposition 2.2, an extension of v to E defines the same topology as the max
norm obtained in terms of a basis as above. Given a Cauchy sequence
~(v) in E,
the n sequences {x.} (i = 1, . . . , n) must be Cauchy sequences in K by the
definition of the max norm. If {xv;} converges to an element z, in K, then it
is clear that the sequence
~(v) converges to ZlW l + ... + ZnWn'
Hence E is
complete.
Furthermore, since any two extensions of v to E are equivalent,
we can apply Proposition 1.1, and we see that we must have A. = 1, since the
extensions induce the same absolute value von K. This proves what we want.
From the uniqueness we can get an explicit determination of the absolute
value on an algebraic extension of K. Observe first that ifE isa normal extension
of K, and a is an automorphism of E over K , then the function
XH [rrx]
is an absolute value on E extending that of K. Hence we must have
[ex] = [x]
for all x E E. If E is algebraic over K, and a is an embedding of E over K in K",
then the same conclusion remains valid, as one sees immediately by embedding
E in a normal extension of K. In particular, if a is algebraic over K, of degree n,
and ifal' . .. , rxn are its conjugates (counting multiplicities, equal to the degree of
inseparability), then all the absolute values Irxi I are equal.
Denoting by N
the norm from K(rx) to K, we see that
IN(rx) I = Io: In,
and taking the n-th root, we get:
Proposition 2.6.
Let K be complete with respect to a non-trivial absolute
value. Let o. be algebraic over K, and let N be the normfrom K(rx) to K. Let
n = [K(rx): K]. Then
In the special case of the complex numbers over the real numbers, we can
write rx = a + bi with a, b E R, and we see that the formula of Proposition 2.6 is
a generalization of the formula for the absolute value of a complex number,
rx = (a2 + b2 ) 1/ 2,
since a2 + b2 is none other than the norm of rx from C to R.

XII, §2
COMPLETIONS
475
Comments and examples.
The process of completion is widespread in
mathematics. The first example occurs in getting the real numbers from the
rational numbers, with the added property of ordering. I carry this process out
in full in [La 90a], Chapter IX, §3. In all other examples I know, the ordering
property does not intervene. We have seen examples of completions of fields in
this chapter, especially with the p-adic absolute values which are far away from
ordering the field. But the real numbers are nevertheless needed as the range of
values of absolute values, or more generally norms .
In analysis, one completes various spaces with various norms . Let V be a
vector space over the complex numbers, say . For many applications, one must
also deal with a seminorm, which satisfies the same conditions except that in
NO 1 we require only that II ~II ~ O. We allow II ~II = 0 even if ~ * O.
One may then form the space of Cauchy sequences, the subspace of null
sequences, and the factor space V. The seminorm can be extended to a semi norm
on V by continuity, and this extension actually turns out to be a norm . It is a
general fact that V is then complete under this extension. A Banach space is a
complete normed vector space .
Example.
Let V be the vector space of step functions on R, a step function
being a complex valued function which is a finite sum of characteristic functions
of intervals (closed, open, or semiclosed, i.e. the intervals mayor may not
contain their endpoints). For f E V we define the Ll-semfnorm by
IIflll = J If(x)!dx.
R
The completion of V with respect to this seminorm is defined to be LI(R). One
then wants to get a better idea of what elements of L1(R) look like. It is a simple
lemma that given an L1-Cauchy sequence in V, and given e > 0, there exists a
subsequence which converges uniformly except on a set of measure less than e.
Thus elements of LI(R) can be identified with pointwise limits of LI-Cauchy
sequences in V. The reader will find details carried out in [La 85].
Analysts use other norms or seminorms, of course, and other spaces, such
as the space of Coo functions on R with compact support, and norms which may
bound the derivatives. There is no end to the possible variations.
Theorem 2.3 and Corollary 2.4 are also used in the theory of Banach algebras,
representing a certain type of Banach algebra as the algebra of continuous func-
tions on a compact space, with the Gelfand-Mazur and Gelfand-Naimark theo-
rems . Cf. [Ri 60] and [Ru 73] .
Arithmetic example.
For p-adic Banach spaces in connection with the
number theoretic work of Dwork, see for instance Serre [Se 62], or also
[La 90b] , Chapter 15.
In this book we limit ourselves to complete fields and their finite extensions.

476
ABSOLUTE VALUES
Bibliography
XII, §3
[La 85]
[La 90a)
[La 90b]
[Ri 60]
[Ru 73]
[Se 62]
S. LANG, Real and Functional Analysis, Springer Verlag, 1993
S. LANG, Undergraduate Algebra, Second Edition, Springer Verlag, 1990
S. LANG, Cyclotomic Fields I and II, Springer Verlag 1990 (combined from
the first editions, 1978 and 1980)
C. RICKART, Banach Algebras, Van Nostrand (1960), Theorems 1.7 .1 and
4.2.2.
W. RUDIN, Functional Analysis, McGraw Hill (1973) Theorems 10.14 and
1l.l8.
1. P. SERRE, Endomorphismes completement continus des espaces de Banach
p-adiques, Pub. Math. IHES 12 (1962), pp. 69-85
§3.
FINITE EXTENSIONS
Throughout this section we shall deal with a field K having a non-trivial
absolute value v.
We wish to describe how this absolute value extends to finite extensions of K.
IfE is an extension of K and wis an absolute value on E extending v,then we shall
write w]»,
If we let K; be the completion, we know that v can be extended to K v, and
then uniquely to its algebraic closure K ~ . If E is a finite extension of K , or even
an algebraic one, then we can extend v to E by embedding E in K~ by an iso-
morphism over K, and taking the induced absolute value on E. We shall now
prove that every extension of v can be obtained in this manner.
Proposition 3.1.
Let E be afinite extension ofK. Let w be an absolute value
on E extending v, and let Ew be the completion. Let Kw be the closure of Kin
Ew and identify E in Ew- Then Ew = EKw (the composite field).
Proof
We observe that K; is a completion of K, and that the-composite
field EK w is algebraic over K; and therefore complete by Proposition 2.5. Since
it contains E, it follows that E is dense in it, and hence that E; = EK w •
If we start with an embedding a: E --+ K~ (always assumed to be over K),
then we know again by Proposition 2.5 that aE· K ; is complete. Thus this
construction and the construction of the proposition are essentially the same, up
to an isomorphism. In the future, we take the embedding point of view. We
must now determine when two embeddings give us the same absolute value on E.
Given two embeddings a, T: E --+ K:., we shall say that they are conjugate
over K; if there exists an automorphism ;, of K ~ over K; such that a = A.T. We
see that actually A. is determined by its effect on rE, or iE . K v •

XII, §3
FINITE EXTENSIONS
477
Proposition 3.2.
Let E be an algebraic extension of K. Two embeddings
(J, r : E ~ K ~ give rise to the same absolute value on E if and only if they are
conjugateover K".
Proof
Suppose they are conjugate over K". Then the uniqueness of the
extension of the absolute value from K" to K ~ guarantees that the induced
absolute values on E are equal.
Conversely, suppose this is the case. Let
A:rE ~ (JE be an isomorphism over K. We shall prove that Aextends to an
isomorphism of rE · K" onto (JE · K" over K". Since iE is dense in rE · K v,
an element x E rE · K; can be written
x = lim rx,
with x, E E. Since the absolute values induced by (J and r on E coincide, it
follows that the sequence Arxn = (JXn converges to an element of (JE . K" which
we denote by AX. One then verifies immediately that AX is independent of the
particular sequence rx, used, and that the map A:rE . K; ~ (JE . K; is an iso-
morphism, which clearly leaves K; fixed. This proves our proposition.
In view of the previous two propositions, if w is an extension of v to a finite
extension E of K, then we may identify E; and a composite extension EK v of E
and Kv • If N = [E :K] is finite, then we shall call
the local degree.
Proposition 3.3.
Let E beafinite separable extensionofK, ofdegree N. Then
Proof
We can write E = K(a) for a single element ex.
Let f(X) be its
irreducible polynomial over K . Then over K v , we have a decomposition
f(X) = fl(X)" , fr(X)
into irreducible factors h(X). They all appear with multiplicity 1 according to
our hypothesis of separability. The embeddings of E into K~ correspond to the
maps of ex onto the roots of the h.Two embeddings are conjugate if and only if
they map ex onto roots of the same polynomial k
On the other hand, it is clear
that the local degree in each case is precisely the degree of h. This proves our
proposition.
Proposition 3.4.
Let E be afinite extension ofK. Then
L[Ew : K v] ~ [E :K].
w]u

478
ABSOLUTE VALUES
XII, §3
IfE is purelyinseparable over K, then thereexists onlyoneabsolutevaluew on
E extending v.
Proof
Let us first prove the second statement. If E is purely inseparable
over K, and p' is its inseparable degree, then apr E K for every a in E. Hence vhas
a unique extension to E. Consider now the general case of a finite extension, and
let F = tr«. Then F is separable over K and E is purely inseparable over F.
By the preceding proposition,
L [Fw :Kvl = [F:K],
wlV
and for each w, we have [Ew : Fw] ~ [E :F]. From this our inequality in the
statement of the proposition is obvious.
Whenever vis an absolute value on K such that for any finite extension E of K
we have [E : K] = L [E w : K v] we shall say that v is wellbehaved. Suppose we
wlv
have a tower of finite extensions, L ::::l E ::::l K. Let w range over the absolute
values of E extending v, and u over those of L extending v. If uIw then L;
contains Ew . Thus we have :
I [Lu : KvJ = I I [L u : Ew] [Ew : K v]
ulv
wlv ulw
= I [Ew : K v] I [Lu : Ew]
wlv
ulw
~ L [Ew : Kv] [L : E]
w] u
~ [E :K][L:E].
From this we immediately see that if v is well behaved, E finite over K, and w
extends v on E, then w is well behaved (we must have an equality everywhere).
Let E be a finite extension of K . Let pr be its inseparable degree. We recall
that the norm of an element a E K is given by the formula
where (J ranges over all distinct isomorphisms of E over K (into a given algebraic
closure).
If w is an absolute value extending v on E, then the norm from E; to K; will
be called the localnorm.
Replacing the above product by a sum, we get the trace, and the local trace.
We abbreviate the trace by Tr.
Proposition 3.8.
Let E be afinite extension of K, and assume that v is well

XII, §3
behaved. Let o: E E. Then:
FINITE EXTENSIONS
479
N~«('f.) = TI N~:«('f.)
wlv
Tr~«('f.) = L Tr~:(IX)
wlu
Proof
Suppose first that E = K(IX), and let f(X) be the irreducible poly-
nomial of IX over K . If we factor f(X) into irreducible terms over K v , then
f(X) = fl(X) " , j,.(X)
where each j;(X) is irreducible, and the j; are distinct because of our hypothesis
that v is well behaved. The norm N~(IX) is equal to (_l)degf times the constant
term of f, and similarly for each j; . Since the constant term of f is equal to the
product of the constant terms of the j; , we get the first part of the proposition.
The statement for the trace follows by looking at the penultimate coefficient off
and each j; .
If E is not equal to K(IX), then we simply use the transitivity of the norm and
trace. We leave the details to the reader.
One can also argue directly on the embeddings. Let aI' . . . , am be the distinct
embeddings of E into
K ~ over K, and let pr be the inseparable degree of E
over K . The inseparable degree of aE . K ; over K; for any a is at most equal
to p",
If we separate a l , . .. , am into distinct conjugacy classes over Kv'
then from our hypothesis that v is well behaved, we conclude at once that the
inseparable degree of a.E :K; over K; must be equal to pr also, for each i.
Thus the formula giving the norm as a product over conjugates with multi-
plicity pr breaks up into a product of factors corresponding to the conjugacy
classes over K v •
Taking into account Proposition 2.6, we have :
Proposition 3.6.
Let K have a well-behaved absolute value v. Let E be a
finite extension ofK , and IX E E. Let
for each absolute valuew on E extending v. Then
TI
I IXI~~ =
IN~(IX)l v'
wlv

480
ABSOLUTE VALUES
§4.
VALUATIONS
XII, §4
In this section, we shall obtain, among other things, the existence theorem
concerning the possibility of extending non-archimedean absolute values to
algebraic extensions. We introduce first a generalization of the notion of non-
archimedean absolute value.
Let I' be a multiplicative commutative group. We shall say that an ordering
is defined in r if we are given a subset S of r closed under multiplication such
that r is the disjoint union of S, the unit element 1,and the set s:' consisting of
all inverses of elements of S.
If ex, fl E r we define ex < fl to mean exp-t E S. We have ex < 1 if and only if
ex E S. One easily verifies the following properties of the relation <:
1. For ex, fl E r we have ex < fl, or ex = fl, or fl < ex, and these possibilities
are mutually exclusive.
2. ex < fl implies exy < fly for any y E r.
3. ex < fl and fl < y implies ex < y.
(Conversely, a relation satisfying the three properties gives rise to a subset S
consisting of all elements < 1. However, we don't need this fact in the sequel.)
It is convenient to attach to an ordered group formally an extra element 0,
such that Oex = 0, and°< ex for all ex E r. The ordered group is then analogous
to the multiplicative group of positive reals, except that there may be non-
archimedean ordering.
If ex E rand n is an integer ¥- 0,such that exn = 1,then ex = 1. This follows at
once from the assumption that S is closed under multiplication and does not
contain 1. In particular, the map ex ~ o" is injective.
Let K be a field. By a valuation of K we shall mean a map x ~ Ix Iof K into
an ordered group F, together with the extra element 0, such that :
VAL 1.
Ix I =°if and only if x = 0.
VAL 2.
Ixyl = Ixllyl for all x, y E K .
VAL 3.
[x + yl ~ maxr]x], Iyl)·
We see that a valuation gives rise to a homomorphism of the multiplicative
group K* into r . The valuation is called trivial if it maps K* on I. If the map
giving the valuation is not surjective, then its image is an ordered subgroup of F,
and by taking its restriction to this image, we obtain a valuation onto an ordered
group, called the value group.
We shall denote valuations also by v. If VI ' V2 are two valuations of K, we
shall say that they are equivalent ifthere exists an order-preserving isomorphism
A. of the image of VI onto the image of V2 such that

XII, §4
VALUATIONS
481
for all x E K. (We agree that A(O) = 0.)
Valuations have additional properties, like absolute values. For instance,
III = 1because III = 111 2 • Furthermore,
I± x] = [x]
for all x E K . Proof obvious. Also, if Ix I < IyI then
[x + y l = Iyl·
To see this, note that under our hypothesis, we have
Iyl = Iy + x -
x] ~ maxt lj: + x ], [xl) = [x + y l ~ maxt[x], IYI) = Iyl·
Finally, in a sum
XI + ... + X n = 0,
at least two elements of the sum have the same value. This is an immediate
consequence of the preceding remark.
Let K be a field. A subring 0 of K is called a valuation ring if it has the
property that for any x E K we have x EO or X-I EO.
We shall now see that valuation rings give rise to valuations. Let 0 be a
valuation ring of K and let V be the group of units of o. We contend that 0 is a
local ring. Indeed suppose that x, YEO are not units. Say x/y EO. Then
1 + x/y = (x + y)/yEO .
Ifx + y were a unit then l/y E 0, contradicting the assumption that y is not a unit.
Hence x + y is not a unit. One sees trivially that for z E 0 , zx is not a unit. Hence
the nonunits form an ideal, which must therefore be the unique maximal ideal
of o.
Let m be the maximal ideal of 0 and let m* be the multiplicative system of
nonzero elements of m. Then
K* = m* u V u m* -l
is the disjoint union ofm*, V, and m* -l. The factor group K* /V can now be
given an ordering. If x E K*, we denote the coset xV by [x] . We put 101 = 0.
We define [x] < 1 (i.e.jx] ES) if and only if x Em*. Our set S is clearly closed
under multiplication, and if we let r = K* /V then r is the disjoint union of S,
1,S- I . In this way we obtain a valuation of K.
We note that if x, y E K and x, y i= 0, then
[x] < IYI¢>lx/YI < 1¢>x/yEm*.
Conversely, given a valuation of K into an ordered group we let 0 be the
subset of K consisting of all x such that Ix I < 1. It follows at once from the

482
ABSOLUTE VALUES
XII.§4
axioms of a valuation that 0 is a ring. If Ix I < I then IX -I I > I so that X - I is
not in o. If Ix I = I then IX-I I = 1. We see that 0 is a valuation ring, whose
maximal ideal consists of those elements x with Ix I < I and whose units consist
ofthose elements x with Ix I = 1. The reader will immediately verify that there is
a bijection between valuation rings of K and equivalence classes of valuations.
The extension theorem for places and valuation rings in Chapter VII now
gives us immediately the extension theorem for valuations.
Theorem 4.1.
Let K be a subfieldofafield L. Then a valuation on K has an
extension to a valuation on L.
Proof
Let 0 be the valuation ring on K corresponding to the given valua-
tion. Let q> : 0 -4 o/m be the canonical homomorphism on the residue class field,
and extend q> to a homomorphism of a valuation ring D of L as in §3 of Chapter
VII. Let we be the maximal ideal of cO. Since we n 0 contains m but does not
contain I , it follows that we n 0 = m. Let V' be the group of units of D. Then
V' n K = V is the group of units of o. Hence we have a canonical injection
K*IV -4 L*IV'
which is immediately verified to be order-preserving.
Identifying K*IV in
L*IV' we have obtained an extension of our valuation of K to a valuation of L.
Ofcourse, when we deal with absolute values, we require that the value group
be a subgroup of the multiplicative reals. Thus we must still prove something
about the nature of the value group L*IV', whenever L is algebraic over K.
Proposition 4.2.
Let L be a finite extension of K , of degree n. Let w be a
valuation of L with value group I", Let r be the value group of K . Then
(r': r) ~ n.
Proof
Let Yl' . .. , Yr be elements of L whose values represent distinct
cosets ofr in I". We shall prove that the Yj are linearly independent over K. In
a relation alYl + ... + arYr = 0 with ajE K, aj =I 0 two terms must have the
same value, say laiyd = lajYjl with i =I j, and hence
This contradicts the assumption that the values ofYi' Yj (i =Ij) represent distinct
cosets of r in I", and proves our proposition.
Corollary 4.3.
There exists an integer e ~ I such that the map y H t
inducesan injective homomorphism of I" into r.
Proof
Take e to be the index (I" : F).

XII, §4
VALUATIONS
483
Corollary 4.4.
If K is a field with a valuation v whose value group is an
ordered subgroup of the ordered group of positive real numbers, and if L is an
algebraic extension of K, then there exists an extension ofv to L whose value
groupis also an ordered subgroup ofthe positive reals.
Proof
We know that we can extend v to a valuation w of L with some value
group I", and the value group r of v can be identified with a subgroup of R +.
By Corollary 4.3, every element of I" has finite period modulo r . Since every
element of R + has a unique e-th root for every integer e ~ 1, we can find in an
obvious wayan order-preserving embedding of I" into R + which induces the
identity on r. In this way we get our extension of v to an absolute value on L.
Corollary 4.5.
If L isfinite over K, and if r is infinitecyclic, then I" is also
infinitecyclic.
Proof
Use Corollary 4.3 and the fact that a subgroup of a cyclic group is
cyclic.
We shall now strengthen our preceding proposition to a slightly stronger one.
We call (I" : F) the ramification index.
Proposition 4.6.
Let L beafinite extensionofdegree nofafield K, andlet ,0
bea valuation ringof L. Let Wl be its maximalideal, let 0 = ,0 n K, andlet m
be the maximal ideal of 0, i.e. m = Wl n o. Then the residue class degree
['o/Wl :o/m] isfinite. Ifwe denoteit by f, andife istheramification index,then
'" <
eJ = n.
Proof
Let YI" ' " Ye be representatives in L* of distinct cosets of r'/r and
let ZI' . . . , z, be elements of ,0 whose residue classes mod Wl are linearly inde-
pendent over o/m. Consider a relation
I
aijZjYi = 0
i.j
with a ij E K , not all a ij = O. In an inner sum
sI
aijZj,
j= 1
divide by the coefficient a.; having the biggest valuation. We obtain a linear
combination of ZI ' . • . , z, with coefficients in 0, and at least one coefficient equal
to a unit. Since ZI' ... , z, are linearly independent mod Wl over o/m, it follows
that our linear combination is a unit. Hence

484
ABSOLUTE VALUES
for some index v. In the sum
XII, §4
viewed as a sum on i, at least two terms have the same value. This contradicts
the independence of IYt l,..., lYe Imod r just as in the proof of Proposition 4.2.
Remark.
Our proof also shows that the elements {ZjYj} are linearly in-
dependent over K. This will be used again later.
If w is an extension of a valuation v, then the ramification index will be
denoted by e(wl v) and the residue class degree will be denoted by f (w lv).
Proposition 4.7. Let K be a field with a valuation v, and let K c EeL be
finite extensions ofK. Let wbe an extension ofv to E and let u be an extension
of w to L. Then
e(u Iw)e(wIv) = e(uIv),
f(ulw)f(wlv) = f(ulv).
Proof
Obvious.
We can express the above proposition by saying that the ramification index
and the residue class degree are multiplicative in towers.
We conclude this section by relating valuation rings in a finite extension with
the integral closure.
Proposition 4.8.
Let 0 be a valuation ring in a field K. Let L be a finite
extension ofK. Let 0 be a valuation ring ofL lying above 0 , and we its maximal
ideal. Let B be the integral closure of 0 in L , and let ~ = 9Jln B. Then D is
equal to the local ring B'lJ.
Proof
It is clear that B'tl is contained in D, Conversely, let x be an element
of .0. Then x satisfies an equation with coefficients in K , not all 0, say
Suppose that as is the coefficient having the biggest value among the aj for the
valuation associated with the valuation ring 0, and that it is the coefficient
farthest to the left having this value. Let b, = ai/as' Then all b,E 0 and

XII, §4
Divide the equation by X
S
• We get
VALUATIONS
485
Let y and z be the two quantities in parentheses in the preceding equation, so
that we can write
-y = zlx
and
-xy = z.
To prove our proposition it will sufficeto show that y and z lie in B and that y is
not in~ .
We use Proposition 3.5 of Chapter VII. If a valuation ring of Labove
contains x, then it contains y because y is a polynomial in x with coefficients in
Hence such a valuation ring also contains z = - xy. If on the other hand the
valuation ring of L above
contains 1/ x, then it contains z because z is a
polynomial in 1/x with coefficients in . Hence this valuation ring also contains
y. From this we conclude by Chapter VII, Proposition 3.5, that y, z lie in B.
Furthermore, since xED, and b., ... , bs+ 1 are in 9Jl by construction, it
follows that y cannot be in 9Jl, and hence cannot be in~ . This concludes the
proof.
Corollary 4.9.
Let the notation be as in the proposition. Then there is only
afinite numberofvaluation ringsofL lying above ~.
Proof
This comes from the fact that there is only a finite number of
maximal ideals ~ of B lying above the maximal ideal of 0 (Corollary of Pro-
position 2.1, Chapter VII).
Corollary 4.10. Let the notationbe as in the proposition. Assumein addition
that L is Galois overK. If.0 and..0' are two valuation ringsofL lyingabove0,
with maximal ideals9Jl, 9Jl' respectively, then there exists an automorphism a
ofLover K such that uD = .0' and u9Jl = 9Jl'.
Proof
Let ~ = .0 n B and ~ ' = .0' n B. By Proposition 2.1 of Chapter
VII, we know that there exists an automorphism a of Lover K such that
u~ = ~'. From this our assertion is obvious.
Example.
Let k be a field, and let K be a finitely generated extension of
transcendence degree 1. If t is a transcendence base of Kover k, then K is finite
algebraic over k(t). Let .0 be a valuation ring of K containing k, and assume that
.0 is =F K . Let 0 = .0 n k(t). Then 0 is obviously a valuation ring of k(t) (the

486
ABSOLUTE VALUES
XII.§5
condition about inverses is afortiori satisfied), and the corresponding valuation
of k(t) cannot be trivial. Either t or t - 1 EO. Say tEO. Then ° II k[t] cannot be
the zero ideal, otherwise the canonical homomorphism°-+ o/m of°modulo its
maximal ideal would induce an isomorphism on k[t] and hence an isomorphism
on k(t), contrary to hypothesis. Hence m II k[t] is a prime ideal p, generated by
an irreducible polynomial pet). The local ring k[t] p is obviously a valuation
ring, which must be°because every element of k(t) has an expression of type pru
where u is a unit in k[t]p . Thus we have determined all valuation rings of k(t)
containing k, and we see that the value group is cyclic. Such valuations will be
called discrete and are studied in greater detail below. In view of Corollary 4.5,
it follows that the valuation ring D of K is also discrete.
The residue class field o/m is equal to k[t] /p and is therefore a finite exten-
sion of k. By Proposition 4.6, it follows that D/Wl is finite over k (if Wldenotes
the maximal ideal of (0).
Finally, we observe that there is only a finite number of valuation rings D
of K containing k such that t lies in the maximal ideal of D. Indeed, such a
valuation ring must lie above k[t]p where p = (r) is the prime ideal generated by
t, and we can apply Corollary 4.9 .
§5.
COMPLETIONS AND VALUATIONS
Throughout this section, we deal with a non-archimedean absolute value
v on a field K. This absolute value is then a valuation, whose value group r K is a
subgroup ofthe positi vereals. We let°be its valuation ring, m the maximal ideal.
Let us denote by K the completion of K at v,and let a(resp. rit) be the closure
of °(resp. m) in K. By continuity, every element of ahas value ;£ 1, and every
element of K which is not in a has value > 1. If x E K then there exists an
element y E K such that Ix - yI is very small, and hence Ix I = IyI for such an
element y (by the non-archimedean property). Hence ais a valuation ring in
K, and mis its maximal ideal. Furthermore,
a II K = ° and
milK = m,
and we have an isomorphism
o/m':' aim.
Thus the residue class field o/m does not change under completion.
Let E be an extension of K , and let 0E be a valuation ring of E lying above o,
Let m E be its maximal ideal. We assume that the valuation corresponding to 0E
is in fact an absolute value, so that we can form the completion E. We then have

XII, §6
a commutative diagram:
DISCRETE VALUATIONS
487
0ElmE--=---. °ENtE
I
1
'"
o/m
----->
131m
the vertical arrows being injections, and the horizontal ones being isomorphisms.
Thus the residue class field extension of our valuation can be studied over the
completions E of K.
We have a similar remark for the ramification index. Let foCK) and fv(K)
denote the value groups of our valuation on K and Krespectively (i.e. the image
of the map x f---+[x I for x E K* and x E K* respectively). We saw above that
foCK) = fv(K) ; in other words, the value group is the same under completion,
because of the non-archimedean property. (This is of course false in the archime-
dean case.) If E is again an extension of K and w is an absolute value of E
extending v, then we have a commutative diagram
r w(E) ----=------. r w(E)
1
0 L
fv(K) -----> fv(K)
from which we see that the ramification index (Tw(E): fv(K)) also does not
change under completion.
§6.
DISCRETE VALUATIONS
A valuation is called discrete if its value group is cyclic. In that case, the
valuation is an absolute value (if we consider the value group as a subgroup of
the positive reals) . The p-adic valuation on the rational numbers is discrete for
each prime number p. By Corollary 4.5, an extension of a discrete valuation to a
finite extension field is also discrete. Aside from the absolute values obtained
by embedding a field into the reals or complex numbers, discrete valuations are
the most important ones in practice. We shall make some remarks concerning
them.
Let v be a discrete valuation on a field K, and let °be its valuation ring. Let
m be the maximal ideal. There exists an element n of m which is such that its
value Itt Igenerates the value group. (The other generator of the value group is
In-11·) Such an element n is called a local parameter for v (or for m). Every

488
ABSOLUTE VALUES
element x of K can be written in the form
x = ure'
XII, §6
with some unit u of 0, and some integer r. Indeed, we have [x] = lrel' = lre'l
for some r E Z, whence x/re' is a unit in o. We call r the order of x at v. It is
obviously independent of the choice of parameter selected. We also say that x
has a zero of order r. (If r is negative, we say that x has a pole of order -r.)
In particular, wesee that m is a principal ideal, generated by re. Asan exercise,
we leave it to the reader to verify that every ideal of 0 is principal, and is a power
of m. Furthermore, we observe that 0 is a factorial ring with exactly one prime
element (up to units), namely re.
If x, yEK, we shall write x r- y if [x] = Iyl. Let rei(i = 1,2, . ..) be a
sequence of elements of 0 such that rei '" rei. Let R be a set of representatives of
o/m in o. This means that the canonical map 0 -+ o/m induces a bijection of R
onto o/m.
Assumethat K iscompleteunderour valuation. Then everyelementx of0 can
be written as a convergent series
with aiE R, and the ajare uniquelydetermined by x.
This is easily proved by a recursive argument. Suppose we have written
then x - (ao + ... + an ren) = ren + lY for some yEO. By hypothesis, we can
write y = an + 1 + ttz with some an + 1 E R. From this we get
and it is clear that the n-th term in our series tends to O. Therefore our series
converges (by the non-archimedean behavior !). The fact that R contains precisely
one representative of each residue class mod m implies that the aj are uniquely
determined.
Examples.
Consider first the case of the rational numbers with the p-adic
valuation vp ' The completion is denoted by Qp. It is the field ofp-adic numbers.
The closure of Z in Qp is the ring of p-adic integers Zp. We note that the prime
number p is a prime element in both Z and its closure Zp. We can select our set
of representatives R to be the set of integers (0, 1, . . . , p -
1). Thus every p-
adic integer can be written uniquely as a convergent sum 2: a.p' where ai is an
integer, 0 ~ a, ~ P -
1. This sum is called its p-adic expansion. Such sums
are added and multiplied in the ordinary manner for convergent series .

XII, §6
DISCRETE VALUATIONS
489
For instance, we have the usual formalism of geometric series, and if we take
p = 3, then
2
2
- 1 = -- = 2(1 + 3 + 3 + ...).
1-3
We note that the representatives (0, 1, . . . , p -
1) are by no means the only
ones which can be used . In fact, it can be shown that Z; contains the (p -
l)-th
roots of unity, and it is often more convenient to select these roots of unity as
representatives for the non-zero elements of the residue class field.
Next consider the case of a rational field k(t), where k is any field and t is
transcendental over k. We have a valuation determined by the prime element t
in the ring k[t]. This valuation is discrete, and the completion of k[t] under this
valuation is the power series ring k[[t]]' In that case, we can take the elements
of k itself as repersentatives of the residue class field, which is canonically
isomorphic to k. The maximal ideal of k[[t]] is the ideal generated by t.
This situation amounts to an algebraization of the usual situation arising in
the theory of complex variables. For instance, let Zo be a point in the complex
plane. Let 0 be the ring offunctions which are holomorphic in some disc around
Zo o Then 0 is a discrete valuation ring, whose maximal ideal consists of those
functions having a zero at zo. Every element of 0 has a power series expansion
00
f(z) = L av(z - zor·
v=m
The representatives of the residue class field can be taken to be complex numbers,
avo Ifam =1= 0, then we say that f(z) has a zero of order m. The order is the same,
whether viewed as order with respect to the discrete valuation in the algebraic
sense, or the order in the sense of the theory of complex variables. We can select a
canonical uniformizing parameter namely z - zo, and
where g(z) is a power series beginning with a non-zero constant. Thus g(z) is
invertible.
Let K be again complete under a discrete valuation, and let E be a finite
extension of K. Let 0E ' mE be the valuation ring and maximal ideal in E lying
above 0, m in K . Let m be a prime element in E. If r E and r K are the value
groups of the valuations in E and K respectively, and
is the ramification index, then
IWI = [z],

490
ABSOLUTE VALUES
and the elements
fhrj, °~ i ~ e - l,j = 0, 1,2, ...
XII, §6
have order je + i in E.
Let WI"' "
w f be elements of E such that their residue classes mod mE from
a basis of 0E/mE ' IfR is as before a set of representatives of o/m in 0, then the set
consisting of all elements
with aj E R is a set of representatives of 0E/mE in 0E' From this we see that every
element of 0E admits a convergent expansion
e - I
f
00
I I I
a v. i.jTCjWvn
i
.
i; O v; 1 j;O
Thus the elements {co, nil form a set of generators of 0E as a module over 0.
On the other hand, we have seen in the proof of Proposition 4.6 that these
elements are linearly independent over K. Hence we obtain :
Proposition 6.1.
Let K be complete under a discrete valuation. Let E be a
finite extension of K, and let e, f be the ramification index and residue class
degree respectively. Then
ef = [E :K].
Corollary 6.2.
Let
CI. E E, CI. :f. 0. Let v be the valuation on K and wits
extension to E. Then
ord, Ni(CI.) = f(wl v) ord., CI..
Proof
This is immediate from the formula
and the definitions.
Corollary 6.3.
Let K beanyfield and va discretevaluation on K. Let E bea
finite extension ofK. If v is well behaved in E (for instance if E is separable
over K), then
I e(wlv)f(wl v) = [E :K].
wlv
If E is Galois over K, then all eware equal to the same number e, all fw are

XII, §7
ZEROS OF POLYNOMIALS IN COMPLETE FIELDS
491
equal to the same number f , and so
efr = [E: K],
where I' is the number ofextensions of v to E.
Proof.
Our first assertion comes from our assumption, and Proposition 3.3.
If E is Galois over K, we know from Corollary 4.10 that any two valuations of E
lying above v are conjugate. Hence all ramification indices are equal, and
similarly for the residue class degrees. Our relation ef r = [E : K] is then
obvious.
§7.
ZEROS OF POLYNOMIALS IN
COMPLETE FIELDS
Let K be complete under a non-trivial absolute value.
Let
f (X ) = n(X - etJri
be a polynomial in K[X] having leading coefficient I, and assume the roots «,
are distinct, with multiplicities r i o Let d be the degree of f . Let 9 be another
polynomial with coefficients in K' , and assume that the degree of9 is also d,and
that 9 has leading coefficient I. We let I9Ibe the maximum of the absolute values
of the coefficients of g. On e sees easily that if I9Iis bounded, then the absolute
values of the roots of 9 are also bounded.
Suppose that 9 comes close to f, in the sense that If - 9 I is small. If f3 is
any roo t of g, then
If([3) - g([3) I = If( [3) I = [I I«, -
[3 /"
is small, and hence [3 must come close to some root of f . As [3 comes close to
say a = al> its distance from the other roots of f approaches the distance of a 1
from the other roots, and is therefore bounded from below. In that case, we say
that [3 belongs to a.
Proposition 7.1.
If9 is sufficiently close to f, and [31' . .. , [3sare the roots of9
belonging to a (counting multiplicities), then s =
1'1 is the multiplicity ofa in f .
Proof
Assume the contrary. Then we can find a sequence g, of poly-
nomi als approaching f with precisely s roots [3\'), ... , [3~') belonging to a, but
with s #- r. (We can take the same multiplicity s since there is only a finite
number ofchoices for such multiplicities.) Furthermore, the other roots of 9 also

492
ABSOLUTE VALUES
XII, §7
belong to roots off, and we may suppose that these roots are bunched together,
according to which root of f they belong to. Since lim gv = f, we conclude that a
must have multiplicity s in f, contradiction.
Next we investigate conditions under which a polynomial has a root in a
complete field.
We assume that K is complete undera discrete valuation,with valuation ring 0 ,
maximal ideal p, We let 1t be a fixed prime element of p,
We shall deal with n-space over o. We denote a vector (al> . .. , an) with
aj E 0 by A. If f(X 1, . . . , X n) E o[X] is a polynomial in n variables, with integral
coefficients, we shall say that A is a zero of f if f(A) = 0, and we say that A is a
zero of f mod pm if f(A) == 0 (mod pm).
Let C = (co, ... , cn) be in o(n +1) . Let m be an integer ~ 1. We consider the
nature of the solutions of a congruence of type
(*)
This congruence is equivalent with the linear congruence
(**)
Ifsome coefficient c, (i = 1, .. . , n) is not == 0 (mod p), then the set of solutions is
not empty, and has the usual structure of a solution of one inhomogeneous
linear equation over the field ojp.
In particular, it has dimension n -
I.
A congruence (*) or (**) with some c, ¢ 0 (mod p) will be called a proper
congruence.
As a matter of notation, we write D,f for the formal partial derivative of f
with respect to X j. We write
grad f(X) = (Dtf(X), ... , Dnf(X)).
Proposition 7.2.
Let f(X) E o[X]. Let r be an integer ~ 1and let A E o(n)be
such that
f(A) == 0
(mod p2r- 1),
o, f(A) == 0
(mod pr- 1),
DJ(A) ¢ 0
(mod p"),
for all
i = 1,.. . , n,
for some i = 1, .. . , n.
Let v be an integer ~ 0 and let B E o(n)be such that
B == A
(mod p")
and
feB) == 0
(mod p2r- 1+V).
A vector Y E o(n)satisfies
Y == B
(mod pr+,')
and fey) == 0
(mod p2r+»

XII, §7
ZEROS OF POLYNOMIALS IN COMPLETE FIELDS
493
ifand only if Y can be written in theform Y = B + nr +vc, with some C E o (n)
satisfying the proper congruence
f( B) + nr + v grad f (B) . C =0
(mod p 2r +V).
Proof
The proof is shorter than the statement of the proposition. Write
Y = B + nr+vc.
By Taylor's expansion,
f(B + nr+vC) = f(B) + nr+vgrad f( B) · C
(mod p 2r + 2v).
To solve this last congruence mod p 2r + v, we obtain a proper congruence by
hypothesis, because grad f( B) =grad f(A ) =0 (mod pr - I).
Corollary 7.3.
Assumptions being as in Proposition 7.2, there exists a zero
of f in o(n) which is congruent to A mod pro
Proof
We can write this zero as a convergent sum
solving for C I ' C2' . . . inductively as in the proposition.
Corollary 7.4.
Let f be a polynomial in one variable in o[X] , and let a E 0
be such that f(a) == 0 (mod P) but f'(a)
=1= 0 (mod P). Then there exists
b e 0 , b = a (mod p) such that fe b) = O.
Proof
Take n = I and r = 1 in the proposition, and apply Corollary 7.3.
Corollary 7.5.
Let m be a positive integer not divisible by the characteristic
of K. There exists an integer r such that for any a E 0, a =1 (mod p'), the
equation X" - a = 0 has a root in K .
Proof
Apply the proposition.
Example.
In the 2-adic field Q 2' there exists a square roo t of - 7, i.e.
~ E Q 2' because -7 = 1 - 8.
When the absolute value is not discrete, it is still possible to formulate a
criterion for a polynomial to have a zero by Newton approximation. (Cf. my
paper, "On quasi-alg ebraic closure ," Annals of Math. (1952) pp. 373-390.
Proposition 7.6.
Let K be a complete under a non-archimedean absolute
value (nontrivial). Let 0 be the valuation ring and let f(X) E o[X] be a poly-
nomial in one variable. Let txo E 0 be such that
If(tx o)I < If'(txo)21
(here f' denotes theformal derivative of I). Then the sequence
f (txi)
txi + I = a, - f'(tx
i
)

494
ABSOLUTE VALUES
XII, §7
converges to a root a off in 0 , and we have
la - aol ~ I~~aoo;21 < 1.
Proof.
Let c = If(ao)/f'(ao)21 < 1. We show inductively that:
1. lad s 1,
2. lai -
aoI ~ c,
3.' f(aJ I<
2'
f'(aJ2
= c .
These three conditions obviously imply our proposition. If i = 0, they are
hypotheses. By induction, assume them for i. Then :
1. If(ai)/f'(aifl ~ C2i gives lai+1 - ad ~ C2i < 1, whence lai+ll ~ 1.
2. lai+1- aoI ~ max{lai+1 -
ad, lai - aoI} = c.
3.
By Taylor's expansion, we have
f(
)
f()
f '( ) f(aJ
R(f(aJ)2
ai+ 1
=
ai -
a, f'(ai) + p f'(aJ
for some pE 0, and this is less than or equal to
in absolute value.
Using Taylor's expansion on f'(ai+ I) we conclude that
From this we get
I
f(ai+l) 1< 2i+ 1
f '(
)2
= C
ai+ 1
as desired.
The technique of the proposition is also useful when dealing with rings, say a
local ring 0 with maximal ideal m such that m" = 0 for some integer r > O.
If one has a polynomial f in o[X] and an approximate root ao such that
f'(ao) :f= 0 mod rn,
then the Newton approximation sequence shows how to refine ao to a root off.
Example in several variables.
Let K be complete under a non-archimedean
absolute value. Letf(XJ•• • • • Xn+ J) E K[X] be a polynomial with coefficients
in K. Let (al"
'"
an' b) E xr:' . Assume that fta , b) = O. Let Dn+! be the

XII, Ex
EXERCISES
495
partial derivative with respect to the (n + I)-th variable, and assume that
Dn+I!(a, b) *- O. Let (a) E K" be sufficientlyclose to (a). Then there exists an
element b of K close to b such that f(a, b) = O.
This statement is an immediate corollary of Proposition 7.6. By multiplying
all a., b by a suitable non-zero element of K one can change them to elements
of o. Changing the variables accordingly, one may assume without loss of gen-
erality that a., b EO, and the condition on the partial derivative not vanishing
is preserved. Hence Proposition 7.6 may be applied . After perturbing (a) to
(a), the element b becomes an approximate solution off(a, X) . As (a) approaches
(a), f(a, b) approaches 0 and Dn+I!(a , b) approaches Dn+I!(a, b) *- O.
Hence for (a) sufficiently close to (a), the conditions of Proposition 7.6 are
satisfied, and one may refine b to a root of f(a , X), thus proving the assertion.
The result was used in a key way in my paper "On Quasi Algebraic Closure".
It is the analogue of Theorem 3.6 of Chapter XI, for real fields.
In the language of algebraic geometry (which we now assume), the result
can be reformulated as follows . Let V be a variety defined over K. Let P be a
simple point of V in K . Then there is a whole neighborhood of simple points of
V in K . Especially, suppose that V is defined by a finite number of polynomial
equations over a finitely generated field k over the prime field . After a suitable
projection, one may assume that the variety is affine, and defined by one equa-
tion f(X\>
, Xn+,) = 0 as in the above statement, and that the point is
P = (aI'
, an' b) as above. One can then select d, = Xi clo se to a, but such
that (XI'
, xn ) are algebraically independent over k. Let y be the refinement
of b such thatf(x, y) = O. Then (x, y) is a generic point of V over k, and the
coordinates of (x , y) lie in K. In geometric term s, this means that the function
field of the variety can be embedded in Kover k, just as Theorem 3.6 of Chapter
Xl gave the similar result for an embedding in a real closed field, e.g. the real
numbers .
EXERCISES
1. (a) Let K be a field with a valuation. If
is a polynomial in K[X], defineIf Ito be the max on the valuesIaiI(i = 0, . . . , n).
Show that this defines an extension of the valuation to K[X], and also that the
valuation can be extended to the rational field K(X). How is Gauss' lemma a
specialcaseofthe abovestatement? Generalizeto polynomialsin severalvariables.
(b) Let f be a polynomial with complex coefficients. DefineIf Ito be the maximum
of the absolute values of the coefficients. Let d be an integer G 1. Show that

496
ABSOLUTE VALUES
XII, Ex
there exist constants Cl' C2 (depending only on d) such that, iff: g are polynomials
in C[X] of degrees ~ d, then
[Hint:
Induction on the number of factors of degree 1. Note that the right
inequality is trivial.]
2. Let MQ be the set of absolute values consisting of the ordinary absolute value and all
p-adic absolute values vp on the fieldof rational numbers Q. Show that for any rational
number a E Q, a f:. 0, we have
n [a], = 1.
HMQ
If K is a finite extension of Q, and MK denotes the set of absolute values on K extending
those of MQ , and for each WE M K we let N w be the local degree [K w : Q v]' show that
for a. E K, a. f:. 0, we have
Il
1a.I~w = 1.
weMx
3. Show that the p-adic numbers Qp have no automorphisms other than the identity.
[Hint: Show that such automorphisms are continuous for the p-adic topology. Use
Corollary 7.5 as an algebraic characterization of elements close to 1.]
4. Let A be a principal entire ring, and let K be its quotient field. Let 0 be a valuation ring
of K containing A, and assume 0 f:. K. Show that 0 is the local ring A(p) for some prime
element p. [This applies both to the ring Z and to a polynomial ring k[ X] over a fieldk.]
5. Let A be the subring of polynomials f (X) E Q[X] such that the constant coefficient
off is in Z. Show that every finitely generated ideal in A is principal, but the ideal
of polynomials in A with 0 constant coefficient is not principal. [Laura Wesson
showed me the above, which gives a counterexample to the exercise stated in previ-
ous editions and printings, using the valuation ring 0 on Q(X) containing Q and
such that X has order 1. Then 0 f:. A(p) for any element p of A.]
6. Let Qp be a p-adic field. Show that Qp contains infinitely many quadratic fields of
type Q(~), where m is a positive integer.
7. Show that the ring of p-adic integers Zp is compact. Show that the group of units in Zp
is compact.
8. If K is a fieldcomplete with respect to a discrete valuation, with finite residue class field,
and if 0 is the ring of elements of K whose orders are ~ 0, show that 0 iscompact. Show
that the group of units of 0 is closed in 0 and is compact.
9. Let K be a fieldcomplete with respect to a discrete valuation, let 0 be the ring of integers
of K , and assume that 0 is compact. Let fl' f2 ' . . . be a sequence of polynomials in n
variables, with coefficients in o. Assume that all these polynomials have degree ~ d,
and that they converge to a polynomialf(i.e. that If - };I --+°as i --+ (0). Ifeach}; has
a zero in 0, show that f has a zero in o. If the polynomials}; are homogeneous ofdegree
d, and ifeachj, has a non-trivial zero in 0, show thatfhas a non-trivial zero in o. [Hint:
Use the compactness of 0 and of the units of 0 for the homogeneous case.]
(For applications of this exercise , and also of Proposition 7.6 , cf. my paper "On
quasi-algebraic closure," Annals of Math ., 55 (1952) , pp. 412-444.)

XII, Ex
EXERCISES
497
10. Show that if p, p' are two distinct prime numbers, then the fields Qp and Qp. are not
isomorphic.
II. Prove thatthe field Qpcontains all (p -
lj-th roots of unity. [Hint: Use Proposition 7.6,
applied to the polynomial XP-I -
I which splits into factors of degree I in the residue
class field.] Show that two distinct (p -
lj-th roots of unity cannot becongruent mod p.
12. (a) Let / (X ) be a polynomial of degree ~ I in Z[X]. Show that the values / (a) for
a E Z are divisible by infinitely many primes.
(b) Let F be a finite extension of Q. Show that there are infinitely many primes p
such that all conjugates of F (in an algebraic closure of Qp) actually are contained
in Q p' [Hint: Use the irreducible polynomial of a generator for a Galois extension
of Q containing F.J
13. Let K be a field of characteristic 0, complete with respect to a non-archimedean absolute
value. Show that the series
x 2
x 3
exp(x) = I + x + - +- + ...
2!
3!
x 2
x 3
10g(1 + x) = x - -
+ - - ..,
2
3
converge in some neighborhood ofO. (The main problem arises when the characteristic
of the residue class field is p > 0, so that p divides the denominators n! and n. Get an
expression which determines the power of p occurring in n!.) Prove that the exp and
log give mappings inverse to each other, from a neighborhood of 0 to a neighborhood
of I.
14. Let K beas in the preceding exercise, of characteristic 0, complete with respect to a non-
archimedean absolute value. For every integer n > 0, show that the usual binomial
expansion for (l + X) I /. converges in some neighborhood ofO. Do this first assuming
that the characteristic of the residue class field does not divide n, in which case the asser-
tion is much simpler to prove.
15.
Let F bea complete field with respect to a discrete valuation,let 0 be the valuation ring,
n a prime element, and assume that o/(n) = k. Prove that if a, be 0 and a == b(mod 7t')
with r > 0 then aP" == b'" (mod nd
" ) for all integers n ~ O.
16. Let F be as above. Show that there exists a system of representatives R for o/(7t) in 0
such that RP = R and that this system is unique (Teichmiiller). [Hint:Let IXbe a residue
class in k. For each v ~ 0 let av be a representative in 0 of aP '. and show that the
sequence ar converges for v --+ 00, and in fact converges to a representative a of IX,
independent of the choices of a v ' ]
Show that the system of representatives R thus
obtained is closed under multiplication, and that if F has characteristic p, then R is
closed under addition, and is isomorphic to k.
17. (a) (Witt vectors again). Let k be a perfect field of characteristic p. We use the
Witt vectors as described in the exercises of Chapter VI. One can define an
absolute value on W(k), namely Ixl = p - r if x, is the first non-zero component
of x. Show that this is an absolute value, obviously discrete, defined on the ring,
and which can be extended at once to the quotient field. Show that this quotient
field is complete , and note that W(k) is the valuation ring. The maximal ideal
consists of those x such that Xo = 0, i.e. is equal to pW(k).

498
ABSOLUTE VALUES
XII, Ex
x'
(b) Assume that F has characteristic O. Map each vector x E W(k) on the element
where ~ j is a representative of Xi in the special system of Exercise 15. Show that
this map is an embedding of W(k) into o.
18. (Local uniformization). Let k be a field,K a finitely generated extension of transcendence
degree 1, and 0 a discrete valuation ring of Kover k, with maximal ideal m. Assume that
o/m = k. Let x be a generator ofm, and assume that K isseparable over k(x). Show that
there exists an element yEo such that K = k(x, y), and also having the following
property. Let q> be the place on K determined by o. Let a = q>(x), b = q>(y) (of course
a = 0). Let f(X, Y) be the irreducible polynomial in k[X, Y] such that f(x, y) = O.
Then D2 f(a, b) of. O. [Hint:
Write first K = k(x, z) where z is integral over k[x]. Let
z = z., ... , zn(n :?; 2) be the conjugates of z over k(x), and extend 0 to a valuation
ring .0 of k(x, Zl, . . . , zn)' Let
z = ao + a.x + ...+ a,x' + ...
be the power series expansion of z with a, E k, and let P,(x) = ao + ... + a.x', For
i = 1,.. . , n let
Zj -
P,(x)
Yi =
Taking r large enough, show that YI has no pole at .0 but Y2, " " Yn have poles at D.
The elements Yi,. . ., Yn are conjugate over k(x). Let f(X, Y) be the irreducible poly-
nomial of (x, y) over k. Then f(x, Y) = t/Jn(x)yn + .., + t/Jo(x) with t/Ji(x)k[x]. We
may also assume t/J;(O) of. 0 (since f is irreducible). Write f(x, Y) in the form
f(x, Y) = t/Jn(X)Y2 ... Yn(Y - YI)(Yi l Y -
1) · ·· (y; IY -
1).
Show that t/Jn(X)Y2 . . . Yn = u does not have a pole at D. Ifw E .0, let wdenote its residue
class modulo the maximal ideal of D. Then
o of. f(x, Y) = (_l)n-Iu(Y - 5\).
Let Y = YI> Y= b. We find that D2 f(a, b) = (-lr IU of. 0.]
19. Prove the converse of Exercise 17, i.e. if K = k(x, y), f(X, Y) is the irreducible poly-
nomial of (x, y) over k, and if a, bE k are such that f(a, b) = 0, but Dd(a, b) of. 0,
then there exists a unique valuation ring 0 of K with maximal ideal m such that x == a
and Y == b (mod m). Furthermore, o/m = k, and x - a is a generator of m. [Hint:
If g(x, y) E k[x, y] is such that g(a, b) = 0, show that g(x, y) = (x - a)A(x, y)/B(x, y)
where A, B are polynomials such that B(a, b) of. O. If A(a, b) = 0 repeat the process.
Show that the process cannot be repeated indefinitely, and leads to a proofof the desired
assertion.]
20. (Iss'sa-Hironaka Ann. ofMath 83 (1966), pp. 34-46). This exercise requires a good
working knowledge of complex variables . Let K be the field of meromorphic functions
on the complex plane C. Let .0 be a discrete valuation ring of K (containing the

XII, Ex
EXERCISES
499
constants C ). Show that the function z is in O . [Hint: Let a l' a2, . . . be a discrete
sequence of complex numbers tending to infinity , for instance the positive integers.
Let VI' V2' . . . , be a sequence of integers, 0 ~ u, ~ p -
I, for some prime number
p , such that 2: Vjp i is not the p-adic expansion of a rational number. Let/be an entire
function having a zero of order Vip i at aj for each i and no other zero . If z is not in
0, consider the quotient
/(z)
g(z) =
- n--
--
n(z - ajYiP'
i= 1
From the Weierstrass factorization of an entire function, show that g(z) = h(z)P" + I for
some entire function h(z). Now analyze the zero of 9 at the discrete valuation of 0 in
term s of that of / and n(z - aj)"P' to get a contradiction.]
If U is a non-compact Riemann surface, and L is the field of meromorphic functions
on U, and if 0 is a discrete valuation ring of L containing the constants, show that every
holomorphicfunction cp on U lies in o. [Hint : Map cp : U ---> C,and get a discrete valua-
tion of K by composing cp with meromorphic functions on C. Apply the first part of the
exercise.] Show that the valuation ring is the one associated with a complex number.
[Further hint:If you don 't know about Riemann surfaces, do it for the complex plane.
For each z E U, let j, be a function holomorphic on U and having only a zero of order 1
at z. Iffor some Zo the function fz o has order ~ I at 0, then show that 0 is the valuation
ring associated with zo. Otherwise,every function /zhas order 0 at o. Conclude that the
valuation of 0 is trivial on any holomorphic function by a limit trick analogous to that
of the first part of the exercise.]

Part Three
LINEAR ALGEBRA
and
REPRESENTATIONS
We shall be concerned with modules and vector spaces, going into their
structure under various points of view. The main theme here is to study a pair,
consisting of a module, and an endomorphism, or a ring of endomorphisms,
and try to decompose this pair into a direct sum of components whose structure
can then be described explicitly. The direct sum theme recurs in every chapter.
Sometimes, we use a duality to obtain our direct sum decomposition relative
to a pairing, and sometimes we get our decomposition directly. If a module
refuses to decompose into a direct sum of simple components, then there is no
choice but to apply the Grothendieck construction and see what can be ob-
tained from it.
The extension theme occurs only once, in Witt's theorem, in a brief counter-
point to the decomposition theme.
501

CHAPTER XIII
Matrices and Linear Maps
Presumably readers of this chapter will have had some basic acquaintance
with linear algebra in elementary courses. We go beyond such courses by pointing
out that a lot of results hold for free modules over a commutative ring. This is
useful when one wants to deal with families of linear maps, and reduction modulo
an ideal.
Note that §8 and §9 give examples of group theory in the context of linear
groups.
Throughout this chapter, we let R be a commutative ring, and we let
E, F be R-modules. We suppress the prefix R in front of linear maps and
modules.
§1.
MATRICES
By an m x n matrix in R one means a doubly indexed family of elements
of R, (ai) , (i = 1, . . . , m and j = 1, . . . , n), usually written in the form
We call the elements a., the coefficients or components of the matrix. A
1 x n matrix is called a row vector (of dimension, or size, n) and a m x 1 matrix
is called a column vector (of dimension, or size, m). In general, we say that
(m, n) is the size of the matrix, or also m x n.
We define addition for matrices of the same size by components. IfA = (ai)
and B = (bi) are matrices of the same size, we define A + B to be the matrix
whose (i-component is a ij + bij • Addition is obviously associative. We define
the multiplication of a matrix A by an element C E R to be the matrix (cai),
503
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

504
MATRICES AND LINEAR MAPS
XIII, §1
whose ij-component is caij' Then the set of m x n matrices in R is a module
(i.e. an R-module).
We define the product AB of two matrices only under certain conditions.
Namely, when A has size (m, n) and B has size (n, r), i.e. only when the size of
the rows of A is the same as the size of the columns of B. If that is the case, let
A = (aj) and let B = (bjk). We define AB to be the m x r matrix whose ik-
component is
nLaijbjk.
j= 1
If A, B, C are matrices such that AB is defined and BC is defined, then so is
(AB)C and A(BC) and we have
(AB)C = A(BC).
This istrivial to prove. If C = (Ck'), then the reader will see at once that the
ii-component of either of the above products is equal to
L L aijbjkck/'
j
k
An m x n matrix is said to be a square matrix if m = n. For example, a
1 x 1 matrix is a square matrix, and will sometimes be identified with the
element of R occurring as its single component.
For a given integer n ~ 1 the set of square n x n matricesforms a ring.
This is again trivially verified and will be left to the reader.
The unit element of the ring of n x n matrices is the matrix
0
...
0
0
1
0
In =
0
0
whose components are equal to 0 except on the diagonal, in which case they
are equal to 1. We sometimes write I instead of In.
If A = (aij) is a square matrix, we define in general its diagonal components
to be the elements ajj'
We have a natural ring-homomorphism of R into the ring of n x n matrices,
given by
Thus cl; is the square n x n matrix having all its components equal to 0 except
the diagonal components, which are equal to c. Let us denote the ring of n x n

XIII, §1
MATRICES
505
matrices in R by Matn(R). Then Matn(R) is an algebra over R (with respect to
the above homomorphism).
Let A = (aij) be an m X n matrix. We define its transpose fA to be the matrix
(aji) (j = I, ... , nand i = I, . . . , m). Then fA is an n X m matrix . The reader
will verify at once that if A, B are of the same size, then
If c E R then '(cA) =
c ~ . If A, B can be multiplied, then 'B ~ is defined and we
have
We note the operations on matrices commute with homomorphisms. More
precisely, let qJ: R -+ R' be a ring-homomorphism. If A, B are matrices in R,
we define qJA to be the matrix obtained by applying qJ to all the components of
A. Then
qJ(A + B) = qJA + qJB,
qJ(AB) = (qJA)(qJB),
qJeA) = fqJ(A).
qJ(cA) = qJ(c)qJA,
A similar remark will hold throughout our discussion of matrices (for
instance in the next section).
Let A = (aij) be a square n x n matrix in a commutative ring R. We define
the trace of A to be
"
tr(A) = Laii ;
i = I
in other words, the trace is the sum of the diagonal elements.
If A, Bare n x n matrices, then
tr(AB) = tr(BA).
Indeed, if A = (aij) and B = (bi) then
tr(AB) = LL a i. b•i = tr(BA).
i
v
As an application, we observe that if B is an invertible n x n matrix, then
tr(B- lAB) = tr(A).
Indeed, tr(B- 1AB) = tr(ABB- 1) = tr(A).

506
MATRICES AND LINEAR MAPS
§2.
THE RANK OF A MATRIX
XIII, §2
Let k be a field and let A be an m x n matrix in k. By the row rank of A we
shall mean the maximum number of linearly independent rows of A, and by the
column rank of A we shall mean the maximum number of linearly independent
columns of A. Thus these ranks are the dimensions of the vector spaces gen-
erated respectively by the rows of A and the columns of A. We contend that
these ranks are equal to the same number, and we define the rank of A to be
that number.
Let AI, .. . , A" be the columns of A, and let Ai"'"
Am be the rows of A.
Let IX = (Xl ' . . . , xm) have components Xi E k. We have a linear map
of k(m) onto the space generated by the row vectors. Let W be its kernel. Then
W is a subspace of k(m) and
dim W + row rank = m.
If Y is a column vector of dimension m, then the map
(X, Y)H'XY = X · Y
is a bilinear map into k, if we view the 1 x 1 matrix IXY as an element of k.
We observe that W is the orthogonal space to the column vectors AI, . .. , A",
i.e. it is the space of all X such that X . Ai = 0 for allj = 1, . . . , n. By the duality
theorem of Chapter III, we know that kIm) is its own dual under the pairing
(X, Y)HX , Y
and that k(m)/w is dual to the space generated by AI, .. ., A". Hence
dim k(m)/w = column rank,
or
dim W + column rank = m.
From this we conclude that
column rank = row rank,
as desired.
We note that W may be viewed as the space of solutions of the system of n
linear equations

XIII, §3
MATRICES AND LINEAR MAPS
507
in m unknowns Xl> ... , Xm • Indeed, if we write out the preceding vector equation
in terms of all the coordinates, we get the usual system of n linear equations.
We let the reader do this if he or she wishes.
§3.
MATRICES AND LINEAR MAPS
Let E be a module, and assume that there exists a basis <:B =
{ ~ 1"
'"
~n }
for E over R. This means that every element of E has a unique expression as a
linear combination
with Xi E R. We call (x I' ... , xn) the components of x with respect to the basis .
We may view this n-tuple as a row vector. We shall denote by X the transpose
of the row vector (XI' ... , x n) . We call X the column vector of x with respect to
the basis .
We observe that if {~'I' .. . , ~~} is another basis of E over R, then m = n.
Indeed, let p be a maximal ideal of R. Then E/pE is a vector space over the
field R/pR, and it is immediately clear that if we denote by ~i the residue class
of ~i mod pE, then {~l> .. . , ~n} is a basis for E/pE over R/pR. Hence n is also
the dimension of this vector space, and we know the invariance of the cardinality
for bases of vector spaces over fields. Thus m = n. We shall call n the dimension
of the module E over R.
We shall view R(n) as the module of column vectors of size n. It is a free
module of dimension n over R. It has a basis consisting of the unit vectors
el , • . . , en such that
lei = (0, . . . , 0, 1,0, . . . , 0)
has components 0 except for its i-th component, which is equal to 1.
An m x n matrix A gives rise to a linear map
by the rule
X 1--+ AX.
Namely, we have A(X + Y) = AX + A Y and A(cX) = cAX for column
vectors X. Y and c E R.

508
MATRICES AND LINEAR MAPS
XIII, §3
The above considerations can be extended to a slightly more general
context, which can be very useful. Let E be an abelian group and assume that
R is a commutative subring of
Endz (E) = Homz(E, E).
Then E is an R-module. Furthermore, if A is an m x n matrix in R, then we get
a linear map
defined by a rule similar to the above, namely X H AX. However, this has to
be interpreted in the obvious way. If A = (aij) and X is a column vector of
elements of E, then
n
where Yi = L: aijxj'
j= 1
If A, B are matrices in R whose product is defined, then for any C E R we
have
Thus we have associativity, namely
A(BX) = (AB)X .
An arbitrary commutative ring R may be viewed as a module over itself.
In this way we recover the special case of our map from R(n) into R(m). Further-
more, ifE is a module over R, then R may be viewed as a ring of endomorphisms
of E.
Proposition 3.1.
Let E be a free module over R, and let {x 1, .. . ,xn} be a
basis. Let Yl' . . . ,Yn be elements of E. Let A be the matrix in R suchthat
{}()
Then {Yl' ... , Yn} is a basis of E if andonly if A is invertible.
Proof.
Let X, Y be the column vectors of our elements. Then AX = Y.
Suppose Y is a basis. Then there exists a matrix C in R such that CY = X.

XIII, §3
MATRICES AND LINEAR MAPS
509
Then CAX = X, whence CA = I and A is invertible. Conversely, assume that
A is invertible. Then X = A-I Y and hence x l ' . .. 'Xn are in the module
generated by Yl' ... , Yn ' Suppose that we have a relation
with b, E R. Let B be the row vector (b1, • •. , bn) . Then
BY = 0
and hence BAX = O. But { X l> "
" x n} is a basis. Hence BA = 0, and hence
BAA - 1 = B = O. This proves that the components of Yare linearly indepen-
dent over R, and proves our proposition.
We return to our situation of modules over an arbitrary commutative
ring R.
Let E, F be modules. We shall see how we can associate a matrix with a
linear map whenever bases of E and F are given. We assume that E, F are free.
Welet<B =UI"'" {n}and (1\' ={{;, ..., {~}bebasesofEandFrespectively.
Let
J:E -+ F
be a linear map. There exist unique elements aij E R such that
or in other words,
m
J(~) = L aij~;
i=1
(Observe that the sum is over the first index.) We define
If X = X 1~ 1 + ... + x, ~n is expressed in terms of the basis, let us denote the
column vector X of components of x by M(jl(x). We see that
M(jl.(J(x)) =
M~.(J)M(jl(x).
In other words, if X ' is the column vector ofJ(x), and M is the matrix associated
withJ then X' = MX . Thus the operation of the linear map is reflected by the
matrix multiplication, and we have J = L M .

510
MATRICES AND LINEAR MAPS
XIII, §3
Proposition 3.2.
Let E, F, D be modules, and let CB, CB', CB" be finite bases
of E, F, D, respectively. Let
be linear maps. Then
Proof.
Let A and B be the matrices associated with the maps f , g respec-
tively, with respect to our given bases. If X is the column vector associated with
x E E, the vector associated with g(f(x)) is B(AX) = (BA)X. Hence BA is the
matrix associated with g 0 f. This pro ves what we wanted.
Corollary 3.3.
Let E = F. Then
M~ .(id)M~ ·(id) = M~ :(id) = I.
Each matrix M~ ,(id) is invertible (i.e. is a unit in the ring of matrices).
Proof.
Obvious.
Corollary 3.4.
Let N = M~ .(id ). Then
(8'
(8 "d)
(8(f)
(8' "d)
(8(f)
- 1
M(8,(f) = M(8.(1
M(8
M(8 (I
= NM(8
N
.
Proof.
Obvious
Corollary 3.5.
Let E be a free module of dimension n over R. Let CB be a
basis of E over R. The map
f l-+ M~ (f)
is a ring-isomorphism of the ring ofendomorphisms ofE onto the ringofn x n
matrices in R. Infact, the isomorphism is one of algebras over R.
We shall call the matrix M~(f) the matrix associated withfwith respect to
the basis CB.
Let E be a free module of dimension n over R. By GL(E) or AutR(E) one
mean s the group of linear automorphisms of E. It is the group of units in
EndR(E). By GLn(R) one means the group of invertible n x n matrices in R.
Once a basis is selected for E over R, we have a group-isomorphism
with respect to this basis.

XIII, §4
Let E be as above. If
f: E -+ E
DETERMINANTS
511
is a linear map, we select a basis CB and let M be the matrix associated with f
relative to CB. We define the trace off to be the trace of M, thus
tr(f) = tr(M).
If M' is the matrix off with respect to another basis, then there exists an in-
vertible matrix N such that M' = N- I MN, and hence the trace is independent
of the choice of basis.
§4.
DETERMINANTS
Let EI , .. • , En' F be modules. A map
f :E I
X • • • x En -+ F
is said to be R-multilinear (or simply multilinear) if it is linear in each variable,
i.e, if for every index i and elements XI"' "
Xi -I ' Xi+ I' ... , Xn , Xj E Ej , the map
is a linear map of E, into F.
A multilinear map defined on an n-fold product is also called n-multilinear.
If E I = ... = En = E, we also say thatfis a multilinear map on E, instead of
saying that it is multilinear on E(n).
Let f be an n-multilinear map. If we take two indices i, j and i # j then
fixing all the variables except the i-th and j-th variable, we can viewf as a
bilinear map on E, x Ej •
Assume that E I = ... = En = E. We say that the multilinear map f is
alternating iff(x l , ... , xn) = 0 whenever there exists an index i, 1 ~ i ~ n - 1,
such that Xi =
Xi+ I (in other words, when two adjacent elements are equal).
Proposition 4.1.
Let f be an n-multilinear alternating map on E. Let
xI, .. . , XnEE. Then
f(·· · , Xi ' Xi+ I' . ..) =
- f(· · ·, x.; I> Xi> ...).
In other words, when we interchange two adjacent arguments off, the value
off changes by a sign. If Xi = x.for i # j then f(xl> " " xn) = o.

512
MATRICES AND LINEAR MAPS
XIII, §4
Proof
Restricting our attention to the factors in the i-th andj-th place, with
j
= i + l, we may assumef is bilinear for the first statement. Then for all x,
y
E E we have
o= f(x + y, x + y) = f(x, y) + fe y, x).
This proves what we want, namely fe y, x) =
- f(x, y). For the second asser-
tion, we can interchange successively adjacent arguments off until we obtain
an n-tuple of elements of E having two equal adjacent arguments. This shows
that when Xi = Xj' i =F j, then f(x" . . . , xn) = O.
Corollary 4.2.
Let f be an n-multilinear alternating map on E.
Let
Xl ' . . . , x, E E. Let i =F j and let a E R. Then the value off on (x., .. . ,xn)
does not change if we replace Xi by Xi + aXj and leave all other components
fixed.
Proof.
Obvious.
A multilinear alternating map taking its value in R is called a multilinear
alternating form.
On repeated occasions we shall evaluate multilinear alternating maps on
linear combinations of elements of E. Let
Let f be n-multilinearalternating on E. Then
We expand this by multilinearity, and get a sum of terms of type
where (1 ranges over arbitrary maps of {I, .. . , n} into itself. If(1 is not a bijection
(i.e. a permutation), then two arguments Va(i) and va(j) are equal for i =F j, and
the term is equal to O. Hence we may restrict our sum to permutations (1.
Shuffling back the elements (vaO)' . . . , vaIn) to their standard ordering and using
Proposition 4.1, we see that we have obtained the following expansion:
Lemma 4.3.
If Wi' ..• , Wn are as above, then
f(w l , · · · , wn) = L£((1)a l , a( l) ' " an,a(n)f(vl>""
Vn)
a
where the sum is taken over all permutations (1 of {l, . . . , n} and £((1) is the
sign ofthe permutation.

XIII, §4
DETERMINANTS
513
For determinants, I shall follow Artin's treatment in Galois Theory.
By an n x n determinant we shall mean a mapping
also written
which, when viewed as a function of the column vectors A l, . . . , Anof a matrix
A, is multilinear alternating, and such that D(I) = 1. In this chapter, we use
mostly the letter D to denote determinants.
We shall prove later that determinants exist. For the moment, we derive
properties.
Theorem 4.4.
(Cramer's Rule).
Let A 1, . • . , Anbecolumnvectorsofdimen-
sion n. Let Xl' ... , x; E R be such that
xlA l + ... + xnAn = B
for some column vector B. Thenfor each i we have
xjD(A l , •. • , An) = D(A l , • . . , B, . .. , An),
where B in this last line occursin the i-th place.
Proof.
Say i = 1. We expand
n
D(B, A 2 , • • • , An) = L xjD(Aj, A 2 , •• • , An),
j = 1
and use Proposition 4.1 to get what we want (all terms on the right are equal
to 0 except the one having Xl in it).
Corollary 4.5.
Assume that R is a field.
Then A l, .. . ,An are linearly
dependent if and only if D(Al, . .. , An) = o.
Proof.
Assume we have a relation
with Xi E R. Then xjD(A) = 0 for all i. If some X i =1= 0 then D(A) = O. Con-
versely, assume that A l, .. . , Anare linearly independent. Then we can express
the unit vectors el , . . . , en as linear combinations

514
MATRICES AND LINEAR MAPS
with bij E R. But
1 = D(el , •• • , en).
XIII, §4
Using a previous lemma, we know that this can be expanded into a sum of
terms involving D(A I , . . . , An), and hence D(A) cannot be O.
Proposition 4.6.
IJ determinants exist, they are unique. IJ A I, . . . , An are
the column vectorsoj dimension n, ofthe matrix A = (aij), then
D(AI , . . . , An) = L£(a)a"(l).1 . . . a,,(n).n,
a
where the sum is taken over all permutations a oj {l, .. . , n}, and /;(a) is the
sign oj the permutation.
ProoJ.
Let el , . . • , en be the unit vectors as usual. We can write
Therefore
D(A I , . .. , An) = L£(a)a"(I).1 ... a,,(n).n
a
by the lemma. This proves that the value of the determinant is uniquely deter-
mined and is given by the expected formula.
Corollary 4.7.
Let cp : R --+ R' be a ring-homomorphism into a commutative
ring. IJ A is a square matrix in R, define cpA to be the matrix obtained by
applying cp to each componentoj A. Then
cp(D(A»
= D(cpA).
Proof.
Apply cp to the expression of Proposition 4.6.
Proposition 4.8.
IJ A is a square matrix in R then
D(A) = D('A).
Proof.
In a product
a,,( 1).1 . . . a,,(n).n
each integer k from 1to noccurs precisely once among the integers a(1), . .. , a(n).
Hence we can rewrite this product in the form

XIII, §4
DETERMINANTS
515
Since £(0") = £(0"-1), we can rewrite the sum in Proposition 4.6 in the form
L £(O" - I)al.a- I (1 ) • . • an,a
I (n)'
a
In this sum, each term corresponds to a permutation 0". However, as 0" ranges
over all permutations, so does 0"-1. Hence our sum is equal to
L £(O")al ,a(l) .. . an, a(n),
a
which is none other than DCA), as was to be shown.
Corollary 4.9.
The determinant is multilinear and alternating with respect
to the rows of a matrix.
We shall now prove existence, and prove simultaneously one additional
important property of determinants.
When n = 1, we define D(a) = a for any a E R.
Assume that we have proved the existence of determinants for all integers
< n (n ~ 2). Let A be an n x n matrix in R, A = (aij)' We let Aij be the
(n -
1) x (n -
1) matrix obtained from A by deleting the i-th row and j-th
column. Let i be a fixed integer, 1 ~ i ~ n. We define inductively
D(A) = (-1y+ lailD(Ail) + ... + (-I)i +nainD(Ain)'
(This is known as the expansion of D according to the i-th row.) We shall prove
that D satisfies the definition of a determinant.
Consider D as a function of the k-th column, and consider any term
(-lY+iaijD(Ai).
Ifj =1= k then aij does not depend on the k-th column, and D(Ai) depends linearly
on the k-th column. Ifj = k, then aij depends linearly on the k-th column, and
D(Ai) does not depend on the k-th column. In any case our term depends
linearly on the k-th column. Since D(A) is a sum of such terms,it depends linearly
on the k-th column, and thus D is multilinear.
Next, suppose that two adjacent columns of A are equal, say Ak = Ak+ I .
Letj be an index
=1= k and =1= k + 1. Then the matrix Aij has two adjacent equal
columns, and hence its determinant is equal to O. Thus the term corresponding
to an index j
=1= k or k + 1 gives a zero contribution to D(A). The other two
terms can be written
The two matrices Aik and Ai,k+1 are equal because of our assumption that the
k-th column of A is equal to the (k + l)-th column. Similarly, aik = ai,k+I'

516
MATRICES AND LINEAR MAPS
XIII, §4
Hence these two terms cancel since they occur with opposite signs. This proves
that our form is alternating, and gives:
Proposition 4.10.
Determinants exist and satisfy the rule of expansion
according to rows and columns.
(For columns, we use the fact that D(A) = DCA).)
Example.
We mention explicity one of the most important determinants.
Let XI ' • .• , xn be elements of a commutative ring. The Vandermonde deter-
minant V = V(xl"
. . , xn ) of these elements is defined to be
X2
V=
whose value can be determined explicitly to be
V = Il (x, -
Xi) '
i<j
J
If the ring is entire and Xi '* Xj for i '* j, it follows that V '* 0. The proof for
the stated value is done by multiplying the next to the last row by XI and subtracting
from the last row. Then repeat this step going up the rows, thus making the
elements of the first column equal to 0, except for I in the upper left-hand corner.
One can then expand according to the first column, and use the homogeneity
property and induction to conclude the proof of the evaluation of V.
Theorem4.11.
Let E be a module over R, and let VI' • •• , Vn be elements ojE.
Let A = (a;) be a matrix in R, and let
Let A be an n-multilinear alternating map on E. Then
Proof.
Weexpand
and find precisely what we want, taking into account D(A) = DCA).

XIII, §4
DETERMINANTS
517
Let E, F be modules, and let L:(E, F) denote the set of n-multilinear alter-
nating maps of E into F. If F = R, we also writeL:(E, R) = L:(E). It is clear
that L:(E, F) is a module over R, i.e. is closed under addition and multiplication
by elements of R.
Corollary 4.12.
Let E beafree moduleoverR, andlet {vj , • •• , vn } be a basis.
Let F be any module, and let WE F. There exists a unique n-multilinear
alternating map
~w : Ex · . . x E --+ F
suchthat ~w(Vj, . . . , vn) = w.
Proof.
Without loss of generality, we may assume that E = R(n), and then,
if A j, • • • , Anare column vectors, we define
~w(A j, ••• , An) = D(A)w.
Then ~w obviously has the required properties.
Corollary 4.13.
If E isfree over R, and has a basisconsisting ofn elements,
then L:(E) isfree over R, and has a basisconsisting of 1 element.
Proof.
We let AI be the multilinear alternating map taking the value 1 on a
basis {v j , • •• , vn}. Any element q> E L:(E) can then be written in a unique way
as C~l' with some c E R, namely c = q>(v j , • •• , vn) . This proves what we wanted.
Any two bases of L:(E) in the preceding corollary differ by a unit in R. In
other words, if ~ is a basis of L:(E), then ~ =
C~l =
~c for some c E R, and c
must be a unit. Our ~ j depends of course on the choice of a basis for E. When
we consider R(nl, our determinant D is precisely ~1' relative to the standard
basis consisting of the unit vectors e1, • . . , en.
It is sometimes convenient terminology to say that any basis of L:(E) is a
determinant on E. In that case, the corollary to Cramer's rule can be stated as
follows.
Corollary 4.14.
Let R be a field. Let E be a vector space of dimension n.
Let ~ be any determinant on E. Let V j , •• • , Vn E E. In order that {V\l"" vn}
be a basis of E it is necessary and sufficientthat
Proposition 4.15.
Let A, B be n x n matricesin R. Then
D(AB) = D(A)D(B).

518
MATRICES AND LINEAR MAPS
XIII, §4
Proof.
This is actually a corollary of Theorem 4.11. We take Vl> "
"
Vn
to be the unit vectors e', ... , en, and consider
We obtain
D(w" .. . , wn) = D(AB)D(e', . .. , en).
On the other hand, by associativity, applying Theorem 4.11 twice,
D(w1, •• • , wn) = D(A)D(B)D(e', . .. , en).
Since D(e1, • •• , ~) = 1, our proposition follows.
Let A = (aij) be an n x n matrix in R. We let
A = (bij)
be the matrix such that
i+j
)
bij = (-1)
D(Aj i •
(Note the reversal of indices!)
Proposition 4.16.
Let d = D(A). Then AA = AA = dI. The determinant
D(A) is invertible in R ifand only if A is invertible, and then
A-l=~A­
d
.
Proof
For any pair of indices i, k the ik-component of AA is
If i = k, then this sum is simply the expansion of the determinant according
to the i-th row, and hence this sum is equal to d. If i =/: k, let A be the matrix
obtained from A by replacing the k-th row by the i-th row, and leaving all other
rows unchanged. Ifwedelete the k-th row and thej-th column from A,weobtain
the same matrix as by deleting the k-th row and j-th column from A. Thus
and hence our sum above can be written

XIII, §4
DETERMINANTS
519
This is the expansion of the determinant of A according to the i-th row. Hence
D(A) = 0, and our sum is O. We have therefore proved that the ik-component
of AA is equal to d if i = k (i.e. if it is a diagonal component), and is equal to 0
otherwise. This proves that AA = dI. On the other hand, we see at once from
the definitions that ?4 =
~ . Then
and consequently, AA = dI also, since t(dI) = dI. When d is a unit in R, then A
is invertible, its inverse being d- 1A. Conversely, if A is invertible, and AA - 1 = I,
then D(A)D(A -1) = 1, and hence D(A) is invertible, as was to be shown.
Corollary 4.17.
Let F be any R-module, and let WI' ... • Wn be elements of
F. Let A = (a(;) be an n X n matrix in R. Let
allwi + ... + alnwn = VI
Then one can solve explicitly
(
D(~)W I )
(~I)
_(~ J)
:
= D(A)
:
= A
:
.
D(A)wn
wn
vn
In particular, if Vi = 0 for all i. then D(A)wi = 0 for all i. If Vi = 0 for all i
and F is generated by wI• . . . , wn' then D(A)F = O.
Proof.
This is immediate from the relation AA = D(A)/, using the remarks
in §3 about applying matrices to column vectors whose components lie in the
module.
Proposition 4.18.
Let E, F be free modules of dimension n over R. Let
f: E -> F be a linear map. Let CB, CB' be bases of E, F respectively over R.
Then f is an isomorphism if and only if the determinant of its associated
matrix M~{f) is a unit in R.
Proof
Let A =
M~ .(f).
By definition, f is an isomorphism if and only
if there exists a linear map 9 : F -> E such that 9 0 f = id and f og = id. If f is
an isomorphism, and B = M~'(g), then AB = BA = I. Taking the determinant
of the product, we conclude that D(A) is invertible in R. Conversely, if D(A)
is a unit, then we can define A-I by Proposition 4.16 . This A-I is the associated
matrix of a linear map g :F ~ E which is an inverse for f, as desired.
Finally, we shall define the determinant of an endomorphism.

520
MATRICES AND LINEAR MAPS
XIII, §4
Let E be a free module over R, and let (B be a basis. Let J:E -+ E be an
endomorphism of E. Let
If (B' is another basis of E, and M' = M~ :(J), then there exists an invertible
matrix N such that
Taking the determinant, we see that D(M') = D(M). Hence the determinant
does not depend on the choice of basis, and will be called the determinant of the
linear mapf
We shall give below a characterization of this determinant which
does not depend on the choice of a basis.
Let E be any module. Then we can view L:(E) as a functor in the variable E
(contravariant). In fact, we can view L:(E, F) as a functor of two variables,
contravariant in the first, and covariant in the second. Indeed, suppose that
E'4E
is a linear map.
To each multilinear map cp : E(n) -+ F we can associate the
composite map cp 0 pn),
E' x ... X E'~Ex .. · x E ~ F
where pn)is the product ofJ with itself n times. The map
L:(J) : L:(E, F) -+ L:(E', F)
given by
cp f-+ cp 0 p n),
is obviously a linear map, which defines our functor. We shall sometimes write
f* instead of L;U)·
In particular, consider the case when E = E' and F = R. We get an induced
map
Proposition 4.19.
LetEbeafree moduleoverR,ojdimensionn.Let{A} bea
basisoj L:(E). Let J: E -+ E be an endomorphism oj E. Then
J*b. = D(J)b..
Proof
This is an immediate consequence of Theorem 4.11. Namely, we
let {v" . . ., vn } be a basis of E, and then take A (or
~) to be a matrix ofJ relative
to this basis. By definition,
J*b.(v " .. . , vn) = b.(J(v,), .. . ,J(vn»,

XIII, §4
DETERMINANTS
521
and by Theorem 4.11, this is equal to
D(A) ~(VI" .. , Vn)'
By Corollary 4.12, we conclude thatf*~ = D(A)~ since both of these forms take
on the same value on (VI" . . , vn)'
The above considerations have dealt with the determinant as a function on
all endomorphisms of a free module . One can also view it multiplicatively, as
a homomorphism.
det : GLn(R) -+ R*
from the group of invertible n x n matrices over R into the group of units of R.
The kernel of this homomorphism, consisting of those matrices with deter-
minant I, is called the special linear group, and is denoted by SL.(R).
We now give an application of determinants to the situation of a free module
and a submodule considered in Chapter III, Theorem 7.8 .
Proposition 4.20.
Let R be a principal entire ring. Let F be a free module
over R and let M be a finitely generated submodule. Let {el • . . . . em' . . . } be
a basis ofF such that there exist non-zero elements ai , . .. • am E R such that:
(i) The elements al e). . . . . amemform a basis of Mover R.
(ii) We have aj Iaj+) for i = 1, . . . , m -
1.
Let L~ be the set of all s-multilin ear alternating forms on F. Let i s be the ideal
generated by all elements f(y ). . . . . ys)' with f E L~ and y ), . . . • ys EM. Then
i s = (a , . . . as)'
Proof
We first show that J s c (a I . . . as)' Indeed, an element y E M can be
written in the form
Hence if YI, . . . •Ys EM, andfis multilinear alternating on F, thenj'(y., . .. , Ys)
is equal to a sum in terms of type
This is non-zero only when ei"
, • • , eis are distinct, in which case the product
al ... as divides this term, and hence i s is contained in the stated ideal.
Conversely, we show that there exists an s-multilinear alternating form which
gives precisely this product. We deduce this from determinants. We can write
F as a direct sum
F = (e" . . " er)Ej;)Fr

522
MATRICES AND LINEAR MAPS
XIII, §5
with some submodule Fr . Let j; (i = 1, ... , r) be the linear map F --+ R such
that/;(e) = Dij , and such thatj, has value 0 on Fr. For VI ' •• • , Vs E F we define
f(VI> .. . , vs) = det(/;(v) .
Then f is multilinear alternating and takes on the value
f(e z, .. . , es) = 1,
as well as the value
This proves the proposition.
The uniqueness of Chapter III, Theorem 7.8 is now obvious, since first (a\)
is unique, then (a ta2) is unique and the quotient (a2) is unique, and so forth by
induction.
Remark.
Compare the above theorem with Theorem 2.9 of Chapter XIX,
in the theory of Fitting ideals , which gives a fancier context for the result.
§5.
DUALITY
Let R be a commutative ring, and let E, F be modules over R. An R-
bilinear form on E x F is a map
f:E x F--+R
having the following properties: For each x E E, the map
y 1-+ f(x, y)
is R-linear, and for each y E F, the map
x 1-+ f(x, y)
is R-linear. We shall omit the prefix R- in the rest of this section, and write
( x, y) f or ( x, y) instead of f(x, y). If x E F, we write x 1.)' if ( x, y) = O.
Similarly, if S is a subset of F, we define x 1. S if x 1. y for all yES. We then say
that x is perpendicular to S. We let SJ. consist of all elements of E which are
perpendicular to S. It is obviously a submodule of E. We define perpendicu-
larity on the other side in the same way. We define the kernel offon the left
to be Flo and the kernel on the right to be E1.. We say thatfis non-degenerate
on the left if its kernel on the left is O. We say thatf is non-degenerate on the
right if its kernel on the right is O. If Eo is the kernel offon the left, then we

XIII, §5
get an induced bilinear map
DUALITY
523
EIEo x F -. R
which is non-degenerate on the left, as one verifies trivially from the definitions.
Similarly, if F 0 is the kernel ofJ on the right, we get an induced bilinear map
EIEo x FIFo -. R
which is non-degenerate on either side. This map arises from the fact that the
value ( x, y) depends only on the coset of x modulo Eo and the coset of y
modulo Fo.
We shall denote by L2(E, F; R) the set of all bilinear maps of E x F into R.
It is clear that this set is a module (i.e. an R-module), addition of maps being the
usual one, and also multiplication of maps by elements of R.
The form J gives rise to a homomorphism
({JI: E -. HomR(F, R)
such that
((Jix)(y) = J(x, y) = (x, y ),
for all xeEandyeF. We shall call HomR(F, R) the dual module ofF, and denote
it by FV• We have an isomorphism
given by JI-+ ({JI' its inverse being defined in the obvious way: If
({J : E -. HomR(F, R)
is a homomorphism, we let J be such that
J(x, y) = ({J(x)(y).
We shall say that J is non-singular on the left if ({JI is an isomorphism, in
other words if our form can be used to identify E with the dual module of F.
We define non-singular on the right in a similar way, and say that J is non-
singular if it is non-singular on the left and on the right.
Warning :
Non-degeneracy does not necessarily imply non-singularity.
We shall now obtain an isomorphism
depending on afixed non-singular bilinear mapJ :E x F -. R.

524
MATRICES AND LINEAR MAPS
Let A E EndR(E) be a linear map of E into itself. Then the map
(x, y) 1---+ <Ax, y ) = <Ax, y ) f
XIII, §5
is bilinear, and in this way, we associate linearly with each A E EndR(E)a bilinear
map in L2(E, F;R).
Conversely, let h : E x F ..... R be bilinear. Given x E E, the map h, :F ..... R
such that hiy) = h(x, y) is linear, and is in the dual space FV• By assumption,
there exists a unique element x' E E such that for all y E F we have
h(x, y) = ( x', y ) .
It is clear that the association x 1---+ x' is a linear map of E into itself. Thus with
each bilinear map E x F ..... R we have associated a linear map E ..... E.
It is immediate that the mappings described in the last two paragraphs are
inverse isomorphisms between EndR(E) and L 2(E, F ; R). We emphasize of
course that they depend on our form [.
Of course, we could also have worked on the right, and thus we have a
similar isomorphism
dependingalso on ourfixed non-singular form f
As an application, let A : E ~ E be linear , and let (x, y) 1---+ (Ax, y) be its
associated bilinear map. There exists a unique linear map
such that
<Ax, y) = ( x, 'Ay )
for all x E E and y E F. We call
IA the transpose of A with respect tof
It is immediately clear that if, A, B are linear maps of E into itself, then for
cER,
More generally, let E, F be modules with non-singular bilinear forms denoted
by ( ,
)E and ( ,
)F respectively. Let A : E ~ F be a linear map. Then by the
non-singularity of ( ,
)E there exists a unique linear map 'A: F ~ E such that
(Ax, Y)F = (x, 'AY)E for all x E E and Y E F .
We also call 'A the transpose with respect to these forms.
Examples.
For a nice classical example of a transpose, see Exercise 33.
For the systematic study when a linear map is equal to its transpose, see the

XIII, §5
DUALITY
525
spectral theorems of Chapter XV. Next I give another example of a transpose
from analysis as follow s. Let E be the (infinite dimen sional) vector space of
exfunctions on R, having compact support, i.e. equal to 0 outs ide some finite
interval. We define the scalar product
oc
(j, g) = Jj(x)g(x)dx.
Let D: E ~ E be the derivative. Then one has the formula
(Dj, g) = -(j, Dg).
Thus one says that 'D = - D , even though the scalar product is not "non-singular",
but much of the formalism of non-singular forms goes over. Also in analysis,
one puts various norms on the spaces and one extends the bilinear form by
continuity to the completions, thus leaving the domain of algebra to enter the
domain of estimates (analysis). Then the spectral theorems become more com-
plicated in such analytic contexts.
Let us assume that E = F. Let f : E x E -+ R be bilinear.
By an auto-
morphism of thepair(E,J), or simply off, we shall mean a linear automorphism
A : E -+ E such that
( Ax, Ay ) = ( x, y )
for all x, y E E. The group of automorphisms of f is denoted by Aut(f).
Proposition 5.1.
Let f :E x E -+ R be a non-singular bilinear form . Let
A: E -+ E be a linear map. Th en A is an automorphism of f if and only if
'AA = id, and A is invertible.
Proof
From the equality
( x, y ) = ( Ax, Ay) = ( x, 'AAy )
holding for all x, y E E, we conclude that 'AA = id if A is an automorphism off
The converse is equally clear.
Note.
If E is free and finite dimensional, then the condition 'AA = id
implies that A is invertible.
Let f :E x E -+ R be a bilinear form.
We say that f is symmetric if
f(x, y) = Its.x) for all x, y E E. The set of symmetric bilinear forms on E will
be denoted by L;(E). Let us take a fixed symmetric non-singular bilinear form
.r on E, denoted by (x, y) H
( x, .1') . An endomorphism A: E -+ E will be said
to be symmetric with respect to f if 'A = A. It is clear that the set of sym-
metric endomorphisms of E is a module, which we shall denote by Sym(E).

526
MATRICES AND LINEAR MAPS
XIII, §5
Depending on our fixed symme tric non-singular f, we have an isomorphism
which we describe as follows. If 9 is symmetric bilinear on E, then there exists
a unique linear map A such that
g(x , y) = (Ax , y)
for all x, y E E. Using the fact that both f , 9 are symmetric, we obtain
( Ax, y ) = ( Ay, x ) = ( y, tAx ) = ( tAx, y).
Hence A = tAo The association 9 1---+ A gives us a homomorphism from L;(E)
into Sym(E). Conversely, given a symmetric endomorphism A of E, we can
define a symmetric form by the rule (x, y) 1---+ ( Ax, y), and the association of
this form to A clearly gives a homomorphism of Sym(E) into L ;(E) which is
inverse to the preceding homomorphism. Hence Sym(E) and L;(E) are iso-
morphic.
We recall that a bilinear form g: E x E -+ R is said to be alternating if
g(x, x ) = 0 for all x E E, and consequently g(x, y) = -g(y, x) for all x, y E E.
The set of bilinear alternating forms on E is a module, denoted by L;(E).
Let f be a fixed symmetric non-singular bilinear form on E. An endo-
morphism A : E -t E will be said to be skew-symmetric or alternating with
respect to! if tA =
- A, and also ( Ax, x ) = 0 for all x E E. If for all a E R,
2a = 0 implies a = 0, then this second condition ( Ax, x ) = 0 is redundant,
because ( Ax, x ) = - ( Ax, x ) implies ( Ax, x ) = O. It is clear that the set of
alternating endomorphisms of E is a module, denoted by Alt(E). Depending
on our fi xed symmetric non-singular form ! , we have an isomorphism
L~ (E) ..... Alt(E)
described as usual. If 9 is an alternating bilinear form on E, its corresponding
linear map A is the one such that
g(x, y) = ( Ax, y )
for all x, y E E. One verifies trivially in a manner similar to the one used in the
symmetric case that the correspondence g ..... A gives us our desired iso-
morphism.
Examples.
Let k be a field and let E be a finite-dimensional vector space
over k. Let j": E x E ~ E be a bilinear map, denoted by (x, y) 1---+ xy . To each

XIII, §6
MATRICES AND BILINEAR FORMS
527
X E E, we associate the linear map Ax : E H E such that
Then the map obtained by taking the trace, namely
is a bilinear form on E. If xy = yx, then this bilinear form is symmetric.
Next, let E be the space of continuous functions on the interval [0, 1]. Let
K(s, t) be a continuous function of two real variables defined on the square
°~ s ~ 1 and°~ t ~ 1. For sp, IjJ E E we define
<<p, 1jJ) = ff<p(s)K(s, t)ljJ(t) dsdt,
the double integral being taken on the square. Then we obtain a bilinear form
on E. IfK(s, t) = Kit, s), then the bilinear form is symmetric. When we discuss
matrices and bilinear forms in the next section, the reader will note the similarity
between the preceding formula and the bilinear form defined by a matrix.
Thirdly, let U be an open subset of a real Banach space E (or a finite-dimen-
sional Euclidean space, if the reader insists), and let f : U ~ R be a map which
is
twice
continuously
differentiable.
For
each
x E U,
the
derivative
Df(x) :E -> R is a continuous linear map, and the second derivative D2f(x)
can be viewed as a continuous symmetric bilinear map of E x E into R.
§6.
MATRICES AND BILINEAR FORMS
We shall investigate the relation between the concepts introduced above and
matrices. Letf :E x F ~ R be bilinear. Assume that E, F are free over R. Let
CB = {VI , . .. , vm } be a basis for E over R, and let CB' = {WI, . . . , wn } be a basis
for F over R. Let gij =
<Vb Wj ) ' If
and
are elements of E and F respectively, with coordinates X b Yj E R, then
m
n
<x,y) = L L gijXiYj-
i = I
j = I

528
MATRICES AND LINEAR MAPS
XIII, §6
Let X, Y be the column vectors of coordinates for x, Y respectively, with respect
to our bases. Then
( x, y) = 'XGY
where G is the matrix (gj)' We could write G = M~ .(f). We call G the matrix
associated with the Cormfrelative to the bases <B, <B'.
Conversely, given a matrix G (of size m x n), we get a bilinear form from
the map
In this way, we get a correspondence from bilinear forms to matrices and back ,
and it is clear that this correspondence induces an isomorphism(of R-modules)
given by
jf-. M~,(f).
The two maps between these two modules which we described above are clearly
inverse to each other.
If we have
bases <B={vl, . . . , vn }
and
<B'={wl, . .. , wn }
such
that
<Vj, wj ) = 6;j' then we say that these bases are dual to each other. In that case,
if X is the coordinate vector of an element of E, and Y the coordinate vector of
an element of F, then the bilinear map on X , Y has the value
X· Y = XIYI + ... + XnYn
given by the usual dot product.
It is easy to derive in general how the matrix G changes when we change
bases in E and F. However, we shall write down the explicit formula only when
E = F and <B = <B'. Thus we have a bilinear form j: E x E --+ R. Let e be
another basis of E and write X (Il and Xe for the column vectors belonging to
an element x of E, relative to the two bases. Let C be the invertible matrix
M~(id) , so that
X(Il = CXe ·
Then our form is given by
We see that
(1)
In other words, the matrix of the bilinear form changes by the transpose.

XIII, §6
MATRICES AND BILINEAR FORMS
529
If F is free over R. with a basis {'T/]•. . . , 'T/ll}' then HomR(F, R) is also free.
and we have a dual basis {'T/\, . . . ,
'T/~ } such that
'T/; ('T/j) = aij'
This has already been mentioned in Chapter Ill, Theorem 6.1.
Proposition 6.1.
Let E, F be free modules of dimension n over R and let
f :E x F -+ R be a bilinear form. Then the following conditions are equiv-
alent:
f is non-singular on the left .
f is non-singularon the right.
f is non-singular.
The determinantofthe matrix of f relative to any bases is invertible in R.
Proof
Assume that f is non-singular on the left. Fix bases of E and F
relative to which we write elements of these modules as column vectors, and
giving rise to the matrix G forf Then our form is given by
(X , y) f-+ 'XGY
where X, Yare column vectors with coefficients in R. By assumption the map
X f-+ 'X G
gives an isomorphism between the module of column vectors, and the module
of row vectors of length n over R. Hence G is invertible, and hence its deter-
minant is a unit in R. The converse is equally clear, and if det(G) is a unit, we
see that the map
Y-+ GY
must also be an isomorphism between the module of column vectors and itself.
This proves our assertion.
We shall now investigate how the transpose behaves in terms of matrices.
Let E, F be free over R, of dimension n.
Letf :E x F -+ R be a non-singular bilinear form, and assume given a basis
(B of E and (B' of F. Let G be the matrix off relative to these bases. Let
A : E -+ E be a linear map. If x E E, y E F, let X , Y be their column vectors
relative to (B, (B'. Let M be the matrix of A relative to (B. Then for x E E and
y E F we have
<Ax, y ) = '(MX)GY = 'X'MGY.
Let N be the matrix of 'A relative to the basis (B'. Then N Y is the column vector
of lAy relative to (B'. Hence
<x, lAy ) = IX GN Y.

530
MATRICES AND LINEAR MAPS
XIII, §6
From this we conclude that fMG = GN, and since G is invertible, we can solve
for N in terms of M. We get :
Proposition 6.2.
Let E, F befree over R, ofdimension n. Letf :E x F -> R
be a non-singular bilinear f orm. Let eB, eB' be bases of E and F respectively
over R, and let G be the matrix of f relative to these bases. Let A : E -> E be a
linear map, and let M be its matrix relati ve to eB.
Th en the matrix of fA
relative to eB' is
Corollary 6.3.
If G is the unit matrix, then the matrix of the transpose is
equal to the transpose of the matrix.
In terms of matrices and bases, we obtain the following characterization
for a matrix to induce an automorphism of the form.
Corollary 6.4.
Let the notation be as in Proposition 6.2, and let E = F,
eB = eB'. An n x n matrix M is the matrix of an automorphism of the form
f (relati ve to our basis) if and only if
'MGM = G.
If this condition is satisfied, then in particular, M is invertible.
Proof.
We use the definitions, together with
the formula given in
Proposition 6.2. We note that M is invertible, for instance because its deter-
minant is a unit in R.
A matrix M is said to be symmetric (resp. alternating) if 'M = M (resp.
'M = - M and the diagonal elements of Mare 0).
Let f: E x E -> R be a bilinear form.
We say that f is symmetric if
f(x, y) = f( y, x) for all x, y E E. We say that f is alternating iff(x, x) = 0 for
all x E E.
Proposition 6.5.
Let E be a fre e module of dimension n over R, and let eB
be a fixed basis. Th e map
f f-> M~(f)
induces an isomorphism between the module of symmetric bilinear forms on
E x E (resp. the module of alternating forms on E x E) and the module of
symmetric n x n matrices over R (resp. the module of alternating n x n
matrices over R).

XIII, §7
SESQUILINEAR DUALITY
531
Proof.
Consider first the symmetric case. Assume thatf is symmetric. In
terms of coordinates, let G =
M~(f). Our form is given by rXGY which must
be equal to 'YGX by symmetry. However, IXGY may be viewed as a 1 x 1
matrix, and is equal to its transpose, namely lylGX. Thus
for all vectors X, Y. It follows that G = IG. Conversely, it is clear that any
symmetric matrix defines a symmetric form.
As for the alternating case, replacing x by x + y in the relation ( x, x) = 0
we obtain
<x, y) + <y,x) = o.
In terms of the coordinate vectors X, Y and the matrix G, this yields
'XGY + IYGX = O.
Taking the transpose of, say, the second of the 1 x I matrices entering in this
relation, yields (for all X , Y) :
'XGY + IXIGY = O.
Hence G + 'G = O. Furthermore, letting X be anyone of the unit vectors
'(0, . . . , 0, I, 0, .. . , 0)
and using the relation 'XGX = 0, we see that the diagonal elements of G
must be equal to O. Conversely, if G is an n x n matrix such that 'G + G = 0,
and such that gii = 0 for i = I, . . . , n then one verifies immediately that the
map
defines an alternating form. This proves our proposition.
Of course, if as is usually the case, 2 is invertible in R, then our condition
1M = - M implies that the diagonal elements of M must be O. Thus in that
case, showing that G + 'G = 0 implies that G is alternating.
§7.
SESQUILINEAR DUALITY
There exist forms which are not quite bilinear, and for which the results
described above hold almost without change, but which must be handled
separately for the sake of clarity in the notation involved.

532
MATRICES AND LINEAR MAPS
XIII, §7
Let R have an automorphism of period 2. We write this automorphism as
a t-> a(and think of complex conjugation).
Following Bourbaki, we say that a map
f :E x F-+R
is a sesquilinear form if it is Z-bilinear, and if for x E E, Y E F, and a E R we
have
f(ax, y) = af(x, y)
and
f(x, ay) = af(x. y).
(Sesquilinear means
l~ times linear, so the terminology is rather good.)
Let E, E' be modules. A map qJ :E -+ E' is said to be anti-linear (or semi-
linear) if it is Z-Iinear, and qJ(ax) = aqJ(x) for all x E E. Thus we may say that
a sesquilinear form is linear in its first variable, and anti-linear in its second
variable. We let HomR(E, E') denote the module of anti-linear maps of E
into E'.
We shall now go systematically through the same remarks that we made
previously for bilinear forms .
We define perpendicularity as before, and also the kernel on the right and
on the left for any sesquilinear form f. These kernels are submodules, say Eo
and F 0 ' and we get an induced sesquilinear form
EIEo x FIFo -+ R,
which is non-degenerate on either side.
Let F be an R-module. We define its anti-module Fto be the module whose
additive group is the same as F, and such that the operation R x F -+ F is
given by
(a, y) t-> ay.
Then F is a module. We have a natural isomorphism
as R-modules.
The sesquilinear form f: E x F -+ R induces a linear map
qJf : E -+ HomR(F, R).
We say thatf is non-singular on the left if qJf is an isomorphism. Similarly, we
have a corresponding linear map

XIII, §7
SESQUILINEAR DUALITY
533
from F into the dual space of E, and we say that f is non-singular on the right
if qJf is an isomo rphism. We say that f is non-singular if it is non-singular on
the left and on the right.
We observe that our sesquilinear formf can be viewed as a bilinear form
f :E x F --+ R,
and that our not ions of non-singularity are then compatible with those defined
previou sly for bilinear form s.
If we have a fixed non-singular sesquilinear form on E x F, then depending
on th is form, we obtain an isomorphism between the module of sesquilinear
forms on E x F and the module of endomorphisms of E. We also obtain an
anti-isomorphism between these modules and the module of end omorphisms
of F. In particular, we can define the analogue of the transpose, which in the
present case we shall call the adjoi nt. Thus, letf :E x F --+ R be a non-singular
sesquilinear form. Let A : E --+ E be a linear map. There exists a unique linear
map
A* :F--+F
such that
( Ax, y) = ( x, A*y )
for all x E E and y E F. Note that A* is linear, not anti-linear. We call A* the
adjoint of A with respect to our forrn j. We have the rules
(cA)* = cA*,
(A + B)* = A* + B*,
(A B)* = B*A*
for all linear maps A, B of E into itself, and c E R.
Let us assume that E = F.
Let f :E x E --+ R be sesquilinear.
By an
automorphism offwe shall mean a linear automorphism A : E --+ E such that
( Ax, Ay) = ( x, y )
ju st as we did for bilinear form s.
Proposition 7.1.
Let f: E x E --+ R be a non-singular sesquilinear form.
Let A : E --+ E be a linear map. Then A is an automorphism of f if and only
if A*A = id, and A is invertible.
The proof, and also the proofs of subsequent propositions, which are
completely similar to those of the bilinear case, will be omitted.
A sesquilinear form g : E x E --+ R is said to be hermitian if
g(x, y) = g(y, x)
for all x, y E E. The set of hermitian forms on E will be denoted by L~(E) . Let
Ro be the subring of R consisting of all elements fixed under our automorphism

534
MATRICES AND LINEAR MAPS
XIII, §7
a --. ii (i.e. cons isting of all elements a E R such that a = ii). Then L~(E) is an
Ro-module.
Let us take a fixed hermitian non-singular form f on E, denoted by
(x, y) 1-+ ( x, y ).
An endomorphism A : E --. E will be said to be hermitian
with respect tof if A* = A. It is clear that the set of hermitian endomorphisms
is an Ro-module, which we shall denote by Herm(E). Depending on our fixed
hermitiannon-singular form f , we have an Ro-isomorphism
L~(E) <--+ Herm(E)
described in the usual way. A hermitian form g corresponds to a hermitian
map A if and only if
g(x, y) = <Ax, y)
for all x, y E E.
We can now describe the relation between our concepts and matrices, just
as we did with bilinear forms .
We start with a sesquilinear form f: E x F --. R.
If E, F are free, and we have selected bases as before, then we can again
associate a matrix G with the form , and in terms of coordinate vectors X, Y
our sesquilinear form is given by
(X, y) 1-+ 'XGY,
where Y is obtained from Y by applying the automorphism to each component
of Y.
If E = F and we use the same basis on the right and on the left, then with
the same notation as that used in formula (1), iff is sesquilinear, the formula
now reads
(1S)
The automorphism appears.
Proposition 7.2.
Let E, F be free modules of dimension n over R, and let
f: E x F -+ R be a sesquilinear form. Then the following conditions are
equivalent.
f is non-singular on the left .
f is non-singular on the right.
f is non-singular.
The determinant of the matrix of f relative to any bases is invertible in R.

XIII, §7
SESQUILINEAR DUALITY
535
Proposition 7.3.
Let E, F befree over R, ofdimension n. Let f :E x F ~ R
be a non-singular sesquilinearform. Let ill, ill' be bases of E and F respectively
over R, and let G be the matrix of f relative to these bases. Let A : E ~ E be
a linear map, and let M be its matrix relative to ill. Then the matrix of A*
relative to ill' is
Corollary 7.4.
If G is the unit matrix, then the matrix of A* is equal to 1M.
Corollary 7.5.
Let the notation be as in the proposition, and let ill = ill'
be a basis of E. An n x n matrix M is the matrix of an automorphism of f
(relative to our basis) if and only if
A matrix M is said to be hermitian if 1M = M.
Let Ro be as before the subring of R consisting of all elements fixed under
our automorphism a ~ a(i.e. consisting of all elements a E R such that a = a).
Proposition 7.6.
Let E be a free module of dimension n over R, and let ill
be a basis. The map
f ~ M~ (f)
induces an Ro-isomorphism between the Ro-module of hermitian forms on E
and the Ro-module of n x n hermitian matrices in R.
Remark.
If we had assumed at the beginning that our automorphism
a ~ ahas period 2 or I (i.e. if we allow it to be the identity), then the results
on bilinear and symmetric forms become special cases of the results of this
section. However, the notational differences are sufficiently disturbing to warrant
a repetition of the results as we have done.
Terminology
For some confusing reason, the group of automorphisms of a symmetric
(resp .alternating, resp. herm itian) form on a vector space is called the orthogonal
(resp. symplectic , resp. unitary) group of the form . The word orthogonal is
especially
unfortunate, because an orthogonal map preserves more than
orthogonality: It also preserves the scalar product, i.e. length.
Furthermore,
the word symplectic is also unfortunate. It turns out that one can carry out a
discussion of hermitian forms over certain division rings (ha ving automorphisms
of order 2), and their group of aut omorphisms have also been called symplectic,
thereby creating genu ine confus ion with the use of the word relati ve to alter-
nating forms.

536
MATRICES AND LINEAR MAPS
XIII, §8
In order to unify and improve the terminology, I have discussed the matter
with several persons, and it seems that one could adopt the following con-
ventions.
As said in the text, the group of automorphisms of any formjis denoted by
Aut(f).
On the other hand, there is a standard form, described over the real numbers
in terms of coordinates by
j(x, x) = xi + ... + x;,
over the complex numbers by
and over the quaternions by the same formula as in the complex case. The
group of automorphisms of this form would be called the unitary group, and
be denoted by Un' The points of this group in the reals (resp. complex, resp.
quaternions) would be denoted by
UiR),
UiC),
and these three groups would be called the real unitary group (resp. complex
unitary group, resp. quaternion unitary group). Similarly, the group of points
of U; in any subfield or subring k of the quaternions would be denoted by Un(k).
Finally, if j is the standard alternating form, whose matrix is
one would denote its group of automorphisms by A 2n , and call it the alternating
form group, or simply the alternating group, if there is no danger of confusion
with the permutation group. The group of points of the alternating form
group in a field k would then be denoted by A2ik).
As usual, the subgroup of Aut(f) consisting of those elements whose
determinant is I would be denoted by adding the letter S in front, and would
still be called the special group. In the four standard cases, this yields
SUiR),
SUiC),
SUn(K),
§8.
THE SIMPLICITY OF SL 2(F)/ ± 1
Let F be a field. Let n be a positive integer. By GLn(F) we mean the group
of n x n invertible matrices over F. By SLn(F) we mean the subgroup of those
matrices whose determinant is equal to I.
By PGLn(F) we mean the factor
group of GLn(F) by the subgroup of scalar matrices (which are in the center).

XIII, §8
THE SIMPLICITY OF SL2(Fl / ±1
537
Similarly for PSLn(f}
In this section, we are interested in giving an applicati on
of mat rices to the group theoretic structure of SL 2 • The analogo us sta tements
for SLn with n ~ 3 will be proved in the next section.
The standard Borel subgroup B of GL 2 is the group of all matrices
with a, b, d e F and ad =f. O.
For the Borel subgroup of SL 2 , we require in
addition that ad = I.
By a Borel subgroup we mean a subgro up which is
conjugate to the sta nda rd Borel subgro up (whether in GL 2 or SL 2 ) . We let
U be the group of matrices
u(b) = (~
~),
with b E F.
We let A be the group of diagonal matrices
(~
~),
with a, d e P.
Let
with a E P
and
IV = ( 0 I).
-I
0
For the rest of this section, we let
G = GL iF)
or
SLiF).
Lemma 8.1.
Th e matrices
X(b) = G~)
and
Y(c) = C~)
generate SLiF).
Proof .
Multiplying an arbitrary element of SL 2(F) by matrices of the
above type on the right and on the left corresponds to elementary row and
column operations, that is adding a scalar multiple of a row to the other, etc.
Thus a given matrix can always be brought into a form
(~
a~ l)

538
MATRICES AND LINEAR MAPS
XIII, §8
by such multipl ications. We want to express this matrix with a * I in the form
Matrix multiplication will show that we can solve this equation, by selecting x
arbitrarily * 0, then solving for b, c, and d successively so that
-x
-b
I + bx = a,
e = I + bx '
d = I + be '
Then one finds I + be = (l + xb) -I and the two symmetric conditions
b + bed + d =°
e + bex + x = 0,
so we get what we want , and thereby prove the lemma .
Let D be the group of lower matrices
Then we see that
Also note the commutation relation
so w normalizes A. Similarly,
wBw- 1 = lJ
is the group of lower triangular matrices.
We note that
B = AV = VA,
and also that A normalizes V .
There is a decomposition of G into disjoint subsets
G = B u BwB.
Indeed, view G as operating on the left of column vectors. The isotropy group of
is obviously V . The orbit Bel consists of all column vectors whose second

XIII, §8
component is 0. On the other hand,
THE SIMPLICITY OF SL2(Fl/ ±1
539
and therefore the orbit Bwe' consists of all vectors whose second component
is =I: 0, and whose first component is arbitrary. Since these two orbits of Band
BwB cover the orbit Gel, it follows that the union of Band BwB is equal to G
(because the isotropy group U is contained in B), and they are obviously
disjoint. This decomposition is called the Bruhat decomposition.
Proposition 8.2.
The Borel subgroup B is a maximal propersubgroup.
Proof.
By the Bruhat decomposition, any element not in B lies in BwB,
so the assertion follows since B, BwB cover G.
Theorem 8.3.
IfF has at leastfour elements, then SLz(F) is equalto its own
commutatorgroup.
Proof.
We have the commutator relation (by matrix multiplication)
s(a)u(b)s(a)-lu(b)-l = u(ba2 -
b) = u(b(aZ -
1» .
Let G = SLzCF) for this proof. We let G' be the commutator subgroup, and
similarly let B' be the commutator subgroup of B. We prove the first assertion
that G = G'. From the hypothesis that F has at least four elements, we can
find an element a =I:°in F such that aZ =I: 1, whence the commutator relation
shows that B' = U. It follows that G' :::> U, and since G' is normal, we get
G':::>wUw- l.
From Lemma 8.1, we conclude that G' = G.
Let Z denote the center of G. It consists of ±I, that is ± the identity 2 x 2
matrix if G = SLz(F) ;and Z is the subgroup of scalar matrices if G = GLz(F).
Theorem 8.4.
IfF has at leastfour elements,then SLz(F)/Z is simple.
The proof will result from two lemmas.
Lemma 8.5.
The intersectionof all conjugatesof B in G is equal to Z.
Proof.
We leave this to the reader, as a simple fact using conjugation
with w.
Lemma 8.6.
Let G = SLz(F). If H is normal in G, then either H c Z or
H:::> G'.
Proof.
By the maximality of B we must have
HB = B
or
HB = G.

540
MATRICES AND LINEAR MAPS
XIII, §9
If HB = B then H c B. Since H is normal, we conclude that H is contained in
every conjugate of B, whence in the center by Lemma 8.5. On the other hand ,
suppose that HB = G. Write
w = hb
with h E H and b E B. Then
because H is normal. Since U c HU and U, Dgenerate SLiF), it follows that
HU = G. Hence
GjH = HUjH:::; Uj(U n H)
is abelian, whence H :::> G', as was to be shown.
The simplicity of Theorem 8.4 is an immediate consequence of Lemma 8.6.
§9.
THE GROUP SLn(F), n ~ 3.
In this section we look at the case with n ~ 3, and follow parts of Artin's
Geometric Algebra, Chapter IV. (Artin even treats the case of a non-commuta-
tive division algebra as the group ring, but we omit this for simplicity.)
For i,j = 1, . . . , nand i i=j and C E F, we let
o
be the matrix which differs from the unit matrix by having c in the ij-component
instead of O. We call such Eij(c) an elementary matrix. Note that
det Eij(c) = 1.
If A is any n x n matrix, then multiplication Eij(c)A on the left adds c times the
j-th row to the i-th row of A. Multiplication AEij(c) on the right adds c times
the i-th column to the j-th column. We shall mostly multiply on the left.
For fixed i i=j the map

XIII, §9
THE GROUP SLn(F), n ;;; 3
541
is a homomorphism of F into the mu ltiplicat ive group of n x n matrices
GLn(F).
Proposition 9.1.
The group SLn(F) is generated by the elementary matrices.
If A E GLiF), then A can be written in the form
A = SD.
where S E SLn(F) and D is a diagonal matrix oftheform
D =(~..~..•......~)
o 0
. . .
d
so D has I on the diagonal except on the lower right corner, where the com-
ponent is d = det(A).
Proof .
Let A E GLn(F). Since A is non-singular, the first component of
some row is not zero, and by an elementary row opera tion, we can make
aI I
=1= O. Adding a suita ble multiple of the first row to the second row, we make
a2 1 =1= 0, and then adding a suita ble multiple of the seco nd row to the first we
make al l = 1. Then we subtract multiples of the first row from the others to
make ai l = 0 for i =1= 1.
We now repeat the procedure with the second row and column, to make
a22 = I and
a i2 = 0 if i > 2. But then we can also make a l 2 = 0 by sub-
tracting a suita ble multiple of the seco nd row from the first, so we can get
a i2 = 0 for i
=1= 2.
We repeat this procedure unt il we are stopped at ann = d =1= 0, and anj = 0
for j =I 11. Subtracting a suita ble mul tiple of the last row from the preceding
ones yields a matrix D of the form indicated in the sta tement of the theorem,
and concludes the proof.
Theorem 9.2.
For 11 ~ 3, SLn(F) is equal to its own commutator group.
Proof.
It suffices to prove that Eij(c) is a commutat or.
Using n ~ 3, let
k =I i, j. Then by direct computation,
expresses Eij(c) as a commutat or. This proves the theorem.
We note that if a matrix M commutes with every element of SLn(F), then
it must be a scalar matrix. Indeed, just the commutation with the elementary
matrices

542
MATRICES AND LINEAR MAPS
XIII, §9
shows that M commutes with all matrices Iij (having I in the ij-component,
ootherwise), so M commutes with all matrices, and is a scalar matrix. Taking
the determinant shows that the center consists of fJ-n(F)/, where fJ-n(F) is the
group of n-th roots of unity in F.
We let Z be the center of SLn(F) , so we have just seen that Z is the group
of scalar matrices such that the scalar is an n-th root of unity . Then we define
Theorem 9.3.
For n ~ 3, PSLn(F) is simple.
The rest of this section is devoted to the proof. We view GLn(F)as operating
on the vector space E = F". If A. is a non-zero functional on E, we let
HA = Ker A.,
and call H A(or simply H) the hyperplane associated with ),. Then dim H = n - I,
and conversely, if H is a subspace of codimension I, then E/H has dimension
l, and is the kernel of a functional.
An element T E GLn(F) is called a transvection if it keeps every element of
some hyperplane H fixed, and for all x E E, we have
Tx = x + h
for some h E H.
Given any element U E H A we define a transvection T" by
Every transvection is of this type. If u, v E H A, it is immediate that
If T is a transvection and A E GLnCF), then the conjugate ATA - I is ob-
viously a transvection.
The elementary matrices Eij(c) are transvections, and it will be useful to
use them with this geometric interpretations, rather than formally as we did
before. Indeed, let el ' . . . , en be the standard unit vectors which form a basis
of F(n). Then Eij(c) leaves ek fixed if k i= j, and the remaining vector ej is moved
by a multiple of e.. We let H be the hyperplane generated by ek with k i= j,
and thus see that Eij(c) is a transvection.
Lemma 9.4.
For n ~ 3, the transvections i= / form a single conjugacy class
in SLn(F).
Proof.
First, by picking a basis of a hyperplane H = H A and using one
more element to form a basis of r». one sees from the matrix of a transvection
T that det T = 1, i.e. transvections are in SLn(F).

XIII, §9
THE GROUP SLn(F), n ~ 3
543
Let T' be another transvection relative to a hyperplane H'. Say
Tx = x + A(X)U
and
T'x = x + A'(x)u'
with u E Hand u' E H'. Let z and z' be vectors such that A(Z) = 1 and A'(z') = 1.
Since a basis for H together with z is a basis for F'", and similarly a basis for
H' together with z' is a basis for r» , there exists an element A E GLn(F) such
that
Au = u',
AH=H',
Az = z'.
It is then immediately verified that
ATA- 1 = T',
so T, T' are conjugate in GLnCF). But in fact, using n ~ 3, the hyperplanes H,
H' contain vectors which are independent. We can change the image of a basis
vector in H' which is independent of u' by some factor in F so as to make
det A = 1, so A E SLn(F). This proves the lemma.
We now want to show that certain subgroups of GLn(F) are either con-
tained in the center, or contain SLn(F). Let G be a subgroup of GLnCF). We
say that Gis SL,,-invariant if
AGA -I c G
for all A E SLn(F).
Lemma 9.5.
Let n ~ 3. Let Gbe SLn-invariant, andsuppose that Gcontains
a transvection T =P 1. Then SLn(F) c G.
Proof.
By Lemma 9.4, all transvections are conjugate, and the set of
transvections contains the elementary matrices which generate SLn(F) by
Proposition 9.1, so the lemma follows.
Theorem 9.6.
Let n ~ 3. IfG isa subgroupofGLn(F) whichis SLn-invariant
and which is not contained in the center of GLnCF), then SLn(F) c G.
Proof.
By the preceding lemma, it suffices to prove that G contains a
transvection, and this is the key step in the proof of Theorem 9.3.
We start with an element A E G which moves some line. This is possible
since G is not contained in the center. So there exists a vector u =P 0 such that
Au is not a scalar multiple of u, say Au = v . Then u, v are contained in some
hyperplane H = Ker A. Let T = Tu and let
Then
A T A-I =P T
and
B = ATA-I T - 1 =P I.

544
MATRICES AND LINEAR MAPS
XIII, §9
This is easily seen by applying say B to an arbitrary vector x, and using the
defin ition of 7;,. In each case, for some x the left-hand side cannot equ al the
right-hand side.
Fo r any vector x E F(n)we have
Bx -
X E (u, v),
where (u, v) is the plane generated by u, v. It follows that BH c H, so
BH = Hand
Bx - x E H.
We now distinguish two cases to conclude the proof. First assume that B
commutes with all transvections with respect to H. Let WE H. Then from the
definitions, we find for an y vector x :
BTwx = Bx + ..1.(x)Bw
TwBx = Bx + ..1.(Bx)w = Bx + ..1.(x)w.
Since we are in the case BTw= TwB, it follows that Bw = w. Therefore B
leaves every vector of H fixed. Since we have seen that Bx - x E H for all x,
it follows that B is a transvection and is in G, thus proving the theorem in this
case.
Second, suppose there is a transvection T; with WE H such that B does not
commute with Tw • Let
Then C #- I and C E G. Fu rthermore C is a product of T: I and BTwB- 1
whose hyperplanes are Hand BH, which is also H by what we have already
proved. Therefore C is a transvection, since it is a product of transvections
with the same hyperplane. And C E G. Th is concludes the proof in the second
case, and also concludes the proof of Theorem 9.6.
We now return to the main theorem, that PSLn(F) is simple. Let G be a
normal subgro up of PSLn(F), and let G be its inverse image in SLn(F). Then G
is SLn-invariant, and if G #- I, then G is not equal to the center of SLiF).
Therefore G contains SLn(F) by Theorem 9.6, and therefore G = PSLII(F), thus
proving that PSLn(F) is simple.
Example.
By Exercise 41 of Chapter I, or whatever other means, one sees
that PSL2(Fs) =As (where Fs is the finite field with 5 elements). While you are
in the mood, show also that

XIII, Ex
EXERCISES
EXERCISES
545
1. Interpret the rank of a matrix A in terms of the dimensions of the image and kernel
of the linear map LA"
2. (a) Let A be an invert ible matrix in a commutative ring R. Show that (lA)-1 = '(A -I).
(b) Let f be a non-singular bilinear form on the module E over R. Let A be an
R-automorphism of E. Show that ('A) -I = '(A- I). Prove the same thing in the
hermitian case, i.e. (A *) -I = (A - 1)*.
3. Let V,
W be finite dimensional vector spaces over a field k. Suppose given
non-degenerate bilinear forms on V and W respectively, denoted both by (,
).
Let L: V ~ W be a surjective linear map and let 'L be its transpose; that is,
(Lv, w) = (v, 'Lw) for v E V and w E W.
(a) Show that 'L is injective.
(b) Assume in addition that if v E V, V * 0 then (v , v) * O. Show that
V = Ker L EB 1m 'L ,
and that the two summands are orthogonal. (Cf. Exerc ise 33 for an example.)
4. Let A I
. . . , Ar be row vectors ofdimension n, over a field k. Let X = (x I ' . . . , xn) . Let
h" . . . , b, E k. By a system of linear equations in k one means a system of type
If hi = ... = b, = 0, one says the system is homogeneous. We call n the number of
variables, and r the number of equations. A solution X of the homogeneous system
is called trivial if Xi = 0, i = I , . . . , n.
(a) Show that a homogeneous system of r linear equations in n unknowns with
n > r always has a non-trivial solution.
(b) Let L be a system of homogeneous linear equations over a field k. Let k be a
subfield of k'. If L has a non-trivial solution in k', show that it has a non-trivial
solution in k.
5. Let M be an n x n matrix over a field k. Assume that tr(MX) = 0 for all n x n matrices
X in k. Show that M = O.
6. Let S be a set of n x n matrices over a field k. Show that there exists a column vector
X i= 0 of dimen sion n in k, such that M X = X for all ME S if and only if there exists
such a vector in some extension field k' of k.
7. Let H be the division ring over the reals generated by elements i, i. k such that
i2 = / = k2 = - I, and
ij =
- ji = k;
jk = - kj = i,
ki =
- ik = i.
Then H has an automorphism of order 2, given by
ao + ali + a2i + a3kf.--->ao - al i - a2i - a3k.
Denote this automorphism by rx f-+ Ci. What is rxCi ? Show that the theory of hermitian

546
MATRICES AND LINEAR MAPS
XIII, Ex
forms can be carried out over H , which is called the division ring of quaternions (or by
abuse of language, the non-commutati ve field of quaternions).
8. Let N be a strictly upper triangular II x II matrix, that is N = (ai) and aij = 0 if i ~ j .
Show that N" = O.
9. Let E be a vector space over k, of dimension II . Let T : E -+ E be a linear map such
that T is nilpotent, that is T" = 0 for some positive integer m. Show that there exists
a basis of E over k such that the matrix of T with respect to this basi s is strictly
upper triangular.
10. If N is a nilpotent II x II matrix, show that J + N is invertible.
II. Let R be the set of all upper triangular II x II matrices (ai) with aij in some field k, so
aij = 0 if i > j . Let J be the set of all strictly upper triangular matrices. Show that J
is a two-sided ideal in R. How would you describe the factor ring RjJ ?
12. Let G be the group of upper tr iangular matrices with non-zero diagonal elements.
Let H be the subgroup con sisting of those matrices whose diagonal element is I.
(Actually prove that H is a subgroup). How would you describe the factor group GjH?
13. Let R be the ring of II X
II matrices over a field k. Let L be the subset of matrices
which are 0 except on the first column.
(a) Show that L is a left ideal.
(b) Show that L is a minimal left ideal; that is, if L' C L is a left ideal and
L' "* 0, then L' = L. (For more on this situation, see Chapter VII , §5.)
14. Let F be any field. Let D be the subgroup of diagonal matrices in GLn(F). Let N be
the normalizer of Din GLn(F). Show that NjD is isomorphic to the symmetric group
on II elements.
15. Let F be a finite field with q elements. Show that the order of GLn(F) is
n
(qn _ 1)(qn _ q) .. . (qn _ qn-I) = qn(n- 11/2 n (qi _ I).
i= 1
[Hillt:
Let x I ' . .. , x, be a basis of F" . Any element of GLn(F) is uniquel y determined
by its effect on this basis, and thu s the order of GLn(F) is equal to the number of all
possible bases. If A E GLn(F), let AXi = )'i ' For j, we can select any of the qn -
I
non-zero vectors in F". Suppose inductively that we have already chosen )'1 "
" ' )',
with r < II . These vectors span a subspace of dimension r which contains q' elements.
For Yi + I we can select any of the q" - q' elements outside of this subspace. The
formula drops out.]
16. Again let F be a finite field with q elements. Show that the order of SLn(F) is
qn(n - ll /2 n(qi _ I);
;=2
and that the order of PSL.(F) is
I
n-1
- qn(n - nrz n (qi -
1),
d
i = 2
where d is the greatest common divisor of II and q -
I.

XIII, Ex
EXERCISES
547
17. Let F be a finite field with q elements. Show that the group of all upper triangular
matrices with 1 on the diagonal is a Sylow subgroup of GLnCF) and of SLn(F).
18. The reduction map Z --+ Z/NZ, where N is a positive integer defines a homomorphism
SLz(Z) --+ SLz(Z/NZ).
Show that this homomorphism is surjective. [Hint:
Use elementary divisors, i.e. the
structure of submodules of rank 2 over the principal ring Z.]
19. Show that the order of SLz(Z/NZ) is equal to
N
3 IT (I -~) ,
piN
P
where the product is taken over all primes dividing N.
20. Show that one has an exact sequence
1 --+ SL 2(Z/NZ) --+ GLz(Z/NZ) ~ (Z/NZ)* --+ I.
In fact, show that
where GN is the group of matrices
(01
°d)
with
d e (Z/NZ)*.
21. Show that SL2(Z) is generated by the matrices
22. Let p be a prime ~ 5. Let G be a subgroup of SLz(Z/pnz) with n ~ 1. Assume that
the image of G in SL 2(Z/ pZ) under the natural homomorphism is all of SL 2(Z/ pZ) .
Prove that G = SL 2(Z/p nz) .
Note . Exercise 22 is a generalization by Serre of a result of Shimura; see Serre's Abelian
£-adic Representations and elliptic curves, Benjamin, 1968, IV, §3, Lemma 3. See also
my exposition in Elliptic Functions, Springer Verlag, reprinted from Addison-Wesley,
1973, Chapter 17, §4.
23. Let k be a field in which every quadratic polynomial has a root. Let B be the Borel
subgroup of GL 2(k) . Show that G is the union of all the conjugates of B . (This cannot
happen for finite groups!)
24. Let A, B be square matrices of the same size over a field k. Assume that B is non-
singular. If t is a variable, show that det(A + tB) is a polynomial in t, whose leading
coefficient is det(B), and whose constant term is det(A).
25. Let all' ... , a In be elements from a principal ideal ring, and assume that they generate
the unit ideal. Suppose n > I. Show that there exists a matrix (aij) with this given
first row, and whose determinant is equal to I.

548
MATRICES AND LINEAR MAPS
26. Let A be a commutative ring, and I = (x I' . . . , x.) an ideal. Let cij E A and let
Yi = L cijxj .
j= I
XIII, Ex
Let I' = (YI> . . . , y,). Let D = det(cij)' Show that DI c I'.
27. Let L be a free module over Z with basis el"
'"
en ' Let M be a freesubmodule of the
same rank, with basis UI, •• . , Un' Let u, = L Cijej ' Show that the index (L: M) is
given by the determinant :
(L : M) = Idet(ci)I.
28. (The Dedekind determinant). Let G be a finite commutative group and let F be the
vector space of functions of G into C. Show that the characters of G (homomorphisms
of G into the roots of unity) form a basis for this space. Iff: G -
C is a function,
show that for a, bEG.
det(f(ab- I» = Il L x(a)f(a),
x
eJEG
where the product is taken over all characters. [Hint:
Use both the characters and
the char..cteristic functions of elements of Gas bases for F, and consider the linear map
T = L f(a)1;.,
where 1;. is translation by a.] Also show that
det(f(ab - I» = (L f(a») det(f(ab -I) - f(b -I»,
aeG
where the determinant on the left is taken for all a, bEG, and the determinant on
the right is taken only for a, b *" 1.
29. Let 9 be a module over the commutative ring R. A bilinear map 9 x 9 -+ g, written
(x, y) ........ [x,y], is said to make 9 a Lie algebra if it is anti-symmetric, i.e.
[x, y] = -[y,x], and if the map Dx : g -+ g defined by Dx(y) = [x, y] is a derivation
of g into itself, that is
D([y, z]) = [Dy, z] + [y,Dz]
and
D(cy) = cD(y)
for all x, y, z E g and C E R.
(a) Let A be an associative algebra over R. For x,YEA , define [x, y] =
xy - yx. Show that this makes A into a Lie algebra. Example: the algebra
of R-endomorphisms of a module M, especially the algebra of matrices
Matn(R) .
(b) Let M be a module over R. For two derivations D[, D2 of M, define
[D. ,D2] = DID2 - D2D\. Show that the set of derivations of M is a Lie
subalgebra of EndR(M).
(c) Show that the map x ........ Ex is a Lie homomorphism of 9 into the Lie algebra
of derivations of 9 into itself.
30. Given a set of polynomials {PiX i) } in the polynomial ring R[Xij] (1 ~ i,j ~ n), a
zero of this set in R is a matrix x = (Xi) such that xij E Rand P.(Xi) = 0 for all v.
We use vector notation, and write (X) = (Xi)' We let G(R) denote the set of zeros

XIII, Ex
EXERCISES
549
of our set of polynomials {PJ. Thus G(R) c Mn(R), and if R' is any commutative
associative R-algebra we have G(R') c
Mn(R '). We say that the set {p.} defines an
algebraic group over R if G(R') is a subgroup of the group GLn(R ') for all R' (where
GLn(R') is the multiplicative group of invertible matrices in R') .
As an example, the group of matrices satisfying the equation tXX = In is an alge-
braic group.
Let R' be the R-algebra which is free, with a basis {l, t} such that t 2 = O. Thus
R' = R[t]' Let g be the set of matrices x E Mn(R) such that In + tx E G(R[t]). Show
that 9 is a Lie algebra. [Hint :
Note that
p .(In + tX) = p .(In) + grad p.(In)tX.
Use the algebra R[t, u] where t 2 = u2 = 0 to show that if In + tx E G(R[t]) and
In + uy E G(R[u]) then [x, y] E g.]
(I have taken the above from the first four pages of [Se 65]. For more information
on Lie algebras and Lie Groups, see [Bo 82] and [Ja 79].
[Bo 82]
N. BOURBAKI, Lie Algebras and Lie Groups, Masson, 1982
[Ja 79]
N. JACOBSON, Lie Algebras, Dover, 1979 (reprinted from Interscience,
1962)
[Se 65]
1. P. SERRE, Lie Algebras and Lie Groups, Benjamin, 1965. Reprinted
Springer Lecture Notes 1500. Springer/Verlag 1992
Non-commutative cocycles
Let K be a finite Galois extension of a field k. Let I' = GLn(K), and G = Gal(Kjk).
Then G operates on F. By a cocycle of G in I' we mean a family of elements {A(a)}
satisfying the relation
A(a)aA(r) = A(ar).
We say that the cocycle splits if there exists B E I' such that
for all a E G.
In this non-commutative case, cocycles do not form a group, but one could define an
equivalence relation to define cohomology classes. For our purposes here, we care
only whether a cocycle splits or not.
When every cocycle splits, we also say that
H l(G,1) = 0 (or 1).
31. Prove that Hl(G, GL.(K»
= 1. [Hint :
Let {el , . . . , eN} be a basis of Matn(k) over k,
say the matrices with I in some component and 0 elsewhere. Let
N
X = LXjej
i= 1
with variables Xi ' There exists a polynomial P(X) such that x is invertible if and only
if ~(Xl>
"
"
XN)';' O. Instead of P(Xl " ' " xN) we also write P(x). Let {A(a)} be a
cocycle. Let {ta} be algebraically independent variables over k. Then

550
MATRICES AND LINEAR MAPS
XIII, Ex
because the polynomial does not vanish when one l y is replaced by I and the others
are replaced by O. By the algebraic independence of automorphisms from Galois
theory, there exists an element y E K such that if we put
B = I (yy)A(y)
then PCB) ¥- 0, so B is invertible. It is then immediately verified that A(u) = BuB- 1.
But when k is finite, cf. my Algebraic Groups over Finite Fields, Am. J. Vol 78 No.
3, 1956.]
32. Invariant bases. (A. Speiser, Zahlentheoretische Satze aus der Gruppentheorie,
Math. Z. 5 (1919) pp. 1-6. See also Kolchin-Lang, Proc. AMS Vol. 11 No.1,
1960). Let K be a finite Galois extension of k, G = Gal(Klk) as in the preceding
exercise. Let V be a finite-dimensional vector space over K , and suppose G operates
on V in such a way that a(av) = u(a)u(v) for a E K and v E V. Prove that there
exists a basis {WI , .. . , wn } such that UWi = Wi for all i = 1, . .. .n and all a E G (an
invariant basis). Hint: Let {VI ,... , vn} be any basis, and let
where A(u) is a matrix in GLn(K). Solve for B in the equation (uB)A(u) = B, and let
The next exercises on harmonic polynomials have their source in Whittaker, Math.
Ann. 1902; see also Whittaker and Watson, Modern Analysis, Chapter XIII.
33. Harmonic polynomials. Let Pol(n, d) denote the vector space of homogeneous poly-
nomials of degree d in n variables XI' .. . , X; over a field k of characteristic O.
For an n-tuple of integers (VI ' "
. , vn) with Vi ~ 0 we denote by M(v) as usual the
monomial
Prove:
(a) The number of monomials of degree dis (n - I + d) ,so this number is
n -
I
the dimension of Pol(n, d) .
(b) Let (D) = (D" . . . , Dn ) where D, is the partial derivative with respect to the
i-th variable. Then we can define P(D) as usual. For P, Q E Pol(n, d), define
(P, Q) = P(D)Q(O).
Prove that this defines a symmetric non-degenerate scalar product on
Pol(n, d) . If k is not real, it may happen that P * 0 but (P, P) = O. However,
if the ground field is real, then (P, P) > 0 for P * O. Show also that the
monomials of degree d form an orthogonal basis. What is (M(v)' M(v»?
(c) The map P ~ P(D) is an isomorphism of Pol(n, d) onto its dual.

XIII, Ex
EXERCISES
551
(d) Let a = DI + .. . + D ~ . Note that .:l: Pol(n, d ) ~ Pol(n, d - 2) is a linear
map . Prove that .:l is surjective.
(e) Define Har(n, d ) = Kerzs = vector space of harmonic homogeneous poly-
nomials of degree d. Prove that
dim Har(n, d ) = (n + d - 3)! (n + 2d - 2)/ (n - 2)!d!.
In particular, if n = 3, then dim Har(3, d ) = 2d + I.
(f) Let r2 = XI + ... + X~ . Let S denote multiplication by r2• Show that
isr, Q) = (P, SQ) for P E Pol(n, d) and Q E Pol(n, d -
2),
so t.:l = S. More generally, for R E Pol(n, m) and Q E Pol(n, d - m) we
have
(R(D)?, Q) = (P, RQ).
(g) Show that [.:l, Sj = 4d + 2n on Pol(n, d) . Here [Il, Sj = Il
0 S - S oil .
Actually, [Il , Sj = 4E + 2n, where E is the Euler operator E = 2:xp;,
which is, however, the degree operator on homogeneous polynomials.
(h) Prove that Pol(n, d) = Har(n , d) EB r2Pol(n , d - 2) and that the two summands
are orthogonal. This is a classical theorem used in the theory of the Laplace
operator.
(i)
"
2
Let (c l , • .. , cn ) E k" be such that L- C ; = O. Let
H~(X ) = (C1X I + .. . + cnXn)d.
Show that H~ is harmonic, i.e . lies in Har(n , d ).
(j)
For any Q E Pol(n, d ), and a positive integer m, show that
Q(D)H';'(X ) = m(m -
I ) ' " (m - d + I)Q(c)H,;,-d(X) .
34. (Continuation of Exercise 33). Prove:
Theorem.
Let k be algebraically closed of characteristic O. Let n
~ 3. Then
Har(n, d) as a vector space over k is generated by all polynomials H~ with (c) E P
such that 2: CT = O.
[Hint: Let Q E Har(n, d) be orthogonal to all polynomials H~ with (c) E k" , By
Exercise 33(h), it suffices to prove that r 2 1Q. But if 2: CT = 0, then by Exercise
33(j) we conclude that Q(c) = O. By the Hilbert Nullstellensatz , it follows that there
exists a polynomial F(X) such that
Q(XY = r2(X)F(X) for some positive integer s.
But n ~ 3 implies that r 2(X ) is irreducible, so r 2(X ) divides Q(X) .j
35. (Continuation of Exercise 34). Prove that the representation of D(n) = Un(R ) on
Har(n,d) is irreducible.
Readers will find a proof in the following :
S. HELGASON, Topics in Harmonic Analysis on Homogeneous Spaces, Birkhauser, 1981
(see especially §3, Theorem 3.I(ii))
N. VILENKIN , Special Functions and the Theory of Group Representations, AMS Trans-
lations of mathematical monographs Vol. 22, 1968 (Russian original, 1965), Chapter
IX, §2.

552
MATRICES AND LINEAR MAPS
XIII, Ex
R. HOWE and E. C. TAN,Non-Abelian Harmonic Analysis, Universitext, Springer Verlag ,
New York, 1992.
The Howe-Tan proof runs as follows . We now use the hermitian product
(P, Q) = J P(x) Q(x) da(x),
5"-1
where
a
is
the rotation
invariant measure
on
the
(n-l)-sphere
sn-l .
Let
el , . .. .e; be the unit vectors in R" . We can identify O(n - I) as the subgroup of
O(n) leaving en fixed. Observe that O(n) operates on Har(n, d), say on the right by
composition P f-> P o A, A E O(n), and this operation commutes with ~ . Let
A: Har(n,d) ---; C
be the functional such that A(P) = P(en). Then ). is O(n - I)-invariant, and since the
hermitian product is non-degenerate, there exists a harmonic polynomial Qn such
that
).(P) = <P, Qn>
for all P E Har(n,d).
Let Me Har(n,d) be an O(n)-submodule. Then the restriction AM of ). to M is
nontrivial because O(n) acts transitively on S n-I. Let Q~IJ be the orthogonal pro-
jection of Qn on M. Then Qtt is O(n - I)-invariant, and so is a linear combination
Q~(x) =
2:
Cj x{ ~l '
j +2k=d
Furthermore Q1,{ is harmonic. From this you can show that Q1,{ is uniquely determined,
by showing the existence of recursive relations among the coefficients Cj ' Thus the
submodule M is uniquely determined, and must be all of Har(n, d) .
Irreducibility of sln(F).
36. Let F be a field of characteristic O. Let 9 = sIn(F) be the vector space of matrices
with trace 0, with its Lie algebra structure [X , Y] = XY - YX. Let Eij be the matrix
having (i,i)-component I and all other components O. Let G = SLn(F). Let A be
the multiplicative group of diagonal matrices over F.
(a) Let
H i = E ii -
Ei+l ,i+1 for i = I, . . . ,n - I. Show that the elements Eij
(i i=i), HI ,. . . ,Hn- I form a basis of 9 over F.
(b) For g E G let c(g) be the conjugation action on g, that is c(g)X = gXg- I •
Show that each Eij is an eigenvector for this action restricted to the group A.
(c) Show that the conjugation representation of G on 9 is irreducible, that is, if
V i= 0 is a subspace of 9 which is c( G)-stable, then V = g. Hint: Look up
the sketch of the proof in [JoL 01], Chapter VII, Theorem 1.5, and put in all
the details. Note that for i i=i the matrix Eij is nilpotent, so for variable t,
the exponential series exp( tEij) is actually a polynomial. The derivative with
respect to t can be taken in the formal power series F[[t]], not using limits. If
Xis a matrix, and x(t ) = exp(tX), show that
d
_ I
-dx(t) Yx(t)
I
= XY - YX = [X , Yj.
t
(=0

CHAPTER XIV
Representation of One
Endomorphism
We deal here with one endomorphism of a module , actually a free module,
and especially a finite dimensional vector space over a field k. We obtain the
Jordan canonical form for a representing matrix , which has a particularly simple
shape when k is algebraically closed. This leads to a discussion of eigenvalues
and the characteristic polynomial. The main theorem can be viewed as giving
an example for the general structure theorem of modules over a principal ring.
In the present case, the principal ring is the polynomial ring k[X] in one variable.
§1 .
REPRESENTATIONS
Let k be a commutative ring and E a module over k. As usual, we denote by
Endk(E) the ring of k-endomorphisms of E, i.e. the ring of k-linear maps of E into
itself.
Let R be a k-algebra (given by a ring-homomorphism k -> R which allows
us to consider R as a k-module). Bya representation of R in E one means a k-
algebra homomorphism R -> Endk(E), that is a ring-homomorphism
which makes the following diagram commutative :
~ /
k
553
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

554
REPRESENTATION OF ONE ENDOMORPHISM
XIV, §1
[As usual, we view Endk(E) as a k-algebra ; if I denotes the identity map of E,
we have the homomorphism of k into Endk(E) given by a f--+ aI. We shall also
use I to denote the unit matrix if bases have been chosen. The context will
always make our meaning clear.]
We shall meet several examples of representations in the sequel, with various
types of rings (both commutative and non-commutative). In this chapter, the
rings will be commutative.
We observe that E may be viewed as an Endk(E) module. Hence E may be
viewed as an R-module, defining the operation of R on E by letting
(x, v) f--+ p(x)v
for x E R and VEE. We usually write xv instead of p(x)v.
A subgroup F of E such that RF c F will be said to be an invariant sub-
module of E. (It is both R-invariant and k-invariant.) We also say that it is
invariant under the representation.
We say that the representation is irreducible, or simple, if E =1= 0, and if the
only invariant submodules are°and E itself.
The purpose of representation theories is to determine the structure of all
representations of various interesting rings, and to classify their irreducible
representations. In most cases, we take k to be a field, which mayor may not
be algebraically closed. The difficulties in proving theorems about representa-
tions may therefore lie in the complication of the ring R, or the complication of
the field k, or the complication of the module E, or all three.
A representation p as above is said to be completely reducible or semi-simple
if E is an R-direct sum of R-submodules Ei ,
E = E 1 EEl .• . EEl Em
such that each E, is irreducible. We also say that E is completely reducible.
It is not true that all representations are completely reducible, and in fact those
considered in this chapter will not be in general. Certain types of completely
reducible representations will be studied later.
There is a special type of representation which will occur very frequently.
Let vEE and assume that E = Rv. We shall also write E = (v). We then say
that E is principal (over R), and that the representation is principal. If that is
the case, the set of elements x E R such that xv =°is a left ideal a of R (obvious).
The map of R onto E given by
X f--+ xv
induces an isomorphism of R-modules,
Ria -+ E
(viewing R as a left module over itself, and Ria as the factor module). In this
map, the unit element 1 of R corresponds to the generator v of E.

XIV, §1
REPRESENTATIONS
555
As a matter of notation, if Vi' . .. , V. E E, we let (Vi "
' "
V. ) denote the sub-
module of E generated by Vi"
' "
V•.
Assume that E has a decomposition into a direct sum of R-submodules
Assume that each E, is free and of dimension ~ lover k. Let CB" . .. , CBs be
bases for E1, ••• , E, respectively over k. Then {CB l ' . .. ,
CBs} is a basis for E.
Let cp E R, and let cPi be the endomorphism induced by cP on Ei: Let Mi be the
matrix of CPi with respect to the basis CB i : Then the matrix M of cP with respect
to {CB 1> • • • , CB s} looks like
o
0
o
0
Ms
A matrix of this type is said to be decomposed into blocks, M i , . , . Ms. When
we have such a decomposition, the study of cp or its matrix is completely reduced
(so to speak) to the study of the blocks.
It does not alwa ys happen that we have such a reduction, but frequently
something almost as good happens. Let E' be a submodule of E, invariant
under R. Assume that there exists a basis of E' over k, say {Vi' .. . , Vm }, and that
this basis can be completed to a basis of E,
This is always the case if k is a field.
Let cp E R. Then the matrix of cp with respect to this basis has the form
( M ' *)
o
M il '
Indeed, since E' is mapped into itself by cp, it is clear that we get M' in the upper
left, and a zero matrix below it. Furthermore, for eachj = m + I, . . . , n we can
write
The transpose of the matrix (Cji) then becomes the matrix
occurring on the right in the matrix representing cp.

556
REPRESENTATION OF ONE ENDOMORPHISM
Furthermore, consider an exact sequence
o--+ E' --+ E --+ E" --+ O.
XIV, §2
Let vm + I, . • . , vn be the images of vm + I"'"
Vn under the canonical map E --+ E".
We can define a linear map
q/' : E" --+ E"
in a natural way so that (qJl') = q>"(v) for all VEE. Then it is clear that the
matrix of tp" with respect to the basis {VI' . . . , Vn} is M".
§2.
DECOMPOSITION OVER ONE
ENDOMORPHISM
Let k be a field and E a finite-dimensional vector space over k, E =1= O. Let
A E Endk(E) be a linear map of E into itself. Let t be transcendental over k. We
shall define a representation of the polynomial ring k[t] in E. Namely, we have
a homomorphism
k[t] --+ k[A] c Endk(E)
which is obtained by substituting A for t in polynomials. The ring k[A] is the
subring of Endk(E) generated by A, and is commutative because powers of A
commute with each other. Thus if f(t) is a polynomial and vEE, then
f(t)v = f(A)v.
The kernel of the homomorphism f(t) f->f(A) is a principal ideal of k[t],
which is
=1= 0 because k[A] is finite dimensional over k. It is generated by a
unique polynomial of degree> 0, having leading coefficient 1. This polynomial
will be called the minimal polynomial of A over k, and will be denoted by qA(t).
It is of course not necessarily irreducible.
Assume that there exists an element VEE such that E = k[t]v = k[A]v.
This means that E is generated over k by the elements
v, Av, A 2v, . . . .
We called such a module principal, and if R = k[t] we may write E = Rv = (v).
If qA(t) = td + ad-Ir:I + ... + ao then the elements
v, Av, ... , Ad-IV
constitute a basis for E over k. This is proved in the same way as the analogous
statement for finite field extensions. First we note that they are linearly inde
pendent, because any relation of linear dependence over k would yield a poly-

XIV, §2
DECOMPOSITION OVER ONE ENDOMORPHISM
557
nom ial g(t) of degree less than deg qA and such that g(A) = O. Second, they
generate E because any polynomial f( t) can be written f( t) = g(t)qA(t) + ret)
with deg r < deg qA- Hencef (A) = rCA).
With respect to this basis, it is clear that the matrix of A is of the following
type:
000
1
0
0
010
o 0
0
0
-ad - 2
o 0
0
. . .
1
-ad - I
If E = (v) is principal, then E is isomorphic to k[t]/(qA(t» under the map
f (t) H f(A)v. The polynomial qA is uniquely determined by A, and does not
depend on the choice of generator v for E. This is essentially obvious, because
iffl ,f2 are two polynomials with leading coefficient 1, then k[t]/(fl(t» is iso-
morphic to k[t]/(f2(t) if and only iffl = f2' (Decompose each polynomial into
prime powers and apply the structure theorem for modules over principal rings.)
If E is principal then we shall call the polynomial qAabove the polynomial
invariant of E, with respect to A, or simply its invariant.
Theorem 2.1.
Let E be a non-zero finite-dimensional space over the field k,
and let A E Endk(E). Then E admits a direct sum decomposition
where each E, is a principal k[A]-submodule, with invariant qi -# 0 such that
The sequence (ql, ... , qr) is uniquely determined by E and A, and q, is the
minimal polynomial of A.
Proof
The first statement is simply a rephrasing in the present language
for the structure theorem for modules over principal rings. Furthermore, it is
clear that qr(A) = 0 since q;!qr for each i. No polynomial of lower degree than
q, can annihilate E, because in particular, such a polynomial does not annihilate
Er. Thus qr is the minimal polynomial.
We shall call (ql"'" qr) the invariants of the pair (E, A). Let E = kIn), and
let A be an n x n matrix, which we view as a linear map of E into itself. The
invariants (ql,"" qr) will be called the invariants of A (over k).
Corollary 2.2.
Let k' be an extensionfield ofk and let A be an n x n matrix
in k.
The invariants of A over k are the same as its invariants over k',

558
REPRESENTATION OF ONE ENDOMORPHISM
XIV, §2
Proof
Let {V I' . . . ' vn} be a basis of k(n) over k. Then we may view it also
as a basis of k'ln) over k'. (The unit vectors are in the k-space generated by
VI' . .. , Vn; hence VI' . . . , Vngenerate the n-dimensional space k'ln) over k'.) Let
E = k(n). Let LA be the linear map of E determined by A. Let L~ be the linear
map of k'ln) determined by A. The matrix of LAwith respect to our given basis is
the same as the matrix of L~. We can select the basis corresponding to the
decomposition
E = E lEE> · . . EE> E,
determined by the invariants ql' .. . , q., It follows that the invariants don't
change when we lift the basis to one of k'ln).
Corollary 2.3.
Let A, B be n x n matrices over a field k and let k' be an
extensionfield ofk. Assumethat there is an invertiblematrix C' ink' such that
B = C'AC'- 1. Then thereisaninvertiblematrix C ink suchthat B = CAe - 1.
Proof
Exercise.
The structure theorem for modules over principal rings gives us two kinds
of decompositions. One is according to the invariants of the preceding theorem.
The other is according to prime powers.
Let E =1= 0 be a finite dimensional space over the field k, and let A : E --+ E
be in Endk(E). Let q = qA be its minimal polynomial. Then q has a factorization,
q = p~1 . . . p~s
into prime powers (distinct). Hence E is a direct sum of submodules
such that each E(pJ is annihilated by p'r . Furthermore, each such submodule
can be expressed as a direct sum of submodules isomorphic to k[t]/(pe) for
some irreducible polynomial p and some integer e ~ 1.
Theorem 2.4.
Let qA(t) = (t -
C() e for some C( E k, e ~ 1. Assume that E
is isomorphic to k[t]/(q). Then E has a basisoverk such that the matrix ofA
relative to this basis is oftype
C(
0
0
1
C(
0
o
0
o ...
1
C(

XIV, §2
DECOMPOSITION OVER ONE ENDOMORPHISM
559
Proof
Since E is isomorphic to k[t]/(q), there exists an element vEE
such that k[t]v = E. This element corresponds to the unit element of k[t] in the
isomorphism
k[t]/(q) --+ E.
We contend that the elements
v, (t - a)v,. . . , (t - ay-lv,
or equivalently,
v,(A - a)v, . . . , (A - at-lv,
form a basis for E over k. They are linearly independent over k because any
relation oflinear dependence would yield a relation oflinear dependence between
v, Av, . .. , Ae - lV,
and hence would yield a polynomial g(t) of degree less than deg q such that
g(A) = O. Since dim E = e, it follows that our elements form a basis for E
over k. But (A - aY = O. It is then clear from the definitions that the matrix of
A with respect to this basis has the shape stated in our theorem.
Corollary 2.5.
Let k be algebraically closed, and let E be afinite-dimensional
non-zero vector space over k. Let A E Endk(E). Then there exists a basis of
E overk suchthat the matrix ofA with respectto this basisconsistsof blocks,
and eachblock is ofthe type described in the theorem.
A matrix having the form described in the preceding corollary is said to be in
Jordan canonical form.
Remark 1.
A matrix (or an endomorphism) N is said to be nilpotent if
there exists an integer d > 0 such that Nd = O. We see that in the decomposition
of Theorem 2.4 or Corollary 2.5, the matrix M is written in the form
M=B+N
where N is nilpotent. Infact, N is a triangular matrix (i.e. it has zero coefficients
on and above the diagonal), and B is a diagonal matrix, whose diagonal elements
are the roots of the minimal polynomial. Such a decomposition can always be
achieved whenever the field k is such that all the roots of the minimal polynomial
lie in k. We observe also that the only case when the matrix N is 0 is when all
the roots of the minimal polynomial have multiplicity 1. In this case, if
n = dim E, then the matrix M is a diagonal matrix, with n distinct elements on
the diagonal.

560
REPRESENTATION OF ONE ENDOMORPHISM
XIV, §2
Remark 2.
The main theorem of this section can also be viewed as falling
under the general pattern of decomposing a module into a direct sum as far as
possible, and also giving normalized bases for vector spaces with respect to
various structures, so that one can tell in a simple way the effect of an endo-
morphism. More formally , consider the category of pairs (E, A), consisting
of a finite dimensional vector space E over a field k, and an endomorphism
A : E ~ E. By a morphism of such pairs
f: (E, A) ~ (E', A')
we mean a k-homomorphism f : E ~ E' such that the following diagram is
commutative:
It is then immediate that such pairs form a category, so we have the notion of
isomorphism. One can reformulate Theorem 2.1 by stating:
Theorem 2.6.
Two pairs (E, A) and (F, B) are isomorphic if and only if they
have the same invariants.
You can prove this as Exercise 19. The Jordan basis gives a normalized form
for the matrix associated with such a pair and an appropriate basis.
In the next chapter, we shall find conditions under which a normalized matrix
is actually diagonal, for hermitian, symmetric, and unitary operators over the
complex numbers.
As an example and application of Theorem 2.6, we prove:
Corollary 2.7.
Let k be a field and let K be a finite separable extension of
degree n. Let V be a finite dimensional vector space ofdimension n over k, and
let p, p' : K ~ Endk(V) be two representations ofK on V; that is, embeddings
of Kin Endk(V) . Then p, p' are conjugate; that is, there exists B E Autk(V)
such that
Proof.
By the primitive element theorem of field theory, there exists an
element a E K such that K = k[a] . Let p(t) be the irreducible polynomial of a
over k. Then (V, p(a» and (V, p'(a» have the same invariant, namely p(t) .
Hence these pairs are isomorphic by Theorem 2.6 , which means that there exists
B E Autk(V) such that
p'(a) = Bp(a)B- 1•
But all elements of K are linear combinations of powers of a with coefficients
in k, so it follows immediately that p'(g) = Bp(g)B- 1 for all g E K , as desired.

XIV, §3
THE CHARACTERISTIC POLYNOMIAL
561
To get a representation of K as in corollary 2.7, one may of course select a
basis of K, and represent multiplication of elements of K on K by matrices with
respect to this basis . In some sense, Corollary 2.7 tells us that this is the only
way to get such representations. We shall return to this point of view when
considering Cartan subgroups of GLn in Chapter XVIII, §12.
§3.
THE CHARACTERISTIC POLYNOMIAL
Let k be a commutative ring and E a free module of dimension n over k.
We consider the polynomial ring k[t], and a linear map A : E -+ E. We have a
homomorphism
k[t] -+ k[A]
as before, mapping a polynomialf(t) onf(A), and E becomes a module over
the ring R = k[t]. Let M be any n x n matrix in k (for instance the matrix of A
relative to a basis of E). We define the characteristic polynomial PM(t) to be the
determinant
det(tIn -
M)
where In is the unit n x n matrix. It is an element of k[t]. Furthermore, if N
is an invertible matrix in R, then
Hence the characteristic polynomial of N - 1MN is the same as that of M. We
may therefore define the characteristic polynomial of A, and denote by PA' the
characteristic polynomial of any matrix M associated with A with respect to
some basis. (If E = 0, we define the characteristic polynomial to be 1.)
If cp : k -+ k' is a homomorphism of commutative rings, and M is an n x n
matrix in k, then it is clear that
where CPPMis obtained from PM by applying cp to the coefficients of PM'
Theorem 3.1.
(Cayley-Hamilton).
We havePA(A) = 0.
Proof
Let {VI ' . .. , vn} be a basis of E over k. Then
n
tVj = L aijvi
i = I
where (aij) = M is the matrix of A with respect to the basis. Let B(t) be the
matrix with coefficients in k[t], defined in Chapter XIII , such that
B(t)B(t) = Pit)In -

562
REPRESENTATION OF ONE ENDOMORPHISM
Then
because
XIV, §3
Hence PA(t)E = 0, and therefore PA(A)E = 0. This means that PA(A) = 0,
as was to be shown.
Assume now that k is a field. Let E be a finite-dimensional vector space over
k, and let A E Endk(E). By an eigenvector w of A in E one means an element
wEE, such that there exists an element AE k for which Aw = AW. Ifw =I- 0, then
Ais determined uniquely, and is called an eigenvalue of A. Of course, distinct
eigenvectors may have the same eigenvalue.
Theorem 3.2.
The eigenvalues of A are precisely the roots ofthe character-
istic polynomial ofA.
Proof
Let Abe an eigenvalue. Then A - AI is not invertible in Endk(E),
and hence det(A - AI) = 0. Hence A. is a root of PA ' The arguments are re-
versible, so we also get the converse.
For simplicity of notation, we often write A - Ainstead of A - AI.
Theorem 3.3.
Let WI ' . . . , W m be non-zero eigenvectorsof A, having distinct
eigenvalues. Then they are linearly independent.
Proof
Suppose that we have
with ai E k, and let this be a shortest relation with not all a, = °(assuming such
exists). Then a, =I-°for all i. Let AI' . . ., Am be the eigenvalues of our vectors.
Apply A - AI to the above relation. We get
a2(A2 - AI )W2 + ... + am(Am- A,)Wm= 0,
which shortens our relation, contradiction.
Corollary 3.4.
If A has n distinct eigenvalues AI' .. ., An belongingto eigen-
vectors v" . . . , vn , and dim E = n, then {VI"' " vn} is a basisfor E. Thematrix

XIV, §3
THE CHARACTERISTIC POLYNOMIAL
563
ojA with respect to this basis is the diagonalmatrix :
Warning.
It is not always true that there exists a basis of E consisting of
eigenvectors!
Remark.
Let k be a subfield of k'. If M is a matrix in k, we can define its
characteristic polynomial with respect to k, and also with respect to k'. It is
clear that the characteristic polynomials thus obtained are equal. IfE is a vector
space over k, we shall see later how to extend it to a vector space over k'. A
linear map A extends to a linear map of the extended space, and the character-
istic polynomial of the linear map does not change either. Actually, if we select
a basis for E over k,then E ~ k(nl,and kIn) c k'(n) in a natural way. Thus selecting
a basis allows us to extend the vector space, but this seems to depend on the
choice of basis. We shall give an invariant definition later.
Let E = EI EB ... EB E, be an expression of E as a direct sum of vector
spaces over k. Let A E EndiE), and assume that AE j c E, for all i = 1, .. . , r.
Then A induces a linear map on Ej • We can select a basis for E consisting of
bases for E 1, . . . , En and then the matrix for A consists of blocks. Hence we see
that
r
PA(t) = I!PAlt).
j= I
Thus the characteristic polynomial is multiplicative on direct sums.
Our condition above that AE j c E, can also be formulated by saying that
E is expressed as a k[A]-direct sum of k[A]-submodules, or also a k[t]-direct
sum of k[t]-submodules. We shall apply this to the decomposition of E given
in Theorem 2.I.
Theorem 3.5.
Let E be a finite-dimensional vector space over a field k, let
A E Endk(E), and let ql' . . . , qrbe the invariants oJ(E, A). Then
Proof
We assume that E = kIn) and that A is represented by a matrix M.
We have seen that the invariants do not change when we extend k to a larger
field,and neither does the characteristic polynomial. Hence we may assume that
k is algebraically closed . In view of Theorem 2.1 we may assume that M has a

564
REPRESENTATION OF ONE ENDOMORPHISM
single invariant q. Write
XIV, §3
with distinct (Xl ' ... , (Xs' We view M as a linear map, and split out vector space
further into a direct sum of submodules (over k[tJ) having invariants
(t -
(XI Y' , ... , (t -
(XsY'
respectively (this is the prime power decomposition ). For each one of these
submodules, we can select a basis so that the matrix of the induced linear map has
the shape described in Theorem 2.4. From this it is immediately clear that the
characteristic polynomial of the map having invariant (t -
(XY is precisely
(t -
(XY, and our theorem is pro ved.
Corollary 3.6.
The minimal polynomial of A and its characteristic poly-
nomialhave the same irreducible factors.
Proof
Because qris the minimal polynomial, by Theorem 2.1.
We shall generalize our remark concerning the multiplicativity of the
characteristic polynomial over direct sums.
Theorem 3.7.
Let k be a commutative ring, and in thefollowingdiagram,
O-E'-E-E"-O
A'j
Aj
A"j
o-----+ E' -----+ E -----+ E" -----+ 0
let the rows be exact sequences offree modules over k, offinite dimension, and
let the vertical maps be k-linearmaps making the diagram commutative. Then
PA(t) = PA t)PA,,(t).
Proof
We may assume that E' is a submodule of E. We select a basis
{VI , ' ''' Vm} for E'. Let {Um+I''''' U} be a basis for E", and let Vm+l, . .. , Vn
be elements of E mapping on um + I ' ... , Un respectively. Then
is a basis for E (same proof as Theorem 5.2 of Chapter III), and we are in the
situation discussed in §1. The matrix for A has the shape
( M' *)
o
M "

XIV, §3
THE CHARACTERISTIC POLYNOMIAL
565
where M' is the matrix for A' and M" is the matrix for A". Taking the character-
istic polynomial with respect to this matrix obviously yields our multiplicative
property.
Theorem 3.8.
Let k be a commutative ring, and E afree module ofdimension
n over k. Let A E Endk(E). Let
Th en
tr(A) =
-Cn - 1
and
det(A) = (-Itco .
Proof
For the determinant, we observe that PA(O) = co. Substituting
t = 0 in the definition of the characteristic polynomial by the determinant shows
that Co = (-It det(A).
For the trace, let M be the matrix representing A with respect to some basis,
M = (au)' We consider the determinant det(tln
-
au). In its expansion as a sum
over permutations, it will contain a diagonal term
which will give a contribution to the coefficient of t"" 1 equal to
No other term in this expansion will give a contribution to the coefficient of
t"- 1, because the power of t occurring in another term will be at most t"- 2.
This proves our assertion concerning the trace.
Corollary 3.9.
Let the notation be as in Theorem 3.7 . Then
tr(A) = tr(A') + tr(A")
and
det(A) = det(A ') det(A ").
Proof
Clear.
We shall now interpret our results in the Euler-Grothendieck group.
Let k be a commutative ring. We consider the category whose objects are
pairs (E, A), where E is a k-module, and A E Endk(E). We define a morphism
(E', A') --+ (E, A)
to be a k-linear map E' .!. E making the following diagram commutative:
E'~E
Aj
jA
E' ------+ E
J

566
REPRESENTATION OF ONE ENDOMORPHISM
XIV, §3
Then we can define the kernel of such a morphism to be again a pair. Indeed,
let Eo be the kernel off: E' -+ E. Then A' maps Eo into itself because
fA'Eo= AfEo= O.
We let Aobe the restriction of A' on Eo . The pair (Eo, Ao) is defined to be the
kernel of our morphism.
We shall denote byf again the morphism of the pair (E', A') -+ (E, A). We
can speak of an exact sequence
(E', A') -+ (E, A) -+ (E", A"),
meaning that the induced sequence
E' -+ E -+ E"
is exact. We also write 0 instead of (0, 0), according to our universal convention
to use the symbol 0 for all things which behave like a zero element.
We observe that our pairs now behave formally like modules, and they in
fact form an abelian category.
Assume that k is a field. Let Ci consist of all pairs (E, A) where E is finite
dimensional over k.
Then Theorem 3.7 asserts that the characteristic polynomial is an Euler-
Poincaremap defined for each object in our category Ci, with values into the
multiplicativemonoid ofpolynomials with leading coefficient 1.
Since the values of the map are in a monoid, this generalizes slightly the notion
of Chapter III, §8, when we took the values in a group . Of course when k is a
field, which is the most frequent application, we can view the values of our map
to be in the multiplicative group of non-zero rational functions, so our previous
situation applies .
A similar remark holds now for the trace and the determinant. If k is a
field, the trace is an Euler map into the additive group ofthefield, and the deter-
minant is an Eulermapinto the multiplicativegroupofthefield. We note also that
all these maps (like all Euler maps) are defined on the isomorphism classes of
pairs, and are defined on the Euler-Grothendieck group.
Theorem 3.10.
Let k be a commutative ring, M an n x n matrix in k, andf
a polynomialin k[t]' Assume that PM(t) has afactorization,
n
PM(t) = fl (t - aJ
i= 1
into linear factors over k. Then the characteristic polynomial of f(M) is
given by
n
P!(M)(t) = fl (r - f(aJ),
i= 1

XIV, Ex
and
tr(f(M»
= I f (a;),
i = 1
EXERCISES
567
det(f(M» = [l f(aJ
i = 1
Proof.
Assume first that k is a field. Then using the canonical decomposi-
tion in terms of matrices given in Theorem 2.4, we find that our assertion is
immediately obvious. When k is a ring, we use a substitution argument. It is
however necessary to know that if X =
(Xij) is a matrix with algebraically
independent coefficients over Z, then Px(t) has n distinct roots )'1' . .. , )'n [in
an algebraic closure of Q(X )] and that we have a homomorphism
mapping X on M and )'1""')'n on a 1, . . . , an ' This is obvious to the reader who
read the chapter on integral ring extensions, and the reader who has not can
forget about this part of the theorem.
EXERCISES
I. Let T be an upper triangular square matrix over a commutative ring (i.e. all the ele-
ments below and on the diagonal are 0). Show that T is nilpotent.
2. Carry out explicitly the proof that the determinant of a matri x
M1
*
*
0
M2
0
0
*
0
0
.. .
0
where each M, is a square matrix, is equal to the product of the determinants of the
matrices M I , . . . , Ms.
3. Let k be a commutative ring, and let M, M' be square n x n matrices in k. Show that
the characteristic polynomials of MM' and M'M are equal.
4. Show that the eigenvalues of the matrix
in the complex numbers are ± 1, ± i.

568
REPRESENTATION OF ONE ENDOMORPHISM
XIV, Ex
5. Let M , M ' be square mat rices over a field k. Let q, q' be their respective minimal
polynom ials. Show that the minimal polynom ial of
(~
~,)
is the least common multiple of q, q.
6. Let A be a nilpotent end omorphism of a finite dimensional vecto r space E over the field
k. Show that tr(A) = O.
7. Let R be a principal entire ring. Let E be a free module over R, and let E V = HomR(E , R)
be its dual module. Then E
V is free of dimension n. Let F be a submodule of E.
Sho w that EV / F 1. can be viewed as a submodule of F V , and that its invariants are
the same as the invariants of F in E.
8. Let E be a finite-dimensional vector space over a field k. Let A E Autk(E). Show that
the following conditions are equivalent :
(a) A = I + N, with N nilpotent.
(b) There exists a basis of E such that the matrix of A with respect to this basis has
all its diagonal elements equal to I and all elements above the diagonal equal
to O.
(c) All roots of the characteristic polynomial of A (in the algebraic closure of k)
are equal to I.
9. Let k be a field of characteristic 0, and let M be an n x n matrix in k. Show that M is
nilpotent if and only if tr(M
V
) = 0 for I ~ v ~ n.
10. Generalize Theorem 3.10 to rational functions (instead of polynomials), assuming
that k is a field.
II. Let E be a finite-dimensional space over the field k. Let IXE k. Let E. be the subspace
of E generated by all eigen vectors of a given endomorphism A of E, having IX as an
eigenvalue. Show that every non-zero element of E. is an eigen vector of A having IX as
an eigenvalue.
12. Let E be finite dimensional over the field k. Let A E Endk(E). Let v be an eigenvector
for A. Let BE Endk(E) be such that AB = BA. Sho w that Bv is also an eigenvector
for A (if Bv =I' 0), with the same eigenvalue.
Diagonalizable endomorphisms
Let E be a finite-dimensional vector space over a field k, and let S E Endk(E). We say
that S is diagonalizable if there exists a basis of E consisting of eigenvectors of S. The
matrix of S with respect to this basis is then a diagonal matrix.
13. (a) If S is diagonalizable, then its min imal polynomial over k is of type
m
q(t) = f1 (t -
Ai)'
i= 1
where At, ... , Am are distinct elements of k.
(b) Conversely, if the minimal polynom ial of S is of the preceding type, then S is
diagonalizable. [Hint:
The space can be decomposed as a direct sum of the
subspaces EA; annihilated by S - Ai']

XIV, Ex
EXERCISES
569
(c) If S is diagonalizable, and if F is a subspace of E such that SF c F, show that S
is diagonalizable as an endomorphism of F, i.e. that F has a basis consisting of
eigenvectors of S.
(d) Let S, T be endomorphisms of E, and assume that S, T commute. Assume that
both S, Tare diagonalizable. Show that they are simultaneously diagonalizable,
i.e. there exists a basis of E consisting of eigenvectors for both Sand T. [Hint :
If A is an eigenvalue of S, and E), is the subspace of E consisting of all vectors v
such that Sv = AV, then TE ), c E), .]
14. Let E be a finite-dimensional vector space over an algebraically closed field k. Let
A E Endk(E). Show that A can be written in a unique way as a sum
A=S+N
where S is diagonalizable, N is nilpotent, and SN = NS . Show that S, N can be ex-
pressed as polynomials in A. [Hint:
Let PA(t) = f1 (t - Ait' be the factorization
of PA(t) with distinct Ai' Let E, be the kernel of (A -
AJm,. Then E is the direct sum of
the Ei. Define S on E so that on Ei, Sv = AjVfor all v E Ei. Let N = A - S. Show
that S, N satisfy our requirements. To get S as a polynomial in A, let 9 be a polynomial
such that
g(t) == Ai mod (t - Ar for all i, and
get) == 0 mod t.
Then S = g(A)
and N = A -
g(A).]
15. After you have read the section on the tensor product of vector spaces, you can easily
do the following exercise. Let E, F be finite-dimensional vector spaces over an alge-
braically closed field k, and let A : E -+ E and B : F -+ F be k-endomorphisms of E, F,
respectively. Let
be the factorizations of their respectively characteristic polynomials, into distinct
linear factors. Then
PA®it) = f1 (t - 1J.;/3)n,mj •
i. j
[Hint :
Decompose E into the direct sum of subspaces Ei> where E, is the subspace of
E annihilated by some power of A -
(Xi ' Do the same for F, getting a decomposition
into a direct sum of subspaces F j • Then show that some power of A ® B -
IJ.jPj
annihilates E, ® Fj • Use the fact that E ® F is the direct sum of the subspaces E, ® Fj ,
and that dimk(Ei ® F) = nimj']
16. Let r be a free abelian group of dimension n ~ I. Let I" be a subgroup of dimension n
also. Let {VI" ' " vn } be a basis of F, and let {WI"' " wn } be a basis of I", Write
Show that the index (I" : I") is equal to the absolute value of the determinant of the
matrix (ai)'
17. Prove the normal basis theorem for finite extensions of a finite field.
18. Let A = (ai) be a square n x n matrix over a commutative ring k. Let Aij be the matrix
obtained by deleting the i-th row and j-th column from A. Let bij = ( - 1y+ j det(Ajj),
and let B be the matrix (bi) . Show that det(B) = det(A)"-I, by reducing the problem to
the case when A is a matrix with variable coefficients over the integers. Use this same
method to give an alternative proof of the Cayley-Hamilton theorem, that PA(A) = O.

570
REPRESENTATION OF ONE ENDOMORPHISM
XIV, Ex
19. Let (E, A) and (E', A') be pairs consisting of a finite-dimensional vector space over a
field k, and a k-endomorphism. Show that these pairs are isomorphic if and only if
their invariants are equal.
20. (a) How many non-conjugate elements of GLiC ) are there with characteristic poly-
nomial t3(1 + 1)2(1 -
1)?
(b) How many with characteristic polynomial t 3 -
1001t?
21. Let V be a finite dimensional vector space over Q and let A : V ~ V be a Q-linear
map such that A5 = Id. Assume that if v E V is such that Av = v, then v = O. Prove
that dim V is divisible by 4.
22. Let V be a finite dimensional vector space over R, and let A : V ~ V be an R-linear
map such that A2 = - Id. Show that dim V is even, and that V is a direct sum of 2-
dimensional A-invariant subspaces.
23. Let E be a finite-dimensional vector space over an algebraically closed field k. Let
A, B be k-endomorphisms of E which commute, i.e. AB = BA. Show that A and B have
a common eigenvector. [Hint :
Consider a subspace consisting of all vectors having
a fixed element of k as eigenvalue.]
24. Let V be a finite dimensional vector space over a field k. Let A be an endomorphism
of V. Let TrlA'")be the trace of Amas an endomorphism of V. Show that the following
power series in the variable t are equal:
Compare with Exercise 23 of Chapter XVIII.
25. Let V, W be finite dimensional vector spaces over k, of dimension n. Let (v , w) ~
(v, w) be a non-singular bilinear form on V x W. Let c E k, and let A : V ~ V and
V : W ~ W be endomorphisms such that
(Av, Bw) = c(v, w) for all v E V and w E W.
Show that
and
det(A )det(tl - B) = (- Wdet(cl - tA)
det(A )det(B) = en.
For an application of Exercises 24 and 25 to a context of topology or algebraic
geometry , see Hartshorne 's Algebraic Geometry, Appendix C, §4.
26. Let G = SLn(C) and let K be the complex unitary group. Let A be the group of di-
agonal matrices with positive real components on the diagonal.
(a) Show that if g E NorG(A ) (normalizer of A in G), then c(g) (conjugation by
g) permutes the diagonal components of A , thus giving rise to a homo-
morphism NorG(A ) --4 W to the group W of permutations of the diagonal
coordinates.
By definition, the kernel of the above homomorphism is the centralizer CenG(A ).
(b) Show that actually all permutations of the coordinates can be achieved by
elements of K, so we get an isomorphism
In fact, the K on the right can be taken to be the real unitary group, because
permutation matrices can be taken to have real components (0 or ±I).

CHAPTER XV
Structure of Bilinear Forms
There are three major types of bilinear forms : hermitian (or symmetric),
unitary, and alternating (skew-symmetric). In this chapter, we give structure
theorems giving normalized expressions for these forms with respect to suitable
bases . The chapter also follows the standard pattern of decomposing an object
into a direct sum of simple objects, insofar as possible.
§1.
PRELIMINARIES, ORTHOGONAL SUMS
The purpose of this chapter is to go somewhat deeper into the structure
theory for our three types of forms. To do this we shall assume most of the time
that our ground ring is a field, and in fact a field of characteristic
-=1= 2 in the
symmetric case.
We recall our three definitions. Let E be a module over a commutative
ring R. Let g : E x E -+ R be a map. If g is bilinear, we call g a symmetric form
if g(x, y) = g(y, x) for all x, y E E. We call g alternating ifg(x, x) = 0, and hence
g(x, y) =
- g(y, x) for all x, y E E. If R has an automorphism of order 2,
written a ~ 5, we say that 9 is a hermitian form if it is linear in its first variable,
antilinear in its second, and
g(x, y) = g(y, x).
We shall write g(x, y) = <x, y) if the reference to g is clear.
We also oc-
casionally write g(x, y) = x . y or g(x, x) = x 2• We sometimes call g a scalar
product.
571
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

572
STRUCTURE OF BILINEAR FORMS
XV, §1
If V I "
' "
Vrn E E, we denote by ( Vi"
' " vrn) the submodule of E generated by
VI ' " '' Vrn •
Let g be symmetric, alternating, or hermitian. Then it is clear that the left
kernel ofg is equal to its right kernel, and it will simply be called the kernel of g.
In anyone of these cases, we say that g is non-degenerate if its kernel is O.
Assume that E is finite dimensional over the field k. The form is non-degenerate
if and only if it is non-singular, i.e., induces an isomorphism of E with its dual
space (anti-dual in the case of hermitian forms).
Except for the few remarks on the anti-linearity made in the previous
chapter, we don't use the results of the duality in that chapter. We need only
the duality over fields, given in Chapter III. Furthermore, we don't essentially
meet matrices again, except for the remarks on the pfaffian in §IO.
We introduce one more notation. In the study of forms on vector spaces,
we shall frequently decompose the vector space into direct sums of orthogonal
subspaces. IfE is a vector space with a form g as above, and F, F' are subspaces,
we shall write
E=F1-r
to mean that E is the direct sum of F and F', and that F is orthogonal (or
perpendicular) to F', in other words, x 1- y (or <x, y) = 0) for all x E F and
y E F'. We then say that E is the orthogonal sum of F and F'. There will be no
confusion with the use ofthe symbol 1-when we write F1- F' to mean simply that
F is perpendicular to F'. The context always makes our meaning clear.
Most of this chapter is devoted to giving certain orthogonal decompositions
ofa vector space withoneofourthree typesof forms, so that eachfactor in the sum
is an easily recognizable type.
In the symmetric and hermitian case, we shall be especially concerned with
direct sum decompositions into factors which are I-dimensional.
Thus if
<,) is symmetric or hermitian, we shall say that { VI' . • • ,vn } is an orthogonal
basis (with respect to the form) if <Vi' Vj ) = 0 whenever i
=1= j. We see that an
orthogonal basis gives such a decomposition. If the form is nondegenerate,
and if {VI"
' " vn } is an orthogonal basis, then we see at once that <V i ' V;)
=1= 0
for all i.
Proposition 1.1.
Let E be a vectorspace overthefield k, and let g be aform
ofone ofthe three abovetypes. Suppose that E is expressedas an orthogonal
sum,
E = EI 1-... 1- Ern.
Then g is non-degenerate on E if and only tf it is non-degenerate on each Ei •
If E? is the kernelofthe restriction ofg to Ei , then the kernel ofg in E is the
orthogonal sum

XV, §1
PRELIMINARIES, ORTHOGONAL SUMS
573
Proof
Elements v, W of E can be written uniquely
with Vi ' Wi E Ei . Then
m
V = I
Vi '
i = 1
m
W= IWi
i = 1
m
u
W = I
Vi ' w.,
i = 1
and u
W = 0 if Vi ' Wi = 0 for each i = 1, . . . , m. From this our assertion is
obvious.
Observe that if EI' . .. , Emare vector spaces over k, and gI '
, gmare forms
on these spaces respectively, then we can define a form g = g1 <±>
<±> gm on the
direct sum E = E1 <±> . . . <±> Em; namely if v, ware written as above, then we let
m
g(v, w) = I
g i( Vi , W;).
i = 1
It is then clear that, in fact, we have E = E 1 .1 .. . .1 Em . We could also write
g=gl.l··· .lgm·
Proposition 1.2.
Let E be a finite-dimensional space over the field k, and let
g be aform of the precedingtype on E. Assume that g is non-degenerate. Let
F be a subspace of E. The form is non-degenerate on F if and only if
F + r- = E, and also if and only if it is non-degenerate on F.1.
Proof
We have (as a trivial consequence of Chapter III , §5)
dim F + dim F.1 = dim E = dim(F + F.1) + dim(F (\ F.1).
Hence F + F.l = E if and only if dim(F (\ F.l) = O. Our first assertion follows
at once. Since F, F.1 enter symmetrically in the dimension condition, our second
assertion also follows.
Instead ofsaying that a form is non-degenerate on E, we shall sometimes say,
by abuse of language, that E is non-degenerate.
Let E be a finite-dimensional space over the field k, and let g be a form of
the preceding type. Let Eo be the kernel of the form. Then we get an induced
form of the same type
go: E/Eo x E/Eo -> k,
because g(x, y) depends only on the coset of x and the coset of y modulo Eo.
Furthermore, go is non-degenerate since its kernel on both sides is O.
Let E, E' be finite-dimensional vector spaces, with forms g, g' as above,
respectively. A linear map (7 : E -> E' is said to be metric if
g'«(7X, (7Y) = g(x, y)

574
STRUCTURE OF BILINEAR FORMS
XV, §2
or in the dot notation, (J X
• (Jy =
X
• Yfor all x, y E E. If (J is a linear isomorphism,
and is metric, then we say that (J is an isometry.
Let E, Eo be as above. Then we have an induced form on the factor space
E/Eo. If W is a complementary subspace of Eo, in other words, E = Eo (f) W,
and if we let (J : E -> E/Eo be the canonical map, then
(J is metric, and induces
an isometry of W on E/Eo. This assertion is obvious, and shows that if
E = Eo (f) W'
is another direct sum decomposition of E, then W' is isometric to W. We know
that W ~ E/Eo is nondegenerate. Hence our form determines a unique non-
degenerate form, up to isometry, on complementary subspaces of the kernel.
§2.
QUADRATIC MAPS
Let R be a commutative ring and let E, F be R-modules. We suppress the
prefix R- as usual. We recall that a bilinear map f :E x E -> F is said to be
symmetric iff(x, y) = f(y, x) for all x, y E E.
We say that F is without 2-torsion if for all y E F such that 2y = 0 we have
y = O. (This holds if 2 is invertible in R.)
Letf :E -> F be a mapping. We shall say thatfisquadratic (i.e, R-quadratic)
ifthere exists a symmetric bilinear map g : E x E -> F and a linear map h : E -> F
such that for all x E E we have
f(x) = g(x, x) + h(x).
Proposition 2.1.
Assume that F is without 2-torsion.
Let f: E -> F be
quadratic, expressed as above in terms of a symmetric bilinear map and a
linear map. Then g, h are uniquely determined by]. For all x, y E E we have
2g(x, y) = f(x + y) - f(x) - f(y)·
Proof.
If we compute f(x + y) - f(x) - f(y), then we obtain 2g(x, y).
If gt is symmetric bilinear, h, is linear, and f(x) = gt(x, x) + ht(x), then
2g(x, y) = 2gt(x, y). Since F is assumed to be without 2-torsion, it follows that
g(x, y) = g t (x, y) for all x, y E E, and thus that g is uniquely determined. But
then h is determined by the relation
h(x) = f(x) - g(x, x).
We call g, h the bilinear and linear maps associated with j.
Iff :E -> F is a map, we define
N :E x E->F

XV, §3
by
SYMMETRIC FORMS, ORTHOGONAL BASES
575
N(x, y) = l(x + y) - f(x) - fey)·
We say that f is homogeneous quadratic if it is quadratic , and if its associated
linear map is o. We shall say that F is uniquely divisible by 2 if for each Z E F
there exists a unique u E F such that 2u = z. (Again this holds if 2 is invertible
in R )
Proposition 2.2.
Let [: E -> F be a map such that to./ is bilinear. Assume
that F is unique ly divisible by 2.
Then the map x I--+I(x) - t N (x, x) is
Z- linear. l f] satisfie s the condition I(2x) = 4[(x), then I is homogeneous
quadratic.
Proof
Ob vious.
By a quadratic form on E, one means a homogeneous quadratic map
I :E -> R, with values in R
In what follows, we are principally concerned with symmetric bilinear
forms. The quadrat ic forms play a secondary role.
§3.
SYMMETRIC FORMS, ORTHOGONAL BASES
Let k be a field of characteristic *- 2.
Let E be a vecto r space over k , with the symmetric form g. We say that 9
is a null form or that E is a null space if ( x, Y) = 0 for all x, Y E E. Since we
assumed that the characteristic of k is ¥= 2, the condition x 2 = 0 for all x E E
implies that 9 is a null form. Indeed,
4x . y = (x + y)2 - (x - y?
Theorem 3.1.
Let E be *- 0 and finite dimensional over k. Let g be a sym-
metric fo rm on E. Then there exists an orthogonal basis.
Proof
We assume first that 9 is non-degenerate, and prove our assertion by
induction in that case. If the dim ension II is 1, then our assertion is obvious.
Assume n > 1. Let V I E E be such that vi -=f. 0 (such an element exists since
9 is assumed non-degenerate). Let F = ( VI) be the subspace generated by V I .
Then F is non-degenerate, and by Proposition 1.2, we have
E = F + F» .
Furtherm ore, dim Flo = n -
1. Let {V2' .. . , vn } be an orthogo nal basis of r-.

576
STRUCTURE OF BILINEAR FORMS
XV, §3
Then {vI' . . . , un} are pairwise orthogonal.
Furthermore, they are linearly
independent, for if
with a, E k then we take the scalar product with Vj to get a,vf = 0 whence ai= 0
for all i.
Remark.
We have shown in fact that if9 is non-degenerate, and v E Eis such
that v2 i= 0 then we can complete v to an orthogonal basis of E.
Suppose that the form 9 is degenerate. Let Eo be its kernel. We can write
E as a direct sum
E = Eo EB W
for some subspace W. The restriction of 9 to W is non-degenerate; otherwise
there would be an element of W which is in the kernel of E, and i= O. Hence if
{VI' . . . , Vr} is a basis of Eo, and {WI "
.• , IVn - r} is an orthogonal basis of W, then
is an orthogonal basis of E, as was to be shown.
Corollary 3.2.
Let {VI" ' " vn} be an orthogonal basis of E. Assume that
vf i= 0 for i ~ rand vr = 0 for i > r. Then the kernel of E is equal to
(vr+I , · ·· ,vn )·
Proof
Obvious.
If {v I' . . . , Vn} is an orthogonal basis of E and if we write
with Xi E k, then
where a, = <Vj, v). In this representation of the form, we say that it is diagonal-
ized. With respect to an orthogonal basis, we see at once that the associated
matrix of the form is a diagonal matrix, namely
Q2
o
Qr
o
o
o

XV, §4
SYMMETRIC FORMS OVER ORDERED FIELDS
577
Example.
Note that Exercise 33 of Chapter XIII gave an interesting example
of an orthogonal decomposition involving harmonic polynomials.
§4.
SYMMETRIC FORMS OVER ORDERED FIELDS
Theorem 4.1.
(Sylvester)
Let k be an ordered field and let E be a finite
dimensional vector space over k, with a non-degenerate symmetricf orm g. There
exists an integer r ~ 0 such that. if {Vb ' .. ,vn } is an orthogonal basis of E.
then precisely r among the n elementsvr.....v ~ are > 0, and n -
r among
these elements are < 0.
Proof
Let a, = vf , for i = 1, . . . , n. After renumbering the basis elements,
say al" . . , a, > 0 and a, < 0 for i > r. Let {WI' . . . , wn} be any orthogonal basis,
and let b, = wf. Say b l , ... , b, > 0 and b, < 0 for j > s. We shall prove that
r = s. Indeed, it will suffice to prove that
are linearly independent, for then we get r + n - s ~ n, whence r ~ s, and
r = s by symmetry. Suppose that
Then
Squaring both sides yields
The left-hand side is ~ 0, and the right-hand side is ~ O. Hence both sides are
equal to 0, and it follows that Xi = Yj = 0, in other words that our vectors are
linearly independent.
Corollary 4.2. Assume that every positive element of k is a square. Then
there ex ists an orth ogonal basis {Vb "
"
vn } of E such that vf = I for i ~ r
and vf = - I f or i > r, and r is uniquely determined.
Proof
We divide each vector in an orthogonal basis by the square root of
the absolute value of its square.
A basis having the property of the corollary is called orthonormal. If X is an
element of E having coordinates (XI" '"
x n) with respect to this basis, then
x 2 = xi + ... + x; - x;+
I
-
.. . - x;.

578
STRUCTURE OF BILINEAR FORMS
XV, §4
We say that a symmetric form 9 is positive definite if X2 > 0 for all
X E E, X * O. This is the case if and only if r = n in Theorem 4.1. We say
that 9 is negative definite if X2 < 0 for all X E E, X* O.
Corollary 4.3. The vector space E admits an orthogonal decomposition
E = E+ 1- E- such that g is positive definite on E+ and negative definite on
E- . The dimension of E+ (or E-) is the same in all such decompositions.
Let us now assume that the form g is positive definite and that every positive
element ofk is a square.
We define the norm of an element V E E by
IVI= ~ .
Then we have Ivi > 0 if v =F O. We also have the Schwarz inequality
Iv ,wl~lvllwl
for all v, WEE. This is proved in the usual way, expanding
o ~ (av ± bW)2 = (av ± bw) . (av ± bw)
by bilinearity, and letting b = IvIand a = IwI. One then gets
=+= 2ab v . w ~ 21v121 w12.
IfIvlor IwI = 0 our inequality is trivial. Ifneither is 0 we divide by IvIIwIto get
what we want.
From the Schwarz inequality, we deduce the triangle inequality
Iv+ w] ~ Ivl + [w].
We leave it to the reader as a routine exercise.
When we have a positive definite form, there is a canonical way of getting an
orthonormal basis, starting with an arbitrary basis {VI ' . .. , vn} and proceeding
inductively. Let
Then VI has norm 1. Let
and then

XV, §5
Inductively, we let
HERMITIAN FORMS
579
and then
The {V'r, .. . , v~} is an orthonormal basis. The inductive process just described
is known as the Gram-Schmidt orthogonalization.
§5.
HERMITIAN FORMS
Let kobe an ordered field (a subfield of the reals, ifyou wish) and let k = ko(i),
where i = j=l. Then k has an automorphism of order 2, whose fixed field
is ko.
Let E be a finite-dimensional vector space over k. We shall deal with a hermi-
tian form on E, i.e. a map
E xE-+k
written
(x, y) 1---+ <x, y)
which is k-Iinear in its first variable, k-anti-linear in its second variable, and such
that
<x, y) = <y, x )
for all x, y E E.
We observe that <x, x ) E ko for all x E E. This is essentially the reason why
the proofs of statements concerning symmetric forms hold essentially without
change in the hermitian case. We shall now make the list of the properties which
apply to this case.
Theorem 5.1.
There exists an orthogonal basis. Iftheform is non-degenerate,
there exists an integer r having the following property . If {VI' . .. , vn} is an
orthogonal basis, then precisely r among the n elements
(VI' VI), . . . , (vn• vn )
are > 0 and n - r among these elements are < O.

580
STRUCTURE OF BILINEAR FORMS
XV, §5
An orthogonal basis { V I' . . . , Vn } such that <Vi> Vi) = I or -I is called an
orthonormal basis.
Corollary 5.2.
Assume that theform isnon-degenerate, and that every positive
element of ko is a square. Then there exists an orthonormal basis.
We say that the hermitian form is positive definite if (x, x) > 0 for all
x E E. We say that it is negative definite if (x, x) < 0 for all x E E, x =t= O.
Corollary 5.3.
Assume that the form is non-degenerate . Then E admits an
orthogonal decomposition E = E+ .1 E- such that the form is positive definite
on E+ and negative definite on E- . The dimension of E+ (or E-) is the same
in all such decompositions.
The proofs of Theorem 5.1 and its corollaries are identical with those of the
analogous results for symmetric forms, and will be left to the reader.
We have the polarization identity, for any k-linear map A : E ~ E, namely
<A(x + y), (x + y» - <A(x - y), (x - y» = 2[<Ax, y) + <Ay, x )].
If <Ax, x) = 0 for all x, we replace x by ix and get
<Ax, y ) + <Ay, x) = 0,
i<Ax, y ) - i<Ay, x) = O.
From this we conclude:
If <Ax, x) = 0, for all x, then A = O.
This is the only statement which has no analogue in the case of symmetric
forms. The presence of i in one of the above linear equations is essential to the
conclusion. In practice, one uses the statement in the complex case, and one
meets an analogous situation in the real case when A is symmetric. Then the
statement for symmetric maps is obvious.
Assume that the hermitian form is positive definite, and that every positive
element ofko is a square.
We have the Schwarz inequality, namely
l<x,y)1 2 ~ ( x, x ) <y, y)
whose proof comes again by expanding
o ~ <ax + py,ax + py)
and setting a = <y, y ) and p = - ( x, y ).
We define the norm of [x] to be
[x] = J <x, x ).

XV, §6
THE SPECTRAL THEOREM (HERMITIANCASE)
581
Then we get at once the triangle inequality
[r + yl ~ Ixl + Iyl,
and for II. E k,
IaxI = 11I.11xl·
Just as in the symmetric case, given a basis, one can find an orthonormal
basis by the inductive procedure of subtracting successive projections. We leave
this to the reader.
§6.
THE SPECTRAL THEOREM (HERMITIAN CASE)
Throughout this section , we let E be afinite dimensional space over C, ofdimension
~ I , and we endow E with a positive definite hermitian form .
Let A : E -+ E be a linear map (i.e. C-linear map) of E into itself. For fixed
Y E E, the map x 1---+ <Ax, y) is a linear functional, and hence there exists a
unique element y* E E such that
<Ax, y) = <x, y*)
for all x E E. We define the map A*:E -+ E by A*Y = y*. It is immediately
clear that A* is linear, and we shall call A* the adjoint of A with respect to our
hermitian form.
The following formulas are trivially verified, for any linear maps A, B of E
into itself:
(A + B)* = A* + B*,
(II.A)* = aA*,
A** = A,
(AB)* = B*A*.
A linear map A is called self-adjoint (or hermitian) if A* = A.
Proposition 6.1.
A is hermitian if and only if<Ax, x) is real for all x E E.
Proof
Let A be hermitian. Then
<Ax, x) = <x, Ax) = <Ax, x ),
whence <Ax, x) is real. Conversely, assume <Ax, x) is real for all x. Then
<Ax, x) = <Ax, x) = <x, Ax) = <A*x, x ),
and consequently <(A - A*)x, x) = 0 for all x. Hence A = A* by polarization.

582
STRUCTURE OF BILINEAR FORMS
XV, §6
Let A : E -+ E be a linear map. An element ¢ E E is called an eigenvector
of A if there exists AE C such that A¢ = A¢. If ¢ =1= 0, then we say that Ais an
eigenvalue of A, belonging to ¢.
Proposition 6.2.
Let A be hermitian. Then all eigenvalues belonging to
nonzero eigenvectors of A are real. If g, f
are eigenvectors * 0 having
eigenvalues A, X respectively, and if A* X, then g ..1 f.
Proof
Let A be an eigenvalue, belonging to the eigenvector ¢ =1= O. Then
<A¢, 0
= <¢, AO, and these two numbers are equal respectively to A<¢, 0
and A:<¢, O. Since ¢ =1= 0, it follows that A= A, i.e. that A is real. Secondly,
assume that ¢, ¢' and A, X are as described above. Then
<A¢, ¢') = A<¢, ¢') = <¢, A¢') = A'<¢, ¢'),
from which it follows that <¢, ¢') = O.
Lemma 6.3.
Let A : E ~ E be a linear map, and dim E ~ I. Then there
exists at least one non-zero eigenvector of A.
Proof
We consider C[A], i.e. the ring generated by A over C. As a vector
space over C, it is contained in the ring of endomorphisms of E, which is finite
dimensional, the dimension being the same as for the ring of all n x n matrices
if n = dim E. Hence there exists a non-zero polynomial P with coefficients in
C such that P(A) = O. We can factor P into a product of linear factors,
with AjE C. Then (A - At /) ' " (A - Am/) = O. Hence not all factors A - AjI
can be isomorphisms, and there exists AE C such that A - AI is not an iso-
morphism. Hence it has an element ¢ =1= 0 in its kernel, and we get A¢ - A¢ = O.
This shows that ¢ is a non-zero eigenvector, as desired.
Theorem 6.4.
(Spectral Theorem, Hermitian Case).
Let E be a non-
zero finite dimensional vector space over the complex numbers, with a positive
definite hermitian form . Let A: E ~ E be a hermitian linear map. Then E has
an orthogonal basis consisting of eigenvectors ofA.
Proof
Let ¢I be a non-zero eigenvector, with eigenvalue At, and let E, be
the subspace generated by ¢I' Then A maps Et into itself, because
whence AEt is perpendicular to ~I'
Since ~I
=1= 0 we have <~I' ~I) > 0 and hence, since our hermitian form is
non-degenerate (being positive definite), we have
E = E 1 Ee Et.

XV, §6
THE SPECTRAL THEOREM (HERMITIAN CASE)
583
The restriction of our form to Et is positive definite (if dim E > 1). From
Proposition 6.1, we see at once that the restriction of A to Efis hermitian. Hence
we can complete the proof by induction .
Corollary 6.5.
Hypotheses being as in the theorem, there exists an ortho-
normal basis consisting of eigenvectors ofA .
Proof
Divide each vector in an orthogonal basis by its norm.
Corollary 6.6.
Let E be a non-zero finite dimensional vector space over the
complex numbers, with a positive definite hermitian form f. Let g be another
hermitian form on E. Then there exists a basis of E which is orthogonal for
bothf and g.
Proof
We write f(x, Y) = (x, y). Since f is non-singular, being positive
definite, there exists a unique hermitian linear map A such that g(x, y) = <Ax, y)
for all x, y E E. We apply the theorem to A, and find a basis as in the theorem,
say {Vb " " Vn}. Let Ai be the eigenvalue such that AVi = AiV;, Then
g(V;, v) = <Av;,v) = A/Vi' Vj),
and therefore our basis is also orthogonal for g, as was to be shown.
We recall that a linear map V : E ~ E is unitary if and only if V* = V-\ .
This condition is equivalent to the property that (Vx, Vy) = (x, y) for all elements
x, y E E. In other words, V is an automorphism of the formf.
Theorem 6.7.
(Spectral Theorem, Unitary Case).
Let E be a non-zero
finite dimensional vector space over the complex numbers, with a positive definite
hermitianform. Let U: E~ E be a unitary linear map. ThenE has an orthogonal
basis consisting of eigenvectors of U.
Proof
Let ~ I
=1= 0 be an eigenvector of V . It is immediately verified that
the subspace of E orthogonal to ~I is mapped into itself by V, using the relation
V* = V-I, because if IJ is perpendicular to ~ 1, then
Thus we can finish the proof by induction as before.
Remark.
If Ais an eigenvalue of the unitary map V, then Ahas necessarily
absolute value 1 (because V preserves length), whence Acan be written in the
form ei8 with 0 real, and we may view Vas a rotation.
Let A : E ~ E be an invertible linear map. Just as one writes a non-zero
complex number z = re'" with r > 0, there exists a decomposition of A as a
product called its polar decomposition. Let P : E ~ E be linear. We say that P
is semipositive if P is hermitian and we have (Px, x) ~ 0 for all x E E. If we
have (Px, x) > 0 for all x*"O in E then we say that P is positive definite . For

584
STRUCTURE OF BILINEAR FORMS
XV, §7
example, if we let P = A*A then we see that P is positive definite, because
(A*Ax, x) = (Ax, Ax) > 0 if x * o.
Proposition 6.8.
Let P be semipositive. Then P has a unique semipositive
square root B : E ~ E, i.e. a semipositive linear map such that B2 = P.
Proof.
For simplicity, we assume that P is positive definite . By the spectral
theorem, there exists a basis of E consisting of eigenvectors. The eigenvalues
must be> 0 (immediate from the condition of positivity). The linear map defined
by sending each eigenvector to its multiple by the square root of the corresponding
eigenvalue satisfies the required conditions. As for uniqueness, sinceB commutes
with P because B2 = P, it follows that if {VI' . . . , vn } is a basis consisting of
eigenvectors for P, then each Vi is also an eigenvector for B. (Cf. Chapter XIV,
Exercises 12 and 13(d).) Since a positive number has a unique positive square
root, it follows that B is uniquely determined as the unique linear map whose
effect on Vi is multiplication by the square root of the corresponding eigenvalue
for P.
Theorem 6.9.
Let A :E ~ E be an invertible linear map. Then A can be
written in a unique way as a product A = UP, where U is unitary and P is
positive definite.
Proof.
Let P = (A*A)1I2, and let U = AP- I. Using the defiitions, it is
immediately verified that U is unitary, so we get the existence of the decom-
position. As for uniqueness, suppose A = UIPI. Let
U2 = PPI I = U-IUI'
Then U2 is unitary, so Ui U2 = I . From the fact that p* = P and Pj = P\> we
conclude that p2 = PI. Since P, PI are Hermitian positive definite, it follows
as in Proposition 6.8 that P = PI' thus proving the theorem.
Remark.
The arguments used to prove Theorem 6.9 apply in the case of
Hilbert space in analysis. Cf. my Real Analysis. However, for the uniqueness,
since there may not be "eigenvalues", one has to use another technique from
analysis, described in that book.
As a matter of terminology, the expression A = UP in Theorem 6.9 is called
the polar decomposition of A. Of course, it does matter in what order we write
the decomposition. There is also a unique decomposition A = PIU1 with PI
positive definite and UI unitary (apply Theorem 6.9 to A- I, and then take
inverses).
§7.
THE SPECTRAL THEOREM (SYMMETRIC CASE)
Let E be a finite dimensional vector space over the real numbers, and let g be
a symmetricpositive definite form on E. If A :E ~ E is a linear map, then we know

XV, §7
THE SPECTRAL THEOREM (SYMMETRIC CASE)
585
that its transpose, relative to g, is defined by the condition
<Ax, y) = <x, fAy )
for all x, y E E. We say that A is symmetric if A = fA. As before, an element
; E E is called an eigenvector of A if there exists AE R such that A; = A;, and A
is called an eigenvalue if; =f. O.
Theorem 7.1.
(Spectral Theorem, Symmetric Case).
Let E "* O. Let
A : E ~ E be a symm etric linear map . Then E has an orthogonal basis
consisting of eigenvectors of A.
Proof.
If we select an orthogonal basis for the positive definite form,
then the matrix of A with respect to this basis is a real symmetric matrix, and
we are reduced to considering the case when E = R", Let M be the matrix repre-
senting A. We may view M as operating on en, and then M represents a hermi-
tian linear map. Let z =f. 0 be a complex eigenvector for M, and write
z = x + iy,
with x, y ERn. By Proposition 6.2, we know that an eigenvalue A for M , be-
longing to z, is real, and we have Mz = Az. Hence Mx = Ax and My = Ay.
But we must have x =f. 0 or y =f. O. Thus we have found a nonzero eigenvector
for M, namely, A, in E. We can now proceed as before. The orthogonal comple-
ment of this eigenvector in E has dimension (n -
1), and is mapped into itself by
A. We can therefore finish the proof by induction.
Remarks.
The spectral theorems are valid over a real closed field; our
proofs don't need any change. Furthermore, the proofs are reasonably close
to those which would be given in analysis for Hilbert spaces, and compact
operators. The existence of eigenvalues and eigenvectors must however be
proved differently, for instance using the Gelfand-Mazur theorem which we have
actually proved in Chapter XII, or using a variational principle (i.e. finding a
maximum or minimum for the quadratic function depending on the operator).
Corollary 7.2.
Hypotheses being as in the theorem , there exists an ortho-
normal basis consisting of eigenvectors of A .
Proof
Divide each vector in an orthogonal basis by its norm.
Corollary 7.3.
Let E be a non-zero finite dimensional vector space over the
reals, with a positive definite symmetric form f. Let g be another symmetric
form on E. Then there exists a basis ofE which is orthogonal for both f and g.
Proof
We write f(x, y) = <x, y ). Since f is non-singular, being positive
definite, there exists a unique symmetric linear map A such that
g(x, y) = <Ax, y )

586
STRUCTURE OF BILINEAR FORMS
XV, §8
for all x, y E E. We apply the theorem to A, and find a basis as in the theorem.
It is clearl y an orthogonal basis for 9 (cf. the same proof in the hermitian case).
The analogues of Propo sition 6.8 and the polar decomposition also hold in
the present case, with the same proofs. See Exerc ise 9.
§8.
ALTERNATING FORMS
Let E be a vector space over the field k,on which we now make no restriction.
We letfbe an alternating form on E, i.e. a bilinear mapf :E x E --+ k such that
f (x, x) = x 2 = 0 for all x E E. Then
x 'y = -y ·x
for all x, y E E, as one sees by substituting (x + y) for x in x 2 = O.
We define a hyperbolic plane (for the alternating form ) to be a 2-dimensional
space which is non-degenerate. We get automatically an element w such that
w2 = 0, W '* O. If P is a hyperbolic plane, and W E P, w '* 0, then there exists
an element y '* 0 in P such that w . y '* O. After dividing y by some constant,
we may assume that w . y = I . Then y . w = - I . Hence the matrix of the form
with respect to the basis {w, y} is
The pair w, y is called a hyperbolic pairas before. G iven a 2-dimensional vector
space over k with a bilinear form, and a pair of elements {w, y} satisfying the
relations
y . w = -1,
w -y = 1,
then we see that the form is alternating, and that (w, y) is a hyperbolic plane for
the form.
Gi ven an alternating form f on E, we say that E (or.f) is hyperbolic if E is
an orthogonal sum of hyperbolic planes. We say that E (or f) is nullif x .y = 0
for all x, y E E.
Theorem 8.1.
Let f be an alternating form on the finite dimensional vector
space E over k. Then E is an orthogonal sum of its kernel and a hyperbolic
subspace. IfE is non-degenerate. then E is a hyperbolic space. and its dimension
is even.
Proof
A complementary subspace to the kernel is non-degenerate, and
hence we may assume that E is non-degenerate.
Let wEE, w i= O. There
exists y E E such that w . y i= 0 and y ¥= O. Then (w, y) is non-degenerate, hence
is a hyperbolic plane P. We have E = P Ei1 p J. and p J. is non-degenerate. We

XV, §8
complete the proof by induction.
ALTERNATING FORMS
587
Corollary 8.2.
All alternating non-degenerate form s of a given dimension
over a field k are isometric.
We see from Theorem 8.1 that there exists a basis of E such that relative to
this basis , the matrix of the alternating form is
o
1
-I
0
o
1
-1
0
o
1
-1
0
o
o
For convenience of writing, we reorder the basis elements of our orthogonal
sum of hyperbolic planes in such a way that the matrix of the form is
t, 0)
o 0
o 0
where l, is the unit r x r matrix. The matrix
(
0
I r )
-I r
0
is called the standard alternating matrix.
Corollary 8.3.
Let E be a finite dimensional vector space over k, with a
non-degenerate symmetric form denoted by < ,
>. Let n be a non-de-
generate alternating form on E. Then there exists a direct sum decomposition
E = E I EB E 2 and a symmetric automorphism A of E (with respect to < , »
having the following property . If x, y E E are written

588
STRUCTURE OF BILINEAR FORMS
then
XV, §9
Proof.
Take a basis of E such that the matrix of 0 with respect to this basis
is the standard alternating matrix. Let J be the symmetric non-degenerate
form on E given by the dot product with respect to this basis. Then we obtain
a direct sum decomposition of E into subspaces EI' Ez (corresponding to the
first n, resp. the last n coordinates), such that
O(x, y) = J(x l , Yz) - J(xz, YI)'
Since <, >is assumed non-degenerate, we can find an automorphism A having
the desired effect, and A is symmetric becauseJ is symmetric.
§9.
THE PFAFFIAN
An alternating matrix is a matrix G such that 'G =
- G and the diagonal
elements are equal to O. As we saw in Chapter XIII , §6, it is the matrix of an
alternating form . We let G be an n x n matrix, and assume n is even. (For odd
n, cf. exercises.)
We start over a field of characteristic O. By Corollary 8.2, there exists a non-
singular matrix C such that lCGC is the matrix
( ° I, 0)
-1,
0
0
o
0
0
and hence
det( C)Z det( G) = 1
or
0
according as the kernel of the alternating form is trivial or non-trivial. Thus in
any case, we see that det(G) is a square in the field.
Now we move over to the integers Z. Let tij (1 ~ i < j
~ n) be n(n -
1)/2
algebraically independent elements over Q, let l u = 0 for i = 1, . .. , n, and let
tij = - tj i for i > j. Then the matrix T = (tij) is alternating, and hence det(T)
is a square in the field Q(t) obtained from Q by adjoining all the variables tij'
However, det(T) is a polynomial in Z[t],and since we have unique factorization
in Z[t], it follows that det(T) is the square of a polynomial in Z[tl We can write
The polynomial P is uniquely determined up to a factor of ± 1. If we substitute

XV, §10
values for the tij so that the matrix T specializes to
WITT'S THEOREM
589
then we see that there exists a unique polynomial P with integer coefficients
taking the value I for this specialized set of values of (r). We call P the generic
Pfaffian of size n, and write it Pf.
Let R be a commutative ring. We have a homomorphism
Z[t] ~ R[t]
induced by the unique homomorphism of Z into R. The image of the generic
Pfaffian of size n in R[t] is a polynomial with coefficients in R, which we still
denote by Pf. If G is an alternating matrix with coefficients in R, then we write
Pf(G) for the value of Pf(t) when we substitute g ij for 'u in Pf. Since the deter-
minant commutes with homomorphisms, we have:
Theorem 9.1.
Let R be a commutative ring. Let (gij) = G be an alternating
matrix with gij E R. Then
det(G) = (Pf(G»2.
Furthermore, if C is an n x n matrix in R, then
pf(CerC) = det(C) Pf(G).
Proof
The first statement has been proved above. The second statement
will follow if we can prove it over Z. Let uij (i,j = I, . . . , n) be algebraically
independent over Q, and such that Uij ' tij are algebraically independent over Q.
Let U be the matrix (uij)' Then
Pf(UT1U) = ± det(U) Pf(T),
as follows immediately from taking the square of both sides. Substitute values
for U and T such that U becomes the unit matrix and T becomes the standard
alternating matrix. We conclude that we must have a + sign on the right-hand
side. Our assertion now follows as usual for any substitution of U to a matrix in
R, and any substitution of T to an alternating matrix in R, as was to be shown.
§10.
WITT'S THEOREM
We go back to symmetric forms and we let k be a field of characteristic *' 2.

590
STRUCTURE OF BILINEAR FORMS
XV, §10
Let E be a vector space over k, with a symmetric form . We say that E is a
hyperbolic plane if the form is non-degenerate, if E has dimension 2, and if there
exists an element 11' i= 0 in E such that wZ = O. We say that E is a hyperbolic
spaceif it is an orthogonal sum of hyperbolic planes. We also say that the form
on E is hyperbolic.
Suppose that E is a hyperbolic plane, with an element
11' i= 0 such that
WZ = O. Let u E E be such that E = (11', u). Then u . 11' i= 0; otherwise 11' would
be a non-zero element in the kernel. Let bE k be such that 11' • bu = bw .u = I.
Then select a E k such that
(aw + bu? = 2abw. u + bZuz = O.
(This can be done since we deal with a linear equation in a.) Put v = aw + bu.
Then we have found a basis for E, namely E = (11', v) such that
WZ =
VZ = 0
and
11' • V = I.
Relative to this basis, the matrix of our form is therefore
We observe that, conversely, a space E having a basis {w, v} satisfying
WZ = VZ = 0 and 11' • V = I is non-degenerate, and thus is a hyperbolic plane. A
basis {w, v} satisfying these relations will be called a hyperbolic pair.
An orthogonal sum of non-degenerate spaces is non-degenerate and hence
a hyperbolic space is non-degenerate. We note that a hyperbolic space always
has even dimension.
Lemma 10.1.
Let E be afinite dimensional vector space over k, with a non-
degenerate symmetric form g. Let F be a subspace, Fo the kernel of F, and
suppose we have an orthogonal decomposition
F = Fa.1 U.
Let {wI ' . . . , ws } be a basis oj Fa. Then there exist elements VI' • • • , Vs in E
perpendicular to U, suchthat eachpair {Wi' v;} is a hyperbolic pairgenerating
a hyperbolic plane Pi' and such that we have an orthogonal decomposition
U .1PI.1 .. · .1 PS •
Proof
Let
U I = (wz, . . . , ws) EB U.
Then U I is contained in Fa EB U properly, and consequently (Fa EB U).i is

XV, §10
WITTS THEOREM
591
contained in vt properly. Hence there exists an element 1/1E vt but
We have WI ' 1/1 i= 0, and hence (W., uI) is a hyperbolic plane PI'
We have
seen previously that we can find VI E PI such that {W I' vd is a hyperbolic pair.
Furthermore, we obtain an orthogonal sum decomposition
Then it is clear that (wz, . . . , ws) is the kernel of F I ' and we can complete the
proof by induction.
Theorem 10.2
Let E be a finite dimensional vector space over k, and let g
be a non-degenerate symmetric form on E. Let F, F' be subspaces of E, and
let U" : F ~ F' be an isometry. Then U"can be extended to an isometry ofE onto
itself,
Proof
We shall first reduce the proof to the case when F is non-degenerate.
We can write F = Fo 1- V as in the lemma of the preceding section, and
then aF = F = aF 0 1-cU, Furthermore, aF 0 = Fa is the kernel of F . No w
we can enlarge both F and F as in the lemma to orthogo na l sums
V 1- PI1-· · ·1- Ps
and
«u 1- P'I1-·
·
· 1- P~
corresponding to a choice of basis in F0 and its corresponding image in Fa.
Thus we can extend a to an isometry of these extended spaces, which are non-
degenerate. This gives us the desired reduction.
We assume that F, F' are non-degenerate, and proceed stepwise.
Suppose first that F' = F, i.e. that (J is an isometry of F onto itself. We can
extend a to E simply by leaving every element of F.l fixed.
Next, assume that dim F = dim F = 1 and that F i= F . Say F = (v) and
F = (v'). Then VZ = v'z. Furthermore, (v, v') has dimension 2.
If (v, v') is non -degenerate, it has an isometry extending a, which maps v on
v' and v' on v. We can apply the preceding step to conc lude the proof.
If (v, v') is degenerate, its kernel has dimension 1. Let w be a basis for this
kernel. There exist a, b e k such that v' = av + bw. Then v'z = aZvz and hence
a = ± 1. Replacing v' by - v' if necessary, we may assume a = 1. Replacing w
by bw , we may assume o' = v + w. Let z = v + v'. We apply Lemma 10.1 to
the space
(w, z) = (w) 1-(z).
We can find an element y E E such that
y· z = 0,
l
= 0,
and
w . y = 1.

592
STRUCTURE OF BILINEAR FORMS
XV, §10
The space (z, w, y) = (z) .L (w, y) is non-degenerate, being an orthogonal sum
of (z) and the hyperbolic plane (w, y). It has an isometry such that
z~z,
w~ -w,
y~-y .
But v = !(z - w) is mapped on v' = !(z + w) by this isometry.
We have
settled the present case.
We finish the proof by induction. By the existence of an orthogonal basis
(Theorem 3.1), every subspace F of dimension > 1 has an orthogonal de-
composition into a sum of subspaces of smaller dimension. Let F = F I .L F 2
with dim F I and dim F 2 ~ I. Then
aF = aF I -l aF2.
Let a I = aIF I be the restriction of a to F I ' By induction, we can extend a I to
an isometry
iii: E -+ E.
Then iil(Ff) = (a IF I)l . Since aF2 is perpendicular to aF I = aIFI, it follows
that aF2 is contained in iil(Ff). Let a2 = a1F2. Then the isometry
extends by induction to an isometry
The pair (ai ' <12 ) gives us an isometry of F I -l Ft = E onto itself, as desired.
Corollary 10.3.
Let E, E' be finite dimensional vector spaces with non-
degenerate symmetric forms , and assume that they are isometric. Let F, F' be
subspaces, and let (F : F ~ F' be an isometry. Then (F can be extended to an
isometry of E onto E'.
Proof
Clear.
Let E be a space with a symmetric form g, and let F be a null subspace.
Then by Lemma 10.1, we can embed F in a hyperbolic subspace H whose
dimension is 2 dim F.
As applications of Theorem 10.2, we get several corollaries.
Corollary 10.4.
Let E be a finite dimensional vector space with a non-
degenerate symmetric form. Let W be a maximal null subspace, and let W' be
some null subspace. Then dim W'
~ dim W, and W' is contained in some
maximal null subspace, whose dimension is the same as dim W.

XV, §10
WITTS THEOREM
593
Proof
That W ' is contained in a maximal null subspace follows by Zorn's
lemma. Suppose dim W' ~ dim W. We have an isometry of W onto a subspace
of W' which we can extend to an isometry of E onto itself. Then (J- '(W') is a
null subspace containing W, hence is equal to W, whence dim W = dim W'.
Our assertions follow by symmetry.
Let E be a vector space with a non-degenerate symmetric form . Let W be a
null subspace. By Lemma 10.1 we can embed W in a hyperbolic subspace H of
E such that W is the maximal null subspace of H, and H is non-degenerate. Any
such H will be called a hyperbolic enlargement of W.
Corollary 10.5.
Let E be a finite dimensional vector space with a non-
degenerate symmetric form . Let Wand W' be maximal null subspaces. Let H,
H' be hyperbolic enlargements ofW, W' respectively. Then H, H' are isometric
and so are H 1. and H' 1. .
Proof
We have obviously an isometry of H on H', which can be extended
to an isometry of E onto itself. This isometry maps H1. on H'L, as desired.
Corollary 10.6.
Let gl' g2' h be symmetricforms on finite dimensional vector
spaces over the field of k. If gl E& h is isometric to g2 E& h, and if g" g2 are
non-degenerate, then gl is isometric to g2'
Proof
Let g, be a form on E, and g2 a form on E2. Let h be a form on F.
Then we have an isometry between FEEl E1 and FEEl E2 • Extend the identity
id : F ~ F to an isometry (T of F E& E1 to F E& E 2 by Corollary 10.3. Since E\
and E2 are the respective orthogonal complements of F in their two spaces, we
must have (T(E 1) = E2, which proves what we wanted.
If 9 is a symmetric form on E, we shall say that 9 is definite if g(x, x) *" 0
for any x E E , x*"O (i.e. x 2 *" 0 if x *" 0).
Corollary 10.7.
Let 9 be a symmetricform on E. Then 9 has a decomposition
as an orthogonal sum
9 = go EEl ghyp EEl gdef
where go is a null form,
ghyp is hyperbolic, and gdef is definite. The form
ghyp EEl gdef is non-degenerate.
The forms go, ghyp, and
gdef are uniquely
determined up to isometries.
Proof
The decomposition 9 = go EEl g, where go is a null form and g\
is non-degenerate is unique up to an isometry, since go corresponds to the
kernel of g.
We may therefore assume that 9 is non-degenerate. If

594
STRUCTURE OF BILINEAR FORMS
XV, §11
where gh is hyperbolic and gd is definite, then gh corresponds to the hyperbolic
enlargement of a maximal null subspace, and by Corollary 10.5 it follows that
gh is uniquely determined. Hence gd is uniquely determined as the orthogonal
complement of gh' (By uniquely determined, we mean of course up to an
isometry.)
We shall abbreviate ghyp by gh and gdef by gd'
§11.
THE WITT GROUP
Let g, 'Pby symmetric forms on finite dimensional vector spaces over k. We
shall say that they are equivalent if gd is isometric to 'Pd' The reader will verify
at once that this is an equivalence relation. Furthermore the (orthogonal) sum
oftwo null forms is a null form, and the sum of two hyperbolic forms is hyperbolic.
However, the sum of two definite forms need not be definite. We write our
equivalence 9 - 'P. Equivalence is preserved under orthogonal sums, and hence
equivalence classes of symmetric forms constitute a monoid.
Theorem 11.1.
The monoid of equivalence classes ofsymmetric forms (over
the field k) is a group .
Proof
We have to show that every element has an additive inverse. Let 9
be a symmetric form, which we may assume definite. We let -g be the form
such that (-g)(x, y) = -g(x, y). We contend that 9 EEl -g is equivalent to O.
Let E be the space on which 9 is defined. Then 9 EEl - 9 is defined on E EEl E.
Let W be the subspace consisting of all pairs (x, x) with x E E. Then W is a null
space for 9 EEl -g. Since dim(E EEl E) = 2 dim W, it follows that W is a maximal
null space, and that 9 EEl - 9 is hyperbolic, as was to be shown.
The group of Theorem 11.1 will be called the Witt group of k, and will be
denoted by W(k). It is of importance in the study of representations of elements
of k by the quadratic form f arising from 9 [i.e. f(x) = g(x, x»), for instance
when one wants to classify the definite forms f.
We shall now define another group, which is of importance in more functorial
studies of symmetric forms, for instance in studying the quadratic forms arising
from manifolds in topology.
We observe that isometry classes of non-degenerate symmetric forms (over
k) constitute a monoid M(k), the law of composition being the orthogonal sum.
Furthermore, the cancellation law holds (Corollary 10.6). We let
cI : M(k) --+ WG(k)

XV, Ex
EXERCISES
595
be the canonical map of M(k) into the Grothendieck group of this monoid,
which we shall call the Witt-Grothendieck group over k. As we know, the
cancellation law implies that cl is injective.
If g is a symmetric non-degenerate form over k, we define its dimension
dim g to be the dimension of the space E on which it is defined. Then it is clear
that
dim(g E9 g') = dim g + dim g'.
Hence dim factor s through a homomorphism
dim : WG(k) --> Z.
This homomorphism splits since we have a non-degenerate symmetric form of
dimension 1.
Let WGo(k) be the kernel of our homomorphism dim. If g is a symmetric
non-degenerate form we can define its determinant det(g) to be the determinant
of a matrix G representing g relative to a basis, modulo squares. This is well
defined as an element of k*/k*2. We define det of the O-formto be 1. Then det is
a homomorphism
det: M(k) --> k*/k*2,
and can therefore be factored through a homomorphism, again denoted by
det, of the Witt-Grothendieck group, det : WG(k) --> k*/k*2.
Other properties of the Witt-Grothendieck group will be given in the
exercises.
EXERCISES
I. (a) Let E be a finite dimensional space over the complex numbers, and let
h :E x E--.C
be a hermitian form. Write
h(x, y) = g(x, y) + if(x, y)
where g, f are real valued . Show that g, f are R-bilinear , 9 is symmetric, f is
alternating.
(b) Let E be finite dimen sional over C. Let g : E x E --. C be R-bilinear.
Assume
that for all x E E, the map y H g(x, y) is C-linear, and that the R-bilinear form
f( x, y) = g(x, y) - g(y , x )

596
STRUCTURE OF BILINEAR FORMS
XV, Ex
is real-valued on E x E. Show that there exists a hermitian form h on E and a
symmetric C-bilinear form Ij; on E such that 2ig = h + Ij;. Show that hand Ij; are
uniquely determined .
2. Prove the real case of the unitary spectral theorem : If E is a non-zero finite dimensional
space over R, with a positive definite symmetric form, and U :E -+ E is a unitary linear
map, then E has an orthogonal decomposition into subspaces of dimension I or 2,
invariant under U. If dim E = 2, then the matrix of U with respect to any ortho-
normal basis is of the form
(
COS6 -sin 6)
or
(-I
sin 0
cos 6
0
0)c6
- sin 0),
I
sm 6
cos 6
depending on whether det(U) = lor -I. Thus U is a rotation, or a rotation followed
by a reflection.
3. Let E be a finite-dimensional, non-zero vector space over the reals, with a positive
definite scalar product. Let T :E -+ E be a unitary automorphism of E. Show that E
is an orthogonal sum of subspaces
such that each E,is T-invariant, and has dimension I or 2. If E has dimension 2, show
that one can find a basis such that the matrix associated with T with respect to this
basis is
(
COS6 -sin 6)
or
(-cos6
sin 6
cos 6
sin 0
sin 6)
cos 6 '
according as det T = I or det T =
- I.
4. Let E be a finite dimensional non-zero vector space over C, with a positive definite
hermitian product. Let A, B : E ~ E be a hermitian endomorphism. Assume that
AB = BA. Prove that there exists a basis of E consisting of common eigenvectors
for A and B.
5. Let E be a finite-dimensional space over the complex, with a positive definite hermitian
form. Let S be a set of (C-linear) endomorphisms of E having no invariant subspace
except 0 and E. (This means that if F is a subspace of E and BF c F for all BE S. then
F = 0 or F = E.) Let A be a hermitian map of E into itself such that AB = BA for all
BE S. Show that A = ),J for some real number A..
[Hint :
Show that there exists
exactly one eigenvalue of A. Ifthere were two eigenvalues, say AI of- A2, one could find
two polynomials f and 9 with real coefficients such that f(A) of- 0, g(A) of- 0 but
f(A)g(A) = O. Let F be the kernel of g(A) and get a contradiction.]
6. Let E be as in Exercise 5.
Let T be a C-linear map of E into itself. Let
A =!(T + T*).
Show that A is hermitian. Show that T can be written in the form A + iB where A, B
are hermitian, and are uniquely determined.
7. Let S be a commutative set of C-linear endomorphisms of E having no invariant sub-
space unequal to 0 or E. Assume in addition that if BE S, then B* E S. Show that each

XV, Ex
EXERCISES
597
element of S is of type al for some complex number a. [Hint :
Let Bo E S. Let
A = t(Bo + B~).
Show that A = AI for some real 1]
8. An endomorphism B of E is said to be normal if Bcommutes with B*. State and prove a
spectral theorem for normal endomorphisms.
Symmetric endomorphisms
For Exercises 9, 10 and I I we let E be a non-zero finite dimensional vector space over
R, with a symmetric positive definite scalar product g, which gives rise to a norm lion E.
Let A : E ~ E be a symmetric endomorphism of E with respect to g. Define A ~ 0
to mean (Ax, x) ~ 0 for all x E E.
9. (a) Show that A ~ 0 if and only if all eigenvalues of A belonging to non-zero
eigenvectors are ~ O. Both in the hermitian case and the symmetric case, one
says that A is semipositive if A ~ 0, and positive definite if (Ax, x) > 0 for all
x » O.
(b) Show that an automorphism A of E can be written in a unique way as a product
A = UP where U is real unitary (that is, 'UU = /), and P is symmetric positive
definite . For two hermitian or symmetric endomorphisms A, B, define A ~ B to
mean A -
B ~ 0, and similarly for A > B . Suppose A > O. Show that there are
two real numbers a > 0 and f3 > 0 such that al ~ A ~ f3I .
10. If A is an endomorphism of E, define its norm IAI to be the greatest lower bound of
all numbers C such that IAxl ~ clxl for all x E E .
(a) Show that this norm satisfies the triangle inequality.
(b) Show that the series
A2
exp(A) = I + A + 2! + . . .
converges, and if A commutes with B, then exp(A + B) = exp(A) exp(B) .
If A is sufficiently close to I, show that the series
(A -
I)
(A -
1)2
log(A) = -1-
-
2
+ . ..
converges, and if A commutes with B, then
log(AB) = log A + log B.
(c) Using the spectral theorem , show how to define log P for arbitrary positive
definite endomorphisms P.
II. Again, let E be non-zero finite dimensional over R, and with a positive definite
symmetric form . Let A : E ~ E be a linear map. Prove:
(a) If A is symmetric (resp. alternating), then exp(A) is symmetric positive definite
(resp. real unitary).
(b) If A is a linear automorphism of E sufficiently close to I, and is symmetric

598
STRUCTURE OF BILINEAR FORMS
XV, Ex
positive definite (resp. real unitary), then log A is symmetric (resp .
alternating).
(c) More generally , if A is positive definite, then log A is symmetric.
12. Let R be a commutative ring, let E, F beR-modules, and letf :E -> F be a mapping.
Assume that multiplication by 2 in F is an invertible map. Show thatfis homogeneous
quadratic if and only iffsatisfies the parallelogram law:
f(x + y) + f(x - y) = 2f(x) + 2f(y)
for all x, y E E.
13. (Tate)
Let E, F be complete normed vector spaces over the real numbers. Let
f :E -> F be a map having the following property. There exists a number C > 0 such
that for all x, y E E we have
If(x + y) - f(x) - f(Y)1 s c.
Show that there exists a unique additive map 9 : E ~ F such that Ig - fl is bounded
(i.e.lg(x) - f(x) Iis bounded as a function of x). Generalize to the bilinear case. [Hint :
Let
f(2'x)
g(x) = lim --.]
' - 00
2'
14. (Tate)
Let S be a set and f: S ~ S a map of S into itself. Let h:S ~ R be a real
valued function. Assume that there exists a real number d > 1 such that h
0 f - df
is bounded. Show that there exists a unique function hf such that hf - h is bounded,
and hf 0 f = dhf . [Hint: Let hf(x) = lim h(r(x»/dn.)
15. Define maps of degree > 2, from one module into another. [Hint :
For degree 3,
consider the expression
f(x + Y + z) - f(x + y) - f(x + z) - fey + z) + f(x) + f(y) + f(z).]
Generalize the statement proved for quadratic maps to these higher-degree maps, i.e.
the uniqueness of the various multilinear maps enter ing into their definitions.
Alternating forms
16. Let E be a vector space over a field k and let 9 be a bilinear form on E. Assume that
whenever x, y E E are such that g(x, y) = 0, then g(y, x) = O. Show that 9 is symmetric
or alternating.
17. Let E be a module over Z. Assume that E is free, of dimension n ~ 1, and letfbe a
bilinear alternating form on E. Show that there exists a basis {eJ (i = 1, . . . , n) and
an integer r such that 2r ;;;; n,
where a l , ••• , ar E Z, aj # 0, and a, divides a., I for i = 1, ... , r -
1 and finally
e, . ej = 0 for all other pairs of indices i ;;;; j . Show that the ideals Za, are uniquely
determined. [Hint :
Consider the injective homomorphism cPf : E -> £Y of E into the

XV, Ex
EXERCISES
599
dual space over Z, viewing q>/E) as a free submodule of £V.]. Generalize to principal
rings when you know the basis theorem for modules over these rings.
Remark.
A basis as in Exercise 18 is called a symplectic basis. For one use of
such a basis, see the theory of theta functions, as in my Introduction to Algebraic and
Abelian Functions (Second Edition, Springer Verlag), Chapter VI, §3.
18. Let E be a finite-dimensional vector space over the reals, and let <, >be a symmetric
positive definite form. Let Q be a non-degenerate alternating form on E. Show that
there exists a direct sum decomposition
E = E1 EB Ez
having the following property. If x, y E E are written
Y = (Yt, Yz)
with
with
then D(x, y) = (XI' yz) - (xz, Yl)' [Hint: Use Corollary 8.3, show that A is positive
definite, and take its square root to transform the direct sum decomposition obtained
in that corollary.]
19. Show that the pfaffian of an alternating n x n matrix is 0 when n is odd.
20. Prove all the properties for the pfaffian stated in Artin's Geometric Algebra (Inter-
science, 1957), p. 142.
The Witt group
21. Show explicitly how W(k) is a homomorphic image of WG(k).
22. Show that WG(k) can be expressed as a homomorphic image of Z[k*/k*Z] [Hint:
Use the existence of orthogonal bases.]
23. Witt's theorem is still true for alternating forms. Prove it or look it up in Artin (ref.
in Exercise 20).
SL,,(R)
There is a whole area of linear algebraic groups, giving rise to an extensive algebraic
theory as well as the possibility of doing Fourier analysis on such groups. The group
SLn(R) (or SLn(C) can serve as a prototype, and a number of basic facts can be easily
verified. Some of them are listed below as exercises. Readers wanting to see solutions can
look them up in [JoL 01], Spherical Inversion on SLn(R), Chapter I.
24. Iwasawa decomposition. We start with GLn(R) . Let:
K = subgroup of real unitary n x n matrices;
U = group of real unipotent upper triangular matrices, that is having components I
on the diagonal, arbitrary above the diagonal, and 0 below the diagonal;

600
STRUCTURE OF BILINEAR FORMS
XV, Ex
A = group of diagonal matrices with positive diagonal components.
Prove that the product map U x A x K -+ UAK eGis actually a bijection. This
amounts to Gram-Schmidt orthogonalization. Prove the similar statement in the
complex case, that is, for G(C) = GL,,(C), K(C) = complex unitary group, U(C) =
complex unipotent upper triangular group, and A the same group of positive diag-
onal matrices as in the real case.
25. Let now G = SLn(R), and let K, A be the corresponding subgroups having deter-
minant I. Show that the product U x A x K -+ UAK again gives a bijection with G.
26. Let a be the R-vector space of real diagonal matrices with trace O. Let a v be the
dual space. Let (Xi (i = I,. . . ,n - I) be the functional defined on an element H =
diag(h l , . .. , hn) by (Xi(H) = hi - hi+l . (a) Show that {(XI,.. . , (Xn- tl is a basis of a v
over R. (b) Let Hi,i+l be the diagonal matrix with hi = I, hi+l = -I, and hj = 0
for j #-i, i + I. Show that {HI,2,... ,Hn-I,n} is a basis of a. (c) Abbreviate
Hi.i+l = Hi (i = I, .. . ,n - I). Let (Xf E a
V be the functional such that (Xf(Hj ) = bij
(= I
if i=j
and
0 otherwise).
Thus
{(XI, ... , (X~_d
is the
dual
basis
of
{HI, .. . ,Hn-tl. Show that
(Xf(H) = hI + ... +hi.
27. The trace form. Let Matn(R) be the vector space of real n x n matrices. Define the
twisted trace form on this space by
B,(X, Y) =tr(X' Y) = (X, Y)"
As usual,
I Y is the transpose of a matrix y. Show that B, is a symmetric positive
definite bilinear form on Matn(R). What is the analogous positive definite hermitian
form on Matn(C)?
28. Positivity. On a (real diagonal matrices with trace 0) the form of Exercise 27 can be
defined by tr(XY), since elements X , YEa are symmetric. Let d = {(XI, .. . , (Xn- I}
denote the basis of Exercise 26. Define an element H E a to be semipositive (writen
H ~ 0) if a.i(H) ~ 0 for all i = I, . . . ,n - I. For each (X E a
V
, let Ha E a represent (X
with respect to B" that is (Ha,H) = a.(H) for all HE a. Show that H ~ 0 if and
only if
n-I
H= LSiHa~
;=1
'
with Si ~ O.
Similarly, define H to be positive and formulate the similar condition with s, > O.
29. Show that the elements n(Xf (i = I, . . . ,n - I) can be expressed as linear combina-
tions of (Xl , . . . , (Xn-I with positive coefficients in Z.
30. Let W be the group of permutations of the diagonal elements in the vector space a of
diagonal matrices. Show that a ~o is a fundamental domain for the action of Won a
(i.e., given HE a, there exists a unique H+ ~ 0 such that H+= wH for some
WE W .

CHAPTER XVI
The Tensor Product
Having considered bilinear maps , we now come to multilinear maps and basic
theorems concerning their structure. There is a universal module representing
multilinear maps, called the tensor product. We derive its basic properties, and
postpone to Chapter XIX the special case of alternating products. The tensor
product derives its name from the use made in differential geometry, when this
product is applied to the tangent space or cotangent space of a manifold. The
tensor product can be viewed also as providing a mechanism for "extending the
base"; that is, passing from a module over a ring to a module over some algebra
over the ring . This "extension" can also involve reduction modulo an ideal,
because what matters is that we are given a ring homomorphism f : A ~ B, and
we pass from modules over A to modules over B. The homomorphismf can be
of both types , an inclusion or a canonical map with B = AIJ for some ideal J,
or a composition of the two.
I have tried to provide the basic material which is immediately used in a
variety of applications to many fields (topology, algebra, differential geometry,
algebraic geometry, etc.).
§1.
TENSOR PRODUCT
Let R be a commutative ring. If E1, • •• , En , F are modules, we denote by
the module of n-multilinear maps
f :E1 x '"
x En -+ F.
601
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

602
THE TENSOR PRODUCT
XVI, §1
We recall that a multilinear map is a map which is linear (i.e., R-linear) in each
variable. We use the words linear and homomorphism interchangeably. Unless
otherwisespecified,modules, homomorphisms, linear, multilinear refertotheringR.
One may viewthe multilinear maps ofa fixed set of modules Ej , .. . , En as the
objects of a category. Indeed, if
f :E1 X
• •. x En --+ F
and
g: E1 X
• . . x En --+ G
are multilinear, we define a morphism f
--+ g to be a homomorphism h :F --+ G
which makes the following diagram commutative:
F
»:
E. x ... x E.~ j.
G
A universal object in this category is called a tensor product of E1, • •• , En
(over R).
We shallnowprovethat a tensorproduct exists, and in fact construct one in a
natural way. By abstract nonsense, we know of course that a tensor product is
uniquely determined, up to a unique isomorphism.
Let M be the free module generated by the set of all n-tuples (Xl"' "
Xn),
(Xi E Ei ) , i.e. generated by the set EI x . .. x En . Let N be the submodule
generated by all the elements of the following type:
for all Xi E Ej , X; E Ej , a E R. We have the canonical injection
of our set into the free module generated by it. We compose this map with the
canonical map M --+ MIN on the factor module, to get a map
We contend that ip is multilinear and is a tensor product.
It is obvious that
qJ is multilinear-our definition was adjusted to this
purpose. Let
f: E1 x ... x En --+ G
be a multilinear map. By the definition of free module generated by

XVI, §1
TENSOR PRODUCT
603
we have an induced linear map M -+ G which makes the following diagram
commutative:
SinceJis multilinear, the induced map M -+ G takes on the value 0 on N. Hence
by the universal property of factor modules, it can be factored through MIN,
and we have a homomorphism f. :MIN -+ G which makes the following dia-
gram commutative:
Since the image of cp generates MIN, it follows that the induced map f. is
uniquely determined. This proves what we wanted.
The module MIN will be denoted by
n
E 1 ® ... ® En
or also
@ s;
i= 1
We have constructed a specific tensor product in the isomorphism class oftensor
products, and we shall call it thetensor product of El ' . . . , En . Ifx, E Ei, wewrite
cp(x 1, . . . , X n) = X l ® . .. ® x, = X l ® R •. • ® R Xn •
We have for all i,
Xl ® .. . ® aXj ® ... ® x, = a(x I ® .. . ® xn) ,
Xl ® .. . ® (Xi + X;)® ... ® x,
for Xi> x; E E, and a E R.
If we have two factors, say E ® F, then every element of E ® F can be
written as a sum ofterms X ® y with X E Eand y E F,because such terms generate
E ® F over R, and a(x ® y) = ax ® y for a E R.

604
THE TENSOR PRODUCT
XVI, §1
Remark.
If an element of the tensor product is 0, then that element can
already be expressed in terms of a finite number of the relations defining the
tensor product. Thus if E is a direct limit of submodules E, then
In particular, every module is a direct limit of finitely generated submodules,
and one uses frequently the technique of testing whether an element of F ® E is
oby testing whether the image of this element in F ® E, is 0 when E, ranges over
the finitely generated submodules of E.
Warning.
The tensor product can involve a great deal of collapsing between
the modules. For instance, take the tensor product over Z of Z/mZ and Z/nZ
where m, n are integers> I and are relatively prime. Then the tensor product
Z/nZ ® Z/mZ = O.
Indeed, we have n(x ® y) = (nx) ® y = 0 and m(x ® y) = x ® my = O. Hence
x ® y = 0 for all x E Z/nZ and y E Z/mZ. Elements of type x ® y generate the
tensor product, which is therefore O. We shall see later conditions under which
there is no collapsing.
In many subsequent results, we shall assert the existence of certain linear
maps from a tensor product. This existence is proved by using the universal
mapping property of bilinear maps factoring through the tensor product. The
uniqueness follows by prescribing the value of the linear maps on elements of
type x ® y (say for two factors) since such elements generate the tensor product.
We shall prove the associativity of the tensor product.
Proposition 1.1.
Let El' E2, E3 be modules. Then there exists a unique
isomorphism
suchthat
(x ® y) ® Z f--+ X ® (y ® z)
Proof
Since elements of type (x ® y) ® z generate the tensor product, the
uniqueness of the desired linear map is obvious. To prove its existence, let
x EEl ' The map

XVI, §1
TENSOR PRODUCT
605
such that Ax(y, z) = (x ® y) ® Z is clearly bilinear, and hence factors through a
linear map of the tensor product
The map
such that
(x, IX) H
XxClX)
for x E E I and IXE E2 ® E3 is then obviously bilinear, and factors through a
linear map
which has the desired property (clear from its construction).
Proposition 1.2.
Let E, F be modules. Then there is a unique isomorphism
such that x ® y H Y ® x for x E E andY E F.
Proof
The map E x F --+ F ® E such that (x, Y) H Y ® x is bilinear, and
factors through the tensor product E ® F, sending x ® Y on Y ® x. Since this
last map has an inverse (by symmetry) we obtain the desired isomorphism.
The tensor product has various functorial properties. First, suppose that
(i = 1, ... , n)
is a collection oflinear maps. We get an induced map on the product,
Ifwe compose TI Ii with the canonical map into the tensor product, then we get
an induced linear map which we may denote by T(fl' . .. , f,,) which makes the
following diagram commutative :
E'I
X
. . . x E~-----+ E'I ® ... ® E~
n"]
]N'"'
E I x . . . x En -----+ E I ® ... ® En

606
THE TENSOR PRODUCT
XVI, §1
It is immediately verified that T is functorial, namely that if we have a com-
posite of linear maps j;
0 9j (i = 1, . . . , n) then
and
T(id, . . . , id) = id.
We observe that T(fl" ' " j,,) is the unique linear map whose effect on an
element X'1 ® .. . ® x~ of E'1 ® ... ® E~ is
We may view T as a map
and the reader will have no difficulty in verifying that this map is multilinear.
We shall write out what this means explicitly for two factors, so that our map can
be written
(f, 9) 1-+ T(f,9)·
Given homomorphisms I :F' --+ F and 91' 92: E' --+ E, then
T(f,91 + 92) = T(f, 91) + T(f,92)'
T(/, a91) = aT(f, 91)'
In particular, select a fixed module F, and consider the functor T =
TF (from
modules to modules) such that
T(E) = F ® E.
Then T gives rise to a linear map
T: L(E', E) --+ L(T(E'), T(E))
for each pair of modules E', E, by the formula
T(f) = T(id, f).
Remark.
By abuse of notation, it is sometimes convenient to write
11 ® ... ® j"
instead of
T(fl" " ,j,,).

XVI, §2
BASIC PROPERTIES
607
This should not be confused with the tensor product of elements taken in the
tensor product of the modules
The context will always make our meaning clear.
§2.
BASIC PROPERTIES
The most basic relation relating linear maps, bilinear maps, and the tensor
product is the following : For three modules E, F, G,
L(E, L(F, G)) ~ L 2(E, F ; G) ~ L(E @ F, G).
The isomorphisms involved are described in a natural way.
(i) L 2(E, F ; G) -. L(E, L(F, G)).
IfI :E x F -. G is bilinear, and x E E, then the map
Ix :F -. G
such that Ix(Y) = [t», y) is linear. Furthermore, the map x H Ix is linear, and
is associated with I to get (i).
(ii) L(E, L(F, G)) -. e(E, F; G).
Let <p E L(E, L(F, G)). We let j~: E x F -. G be the bilinear map such that
I",(x, y) = <p(x) (y).
Then <p H I", defines (ii).
It is clear that the homomorphisms of (i) and (ii) are inverse to each other
and therefore give isomorphisms of the first two objects in the enclosed box.
(iii) L 2(E, F; G) -. L(E @ F, G).
This is the map I H I* which associates to each bilinear map I the induced
linear map on the tensor product. The association I H I* is injective (because
I* is uniquely determined by f), and it is surjective, because any linear map
of the tensor product composed with the canonical map E x F -. E @ F gives
rise to a bilinear map on E x F.

608
THE TENSOR PRODUCT
XVI, §2
n
Proposition 2.1.
Let E = EB E, be a direct sum. Then we havean isomor-
i = !
phism
n
F @ E +-+EB (F @ EJ
j = I
Proof
The isomorphism is given by abstract nonsense. We keep F fixed,
and consider the functor T : X H F @ X. As we saw above, T is linear. We have
projections n, : E -+ E of E on Ej • Then
if
i =I j,
nLnj = id.
j= !
We apply the functor T, and see that T(nJ satisfies the same relations, hence gives
a direct sum decomposition of T(E) = F @ E. Note that T(nJ = id @ n i'
Corollary 2.2.
Let I be an indexing set, and E = EB Ej • Then we have an
i e l
isomorphism
Proof
Let S be a finite subset of I. We have a sequence of maps
the first of which is bilinear, and the second is linear, induced by the inclusion of
S in I. The first isthe obvious map. IfS c Sf, then a trivial commutative diagram
shows that the restriction of the map
induces our preceding map on the sum for i E S. But we have an injection
Hence by compatibility, we can define a bilinear map

XVI, §2
and consequently a linear map
BASIC PROPERTIES
609
In a similar way, one defines a map in the opposite direction, and it is clear
that these maps are inverse to each other, hence give an isomorphism.
Suppose now that E is free, of dimension l over R. Let {v} be a basis, and
consider F ® E. Every element of F ® Ecan be written as a sum of terms Y ® av
with Y E Fand a E R. However, y ® av = ay ® v. In a sum ofsuch terms, we can
then use linearity on the left,
Yi EF.
Hence every element is in fact of type Y ® v with some Y E F.
We have a bilinear map
F x E-+F
such that (Y, av) f--+ ay, inducing a linear map
We also have a linear map F -+ F ® E given by y f--+ Y ® v. It is clear that these
maps are inverse to each other, and hence that we have an isomorphism
F ®E;:::: F.
Thus every element of F ® E can be written uniquely in the form y ® v, Y E F.
Proposition 2.3.
Let E befree over R, with basis {Vi}i e I , Then every element
of F ® E has a unique expression of theform
YiEF
with almost all Yi = O.
Proof.
This follows at once from the discussion of the l-dimensional case,
and the corollary of Proposition 2.1 .
Coronary 2.4.
Let E, F be free over R, with bases {viLel and {wj}jeJ re-
spectively. Then E ® F isfree, with basis {Vi ® wj } . We have
dim(E ® F) = (dim E) (dim F).

610
THE TENSOR PRODUCT
XVI, §2
Proof
Immediate from the proposition.
We see that when E is free over R, then there is no collapsing in the tensor
product. Every element of F @ E can be viewed as a " formal" linear combina-
tion of elements in a basis of E with coefficients in F.
In particular, we see that R @ E (or E @ R) is isomorphic to E, under the
correspondence x H x @ 1.
Proposition 2.5.
Let E, F befree offinite dimensionover R. Then wehavean
isomorphism
which is the uniquelinearmap such that
f @gH T(f, g)
for f E EndR(E) and g E EndR(F).
[We note that the tensor product on the left is here taken in the tensor
product of the two modules EndR(E) and EndR(F).]
Proof
Let {vJ be a basis of E and let {wJ be a basis of F. Then {Vi @ W j}
is a basis of E @ F. For each pair of indices (i', j') there exists a unique endo-
morphism f
= Ai' of E and g = gj,j' of F such that
f(vJ = Vi'
and
f(vv) = 0
if v =1= i
g(w) = wj'
and
g(wl/) = 0
if J1 =1= j .
Furthermore, the families {};,i'} and {gj,j'} are bases of EndR(E) and EndR(F)
respectively. Then
Thus the family {T(};,i" gj,j')} is a basis of EndR(E @ F). Since the family
{Ii. i' @ gj,j'} is a basis ofEndR(E) @ EndR(F),the assertion of our proposition is
now clear.
In Proposition 2.5, we see that the ambiguity of the tensor sign inf @ g is in
fact unambiguous in the important special case of free, finite dimensional
modules. We shall see later an important application of Proposition 2.5 when
we discuss the tensor algebra of a module.
Proposition 2.6.
Let
o-+ E' ~ E s. E" -+ 0

XVI, §2
BASIC PROPERTIES
611
be an exact sequence, and F any module. Then the sequence
F @ E' -+ F @ E -+ F @ E" -+°
is exact.
Proof
Given x" E E" and y E F, there exists x E E such that x" = r/J(x), and
hence y @ x" is the image of y @ x under the linear map
F@E-+F@E".
Since elements of type y @ x" generate F @ E", we conclude that the preceding
linear map is surjective. One also verifies trivially that the image of
F@E'-+F@E
is contained in the kernel of
F@E-+F@E".
Conversely, let 1 be the image of F @ E' -+ F @ E, and let
f: (F @ E)/I -+ F @ E"
be the canonical map. We shall define a linear map
9 : F @ E" -+ (F @ E)/I
such that 9 0 f = id. This obviously will imply that f is injective, and hence
will prove the desired converse.
Let y E F and x" E E". Let x E E be such that r/J(x) = x". We define a map
F x E" -+ (F @ E)/I by letting
(y, x") f-+ Y @ x
(mod I),
and contend that this map is well defined, i.e. independent of the choice of x
such that r/J(x) = x". If r/J(Xl) = r/J(X2) = x", then
r/J(x l -
X2) = 0, and by
hypothesis, Xl -
X2 = qJ(x') for some x' E E'. Then
This shows that y @ Xl == Y @ X2 (mod I), and proves that our map is well
defined. It is obviously bilinear, and hence factors through a linear map g, on
the tensor product. It is clear that the restriction of g of on elements of type
y @ x is the identity. Since these elements generate F @ E, we conclude that f
is injective, as was to be shown.

612
THE TENSOR PRODUCT
It is not always true that the sequence
o--+ F (8) E' --+ F (8) E --+ F (8) E" --+ 0
XVI, §3
is exact. It is exact if the first sequence in Proposition 2.6 splits, i.e. if E is
essentially the direct sum of E' and E", This is a trivial consequence of Pro-
position 2.1,and the reader should carry out the details to get accustomed to the
formalism of the tensor product.
Proposition 2.7.
Let a be an idealof R. Let E be a module. Then the map
(Ria) x E --+ ElaE induced by
(a, x) H ax
(mod aE),
is bilinearand induces an isomorphism
aER, xEE
(Ria) (8) E .:. ElaE.
Proof.
Our map (a, x) H ax (mod aE) clearly induces a bilinear map of
Ria x E onto ElaE, and hence a linear map of Ria (8) E onto ElaE. We can
construct an inverse, for we have a well-defined linear map
E --+ Ria (8) E
such that x H I (8) x (where I is the residue class of 1 in Ria). It is clear that aE
is contained in the kernel of this last linear map, and thus that we obtain a
homomorphism
ElaE --+ Ria (8) E,
which is immediately verified to be inverse to the homomorphism described in
the statement of the proposition.
The association E H ElaE ~ Ria (8) E is often called a reduction map. In
§4,we shall interpret this reduction map as an extension of the base.
§3.
FLAT MODULES
The question under which conditions the left-hand arrow in Proposition 2.6
is an injection gives rise to the theory of those modules for which it is, and we
follow Serre in calling them flat. Thus formally, the following conditions are
equivalent, and define a flat module F, which should be called tensor exact.
F 1.
For every exact sequence
E' --+ E --+ E"

XVI, §3
the sequence
is exact.
FLAT MODULES
613
F 2.
For every short exact sequence
o-> E' -> E -> E" -> 0
the sequence
o-> F @ E' -> F @ E -> F @ E" -> 0
is exact.
F 3. For every injection 0 ~ E' ~ E the sequence
o-> F @ E' -> F @ E
is exact.
It is immediate that F 1 implies F 2 implies F 3. Finally, we see that F 3 implies
F 1 by writing down the kernel and image of the map E' -> E and applying F 3.
We leave the details to the reader.
The following proposition gives tests for flatness, and also examples.
Proposition 3.1.
(i) The groundring isfiat as moduleover itself.
(ii) Let F = EB F, be a direct sum. Then F isflat ifandonly ifeachF, isfiat.
(iii) A projective moduleisfiat.
The properties expressed in this proposition are basically categorical, cr. the
comments on abstract nonsense at the end of the section. In another vein, we
have the following tests having to do with localization.
Proposition 3.2.
(i) Let 5 be a multiplicative subset ofR. Then 5- 1R isfiat over R.
(ii) A module M isfiat over R ifandonly ifthe localization M p isfiat overR;
for each primeideal p of R.
(iii) Let R be a principal ring. A moduleF isjlat ifandonly ifF is torsionfree.
The proofs are simple, and will be left to the reader. More difficult tests for
flatness will be proved below , however.
Examples of non-flatness.
If R is an entire ring, and a module Mover R
has torsion, then M is not flat. (Prove this, which is immediate.)

614
THETENSORPRODUCT
XVI, §3
There is another type of example which illustrates another bad phenomenon.
Let R be some ring in a finite extension K of Q, and such that R is a finite
module over Z but not integrally closed. Let R ' be its integral closure. Let p be
a maximal ideal of R and suppose that pR' is contained in two distinct maximal
ideals ~ I and ~2 ' Then it can be shown that R' is not flat over R, otherwise R'
would be free over the local ring Rp , and the rank would have to be I , thus
precluding the possibility of the two primes ~I and ~2' It is good practice for
the reader actually to construct a numerical example of this situation. The same
type of example can be constructed with a ring R = k[x,y], where k is an
algebraically closed field, even of characteristic 0, and x, yare related by an
irreducible polynomial equation f(x,y) = 0 over k. We take R not integrally
closed, such that its integral closure exhibits the same splitting of a prime p of
R into two primes. In each one of these similar cases, one says that there is a
singularity at p.
As a third example, let R be the power series ring in more than one variable
over a field k. Let m be the maximal ideal. Then m is not flat, because otherwise,
by Theorem 3.8 below , m would be free, and if R = k[[xl' . .. ' xn]], then XI'
. . . , xn would be a basis for mover R, which is obviously not the case, since
XI' X2 are linearly dependent over R when n ~ 2. The same argument, of course,
applies to any local ring R such that m/m 2 has dimension ~ 2 over Rim .
Next we come to further criteria when a module is flat. For the proofs, we
shall snake it all over the place. Cf. the remark at the end of the section.
Lemma3.3.
Let F be fiat, and suppose that
is an exact sequence. Thenfor any E, we have an exact sequence
o--+ N @ E -+ M @ E --+ F @ E -+ O.
Proof
Represent E as a quotient of a flat L by an exact sequence
o--+ K -+ L -+ E --+ O.

XVI, §3
FLAT MODULES
615
Then we have the following exact and commutative diagram:
The top right 0 comes by hypothesis that F is flat. The 0 on the left comes from
the fact that L is flat. The snake lemma yields the exact sequence
which proves the lemma.
Proposition 3.4.
Let
o-+ F' -+ F -+ F" -+ 0
be an exact sequence, and assume that F" isfiat.
Then F isflat ifand only ifF'
is flat . More generally, let
be an exact sequence such that F I, . . . , F" are flat . Then FO is flat .

616
THE TENSOR PRODUCT
XVI, §3
Proof.
Let 0 -> E' -> E be an injection. We have an exact and commuta-
tive diagram :
o
!
0----+ F' ® E' ----+ F ® E' ----+ F" ® E' ----+ 0
!
!
!
o----+ F' ® E ----+ F ® E ----+ F" ® E
The 0 on top is by hypothesis that F" is flat, and the two zeros on the left are
justified by Lemma 3.3. IfF' is flat, then the first vertical map is an injection, and
the snake lemma shows that F is flat. If F is flat, then the middle column is an
injection. Then the two zeros on the left and the commutativity of the left square
show that the map F' ® E' -> F' ® E is an injection, so F' is flat. This proves the
first statement.
The proof of the second statement is done by induction, introducing kernels
and cokernels at each step as in dimension shifting, and apply the first statement
at each step. This proves the proposition
To give flexibility in testing for flatness, the next two lemmas are useful, in
relating the notion of flatness to a specific module. Namely, we say that F is
E-flat or flat for E, if for every monomorphism
0-> E' -> E
the tensored sequence
o-> F ® E' -> F ® E
is also exact.
Lemma 3.5.
Assume that F is E-fiat. Then F is alsofiat for every submodule
and every quotient moduleof E.
Proof
The submodule part is immediate because if E'1 c
E~ c E are
submodules, and F ® E'1 -> F ® E is a monomorphism so is F ® E'1 -> F ® E~
since the composite map with F ® E~ -> F ® E is a monomorphism. The only
question lies with a factor module. Suppose we have an exact sequence
o-> N -> E -> M -> O.
Let M' be a submodule of M and E' its inverse image in E. Then we have a

XVI, §3
commutative diagram of exact sequences:
FLAT MODULES
617
0---+ N ---+ E' ---+ M' ---+ 0
II
I I
0---+ N ---+ E ---+ M ---+ O.
We tensor with F to get the exact and commutative diagram
o
K
I
I
F® N---+F ® E'---+F® M'---+O
I
I
I
O---+F®N---+F®E~F®M
Io
where K is the questionable kernel which we want to prove is O. But the snake
lemma yields the exact sequence
which concludes the proof.
Lemma 3.6.
Let {EJ beafamilyofmodules,and suppose that F isflatfor each
Ej • Then F isftatfor their direct sum.
Proof
Let E = EB E, be their direct sum. We have to prove that given any
submodule E' of E, the sequence
o-> F ® E' -> F ® E = EB F ® e,
is exact. Note that if an element of F ® E' becomes 0 when mapped into the
direct sum, then it becomes 0 already in a finite subsum, so without loss of
generality we may assume that the set of indices is finite. Then by induction,
we can assume that the set of indices consists of two elements, so we have two
modules E, and E2, and E = E, EB E2• Let N be a submodule of E. Let N,
= NnE, and let N2 be the image of N under the projection on E2• Then

618
THE TENSOR PRODUCT
we have the following commutative and exact diagram:
0---+ E1 ~ E -----+ E2
Tensoring with F we get the exact and commutative diagram :
o
0
j
j
FiN'~FiN~FiN'~O
o-----+F ® E1 -----+ F ® E ~F ® E2
XVI, §3
The lower left exactness is due to the fact that E = E( EE> E2• Then the snake
lemma shows that the kernel of the middle vertical map is O. This proves the
lemma.
The next proposition shows that to test for flatness, it suffices to do so only
for a special class of exact sequences arising from ideals.
Proposition 3.7.
F isfiat ifand only iffor every ideala ofR the naturalmap
a ® F --+ aF
is an isomorphism. Infact, F isfiat ifand onlyfor every ideala ofR tensoring
the sequence
o--+ a --+ R --+ Ria --+ 0
with F yields an exact sequence.
Proof
If F is flat, then tensoring with F and using Proposition 2.7 shows
that the natural map isan isomorphism, because aM is the kernel of M --+ MlaM.
Conversely, assume that this map is an isomorphism for all ideals a. This means

XVI, §3
FLATMODULES
619
that F is R-flat. By Lemma 3.6 it follows that F is flat for an arbitrary direct sum
of R with itself, and since any module M is a quotient of such a direct sum,
Lemma 3.5 implies that F is M-flat, thus concluding the proof.
Remark on abstract nonsense.
1 he proofs of Proposition 3.I(i), (ii), (iii),
and Propositions 3.3 through 3.7 are basically rooted in abstract nonsense,
and depend only on arrow theoretic arguments. Specifically, as in Chapter XX,
§8, suppose that we have a bifunctor T on two distinct abelian categories ct and
(B such that for each A, the functor B ~ T(A, B) is right exact and for each B
the functor A ~ T(A, B) is right exact. Instead of " flat" we call an object A
of ct T-exact if B f-+ T(A,B) is an exact functor; and we call an object L of (B
'T-exact if A f-+ T(A,L) is exact. Then the references to the base ring and free
modules can be replaced by abstract nonsense conditions as follows.
In the use of L in Lemma 3.3, we need to assume that for every object E of(B
there is a IT-exact L and an epimorphism
L -+ E -+ O.
For the analog of Proposition 3.7, we need to assume that there is some
object R in (B for which F is R-exact, that is given an exact sequence
O-+a-+R
then 0 -+ T(F, a) -+ T(F, R) is exact ; and we also need to assume that R is a
generator in the sense that every object B is the quotient of a direct sum of R with
itself, taken over some family of indices, and T respects direct sums.
The snake lemma is valid in arbitrary abelian categories, either because its
proof is "functorial," or by using a representation functor to reduce it to the
category of abelian groups. Take your pick.
In particular, we really don't need to have a commutative ring as base ring,
this was done only for simplicity of language.
We now pass to somewhat different considerations.
Theorem 3.8.
Let R be a commutative local ring, and let M be a finite flat
moduleover R. Then M isfree. Infact, ifxt> .. . , x, EM are elementsofM
whose residue classes are a basis of MlmM over Rim , then XI' . . . , Xn form
a basis of Mover R.
Proof
Let R(n )-+ M be the map which sends the unit vectors of R(n ) on
XI' ... , X n respectively, and let N be its kernel. We get an exact sequence
o-+ N -+ R(n )-+ M,

620
THE TENSOR PRODUCT
whence a commutative diagram
m@ N --+m@ R(n)--+ m@M
I[
.[
,[
o
IN
I R(n)
1M
XVI, §3
in which the rows are exact. Since M is assumed flat, the map h is an injection.
By the snake lemma one gets an exact sequence
o--+ coker f --+ coker g --+ coker h,
and the arrow on the right is merely
R(n)/mR(n) --+ M/mM,
which is an isomorphism by the assumption on Xl "
' "
Xn • It follows that
cokerf
= 0, whence mN = N, whence N = 0 by Nakayama ifR is Noetherian,
so N is finitely generated. If R is not assumed Noetherian, then one has to add
a slight argument as follows in case M is finitely presented.
Lemma 3.9.
Assume that M isfinitely presented, and let
be exact, with Efinitefree. Then N is finitely generated.
Proof
Let
L I --+ L 2 --+ M --+ 0
be a finite presentation of M, that is an exact sequence with L 1, L 2 finite free.
Using the freeness, there exists a commutative diagram
l~l'~l·~O
O-N --+E--+M--+O
such that L2 --+ E is surjective. Then the snake lemma gives at once the exact
sequence
0--+ cokertj., --+ N) --+ 0,
so cokenz., --+ N) = 0, whence N is an image of L I and is therefore finitely
generated, thereby proving the lemma,and also completing the proofofTheorem
3.8 when M is finitely presented.

XVI, §3
FLAT MODULES
621
We still have not proved Theorem 3.8 in the fully general case. For this we
use Matsumura's proof (see his Commutative Algebra, Chapter 2), based on the
following lemma.
Lemma 3.10.
Assume that M is fiat over R. Let a, E A, Xi E M for i = I,
... , n, and suppose that we have the relation
n
La jX i = O.
i= I
Then there exists an integer s and elements bij E A and Yj EM (j = I, ... , s)
such that
L aibij = 0
for allj
and
Xi = L bij)'j
for all i.
j
Proof
We consider the exact sequence
o--+ K --+ R(n) --+ R
where the map R(n) --+ R is given by
and K is its kernel. Since M is flat it follows that
K ® M --+ M(n) !.!: M
is exact, where fMis given by
n
J:..,(ZI, · ··, Zn) =
L aizi.
i = I
Therefore there exist elements {Jj E K and Yj EM such that
s
(XI' · · · ' x n) = L{Jj Yi-
j= I
Write {Jj = (blj, .. . , bn) with bij E R. This proves the lemma.
We may now apply the lemma to prove the theorem in exactly the same way
we proved that a finite projective module over a local ring is free in Chapter X,
Theorem 4.4, by induction. This concludes the proof.
Remark.
Inthe applications I know of, the base ring is Noetherian, and so
one gets awa y with the very simple proofgiven at first. I did not want to obstruct
the simplicity of this pro of, and that is the reason I gave the additional tech-
nicalities in increasing order of generality.

622
THE TENSOR PRODUCT
XVI, §3
Applications of homology.
We end this section by pointing out a connection
between the tensor product and the homological considerations of Chapter XX,
§8 for those readers who want to pursue this trend of thoughts . The tensor product
is a bifunctor to which we can apply the considerations of Chapter XX, §8. Let
M , N be modules . Let
. .. -> Ej -> Ej _ 1 -> Eo -> M -> 0
be a free or projective resolution of M, i.e. an exact sequence where E, is free or
projective for all i ~ O. We write this sequence as
EM -> M -> O.
Then by definition,
Torj(M, N) = i-th homology of the complex E @ N, that is of
. . . -> E, @ N -> Ej _ 1 @ N -> ... -> Eo @ N -> O.
This homology is determined up to a unique isomorphism. I leave to the reader
to pick whatever convention is agreeable to fix one resolution to determine a
fixed representation of Torj(M, N), to which all others are isomorphic by a
unique isomorphism.
Since we have a bifunctorial isomorphism M @ N :::::; N @ M, we also get a
bifunctorial isomorphism
Torj(M, N) :::::; Torj(N, M)
for all i. See Propositions 8.2 and 8.2' of Chapter XX.
Following general principles, we say that M has Tor-dimension ;§ d if
Torj(M, N) = 0 for all i > d and all N . From Chapter XX, §8 we get the follow-
ing result, which merely replace s T-exact by flat.
Theorem 3.11.
The following three conditions are equivalent concerning a
module M.
(i) M is fiat.
(ii) Torl(M, N) = 0 for all N.
(iii) Tor;(M, N) = 0 for all i ~ I and all N, in other words, M has Tor-
dimension O.
Remark.
Readers willing to use this characterization can replace some of
the preceding proofs from 3.3 to 3.6 by a Tor-dimension argument, which is
more formal, or at least formal in a different way, and may seem more rapid.
The snake lemma was used ad hoc in each case to prove the desired result. The
general homology theory simply replaces this use by the corresponding formal
homological step, once the general theory of the derived functor has been carried
out.

XVI, §4
§4.
EXTENSION OF THE
BASE
EXTENSION OF THE BASE
623
Let R be a commutative ring and let E be a R-module. We specify R since
we are going to work with several rings in a moment. Let R -+ R' be a homo-
morphism ofcommutative rings, so that R' isan R-algebra, and may be viewed as
an R-module also. We have a 3-multilinear map
R' x R' x E -+ R' ® E
defined by the rule
(a, b, x) H ab ® x.
This induces therefore a R-linear map
R' ® (R' ® E) -+ R' ® E
and hence a R-bilinear map R' x (R' ® E) -+ R' ® E. It is immediately verified
that our last map makes R' ® E into a R'-module, which we shall call the
extension of Eover R', and denote by ER"
We also say that ER' is obtained by
extension of the base ring from R to R',
Example 1.
Let a be an ideal of R and let R -+ Ria be the canonical homo-
morphism. Then the extension of E to Ria is also called the reduction of E
modulo a. This happens often over the integers, when we reduce modulo a prime
p (i.e. modulo the prime ideal (P)).
Example 2.
Let R be a field and R' an extension field. Then E is a vector
space over R, and ER' is a vector space over R'. In terms of a basis, we see that
our extension gives what was alluded to in the preceding chapter. This example
will be expanded in the exercises.
We draw the same diagrams as in field theory:
ER'
E /
~R'
~R /
to visualize an extension of the base. From Proposition 2.3, we conclude:
Proposition 4.1. Let E be a free module over R, with basis {VJ iEI ' Let
v; = 1 ® Vi' Then ER' is afree module over R', with basis {V;}iEI '
We had already used a special case of this proposition when we observed that
the dimension of a free module is defined, i.e. that two bases have the same

624
THE TENSOR PRODUCT
XVI, §4
cardinality. Indeed, in that case, we reduced modulo a maximal ideal of R to
reduce the question to a vector space over a field.
When we start changing rings, it is desirable to indicate R in the notation
for the tensor product. Thus we write
Then we have transitivity ofthe extension ofthe base, namely, if R -. R' -+ R" is a
succession of homomorphisms of commutative rings , then we have an iso-
morphism
and this isomorphism is one of R"-modules. The proof is tr ivial and will be left
to the reader.
If E has a multiplicative structure, we can extend the base also for this
multiplication. Let R -+ A be a ring-homomorphism such that every element in
the image of R in A commutes with every element in A (Le. an R-algebra). Let
R -+ R' be a homomorphism of commutative rings. We have a 4-multilinear
map
R' x A
X R' x A -. R' @ A
defined by
(a, x, b, y) f-+ ab @ xy.
We get an induced R-linear map
R' @ A @ R' @ A -. R' @ A
and hence an induced R-bilinear map
(R' @ A) x (R' @ A) -+ R' @ A.
It is trivially verified that the law of composition on R' @ A we have just
defined is associative. There is a unit element in R' @ A, namely, 1 @ 1. We
have a ring-homomorphism of R' into R' @ A, given by a f-+ a @ I. In this way
one sees at once that R' @ A = AR , is an R'-algebra. We note that the map
xf-+l@x
is a ring-homomorphism of A into R' @ A, and that we get a commutative
diagram of ring homomorphisms,

XVI, §5
SOME FUNCTORIAL ISOMORPHISMS
625
For the record, we give some routine tests for flatness in the context of base
extension.
Proposition 4.2.
Let R -+ A be an R-algebra, and assume A commutative.
(i) Base change. IfF is a flat R-module, then A ®RF is aflat A-module.
(ii) Transitivity. IfA isaflat commutative R-algebra and M is aflat A-module,
then M is fiat as R-module.
The proofs are immediate, and will be left to the reader.
§5.
SOME FUNCTORIAL ISOMORPHISMS
We recall an abstract definition. Let m, '.8 be two categories. The functors
of minto '.8 (say covariant, and in one variable) can be viewed as the
objects of a category, whose morphisms are defined as follows. If L, M are two
such functors, a morphism H : L -+ M is a rule which to each object X of m
associates a morphism Hx: L(X ) -+ M(X) in '.8, such that for any morphism
f: X -+ Y in m, the following diagram is commutative:
L (X)~M(X )
"Ilj
jM(1l
L ( Y)~M( Y)
We can therefore speak of isomorphisms of functors. We shall see examples of
these in the theory of tensor products below. In our applications, our categories
are additive, that is, the set ofmorphisms is an additive group, and the composi-
tion law is Z-bilinear. In that case, a functor L is called additive if
L(f + g) = L(f) + L(g).
We let R be a commutative ring, and we shall consider additive functors from
the category of R-modules into itself. For instance we may view the dual
module as a functor,
E ~ EV = L (E , R) = HomR(E , R).
Similarly, we have a functor in two variables,
(E, F) H
L(E, F) = HomR(E, F),
contravariant in the first, covariant in the second, and bi-additive.

626
THE TENSOR PRODUCT
XVI, §5
We shall give several examples of functorial isomorphisms connected with
the tensor product, and for this it is most convenient to state a general theorem,
giving us a criterion when a morphism of functors is in fact an isomorphism.
Proposition 5.1.
Let L, M be two functors (both covariant or both contra-
variant) Jrom the category ojR-modules into itself. Assume that both functors
are additive. Let H : L ..... M be a morphism oj'functors. IJ HE :L(E) ..... M(E)
is an isomorphismJor every I-dimensionalJree module E over R, then HE is an
isomorphismJor every finite-dimensional free module over R.
Proof
We begin with a lemma.
Lemma 5.2.
Let E and E; (i = I, . .. , m) be modules over a ring.
Let
C{Ji: E; ..... E and l/J;:E ..... E, be homomorphisms having theJollowing properties:
t/J; 0 C{Jj = 0
if
i
=1= j
mL C{J; 0 t/J; = id,
; =1
Then the map
m
is an isomorphism oj E onto the direct product TI Ei , and the map
i ;::: l
is an isomorphism oJthe product onto E. Conversely, if E is equal to the direct
sum oj submodules E, (i = 1, . .. , m), if we let t/J; be the inclusion oj E; in E,
and C{J; the projection oj Eon Ei , then these maps satisJy the above-mentioned
properties .
Proof.
The proof is routine , and is essentially the same as that of Proposition
3.1 of Chapter III. We shall leave it as an exercise to the reader.
We observe that the families {C{J;} and {t/J;} satisfying the properties of the
lemma behave functorially : If T is an additive contravariant functor, say, then
the families {T(t/J;)}and {T( C{J;)} also satisfy the properties of the lemma. Similarly
if T is a covariant functor.
To apply the lemma, we take the modules E, to be the I-dimensional
components occurring in a decomposition of E in terms of a basis. Let us assume
for instance that L, M are both covariant. We have for each module E a com-

XVI, §5
mutative diagram
SOME FUNCTORIAL ISOMORPHISMS
627
L(E) ~ M(E)
L(ql'l]
]Mlql;)
L(EJ~M(EJ
and a similar diagram replacing tp, by IjJ j, reversing the two vertical arrows.
Hence we get a direct sum decomposition of L(E) in terms of L(ljJi) and L(cpj),
and similarly for M(E) , in terms of M(ljJ j)and M(cpJ By hypothesis, HE, is an
isomorphism. It then follows trivially that HEis an isomorphism. For instance,
to pro ve injectivity, we write an element v E L(E) in the form
with Vi E L(EJ If HEv = 0, then
0= L HEL(cpJVi = L M(cpJHEiV;,
and since the maps M(CPi) (i = 1, . . . , m) give a direct sum decomposition of
M(E), we conclude that HE,Vi = 0 for all i, whence Vj = 0, and V = O. The
surjectivity is equally trivial.
When dealing with a functor of several variables, additive in each variable,
one can keep all but one of the variables fixed, and then apply the proposition.
We shall do this in the following corollaries.
Corollary 5.3.
Let E', E, F', F befree andfinite dimensional over R. Then we
have afunctorial isomorphism
L(E', E) ® L(F', F) -> L(E' ® F', E ® F)
such that
f ® g H T(f, g).
Proof
Keep E, F', F fixed, and view L(E', E) ® L(F', F) as a functor in the
variable E'. Similarly, view
L(E' ® F', E ® F)
as a functor in E'. The mapf ® g H T(f, g) is functorial, and thus by the lemma,
it suffices to prove that it yields an isomorphism when E' has dimension 1.
Assume now that this is the case; fix E' of dimension 1, and view the two
expressions in the corollary as functors of the variable E. Applying the lemma

628
THE TENSOR PRODUCT
XVI, §5
again, it suffices to pro ve that our arrow is an isomorphism when E has di-
mension 1. Similarly, we may assume that F, F' ha ve dimension l.
In that
case the verification that the arrow is an isomorphism is a triviality, as desired.
Corollary 5.4.
Let E, F be fre e and finite dimensional.
Then we have a
natural isomorphism
Proof
Special case of Corollary 5.3.
Note that Corollary 5.4 had already been proved before, and that we
mention it here only to see how it fits with the present point of view.
Corollary 5.5.
Let E, F be free finite dimensional over R. There is a func-
torial isomorphism
E V ® F ~ L(E, F)
given for A. E E v and y E F by the map
A. ® y I---' A;.,y
where A ).,y is such that for all x E E, we have A .<,y(x ) = ;.(x)y.
The inverse isomorphism of Corollary 5.5 can be described as follows.
Let {VI ,... ,vn } be a basis of E, and let {v; , ... , v~ } be the dual basis. If
A E L(E,F), then the element
n
~ V;®A (Vi)EEV®F
i= 1
maps to A. In particular, if E = F, then the element mapping to the identity idE
is called the Casimir element
n
~ v; ® Vi,
i= 1
independent of the choice of basis. Cf. Exercise 14.
To prove Corollary 5.5, justify that there is a well-defined homomorphism
of E
V ® F to L(E,F), by the formula written down. Verify that this homo-
morphism is both injective and surjective. We leave the details as exercises.
Differential geometers are very fond of the isomorphism
L(E, E) ~ E V ® E,
and often use E V ® E when they think geometrically of L(E , E), thereby em-
phasizing an unnecessary dualization, and an irrelevant formalism , when it is
easier to deal directly with L(E, E).
In differential geometry, one applies
various functors L to the tangent space at a point on a manifold, and elements
of the spaces thus obtained are called tensors (of type L).

XVI, §6
TENSOR PRODUCT OF ALGEBRAS
629
Corollary 5.6.
Let E, F befree and finite dimensional over R. There is a
functorial isomorphism
EV®FV -+ (E®F)v .
given for ), E E V and fJ- E F V by the map
A@fJ- t-+ A,
where A is such that.for all x E E and y E F,
A(x @ y) = A(X)fJ-(Y)
Proof.
As before.
Finally, we leave the following results as an exercise.
Proposition 5.7.
Let E be free and finite dimensional over R. The trace
function on L(E,E) is equalto the composite ofthe two maps
L(E, E) -+ EV ® E -+ R,
where thefirst mapis the inverse of the isomorphism described inCorollary 5.5,
andthe second map is induced by the bilinear map
(A,X) t-+ A(X).
Of course, it is precisely in a situation involving the trace that the iso-
morphism of Corollary 5.5 becomes important, and that the finite dimen-
sionality of E is used. In many applications, this finite dimensionality plays
no role, and it is better to deal with L(E, E) directly.
§6.
TENSOR PRODUCT OF ALGEBRAS
In this section, we again let R be a commutative ring. By an R-algebra we
mean a ring homomorphism R -+ A into a ring A such that the image of R is
contained in the center of A.
Let A, B be R-algebras. We shall make A ® B into an R-algebra. Given
(a, b) E A x B, we have an R-bilinear map
Ma,b: A X B -+ A ® B such that Ma,b(a', b') = aa' ® bb'.
Hence Ma,b induces an R-linear map ma,b: A ® B -+ A ® B such that
ma,b(a', b') = aa' ® bb'. But ma,b depends bilinearly on a and b, so we obtain
finally a unique R-bilinear map
A®BXA®B-+A®B

630
THE TENSOR PRODUCT
XVI, §6
such that (a (9 b)(a' (9 b' ) = aa' (9 bb'. This map is obviously associative, and
we have a natural ring homomorphism
R ~ A (9 B
given by
c ~ 1 (9 c = c (9 I.
Thus A (9 B is an R-algebra, called the ordinary tensor product.
Application: commutative rings
We shall now see the implication of the above for commutative rings.
Proposition 6.1.
Finite coproducts exist in the category of commutative
rings, and in the category of commutative algebras over a commutative ring .
If R ~ A and R ~ B are two homomorphisms of commutative rings , then their
coproduct over R is the homomorphism R ~ A (9 B given by
a~a (91 = 1 (9 a.
Proof.
We shall limit our proof to the case of the coproduct of two ring
homomorphisms R ~ A and R ~ B. One can use induction.
Let A, B be commutative rings, and assume given ring-homomorphisms into
a commutative ring C,
cp : A --+ C
and
tjJ:B --+ C.
Then we can define a Z-bilinear map
A x B --+ C
by (x, y) ~ cp(x)tjJ(y). From this we get a unique additive homomorphism
such that x (9 y ~ cp(x)tjJ(y). We have seen above that we can define a ring
structure on A (9 B, such that
(a (9 b)(c (9 d) = ac (9 bd.
It is then clear that our map A (9 B --+ C is a ring-homomorphism. We also have
two ring-homomorphisms
A 1. A (9 Band
B.!4 A (9 B
given by
x ~ x (9 1
and
y ~ 1 (9 y.
The universal property of the tensor product shows that (A (9 B, f, g) is a
coproduct of our rings A and B.
If A, B, Care R-algebras, and if rp, tjJ make the following diagram com-

XVI, §6
mutative,
TENSOR PRODUCT OF ALGEBRAS
631
then A ® B is also an R-algebra (it is in fact an algebra over R, or A, or B, de-
pending on what one wants to use), and the map A ® B --+ C obtained above
gives a homomorphism of R-algebras.
A commutative ring can always be viewed as a Z-algebra (i.e. as an algebra
over the integers). Thus one sees the coproduct of commutative rings as a
special case of the coproduct of R-algebras.
Graded Algebras.
Let G be a commutative monoid, written additively . By
a G-graded ring, we shall mean a ring A, which as an additive group can be
expressed as a direct sum.
and such that the ring multiplication maps Ar x As into Ar+s' for all r, S E G.
In particular, we see that Ao is a subring.
The elements of Ar are called the homogeneous elements of degree r,
We shall construct several examples of graded rings, according to the
following pattern. Suppose given for each rEG an abelian group Ar (written
additively), and for each pair r, S EGa map Ar x As ~ Ar+s' Assume that Ao
is a commutative ring, and that composition under these maps is associative and
Ao-bilinear. Then the direct sum A = EB Ar is a ring: We can define multiplica-
rEG
tion in the obvious way, namely
(L xr) (L YS) = L ( L x rYs) ,
r EG
SEG
tEG
r + s=t
The above product is called the ordinary product. However, there is another
way. Suppose the grading is in Z or Z/2Z. We define the super product of
x E Ar and YEAs to be (_l)rsxy, where xy is the given product. It is easily veri-
fied that this product is associative, and extends to what is called the super
product A ® A ~ A associated with the bilinear maps. If R is a commutative
ring such that A is a graded R-algebra, i.e. RAr CAr for all r (in addition to the
condition that A is a graded ring), then with the super product, A is also an
R-algebra, which will be denoted by Asu' and will be called the super algebra
associated with A.

632
THE TENSOR PRODUCT
XVI, §7
Example.
In the next section, we shall meet the tensor algebra T(E), which
will be graded as the direct sum of F(E), and so we get the associated super
tensor algebra Tsu(E) according to the above recipe.
Similarly, let A, B be graded algebras (graded by the natural numbers as
above). We define their super tensor product
A ®su B
to be the ordinary tensor product as graded module, but with the super product
(a 0 b)(a' 0 b') = (_l)(degb)(dega')aa' 0 bb'
if b, a' are homogeneous elements of BandA respectively. It is routinely verified
that A ®su B is then a ring which is also a graded algebra. Except for the sign,
the product is the same as the ordinary one, but it is necessary to verify associativity
explicitly. Suppose a' E Ai' b E Bj , a" E As' and b' E Br. Then the reader will
find at once that the sign which comes out by computing
(a ®su b)(a' ®su b')(a" ®su b")
in two ways turns out to be the same, namely (_lij+js+sr. Since bilinearity is
trivially satisfied, it follows that A ®su B is indeed an algebra.
The super product in many ways is more natural than what we called the
ordinary product. For instance, it is the natural product of cohomology in topol-
ogy. Cf. Greenberg-Harper, Algebraic Topology, Chapter 29. For a similar con-
struction with Z/2Z-grading, see Chapter XIX, §4.
§7.
THE TENSOR ALGEBRA OF A MODULE
Let R be a commutative ring as before, and let E be a module (i.e. an
R-module). For each integer r ~ 0, we let
,
T'(E) = (8) E
and
TO(E) = R.
i = 1
Thus T'(E) = E 0 ... ® E (tensor product taken r times). Then T' is a functor,
whose effect on linear maps is given as follows. Iff : E -> F is a linear map, then
T'(j) = T(j, ... , f)
in the sense of §1.
From the associativity of the tensor product, we obtain a bilinear map
T'(E) x peE) -+ T'+ S(E),

XVI, §7
THE TENSOR ALGEBRA OF A MODULE
633
which is associative. Consequently, by means of this bilinear map, we can define
a ring structure on the direct sum
00
T(E) = E8 T'(E),
, =0
and in fact an algebra structure (mapping R on TO(E) = R). We shall call T(E)
the tensor algebra of E, over R. It is in general not commutative. If x, y E T(E),
we shall again write x ® y for the ring operation in T(E).
Let f :E --. F be a linear map. Then f induces a linear map
T'(f) : T'(E) --. T'(F)
for each r ~ 0, and in this way induces a map which we shall denote by T(f) on
T(E). (There can be no ambiguity with the map of §l, which should now be
written TI(f), and is in fact equal to f since TI(E) = E.) It is clear that T(f) is
the unique linear map such that for XI' . . . , X, E E we have
T(f)(x I ® ... ® x.) = f(x l ) ® . .. ® f(x.).
Indeed, the elements of TI(E) = E are algebra-generators of T(E) over R. We
see that T(f) is an algebra-homomorphism. Thus T may be viewed as afunctor
from the category of modules to the category of graded algebras, T(f) being a
homomorphism of degree 0.
When E is free and finite dimensional over R, we can determine the structure
of T(E) completely, using Proposition 2.3. Let P be an algebra over k. We shall
say that P is a non-commutative polynomial algebra if there exist elements
t I' ... , tn E P such that the elements
M(i)(t) = til ' . . tis
with 1 ~ i, ~ n form a basis of P over R. We may call these elements non-
commutative monomials in (z),
As usual , by convention, when r = 0, the
corresponding monomial is the unit element of P. We see that tI' . . . , i, generate
P as an algebra over k,and that P is in fact a graded algebra, where P, consists of
linear combinations of monomials ti. : : t., with coefficients in R. It is natural to
say that t I ' .. . , In are independent non-commutative variables over R.
Proposition 7.1.
Let E befree ofdimensionnoverR. Then T(E) is isomorphic
to the non-commutative polynomial algebra on n variables over R. In other
words, if {VI" '" vn } is a basis of E over R, then the elements
form a basis of T'(E), and every element of T(E) has a uniqueexpressionas a
finite sum
La(i)M(i)(v),
(i)

634
THE TENSOR PRODUCT
XVI, §7
with almost all a(i) equal to O.
Proof
This follows at once from Proposition 2.3.
The tensor product of linear maps will now be interpreted in the context of
the tensor algebra.
For convenience, we shall denote the module oj endomorphisms EndR(E) by
L(E)Jor the rest ofthis section.
We form the direct sum
00
(LT)(E) = EB L(r(E)),
r=O
which we shall also write LT(E) for simplicity. (Of course, LT(E) is not equal to
EndR(T(E)), so we must view LT as a single symbol.) We shall see that LT is a
functor from modules to graded algebras, by defining a suitable multiplication
on LT(E). Let J E L(r(E)), g E L(T'(E)), h E L(Tm(E)). We define the product
Jg E L(Tr+s(E)) to be T(f, g), in the notation of §l, in other words to be the
unique linear map whose effect on an element x ® y with x E r(E) and
yE T'(E) is
x ® y f-> J(x) ® g(y).
In view of the associativity of the tensor product, we obtain at once the as-
sociativity (fg)h = J(gh), and we also see that our product is bilinear. Hence
LT(E) is a k-algebra.
We have an algebra-homomorphism
T(L(E)) --+ LT(E)
given in each dimension r by the linear map
We specify here that the tensor product on the left is taken in
L(E) ® .. . ® L(E).
We also note that the homomorphism isin general neither surjective nor injective.
When E is free finite dimensional over R, the homomorphism turns out to be
both, and thus we have a clear picture of LT(E) as a non-commutative poly-
nomial algebra, generated by L(E). Namely, from Proposition 2.5, we obtain :
Proposition 7.2.
Let E befree, finite dimensional over R. Then we have an
algebra-isomorphism
00
T(L(E)) = T(EndR(E)) --+ LT(E) = EB EndR(r(E))
r=O

XVI, §8
given by
SYMMETRIC PRODUCTS
635
f @ g H
T(.f, g).
Proof.
By Proposition 2.5, we have a linear isomorphism in each dimen-
sion, and it is clear that the map preserves multiplication.
In particular, we see that LT(E) IS a noncommutative polynomial algebra.
§8.
SYMMETRIC PRODUCTS
Let 6 n denote the symmetric group on n letters, say operating on the integers
(1, . . . , n). An r-multilinear map
f :E(r) -> F
is said to be symmetric if f(x\, ... , xr) = f(x,,(l)' . .. , x,,(r») for all (J E 6 r.
In T'(E), we let b, be the submodule generated by all elements of type
for all Xi E E and
(J E 6 r • We define the factor module
sr(E) = Tr(E)jb"
and let
00
S(E) = EB sr(E)
r=O
be the direct sum. It is immediately obvious that the direct sum
is an ideal in T(E), and hence that S(E) is a graded R-algebra, which is called the
symmetric algebra of E.
Furthermore, the canonical map
E(r) -> sr(E)
obt ained by composing the maps
E(r) -> T'(E) -> Tr(E)/br = sr(E)
is universal for r-multilinear symmetric maps.

636
THE TENSOR PRODUCT
XVI, §8
We observe that 5 is a functor.from the category ofmodules to the category
of graded R-alqebras. The image of (XI" ' " x.) under the canonical map
E(r) --+ 5'(E)
will be denoted simply by Xl . . . X,.
Proposition 8.1.
Let E befree ofdimension n over R. Let {VI"' " vn} be a
basisofE overk. Viewed as elementsof51(E) in 5(E), these basiselementsare
algebraically independent over R, and S(E) is therefore isomorphic to the
polynomial algebra in n variables over R.
Proof
Let t 1, ... ,tn be algebraically independent variables over R, and
form the polynomial algebra R[t 1"
' " tnJ. Let P, be the R-module of homo-
geneous polynomials of degree r. We define a map of E(') --+ P, as follows. If
WI' . . . , w, are elements of E which can be written
n
Wi = Lai.v.,
v = I
then our map is given by
i = 1,.. . , r,
It is obvious that this map is multilinear and symmetric. Hence it factors
through a linear map of S'(E) into Pr :
E(r) ------+ 5'(E)
~p/
,
From the commutativity of our diagram, it is clear that the element ViI' •. Vis in
S'(E) maps on til' . . tis in P, for each r-tuple of integers (i) = (i" . . . ,i,). Since
the monomials Ma,(t) of degree r are linearly independent over k, it follows that
the monomials Ma)(v) in sr(E) are also linearly independent over R, and that
our map 5'(E) --+ P, is an isomorphism. One verifies at once that the multiplica-
tion in 5(E) corresponds to the multiplication of polynomials in R[t] , and thus
that the map of S(E) into the polynomial algebra described as above for each
component sr(E) induces an algebra-isomorphism of S(E) onto R[t] , as desired.
Proposition 8.2.
Let E = E' EB E" be a direct sum offinite free modules.
Then there is a natural isomorphism
sn(E' EB E") ~ EB SPE' ® 5QE".
p+q=n
In fact, this is but the n-part ofa graded isomorphism
S(E' EB E") ~ SE' ® SE".

XVI, Ex
EXERCISES
637
Proof
The isomorphism comes from the following maps. The inclusions
of E' and E" into their direct sum give rise to the functorial maps
SE' @ SE" -> SE,
and the claim is that this is a graded isomorphism. Note that SE' and SE" are
commutative rings, and so their tensor product is just the tensor product of
commutative rings discussed in §6. The reader can either give a functorial map
backward to prove the desired isomorphism, or more concretely, SE' is the
polynomial ring on a finite family of variables, SE" is the polynomial ring in
another family of variables, and their tensor product isjust the polynomial ring
in the two families of variables. The matter is easy no matter what, and the
formal proof is left to the reader.
EXERCISES
I. Let k be a field and k(ex) a finite extension. Let f(X) = Irrt«, k, X),and suppose thatfis
separable. Let k' be any extension of k. Show that k(ex) ® k' is a direct sum of fields.
If k' is algebraically closed, show that these fields correspond to the embeddings of
k(ex) in k'.
2. Let k be a field, f(X) an irreducible polynomial over k, and ex a root off. Show that
k(ex) ® k' is isomorphic, as a k'-algebra, to k'[X]j(f(X» .
3. Let E be a finite extension of a field k. Show that E is separable over k if and only if
E ®kL has no nilpotent elements for all extensions L of k, and also when L = k".
4. Let cp : A ~ B be a commutative ring homomorphism. Let E be an A-module and F
a B-module. Let FA be the A-module obtained from F via the operation of A on F
through tp, that is for y E FA and a E A this operat ion is given by
(a, y) H
cp(a)y.
Show that there is a natural isomorphism
5. The norm. Let B be a commutative algebra over the commutative ring R and assume
that B is free of rank r . Let A be any commutative R-algebra. Then A @ B is both
an A-algebra and a B-algebra. We view A @ B as an A-algebra, which is also free
of rank r . If {e. , . . . , e.} is a basis of B over R, then
is a basis of A ® B over A. We may then define the norm
N = N A 0 B. A : A ® B -+ A
as the unique map which coincides with the determinant of the regular representation.

638
THE TENSOR PRODUCT
Inother words, if b e B and bB denotes multiplication by b, then
XVI, Ex
and similarly after extension of the base. Prove:
(a) Let tp : A -+ C be a homomorphism of R-algebras. Then the following diagram
is commutative:
(b) Let x, yE A ® B. Then N(x ®By) = N(x) ® N(y ). [Hint :
Use the com-
mutativity relations eiej = ejei and the associativity.]
A little flatness
6. Let M , N be flat. Show that M ® N is flat.
7. Let F be a flat R-module, and let a E R be an element which is not a zero-divisor. Show
that if ax = 0 for some x E F then x = o.
8. Prove Proposition 3.2.
Faithfully flat
9. We cont inue to assume that rings are commutative. Let M be an A-module. We say
that M is faithfully flatif M is flat, and if the functor
is faithful, that is E # 0 implies M ® A E # O. Prove that the following cond itions are
equivalent.
(i) M is faithfully flat.
(ii) M is flat, and if u :F -+ E is a homomorphism of A-modules, U # 0, then
Tw(u): M ®A F -+ M ®A E is also # 0.
(iii) M is flat, and for all maximal ideals m of A, we have mM # M .
(iv) A sequence of A-modules N' -+ N -+ N" is exact if and only if the sequence
tensored with M is exact.
10. (a) Let A -+ B be a ring-homomorphism. If M is faithfully flat over A, then B ®AM
is faithfully flat over B.
(b) Let M be faithfullyflat over B. Then M viewed as A-module via the homomorphism
A -+ B is faithfully flat over A if B is faithfully flat over A.
II. Let P, M, E bemodules over the commutative ring A. If P is finitely generated (resp.
finitely presented) and E is flat, show that the natural homomorphism
is a monomorphism (resp. an isomorphism).

XVI, Ex
EXERCISES
639
[Hillt:
Let F I -> F0 -> P -> 0 be a finite presentation, say. Consider the diagram
j
j
j
Tensor products and direct limits
12. Show that the tensor product commutes with direct limits. Inother words, if {E;} is a
directed family of modules, and M is any module, then there is a natural isomorphism
~(Ej ® AM):::; (~Ej) ®A M.
13. (D. Lazard)
Let E be a module over a commutative ring A. Tensor products are all
taken over that ring. Show that the following conditions are equivalent :
(i) There exists a direct family {F;} of free modules of finite type such that
(ii) E is flat.
(iii) For every finitely presented module P the natural homomorphism
H om A(P, A) ®A E -> HomA(P, E)
is surjective.
(iv) For every finitely presented module P and homomorphism f :P -> E there
exists a free module F, finitely generated, and homomorphisms
9 : P -> F
and
h : F -> E
such that f = h og.
Remark.
The point of Lazard 's theorem lies in the first two conditions: E is flat
if and only if E is a direct limit of fr ee modules offinite type.
[Hint:
Since the tensor product commutes with direct limits, that (i) implies (ii)
comes from the preceding exercise and the definition of flat.
To show that (ii) implies (iii), use Exercise II.
To show that (iii) implies (iv) is easy from the hypothesis.
To show that (iv) implies (i), use the fact that a module is a direct limit of finitely
presented modules (an exercise in Chapter III), and (iv) to get the free modules
instead. For complete details, see for instance Bourbaki, Algebre, Chapter X, §I,
Theorem I, p. 14.]
The Casimir element
14. Let k be a commutative field and let E be a vector space over k, of finite dimension
II . Let B be a nondegenerate symmetric bilinear form on E, inducing an iso-

640
THE TENSOR PRODUCT
XVI, Ex
morphism E --> E v of E with its dual space. Let {VI,... ,vn } be a basis of E. The B-
dual basis {vf,.. . , v~ } consists of the elements of E such that B(Vi, vJ) =bij.
(a) Show that the element I: Vi ® V; in E ® E is independent of the choice of
basis. We call this element the Casimir element (see below).
(b) In the symmetric algebra S(E), let QB= I: ViV;, Show that QB is indepen-
dent of the choice of basis. We call QBthe Casimir polynomial.It depends on
B, of course.
(c) More generally, let D be an (associative) algebra over k, let P): E --> D be an
injective linear map of E into D. Show that the element I: P)(Vi )P)(V;) =
WB,fJJ is independent of the choice of basis. We call it the Casimir element in
D, determined by p) and B.
Remark.
The terminology of the Casimir element is determined by the classical
case, when G is a Lie group, E = 9 = Lie(G) is the Lie algebra of G (tangent space at the
origin with the Lie algebra product determined by the Lie derivative), and P)(v) is the
differential operator associated with V (Lie derivative in the direction of v). The Casimir
element is then a partial differential operator in the algebra of all differential operators
on G. Cf. basic books on manifolds and Lie theory, for instance [JoL Oil, Chapter II, §1
and Chapter VII, §2.
15. Let E = sln(k) = subspace of Matn (k) consisting of matrices with trace O. Let B be
the bilinear form defined by B(X , Y) = tr(XY). Let G = SLn(k). Prove:
(a) B is c(G)-invariant, where c(g) is conjugation by an element g E G.
(b) B is invariant under the transpose (X , Y) f-+ e X , I Y).
(c) Let k = R. Then B is positive definite on the symmetric matrices and nega-
tive definite on the skew-symmetric matrices.
(d) Suppose G is given with an action on the algebra D of Exercise 14, and that
the linear map ~ : E --> D is G-linear. Show that the Casimir element is G-
invariant (for the conjugation action on S(E), and the given action on D).

CHAPTER XVII
Semisimplicity
In many applications, a module decomposes as a direct sum of simple sub-
modules, and then one can develop a fairly precise structure theory, both under
general assumptions, and particular applications. This chapter is devoted to
those results which can be proved in general. In the next chapter, we consider
those additional results which can be proved in a classical and important special
case.
I have more or less followed Bourbaki in the proof of Jacobson's density
theorem.
§1.
MATRICES AND LINEAR MAPS OVER
NON-COMMUTATIVE RINGS
In Chapter XIII, we considered exclusively matrices over commutative
rings. For our present purposes, it is necessary to consider a more general
situation.
Let K be a ring. We define a matrix (cpij) with coefficients in K just as we
did for commutative rings. The product of matrices is defined by the same
formula . Then we again have associativity and distributivity, whenever the
size of the matrices involved in the operations makes the operations defined.
In particular, the square n x n matrices over K form a ring, again denoted by
MatiK). We have a ring-homomorphism
on the diagonal.
641
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

642
SEMISIMPLICITY
XVII, §1
By a division ring we shall mean a ring with 1 =I 0, and such that every
non-zero element has a multiplicative inverse.
If K is a division ring, then every non-zero K-module has a basis, and the
cardinalities of two bases are equal. The proofis the same as in the commutative
case; we never needed commutativity in the arguments. This cardinality is
again called the dimension of the module over K, and a module over a division
ring is called a vector space.
We can associate a matrix with linear maps, depending on the choice of a
finite basis, just as in the commutative case. However, we shall consider a
somewhat different situation which we want to apply to semisimple modules.
Let R be a ring, and let
be R-modules, expressed as direct sums of R-submodules. We wish to describe
the most general R-homomorphism of E into F.
Suppose first F = F 1 has one component. Let
({J : E 1 ~ .. • ~ En -. F
be a homomorphism. Let ({Jj: E, -. F be the restriction of ({J to the factor Ej •
Every element x E E has a unique expression x = Xl + ... + X n, with X j E Ej •
We may therefore associate with x the column vector X = I(Xl> . •. , x n) , whose
components are in El> . .. , En respectively. We·can associate with ({J the row
vector (({Jl' .. . , ({In), ({Jj E HomR(Ej , F), and the effect of ({J on the element x of
E is described by matrix multiplication, of the row vector times the column
vector.
More generally, consider a homomorphism
({J : E1 EB . .. EB En -. F 1 EB . .. EB Fm '
Let tt, : F 1 ~ • . . EB Fm -. F, be the projection on the i-th factor. Then we can
apply our previous remarks to 1ti 0 ({J, for each i. In this way, we see that there
exist unique elements ({Jij E HomR(Ej , F;), such that ({J has a matrix representa-
tion
whose effect on an element x is given by matrix multiplication, namely

XVII, §1
MATRICES AND LINEAR MAPS OVER NON-COMMUTATIVE RINGS
643
Conversely, given a matrix (qJij) with qJij E HomR(Ej , Fi) , we can define an
element of HomR(E, F) by means of this matrix. We have an additive group-
isomorphism between HomR(E, F) and this group of matrices.
In particular, let E be afixed R-module, and let K = EndR(E). Then we have
a ring-isomorphism
which to each qJ E EndR(E(n )) associates the matrix
determined as before, and operating on the left on column vectors of s», with
components in E.
Remark.
Let E be a l-dirnensional vector space over a division ring D,
and let {v} be a basis.
For each a E D, there exists a unique D-linear map
fa: E --+ E such that fa(v) = avo Then we have the rule
Thus when we associate a matrix with a linear map, depending on a basis, the
multiplication gets twisted. Nevertheless, the statement wejust made preceding
this remark is correct!! The point is that we took the qJij in EndR(E), and not
in D, in the special case that R = D. Thus K is not isomorphic to D (in the
non-commutative case), but anti-isomorphic. This is the only point of difference
of the formal elementary theory of linear maps in the commutative or non-
commutative case.
We recall that an R-module E is said to be simple if it is # 0 and if it has no
submodule other than 0 or E.
Proposition 1.1.
Schur's Lemma.
Let E, F be simple R-modules. Every
non-zero homomorphism of E into F is an isomorphism. The ring EndR(E) is
a division ring.
Proof.
Let f : E --+ F be a non-zero homomorphism. Its image and kernel
are submodules, hence Ker f = 0 and 1m f = F. Hence f is an isomorphism.
If E = F, then f has an inverse, as desired .
The next proposition describes completely the ring of endomorphisms of a
direct sum of simple modules.
Proposition 1.2.
Let E = E\ntl E3j . . . E3j E~nr ) be a direct sum of simple
modules, the Ei being non-isomorphic, and each E, being repeated n, times in

644
SEMISIMPLICITY
XVII, §1
the sum. Then, up to a permutation, E 1, • • • , E, are uniquely determined up
to isomorphisms, and the multiplicities n1, ••• , n, are uniquely determined.
The ring EndR(E) is isomorphic to a ring of matrices, of type
where M ; is an nj x n, matrix over EndR(EJ, (The isomorphism is the one
with respect to our direct sum decomposition.)
Proof.
The last statement follows from our previous considerations, taking
into account Proposition 1.1.
Suppose now that we have two R-modules, with direct sum decompositions
into simple submodules, and an isomorphism
such that the E; are non-i somorphic, and the Fj are non-isomorphic. From
Proposition 1.1, we conclude that each E, is isomorphic to some Fj , and con-
versely. It follows that r = s, and that after a permutation, E, ~ Fj • Further-
more, the isomorphism must induce an isomorphism
for each i. Since E, ~ Fj, we may assume without loss of generality that in
fact E, = F j • Thus we are reduced to pro ving : If a module is isomorphic to
E(n) and to E(m), with some simple module E, then n = m. But EndR(E(n)) is
isomorphic to the n x n matrix ring over the division ring EndR(E) = K.
Furthermore this isomorphism is verified at once to be an isomorphism as
K-vector space. The dimension of the space of n x n matrices over K is n2•
This proves that the multiplicity n is uniquely determined, and proves our
proposition.
When E admits a (finite) direct sum decomposition of simple submodules,
the number of times that a simple module of a given isomorphism class occurs
in a decomposition will be called the multiplicity of the simple module (or of
the isomorphism class of the simple module).
Furthermore, if
is expressed as a sum of simple submodules, we shall call nl + ... + n, the
length of E. In man y applications, we shall also write
,
E = n1E 1 EB ... EB n.E; = EB n.E].
j= I

XVII, §2
CONDITIONS DEFINING SEMISIMPLICITY
645
§2.
CONDITIONS DEFINING SEMISIMPLICITY
Let R be a ring. Unless otherwise specified in this section all modules and
homomorphisms willbe R-modules and R-homomorphisms.
The following conditions on a module E are equivalent :
SS 1.
E is the sum of a family of simple submodules.
SS 2.
E is the direct sum of a family of simple submodules.
SS 3.
Every submodule F of E is a direct summand, i.e. there exists a
submodule Y such that E = F Et> Y.
We shall now prove that these three conditions are equivalent.
Lemma 2.1.
Let E = E E, be a sum (not necessarily direct) ofsimple sub-
iEI
modules. Then there exists a subset J c I such that E is the direct sum
EBEj .
j EJ
Proof.
Let J be a maximal subset of I such that the sum L Ej is direct.
jeJ
We contend that this sum is in fact equal to E. It will suffice to prove that each
E, is contained in this sum. But the intersection of our sum with E, is a sub-
module of E;, hence equal to 0 or Ei • If it is equal to 0, then J is not maximal,
since we can adjoin i to it. Hence E, is contained in the sum, and our lemma is
proved.
The lemma shows that SS 1 implies SS 2. To see that SS 2 implies SS 3, take
a submodule F,and let J be a maximal subset of I such that the sum F + EB E,
jeJ
is direct. The same reasoning as before shows that this sum is equal to E.
Finally assume SS3. To show SS 1, we shall first prove that every non-zero
submodule of E contains a simple submodule. Let vEE, v * O. Then by
definition, Rv is a principal submodule, and the kernel of the homomorphism
R -. Rv
is a left ideal L =f: R. Hence L is contained in a maximal left ideal M =f: R
(by Zorn's lemma). Then MIL is a maximal submodule of RIL (unequal to
RIL), and hence Mv is a maximal submodr''e of Rv, unequal to Rv,correspond-
ing to MIL under the isomorphism
R/L -. Rv.

646
SEMISIMPLICITY
We can write E = Mv EEl M' with some submodule M'. Then
Rv = Mv EEl (M' n Rv),
XVII. §3
because every element x E Rv can be written uniquely as a sum x = av + x'
with a EM and x' EM', and x' = x - av lies in Rv. Since Mv is maximal in
Rv, it follows that M' n Rv is simple, as desired.
Let Eo be the submodule of E which is the sum of all simple submodules of
E. If Eo =f:. E, then E = Eo EEl F with F =f:. 0, and there exists a simple sub-
module of F, contradicting the definition of Eo. This proves that 553 implies
551.
A module E satisfying our three conditions is said to be semisimple.
Proposition 2.2.
Every submodule and everyfactor module of a semisimple
moduleis semisimpIe.
Proof.
Let F be a submodule. Let F0 be the sum of all simple submodules
of F. Write E = F0 EEl Fo. Every element x of F has a unique expression
x = Xo + Xo with Xo E F0 and Xo E Fo. But Xo = x -
Xo E F. Hence F is
the direct sum
F = F0 EEl (F n Fo)·
We must therefore have F 0 = F, which is semisimple. As for the factor module,
write E = FEElF'. Then F' is a sum of its simple submodules, and the canonical
map E --+ ElF induces an isomorphism of F' onto ElF. Hence ElF is semisimple.
§3.
THE DENSITY THEOREM
Let E be a semisimple R-module. Let R' = R'(E) be the ring EndR(E) . Then
E is also a R'-module, the operation of R' on E being given by
(<p, x) H
<p(x)
for 'P E R' and x E E. Each a E R induces a R'-homomorphismfa : E ~ E by
the map fa(x) = ax. This is what is meant by the condition
<p(rxX) = rx<p(X).
We let R" = R"(E) = EndR,(E). We call R' the commutant of Rand R" the
bicommutant. Thus we get a ring-homomorphism
R ~ EndR,(E) = R"(E) = R"

XVII, §3
THE DENSITY THEOREM
647
by
IJ. f--->fa. We now ask how big is the image of this ring-homomorphism.
The density theorem states that it is quite big.
Lemma 3.1.
Let E be semisimple over R. Let R' = EndR(E), f E EndR,(E)
as above . Let x E R. There exists an element a E R such that ax = f(x) .
Proof.
Since E is semisimple, we can write an R-direct sum
E = Rx EB F
with some submodule F . Let 7T: E ~ Rx be the projection. Then
7T E R', and
hence
f(x) = f(nx) = nf(x).
This shows that f(x) E Rx, as desired.
The density theorem generalizes the lemma by dealing with a finite number
of elements of E instead of just one. For the proof, we use a diagonal trick.
Theorem
3.2.
(Jacobson).
Let
E
be
semisimple
over
R,
and
let
R' = EndR(E). Let f E EndR,(E). Let XI, . •. , xn E E. Then there exists an
element a E R such that
aXj = j(Xj)
for
i = I, .. . , n.
IfE isfinitely generated over R', then the natural map R~ EndR,(E) is surjective.
Proof.
For clarity of notation, we shall first carry out the proof in case E
is simple. Letj'?" : E(n) --+ E(n) be the product map, so that
Let R~ = EndR(E(n». Then R~ is none other than the ring of matrices with
coefficients in R'. Since f commutes with elements of R' in its action on E, one
sees immediately thatj<n) is in EndR~(E(n». By the lemma, there exists an element
a E R such that
which is what we wanted to prove.
When E is not simple, suppose that E is equal to a finite direct sum of simple
submodules E, (non-isomorphic), with multiplicities n.:
(Ei*E j
if
i =lJ),
then the matrices representing the ring of endomorphisms split according to
blocks corresponding to the non-i somorphic simple components in our direct
sum decomposition. Hence here again the argument goes through as before.

648
SEMISIMPLICITY
XVII, §3
The main point is thatjCn) lies in EndR~(E(n», and that we can apply the lemma.
We add the observation that if E is finitely generated over R', then an element
f E EndR,(E) is determined by its value on a finite number of elements of E, so
the asserted surjectivity R ~ EndR,(E) follows at once . In the applications
below, E will be a finite dimensional vector space over a field k, and R will be
a k-algebra, so the finiteness condition is automatically satisfied.
The argument when E is an infinite direct sum would be similar, but the
notation is disagreeable. However, in the applications we shall never need the
theorem in any case other than the case when E itself is a finite direct sum of
simple modules, and this is the reason why we first gave the proof in that case,
and let the reader write out the formal details in the other cases, if desired.
Corollary 3.3.
(Burnside's Theorem).
Let E be a finite-dimensional
vector space over an algebraically closedfield k, and let R be a subalgebra of
Endk(E). If E is a simple Rcmodule, then R = EndR, (E).
Proof.
We contend that EndR(E) = k. At any rate, EndR(E) is a division
ring R', containing k as a subring and every element of k commutes with every
element of R' . Let a E R'. Then k(a) is a field. Furthermore, R' is contained in
Endk(E) as a k-subspace, and is therefore finite dimensional over k. Hence k(rx)
is finite over k, and therefore equal to k since k is algebraically closed. This
proves that EndR(E) = k. Let now {VI' ... , vn} be a basis of E over k. Let
A E Endk(E). According to the density theorem, there exists a E R such that
rxVj = AVj
for
i = 1, . . . , n.
Since the effect of A is determined by its effect on a basis, we conclude that
R = Endk(E).
Corollary 3.3 is used in the following situation as in Exercise 8. Let E
be a finite-dimensional vector space over field k. Let G be a submonoid of
GL(E) (multiplicative). A G-invariant subspace F of E is a subspace such that
CTF C F for all CT E G. We say that E is G-simple if it has no G-invariant
subspace other than 0 and E itself, and E * O. Let R = k[G] be the subalgebra
of EndiE) generated by Gover k. Since we assumed that G is a monoid, it
follows that R consists of linear combinations
with a, E k and a, E G. Then we see that a subspace F of E is G-invariant if and
only if it is R-invariant. Thus E is G-simple if and only if it is simple over R in
the sense which we have been considering. We can then restate Burnside's
theorem as he stated it:
Corollary3.4.
Let E be a finite dimensional vector space over an alge-
braically closedfield k, and let G be a (multiplicative) submonoid of GL(E).

XVII, §3
If E is G-simple, then keG] = Endk(E).
THE DENSITY THEOREM
649
When k is not algebraically closed, then we still get some result.
Quite
generally, let R be a ring and E a simple R-module. We have seen that EndR(E)
is a division ring, which we denote by D, and E is a vector space over D.
Let R be a ring, and E any R-module. We shall say that E is a faithful
module if the following cond ition is satisfied . Given
(X E R such that (Xx = 0
for all x E E, we have (X = O. In the applications, E is a vector space over a field
k, and we have a ring-homomorphism of R into Endk(E). In this way, E is an
R-module, and it is faithful if and only if this homomorphism is injective.
Corollary 3.5.
(Wedderburn's Theorem),
Let R be a ring, and E a simple,
faithful moduleover R. Let D = EndR(E), and assumethat E isfinite dimen-
sional over D. Then R = EndD(E).
Proof.
Let {VI "' " vn } be a basis of E over D. Given A E EndD(E), by
Theorem 3.2 there exists (X E R such that
(XVi =
AVi
for
i = 1, . . . , n .
Hence the map R --+ EndD(E) is surjective. Our assumption that E is faithful
over R implies that it is injective, and our corollary is proved.
Example.
Let R be a finite-dimensional algebra over a field k, and assume
that R has a unit element, so is a ring. If R does not have any two-sided ideals
other than 0 and R itself, then any nonzero module E over R is faithful, because
the kernel of the homomorphism
is a two-sided ideal # R. If E is simple, then E is finite dimensional over k.
Then D is a finite-dimensional division algebra over k. Wedderburn's theorem
gives a representation of R as the ring of D-endomorphisms of E.
Under the assumption that R is finite dimensional, one can find a simple
module simply by taking a minimal left ideal
=1= O. Such an ideal exists merely
by taking a left ideal of minimal non-zero dimension over k. An even shorter
proof of Wedderburn's theorem will be given below (Rieffel's theorem) in this
case .
Corollary 3.6.
LetR be a ring.finitedimensional algebraoverafield k which
is algebraically closed. Let V be a finite dimensional vector space over k, with
a simplefaithful representation p: R ~ Endk(V). Then p is an isomorphism.
in other words. R = Matn(k).
Proof.
We apply Corollary 3.5, noting that D is finite dimensional over
k. Given a E D , we note that k(a) is a commutative subfield of D, whence
k(a) = k by assumption that k is algebraically closed , and the corollary follows.

650
SEMISIMPLICITY
XVII, §3
Note.
The corollary applies to simple rings, which will be defined below.
Suppose next that VI' . . . , Vm are finite dimensional vector spaces over a field
k, and that R is a k-algebra with repre sentations
R -,> Endk(V;), i = I , .. . , m,
so V; is an R-module. If we let
E = VI EB . . . EB Vm,
then E is finite over R'(E), so we get the following consequence of Jacobson's
density theorem.
Theorem 3.7 .
Existence of projection operators.
Let k be a field. R a
k-alqebra, and VI' ... , Vm finite dimensional k-spaces which are also simple
R-modules, and such that V; is not R-isomorphic to \.} for i 1= j. Then there
exist elements ei E R such that ei acts as the identity on V; and ei\.} = 0
if j 1= i.
Proof.
We observe that the projection fi from the direct sum E to the i -th
factor is in EndR,(E), because if cp E R' then cp(\.}) C \.} for allj. We may therefore
apply the density theorem to conclude the proof.
Corollary 3.8.
(Bourbaki).
Let k be a field of characteristic O. Let R be
a k-algebra , and let E, F be semisimple Rsmodules, finite dimensional over k.
For each a E R, let aE' aF be the corresponding k-endomorphisms on E and
F respectively. Suppose that the traces are equal; that is,
tr(aE) = tr(aF) for all a E R.
Then E is isomorphic to F as R-module.
Proof.
Each of E and F is isomorphic to a finite direct sum of simple R-
modules, with certain multiplicities. Let V be a simple R-module, and suppose
E = y<n) EB direct summands not isomorphic to V
F = y<m ) EB direct summands not isomorphic to V.
It will suffice to prove that m = n. Let ev be the element of R found in Theorem
3.7 such that ev acts as the identity on V, and is 0 on the other direct summands
of E and F . Then
tr(eE) = ndimk(V)
and
tr(eF) = mdimk(V),
Since the traces are equal by assumption, it follows that m = n, thus concluding
the proof. Note that the characteristic 0 is used here , because the values of the
trace are in k.
Example.
In the language of repre sentations, suppose G is a monoid, and

XVII, §4
SEMISIMPLE RINGS
651
we have two semisimple representations into finite dimensional k-spaces
p : G ~ Endk(E)
and
pi : G ~ Endk(F)
(so p and p' map G into the multiplicative monoid of Endj ). Assume that
tr p((T) = tr p'((T) for all (T E G. Then p and pi are isomorphic. Indeed, we let
R = k[GJ, so that p and pi extend to representations of R. By linearity, one has
that tr pea) = tr p'ea) for all a E R, so one can apply Corollary 3.8.
§4.
SEMISIMPlE RINGS
A ring R is called semisimple if 1 #- 0, and if R is semisimple as a left module
over itself.
Proposition 4.1.
If R is semisimple, then every R-module is semisimple.
Proof.
An R-module is a factor module of a free module, and a free module
is a direct sum of R with itself a certain number of times. We can apply Proposi-
tion 2.2 to conclude the proof.
Examples.
I) Let k be a field and let R = Matn(k) be the algebra of
n x n matrices over k. Then R is semisimple, and actually simple, as we shall
define and prove in §5, Theorem 5.5.
2) Let G be a finite group and suppose that the characteristic of k does not
divide #(G). Then the group ring k[G] is semisimple, as we shall prove in Chapter
XVIII, Theorem 1.2.
3) The Clifford algebras enover the real numbers are semisimple. See Exer-
cise 19 of Chapter XIX.
A left ideal of R is an R-module, and is thus called simple if it is simple as a
module.
Two ideals L, L' are called isomorphic if they are isomorphic as
modules.
We shall now decompose R as a sum of its simple left ideals, and thereby
get a structure theorem for R.
Let {LJi EI be a family of simple left ideals, no two of which are isomorphic,
and such that each simple left ideal is isomorphic to one of them. We say that
this family is a family of representatives for the isomorphism classes of simple
left ideals.
Lemma 4.2.
Let L be a simple left ideal, and let E be a simple R-module.
If L is not isomorphic to E, then LE = 0.
Proof.
We have RLE = LE, and LE is a submodule of E, hence equal to

652
SEMISIMPLICITY
oor E. Suppose LE = E. Let y E E be such that
Ly i= O.
XVII, §4
Since Ly is a submodule of E, it follows that Ly = E. The map I'J. H
l'J.y of L
into E is a homomorphism of L into E, which is surjective, and hence nonzero.
Since L is simple, this homomorphism is an isomorphism.
Let
be the sum of all simple left ideals isomorphic to L: From the lemma, we con-
clude that RjRj = 0 if i i= j. This will be used constantly in what follows. We
note that R, is a left ideal, and that R is the sum
because R is a sum of simple left ideals. Hence for any j E I,
R, C RjR = RjRj C Rj,
the first inclusion because R contains a unit element, and the last because Rj
is a left ideal. We conclude that R, is also a right ideal, i.e. R, is a two-sided
ideal for allj E I .
We can express the unit element 1 of R as a sum
1= L e,
j e l
with ej E R j. This sum is actually finite, almost all ej = O.
Say e, i= 0 for
indices i = 1, . .. , s, so that we write
r = e1 + ... + es.
For any x E R, write
x = LXj,
i e l
For j = 1, ... , s we have ejx = ejxj and also
Furthermore, x = e1x + ... + e,x.
This proves that there is no index i
other than i = 1, .. . , s and also that the i-th component x, of x is uniquely
determined as e,x = e.x..
Hence the sum R = R 1 + ... + R, is direct, and
furthermore, e, is a unit element for R;, which is therefore a ring.
Since

XVII, §4
R,Rj = 0 for i i= i. we find that in fact
R = Il Rj
j = I
SEMISIMPLE RINGS
653
is a direct product of the rings Rj •
A ring R is said to be simple if it is semisimple, and if it has only one
isomorphism class of simple left ideals . We see that we have proved a structure
theorem for semisimple rings:
Theorem 4.3.
Let R be semisimple. Then there is only a finit e number of
non-isomorphic simple left ideals, say L I , •.. , Ls . If
R j = L L
L
~ t.,
is the sum ofall simple left ideals isomorphic to Lj, then R, is a two-sided ideal,
which is also a ring (the operations being those induced by R), and R is ring
isomorphic to the direct product
s
R = f1 s..
j = I
Each R, is a simple ring. If e, is its unit element, then 1 = el + ... + e., and
R, = Re.. We have ejej = 0 if i i= j .
We shall now discuss modules.
Theorem 4.4.
Let R be semisimple, and let E be an R-module i= O. Then
s
s
E = EBR jE = EB ejE,
j = I
j = I
and RjE is the submodule of E consisting of the sum of all simple submodules
isomorphic to L j.
Proof.
Let E, be the sum of all simple submodules of E isomorphic to Li.
If V is a simple submodule of E, then R V = V, and hence L, V = V for some i.
By a previous lemma, we have L, ~ V. Hence E is the direct sum of E I , . . . , Es •
It is then clear that RjE = Ej •
Corollary 4.5.
Let R be semisimple. Every simple module is isomorphic to
one ofthe simple left ideals L:
Corollary 4.6.
A simple ring has exactly one simple module, up to iso-
morphism.

654
SEMISIMPLICITY
XVII, §5
Both these corollaries are immediate consequences of Theorems 4.3 and 4.4.
Proposition 4.7.
Let k be a field and E a finite dimensional vector space
over k. Let S be a subset of Endk(E). Let R be the k-algebra generated by the
elements ofS. Then R is semisimple if and only if E is a semisimple R (or S)
module.
Proof.
If R is semisimple, then E is semisimple by Proposition 4.1. Con-
versely, assume E semisimple as S-module. Then E is semisimple as R-module,
and so is a direct sum
n
E = EB E,
i= I
where each E, is simple. Then for each i there exists an element Vj E E, such
that E; = Ru.. The map
X 1---+ (XVI, .. . , xvn)
is a R-homomorphism of R into E, and is an injection since R is contained in
Endk(E). Since a submodule of a semisimple module is semisimple by Proposi-
tion 2.2, the desired result follows.
§5.
SIMPLE RINGS
Lemma 5.1.
Let R be a ring, and l/J E EndR(R) a homomorphism of R into
itself, viewed as R-module. Then there exists a E R such that l/J(x) = xa for
all X E R.
Proof.
We have l/J(x) = l/J(x · I) = xl/J(1). Let a = l/J(1).
Theorem 5.2.
Let R be a simple ring. Then R is afinite direct sum of simple
left ideals. There are no two-sided ideals except 0 and R. If L, M are simple
left ideals, then there exists a E R such that La = M. We have LR = R.
Proof.
Since R is by definition also semisimple, it is a direct sum of simple
m
left ideals, say EBLj . We can write I as a finite sum I = ?: f3j ' with f3j E Lj •
j EJ
r
l
Then
m
m
R = EB Rflj = EB Lj.
j= I
j = I

XVII, §5
SIMPLE RINGS
655
This proves our first assertion. As to the second, it is a consequence of the
third. Let therefore L be a simple left ideal. Then LR is a left ideal, because
RLR = LR, hence (R being semisimple) is a direct sum of simple left ideals,
say
m
LR = ffiL j ,
j = 1
Let M be a simple left ideal. We have a direct sum decomposition R = LEE> L'.
Let n : R -> L be the projection. It is an R-endomorphism. Let a: L --+ M be
an isomorphism (it exists by Theorem 4.3). Then a 0 n :R -> R is an R-endo-
morphism. By the lemma, there exists a E R such that
a
0 n(x) = x«
for all
x E R.
Apply this to elements x E 1. We find
a(x) = x«
for all
x E 1.
The map x H x« is a R-homomorphism of L into M, is non-zero, hence is an
isomorphism. From this it follows at once that LR = R, thereby proving our
theorem.
Corollary 5.3.
Let R be a simple ring. Let E be a simple R-module, and L
a simpleleft idealof R. Then LE = E and E is faithful.
Proof.
We
have
LE = L(RE) = (LR)E = RE = E.
Suppose aE =°
for some rx E R. Then RrxRE = RrxE = 0. But RrxR is a two-sided ideal. Hence
RaR = 0, and a = O. This proves that E is faithful.
Theorem 5.4.
(Rieffel).
Let R be a ring without two-sidedideals except 0
and R. Let L be a nonzero left ideal, R' = EndR(L) and R" = EndR'(L).
Then the naturalmap A: R --+ R" is an isomorphism.
Proof.
The kernel of A is a two-sided ideal, so ), is injective. Since LR
is a two-sided ideal, we have LR = Rand A(L)A(R) = A(R). For any x, y E L,
and fER", we have f(xy) = f(x)y, because right multiplication by y is an
R-endomorphism of 1. Hence A(L) is a left ideal of R", so
R" = R"A(R) = R"A(L)A(R) = A(L)A(R) = A(R),
as was to be shown.
In Rieffel's theorem, we do not need to assume that L is a simple module.

656
SEMISIMPLICITY
XVII, §5
On the other hand, L is an ideal. So this theorem is not equivalent with previous
ones of the same nature. In §7, we shall give a very general condition under
which the canonical homomorphism
R -+ R"
of a ring into the double endomorphism ring of a module is an isomorphism.
This will cover all the pre vious cases.
As pointed out in the example following Wedderburn's theorem, Rieffel's
theorem applies to give another proof when R is a finite-dimensional algebra
(with unit) over a field k.
The next theorem gives a converse, showing that matrix rings over division
algebras are simple.
Theorem 5.5.
Let D be a division ring, and E a finite-dimensional vector
spaceoverD. Let R = EndD(E). Then R is simpleandE is a simpleR-module.
Furthermore, D = EndR(E).
Proof.
We first show that E is a simple R-module. Let vEE, v =I- O. Then
v can be completed to a basis of E over D, and hence, given wEE, there exists
a E R such that av = w. Hence E cannot have any invariant subspaces other
than 0 or itself, and is simple over R. It is clear that E is faithful over R. Let
{VI' ... , vm } be a basis of E over D. The map
of R into E(m) is an R-homomorphism of R into E(m), and is injective. Given
(WI> • . . , wm) E E(m), there exists
(X E R such that av; = Wi and hence R is R-
isomorphic to E(m). This shows that R (as a module over itself) is isomorphic
to a direct sum of simple modules and is therefore semisimple. Furthermore,
all these simple modules are isomorphic to each other, and hence R is simple
by Theorem 4.3.
There remains to prove that D = EndR(E). We note that E is a semisimple
module over D since it is a vector space, and every subspace admits a com-
plementary subspace. We can therefore apply the density theorem (the roles
of Rand D are now permuted !). Let cp E EndR(E).
Let vEE, v =I- O. By the
density theorem, there exists an element a E D such that cp(v) = avo Let WEE.
There exists an element fER such that f(v) = w. Then
cp(W) = cp(f(v»
= f(cp(v»
= f(av) = af( v) = aw.
Therefore cp(w) = aw for all WEE. This means that cp E D, and concludes our
proof.
Theorem 5.6.
Let k be a field and E a finite-dimensional vector space of

XVII, §6THE JACOBSON RADICAL, BASE CHANGE, AND TENSOR PRODUCTS
657
dimension mover k. Let R = EndiE). Then R is a k-space,and
dim, R = m",
Furthermore, m is the number of simple left ideals appearing in a direct sum
decomposition of R as sucha sum.
Proof.
The k-space of k-endomorphisms of E is represented by the space
of m x m matrices in k, so the dimension of R as a k-space is m2• On the other
hand, the proof of Theorem 5.5 showed that R is R-isomorphic as an R-module
to the direct sum
E(m).
We know the uniqueness of the decomposition of a
module into a direct sum of simple modules (Proposition 1.2), and this proves
our assertion.
In the terminology introduced in §I, we see that the integer m in Theorem
5.6 is the length of R.
We can identify R = Endk(E) with the ring of matrices Matm(k), once a
basis of E is selected. In that case, we can take the simple left ideals to be the
ideals L, (i = 1, . . . , m) where a matrix in L, has coefficients equal to 0 except
in the i-th column. An element of L 1 thus looks like
o
0)
o
0
·
.
·
.
·
.
o ...
0
We see that R is the direct sum of the m columns.
We also observe that Theorem 5.5 implies the following :
If a matrix M E Matm(k) commuteswith all elements of Matm(k), then M is a
scalar matrix.
Indeed, such a matrix M can then be viewed as an R-endomorphism of E,
and we know by Theorem 5.5 that such an endomorphism lies in k. Of course,
one can also verify this directly by a brute force computation.
§6.
THE JACOBSON RADICAL, BASE CHANGE,
AND TENSOR PRODUCTS
Let R be a ring and let M be a maximal left ideal. Then RIM is an R-module,
and actually RIM is simple . Indeed, let J be a submodule of RIM with
J =1= RIM . Let J be its inverse image in R under the canonical homomorphism.

658
SEMISIMPLICITY
XVII, §6
Then J is a left ideal *" M because J *" RIM, so J = Rand J = O. Conversely,
let E be a simple R-module and let vEE, v *" O. Then Rv is a submodule *" a
of E, and hence Rv = E. Let M be the kernel of the homomorphism x ~ xv .
Then M is a left ideal, and M is maximal; otherwise there is a left ideal M' with
R :> M' :> M and M' *" R, *" M. Then RIM = E and RIM' is a non-zero homo-
morphic image of E, which cannot exist since E is simple (Schur's lemma,
Proposition 1.1) . Thus we obtain a bijection between maximal left ideals and
simple R-modules (up to isomorphism).
We define the Jacobson radical of R to be the left ideal N which is the
intersection of all maximal left ideals of R. We may also denote N = Rad(R).
Theorem 6.1.
(a)
For every simple R-module we have NE = O.
(b) The radical N is a two-sided ideal, containing all nilpotent two-sided ideals.
(c) Let R be a finite dimensional algebra over field k. Its radical is {O}, if and
only if R is semisimple.
(d) If R is a finite dimensional algebra over a field k, then its radical N is
nilpotent (i.e. NT = 0 for some positive integer r).
These statements are easy to prove, and hints will be given appropriately. See
Exercises 1 through 5.
Observe that under finite dimensionality conditions, the radical's being a
gives us a useful criterion for a ring to be semisimple, which we shall use in
the next result.
Theorem 6.2.
Let A be a semisimple algebra, finite dimensional over a field
k. Let K be a finite separable extension of k. Then K 0 k A is a semisimple
over K.
Proof.
In light of the radical criterion for semisimplicity, it suffices to prove
that K 0 k A has zero radical, and it suffices to do so for an even larger extension
than K, so that we may assume K is Galois over k, say with Galois group G.
Then G operates on K 0 A by
u(x 0 a) = ox I8l a
for
x E K
and
a EA .
Let N be the radical of K 0 A . Since N is nilpotent, it follows that uN is also
nilpotent for all a E G, whence uN = N because N is the maximal nilpotent
ideal (Exercise 5). Let {aI' . .. , am}be a basis of A over k. Suppose N contains
the element
, = LXi I8l a, *" a
with
Xi E K.
For every y E K the element (y 0 1)' = 2: YXi 0 a, also lies in N. Then
traceu y I8l 1)') = 2: u, = 2: Tr(yxi) 0 a, = 2: 1 0 aiTr(yxi)
also lies in N, and lies in 1 I8l A = A, thus proving the theorem.

XVII, §6 THE JACOBSON RADICAL, BASE CHANGE, AND TENSOR PRODUCTS
659
Remark.
For the case when A is a finite extension of k, compare with
Exercises I, 2, 3 of Chapter XVI.
Let A be a semi simple algebra, finite dimensional over a field k. Then by
Theorem 6.2 the extension of scalars A 0 k P is semisimple if k is perfect. In
general, an algebra A over k is said to be absolutely semisimple if A 0 k P is
semi simple.
We now look at semisimple algebras over an algebraically closed field .
Theorem 6.3.
Let A, B be simple algebras, finite dimensional over a
field k which is algebraically closed. Then A 0 k B is also simple. We have
A :::: Endk(V) and B :::: Endk(W) whereV, Ware finite dimensionalvectorspaces
over k, and there is a natural isomorphism
A Q9 k B :::: Endk(V 0 k W) :::: Endk(V) 0 k Endk(W).
Proof.
The formula is a special case of Theorem 2.5 of Chapter XVI, and
the isomorphisms A :::: Endk(V), B :::: Endk(W) exist by Wedderburn's theorem
or its corollaries.
Let A be an algebra over k and let F be an extension field of k. We denote
by AF the extension of scalars
AF = A Q9 k F.
Thu s AF is an algebra over F . As an exercise, prove that if k is the center of A,
then F is the center of AF . (Here we identify F with I 0 F. )
Let A , B be algebras over k. We leave to the reader the proof that for every
extension field F of k, we have a natural isomorphism
(A 0 k B )F = AF Q9 F B F ·
We apply the above considerations to the tensor product of semisimple
algebras.
Theorem 6.4.
Let A, B be absolutely semisimple algebrasfinite dimensional
over a field k. Then A Q9 k B is absolutely semisimple.
Proof.
Let F = k", Then AF is semisimple by hypothesis, so it is a direct
product of simple algebras, which are matrix algebras, and in particular we can
apply Theorem 6.3 to see that AF Q9 F B F has no radical. Hence A 0 k B has no
radical (because if N is its radical, then N Q9 k F = NF is a nilpotent ideal of
AF 0 F B F), whence A Q9 k B is semisimple by Theorem 6.I(c).
Remark.
We have proved the above tensor product theorems rapidly in
special cases, which are already important in various applications. For a more
general treatment, I recommend Bourbaki's Algebra, Chapter VIII, which gives
an exhaustive treatment of tensor products of semi simple and simple algebras.

660
SEMISIMPLICITY
§7.
BALANCED MODULES
Let R be a ring and E a module. We let R'(E) = EndR(E) and
R"(E) = EndR.(E).
XVII, §7
Let A:R --+ R" be the natural homomorphism such that Aiv) = xv for x E R
and VEE. If Ais an isomorphism, we shall say that E is balanced. We shall say
that E is a generator (for R-modules) if every module is a homomorphic image
of a (possibly infinite) direct sum of E with itself. For example, R is a generator.
More interestingly, in Rieffel's Theorem 5.4, the left ideal L is a gen-
erator, becau se LR = R implies that there is a surjective homomorphism
LX' .. x L ~ R since we can write 1 as a finite combination
1 = x\a\ + ... + xnan with xi ELand a, E R.
The map (xl' . . . ,Xn) ~ xla\ + ... + xnanis a R-homomorphism of left module
onto R.
If E is a generator, then there is a surjective homomorphism En) ~ R (we
can take n finite since R is finitely generated, by one element 1).
Theorem 7.1.
(Morita).
Let E be an R-module. Then E is a generator if
and only if E is balanced and finitely generated projective over R'(E).
Proof.
We shall prove half of the theorem, leaving the other half to the
reader, using similar ideas (see Exercise 12). So we assume that E is a generator,
and we prove that it satisfies the other properties by arguments due to Faith .
We first prove that for any module F, R EB F is balanced. We identify Rand
F as the submodules R EB 0 and 0 EB F of R EB F, respectively. For W E F,
let «Pw :R EB F ~ F be the map «Pw(x + v) = XW. Then any f E R"(R EB F)
commutes with
7T\,
7T2'
and each
«Pw. From this
we see at once that
f(x + v) = f(l)(x + v) and hence that R EB F is balanced. Let E be a gen-
erator, and E(n) ~ R a surjective homomorphism. Since R is free , we can write
E(n) = R EB F for some module F, so that En) is balanced, Let 9 E R'(E) .
Then g(n) commutes with every element ({) = «(()ij) in R'(E(n» (with components
({)ij E R '(E» , and hence there is some X E R such that g(n) =
A~n ) . Hence
9 = Ax, thereby proving that E is balanced, since A is obviously injective.
To prove that E is finitely generated over R'(E), we have
as additive groups. This relation also obviously holds as R'-modules if we
define the operation of R' to be composition of mappings (on the left). Since
HomR(R, E) is R'-isomorphic to E under the map h ~ h(l), it follows that E is
an R'-homomorphic image of R,(nl, whence finitely generated over R'. We also
see that E is a direct summand of the free R'-module R,(n) and is therefore
projective over R'(E) . This concludes the proof.

XVII, Ex
EXERCISES
The radical
EXERCISES
661
1. (a) Let R be a ring. We define the radical of R to be the left ideal N which is the inter-
section of all maximal left ideals of R. Show that NE = 0 for every simple R-module
E. Show that N is a two-sided ideal. (b) Show that the radical of RjN is O.
2. A ring is said to be Artinian if every descending sequence of left ideals J I :::> J2 :::> • • •
with J; =1= J;+I is finite. (a) Show that a finite dimensional algebra over a field is
Artinian . (b) If R is Artinian , show that every non-zero left ideal contains a simple
left ideal. (c) If R is Artinian , show that every non-empty set of ideals contain s a
minimal ideal.
3. Let R be Artinian . Show that its radical is 0 if and only if R is semisimple. [Hint: Get
an injection of R into a direct sum EB RIM ; where {MJ is a finite set of maximal left
ideals.]
4. Nakayama's lemma. Let R be any ring and M a finitely generated module . Let N
be the radical of R. If NM = M show that M = O. [Hint:
Observe that the proof
of Nakayama's lemma still holds.]
5. (a) LetJ be a two-sided nilpotent ideal of R. Show thatJ is contained in the radical.
(b) Conversely, assume that R is Artinian . Show that its radical is nilpotent, i.e.,
that there exists an integer r ~ I such that N' = O. [Hint: Consider the descending
sequence of powers N", and apply Nakayama to a minimal finitely generated left
ideal LeN'" such that NOOL
=1= O.
6. Let R be a semisimple commutative ring. Show that R is a direct product of fields.
7. Let R be a finite dimensional commutative algebra over a field k. If R has no nilpotent
element # 0, show that R is semisimple.
8. (Kolchin)
Let E be a finite-dimensional vector space over a field k. Let G be a sub-
group of GL(E) such that every element A EGis of type l + N where N is nilpotent.
Assume E # O. Show that there exists an element v E E, v # 0 such that Av = v for all
A E G. [Hint :
First reduce the question to the case when k is algebraically closed by
showing that the problem amounts to solving linear equations. Secondly, reduce it to
the case when E is a simple k[G]-module. Combining Burnside's theorem with the
fact that tr(A) = tr(l) for all A E G, show that if Ao E G, Ao = I + N, then tr(NX) = 0
for all X E Endk(E), and hence that N = 0, Ao = [.J
Semisimple operations
9. Let E be a finite dimensional vector space over a field k. Let R be a semisimple sub-
algebra of Endk(E). Let a, b E R. Assume that
Ker bE =:> Ker aE,
where bE is multipl ication by b on E and similarly for aE' Show that there exists an
element S ER such that sa = b. [Hint :
Reduce to R simple. Then R = EndD(Eo)
and E =
E~ ) .
Let VI"'"
u, E E be a D-basis for aE. Define s by s(avj) = bu, and

662
SEMISIMPLICITY
XVII, Ex
extend s by D-linearity. Then saE = bE, so sa = b.]
10. Let E be a finite-dimensional vector space over a field k. Let A E Endk(E). We say
that A is semisimple if E is a semisimple A-space,or equivalently, let R be the k-algebra
generated by A, then E is semisimple over R. Show that A is semisimple if and only
if its minimal polynomial has no factors of multiplicity > lover k,
II. Let E be a finite-dimensional vector space over a field k, and let S be a commutative
set of endomorphisms of E. Let R = k[S]. Assume that R is semisimple. Show that
every subset of S is semisimpIe.
12. Pro ve that an R-module E is a generator if and only if it is balanced, and finitely
generated projective over R'(E ). Show that Theorem 5.4 is a consequence of Theorem
7.1.
13. Let A be a principal ring with quotient field K . Let Anbe n-space over A, and let
T = An EEl An EB ... EEl An
be the direct sum of Anwith itself r times. Then T is free of rank nr over A. If we view
elements of An as column vectors, then T is the space of n x r matrices over A. Let
M = Matn(A) be the ring of n x n matrices over A, operating on the left of T. By a
lattice L in T we mean an A-submodule of rank nr over A. Prove that any such lattice
which is M-stable is M-isomorphic to T itself. Thus there is just one M-isomorphism
class of lattices. [Hint:
Let g EM be the matrix with I in the upper left corner and
oeverywhere else, so g is a projection of Anon a l-dimensional subspace. Then multi-
plication on the left g: T ~ A, maps T on the space of n x r matrices with arbitrary
first row and 0 everywhere else. Furthermore, for any lattice L in T the image gL is a
lattice in A" that is a free A-submodule of rank r. By elementary divisors there exists
an r x r matrix Qsuch that
gL = A,Q
(multiplication on the right).
Then show that TQ = L and that multiplication by Qon the right is an M-isomorphism
of T with L.]
14. Let F be a field. Let n = n(F) be the vector space of strictly upper triangular n x II
matrices over F. Show that n is actually an algebra, and all elements of n are nilpo-
tent (some positive integral power is 0).
15. Conjugation representation. Let A be the multiplicative group of diagonal matrices in
F with non-zero diagonal components. For a E A, the conjugation action of a on
Matll(F) is denoted by c(a), so c(a)M = «Ma:' for ME Maln(F). (a) Show that n
is stable under this action. (b) Show that n is semisimple under this action . More
precisely, for I ~ i < j ~ II, let Eij be the matrix with ((i)-component I, and all other
components O. Then these matrices Eij form a basis for n over F, and each Eij is an
eigenvector for the conjugation action, namely for a = diag(al ," " all)' we have
aEija - 1 = (a;/aj) Eij ,
so the corresponding character Xij is given by Xij(a) = a.f a] . (c) Show that Matll(F)
is semisimple, and in fact is equal to b EEl n EB In, where b is the space of diagonal
matrices.

CHAPTER XVIII
Representations of Finite
Groups
The theory of group representations occurs in many contexts. First, it is
developed for its own sake: determine all irreducible representations of a given
group. See for instance Curti s-Reiner's Methods ofRepresentation Theory (Wiley-
Interscience, 1981). Itis also used in classifying finite simple groups. But already
in this book we have seen applications of representations to Galois theory and
the determination of the Galois group over the rationals. In addition, there is an
analogous theory for topological groups. Inthis case, the closest analogy is with
compact groups, and the reader will find a self-contained treatment of the compact
case entirely similar to §5 of this chapter in my book SL 2(R) (Springer Verlag),
Chapter 11, §2. Essenti ally, finite sums are replaced by integrals, otherwise the
formalism is the same. The analysis comes only in two places. One of them is
to show that every irreducible representation of a compact group is finite dimen-
sional; the other is Schur's lemma. The detail s of these extra considerations are
carried out completely in the above-mentioned reference. 1 was care ful to write
up §5 with the analogy in mind .
Similarly, readers will find analogous material on induced repre sentations in
SL 2(R), Chapter III, §2 (which is also self-contained).
Examples of the general theory come in various shapes. Theorem 8.4 may
be viewed as an example, showing how a certain repre sentation can be expressed
as a direct sum of induced representations from I-dimensional repre sentations.
Examples of repre sentations of S3 and S4 are given in the exercises. The entire
last section works out completely the simple characters for the group GL2(F)
when F is a finite field, and shows how these characters essentially come from
induced characters.
For other examples also leading into Lie groups, see W. Fulton and J. Harris,
Representation Theory, Springer Verlag 1991.
663
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

664
REPRESENTATIONS OF FINITE GROUPS
§1.
REPRESENTATIONS AND SEMISIMPLICITY
XVIII, §1
Let R be a commutative ring and G a group. We form the group algebra
R[G) . As explained in Chapter II, §3 it consists of all formal linear comb inations
with coefficients au E R, almost all of which are O. The product is taken in the
natural way ,
Let E be an R-module. Every algebra-homomorphism
R[G) ~ EndR(E)
induces a group-homomorphism
G ~ AutR(E) ,
and thus a representation of the ring R[G) in E gives rise to a representation of
the group. Given such representations, we also say that R[GJ, or G, operate on
E. We note that the representation makes E into a module over the ring R[G) .
Conversely, given a representation of the group, say p : G ~ AutR(E) , we
can extend p to a representation of R[G) as follows . Let Q' = 2: auO" and x E E.
We define
p(a)x = L a"p«(J)x.
It is immediately verified that p has been extended to a ring-homomorphism of
R[G] into EndR(E). We say that p is faithful on G if the map p : G ~ AutR(E)
is injective. The extension of p to R[G) may not be faithful, however.
Given a representation of G on E, we often write simply ox instead of p(CT)X,
whenever we deal with a fixed repre sentation throughout a discussion.
An R-module E, together with a representation p, will be called a G-module,
or G-space, or also a (G, R)-module if we wish to specify the ring R. If E, F
are G-modules, we recall that a G-homomorphismf: E ~ F is an R-linear map
such thatf(ox) = CTf(x) for all x E E and CT E G.
Given a G-homomorphism f : E ~ F, we note that the kernel of f is a G-
submodule of E, and that the R-factor module F/f(E) admits an operation of G
in a unique way such that the canonical map F ~ F/f(E) is a G-homomorphism.
By a trivial representation p : G~ AutR(E) , we shall mean the representation
such that p(G) =
1. A representation is trivial if and only if ox = x for all
x E E. We also say in that case that G operates trivially.

XVIII, §1
REPRESENTATIONS AND SEMISIMPLICITY
665
We make R into a G-module by making G act trivially on R.
We shall now discuss systematically the representations which arise from a
given one , on Hom, the dual , and the tensor product. This pattern will be repeated
later when we deal with induced representations.
First, HomR(E, F) is a G-module under the action defined forfE HomR(E, F)
by
([alf)(x) = a"!(a-1x).
The conditions for an operation are trivially verified. Note the a -I inside the
expression. We shall usually omit parentheses, and write simply [a]f(x) for the
left-hand side. We note that f is a G-homomorphism if and only if [a]f = f for
all a E G.
We are particularly concerned when F = R (so with trivial action), in which
case HomR(E, R) = E V is the dual module. In the terminology of representations,
if p: G ~ AutR(E) is a representation of G on E, then the action we have just
described gives a representation denoted by
and called the dual representation (also called contragredient (ugh!) in the
literature).
Suppose now that the modules E, F are free and finite dimensional over R.
Let p be representation of G on E. Let M be the matrix of p(a) with respect to
a basis, and let MV be the matrix of pV(a) with respect to the dual basis . Then
it is immediately verified that
(I)
Next we consider the tensor product instead of Hom . Let E, E' be (G, R)-
modules. We can form their tensor product E (9 E', always taken over R. Then
there is a unique action of G on E @ E' such that for a E G we have
a(x @ x') = ax @ ax'.
Suppose that E, F are finite free over R. Then the R-isomorphism
(2)
of Chapter XVI, Corollary 5.5, is immediately verified to be a G-isomorphism.
Whether E is free or not, we define the G-invariant submodule of E to be
invG(E) = R-submodule of elements x E E such that ax = x for all a E G. If
E, F are free then we have an R-isomorphism
(3)
invG(EV (9 F) "'" HomG(E, F) .

666
REPRESENTATIONS OF FINITE GROUPS
XVIII, §1
If p: G ~ AutR(E) and p' : G ~ AutR(E') are representations of G on E
and E' respectively, then we define their sum p EB p' to be the representation
on the direct sum E EB E', with a E G acting componentwise. Observe that G-iso-
morph ism classes of representations have an additive monoid structure under
this direct sum, and also have an associative multiplicative structure under the
tensor product. With the notation of representations, we denote this product by
p 0
p'. This product is distributive with respect to the addition (direct sum) .
If G is a finite group , and E is a G-module, then we can define the trace
Trc : E ~ E which is an R-homomorphism, namely
We observe that Trc(x) lies in invc(E), i.e. is fixed under the operation of
all elements of G. This is because
r TrG(x) = L rex,
<1 EG
and multiplying by r on the left permutes the elements of G.
In particular, if f: E ~ F is an R-homomorphism of G-modules, then
Trc(f) : E ~ F is a G-homomorphism.
Proposition 1.1.
Let G be a finite group and let E', E, F, F be G-modules.
Let
be R-homomorphisms, and assume that 'P, t/J are G-homomorphisms . Then
Proof
We have
TrG(t/J 0 f
0 cp) = L a(t/J 0 f
0 cp) = L (at/J)
0 (af)
0 (acp)
<1EG
<1EG
Theorem 1.2.
(Maschke).
Let G be afinite group oforder n, and let k be a
field whose characteristic does not divide n. Then the group ring kEG] is
semisimple.
Proof
Let E be a G-module, and F a G-submodule. Since k is a field,
there exists a k-subspace F such that E is the k-direct sum of F and F. We let
the k-linear map rr: E ~ F be the projection on F. Then n(x) = X for all X E F.

XVIII, §2
Let
CHARACTERS
667
We have then two G-ho momorphisms
O-+F-kE
tp
such that j is the inclusio n, and qJ 0 j = id. It follows that E is the G-direct sum
of F and Ker rp, there by proving that kEG] is semisimple.
Except in §7 we denote by G a finite group, and we denote E, F finite
dimensional k-spaces, where k is a field of characteristic not dividing
# (G). We usually denote # (G) by n ,
§2.
CHARACTERS
Let p :kEG] -+ Endk(E) be a represent at ion. By the character Xp of the
representation, we shall mean the k-valued function
Xp : kEG] -+ k
such that xia) = tr p(a) for all a E kEG]. The trace here is the trace of an endo-
morphism, as defined in Cha pter XIII, §3. If we select a basis for E over k, it is
the trace of the matrix representing p(a), i.e., the sum of the diagonal elements.
We have seen previously that the trace does not depend on the choice ofthe basis.
We sometimes write XEinstead of Xp '
We also call E the representation space of p,
By the trivial character we shall mean the character of the representat ion of
G on the k-space equal to k itself,such that ax = x for all x E k. It is the function
taking the value 1 on all elements of G. We denote it by Xo or also by IGif we
need to specify the dependence on G.
We observe that characters are functions on G, and that the values of a
character on elements of kEG] are determined by its values on G (the extension
from G to kEG] being by k-linearity).
We say that two represent ations p, qJ of G on spaces E, F are isomorphic if
there is a G-isomorphism betwee n E and F . We then see that if p, qJ are iso-
morphic represent ations, then their characters are equal. (Put in another way,
if E, Fare G-spaces and are G-isomorphic, then XE = XF') In everything that
follows, we are interested only in isomorphism classes of represent ations.

668
REPRESENTATIONS OF FINITE GROUPS
XVIII, §2
If E, Fare G-spaces, then their direct sum E EF> F is also a G-space, the opera-
tion of G being componentwise. If x EF> y E E EF> F with x E E and y E F, then
a(x EF> y) = ax EF> ay.
Similarly, the tensor product E ®k F = E ® F is a G-space, the operation
of G being given by a(x ® y) = ax ® ay.
Proposition 2.1.
If E, Fare G-spaces, then
XE + XF = XE <ifJF
and
XE XF = XEI$9F'
If XV denotes the character of the dual representation on EV , then
XV(O') = X(O'-l)
X(O') if k = C.
Proof
The first relation holds because the matrix of an element a in the
representation E EF> F decomposes into blocks corresponding to the representa-
tion in E and the representation in F. As to the second, if {V i} is a basis of E and
{Wj} is a basis of F over k, then we know that {V i ® Wj} is a basis of E ® F. Let
(aiv) be the matrix of a with respect to our basis of E, and (bjJl) its matrix with
respect to our basis of F. Then
a(Vi ® Wj) = au, ® aWj = Laivvv ® LbjJlWJl
v
Jl
= L aivbjJlVv ® WJl'
v, u
By definition, we find
XEI$9F(a) = LL aiibjj = xECa)XF(a),
i
j
thereby proving the statement about tensor products . The statement for the char-
acter of the dual representation follows from the formula for the matrix fM-\
given in §1. The value given as the complex conjugate in case k = C will be
proved later in Corollary 3.2.
So far, we have defined the notion of character associated with a representa-
tion. It is now natural to form linear combinations of such characters with more
general coefficients than positive integers. Thus by a character of G we shall
mean a function on G which can be written as a linear combination of characters
of representations with arbitrary integer coefficients. The characters associated
with representations will be called effective characters. Everything we have
defined of course depends on the fieldk, and we shall add over k to our expressions
if we need to specify the field k.

XVIII, §2
CHARACTERS
669
We observe that the characters form a ring in view of Proposition 2.1 . For
most of our work we do not need the multiplicative structure, only the additive
one.
By a simple or irreducible character of G one means the character of a
simple representation (i.e., the character associated with a simple k[G]-module) .
Taking into account Theorem 1.2, and the results of the preceding chapter
concerning the structure of simple and semisimple modules over a semisimple
ring (Chapter XVII, §4) we obtain:
Theorem 2.2.
There are only a finite number ofsimple characters ofG (over
k). The characters of representations of G are the linear combinations of the
simple characters with integer coefficients ~ O.
We shall use the direct product decomposition of a semisimple ring. We
have
s
keG] = fI n,
i= I
where each R, is simple, and we have a corresponding decomposition of the unit
element of k[G] :
where e, is the unit element of Ri , and e,e, = 0 if i =1= j . Also, R;Rj = 0 if i =1= j .
We note that s = s(k) depends on k.
If L, denotes a typical simple module for R, (say one of the simple left ideals),
we let Xi be the character of the representation on Li.
We observe that X;(C() = Ofor all C( E R j ifi =1= j. This is afundamental relation
of orthogonality, which is obvious, but from which all our other relations will
follow.
Theorem 2.3.
Assume that k has characteristic O. Then every effective char-
acter has a unique expression as a linear combination
s
X= LniX;,
i= I
where XI' . . . , Xs are the simple characters ofGover k. Two representations are
isomorphic if and only if their associated characters are equal.

670
REPRESENTATIONS OF FINITE GROUPS
XVIII, §2
Proof
Let E be the representation space of X. Then by Theorem 4.4 of
Chapter XVII,
s
E ~ EEl «t.;
i ; 1
The sum is finite because we assume throughout that E is finite dimensional.
Since e, acts as a unit element on Lj, we find
We have already seen that Xi(e) = 0 if i
=1= j. Hence
Since dim, L; depends only on the structure of the group algebra, we have
recovered the mult iplicities nl> . .. , ns • Namely, n, is the number of times that
L, occurs (up to an isomorphism) in the representation space of X, and is the
value of x(eJ divided by dim, L, (we are in characteristic 0). This proves our
theorem.
As a matter of definition, in Theorem 2.3 we call ni the multiplicity of Xi in X.
In both corollaries, we continue to assume that k has characteristic O.
Corollary 2.4.
Asfun ctions ofG into k, the simple characters
are linearly independent over k.
Proof
Suppose that L aiXi = 0 with a; E k. We apply this expression to ej
and get
Hence aj = 0 for all j.
In characteristic 0 we define the dimension of an effective character to be
the dimension of the associated representation space .
Corollary 2.5.
Thefunction dim is a homomorphism ofthe monoid of effective
characters into Z.

XVIII, §3
1-DIMENSIONAL REPRESENTATIONS
671
Example.
Let G be a cyclic group of order equal to a prime number p.
We form the group algebra Q[G]. Let (J be a generator of G. Let
I + (J + (J2 + .., + (JP- I
e l = - ----
-
-
-
-
-
p
Then reI = eI for an y rEG and consequently ef = eI' It then follows that
e~ = e2 and ele2 = O. The field Qe 1 is isomorphic to Q. Let w = (Je2' Then
wP = e2' Let Q 2 = Q e2' Since w =1= e2' and satisfies the irreducible equation
X p - 1 + ... + I = 0
over Q2 ' it follows that Qiw) is isomorphic to the field obtained by adjoining
a primitive p-th root of unity to the rationals. Consequently, Q[G] admits the
direct product decomposition
Q[G] ~ Q x Q(()
where ( is a primitive p-th root of unity.
As another example, let G be any finite group, and let
I
e l = - L (J.
n ITE G
Then for any r E G we ha ve reI = e" and ef = el' If we let e'l = 1 - e, then
e'? = e'I' and e'lel = ele'l = O. Thus for any field k (whose characteristic does
not divide the order of G according to conventions in force), we see that
keG] = ke, x k[G]e'l
is a direct product decomposition. In particular, the representation of G on the
group algebra keG] itself contains a l-dirnensional representation on the
component kel , whose character is the tri vial character.
§3.
1-DIMENSIONAL REPRESENTATIONS
By abuse oflanguage, even in characteristic p > 0, we say that a character is
I-dimensional if it is a homomorphism G -> k*.
Assume that E is a I-dimensional vector space over k. Let
p : G -> Autk(E)
be a representation. Let {v} be a basis of E over k. Then for each (JE G, we have
(JV = Z((J)v

672
REPRESENTATIONS OF FINITE GROUPS
XVIII, §3
for some element x(a) E k, and x(a) =t- 0 since a induces an automorphism of E.
Then for rEG,
rav = x(a)rv = x(a)x(r)v = x(ar)v.
We see that X: G -. k* is a homomorphism, and that our I-dimensional char-
acter is the same type of thing that occurred in Artin's theorem in Galois theory.
Conversely, let X: G -. k* be a homomorphism. Let E be a f-dimensional
k-space, with basis {v}, and define a(av) = ax(a)v for all a E k. Then we see at
once that this operation of G on E gives a representation of G, whose associated
character is X.
Since G is finite, we note that
Hence the values of l-dimensional characters are n-th roots of unity.
The
l-dimensional characters form a group under multiplication, and when G is a
finite abelian group, we have determined its group of l-dimensional characters
in Chapter I, §9.
Theorem 3.1.
Let G be a finite abelian group, and assume that k is alge-
braicallyclosed. Then every simple representation ofG is s-dimensional. The
simplecharacters ofG are the homomorphisms ofG into k*.
Proof.
The group ring k[G] is semisimple, commutative, and is a direct
product of simple rings. Each simple ring is a ring of matrices over k (by Corollary
3.6 Chapter XVII), and can be commutative if and only if it is equal to k.
For every l-dimensional character X of G we have
If k is the field of complex numbers, then
Corollary 3.2.
Let k be algebraically closed. Let G be a finite group. For
any characterXanda E G,the valuex(a) is equalto a sumofrootsofunity with
integer coefficients (i.e. coefficients in Z or Z/pZ depending on the char-
acteristic ofk).
Proof
Let H be the subgroup generated by a. Then H is a cyclic subgroup.
A representation of G having character Xcan be viewed as a representation for
H by restriction, having the same character. Thus our assertion follows from
Theorem 3.1.

XVIII, ~4
THE SPACE OF CLASS FUNCTIONS
673
§4.
THE SPACE OF CLASS FUNCTIONS
By a class function of G (over k, or with values in k), we shall mean a function
f : G -
k such that f( lTTlT- 1) = f( T) for all IT,
T E G. It is clear that characters
are class functions, because for square matrices M, M' we have
tr(MM'M- 1) = tr(M').
Thus a class function may be viewed as a function on conjugacy classes.
We shall always extend the domain of definition of a class function to the
group ring, by linearity. If
and f is a class function, we define
f(a) = La,J(a).
UEG
Let a0 E G. If a E G, we write a ""' a0 if a is conjugate to a0 ' that is, if there
exists an element r such that ao = rar- I . An element of the group ring of type
y = L a
(1-°0
will also be called a conjugacy class.
Proposition 4.1.
An element of k[G] commutes with every element of G if
and only if it is a linear combination ofconjugacy classes with coefficients in k.
Proof
Let a = L aua and assume ar = ra for all rEG. Then
UEG
L aurar- 1 = L aua.
UEG
UEG
Hence auo = au whenever a is conjugate to a0 , and this means that we can write
where the sum is taken over all conjugacy classes y.
Remark.
We note that the conjugacy classes in fact form a basis of the
center of Z[G] over Z, and thus playa universal role in the theory of rep-
resentations.
We observe that the conjugacy classes are linearly independent over k,
and form a basis for the center of keG] over k.

674
REPRESENTATIONS OF FINITE GROUPS
Assumefor the rest of this section that k is algebraically closed. Then
s
keG] = Il e,
i = I
XVIII, §4
is a direct product of simple rings, and each R, is a matrix algebra over k. In a
direct product, the center is obviously the product of the centers of each factor .
Let us denote by k, the image of k in Rj, in other words,
k, = ke.,
where e, is the unit element of R: Then the center of keG] is also equal to
sIl kj
i = I
which is s-dimensional over k.
If L, is a typical simple left ideal of Rj, then
We let
Then
s
d; = dim, R,
and
L d; = n.
i= 1
We also have the direct sum decomposition
as a (G, k)-space.
The above notation will remain fixed from now on.
We can summarize some of our results as follows .
Proposition 4.2.
Let k bealgebraically closed. Then the numberofconjugacy
classesofG is equalto the numberofsimplecharacters ofG,both ofthesebeing
equal to the number s above. The conjugacy classes Yl, . .. , Ys and the unit
elements eI' . .. , e, form basesof the center of k[G].
The number of elements in Yjwill be denoted by h., The number of elements
in a conjugacy class Y will be denoted by hy. We call it the class number. The
center of the group algebra will be denoted by Zk(G).

XVIII, §4
THE SPACE OF CLASS FUNCTIONS
675
We can view keG] as a G-module. Its character will be called the regular
character, and will be denoted by Xreg or r G if we need to specify the dependence
on G. The representation on keG] is called theregular representation. From our
direct sum decomposition of keG] we get
s
Xreg = L diXi '
i=1
We shall determine the values of the regular character.
Proposition 4.3.
Let Xreg be the regular character. Then
Xreg(O-) = 0 if
a E G, a i= 1
xreil) = n.
Proof.
Let 1 = ai' . . . , an be the elements of G. They form a basis of k[ G]
over k. The matrix of 1 is the unit n x n matrix. Thus our second assertion
follows. If a i= 1, then multiplication by a permutes ai ' . . . , an' and it is im-
mediately clear that all diagonal elements in the matrix representing a are O.
This proves what we wanted.
We observe that we have two natural bases for the center Zk(G) of the
group ring. First, the conjugacy classes of elements of G. Second, the elements
e 1, • • • , es (i.e. the unit clements of the rings RJ We wish to find the relation
between these, in other words, we wish to find the coefficients of e, when ex-
pressed in terms of the group elements. The next proposition does this. The
values of these coefficients will be interpreted in the next section as scalar
products. This will clarify their mysterious appearance.
Proposition 4.4.
Assume again that k is algebraically closed. Let
Then
e, = L ar "
reG
arE k.
Proof.
We have for all, E G:
Xreg(ei,-I) = Xreg( Laua,-I) = LauXreia,-I).
ueG
u eG

676
REPRESENTATIONS OF FINITE GROUPS
By Proposition 4.3, we find
On the oth er hand ,
Xreg(ejr - I ) = L d/I..j(ejr - I) = diXj(ejr - l ) = djxir-I ).
j= I
Hence
for all r E G. This proves our proposition .
XVIII, §4
Corollary 4.5.
Each e, can be expressed in terms of group elements with
coefficients which lie in the field generated over the primefield by m-th roots
ofunity, if m is an exponent for G.
Corollary 4.6.
The dimensionsd, are not divisible by the characteristic ofk.
Proof
Otherwise, ej = 0, which is impossible.
Corollary 4.7.
The simple characters XI' .. . , Xs are linearly independent
over k.
Proof
The proof in Corollary 2.4 applies, since we now kno w that the
characteristic does not divide d..
Corollary 4.8.
Assume in addition that k has characteristic 0. Then d,In
for each i.
Proof.
Multiplying our expression for e, by nidi> and also by e., we find
Let ( be a primitive m-th root of unity, and let M be the module over Z gen-
erated by the finite number of elements (Vaej (v = 0, . .. , m -
1 and a E G).
Then from the preceding relation, we see at once that multiplication by nld,
maps M into itself. By definition, we conclude that nidi is integral over Z,
and hence lies in Z, as desired.
Theorem 4.9.
Let k be algebraically closed.
Let Zk(G) be the center of
k[G], and let X k(G) be the k-space of classfunctions on G. Then Zk(G) and
X k(G) are the dual spaces of each other, under the pairing
(f, a) f-+f(a).

XVIII.
~ 5
ORTHOGONALITY RELATIONS
677
The simple characters and the unit elements el' . . . , esform orthogonal bases
to eachother. We have
;(j(e;) = JiA .
Proof.
The formula has been proved in the proof of Theorem 2.3. The
two spaces involved here both have, dimension s, and d, i= 0 in k. Our prop-
osition is then clear.
§5.
ORTHOGONALITY RELATIONS
Throughout this section, we assume that k is algebraically closed.
If R is a subring of k, we denote by X R(G) the R-module generated over R
by the characters of G. It is therefore the module of functions which are linear
combinations of simple characters with coefficients in R. If R is the prime ring
(i.e. the integers Z or the integers mod p ifk has characteristic p), then we denote
XR(G) by X(G).
We shall now define a bilinear map on X(G) x X(G). Iff, g E X(G), we
define
1
<f, g) = - L f«(J)g«(J-I).
n Ge G
Theorem 5.1.
The symbol <f, g) for f, g E X(G) takes on values in the prime
ring. The simple charactersform anorthonormal basisfor X(G), in otherwords
<Xi> Xi) = Jij'
For each ring R c k, the symbol hasa uniqueextension to an R-bilinearform
XR(G) x XR(G) -+ R, givenby the sameformula as above.
Proof
By Proposition 4.4, we find
d, '\'
_I
x/eJ = -
L. xl(J
)X/a).
n GeG
If i i= j we get 0 on the left-hand side, so that Xi and Xi are orthogonal. If i = j
we get d, on the left-hand side, and we know that d, i= 0 in k, by Corollary 4.6.
Hence <Xi' X;) = 1. Since every element of X(G) is a linear combination of
simple characters with integer coefficients, it follows that the values of our
bilinear map are in the prime ring. The extension statement is obvious, thereby
proving our theorem.

678
REPRESENTATIONS OF FINITE GROUPS
XVIII, §5
Assume that k has characteristic O. Let m be an exponent for G, and let R
contain the m-th roots of unity. If R has an automorphism of order 2 such that
its effect on a root of unity is , H ,- I, then we shall call such an automorphism
a conjugation, and denote it by aHa.
Theorem 5.2.
Let k havecharacteristic 0, and let R be a subring containing
the m-th roots of unity, and having a conjugation. Then the bilinear form on
X(G) has a unique extension to a hermitian form
given by theformula
I,
-
<f, g) = -
L. f(a)g(a).
n "EG
The simple characters constitutean orthonormal basis of X R(G) with respect
to thisform.
Proof
The formula given in the statement of the theorem gives the same
value as before for the symbol <f, g) whenf, g lie in X(G). Thus the extension
exists, and is obviously unique.
We return to the case when k has arbitrary characteristic.
Let Z(G) denote the additive group generated by the conjugacy classes
Yb ' .. ,Ysover the prime ring. It is of dimension s. We shall define a bilinear map
on Z(G) x Z(G). If Ct. = La"a has coefficients in the prime ring, we denote by
«: the element L a"a- I.
Proposition 5.3.
For Ct., 13 E Z(G), wecandefine a symbol<Ct., 13> by eitherone
ofthefollowing expressions, which are equal:
The values ofthe symbollie in the prime ring.
Proof
Each expression is linear in its first and second variable.
Hence
to prove their equality, it will suffice to prove that the two expressions are equal
when we replace
Ct. by e, and 13 by an element r of G. But then, our equality is
equivalent to
s
Xreg(ei r - I ) = L Xv(ei)Xv(r- I ) .
v= I
Since Xv(ei) = 0 unless v = i, we see that the right-hand side of this last relation
is equal to diXi(r- I ) . Our two expressions are equal in view of Proposition 4.4.

XVIII, §5
ORTHOGONALITY RELATIONS
679
The fact that the values lie in the prime ring follows from Proposition 4.3: The
values of the regular character on group elements are equal to 0 or n, and hence
in characteristic 0, are integers divisible by n.
As with X R(G), we use the notation ZR(G) to denote the R-module generated
by rl'...,rsover an arbitrary subring R of k.
Lemma 5.4.
For each ring R contained in k, the pairing oj Proposition 5.3
has a unique extension to a map
which is R-linear in its first variable. IJ R contains the m-th roots oj unity,
where m is an exponent[or G, and also contains lin, then e, E ZR(G)Jorall i.
The class number hi is not divisible by the characteristic ojk, and we have
s
I
e, = L <ei, rv> -h rv'
v = l
v
Proof
We note that hi is not divisible by the characteristic because it is
the index of a subgroup of G (the isotropy group of an element in ri when G
operates by conjugation), and hence hi divides n. The extension of our pairing
as stated is obvious, since 1'1 ' . .. , 1's form a basis of Z(G) over the prime ring .
The expression of e, in terms of this basis is only a reinterpretation of Proposition
4.4 in terms of the present pairing .
Let E be a free module over a subring R of k, and assume that we have a
bilinear symmetric (or hermitian) form on E. Let {VI " ' " vs} be an orthogonal
basis for this module. If
with a, E R, then we call ai' .. . , as the Fourier coefficients of v with respect to
our basis. In terms of the form, these coefficients are given by
provided <Vi' v) :f. O.
We shall see in the next theorem that the expression for ei in terms of
rl'...,rs is a Fourier expansion.
Theorem 5.5.
The conjugacy classes rl' ..., rs constitute an orthogonal
basis for Z(G). We have<ri ' r) = hi' For each ring R contained in k, the
bilinear mapoj Proposition 5.3 has a unique extension to a R-bilinear map

680
REPRESENTATIONS OF FINITE GROUPS
XVIII, §5
Proof
We use the lemma. By linearity, the formula in the lemma remains
valid when we replace R by k, and when we replace e, byanyelementof Z k(G), in
particular when we replace e, by Yi ' But {YI" '" Ys} is a basis of Z k(G), over k.
Hence we find that <Yi' Yi) = hi and <Yi' Yj) = °if i i=j, as was to shown.
Corollary 5.6.
If G is commutative, then
I
n
_ 1 {o if
(J is not equal to r
~JIXv((J)Xv(r
) =
I
if
(J is equal to r,
Proof
When G is commutative, each conjugacy class has exactly one ele-
ment, and the number of simple characters is equal to the order of the group.
Weconsider the case ofcharacteristic°for our Z(G) just as wedid for X(G).
Let k have characteristic 0, and R be a subring of k containing the m-th roots of
unity, and having a conjugation. Let oc = L a,,(J with a" E R. We define
ae G
-
,, -
-I
oc =
~ a,,(J
.
"eG
Theorem 5.7.
Let k have characteristic 0, and let R be a subring of k, con-
taining the m-th roots ofunity, and havinga conjugation. Then the pairing of
Proposition 5.3 has a unique extension to a hermitian form
given by theformulas
I
I
s
_
_
<oc, f3 ) = - X,eg(ocfJ) = - L Xv(oc)Xv(f3)·
n
n v = 1
The conjugacy classes YI' .. . , Ys form an orthogonal basis for ZR(G). If R
contains lin, then e" ... ,es lie in ZR(G) andalsoform an orthogonal basisfor
ZR(G). We have <ei' e) = df/n.
Proof
The formula given in the statement of the theorem gives the same
value as the symbol <oc, f3) of Proposition 5.3 when oc, f3 lie in Z(G). Thus the
extension exists,and is obviously unique. Using the second formula in Propo-
sition 5.3,defining the scalar product, and recalling that Xv(ei) = °if v i= i, we
see that
whence our assertion follows.

XVIII, §5
ORTHOGONALITY RELATIONS
681
We observe that the Fourier coefficients of e, relat ive to the basis YI" ' " Y,
are the same with respect to the bilinear form of Theorem 5.5, or the hermitian
form of Theorem 5.7. Th is comes from the fact that Yl' .. . , Ys lie in Z(G), and
form a basis of Z(G) over the prime ring.
We shall now reprove and generalize the orthogonality relations by another
method. Let E be a finite dimensional (G, k)-space, so we have a representation
After selecting a basis of E, we get a representation of G by d x d matrices. If
{V I' . .. , Vd} is the basis, then we have the dual basis {A.I , . .. , Ad} such that
Ai(V) = Jij . If an element (J of G is represented by a matrix (Pij{(J» , then each
coefficient Pij{(J) is a function of (J, called theij-coefficient function. We can also
write
But instead of indexing elements of a basis or the dual basis, we may just as
well work with any functional Aon E, and any vector v. Then we get a function
(J f.....d«(J v) = P;,.v<(J),
which will also be called a coefficient function. In fact, one can always complete
V = VI to a basis such that A= AI is the first element in the dual basis, but using
the notation P;,.v is in many respects more elegant.
We shall constantly use:
Schur's Lemma.
Let E, F be simple (G, k)-spaces, and let
cp :E-+F
be a homomorphism. Then either cp = 0 or cp is an isomorphism.
Proof
Indeed, the kernel of cp and the image of cp are subspaces, so the
assertion is obvious.
We use the same formul a as before to define a scalar product on the space of
all k-valued functions on G, namely
1
<f, g>= - Lf «(J)g((J - 1).
n u E G
We shall derive various orthogonality relations among coefficient functions.
Theorem 5.8.
Let E, F be simple(G, k)-spaces. Let Abe a k-linearfunctional
on E, let x E E andY E F. If E, F are not isomorphic, then
L A«(JX)(J - I y = O.
UEG

682
REPRESENTATIONS OF FINITE GROUPS
XVIII, §5
IJfl is aJunctional on F then the coefficientJunctions P;., x and PIl •yare ortho-
gonal, that is
L ,1.(ax )fl(a- 1y) = 0.
<JEG
Proof
The map x 1---+ L,1.(ax)a - 1y is a G-homomorphism of E into F, so
Schur's lemma concludes the proof of the first statement. The second comes by
applying the functional u.
As a corollary, we see that if X, «/1 are distinct irreducible characters of G
over k, then
(X, «/1) = 0,
that is the characters are orthogonal. Indeed, the character associated with a
representation P is the sum of the diagonal coefficient functions,
d
X = LPii,
i= 1
where d is the dimension of the representation. Two distinct characters cor-
respond to non-isomorphic representations, so we can apply Proposition 5.8.
Lemma 5.9.
Let E be a simple (G, k)-space. Then any G-endomorphism oj
E is equal to a scalarmultiple ojthe identity.
Proof
The algebra EndG.k(E) is a division algebra by Schur's lemma,
and is finite dimensional over k. Since k is assumed algebraically closed , it must
be equal to k because any element generates a commutative subfield over k.
This proves the lemma.
Lemma 5.10.
Let E be a representation spacefor G ofdimension d. Let X
be aJunctional on E, and let x E E. Let ({J;.. x E Endk(E) be the endomorphism
such that
Then tr(cp;.,x) = ,1.(x).
Proof
If x =°the statement is obvious. Let x # 0. If ,1.(x) # °we pick
a basis of E consisting of x and a basis of the kernel of,1.. If ,1.(x) = 0, we pick a
basis of E consisting of a basis for the kernel of ,1., and one other element. In
either case it is immediate from the corresponding matrix representing ({J;.,x that
the trace is given by the formul a as stated in the lemma.
Theorem 5.11.
Let p: G -> Autk(E) be a simple representation of G, of
dimension d. Then thecharacteristic ofk doesnotdivided. Let x, y E E. Then
for anyfunctionals ,1., fl on E,

XVIII, §5
Proof
It suffices to prove that
ORTHOGONALITY RELATIONS
683
n
I
A(ax)a- 1Y = dA(y)X.
I1EG
For fixed y the map
is immediately verified to be a G-endomorphism of E, so is equal to cl for some
c E k by Lemma 5.9. In fact, it is equal to
I p(a-I) 0 qJ)" y 0 p(a).
I1EG
The trace of this expression isequal to n . tr( qJ)" y)by Lemma 5.10,and also to de.
Taking A, y such that A(Y) = 1 shows that the characteristic does not divide d,
and then we can solve for c as stated in the theorem.
Corollary 5.12.
Let X be the character oj the representation oj G on the
simple space E. Then
<X, X) = 1.
Proof
This follows immediately from the theorem, and the expression of
Xas
X = P11 + ... + Pdd'
We have now recovered the fact that the characters of simple representations
are orthonormal. We may then recover the idempotents in the group ring, that
is, if Xl' . . . , Xs are the simple characters, we may now define
Then the orthonormality of the characters yields the formulas :
s
Corollary 5.13.
Xi(e) = (jijdi and Xreg = I diXi'
i = 1
Proof
The first formula is a direct application of the orthonormality of the
characters. The second formula concerning the regular character is obtained
by writing
Xreg = I mjXj
j

684
REPRESENTATIONS OF FINITE GROUPS
XVIII, §5
with unknown coefficients. We know the values Xreg(1) = nand Xreg(a) = 0 if
a
=1= 1. Taking the scalar product of Xreg with Xi for i = 1, . .. , s immediately
yields the desired values for the coefficients mj '
Since a character is a class function, one sees directly that each e, is a linear
combination of conjugacy classes, and so is in the center of the group ring k[ G].
Now let E, be a representation space of Xi' and let Pi be the representation
of G or kEG] on Ei • For a E kEG] we let pi(a):Ei -+ E, be the map such that
pi(a)x = ax for all x E Ei.
Proposition 5.14.
We have
Proof
The map x t--t e.x is a G-homomorphism of E, into itself since e, is in
the center of kEG].
Hence by Lemma 5.9 this homomorphism is a scalar
multiple of the identity. Taking the trace and using the orthogonality relations
between simple characters immediately gives the desired value of this scalar.
We now find that
s
Iei = 1
i= 1
because the group ring kEG] is a direct sum of simple spaces, possibly with
multiplicities, and operates faithfully on itself.
The orthonormality relations also allow us to expand a function in a Fourier
expression, relative to the characters if it is a class function, and relative to the
coefficient functions in general. We state this in two theorems.
Theorem 5.15.
Letfbe a classfunction on G. Then
s
f = L <J. X;)Xi'
i= 1
Proof
The number of conjugacy class is equal to the number of distinct
characters, and these are linearly independent, so they form a basis for the class
functions. The coefficientsare given by the stated formula, as one sees by taking
the scalar product offwith any character Xj and using the orthonormality.
Theorem 5.16.
Let p(i) be a matrix representation of G on E, relative to a
choice ofbasis, andlet p~i!/l bethecoefficientfunctionsofthismatrix,i = 1,. .. ,s
and v,Jl = 1, ... , d.. Then thefunctions p~i!Jorm an orthogonal basisfor the
spaceofallfunctions on G, and hencefor any[unction]on G we have
~ "
1
(i)
(i)
f = L,
L, d <f, PV,/l )Pv,Jl'
i= 1 V.J.l
i

XVIII, §5
ORTHOGONALITY RELATIONS
685
Proof
That the coefficient functions form an orthogonal basis follows from
Theorems 5.8 and 5.11. The expression off in terms of this basis is then merely
the standard Fourier expansion relative to any scalar product. This concludes
the proof.
Suppose now for concreteness that k = C is the complex numbers. Recall
that an effective character X is an element of X(G) , such that if
s
X = LmiXi
i=1
is a linear combination of the simple characters with integral coefficients, then
we have mi ~ 0 for all i. In light of the orthonormality of the simple characters,
we get for all elements X E X(G) the relations
s
IIxf = (X, X) = L mr
and
mi = (X, X;)·
i=l
Hence we get (a) of the next theorem.
Theorem 5.17.
(a) Let X be an effective character in X(G). Then X is simple
over C if and only if IIxI12 = I, or alternatively,
L IX(CT) 12 = #(G) .
rTEe
(b) Let X, t/J be effective characters in X(G), and let E, F be their representation
spaces over C. Then
(X, t/J)e = dim Home(E, F).
Proof.
The first part has been proved, and for (b) , let t/J = 2: qiXi' Then by
orthonormality, we get
But if E, is the representation space of Xi over C, then by Schur's lemma
dim Home(E i , Ei ) = 1 and dim Home(Ei , Ej ) = 0 for i * j .
Hence dim Home(E, F) = 2: m.q., thus proving (b).
Corollary 5.18
With the above notation and k = Cfor simplicity, we have:
(a) The multiplicity of Ie in E V Q9 F is dim, inve(Ev Q9 F).
(b) The (G, k)-space E is simple if and only if Ie has multiplicity I in E V Q9 E.
Proof
Immediate from Theorem 5.17 and formula (3) of §I.
Remark.
The criterion of Theorem 5.17(a) is useful in testing whether a
representation is simple. In practice, representations are obtained by inducing
from l-dirnensional characters, and such induced representations do have a ten-
dency to be irreducible. We shall see a concrete case in §12.

686
REPRESENTATIONS OF FINITE GROUPS
§6.
INDUCED CHARACTERS
XVIII, §6
The notation is the same as in the preceding section. However, wedon 't need
all the results proved there; all we need is the bilinear pairing on X(G), and its
extension to
The symbol <, ) may be interpreted either as the bilinear extension, or the
hermitian extension according to Theorem 5.2.
Let S be a subgroup of G. We have an R-linear map called the restriction
which to each class function on G associates its restriction to S. It is a ring-
homomorphism. We sometimes letfs denote the restriction of f to S.
We shall define a map in the opposite direction,
indr : XR(S) ~ XR(G),
which we call the induction map. If 9 E XR(S), we extend 9 to gs on G by
letting gs(fJ) = 0 if a ¢. S. Then we define the induced function
G
_
. dG( )(
) _
I
""
-I
9 (rr) -
10 S 9
a
-
(S : l) L.J gS<rfJ'T
).
'rEG
Then indy(g) is a class function on G. It is clear that indy is R-linear.
Since we deal with two groups Sand G, we shall denote the scalar product
by <, ) s and <, ) Gwhen it is taken with these respective groups. The next
theorem shows among other things that the restriction and transfer are adjoint
to each other with respect to our form.
Theorem 6.1.
Let S be a subgroup ofG. Then thefollowing rules hold:
(i) (Frobenius reciprocity) For f E XR(G) , and 9 E XR(S) we have
(indr(g), f)G = (g, ResrU» s'
(ii) Indr(g)f = indr(gfs)·
(iii) 1fT esc G are subgroups ofG, then
indr
0 indf = indy.
(iv) If a E G and ga is defined by ga(r") = g(r), where r" = fJ-1rfJ, then
indr(g) = indru(ga).
(v) If l/! is an effective character of S then indr(l/!) is effective.

XVIII, §6
INDUCED CHARACTERS
687
Proof.
Let us first prove (ii). We must show that gGf = (gfs)G. We have
(gGf)(r) = (S ~ 1) L gS<(J7(T-l)f(r) = (S ~ 1) L gs«(Tr(T -I)f«(J7(T-I).
•
o e G
•
o e G
The last expression just obtained is equal to (gf s)G, thereby proving (ii) . Let us
sum over r in G. The only non-zero contributions in our double sum will come
from those elements of S which can be expressed in the form (JTa - 1 with a, rEG.
The number of pairs (a, r) such that ata" I is equal to a fixed element of G is
equal to n (because for every AE G, (aA, A-IrA) is another such pair, and the
total number of pairs is n2 ). Hence our expression is equal to
1
(G : 1) (S : 1) A~sg(A)f (A) .
Our first rule then follows from the definitions of the scalar products in G and S
respectively.
Now let 9 = t/J be an effective character of S, and let f = X be a simple
character of G~ From (i) we find that the Fourier coefficients of gG are integers
~ 0 because resq(x) is an effective character of S. Therefore the scalar product
(t/J, resq(x»s
is ~ O. Hence t/JG is an effective character of G, thereby proving (v) .
In order to prove the transiti vity property, it is convenient to use the fol-
lowing notation.
Let {c} denote the set of right cosets of Sin G. For each right coset c, we
select a fixed coset representative denoted by c. Thus if C\l
. . . , c, are these
representatives, then
r
G = Uc = USc = USCi ·
i = I
Lemma 6.2.
Let g be a classfunction on S. Then
r
indf (g ) ( ~ ) = LgS(Ci~Ci-I ) .
i= 1
Proof.
We can split the sum over all a E G in the definition of the induced
function into a double sum
r
L = L L
ae G
l'J ES i=l

688
REPRESENTATIONS OF FINITE GROUPS
XVIII, §7
and observe that each term 95 (TC~C-l (T-l) is equal to 95 (c ~c -l) if (T E S, because
9 is a class function . Hence the sum over (T E S is enough to cancel the factor
lieS : I) in front, to give the expression in the lemma .
If T c: S c: G are subgroups of G, and if
G = USCi
and
S = UTJj
are decompositions into right cosets, then {JA} form a system of representatives
for the right cosets of Tin G. From this the transitivity property (iii) is obvious.
We shall leave (iv) as an exercise (trivial, using the lemma).
§7.
INDUCED REPRESENTATIONS
Let G be a group and S a subgroup of finite index . Let F be an S-module.
We consider the category e whose objects are S-homomorphisms tp : F -
E of
F into a G-module E. (We note that a G-module E can be regarded as an S-
module by restriction.) If cp' :F -
E' is another object in e, we define a morphism
tp' -
cp in e to be a G-homomorphism 1] : E' -
E making the following diagram
commutative:
E'
Y]
F
q
~E
A universal object in e is determined up to a unique G-isomorphism. It will
be denoted by
ind~ : F -
ind~(F) .
We shall prove below that a universal object always exists. If <p : F --> E is a
universal object, we call Ean induced module. It is uniquely determined, up to a
unique G-isomorphism making a diagram commutative. For convenience, we
shall select one induced module such that <p is an inclusion. We shall then call
this particular module ind~(F) the G-module induced by F. Inparticular, given
an S-homomorphism cp: F -
E into a G-module E, there is a unique G-homo-
morphism cp* : ind~(F) -
E making the following diagram commutative:
'ndfG../" ind~(F)
1/]
F
'P. = indf<'P)
~E

XVIII, §7
INDUCED REPRESENTATIONS
689
The association q; ~
i nd~(q;) then induces an isomorphi sm
HomcCind~ (F) , E) = Homs(F , res~ (E)) ,
for an S-module F and a G-module E. We shall see in a moment that ind~ is a
functor from Mod(S) to Mod(G), and the above formula may be described as
sayi ng that induction is the adjoint functor of restriction. One also calls this
relation Frobenius reciprocity for modules , because Theorem 6.1 (i) is a
corollary.
Sometimes, if the reference to F as an S-module is clear, we shall omit the
subscript S, and write simply
for the induced module.
Let f: F' -+ F be an S-homomorphism. If
q; ~ : F' ~ ind~(F')
is a G-module induced by F', then there exists a unique G-homomorphism
ind~ (F' ) ~
ind~(F ) making the following diagram commutative:
It is simply the G-homomorphism corresponding to the universal property
for the S-homomorphism
q;~ 0 f, represented by a dashed line in our diagram.
Thus
ind~ is a functor, from the category of S-modules to the category of G-
modules.
From the universalit y and uniqueness of the induced module, we get some
formal properties :
ind~ commutes with direct sums : If we have an Ssdirect sum F EEl F', then
ind~(F EB F') = ind~(F) EEl ind~(F ') ,
the direct sum on the right being a G-direct sum.
Iff, g: F' -+ Fare S-homomorphisms, then
ind~(f + g) = ind~(f ) + ind~(g ).
1fT e S c G are subgroups ofG, and F is a T-module, then
i nd~
0 indhF) = ind¥( F) .

690
REPRESENTATIONS OF FINITE GROUPS
XVIII, §7
In all three cases, the equality between the left member and the right member
of our equations follows at once by using the uniqueness of the universal object.
We shall leave the verifications to the reader.
To prove the existence of the induced module, we let M~(F) be the additive
group of functions f :G ~ F satisfying
af(~) = f(a~)
for a ES and ~ E G. We define an operation of G on M~(F) by letting
(af)(~) = f(~a)
for a, ~ E G. It is then clear that M~(F) is a G-module.
Proposition 7.1.
Let <p : F ~ M~(F) be such that <p(x) = <Px is the map
() = {O
if
r¢S
<Px r
'f
S
rx
I
r s o.
Then <p is an S-homomorphism, <p : F ~ M~(F) is universal, and <p is injective.
The image of <p consists of those elementsfE M~(F) such that f(r) = °if
r¢S.
Proof.
Let a ES and x EF. Let rEG. Then
If rES, then this last expression is equal to <p"x(r). If r¢S, then to e S, and
hence both <p"x(r) and <px(ra) are equal to O. Thus <p is an S-homomorphism,
and it is immediately clear that <p is injective. Furthermore, iffE M~(F) is such
thatf(r) = 0 ifr¢S, then from the definitions, we conclude thatf= <Px where
x = f(1).
There remains to prove that <p is universal. To do this, we shall analyze more
closely the structure of M~(F) .
r
Proposition 7.2.
Let G = USCi be a decomposition of G into right cosets.
i = 1
Let F 1 be the additivegroupoffunctions in M~(F) having value0 at elements
~ E G, ~ ¢ S. Then
r
M~(F) = EB ci1F1,
i= 1
the direct sumbeing taken as an abelian group.
Proof
For eachj's M~(F), let}; be the function such that
{
o
if
~ ¢ SCi
};(~) =
f(~)
if
~ E SCi'

XVIII, §7
INDUCED REPRESENTATIONS
691
For all a E S we have Ji(acJ = (cjJi)(a). It is immediately clear that CiJi lies in
F 1, and
f = LCi-
1(CjJi).
i= 1
Thus Mt(F) is the sum of the subgroups Ci- 1F i - It is clear that this sum is
direct, as desired.
We note that {c II, . .. , c;: I} form a system of representatives for the left
cosets of S in G. The operation of G on M!j;(F) is defined by the presceding direct
sum decomposition. We see that G permutes the factors transitively. The factor
F 1 is S-isomorphic to the original module F, as stated in Proposition 7.1.
Suppose that instead of considering arbitrary modules, we start with a com-
mutative ring R and consider only R-modules E on which we have a representation
of G, i.e. a homomorphism G ~ AutR(E) , thus giving rise to what we call a
(G, R)-module. Then it is clear that all our constructions and definitions can be
applied in this context. Therefore if we have a representation of S on an R-module
F, then we obtain an induced representation of G on ind~ (F ) . Then we deal with
the category e of S-homomorphisms of an (S, R)-module into a (G, R)-module.
To simplify the notation, we may write "G-module" to mean "(G, R)-module"
when such a ring R enters as a ring of coefficients.
Theorem 7.3.
Let {A'll ... , Ar } be a system ofleft coset representatives ofS in
G. Th ere exists a G-module E containing F as an S-submodule, such that
r
E = EB A;F
i= 1
is a direct sum (as R-modules). Let cp : F ~ E be the inclusion mapping. Then
cp is universal in our category e, i.e. E is an induced module.
Proof
By the usual set-theoretic procedure of replacing F 1 by F in Mt(F),
obtain a G-module E containing F as a S-submodule, and having the desired
direct sum decomposition.
Let tp": F -> E' be an S-homomorphism into a
G-module E'. We define
h : E -> E'
by the rule
for Xi E F. This is well defined since our sum for E is direct. We must show that
h is a G-homomorphism. Let a E G. Then
where a(i ) is some index depending on a and i, and 'a,j is an element of S, also

692
REPRESENTATIONS OF FINITE GROUPS
depending on a, i. Then
h(aAjx;) = h(A"(ilT".iXi) = A"(i)cp'(T,,.jXJ
Since cp' is an S-homomorphism, we see that this expression is equal to
A"(i) T". jCP'(Xj) = ah(Ajxj)'
By linearity, we conclude that h is a G-homomorphism, as desired.
In the next proposition we return to the case when R is our field k.
XVIII, §7
Proposition 7.4.
Let l/J be the character of the representation of S on the
k-spaceF. Let E bethespaceofaninduced representation. Then thecharacter
X ofE is equalto the induced character l/JG, i.e. is given by theformula
c
where the sumis takenoverthe rightcosetsc ofS in G,cis afixed cosetrepre-
sentativefor c, andv« is the extensionofl/J to Gobtained by setting l/Jo(a) = 0
if a ¢ S.
Proof
Let {w 1, • • • , wm} be a basis for F over k. We know that
Let a be an element of G. The elements {ca-1wj}c.j form a basis for E over k.
We observe that caca- 1 is an element of S because
Sea = Sea = Sca.
We have
Let
(caca-1)ltj
be the components of the matrix representing the effect of caca- 1 on F with
respect to the basis {w1, • •. , wm}. Then the action of a on E is given by
a(ca-1wj ) = c-1 L: (caca-1)ltjwlt
It
= L: (caca-1)ItP-1wlt)·
It
By definition,
x(a) = L: L(caca-1)jj'
ca= ,
j

XVIII, §7
INDUCED REPRESENTATIONS
693
But C(J = C if and only if c(Jc- 1 E S. Furthermore,
t/!(C(JC- I ) = L(c(Jc-1)jj'
j
Hence
as was to be shown.
Remark.
Having given an explicit description of the representation space
for an induced character, we have in some sense completed the more elementary
part ofthe theory ofinduced characters. Readers interested in seeing an application
can immediately read §12.
Double easets
Let G be a group and let S be a subgroup. To avoid superscripts we use the
following notation. Let y E G. We write
[y]S = ySy-1
and
SlY] = y-ISy.
We shall suppose that S has finite index. We let H be a subgroup. A subset of G
of the form HyS is called a double coset. As with cosets , it is immediately
verified that G is a disjoint union of double cosets. We let {y} be a family of
double coset representatives, so we have the disjoint union
G = U HyS .
y
For each y we have a decomposition into ordinary cosets
H = U 'TyfH n[y]S),
T y
where {'Ty} is a finite family of elements of H, depending on y.
Lemma 7.5.
The elements {'TyY} form a family of left coset representatives
for S in G; that is, we have a disjoint union
G = U 'TyYS.
Y. Ty
Proof.
First we have by hypothesis
G = U U 'Ty(H n [y]S)yS,
y
T y
and so every element of G can be written in the form
'Tyys\y-I YS2 =
'TyYs
with
Sf' s2' s E S.
On the other hand, the elements 'TyY represent distinct cosets of S, because if
'TyyS = 'Tv'l'S, then y = y', since the elements 'Y represent distinct double cosets,

694
REPRESENTATIONS OF FINITE GROUPS
XVIII, §7
whence Ty and T1' represent the same coset of ySy-l , and therefore are equal.
This proves the lemma .
Let F be an S-module. Given y E G, we denote by [y]F the [y]S-module
such that for ysy-I E [y]S, the operation is given by
ysy-I . [y]x = [y]sx.
This notation is compatible with the notation that if F is a submodule of a G-
module E, then we may form yF either according to the formal definition above,
or according to the operation of G. The two are naturally isomorphic (essentially
equal). We shall write
[y] : F ~ yF or [y]F
for the above isomorphism from the S-module F to the [y]5-module yF. If 51
is a subgroup of S, then by restriction F is also an SI-module, and we use [y]
also in this context, especially for the subgroup H n [y]S which is contained in
[ y]S.
Theorem 7.6.
Applied to the S-module F, we have an isomorphism of H-
modules
G
. dG
zrs , dH
[y]S
[
]
resH 0 III S = IJ7 III Hn[y]S
0 resHn[yjS 0
y
y
.
where the direct sum is taken over double coset representatives y.
Proof.
The induced module ind~(F) is simply the direct sum
ind~(F) = E9 TyyF
y ,Ty
by Lemma 7.5, which gives us coset representatives of S in G, and Theorem
7.3. On the other hand, for each y, the module
.
EB TyyF
T y
is a representation module for the induced representation from Hn[y]S on yF
to H . Taking the direct sum over y, we get the right-hand side of the expression
in the theorem, and thus prove the theorem.
Remark.
The formal relation of Theorem 7.6 is one which occurred in
Artin's formalism of induced characters and L-functions; cf. the exercises and
[La 70], Chapter XII, §3. For applications to the cohomology of groups, see
[La 96]. The formalism also emerged in Mackey's work [Ma 51], [Ma 53], which
we shall now consider more systematically. The rest of this section is due
to Mackey. For more extensive results and applications, see Curtis-Reiner
[CuR 81], especially Chapter 1. See also Exercises 15, 16, and 17.
To deal more systematically with conjugations, we make some general func-
torial remarks. Let E be a G-module. Possibly one may have a commutative ring
R such that E is a (G, R)-module. We shall deal systematically with the functors

XVIII. §7
INDUCED REPRESENTATIONS
695
Homc , EV , and the tensor product. Let
A: E~ AE
by a R-isomorphism. Then interpreting elements of G as endomorphisms of E
we obtain a group AGA-\ operating on AE. We shall also write [A]G instead of
AGA - I . Let E, . E 2 be (G, R)-modules. Let A, : E, ~ AjEj be R-isomorphisms.
Then we have a natural R-isomorphism
(1)
A2Homc (EI, E2)A1
1 = HomA2CAi l(AIEI> A2E2),
and especially
[A]Homc (E, E ) = Hom[A)C(AE, AE).
As a special case of the general situation, let H, S be subgroups of G, and let
F\ , F2 be (H , R)- and (S, R)-modules respectively, and let a, T E G. Suppose
that cr-\T lies in the double coset D = HyS . Then we have an R-isomorphism
(2)
Hom[lT)Hn['T)s([cr]F\ , [T]F2 ) = HomH n[ y)s(F\ , [y]F2 ) ·
Thi s is immediate by conjugation, writing T = ohvs with h E H ,s E S, conjugating
first with [ahr\, and then observing that for s E S, and an S-module F, we
have [s]S = S, and [s-I]F is isomorphic to F . In light of (2), we see that the
R-module on the left-hand side depends only on the double coset. Let D be a
double coset. We shall use the notation
MD{F" F2) = HomH n [y)S (Fl , [y]F2)
where y represent s the double coset D . With this notation we have:
Theorem 7.7.
L et H . S be subgroups offinite index in G. Let Fl ' F2 be
(H . R) and (S. R)-modules respecti vely. Then we have an isomorphism of R-
modules
Homc(ind~(F\ ) ,
i nd~(F2)) = EB MD(F l , F2) ,
D
where the direct sum is taken over all double cosets HyS = D .
Proof.
We have the isomorphisms:
Homc(ind~{F\) , ind.f{F2)) = HomH(F\ , resfi 0 indf{F2))
= EB HomH (Fl , ind%n[y]s
0 res JJ~[y]S 0 [y]F2)
y
= EB Homj,n [y)s(F\, [y]F2)
y
by applying the definition of the induced module in the first and third step, and
appl ying Theorem 7.6 in the second step. Each term in the last expression is
what we denoted by MD{FI, F2) if y is a representative for the double coset D .
Thi s proves the theorem.

696
REPRESENTATIONS OF FINITE GROUPS
XVIII, §7
Corollary 7.8.
Let R = k = C. Let S, H be subgroups of the finite group
G. Let D = HyS range over the double cosets, with representatives y. Let X
be an effective character ofHand t/J an effective character ofS. Then
(ind~«x), ind~(t/J»G = L (X, [y] t/J)Hn [ylS'
y
Proof.
Immediate from Theorem 5.17(b) and Theorem 7.7, taking dimen-
sions on the left-hand side and on the right-hand side.
Corollary 7.9.
(Irreducibility of the induced character).
Let S be a
subgroup ofthe finite group G. Let R = k = C. Let t/J be an effective character
ofS. Then ind~(t/J) is irreducible if and only if t/J is irreducible and
(t/J, [y]t/J)sn[yjS =°
for all y E G, y ¢. S.
Proof.
Immediate from Corollary 7.8 and Theorem 5.17(a). It is of course
trivial that if t/J is reducible, then so is the induced character.
Another way to phrase Corollary 7.9 is as follows . Let F, F' be representation
spaces for S (over C). We call F, F' disjoint if no simple S-space occurs both
in F and F'. Then Corollary 7.9 can be reformulated:
Corollary 7.9'.
Let S be a subgroup of the finite group G. Let F be an
(S, k)-space (with k = C) . Then ind~(F) is simple if and only if F is simple
and for all y E G and y ¢ S, the S n [yJS-modules F and [yJF are disjoint .
Next we have the commutation of the dual and induced representations.
Theorem 7.10.
Let S be a subgroup ofG and let F be a finite free R-module .
Then there is a G-isomorphism
ind~(PV) = (ind~(F»v .
Proof.
Let G = UA;S be a left coset decomposition. Then, as in Theorem
7.3, we can express the representation space for ind~(F) as
ind~(F) = EBA;F.
We may select AI = I (unit element of G) . There is a unique R-homomorphism
f: FV ~ (ind~(F»V
such that for (j) E FV and x E F we have
{o
if i * I
f«(j)(A;x) =
() if .
I
(j)X
I
1=
,
which is in fact an R-isomorphism of FV on (A(F)v. We claim that it is an S-

XVIII, §7
INDUCED REPRESENTATIONS
697
homomorphism . Thi s is a routine verification, which we write down . We have
{o
if i *" I
f ([<T] cp)(Aix) =
«(
- I » if .
I
<Tcp<T
X
1[=.
On the other hand, note that if <T E S then <T- 1AI E S so <T- IA1x E A1F for
x E F; but if <T ¢. S, then <T- 1Ai ¢. S for i *" I so <T- JAix ¢. AIF. Hence
{o
if i *" I
[<T](f(cp» (A, x) = <Tf (cp)(<T-IAix) =
«
- I » if .
1
<Tcp<T
X
1 [=
.
This proves that f commutes with the action of S.
By the universal property of the induced module, it follows that there is a
unique (G, R)-homomorphism
ind~(f) :
i nd~(Fv ) ~ (ind~(F» v ,
which must be an isomorphism becausefwas an isomorphism on its image, the
AJ-component of the induced module . Thi s concludes the proof of the theorem.
Theorems and defin itions with Hom have analogues with the tensor product.
We start with the analogue of the definition.
Theorem 7.11.
Let S be a subgroup of finite index in G. Let F be an S-
module, and E a G-module (over the commutative ring R). Then there is an
isomorphism
ind~(re ss(E ) 0 F ) = E 0
ind~ (F).
Proof.
The G-module ind~ (F) contains F as a summand, because it is the
direct sum EBAiF with left coset representatives Ai as in Theorem 7.3. Hence
we hav e a natural S-isomorphism
f: ress(E) 0 F ~ E 0 A)F C E 0
ind~ (F) .
taking the representative AI to be I (the unit element of G). By the universal
property of induction, there is a G-homomorphism
ind~(f) : ind ~(re ss(E) 0 F) ~ E 0
ind~ (F) ,
which is immediately verified to be an isomorphism , as desired. (Note that here
it only needed to verify the bijectivity in this last step, which comes from the
structure of direct sum as R-modules.)
Before going further , we make some remarks on functorialities. Suppose we
have an isomorphism G = G', a subgroup H of G corresponding to a subgroup
H' of G' under the isomorphism , and an isomorphism F = F' from an H-module
F to an H'-rnodule F' commuting with the actions of H , H'. Then we get an
isomorphism
ind~(F ) = indW(F' ).

698
REPRESENTATIONS OF FINITE GROUPS
XVIII, §7
by Theorem 7. II
In particular, we could take a E G, let G' = [a]G = G, H' = [a]H and
F' = [a]F.
Next we deal with the analogue of Theorem 7.7 . We keep the same notation
as in that theorem and the discussion preceding it. With the two subgroups H
and S, we may then form the tensor product
[a]F) Q9 [T]F2
with a, T E G. Suppose a-IT ED for some double coset D = HyS. Note that
[a]F, @ [T]F2is a [a]H n [T]S-module. By conjugation we have an isomorphism
(3)
indfu)Hn[T]s([a]F, Q9 [T]F2) = indfjn[y)s(FI @ [y]F2).
Theorem 7.12.
There is a G-isomorphism
ind~(FI) @ ind~(F2) = EB ind~n[y)s(F) @ [y]F2),
y
where the sum is taken over double coset representatives y.
Proof.
We have:
ind~(F,) @ ind~(F2) = ind~(F1 Q9 resH ind~(F2»
= EB ind~(F 1 @ ind~n[y]s resHn[~l~([y]F2)
by Theorem 7.6
y
= ~ ind~(nd~n[y)s(resJ1n[y)s(FI) Q9 resJl~s[Y) s([Y]F2»))
by Theorem 7.7
= EB ind~ n [y)s(F, @ [y]F2)
by transitivity of induction
y
where we view FI n [y]F2 as an H n [y]S-module in this last line. This proves
the theorem.
General comment.
This section has given a lot of relations for the induced
representations. In light of the cohomology of groups, each formula may be
viewed as giving an isomorphism of functors in dimension 0, and therefore gives
rise to corresponding isomorphisms for the higher cohomology groups Hs , The
reader may see this developed further than the exercises in [La 96].
Bibliography
[CuR 81]
[La 96]
[La 70J
[Ma 51]
[Ma 53]
C . W. CURTIS and 1. REINER , Methods ofRepresentation Theory, John Wiley
and Sons, 1981
S. LANG, Topics in cohomology of groups , Springer Lecture Notes 1996
S. LANG, Algebraic Number Theory, Addison-Wesley, 1970, reprinted by
Springer Verlag, 1986
G. MACKEY, On induced representations of groups, Amer. J. Math. 73 (1951),
pp. 576-592
G. MACKEY, Symmetric and anti-symmetric Kronecker squares of induced
representations of finite groups, Amer. J. Math. 75 (1953), pp. 387-405

XVIII. §8
POSITIVE DECOMPOSITION OF THE REGULAR CHARACTER
699
The next three sections, which are essentially independent ofeach other, give
examples of induced representations. In each case, we show that certain
representations are either induced from certain well-known types, or are linear
combinations with integral coefficients ofcertain well-known types. The most
striking feature is that we obtain all characters as linear combinations of in-
duced characters arising from i-dimensional characters. Thus the theory of
characters is to alarge extent reduced to the study of i-dimensional, or abelian
characters .
§8.
POSITIVE DECOMPOSITION OF THE
REGULAR CHARACTER
Let G be a finite group and let k be the complex numbers. We let I G be the
trivial character, and rG denote the regular character.
Proposition 8.1.
Let H be a subgroup of G. and let l/J be a character ofH.
Let l/JG be the induced character. Then the multiplicity of IHin l/J is the same
as the multiplicity of IGin l/JG.
Proof
By Theorem 6.1 (i), we have
These scalar products are precisely the multiplicities in question.
Proposition 8.2.
The regular representation is the representation induced
by the trivial character on the trivial subgroup of G.
Proof
This follows at once from the definition of the induced character
taking l/J = I on the trivial subgroup.
Corollary 8.3.
The multiplicity of IG in the regular character rG is equal to 1.
We shall now investigate the character
Theorem 8.4.
(Aramata).
The character nUG is a linear combination with
positive integer coefficients of characters induced by i-dimensional characters
of cyclic subgroups of G.
The proof consists of two propositions, which give an explicit description of
the induced characters. I am indebted to Serre for the exposition, derived from
Brauer's.

700
REPRESENTATIONS OF FINITE GROUPS
XVIII, §8
If A is a cyclic group of order a, we define the function (JA on A by the condi-
tions :
II
)
_ {a
if (J is a generator of A
ui(J - o otherwise.
We let AA = qJ(a)rA -
(JA(where qJ is the Euler function), and AA = 0 if a = 1.
The desired result is contained in the following two propositions.
Proposition 8.5.
Let G be afinite group ojorder n. Then
nuc = 2: AX,
the sum being taken over all cyclic subgroups ofG.
Proof
Given two class functions X, tj; on G, we have the usual scalar
product :
1"
-
<tj;, X>G = -
L. tj;«(J)X«(J)·
n GEG
Let tj; be any class function on G. Then:
<tj;, nuG>= <tj;, nrG> - <tj;, nlG>
= ntj;(l) - L tj;«(J).
GEG
On the other hand, using the fact that the induced character is the transpose of
the restriction, we obtain
= L: <tj; IA, qJ(a)rA -
(JA >
A
1
= L qJ(a)tj;(l) - L:- L atj;«(J)
A
A a GgenA
= ntj;(l) - L tj;«(J).
GEG
Since the functions on the right and leftof the equality sign in the statement of our
proposition have the same scalar product with an arbitrary function, they are
equal. This proves our proposition.
Proposition 8.6.
IJ A i= {I}, the Junction AA is a linear combination oj ir-
reducible nontrivialcharacters oj A with positive integralcoefficients.

XVIII, §8
POSITIVE DECOMPOSITION OF THE REGULAR CHARACTER
701
Proof
If A is cyclic of prime order, then by Proposition 8.5, we know that
I'A =
nU A' and our assertion follows from the standard structure of the regular
representation.
In order to prove the assertion in general, it suffices to prove that the Fourier
coefficients of AAwith respect to a character of degree 1 are integers ~ O. Let
IjJ be a character of degree 1. We take the scalar product with respect to A, and
obtain:
a gen
= cp(a) - L ljJ(a)
e gen
= L (1 -
ljJ(a» .
e gen
The sum LljJ(a) taken over generators of A is an algebraic integer, and is in fact
a rational number (for any number of elementary reasons), hence a rational
integer. Furthermore, if IjJ is non-trivial, all real parts of
1 -
ljJ(a)
are> 0 ifa # id and are 0 ifa = id. From the last two inequalities, we conclude
that the sums must be equal to a positive integer. If IjJ is the trivial character,
then the sum is clearly O. Our proposition is proved.
Remark.
Theorem 8.4 and Proposition 8.6 arose in the context of zeta
functions and L-functions, in Aramata's proof that the zeta function of a number
field divides the zeta function of a finite extension [Ar 31], [Ar 33]. See also
Brauer [Br 47a], [Br 47b]. These results were also used by Brauer in showing
an asymptotic behavior in algebraic number theory , namely
log(hR) -
log DI /2 for [k : Q]/log D -
0 ,
where h is the number of ideal classes in a number field k, R is the regulator,
and D is the absolute value of the discriminant. For an exposition of this appli-
cation, see [La 70], Chapter XVI.
Bibliography
[Ar 31)
H. ARAMATA, Uber die Teilbarkeit der Dedekindschen Zetafunktionen, Proc.
Imp. Acad. Tokyo 7 (1931), pp. 334-336
[Ar 33)
H. ARAMATA, Uber die Teilbarkeit der Dedekindschen Zetafunktionen, Proc.
Imp. Acad. Tokyo 9 (1933) , pp. 31-34
[Br 47a)
R. BRAUER, On the zeta functions of algebraic number fields, Amer. J. Math.
69 (1947) , pp. 243-250
[Br 47b)
R. BRAUER, On Artin's L-serie s with general group characters, Ann. Math. 48
(1947) , pp. 502-514
[La 70)
S. LANG, Algebraic Number Theory, Springer Verlag (reprinted from Addison-
Wesley, 1970)

702
REPRESENTATIONS OF FINITE GROUPS
§9.
SUPERSOLVABLE GROUPS
XVIII, §9
Let G be a finite group. We shall say that G is supersolvable if there exists a
sequence of subgroups
such that each G, is normal in G, and Gi+dGi is cyclic of prime order.
From the theory of p-groups, we know that every p-group is super-solvable,
and so is the direct product of a p-group with an abelian group.
Proposition 9.1.
Every subgroup and every factor group ofa super-solvable
group is supersolvable.
Proof
Obvious, using the standard homomorphism theorems.
Proposition 9.2.
Let G be a non-abelian supersolvable group. Then there
exists a normal abelian subgroup which contains the center properly.
Proof
Let C be the center of G, and let G = G/C.
Let H be a normal
subgroup of prime order in G and let H be its inverse image in G under the
canonical map G ~ G/C. Ifa is a generator of H, then an inverse image a of a,
together with C, generate H. Hence H is abelian, normal, and contains the
center properly.
Theorem 9.3.
(Blichfeldt) .
Let G be a supersolvable group, let k be alge-
braically closed. Let E be a simple (G, k)-space. If dim, E > I, then there
exists a proper subgroup H ofG and a simple H-space F such that E is induced
byF.
Proof
Since a simple representation of an abelian group is l-dimensional,
our hypothesis implies that G is not abelian.
We shall first give the proof of our theorem under the additional hypothesis
that E is faithful. (This means that ax = x for all x E E implies a = 1.) It will
be easy to remove this restriction at the end.
Lemma 9.4.
Let G be a finite group, and assume k algebraically closed. Let
E be a simple,faithful Grspace over k. Assume that there exists a normal abelian
subgroup H of G containing the center of G properly . Then there exists a
proper subgroup HI of G containing H, and a simple HI-space F such that E
is the induced module ofF from HI to G.
Proof
We view E as an H-space. It is a direct sum of simple H-spaces, and
since H is abelian, such simple H-space is l-dimensional.
Let V E E generate a l-dimensional H-space. Let rjJ be its character. If
WEE also generates a l-dimensional H-space, with the same character rjJ, then

XVIII, §9
for all a, b e k and r E H we have
SUPERSOLVABLE GROUPS
703
r(av + bw) = t/J(r)(av + bw).
If we denote by F", the subspace of E generated by all I-dimensional H-sub-
spaces having the character t/J, then we have an H-direct sum decomposition
E=EBF", .
'"
We contend that E i= F", . Otherwise, let vEE, v i= 0, and a E G. Then a-Iv
is a I-dimensional H-space by assumption, and has character t/J. Hence for
rEH,
rea-Iv) = t/J(r)a-I v
(aw-I)v = at/J(r)a-I v = t/J(r)v.
This shows that aw- I and r have the same effect on the element v of E. Since
H is not contained in the center of G, there exist r EH and a E G such that
ara- I i= r, and we have contradicted the assumption that E is faithful.
We shall prove that G permutes the spaces F", transitively.
Let v EF",. For any r EH and a E G, we have
r(av) = a(a-Ira)v = at/J(a-Iw)v = t/J,rCr)av,
where t/J(l is the function on H given by t/Jir) = t/J(a-Ira). This shows that a
maps F", into F"'a' However, by symmetry, we see that a-I maps F"'a into F"',
and the two maps a, a-I give inverse mappings between F"'a and F",. Thus G
permutes the spaces {F",}.
Let E' = GFl/Jo = 2: aFl/Jofor some fixed t/Jo. Then E' is a G-subspace of E,
and since E was assumed to be simple , it follows that E'
= E. This proves that
the spaces {Fl/J} are permuted transitively .
Let F = F"'1 for some fixed t/J I ' Then F is an H-subspace of E. Let HI be
the subgroup of all elements rEG such that iF = F. Then HI i= G since
E i= F", . We contend that F is a simple H I-subspace, and that E is the induced
space ofF from HI to G.
To see this, let G = UH IC be a decomposition of G in terms of right cosets
of HI' Then the elements {c- I} form a system of left coset representatives of
HI ' Since
E = LaF
(leG
it follows that
We contend that this last sum is direct, and that F is a simple HI-space.

704
REPRESENTATIONS OF FINITE GROUPS
XVIII, §10
Since G permutes the spaces {F,p}, we see by definition that HI is the isotropy
group of F for the operation of G on this set of spaces, and hence that the elements
of the orbit are precisely {c- IF}, as c ranges over all the cosets. Thus the spaces
{c- IF} are distinct, and we have a direct sum decomposition
If W is a proper H I-subspace of F, then E8 c: IW is a proper G-subspace of E,
contradicting the hypothesis that E is simple. This proves our assertions.
We can now apply Theorem 7.3 to conclude that E is the induced module
from F, thereby proving Theorem 9.3,in case E is assumed to be faithful.
Suppose now that E is not faithful.
Let Go be the normal subgroup of G
which is the kernel of the representation G -+ Autk(E). Let G = GIGo. Then
E gives a faithful representation of G. As E is not l-dimensional, then Gis not
abelian and there exists a proper normal subgroup Hof Gand a simple H-space
F such that
E = ind~F) .
Let H be the inverse image of H in the natural map G -+ G. Then H :::> Go,
and F is a simple H-space. In the operation of Gas a permutation group of the
k-subspaces {oP}ueG, we know that His the isotropy group of one component.
Hence H is the isotropy group in G of this same operation, and hence applying
Theorem 7.3 again, we conclude that E is induced by F in G, i.e.
E = ind~(F),
thereby proving Theorem 9.3.
Corollary 9.5.
Let G be a product ofa p-qroup and a cyclic group, and let k
be algebraically closed. If E is a simple (G, k)-space and is not Y-dimensional,
then E is induced by a i-dimensional representation of some subgroup .
Proof
We apply the theorem step by step using the transitivity of induced
representations until we get a I-dimensional representation of a subgroup.
§10.
BRAUER'S THEOREM
We let k = C be the field of complex numbers . We let R be a subring of k.
We shall deal with XR(G), i.e . the ring consisting of all linear combinations with
coefficients in R of the simple characters of Gover k. (It is a ring by Proposition
2.1.)

XVIII, §10
BRAUER'S THEOREM
705
Let H =
{ H~} be a fixed family of subgroups of G, indexed by indices {a}.
We let VR(G) be the additive subgroup of XR(G) generated by all the functions
which are induced by functions in X R(H~ ) for some H~ in our family. In other
words,
VR(G) = 2: ind~a<XR(Ha)) '
a
We could also say that VR(G) is the subgroup generated over R by all the char-
acters induced from all the Ho •
Lemma 10.1.
VR(G) is an ideal in XR(G).
Proof
This is immediate from Theorem 6.1.
For many applications, the family of subgroups will consist of "elementary"
subgroups: Let p be a prime number. By a p-elementary group we shall mean
the product of a p-group and a cyclic group (whose order may be assumed prime
to p, since we can absorb the p-part of a cyclic factor into the p-group). An
element
(J E G is said to be p-regular if its period is prime to p, and p-singular
if its period is a power of p. Given x E G, we can write in a unique way
x = (JT
where (J is p-singular, T is p-regular,and (J , T commute. Indeed, ifp'mis the period
ofx, with m prime to p,then 1 = vp" + 11m whence x = (xm)"(x pr)" and we get our
factorization.
It is clearl y unique, since the factors have to lie in the cyclic
subgroup generated by x. We call the two factors the p-singular and p-regular
factors of x respectively.
The above decomposition also shows:
Proposition 10.2.
Every subgroup and every factor group of a p-elementary
group is p-elementary. If 5 is a subgroup of the p-elementary group P x C,
where P is a p-qroup, and C is cyclic, of order prime to p, then
5 = (5 (l P) x (5 (l C).
Proof
Clear.
Our purposeis to show,among other things, that ifourfamily {Ho } is such that
every p-elementary subgroup of G is contained in some H.. then VR(G) = XR(G)
for every ring R. It would of course suffice to do it for R = Z, but for our pur-
poses, it is necessary to pro ve the result first using a bigger ring. The main result
is contained in Theorems 10.11 and 10.13, due to Brauer. We shall give an
exposition of Brauer-Tate (Annals of Math., July 1955).
We let R be the ring Z[(] where ( is a primitive n-th root of unity. There
exists a basis of R as a Z-module, namely 1, (, ... , ( N- 1 for some integer N.
This is a trivial fact, and we can take N to be the degree of the irreducible poly-
nomial of ( over Q. Th is irreducible polynomial has leading coefficient 1, and

706
REPRESENTATIONS OF FINITE GROUPS
XVIII, §10
has integer coefficients, so the fact that
I, (, ... ,(N- I
form a basis of Z[(J follows from the Euclidean algorithm. We don't need to
know anything more about this degree N.
We shall pro ve our assertion first for the above ring R. The rest then follows
by using the following lemma.
Lemma 10.3.
If d e Z and the constant function d.1G belongs to VR then
d.1G belongs to Vz .
Proof
We contend that I, (, . . . , (N- I are linearly independent over X z(G).
Indeed, a relation of linear dependence would yield
s
N - I
L L CVjXv ( j = 0
v= I
j = 0
with integers cvj not all O. But the simple characters are linearly independent
over k. The above relation is a relation between these simple characters with
coefficients in R, and we get a contradiction. We conclude therefore that
is a direct sum (of abelian groups), and our lemma follows.
If we can succeed in proving that the constant function IG lies in VR(G),
then by the lemma, we conclude that it lies in Vz(G),and since Vz(G) is an ideal,
that X z(G) = Vz(G).
To prove our theorem, we need a sequence of lemmas.
Two elements x, x' of G are said to be p-conjugate if their p-regular factor s
are conjugate in the ordinary sense. It is clear that p-conjugacy is an equivalence
relation, and an equivalence class will be called a p-conjugacy class, or simply a
p-class.
Lemma 10.4.
LetfEXR(G), and assume thatf(a)EZfor all aEG. Then
f is constant mod p on every p-class.
Proof
Let x = rrr, where a is p-singular, and t is p-regular, and a, r com-
mute. It will suffice to prove that
f( x) =f(r)
(mod p).
Let H be the cyclic subgroup generated by x. Then the restriction of f to H
can be written

XVIII, §10
BRAUER'S THEOREM
707
with aj ER, and l/Jj being the simple characters of H, hence homomorphisms of
H into k*. For some power p' we have x'" = "Cpr, whence l/Jixyr = l/J/"Cyr, and
hence
f(xyr =f(ryr
(mod pR).
We now use the following lemma.
Lemma 10.5.
Let R = Z[n be as before. If a E Z and a E pR then a E pZ.
Proof
This is immediate from the fact that R has a basis over Z such that
1 is a basis element.
Applying Lemma 10.5, we conclude that f(x) =f("C) (mod p), because
bY =b (mod p) for every integer b.
Lemma 10.6.
Let r be p-reqular in G, and let T be the cyclic subgroup
generated by "C. Let C be the subgroup of G consisting of all elements com-
mutingwith T. Let P be a p-Sylowsubgroup ofC. Then thereexists anelement
l/JE XR(T x P)suchthattheinducedfunctionf= IjP hasthefollowingproperties:
(i) f(a) E Z for all a E G.
(ii) f(a) = 0 if a does not belong to the p-class of r.
(iii) f("C) = (C : P) =1= 0 (mod p).
Proof
We note that the subgroup of Ggenerated by T and P is a direct pro-
duct T x P. Let l/J l' . . . , l/J, be the simple characters of the cyclic group T, and
assume that these are extended to T x P by composition with the projection :
T x P -> T -> k*.
We denote the extensions again by l/J 1> • •• , l/J,. Then we let
r
l/J = L l/Jv(r)l/Jv'
v= 1
The orthogonality relations for the simple characters of T show that
l/J(ry) = l/J(r) =(T:l)
for
yEP
l/J(a) = 0
if
a E TP,
and
a ¢ "CP.
We contend that l/JG satisfies our requirements.
First, it is clear that l/J lies in XR(TP).

708
REPRESENTATIONS OF FINITE GROUPS
We have for IT E G:
G
_
I
""
_ I __1_ ( )
!/J (IT) -
(TP: I) ~ !/Jyp(xax
) -
(P : I)JL IT
XVIII, §10
where JL( IT) is the number of elements x E G such that xax- I lies in TP. The
number J1«(J) is divisible by (P: 1) because if an element x of G moves (J into iP
by conjugation, so does every element of Px. Hence the values of !/JG lie in Z.
Furthermore, J1«(J)
=1= 0 only if (J is p-conjugate to r, whence our condition
(ii) follows.
Finally, we can have xrx" 1 = ry with yEP only ify = 1(because the period
of r is prime to p). Hence J1(r) = (C: 1), and our condition (iii) follows.
Lemma 10.7.
Assumethat thefamily ofsubgroups {Ha} covers G ti.e.every
element of G liesin someHa). Iff is a classfunction on G taking its values in
Z, and such that all the values are divisible by n = (G: 1), thenf belongs to
VR(G).
Proof.
Let y be a conjugacy class, and let p be prime to n. Every element
of Gis p-regular, and all p-subgroups of G are trivial. Furthermore, p-conjugacy
is the same as conjugacy. Applying Lemma 10.6, we find that there exists in
VR(G) a function taking the value 0 on elements (J ¢ y, and taking an integral
value dividing n on elements ofy. Multiplying this function by some integer, we
find that there exists a function in VR(G) taking the value n for all elements of y,
and the value 0 otherwise. The lemma then follows immediately.
Theorem 10.8.
(Artin).
Every character of G is a linear combination with
rational coefficients ofinduced characters from cyclicsubgroups.
Proof.
In Lemma 10.7, let {Ha } be the family of cyclic subgroups of G. The
constant function n.lGbelongs to VR(G). By Lemma 10.3,this function belongs
to Vz(G), and hence nXz(G) c
Vz(G). Hence
1
Xz(G) c - Vz(G),
n
thereby proving the theorem.
Lemma 10.9.
Let p be a prime number, and assume that every p-elementary
subgroup ofG is contained in someHi: Then thereexists afunctionf e VR(G)
whose values are in Z, and == 1 (mod pr).
Proof.
We apply Lemma 10.6 again. For each p-class y,we can find a func-
tion j , in VR(G), whose values are 0 on elements outside y, and
=1= 0 mod p for
elements of y. Let f = L fr, the sum being taken over all p-classes. Then
f((J)
=1= 0 (modp) for all (J E G. Taking f (p-Ijp,-l gives what we want.

XVIII, §10
BRAUER'S THEOREM
709
Lemma 10.10.
Let p be a prime number and assume that every p-elementary
subgroup oj G is contained in some H, . Let n = nop' where no is prime to p.
Then the constantJunction no.1G belongs to Vz(G).
Proof
By Lemma 10.3, it suffices to pro ve that no.1G belongs to VR(G).
Let Jbe as in Lemma 10.9. Then
Since no(1G - J) has values divisible by nop' = n, it lies in VR ( G) by Lemma
10.7. On the other hand , noJ E VR ( G) because J E VR ( G).This proves our lemma.
Theorem 10.11.
(Brauer).
Assume that Jor every prime number p, every
p-eiementary subgroup of G is contained in some H, . Then X(G) = Vz(G).
Every character of G is a linear combination, with integer coefficients, oj
characters induced Jrom subgroups H, .
Proof
Immediate from Lemma 10.10, since we can find functions no.lG in
Vz(G) with no relativel y prime to any given prime number.
Corollary 10.12.
A class Junction J on G belongs to X (G) if and only if its
restriction to H, belongs to X (H , )Jor each a.
Proof
Assume that the restriction ofJto H, is a character on H, for each a.
By the theorem, we can write
where c, E Z, and 1jJ, E X (H,). Hence
using Theorem 6.1. IfJH. E X(H,), we conclude that J belongs to X(G). The
converse is of course trivial.
Theorem 10.13.
(Brauer).
Every character oj G is a linear comb ination
with integ er coefficients oj characters induced by s-dimensionol characters of
subgroups.
Proof
By Theorem 10.11, and the transitivity of induction, it suffices to
prove that every character of a p-elementary group has the property stated in
the theorem. But we have pro ved this in the preceding section, Corollary 9.5.

710
REPRESENTATIONS OF FINITE GROUPS
§11.
FIELD OF DEFINITION OF A
REPRESENTATION
XVIII, §11
We go back to the general case of k having characteristic prime to #G. Let
E be a k-space and assume we have a representation of G on E. Let k' be an
extension field of k. Then G operates on k' @k E by the rule
ata ® x) = a ® ax
for a E k' and x E E. This is obtained from the bilinear map on the product
k' x E given by
(a, x)Ha ® ax.
We view E' = k' ®k E as the extension of E by k',and we obtain a representation
ofG on E'.
Proposition 11.1.
Let the notation be as above. Then the characters ofthe
representations ofG on E and on E' are equal.
Proof
Let {VI"' " vm } be a basis of E over k. Then
is a basis of E' over k'. Thus the matrices representing an element a of G with
respect to the two bases are equal, and consequently the traces are equal.
Conversely, let k' be a field and k a subfield. A representation of G on a
k'-space E' is said to be definable overk if there exists a k-space E and a repre-
sentation of G on E such that E' is G-isomorphic to k' ®k E.
Proposition 11.2.
Let E, F be simple representation spaces for the finite
group Gover k. Let k' be an extension of k. Assume that E, F are not G-
isomorphic. Then no k'-simple component of Ek, appears in the direct sum
decomposition ofFk, into k'-simple subspaces.
Proof
Con sider the direct product decomposition
s(k )
keG] = Il Rik)
1'= 1
over k, into a direct product of simple rings. Without loss of generality, we may
assume that E, Fare simle left ideals of keG], and they will belong to distinct
factors of this product by assumption. We now take the tensor product with
k', getting nothing else but k'[G]. Then we obtain a direct product decomposi-
tion over k'. Since Rv(k)Rik) = 0 if v # u, this will actually be given by a direct

XVIII, §11
FIELD OF DEFINITION OF A REPRESENTATION
711
product decomposition of each factor RJk) :
s(k) m(Jl)
k'[G] = Il Il RJlj(k').
Jl = 1
j = I
Say E = L ; and F = L Jl with v #- p. Then RJlE = O. Hence RJljEk • = 0 for
each i = 1, . .. , m(p). This implies that no simple component of Ek• can be
G-isomorphic to anyone of the simple left ideals of RJlj , and proves what we
wanted.
Corollary 11.3.
The simple characters XI' . . . , Xs (k ) oj G over k are linearly
independent over any extension k' ojk.
Proof
This follows at once from the proposition, together with the linear
independence of the k'-sirnple characters over k'.
Propositions 11.1 and 11.2 are essentially general statements of an abstract
nature. The next theorem uses Brauer's theorem in its proof.
Theorem 11.4.
(Brauer).
Let G be a finite group oj exponent m. Every
representation oj G over the complex numbers (or an algebraically closedfield
oj characteristic 0) is definable over the field Q«(m) where (m is a primitive
m-th root of unity.
Proof.
Let Xbe the character of a representation of Gover C, i.e. an effective
character. By Theorem 10.13, we can write
the sum being taken over a finite number of subgroups Sj ' and l/Jj being a 1-
dimensional character of Sj ' It is clear that each l/Jj is definable over Q«(m)' Thus
the induced character l/JY is definable over Q«(m)' Each #' can be written
where {XJl } are the simple characters of Gover Q«(m)' Hence
The expression of Xas a linear combination of the simple characters over k is
unique, and hence the coefficient
is ~ O. This proves what we wanted.

712
REPRESENTATIONS OF FINITE GROUPS
§12.
EXAMPLE: GL 2 OVER A FINITE FIELD
XVIII, §12
Let F be a field. We view GL2(F) as operating on the 2-dimensional
vector space V = F2• We let Fa be the algebraic closure as usual, and we let
va = Fax Fa = P 0 V (tensor product over F). By semisimple, we always
mean absolutely semisimple, i.e. semisimple over the algebraic closure Fa. An
element a E GL2(F ) is called semisimple if va is semisimple over P[a] . A sub-
group is called semisimple if all its elements are semisimple.
Let K be a separable quadratic extension of F. Let {WI' W2} be a basis of K.
Then we have the regular representation of K with respect to this basis, namely
multiplication representing K* as a subgroup of GL2(F). The elements of norm
1 correspond precisely to the elements of SL2(F) in the image of K*. A different
choice of basis of K corresponds to conjugation of this image in GL2(F ). Let CK
denote one of these images . Then CK is called a non-split Cartan subgroup.
The subalgebra
is isomorphic to K itself, and the units of the algebra are therefore the elements
of CK = K*.
Lemma 12.1.
The subgroup CK is a maximal commutative semisimple
subgroup .
Proof.
If a E GL2(F) commutes with all elements of CK then a must lie in
F[CK ], for otherwise {l, a} would be linearly independent over F[CK ], whence
Mat2(F) would be commutative, which is not the case . Since a is invertible, a
is a unit in F[CK ], so a E CK , as was to be shown.
By the split Cartan subgroup we mean the group of diagonal matrices
(~
~) with a, dE F*.
We denote the split Cartan by A, or A(F) if the reference to F is needed.
By a Cartan subgroup we mean a subgroup conjugate to the split Cartan or
to one of the subgroups CK as above .
Lemma 12.2.
Every maximal commutative semisimple subgroup of GL2(F)
is a Cartan subgroup, and conversely.
Proof.
It is clear that the split Cartan subgroup is maximal commutative
semisimple. Suppose that H is a maximal commutative semisimple subgroup of
GL2(F). If H is diagonalizable over F, then H is contained in a conjugate of the
split Cartan. On the other hand, suppose H is not diagonalizable over F . It is
diagonalizable over the separable closure of F, and the two eigenspaces of

XVIII, §12
EXAMPLE: GL2 OVER A FINITE FIELD
713
dim ension I give rise to two characters
t/J, t/J'
: H ~P *
of H in the multiplicative group of the separable clo sure. For each element
a E H the values t/J(a) and t/J'(a ) are the eigenvalues of a , and for some element
a E H these eigenvalues are distinct , otherwise H is diagonalizable over F.
Hence the pair of element s t/J(a),
t/J'(a) are conjugate over F . The image t/J(H )
is cyclic, and if t/J(a) generates this image, then we see that t/J(a) generates a
quadratic extension K of F . The map
a ~ t/J(a) with a E H
extends to an F-linear mapping, also denoted by t/J, of the algebra F[H] into K .
Since F[H] is semisimple, it follows that t/J : F[H] ~ K is an isomorphism.
Hence t/J maps H into K*, and in fact map s H onto K* because H was taken to
be maximal. This proves the lemma.
In the above proof, the two characters t/J, t/J' are called the (eigen)characters
of the Cartan subgroup. In the split case, if a has diagonal elements, a, d then
we get the two characters such that t/J(a) = a and t/J'(a) = d . In the split case,
the values of the characters are in F. In the non- split case , these values are
conjugate quadratic over F, and lie in K.
Proposition 12.3.
Let H be a Cartan subgroup ofGL2(F) (split or not ). Then
H is of index 2 in its normalizer N(H).
Proof.
We may view GL 2(F) as operating on the 2-dimensional vector space
va= P
ED P, over the algebraic clo sure Fa. Whether H is split or not , the
eigencharacters are distinct (because of the separability assumption in the non-
split case), and an element of the normalizer must either fix or interchange the
eigenspaces . If it fixes them , then it lies in H by the maximality of H in Lemma
12.2 . If it interchanges them, then it doe s not lie in H , and generates a unique
coset of N/ H , so that H is of index 2 in N .
In the split case , a representative of N/ A which interchanges the eigenspaces
is given by
w = G ~) .
In the non-split case, let rr: K ~ K be the non-trivial automorphism . Let
{a, rro} be a normal basis. With respect to this basis, the matrix of rr is precisely
the matrix
w = G ~) .
Therefore again in this case we see that there exi sts a non-trivial element in the

714
REPRESENTATIONS OF FINITE GROUPS
normalizer of A. Note that it is immediate to verify the relation
M((J')M(x)M( (J'-l) = M(ox),
XVIII, §12
if M(x) is the matrix associated with an element x E K.
Since the order of an element in the multiplicative group of a field is prime
to the characteristic, we conclude:
IfF has characteristic p. then an element offinite order in GLz(F) is semisimple
if and only if its order is prime to p .
Conjugacy classes
We shall determine the conjugacy classes explicitly. We specialize the sit-
uation, and from now on we let:
F = finite field with q elements;
G = GL2(F);
Z = center of G;
A = diagonal subgroup of G;
C = K* = a non-split Cartan subgroup of G.
Up to conjugacy there is only one non-split Cartan because over a finite field
there is only one quadratic extension (in a given algebraic closure Fa) (cf.
Corollary 2.7 of Chapter XIV). Recall that
#(G) = (q2 -
1)(q2 -
q) = q(q + I)(q -
1)2.
This should have been worked out as an exercise before. Indeed, F x F has q2
elements, and #(G) is equal to the number of bases of F x F. There are q2 -
1
choices for a first basis element, and then q2 - q choices for a second (omitting
(0, 0) the first time, and all chosen elements the second time) . This gives the
value for #(G).
There are two cases for the conjugacy classes of an element a.
Case 1.
The characteristic polynomial is reducible, so the eigenvalues lie
in F . In this case, by the Jordan canonical form , such an element is conjugate
to one of the matrices
(~
~),
(~
~),
(~
~)
withd*a .
These are called central, unipotent, or rational not central respectively.
Case 2.
The characteristic polynomial is irreducible. Then a is such that
F[a] = E, where E is the quadratic extension of F of degree 2. Then {I, a} is
a basis of F[a] over F , and the matrix associated with a under the representation
by multiplication on F[ a] is
(0 -b),
I
-a

XVIII, §12
EXAMPLE: GL2 OVER A FINITE FIELD
715
where a, b are the coefficients of the characteristic polynomial X2 + ax + b.
We then have the following table .
Tahle 12.4
class
# of classes
# of elements in the class
(~ :)
q -
1
1
(~
~)
q-l
q2 -
I
(~
~)
1
q2 + q
-(q -
l)(q -
2)
2
with a "* d
a E C -
F*
1
q2 _ q
-(q -
l)q
2
In each case one computes the number of elements in a given class as the index
of the normalizer of the element (or centralizer of the element). Case 1 is trivial.
Case 2 can be done by direct computation, since the centralizer is then seen to
consist of the matrices
(~
~), X E F,
with x "* O. The third and fourth cases can be done by using Proposition 12.3 .
As for the number of classes of each type, the first and second cases correspond
to distinct choices of a E F* so the number of classes is q -
1 in each case. In
the third case, the conjugacy class is determined by the eigenvalues. There are
q -
1 possible choices for a, and then q -
2 possible choices for d. But the
non-ordered pair of eigenvalues determines the conjugacy class, so one must
divide (q - l)(q - 2) by 2 to get the number of classes. Finally, in the case
of an element in a non-split Cartan, we have already seen that if a generates
Gal(K jF) , then M(ax) is conjugate to M(x) in GL2(F). But on the other
hand, suppose x, x' E K* and M(x) , M(x') are conjugate in GL2(F) under a given
regular representation of K* on K with respect to a given basis . Then this
conjugation induces an F-algebra isomorphism on F[CK ], whence an automor-
phismof K, which is the identity, or the non-trivial automorphism a. Consequently
the number of conjugacy classes for elements of the fourth type is equal to
#(K) -
#(F) _ q2 -
q
2
-
2
which gives the value in the table.

716
REPRESENTATIONS OF FINITE GROUPS
Borel subgroup and induced representations
We let:
V = group of unipotent elements (~
~) ;
B = Borel subgroup = VA = AV.
XVIII, §12
Then #(B) = q(q -
1)2 = (q -
I)(q2 -
q) . We shall construct representations
of G by inducing characters from B, and eventually we shall construct all irre-
ducible representations ofG by combining the induced representations in a suitable
way. We shall deal with four types of characters. Except in the first type, which
is l-dirnensional and therefore obviously simple, we shall prove that the other
types are simple by computing induced characters. In one case we need to subtract
a one-dimensional character. In the other cases, the induced character will turn
out to be simple. The procedure will be systematic. We shall give a table of
values for each type. We verify in each case that for the character X which we
want to prove simple we have
2: Ix({3)1 2 = #(G),
(3EG
and then apply Theorem 5.17(a) to get the simplicity. Once we have done this
for all four types, from the tables of values we see that they are distinct. Finally,
the total number of distinct characters which we have exhibited will be equal to
the number of conjugacy classes, whence we conclude that we have exhibited
all simple characters.
We now carry out this program. I myself learned the simple characters of
GL2(F) from a one-page handout by Tate in a course at Harvard, giving the
subsequent tables and the values of the characters on conjugacy classes. I filled
out the proofs in the following pages.
First type
J.L : F* ~ C* denotes a homomorphism. Then we obtain the character
J.L 0 det: G ~ C*,
which is l-dimensional, Its values on representatives of the conjugacy classes
are given in the following table.
Table 12.5(1)
X
(~
~)
(~
~)
(~
~)d * a
a E C - F*
J.L 0 det
J.L(a)2
J.L(a)2
J.L(ad)
J.L 0 det( a)

XVIII, §12
EXAMPLE : GL2 OVER A FINITE FIELD
717
The stated values are by definition . The last value can also be written
JL(det a) = JL(NK1F(a)),
viewing a as an element of K*, because the reader should know from field theory
that the determinant gives the norm .
A character of G will be said to be of first type if it is equal to JL 0 det for
some JL. There are q -
I characters of first type, because #(F*) = q -
1.
Second type
Observe that we have B/ U = A. A character of A can therefore be viewed
as a character on B via B/U. We let:
l/JJ.t = resA(JL
0 det) , and view l/JJ.t therefore as a character on B. Thus
l/JJ.t(~
~) = JL(ad).
We obtain the induced character
l/J~ = ind~(l/JJ.t) .
Then
l/J~ is not simple. It contains JL 0 det , as one sees by Frobenius reciprocity:
< ind~ l/JI"
f.1 0 det> G = <l/JI" f.1 0 det>B =
(IS) L 1f.1 0 det(jJ)1
2 = I.
#
pEB
Characters X =
l/J~ -
JL
0 det will be called of second type .
The values on the representatives of conjugacy classes are as follows .
Table 12.5(11)
X
(~
~)
(~
~)
(~
~)d * a
a E C - F*
l/J~ -
JL
0 det
qJL(af
0
JL(ad)
- JL
0 det(a)
Actually, one computes the values of
l/J~ , and one then subtracts the value of
(J 0 del. For this case and the next two cases, we use the formula for the induced
function:
where 'PH is the function equal to 'P on Hand 0 outside H . An element of the
center commutes with all f3 E G, so for 'P = l/JJ.t the value of the induced character

718
REPRESENTATIONS OF FINITE GROUPS
on such an element is
#(G)
2 _
2
#(B) /J-(a)
-
(q + l)/J-(a) ,
XVIII, §12
which gives the stated value .
For an element u = (~
~) , the only elements f3 E G such that f3uf3-1 lies
in B are the elements of B (by direct verification). It is then immediate that
which yields the stated value for the character X. Using Table 12.4, one finds
at once that L IX(f3)12 = #(G) , and hence;
A character X of second type is simple.
The table of values also shows that there are q - 1 characters of second type.
The next two types deal especially with the Cartan subgroups.
Third type
riJ : A ~ C* denotes a homomorphism.
As mentioned following Proposition 12.3, the representative w = wA = W - I for
N(A)jA is such that
Thus conjugation by w is an automorphism of order 2 on A . Let [w] t/J be the
conjugate character; that is, ([w]t/J)(a) = t/J(waw) = t/J(a
W
) for a E A . Then
[w](,u 0 det) = i1 0 det. The characters,u 0 det on A are precisely those which are
invariant under [w] . The others can be written in the form
with distinct characters t/JI '
t/J2: F* ~ C*. In light of the isomorphism
Bj U = A, we view t/J has a character on B. Then we form the induced character
t/JG= ind~( t/J) = indj?([w] t/J) .
With t/J such that [w]«/J
=1= t/J, the characters X = t/JG will be said to be of the
third type. Here is their table of values.

XVIII, §12
EXAMPLE: GL2 OVER A FINITE FIELD
719
Table 12.5(111)
x
(~
~)
(~
~)
a = (~
~)d * a
a E C - F*
l/JG
(q + l)l/J(a)
l/J(a)
l/J(a) + l/J(aW)
0
l/J * [w]l/J
The first entry on central elements is immediate. For the second, we have already
seen that if f3 EGis such that conjugating
f3(~
~)f3-1 EB,
then f3 E B, and so the formula
l/JG(a) = #:B) f3~G l/JB(f3aW
1
)
immediately gives the value of ifP on unipotent elements. For an element of A
with a * d, there is the additional possibility of the normalizer of A with the
elements w, and the value in the table then drops out from the formula. For
elements of the non-split Cartan group, there is no element of G which conjugates
them to elements of B, so the value in the last column is O.
We claim that a character X = l/JG of third type is simple.
The proof again uses the test for simplicity, i.e. that 2:
1X(f3) 12 = #(G). Observe
that two elements a , a' E A are in the same conjugacy class in G if and only if
a' =
a or a ' = [w]a . This is verified by brute force . Therefore, writing the
sum 2: Il/JG(f3) 12 for f3 in the various conjugacy classes, and using Table 12.4,
we find:
2:
1l/JG(f3) I 2 = (q + 1)2(q -
1)
{kG
+ (q -
1)(q2 -
1) + (q2 + q)
2:
Il/J(a) + l/J(a")1 2.
a E(A -F*l/w
The third term can be written
~(q2 + q) aE~F* (l/J(a) + l/J(aW))(l/J(a - 1) + l/J(a - W))
= -21(q2 + q)
2:
(l + 1 + l/J(a l -w) + l/J(aw- I)) .
a EA - F*
We write the sum over a E A -
F* as a sum for a E A minus the sum for

720
REPRESENTATIONS OF FINITE GROUPS
XVIII, §12
a EO F* . If a EO F* then a 1- W = a W - I = 1. By assumption on l/J, the character
a'- l/J(al - w ) for a EO A
is non-trivial, and therefore the sum over a EO A is equal to O. Therefore, putting
these remarks together, we find that the third term is equal to
I2,(q2 + q)[2(q -
1)2 -
2(q -
I) -
2(q -
1)] = q(q2 -
I)(q - 3).
Hence finally
2: IrfP(,B)I2 = (q + 1)(q2 -
I) + (q -
1)(q2 -
I) + q(q2 -
I)(q -
3)
{3EG
= q(q -
1)(q2 -
I) = #(G),
thus proving that l/JG is simple.
Finally we observe that there are 4(q -
l)(q -
2) characters of third type .
This is the number of characters l/J such that [w]l/J * l/J, divided by 2 because
each pair l/J and [w]l/J yields the same induced character l/JG . The table of values
shows that up to this coincidence, the induced characters are distinct.
Fourth type
() : K* ~ C* denotes a homomorphism, which is viewed as a character on
C = CK •
By Proposition 12.3, there is an element w EO N(C) but w ¢ C, w = w- 1• Then
a'- waw = [w]a
is an automorphism of C, but x .- wxw is also a field automorphism of
F[C] = Kover F . Since [K: F] = 2, it follow s that conjugation by w is the auto-
morphism a .- a" , As a result we obtain the conjugate character [w](} such that
([w](})(a) =
(}([w]a) = (}(aw),
and we get the induced character
(}G = indg«(}) = indg([w](}) .
Let /-L : F * ~ C* denote a homomorphism as in the first type. Let:
A : F+ ~ C* be a non-trivial homomorphism.
(/-L, A) = the character on ZU such that
(/-L, A)((~
:)) = /-L(a)A(x).
(/-L, A)G = ind~u(/-L , A).

XVIII, §12
EXAMPLE: GL2 OVER A FINITE FIELD
721
A routine computation of the same nature that we have had previously gives the
following values for the induced characters OG and (fJ-, A)G.
x
(~ :)
(~
~)
(~
~)d * a
a E C - F*
OG
(q2 -
q)O(a)
0
0
O(a) + O(aW )
(fJ-, A)G
(q2 -
1)fJ-(a)
-fJ-(a)
0
0
These are intermediate steps . Note that a direct computation using Frobenius
reciprocity shows that OG occurs in the character (res 0, A)G, where the restriction
res 0 is to the group F*, so res 0 is one of our characters u: Thus we define:
0' = (res 0, A)G -
OG = ([w]O)',
which is an effective character. A character 0' is said to be of fourth type if 0
is such that 0 * [w] O. These are the characters we are looking for. Using the
intermediate table of values, one then finds the table of values for those characters
of fourth type.
Table 12.5(IV)
x
(~ :)
(~
~)
(~
~)d * a
a E C - F*
0'
(q -
I)O(a)
-O(a)
0
- O(a) -
O(a
W
)
0* [w]O
We claim that the characters 0' offourth type are simple .
To prove this, we evaluate
2: 10'(,8)1 2 = (q -
l)1:q -
1) + (q -
1)(q2 -
1)
I3EG
+ 4(q2 -
q) CXE'f;-F* IO(a) + O(a"')I2.
We use the same type of expansion as for characters of third type, and the final
value does turn out to be #(G), thus proving that 0' is simple.
The table also shows that there are4#(C - F*) = 4(q2 - q) distinct characters
of fourth type . We thus come to the end result of our computations.

722
REPRESENTATIONS OF FINITE GROUPS
XVIII, Ex
Theorem 12.6.
The irreducible characters of G = GL2(F) are as follows .
type
number of
dimension
that type
I
J.L 0 det
q -
1
1
II
l/J~ -
J.L 0 det
q -
1
q
III
l/JG from pairs l/J "* [w]l/J
1
q + 1
-(q -
1)(q - 2)
2
IV
()' from pairs () "* [w] ()
1-(q -
l)q
q -
1
2
Proof.
We have exhibited characters of four types . In each case it is imme-
diate from our construction that we get the stated number of distinct characters
of the given type . The dimensions as stated are immediately computed from the
dimensions of induced characters as the index of the subgroup from which we
induce, and on two occasions we have to subtract something which was needed
to make the character of given type simple. The end result is the one given in
the above table . The total number of listed characters is precisely equal to the
number of classes in Table 12.4, and therefore we have found all the simple
characters, thus proving the theorem.
EXERCISES
1. The group 83, Let 5 3 be the symmetric group on 3 elements,
(a) Show that there are three conjugacy classes .
(b) There are two characters of dimension I, on 53/ A3 •
(c) Let d, (i = 1, 2, 3) be the dimensions of the irreducible characters. Since
L: dr =
6, the third irreducible character has dimension 2. Show that
the third representation can be realized by considering a cubic equation
X3 + aX + b = 0, whose Galois group is 53 over a field k. Let V be the k-
vector space generated by the roots. Show that this space is 2-dimensional
and gives the desired representation, which remains irreducible after tensoring
with k'.
(d) Let G = 53' Write down an idempotent for each one of the simple components
of C[GJ. What is the multiplicity of each irreducible representation of G in
the regular representation on erG]?

XVIII, Ex
EXERCISES
723
2. The groups 54 and A 4 . Let 54 be the symmetric group on 4 elements.
(a) Show that there are 5 conjugacy classes.
(b) Show that A4 has a unique subgroup of order 4, which is not cyclic, and
which is normal in 54. Show that the factor group is isomorphic to 53' so
the representations of Exercise I give rise to representations of 54.
(c) Using the relation L d] = # (54) = 24, conclude that there are only two other
irreducible characters of 54' each of dimension 3.
(d) Let X4 + azXz + alX + ao be an irreducible polynomial over a field k, with
Galois group 54. Show that the roots generate a 3-dimensional vector space
V over k, and that the represe ntation of 54 on this space is irreducible, so
we obtain one of the two miss ing represe ntations.
(e) Let p be the representation of (d). Define pi by
p'(a) = p(a) if a is even ;
p' (a) = -p(a) if a is odd.
Show that pi is also irreducible, remains irreducible after tensoring with ka ,
and is non- isomorphic to p. Thi s concludes the description of all irreducible
representations of 54.
(f') Show that the 3-dimensional irreducible representations of 54 provide an
irreducible representation of A4 •
(g) Show that all irreducible representations ofA4 are given by the representations
in (f) and three others which are one-dimensio nal.
3. The quaternion group. Let Q = {± l , ±x, ±y, ±z} be the quaternion group, with
XZ = yZ = zZ = - I and xy = - yx, xz = - ZX, yz = - zy.
(a) Show that Q has 5 conjugacy classes.
Let A = {± I}. Then Q/ A is of type (2, 2), and hence has 4 simple characters ,
which can be viewed as simple characters of Q.
(b) Show that there is only one more simple character of Q, of dimensio n 2.
Show that the corre sponding representation can be given by a matrix rep-
rese ntation such that
( i
0)
( 0 I)
p(x ) =
0
- i
'
p(y) =
-I
0'
p(z) = G~) .
(c) Let H be the quatern ion field, i.e. the algebra over R having dimension 4,
with basis {I, x, y , z] as in Exercise 3, and the corresponding relations as
above. Sho w that C 0 RH = Matz(C ) (2 X 2 complex matrices). Relate this
to (b).
4. Let 5 be a normal subgroup of G. Let IjJ be a simple charac ter of 5 over C . Show
that indf (1jJ) is simple if and only if IjJ = [a] 1jJ for all a E S.
5. Let G be a finite group and 5 a normal subgroup. Let p be an irreducible representation
of Gover C . Prove that either the restriction of p to 5 has all its irreducible components
5-isomorphic to each other, or there exists a proper subgro up H of G contai ning 5
and an irreducible representation (J of H such that p = ind~((J ) .
6. Dihedral group D2n . There is a group of order 2n (n even integer ~ 2) generated
by two ele ments a , T such that

724
REPRESENTATIONS OF FINITE GROUPS
XVIII, Ex
It is called the dihedral group.
(a) Show that there are four representations of dimension I, obtained by the four
possible values ± I for a and T.
(b) Let Cn be the cyclic subgroup of DZn generated by cr. For each integer
r = 0, . . . , n -
I let r/Jr be the character of Cn such that
r/Jr((J) = ('
(( = prim. n-th root of unity)
Let X; be the induced character. Show that Xr = Xn-r'
(c) Show that for 0 < r < n/2 the induced character Xr is simple, of dimension
2, and that one gets thereby (~ - I) distinct characters of dimension 2.
(d) Prove that the simple characters of (a) and (c) give all simple characters of
DZn'
7. Let G be a finite group, semidirect product of A, H where A is commutative and
normal. Let A" = Hom(A, C*) be the dual group . Let G operate by conjugation on
characters, so that for o E G, a E A, we have
Let r/JI' .. . , r/Jr be representatives of the orbits of H in A", and let H i(i = I, . . . , r)
be the isotropy group of r/Ji' Let G, = AHi.
(a) For a E A and h E Hi, define r/Ji(ah) = r/Ji(a) . Show that r/Ji is thus extended
to a character on Gi.
Let 0 be a simple representation of Hi (on a vector space over C). From
Hi = GJA, view 0 as a simple representation of Gi. Let
Pi.8 = indg,(l/Ji @ 0).
(b) Show that Pi.8is simple .
(c) Show that Pi.8 "'" Pi:8' implies i = i' and 0"'" (}/.
(d) Show that every irreducible representation of G is isomorphic to some Pi.(J
8. Let G be a finite group operating on a finite set S. Let qSj be the vector space
generated by S over C . Let r/J be the character of the corresponding representation
of G on qSj .
(a) Let a E G. Show that r/J(cr) = number of fixed points of a in S.
(b) Show that (r/J, IC>G is the number of G-orbits in S.
9. Let A be a commutative subgroup of a finite group G. Show that every irreducible
representation of Gover C has dimension ~ (G : A) .
10. Let F be a finite field and let G = SLz(F) . Let B be the subgroup of G consisting of
all matrices
Let IL : F* -- C* be a homomorphism and let r/JIL : B -- C* be the homomorphism
such that r/JIL(a) =
lL(a) . Show that the induced character
ind~(r/JIL) is simple if
ILz *" 1.

XVIII, Ex
EXERCISES
725
II. Determine all simple characters of SLz(F ), giving a table for the number of such
characters. representatives for the conjugacy classes. as was done in the text for GLz,
over the complex numbers.
12. Observe that As ~ SLz(F4 ) ~ PSLz(Fs)' As a result. verify that there are 5 conjugacy
classes, whose clements have orders I, 2. 3, 5, 5 respectively. and write down
explicitly the character table for As as was done in the text for GLz.
13. Let G be a p-group and let G -+ Aut(V) be a representation on a finite dimen sional
vector space over a field of characteristic p. Assume that the representation is irre-
ducible. Show that the representat ion is trivial , i.e . G acts as the identity on V.
14. Let G be a finite group and let C be a conjugacy class. Prove that the following two
conditions are equivalent. They define what it means for the class to be rational.
RAT 1. For all characters X of G. X(0') E Q for 0' E C.
RAT 2. For all 0' E C, and j prime to the order of 0', we have a! E C.
15. Let G be a group and let HI ' Hz be subgroups of finite index . Let PI' P: be repre-
sentations of HI. Hz on R-module s F l. Fz respectively . Let MG(F1, Fz) be the R-
module of functions j : G -+ HomR(FI. Fz) such that
!(hluhz) = Pz(hz)!(U)PI(h l )
for all 0' E G, hi E Hi (i = 1, 2). Establish an R-module isomorphism
HomR(F f . Fy )"'::' MG(FI, Fz).
By Ff we have abbreviated
ind ~ i(FJ.
16. (a) Let GJ, Gz be two finite groups with representat ions on C-spaces E J, Ez. Let
E 1 @ Ez be the usual tensor product over C, but now prove that there is an action
of GJ x Gz on this tensor product such that
( 0'1' uz)(x @ y) = UIX @ uzy for 0'1 E G 1• Uz E Gz.
This action is called the tensor product of the other two. If PJ, pz are the
representations of G I . Gz on EI . Ez respectively, then their tensor product is
denoted by PI @ Pz. Prove: If PI' pzare irreducible then pz@ pzis also irreducible.
[Hint : Use Theorem 5.17.]
(b) Let XI. Xz be the characters of PI' pz respectively. Show that XJ @ Xz is the
character of the tensor product. By definition.
17. With the same notation as in Exercise 16. show that every irreducible representation
of G I x Gz over C is isomorphic to a tensor product representation as in Exercise
16. [Hint : Prove that if a character is orthogonal to all the products XI @ Xz of
Exercise 16(b) then the character is 0.]
Tensor product representations
18. Let P be the non -commutative polynomial algebra over a field k, in n variables. Let
X I • • • . , x, be distinct element s of PI (i.e. linear expressions in the variables tl' ... , tn)

726
REPRESENTATIONS OF FINITE GROUPS
and let at> ... , a, E k. If
XVIII, Ex
for all integers v = 1, .. . , r show that ai = 0 for i = 1,. .. , r.
[Hint :
Take the
homomorphism on the commutative polynomial algebra and argue there.]
19. Let G be a finite set of endomorphisms of a finite-dimensional vector space E over the
field k. For each a E G, let c" be an element of k. Show that if
L c, T'(a) = 0
" EG
for all integers r ~ 1, then c" = 0 for all a E G. [Hint :
Use the preceding exercise, and
Proposition 7.2 of Chapter XVI.]
20. (Steinberg). Let G be a finite monoid, and k[G] the monoid algebra over a field k. Let
G -+ Endk(E) be a faithful representation (i.e. injective), so that we identify G with a
multiplicative subset of Endk(E). Show that T' induces a representation of G on T'(E),
whence a representation of keG] on T'(E) by linearity. If ex E keG] and if T'(ex) = 0 for
all integers r ~ 1,show that ex = O. [Hint :
Apply the preceding exercise.]
21. (Burnside). Deduce from Exercise 20 the following theorem of Burnside: Let G be
a finite group, k a field of characteristic prime to the order of G, and E a finite
dimensional (G, k)-space such that the representation of G is faithful. Then every
irreducible representation of G appears with multiplicity ~ 1 in some tensor power
F(E) .
22. Let X(G) be the character ring of a finite group G, generated over Z by the simple
characters over C. Show that an elementf E X(G) is an effective irreducible character
if and only if (J,f)G = I andf(l) ~ O.
23. In this exercise, we assume the next chapter on alternating products. Let p be an
irreducible representation of G on a vector space E over C. Then by functoriality we
have the corresponding representat ions S'(p) and /'( p) on the r-th symmetric power
and r-th alternating power of E over C. If X is the character of p, we let S'(X) and
/'(X) be the characters of S'(p) and /'( p) respectively , on S'(E) and /'( E ). Let t
be a variable and let
'"
'"
O'/(X) = 2: S'(X)t',
A/(X) = 2: /'((X)t' .
, -0
,-0
(a) Comparing with Exercise 24 of Chapter XIV, prove that for x E G we have
O'/(X)(x) = det(l -
p(X)t)-1
and
A,(X)(x) = det(l + p(x)t).
(b) For a functionfon G define 1Jtn(j) by 1Jtn(f)(x) = [ix''), Show that
d
co
d
eo
--log O'ix) = 2: 1Jtn(xW
and
--dlog L,(X) = 2: 1Jtn(x)r ,
dt
n-l
t
n = 1
(c) Show that
n
nSn(x) = 2: 1Jt'(X)sn-,(X)
and
r =l
'"
n(\n(x) = 2: (-I)'- I 1Jt' (X)!\n- ,(X).
r=l

XVIII, Ex
EXERCISES
727
24. Let X be a simple character of G. Prove that pn(X) is also simple . (The characters
are over C.)
25. We now assume that you know §3 of Chapter XX.
(a) Prove that the Grothendieck ring defined there for ModC<G) is naturally
isomorphic to the character ring X(G).
(b) Relate the above formulas with Theorem 3.12 of Chapter XX.
(c) Read Fulton-Lang's Riemann-Rocli Algebra, Chapter I, especially §6, and
show that X(G) is a A-ring, with pn as the Adams operations.
Note. For further connections with homology and the cohomology of groups, see
Chapter XX, §3, and the references given at the end of Chapter XX, §3.
26. The following formalism is the analogue of Artin's formalism of L-series in number
theory. Cf. Artin's " Zur Theorie der L-Reihen mit allgemeinen Gruppenchar-
akteren", Collected papers, and also S. Lang, "L-series of a covering", Proc. Nat.
Acad. Sc. USA (1956). For the Artin formalism in a context of analysis, see J. Jor-
genson and S. Lang, "Artin formalism and heat kernels", J. reine angew. Math. 447
(1994) pp. 165-200.
We consider a category with objects {V}. As usual, we say that a finite group G
operates on V ifwe are given a homomorphism p :G --+ Aut(V). We then say that V is a
G-object, and also that p is a representation of Gin V. We say that G operates trivially
if peG) = id. For simplicity, we omit the p from the notation. By a G-morphism
f :V --+ V between G-objects, one means a morphism such thatf 0 (J =
(J
0 ffor all (J E G.
We shall assume that for each G-object V there exists an object V/G on which G
operates trivially, and a G-morphism TCv. G : V --+ V/G having the following universal
property : Iff :V --+ V' is a G-morphism, then there exists a unique morphism
f /G : V /G --+ V '/G
making the following diagram commutative:
V~V '
j
j
V/G~V '/G
In particular, if H is a normal subgroup of G, show that G/H operates in a natural way
on V/H .
Let k be an algebraically closed field of characteristic O. We assume given a functor
E from our category to the category of finite dimensional k-spaces. If V is an object in
our category, andJ: V --+ V' is a morphism, then we get a homomorphism
E(f) = [; : E(V) --+ E(V').
(The reader may keep in mind the special case when we deal with the category of
reasonable topological spaces, and E is the homology functor in a given dimension.)
If G operates on V , then we get an operation of G on E(V) by functoriality.
Let V be a G-object, and F : V --+ VaG-morphism. If PAt) = n(t - aJ is the
characteristic polynomial of the linear map F*:E(V) --+ E(V), we define
ZF(t) = n(1 -
IXjt),

728
REPRESENTATIONS OF FINITE GROUPS
XVIII, Ex
and call this the zeta function of F. If F is the identity, then ZF(t) = (I -
t)B(U) where
we define R(U) to be dim, E(U).
Let Xbe a simple character of G. Let dx be the dimension of the simple representation
of G belonging to X, and n = ord (G). We define a linear map on E(U) by letting
Show that e; = ex' and that for any positive integer II we have (ex 0 F*)P = ex 0 F~ .
If Pi t) = IT (t - Pix» is the characteristic polynomial of ex 0 F*, define
LFCt, x. U/G) = IT (1 - Pix)t).
Show that the logarithmic derivative of this function is equal to
Define LF(t, x, U/G) for any character Xby linearity. If we write V = U/G by abu se of
notation, then we also write LF(t, x, UIV). Then for any x, x' we have by definition,
We make one additional assumption on the situation :
Assume that the characteristic polynomial of
isequalto the characteristic polynomialofF/G on E(U/G). Prove the following statement:
(a) IfG = {I} then
(b) Let V = U/G. Then
(c) Let H be a subgroup of G and let rjJ be a character of H. Let W = U/H, and let
rjJGbe the induced character from H to G. Then
(d) Let H be normal in G. Then G/H operates on U/H = W. Let rjJ be a character
of G/H, and let X be the character of G obtained by composing rjJ with the
canonical map G -> G/H. Let qJ = F/H be the morphism induced on
U/H = W.
Then
L,p(t, rjJ, W/V) = LF(t, x. U/V).
(e) If V = U/G and R(V) = dim, E( V), sho w that (1 -
t)B(V) divides (1 - tl(U).
Use the regular character to determine a factorization of (1 - tllU).

XVIII, Ex
EXERCISES
729
27. Do this exercise after you have read some of Chapter VII . The point is that for fields
of characteristic not dividing the order of the group, the representations can be obtained
by "reducing modulo a prime". Let G be a finite group and let p be a prime not
dividing the order of G. Let F be a finite extension of the rationals with ring of
algebraic integers OF' Suppose that F is sufficiently large so that all F-irreducible
representations of G remain irreducible when tensored with Qa = Fa. Let p be a
prime of OF lying above p, and let op be the corresponding local ring . .
(a) Show that an irreducible (G, F)-space V can be obtained from a (G, op)-
module E free over oj., by extending the base from o, to F, i.e . by tensoring
so that V = E Q9 F (tensor product over op).
(b) Show that the reduction mod p of E is an irreducible representation of G in
characteristic p . Inother words, let k =011'=op /mp where mp is the maximal
ideal of op. Let E(p) = E Q9 k (tensor product over op). Show that G operates
on E( 1') in a natural way , and that this representation is irreducible. In fact,
if X is the character of G on V, show that X is also the character on E, and
that X mod rn p is the character on E(1').
(c) Show that all irreducible characters of G in characteristic p are obtained as
in (b).

CHAPTER XIX
The Alternating Product
The alternating product has applications throughout mathematics. In differ-
ential geometry, one takes the maximal alternating product of the tangent space
to get a canonical line bundle over a manifold. Intermediate alternating products
give rise to differential forms (sections of these products over the manifold). In
this chapter, we give the algebraic background for these constructions.
For a reasonably self-contained treatment of the action of various groups of
automorphisms of bilinear forms on tensor and alternating algebras, together
with numerous classical examples, I refer to:
R. HOWE, Remarks on classical invariant theory, Trans. AMS 313 (1989),
pp. 539-569
§1
DEFINITION AND BASIC PROPERTIES
Consider the category of modules over a commutative ring R.
We recall that an r-multilinear map f: E(') --+ F is said to be alternating
if!(XI, ... , x.) = 0 whenever Xi = Xj for some i =1= j.
Let ar be the submodule of the tensor product F(E) generated by all elements
of type
Xl @ . . . @x,
where Xi = x j for some i =1= j. We define
/\'(E) = T'(E)/a,.
Then we have an r-multilinear map E(') --+ /\'(E) (called canonical) obtained
731
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

732
THE ALTERNATING PRODUCT
from the composition
E(r) --+ Tr(E) --+ T'(Ei]«, = /\ r(E).
XIX, §1
It is clear that our map is alternating. Furthermore, it is universal with respect
to r-multilinear alternating maps on E. In other words, iff :E(r) --+ F is such a
map, there exists a unique linear map f* : /\r(E) --+ F such that the following
diagram is commutative:
/\r(E)
E(r)/l f.
<. F
Our map f* exists because we can first get an induced map r(E) --+ F making
the following diagram commutative:
and this induced map vanishes on an hence inducing our f* .
The image of an element
(XI "
' " x.) E E(r) in the canonical map into
/\r(E) will be denoted by Xl /\ ... /\ x. . It is also the image of Xl ® . .. ® x, in
the factor homomorphism Tr(E) --+ /\r(E).
In this way, r: becomes a functor, from modules to modules. Indeed, let
u: E ~ F be a homomorphism. Given elements XI , . . . , x, E E, we can map
(xI>' . . , xr) ~ U(XI) 1\ • • • 1\ u(xr) E Ar(F).
This map is multilinear alternating, and therefore induces a homomorphism
A r(u): Ar(E) ~ Ar(F).
The association u ~ Ar(u) is obviously functorial.
Example.
Open any book on differential geometry (complex or real) and
you will see an application of this construction when E is the tangent space of
a point on a manifold, or the dual of the tangent space . When taking the dual,
the construction gives rise to differential forms .
We let /\(E) be the direct sum
00
/\ (E) = EB /\r(E).
r=O

XIX, §1
DEFINITION AND BASIC PROPERTIES
733
We shall make I\(E) into a graded R-algebra and call it the alternating algebra
of E, or also the exterior algebra, or the Grassmann algebra. We shall first
discuss the general situation, with arbitrary graded rings .
Let G be an additive monoid again, and let A = EB A r be a G-graded
reG
R-algebra. Suppose given for each A r a submodule an and let a = EB o..
reG
Assume that a is an ideal of A . Then a is called a homogeneous ideal, and we can
define a graded structure on A/a. Indeed, the bilinear map
sends o, x Asinto ar +sand similarly, sends Ar x asinto ar +s' Thus using repre-
sentatives in An Asrespectively, we can define a bilinear map
and thus a bilinear map A/a x A/a -+ A/a, which obviously makes A/a into a
graded R-algebra.
We apply this to r(E) and the modules u, defined previously. If
in a product X l
II. . . . II. x., then for any Yl " ' " Ys E E we see that
Xl
II. .. . II. x, II. Yl
II. .. . II. Ys
lies in ar +s ' and similarly for the product on the left. Hence the direct sum EB o,
is an ideal of T(E), and we can define an R-algebra structure on T(E)/a. The
product on homogeneous elements is given by the formula
We use the symbol II. also to denote the product in I\(E). This product is called
the alternating product or exterior product. If x
E E and y
E E, then
x A y = - y A x , as follows from the fact that (x + y) A (x + y) = O.
We observe that 1\ is a functor from the category of modules to the category
ofgraded R-algebras. To each linear map f : E -+ F we obtain a map
rs»:I\(E) -+ I\(F)
which is such that for Xl ' ... , x, E E we have
Furthermore, I\(f) is a homomorphism of graded R-algebras.

734
THE ALTERNATING PRODUCT
XIX, §1
Proposition 1.1. Let E be free of dimension n over R. If r >I n then
I\r(£) = O.
Let { VI' . . . , vn} be a basis of E over R. If I ~ r ~ n, then
I\r(£) is free over R, and the elements
form a basis of I\r(E) over k. We have
dim, I\r(E) = (~).
Proof
We shall first prove our assertion when r = n. Every element of E
can be written in the form L ai Vi> and hence using the formula x /\ y =
- y /\ X
we conclude that VI /\ •. • /\ Vngenerates I\n(E). On the other hand, we know
from the theory of determinants that given a E R, there exists a unique multi-
linear alternating form fa on E such that
Consequently, there exists a unique linear map
taking the value
a on
VI /\ ' "
/\ Vn •
From this it follows at once that
VI /\ •• • /\ Vnis a basis of I\n(E) over R.
We now prove our statement for I ~ r ~ n. Suppose that we have a relat ion
0= "a(.)v. /\ ... /\ v·
L
I
I I
I,.
with i 1 < . .. < irand a ti ) E R. Select any r-tuple (j) = (j1> • . • , ir) such that
il < .,. < ir and letjr +I" " .i, be those values of i which do not appear among
01, ' " ,i r)' Take the alternating product with vi,+I
/\
. .
• /\ vin' Then we shall
have alternating products in the sum with repeated components in all the terms
except the (j)-term, and thus we obtain
Reshuffling
Vii
/\ .. . /\ vin into VI /\ ••• /\ Vn simply changes the right-hand
side by a sign. From what we proved at the beginning of this proof, it follows
that a(j) = 0. Hence we have proved our assertion for I ~ r ~ n.
When r = 0, we deal with the empty product, and I is a basis for 1\O(E) = R
over R. We leave the case r > n as a trivial exercise to the reader.
The assertion concerning the dimension is trivial, considering that there is a
bijection between the set of basis elements, and the subsets of the set of integers
(1, . .. , n).

XIX, §1
DEFINITION AND BASIC PROPERTIES
735
Remark.
It is possible to give the first part of the proof, for I\n(E), without
assuming known the existence of determinants. One must then show that an
admits a l-dimensional complementary submodule in Tn(E). This can be done
by simple means, which we leave as an exercise which the reader can look up
in the more general situation of §4. When R is a field, this exercise is even more
trivial, since one can verify at once that VI @ . .. @ u; does not lie in an- This
alternative approach to the theorem then proves the existence of determinants.
Proposition 1.2.
Let
o~ E' ~ E ~ E" ~ 0
be an exact sequence offree R-modules offinite ranks r, n, and s respectively.
Then there is a natural isomorphism
cp : I\rE' 0 I\s E" ~ 1\-e.
This isomorphismis the uniqueisomorphismhaving thefollowing property. For
elements VI ' . . . , u; E E' and WI' . .. , Ws E E", let UI . . . . , Us be liftings of
WI • . . . , Ws in E. Then
CP«VI /\ . .. /\ vr) @ (wI /\ .. . /\ ws)) = VI /\ . .. /\ Vr /\ UI /\ . . . /\ us'
Proof.
The proof proceeds in the usual two steps. First one shows the
existence of a homomorphism cP having the desired effect. The value on the right
of the above formula is independent of the choice of UI " . . , Us lifting
wI' . . . , W s by using the alternating property, so we obtain a homomorphism cp.
Selecting in particular {VI' . . . , vr } and {WI' ... , ws } to be bases of E' and E"
respectively, one then sees that cp is both injective and surjective. We leave the
details to the reader.
Given a free module E of rank n, we define its determinant to be
det E = I\maxE = 1\-t:
Then Proposition 1.2 may be reformulated by the isomorphism formula
det(E') 0 det(E") = det(E).
If R = k is a field, then we may say that det is an Euler-Poincare map on the
category of finite dimensional vector spaces over k.
Example.
Let V be a finite dimensional vector space over R. By a volume
on V we mean a norm IIII on det V. Since V is finite dimensional , such a norm
is equivalent to assigning a positive number c to a given basis of det(V) . Such
a basis can be expressed in the form el /\ . .. /\ en' where {e. , ... , en} is a basis
of V. Then for a E R we have
Ilael /\ .. . /\ enll = laic.

736
THE ALTERNATING PRODUCT
XIX, §1
In analysis, given a volume as above, one then defines a Haar measure JL on V
by defining the measure of a set S to be
JL(S) =f llel II ... II enll dx , ... dxn,
s
where xI ' . . . , xn are the coordinates on V with respect to the above basis. As
an exercise, show that the expression on the right is the independent of the choice
of basis.
Proposition 1.2 is a special case of the following more general situation. We
consider again an exact sequence of free R-modules of finite rank as above . With
respect to the submodule E' of E, we define
1\7E = submodule of I\nEgenerated by all elements
XiI /\ . .. /\ x; /\ Yi+I /\ . . . /\ Yn
with XiI' . . . , x; E E' viewed as submodule of E.
Then we have a filtration
Proposition 1.3. There is a natural isomorphism
Proof
Let x';, . .. ,x:-i be elements of E", and lift them to elements
YI' . . . , Yn-i of E. We consider the map
(X'I"'" xi, x';,... , X:-i)
t---+ X'I /\ ... /\ xi /\ YI /\ ... /\ Yn- i
with the right-hand side taken mod 1\7+IE. Then it is immediate that this map
factors through
and picking bases shows that one gets an isomorphism as desired.
In a similar vein, we have :
Proposition 1.4.
Let E = E' EB E" be a direct sum of finite fr ee modules.
Then for every positive integer n, we have a module isomorphism
I\nE ~ EB I\PE' ® I\qE".
p+q=n

XIX, §1
DEFINITION AND BASIC PROPERTIES
737
In terms ofthe alternating algebras, we have an isomorphism
I\E:=:: I\E' @su I\E".
where @su is the superproduct of graded algebras.
Proof.
Each natural injection of E' and E" into E induces a natural map on
the alternating algebras, and so gives the homomorphism
I\E' @ I\E" -+ I\E,
which is graded, i.e. for p = 0, . . . , n we have
To verify that this yields the desired isomorphism, one can argue by picking
bases, which we leave to the reader. The anti-commutation rule of the alternating
product immediately shows that the isomorphism is an algebra isomorphism for
the super product I\E' e; I\E".
We end this sect ion with comments on duality. In Exercise 3, you will prove:
Proposition 1.5.
Let E be free of rank n over R. For each positive integer
r, we have a natural isomorphism
The isomorphism is explicitly described in that exercise. A more precise property
than "natural" would be that the isomorphism is functorial with respect to the
category whose objects are finite free modules over R, and whose morphisms
are isomorphisms.
Examples.
Let L be a free module over R of rank 1. We have the dual
module LV = HomR(L, R), which is also free of the same rank . For a positive
integer m, we define
L@-m = (LV)@m = LV@ . . . 0 LV (tensor product taken m times) .
Thus we have defined the tensor product of a line with itself for negative integers.
We define L@O = R. You can easily verify that the rule
L@P 0 L@q :=:: L@(p+q)
holds for all integers p, q E Z, with a natural isomorphism. In particular, if
q = -p then we get R itself on the right-hand side .
Now let E be an exact sequence of free modules:

738
THE ALTERNATING PRODUCT
We define the determinant of this exact sequence to be
det(E) = ® det(Eiy~(-I ); .
XIX, §2
As an exercise, prove that det(E) has a natural isomorphism with R, functorial
with respect to isomorphisms of exact sequences.
Examples.
Determinants of vector spaces or free modules occur in several
branches of mathematics, e.g. complexes of partial differential operators, homol-
ogy theories, the theory of determinant line bundles in algebraic geometry, etc .
For instance, given a non-singular projective variety V over C, one defines the
determinant of cohomology of V to be
det H(V) = ® det H i(V)0(-Ii,
where Hi(V) are the cohomology groups. Then det H(V) is a one-dimensional
vector space over C, but there is no natural identification of this vector space
with C, because a priori there is no natural choice of a basis. For a notable
application of the determinant of cohomology, following work of Faltings, see
Deligne, Le determinant de la cohomologie, in Ribet, K. (ed.) , Current Trends
in ArithmeticalAlgebraic Geometry, Proc . Arcata 1985. (ContemporaryMath. vol
67, AMS (1985) , pp. 93-178.)
§2.
FITTING IDEALS
Certain ideals generated by determinants are coming more and more into
use, in several branches of algebra and algebraic geometry. Therefore I include
this section which summarizes some of their properties. For a more extensive
account, see Northcott's book Finite Free Resolutions which I have used, as well
as the appendix of the paper by Mazur-Wiles :"Class Fields of abelian extensions
of Q," which they wrote in a self-contained way . (Invent. Math. 76 (1984), pp.
179-330.)
Let R be a commutative ring . Let A be a p x q matrix and B a q x s matrix
with coefficients in R. Let r ~ 0 be an integer. We define the determinant ideal
Ir(A) to be the ideal generated by all determinants of r x r submatrices of A.
This ideal may also be described as follows. Let S~ be the set of sequences
J = ii.....,jr) with 1 ~ i, < i, <
< jr ~ p.
Let A = (aij)' Let 1 ~ r ~ min(p, q). Let K = (k \,
, kr ) be another element
of S~. We define
ahk,
ahk2
«»:
A(r) -
ahk,
ahk2
ahkr
JK
-
«»,
ajrk2
ajrkr

XIX, §2
FITTING IDEALS
739
where tile vertical bars denote the determinant. With J, K ranging over
S~
we may view A1k as the JK-component of a matrix A(r) which we call the r-th
exterior power of A.
One may also describe the matrix as follcws . Let {e. , . . . , ep } be a basis of
RP and {u" . . . , uq } a basis of R", Then the elements
e, /\ .. . /\ e,
)1
J,.
form a basis for !\RP and similarly for a basis of !\Rq. We may view A as a
linear map of RP into R", and the matrix AIr)is then the matrix representing the
exterior power !\rA viewed as a linear map of !\RP into !\Rq. On the whole,
this interpretation will not be especially useful for certain computations, but it
does give a slightly more conceptual context for the exterior power. Just at the
beginning, this interpretation allows for an immediate proof of Proposition 2.1 .
For r = 0 we define A(O) to be the 1 x 1 matrix whose single entry is the
unit element of R. We also note that A(1) = A.
Proposition 2.1.
Let A be a p X q matrix and B a q X s matrix. Then
If one uses the alternating products as mentioned above, the proof simply
says that the matrix of the composite of linear maps with respect to fixed bases
is the product of the matrices. If one does not use the alternating products, then
one can prove the proposition by a direct computation which will be left to the
reader.
We have formed a matrix whose entries are indexed by a finite set S~. For
any finite set S and doubly indexed family (cJ K ) with J, K E S we may also
define the determinant as
det(C}K) = L E(O')(n C}.G(}))
G
} eS
where 0' ranges over all permutations of the set.
For r ~ 0 we define the determinant ideallr(A) to be the ideal generated by
all the components of A(r), or equivalently by all r x r subdeterminants of A.
We have by definition
A(O) = Rand
A(1) = ideal generated by the components of A.
Furthermore
l/A) = 0
for
r> min(p, q)
and the inclusions

740
THE ALTERNATING PRODUCT
By Proposition 10.1, we also have
XIX, §2
( I)
fr(AB) c fr(A) n fr(B).
Therefore, if A = VBV' where V, V' are square matrices of determinant I, then
(2)
fr(A) = [reB).
Next, let E be an R-module. Let Xl' . . . , x q be generators of E. Then we
may form the matrix of relations (ai ' .. . , aq) E Rq such that
qL a j Xj = O.
j= I
Suppose first we take only finitely many relations, thus giving rise to a p x q
matrix A. We form the determinant ideal [rCA). We let the determinant ideals
of the family of generators be :
[r(X I" ", xq) = fr(x) = ideal generated by fr(A) for all A.
Thus we may in fact take the infinite matrix of relations, and say that [rex) is
generated by the determinants of all r x r submatrices. The inclu sion relations
of (I ) show that
R = f o(x)::> fl(x)::> fix)::> ...
fr(x) = 0
if
r > q.
Furthermore, it is easy to see that if we form a submatrix M of the matrix of all
relations by taking only a family of relations which generate the ideal of all
relations in R'', then we have
fr(M) = [rex).
We leave the verification to the reader. We can take M to be a finite matrix when
E is finitely presented, which happens if R is Noetherian.
In terms of this representation of a module as a quotient of R", we get the
following characterization.
Proposition 2.2.
Let Rq ~ E ~ 0 be a representation of E as a quotient of
Rq, and let Xl"
' "
xq be the images of the unit vectors in R", Then fr(x) is the
ideal generated by all values
where WI' .. . , w, E Ker(Rq -+ E) and A. E L~(Rq , R).
Proof.
This is immediate from the definition of the determinant ideal.

XIX, §2
FiniNG IDEALS
741
The above proposition can be useful to replace a matrix computation by a
more conceptual argument with fewer indices. The reader can profitably trans-
late some of the following matrix arguments in these more invariant terms.
We now change the numbering, and let the Fitting ideals be:
when
k » q.
Lemma 2.3.
The Fitting ideal Fk(x) does not depend on the choice of
generators (x).
Proof.
Let YI' . . . , Ysbe elements of E. We shall prove that
Ir(x) = Ir+,(x, y).
The relations of (x, y) constitute a matrix of the form
all
al q
0
0
w=
a p l
a pq
0
0
bll
b l q
I
0
0
bSI
bsq
0
By elementary column operations, we can change this to a matrix
and such operations do not change the determinant ideals by (2). Then we
conclude that for all r ~ 0 we have
Ir(A) = Ir+.(W) c Ir+.(x, y).
This proves that Ir(x) c Ir+.(x, y).
Conversely, let C be a matrix of relations between the generators (x, y).
We also have a matrix of relations
z=
C
By elementary row operations, we can bring this matrix into the same shape

742
THE ALTERNATING PRODUCT
as B above, with some mat rix of relati ons A' for (x), namel y
Then
XIX, §2
whence Ir+s(C) c Ir(x). Taking all possible matrices of relations C sho ws
that Ir+.(x, y) c Ilx), which combined with the previous inequality yields
Ir+.(x , y) = Ir(x).
Now given two families of generators (x) and (y), we simply put them side
by side (x, y) and use the new numbering for the F, to conclude the proof of
the lemma.
Now let E be a finitely generated R-module with presentation
°-+ K -+ Rq -+ E -+ 0,
where the sequence is exact and K is defined as the kernel. Then K is generated
by q-vectors, and can be viewed as an infinite matrix. The images of the unit
vectors in Rq are generators (x I ' ... ,xq). We define the Fitting ideal of the
module to be
Lemma 2.3 shows that the ideal is independent of the choice of presentation.
The inclu sion relations of a determinant ideal I/A ) of a matrix now translate
into reverse inclusion relations for the Fitting ideal s, namel y:
Proposition 2.4.
(i) We have
(ii) If E can be generated by q elements, then
(iii) If E isfinitely presented then Fk(E) is finitely generatedfor all k.
Thi s last statement merely repe ats the property that the determinant ideals of a
matrix can be genera ted by the determinants associated with a finite submatrix
if the row space of the matrix is finitely generated.

XIX, §2
FITTING IDEALS
743
Example.
Let E = Rqbe the free module of dimension q. Then :
if
0 ~ k < q
if
k ~ q.
This is immediate fro m the definitions and the fact that the only relati on of a
basis for E is the tri vial one.
The Fitting ideal Fo(E) is called the zero-th or initial Fitting ideal. In some
applications it is the onl y one which comes up, in which case it is called " the"
Fitting ideal F(E) of E. It is the ideal generated by all q x q determinants in
the matrix of relations of q generato rs of the module.
For an y module E we let annR(E) be the annihilator of E in R, that is the
set of elements a E R such that aE = O.
Proposition 2.5 .
Suppose that E can be generated by q elements. Then
In particular, if E can be generated by one element, then
F(E) = annR(E).
Proof.
Let Xl ' .. . , xq be generators of E. Let a l , . . . , aq be elements of R
annihilating E. Then the diagonal matrix whose diagonal components are
a l , • .• , aq is a mat rix of relations, so the definition of the Fitting ideal shows
that the determinant of this mat rix, which is the product al .. . aq lies in
Iq(E) c Fo(E). This proves the inclusion
annR(E)q c F(E).
Con versely, let A be a q x q matrix of relations between X I"
'" xq • Then
det(A)xj = 0 for all i so det(A) E annR(E). Since F(E) is generated by such
determinants, we get the reverse inclusion which proves the proposition .
Corollary 2.6.
Let E = Ria for some ideal a. Then F(E) = a.
Proof.
The module Ria can be generated by one element so the corollary
is an immediate consequence of the proposition.
Proposition 2.7.
Let
o-> E' -> E -> En -> 0
be an exact sequence offinite R-modules. For integers m, n ~ 0 we have

744
THE ALTERNATING PRODUCT
/11 particular for F = Fo.
F(E')F(E") c F(E).
XIX, §2
Proof.
We may assume E' is a submodule of E. We pick generators
X I"
'"
x p of E' and elements YI" ' " Yq in E such that their images i ;, ...,Y;
in E" generate E". Then (x , y) is a family of generators for E. Suppose first that
m ~ p and
11 ~ q. Let A be a matrix of relations among y';, ... , Y; with q
columns. If (aI' . . . , aq) is such a relation, then
so there exist elements bl , . . . , b, E R such that
I aiJ'i + L bjXj = O.
Thus we can find a matrix B with p columns and the same number of rows as
A such that (B, A) is a matrix of relations of (x, y). Let C be a matrix of relations
of (XI"' " x p ) . Then
is a matrix of relations of (x, y). If D" is a (q -
11) X (q -
11) subdeterminant of
A and D' is a (p - m) x (p -
m) subdeterminant of C then D"D' is a
(p + q - m - n) x (p + q - m -
11)
subdeterminant of the matrix
and D"D' E Fm+n(E).
Since Fm(E') is generated by determinants like D' and
Fn(E") is generated by determinants like D", this proves the proposition in the
present case.
Ifm > pandn > q then Fm+n(E) = Fm(E') = Fn(E") = Rsotheproposition
is trivial in this case.
Say m ~ p and n > q. Then FiE") = R = FiE") and hence
Fm(E')Fn(E") = FiE")Fm(E') c Fp+iE) c
Fm +n(E)
where the inclusion follows from the first case. A similar argument proves
the remaining case with m > p and n ~ q. This concludes the proof.
Proposition 2.8.
Let E', E" be finite R-modules. For any integer n ~ 0 we
have
Fn(E' EB E") = I
F,(E')F.(E").
r+s=n

XIX, §2
FITTING IDEALS
745
Proof.
Let xI' .. . , xp generate Ei and YI' . . . , Yq generate E". Then (x, Y)
generate E' EB E". By Proposition 2.6 we know the inclusion
LFr(E')Fs(E") c FiE' EB E"),
so we have to prove the converse. If n ~ p + q then we can take r ~ p and
s ~ q in which case
and we are done. So we assume n < p + q. A relation between (x, y) in the
direct sum splits into a relation for (x) and a relation for (y). The matrix of
relations for (x, y) is therefore of the form
(
A' 0)
C =
0
A"
where A' is the matrix of relations for (x) and A" the matrix of relations for
(y). Thus
Fn(E' EB E") = 2:)p+Q-iC)
c
where the sum is taken over all matrices C as above. Let D be a
(p + q - n) x (p + q - n)
subdeterminant. Then D has the form
I
B'
0 I
D= o
B"
where B' is a k' x (p -
r) matrix, and B" is a k" x (q -
s) matrix with some
positive integers k', k", r, s satisfying
k' + k" = p + q - nand
r + s = n.
Then D = 0 unless k' = p - rand k" = q -
s. In that case
D = det(B')det(B") E Fr(E')Fs(E"),
which proves the reverse inclusion and concludes the proof of the proposition.
Corollary 2.9.
Let
s
E = EB Ria;
j= 1
where a j is an ideal. Then F(E) = a l '"
as.
Proof.
This is really a corollary of Proposition 2.8 and Corollary 2.6 .

746
THE ALTERNATING PRODUCT
§3.
UNIVERSAL DERIVATIONS
AND THE DE RHAM COMPLEX
In this section, all rings R, A, etc. are assumed commutative.
XIX, §3
Let A be an R-algebra and M an A-module.
By a derivation D : A --+ M
(over R) we mean an R-linear map satisfying the usual rules
D(ab) = aDb + bDa.
Note that D(1) = 2D(1)so D(1) = 0, whence D(R) = 0. Such derivations form
an A-module DerR(A, M) in a natural way,where aDisdefined by(aD)(b) = aDb.
By a universal derivation for A over R, we mean an A-module Q, and a
derivation
d :A--+Q
such that, given a derivation D : A --+ M there exists a unique A-homomorphism
I :Q --+ M making the following diagram commutative:
A~Q
~}
M
It is immediate from the definition that a universal derivation (d, Q) is uniquely
determined up to a unique isomorphism. By definition, we have a functorial
isomorphism
I
DerR(A, M) ~ HomA(Q, M). I
We shall now prove the existence of a universal derivation.
The following general remark will be useful. Let
ft,f2:A -+ B
be two homomorphisms of R-algebras, and let J be an ideal in B such that
P = 0. Assume that It == f2 mod J; this means that ft(x) == fix) mod J for
all x in A. Then
D=/2-ft
is a derivation. This fact is immediately verified as follows:
12(ab) = f2(a)/2(b) = Ut(a) + D(a)]Ut(b) + D(b)]
= ft(ab) + ft(b)D(a) + ft(a)D(b) .

XIX, §3
UNIVERSAL DERIVATIONS AND THE DE RHAM COMPLEX
747
But the A-module structure of J is given viaI I or 12(which amount to the same
thing in light of our assumptions on II' 12),so the fact is proved.
Let the tensor product be taken over R.
Let m, : A ® A -+ A
be the
multiplication
homomorphism, such that
m ACa ® b) = abo Let J = Ker rnA- We define the module of differentials
n AIR = JIJ
2
,
as an ideal in (A ® A)jJ2 . The A-module structure will always be given via the
embedding on the first fact or:
A -+ A ® A
by
a 1---+ a ® I.
Note that we have a direct sum decomposition of A-modules
A ® A = (A ® 1) ffi J ,
and therefore
(A ® A)/P = (A ® 1) ffi JjJ2.
Let
d :A
--+ JjJ2 be the R-linear map a 1---+ 1 ® a -
a ® I mod J2.
Taking fl : a 1---+ a i8l I and f2 :a 1---+ I i8l a, we see that d =f2 - fl ' Hence d is
a derivation when viewed as a map into J/P.
We note that J is generated by elements of the form
t-.«.
Indeed, if L Xi ® Yi E J , then by definition L XiYi = 0, and hence
L Xi ® Yi = L x;(1 ® Yi - Yi ® 1),
according to the A-module structure we have put on A ® A (operation of A on
the left factor.)
Theorem 3.1.
The pair (J/ J 2, d) is universal for derivations of A. This
means : Given a derivation D: A ~ M there exists a unique A-linear map
f : J/J 2 ~ M making the f ollowing diagram commutative.
\1
M

748
THE ALTERNATING PRODUCT
XIX, §3
Proof
There is a unique R-bilinear map
f : A @ A ...... M
given by
x@Yf--> xDy,
which is A-linear by our definition of the A-module structure on A @ A. Then
by definition, the diagram is commutative on elements of A, when we take f
restricted to J, because
f(l @ y - y @ 1) = Dy.
Since l iP is generated by elements of the form x dy, the uniqueness of the map
in the diagram of the theorem is clear.
This proves the desired universal
property.
We may write the result expressed in the theorem as a formula
The reader will find exercises on derivations which give an alternative way of
constructing the universal derivation, especially useful when dealing with
finitely generated algebras, which are factors of polynomial rings.
I insert here without proofs some further fundamental constructions, im-
portant in differential and algebraic geometry. The proofs are easy, and provide
nice exercises.
Let R ...... A be an R-algebra of commutative rings. For i ~ 0 define
Ai
I\i A1
UA /R =
~~A /R '
where O~/R = A.
Theorem 3.2.
There exists a unique sequence of R-homomorphisms
d . Ai
A i+1
i . UA /R ...... ~~A /R
such that for W E Oi and I] E OJ we have
d(W
1\ 1]) = do: 1\ I] + (- 1Yw 1\ dn.
Furthermore d od = O.
The proof will be left as an exercise.
Recall that a complex of modules is a sequence of homomorphisms
.
I
d i - 1
• d i
.
I
. . . ~ E' -
----,) E' ~ E' +
~
such that d! 0 di - \ = O. One usually omits the superscript on the maps d. With
this terminology, we see that the O~ /R form a complex, called the De Rham
complex.

XIX, §4
THE CLIFFORD ALGEBRA
749
Theorem 3.3.
Let k be a field of characteristic 0, and let A = k[XI, . . . , Xnl
be the polynomial ring in n variables . Then the De Rham complex
is exact.
Again the proof will be left as an exerci se. Hint :
Use induction and
integrate formally.
Other results concerning connections will be found in the exercises below.
§4.
THE CLIFFORD ALGEBRA
Let k be a field. By an algebra throughout this section, we mean a k-algebra
given by a ring homomorphism k ~ A such that the image of k is in the center
of A.
Let E be a finite dimensional vector space over the field k, and let 9 be a
symmetric form on E. We would like to find a universal algebra over k, in which
we can embed E, and such that the square in the algebra corresponds to the value
of the quadratic form in E. More precisely, by a Clifford algebra for g, we
shall
mean
a k-algebra C(g) , also denoted by C/E),
and
a linear map
p: E ~ C(g) having the following property: If !/J : E ~ L is a linear map of E
into a k-algebra L such that
r/J(X)2 = g(x, x) . I
(l = unit element of L)
for all x E E, then there exists a unique algebra-homomorphism
C(!/J) = !/J*: C(g) -+ L
such that the following diagram is commutative :
E~C(g)
~I
L
By abstract nonsense, a Clifford algebra for 9 is uniquely determined, up to a
unique isomorphism. Furthermore, it is clear that if (C(g ), p) exists, then C(g)
is generated by the image of p, i.e. by p(E), as an algebra over k.
We shall write p = Pgif it is necessary to specify the reference to 9 explicitly.

750
THE ALTERNATING PRODUCT
We have trivially
p(X)2 = g(X, x ) . 1
for all x E E, and
p(x)p(y) + p(y)p(x) = 2g(x, y) . 1
as one sees by replacing x by x + y in the preceding relation.
XIX, §4
Theorem 4.1.
Let g be a symmetric bilinear form on a finite dimensional
vector space E over k. Then the Clifford algebra (C(g), p) exists. The map p
in injective, and C(g) has dimension 2n over k, if n = dim E.
Proof.
Let T(E) be the tensor algebra as in Chapter XVI, §7. In that algebra,
we let I 9 be the two-sided ideal generated by all elements
x 0 x - g(x, x) . I for x E E.
We define CgCE) = T(E)IIg. Observe that E is naturally embedded in T(E) since
T(E) = k EB E EB (E 0 E) EB . . ..
Then the natural embedding of E in TE followed by the canonical homomorphisms
of T(E) onto Cg(E) defines our k-linear map p : E ---'> Cg(E) . It is immediate from
the universal property of the tensor product that Cg(E) as just defined satisfies
the universal property of a Clifford algebra, which therefore exists. The only
problem is to prove that it has the stated dimension over k.
We first prove that the dimension is
~ 2n . We give a proof only when
the characteristic of k is
oF 2 and leave characteristic 2 to the reader. Let
{VI' .. . , vn } be an orthogonal basis of E as given by Theorem 3.1 of Chapter
XV . Let e, = ljJ(Vj), where ljJ : E ---'> L is given as in the beginning of the sec-
tion. Let c, = g(Vj, Vj). Then we have the relations
er=
Cj ,
This immediately implies that the subalgebra of L generated by ljJ(E) over k is
generated as a vector space over k by all elements
ell . . . e~n with Vj =°or 1 for i = I, .. . , n.
Hence the dimension of this subalgebra is ~ 2n . In particular, dim CgCE) ~ 2n
as desired.
There remains to show that there exists at least one ljJ : E ---'> L such that L
is generated by ljJ(E) as an algebra over k, and has dimension 2n; for in that
case , the homomorphism ljJ* : CgCE) ---'> L being surjective, it follows that dim
C/E) ~ 2n and the theorem will be proved. We construct L in the following
way . We first need some general notion s.
Let M be a module over a commutative ring . Let i, j E Z/2Z. Suppose M
is a direct sum M = Mo EEl M) where 0, I are viewed as the elements of Z /2Z.
We then say that M is Z/2Z-graded. If M is an algebra over the ring, we say

XIX, §4
THE CLIFFORD ALGEBRA
751
it is a Z/2Z-graded algebra if M;Mj C M;+j for all i , j E Z/2Z. We simply
say graded, omitting the Z/2Z prefix when the reference to Z/2Z is fixed
throughout a discussion , which will be the case in the rest of this section.
Let A, B be graded modules as above , with A = Ao ffi AI and B = Bo ffi BI'
Then the tensor product A 0 B has a direct sum decomposition
A 0 B = EB A; 0 Bj .
t.i
We define a grading on A Q9 B by letting (A 0 B)o con sist of the sum over indices
i , j such that i + j = 0 (in Z/2Z), and (A Q9 B)I consist of the sum over the
indices i , j such that i + j = I .
Suppose that A, B are graded algebras over the given commutative ring. There
is a unique bilinear map of A Q9 B into itself such that
(a Q9 b)(a' Q9 b') = (-I );jaa' Q9 bb'
if a' E Ai and b E Bj . Just as in Chapter XVI, §6, one verifies associativity and
the fact that this product gives rise to a graded algebra, whose product is called
the super tensor product, or super product. As a matter of notation, when we
take the super tensor product of A and B, we shall denote the resulting algebra
by
A e, B
to distinguish it from the ordinary algebra A 0 B of Chapter XVI , §6.
Next suppose that E has dimension lover k. Then the factor polynomial ring
kIX] / (x2 -
CI) is immediately verified to be the Clifford algebra in this case .
We let t l be the image of X in the factor ring , so Cg(E ) = k[tJl with tT = CI '
The vector space E is imbedded as kt I in the direct sum k ffi kt I '
In general we now take the super tensor product inductively:
CiE) = k[tJl 0 su kIt:!) 0 su . • • Q9S1i kit,,], with kIt;] = k[X) / (X2 -
c,).
Its dimension is 2". Then E is embedded in Cg(E) by the map
al vl + ... + a"v" ~ altl EB ... EB a"tll"
The desired commutation rules among ti , tj are immediately verified from the
definition of the super product , thus concluding the proof of the dimension of
the Clifford algebra.
Note that the proof gives an explicit representation of the relations of the
algebra, which also makes it easy to compute in the algebra. Note further that
the alternating algebra of a free module is a special case, taking Ci = 0 for all
i. Taking the c, to be algebraically independent shows that the alternating algebra
is a specialization of the generic Clifford algebra, or that Clifford algebras are
what one calls perturbations of the alternating algebra. Just as for the alternating
algebra, we have immediately from the construction:
Theorem 4.2.
Let g, g' by symmetric fo rms on E, E' respectively. Then we

752
THE ALTERNATING PRODUCT
have an algebra isomorphism
C( g EB g' ) = C(g) @suC(g' ).
XIX, §4
Examples.
Clifford algebras have had increasingly wide applications in
physics, differential geometry, topo logy, group representations (finite groups
and Lie groups), and number theory. First, in topology I refer to Adams [Ad 62]
and [ABS 64] giving applications of the Clifford algebra to various problems
in topolog y, notably a description of the way Clifford algebras over the real s
are related to the existence of vector fields on spheres . The multiplication in the
Clifford algebra gives rise to a multiplication on the sphere, whence to vector
fields. [ABS 64] also gives a number of computations related to the Clifford
algebra and its applications to topology and physics. For instance, let E = Rn
and let 9 be the negative of the standard dot product. Or more invariantly, take
for E an n-dimensional vector space over R, and let 9 be a negative definite
symmetric form on E. Let C; = C(g) .
The operation
VI 0 . .. @ u; ~ u, @ ... @ VI = (VI @ ... 0 vr)* for Vi E E
induces an endomorphism of F (E) for r ~ O. Since V 0
V -
g(v , v ) . I (for
V E E ) is invariant under this operation, there is an induced endomorphism
* : C; ~ Cn' which is actually an involution, that is x** = x and (xy)* = y*x*
for x E Cn' We let Spin(n) be the subgroup of units in C; generated by the unit
sphere in E (i.e. the set of elements such that g(v , v) = -I ), and lying in the
even part of Cn' Equivalently, Spin(n) is the group of elements x such that
xx* = I . The name date s back to Dirac who used this group in his study of elec-
tron spin. Topologists and others view that group as being the universal cover-
ing group of the special orthogonal group SO(n) = SUn(R).
An account of some of the results of [Ad 62] and [ABS 64] will also be
found in [Hu 75], Chapter II. Second I refer to two works encompassing two
decades, concerning the heat kernel , Dirac operator, index theorem, and number
theory, ranging from Atiyah, Bott and Patodi [ABP 73] to Faltings [Fa 91], see
especially §4, entitled "The local index theorem for Dirac operators" . The vector
space to which the general theory is applied is mostly the cotangent space at a
point on a manifold. I recommend the book [BGV 92], Chapter 3.
Finally, I refer to Brocker and Tom Dieck for applications of the Clifford
algebra to representation theory, starting with their Chapter I, §6, [BtD 85].
Bibliography
[Ad 62]
[ABP 73]
F. AD AMS, Vector Fields on Spheres, Ann. Math. 75 (1962) pp. 603-632
M. ATIYAH , R. BOTT, V. P ATODI , Ontheheatequationand theindex theorem,
Invent. Math. 19 (1973) pp. 270- 330; erratum 38 (1975) pp. 277-280

XIX, Ex
EXERCISES
753
lABS 64]
M. ATIYAH, R. BOTT, A. SHAPIRO, Clifford Modules, Topology Vol. 3,
Supp. 1 (1964) pp. 3-38
[BGV 92]
N. BERLINE, E. GETZLER, and M. VERGNE, Heat Kernels and Dirac Oper-
ators, Springer Verlag, 1992
[BtD 85]
T. BROCKER and T. TOM DIECK, Representations of Compact Lie Groups,
Springer Verlag 1985
[Fa 91]
G. FALTINGS, Lectures on the arithmetic Riemann-Roch theorem , Annals of
Math. Studies 1991
[Hu 75]
D. HUSEMOLLER, Fibre Bundles, Springer Verlag, Second Edition, 1975
EXERCISES
I. Let E be a finite dimensional vector space over a field k. Let Xl' . . . , x p be elements of E
such that XI II ... II x p # 0, and similarly YI II . . . II Yp # o. If c E k and
X l
II
II x p = CYI II . . . II Yp
show that XI "
' . ' xp and YI,
, Yp generate the same subspace. Thus non-zero
decomposable vectors in IVE up to non-zero scalar multiples correspond to
p-dimensional subspaces of E.
2. Let E be a free module of dimension n over the commutative ring R. Let f :E -+ E
be a linear map. Let rt.,(f) = tr /\'(f ), where /\,(f ) is the endomorphism of /\,(E)
into itself induced by f. We have
rt.o(f) = 1,
rt.1(f) = tr(f),
rt.n(f) = det [,
and rt.,(f) = 0 if r > n. Show that
det(l + f) =
2:>,(f).
r ~O
[Hint:
As usual, prove the statement when f is represented by a matrix with variable
coefficients over the integers.] Interpret the rt.,(f ) in terms of the coefficients of the
characteristic polynomial of f.
3. Let E be a finite dimensional free module over the commutative ring R. Let E V be
its dual module. For each integer r ~ I show that I\'Eand l\'Ev are dual modules
to each other, under the bilinear map such that
(V I 1\ • • • 1\ v" v; 1\ •• • 1\ v~) ~ det «Vi' vi»
where (V i' vi>is the value of vi on Vi' as usual , for Vi E E and vi E EV.
4. Notation being as in the preceding exercise, let F be another R-module which is free,
finite dimensional. Let f: E -+ F be a linear map. Relative to the bilinear map of the
preceding exercise, show that the transpose of /\'f is /\'('!), i.e. is equal to the roth
alternating product of the transpose of f.
5. Let R be a commutative ring . If E is an R-module, denote by L~(E) the module of

754
THE ALTERNATING PRODUCT
XIX, Ex
r-multilinear alternating maps of E into R itself (i.e . the r-multilinear alternating
forms on E). Let L~(E) = R, and let
00
Q(E) = EB L~(E).
r = O
Show that Q(E) is a graded R-algebra, the multiplication being defined as follows. If
W E L~(E) and if! E L~(E), and VI' . .. , Vr+s are elements of E, then
(w A if!)(v\> . . . , vr+s) = I £(a)w(vul' . . . • Vur)if!(Vu(r+I ), • .. , vus)'
the sum being taken over all permutations a of (I , . .. , r + s) such that a l < ... < or
and a(r + 1) < ... < as.
Derivations
In thefollowing exercises on derivations, all rings are assumed commutative. Among
other things, the exercises give another proof of the existence of universal derivations.
Let R -> A be a R-algebra (of commutative rings, according to our convention).
We denote the module of universal derivations of A over R by (dA1R, Q~ IR)' but wedo not
assume that it necessarily exists. Sometimes we write d instead of dA/R for simplicity
if the reference to AIR is clear.
6. Let A = R[X,] be a polynomial ring in variables X•• where ex ranges over some
indexing set, possibly infinite. Let Q be the free A-module on the symbols dX" and let
d :A -> Q
be the mapping defined by
af
df( X ) = I -a ax;
a x,
Show that the pair (d, Q) is a universal derivation (dA1R, Q~ IR ) '
7. Let A -> B be a homomorphism of R-algebras. Assume that the universal derivations
for AIR, BIR, and BIA exist. Show that one has a natural exact sequence:
[Hint :
Consider the sequence
which you prove is exact. Use the fact that a sequence of B-modules
N' -> N -> N" -> 0
is exact if and only if its Hom into M is exact for every B-module M. Apply this to the
sequence of derivations.]
8. Let R -> A be an R-algebra, and let I be an ideal of A. Let B = A/I. Suppose that the
universal derivation of A over R exists. Show that the universal derivation of B over R

XIX. Ex
also exists, and that there is a natural exact sequence
[Hint:
Let M be a B-module. Show that the sequen ce
EXERCISES
755
is exact.]
9. Let R ~ B be an R-algebra . Show that the universal derivation of B over R exists
as follows. Represent B as a quotient of a polynomial ring, possibly in infinitely
many variables. Apply Exercises 6 and 7.
10. Let R -+ A be an R-algebra. Let So bea mult iplicative subset of R,and S a multiplicative
subset of A such that So map s into S. Show that the univer sal derivat ion of S- 1A over
So 1R is (d, S -lQ~ /R)' where
II . Let B be an R-algebra and M a B-module. On B EEl M define a product
(b, x )(b', y) = (bb', by + b'x ).
Show that B EEl M is a B-algebra, if we identify an element b e B with (b,O). For any
R-algebra A, show that the algebra homomorphisms HomAlg/R(A, B EEl M) consist of
pairs (qJ, D), where
qJ :A -+ B is an algebra homomorphism, and D : A -+ M is a
der ivation for the A-module structure on M induced by tp.
12. Let A be an R-algebra. Let s : A -+ R be an algebra homomorphism, which we call an
augmentation. Let M be an R-m odule. Define an A-module structure on M via 1:, by
a · x = f.(a)x
for
aEA
and
xE M.
Write M, to denote M with this new module structure. Let :
Der,(A, M) = A-module of deri vations for the s-module structure on M
1= Ker s.
Then Der,(A , M) is an A/I-module. Note that there is an R-module direct sum de-
composition A = R EEl I. Show that there is a natural A-module isomorphism
and an R-module isomorphism
In particular, let IJ : A -+ 1/12 be the projection of A on 1/12 relative to the direct sum
decomposition A = R EEl I. Then IJ is the universal s-derivation.
Derivations and connections
13. Let R -+ A be a homomorphism of commutative rings, so we view A as an R-algebra.

756
THE ALTERNATING PRODUCT
XIX, Ex
Let E be an A-module. A connection on E is a homomorphism of abelian groups
such that for a E A and x E E we have
V(ax) = aV(x) + da ® x,
where the tensor product is taken over A unless otherwise specified. The kernel of V,
denoted by Ev,iscalled the submoduleofhorizontal elements, or the horizontal submodule
of(E, V).
(a) For any integer i ;;;; I, define
ni
I\inl
"AIR =
"AIR '
Show that V can be extended to a homomorphism of R-modules
by
Vlw ® x) = dw ® x + (-I)iW 1\ Vex).
(b) Define the curvature of the connection to be the map
Show that K is an A-homomorphism. Show that
Vi + 1 0 Vlw ® x) =
W
1\ K(x)
for w E n~/R and x E E.
(c) Let Der(A/R) denote the A-module of derivations of A into itself, over R.
Let V be a connection on E. Show that V induces a unique A-linear map
V: Der(A/R) -+ EndR(E)
such that
V(D)(ax) = D(a)x + aV(D) (x).
(d) Prove the formula
In this formula, the bracket is defined by [f, g] = f og - g of for two endo-
morphisms f, gofE. Furthermore,the right-hand side isthe composed mapping

XIX, Ex
EXERCISES
757
14. (a) For any derivation D ofa ring A into itself, prove Leibniz's rule:
(b) Suppose A has characteristic p. Show that DP is a derivation.
15. Let A/R be an algebra, and let E be an A-module with a connection V. Assume that R
has characteristic p. Define
tj;: Der(A/R) -+ EndR(E)
by
tj;(D) = (V(D»P - V(DP).
Prove that tj;(D) is A-linear. [Hint :
Use Leibniz's formula and the definition of a
connection.] Thus the image of tj;is actually in EndiE).
Some Clifford exercises
16. Let Cg(E) be the Clifford algebra as defined in §4. Define Fj(Cg) = (k + E)i, viewing
E as embedded in Cg. Define the similar object F;C I\E) in the alternating algebra. Then
Fi+ 1 ::::> F, in both cases, and we define the i-th graded module gr, = FjFj_ l • Show
that there is a natural (functorial) isomorphism
grj(Cg(E» .z, gr;(I\E).
17. Suppose that k = R, so E is a real vector space, which we now assume of even
dimension 2m. We also assume that g is non-degenerate. We omit the index g since
the symmetric form is now fixed , and we write C+, C- for the spaces of degree 0
and I respecti vely in the Z/2Z-grading. For elements x, y in C+ or C- , define their
supercommutator to be
{x , y} = xy -
(_ I)(dep
)(deg \' )yx .
Show that F2m - 1 is generated by supercommutators .
18. Still
assuming
g
non-degenerate,
let 1 be an automorphism
of
(E, g) (i.e.
g(Jx , ly) = g(x, y) for all x , y E E) such that j2 = -id. Let Ec = C Q9RE be the
extension of scalars from R to C. Then Ec has a direct sum decomposition
Ec = EcEB Ec
into the eigenspaces of 1, with eigenvalues I and - I respect ively . (Proof?) There
is a representation of Ec on I\Ec,i.e . a homomorphism Ec ~ Endc(Ec)whereby
an element of Ecoperates by exterior multiplication, and an element of Ecoperates
by inner multiplication, defined as follow s.
For x' E Ecthere is a unique C-Iinear map having the effect
r
X '(X I 1\ • •• 1\ xr) = -22: ( - I)i- I (x', x) x \ 1\ • •• 1\ Xi 1\ • • • 1\ xr .
;= 1

758
THE ALTERNATING PRODUCT
Prove that under this operation, you get an isomorphism
Cg(E)c ~ Endd AEc)'
XIX, Ex
[Hint : Count dimensions.]
19. Consider the Clifford algebra over R. The standard notation is Cn if E = R" with
the negative definite form, and C~ if E = R n with the positive definite form. Thus
dim Cn = dim C~ = 2n •
(a) Show that
Cz = H (the division ring of quatemions)
C2= M z(R) (2 x 2 matrices over R)
20. Establish isomorphisms:
C 0 R C = C x C;
C 0 R H = Mz(C);
H 0 R H = M 4(R)
where Md(F) = d x d matrices over F . For the third one, with H 0 H, define an
isomorphism
f : H 0 R H ~ HomR(H , H) = M 4(R)
by f(x 0 y)(z) = xzy, where if y = Yo + y1i + yzj + Y3k then
y = Yo - y1i - yzj - Y3k.
21. (a) Establish isomorphisms
Cn+Z = C~ 0 Cz
and
[Hint: Let {e" . . . , en+z} be the orthonormalized basis with e; = -I. Then for
. the first isomorphism map ei H
e; 0 e,ez for i = 1, . .. , n and map en+I' en+z
on 1 0 e, and I 0 ez respectively.]
(b) Prove that Cn + & = C; 0 M I 6(R ) (which is called the periodicity property).
(c) Conclude that Cn is a semi-simple algebra over R for all n.
From (c) one can tabulate the simple modules over Cn' See [ABS 64], reproduced
in Husemoller [Hu 75], Chapter II, §6.

Part Four
HOMOLOGICAL
ALGEBRA
In the forties and fifties (mostly in the works of Cartan, Eilenberg, MacLane,
and Steenrod, see [CaE 57]), it was realized that there was a systematic way of
developing certain relations of linear algebra, depending only on fairly general
constructions which were mostly arrow-theoretic, and were affectionately called
abstract nonsense by Steenrod. (For a more recent text, see [Ro 79] .) The results
formed a body of algebra, some of it involving homological algebra, which had
arisen in topology, algebra, partial differential equations, and algebraic geometry.
In topology, some of these constructions had been used in part to get homology
and cohomology groups of topological spaces as in Eilenberg-Steenrod [ES 52] .
In algebra, factor sets and l-cocycles had arisen in the theory of group extensions,
and, for instance, Hilbert's Theorem 90. More recently, homological algebra
has entered in the cohomology of groups and the representation theory of groups.
See for example Curtis-Reiner [CuR 81], and any book on the cohomology of
groups, e.g. [La 96], [Se 64], and [Sh 72]. Note that [La 96] was written to pro-
vide background for class field theory in [ArT 68].
From an entirely different direction, Leray developed a theory of sheaves
and spectral sequences motivated by partial differential equations. The basic
theory of sheaves was treated in Godement's book on the subject [Go 58].
Fundamental insights were also given by Grothendieck in homological algebra
[Gro 57], to be applied by Grothendieck in the theory of sheaves over schemes
in the fifties and sixties. In Chapter XX, I have included whatever is necessary
of homological algebra for Hartshorne's use in [Ha 77]. Both Chapters XX and
XXI give an appropriate background for the homological algebra used in Griffiths-
Harris [GrH 78], Chapter 5 (especially §3 and §4), and Gunning [Gu 90] . Chapter
XX carries out the general theory of derived functors . The exercises and Chapter
XXI may be viewed as providing examples and computations in specific concrete
instances of more specialized interest.
759

760
HOMOLOGICAL ALGEBRA
PART FOUR
The commutative algebra of Chapter X and the two chapters on homological
algebra in this fourth part also provide an appropriate background for certain
topics in algebraic geometry such as Serre 's study of intersection theory [Se 65],
Grothendieck duality, and Grothendieck's Riemann-Roch theorem in algebraic
geometry. See for instance [SGA 6].
Finally I want to draw attention to the use of homological algebra in certain
areas of partial differential equations, as in the papers of Atiyah-Bott-Patodi and
Atiyah-Singer on complexes of elliptic operators. Readers can trace some of the
literature from the bibliography given in [ABP 73].
The choice of material in this part was to a large extent motivated by all the
above applications.
For this chapter, considering the number of references and cross-references
given, the bibliography for the entire chapter is placed at the end of the chapter.

CHAPTER XX
General Homology Theory
To a large extent the present chapter is arrow-theoretic. There is a substantial
body of linear algebra which can be formalized very systematically, and con-
stitutes what Steenrod called abstract nonsense, but which provides a well-oiled
machinery applicable to many domains. References will be given along the way.
Most of what we shall do applies to abelian categories, which were mentioned
in Chapter III, end of §3. However, in first reading, I recommend that readers
disregard any allusions to general abelian categories and assume that we are
dealing with an abelian category of modules over a ring, or other specific abelian
categories such as complexes of modules over a ring .
§1.
COMPLEXES
Let A be a ring. By an open complex of A-modules, one means a sequence
of modules and homomorphisms {(Ei, di)},
where i ranges over all integers and d, maps Ei into e: 1, and such that
for all i.
One frequently considers a finite sequence of homomorphisms, say
E 1 ....... . . ........ E'
761
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

762
GENERAL HOMOLOGY THEORY
XX, §1
such that the composite of two successive ones is 0, and one can make this
sequence into a complex by inserting 0 at each end :
Such a complex is called a finite or bounded complex.
Remark.
Complexes can be indexed with a descending sequence of integers,
namely,
E
du
I E
di E
--+
i +
l ~
i--+
i - I --+
When that notation is used systematically, then one uses upper indices for
complexes which are indexed with an ascending sequence of integers:
In this book, I shall deal mostly with ascending indices.
As stated in the introduction of this chapter, instead of modules over a ring,
we could have taken objects in an arbitrary abelian category.
The homomorphisms di are often called differentials, because some of the
first complexes which arose in practice were in analysis, with differential operators
and differential forms. Cf. the examples below.
We denote a complex as above by (E, d). If the complex is exact, it is often
useful to insert the kernels and cokernels of the differentials in a diagram as
follows, letting M, = Ker di = 1me>.
----> Ei- 2 ----> Ei- 1 ----> Ei ----> Ei+ 1 ---->
\ / \ /\ /
Mi - 1
M i
M i+ 1
/\ / \ /\
o
0
0
0
Thus by definition, we obtain a family of short exact sequences
If the complex is not exact, then of course we have to insert both the image of
di - 1 and the kernel of di• The factor
will be studied in the next section. It is called the homology of the complex,
and measures the deviation from exactness.

XX, §1
COMPLEXES
763
Let M be a module. By a resolution of M we mean an exact sequence
Thus a resolution is an exact complex who se furthest term on the right before
ois M. The resolution is indexed as shown. We usually write EMfor the part of
complex formed onl y of the E;'s, thus :
stopping at Eo. We then write E for the complex obtained by sticking 0 on
the right :
E is:
-> En -> En- 1 -> .. . -> Eo -> O.
If the objects E, of the resolution are taken in some family, then the resolution is
qu alified in the same way as the family. For instance, if E, is free for all i ~ 0
then we say that the resolution is a free resolution. If E, is projective for all
i
~ 0 then we say that the resolution is projective. And so forth. The same
terminology is applied to the right , with a resolution
also written
We then write E for the complex
See §5 for injecti ve resolutions.
A resolution is said to be finite if E, (or £i) = 0 for all but a finite number of
indices i.
Example.
Every module admits a free resolution (on the left). This is a
simple application of the notion of free module. Indeed, let M be a module , and
let {Xj} be a family of generators, with j in some indexing set J. For each j let
Rej be a free module over R with a basis consisting of one element ej' Let
be their direct sum. There is a unique epimorphism
sending ej on X j ' Now we let M 1 be the kernel, and again represent Mias the
qu otient of a free module.
Inductively, we can construct the desired free
resolution.

764
GENERAL HOMOLOGY THEORY
XX, §1
Example.
The Standard Complex.
Let S be a set. For i = 0, 1, 2, . . .
let E, be the free module over Z generated by (i + I)-tuples (xo, . .. , x) with
Xo, . .. , Xi E S. Thus such (i + l j-tuples form a basis of E, over Z. There is a
unique homomorphism
di+ l : Ei+ 1 ~ E,
such that
i+ 1
di+I(XO" ' "
Xi+I) = 2: (-l)j(xo, · .. , Xj"' "
Xi+I),
j =O
where the symbol Xj means that this term is to be omitted. For i = 0, we define
do : Eo ~ Z to be the unique homomorphism such that do(xo) = 1. The map do
is sometimes called the augmentation, and is also denoted by E. Then we obtain
a resolution of Z by the complex
~ Ei+ 1 ~ E, ~ . . . ~ Eo -4 Z ~ 0.
The formalism of the above maps d, is pervasive in mathematics. See Exercise
2 for the use of the standard complex in the cohomology theory of groups. For
still another example of this same formalism, compare with the Koszul complex
in Chapter XXI, §4.
Given a module M, one may form Hom(Ei , M) for each i , in which case one
gets coboundary maps
8i : Hom(Ei , M) ~ Hom(E i + 1, M),
8(!) = fa d i + l ,
obtained by composition of mappings. This procedure will be used to obtain
derived functors in §6. In Exercises 2 through 6, you will see how this procedure
is used to develop the cohomology theory of groups .
Instead of using homomorphisms, one may use a topological version with
simplices, and continuous maps, in which case the standard complex gives rise to
the singular homology theory of topological spaces. See [GreH 81], Chapter 9.
Examples.
Finite free resolutions.
In Chapter XXI, you will find other
examples of complexes, especially finite free , constructed in various ways with
different tools . This subsequent entire chapter may be viewed as providing
examples for the current chapter.
Examples with differential forms.
In Chapter XIX, §3, we gave the exam-
ple of the de Rham complex in an algebraic setting. In the theory of differential
manifolds, the de Rham complex has differential maps
d': O i ~ O i+l,
sending differential forms of degree i to those of degree i + 1, and allows for
the computation of the homology of the manifold.
A similar situation occurs in complex differential geometry, when the maps
d' are given by the Dolbeault a-operators
ai : Op. i ~ Op·i+l

XX, §1
COMPLEXES
765
operating on forms of type (p, i) . Interested readers can look up for instance
Gunning's book [Gu 90] mentioned in the introduction to Part IV,Volume I, E.
The associated homology of this complex is called the DoIbeault or a-cohom-
ology of the complex manifold.
Let us return to the general algebraic aspects of complexes and resolutions.
It is an interesting problem to discuss which modules admit finite resoutions,
and variations on this theme. Some conditions are discussed later in this chapter
and in Chapter XXI. If a resolution
is such that Em = 0 for m > n, then we say that the resolution has length ;£ n
(sometimes we say it has length n by abuse oflanguage).
A closed complex of A-modules is a sequence of modules and homomorph-
isms {(E i, din where i ranges over the set of integers mod n for some n ~ 2
and otherwise satisfying the same properties as above. Thus a closed complex
looks like this :
We call n the Jength of the closed complex.
Without fear of confusion, one can omit the index i on d' and write just d.
We also write (E, d) for the complex {(E i, din, or even more briefly, we write
simply E.
Let (E, d) and (E', d') be complexes (both open or both closed). Let r be an
integer. A morphism or homomorphism (of complexes)
f:(E', d') -> (E, d)
of degree r is a sequence
of homomorphisms such that for all i the following diagram is commutative:
Just as we write d instead ofi, we shall also writef instead ofj;. If the com-
plexes are closed, we define a morphism from one into the other only if they
have the same length.
It is clear that complexes form a category. In fact they form an abelian
category. Indeed, say we deal with complexes indexed by Z for simplicity, and
morphisms of degree O. Say we have a morphism of complexes f :C -> C" or

766
GENERAL HOMOLOGY THEORY
putting the indices:
XX, §1
We let C~ = KertC, -> C~). Then the family
(C~) forms a complex, which we
define to be the kernel off. We let the reader check the details that this and a
similar definition for cokernel and finite direct sums make complexes of
modules into an abelian category. At this point , readers should refer to Chapter
III, §9, where kernels and cokernels are discussed in this context. The snake
lemma of that chapter will now become central to the next section.
It will be useful to have another notion to deal with objects indexed by a
monoid. Let G be a monoid, which we assume commutative and additive to
fit the applications we have in mind here. Let {MJi eG be a family of modules
indexed by G. The direct sum
M = EB M,
i e G
will be called the G-graded module associated with the family {MJ i e G • Let
{MJieG and {MiLeGbe families indexed by G, and let M, M' be their asso-
ciated G-graded modules. Let rEG. Bya G-graded morphismf : M ' -> M of
degree r we shall mean a homomorphism such that fmaps M; into Mi+r for
each i E G (identifying M; with the corresponding submodule of the direct
sum on the i-th component). Thus f is nothing else than a family of homo-
morphismsJ; :M; -> M i + r •
If(E, d) is a complex we may view E as a G-graded module (taking the direct
sum of the components of the complex), and we may view d as a G-graded
morphism of degree 1, letting G be Z or Z/nZ. The most common case we en-
counter is when G = Z. Then we write the complex as
E = EB Eh
and
d :E -> E
maps E into itself. The differential d is defined as d, on each direct summand
Eh and has degree I.
Conversely, if G is Z or Z/nZ, one may view a G-graded module as a com-
plex, by defining d to be the zero map.
For simplicity, we shall often omit the prefix "G-graded" in front of the word
" morphism", when dealing with G-graded morphisms.

XX, §2
§2.
HOMOLOGY SEQUENCE
Let (E, d) be a complex. We let
Zi( E) = Ker d'
and call Zi(E) the module of i-cycles. We let
Bi(E) = 1m di- 1
HOMOLOGY SEQUENCE
767
and call Bi(E) the module of i-boundaries. We frequently write Zi and Bi
instead of Zi(E) and Bi(E), respectively. We let
Hi(E) = Zi/Bi = Ker di/lm di- 1,
and call H i(E) the i-th homology group of the complex. The graded module
associated with the family {Hi} will be denoted by H(E), and will be called the
homology of E. One sometimes writes H*(E) instead of H(E).
Iff :E' -+ E is a morphism of complexes, say of degree 0, then we get an
induced canonical homomorphism
on each homology group . Indeed , from the commutative diagram defining a
morphism of complexes, one sees at once thatfmaps Zi(E') into Zi(E) and Bi(E')
into Bi(E), whence the induced homomorphism Hi(f). Compare with the begin-
ning remarks of Chapter III, §9. One often writes this induced homomorphism
asfi* rather than H i(f), and if H(E) denotes the graded module of homology as
above, then we write
H(f) = I; : H(E') -
H(E) .
We call H(f) the map induced byf on homology. If Hi(f) is an isomorphism
for all i , then we say thatf is a homology isomorphism.
Note that iff : E' -
E and g : E -
Elf are morphisms of complexes, then it
is immediately verified that
H(g)
0 H(f) = H(g
0 f)
and
H(id) = id.
Thus H is a functor from the category of complexes to the category of graded
modules.
We shall consider short exact sequences of complexes with morphisms of
degree 0:
°-+ E' ~ E !. Elf -+ 0,

768
GENERAL HOMOLOGY THEORY
which written out in full look like this:
I
I
I
O
s v:»
Ei-1
ev:»
O
j
j
j
o--- E,j
-.L...... Ei
---.!-.... E"j
--- 0
I
j
j
O
E'(i+l)-.L......Ei+l~E"(j+l)
O
j
I
j
O
E,(i+2)
Ei+ 2
E,,(i+2)
O
I
I
I
One can define a morphism
<5 : H(E") -+ H(E')
ofdegree 1, in other words, afamily ofhomomorphisms
by the snake lemma.
Theorem 2.1.
Let
o-+ E' ~ E s; E" -+ 0
XX, §2
be an exact sequence ofcomplexes withf, g ofdegree O. Then the sequence
H(E')~H(E)
\
}
H(E")
is exact.
This theorem is merely a special application of the snake lemma.
If one writes out in full the homology sequence in the theorem, then it looks
like this :

XX, §3
EULER CHARACTERISTIC AND THE GROTHENDIECK GROUP
769
It is clear that our map 15 is functorial (in an obvious sense), and hence that
our whole structure (H , 15) is a functor from the category of short exact sequences
of complexes into the category of complexes.
§3.
EULER CHARACTERISTIC AND THE
GROTH ENDIECK GROUP
This section may be viewed as a continuation of Chapter III, §8, on Euler-
Poincare maps . Consider complexes of A-modules, for simplicity.
Let E be a complex such that almost all homology groups Hi are equal to O.
Assume that E is an open complex. As in Chapter III, §8, let cp be an Euler-
Poincare mapping on the category of modules (i.e. A-modules). We define the
Euler-Poincare characteristic Xcp(E) (or more briefly the Euler characteristic)
with respect to cp, to be
X",(E) = L(-lycp(Hi)
provided cp(Hi) is defined for all Hi, in which case we say that X", is defined for the
complex E.
IfE is a closed complex, we select a definite order (E 1, • • • , En) for the integers
mod n and define the Euler characteristic by the formula
n
xiE) = L (- I )icp(Hi)
i= 1
provided again all cp(Hi) are defined.
For an example, the reader may refer to Exercise 28 of Chapter I.
One may view H as a complex, defining d to be the zero map. In that case,
we see that X",(H) is the alternating sum given above. More generally:
Theorem 3.1.
Let F be a complex, which is of even length if it is closed.
Assume that cp(Fi) is defined/or all i, cp(Fi) = Ofor almost all i, and Hi(F) = 0
for almost all i. Then X",(F) is defined, and
X",(F) = L (- 1)icp(Fi).
i
Proof
Let Zi and Bi be the groups of i-cycles and i-boundaries in Fi
respectively. We have an exact sequence
Hence Xcp(F) is defined, and
cp(Fi) = cp(Zi) + cp(Bi+ I ) .

770
GENERALHOMOLOGYTHEORY
Taking the alternating sum, our conclusion follows at once.
A complex whose homology is trivial is called acyclic.
XX, §3
Corollary 3.2.
Let F be an acyclic complex, such that <p(Fi) is definedJar
all i, and equalto 0Jar almost all i. IJ F is closed, we assume that F has even
length. Then
X",(F) = O.
In many applications, an open complex F is such that F i = 0 for almost
all i, and one can then treat this complex as a closed complex by defining an
additional map going from a zero on the far right to a zero on the far left. Thus
in this case, the study of such an open complex is reduced to the study of a
closed complex.
Theorem3.3.
Let
o~ E' ~ E ~ E" ~ 0
be an exact sequence oj complexes, with morphisms ojdegree O. IJ the com-
plexes are closed, assumethat their lengthis even. Let <p be an Euler-Poincare
mapping on the category oj modules. IJ X", is defined Jar two oj the above
three complexes, then it is definedJar the third, and we have
Proof
We have an exact homology sequence
This homology sequence is nothing but a complex whose homology is trivial.
Furthermore, each homology group belonging say to E is between homology
groups of E' and E". Hence if X", is defined for E' and E" it is defined for E.
Similarly for the other two possibilities. If our complexes are closed of even
length n, then this homology sequence has even length 3n. We can therefore
apply the corollary of Theorem 3.1 to get what we want.
For certain applications, it is convenient to construct a universal Euler
mapping. Let G. be the set of isomorphism classes of certain modules. If E is a
module, let [E] denote its isomorphism class.
We require that G. satisfy the
Euler-Poincare condition, i.e. if we have an exact sequence
o~ E' ~ E ~ E" ~ 0,
then [E] is in G. if and only if [E'] and [E"] are in G.. Furthermore, the zero
module is in G..

XX, §3
EULER CHARACTERISTIC AND THE GROTHENDIECK GROUP
771
Theorem 3.4.
Assume that Q satisfies the Euler-Poincare condition. Then
there is a map
y : Q -+ K(Q)
of Q into an abelian group K(Q) having the universal property with respect to
Euler-Poincare maps defined on Q.
To construct this, let F.b(Q) be the free abelian group generated by the set of
such [E]. Let B be the subgroup generated by all elements of type
[E] -
[E'] - [E"] ,
where
o-+ E' -+ E -+ E" -+ 0
is an exact sequence whose members are in Q. We let K(Q) be the factor group
F.b(Q)jB, and let y: Q -+ K(Q) be the natural map.
It is clear that y has the
universal property.
We observe the similarity of construction with the Grothendieck group of a
monoid. In fact , the present group is known as the Euler-Grothendieck group
of Q, with Euler usually left out.
The reader should observe that the above arguments are valid in abelian
categories, although we still used the word module. Just as with the elementary
isomorphism theorems for groups, we have the analogue of the Jordan-Holder
theorem for modules. Of course in the case of modules, we don't have to worry
about the normality of submodules.
We now go a little deeper into K-theory. Let Q be an abelian category. In
first reading, one may wish to limit attention to an abelian category of modules
over a ring. Let C be a famil y of objects in <1 . We shall say that e is a K-family
if it satisfies the following conditions.
K l.
e is closed under taking finite direct sums, and 0 is in e.
K 2.
Given an object E in Q there exists an epimorphism
with Lin e.
K 3.
Let E be an object admitting a finite resolution of length n
o-+ L; -+ .. . -+ L o -+ E -+ 0
with L, E e for all i. If
0-+ N -+ Fn- 1 -+ . .. -+ F 0 -+ E -+ 0
is a resolution with N in Q and F0, . . . , F n - 1 in e, then N is also in e.

772
GENERAL HOMOLOGY THEORY
XX, §3
We note that it follows from these axioms that if F is in e and F' is iso-
morphic to F, then F' is also in e, as one sees by looking at the resolution
O->F'->F->O->O
and applying K 3. Furthermore, given an exact sequence
o-> F' -> F -> F" -> 0
with F and F" in e, then F' is in e, again by applying K3.
Example.
One may take for Q the category of modules over a commutative
ring, and for e the family of projective modules. Later we shall also consider
Noetherian rings, in which case one may take finite modules, and finite pro-
jective modules instead. Condition K 2 will be discussed in §8.
From now on we assume that e is a K-family. For each object E in Q, we
let [E] denote its isomorphism class. An object E of Q will be said to have
finite e-dimension if it admits a finite resolution with elements of e . We let
Q(e) be the family of objects in Q which are of finite e-dimension. We may
then form the
where R(Q(e» is the group generated by all elements [E] -
[E'] -
[E"]
arising from an exact sequence
o-> E' -> E -> E" -> 0
in Q(e). Similarly we define
K(e) = Z[(e)]/R(e),
where R(e) is the group of relations generated as above, but taking E', E, E"
in e itself.
There are natural maps
Ya(e): Q(e) -> K(Q(e»
and
Ye : e -> K(e),
which to each object associate its class in the corresponding Grothendieck
group. There is also a natural homomorphism
since an exact sequence of objects of e can also be viewed as an exact sequence
of objects of Q( e).

XX, §3
EULER CHARACTERISTIC AND THE GROTHENDIECK GROUP
773
Theorem 3.5.
Let ME Q(e) and suppose we have two resolutions
by finite complexes LM andL:w in e. Then
Proof
Take first the special case when there is an epimorphism LM--+ LM ,
with kernel E illustrated on the following commutative and exact diagram.
The kernel is a complex
which is exact because we have the homology sequence
For p ~ 1 we have HiL) = H p(L') = 0 by definition, so H p(E) = 0 for p ~ 1.
And for p = 0 we consider the exact sequence
Now we have H)(L) = 0, and Ho(L') --+ Ho(L) corresponds to the identity
morphisms on M so is an isomorphism. It follows that Ho(E) = 0 also.
By definition of K-family, the objects E; are in e. Then taking the Euler
characteristic in K(e) we find
X(L') - X(L) = x(E) = 0
which proves our assertion in the special case.
The general case follows by showing that given two resolutions of M in e
we can always find a third one which tops both of them. The pattern of our
construction will be given by a lemma.

774
GENERAL HOMOLOGY THEORY
XX, §3
Lemma 3.6.
Given two epimorphisms u :M -> N and v:M' -> N in ct,
there exist epimorphisms F -> M and F -> M' with F in e makingthefollowinq
diagram commutative.
Proof
Let E = M x N M', that is E is the kernel of the morphism
M x M ' -> N
given by (x, y) I--> UX -
vy. (Elements are not really used here, and we could
write formally u - v instead.) There is some F in e and an epimorphism
F -> E -> o. The composition of this epimorphism with the natural projections
of E on each factor gives us what we want.
We construct a complex L ~1 giving a resolution of M with a commutative
and exact diagram:
The construction is done inductively, so we put indices:
1;~l'~
L[~r'~

XX, §3
EULER CHARACTERISTIC AND THE GROTHENDIECK GROUP
775
Suppose that we have constructed up to Li'- I with the desired epimorphisms on
L j _ 1 and Li- I '
We want to construct Li'· Let B, = Ker(L j _ 1 ---> Li: 2) and
similarly for B'; and Bi'. We obtain the commutative diagram :
Lj ------+ Bj ------+ L j -
1 ------+ L j - 2
I
I
I
B;' ------+ L;'_1 ------+ Li'- 2
j
j
j
If B;' ---> B, or Bi' ---> B, are not epimorphisms, then we replace L i'- 1 by
We let the boundary map to L;'_ 2 be 0 on the new summands, and similarly
define the maps to L j _ 1 and Li- 1 to be 0 on L; and L j _ 1 respectively.
Without loss of generality we may now assume that
are epimorphisms. We then use the construction of the preceding lemma.
We let
E = L '~D B ~'
and
E. = B ~'~D'C .
l
I'I/U j
I
I
'W'V j
J
Then both E, and E; have natural epimorphisms on Bi'. Then we let
N· = E·!::DD" e.
I
IQ7D j
I
and we find an object L ;' in e with an epimorphism Li' ---> N j • This gives us the
inductive construction of L" up to the very end. To stop the process, we use
K 3 and take the kernel of the last constructed Li' to conclude the proof.
Theorem 3.7.
The natural map
is an isomorphism.
Proof
The map is surjective because given a resolution
with F, E e for all i, the element

776
GENERAL HOMOLOGY THEORY
XX, §3
maps on Yale lM) under c. Conversely, Theorem 3.5 shows that the association
is a well-defined mapping. Since for any LEe we have a short exact sequence
0--+ L --+ L -> 0, it follows that this mapping following f. is the identity on Kce),
so f. is a monomorphism. Hence f. is an isomorphism, as was to be shown.
It may be helpful to the reader actually to see the next lemma which makes
the additivity of the inverse more explicit.
Lemma 3.8.
Given an exact sequence in ace)
o-+ M' -> M -+ M" -+ 0
there exists a commutative and exact diagram
o~ L M ,~ L M ------> LM" ------> 0
j
j
j
o~ M' ~ M ------> M" ~ 0
j
j
j
o
0
0
with finite resolutions L M " LM , LM" in e.
Proof
We first show that we can find L', L, L" in e to fit an exact and
commutative diagram
o------> L' ~ L ~ L" ------> 0
j
j
j
o~ M ' ------> M ~ M "~ 0
j
j
j
o
0
0
We first select an epimorphism L" -> M " with L" in e. By Lemma 3.6 there
exists L) E e and epimorphisms L) -+ M , L) --+ L" making the diagram com-
mutative. Then let L 2 -+ M' be an epimorphism with L 2 E e,and finally define
L = L)
EE> L 2 • Then we get morphisms L -> M and L -> L" in the obvious
way. Let L' be the kernel of L -+ L". Then L 2 c L' so we get an epimorphism
L'-+M'.

XX, §3
EULER CHARACTERISTIC AND THE GROTHENDIECK GROUP
777
Th is now allows us to con struct resolutions inductively until we hit the
n-th step, where n is some integer such that M, M" admit resolutions of length
n in e. The last horizontal exact sequence that we obta in is
and L~ can be chosen to be the kernel of L~_ 1 -> L~ _ 2' By K 3 we know that
L ~ lies in e, and the sequence
o-> L~ -> L~_ 1
is exact. This implies that in the next inductive step, we can take L~ + 1 = O.
Then
is exact, and at the next step we just take the kernels of the vertical arrows to
complete the desired finite resolutions in e. This concludes the proof of the
lemma.
Remark.
The argument in the proof of Lemma 3.8 in fact shows :
If
o-> M' -> M -> M " -> 0
is an exact sequence in (1, and ifM , M " havefinite e-dimension, then so does
M '.
In the category of modules, one has a more precise statement:
Theorem 3.9.
Let (1 be the category of modules over a ring. Let (J> be the
family of projective modules. Given an exact sequence ofmodules
o-> E' -> E -> E" -> 0
if any two ofE', E, E" admitfinite resolutions in (J> then the third does also.
Proofs in a more subtle case will be given in Chapter XXI , Theorem 2.7.
Next we shall use the tensor product to investigate a ring structure on the
Grothendieck group . We suppose for simplicity that we deal with an abelian
category of modules over a commutative ring, denoted by (1, together with a K-
farnily C as above , but we now assume that (1 is closed under the tensor product.
The only properties we shall actually use for the next results are the following
ones, denoted by TG (for "tensor" and "Grothendieck" respectively):
TG 1.
There is a bifunctorial isomo rphism giving commutativity
M @ N~ N @M
for all M, N in (1 ; and similarly for distributivity over direct sums,
and associativity.

778
GENERAL HOMOLOGY THEORY
TG 2.
For all L in e the functor M t--->L ® M is exact.
TG 3.
If L, L' are in e then L ® L' is in e.
Then we may give K(e) the structure of an algebra by defining
cle(L) cle(L') = cle(L ® L').
XX, §3
Condition TG 1 implies that this algebra is commutative, and we call it the
Grothendieck algebra . In practice, there is a unit element, but if we want one in
the present axiomatization, we have to make it an explicit assumption :
TG 4.
There is an object R in e such that R ® M ~ M for all M in a.
Then cle(R) is the unit element.
Similarly, condition TG 2 shows that we can define a module structure on
K(a) over K(e) by the same formula
cle(L) cla(M) = cla(L ® M),
and similarly K(a(e)) is a module over K(e), where we recall that ace) is the
family of objects in a which admit finite resolutions by objects in e.
Since we know from Theorem 3.7 that K(e) = K(a(e», we also have a
ring structure on K(a(e» via this isomorphism. We then can make the product
more explicit as follows.
Proposition 3.10. Let ME ace) and let N E a. Let
o--+ L; --+ •• • --+ Lo --+ M --+ 0
be afinite resolution ofM by objects in e. Then
cle(M) cla(N) = L (-lY cla(Lj® N).
= L(-lY cla(Hi(K))
where K is the complex
o--+ L; ® N --+ • •• --+ Lo ® N --+ M ® N --+ 0
and Hi(K) is the i-th homologyofthis complex.
Proof.
The formulas are immediate consequences of the definitions, and of
Theorem 3. I.
Example.
Let a be the abelian category of modules over a commutative
ring. Let e be the family of projective modules . From §6 on derived functors
the reader will know that the homology of the complex K in Proposition 3.10
is just Tor(M, N). Therefore the formula in that proposition can also be written
cle(M) cla(N) = L(-lY cla(Tori(M, N)).

XX. §3
EULER CHARACTERISTIC AND THE GROTHENDIECK GROUP
779
Example.
Let k be a field. Let G be a group. By a (G, k)-module, we shall
mean a pair (E, p), consi sting of a k-space E and a homomorphism
Such a homomorphism is also called a representation of G in E. By abuse of
language, we also say that the k-space E is a G-moduJe. The group G operates
on E, and we write ax instead of p(a) x. The field k will be kept fixed in what
follows.
Let Modk(G) denote the category whose objects are (G, k)-modules. A mor-
phism in Modk(G) is what we call a G-homomorphism , that is a k-linear map
f: E ~ F such that f( ox) = af(x) for all a E G. The group of morphisms in
Modk(G) is denoted by Home '
If E is a G-module, and a E G, then we have by definition a k-automorphism
a: E -+ E. Since T' is a functor, we have an induced automorphism
T'(a) : T'(E) -+ Tr(E)
for each r, and thus F(E) is also a G-module. Taking the direct sum, we see
that T(E) is a G-module, and hence that T is a functor from the category of
G-modules to the category of graded G-modules. Similarly for /\r, S", and /\, S.
It is clear that the kernel of a G-homomorphism is a G-submodule, and that
the factor module of a G-module by a G-submodule is again a G-module so the
category of G-modules is an abelian category.
We can now apply the general considerations on the Grothendieck group
which we write
K(G) = K(Modk(G))
for simplicity in the present case. We have the canonical map
cl: Modk(G) ~ K(G) .
which to each G-module associates its class in K(G).
If E, Fare G-modules, then their tensor product over k, E @ F, is also a
G-module. Here again, the operation of G on E @ F is given functorially. If
a E G, there exists a unique k-linear map E @ F -+ E @ F such that for x E E,
y E F we have x @ y 1-+ (ax) @ (oy). The tensor product induces a law of
composition on Modk(G) becau se the tensor products of G-isomorphic modules
are G-isomorphic.
Furthermore all the conditions TG 1 through TG 4 are satisfied. Since k is a
field, we find also that tensoring an exact sequence of G-modules over k with any
G-module over k preserves the exactness, so TG 2 is satisfied for all (G, k)-
modules. Thus the Grothendieck group K(G) is in fact the Grothendieck ring,
or the Grothendieck algebra over k.

780
GENERAL HOMOLOGY THEORY
XX, §3
By Proposition 2.1 and Theorem 2.3 of Chapter XVIII , we also see:
The Grothendieck ring of a finite group G consisting ofisomorphism classes of
finite dimensional (G. k)-spaces over a field k of characteristic 0 is naturally
isomorphic to the character ring Xz(G).
We can axiomatize this a little more. We consider an abelian category of
modules over a commutative ring R, which we denote by <1 for simplicity. For
two modules M, N in <1 we let Mor(M, N) as usual be the morphisms in <1, but
Mor(M, N) is an abelian subgroup of HomR(M, N). For example, we could take
<1 to be the category of (G, k)-modules as in the example we have just discussed,
in which case Mor(M, N) = HomG(M, N).
We let e be the family of finite free modules in <1. We assume that e satisfies
TG 1,TG 2, TG 3, TG 4, and also that e is closed under taking alternating pro-
ducts, tensor products and symmetric products. We let K = K(e). As we have
seen, K is itself a commutative ring. We abbreviate d e = cl.
We shall define non-linear maps
Ai : K ~ K
using the alternating product. If E is finite free, we let
Proposition 1.1 of Chapter XIX can now be formulated for the K-ring as follows .
Proposition 3.11.
Let
o~ E' ~ E ~ E" ~ 0
be an exact sequence offinitefree modules in <1. Thenfor every integer n ~ 0
we have
n
An(E) = LAi(E')An- i(E").
i=O
As a result of the proposition, we can define a map
AI : K ~ I + tK[[t]]
of K into the multiplicative group of formal power series with coefficients in K,
and with constant term 1, by letting
00
AI(X) = L Ai(XW.
i=O

XX, §3
EULER CHARACTERISTIC AND THE GROTHENDIECK GROUP
781
Proposition 1.4 of Chapter XIX can be formulated by saying that:
The map
A, : K ...... 1 + tK[[t]]
is a homomorphism.
We note that if L isfree ofrank 1, then
AO(L) = ground ring ;
AteL) = c1(L) ;
Ai(L) = 0
for
i > 1.
This can be summarized by writing
A,(L) = 1 + c1(L)t.
Next we can do a similar construction with the symmetric product instead of
the alternating product. If E is a finite free module in e we let as usual :
See) = symmetric algebra of E;
Si(E) = homogeneous component of degree i in See).
We define
and the corresponding power series
Theorem 3.12.
Let E be a finite free module in (1, of rank r. Then for all
integers n ~ 1 we have
rL (_I)iAi(E)an- i(E) = 0,
i= O
where by definition aj(E) = 0for j < O. Furthermore
al(E)L,(E) = 1,
so the powerseries al(E) and A_,(E) are inverseto each other.
Proof.
The first formula depends on the analogue for the symmetric product
and the alternating product of the formula given in Proposition 1.1 of Chapter

782
GENERALHOMOLOGYTHEORY
XX, §4
XIX . It could be proved directly now , but the reader will find a proof as a special
case of the theory of Koszul complexes in Chapter XXI , Corollary 4 .14 . The
power series relation is essentiall y a reformulation of the first formula .
From the above formali sm, it is possible to define other maps besides Ai and
a',
Example.
Assume that the group G is trivial, and just write K for the
Grothendieck ring instead of K(l ). For x E K define
l/J- '(x) == - ( :r log A,(x) == - ( A; (x)/ A,(x).
Show that l/J-, is an additive and multiplicative homomorphism. Show that
l/J,(£) == I + cl(£) ( + cl(£)2(2 + ... .
Thi s kind of construction with the logarithmic derivative leads to the Adams
operations l/Ji in topology and algebraic geometry. See Exercise 22 of Chapter
XVIII.
Remark.
If it happens in Theorem 3.12 that E admits a decomposition into
I-dimensional free modules in the K-group, then the proof trivializes by using
the fact that A,(L) == I + cl(L)( if L is I-dimensional. But in the example of
(G, k)-spaces when k is a field, this is in general not possible, and it is also not
possible in other examples arising naturally in topology and algebraic geometry.
Howe ver , by "changing the base," one can sometimes achieve this simpler
situation, but Theorem 3.1 2 is then used in establishing the basic properties. Cf.
Grothendieck [SGA 6], mentioned in the introduction to Part IV, and other works
mentioned in the bibliography at the end , namel y [Ma 69], [At 61], [At 67],
[Ba 68], [Bo 62]. The lectures by Atiyah and Bott emphasize the topological
aspects as distinguished from the algebraic-geometric aspects. Grothendieck
[Gr 68] actually shows how the formalism of Chern classes from algebraic
geometry and topology also enters the theory of repre sentations of linear groups.
See also the exposition in [FuL 85], especially the formalism of Chapter I, §6.
For special emphasis on applications to representation theory, see Brocket-tom
Dieck [BtD 85], especially Chapter II, §7, concerning compact Lie groups.
§4.
INJECTIVE MODULES
In Chapter III , §4, we defined projective modules, which have a natural
relation to free modules. By reversing the arrows, we can define a module Q to
be injective if it satisfies anyone of the following conditions which are equivalent:
I 1.
Given an y module M and a submodule M ', and a homomorphism
f :M' -> Q, there exists an extension of this homomorphism to M,

XX, §4
INJECTIVE MODULES
783
that is there exists h : M --+ Q making the following diagram commuta-
tive :
O~M'~M
fl/
Q
12.
The functor M H
HomA(M, Q) is exact.
13.
Every exact sequence 0 --+ Q --+ M --+ Mil --+ 0 splits.
We prove the equivalence. General considerations on homomorphisms as in
Proposition 2.1, show that exactness of the homed sequence may fail only at
one point, namely given
o --+ M' --+ M --+ Mil --+ 0,
the question is whether
HomiM, Q) --+ HomA(M' , Q) --+ 0
is exact. But this is precisely the hypothesis as formulated in I 1, so I 1 implies
12 is essentially a matter of linguistic reformulation, and in fact I 1 is equivalent
to 12.
Assume I 2 or I 1, which we know are equivalent. To get I 3 is immediate, by
applying Ll to the diagram :
O~Q~M
.j/
Q
To prove the converse, we need the notion of push-out (cf. Exercise 52 of
Chapter 1). Given an exact diagram
O~M'~M
I
Q
we form the push-out :
M'~M
I
j
Q ~ N = Q EBM ' M .

784
GENERAL HOMOLOGY THEORY
XX, §4
Since M' --+ M is a monomorphism, it is immediately verified from the construc-
tion of the push-out that Q --+ N is also a monomorphism. By 13, the sequence
splits, and we can now compose the splitting map N --+ Qwith the push-out map
M --+ N to get the desired h : M --+ Q, thus proving I 1.
We saw easily that every module is a homomorphic image of a free module.
There is no equally direct construction for the dual fact :
Theorem 4.1.
Every module is a submodule ofan injective module.
The proof will be given by dualizing the situation, with some lemmas.
We
first look at the situation in the category of abelian groups. If M is an abelian
group, let its dual group be M" = Hom(M, Q/Z). If F is a free abelian group,
it is reasonable to expect, and in fact it is easily proved that its dual F" is an
injective module, since injectivity is the dual notion of projectivity. Furthermore,
M has a natural map into the double dual M"", which is shown to be a mono-
morphism. Now represent M" as a quotient of a free abelian group,
F~M"~O.
Dualizing this sequence yields a monomorphism
O~ M"" ~ FA,
and since M is embedded naturally as a subgroup of M"", we get the desired
embedding of M as a subgroup of F" .
This proof also works in general, but there are details to be filled in. First
we have to prove that the dual of a free module is injective, and second we have
to be careful when passing from the category of abelian groups to the category
of modules over an arbitrary ring. We now carry out the details.
We say that an abelian group T is divisible if for every integer m, the homo-
morphism
mT: xJ---+mx
is surjective.
Lemma 4.2.
If T is divisible, then T is injective in the category of abelian
groups.
Proof
Let M' c M be a subgroup of an abelian group, and let f :M' --+ T
be a homomorphism. Let x E M. We want first to extend f to the module
(M', x) generated by M' and x. If x is free over M', then we select any value
t E T, and it is immediately verified that j'extends to (M', x) by giving the value
f(x) = t. Suppose that x is torsion with respect to M', that is there is a
positive integer m such that mx EM'. Let d be the period of x mod M', so

XX, §4
INJECTIVE MODULES
785
dx EM', and d is the least positive integer such that dx EM'. By hypothesis,
there exists an element U E T such that du = f(dx). For any integer n, and Z E M'
define
fez + nx) = fez) + nu.
By the definit ion of d. and the fact that Z is principal, one sees that this value
forf is independent of the representation of an element of (M', x) in the form
z + nx, and then it follows at once that this extended definition of f is a
homomorphism. Thus we have extended f to (M', x).
The rest of the proof is merely an application of Zorn's lemma. We consider
pairs (N , g) consisting of submodules of M containing M ', and an extension g
of f to N. We say that (N , g) ~ (N I' gl) if N c N 1 and the restriction of gl
to N is g. Then such pairs are inductively ordered. Let (N, g) be a maximal
element. If N
=1= M then there is some x E M, x ¢ N and we can apply the first
part of the proof to extend the homomorphism to (N, x), which contradicts
the maximality, and concludes the proof of the lemma.
Example.
The abelian groups Q/Z and R/Z are divisible, and hence are
injective in the category of abelian groups.
We can prove Theorem 4.1 in the category of abelian groups following the
pattern described above . If F is a free abelian group, then the dual FAis a direct
product of groups isomorphic to Q/Z, and is therefore injective in the category
of abelian groups by Lemma 4.2. This concludes the proof.
Next we must make the necessary remarks to extend the system to modules.
Let A be a ring and let T be an abelian group. We make Homz(A, T) into an
A-module as follows. Letf :A -> T be an abelian group homomorphism. For
a E A we define the operation
(af)(b) = f(ba) .
The rules for an operation are then immediately verified. Then for any A-module
X we have a natural isomorphism of abelian groups:
Indeed, let ljJ: X -> T be a Z-homomorphism. We associate with ljJ the homo-
morphism
f:X -> Homz(A, T)
such that
f(x)(a) = ljJ(ax).

786
GENERAL HOMOLOGY THEORY
XX, §4
The definition of the A-module structure on Homz(A, T) shows that f is an
A-homomorphism, so we get an arrow from Homz(X, T) to
Conversely, let f :X ~ Homz(A, T) be an A-homomorphism. We define the
corresponding tjJ by
tjJ(x) = f(x)(l).
It is then immediately verified that these maps are inverse to each other.
We shall apply this when T is any divisible group, although we think of T
as being Q/Z, and we think of the homomorphisms into T as representing the
dual group according to the pattern described previously.
Lemma 4.3. If T is a divisible abelian group,then Homz(A, T) is injectivein
the category ofA-modules.
Proof
It suffices to prove that if 0 ~ X ~ Y is exact in the category of
A-modules, then the dual sequence obtained by taking A-homomorphisms into
Homz(A, T) is exact, that is the top map in the following diagram is surjective.
Homz(Y, T)
----+
Homz(X, T)
----+0
But we have the isomorphisms described before the lemma, given by the vertical
arrows of the diagram, which is commutative. The bottom map is surjective
because T is an injective module in the category of abelian groups. Therefore
the top map is surjective, thus proving the lemma.
Now we prove Theorem 4.1 for A-modules. Let M be an A-module. We can
embed M in a divisible abelian group T,
O~ M 1, T.
Then we get an A-homomorphism
M ~ Homz(A, T)
by x ~fx, where fia) = f(ax). One verifies at once that x ~fx gives an em-
bedding of Min Homz(A, Ti, which is an injective module by Lemma 4.3. This
concludes the proof of Theorem 4.1 .

XX, §5
HOMOTOPIES OF MORPHISMS OF COMPLEXES
787
§5.
HOMOTOPIES OF MORPHISMS OF
COMPLEXES
The purpose of this section is to describe a condition under which homo-
morphisms of complexes induce the same map on the homology and to show
that this condition is satisfied in an important case, from which we derive
applications in the next section.
The arguments are applicable to any abelian category. The reader may pre-
fer to think of modules, but we use a langu age which applies to both, and is no
more complicated than if we insisted on dealing only with modules.
Let E = {(En, dn)} and E' = {(E'n, d'n)} be two complexes. Let
f, g : E -> E'
be two morphisms of complexes (of degree 0). We say thatfis homotopic to g
if there exists a sequence of homomorphisms
such that
J,
- d,(n-I'h + h
dn
n -
gn -
n
n + 1
•
Lemma 5.1.
Iff, g are homotopic, thenf, g induce the same homomorphism
on the homology H(E), that is
Proof
The lemma is immediate, because J" - gn vanishes on the cycles,
which are the kernel of d", and the homotopy condition shows that the image of
I, - gn is contained in the boundaries, that is, in the image of r»:».
Remark.
The terminology of homotopy is used because the notion and
formalism first arose in the context of topology . Cf. [ES 52] and [GreH 81].
We apply Lemma 5.1 to injective objects . Note that as usual the definition
of an injective module applies without change to define an injective object in
any abelian category . Instead of a submodule in I 1, we use a subobject, or
equivalently a monomorphism. The proofs of the equivalence of the three con-
ditions defining an injective module depended only on arrow-theoretic juggling,
and apply in the general case of abelian categories.
We say that an abelian category has enough injectives if given any object M
there exists a monomorphism

788
GENERAL HOMOLOGY THEORY
XX, §5
into an injective object. We proved in §4 that the category of modules over a
ring has enough injectives . We now assume that the abelian category we work
with has enough injectives.
By an injective resolution of an object M one means an exact sequence
such that each In(n ~ 0) is injective. Given M, such a resolution exists. Indeed,
the monomorphism
exists by hypothesis. Let MO be its image. Again by assumption, there exists a
monomorphism
0-> IO/Mo -> II,
and the corresponding homomorphism 1° -> II has kernel MO. So we have
constructed the first step of the resolution, and the next steps proceed in the
same fashion.
An injective resolution is of course not unique, but it has some uniqueness
which we now formulate.
Lemma5.2.
Consider two complexes :
0- M -
EO ------+ E I ------+ E2 -
• • •
~I
0------+ M ' ------+ 1° -
II -
12 -
•• •
Suppose that the top row is exact, and that each I" (n ~ 0) is injective. Let
cp : M -> M' be a given homomorphism.
Then there exists a morphism f of
complexes such thatf: , = cp; and any two such are homotopic.
Proof
By definition of an injective, the homomorphism M -> 1° via M'
extends to a homomorphism
which makes the first square commute:

XX, §5
HOMOTOPIES OF MORPHISMS OF COMPLEXES
789
Next we must constructII' We write the second square in the form
with the exact top row as shown. Again because [1 is injective, we can apply the
same argument and findII to make the second square commute. And so on,
thus constructing the morphism of complexesf
Suppose f, 9 are two such morphisms. We define ho : EO --+ M' to be O.
Then the condition for a homotopy is satisfied in the first instance, when
1-1 = g-I = tp,
Next let d" I : M --+ EO be the embedding of M in EO. Since [0 is injective,
we can extend
dO : EO11m d- I --+ E 1
to a homomorphism hi :E1 --+ [0 . Then the homotopy condition is verified for
10 - go' Since ho = 0 we actually have in this case
10 - go = h.do,
but this simplification is misleading for the inductive step which follows. We
assume constructed the map hn + I' and we wish to show the existence of hn + 2
satisfying
Since Irn dn = Ker dn+ I, we have a monomorphism E"+ 111m d" --+ e: 2. By
the definition of an injective object, which in this case is l" + 1, it suffices to prove
that
In+ 1 -
gn+ I - d'nhn+ 1
vanishes on the image of d",
and to use the exact diagram :
O--En+l/lm dn__ En+ 2
f n + I - 9n + 1j
r : 1
to get the existence of h;+ 2 : En + 2 --+ I"+ 1 extending In+ I
-
gn + i -
But we
have :
(fn+1 -
gn+1 -
d'nhn+l)dn
= (In+l -
gn +l)dn - d'"hn +ldn

790
GENERALHOMOLOGYTHEORY
= U,,+ I
-
g,,+I)d" - d'''U" - g" - d'(,,-I)h,,)
= U,,+I - g,, +I)d" - d'''U" - g,,)
=0
XX, §6
by induction
because d'd' = 0
becausef, g are
homomorphisms of
complexes.
This concludes the proof of Lemma 5.2.
Remark.
Dually, let PM' ~ M' ~ 0 be a complex with pi projective for
i ~ O,and let EM ~ M ~ Obearesolution. Let e : M' ~ Mbeahomomorphism.
Then <p extends to a homomorphism of complex P ~ E. The proof is obtained
by reversing arrows in Lemma 5.2. The books on homological algebra that I
know of in fact carry out the projective case, and leave the injective case to the
reader.
However, one of my motivations is to do here what is needed, for
instance in [Ha 77], Chapter III, on derived functors, as a preliminary to the
cohomology of sheaves. For an example of projective resolutions using free
modules, see Exercises 2-7, concerning the cohomology of groups .
§6.
DERIVED FUNCTORS
We continue to work in an abelian category. A covariant additive functor
F :C1~CB
is said to be left exact if it transforms an exact sequence
O~M'~M~M "
into an exact sequence 0 ~ F(M') ~ F(M) ~ F(M"). We remind the reader
that F is called additive if the map
Hom(A', A) ~ Hom(FA', FA)
is additive.
We assume throughout that F is left exact unless otherwise specified, and
additive. We continue to assume that our abelian category has enough in-
jectives.
Given an object M, let
o~ M ~ [0 ~ [I ~ [2 ~
be an injective resolution, which we abbreviate by
O~M~IM'
where [M is the complex 1° ~ II ~ [2~. We let [ be the complex
O~ [0 ~ [I ~ [2 ~

XX, §6
DERIVED FUNCTORS
791
We define the right-derived functor WF by
WF(M) = H"(F(I)),
in other words, the n-th homology of the complex
o~ F(I°) ~ FW) ~ F(I2) ~
Directly from the definitions and the monomorphism M ~ 1o, we see that there
is an isomorphism
ROF(M) = F(M).
This isomorphism seems at first to depend on the injective resolution, and so
do the functors RnF(M) for other n. However, from Lemmas 5.1 and 5.2 we
see that given two injective resolutions of M, there is a homomorphism between
them, and that any two homomorphisms are homotopic. Ifwe apply the functor
F to these homomorphisms and to the homotopy, then we see that the homology
of the complex F(I) is in fact determined up to a unique isomorphism. One
therefore omits the resolution from the notation and from the language.
Example 1.
Let R be a ring and let a = Mod(R) be the category of R-
modules. Fix a module A . The functor M ~ Hom(A , M) is left exact, i.e. given
an exact sequence 0 ~ M' ~ M ~ Mil, the sequence
o~ Hom(A , M') ~ Hom(A, M) ~ Hom (A , Mil)
is exact. Its right derived functors are denoted by Extn(A , M) for M variable.
Similarly, for a fixed module B, the functor X ~ Hom (X, B) is right exact,
and it gives rise to its left derived functors . For the explicit mirror image of
the terminology, see the end of this section. In any case, we may consider A as
variable. In §8 we shall go more deeply into this aspect of the formali sm, by
dealing with bifunctors. It will turn out that Ext" (A, B) has a dual interpretation
as a left derived functor of the first variable and right derived functor of the
second variable. See Corollary 8.5.
In the exercises, you will prove that Ext I (A, M) is in bijection with iso-
morphi sm classes of extensions, of M by A, that is, isomorphism classes of exact
sequences
O~A~E~M~O.
The name Ext comes from this interpretation in dimension 1.
For the computation of Exti in certain important cases , see Chapter XXI,
Theorems 4.6 and 4.11 , which serve as examples for the general theory .
Example 2.
Let R be commutative. The functor M ~ A 0 M is right exact,
in other words , the sequence
A ® M' ~ A 0 M ~ A 0 M il ~ 0
is exact. Its left derived functor s are denoted by Torn(A, M) for M variable.

792
GENERALHOMOLOGYTHEORY
XX, §6
Example 3.
Let G be a group and let R = Z[G] be the group ring . Let <l
be the category of G-modules, i.e. <l = Mod(R), also denoted by Mod(G). For
a G-module A, let AG be the submodule (abelian group) consisting of those
elements v such that xv = v for all x E G. Then A ~ AG is a left exact functor
from Mod(R) into the category of abelian groups. Its left derived functors give
rise to the cohomology of groups. Some results from this special cohomology
will be carried out in the exercises, as further examples of the general theory.
Example 4.
Let X be a topological space (we assume the reader knows
what this is). By a sheaf ;r of abelian groups on X, we mean the data:
(a) For every open set V of X there is given an abelian group ;r (V).
(b) For every inclusion V C V of open sets there is given a homomorphism
res~ : ;r(V) ~ ;reV) ,
called the restriction from V to V, subject to the following conditions:
SH 1. ;r(empty set) = O.
SH 2.
res~ is the identity ;r(V) ~ ;r(V).
SH 3. If W eve V are open sets, then resw
0 res~ = res~
.
SH 4. Let V be an open set and {V;} be an open covering of V. Let
s E ;r (V). If the restriction of s to each V; is 0, then s=:O.
SH 5. Let V be an open set and let {V;} be an open covering of V . Suppose
given si E ;r(V;) for each i , such that given i , j the restrictions of si
and Sj to V; n Vj are equal. Then there exists a unique S E ;r (V) whose
restriction to V; is S; for all i .
Elements of ;r (V) are called sections of ;r over V. Elements of ;r (X) are called
global sections. Just as for abelian groups, it is possible to define the notion of
homomorphisms of sheaves, kernels, cokernels, and exact sequences. The asso-
ciation ;r ~ ;r (X) (global sections functor) is a functor from the category of
sheaves of abelian groups to abelian groups, and this functor is left exact. Its
right derived functors are the basis of cohomology theory in topology and algebraic
geometry (among other fields of mathematics). The reader will find a self-
contained brief definition of the basic properties in [Ha 77], Chapter II, §1, as
well as a proofthat these form an abelian category. For a more extensive treatment
I recommend Gunning's [Gu 91], mentioned in the introduction to Part IV,
notably Volume III, dealing with the cohomology of sheaves.
We now return to the general theory of derived functors . The general theory
tells us that these derived functors do not depend on the resolution by projectives
or injectives according to the variance. As we shall also see in §8, one can even
use other special types of objects such as acyclic or exact (to be defined), which
gives even more flexibility in the ways one has to compute homology. Through
certain explicit resolutions, we obtain means of computing the derived functors

XX, §6
DERIVED FUNCTORS
793
explicitly. For example, in Exercise 16, you will see that the cohomology of
finite cyclic groups can be computed immediately by exhibiting a specific free
resolution of Z adapted to such groups. Chapter XXI will contain several other
examples which show how to construct explicit finite free resolutions, which
allow the determination of derived functors in various contexts.
The next theorem summarizes the basic properties of derived functors .
Theorem 6.1.
Let ct be an abelian category with enough injectives, and let
F :ct -+ <13 be a covariant additive left exact functor to another abelian cate-
gory <13. Then:
(i) For each n ~ 0, R"F as defined above is an additivefunctor from ct
to <13. Furthermore, it is independent, up to a unique isomorphism of
functors, of the choices ofresolutions made.
(ii) There is a natural isomorphism F ~ ROF.
(iii) For eachshort exact sequence
o-+ M' -+ M -+ M " -+ 0
andfor each n ~ 0 there is a naturalhomomorphism
b":R"F(M") -+ W +1F(M)
such that we obtain a longexact sequence:
-+ R"F(M') -+ WF(M) -+ R"F(M") ~ w+ 1F(M') -+ .
(iv) Given a morphism ofshort exact sequences
o----> M ' ----> M ----> M" ----> 0
I
I
I
o----> N' ----> N ----> N" ----> 0
the (j's give a commutative diagram :
WF(M") ~ w+ 1F(M')
I
I
R"F(N") ~ W+ 1F(N')
(v) ForeachinjectiveobjectI ofA andfor eachn > owehaveR"F(I) = O.
Properties (i), (ii), (iii), and (iv) essentially say that R"F is a delta-functor in a
sense which will be expanded in the next section. The last property (v) will be
discussed after we deal with the delta-functor part of the theorem.

794
GENERAL HOMOLOGY THEORY
XX, §6
We now describe how to construct the J-homomorphisms. Given a short
exact sequence, we can find an injective resolution of M', M, M" separately, but
they don't necessarily fit in an exact sequence of complexes. So we must achieve
this to apply the considerations of §1. Consider the diagram :
o
0
0
I
j
I
o~ M' ------> M ------> M"~ 0
I
I
I
O~I'°~X~]"o~O.
We give monomorphisms M' -> /'0 and M" -> ]"0 into injectives, and we want to
find X injective with a monomorphism M -> X such that the diagram is exact.
We take X to be the direct sum
X = 1'0 EB ]"0.
Since 1'0 is injective, the monomorphism M' -> ]'0 can be extended to a homo-
morphism M -> ]'0. We take the homomorphism of Minto ]'0 EB ]"0 which
comes from this extension on the first factor 1'0, and is the composite map
M -> M" -> ]"0
on the second factor. Then M -> X is a monomorphism. Furthermore I'? -> X
is the monomorphism on the first factor, and X -> ]"0 is the projection on the
second factor.
So we have constructed the diagram we wanted, giving the
beginning of the compatible resolutions.
Now we take the quotient homomorphism, defining the third row, to get an
exact diagram :
o
0
0
I
I
I
o~ M' ~ M ~ M" ------> 0
I
I
I
o~]'o ------> /0 ~ ]"0 ~ 0
I
I
I
O~N ' ------> N ~N " ~O
I
I
I
o
0
0

XX, §6
DERIVED FUNCTORS
795
where we let 1° = X , and N' , N, N" are the cokernels of the vertical maps by
definition. The exactness of the N-sequence is left as an exercise to the reader.
We then repeat the construction with the N-sequence,and by induction construct
injecti ve resolutions
o
0
0
I
I
I
O~M'~M~M"~O
I
I
I
O~/ :W .~/M~/'J.t,,~O
of the M-sequence such that the diagram of the resolutions is exact.
We now apply the functor F to this diagram. We obtain a short sequence of
complexes:
o--> F(l') --> F(l) --> F(I") --> 0,
which is exact because 1 = I' E9 I" is a direct sum and F is left exact , so F com-
mutes with direct sums. We are now in a position to apply the construction of
§1 to get the coboundary operato r in the homology sequence:
WF(M ') --> WF(M) --> WF(M") ~ w+1F(M').
This is legitimate because the right deri ved functor is independent of the chosen
resolutions.
So far, we have pro ved (i), (ii), and (iii). To pro ve (iv), that is the naturality of
the delt a homomorphisms, it is necessary to go through a three-dimensional
commutative diagram. At this point, I feel it is best to leave this to the reader,
since it is just more of the same routine.
Finally, the last property (v) is obvious, for if 1 is injective, then we can
use the resolution
to compute the derived functors, from which it is clear that R"F = 0 for n > O.
This concludes the proof of Theorem 6.1.
In applications, it is useful to determine the derived functors by means of
other resolutions besides injective ones (which are useful for theoretical
purposes, but not for computational ones). Let again F be a left exact additive
functor. An object X is called F-acyclic if RnF(X) = 0 for all n > O.

796
GENERAL HOMOLOGY THEORY
Theorem 6.2.
Let
be a resolution of M by F-acyclics. Let
XX, §6
beaninjectiveresolution. Thenthere existsamorphismof complexes X M -+ 1M
extending the identity on M , and this morphism induces an isomorphism
WF(X) ~ H"F(I) = R"F(M)
for all n ~ O.
Proof
The existence of the morphism of complexes extending the identity
on M is merely Lemma 5.2. The usual proof of the theorem via spectral se-
quences can be formulated independently in the following manner, shown to
me by David Benson. We need a lemma.
Lemma 6.3.
Let y i (i ~ 0) be F-acyclic, and suppose the sequence
o-+ yO-+ y' -+ y 2 -+ . . .
is exact. Then
is exact.
Proof
Since F is left exact, we have an exact sequence
We want to show exactness at the next joint. We draw the cokernels:
o ------+ yO------+ y' ------+ Y2 ------+ Y3
So 2, = Coker(Yo -+ Y') ; 2 2 = Coker(Y' -+ y 2) ; etc. Applying F we have
an exact sequence

XX, §6
DERIVED FUNCTORS
797
So F(Z I) = Coker(F(Yo) -> F(y l». We now consider the exact sequence
giving the exact sequence
by the left-exactness of F, and proving what we wanted . But we can now
continue by induction because Z 1 is F-acyclic, by the exact sequence
This concludes the proof of Lemma 6.3.
We return to the proof of Theorem 6.2. The injective resolution
can be chosen such that the homomorphisms X n -> In are monomorphisms for
n ~ 0, because the derived functor is independent of the choice of injective
resolution. Thus we may assume without loss of generality that we have an
exact diagram :
000
j
j
j
0~M--4XO~Xl_X2-
;'[
[
[
[
O_M_/O_/1 _/2--4
j
j
j
0_yO_y1_y2 _
j
j
j
000
defining yn as the appropriate cokernel of the vertical map.
Since X" and In are acyclic, so is yn from the exact sequence
Applying F we obtain a short exact sequence of complexes
0-> F(X) -+ F(1) -> F(Y) -+ O.

798
GENERAL HOMOLOGY THEORY
XX, §6
whence the corresponding homology sequence
tr:' F(Y) --+ HnF(X) --+ HnF(I) --+ HnF(Y).
Both extremes are 0 by Lemma 6.3, so we get an isomorphism in the middle,
which by definition is the isomorphism
HnF(X) ~ WF(M),
thus proving the theorem.
Left derived functors
We conclude this section by a summary of the properties of left derived
functors.
Weconsider complexes going the other way,
--+Xn--+···--+X2-+Xt-+Xo-+M-+O
which we abbreviate by
X M --+ M --+ O.
We call such a complex a resolution of M if the sequence is exact. We call it a
projective resolution if Xn is projective for all n ~ O.
Given projective resolutions X M' YM ' and a homomorphism
sp :M --+ M '
there always exists a homomorphism X M -+ YM , extending ip, and any two
such are homotopic.
In fact, one need only assume that XM is a projective resolution, and that
YM , is a resolution, not necessarily projective, for the proof to go through.
Let T be a covariant additive functor. Fix a projective resolution of an ob-
ject M,
PM --+ M -+ O.
We define the left derived functor L;T by
where T(P) is the complex
The existence of homotopies shows that L; T(M) is uniquely determined up
to a unique isomorphism if one changes the projective resolution.
We define T to be right exact if an exact sequence
M ' -+ M -+ M " --+ 0

XX, §7
yields an exact sequence
DELTA-FUNCTORS
799
T(M') --> T(M) --> T(M") --> 0.
If T is right exact, then we have immediately from the definitions
t.; T(M) ~ M.
Theorems 6.1 and 6.2 then go over to this case with similar proofs. One
has to replace" injectives" by "projectives" throughout, and in Theorem 6.1,
the last condition states that for n > 0,
LII T(P) = °
if P is projective.
Otherwise, it is just a question of reversing certain arrows in the proofs . For
an example of such left derived functors, see Exercises 2-7 concerning the
cohomology of groups .
§7.
DELTA-FUNCTORS
Inthis section, we axiomatize the properties stated in Theorem 6.1 following
Grothendieck.
Let a, CB be abelian categories. A (covariant) l5-fuDctor from a to CB is a
family of additive functors F =
{FII }II ~o, and to each short exact sequence
°--> M ' --> M --> M" -->°
an associated family of morphisms
l5" : F"(M") --> F" +1(M')
with n ~ 0, satisfying the following conditions:
DEL 1.
For each short exact sequence as above, there is a long exact
sequence°--> FO(M')
--> FO(M) --> FO(M") --> F 1(M') --> • • •
--> F"(M') --> F"(M) --> F"(M") --> F" +1(M') -->
DEL 2.
For each morphism of one short exact sequence as above into
another °--> N' --> N --> N" --> 0, the
l5's give a commutative
diagram :
F"(M") ~ F" +1(M')
I
I
F"(N") ~ F" +1(N').

800
GENERAL HOMOLOGY THEORY
XX, §7
Before going any further, it is useful to give another definition. Many proofs
in homology theory are given by induction from one index to the next. It turns
out that the only relevant data for going up by one index is given in two succes-
sive dimensions, and that the other indices are irrelevant. Therefore we general-
ize the notion of Ci-functor as follows.
A o-functor defined in degrees 0, 1 is a pair of functors (pO, F 1) and to
each short exact sequence
o-> A' -> A -> A" -> 0
an associated morphism
satisfying the two conditions as before, but putting n = 0, n + 1 = 1, and for-
getting about all other integers n. We could also use any two consecutive posi-
tive integers to index the Ci-functor, or any sequence of consecutive integers
~ O. In practice, only the case of all integers ~ 0 occurs, but for proofs, it is
useful to have the flexibility provided by using only two indices, say 0, 1.
The (i-functor F is said to be universal, if given any other Ci-functor G of (1
into CB, and given any morphism of functors
there exists a unique sequence of morphisms
for all n ~ 0, which commute with the 15" for each short exact sequence.
By the definition of universality, a Ci-functor G such that GO = FO is uniquely
determined up to a unique isomorphism of functors. We shall give a condition
for a functor to be universal.
An additive functor F of (1 into CB is called erasable if to each object A there
exists a monomorphism u : A -> M for some M such that F(u) = O. In practice,
it even happens that F(M) = 0, but we don't need it in the axiomatization.
Linguistic note.
Grothendieck originally called the notion" effaceable" in
French. The dictionary translation is "erasable," as I have used above.
Ap-
parently people who did not know French have used the French word in English,
but there is no need for this, since the English word is equally meaningful and
convenient.
We say the functor is erasable by injectives if in addition M can be taken to
be injective.

XX, §7
DELTA-FUNCTORS
801
Example.
Of course , a right deri ved functor is erasable by injectives, and
a left derived functor by projectives. However, there are many cases when one
wants erasability by other types of objects. In Exercises 9 and 14, dealing with
the cohomology of groups, you will see how one erases the cohomology functor
with induced modules, or regular modules when G is finite . In the category of
coherent sheaves in algebraic geometry, one erases the cohomology with locally
free sheaves of finite rank.
Theorem 7.1.
Let F = {P} be a covariant S-functorf rom (I into <B. IfPis
erasable for each n > 0, then F is universal.
Proof
Given an object A, we erase it with a monomorphism u, and get a
short exact sequence:
o-> A ~ M -> X -> O.
Let G be another b-functor with given fo : FO -> GO. We have an exact com-
mutative diagram
We get the 0 on the top right because of the erasability assumption that
Fl(cp) = O.
We want to construct
which makes the diagram commutative, is functorial in A, and also commutes
with the b. Commutativity in the left square shows that Ker bF is contained in
the kernel of bG 0 fo . Hence there exists a unique homomorphism
f l(A ): Fl(A) -> Gl(A)
which makes the right square commutative. We are going to show thatfl(A)
satisfies the desired conditions. The rest of the proofthen proceeds by induction
following the same pattern.
We first prove the functoriality in A.
Let u : A -> B be a morphism. We form the push-out P in the diagram
B -----+ P

802
GENERAL HOMOLOGY THEORY
XX, §7
Since qJ is a monomorphism, it follows that B --+ P is a monomorphism also.
Then we let P --+ N be a monomorphism which erases Fr- This yields a com-
mutative diagram
o------+ B ------+ N ------+ Y ------+ 0
where B --+ N is the composite B --+ P --+ N, and Y is defined to be the cokernel
of B --+ N.
Functoriality in A means that the following diagram is commutative.
This square is the right-hand side of the following cube:
All the faces of the cube are commutative except possibly the right-hand face.
It is then a general fact that ifthe top maps here denoted by (jFare epimorphisms,

XX, §7
DELTA-FUNCTORS
803
then the right-hand side is commutative also. This can be seen as follows . We
start with ! 1(B)FI(u)DF • We then use commutativity on the top of the cube,
then the front face, then the left face, then the bottom, and finally the back face.
Th is yields
Since DF is an epimorphism, we can cancel DF to get what we want.
Second, we have to show that j', commutes with D. Let
0-+ A' -+ A -+ A" -+ 0
be a short exact sequence. The same push-out argument as before shows that
there exists an erasing monomorphism 0 -+ A' -+ M and morphisms v,
W
making the following diagram commutative:
o----+ A' ----+ A ----+ A"----+ 0
;,]
j,
j,
0----+ A' ----+ M ----+ X ----+ 0
Here X is defined as the appropriate cokernel of the bottom row . We now
consider the following diagram :
Our purpose is to prove that the right-hand face is commutative. The triangles
on top and bottom are commutative by the definition of a (j-functor. The

804
GENERAL HOMOLOGY THEORY
XX, §7
left-hand square is commutative by the hypothesis that fo is a morphism
of functors.
The front square is commutative by the definition of fl (A').
Therefore we find :
fl(A ')c5F = fl(A')c5 FFo(w)
= c5F foFO(w)
= c5FGO(w)fo
=
c5F fo
(top triangle)
(front square)
(left square)
(bottom triangle).
This concludes the proof of Theorem 7.1, since instead of the pair of indices
(0, 1) we could have used (n, n + 1).
Remark.
The morphism fl constructed in Theorem 7.1 depends functori-
ally onfo in the following sense. Suppose we have three delta functors F, G, H
defined in degrees 0, 1. Suppose given morphisms
I« :FO -. GO
and
go:GO -. HO.
Suppose that the erasing monomorphisms erase both F and G. Then we can
constructj, and gl by applying the theorem. On the other hand, the composite
gofo=ho:F°-.Ho
is also a morphism of functors, and the theorem yields the existence of a morph-
ism
hI: F I -. HI
such that (ho, hI) is a c5-morphism. By uniqueness, we therefore have
This is what we mean by the functorial dependence as mentioned above.
Corollary 7.2.
Assume that a hasenoughinjectioes. Thenfor any left exact
junctor F: a -. ill, the derived functors R"F with n ~ 0 form a universal
o-functor with F:::::: ROF, which is erasable by injectives.
Conversely, if
G =
{G"}"~o is a universal o-functor, then GO is left exact, and the G" are
isomorphicto R"GO for each n ~ o.
Proof.
If F is a left exact functor, then the
{R "F } " ~ o form a c5-functor
by Theorem 6.1. Furthermore, for any object A, let u: A -. I be a monomor-
phism of A into an injective.
Then R"F(I) = 0 for n > 0 by Theorem
6.l(iv), so R"F(u) = O. Hence R"F is erasable for all n > 0, and we can apply
Theorem 7.1.
Remark.
As usual, Theorem 7.1 applies to functors with different variance.
Suppose {F"} is a family of contravariant additive functors, with n ranging over

XX, §7
DELTA·FUNCTORS
805
a sequence of consecutive integers, say for simplicity n ~ O. We say that F is a
contravariant b-functor if given an exact sequence
o-. M' -. M -. M" -. 0
then there is an associated family of morphisms
D" : F"(M') -. F" +l(M')
satisfying DEL 1 and DEL 2 with M' interchanged with M" and N' inter-
changed with N". We say that F is coerasable if to each object A there exists an
epimorphism u : M -. A such that F(u) = O.
We say that F is universal if
given any other D-functor G of (1 into CB and given a morphism of functors
fo :FO -. GO
there exists a unique sequence of morphisms
f" :F" -. G"
for all n ~ 0 which commute with Dfor each short exact sequence.
Theorem 7.1'.
Let F = {F"} (n ranging over a consecutive sequence of
integers ~ 0) be a contravariant b-functorfrom (1 into CB, and assume that
F" is coerasable for n ~ 1. Then F is universal.
Examples of D-functors with the variances as in Theorems 7.1 and 7.1' will
be given in the next section in connection with bifunctors.
Dimension shifting
Let F = {F"} be a contravariant delta functor with n ~ O. Let e be a
family of objects which erases F" for all n ~ 1, that is F"(E) = 0 for n ~ 1 and
E E e. Then such a family allows us to do what is called dimension shifting as
follows. Given an exact sequence
O-.Q-.E-.M-.O
with E E e, we get for n ~ 1 an exact sequence
o= F"(E) -. F"(Q) -. F" +I(M) -. F" +I(E) = 0,
and therefore an isomorphism
F"(Q) .s, F" +I(M),
which exhibits a shift of dimensions by one. More generally:
Proposition 7.3.
Let
0-. Q-. E"_ I -. .. . -. Eo -. M -. 0

806
GENERAL HOMOLOGY THEORY
XX, §8
be an exact sequence,such that E;E E, Then we have an isomorphism
for p ~ 1.
Proof
Let Q= Qn' Also without loss of generality, take p = 1. We may
insert kernels and cokernels at each step as follows:
M
\ o
En - I -----+ En- 2 -----+ . . . -----+1Eo
/ \ / \ /
/ :
c,
Qn - 1
Qn- 2
e.
/
/ \ / \ \ /
o
0
0
0···0
Then shifting dimension with respect to each short exact sequence, we find
isomorphisms
This concludes the proof.
One says that M ha s F-dimension ~ d if Fn(M) = 0 for n ~ d + 1. By
dimension shifting, we see that if M has F-dimension
~ d, then Q has F-
dimension ~ d - n in Proposition 7.3. In particular, if M has F-dimension n,
then Qhas F-dimension O.
The reader should rewrite all thi s formalism by changing notation, using for
F the standard functors arising from Hom in the first variable, on the category
of modules over a ring, which has enough projectives to erase the left derived
functors of
A 1-+ Hom(A, B),
for B fixed. We shall study th is situation, suitably axiomatized, in the next sec-
tion.
§8.
BIFUNCTORS
In an abelian category one often deals with Hom, which can be viewed as a
functor in two variables; and also the tensor product, which is a functor in two
variables, but their variance is different. In any case, these examples lead to the
notion of bifunctor. Thi s is an association
(A, B) 1-+ T(A, B)

XX, §8
BIFUNCTORS
807
where A, B are objects of abelian categories a and CB respectively, with values
in some abelian category. Th is mean s that T is functo rial in each variable, with
the appropriate variance (there are four possibilities, with covariance and con-
travariance in all possible combinations) ; and if, say, T is covariant in all
variables, we also require that for homomorphisms A' -+ A and B' -+ B there
is a commutative diagram
T(A', B') ---+ T (A', B)
I
I
T(A, B') ---+ T (A, B).
If the variances are shuffled, then the arrows in the diagram are to be reversed in
the appropriate manner. Finally, we require that as a functor in each variable,
T is additive.
Note that Hom is a bifunctor, contravariant in the first variable and covari-
ant in the second. The tensor product is covariant in each variable.
The Hom functor is a bifunctor T satisfying the following properties:
HOM 1.
T is contravariant and left exact in thefirst variable.
HOM 2.
T is covariant and left exact in the second variable.
HOM 3.
For any injective object J thefunctor
A 1---+ T (A, J)
is exact.
They are the only propert ies which will enter into consideration in this
section. There is a possible fourth one which might come in other times:
HOM 4.
For any projectiveobject Qthefunctor
BI---+T(Q,B)
is exact.
But we shall deal non-symmetrically, and view T as a functor of the second
variable, keeping thefirst onefixed, in order to get derivedfunctors of the second
variable. On the other hand, we shall also obtain a <5-functor of the first variable
by using the bifunctor, even though this <5-functor is not a derived functo r.
If CB has eno ugh injectives, then we may form the right derived functors with
respect to the second variable
B 1---+ R" T (A, B),
also denoted by R" TiB),

808
GENERAL HOMOLOGY THEORY
XX, §8
fixing A, and viewing B as variable. If T = Hom, then this right derived functor
is called Ext, so we have by definition
ExnA , X) = R" Hom(A , X).
We shall now give a criterion to compute the right derived functors in terms
of the other (first) variable. We say that an object A is T-exact if the functor
B ~ T(A, B) is exact. Bya T-exact resolution of an object A, we mean a resolu-
tion
where M; is T-exact for all n ~ 0.
Examples.
Let Q and <B be the categories of modules over a commutative
ring. Let T = Hom. Then aT-exact object is by definition a projective module.
Now let the transpose of T be given by
'T (A, B) = T(B, A).
Then a 'T-exact object is by definition an injective module.
If T is the tensor product, such that T(A, B) = A 0 B, then a T-exact object
is called flat.
Remark.
In the category of modules over a ring, there are enough pro-
jectives and injectives. But there are other situations when this is not the case.
Readers who want to see all this abstract nonsense in action may consult
[GriH 78], [Ha 77], not to speak of [SGA 6] and Grothendieck's collected works.
It may genuinely happen in practice that <B has enough injectives but Q does not
have enough projectives, so the situation is not all symmetric. Thus the functor
A ~ RnT(A, B) for fixed B is not a derived functor in the variable A. In the
above references, we may take for Q the category of coherent sheaves on a
variety, and for <B the category of all sheaves. We let T = Hom. The locally
free sheaves of finite rank are T-exact, and there are enough of them in Q. There
are enough injectives in <B. And so it goes. The balancing act between T-exacts
on one side, and injectives on the other is inherent to the situation.
Lemma 8.1.
Let T be a bifunctor satisf ying HOM 1, HOM 2. Let A E Q,
and let M A -> A -> 0, that is
be a T-exact resolution of A. Let Fn(B) = Hn(T(M, B))for BE <B. Then F
is a o-functor and FO(B) = T(A, B).
If in addition T satisfies HOM 3,
then P(J) =°for J injective and n ~ 1.

XX, §8
Proof
Given an exact sequence
o~ B' ~ B ~ B" ~ 0
we get an exact sequence of complexes
BIFUNCTORS
809
o~ T(M, B') ~ T(M, B) ~ T(M, B") ~ 0,
whence a cohomology sequence which makes F into a D-functor. For n = 0
we get FO(B) = T(A, B) because X ~ T(X, B) is contravariant and left exact
for X E Q. If B is injective, then PCB) = 0 for n ~ 1 by HOM 3, because
X ~ T(X, B) is exact. This proves the lemma.
Proposition 8.2.
Let T be a bifunctor satisfying HOM 1, HOM 2, HOM 3.
Assume that ill has enough injectives. Let A E Q. Let
be a T-exact resolution of A. Then the two o-functors
B ~ R"T(A, B)
and
B ~ Hn(T(M, B))
are isomorphic as universal o-functors vanishing on injectives,for n ~ 1, and
such that
ROT(A, B) = HO(T(M), B) = T(A, B).
Proof
This comes merely from the universality of a D-functor erasable
by injectives.
We now look at the functoriality in A.
Lemma 8.3.
Let T satisfy HOM 1, HOM 2, and HOM 3. Assume that
ill has enough iniectioes. Let
o~ A' ~ A ~ A" ~ 0
be a short exact sequence. Then for fixed B, we have a long exact sequence
o~ T(A", B) ~ T(A, B) ~ T(A', B) ~
~ R1T(A", B) ~ R1T(A, B) ~ R1T(A', B)-+
such that the association
A ~R"T(A, B)
is a D1unctor.

810
GENERAL HOMOLOGY THEORY
XX, §8
Proof
Let 0 ~ B ~ I B be an injective resolution of B. From the exactness
of the functor A f-+ T(A, J), for J injective we get a short exact sequence of
complexes
Taking the associated long exact sequence of homology groups of these com-
plexes yields the sequence of the proposition.
(The functorality is left to
the readers.)
If T = Hom, then the exact sequence looks like
o~ Hom(A", B) ~ Hom(A, B) ~ Hom(A', B) ~
~ Ext 1(A", B) ~ Ext 1(A, B) ~ Ext 1(A', B) ~
and so forth.
We shall say that Q has enough T-exacts if given an object A in Q there is a
T-exact M and an epimorphism
M ~ A -+ O.
Proposition 8.4.
Let T satisfy HOM 1, HOM 2, HOM 3. Assume that CB
has enough injectives. Fix BE CB. Then the association
A f-+ R"T(A, B)
is a contravariant o-functor on Q which vanishes on T-exacts,jor n ~ 1. If
Q has enough T -exacts, then this functor is universal, coerasable by T -exacts,
with value
ROT(A, B) = T(A, B).
Proof
By Lemma 8.3 we know that the association is a c5-functor, and it
vanishes on T -exacts by Lemma 8.1. The last statement is then merely an
application of the universality of erasable c5-functors.
Corollary 8.5.
Let Q = CB be the category ofmodules over a ring. For fixed
B, let ext"(A, B) be the left derived functor of A f-+ Hom(A, B), obtained by
means ofprojective resolutions of A. Then
ext"(A, B) = Ext"(A, B).
Proof
Immediate from Proposition 8.4.
The following proposition characterizes T-exacts cohomologically.

XX, §8
BIFUNCTORS
811
Proposition 8.6.
Let T be a bifunctor satisfying HOM 1, HOM 2, HOM 3.
Assume that <B has enough inject ioes.
Then the following conditions are
equivalent :
TE 1.
A is T -exact,
TE 2.
For every B and every integer n ~ 1, we have R"T(A , B) = O.
TE3.
For every B we have RIT(A , B) = O.
Proof
Let
0 ...... B ...... 10 ...... II ......
be an injective resolution of B. By definition, R"T(A, B) is the n-th homology of
the sequence
If A is T-exact, then this sequence is exact for n ~ 1, so the homology is 0 and
TE 1 implies TE 2. Trivially, TE 2 implies TE 3. Finally assume TE 3. Given
an exact sequence
o...... B' ...... B ...... B" ...... 0,
we have the homology sequence
o...... T (A , B' ) ...... T (A, B) ...... T (A , B"; ...... R 1T (A , B') .......
If R I T(A , B') = 0, then by definition A is T -exact , thu s proving the proposition.
We shall say that an object A has T -dimension ~ d if
R"T(A , B) = 0
for n > d and all B.
Then the proposition states in particular that A is T-exa ct if and only if A has
T -dimension O.
Proposition 8.7.
Let T satisfy HOM 1, HOM 2, HOM 3. Assume that <B
has enough injectives. Suppose that an object A admits a resolution
0 ...... Ed ...... Ed-I ...... . . . ...... Eo ...... A ...... 0
where Eo, ... , Ed are T-exact. Then A has T-dimension
~ d. Assume this
is the case. Let
o...... Q...... Ld _ I ...... .. . ...... Lo ...... A ...... 0
be a resolution where Lo, . .. , L d - I are T -exact. Then Q is T -exact also.
Proof
By dimension shifting we conclude that Q has T-dimension 0,
whence Qis T-exact by Proposition 8.6.

812
GENERAL HOMOLOGY THEORY
XX, §8
Proposition 8.7, like others, is used in the context of modules over a ring.
In that case, we can take T = Hom, and
R"T(A, B) = ExtncA, B).
For A to have T-dimension ~ d means that
Ext"(A, B) = 0
for n > d and all B.
Instead of T-exact, one can then read projective in the proposition.
Let us formulate the analogous result for a bifunctor that will apply to the
tensor product. Consider the following properties.
TEN 1.
T is covariant and right exact in thefirst variable.
TEN 2.
T is covariant and right exact in the second variable.
TEN 3.
For any projective object P thefunctor
A I---> T(A, P)
is exact.
As for Hom, there is a possible fourth property which will play no role in this
section:
TEN 4.
For any projective object Qthefunctor
BI---> T(Q, B)
is exact.
Proposition 8.2'.
Let T be a bifunctor satisfying TEN 1, TEN 2, TEN 3.
Assume that <B has enough projectives. Let A E Q. Let
be a T-exact resolution of A. Then the two o-functors
are isomorphicas universal o-functors vanishing on projectives, and such that
i.; T(A, B) = Ho(T(M), B) = T(A, B).
Lemma 8.3'.
Assume that T satisfies TEN 1,TEN 2, TEN 3. Assume that
<B has enough projectives. Let
o-+ A' -+ A -+ An -+ 0

XX, §8
BIFUNCTORS
813
be a short exact sequence. Then for fixed B, we have a long exact sequence:
---> L 1T(A', B) ---> L 1T(A, B) ---> L 1T(A ", B) --->
---> T(A', B) ---> T(A , B) ---> T(A", B) ---> 0
which makes the association A f--->L; T(A , B) a o-functor.
Proposition 8.4'.
Let T satisfy TEN 1, TEN 2, TEN 3. Assume that CB has
enough projectives. Fix BE CB. Then the association
A f--->t; T(A, B)
is a contravariant b-functor on <1. which vanishes on T -exactsfor n f; 1. If <1.
has enough T -exacts, then this functor is universal, coerasable by T -exacts,
with the value
t.; T(A, B) = T(A, B).
Corollary 8.8.
If there is a bifunctorial isomorphism T(A, B) ;:::: T(B, A),
and if B is T-exact, then for all A, L; T(A , B) = 0 for n f; 1. In short,
T-exact implies acyclic.
Proof
Let M A = PA be a projective resolution in Proposition 8.2'. By
hypotheses, X f---> T(X, B) is exact so Hn(T(P, B)) = 0 for n f; 1; so the
corollary is a consequence of the proposition.
The above corollary is formulated so as to apply to the tensor product.
Proposition 8.6'.
Let T be a bifunctor satisf ying TEN 1, TEN 2, TEN 3.
Assume that
CB has enough projectives. Th en the following conditions are
equivalent :
TE 1.
A is T-exact.
TE 2.
For every B and every integer n f; 1 we have L; T(A, B) = O.
TE 3.
For every B, we have L I T(A, B) = O.
Proof
We repeat the proof of 8.6 so the reader can see the arrows pointing
in different ways.
Let
be a projective resolution of B. By definition, L, T(A , B) is the n-th homology
of the sequence

814
GENERAL HOMOLOGY THEORY
XX, §9
If A is T-exact, then this sequence is exact for n ~ 1, so the homology is 0, and
TE I implies TE 2. Trivially, TE 2 implies TE 3. Finally, assume TE 3. Given
an exact sequence
o-> B' -> B -> B" -> 0
we have the homology sequence
-> L 1T(A, B") -> T(A, B') -> T(A, B) -> T(A, B
n
) -> O.
IfL 1T(A, B") is 0, then by definition, A is T-exact, thus proving the proposition.
§9.
SPECTRAL SEQUENCES
This section is included for convenience of reference, and has two purposes:
first, to draw attention to an algebraic gadget which has wide applications in
topology, differential geometry, and algebraic geometry, see Griffiths-Harris,
[GrH 78]; second, to show that the basic description of this gadget in the context
in which it occurs most frequently can be done in just a few pages.
In the applications mentioned above, one deals with a filtered complex
(which we shall define later), and a complex may be viewed as a graded object,
with a differential d of degree 1. To simplify the notation at first, we shall deal
with filtered objects and omit the grading index from the notation. This index
is irrelevant for the construction of the spectral sequence, for which we follow
Godement.
So let F be an object with a differential (i.e. endomorphism) d such that
d2 = O. We assume that F isfiltered, that is that we have a sequence
and that dP c P . This data is called afiltered differential object. (We assume
that the filtration ends with 0 after a finite number of steps for convenience.)
One defines the associated graded object
Gr F = EEl GrPF
where
GrPF = P /P+ I .
P~O
Infact, Gr F is a complex, with a differential of degree 0 induced by d itself, and
we have the homology H(GrP F).
The filtration {P} also induces a filtration on the homology H(F, d) = H(F);
namely we let
H(F)P = image of H(P) in H(F).

XX, §9
SPECTRAL SEQUENCES
815
Since d maps P
into itself, H(P) is the homology of P
with respect to the
restriction of d to P , and it has a natural image in H(F) which yields this filtra-
tion. In particular, we then obtain a graded object associated with the filtered
homology, namely
Gr H(F) = EB GrP H(F).
A spectral sequence is a sequence {En dr} (r ~ 0) of graded objects
E; = EB E~
P ~O
together with homomorphisms (also called differentials) of degree r,
satisfying d; = 0, and such that the homology of E, is Er + I' that is
H(Er) = Er+ I ·
In practice, one usually has E, = Er + 1 = .. . for r ~ roo This limit object is
called E oo' and one says that the spectral sequence abuts to Eoo• Actually, to be
perfectly strict, instead of equalities one should really be given isomorphisms,
but for simplicity, we use equalities.
Proposition 9.1.
Let F be a filtered differential object. Then there exists a
spectral sequence {Er } with:
Proof
Define
Elf = H(GrP F) ;
E~ = GrP H(F).
Zf = {x E P such that dx E p+ r }
E~ = Zf/[dZ~~l'-l ) + Zf~f].
The definition of E~ makes sense, since Z~ is immediately verified to contain
dZ~~lr -l) + Z~~l. Furthermore, d maps Z~ into z~+r, and hence includes a
homomorphism
We shall now compute the homology and show that it is what we want.
First, for the cycles: An element x E Z~ represents a cycle of degree p in E;
if and only if dx E dz~:i + Z:~;+l , in other words
dx = dy + z,

816
GENERAL HOMOLOGY THEORY
XX, §9
Write x = y + u, so du = z. Then U E FP and du E FP +r + 1, that is U E Zf+ i - It
follows that
p-cycles of E, = (Zf+ 1 + Zf~ l)/(dZf~~+ 1 + Zf~l).
On the other hand, the p-boundaries in E, are represented by elements of
dZf- r, which contains dZf~~+ I. Hence
p-boundaries of E, = (dZf- r + Zf~l)/(dZf~~+1 + Zf~n.
Therefore
HP(Er ) = (Zf+ 1 + Zf~l)/(dZf-' + Zf~l)
= Z~+l /(Z~+1 n (dZr- r + z~~/)) .
Since
Zp
dzp-r
d
ZP
zi: 1 -
Zp+l
r+ 1:::>
r
an
r+ 1 n
r-l
-
r
,
it follows that
thus proving the property of a spectral sequence.
Remarks.
It is sometimes useful in applications to note the relation
The verification is immediate, but Griffiths-Harris use the expression on the
right in defining the spectral sequence, whereas Godement uses the expression
on the left as we have done above. Thus the spectral sequence may also be
defined by
Ef = Zf
mod(dp- r + 1 + P+ 1).
This is to be interpreted in the sense that Z mod S means
(Z + S)/S
or
Z/(Z n S).
The term Eb is P /P+ 1 immediately from the definitions, and by the
general property already proved, we get Ef = H(P/P+ 1). As to
E~, for
r large we have Zf = ZP = cycles in P, and

XX, §9
SPECTRAL SEQUENCES
817
which is independent of r, and is precisely Gr P H(F), namely the p-graded
component of H(F), thus proving the theorem.
The differential d1 can be specified as follows.
Proposition 9.2.
The homomorphism
is the coboundary operator arisingfrom the exact sequence
viewingeach term as a complex with differential induced by d.
Proof
Indeed, the coboundary
() :El = H(P/P+ I) -+ H(P+ l/p+ 2) = El+1
is defined on a representative cycle z by dz, which is the same way that we de-
fined d l •
In most applications, the filtered differential object is itself graded, because
it arises from the following situation. Let K be a complex, K = (KP,d) with
p ~ 0 and d of degree 1. By a filtration FK, also called a filtered complex, we
mean a decreasing sequence of subcomplexes
Observe that a short exact sequence of complexes
o-+ K' -+ K -+ K" -+ 0
gives rise to a filtration K
:::> K ' :::> {O}, viewing K' as a subcomplex.
To each filtered complex FK we associated the complex
Gr FK = Gr K = EB GrP K,
p?;O
where
GrPK = PK/P+IK,
and the differential is the obvious one. The filtration PK on K also induces a
filtration PH(K) on the cohomology, by

818
GENERAL HOMOLOGY THEORY
The associated graded homology is
XX, §9
where
Gr H(K) = EB GrPHq(K),
p,q
A spectral sequence is a sequence {En dr} (r ~ 0) of bigraded objects
E, = EB
E~ ·q
P .q ~O
together with homomorphisms (called differentials)
d. : E~·q -+ E~+r,q-r+ 1
satisfying
d; = 0,
and such that the homology of E, is Er + 1, that is
H(Er) = Er+I'
A spectral sequence is usually represented by the following picture:
(p ,q)
.~
• (p + r, q - r + I)
In practice, one usually has E; = Er + 1 = , ., for r ~ roo This limit object
is called Eco' and one says that the spectral sequence abuts to Eco'
Proposition 9.3.
Let FK be afiltered complex. Then there exists a spectral
sequence {Er} with :
Eg,q = FPKp+q/FP+1Kr:" :
E~ ·q = Hp+q(GrPK);
E~q = GrP(Hp+q(K)).
The last relation is usually written
E, = H(K),
and we say that the spectral sequence abuts to H(K) .

XX, §9
SPECTRAL SEQUENCES
819
The statement of Proposition 9.3 is merely a special case of Proposition 9.1,
taking into account the extra graduation.
One of the main examples is the spectral sequence associated with a double
complex
K = EB
KP. q
P.q ;:; O
which is a bigraded object, together with differentials
d' : KP.q --+ KP + l. q
and
d": KP.q --+ KP.q + I
satisfying
d'2 = d"? = 0
and
d'd" + dOd' = O.
We denote the double complex by (K, d', dO). The associated single complex
(Tot(K), D) (Tot for total complex), abbreviated K*, is defined by
K" = EB
KP.q
and
D = d' + d''.
p+q =n
There are two filtrations on (K*, D) given by
' F PK n =
EB
Kp··q
p' + q= n
p' ;:;p
° F qK n =
EB
K P.q"'.
p +q ' = n
q' ;:; q
There are two spectral sequences {'Er } and {"Er } , both abutting to H(Tot(K» .
For applications, see [OrH 78], Chapter 3, §5; and also, for instance, [FuL 85],
Chapter V. There are many situations when dealing with a double complex directly
is a useful substitute for using spectral sequences, which are deri ved from double
complexes anyhow.
We shall now derive the existence of a spectra l sequence in one of the most
important cases, the Grothendieck spectral sequence associated with the com-
posite of two functors. W e assume that our abelian category has enough injectives.
Let C = EB cP be a complex, and suppose CP = 0 if p < 0 for simplicity.
We define injective resolution of C to be a resolution
0--+ C --+ 10 --+ II --+ 12 --+ . . .
written briefly
such that each Ii is a complex, I i = EB Ii.P, with differentials

820
GENERAL HOMOLOGY THEORY
XX, §9
and such that Ii.P is an injective object. Then in particular, for each p we get
an injective resolution of CP, namely :
We let:
zj , P = Ker dj , P = cycles in degree p
Bi,P = Irn dj, p- 1 = boundaries in degree p
n-» = Zj,P/Bj·P = homology in degree p.
We then get complexes
0--+ ZP(C) --+ Zo,p --+ ZI.P--+
o--+ BP(C) --+ BO, P --+ BI. P --+
o--+ HP(C) --+ HO,P--+ HI. P--+
We say that the resolution 0 --+ C --+ Ic is fully injective if these three com-
plexes are injective resolutions of ZP(C), BP(C) and HP(C) respectively.
Lemma 9.4.
Let
o--+ M ' --+ M --+ M il --+ 0
be a short exact sequence. Let
o--+ M ' --+ 1M'
and
0 --+ Mil --+ 1M"
be injective resolutionsofM' and Mil. Then there exists an injectiveresolution
ofM and morphismswhichmake thefollowing diagramexact andcommutative:
O~l~l~l~O
0-----+ M ' --- M -----+ M il---> 0
1
1
1
o
0
0
Proof
The proof is the same as at the beginning of the proof of Theorem
6.1.

XX, §9
SPECTRAL SEQUENCES
821
Lemma 9.5.
Given a complex C there exists a jully injective resolution ofC.
Proof
We insert the kernels and cokernels in C, giving rise to the short
exact sequences with boundaries BP and cycles ZP:
o-+ BP-+ ZP-+ HP -+ 0
o-+ ZP- 1 -+ CP- I -+ BP -+ O.
We proceed inductively. We start with an injective resolution of
0-+ ZP- 1 -+ CP - 1 -+ BP -+ 0
using Lemma 9.4. Next let
be an injective resolution of HP. By Lemma 9.4 there exists an injective resolu-
tion
which fits in the middle of the injective resolutions we already have for BP and
HP. This establishes the inductive step, and concludes the proof.
Given a left exact functor G on an abelian category with enough injectives,
we say that an object X is G.acyclic if WG(X) = 0 for p ~ 1. Of course,
ROG(X) = G(X).
Theorem 9.6.
(Grothendieck spectral sequence).
Let
T : (1 -+ (B
and
G: (B -+ e
be covariant left exact functors such that if I is injective in (1, then T(I) is
G-acyc/ic. Then for each A in (1 there is a spectral sequence {El A)}, such that
and Ef·q abuts (with respect to p) to W+q(GT)(A), where q is the grading
index.
Proof
Let A be an object of (1, and let 0 -+ A -+ CA be an injective resolu-
tion. We apply T to get a complex
TC :
0 -+ TCo -+ TC' -+ TC 2 -+
By Lemma 9.5 there exists a fully injective resolution
0-+ TC -+ ITc
which has the 2-dimensional representation :

822
GENERAL HOMOLOGY THEORY
I
I
I
0-----+ 1°,1 __ 11,1----+ 12 •1----+
I
I
1
0 __ 1°,0 ----+1 1.0 __ 12'°----+
I
I
I
O----+TC°----+ TC I----+TC 2--
I
I
1
000
XX, §9
Then G1 is a double complex. Let Tot(GI) be the associated single complex.
We now consider each of the two possible spectral sequences in succession,
which we denote by IE~,q and
2E~ ·q.
The first one is the easiest. For fixed p, we have an injective resolution
0--+ TCP --+ life
where we write l!J.e instead of I TO' This is the p-th column in the diagram. By
definition of derived functors, G1P is a complex whose homology is RqG, in
other words , taking homology with respect to d" we have
By hypothesis, CP injective implies that (RqG)(TCP) = 0 for q > O. Since G
is left exact, we have ROG(TCP) = TCP. Hence we get
{
GT(CP)
if q = 0
"HP·q(GI) = o
if q > 0.'
Hence the non-zero terms are on the p-axis, which looks like
Taking
I HP we get
lE~ ,q(A ) = {ROP(GT)(A)
if q = 0
if q > o.
This yields
W(Tot(GI)
~ W(GT)(A ).

XX, §9
SPECTRAL SEQUENCES
823
The second one will use the full strength of Lemma 9.5, which had not been
used in the first part of the proof, so it is now important that the resolution
I T C is fully injective. We therefore have injective resolutions
O-+ZP(TC) -+ l ZO, p -+ lZ l,p-+ l Z2, p -+
0-+ BP(TC) -+ lBo,p -+ 'e:» -+ lB2,p -+
0-+ H P(TC) -+ 1HO,p -+ 1H 1,p -+ 1H 2,p-+
and the exact sequences
0-+ lZ q, p -+ p .p-+ lBq+l ,p-+O
split because of the injectivity of the terms, We denote by I (P)the p-th row of the
double complex I = {Iq.P }, Then we find:
'Hq,P(GI) = Hq(GI(P») = G1Zq,P/G1Bq,p
= G' Hq' P(l)
by the first split sequence
by the second split sequence
because applying the functor G to a split exact sequence yields a split exact
sequence,
Then
By the full injectivity of the resolutions, the complex 'Hq'P(l) with p ~ 0 is an
injective resolution of
W(TC) = (RqT)(A ).
Furthermore, we have
since a derived functor is the homology of an injective resolution. This proves
that (RPG)RqT(A))abuts to R"(GT)(A), and concludes the proof of the theorem.
Just to see the spectral sequence at work , we give one application relating
it to the Euler characteristic discussed in §3,
Let a have enough injectives, and let
be a covariant left exact functor. Let ~Cl be a family of objects in a giving rise
to a K-group. More precisely, in a short exact sequence in a,iftwo of the objects
lie in ~ Cl ' then so doe s the third. We also assume that the objects of ~Cl have
finite NT-dimension, which means by definition that if A E ~ Cl then RiT(A) = 0

824
GENERALHOMOLOGYTHEORY
XX, §9
for all i sufficiently large. We could take lja in fact to be the family of all objects
in C1 which have finite RT-dimension.
We define the Euler characteristic associated with Ton K(lja) to be
00
XT(A) = L (-lY cl(RiT(A».
i=O
The cl denotes the class in the K-group K(lj",) associated with some family
lj", of objects in ill, and such that RiT(A) E lj", for all A E lja . This is the mini-
mum required for the formula to make sense.
Lemma 9.7.
The map XT extends to a homomorphism
Proof
Let
o-+ A' -+ A -+ A" -+ 0
be an exact sequence in lj. Then we have the cohomology sequence
in which all but a finite number of terms are O. Taking the alternating sum in the
K-group shows that XT is an Euler-Poincare map, and concludes the proof.
Note that we have merely repeated something from §3, in ajazzed up context.
In the next theorem, we have another functor
G: ill -+ e,
and we also have a family lje giving rise to a K-group K(lje). We suppose that
we can perform the above procedure at each step, and also need some condition
so that we can apply the spectral sequence. So, precisely, we assume :
CHAR 1.
For all i, RiT maps lja into lj""
RiG maps lj", into lje ' and
Ri(GT) maps lja into lje'
CHAR 2.
Each subobject of an element of lja lies in lja and has finite
RT- and R(GT)-dimension; each subobject of an element of
lj", lies in lj", and has finite RG-dimension.
Theorem 9.8.
Assume that T: C1 -+ ill and G : ill -+ e satisfy the conditions
CHAR I and CHAR 2. Also assume that T maps injectives to G-acyclics.
Then
XG
0 XT = XGT '

XX, §9
SPECTRAL SEQUENCES
825
Proof
By Theorem 9.6, the Grothendieck spectral sequence of the com-
posite functor implies the existence of a filtration
. . . c PR"(GT)(A) C r«: I R"(GT)(A) c ' "
of R"(GT)(A), such that
Then
00
XGT(A) = L (-1)" cl(R"(GT)(A))
"=0
00
00
= L (-1)" I
cl(E~" -P)
" =0
p =o
00
= L(-I)" cl(E':.,).
"=0
On the other hand,
00
XT(A) = L (-1)q cl(RqT(A))
q=O
and so
00
XG
0 XT(A) = I (-1)qXG(RqT(A))
q=O
00
00
= L (- I)q L (- 1)p cl(RPG(RqT(A))
q=O
p=o
00
"
= I (-I)" I cl(RPG(R" -PT(A))
" =0
p =o
00
= L(-I)"cl(E2).
"=0
Since Er + I is the homology of En we get
00
00
00
L (-1)" cl(E2) = L ( -1)" cl(E3) = . . . = L ( -I)" cl(E':.,).
"=0
"=0
"=0
This concludes the proof of the theorem.

826
GENERAL HOMOLOGY THEORY
EXERCISES
XX, Ex
1. Prove that the example of the standard complex given in §1 is actually a complex ,
and is exact, so it gives a resolution of Z. [Hint :
To show that the sequence of the
standard complex is exact, choose an element z E S and define h : Ei -'? Ei+I by letting
h(xo, . . . , x;) = (z, xo, .. . , x;).
Prove that dh + hd = id, and that dd = O. Exactness follows at once.]
Cohomology of groups
2. Let G be a group. Use G as the set S in the standard complex. Define an action of
G on the standard complex E by letting
x(xo , . . . , x;) = (xxo, . .. , xx;).
Prove that each E, is a free module over the group ring Z[G] . Thus if we let
R = Z[G] be the group ring, and consider the category Mod(G) of G-modules , then
the standard complex gives a free resolution of Z in this category .
3. The standard complex E was written in homogeneous form, so the boundary maps
have a certain symmetry . There is another complex which exhibits useful features
as follows . Let Fi be the free Z[G]-module having for basis i-tuples (rather than
(i + Ij-tuples) (XI' . . . , x;). For i = 0 we take Fo = Z[G] itself. Define the boundary
operator by the formula
i-I
d(XI,' " ,Xi) = XI(X2, . . . ,Xi) + 2:(-I)j(XI, . . . ,XjXj+I, · ·· ,Xi)
j; 1
i+ 1
+ (-1 )
(XI " " ,Xi).
Show that E ee F (as complexes of G-modules) via the association
and that the operator d given for F corresponds to the operator d given for E under
this isomorphism.
4. If A is a G-module, let AG be the submodule consisting of all elements v E A such
that xv = v for all x E G. Thus AG has trivial G-action . (This notation is convenient,
but is not the same as for the induced module of Chapter XVIII.)
(a) Show
that
if
Hq(G, A)
denotes
the q-th
homology
of
the
complex
HomG(E , A), then HO(G, A) = AG. Thus the left derived functors of A HAG
are the homology groups of the complex HomG(E, A), or for that matter,
of the complex Hom(F, A) , where F is as in Exercise 3.
(b) Show that the group of I-cycle s Zl(G, A) consists of those functions
f : G -'? A satisfying
f(x) + xf(y) = f(xy) for all x, y E G.
Show that the subgroup of coboundaries Bl(G, A) consists of those functions
f io: which there exists an element a E A such thatf(x) = xa - a. The factor
group is then HI(G , A) . See Chapter VI, §10for the determination of a special
case.

XX, Ex
EXERCISES
827
(c) Show that the group of 2-cocycles Z2(G , A) consists of those functions
j : G ~ A satisfying
xj (y, z) - j (xy , z) + j(x , yz) - j (x, y) = o.
Such 2-cocycles are also called factor sets , and they can be used to describe
isomorphism classe s of group extensions, as follows .
5. Group extensions. Let W be a group and A a normal subgroup, written multipli-
catively. Let G = W/ A be the factor group. Let F: G ~ W be a choice of coset
representatives. Define
j(x, y) = F(x) F(y)F(xy) - I.
(a) Prove that j is A-valued, and that j: G x G ~ A is a 2-cocycle.
(b) Given a group G and an abelian group A, we view an extension W as an
exact sequence
Show that if two such extensions are isomorphic then the 2-cocycles associated
to these extensions as in (a) define the same class in H l(G, A) .
(c) Prove that the map which we obtained above from isomorphism classes of
group extensions to H 2(G , A) is a bijection.
6. Morphisms of the cohomology functor. Let A: G' ~ G be a group homomorphism.
Then A gives rise to an exact functor
ct>A : Mod(G) ~ Mod(G') ,
because every G-module can be viewed as a G'-module by defining the operation of
a' E G' to be a'a = A(u ' )a. Thus we obtain a cohomology functor H G' 0 ct>A'
Let G' be a subgroup of G. In dimension 0, we have a morphism of functors
A* : H g ~ H g, 0 ct>A given by the inclusion AG~ AG' =
ct>A(A )G'.
(a) Show that there is a unique morphism of 8-functors
A* : HG ~ HG'
0 ct>A
which has the above effect on ns:We have the following important special
cases ,
Restriction. Let H be a subgroup of G, Let A be a G-module, A funct ion
from G into A restricts to a function from H into A, In this way, we get a
natural homomorphism called the restriction
res: Hq(G , A ) ~ Hq(H , A).
Inflation, Suppose that H is normal in G, Let AH be the subgroup of A
consisting of those elements fixed by H. Then it is immediately verified that
AH is stable under G, and so is a G/ H-module. The inclusion AH ~ A induces
a homomorphism
Define the inflation

828
GENERAL HOMOLOGY THEORY
XX, Ex
as the composite of the functorial morphism Hq(G/H, AH) ~ Hq(G, AH)
followed by the induced homomorphism uq = H'b(u) as above .
In dimension 0, the inflation gives the identity (AH) G/H = AG.
(b) Show that the inflation can be expressed on the standard cochain complex
by the natural map which to a function of G/H in AH associates a function
of G into AH CA.
(c) Prove that the following sequence is exact.
o~ H 1(G/H, AH) ~ HI(G , A) ~ Hl(H, A).
(d) Describe how one gets an operation of G on the cohomology functor HG "by
conjugation" and functoriality .
(e) In (c), show that the image of restriction on the right actually lies in
HI(H, A)G (the fixed subgroup under G) .
Remark.
There is an analogous result for higher cohomology groups,
whose proof needs a spectral sequence of Hochschild-Serre. See [La 96],
Chapter VI, §2, Theorem 2. It is actually this version for H2 which is applied
to H2(G, K*), when K is a Galois extension , and is used in class field theory
[ArT 67].
7. Let G be a group, B an abelian group and MG(B) = M(G, B) the set of mappings
from G into B . For x E G andfE M(G , B) define ([x]f)(y) = f( yx) .
(a) Show that B ~ M G(B) is a covariant, additive, exact functor from Mod(Z)
(category of abelian groups) into Mod(G) .
(b) Let G' be a subgroup of G and G = UxjG' a coset decomposition. For
f E M(G, B) let h be the function in M(G', B) such that hey) = f (xjy ).
Show that the map
f~I1h
J
is a G/-isomorphism from M(G , B) to I1 M(G', B) .
j
8. For each G-module A E Mod(G), define
fA : A ~ M(G, A) by the condition
fA (a) = the function fa such that fzClT) = aa for a E G. Show that a ~ fa is a
G-module embedding , and that the exact sequence
o~ A ~ M(G, A) ~ XA = coker fA ~ 0
splits over Z. (In fact, the map f ~ fee) splits the left side arrow .)
9. Let B E Mod(Z) . Let Hs be the left derived functor of A ~ AG•
(a) Show that Hq(G , MG(B» = 0 for all q > O. [Hint : use a contracting homotopy
by
(sf>x2. .. . .x,(x) = fx.X2•.. . •X,(l )·
Show thatf = sdf + dsf.] Thus MG erases the cohomology functor.
(b) Also show that for all SUbgroups G' of G one has Hq(G ' , MG(B»
= 0 for
q > O.
10. Let G be a group and S a subgroup . Show that the bifunctors
(A , B) ~ HomG(A , M~(B» and (A, B) ~ Homs(A, B)
on Mod(G) X Mod(S) with value in Mod(Z) are isomorphic. The isomorphism is
given by the maps
cP ~ (a ~ ga), for cp E Homs(A, B) , where ga(lT) = cp(lTa), ga E M~(B).

XX, Ex
The inverse mapping is given by
EXERCISES
829
f l->f(l) withfE HomG(A , M f;(B)) .
Recall that M f; (B) was defined in Chapter XVIII, §7 for the induced representation.
Basically you should already know the above isomorphism.
II . Let G be a group and S a subgroup. Show that the map
Hq(G , M f; (B)) ~ H q(S, B ) for B E Mod(S),
obtained by composing the restriction re s~ with the S-homomorphism f I-> f(l) , is
an isomorphism for q > O. [Hint: Use the uniqueness theorem for cohomology
functors.]
12. Let G be a group. Let E : Z[G] ~ Z be the homomorphism such that E(L n(x)x) =
L n(x) . Let l c be its kernel. Prove that l o is an ideal of Z[G] and that there is an
isomorphism of functors (on the category of groups)
by
xGCI-> (x -
I) + lb.
13. Let A E Mod(G) and a E H ' (G , A) . Let {a(X)}X EGbe a standard I-cocycle representing
a . Show that there exists a G-homomorphism f : lG~ A such that f (x -
I) = a(x) ,
sof E (Hom(lG' A))G. Show that the sequence
a ~ A = Hom(Z , A) ~ Hom(Z[GJ, A) ~ Hom(lG' A) ~ a
is exact, and that if S is the coboundary for the cohomology sequence, then
S(i) = - a .
Finite groups
We now turn to the case of finite groups G. For such groups and a G-module A we
have the trace
defined by
ToCa) = 2: aa.
U EG
We define a module A to be G-regular if there exists a Z-endomorphism u : A ~ A such
that id, = TG(u). Recall that the operation of G on End(A) is given by
[alf(a) = aI(a-'a) for a E G.
14. (a) Show that a projective object in Mod(G) is G-regular.
(b) Let R be a commutative ring and let A be in ModR(G ) (the category of (G, R)-
modules). Show that A is R[G]-projective if and only if A is R-projective and
R[G]-regular, meaning that idA = TG(u ) for some R-homomorphism u : A ~ A.
15. Consider the exact sequences:
(I)
(2)
O ~ l c :" Z[G] ~ Z ~ a
e'
a ~ Z ~ Z[ G] ~ JG ~ a
where the first one defines l c- and the second is defined by the embedding
E'
: Z ~ Z[G] such that E'(n) = n(L u) ,
i.e. on the "diagonal". The cokernel of E' is JG by definition.
(a) Prove that both sequences (I) and (2) split in Mod(G).

830
GENERAL HOMOLOGY THEORY
XX, Ex
(b) Define MG(A) = Z[G] 181 A (tensor product over Z) for A E Mod(G) . Show
that MG(A) is G-regular, and that one gets exact sequences (lA) and (2A ) by
tensoring (I) and (2) with A . As a result one gets an embedding
e~ = e' 181 id : A = Z 181 A ~ Z[G] 181 A .
16. Cyclic groups. Let G be a finite cyclic group of order n. Let c be a generator of G.
Let Ki = Z[G] for i > O. Let e : KO ~ Z be the augmentation as before. For i odd
~ 1, let d' : Ki ~ Ki-l be multiplication by 1 -
a. For i even ~ 2, let d' be
multiplication by 1 + a + ... + rrn - I . Prove that K is a resolution of Z. Conclude
that:
For i odd : Hi(G, A) = AG/TGA where TG : a ~ (l + a + ... + rrn-1)a;
For i even ~ 2: Hi(G , A) = Ad(l -
rr)A , where AT is the kernel of TG in A .
17. Let G be a finite group . Show that there exists a 8-functor H from Mod(G) to
Mod (Z) such that:
(l) HO is (isomorphic to) the functor A ~ AG/ TGA.
(2) Hq(A) = 0 if A is injectiv e and q > 0, and Hq(A) = 0 if A is projective and q
is arbitrary.
(3) H is erased by G-regular modules . In particular, H is erased by MG'
The 8-functor of Exercise 17 is called the special cohomology functor. It differs
from the other one only in dimension O.
18. Let H = H G be the special cohomology functor for a finite group G. Show that:
HO(/d = 0; HO(Z) "" HI(I) "" Z/nZ where n = #(G);
HO(Q/z) = HI(Z) = W(I) = 0
HI(Q/z) "" H2(Z) "" H3(1) "" GA = Hom(G, Q/Z) by definition.
Injectives
19. (a) Show that if an abelian group T is injective in the category of abelian groups. then
it is divisible.
(b) Let A be a principal entire ring.Define the notion of divisibility by elements of A for
modules in a manner analogous to that for abelian groups. Show that an A-
module is injective if and only if it is A-divisible. [The proof for Z should work
in exactly the same way.]
20. Let S be a multiplicative subset of the commutative Noetherian ring A. If / is an
injective A-module , show that s: '! is an injective S-l A-module.
21. (a) Show that a direct sum of projective modules is projective .
(b) Show that a direct product of injective modules is injective.
22. Show that a factor module, direct summand, direct product, and direct sum of divisible
modules are divisible.
23. Let Q be a module over a commutative ring A. Assume that for every left ideal J of
A, every homomorphism cp : J ~ Q can be extended to a homomorphism of A into
Q. Show that Q is injective. [Hint: Given M' C M and j" : M
f ~ Q, let xo E M
and xo ¢:. M'. Let J be the left ideal of elements a E A such that axo EM'. Let
cp(a) = !(axo) and extend
cp to A, as can be done by hypothesis. Then show that

XX, Ex
one can extend j to M by the formula
j(x' + bxo) = j(x') + cp(b),
EXERCISES
831
for x' EM and b EA. Then use Zorn's lemma. This is the same pattern of proof as
the proof of Lemma 4.2.]
24. Let
be an exact sequence of modules. Assume that I I' 12 are injective.
(a) Show that the sequence splits.
(b) Show that 13 is injective.
(c) If I is injective and I = M EB N, show that M is injective.
25. (Do this exercise after you have read about Noetherian rings.) Let A be a Noetherian
commutative ring, and let Q be an injective A-module. Let a be an ideal of A, and let
Q(Q) be the subset of elements x E Q such that a"x = 0 for some n, depending on x.
Show that Q(Q) is injective. [Hint: Use Exercise 23.]
26. Let A be a commutative ring. Let E be an A-module, and let E A = Homz(E, Q/Z)
be the dual module . Prove the following statements.
(a) A sequence
is exact if and only if the dual sequence
is exact.
(b) Let F be flat and I injective in the category of A-modules . Show that
HomA(F, l) is injective.
(c) E is flat if and only if E A is injective .
27. Extensions of modules. Let M , N be modules over a ring. By an extension of M
by N we mean an exact sequence
(*)
O~N~E~M~ O.
We shall now define a map from such extensions to Extl(M, N) . Let P be projective,
with a surjective homomorphism onto M , so we get an exact sequence
(**)
0 ~ K ~ P -4 M ~ 0
where K is defined to be the kernel. Since P is projective, there exists a homomorphism
u: P ~ E, and depending on u a unique homomorphism v : K ~ N making the
diagram commutative:
o -----+
K
-----+ P ----+ M -----+ 0
'j
'j
;dj
o -----+
N
-----+ E -----+ M
-----+ 0

832
GENERAL HOMOLOGY THEORY
XX, Ex
On the other hand, we have the exact sequence
(***)
0 ~ Hom(M, N) ~ Hom(P, N) ~ Hom(K , N) ~ Extl(M, N) ~ 0,
with the last term on the right being equal to 0 because Ext I(P, N) = O. To the
extension (*) we associate the image of v in Ext I(M , N ).
Prove that this association is a bijection between isomorph ism classes of extensions
(i.e. isomorphism classes of exact sequences as in (*», and Extl(M, N). [Hint:
Construct an inverse as follows . Given an element e of Extl (M, N ), using an exact
sequence (**), there is some element v E Hom(K , N) which maps on e in (***). Let
E be the push-out of v and w. In other words , let J be the submodule of N Ef) P
consisting of all elements (v(x ), -w(x» with x E K, and let E = (N Ef) P)/J. Show
that the map y ~ (y, 0) mod J gives an injection of N into E. Show that the map
N Ef) P ~ M vanishe s on J, and so gives a surjective homomorphism E ~ M ~ O.
Thus we obtain an exact sequence (*) ; that is, an extension of M by N. Thus to each
element of Ext I(M, N) we have associated an isomorphism class of extensions of M
by N . Show that the maps we have defined are inverse to each other between iso-
morphism classes of extensions and elements of Ext 1(M, N).J
28. Let R be a principal entire ring. Let a E R. For every R-module N, prove :
(a) Ext1(R/aR , N) = N/aN.
(b) For bE R we have Ext I(R/aR, R/bR) = R/(a, b), where (a , b) is the g.c.d
of a and b, assuming ab "* O.
Tensor product of complexes.
29. Let K = EB K; and L = EB Lq be two complexes indexed by the integers, and with
boundary maps lower indices by I. Define K ® L to be the direct sum of the modules
(K ® L)., where
(K e L). =
EB «,® t.;
p +q=n
Show that there exist unique homomorphisms
d = d. :(K ® L). ~ (K ® L). _I
such that
d(x ® y) = d(x) ® y + (-l)Px ® d(y).
Show that K ® L with these homomorphisms is a complex, that is d od = O.
30. Let K, L be double complexes. We write K; and L, for the ordinary column complexes
of K and L respectively. Let cp: K ~ L be a homomorphism of double complexes.
Assume that each homomorphism
is a homology isomorphism.
(a) Prove that Tot(cp) : Tot(K) ~ Tot(L) is a homology isomorphism. (If you
want to see this worked out, cf. [FuL 85), Chapter V, Lemma 5.4.)
(b) Prove Theorem 9.8 using (a) instead of spectral sequences.

XX. Ex
[ArT 68]
[At 61]
[At 67]
[ABP 73]
[Ba 68]
[Bo 69]
[BID 85]
[CaE 57]
[CuR 81]
[ES 52]
[FuL 85]
[Go 58]
[GreH 81]
[GriH 78]
[Gro 57]
[Gro 68]
[Gu 91]
[Ha 77]
[HiS 70]
[La 96]
[Man 69]
[Mat 70]
[No 68]
[No 76]
[Ro 79]
[Se 64]
EXERCISES
833
Bibliography
E. ARTIN and J. TATE, Class Field Theory, Benjamin, 1968; Addison-Wesley,
1991
M. ATIYAH , Characters and cohomology of finite groups, Pub. IHES 9
(1961), pp. 5-26
M. ATIYAH, K-theory, Benjamin, 1967; reprinted Addison-Wesley, 1991
M. ATIYAH, R. BOTT, and R. PATODl, On the heat equation and the index
theorem, Invent. Math. 19 (1973), pp. 279-330
H. BASS, Algebraic K-theory, Benjamin, 1968
R. BOTT, Lectures on K(X ), Benjamin, 1969
T. BROCKER and T. TOM DIECK, Representations of Compact Lie Groups,
Springer Verlag, 1985
H. CARTAN and S. ElLENBERG, Homological Algebra, Princeton University
Press, 1957
C. CURTIS and I. REINER, Methods ofRepresentation Theory, John Wiley &
Sons, 1981
S. ElLENBERG and N. STEENROD, Foundations of Algebraic Topology,
Princeton University Press, 1952
W. FULTON and S. LANG, Riemann-Roch algebra, Springer Verlag, 1985
R. GODEMENT, Theorie desfaisceaux, Hermann Paris, 1958
M. GREENBERG and L HARPER, Algebraic Topology: A First Course, Ben-
jamin-Addison-Wesley, 1981
P. GRIFFITHS and J. HARRIS, Principles of algebraic geometry, Wiley Inter-
science 1978
A. GROTHENDIECK, Sur quelques points d'algebre homologique, Tohoku
Math. J. 9 (1957) pp. 119-221
A. GROTHENDIECK, Classes de Chern et representations lineaires des groupes
discrets, Dix exposes sur lacohomologie etale des schemas, North-Holland,
Amsterdam, 1968
R. GUNNING, Introduction to holomorphic functions ofseveral variables, Vol.
III Wadsworth & Brooks/Cole, 1990
R. HARTSHORNE, Algebraic Geometry, Springer Verlag, 1977
P. J. HILTONand U. STAMMBACH, A Course inHomological Algebra, Graduate
Texts in Mathematics, Springer Verlag, 1970.
S. LANG, Topics in cohomology of groups, Springer Lecture Notes, 1996
L MANIN, Lectures on the Kjunctor in Algebraic Geometry. Russian Math
Surveys 24(5) (1969) pp. 1- 89
H.
MATSUMURA,
Commutative
Algebra ,
Second
Edition,
Benjamin-
Cummings, 1981
D. NORTHCOTT, Lessons on Rings, Modules and Multiplicities, Cambridge
University Press, 1968
D. NORTHCOTT, Finite Free Resolutions, Cambridge University Press, 1976
L ROTMAN, Introduction to Homological Algebra, Academic Press, 1979
L-P . SERRE, Cohomologie Galoisienne, Springer Lecture Notes 5, 1964

834
GENERAL HOMOLOGY THEORY
XX, Ex
[Se 65)
[SGA 6]
[Sh 72]
J.-P. ~ ERR E, Alqebre locale, multiplicites, Springer Lecture Notes 11 (1965)
Third Edition 1975
P. BERTHELOT, A. GROTHENDIECK, L. ILLUSIE et al. Theone des intersections
et theoreme de Riemann-Roch, Springer Lecture Notes 146, 1970
S. SHATZ, Profinite groups, arithmetic and geometry, Ann. of Math Studies,
Princeton University Press 1972

CHAPTER XXI
Finite Free Resolutions
This chapter puts together specific computations of complexes and homology.
Partly these provide examples for the general theory of Chapter XX, and partly
they provide concrete results which have occupied algebraists for a century.
They have one aspect in common: the computation of homology is done by means
of a finite free resolution, i.e. a finite complex whose modules are finite free.
The first section shows a general technique (the mapping cylinder) whereby
the homology arising from some complex can be computed by using another
complex which is finite free . One application of such complexes has already
been given in Chapter X, putting together Propos ition 4.5 followed by Exercises
10-15 of that chapter.
Then we go to major theorems , going from Hilbert's Syzygy theorem, from
a century ago, to Serre's theorem about finite free resolutions of modules over
polynomial rings, and the Quillen-Suslin theorem. We also include a discussion
of certain finite free resolutions obtained from the Koszul complex. These apply,
among other things , to the Grothendieck Riemann-Roch theorem of algebraic
geometry.
Bibliographical references refer to the list given at the end of Chapter XX.
§1.
SPECIAL COMPLEXES
As in the preceding chapter, we work with the category of modules over a
ring, but the reader will notice that the arguments hold quite generally in an
abelian category.
In some applications one determines homology from a complex which is
not suitable for other types of construction, like changing the base ring. In this
section, we give a general procedure which constructs another complex with
835
S. Lang, Algebra
© Springer Science+Business Media LLC 2002

836
FINITE FREE RESOLUTIONS
XXI, §1
better properties than the first one, while giving the same homology. For an
application to Noetherian modules, see Exercises 12-15 of Chapter X.
Let f: K -+ C be a morphism of complexes. We say that f is a homology
isomorphism ifthe natural map
H(f) :H(K) -+ H(C)
isan isomorphism. The definition is valid in an abelian category, but the reader
may think of modules over a ring, or abelian groups even. Afamilylr ofobjects
will be called sufficient if given an object E there exists an element F in lr and
an epimorphism
F -+ E -+ 0,
and iflr is closed under taking finite direct sums. For instance, we may use for
lr the familyof freemodules. However, in important applications,we shall deal
with finitelygenerated modules, in which case lr might be taken as the familyof
finite free modules. These are in fact the applications I have in mind, which
resulted in having axiomatized the situation.
Proposition 1.1. Let C be a complex such that HP(C) i= 0 only for
o ~ p ~ n. Let lr be a sufficient family of projectives. There exists a
complex
o-+ KO -+ K 1 -+ . .. -+ K" -+ 0
such that:
KPi=O
onlyfor
O~p~n ;
KPisinlrforallp~ 1;
and there exists a homomorphism ofcomplexes
f: K -+ C
which is a homologyisomorphism.
Proof
We definej; by descending induction on m:
We suppose that we have defined a morphism of complexes with p ~ m + 1
such that HP(f) is an isomorphism for p ~ m + 2, and
fm+ 1:z-: l(K) -+ n-: l(C)

XXI, §1
SPECIAL COMPLEXES
837
is an epimorphism, where Z denotes the cycles, that is Ker b. We wish to con-
struct K" and fm' thus propagating to the left. First let m ~ O. Let B" + 1 be
the kernel of
Ker b;(' +l --+ n-: 1(C).
Let K' be in tj with an epimorphism
b' : K' --+ B" + 1.
Let K" --+ Hm(C) be an epimorphism with K" in tj, and let
f" :K " --+ zm(c)
be any lifting, which exists since K" is projective. Let
K" = K ' EB K"
and define bm : K'" --+ x:: 1 to be b' on K' and 0 on K". Then
and hence there existsf' :K' --+ C" such that
be of ' =fm+1 -s.
We now define fm : K'" --+ C" to be f' on K ' and f" on K". Then we have
defined a morphism of complexes truncated down to m as desired.
Finally, if m = -I, we have constructed down to KO, bO, andj~ with
K°!5!. HO(C) --+ 0
exact. The last square looks like this, defining K - 1 = O.
o-----» CO --------» C1
We replace KO by KOj(K er bO n Ker fo) . Then H°(f) becomes an isomorphism,
thus proving the proposition.
We want to say something more about KO. For this purpose, we define a
new concept. Let tj be a family of objects in the given abelian category (think
of modules in first reading). We shall say that tj is complete if it is sufficient, and
for any exact sequence
o--+ F' --+ F --+ F" --+ 0
with F" and F in tj then F' is also in tj.

838
FINITE FREE RESOLUTIONS
XXI, §1
Example.
In Chapter XVI, Theorem 3.4 we proved that the family of finite
flat modules in the category of finite modules over a Noetherian ring is complete.
Similarly, the family of flat modules in the category of modules over a ring is
complete. We cannot get away with just projectives or free modules, because
in the statement of the proposition, KOis not necessarily free but we want to
include it in the family as having especially nice properties. In practice, the
family consists of the flat modules, or finite flat modules. Cf. Chaper X, Theorem
4.4, and Chapter XVI, Theorem 3.8.
Proposition 1.2. Let f: K -+ C be a morphism of complexes, such that KP,
HP(C) are #0 onlyfor p = 1,. .. , n. Let ty be a complete family, and assume
that KP, CP are in ty for all p, except possibly for KO. Iff is a homology
isomorphism, then KO is also in ty.
Before giving the proof, we define a new complex called the mapping cylinder
of an arbitrary morphism of complexes f by letting
MP = KP EB CP- 1
and defining bM : MP -+ MP+1 by
bM(x, y) = (bx,jx -
by).
It is trivially verified that M is then a complex, i.e. b ob = O. If C' is the com-
plex obtained from C by shifting degrees by one (and making a sign change
in be>, so C'P = CP- 1, then we get an exact sequence of complexes
O-+C'-+M-+K-+O
and hence the mapping cylinder exact cohomology sequence
HP(K) ----> HP+1(C) ----> HP +l(M) ----> HP+l(K) -------. HP+2(C')
II
II
HP(C)
HP+1(C)
and one sees from the definitions that the cohomology maps
are the ones induced by f: K -+ C.
We now return to the assumptions of Proposition 1.2, so that these maps are
isomorphisms. We conclude that H(M) = O. This implies that the sequence
is exact.
Now each MP is in ty by assumption. Inserting the kernels and
cokernels at each step and using induction together with the definition of a
complete family, we conclude that KO is in ty, as was to be shown.

XXI, §2
FINITE FREE RESOLUTIONS
839
In the next proposition, we have axiomatized the situation so that it is
applicable to the tensor product, discussed later, and to the case when the family
(Y consists of flat modules, as defined in Chapter XVI. No knowledge of this
chapter is needed here, however, since the axiomatization uses just the general
language of functors and exactness.
Let (Y be a complete family again, and let T be a covariant additive functor
on the given category. We say that (Y is exact for T if given an exact sequence
o...... F' ...... F ...... F" ...... 0
in (Y, then
o...... T(F') ...... T(F) ...... T(F") ...... 0
is exact.
Proposition 1.3.
Let (Y be a complete Jamily which is exact for T . Let
J :K ...... C be a morphism oj complexes, such that KP and CP are in (Y Jor all
p, and KP, HP(C) are zero [or all but a finite number oj p. Assume that J is a
homology isomorphism. Then
TU) : T(K) ...... T(C)
is a homology isomorphism.
Proof.
Construct the mapping cylinder M for f. As in the proof of Propo-
sition 1.2, we get H(M) = 0 so M is exact. We then start inductively from the
right with zeros. We let ZPbe the cycles in MP and use the short exact sequences
0 ...... ZP ...... MP ...... » : 1 ...... 0
together with the definition of a complete family to conclude that ZPis in (Y for
all p. Hence the short sequences obtained by applying T are exact. But T(M)
is the mapping cylinder of the morphism
TU) : T(K) ...... T(C),
which is therefore an isomorphism, as one sees from the homology sequence of
the mapping cylinder. This concludes the proof.
§2.
FINITE FREE RESOLUTIONS
The first part of this section develops the notion of resolutions for a case
somewhat more subtle than projective resolutions, and gives a good example for
the considerations of Chapter XX. Northcott in [No 76] pointed out that minor
adjustments of standard proofs also applied to the non-Noetherian rings, only
occasionally slightly less tractable than the Noetherian ones.

840
FINITE FREE RESOLUTIONS
XXI, §2
Let A be a ring. A module E is called stably free if there exists a finite free
module F such that E $ F is finite free, and thus isomorphic to A (n) for some
positive integer n. In particular, E is projective and finitely generated.
We say that a module M has a finite freeresolution if there exists a resolution
such that each E, is finite free.
Theorem 2.1.
Let M be a projective module. Then M is stably fr ee if and
only if M admits a finite free resolution.
Proof.
If M is stably free then it is trivial that M has a finite free resolution.
Conversely assume the existence of the resolution with the above notation.
We prove that M is stably free by induction on n. The assertion is obvious if
n = O. Assume n ~ 1. Insert the kernels and cokernels at each step, in the
manner of dimension shifting. Say
M 1 = Ker(Eo -+ P),
giving rise to the exact sequence
o-+ M 1 -+ Eo -+ M -+ O.
Since M is projective, this sequence splits, and Eo ~ M $ M i - But M 1 has a
finite free resolution of length smaller than the resolution of M, so there exists
a finite free module F such that M 1 E9 F is free. Since Eo E9 F is also free, this
concludes the proof of the theorem.
A resolution
is called stably free if all the modules E, (i = 0, ... , n) are stably free.
Proposition 2.2.
Let M be an A-module. Then M has afinitefree resolution
of length n i?; 1 if and only if M has a stably free resolution of length n,
Proof.
One direction is trivial, so we suppose given a stably free resolution
with the above notation. Let 0 ~ i < n be some integer, and let Fi , Fi + 1 be
finite free such that E, E9 F, and Ei + 1 E9 Fi ; 1 are free. Let F = F, EEl F i+ i-
Then we can form an exact sequence
in the obvious manner. In this way, we have changed two consecutive modules
in the resolution to make them free. Proceeding by induction, we can then
make Eo, £1 free, then £1' E2 free, and so on to conclude the proof of the
proposition.

XXI, §2
FINITE FREE RESOLUTIONS
841
The next lemma is designed to facilitate dimension shifting.
We say that two modules M I ' M2 are stably isomorphic if there exist finite
free modules F I' F 2 such that M I EEl F I ~ M2 EEl F 2'
Lemma 2.3.
Let M1 be stably isomorphic to M2• Let
O~NI~EI~MI~O
O~N2~E2~M2~O
be exact sequences, where M I is stably isomorphic to M 2' and EI' E2 are
stably free.
Then N I is stably isomorphic to N 2'
Proof.
By definition, there is an isomorphism MI EEl FI ~ M2 EEl F2 '
We have exact sequences
o~ N I ~ EI EEl FI ~ MI EEl FI ~ 0
o~ N 2 ~ E2 EEl F2 ~ M2 EEl F2 ~ 0
By Schanuel's lemma (see below) weconclude that
Since E
"
E2 , F I, F2 are stably free, wecan add finite free modules to each side
so that the summands of N I and N 2 become free, and by adding l-dimensional
free modules if necessary, wecan preserve the isomorphism, which proves that
N I is stably isomorphic to N 2 •
We still have to take care of Schanuel's lemma:
Lemma 2.4.
Let
o~ K ' ~ P' ~ M ~ 0
be exact sequences where P, P' are projective. Then there is an isomorphism
K EEl P' ~ K' EEl P.
Proof.
Since P is projective,there existsa homomorphism P ~ P' making
the right square in the following diagram commute.
0----+ K ~ P ----+ M ----+ 0
.j
j.
j;,
O-K '~P'-M-O

842
FINITE FREE RESOLUTIONS
XXI, §2
Then one can find a homomorphism K --+ K ' which makes the left square
commute. Then we get an exact sequence
o--+ K --+ P EB K' --+ P' --+ 0
by x H (ix, ux) for x E K and (y, z) H wy - jz. We leave the verification of
exactness to the reader. Since P' is projective, the sequence splits thus proving
Schanuel's lemma. This also concludes the proof of Lemma 2.3.
The minimal length of a stably free resolution of a module is called its
stably free dimension. To construct a stably free resolution of a finite module,
we proceed inductively. The preceding lemmas allow us to carry out the induc-
tion, and also to stop the construction if a module is of finite stably free dimen-
sion.
Theorem 2.5.
Let M be a module which admits a stablyfree resolution of
length n
Let
be an exact sequence with F, stablyfreefor i = 0, . . . , m.
(i) If m < n - 1 then there exists a stablyfree Fm+ I such that the exact
sequence can be continued exactly to
F m + I --+ . .• --+ F 0 --+ M --+ O.
(ii) If m = n -
1, let F; = Ker(Fn _ I --+ Fn - 2)' Then F; is stably free
and thus
is a stably free resolution.
Remark.
If A is Noetherian then of course (i) is trivial, and we can even
pick Fm+ I to be finite free.
Proof.
Insert the kernels and cokernels in each sequence, say
Km = Ker(Em--+ Em-I)
if
m =1= 0
K o = Ker(Eo --+ M),
and define K;" similarly. By Lemma 2.3, Km is stably isomorphic to K;", say
with F, F' finite free.

XXI, §2
FINITE FREE RESOLUTIONS
843
If m <
11 -
1, then K m is a homomorphic image of Em + I ; so both K m Ef) F
and K ~ Ef) F' are homomorphic images of Em + I Ef) F. Therefore K ~ is a homo-
morphic image of Em + I Ef) F which is sta bly free. We let Fm + I = Em + I Ef) F to
conclude the proof in this case.
If m = 11 -
1, then we can take K; = En . Hence KmEf) F is stably free, and
so is K ~ Ef) F' by the isomorphism in the first part ofthe proof. It follows trivially
that K ~ is stably free, and by definition, K ~ = Fm + I in this case. This concludes
the proof of the theorem.
Corollary 2.6.
If 0 ~ M I ~ E ~ M ~ 0 is exact, M has stably fr ee dimen-
sion ~ n, and E is stably f ree, then M 1 has stably free dimension ~ n -
1.
Theorem 2.7.
Let
o-. M' ~ M~ M"~ 0
be an exact sequence. If any two of these modules have a finite fr ee resolution,
then so does the third .
Proof.
Assume M ' and M have finite free resolutions. Since M is finite, it
follows that MOl is also finite. By essentially the same construction as Chapter
XX, Lemma 3.8, we can construct an exact and commutative diagram where
E', E, E" are stably free:
000
j
j
j
O~l;~l'~M(~O
0----+ E' ----+ E --- E" --- 0
j
j
j
0 ----+ M' ----+ M --- M "----+ 0
j
j
j
000
We then argue by induction on the stably free dimension of M. We see
that M I has stably free dimension ~ n -
1 (actually n -
1, but we don't care),
and M 'I has finite stably free dimension. By induction we are reduced to the
case when M has stably free dimension 0, which means that M is stably free.
Since by assumption there is a finite free resolution of M ', it follows that MOl
also has a finite free resolution, thus concluding the proof of the first assertion.

844
FINITE FREE RESOLUTIONS
XXI, §2
Next assume that M ', M " have finite free resolutions. Then M is finite.
If both M ' and M " have stabl y free dimension 0, then M ', M " are projective
and M
~ M ' EEl M " is also stably free and we are done. We now argue by
induction on the maximum of their stably free dimension n, and we assume
n ~ 1. We can construct an exact and commutative diagram as in the previous
case with E', E, E" finite free (we leave the details to the reader). But the maxi-
mum of the stably free dimensions of M 'I and M '{ is at most n - 1, and so by
induction it follow s that MI has finite stably free dimen sion. This concludes the
proof of the second case.
Observe that the third statement has been proved in Chapter XX, Lemma 3.8
when A is Noetherian, taking for <t the abelian category of finite modules, and
for rt the family of stably free modules. Mitchell Stokes pointed out to me that
the statement is valid in general without Noetherian assumption, and can be
proved as follows . We assume that M, M" have finite free resolutions. We first
show that M' is finitely generated. Indeed, suppose first that M is finite free . We
have two exact sequences
O-M' - M-M"- 0
O-K"- F"-M"- 0
where F" is finite free , and K" is finitely generated because of the assumption
that M" has a finite free resolution. That M' is finitely generated follows from
Schanuel's lemma. If M is not free , one can reduce the finite generation of M'
to the case when M is free by a pull-back, which we leave to the reader.
Now suppose that the stably free dimension of M" is positive. We use the
same exact commutative diagram as in the previous cases, with E', E , E" finite
free . The stably free dimension of M'I is one less than that of M", and we are
done by induction. This concludes the proof of Theorem 2.7.
This also concludes our general discussion of finite free resolutions. For
more information cf. Northcott's book on the subject.
We now come to the second part of this section, which provides an applica-
tion to polynomial rings.
Theorem 2.8.
Let R be a commutative Noetherian ring . Let x be a variable.
Ifeveryfinite R-module has a finite free resolution. then everyfinite R[x ]-module
has a finite free resolution.
In other words, in the category of finite R-modules, if every object is of
finite stably free dimension, then the same property applies to the category of
finite R[x]-modules. Before proving the theorem, we state the application we
have in mind.
Theorem 2.9.
(Serre).
If k is a field and XI , . . .• .r, independent vari-
ables. then every finite projective module over k[x ), . . . , xr] is stably free. or
equivalently admits a finite free resolution.

XXI, §2
FINITE FREE RESOLUTIONS
845
Proof.
By induction and Theorem 2.8 we conclude that every finite module
over k[Xl' . . . , xr] is of finite stably free dimension. (We are using Theorem
2. I.) This concludes the proof.
The rest of this section is devoted to the proof of Theorem 2.8 .
Let M be a finite R[x]-module. By Chapter X, CorolIary 2.8, M has a finite
filtration
such that each factor MJM j+ I is isomorphic to R[x]IPj for some prime Pj.
In light of Theorem 2.7, it suffices to prove the theorem in case M = R[x]/P
where P is prime, which we now assume. In light of the exact sequence
0--+ P --+ R[x] --+ R[x]IP --+ O.
and Theorem 2.7, we note that M has a finite free resolution if and only if P
does.
Let p = P 11 R. Then p is prime in R. Suppose there is some M = R[x]IP
which does not admit a finite free resolution. Among all such M we select one for
which the intersection p is maximal in the family of prime ideals obtained as
above. This is possible in light of one of the basic properties characterizing
Noetherian rings .
Let Ro = Rip so Ro is entire. Let Po = PlpR[x]. Then we may view M
as an Ro[x]-module, equal to RoIPo. Let! I"' " In be a finite set of generators
for Po, and let ! be a polynomial of minimal degree in Po. Let Ko be the
quotient field of Ro. By the euclidean algorithm, we can write
Ii = qJ + r,
for
i = I, ... , n
with qi, rj E Ko[x] and deg rj < deg f.
Let do be a common denominator for
the coefficients of all qj, r i o Then do i= 0 and
where q; = doqj and r; = dorj lie in Ro[x].
Since deg j' is minimal in Po it
follows that r;= 0 for all i, so
Let No = PoIU), so No is a module over Ro[x], and we can also view No
as a module over R[x]. When so viewed, we denote No by N. Let d e R be any
element reducing to do mod p. Then d ¢ p since do i= O. The module No has
a finite filtration such that each factor module of the filtration is isomorphic to
some Ro[x]IQo where Qo is an associated prime of No. Let Q be the inverse
image of Qo in R[x]. These prime ideals Q are precisely the associated primes
of N in R[x]. Since do ki11s No it follows that d kills N and therefore d lies in
every associated prime of N. By the maximal ity property in the selection of P,

846
FINITE FREE RESOLUTIONS
XXI, §3
it follows that every one of the factor modules in the filtration of N has a finite
free resolution, and by Theorem 2.7 it follo ws that N itself has a finite free
resolution.
Now we view Ro[x] as an R[x]-module, via the canonical homomorphism
R[x] -+ Ro[x] = R[x]jpR[x].
By assumption, p has a finite free resolution as R-module, say
o-+ En -+ . . . -+ Eo -+ p -+ O.
Then we may simply form the modules EJx] in the obvious sense to obtain a
finite free resolution of p[x] = pR[x]. From the exact sequence
o-+ pR[x] -+ R[x] -+ Ro[x] -+ 0
we conclude that Ro[x] has a finite free resolution as R[x]-module.
Since Ro is entire, it follows that the principal ideal (f) in Ro[x] is R[x]-
isomorphic to Ro[x], and therefore has a finite free resolution as R[x]-module.
Theorem 2.7 applied to the exact sequence of R[x]-modules
o-+ (f) -+ Po -+ N -+ 0
shows that Po has a finite free resolution ; and further applied to the exact
sequence
0-+ pR[x] -+ P -+ Po -+ 0
shows that P has a finite free resolution, thereby concluding the proof of
Theorem 2.8 .
§3.
UNIMODULAR POLYNOMIAL VECTORS
Let A be a commutative ring. Let (fl' . . . , f,,) be elements of A generating
the unit ideal. We call such elements unimodular. We shall say that they have
the unimodular extension property if there exists a matrix in GLn(A) with first
column '(fl' .. . ,fn)' If A is a principal entire ring, then it is a trivial exercise to
prove that this is always the case. Serre originally asked the question whether
it is true for a polynomial ring k[x I ' . .. , xr] over a field k. The problem was
solved by Quillen and Suslin. We give here a simplification of Suslin's proof by
Vaserstein, also using a previous result of Horrocks. The meth od is by induc-
tion on the number of variables. in some fashion.
We shall write f = l(fl""
,j~ ) for the column vector.
We first remark
thatfhas the unimodular extension property if and only if the vector obtained
by a permutation of its components has this property. Similarl y, we can make

XXI, §3
UNIMODULAR POLYNOMIAL VECTORS
847
the usual row operations, add ing a mult iple et. to JJ (j '" i), and f has the uni-
modular extension property if and only if any one of its transforms by row
operations has the unimodular extension property.
We first prove the theorem in a context which allows the induction.
Theorem 3.1.
(Horrocks).
Let (0, m) be a local ring and let A = o[x]
be the polynomial ring in one variable over o. Let f be a unimodular vector
in A(n) such that some component has leading coefficient I. Then f has the
unimodular extension property.
Proof.
(Suslin).
If n = 1 or 2 then the theorem is obvious even without
assuming that 0 is local.
So we assume n ~ 3 and do an induction of the
smallest degree d of a component off with leading coefficient I. First we note
that by the Euclidean algorithm and row operations, we may assume that fl
has leading coefficient 1, degree d, and that degj; < d for j '" 1. Since f is
unimodular, a relation Lgij; = 1 shows that not all coefficients of fz , ... ,f"
can lie in the maximal ideal m. Without loss of generality, we may assume that
some coefficient offz does not lie in m and so is a unit since 0 is local. Write
fl(x) = xd+ ad_Ixd- 1 + ... + ao
with
ai EO,
fz(X) =
bsxs + ' " + bo
with
b, E 0, S ~ d -
I,
so that some b,is a unit. Let a be the ideal generated by all leading coefficients
of polynomials e.I, + gz fz of degree
~ d - I. Then a contains all the co-
efficients bi' i = 0, .. . , s. One sees this by descending induction, starting with
b, which is obvious, and then using a linear combination
Therefore a is the unit ideal, and there exists a polynomial 9dl + g2f2 of
degree ~ d -
1 and leading coefficient 1. By row operations, we may now get
a polynomial of degree
~ d -
1 and leading coefficient 1 as some component
in the i-th place for some i", 1, 2. Thus ultimately, by induction, we may
assume that d = 0 in which case the theorem is obvious. This concludes the
proof.
Over any commutative ring A , for two column vectors f, 9 we write f -
9
over A to mean that there exists M E GLn(A) such that
f= Mg,
and we say that f is equivalent to g over A. Horrocks' theorem states that a
unimodular vectorf with one component having leading coefficient 1 is o[x]-
equivalent to the first unit vector e'.
We are interested in getting a similar
descent over non-local rings. We can write f = f(x), and there is a natural
"constant " vector f(O) formed with the constant coefficients. As a corollary of
Horrocks' theorem, we get :

848
FINITE FREE RESOLUTIONS
XXI, §3
Corollary 3.2.
Let
0 be a local ring.
Let f be a unimodular vecto r in
o[x]ln) such that some component has leading coefficient 1.
Then f
- f(O)
over o[x].
Proof.
Note that f (O) E o(n) has one component which is a unit. It suffices
to prove that over any commutative ring R any element c E R (n)such that some
component is a unit is equi valent over R to e l , and this is obvious.
Lemma 3.3.
Let R be an entire ring, and let S be a multiplicative subset.
Let x, y be independent variables. Iff (x) - f (O) over S-)R[x], then there exists
c E S such that f(x + cy) - f (x) over R[x, y].
Proof.
Let ME GLn(S - 1R[x]) be such
that f(x) = M(x)f(O).
Then
M(X)-If(x) = f(O) is constant, and thus invariant under translation x 1---+ x + y.
Let
G(x, y) = M(x)M(x + y)-I.
Then G(x, y)f (x + y) = f(x). We have G(x, 0) = I whence
G(x , y) = I + yH(x , y)
with H(x , y) E S- 1R[x, y]. There exists c E S such that cH has coefficients in
R. Then G(x , cy) has coefficients in R. Since det M(x) is constant in S-I R, it
follows that det M(x + cy) is equal to this same constant and therefore that
det G(x , cy) = 1. This pro ves the lemma.
Theorem 3.4.
Let R be an entire ring, and let I be a unimodular vector in
R[x](n), such that one component has leading coefficient 1. Then I (x) - f (O)
over R[x].
Proof.
Let J be the set of elements c E R such that f(x + cy) is equivalent
to f(x) over R[x , y]. Then J is an ideal, for if c E J and a E R then replacing y
by ay in the definition of equi valence shows that f(x + cay) is equivalent to
f(x) over R[x, ay], so over R[x, y]. Equally easily, one sees that if c, c' E J
then c + c' E J. Now let p be a prime ideal of R. By Corollary 3.2 we know
that f(x) is equivalent to f(O) over Rp[x], and by Lemm a 3.3 it follows that
there exists c E Rand c ¢ p such that f(x + cy ) is equivalent to f(x) over
R[x, y]. Hence J is not contained in p, and so J is unit ideal in R , so there exists
an invertible matrix M(x, y) over R[x, y] such that
f (x + y) = M(x, y)f(x).
Since the homomorphic image of an invertible matrix is invertible, we substitute
ofor x in this last relation to conclude the proof of the theorem.
Theorem 3.5.
(Quillen-Suslin).
Let k be afield and letfbe a unimodular
vector in k[x) , . .. , xr](n). Then I has the unimodular extension property .

XXI, §3
UNIMODULAR POLYNOMIAL VECTORS
849
Proof.
By induction on r. If r = 1 then k[xlJ is a principal ring and the
theorem is left to the reader. Assume the theorem for r -
1variables with r ~ 2,
and put
We view f as a vector of polynomials in the last variable x, and want to apply
Theorem 3.4. We can do so if some component off has leading coefficient 1 in
the variable x., We reduce the theorem to this case as follows. The proof of the
Noether Normalization Theorem (Chapter VIII , Theorem 2.1) shows that if we
let
Yi = Xi -
X ~"
then the polynomial vector
has one component with Yr-leading coefficient equal to 1. Hence there exists a
matrix N(y) = M(x) invertible over R[xrJ = R[YrJ such that
g(YI"' " Yr) = N(YI"' " Yr)g(YI" ' " Yr-I' 0),
and g(YI" '"
Yr-] , 0) is unimodular in k[YI' . .. , Yr _l]<n). We can therefore
conclude the proof by induction.
We now give other formulations of the theorem. First we recall that a
module E over a commutative ring A is called stably free if there exists a finite
free module F such that E EB F is finite free.
We shall say that a commutative ring A has the unimodular column exten-
sion property if every unimodular vectorf
E A(n) has the unimodular extension
property, for all positive integers n.
Theorem 3.6.
Let A be a commutative ring which has the unimodular column
extension property. Then every stably free module over A is free.
Proof.
Let E be stably free. We use induction on the rank of the free
modules F such that E EB F is free. By induction, it suffices to prove that if
E EB A is free then E is free. Let E EB A = A(n) and let
be the projection. Let ul be a basis of A over itself. Viewing A as a direct
summand in E EB A = A(n) we write

850
FINITE FREE RESOLUTIONS
XXI, §4
Then u l is unimodular, and by assumption u l is the first column of a mat rix
M = (aij) whose determinant is a unit in A. Let
uj= A1ej
for j=l, ... , n,
where e! is the j-th unit column vector of A(n). Note that u I is the first column
of M. By elementary column operations, we may change M so that uj E E for
j = 2, . . . , n. Indeed, if pe! = CU i for j f; 2 we need only replace ej by e' -
eel.
Without loss of generality we may therefore assume that u2, •• • , u" lie in E.
Since M is invertible over A, it follows that M induces an automorphism of
A(n) as A-module with itself by
XHMX.
It follows immediately from the construction and the fact that A(n) = E EEl A
that M maps the free module with basis {e2, .• . , en} onto E. This concludes
the proof.
If we now feed Serre' s Theorem 2.9 into the present machinery consisting
of the Quillen-Suslin theorem and Theorem 3.6, we obtain the alternative version
of the Quillen-Suslin theorem:
Theorem 3.7.
Let k be a field. Then every finite projective module over the
polynomial ring k[x I> . .. , x,] is fr ee.
§4.
THE KOSZUL COMPLEX
In this section, we describe a finite complex built out of the alternating
product of a free module. This gives an application of the alternating product,
and also gives a fundamental construction used in algebraic geometry, both
abstract and complex, as the reader can verify by looking at Griffiths-Harris
[GrH 78], Chapter V, §3; Grothendieck's [SGA 6]; Hartshorne [Ha 77], Chapter
III , §7; and Fulton-Lang [FuL 85], Chapter IV, §2.
We know from Chapter XX that a free resolution of a module allows us to
compute certain homology or cohomology groups of a functor. We apply this
now to Hom and also to the tensor product. Thus we also get examples of explicit
computations of homology, illustrating Chapter XX, by means of the Koszul
complex. We shall also obtain a classical application by deriving the so-called
Hilbert Syzygy theorem.
Let A be a ring (always assumed commutative) and M a module . A sequence
of elements X I "
' "
x; in A is called M-regular if M!(Xl"
'"
x,)M "* 0, if X l

XXI, §4
THE KOSZUL COMPLEX
851
is not divisor of zero in M , and for i ~ 2, Xi is not divisor of 0 in
It is called regular when M = A.
Proposition 4.1.
Let / = (xl"
. . , xr) be generated by a regular sequence
in A. Then //P is f ree of dimension rover A//.
Proof
Let Xi be the class of Xi mod / 2. It suffices to prove that Xl> ... , Xr
are linearly independent. We do this by induction on r. For r = 1, if ax = 0,
then ax = bx?for some b E A, so x(a -
bx) = O. Since x is not zero divisor in A,
we have a = bx so a= O.
Now suppose the proposition true for the regular sequence XI"' "
Xr-I '
Suppose
t n.s; = 0
in
/1/2 •
i = I
We may assume that L aixi = 0 in A; otherwise L a.x, = L YiXiwith Yi E / and
we can replace a, by ai - Yi without changing ai'
Since x , is not zero divisor in AI(x l , .• • , xr - I ) there exist b, E A such that
, -1
, -I
,- I
a,x, + L a.x, = 0 = a, = L b.x, = L (ai + bixr)Xi = O.
i= I
i= I
i = I
By induction,
, - I
aj+bjx,E LAx j
i = 1
u = 1, . . . , r -
1)
so aj E / for all j, so aj = 0 for allj, thus proving the proposition.
Let K, L be complexes, which we write as direct sums
with p, qEZ.
Usually, Kp = Lq = 0 for p, q < O.
Then the tensor product
K ® L is the complex such that
(K ® L)n =
EEl «, ® i.;
p +q=n
and for U E K p , v E Lq the differential is defined by
d(u ® v) = du ® v + (-l)pu ® dv.
(Carry out the detailed verification, which is routine, that this gives a complex.)

852
FINITE FREE RESOLUTIONS
XXI, §4
Let A be a commutative ring and x E A. We define the complex K(x) to have
Ko(x) = A,KI(x) = Ael , where el is a symbol, Ael is the free module of rank 1
with basis {ed, and the boundary map is defined by del = x, so the complex
can be represented by the sequence
d
O-Ael
-
A-O
"
II
O-KI(x)-Ko(x)-O
More generally, for elements XI' ... , X, E A we define the Koszul complex
K(x) = K(XI, . . . , x.) as follows. We put :
Ko(x) = A;
KI(x) = free module E with basis {el"' "
er };
KpCx) == free module /'fE with basis {eiJ II ... II ei)' it < '"
< ip ;
Kr(x) == free module /'(E of rank I with basis el
II ... II e..
We define the boundary maps by de; = Xi and in general
by
p
dee· /\ ... /\ e, ) = L(-l)i- 1x. e, /\ . . . /\ e: /\ ... /\ e, .
1 1
I p
j === J
I j
1 1
I j
I p
A direct verification shows that d2 = 0, so we have a complex
0-+ K,(x) -+ . .. -+ Kp(x) -+ .. , -+ K l(x) -+ A -+ 0
The next lemma shows the extent to which the complex is independent of the
ideal I == (xI' ... , xr) generated by (x) . Let
be two ideals of A. We have a natural ring homomorphism
can : A/I' -+ A/I.
Let {e'l , •• • , e~} be a basis for KI(y), and let

XXI, §4
and
THE KOSZUL COMPLEX
853
product taken p times.
Let D = det(ci) be the determinant. Then for p = r we get that
f,. : K,(y) -+ K,(x) is multiplication by D.
Lemma 4.2.
Notation as above, the homomorphisms/p define a morphism of
Koszul complexes:
and define an isomorphism ifD is a unit in A. for instance if (y) is a permutation
of (x) .
Proof
By definition
f(e~
A
' "
A e~ ) = (~ c..e .)
A .. . A (~c. .e.)
II
i p
L,
111
}
L,
Ip }
}
•
j=!
j = !
Then
fi(J(e ~
A' "
A
e ~ )
11
I p
= f("(-l)k -l y. e~
A .. . A? A
. .. A e~)
Z:
lk
I I
l k
Ip
k
A ... A (~c..e.)
L,
Ip}
}
j=!
=
dlf(e ~
A
' "
A
e~ )
11
Ip
using Yik = 2: CikjXj' This concludes the proof that thefp define a homomorphism
of complexes.
In particular, if (x) and (y) generate the same ideal, and the determinant D
is a unit (i.e. the linear transformation going from (x) to (y) is invertible over
the ring), then the two Koszul complexes are isomorphic.

854
FINITE FREE RESOLUTIONS
The next lemma gives us a useful way of making inductions later.
Proposition 4.3.
There is a natural isomorphism
XXI, §4
Proof
The proof will be left as an exercise.
Let I = (Xl' ... , X.) be the ideal generated by Xl"' " X•. Then directly from
the definitions we see that the O-th homology of the Koszul complex is simply
A/IA.
More generally, let M be an A-module. Define the Koszul complex of M by
K(x; M) = K(x l , ... , x.; M) = K(x l , . .. , x.) ®A M
Then this complex looks like
o~ K/x) ® M ~ ... ~ K2(x) ®A M ~ M(r) ~ M ~ O.
We sometimes abbreviate HpCx; M) for HpK(x; M) . The first and last homology
groups are then obtained directly from the definition of boundary. We get
Ho(K(x; M» = M/IM;
Hr(K(x); M) = {v E M such that XiV = 0 for all i = I , ... , r} .
In light of Proposition 4.3 , we study generally what happens to a tensor
product of any complex with K(x), when X consists of a single element. Let
yEA and let C be an arbitrary complex ofA-modules. We have an exact sequence
of complexes
(1)
o~ C ~ C 0 K(y) ~ (C ® K(y»/C ~ 0
made explicit as follows .

XXI, §4
THE KOSZUL COMPLEX
855
We note that C 0 K1(y) is just C with a dimension shift by one unit , in other
words
(2)
In particular,
(3)
(4)
Associated with an exact sequence of complexes, we have the homology sequence,
which in this case yields the long exact sequence
a
--> H n+ 1(C 0 K(y)/C)--> Hn(C)
n
Hn(C)
which we write stacked up according to the index:
~ Hp+I(C) ~ Hp+1(C) ~ Hp+I(C Q9 K(y)) ~
~ Hp(C) ~ HpCC) ~ Hp(C Q9 K(y)) ~
ending in lowest dimension with
(5)
Furthermore, a direct application of the definition of the boundary map and the
tensor product of complexes yields:
The boundary map on HpCC) (p
~ 0) is induced by multiplication by (-l)Py:
(6)
Indeed, write
(C Q9 as»; = (Cp Q9 A) EB (Cp_1 0 K1(y)) = c, EB Cp_I '
Let (v, w)
E Cp EB Cp_1 with v E Cp and W E Cp _ I ' Then directly from the
definitions,
(7)
d(v, w) = (dv + (-l)p-lyw, dw).
To see (6), one merely follows up the definitions of the boundary, taking an
element w E Cp = Cp Q9 K1(y), lifting back to (0, w) , applying d, and lifting
back to Cpo If we start with a cycle, i.e. dw = 0, then the map is well defined
on the homology class, with values in the homology.
Lemma 4.4.
Let yEA and let C be a complex as above . Then m(y) annihilates
Hp(C 0 K(y)) for all p ~ O.
Proof.
If (v, w) is a cycle, i.e. d(v, w) = 0, then from (7) we get at once
that (yv, yw) = d(O, (-l)Pv), which proves the lemma.

856
FINITE FREE RESOLUTIONS
In the applications we have in mind , we let y = .r, and
C = K(xI"' " Xr-I ; M ) = Ktx, , . . . , Xr- I) Q9 M.
Then we obtain:
Theorem 4.5.(a)
There is an exact sequence with maps as above:
XXI, §4
~ HpK(xJ""
,-Xr-I; M) ~ HpK(x" . . . , xr- J; M ) ~ HpK(x" . . . , Xr; M)
m(x r)
• . . ~ H1(XI "
' " Xr; M ) ~ HO(XI"
'"
Xr-I ; M)
~ HO(x l , ••• , Xr-I; M ).
(b) Every element ofI = (XI"
.. , xr) annihilates Hp(x; M)for p ~ o.
(c) If I = A, then Hp(x; M) = 0 for all p ~ O.
Proof.
This is immediate from Proposition 4.3 and Lemma 4.4.
We define the augmented Koszul complex to be
O~Kr(x;M)~
"
' ~ K I (x ; M ) =M(r)~M~M/IM~O.
Theorem 4.6.
Let M be an A-module.
(a) Let XI' ... , xr be a regular sequence for M. Then HpK(x; M) = 0 for
p > o. (Of course, HoK(x; M) = M/IM.) In other words, the augmented
Koszul complex is exact.
(b) Conversely, suppose A is local, and x" . . . , .r, lie in the maximal ideal of
A. Suppose M isfinite over A, and also assume that H1K(x; M) = O. Then
(xI' . . . , xr) is M-regular.
Proof.
We prove (a) .by induction on r. If r = 1 then H1 (x;M ) = 0 directly
from the definition. Suppose r > I . We use the exact sequence of Theorem
4.5(a). If p > 1 then Hp(x;M ) is between two homology groups which are 0, so
Hp(x; M ) = O. If p = I , we use the very end of the exact sequence of Theorem
4.5(a), noting that m(xr) is injective, so by induction we find HJ (x; M ) = 0 also ,
thus proving (a).
As to (b), by Lemma 4.4 and the hypothesis, we get an exact sequence
m(x,)
H, (xJ" ' " Xr-I; M) ~ H1(x" . .. , xr- l ; M) ~ H1(x; M) = 0,
so m(xr) is surjective. By Nakayama's lemma, it follows that
HI(x" . . . , xr-I ; M) = O.
By induction (x" . . . , Xr- I) is an M-regular sequence. Looking again at the tail
end of the exact sequence as in (a) shows that xr is M/ (x" .. . , xr_I)M-regu!ar,
whence proving (b) and the theorem.
We note that (b), which uses only the triviality of HI (and not all Hp) is
due to Northcott [No 68], 8.5 , Theorem 8. By (a), it follow s that Hp = 0 for
p > O.

XXI, §4
THE KOSZUL COMPLEX
857
An important special case of Theorem 4.6(a) is when M = A, in which case
we restate the theorem in the form:
Let x t , ... , x, be a regular sequence in A. Then K(xI' . . . , x,) is a free
resolution of All :
0-+ K,(x) -+ ... -+ K1(x) -+ A -+ A/I -+ O.
In particular, A/I has Tor-dimension ~ r.
For the Hom functor, we have :
Theorem 4.7.
Let x 10 • • • , x, be a regular sequence in A. Then there is an
isomorphism
({Jx,M : W(Hom(K(x), M)) -+ M/IM
to be described below.
Proof
The module Kr(x) is l-dimensional, with basis el
1\ . .. 1\ e..
Depending on this basis, we have an isomorphism
Hom(K,(x), M) ~ M,
whereby a homomorphism is determined by its value at the basis element in M.
Then directly from the definition of the boundary map d,in the Koszul complex,
which is
r
d . ell ' .. II e
1-+ ~ (-ly·-t x.e
II' "
II e· II , . . II e
,'1
r
~
JI
J
r
J=l
we see that
W(Hom(Kr(x), M) ~ Hom(Kr(x), M)/dr- 1 Hom(Kr_1(x), M)
~ M/IM.
This proves the theorem.
The reader who has read Chapter XX knows that the i -th homology group
of Hom(K(x), M) is called Exti(AI I, M), determined up to a unique isomorphism
by the complex, since two resolutions of AII differ by a morphism of complexes,
and two such morphisms differ by a homotopy which induces a homology iso-
morphism. Thus Theorem 4.7 gives an isomorphism
({Jx,M: Extr(A/I, M) -+ M/IM.
In fact, we shall obtain morphisms of the Koszul complex from changing the
sequence. We go back to the hypothesis of Lemma 4.2.

858
FINITE FREE RESOLUTIONS
XXI, §4
Lemma 4.8.
If I = (x) = (y) where (x) , (y) are two regular sequences, then
we have a commutative diagram
M/IM
Ext'(AII, Ml(
jD-''''',,1
M/IM
where all the maps are isomorphisms of All-modules.
The fact that we are dealing with A/I-modules is immediate since multiplication
by an element of A commutes with all homomorphisms in sight, and I an-
nihilates A/I.
By Proposition 4.1, we know that 1/P is a free module of rank r over AII.
Hence
is a free module of rank 1, with basis Xl 1\ • .. 1\ X, (where the bar denotes
residue class mod [2). Taking the dual of this exterior product, we see that under
a change of basis, it transforms according to the inverse of the determinant
mod 12 • This allows us to get a canonical isomorphism as in the next theorem.
Theorem 4.9.
Let xI' . .. , x, be a regular sequence in A, and let I = (x).
Let M be an A-module. Let
t/!x,M: M/IM -+ (M/IM) ® 1\'(I/12)dual
be the embedding determined by the basis (Xl 1\ • . . 1\ x,)dual of 1\'(I/12)dUal.
Th en the composite isomorphism
Ext'( A/I , M) ~ M/IM ~ (M/IM) ® 1\'(I/[2)dual
is a fun ctorial isomorphism, independent of the choice of regular generators
for I.
We also have the analogue of Theorem 4.5 in intermediate dimensions.
Theorem 4.10.
Let Xl' . . . , X, be an M-regular sequence in A. Let I = (x) .
Then
Exti(A/I , M) = 0
for
i < r.
Proof
For the proof, we assume that the reader is acquainted with the
exact homology sequence. Assume by induction that Exti(A/I, M) = 0 for

XXI, §4
i < r -
1. Then we have the exact sequence
THE KOSZUL COMPLEX
859
for i < r. But X I E I so multiplication by X I induces 0 on the homology groups,
which gives Exti(A/I , M) = 0 as desired.
Let L N --+ N --+ 0 be a free resolution of a module N. By definition,
Tort(N , M) = i-th hom ology of the complex L ® M.
This is independent of the choice of L N up to a unique isomorphism. We now
want to do for Tor what we have just done for Ext.
Theorem 4.11 .
Let I = (XI' . . .• xr ) be an ideal of A generated by a regular
sequence of length r.
(i) There is a natural isomorphism
Tort(A/I , AI!) ~ 1\~ /I(I/I 2 ) ,
f or
i ~ O.
(ii) Let L be a f ree All-module, ex tended naturally to an A-module. Then
Tort(L, A/I ) ~ L ® 1\~ /I(I/I2 ),
f or
i ~ O.
These isomorphisms will follow from the next considerations.
First we use again that the residue classes XI' . .. , X, mod 12 form a basis of
1/12 over A/I. Therefore we have a unique isomorphism of complexes
with zero differentials on the right-hand side, such that
e. /\ . . . /\ e, I-> x· /\ ... /\ x· .
11
Ip
11
l p
Lemma 4.12.
Let I = (x) => I' = (y) be two ideals generated by regular
sequences oflength r. Let f : K(y) ~ K(x) be the morphism ofKoszul complexes
defined in Lemma 4.2. Then the following diagram is commutative:

860
FINITE FREE RESOLUTIONS
Proof
We have
r
r
= "C· ·x· /\ ... /\ "C . ·x·
L.
'11
}
L.
I p }
}
j=2
j=1
This proves the lemma.
In particular, if I' = I then we have the commutative diagram
K(y)
f.'j "\ !\(ljJ')
K(X)~
XXI, §4
which shows that the identification of Tori(AII, All) with l\i(III2) via the
choices of bases is compatible under one isomorphism of the Koszul complexes,
which provide a resolution of A/I. Since any other homomorphism of Koszul
complexes is homotopic to this one, it follows that this identification does not
depend on the choices made and proves the first part of Theorem 4.11 .
The second part follows at once, because we have
Torf(A/I, L) = Hi(K(x) @ L) = Hi«K(x) @A A/l) @A/IL
= 1\~/I(I/I2) @ L.
This concludes the proof of Theorem 4.11.
Example.
Let k be a field and let A = k[XI' . . . , xr] be the polynomial ring
in r variables. Let I = (x I ' . . . , x.) be the ideal generated by the variables. Then
A/I = k, and therefore Theorem 4.11 yields for i ~ 0:
Tort(k, k) ~ l\iU/I2)
Tort(L, k) ~ L @ l\iU/I2)
Note that in the present case, we can think of 1112as the vector space over k with
basis XI" '" xr • Then A can be viewed as the symmetric algebra SE, where E
is this vector space. We can give a specificexample of the Koszul complex in this
context as in the next theorem, given for a free module.

XXI, §4
THE KOSZUL COMPLEX
861
Theorem 4.13.
Let E be afinitefree module ofrank r over the ring R. For
each p = I, . . . , r there is a unique homomorphism
such that
P
=
L (-Iy-I(x i
/\ ... /\ X; /\ ... /\ xp) @(X j@Y)
i = 1
where Xi E E and Y ESE. This gives the resolution
Proof
The above definitions are merely examples of the Koszul complex
for the symmetric algebra SE with respect to the regular sequence consisting of
some basis of E.
Since dp maps /\PE @ SqE into /\P-IE e sq+IE, we can decompose this
complex into a direct sum corresponding to a given graded component, and
hence :
Corollary 4.14.
For each integer n ~ I, we have an exact sequence
o--+ /\rE @ S"-rE --+ •• • --+ /\ 1E @ S"- 1E --+ S"E --+ 0
where SjE = 0forj < o.
Finally, we give an appl ication to a classical theorem of Hilbert. The poly-
nomial ring A = k[x 1, . .. , x.] is naturally graded, by the degrees of the homo-
geneous components. We shall consider graded modules, where the grading is in
dimensions ~ 0, and we assume that homomorphisms are graded of degree O.
So suppose M is a graded module (and thus M; = 0 for i < 0) and M is finite
over A. Then we can find a graded surjective homomorphism
L o --+ M --+ 0
where Lo is finite free. Indeed, let W I' ... , Wn be homogeneous generators of M.
Let el' . . . , en be basis elements for a free module Lo over A. We give Lo the
grading such that ifa E A is homogeneous of degree d then aejis homogeneous of
degree
deg aei = deg a + deg Wj '
Then the homomorphism of L o onto M sending e,~ Wi is graded as desired.

862
FINITE FREE RESOLUTIONS
XXI, §4
The kernel M I is a graded submodule ofLo. Repeating the process,we can find a
surjective homomorphism
We continue in this way to obtain a graded resolution of M. We want this
resolution to stop, and the possibility of its stopping is given by the next theorem.
Theorem 4.15.
(Hilbert Syzygy Theorem).
Let k be afield and
the polynomial ring in r variables. Let M be a gradedmodule over A, and let
be an exact sequence ofgraded homomorphisms ofgraded modules, such that
Lo'
, Lr- ) arefree. Then K is free. If M is in addition finite over A and
Lo,
, L,
-t I arefinite free, then K is finite free.
Proof.
From the Koszul complex we know that Tori(M, k) = 0 for i > r
and all M. By dimension shifting, it follows that
Tori(K, k) = 0
for
i > O.
The theorem is then a consequence of the next result.
Theorem 4.16.
Let F be a gradedfinite moduleover A = k[x), . .. , xrJ. If
Torl(F, k) = 0 then F isfree.
Proof.
The method is essentially to do a Nakayama type argument in the
case of the non-local ring A. First note that
F@k = F/IF
where 1 = (XI' . . . , x.),
Thus F @ k is naturally an A/I = k-module.
Let
VI ' • • • , Vnbe homogeneous elements of F whose residue classes mod IF form a
basis of F/IF over k. Let L be a free module with basis e), . . . , en' Let
L~F
be the graded homomorphism sending ei H
Vi for i = 1,. . . , n. It suffices to
prove that this is an isomorphism. Let C be the cokernel, so we have the exact
sequence
L~F~ C~O.
Tensoring with k yields the exact sequence
L @ k ~ F @ k ~ C @ k ~ O.

XXI, §4
THE KOSZUL COMPLEX
863
Since by construction the map L @ k -> F @ k is surjective, it follows that
C @ k = O. But C is graded, so the next lemma shows that C = O.
Lemma 4.17.
Let N be a graded module over A = k[XI," " Xr ].
Let
I = (XI • . . . ,xr) . If N/IN = 0 then N = O.
Proof
This is immediate by using the grading, looking at elements of N
of smallest degree if they exist, and using the fact that elements of I have degree
> O.
We now get an exact sequence of graded modules
O->E->L->F->O
and we must show that E = O. But the exact homology sequence and our as-
sumption yields
0= Torl(F, k) -> E @ k -> L @ k -> F @ k -> O.
By construction L @ k -> F @ k is an isomorphism, and hence E @ k = O.
Lemma 4.17 now shows that E = O. This concludes the proof of the syzygy
theorem.
Remark.
The only place in the proof where we used that k is a field is in the
proof of Theorem 4. 16 when we picked homogeneous elements vI ' ... , Vn in M
whose residue classes mod 1M form a basis of M/IM over A/IA. Hilbert's
theorem can be generalized by making the appropriate hypothesis which allows
us to carry out this step, as follows.
Theorem 4.18.
Let R be a commutative localringand let A = R[xI' .. . , xr ]
be the polynomial ring in I' variables. Let M be a gradedfinite module over A,
projective over R. Let
0-> K -> Lr - I -> . .. -> Lo -> M -> 0
be an exact sequence of graded homomorphisms of graded modules such that
Lo, .. . , L, _ I arefinite free. Then K is finite free.
Proof
Replace k by R everywhere in the proof of the Hilbert syzygy
theorem. We use the fact that a finite projective module over a local ring is free.
Not a word needs to be changed in the above proof with the following exception.
We note that the projectivity propagates to the kernels and cokernels in the
given resolution. Thus F in the statement of Theorem 4.16 may be assumed
projective, and each graded component is projective. Then F/I F is projective
over A/I A = R, and so is each graded component.
Since a finite projective
module over a local ring is free,and one gets the freeness by lifting a basis from the
residue class field, we may pick V b .. . • Vn homogeneous exactly as we did in the
proof of Theorem 4.16. This concludes the proof.

864
FINITE FREE RESOLUTIONS
EXERCISES
XXI, Ex
For exercises I through 4 on the Koszul complex, see [No 68], Chapter 8.
1. Let 0 ~ M ' ~ M ~ M" ~ 0 be an exact sequence of A-modules . Show that tensoring
with the Koszul complex K(x) one gets an exact sequence of complexes, and therefore
an exact homology sequence
o~ HrK(x; M') ~ HrK(x; M) ~ HrK(x; M") ~
.
. . . ~ HpK(x; M') ~ H~(x; M) ~ HpK(x; M") ~
.
. . . ~ HoK(x; M') ~ HoK(x; M) ~ HoK(x; M") ~ 0
2. (a) Show that there is a unique homomorphism of complexes
f : K(x; M) ~ K(XI"
' "
xr-I; M)
such that for v E M:
{
e. II .• • II e, @ x v
if ip = r
j, (e;
II • . . II e, @ v) =
/1
/p
r
Pip
e.
II •• • II e·@v
if ip = r .
'I
Ip
(b) Show thatfis injective if .r, is not a divisor of zero in M .
(c) For a complex C, denote by C(- I) the complex shifted by one place to the left,
so C(-I)n =
Cn- 1 for all n. Let M = M/xrM. Show that there is a unique
homomorphism of complexes
g: K(xI "
' "
Xr-l' 1; M) ~ K(Xl"
' "
Xr-l; M)(-I)
such that for v E M:
{
ei l II •.• II e,
I @ v
if ip = r
9 (e·
II • • • II C
@ v) =
e:
P
/1
/p
0
if ip < r .
(d) If x, is not a divisor of 0 in M, show that the following sequence is exact:
f
9
-
o~ K(x; M) ~ K(x 1, • • • , Xr-I, I; M) ~ K(x l , •• • , xr- 1; M)(-I) ~ O.
Using Theorem 4.5(c), conclude that for all p ~ 0, there is an isomorphism
HpK(x; M) ~ HpK(xt> . . . , Xr-l ; M).
3. Assume A and M Noetherian. Let I be an ideal of A. Let at, . .. , ak be an M-regular
sequence in I . Show that this sequence can be extended to a maximal M-regular
sequence al "
. . , aq in I, in other words an M-regular sequence such that there is
no M-regular sequence aI' . . . , aq+ I in I .
4. Again assume A and M Noetherian . Let I = (xI' . .. , xr) and let ai' . . . , aq be a
maximal M-regular sequence in I. Assume 1M =1= M. Prove that
Hr _qCx; M)
=1= 0 but Hp(x ; M) = 0 for p > r - q.
[See [No 68], 8.5 Theorem 6. The result is similar to the result in Exercise 5, and
generalizes Theorem 4.5(a). See also [Mat 80], pp. 100-103. The result shows that

XXI, Ex
EXERCISES
865
all maximal M-regular sequences in M have the same length , which is called the
I-depthof M and is denoted by depth/M). For the proof, let s be the maximal integer
such that HsK(x; M) "* O. By assumption, Ho(x; M) = M /IM "* 0, so sexists.
We have to prove that q + s = r. First note that if q = 0 then s = r. Indeed, if
q = 0 then every element of I is zero divisor in M, whence I is contained in the
union of the associated primes of M , whence in some associated prime of M . Hence
Hr(x; M) "* O.
Next assume q > 0 and proceed by induction . Consider the exact sequence
O~ M~ M~M/ajM~ 0
where the first map is meal) ' Since I annihilates Hp(x; M) by Theorem 4.5(c) , we
get an exact sequence
o~ H/x; M) ~ Hp(x; M /a\M) ~ Hp_'(x ; M) ~ O.
Hence Hs+ l(X;M /a\M) "* 0, but Hp(x;M /a,M) = 0 for p ~ s + 2. From the hypothesis
that a j, . . . , aq is a maximal M-regular sequence , it follows at once that a2, .. . , aq
is maximal M/a,M-regular in I, so by induction , q -
1 = r -
(s + 1) and hence
q + s = r, as was to be shown .]
5. The following exercise combines some notions of Chapter XX on homology , and
some notions covered in this chapter and in Chapter X, §5. Let M be an A-module.
Let A be Noetherian, M finite module over A, and I an ideal of A such that 1M # M.
Let r be an integer ~ I. Prove that the following conditions are equivalent :
(i) Exe(N, M) = 0 for all i < rand all finite modules N such that supp(N) c ?1 (f) .
(ii) Exti(A/I, M) = 0 for all i < r.
(iii) There exists a finite module N with supp(N) = ?1(l) such that
Exe(N, M) = 0
for all i < r.
(iv) There exists an M-regular sequence ai' . . . , a, in I .
[Hint:
(i) => (ii) => (iii) is clear. For (iii) => (iv), first note that
o= Exto(N, M) = Hom(N, M).
Assume supp(N) = ?1(l ). Find an M-regular element in I. If there is no such element,
then I is contained in the set of divisors of 0 of M in A, which is the union of the as-
sociated primes. Hence I c; P for some associated prime P. This yields an injection
A/PcM,so
By hypothesis, N; # 0 so Np/PNp # 0, and Np/PNp is a vector space over Ap/PA p,
so there exists a non-zero Ap/PAp homomorphism
so HomAp(Np, Mp) # 0, whence Hom(N, M) # 0, a contradiction. This proves the
existence of one regular element al •

866
FINITE FREE RESOLUTIONS
Now let M t = M/atM. The exact sequence
yields the exact cohomology sequence
XXI, Ex
so Exti(N, M/atM) = 0 for i < r - 1. By induction there exists an Mt-regular se-
quence a2' .. ., a, and we are done.
Last, (iv) ~ (i). Assume the existence of the regular sequence. By induction,
Exe(N, atM) = 0 for i < r - 1. We have an exact sequence for i < r:
o-+ Exe(N, M) ~ Exe(N, M)
But supp(N) =
~(ann(N»
C
~(l), so I C rad(ann(N», so at is nilpotent on N.
Hence at is nilpotent on Exti(N , M), so Exti(N , M) = O. Done.) See Matsumura's
[Mat 70), p. 100, Theorem 28. The result is useful in algebraic geometry, with for
instance M = A itself. One thinks of A as the affine coordinate ring of some variety,
and one thinks of the equations a, = 0 as defining hypersurface sections of this variety,
and the simultaneous equations at = . . . = a, = 0 as defining a complete intersection.
The theorem gives a cohomological criterion in terms of Ext for the existence of such
a complete intersection.

APPENDIX 1
The Transcendence of
e and π
The proof which we shall give here follows the classical method of Gelfond 
and Schneider, properly formulated. It is based on a theorem concerning values 
offunctions satisfying differential equations,and it had been recognizedforsome 
time that such values are subject to severe restrictions, in various contexts. 
Here, we deal with the most general algebraic differential equation.
We shall assume that the reader is acquainted with elementary facts con-
cerning functions of a complex variable. Let f be an entire function (i.e. a 
function which is holomorphic on the complex plane). For our purposes, we 
say f is of order ~ p if there exists a number C > 1such that for all large R we 
have
If(z)1 ~ CRP 
whenever 1z I ~ R. A meromorphic function is said to be of order ~ p if it is a 
quotient of entire functions of order ~ p.
Theorem. Let K be afinite extension ofthe rational numbers. Let f l' 
, fN
be meromorphic functions of order ~ p. Assume that the field K(fl , 
, fN)
has transcendence degree ~ 2 over K, and that the derivative D = djdz maps 
the ring K[fl' .. . , fN ] into itself. Let WI' . .. , Wm be distinct complex numbers 
not lying among the poles of the /;, such that
/;(WJE K 
for all i = 1, .. . , N and v = 1, .. . , m. Then m ~ lOp[K :Q].
Corollary 1. (Hermite-Lindemann) , If a is algebraic (over Q) and =1= 0, 
then e' is transcendental. Hence 1t is transcendental.
867

868
THE TRANSCENDENCE OF e AND 1T
APPENDIX 1
Proof
Suppose that a and ea are algebraic. Let K = Q(a, ea). The two
functions z and e
Z are algebraically independent over K (trivial), and the ring
K[z, e"] is obviously mapped into itself by the derivative. Our functions take on
algebraic values in K at a, 2a, . .. , ma for any m, contradiction. Since e2ni = 1,
it follows that 27Ci is transcendental.
Corollary 2.
(Gelfond-Schneider). If a is algebraic
:1= 0, I and if P is
algebraic irrational, then aP = ePIOg2 is transcendental.
Proof
We proceed as in Corollary 1, considering the functions eP1and e'
which are algebraically independent because Pis assumed irrational. We look
at the numbers log a, 2 log a, . . . , m log a to get a contradiction as in Corollary 1.
Before giving the main arguments proving the theorem,westatesome lemmas.
The first two, due to Siegel, have to do with integral solutions of linear homo-
geneous equations.
Lemma 1.
Let
be a system oflinear equations with integercoefficients aij, and n > r. Let A
be a number such that IaijI ~ A for all i, j . Then there exists an integral,
non-trivialsolution with
Proof
We view our system of linear equations as a linear equation
L(X) = 0, where L is a linear map, L: z<n) -> zr: determined by the matrix of
coefficients. If B is a positive number, we denote by z<n)(B) the set of vectors X
in z<n) such that IX I ~ B (where IX I is the maximum of the absolute values
of the coefficients of X). Then L maps z<n)(B) into Z<r)(nBA). The number of
elements in z(n)(B) is ~ B" and ~ (2B + It. We seek a value of B such that
there will be two distinct elements X, Y in z(n)(B) having the same image,
L(X) = L(Y). For this, it will suffice that B" > (2nBA)', and thus it will suffice
that
B = (2nA)'/(n-r).
We take X -
Y as the solution of our problem.
Let K be a finite extension of Q, and let I K be the integral closure of Z in K.
From Exercise 5 of Chapter IX, we know that I K is a free module over Z, of
dimension [K : Q].
We view K as contained in the complex numbers. If

APPENDIX 1
THE TRANSCENDENCE OF e AND 7T
869
rt. E K,a conjugate of rt. will be taken to be an element co;where a is an embedding
of K in C. By the size ofa set ofelements of K we shall mean the maximum of the
absolute values of all conjugates of these elements.
By the size of a vector X = (x I ' .. . , x n) we shall mean the size of the set of its
coordinates.
Let WI"' "
WM be a basis of l x over Z. Let rt. E Ix, and write
Let W 'I ' .. . , w~ be the dual basis of WI' • .. , WM with respect to the trace. Then
we can express the (Fourier) coefficients aj of rt. as a trace,
aj = Tr(awj).
The trace is a sum over the conjugates. Hence the size of these coefficients is
bounded by the size of a, times a fixed constant, depending on the size of the
elements wj .
Lemma 2.
Let K be afinite extensionofQ. Let
be a system of linear equations with coefficients in Ix' and n > r. Let A be a
number such that size(ai) ~ A, for all i, j. Then there exists a non-trivial
solution X in Ix suchthat
where C I , C2 are constants depending only on K.
Proof
Let WI' . . . , WM be a basis of l x over Z. Each Xj can be written
Xj =
~jIWI + ... + ~jMWM
with unknowns ~j;.. Each aij can be written
with integers aij;. E Z. Ifwe multiply out the rt.ijXj' we find that our linear equa-
tions with coefficients in I x are equivalent to a system of rM linear equations in
the nM unknowns ~j)., with coefficients in Z, whose size is bounded by CA, where
C is a number depending only on M and the size of the elements W A' together with
the products W ..W" , in other words where C depends only on K . Applying
Lemma 1,we obtain a solution in terms of the
~j'" and hence a solution X in Ix,
whose size satisfies the desired bound.

870
THE TRANSCENDENCE OF e AND 1T'
APPENDIX 1
The next lemma has to do with estimates of derivatives. By the size of a
polynomial with coefficients in K, we shall mean the size of its set of coefficients.
A denominator for a set of elements of K will be any positive rational integer
whose product with every element of the set is an algebraic integer. We define in
a similar way a denominator for a polynomial with coefficients in K.
We
abbreviate "denominator" by den.
Let
be a polynomial with complex coefficients, and let
be a polynomial with real coefficients
~O .
We say that Q dominates P if
I(X(v) I ::s; {3(V) for all (v). It is then immediately verified that the relation of domi-
nance is preserved under addition, multiplication, and taking partial derivatives
with respect to the variables TI, ... , TN'
Lemma 3.
Let K be offinite degree over Q. Let fl' . .. , fN be functions,
holomorphic on a neighborhood of a point WEe, and assume that D = dldz
maps the ring K[fl' . .. , fN] into itself. Assume that };(w)E Kfor all i. Then
there exists a numberC I havingthefollowing property. Let P(TI, . .. , TN) be
a polynomial withcoefficients in K, ofdegree ~ r. Ifwe set f
= PUI" '"
fN),
then we have,for all positive integersk,
size(D'J(w)) ~ size(P)rkk! q+r
Furthermore, there is a denominator for D'J(w) bounded by den(P)C~+r.
Proof
There exist polynomials Pj(TI, .. . , TN) with coefficients in K such
that
Let h be the maximum of their degrees. There exists a unique derivation 15 on
K[TI, .. . , TN] such that Dr; = Pi(TI, . . . , TN)' For any polynomial P we have
N
D(P(TI, . . ., TN)) = L(DjP)(TI , . .. , TN) ' P/TI, . . . , TN),
i= I
where DI' ... , DN are the partial derivatives. The polynomial P is dominated by
size(P)(1 + TI + ... + TN)',
and each P, is dominated by size(P;)(1 + TI + ...+ TN)h. Thus DPis dominated
by

APPENDIX 1
THE TRANSCENDENCE OF e AND 7T
871
Proceeding inductively, one sees that Dkp is dominated by
size(P)C~,J<k!(l + TI . .. + TNy+kh.
Substituting values fi(w) for 7;, we obtain the desired bound on DkJ(w). The
second assertion concerning denominators is proved also by a trivial induction.
We now come to the main part of the proof of our theorem. Let J,9 be two
functions among JI'..., IN which are algebraically independent over K. Let
r be a positive integer divisible by 2m. We shall let r tend to infinity at the end
of the proof.
Let
r
F = L bijtgi
i.i =1
have coefficients bijin K. Let n = r 2/2m. We can select the bijnot all equal to 0,
and such that
for°~ k < n and v = 1, . .. , m. Indeed, we have to solve a system of mn linear
equations in r 2 = 2mn unknowns. Note that
mn
= 1.
2mn - mn
We multiply these equations by a denominator for the coefficients. Using the
estimate of Lemma 3, and Lemma 2, we can in fact take the bij to be algebraic
integers, whose size is bounded by
O(rnn! q +r) ~ 0(n2n)
for n --+ 00.
Since J, 9 are algebraically independent over K , our function F is not
identically zero. We let 5 be the smallest integer such that all derivatives of F
up to order 5 -
1 vanish at all points WI' . . . , wm , but such that DSF does not
vanish at one of the w, say WI ' Then 5 ~ n. We let
y = DSF(w I ) i= 0.
Then y is an element of K, and by Lemma 3, it has a denominator which is
bounded by O(CD for 5 --+ 00 . Let c be this denominator. The norm of cy from
K to Q is then a non-zero rational integer. Each conjugate of cy is bounded by
0(5 5S). Consequently, we get
(1)

872
THE TRANSCENDENCE OF e AND 1T
APPENDIX 1
where IyIis the fixed absolute value of y,which will now be estimated very well by
global arguments.
Let () be an entire function of order ~ p, such that Of and (}gare entire, and
(}(w 1) =I- O. Then (}2rF is entire. We consider the entire function
H(z) =
~(z)2rF(z) .
Il (z -
wv)S
v = 1
Then H(w1) differs from DSF(w 1) by obvious factors, bounded by C~s!. By the
maximum modulus principle, its absolute value is bounded by the maximum of
H on a large circle of radius R. Ifwe take R large, then z - w, has approximately
the same absolute value as R, and consequently, on the circle of radius R, H(z)
is bounded in absolute value by an expression of type
We select R =
Sl /2P . We then get the estimate
We now let r tend to infinity. Then both nand s tend to infinity. Combining this
last inequality with inequality (1), we obtain the desired bound on m. This
concludes the proof.
Of course, we made no effort to be especially careful in the powers of s
occurring in the estimates, and the number 10 can obviously be decreased by
exercising a little more care in the estimates.
The theorem we proved is only the simplest in an extensive theory
dealing with problems of transcendence degree. In some sense, the theorem is
best possible without additional hypotheses. For instance, ifP(t) is a polynomial
with integer coefficients, then eP(I) will take the value 1at all roots of P, these being
algebraic. Furthermore, the functions
t
t2
,n
t, e, e , ... , e
are algebraically independent, but take on values in Q(e) for all integral values
of t.
However, one expects rather strong results of algebraic independence to hold.
Lindemann proved that ifrx1, •. • , a; arealgebraic numbers, linearly independent
overQ, then
are algebraically independent.

APPENDIX 1
THE TRANSCENDENCE OF e AND tt
873
More generally, Schanuel has made the following conjecture: If IX!, . .. , IX"
are complex numbers, linearly independent over Q, then the transcendence
degree of
CL l ' ... , CLn , eat, . . . , ea."
should be ~ n.
From this one would deduce at once the algebraic independence of e and n
(looking at 1, Lni, e, eZlti ) , and all other independence statements concerning the
ordinary exponential function and logarithm which one feels to be true, for
instance, the statement that n cannot lie in the field obtained by starting with the
algebraic numbers,adjoining values of the exponential funct ion, taking algebraic
closure, and iterating these two operations. Such statements have to do with
values of the exponential function lying in certain fields of transcendence degree
< n, and one hopes that by a suitable deepening of Theorem 1, one will reach
the desired results.

APPENDIX 2
Some Set Theory
§1.
DENUMERABLE SETS
Let n be a positive integer. Let J n be the set consisting of all integers k,
1 ~ k ~ n. IfS is a set, we say that S has nelements if there is a bijection between
Sand Jn' Such a bijection associates with each integer k as above an element of S,
say k H ai , Thus we may use J, to "count" S. Part of what we assume about the
basic facts concerning positive integers is that ifS has n elements, then the integer
n is uniquely determined by S.
One also agrees to say that a set has 0 elements if the set is empty.
We shall say that a set S isdenumerable if there exists a bijection of S with the
set of positive integers Z +. Such a bijection is then said to enumerate the set S.
It is a mapping
which to each positive integer n associates an element of S, the mapping being
injective and surjective.
If D is a denumerable set, and J: S --+ D is a bijection of some set S with D,
then S is also denumerable. Indeed, there is a bijection g : D --+ Z +, and hence
g 0 J is a bijection of S with Z +.
Let T be a set. A sequence of elements of T is simply a mapping of Z + into T.
If the map is given by the association n H
Xn, we also write the sequence as
{Xn}n~ 1, or also {x., Xl ' . ..}. For simplicity, we also write {x.}for the sequence.
Thuswe think of the sequence as prescribing a first, second, ... , n-th element of
T. We use the same braces for sequences as for sets, but the context will always
make our meaning clear.
875

876
SOME SET THEORY
APPENDIX 2
Examples.
The even positi ve integers may be viewed as a sequence {x n} if
we put x, = 2n for n = 1,2, . . . . The odd positive integers may also be viewed
as a sequence {Yn} if we put Yn = 2n -
I for n = 1, 2, . . . . In each case, the
sequence gives an enumeration of the given set.
We also use the word sequencefor mappings of the natural numbers into a set,
thus allowing our sequences to start from 0 instead of 1. If we need to specify
whether a sequence starts with the O-th term or the first term, we write
{xn}n ~O
or
{xn}n ~ I
according to the desired case. Unless otherwise specified, however, we always
assume that a sequence will start with the first term. Note that from a sequence
{xn } n~ O we can define a new sequence by letting Yn =
Xn - I for n ~ 1. Then
YI = xo,Y2 =
Xl ' . · .. Thus there is no essential difference between the two
kinds of sequences.
Given a sequence {xn}, we call x, the n-th term of the sequence. A sequence
may very well be such that all its terms are equal. For instance, if we let x, = 1
for all n ~ 1, we obtain the sequence {I, 1, 1, . ..}. Thus there is a difference
between a sequence of elements in a set T, and a subset of T. In the example just
given, the set of all terms of the sequence consists of one element, namely the
single number 1.
Let {XI' X2""} be a sequence in a set S. Bya subsequence we shall mean a
sequence {xn" xn2,. . .} such that nl < n2 < .... For instance, if {xn} is the
sequence of positive integers, x, = n,the sequence of even positive integers {X2n}
is a subsequence.
An enumeration of a set S is of course a sequence in S.
A set is finite if the set is empty, or if the set has n elements for some positive
integer n. If a set is not finite, it is called infinite.
Occasionally, a map of I n into a set T will be called a finite sequence in T.
A finite sequence is written as usual,
{XI" ' " xn }
or
{X;}i=I .....n ·
When we need to specify the distinction between finite sequences and maps of
Z + into T, we call the latter infinite sequences. Unless otherwise specified, we
shall use the word sequence to mean infinite sequence.
Proposition 1.1.
Let D be an infinite subsetofZ", ThenD is denumerable.
and infact there is a unique enumeration ofD. say {kl' k2, ...} such that
k I < k2 < ... < k; < k; + I < ... .
Proof
We let k l be the smallest element of D. Suppose inductively that we
have defined k, < .. . < kn , in such a way that any element k in D which is not
equal to k l , • • . , k; is > k. , We define kn + I to be the smallest element of D which
is > k. , Then the map n 1---+ k; is the desired enumeration of D.

APPENDIX 2
SOME SET THEORY
877
Corollary 1.2.
Let S be a denumerable set and D an infinite subset of S.
Then D is denumerable.
Proof
Given an enumeration of S, the subset D corresponds to a subset of
Z + in this enumeration. Using Proposition 1.1,we conclude that we can enumer-
ate D.
Proposition 1.3.
Every infiniteset contains a denumerable subset.
Proof
Let S be an infinite set. For every non-empty subset T of S, we
select a definite element aT in T. We then proceed by induction. We let X I be the
chosen element as. Suppose that we have chosen X I ' . . . , x, having the property
that for each k = 2, .. . , n the element Xk is the selected element in the subset
which is the complement of {X I"
' " xi: d. We let Xn + I be the selected element
in the complement of the set {XI "
' " x.} . By induction, we thus obtain an
association n 1---+ x, for all positive integers n, and since x,
=1= Xk for all k < n it
follows that our association is injective, i.e. gives an enumeration of a subset of S.
Proposition 1.4.
Let D be a denumerable set, and f: D -+ S a surjective
mapping. Then S is denumerableorfinite.
Proof
For each YES, there exists an element X y ED such that f(xy ) = y
because f is surjective. The association y f---+ xy is an injective mapping of S
into D, because if
y, Z ESand
xy = Xz
then
Let g(y) = x y. The image of 9 is a subset of D and D is denumerable. Since 9
is a bijection between S and its image, it follows that S is denumerable or finite.
Proposition 1.5.
Let Dbeadenumerableset. Then D x D(thesetofallpairs
(x, y) with x, y E D) is denumerable.
Proof.
There is a bijection between D x Dand Z + x Z + , so it will suffice to
prove that Z + x Z + is denumerable. Consider the mapping of Z + x Z + -+ Z +
given by
It is injective, and by Proposition 1.1, our result follows .
Proposition 1.6.
Let {DI , D2 , •• •} bea sequence ofdenumerable sets. Let S
be the union ofall sets D, (i = 1,2, . . .). Then S is denumerable.

878
SOME SETTHEORY
APPENDIX 2
Proof
For each i = 1,2, . . . we enumerate the elements of Db as indicated
in the following notation :
D I :
{XII' X I Z , X!3' .. . }
Dz:
{XZI ' XZ Z ' XZ3 ' · · ·}
The map f :Z + x Z + --+ D given by
f(i,j) = xij
is then a surjective map of Z + x Z + onto S. By Proposition 1.4, it follows that
S is denumerable.
Corollary 1.7.
Let F bea non-emptyfinite set and Dadenumerable set. Then
F x D is denumerable. If SI' Sz, . . . are a sequence of sets, each of which is
finite or denumerable, then the unionSIUSZ U . .. is denumerable orfinite.
Proof
There isan injection of F into Z + and a bijection of Dwith Z ". Hence
there is an injection of F x Z + into Z + x Z + and we can apply Corollary 1.2
and Proposition 1.6 to prove the first statement. One could also define a sur-
jective map of Z + x Z + onto F x D. (Cf. Exercises 1 and 4.) As for the second
statement, each finite set iscontained in some denumerable set,so that the second
statement follows from Proposition 1.1 and 1.6.
For convenience, we shall say that a set is countable if it is either finite or
denumerable.
§2.
ZORN'S LEMMA
In order to deal efficiently with infinitely many sets simultaneously, one needs
a special property. To state it, we need some more terminology.
Let S be a set. An ordering (also called partial ordering) of S is a relation,
written X ~ y,among some pairs of elements ofS, having the following properties.
ORD 1.
We have X ~ x.
ORD 2.
If X ~ Y and y ~ z then x ~ z.
ORD 3.
If x ~ y and y ~ x then x = y.

APPENDIX 2
SOME SET THEORY
879
We sometimes write y ~ x for x ~ y. Note that wedon't require that the relation
x ~ y or y ~ x hold for every pair of elements (x, y) of S. Some pairs may not be
comparable. Ifthe ordering satisfies this additional property, then we say that it
is a total ordering.
Example 1.
Let G be a group. Let S be the set of subgroups. If H, H' are
subgroups of G, we define
H~H '
if H is a subgroup of H'. One verifies immediately that this relation defines an
ordering on S. Given two subgroups H, H' of G, we do not necessarily have
H ~ H' or H' ~ H.
Example 2.
Let R be a ring, and let S be the set ofleft ideals of R. We define
an ordering in S in a way similar to the above, namely if L, L' are left ideals of R,
we define
L ~ L'
if L c L'.
Example 3.
Let X be a set, and S the set of subsets of X. If Y,Z are subsets
of X, we define Y ~ Z if Y is a subset of Z. This defines an ordering on S.
In all these examples, the relation of ordering is said to be that of inclusion.
In an ordered set, if x ~ y and x
=1= y we then write x < y.
Let A be an ordered set, and B a subset. Then we can define an ordering on B
by defining x ~ y for x, y E B to hold if and only if x ~ yin A. We shall say that
Ro is the ordering on B induced by R, or is the restriction to B of the partial
ordering of A.
Let S be an ordered set. Bya least element of S (or a smallest element) one
means an element a ES such that a ~ x for all XES. Similarly, by a greatest
element one means an element b such that x ~ b for all XES.
By a maximal element m of S one means an element such that if XES and
x ~ m,then x = m. Note that a maximal element need not be a greatest element.
There may be many maximal elements in S, whereas if a greatest element exists,
then it is unique (proof ?).
Let S be an ordered set. We shall say that S is totally ordered if given x, yES
we have necessarily x ~ y or y ~ x.
Example 4.
The integers Z are totally ordered by the usual ordering. So
are the real numbers.
Let S be an ordered set, and T a subset. An upper bound of T (in S) is an
element b E S such that x ~ b for all x E T. A least upper bound of T in S is an
upper bound b such that, if c is another upper bound, then b ~ c. We shall say

880
SOME SET THEORY
APPENDIX 2
that S is inductively ordered if every non-empty totally ordered subset has an
upper bound.
We shall say that S is strictly inductively ordered if every non-empty totally
ordered subset has a least upper bound.
In Examples 1, 2, 3, in each case, the set is strictly inductively ordered. To
prove this, let us take Example 1. Let T be a non-empty totally ordered subset
of the set of subgroups ofG. This means thatifH,H' E T,then H c H' or H' c H.
Let V be the union of all sets in T. Then :
1. V is a subgroup. Proof: If x, y E V, there exist subgroups H, H' E T
such that x EHand y E H'. If, say, H c H', then both x, y EH' and hence
xy EH'.
Hence xy E U.
Also, x- 1 EH', so x- 1 E U.
Hence V is a
subgroup.
2. V is an upper bound for each element of T. Proof:
Every HE T is con-
tained in V, so H ;£ V for all HE T.
3. V is a least upper bound for T. Proof:
Any subgroup of G which
contains all the subgroups HE T must then contain their union U.
The proof that the sets in Examples 2, 3 are strictly inductively ordered is
entirely similar.
We can now state the property mentioned at the beginning of the section.
Zorn's Lemma.
Let S be a non-empty inductively ordered set.
Then there
exists a maximal element in S.
As an example of Zorn's lemma, we shall now prove the infinite version of a
theorem given in Chapters 1, §7, and XIV, §2, namely:
Let R be an entire, principal ring and let E be afree module over R. Let F be a
submodule. Then F isfree. Infact, if {ViLe! is a basis for E, and F # {O},
then there exists a basis for F indexed by a subset of I.
Proof
For each subset J of I we let EJ be the free submodule of E generated
by all Vj,jEJ, and we let F J = EJ n F. We let S be the set of all pairs (F J , w)
where J is a subset of I, and w : J' -. FJ is a basis of FJ indexed by a subset J' of J.
We write wj instead of w(j) for j EJ' . If (F], w) and (Fx' u) are such pairs, we
define (Fj , w) ;£ (FK,u) if J c K, if J' c K', and if the restriction of u to J' is
equal to w. (In other words, the basis u for Fx is an extension of the basis w for
FJ .) This defines an ordering on S, and it is immediately verified that S is in fact
inductively ordered, and non-empty (say by the finite case of the result). We can
therefore apply Zorn's lemma. Let (Fj, w) be a maximal element. We contend
that J = I (this will prove our result). Suppose J # I and let k EI but k ¢ J. Let
K = J u {k}. If

APPENDIX 2
SOME SET THEORY
BB1
then (F K ' w) is a bigger pair than (F j, w) contradicting the maximality assump-
tion. Otherwise there exist elements of F K which can be written in the form
with some y E EJ and c E R, c =f. O. The set of all elements c E R such that there
exists y E EJ for which CVk + Y E F is an ideal. Let a be a generator of this ideal,
and let
be an element of F, with y E EJ. If Z E FK then there exists b E R such that
Z -
bWk E EJ . But z - bw, E F, whence z -
bWk E FJ . It follows at once that
the family consisting of wj (j E J) and Wk is a basis for FK' thus contradicting the
maximality again. This proves what we wanted.
Zorn's lemma could be just taken as an axiom of set theory. However, it is
not psychologically completely satisfactory as an axiom, because its statement
is too involved, and one does not visualize easily the existence of the maximal
element asserted in that statement. We show how one can prove Zorn's lemma
from other properties of sets which everyone would immediately grant as ac-
ceptable psychologically.
From now on to the end of the proof of Theorem 2.1, we let A be a non-
empty partially ordered and strictly inductively ordered set. We recall that
strictly inductively ordered means that every nonempty totally ordered subset
has a least upper bound. We assume given a map f :A -+ A such that for all
x E A we have x ~ f(x). We could call such a map an increasing map.
Let a E A. Let B be a subset of A. We shall say that B is admissible if:
1. B contains a.
2. We have f(B) c
B.
3. Whenever T is a non-empty totally ordered subset of B, the least upper
bound of T in A lies in B.
Then B is also strictly inductively ordered, by the induced ordering of A. We
shall prove:
Theorem 2.1.
(Bourbaki).
Let A be a non-empty partially ordered and
strictly inductively ordered set. Let f :A -+ A be an increasing mapping.
Then there exists an element Xo E A such that f(xo) = Xo '
Proof.
Suppose that A were totally ordered. By assumption, it would have
a least upper bound bE A, and then
b ~ f(b) ~ b,

882
SOME SET THEORY
APPENDIX 2
so that in this case, our theorem is clear. The whole problem is to reduce the
theorem to that case. In other words, what we need to find is a totally ordered
admissible subset of A.
If we throw out of A all elements x E A such that x is not
~ a, then what
remains is obviously an admissible subset. Thus without loss of generality, we
may assume that A has a least element a, that is a ~ x for all x E A.
Let M be the intersection of all admissible subsets of A. Note that A itself is
an admissible subset, and that all admissible subsets of A contain a, so that M is
not empty. Furthermore, M is itself an admissible subset of A. To see this, let
x E M. Then x is in every admissible subset, so f(x) is also in every admissible
subset, and hence f(x) E M. Hence f(M) c M. If T is a totally ordered non-
empty subset of M, and b is the least upper bound of T in A, then b lies in every
admissible subset of A, and hence lies in M. It follows that M is the smallest
admissible subset of A, and that any admissible subset of A contained in M is
equal to M.
We shall prove that M is totally ordered, and thereby prove Theorem 2.1.
[First we make some remarks which don't belong to the proof, but will help
in the understanding of the subsequent lemmas. Since a EM, we see that
f(a) E M, f
0 f(a) E M, and in general f"(a) E M. Furthermore,
a ~ f(a) ~ f2(a) ~ .. . .
If we had an equality somewhere, we would be finished, so we may assume that
the inequalities hold. Let Do be the totally ordered set {fn(a)}n~o . Then Do
looks like this:
a < f(a) < pCa) < .. . < f"Ca) < . .. .
Let al be the least upper bound of Do. Then we can form
in the same way to obtain D l' and we can continue this process, to obtain
It is clear that Db D 2 , • •• are contained in M. If we had a precise way of ex-
pressing the fact that we can establish a never-ending string of such denumerable
sets, then we would obtain what we want. The point is that we are now trying to
prove Zorn's lemma, which is the natural tool for guaranteeing the existence of
such a string. However, given such a string, we observe that its elements have
two properties: If c is an element of such a string and x < c, then f(x) ~ c.
Furthermore, there is no element between c and fCc), that is ifx is an element of
the string, then x ~ c or fCc) ~ x. We shall now prove two lemmas which show
that elements of M have these properties.]

APPENDIX 2
SOME SET THEORY
883
Let c EM. We shall say that c is an extreme point of M if whenever x E M and
x < c, then f(x) ~ c. For each extreme point c EM we let
Me = set of XE M
such that
x ~ c
or
f(c) ~ x.
Note that Me is not empty because a is in it.
Lemma 2.2.
We have Me = M for every extreme point c ofM.
Proof
It will suffice to prove that Meis an admissible subset. Let x EMe.
If X < c then f(x) ~ c so f(x) EMe. If X = c then f(x) = f(c) is again in Me·
If f(c) ~ x, then f(c) ~ x ~ f(x), so once more f(x) E Me. Thus we have
proved that f(Me) C Me.
Let T be a totally ordered subset of Me and let b be the least upper bound of
Tin M. If all elements x E T are ~ c, then b ~ c and bE Me. If some x E Tis
suchthatf(c) ~ x,thenf(c) ~ x ~ b,andsobisinMe• This proves ourlemma.
Lemma 2.3.
Every element of M is an extreme point.
Proof
Let E be the set of extreme points of M. Then E is not empty because
a EE. It will suffice to prove that E is an admissible subset. We first prove that
fmapsEintoitself. Let c e E. LetxEMandsupposex < f(c). Wemustprove
thatf(x) ;5;f(c). By Lemma 2.2, M = Mc' and hence we have x < c, or x = c,
or f(c) ~ x. This last possibility cannot occur because x < f(c). If x < c
then
f(x) ~ c ~ f(c).
If x = c then f(x) = f(c), and hence f(E) c E.
Next let T be a totally ordered subset of E. Let b be the least upper bound
of T in M . We must prove that bEE. Let x E M and x < b. If for all c E T we
havef(c) ;5; x, then c ;5;f(c) ;5; x implies that x is an upper bound for T, whence
b ;5; x, which is impossible. Since M; = M for all c E E, we must therefore
have x ;5; c for some c E T. If x < c, thenf(x) ;5; c ;5; b, and if x = c, then
c = x < b.
Since c is an extreme point and M; = M, we get f(x) ;5; b. This proves that
bEE, that E is admissible, and thus proves Lemma 2.3.
We now see trivially that M is totally ordered. For let x, y EM. Then x is an
extreme point of M by Lemma 2, and y E M; so y ~ x or
x ~ f(x) ~ y,
thereby proving that M is totally ordered. As remarked previously, this con -
cludes the proof of Theorem 2.1.

884
SOME SET THEORY
APPENDIX 2
We shall obtain Zorn's lemma essentially as a corollary of Theorem 2.1.
We first obtain Zorn's lemma in a slightly weaker form.
Corollary 2.4.
Let A bea non-emptystrictly inductively ordered set. Then A
has a maximalelement.
Proof
Suppose that A does not have a maximal element. Then for each
x E A there exists an element yx E A such that x < yx- Let f: A ~ A be the map
such thatf(x) = Yx for all x EA. Then A , f satisfy the hypotheses of Theorem
2.1 and applying Theorem 2.1 yields a contradiction.
The only difference between Corollary 2.4 and Zorn's lemma is that in
Corollary 2.4, we assume that a non-empty totally ordered subset has a least
upper bound, rather than an upper bound. It is, however, a simple matter to
reduce Zorn's lemma to the seemingly weaker form of Corollary 2.4. We do
this in the second corollary.
Corollary 2.5. (Zorn's lemma).
Let S be a non-empty inductively ordered
set. Then S has a maximalelement.
Proof
Let A be the set of non-empty totally ordered subsets of S. Then A
is not empty since any subset of S with one element belongs to A. If X , YEA,
we define X ~ Y to mean X c
Y. Then A is partially ordered, and is in fact
strictly inductively ordered. For let T = {X i}iEI be a totally ordered subset of A.
Let
z= UX i •
iel
Then Z is totally ordered. To see this, let x, y E Z. Then x E Xi and y E X j for
some i,j E I . Since T is totally ordered, say Xi c X j • Then x, y E X j and since
X, is totally ordered, x ~ y or y ~ x. Thus Z is totally ordered, and is obviously
a least upper bound for T in A. By Corollary 2.4, we conclude that A has a
maximal element Xo- This means that X 0 is a maximal totally ordered subset of
S (non-empty). Let m be an upper bound for X 0 in S. Then m is the desired
maximal element of S. For if XES and m ~ x then Xo u {x} is totally ordered,
whence equal to X 0 by the maximality of Xo- Thus x E X 0 and x ~ m. Hence
x = m, as was to be shown.
§3.
CARDINAL NUMBERS
Let A, B be sets. We shall say that the cardinality of A is the same as the
cardinality ofB, and write
card(A) = card(B)
if there exists a bijection of A onto B.

APPENDIX 2
SOME SET THEORY
885
We say card(A) ~ card(B) if there exists an injective mapping (injection)
j :A -+ B. We also write card(B) ~ card(A) in this case. It is clear that if
card(A) ~ card(B) and card(B) ~ card(C), then card(A) ~ card(C).
Th is amounts to saying that a composite of injective mappings is injecti ve.
Similarly, if card(A) = card(B) and card(B) = card(C) then card(A) = card(C).
This amounts to saying that a composite of bijective mappings is bijective.
We clearly have card(A) = card(A). Using Zorn 's lemma , it is easy to show (see
Exercise 14) that
card(A) ~ card(B)
or
card(B) ~ card(A).
Let j: A -+ B be a surjective map ofa set A onto a set B. Th en
card(B) ~ card(A).
This is easily seen, because for each )' E B there exists an element x E A,
denoted by x}"such that j(xy) = y. Then the assoc iation y f-+ xy is an injective
mapping of B into A, whence by definition,card(B) ~ card(A).
Given two nonempty sets A , B we have card(A) ~ card(B) or card(B) ~ card(A).
This is a simple application of Zorn's lemma. We consider the family of pairs
(S,j) where S is a subset of A and j': S ~ B is an injective mapping. From the
existence of a maximal element, the assertion follows at once.
Theorem 3.1.
(Schroeder-Bernstein).
Let A , B be sets, and suppose that
card(A) ~ card(B), and card(B) ~ card(A). Then
card(A) = card(B).
Proof.
Let
I: A -+ Band
g: B -+ A
be injections. We separate A into two disjoint sets AI and A2 • We let AI consist
of all x E A such that, when we lift back x by a succession of inverse maps ,
x, g - I(X), .r 10g- l (X),
g-I 01 - 10g - l (X ), .. .
then at some stage we reach an element of A which cannot be lifted back to B by
g. We let A 2 be the complement of AI ' in other words, the set of x E A which can
be lifted back indefinitely, or such that we get stopped in B (i.e. reach an element
of B which has no inverse image in A by f). Then A = A I U A 2 ' We shall define
a bijection h of A onto B.
If x E A I ' we define h(x) = j(x).
If x E A 2 , we define
h(x) = g -I(X) = unique element y E B such
that
g(y) = x.
Then trivially, h is injecti ve. We must prove that h is surjective. Let b e B.
If, when we try to lift back b by a succession of maps
'" ,.r:' o o
1 ,_t :
0 e:' u j- I(b)

886
SOME SET THEORY
APPENDIX 2
we can lift back indefinitely, or if we get stopped in B, then g (b) belongs to Az
and consequently b = h(g(b)), so b liesin the imageof h. On the other hand, if we
cannot lift back b indefinitely, and get stopped in A, then f-l(b) is defined
(i.e., b is in the image of f), and f-l(b) lies in AI. In this case, b = h(f-I(b))
is also in the image of h, as was to be shown.
Next we consider theorems concerning sums and products of cardinalities.
We shall reduce the study of cardinalities of products of arbitrary sets to the
denumerable case, using Zorn's lemma. Note first that an infinite set A always
contains a denumerable set. Indeed, since A is infinite, we can first select an
element al E A, and the complement of {ad is infinite. Inductively, if we have
selected distinct elements ai' .. . , an in A, the complement of {ai, . . . , an} is
infinite, and we can select an + I in this complement. In this way, we obtain a
sequence of distinct elements of A, giving rise to a denumerable subset of A.
Let A be a set. Bya covering of A one means a set I' of subsets of A such that
the union
of all the elements of F is equal to A. We shall say that I' is a disjoint covering if
whenever C, C' E T, and C =F C', then the intersection of C and C' is empty.
Lemma 3.2.
Let A be an infinite set. Then there exists a disjoint covering of
A by denumerable sets.
Proof
Let S be the set whose elements are pairs (B, T) consisting of a
subset B of A, and a disjoint covering of B by denumerable sets. Then S is not
empty. Indeed, since A is infinite, A contains a denumerable set D, and the pair
(D, {D}) is in S. If (B, I') and (B', I") are elements of S, we define
(B, r) ~ (B', f')
to mean that B c B', and F c I". Let T be a totally ordered non-empty subset
of S. We may write T = {(Bj, fi)};eI for some indexing set I. Let
B = UBi
and
ieI
If C, C' E I', C =F C', then there exists some indices i, j such that C E F, and
C' E f j . Since T is totally ordered, we have, say,
Hence in fact, C, C' are both elements of f j , and hence C, C' have an empty
intersection. On the other hand, ifx E B, then x E B, for some i, and hence there
is some C E f i such that x E C. Hence I" is a disjoint covering of B. Since the

APPENDIX 2
SOME SET THEORY
887
elements of each F, are denumerable subsets of A, it follows that r is a disjoint
covering of B by denumerable sets, so (B, I') is in S, and is obviously an upper
bound for T. Therefore S is inductively ordered.
Let (M, <'1) be a maximal element of S, by Zorn's lemma. Suppose that
M
=1= A. If the complement of M in A is infinite, then there exists a denumerable
set D contained in this complement. Then
(M u D, <'1 u {D})
is a bigger pair than (M, <'1), contradicting the maximality of (M, <'1). Hence the
complement of M in A is a finite set F. Let Do be an element of <'1. Let
Then D1 is denumerable. Let <'1 1 be the set consisting of all elements of <'1, except
Do, together with D 1• Then <'1 1 is a disjoint covering of A by denumerable sets,
as was to be shown.
Theorem 3.3.
Let A be an infinite set, and let D be a denumerable set. Then
card(A x D) = card(A).
Proof
By the lemma, we can write
A = UD j
j E I
as a disjoint union of denumerable sets. Then
A x D = U(D j x D).
ieI
For each i E I, there is a bijection of D, x Don D, by Proposition 1.5. Since the
sets D, x D are disjoint, we get in this way a bijection of A x D on A, as desired.
Corollary 3.4.
IfF is afinite non-empty set, then
card(A x F) = card(A).
Proof
We have
card(A) ~ card(A x F) ~ card(A x D) = card(A).
We can then use Theorem 3.1 to get what we want.
Corollary 3.5.
Let A, B be non-empty sets, A infinite, and suppose
card(B) ~ card(A).

888
SOME SET THEORY
Then
card(A u B) = card(A).
APPENDIX 2
Proof
We can write Au B = Au C for some subset C of B, such that C
and A are disjoint. (We let Cbe the set of all elements of B which are not elements
of A.) Then card(C) ~ card(A). We can then construct an injection of Au C
into the product
Ax{l,2}
of A with a set consisting of 2 elements. Namely, we have a bijection of A with
A x {l} in the obvious way, and also an injection of C into A x {2}. Thus
card(A u C) ~ card(A x {l,2}).
We conclude the proof by Corollary 3.4 and Theorem 3.1.
Theorem 3.6.
Let A be an infinite set. Then
card(A x A) = card(A).
Proof
Let S be the set consisting of pairs (B, f) where B is an infinite subset
of A, and f is a bijection of B onto B x B. Then S is not empty because if D is
a denumerable subset of A, we can always find a bijection of Don D x D. If
(B,J) and (B',J') are in S, we define (B,J) ~ (B',J') to mean Be B', and
the restriction of I' to B is equal to f. Then S is partially ordered, and we con-
tend that S is inductively ordered. Let T be a non-empty totally ordered subset
of S, and say T consists of the pairs (Bi,f;) for i in some indexing set I . Let
M= UBi'
ie l
We shall define a bijection g: M -+ M x M. If x E M, then x lies in some Bi •
We define g(x) = };(x). This value };(x) is independent of the choice of Bi in
which x lies. Indeed, if x E B, for some j E I , then say
By assumption, B, c Bj , and fj(x) = };(x), so 9 is well defined. To show 9 is
surjective, let x, y E M and (x, y) E M x M.
Then x E B, for some i E I and
y E B/or somej E I. Again since Tis totally ordered, say (B;,};) ~ (Bj , fj) .Thus
B, c Bj , and x, y E Bj . There exists an element b e B, such that
h{b) = (x ,Y)EBj x Bj •
By definition, g(b) = (x, y), so 9 is surjective. We leave the proof that 9 is
injective to the reader to conclude the proof that 9 is a bijection. We then see

APPENDIX 2
SOME SET THEORY
889
that (M, g) is an upper bound for Tin S, and therefore that S is inductively
ordered.
Let (M, g) be a maximal element of S, and let C be the complement of Min A.
If card(C) ~ card(M), then
card(A) = card(M u C) = card(M)
by
Corollary
3.5,
and
hence
card(M) = card(A) .
Since
card(M) =
card(M x M) , we are done with the proof in this case. If
card(M) ~ card(C),
then there exists a subset M 1 of C having the same cardinality as M. We consider
(MuM 1) x (MuM 1)
= (M x M) u (M 1 x M) u (M x M I) u (M 1 x M 1) '
By the assumption on M and Corollary 3.5, the last three sets in parentheses on
the right of this equation have the same cardinality as M. Thus
where M 2 is disjoint from M x M, and has the same cardinality as M. We now
define a bijection
We let g1(X) = g(x) ifx E M, and we let g1 on M 1 be any bijection of M 1 on M 2 '
In this way we have extended g to M U M 1, and the pair (M u M 1, g1) is in S,
contradicting the maximality of (M, g). The case card(M) ~ card(C) therefore
cannot occur, and our theorem is proved (using Exercise 14 below).
Corollary 3.7.
If A is an infinite set, and A(n) = A x .. . x A is the product
taken n times, then
card(A(n)
= card(A).
Proof
Induction.
Corollary 3.8.
If At> . . . , An are non-empty sets with An infinite. and
for i = 1, . .. , n, then
card(A 1 X
• •• x An) = card(A n) .

890
SOME SET THEORY
APPENDIX 2
Proof
We have
card(A n) ~ card(A I x . . . x An) ~ cardt.t, x . .. X An)
and we use Corollary 3.7 and the Schroeder-Bernstein theorem to conclude the
proof.
Corollary 3.9.
Let A be an infinite set, and let <I> be the set of finite subsets
of A.
Then
card(<I»
= card(A).
Proof
Let <l>n be the set of subsets of A having exactly n elements, for each
integer n = 1,2, . . . . We first show that card(<I>n) ~ card(A). IfF is an element
of <l>n' we order the elements of F in any way, say
and we associate with F the element (XI ' . . . , xn) E A(n),
If G is another subset of A having n elements, say G = {YI' . .. , Yn}, and G 1= F,
then
Hence our map
of<l>ninto A(n) is injective. By Corollary 3.7, we conclude that
card(<I>n) ~ card(A).
Now <I> is the disjoint union of the <l>n for n = 1,2, . . . and it is an exercise to
show that card(<I»
~ card(A) (cf. Exercise 1). Since
card(A) ~ card(<I» ,
because in particular, card(<I>l) = card(A), we see that our corollary is proved.
In the next theorem, weshall see that given a set, there always exists another
set whose cardinality is bigger.
Theorem 3.10.
Let A be an infinite set, and T the set consisting of two
elements {O, I}. Let M be the set ofall maps of A into T . Then
card(A) ~ card(M)
and
card(A) 1= card(M).

APPENDIX 2
Proof
For each x E A we let
SOME SET THEORY
891
be the map such that Jx(x) = 1andJAy) = 0 ify ¥-.x. Then x 1--+ Jx is obviously
an injection of A into M, so that card(A) ~ card(M). Suppose that
card(A) = card(M).
Let
be a bijection between A and M. We define a map h : A -> {O, I} by the rule
h(x) = 0
if
gx(x) = 1,
h(x) = 1
if
gAx) = o.
Then certainly h ¥- gxfor any x, and this contradicts the assumption that x 1--+gx
is a bijection, thereby pro ving Theorem 3.10.
Corollary 3.11.
Let A be an infinite set, and let S be the set ojall subsets oj A.
Then card(A ) ~ card (S) and card(A) ¥- card(S).
Proof
We leave it as an exercise. [Hint:
If B is a non-empty subset of A,
use the characteristic funct ion ({JBsuch that
({JB(X) = I
if
x EB,
({Jix) = 0
if
x ¢ B.
What can you say about the association B 1--+ ({JB?]
§4.
WELL-ORD ERING
An ordered set A is said to be well-ordered if it is totally ordered, and if every
non -empty subset B has a least element, that is, an element a EB such that
a ~ x for all x EB.
Example 1.
The set of positive integers Z + is well-ordered. Any finite set
can be well-ordered, and a denumerable set D can be well-ordered : Any bijection
of D with Z + will give rise to a well-ordering of D.
Example 2.
Let S be a well-ordered set and let b be an element of some set,
b ¢ S. Let A = S u {b}. We define x ~ b for all XES. Then A is totally ordered,
and is in fact well-ordered.

892
SOME SET THEORY
APPENDIX 2
Proof
Let B be a non-empty subset of A. IfB consists of b alone, then b is a
least element of B. Otherwise, B contains some element a E A. Then B (1 A is not
empty, and hence has a least element, which is obviously also a least element for
B.
Theorem 4.1.
Every non-empty set can be well-ordered.
Proof
Let A be a non-empty set.' Let S be the set of all pairs (X , w), where
X is a subset of A and W isa well-ordering of X. Note that S is not empty because
any single element of A gives rise to such a pair. If(X, w) and (X', co') are such
pairs , we define (X, w) ~ (X', Wi) if X C X', if the ordering induced on X by
to' is equal to co, and if X is an initial segment of X'. It is obvious that this
defines an ordering on S, and we contend that S is inductively ordered. Let
{(Xi' Wi)} be a totally ordered non-empty subset of S. Let X = U Xi- Ifa, b E X,
then a, b lie in some Xi' and we define a ~ b in X if a ~ b with respect to the
ordering Wi' This is independent of the choice of i (immediate from the assumption
of total ordering). In fact, X is well ordered, for if Y is a non-empty subset of
X, then there is some element y E Y which lies in some Xj' Let c be a least
element of Xj n Y. One verifies at once that c is a least element of Y. We can
therefore apply Zorn's lemma. Let (X, w) be a maximal element in S. If X ¥= A,
then, using Example 2, we can define a well-ordering on a bigger subset than
X, contradicting the maximality assumption. This proves Theorem 4.1.
Note.
Theorem 4.1 is an immediate and straightforward consequence of
Zorn's lemma. Usually in mathematics, Zorn's lemma is the most efficient tool
when dealing with infinite processes.
EXERCISES
1. Prove the statement made in the proof of Corollary 3.9.
2. IfA isan infiniteset,and <1>. isthe set ofsubsetsofA havingexactlynelements,showthat
card(A) ~ card(<1>.)
for n ;;; 1.
3. Let Ai be infinitesets for i = I, 2, ... and assume that
card(Ai) ~ card(A)
for some set A, and all i. Show that

APPENDIX 2
SOME SET THEORY
893
4. Let K be a subfield of the complex numbers. Show that for each integer n ~ 1, the
cardinality of the set of extensions of K of degree n in C is 3 card(K).
5. Let K be an infinite field, and E an algebraic extension of K . Show that
card(E) = card(K).
6. Finish the proof of the Corollary 3.11.
7. If A, B are sets, denote by M(A , B) the set of all maps of A into B. If B, B' are sets with
the same cardinality, show that M(A, B) and M(A, B') have the same cardinality. If
A, A' have the same cardinality, show that M(A, B) and M(A', B) have the same
cardinality.
8. Let A be an infinite set and abbreviate card(A) by a. If B is an infinite set, abbreviate
card(B) by f3. Define af3 to be card(A x B) . Let B' be a set disjoint from A such that
card(B) = card(B') . Define a + f3 to be card(A u B'). Denote by BA the set of all maps
of A into B , and denote card(BA) by f3a. Let C be an infinite set and abbreviate card(C)
by y. Prove the following statements :
(a) IX({J + y) = IX{J + IXY·
(b)
IX{J = {JIX.
(c) IXP+Y =
IXPIX' .
9. Let K be an infinite field. Prove that there exists an algebraically closed field K"
containing K as a subfield, and algebraic over K. [Hint:
Let Q be a set of cardinality
strictly greater than the cardinality of K, and containing K. Consider the set S of all
pairs (E, q» where E is a subset of Q such that K c E, and q> denotes a law of addition
and multiplication on E which makes E into a field such that K is a subfield, and E is
algebraic over K . Define a partial ordering on S in an obvious way; show that S is
inductively ordered , and that a maximal element is algebraic over K and algebraically
closed. You will need Exercise 5 in the last step.]
to. Let K be an infinite field. Show that the field of rational functions K(t) has the same
cardinality as K.
11. Let J n be the set of integers {I, . . . , n}. Let Z + be the set of positive integers. Show
that the following sets have the same cardinality:
(a) The set of all maps M(Z +, Jn)'
(b) The set of all maps M(Z " . J2)'
(c) The set of all real numbers x such that 0 ~ x < 1.
(d) The set of all real numbers.
12. Show that M(Z+, Z+) has the same cardinality as the real numbers.
13. Let S be a non-empty set. Let S' denote the product S with itself taken denumerably
many times. Prove that (S') ' has the same cardinality as S' . [Given a set S whose
cardinality is strictly greater than the cardinality of R, I do not know whether it is
always true that card S = card S'.J Added 1994: The grapevine communicates to me
that according to Solovay, the answer is "no."
14. Let A, B be non-empty sets. Prove that
card(A) 3 card(B)
or
card(B) 3 card(A) .
[Hint: consider the family of pairs (C, f) where C is a subset of A and f : C -
B is
an injective map. By Zorn's lemma there is a maximal element. Now finish the proof].

[Ad 62]
[Ara 31]
[Ara 33]
[Art 24]
[Art 27]
[Art 44]
[ArS 27]
[ArT 68]
[Art 68]
[ArM 65]
[At 61]
[At 67]
[ABP 73]
[ABS 64]
[AtM 69]
[Ba 68]
[BaH 62]
[Be 80]
[Be 83]
[BeY 91]
[BGV 92]
[BCHS 65]
[Bott 69]
[Boun 1854]
BIBLIOGRAPHY
895
Bibliography
F. ADAMS, Vector Fields on Spheres, Ann. Math. 75 (1962) pp. 603-632
H. ARAMATA, Uber die Teilbarkeit der Dedekindschen Zetafunktionen,
Proc. Imp. Acad. Tokyo 7 (1931) pp. 334-336
H. ARAMATA, Uber die Teilbarkeit der Dedekindschen Zetafunktionen,
Proc. Imp. Acad. Tokyo 9 (1933) pp. 31-34
E. ARTIN, Kennzeichnumg des Korpers der reellen algebraischen Zahlen,
Abh. Math. Sem. Hansischen Univ. 3 (1924) pp. 319-323
E. ARTIN, Uber die Zerlegung definiter Funktionen in Quadrate, Abh.
Ma th. Sem. Hansischen Univ. 5 (1927) pp. 100- 11 5
E. ARTIN, Galois Theory, University of Notre Dame, 1944
E. ARTIN and E. SCHREIER, Algebraische Konstruktion reeller Korper,
Abh . Math. Sem. Hansischen Univ, 5 (1927) pp. 85-99
E. ARTIN and 1. TATE, Class Field Theory, Benjamin-Addison Wesley,
1968 (reprinted by Addison-Wesley, 1991)
M. ARTIN, On the solutions of analytic equations, Invent. Math. 5 (1968)
pp.277-291
M. ARTIN and B. MAZUR, On periodic points, Ann. Math . (2) 81 (1965)
pp. 89-99
M. ATIYAH, Characters and cohomology of finite groups, Pub. IHES 9
(1961) pp. 5-26
M. ATIYAH, K-Theory, Addison-Wesley, (reprinted from the Benjamin
Lecture Notes, 1967)
M. ATIYAH , R. BOTT, V. PATODI , On the heat equation and the index
theorem, Invent. Math. 19 (1973) pp. 270-330
M. ATIYAH , R. BOTT, A. SHAPIRO, Clifford Modules, Topology Vol. 3
Supp. 1 (1964) pp. 3- 38
M. ATIYAH and 1. McDoNALD, Introduction to commutative algebra ,
Addison-Wesley, 1969
H. BAss, Algebraic K-theory, Benjamin, 1968
P. T. BATEMANand R. HORN, A heuristic asymptotic formula concerning
the distribution of prime numbers, Math. Comp o 16 (1962) pp.
363-367
G. BELYI, Galois extensions of the maximal cyclotomic field, Izv. Akad.
Nauk SSSR 43 (1979) pp. 267-276 ( = Math. USSR Izv. 14 (1980), pp.
247-256
G. BELVI, On extensions of the maximal cyclotomic field having a given
classical Galois group, J. reine angew. Math. 341 (1983) pp. 147-1 56
C. BERENSTEINand A. YGER, Effective Bezout identities in Q[ZI"" znL
Acta Math. 166 (1991) pp. 69- 120
N. BERLINE, E. GETZLER, M. VERGNE, Heat kernels and Dirac operators ,
Springer-Verlag, 1992
B. BIRCH, S. CHOWLA, M. HALL, and A. SCHINZEL, On the difference
x 3 -
y2, Norske Vid. Selsk. Forrh. 38 (1965) pp. 65-69
R. BOTT, Lectures on K(X), Benjamin 1969
V. BOUNIAKOWSKY, Sur les diviseurs numeriques invariables des fonctions

896
BIBLIOGRAPHY
[Bour 82]
[Bra 47a]
[Bra 47b]
[BLSTW 83]
[BtD 85]
[Br 87]
[Br 88]
[Br 89]
[BrCDT OIl
[CaE 57]
[CCFf 91]
[CuR 81]
[Da 65]
[De 68]
[De 73]
[DeS 74]
[Dou 64]
[ES 52]
[Fa 91]
[Fr 87]
rationnelles entieres, Memoires sc. math. et phys. T. VI (1854-1855)
pp. 307-329
N. BOURBAKI, Lie algebras and Lie groups, Masson, 1982
R. BRAUER, On the zeta functions of algebraic number fields, Amer. J.
Math. 69 (1947) pp. 243-250
R. BRAUER, On Artin's L-series with general group characters, Ann. Math.
48 (1947) pp. 502-514
J. BRILLHART, D. H. LEHMER, J. L. SELFRIDGE, B. TUCKERMAN, and S.
WAGSTAFF, Factorization of b" ± I, b = 2, 3, 5, 6, 7, 10, II up to
high powers, Contemporary Mathematics Vol. 22, AMS, Providence,
RI, 1983
T. BROCKER and T. TOM DIECK, Representations of Compact Lie Groups,
Springer-Verlag, 1985
D. BROWNAWELL, Bounds for the degree in Nullstellensatz, Ann. ofMath.
126 (1987) pp. 577-592
D. BROWNAWELL, Local diophantine nullstellen inequalities, J. Amer.
Math. Soc. 1 (1988) pp. 311-322
D. BROWNAWELL, Applications of Cayley-Chow forms, Springer Lecture
Notes 1380: Number Theory, VIm, 1987, H. P. Schlickewei and E.
Wirsing (eds.) pp. 1-18
C. BREUlL, B. CONRAD, F. DIAMOND, R. TAYLOR, On the modularity of
elliptic curves over Q: Wild 3-adic exercises, J. Amer. Math. Soc. 14
(200I) pp. 843-939
E. CARTAN andS. ElLENBERG, HomologicalAlgebra, Princeton University
Press, 1957
P. CAssou-NoGUES, T. CHINBURG, A. FROLICH, M. J. TAYLOR, L-func-
lions and Galois modules, in L-functions and Arithmetic, J. Coates and
M. J. Taylor (eds.), Proceedings of the Durham symposium July 1989,
LondonMath. Soc.LectureNotesSeries 153, Cambridge University Press
(1991) pp. 75-139
C. W. CURTIS and I. REINER, Methods of Representation Theory, John
Wiley and Sons, 1981
H. DAVENPORT, Onj3(t) -
g2(t), Norske Vid. Selsk. Forrh. 38 (1965)
pp. 86-87
P. DELIGNE, Formes modulaires et representations l-adiques, Seminaire
Bourbaki 1968-1969, pp. 55-105
P. DELIGNE, Formes modulaires et representations de GL(2), Springer
Lecture Notes 349 (1973) pp. 507-530
P. DELIGNE and J.-P. SERRE, Formes modulaires de poids 1, Ann. Sci.
ENS 7 (1974) pp. 507-530
A . DOUADY, Determination d'un groupe de Galois, C.R. Acad. Sci. 258
(1964), pp. 5305-5308
S. ElLENBERG and N. STEENROD, Foundations of Algebraic Topology,
Princeton University Press, 1952
G. FALTINGS, Lectures on the arithmetic Riemann-Roch theorem, Ann.
Math. Studies 127, 1991
G. FREY, Links between stable elliptic curves and certain diophantine
equations, Number Theory, Lecture Notes 1380, Springer-Verlag 1987
pp.31-62

[Fro 83]
[FuL 85]
[God 58]
[Gor 68]
[Gor 82]
[Gor 83]
[Gor 86]
[GreH 81]
[GriH 78]
[Gro 57)
[Gro 68]
[Gu 90]
[HaiR 74]
[Hal 71]
[HardW 71]
[Hart 77]
[Has 34]
[HilS 70]
[Hir 66]
[Hu 75]
[Ih 66]
[Ik 77]
[lw 53]
[Ja 79]
BIBLIOGRAPHY
897
A. FROLICH , Galois Module Stuctures of Algebraic Integers, Ergebnisse
der Math. 3 Folge Vol. I, Springer-Verlag (1983)
W. FULTON and S. LANG, Riemann-Roch Algebra, Springer-Verlag, 1985
R. GODEMENT, Theorie desfaisceaux, Hermann Paris, 1958
D. GORENSTEIN , Finite groups, Harper and Row, 1968
D. GORENSTEIN, Finite simple groups, Plenum Press, 1982
D. GORENSTEIN, The classification of finite simple groups, Plenum Press,
1983
D. GORENSTEIN, Classifying the finite simple groups, Bull. AMS 14
No. I (1986) pp. 1-98
M. GREENBERG and J. HARPER, Algebraic Topology: A First Course,
Benjamin-Addison Wesley, 1981
P. GRIFFITHS and 1. HARRIS, Principles of Algebraic Geometry, Wiley
Interscience, New York, 1978
A. GROTHENDIECK, Sur quelques points d'algebre homologique, Tohoku
Math. J. 9 (1957) pp. 119-221
A. GROTHENDIECK, Classes de Chern et representations lineaires des
groupes discrets, Dix exposes sur la cohomologie etaIe des schemas,
North-Holland, Amsterdam, 1968
R. GUNNING, Introduction to Holomorphic Functions ofSeveral Variables,
Vol. II: Local Theory; Vol. III, Wadsworth and Brooks/Cole, 1990
H. HALBERSTAM and H.-E. RICHERT, Sieve methods, Academic Press,
1974
M. HALL, The diophantine equation x 3 -
y2 = k, Computers and Number
Theory, ed. by A. O. L. Atkin and B. Birch, Academic Press, London
1971 pp. 173-198
G. H. HARDY and E. M. WRIGHT,An Introduction to the Theory ofNumbers,
Oxford University Press, Oxford, UK, 1938-01971 (several editions)
R. HARTSHORNE, Algebraic Geometry, Springer-Verlag, New York, 1977
H. HASSE, Abstrakte Begrundung der komplexen Multiplikation und Rie-
mannsche Vermutung in Funktionenkorpern, Abh. Math. Sem. Univ.
Hamburg 10 (1934) pp. 325-348
P. J. HILTON and U. STAMMBACH, A course in homological algebra , Grad-
uate Texts in Mathematics, Springer-Verlag 1970
F. HIRZEBRUCH, Topological methods in algebraic geometry, Springer-
Verlag, New York, 1966 (Translated and expanded from the original
German, 1956)
D. HUSEMOLLER, Fibre Bundles, Springer-Verlag, second edition, 1975
Y. IHARA, On discrete subgroups of the two by two projective linear group
over p-adic fields, J. Math Soc. Japan 18 (1966) pp. 219-235
M. IKEDA, Completeness of the absolute Galois group of the rational
number field, 1. reine angew. Math. 291 (1977) pp. 1-22
K. IWAsAwA, On solvable extensions of algebraic number fields, Ann.
Math. 548 (1953) pp. 548-572
N. JACOBSON, Lie algebras, Dover, 1979 (reprinted from Interscience,
1962)

898
BIBLIOGRAPHY
(la 85J
[JoL OIJ
[Jou 80]
(lou 90]
(lou 91]
[Ko 88]
[Kr 32]
[La 52]
[La 53]
[La 58]
[La 70]
[La 72]
[La 73]
[La 76]
[La 78]
[La 82]
[La 83]
[La 85]
[La 90a]
[La 90bJ
[La 90c]
[La 96]
[La 99a]
[La 99b]
[LaT 75]
[Ma 16]
[Mack 51]
[Mack 53]
N. JACOBSON , Basic Algebra I and II, second edition, Freeman, 1985
J. JORGENSON and S. LANG, Spherical Inversion on SLn(R), Springer
Verlag 2001
I.-P. JOUANOLOU, Ideaux resultants, Advances in Mathematics 37 No, 3
(1980) pp. 212-238
I. -P. JOUANOLOU, Le formalisme du resultant, Advances in Mathematics
90 No.2 (1991) pp. 117-263
J.-P. JOUANOLOU, Aspects invariants de !'elimination, Departernent de
Mathematiques, Universite Louis Pasteur, Strasbourg, France (1991)
1. KOLLAR, Sharp effective nullstellensatz, J. Amer. Math . Soc . 1 No.4
(1988) pp. 963-975
W. KRULL, Allgemeine Bewertungstheorie, J. reine angew . Math. (1932)
pp. 169-196
S. LANG, On quasi algebraic closure, Ann . Math . 55 (1952) pp. 373-390
S. LANG, The theory of real places, Ann. Math . 57 No.2 (1953) pp.
378-391
S. LANG, Introduction to Algebraic Geometry, Interscience, 1958
S. LANG, Algebraic Number Theory, Addison-Wesley, 1970; reprinted by
Springer-Verlag; second edition 1994
S. LANG, Differential Manifolds, Addison-Wesley, 1972; reprinted by
Springer-Verlag, 1985; superceded by [La 99a]
S. LANG, Elliptic Functions, Springer-Verlag, 1973; second edition 1987
S. LANG, Introduction to Modular Forms, Springer-Verlag 1976
S. LANG, Elliptic Curves: Diophantine Analysis, Springer 1978
S. LANG, Units and class groups in number theory and algebraic geometry,
Bull . AMS Vol. 6 No.3 (1982) pp. 253-316
S. LANG, Fundamentals ofDiophantine Geometry, Springer-Verlag 1983
S. LANG, Real Analysis, Second edition, Addison-Wesley, 1985; third
edition Real and Functional Analysis, Springer-Verlag, 1993
S. LANG, Undergraduate Algebra, second edition, Springer-Verlag, 1990
S. LANG, Cyclotomic fields, I and 1/, Springer-Verlag, New York , 1990,
combined edition of the original editions, 1978, 1980
S. LANG, Old and new conjectured diophantine inequalities, Bull. AMS
Vol. 23 No.1 (1990) pp. 37-75
S. LANG, Topics in Cohomology of Groups, Springer Lecture Notes 1996,
reproduced in Lang's Collected Papers, Vol. IV, Springer 2000
S. LANG, Fundamentals of Differential Geometry, Springer Verlag, 1999
S. LANG, Math Talksfor Undergraduates, Springer Verlag, 1999
S. LANG and H. TROTTER, Distribution of Frobenius Elements in G~·
Extensions of the Rational Numbers, Springer Lecture Notes 504
F. MACAULAY, The algebraic theory ofmodular systems, Cambridge Uni-
versity Press, Cambridge UK, 1916
G. MACKEY, On induced representations of groups, Amer. J. Math . 73
(1951) pp. 576-592
G. MACKEY, Symmetric and anti-symmetric Kronecker squares of induced
representations of finite groups, Amer. J. Math. 75 (1973) pp. 387-405

(Man 69)
(Man 71)
(Mas 84a)
(Mas 84b)
[Mas 84c]
(MaW 85)
(Mat 80)
(Mat 86)
[Matz 87)
[Matz 88)
[Neu 69a]
[Neu 69b]
[Neu 69c]
[No 76)
[Ph 86]
[Ph 91-95]
[Pop 94]
[Pop 95]
[Ri 90a)
[Rib 90b)
[Ric 60)
[Ro 79)
[Ru 73)
[Schi 58)
[Schulz 37)
BIBLIOGRAPHY
899
1. MANIN, Lectures on the K-functor in algebraic geometry, Russian Math .
Surveys 24(5) (1969) pp. 1-89
A. MANNING, Axiom A diffeomorphisms have rational zeta functions,
Bull . Lond . Math . Soc. 3 (1971) pp. 215-220
R. C. MASON, Equations over function fields, Springer Lecture Notes
1068 (1984) pp. 149-157; in Number Theory, Proceedings ofthe Noord-
wijkerhout, 1983
R. C. MASON, Diophantine equations over function fields, London Math.
Soc. Lecture Note Series Vol. 96, Cambridge University Press, 1984
R. C. MASON, The hyperelliptic equation over function fields, Math. Proc.
Cambridge Phi/os. Soc. 93 (1983) pp. 219-230
D. MASSER and G. WOSTHOLZ, Zero estimates on group varieties II, Invent .
Math. 80 (1985) pp. 233-267
H.
MATSUMURA,
Commutative algebra ,
second
edition,
Benjamin-
Cummings, New York 1980
H. MATSUMURA, Commutative rings, Cambridge University Press , 1986
B. MATZAT, Konstruktive Galoistheorie, Springer Lecture Notes 1284,
1987
B. MATZAT, Uber das Umkehrproblem der Galoischen Theorie, Jahrs-
bericht Deutsch. Mat.-Verein. 90 (1988) pp. 155-183
J. NEUKIRCH, Uber eine algebraische Kennzeichnung der Henselkorper,
J. reine angew. Math. 231 (1968) pp. 75-81
J. NEUKIRCH, Kennzeichnung der p-adischen und endlichen algebrai-
schen Zahlkorper, Invent. Math. 6 (1969) pp . 269-314
J. NEuKIRcH, Kennzeichnung der
endlich-algebraischen Zahlkorper
durch die Galoisgruppe der maximal auflosbaren Erweiterungen, J. fur
Math. 238 (1969) pp. 135-147
D. NORTHCOTT, Finite FreeResolutions, Cambridge University Press, 1976
P. PHILIPPON, Lemmes de zeros dans les groupes algebriques commu-
tatifs , Bull. Soc. Math. France 114 (1986) pp. 355-383
P. PHILIPPON, Sur des hauteurs alternatives I, Math. Ann. 289 (1991) pp.
255-283; II Ann. Inst. Fourier 44 (1994) pp. 1043-1065; III J. Math.
Pures App!. 74 (1995) pp. 345-365
F. POP, On Grothendieck's conjecture of birational anabelian geometry,
Annals of Math . (2) 139 (1994) pp. 145-182
F. POP, Etale Galois covers of affine smooth curves, Invent. Math. 120
(1995), pp. 555-578
K. RIBET, On modular representations of Gal(Q8/Q) arising from modular
forms, Invent. Math. 100 (1990) pp. 431-476
K. RIBET, From the Taniyama-Shimura conjecture to Fermat's last the-
orem , Annales de la Fac. des Sci. Toulouse (1990) pp. 116-170
C. RICKART, Banach Algebras, Van Nostrand (1960), Theorems 1.7.1 and
4.2 .2
1. ROH1AN, Introduction to Homological Algebra, Academic Press, 1979
W. RUDIN , Functional Analysis, McGraw Hill (1973) Theorems 10.14,
and 11.18
A. SCHINZEL and W. SIERPINSKI, Sur certaines hypotheses concernant
les nombres premiers, Acta Arith. 4 (1948) pp, 185-208
W. SCHULZ, Uber die Galoissche Gruppe der Hermitschen Polynome, J.
reine angew. math. 177 (1937) pp. 248-252

900
BIBLIOGRAPHY
[Schur 31]
(Se 62]
[Se 64)
[Se 65a]
[Se 65b]
[Se 68a]
[Se 68b]
[Se 72a]
[Se 72b]
[Se 73]
[Se 80]
[Se 87]
[Se 88]
[Se 92]
[SGA 6]
[Shaf 54]
[Shat 72]
[Shih 74]
[Shim 66]
[Shim 71]
[Shu 87]
[Si188]
[Sn 00]
[Sol 01]
1. SCHUR, Affektlose Gleichungen in der Theorie der Laguereschen und
Hermiteschen Polynome , J. reine anqew, math. 165 (1931) pp. 52-58
l.-P. SERRE, Endomorphismes completements continus des espaces de
Banach p-adiques, Pub. Math . IHES 12 (1962) pp. 69-85
l .-P. SERRE, Cohomologie Galoisienne, Springer Lecture Notes 5, 1964
l .-P. SERRE, Algebre locale. multiplicites, Springer Lecture Notes 11 (1965)
Third Edition 1975
l.-P. SERRE, Lie algebras and Lie groups, Benjamin , 1965; reprinted
Springer Lecture Notes 1500, Springer-Verlag 1992
l.-P. SERRE, Abelian l-adic representations and Elliptic Curves, Benjamin,
1968
l .-P. SERRE, Une interpretation des congruences relatives a la fonction
de Ramanujan, Seminaire Delanqe-Poitou-Pisot, 1971-1972
l .-P . SERRE, Proprietes Galoisiennes des points d'ordre fini des courbes
elliptiques, Invent. Math. 15 (1972) pp. 259-331
l .-P. SERRE, Congruences et formes modulaires (d'apres Swinnerton-
Dyer), SeminaireBourbaki, 1971-1972
l .-P. SERRE, A Course in Arithmetic, Springer-Verlag, New York, 1973
l .-P. SERRE, Trees, Springer-Verlag, 1980
l .-P. SERRE, Sur les representations modulaires de degre 2 de Gal(Qa/Q),
Duke Math. J. 54 (1987) , pp. 179-230
l .-P. SERRE, Groupes de Galois sur Q, Seminaire Bourbaki, 1987-1988,
Asterisque 161-162, pp. 73-85
l .-P. SERRE, Topics in Galois theory , course at Harvard, 1989,lones and
Bartlett, Boston 1992
P. BERTHELOT, A. GROTHENDJECK, L. ILLUSIE et al. , Theone des inter-
sections et theoreme de Riemann-Roch, Springer Lecture Notes 146 (1967)
I. SHAFAREVICH, Construction of fields of algebraic number with given
solvable Galois group , Izv. Akad. Nauk SSSR 18 (1954) pp. 525-578
(Amer. math. Soc. Transl. 4 (1956» pp. 185-237
S. SHATZ, Profinite groups, arithmetic and geometry , Ann. of Math. Stud-
ies, Princeton University Press 1972
R.- Y. SHIH, On the construction of Galois extensions of function fields
and number fields, Math . Ann . 207 (1974) , pp. 99-120
G. SHIMURA, A Reciprocity law in non-solvable extensions,J. reineanqew,
Math . 224 (1966) pp. 209-220
G. SHIMURA, Introduction to the arithmetic theory ofAutomorphicFunctions,
Iwanami Shoten and Princeton University Press, 1971
M. SHUB, Global Stability of Dynamical Systems, Springer-Verlag, New
York 1987
1. SILVERMAN, Wieferich 's criterion and the abc conjecture, J. Number
Theory 30 (1988) pp. 226-237
N. SNYDER, An alternate proof of Mason's theorem, Elemente der Math.
55 (2000) pp. 93-94
R. SoLOMON, A brief history of the classification of the finite simple
groups, Bull. AMS Vol. 38 No.3 (2001) pp. 315-322

[Sou 90J
[SteT 86]
[Sto 81J
[Sw 69J
[Sw 83]
[SwD 73J
[TaW 95]
[Uch 77]
[Uch 79]
[Uch 81]
[vdW 29J
[vdW 30)
[WiI95]
[Win 91]
[Wit 35]
[Wit 36)
[Wit 37]
[Za 95]
BIBLIOGRAPHY
901
C. SoULE, Geornetrie d'Arakelov et theorie des nombres transcendants,
Preprint, 1990
c.L. STEWART and R. TUDEMAN, On the Oesterle-Masser Conjecture,
Mon. Math. 102 (1986) pp. 251-257
W. STOTHERS, Polynomial identites and hauptmoduln, Quart. 1. Math.
Oxford (2) 32 (1981) pp. 349-370
R. SWAN, Invariant rational functions and a problem of Steenrod,
Invent. Math. 7 (1969) pp. 148-158
R. SWAN, Noether's problem in Galois theory, Emmy Noether in Bryn
Mawr, 1. D. Sally and B. Srinivasan , eds., Springer-Verlag, 1983, p. 40
H. P. SWINNERTON-DYER, On l-adic representations and congruences for
coefficients of modular forms, Antwerp conference, Springer Lecture
Notes 350 (1973)
R. TAYLOR and A. WILES, Ring-theoretic properties of certain Heeke
algebras, Annals of Math. 141 (1995) pp. 553-572
K. UCHIDA, Isomorphisms of Galois groups of algebraic function fields,
Ann. of Math. 106 (1977) pp. 589-598
K. UCHIDA, Isomorphisms of Galois groups of solvable closed Galois
extensions, Tohoku Math. 1. 31 (1979) pp. 359-362
K. UCHIDA, Homomorphisms of Galois groups of solvably closed Galois
extensions, J. Math. Soc. Japan 33 (1981) pp. 595-604
B. L. VAN DER WAERDEN, On Hilbert's function, series ofcomposition of
ideals and a generalization of the theorem of Bezout, Proc. R. Soc.
Amsterdam 31 (1929) pp. 749-770
B. L. VAN DER WAERDEN, Modern Algebra, Springer-Verlag, 1930
A. WILES, Modular elliptic curves and Fermat's last theorem, Annals of
Math. 141 (1995) pp . 443-551
K. WINBERG, On Galois groups of p-closed algebraic number fields with
restricted ramification, I, J. reine angew. Math. 400 (1989) pp. 185-202
and II, ibid. 416 (1991) pp. 187-194
E. WITT, Der Existenzsatz fur abelsche Funktionenkorper, J. reine
angew. Math. 173 (1936) pp. 43-51
E. WITT, Konstruktion von galoisschen Korpern der Charakteristik p
mit vorgegebener Gruppe der Ordnung pi , J. reine angew. Math. 174
(1936) pp. 237- 245
E. WITT, Zyklische Korper und Aigebren der Charakteristik p vom Grad
r" . Struktur diskret bewerteter perfekter Korper mit vollkommenem
Restklassenkorper der Charakteristik p, J. reine angew. Math. 176
(1937) pp. 126-140
U. ZANNIER, On Davenport's bound for the degree off3 - g2 and Rie-
mann's existence theorem, Acta Arithm. LXXI.2(1995) pp. 107-137

INDEX
abc conjecture, 195
abelian, 4
category, 133
extension, 266, 278
group, 4, 42, 79
Kummer theory, 293
tower, 18
absolute value, 465
absolutely semisimple, 659
abstract nonsense, 759
abut, 815
action of a group, 25
acyclic, 795
Adams operations, 726, 782
additive category, 133
additive functor, 625, 790
additive polynomial, 308
adic
completion, 163, 206
expansion, 190
topology, 162, 206
adjoint, 533, 581
affine space, 383
algebra , 121,629,749
algebraic
closure, 178, 231, 272
element, 223
extension, 224
group, 549
integer, 371
set, 379
space, 383, 386
algebraically
closed, 272
independent, 102, 308, 356
almost all, 5
alternating
algebra, 733
form, 511, 526, 530, 571, 598
group, 31, 32, 722
matrix, 530, 587
multilinear map, 511, 731
product, 733, 780
annihilator, 417
anti-dual, 532
anti-linear, 562
anti-module, 532
approximation theorem , 467
Aramata's theorem, 701
archimedean ordering, 450
Arlin
conjectures, 256, 30I
theorems, 264, 283, 290, 429
artinian, 439, 443, 661
Artin-Rees theorem , 429
Artin-Schreier theorem, 290
associated
graded ring, 428, 430
group and field, 30I
ideal of algebraic set, 381
linear map, 507
matrix of bilinear map, 528
object, 814
prime, 418
associative, 3
asymptotic Fermat, 196
automorphism, 10, 54
inner, 26
of a form, 525, 533
Banach space, 475
balanced, 660
base change, 625
basis, 135, 140
Bateman-Hom conjecture, 323
belong
group and field, 263
ideal and algebraic set, 381
prime and primary ideal, 421
Bernoulli
numbers, 218
polynomials, 219
bifunctor, 806
bijective, ix
bilinear form, 146, 522
903

904
INDEX
bilinear map, 48, 121, 144
binomial polynomial, 434
Blichfeldt theorem, 702
blocks, 555
Borel subgroup , 537
boundaries, 767
bounded complex, 762
Bourbaki theorems
on sets, 881
on traces and semisimplicity, 650
bracket product, 121
Brauer's theorems, 701, 709
Bruhat decomposition, 539
Burnside theorems
on simple modules, 648
on tensor representations, 726
butterfly lemma, 20
e-dimension, 772
cancellation law, 40
canonical map, 14, 16
cardinal number, 885
Carlan subgroup, 712
Casimir, 628, 639
category, 53
Cauchy
family, 52
sequence, 51, 162,206,469
Cayley-Hamilton theorem, 561
center
of a group, 26, 29
of a ring, 84
central element, 714
centralizer , 14
chain condition, 407
character, 282, 327, 667, 668
independence , 283, 676
characteristic , 90
characteristic polynomial, 256, 434, 561
of tensor product, 569
Chevalley's theorem, 214
Chinese remainder theorem, 94
class formula, 29
class function, 673
class number, 674
Clifford algebra, 749, 757
closed
complex, 765
subgroup, 329
under law of composition, 6
coboundary, 302
cocycle
GL. ,549
Hilbert's theorem, 90, 288
Sah's theorem, 303
coefficient function, 681
coefficients
of linear combination, 129
of matrix, 503
of polynomial, 98, 101
coerasable, 805
cofinal,52
cohomology, 288, 302, 303, 549, 764
of groups, 826
cokernel, 119, 133
column
operation, 154
rank,506
vector, 503
commutative, 4
diagram, ix
group, 4
ring, 83, 84, 86
commutator, 20, 69, 75
commutator subgroup, 20, 75
of SL., 539, 541
commute, 29
compact
Krull topology, 329
spec of a ring, 411
complete
family, 837
field, 469
ring and local ring, 206
completely reducible, 554
completion, 52, 469, 486
complex, 445, 761, 765
complex numbers, 272
component, 503, 507
of a matrix, 503
composition of mappings, 85
compositum of fields, 226
conjugacy class, 673
conjugate elements
of a group, 26
of a field, 243
conjugate
embeddings, 243, 476
fields, 243, 477
subgroups, 26, 28, 35
conjugation, 26, 552, 570, 662
connected, 411
connected sum, 6
connection, 755

constant polynomial, 175
constant term, 100
content, 181
contragredient,665
contravariantfunctor, 62
convergence, 206
convolution, 85, 116
coordinates, 408
coproduct, 59, 80
of commutative rings, 630
of groups, 70, 72
of modules, 128
correspondence, 76
coset, 12
representative, 12
countable, 878
covariantfunctor, 62
Cramer's rule, 513
cubic extension, 270
cuspidal, 318
cycle
in homology, 767
in permutations, 30
cyclic
endomorphism, 96
extension, 266, 288
group, 8, 23, 96, 830
module, 147, 149
tower, 18
cyclotomic
field, 277-282, 314, 323
polynomials, 279
Davenporttheorem, 195
decomposable, 439
decomposition
field, 341
group, 341
Dedekind
determinant, 548
ring, 88, 116, 168, 353
defined, 710, 769
definiteform, 593
degree
of extension, 224
of morphism, 765
of polynomial, 100, 190
of variety, 438
Weierstrass, 208
Deligne-Serre theorem, 319
density theorem, 647
denumerableset, 875
INDEX
905
dependentabsolutevalues, 465
de Rhamcomplex, 748
derivation, 214, 368, 746, 754
over a subfield, 369
universal, 746
derivative, 178
derivedfunctor, 791
descending chain condition,408, 439, 443,
661
determinant, 513
ideal, 738, 739
of cohomology, 738
of linear map, 513, 520
of module, 735
of Witt group, 595
diagonalelement, 504
diagonalizable, 568
diagonalized form, 576
difference equations, 256
differential, 747, 762, 814
dihedralgroup, 78, 723
dimension
of character, 670
of module, 146, 507
of transcendental extension, 355
of vector space, 141
dimension in homology, 806, 811, 823
shifting, 805
direct
limit, 160, 170, 639
product, 9, 127
sum, 36, 130, 165
directed family, 51, 160
discrete valuation ring, 487
discriminant, 193,204,270,325
distinguished extensions
of fields, 227, 242
of rings, 335, 291
distinguished polynomials, 209
distributivity, 83
divide, III, 116
divisible, 50
division ring, 84, 642
Dolbeauitcomplex, 764
dominate(polynomials), 870
double coset, 75, 693
doubly transitive, 80
dual
basis, 142, 287
group, 46, 145
module, 142, 145, 523, 737
representation, 665

906
INDEX
effective character, 668, 685
eigenvalue, 562
eigenvector, 562, 582-585
Eisenstein criterion, 183
elementary
divisors, 153, 168, 521, 547
group, 705
matrix, 540
symmetric polynomials, 190,217
elimination, 391
ideal, 392
embedding, II , 120
of fields, 229
of rings, 91
endomorphism, 10, 24, 54
of cyclic groups, 96
enough
injectives, 787
T-exacts, 810
entire, 91
functions, 87
epimorphism, 120
equivalent
norms, 470
places, 349
valuations, 480
erasable, 800
euclidean algorithm, 173, 207
Euler characteristic, 769
Euler-Grothendieck group, 771
Euler phi function, 94
Euler-Poincare
characteristic, 769, 824
map, 156, 433, 435, 770
evaluation, 98, 101
even permutation, 31
exact, 15, 120
for a functor, 619
sequence of complexes, 767
expansion of determinant, 515
exponent
of an element, 23, 149
of a field extension, 293
of a group, 23
of a module, 149
exponential, 497
Ext, 791, 808, 810, 831, 857
extension
of base, 623
of derivations, 375
of fields, 223
of homomorphisms, 347, 378
of modules, 831
exterior
algebra, 733
product, 733
extreme point, 883
factor
group, 14
module, 119, 141
ring, 89
factorial, III , 115, 175,209
faithful, 28, 334, 649, 664
faithfully flat, 638
Fermat theorem, 195,319
fiber product, 61, 81
field,93
of definition of a representation, 710
filtered complex, 817
filtration, 156, 172, 426, 814, 817
finite
complex, 762
dimension, 141,772, 823
extension, 223
field, 244
free resolution, 840
homological dimension, 772, 823
module, 129
resolution, 763
sequence, 877
set, 877
type, 129
under a place, 349
finitely generated
algebra, 121
extension, 226
group, 66
module, 129
ring, 90
finitely presented, 171
Fitting ideal, 738-745
Fitting lemma, 440
five lemma, 169
fixed
field, 261
point, 28, 34, 80
flat, 612, 808
for a module, 616
forgetful functor, 62
form
multilinear, 450, 466
polynomial, 384
formal power series, 205
Fourier coefficients, 679

fractional ideal, 88
fractions, 107
free
abelian group, 38, 39
extension, 362
generators, 137
group, 66, 82
module, 135
module generatedby a set, 137
resolution, 763
Frey polynomial, 198
Frobenius
element, 180, 246, 316, 346
reciprocity, 686, 689
functionals, 142
functor, 62
fundamental group, 63
G or (G,k)-module, 664, 779
G-homomorphism, 779
G-object, 55
G-regular, 829
G-set, 25, 27, 55
Galois
cohomology, 288, 302
extension, 261
group, 252, 262, 269
theory, 262
Gauss lemma, 181, 209, 495
Gauss sum, 277
g.c.d., III
Gelfand-Mazurtheorem, 471
Gelfand-Naimarktheorem, 406
Gelfond-Schneider, 868
generate and generators
for a group, 9, 23, 68
for an ideal, 87
for a module, 660
for a ring, 90
generatingfunction or power series, 211
generatorsand relations, 68
generic
forms, 390, 392
hyperplane, 374
pfaffian, 589
point, 383, 408
polynomial, 272, 345
ghost components, 330
GL2, 300, 317, 537, 715
GLn, 19, 521, 543, 546, 547
global sections, 792
Goursat's lemma, 75
INDEX
907
graded
algebra, 172, 631
module, 427, 751, 765
morphism, 765, 766
object, 814
ring, 631
Gram-Schmidt orthogonalization, 579, 599
Grassmanalgebra, 733
greatestcommondivisor, III
Grothendieck
algebra and ring, 778-782
group, 40, 139
power series, 218
spectralsequence, 819
group, 7
algebra, 104, 121
automorphism, 10
extensions, 827
homomorphism, 10
object, 65
ring, 85, 104, 126
Hall conjecture, 197
harmonic polynomials, 354, 550
Hasse zeta function, 255
height, 167
Herbrandquotient, 79
Hermite-Lindemann, 867
hermitian
form, 533, 571, 579
linear map, 534
matrix, 535
Hilbert
Nullstellensatz, 380, 551
polynomial, 433
-Serre theorem, 431
syzygy theorem, 862
theoremon polynomial rings, 185
theorem 90, 288
-Zariskitheorem, 409
homogeneous, 410, 427, 631
algebraic space, 385
ideal, 385, 436, 733
integralclosure, 409
point, 385
polynomial, 103, 107, 190,384,436
quadraticmap, 575
homology, 445, 767
isomorphism, 767, 836
homomorphisms in categories, 765
homomorphism
of complex, 445, 765

908
INDEX
homomorphism (continued)
of groups, 10
of inverse systems, 163
of modules , 119, 122
of monoid, 10
of representations, 125
of rings , 88
homotopies of complexes,
787
Horrock 's theorem , 847
Howe's proof, 258
hyperbolic
enlargement, 593
pair, 586, 590
plane, 586, 590
space, 590
hyperplane, 542
section , 374, 410
Ideal, 86
class group , 88, 126
idempotent, 443
image, II
indecomposable, 440
independent
absolute values, 465
characters , 283, 676
elements of module, 151
extensions, 362
variables , 102, 103
index, 12
induced
character, 686
homomorphism, 16
module, 688
ordering, 879
representation, 688
inductively ordered, 880
inertia
form, 393
group, 344
infinite
cyclic group , 8, 23
cyclic module, 147
extension, 223, 235
Galois extensions, 313
period, 8, 23
set, 876
under a place, 349
infinitely
large, 450
small, 450
injective
map, ix
module, 782, 830
resolution, 788, 80I, 819
inner automorphi sm, 26
inseparable
degree, 249
extension, 247
integers mod n, 94
integral, 334, 351, 352, 409
closure, 336, 409
domain, 91
equation, 334
extension, 340
homomorphism, 337
map, 357
root test, 185
valued polynomials, 216, 435
integrally closed, 337
integrality criterion, 352, 409
invariant
bases, 550
submodule, 665
invariant
of linear map, 557, 560
of matrix, 557
of module, 153,557,563
of submodule, 153, 154
inverse, ix, 7
inverse limit, 50, 51, 161, 163, 169
of Galois groups, 313, 328
inverse matrix, 518
invertible, 84
Irr(z,k,x), 224
irreducible
algebraic set, 382, 408
character, 669, 696
element, III
module, 554
polynomial, 175, 183
polynomial of a field element, 224
irrelevant prime, 436
isolated prime, 422
isometry, 572
isomorphism, 10, 54
of representations, 56, 667
isotropy group, 27
Iss'sa-Hironaka theorem, 498
Jacobson
density, 647
radical, 658
Jordan-Holder , 22, 156
Jordan canonical form, 559

K-family,771
K-theory, 139,771-782
kernel
of bilinear map, 48, 144, 522, 572
of homomorphism , II, 133
Kolchin's theorem, 661
Koszul complex, 853
Krull
theorem, 429
topology, 329
Krull-Remak-Schmidt ,441
Kummer extensions
abelian, 294-296, 332
non-abelian, 297, 304, 326
L-functions, 727
lambda operation, 217
lambda-ring, 218, 780
Langlands conjectures, 316, 319
lattice, 662
law of composition, 3
Lazard's theorem, 639
leading coefficient, 100
least
common multiple, 113
element, 879
upper bound, 879
left
coset, 12
derived functor, 791
exact, 790
ideal,86
module, 117
length
of complex, 765
of filtration, 433
of module, 433, 644
Lie algebra, 548
lie above
prime, 338
valuation ring, 350
lifting, 227
linear
combination , 129
dependence, 130
independence, 129, 150, 283
map, 119
polynomial, 100
linearly disjoint , 360
local
degree, 477
homomorphism , 444
INDEX
909
norm, 478
parameter, 487
ring, 110,425,441
uniformization, 498
localization, 110
locally nilpotent, 418
logarithm, 497, 597
logarithmic derivative, 214, 375
Mackey's theorems, 694
MacLane's criterion, 364
mapping cylinder, 838
Maschke's theorem, 666
Mason-St others theorem , 194, 220
matrix, 503
of bilinear map, 528
over non-commutative ring, 641
maximal
abelian extension, 269
archimedean, 450
element, 879
ideal, 92
metric linear map, 573
minimal polynomial, 556, 572
Mittag-Leffler condition , 164
modular forms, 318, 319
module,I17
over principal ring, 146, 521
modulo an ideal, 90
Moebius inversion, 116, 254
monic, 175
monoid ,3
algebra, 106, 126
homomorphism, 10
monomial, 101
monomorphism, 120
Morita' s theorem, 660
morphism, 53
of complex, 765
of functor, 65, 625, 800
or representation, 125
multilinear map, 511, 521, 602
multiple root, 178,247
multiplicative
function, 116
subgroup of a field, 177
subset, 107
multiplicity
of character, 670
of root, 178
of simple module, 644
Nakayama's lemma, 424, 661
natural transformation, 65

910
INDEX
negative, 449
definite , 578
Newton approximation, 493
nilpotent, 416, 559 , 569
Noether normalization, 357
Noetherian, 186,210,408-409,415,427
graded ring, 427
module, 413
non-commutative variables, 633
non-degenerate, 522 , 572
non-singular, 523 , 529
norm, 284 , 578 , 637
on a vector space , 469
on a finitely generated abelian group , 166
normal
basis theorem, 312
endomorphism, 597
extension, 238
subgroup, 14
tower, 18
normalizer, 14
Northcott theorems, 864
null
sequence, 52
space, 586
nullstellensatz, 380, 383
occur, 102, 176
odd permutation, 31
one-dimensional
character, 671
representation, 671
open complex, 761
open set, 406
operate
on a module, 664
on an object, 55
on a set, 25, 76
orbit , 28
decomposition formula, 29
order
of a group, 12
at p, 113, 488
at a valuation, 488
of a zero, 488
ordering, 449 , 480 , 878
ordinary tensor product, 630
orthogonal
basis, 572-585
element, 48, 144, 572
group, 535
map, 535
sum , 572
orthogonality relations , 677
orthogonalization, 579
orthonormal, 577
over a map, 229
p-adic
integers, 51, 162, 169,488
numbers, 488
p-class, 706
p-conjugate, 706
p-divisible, 50
p-elementary, 705
p-group, 33
p-regular, 705
p-singular, 705
p-subgroup, 33
pairing, 48
parallelogram law, 598
partial fractions , 187
partit ion, 79
function, 211
perfect, 252
period, 23, 148
periodicity of Clifford algebra, 758
permutation, 8, 30
perpendicular, 48, 144, 522
Pfaffian, 589
Pic or Picard group , 88, 126
place, 349,482
Poincare series, 211, 431
point
of algebraic set, 383
in a field, 408
polar decomposition, 584
polarization identity, 580
pole, 488
polynomial, 97
algebra, 97, 633
function, 98
invariants, 557
irreducible, 175, 183
Noetherian, 185
Pontrjagin dual, 145
positive, 449
definite, 578 , 583
power map, 10
power series, 205
factorial, 209
Noetherian, 210
primary
decomposition, 422
ideal , 421
module, 421

prime
element, 113
field,9O
ideal,92
ring, 90
primitive
element, 243, 244
group, 80
operation, 79
polynomials, 181, 182
power series, 209
root, 301
root of unity, 277, 278
principal
homomorphism, 418
ideal, 86, 88
module, 554, 556
representation, 554
ring, 86, 146, 521
product
in category, 58
of groups, 9
of modules, 127
of rings, 91
profinite, 51
projection, 388
projective
module, 137, 168,848,850
resolution, 763
space, 386
proper, ix
congruence, 492
pull-back, 61
purely inseparable
element, 249
extension, 250
push-out, 62, 81
quadratic
extension, 269
form, 575
map, 574
symbol,281
quadratically closed, 462
quatemions, 9, 545, 723, 758
Quillen-Suslin theorem, 848
quotient
field, 110
ring, 107
radical
of an ideal, 388,417
INDEX
911
of a ring, 661
of an integer, 195
Ramanujan power series, 212
ramification index, 483
rank, 42, 46
of a matrix, 506
rational
conjugacy class, 276, 326, 725
element, 714
function, 110
real, 451
closed,451
closure, 452
place, 462
zero, 457
reduced
decomposition, 422, 443
polynomial, 177
reduction
criterion, 185
map, 99, 102
modulo an ideal, 446, 623
mod p, 623
refinement of a tower, 18
regular
character, 675, 699
extension, 366
module, 699, 829
representation, 675, 829
sequence, 850
relations, 68
relative invariant, 171, 327
relatively prime, 113
representation, 55, 124, 126
functor, 64
of a group, 55, 317, 664
of a ring, 553
space, 667
residue class, 91
degree, 422, 483
ring, 91
resolution, 763, 798
resultant, 200, 398, 410
system , 403
variety , 393
Ribet, 319
Rieffel's theorem , 655
Riemann surface, 275
Riemann-Roch, 212, 218, 220, 258
right
coset, 12, 75
derived functor, 791
exact functor, 791, 798

912
INDEX
right (continued)
ideal, 66
module, 117
rigid, 275
rigidity theorem, 276
ring, 83
homomorphism, 88
of fractions, 107
root, 175
of unity, 177, 276
row
operation, 154
rank,506
vector, 503
S3 and S4' 722
scalar product, 571
Schanuel
conjecture, 873
lemma, 841
Schreier's theorem, 22
Schroeder-Bernstein theorem, 885
Schur
Galois groups, 274
lemma, 643
Schwarz inequality, 578, 580
section, 64, 792
self-adjoint, 581
semidirect product, 15, 76
semilinear, 532
seminorm, 166, 475
semipositive, 583, 597
semisimple
endomorphism, 569, 661
module, 554, 647, 659
representation, 554, 712
ring, 651
separable
closure, 243
degree, 239
element, 240
extension, 241, 658
polynomial,241
separably generated, 363
separating transcendence basis, 363
sequence, 875
Serre's conjecture, 848
theorem, 844
sesquilinear form, 532
Shafarevich conjecture, 314
sheaf, 792
sign of a permutation, 31, 77
simple
character, 669
group, 20
module, 156, 554, 643
ring, 653, 655
root, 247
simplicity of SL., 539, 542
size of a matrix, 503
skew symmetric, 526
SL2 , 69, 537, 539, 546
generators and relations, 69, 70, 537
SL., 521, 539, 541, 547
snake lemma, 158, 169, 614-621
Snyder's proof, 220
solvable
extension, 291, 314
group, 18, 293, 314
by radicals, 292
spec of a ring, 405, 410
special linear group, 14, 52, 59, 69, 541, 546,
547
specializing, 101
specialization, 384
spectral
sequence, 815-825
theorem, 581, 583, 585
split exact sequence, 132
splitting field, 235
square
matrix, 504
group, 9, 77, 270
root of operator, 584
stably free, 840
dimension, 840
stably isomorphic, 841
stalk, 161
standard
complex, 764
alternating matrix, 587
Steinberg theorem, 726
Stewart-Tijdeman, 196
strictly inductively ordered, 881
stripping functor, 62
Sturm's theorem, 454
subgroup, 9
submodule, 118
submonoid, 6
subobject, 134
subring, 84
subsequence, 876
subspace, 141
substituting, 98, 101

super
algebra, 632
commutator, 757
product, 631, 751
tensor product, 632, 751
supersolvable, 702
support, 419
surjective, ix
Sylow group, 33
Sylvester's theorem, 577
symmetric
algebra, 635
endomorphism, 525, 585, 597
form, 525, 571
group, 28, 30,269, 272-274
matrix, 530
multilinearmap, 635
polynomial, 190, 217
product, 635, 781, 861
symplectic, 535
basis, 599
syzygy theorem, 862
Szpiro conjecture, 198
Taniyama-Shimura conjecture, 316, 319
Tate group, 50, 163, 169
limit, 598
Taylor series, 213
tensor, 581, 628
algebra, 633
exact, 612
product, 602, 725
product of complexes, 832, 851
product representation, 725, 799
Tits constructionof free group, 81
tor (for torsion), 42, 47, 149
Tor, 622, 791
dimension, 622
Tornheimproof, 471
torsion
free, 45, 147
module, 147, 149
total
complex, 815
degree, 103
totally ordered, 879
tower
of fields, 225
of groups, 18
trace
of element, 284, 666
of linear map, 511, 570
of matrix, 505, 511
INDEX
913
transcendence
basis, 356
degree, 355
of e, 867
transcendental, 99
transitive, 28, 79
translation, 26, 227
transpose
of bifunctor, 808
of linear map, 524
of matrix, 505
transposition, 13
transvection, 542
trigonometric degree, 115
polynomial, 114, 115
trivial
character, 282
operation, 664
representation, 664
subgroup,9
valuation, 465
two-sided ideal, 86, 655
type
of abeliangroup, 43
of module, 149
unimodular, 846
extensionproperty, 849
unipotent, 714
unique factorization, Ill, 116
uniquely divisible, 575
unit, 84
element, 3, 83
ideal, 87
unitary, 535, 583
universal, 37
delta-functor, 800
derivation, 746
universally
attracting, 57
repelling, 57
upper bound, 879
upper diagonal group, 19
valuation, 465
valuationring, 348, 481
determined by ordering, 450, 452
value group, 480
Vandermonde determinant, 257-259, 516
vanishingideal, 38
variable, 99, 104
variationof signs, 454

914
INDEX
variety, 382
vector space, 118, 139
volume, 735
Warning's theorem, 214
Wedderburn' s theorem, 649
Weierstrass
degree, 208
polynomial, 208
preparation theorem, 208
weight, 191
well-behaved, 410, 478
well-defined, x
well-ordering, 891
Weyl group, 570
Witt group, 594, 599
theorem, 591
vector, 330, 492
Witt-Grothendieck group, 595
Zariski-Matsusaka theorem, 372
Zariski topology, 407
Zassenhaus lemma, 20
zero
divisor, 91
element, 3
of ideal, 390, 405
of polynomial, 102, 175,379,390
zeta function, 211, 212, 255
Zorn's lemma, 880, 884

Graduate Texts in Mathematics
TAKEUTIIZARING. Introductionto
34
SPITZER. Principlesof Random Walk.
AxiomaticSet Theory. 2nd ed.
2nd ed.
2
OXTOBY. Measure and Category. 2nd ed.
35
ALEXANDER/WERMER. SeveralComplex
3
SCHAEFER. TopologicalVector Spaces.
Variablesand Banach Algebras. 3rd ed.
2nd ed.
36
KELLEy!NAMIOKA et a1. Linear
4
HILTON/STAMMBACH. A Course in
TopologicalSpaces.
Homological Algebra. 2nd ed.
37
MONK. MathematicalLogic.
5
MAC LANE. Categories for the Working
38
GRAUERTIFRlTZSCHE. SeveralComplex
Mathematician.2nd ed.
Variables.
6
HUGHESIPIPER. Projective Planes.
39
ARVESON. An Invitationto C*-Algebras.
7
J.-P. SERRE. A Course in Arithmetic.
40
KEMENY/SNELLIKNAPP. Denumerable
8
TAKEUTIIZARING. Axiomatic Set Theory.
MarkovChains. 2nd ed.
9
HUMPHREYS. Introductionto LieAlgebras
41
ApOSTOL. ModularFunctionsand
and Representation Theory.
DirichletSeriesin Number Theory.
10
COHEN. A Course in Simple Homotopy
2nd ed.
Theory.
42
J.-P. SERRE. Linear Representations of
11
CONWAY. Functionsof One Complex
FiniteGroups.
VariableI. 2nd ed.
43
GILLMAN/JERISON. Rings of Continuous
12
BEALS. Advanced MathematicalAnalysis.
Functions.
13
ANDERSONlFuLLER. Rings and Categories
44
KENDIG. ElementaryAlgebraicGeometry.
of Modules. 2nd ed.
45
LoiNE. ProbabilityTheoryI. 4th ed.
14
GOLUBITSKY/GUILLEMIN. Stable Mappings
46
LoEVE. ProbabilityTheory 11. 4th ed.
and Their Singularities.
47
MOISE. GeometricTopologyin
15
BERBERIAN. Lecturesin Functional
Dimensions2 and 3.
Analysisand OperatorTheory.
48
SACHS/WU. General Relativityfor
16
WINTER. The Structureof Fields.
Mathematicians.
17
ROSENBLATT. Random Processes. 2nd ed.
49
GRUENBERG/WEIR. LinearGeometry.
18
HALMOS. MeasureTheory.
2nd ed.
19
HALMOS. A HilbertSpace ProblemBook.
50
EDWARDS. Fermat's LastTheorem.
2nd ed.
51
KLINGENBERG. A Course in Differential
20
HUSEMOLLER. FibreBundles. 3rd ed.
Geometry.
21
HUMPHREYS. LinearAlgebraicGroups.
52
HARTSHORNE. AlgebraicGeometry.
22
BARNES/MACK. An Algebraic Introduction
53
MANIN. A Course in MathematicalLogic.
to MathematicalLogic.
54
GRAVER/WATKINS. Combinatoricswith
23
GREUB. LinearAlgebra.4th ed.
Emphasison the Theoryof Graphs.
24
HOLMES. Geometric FunctionalAnalysis
55
BROWN/PEARCY. Introductionto Operator
and Its Applications.
TheoryI: Elementsof FunctionalAnalysis.
25
HEWITT/STROMBERG. Real and Abstract
56
MASSEY. AlgebraicTopology: An
Analysis.
Introduction.
26
MANES. AlgebraicTheories.
57
CROWELLIFox. Introductionto Knot
27
KELLEY. GeneralTopology.
Theory.
28
ZARISKIISAMUEL. CommutativeAlgebra.
58
KOBLITZ.p-adic Numbers,p-adic
Vol.I.
Analysis.and Zeta-Functions. 2nd ed.
29
ZARlsKiiSAMUEL. CommutativeAlgebra.
59
LANG. CyclotomicFields.
Vo1.lI.
60
ARNOLD. MathematicalMethods in
30
JACOBSON. Lecturesin Abstract AlgebraI.
Classical Mechanics. 2nd ed.
Basic Concepts.
61
WHITEHEAD. Elementsof Homotopy
31
JACOBSON. Lecturesin Abstract Algebra 11.
Theory.
LinearAlgebra.
62
KARGAPOLOvIMERLZJAKOV. Fundamentals
32
JACOBSON. Lecturesin Abstract Algebra
of the Theoryof Groups.
111. Theoryof Fields and GaloisTheory.
63
BOLLOBAS. Graph Theory.
33
HIRSCH. DifferentialTopology.

Graduate Texts in Mathematics
64
EDWARDS. FourierSeries. Vol. I. 2nd ed.
96
CONWAY. A Coursein Functional
65
WELLS. Differential Analysison Complex
Analysis. 2nd ed.
Manifolds. 2nd ed.
97
KOBLITZ. Introduction to EllipticCurves
66
WATERHOUSE. Introduction to Affine
and ModularForms. 2nd ed.
GroupSchemes.
98
BROCKERITOM DIECK. Representations of
67
SERRE. LocalFields.
CompactLieGroups.
68
WEIDMANN. LinearOperatorsin Hilbert
99
GROVE!BENSON. Finite ReflectionGroups.
Spaces.
2nd ed.
69
LANG. CyclotomicFieldsII.
100 BERG/CHRISTENSEN/REsSEL. Harmonic
70
MASSEY. SingularHomology Theory.
Analysison Semigroups: Theoryof
71
FARKASIKRA. RiemannSurfaces.2nd ed.
PositiveDefiniteand RelatedFunctions.
72
STILLWELL. ClassicalTopologyand
101 EDWARDS. GaloisTheory.
CombinatorialGroupTheory.2nd ed.
102 VARADARAJAN. LieGroups, Lie Algebras
73
HUNGERFORD. Algebra.
and Their Representations.
74
DAVENPORT. MultiplicativeNumber
103 LANG. ComplexAnalysis. 3rd ed.
Theory. 3rd ed.
104 DUBROVIN/FoMENKOlNovIKOV. Modem
75
HOCHSCHILD. BasicTheoryof Algebraic
Geometry-Methods and Applications.
Groupsand Lie Algebras.
Part II.
76
IITAKA. AlgebraicGeometry.
105 LANG. SL2(R).
77
HECKE. Lectureson the Theoryof
106 SILVERMAN. TheArithmeticof Elliptic
AlgebraicNumbers.
Curves.
78
BURRIS/SANKAPPANAVAR. A Coursein
107 OLVER. Applications of LieGroupsto
UniversalAlgebra.
Differential Equations. 2nd ed.
79
WALTERS. An Introduction to Ergodic
108 RANGE. Holomorphic Functionsand
Theory.
IntegralRepresentations in Several
80
ROBINSON. A Coursein the Theoryof
ComplexVariables.
Groups. 2nd ed.
109 LEHTO. UnivalentFunctionsand
81
FORSTER. Lectureson RiemannSurfaces.
Teichmiiller Spaces.
82
Borr/Tu. Differential Formsin Algebraic
110 LANG. AlgebraicNumberTheory.
Topology.
III
HUSEMOLLER. EllipticCurves. 2nd ed.
83
WASHINGTON. Introduction to Cyclotomic
112 LANG. EllipticFunctions.
Fields.2nd ed.
113 KARATZAS/SHREVE. BrownianMotionand
84
iRELAND/ROSEN. A ClassicalIntroduction
StochasticCalculus. 2nd ed.
to Modem NumberTheory. 2nd ed.
114 KOBLITZ. A Coursein NumberTheoryand
85
EDWARDS. FourierSeries. Vol. II.2nd ed.
Cryptography. 2nd ed.
86
VAN LINT. Introduction to Coding Theory.
115 BERGERIGOSTIAUX. Differential Geometry:
2nd ed.
Manifolds,Curves,and Surfaces.
87
BROWN. Cohomologyof Groups.
116 KELLEy/SRJNNASAN. Measureand
88
PIERCE. AssociativeAlgebras.
Integral. Vol. I.
89
LANG. Introduction to Algebraicand
117 J.-P. SERRE. Algebraic Groupsand Class
AbelianFunctions.2nd ed.
Fields.
90
BR0NDSTED. An Introduction to Convex
118 PEDERSEN. AnalysisNow.
Polytopes.
119 ROTMAN. An Introduction to Algebraic
91
BEARDON. On the Geometryof Discrete
Topology.
Groups.
120 ZIEMER. WeaklyDifferentiable Functions:
92
DIESTEL. Sequencesand Seriesin Banach
SobolevSpacesand Functions of Bounded
Spaces.
Variation.
93
DUBROVINlFoMENKOINOVIKOV. Modem
121 LANG. CyclotomicFieldsI and II.
Geometry-Methods and Applications.
Combined2nd ed.
Part I. 2nd ed.
122 REMMERT. Theoryof ComplexFunctions.
94
WARNER. Foundations of Differentiable
Readingsin Mathematics
Manifoldsand LieGroups.
123 EBBINGHAuS/HERMES et al. Numbers.
95
SHIRYAEV. Probability. 2nd ed.
Readingsin Mathematics

124 DUBROVIN/FoMENKOlNovIKOV. Modem
152 ZIEGLER. Lectureson Polytopes.
Geometry-Methods and Applications.
153 FULTON. AlgebraicTopology: A
Part 1Il
FirstCourse.
125 BERENSTEIN/GAY. Complex Variables:
154 BROWN/PEARCY. An Introductionto
An Introduction.
Analysis.
126 BOREL. Linear Algebraic Groups. 2nd ed.
ISS KAsSEL.Quantum Groups.
127 MASSEY. A Basic Course in Algebraic
156 KECHRIS. Classical Descriptive Set
Topology.
Theory.
128 RAUCH. Partial Differential Equations.
157 MALLIAVIN. Integration and
129 FULTON/HARRIS. Representation Theory: A
Probability.
First Course.
158 ROMAN. FieldTheory.
Readings in Mathematics
159 CONWAY. Functions of One
130 DoOSONIPOSTON. Tensor Geometry.
Complex Variable II.
131
LAM. A First Course in Noncommutative
160
LANG. Differential and Riemannian
Rings. 2nd ed.
Manifolds.
132 BEARDON. Iteration of Rational Functions.
161 BORWEIN/ERDELVI. Polynomials and
133 HARRIS. Algebraic Geometry: A First
Polynomial Inequalities.
Course.
162 ALPERINIBELL. Groupsand
134
ROMAN. Coding and Information Theory.
Representations.
135 ROMAN. Advanced Linear Algebra.
163 DIXON/MORTIMER. PermutationGroups.
136 AOKINsIWEINTRAUB. Algebra: An
164 NATHANSON. Additive Number Theory:
Approachvia Module Theory.
The Classical Bases.
137 AXLERlBoURDON/RAMEY. Harmonic
165 NATHANSON. Additive Number Theory:
FunctionTheory. 2nd ed.
InverseProblems and the Geometryof
138 COHEN. A Course in Computational
Sumsets.
Algebraic Number Theory.
166 SHARPE. DifferentialGeometry: Carlan's
139 BREDON. Topologyand Geometry.
Generalizationof Klein's Erlangen
140 AUBIN. Optima and Equilibria.An
Program.
Introduction to Nonlinear Analysis.
167 MORANDI. Field and GaloisTheory.
141 BECKERIWEISPFENNING/KREOEL. Grebner
168 EWALD. CombinatorialConvexity and
Bases. A Computational Approachto
AlgebraicGeometry.
CommutativeAlgebra.
169 BHATIA. Matrix Analysis.
142 LANG. Real and Functional Analysis.
170 BREDON. Sheaf Theory. 2nd ed.
3rd ed.
171
PETERSEN. RiemannianGeometry.
143 DooB. Measure Theory.
172 REMMERT. ClassicalTopics in Complex
144 DENNlslFARB. Noncommutative
FunctionTheory.
Algebra.
173 DIESTEL.Graph Theory. 2nd ed.
145 VICK. Homology Theory.An
174 BRIDGES. Foundations of Realand
Introduction to Algebraic Topology.
AbstractAnalysis.
2nd ed.
175 LICKORISH. An Introductionto Knot
146 BRIDGES. Computability: A
Theory.
Mathematical Sketchbook.
176 LEE. Riemannian Manifolds.
147
ROSENBERG. Algebraic K-Theory
177 NEWMAN. Analytic Number Theory.
and Its Applications.
178 CLARKEILEDYAEv/STERNIWOLENSKI.
148 ROTMAN. An Introduction to the
Nonsmooth Analysisand Control
Theoryof Groups. 4th ed.
Theory.
149 RATCLIFFE. Foundations of
179 DOUGLAS. Banach AlgebraTechniques in
Hyperbolic Manifolds.
Operator Theory. 2nd ed.
ISO
EISENBUD. Commutative Algebra
180 SRIVASTAVA. A Courseon Borel Sets.
with a ViewToward Algebraic
181 KREss. NumericalAnalysis.
Geometry.
182 WALTER. Ordinary Differential
151
SILVERMAN. AdvancedTopics in
Equations.
the Arithmeticof Elliptic Curves.

183 MEGGINSON. An Introduction to Banach
204 ESCOFIER. GaloisTheory.
SpaceTheory.
205 FEUX/HALPERlNITHOMAS. Rational
184 BOLLOBAS. ModemGraph Theory.
Homotopy Theory. 2nd ed.
185 COx/LITTLE/O'SHEA. UsingAlgebraic
206 MURTY. Problems in Analytic Number
Geometry.
Theory.
186 RAMAKRISHNANNALENZA. Fourier
Readings in Mathematics
Analysis on NumberFields.
207 GODSIIJROYLE. AlgebraicGraph Theory.
187 HARRIslMoRRlSON. Moduli of Curves.
208 CHENEY. Analysis for Applied
188 GOLDBLATT. Lectureson the Hyperreals:
Mathematics.
An Introduction to NonstandardAnalysis.
209 ARVESON. A ShortCourseon Spectral
189 LAM. Lectureson Modulesand Rings.
Theory.
190 EsMONDElMURTY. Problems in Algebraic
210 ROSEN. NumberTheoryin Function
NumberTheory.
Fields.
191 LANG. Fundamentals of Differential
211 LANG. Algebra. Revised 3rd ed.
Geometry.
212 MATOUSEK. Lectureson Discrete
192 HIRSCH/LACOMBE. Elementsof
Geometry.
FunctionalAnalysis.
213 FRlTZSCHE/GRAUERT. FromHolomorphic
193 COHEN. Advanced Topics in
Functions to ComplexManifolds.
ComputationalNumberTheory.
214 JOST. Partial Differential Equations.
194 ENGEliNAGEL. One-Parameter Semigroups
215 GoLDSCHMIDT. AlgebraicFunctionsand
for Linear Evolution Equations.
Projective Curves.
195 NATHANSON. ElementaryMethods in
216 D. SERRE. Matrices: Theory and
NumberTheory.
Applications.
196 OSBORNE. Basic Homological Algebra.
217 MARKER. ModelTheory: An Introduction.
197 EISENBUD/HARRIs. The Geometryof
218 LEE. Introduction to Smooth Manifolds.
Schemes.
219 MACLACHLAN/REID. The Arithmetic of
198 ROBERT. A Course in p-adic Analysis.
Hyperbolic 3-Manifolds.
199 HEDENMALMlKORENBLUMIZHU. Theory
220 NESTRUEV. SmoothManifoldsand
of BergmanSpaces.
Observables.
200 BAO/CHERN/SHEN. An Introduction to
221 GRONBAUM. Convex Polytopes. 2nd ed.
Riemann-Finsler Geometry.
222 HALL. Lie Groups, LieAlgebras,and
201 HINDRY/SILVERMAN. Diophantine
Representations: An Elementary
Geometry: An Introduction.
Introduction.
202 LEE. Introduction to Topological
223 VRETBLAD. FourierAnalysis and
Manifolds.
ItsApplications.
203 SAGAN. The SymmetricGroup:
224 WALSCHAP. MetricStructuresin
Representations, Combinatorial
Differential Geometry.
Algorithms, and SymmetricFunctions.

